loaded G
loaded D
Using device cuda:5
begin rl....
rl epoch 0, begin RL for generator...
batch reward last col mean 0.3061710000038147 first col mean 0.3380054235458374 all mean 0.30855849385261536
rl training, epoch0, iter0, batch0/1133, batch loss:0.9389232397079468, Training time:29.970516681671143
batch reward last col mean 0.3035297393798828 first col mean 0.32296478748321533 all mean 0.30414023995399475
rl training, epoch0, iter0, batch1/1133, batch loss:0.9272671937942505, Training time:60.36073279380798
batch reward last col mean 0.3301692306995392 first col mean 0.32386326789855957 all mean 0.3300570845603943
rl training, epoch0, iter0, batch2/1133, batch loss:0.9201620817184448, Training time:90.10976362228394
batch reward last col mean 0.303998202085495 first col mean 0.3430313467979431 all mean 0.30724477767944336
rl training, epoch0, iter0, batch3/1133, batch loss:0.9527159929275513, Training time:120.3161039352417
batch reward last col mean 0.3071907162666321 first col mean 0.3451305627822876 all mean 0.3093465268611908
rl training, epoch0, iter0, batch4/1133, batch loss:0.9346931576728821, Training time:149.06253671646118
batch reward last col mean 0.33539146184921265 first col mean 0.3298504948616028 all mean 0.3348101079463959
rl training, epoch0, iter0, batch5/1133, batch loss:1.0184204578399658, Training time:177.01019501686096
batch reward last col mean 0.35650143027305603 first col mean 0.35056132078170776 all mean 0.35662195086479187
rl training, epoch0, iter0, batch6/1133, batch loss:1.0394388437271118, Training time:206.64394545555115
batch reward last col mean 0.34025442600250244 first col mean 0.3289378881454468 all mean 0.3399002254009247
rl training, epoch0, iter0, batch7/1133, batch loss:1.0285919904708862, Training time:233.54068660736084
batch reward last col mean 0.345361590385437 first col mean 0.35800448060035706 all mean 0.3438425660133362
rl training, epoch0, iter0, batch8/1133, batch loss:0.9904057383537292, Training time:260.6339716911316
batch reward last col mean 0.3572198152542114 first col mean 0.35847529768943787 all mean 0.35825905203819275
rl training, epoch0, iter0, batch9/1133, batch loss:1.0916976928710938, Training time:287.62260460853577
batch reward last col mean 0.3498828411102295 first col mean 0.326029896736145 all mean 0.3475557565689087
rl training, epoch0, iter0, batch10/1133, batch loss:1.0518138408660889, Training time:314.74382734298706
batch reward last col mean 0.33441776037216187 first col mean 0.33499568700790405 all mean 0.3357442319393158
rl training, epoch0, iter0, batch11/1133, batch loss:0.9690595269203186, Training time:341.923593044281
batch reward last col mean 0.36421293020248413 first col mean 0.3776502013206482 all mean 0.364610493183136
rl training, epoch0, iter0, batch12/1133, batch loss:1.1058629751205444, Training time:368.96775460243225
batch reward last col mean 0.3620775043964386 first col mean 0.37598004937171936 all mean 0.3620215654373169
rl training, epoch0, iter0, batch13/1133, batch loss:1.0998440980911255, Training time:395.93645095825195
batch reward last col mean 0.3531515896320343 first col mean 0.35843533277511597 all mean 0.3547725975513458
rl training, epoch0, iter0, batch14/1133, batch loss:1.0971771478652954, Training time:423.0098316669464
batch reward last col mean 0.3740033209323883 first col mean 0.36359670758247375 all mean 0.37522563338279724
rl training, epoch0, iter0, batch15/1133, batch loss:1.0773627758026123, Training time:450.1886124610901
batch reward last col mean 0.3596007525920868 first col mean 0.3694787919521332 all mean 0.36178189516067505
rl training, epoch0, iter0, batch16/1133, batch loss:1.1458851099014282, Training time:477.4946529865265
batch reward last col mean 0.38947993516921997 first col mean 0.3830115497112274 all mean 0.38898327946662903
rl training, epoch0, iter0, batch17/1133, batch loss:1.154364824295044, Training time:504.7209894657135
batch reward last col mean 0.3850657045841217 first col mean 0.364238977432251 all mean 0.38458967208862305
rl training, epoch0, iter0, batch18/1133, batch loss:1.1371570825576782, Training time:532.0801162719727
batch reward last col mean 0.35716715455055237 first col mean 0.37767404317855835 all mean 0.3607384264469147
rl training, epoch0, iter0, batch19/1133, batch loss:1.125035047531128, Training time:559.5612745285034
batch reward last col mean 0.3751148581504822 first col mean 0.3569808006286621 all mean 0.37732061743736267
rl training, epoch0, iter0, batch20/1133, batch loss:1.1681324243545532, Training time:587.1777160167694
batch reward last col mean 0.3915281891822815 first col mean 0.4032863974571228 all mean 0.39273062348365784
rl training, epoch0, iter0, batch21/1133, batch loss:1.1953085660934448, Training time:614.7393250465393
batch reward last col mean 0.4035720229148865 first col mean 0.411214143037796 all mean 0.4050522744655609
rl training, epoch0, iter0, batch22/1133, batch loss:1.2725870609283447, Training time:642.3621544837952
batch reward last col mean 0.40613892674446106 first col mean 0.41004297137260437 all mean 0.4085026681423187
rl training, epoch0, iter0, batch23/1133, batch loss:1.3077319860458374, Training time:670.0525412559509
batch reward last col mean 0.4665740132331848 first col mean 0.4401339292526245 all mean 0.4598921537399292
rl training, epoch0, iter0, batch24/1133, batch loss:1.4366788864135742, Training time:698.2292585372925
batch reward last col mean 0.42780840396881104 first col mean 0.40731292963027954 all mean 0.42558449506759644
rl training, epoch0, iter0, batch25/1133, batch loss:1.3056137561798096, Training time:726.1815733909607
batch reward last col mean 0.3933961093425751 first col mean 0.4309079647064209 all mean 0.3949326276779175
rl training, epoch0, iter0, batch26/1133, batch loss:1.293163776397705, Training time:754.2715768814087
batch reward last col mean 0.36125636100769043 first col mean 0.36092609167099 all mean 0.36324578523635864
rl training, epoch0, iter0, batch27/1133, batch loss:1.1929744482040405, Training time:782.4807212352753
batch reward last col mean 0.42301782965660095 first col mean 0.44985446333885193 all mean 0.4276171624660492
rl training, epoch0, iter0, batch28/1133, batch loss:1.3836698532104492, Training time:810.819540977478
batch reward last col mean 0.395393043756485 first col mean 0.434874951839447 all mean 0.398237019777298
rl training, epoch0, iter0, batch29/1133, batch loss:1.324771761894226, Training time:839.1636605262756
batch reward last col mean 0.38554736971855164 first col mean 0.43055614829063416 all mean 0.39168083667755127
rl training, epoch0, iter0, batch30/1133, batch loss:1.2760087251663208, Training time:867.4918546676636
batch reward last col mean 0.4130673408508301 first col mean 0.4274263083934784 all mean 0.420167475938797
rl training, epoch0, iter0, batch31/1133, batch loss:1.3124990463256836, Training time:895.9011754989624
batch reward last col mean 0.40699082612991333 first col mean 0.42334845662117004 all mean 0.40964603424072266
rl training, epoch0, iter0, batch32/1133, batch loss:1.2758930921554565, Training time:924.4213526248932
batch reward last col mean 0.4205622375011444 first col mean 0.4379580020904541 all mean 0.4174829423427582
rl training, epoch0, iter0, batch33/1133, batch loss:1.2983479499816895, Training time:952.8796851634979
batch reward last col mean 0.4491384029388428 first col mean 0.4619791805744171 all mean 0.4483605623245239
rl training, epoch0, iter0, batch34/1133, batch loss:1.431777834892273, Training time:981.3837811946869
batch reward last col mean 0.42407840490341187 first col mean 0.4162161648273468 all mean 0.4345332384109497
rl training, epoch0, iter0, batch35/1133, batch loss:1.3751775026321411, Training time:1009.9276165962219
batch reward last col mean 0.3892013430595398 first col mean 0.4282435476779938 all mean 0.3929581344127655
rl training, epoch0, iter0, batch36/1133, batch loss:1.2341301441192627, Training time:1038.4174733161926
batch reward last col mean 0.45212745666503906 first col mean 0.44390004873275757 all mean 0.45136183500289917
rl training, epoch0, iter0, batch37/1133, batch loss:1.3437737226486206, Training time:1066.8923070430756
batch reward last col mean 0.47486960887908936 first col mean 0.44973230361938477 all mean 0.4657834768295288
rl training, epoch0, iter0, batch38/1133, batch loss:1.346600890159607, Training time:1095.5979323387146
batch reward last col mean 0.4354283809661865 first col mean 0.4336787164211273 all mean 0.44144779443740845
rl training, epoch0, iter0, batch39/1133, batch loss:1.3105238676071167, Training time:1124.1413972377777
batch reward last col mean 0.4218289256095886 first col mean 0.43157023191452026 all mean 0.42714497447013855
rl training, epoch0, iter0, batch40/1133, batch loss:1.2734891176223755, Training time:1152.8009898662567
batch reward last col mean 0.4211493134498596 first col mean 0.4179507791996002 all mean 0.42223235964775085
rl training, epoch0, iter0, batch41/1133, batch loss:1.3089327812194824, Training time:1181.3088309764862
batch reward last col mean 0.45424437522888184 first col mean 0.43879765272140503 all mean 0.455441951751709
rl training, epoch0, iter0, batch42/1133, batch loss:1.4276350736618042, Training time:1209.8597149848938
batch reward last col mean 0.4297761619091034 first col mean 0.4512234926223755 all mean 0.43065422773361206
rl training, epoch0, iter0, batch43/1133, batch loss:1.3986984491348267, Training time:1238.278870344162
batch reward last col mean 0.4820416271686554 first col mean 0.4596553146839142 all mean 0.4750312566757202
rl training, epoch0, iter0, batch44/1133, batch loss:1.4361085891723633, Training time:1266.7109150886536
batch reward last col mean 0.41548171639442444 first col mean 0.42856037616729736 all mean 0.41521161794662476
rl training, epoch0, iter0, batch45/1133, batch loss:1.4000545740127563, Training time:1295.2011921405792
batch reward last col mean 0.4648226201534271 first col mean 0.4496914744377136 all mean 0.46282288432121277
rl training, epoch0, iter0, batch46/1133, batch loss:1.4685620069503784, Training time:1323.6215767860413
batch reward last col mean 0.417391300201416 first col mean 0.4660438001155853 all mean 0.4343253970146179
rl training, epoch0, iter0, batch47/1133, batch loss:1.419177532196045, Training time:1352.1492002010345
batch reward last col mean 0.4503069221973419 first col mean 0.4594065845012665 all mean 0.4507423937320709
rl training, epoch0, iter0, batch48/1133, batch loss:1.383417010307312, Training time:1380.6297328472137
batch reward last col mean 0.45932120084762573 first col mean 0.45459842681884766 all mean 0.45829010009765625
rl training, epoch0, iter0, batch49/1133, batch loss:1.4335355758666992, Training time:1409.0291566848755
batch reward last col mean 0.4516105651855469 first col mean 0.4433017075061798 all mean 0.45353808999061584
rl training, epoch0, iter0, batch50/1133, batch loss:1.3747029304504395, Training time:1437.5444266796112
batch reward last col mean 0.45888346433639526 first col mean 0.48023226857185364 all mean 0.45786789059638977
rl training, epoch0, iter0, batch51/1133, batch loss:1.3827342987060547, Training time:1466.0018754005432
batch reward last col mean 0.3950170874595642 first col mean 0.4263104796409607 all mean 0.40337085723876953
rl training, epoch0, iter0, batch52/1133, batch loss:1.2730027437210083, Training time:1494.4968354701996
batch reward last col mean 0.48600953817367554 first col mean 0.4811498820781708 all mean 0.4781627953052521
rl training, epoch0, iter0, batch53/1133, batch loss:1.432425618171692, Training time:1522.973377943039
batch reward last col mean 0.46585366129875183 first col mean 0.47483521699905396 all mean 0.467619389295578
rl training, epoch0, iter0, batch54/1133, batch loss:1.5034537315368652, Training time:1551.4046466350555
batch reward last col mean 0.46247977018356323 first col mean 0.4576694667339325 all mean 0.46776530146598816
rl training, epoch0, iter0, batch55/1133, batch loss:1.4785809516906738, Training time:1579.9191048145294
batch reward last col mean 0.469051718711853 first col mean 0.4944687485694885 all mean 0.4691581428050995
rl training, epoch0, iter0, batch56/1133, batch loss:1.4390826225280762, Training time:1608.5310683250427
batch reward last col mean 0.5085733532905579 first col mean 0.509688675403595 all mean 0.5091120600700378
rl training, epoch0, iter0, batch57/1133, batch loss:1.6086833477020264, Training time:1637.0078558921814
batch reward last col mean 0.45328065752983093 first col mean 0.47917306423187256 all mean 0.45606446266174316
rl training, epoch0, iter0, batch58/1133, batch loss:1.496631383895874, Training time:1665.602467060089
batch reward last col mean 0.45308974385261536 first col mean 0.44931477308273315 all mean 0.4539535939693451
rl training, epoch0, iter0, batch59/1133, batch loss:1.3442580699920654, Training time:1694.0897903442383
batch reward last col mean 0.47164398431777954 first col mean 0.47523394227027893 all mean 0.4759887456893921
rl training, epoch0, iter0, batch60/1133, batch loss:1.418771505355835, Training time:1722.6057922840118
batch reward last col mean 0.4772583842277527 first col mean 0.5029438734054565 all mean 0.4791214168071747
rl training, epoch0, iter0, batch61/1133, batch loss:1.550995945930481, Training time:1750.924207687378
batch reward last col mean 0.5064769387245178 first col mean 0.4972001016139984 all mean 0.5077375173568726
rl training, epoch0, iter0, batch62/1133, batch loss:1.515001893043518, Training time:1779.6349971294403
batch reward last col mean 0.42944252490997314 first col mean 0.469903826713562 all mean 0.447143018245697
rl training, epoch0, iter0, batch63/1133, batch loss:1.396042823791504, Training time:1808.2129492759705
batch reward last col mean 0.49123525619506836 first col mean 0.509056568145752 all mean 0.4880179464817047
rl training, epoch0, iter0, batch64/1133, batch loss:1.4551182985305786, Training time:1836.7723462581635
batch reward last col mean 0.45717841386795044 first col mean 0.48065322637557983 all mean 0.45938417315483093
rl training, epoch0, iter0, batch65/1133, batch loss:1.4129618406295776, Training time:1865.3070073127747
batch reward last col mean 0.5133153796195984 first col mean 0.508484959602356 all mean 0.5086178779602051
rl training, epoch0, iter0, batch66/1133, batch loss:1.5644285678863525, Training time:1893.923977613449
batch reward last col mean 0.46610838174819946 first col mean 0.4559023678302765 all mean 0.46744513511657715
rl training, epoch0, iter0, batch67/1133, batch loss:1.4273205995559692, Training time:1922.5080840587616
batch reward last col mean 0.5033099055290222 first col mean 0.4665929079055786 all mean 0.4916960597038269
rl training, epoch0, iter0, batch68/1133, batch loss:1.4929063320159912, Training time:1951.3340995311737
batch reward last col mean 0.4819669723510742 first col mean 0.5033948421478271 all mean 0.48457297682762146
rl training, epoch0, iter0, batch69/1133, batch loss:1.4633111953735352, Training time:1980.010850429535
batch reward last col mean 0.5190547704696655 first col mean 0.5036101341247559 all mean 0.5175173878669739
rl training, epoch0, iter0, batch70/1133, batch loss:1.53598952293396, Training time:2008.7778840065002
batch reward last col mean 0.4883861839771271 first col mean 0.4791135787963867 all mean 0.4828220307826996
rl training, epoch0, iter0, batch71/1133, batch loss:1.4272243976593018, Training time:2037.8654413223267
batch reward last col mean 0.5440161824226379 first col mean 0.5042690634727478 all mean 0.5235980749130249
rl training, epoch0, iter0, batch72/1133, batch loss:1.4576523303985596, Training time:2066.712643623352
batch reward last col mean 0.5318147540092468 first col mean 0.5069593787193298 all mean 0.5357115864753723
rl training, epoch0, iter0, batch73/1133, batch loss:1.5159492492675781, Training time:2095.744905233383
batch reward last col mean 0.4978395998477936 first col mean 0.49972864985466003 all mean 0.498378723859787
rl training, epoch0, iter0, batch74/1133, batch loss:1.4833917617797852, Training time:2124.552371263504
batch reward last col mean 0.4774973392486572 first col mean 0.5084046721458435 all mean 0.4830024540424347
rl training, epoch0, iter0, batch75/1133, batch loss:1.417806625366211, Training time:2153.5629534721375
batch reward last col mean 0.5615671277046204 first col mean 0.527853786945343 all mean 0.5560115575790405
rl training, epoch0, iter0, batch76/1133, batch loss:1.5212135314941406, Training time:2182.748072385788
batch reward last col mean 0.4784735143184662 first col mean 0.5160244703292847 all mean 0.4806577265262604
rl training, epoch0, iter0, batch77/1133, batch loss:1.3309365510940552, Training time:2211.6670141220093
batch reward last col mean 0.48370689153671265 first col mean 0.5020922422409058 all mean 0.4798244535923004
rl training, epoch0, iter0, batch78/1133, batch loss:1.3489456176757812, Training time:2241.043532371521
batch reward last col mean 0.5459239482879639 first col mean 0.5275631546974182 all mean 0.5388319492340088
rl training, epoch0, iter0, batch79/1133, batch loss:1.398162603378296, Training time:2270.0989520549774
batch reward last col mean 0.53951495885849 first col mean 0.5132066011428833 all mean 0.5370619893074036
rl training, epoch0, iter0, batch80/1133, batch loss:1.394676923751831, Training time:2299.1139662265778
batch reward last col mean 0.5037109851837158 first col mean 0.5201025009155273 all mean 0.510806143283844
rl training, epoch0, iter0, batch81/1133, batch loss:1.3439209461212158, Training time:2328.4727654457092
batch reward last col mean 0.4957387447357178 first col mean 0.5141278505325317 all mean 0.5033031702041626
rl training, epoch0, iter0, batch82/1133, batch loss:1.2408576011657715, Training time:2357.7106652259827
batch reward last col mean 0.49973994493484497 first col mean 0.5092124938964844 all mean 0.509057879447937
rl training, epoch0, iter0, batch83/1133, batch loss:1.2385320663452148, Training time:2386.9384577274323
batch reward last col mean 0.5416607856750488 first col mean 0.5327127575874329 all mean 0.5483221411705017
rl training, epoch0, iter0, batch84/1133, batch loss:1.29185950756073, Training time:2416.1691267490387
batch reward last col mean 0.5314562320709229 first col mean 0.5438517332077026 all mean 0.5360468626022339
rl training, epoch0, iter0, batch85/1133, batch loss:1.34381902217865, Training time:2445.245942592621
batch reward last col mean 0.5048563480377197 first col mean 0.5381209254264832 all mean 0.5114636421203613
rl training, epoch0, iter0, batch86/1133, batch loss:1.2075352668762207, Training time:2474.6000797748566
batch reward last col mean 0.5671333074569702 first col mean 0.5704623460769653 all mean 0.5749306678771973
rl training, epoch0, iter0, batch87/1133, batch loss:1.2686021327972412, Training time:2503.7227075099945
batch reward last col mean 0.592797577381134 first col mean 0.5901479721069336 all mean 0.5983422994613647
rl training, epoch0, iter0, batch88/1133, batch loss:1.247891902923584, Training time:2533.061954021454
batch reward last col mean 0.6064614653587341 first col mean 0.6155616641044617 all mean 0.6026564836502075
rl training, epoch0, iter0, batch89/1133, batch loss:1.2297512292861938, Training time:2562.1248540878296
batch reward last col mean 0.6515712738037109 first col mean 0.6727218627929688 all mean 0.6730661988258362
rl training, epoch0, iter0, batch90/1133, batch loss:1.18107271194458, Training time:2590.9049985408783
batch reward last col mean 0.7135251760482788 first col mean 0.7220088243484497 all mean 0.7330477833747864
rl training, epoch0, iter0, batch91/1133, batch loss:1.104871392250061, Training time:2619.208746433258
batch reward last col mean 0.7625703811645508 first col mean 0.7621591091156006 all mean 0.7561365962028503
rl training, epoch0, iter0, batch92/1133, batch loss:1.069596290588379, Training time:2647.5488171577454
batch reward last col mean 0.8125366568565369 first col mean 0.7903779745101929 all mean 0.8098965883255005
rl training, epoch0, iter0, batch93/1133, batch loss:1.0579971075057983, Training time:2675.4169356822968
batch reward last col mean 0.7461352348327637 first col mean 0.8032354712486267 all mean 0.7998234629631042
rl training, epoch0, iter0, batch94/1133, batch loss:1.069187879562378, Training time:2703.432022333145
batch reward last col mean 0.7952090501785278 first col mean 0.8140262365341187 all mean 0.8173877596855164
rl training, epoch0, iter0, batch95/1133, batch loss:1.1006678342819214, Training time:2730.9280018806458
batch reward last col mean 0.7422279119491577 first col mean 0.7914831638336182 all mean 0.7684841156005859
rl training, epoch0, iter0, batch96/1133, batch loss:1.1146522760391235, Training time:2758.6696009635925
batch reward last col mean 0.7834896445274353 first col mean 0.787494957447052 all mean 0.8117826581001282
rl training, epoch0, iter0, batch97/1133, batch loss:1.2425330877304077, Training time:2786.33838391304
batch reward last col mean 0.8014465570449829 first col mean 0.7805588245391846 all mean 0.7869301438331604
rl training, epoch0, iter0, batch98/1133, batch loss:1.2322161197662354, Training time:2814.065155506134
batch reward last col mean 0.8161244988441467 first col mean 0.8184414505958557 all mean 0.8276628255844116
rl training, epoch0, iter0, batch99/1133, batch loss:1.255919337272644, Training time:2841.6115436553955
batch reward last col mean 0.8330208659172058 first col mean 0.8483349680900574 all mean 0.8613372445106506
rl training, epoch0, iter0, batch100/1133, batch loss:1.2287356853485107, Training time:2869.2434833049774
batch reward last col mean 0.8549294471740723 first col mean 0.8729952573776245 all mean 0.8654889464378357
rl training, epoch0, iter0, batch101/1133, batch loss:1.1750800609588623, Training time:2896.579010486603
batch reward last col mean 0.853055477142334 first col mean 0.8895460963249207 all mean 0.8716138005256653
rl training, epoch0, iter0, batch102/1133, batch loss:1.0924986600875854, Training time:2923.918532371521
batch reward last col mean 0.8807011842727661 first col mean 0.9018500447273254 all mean 0.8983045816421509
rl training, epoch0, iter0, batch103/1133, batch loss:0.965829074382782, Training time:2951.284968852997
batch reward last col mean 0.8893336653709412 first col mean 0.9011259078979492 all mean 0.9045533537864685
rl training, epoch0, iter0, batch104/1133, batch loss:0.8342183828353882, Training time:2978.535649061203
batch reward last col mean 0.8832367658615112 first col mean 0.8953171372413635 all mean 0.9021056890487671
rl training, epoch0, iter0, batch105/1133, batch loss:0.7542194724082947, Training time:3005.956051826477
batch reward last col mean 0.9124234914779663 first col mean 0.9249580502510071 all mean 0.922918438911438
rl training, epoch0, iter0, batch106/1133, batch loss:0.7638710737228394, Training time:3033.365694999695
batch reward last col mean 0.8820961117744446 first col mean 0.8959505558013916 all mean 0.9053336977958679
rl training, epoch0, iter0, batch107/1133, batch loss:0.7176231741905212, Training time:3060.8001713752747
batch reward last col mean 0.9269088506698608 first col mean 0.9226891398429871 all mean 0.9342567920684814
rl training, epoch0, iter0, batch108/1133, batch loss:0.7020906209945679, Training time:3087.9787497520447
batch reward last col mean 0.8975855708122253 first col mean 0.9049686193466187 all mean 0.9061497449874878
rl training, epoch0, iter0, batch109/1133, batch loss:0.6850645542144775, Training time:3115.236720561981
batch reward last col mean 0.8443812131881714 first col mean 0.884207010269165 all mean 0.8796294331550598
rl training, epoch0, iter0, batch110/1133, batch loss:0.6919684410095215, Training time:3142.394085407257
batch reward last col mean 0.9056212306022644 first col mean 0.8897983431816101 all mean 0.8980236649513245
rl training, epoch0, iter0, batch111/1133, batch loss:0.7263217568397522, Training time:3169.5772738456726
batch reward last col mean 0.8511072993278503 first col mean 0.8806347250938416 all mean 0.8900268077850342
rl training, epoch0, iter0, batch112/1133, batch loss:0.7085057497024536, Training time:3196.7474884986877
batch reward last col mean 0.842458188533783 first col mean 0.879681408405304 all mean 0.8773506283760071
rl training, epoch0, iter0, batch113/1133, batch loss:0.708340585231781, Training time:3223.834746360779
batch reward last col mean 0.8663336038589478 first col mean 0.8776354789733887 all mean 0.8796923160552979
rl training, epoch0, iter0, batch114/1133, batch loss:0.7474308609962463, Training time:3250.9773802757263
batch reward last col mean 0.886303186416626 first col mean 0.8740426301956177 all mean 0.8757103681564331
rl training, epoch0, iter0, batch115/1133, batch loss:0.7288952469825745, Training time:3278.006244659424
batch reward last col mean 0.8703145384788513 first col mean 0.9008663296699524 all mean 0.892427921295166
rl training, epoch0, iter0, batch116/1133, batch loss:0.7366050481796265, Training time:3305.0389289855957
batch reward last col mean 0.9199422001838684 first col mean 0.9054726958274841 all mean 0.9150855541229248
rl training, epoch0, iter0, batch117/1133, batch loss:0.6991364359855652, Training time:3332.1216650009155
batch reward last col mean 0.9390993118286133 first col mean 0.9166993498802185 all mean 0.9187508225440979
rl training, epoch0, iter0, batch118/1133, batch loss:0.6363223791122437, Training time:3359.2612957954407
batch reward last col mean 0.9188952445983887 first col mean 0.9223256707191467 all mean 0.9247487187385559
rl training, epoch0, iter0, batch119/1133, batch loss:0.6327412128448486, Training time:3386.356593847275
batch reward last col mean 0.9351345300674438 first col mean 0.9298245906829834 all mean 0.9330599904060364
rl training, epoch0, iter0, batch120/1133, batch loss:0.6101117134094238, Training time:3413.433948278427
batch reward last col mean 0.9461384415626526 first col mean 0.9376894235610962 all mean 0.9486110210418701
rl training, epoch0, iter0, batch121/1133, batch loss:0.6796332001686096, Training time:3440.3717074394226
batch reward last col mean 0.9527311325073242 first col mean 0.9593771696090698 all mean 0.9588183164596558
rl training, epoch0, iter0, batch122/1133, batch loss:0.747069239616394, Training time:3467.2998943328857
RL early break
rl training, epoch 0, iter 0, loss:1.1911952437424078, Training time:3467.304185628891 
rl epoch 0, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6540988920961769 Time: 198.60255026817322 s
cur_epoch: 1
D Training Loss: 0.5890537977797313 Time: 174.84534335136414 s
cur_epoch: 2
D Training Loss: 0.5467341330760576 Time: 174.97319841384888 s
cur_epoch: 3
D Training Loss: 0.5195703367585117 Time: 174.89318537712097 s
cur_epoch: 4
D Training Loss: 0.48840766128511 Time: 175.4600865840912 s
rl epoch 1, begin RL for generator...
batch reward last col mean 0.0002500132832210511 first col mean 7.481727379854419e-07 all mean 0.00026527277077548206
rl training, epoch1, iter0, batch0/1133, batch loss:0.00012059810251230374, Training time:4393.084822893143
batch reward last col mean 7.131754703318662e-17 first col mean 0.0010468902764841914 all mean 4.216344314045273e-05
rl training, epoch1, iter0, batch1/1133, batch loss:6.751184992026538e-05, Training time:4420.065936326981
batch reward last col mean 2.129479045141611e-17 first col mean 0.0001295315014431253 all mean 3.9368947909679264e-05
rl training, epoch1, iter0, batch2/1133, batch loss:7.128938887035474e-05, Training time:4446.845757484436
batch reward last col mean 4.3554273211556145e-15 first col mean 0.0008464333950541914 all mean 1.8296723283128813e-05
rl training, epoch1, iter0, batch3/1133, batch loss:3.2793010177556425e-05, Training time:4473.670031785965
batch reward last col mean 1.0409681709016346e-14 first col mean 0.0016081680078059435 all mean 6.130306428531185e-05
rl training, epoch1, iter0, batch4/1133, batch loss:7.158635708037764e-05, Training time:4500.498799800873
batch reward last col mean 2.4496573587384773e-06 first col mean 1.62908736456302e-06 all mean 3.212735100532882e-05
rl training, epoch1, iter0, batch5/1133, batch loss:5.404004696174525e-05, Training time:4527.400365829468
batch reward last col mean 4.294776658753108e-07 first col mean 5.1335300454979915e-09 all mean 4.696463292930275e-05
rl training, epoch1, iter0, batch6/1133, batch loss:5.728714313590899e-05, Training time:4554.215763568878
batch reward last col mean 0.005025137215852737 first col mean 3.2209216442424804e-05 all mean 0.004201630130410194
rl training, epoch1, iter0, batch7/1133, batch loss:0.0008044744608923793, Training time:4581.1368932724
batch reward last col mean 1.0296762574524276e-11 first col mean 1.0118659702129662e-05 all mean 4.6536104491679e-05
rl training, epoch1, iter0, batch8/1133, batch loss:3.0747276468900964e-05, Training time:4607.859243154526
batch reward last col mean 0.0003186442772857845 first col mean 0.0018671408761292696 all mean 0.00023625783796887845
rl training, epoch1, iter0, batch9/1133, batch loss:7.879504846641794e-05, Training time:4634.674071073532
batch reward last col mean 1.3335825499449783e-10 first col mean 0.0008777647744864225 all mean 5.6353852414758876e-05
rl training, epoch1, iter0, batch10/1133, batch loss:5.973266888759099e-05, Training time:4661.49705862999
batch reward last col mean 0.0008926769951358438 first col mean 0.0009571867412887514 all mean 0.0009544930653646588
rl training, epoch1, iter0, batch11/1133, batch loss:0.00014539246330969036, Training time:4688.350438117981
batch reward last col mean 4.831657133763656e-05 first col mean 9.633554043375625e-08 all mean 0.00013287796173244715
rl training, epoch1, iter0, batch12/1133, batch loss:0.0002117952681146562, Training time:4715.146686553955
batch reward last col mean 1.4983309460769173e-13 first col mean 0.0027769366279244423 all mean 6.42013328615576e-05
rl training, epoch1, iter0, batch13/1133, batch loss:0.00027851268532685935, Training time:4741.860233545303
batch reward last col mean 1.2085602065781131e-05 first col mean 0.0018489451613277197 all mean 8.081013220362365e-05
rl training, epoch1, iter0, batch14/1133, batch loss:0.0001475480239605531, Training time:4768.652796268463
batch reward last col mean 0.00010597382788546383 first col mean 0.000275928876362741 all mean 0.00015368116146419197
rl training, epoch1, iter0, batch15/1133, batch loss:0.00012538881856016815, Training time:4795.453323841095
batch reward last col mean 1.1861446182592772e-05 first col mean 0.0010242648422718048 all mean 8.776319009484723e-05
rl training, epoch1, iter0, batch16/1133, batch loss:0.00013239079271443188, Training time:4822.209348678589
batch reward last col mean 7.942967172880344e-09 first col mean 0.0017994914669543505 all mean 0.00010622163244988769
rl training, epoch1, iter0, batch17/1133, batch loss:0.00021921021107118577, Training time:4848.871106624603
batch reward last col mean 2.0628788206522586e-06 first col mean 0.0002676423464436084 all mean 6.947790825506672e-05
rl training, epoch1, iter0, batch18/1133, batch loss:0.0001809782552300021, Training time:4875.520877122879
batch reward last col mean 8.849109872244298e-05 first col mean 0.0019035310251638293 all mean 0.00011264102795394138
rl training, epoch1, iter0, batch19/1133, batch loss:0.00023103538842406124, Training time:4902.157917737961
batch reward last col mean 4.1694428887240065e-07 first col mean 3.24950015055947e-05 all mean 5.9855687140952796e-05
rl training, epoch1, iter0, batch20/1133, batch loss:0.00018084864132106304, Training time:4928.65744137764
batch reward last col mean 0.0028355263639241457 first col mean 4.531693411991e-05 all mean 0.002456055721268058
rl training, epoch1, iter0, batch21/1133, batch loss:0.0004078350611962378, Training time:4955.359843969345
batch reward last col mean 2.788011249817146e-13 first col mean 1.825573963287752e-05 all mean 0.00010949617717415094
rl training, epoch1, iter0, batch22/1133, batch loss:8.181798330042511e-05, Training time:4982.020968198776
batch reward last col mean 9.44796473586855e-14 first col mean 9.8474611149868e-06 all mean 8.089311450021341e-05
rl training, epoch1, iter0, batch23/1133, batch loss:0.00013278648839332163, Training time:5008.614368915558
batch reward last col mean 0.0014688698574900627 first col mean 0.0014337083557620645 all mean 0.0012869903584942222
rl training, epoch1, iter0, batch24/1133, batch loss:0.00029232283122837543, Training time:5035.340909481049
batch reward last col mean 5.891905675525777e-05 first col mean 1.1759634332975111e-07 all mean 0.00011662772158160806
rl training, epoch1, iter0, batch25/1133, batch loss:0.00016093860904220492, Training time:5062.045162677765
batch reward last col mean 6.372927359443725e-13 first col mean 0.0029660083819180727 all mean 0.0001070434955181554
rl training, epoch1, iter0, batch26/1133, batch loss:0.00022229744354262948, Training time:5088.719306945801
batch reward last col mean 6.145517090772046e-07 first col mean 1.1671600077534094e-06 all mean 0.00010685673623811454
rl training, epoch1, iter0, batch27/1133, batch loss:0.0002772095031104982, Training time:5115.455614566803
batch reward last col mean 0.00017659262812230736 first col mean 3.2277715945383534e-05 all mean 0.00020494349882937968
rl training, epoch1, iter0, batch28/1133, batch loss:0.00016219360986724496, Training time:5142.140208482742
batch reward last col mean 0.00012556811270769686 first col mean 0.0007297200500033796 all mean 0.00019405223429203033
rl training, epoch1, iter0, batch29/1133, batch loss:0.00020395370665937662, Training time:5168.9017243385315
batch reward last col mean 0.0002573027741163969 first col mean 0.0004557477368507534 all mean 0.00017170260252896696
rl training, epoch1, iter0, batch30/1133, batch loss:0.0003271523164585233, Training time:5195.604309558868
batch reward last col mean 0.0004994154442101717 first col mean 2.5283003196818754e-05 all mean 0.0003380489069968462
rl training, epoch1, iter0, batch31/1133, batch loss:0.00020381039939820766, Training time:5222.345981836319
batch reward last col mean 6.0983464209130034e-05 first col mean 0.0021989294327795506 all mean 0.00020120403496548533
rl training, epoch1, iter0, batch32/1133, batch loss:0.00036730527062900364, Training time:5249.0894429683685
batch reward last col mean 1.041181233569187e-13 first col mean 0.005006236489862204 all mean 0.0001681468274910003
rl training, epoch1, iter0, batch33/1133, batch loss:0.0002310581912752241, Training time:5275.774561882019
batch reward last col mean 1.4773904410958494e-07 first col mean 0.0010211360640823841 all mean 0.00010549758735578507
rl training, epoch1, iter0, batch34/1133, batch loss:8.565671305404976e-05, Training time:5302.500120639801
batch reward last col mean 0.007010980509221554 first col mean 0.0016202537808567286 all mean 0.00679022865369916
rl training, epoch1, iter0, batch35/1133, batch loss:0.0011522929416969419, Training time:5329.2262988090515
batch reward last col mean 0.006972450762987137 first col mean 0.0001277820992982015 all mean 0.006987976375967264
rl training, epoch1, iter0, batch36/1133, batch loss:0.0008104303269647062, Training time:5356.273906946182
batch reward last col mean 0.0005440444219857454 first col mean 0.002370548667386174 all mean 0.00031417058198712766
rl training, epoch1, iter0, batch37/1133, batch loss:0.00022841802274342626, Training time:5383.298196315765
batch reward last col mean 0.006922656204551458 first col mean 4.996172719984315e-05 all mean 0.005079296883195639
rl training, epoch1, iter0, batch38/1133, batch loss:0.0007723472081124783, Training time:5410.148499011993
batch reward last col mean 0.0016155691118910909 first col mean 5.731410055886954e-05 all mean 0.001441657543182373
rl training, epoch1, iter0, batch39/1133, batch loss:0.0005269104731269181, Training time:5437.070882558823
batch reward last col mean 0.011855816468596458 first col mean 9.92849818430841e-05 all mean 0.011445426382124424
rl training, epoch1, iter0, batch40/1133, batch loss:0.0015301243402063847, Training time:5464.127304315567
batch reward last col mean 2.381099903914219e-07 first col mean 0.000918661942705512 all mean 9.72700581769459e-05
rl training, epoch1, iter0, batch41/1133, batch loss:0.00018697063205763698, Training time:5491.295694112778
batch reward last col mean 0.00019897120364475995 first col mean 0.0006235354812815785 all mean 0.00017120125994551927
rl training, epoch1, iter0, batch42/1133, batch loss:0.00011768829426728189, Training time:5517.991267442703
batch reward last col mean 0.00017019746883306652 first col mean 3.0727321700396715e-06 all mean 0.0002656594733707607
rl training, epoch1, iter0, batch43/1133, batch loss:0.00018968350195791572, Training time:5544.83846449852
batch reward last col mean 4.0617470631332253e-07 first col mean 0.0002857778163161129 all mean 0.0001281160512007773
rl training, epoch1, iter0, batch44/1133, batch loss:0.0003401707508601248, Training time:5571.83567404747
batch reward last col mean 0.00664268434047699 first col mean 0.00022221308609005064 all mean 0.006242049857974052
rl training, epoch1, iter0, batch45/1133, batch loss:0.0011744439834728837, Training time:5598.993525028229
batch reward last col mean 2.7975771445198916e-05 first col mean 0.001383375027216971 all mean 0.00016424234490841627
rl training, epoch1, iter0, batch46/1133, batch loss:0.0002915924706030637, Training time:5625.677892923355
batch reward last col mean 1.0929707968898583e-05 first col mean 0.0004254147061146796 all mean 0.00018351981998421252
rl training, epoch1, iter0, batch47/1133, batch loss:0.0002639520389493555, Training time:5652.8219265937805
batch reward last col mean 4.985333977233775e-13 first col mean 0.0018885263707488775 all mean 0.00017581666179466993
rl training, epoch1, iter0, batch48/1133, batch loss:0.000268541305558756, Training time:5679.780140399933
batch reward last col mean 4.2684470827225596e-05 first col mean 0.0009301357786171138 all mean 9.352058987133205e-05
rl training, epoch1, iter0, batch49/1133, batch loss:7.692860526731238e-05, Training time:5706.826353788376
batch reward last col mean 0.010244312696158886 first col mean 0.0006471530650742352 all mean 0.009492963552474976
rl training, epoch1, iter0, batch50/1133, batch loss:0.0014309196267277002, Training time:5733.944766521454
batch reward last col mean 0.0002962899743579328 first col mean 6.777571979910135e-05 all mean 0.00036159734008833766
rl training, epoch1, iter0, batch51/1133, batch loss:0.00022544075909536332, Training time:5760.899614095688
batch reward last col mean 1.4874898113248491e-07 first col mean 0.0005479849060066044 all mean 0.0001333916443400085
rl training, epoch1, iter0, batch52/1133, batch loss:0.00017502025002613664, Training time:5787.881729125977
batch reward last col mean 0.004404190927743912 first col mean 0.0005976904649287462 all mean 0.0031706395093351603
rl training, epoch1, iter0, batch53/1133, batch loss:0.0006270948215387762, Training time:5814.814117908478
batch reward last col mean 1.5682289813412353e-05 first col mean 8.546731260139495e-05 all mean 0.00011480474495328963
rl training, epoch1, iter0, batch54/1133, batch loss:0.00016266139573417604, Training time:5841.703446626663
batch reward last col mean 6.172477878862992e-05 first col mean 4.064627501065843e-05 all mean 0.00026067779981531203
rl training, epoch1, iter0, batch55/1133, batch loss:0.00027483722078613937, Training time:5868.74063706398
batch reward last col mean 0.0001013289947877638 first col mean 0.0016923173097893596 all mean 0.00019841727043967694
rl training, epoch1, iter0, batch56/1133, batch loss:0.00034468862577341497, Training time:5895.581022262573
batch reward last col mean 0.005446594674140215 first col mean 0.0020750616677105427 all mean 0.0016860115574672818
rl training, epoch1, iter0, batch57/1133, batch loss:0.0009929699590429664, Training time:5922.641668081284
batch reward last col mean 0.0013161060633137822 first col mean 0.00106778834015131 all mean 0.0006994474097155035
rl training, epoch1, iter0, batch58/1133, batch loss:0.0003980763431172818, Training time:5949.683797597885
batch reward last col mean 7.496474836443667e-07 first col mean 0.001979655819013715 all mean 0.00024586592917330563
rl training, epoch1, iter0, batch59/1133, batch loss:0.00032570597250014544, Training time:5976.720222949982
batch reward last col mean 3.618275513872504e-05 first col mean 0.0007540746591985226 all mean 9.357923408970237e-05
rl training, epoch1, iter0, batch60/1133, batch loss:9.105079516302794e-05, Training time:6003.567052364349
batch reward last col mean 0.00014981426647864282 first col mean 5.062362106400542e-06 all mean 0.00030056710238568485
rl training, epoch1, iter0, batch61/1133, batch loss:0.0003594890877138823, Training time:6030.727788925171
batch reward last col mean 6.437110278056934e-05 first col mean 0.00024893839145079255 all mean 0.0001629545440664515
rl training, epoch1, iter0, batch62/1133, batch loss:0.0002088201290462166, Training time:6057.714214086533
batch reward last col mean 0.008466599509119987 first col mean 6.105346255935729e-05 all mean 0.0042940895073115826
rl training, epoch1, iter0, batch63/1133, batch loss:0.0011984810698777437, Training time:6084.809905290604
batch reward last col mean 4.0574275772087276e-05 first col mean 0.0013584722764790058 all mean 0.0002332092699361965
rl training, epoch1, iter0, batch64/1133, batch loss:0.000319870887324214, Training time:6111.667822122574
batch reward last col mean 8.574618732382078e-06 first col mean 0.0006950211245566607 all mean 0.0003784473519772291
rl training, epoch1, iter0, batch65/1133, batch loss:0.0005373075255192816, Training time:6138.672786474228
batch reward last col mean 0.00776435574516654 first col mean 0.00015208919649012387 all mean 0.007474196143448353
rl training, epoch1, iter0, batch66/1133, batch loss:0.0012412008363753557, Training time:6165.7198185920715
batch reward last col mean 4.301745866541751e-05 first col mean 0.0011983502190560102 all mean 0.00044885932584293187
rl training, epoch1, iter0, batch67/1133, batch loss:0.0008331864955835044, Training time:6192.771306991577
batch reward last col mean 0.0024095482658594847 first col mean 0.0003639580390881747 all mean 0.0023275245912373066
rl training, epoch1, iter0, batch68/1133, batch loss:0.000567899493034929, Training time:6219.7752006053925
batch reward last col mean 0.003422569716349244 first col mean 0.0010495171882212162 all mean 0.003395382547751069
rl training, epoch1, iter0, batch69/1133, batch loss:0.000613768701441586, Training time:6246.959552288055
batch reward last col mean 0.00010964054672513157 first col mean 0.001252250513061881 all mean 0.0002051455230684951
rl training, epoch1, iter0, batch70/1133, batch loss:0.00029683156753890216, Training time:6273.863886356354
batch reward last col mean 6.532204861287028e-05 first col mean 0.0010543792741373181 all mean 0.0003778957761824131
rl training, epoch1, iter0, batch71/1133, batch loss:0.0005429192679002881, Training time:6301.19366145134
batch reward last col mean 0.00048406669520772994 first col mean 0.0003156607272103429 all mean 0.0005250266985967755
rl training, epoch1, iter0, batch72/1133, batch loss:0.0003666016855277121, Training time:6328.172668933868
batch reward last col mean 0.0007543286774307489 first col mean 0.0007338383584283292 all mean 0.0008112590294331312
rl training, epoch1, iter0, batch73/1133, batch loss:0.000623025989625603, Training time:6355.2858073711395
batch reward last col mean 0.0011373176239430904 first col mean 1.0220997864962555e-05 all mean 0.0010429528774693608
rl training, epoch1, iter0, batch74/1133, batch loss:0.0007703840965405107, Training time:6382.237148284912
batch reward last col mean 1.9668093542701826e-10 first col mean 0.0013439134927466512 all mean 0.0003729863674379885
rl training, epoch1, iter0, batch75/1133, batch loss:0.0006864232709631324, Training time:6409.094767093658
batch reward last col mean 0.005225791595876217 first col mean 0.00038732640678063035 all mean 0.002937741344794631
rl training, epoch1, iter0, batch76/1133, batch loss:0.0009270660812035203, Training time:6436.198003530502
batch reward last col mean 3.270200750193908e-06 first col mean 0.0009643217781558633 all mean 0.00045407243305817246
rl training, epoch1, iter0, batch77/1133, batch loss:0.000586933339945972, Training time:6463.283816099167
batch reward last col mean 0.0002163041936000809 first col mean 0.0005953444633632898 all mean 0.00044511552550829947
rl training, epoch1, iter0, batch78/1133, batch loss:0.0005454377387650311, Training time:6490.305838346481
batch reward last col mean 0.008959058672189713 first col mean 0.003910352475941181 all mean 0.008353388868272305
rl training, epoch1, iter0, batch79/1133, batch loss:0.0015985541976988316, Training time:6517.251458406448
batch reward last col mean 0.013299444690346718 first col mean 0.0020746877416968346 all mean 0.011938010342419147
rl training, epoch1, iter0, batch80/1133, batch loss:0.0021213283762335777, Training time:6544.398685693741
batch reward last col mean 6.819207919761539e-05 first col mean 0.0008692165138199925 all mean 0.0006799728143960238
rl training, epoch1, iter0, batch81/1133, batch loss:0.0009935576235875487, Training time:6571.453161239624
batch reward last col mean 0.00037261127727106214 first col mean 0.001388049335218966 all mean 0.0006811809143982828
rl training, epoch1, iter0, batch82/1133, batch loss:0.0006097753066569567, Training time:6598.495918750763
batch reward last col mean 0.0010913892183452845 first col mean 0.002569604432210326 all mean 0.0011177037376910448
rl training, epoch1, iter0, batch83/1133, batch loss:0.001056638197042048, Training time:6625.457068681717
batch reward last col mean 0.00028998241759836674 first col mean 0.0011763537768274546 all mean 0.0007953697931952775
rl training, epoch1, iter0, batch84/1133, batch loss:0.001211823895573616, Training time:6652.349777936935
batch reward last col mean 6.817899702582508e-06 first col mean 0.0009910413064062595 all mean 0.0009541285689920187
rl training, epoch1, iter0, batch85/1133, batch loss:0.001443033223040402, Training time:6679.295833349228
batch reward last col mean 0.007950383238494396 first col mean 0.0019750939682126045 all mean 0.007501673419028521
rl training, epoch1, iter0, batch86/1133, batch loss:0.001674311701208353, Training time:6706.112508773804
batch reward last col mean 0.005881825927644968 first col mean 0.0029613282531499863 all mean 0.004964620806276798
rl training, epoch1, iter0, batch87/1133, batch loss:0.0014965138398110867, Training time:6733.236587047577
batch reward last col mean 0.0016407778020948172 first col mean 0.0012740505626425147 all mean 0.0016520876670256257
rl training, epoch1, iter0, batch88/1133, batch loss:0.0011780861532315612, Training time:6760.251146316528
batch reward last col mean 0.00010211470362264663 first col mean 0.0015997663140296936 all mean 0.0010918875923380256
rl training, epoch1, iter0, batch89/1133, batch loss:0.001372164231725037, Training time:6787.187776565552
batch reward last col mean 0.0065184482373297215 first col mean 0.0019885350484400988 all mean 0.00574144022539258
rl training, epoch1, iter0, batch90/1133, batch loss:0.002511624712496996, Training time:6814.347720384598
batch reward last col mean 0.012731857597827911 first col mean 0.006959070917218924 all mean 0.00904093123972416
rl training, epoch1, iter0, batch91/1133, batch loss:0.0022739379201084375, Training time:6841.717106342316
batch reward last col mean 0.0001697657717159018 first col mean 0.003978181630373001 all mean 0.0009421315044164658
rl training, epoch1, iter0, batch92/1133, batch loss:0.0011781486682593822, Training time:6868.8265516757965
batch reward last col mean 0.001152664772234857 first col mean 0.0026169202756136656 all mean 0.0013897347962483764
rl training, epoch1, iter0, batch93/1133, batch loss:0.0017188064521178603, Training time:6895.804757356644
batch reward last col mean 0.001836202573031187 first col mean 0.0066425129771232605 all mean 0.0033516143448650837
rl training, epoch1, iter0, batch94/1133, batch loss:0.002305608941242099, Training time:6923.015789747238
batch reward last col mean 0.003811277449131012 first col mean 0.0021571742836385965 all mean 0.002620491199195385
rl training, epoch1, iter0, batch95/1133, batch loss:0.001954444916918874, Training time:6950.151486873627
batch reward last col mean 0.009039337746798992 first col mean 0.005503552500158548 all mean 0.004370919428765774
rl training, epoch1, iter0, batch96/1133, batch loss:0.003944517113268375, Training time:6977.295986413956
batch reward last col mean 0.0009822803549468517 first col mean 0.004002835135906935 all mean 0.002305359346792102
rl training, epoch1, iter0, batch97/1133, batch loss:0.0028317521791905165, Training time:7004.533559322357
batch reward last col mean 0.005233447067439556 first col mean 0.00716184638440609 all mean 0.002742381999269128
rl training, epoch1, iter0, batch98/1133, batch loss:0.0029104682616889477, Training time:7031.7052545547485
batch reward last col mean 0.009486278519034386 first col mean 0.007000303361564875 all mean 0.007232033647596836
rl training, epoch1, iter0, batch99/1133, batch loss:0.004213918466120958, Training time:7059.291018486023
batch reward last col mean 0.005279870703816414 first col mean 0.0086637819185853 all mean 0.007016136310994625
rl training, epoch1, iter0, batch100/1133, batch loss:0.00664427038282156, Training time:7086.598656654358
batch reward last col mean 0.02383791096508503 first col mean 0.0056988392025232315 all mean 0.017675207927823067
rl training, epoch1, iter0, batch101/1133, batch loss:0.005417360458523035, Training time:7114.168565750122
batch reward last col mean 0.0028806354384869337 first col mean 0.0033532315865159035 all mean 0.005011961329728365
rl training, epoch1, iter0, batch102/1133, batch loss:0.0052167801186442375, Training time:7141.377794504166
batch reward last col mean 0.009856139309704304 first col mean 0.014364752918481827 all mean 0.007387930527329445
rl training, epoch1, iter0, batch103/1133, batch loss:0.006347617134451866, Training time:7168.930379867554
batch reward last col mean 0.007945530116558075 first col mean 0.011982517316937447 all mean 0.0097660468891263
rl training, epoch1, iter0, batch104/1133, batch loss:0.009272519499063492, Training time:7196.411830663681
batch reward last col mean 0.010296326130628586 first col mean 0.013909399509429932 all mean 0.0115117859095335
rl training, epoch1, iter0, batch105/1133, batch loss:0.009684725664556026, Training time:7223.981453895569
batch reward last col mean 0.02487906441092491 first col mean 0.011545492336153984 all mean 0.026346838101744652
rl training, epoch1, iter0, batch106/1133, batch loss:0.014793171547353268, Training time:7251.753909111023
batch reward last col mean 0.015404241159558296 first col mean 0.020725788548588753 all mean 0.01832074299454689
rl training, epoch1, iter0, batch107/1133, batch loss:0.014601022005081177, Training time:7279.337944984436
batch reward last col mean 0.013246128335595131 first col mean 0.016697682440280914 all mean 0.014168859459459782
rl training, epoch1, iter0, batch108/1133, batch loss:0.014829853549599648, Training time:7307.02664732933
batch reward last col mean 0.02411509118974209 first col mean 0.026368577033281326 all mean 0.01723705604672432
rl training, epoch1, iter0, batch109/1133, batch loss:0.012656008824706078, Training time:7334.856810092926
batch reward last col mean 0.04693545773625374 first col mean 0.048723749816417694 all mean 0.03796658292412758
rl training, epoch1, iter0, batch110/1133, batch loss:0.0428372323513031, Training time:7362.886909484863
batch reward last col mean 0.0739976093173027 first col mean 0.06407392024993896 all mean 0.059987396001815796
rl training, epoch1, iter0, batch111/1133, batch loss:0.057197555899620056, Training time:7391.263752222061
batch reward last col mean 0.04709907993674278 first col mean 0.04793725162744522 all mean 0.05024900287389755
rl training, epoch1, iter0, batch112/1133, batch loss:0.04577836021780968, Training time:7419.870168209076
batch reward last col mean 0.0722668319940567 first col mean 0.07612500339746475 all mean 0.08347077667713165
rl training, epoch1, iter0, batch113/1133, batch loss:0.08244865387678146, Training time:7448.643000125885
batch reward last col mean 0.09109519422054291 first col mean 0.09020422399044037 all mean 0.08593259006738663
rl training, epoch1, iter0, batch114/1133, batch loss:0.0847659558057785, Training time:7477.7228536605835
batch reward last col mean 0.13725531101226807 first col mean 0.12346057593822479 all mean 0.14128443598747253
rl training, epoch1, iter0, batch115/1133, batch loss:0.18658563494682312, Training time:7507.047768831253
batch reward last col mean 0.1718350052833557 first col mean 0.15366588532924652 all mean 0.16097570955753326
rl training, epoch1, iter0, batch116/1133, batch loss:0.22576379776000977, Training time:7536.512461900711
batch reward last col mean 0.21853405237197876 first col mean 0.2045852392911911 all mean 0.2162657529115677
rl training, epoch1, iter0, batch117/1133, batch loss:0.31652650237083435, Training time:7565.651974201202
batch reward last col mean 0.18743646144866943 first col mean 0.236815944314003 all mean 0.19379647076129913
rl training, epoch1, iter0, batch118/1133, batch loss:0.38448140025138855, Training time:7594.232556581497
batch reward last col mean 0.262090265750885 first col mean 0.2695254981517792 all mean 0.26208946108818054
rl training, epoch1, iter0, batch119/1133, batch loss:0.4885718524456024, Training time:7622.365189790726
batch reward last col mean 0.26460063457489014 first col mean 0.2556019425392151 all mean 0.2617761790752411
rl training, epoch1, iter0, batch120/1133, batch loss:0.505338728427887, Training time:7650.36674618721
batch reward last col mean 0.32739296555519104 first col mean 0.3127729892730713 all mean 0.3225994110107422
rl training, epoch1, iter0, batch121/1133, batch loss:0.6685293316841125, Training time:7678.1658411026
batch reward last col mean 0.3214258551597595 first col mean 0.3239440619945526 all mean 0.32323840260505676
rl training, epoch1, iter0, batch122/1133, batch loss:0.7246771454811096, Training time:7705.7819628715515
batch reward last col mean 0.36501166224479675 first col mean 0.34035858511924744 all mean 0.36140456795692444
rl training, epoch1, iter0, batch123/1133, batch loss:0.7890479564666748, Training time:7733.163112163544
batch reward last col mean 0.38154706358909607 first col mean 0.35238730907440186 all mean 0.3800356388092041
rl training, epoch1, iter0, batch124/1133, batch loss:0.8760972023010254, Training time:7760.726699590683
batch reward last col mean 0.39730778336524963 first col mean 0.4096713662147522 all mean 0.3975176513195038
rl training, epoch1, iter0, batch125/1133, batch loss:0.9280256628990173, Training time:7788.165310144424
batch reward last col mean 0.4149662256240845 first col mean 0.36739209294319153 all mean 0.41341519355773926
rl training, epoch1, iter0, batch126/1133, batch loss:1.0057100057601929, Training time:7815.506007909775
batch reward last col mean 0.41535085439682007 first col mean 0.4229992628097534 all mean 0.4158577620983124
rl training, epoch1, iter0, batch127/1133, batch loss:0.967792809009552, Training time:7842.801322937012
batch reward last col mean 0.4816857576370239 first col mean 0.4645964503288269 all mean 0.48239660263061523
rl training, epoch1, iter0, batch128/1133, batch loss:1.1335922479629517, Training time:7869.908088684082
batch reward last col mean 0.4109635353088379 first col mean 0.4365914762020111 all mean 0.4119391441345215
rl training, epoch1, iter0, batch129/1133, batch loss:0.9554890990257263, Training time:7897.226222991943
batch reward last col mean 0.4020974636077881 first col mean 0.41405189037323 all mean 0.4021865725517273
rl training, epoch1, iter0, batch130/1133, batch loss:1.0107086896896362, Training time:7924.633918523788
batch reward last col mean 0.44869014620780945 first col mean 0.44469040632247925 all mean 0.4479174315929413
rl training, epoch1, iter0, batch131/1133, batch loss:1.0805176496505737, Training time:7952.054834365845
batch reward last col mean 0.49256807565689087 first col mean 0.5093821883201599 all mean 0.49291014671325684
rl training, epoch1, iter0, batch132/1133, batch loss:1.2103595733642578, Training time:7979.370556354523
batch reward last col mean 0.46917662024497986 first col mean 0.4792732894420624 all mean 0.4690772294998169
rl training, epoch1, iter0, batch133/1133, batch loss:1.1827874183654785, Training time:8006.409985780716
batch reward last col mean 0.48233190178871155 first col mean 0.4917633533477783 all mean 0.48267918825149536
rl training, epoch1, iter0, batch134/1133, batch loss:1.1879700422286987, Training time:8033.628067731857
batch reward last col mean 0.48458755016326904 first col mean 0.4836323857307434 all mean 0.48611781001091003
rl training, epoch1, iter0, batch135/1133, batch loss:1.342084527015686, Training time:8061.014724731445
batch reward last col mean 0.48122692108154297 first col mean 0.49576377868652344 all mean 0.48073047399520874
rl training, epoch1, iter0, batch136/1133, batch loss:1.2699781656265259, Training time:8088.554151535034
batch reward last col mean 0.474196195602417 first col mean 0.5036563277244568 all mean 0.47577762603759766
rl training, epoch1, iter0, batch137/1133, batch loss:1.28298819065094, Training time:8115.908108711243
batch reward last col mean 0.5133095979690552 first col mean 0.5251068472862244 all mean 0.511965274810791
rl training, epoch1, iter0, batch138/1133, batch loss:1.3553727865219116, Training time:8143.125495672226
batch reward last col mean 0.5382892489433289 first col mean 0.539053738117218 all mean 0.5357716083526611
rl training, epoch1, iter0, batch139/1133, batch loss:1.4050650596618652, Training time:8170.430322885513
batch reward last col mean 0.493481308221817 first col mean 0.504098653793335 all mean 0.49347832798957825
rl training, epoch1, iter0, batch140/1133, batch loss:1.3751190900802612, Training time:8197.859772205353
batch reward last col mean 0.5733275413513184 first col mean 0.5122681856155396 all mean 0.5687950849533081
rl training, epoch1, iter0, batch141/1133, batch loss:1.424596905708313, Training time:8225.355287790298
batch reward last col mean 0.5478057861328125 first col mean 0.5035498142242432 all mean 0.5449044704437256
rl training, epoch1, iter0, batch142/1133, batch loss:1.4007586240768433, Training time:8252.799570322037
batch reward last col mean 0.5014911890029907 first col mean 0.5487606525421143 all mean 0.5021162629127502
rl training, epoch1, iter0, batch143/1133, batch loss:1.3817722797393799, Training time:8280.135693073273
batch reward last col mean 0.5555417537689209 first col mean 0.5354086756706238 all mean 0.5547146797180176
rl training, epoch1, iter0, batch144/1133, batch loss:1.4314671754837036, Training time:8307.804059267044
batch reward last col mean 0.5675598978996277 first col mean 0.5329784750938416 all mean 0.5681498646736145
rl training, epoch1, iter0, batch145/1133, batch loss:1.6513948440551758, Training time:8335.452160358429
batch reward last col mean 0.5362697243690491 first col mean 0.525299072265625 all mean 0.5380480289459229
rl training, epoch1, iter0, batch146/1133, batch loss:1.4784384965896606, Training time:8362.938119888306
batch reward last col mean 0.5536766052246094 first col mean 0.545701801776886 all mean 0.5543245077133179
rl training, epoch1, iter0, batch147/1133, batch loss:1.5541999340057373, Training time:8390.476092338562
batch reward last col mean 0.5262492299079895 first col mean 0.5911598205566406 all mean 0.5317327380180359
rl training, epoch1, iter0, batch148/1133, batch loss:1.5665583610534668, Training time:8417.912000894547
batch reward last col mean 0.5579633116722107 first col mean 0.5303075313568115 all mean 0.5526503324508667
rl training, epoch1, iter0, batch149/1133, batch loss:1.5725339651107788, Training time:8445.306431531906
batch reward last col mean 0.5942198038101196 first col mean 0.5546997785568237 all mean 0.588826596736908
rl training, epoch1, iter0, batch150/1133, batch loss:1.6639147996902466, Training time:8472.79115152359
batch reward last col mean 0.5843042135238647 first col mean 0.5691710710525513 all mean 0.5827807784080505
rl training, epoch1, iter0, batch151/1133, batch loss:1.6086361408233643, Training time:8500.162622451782
batch reward last col mean 0.5797629952430725 first col mean 0.5816910266876221 all mean 0.5777879357337952
rl training, epoch1, iter0, batch152/1133, batch loss:1.592803955078125, Training time:8527.783789634705
batch reward last col mean 0.5897790789604187 first col mean 0.5971753597259521 all mean 0.5894284844398499
rl training, epoch1, iter0, batch153/1133, batch loss:1.6354594230651855, Training time:8555.21700668335
batch reward last col mean 0.5056489109992981 first col mean 0.563559889793396 all mean 0.5085851550102234
rl training, epoch1, iter0, batch154/1133, batch loss:1.5287675857543945, Training time:8582.477048397064
batch reward last col mean 0.5728332996368408 first col mean 0.560727596282959 all mean 0.5729285478591919
rl training, epoch1, iter0, batch155/1133, batch loss:1.5229980945587158, Training time:8609.984793424606
batch reward last col mean 0.6031956076622009 first col mean 0.6168335676193237 all mean 0.6043864488601685
rl training, epoch1, iter0, batch156/1133, batch loss:1.7099016904830933, Training time:8637.352791309357
batch reward last col mean 0.4964525103569031 first col mean 0.538659930229187 all mean 0.5002256631851196
rl training, epoch1, iter0, batch157/1133, batch loss:1.4421497583389282, Training time:8664.844157934189
batch reward last col mean 0.5499778985977173 first col mean 0.5640988349914551 all mean 0.5516111850738525
rl training, epoch1, iter0, batch158/1133, batch loss:1.4971851110458374, Training time:8692.23507976532
batch reward last col mean 0.5209518074989319 first col mean 0.5332686901092529 all mean 0.5227199792861938
rl training, epoch1, iter0, batch159/1133, batch loss:1.3875367641448975, Training time:8719.382420778275
batch reward last col mean 0.5087381601333618 first col mean 0.5481708645820618 all mean 0.5106116533279419
rl training, epoch1, iter0, batch160/1133, batch loss:1.4156384468078613, Training time:8746.78762102127
batch reward last col mean 0.5193169713020325 first col mean 0.5569392442703247 all mean 0.5210240483283997
rl training, epoch1, iter0, batch161/1133, batch loss:1.4306330680847168, Training time:8774.216752767563
batch reward last col mean 0.5514016151428223 first col mean 0.547976016998291 all mean 0.5517107248306274
rl training, epoch1, iter0, batch162/1133, batch loss:1.4353711605072021, Training time:8801.64370059967
batch reward last col mean 0.5632858872413635 first col mean 0.5513075590133667 all mean 0.5614821910858154
rl training, epoch1, iter0, batch163/1133, batch loss:1.4920275211334229, Training time:8829.009981155396
batch reward last col mean 0.5830246806144714 first col mean 0.5704759359359741 all mean 0.5807991623878479
rl training, epoch1, iter0, batch164/1133, batch loss:1.4627759456634521, Training time:8856.06151342392
batch reward last col mean 0.5639076232910156 first col mean 0.5944669246673584 all mean 0.568418025970459
rl training, epoch1, iter0, batch165/1133, batch loss:1.5508860349655151, Training time:8883.541761398315
batch reward last col mean 0.583335280418396 first col mean 0.5578270554542542 all mean 0.5804317593574524
rl training, epoch1, iter0, batch166/1133, batch loss:1.4750043153762817, Training time:8910.695004701614
batch reward last col mean 0.6015906929969788 first col mean 0.5655922293663025 all mean 0.597202479839325
rl training, epoch1, iter0, batch167/1133, batch loss:1.6288926601409912, Training time:8938.18508052826
batch reward last col mean 0.6337430477142334 first col mean 0.603349506855011 all mean 0.6293753981590271
rl training, epoch1, iter0, batch168/1133, batch loss:1.6314802169799805, Training time:8965.861986398697
batch reward last col mean 0.5445659756660461 first col mean 0.5477203130722046 all mean 0.5466516017913818
rl training, epoch1, iter0, batch169/1133, batch loss:1.4980486631393433, Training time:8993.121027708054
batch reward last col mean 0.6242243647575378 first col mean 0.5970526337623596 all mean 0.6221592426300049
rl training, epoch1, iter0, batch170/1133, batch loss:1.6783372163772583, Training time:9020.632416963577
batch reward last col mean 0.591439962387085 first col mean 0.5779231190681458 all mean 0.5890032649040222
rl training, epoch1, iter0, batch171/1133, batch loss:1.4977716207504272, Training time:9047.931758880615
batch reward last col mean 0.5543016195297241 first col mean 0.5741052627563477 all mean 0.5552976727485657
rl training, epoch1, iter0, batch172/1133, batch loss:1.5412198305130005, Training time:9075.369527339935
batch reward last col mean 0.5491729974746704 first col mean 0.5420306921005249 all mean 0.5498456954956055
rl training, epoch1, iter0, batch173/1133, batch loss:1.452521800994873, Training time:9102.950433969498
batch reward last col mean 0.5633711218833923 first col mean 0.5745070576667786 all mean 0.5625960826873779
rl training, epoch1, iter0, batch174/1133, batch loss:1.5137355327606201, Training time:9130.38910150528
batch reward last col mean 0.539461612701416 first col mean 0.5517594814300537 all mean 0.5420297980308533
rl training, epoch1, iter0, batch175/1133, batch loss:1.4196799993515015, Training time:9157.984868764877
batch reward last col mean 0.5398553013801575 first col mean 0.5657315254211426 all mean 0.541496992111206
rl training, epoch1, iter0, batch176/1133, batch loss:1.4460055828094482, Training time:9185.520964622498
batch reward last col mean 0.5784494876861572 first col mean 0.5866198539733887 all mean 0.5774703025817871
rl training, epoch1, iter0, batch177/1133, batch loss:1.6755460500717163, Training time:9213.0172560215
batch reward last col mean 0.5584409832954407 first col mean 0.531493067741394 all mean 0.5528677105903625
rl training, epoch1, iter0, batch178/1133, batch loss:1.4923080205917358, Training time:9241.018217802048
batch reward last col mean 0.5764638185501099 first col mean 0.5662720203399658 all mean 0.5765406489372253
rl training, epoch1, iter0, batch179/1133, batch loss:1.5569907426834106, Training time:9268.608802556992
batch reward last col mean 0.5662537217140198 first col mean 0.5402424335479736 all mean 0.5644807815551758
rl training, epoch1, iter0, batch180/1133, batch loss:1.6089144945144653, Training time:9296.615850925446
batch reward last col mean 0.6064035892486572 first col mean 0.5982795357704163 all mean 0.6056340336799622
rl training, epoch1, iter0, batch181/1133, batch loss:1.5815386772155762, Training time:9324.68264746666
batch reward last col mean 0.5178581476211548 first col mean 0.5156397223472595 all mean 0.5163987874984741
rl training, epoch1, iter0, batch182/1133, batch loss:1.4935150146484375, Training time:9352.53326702118
batch reward last col mean 0.4860062599182129 first col mean 0.5053951144218445 all mean 0.4926318824291229
rl training, epoch1, iter0, batch183/1133, batch loss:1.3527400493621826, Training time:9380.989598035812
batch reward last col mean 0.5559210777282715 first col mean 0.5245740413665771 all mean 0.5533608198165894
rl training, epoch1, iter0, batch184/1133, batch loss:1.5213892459869385, Training time:9409.053597450256
batch reward last col mean 0.5793650150299072 first col mean 0.5543245077133179 all mean 0.5716522932052612
rl training, epoch1, iter0, batch185/1133, batch loss:1.5729179382324219, Training time:9437.308615922928
batch reward last col mean 0.4882063567638397 first col mean 0.49643492698669434 all mean 0.4944423735141754
rl training, epoch1, iter0, batch186/1133, batch loss:1.289897084236145, Training time:9465.363812446594
batch reward last col mean 0.5424631237983704 first col mean 0.5634922385215759 all mean 0.5484949946403503
rl training, epoch1, iter0, batch187/1133, batch loss:1.568029522895813, Training time:9493.36583852768
batch reward last col mean 0.5449585914611816 first col mean 0.5291474461555481 all mean 0.5402476191520691
rl training, epoch1, iter0, batch188/1133, batch loss:1.4931297302246094, Training time:9521.272232055664
batch reward last col mean 0.5514916777610779 first col mean 0.5430289506912231 all mean 0.556540310382843
rl training, epoch1, iter0, batch189/1133, batch loss:1.5088109970092773, Training time:9549.041922807693
batch reward last col mean 0.5431828498840332 first col mean 0.5452848672866821 all mean 0.5401738286018372
rl training, epoch1, iter0, batch190/1133, batch loss:1.4186815023422241, Training time:9576.89806342125
batch reward last col mean 0.5965816974639893 first col mean 0.5844893455505371 all mean 0.5945936441421509
rl training, epoch1, iter0, batch191/1133, batch loss:1.5612832307815552, Training time:9604.717708587646
batch reward last col mean 0.545019805431366 first col mean 0.5663149952888489 all mean 0.5487440228462219
rl training, epoch1, iter0, batch192/1133, batch loss:1.558061957359314, Training time:9632.293473482132
batch reward last col mean 0.5410109162330627 first col mean 0.5274312496185303 all mean 0.5388581156730652
rl training, epoch1, iter0, batch193/1133, batch loss:1.392066240310669, Training time:9659.93724822998
batch reward last col mean 0.5494883060455322 first col mean 0.5184684991836548 all mean 0.5474968552589417
rl training, epoch1, iter0, batch194/1133, batch loss:1.3708003759384155, Training time:9687.738589286804
batch reward last col mean 0.5746656060218811 first col mean 0.5615865588188171 all mean 0.5709384679794312
rl training, epoch1, iter0, batch195/1133, batch loss:1.4837298393249512, Training time:9715.462569236755
batch reward last col mean 0.6471558809280396 first col mean 0.5713809132575989 all mean 0.6418225765228271
rl training, epoch1, iter0, batch196/1133, batch loss:1.4207152128219604, Training time:9742.867303609848
batch reward last col mean 0.5211818218231201 first col mean 0.5073251724243164 all mean 0.5204193592071533
rl training, epoch1, iter0, batch197/1133, batch loss:1.3049086332321167, Training time:9770.299217700958
batch reward last col mean 0.49527353048324585 first col mean 0.5149549841880798 all mean 0.4976266324520111
rl training, epoch1, iter0, batch198/1133, batch loss:1.2453151941299438, Training time:9797.549253702164
batch reward last col mean 0.5541040897369385 first col mean 0.5548117756843567 all mean 0.5553702712059021
rl training, epoch1, iter0, batch199/1133, batch loss:1.4062788486480713, Training time:9824.818395853043
batch reward last col mean 0.5355745553970337 first col mean 0.5241808295249939 all mean 0.5345427989959717
rl training, epoch1, iter0, batch200/1133, batch loss:1.262150526046753, Training time:9852.073621034622
batch reward last col mean 0.5634279251098633 first col mean 0.5269734263420105 all mean 0.5607785582542419
rl training, epoch1, iter0, batch201/1133, batch loss:1.5053176879882812, Training time:9879.221460342407
batch reward last col mean 0.5854902863502502 first col mean 0.5968610644340515 all mean 0.5853017568588257
rl training, epoch1, iter0, batch202/1133, batch loss:1.5909020900726318, Training time:9906.652963638306
batch reward last col mean 0.5380861759185791 first col mean 0.5468839406967163 all mean 0.5384989976882935
rl training, epoch1, iter0, batch203/1133, batch loss:1.4659886360168457, Training time:9933.728383541107
batch reward last col mean 0.5454918742179871 first col mean 0.5985792279243469 all mean 0.5492903590202332
rl training, epoch1, iter0, batch204/1133, batch loss:1.4229108095169067, Training time:9960.987943172455
batch reward last col mean 0.5787780284881592 first col mean 0.5874959230422974 all mean 0.5776340365409851
rl training, epoch1, iter0, batch205/1133, batch loss:1.5565435886383057, Training time:9988.293534994125
batch reward last col mean 0.5529119372367859 first col mean 0.570231020450592 all mean 0.5557231903076172
rl training, epoch1, iter0, batch206/1133, batch loss:1.500431776046753, Training time:10015.679188966751
batch reward last col mean 0.5621334314346313 first col mean 0.5623480081558228 all mean 0.5637160539627075
rl training, epoch1, iter0, batch207/1133, batch loss:1.603874683380127, Training time:10043.154798030853
batch reward last col mean 0.5546042919158936 first col mean 0.5823936462402344 all mean 0.5559271574020386
rl training, epoch1, iter0, batch208/1133, batch loss:1.564092755317688, Training time:10070.453396081924
batch reward last col mean 0.5303998589515686 first col mean 0.5105454921722412 all mean 0.5292569398880005
rl training, epoch1, iter0, batch209/1133, batch loss:1.5359406471252441, Training time:10097.594987154007
batch reward last col mean 0.553986132144928 first col mean 0.5301547050476074 all mean 0.5520709156990051
rl training, epoch1, iter0, batch210/1133, batch loss:1.5331439971923828, Training time:10125.230766773224
batch reward last col mean 0.5339258313179016 first col mean 0.5701205134391785 all mean 0.5369852781295776
rl training, epoch1, iter0, batch211/1133, batch loss:1.5458545684814453, Training time:10152.513764381409
batch reward last col mean 0.5558450222015381 first col mean 0.5370528697967529 all mean 0.5566611289978027
rl training, epoch1, iter0, batch212/1133, batch loss:1.5318952798843384, Training time:10180.286695957184
batch reward last col mean 0.537456750869751 first col mean 0.5595695972442627 all mean 0.5399897694587708
rl training, epoch1, iter0, batch213/1133, batch loss:1.5578149557113647, Training time:10207.766803503036
batch reward last col mean 0.574691653251648 first col mean 0.5627083778381348 all mean 0.5721345543861389
rl training, epoch1, iter0, batch214/1133, batch loss:1.6266535520553589, Training time:10235.567479133606
batch reward last col mean 0.5178636312484741 first col mean 0.5253951549530029 all mean 0.5172282457351685
rl training, epoch1, iter0, batch215/1133, batch loss:1.4619570970535278, Training time:10263.717584371567
batch reward last col mean 0.5899044275283813 first col mean 0.5599636435508728 all mean 0.5853722095489502
rl training, epoch1, iter0, batch216/1133, batch loss:1.5415019989013672, Training time:10291.92132115364
batch reward last col mean 0.5300052762031555 first col mean 0.5151821970939636 all mean 0.5307449698448181
rl training, epoch1, iter0, batch217/1133, batch loss:1.4646011590957642, Training time:10320.703632354736
batch reward last col mean 0.5365304350852966 first col mean 0.5618113875389099 all mean 0.5368652939796448
rl training, epoch1, iter0, batch218/1133, batch loss:1.4479138851165771, Training time:10349.543061256409
batch reward last col mean 0.5531850457191467 first col mean 0.5274583697319031 all mean 0.5503076314926147
rl training, epoch1, iter0, batch219/1133, batch loss:1.420559048652649, Training time:10378.442931890488
batch reward last col mean 0.5864477157592773 first col mean 0.5612457394599915 all mean 0.5830128788948059
rl training, epoch1, iter0, batch220/1133, batch loss:1.4769612550735474, Training time:10407.395007610321
batch reward last col mean 0.5875346064567566 first col mean 0.5959097146987915 all mean 0.5920363664627075
rl training, epoch1, iter0, batch221/1133, batch loss:1.5964717864990234, Training time:10436.503705263138
batch reward last col mean 0.5627449750900269 first col mean 0.5088255405426025 all mean 0.5391866564750671
rl training, epoch1, iter0, batch222/1133, batch loss:1.2768586874008179, Training time:10465.371181249619
batch reward last col mean 0.579526960849762 first col mean 0.5456105470657349 all mean 0.5580691695213318
rl training, epoch1, iter0, batch223/1133, batch loss:1.3677005767822266, Training time:10494.179418563843
batch reward last col mean 0.5114676356315613 first col mean 0.5155203938484192 all mean 0.5149784088134766
rl training, epoch1, iter0, batch224/1133, batch loss:1.2269388437271118, Training time:10523.254615783691
batch reward last col mean 0.5559225082397461 first col mean 0.5551919937133789 all mean 0.5572521090507507
rl training, epoch1, iter0, batch225/1133, batch loss:1.445881962776184, Training time:10552.206917762756
batch reward last col mean 0.5413655638694763 first col mean 0.5383655428886414 all mean 0.5395667552947998
rl training, epoch1, iter0, batch226/1133, batch loss:1.2905313968658447, Training time:10581.139716625214
batch reward last col mean 0.5476279258728027 first col mean 0.5359904170036316 all mean 0.5508573055267334
rl training, epoch1, iter0, batch227/1133, batch loss:1.335452914237976, Training time:10610.23684668541
batch reward last col mean 0.5248057842254639 first col mean 0.5454003810882568 all mean 0.5209341049194336
rl training, epoch1, iter0, batch228/1133, batch loss:1.333625078201294, Training time:10639.207910299301
batch reward last col mean 0.533822238445282 first col mean 0.5812982320785522 all mean 0.5418939590454102
rl training, epoch1, iter0, batch229/1133, batch loss:1.468299388885498, Training time:10668.459873199463
batch reward last col mean 0.5559481382369995 first col mean 0.554986298084259 all mean 0.5570068955421448
rl training, epoch1, iter0, batch230/1133, batch loss:1.4605340957641602, Training time:10697.484722614288
batch reward last col mean 0.6107199192047119 first col mean 0.567374587059021 all mean 0.5953487157821655
rl training, epoch1, iter0, batch231/1133, batch loss:1.451115608215332, Training time:10726.493023395538
batch reward last col mean 0.51631760597229 first col mean 0.5635521411895752 all mean 0.5276392698287964
rl training, epoch1, iter0, batch232/1133, batch loss:1.4417964220046997, Training time:10755.489469766617
batch reward last col mean 0.5326433181762695 first col mean 0.5508008599281311 all mean 0.5319963097572327
rl training, epoch1, iter0, batch233/1133, batch loss:1.4248013496398926, Training time:10784.62115764618
batch reward last col mean 0.49195289611816406 first col mean 0.5351701974868774 all mean 0.4999973475933075
rl training, epoch1, iter0, batch234/1133, batch loss:1.2423557043075562, Training time:10813.632677793503
batch reward last col mean 0.5673112869262695 first col mean 0.5157233476638794 all mean 0.5505553483963013
rl training, epoch1, iter0, batch235/1133, batch loss:1.4066119194030762, Training time:10842.483376264572
batch reward last col mean 0.5272361040115356 first col mean 0.5132290124893188 all mean 0.5179687142372131
rl training, epoch1, iter0, batch236/1133, batch loss:1.3282337188720703, Training time:10871.419743299484
batch reward last col mean 0.5334916114807129 first col mean 0.5212961435317993 all mean 0.5329539775848389
rl training, epoch1, iter0, batch237/1133, batch loss:1.3676364421844482, Training time:10900.56394314766
batch reward last col mean 0.4820517897605896 first col mean 0.48367077112197876 all mean 0.4746619760990143
rl training, epoch1, iter0, batch238/1133, batch loss:1.1990834474563599, Training time:10929.190227031708
batch reward last col mean 0.5016809105873108 first col mean 0.4954107403755188 all mean 0.5019069910049438
rl training, epoch1, iter0, batch239/1133, batch loss:1.2906568050384521, Training time:10957.997638940811
batch reward last col mean 0.48223185539245605 first col mean 0.4840947985649109 all mean 0.4855182468891144
rl training, epoch1, iter0, batch240/1133, batch loss:1.1960828304290771, Training time:10986.51733994484
batch reward last col mean 0.4488120675086975 first col mean 0.47462260723114014 all mean 0.449375182390213
rl training, epoch1, iter0, batch241/1133, batch loss:1.1524134874343872, Training time:11015.363336801529
batch reward last col mean 0.5332501530647278 first col mean 0.5527346134185791 all mean 0.533032238483429
rl training, epoch1, iter0, batch242/1133, batch loss:1.5410740375518799, Training time:11043.85723400116
batch reward last col mean 0.4908224940299988 first col mean 0.49488523602485657 all mean 0.4873635768890381
rl training, epoch1, iter0, batch243/1133, batch loss:1.312928557395935, Training time:11072.277002334595
batch reward last col mean 0.5117965936660767 first col mean 0.4924895763397217 all mean 0.5099503993988037
rl training, epoch1, iter0, batch244/1133, batch loss:1.3947656154632568, Training time:11100.732280731201
batch reward last col mean 0.5463144779205322 first col mean 0.5434933304786682 all mean 0.5428329110145569
rl training, epoch1, iter0, batch245/1133, batch loss:1.5285539627075195, Training time:11129.022990703583
batch reward last col mean 0.5682850480079651 first col mean 0.5585761666297913 all mean 0.5690356492996216
rl training, epoch1, iter0, batch246/1133, batch loss:1.6042362451553345, Training time:11157.313373088837
batch reward last col mean 0.5778840184211731 first col mean 0.5859452486038208 all mean 0.5781747102737427
rl training, epoch1, iter0, batch247/1133, batch loss:1.582157015800476, Training time:11185.22511601448
batch reward last col mean 0.5407204627990723 first col mean 0.5612157583236694 all mean 0.5501284599304199
rl training, epoch1, iter0, batch248/1133, batch loss:1.580094575881958, Training time:11213.50076341629
batch reward last col mean 0.5524113774299622 first col mean 0.5856420993804932 all mean 0.5565574169158936
rl training, epoch1, iter0, batch249/1133, batch loss:1.5299538373947144, Training time:11241.67692399025
batch reward last col mean 0.6463077664375305 first col mean 0.5966554284095764 all mean 0.6454103589057922
rl training, epoch1, iter0, batch250/1133, batch loss:1.6597535610198975, Training time:11269.567996501923
batch reward last col mean 0.5561665892601013 first col mean 0.55584716796875 all mean 0.5552249550819397
rl training, epoch1, iter0, batch251/1133, batch loss:1.4460580348968506, Training time:11297.619781017303
batch reward last col mean 0.5865770578384399 first col mean 0.5908609628677368 all mean 0.586650013923645
rl training, epoch1, iter0, batch252/1133, batch loss:1.6026787757873535, Training time:11325.289193630219
batch reward last col mean 0.5724648237228394 first col mean 0.593396782875061 all mean 0.573214590549469
rl training, epoch1, iter0, batch253/1133, batch loss:1.564977765083313, Training time:11352.79324388504
batch reward last col mean 0.6020037531852722 first col mean 0.6187329292297363 all mean 0.5989540815353394
rl training, epoch1, iter0, batch254/1133, batch loss:1.6045506000518799, Training time:11380.49318099022
batch reward last col mean 0.5399585962295532 first col mean 0.5934427976608276 all mean 0.5422457456588745
rl training, epoch1, iter0, batch255/1133, batch loss:1.482603907585144, Training time:11408.20925283432
batch reward last col mean 0.5760385394096375 first col mean 0.61021488904953 all mean 0.5800896883010864
rl training, epoch1, iter0, batch256/1133, batch loss:1.629554033279419, Training time:11435.881410360336
batch reward last col mean 0.6084880828857422 first col mean 0.5875377655029297 all mean 0.6070891618728638
rl training, epoch1, iter0, batch257/1133, batch loss:1.6313047409057617, Training time:11463.862972259521
batch reward last col mean 0.5941622853279114 first col mean 0.6148626804351807 all mean 0.594083309173584
rl training, epoch1, iter0, batch258/1133, batch loss:1.5609925985336304, Training time:11491.643851041794
batch reward last col mean 0.6288628578186035 first col mean 0.6061107516288757 all mean 0.6266319751739502
rl training, epoch1, iter0, batch259/1133, batch loss:1.6918916702270508, Training time:11519.357283115387
batch reward last col mean 0.6491212844848633 first col mean 0.631706953048706 all mean 0.6493809223175049
rl training, epoch1, iter0, batch260/1133, batch loss:1.6787077188491821, Training time:11547.158503055573
batch reward last col mean 0.6521773338317871 first col mean 0.6265584826469421 all mean 0.6514171957969666
rl training, epoch1, iter0, batch261/1133, batch loss:1.6891710758209229, Training time:11574.867754936218
batch reward last col mean 0.5500531196594238 first col mean 0.5994693040847778 all mean 0.5546364784240723
rl training, epoch1, iter0, batch262/1133, batch loss:1.444674015045166, Training time:11602.559268712997
batch reward last col mean 0.6229921579360962 first col mean 0.6131974458694458 all mean 0.6213530898094177
rl training, epoch1, iter0, batch263/1133, batch loss:1.5710759162902832, Training time:11630.410863399506
batch reward last col mean 0.6237204074859619 first col mean 0.5909442901611328 all mean 0.6211447715759277
rl training, epoch1, iter0, batch264/1133, batch loss:1.6160337924957275, Training time:11658.27985239029
batch reward last col mean 0.5818263292312622 first col mean 0.579103946685791 all mean 0.5818548202514648
rl training, epoch1, iter0, batch265/1133, batch loss:1.4913150072097778, Training time:11686.080615282059
batch reward last col mean 0.6017804145812988 first col mean 0.6020075678825378 all mean 0.6035600900650024
rl training, epoch1, iter0, batch266/1133, batch loss:1.686835765838623, Training time:11713.986824512482
batch reward last col mean 0.6291150450706482 first col mean 0.650567889213562 all mean 0.6293092370033264
rl training, epoch1, iter0, batch267/1133, batch loss:1.6654398441314697, Training time:11741.704126119614
batch reward last col mean 0.5923793911933899 first col mean 0.5933059453964233 all mean 0.5925543904304504
rl training, epoch1, iter0, batch268/1133, batch loss:1.5649223327636719, Training time:11769.61987566948
batch reward last col mean 0.557516872882843 first col mean 0.6096115112304688 all mean 0.5641902685165405
rl training, epoch1, iter0, batch269/1133, batch loss:1.48423171043396, Training time:11797.431344985962
batch reward last col mean 0.5905026197433472 first col mean 0.6140930652618408 all mean 0.5920229554176331
rl training, epoch1, iter0, batch270/1133, batch loss:1.5351431369781494, Training time:11825.232232093811
batch reward last col mean 0.63765949010849 first col mean 0.6599175333976746 all mean 0.6428949236869812
rl training, epoch1, iter0, batch271/1133, batch loss:1.657059907913208, Training time:11853.266657590866
batch reward last col mean 0.646043598651886 first col mean 0.631555438041687 all mean 0.6470416188240051
rl training, epoch1, iter0, batch272/1133, batch loss:1.6185646057128906, Training time:11881.106934309006
batch reward last col mean 0.6426266431808472 first col mean 0.6292189359664917 all mean 0.6389855742454529
rl training, epoch1, iter0, batch273/1133, batch loss:1.638566017150879, Training time:11908.88957977295
batch reward last col mean 0.6425231695175171 first col mean 0.6192169189453125 all mean 0.6421512365341187
rl training, epoch1, iter0, batch274/1133, batch loss:1.6432024240493774, Training time:11936.80578660965
batch reward last col mean 0.6382083892822266 first col mean 0.6431635618209839 all mean 0.6357864737510681
rl training, epoch1, iter0, batch275/1133, batch loss:1.558424472808838, Training time:11964.284121990204
batch reward last col mean 0.6276037096977234 first col mean 0.6346844434738159 all mean 0.6282330751419067
rl training, epoch1, iter0, batch276/1133, batch loss:1.5852024555206299, Training time:11991.847751617432
batch reward last col mean 0.6044374108314514 first col mean 0.6161357164382935 all mean 0.6053339838981628
rl training, epoch1, iter0, batch277/1133, batch loss:1.4818141460418701, Training time:12019.641701936722
batch reward last col mean 0.6095899343490601 first col mean 0.6016738414764404 all mean 0.6082253456115723
rl training, epoch1, iter0, batch278/1133, batch loss:1.5102102756500244, Training time:12047.380577802658
batch reward last col mean 0.638407289981842 first col mean 0.6230353116989136 all mean 0.6420029997825623
rl training, epoch1, iter0, batch279/1133, batch loss:1.6258407831192017, Training time:12075.30555486679
batch reward last col mean 0.6294703483581543 first col mean 0.624783992767334 all mean 0.6322593092918396
rl training, epoch1, iter0, batch280/1133, batch loss:1.556852102279663, Training time:12103.267646551132
batch reward last col mean 0.6199157238006592 first col mean 0.6136200428009033 all mean 0.6173397898674011
rl training, epoch1, iter0, batch281/1133, batch loss:1.5242871046066284, Training time:12130.732340335846
batch reward last col mean 0.6004842519760132 first col mean 0.6300975680351257 all mean 0.6028909683227539
rl training, epoch1, iter0, batch282/1133, batch loss:1.570295810699463, Training time:12158.807468175888
batch reward last col mean 0.6108850240707397 first col mean 0.6254504323005676 all mean 0.6145856976509094
rl training, epoch1, iter0, batch283/1133, batch loss:1.4666757583618164, Training time:12186.66366648674
batch reward last col mean 0.6224349737167358 first col mean 0.6385892629623413 all mean 0.6212364435195923
rl training, epoch1, iter0, batch284/1133, batch loss:1.544463038444519, Training time:12214.351841449738
batch reward last col mean 0.6027953028678894 first col mean 0.6007731556892395 all mean 0.6023906469345093
rl training, epoch1, iter0, batch285/1133, batch loss:1.5311223268508911, Training time:12242.566445350647
batch reward last col mean 0.5814311504364014 first col mean 0.6026965975761414 all mean 0.5826610922813416
rl training, epoch1, iter0, batch286/1133, batch loss:1.5360256433486938, Training time:12270.310152053833
batch reward last col mean 0.6337991952896118 first col mean 0.6245309114456177 all mean 0.6338310837745667
rl training, epoch1, iter0, batch287/1133, batch loss:1.6448355913162231, Training time:12298.053574562073
batch reward last col mean 0.5957313776016235 first col mean 0.6429641842842102 all mean 0.6011542677879333
rl training, epoch1, iter0, batch288/1133, batch loss:1.4661686420440674, Training time:12325.835216999054
batch reward last col mean 0.6129463315010071 first col mean 0.6234713792800903 all mean 0.6100786924362183
rl training, epoch1, iter0, batch289/1133, batch loss:1.555977702140808, Training time:12353.58929181099
batch reward last col mean 0.6414749026298523 first col mean 0.6198164224624634 all mean 0.6354223489761353
rl training, epoch1, iter0, batch290/1133, batch loss:1.5764859914779663, Training time:12381.82657289505
batch reward last col mean 0.642149806022644 first col mean 0.6480231285095215 all mean 0.6393377184867859
rl training, epoch1, iter0, batch291/1133, batch loss:1.448628306388855, Training time:12409.535651445389
batch reward last col mean 0.6780053377151489 first col mean 0.6487607359886169 all mean 0.6737833023071289
rl training, epoch1, iter0, batch292/1133, batch loss:1.604225993156433, Training time:12437.359821557999
batch reward last col mean 0.6350078582763672 first col mean 0.6353517174720764 all mean 0.6318601369857788
rl training, epoch1, iter0, batch293/1133, batch loss:1.5039952993392944, Training time:12465.07927274704
batch reward last col mean 0.6292405128479004 first col mean 0.6630220413208008 all mean 0.6304602026939392
rl training, epoch1, iter0, batch294/1133, batch loss:1.6142594814300537, Training time:12492.785646677017
batch reward last col mean 0.6996486186981201 first col mean 0.6674292683601379 all mean 0.6976396441459656
rl training, epoch1, iter0, batch295/1133, batch loss:1.63525390625, Training time:12520.800918340683
batch reward last col mean 0.6118234395980835 first col mean 0.6435830593109131 all mean 0.6162246465682983
rl training, epoch1, iter0, batch296/1133, batch loss:1.573211431503296, Training time:12548.948533535004
batch reward last col mean 0.6636339426040649 first col mean 0.6464110016822815 all mean 0.6614760756492615
rl training, epoch1, iter0, batch297/1133, batch loss:1.5527684688568115, Training time:12577.042289495468
batch reward last col mean 0.6389040350914001 first col mean 0.6148546934127808 all mean 0.6359927654266357
rl training, epoch1, iter0, batch298/1133, batch loss:1.5565671920776367, Training time:12604.940682649612
batch reward last col mean 0.6434289216995239 first col mean 0.6227240562438965 all mean 0.6434354782104492
rl training, epoch1, iter0, batch299/1133, batch loss:1.5088584423065186, Training time:12633.02690243721
batch reward last col mean 0.6412502527236938 first col mean 0.6271970868110657 all mean 0.6424514651298523
rl training, epoch1, iter0, batch300/1133, batch loss:1.4984971284866333, Training time:12661.227811574936
batch reward last col mean 0.646376371383667 first col mean 0.6129454374313354 all mean 0.6413124203681946
rl training, epoch1, iter0, batch301/1133, batch loss:1.5481765270233154, Training time:12689.614601135254
batch reward last col mean 0.6240953803062439 first col mean 0.6625796556472778 all mean 0.6263870000839233
rl training, epoch1, iter0, batch302/1133, batch loss:1.5718120336532593, Training time:12718.07594203949
batch reward last col mean 0.6035528779029846 first col mean 0.6246996521949768 all mean 0.6120017766952515
rl training, epoch1, iter0, batch303/1133, batch loss:1.501193642616272, Training time:12746.569149017334
batch reward last col mean 0.5675520896911621 first col mean 0.6431589126586914 all mean 0.5722670555114746
rl training, epoch1, iter0, batch304/1133, batch loss:1.3376753330230713, Training time:12774.817895412445
batch reward last col mean 0.5873939394950867 first col mean 0.5923376083374023 all mean 0.5827345252037048
rl training, epoch1, iter0, batch305/1133, batch loss:1.3139694929122925, Training time:12803.44249677658
batch reward last col mean 0.5962531566619873 first col mean 0.5802465677261353 all mean 0.5961976647377014
rl training, epoch1, iter0, batch306/1133, batch loss:1.2036523818969727, Training time:12831.913041353226
batch reward last col mean 0.5815920829772949 first col mean 0.5740236043930054 all mean 0.5796313285827637
rl training, epoch1, iter0, batch307/1133, batch loss:1.124643087387085, Training time:12860.346916437149
batch reward last col mean 0.5442543625831604 first col mean 0.5551891326904297 all mean 0.5441610813140869
rl training, epoch1, iter0, batch308/1133, batch loss:1.1601964235305786, Training time:12888.738085746765
batch reward last col mean 0.5884801745414734 first col mean 0.5935930013656616 all mean 0.5824729800224304
rl training, epoch1, iter0, batch309/1133, batch loss:1.294249415397644, Training time:12917.134114980698
batch reward last col mean 0.5635762214660645 first col mean 0.5943711400032043 all mean 0.570099949836731
rl training, epoch1, iter0, batch310/1133, batch loss:1.314786434173584, Training time:12945.511246919632
batch reward last col mean 0.6367683410644531 first col mean 0.6118927001953125 all mean 0.631227970123291
rl training, epoch1, iter0, batch311/1133, batch loss:1.3302003145217896, Training time:12973.834576129913
batch reward last col mean 0.5952522158622742 first col mean 0.5855886340141296 all mean 0.5898728966712952
rl training, epoch1, iter0, batch312/1133, batch loss:1.3728325366973877, Training time:13002.562226295471
batch reward last col mean 0.5860958099365234 first col mean 0.6150822639465332 all mean 0.5854971408843994
rl training, epoch1, iter0, batch313/1133, batch loss:1.4488332271575928, Training time:13031.070034980774
batch reward last col mean 0.6340572834014893 first col mean 0.6038572788238525 all mean 0.6297215819358826
rl training, epoch1, iter0, batch314/1133, batch loss:1.5675586462020874, Training time:13059.3855240345
batch reward last col mean 0.625114381313324 first col mean 0.6463444232940674 all mean 0.6282506585121155
rl training, epoch1, iter0, batch315/1133, batch loss:1.686003565788269, Training time:13087.823172092438
batch reward last col mean 0.6115134358406067 first col mean 0.6254724860191345 all mean 0.606666088104248
rl training, epoch1, iter0, batch316/1133, batch loss:1.6082570552825928, Training time:13116.35007095337
batch reward last col mean 0.5944526195526123 first col mean 0.609116792678833 all mean 0.5909731388092041
rl training, epoch1, iter0, batch317/1133, batch loss:1.4887410402297974, Training time:13145.04370355606
batch reward last col mean 0.6477550268173218 first col mean 0.6669521331787109 all mean 0.6513561606407166
rl training, epoch1, iter0, batch318/1133, batch loss:1.6901636123657227, Training time:13173.007712841034
batch reward last col mean 0.665736973285675 first col mean 0.6454834938049316 all mean 0.663885235786438
rl training, epoch1, iter0, batch319/1133, batch loss:1.5986251831054688, Training time:13201.05725812912
batch reward last col mean 0.6442399621009827 first col mean 0.639620840549469 all mean 0.6453889012336731
rl training, epoch1, iter0, batch320/1133, batch loss:1.6197232007980347, Training time:13228.967215776443
batch reward last col mean 0.6430128216743469 first col mean 0.6302141547203064 all mean 0.6416682004928589
rl training, epoch1, iter0, batch321/1133, batch loss:1.764670968055725, Training time:13256.547920703888
batch reward last col mean 0.6783809661865234 first col mean 0.659231960773468 all mean 0.6759064197540283
rl training, epoch1, iter0, batch322/1133, batch loss:1.6906331777572632, Training time:13284.5571475029
batch reward last col mean 0.6339865326881409 first col mean 0.63086998462677 all mean 0.6353437900543213
rl training, epoch1, iter0, batch323/1133, batch loss:1.5750709772109985, Training time:13312.1425511837
batch reward last col mean 0.6412501335144043 first col mean 0.6168242692947388 all mean 0.643130898475647
rl training, epoch1, iter0, batch324/1133, batch loss:1.7621281147003174, Training time:13339.753422498703
batch reward last col mean 0.6237473487854004 first col mean 0.6437549591064453 all mean 0.6244800686836243
rl training, epoch1, iter0, batch325/1133, batch loss:1.5673034191131592, Training time:13367.394421339035
batch reward last col mean 0.6513352990150452 first col mean 0.6230122447013855 all mean 0.6507429480552673
rl training, epoch1, iter0, batch326/1133, batch loss:1.5197062492370605, Training time:13394.688351869583
batch reward last col mean 0.6445056200027466 first col mean 0.6478700637817383 all mean 0.6476916670799255
rl training, epoch1, iter0, batch327/1133, batch loss:1.619293212890625, Training time:13422.217354774475
batch reward last col mean 0.6270334720611572 first col mean 0.6030293703079224 all mean 0.6255272626876831
rl training, epoch1, iter0, batch328/1133, batch loss:1.6112375259399414, Training time:13449.537747383118
batch reward last col mean 0.6364904046058655 first col mean 0.6513739824295044 all mean 0.6364471912384033
rl training, epoch1, iter0, batch329/1133, batch loss:1.6011362075805664, Training time:13476.91405582428
batch reward last col mean 0.633261501789093 first col mean 0.6277974843978882 all mean 0.6335467100143433
rl training, epoch1, iter0, batch330/1133, batch loss:1.5156091451644897, Training time:13504.496690750122
batch reward last col mean 0.5966061353683472 first col mean 0.602445662021637 all mean 0.594992458820343
rl training, epoch1, iter0, batch331/1133, batch loss:1.3513175249099731, Training time:13532.340349197388
batch reward last col mean 0.6232418417930603 first col mean 0.5988713502883911 all mean 0.6230007410049438
rl training, epoch1, iter0, batch332/1133, batch loss:1.4239593744277954, Training time:13559.882397413254
batch reward last col mean 0.6254838109016418 first col mean 0.6141723990440369 all mean 0.6259436011314392
rl training, epoch1, iter0, batch333/1133, batch loss:1.4206418991088867, Training time:13587.435588598251
batch reward last col mean 0.6742002964019775 first col mean 0.6447895169258118 all mean 0.6722052693367004
rl training, epoch1, iter0, batch334/1133, batch loss:1.558648705482483, Training time:13615.023191690445
batch reward last col mean 0.5953050851821899 first col mean 0.5740492939949036 all mean 0.5935879945755005
rl training, epoch1, iter0, batch335/1133, batch loss:1.3051815032958984, Training time:13642.602168560028
batch reward last col mean 0.6304882764816284 first col mean 0.6009417772293091 all mean 0.6308254599571228
rl training, epoch1, iter0, batch336/1133, batch loss:1.5244678258895874, Training time:13669.972646713257
batch reward last col mean 0.651778519153595 first col mean 0.6246522665023804 all mean 0.6487576961517334
rl training, epoch1, iter0, batch337/1133, batch loss:1.500443935394287, Training time:13697.309566736221
batch reward last col mean 0.6359978914260864 first col mean 0.6178275942802429 all mean 0.6326919794082642
rl training, epoch1, iter0, batch338/1133, batch loss:1.462416172027588, Training time:13724.736813306808
batch reward last col mean 0.6010960936546326 first col mean 0.6189191341400146 all mean 0.6037294864654541
rl training, epoch1, iter0, batch339/1133, batch loss:1.32486093044281, Training time:13752.142125844955
batch reward last col mean 0.5944268107414246 first col mean 0.5830886960029602 all mean 0.5931167006492615
rl training, epoch1, iter0, batch340/1133, batch loss:1.3841848373413086, Training time:13779.228684902191
batch reward last col mean 0.6000663638114929 first col mean 0.5797576308250427 all mean 0.5988161563873291
rl training, epoch1, iter0, batch341/1133, batch loss:1.3921489715576172, Training time:13806.250999689102
batch reward last col mean 0.5678155422210693 first col mean 0.5798550248146057 all mean 0.5703405737876892
rl training, epoch1, iter0, batch342/1133, batch loss:1.353954792022705, Training time:13833.380610466003
batch reward last col mean 0.6195496320724487 first col mean 0.6277436017990112 all mean 0.6193419694900513
rl training, epoch1, iter0, batch343/1133, batch loss:1.474126935005188, Training time:13861.027159929276
batch reward last col mean 0.5948647856712341 first col mean 0.6039453744888306 all mean 0.5956361293792725
rl training, epoch1, iter0, batch344/1133, batch loss:1.3965164422988892, Training time:13888.391661167145
batch reward last col mean 0.6807721853256226 first col mean 0.6427489519119263 all mean 0.678894579410553
rl training, epoch1, iter0, batch345/1133, batch loss:1.4959721565246582, Training time:13915.941719293594
batch reward last col mean 0.6123784184455872 first col mean 0.6225537061691284 all mean 0.6129977107048035
rl training, epoch1, iter0, batch346/1133, batch loss:1.4420640468597412, Training time:13943.052337169647
batch reward last col mean 0.6392656564712524 first col mean 0.6039347052574158 all mean 0.6397960782051086
rl training, epoch1, iter0, batch347/1133, batch loss:1.5580004453659058, Training time:13969.98280453682
batch reward last col mean 0.6001408100128174 first col mean 0.6205486059188843 all mean 0.6031098961830139
rl training, epoch1, iter0, batch348/1133, batch loss:1.5799728631973267, Training time:13997.014184474945
batch reward last col mean 0.6121057271957397 first col mean 0.6129047870635986 all mean 0.6110787987709045
rl training, epoch1, iter0, batch349/1133, batch loss:1.421329140663147, Training time:14024.127766609192
batch reward last col mean 0.6210750937461853 first col mean 0.5977871417999268 all mean 0.6198261380195618
rl training, epoch1, iter0, batch350/1133, batch loss:1.415409803390503, Training time:14051.379135131836
batch reward last col mean 0.6027051210403442 first col mean 0.549992561340332 all mean 0.6014963984489441
rl training, epoch1, iter0, batch351/1133, batch loss:1.390239953994751, Training time:14079.204093694687
batch reward last col mean 0.5444976687431335 first col mean 0.5653063058853149 all mean 0.5460811853408813
rl training, epoch1, iter0, batch352/1133, batch loss:1.3210194110870361, Training time:14106.261450529099
batch reward last col mean 0.577218770980835 first col mean 0.549758791923523 all mean 0.5748401284217834
rl training, epoch1, iter0, batch353/1133, batch loss:1.2979425191879272, Training time:14133.44029545784
batch reward last col mean 0.5711286067962646 first col mean 0.5841326117515564 all mean 0.5713710784912109
rl training, epoch1, iter0, batch354/1133, batch loss:1.3411967754364014, Training time:14160.651882886887
batch reward last col mean 0.5699622631072998 first col mean 0.5794265270233154 all mean 0.5710016489028931
rl training, epoch1, iter0, batch355/1133, batch loss:1.3613427877426147, Training time:14187.823256015778
batch reward last col mean 0.5458007454872131 first col mean 0.564784586429596 all mean 0.5475075244903564
rl training, epoch1, iter0, batch356/1133, batch loss:1.2754460573196411, Training time:14215.03617978096
batch reward last col mean 0.5151755213737488 first col mean 0.5478330850601196 all mean 0.5174542665481567
rl training, epoch1, iter0, batch357/1133, batch loss:1.2942975759506226, Training time:14242.28837442398
batch reward last col mean 0.5712871551513672 first col mean 0.5959184169769287 all mean 0.5721032619476318
rl training, epoch1, iter0, batch358/1133, batch loss:1.4067411422729492, Training time:14269.586469650269
batch reward last col mean 0.5350717306137085 first col mean 0.5522269606590271 all mean 0.536711573600769
rl training, epoch1, iter0, batch359/1133, batch loss:1.230688214302063, Training time:14296.832057714462
batch reward last col mean 0.560626745223999 first col mean 0.5568033456802368 all mean 0.5605211853981018
rl training, epoch1, iter0, batch360/1133, batch loss:1.2287572622299194, Training time:14323.938621997833
batch reward last col mean 0.546524703502655 first col mean 0.5511422753334045 all mean 0.5475937128067017
rl training, epoch1, iter0, batch361/1133, batch loss:1.101961374282837, Training time:14350.96954536438
batch reward last col mean 0.5988203287124634 first col mean 0.5954515337944031 all mean 0.598458468914032
rl training, epoch1, iter0, batch362/1133, batch loss:1.3608605861663818, Training time:14377.81163930893
batch reward last col mean 0.5577148795127869 first col mean 0.5555912256240845 all mean 0.558525562286377
rl training, epoch1, iter0, batch363/1133, batch loss:1.3027350902557373, Training time:14404.757889270782
batch reward last col mean 0.5704100131988525 first col mean 0.6131552457809448 all mean 0.570925235748291
rl training, epoch1, iter0, batch364/1133, batch loss:1.2927007675170898, Training time:14431.789838314056
batch reward last col mean 0.6058475971221924 first col mean 0.6214792728424072 all mean 0.6061791181564331
rl training, epoch1, iter0, batch365/1133, batch loss:1.3380584716796875, Training time:14459.00516796112
batch reward last col mean 0.5431050658226013 first col mean 0.5865449905395508 all mean 0.5447525382041931
rl training, epoch1, iter0, batch366/1133, batch loss:1.3403422832489014, Training time:14486.326956033707
batch reward last col mean 0.5556848049163818 first col mean 0.5655259490013123 all mean 0.5559966564178467
rl training, epoch1, iter0, batch367/1133, batch loss:1.2651869058609009, Training time:14513.195911169052
batch reward last col mean 0.6194518208503723 first col mean 0.6100620627403259 all mean 0.619819700717926
rl training, epoch1, iter0, batch368/1133, batch loss:1.3698620796203613, Training time:14540.3805103302
batch reward last col mean 0.570793628692627 first col mean 0.5806227922439575 all mean 0.5728709697723389
rl training, epoch1, iter0, batch369/1133, batch loss:1.237009882926941, Training time:14567.691175937653
batch reward last col mean 0.6299484968185425 first col mean 0.6094024777412415 all mean 0.6290864944458008
rl training, epoch1, iter0, batch370/1133, batch loss:1.346850872039795, Training time:14594.79766535759
batch reward last col mean 0.6682616472244263 first col mean 0.6493960618972778 all mean 0.6680641770362854
rl training, epoch1, iter0, batch371/1133, batch loss:1.4331364631652832, Training time:14621.724248409271
batch reward last col mean 0.633155345916748 first col mean 0.637435257434845 all mean 0.6334075331687927
rl training, epoch1, iter0, batch372/1133, batch loss:1.3280694484710693, Training time:14648.438697099686
batch reward last col mean 0.5745518803596497 first col mean 0.5672239661216736 all mean 0.573756217956543
rl training, epoch1, iter0, batch373/1133, batch loss:1.2930277585983276, Training time:14675.564264059067
batch reward last col mean 0.5799685120582581 first col mean 0.5776815414428711 all mean 0.5809688568115234
rl training, epoch1, iter0, batch374/1133, batch loss:1.2587120532989502, Training time:14702.674359083176
batch reward last col mean 0.5988240242004395 first col mean 0.5948704481124878 all mean 0.5987809896469116
rl training, epoch1, iter0, batch375/1133, batch loss:1.2628669738769531, Training time:14729.622369289398
batch reward last col mean 0.5802816152572632 first col mean 0.6061820983886719 all mean 0.5816499590873718
rl training, epoch1, iter0, batch376/1133, batch loss:1.1813938617706299, Training time:14756.668937206268
batch reward last col mean 0.5838751792907715 first col mean 0.579878032207489 all mean 0.5837969779968262
rl training, epoch1, iter0, batch377/1133, batch loss:1.1749120950698853, Training time:14783.515485525131
batch reward last col mean 0.6473125219345093 first col mean 0.6717109680175781 all mean 0.6479306221008301
rl training, epoch1, iter0, batch378/1133, batch loss:1.412798523902893, Training time:14810.371990203857
batch reward last col mean 0.6297554969787598 first col mean 0.6044235229492188 all mean 0.6291570067405701
rl training, epoch1, iter0, batch379/1133, batch loss:1.278549075126648, Training time:14837.486300706863
batch reward last col mean 0.5749038457870483 first col mean 0.597681999206543 all mean 0.5763214230537415
rl training, epoch1, iter0, batch380/1133, batch loss:1.2782881259918213, Training time:14864.394921064377
batch reward last col mean 0.5889482498168945 first col mean 0.6020421385765076 all mean 0.5903064012527466
rl training, epoch1, iter0, batch381/1133, batch loss:1.2777589559555054, Training time:14891.540046691895
batch reward last col mean 0.6359952092170715 first col mean 0.6525343060493469 all mean 0.6368677020072937
rl training, epoch1, iter0, batch382/1133, batch loss:1.4471632242202759, Training time:14918.799703598022
batch reward last col mean 0.6560097336769104 first col mean 0.6365298628807068 all mean 0.6545097231864929
rl training, epoch1, iter0, batch383/1133, batch loss:1.3943893909454346, Training time:14945.819234132767
batch reward last col mean 0.6390184164047241 first col mean 0.6175429821014404 all mean 0.6383788585662842
rl training, epoch1, iter0, batch384/1133, batch loss:1.3190457820892334, Training time:14973.004040002823
batch reward last col mean 0.6185814142227173 first col mean 0.6267745494842529 all mean 0.6208553910255432
rl training, epoch1, iter0, batch385/1133, batch loss:1.2333505153656006, Training time:15000.536610364914
batch reward last col mean 0.5898761749267578 first col mean 0.6050665974617004 all mean 0.591763973236084
rl training, epoch1, iter0, batch386/1133, batch loss:1.0822561979293823, Training time:15028.522030830383
batch reward last col mean 0.644436240196228 first col mean 0.6176154613494873 all mean 0.6363680362701416
rl training, epoch1, iter0, batch387/1133, batch loss:1.0586482286453247, Training time:15056.633801221848
batch reward last col mean 0.6812194585800171 first col mean 0.6408511400222778 all mean 0.6660643219947815
rl training, epoch1, iter0, batch388/1133, batch loss:1.2101584672927856, Training time:15084.696320772171
batch reward last col mean 0.6263666152954102 first col mean 0.6339997053146362 all mean 0.6267523169517517
rl training, epoch1, iter0, batch389/1133, batch loss:1.2811304330825806, Training time:15112.290576457977
batch reward last col mean 0.5952271223068237 first col mean 0.6137359142303467 all mean 0.5966945886611938
rl training, epoch1, iter0, batch390/1133, batch loss:1.2400932312011719, Training time:15139.307399749756
batch reward last col mean 0.6141736507415771 first col mean 0.6058157086372375 all mean 0.6136661171913147
rl training, epoch1, iter0, batch391/1133, batch loss:1.248486876487732, Training time:15166.6742041111
batch reward last col mean 0.6193103194236755 first col mean 0.6015654802322388 all mean 0.6180989146232605
rl training, epoch1, iter0, batch392/1133, batch loss:1.2474429607391357, Training time:15194.32788014412
batch reward last col mean 0.5954409837722778 first col mean 0.6526688933372498 all mean 0.597632646560669
rl training, epoch1, iter0, batch393/1133, batch loss:1.2031272649765015, Training time:15221.39450955391
batch reward last col mean 0.5643343925476074 first col mean 0.6059980988502502 all mean 0.5657452940940857
rl training, epoch1, iter0, batch394/1133, batch loss:1.2652044296264648, Training time:15248.515105962753
batch reward last col mean 0.6094455718994141 first col mean 0.6610921621322632 all mean 0.6107667088508606
rl training, epoch1, iter0, batch395/1133, batch loss:1.2925198078155518, Training time:15275.768430709839
batch reward last col mean 0.6345540285110474 first col mean 0.6519616842269897 all mean 0.634796142578125
rl training, epoch1, iter0, batch396/1133, batch loss:1.2071473598480225, Training time:15302.882934331894
batch reward last col mean 0.6479425430297852 first col mean 0.6510505676269531 all mean 0.6479989886283875
rl training, epoch1, iter0, batch397/1133, batch loss:1.251494288444519, Training time:15330.366250514984
batch reward last col mean 0.6089624762535095 first col mean 0.6228532195091248 all mean 0.6084478497505188
rl training, epoch1, iter0, batch398/1133, batch loss:1.194981336593628, Training time:15357.203078985214
batch reward last col mean 0.6514745950698853 first col mean 0.6658331155776978 all mean 0.6508433222770691
rl training, epoch1, iter0, batch399/1133, batch loss:1.3525803089141846, Training time:15384.540601968765
batch reward last col mean 0.6118514537811279 first col mean 0.6056072115898132 all mean 0.6125146150588989
rl training, epoch1, iter0, batch400/1133, batch loss:1.1979832649230957, Training time:15411.67633485794
batch reward last col mean 0.6536526083946228 first col mean 0.6445642709732056 all mean 0.6529711484909058
rl training, epoch1, iter0, batch401/1133, batch loss:1.178166389465332, Training time:15438.61578321457
batch reward last col mean 0.6417577266693115 first col mean 0.6338504552841187 all mean 0.6413655281066895
rl training, epoch1, iter0, batch402/1133, batch loss:1.2582075595855713, Training time:15465.676085948944
batch reward last col mean 0.6840706467628479 first col mean 0.6594164371490479 all mean 0.6836284399032593
rl training, epoch1, iter0, batch403/1133, batch loss:1.200720191001892, Training time:15492.573714494705
batch reward last col mean 0.6290999054908752 first col mean 0.6295733451843262 all mean 0.6294296383857727
rl training, epoch1, iter0, batch404/1133, batch loss:1.2816969156265259, Training time:15519.849124193192
batch reward last col mean 0.6241536736488342 first col mean 0.6305719017982483 all mean 0.6246613264083862
rl training, epoch1, iter0, batch405/1133, batch loss:1.3023650646209717, Training time:15547.198829889297
batch reward last col mean 0.6756917834281921 first col mean 0.6353371143341064 all mean 0.6732843518257141
rl training, epoch1, iter0, batch406/1133, batch loss:1.3284190893173218, Training time:15574.460358858109
batch reward last col mean 0.6313093900680542 first col mean 0.6542164087295532 all mean 0.6319290399551392
rl training, epoch1, iter0, batch407/1133, batch loss:1.1771312952041626, Training time:15601.594904184341
batch reward last col mean 0.5917081236839294 first col mean 0.5943406224250793 all mean 0.5920276045799255
rl training, epoch1, iter0, batch408/1133, batch loss:1.1946542263031006, Training time:15628.532983541489
batch reward last col mean 0.6691361665725708 first col mean 0.6563150882720947 all mean 0.6700129508972168
rl training, epoch1, iter0, batch409/1133, batch loss:1.2417962551116943, Training time:15655.931024551392
batch reward last col mean 0.6410621404647827 first col mean 0.6432977914810181 all mean 0.6414005160331726
rl training, epoch1, iter0, batch410/1133, batch loss:1.1610469818115234, Training time:15683.145724773407
batch reward last col mean 0.6379039883613586 first col mean 0.6288189888000488 all mean 0.6377874612808228
rl training, epoch1, iter0, batch411/1133, batch loss:1.0769740343093872, Training time:15710.034526348114
batch reward last col mean 0.639517068862915 first col mean 0.6426304578781128 all mean 0.6406071782112122
rl training, epoch1, iter0, batch412/1133, batch loss:1.2400563955307007, Training time:15737.080726623535
batch reward last col mean 0.6615456938743591 first col mean 0.6369913816452026 all mean 0.6610283255577087
rl training, epoch1, iter0, batch413/1133, batch loss:1.1971839666366577, Training time:15764.563294410706
batch reward last col mean 0.6062070727348328 first col mean 0.583402156829834 all mean 0.6056395769119263
rl training, epoch1, iter0, batch414/1133, batch loss:1.0921767950057983, Training time:15791.426320552826
batch reward last col mean 0.564082682132721 first col mean 0.5797702670097351 all mean 0.5642975568771362
rl training, epoch1, iter0, batch415/1133, batch loss:1.1368060111999512, Training time:15818.640644788742
batch reward last col mean 0.6425740718841553 first col mean 0.6506737470626831 all mean 0.6435143351554871
rl training, epoch1, iter0, batch416/1133, batch loss:1.2060539722442627, Training time:15845.378781080246
batch reward last col mean 0.588330864906311 first col mean 0.585649847984314 all mean 0.5878425240516663
rl training, epoch1, iter0, batch417/1133, batch loss:1.1039998531341553, Training time:15872.616682767868
batch reward last col mean 0.6604261994361877 first col mean 0.6703060269355774 all mean 0.6624717116355896
rl training, epoch1, iter0, batch418/1133, batch loss:1.341493844985962, Training time:15899.950330972672
batch reward last col mean 0.6469061374664307 first col mean 0.6373699903488159 all mean 0.6470450758934021
rl training, epoch1, iter0, batch419/1133, batch loss:1.1204538345336914, Training time:15926.912512779236
batch reward last col mean 0.6049540042877197 first col mean 0.5931243896484375 all mean 0.6049551963806152
rl training, epoch1, iter0, batch420/1133, batch loss:1.1337989568710327, Training time:15954.266084194183
batch reward last col mean 0.6308562755584717 first col mean 0.641840398311615 all mean 0.6317676901817322
rl training, epoch1, iter0, batch421/1133, batch loss:1.1491726636886597, Training time:15981.42329788208
batch reward last col mean 0.6823889017105103 first col mean 0.6474827527999878 all mean 0.6801030039787292
rl training, epoch1, iter0, batch422/1133, batch loss:1.2716574668884277, Training time:16008.312035560608
batch reward last col mean 0.6417550444602966 first col mean 0.6616727113723755 all mean 0.64161616563797
rl training, epoch1, iter0, batch423/1133, batch loss:1.127250075340271, Training time:16035.6691634655
batch reward last col mean 0.6296897530555725 first col mean 0.6081395149230957 all mean 0.6287572979927063
rl training, epoch1, iter0, batch424/1133, batch loss:1.1076531410217285, Training time:16062.801617383957
batch reward last col mean 0.6736289262771606 first col mean 0.6369608044624329 all mean 0.6715112328529358
rl training, epoch1, iter0, batch425/1133, batch loss:1.122590184211731, Training time:16090.174068927765
batch reward last col mean 0.6443253755569458 first col mean 0.6260287761688232 all mean 0.6433926820755005
rl training, epoch1, iter0, batch426/1133, batch loss:1.1372590065002441, Training time:16117.5420088768
batch reward last col mean 0.6545791625976562 first col mean 0.6497869491577148 all mean 0.6538956165313721
rl training, epoch1, iter0, batch427/1133, batch loss:1.1843265295028687, Training time:16144.828935623169
batch reward last col mean 0.5893955230712891 first col mean 0.5950769782066345 all mean 0.5886884927749634
rl training, epoch1, iter0, batch428/1133, batch loss:1.0081812143325806, Training time:16172.284117937088
batch reward last col mean 0.6850172281265259 first col mean 0.6711564660072327 all mean 0.6850304007530212
rl training, epoch1, iter0, batch429/1133, batch loss:1.2052829265594482, Training time:16199.726213693619
batch reward last col mean 0.6352542042732239 first col mean 0.6283437013626099 all mean 0.6343151926994324
rl training, epoch1, iter0, batch430/1133, batch loss:1.1091907024383545, Training time:16226.984237909317
batch reward last col mean 0.6814655065536499 first col mean 0.6937934160232544 all mean 0.6810951828956604
rl training, epoch1, iter0, batch431/1133, batch loss:1.1832141876220703, Training time:16254.426602125168
batch reward last col mean 0.704858660697937 first col mean 0.662204384803772 all mean 0.7016506195068359
rl training, epoch1, iter0, batch432/1133, batch loss:1.115206003189087, Training time:16281.725102901459
batch reward last col mean 0.6560097932815552 first col mean 0.6493449211120605 all mean 0.6533113718032837
rl training, epoch1, iter0, batch433/1133, batch loss:1.0903767347335815, Training time:16309.65978360176
batch reward last col mean 0.5942779779434204 first col mean 0.6140198707580566 all mean 0.5956727862358093
rl training, epoch1, iter0, batch434/1133, batch loss:1.0230919122695923, Training time:16337.287339687347
batch reward last col mean 0.6387926340103149 first col mean 0.6699323654174805 all mean 0.6386163830757141
rl training, epoch1, iter0, batch435/1133, batch loss:1.125260353088379, Training time:16365.162127494812
batch reward last col mean 0.6386105418205261 first col mean 0.6417195200920105 all mean 0.6383371949195862
rl training, epoch1, iter0, batch436/1133, batch loss:0.8914287090301514, Training time:16392.751493692398
batch reward last col mean 0.6269412040710449 first col mean 0.6397823095321655 all mean 0.628084659576416
rl training, epoch1, iter0, batch437/1133, batch loss:0.9532853364944458, Training time:16419.769533634186
batch reward last col mean 0.6473336219787598 first col mean 0.6670636534690857 all mean 0.6487733721733093
rl training, epoch1, iter0, batch438/1133, batch loss:0.8957760334014893, Training time:16447.095567703247
batch reward last col mean 0.609854519367218 first col mean 0.6262422800064087 all mean 0.6103599071502686
rl training, epoch1, iter0, batch439/1133, batch loss:0.7853690385818481, Training time:16474.399760246277
batch reward last col mean 0.6467224359512329 first col mean 0.6298929452896118 all mean 0.6460173726081848
rl training, epoch1, iter0, batch440/1133, batch loss:0.8442184925079346, Training time:16501.465356111526
batch reward last col mean 0.6064037680625916 first col mean 0.6259081363677979 all mean 0.6072248220443726
rl training, epoch1, iter0, batch441/1133, batch loss:0.7186664938926697, Training time:16528.678899288177
batch reward last col mean 0.6335444450378418 first col mean 0.6099055409431458 all mean 0.6326289176940918
rl training, epoch1, iter0, batch442/1133, batch loss:0.7905080318450928, Training time:16555.414962291718
batch reward last col mean 0.6099352836608887 first col mean 0.6328328847885132 all mean 0.6101244688034058
rl training, epoch1, iter0, batch443/1133, batch loss:0.7873536348342896, Training time:16582.5926861763
batch reward last col mean 0.6281899809837341 first col mean 0.6326148509979248 all mean 0.6274645328521729
rl training, epoch1, iter0, batch444/1133, batch loss:0.7639015913009644, Training time:16609.845658540726
batch reward last col mean 0.5715469121932983 first col mean 0.6125515699386597 all mean 0.572931170463562
rl training, epoch1, iter0, batch445/1133, batch loss:0.7026931643486023, Training time:16637.07665514946
batch reward last col mean 0.6268545389175415 first col mean 0.6373600959777832 all mean 0.626613438129425
rl training, epoch1, iter0, batch446/1133, batch loss:0.741111695766449, Training time:16664.272058963776
batch reward last col mean 0.6265062093734741 first col mean 0.6100472807884216 all mean 0.6260448098182678
rl training, epoch1, iter0, batch447/1133, batch loss:0.7659817337989807, Training time:16691.32244205475
batch reward last col mean 0.6387671232223511 first col mean 0.6345452070236206 all mean 0.6381047368049622
rl training, epoch1, iter0, batch448/1133, batch loss:0.6953203082084656, Training time:16718.203632831573
batch reward last col mean 0.5632343292236328 first col mean 0.5666537284851074 all mean 0.5638856291770935
rl training, epoch1, iter0, batch449/1133, batch loss:0.6722540855407715, Training time:16745.618802309036
batch reward last col mean 0.6292708516120911 first col mean 0.6442726850509644 all mean 0.6300069689750671
rl training, epoch1, iter0, batch450/1133, batch loss:0.7697381973266602, Training time:16772.597388744354
batch reward last col mean 0.5645803809165955 first col mean 0.5718001127243042 all mean 0.5654507875442505
rl training, epoch1, iter0, batch451/1133, batch loss:0.629126787185669, Training time:16799.82113790512
batch reward last col mean 0.6027853488922119 first col mean 0.6270407438278198 all mean 0.604180634021759
rl training, epoch1, iter0, batch452/1133, batch loss:0.6927998661994934, Training time:16827.199891090393
batch reward last col mean 0.6371420621871948 first col mean 0.618768036365509 all mean 0.6363852620124817
rl training, epoch1, iter0, batch453/1133, batch loss:0.820759117603302, Training time:16854.354742527008
batch reward last col mean 0.6108869314193726 first col mean 0.6405655741691589 all mean 0.6109504103660583
rl training, epoch1, iter0, batch454/1133, batch loss:0.7821902632713318, Training time:16881.685863018036
batch reward last col mean 0.6561029553413391 first col mean 0.6414742469787598 all mean 0.6541182398796082
rl training, epoch1, iter0, batch455/1133, batch loss:0.799993634223938, Training time:16908.7617020607
batch reward last col mean 0.6061053276062012 first col mean 0.6164045929908752 all mean 0.605957567691803
rl training, epoch1, iter0, batch456/1133, batch loss:0.699470579624176, Training time:16936.258516550064
batch reward last col mean 0.6394891142845154 first col mean 0.6144920587539673 all mean 0.638390839099884
rl training, epoch1, iter0, batch457/1133, batch loss:0.7770442962646484, Training time:16963.60186600685
batch reward last col mean 0.6509362459182739 first col mean 0.6598294973373413 all mean 0.6531145572662354
rl training, epoch1, iter0, batch458/1133, batch loss:0.820544421672821, Training time:16991.15271282196
batch reward last col mean 0.6389024257659912 first col mean 0.6519268155097961 all mean 0.6402503848075867
rl training, epoch1, iter0, batch459/1133, batch loss:0.6828198432922363, Training time:17018.884924411774
batch reward last col mean 0.6195763349533081 first col mean 0.6539320945739746 all mean 0.6216970086097717
rl training, epoch1, iter0, batch460/1133, batch loss:0.8185323476791382, Training time:17046.592599630356
batch reward last col mean 0.5989892482757568 first col mean 0.621173620223999 all mean 0.5996409058570862
rl training, epoch1, iter0, batch461/1133, batch loss:0.6464607119560242, Training time:17073.83655357361
batch reward last col mean 0.5707938075065613 first col mean 0.5647587180137634 all mean 0.5704145431518555
rl training, epoch1, iter0, batch462/1133, batch loss:0.6720266938209534, Training time:17101.117022275925
batch reward last col mean 0.5562001466751099 first col mean 0.5824260711669922 all mean 0.5588180422782898
rl training, epoch1, iter0, batch463/1133, batch loss:0.6317281126976013, Training time:17128.55175590515
batch reward last col mean 0.6309808492660522 first col mean 0.6529317498207092 all mean 0.6313729882240295
rl training, epoch1, iter0, batch464/1133, batch loss:0.7146539092063904, Training time:17155.89018845558
batch reward last col mean 0.5990344285964966 first col mean 0.5849021673202515 all mean 0.598008930683136
rl training, epoch1, iter0, batch465/1133, batch loss:0.6323341727256775, Training time:17183.277211666107
batch reward last col mean 0.6742762327194214 first col mean 0.6837162375450134 all mean 0.6742274761199951
rl training, epoch1, iter0, batch466/1133, batch loss:0.7165496349334717, Training time:17210.44375896454
batch reward last col mean 0.6119891405105591 first col mean 0.6240324378013611 all mean 0.6117768883705139
rl training, epoch1, iter0, batch467/1133, batch loss:0.6057386994361877, Training time:17237.431923866272
batch reward last col mean 0.6670175194740295 first col mean 0.6636561155319214 all mean 0.666323721408844
rl training, epoch1, iter0, batch468/1133, batch loss:0.7320364117622375, Training time:17264.45336508751
batch reward last col mean 0.6282367706298828 first col mean 0.6451208591461182 all mean 0.6302667260169983
rl training, epoch1, iter0, batch469/1133, batch loss:0.6743870973587036, Training time:17291.293974876404
batch reward last col mean 0.6471635699272156 first col mean 0.6405737996101379 all mean 0.6464980244636536
rl training, epoch1, iter0, batch470/1133, batch loss:0.6289587616920471, Training time:17318.298640727997
batch reward last col mean 0.5950176119804382 first col mean 0.6179041266441345 all mean 0.5963072180747986
rl training, epoch1, iter0, batch471/1133, batch loss:0.6027665138244629, Training time:17345.042603969574
batch reward last col mean 0.6645549535751343 first col mean 0.6528481245040894 all mean 0.6641095280647278
rl training, epoch1, iter0, batch472/1133, batch loss:0.7018703818321228, Training time:17371.65416240692
batch reward last col mean 0.5956170558929443 first col mean 0.6340624690055847 all mean 0.5970267057418823
rl training, epoch1, iter0, batch473/1133, batch loss:0.5993859767913818, Training time:17398.572708129883
batch reward last col mean 0.6201510429382324 first col mean 0.6296042203903198 all mean 0.6201817393302917
rl training, epoch1, iter0, batch474/1133, batch loss:0.553987979888916, Training time:17425.3511531353
batch reward last col mean 0.6476821899414062 first col mean 0.6590372323989868 all mean 0.6476972699165344
rl training, epoch1, iter0, batch475/1133, batch loss:0.6437284350395203, Training time:17452.311520814896
batch reward last col mean 0.6115260124206543 first col mean 0.6242215037345886 all mean 0.6115614771842957
rl training, epoch1, iter0, batch476/1133, batch loss:0.5800939798355103, Training time:17479.25585913658
batch reward last col mean 0.6637058854103088 first col mean 0.6627172231674194 all mean 0.663662850856781
rl training, epoch1, iter0, batch477/1133, batch loss:0.6179227828979492, Training time:17506.04841542244
batch reward last col mean 0.6305322051048279 first col mean 0.6276546120643616 all mean 0.6302474737167358
rl training, epoch1, iter0, batch478/1133, batch loss:0.6199755072593689, Training time:17533.123999595642
batch reward last col mean 0.5989357233047485 first col mean 0.6329166293144226 all mean 0.6002355217933655
rl training, epoch1, iter0, batch479/1133, batch loss:0.5680146217346191, Training time:17559.91719174385
batch reward last col mean 0.6769774556159973 first col mean 0.6675381064414978 all mean 0.6757152676582336
rl training, epoch1, iter0, batch480/1133, batch loss:0.5495223999023438, Training time:17586.898263692856
batch reward last col mean 0.6242308616638184 first col mean 0.6387704610824585 all mean 0.6251612305641174
rl training, epoch1, iter0, batch481/1133, batch loss:0.5070260167121887, Training time:17613.748113155365
batch reward last col mean 0.6000182032585144 first col mean 0.6156641244888306 all mean 0.599860429763794
rl training, epoch1, iter0, batch482/1133, batch loss:0.5570473074913025, Training time:17640.43213367462
batch reward last col mean 0.6620188355445862 first col mean 0.6672091484069824 all mean 0.6624943614006042
rl training, epoch1, iter0, batch483/1133, batch loss:0.5506414771080017, Training time:17667.58772277832
batch reward last col mean 0.5800871849060059 first col mean 0.5719601511955261 all mean 0.5801781415939331
rl training, epoch1, iter0, batch484/1133, batch loss:0.4331812560558319, Training time:17694.502977132797
batch reward last col mean 0.6315712928771973 first col mean 0.6168777942657471 all mean 0.6305692195892334
rl training, epoch1, iter0, batch485/1133, batch loss:0.5292866826057434, Training time:17721.512821674347
batch reward last col mean 0.6187151074409485 first col mean 0.6170938611030579 all mean 0.619076132774353
rl training, epoch1, iter0, batch486/1133, batch loss:0.5028995871543884, Training time:17748.44632601738
batch reward last col mean 0.5951752066612244 first col mean 0.5795892477035522 all mean 0.5939704179763794
rl training, epoch1, iter0, batch487/1133, batch loss:0.4838486909866333, Training time:17775.199854373932
batch reward last col mean 0.6144720315933228 first col mean 0.611229658126831 all mean 0.6144615411758423
rl training, epoch1, iter0, batch488/1133, batch loss:0.4996260106563568, Training time:17801.987916469574
batch reward last col mean 0.6638601422309875 first col mean 0.6659684777259827 all mean 0.6636600494384766
rl training, epoch1, iter0, batch489/1133, batch loss:0.6314911246299744, Training time:17828.95964717865
batch reward last col mean 0.6588455438613892 first col mean 0.6600863933563232 all mean 0.6588813066482544
rl training, epoch1, iter0, batch490/1133, batch loss:0.558608889579773, Training time:17855.57416152954
batch reward last col mean 0.6042336225509644 first col mean 0.6350997686386108 all mean 0.6052457094192505
rl training, epoch1, iter0, batch491/1133, batch loss:0.5578307509422302, Training time:17882.273320674896
batch reward last col mean 0.6362698674201965 first col mean 0.6483826637268066 all mean 0.6367987394332886
rl training, epoch1, iter0, batch492/1133, batch loss:0.6343045234680176, Training time:17908.73726129532
batch reward last col mean 0.6996955275535583 first col mean 0.6760291457176208 all mean 0.699506402015686
rl training, epoch1, iter0, batch493/1133, batch loss:0.5800813436508179, Training time:17935.444499731064
batch reward last col mean 0.6509460210800171 first col mean 0.6708406805992126 all mean 0.6515186429023743
rl training, epoch1, iter0, batch494/1133, batch loss:0.5813676714897156, Training time:17962.26063156128
batch reward last col mean 0.6394416689872742 first col mean 0.6428992748260498 all mean 0.6397489905357361
rl training, epoch1, iter0, batch495/1133, batch loss:0.5185931921005249, Training time:17988.808150291443
batch reward last col mean 0.7226362824440002 first col mean 0.6868529915809631 all mean 0.7217040657997131
rl training, epoch1, iter0, batch496/1133, batch loss:0.6411550641059875, Training time:18015.568531513214
batch reward last col mean 0.6367167830467224 first col mean 0.6137708425521851 all mean 0.6361984610557556
rl training, epoch1, iter0, batch497/1133, batch loss:0.5422020554542542, Training time:18042.306772232056
batch reward last col mean 0.6385782957077026 first col mean 0.6170624494552612 all mean 0.6387059092521667
rl training, epoch1, iter0, batch498/1133, batch loss:0.6345778107643127, Training time:18068.950085163116
batch reward last col mean 0.6157363057136536 first col mean 0.6255661845207214 all mean 0.615990161895752
rl training, epoch1, iter0, batch499/1133, batch loss:0.5580634474754333, Training time:18095.831831932068
batch reward last col mean 0.6206180453300476 first col mean 0.6313760876655579 all mean 0.6210470199584961
rl training, epoch1, iter0, batch500/1133, batch loss:0.4397389888763428, Training time:18122.498130321503
batch reward last col mean 0.6267929077148438 first col mean 0.6412271857261658 all mean 0.6265122890472412
rl training, epoch1, iter0, batch501/1133, batch loss:0.48981204628944397, Training time:18149.35227894783
batch reward last col mean 0.6191415786743164 first col mean 0.630968451499939 all mean 0.6192187070846558
rl training, epoch1, iter0, batch502/1133, batch loss:0.5901188254356384, Training time:18176.080179452896
batch reward last col mean 0.6461495161056519 first col mean 0.6362812519073486 all mean 0.6462860703468323
rl training, epoch1, iter0, batch503/1133, batch loss:0.4801005423069, Training time:18202.681308984756
batch reward last col mean 0.6776052117347717 first col mean 0.6681996583938599 all mean 0.6769793033599854
rl training, epoch1, iter0, batch504/1133, batch loss:0.5106480717658997, Training time:18229.725290060043
batch reward last col mean 0.6194107532501221 first col mean 0.6232860684394836 all mean 0.6192269921302795
rl training, epoch1, iter0, batch505/1133, batch loss:0.4688832461833954, Training time:18256.407258749008
batch reward last col mean 0.6852878928184509 first col mean 0.6808199286460876 all mean 0.6854422688484192
rl training, epoch1, iter0, batch506/1133, batch loss:0.49909472465515137, Training time:18283.089292526245
batch reward last col mean 0.6544709801673889 first col mean 0.6308802962303162 all mean 0.6537351608276367
rl training, epoch1, iter0, batch507/1133, batch loss:0.5504955053329468, Training time:18309.937169790268
batch reward last col mean 0.6593478322029114 first col mean 0.6431994438171387 all mean 0.6587063670158386
rl training, epoch1, iter0, batch508/1133, batch loss:0.5855783820152283, Training time:18336.520790815353
batch reward last col mean 0.6171215176582336 first col mean 0.6207202672958374 all mean 0.6170799732208252
rl training, epoch1, iter0, batch509/1133, batch loss:0.4874115586280823, Training time:18363.39009952545
batch reward last col mean 0.6705992221832275 first col mean 0.6760694980621338 all mean 0.6711387038230896
rl training, epoch1, iter0, batch510/1133, batch loss:0.4547748267650604, Training time:18390.366112947464
batch reward last col mean 0.6374431252479553 first col mean 0.648368239402771 all mean 0.637147068977356
rl training, epoch1, iter0, batch511/1133, batch loss:0.4784528315067291, Training time:18417.320004701614
batch reward last col mean 0.6538386940956116 first col mean 0.6221992373466492 all mean 0.6532584428787231
rl training, epoch1, iter0, batch512/1133, batch loss:0.5047354698181152, Training time:18444.10118341446
batch reward last col mean 0.6200596690177917 first col mean 0.6427826881408691 all mean 0.6210682392120361
rl training, epoch1, iter0, batch513/1133, batch loss:0.3989291489124298, Training time:18470.963498592377
batch reward last col mean 0.6123124361038208 first col mean 0.5956372022628784 all mean 0.6120890378952026
rl training, epoch1, iter0, batch514/1133, batch loss:0.44209885597229004, Training time:18497.699558019638
batch reward last col mean 0.6518838405609131 first col mean 0.623248815536499 all mean 0.6512606739997864
rl training, epoch1, iter0, batch515/1133, batch loss:0.43834975361824036, Training time:18524.63696360588
batch reward last col mean 0.5925333499908447 first col mean 0.6352333426475525 all mean 0.5935680866241455
rl training, epoch1, iter0, batch516/1133, batch loss:0.5142199397087097, Training time:18551.41811132431
batch reward last col mean 0.650998055934906 first col mean 0.6276971697807312 all mean 0.6504831314086914
rl training, epoch1, iter0, batch517/1133, batch loss:0.4169425368309021, Training time:18578.31140446663
batch reward last col mean 0.624779462814331 first col mean 0.6345760226249695 all mean 0.6249126195907593
rl training, epoch1, iter0, batch518/1133, batch loss:0.48100709915161133, Training time:18605.199301719666
batch reward last col mean 0.6746810078620911 first col mean 0.667656421661377 all mean 0.6745038032531738
rl training, epoch1, iter0, batch519/1133, batch loss:0.4510529935359955, Training time:18632.15185689926
batch reward last col mean 0.7050358057022095 first col mean 0.7029786705970764 all mean 0.7051253914833069
rl training, epoch1, iter0, batch520/1133, batch loss:0.5214197635650635, Training time:18659.213523626328
batch reward last col mean 0.6331812143325806 first col mean 0.6414556503295898 all mean 0.633855938911438
rl training, epoch1, iter0, batch521/1133, batch loss:0.5027904510498047, Training time:18686.019498109818
batch reward last col mean 0.6553705334663391 first col mean 0.6746349930763245 all mean 0.6559370160102844
rl training, epoch1, iter0, batch522/1133, batch loss:0.4696153402328491, Training time:18712.739290952682
batch reward last col mean 0.5962059497833252 first col mean 0.6179318428039551 all mean 0.5968413949012756
rl training, epoch1, iter0, batch523/1133, batch loss:0.4287094473838806, Training time:18739.76263332367
batch reward last col mean 0.634536862373352 first col mean 0.6335315704345703 all mean 0.6343010663986206
rl training, epoch1, iter0, batch524/1133, batch loss:0.4578331708908081, Training time:18766.678206205368
batch reward last col mean 0.6575770378112793 first col mean 0.6833974123001099 all mean 0.6583247184753418
rl training, epoch1, iter0, batch525/1133, batch loss:0.4438615143299103, Training time:18793.641248703003
batch reward last col mean 0.6417646408081055 first col mean 0.6524218320846558 all mean 0.642339289188385
rl training, epoch1, iter0, batch526/1133, batch loss:0.5242065191268921, Training time:18820.56194639206
batch reward last col mean 0.6213324069976807 first col mean 0.6484231948852539 all mean 0.6220222115516663
rl training, epoch1, iter0, batch527/1133, batch loss:0.4251500368118286, Training time:18847.64130306244
batch reward last col mean 0.6684951782226562 first col mean 0.6961715221405029 all mean 0.6690365076065063
rl training, epoch1, iter0, batch528/1133, batch loss:0.45651835203170776, Training time:18874.688495397568
batch reward last col mean 0.6072344779968262 first col mean 0.6150998473167419 all mean 0.6076175570487976
rl training, epoch1, iter0, batch529/1133, batch loss:0.4192381799221039, Training time:18901.658461093903
batch reward last col mean 0.6823422312736511 first col mean 0.6684935688972473 all mean 0.6821224093437195
rl training, epoch1, iter0, batch530/1133, batch loss:0.47714459896087646, Training time:18928.58466029167
batch reward last col mean 0.662733793258667 first col mean 0.656690239906311 all mean 0.6625416874885559
rl training, epoch1, iter0, batch531/1133, batch loss:0.43947312235832214, Training time:18955.645116090775
batch reward last col mean 0.6577392220497131 first col mean 0.6701372861862183 all mean 0.6578277349472046
rl training, epoch1, iter0, batch532/1133, batch loss:0.4617493450641632, Training time:18982.37883901596
batch reward last col mean 0.6383484601974487 first col mean 0.6448526382446289 all mean 0.6381322145462036
rl training, epoch1, iter0, batch533/1133, batch loss:0.41821449995040894, Training time:19009.322909832
batch reward last col mean 0.6814627647399902 first col mean 0.6635891199111938 all mean 0.6808308362960815
rl training, epoch1, iter0, batch534/1133, batch loss:0.47679153084754944, Training time:19036.038270950317
batch reward last col mean 0.642436146736145 first col mean 0.6488292217254639 all mean 0.6426862478256226
rl training, epoch1, iter0, batch535/1133, batch loss:0.4904007911682129, Training time:19063.051283597946
batch reward last col mean 0.626697301864624 first col mean 0.6221807599067688 all mean 0.6262456178665161
rl training, epoch1, iter0, batch536/1133, batch loss:0.4388028085231781, Training time:19090.05757832527
batch reward last col mean 0.6174342632293701 first col mean 0.6085657477378845 all mean 0.6174450516700745
rl training, epoch1, iter0, batch537/1133, batch loss:0.40382063388824463, Training time:19116.847729444504
batch reward last col mean 0.6305216550827026 first col mean 0.6223101019859314 all mean 0.6304517984390259
rl training, epoch1, iter0, batch538/1133, batch loss:0.5456652641296387, Training time:19143.8111307621
batch reward last col mean 0.6394357085227966 first col mean 0.6449644565582275 all mean 0.6395612955093384
rl training, epoch1, iter0, batch539/1133, batch loss:0.39632824063301086, Training time:19170.81733727455
batch reward last col mean 0.6619902849197388 first col mean 0.6708465218544006 all mean 0.6620122790336609
rl training, epoch1, iter0, batch540/1133, batch loss:0.46970710158348083, Training time:19197.63646006584
batch reward last col mean 0.6563040018081665 first col mean 0.6512668132781982 all mean 0.656106173992157
rl training, epoch1, iter0, batch541/1133, batch loss:0.4311263859272003, Training time:19224.596097946167
batch reward last col mean 0.6259870529174805 first col mean 0.6323241591453552 all mean 0.6256887316703796
rl training, epoch1, iter0, batch542/1133, batch loss:0.44426941871643066, Training time:19251.31547641754
batch reward last col mean 0.6303149461746216 first col mean 0.644558310508728 all mean 0.6302652955055237
rl training, epoch1, iter0, batch543/1133, batch loss:0.42082563042640686, Training time:19278.230184555054
batch reward last col mean 0.6706807017326355 first col mean 0.649754524230957 all mean 0.6698833703994751
rl training, epoch1, iter0, batch544/1133, batch loss:0.4091409742832184, Training time:19305.186676979065
batch reward last col mean 0.7034240961074829 first col mean 0.7030821442604065 all mean 0.7036644220352173
rl training, epoch1, iter0, batch545/1133, batch loss:0.46555811166763306, Training time:19332.14908337593
batch reward last col mean 0.6756560206413269 first col mean 0.6692788600921631 all mean 0.6756763458251953
rl training, epoch1, iter0, batch546/1133, batch loss:0.4887795150279999, Training time:19359.082319498062
batch reward last col mean 0.6528072357177734 first col mean 0.6557908058166504 all mean 0.6526738405227661
rl training, epoch1, iter0, batch547/1133, batch loss:0.45311087369918823, Training time:19385.63752388954
batch reward last col mean 0.6945455074310303 first col mean 0.6921907663345337 all mean 0.6943703293800354
rl training, epoch1, iter0, batch548/1133, batch loss:0.4037197530269623, Training time:19412.52102136612
batch reward last col mean 0.6727214455604553 first col mean 0.6689480543136597 all mean 0.6728063821792603
rl training, epoch1, iter0, batch549/1133, batch loss:0.5568211674690247, Training time:19439.400628328323
batch reward last col mean 0.6840481758117676 first col mean 0.6733202338218689 all mean 0.6837602853775024
rl training, epoch1, iter0, batch550/1133, batch loss:0.5109742283821106, Training time:19466.129051446915
batch reward last col mean 0.7040368914604187 first col mean 0.7266964316368103 all mean 0.7047068476676941
rl training, epoch1, iter0, batch551/1133, batch loss:0.4792878329753876, Training time:19492.952948331833
batch reward last col mean 0.60447096824646 first col mean 0.600124180316925 all mean 0.6044000387191772
rl training, epoch1, iter0, batch552/1133, batch loss:0.42390161752700806, Training time:19519.73161458969
batch reward last col mean 0.6777077913284302 first col mean 0.6580007076263428 all mean 0.6771787405014038
rl training, epoch1, iter0, batch553/1133, batch loss:0.5637720823287964, Training time:19546.65065908432
batch reward last col mean 0.6012078523635864 first col mean 0.6053417921066284 all mean 0.6012508273124695
rl training, epoch1, iter0, batch554/1133, batch loss:0.49376028776168823, Training time:19573.574697494507
batch reward last col mean 0.6961489915847778 first col mean 0.691290557384491 all mean 0.6958428621292114
rl training, epoch1, iter0, batch555/1133, batch loss:0.509105384349823, Training time:19600.20321536064
batch reward last col mean 0.6013178825378418 first col mean 0.6137232780456543 all mean 0.6015081405639648
rl training, epoch1, iter0, batch556/1133, batch loss:0.41688087582588196, Training time:19627.146749019623
batch reward last col mean 0.6410943865776062 first col mean 0.6388475298881531 all mean 0.6414579153060913
rl training, epoch1, iter0, batch557/1133, batch loss:0.5226016044616699, Training time:19653.957092046738
batch reward last col mean 0.629361629486084 first col mean 0.6471095681190491 all mean 0.6299928426742554
rl training, epoch1, iter0, batch558/1133, batch loss:0.49774169921875, Training time:19680.742238283157
batch reward last col mean 0.6128076910972595 first col mean 0.6315422654151917 all mean 0.6131499409675598
rl training, epoch1, iter0, batch559/1133, batch loss:0.49247992038726807, Training time:19707.70934653282
batch reward last col mean 0.6093724966049194 first col mean 0.6301417350769043 all mean 0.6103569269180298
rl training, epoch1, iter0, batch560/1133, batch loss:0.5200819373130798, Training time:19734.714779138565
batch reward last col mean 0.6670540571212769 first col mean 0.6335351467132568 all mean 0.6666817665100098
rl training, epoch1, iter0, batch561/1133, batch loss:0.560555636882782, Training time:19761.69318461418
batch reward last col mean 0.6021025776863098 first col mean 0.5724272727966309 all mean 0.6012706756591797
rl training, epoch1, iter0, batch562/1133, batch loss:0.49999675154685974, Training time:19788.600591897964
batch reward last col mean 0.6202093362808228 first col mean 0.602918267250061 all mean 0.6195114254951477
rl training, epoch1, iter0, batch563/1133, batch loss:0.5481641292572021, Training time:19815.581300497055
batch reward last col mean 0.5780379772186279 first col mean 0.5840672254562378 all mean 0.578772246837616
rl training, epoch1, iter0, batch564/1133, batch loss:0.5315409302711487, Training time:19842.30961060524
batch reward last col mean 0.6036702990531921 first col mean 0.6088691353797913 all mean 0.6034961342811584
rl training, epoch1, iter0, batch565/1133, batch loss:0.5440122485160828, Training time:19869.348457574844
batch reward last col mean 0.6543711423873901 first col mean 0.6372393369674683 all mean 0.6533264517784119
rl training, epoch1, iter0, batch566/1133, batch loss:0.5559283494949341, Training time:19896.170855283737
batch reward last col mean 0.6416630148887634 first col mean 0.6515945792198181 all mean 0.6417034268379211
rl training, epoch1, iter0, batch567/1133, batch loss:0.5823802947998047, Training time:19922.958742141724
batch reward last col mean 0.6884129047393799 first col mean 0.6630142331123352 all mean 0.6876894235610962
rl training, epoch1, iter0, batch568/1133, batch loss:0.5684410929679871, Training time:19949.871768712997
batch reward last col mean 0.6021853089332581 first col mean 0.6238032579421997 all mean 0.6029629707336426
rl training, epoch1, iter0, batch569/1133, batch loss:0.5841040015220642, Training time:19976.852796316147
batch reward last col mean 0.6686112284660339 first col mean 0.6175575256347656 all mean 0.6665635704994202
rl training, epoch1, iter0, batch570/1133, batch loss:0.5993773937225342, Training time:20003.889061689377
batch reward last col mean 0.6967369914054871 first col mean 0.6877818703651428 all mean 0.6962839961051941
rl training, epoch1, iter0, batch571/1133, batch loss:0.5402435660362244, Training time:20030.674060106277
batch reward last col mean 0.6417698860168457 first col mean 0.6607023477554321 all mean 0.6424946784973145
rl training, epoch1, iter0, batch572/1133, batch loss:0.5688084363937378, Training time:20057.7347304821
batch reward last col mean 0.6279712915420532 first col mean 0.6343815922737122 all mean 0.6280442476272583
rl training, epoch1, iter0, batch573/1133, batch loss:0.6083686351776123, Training time:20084.978434562683
batch reward last col mean 0.6689950823783875 first col mean 0.7038044929504395 all mean 0.6709862947463989
rl training, epoch1, iter0, batch574/1133, batch loss:0.6260530352592468, Training time:20112.04812479019
batch reward last col mean 0.6378639340400696 first col mean 0.6291462779045105 all mean 0.6376511454582214
rl training, epoch1, iter0, batch575/1133, batch loss:0.4978087842464447, Training time:20139.3815844059
batch reward last col mean 0.67592853307724 first col mean 0.6624101400375366 all mean 0.6753393411636353
rl training, epoch1, iter0, batch576/1133, batch loss:0.5793110132217407, Training time:20166.411917448044
batch reward last col mean 0.6548640727996826 first col mean 0.6486212611198425 all mean 0.6547930240631104
rl training, epoch1, iter0, batch577/1133, batch loss:0.5530909299850464, Training time:20193.440774440765
batch reward last col mean 0.7072383165359497 first col mean 0.69672691822052 all mean 0.7069485783576965
rl training, epoch1, iter0, batch578/1133, batch loss:0.6371413469314575, Training time:20220.449085474014
batch reward last col mean 0.6547703742980957 first col mean 0.6349675059318542 all mean 0.6547355055809021
rl training, epoch1, iter0, batch579/1133, batch loss:0.5290108323097229, Training time:20247.42041516304
batch reward last col mean 0.6510179042816162 first col mean 0.6634623408317566 all mean 0.6518102884292603
rl training, epoch1, iter0, batch580/1133, batch loss:0.5433809757232666, Training time:20274.425463199615
batch reward last col mean 0.6322140097618103 first col mean 0.6606979966163635 all mean 0.6331861019134521
rl training, epoch1, iter0, batch581/1133, batch loss:0.44954729080200195, Training time:20301.332363843918
batch reward last col mean 0.6368113160133362 first col mean 0.6298458576202393 all mean 0.636481761932373
rl training, epoch1, iter0, batch582/1133, batch loss:0.4740199148654938, Training time:20328.186789512634
batch reward last col mean 0.6301404237747192 first col mean 0.6216742992401123 all mean 0.6298864483833313
rl training, epoch1, iter0, batch583/1133, batch loss:0.4039616882801056, Training time:20355.292482614517
batch reward last col mean 0.657146692276001 first col mean 0.668716311454773 all mean 0.6573175191879272
rl training, epoch1, iter0, batch584/1133, batch loss:0.44118815660476685, Training time:20382.1214966774
batch reward last col mean 0.6581098437309265 first col mean 0.6764105558395386 all mean 0.6581545472145081
rl training, epoch1, iter0, batch585/1133, batch loss:0.5659846663475037, Training time:20409.377743005753
batch reward last col mean 0.6561456918716431 first col mean 0.6549390554428101 all mean 0.6558296084403992
rl training, epoch1, iter0, batch586/1133, batch loss:0.43061384558677673, Training time:20436.750438928604
batch reward last col mean 0.6427828669548035 first col mean 0.6626803874969482 all mean 0.6456735730171204
rl training, epoch1, iter0, batch587/1133, batch loss:0.37351876497268677, Training time:20463.9499771595
batch reward last col mean 0.6333686709403992 first col mean 0.6234884858131409 all mean 0.6325212717056274
rl training, epoch1, iter0, batch588/1133, batch loss:0.5142431855201721, Training time:20491.154166936874
batch reward last col mean 0.6546076536178589 first col mean 0.6791307926177979 all mean 0.6555970907211304
rl training, epoch1, iter0, batch589/1133, batch loss:0.4511340260505676, Training time:20519.095329284668
batch reward last col mean 0.7065590023994446 first col mean 0.6827871799468994 all mean 0.7053638696670532
rl training, epoch1, iter0, batch590/1133, batch loss:0.4987774193286896, Training time:20546.799545764923
batch reward last col mean 0.6146438717842102 first col mean 0.6343377828598022 all mean 0.6148303747177124
rl training, epoch1, iter0, batch591/1133, batch loss:0.3778563141822815, Training time:20574.908511161804
batch reward last col mean 0.6562079191207886 first col mean 0.6502150297164917 all mean 0.6560501456260681
rl training, epoch1, iter0, batch592/1133, batch loss:0.48611533641815186, Training time:20602.593219280243
batch reward last col mean 0.664459228515625 first col mean 0.6603009700775146 all mean 0.6657229065895081
rl training, epoch1, iter0, batch593/1133, batch loss:0.4784358739852905, Training time:20630.695292711258
batch reward last col mean 0.640608012676239 first col mean 0.6387087106704712 all mean 0.6406408548355103
rl training, epoch1, iter0, batch594/1133, batch loss:0.397573858499527, Training time:20659.159870386124
batch reward last col mean 0.6602944731712341 first col mean 0.637340784072876 all mean 0.6588644981384277
rl training, epoch1, iter0, batch595/1133, batch loss:0.5065729022026062, Training time:20687.20316672325
batch reward last col mean 0.6371586322784424 first col mean 0.6387885212898254 all mean 0.6381010413169861
rl training, epoch1, iter0, batch596/1133, batch loss:0.41266804933547974, Training time:20715.496417999268
batch reward last col mean 0.6313427686691284 first col mean 0.6359274387359619 all mean 0.6307857036590576
rl training, epoch1, iter0, batch597/1133, batch loss:0.4133527874946594, Training time:20744.072029590607
batch reward last col mean 0.6716501712799072 first col mean 0.6707240343093872 all mean 0.6712161898612976
rl training, epoch1, iter0, batch598/1133, batch loss:0.4831710159778595, Training time:20771.694492578506
batch reward last col mean 0.6449762582778931 first col mean 0.6480854749679565 all mean 0.6446502208709717
rl training, epoch1, iter0, batch599/1133, batch loss:0.45979374647140503, Training time:20799.15311551094
batch reward last col mean 0.6263616681098938 first col mean 0.6067179441452026 all mean 0.6255965828895569
rl training, epoch1, iter0, batch600/1133, batch loss:0.5775066614151001, Training time:20826.407485961914
batch reward last col mean 0.6496262550354004 first col mean 0.6409088373184204 all mean 0.648931622505188
rl training, epoch1, iter0, batch601/1133, batch loss:0.5211064219474792, Training time:20853.987180948257
batch reward last col mean 0.5911440253257751 first col mean 0.5834029316902161 all mean 0.5910112857818604
rl training, epoch1, iter0, batch602/1133, batch loss:0.5782954692840576, Training time:20881.072489261627
batch reward last col mean 0.6739572286605835 first col mean 0.6535733938217163 all mean 0.6723435521125793
rl training, epoch1, iter0, batch603/1133, batch loss:0.5205585360527039, Training time:20908.447776556015
batch reward last col mean 0.7325307726860046 first col mean 0.6840683221817017 all mean 0.7304785847663879
rl training, epoch1, iter0, batch604/1133, batch loss:0.6274828314781189, Training time:20935.6234061718
batch reward last col mean 0.6653685569763184 first col mean 0.6762989163398743 all mean 0.6658446788787842
rl training, epoch1, iter0, batch605/1133, batch loss:0.5682724714279175, Training time:20962.591949939728
batch reward last col mean 0.6580637693405151 first col mean 0.6553676724433899 all mean 0.6584306359291077
rl training, epoch1, iter0, batch606/1133, batch loss:0.5400567650794983, Training time:20989.762214422226
batch reward last col mean 0.672931432723999 first col mean 0.6659694910049438 all mean 0.6719930768013
rl training, epoch1, iter0, batch607/1133, batch loss:0.5120922327041626, Training time:21016.552329063416
batch reward last col mean 0.6531263589859009 first col mean 0.6651841998100281 all mean 0.6534729599952698
rl training, epoch1, iter0, batch608/1133, batch loss:0.5665506720542908, Training time:21043.42627620697
batch reward last col mean 0.6434522271156311 first col mean 0.6285356283187866 all mean 0.6432213187217712
rl training, epoch1, iter0, batch609/1133, batch loss:0.5654440522193909, Training time:21070.52538585663
batch reward last col mean 0.641181230545044 first col mean 0.6205084323883057 all mean 0.6408240795135498
rl training, epoch1, iter0, batch610/1133, batch loss:0.569692850112915, Training time:21097.31997704506
batch reward last col mean 0.6639719009399414 first col mean 0.6514296531677246 all mean 0.6642401814460754
rl training, epoch1, iter0, batch611/1133, batch loss:0.5282645225524902, Training time:21124.20280599594
batch reward last col mean 0.6863833069801331 first col mean 0.6646973490715027 all mean 0.6863081455230713
rl training, epoch1, iter0, batch612/1133, batch loss:0.48662492632865906, Training time:21150.977065563202
batch reward last col mean 0.6058820486068726 first col mean 0.6222702264785767 all mean 0.6063953042030334
rl training, epoch1, iter0, batch613/1133, batch loss:0.454827219247818, Training time:21178.053377628326
batch reward last col mean 0.6589411497116089 first col mean 0.6546515226364136 all mean 0.659031093120575
rl training, epoch1, iter0, batch614/1133, batch loss:0.47943249344825745, Training time:21205.087049484253
batch reward last col mean 0.6459370851516724 first col mean 0.6559128165245056 all mean 0.646150529384613
rl training, epoch1, iter0, batch615/1133, batch loss:0.4509360194206238, Training time:21232.099383354187
batch reward last col mean 0.6375496983528137 first col mean 0.6409086585044861 all mean 0.6378358602523804
rl training, epoch1, iter0, batch616/1133, batch loss:0.49954816699028015, Training time:21258.86088848114
batch reward last col mean 0.6065559983253479 first col mean 0.617902398109436 all mean 0.6070969104766846
rl training, epoch1, iter0, batch617/1133, batch loss:0.49317535758018494, Training time:21285.739681005478
batch reward last col mean 0.5869209170341492 first col mean 0.6134243011474609 all mean 0.5877439975738525
rl training, epoch1, iter0, batch618/1133, batch loss:0.42835086584091187, Training time:21313.012984991074
batch reward last col mean 0.6392086744308472 first col mean 0.6254022121429443 all mean 0.638693630695343
rl training, epoch1, iter0, batch619/1133, batch loss:0.4396075904369354, Training time:21340.20544362068
batch reward last col mean 0.6629719138145447 first col mean 0.6506614089012146 all mean 0.6627744436264038
rl training, epoch1, iter0, batch620/1133, batch loss:0.43648770451545715, Training time:21367.361718177795
batch reward last col mean 0.6540833711624146 first col mean 0.667995810508728 all mean 0.654288649559021
rl training, epoch1, iter0, batch621/1133, batch loss:0.5836164355278015, Training time:21394.455241680145
batch reward last col mean 0.670915961265564 first col mean 0.661960780620575 all mean 0.6708884835243225
rl training, epoch1, iter0, batch622/1133, batch loss:0.39528560638427734, Training time:21421.57062649727
batch reward last col mean 0.6526010632514954 first col mean 0.6696180105209351 all mean 0.6530025005340576
rl training, epoch1, iter0, batch623/1133, batch loss:0.5413656830787659, Training time:21448.808877944946
batch reward last col mean 0.6455859541893005 first col mean 0.6389071345329285 all mean 0.6451770663261414
rl training, epoch1, iter0, batch624/1133, batch loss:0.4569132924079895, Training time:21475.870415210724
batch reward last col mean 0.6634228229522705 first col mean 0.6521036624908447 all mean 0.6632230281829834
rl training, epoch1, iter0, batch625/1133, batch loss:0.4579862654209137, Training time:21503.154890537262
batch reward last col mean 0.6647327542304993 first col mean 0.6650193929672241 all mean 0.6649861931800842
rl training, epoch1, iter0, batch626/1133, batch loss:0.43323925137519836, Training time:21530.34627532959
batch reward last col mean 0.674858808517456 first col mean 0.6700417995452881 all mean 0.6745278835296631
rl training, epoch1, iter0, batch627/1133, batch loss:0.4770626127719879, Training time:21557.54402899742
batch reward last col mean 0.681615948677063 first col mean 0.7007259130477905 all mean 0.68218994140625
rl training, epoch1, iter0, batch628/1133, batch loss:0.427336186170578, Training time:21584.776497125626
batch reward last col mean 0.6815042495727539 first col mean 0.6969686150550842 all mean 0.6820563077926636
rl training, epoch1, iter0, batch629/1133, batch loss:0.48852959275245667, Training time:21611.904876470566
batch reward last col mean 0.6731360554695129 first col mean 0.7044132947921753 all mean 0.6739581823348999
rl training, epoch1, iter0, batch630/1133, batch loss:0.36543822288513184, Training time:21639.347675085068
batch reward last col mean 0.6856788396835327 first col mean 0.690375566482544 all mean 0.6860512495040894
rl training, epoch1, iter0, batch631/1133, batch loss:0.43062466382980347, Training time:21666.397284030914
batch reward last col mean 0.7153720259666443 first col mean 0.7027819752693176 all mean 0.7148658037185669
rl training, epoch1, iter0, batch632/1133, batch loss:0.46950051188468933, Training time:21693.338331460953
batch reward last col mean 0.6979231834411621 first col mean 0.6920669078826904 all mean 0.6975352168083191
rl training, epoch1, iter0, batch633/1133, batch loss:0.46511805057525635, Training time:21720.552618026733
batch reward last col mean 0.6666978597640991 first col mean 0.6707029342651367 all mean 0.667147159576416
rl training, epoch1, iter0, batch634/1133, batch loss:0.4057416319847107, Training time:21747.62569642067
batch reward last col mean 0.6636914014816284 first col mean 0.6590195894241333 all mean 0.6634132862091064
rl training, epoch1, iter0, batch635/1133, batch loss:0.4643838703632355, Training time:21774.936631202698
batch reward last col mean 0.6677263379096985 first col mean 0.6615680456161499 all mean 0.667666494846344
rl training, epoch1, iter0, batch636/1133, batch loss:0.43397048115730286, Training time:21802.000663280487
batch reward last col mean 0.6423013210296631 first col mean 0.634307861328125 all mean 0.6419472098350525
rl training, epoch1, iter0, batch637/1133, batch loss:0.40944424271583557, Training time:21828.819556474686
batch reward last col mean 0.6641222238540649 first col mean 0.6627532243728638 all mean 0.6641509532928467
rl training, epoch1, iter0, batch638/1133, batch loss:0.4571908116340637, Training time:21855.996040582657
batch reward last col mean 0.6789000034332275 first col mean 0.6813358664512634 all mean 0.678808867931366
rl training, epoch1, iter0, batch639/1133, batch loss:0.3810614347457886, Training time:21883.014172792435
batch reward last col mean 0.6694936752319336 first col mean 0.6634937524795532 all mean 0.6692207455635071
rl training, epoch1, iter0, batch640/1133, batch loss:0.5002963542938232, Training time:21910.255833625793
batch reward last col mean 0.6680196523666382 first col mean 0.6722261905670166 all mean 0.6678574085235596
rl training, epoch1, iter0, batch641/1133, batch loss:0.41505396366119385, Training time:21937.486253976822
batch reward last col mean 0.6810062527656555 first col mean 0.661322832107544 all mean 0.6803289651870728
rl training, epoch1, iter0, batch642/1133, batch loss:0.43070554733276367, Training time:21964.55320763588
batch reward last col mean 0.6694660186767578 first col mean 0.6646430492401123 all mean 0.6692927479743958
rl training, epoch1, iter0, batch643/1133, batch loss:0.4549664258956909, Training time:21991.69302535057
batch reward last col mean 0.6518242359161377 first col mean 0.6844095587730408 all mean 0.6527224183082581
rl training, epoch1, iter0, batch644/1133, batch loss:0.3773447871208191, Training time:22019.20513153076
batch reward last col mean 0.6644690632820129 first col mean 0.6724920272827148 all mean 0.6648072600364685
rl training, epoch1, iter0, batch645/1133, batch loss:0.45649659633636475, Training time:22046.235085725784
batch reward last col mean 0.6684949994087219 first col mean 0.6829801797866821 all mean 0.6689786314964294
rl training, epoch1, iter0, batch646/1133, batch loss:0.4194672107696533, Training time:22073.556722164154
batch reward last col mean 0.6908655166625977 first col mean 0.6801326870918274 all mean 0.6907986998558044
rl training, epoch1, iter0, batch647/1133, batch loss:0.44813910126686096, Training time:22100.496152877808
batch reward last col mean 0.6637617349624634 first col mean 0.6831409335136414 all mean 0.6641011238098145
rl training, epoch1, iter0, batch648/1133, batch loss:0.4021052122116089, Training time:22127.720106601715
batch reward last col mean 0.6625562906265259 first col mean 0.6668087840080261 all mean 0.6626737713813782
rl training, epoch1, iter0, batch649/1133, batch loss:0.45089542865753174, Training time:22155.052409648895
batch reward last col mean 0.6657118797302246 first col mean 0.655553936958313 all mean 0.6652466654777527
rl training, epoch1, iter0, batch650/1133, batch loss:0.45183509588241577, Training time:22182.368585824966
batch reward last col mean 0.6764744520187378 first col mean 0.6645596027374268 all mean 0.6759170293807983
rl training, epoch1, iter0, batch651/1133, batch loss:0.4224218428134918, Training time:22209.526021957397
batch reward last col mean 0.6893762350082397 first col mean 0.6694623231887817 all mean 0.6887376308441162
rl training, epoch1, iter0, batch652/1133, batch loss:0.4915800392627716, Training time:22236.36187005043
batch reward last col mean 0.6571524739265442 first col mean 0.6612279415130615 all mean 0.6570077538490295
rl training, epoch1, iter0, batch653/1133, batch loss:0.4516124129295349, Training time:22263.458038568497
batch reward last col mean 0.6932216882705688 first col mean 0.6847941875457764 all mean 0.6929308772087097
rl training, epoch1, iter0, batch654/1133, batch loss:0.4921153783798218, Training time:22290.66002035141
batch reward last col mean 0.6663002967834473 first col mean 0.659171998500824 all mean 0.6657229065895081
rl training, epoch1, iter0, batch655/1133, batch loss:0.4399113953113556, Training time:22317.871359825134
batch reward last col mean 0.6901919841766357 first col mean 0.6717649102210999 all mean 0.6899188756942749
rl training, epoch1, iter0, batch656/1133, batch loss:0.467571496963501, Training time:22344.99121785164
batch reward last col mean 0.639046311378479 first col mean 0.6611219048500061 all mean 0.639568030834198
rl training, epoch1, iter0, batch657/1133, batch loss:0.45206063985824585, Training time:22372.379185676575
batch reward last col mean 0.6454101204872131 first col mean 0.6539443731307983 all mean 0.6457066535949707
rl training, epoch1, iter0, batch658/1133, batch loss:0.42869481444358826, Training time:22399.575690746307
batch reward last col mean 0.7168829441070557 first col mean 0.7046648859977722 all mean 0.7164478302001953
rl training, epoch1, iter0, batch659/1133, batch loss:0.5170701146125793, Training time:22426.818215847015
batch reward last col mean 0.6959931254386902 first col mean 0.6864455342292786 all mean 0.6953195929527283
rl training, epoch1, iter0, batch660/1133, batch loss:0.49189814925193787, Training time:22454.129297971725
batch reward last col mean 0.6695881485939026 first col mean 0.6461168527603149 all mean 0.6686761379241943
rl training, epoch1, iter0, batch661/1133, batch loss:0.4804777503013611, Training time:22481.605384349823
batch reward last col mean 0.6461456418037415 first col mean 0.6607327461242676 all mean 0.6472875475883484
rl training, epoch1, iter0, batch662/1133, batch loss:0.42689406871795654, Training time:22508.873003721237
batch reward last col mean 0.654184877872467 first col mean 0.6847543716430664 all mean 0.6552003026008606
rl training, epoch1, iter0, batch663/1133, batch loss:0.5753973722457886, Training time:22536.011896133423
batch reward last col mean 0.6212941408157349 first col mean 0.6368331909179688 all mean 0.621559202671051
rl training, epoch1, iter0, batch664/1133, batch loss:0.5174098610877991, Training time:22563.0326628685
batch reward last col mean 0.7425287365913391 first col mean 0.74683678150177 all mean 0.7425597310066223
rl training, epoch1, iter0, batch665/1133, batch loss:0.5713312029838562, Training time:22589.99232006073
batch reward last col mean 0.6842743158340454 first col mean 0.6966403722763062 all mean 0.6852575540542603
rl training, epoch1, iter0, batch666/1133, batch loss:0.5105922818183899, Training time:22616.96847128868
batch reward last col mean 0.6485826969146729 first col mean 0.6642125248908997 all mean 0.6489549875259399
rl training, epoch1, iter0, batch667/1133, batch loss:0.4980376064777374, Training time:22643.984902381897
batch reward last col mean 0.6998125314712524 first col mean 0.6787816286087036 all mean 0.6989081501960754
rl training, epoch1, iter0, batch668/1133, batch loss:0.6173033118247986, Training time:22671.079609632492
batch reward last col mean 0.6959265470504761 first col mean 0.7132835984230042 all mean 0.6960643529891968
rl training, epoch1, iter0, batch669/1133, batch loss:0.5936309099197388, Training time:22698.145114421844
batch reward last col mean 0.666134238243103 first col mean 0.6934323310852051 all mean 0.6664121747016907
rl training, epoch1, iter0, batch670/1133, batch loss:0.5385636687278748, Training time:22725.289742469788
batch reward last col mean 0.6820252537727356 first col mean 0.6903690695762634 all mean 0.6827132105827332
rl training, epoch1, iter0, batch671/1133, batch loss:0.5684477686882019, Training time:22752.652554035187
batch reward last col mean 0.6914031505584717 first col mean 0.6857275366783142 all mean 0.6910778284072876
rl training, epoch1, iter0, batch672/1133, batch loss:0.5394803881645203, Training time:22779.743890047073
batch reward last col mean 0.6730480194091797 first col mean 0.6699901819229126 all mean 0.6735015511512756
rl training, epoch1, iter0, batch673/1133, batch loss:0.4840722382068634, Training time:22807.07237482071
batch reward last col mean 0.6644202470779419 first col mean 0.6704996824264526 all mean 0.6652369499206543
rl training, epoch1, iter0, batch674/1133, batch loss:0.6272165179252625, Training time:22834.304586410522
batch reward last col mean 0.731548011302948 first col mean 0.7144368290901184 all mean 0.731041669845581
rl training, epoch1, iter0, batch675/1133, batch loss:0.5372493267059326, Training time:22861.40509080887
batch reward last col mean 0.710515558719635 first col mean 0.7052869200706482 all mean 0.7108806371688843
rl training, epoch1, iter0, batch676/1133, batch loss:0.595494270324707, Training time:22888.485972881317
batch reward last col mean 0.6948238015174866 first col mean 0.708248496055603 all mean 0.6948986053466797
rl training, epoch1, iter0, batch677/1133, batch loss:0.608169436454773, Training time:22915.338686466217
batch reward last col mean 0.6890902519226074 first col mean 0.7134068608283997 all mean 0.6899818778038025
rl training, epoch1, iter0, batch678/1133, batch loss:0.5710832476615906, Training time:22942.37436056137
batch reward last col mean 0.7181984186172485 first col mean 0.7081195712089539 all mean 0.7170436382293701
rl training, epoch1, iter0, batch679/1133, batch loss:0.615966260433197, Training time:22969.52761530876
batch reward last col mean 0.654620349407196 first col mean 0.6380417943000793 all mean 0.6549548506736755
rl training, epoch1, iter0, batch680/1133, batch loss:0.623913049697876, Training time:22996.700669765472
batch reward last col mean 0.696851372718811 first col mean 0.6990706324577332 all mean 0.6967083811759949
rl training, epoch1, iter0, batch681/1133, batch loss:0.5982739925384521, Training time:23023.759254455566
batch reward last col mean 0.6680052280426025 first col mean 0.6661098003387451 all mean 0.6685428619384766
rl training, epoch1, iter0, batch682/1133, batch loss:0.5694537162780762, Training time:23050.964461565018
batch reward last col mean 0.6632580757141113 first col mean 0.6765419244766235 all mean 0.6635020971298218
rl training, epoch1, iter0, batch683/1133, batch loss:0.5535793900489807, Training time:23078.04803299904
batch reward last col mean 0.6510254144668579 first col mean 0.649467408657074 all mean 0.6517626643180847
rl training, epoch1, iter0, batch684/1133, batch loss:0.6349689960479736, Training time:23105.292147397995
batch reward last col mean 0.6519378423690796 first col mean 0.6732336282730103 all mean 0.6527842283248901
rl training, epoch1, iter0, batch685/1133, batch loss:0.5191702246665955, Training time:23132.595979452133
batch reward last col mean 0.6309740543365479 first col mean 0.6311840415000916 all mean 0.6299319267272949
rl training, epoch1, iter0, batch686/1133, batch loss:0.4614149034023285, Training time:23159.80797934532
batch reward last col mean 0.5967402458190918 first col mean 0.5967915058135986 all mean 0.5963086485862732
rl training, epoch1, iter0, batch687/1133, batch loss:0.43107908964157104, Training time:23187.26531457901
batch reward last col mean 0.6299943923950195 first col mean 0.6154272556304932 all mean 0.6287837028503418
rl training, epoch1, iter0, batch688/1133, batch loss:0.4121772050857544, Training time:23214.842190027237
batch reward last col mean 0.6149624586105347 first col mean 0.6066681146621704 all mean 0.6146988272666931
rl training, epoch1, iter0, batch689/1133, batch loss:0.38941651582717896, Training time:23242.467831373215
batch reward last col mean 0.6158196926116943 first col mean 0.6035889983177185 all mean 0.6162019371986389
rl training, epoch1, iter0, batch690/1133, batch loss:0.30542775988578796, Training time:23271.070511102676
batch reward last col mean 0.6640480756759644 first col mean 0.6453726291656494 all mean 0.6618505716323853
rl training, epoch1, iter0, batch691/1133, batch loss:0.34777528047561646, Training time:23299.503484725952
batch reward last col mean 0.6437459588050842 first col mean 0.6364737749099731 all mean 0.6430048942565918
rl training, epoch1, iter0, batch692/1133, batch loss:0.3533782362937927, Training time:23328.29718732834
batch reward last col mean 0.6354856491088867 first col mean 0.6350384950637817 all mean 0.6336636543273926
rl training, epoch1, iter0, batch693/1133, batch loss:0.3232886493206024, Training time:23356.633541107178
batch reward last col mean 0.6030557751655579 first col mean 0.5919079780578613 all mean 0.6045737266540527
rl training, epoch1, iter0, batch694/1133, batch loss:0.3013651967048645, Training time:23385.54255247116
batch reward last col mean 0.6523926258087158 first col mean 0.6458008885383606 all mean 0.6518107652664185
rl training, epoch1, iter0, batch695/1133, batch loss:0.41083648800849915, Training time:23413.466021060944
batch reward last col mean 0.6359250545501709 first col mean 0.6334916353225708 all mean 0.6329423785209656
rl training, epoch1, iter0, batch696/1133, batch loss:0.3927697241306305, Training time:23441.79865670204
batch reward last col mean 0.722682535648346 first col mean 0.6885178089141846 all mean 0.7192219495773315
rl training, epoch1, iter0, batch697/1133, batch loss:0.4052967131137848, Training time:23470.310024499893
batch reward last col mean 0.6884857416152954 first col mean 0.6782870292663574 all mean 0.6860798001289368
rl training, epoch1, iter0, batch698/1133, batch loss:0.5004351735115051, Training time:23498.387296438217
batch reward last col mean 0.6643930673599243 first col mean 0.6708728075027466 all mean 0.664486825466156
rl training, epoch1, iter0, batch699/1133, batch loss:0.5039834976196289, Training time:23526.046853542328
batch reward last col mean 0.6732557415962219 first col mean 0.6892380714416504 all mean 0.6734393239021301
rl training, epoch1, iter0, batch700/1133, batch loss:0.4789508879184723, Training time:23553.066226243973
batch reward last col mean 0.6205635666847229 first col mean 0.6394453644752502 all mean 0.6209239363670349
rl training, epoch1, iter0, batch701/1133, batch loss:0.48686274886131287, Training time:23580.736135721207
batch reward last col mean 0.7265479564666748 first col mean 0.71466064453125 all mean 0.7256064414978027
rl training, epoch1, iter0, batch702/1133, batch loss:0.49530670046806335, Training time:23608.18795156479
batch reward last col mean 0.7129152417182922 first col mean 0.7071325182914734 all mean 0.7133110761642456
rl training, epoch1, iter0, batch703/1133, batch loss:0.5550180077552795, Training time:23635.487821102142
batch reward last col mean 0.7022240161895752 first col mean 0.7165093421936035 all mean 0.702395498752594
rl training, epoch1, iter0, batch704/1133, batch loss:0.4667458236217499, Training time:23662.656871557236
batch reward last col mean 0.692741870880127 first col mean 0.6637199521064758 all mean 0.6919824481010437
rl training, epoch1, iter0, batch705/1133, batch loss:0.5286067128181458, Training time:23689.890199661255
batch reward last col mean 0.6730604767799377 first col mean 0.6636328101158142 all mean 0.6732159852981567
rl training, epoch1, iter0, batch706/1133, batch loss:0.4671526849269867, Training time:23716.915471076965
batch reward last col mean 0.6747118234634399 first col mean 0.6806833148002625 all mean 0.6750619411468506
rl training, epoch1, iter0, batch707/1133, batch loss:0.3966478109359741, Training time:23743.983957529068
batch reward last col mean 0.6942781209945679 first col mean 0.6877369284629822 all mean 0.6940397024154663
rl training, epoch1, iter0, batch708/1133, batch loss:0.4744984209537506, Training time:23771.044887542725
batch reward last col mean 0.7120524048805237 first col mean 0.7091987133026123 all mean 0.7120105624198914
rl training, epoch1, iter0, batch709/1133, batch loss:0.41605645418167114, Training time:23798.067826747894
batch reward last col mean 0.6733978390693665 first col mean 0.6761461496353149 all mean 0.6728454828262329
rl training, epoch1, iter0, batch710/1133, batch loss:0.4638534486293793, Training time:23825.068413496017
batch reward last col mean 0.6921895146369934 first col mean 0.7000629305839539 all mean 0.692816972732544
rl training, epoch1, iter0, batch711/1133, batch loss:0.3744065761566162, Training time:23852.152430057526
batch reward last col mean 0.6678036451339722 first col mean 0.6637921929359436 all mean 0.6682373285293579
rl training, epoch1, iter0, batch712/1133, batch loss:0.475631982088089, Training time:23879.202029705048
batch reward last col mean 0.7230969071388245 first col mean 0.7154796719551086 all mean 0.7229284644126892
rl training, epoch1, iter0, batch713/1133, batch loss:0.41123467683792114, Training time:23906.309416532516
batch reward last col mean 0.6859015226364136 first col mean 0.6898072957992554 all mean 0.6865411400794983
rl training, epoch1, iter0, batch714/1133, batch loss:0.38024431467056274, Training time:23933.25977039337
batch reward last col mean 0.7016884088516235 first col mean 0.6870280504226685 all mean 0.7008188962936401
rl training, epoch1, iter0, batch715/1133, batch loss:0.4529552459716797, Training time:23960.35974597931
batch reward last col mean 0.7261053323745728 first col mean 0.7085962891578674 all mean 0.7255672812461853
rl training, epoch1, iter0, batch716/1133, batch loss:0.4109286367893219, Training time:23987.15959072113
batch reward last col mean 0.6809227466583252 first col mean 0.6617854237556458 all mean 0.6798568367958069
rl training, epoch1, iter0, batch717/1133, batch loss:0.37866219878196716, Training time:24013.780397892
batch reward last col mean 0.6663530468940735 first col mean 0.6746172308921814 all mean 0.6664924025535583
rl training, epoch1, iter0, batch718/1133, batch loss:0.3924176096916199, Training time:24040.572063207626
batch reward last col mean 0.6351419687271118 first col mean 0.6537410020828247 all mean 0.6357311606407166
rl training, epoch1, iter0, batch719/1133, batch loss:0.38134104013442993, Training time:24067.494062662125
batch reward last col mean 0.6799384355545044 first col mean 0.6539452075958252 all mean 0.6789029836654663
rl training, epoch1, iter0, batch720/1133, batch loss:0.3565307557582855, Training time:24094.300085783005
batch reward last col mean 0.6503514051437378 first col mean 0.6688094735145569 all mean 0.6508688926696777
rl training, epoch1, iter0, batch721/1133, batch loss:0.4604690372943878, Training time:24121.5958275795
batch reward last col mean 0.6384273767471313 first col mean 0.6549853086471558 all mean 0.6388295292854309
rl training, epoch1, iter0, batch722/1133, batch loss:0.407408744096756, Training time:24148.471454381943
batch reward last col mean 0.6975904703140259 first col mean 0.6900626420974731 all mean 0.6976906061172485
rl training, epoch1, iter0, batch723/1133, batch loss:0.4262208342552185, Training time:24175.372087955475
batch reward last col mean 0.6459600329399109 first col mean 0.6384790539741516 all mean 0.6463351249694824
rl training, epoch1, iter0, batch724/1133, batch loss:0.36599552631378174, Training time:24202.465829133987
batch reward last col mean 0.650413453578949 first col mean 0.64459627866745 all mean 0.6499972343444824
rl training, epoch1, iter0, batch725/1133, batch loss:0.38501447439193726, Training time:24229.40496993065
batch reward last col mean 0.6411712765693665 first col mean 0.64369797706604 all mean 0.6413593888282776
rl training, epoch1, iter0, batch726/1133, batch loss:0.33404341340065, Training time:24256.352451086044
batch reward last col mean 0.6600420475006104 first col mean 0.6792271137237549 all mean 0.6599394679069519
rl training, epoch1, iter0, batch727/1133, batch loss:0.4054664373397827, Training time:24283.22559261322
batch reward last col mean 0.6417087316513062 first col mean 0.6481716632843018 all mean 0.6423503756523132
rl training, epoch1, iter0, batch728/1133, batch loss:0.353045791387558, Training time:24311.05047392845
batch reward last col mean 0.6934972405433655 first col mean 0.7031406760215759 all mean 0.6929805874824524
rl training, epoch1, iter0, batch729/1133, batch loss:0.4294792711734772, Training time:24338.338458538055
batch reward last col mean 0.6603391766548157 first col mean 0.6335628032684326 all mean 0.658970057964325
rl training, epoch1, iter0, batch730/1133, batch loss:0.3840891122817993, Training time:24365.651889562607
batch reward last col mean 0.694749116897583 first col mean 0.6895017027854919 all mean 0.6938316822052002
rl training, epoch1, iter0, batch731/1133, batch loss:0.3497900068759918, Training time:24393.051042318344
batch reward last col mean 0.6321312785148621 first col mean 0.6406890153884888 all mean 0.6319291591644287
rl training, epoch1, iter0, batch732/1133, batch loss:0.35558345913887024, Training time:24420.791701555252
batch reward last col mean 0.6653226017951965 first col mean 0.6703598499298096 all mean 0.6654336452484131
rl training, epoch1, iter0, batch733/1133, batch loss:0.4170570969581604, Training time:24448.446395158768
batch reward last col mean 0.6154545545578003 first col mean 0.6417697668075562 all mean 0.6163164377212524
rl training, epoch1, iter0, batch734/1133, batch loss:0.42475008964538574, Training time:24475.85952949524
batch reward last col mean 0.6352059841156006 first col mean 0.6293858885765076 all mean 0.635020911693573
rl training, epoch1, iter0, batch735/1133, batch loss:0.3358685076236725, Training time:24503.773840665817
batch reward last col mean 0.6359629034996033 first col mean 0.624544620513916 all mean 0.6355600357055664
rl training, epoch1, iter0, batch736/1133, batch loss:0.3375478684902191, Training time:24531.20407319069
batch reward last col mean 0.6973564624786377 first col mean 0.6954426765441895 all mean 0.6965953707695007
rl training, epoch1, iter0, batch737/1133, batch loss:0.40996238589286804, Training time:24558.73692893982
batch reward last col mean 0.6970605850219727 first col mean 0.6628403663635254 all mean 0.6951333284378052
rl training, epoch1, iter0, batch738/1133, batch loss:0.39825472235679626, Training time:24586.560723543167
batch reward last col mean 0.7046664953231812 first col mean 0.6853418350219727 all mean 0.7034367918968201
rl training, epoch1, iter0, batch739/1133, batch loss:0.42302149534225464, Training time:24613.96994638443
batch reward last col mean 0.7020221948623657 first col mean 0.6884856820106506 all mean 0.701382577419281
rl training, epoch1, iter0, batch740/1133, batch loss:0.4066985845565796, Training time:24641.0189909935
batch reward last col mean 0.6311774253845215 first col mean 0.6502653360366821 all mean 0.6318650841712952
rl training, epoch1, iter0, batch741/1133, batch loss:0.33624887466430664, Training time:24668.201899290085
batch reward last col mean 0.6192103028297424 first col mean 0.6524693965911865 all mean 0.6210930347442627
rl training, epoch1, iter0, batch742/1133, batch loss:0.4102013111114502, Training time:24695.54300379753
batch reward last col mean 0.6440409421920776 first col mean 0.6641938090324402 all mean 0.6448808312416077
rl training, epoch1, iter0, batch743/1133, batch loss:0.4034208357334137, Training time:24722.771151542664
batch reward last col mean 0.6248353123664856 first col mean 0.6388841867446899 all mean 0.6247814297676086
rl training, epoch1, iter0, batch744/1133, batch loss:0.41210195422172546, Training time:24750.04231929779
batch reward last col mean 0.665593147277832 first col mean 0.6568686962127686 all mean 0.6658838391304016
rl training, epoch1, iter0, batch745/1133, batch loss:0.49681127071380615, Training time:24777.575196027756
batch reward last col mean 0.662010669708252 first col mean 0.6664954423904419 all mean 0.661866307258606
rl training, epoch1, iter0, batch746/1133, batch loss:0.38725319504737854, Training time:24804.812196731567
batch reward last col mean 0.6312156319618225 first col mean 0.6323781609535217 all mean 0.6312655210494995
rl training, epoch1, iter0, batch747/1133, batch loss:0.39511507749557495, Training time:24831.900217294693
batch reward last col mean 0.6589487791061401 first col mean 0.6654322147369385 all mean 0.6597051024436951
rl training, epoch1, iter0, batch748/1133, batch loss:0.45783451199531555, Training time:24858.774931907654
batch reward last col mean 0.654815673828125 first col mean 0.6746207475662231 all mean 0.6562923789024353
rl training, epoch1, iter0, batch749/1133, batch loss:0.45388129353523254, Training time:24886.07514309883
batch reward last col mean 0.6428233981132507 first col mean 0.6334878206253052 all mean 0.6414965391159058
rl training, epoch1, iter0, batch750/1133, batch loss:0.383586049079895, Training time:24913.15311717987
batch reward last col mean 0.6612857580184937 first col mean 0.6637215614318848 all mean 0.6611065864562988
rl training, epoch1, iter0, batch751/1133, batch loss:0.46003660559654236, Training time:24940.74335694313
batch reward last col mean 0.6056483387947083 first col mean 0.6109976768493652 all mean 0.6061782240867615
rl training, epoch1, iter0, batch752/1133, batch loss:0.39470189809799194, Training time:24968.558987140656
batch reward last col mean 0.6315829753875732 first col mean 0.627790093421936 all mean 0.6315911412239075
rl training, epoch1, iter0, batch753/1133, batch loss:0.3889802396297455, Training time:24995.95360350609
batch reward last col mean 0.6823983192443848 first col mean 0.6701282262802124 all mean 0.6814752221107483
rl training, epoch1, iter0, batch754/1133, batch loss:0.4196363091468811, Training time:25023.23187494278
batch reward last col mean 0.6602175831794739 first col mean 0.654303252696991 all mean 0.6595944762229919
rl training, epoch1, iter0, batch755/1133, batch loss:0.4460393488407135, Training time:25050.491822719574
batch reward last col mean 0.6641349196434021 first col mean 0.6650432348251343 all mean 0.6634695529937744
rl training, epoch1, iter0, batch756/1133, batch loss:0.38412827253341675, Training time:25077.819529771805
batch reward last col mean 0.6486547589302063 first col mean 0.6608279347419739 all mean 0.649320662021637
rl training, epoch1, iter0, batch757/1133, batch loss:0.38970860838890076, Training time:25105.04979491234
batch reward last col mean 0.6917093396186829 first col mean 0.6865590810775757 all mean 0.6914790272712708
rl training, epoch1, iter0, batch758/1133, batch loss:0.35041484236717224, Training time:25132.577785015106
batch reward last col mean 0.6899263858795166 first col mean 0.6880780458450317 all mean 0.689817488193512
rl training, epoch1, iter0, batch759/1133, batch loss:0.38333237171173096, Training time:25159.741072416306
batch reward last col mean 0.6490302085876465 first col mean 0.6741250157356262 all mean 0.6493728160858154
rl training, epoch1, iter0, batch760/1133, batch loss:0.3663843274116516, Training time:25186.817229747772
batch reward last col mean 0.6623774170875549 first col mean 0.6720303297042847 all mean 0.6626402139663696
rl training, epoch1, iter0, batch761/1133, batch loss:0.3473336100578308, Training time:25213.8888027668
batch reward last col mean 0.6644522547721863 first col mean 0.6580374240875244 all mean 0.6643231511116028
rl training, epoch1, iter0, batch762/1133, batch loss:0.3704374432563782, Training time:25241.106223344803
batch reward last col mean 0.6345735192298889 first col mean 0.6386055946350098 all mean 0.634911298751831
rl training, epoch1, iter0, batch763/1133, batch loss:0.35306742787361145, Training time:25268.148452997208
batch reward last col mean 0.661263108253479 first col mean 0.6538497805595398 all mean 0.6608911156654358
rl training, epoch1, iter0, batch764/1133, batch loss:0.3563781976699829, Training time:25295.491053581238
batch reward last col mean 0.6354050636291504 first col mean 0.6449835896492004 all mean 0.636023223400116
rl training, epoch1, iter0, batch765/1133, batch loss:0.3491063117980957, Training time:25322.564463615417
batch reward last col mean 0.6544066071510315 first col mean 0.6562885046005249 all mean 0.6547147035598755
rl training, epoch1, iter0, batch766/1133, batch loss:0.3635360896587372, Training time:25349.89067053795
batch reward last col mean 0.6538199782371521 first col mean 0.671006977558136 all mean 0.6543387770652771
rl training, epoch1, iter0, batch767/1133, batch loss:0.3343753516674042, Training time:25377.257802248
batch reward last col mean 0.7254827618598938 first col mean 0.7080242037773132 all mean 0.7250865697860718
rl training, epoch1, iter0, batch768/1133, batch loss:0.32214727997779846, Training time:25404.524868011475
batch reward last col mean 0.6705330610275269 first col mean 0.6625351905822754 all mean 0.6699826121330261
rl training, epoch1, iter0, batch769/1133, batch loss:0.361535906791687, Training time:25431.927814006805
batch reward last col mean 0.6591402292251587 first col mean 0.6490627527236938 all mean 0.6590033769607544
rl training, epoch1, iter0, batch770/1133, batch loss:0.33618220686912537, Training time:25459.58260321617
batch reward last col mean 0.6945743560791016 first col mean 0.7156795263290405 all mean 0.6953309774398804
rl training, epoch1, iter0, batch771/1133, batch loss:0.3921512961387634, Training time:25487.53680419922
batch reward last col mean 0.6622500419616699 first col mean 0.6522568464279175 all mean 0.6590429544448853
rl training, epoch1, iter0, batch772/1133, batch loss:0.3502843677997589, Training time:25515.445159196854
batch reward last col mean 0.6791753768920898 first col mean 0.6702587604522705 all mean 0.676410973072052
rl training, epoch1, iter0, batch773/1133, batch loss:0.2713479995727539, Training time:25543.665934562683
batch reward last col mean 0.7179756760597229 first col mean 0.7341312170028687 all mean 0.7169087529182434
rl training, epoch1, iter0, batch774/1133, batch loss:0.2801881730556488, Training time:25571.721207618713
batch reward last col mean 0.7243642807006836 first col mean 0.7172912955284119 all mean 0.7224786877632141
rl training, epoch1, iter0, batch775/1133, batch loss:0.34386634826660156, Training time:25599.892909049988
batch reward last col mean 0.6853079199790955 first col mean 0.7038566470146179 all mean 0.6853384971618652
rl training, epoch1, iter0, batch776/1133, batch loss:0.37496376037597656, Training time:25627.47429037094
batch reward last col mean 0.6930241584777832 first col mean 0.6894580125808716 all mean 0.6930017471313477
rl training, epoch1, iter0, batch777/1133, batch loss:0.38135746121406555, Training time:25654.905809164047
batch reward last col mean 0.6987618207931519 first col mean 0.6891213655471802 all mean 0.6985621452331543
rl training, epoch1, iter0, batch778/1133, batch loss:0.3841315805912018, Training time:25682.580852508545
batch reward last col mean 0.6402679681777954 first col mean 0.6451849937438965 all mean 0.6404619216918945
rl training, epoch1, iter0, batch779/1133, batch loss:0.36049219965934753, Training time:25710.498029708862
batch reward last col mean 0.6790575385093689 first col mean 0.7020904421806335 all mean 0.6787616610527039
rl training, epoch1, iter0, batch780/1133, batch loss:0.3732439875602722, Training time:25738.493155002594
batch reward last col mean 0.6961076259613037 first col mean 0.7036694884300232 all mean 0.6961708664894104
rl training, epoch1, iter0, batch781/1133, batch loss:0.3956555724143982, Training time:25766.341506958008
batch reward last col mean 0.6525158286094666 first col mean 0.6567848324775696 all mean 0.6524870991706848
rl training, epoch1, iter0, batch782/1133, batch loss:0.4143800735473633, Training time:25793.702795028687
batch reward last col mean 0.6569943428039551 first col mean 0.6644940972328186 all mean 0.6560176014900208
rl training, epoch1, iter0, batch783/1133, batch loss:0.34176236391067505, Training time:25821.54607820511
batch reward last col mean 0.6445573568344116 first col mean 0.666025698184967 all mean 0.6454758048057556
rl training, epoch1, iter0, batch784/1133, batch loss:0.44943031668663025, Training time:25849.324295282364
batch reward last col mean 0.6834744215011597 first col mean 0.6813832521438599 all mean 0.682945191860199
rl training, epoch1, iter0, batch785/1133, batch loss:0.44620880484580994, Training time:25876.955058813095
batch reward last col mean 0.6517667770385742 first col mean 0.6533803939819336 all mean 0.6519185900688171
rl training, epoch1, iter0, batch786/1133, batch loss:0.4198744297027588, Training time:25904.422955036163
batch reward last col mean 0.6979916095733643 first col mean 0.7106966376304626 all mean 0.6983664035797119
rl training, epoch1, iter0, batch787/1133, batch loss:0.41034722328186035, Training time:25931.67210292816
batch reward last col mean 0.6586551666259766 first col mean 0.6970822215080261 all mean 0.6597120761871338
rl training, epoch1, iter0, batch788/1133, batch loss:0.4363071620464325, Training time:25959.34659218788
batch reward last col mean 0.6904309391975403 first col mean 0.6859343647956848 all mean 0.6903254985809326
rl training, epoch1, iter0, batch789/1133, batch loss:0.47484636306762695, Training time:25986.969732046127
batch reward last col mean 0.6603463292121887 first col mean 0.6752129793167114 all mean 0.6606197953224182
rl training, epoch1, iter0, batch790/1133, batch loss:0.4303617477416992, Training time:26014.68783044815
batch reward last col mean 0.6653254628181458 first col mean 0.676032543182373 all mean 0.6659532785415649
rl training, epoch1, iter0, batch791/1133, batch loss:0.4193042814731598, Training time:26041.90318441391
batch reward last col mean 0.6677426099777222 first col mean 0.6569496393203735 all mean 0.6671388149261475
rl training, epoch1, iter0, batch792/1133, batch loss:0.41149622201919556, Training time:26069.54964518547
batch reward last col mean 0.7049398422241211 first col mean 0.7124695181846619 all mean 0.7035248875617981
rl training, epoch1, iter0, batch793/1133, batch loss:0.3762929439544678, Training time:26097.647161483765
batch reward last col mean 0.6980009078979492 first col mean 0.691908597946167 all mean 0.6977270841598511
rl training, epoch1, iter0, batch794/1133, batch loss:0.42921343445777893, Training time:26125.201357126236
batch reward last col mean 0.6114755868911743 first col mean 0.6112659573554993 all mean 0.6110277771949768
rl training, epoch1, iter0, batch795/1133, batch loss:0.34278738498687744, Training time:26152.928102254868
batch reward last col mean 0.6536105871200562 first col mean 0.650005578994751 all mean 0.6541595458984375
rl training, epoch1, iter0, batch796/1133, batch loss:0.4979245662689209, Training time:26180.3676404953
batch reward last col mean 0.6804709434509277 first col mean 0.6850184202194214 all mean 0.680537223815918
rl training, epoch1, iter0, batch797/1133, batch loss:0.48883554339408875, Training time:26207.63744878769
batch reward last col mean 0.6483103036880493 first col mean 0.6688733100891113 all mean 0.6488271355628967
rl training, epoch1, iter0, batch798/1133, batch loss:0.4434967339038849, Training time:26234.98316168785
batch reward last col mean 0.6431527733802795 first col mean 0.6536280512809753 all mean 0.6439671516418457
rl training, epoch1, iter0, batch799/1133, batch loss:0.3964913487434387, Training time:26262.338309764862
batch reward last col mean 0.6920912265777588 first col mean 0.6837158203125 all mean 0.6915948390960693
rl training, epoch1, iter0, batch800/1133, batch loss:0.4763447642326355, Training time:26289.693240880966
batch reward last col mean 0.7391563653945923 first col mean 0.7221971750259399 all mean 0.7386265993118286
rl training, epoch1, iter0, batch801/1133, batch loss:0.48138442635536194, Training time:26316.7782933712
batch reward last col mean 0.6450003981590271 first col mean 0.6468701958656311 all mean 0.6452564001083374
rl training, epoch1, iter0, batch802/1133, batch loss:0.396520733833313, Training time:26343.634316921234
batch reward last col mean 0.7007148861885071 first col mean 0.6896283030509949 all mean 0.7003546953201294
rl training, epoch1, iter0, batch803/1133, batch loss:0.4337477385997772, Training time:26370.79177379608
batch reward last col mean 0.6543156504631042 first col mean 0.6494969725608826 all mean 0.6538107395172119
rl training, epoch1, iter0, batch804/1133, batch loss:0.426006942987442, Training time:26398.733406066895
batch reward last col mean 0.6879304051399231 first col mean 0.6890638470649719 all mean 0.6883742213249207
rl training, epoch1, iter0, batch805/1133, batch loss:0.4524240493774414, Training time:26426.149515628815
batch reward last col mean 0.6667371392250061 first col mean 0.6773188710212708 all mean 0.666936993598938
rl training, epoch1, iter0, batch806/1133, batch loss:0.40080976486206055, Training time:26453.379733085632
batch reward last col mean 0.6652873754501343 first col mean 0.6777932643890381 all mean 0.6657190918922424
rl training, epoch1, iter0, batch807/1133, batch loss:0.431694358587265, Training time:26480.388868808746
batch reward last col mean 0.6433136463165283 first col mean 0.6518951654434204 all mean 0.6435905694961548
rl training, epoch1, iter0, batch808/1133, batch loss:0.447373628616333, Training time:26507.56485915184
batch reward last col mean 0.6766087412834167 first col mean 0.6739101409912109 all mean 0.6768139004707336
rl training, epoch1, iter0, batch809/1133, batch loss:0.49996986985206604, Training time:26535.01770710945
batch reward last col mean 0.672555685043335 first col mean 0.6640603542327881 all mean 0.6724318861961365
rl training, epoch1, iter0, batch810/1133, batch loss:0.46825680136680603, Training time:26562.200998067856
batch reward last col mean 0.706203043460846 first col mean 0.7087710499763489 all mean 0.7064341306686401
rl training, epoch1, iter0, batch811/1133, batch loss:0.4037224054336548, Training time:26589.162582874298
batch reward last col mean 0.6748362183570862 first col mean 0.6700000762939453 all mean 0.6744881868362427
rl training, epoch1, iter0, batch812/1133, batch loss:0.46813565492630005, Training time:26616.077446699142
batch reward last col mean 0.6604461073875427 first col mean 0.6545922756195068 all mean 0.6601451635360718
rl training, epoch1, iter0, batch813/1133, batch loss:0.4384189248085022, Training time:26643.060010910034
batch reward last col mean 0.6788299083709717 first col mean 0.6922682523727417 all mean 0.6791713237762451
rl training, epoch1, iter0, batch814/1133, batch loss:0.39900073409080505, Training time:26670.329424381256
batch reward last col mean 0.6553845405578613 first col mean 0.6565508842468262 all mean 0.6555669903755188
rl training, epoch1, iter0, batch815/1133, batch loss:0.3239828646183014, Training time:26697.527240753174
batch reward last col mean 0.6854028701782227 first col mean 0.6732809543609619 all mean 0.6854451298713684
rl training, epoch1, iter0, batch816/1133, batch loss:0.41751784086227417, Training time:26724.551139593124
batch reward last col mean 0.6461382508277893 first col mean 0.6288754940032959 all mean 0.6463167071342468
rl training, epoch1, iter0, batch817/1133, batch loss:0.3760382831096649, Training time:26751.239998817444
batch reward last col mean 0.6697562336921692 first col mean 0.6830814480781555 all mean 0.6704754829406738
rl training, epoch1, iter0, batch818/1133, batch loss:0.39851173758506775, Training time:26778.286665201187
batch reward last col mean 0.6362993717193604 first col mean 0.647132933139801 all mean 0.6365898847579956
rl training, epoch1, iter0, batch819/1133, batch loss:0.32740044593811035, Training time:26805.464883565903
batch reward last col mean 0.6823115348815918 first col mean 0.6880937814712524 all mean 0.6823940873146057
rl training, epoch1, iter0, batch820/1133, batch loss:0.32720792293548584, Training time:26832.66660308838
batch reward last col mean 0.7011440396308899 first col mean 0.7072761654853821 all mean 0.7013838291168213
rl training, epoch1, iter0, batch821/1133, batch loss:0.3315260410308838, Training time:26859.827225208282
batch reward last col mean 0.670700192451477 first col mean 0.6500664949417114 all mean 0.6700965166091919
rl training, epoch1, iter0, batch822/1133, batch loss:0.3296186327934265, Training time:26886.970277309418
batch reward last col mean 0.6795555353164673 first col mean 0.6874099373817444 all mean 0.6800335049629211
rl training, epoch1, iter0, batch823/1133, batch loss:0.32633665204048157, Training time:26914.493916749954
batch reward last col mean 0.6741336584091187 first col mean 0.6701139211654663 all mean 0.6743170022964478
rl training, epoch1, iter0, batch824/1133, batch loss:0.35712963342666626, Training time:26942.10997581482
batch reward last col mean 0.7103523015975952 first col mean 0.7081020474433899 all mean 0.7102733850479126
rl training, epoch1, iter0, batch825/1133, batch loss:0.3762151896953583, Training time:26969.557106733322
batch reward last col mean 0.7053580284118652 first col mean 0.7100252509117126 all mean 0.7058248519897461
rl training, epoch1, iter0, batch826/1133, batch loss:0.35711607336997986, Training time:26996.877660751343
batch reward last col mean 0.6957966089248657 first col mean 0.7140981554985046 all mean 0.6962853670120239
rl training, epoch1, iter0, batch827/1133, batch loss:0.35665252804756165, Training time:27024.032376766205
batch reward last col mean 0.7283833622932434 first col mean 0.7232447862625122 all mean 0.7280833125114441
rl training, epoch1, iter0, batch828/1133, batch loss:0.4007742404937744, Training time:27051.29949784279
batch reward last col mean 0.7040818333625793 first col mean 0.694413423538208 all mean 0.7036459445953369
rl training, epoch1, iter0, batch829/1133, batch loss:0.35849541425704956, Training time:27078.672351121902
batch reward last col mean 0.7034570574760437 first col mean 0.7131705284118652 all mean 0.7039278745651245
rl training, epoch1, iter0, batch830/1133, batch loss:0.3376156687736511, Training time:27105.938407182693
batch reward last col mean 0.6830442547798157 first col mean 0.684952974319458 all mean 0.6830062866210938
rl training, epoch1, iter0, batch831/1133, batch loss:0.2946069538593292, Training time:27133.45987057686
batch reward last col mean 0.6757142543792725 first col mean 0.7027707099914551 all mean 0.6762111186981201
rl training, epoch1, iter0, batch832/1133, batch loss:0.35895034670829773, Training time:27160.869668245316
batch reward last col mean 0.7062662243843079 first col mean 0.6899665594100952 all mean 0.7059879302978516
rl training, epoch1, iter0, batch833/1133, batch loss:0.39502692222595215, Training time:27188.19809293747
batch reward last col mean 0.7041612267494202 first col mean 0.7139084339141846 all mean 0.7044817209243774
rl training, epoch1, iter0, batch834/1133, batch loss:0.3447723090648651, Training time:27215.751504421234
batch reward last col mean 0.6677752733230591 first col mean 0.6950717568397522 all mean 0.6685707569122314
rl training, epoch1, iter0, batch835/1133, batch loss:0.386654794216156, Training time:27242.86350250244
batch reward last col mean 0.6969619989395142 first col mean 0.6970872282981873 all mean 0.6968914270401001
rl training, epoch1, iter0, batch836/1133, batch loss:0.2778514325618744, Training time:27270.051777362823
batch reward last col mean 0.6506505012512207 first col mean 0.6771926283836365 all mean 0.6514493227005005
rl training, epoch1, iter0, batch837/1133, batch loss:0.34350451827049255, Training time:27297.333203554153
batch reward last col mean 0.6899113655090332 first col mean 0.6921663284301758 all mean 0.6900330185890198
rl training, epoch1, iter0, batch838/1133, batch loss:0.4026550352573395, Training time:27324.543511390686
batch reward last col mean 0.6792638897895813 first col mean 0.6880437135696411 all mean 0.6793226003646851
rl training, epoch1, iter0, batch839/1133, batch loss:0.34034284949302673, Training time:27351.80538201332
batch reward last col mean 0.6828002333641052 first col mean 0.6911615133285522 all mean 0.6830342411994934
rl training, epoch1, iter0, batch840/1133, batch loss:0.37448933720588684, Training time:27379.008430957794
batch reward last col mean 0.6982177495956421 first col mean 0.6925851106643677 all mean 0.6982342004776001
rl training, epoch1, iter0, batch841/1133, batch loss:0.3310776352882385, Training time:27406.201311588287
batch reward last col mean 0.6880802512168884 first col mean 0.688521146774292 all mean 0.6882465481758118
rl training, epoch1, iter0, batch842/1133, batch loss:0.38856881856918335, Training time:27433.37102675438
batch reward last col mean 0.6577850580215454 first col mean 0.6604570150375366 all mean 0.6576992869377136
rl training, epoch1, iter0, batch843/1133, batch loss:0.2988470494747162, Training time:27460.728307008743
batch reward last col mean 0.7234525084495544 first col mean 0.7148836851119995 all mean 0.7233631014823914
rl training, epoch1, iter0, batch844/1133, batch loss:0.4306666851043701, Training time:27488.075874328613
batch reward last col mean 0.644108235836029 first col mean 0.6433479189872742 all mean 0.6443997025489807
rl training, epoch1, iter0, batch845/1133, batch loss:0.34218794107437134, Training time:27515.482489347458
batch reward last col mean 0.6828190088272095 first col mean 0.6930828094482422 all mean 0.6827981472015381
rl training, epoch1, iter0, batch846/1133, batch loss:0.3242203891277313, Training time:27542.824113607407
batch reward last col mean 0.7156364321708679 first col mean 0.6992520689964294 all mean 0.7153449654579163
rl training, epoch1, iter0, batch847/1133, batch loss:0.31644248962402344, Training time:27570.04191684723
batch reward last col mean 0.7014148831367493 first col mean 0.6963173747062683 all mean 0.7013307809829712
rl training, epoch1, iter0, batch848/1133, batch loss:0.3443717360496521, Training time:27597.31086421013
batch reward last col mean 0.691585898399353 first col mean 0.6755249500274658 all mean 0.691287100315094
rl training, epoch1, iter0, batch849/1133, batch loss:0.4216833710670471, Training time:27624.854591846466
batch reward last col mean 0.6924771666526794 first col mean 0.6946484446525574 all mean 0.6925504803657532
rl training, epoch1, iter0, batch850/1133, batch loss:0.3465474545955658, Training time:27652.151179790497
batch reward last col mean 0.7091587781906128 first col mean 0.7055130004882812 all mean 0.7093347311019897
rl training, epoch1, iter0, batch851/1133, batch loss:0.2983874976634979, Training time:27679.390570640564
batch reward last col mean 0.7329355478286743 first col mean 0.7280667424201965 all mean 0.7325881719589233
rl training, epoch1, iter0, batch852/1133, batch loss:0.4899427890777588, Training time:27706.37003469467
batch reward last col mean 0.7226690053939819 first col mean 0.7317104339599609 all mean 0.7227848768234253
rl training, epoch1, iter0, batch853/1133, batch loss:0.3162623941898346, Training time:27733.738755702972
batch reward last col mean 0.7363592386245728 first col mean 0.7441600561141968 all mean 0.7367343902587891
rl training, epoch1, iter0, batch854/1133, batch loss:0.3327469229698181, Training time:27760.978985071182
batch reward last col mean 0.6543593406677246 first col mean 0.6615593433380127 all mean 0.6547520160675049
rl training, epoch1, iter0, batch855/1133, batch loss:0.3672473430633545, Training time:27788.202548980713
batch reward last col mean 0.7091701626777649 first col mean 0.6951813697814941 all mean 0.7090401649475098
rl training, epoch1, iter0, batch856/1133, batch loss:0.41936346888542175, Training time:27815.344031333923
batch reward last col mean 0.7175381183624268 first col mean 0.7252993583679199 all mean 0.7174479961395264
rl training, epoch1, iter0, batch857/1133, batch loss:0.5110089182853699, Training time:27842.588585615158
batch reward last col mean 0.6531603336334229 first col mean 0.6666229963302612 all mean 0.6531541347503662
rl training, epoch1, iter0, batch858/1133, batch loss:0.37622013688087463, Training time:27869.865936756134
batch reward last col mean 0.7036194205284119 first col mean 0.7146360874176025 all mean 0.7038567066192627
rl training, epoch1, iter0, batch859/1133, batch loss:0.3982335329055786, Training time:27897.205317258835
batch reward last col mean 0.677770733833313 first col mean 0.6892364621162415 all mean 0.6779223084449768
rl training, epoch1, iter0, batch860/1133, batch loss:0.4650209844112396, Training time:27924.379737377167
batch reward last col mean 0.6887274980545044 first col mean 0.7130812406539917 all mean 0.6892186999320984
rl training, epoch1, iter0, batch861/1133, batch loss:0.3698098957538605, Training time:27951.625029563904
batch reward last col mean 0.674817681312561 first col mean 0.6603927612304688 all mean 0.6743885278701782
rl training, epoch1, iter0, batch862/1133, batch loss:0.43772780895233154, Training time:27978.58651137352
batch reward last col mean 0.6770153045654297 first col mean 0.6651067137718201 all mean 0.6766836047172546
rl training, epoch1, iter0, batch863/1133, batch loss:0.35473379492759705, Training time:28005.52467441559
batch reward last col mean 0.7303556799888611 first col mean 0.7241647243499756 all mean 0.7303216457366943
rl training, epoch1, iter0, batch864/1133, batch loss:0.4622904062271118, Training time:28032.65763735771
batch reward last col mean 0.714694082736969 first col mean 0.7000880241394043 all mean 0.7145019769668579
rl training, epoch1, iter0, batch865/1133, batch loss:0.4382922351360321, Training time:28060.009266614914
batch reward last col mean 0.7224441170692444 first col mean 0.721640944480896 all mean 0.7223478555679321
rl training, epoch1, iter0, batch866/1133, batch loss:0.4526960551738739, Training time:28087.131365299225
batch reward last col mean 0.7054033279418945 first col mean 0.7125223278999329 all mean 0.7056356072425842
rl training, epoch1, iter0, batch867/1133, batch loss:0.4310651421546936, Training time:28114.22751069069
batch reward last col mean 0.7035819292068481 first col mean 0.6977472305297852 all mean 0.7037526369094849
rl training, epoch1, iter0, batch868/1133, batch loss:0.44538432359695435, Training time:28141.48654603958
batch reward last col mean 0.7095099687576294 first col mean 0.7130399942398071 all mean 0.7097023725509644
rl training, epoch1, iter0, batch869/1133, batch loss:0.4198046028614044, Training time:28168.971360206604
batch reward last col mean 0.6907047629356384 first col mean 0.6963542103767395 all mean 0.6908179521560669
rl training, epoch1, iter0, batch870/1133, batch loss:0.4771344065666199, Training time:28196.398684978485
batch reward last col mean 0.7432647347450256 first col mean 0.736997663974762 all mean 0.7431641221046448
rl training, epoch1, iter0, batch871/1133, batch loss:0.452472448348999, Training time:28223.61331677437
batch reward last col mean 0.7299010753631592 first col mean 0.7297846078872681 all mean 0.730040431022644
rl training, epoch1, iter0, batch872/1133, batch loss:0.44294553995132446, Training time:28250.702001571655
batch reward last col mean 0.6940901279449463 first col mean 0.713283121585846 all mean 0.6943178772926331
rl training, epoch1, iter0, batch873/1133, batch loss:0.5197880864143372, Training time:28277.98700761795
batch reward last col mean 0.677210807800293 first col mean 0.6847293972969055 all mean 0.6774522662162781
rl training, epoch1, iter0, batch874/1133, batch loss:0.4525863528251648, Training time:28305.480224847794
batch reward last col mean 0.6939731240272522 first col mean 0.706128716468811 all mean 0.694145917892456
rl training, epoch1, iter0, batch875/1133, batch loss:0.3308464586734772, Training time:28332.82164311409
batch reward last col mean 0.6764917969703674 first col mean 0.6874310374259949 all mean 0.6765324473381042
rl training, epoch1, iter0, batch876/1133, batch loss:0.3529272675514221, Training time:28360.38647556305
batch reward last col mean 0.6790123581886292 first col mean 0.6749045848846436 all mean 0.6790316700935364
rl training, epoch1, iter0, batch877/1133, batch loss:0.4555107355117798, Training time:28387.632344961166
batch reward last col mean 0.7065464854240417 first col mean 0.7221407890319824 all mean 0.7069411873817444
rl training, epoch1, iter0, batch878/1133, batch loss:0.3771075904369354, Training time:28414.930933475494
batch reward last col mean 0.6741834878921509 first col mean 0.6812760233879089 all mean 0.6743621826171875
rl training, epoch1, iter0, batch879/1133, batch loss:0.44338640570640564, Training time:28441.965706825256
batch reward last col mean 0.7066676616668701 first col mean 0.6883945465087891 all mean 0.7063235640525818
rl training, epoch1, iter0, batch880/1133, batch loss:0.4259829819202423, Training time:28469.149617671967
batch reward last col mean 0.676226019859314 first col mean 0.6888700723648071 all mean 0.676250159740448
rl training, epoch1, iter0, batch881/1133, batch loss:0.43903863430023193, Training time:28496.427332878113
batch reward last col mean 0.7433742880821228 first col mean 0.7333343029022217 all mean 0.7430319786071777
rl training, epoch1, iter0, batch882/1133, batch loss:0.45557937026023865, Training time:28523.642993211746
batch reward last col mean 0.6803923845291138 first col mean 0.6848647594451904 all mean 0.6805583238601685
rl training, epoch1, iter0, batch883/1133, batch loss:0.5356494784355164, Training time:28550.97923231125
batch reward last col mean 0.6923938989639282 first col mean 0.6923011541366577 all mean 0.6924140453338623
rl training, epoch1, iter0, batch884/1133, batch loss:0.4974278509616852, Training time:28578.30610346794
batch reward last col mean 0.7037278413772583 first col mean 0.6943643093109131 all mean 0.7035975456237793
rl training, epoch1, iter0, batch885/1133, batch loss:0.48416629433631897, Training time:28605.928434610367
batch reward last col mean 0.679046630859375 first col mean 0.6747020483016968 all mean 0.6789911389350891
rl training, epoch1, iter0, batch886/1133, batch loss:0.4278537631034851, Training time:28633.074818134308
batch reward last col mean 0.7096100449562073 first col mean 0.7143917083740234 all mean 0.709919810295105
rl training, epoch1, iter0, batch887/1133, batch loss:0.5344905853271484, Training time:28660.395088911057
batch reward last col mean 0.6520527601242065 first col mean 0.6958808898925781 all mean 0.6530444025993347
rl training, epoch1, iter0, batch888/1133, batch loss:0.4353812634944916, Training time:28687.692535161972
batch reward last col mean 0.6739516854286194 first col mean 0.6918264031410217 all mean 0.6738952398300171
rl training, epoch1, iter0, batch889/1133, batch loss:0.5407386422157288, Training time:28714.807786226273
batch reward last col mean 0.7323054075241089 first col mean 0.7452676892280579 all mean 0.7326884269714355
rl training, epoch1, iter0, batch890/1133, batch loss:0.5015615820884705, Training time:28741.955522298813
batch reward last col mean 0.6768863201141357 first col mean 0.6716652512550354 all mean 0.6767891049385071
rl training, epoch1, iter0, batch891/1133, batch loss:0.4967082738876343, Training time:28769.52886366844
batch reward last col mean 0.6797565817832947 first col mean 0.6995717287063599 all mean 0.6803017854690552
rl training, epoch1, iter0, batch892/1133, batch loss:0.5726086497306824, Training time:28796.701377868652
batch reward last col mean 0.6861914992332458 first col mean 0.661434531211853 all mean 0.6855165362358093
rl training, epoch1, iter0, batch893/1133, batch loss:0.588311493396759, Training time:28824.296299934387
batch reward last col mean 0.6422033309936523 first col mean 0.6339071393013 all mean 0.6420977711677551
rl training, epoch1, iter0, batch894/1133, batch loss:0.5286550521850586, Training time:28851.887385845184
batch reward last col mean 0.6747807264328003 first col mean 0.6879125833511353 all mean 0.6750243306159973
rl training, epoch1, iter0, batch895/1133, batch loss:0.43310701847076416, Training time:28878.97966146469
batch reward last col mean 0.6886546611785889 first col mean 0.687328577041626 all mean 0.6885591745376587
rl training, epoch1, iter0, batch896/1133, batch loss:0.6228700876235962, Training time:28906.196933031082
batch reward last col mean 0.6993593573570251 first col mean 0.7028622031211853 all mean 0.699560284614563
rl training, epoch1, iter0, batch897/1133, batch loss:0.6329219341278076, Training time:28933.105932235718
batch reward last col mean 0.6809332370758057 first col mean 0.6791476607322693 all mean 0.6810160875320435
rl training, epoch1, iter0, batch898/1133, batch loss:0.5822223424911499, Training time:28960.287396907806
batch reward last col mean 0.6336204409599304 first col mean 0.652626097202301 all mean 0.6341257095336914
rl training, epoch1, iter0, batch899/1133, batch loss:0.6045559048652649, Training time:28988.30965065956
batch reward last col mean 0.7014303207397461 first col mean 0.7022302150726318 all mean 0.701781690120697
rl training, epoch1, iter0, batch900/1133, batch loss:0.5591567754745483, Training time:29015.521245718002
batch reward last col mean 0.6727418899536133 first col mean 0.6709455847740173 all mean 0.6725953221321106
rl training, epoch1, iter0, batch901/1133, batch loss:0.4974164664745331, Training time:29042.79315853119
batch reward last col mean 0.6757373213768005 first col mean 0.6795111894607544 all mean 0.6755075454711914
rl training, epoch1, iter0, batch902/1133, batch loss:0.5841193199157715, Training time:29070.00357222557
batch reward last col mean 0.665569007396698 first col mean 0.659834623336792 all mean 0.6656991243362427
rl training, epoch1, iter0, batch903/1133, batch loss:0.5356950759887695, Training time:29097.419814825058
batch reward last col mean 0.6778241395950317 first col mean 0.6703026294708252 all mean 0.6776307821273804
rl training, epoch1, iter0, batch904/1133, batch loss:0.5136731863021851, Training time:29124.70563530922
batch reward last col mean 0.688616156578064 first col mean 0.6983946561813354 all mean 0.6890537142753601
rl training, epoch1, iter0, batch905/1133, batch loss:0.5513281226158142, Training time:29151.905669927597
batch reward last col mean 0.6568396091461182 first col mean 0.6435588002204895 all mean 0.656714677810669
rl training, epoch1, iter0, batch906/1133, batch loss:0.5085257291793823, Training time:29179.244601249695
batch reward last col mean 0.7017358541488647 first col mean 0.7088450193405151 all mean 0.7016714215278625
rl training, epoch1, iter0, batch907/1133, batch loss:0.5100243091583252, Training time:29206.902054071426
batch reward last col mean 0.6776279807090759 first col mean 0.6784775257110596 all mean 0.6777490973472595
rl training, epoch1, iter0, batch908/1133, batch loss:0.4846958816051483, Training time:29234.52680873871
batch reward last col mean 0.6845434904098511 first col mean 0.6629893779754639 all mean 0.6835146546363831
rl training, epoch1, iter0, batch909/1133, batch loss:0.45490676164627075, Training time:29262.35549712181
batch reward last col mean 0.6780935525894165 first col mean 0.68988037109375 all mean 0.6781153082847595
rl training, epoch1, iter0, batch910/1133, batch loss:0.4363652467727661, Training time:29290.313214063644
batch reward last col mean 0.6175342202186584 first col mean 0.6124922037124634 all mean 0.6177352070808411
rl training, epoch1, iter0, batch911/1133, batch loss:0.4382840096950531, Training time:29317.975492954254
batch reward last col mean 0.653262197971344 first col mean 0.6604914665222168 all mean 0.6528226137161255
rl training, epoch1, iter0, batch912/1133, batch loss:0.43812406063079834, Training time:29345.667300224304
batch reward last col mean 0.6923657059669495 first col mean 0.6872560381889343 all mean 0.6903210282325745
rl training, epoch1, iter0, batch913/1133, batch loss:0.3487909138202667, Training time:29374.051628112793
batch reward last col mean 0.6823703050613403 first col mean 0.6751660704612732 all mean 0.6817715764045715
rl training, epoch1, iter0, batch914/1133, batch loss:0.40693721175193787, Training time:29401.982858657837
batch reward last col mean 0.6666349172592163 first col mean 0.6989474296569824 all mean 0.6674103140830994
rl training, epoch1, iter0, batch915/1133, batch loss:0.3143406808376312, Training time:29429.88137292862
batch reward last col mean 0.6785688400268555 first col mean 0.679240882396698 all mean 0.6778267025947571
rl training, epoch1, iter0, batch916/1133, batch loss:0.4012771546840668, Training time:29457.50867819786
batch reward last col mean 0.6619120836257935 first col mean 0.652744710445404 all mean 0.6621204614639282
rl training, epoch1, iter0, batch917/1133, batch loss:0.4575142562389374, Training time:29485.1578912735
batch reward last col mean 0.7016081809997559 first col mean 0.6958839297294617 all mean 0.701320469379425
rl training, epoch1, iter0, batch918/1133, batch loss:0.46745961904525757, Training time:29512.715125322342
batch reward last col mean 0.6982564926147461 first col mean 0.6710411310195923 all mean 0.6973658204078674
rl training, epoch1, iter0, batch919/1133, batch loss:0.4823521673679352, Training time:29540.489459753036
batch reward last col mean 0.6791471242904663 first col mean 0.6718531250953674 all mean 0.6791850328445435
rl training, epoch1, iter0, batch920/1133, batch loss:0.45420363545417786, Training time:29568.075905561447
batch reward last col mean 0.6824414730072021 first col mean 0.6687246561050415 all mean 0.6823641061782837
rl training, epoch1, iter0, batch921/1133, batch loss:0.45220252871513367, Training time:29596.21340250969
batch reward last col mean 0.713721752166748 first col mean 0.7197453379631042 all mean 0.7137746214866638
rl training, epoch1, iter0, batch922/1133, batch loss:0.45695996284484863, Training time:29623.481040477753
batch reward last col mean 0.7016208171844482 first col mean 0.7104765176773071 all mean 0.701812744140625
rl training, epoch1, iter0, batch923/1133, batch loss:0.5690027475357056, Training time:29650.829612493515
batch reward last col mean 0.713155210018158 first col mean 0.7165535688400269 all mean 0.7130466103553772
rl training, epoch1, iter0, batch924/1133, batch loss:0.5348975658416748, Training time:29678.156539440155
batch reward last col mean 0.7253135442733765 first col mean 0.7027167081832886 all mean 0.7257256507873535
rl training, epoch1, iter0, batch925/1133, batch loss:0.5129289031028748, Training time:29705.67094874382
batch reward last col mean 0.6902218461036682 first col mean 0.7018236517906189 all mean 0.6900696158409119
rl training, epoch1, iter0, batch926/1133, batch loss:0.45118752121925354, Training time:29732.95378470421
batch reward last col mean 0.6792747378349304 first col mean 0.6734656095504761 all mean 0.6786927580833435
rl training, epoch1, iter0, batch927/1133, batch loss:0.432186096906662, Training time:29760.39638543129
batch reward last col mean 0.6404386758804321 first col mean 0.661324143409729 all mean 0.6409856081008911
rl training, epoch1, iter0, batch928/1133, batch loss:0.44016727805137634, Training time:29787.57430934906
batch reward last col mean 0.6881701946258545 first col mean 0.7033361196517944 all mean 0.6886200308799744
rl training, epoch1, iter0, batch929/1133, batch loss:0.508251428604126, Training time:29814.848874092102
batch reward last col mean 0.7047315239906311 first col mean 0.7019878625869751 all mean 0.7047458291053772
rl training, epoch1, iter0, batch930/1133, batch loss:0.5266456604003906, Training time:29842.130568027496
batch reward last col mean 0.7542490363121033 first col mean 0.7301933169364929 all mean 0.7537416219711304
rl training, epoch1, iter0, batch931/1133, batch loss:0.5607823133468628, Training time:29869.319012880325
batch reward last col mean 0.6909072399139404 first col mean 0.6985608339309692 all mean 0.6912679672241211
rl training, epoch1, iter0, batch932/1133, batch loss:0.5499387383460999, Training time:29896.902490854263
batch reward last col mean 0.6568375825881958 first col mean 0.661764919757843 all mean 0.65753173828125
rl training, epoch1, iter0, batch933/1133, batch loss:0.5536185503005981, Training time:29924.237666130066
batch reward last col mean 0.7574678659439087 first col mean 0.7299471497535706 all mean 0.7563002109527588
rl training, epoch1, iter0, batch934/1133, batch loss:0.6011992692947388, Training time:29951.52807354927
batch reward last col mean 0.7079657912254333 first col mean 0.6993956565856934 all mean 0.7073819637298584
rl training, epoch1, iter0, batch935/1133, batch loss:0.49509987235069275, Training time:29978.96356034279
batch reward last col mean 0.6779677867889404 first col mean 0.6750585436820984 all mean 0.6782258749008179
rl training, epoch1, iter0, batch936/1133, batch loss:0.5504398941993713, Training time:30006.33969950676
batch reward last col mean 0.6338247060775757 first col mean 0.6523908376693726 all mean 0.6344325542449951
rl training, epoch1, iter0, batch937/1133, batch loss:0.5407195687294006, Training time:30033.316577911377
batch reward last col mean 0.6988223791122437 first col mean 0.6903845071792603 all mean 0.6990993022918701
rl training, epoch1, iter0, batch938/1133, batch loss:0.5926554203033447, Training time:30060.517578840256
batch reward last col mean 0.6245248317718506 first col mean 0.631781280040741 all mean 0.6250646710395813
rl training, epoch1, iter0, batch939/1133, batch loss:0.5722351670265198, Training time:30087.914155244827
batch reward last col mean 0.6475155353546143 first col mean 0.6503374576568604 all mean 0.6477246284484863
rl training, epoch1, iter0, batch940/1133, batch loss:0.5525493025779724, Training time:30115.20442223549
batch reward last col mean 0.6690009832382202 first col mean 0.6721540689468384 all mean 0.668668806552887
rl training, epoch1, iter0, batch941/1133, batch loss:0.4700303375720978, Training time:30142.411818027496
batch reward last col mean 0.6273478269577026 first col mean 0.6438994407653809 all mean 0.6281133890151978
rl training, epoch1, iter0, batch942/1133, batch loss:0.5394800901412964, Training time:30169.418430566788
batch reward last col mean 0.6517525911331177 first col mean 0.6854027509689331 all mean 0.6522142887115479
rl training, epoch1, iter0, batch943/1133, batch loss:0.5466731190681458, Training time:30196.62518978119
batch reward last col mean 0.718974232673645 first col mean 0.7242296934127808 all mean 0.719721794128418
rl training, epoch1, iter0, batch944/1133, batch loss:0.5509816408157349, Training time:30224.34810590744
batch reward last col mean 0.6726493835449219 first col mean 0.6813029050827026 all mean 0.6729822754859924
rl training, epoch1, iter0, batch945/1133, batch loss:0.531642496585846, Training time:30251.52537035942
batch reward last col mean 0.6938654184341431 first col mean 0.697360634803772 all mean 0.6939902305603027
rl training, epoch1, iter0, batch946/1133, batch loss:0.5063222646713257, Training time:30278.727709770203
batch reward last col mean 0.6711093783378601 first col mean 0.6823855042457581 all mean 0.6715126633644104
rl training, epoch1, iter0, batch947/1133, batch loss:0.5273207426071167, Training time:30305.96405148506
batch reward last col mean 0.7404395341873169 first col mean 0.7246271371841431 all mean 0.7397220730781555
rl training, epoch1, iter0, batch948/1133, batch loss:0.5884316563606262, Training time:30333.148966550827
batch reward last col mean 0.6756304502487183 first col mean 0.6744486689567566 all mean 0.6753054261207581
rl training, epoch1, iter0, batch949/1133, batch loss:0.48781993985176086, Training time:30360.734447956085
batch reward last col mean 0.6886273622512817 first col mean 0.6732921600341797 all mean 0.6880537867546082
rl training, epoch1, iter0, batch950/1133, batch loss:0.541337788105011, Training time:30387.98306465149
batch reward last col mean 0.7068321704864502 first col mean 0.7189205884933472 all mean 0.707362174987793
rl training, epoch1, iter0, batch951/1133, batch loss:0.508014440536499, Training time:30415.148880004883
batch reward last col mean 0.6722187995910645 first col mean 0.691551923751831 all mean 0.6727907657623291
rl training, epoch1, iter0, batch952/1133, batch loss:0.6103391051292419, Training time:30442.569130182266
batch reward last col mean 0.6696076989173889 first col mean 0.6603251695632935 all mean 0.6695590019226074
rl training, epoch1, iter0, batch953/1133, batch loss:0.5541055798530579, Training time:30469.909809350967
batch reward last col mean 0.681674599647522 first col mean 0.7018148303031921 all mean 0.6817172169685364
rl training, epoch1, iter0, batch954/1133, batch loss:0.5262845158576965, Training time:30497.256182670593
batch reward last col mean 0.7547022104263306 first col mean 0.7363231182098389 all mean 0.754513144493103
rl training, epoch1, iter0, batch955/1133, batch loss:0.5756611227989197, Training time:30524.407056331635
batch reward last col mean 0.7067925930023193 first col mean 0.6958687901496887 all mean 0.7065761089324951
rl training, epoch1, iter0, batch956/1133, batch loss:0.5368151664733887, Training time:30551.60677599907
batch reward last col mean 0.6211587190628052 first col mean 0.6284935474395752 all mean 0.6211294531822205
rl training, epoch1, iter0, batch957/1133, batch loss:0.4570935368537903, Training time:30578.760709524155
batch reward last col mean 0.7059141397476196 first col mean 0.6961252689361572 all mean 0.7059199213981628
rl training, epoch1, iter0, batch958/1133, batch loss:0.5838093161582947, Training time:30605.833121538162
batch reward last col mean 0.6834482550621033 first col mean 0.6883874535560608 all mean 0.6835083365440369
rl training, epoch1, iter0, batch959/1133, batch loss:0.5465381145477295, Training time:30633.148052453995
batch reward last col mean 0.6863623857498169 first col mean 0.6861882209777832 all mean 0.6862567663192749
rl training, epoch1, iter0, batch960/1133, batch loss:0.5830600261688232, Training time:30660.370594501495
batch reward last col mean 0.7087441682815552 first col mean 0.7317003607749939 all mean 0.7091085314750671
rl training, epoch1, iter0, batch961/1133, batch loss:0.4493075907230377, Training time:30687.647190332413
batch reward last col mean 0.7166532278060913 first col mean 0.7203848361968994 all mean 0.7163822650909424
rl training, epoch1, iter0, batch962/1133, batch loss:0.4535365402698517, Training time:30714.852796316147
batch reward last col mean 0.693780243396759 first col mean 0.6936075687408447 all mean 0.6931770443916321
rl training, epoch1, iter0, batch963/1133, batch loss:0.47527405619621277, Training time:30741.98681497574
batch reward last col mean 0.72489333152771 first col mean 0.7102541327476501 all mean 0.7243725061416626
rl training, epoch1, iter0, batch964/1133, batch loss:0.43459513783454895, Training time:30769.39483475685
batch reward last col mean 0.7023805379867554 first col mean 0.7082621455192566 all mean 0.7026486396789551
rl training, epoch1, iter0, batch965/1133, batch loss:0.43532848358154297, Training time:30796.762937784195
batch reward last col mean 0.6752498149871826 first col mean 0.6906206607818604 all mean 0.6757280826568604
rl training, epoch1, iter0, batch966/1133, batch loss:0.4542526304721832, Training time:30823.898921966553
batch reward last col mean 0.731675386428833 first col mean 0.7292130589485168 all mean 0.7316129803657532
rl training, epoch1, iter0, batch967/1133, batch loss:0.37752795219421387, Training time:30851.11362886429
batch reward last col mean 0.7307226061820984 first col mean 0.7208240628242493 all mean 0.7301751375198364
rl training, epoch1, iter0, batch968/1133, batch loss:0.43151360750198364, Training time:30878.38348841667
batch reward last col mean 0.7596359848976135 first col mean 0.7521853446960449 all mean 0.7596787214279175
rl training, epoch1, iter0, batch969/1133, batch loss:0.5153665542602539, Training time:30905.56655907631
batch reward last col mean 0.6749509572982788 first col mean 0.6819934844970703 all mean 0.6751224994659424
rl training, epoch1, iter0, batch970/1133, batch loss:0.5094070434570312, Training time:30932.939314365387
batch reward last col mean 0.7281413674354553 first col mean 0.7373948097229004 all mean 0.7283545732498169
rl training, epoch1, iter0, batch971/1133, batch loss:0.4401163160800934, Training time:30960.25825381279
batch reward last col mean 0.7001304030418396 first col mean 0.716985821723938 all mean 0.7007445693016052
rl training, epoch1, iter0, batch972/1133, batch loss:0.46679848432540894, Training time:30987.802936315536
batch reward last col mean 0.7208247184753418 first col mean 0.7145163416862488 all mean 0.7200617790222168
rl training, epoch1, iter0, batch973/1133, batch loss:0.4624868631362915, Training time:31015.23266839981
batch reward last col mean 0.727898359298706 first col mean 0.7275997400283813 all mean 0.7280877828598022
rl training, epoch1, iter0, batch974/1133, batch loss:0.426213800907135, Training time:31043.07792377472
batch reward last col mean 0.6992822289466858 first col mean 0.7067714929580688 all mean 0.6996309161186218
rl training, epoch1, iter0, batch975/1133, batch loss:0.4709654152393341, Training time:31070.703255414963
batch reward last col mean 0.7076666951179504 first col mean 0.7185585498809814 all mean 0.7082273960113525
rl training, epoch1, iter0, batch976/1133, batch loss:0.43758514523506165, Training time:31097.788980722427
batch reward last col mean 0.7275128364562988 first col mean 0.6966915130615234 all mean 0.7267829179763794
rl training, epoch1, iter0, batch977/1133, batch loss:0.47651103138923645, Training time:31124.920247077942
batch reward last col mean 0.7410298585891724 first col mean 0.7353199124336243 all mean 0.7402976155281067
rl training, epoch1, iter0, batch978/1133, batch loss:0.5102216005325317, Training time:31152.02346944809
batch reward last col mean 0.7004483342170715 first col mean 0.6980370283126831 all mean 0.7006982564926147
rl training, epoch1, iter0, batch979/1133, batch loss:0.4306051433086395, Training time:31179.289665937424
batch reward last col mean 0.711569607257843 first col mean 0.7189338207244873 all mean 0.7119240760803223
rl training, epoch1, iter0, batch980/1133, batch loss:0.4939437210559845, Training time:31207.0009701252
batch reward last col mean 0.7196915745735168 first col mean 0.726050853729248 all mean 0.7204132080078125
rl training, epoch1, iter0, batch981/1133, batch loss:0.5460460782051086, Training time:31234.41445374489
batch reward last col mean 0.7302455902099609 first col mean 0.7199206948280334 all mean 0.7301466464996338
rl training, epoch1, iter0, batch982/1133, batch loss:0.4997553527355194, Training time:31261.7663025856
batch reward last col mean 0.7338283658027649 first col mean 0.7401025891304016 all mean 0.7339175343513489
rl training, epoch1, iter0, batch983/1133, batch loss:0.5908144116401672, Training time:31288.904653310776
batch reward last col mean 0.6951853036880493 first col mean 0.7103323340415955 all mean 0.6954438090324402
rl training, epoch1, iter0, batch984/1133, batch loss:0.49996626377105713, Training time:31316.099765062332
batch reward last col mean 0.7250220775604248 first col mean 0.753395140171051 all mean 0.7253918647766113
rl training, epoch1, iter0, batch985/1133, batch loss:0.489707350730896, Training time:31343.618982315063
batch reward last col mean 0.7340381145477295 first col mean 0.72675621509552 all mean 0.7342316508293152
rl training, epoch1, iter0, batch986/1133, batch loss:0.6220627427101135, Training time:31370.607783317566
batch reward last col mean 0.732161819934845 first col mean 0.7164169549942017 all mean 0.7321116924285889
rl training, epoch1, iter0, batch987/1133, batch loss:0.6056087017059326, Training time:31397.846443891525
batch reward last col mean 0.7151696085929871 first col mean 0.7088111042976379 all mean 0.715046763420105
rl training, epoch1, iter0, batch988/1133, batch loss:0.6681032180786133, Training time:31425.152127742767
batch reward last col mean 0.7413115501403809 first col mean 0.7389640808105469 all mean 0.7407103180885315
rl training, epoch1, iter0, batch989/1133, batch loss:0.6529856324195862, Training time:31452.196094751358
batch reward last col mean 0.7014206051826477 first col mean 0.716646671295166 all mean 0.7016982436180115
rl training, epoch1, iter0, batch990/1133, batch loss:0.569833517074585, Training time:31479.36818265915
batch reward last col mean 0.7357510328292847 first col mean 0.7330975532531738 all mean 0.7358405590057373
rl training, epoch1, iter0, batch991/1133, batch loss:0.5687475800514221, Training time:31506.562293291092
batch reward last col mean 0.7243508100509644 first col mean 0.7314169406890869 all mean 0.7242321968078613
rl training, epoch1, iter0, batch992/1133, batch loss:0.6011992692947388, Training time:31533.584628582
batch reward last col mean 0.72447669506073 first col mean 0.7417808175086975 all mean 0.7249977588653564
rl training, epoch1, iter0, batch993/1133, batch loss:0.6178581714630127, Training time:31560.6347990036
batch reward last col mean 0.7332132458686829 first col mean 0.7198216915130615 all mean 0.7327350378036499
rl training, epoch1, iter0, batch994/1133, batch loss:0.6250185370445251, Training time:31587.558877706528
batch reward last col mean 0.6827515363693237 first col mean 0.6846337914466858 all mean 0.6829720139503479
rl training, epoch1, iter0, batch995/1133, batch loss:0.5049681663513184, Training time:31614.624010324478
batch reward last col mean 0.7657976746559143 first col mean 0.7371120452880859 all mean 0.76482754945755
rl training, epoch1, iter0, batch996/1133, batch loss:0.5537121295928955, Training time:31641.893961906433
batch reward last col mean 0.7385697364807129 first col mean 0.7557291388511658 all mean 0.7396642565727234
rl training, epoch1, iter0, batch997/1133, batch loss:0.6520801782608032, Training time:31668.727148771286
batch reward last col mean 0.7159408926963806 first col mean 0.7172871828079224 all mean 0.7159662842750549
rl training, epoch1, iter0, batch998/1133, batch loss:0.5936738848686218, Training time:31695.71408557892
batch reward last col mean 0.711249589920044 first col mean 0.6882787942886353 all mean 0.7106862664222717
rl training, epoch1, iter0, batch999/1133, batch loss:0.5743127465248108, Training time:31722.554701328278
batch reward last col mean 0.7443681955337524 first col mean 0.7590676546096802 all mean 0.7446512579917908
rl training, epoch1, iter0, batch1000/1133, batch loss:0.5652750134468079, Training time:31749.605251312256
batch reward last col mean 0.7714799046516418 first col mean 0.7548695206642151 all mean 0.7714506387710571
rl training, epoch1, iter0, batch1001/1133, batch loss:0.5954562425613403, Training time:31776.660807609558
batch reward last col mean 0.7164701819419861 first col mean 0.7311926484107971 all mean 0.7164289951324463
rl training, epoch1, iter0, batch1002/1133, batch loss:0.5766052603721619, Training time:31803.414618968964
batch reward last col mean 0.6708964109420776 first col mean 0.7040799856185913 all mean 0.6719042658805847
rl training, epoch1, iter0, batch1003/1133, batch loss:0.583855152130127, Training time:31830.586651086807
batch reward last col mean 0.7071309685707092 first col mean 0.7068127393722534 all mean 0.7070138454437256
rl training, epoch1, iter0, batch1004/1133, batch loss:0.5302019715309143, Training time:31857.594766139984
batch reward last col mean 0.7720417380332947 first col mean 0.746873676776886 all mean 0.771294116973877
rl training, epoch1, iter0, batch1005/1133, batch loss:0.560697078704834, Training time:31884.514449596405
batch reward last col mean 0.7135716080665588 first col mean 0.7149534225463867 all mean 0.7133710980415344
rl training, epoch1, iter0, batch1006/1133, batch loss:0.5727024674415588, Training time:31911.71874165535
batch reward last col mean 0.6655097007751465 first col mean 0.679685652256012 all mean 0.6662479043006897
rl training, epoch1, iter0, batch1007/1133, batch loss:0.5975838303565979, Training time:31938.627700328827
batch reward last col mean 0.7048062682151794 first col mean 0.6982606649398804 all mean 0.7043875455856323
rl training, epoch1, iter0, batch1008/1133, batch loss:0.5192886590957642, Training time:31965.73827624321
batch reward last col mean 0.7147581577301025 first col mean 0.7273051738739014 all mean 0.7153763175010681
rl training, epoch1, iter0, batch1009/1133, batch loss:0.5825393199920654, Training time:31993.057946920395
batch reward last col mean 0.6710659861564636 first col mean 0.6894505620002747 all mean 0.6718421578407288
rl training, epoch1, iter0, batch1010/1133, batch loss:0.5761863589286804, Training time:32020.34915947914
batch reward last col mean 0.7440192103385925 first col mean 0.7520278692245483 all mean 0.7441506385803223
rl training, epoch1, iter0, batch1011/1133, batch loss:0.5667003989219666, Training time:32047.595512866974
batch reward last col mean 0.724146842956543 first col mean 0.7215642929077148 all mean 0.7240449786186218
rl training, epoch1, iter0, batch1012/1133, batch loss:0.541344940662384, Training time:32074.627334833145
batch reward last col mean 0.7328730821609497 first col mean 0.7372097373008728 all mean 0.7333215475082397
rl training, epoch1, iter0, batch1013/1133, batch loss:0.7206161022186279, Training time:32102.013642311096
batch reward last col mean 0.718086838722229 first col mean 0.7252997159957886 all mean 0.718348503112793
rl training, epoch1, iter0, batch1014/1133, batch loss:0.6509214639663696, Training time:32129.29798603058
batch reward last col mean 0.676615297794342 first col mean 0.6629370450973511 all mean 0.6762929558753967
rl training, epoch1, iter0, batch1015/1133, batch loss:0.5710746049880981, Training time:32156.405885457993
batch reward last col mean 0.6891246438026428 first col mean 0.7160974740982056 all mean 0.6895178556442261
rl training, epoch1, iter0, batch1016/1133, batch loss:0.5917049050331116, Training time:32183.56285429001
batch reward last col mean 0.7145862579345703 first col mean 0.6961666345596313 all mean 0.7145627737045288
rl training, epoch1, iter0, batch1017/1133, batch loss:0.6092072129249573, Training time:32210.567678689957
batch reward last col mean 0.7295058369636536 first col mean 0.7409001588821411 all mean 0.7298128008842468
rl training, epoch1, iter0, batch1018/1133, batch loss:0.5311336517333984, Training time:32237.90626859665
batch reward last col mean 0.768682599067688 first col mean 0.7493566870689392 all mean 0.7681894302368164
rl training, epoch1, iter0, batch1019/1133, batch loss:0.5958293080329895, Training time:32265.254426002502
batch reward last col mean 0.7009667158126831 first col mean 0.7020509243011475 all mean 0.7010663151741028
rl training, epoch1, iter0, batch1020/1133, batch loss:0.5679308772087097, Training time:32292.45896077156
batch reward last col mean 0.770409107208252 first col mean 0.7626104354858398 all mean 0.7697190642356873
rl training, epoch1, iter0, batch1021/1133, batch loss:0.6529682874679565, Training time:32319.68591284752
batch reward last col mean 0.7671080827713013 first col mean 0.7609515190124512 all mean 0.7672696113586426
rl training, epoch1, iter0, batch1022/1133, batch loss:0.6321962475776672, Training time:32346.739300251007
batch reward last col mean 0.6808967590332031 first col mean 0.6912949681282043 all mean 0.6814394593238831
rl training, epoch1, iter0, batch1023/1133, batch loss:0.5072722434997559, Training time:32373.680272579193
batch reward last col mean 0.744388997554779 first col mean 0.7466840744018555 all mean 0.7443321943283081
rl training, epoch1, iter0, batch1024/1133, batch loss:0.599143385887146, Training time:32400.88617706299
batch reward last col mean 0.7699100375175476 first col mean 0.7716442346572876 all mean 0.7694289088249207
rl training, epoch1, iter0, batch1025/1133, batch loss:0.5817694067955017, Training time:32427.96236729622
batch reward last col mean 0.7326111197471619 first col mean 0.723805844783783 all mean 0.7326490879058838
rl training, epoch1, iter0, batch1026/1133, batch loss:0.5180047154426575, Training time:32455.111353874207
batch reward last col mean 0.7618489265441895 first col mean 0.7595155835151672 all mean 0.7617287039756775
rl training, epoch1, iter0, batch1027/1133, batch loss:0.5782458186149597, Training time:32482.321479797363
batch reward last col mean 0.7383095622062683 first col mean 0.736315131187439 all mean 0.7383293509483337
rl training, epoch1, iter0, batch1028/1133, batch loss:0.519260823726654, Training time:32509.859865665436
batch reward last col mean 0.7098280787467957 first col mean 0.7172693014144897 all mean 0.709952175617218
rl training, epoch1, iter0, batch1029/1133, batch loss:0.5508712530136108, Training time:32537.20625424385
batch reward last col mean 0.7360618710517883 first col mean 0.7313804030418396 all mean 0.7362566590309143
rl training, epoch1, iter0, batch1030/1133, batch loss:0.48127174377441406, Training time:32564.563777446747
batch reward last col mean 0.7325288653373718 first col mean 0.7178693413734436 all mean 0.7321087718009949
rl training, epoch1, iter0, batch1031/1133, batch loss:0.5457788109779358, Training time:32591.84929418564
batch reward last col mean 0.7169187664985657 first col mean 0.7029529809951782 all mean 0.7165958285331726
rl training, epoch1, iter0, batch1032/1133, batch loss:0.4625575840473175, Training time:32619.096765995026
batch reward last col mean 0.7143803238868713 first col mean 0.7349539995193481 all mean 0.7147934436798096
rl training, epoch1, iter0, batch1033/1133, batch loss:0.477477103471756, Training time:32646.149884462357
batch reward last col mean 0.735774040222168 first col mean 0.7301209568977356 all mean 0.7354475855827332
rl training, epoch1, iter0, batch1034/1133, batch loss:0.4212234914302826, Training time:32673.363459825516
batch reward last col mean 0.7342392802238464 first col mean 0.726416826248169 all mean 0.7341715693473816
rl training, epoch1, iter0, batch1035/1133, batch loss:0.43794363737106323, Training time:32700.542697906494
batch reward last col mean 0.734976053237915 first col mean 0.7293837666511536 all mean 0.7348757386207581
rl training, epoch1, iter0, batch1036/1133, batch loss:0.4868621230125427, Training time:32727.55966091156
batch reward last col mean 0.715313196182251 first col mean 0.7014461159706116 all mean 0.7150065302848816
rl training, epoch1, iter0, batch1037/1133, batch loss:0.5304588675498962, Training time:32754.673629760742
batch reward last col mean 0.6872397661209106 first col mean 0.6984779834747314 all mean 0.6876236200332642
rl training, epoch1, iter0, batch1038/1133, batch loss:0.4851416349411011, Training time:32782.08031272888
batch reward last col mean 0.7052340507507324 first col mean 0.7036098837852478 all mean 0.7050213813781738
rl training, epoch1, iter0, batch1039/1133, batch loss:0.5371553301811218, Training time:32809.48379945755
batch reward last col mean 0.7781124114990234 first col mean 0.7724037170410156 all mean 0.7777890563011169
rl training, epoch1, iter0, batch1040/1133, batch loss:0.5694069862365723, Training time:32836.71107172966
batch reward last col mean 0.7220278382301331 first col mean 0.7397630214691162 all mean 0.7221819758415222
rl training, epoch1, iter0, batch1041/1133, batch loss:0.5071942806243896, Training time:32863.933789253235
batch reward last col mean 0.7170572280883789 first col mean 0.7288274765014648 all mean 0.7175572514533997
rl training, epoch1, iter0, batch1042/1133, batch loss:0.5338130593299866, Training time:32891.14965891838
batch reward last col mean 0.7659738063812256 first col mean 0.7606019377708435 all mean 0.7656208276748657
rl training, epoch1, iter0, batch1043/1133, batch loss:0.5773976445198059, Training time:32918.14929318428
batch reward last col mean 0.7541672587394714 first col mean 0.7452328205108643 all mean 0.7538946866989136
rl training, epoch1, iter0, batch1044/1133, batch loss:0.5912944078445435, Training time:32945.12688279152
batch reward last col mean 0.7779715061187744 first col mean 0.7683863639831543 all mean 0.7781184911727905
rl training, epoch1, iter0, batch1045/1133, batch loss:0.6425597667694092, Training time:32972.340391397476
batch reward last col mean 0.7458956241607666 first col mean 0.7528433799743652 all mean 0.7460951209068298
rl training, epoch1, iter0, batch1046/1133, batch loss:0.6524540185928345, Training time:32999.5743367672
batch reward last col mean 0.7172517776489258 first col mean 0.7313823103904724 all mean 0.7175469398498535
rl training, epoch1, iter0, batch1047/1133, batch loss:0.5617973208427429, Training time:33026.92297554016
batch reward last col mean 0.7273682951927185 first col mean 0.7432936429977417 all mean 0.7279118895530701
rl training, epoch1, iter0, batch1048/1133, batch loss:0.5635928511619568, Training time:33054.040481090546
batch reward last col mean 0.7272626161575317 first col mean 0.7212570309638977 all mean 0.7271614670753479
rl training, epoch1, iter0, batch1049/1133, batch loss:0.5535323023796082, Training time:33081.29376554489
batch reward last col mean 0.7109354138374329 first col mean 0.7368078827857971 all mean 0.7119230031967163
rl training, epoch1, iter0, batch1050/1133, batch loss:0.5432043075561523, Training time:33108.64265012741
batch reward last col mean 0.7268020510673523 first col mean 0.7112612128257751 all mean 0.7264054417610168
rl training, epoch1, iter0, batch1051/1133, batch loss:0.6800883412361145, Training time:33135.77801537514
batch reward last col mean 0.7133258581161499 first col mean 0.7113804221153259 all mean 0.7133504748344421
rl training, epoch1, iter0, batch1052/1133, batch loss:0.589638888835907, Training time:33162.98493528366
batch reward last col mean 0.7426523566246033 first col mean 0.7331677079200745 all mean 0.7419222593307495
rl training, epoch1, iter0, batch1053/1133, batch loss:0.5732870697975159, Training time:33190.81723380089
batch reward last col mean 0.7109113931655884 first col mean 0.7188422083854675 all mean 0.7106606960296631
rl training, epoch1, iter0, batch1054/1133, batch loss:0.6256696581840515, Training time:33218.34096503258
batch reward last col mean 0.6983643770217896 first col mean 0.6964287161827087 all mean 0.6988654732704163
rl training, epoch1, iter0, batch1055/1133, batch loss:0.5662955641746521, Training time:33245.646297216415
batch reward last col mean 0.7337369918823242 first col mean 0.738637387752533 all mean 0.7337982654571533
rl training, epoch1, iter0, batch1056/1133, batch loss:0.6123834848403931, Training time:33272.82331252098
batch reward last col mean 0.7097308039665222 first col mean 0.7161630392074585 all mean 0.7098281383514404
rl training, epoch1, iter0, batch1057/1133, batch loss:0.5736237168312073, Training time:33300.0261888504
batch reward last col mean 0.6902163028717041 first col mean 0.6864649653434753 all mean 0.6898549199104309
rl training, epoch1, iter0, batch1058/1133, batch loss:0.597910463809967, Training time:33327.56689786911
batch reward last col mean 0.7056450247764587 first col mean 0.7097852230072021 all mean 0.7056906223297119
rl training, epoch1, iter0, batch1059/1133, batch loss:0.5692898631095886, Training time:33354.99560022354
batch reward last col mean 0.7379456162452698 first col mean 0.7149606943130493 all mean 0.7371875643730164
rl training, epoch1, iter0, batch1060/1133, batch loss:0.5878227949142456, Training time:33382.4854722023
batch reward last col mean 0.7314892411231995 first col mean 0.731521487236023 all mean 0.7314150333404541
rl training, epoch1, iter0, batch1061/1133, batch loss:0.6682816743850708, Training time:33409.81672644615
batch reward last col mean 0.6937342286109924 first col mean 0.7165833711624146 all mean 0.6941027641296387
rl training, epoch1, iter0, batch1062/1133, batch loss:0.5893678665161133, Training time:33436.9143614769
batch reward last col mean 0.7227009534835815 first col mean 0.7210512757301331 all mean 0.7224752902984619
rl training, epoch1, iter0, batch1063/1133, batch loss:0.5998032093048096, Training time:33464.32413506508
batch reward last col mean 0.7006626725196838 first col mean 0.7099994421005249 all mean 0.7011300921440125
rl training, epoch1, iter0, batch1064/1133, batch loss:0.5550171732902527, Training time:33491.655480623245
batch reward last col mean 0.714582622051239 first col mean 0.700177788734436 all mean 0.7143352031707764
rl training, epoch1, iter0, batch1065/1133, batch loss:0.5429216623306274, Training time:33519.03158736229
batch reward last col mean 0.7183051109313965 first col mean 0.7048595547676086 all mean 0.7183640599250793
rl training, epoch1, iter0, batch1066/1133, batch loss:0.6417797207832336, Training time:33546.2712495327
batch reward last col mean 0.7488137483596802 first col mean 0.755391001701355 all mean 0.7493079304695129
rl training, epoch1, iter0, batch1067/1133, batch loss:0.598547637462616, Training time:33573.55402779579
batch reward last col mean 0.766238808631897 first col mean 0.7789820432662964 all mean 0.7664101123809814
rl training, epoch1, iter0, batch1068/1133, batch loss:0.5642611980438232, Training time:33601.2085351944
batch reward last col mean 0.7256662845611572 first col mean 0.7485525608062744 all mean 0.7262634634971619
rl training, epoch1, iter0, batch1069/1133, batch loss:0.49105536937713623, Training time:33628.585403203964
batch reward last col mean 0.7528693079948425 first col mean 0.753526508808136 all mean 0.752999484539032
rl training, epoch1, iter0, batch1070/1133, batch loss:0.5980311036109924, Training time:33656.13557600975
batch reward last col mean 0.7541377544403076 first col mean 0.7563380599021912 all mean 0.7542171478271484
rl training, epoch1, iter0, batch1071/1133, batch loss:0.4318944215774536, Training time:33683.60339140892
batch reward last col mean 0.7713358402252197 first col mean 0.7726852893829346 all mean 0.7712537050247192
rl training, epoch1, iter0, batch1072/1133, batch loss:0.5332099795341492, Training time:33711.01695537567
batch reward last col mean 0.7339302897453308 first col mean 0.7201318740844727 all mean 0.7335744500160217
rl training, epoch1, iter0, batch1073/1133, batch loss:0.5195191502571106, Training time:33738.49360752106
batch reward last col mean 0.6959123015403748 first col mean 0.7241640686988831 all mean 0.6965606212615967
rl training, epoch1, iter0, batch1074/1133, batch loss:0.47606414556503296, Training time:33765.98226952553
batch reward last col mean 0.7407231330871582 first col mean 0.7438763380050659 all mean 0.7406606674194336
rl training, epoch1, iter0, batch1075/1133, batch loss:0.5528454780578613, Training time:33793.50408244133
batch reward last col mean 0.7234959602355957 first col mean 0.7396591901779175 all mean 0.7238254547119141
rl training, epoch1, iter0, batch1076/1133, batch loss:0.4918406903743744, Training time:33820.900171756744
batch reward last col mean 0.7406598329544067 first col mean 0.7428970336914062 all mean 0.7409316301345825
rl training, epoch1, iter0, batch1077/1133, batch loss:0.5209512114524841, Training time:33848.253601789474
batch reward last col mean 0.7570416331291199 first col mean 0.7605634331703186 all mean 0.7569079399108887
rl training, epoch1, iter0, batch1078/1133, batch loss:0.5553278923034668, Training time:33875.73840856552
batch reward last col mean 0.7506207823753357 first col mean 0.7482092380523682 all mean 0.7504985332489014
rl training, epoch1, iter0, batch1079/1133, batch loss:0.5363779067993164, Training time:33903.116562366486
batch reward last col mean 0.7722886800765991 first col mean 0.7448925971984863 all mean 0.771933913230896
rl training, epoch1, iter0, batch1080/1133, batch loss:0.6040983200073242, Training time:33930.56976103783
batch reward last col mean 0.7631582021713257 first col mean 0.7589085102081299 all mean 0.7631444334983826
rl training, epoch1, iter0, batch1081/1133, batch loss:0.48016852140426636, Training time:33958.06549143791
batch reward last col mean 0.681316614151001 first col mean 0.7166339159011841 all mean 0.6821321249008179
rl training, epoch1, iter0, batch1082/1133, batch loss:0.508084774017334, Training time:33985.15550017357
batch reward last col mean 0.7228245139122009 first col mean 0.7441537380218506 all mean 0.7233185172080994
rl training, epoch1, iter0, batch1083/1133, batch loss:0.5708479285240173, Training time:34012.529535770416
batch reward last col mean 0.7523956298828125 first col mean 0.7689207792282104 all mean 0.7525928616523743
rl training, epoch1, iter0, batch1084/1133, batch loss:0.5124256610870361, Training time:34039.969504117966
batch reward last col mean 0.7372684478759766 first col mean 0.7413244843482971 all mean 0.737396776676178
rl training, epoch1, iter0, batch1085/1133, batch loss:0.4824906587600708, Training time:34067.460267066956
batch reward last col mean 0.7278364896774292 first col mean 0.7216991782188416 all mean 0.7277520895004272
rl training, epoch1, iter0, batch1086/1133, batch loss:0.4707667827606201, Training time:34094.82420396805
batch reward last col mean 0.6909140944480896 first col mean 0.7010315656661987 all mean 0.6909422278404236
rl training, epoch1, iter0, batch1087/1133, batch loss:0.43651193380355835, Training time:34121.94169664383
batch reward last col mean 0.740132212638855 first col mean 0.734555721282959 all mean 0.7397779822349548
rl training, epoch1, iter0, batch1088/1133, batch loss:0.4663812518119812, Training time:34149.306015729904
batch reward last col mean 0.7306927442550659 first col mean 0.7296798229217529 all mean 0.7306857705116272
rl training, epoch1, iter0, batch1089/1133, batch loss:0.38517996668815613, Training time:34176.574697732925
batch reward last col mean 0.6948040723800659 first col mean 0.7065375447273254 all mean 0.6954001784324646
rl training, epoch1, iter0, batch1090/1133, batch loss:0.4273110330104828, Training time:34203.73883843422
batch reward last col mean 0.7493995428085327 first col mean 0.751863956451416 all mean 0.7496166825294495
rl training, epoch1, iter0, batch1091/1133, batch loss:0.5175904035568237, Training time:34231.03595542908
batch reward last col mean 0.7552716732025146 first col mean 0.7265878319740295 all mean 0.7546773552894592
rl training, epoch1, iter0, batch1092/1133, batch loss:0.48434150218963623, Training time:34258.46400117874
batch reward last col mean 0.7449089288711548 first col mean 0.7294490933418274 all mean 0.7448462843894958
rl training, epoch1, iter0, batch1093/1133, batch loss:0.4420175552368164, Training time:34285.63706588745
batch reward last col mean 0.7049012780189514 first col mean 0.6977276802062988 all mean 0.7050834894180298
rl training, epoch1, iter0, batch1094/1133, batch loss:0.49121347069740295, Training time:34313.004813194275
batch reward last col mean 0.7495273351669312 first col mean 0.7525887489318848 all mean 0.749869167804718
rl training, epoch1, iter0, batch1095/1133, batch loss:0.4269012212753296, Training time:34340.237458229065
batch reward last col mean 0.7631869316101074 first col mean 0.7652028799057007 all mean 0.7634288668632507
rl training, epoch1, iter0, batch1096/1133, batch loss:0.5301763415336609, Training time:34367.5617210865
batch reward last col mean 0.7320625185966492 first col mean 0.7241348028182983 all mean 0.7317222952842712
rl training, epoch1, iter0, batch1097/1133, batch loss:0.5356387495994568, Training time:34394.75588607788
batch reward last col mean 0.7671434879302979 first col mean 0.7405260801315308 all mean 0.7666565775871277
rl training, epoch1, iter0, batch1098/1133, batch loss:0.5154286623001099, Training time:34421.82964158058
batch reward last col mean 0.7451189756393433 first col mean 0.7373486757278442 all mean 0.7449153065681458
rl training, epoch1, iter0, batch1099/1133, batch loss:0.474063903093338, Training time:34449.06080079079
batch reward last col mean 0.7283313870429993 first col mean 0.7287571430206299 all mean 0.728148877620697
rl training, epoch1, iter0, batch1100/1133, batch loss:0.5068177580833435, Training time:34476.41018819809
batch reward last col mean 0.7556999921798706 first col mean 0.7808736562728882 all mean 0.7564139366149902
rl training, epoch1, iter0, batch1101/1133, batch loss:0.5224440097808838, Training time:34503.61262464523
batch reward last col mean 0.7205711603164673 first col mean 0.7135289311408997 all mean 0.7205802798271179
rl training, epoch1, iter0, batch1102/1133, batch loss:0.4354654550552368, Training time:34530.83528614044
batch reward last col mean 0.7594810724258423 first col mean 0.779743492603302 all mean 0.7598276138305664
rl training, epoch1, iter0, batch1103/1133, batch loss:0.4304359257221222, Training time:34558.669420957565
batch reward last col mean 0.7082881927490234 first col mean 0.7306327819824219 all mean 0.7090785503387451
rl training, epoch1, iter0, batch1104/1133, batch loss:0.536683201789856, Training time:34585.963109731674
batch reward last col mean 0.6660375595092773 first col mean 0.6842260956764221 all mean 0.6666415929794312
rl training, epoch1, iter0, batch1105/1133, batch loss:0.3363398611545563, Training time:34613.347317934036
batch reward last col mean 0.7189934849739075 first col mean 0.7348049879074097 all mean 0.7191044688224792
rl training, epoch1, iter0, batch1106/1133, batch loss:0.5139907002449036, Training time:34640.403342962265
batch reward last col mean 0.7275252342224121 first col mean 0.7273695468902588 all mean 0.727451503276825
rl training, epoch1, iter0, batch1107/1133, batch loss:0.508459210395813, Training time:34667.45410323143
batch reward last col mean 0.7435943484306335 first col mean 0.748722493648529 all mean 0.7439451813697815
rl training, epoch1, iter0, batch1108/1133, batch loss:0.4086794853210449, Training time:34694.95557117462
batch reward last col mean 0.7289499044418335 first col mean 0.7476272583007812 all mean 0.7292160391807556
rl training, epoch1, iter0, batch1109/1133, batch loss:0.4141053557395935, Training time:34722.151240587234
batch reward last col mean 0.7545905709266663 first col mean 0.7584008574485779 all mean 0.7547917366027832
rl training, epoch1, iter0, batch1110/1133, batch loss:0.5226808786392212, Training time:34749.9642598629
batch reward last col mean 0.7508627772331238 first col mean 0.7538233399391174 all mean 0.7509493827819824
rl training, epoch1, iter0, batch1111/1133, batch loss:0.47566530108451843, Training time:34777.156764507294
batch reward last col mean 0.7144030332565308 first col mean 0.7076561450958252 all mean 0.7142084240913391
rl training, epoch1, iter0, batch1112/1133, batch loss:0.4311438500881195, Training time:34804.30596089363
batch reward last col mean 0.7540315389633179 first col mean 0.7352455854415894 all mean 0.7534617185592651
rl training, epoch1, iter0, batch1113/1133, batch loss:0.48024627566337585, Training time:34831.874403715134
batch reward last col mean 0.7666466236114502 first col mean 0.7868006825447083 all mean 0.7669070363044739
rl training, epoch1, iter0, batch1114/1133, batch loss:0.39698758721351624, Training time:34859.28474974632
batch reward last col mean 0.731002926826477 first col mean 0.7386116981506348 all mean 0.7311399579048157
rl training, epoch1, iter0, batch1115/1133, batch loss:0.42921438813209534, Training time:34886.56009173393
batch reward last col mean 0.774775505065918 first col mean 0.7582425475120544 all mean 0.7744576930999756
rl training, epoch1, iter0, batch1116/1133, batch loss:0.5419093370437622, Training time:34913.73558855057
batch reward last col mean 0.7354962229728699 first col mean 0.7208812236785889 all mean 0.7351154088973999
rl training, epoch1, iter0, batch1117/1133, batch loss:0.4069153070449829, Training time:34940.7481648922
batch reward last col mean 0.7445888519287109 first col mean 0.7461490631103516 all mean 0.7445592880249023
rl training, epoch1, iter0, batch1118/1133, batch loss:0.44440948963165283, Training time:34967.7140455246
batch reward last col mean 0.7311558723449707 first col mean 0.7163534164428711 all mean 0.7309597134590149
rl training, epoch1, iter0, batch1119/1133, batch loss:0.46207261085510254, Training time:34994.702443122864
batch reward last col mean 0.7335075736045837 first col mean 0.7138151526451111 all mean 0.7328124642372131
rl training, epoch1, iter0, batch1120/1133, batch loss:0.41025182604789734, Training time:35021.849219322205
batch reward last col mean 0.7397310137748718 first col mean 0.7409955859184265 all mean 0.7397484183311462
rl training, epoch1, iter0, batch1121/1133, batch loss:0.5005090832710266, Training time:35049.61356925964
batch reward last col mean 0.7528190016746521 first col mean 0.7457908987998962 all mean 0.7527866363525391
rl training, epoch1, iter0, batch1122/1133, batch loss:0.4714892506599426, Training time:35076.68665146828
batch reward last col mean 0.7349669337272644 first col mean 0.7329971790313721 all mean 0.7351298332214355
rl training, epoch1, iter0, batch1123/1133, batch loss:0.4427395462989807, Training time:35104.3086681366
batch reward last col mean 0.7347506284713745 first col mean 0.7419106960296631 all mean 0.7352124452590942
rl training, epoch1, iter0, batch1124/1133, batch loss:0.52498859167099, Training time:35131.38562583923
batch reward last col mean 0.75908362865448 first col mean 0.7500424385070801 all mean 0.7594807744026184
rl training, epoch1, iter0, batch1125/1133, batch loss:0.48028409481048584, Training time:35158.5893599987
batch reward last col mean 0.7359369993209839 first col mean 0.7321262359619141 all mean 0.735572874546051
rl training, epoch1, iter0, batch1126/1133, batch loss:0.4798179566860199, Training time:35185.69116330147
batch reward last col mean 0.7171751260757446 first col mean 0.7316864728927612 all mean 0.7174963355064392
rl training, epoch1, iter0, batch1127/1133, batch loss:0.39614084362983704, Training time:35212.96120977402
batch reward last col mean 0.7392311692237854 first col mean 0.7106070518493652 all mean 0.7387924194335938
rl training, epoch1, iter0, batch1128/1133, batch loss:0.4475894272327423, Training time:35240.248989105225
batch reward last col mean 0.7179235219955444 first col mean 0.7199058532714844 all mean 0.7179597020149231
rl training, epoch1, iter0, batch1129/1133, batch loss:0.42707133293151855, Training time:35267.36819243431
batch reward last col mean 0.758874773979187 first col mean 0.7570772767066956 all mean 0.7589766979217529
rl training, epoch1, iter0, batch1130/1133, batch loss:0.5086796283721924, Training time:35294.5858669281
batch reward last col mean 0.6830875873565674 first col mean 0.7024722695350647 all mean 0.6833901405334473
rl training, epoch1, iter0, batch1131/1133, batch loss:0.4174763262271881, Training time:35321.856045246124
batch reward last col mean 0.7645990252494812 first col mean 0.7731402516365051 all mean 0.7648816108703613
rl training, epoch1, iter0, batch1132/1133, batch loss:0.4135150909423828, Training time:35346.45437502861
rl training, epoch 1, iter 0, loss:0.6940641527685799, Training time:35346.45467758179 
rl epoch 1, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4761681803432273 Time: 173.55261945724487 s
cur_epoch: 1
D Training Loss: 0.4356593485175248 Time: 171.84349131584167 s
cur_epoch: 2
D Training Loss: 0.41287870928710896 Time: 171.16837644577026 s
cur_epoch: 3
D Training Loss: 0.3937356408359935 Time: 170.48800778388977 s
cur_epoch: 4
D Training Loss: 0.3705027200616995 Time: 174.5082507133484 s
rl epoch 2, begin RL for generator...
batch reward last col mean 1.3851416724719456e-06 first col mean 0.00038873348967172205 all mean 5.313439487508731e-06
rl training, epoch2, iter0, batch0/1133, batch loss:9.957144357031211e-06, Training time:36235.30457353592
batch reward last col mean 3.3169646940223174e-06 first col mean 5.757665803685086e-06 all mean 3.373800154804485e-06
rl training, epoch2, iter0, batch1/1133, batch loss:4.056269972352311e-06, Training time:36262.82698512077
batch reward last col mean 8.866523785400204e-06 first col mean 1.7236321582458913e-05 all mean 9.324121492682025e-06
rl training, epoch2, iter0, batch2/1133, batch loss:4.132727553951554e-05, Training time:36289.94920921326
batch reward last col mean 4.3971223931293935e-05 first col mean 0.00010312852100469172 all mean 4.469188934308477e-05
rl training, epoch2, iter0, batch3/1133, batch loss:0.00016377931751776487, Training time:36317.19536828995
batch reward last col mean 4.45015348304878e-06 first col mean 0.0001566680584801361 all mean 6.056655820430024e-06
rl training, epoch2, iter0, batch4/1133, batch loss:1.1424413060012739e-05, Training time:36344.75325965881
batch reward last col mean 0.00025300143170170486 first col mean 8.476313269056845e-06 all mean 0.00024921950534917414
rl training, epoch2, iter0, batch5/1133, batch loss:0.0004972690367139876, Training time:36372.19682407379
batch reward last col mean 0.0003483310283627361 first col mean 3.738212399184704e-06 all mean 0.00033773889299482107
rl training, epoch2, iter0, batch6/1133, batch loss:0.0014134130906313658, Training time:36399.493544340134
batch reward last col mean 9.445643627259415e-06 first col mean 0.00013704934099223465 all mean 2.8398591894074343e-05
rl training, epoch2, iter0, batch7/1133, batch loss:0.0007830270915292203, Training time:36426.64081144333
batch reward last col mean 0.0001080639922292903 first col mean 0.0006138100288808346 all mean 0.0001247074396815151
rl training, epoch2, iter0, batch8/1133, batch loss:0.0008372441516257823, Training time:36454.34642601013
batch reward last col mean 8.865848712957813e-07 first col mean 2.6186251034232555e-06 all mean 1.7961779121833388e-06
rl training, epoch2, iter0, batch9/1133, batch loss:3.522376573528163e-06, Training time:36481.43439531326
batch reward last col mean 5.683483777829679e-06 first col mean 0.00040995603194460273 all mean 1.3777054846286774e-05
rl training, epoch2, iter0, batch10/1133, batch loss:1.9875071302521974e-05, Training time:36508.76958656311
batch reward last col mean 2.4103050236590207e-05 first col mean 2.367037996009458e-05 all mean 2.3277654690900818e-05
rl training, epoch2, iter0, batch11/1133, batch loss:3.2772208214737475e-05, Training time:36536.07985162735
batch reward last col mean 1.1326427738822531e-05 first col mean 4.419428478286136e-06 all mean 1.1277819794486277e-05
rl training, epoch2, iter0, batch12/1133, batch loss:7.774816367600579e-06, Training time:36563.205927848816
batch reward last col mean 1.5392791965496144e-06 first col mean 6.1575542531500105e-06 all mean 1.6087975609480054e-06
rl training, epoch2, iter0, batch13/1133, batch loss:2.0848292479058728e-06, Training time:36590.41814947128
batch reward last col mean 2.3765322112012655e-05 first col mean 3.30568291246891e-05 all mean 2.547762960602995e-05
rl training, epoch2, iter0, batch14/1133, batch loss:1.2431406503310427e-05, Training time:36617.695590019226
batch reward last col mean 8.210023224819452e-06 first col mean 7.214318429760169e-06 all mean 1.1742930837499443e-05
rl training, epoch2, iter0, batch15/1133, batch loss:0.00019634714408311993, Training time:36644.85178756714
batch reward last col mean 0.00676771393045783 first col mean 7.937945156299975e-06 all mean 0.006597291212528944
rl training, epoch2, iter0, batch16/1133, batch loss:0.01917559653520584, Training time:36672.148119688034
batch reward last col mean 7.465847011189908e-05 first col mean 6.945669156266376e-05 all mean 7.664567237952724e-05
rl training, epoch2, iter0, batch17/1133, batch loss:0.00028241093968972564, Training time:36699.414727926254
batch reward last col mean 2.1059288428659784e-06 first col mean 3.285955244791694e-05 all mean 2.65081507677678e-06
rl training, epoch2, iter0, batch18/1133, batch loss:2.1579362510237843e-05, Training time:36726.66569471359
batch reward last col mean 1.3705409401154611e-05 first col mean 0.0004429640539456159 all mean 1.7953267160919495e-05
rl training, epoch2, iter0, batch19/1133, batch loss:3.144933361909352e-05, Training time:36753.88688206673
batch reward last col mean 1.6411638625868363e-06 first col mean 7.260739948833361e-06 all mean 1.9546866951714037e-06
rl training, epoch2, iter0, batch20/1133, batch loss:3.3662188343441812e-06, Training time:36780.83386039734
batch reward last col mean 5.559860073844902e-05 first col mean 0.0009808901231735945 all mean 6.502902397187427e-05
rl training, epoch2, iter0, batch21/1133, batch loss:0.0003430779615882784, Training time:36808.04768848419
batch reward last col mean 0.00022542021179106086 first col mean 1.1548117981874384e-05 all mean 0.00021911616204306483
rl training, epoch2, iter0, batch22/1133, batch loss:0.0005803927779197693, Training time:36835.202493429184
batch reward last col mean 9.463568858336657e-05 first col mean 3.732395271072164e-05 all mean 9.463302558287978e-05
rl training, epoch2, iter0, batch23/1133, batch loss:0.00010257147368974984, Training time:36862.41550374031
batch reward last col mean 2.036012665485032e-05 first col mean 0.00021658847981598228 all mean 2.374122959736269e-05
rl training, epoch2, iter0, batch24/1133, batch loss:0.00014392880257219076, Training time:36889.71253824234
batch reward last col mean 3.889856088790111e-06 first col mean 7.037082468741573e-06 all mean 4.054914825246669e-06
rl training, epoch2, iter0, batch25/1133, batch loss:2.577882241894258e-06, Training time:36916.77769589424
batch reward last col mean 0.0006981771439313889 first col mean 5.21759193361504e-06 all mean 0.0006697457865811884
rl training, epoch2, iter0, batch26/1133, batch loss:0.0006866457406431437, Training time:36944.599252939224
batch reward last col mean 0.0011549516348168254 first col mean 0.00030005001462996006 all mean 0.0011463515693321824
rl training, epoch2, iter0, batch27/1133, batch loss:0.0010407953523099422, Training time:36971.65453338623
batch reward last col mean 4.341041403677082e-06 first col mean 0.00016502750804647803 all mean 6.81945493852254e-06
rl training, epoch2, iter0, batch28/1133, batch loss:3.2337531592929736e-05, Training time:36998.65043640137
batch reward last col mean 3.330168283355306e-06 first col mean 4.7822373744565994e-05 all mean 3.7846650684514316e-06
rl training, epoch2, iter0, batch29/1133, batch loss:3.362531288075843e-06, Training time:37025.89431357384
batch reward last col mean 4.2328563722549006e-05 first col mean 1.616231884327135e-06 all mean 4.200709008728154e-05
rl training, epoch2, iter0, batch30/1133, batch loss:6.595747254323214e-05, Training time:37053.03885650635
batch reward last col mean 7.936499969218858e-06 first col mean 4.231287311995402e-05 all mean 9.392509127792437e-06
rl training, epoch2, iter0, batch31/1133, batch loss:0.00011879688099725172, Training time:37080.56047606468
batch reward last col mean 5.352150765247643e-06 first col mean 0.0001016723908833228 all mean 1.042802250594832e-05
rl training, epoch2, iter0, batch32/1133, batch loss:0.0003945831267628819, Training time:37108.30912041664
batch reward last col mean 0.003520373022183776 first col mean 1.7795151734389947e-06 all mean 0.0034118604380637407
rl training, epoch2, iter0, batch33/1133, batch loss:0.0027342711109668016, Training time:37135.66744327545
batch reward last col mean 3.392158532733447e-06 first col mean 1.0736012882262003e-05 all mean 4.110483132535592e-06
rl training, epoch2, iter0, batch34/1133, batch loss:9.283575309382286e-06, Training time:37162.90659213066
batch reward last col mean 3.0083130695857108e-05 first col mean 5.154386963113211e-05 all mean 5.569373752223328e-05
rl training, epoch2, iter0, batch35/1133, batch loss:0.0006701383972540498, Training time:37190.07369995117
batch reward last col mean 5.819352395519672e-07 first col mean 2.1733067114837468e-06 all mean 8.021933695090411e-07
rl training, epoch2, iter0, batch36/1133, batch loss:6.034801572241122e-06, Training time:37217.248274326324
batch reward last col mean 6.03767330176197e-05 first col mean 1.251557932846481e-05 all mean 5.9904512454522774e-05
rl training, epoch2, iter0, batch37/1133, batch loss:0.00010852705599972978, Training time:37244.582141160965
batch reward last col mean 2.9680145416932646e-06 first col mean 7.948523489176296e-06 all mean 3.3554429137439e-06
rl training, epoch2, iter0, batch38/1133, batch loss:1.0130307600775268e-05, Training time:37271.682629823685
batch reward last col mean 2.459891902617528e-06 first col mean 0.00011075015208916739 all mean 3.7540380617429037e-06
rl training, epoch2, iter0, batch39/1133, batch loss:5.27460542798508e-06, Training time:37298.61023592949
batch reward last col mean 0.00023895269259810448 first col mean 2.2155507394927554e-05 all mean 0.000234875304158777
rl training, epoch2, iter0, batch40/1133, batch loss:0.00015625622472725809, Training time:37325.657402038574
batch reward last col mean 2.2587220882996917e-05 first col mean 8.12764119473286e-06 all mean 2.2606089260079898e-05
rl training, epoch2, iter0, batch41/1133, batch loss:3.034686960745603e-05, Training time:37352.750175237656
batch reward last col mean 2.8608706998056732e-05 first col mean 0.0005168647039681673 all mean 3.362806819495745e-05
rl training, epoch2, iter0, batch42/1133, batch loss:9.621174103813246e-05, Training time:37379.98911857605
batch reward last col mean 4.2335832404205576e-06 first col mean 1.836234332586173e-05 all mean 4.410867404658347e-06
rl training, epoch2, iter0, batch43/1133, batch loss:6.79070171827334e-06, Training time:37407.55881333351
batch reward last col mean 1.2230975698912516e-05 first col mean 5.7285160437459126e-05 all mean 1.2835969755542465e-05
rl training, epoch2, iter0, batch44/1133, batch loss:7.357585855061188e-05, Training time:37434.46969676018
batch reward last col mean 1.31480521758931e-06 first col mean 5.763361627941777e-07 all mean 1.394741389049159e-06
rl training, epoch2, iter0, batch45/1133, batch loss:4.990867637388874e-06, Training time:37461.6022298336
batch reward last col mean 6.081237643229542e-06 first col mean 5.531794613489183e-06 all mean 5.950240392849082e-06
rl training, epoch2, iter0, batch46/1133, batch loss:5.231408067629673e-06, Training time:37489.05384731293
batch reward last col mean 3.816739990725182e-05 first col mean 2.2365489712683484e-05 all mean 3.777739038923755e-05
rl training, epoch2, iter0, batch47/1133, batch loss:6.064877743483521e-05, Training time:37516.20231103897
batch reward last col mean 1.203902229462983e-06 first col mean 0.000125821097753942 all mean 2.8389204089762643e-06
rl training, epoch2, iter0, batch48/1133, batch loss:2.473863060004078e-05, Training time:37543.9406311512
batch reward last col mean 3.209248825442046e-05 first col mean 1.4418332057175576e-06 all mean 3.17546036967542e-05
rl training, epoch2, iter0, batch49/1133, batch loss:6.33764939266257e-05, Training time:37571.43042802811
batch reward last col mean 3.810278940363787e-06 first col mean 1.0440458936500363e-05 all mean 3.869726242555771e-06
rl training, epoch2, iter0, batch50/1133, batch loss:6.390788712451467e-06, Training time:37598.71767425537
batch reward last col mean 3.092221504630288e-06 first col mean 5.9362564570619725e-06 all mean 3.1377464893012075e-06
rl training, epoch2, iter0, batch51/1133, batch loss:2.259127995785093e-06, Training time:37625.809737205505
batch reward last col mean 5.252921982901171e-05 first col mean 0.00010661374835763127 all mean 5.3719231800641865e-05
rl training, epoch2, iter0, batch52/1133, batch loss:6.280065281316638e-05, Training time:37652.87418746948
batch reward last col mean 0.00016063048678915948 first col mean 1.4641201460108277e-06 all mean 0.00015812457422725856
rl training, epoch2, iter0, batch53/1133, batch loss:0.00010879618639592081, Training time:37680.20190191269
batch reward last col mean 5.2031391533091664e-06 first col mean 2.5037013529072283e-06 all mean 5.2085979405092075e-06
rl training, epoch2, iter0, batch54/1133, batch loss:5.528554538614117e-06, Training time:37707.51333451271
batch reward last col mean 5.4278575589705724e-06 first col mean 6.591561395907775e-05 all mean 5.978082754154457e-06
rl training, epoch2, iter0, batch55/1133, batch loss:5.791755029349588e-06, Training time:37734.9624004364
batch reward last col mean 1.8834764432540396e-06 first col mean 4.513701242103707e-06 all mean 1.929121481225593e-06
rl training, epoch2, iter0, batch56/1133, batch loss:2.9545280995080248e-06, Training time:37762.21402621269
batch reward last col mean 5.139400855114218e-06 first col mean 5.012691872252617e-06 all mean 1.684942253632471e-05
rl training, epoch2, iter0, batch57/1133, batch loss:0.0006342677515931427, Training time:37789.433445215225
batch reward last col mean 9.111759936786257e-06 first col mean 4.128214641241357e-06 all mean 9.153553037322126e-06
rl training, epoch2, iter0, batch58/1133, batch loss:7.581828867841978e-06, Training time:37816.668524980545
batch reward last col mean 1.9595204321376514e-06 first col mean 9.890312867355533e-06 all mean 2.5713643481140025e-06
rl training, epoch2, iter0, batch59/1133, batch loss:2.839886656147428e-05, Training time:37844.00823736191
batch reward last col mean 3.0421117116929963e-05 first col mean 3.7354795495048165e-05 all mean 3.126831506961025e-05
rl training, epoch2, iter0, batch60/1133, batch loss:9.14429037948139e-05, Training time:37871.20241475105
batch reward last col mean 3.948860921809683e-06 first col mean 0.0013155655469745398 all mean 1.7221431335201487e-05
rl training, epoch2, iter0, batch61/1133, batch loss:1.788579174899496e-05, Training time:37898.94172000885
batch reward last col mean 2.6614022772264434e-06 first col mean 1.031805481943593e-06 all mean 1.5986815924406983e-05
rl training, epoch2, iter0, batch62/1133, batch loss:0.0006572413258254528, Training time:37926.03713798523
batch reward last col mean 0.0005365482647903264 first col mean 1.8323092945138342e-06 all mean 0.0005297583993524313
rl training, epoch2, iter0, batch63/1133, batch loss:0.0010807419894263148, Training time:37953.30566287041
batch reward last col mean 0.00027397836674936116 first col mean 1.8760292732622474e-05 all mean 0.0002655664866324514
rl training, epoch2, iter0, batch64/1133, batch loss:0.00047621442354284227, Training time:37980.2497549057
batch reward last col mean 4.159126547165215e-06 first col mean 3.1962997582013486e-06 all mean 4.1425864765187725e-06
rl training, epoch2, iter0, batch65/1133, batch loss:5.904926183575299e-06, Training time:38007.03356766701
batch reward last col mean 2.8526766982395202e-05 first col mean 0.0011282783234491944 all mean 4.8203572077909485e-05
rl training, epoch2, iter0, batch66/1133, batch loss:0.0014193471288308501, Training time:38034.30231285095
batch reward last col mean 2.0221873455739114e-06 first col mean 2.06475192499056e-06 all mean 2.046265308308648e-06
rl training, epoch2, iter0, batch67/1133, batch loss:2.16125567931158e-06, Training time:38061.53179860115
batch reward last col mean 3.5642531202029204e-06 first col mean 5.811043592984788e-06 all mean 5.120820787851699e-06
rl training, epoch2, iter0, batch68/1133, batch loss:4.725474809674779e-06, Training time:38088.82002234459
batch reward last col mean 1.022781270876294e-05 first col mean 4.455081125342986e-06 all mean 1.1253201591898687e-05
rl training, epoch2, iter0, batch69/1133, batch loss:8.102267747744918e-05, Training time:38116.20391583443
batch reward last col mean 3.441767375989002e-06 first col mean 2.964358145618462e-06 all mean 3.464892415649956e-06
rl training, epoch2, iter0, batch70/1133, batch loss:4.181598797003971e-06, Training time:38143.55793881416
batch reward last col mean 9.5179675554391e-05 first col mean 0.0001356476277578622 all mean 9.582131315255538e-05
rl training, epoch2, iter0, batch71/1133, batch loss:0.0002622123865876347, Training time:38170.894896268845
batch reward last col mean 9.599930308468174e-06 first col mean 4.751228516397532e-06 all mean 2.2072254068916664e-05
rl training, epoch2, iter0, batch72/1133, batch loss:0.0003719806845765561, Training time:38198.05354785919
batch reward last col mean 8.264350981335156e-06 first col mean 2.6950929168378934e-06 all mean 8.23353275336558e-06
rl training, epoch2, iter0, batch73/1133, batch loss:6.413479695766e-06, Training time:38225.46399998665
batch reward last col mean 3.5276286780572264e-06 first col mean 4.208264272165252e-06 all mean 3.5865200516127516e-06
rl training, epoch2, iter0, batch74/1133, batch loss:7.118934263417032e-06, Training time:38252.70431447029
batch reward last col mean 1.0950831892841961e-05 first col mean 1.3248230970930308e-05 all mean 1.0990821465384215e-05
rl training, epoch2, iter0, batch75/1133, batch loss:2.2669930331176147e-05, Training time:38279.79589390755
batch reward last col mean 1.4490107787423767e-05 first col mean 5.8833174989558756e-05 all mean 1.5080554476298857e-05
rl training, epoch2, iter0, batch76/1133, batch loss:3.170100899296813e-05, Training time:38307.11803174019
batch reward last col mean 0.0023008394055068493 first col mean 0.0007469133706763387 all mean 0.002288691233843565
rl training, epoch2, iter0, batch77/1133, batch loss:0.002668678527697921, Training time:38334.2333920002
batch reward last col mean 3.95627212128602e-05 first col mean 2.078697070828639e-05 all mean 4.0592127334093675e-05
rl training, epoch2, iter0, batch78/1133, batch loss:5.751068238168955e-05, Training time:38361.54474592209
batch reward last col mean 1.7503371054772288e-06 first col mean 3.0553890155715635e-06 all mean 2.460491941747023e-06
rl training, epoch2, iter0, batch79/1133, batch loss:2.8366598598950077e-06, Training time:38388.98102545738
batch reward last col mean 3.5742409636441153e-06 first col mean 9.71935241977917e-06 all mean 5.19409195476328e-06
rl training, epoch2, iter0, batch80/1133, batch loss:1.3308475899975747e-05, Training time:38416.53106689453
batch reward last col mean 5.926934591116151e-06 first col mean 2.8722983188345097e-05 all mean 6.143853170215152e-06
rl training, epoch2, iter0, batch81/1133, batch loss:6.05557170274551e-06, Training time:38443.76193070412
batch reward last col mean 2.636211775097763e-06 first col mean 3.649354039225727e-05 all mean 3.1268762086256174e-06
rl training, epoch2, iter0, batch82/1133, batch loss:8.964607332018204e-06, Training time:38471.0971827507
batch reward last col mean 1.4843371900497004e-06 first col mean 1.338022912023007e-06 all mean 2.083739218505798e-06
rl training, epoch2, iter0, batch83/1133, batch loss:3.497784746286925e-06, Training time:38498.293143987656
batch reward last col mean 1.630829046916915e-06 first col mean 1.642364622966852e-06 all mean 1.7041709270415595e-06
rl training, epoch2, iter0, batch84/1133, batch loss:4.050796178489691e-06, Training time:38525.55095386505
batch reward last col mean 2.8703996576950885e-05 first col mean 9.76365390670253e-06 all mean 2.7826470613945276e-05
rl training, epoch2, iter0, batch85/1133, batch loss:2.60271699517034e-05, Training time:38552.676275491714
batch reward last col mean 1.6465703538415255e-06 first col mean 1.6866928490344435e-05 all mean 1.7928098259289982e-06
rl training, epoch2, iter0, batch86/1133, batch loss:2.4429332370345946e-06, Training time:38579.92851448059
batch reward last col mean 2.369105459365528e-06 first col mean 7.3901387622754555e-06 all mean 2.615368430269882e-06
rl training, epoch2, iter0, batch87/1133, batch loss:5.664584477926837e-06, Training time:38607.204246520996
batch reward last col mean 2.807315468089655e-06 first col mean 0.0011640035081654787 all mean 3.8104761188151315e-05
rl training, epoch2, iter0, batch88/1133, batch loss:0.0006056735874153674, Training time:38634.53964972496
batch reward last col mean 9.385335943079554e-06 first col mean 0.0007502610678784549 all mean 2.7222959033679217e-05
rl training, epoch2, iter0, batch89/1133, batch loss:0.0002950495108962059, Training time:38661.81782269478
batch reward last col mean 3.839429155050311e-06 first col mean 1.1324799743306357e-05 all mean 6.112025403126609e-06
rl training, epoch2, iter0, batch90/1133, batch loss:0.00012099357263650745, Training time:38689.20165538788
batch reward last col mean 3.61008596883039e-06 first col mean 8.347364200744778e-06 all mean 3.961981292377459e-06
rl training, epoch2, iter0, batch91/1133, batch loss:8.8957622210728e-06, Training time:38716.26326560974
batch reward last col mean 2.9006464501435403e-06 first col mean 6.931124062248273e-06 all mean 3.6992896639276296e-06
rl training, epoch2, iter0, batch92/1133, batch loss:3.46088781952858e-05, Training time:38743.454411268234
batch reward last col mean 5.826303095091134e-06 first col mean 7.4484041761024855e-06 all mean 6.020775799697731e-06
rl training, epoch2, iter0, batch93/1133, batch loss:1.2858386071457062e-05, Training time:38770.70840024948
batch reward last col mean 3.68415167031344e-05 first col mean 6.400109850801528e-05 all mean 4.843592250836082e-05
rl training, epoch2, iter0, batch94/1133, batch loss:0.0009695235639810562, Training time:38798.12605190277
batch reward last col mean 5.723988215322606e-05 first col mean 5.786671408714028e-06 all mean 6.739139644196257e-05
rl training, epoch2, iter0, batch95/1133, batch loss:0.00119727139826864, Training time:38825.15428304672
batch reward last col mean 7.178287432907382e-06 first col mean 2.2115367755759507e-05 all mean 7.525406999775441e-06
rl training, epoch2, iter0, batch96/1133, batch loss:1.626885568839498e-05, Training time:38852.22943735123
batch reward last col mean 3.4092115583916893e-06 first col mean 8.059498213697225e-06 all mean 3.4837819384847535e-06
rl training, epoch2, iter0, batch97/1133, batch loss:7.607821771671297e-06, Training time:38879.50995731354
batch reward last col mean 9.300076271756552e-06 first col mean 8.350661119038705e-06 all mean 2.3694892661296763e-05
rl training, epoch2, iter0, batch98/1133, batch loss:0.0006419603596441448, Training time:38906.882175922394
batch reward last col mean 0.0005293104914017022 first col mean 1.0387887414253782e-05 all mean 0.0005206084460951388
rl training, epoch2, iter0, batch99/1133, batch loss:0.000806582102086395, Training time:38934.1202685833
batch reward last col mean 1.860111524365493e-06 first col mean 0.0001794036361388862 all mean 4.375031949166441e-06
rl training, epoch2, iter0, batch100/1133, batch loss:5.4414318583440036e-05, Training time:38961.25174212456
batch reward last col mean 5.013502232031897e-06 first col mean 0.0011727855307981372 all mean 1.680611603660509e-05
rl training, epoch2, iter0, batch101/1133, batch loss:7.098057722032536e-06, Training time:38988.377360105515
batch reward last col mean 8.639844963909127e-06 first col mean 0.0003594350127968937 all mean 1.3652148481924087e-05
rl training, epoch2, iter0, batch102/1133, batch loss:5.362068259273656e-05, Training time:39015.69490003586
batch reward last col mean 2.747977305261884e-05 first col mean 0.0017858579521998763 all mean 4.9962727644015104e-05
rl training, epoch2, iter0, batch103/1133, batch loss:0.000889226037543267, Training time:39043.048981666565
batch reward last col mean 3.1621334528608713e-06 first col mean 2.888559720304329e-06 all mean 4.183231339993654e-06
rl training, epoch2, iter0, batch104/1133, batch loss:1.9586634152801707e-05, Training time:39070.19852757454
batch reward last col mean 3.6678648029919714e-05 first col mean 4.888810872216709e-05 all mean 3.8127171137603e-05
rl training, epoch2, iter0, batch105/1133, batch loss:3.190759161952883e-05, Training time:39097.32143449783
batch reward last col mean 1.8576639604361844e-06 first col mean 2.5377414658578346e-06 all mean 2.0759898688993417e-06
rl training, epoch2, iter0, batch106/1133, batch loss:1.2544679520942736e-05, Training time:39124.782203912735
batch reward last col mean 9.270042937714607e-05 first col mean 2.704462531255558e-05 all mean 0.00011144721793243662
rl training, epoch2, iter0, batch107/1133, batch loss:0.002133120782673359, Training time:39151.93327498436
batch reward last col mean 4.580735549097881e-06 first col mean 5.239597521722317e-05 all mean 5.337061793397879e-06
rl training, epoch2, iter0, batch108/1133, batch loss:9.893610695144162e-06, Training time:39179.207924366
batch reward last col mean 2.9823377190041356e-06 first col mean 1.4283904420153704e-05 all mean 1.756125311658252e-05
rl training, epoch2, iter0, batch109/1133, batch loss:0.0005514505319297314, Training time:39206.248128414154
batch reward last col mean 3.3281176001764834e-05 first col mean 0.00010224965080851689 all mean 3.343809294165112e-05
rl training, epoch2, iter0, batch110/1133, batch loss:4.593239282257855e-05, Training time:39233.33714938164
batch reward last col mean 0.00021638197358697653 first col mean 0.0003230453876312822 all mean 0.00022655961220152676
rl training, epoch2, iter0, batch111/1133, batch loss:0.002161528682336211, Training time:39260.28309226036
batch reward last col mean 6.36709519312717e-05 first col mean 9.851230424828827e-05 all mean 6.473876419477165e-05
rl training, epoch2, iter0, batch112/1133, batch loss:0.0001145268470281735, Training time:39287.28977012634
batch reward last col mean 9.937339200405404e-07 first col mean 1.2142421837779693e-05 all mean 1.224931452270539e-06
rl training, epoch2, iter0, batch113/1133, batch loss:2.948652991108247e-06, Training time:39314.247602939606
batch reward last col mean 0.004005160182714462 first col mean 8.726905070943758e-05 all mean 0.003961510956287384
rl training, epoch2, iter0, batch114/1133, batch loss:0.00539021659642458, Training time:39341.182085990906
batch reward last col mean 1.714312475087354e-06 first col mean 7.57613088353537e-06 all mean 5.838079687237041e-06
rl training, epoch2, iter0, batch115/1133, batch loss:0.00020079159003216773, Training time:39368.2733540535
batch reward last col mean 1.2517873528850032e-06 first col mean 3.973783805122366e-06 all mean 1.5699706636951305e-06
rl training, epoch2, iter0, batch116/1133, batch loss:1.5370229675681912e-06, Training time:39395.327713012695
batch reward last col mean 3.5405412290856475e-06 first col mean 0.0012156657176092267 all mean 1.582091863383539e-05
rl training, epoch2, iter0, batch117/1133, batch loss:8.194854672183283e-06, Training time:39422.44107437134
batch reward last col mean 0.00019288399198558182 first col mean 2.1353745978558436e-05 all mean 0.00019053953292313963
rl training, epoch2, iter0, batch118/1133, batch loss:0.00020062216208316386, Training time:39449.819791555405
batch reward last col mean 0.0009943468030542135 first col mean 1.3972880879009608e-05 all mean 0.0009844953892752528
rl training, epoch2, iter0, batch119/1133, batch loss:0.0029313622508198023, Training time:39476.9693710804
batch reward last col mean 0.0001324336917605251 first col mean 0.0007931622676551342 all mean 0.00013719622802454978
rl training, epoch2, iter0, batch120/1133, batch loss:0.00020326727826613933, Training time:39503.98016119003
batch reward last col mean 4.494600943871774e-06 first col mean 1.6933172446442768e-05 all mean 7.111490958777722e-06
rl training, epoch2, iter0, batch121/1133, batch loss:0.00013135976041667163, Training time:39531.091324329376
batch reward last col mean 0.004218540620058775 first col mean 0.0011527391616255045 all mean 0.004175432492047548
rl training, epoch2, iter0, batch122/1133, batch loss:0.007848442532122135, Training time:39558.66311335564
batch reward last col mean 0.0001492701267125085 first col mean 2.1115893105161376e-05 all mean 0.00014688617375213653
rl training, epoch2, iter0, batch123/1133, batch loss:0.0004011412092950195, Training time:39586.22610497475
batch reward last col mean 9.772099929250544e-07 first col mean 2.415811195533024e-06 all mean 1.0091152944369242e-06
rl training, epoch2, iter0, batch124/1133, batch loss:9.540061682855594e-07, Training time:39613.372681856155
batch reward last col mean 1.2889271374660893e-06 first col mean 1.7859691070043482e-05 all mean 2.448020268275286e-06
rl training, epoch2, iter0, batch125/1133, batch loss:3.911005478585139e-05, Training time:39640.35015511513
batch reward last col mean 3.8493890315294266e-06 first col mean 2.4213536562456284e-06 all mean 9.2614727691398e-06
rl training, epoch2, iter0, batch126/1133, batch loss:1.2070926459273323e-05, Training time:39667.4143640995
batch reward last col mean 2.17518072531675e-06 first col mean 0.0001731403754092753 all mean 8.371995136258192e-06
rl training, epoch2, iter0, batch127/1133, batch loss:0.00011853368050651625, Training time:39694.623254060745
batch reward last col mean 4.852613346884027e-05 first col mean 0.0005319927004165947 all mean 5.3484087402466685e-05
rl training, epoch2, iter0, batch128/1133, batch loss:4.017497121822089e-05, Training time:39721.78642201424
batch reward last col mean 4.339701263234019e-05 first col mean 5.1510127377696335e-05 all mean 4.3560754420468584e-05
rl training, epoch2, iter0, batch129/1133, batch loss:8.499932300765067e-05, Training time:39748.85864543915
batch reward last col mean 4.602177341439528e-06 first col mean 5.683991912519559e-05 all mean 5.106317985337228e-06
rl training, epoch2, iter0, batch130/1133, batch loss:5.344563305698102e-06, Training time:39775.8697040081
batch reward last col mean 4.984732731827535e-05 first col mean 3.313009801786393e-05 all mean 5.854958726558834e-05
rl training, epoch2, iter0, batch131/1133, batch loss:0.002231820020824671, Training time:39802.97063279152
batch reward last col mean 5.909619721933268e-05 first col mean 5.760595013271086e-05 all mean 5.8253535826224834e-05
rl training, epoch2, iter0, batch132/1133, batch loss:8.34029124234803e-05, Training time:39830.04334926605
batch reward last col mean 6.555163963639643e-06 first col mean 1.769998016243335e-05 all mean 3.477882273728028e-05
rl training, epoch2, iter0, batch133/1133, batch loss:0.002024382119998336, Training time:39857.17428302765
batch reward last col mean 0.0007533713942393661 first col mean 6.167228093545418e-06 all mean 0.0007313538808375597
rl training, epoch2, iter0, batch134/1133, batch loss:0.0005294173606671393, Training time:39884.24438333511
batch reward last col mean 4.103766514162999e-06 first col mean 6.061997919459827e-05 all mean 4.717014235211536e-06
rl training, epoch2, iter0, batch135/1133, batch loss:1.0533993190620095e-05, Training time:39911.150584220886
batch reward last col mean 0.0004651336057577282 first col mean 0.0009715539054013789 all mean 0.0004708011692855507
rl training, epoch2, iter0, batch136/1133, batch loss:0.0010446639498695731, Training time:39938.569709062576
batch reward last col mean 2.1514737454708666e-05 first col mean 6.3433608374907635e-06 all mean 2.0994924852857366e-05
rl training, epoch2, iter0, batch137/1133, batch loss:4.472133514354937e-05, Training time:39966.0522236824
batch reward last col mean 0.0016569973668083549 first col mean 0.0008028220618143678 all mean 0.001644653850235045
rl training, epoch2, iter0, batch138/1133, batch loss:0.003031992819160223, Training time:39993.952687978745
batch reward last col mean 1.8497146356821759e-06 first col mean 2.9041666493867524e-05 all mean 2.434374209769885e-06
rl training, epoch2, iter0, batch139/1133, batch loss:8.587818228988908e-06, Training time:40021.28780531883
batch reward last col mean 0.0018827382009476423 first col mean 5.491481351782568e-05 all mean 0.0017809867858886719
rl training, epoch2, iter0, batch140/1133, batch loss:0.003119490575045347, Training time:40048.17530274391
batch reward last col mean 0.0002676845761016011 first col mean 2.3289078399102436e-06 all mean 0.00028078831383027136
rl training, epoch2, iter0, batch141/1133, batch loss:0.0003448695642873645, Training time:40075.608414411545
batch reward last col mean 1.928430947373272e-06 first col mean 1.092722868634155e-05 all mean 2.0705967926915037e-06
rl training, epoch2, iter0, batch142/1133, batch loss:4.834522769670002e-06, Training time:40103.024028778076
batch reward last col mean 0.005834896117448807 first col mean 4.062794323544949e-05 all mean 0.005782994441688061
rl training, epoch2, iter0, batch143/1133, batch loss:0.008454049937427044, Training time:40130.20922207832
batch reward last col mean 0.0001492057926952839 first col mean 0.0003000147407874465 all mean 0.0001507789856987074
rl training, epoch2, iter0, batch144/1133, batch loss:0.00022826920030638576, Training time:40157.471368551254
batch reward last col mean 0.00023043001419864595 first col mean 1.249430533789564e-05 all mean 0.0002249897224828601
rl training, epoch2, iter0, batch145/1133, batch loss:0.00018306767742615193, Training time:40184.700102090836
batch reward last col mean 3.15894703817321e-06 first col mean 6.366597062879009e-06 all mean 3.2198884127865313e-06
rl training, epoch2, iter0, batch146/1133, batch loss:3.752262273337692e-06, Training time:40212.04416179657
batch reward last col mean 3.1143767955654766e-06 first col mean 7.9953106251196e-06 all mean 3.495842520351289e-06
rl training, epoch2, iter0, batch147/1133, batch loss:2.2753838493372314e-05, Training time:40239.47337627411
batch reward last col mean 8.512955901096575e-06 first col mean 0.00011011580500053242 all mean 9.822862921282649e-06
rl training, epoch2, iter0, batch148/1133, batch loss:2.3444063117494807e-05, Training time:40266.79803776741
batch reward last col mean 1.092472029995406e-05 first col mean 0.0015292377211153507 all mean 4.436486415215768e-05
rl training, epoch2, iter0, batch149/1133, batch loss:0.0013040994526818395, Training time:40294.1444747448
batch reward last col mean 1.589810381119605e-05 first col mean 9.006347454487695e-07 all mean 2.55501927313162e-05
rl training, epoch2, iter0, batch150/1133, batch loss:0.0009557294542901218, Training time:40321.36866879463
batch reward last col mean 0.002528629032894969 first col mean 2.186108076784876e-06 all mean 0.0025046321097761393
rl training, epoch2, iter0, batch151/1133, batch loss:0.004357518628239632, Training time:40348.69784832001
batch reward last col mean 0.0020430441945791245 first col mean 7.235678640427068e-05 all mean 0.0020320957992225885
rl training, epoch2, iter0, batch152/1133, batch loss:0.0031307244207710028, Training time:40375.93251681328
batch reward last col mean 1.5979172758306959e-06 first col mean 2.50891171162948e-05 all mean 1.8793202798406128e-06
rl training, epoch2, iter0, batch153/1133, batch loss:5.538409823202528e-06, Training time:40403.121217012405
batch reward last col mean 2.2381977942131925e-06 first col mean 4.035517122247256e-06 all mean 2.9000909762544325e-06
rl training, epoch2, iter0, batch154/1133, batch loss:0.00010408070374978706, Training time:40430.31109547615
batch reward last col mean 0.00031858886359259486 first col mean 0.0006057617138139904 all mean 0.00032199188717640936
rl training, epoch2, iter0, batch155/1133, batch loss:0.0005230215610936284, Training time:40457.42260622978
batch reward last col mean 1.9441671611275524e-05 first col mean 7.40504356144811e-06 all mean 3.7406094634206966e-05
rl training, epoch2, iter0, batch156/1133, batch loss:0.000586046720854938, Training time:40484.67638087273
batch reward last col mean 1.477719888498541e-05 first col mean 5.0549183470138814e-06 all mean 1.751413947204128e-05
rl training, epoch2, iter0, batch157/1133, batch loss:0.00027228545513935387, Training time:40511.95581626892
batch reward last col mean 2.1383293642429635e-06 first col mean 3.9559607103001326e-05 all mean 2.5440733679715777e-06
rl training, epoch2, iter0, batch158/1133, batch loss:2.1897376427659765e-06, Training time:40539.20081734657
batch reward last col mean 3.840781118924497e-06 first col mean 5.862171747139655e-05 all mean 1.0895442756009288e-05
rl training, epoch2, iter0, batch159/1133, batch loss:2.9212227673269808e-05, Training time:40566.40102529526
batch reward last col mean 2.2992662707110867e-06 first col mean 0.001386097981594503 all mean 1.6410291209467687e-05
rl training, epoch2, iter0, batch160/1133, batch loss:4.895976871921448e-06, Training time:40593.51237177849
batch reward last col mean 0.0002031132607953623 first col mean 3.1451472750632092e-06 all mean 0.00020451279124245048
rl training, epoch2, iter0, batch161/1133, batch loss:0.0006596023449674249, Training time:40620.57056474686
batch reward last col mean 1.7506881704321131e-06 first col mean 5.817055716761388e-05 all mean 2.999752950927359e-06
rl training, epoch2, iter0, batch162/1133, batch loss:2.1892426957492717e-05, Training time:40647.94671869278
batch reward last col mean 8.468524356430862e-06 first col mean 0.00020145750022493303 all mean 1.2297345165279694e-05
rl training, epoch2, iter0, batch163/1133, batch loss:0.0003884105826728046, Training time:40675.23719334602
batch reward last col mean 8.250209248217288e-06 first col mean 2.4933113309089094e-05 all mean 8.510803127137478e-06
rl training, epoch2, iter0, batch164/1133, batch loss:2.9041913876426406e-05, Training time:40702.914632081985
batch reward last col mean 0.0001326194469584152 first col mean 0.00016477162716910243 all mean 0.00014349204138852656
rl training, epoch2, iter0, batch165/1133, batch loss:0.0012231303844600916, Training time:40732.011437654495
batch reward last col mean 4.84962401969824e-06 first col mean 1.1229393749090377e-05 all mean 4.964736035617534e-06
rl training, epoch2, iter0, batch166/1133, batch loss:7.79739366407739e-06, Training time:40760.45974087715
batch reward last col mean 1.5180024774963385e-06 first col mean 0.00036284435191191733 all mean 8.559884918213356e-06
rl training, epoch2, iter0, batch167/1133, batch loss:0.0007438878528773785, Training time:40787.8341486454
batch reward last col mean 7.789580195094459e-06 first col mean 8.470054126519244e-06 all mean 8.77227466844488e-06
rl training, epoch2, iter0, batch168/1133, batch loss:9.789044270291924e-05, Training time:40815.22739863396
batch reward last col mean 3.650055077741854e-06 first col mean 6.27102735961671e-06 all mean 4.0670261114428286e-06
rl training, epoch2, iter0, batch169/1133, batch loss:1.3618775483337231e-05, Training time:40842.38821077347
batch reward last col mean 2.11497626878554e-06 first col mean 4.007002280559391e-05 all mean 3.1300537557399366e-06
rl training, epoch2, iter0, batch170/1133, batch loss:6.405568001355277e-06, Training time:40869.53117275238
batch reward last col mean 7.746541996311862e-06 first col mean 0.0002856654755305499 all mean 1.1169973731739447e-05
rl training, epoch2, iter0, batch171/1133, batch loss:8.529978367732838e-05, Training time:40896.660840034485
batch reward last col mean 5.645380952046253e-06 first col mean 6.232720807020087e-06 all mean 5.798764959763503e-06
rl training, epoch2, iter0, batch172/1133, batch loss:9.494922778685577e-06, Training time:40924.02941441536
batch reward last col mean 3.3989124403888127e-06 first col mean 2.822479473252315e-06 all mean 3.426575631237938e-06
rl training, epoch2, iter0, batch173/1133, batch loss:4.2940878302033525e-06, Training time:40951.450501680374
batch reward last col mean 1.3976889476907672e-06 first col mean 2.630642711665132e-06 all mean 1.4247232229536166e-06
rl training, epoch2, iter0, batch174/1133, batch loss:1.984175469260663e-06, Training time:40978.80128002167
batch reward last col mean 1.0332656529499218e-05 first col mean 4.434375659911893e-05 all mean 2.8787660994566977e-05
rl training, epoch2, iter0, batch175/1133, batch loss:0.0019541748333722353, Training time:41005.981922864914
batch reward last col mean 0.002476594876497984 first col mean 0.0001596099609741941 all mean 0.002407959196716547
rl training, epoch2, iter0, batch176/1133, batch loss:0.0038397149182856083, Training time:41033.351644039154
batch reward last col mean 9.66135644375754e-07 first col mean 5.1896429795306176e-05 all mean 2.3013833470031386e-06
rl training, epoch2, iter0, batch177/1133, batch loss:2.2959486614126945e-06, Training time:41060.72122788429
batch reward last col mean 2.937777571787592e-05 first col mean 1.555174821987748e-05 all mean 2.96694506687345e-05
rl training, epoch2, iter0, batch178/1133, batch loss:4.9584454245632514e-05, Training time:41088.07726716995
batch reward last col mean 3.6440969779505394e-06 first col mean 5.434654667624272e-06 all mean 3.97350868297508e-06
rl training, epoch2, iter0, batch179/1133, batch loss:5.669096935889684e-06, Training time:41115.32476401329
batch reward last col mean 3.623507836891804e-06 first col mean 0.0002624079934321344 all mean 7.672062565688975e-06
rl training, epoch2, iter0, batch180/1133, batch loss:0.0005781447980552912, Training time:41142.578867435455
batch reward last col mean 4.594754136633128e-05 first col mean 1.0820954230439384e-06 all mean 4.481361975194886e-05
rl training, epoch2, iter0, batch181/1133, batch loss:4.90189268020913e-05, Training time:41169.882536649704
batch reward last col mean 4.579456344799837e-06 first col mean 1.1484659808047581e-05 all mean 5.237738150754012e-06
rl training, epoch2, iter0, batch182/1133, batch loss:4.022388384328224e-05, Training time:41197.11781549454
batch reward last col mean 5.409319783211686e-05 first col mean 8.06743173598079e-06 all mean 5.543402585317381e-05
rl training, epoch2, iter0, batch183/1133, batch loss:0.00014222793106455356, Training time:41224.474136829376
batch reward last col mean 1.3280192433740012e-05 first col mean 2.295271224284079e-05 all mean 1.3507468793250155e-05
rl training, epoch2, iter0, batch184/1133, batch loss:4.604393689078279e-05, Training time:41251.74859857559
batch reward last col mean 3.8715425034752116e-06 first col mean 4.113614522793796e-06 all mean 3.9524984458694234e-06
rl training, epoch2, iter0, batch185/1133, batch loss:6.278543878579512e-06, Training time:41278.91834950447
batch reward last col mean 1.225454434461426e-05 first col mean 0.0017328985268250108 all mean 2.9649520001839846e-05
rl training, epoch2, iter0, batch186/1133, batch loss:0.000835443614050746, Training time:41306.20058131218
batch reward last col mean 5.229275120655075e-05 first col mean 2.2458361854660325e-06 all mean 5.202615648158826e-05
rl training, epoch2, iter0, batch187/1133, batch loss:0.0002481503179296851, Training time:41333.419655799866
batch reward last col mean 5.4692882258677855e-06 first col mean 5.841749498358695e-06 all mean 5.610744665318634e-06
rl training, epoch2, iter0, batch188/1133, batch loss:6.592855697817868e-06, Training time:41360.6274497509
batch reward last col mean 7.337906481552636e-06 first col mean 4.640439146896824e-05 all mean 1.1846380402857903e-05
rl training, epoch2, iter0, batch189/1133, batch loss:2.295337981195189e-05, Training time:41387.94881463051
batch reward last col mean 2.5398180696356576e-06 first col mean 6.187967301229946e-06 all mean 2.60923707173788e-06
rl training, epoch2, iter0, batch190/1133, batch loss:7.328002084250329e-06, Training time:41415.12180733681
batch reward last col mean 6.676191333099268e-07 first col mean 7.161307848946308e-07 all mean 9.817396176003967e-07
rl training, epoch2, iter0, batch191/1133, batch loss:2.6677951154852053e-06, Training time:41442.37810444832
batch reward last col mean 1.4581320328943548e-06 first col mean 0.00013193294580560178 all mean 2.826305262715323e-06
rl training, epoch2, iter0, batch192/1133, batch loss:2.3119189336284762e-06, Training time:41469.39281630516
batch reward last col mean 0.002350581344217062 first col mean 1.8176001503888983e-06 all mean 0.0023120699916034937
rl training, epoch2, iter0, batch193/1133, batch loss:0.0032250152435153723, Training time:41497.17481946945
batch reward last col mean 1.4529521649819799e-05 first col mean 4.790032107848674e-06 all mean 1.5537601939286105e-05
rl training, epoch2, iter0, batch194/1133, batch loss:3.5098044463666156e-05, Training time:41525.342183589935
batch reward last col mean 2.119314558512997e-05 first col mean 2.3738697564112954e-05 all mean 2.12177856155904e-05
rl training, epoch2, iter0, batch195/1133, batch loss:3.41837658197619e-05, Training time:41552.863772153854
batch reward last col mean 1.0912437574006617e-05 first col mean 7.790607196511701e-05 all mean 1.1466235264379065e-05
rl training, epoch2, iter0, batch196/1133, batch loss:3.661636947072111e-05, Training time:41580.147446870804
batch reward last col mean 1.515287749498384e-06 first col mean 0.0006010291981510818 all mean 7.937633199617267e-06
rl training, epoch2, iter0, batch197/1133, batch loss:0.000525513372849673, Training time:41607.413826942444
batch reward last col mean 0.00046075048157945275 first col mean 0.00026245167828164995 all mean 0.00045759204658679664
rl training, epoch2, iter0, batch198/1133, batch loss:0.0009755047503858805, Training time:41634.887058496475
batch reward last col mean 0.00045040989061817527 first col mean 2.6360412448411807e-06 all mean 0.00043676167842932045
rl training, epoch2, iter0, batch199/1133, batch loss:0.0012054798426106572, Training time:41661.77319955826
batch reward last col mean 4.068078123964369e-05 first col mean 4.337999052950181e-05 all mean 4.3945430661551654e-05
rl training, epoch2, iter0, batch200/1133, batch loss:0.00014716261648572981, Training time:41688.94160819054
batch reward last col mean 0.0003794218064285815 first col mean 3.882322289427975e-06 all mean 0.0003722751571331173
rl training, epoch2, iter0, batch201/1133, batch loss:0.000696966890245676, Training time:41716.23998880386
batch reward last col mean 0.0011977197136729956 first col mean 1.3089291314827278e-05 all mean 0.0011686866637319326
rl training, epoch2, iter0, batch202/1133, batch loss:0.0020381093490868807, Training time:41743.48338985443
batch reward last col mean 4.3420564907137305e-05 first col mean 2.8320035198703408e-05 all mean 4.437606185092591e-05
rl training, epoch2, iter0, batch203/1133, batch loss:4.958417048328556e-05, Training time:41770.82467842102
batch reward last col mean 1.5226748928398592e-06 first col mean 8.37792958918726e-06 all mean 1.601088683855778e-06
rl training, epoch2, iter0, batch204/1133, batch loss:3.8378821045625955e-06, Training time:41798.062509298325
batch reward last col mean 7.329345407924848e-06 first col mean 0.00014605140313506126 all mean 1.2146068002039101e-05
rl training, epoch2, iter0, batch205/1133, batch loss:0.0004245667369104922, Training time:41825.25494790077
batch reward last col mean 0.0007059650961309671 first col mean 1.7091038898797706e-05 all mean 0.000672236317768693
rl training, epoch2, iter0, batch206/1133, batch loss:0.001147039933130145, Training time:41852.48371076584
batch reward last col mean 9.157267868431518e-07 first col mean 0.001563723897561431 all mean 1.6836749637150206e-05
rl training, epoch2, iter0, batch207/1133, batch loss:5.0672249926719815e-05, Training time:41879.720831632614
batch reward last col mean 6.742912228219211e-05 first col mean 1.8787557110044872e-06 all mean 6.643213419010863e-05
rl training, epoch2, iter0, batch208/1133, batch loss:0.00010259499686071649, Training time:41907.002239227295
batch reward last col mean 7.023954822216183e-07 first col mean 8.322368557855953e-06 all mean 8.722535085325944e-07
rl training, epoch2, iter0, batch209/1133, batch loss:3.1415222565556178e-06, Training time:41934.33413887024
batch reward last col mean 2.4652072170283645e-06 first col mean 1.3888625289837364e-05 all mean 2.7540897917788243e-06
rl training, epoch2, iter0, batch210/1133, batch loss:7.5285347520548385e-06, Training time:41961.50731420517
batch reward last col mean 1.3580071026808582e-05 first col mean 0.00012592683196999133 all mean 1.4905312127666548e-05
rl training, epoch2, iter0, batch211/1133, batch loss:3.246101550757885e-05, Training time:41988.9365875721
batch reward last col mean 0.00021971181558910757 first col mean 0.0003756526275537908 all mean 0.00022004469064995646
rl training, epoch2, iter0, batch212/1133, batch loss:0.0003679738147184253, Training time:42016.39096951485
batch reward last col mean 6.865900559205329e-06 first col mean 1.2546637663035654e-05 all mean 9.632470209908206e-06
rl training, epoch2, iter0, batch213/1133, batch loss:6.760437827324495e-05, Training time:42043.69006609917
batch reward last col mean 0.00012525980127975345 first col mean 6.690739155601477e-06 all mean 0.00012379697000142187
rl training, epoch2, iter0, batch214/1133, batch loss:0.0002817209460772574, Training time:42070.99076485634
batch reward last col mean 6.411732556443894e-06 first col mean 2.49977529165335e-06 all mean 6.636436410190072e-06
rl training, epoch2, iter0, batch215/1133, batch loss:3.9668535464443266e-05, Training time:42098.15244960785
batch reward last col mean 3.671187869258574e-06 first col mean 1.762401734595187e-05 all mean 3.912970441888319e-06
rl training, epoch2, iter0, batch216/1133, batch loss:1.7381549696438015e-05, Training time:42125.52078604698
batch reward last col mean 2.2059972252463922e-05 first col mean 0.0001418304891558364 all mean 5.564781167777255e-05
rl training, epoch2, iter0, batch217/1133, batch loss:0.0020680485758930445, Training time:42152.817558050156
batch reward last col mean 6.743678568454925e-06 first col mean 6.262499027798185e-06 all mean 6.717501037201146e-06
rl training, epoch2, iter0, batch218/1133, batch loss:1.0852626473933924e-05, Training time:42180.149151325226
batch reward last col mean 7.575154995720368e-06 first col mean 0.0001796016440493986 all mean 9.410677193955053e-06
rl training, epoch2, iter0, batch219/1133, batch loss:0.00035116056096740067, Training time:42207.44965195656
batch reward last col mean 6.656839104834944e-06 first col mean 2.701150515349582e-05 all mean 6.7714854594669305e-06
rl training, epoch2, iter0, batch220/1133, batch loss:8.245790922956076e-06, Training time:42234.6385884285
batch reward last col mean 8.395517397730146e-06 first col mean 1.9574330508476123e-05 all mean 1.054966742231045e-05
rl training, epoch2, iter0, batch221/1133, batch loss:1.8875813111662865e-05, Training time:42261.93891906738
batch reward last col mean 0.0003306611906737089 first col mean 2.281635943290894e-06 all mean 0.00031352206133306026
rl training, epoch2, iter0, batch222/1133, batch loss:0.0003604598168749362, Training time:42289.26085281372
batch reward last col mean 1.223579420184251e-05 first col mean 6.780649073334644e-06 all mean 1.3467059943650384e-05
rl training, epoch2, iter0, batch223/1133, batch loss:0.00016183398838620633, Training time:42316.59039878845
batch reward last col mean 2.2789829472458223e-06 first col mean 2.6013869501184672e-05 all mean 2.7703147225111024e-06
rl training, epoch2, iter0, batch224/1133, batch loss:4.349658411229029e-05, Training time:42343.52617907524
batch reward last col mean 2.364563897572225e-06 first col mean 2.104543091263622e-05 all mean 2.8463034595915815e-06
rl training, epoch2, iter0, batch225/1133, batch loss:4.043508670292795e-05, Training time:42370.63621878624
batch reward last col mean 5.1841252570739016e-05 first col mean 2.2556394469575025e-05 all mean 5.178626815904863e-05
rl training, epoch2, iter0, batch226/1133, batch loss:8.212418470066041e-05, Training time:42397.922365903854
batch reward last col mean 2.1211149032751564e-06 first col mean 4.198770329821855e-05 all mean 2.7166349809704116e-06
rl training, epoch2, iter0, batch227/1133, batch loss:1.1581199942156672e-05, Training time:42425.385026454926
batch reward last col mean 4.909183189738542e-05 first col mean 0.0007155659841373563 all mean 5.606317427009344e-05
rl training, epoch2, iter0, batch228/1133, batch loss:0.00023762100317981094, Training time:42452.9117398262
batch reward last col mean 1.2756327123497613e-06 first col mean 0.00015088618965819478 all mean 1.0091409421875142e-05
rl training, epoch2, iter0, batch229/1133, batch loss:0.00018987520888913423, Training time:42480.80685019493
batch reward last col mean 7.160427685448667e-06 first col mean 1.2334650818957016e-05 all mean 7.2903544605651405e-06
rl training, epoch2, iter0, batch230/1133, batch loss:1.2040697583870497e-05, Training time:42508.786086797714
batch reward last col mean 5.0639182518352754e-06 first col mean 5.1092789362883195e-05 all mean 5.6623043747094925e-06
rl training, epoch2, iter0, batch231/1133, batch loss:8.105036613414995e-06, Training time:42537.34815311432
batch reward last col mean 2.7697956284100655e-06 first col mean 7.032213488855632e-06 all mean 4.714150691143004e-06
rl training, epoch2, iter0, batch232/1133, batch loss:3.2271545933326706e-05, Training time:42566.83696937561
batch reward last col mean 0.0007225944427773356 first col mean 7.031624136288883e-06 all mean 0.0007072300068102777
rl training, epoch2, iter0, batch233/1133, batch loss:0.0012841535499319434, Training time:42594.81031751633
batch reward last col mean 0.00019622399122454226 first col mean 0.00010780079901451245 all mean 0.00019322817388456315
rl training, epoch2, iter0, batch234/1133, batch loss:0.0006225473480299115, Training time:42622.851197719574
batch reward last col mean 1.693780291134317e-06 first col mean 0.00026304571656510234 all mean 4.715193426818587e-06
rl training, epoch2, iter0, batch235/1133, batch loss:3.522467886796221e-05, Training time:42650.762209653854
batch reward last col mean 8.424132829532027e-06 first col mean 9.73564965534024e-05 all mean 1.7339729311061092e-05
rl training, epoch2, iter0, batch236/1133, batch loss:0.0002785523538477719, Training time:42679.50134205818
batch reward last col mean 1.3589938134828117e-06 first col mean 0.00020283930643927306 all mean 3.6242729493096704e-06
rl training, epoch2, iter0, batch237/1133, batch loss:2.1181658667046577e-05, Training time:42707.4139251709
batch reward last col mean 0.0001004232035484165 first col mean 1.999084588533151e-06 all mean 9.866617619991302e-05
rl training, epoch2, iter0, batch238/1133, batch loss:0.00017139762348961085, Training time:42735.11721992493
batch reward last col mean 1.9749584225792205e-06 first col mean 1.0934611964330543e-05 all mean 2.2503536456497386e-06
rl training, epoch2, iter0, batch239/1133, batch loss:1.1668016668409109e-05, Training time:42763.01958847046
batch reward last col mean 1.221423372044228e-05 first col mean 0.00024822287377901375 all mean 1.4464811101788655e-05
rl training, epoch2, iter0, batch240/1133, batch loss:3.060737799387425e-05, Training time:42791.047112226486
batch reward last col mean 8.007882570382208e-06 first col mean 0.00020551747002173215 all mean 1.1809719580924138e-05
rl training, epoch2, iter0, batch241/1133, batch loss:0.000129899664898403, Training time:42818.71037530899
batch reward last col mean 8.930574949772563e-06 first col mean 6.2347444327315316e-06 all mean 2.7947668058914132e-05
rl training, epoch2, iter0, batch242/1133, batch loss:0.0006143663194961846, Training time:42847.40484714508
batch reward last col mean 1.824158061936032e-05 first col mean 8.901616092771292e-05 all mean 5.344416058505885e-05
rl training, epoch2, iter0, batch243/1133, batch loss:0.00303826411254704, Training time:42875.83354949951
batch reward last col mean 1.8803229977493174e-05 first col mean 1.8439577615936287e-05 all mean 1.8774999261950143e-05
rl training, epoch2, iter0, batch244/1133, batch loss:1.013032942864811e-05, Training time:42904.66179203987
batch reward last col mean 1.7703205230645835e-05 first col mean 1.3239350664662197e-05 all mean 1.7746095181792043e-05
rl training, epoch2, iter0, batch245/1133, batch loss:5.30011675436981e-05, Training time:42932.29736328125
batch reward last col mean 2.2415450075641274e-05 first col mean 0.00010607529111439362 all mean 3.066399949602783e-05
rl training, epoch2, iter0, batch246/1133, batch loss:5.3433348512044176e-05, Training time:42960.23366045952
batch reward last col mean 1.6692259805495269e-06 first col mean 0.00043508264934644103 all mean 2.4342292817891575e-05
rl training, epoch2, iter0, batch247/1133, batch loss:0.0007573498878628016, Training time:42988.61923265457
batch reward last col mean 2.210603815910872e-05 first col mean 5.9432859416119754e-06 all mean 2.2035375877749175e-05
rl training, epoch2, iter0, batch248/1133, batch loss:4.254232771927491e-05, Training time:43016.78074502945
batch reward last col mean 2.9587770313810324e-06 first col mean 1.0600658242765348e-05 all mean 3.104530696873553e-05
rl training, epoch2, iter0, batch249/1133, batch loss:4.0691360482014716e-05, Training time:43045.527869701385
batch reward last col mean 4.412097041495144e-06 first col mean 0.0008598689455538988 all mean 1.310632342210738e-05
rl training, epoch2, iter0, batch250/1133, batch loss:5.457745373860234e-06, Training time:43073.01161003113
batch reward last col mean 5.956467703072121e-06 first col mean 4.264057497493923e-05 all mean 6.390842372638872e-06
rl training, epoch2, iter0, batch251/1133, batch loss:2.0316121663199738e-05, Training time:43100.79990720749
batch reward last col mean 2.793366184050683e-05 first col mean 6.169358584884321e-06 all mean 2.8504746296675876e-05
rl training, epoch2, iter0, batch252/1133, batch loss:8.100954437395558e-05, Training time:43129.43738603592
batch reward last col mean 6.384020525729284e-05 first col mean 1.1325174455123488e-05 all mean 6.272210885072127e-05
rl training, epoch2, iter0, batch253/1133, batch loss:3.1316583772422746e-05, Training time:43157.45225906372
batch reward last col mean 2.8234749152034055e-06 first col mean 9.138848326983862e-06 all mean 3.2124166864377912e-06
rl training, epoch2, iter0, batch254/1133, batch loss:1.5602094208588824e-05, Training time:43185.56719875336
batch reward last col mean 6.141031917650253e-05 first col mean 1.5032545888971072e-05 all mean 5.859047087142244e-05
rl training, epoch2, iter0, batch255/1133, batch loss:0.00018393828941043466, Training time:43213.67124462128
batch reward last col mean 2.734823829086963e-05 first col mean 9.882158337859437e-06 all mean 2.7033891456085257e-05
rl training, epoch2, iter0, batch256/1133, batch loss:2.4252611183328554e-05, Training time:43242.2003390789
batch reward last col mean 6.058279723220039e-06 first col mean 0.0017909306334331632 all mean 2.3963675630511716e-05
rl training, epoch2, iter0, batch257/1133, batch loss:1.604636236152146e-05, Training time:43269.96618556976
batch reward last col mean 0.0001381021284032613 first col mean 0.001995389349758625 all mean 0.00015700349467806518
rl training, epoch2, iter0, batch258/1133, batch loss:0.004131609573960304, Training time:43297.796857357025
batch reward last col mean 8.171252557076514e-05 first col mean 4.495552639127709e-05 all mean 8.138089469866827e-05
rl training, epoch2, iter0, batch259/1133, batch loss:0.00010153477342100814, Training time:43325.67650389671
batch reward last col mean 6.522244575535296e-07 first col mean 4.91210630571004e-05 all mean 1.1940505828533787e-06
rl training, epoch2, iter0, batch260/1133, batch loss:2.992964027725975e-06, Training time:43353.62595415115
batch reward last col mean 4.154428097535856e-06 first col mean 5.6682401918806136e-06 all mean 4.914544661005493e-06
rl training, epoch2, iter0, batch261/1133, batch loss:5.492848140420392e-05, Training time:43381.92330479622
batch reward last col mean 6.662955274805427e-05 first col mean 0.0002666540094651282 all mean 6.757727533113211e-05
rl training, epoch2, iter0, batch262/1133, batch loss:0.0004310887597966939, Training time:43410.67592430115
batch reward last col mean 3.68462351616472e-05 first col mean 0.0002870303578674793 all mean 3.9580772863700986e-05
rl training, epoch2, iter0, batch263/1133, batch loss:6.03531880187802e-05, Training time:43438.86192154884
batch reward last col mean 4.071543116879184e-06 first col mean 1.4635932529927231e-05 all mean 1.3741462680627592e-05
rl training, epoch2, iter0, batch264/1133, batch loss:0.001261292607523501, Training time:43467.11734175682
batch reward last col mean 3.1040199246490374e-05 first col mean 0.0013516314793378115 all mean 4.435190567164682e-05
rl training, epoch2, iter0, batch265/1133, batch loss:0.001989585580304265, Training time:43495.49310708046
batch reward last col mean 8.28523661766667e-06 first col mean 4.340959549153922e-06 all mean 8.194445399567485e-06
rl training, epoch2, iter0, batch266/1133, batch loss:5.880908247490879e-06, Training time:43523.699624061584
batch reward last col mean 2.6881123176281108e-06 first col mean 2.765483259281609e-06 all mean 2.7074941044702427e-06
rl training, epoch2, iter0, batch267/1133, batch loss:5.16907857672777e-06, Training time:43551.80681848526
batch reward last col mean 9.554753432894358e-07 first col mean 7.926274702185765e-05 all mean 1.3601718819700181e-05
rl training, epoch2, iter0, batch268/1133, batch loss:5.337854236131534e-05, Training time:43579.65192770958
batch reward last col mean 9.254642463929486e-06 first col mean 5.5176369642140344e-05 all mean 1.4176034710544627e-05
rl training, epoch2, iter0, batch269/1133, batch loss:5.1191022066632286e-05, Training time:43607.63703894615
batch reward last col mean 3.2240052405541064e-06 first col mean 3.326183286844753e-05 all mean 3.5830471460940316e-06
rl training, epoch2, iter0, batch270/1133, batch loss:1.2700410479737911e-05, Training time:43635.586178064346
batch reward last col mean 1.5319825479309657e-06 first col mean 2.241839320049621e-05 all mean 1.4062602531339508e-05
rl training, epoch2, iter0, batch271/1133, batch loss:0.0006756256916560233, Training time:43663.98540878296
batch reward last col mean 0.00501589197665453 first col mean 0.0019480352057144046 all mean 0.004751740489155054
rl training, epoch2, iter0, batch272/1133, batch loss:0.015656830742955208, Training time:43692.071622133255
batch reward last col mean 1.3264297194837127e-05 first col mean 2.604392466309946e-05 all mean 1.5653069567633793e-05
rl training, epoch2, iter0, batch273/1133, batch loss:0.000123500736663118, Training time:43719.89576148987
batch reward last col mean 7.985962611201103e-07 first col mean 1.6452073396067135e-05 all mean 1.4491253068626975e-06
rl training, epoch2, iter0, batch274/1133, batch loss:1.5657065887353383e-05, Training time:43747.876364946365
batch reward last col mean 0.00016082356160040945 first col mean 8.250970495282672e-06 all mean 0.00015847139002289623
rl training, epoch2, iter0, batch275/1133, batch loss:0.000183426498551853, Training time:43776.18846940994
batch reward last col mean 1.7271442629862577e-05 first col mean 8.352076292794663e-06 all mean 1.766386048984714e-05
rl training, epoch2, iter0, batch276/1133, batch loss:5.11975958943367e-05, Training time:43804.118903398514
batch reward last col mean 8.696683835296426e-07 first col mean 1.4005828234076034e-05 all mean 1.0652298669810989e-06
rl training, epoch2, iter0, batch277/1133, batch loss:1.4045242551219417e-06, Training time:43832.57780265808
batch reward last col mean 5.182548648008378e-07 first col mean 5.557780241360888e-06 all mean 5.771735800408351e-07
rl training, epoch2, iter0, batch278/1133, batch loss:6.793813440708618e-07, Training time:43860.992304325104
batch reward last col mean 2.9368160539888777e-05 first col mean 1.2959728337591514e-05 all mean 3.020974327228032e-05
rl training, epoch2, iter0, batch279/1133, batch loss:9.65885046753101e-05, Training time:43889.38675951958
batch reward last col mean 0.0019318325212225318 first col mean 0.00041500673978589475 all mean 0.0019200489623472095
rl training, epoch2, iter0, batch280/1133, batch loss:0.007564452942460775, Training time:43918.067145586014
batch reward last col mean 5.136628260515863e-06 first col mean 0.0002297895262017846 all mean 7.730903234914877e-06
rl training, epoch2, iter0, batch281/1133, batch loss:3.452686360105872e-05, Training time:43945.94770026207
batch reward last col mean 1.931646920638741e-06 first col mean 8.778021765465382e-06 all mean 4.982740392733831e-06
rl training, epoch2, iter0, batch282/1133, batch loss:5.7309167459607124e-05, Training time:43973.95247507095
batch reward last col mean 1.3041643796896096e-05 first col mean 5.202497050049715e-06 all mean 1.2799055184586905e-05
rl training, epoch2, iter0, batch283/1133, batch loss:1.2396208148857113e-05, Training time:44002.42387342453
batch reward last col mean 9.422405128134415e-06 first col mean 0.000316738267429173 all mean 2.062014573311899e-05
rl training, epoch2, iter0, batch284/1133, batch loss:0.001053103362210095, Training time:44030.813685417175
batch reward last col mean 3.0698189220856875e-05 first col mean 9.482397581450641e-05 all mean 3.133471545879729e-05
rl training, epoch2, iter0, batch285/1133, batch loss:3.692582686198875e-05, Training time:44059.869606256485
batch reward last col mean 0.00012609176337718964 first col mean 0.0008781299111433327 all mean 0.0001318937138421461
rl training, epoch2, iter0, batch286/1133, batch loss:0.0001509588910266757, Training time:44087.87400794029
batch reward last col mean 0.0005251709371805191 first col mean 0.001918282127007842 all mean 0.0005364012322388589
rl training, epoch2, iter0, batch287/1133, batch loss:0.0019750113133341074, Training time:44116.99923157692
batch reward last col mean 0.007137176115065813 first col mean 0.004967446438968182 all mean 0.007116167340427637
rl training, epoch2, iter0, batch288/1133, batch loss:0.013888280838727951, Training time:44144.56720519066
batch reward last col mean 0.0001732617529341951 first col mean 1.5162111594690941e-05 all mean 0.0001827679661801085
rl training, epoch2, iter0, batch289/1133, batch loss:0.0009465347975492477, Training time:44171.9588766098
batch reward last col mean 5.939587936154567e-06 first col mean 2.756431513262214e-06 all mean 8.031831384869292e-06
rl training, epoch2, iter0, batch290/1133, batch loss:2.5677380108390935e-05, Training time:44199.01090168953
batch reward last col mean 4.4071753109165e-06 first col mean 7.623237252118997e-06 all mean 5.320007403497584e-06
rl training, epoch2, iter0, batch291/1133, batch loss:3.7157929909881204e-05, Training time:44226.202065229416
batch reward last col mean 1.0382982509327121e-05 first col mean 0.0006049357471056283 all mean 1.7424570614821278e-05
rl training, epoch2, iter0, batch292/1133, batch loss:0.0001611578045412898, Training time:44253.41805243492
batch reward last col mean 2.70950113190338e-05 first col mean 1.337598223472014e-05 all mean 2.8039776225341484e-05
rl training, epoch2, iter0, batch293/1133, batch loss:0.0001079368666978553, Training time:44280.64343500137
batch reward last col mean 2.1589296011370607e-05 first col mean 1.3428506463242229e-05 all mean 2.2033211280358955e-05
rl training, epoch2, iter0, batch294/1133, batch loss:2.6814712327905e-05, Training time:44307.725093364716
batch reward last col mean 0.00021513109095394611 first col mean 1.358963163511362e-05 all mean 0.00020870477601420134
rl training, epoch2, iter0, batch295/1133, batch loss:0.00016993135795928538, Training time:44334.79195404053
batch reward last col mean 0.0001463076041545719 first col mean 0.000405029917601496 all mean 0.00014763382205273956
rl training, epoch2, iter0, batch296/1133, batch loss:0.0004938978236168623, Training time:44361.76687717438
batch reward last col mean 0.00011752972932299599 first col mean 2.0813588434975827e-06 all mean 0.00011501299741212279
rl training, epoch2, iter0, batch297/1133, batch loss:0.00013371233944781125, Training time:44388.9342815876
batch reward last col mean 5.063730554866197e-07 first col mean 1.7195474129039212e-06 all mean 7.169342097768094e-07
rl training, epoch2, iter0, batch298/1133, batch loss:1.8857024315366289e-06, Training time:44416.308135032654
batch reward last col mean 2.016824873862788e-05 first col mean 4.105025436729193e-05 all mean 2.6465384507901035e-05
rl training, epoch2, iter0, batch299/1133, batch loss:0.00030632788548246026, Training time:44443.50332069397
batch reward last col mean 2.1710116016038228e-06 first col mean 3.244441177230328e-05 all mean 8.603327842138242e-06
rl training, epoch2, iter0, batch300/1133, batch loss:0.00011374359746696427, Training time:44470.40007019043
batch reward last col mean 0.007680350914597511 first col mean 2.7203177523915656e-05 all mean 0.007463701069355011
rl training, epoch2, iter0, batch301/1133, batch loss:0.01383106131106615, Training time:44497.50148963928
batch reward last col mean 8.896096005628351e-06 first col mean 0.00024670682614669204 all mean 1.1410340448492207e-05
rl training, epoch2, iter0, batch302/1133, batch loss:1.6722589862183668e-05, Training time:44524.710968494415
batch reward last col mean 8.099133992800489e-06 first col mean 0.0001242303551407531 all mean 1.1034671842935495e-05
rl training, epoch2, iter0, batch303/1133, batch loss:4.381962207844481e-05, Training time:44551.96908783913
batch reward last col mean 8.119111953419633e-06 first col mean 7.711319994996302e-06 all mean 8.226767022279091e-06
rl training, epoch2, iter0, batch304/1133, batch loss:1.8907121557276696e-05, Training time:44579.14472031593
batch reward last col mean 0.0002468552556820214 first col mean 5.661294562742114e-05 all mean 0.0002428637963021174
rl training, epoch2, iter0, batch305/1133, batch loss:0.00013904066872783005, Training time:44606.27367448807
batch reward last col mean 4.111423550057225e-05 first col mean 0.0003848001069854945 all mean 4.47008314949926e-05
rl training, epoch2, iter0, batch306/1133, batch loss:4.048326445627026e-05, Training time:44633.28127741814
batch reward last col mean 1.720391992421355e-05 first col mean 0.00014647803618572652 all mean 2.2165500922710635e-05
rl training, epoch2, iter0, batch307/1133, batch loss:0.0003422268491704017, Training time:44660.340470314026
batch reward last col mean 3.35519143845886e-05 first col mean 0.0005043335258960724 all mean 3.9203940104926005e-05
rl training, epoch2, iter0, batch308/1133, batch loss:0.00022038324095774442, Training time:44688.20049738884
batch reward last col mean 0.00021551734243985265 first col mean 0.00018939533038064837 all mean 0.0002053099888144061
rl training, epoch2, iter0, batch309/1133, batch loss:0.00033005158184096217, Training time:44718.41434788704
batch reward last col mean 4.7603476559743285e-05 first col mean 0.00010820115858223289 all mean 4.831603291677311e-05
rl training, epoch2, iter0, batch310/1133, batch loss:8.921120752347633e-05, Training time:44745.62841582298
batch reward last col mean 1.4332029422803316e-05 first col mean 2.6382203941466287e-05 all mean 1.4730637303728145e-05
rl training, epoch2, iter0, batch311/1133, batch loss:3.4856635465985164e-05, Training time:44772.839796066284
batch reward last col mean 6.470490188803524e-05 first col mean 1.8888000340666622e-05 all mean 6.366205343510956e-05
rl training, epoch2, iter0, batch312/1133, batch loss:0.0001234952942468226, Training time:44800.01630139351
batch reward last col mean 0.0001296058326261118 first col mean 9.321416655438952e-06 all mean 0.00013331139052752405
rl training, epoch2, iter0, batch313/1133, batch loss:0.00039554867544211447, Training time:44827.17016363144
batch reward last col mean 2.006429531320464e-05 first col mean 0.00021827020100317895 all mean 2.1741469026892446e-05
rl training, epoch2, iter0, batch314/1133, batch loss:0.00011864975385833532, Training time:44854.368119716644
batch reward last col mean 2.9214925234555267e-05 first col mean 6.536362889164593e-06 all mean 4.861941852141172e-05
rl training, epoch2, iter0, batch315/1133, batch loss:0.0023756464943289757, Training time:44881.57172393799
batch reward last col mean 0.0003108428209088743 first col mean 5.8408736549608875e-06 all mean 0.0003027273342013359
rl training, epoch2, iter0, batch316/1133, batch loss:0.0004750041989609599, Training time:44908.82258272171
batch reward last col mean 8.631404853076674e-06 first col mean 3.6168305541650625e-06 all mean 9.448114724364132e-06
rl training, epoch2, iter0, batch317/1133, batch loss:1.2692295058513992e-05, Training time:44935.98944282532
batch reward last col mean 4.049387825943995e-06 first col mean 5.8485238696448505e-06 all mean 4.0575978346168995e-06
rl training, epoch2, iter0, batch318/1133, batch loss:3.0952171528042527e-06, Training time:44963.05401802063
batch reward last col mean 1.427466145287326e-06 first col mean 1.6519017663085833e-05 all mean 5.555959887715289e-06
rl training, epoch2, iter0, batch319/1133, batch loss:0.00036600837484002113, Training time:44990.22935628891
batch reward last col mean 1.6574884284636937e-05 first col mean 0.00023056694772094488 all mean 1.9124465325148776e-05
rl training, epoch2, iter0, batch320/1133, batch loss:3.18821839755401e-05, Training time:45017.2548596859
batch reward last col mean 0.003658343805000186 first col mean 1.5475308828172274e-05 all mean 0.0035458989441394806
rl training, epoch2, iter0, batch321/1133, batch loss:0.010137559846043587, Training time:45044.48391723633
batch reward last col mean 0.0011570975184440613 first col mean 3.427178398851538e-06 all mean 0.001122326822951436
rl training, epoch2, iter0, batch322/1133, batch loss:0.0032253798563033342, Training time:45071.64731478691
batch reward last col mean 1.4780158380744979e-05 first col mean 3.334732537041418e-05 all mean 2.1440080672618933e-05
rl training, epoch2, iter0, batch323/1133, batch loss:0.000424723606556654, Training time:45098.81891846657
batch reward last col mean 4.018730032839812e-05 first col mean 4.173704837739933e-06 all mean 3.974146238761023e-05
rl training, epoch2, iter0, batch324/1133, batch loss:4.4402935600373894e-05, Training time:45125.9377450943
batch reward last col mean 0.00010725318134063855 first col mean 0.00018195937445852906 all mean 0.00010768721404019743
rl training, epoch2, iter0, batch325/1133, batch loss:0.0001536288036732003, Training time:45153.044254779816
batch reward last col mean 1.565062120789662e-05 first col mean 0.00038748409133404493 all mean 2.353538184252102e-05
rl training, epoch2, iter0, batch326/1133, batch loss:0.0001896966714411974, Training time:45180.2000439167
batch reward last col mean 1.1133714906463865e-05 first col mean 6.0749669501092285e-05 all mean 1.4423552784137428e-05
rl training, epoch2, iter0, batch327/1133, batch loss:0.00010228651080979034, Training time:45207.333637714386
batch reward last col mean 4.867145617026836e-05 first col mean 0.0015906181652098894 all mean 6.635149475187063e-05
rl training, epoch2, iter0, batch328/1133, batch loss:0.0005558037082664669, Training time:45234.71812725067
batch reward last col mean 3.4086201594618615e-06 first col mean 1.4044588169781491e-05 all mean 3.6856779388472205e-06
rl training, epoch2, iter0, batch329/1133, batch loss:1.650918784434907e-05, Training time:45261.93358421326
batch reward last col mean 2.0808667613891885e-05 first col mean 0.0010307782795280218 all mean 3.457469574641436e-05
rl training, epoch2, iter0, batch330/1133, batch loss:0.0002851501922123134, Training time:45289.050589084625
batch reward last col mean 2.3601951397722587e-05 first col mean 0.00044093417818658054 all mean 2.8336562536424026e-05
rl training, epoch2, iter0, batch331/1133, batch loss:0.00015777090447954834, Training time:45316.2053296566
batch reward last col mean 2.3775937734171748e-05 first col mean 0.00024016032693907619 all mean 2.5762054065125994e-05
rl training, epoch2, iter0, batch332/1133, batch loss:2.9909970180597156e-05, Training time:45343.629883766174
batch reward last col mean 1.5494368881263654e-06 first col mean 0.00033736624754965305 all mean 9.38752964430023e-06
rl training, epoch2, iter0, batch333/1133, batch loss:0.0006274728802964091, Training time:45370.95595932007
batch reward last col mean 1.186633880934096e-06 first col mean 3.370023478055373e-06 all mean 1.2222535588080063e-06
rl training, epoch2, iter0, batch334/1133, batch loss:2.091147280225414e-06, Training time:45398.0749976635
batch reward last col mean 4.777371032105293e-06 first col mean 7.694876694586128e-05 all mean 5.821622835355811e-06
rl training, epoch2, iter0, batch335/1133, batch loss:1.9476730813039467e-05, Training time:45425.15913629532
batch reward last col mean 9.620676792110316e-06 first col mean 0.0001675714156590402 all mean 1.610253457329236e-05
rl training, epoch2, iter0, batch336/1133, batch loss:0.00018920162983704358, Training time:45452.360033512115
batch reward last col mean 1.3125088116794359e-05 first col mean 9.101582691073418e-05 all mean 2.7250296625425108e-05
rl training, epoch2, iter0, batch337/1133, batch loss:5.930285988142714e-05, Training time:45479.60556769371
batch reward last col mean 1.1917814845219254e-05 first col mean 1.7101585399359465e-05 all mean 1.166412857855903e-05
rl training, epoch2, iter0, batch338/1133, batch loss:2.1367626686696894e-05, Training time:45506.78363800049
batch reward last col mean 1.5210775927698705e-05 first col mean 0.0004789512022398412 all mean 2.0114126527914777e-05
rl training, epoch2, iter0, batch339/1133, batch loss:0.00036393682239577174, Training time:45533.97795057297
batch reward last col mean 4.764444747706875e-05 first col mean 0.0015026764012873173 all mean 6.388089968822896e-05
rl training, epoch2, iter0, batch340/1133, batch loss:0.00011852302122861147, Training time:45561.11601018906
batch reward last col mean 0.004848118871450424 first col mean 0.0005460007814690471 all mean 0.0047073098830878735
rl training, epoch2, iter0, batch341/1133, batch loss:0.008339731954038143, Training time:45588.4114382267
batch reward last col mean 4.248227924108505e-05 first col mean 0.0001493515446782112 all mean 4.693510345532559e-05
rl training, epoch2, iter0, batch342/1133, batch loss:6.404353916877881e-05, Training time:45615.69364786148
batch reward last col mean 1.5663360954931704e-06 first col mean 3.9496077079093084e-05 all mean 3.919982191291638e-06
rl training, epoch2, iter0, batch343/1133, batch loss:8.190752851078287e-06, Training time:45642.98334026337
batch reward last col mean 1.1893350801983615e-06 first col mean 4.9108548410004005e-05 all mean 1.8531125533627346e-05
rl training, epoch2, iter0, batch344/1133, batch loss:0.000729645078536123, Training time:45670.49601197243
batch reward last col mean 1.5952173271216452e-05 first col mean 0.0002752937434706837 all mean 1.839186552388128e-05
rl training, epoch2, iter0, batch345/1133, batch loss:2.5746763640199788e-05, Training time:45697.54461145401
batch reward last col mean 5.217300440563122e-06 first col mean 0.0002691162808332592 all mean 8.311602869071066e-06
rl training, epoch2, iter0, batch346/1133, batch loss:2.9998573154443875e-05, Training time:45724.829144239426
batch reward last col mean 0.002783810021355748 first col mean 1.782955223461613e-05 all mean 0.002727543469518423
rl training, epoch2, iter0, batch347/1133, batch loss:0.0035752977710217237, Training time:45751.998512506485
batch reward last col mean 0.0007647910388186574 first col mean 1.5332734619732946e-05 all mean 0.0007418919121846557
rl training, epoch2, iter0, batch348/1133, batch loss:0.001295307301916182, Training time:45779.25499033928
batch reward last col mean 9.45042756939074e-06 first col mean 0.00010155780182685703 all mean 1.0919105989160016e-05
rl training, epoch2, iter0, batch349/1133, batch loss:2.4105147531372495e-05, Training time:45806.401435136795
batch reward last col mean 3.8176913221832365e-05 first col mean 0.0002206999488407746 all mean 4.084538886672817e-05
rl training, epoch2, iter0, batch350/1133, batch loss:8.543591684428975e-05, Training time:45833.3464615345
batch reward last col mean 0.00023765768855810165 first col mean 0.0001182270425488241 all mean 0.00024396214575972408
rl training, epoch2, iter0, batch351/1133, batch loss:0.0015417193062603474, Training time:45860.57579302788
batch reward last col mean 7.14804582457873e-06 first col mean 4.665022061089985e-05 all mean 7.608186479046708e-06
rl training, epoch2, iter0, batch352/1133, batch loss:8.753252586757299e-06, Training time:45887.805194854736
batch reward last col mean 0.0006530166137963533 first col mean 4.30560321547091e-05 all mean 0.0006368665490299463
rl training, epoch2, iter0, batch353/1133, batch loss:0.0023220169823616743, Training time:45914.98204922676
batch reward last col mean 0.003519547637552023 first col mean 0.00044161369442008436 all mean 0.0034098653122782707
rl training, epoch2, iter0, batch354/1133, batch loss:0.0012800899567082524, Training time:45942.22310423851
batch reward last col mean 1.4190246474754531e-05 first col mean 3.9646265577175654e-06 all mean 1.3643153579323553e-05
rl training, epoch2, iter0, batch355/1133, batch loss:1.8432185243000276e-05, Training time:45969.23238778114
batch reward last col mean 0.0002674665302038193 first col mean 0.000666570442263037 all mean 0.0002684367645997554
rl training, epoch2, iter0, batch356/1133, batch loss:0.00042623415356501937, Training time:45996.42779660225
batch reward last col mean 1.3788600881525781e-05 first col mean 0.0007039451156742871 all mean 2.329671951883938e-05
rl training, epoch2, iter0, batch357/1133, batch loss:0.000151961125084199, Training time:46023.67704939842
batch reward last col mean 1.038886603055289e-05 first col mean 1.7787533579394221e-06 all mean 1.0322172784071881e-05
rl training, epoch2, iter0, batch358/1133, batch loss:1.0459162695042323e-05, Training time:46050.81032538414
batch reward last col mean 0.00017880227824207395 first col mean 0.0003140638582408428 all mean 0.0002380188088864088
rl training, epoch2, iter0, batch359/1133, batch loss:0.006252523045986891, Training time:46078.080036878586
batch reward last col mean 0.0024857043754309416 first col mean 1.4290110811998602e-05 all mean 0.002428250154480338
rl training, epoch2, iter0, batch360/1133, batch loss:0.003165642963722348, Training time:46105.02882218361
batch reward last col mean 7.275665848283097e-05 first col mean 8.597883424954489e-05 all mean 7.297884440049529e-05
rl training, epoch2, iter0, batch361/1133, batch loss:6.445468898164108e-05, Training time:46132.222141981125
batch reward last col mean 0.003792788600549102 first col mean 9.556391887599602e-05 all mean 0.003721729153767228
rl training, epoch2, iter0, batch362/1133, batch loss:0.0058267368003726006, Training time:46159.66702890396
batch reward last col mean 0.0010266717290505767 first col mean 1.3787694115308113e-05 all mean 0.0010150228627026081
rl training, epoch2, iter0, batch363/1133, batch loss:0.0005732442368753254, Training time:46187.035279750824
batch reward last col mean 0.00012066494673490524 first col mean 0.00025217971415258944 all mean 0.00013150260201655328
rl training, epoch2, iter0, batch364/1133, batch loss:0.0004345080815255642, Training time:46214.14372944832
batch reward last col mean 2.455251433275407e-06 first col mean 0.00018074963008984923 all mean 4.4345661081024446e-06
rl training, epoch2, iter0, batch365/1133, batch loss:3.981068857683567e-06, Training time:46241.287316560745
batch reward last col mean 4.323451889831631e-07 first col mean 1.3444716387311928e-05 all mean 7.899592446847237e-07
rl training, epoch2, iter0, batch366/1133, batch loss:4.0927161535364576e-06, Training time:46268.43850874901
batch reward last col mean 3.179266059305519e-06 first col mean 4.541594898910262e-05 all mean 5.611287178908242e-06
rl training, epoch2, iter0, batch367/1133, batch loss:1.2694129509327468e-05, Training time:46295.65163898468
batch reward last col mean 9.153480641543865e-05 first col mean 0.0007036690949462354 all mean 9.823073196457699e-05
rl training, epoch2, iter0, batch368/1133, batch loss:0.0006892035598866642, Training time:46322.98768925667
batch reward last col mean 1.4030697457201313e-05 first col mean 7.934295717859641e-05 all mean 4.977322168997489e-05
rl training, epoch2, iter0, batch369/1133, batch loss:0.0011197549756616354, Training time:46350.15910387039
batch reward last col mean 0.0008266599616035819 first col mean 9.470556506130379e-06 all mean 0.0007896082242950797
rl training, epoch2, iter0, batch370/1133, batch loss:0.0015654789749532938, Training time:46377.584233522415
batch reward last col mean 0.003447463735938072 first col mean 0.0016954600578173995 all mean 0.0034503135830163956
rl training, epoch2, iter0, batch371/1133, batch loss:0.004644130356609821, Training time:46404.70332407951
batch reward last col mean 1.383685685141245e-06 first col mean 2.7133675757795572e-05 all mean 2.263418764414382e-06
rl training, epoch2, iter0, batch372/1133, batch loss:3.476797792245634e-05, Training time:46432.032340765
batch reward last col mean 4.123298822378274e-06 first col mean 6.014148675603792e-05 all mean 4.903690751234535e-06
rl training, epoch2, iter0, batch373/1133, batch loss:3.4835808037314564e-05, Training time:46459.21897482872
batch reward last col mean 1.8263650417793542e-05 first col mean 2.765361568890512e-05 all mean 2.1628738977597095e-05
rl training, epoch2, iter0, batch374/1133, batch loss:0.0002249510434921831, Training time:46486.40252971649
batch reward last col mean 2.166119884350337e-06 first col mean 4.552841346594505e-06 all mean 5.5351680202875286e-05
rl training, epoch2, iter0, batch375/1133, batch loss:0.003743285546079278, Training time:46513.33032178879
batch reward last col mean 1.472818803449627e-05 first col mean 2.9016042390139773e-05 all mean 1.785636050044559e-05
rl training, epoch2, iter0, batch376/1133, batch loss:0.00035065863630734384, Training time:46540.45563364029
batch reward last col mean 1.8862633623939473e-06 first col mean 0.0004792003892362118 all mean 7.649858162039891e-06
rl training, epoch2, iter0, batch377/1133, batch loss:6.53666429570876e-05, Training time:46567.72211122513
batch reward last col mean 5.812402378069237e-05 first col mean 0.00015518825966864824 all mean 5.98913429712411e-05
rl training, epoch2, iter0, batch378/1133, batch loss:0.00010978346108458936, Training time:46594.929262161255
batch reward last col mean 8.978095866041258e-05 first col mean 0.00022267377062235028 all mean 9.730127203511074e-05
rl training, epoch2, iter0, batch379/1133, batch loss:0.0006124671199359, Training time:46622.111221551895
batch reward last col mean 4.030518539366312e-06 first col mean 4.6436285629170015e-05 all mean 4.495362190937158e-06
rl training, epoch2, iter0, batch380/1133, batch loss:4.371956947579747e-06, Training time:46649.17796087265
batch reward last col mean 0.00034142975346185267 first col mean 0.0003926220233552158 all mean 0.0003647370031103492
rl training, epoch2, iter0, batch381/1133, batch loss:0.003362505929544568, Training time:46676.222180366516
batch reward last col mean 4.7618422627238033e-07 first col mean 1.5982224795152433e-05 all mean 1.952061893462087e-06
rl training, epoch2, iter0, batch382/1133, batch loss:3.4813576348824427e-05, Training time:46703.42565250397
batch reward last col mean 6.827483593951911e-05 first col mean 0.0005261344485916197 all mean 8.849918231135234e-05
rl training, epoch2, iter0, batch383/1133, batch loss:0.0001933657913468778, Training time:46730.67945241928
batch reward last col mean 0.0014035371132194996 first col mean 4.126061321585439e-05 all mean 0.0013477969914674759
rl training, epoch2, iter0, batch384/1133, batch loss:0.0030874726362526417, Training time:46757.806978940964
batch reward last col mean 0.0001271754881599918 first col mean 5.315136149874888e-06 all mean 0.00012670247815549374
rl training, epoch2, iter0, batch385/1133, batch loss:0.0001644230360398069, Training time:46784.74939036369
batch reward last col mean 0.002238304354250431 first col mean 0.001977713080123067 all mean 0.0021632779389619827
rl training, epoch2, iter0, batch386/1133, batch loss:0.0012974190758541226, Training time:46811.87225294113
batch reward last col mean 1.7866790358311846e-06 first col mean 2.1352587282308377e-05 all mean 2.028380549745634e-06
rl training, epoch2, iter0, batch387/1133, batch loss:5.094603693578392e-06, Training time:46839.09931063652
batch reward last col mean 2.2068536054575816e-05 first col mean 0.0001518909994047135 all mean 2.3610296921106055e-05
rl training, epoch2, iter0, batch388/1133, batch loss:7.781795284245163e-05, Training time:46866.32037258148
batch reward last col mean 0.009757992811501026 first col mean 0.0005234564887359738 all mean 0.009490982629358768
rl training, epoch2, iter0, batch389/1133, batch loss:0.014045735821127892, Training time:46893.379807949066
batch reward last col mean 5.023905941925477e-06 first col mean 0.00017446637502871454 all mean 7.341179752984317e-06
rl training, epoch2, iter0, batch390/1133, batch loss:2.57672891166294e-05, Training time:46920.38319373131
batch reward last col mean 2.131795099558076e-06 first col mean 7.43880809750408e-05 all mean 8.878560038283467e-06
rl training, epoch2, iter0, batch391/1133, batch loss:0.0004618474922608584, Training time:46947.446748018265
batch reward last col mean 0.0003606214886531234 first col mean 0.0004220805421937257 all mean 0.00035647611366584897
rl training, epoch2, iter0, batch392/1133, batch loss:0.0008858649525791407, Training time:46974.496631383896
batch reward last col mean 7.867251042625867e-06 first col mean 4.436980816535652e-05 all mean 1.992516263271682e-05
rl training, epoch2, iter0, batch393/1133, batch loss:0.0006141567719168961, Training time:47001.65022158623
batch reward last col mean 0.003201583866029978 first col mean 0.0025373378302901983 all mean 0.003202608088031411
rl training, epoch2, iter0, batch394/1133, batch loss:0.006057616788893938, Training time:47028.80771660805
batch reward last col mean 0.0007013605791144073 first col mean 0.00021136549185030162 all mean 0.0006929605733603239
rl training, epoch2, iter0, batch395/1133, batch loss:0.0007369567756541073, Training time:47055.8344438076
batch reward last col mean 0.00025228672893717885 first col mean 5.6206172303063795e-06 all mean 0.00025003618793562055
rl training, epoch2, iter0, batch396/1133, batch loss:0.00034810497891157866, Training time:47082.94171190262
batch reward last col mean 1.2230815627845004e-05 first col mean 0.00015508588694501668 all mean 1.3798612599202897e-05
rl training, epoch2, iter0, batch397/1133, batch loss:3.9583726902492344e-05, Training time:47110.08452916145
batch reward last col mean 8.917263039620593e-05 first col mean 0.0003878189600072801 all mean 0.00010243741417070851
rl training, epoch2, iter0, batch398/1133, batch loss:0.00023113787756301463, Training time:47137.214416503906
batch reward last col mean 4.744115813082317e-06 first col mean 1.0049138836620841e-05 all mean 5.414258339442313e-06
rl training, epoch2, iter0, batch399/1133, batch loss:1.4232897228794172e-05, Training time:47164.31518697739
batch reward last col mean 0.0003028419450856745 first col mean 7.341130640270421e-06 all mean 0.0003083065093960613
rl training, epoch2, iter0, batch400/1133, batch loss:0.0015553731936961412, Training time:47191.2385699749
batch reward last col mean 1.2291990969970357e-05 first col mean 4.1014744056155905e-05 all mean 1.2818860341212712e-05
rl training, epoch2, iter0, batch401/1133, batch loss:4.777932190336287e-05, Training time:47218.24370932579
batch reward last col mean 0.0077156852930784225 first col mean 0.003650345141068101 all mean 0.007667869795113802
rl training, epoch2, iter0, batch402/1133, batch loss:0.017609883099794388, Training time:47245.30824637413
batch reward last col mean 0.002597498707473278 first col mean 3.4164386306656525e-05 all mean 0.00254776980727911
rl training, epoch2, iter0, batch403/1133, batch loss:0.001699513872154057, Training time:47272.565729141235
batch reward last col mean 3.638358975877054e-06 first col mean 8.943436114350334e-05 all mean 9.904014405037742e-06
rl training, epoch2, iter0, batch404/1133, batch loss:0.00012357512605376542, Training time:47299.55471611023
batch reward last col mean 1.4335839296109043e-05 first col mean 8.142090518958867e-05 all mean 1.5068199900269974e-05
rl training, epoch2, iter0, batch405/1133, batch loss:4.456792157725431e-05, Training time:47326.537739276886
batch reward last col mean 0.00019628129666671157 first col mean 0.0006738952361047268 all mean 0.00020062309340573847
rl training, epoch2, iter0, batch406/1133, batch loss:0.00042695141746662557, Training time:47353.66451716423
batch reward last col mean 0.0018478770507499576 first col mean 0.0015985156642273068 all mean 0.0018462183652445674
rl training, epoch2, iter0, batch407/1133, batch loss:0.0024236401077359915, Training time:47380.80679607391
batch reward last col mean 1.957623680937104e-05 first col mean 0.0016242146957665682 all mean 8.919761603465304e-05
rl training, epoch2, iter0, batch408/1133, batch loss:0.0016023179050534964, Training time:47407.935195207596
batch reward last col mean 1.462177806388354e-06 first col mean 0.0001187808156828396 all mean 3.757171043616836e-06
rl training, epoch2, iter0, batch409/1133, batch loss:7.2305351750401314e-06, Training time:47434.9077372551
batch reward last col mean 0.00012677481572609395 first col mean 7.506978363380767e-06 all mean 0.00012406325549818575
rl training, epoch2, iter0, batch410/1133, batch loss:8.190932567231357e-05, Training time:47462.074487924576
batch reward last col mean 0.00013216538354754448 first col mean 0.002350396243855357 all mean 0.00016044065705500543
rl training, epoch2, iter0, batch411/1133, batch loss:0.00045853431220166385, Training time:47489.23067188263
batch reward last col mean 2.3011263692751527e-05 first col mean 1.7478263544035144e-05 all mean 2.862936889869161e-05
rl training, epoch2, iter0, batch412/1133, batch loss:0.0002512514474801719, Training time:47516.304589509964
batch reward last col mean 0.0006203183438628912 first col mean 5.458419400383718e-05 all mean 0.0006173709407448769
rl training, epoch2, iter0, batch413/1133, batch loss:0.00024093748652376235, Training time:47543.38353037834
batch reward last col mean 1.9920949853258207e-05 first col mean 0.00347866746596992 all mean 5.512153074960224e-05
rl training, epoch2, iter0, batch414/1133, batch loss:0.0006003078306093812, Training time:47570.50205659866
batch reward last col mean 2.8997515073569957e-06 first col mean 0.002230668207630515 all mean 2.8787402698071674e-05
rl training, epoch2, iter0, batch415/1133, batch loss:0.0002388371212873608, Training time:47597.45797204971
batch reward last col mean 4.941489805787569e-06 first col mean 0.00033422576962038875 all mean 2.3735918148304336e-05
rl training, epoch2, iter0, batch416/1133, batch loss:0.001553421257995069, Training time:47624.56864094734
batch reward last col mean 0.00038121012039482594 first col mean 7.29917737771757e-05 all mean 0.00038943468825891614
rl training, epoch2, iter0, batch417/1133, batch loss:0.0020657898858189583, Training time:47651.75265169144
batch reward last col mean 2.160301482945215e-05 first col mean 2.6928599254461005e-05 all mean 2.388057873758953e-05
rl training, epoch2, iter0, batch418/1133, batch loss:0.00023253141262102872, Training time:47678.966549396515
batch reward last col mean 2.9389575502136722e-06 first col mean 0.001508099609054625 all mean 3.834543895209208e-05
rl training, epoch2, iter0, batch419/1133, batch loss:0.00040549220284447074, Training time:47706.080067873
batch reward last col mean 0.0014644409529864788 first col mean 0.002899657469242811 all mean 0.0014722297200933099
rl training, epoch2, iter0, batch420/1133, batch loss:0.002836499596014619, Training time:47733.004642248154
batch reward last col mean 0.0004471410939004272 first col mean 0.0030850006733089685 all mean 0.000479519076179713
rl training, epoch2, iter0, batch421/1133, batch loss:0.0019641953986138105, Training time:47760.14358854294
batch reward last col mean 0.012238976545631886 first col mean 0.010755694471299648 all mean 0.012217451818287373
rl training, epoch2, iter0, batch422/1133, batch loss:0.011334149166941643, Training time:47787.22182250023
batch reward last col mean 0.006794806569814682 first col mean 0.002065188018605113 all mean 0.006574953440576792
rl training, epoch2, iter0, batch423/1133, batch loss:0.009892378933727741, Training time:47814.305580854416
batch reward last col mean 0.00013305929314810783 first col mean 0.001419850974343717 all mean 0.00014734828437212855
rl training, epoch2, iter0, batch424/1133, batch loss:0.0002771108993329108, Training time:47841.35100221634
batch reward last col mean 0.002608372364193201 first col mean 0.0022458755411207676 all mean 0.002599431434646249
rl training, epoch2, iter0, batch425/1133, batch loss:0.0020005980040878057, Training time:47868.47243857384
batch reward last col mean 0.009908242151141167 first col mean 0.007997188717126846 all mean 0.009899021126329899
rl training, epoch2, iter0, batch426/1133, batch loss:0.003132968908175826, Training time:47895.56358742714
batch reward last col mean 0.00620685052126646 first col mean 0.004702742677181959 all mean 0.006166108883917332
rl training, epoch2, iter0, batch427/1133, batch loss:0.00909639522433281, Training time:47922.59095478058
batch reward last col mean 3.7283120946085546e-06 first col mean 3.176083555445075e-05 all mean 1.181344941869611e-05
rl training, epoch2, iter0, batch428/1133, batch loss:0.0003393431834410876, Training time:47949.61564517021
batch reward last col mean 0.006384092848747969 first col mean 0.009458718821406364 all mean 0.006426151376217604
rl training, epoch2, iter0, batch429/1133, batch loss:0.0022437043953686953, Training time:47976.64689421654
batch reward last col mean 0.0010410581016913056 first col mean 0.0006883059977553785 all mean 0.0010394449345767498
rl training, epoch2, iter0, batch430/1133, batch loss:0.0007924878154881299, Training time:48003.61136889458
batch reward last col mean 0.0011976944515481591 first col mean 0.002125985687598586 all mean 0.0012156773591414094
rl training, epoch2, iter0, batch431/1133, batch loss:0.00250025256536901, Training time:48030.65742826462
batch reward last col mean 0.007293251808732748 first col mean 0.005617924965918064 all mean 0.007284211926162243
rl training, epoch2, iter0, batch432/1133, batch loss:0.003634872380644083, Training time:48057.72862458229
batch reward last col mean 0.007157072890549898 first col mean 0.007461806759238243 all mean 0.00716284429654479
rl training, epoch2, iter0, batch433/1133, batch loss:0.001651340862736106, Training time:48085.00089144707
batch reward last col mean 1.5325551430578344e-05 first col mean 0.002018641447648406 all mean 4.457544127944857e-05
rl training, epoch2, iter0, batch434/1133, batch loss:0.0008440505480393767, Training time:48112.18051147461
batch reward last col mean 0.02032153680920601 first col mean 0.017420686781406403 all mean 0.02030445821583271
rl training, epoch2, iter0, batch435/1133, batch loss:0.023354601114988327, Training time:48139.12341785431
batch reward last col mean 0.0007620708784088492 first col mean 0.0011649110820144415 all mean 0.0007827254594303668
rl training, epoch2, iter0, batch436/1133, batch loss:0.0004908646224066615, Training time:48166.24773359299
batch reward last col mean 0.010822421871125698 first col mean 0.01065068505704403 all mean 0.010811993852257729
rl training, epoch2, iter0, batch437/1133, batch loss:0.0024372562766075134, Training time:48193.41749048233
batch reward last col mean 0.03179088979959488 first col mean 0.02655777707695961 all mean 0.031691744923591614
rl training, epoch2, iter0, batch438/1133, batch loss:0.01822413131594658, Training time:48220.55905652046
batch reward last col mean 1.786514803825412e-05 first col mean 6.40196813037619e-05 all mean 1.853758112702053e-05
rl training, epoch2, iter0, batch439/1133, batch loss:4.439921394805424e-05, Training time:48247.54867839813
batch reward last col mean 0.0043434579856693745 first col mean 0.004636888392269611 all mean 0.004357169847935438
rl training, epoch2, iter0, batch440/1133, batch loss:0.0009795367950573564, Training time:48274.5904815197
batch reward last col mean 0.0013269803021103144 first col mean 0.003316024551168084 all mean 0.0013652320485562086
rl training, epoch2, iter0, batch441/1133, batch loss:0.0015337017830461264, Training time:48301.7054502964
batch reward last col mean 0.018075767904520035 first col mean 0.014402267523109913 all mean 0.018036136403679848
rl training, epoch2, iter0, batch442/1133, batch loss:0.00768186105415225, Training time:48328.75895404816
batch reward last col mean 0.006855566054582596 first col mean 0.007324206177145243 all mean 0.006872185971587896
rl training, epoch2, iter0, batch443/1133, batch loss:0.0062098428606987, Training time:48355.80499410629
batch reward last col mean 0.02607390098273754 first col mean 0.027889445424079895 all mean 0.02614794857800007
rl training, epoch2, iter0, batch444/1133, batch loss:0.00925750657916069, Training time:48382.781905174255
batch reward last col mean 0.01183120533823967 first col mean 0.014439602382481098 all mean 0.011833510361611843
rl training, epoch2, iter0, batch445/1133, batch loss:0.00466738548129797, Training time:48409.79920196533
batch reward last col mean 0.010671596974134445 first col mean 0.0068953679874539375 all mean 0.010626289993524551
rl training, epoch2, iter0, batch446/1133, batch loss:0.006164100021123886, Training time:48436.88556599617
batch reward last col mean 0.023915104568004608 first col mean 0.024876385927200317 all mean 0.02394302934408188
rl training, epoch2, iter0, batch447/1133, batch loss:0.0024480284191668034, Training time:48463.96159863472
batch reward last col mean 0.02041349746286869 first col mean 0.020147591829299927 all mean 0.02042444236576557
rl training, epoch2, iter0, batch448/1133, batch loss:0.006825381424278021, Training time:48491.068284749985
batch reward last col mean 0.002344649052247405 first col mean 0.0011088608298450708 all mean 0.0023077086079865694
rl training, epoch2, iter0, batch449/1133, batch loss:0.004626282025128603, Training time:48518.08697938919
batch reward last col mean 0.023105479776859283 first col mean 0.023014148697257042 all mean 0.023119032382965088
rl training, epoch2, iter0, batch450/1133, batch loss:0.009102098643779755, Training time:48545.067415714264
batch reward last col mean 0.013499340042471886 first col mean 0.010360999032855034 all mean 0.013363481499254704
rl training, epoch2, iter0, batch451/1133, batch loss:0.00825690571218729, Training time:48572.14479851723
batch reward last col mean 0.017952121794223785 first col mean 0.01754702813923359 all mean 0.017945004627108574
rl training, epoch2, iter0, batch452/1133, batch loss:0.008608631789684296, Training time:48599.27406144142
batch reward last col mean 0.012237810529768467 first col mean 0.013438519090414047 all mean 0.012249493971467018
rl training, epoch2, iter0, batch453/1133, batch loss:0.0006031324155628681, Training time:48626.472841739655
batch reward last col mean 0.02544320560991764 first col mean 0.027847930788993835 all mean 0.025498351082205772
rl training, epoch2, iter0, batch454/1133, batch loss:0.017819445580244064, Training time:48653.46204209328
batch reward last col mean 0.029777368530631065 first col mean 0.01991662010550499 all mean 0.02964375726878643
rl training, epoch2, iter0, batch455/1133, batch loss:0.017380429431796074, Training time:48680.4984357357
batch reward last col mean 0.020625079050660133 first col mean 0.015774210914969444 all mean 0.020580440759658813
rl training, epoch2, iter0, batch456/1133, batch loss:0.0033732010051608086, Training time:48707.64661049843
batch reward last col mean 0.027187779545783997 first col mean 0.028504686430096626 all mean 0.027221476659178734
rl training, epoch2, iter0, batch457/1133, batch loss:0.012074601836502552, Training time:48735.0358543396
batch reward last col mean 0.014015239663422108 first col mean 0.015653790906071663 all mean 0.014037970453500748
rl training, epoch2, iter0, batch458/1133, batch loss:0.007021070923656225, Training time:48761.92624044418
batch reward last col mean 0.05830475315451622 first col mean 0.061206210404634476 all mean 0.058390386402606964
rl training, epoch2, iter0, batch459/1133, batch loss:0.03854361176490784, Training time:48789.05396723747
batch reward last col mean 0.07383255660533905 first col mean 0.07315729558467865 all mean 0.07386791706085205
rl training, epoch2, iter0, batch460/1133, batch loss:0.11144418269395828, Training time:48815.85887551308
batch reward last col mean 0.051835350692272186 first col mean 0.046857915818691254 all mean 0.051796190440654755
rl training, epoch2, iter0, batch461/1133, batch loss:0.052744895219802856, Training time:48842.77637553215
batch reward last col mean 0.042830031365156174 first col mean 0.04954548925161362 all mean 0.043021660298109055
rl training, epoch2, iter0, batch462/1133, batch loss:0.021497653797268867, Training time:48869.696654081345
batch reward last col mean 0.04764045029878616 first col mean 0.049989793449640274 all mean 0.04766383394598961
rl training, epoch2, iter0, batch463/1133, batch loss:0.023519426584243774, Training time:48896.806643009186
batch reward last col mean 0.009525279514491558 first col mean 0.010991441085934639 all mean 0.009536638855934143
rl training, epoch2, iter0, batch464/1133, batch loss:0.0033851368352770805, Training time:48923.79064369202
batch reward last col mean 0.02823973260819912 first col mean 0.03221751004457474 all mean 0.02837410382926464
rl training, epoch2, iter0, batch465/1133, batch loss:0.017528101801872253, Training time:48950.805757284164
batch reward last col mean 0.021440766751766205 first col mean 0.020147759467363358 all mean 0.021432416513562202
rl training, epoch2, iter0, batch466/1133, batch loss:0.02218886837363243, Training time:48977.96607208252
batch reward last col mean 0.01863468997180462 first col mean 0.022412296384572983 all mean 0.01864725910127163
rl training, epoch2, iter0, batch467/1133, batch loss:0.00849736575037241, Training time:49005.13336968422
batch reward last col mean 0.04671670123934746 first col mean 0.04536696523427963 all mean 0.04667966440320015
rl training, epoch2, iter0, batch468/1133, batch loss:0.015926353633403778, Training time:49032.250774145126
batch reward last col mean 0.027278287336230278 first col mean 0.02706374041736126 all mean 0.027311695739626884
rl training, epoch2, iter0, batch469/1133, batch loss:0.017028775066137314, Training time:49059.27783226967
batch reward last col mean 0.03892119601368904 first col mean 0.03956596553325653 all mean 0.03890279307961464
rl training, epoch2, iter0, batch470/1133, batch loss:0.015820994973182678, Training time:49086.26427721977
batch reward last col mean 0.021761925891041756 first col mean 0.022578727453947067 all mean 0.021789535880088806
rl training, epoch2, iter0, batch471/1133, batch loss:0.011996996589004993, Training time:49113.291221380234
batch reward last col mean 0.02722424641251564 first col mean 0.030657827854156494 all mean 0.027243802323937416
rl training, epoch2, iter0, batch472/1133, batch loss:0.011796532198786736, Training time:49140.37533330917
batch reward last col mean 0.04766783490777016 first col mean 0.04088292270898819 all mean 0.04753055050969124
rl training, epoch2, iter0, batch473/1133, batch loss:0.01999361254274845, Training time:49167.41294193268
batch reward last col mean 0.027299994602799416 first col mean 0.028678258880972862 all mean 0.02734028361737728
rl training, epoch2, iter0, batch474/1133, batch loss:0.017619317397475243, Training time:49194.42963433266
batch reward last col mean 0.04222198575735092 first col mean 0.04060763120651245 all mean 0.042181987315416336
rl training, epoch2, iter0, batch475/1133, batch loss:0.01010502316057682, Training time:49221.46117854118
batch reward last col mean 0.031040508300065994 first col mean 0.02736707776784897 all mean 0.03093893826007843
rl training, epoch2, iter0, batch476/1133, batch loss:0.009527411311864853, Training time:49248.491834163666
batch reward last col mean 0.02668626606464386 first col mean 0.02425197698175907 all mean 0.026666831225156784
rl training, epoch2, iter0, batch477/1133, batch loss:0.009063711389899254, Training time:49275.660365104675
batch reward last col mean 0.019004588946700096 first col mean 0.0166592039167881 all mean 0.018987104296684265
rl training, epoch2, iter0, batch478/1133, batch loss:0.00773662282153964, Training time:49302.74598503113
batch reward last col mean 0.04378076270222664 first col mean 0.04336002841591835 all mean 0.043868232518434525
rl training, epoch2, iter0, batch479/1133, batch loss:0.023751363158226013, Training time:49329.75522542
batch reward last col mean 0.05042455345392227 first col mean 0.04817282408475876 all mean 0.05038008838891983
rl training, epoch2, iter0, batch480/1133, batch loss:0.012795193120837212, Training time:49356.66872763634
batch reward last col mean 0.02969626896083355 first col mean 0.027678467333316803 all mean 0.029569759964942932
rl training, epoch2, iter0, batch481/1133, batch loss:0.011979053728282452, Training time:49383.688737630844
batch reward last col mean 0.029023712500929832 first col mean 0.03157249465584755 all mean 0.029029108583927155
rl training, epoch2, iter0, batch482/1133, batch loss:0.009618991985917091, Training time:49410.88078260422
batch reward last col mean 0.02604539319872856 first col mean 0.029575716704130173 all mean 0.026162711903452873
rl training, epoch2, iter0, batch483/1133, batch loss:0.007649985607713461, Training time:49438.02156329155
batch reward last col mean 0.05472178012132645 first col mean 0.05621328949928284 all mean 0.054758381098508835
rl training, epoch2, iter0, batch484/1133, batch loss:0.03422538936138153, Training time:49465.14939379692
batch reward last col mean 0.08716711401939392 first col mean 0.08567848056554794 all mean 0.08709146827459335
rl training, epoch2, iter0, batch485/1133, batch loss:0.030519600957632065, Training time:49491.982283592224
batch reward last col mean 0.038002535700798035 first col mean 0.041955217719078064 all mean 0.03810471296310425
rl training, epoch2, iter0, batch486/1133, batch loss:0.016976501792669296, Training time:49518.82080936432
batch reward last col mean 0.0495818667113781 first col mean 0.058569055050611496 all mean 0.04996875673532486
rl training, epoch2, iter0, batch487/1133, batch loss:0.028203213587403297, Training time:49545.74327588081
batch reward last col mean 0.053624626249074936 first col mean 0.05570243299007416 all mean 0.053662415593862534
rl training, epoch2, iter0, batch488/1133, batch loss:0.018494611606001854, Training time:49572.6483104229
batch reward last col mean 0.04360225424170494 first col mean 0.042747437953948975 all mean 0.043550752103328705
rl training, epoch2, iter0, batch489/1133, batch loss:0.033018723130226135, Training time:49600.06040287018
batch reward last col mean 0.07707659900188446 first col mean 0.07092347741127014 all mean 0.07697183638811111
rl training, epoch2, iter0, batch490/1133, batch loss:0.03244996443390846, Training time:49626.84080982208
batch reward last col mean 0.07980524003505707 first col mean 0.07963843643665314 all mean 0.07990134507417679
rl training, epoch2, iter0, batch491/1133, batch loss:0.026410957798361778, Training time:49653.997378110886
batch reward last col mean 0.060438044369220734 first col mean 0.06083192676305771 all mean 0.060452643781900406
rl training, epoch2, iter0, batch492/1133, batch loss:0.02175084687769413, Training time:49681.202075481415
batch reward last col mean 0.036793120205402374 first col mean 0.035764411091804504 all mean 0.03683792054653168
rl training, epoch2, iter0, batch493/1133, batch loss:0.014637397602200508, Training time:49708.552953243256
batch reward last col mean 0.06809055805206299 first col mean 0.06744760274887085 all mean 0.06808073818683624
rl training, epoch2, iter0, batch494/1133, batch loss:0.017485305666923523, Training time:49735.78559923172
batch reward last col mean 0.055044032633304596 first col mean 0.05487648397684097 all mean 0.055047787725925446
rl training, epoch2, iter0, batch495/1133, batch loss:0.010191272012889385, Training time:49763.096237659454
batch reward last col mean 0.04640324413776398 first col mean 0.046407055109739304 all mean 0.04653662070631981
rl training, epoch2, iter0, batch496/1133, batch loss:0.008655786514282227, Training time:49790.12753486633
batch reward last col mean 0.056237127631902695 first col mean 0.048708103597164154 all mean 0.05600564554333687
rl training, epoch2, iter0, batch497/1133, batch loss:0.015363669022917747, Training time:49817.34939932823
batch reward last col mean 0.04681713879108429 first col mean 0.051856301724910736 all mean 0.04690945893526077
rl training, epoch2, iter0, batch498/1133, batch loss:0.007412762846797705, Training time:49844.64437413216
batch reward last col mean 0.0568120963871479 first col mean 0.05750076472759247 all mean 0.05683445557951927
rl training, epoch2, iter0, batch499/1133, batch loss:0.01782182790338993, Training time:49871.936890125275
batch reward last col mean 0.03833314776420593 first col mean 0.03893832117319107 all mean 0.0383644625544548
rl training, epoch2, iter0, batch500/1133, batch loss:0.0069367666728794575, Training time:49899.3522810936
batch reward last col mean 0.05949679762125015 first col mean 0.058589670807123184 all mean 0.05950236693024635
rl training, epoch2, iter0, batch501/1133, batch loss:0.007839559577405453, Training time:49926.50581932068
batch reward last col mean 0.07094122469425201 first col mean 0.0715181827545166 all mean 0.07097041606903076
rl training, epoch2, iter0, batch502/1133, batch loss:0.009665564633905888, Training time:49953.7454457283
batch reward last col mean 0.11419875919818878 first col mean 0.11706646531820297 all mean 0.11423883587121964
rl training, epoch2, iter0, batch503/1133, batch loss:0.02597624436020851, Training time:49981.03588581085
batch reward last col mean 0.04404369741678238 first col mean 0.04556058347225189 all mean 0.044086914509534836
rl training, epoch2, iter0, batch504/1133, batch loss:0.006767010781913996, Training time:50008.306044340134
batch reward last col mean 0.07913484424352646 first col mean 0.07694587856531143 all mean 0.07908172160387039
rl training, epoch2, iter0, batch505/1133, batch loss:0.009086813777685165, Training time:50035.512994766235
batch reward last col mean 0.08373439311981201 first col mean 0.0872931256890297 all mean 0.08381521701812744
rl training, epoch2, iter0, batch506/1133, batch loss:0.018169889226555824, Training time:50062.76349401474
batch reward last col mean 0.041116852313280106 first col mean 0.04061993956565857 all mean 0.04111053794622421
rl training, epoch2, iter0, batch507/1133, batch loss:0.006872493773698807, Training time:50089.84743261337
batch reward last col mean 0.03670699894428253 first col mean 0.039021722972393036 all mean 0.03674595430493355
rl training, epoch2, iter0, batch508/1133, batch loss:0.007409234996885061, Training time:50117.37373542786
batch reward last col mean 0.049156852066516876 first col mean 0.0500517375767231 all mean 0.049162812530994415
rl training, epoch2, iter0, batch509/1133, batch loss:0.004921114072203636, Training time:50144.59907054901
batch reward last col mean 0.0843581035733223 first col mean 0.085207499563694 all mean 0.08436410874128342
rl training, epoch2, iter0, batch510/1133, batch loss:0.01858002506196499, Training time:50171.7324283123
batch reward last col mean 0.04610603302717209 first col mean 0.04322578012943268 all mean 0.04605965316295624
rl training, epoch2, iter0, batch511/1133, batch loss:0.007745188660919666, Training time:50198.77638506889
batch reward last col mean 0.02820049598813057 first col mean 0.029094964265823364 all mean 0.02822374552488327
rl training, epoch2, iter0, batch512/1133, batch loss:0.004029032774269581, Training time:50225.6147415638
batch reward last col mean 0.0549275204539299 first col mean 0.04800938814878464 all mean 0.05478888750076294
rl training, epoch2, iter0, batch513/1133, batch loss:0.021039268001914024, Training time:50252.50552845001
batch reward last col mean 0.040026552975177765 first col mean 0.03640894964337349 all mean 0.04000592976808548
rl training, epoch2, iter0, batch514/1133, batch loss:0.009542782790958881, Training time:50279.30405306816
batch reward last col mean 0.05233781039714813 first col mean 0.0512486957013607 all mean 0.052310746163129807
rl training, epoch2, iter0, batch515/1133, batch loss:0.010252206586301327, Training time:50306.01762795448
batch reward last col mean 0.04651239514350891 first col mean 0.046269357204437256 all mean 0.046544961631298065
rl training, epoch2, iter0, batch516/1133, batch loss:0.012686757370829582, Training time:50333.005066394806
batch reward last col mean 0.046019911766052246 first col mean 0.05455029755830765 all mean 0.04614921659231186
rl training, epoch2, iter0, batch517/1133, batch loss:0.01730963960289955, Training time:50360.15118813515
batch reward last col mean 0.025608042255043983 first col mean 0.0281415693461895 all mean 0.025661712512373924
rl training, epoch2, iter0, batch518/1133, batch loss:0.015930872410535812, Training time:50387.20230436325
batch reward last col mean 0.0875939205288887 first col mean 0.0809054896235466 all mean 0.0874628946185112
rl training, epoch2, iter0, batch519/1133, batch loss:0.02679704688489437, Training time:50414.200033426285
batch reward last col mean 0.04824155196547508 first col mean 0.04934384673833847 all mean 0.04823656752705574
rl training, epoch2, iter0, batch520/1133, batch loss:0.00851211603730917, Training time:50441.20362019539
batch reward last col mean 0.09178013354539871 first col mean 0.09061740338802338 all mean 0.0917760506272316
rl training, epoch2, iter0, batch521/1133, batch loss:0.022770261391997337, Training time:50468.40673780441
batch reward last col mean 0.04975065961480141 first col mean 0.05573214590549469 all mean 0.0498616062104702
rl training, epoch2, iter0, batch522/1133, batch loss:0.010299325920641422, Training time:50495.733358860016
batch reward last col mean 0.07102825492620468 first col mean 0.06321898847818375 all mean 0.07078880071640015
rl training, epoch2, iter0, batch523/1133, batch loss:0.023155037313699722, Training time:50523.0467338562
batch reward last col mean 0.06272868812084198 first col mean 0.06364088505506516 all mean 0.06274107843637466
rl training, epoch2, iter0, batch524/1133, batch loss:0.01647239178419113, Training time:50550.31633734703
batch reward last col mean 0.06246594712138176 first col mean 0.061369720846414566 all mean 0.062448885291814804
rl training, epoch2, iter0, batch525/1133, batch loss:0.013380789197981358, Training time:50577.57726812363
batch reward last col mean 0.062063246965408325 first col mean 0.06341555714607239 all mean 0.06207674741744995
rl training, epoch2, iter0, batch526/1133, batch loss:0.015266615897417068, Training time:50604.92769932747
batch reward last col mean 0.04400857537984848 first col mean 0.045464299619197845 all mean 0.04406603425741196
rl training, epoch2, iter0, batch527/1133, batch loss:0.015420534648001194, Training time:50632.315296411514
batch reward last col mean 0.06181132048368454 first col mean 0.05935171991586685 all mean 0.06175960972905159
rl training, epoch2, iter0, batch528/1133, batch loss:0.02010066621005535, Training time:50659.57549524307
batch reward last col mean 0.07260816544294357 first col mean 0.07132869958877563 all mean 0.07258009910583496
rl training, epoch2, iter0, batch529/1133, batch loss:0.019462628290057182, Training time:50687.00645852089
batch reward last col mean 0.0738564282655716 first col mean 0.07374885678291321 all mean 0.07382675260305405
rl training, epoch2, iter0, batch530/1133, batch loss:0.031468216329813004, Training time:50714.30603146553
batch reward last col mean 0.03775322437286377 first col mean 0.040637608617544174 all mean 0.03783094510436058
rl training, epoch2, iter0, batch531/1133, batch loss:0.008840236812829971, Training time:50741.85032081604
batch reward last col mean 0.05264347046613693 first col mean 0.05211330205202103 all mean 0.05266546830534935
rl training, epoch2, iter0, batch532/1133, batch loss:0.011458056047558784, Training time:50769.501865148544
batch reward last col mean 0.10232993215322495 first col mean 0.09180750697851181 all mean 0.10183961689472198
rl training, epoch2, iter0, batch533/1133, batch loss:0.054282188415527344, Training time:50797.085317373276
batch reward last col mean 0.06528881937265396 first col mean 0.06536952406167984 all mean 0.06546299159526825
rl training, epoch2, iter0, batch534/1133, batch loss:0.023500820621848106, Training time:50824.56414318085
batch reward last col mean 0.07178786396980286 first col mean 0.066986583173275 all mean 0.07160276174545288
rl training, epoch2, iter0, batch535/1133, batch loss:0.020211726427078247, Training time:50851.78231024742
batch reward last col mean 0.09632694721221924 first col mean 0.09832191467285156 all mean 0.096420519053936
rl training, epoch2, iter0, batch536/1133, batch loss:0.04126167669892311, Training time:50879.259892463684
batch reward last col mean 0.08463151007890701 first col mean 0.08317439258098602 all mean 0.08456191420555115
rl training, epoch2, iter0, batch537/1133, batch loss:0.028225621208548546, Training time:50906.54871344566
batch reward last col mean 0.06809637695550919 first col mean 0.06660899519920349 all mean 0.06807252764701843
rl training, epoch2, iter0, batch538/1133, batch loss:0.01935778744518757, Training time:50933.73713469505
batch reward last col mean 0.07872167229652405 first col mean 0.07733114808797836 all mean 0.07861460745334625
rl training, epoch2, iter0, batch539/1133, batch loss:0.038256995379924774, Training time:50960.93258237839
batch reward last col mean 0.10153202712535858 first col mean 0.09265583753585815 all mean 0.10120546817779541
rl training, epoch2, iter0, batch540/1133, batch loss:0.03924918919801712, Training time:50988.1190636158
batch reward last col mean 0.08979203552007675 first col mean 0.0900837630033493 all mean 0.08973786979913712
rl training, epoch2, iter0, batch541/1133, batch loss:0.02542860060930252, Training time:51015.431726932526
batch reward last col mean 0.06503944098949432 first col mean 0.06332764774560928 all mean 0.06481273472309113
rl training, epoch2, iter0, batch542/1133, batch loss:0.023943832144141197, Training time:51042.74328684807
batch reward last col mean 0.05895485728979111 first col mean 0.06358736008405685 all mean 0.05914190039038658
rl training, epoch2, iter0, batch543/1133, batch loss:0.013733243569731712, Training time:51070.039965867996
batch reward last col mean 0.0740789994597435 first col mean 0.07971987873315811 all mean 0.07426172494888306
rl training, epoch2, iter0, batch544/1133, batch loss:0.032032012939453125, Training time:51097.2787861824
batch reward last col mean 0.07521108537912369 first col mean 0.07989536225795746 all mean 0.07534625381231308
rl training, epoch2, iter0, batch545/1133, batch loss:0.020430108532309532, Training time:51124.415477991104
batch reward last col mean 0.06280972063541412 first col mean 0.060796741396188736 all mean 0.06295932084321976
rl training, epoch2, iter0, batch546/1133, batch loss:0.03130410611629486, Training time:51151.68124485016
batch reward last col mean 0.1382172852754593 first col mean 0.13589423894882202 all mean 0.13825133442878723
rl training, epoch2, iter0, batch547/1133, batch loss:0.0622432604432106, Training time:51178.829775094986
batch reward last col mean 0.07248847931623459 first col mean 0.06960756331682205 all mean 0.07219290733337402
rl training, epoch2, iter0, batch548/1133, batch loss:0.028890255838632584, Training time:51207.98233938217
batch reward last col mean 0.09210121631622314 first col mean 0.08271501213312149 all mean 0.09165825694799423
rl training, epoch2, iter0, batch549/1133, batch loss:0.04238111153244972, Training time:51237.16330456734
batch reward last col mean 0.10582253336906433 first col mean 0.10360535979270935 all mean 0.10562045872211456
rl training, epoch2, iter0, batch550/1133, batch loss:0.043300654739141464, Training time:51266.49886751175
batch reward last col mean 0.0723789632320404 first col mean 0.07391735911369324 all mean 0.07239645719528198
rl training, epoch2, iter0, batch551/1133, batch loss:0.03721163049340248, Training time:51295.8588206768
batch reward last col mean 0.06073904410004616 first col mean 0.05969017744064331 all mean 0.06069718301296234
rl training, epoch2, iter0, batch552/1133, batch loss:0.015552613884210587, Training time:51325.28303647041
batch reward last col mean 0.10454662144184113 first col mean 0.11148907244205475 all mean 0.10479693859815598
rl training, epoch2, iter0, batch553/1133, batch loss:0.04112919047474861, Training time:51354.7728202343
batch reward last col mean 0.1271289885044098 first col mean 0.12300900369882584 all mean 0.12700355052947998
rl training, epoch2, iter0, batch554/1133, batch loss:0.04180137440562248, Training time:51384.31811976433
batch reward last col mean 0.09418292343616486 first col mean 0.09789242595434189 all mean 0.0943254604935646
rl training, epoch2, iter0, batch555/1133, batch loss:0.039612431079149246, Training time:51414.18904829025
batch reward last col mean 0.06849727034568787 first col mean 0.06759167462587357 all mean 0.06854153424501419
rl training, epoch2, iter0, batch556/1133, batch loss:0.024357030168175697, Training time:51443.519780397415
batch reward last col mean 0.07939931750297546 first col mean 0.08260548859834671 all mean 0.07926999777555466
rl training, epoch2, iter0, batch557/1133, batch loss:0.03814469277858734, Training time:51472.84974527359
batch reward last col mean 0.10380102694034576 first col mean 0.11067681014537811 all mean 0.10387326031923294
rl training, epoch2, iter0, batch558/1133, batch loss:0.041788168251514435, Training time:51501.25620341301
batch reward last col mean 0.08832338452339172 first col mean 0.08423405885696411 all mean 0.08836272358894348
rl training, epoch2, iter0, batch559/1133, batch loss:0.029143493622541428, Training time:51530.51059746742
batch reward last col mean 0.10258135199546814 first col mean 0.10907059162855148 all mean 0.10282252728939056
rl training, epoch2, iter0, batch560/1133, batch loss:0.05191519856452942, Training time:51559.51213932037
batch reward last col mean 0.07790609449148178 first col mean 0.08422698080539703 all mean 0.07801202684640884
rl training, epoch2, iter0, batch561/1133, batch loss:0.020658105611801147, Training time:51588.96611618996
batch reward last col mean 0.03765101358294487 first col mean 0.0437438003718853 all mean 0.03773832693696022
rl training, epoch2, iter0, batch562/1133, batch loss:0.019443830475211143, Training time:51618.56555557251
batch reward last col mean 0.08226307481527328 first col mean 0.08240819722414017 all mean 0.0822799950838089
rl training, epoch2, iter0, batch563/1133, batch loss:0.02647208422422409, Training time:51647.89566373825
batch reward last col mean 0.06999854743480682 first col mean 0.06487619876861572 all mean 0.06999765336513519
rl training, epoch2, iter0, batch564/1133, batch loss:0.03309054300189018, Training time:51677.24708485603
batch reward last col mean 0.07414982467889786 first col mean 0.07296004146337509 all mean 0.0742335245013237
rl training, epoch2, iter0, batch565/1133, batch loss:0.028543980792164803, Training time:51706.83501911163
batch reward last col mean 0.08714427798986435 first col mean 0.09008399397134781 all mean 0.08729277551174164
rl training, epoch2, iter0, batch566/1133, batch loss:0.04198429360985756, Training time:51735.323915958405
batch reward last col mean 0.11109678447246552 first col mean 0.10888853669166565 all mean 0.11115606129169464
rl training, epoch2, iter0, batch567/1133, batch loss:0.04468706250190735, Training time:51764.61501598358
batch reward last col mean 0.11043672263622284 first col mean 0.10641229897737503 all mean 0.11015189439058304
rl training, epoch2, iter0, batch568/1133, batch loss:0.027719302102923393, Training time:51793.85728812218
batch reward last col mean 0.08811244368553162 first col mean 0.1002316027879715 all mean 0.08844408392906189
rl training, epoch2, iter0, batch569/1133, batch loss:0.03496700897812843, Training time:51823.09784412384
batch reward last col mean 0.055790677666664124 first col mean 0.05502762645483017 all mean 0.05563274398446083
rl training, epoch2, iter0, batch570/1133, batch loss:0.024912379682064056, Training time:51851.8474009037
batch reward last col mean 0.13092605769634247 first col mean 0.11257916688919067 all mean 0.12984305620193481
rl training, epoch2, iter0, batch571/1133, batch loss:0.053975798189640045, Training time:51880.97884726524
batch reward last col mean 0.08421385288238525 first col mean 0.08212860673666 all mean 0.08412186056375504
rl training, epoch2, iter0, batch572/1133, batch loss:0.040588848292827606, Training time:51910.556275844574
batch reward last col mean 0.101140096783638 first col mean 0.10251608490943909 all mean 0.10126397013664246
rl training, epoch2, iter0, batch573/1133, batch loss:0.049209900200366974, Training time:51939.84862089157
batch reward last col mean 0.08700794726610184 first col mean 0.07756886631250381 all mean 0.08670878410339355
rl training, epoch2, iter0, batch574/1133, batch loss:0.036224689334630966, Training time:51969.45340061188
batch reward last col mean 0.1204630583524704 first col mean 0.12202125787734985 all mean 0.12072286009788513
rl training, epoch2, iter0, batch575/1133, batch loss:0.05977318063378334, Training time:51998.5613322258
batch reward last col mean 0.07188240438699722 first col mean 0.07940138131380081 all mean 0.072013258934021
rl training, epoch2, iter0, batch576/1133, batch loss:0.051755912601947784, Training time:52028.62770962715
batch reward last col mean 0.07615572959184647 first col mean 0.07211588323116302 all mean 0.07588409632444382
rl training, epoch2, iter0, batch577/1133, batch loss:0.0471663698554039, Training time:52058.19272375107
batch reward last col mean 0.08438249677419662 first col mean 0.07512755692005157 all mean 0.0839826911687851
rl training, epoch2, iter0, batch578/1133, batch loss:0.04616014286875725, Training time:52087.883679151535
batch reward last col mean 0.11642122268676758 first col mean 0.09481611847877502 all mean 0.11497418582439423
rl training, epoch2, iter0, batch579/1133, batch loss:0.04504036530852318, Training time:52117.71775960922
batch reward last col mean 0.06946028769016266 first col mean 0.05967264249920845 all mean 0.06839898973703384
rl training, epoch2, iter0, batch580/1133, batch loss:0.03566276654601097, Training time:52147.28903412819
batch reward last col mean 0.12029682099819183 first col mean 0.1231289729475975 all mean 0.12043650448322296
rl training, epoch2, iter0, batch581/1133, batch loss:0.06427625566720963, Training time:52176.630224466324
batch reward last col mean 0.166908860206604 first col mean 0.1658758968114853 all mean 0.16642729938030243
rl training, epoch2, iter0, batch582/1133, batch loss:0.06460931897163391, Training time:52206.37990832329
batch reward last col mean 0.16505330801010132 first col mean 0.16174554824829102 all mean 0.16628745198249817
rl training, epoch2, iter0, batch583/1133, batch loss:0.08361894637346268, Training time:52236.60713338852
batch reward last col mean 0.1161576509475708 first col mean 0.11114582419395447 all mean 0.11552885174751282
rl training, epoch2, iter0, batch584/1133, batch loss:0.030449271202087402, Training time:52266.78163123131
batch reward last col mean 0.07682931423187256 first col mean 0.07397487759590149 all mean 0.07533783465623856
rl training, epoch2, iter0, batch585/1133, batch loss:0.03390757739543915, Training time:52297.42231416702
batch reward last col mean 0.08488243818283081 first col mean 0.07437091320753098 all mean 0.0777900367975235
rl training, epoch2, iter0, batch586/1133, batch loss:0.021764542907476425, Training time:52327.783047914505
batch reward last col mean 0.04673506319522858 first col mean 0.044042862951755524 all mean 0.044644732028245926
rl training, epoch2, iter0, batch587/1133, batch loss:0.011077149771153927, Training time:52358.424968481064
batch reward last col mean 0.09181225299835205 first col mean 0.08994082361459732 all mean 0.0927509218454361
rl training, epoch2, iter0, batch588/1133, batch loss:0.015579606406390667, Training time:52389.1180536747
batch reward last col mean 0.05482346937060356 first col mean 0.047902874648571014 all mean 0.054587047547101974
rl training, epoch2, iter0, batch589/1133, batch loss:0.014548010192811489, Training time:52419.86474752426
batch reward last col mean 0.06400631368160248 first col mean 0.056958071887493134 all mean 0.05891173332929611
rl training, epoch2, iter0, batch590/1133, batch loss:0.010830984450876713, Training time:52450.78974747658
batch reward last col mean 0.0890185534954071 first col mean 0.08080319315195084 all mean 0.0835275650024414
rl training, epoch2, iter0, batch591/1133, batch loss:0.017094114795327187, Training time:52481.489953279495
batch reward last col mean 0.06866946816444397 first col mean 0.05739327892661095 all mean 0.06621486693620682
rl training, epoch2, iter0, batch592/1133, batch loss:0.013764826580882072, Training time:52512.8524479866
batch reward last col mean 0.10410844534635544 first col mean 0.09212201833724976 all mean 0.09609328210353851
rl training, epoch2, iter0, batch593/1133, batch loss:0.02553202211856842, Training time:52543.9291408062
batch reward last col mean 0.09361033886671066 first col mean 0.08927877247333527 all mean 0.09121910482645035
rl training, epoch2, iter0, batch594/1133, batch loss:0.03309943899512291, Training time:52575.068943977356
batch reward last col mean 0.1109018474817276 first col mean 0.10220550000667572 all mean 0.10721966624259949
rl training, epoch2, iter0, batch595/1133, batch loss:0.03520245477557182, Training time:52605.640583753586
batch reward last col mean 0.08711415529251099 first col mean 0.08788733184337616 all mean 0.08696716278791428
rl training, epoch2, iter0, batch596/1133, batch loss:0.03290480747818947, Training time:52636.17070508003
batch reward last col mean 0.11207028478384018 first col mean 0.12003172934055328 all mean 0.11251749098300934
rl training, epoch2, iter0, batch597/1133, batch loss:0.0527079813182354, Training time:52666.14760041237
batch reward last col mean 0.14421653747558594 first col mean 0.13988235592842102 all mean 0.1450410932302475
rl training, epoch2, iter0, batch598/1133, batch loss:0.07108846306800842, Training time:52696.299080848694
batch reward last col mean 0.1089402288198471 first col mean 0.11681517958641052 all mean 0.10908978432416916
rl training, epoch2, iter0, batch599/1133, batch loss:0.06727591902017593, Training time:52725.27681875229
batch reward last col mean 0.12397385388612747 first col mean 0.12635238468647003 all mean 0.12378790229558945
rl training, epoch2, iter0, batch600/1133, batch loss:0.03868015110492706, Training time:52754.815878391266
batch reward last col mean 0.14827418327331543 first col mean 0.14772146940231323 all mean 0.14820414781570435
rl training, epoch2, iter0, batch601/1133, batch loss:0.08208991587162018, Training time:52783.49542808533
batch reward last col mean 0.15136927366256714 first col mean 0.15844863653182983 all mean 0.15166711807250977
rl training, epoch2, iter0, batch602/1133, batch loss:0.09855060279369354, Training time:52812.94246482849
batch reward last col mean 0.16783879697322845 first col mean 0.16331696510314941 all mean 0.1675383448600769
rl training, epoch2, iter0, batch603/1133, batch loss:0.0755297839641571, Training time:52841.92942547798
batch reward last col mean 0.1274847686290741 first col mean 0.11848092824220657 all mean 0.1270671933889389
rl training, epoch2, iter0, batch604/1133, batch loss:0.057779792696237564, Training time:52870.806223630905
batch reward last col mean 0.172660231590271 first col mean 0.15282884240150452 all mean 0.17250746488571167
rl training, epoch2, iter0, batch605/1133, batch loss:0.06922617554664612, Training time:52900.052680015564
batch reward last col mean 0.16018646955490112 first col mean 0.16298238933086395 all mean 0.16009260714054108
rl training, epoch2, iter0, batch606/1133, batch loss:0.07520618289709091, Training time:52929.42506933212
batch reward last col mean 0.10840238630771637 first col mean 0.11384084820747375 all mean 0.10850430279970169
rl training, epoch2, iter0, batch607/1133, batch loss:0.06680522114038467, Training time:52958.44213581085
batch reward last col mean 0.1230921521782875 first col mean 0.1376671940088272 all mean 0.12337326258420944
rl training, epoch2, iter0, batch608/1133, batch loss:0.052751123905181885, Training time:52987.66907334328
batch reward last col mean 0.1438109427690506 first col mean 0.12880195677280426 all mean 0.14340414106845856
rl training, epoch2, iter0, batch609/1133, batch loss:0.04772467538714409, Training time:53017.71700358391
batch reward last col mean 0.16072238981723785 first col mean 0.16174763441085815 all mean 0.16089372336864471
rl training, epoch2, iter0, batch610/1133, batch loss:0.045225344598293304, Training time:53046.67370176315
batch reward last col mean 0.16498571634292603 first col mean 0.15586721897125244 all mean 0.1646893471479416
rl training, epoch2, iter0, batch611/1133, batch loss:0.0893109142780304, Training time:53074.738545417786
batch reward last col mean 0.14789468050003052 first col mean 0.13638201355934143 all mean 0.14746786653995514
rl training, epoch2, iter0, batch612/1133, batch loss:0.0718177929520607, Training time:53104.15702223778
batch reward last col mean 0.19775497913360596 first col mean 0.19659079611301422 all mean 0.19763144850730896
rl training, epoch2, iter0, batch613/1133, batch loss:0.061970990151166916, Training time:53133.267386198044
batch reward last col mean 0.17080877721309662 first col mean 0.15757344663143158 all mean 0.17062954604625702
rl training, epoch2, iter0, batch614/1133, batch loss:0.04989682137966156, Training time:53162.16657996178
batch reward last col mean 0.1827128827571869 first col mean 0.19329339265823364 all mean 0.1829189509153366
rl training, epoch2, iter0, batch615/1133, batch loss:0.10456211119890213, Training time:53191.101548433304
batch reward last col mean 0.1824766993522644 first col mean 0.19177883863449097 all mean 0.1830235868692398
rl training, epoch2, iter0, batch616/1133, batch loss:0.1259479522705078, Training time:53220.34444308281
batch reward last col mean 0.16517597436904907 first col mean 0.17597714066505432 all mean 0.1657075732946396
rl training, epoch2, iter0, batch617/1133, batch loss:0.07329656928777695, Training time:53249.46236348152
batch reward last col mean 0.13528941571712494 first col mean 0.14834895730018616 all mean 0.1354716569185257
rl training, epoch2, iter0, batch618/1133, batch loss:0.05867696553468704, Training time:53278.45082950592
batch reward last col mean 0.16584636270999908 first col mean 0.16393022239208221 all mean 0.16590189933776855
rl training, epoch2, iter0, batch619/1133, batch loss:0.06676069647073746, Training time:53307.569672346115
batch reward last col mean 0.21092459559440613 first col mean 0.20107032358646393 all mean 0.21065717935562134
rl training, epoch2, iter0, batch620/1133, batch loss:0.07033935189247131, Training time:53336.627549648285
batch reward last col mean 0.1827308088541031 first col mean 0.20241212844848633 all mean 0.1831444799900055
rl training, epoch2, iter0, batch621/1133, batch loss:0.06196504086256027, Training time:53365.619762420654
batch reward last col mean 0.17360731959342957 first col mean 0.18354520201683044 all mean 0.17395271360874176
rl training, epoch2, iter0, batch622/1133, batch loss:0.07196954637765884, Training time:53394.90345573425
batch reward last col mean 0.2114342451095581 first col mean 0.2008155882358551 all mean 0.2110741287469864
rl training, epoch2, iter0, batch623/1133, batch loss:0.11056429147720337, Training time:53424.09460449219
batch reward last col mean 0.15567433834075928 first col mean 0.15329037606716156 all mean 0.15566498041152954
rl training, epoch2, iter0, batch624/1133, batch loss:0.07673287391662598, Training time:53453.15953230858
batch reward last col mean 0.2311667501926422 first col mean 0.2245934158563614 all mean 0.23104983568191528
rl training, epoch2, iter0, batch625/1133, batch loss:0.05072832480072975, Training time:53482.06465625763
batch reward last col mean 0.22760476171970367 first col mean 0.23803041875362396 all mean 0.22779245674610138
rl training, epoch2, iter0, batch626/1133, batch loss:0.06686627119779587, Training time:53511.23367214203
batch reward last col mean 0.23413872718811035 first col mean 0.2199622392654419 all mean 0.23375681042671204
rl training, epoch2, iter0, batch627/1133, batch loss:0.10318715125322342, Training time:53539.9584209919
batch reward last col mean 0.18961893022060394 first col mean 0.1889759600162506 all mean 0.18961256742477417
rl training, epoch2, iter0, batch628/1133, batch loss:0.06919939070940018, Training time:53569.62042403221
batch reward last col mean 0.17765364050865173 first col mean 0.16836436092853546 all mean 0.17733266949653625
rl training, epoch2, iter0, batch629/1133, batch loss:0.06150520592927933, Training time:53598.983651161194
batch reward last col mean 0.22751571238040924 first col mean 0.23106731474399567 all mean 0.22767804563045502
rl training, epoch2, iter0, batch630/1133, batch loss:0.10507217794656754, Training time:53628.47690176964
batch reward last col mean 0.22679339349269867 first col mean 0.23166893422603607 all mean 0.2269146889448166
rl training, epoch2, iter0, batch631/1133, batch loss:0.09934248775243759, Training time:53657.86892366409
batch reward last col mean 0.24749666452407837 first col mean 0.25636613368988037 all mean 0.24770717322826385
rl training, epoch2, iter0, batch632/1133, batch loss:0.07337111979722977, Training time:53686.81291151047
batch reward last col mean 0.1785021275281906 first col mean 0.18314090371131897 all mean 0.1788128912448883
rl training, epoch2, iter0, batch633/1133, batch loss:0.04164368659257889, Training time:53716.33054566383
batch reward last col mean 0.252936989068985 first col mean 0.2534964084625244 all mean 0.2533426880836487
rl training, epoch2, iter0, batch634/1133, batch loss:0.08420570939779282, Training time:53745.685334682465
batch reward last col mean 0.2273412048816681 first col mean 0.2321700006723404 all mean 0.22748738527297974
rl training, epoch2, iter0, batch635/1133, batch loss:0.07170075178146362, Training time:53774.92557430267
batch reward last col mean 0.2639443874359131 first col mean 0.2613603472709656 all mean 0.2636767029762268
rl training, epoch2, iter0, batch636/1133, batch loss:0.07268059253692627, Training time:53804.007882356644
batch reward last col mean 0.22388094663619995 first col mean 0.2329692393541336 all mean 0.22414924204349518
rl training, epoch2, iter0, batch637/1133, batch loss:0.10380565375089645, Training time:53833.491176605225
batch reward last col mean 0.17093107104301453 first col mean 0.18695737421512604 all mean 0.17115572094917297
rl training, epoch2, iter0, batch638/1133, batch loss:0.07419055700302124, Training time:53863.030088186264
batch reward last col mean 0.22080211341381073 first col mean 0.21891868114471436 all mean 0.22081321477890015
rl training, epoch2, iter0, batch639/1133, batch loss:0.07090890407562256, Training time:53892.299952983856
batch reward last col mean 0.20450860261917114 first col mean 0.21025526523590088 all mean 0.20455479621887207
rl training, epoch2, iter0, batch640/1133, batch loss:0.0872928649187088, Training time:53921.2965567112
batch reward last col mean 0.17249849438667297 first col mean 0.16417308151721954 all mean 0.17188231647014618
rl training, epoch2, iter0, batch641/1133, batch loss:0.058866649866104126, Training time:53950.840008974075
batch reward last col mean 0.20959003269672394 first col mean 0.2186756581068039 all mean 0.21003742516040802
rl training, epoch2, iter0, batch642/1133, batch loss:0.08392023295164108, Training time:53980.76964497566
batch reward last col mean 0.21453717350959778 first col mean 0.21483683586120605 all mean 0.2146100103855133
rl training, epoch2, iter0, batch643/1133, batch loss:0.09459318220615387, Training time:54010.43499779701
batch reward last col mean 0.2254222184419632 first col mean 0.2349642813205719 all mean 0.22562213242053986
rl training, epoch2, iter0, batch644/1133, batch loss:0.07156043499708176, Training time:54039.87590909004
batch reward last col mean 0.1888674646615982 first col mean 0.19164149463176727 all mean 0.18887585401535034
rl training, epoch2, iter0, batch645/1133, batch loss:0.07136231660842896, Training time:54069.26719403267
batch reward last col mean 0.22313889861106873 first col mean 0.2195839136838913 all mean 0.22308731079101562
rl training, epoch2, iter0, batch646/1133, batch loss:0.08581864088773727, Training time:54098.23805785179
batch reward last col mean 0.20409291982650757 first col mean 0.21294286847114563 all mean 0.20432083308696747
rl training, epoch2, iter0, batch647/1133, batch loss:0.06195145100355148, Training time:54127.80714273453
batch reward last col mean 0.24293465912342072 first col mean 0.24789980053901672 all mean 0.2431294173002243
rl training, epoch2, iter0, batch648/1133, batch loss:0.08138854801654816, Training time:54157.0643620491
batch reward last col mean 0.21211202442646027 first col mean 0.21721932291984558 all mean 0.2121618688106537
rl training, epoch2, iter0, batch649/1133, batch loss:0.057164158672094345, Training time:54186.538836717606
batch reward last col mean 0.19916558265686035 first col mean 0.19709476828575134 all mean 0.19916920363903046
rl training, epoch2, iter0, batch650/1133, batch loss:0.05569791793823242, Training time:54215.86824941635
batch reward last col mean 0.1881747841835022 first col mean 0.18772980570793152 all mean 0.18810899555683136
rl training, epoch2, iter0, batch651/1133, batch loss:0.06478327512741089, Training time:54244.95505857468
batch reward last col mean 0.25020432472229004 first col mean 0.2470785677433014 all mean 0.25019365549087524
rl training, epoch2, iter0, batch652/1133, batch loss:0.10832364112138748, Training time:54274.00068426132
batch reward last col mean 0.23465943336486816 first col mean 0.2456263303756714 all mean 0.23489707708358765
rl training, epoch2, iter0, batch653/1133, batch loss:0.07746001332998276, Training time:54303.464054107666
batch reward last col mean 0.2358023226261139 first col mean 0.22993452847003937 all mean 0.23565474152565002
rl training, epoch2, iter0, batch654/1133, batch loss:0.04920642450451851, Training time:54333.01811552048
batch reward last col mean 0.22544971108436584 first col mean 0.21506252884864807 all mean 0.22520986199378967
rl training, epoch2, iter0, batch655/1133, batch loss:0.07950963824987411, Training time:54361.95100903511
batch reward last col mean 0.24820956587791443 first col mean 0.24584609270095825 all mean 0.24824300408363342
rl training, epoch2, iter0, batch656/1133, batch loss:0.1193745955824852, Training time:54391.3573410511
batch reward last col mean 0.20512503385543823 first col mean 0.19270287454128265 all mean 0.20479533076286316
rl training, epoch2, iter0, batch657/1133, batch loss:0.0748160108923912, Training time:54420.99384641647
batch reward last col mean 0.24608060717582703 first col mean 0.23947873711585999 all mean 0.24579103291034698
rl training, epoch2, iter0, batch658/1133, batch loss:0.0845232605934143, Training time:54449.64606428146
batch reward last col mean 0.22784920036792755 first col mean 0.22388258576393127 all mean 0.22779880464076996
rl training, epoch2, iter0, batch659/1133, batch loss:0.07732220739126205, Training time:54478.99472737312
batch reward last col mean 0.18737046420574188 first col mean 0.19384855031967163 all mean 0.18752281367778778
rl training, epoch2, iter0, batch660/1133, batch loss:0.07153471559286118, Training time:54508.16635417938
batch reward last col mean 0.1734102964401245 first col mean 0.17648740112781525 all mean 0.1734149307012558
rl training, epoch2, iter0, batch661/1133, batch loss:0.05090364068746567, Training time:54537.46676635742
batch reward last col mean 0.24983075261116028 first col mean 0.23892198503017426 all mean 0.24952591955661774
rl training, epoch2, iter0, batch662/1133, batch loss:0.09510503709316254, Training time:54566.97776603699
batch reward last col mean 0.23310261964797974 first col mean 0.2272370457649231 all mean 0.23286792635917664
rl training, epoch2, iter0, batch663/1133, batch loss:0.10763587057590485, Training time:54596.83696222305
batch reward last col mean 0.1873147040605545 first col mean 0.1855328530073166 all mean 0.18733443319797516
rl training, epoch2, iter0, batch664/1133, batch loss:0.07185234129428864, Training time:54626.39995288849
batch reward last col mean 0.17240318655967712 first col mean 0.1717618852853775 all mean 0.17248928546905518
rl training, epoch2, iter0, batch665/1133, batch loss:0.09188583493232727, Training time:54656.08234786987
batch reward last col mean 0.21186615526676178 first col mean 0.20629464089870453 all mean 0.21191726624965668
rl training, epoch2, iter0, batch666/1133, batch loss:0.09967242926359177, Training time:54685.012420892715
batch reward last col mean 0.19502252340316772 first col mean 0.2038375288248062 all mean 0.19543273746967316
rl training, epoch2, iter0, batch667/1133, batch loss:0.08644687384366989, Training time:54714.35416102409
batch reward last col mean 0.2048095166683197 first col mean 0.20815856754779816 all mean 0.20479221642017365
rl training, epoch2, iter0, batch668/1133, batch loss:0.10722924023866653, Training time:54743.999635219574
batch reward last col mean 0.32274794578552246 first col mean 0.29443731904029846 all mean 0.32179561257362366
rl training, epoch2, iter0, batch669/1133, batch loss:0.16504472494125366, Training time:54773.329265356064
batch reward last col mean 0.24577653408050537 first col mean 0.24433393776416779 all mean 0.24552050232887268
rl training, epoch2, iter0, batch670/1133, batch loss:0.14998149871826172, Training time:54802.62819647789
batch reward last col mean 0.25693410634994507 first col mean 0.2632014751434326 all mean 0.2574823200702667
rl training, epoch2, iter0, batch671/1133, batch loss:0.11787128448486328, Training time:54831.967661857605
batch reward last col mean 0.19822077453136444 first col mean 0.21250298619270325 all mean 0.19842687249183655
rl training, epoch2, iter0, batch672/1133, batch loss:0.11243213713169098, Training time:54861.80136990547
batch reward last col mean 0.2274516224861145 first col mean 0.23739585280418396 all mean 0.2276506870985031
rl training, epoch2, iter0, batch673/1133, batch loss:0.11833865940570831, Training time:54891.108978271484
batch reward last col mean 0.23013438284397125 first col mean 0.24725908041000366 all mean 0.23057015240192413
rl training, epoch2, iter0, batch674/1133, batch loss:0.1269218474626541, Training time:54920.58617401123
batch reward last col mean 0.18051362037658691 first col mean 0.17684510350227356 all mean 0.18025949597358704
rl training, epoch2, iter0, batch675/1133, batch loss:0.11005102097988129, Training time:54950.016449689865
batch reward last col mean 0.2506633996963501 first col mean 0.25902682542800903 all mean 0.25124868750572205
rl training, epoch2, iter0, batch676/1133, batch loss:0.10242923349142075, Training time:54979.35663676262
batch reward last col mean 0.2284787893295288 first col mean 0.23055240511894226 all mean 0.22908757627010345
rl training, epoch2, iter0, batch677/1133, batch loss:0.11953472346067429, Training time:55008.97720837593
batch reward last col mean 0.2291330099105835 first col mean 0.22769206762313843 all mean 0.22912031412124634
rl training, epoch2, iter0, batch678/1133, batch loss:0.14073215425014496, Training time:55038.217908382416
batch reward last col mean 0.17718291282653809 first col mean 0.17514964938163757 all mean 0.1766919195652008
rl training, epoch2, iter0, batch679/1133, batch loss:0.09612253308296204, Training time:55067.70180773735
batch reward last col mean 0.24576081335544586 first col mean 0.2424658238887787 all mean 0.24576646089553833
rl training, epoch2, iter0, batch680/1133, batch loss:0.1485375016927719, Training time:55097.34022116661
batch reward last col mean 0.2053435891866684 first col mean 0.21007007360458374 all mean 0.2055014967918396
rl training, epoch2, iter0, batch681/1133, batch loss:0.0934067964553833, Training time:55126.62418580055
batch reward last col mean 0.30121350288391113 first col mean 0.28540679812431335 all mean 0.30081623792648315
rl training, epoch2, iter0, batch682/1133, batch loss:0.13426236808300018, Training time:55156.095808029175
batch reward last col mean 0.23495250940322876 first col mean 0.23472902178764343 all mean 0.23455871641635895
rl training, epoch2, iter0, batch683/1133, batch loss:0.11276675760746002, Training time:55185.49288082123
batch reward last col mean 0.2584492862224579 first col mean 0.2654609680175781 all mean 0.25852277874946594
rl training, epoch2, iter0, batch684/1133, batch loss:0.12751325964927673, Training time:55214.71817326546
batch reward last col mean 0.229731023311615 first col mean 0.22572554647922516 all mean 0.22959676384925842
rl training, epoch2, iter0, batch685/1133, batch loss:0.12427901476621628, Training time:55243.95673108101
batch reward last col mean 0.3005237281322479 first col mean 0.28199803829193115 all mean 0.29997676610946655
rl training, epoch2, iter0, batch686/1133, batch loss:0.14828018844127655, Training time:55273.42536664009
batch reward last col mean 0.2047485113143921 first col mean 0.19694934785366058 all mean 0.2043256312608719
rl training, epoch2, iter0, batch687/1133, batch loss:0.10266829282045364, Training time:55302.422640800476
batch reward last col mean 0.21437767148017883 first col mean 0.23189160227775574 all mean 0.21471333503723145
rl training, epoch2, iter0, batch688/1133, batch loss:0.09215155988931656, Training time:55331.665276288986
batch reward last col mean 0.27355706691741943 first col mean 0.26602599024772644 all mean 0.27334126830101013
rl training, epoch2, iter0, batch689/1133, batch loss:0.09571795910596848, Training time:55360.754725933075
batch reward last col mean 0.2368328720331192 first col mean 0.2559252083301544 all mean 0.23729482293128967
rl training, epoch2, iter0, batch690/1133, batch loss:0.07583654671907425, Training time:55390.057555913925
batch reward last col mean 0.3079370856285095 first col mean 0.2961459755897522 all mean 0.3078303933143616
rl training, epoch2, iter0, batch691/1133, batch loss:0.13840526342391968, Training time:55419.797839164734
batch reward last col mean 0.27774935960769653 first col mean 0.2800063490867615 all mean 0.2776719629764557
rl training, epoch2, iter0, batch692/1133, batch loss:0.08766812086105347, Training time:55450.00564575195
batch reward last col mean 0.25646328926086426 first col mean 0.28154322504997253 all mean 0.2569079101085663
rl training, epoch2, iter0, batch693/1133, batch loss:0.14983877539634705, Training time:55479.349503040314
batch reward last col mean 0.2533677816390991 first col mean 0.25655049085617065 all mean 0.253527969121933
rl training, epoch2, iter0, batch694/1133, batch loss:0.08915749937295914, Training time:55508.83919763565
batch reward last col mean 0.27980825304985046 first col mean 0.2986217737197876 all mean 0.2800196409225464
rl training, epoch2, iter0, batch695/1133, batch loss:0.09610053896903992, Training time:55538.51953482628
batch reward last col mean 0.20620237290859222 first col mean 0.19304737448692322 all mean 0.20569799840450287
rl training, epoch2, iter0, batch696/1133, batch loss:0.10395701229572296, Training time:55568.25188946724
batch reward last col mean 0.28162699937820435 first col mean 0.2745073139667511 all mean 0.2813691794872284
rl training, epoch2, iter0, batch697/1133, batch loss:0.08351881802082062, Training time:55598.09091711044
batch reward last col mean 0.25517022609710693 first col mean 0.2514510452747345 all mean 0.25510141253471375
rl training, epoch2, iter0, batch698/1133, batch loss:0.1255611628293991, Training time:55627.339159965515
batch reward last col mean 0.27311137318611145 first col mean 0.28235143423080444 all mean 0.27314886450767517
rl training, epoch2, iter0, batch699/1133, batch loss:0.13784608244895935, Training time:55656.8257021904
batch reward last col mean 0.1868567168712616 first col mean 0.18010085821151733 all mean 0.18672685325145721
rl training, epoch2, iter0, batch700/1133, batch loss:0.06625578552484512, Training time:55686.355640649796
batch reward last col mean 0.22356514632701874 first col mean 0.2174607813358307 all mean 0.22357584536075592
rl training, epoch2, iter0, batch701/1133, batch loss:0.09621461480855942, Training time:55715.34151649475
batch reward last col mean 0.21056854724884033 first col mean 0.220285102725029 all mean 0.21060839295387268
rl training, epoch2, iter0, batch702/1133, batch loss:0.08383650332689285, Training time:55744.744022369385
batch reward last col mean 0.28283974528312683 first col mean 0.2844095230102539 all mean 0.2830134630203247
rl training, epoch2, iter0, batch703/1133, batch loss:0.10592992603778839, Training time:55774.05759716034
batch reward last col mean 0.20415166020393372 first col mean 0.2150285392999649 all mean 0.20447862148284912
rl training, epoch2, iter0, batch704/1133, batch loss:0.06599019467830658, Training time:55803.4020216465
batch reward last col mean 0.2580259442329407 first col mean 0.2622540593147278 all mean 0.25809961557388306
rl training, epoch2, iter0, batch705/1133, batch loss:0.11259783804416656, Training time:55832.24387907982
batch reward last col mean 0.2880069613456726 first col mean 0.27935370802879333 all mean 0.2879064977169037
rl training, epoch2, iter0, batch706/1133, batch loss:0.1305435448884964, Training time:55861.809540987015
batch reward last col mean 0.24471698701381683 first col mean 0.24589020013809204 all mean 0.24440668523311615
rl training, epoch2, iter0, batch707/1133, batch loss:0.11960852146148682, Training time:55890.848294496536
batch reward last col mean 0.2590147852897644 first col mean 0.24693018198013306 all mean 0.25823327898979187
rl training, epoch2, iter0, batch708/1133, batch loss:0.12752842903137207, Training time:55920.343131542206
batch reward last col mean 0.20057260990142822 first col mean 0.20697730779647827 all mean 0.20069529116153717
rl training, epoch2, iter0, batch709/1133, batch loss:0.08551238477230072, Training time:55950.037289857864
batch reward last col mean 0.22065207362174988 first col mean 0.22160926461219788 all mean 0.22062914073467255
rl training, epoch2, iter0, batch710/1133, batch loss:0.1168045699596405, Training time:55979.21909356117
batch reward last col mean 0.2810215651988983 first col mean 0.28746071457862854 all mean 0.28134074807167053
rl training, epoch2, iter0, batch711/1133, batch loss:0.1592256873846054, Training time:56008.87372088432
batch reward last col mean 0.22850869596004486 first col mean 0.2303590178489685 all mean 0.22861522436141968
rl training, epoch2, iter0, batch712/1133, batch loss:0.12116171419620514, Training time:56038.28013300896
batch reward last col mean 0.22522053122520447 first col mean 0.23406822979450226 all mean 0.22560393810272217
rl training, epoch2, iter0, batch713/1133, batch loss:0.127409428358078, Training time:56067.80903887749
batch reward last col mean 0.273897260427475 first col mean 0.271509051322937 all mean 0.27350080013275146
rl training, epoch2, iter0, batch714/1133, batch loss:0.10888256132602692, Training time:56097.36985707283
batch reward last col mean 0.282777339220047 first col mean 0.2626075744628906 all mean 0.2818842828273773
rl training, epoch2, iter0, batch715/1133, batch loss:0.15892179310321808, Training time:56126.33876276016
batch reward last col mean 0.2818424105644226 first col mean 0.2666502296924591 all mean 0.28120648860931396
rl training, epoch2, iter0, batch716/1133, batch loss:0.17574238777160645, Training time:56155.6120262146
batch reward last col mean 0.2674746811389923 first col mean 0.26675841212272644 all mean 0.2671947777271271
rl training, epoch2, iter0, batch717/1133, batch loss:0.2107551246881485, Training time:56185.31382274628
batch reward last col mean 0.28827938437461853 first col mean 0.30341535806655884 all mean 0.28874367475509644
rl training, epoch2, iter0, batch718/1133, batch loss:0.13991698622703552, Training time:56214.39871931076
batch reward last col mean 0.31539902091026306 first col mean 0.3177231550216675 all mean 0.31552714109420776
rl training, epoch2, iter0, batch719/1133, batch loss:0.21972623467445374, Training time:56243.65758037567
batch reward last col mean 0.31275784969329834 first col mean 0.29608863592147827 all mean 0.3122234642505646
rl training, epoch2, iter0, batch720/1133, batch loss:0.2021162062883377, Training time:56272.41058945656
batch reward last col mean 0.31121525168418884 first col mean 0.31942105293273926 all mean 0.31119006872177124
rl training, epoch2, iter0, batch721/1133, batch loss:0.22761270403862, Training time:56301.908556222916
batch reward last col mean 0.315548837184906 first col mean 0.32653242349624634 all mean 0.31558170914649963
rl training, epoch2, iter0, batch722/1133, batch loss:0.2413189709186554, Training time:56331.38324403763
batch reward last col mean 0.29244381189346313 first col mean 0.2883320152759552 all mean 0.2916579246520996
rl training, epoch2, iter0, batch723/1133, batch loss:0.2233331799507141, Training time:56360.85759425163
batch reward last col mean 0.2725059986114502 first col mean 0.26754680275917053 all mean 0.2718713879585266
rl training, epoch2, iter0, batch724/1133, batch loss:0.3110089600086212, Training time:56390.32227706909
batch reward last col mean 0.34550708532333374 first col mean 0.3511069416999817 all mean 0.34559956192970276
rl training, epoch2, iter0, batch725/1133, batch loss:0.3220645785331726, Training time:56419.60812211037
batch reward last col mean 0.33891716599464417 first col mean 0.3174258768558502 all mean 0.3377498388290405
rl training, epoch2, iter0, batch726/1133, batch loss:0.22814743220806122, Training time:56448.43293046951
batch reward last col mean 0.3341381549835205 first col mean 0.3316606283187866 all mean 0.3340736925601959
rl training, epoch2, iter0, batch727/1133, batch loss:0.35497355461120605, Training time:56477.89697313309
batch reward last col mean 0.3976879417896271 first col mean 0.3913766145706177 all mean 0.39757969975471497
rl training, epoch2, iter0, batch728/1133, batch loss:0.3718453347682953, Training time:56507.352585077286
batch reward last col mean 0.2872157394886017 first col mean 0.29606831073760986 all mean 0.28809118270874023
rl training, epoch2, iter0, batch729/1133, batch loss:0.2863900363445282, Training time:56537.44099354744
batch reward last col mean 0.2988649606704712 first col mean 0.34064844250679016 all mean 0.3012094497680664
rl training, epoch2, iter0, batch730/1133, batch loss:0.2732102572917938, Training time:56567.172924757004
batch reward last col mean 0.35370659828186035 first col mean 0.364618718624115 all mean 0.35503825545310974
rl training, epoch2, iter0, batch731/1133, batch loss:0.3702279329299927, Training time:56597.315083265305
batch reward last col mean 0.3591614365577698 first col mean 0.3619541525840759 all mean 0.35970669984817505
rl training, epoch2, iter0, batch732/1133, batch loss:0.39511430263519287, Training time:56627.71960926056
batch reward last col mean 0.3113812804222107 first col mean 0.3302989602088928 all mean 0.3234807550907135
rl training, epoch2, iter0, batch733/1133, batch loss:0.2134057879447937, Training time:56657.77772021294
batch reward last col mean 0.33678069710731506 first col mean 0.3544510304927826 all mean 0.33999308943748474
rl training, epoch2, iter0, batch734/1133, batch loss:0.19137471914291382, Training time:56688.684882164
batch reward last col mean 0.3209575414657593 first col mean 0.32789909839630127 all mean 0.3281172215938568
rl training, epoch2, iter0, batch735/1133, batch loss:0.12646318972110748, Training time:56718.9306678772
batch reward last col mean 0.31722205877304077 first col mean 0.310976505279541 all mean 0.3143489956855774
rl training, epoch2, iter0, batch736/1133, batch loss:0.16743047535419464, Training time:56749.5487203598
batch reward last col mean 0.3099316656589508 first col mean 0.29079151153564453 all mean 0.304926335811615
rl training, epoch2, iter0, batch737/1133, batch loss:0.14790421724319458, Training time:56780.08850646019
batch reward last col mean 0.27630478143692017 first col mean 0.30426791310310364 all mean 0.27853983640670776
rl training, epoch2, iter0, batch738/1133, batch loss:0.15570753812789917, Training time:56810.391015291214
batch reward last col mean 0.3165249526500702 first col mean 0.32303911447525024 all mean 0.31807148456573486
rl training, epoch2, iter0, batch739/1133, batch loss:0.12438466399908066, Training time:56840.78534579277
batch reward last col mean 0.2942352294921875 first col mean 0.31823432445526123 all mean 0.2977825403213501
rl training, epoch2, iter0, batch740/1133, batch loss:0.14814770221710205, Training time:56870.89782619476
batch reward last col mean 0.2690335810184479 first col mean 0.27443981170654297 all mean 0.26868221163749695
rl training, epoch2, iter0, batch741/1133, batch loss:0.1268693506717682, Training time:56901.650035619736
batch reward last col mean 0.3518074154853821 first col mean 0.3616681396961212 all mean 0.35238152742385864
rl training, epoch2, iter0, batch742/1133, batch loss:0.27219706773757935, Training time:56932.07658910751
batch reward last col mean 0.3293722867965698 first col mean 0.31714576482772827 all mean 0.3279377818107605
rl training, epoch2, iter0, batch743/1133, batch loss:0.2038138061761856, Training time:56962.49246573448
batch reward last col mean 0.3141835033893585 first col mean 0.3038260340690613 all mean 0.31307172775268555
rl training, epoch2, iter0, batch744/1133, batch loss:0.16532942652702332, Training time:56992.70360374451
batch reward last col mean 0.25575774908065796 first col mean 0.246126189827919 all mean 0.25611257553100586
rl training, epoch2, iter0, batch745/1133, batch loss:0.11257335543632507, Training time:57023.16010308266
batch reward last col mean 0.27047497034072876 first col mean 0.2615774869918823 all mean 0.268902987241745
rl training, epoch2, iter0, batch746/1133, batch loss:0.11833862215280533, Training time:57053.98786067963
batch reward last col mean 0.22710566222667694 first col mean 0.22146645188331604 all mean 0.22708557546138763
rl training, epoch2, iter0, batch747/1133, batch loss:0.12871840596199036, Training time:57084.999084711075
batch reward last col mean 0.2509903609752655 first col mean 0.24740828573703766 all mean 0.24976660311222076
rl training, epoch2, iter0, batch748/1133, batch loss:0.10538533329963684, Training time:57115.90243721008
batch reward last col mean 0.25617510080337524 first col mean 0.25947844982147217 all mean 0.25651028752326965
rl training, epoch2, iter0, batch749/1133, batch loss:0.13189201056957245, Training time:57147.03223276138
batch reward last col mean 0.3005315065383911 first col mean 0.29587769508361816 all mean 0.2993311583995819
rl training, epoch2, iter0, batch750/1133, batch loss:0.18805105984210968, Training time:57177.07188177109
batch reward last col mean 0.34327054023742676 first col mean 0.356963574886322 all mean 0.3456820547580719
rl training, epoch2, iter0, batch751/1133, batch loss:0.17317217588424683, Training time:57207.2892870903
batch reward last col mean 0.2989961504936218 first col mean 0.3020898103713989 all mean 0.3009909689426422
rl training, epoch2, iter0, batch752/1133, batch loss:0.21141721308231354, Training time:57237.73622393608
batch reward last col mean 0.31187957525253296 first col mean 0.3358614444732666 all mean 0.31432339549064636
rl training, epoch2, iter0, batch753/1133, batch loss:0.19725066423416138, Training time:57267.36109638214
batch reward last col mean 0.37777644395828247 first col mean 0.36797547340393066 all mean 0.3774425983428955
rl training, epoch2, iter0, batch754/1133, batch loss:0.303397536277771, Training time:57297.6285443306
batch reward last col mean 0.3616032600402832 first col mean 0.35845518112182617 all mean 0.3608268201351166
rl training, epoch2, iter0, batch755/1133, batch loss:0.23044061660766602, Training time:57328.08893489838
batch reward last col mean 0.33263736963272095 first col mean 0.3455785810947418 all mean 0.33202075958251953
rl training, epoch2, iter0, batch756/1133, batch loss:0.21868357062339783, Training time:57358.571867227554
batch reward last col mean 0.3787912130355835 first col mean 0.37169209122657776 all mean 0.37844011187553406
rl training, epoch2, iter0, batch757/1133, batch loss:0.2828311026096344, Training time:57388.86440515518
batch reward last col mean 0.3500142991542816 first col mean 0.3492324948310852 all mean 0.3501274287700653
rl training, epoch2, iter0, batch758/1133, batch loss:0.3341902494430542, Training time:57419.25348377228
batch reward last col mean 0.36566174030303955 first col mean 0.3558695316314697 all mean 0.36491942405700684
rl training, epoch2, iter0, batch759/1133, batch loss:0.3280189335346222, Training time:57449.7671995163
batch reward last col mean 0.32486048340797424 first col mean 0.3298530578613281 all mean 0.3252846300601959
rl training, epoch2, iter0, batch760/1133, batch loss:0.24165643751621246, Training time:57479.96110701561
batch reward last col mean 0.35533809661865234 first col mean 0.34726640582084656 all mean 0.3569861054420471
rl training, epoch2, iter0, batch761/1133, batch loss:0.23679208755493164, Training time:57510.50202202797
batch reward last col mean 0.37116485834121704 first col mean 0.37684234976768494 all mean 0.3743284344673157
rl training, epoch2, iter0, batch762/1133, batch loss:0.20051209628582, Training time:57540.698325634
batch reward last col mean 0.32332518696784973 first col mean 0.30212152004241943 all mean 0.32463011145591736
rl training, epoch2, iter0, batch763/1133, batch loss:0.28889620304107666, Training time:57571.04560828209
batch reward last col mean 0.2875868082046509 first col mean 0.30544188618659973 all mean 0.28907790780067444
rl training, epoch2, iter0, batch764/1133, batch loss:0.2548638880252838, Training time:57601.68131637573
batch reward last col mean 0.27754056453704834 first col mean 0.29687798023223877 all mean 0.2794003486633301
rl training, epoch2, iter0, batch765/1133, batch loss:0.20255553722381592, Training time:57632.138677835464
batch reward last col mean 0.2859496474266052 first col mean 0.27350080013275146 all mean 0.2826034128665924
rl training, epoch2, iter0, batch766/1133, batch loss:0.1970137357711792, Training time:57662.395340681076
batch reward last col mean 0.3197452425956726 first col mean 0.3162158727645874 all mean 0.31917279958724976
rl training, epoch2, iter0, batch767/1133, batch loss:0.2733871638774872, Training time:57692.009729623795
batch reward last col mean 0.3720349073410034 first col mean 0.39346933364868164 all mean 0.37325334548950195
rl training, epoch2, iter0, batch768/1133, batch loss:0.3498387038707733, Training time:57721.45177054405
batch reward last col mean 0.330476850271225 first col mean 0.3190632164478302 all mean 0.3300912380218506
rl training, epoch2, iter0, batch769/1133, batch loss:0.15707246959209442, Training time:57751.087861299515
batch reward last col mean 0.3306259512901306 first col mean 0.3278374969959259 all mean 0.33043786883354187
rl training, epoch2, iter0, batch770/1133, batch loss:0.24493373930454254, Training time:57780.41080713272
batch reward last col mean 0.328745573759079 first col mean 0.3235742151737213 all mean 0.329059898853302
rl training, epoch2, iter0, batch771/1133, batch loss:0.32367590069770813, Training time:57809.29424357414
batch reward last col mean 0.3316386342048645 first col mean 0.3322463929653168 all mean 0.3313819169998169
rl training, epoch2, iter0, batch772/1133, batch loss:0.2625758647918701, Training time:57838.06280326843
batch reward last col mean 0.3879130482673645 first col mean 0.3782426118850708 all mean 0.38802671432495117
rl training, epoch2, iter0, batch773/1133, batch loss:0.2733871638774872, Training time:57866.73999094963
batch reward last col mean 0.336287260055542 first col mean 0.3524158000946045 all mean 0.3377496004104614
rl training, epoch2, iter0, batch774/1133, batch loss:0.31049713492393494, Training time:57895.7610783577
batch reward last col mean 0.3105084300041199 first col mean 0.33255535364151 all mean 0.3117947280406952
rl training, epoch2, iter0, batch775/1133, batch loss:0.3444123864173889, Training time:57924.41692376137
batch reward last col mean 0.33829835057258606 first col mean 0.3245607614517212 all mean 0.33767133951187134
rl training, epoch2, iter0, batch776/1133, batch loss:0.37588751316070557, Training time:57953.598638534546
batch reward last col mean 0.3725515604019165 first col mean 0.36471986770629883 all mean 0.3718549907207489
rl training, epoch2, iter0, batch777/1133, batch loss:0.41773325204849243, Training time:57982.49557876587
batch reward last col mean 0.3462373614311218 first col mean 0.3496907353401184 all mean 0.3474003076553345
rl training, epoch2, iter0, batch778/1133, batch loss:0.4464709460735321, Training time:58011.907582998276
batch reward last col mean 0.37629908323287964 first col mean 0.39376673102378845 all mean 0.3770771920681
rl training, epoch2, iter0, batch779/1133, batch loss:0.45795825123786926, Training time:58041.43571639061
batch reward last col mean 0.3749610483646393 first col mean 0.37104564905166626 all mean 0.3738039433956146
rl training, epoch2, iter0, batch780/1133, batch loss:0.38391539454460144, Training time:58071.7437748909
batch reward last col mean 0.29839545488357544 first col mean 0.3227720856666565 all mean 0.2981705665588379
rl training, epoch2, iter0, batch781/1133, batch loss:0.35622528195381165, Training time:58102.40373849869
batch reward last col mean 0.40924835205078125 first col mean 0.3971070647239685 all mean 0.41017141938209534
rl training, epoch2, iter0, batch782/1133, batch loss:0.41123753786087036, Training time:58132.60544586182
batch reward last col mean 0.4132187068462372 first col mean 0.3774586021900177 all mean 0.40968096256256104
rl training, epoch2, iter0, batch783/1133, batch loss:0.35986167192459106, Training time:58162.629292964935
batch reward last col mean 0.405331015586853 first col mean 0.41313648223876953 all mean 0.4056023061275482
rl training, epoch2, iter0, batch784/1133, batch loss:0.3023238480091095, Training time:58192.379033088684
batch reward last col mean 0.3684368431568146 first col mean 0.3425385355949402 all mean 0.36750319600105286
rl training, epoch2, iter0, batch785/1133, batch loss:0.27321887016296387, Training time:58222.00608110428
batch reward last col mean 0.384838730096817 first col mean 0.37781715393066406 all mean 0.3821263909339905
rl training, epoch2, iter0, batch786/1133, batch loss:0.2513527274131775, Training time:58252.0940926075
batch reward last col mean 0.41115111112594604 first col mean 0.3902575671672821 all mean 0.409572571516037
rl training, epoch2, iter0, batch787/1133, batch loss:0.29423588514328003, Training time:58282.267204761505
batch reward last col mean 0.3751370906829834 first col mean 0.37759295105934143 all mean 0.3754028081893921
rl training, epoch2, iter0, batch788/1133, batch loss:0.21385307610034943, Training time:58310.684687137604
batch reward last col mean 0.3599392771720886 first col mean 0.349804162979126 all mean 0.3597559928894043
rl training, epoch2, iter0, batch789/1133, batch loss:0.25783148407936096, Training time:58339.75978922844
batch reward last col mean 0.3869611918926239 first col mean 0.38029399514198303 all mean 0.3867293894290924
rl training, epoch2, iter0, batch790/1133, batch loss:0.33488041162490845, Training time:58368.81136107445
batch reward last col mean 0.4890533685684204 first col mean 0.4868033528327942 all mean 0.4888562262058258
rl training, epoch2, iter0, batch791/1133, batch loss:0.3589119017124176, Training time:58397.706703186035
batch reward last col mean 0.3892245888710022 first col mean 0.4011491537094116 all mean 0.38919132947921753
rl training, epoch2, iter0, batch792/1133, batch loss:0.307269424200058, Training time:58426.66096949577
batch reward last col mean 0.3325271010398865 first col mean 0.3575560450553894 all mean 0.33306118845939636
rl training, epoch2, iter0, batch793/1133, batch loss:0.27519938349723816, Training time:58455.51525568962
batch reward last col mean 0.4114256501197815 first col mean 0.4109600782394409 all mean 0.4112910330295563
rl training, epoch2, iter0, batch794/1133, batch loss:0.28037935495376587, Training time:58484.76484847069
batch reward last col mean 0.4306541085243225 first col mean 0.4300934970378876 all mean 0.43074968457221985
rl training, epoch2, iter0, batch795/1133, batch loss:0.31937238574028015, Training time:58513.94507241249
batch reward last col mean 0.45646291971206665 first col mean 0.43914806842803955 all mean 0.45557689666748047
rl training, epoch2, iter0, batch796/1133, batch loss:0.3470053970813751, Training time:58542.56031847
batch reward last col mean 0.37267449498176575 first col mean 0.36880719661712646 all mean 0.37233299016952515
rl training, epoch2, iter0, batch797/1133, batch loss:0.2935524880886078, Training time:58571.40117263794
batch reward last col mean 0.45834726095199585 first col mean 0.4191100001335144 all mean 0.45611879229545593
rl training, epoch2, iter0, batch798/1133, batch loss:0.3938150107860565, Training time:58600.19842147827
batch reward last col mean 0.37789806723594666 first col mean 0.39618349075317383 all mean 0.3784807622432709
rl training, epoch2, iter0, batch799/1133, batch loss:0.33367130160331726, Training time:58629.11033201218
batch reward last col mean 0.4275248050689697 first col mean 0.4282085597515106 all mean 0.42806321382522583
rl training, epoch2, iter0, batch800/1133, batch loss:0.3558958172798157, Training time:58658.09251999855
batch reward last col mean 0.4054209291934967 first col mean 0.4019179344177246 all mean 0.40483933687210083
rl training, epoch2, iter0, batch801/1133, batch loss:0.38602784276008606, Training time:58687.24782371521
batch reward last col mean 0.5086162686347961 first col mean 0.46667909622192383 all mean 0.5075671076774597
rl training, epoch2, iter0, batch802/1133, batch loss:0.48582887649536133, Training time:58716.424980163574
batch reward last col mean 0.39966756105422974 first col mean 0.3944876492023468 all mean 0.3996245265007019
rl training, epoch2, iter0, batch803/1133, batch loss:0.3785715103149414, Training time:58745.5552444458
batch reward last col mean 0.440982460975647 first col mean 0.44847097992897034 all mean 0.44143739342689514
rl training, epoch2, iter0, batch804/1133, batch loss:0.439812570810318, Training time:58774.55073881149
batch reward last col mean 0.48616212606430054 first col mean 0.4870751202106476 all mean 0.48579731583595276
rl training, epoch2, iter0, batch805/1133, batch loss:0.35568511486053467, Training time:58803.68487739563
batch reward last col mean 0.4737274944782257 first col mean 0.47256264090538025 all mean 0.47402703762054443
rl training, epoch2, iter0, batch806/1133, batch loss:0.49358347058296204, Training time:58832.869112730026
batch reward last col mean 0.4086343050003052 first col mean 0.4233933687210083 all mean 0.4100073575973511
rl training, epoch2, iter0, batch807/1133, batch loss:0.3271869421005249, Training time:58861.99512767792
batch reward last col mean 0.3615967631340027 first col mean 0.3778940737247467 all mean 0.3633551299571991
rl training, epoch2, iter0, batch808/1133, batch loss:0.3182969093322754, Training time:58891.12934708595
batch reward last col mean 0.427801251411438 first col mean 0.43549612164497375 all mean 0.42740869522094727
rl training, epoch2, iter0, batch809/1133, batch loss:0.4028983414173126, Training time:58920.564688682556
batch reward last col mean 0.43963146209716797 first col mean 0.43640369176864624 all mean 0.44024693965911865
rl training, epoch2, iter0, batch810/1133, batch loss:0.2885652780532837, Training time:58949.5681180954
batch reward last col mean 0.457399845123291 first col mean 0.4606444835662842 all mean 0.45760074257850647
rl training, epoch2, iter0, batch811/1133, batch loss:0.4041358530521393, Training time:58978.629843473434
batch reward last col mean 0.4510834217071533 first col mean 0.4561234414577484 all mean 0.4508931338787079
rl training, epoch2, iter0, batch812/1133, batch loss:0.43282681703567505, Training time:59007.72120022774
batch reward last col mean 0.4227500855922699 first col mean 0.4242843985557556 all mean 0.4241842031478882
rl training, epoch2, iter0, batch813/1133, batch loss:0.4199366271495819, Training time:59036.97826337814
batch reward last col mean 0.399140328168869 first col mean 0.4023969769477844 all mean 0.39985883235931396
rl training, epoch2, iter0, batch814/1133, batch loss:0.3636173605918884, Training time:59065.73237800598
batch reward last col mean 0.44225484132766724 first col mean 0.45659154653549194 all mean 0.44192057847976685
rl training, epoch2, iter0, batch815/1133, batch loss:0.3917275369167328, Training time:59094.7481944561
batch reward last col mean 0.3841071128845215 first col mean 0.3904283046722412 all mean 0.3840697407722473
rl training, epoch2, iter0, batch816/1133, batch loss:0.31113091111183167, Training time:59123.77880311012
batch reward last col mean 0.42261892557144165 first col mean 0.3980807662010193 all mean 0.4219360649585724
rl training, epoch2, iter0, batch817/1133, batch loss:0.38514217734336853, Training time:59152.83625173569
batch reward last col mean 0.3864597976207733 first col mean 0.3991437256336212 all mean 0.38730388879776
rl training, epoch2, iter0, batch818/1133, batch loss:0.28895342350006104, Training time:59182.15160155296
batch reward last col mean 0.4432147443294525 first col mean 0.45281943678855896 all mean 0.4450729787349701
rl training, epoch2, iter0, batch819/1133, batch loss:0.38933420181274414, Training time:59211.45893597603
batch reward last col mean 0.4021032154560089 first col mean 0.41174229979515076 all mean 0.40177130699157715
rl training, epoch2, iter0, batch820/1133, batch loss:0.33432430028915405, Training time:59241.092475652695
batch reward last col mean 0.40376803278923035 first col mean 0.4276450276374817 all mean 0.40549492835998535
rl training, epoch2, iter0, batch821/1133, batch loss:0.38825881481170654, Training time:59270.7677526474
batch reward last col mean 0.4540170729160309 first col mean 0.455663800239563 all mean 0.45526793599128723
rl training, epoch2, iter0, batch822/1133, batch loss:0.38175275921821594, Training time:59300.39451909065
batch reward last col mean 0.5128523111343384 first col mean 0.47715437412261963 all mean 0.5100528001785278
rl training, epoch2, iter0, batch823/1133, batch loss:0.42273083329200745, Training time:59329.01621437073
batch reward last col mean 0.4759385287761688 first col mean 0.49636122584342957 all mean 0.47801870107650757
rl training, epoch2, iter0, batch824/1133, batch loss:0.32322198152542114, Training time:59358.382573604584
batch reward last col mean 0.44228672981262207 first col mean 0.43139147758483887 all mean 0.4407493472099304
rl training, epoch2, iter0, batch825/1133, batch loss:0.31577548384666443, Training time:59388.16429209709
batch reward last col mean 0.5242854356765747 first col mean 0.49600866436958313 all mean 0.5203822255134583
rl training, epoch2, iter0, batch826/1133, batch loss:0.35827603936195374, Training time:59418.112998485565
batch reward last col mean 0.4246005415916443 first col mean 0.4031197130680084 all mean 0.4144851267337799
rl training, epoch2, iter0, batch827/1133, batch loss:0.26735952496528625, Training time:59448.34042453766
batch reward last col mean 0.4039301872253418 first col mean 0.3955637216567993 all mean 0.3988036811351776
rl training, epoch2, iter0, batch828/1133, batch loss:0.1942463368177414, Training time:59479.54702758789
batch reward last col mean 0.361194908618927 first col mean 0.3201426565647125 all mean 0.3564317524433136
rl training, epoch2, iter0, batch829/1133, batch loss:0.14470988512039185, Training time:59510.07006120682
batch reward last col mean 0.3688739240169525 first col mean 0.33688509464263916 all mean 0.3494948446750641
rl training, epoch2, iter0, batch830/1133, batch loss:0.14650383591651917, Training time:59540.01134347916
batch reward last col mean 0.37294721603393555 first col mean 0.3494330048561096 all mean 0.359721839427948
rl training, epoch2, iter0, batch831/1133, batch loss:0.15055058896541595, Training time:59570.4163646698
batch reward last col mean 0.4482289254665375 first col mean 0.43712717294692993 all mean 0.4452792704105377
rl training, epoch2, iter0, batch832/1133, batch loss:0.26529884338378906, Training time:59601.22468280792
batch reward last col mean 0.4725493788719177 first col mean 0.4581605792045593 all mean 0.4703679382801056
rl training, epoch2, iter0, batch833/1133, batch loss:0.2864716053009033, Training time:59631.36978125572
batch reward last col mean 0.4407062530517578 first col mean 0.4632646441459656 all mean 0.4416070282459259
rl training, epoch2, iter0, batch834/1133, batch loss:0.3079058527946472, Training time:59661.821346998215
batch reward last col mean 0.3752073049545288 first col mean 0.3819734752178192 all mean 0.3761117458343506
rl training, epoch2, iter0, batch835/1133, batch loss:0.3531360924243927, Training time:59691.97472667694
batch reward last col mean 0.49526649713516235 first col mean 0.5005375146865845 all mean 0.4953876733779907
rl training, epoch2, iter0, batch836/1133, batch loss:0.43705928325653076, Training time:59721.40152692795
batch reward last col mean 0.45857056975364685 first col mean 0.4566155672073364 all mean 0.4590674638748169
rl training, epoch2, iter0, batch837/1133, batch loss:0.4107919931411743, Training time:59751.10207104683
batch reward last col mean 0.4760357141494751 first col mean 0.4632606506347656 all mean 0.47614946961402893
rl training, epoch2, iter0, batch838/1133, batch loss:0.44143253564834595, Training time:59781.16974258423
batch reward last col mean 0.41830095648765564 first col mean 0.4181608557701111 all mean 0.41810715198516846
rl training, epoch2, iter0, batch839/1133, batch loss:0.39064106345176697, Training time:59811.1787211895
batch reward last col mean 0.452766090631485 first col mean 0.45920413732528687 all mean 0.4517294764518738
rl training, epoch2, iter0, batch840/1133, batch loss:0.4293724000453949, Training time:59840.66059732437
batch reward last col mean 0.48042845726013184 first col mean 0.4779001772403717 all mean 0.4823992848396301
rl training, epoch2, iter0, batch841/1133, batch loss:0.4647485613822937, Training time:59870.27299118042
batch reward last col mean 0.5493359565734863 first col mean 0.5682982206344604 all mean 0.5494374632835388
rl training, epoch2, iter0, batch842/1133, batch loss:0.4631849527359009, Training time:59899.69781279564
batch reward last col mean 0.4786662757396698 first col mean 0.4608479142189026 all mean 0.4772886037826538
rl training, epoch2, iter0, batch843/1133, batch loss:0.45826494693756104, Training time:59930.187633514404
batch reward last col mean 0.4653555154800415 first col mean 0.5074977874755859 all mean 0.4677569568157196
rl training, epoch2, iter0, batch844/1133, batch loss:0.35935959219932556, Training time:59960.07894206047
batch reward last col mean 0.4899660348892212 first col mean 0.5063250660896301 all mean 0.49246490001678467
rl training, epoch2, iter0, batch845/1133, batch loss:0.4175530970096588, Training time:59989.57108306885
batch reward last col mean 0.4223981499671936 first col mean 0.42696613073349 all mean 0.42548254132270813
rl training, epoch2, iter0, batch846/1133, batch loss:0.3934418857097626, Training time:60019.444576740265
batch reward last col mean 0.4366397261619568 first col mean 0.4259040355682373 all mean 0.4360044002532959
rl training, epoch2, iter0, batch847/1133, batch loss:0.5039045214653015, Training time:60048.63183641434
batch reward last col mean 0.435055673122406 first col mean 0.4312244653701782 all mean 0.4367295205593109
rl training, epoch2, iter0, batch848/1133, batch loss:0.44326433539390564, Training time:60078.19088077545
batch reward last col mean 0.4801619350910187 first col mean 0.47995251417160034 all mean 0.4784497618675232
rl training, epoch2, iter0, batch849/1133, batch loss:0.44748881459236145, Training time:60107.691776275635
batch reward last col mean 0.4958955943584442 first col mean 0.5068919062614441 all mean 0.4949452877044678
rl training, epoch2, iter0, batch850/1133, batch loss:0.4704548120498657, Training time:60137.02239871025
batch reward last col mean 0.4564359784126282 first col mean 0.4742623269557953 all mean 0.4586173892021179
rl training, epoch2, iter0, batch851/1133, batch loss:0.4574309289455414, Training time:60166.380273103714
batch reward last col mean 0.45380863547325134 first col mean 0.48063310980796814 all mean 0.45621320605278015
rl training, epoch2, iter0, batch852/1133, batch loss:0.553569495677948, Training time:60195.76814317703
batch reward last col mean 0.48823070526123047 first col mean 0.5054683685302734 all mean 0.4899154007434845
rl training, epoch2, iter0, batch853/1133, batch loss:0.5445680022239685, Training time:60225.213980674744
batch reward last col mean 0.5349901914596558 first col mean 0.4939994812011719 all mean 0.5328748822212219
rl training, epoch2, iter0, batch854/1133, batch loss:0.542451024055481, Training time:60254.7494559288
batch reward last col mean 0.5029601454734802 first col mean 0.49837392568588257 all mean 0.5024957656860352
rl training, epoch2, iter0, batch855/1133, batch loss:0.6323446035385132, Training time:60284.48557329178
batch reward last col mean 0.42759913206100464 first col mean 0.4380459189414978 all mean 0.42881396412849426
rl training, epoch2, iter0, batch856/1133, batch loss:0.5831575989723206, Training time:60314.213676691055
batch reward last col mean 0.5426453948020935 first col mean 0.5063869953155518 all mean 0.5399380326271057
rl training, epoch2, iter0, batch857/1133, batch loss:0.6055098176002502, Training time:60343.58923149109
batch reward last col mean 0.5151627659797668 first col mean 0.5155167579650879 all mean 0.5148627161979675
rl training, epoch2, iter0, batch858/1133, batch loss:0.570610523223877, Training time:60373.17744612694
batch reward last col mean 0.49386370182037354 first col mean 0.5077649354934692 all mean 0.49496719241142273
rl training, epoch2, iter0, batch859/1133, batch loss:0.5725014209747314, Training time:60403.23640584946
batch reward last col mean 0.4687277376651764 first col mean 0.4818270802497864 all mean 0.46642062067985535
rl training, epoch2, iter0, batch860/1133, batch loss:0.6342782974243164, Training time:60432.831104278564
batch reward last col mean 0.47625476121902466 first col mean 0.4630548357963562 all mean 0.4767756164073944
rl training, epoch2, iter0, batch861/1133, batch loss:0.5861068964004517, Training time:60462.33135986328
batch reward last col mean 0.5592655539512634 first col mean 0.5447901487350464 all mean 0.55617755651474
rl training, epoch2, iter0, batch862/1133, batch loss:0.6522449254989624, Training time:60492.66540527344
batch reward last col mean 0.4659454822540283 first col mean 0.4943420886993408 all mean 0.46965092420578003
rl training, epoch2, iter0, batch863/1133, batch loss:0.5030831694602966, Training time:60522.17932987213
batch reward last col mean 0.4412725865840912 first col mean 0.4701646566390991 all mean 0.4417610466480255
rl training, epoch2, iter0, batch864/1133, batch loss:0.5100365281105042, Training time:60552.041590213776
batch reward last col mean 0.6147264242172241 first col mean 0.6120600700378418 all mean 0.6141954064369202
rl training, epoch2, iter0, batch865/1133, batch loss:0.6222050189971924, Training time:60581.75514817238
batch reward last col mean 0.49201101064682007 first col mean 0.5103853940963745 all mean 0.49244681000709534
rl training, epoch2, iter0, batch866/1133, batch loss:0.4750188887119293, Training time:60612.104687452316
batch reward last col mean 0.5609764456748962 first col mean 0.5710151195526123 all mean 0.5608373284339905
rl training, epoch2, iter0, batch867/1133, batch loss:0.5992648005485535, Training time:60642.73029899597
batch reward last col mean 0.5706467628479004 first col mean 0.5802810788154602 all mean 0.5731948018074036
rl training, epoch2, iter0, batch868/1133, batch loss:0.6108844876289368, Training time:60672.636892318726
batch reward last col mean 0.4936003088951111 first col mean 0.49457573890686035 all mean 0.49394598603248596
rl training, epoch2, iter0, batch869/1133, batch loss:0.6103615164756775, Training time:60702.0271821022
batch reward last col mean 0.5222674608230591 first col mean 0.4860062003135681 all mean 0.520515501499176
rl training, epoch2, iter0, batch870/1133, batch loss:0.6028241515159607, Training time:60731.49150323868
batch reward last col mean 0.5177001357078552 first col mean 0.5270708799362183 all mean 0.5196835994720459
rl training, epoch2, iter0, batch871/1133, batch loss:0.6503357887268066, Training time:60761.564439058304
batch reward last col mean 0.4941009283065796 first col mean 0.49338680505752563 all mean 0.4943200945854187
rl training, epoch2, iter0, batch872/1133, batch loss:0.6273680329322815, Training time:60791.51214623451
batch reward last col mean 0.5098502039909363 first col mean 0.513168454170227 all mean 0.5082330703735352
rl training, epoch2, iter0, batch873/1133, batch loss:0.5967161655426025, Training time:60821.875606775284
batch reward last col mean 0.4944596290588379 first col mean 0.5297274589538574 all mean 0.49929651618003845
rl training, epoch2, iter0, batch874/1133, batch loss:0.6868114471435547, Training time:60852.46789312363
batch reward last col mean 0.5390885472297668 first col mean 0.5573152303695679 all mean 0.5380445718765259
rl training, epoch2, iter0, batch875/1133, batch loss:0.6018877029418945, Training time:60882.25882554054
batch reward last col mean 0.5497083067893982 first col mean 0.5196558237075806 all mean 0.5460116267204285
rl training, epoch2, iter0, batch876/1133, batch loss:0.6735576391220093, Training time:60912.46131134033
batch reward last col mean 0.4965441823005676 first col mean 0.48992758989334106 all mean 0.4985271394252777
rl training, epoch2, iter0, batch877/1133, batch loss:0.6345378160476685, Training time:60943.649945259094
batch reward last col mean 0.5581929087638855 first col mean 0.5360907912254333 all mean 0.5548853278160095
rl training, epoch2, iter0, batch878/1133, batch loss:0.694911777973175, Training time:60974.68395471573
batch reward last col mean 0.5235124230384827 first col mean 0.5215765833854675 all mean 0.5171737670898438
rl training, epoch2, iter0, batch879/1133, batch loss:0.6219449639320374, Training time:61005.56071805954
batch reward last col mean 0.5014106631278992 first col mean 0.4530624449253082 all mean 0.4833744764328003
rl training, epoch2, iter0, batch880/1133, batch loss:0.4137074649333954, Training time:61036.15731191635
batch reward last col mean 0.5209150314331055 first col mean 0.4828321039676666 all mean 0.5102266669273376
rl training, epoch2, iter0, batch881/1133, batch loss:0.433529794216156, Training time:61067.29850959778
batch reward last col mean 0.48876482248306274 first col mean 0.4837479591369629 all mean 0.48889005184173584
rl training, epoch2, iter0, batch882/1133, batch loss:0.4636056423187256, Training time:61097.54932665825
batch reward last col mean 0.548638641834259 first col mean 0.5776376724243164 all mean 0.5538758039474487
rl training, epoch2, iter0, batch883/1133, batch loss:0.6364960074424744, Training time:61128.68714380264
batch reward last col mean 0.5423859357833862 first col mean 0.5324501395225525 all mean 0.5431711077690125
rl training, epoch2, iter0, batch884/1133, batch loss:0.5523589849472046, Training time:61159.44376015663
batch reward last col mean 0.5565094947814941 first col mean 0.5498710870742798 all mean 0.5585744380950928
rl training, epoch2, iter0, batch885/1133, batch loss:0.6645780801773071, Training time:61189.03706741333
batch reward last col mean 0.5098360776901245 first col mean 0.5258969068527222 all mean 0.5088945627212524
rl training, epoch2, iter0, batch886/1133, batch loss:0.5995485782623291, Training time:61219.25492858887
batch reward last col mean 0.5325021147727966 first col mean 0.5528333783149719 all mean 0.5318244695663452
rl training, epoch2, iter0, batch887/1133, batch loss:0.5959291458129883, Training time:61250.11237311363
batch reward last col mean 0.5161646008491516 first col mean 0.527974009513855 all mean 0.5174691081047058
rl training, epoch2, iter0, batch888/1133, batch loss:0.6742697954177856, Training time:61279.8952357769
batch reward last col mean 0.5278393626213074 first col mean 0.5069660544395447 all mean 0.526076078414917
rl training, epoch2, iter0, batch889/1133, batch loss:0.6763383746147156, Training time:61309.78466653824
batch reward last col mean 0.5327814817428589 first col mean 0.492946982383728 all mean 0.5297965407371521
rl training, epoch2, iter0, batch890/1133, batch loss:0.6654970049858093, Training time:61339.73704004288
batch reward last col mean 0.5605884790420532 first col mean 0.5759652853012085 all mean 0.5611955523490906
rl training, epoch2, iter0, batch891/1133, batch loss:0.6925328969955444, Training time:61369.61356425285
batch reward last col mean 0.5329114198684692 first col mean 0.534218430519104 all mean 0.5330674648284912
rl training, epoch2, iter0, batch892/1133, batch loss:0.6824725866317749, Training time:61398.9932115078
batch reward last col mean 0.5549567937850952 first col mean 0.5274074673652649 all mean 0.5522561073303223
rl training, epoch2, iter0, batch893/1133, batch loss:0.6951162815093994, Training time:61428.99863553047
batch reward last col mean 0.539872407913208 first col mean 0.5702962875366211 all mean 0.5416675806045532
rl training, epoch2, iter0, batch894/1133, batch loss:0.7171961665153503, Training time:61457.78445863724
batch reward last col mean 0.4833267033100128 first col mean 0.51495361328125 all mean 0.4841752350330353
rl training, epoch2, iter0, batch895/1133, batch loss:0.6472209692001343, Training time:61487.01076459885
batch reward last col mean 0.5644998550415039 first col mean 0.5712820887565613 all mean 0.5641390681266785
rl training, epoch2, iter0, batch896/1133, batch loss:0.760309636592865, Training time:61516.84591627121
batch reward last col mean 0.5788123607635498 first col mean 0.5618026256561279 all mean 0.5783472061157227
rl training, epoch2, iter0, batch897/1133, batch loss:0.7303051948547363, Training time:61546.49745106697
batch reward last col mean 0.5005964636802673 first col mean 0.5220353603363037 all mean 0.5015518665313721
rl training, epoch2, iter0, batch898/1133, batch loss:0.6245933771133423, Training time:61575.86956381798
batch reward last col mean 0.5358834266662598 first col mean 0.5449259877204895 all mean 0.5359650254249573
rl training, epoch2, iter0, batch899/1133, batch loss:0.6449976563453674, Training time:61605.49982523918
batch reward last col mean 0.5292254090309143 first col mean 0.5467619299888611 all mean 0.5300747752189636
rl training, epoch2, iter0, batch900/1133, batch loss:0.649140477180481, Training time:61634.57504105568
batch reward last col mean 0.5578502416610718 first col mean 0.5496973395347595 all mean 0.5564885139465332
rl training, epoch2, iter0, batch901/1133, batch loss:0.6568402647972107, Training time:61664.400884628296
batch reward last col mean 0.5488232970237732 first col mean 0.5433504581451416 all mean 0.5463964343070984
rl training, epoch2, iter0, batch902/1133, batch loss:0.6668544411659241, Training time:61694.66848921776
batch reward last col mean 0.5292693376541138 first col mean 0.5406179428100586 all mean 0.5309752821922302
rl training, epoch2, iter0, batch903/1133, batch loss:0.6496908664703369, Training time:61725.125183820724
batch reward last col mean 0.5882219672203064 first col mean 0.5570186376571655 all mean 0.5851827263832092
rl training, epoch2, iter0, batch904/1133, batch loss:0.647310197353363, Training time:61755.25212144852
batch reward last col mean 0.5185996890068054 first col mean 0.5196722745895386 all mean 0.5163556337356567
rl training, epoch2, iter0, batch905/1133, batch loss:0.5723677277565002, Training time:61785.32223033905
batch reward last col mean 0.5408861041069031 first col mean 0.5196289420127869 all mean 0.5387410521507263
rl training, epoch2, iter0, batch906/1133, batch loss:0.582360029220581, Training time:61815.65854096413
batch reward last col mean 0.5109713077545166 first col mean 0.49701058864593506 all mean 0.5117148756980896
rl training, epoch2, iter0, batch907/1133, batch loss:0.5575940012931824, Training time:61845.437383413315
batch reward last col mean 0.46369507908821106 first col mean 0.47699829936027527 all mean 0.4626410901546478
rl training, epoch2, iter0, batch908/1133, batch loss:0.5753969550132751, Training time:61875.13802242279
batch reward last col mean 0.49910569190979004 first col mean 0.49564599990844727 all mean 0.4986649453639984
rl training, epoch2, iter0, batch909/1133, batch loss:0.6522876024246216, Training time:61904.799258470535
batch reward last col mean 0.5087375044822693 first col mean 0.4954431354999542 all mean 0.5084617137908936
rl training, epoch2, iter0, batch910/1133, batch loss:0.5825586915016174, Training time:61934.55209302902
batch reward last col mean 0.5699636936187744 first col mean 0.5881542563438416 all mean 0.5699237585067749
rl training, epoch2, iter0, batch911/1133, batch loss:0.7096170783042908, Training time:61963.975534677505
batch reward last col mean 0.5284526348114014 first col mean 0.5332408547401428 all mean 0.5293394327163696
rl training, epoch2, iter0, batch912/1133, batch loss:0.6520907282829285, Training time:61993.594863414764
batch reward last col mean 0.5060400366783142 first col mean 0.4938308000564575 all mean 0.5059124231338501
rl training, epoch2, iter0, batch913/1133, batch loss:0.6835885047912598, Training time:62023.085346221924
batch reward last col mean 0.5442681908607483 first col mean 0.5397071838378906 all mean 0.5428504347801208
rl training, epoch2, iter0, batch914/1133, batch loss:0.6861205101013184, Training time:62052.3821182251
batch reward last col mean 0.4942083954811096 first col mean 0.5295427441596985 all mean 0.4972917139530182
rl training, epoch2, iter0, batch915/1133, batch loss:0.6310098171234131, Training time:62081.903757333755
batch reward last col mean 0.5400153398513794 first col mean 0.5270564556121826 all mean 0.5388098955154419
rl training, epoch2, iter0, batch916/1133, batch loss:0.6649279594421387, Training time:62111.177720069885
batch reward last col mean 0.53890061378479 first col mean 0.5459222197532654 all mean 0.5397112965583801
rl training, epoch2, iter0, batch917/1133, batch loss:0.6971721649169922, Training time:62140.60484910011
batch reward last col mean 0.5226276516914368 first col mean 0.5460923910140991 all mean 0.5238123536109924
rl training, epoch2, iter0, batch918/1133, batch loss:0.6170093417167664, Training time:62170.035176754
batch reward last col mean 0.5727218389511108 first col mean 0.5629764795303345 all mean 0.5708483457565308
rl training, epoch2, iter0, batch919/1133, batch loss:0.6821531653404236, Training time:62198.17976021767
batch reward last col mean 0.550779402256012 first col mean 0.5535194277763367 all mean 0.5516586899757385
rl training, epoch2, iter0, batch920/1133, batch loss:0.661970853805542, Training time:62228.0511944294
batch reward last col mean 0.568513810634613 first col mean 0.5784041881561279 all mean 0.5685303807258606
rl training, epoch2, iter0, batch921/1133, batch loss:0.6778673529624939, Training time:62257.04845952988
batch reward last col mean 0.5155044198036194 first col mean 0.5391470193862915 all mean 0.5165999531745911
rl training, epoch2, iter0, batch922/1133, batch loss:0.6010715961456299, Training time:62286.15842461586
batch reward last col mean 0.5189369320869446 first col mean 0.5323116779327393 all mean 0.520893931388855
rl training, epoch2, iter0, batch923/1133, batch loss:0.5714750289916992, Training time:62315.52241754532
batch reward last col mean 0.5706692934036255 first col mean 0.5580667853355408 all mean 0.5701069831848145
rl training, epoch2, iter0, batch924/1133, batch loss:0.6296380162239075, Training time:62344.785348415375
batch reward last col mean 0.5138630270957947 first col mean 0.5302542448043823 all mean 0.5159705877304077
rl training, epoch2, iter0, batch925/1133, batch loss:0.6085294485092163, Training time:62374.591213703156
batch reward last col mean 0.594236433506012 first col mean 0.5943681001663208 all mean 0.5953512191772461
rl training, epoch2, iter0, batch926/1133, batch loss:0.6504300832748413, Training time:62404.710419654846
batch reward last col mean 0.5097268223762512 first col mean 0.5161560773849487 all mean 0.5106254816055298
rl training, epoch2, iter0, batch927/1133, batch loss:0.5706782937049866, Training time:62434.37666130066
batch reward last col mean 0.5538754463195801 first col mean 0.5491951107978821 all mean 0.5539067387580872
rl training, epoch2, iter0, batch928/1133, batch loss:0.5903641581535339, Training time:62463.99076628685
batch reward last col mean 0.5126794576644897 first col mean 0.5255464315414429 all mean 0.5133818984031677
rl training, epoch2, iter0, batch929/1133, batch loss:0.6296838521957397, Training time:62493.15331149101
batch reward last col mean 0.6017731428146362 first col mean 0.5909597277641296 all mean 0.6013202667236328
rl training, epoch2, iter0, batch930/1133, batch loss:0.701100766658783, Training time:62523.233778715134
batch reward last col mean 0.5710952877998352 first col mean 0.5468443632125854 all mean 0.5711845755577087
rl training, epoch2, iter0, batch931/1133, batch loss:0.644516110420227, Training time:62552.02618408203
batch reward last col mean 0.5638696551322937 first col mean 0.5575958490371704 all mean 0.5637335181236267
rl training, epoch2, iter0, batch932/1133, batch loss:0.6925726532936096, Training time:62581.19830727577
batch reward last col mean 0.5689274072647095 first col mean 0.5625662803649902 all mean 0.5684605836868286
rl training, epoch2, iter0, batch933/1133, batch loss:0.5874336957931519, Training time:62610.348986148834
batch reward last col mean 0.521443247795105 first col mean 0.543837308883667 all mean 0.5237482786178589
rl training, epoch2, iter0, batch934/1133, batch loss:0.5704993605613708, Training time:62639.52702832222
batch reward last col mean 0.5546395778656006 first col mean 0.5590640306472778 all mean 0.5563544034957886
rl training, epoch2, iter0, batch935/1133, batch loss:0.56575608253479, Training time:62669.11358046532
batch reward last col mean 0.5525990128517151 first col mean 0.5775699615478516 all mean 0.55227130651474
rl training, epoch2, iter0, batch936/1133, batch loss:0.4909839630126953, Training time:62698.53690576553
batch reward last col mean 0.605614185333252 first col mean 0.5778457522392273 all mean 0.6031156182289124
rl training, epoch2, iter0, batch937/1133, batch loss:0.6229787468910217, Training time:62727.9568874836
batch reward last col mean 0.5504652857780457 first col mean 0.5545334815979004 all mean 0.5500696301460266
rl training, epoch2, iter0, batch938/1133, batch loss:0.5136763453483582, Training time:62758.00627326965
batch reward last col mean 0.5740729570388794 first col mean 0.5846744179725647 all mean 0.5745219588279724
rl training, epoch2, iter0, batch939/1133, batch loss:0.5365720391273499, Training time:62788.061913490295
batch reward last col mean 0.5223565697669983 first col mean 0.5170528292655945 all mean 0.5211806893348694
rl training, epoch2, iter0, batch940/1133, batch loss:0.4803083837032318, Training time:62817.32419347763
batch reward last col mean 0.5255558490753174 first col mean 0.5327615737915039 all mean 0.5282018780708313
rl training, epoch2, iter0, batch941/1133, batch loss:0.44365766644477844, Training time:62847.21293568611
batch reward last col mean 0.5381777882575989 first col mean 0.5336748361587524 all mean 0.5366068482398987
rl training, epoch2, iter0, batch942/1133, batch loss:0.3721063435077667, Training time:62877.897002220154
batch reward last col mean 0.517801821231842 first col mean 0.5141044855117798 all mean 0.5156041979789734
rl training, epoch2, iter0, batch943/1133, batch loss:0.4164792001247406, Training time:62908.24139356613
batch reward last col mean 0.4824002981185913 first col mean 0.4614900052547455 all mean 0.4791208803653717
rl training, epoch2, iter0, batch944/1133, batch loss:0.2854863703250885, Training time:62938.988916158676
batch reward last col mean 0.5579609870910645 first col mean 0.5295937061309814 all mean 0.5538135766983032
rl training, epoch2, iter0, batch945/1133, batch loss:0.40888985991477966, Training time:62969.75850582123
batch reward last col mean 0.5704986453056335 first col mean 0.5439664125442505 all mean 0.5687045454978943
rl training, epoch2, iter0, batch946/1133, batch loss:0.4437687397003174, Training time:62999.53909778595
batch reward last col mean 0.5444276332855225 first col mean 0.5713673830032349 all mean 0.5459369421005249
rl training, epoch2, iter0, batch947/1133, batch loss:0.4740489423274994, Training time:63028.77512836456
batch reward last col mean 0.5868856906890869 first col mean 0.5885658860206604 all mean 0.5877755880355835
rl training, epoch2, iter0, batch948/1133, batch loss:0.5098223090171814, Training time:63058.25949382782
batch reward last col mean 0.5584564208984375 first col mean 0.5302430391311646 all mean 0.5569828152656555
rl training, epoch2, iter0, batch949/1133, batch loss:0.5342576503753662, Training time:63087.574578523636
batch reward last col mean 0.5710800886154175 first col mean 0.5830433368682861 all mean 0.5719968676567078
rl training, epoch2, iter0, batch950/1133, batch loss:0.5564565062522888, Training time:63116.57483577728
batch reward last col mean 0.569398045539856 first col mean 0.5738092064857483 all mean 0.5670011639595032
rl training, epoch2, iter0, batch951/1133, batch loss:0.5663449764251709, Training time:63145.440932273865
batch reward last col mean 0.5470458269119263 first col mean 0.5206406712532043 all mean 0.5462979674339294
rl training, epoch2, iter0, batch952/1133, batch loss:0.4691992998123169, Training time:63174.58190727234
batch reward last col mean 0.5679822564125061 first col mean 0.5913738012313843 all mean 0.5696977972984314
rl training, epoch2, iter0, batch953/1133, batch loss:0.5095359683036804, Training time:63203.902975559235
batch reward last col mean 0.5020880103111267 first col mean 0.5223048329353333 all mean 0.5034030675888062
rl training, epoch2, iter0, batch954/1133, batch loss:0.45334920287132263, Training time:63233.11825656891
batch reward last col mean 0.6083242297172546 first col mean 0.624527096748352 all mean 0.6091972589492798
rl training, epoch2, iter0, batch955/1133, batch loss:0.5241287350654602, Training time:63262.06532430649
batch reward last col mean 0.5894899964332581 first col mean 0.5721216797828674 all mean 0.5889962911605835
rl training, epoch2, iter0, batch956/1133, batch loss:0.564482569694519, Training time:63291.575119018555
batch reward last col mean 0.5311344861984253 first col mean 0.5217955708503723 all mean 0.5301507711410522
rl training, epoch2, iter0, batch957/1133, batch loss:0.5197107195854187, Training time:63320.98316049576
batch reward last col mean 0.5456555485725403 first col mean 0.5176963806152344 all mean 0.545195460319519
rl training, epoch2, iter0, batch958/1133, batch loss:0.5411852598190308, Training time:63349.504012584686
batch reward last col mean 0.48525065183639526 first col mean 0.49628764390945435 all mean 0.4859330952167511
rl training, epoch2, iter0, batch959/1133, batch loss:0.420553982257843, Training time:63378.53109025955
batch reward last col mean 0.5266773104667664 first col mean 0.536816418170929 all mean 0.5266302824020386
rl training, epoch2, iter0, batch960/1133, batch loss:0.46569475531578064, Training time:63407.718302726746
batch reward last col mean 0.5273984670639038 first col mean 0.5590091347694397 all mean 0.5287052989006042
rl training, epoch2, iter0, batch961/1133, batch loss:0.4904497563838959, Training time:63436.61999297142
batch reward last col mean 0.5348793864250183 first col mean 0.539614200592041 all mean 0.5361433029174805
rl training, epoch2, iter0, batch962/1133, batch loss:0.5145049095153809, Training time:63465.50018644333
batch reward last col mean 0.5487712621688843 first col mean 0.5553897619247437 all mean 0.5493803024291992
rl training, epoch2, iter0, batch963/1133, batch loss:0.4460750222206116, Training time:63494.474556684494
batch reward last col mean 0.5841348767280579 first col mean 0.5544840693473816 all mean 0.5836951732635498
rl training, epoch2, iter0, batch964/1133, batch loss:0.5134246349334717, Training time:63524.164428949356
batch reward last col mean 0.5245028734207153 first col mean 0.5130359530448914 all mean 0.5242719650268555
rl training, epoch2, iter0, batch965/1133, batch loss:0.5322957038879395, Training time:63553.73213720322
batch reward last col mean 0.5318292379379272 first col mean 0.5379050970077515 all mean 0.5314342379570007
rl training, epoch2, iter0, batch966/1133, batch loss:0.4220418334007263, Training time:63582.878328084946
batch reward last col mean 0.5284665822982788 first col mean 0.5448427796363831 all mean 0.529682457447052
rl training, epoch2, iter0, batch967/1133, batch loss:0.48506543040275574, Training time:63612.69716358185
batch reward last col mean 0.5937008857727051 first col mean 0.5968613624572754 all mean 0.5928837656974792
rl training, epoch2, iter0, batch968/1133, batch loss:0.3871716558933258, Training time:63641.85829305649
batch reward last col mean 0.5539137125015259 first col mean 0.5387179851531982 all mean 0.5518724322319031
rl training, epoch2, iter0, batch969/1133, batch loss:0.4232743978500366, Training time:63671.75986742973
batch reward last col mean 0.5654342174530029 first col mean 0.5633493065834045 all mean 0.5649153590202332
rl training, epoch2, iter0, batch970/1133, batch loss:0.4319002628326416, Training time:63701.07594490051
batch reward last col mean 0.5810223817825317 first col mean 0.5525991916656494 all mean 0.5784783363342285
rl training, epoch2, iter0, batch971/1133, batch loss:0.4149574935436249, Training time:63729.802991867065
batch reward last col mean 0.6189613938331604 first col mean 0.6320436000823975 all mean 0.6194815039634705
rl training, epoch2, iter0, batch972/1133, batch loss:0.5379592180252075, Training time:63759.13846325874
batch reward last col mean 0.5946213603019714 first col mean 0.5995116233825684 all mean 0.5947362780570984
rl training, epoch2, iter0, batch973/1133, batch loss:0.5090656876564026, Training time:63788.27994680405
batch reward last col mean 0.6026783585548401 first col mean 0.6051266193389893 all mean 0.6019145250320435
rl training, epoch2, iter0, batch974/1133, batch loss:0.5270829796791077, Training time:63817.74167585373
batch reward last col mean 0.6329896450042725 first col mean 0.6378260850906372 all mean 0.633666455745697
rl training, epoch2, iter0, batch975/1133, batch loss:0.5512654781341553, Training time:63847.104939460754
batch reward last col mean 0.5859518647193909 first col mean 0.5783751010894775 all mean 0.5851283073425293
rl training, epoch2, iter0, batch976/1133, batch loss:0.4851149022579193, Training time:63875.914811849594
batch reward last col mean 0.5960803031921387 first col mean 0.5976337194442749 all mean 0.5960214734077454
rl training, epoch2, iter0, batch977/1133, batch loss:0.49360391497612, Training time:63904.92834997177
batch reward last col mean 0.6046192646026611 first col mean 0.6434007883071899 all mean 0.606177568435669
rl training, epoch2, iter0, batch978/1133, batch loss:0.5629613995552063, Training time:63932.98323106766
batch reward last col mean 0.6328572034835815 first col mean 0.6371368169784546 all mean 0.6326867938041687
rl training, epoch2, iter0, batch979/1133, batch loss:0.559814989566803, Training time:63961.68614935875
batch reward last col mean 0.646208643913269 first col mean 0.6295214891433716 all mean 0.6451345086097717
rl training, epoch2, iter0, batch980/1133, batch loss:0.5309334397315979, Training time:63990.5462846756
batch reward last col mean 0.6588289141654968 first col mean 0.6255264282226562 all mean 0.6586827039718628
rl training, epoch2, iter0, batch981/1133, batch loss:0.5289960503578186, Training time:64019.542056560516
batch reward last col mean 0.6720740795135498 first col mean 0.6714353561401367 all mean 0.6711883544921875
rl training, epoch2, iter0, batch982/1133, batch loss:0.536004900932312, Training time:64048.37350964546
batch reward last col mean 0.6129608154296875 first col mean 0.6145612001419067 all mean 0.6131436824798584
rl training, epoch2, iter0, batch983/1133, batch loss:0.479854017496109, Training time:64077.31338953972
batch reward last col mean 0.6133022904396057 first col mean 0.6297569274902344 all mean 0.6143871545791626
rl training, epoch2, iter0, batch984/1133, batch loss:0.5188916325569153, Training time:64106.596068143845
batch reward last col mean 0.5869334936141968 first col mean 0.5851830244064331 all mean 0.5865079164505005
rl training, epoch2, iter0, batch985/1133, batch loss:0.45128318667411804, Training time:64135.62301015854
batch reward last col mean 0.5405073761940002 first col mean 0.5403717756271362 all mean 0.5403520464897156
rl training, epoch2, iter0, batch986/1133, batch loss:0.3535078763961792, Training time:64164.70457267761
batch reward last col mean 0.5888155698776245 first col mean 0.6163899302482605 all mean 0.5897305607795715
rl training, epoch2, iter0, batch987/1133, batch loss:0.4360986053943634, Training time:64193.94955801964
batch reward last col mean 0.5632210969924927 first col mean 0.5890389680862427 all mean 0.5640538930892944
rl training, epoch2, iter0, batch988/1133, batch loss:0.41222772002220154, Training time:64223.10588479042
batch reward last col mean 0.6002455949783325 first col mean 0.6033675670623779 all mean 0.6002344489097595
rl training, epoch2, iter0, batch989/1133, batch loss:0.44468462467193604, Training time:64252.250920295715
batch reward last col mean 0.636517345905304 first col mean 0.6284750699996948 all mean 0.6369242072105408
rl training, epoch2, iter0, batch990/1133, batch loss:0.48871198296546936, Training time:64280.51133799553
batch reward last col mean 0.6105899214744568 first col mean 0.6015589237213135 all mean 0.6106215715408325
rl training, epoch2, iter0, batch991/1133, batch loss:0.4243618845939636, Training time:64309.28851675987
batch reward last col mean 0.6034095287322998 first col mean 0.6083099246025085 all mean 0.6034521460533142
rl training, epoch2, iter0, batch992/1133, batch loss:0.3681170344352722, Training time:64338.22617292404
batch reward last col mean 0.6436723470687866 first col mean 0.6262408494949341 all mean 0.6426202654838562
rl training, epoch2, iter0, batch993/1133, batch loss:0.4049985408782959, Training time:64367.24120283127
batch reward last col mean 0.5854610204696655 first col mean 0.6106225848197937 all mean 0.5861375331878662
rl training, epoch2, iter0, batch994/1133, batch loss:0.37535420060157776, Training time:64396.12074971199
batch reward last col mean 0.6207471489906311 first col mean 0.6464813351631165 all mean 0.6211839318275452
rl training, epoch2, iter0, batch995/1133, batch loss:0.5187496542930603, Training time:64424.81761932373
batch reward last col mean 0.5917201042175293 first col mean 0.5816696882247925 all mean 0.5912160277366638
rl training, epoch2, iter0, batch996/1133, batch loss:0.3861727714538574, Training time:64453.54600214958
batch reward last col mean 0.5272812843322754 first col mean 0.5445920825004578 all mean 0.527797281742096
rl training, epoch2, iter0, batch997/1133, batch loss:0.40223395824432373, Training time:64482.077827215195
batch reward last col mean 0.5663468241691589 first col mean 0.6099721789360046 all mean 0.5669879913330078
rl training, epoch2, iter0, batch998/1133, batch loss:0.41689932346343994, Training time:64510.85097074509
batch reward last col mean 0.5822144746780396 first col mean 0.5924336910247803 all mean 0.582449197769165
rl training, epoch2, iter0, batch999/1133, batch loss:0.3557102084159851, Training time:64539.822266340256
batch reward last col mean 0.5559006929397583 first col mean 0.5579647421836853 all mean 0.5560324788093567
rl training, epoch2, iter0, batch1000/1133, batch loss:0.37672969698905945, Training time:64568.62102675438
batch reward last col mean 0.5619871616363525 first col mean 0.5541199445724487 all mean 0.5618854761123657
rl training, epoch2, iter0, batch1001/1133, batch loss:0.3623808026313782, Training time:64597.44878292084
batch reward last col mean 0.5803698301315308 first col mean 0.5943945646286011 all mean 0.5810633897781372
rl training, epoch2, iter0, batch1002/1133, batch loss:0.38836368918418884, Training time:64626.431312799454
batch reward last col mean 0.5713378190994263 first col mean 0.579421877861023 all mean 0.5714053511619568
rl training, epoch2, iter0, batch1003/1133, batch loss:0.3824881315231323, Training time:64655.208535671234
batch reward last col mean 0.5601891279220581 first col mean 0.5521034002304077 all mean 0.5600197911262512
rl training, epoch2, iter0, batch1004/1133, batch loss:0.39194348454475403, Training time:64682.794830322266
batch reward last col mean 0.6147448420524597 first col mean 0.6169636249542236 all mean 0.6157219409942627
rl training, epoch2, iter0, batch1005/1133, batch loss:0.4118708372116089, Training time:64711.630575180054
batch reward last col mean 0.5924516320228577 first col mean 0.5868873000144958 all mean 0.5919168591499329
rl training, epoch2, iter0, batch1006/1133, batch loss:0.35850921273231506, Training time:64740.93624711037
batch reward last col mean 0.5566977262496948 first col mean 0.5726167559623718 all mean 0.5571572184562683
rl training, epoch2, iter0, batch1007/1133, batch loss:0.3458002805709839, Training time:64769.526471853256
batch reward last col mean 0.6209884881973267 first col mean 0.6146798133850098 all mean 0.6214092969894409
rl training, epoch2, iter0, batch1008/1133, batch loss:0.4210590422153473, Training time:64798.03925585747
batch reward last col mean 0.6084542274475098 first col mean 0.579414427280426 all mean 0.6074756383895874
rl training, epoch2, iter0, batch1009/1133, batch loss:0.39038658142089844, Training time:64826.452430963516
batch reward last col mean 0.5929189920425415 first col mean 0.6106961369514465 all mean 0.593563973903656
rl training, epoch2, iter0, batch1010/1133, batch loss:0.40219804644584656, Training time:64855.419430971146
batch reward last col mean 0.6459832191467285 first col mean 0.6103821396827698 all mean 0.6448484659194946
rl training, epoch2, iter0, batch1011/1133, batch loss:0.4048348367214203, Training time:64883.90527629852
batch reward last col mean 0.600953221321106 first col mean 0.5852853655815125 all mean 0.6010725498199463
rl training, epoch2, iter0, batch1012/1133, batch loss:0.37688934803009033, Training time:64912.89861059189
batch reward last col mean 0.6302120685577393 first col mean 0.6206653714179993 all mean 0.6301358938217163
rl training, epoch2, iter0, batch1013/1133, batch loss:0.3929402232170105, Training time:64941.97424411774
batch reward last col mean 0.609656035900116 first col mean 0.5937632322311401 all mean 0.6092351078987122
rl training, epoch2, iter0, batch1014/1133, batch loss:0.4049554765224457, Training time:64971.10588788986
batch reward last col mean 0.6155000925064087 first col mean 0.6192949414253235 all mean 0.6157344579696655
rl training, epoch2, iter0, batch1015/1133, batch loss:0.4462629556655884, Training time:65000.127544403076
batch reward last col mean 0.6774395108222961 first col mean 0.6535054445266724 all mean 0.6762174367904663
rl training, epoch2, iter0, batch1016/1133, batch loss:0.4223783612251282, Training time:65029.031000614166
batch reward last col mean 0.5986231565475464 first col mean 0.580410361289978 all mean 0.5982517004013062
rl training, epoch2, iter0, batch1017/1133, batch loss:0.38443613052368164, Training time:65057.319207429886
batch reward last col mean 0.6283621788024902 first col mean 0.6433418989181519 all mean 0.6289331912994385
rl training, epoch2, iter0, batch1018/1133, batch loss:0.40467458963394165, Training time:65086.54034614563
batch reward last col mean 0.5726014971733093 first col mean 0.6014876365661621 all mean 0.5734608769416809
rl training, epoch2, iter0, batch1019/1133, batch loss:0.3905123174190521, Training time:65115.60290789604
batch reward last col mean 0.6157577633857727 first col mean 0.5969300270080566 all mean 0.6156941652297974
rl training, epoch2, iter0, batch1020/1133, batch loss:0.4647572636604309, Training time:65145.185678482056
batch reward last col mean 0.5969758033752441 first col mean 0.6145474314689636 all mean 0.5976153016090393
rl training, epoch2, iter0, batch1021/1133, batch loss:0.39074382185935974, Training time:65174.5580432415
batch reward last col mean 0.5651752352714539 first col mean 0.5743716359138489 all mean 0.565069854259491
rl training, epoch2, iter0, batch1022/1133, batch loss:0.37104183435440063, Training time:65203.42286109924
batch reward last col mean 0.6169775724411011 first col mean 0.627354621887207 all mean 0.6166220903396606
rl training, epoch2, iter0, batch1023/1133, batch loss:0.427599161863327, Training time:65232.17168903351
batch reward last col mean 0.6537669897079468 first col mean 0.6394405364990234 all mean 0.6530343890190125
rl training, epoch2, iter0, batch1024/1133, batch loss:0.4207842946052551, Training time:65260.79271483421
batch reward last col mean 0.5954908132553101 first col mean 0.6133913993835449 all mean 0.5961827635765076
rl training, epoch2, iter0, batch1025/1133, batch loss:0.42449089884757996, Training time:65289.6026391983
batch reward last col mean 0.5826748609542847 first col mean 0.6233829259872437 all mean 0.5840318202972412
rl training, epoch2, iter0, batch1026/1133, batch loss:0.42480847239494324, Training time:65318.38358449936
batch reward last col mean 0.607168436050415 first col mean 0.6174062490463257 all mean 0.6070302128791809
rl training, epoch2, iter0, batch1027/1133, batch loss:0.46242958307266235, Training time:65347.55694413185
batch reward last col mean 0.6123273372650146 first col mean 0.5997051000595093 all mean 0.6113930344581604
rl training, epoch2, iter0, batch1028/1133, batch loss:0.4159325659275055, Training time:65376.770654439926
batch reward last col mean 0.6074718236923218 first col mean 0.622921347618103 all mean 0.6081028580665588
rl training, epoch2, iter0, batch1029/1133, batch loss:0.4187982380390167, Training time:65406.27211737633
batch reward last col mean 0.6717928647994995 first col mean 0.6712974905967712 all mean 0.6711028218269348
rl training, epoch2, iter0, batch1030/1133, batch loss:0.46312057971954346, Training time:65435.61097693443
batch reward last col mean 0.6000512838363647 first col mean 0.5950922966003418 all mean 0.599175751209259
rl training, epoch2, iter0, batch1031/1133, batch loss:0.43457555770874023, Training time:65465.02203011513
batch reward last col mean 0.6602831482887268 first col mean 0.6385791897773743 all mean 0.6587197780609131
rl training, epoch2, iter0, batch1032/1133, batch loss:0.47445711493492126, Training time:65494.17109847069
batch reward last col mean 0.5840567946434021 first col mean 0.5848613381385803 all mean 0.5837652683258057
rl training, epoch2, iter0, batch1033/1133, batch loss:0.3904164731502533, Training time:65523.57271528244
batch reward last col mean 0.6707600355148315 first col mean 0.6751671433448792 all mean 0.6712397336959839
rl training, epoch2, iter0, batch1034/1133, batch loss:0.4896338880062103, Training time:65553.1807949543
batch reward last col mean 0.6248556971549988 first col mean 0.5939599275588989 all mean 0.624075710773468
rl training, epoch2, iter0, batch1035/1133, batch loss:0.43846532702445984, Training time:65582.46621274948
batch reward last col mean 0.6173322796821594 first col mean 0.653297483921051 all mean 0.6182985305786133
rl training, epoch2, iter0, batch1036/1133, batch loss:0.48952868580818176, Training time:65612.05937361717
batch reward last col mean 0.6158205270767212 first col mean 0.6123785972595215 all mean 0.6155054569244385
rl training, epoch2, iter0, batch1037/1133, batch loss:0.4672337770462036, Training time:65641.63440561295
batch reward last col mean 0.6329134702682495 first col mean 0.6223176717758179 all mean 0.634333074092865
rl training, epoch2, iter0, batch1038/1133, batch loss:0.45093581080436707, Training time:65671.61342811584
batch reward last col mean 0.5805443525314331 first col mean 0.5847874879837036 all mean 0.5819764733314514
rl training, epoch2, iter0, batch1039/1133, batch loss:0.43885326385498047, Training time:65700.87438750267
batch reward last col mean 0.5923792719841003 first col mean 0.628273606300354 all mean 0.5927327275276184
rl training, epoch2, iter0, batch1040/1133, batch loss:0.4014184772968292, Training time:65730.60181427002
batch reward last col mean 0.6076593399047852 first col mean 0.6019798517227173 all mean 0.6070475578308105
rl training, epoch2, iter0, batch1041/1133, batch loss:0.4309924840927124, Training time:65759.97683215141
batch reward last col mean 0.6050493717193604 first col mean 0.6194428205490112 all mean 0.6067109107971191
rl training, epoch2, iter0, batch1042/1133, batch loss:0.42617323994636536, Training time:65789.61109638214
batch reward last col mean 0.6192083358764648 first col mean 0.5972069501876831 all mean 0.6181433796882629
rl training, epoch2, iter0, batch1043/1133, batch loss:0.4332154393196106, Training time:65819.43973183632
batch reward last col mean 0.5896797776222229 first col mean 0.5791831016540527 all mean 0.5870910882949829
rl training, epoch2, iter0, batch1044/1133, batch loss:0.3687599301338196, Training time:65849.33207035065
batch reward last col mean 0.5616940259933472 first col mean 0.575716495513916 all mean 0.563298225402832
rl training, epoch2, iter0, batch1045/1133, batch loss:0.35722029209136963, Training time:65878.94666290283
batch reward last col mean 0.7083569765090942 first col mean 0.6608794927597046 all mean 0.7042796611785889
rl training, epoch2, iter0, batch1046/1133, batch loss:0.40600407123565674, Training time:65909.09923624992
batch reward last col mean 0.5972406268119812 first col mean 0.5768468976020813 all mean 0.5949946641921997
rl training, epoch2, iter0, batch1047/1133, batch loss:0.37262797355651855, Training time:65938.51158618927
batch reward last col mean 0.5684977769851685 first col mean 0.5459481477737427 all mean 0.5682581067085266
rl training, epoch2, iter0, batch1048/1133, batch loss:0.34790363907814026, Training time:65967.81852936745
batch reward last col mean 0.6091374754905701 first col mean 0.5992257595062256 all mean 0.6089932918548584
rl training, epoch2, iter0, batch1049/1133, batch loss:0.403400719165802, Training time:65997.37838816643
batch reward last col mean 0.6437565088272095 first col mean 0.5974844098091125 all mean 0.6424297094345093
rl training, epoch2, iter0, batch1050/1133, batch loss:0.38686129450798035, Training time:66026.44048428535
batch reward last col mean 0.5953667759895325 first col mean 0.5897561311721802 all mean 0.5949887633323669
rl training, epoch2, iter0, batch1051/1133, batch loss:0.3926358222961426, Training time:66055.11532449722
batch reward last col mean 0.6152610778808594 first col mean 0.6241716146469116 all mean 0.6151952147483826
rl training, epoch2, iter0, batch1052/1133, batch loss:0.39076510071754456, Training time:66083.99257516861
batch reward last col mean 0.6212067604064941 first col mean 0.616325318813324 all mean 0.6207256317138672
rl training, epoch2, iter0, batch1053/1133, batch loss:0.3838098347187042, Training time:66112.62819623947
batch reward last col mean 0.6526870727539062 first col mean 0.6303625702857971 all mean 0.6521418690681458
rl training, epoch2, iter0, batch1054/1133, batch loss:0.4634460210800171, Training time:66141.54837298393
batch reward last col mean 0.6122865676879883 first col mean 0.5966465473175049 all mean 0.6113036870956421
rl training, epoch2, iter0, batch1055/1133, batch loss:0.4262566864490509, Training time:66170.05955934525
batch reward last col mean 0.5703395009040833 first col mean 0.5520386695861816 all mean 0.5694724321365356
rl training, epoch2, iter0, batch1056/1133, batch loss:0.40668976306915283, Training time:66198.6858818531
batch reward last col mean 0.591945469379425 first col mean 0.6059349775314331 all mean 0.5920131802558899
rl training, epoch2, iter0, batch1057/1133, batch loss:0.40246349573135376, Training time:66227.15667295456
batch reward last col mean 0.5756787061691284 first col mean 0.5836892127990723 all mean 0.5758570432662964
rl training, epoch2, iter0, batch1058/1133, batch loss:0.4755847752094269, Training time:66255.96780896187
batch reward last col mean 0.6208899021148682 first col mean 0.6297296285629272 all mean 0.621519923210144
rl training, epoch2, iter0, batch1059/1133, batch loss:0.43875566124916077, Training time:66284.4262354374
batch reward last col mean 0.6244174838066101 first col mean 0.6319125890731812 all mean 0.6246638298034668
rl training, epoch2, iter0, batch1060/1133, batch loss:0.4428670108318329, Training time:66313.3567764759
batch reward last col mean 0.6361619234085083 first col mean 0.6262770891189575 all mean 0.6359569430351257
rl training, epoch2, iter0, batch1061/1133, batch loss:0.43437081575393677, Training time:66342.91308498383
batch reward last col mean 0.6376063823699951 first col mean 0.6318269968032837 all mean 0.6372477412223816
rl training, epoch2, iter0, batch1062/1133, batch loss:0.4876028001308441, Training time:66371.88003492355
batch reward last col mean 0.6582899689674377 first col mean 0.686110258102417 all mean 0.6592379212379456
rl training, epoch2, iter0, batch1063/1133, batch loss:0.5004213452339172, Training time:66400.70234680176
batch reward last col mean 0.6260919570922852 first col mean 0.6307041049003601 all mean 0.6260389089584351
rl training, epoch2, iter0, batch1064/1133, batch loss:0.4047035872936249, Training time:66429.57341980934
batch reward last col mean 0.6747543215751648 first col mean 0.6612259745597839 all mean 0.6739804148674011
rl training, epoch2, iter0, batch1065/1133, batch loss:0.47015732526779175, Training time:66458.9663863182
batch reward last col mean 0.6025328636169434 first col mean 0.6009557247161865 all mean 0.6030198335647583
rl training, epoch2, iter0, batch1066/1133, batch loss:0.45766961574554443, Training time:66487.08546614647
batch reward last col mean 0.6281000375747681 first col mean 0.616675078868866 all mean 0.6270865201950073
rl training, epoch2, iter0, batch1067/1133, batch loss:0.475446879863739, Training time:66515.92255854607
batch reward last col mean 0.6319971084594727 first col mean 0.6307704448699951 all mean 0.6323630809783936
rl training, epoch2, iter0, batch1068/1133, batch loss:0.48720782995224, Training time:66545.31766438484
batch reward last col mean 0.6126291751861572 first col mean 0.6479370594024658 all mean 0.6136718392372131
rl training, epoch2, iter0, batch1069/1133, batch loss:0.43943068385124207, Training time:66574.86374878883
batch reward last col mean 0.5524182319641113 first col mean 0.5948432087898254 all mean 0.5552691221237183
rl training, epoch2, iter0, batch1070/1133, batch loss:0.4316924810409546, Training time:66604.38803792
batch reward last col mean 0.5837796926498413 first col mean 0.5761905312538147 all mean 0.5843385457992554
rl training, epoch2, iter0, batch1071/1133, batch loss:0.4399678409099579, Training time:66634.41038823128
batch reward last col mean 0.5515207052230835 first col mean 0.5498508810997009 all mean 0.5515210628509521
rl training, epoch2, iter0, batch1072/1133, batch loss:0.39073172211647034, Training time:66664.22589993477
batch reward last col mean 0.5894950032234192 first col mean 0.5862882733345032 all mean 0.5906660556793213
rl training, epoch2, iter0, batch1073/1133, batch loss:0.396890252828598, Training time:66694.93532395363
batch reward last col mean 0.5359147787094116 first col mean 0.5721100568771362 all mean 0.5392244458198547
rl training, epoch2, iter0, batch1074/1133, batch loss:0.3849024474620819, Training time:66725.5341322422
batch reward last col mean 0.49375787377357483 first col mean 0.4934840798377991 all mean 0.4888664782047272
rl training, epoch2, iter0, batch1075/1133, batch loss:0.2988271117210388, Training time:66756.61790251732
batch reward last col mean 0.49870625138282776 first col mean 0.48704785108566284 all mean 0.492722749710083
rl training, epoch2, iter0, batch1076/1133, batch loss:0.31430405378341675, Training time:66786.82070851326
batch reward last col mean 0.4861166477203369 first col mean 0.47135844826698303 all mean 0.4743126630783081
rl training, epoch2, iter0, batch1077/1133, batch loss:0.29202699661254883, Training time:66817.3319234848
batch reward last col mean 0.5413995385169983 first col mean 0.49864447116851807 all mean 0.5408549308776855
rl training, epoch2, iter0, batch1078/1133, batch loss:0.3651358187198639, Training time:66848.00998950005
batch reward last col mean 0.5446919798851013 first col mean 0.5343272089958191 all mean 0.5405074954032898
rl training, epoch2, iter0, batch1079/1133, batch loss:0.39619994163513184, Training time:66878.62281489372
batch reward last col mean 0.5602375268936157 first col mean 0.5348531007766724 all mean 0.5534641146659851
rl training, epoch2, iter0, batch1080/1133, batch loss:0.41330182552337646, Training time:66909.09821653366
batch reward last col mean 0.4786878526210785 first col mean 0.4940544068813324 all mean 0.4812760651111603
rl training, epoch2, iter0, batch1081/1133, batch loss:0.3935198187828064, Training time:66940.17547011375
batch reward last col mean 0.5315492749214172 first col mean 0.5348421335220337 all mean 0.5325578451156616
rl training, epoch2, iter0, batch1082/1133, batch loss:0.42826133966445923, Training time:66969.75061178207
batch reward last col mean 0.5109864473342896 first col mean 0.5380859375 all mean 0.5120670795440674
rl training, epoch2, iter0, batch1083/1133, batch loss:0.4329903721809387, Training time:66999.72713589668
batch reward last col mean 0.5554702877998352 first col mean 0.5556288361549377 all mean 0.5544639825820923
rl training, epoch2, iter0, batch1084/1133, batch loss:0.4746352732181549, Training time:67029.75624346733
batch reward last col mean 0.5725763440132141 first col mean 0.5723823308944702 all mean 0.5700084567070007
rl training, epoch2, iter0, batch1085/1133, batch loss:0.47533532977104187, Training time:67060.0169095993
batch reward last col mean 0.5448839664459229 first col mean 0.5482330322265625 all mean 0.5464637279510498
rl training, epoch2, iter0, batch1086/1133, batch loss:0.44593387842178345, Training time:67090.07987976074
batch reward last col mean 0.5376056432723999 first col mean 0.5386652946472168 all mean 0.5410281419754028
rl training, epoch2, iter0, batch1087/1133, batch loss:0.45771899819374084, Training time:67120.05764579773
batch reward last col mean 0.4892931878566742 first col mean 0.5409462451934814 all mean 0.4928145110607147
rl training, epoch2, iter0, batch1088/1133, batch loss:0.46450352668762207, Training time:67150.54475307465
batch reward last col mean 0.5938767790794373 first col mean 0.5845884680747986 all mean 0.5897293090820312
rl training, epoch2, iter0, batch1089/1133, batch loss:0.5137837529182434, Training time:67181.15454697609
batch reward last col mean 0.5562915802001953 first col mean 0.5461421608924866 all mean 0.5549312829971313
rl training, epoch2, iter0, batch1090/1133, batch loss:0.48745250701904297, Training time:67211.21873164177
batch reward last col mean 0.5655059814453125 first col mean 0.5657264590263367 all mean 0.5627912282943726
rl training, epoch2, iter0, batch1091/1133, batch loss:0.5191378593444824, Training time:67241.18757891655
batch reward last col mean 0.5366018414497375 first col mean 0.5532597899436951 all mean 0.5375884175300598
rl training, epoch2, iter0, batch1092/1133, batch loss:0.4758932292461395, Training time:67271.06463980675
batch reward last col mean 0.5699938535690308 first col mean 0.5923335552215576 all mean 0.5690072774887085
rl training, epoch2, iter0, batch1093/1133, batch loss:0.5219875574111938, Training time:67301.01230955124
batch reward last col mean 0.5845533609390259 first col mean 0.5666412115097046 all mean 0.5820153951644897
rl training, epoch2, iter0, batch1094/1133, batch loss:0.5487356781959534, Training time:67331.26361227036
batch reward last col mean 0.6532221436500549 first col mean 0.6638175249099731 all mean 0.6524185538291931
rl training, epoch2, iter0, batch1095/1133, batch loss:0.6633797287940979, Training time:67361.30778121948
batch reward last col mean 0.6019095778465271 first col mean 0.5960080027580261 all mean 0.6021966934204102
rl training, epoch2, iter0, batch1096/1133, batch loss:0.5299182534217834, Training time:67390.67060279846
batch reward last col mean 0.6335210204124451 first col mean 0.6238221526145935 all mean 0.632609486579895
rl training, epoch2, iter0, batch1097/1133, batch loss:0.6137785911560059, Training time:67420.083558321
batch reward last col mean 0.574199914932251 first col mean 0.5817065238952637 all mean 0.575551450252533
rl training, epoch2, iter0, batch1098/1133, batch loss:0.5278604626655579, Training time:67449.68602752686
batch reward last col mean 0.5493977069854736 first col mean 0.6016806364059448 all mean 0.5525137186050415
rl training, epoch2, iter0, batch1099/1133, batch loss:0.5353353023529053, Training time:67479.03879642487
batch reward last col mean 0.6198888421058655 first col mean 0.6291916370391846 all mean 0.6197943091392517
rl training, epoch2, iter0, batch1100/1133, batch loss:0.5054721236228943, Training time:67508.72411227226
batch reward last col mean 0.596889853477478 first col mean 0.5982866287231445 all mean 0.5971419811248779
rl training, epoch2, iter0, batch1101/1133, batch loss:0.4824327826499939, Training time:67537.94801902771
batch reward last col mean 0.6265040636062622 first col mean 0.6468101143836975 all mean 0.6267831325531006
rl training, epoch2, iter0, batch1102/1133, batch loss:0.592975914478302, Training time:67567.410572052
batch reward last col mean 0.6434828639030457 first col mean 0.6500324010848999 all mean 0.6424136757850647
rl training, epoch2, iter0, batch1103/1133, batch loss:0.5767958760261536, Training time:67596.42704415321
batch reward last col mean 0.6218087673187256 first col mean 0.6201469898223877 all mean 0.6212923526763916
rl training, epoch2, iter0, batch1104/1133, batch loss:0.49944671988487244, Training time:67625.64427399635
batch reward last col mean 0.6022675037384033 first col mean 0.6045342087745667 all mean 0.6032285690307617
rl training, epoch2, iter0, batch1105/1133, batch loss:0.4962203800678253, Training time:67654.5315144062
batch reward last col mean 0.5797575116157532 first col mean 0.595812201499939 all mean 0.5795843005180359
rl training, epoch2, iter0, batch1106/1133, batch loss:0.5019535422325134, Training time:67683.22857403755
batch reward last col mean 0.6339111328125 first col mean 0.633571445941925 all mean 0.6343690156936646
rl training, epoch2, iter0, batch1107/1133, batch loss:0.4958680272102356, Training time:67712.52777600288
batch reward last col mean 0.6223896145820618 first col mean 0.6295384168624878 all mean 0.6221809983253479
rl training, epoch2, iter0, batch1108/1133, batch loss:0.5035423636436462, Training time:67741.34059429169
batch reward last col mean 0.6063528060913086 first col mean 0.5998990535736084 all mean 0.6058229207992554
rl training, epoch2, iter0, batch1109/1133, batch loss:0.39485833048820496, Training time:67771.26518154144
batch reward last col mean 0.6346082091331482 first col mean 0.6290422677993774 all mean 0.634900689125061
rl training, epoch2, iter0, batch1110/1133, batch loss:0.4646461009979248, Training time:67800.71617126465
batch reward last col mean 0.6202396750450134 first col mean 0.6322742700576782 all mean 0.6211226582527161
rl training, epoch2, iter0, batch1111/1133, batch loss:0.4221126139163971, Training time:67829.63804292679
batch reward last col mean 0.6319115161895752 first col mean 0.6268981099128723 all mean 0.6311256289482117
rl training, epoch2, iter0, batch1112/1133, batch loss:0.5120874047279358, Training time:67858.63011074066
batch reward last col mean 0.6233556270599365 first col mean 0.6401005983352661 all mean 0.6233795881271362
rl training, epoch2, iter0, batch1113/1133, batch loss:0.48210448026657104, Training time:67888.04622936249
batch reward last col mean 0.680227518081665 first col mean 0.6544042825698853 all mean 0.6798251271247864
rl training, epoch2, iter0, batch1114/1133, batch loss:0.5015417337417603, Training time:67917.14168381691
batch reward last col mean 0.7166855335235596 first col mean 0.704788088798523 all mean 0.7152509093284607
rl training, epoch2, iter0, batch1115/1133, batch loss:0.5029048919677734, Training time:67946.43889570236
batch reward last col mean 0.6417051553726196 first col mean 0.6261497735977173 all mean 0.6402327418327332
rl training, epoch2, iter0, batch1116/1133, batch loss:0.46883541345596313, Training time:67975.7064974308
batch reward last col mean 0.6971067190170288 first col mean 0.678643524646759 all mean 0.696862518787384
rl training, epoch2, iter0, batch1117/1133, batch loss:0.5122926235198975, Training time:68004.90412735939
batch reward last col mean 0.6186693906784058 first col mean 0.6393656134605408 all mean 0.6191496253013611
rl training, epoch2, iter0, batch1118/1133, batch loss:0.4128751754760742, Training time:68035.21495509148
batch reward last col mean 0.6215070486068726 first col mean 0.6092289090156555 all mean 0.6208401918411255
rl training, epoch2, iter0, batch1119/1133, batch loss:0.3656908869743347, Training time:68065.06820464134
batch reward last col mean 0.6409677267074585 first col mean 0.6113539934158325 all mean 0.6350484490394592
rl training, epoch2, iter0, batch1120/1133, batch loss:0.36644160747528076, Training time:68095.8044564724
batch reward last col mean 0.6230303049087524 first col mean 0.5729933977127075 all mean 0.620179295539856
rl training, epoch2, iter0, batch1121/1133, batch loss:0.38933369517326355, Training time:68126.16349315643
batch reward last col mean 0.5736437439918518 first col mean 0.527472972869873 all mean 0.5680667757987976
rl training, epoch2, iter0, batch1122/1133, batch loss:0.32233133912086487, Training time:68156.9618089199
batch reward last col mean 0.6114199161529541 first col mean 0.5993281006813049 all mean 0.6050683856010437
rl training, epoch2, iter0, batch1123/1133, batch loss:0.28333500027656555, Training time:68188.12528657913
batch reward last col mean 0.5944358706474304 first col mean 0.5419200658798218 all mean 0.5872888565063477
rl training, epoch2, iter0, batch1124/1133, batch loss:0.2885787785053253, Training time:68218.66619420052
batch reward last col mean 0.5580084323883057 first col mean 0.5749515295028687 all mean 0.552285373210907
rl training, epoch2, iter0, batch1125/1133, batch loss:0.2849019765853882, Training time:68248.29521632195
batch reward last col mean 0.5886218547821045 first col mean 0.5913734436035156 all mean 0.5929673910140991
rl training, epoch2, iter0, batch1126/1133, batch loss:0.2964044213294983, Training time:68279.22148394585
batch reward last col mean 0.603704571723938 first col mean 0.6010667085647583 all mean 0.6034422516822815
rl training, epoch2, iter0, batch1127/1133, batch loss:0.3413562476634979, Training time:68309.85177183151
batch reward last col mean 0.5917252898216248 first col mean 0.6040087938308716 all mean 0.5908413529396057
rl training, epoch2, iter0, batch1128/1133, batch loss:0.37784355878829956, Training time:68339.74835419655
batch reward last col mean 0.6062668561935425 first col mean 0.6015404462814331 all mean 0.6073048710823059
rl training, epoch2, iter0, batch1129/1133, batch loss:0.40079739689826965, Training time:68369.64847898483
batch reward last col mean 0.667025089263916 first col mean 0.65377277135849 all mean 0.6662719249725342
rl training, epoch2, iter0, batch1130/1133, batch loss:0.3915533423423767, Training time:68399.04034042358
batch reward last col mean 0.6272526383399963 first col mean 0.6354566812515259 all mean 0.627497673034668
rl training, epoch2, iter0, batch1131/1133, batch loss:0.42845794558525085, Training time:68428.39923524857
batch reward last col mean 0.6314276456832886 first col mean 0.6111611723899841 all mean 0.631189227104187
rl training, epoch2, iter0, batch1132/1133, batch loss:0.3774097263813019, Training time:68455.29998636246
rl training, epoch 2, iter 0, loss:0.1727250534554333, Training time:68455.30043411255 
rl epoch 2, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.3730246845800479 Time: 162.49627494812012 s
cur_epoch: 1
D Training Loss: 0.3448599198831464 Time: 161.6265070438385 s
cur_epoch: 2
D Training Loss: 0.33506874757221283 Time: 165.45838570594788 s
cur_epoch: 3
D Training Loss: 0.32706965221994655 Time: 161.3918433189392 s
cur_epoch: 4
D Training Loss: 0.3156544651247607 Time: 164.62540364265442 s
rl epoch 3, begin RL for generator...
batch reward last col mean 7.808083637428354e-07 first col mean 1.1552908745215973e-06 all mean 1.4826714505034033e-06
rl training, epoch3, iter0, batch0/1133, batch loss:3.3710368825268233e-06, Training time:69299.93702745438
batch reward last col mean 1.9890328530891566e-06 first col mean 7.16501517672441e-06 all mean 2.0108257103856886e-06
rl training, epoch3, iter0, batch1/1133, batch loss:1.1533184078871273e-06, Training time:69329.63400292397
batch reward last col mean 1.472515123168705e-06 first col mean 2.5271169761253987e-06 all mean 1.5902659242783557e-06
rl training, epoch3, iter0, batch2/1133, batch loss:3.88482794733136e-06, Training time:69358.84714150429
batch reward last col mean 1.2763380254909862e-06 first col mean 7.310396767934435e-07 all mean 1.9261146007920615e-05
rl training, epoch3, iter0, batch3/1133, batch loss:0.00019462470663711429, Training time:69386.22053337097
batch reward last col mean 5.59400461952464e-07 first col mean 8.328592002726509e-07 all mean 7.260160828082007e-07
rl training, epoch3, iter0, batch4/1133, batch loss:1.1088965948147234e-05, Training time:69414.3107202053
batch reward last col mean 1.0873814062506426e-06 first col mean 2.3821910417609615e-06 all mean 1.169042434412404e-06
rl training, epoch3, iter0, batch5/1133, batch loss:2.3882257664809003e-06, Training time:69443.42432928085
batch reward last col mean 3.4195325042674085e-06 first col mean 2.556865001679398e-05 all mean 4.0163067751564085e-06
rl training, epoch3, iter0, batch6/1133, batch loss:5.107061497255927e-06, Training time:69470.31678915024
batch reward last col mean 1.400037064058779e-07 first col mean 1.159135535999667e-06 all mean 7.023659236438107e-07
rl training, epoch3, iter0, batch7/1133, batch loss:1.5117532711883541e-05, Training time:69498.74286341667
batch reward last col mean 2.274906591992476e-06 first col mean 3.078536337852711e-06 all mean 1.1050311513827182e-05
rl training, epoch3, iter0, batch8/1133, batch loss:7.426169031532481e-05, Training time:69528.61431336403
batch reward last col mean 6.299241590568272e-07 first col mean 5.857394626218593e-06 all mean 7.758582682981796e-07
rl training, epoch3, iter0, batch9/1133, batch loss:1.5333487226598663e-06, Training time:69557.73997688293
batch reward last col mean 1.0742245422079577e-06 first col mean 2.807275052418845e-07 all mean 1.0380113053543027e-06
rl training, epoch3, iter0, batch10/1133, batch loss:6.384925654856488e-07, Training time:69585.55273222923
batch reward last col mean 2.464741442054219e-07 first col mean 2.536525425966829e-05 all mean 6.596926027668815e-07
rl training, epoch3, iter0, batch11/1133, batch loss:4.760472165799001e-06, Training time:69614.0337331295
batch reward last col mean 0.00582512654364109 first col mean 7.93527033238206e-06 all mean 0.005672134459018707
rl training, epoch3, iter0, batch12/1133, batch loss:0.00459508690983057, Training time:69643.66174674034
batch reward last col mean 8.051803774833388e-07 first col mean 9.295827112509869e-07 all mean 8.11926781807415e-07
rl training, epoch3, iter0, batch13/1133, batch loss:1.0538218475630856e-06, Training time:69673.00943565369
batch reward last col mean 2.8624043579839054e-07 first col mean 3.846748222713359e-05 all mean 7.790131348883733e-07
rl training, epoch3, iter0, batch14/1133, batch loss:2.8053534606442554e-06, Training time:69702.6070535183
batch reward last col mean 5.253800168247835e-07 first col mean 4.761501770644827e-07 all mean 4.945064802086563e-07
rl training, epoch3, iter0, batch15/1133, batch loss:5.621892000817752e-07, Training time:69731.68385100365
batch reward last col mean 1.1205765986233018e-06 first col mean 1.305048954236554e-06 all mean 2.136707962563378e-06
rl training, epoch3, iter0, batch16/1133, batch loss:2.2080566850490868e-05, Training time:69761.0842769146
batch reward last col mean 1.0746288353402633e-05 first col mean 8.931638717513124e-07 all mean 9.98474297375651e-06
rl training, epoch3, iter0, batch17/1133, batch loss:5.2182895160513e-06, Training time:69790.17694592476
batch reward last col mean 0.0008686029468663037 first col mean 7.391060421468865e-07 all mean 0.0008544811862520874
rl training, epoch3, iter0, batch18/1133, batch loss:0.00030254657031036913, Training time:69819.24411082268
batch reward last col mean 2.3290431272471324e-06 first col mean 1.0535436558711808e-06 all mean 3.6131550587015226e-06
rl training, epoch3, iter0, batch19/1133, batch loss:1.0408332400402287e-06, Training time:69848.27883768082
batch reward last col mean 3.613788749134983e-06 first col mean 1.620593820916838e-06 all mean 3.832916718238266e-06
rl training, epoch3, iter0, batch20/1133, batch loss:6.544874395331135e-06, Training time:69877.47386574745
batch reward last col mean 4.5095097789271676e-07 first col mean 3.1477775337407365e-06 all mean 5.388243948800664e-07
rl training, epoch3, iter0, batch21/1133, batch loss:1.8997870938619599e-06, Training time:69906.96335148811
batch reward last col mean 3.177584346758522e-07 first col mean 2.2589313175558345e-07 all mean 1.3584347016148968e-06
rl training, epoch3, iter0, batch22/1133, batch loss:3.5759626371145714e-06, Training time:69936.7197356224
batch reward last col mean 1.1753978697015555e-06 first col mean 7.30378951629973e-06 all mean 2.870636990337516e-06
rl training, epoch3, iter0, batch23/1133, batch loss:6.700945050397422e-06, Training time:69965.87407016754
batch reward last col mean 2.9689959774259478e-05 first col mean 1.772351197359967e-06 all mean 2.973339542222675e-05
rl training, epoch3, iter0, batch24/1133, batch loss:1.378918477712432e-05, Training time:69994.90304160118
batch reward last col mean 2.026552294864814e-07 first col mean 1.154623305410496e-06 all mean 6.573803261744615e-07
rl training, epoch3, iter0, batch25/1133, batch loss:6.804932581871981e-06, Training time:70023.90453147888
batch reward last col mean 1.4839159803159419e-06 first col mean 5.610952030110639e-06 all mean 1.964182274605264e-06
rl training, epoch3, iter0, batch26/1133, batch loss:8.977499419415835e-06, Training time:70053.65087103844
batch reward last col mean 5.975342901365366e-06 first col mean 3.1791323635843582e-06 all mean 5.927541678829584e-06
rl training, epoch3, iter0, batch27/1133, batch loss:2.4186554128391435e-06, Training time:70083.27534341812
batch reward last col mean 1.4044454701434006e-06 first col mean 7.364628800132778e-07 all mean 1.4733367379449192e-06
rl training, epoch3, iter0, batch28/1133, batch loss:1.1274735243205214e-06, Training time:70112.95383405685
batch reward last col mean 2.6375812467449578e-06 first col mean 1.5334173895098502e-06 all mean 3.681252565002069e-06
rl training, epoch3, iter0, batch29/1133, batch loss:1.3796822713629808e-05, Training time:70142.65821027756
batch reward last col mean 1.995637830987107e-06 first col mean 9.751820471137762e-07 all mean 2.206213594035944e-06
rl training, epoch3, iter0, batch30/1133, batch loss:1.4694375067847432e-06, Training time:70172.36985445023
batch reward last col mean 1.9714508425749955e-07 first col mean 1.0911057302109839e-07 all mean 2.2580049119369505e-07
rl training, epoch3, iter0, batch31/1133, batch loss:1.6849190842549433e-07, Training time:70201.78972196579
batch reward last col mean 7.587999562019832e-07 first col mean 2.7210903681407217e-06 all mean 1.0630599263095064e-06
rl training, epoch3, iter0, batch32/1133, batch loss:2.6049965526908636e-06, Training time:70231.26035547256
batch reward last col mean 6.618338375119492e-07 first col mean 9.194342851515103e-07 all mean 7.185941512943828e-07
rl training, epoch3, iter0, batch33/1133, batch loss:5.682970822817879e-07, Training time:70260.95035886765
batch reward last col mean 3.0742810395167908e-06 first col mean 1.0055594430014025e-05 all mean 6.4263913372997195e-06
rl training, epoch3, iter0, batch34/1133, batch loss:3.361266135470942e-05, Training time:70290.73388838768
batch reward last col mean 3.300782736914698e-06 first col mean 4.7544672270305455e-06 all mean 3.367602175785578e-06
rl training, epoch3, iter0, batch35/1133, batch loss:1.6116799770315993e-06, Training time:70320.85246038437
batch reward last col mean 1.3798194231640082e-06 first col mean 1.8177516949435812e-06 all mean 8.018258995434735e-06
rl training, epoch3, iter0, batch36/1133, batch loss:1.2655577847908717e-05, Training time:70350.15051555634
batch reward last col mean 6.606863394154061e-07 first col mean 3.6392347624314425e-07 all mean 6.573268933607324e-07
rl training, epoch3, iter0, batch37/1133, batch loss:3.990583365975908e-07, Training time:70380.1995921135
batch reward last col mean 7.118385383364512e-07 first col mean 1.4645072496932698e-06 all mean 7.046938890198362e-07
rl training, epoch3, iter0, batch38/1133, batch loss:4.128055195451452e-07, Training time:70409.87067437172
batch reward last col mean 1.3825929272570647e-05 first col mean 6.083225889597088e-05 all mean 1.371693542751018e-05
rl training, epoch3, iter0, batch39/1133, batch loss:1.1537993486854248e-05, Training time:70439.27992081642
batch reward last col mean 1.1681138857966289e-05 first col mean 1.8226039628643775e-06 all mean 1.1534076293173712e-05
rl training, epoch3, iter0, batch40/1133, batch loss:3.2840400763234356e-06, Training time:70469.52146458626
batch reward last col mean 1.5010165554940613e-07 first col mean 5.65132893370901e-07 all mean 2.0855735272107268e-07
rl training, epoch3, iter0, batch41/1133, batch loss:3.6374942169459246e-07, Training time:70498.67505669594
batch reward last col mean 1.0100884395569665e-07 first col mean 2.5839457862275594e-07 all mean 2.0735396901727654e-06
rl training, epoch3, iter0, batch42/1133, batch loss:1.0961056432279292e-05, Training time:70528.44443011284
batch reward last col mean 1.2572559171530884e-06 first col mean 3.514094260026468e-06 all mean 8.133672054100316e-06
rl training, epoch3, iter0, batch43/1133, batch loss:2.8116817247791914e-06, Training time:70558.48289990425
batch reward last col mean 1.8807705259860086e-07 first col mean 6.040787638994516e-07 all mean 7.25657002931257e-07
rl training, epoch3, iter0, batch44/1133, batch loss:1.685102574811026e-06, Training time:70588.06776428223
batch reward last col mean 1.043540942191612e-05 first col mean 2.4224864318966866e-06 all mean 1.1095344234490767e-05
rl training, epoch3, iter0, batch45/1133, batch loss:6.952943749638507e-06, Training time:70617.40328454971
batch reward last col mean 0.00013079404016025364 first col mean 0.00014616365660913289 all mean 0.0001271996443392709
rl training, epoch3, iter0, batch46/1133, batch loss:0.00013026582018937916, Training time:70646.5479528904
batch reward last col mean 0.0014412616146728396 first col mean 4.1568765141164477e-07 all mean 0.0013554857578128576
rl training, epoch3, iter0, batch47/1133, batch loss:0.00047635805094614625, Training time:70675.76659703255
batch reward last col mean 9.748838056111708e-05 first col mean 4.2168204572590184e-07 all mean 9.669311839388683e-05
rl training, epoch3, iter0, batch48/1133, batch loss:4.089761205250397e-05, Training time:70704.98540711403
batch reward last col mean 2.742855258475174e-07 first col mean 3.1621914331481094e-06 all mean 3.9165976772892463e-07
rl training, epoch3, iter0, batch49/1133, batch loss:2.816415474171663e-07, Training time:70734.27595758438
batch reward last col mean 2.043160947096112e-07 first col mean 3.0868418434693012e-06 all mean 4.176674224254384e-07
rl training, epoch3, iter0, batch50/1133, batch loss:8.309791610372486e-07, Training time:70763.09023499489
batch reward last col mean 2.9788864708280016e-07 first col mean 0.00010934208694379777 all mean 1.4377502566276235e-06
rl training, epoch3, iter0, batch51/1133, batch loss:4.189035280433018e-06, Training time:70790.08584022522
batch reward last col mean 1.9685948871028813e-07 first col mean 3.6553450399878784e-07 all mean 3.699704507198476e-07
rl training, epoch3, iter0, batch52/1133, batch loss:4.2994870455004275e-06, Training time:70817.25126123428
batch reward last col mean 1.2469148487070925e-06 first col mean 7.964597170939669e-05 all mean 2.48102810473938e-06
rl training, epoch3, iter0, batch53/1133, batch loss:8.693668860360049e-06, Training time:70844.43958687782
batch reward last col mean 1.5748491932754405e-06 first col mean 3.548128404418094e-07 all mean 6.294821105257142e-06
rl training, epoch3, iter0, batch54/1133, batch loss:6.66056121190195e-06, Training time:70871.66049051285
batch reward last col mean 4.261667072569253e-06 first col mean 1.5916058373477426e-06 all mean 4.220177288516425e-06
rl training, epoch3, iter0, batch55/1133, batch loss:3.103213884969591e-06, Training time:70898.69613695145
batch reward last col mean 5.999167115078308e-05 first col mean 1.5606688066327479e-06 all mean 5.9053971199318767e-05
rl training, epoch3, iter0, batch56/1133, batch loss:0.00010819138697115704, Training time:70925.61795520782
batch reward last col mean 1.1793259773185127e-06 first col mean 3.1684244277130347e-06 all mean 1.269934273295803e-06
rl training, epoch3, iter0, batch57/1133, batch loss:2.551828856667271e-06, Training time:70953.11959028244
batch reward last col mean 1.3826668521232932e-07 first col mean 1.3583645568360225e-06 all mean 2.054431718079286e-07
rl training, epoch3, iter0, batch58/1133, batch loss:2.4628084815958573e-07, Training time:70980.22472548485
batch reward last col mean 0.00040669209556654096 first col mean 9.572922863299027e-07 all mean 0.00040261034155264497
rl training, epoch3, iter0, batch59/1133, batch loss:0.00010995939373970032, Training time:71007.14562535286
batch reward last col mean 3.489038817861001e-06 first col mean 4.712876943813171e-06 all mean 3.5227569696871797e-06
rl training, epoch3, iter0, batch60/1133, batch loss:2.438416004224564e-06, Training time:71034.25702381134
batch reward last col mean 2.949444478872465e-06 first col mean 8.518556569470093e-06 all mean 2.1250203644740395e-05
rl training, epoch3, iter0, batch61/1133, batch loss:0.0003329836472403258, Training time:71061.56323361397
batch reward last col mean 4.820320214093954e-07 first col mean 1.6762192899477668e-05 all mean 6.984583365010621e-07
rl training, epoch3, iter0, batch62/1133, batch loss:2.802212748065358e-06, Training time:71088.79404067993
batch reward last col mean 1.3503354239219334e-06 first col mean 5.233075057731185e-07 all mean 1.5715311292296974e-06
rl training, epoch3, iter0, batch63/1133, batch loss:9.01295425137505e-06, Training time:71116.30656051636
batch reward last col mean 1.1587052313188906e-06 first col mean 1.7623281109990785e-06 all mean 1.3646018715007813e-06
rl training, epoch3, iter0, batch64/1133, batch loss:1.3827744851369062e-06, Training time:71143.09016036987
batch reward last col mean 5.145606110090739e-07 first col mean 1.4001012687003822e-06 all mean 5.660440933752398e-07
rl training, epoch3, iter0, batch65/1133, batch loss:5.662601552103297e-07, Training time:71170.14629507065
batch reward last col mean 1.0671472239209834e-07 first col mean 5.479803348862333e-06 all mean 1.0510010497455369e-06
rl training, epoch3, iter0, batch66/1133, batch loss:6.893385943840258e-06, Training time:71197.35200762749
batch reward last col mean 3.1853542736826057e-07 first col mean 1.146295471698977e-05 all mean 6.977846283007239e-07
rl training, epoch3, iter0, batch67/1133, batch loss:2.762319127214141e-06, Training time:71224.39182043076
batch reward last col mean 2.112815082000452e-06 first col mean 0.00022768392227590084 all mean 6.032677902112482e-06
rl training, epoch3, iter0, batch68/1133, batch loss:4.803322553925682e-06, Training time:71252.05927324295
batch reward last col mean 2.982061459988472e-07 first col mean 2.3588238036609255e-05 all mean 6.505342753371224e-07
rl training, epoch3, iter0, batch69/1133, batch loss:1.8133395087716053e-06, Training time:71279.07010316849
batch reward last col mean 7.998395972208527e-07 first col mean 3.0516375773004256e-06 all mean 1.0251408184558386e-06
rl training, epoch3, iter0, batch70/1133, batch loss:1.150260118265578e-06, Training time:71306.82734251022
batch reward last col mean 7.458502864210459e-07 first col mean 1.3766605206910754e-06 all mean 1.062542651197873e-06
rl training, epoch3, iter0, batch71/1133, batch loss:3.132485062451451e-06, Training time:71334.47698187828
batch reward last col mean 1.5267839899024693e-06 first col mean 1.0529803148529027e-05 all mean 1.985894641620689e-06
rl training, epoch3, iter0, batch72/1133, batch loss:3.603246341299382e-06, Training time:71361.95316648483
batch reward last col mean 7.121057592485158e-07 first col mean 4.051676114613656e-06 all mean 2.566204966569785e-05
rl training, epoch3, iter0, batch73/1133, batch loss:5.321858679963043e-06, Training time:71389.02143907547
batch reward last col mean 4.1839874143079214e-07 first col mean 2.505363909222069e-06 all mean 2.086210315610515e-06
rl training, epoch3, iter0, batch74/1133, batch loss:7.001334552114713e-07, Training time:71415.93106007576
batch reward last col mean 7.862383426981978e-06 first col mean 1.4525453480018768e-06 all mean 7.638474016857799e-06
rl training, epoch3, iter0, batch75/1133, batch loss:9.853426490735728e-06, Training time:71443.06419920921
batch reward last col mean 1.2469541843529441e-06 first col mean 7.595708211738383e-06 all mean 1.6360315839847317e-06
rl training, epoch3, iter0, batch76/1133, batch loss:1.0523371201998089e-05, Training time:71469.97366333008
batch reward last col mean 1.4094979405854247e-07 first col mean 5.569448603637284e-06 all mean 4.946239755554416e-07
rl training, epoch3, iter0, batch77/1133, batch loss:3.1298038720706245e-06, Training time:71497.0936563015
batch reward last col mean 1.543432830430902e-07 first col mean 2.136372643235518e-07 all mean 5.071930218036869e-07
rl training, epoch3, iter0, batch78/1133, batch loss:1.6720819985494018e-05, Training time:71523.89719629288
batch reward last col mean 4.7961384552763775e-06 first col mean 1.2492348105297424e-05 all mean 5.265994786896044e-06
rl training, epoch3, iter0, batch79/1133, batch loss:9.487668648944236e-06, Training time:71550.81522011757
batch reward last col mean 7.010358444858866e-07 first col mean 4.485345357352344e-07 all mean 7.100098287082801e-07
rl training, epoch3, iter0, batch80/1133, batch loss:7.776254165037244e-07, Training time:71578.01701188087
batch reward last col mean 9.807788501348114e-07 first col mean 8.076299309323076e-07 all mean 1.0327747759220074e-06
rl training, epoch3, iter0, batch81/1133, batch loss:1.105990804717294e-06, Training time:71605.15971136093
batch reward last col mean 7.8175270346037e-07 first col mean 6.074155862734187e-06 all mean 1.709031266727834e-06
rl training, epoch3, iter0, batch82/1133, batch loss:3.128227035631426e-05, Training time:71632.30681228638
batch reward last col mean 3.902213450146519e-07 first col mean 1.2629952834686264e-06 all mean 5.897900337004103e-07
rl training, epoch3, iter0, batch83/1133, batch loss:5.2035916269232985e-06, Training time:71659.47254633904
batch reward last col mean 1.0796082960951026e-06 first col mean 1.8903344312093395e-07 all mean 1.019478622765746e-05
rl training, epoch3, iter0, batch84/1133, batch loss:0.00011775383609347045, Training time:71686.38696980476
batch reward last col mean 8.385823093703948e-07 first col mean 1.3864008906239178e-05 all mean 1.2703427501037368e-06
rl training, epoch3, iter0, batch85/1133, batch loss:8.531406479050929e-07, Training time:71713.36664175987
batch reward last col mean 8.827634883346036e-05 first col mean 1.6707651866454398e-06 all mean 8.311356214107946e-05
rl training, epoch3, iter0, batch86/1133, batch loss:2.3294196580536664e-05, Training time:71740.36961579323
batch reward last col mean 6.487497103080386e-06 first col mean 3.1238710107572842e-06 all mean 6.508770184154855e-06
rl training, epoch3, iter0, batch87/1133, batch loss:3.455744717939524e-06, Training time:71767.51337361336
batch reward last col mean 1.1185284165549092e-06 first col mean 9.901863086270168e-05 all mean 8.0555355452816e-06
rl training, epoch3, iter0, batch88/1133, batch loss:0.00017999783449340612, Training time:71794.59783506393
batch reward last col mean 2.1123770466147107e-07 first col mean 3.361123219747242e-07 all mean 8.076619906205451e-07
rl training, epoch3, iter0, batch89/1133, batch loss:1.335979231953388e-05, Training time:71821.59640026093
batch reward last col mean 4.4216804440111446e-07 first col mean 1.5714432493041386e-06 all mean 1.3204250990384025e-06
rl training, epoch3, iter0, batch90/1133, batch loss:2.097031392622739e-05, Training time:71848.8891339302
batch reward last col mean 2.1112368813192006e-06 first col mean 5.312926532496931e-06 all mean 3.8129498989292188e-06
rl training, epoch3, iter0, batch91/1133, batch loss:6.199190465849824e-06, Training time:71875.87531399727
batch reward last col mean 4.5559767158920295e-07 first col mean 1.381152560497867e-05 all mean 1.97981103156053e-06
rl training, epoch3, iter0, batch92/1133, batch loss:2.866893555619754e-05, Training time:71902.9559943676
batch reward last col mean 6.693263685519923e-07 first col mean 3.5040759485127637e-06 all mean 8.551128871658875e-07
rl training, epoch3, iter0, batch93/1133, batch loss:8.584816555412544e-07, Training time:71930.19632554054
batch reward last col mean 7.907925692052231e-07 first col mean 4.440053658072429e-07 all mean 9.007438279695634e-07
rl training, epoch3, iter0, batch94/1133, batch loss:1.0380067578807939e-06, Training time:71957.00643253326
batch reward last col mean 1.448606894882687e-06 first col mean 1.192373247249634e-06 all mean 1.4518903981297626e-06
rl training, epoch3, iter0, batch95/1133, batch loss:2.397684056631988e-06, Training time:71984.2050087452
batch reward last col mean 6.10265999512194e-07 first col mean 0.0010374358389526606 all mean 1.1257709957135376e-05
rl training, epoch3, iter0, batch96/1133, batch loss:0.00010061755165224895, Training time:72011.35107803345
batch reward last col mean 3.256174068155815e-07 first col mean 1.3634357856062707e-06 all mean 5.459069143398665e-07
rl training, epoch3, iter0, batch97/1133, batch loss:1.2889009894934134e-06, Training time:72038.57033348083
batch reward last col mean 0.006160230841487646 first col mean 0.006160279735922813 all mean 0.006160176824778318
rl training, epoch3, iter0, batch98/1133, batch loss:0.0035095319617539644, Training time:72065.69443368912
batch reward last col mean 9.226173460774589e-07 first col mean 2.5162167730741203e-05 all mean 1.2967226439286605e-06
rl training, epoch3, iter0, batch99/1133, batch loss:2.289655640197452e-06, Training time:72092.82805538177
batch reward last col mean 1.1878576060553314e-06 first col mean 3.0930881621316075e-05 all mean 4.607274149748264e-06
rl training, epoch3, iter0, batch100/1133, batch loss:0.00011095740046584979, Training time:72120.08111286163
batch reward last col mean 4.393805738800438e-06 first col mean 1.7802731235860847e-06 all mean 4.674634510593023e-06
rl training, epoch3, iter0, batch101/1133, batch loss:1.2643472473428119e-05, Training time:72147.1251642704
batch reward last col mean 4.143171850046201e-07 first col mean 9.826785571931396e-07 all mean 1.7872058606371866e-06
rl training, epoch3, iter0, batch102/1133, batch loss:8.799378292678739e-07, Training time:72174.14548397064
batch reward last col mean 4.685101885115728e-06 first col mean 2.1547696178458864e-06 all mean 1.192664149129996e-05
rl training, epoch3, iter0, batch103/1133, batch loss:6.449623015214456e-06, Training time:72201.46409249306
batch reward last col mean 4.6645089923913474e-07 first col mean 4.360156822258432e-07 all mean 4.250487961598992e-07
rl training, epoch3, iter0, batch104/1133, batch loss:3.70455637721534e-07, Training time:72228.44142746925
batch reward last col mean 0.0005971790524199605 first col mean 0.0006312521873041987 all mean 0.000597463920712471
rl training, epoch3, iter0, batch105/1133, batch loss:0.00037597338086925447, Training time:72255.38875985146
batch reward last col mean 9.659740953793516e-07 first col mean 3.591480890463572e-06 all mean 6.074512839404633e-06
rl training, epoch3, iter0, batch106/1133, batch loss:0.00016460497863590717, Training time:72282.36786103249
batch reward last col mean 1.3335037692741025e-05 first col mean 1.19030767109507e-06 all mean 1.2616847925528418e-05
rl training, epoch3, iter0, batch107/1133, batch loss:9.953571861842647e-06, Training time:72309.50848555565
batch reward last col mean 3.326561852645682e-07 first col mean 7.280627301042841e-07 all mean 1.5256844108080259e-06
rl training, epoch3, iter0, batch108/1133, batch loss:5.2459450671449304e-05, Training time:72336.64092350006
batch reward last col mean 3.0432238418143243e-06 first col mean 1.3883328620067914e-06 all mean 3.142496098007541e-06
rl training, epoch3, iter0, batch109/1133, batch loss:5.8886612350761425e-06, Training time:72363.55772256851
batch reward last col mean 4.295590315450681e-06 first col mean 7.301850928342901e-07 all mean 4.412851922097616e-06
rl training, epoch3, iter0, batch110/1133, batch loss:1.4640039808000438e-05, Training time:72390.4465098381
batch reward last col mean 1.1078320767410332e-06 first col mean 4.7604765995856724e-07 all mean 1.0905038152486668e-06
rl training, epoch3, iter0, batch111/1133, batch loss:1.2048398048136733e-06, Training time:72417.54446148872
batch reward last col mean 3.447009362389508e-07 first col mean 6.174579084472498e-06 all mean 6.802727966714883e-06
rl training, epoch3, iter0, batch112/1133, batch loss:0.00044771283864974976, Training time:72444.92770457268
batch reward last col mean 4.720776018984907e-07 first col mean 7.523726708313916e-07 all mean 5.474052500176185e-07
rl training, epoch3, iter0, batch113/1133, batch loss:1.3667249731952325e-06, Training time:72471.89959979057
batch reward last col mean 5.99249062815943e-07 first col mean 0.0016403751214966178 all mean 1.9203374904464e-05
rl training, epoch3, iter0, batch114/1133, batch loss:0.00013138291251379997, Training time:72499.13135266304
batch reward last col mean 1.1122842806798872e-05 first col mean 4.568414624372963e-06 all mean 3.8734757254133e-05
rl training, epoch3, iter0, batch115/1133, batch loss:0.0007587593281641603, Training time:72526.82664728165
batch reward last col mean 3.1493389087700052e-06 first col mean 1.2589089237735607e-06 all mean 3.5945120089309057e-06
rl training, epoch3, iter0, batch116/1133, batch loss:1.2699032595264725e-05, Training time:72554.00225520134
batch reward last col mean 3.6466204278440273e-07 first col mean 4.370330088931951e-07 all mean 1.1605743566178717e-05
rl training, epoch3, iter0, batch117/1133, batch loss:0.0002959207631647587, Training time:72581.05133676529
batch reward last col mean 1.951298600033624e-06 first col mean 8.232062100432813e-05 all mean 1.747260830597952e-05
rl training, epoch3, iter0, batch118/1133, batch loss:7.325563728954876e-06, Training time:72608.15554332733
batch reward last col mean 5.85405359743163e-06 first col mean 1.5820493217688636e-06 all mean 7.266361080837669e-06
rl training, epoch3, iter0, batch119/1133, batch loss:4.0661489038029686e-05, Training time:72635.17831730843
batch reward last col mean 1.495853325650387e-06 first col mean 1.5206487660179846e-06 all mean 1.5286502730305074e-06
rl training, epoch3, iter0, batch120/1133, batch loss:6.994585532993369e-07, Training time:72662.24602746964
batch reward last col mean 8.592735980528232e-07 first col mean 2.882103160573024e-07 all mean 1.3341466456040507e-06
rl training, epoch3, iter0, batch121/1133, batch loss:2.78191214420076e-06, Training time:72689.2869811058
batch reward last col mean 5.383627126320789e-07 first col mean 3.651547331173788e-07 all mean 5.654012511513429e-07
rl training, epoch3, iter0, batch122/1133, batch loss:6.765795887986314e-07, Training time:72717.23263692856
batch reward last col mean 4.641571536012634e-07 first col mean 4.123408143641427e-05 all mean 1.403143755851488e-06
rl training, epoch3, iter0, batch123/1133, batch loss:1.0778289833979215e-05, Training time:72744.6073255539
batch reward last col mean 4.7181666218421014e-07 first col mean 5.511863037099829e-07 all mean 5.701285203940643e-07
rl training, epoch3, iter0, batch124/1133, batch loss:2.0439990748855053e-06, Training time:72771.44179797173
batch reward last col mean 3.029609842997161e-07 first col mean 2.6448921630617406e-07 all mean 3.3965685020120873e-07
rl training, epoch3, iter0, batch125/1133, batch loss:3.213876027530205e-07, Training time:72798.6247639656
batch reward last col mean 2.7674641955854895e-07 first col mean 0.00037919124588370323 all mean 1.8309627193957567e-05
rl training, epoch3, iter0, batch126/1133, batch loss:0.0002272892597829923, Training time:72825.67734718323
batch reward last col mean 4.828640953746799e-07 first col mean 1.418548777110118e-06 all mean 5.001934937354235e-07
rl training, epoch3, iter0, batch127/1133, batch loss:6.517027486552252e-07, Training time:72852.55564761162
batch reward last col mean 6.961811322980793e-06 first col mean 2.908078613472753e-06 all mean 8.479576536046807e-06
rl training, epoch3, iter0, batch128/1133, batch loss:1.683877235336695e-05, Training time:72879.50977420807
batch reward last col mean 6.233301519387169e-07 first col mean 0.00020704802591353655 all mean 3.565707856978406e-06
rl training, epoch3, iter0, batch129/1133, batch loss:8.578100278100464e-06, Training time:72906.66347980499
batch reward last col mean 1.106849595089443e-05 first col mean 1.8072372768074274e-05 all mean 1.152855020336574e-05
rl training, epoch3, iter0, batch130/1133, batch loss:8.03079365141457e-06, Training time:72933.66452980042
batch reward last col mean 6.927907179488102e-06 first col mean 3.0627720661868807e-06 all mean 7.478742645616876e-06
rl training, epoch3, iter0, batch131/1133, batch loss:9.259288162866142e-06, Training time:72960.66337394714
batch reward last col mean 8.002857612154912e-07 first col mean 1.3103639275868773e-06 all mean 1.022415972329327e-06
rl training, epoch3, iter0, batch132/1133, batch loss:1.336542936769547e-06, Training time:72987.8305220604
batch reward last col mean 2.18257710571379e-07 first col mean 0.00019939878256991506 all mean 3.8786120057920925e-06
rl training, epoch3, iter0, batch133/1133, batch loss:7.360335985140409e-06, Training time:73014.97384524345
batch reward last col mean 3.0558240382561053e-07 first col mean 2.6808924303622916e-05 all mean 1.0487939334780094e-06
rl training, epoch3, iter0, batch134/1133, batch loss:1.7250375776711735e-06, Training time:73042.04513430595
batch reward last col mean 1.3181819440433173e-06 first col mean 1.2110058378311805e-06 all mean 1.4274675095293787e-06
rl training, epoch3, iter0, batch135/1133, batch loss:3.03887145491899e-06, Training time:73069.26644206047
batch reward last col mean 4.1040751966647804e-05 first col mean 6.98393478160142e-06 all mean 4.072320007253438e-05
rl training, epoch3, iter0, batch136/1133, batch loss:9.845163731370121e-06, Training time:73096.30810070038
batch reward last col mean 8.333555712169982e-08 first col mean 3.019530083747668e-07 all mean 1.7399658247541083e-07
rl training, epoch3, iter0, batch137/1133, batch loss:1.6245454617092037e-06, Training time:73123.39191436768
batch reward last col mean 1.115544023377879e-06 first col mean 1.1686975994962268e-05 all mean 2.3318323201237945e-06
rl training, epoch3, iter0, batch138/1133, batch loss:2.2249319044931326e-06, Training time:73150.82046175003
batch reward last col mean 9.944630363634133e-08 first col mean 1.2283119303901913e-06 all mean 2.7423376991464465e-07
rl training, epoch3, iter0, batch139/1133, batch loss:5.425689778348897e-06, Training time:73177.64630675316
batch reward last col mean 5.050791151006706e-05 first col mean 2.8736398235196248e-05 all mean 4.8493817303096876e-05
rl training, epoch3, iter0, batch140/1133, batch loss:7.430685218423605e-05, Training time:73204.70976305008
batch reward last col mean 6.822895670666185e-07 first col mean 4.9844843488244805e-06 all mean 8.424266866313701e-07
rl training, epoch3, iter0, batch141/1133, batch loss:2.4676637622178532e-06, Training time:73231.89620375633
batch reward last col mean 2.5598199499654584e-05 first col mean 7.285757419595029e-07 all mean 3.057791036553681e-05
rl training, epoch3, iter0, batch142/1133, batch loss:0.00028885476058349013, Training time:73259.06654500961
batch reward last col mean 7.14029965820373e-07 first col mean 7.053080025798408e-06 all mean 1.71488500200212e-06
rl training, epoch3, iter0, batch143/1133, batch loss:1.887987309601158e-05, Training time:73286.18213677406
batch reward last col mean 1.0928009942290373e-05 first col mean 8.701334991201293e-06 all mean 1.429464464308694e-05
rl training, epoch3, iter0, batch144/1133, batch loss:4.5747441618004814e-05, Training time:73314.99391365051
batch reward last col mean 1.0710971309890738e-06 first col mean 1.0233324019282009e-06 all mean 1.1065660601161653e-06
rl training, epoch3, iter0, batch145/1133, batch loss:7.473085474885011e-07, Training time:73344.5328669548
batch reward last col mean 1.6462112739645818e-07 first col mean 6.4805595911821e-07 all mean 7.174600114012719e-07
rl training, epoch3, iter0, batch146/1133, batch loss:1.9181402421963867e-06, Training time:73373.94468927383
batch reward last col mean 6.310105618467787e-06 first col mean 2.231548705822206e-06 all mean 6.184975973155815e-06
rl training, epoch3, iter0, batch147/1133, batch loss:2.4425976334896404e-06, Training time:73403.75918149948
batch reward last col mean 5.065897425993171e-07 first col mean 3.7546340081462404e-06 all mean 9.05110823623545e-07
rl training, epoch3, iter0, batch148/1133, batch loss:1.1065785656683147e-06, Training time:73433.32758331299
batch reward last col mean 1.1210266848138417e-06 first col mean 2.798023160721641e-06 all mean 1.9139926735078916e-05
rl training, epoch3, iter0, batch149/1133, batch loss:7.255226250890701e-07, Training time:73462.6728053093
batch reward last col mean 3.9699409626337e-07 first col mean 2.541861931604217e-06 all mean 1.8956844769491e-06
rl training, epoch3, iter0, batch150/1133, batch loss:3.852532699966105e-06, Training time:73491.98097586632
batch reward last col mean 4.900904286841978e-07 first col mean 0.00024646881502121687 all mean 2.9842674393876223e-06
rl training, epoch3, iter0, batch151/1133, batch loss:1.3851447420165641e-06, Training time:73521.45798873901
batch reward last col mean 3.4243653317389544e-06 first col mean 2.0627653611882124e-06 all mean 3.1132706226344453e-06
rl training, epoch3, iter0, batch152/1133, batch loss:1.997940671571996e-06, Training time:73551.77055954933
batch reward last col mean 1.4416473277378827e-06 first col mean 1.1495105809444794e-06 all mean 1.4786998008275987e-06
rl training, epoch3, iter0, batch153/1133, batch loss:2.1129167180333752e-06, Training time:73580.81951713562
batch reward last col mean 1.076730654858693e-06 first col mean 2.0687064079538686e-06 all mean 1.1207165471205371e-06
rl training, epoch3, iter0, batch154/1133, batch loss:6.979801128181862e-07, Training time:73610.13739323616
batch reward last col mean 1.8953291146317497e-05 first col mean 1.8136809103452833e-06 all mean 1.5189569239737466e-05
rl training, epoch3, iter0, batch155/1133, batch loss:1.0139963706023991e-05, Training time:73639.92882680893
batch reward last col mean 2.0077429780940292e-06 first col mean 3.60354732720225e-07 all mean 1.8971036297443788e-06
rl training, epoch3, iter0, batch156/1133, batch loss:1.2121583949920023e-06, Training time:73669.42252159119
batch reward last col mean 1.685878032731125e-07 first col mean 1.9713192159542814e-05 all mean 4.35126509046313e-07
rl training, epoch3, iter0, batch157/1133, batch loss:3.9221131942213106e-07, Training time:73699.04442691803
batch reward last col mean 1.4954346170270583e-06 first col mean 2.0251100067980587e-06 all mean 1.5110829281184124e-06
rl training, epoch3, iter0, batch158/1133, batch loss:1.300912458646053e-06, Training time:73728.233014822
batch reward last col mean 4.100799060324789e-07 first col mean 3.4543413676146884e-06 all mean 1.0084327186632436e-06
rl training, epoch3, iter0, batch159/1133, batch loss:9.032901289174333e-07, Training time:73757.49463295937
batch reward last col mean 1.302374016631802e-06 first col mean 0.00034556022728793323 all mean 3.11629701172933e-05
rl training, epoch3, iter0, batch160/1133, batch loss:0.0012416283134371042, Training time:73787.37217783928
batch reward last col mean 1.0928538358712103e-06 first col mean 1.955484549398534e-05 all mean 1.2890792504549609e-06
rl training, epoch3, iter0, batch161/1133, batch loss:1.5967010767781176e-05, Training time:73816.43119239807
batch reward last col mean 8.890956451068632e-07 first col mean 4.156750037509482e-06 all mean 1.4110897836872027e-06
rl training, epoch3, iter0, batch162/1133, batch loss:6.2116341723594815e-06, Training time:73846.13282132149
batch reward last col mean 0.00011760772031266242 first col mean 2.8402590032783337e-05 all mean 0.00010830524115590379
rl training, epoch3, iter0, batch163/1133, batch loss:2.846257484634407e-05, Training time:73875.64023947716
batch reward last col mean 1.390440775139723e-05 first col mean 9.213721205014735e-05 all mean 1.4857236237730831e-05
rl training, epoch3, iter0, batch164/1133, batch loss:6.757080882380251e-06, Training time:73905.01221203804
batch reward last col mean 2.495768740118365e-06 first col mean 2.0903546555928187e-06 all mean 2.879276735257008e-06
rl training, epoch3, iter0, batch165/1133, batch loss:8.665781024319585e-06, Training time:73935.04262757301
batch reward last col mean 1.635542616895691e-06 first col mean 4.9715872592059895e-06 all mean 1.591170257597696e-05
rl training, epoch3, iter0, batch166/1133, batch loss:7.012119749560952e-05, Training time:73964.29307985306
batch reward last col mean 4.914447231385566e-07 first col mean 1.5627387028871453e-06 all mean 5.567188168242865e-07
rl training, epoch3, iter0, batch167/1133, batch loss:4.9677059905661736e-06, Training time:73993.81624174118
batch reward last col mean 1.4651387800768134e-06 first col mean 2.307847807969665e-06 all mean 1.6209437490033451e-06
rl training, epoch3, iter0, batch168/1133, batch loss:1.7518137838123948e-06, Training time:74023.05045604706
batch reward last col mean 6.0564120758499485e-06 first col mean 1.1855328921228647e-05 all mean 6.25813618171378e-06
rl training, epoch3, iter0, batch169/1133, batch loss:2.484299329807982e-06, Training time:74053.06665325165
batch reward last col mean 5.52348126348079e-07 first col mean 6.159159966045991e-06 all mean 6.064428248464537e-07
rl training, epoch3, iter0, batch170/1133, batch loss:1.2658928199016373e-06, Training time:74082.71242570877
batch reward last col mean 9.523920994070068e-07 first col mean 6.899953859829111e-06 all mean 1.2121097370254574e-06
rl training, epoch3, iter0, batch171/1133, batch loss:1.4175896012602607e-06, Training time:74112.01228141785
batch reward last col mean 5.507366722667939e-07 first col mean 4.552401151158847e-06 all mean 1.800900349735457e-06
rl training, epoch3, iter0, batch172/1133, batch loss:6.716024927300168e-06, Training time:74141.90980958939
batch reward last col mean 3.519037363730604e-07 first col mean 8.436290954705328e-07 all mean 3.2847495390342374e-07
rl training, epoch3, iter0, batch173/1133, batch loss:2.255030722153606e-07, Training time:74171.69157481194
batch reward last col mean 5.1604369218694046e-05 first col mean 4.7975845518521965e-05 all mean 6.325901631498709e-05
rl training, epoch3, iter0, batch174/1133, batch loss:0.0006501250900328159, Training time:74201.383446455
batch reward last col mean 1.0108877859238419e-06 first col mean 3.7048262129246723e-06 all mean 1.4919245359124034e-06
rl training, epoch3, iter0, batch175/1133, batch loss:2.440441903672763e-06, Training time:74231.54139328003
batch reward last col mean 0.0008626753115095198 first col mean 8.39753556647338e-06 all mean 0.0008346723625436425
rl training, epoch3, iter0, batch176/1133, batch loss:0.00034282871638424695, Training time:74261.13173031807
batch reward last col mean 1.8463222772879817e-07 first col mean 0.00021873718651477247 all mean 2.5803067273955094e-06
rl training, epoch3, iter0, batch177/1133, batch loss:5.571785004576668e-05, Training time:74290.51832604408
batch reward last col mean 5.9062284663014e-07 first col mean 3.400786283691559e-07 all mean 1.0718634257500526e-05
rl training, epoch3, iter0, batch178/1133, batch loss:1.0012297479988774e-06, Training time:74320.225918293
batch reward last col mean 3.530103640514426e-05 first col mean 2.4391201804974116e-06 all mean 3.79728116968181e-05
rl training, epoch3, iter0, batch179/1133, batch loss:9.582037455402315e-05, Training time:74349.98878073692
batch reward last col mean 3.1641292252970743e-07 first col mean 2.802873041218845e-06 all mean 1.1660806649160804e-06
rl training, epoch3, iter0, batch180/1133, batch loss:1.3078670235699974e-06, Training time:74379.90503025055
batch reward last col mean 6.688166536150675e-07 first col mean 4.4127176579422667e-07 all mean 8.960697641668958e-07
rl training, epoch3, iter0, batch181/1133, batch loss:3.6402111618372146e-06, Training time:74409.7002556324
batch reward last col mean 2.164606030419236e-06 first col mean 1.8637563243828481e-06 all mean 2.2544297735294094e-06
rl training, epoch3, iter0, batch182/1133, batch loss:8.371568583243061e-06, Training time:74440.0378818512
batch reward last col mean 5.680803587893024e-05 first col mean 8.572197316425445e-07 all mean 4.8835903726285324e-05
rl training, epoch3, iter0, batch183/1133, batch loss:4.5977780246175826e-05, Training time:74470.06958723068
batch reward last col mean 1.324690060755529e-06 first col mean 2.4520807073713513e-06 all mean 1.2349080407147994e-06
rl training, epoch3, iter0, batch184/1133, batch loss:1.2159803191025276e-06, Training time:74499.14850068092
batch reward last col mean 3.7329681390474434e-07 first col mean 2.851495764844003e-06 all mean 1.4320397667688667e-06
rl training, epoch3, iter0, batch185/1133, batch loss:1.790892747521866e-05, Training time:74528.25697731972
batch reward last col mean 2.4763212991274486e-07 first col mean 4.468314728001133e-06 all mean 3.9347216329588264e-07
rl training, epoch3, iter0, batch186/1133, batch loss:1.4018710317031946e-06, Training time:74557.78915977478
batch reward last col mean 4.2819607187993824e-05 first col mean 5.176959348318633e-06 all mean 4.224403164698742e-05
rl training, epoch3, iter0, batch187/1133, batch loss:1.9119221178698353e-05, Training time:74587.84704732895
batch reward last col mean 2.9550341196227237e-07 first col mean 6.557860160683049e-06 all mean 4.5884209498581185e-07
rl training, epoch3, iter0, batch188/1133, batch loss:8.744552246753301e-07, Training time:74616.93865299225
batch reward last col mean 1.0495364222151693e-06 first col mean 9.606897947378457e-06 all mean 1.1620568329817615e-06
rl training, epoch3, iter0, batch189/1133, batch loss:1.5556095149804605e-06, Training time:74646.74627423286
batch reward last col mean 4.801325985681615e-07 first col mean 5.439286496766726e-07 all mean 5.366238156057079e-07
rl training, epoch3, iter0, batch190/1133, batch loss:8.463609333375643e-07, Training time:74676.3630566597
batch reward last col mean 2.358363417442888e-05 first col mean 2.434081807223265e-06 all mean 2.3092054107110016e-05
rl training, epoch3, iter0, batch191/1133, batch loss:1.1469104720163159e-05, Training time:74705.31402301788
batch reward last col mean 1.5196361573543982e-06 first col mean 0.00010798604489536956 all mean 3.727027660715976e-06
rl training, epoch3, iter0, batch192/1133, batch loss:8.488386811222881e-07, Training time:74734.81554245949
batch reward last col mean 3.9355387571049505e-07 first col mean 3.8578360772589804e-07 all mean 4.643606246190757e-07
rl training, epoch3, iter0, batch193/1133, batch loss:7.694737291785714e-07, Training time:74763.98810958862
batch reward last col mean 2.8534117291201255e-07 first col mean 5.926178801018978e-07 all mean 3.032000392977352e-07
rl training, epoch3, iter0, batch194/1133, batch loss:4.755427482905361e-07, Training time:74793.30426001549
batch reward last col mean 6.149112437014992e-07 first col mean 8.762065135670127e-07 all mean 5.375963155529462e-06
rl training, epoch3, iter0, batch195/1133, batch loss:1.985315975616686e-06, Training time:74822.68391942978
batch reward last col mean 0.0002442620461806655 first col mean 0.00019637978402897716 all mean 0.0002479782560840249
rl training, epoch3, iter0, batch196/1133, batch loss:0.000238443462876603, Training time:74852.43737268448
batch reward last col mean 3.838667907984927e-06 first col mean 2.839237822627183e-05 all mean 3.303542689536698e-05
rl training, epoch3, iter0, batch197/1133, batch loss:0.0008443110273219645, Training time:74881.83013248444
batch reward last col mean 2.688266249606386e-06 first col mean 1.160118017651257e-06 all mean 4.5478086576622445e-06
rl training, epoch3, iter0, batch198/1133, batch loss:5.527192115550861e-06, Training time:74911.81008672714
batch reward last col mean 6.512708750960883e-06 first col mean 2.9965653425279015e-07 all mean 6.54068071526126e-06
rl training, epoch3, iter0, batch199/1133, batch loss:3.1879949347057845e-06, Training time:74941.69265604019
batch reward last col mean 3.6525680116028525e-06 first col mean 0.00029971011099405587 all mean 6.56565816825605e-06
rl training, epoch3, iter0, batch200/1133, batch loss:7.2972356974787544e-06, Training time:74971.46249771118
batch reward last col mean 4.035122856294038e-06 first col mean 1.597766276972834e-05 all mean 4.621135758497985e-06
rl training, epoch3, iter0, batch201/1133, batch loss:3.8066352772148093e-06, Training time:75001.12115907669
batch reward last col mean 2.726117827478447e-06 first col mean 1.0922390174528118e-05 all mean 3.207568397556315e-06
rl training, epoch3, iter0, batch202/1133, batch loss:2.6469888325664215e-06, Training time:75030.58079195023
batch reward last col mean 2.1909297629463254e-06 first col mean 9.070813007383549e-07 all mean 2.6381960651633563e-06
rl training, epoch3, iter0, batch203/1133, batch loss:3.584078513085842e-06, Training time:75060.25803303719
batch reward last col mean 0.004742454271763563 first col mean 0.00020560651319101453 all mean 0.004642564337700605
rl training, epoch3, iter0, batch204/1133, batch loss:0.0019984557293355465, Training time:75089.78971886635
batch reward last col mean 2.0024654077133164e-06 first col mean 6.225481683941325e-06 all mean 1.9646238342829747e-06
rl training, epoch3, iter0, batch205/1133, batch loss:3.231591108487919e-06, Training time:75119.38952493668
batch reward last col mean 1.3084389820505749e-06 first col mean 1.0432007684357814e-06 all mean 2.941111915788497e-06
rl training, epoch3, iter0, batch206/1133, batch loss:9.825757297221571e-05, Training time:75148.6970205307
batch reward last col mean 5.314514623933064e-07 first col mean 6.184919811857981e-07 all mean 9.032458478941408e-07
rl training, epoch3, iter0, batch207/1133, batch loss:2.010798652918311e-06, Training time:75178.01891493797
batch reward last col mean 7.888773438935459e-07 first col mean 1.238123786606593e-06 all mean 1.123441734307562e-06
rl training, epoch3, iter0, batch208/1133, batch loss:5.742295343225123e-06, Training time:75207.5236120224
batch reward last col mean 1.1221832210139837e-05 first col mean 0.00015796467778272927 all mean 2.0516452423180453e-05
rl training, epoch3, iter0, batch209/1133, batch loss:3.979508619522676e-05, Training time:75237.23196172714
batch reward last col mean 2.4191115244320827e-06 first col mean 6.848327757325023e-06 all mean 2.982677642648923e-06
rl training, epoch3, iter0, batch210/1133, batch loss:1.6778518329374492e-05, Training time:75267.31878185272
batch reward last col mean 2.532935923227342e-06 first col mean 4.589542731991969e-05 all mean 3.1220972687151516e-06
rl training, epoch3, iter0, batch211/1133, batch loss:1.1738729881471954e-05, Training time:75296.74117541313
batch reward last col mean 4.870063094131183e-06 first col mean 1.1828251444967464e-05 all mean 4.914545115752844e-06
rl training, epoch3, iter0, batch212/1133, batch loss:3.604277026170166e-06, Training time:75326.07406139374
batch reward last col mean 6.694912826787913e-06 first col mean 8.387115485675167e-06 all mean 7.864775398047641e-06
rl training, epoch3, iter0, batch213/1133, batch loss:6.051503987691831e-06, Training time:75355.57594323158
batch reward last col mean 4.96997654408915e-06 first col mean 3.569255568436347e-06 all mean 4.9927075451705605e-06
rl training, epoch3, iter0, batch214/1133, batch loss:6.062346074031666e-06, Training time:75384.5841190815
batch reward last col mean 1.095915195037378e-06 first col mean 8.417716230724182e-07 all mean 1.1700493587341043e-06
rl training, epoch3, iter0, batch215/1133, batch loss:1.1634000429694424e-06, Training time:75414.23158335686
batch reward last col mean 9.667944596003508e-07 first col mean 7.39891561352124e-07 all mean 1.0410578852315666e-06
rl training, epoch3, iter0, batch216/1133, batch loss:1.0560787586655351e-06, Training time:75443.63420057297
batch reward last col mean 1.0159250223296112e-06 first col mean 6.488116468972294e-06 all mean 1.620560033188667e-05
rl training, epoch3, iter0, batch217/1133, batch loss:0.0003503368643578142, Training time:75472.93223786354
batch reward last col mean 0.00030199828324839473 first col mean 0.0004699807323049754 all mean 0.00030568937654607
rl training, epoch3, iter0, batch218/1133, batch loss:0.0005600760341621935, Training time:75502.90201282501
batch reward last col mean 2.0477305952226743e-05 first col mean 1.4031006685399916e-06 all mean 1.986434835998807e-05
rl training, epoch3, iter0, batch219/1133, batch loss:6.713014954584651e-06, Training time:75532.78369188309
batch reward last col mean 1.2465818599594058e-06 first col mean 2.3491363663197262e-06 all mean 1.5257744507835014e-06
rl training, epoch3, iter0, batch220/1133, batch loss:1.784030132512271e-06, Training time:75562.39300775528
batch reward last col mean 1.0256369478156557e-06 first col mean 8.028161460060801e-07 all mean 1.517443593002099e-06
rl training, epoch3, iter0, batch221/1133, batch loss:2.117395069944905e-06, Training time:75591.65674328804
batch reward last col mean 9.574764590070117e-07 first col mean 7.824027647984622e-07 all mean 8.812150440462574e-07
rl training, epoch3, iter0, batch222/1133, batch loss:6.62533068407356e-07, Training time:75620.9597465992
batch reward last col mean 1.5472296581720002e-06 first col mean 1.4165584616421256e-05 all mean 1.5510115645156475e-06
rl training, epoch3, iter0, batch223/1133, batch loss:1.2569172440635157e-06, Training time:75650.10618710518
batch reward last col mean 5.62682471354492e-05 first col mean 1.2350831184448907e-06 all mean 5.571582732954994e-05
rl training, epoch3, iter0, batch224/1133, batch loss:1.9460258045000955e-05, Training time:75679.50745773315
batch reward last col mean 3.493861413517152e-06 first col mean 5.538904588320293e-07 all mean 4.1020089156518225e-06
rl training, epoch3, iter0, batch225/1133, batch loss:1.2348440577625297e-05, Training time:75709.169880867
batch reward last col mean 1.0727399057941511e-06 first col mean 1.6798206843304797e-06 all mean 1.5768313460284844e-05
rl training, epoch3, iter0, batch226/1133, batch loss:0.00036593686672858894, Training time:75739.02409029007
batch reward last col mean 6.670385573670501e-06 first col mean 5.04481158714043e-06 all mean 1.9789385987678543e-05
rl training, epoch3, iter0, batch227/1133, batch loss:0.0003544527280610055, Training time:75768.72185850143
batch reward last col mean 0.001669343444518745 first col mean 9.670455256127752e-06 all mean 0.0015979916788637638
rl training, epoch3, iter0, batch228/1133, batch loss:0.0010002611670643091, Training time:75798.14733099937
batch reward last col mean 6.736939326401625e-07 first col mean 4.500135219132062e-06 all mean 7.404537996080762e-07
rl training, epoch3, iter0, batch229/1133, batch loss:5.063996582066466e-07, Training time:75827.93820261955
batch reward last col mean 4.768481289829651e-07 first col mean 5.598971029030508e-07 all mean 8.474314654449699e-07
rl training, epoch3, iter0, batch230/1133, batch loss:4.836439075006638e-06, Training time:75856.99213862419
batch reward last col mean 3.339582690387033e-07 first col mean 7.234805821099144e-07 all mean 2.039415812760126e-05
rl training, epoch3, iter0, batch231/1133, batch loss:0.0008464339771308005, Training time:75886.85691666603
batch reward last col mean 1.3997571386425989e-06 first col mean 4.958195859217085e-06 all mean 1.0734773240983486e-05
rl training, epoch3, iter0, batch232/1133, batch loss:7.668678154004738e-05, Training time:75917.26147723198
batch reward last col mean 3.888020501108258e-07 first col mean 1.9596811853261897e-06 all mean 1.903648444567807e-05
rl training, epoch3, iter0, batch233/1133, batch loss:0.0009701963281258941, Training time:75946.41156506538
batch reward last col mean 1.2988815001335752e-07 first col mean 1.6885209674910584e-07 all mean 2.0149353474607778e-07
rl training, epoch3, iter0, batch234/1133, batch loss:4.813242071577406e-07, Training time:75975.9707725048
batch reward last col mean 7.002121833465935e-07 first col mean 1.2787660352842067e-06 all mean 1.1245955420235987e-06
rl training, epoch3, iter0, batch235/1133, batch loss:4.1733715079317335e-06, Training time:76005.07544732094
batch reward last col mean 1.2070041520928498e-05 first col mean 4.124080533074448e-06 all mean 1.2331937796261627e-05
rl training, epoch3, iter0, batch236/1133, batch loss:5.607878392765997e-06, Training time:76034.71649980545
batch reward last col mean 1.3052667782176286e-06 first col mean 4.716285729955416e-06 all mean 2.0034658518852666e-06
rl training, epoch3, iter0, batch237/1133, batch loss:4.097740202269051e-06, Training time:76065.02378177643
batch reward last col mean 3.1479675044465694e-07 first col mean 5.557586177928897e-07 all mean 3.379853978913161e-07
rl training, epoch3, iter0, batch238/1133, batch loss:9.040849135999451e-07, Training time:76094.74577617645
batch reward last col mean 7.010016997810453e-05 first col mean 7.604856364196166e-06 all mean 6.854355160612613e-05
rl training, epoch3, iter0, batch239/1133, batch loss:2.399348159087822e-05, Training time:76124.04859614372
batch reward last col mean 5.639470259666268e-07 first col mean 9.684711585578043e-06 all mean 1.444200847799948e-06
rl training, epoch3, iter0, batch240/1133, batch loss:6.963781288504833e-06, Training time:76153.9890973568
batch reward last col mean 3.8255216168181505e-06 first col mean 8.617153980594594e-06 all mean 5.244530257186852e-06
rl training, epoch3, iter0, batch241/1133, batch loss:4.616873775376007e-05, Training time:76183.25436663628
batch reward last col mean 1.4368092706718016e-05 first col mean 7.019745225989027e-06 all mean 1.4251883840188384e-05
rl training, epoch3, iter0, batch242/1133, batch loss:3.7695488117606146e-06, Training time:76213.16018438339
batch reward last col mean 4.7516365157207474e-05 first col mean 2.3739225980534684e-06 all mean 4.527716009761207e-05
rl training, epoch3, iter0, batch243/1133, batch loss:7.539967100456124e-06, Training time:76242.42673563957
batch reward last col mean 1.4634702893090434e-05 first col mean 6.175775979500031e-07 all mean 1.480835817346815e-05
rl training, epoch3, iter0, batch244/1133, batch loss:1.873548171715811e-05, Training time:76271.2341170311
batch reward last col mean 4.040094836454955e-07 first col mean 1.9553299352992326e-06 all mean 1.162585931524518e-06
rl training, epoch3, iter0, batch245/1133, batch loss:1.7160256902570836e-05, Training time:76300.68707466125
batch reward last col mean 7.302405720110983e-05 first col mean 5.009141545997409e-07 all mean 7.146042480599135e-05
rl training, epoch3, iter0, batch246/1133, batch loss:3.39101352437865e-05, Training time:76330.44336891174
batch reward last col mean 7.144726168917259e-06 first col mean 3.1909160043142037e-06 all mean 7.211475349322427e-06
rl training, epoch3, iter0, batch247/1133, batch loss:1.8578321032691747e-05, Training time:76360.38207149506
batch reward last col mean 5.581684945354937e-07 first col mean 9.116851060753106e-07 all mean 6.97909115388029e-07
rl training, epoch3, iter0, batch248/1133, batch loss:3.976700554630952e-06, Training time:76390.29914331436
batch reward last col mean 1.6863494920471567e-06 first col mean 2.6301595426048152e-06 all mean 1.593507931829663e-06
rl training, epoch3, iter0, batch249/1133, batch loss:1.2674073559537646e-06, Training time:76419.55881357193
batch reward last col mean 9.564881793266977e-07 first col mean 2.544250037317397e-06 all mean 9.838174719334347e-07
rl training, epoch3, iter0, batch250/1133, batch loss:1.1107490536232945e-06, Training time:76448.87939357758
batch reward last col mean 2.4940919729488087e-07 first col mean 1.2226173566887155e-06 all mean 2.298902700204053e-06
rl training, epoch3, iter0, batch251/1133, batch loss:1.5953488400555216e-05, Training time:76478.25155878067
batch reward last col mean 2.509940713935066e-06 first col mean 5.489513114298461e-06 all mean 3.1264421522791963e-06
rl training, epoch3, iter0, batch252/1133, batch loss:2.8197777282912284e-05, Training time:76507.93738675117
batch reward last col mean 6.426807885873131e-07 first col mean 3.920320978068048e-06 all mean 7.816182119313453e-07
rl training, epoch3, iter0, batch253/1133, batch loss:2.151819217033335e-06, Training time:76537.12487697601
batch reward last col mean 1.0970613402605522e-05 first col mean 5.482559572556056e-06 all mean 1.052907646226231e-05
rl training, epoch3, iter0, batch254/1133, batch loss:9.696841516415589e-06, Training time:76567.10089945793
batch reward last col mean 1.1223452020203695e-05 first col mean 1.067494736162189e-06 all mean 2.228129051218275e-05
rl training, epoch3, iter0, batch255/1133, batch loss:4.285808972781524e-05, Training time:76596.81588053703
batch reward last col mean 4.511352926783729e-06 first col mean 1.9266717572463676e-06 all mean 5.7265260693384334e-06
rl training, epoch3, iter0, batch256/1133, batch loss:9.981481525755953e-06, Training time:76626.15629506111
batch reward last col mean 2.733309520408511e-05 first col mean 2.3621469154022634e-06 all mean 2.6871713998843916e-05
rl training, epoch3, iter0, batch257/1133, batch loss:1.0061467946798075e-05, Training time:76655.47320079803
batch reward last col mean 3.5958021271653706e-06 first col mean 0.00013428396778181195 all mean 5.098170277051395e-06
rl training, epoch3, iter0, batch258/1133, batch loss:1.132996658270713e-05, Training time:76685.89880728722
batch reward last col mean 8.903268735593883e-07 first col mean 1.9446833903202787e-06 all mean 3.393148062968976e-06
rl training, epoch3, iter0, batch259/1133, batch loss:2.6258085199515335e-05, Training time:76715.16607165337
batch reward last col mean 3.5064340409007855e-07 first col mean 7.598036972922273e-07 all mean 4.979675054528343e-07
rl training, epoch3, iter0, batch260/1133, batch loss:1.6149058410519501e-06, Training time:76744.9646012783
batch reward last col mean 2.711230308705126e-06 first col mean 1.5775219708302757e-06 all mean 2.8986542019993067e-06
rl training, epoch3, iter0, batch261/1133, batch loss:3.2583961910859216e-06, Training time:76774.64422488213
batch reward last col mean 9.586240139469737e-07 first col mean 2.1819141693413258e-07 all mean 1.1864873386002728e-06
rl training, epoch3, iter0, batch262/1133, batch loss:1.243623046320863e-06, Training time:76804.583725214
batch reward last col mean 9.769796633918304e-07 first col mean 8.57414761412656e-06 all mean 1.0371592225055792e-06
rl training, epoch3, iter0, batch263/1133, batch loss:5.172959845367586e-06, Training time:76834.05795621872
batch reward last col mean 2.8140584618085995e-06 first col mean 4.8574227548670024e-05 all mean 3.4101180972356815e-06
rl training, epoch3, iter0, batch264/1133, batch loss:1.5866449984969222e-06, Training time:76863.86689662933
batch reward last col mean 1.524089611848467e-06 first col mean 1.0695036962715676e-06 all mean 7.860957339289598e-06
rl training, epoch3, iter0, batch265/1133, batch loss:0.00010466724779689685, Training time:76893.58141708374
batch reward last col mean 6.649725037277676e-07 first col mean 3.052052761631785e-06 all mean 1.2714451713691233e-06
rl training, epoch3, iter0, batch266/1133, batch loss:4.351203187979991e-06, Training time:76922.69103503227
batch reward last col mean 1.8481773622625042e-07 first col mean 3.365832526469603e-06 all mean 3.4327362641306536e-07
rl training, epoch3, iter0, batch267/1133, batch loss:9.061770356311172e-07, Training time:76952.05547714233
batch reward last col mean 4.9073849368141964e-05 first col mean 1.3079496966383886e-05 all mean 4.7567376896040514e-05
rl training, epoch3, iter0, batch268/1133, batch loss:2.1548656150116585e-05, Training time:76981.39559531212
batch reward last col mean 1.1446983990026638e-05 first col mean 6.938270234968513e-05 all mean 1.89125621545827e-05
rl training, epoch3, iter0, batch269/1133, batch loss:7.421591726597399e-05, Training time:77010.18006300926
batch reward last col mean 1.4185913244091353e-07 first col mean 2.4226894765888574e-06 all mean 5.68332552575157e-07
rl training, epoch3, iter0, batch270/1133, batch loss:1.2522676115622744e-05, Training time:77039.87166166306
batch reward last col mean 5.855925337527879e-06 first col mean 8.078042128545349e-07 all mean 5.857529231434455e-06
rl training, epoch3, iter0, batch271/1133, batch loss:9.318838465333101e-07, Training time:77069.43233776093
batch reward last col mean 1.774510280938557e-07 first col mean 2.0571244476741413e-06 all mean 2.6217023219032853e-07
rl training, epoch3, iter0, batch272/1133, batch loss:3.494373856938182e-07, Training time:77098.67641592026
batch reward last col mean 4.7489834287262056e-07 first col mean 6.265245247050188e-07 all mean 9.444388524570968e-07
rl training, epoch3, iter0, batch273/1133, batch loss:1.29446777918929e-06, Training time:77128.58886742592
batch reward last col mean 9.215680620400235e-06 first col mean 2.8285555799811846e-06 all mean 9.024026439874433e-06
rl training, epoch3, iter0, batch274/1133, batch loss:3.033384473383194e-06, Training time:77158.42300200462
batch reward last col mean 0.001502582454122603 first col mean 3.396981810510624e-06 all mean 0.0014617039123550057
rl training, epoch3, iter0, batch275/1133, batch loss:0.00032156455563381314, Training time:77188.2910079956
batch reward last col mean 5.493719754667836e-07 first col mean 3.5432098229648545e-05 all mean 9.009770565171493e-07
rl training, epoch3, iter0, batch276/1133, batch loss:6.805934731346497e-07, Training time:77217.94689178467
batch reward last col mean 6.388618203345686e-07 first col mean 1.6707065242371755e-06 all mean 6.971124548726948e-07
rl training, epoch3, iter0, batch277/1133, batch loss:1.600880409569072e-06, Training time:77246.20975804329
batch reward last col mean 5.926392077526543e-06 first col mean 4.346920468378812e-05 all mean 5.615475856757257e-06
rl training, epoch3, iter0, batch278/1133, batch loss:3.867578925564885e-06, Training time:77275.641872406
batch reward last col mean 1.3735411812376697e-05 first col mean 1.3297881196194794e-05 all mean 1.6157038771780208e-05
rl training, epoch3, iter0, batch279/1133, batch loss:0.00014977554383222014, Training time:77305.29051065445
batch reward last col mean 7.63035757245234e-07 first col mean 0.0002889680617954582 all mean 8.810517101665027e-06
rl training, epoch3, iter0, batch280/1133, batch loss:2.202720224886434e-06, Training time:77334.83380842209
batch reward last col mean 3.3541223842803447e-07 first col mean 2.474863549650763e-06 all mean 6.355782034006552e-07
rl training, epoch3, iter0, batch281/1133, batch loss:1.7935075220520957e-06, Training time:77364.83080029488
batch reward last col mean 6.245943222893402e-05 first col mean 9.238708298653364e-05 all mean 6.258234498091042e-05
rl training, epoch3, iter0, batch282/1133, batch loss:1.8072301827487536e-05, Training time:77394.66697216034
batch reward last col mean 4.961921149515547e-07 first col mean 6.807714271417353e-06 all mean 6.769380433979677e-07
rl training, epoch3, iter0, batch283/1133, batch loss:2.2381459530151915e-06, Training time:77424.35096526146
batch reward last col mean 8.714285968380864e-07 first col mean 4.01144416173338e-06 all mean 1.098069446925365e-06
rl training, epoch3, iter0, batch284/1133, batch loss:1.2405382676661247e-06, Training time:77453.69911551476
batch reward last col mean 3.67050097338506e-06 first col mean 5.689479075954296e-05 all mean 4.863362391915871e-06
rl training, epoch3, iter0, batch285/1133, batch loss:2.8738737455569208e-05, Training time:77483.32943415642
batch reward last col mean 2.6693118115872494e-07 first col mean 4.317988896218594e-06 all mean 8.613581599092868e-07
rl training, epoch3, iter0, batch286/1133, batch loss:1.8011583961197175e-05, Training time:77512.54439735413
batch reward last col mean 8.216846936193178e-07 first col mean 4.87468128085311e-07 all mean 7.791722964611836e-07
rl training, epoch3, iter0, batch287/1133, batch loss:4.170529450675531e-07, Training time:77541.57346653938
batch reward last col mean 1.3431707657218794e-07 first col mean 0.00011558079859241843 all mean 1.602932570676785e-06
rl training, epoch3, iter0, batch288/1133, batch loss:1.257331132364925e-05, Training time:77570.52617526054
batch reward last col mean 2.3566518336792797e-07 first col mean 4.438842893250694e-07 all mean 2.9728008144047635e-07
rl training, epoch3, iter0, batch289/1133, batch loss:6.727185564159299e-07, Training time:77600.08191275597
batch reward last col mean 2.2069734768592753e-06 first col mean 2.0318211682024412e-05 all mean 5.034438345319359e-06
rl training, epoch3, iter0, batch290/1133, batch loss:1.8451935829943977e-05, Training time:77629.62724041939
batch reward last col mean 1.5700078392910655e-06 first col mean 0.0018895870307460427 all mean 2.6662033633328974e-05
rl training, epoch3, iter0, batch291/1133, batch loss:0.0005703899078071117, Training time:77659.49437785149
batch reward last col mean 1.355904259980889e-06 first col mean 0.00010318028216715902 all mean 3.6266665119910613e-06
rl training, epoch3, iter0, batch292/1133, batch loss:7.409044337691739e-05, Training time:77689.14839076996
batch reward last col mean 3.3345650081173517e-06 first col mean 3.149848635075614e-05 all mean 3.5882553675037343e-06
rl training, epoch3, iter0, batch293/1133, batch loss:2.330125880689593e-06, Training time:77718.62230587006
batch reward last col mean 1.305997466261033e-05 first col mean 4.347645699454006e-06 all mean 1.4304204341897275e-05
rl training, epoch3, iter0, batch294/1133, batch loss:8.437978976871818e-06, Training time:77747.82270216942
batch reward last col mean 1.42034400596458e-06 first col mean 1.1526329899425036e-06 all mean 1.4335313380797743e-06
rl training, epoch3, iter0, batch295/1133, batch loss:1.3048951359451166e-06, Training time:77777.2908270359
batch reward last col mean 2.0553425201796927e-06 first col mean 0.0007309764041565359 all mean 1.1394534340070095e-05
rl training, epoch3, iter0, batch296/1133, batch loss:4.722147423308343e-05, Training time:77806.62641692162
batch reward last col mean 8.43251655169297e-07 first col mean 2.9880189686082304e-05 all mean 1.4609576055590878e-06
rl training, epoch3, iter0, batch297/1133, batch loss:1.9408655589359114e-06, Training time:77836.18109679222
batch reward last col mean 2.9634443876602745e-07 first col mean 7.766819862808916e-07 all mean 3.953554710278695e-07
rl training, epoch3, iter0, batch298/1133, batch loss:8.24401183763257e-07, Training time:77865.49706578255
batch reward last col mean 3.7383966855486506e-07 first col mean 3.6578226172423456e-06 all mean 2.1494977318070596e-06
rl training, epoch3, iter0, batch299/1133, batch loss:5.7913239288609475e-05, Training time:77895.47973537445
batch reward last col mean 2.5395015654794406e-06 first col mean 2.6715918011177564e-07 all mean 2.5024601200129837e-06
rl training, epoch3, iter0, batch300/1133, batch loss:2.0549273358483333e-06, Training time:77924.6751601696
batch reward last col mean 1.616787699276756e-07 first col mean 1.5500884842367668e-07 all mean 1.975614907223644e-07
rl training, epoch3, iter0, batch301/1133, batch loss:2.1220033374902414e-07, Training time:77954.34374928474
batch reward last col mean 3.49046695191646e-06 first col mean 0.0001385666837450117 all mean 4.8979495659295935e-06
rl training, epoch3, iter0, batch302/1133, batch loss:2.8474946702772286e-06, Training time:77984.23973727226
batch reward last col mean 8.494934036207269e-07 first col mean 7.385917797364527e-07 all mean 8.827202009342727e-07
rl training, epoch3, iter0, batch303/1133, batch loss:6.291796808000072e-07, Training time:78014.10585141182
batch reward last col mean 5.231664772509248e-07 first col mean 7.772953836138186e-07 all mean 2.900277877415647e-06
rl training, epoch3, iter0, batch304/1133, batch loss:6.787759775761515e-05, Training time:78043.76202559471
batch reward last col mean 2.8770921289833495e-06 first col mean 2.0029909137520008e-05 all mean 3.6198900943418266e-06
rl training, epoch3, iter0, batch305/1133, batch loss:3.2572572763456265e-06, Training time:78073.20480108261
batch reward last col mean 1.6279450392175931e-06 first col mean 3.0939504540583584e-06 all mean 3.5228313208790496e-06
rl training, epoch3, iter0, batch306/1133, batch loss:2.6268442070431774e-06, Training time:78102.7879974842
batch reward last col mean 3.9605718484381214e-05 first col mean 3.871943772537634e-05 all mean 4.762216849485412e-05
rl training, epoch3, iter0, batch307/1133, batch loss:5.897438677493483e-05, Training time:78132.68173217773
batch reward last col mean 8.423846338700969e-06 first col mean 7.935201210784726e-06 all mean 8.426698514085729e-06
rl training, epoch3, iter0, batch308/1133, batch loss:4.487954811338568e-06, Training time:78162.25081539154
batch reward last col mean 5.205134129937505e-06 first col mean 8.056925935306936e-07 all mean 5.18893648404628e-06
rl training, epoch3, iter0, batch309/1133, batch loss:6.820854196121218e-06, Training time:78190.99999213219
batch reward last col mean 0.00010645816655596718 first col mean 4.0532271668780595e-05 all mean 0.00010327892960049212
rl training, epoch3, iter0, batch310/1133, batch loss:4.3069874664070085e-05, Training time:78220.3711822033
batch reward last col mean 4.412803264131071e-06 first col mean 2.8315207600826398e-06 all mean 4.628655005944893e-06
rl training, epoch3, iter0, batch311/1133, batch loss:6.77124398862361e-06, Training time:78249.86796331406
batch reward last col mean 1.618193721242278e-07 first col mean 9.602524642104981e-07 all mean 1.530847293906845e-05
rl training, epoch3, iter0, batch312/1133, batch loss:0.00024594325805082917, Training time:78279.31830620766
batch reward last col mean 0.0005956641398370266 first col mean 5.923987487221893e-07 all mean 0.0005698108579963446
rl training, epoch3, iter0, batch313/1133, batch loss:0.0002986665058415383, Training time:78308.86298751831
batch reward last col mean 5.488253691510181e-07 first col mean 2.0837785541516496e-06 all mean 2.3911632069939515e-06
rl training, epoch3, iter0, batch314/1133, batch loss:7.81415292294696e-06, Training time:78338.22529530525
batch reward last col mean 5.779882030765293e-07 first col mean 1.7164823020721087e-06 all mean 9.688317277323222e-07
rl training, epoch3, iter0, batch315/1133, batch loss:2.0539480374281993e-06, Training time:78368.05204343796
batch reward last col mean 1.5635465615559951e-06 first col mean 8.872850230545737e-06 all mean 1.4915210613253294e-06
rl training, epoch3, iter0, batch316/1133, batch loss:1.6417779988842085e-06, Training time:78398.25671601295
batch reward last col mean 1.3176721722629736e-06 first col mean 0.00019030377734452486 all mean 3.921218649338698e-06
rl training, epoch3, iter0, batch317/1133, batch loss:6.943360494915396e-05, Training time:78427.77108240128
batch reward last col mean 8.613149589109526e-07 first col mean 1.8856389942811802e-06 all mean 8.935921869124286e-07
rl training, epoch3, iter0, batch318/1133, batch loss:1.2829863180741086e-06, Training time:78457.62145400047
batch reward last col mean 4.308103962102905e-05 first col mean 3.5354282772459555e-06 all mean 3.823876613751054e-05
rl training, epoch3, iter0, batch319/1133, batch loss:1.559523298055865e-05, Training time:78487.30992555618
batch reward last col mean 7.602726270761195e-08 first col mean 2.5996860131272115e-05 all mean 4.203337482522329e-07
rl training, epoch3, iter0, batch320/1133, batch loss:3.8910206967557315e-07, Training time:78516.97585654259
batch reward last col mean 2.9521061151172034e-06 first col mean 3.89889964935719e-06 all mean 2.951660007965984e-06
rl training, epoch3, iter0, batch321/1133, batch loss:3.4874549328378635e-06, Training time:78546.58718919754
batch reward last col mean 2.8423735898286395e-07 first col mean 5.279944889480248e-05 all mean 9.982068149838597e-07
rl training, epoch3, iter0, batch322/1133, batch loss:8.6345471572713e-06, Training time:78576.29973959923
batch reward last col mean 6.615709025936667e-06 first col mean 1.6309741113218479e-06 all mean 6.616332029807381e-06
rl training, epoch3, iter0, batch323/1133, batch loss:2.306661144757527e-06, Training time:78605.78553557396
batch reward last col mean 2.223580850113649e-06 first col mean 3.54994299414102e-05 all mean 2.8974727683817036e-06
rl training, epoch3, iter0, batch324/1133, batch loss:4.120311587030301e-06, Training time:78635.13357043266
batch reward last col mean 5.506362299456669e-07 first col mean 4.0495351640856825e-06 all mean 1.008455456030788e-06
rl training, epoch3, iter0, batch325/1133, batch loss:1.746307930261537e-06, Training time:78664.93427467346
batch reward last col mean 1.6776015172581538e-06 first col mean 1.0658918654371519e-05 all mean 2.1820249003212666e-06
rl training, epoch3, iter0, batch326/1133, batch loss:2.5156916763080517e-06, Training time:78694.4175517559
batch reward last col mean 9.061900527740363e-07 first col mean 1.69837185239885e-05 all mean 2.25294497795403e-05
rl training, epoch3, iter0, batch327/1133, batch loss:9.521238825982437e-05, Training time:78723.5155377388
batch reward last col mean 2.4712716140129487e-07 first col mean 6.541455377373495e-07 all mean 3.088154869601567e-07
rl training, epoch3, iter0, batch328/1133, batch loss:5.458639975586266e-07, Training time:78753.42054581642
batch reward last col mean 2.1194025521253934e-06 first col mean 4.261584649611905e-07 all mean 1.7941027863344061e-06
rl training, epoch3, iter0, batch329/1133, batch loss:2.364239662711043e-06, Training time:78783.23908543587
batch reward last col mean 2.4236209128503106e-07 first col mean 4.0681499058337067e-07 all mean 3.572954767605552e-07
rl training, epoch3, iter0, batch330/1133, batch loss:6.13997769960406e-07, Training time:78812.88260817528
batch reward last col mean 1.1241108950343914e-06 first col mean 5.507613423105795e-07 all mean 1.5731633311588666e-06
rl training, epoch3, iter0, batch331/1133, batch loss:2.761292080322164e-06, Training time:78842.77197527885
batch reward last col mean 5.244579597274424e-07 first col mean 2.748471342783887e-05 all mean 9.055847840500064e-07
rl training, epoch3, iter0, batch332/1133, batch loss:3.400195510039339e-06, Training time:78872.56653261185
batch reward last col mean 3.041614036192186e-06 first col mean 0.00014610009384341538 all mean 4.277059360902058e-06
rl training, epoch3, iter0, batch333/1133, batch loss:1.2993899872526526e-05, Training time:78902.19400548935
batch reward last col mean 1.048236299538985e-06 first col mean 1.0076150829263497e-06 all mean 3.2898387871682644e-05
rl training, epoch3, iter0, batch334/1133, batch loss:3.7206213164608926e-05, Training time:78931.988063097
batch reward last col mean 4.30381296609994e-05 first col mean 0.0003866869956254959 all mean 5.0827711675083265e-05
rl training, epoch3, iter0, batch335/1133, batch loss:8.8689943368081e-05, Training time:78961.51321911812
batch reward last col mean 1.5823803551029414e-05 first col mean 1.6028732261474943e-06 all mean 1.5200193047348876e-05
rl training, epoch3, iter0, batch336/1133, batch loss:9.05010529095307e-06, Training time:78991.50260043144
batch reward last col mean 7.819927532182191e-07 first col mean 1.308590617554728e-05 all mean 2.0087638404220343e-05
rl training, epoch3, iter0, batch337/1133, batch loss:6.252333696465939e-05, Training time:79021.14503526688
batch reward last col mean 7.598248430440435e-07 first col mean 1.1036382829843205e-06 all mean 1.0463108992553316e-06
rl training, epoch3, iter0, batch338/1133, batch loss:1.0470832421560772e-05, Training time:79050.44333577156
batch reward last col mean 2.079099795082584e-05 first col mean 4.541410362435272e-06 all mean 2.253501043014694e-05
rl training, epoch3, iter0, batch339/1133, batch loss:7.395707507384941e-05, Training time:79080.11832165718
batch reward last col mean 0.00046302369446493685 first col mean 7.891764653322753e-06 all mean 0.00040908128721639514
rl training, epoch3, iter0, batch340/1133, batch loss:0.00022036478912923485, Training time:79109.78441309929
batch reward last col mean 2.1512178136617877e-06 first col mean 2.4801474864943884e-06 all mean 2.6553088900982402e-06
rl training, epoch3, iter0, batch341/1133, batch loss:3.7645245356543455e-06, Training time:79139.19010257721
batch reward last col mean 4.4533095433507697e-07 first col mean 1.0288188150298083e-06 all mean 5.652252639265498e-07
rl training, epoch3, iter0, batch342/1133, batch loss:1.1523015928105451e-06, Training time:79169.44394874573
batch reward last col mean 3.7857088841519726e-07 first col mean 1.9206436263630167e-06 all mean 5.87167505727848e-07
rl training, epoch3, iter0, batch343/1133, batch loss:2.1060186554677784e-06, Training time:79198.54536414146
batch reward last col mean 5.115967738333893e-08 first col mean 8.113473199955479e-07 all mean 1.1699576418777724e-07
rl training, epoch3, iter0, batch344/1133, batch loss:8.487788818456465e-07, Training time:79228.11303019524
batch reward last col mean 1.0518265298742335e-06 first col mean 3.3584205993975047e-06 all mean 1.1283630101388553e-06
rl training, epoch3, iter0, batch345/1133, batch loss:8.540975500181958e-07, Training time:79258.14206266403
batch reward last col mean 8.717960326976026e-07 first col mean 1.481874392084137e-06 all mean 9.264015261578606e-07
rl training, epoch3, iter0, batch346/1133, batch loss:1.8078961829814943e-06, Training time:79288.02801203728
batch reward last col mean 9.758646228874568e-07 first col mean 2.1415576156869065e-06 all mean 9.069634074876376e-07
rl training, epoch3, iter0, batch347/1133, batch loss:2.3874015369074186e-06, Training time:79317.56612205505
batch reward last col mean 7.435812108269602e-07 first col mean 2.5294873466918943e-06 all mean 8.03010550498584e-07
rl training, epoch3, iter0, batch348/1133, batch loss:6.989610596974671e-07, Training time:79347.10550117493
batch reward last col mean 3.905422090610955e-06 first col mean 2.2974757030169712e-06 all mean 4.027512204629602e-06
rl training, epoch3, iter0, batch349/1133, batch loss:2.3151744699134724e-06, Training time:79376.948117733
batch reward last col mean 3.072777587931341e-07 first col mean 3.5059161973549635e-07 all mean 8.687746344548941e-07
rl training, epoch3, iter0, batch350/1133, batch loss:7.416146672767354e-06, Training time:79406.13319134712
batch reward last col mean 0.0036481895949691534 first col mean 1.3469058330883854e-06 all mean 0.0035663091111928225
rl training, epoch3, iter0, batch351/1133, batch loss:0.0016142724780365825, Training time:79436.1513133049
batch reward last col mean 1.496036503567666e-07 first col mean 2.757565653155325e-06 all mean 3.507101098421117e-07
rl training, epoch3, iter0, batch352/1133, batch loss:1.0887404187087668e-06, Training time:79465.51962304115
batch reward last col mean 8.724904319024063e-07 first col mean 0.00047599527169950306 all mean 8.220783456636127e-06
rl training, epoch3, iter0, batch353/1133, batch loss:6.271187885431573e-05, Training time:79495.75726437569
batch reward last col mean 6.921304702700581e-07 first col mean 1.2224612873978913e-05 all mean 1.0927154789897031e-06
rl training, epoch3, iter0, batch354/1133, batch loss:1.1218924555578269e-05, Training time:79526.07312822342
batch reward last col mean 8.386087756662164e-06 first col mean 9.277579010813497e-06 all mean 8.685680768394377e-06
rl training, epoch3, iter0, batch355/1133, batch loss:8.880637324182317e-06, Training time:79556.37125968933
batch reward last col mean 3.712690158863552e-05 first col mean 0.0002937596873380244 all mean 3.874421599903144e-05
rl training, epoch3, iter0, batch356/1133, batch loss:1.0987618225044571e-05, Training time:79586.1457362175
batch reward last col mean 0.00020447229326236993 first col mean 4.589277864397445e-07 all mean 0.00019571588200051337
rl training, epoch3, iter0, batch357/1133, batch loss:9.785679139895365e-05, Training time:79616.20539450645
batch reward last col mean 2.1953949271846795e-06 first col mean 2.9720285965595394e-06 all mean 2.352481942580198e-06
rl training, epoch3, iter0, batch358/1133, batch loss:2.1740797819802538e-06, Training time:79645.91370844841
batch reward last col mean 3.803706567850895e-05 first col mean 8.313181751873344e-06 all mean 4.2803596443263814e-05
rl training, epoch3, iter0, batch359/1133, batch loss:8.499713658238761e-06, Training time:79675.8966140747
batch reward last col mean 3.6478275433182716e-05 first col mean 5.0742237363010645e-05 all mean 3.626602847361937e-05
rl training, epoch3, iter0, batch360/1133, batch loss:2.9188149710535072e-05, Training time:79705.25793719292
batch reward last col mean 6.818483143433696e-06 first col mean 2.3861948648118414e-06 all mean 2.4458249754388817e-05
rl training, epoch3, iter0, batch361/1133, batch loss:0.000264031725237146, Training time:79734.5779261589
batch reward last col mean 4.363241714600008e-07 first col mean 8.531277853762731e-05 all mean 2.5203469249390764e-06
rl training, epoch3, iter0, batch362/1133, batch loss:4.155395436100662e-05, Training time:79764.35927939415
batch reward last col mean 9.794149491426651e-07 first col mean 3.5003079119633185e-06 all mean 3.15577949550061e-06
rl training, epoch3, iter0, batch363/1133, batch loss:1.4699136045237537e-05, Training time:79793.93423724174
batch reward last col mean 5.946801138634328e-06 first col mean 7.264030136866495e-05 all mean 6.5996491684927605e-06
rl training, epoch3, iter0, batch364/1133, batch loss:5.377981779020047e-06, Training time:79823.51180934906
batch reward last col mean 0.002808541292324662 first col mean 2.577233772171894e-06 all mean 0.002522112103179097
rl training, epoch3, iter0, batch365/1133, batch loss:0.003515094518661499, Training time:79853.35685443878
batch reward last col mean 4.824725010621478e-07 first col mean 0.00020570019842125475 all mean 2.721009423112264e-06
rl training, epoch3, iter0, batch366/1133, batch loss:1.3640686802318669e-06, Training time:79883.19370794296
batch reward last col mean 2.111832145601511e-05 first col mean 8.244517175626243e-07 all mean 2.3865766706876457e-05
rl training, epoch3, iter0, batch367/1133, batch loss:7.649632607353851e-05, Training time:79912.72111701965
batch reward last col mean 4.939308837492717e-07 first col mean 1.0460888688612613e-06 all mean 5.515226462193823e-07
rl training, epoch3, iter0, batch368/1133, batch loss:5.699123448721366e-07, Training time:79942.90000391006
batch reward last col mean 0.00021863078291062266 first col mean 3.2039472444012063e-06 all mean 0.0002080898266285658
rl training, epoch3, iter0, batch369/1133, batch loss:9.301074896939099e-05, Training time:79972.48358893394
batch reward last col mean 6.383933168763178e-07 first col mean 5.70276779399137e-06 all mean 1.3392809705692343e-06
rl training, epoch3, iter0, batch370/1133, batch loss:1.0916785413428443e-06, Training time:80002.62169623375
batch reward last col mean 3.885604655806674e-06 first col mean 9.576671118338709e-07 all mean 3.7226830045256065e-06
rl training, epoch3, iter0, batch371/1133, batch loss:1.0027039252236136e-06, Training time:80031.97788643837
batch reward last col mean 2.8181830202811398e-06 first col mean 7.498400373151526e-05 all mean 3.5803902846964775e-06
rl training, epoch3, iter0, batch372/1133, batch loss:2.1996286250214325e-06, Training time:80061.53284525871
batch reward last col mean 5.861802947038086e-06 first col mean 1.0171959274885012e-06 all mean 1.0408140042272862e-05
rl training, epoch3, iter0, batch373/1133, batch loss:1.99917903955793e-05, Training time:80090.85190033913
batch reward last col mean 1.1435543001425685e-06 first col mean 3.2900375117606018e-06 all mean 3.895627742167562e-06
rl training, epoch3, iter0, batch374/1133, batch loss:2.049355089184246e-06, Training time:80120.39466834068
batch reward last col mean 7.869826958994963e-07 first col mean 8.032836376514751e-06 all mean 1.021056050376501e-06
rl training, epoch3, iter0, batch375/1133, batch loss:2.6292862003174378e-06, Training time:80150.07499670982
batch reward last col mean 0.00024775805650278926 first col mean 0.0001283226883970201 all mean 0.0002363195817451924
rl training, epoch3, iter0, batch376/1133, batch loss:7.85255033406429e-05, Training time:80180.41646814346
batch reward last col mean 2.989643803630315e-07 first col mean 1.212872302858159e-05 all mean 4.647897071663465e-07
rl training, epoch3, iter0, batch377/1133, batch loss:7.206854775176907e-07, Training time:80210.09925079346
batch reward last col mean 1.0375104466220364e-05 first col mean 1.1964005352638196e-05 all mean 1.0024424227594864e-05
rl training, epoch3, iter0, batch378/1133, batch loss:6.264161584113026e-06, Training time:80239.6632091999
batch reward last col mean 3.3714202345436206e-06 first col mean 6.086504527047509e-07 all mean 3.6986375562264584e-06
rl training, epoch3, iter0, batch379/1133, batch loss:1.664072806306649e-05, Training time:80268.89363622665
batch reward last col mean 8.331826961693878e-08 first col mean 1.1255004892518627e-06 all mean 2.043204403889831e-05
rl training, epoch3, iter0, batch380/1133, batch loss:0.0005995299434289336, Training time:80298.66331672668
batch reward last col mean 1.399042389493843e-06 first col mean 2.103916813211981e-06 all mean 2.087893562929821e-06
rl training, epoch3, iter0, batch381/1133, batch loss:6.102314728195779e-06, Training time:80328.1193163395
batch reward last col mean 2.8276429020479554e-06 first col mean 2.1347148049244424e-06 all mean 3.202755351594533e-06
rl training, epoch3, iter0, batch382/1133, batch loss:3.131362518615788e-06, Training time:80358.10410499573
batch reward last col mean 2.8267261313885683e-06 first col mean 4.143391197430901e-05 all mean 3.2369921427743975e-06
rl training, epoch3, iter0, batch383/1133, batch loss:2.7978298930975143e-06, Training time:80387.58341622353
batch reward last col mean 7.134506631700788e-06 first col mean 3.2787802410894074e-06 all mean 5.985760253679473e-06
rl training, epoch3, iter0, batch384/1133, batch loss:4.10421353080892e-06, Training time:80417.45239949226
batch reward last col mean 1.8616523448145017e-05 first col mean 4.909174094791524e-05 all mean 1.879228511825204e-05
rl training, epoch3, iter0, batch385/1133, batch loss:5.2148210670566186e-05, Training time:80446.91263437271
batch reward last col mean 4.7166972194645496e-07 first col mean 4.70258564746473e-05 all mean 1.0091442845805432e-06
rl training, epoch3, iter0, batch386/1133, batch loss:1.7938282326213084e-06, Training time:80476.5523879528
batch reward last col mean 3.1497495456278557e-06 first col mean 4.58657814306207e-06 all mean 3.4395607144688256e-06
rl training, epoch3, iter0, batch387/1133, batch loss:2.3166287519416073e-06, Training time:80505.95656323433
batch reward last col mean 1.1298267963866238e-05 first col mean 1.0358355666539865e-06 all mean 1.161380987468874e-05
rl training, epoch3, iter0, batch388/1133, batch loss:3.8123351259855554e-05, Training time:80535.028683424
batch reward last col mean 6.267751473387762e-07 first col mean 7.206176064755709e-07 all mean 8.604772574472008e-07
rl training, epoch3, iter0, batch389/1133, batch loss:2.524325509511982e-06, Training time:80564.64345049858
batch reward last col mean 2.857799245248316e-06 first col mean 2.250783154522651e-06 all mean 3.5443588330963394e-06
rl training, epoch3, iter0, batch390/1133, batch loss:8.792195330897812e-06, Training time:80594.40293478966
batch reward last col mean 1.547176179883536e-05 first col mean 3.098642991972156e-06 all mean 1.5250214346451685e-05
rl training, epoch3, iter0, batch391/1133, batch loss:6.18462945567444e-06, Training time:80624.1756951809
batch reward last col mean 3.2735039212639094e-07 first col mean 2.57013698501396e-06 all mean 9.137191909758258e-07
rl training, epoch3, iter0, batch392/1133, batch loss:4.129062290303409e-06, Training time:80653.64294219017
batch reward last col mean 1.6471244634885807e-07 first col mean 2.966152976568992e-07 all mean 5.79427478442085e-07
rl training, epoch3, iter0, batch393/1133, batch loss:1.1774282029364258e-06, Training time:80683.46306347847
batch reward last col mean 1.7430087950742745e-07 first col mean 5.49079004485975e-06 all mean 5.344032615539618e-06
rl training, epoch3, iter0, batch394/1133, batch loss:0.00011553294461918995, Training time:80712.63873291016
batch reward last col mean 5.702586349798366e-07 first col mean 1.2513831961769029e-06 all mean 5.954210564595996e-07
rl training, epoch3, iter0, batch395/1133, batch loss:3.7876679925830103e-07, Training time:80742.08188343048
batch reward last col mean 9.663479431765154e-05 first col mean 1.2978338190805516e-06 all mean 9.170090197585523e-05
rl training, epoch3, iter0, batch396/1133, batch loss:1.891983629320748e-05, Training time:80771.48704791069
batch reward last col mean 1.0336144669054192e-06 first col mean 8.58331986819394e-06 all mean 2.3487855287385173e-06
rl training, epoch3, iter0, batch397/1133, batch loss:5.2234936447348446e-06, Training time:80800.82424974442
batch reward last col mean 1.7248513017875666e-07 first col mean 1.1667144690363784e-06 all mean 2.87840492774194e-07
rl training, epoch3, iter0, batch398/1133, batch loss:7.657655487491866e-07, Training time:80830.44131684303
batch reward last col mean 4.378788617032114e-06 first col mean 2.5806688427110203e-05 all mean 4.667945177061483e-06
rl training, epoch3, iter0, batch399/1133, batch loss:1.9064892740061623e-06, Training time:80859.59685254097
batch reward last col mean 8.33303090530535e-07 first col mean 1.6111805507534882e-06 all mean 9.434638172933774e-07
rl training, epoch3, iter0, batch400/1133, batch loss:1.0425396794744302e-06, Training time:80889.51010203362
batch reward last col mean 1.893320700219192e-06 first col mean 1.1908490478163003e-06 all mean 1.3319162462721579e-05
rl training, epoch3, iter0, batch401/1133, batch loss:4.986199928680435e-05, Training time:80919.18868422508
batch reward last col mean 3.858431591652334e-05 first col mean 4.793529910784855e-07 all mean 3.812633076449856e-05
rl training, epoch3, iter0, batch402/1133, batch loss:2.1067589841550216e-05, Training time:80948.82077884674
batch reward last col mean 1.584779170116235e-06 first col mean 3.615825789893279e-07 all mean 1.5719699604233028e-06
rl training, epoch3, iter0, batch403/1133, batch loss:1.0032646287072566e-06, Training time:80978.98928141594
batch reward last col mean 2.0330985535110813e-06 first col mean 1.3552036080000107e-06 all mean 2.108357648467063e-06
rl training, epoch3, iter0, batch404/1133, batch loss:2.0768022750417003e-06, Training time:81008.471804142
batch reward last col mean 2.2932857973501086e-05 first col mean 7.117788300092798e-06 all mean 2.3065013010636903e-05
rl training, epoch3, iter0, batch405/1133, batch loss:1.5123093362490181e-05, Training time:81038.16534543037
batch reward last col mean 0.0012163632782176137 first col mean 1.0165719686483499e-05 all mean 0.001204369473271072
rl training, epoch3, iter0, batch406/1133, batch loss:0.0006652798037976027, Training time:81067.70936608315
batch reward last col mean 8.938329301599879e-06 first col mean 6.6817701735999435e-06 all mean 4.882337816525251e-05
rl training, epoch3, iter0, batch407/1133, batch loss:0.0017322272760793567, Training time:81097.29909801483
batch reward last col mean 1.2359012089291355e-06 first col mean 0.00041924582910723984 all mean 5.766137746832101e-06
rl training, epoch3, iter0, batch408/1133, batch loss:1.5187784811132587e-05, Training time:81126.87977147102
batch reward last col mean 0.0011176406405866146 first col mean 0.0011111735366284847 all mean 0.001156322075985372
rl training, epoch3, iter0, batch409/1133, batch loss:0.0004375958815217018, Training time:81156.40875911713
batch reward last col mean 3.107712109340355e-05 first col mean 5.943922133155866e-06 all mean 3.021186239493545e-05
rl training, epoch3, iter0, batch410/1133, batch loss:1.406492719979724e-05, Training time:81185.66785264015
batch reward last col mean 2.986241725011496e-06 first col mean 2.7258927730144933e-05 all mean 3.258627202740172e-06
rl training, epoch3, iter0, batch411/1133, batch loss:5.2710811360157095e-06, Training time:81214.344881773
batch reward last col mean 5.729825716116466e-07 first col mean 0.0003938625450246036 all mean 6.34397474641446e-06
rl training, epoch3, iter0, batch412/1133, batch loss:1.370039171888493e-05, Training time:81244.30613613129
batch reward last col mean 1.97856707018218e-06 first col mean 4.311079919716576e-06 all mean 3.249913561376161e-06
rl training, epoch3, iter0, batch413/1133, batch loss:7.75537955632899e-06, Training time:81273.66497945786
batch reward last col mean 9.682175004854798e-06 first col mean 6.2647923186887056e-06 all mean 1.118550881074043e-05
rl training, epoch3, iter0, batch414/1133, batch loss:7.043835921649588e-06, Training time:81302.42251706123
batch reward last col mean 7.325734259211458e-06 first col mean 1.5062996681081131e-05 all mean 7.581251338706352e-06
rl training, epoch3, iter0, batch415/1133, batch loss:5.3086350817466155e-06, Training time:81332.24055838585
batch reward last col mean 3.067114562327333e-07 first col mean 0.00012236664770171046 all mean 1.5957982668624027e-06
rl training, epoch3, iter0, batch416/1133, batch loss:2.511499133106554e-06, Training time:81362.2014966011
batch reward last col mean 1.0078343848363147e-06 first col mean 3.851056362691452e-07 all mean 1.0738647233665688e-06
rl training, epoch3, iter0, batch417/1133, batch loss:1.1152773140565841e-06, Training time:81392.09615707397
batch reward last col mean 1.4469053439825075e-06 first col mean 1.4289859109339886e-06 all mean 1.5681043805670924e-06
rl training, epoch3, iter0, batch418/1133, batch loss:1.7512543308839668e-06, Training time:81421.75026345253
batch reward last col mean 2.752888758550398e-05 first col mean 6.139480774436379e-06 all mean 2.7000824047718197e-05
rl training, epoch3, iter0, batch419/1133, batch loss:5.274007435218664e-06, Training time:81451.31402230263
batch reward last col mean 7.2600018938828725e-06 first col mean 4.008674750366481e-06 all mean 6.7227565523353405e-06
rl training, epoch3, iter0, batch420/1133, batch loss:7.541009836131707e-06, Training time:81481.05873131752
batch reward last col mean 1.2175227311672643e-05 first col mean 1.4410659332497744e-06 all mean 1.312597578362329e-05
rl training, epoch3, iter0, batch421/1133, batch loss:3.221221049898304e-05, Training time:81510.87727284431
batch reward last col mean 2.3160209821071476e-06 first col mean 1.7155142586489092e-06 all mean 2.3521240564150503e-06
rl training, epoch3, iter0, batch422/1133, batch loss:2.390197550994344e-06, Training time:81540.23154902458
batch reward last col mean 3.0785586204729043e-06 first col mean 4.456544411368668e-05 all mean 3.91845469494001e-06
rl training, epoch3, iter0, batch423/1133, batch loss:8.983556654129643e-06, Training time:81570.06213831902
batch reward last col mean 1.4617558008467313e-06 first col mean 2.3642153337277705e-06 all mean 2.22326343646273e-06
rl training, epoch3, iter0, batch424/1133, batch loss:3.3512235404487e-06, Training time:81599.70941090584
batch reward last col mean 3.8103914334897127e-07 first col mean 7.383482056866342e-07 all mean 4.3225213630648796e-07
rl training, epoch3, iter0, batch425/1133, batch loss:8.113887020044785e-07, Training time:81629.14743685722
batch reward last col mean 2.44594133391729e-07 first col mean 4.608331778399588e-07 all mean 2.744704090673622e-07
rl training, epoch3, iter0, batch426/1133, batch loss:3.674827553368232e-07, Training time:81658.64695167542
batch reward last col mean 2.084421566905803e-06 first col mean 4.020465951271035e-07 all mean 2.0636969111365033e-06
rl training, epoch3, iter0, batch427/1133, batch loss:2.3909201445349026e-06, Training time:81687.61442279816
batch reward last col mean 5.861920726601966e-07 first col mean 1.6495507679792354e-06 all mean 1.9188782971468754e-05
rl training, epoch3, iter0, batch428/1133, batch loss:2.7693355150404386e-05, Training time:81716.89739894867
batch reward last col mean 2.636678573253448e-06 first col mean 9.227280770573998e-07 all mean 3.491460120130796e-06
rl training, epoch3, iter0, batch429/1133, batch loss:2.607433452794794e-05, Training time:81746.52738142014
batch reward last col mean 5.757713665843767e-07 first col mean 1.887250959953235e-06 all mean 1.3478781966114184e-06
rl training, epoch3, iter0, batch430/1133, batch loss:1.0799358278745785e-05, Training time:81776.32331347466
batch reward last col mean 3.31093389149828e-07 first col mean 2.4279830540763214e-05 all mean 6.462784767791163e-06
rl training, epoch3, iter0, batch431/1133, batch loss:4.6276520151877776e-05, Training time:81806.49695420265
batch reward last col mean 2.2450374217442004e-06 first col mean 2.7446908461570274e-06 all mean 2.41671955336642e-06
rl training, epoch3, iter0, batch432/1133, batch loss:2.6351767701271456e-06, Training time:81836.0262799263
batch reward last col mean 2.3312250618801045e-07 first col mean 1.001599116534635e-06 all mean 1.345130931440508e-05
rl training, epoch3, iter0, batch433/1133, batch loss:0.0003573297581169754, Training time:81865.85735821724
batch reward last col mean 1.1069715810663183e-06 first col mean 5.860654255229747e-07 all mean 1.2820649999412126e-06
rl training, epoch3, iter0, batch434/1133, batch loss:4.6956488404248375e-06, Training time:81895.34498643875
batch reward last col mean 8.812785381451249e-07 first col mean 1.4636082141805673e-06 all mean 1.388580471939349e-06
rl training, epoch3, iter0, batch435/1133, batch loss:3.5918421872338513e-06, Training time:81924.83000540733
batch reward last col mean 3.049314000236336e-05 first col mean 4.37992503066198e-06 all mean 2.993308771692682e-05
rl training, epoch3, iter0, batch436/1133, batch loss:1.3431834304356016e-05, Training time:81954.96658849716
batch reward last col mean 6.346129453049798e-07 first col mean 4.806271363122505e-07 all mean 1.101112275136984e-06
rl training, epoch3, iter0, batch437/1133, batch loss:1.5991296095307916e-05, Training time:81984.57807993889
batch reward last col mean 6.990382530602801e-07 first col mean 1.4878859246891807e-06 all mean 8.365686881006695e-06
rl training, epoch3, iter0, batch438/1133, batch loss:0.00036299272323958576, Training time:82013.74451875687
batch reward last col mean 4.589597324411443e-07 first col mean 7.581146519441972e-07 all mean 7.376822850346798e-07
rl training, epoch3, iter0, batch439/1133, batch loss:1.7453364762332058e-06, Training time:82043.10987758636
batch reward last col mean 5.035431513533695e-06 first col mean 1.698560663498938e-05 all mean 5.38071753908298e-06
rl training, epoch3, iter0, batch440/1133, batch loss:6.735685019521043e-06, Training time:82073.37097597122
batch reward last col mean 1.831245026551187e-05 first col mean 3.219650807295693e-06 all mean 1.749591319821775e-05
rl training, epoch3, iter0, batch441/1133, batch loss:8.762539437157102e-06, Training time:82103.17321228981
batch reward last col mean 5.080850769445533e-06 first col mean 5.870668928764644e-07 all mean 5.3576841310132295e-06
rl training, epoch3, iter0, batch442/1133, batch loss:3.2598525194771355e-06, Training time:82132.54536795616
batch reward last col mean 2.269741344207432e-06 first col mean 1.2874676258434192e-06 all mean 2.1159949028515257e-06
rl training, epoch3, iter0, batch443/1133, batch loss:7.974097115948098e-07, Training time:82162.13714814186
batch reward last col mean 8.078362725427723e-07 first col mean 5.430952569440706e-06 all mean 1.0707308319979347e-06
rl training, epoch3, iter0, batch444/1133, batch loss:1.6930168840190163e-06, Training time:82191.23385548592
batch reward last col mean 9.520808816887438e-06 first col mean 2.3675759166508215e-06 all mean 9.216626494890079e-06
rl training, epoch3, iter0, batch445/1133, batch loss:8.318151230923831e-06, Training time:82220.50434088707
batch reward last col mean 5.155654434929602e-06 first col mean 5.441468965727836e-05 all mean 6.81806477587088e-06
rl training, epoch3, iter0, batch446/1133, batch loss:2.8609856599359773e-05, Training time:82249.90666460991
batch reward last col mean 9.411343853571452e-06 first col mean 1.0370811196480645e-06 all mean 8.783661542111076e-06
rl training, epoch3, iter0, batch447/1133, batch loss:1.3496182873495854e-06, Training time:82279.35730051994
batch reward last col mean 1.674570853538171e-06 first col mean 7.031152335912338e-07 all mean 2.945311280200258e-06
rl training, epoch3, iter0, batch448/1133, batch loss:3.6196104247210314e-06, Training time:82309.14377260208
batch reward last col mean 1.052869379236654e-06 first col mean 1.6086464711406734e-06 all mean 1.072762916010106e-05
rl training, epoch3, iter0, batch449/1133, batch loss:0.0001087325144908391, Training time:82338.70100975037
batch reward last col mean 1.984397613341571e-06 first col mean 3.4245846336489194e-07 all mean 2.5272472612414276e-06
rl training, epoch3, iter0, batch450/1133, batch loss:1.9184587927156826e-06, Training time:82368.3950240612
batch reward last col mean 3.887785624101525e-06 first col mean 2.7893534934264608e-05 all mean 4.980211997462902e-06
rl training, epoch3, iter0, batch451/1133, batch loss:9.41366670303978e-06, Training time:82397.66976928711
batch reward last col mean 1.0555282869972871e-07 first col mean 3.229727008147165e-05 all mean 5.131303169036983e-07
rl training, epoch3, iter0, batch452/1133, batch loss:3.774978495130199e-06, Training time:82427.34725737572
batch reward last col mean 1.5201775340756285e-06 first col mean 5.625896847050171e-06 all mean 3.858869604300708e-06
rl training, epoch3, iter0, batch453/1133, batch loss:1.7139705960289575e-05, Training time:82456.5159676075
batch reward last col mean 5.76616321268375e-06 first col mean 5.497708480106667e-05 all mean 6.883242349431384e-06
rl training, epoch3, iter0, batch454/1133, batch loss:1.6188201698241755e-05, Training time:82485.98423290253
batch reward last col mean 1.2747915207000915e-05 first col mean 2.2072458705224562e-06 all mean 1.5320545571739785e-05
rl training, epoch3, iter0, batch455/1133, batch loss:9.968305676011369e-06, Training time:82514.96354699135
batch reward last col mean 3.7603995224344544e-06 first col mean 2.202021505581797e-06 all mean 6.862568625365384e-06
rl training, epoch3, iter0, batch456/1133, batch loss:2.600338848424144e-05, Training time:82544.21556711197
batch reward last col mean 0.0001075604886864312 first col mean 2.8119079615862574e-06 all mean 0.00011678841838147491
rl training, epoch3, iter0, batch457/1133, batch loss:0.00038479393697343767, Training time:82574.32796049118
batch reward last col mean 7.367002581304405e-07 first col mean 0.00027231077547185123 all mean 4.379498477646848e-06
rl training, epoch3, iter0, batch458/1133, batch loss:4.774182161781937e-05, Training time:82603.94559526443
batch reward last col mean 9.898902817440103e-07 first col mean 5.847564921168669e-07 all mean 1.2373161553114187e-06
rl training, epoch3, iter0, batch459/1133, batch loss:4.5817455429641996e-06, Training time:82633.60821723938
batch reward last col mean 4.2373383735139214e-07 first col mean 1.2221019005664857e-06 all mean 4.3591544454102404e-06
rl training, epoch3, iter0, batch460/1133, batch loss:0.00020736828446388245, Training time:82663.22471213341
batch reward last col mean 2.0685370145656634e-06 first col mean 1.134610556619009e-06 all mean 5.1509850891307e-06
rl training, epoch3, iter0, batch461/1133, batch loss:7.583321803394938e-06, Training time:82693.06158661842
batch reward last col mean 2.5452973204664886e-06 first col mean 7.608326768604456e-07 all mean 2.4395724267378682e-06
rl training, epoch3, iter0, batch462/1133, batch loss:1.5252973071255838e-06, Training time:82723.01791143417
batch reward last col mean 7.01495139310282e-07 first col mean 4.388192564874771e-07 all mean 3.0835840334475506e-06
rl training, epoch3, iter0, batch463/1133, batch loss:5.092466381029226e-06, Training time:82752.91637587547
batch reward last col mean 1.0563960586296162e-06 first col mean 0.00016213183698710054 all mean 2.145183680113405e-05
rl training, epoch3, iter0, batch464/1133, batch loss:0.00022072793217375875, Training time:82781.99683141708
batch reward last col mean 3.037652641069144e-05 first col mean 1.4873149893901427e-06 all mean 2.853928890544921e-05
rl training, epoch3, iter0, batch465/1133, batch loss:1.1721990631485824e-05, Training time:82811.40123224258
batch reward last col mean 1.3020342066738522e-06 first col mean 7.227071364468429e-06 all mean 1.743863322190009e-06
rl training, epoch3, iter0, batch466/1133, batch loss:3.7783331663376885e-06, Training time:82841.0305724144
batch reward last col mean 1.8638235133039416e-06 first col mean 7.83870473242132e-06 all mean 1.948677208929439e-06
rl training, epoch3, iter0, batch467/1133, batch loss:1.7966785890166648e-06, Training time:82870.95518112183
batch reward last col mean 6.070405333957751e-07 first col mean 5.558885050049867e-07 all mean 6.799079415031883e-07
rl training, epoch3, iter0, batch468/1133, batch loss:1.175879560832982e-06, Training time:82900.34228920937
batch reward last col mean 7.671486628169077e-07 first col mean 2.328531991224736e-05 all mean 1.1871601373059093e-06
rl training, epoch3, iter0, batch469/1133, batch loss:2.855375441868091e-06, Training time:82929.59066534042
batch reward last col mean 4.391868060338311e-07 first col mean 1.2719875485345256e-05 all mean 1.5027085282781627e-06
rl training, epoch3, iter0, batch470/1133, batch loss:4.88312252855394e-06, Training time:82958.97533869743
batch reward last col mean 5.38161020813277e-06 first col mean 1.26220711536007e-05 all mean 5.452658569993218e-06
rl training, epoch3, iter0, batch471/1133, batch loss:2.947008397313766e-06, Training time:82988.42079544067
batch reward last col mean 2.7960515581071377e-05 first col mean 2.736153419391485e-06 all mean 2.788671372400131e-05
rl training, epoch3, iter0, batch472/1133, batch loss:1.6038280591601506e-05, Training time:83017.50086283684
batch reward last col mean 8.315391255564464e-07 first col mean 8.303245522256475e-06 all mean 1.060575868905289e-06
rl training, epoch3, iter0, batch473/1133, batch loss:1.0049947150037042e-06, Training time:83047.08171367645
batch reward last col mean 2.3142019927036017e-06 first col mean 6.98412477504462e-05 all mean 1.9354454707354307e-05
rl training, epoch3, iter0, batch474/1133, batch loss:0.0002401686942903325, Training time:83076.87712550163
batch reward last col mean 0.00018420211563352495 first col mean 1.106765466829529e-05 all mean 0.00016773538663983345
rl training, epoch3, iter0, batch475/1133, batch loss:0.00013537087943404913, Training time:83106.37465548515
batch reward last col mean 2.17825095205626e-06 first col mean 4.624203597813903e-07 all mean 2.0514992229436757e-06
rl training, epoch3, iter0, batch476/1133, batch loss:1.568858806422213e-06, Training time:83135.73166847229
batch reward last col mean 2.351190232730005e-06 first col mean 2.749099849097547e-06 all mean 6.134443083283259e-06
rl training, epoch3, iter0, batch477/1133, batch loss:4.507761696004309e-05, Training time:83165.37248039246
batch reward last col mean 1.0386618214397458e-06 first col mean 1.9046306078962516e-06 all mean 1.208100002259016e-06
rl training, epoch3, iter0, batch478/1133, batch loss:1.0004268915508874e-06, Training time:83195.02234387398
batch reward last col mean 1.0036081221187487e-05 first col mean 7.191683835117146e-06 all mean 1.101619636756368e-05
rl training, epoch3, iter0, batch479/1133, batch loss:2.092343675030861e-05, Training time:83224.68486022949
batch reward last col mean 2.276536861245404e-06 first col mean 1.2634394579436048e-06 all mean 2.8971701340196887e-06
rl training, epoch3, iter0, batch480/1133, batch loss:1.0221070624538697e-05, Training time:83254.10773086548
batch reward last col mean 5.579773301178648e-07 first col mean 3.579590952540457e-07 all mean 7.06329558397556e-07
rl training, epoch3, iter0, batch481/1133, batch loss:3.2933160127868177e-06, Training time:83284.24456191063
batch reward last col mean 9.14092765924579e-07 first col mean 1.0961300176859368e-05 all mean 1.231700821335835e-06
rl training, epoch3, iter0, batch482/1133, batch loss:1.1443492439866532e-05, Training time:83314.07793855667
batch reward last col mean 8.92450498213293e-06 first col mean 4.073116724612191e-05 all mean 9.59479348239256e-06
rl training, epoch3, iter0, batch483/1133, batch loss:2.016122562054079e-05, Training time:83343.67057299614
batch reward last col mean 3.208067482773913e-06 first col mean 1.908693093355396e-06 all mean 3.704035634655156e-06
rl training, epoch3, iter0, batch484/1133, batch loss:9.160970876109786e-06, Training time:83373.47096347809
batch reward last col mean 1.4700708561576903e-06 first col mean 8.355205864063464e-06 all mean 1.625664708626573e-06
rl training, epoch3, iter0, batch485/1133, batch loss:1.5847814438529895e-06, Training time:83403.32386136055
batch reward last col mean 4.7251283831428736e-05 first col mean 4.804349009646103e-05 all mean 4.652309144148603e-05
rl training, epoch3, iter0, batch486/1133, batch loss:7.348167855525389e-06, Training time:83432.53245520592
batch reward last col mean 5.23981952937902e-07 first col mean 2.169144863728434e-05 all mean 1.1655786238407018e-06
rl training, epoch3, iter0, batch487/1133, batch loss:5.32120566276717e-06, Training time:83461.62879776955
batch reward last col mean 6.044122073944891e-06 first col mean 3.1832198601478012e-06 all mean 6.0347351791278925e-06
rl training, epoch3, iter0, batch488/1133, batch loss:7.189079042291269e-06, Training time:83491.43224811554
batch reward last col mean 8.318539812535164e-07 first col mean 2.49712320510298e-06 all mean 1.3809882375426241e-06
rl training, epoch3, iter0, batch489/1133, batch loss:1.239032280864194e-05, Training time:83521.30924582481
batch reward last col mean 7.850858310121112e-07 first col mean 5.447067223940394e-07 all mean 6.731133908033371e-07
rl training, epoch3, iter0, batch490/1133, batch loss:7.816254310455406e-07, Training time:83550.7974460125
batch reward last col mean 2.930158188974019e-06 first col mean 9.18196474231081e-06 all mean 3.351547775309882e-06
rl training, epoch3, iter0, batch491/1133, batch loss:2.972490165120689e-06, Training time:83580.81630396843
batch reward last col mean 5.911758762522368e-07 first col mean 0.001003510202281177 all mean 1.1400132279959507e-05
rl training, epoch3, iter0, batch492/1133, batch loss:8.599770080763847e-05, Training time:83610.3653512001
batch reward last col mean 9.503027627033589e-07 first col mean 2.7655039502860745e-06 all mean 1.543620442134852e-06
rl training, epoch3, iter0, batch493/1133, batch loss:1.5490397345274687e-05, Training time:83640.2082054615
batch reward last col mean 4.761100740324764e-07 first col mean 2.185222001571674e-06 all mean 7.126793661882402e-07
rl training, epoch3, iter0, batch494/1133, batch loss:1.7963270693144295e-06, Training time:83669.86153554916
batch reward last col mean 3.1153276722761802e-06 first col mean 6.908779141667765e-06 all mean 2.877616680052597e-05
rl training, epoch3, iter0, batch495/1133, batch loss:2.8157486667623743e-05, Training time:83699.36855077744
batch reward last col mean 3.4471822800696827e-06 first col mean 2.225674961664481e-06 all mean 3.4605318433023058e-06
rl training, epoch3, iter0, batch496/1133, batch loss:9.727115184432478e-07, Training time:83728.61969900131
batch reward last col mean 4.896954578725854e-06 first col mean 8.71649717737455e-06 all mean 9.066488928510807e-06
rl training, epoch3, iter0, batch497/1133, batch loss:5.043013516115025e-06, Training time:83758.49932217598
batch reward last col mean 3.666978329874837e-07 first col mean 3.5309708437125664e-06 all mean 1.138192033067753e-06
rl training, epoch3, iter0, batch498/1133, batch loss:1.4001185263623483e-05, Training time:83787.83489918709
batch reward last col mean 2.9664549856533995e-06 first col mean 0.0008074447978287935 all mean 6.45829422865063e-05
rl training, epoch3, iter0, batch499/1133, batch loss:0.0014372706646099687, Training time:83817.20629453659
batch reward last col mean 1.9007595255970955e-05 first col mean 2.420667624392081e-05 all mean 1.9032331692869775e-05
rl training, epoch3, iter0, batch500/1133, batch loss:4.283531234250404e-05, Training time:83847.55497860909
batch reward last col mean 8.134462063935644e-07 first col mean 0.00012857737601734698 all mean 7.67951860325411e-06
rl training, epoch3, iter0, batch501/1133, batch loss:9.779826359590515e-05, Training time:83877.20832705498
batch reward last col mean 4.0374629861616995e-06 first col mean 1.6015852452255785e-05 all mean 4.135854396736249e-06
rl training, epoch3, iter0, batch502/1133, batch loss:2.315251094842097e-06, Training time:83906.58714461327
batch reward last col mean 1.5798543699929724e-06 first col mean 1.5467665434698574e-05 all mean 2.1552273210545536e-06
rl training, epoch3, iter0, batch503/1133, batch loss:6.718623808410484e-06, Training time:83936.20771932602
batch reward last col mean 2.477508189713262e-07 first col mean 1.6069066077761818e-06 all mean 4.6515182816619927e-07
rl training, epoch3, iter0, batch504/1133, batch loss:8.260523713943257e-07, Training time:83966.07019209862
batch reward last col mean 6.704362021991983e-05 first col mean 0.001464212778955698 all mean 8.039231033762917e-05
rl training, epoch3, iter0, batch505/1133, batch loss:1.961798989214003e-05, Training time:83995.71757292747
batch reward last col mean 6.735062356710841e-07 first col mean 0.00015984976198524237 all mean 3.3086921575886663e-06
rl training, epoch3, iter0, batch506/1133, batch loss:1.98439975065412e-05, Training time:84025.44630861282
batch reward last col mean 1.298956959772113e-07 first col mean 2.389680958003737e-05 all mean 3.986342846928892e-07
rl training, epoch3, iter0, batch507/1133, batch loss:8.615752449259162e-07, Training time:84055.17243123055
batch reward last col mean 9.571199370839167e-07 first col mean 2.1278254280332476e-05 all mean 1.8567292272564373e-06
rl training, epoch3, iter0, batch508/1133, batch loss:9.124558346229605e-06, Training time:84084.76451253891
batch reward last col mean 0.0016758914571255445 first col mean 3.424341048230417e-05 all mean 0.0014790178975090384
rl training, epoch3, iter0, batch509/1133, batch loss:0.0008946362650021911, Training time:84114.36240649223
batch reward last col mean 7.124283001758158e-06 first col mean 0.00017842256056610495 all mean 8.80934385349974e-06
rl training, epoch3, iter0, batch510/1133, batch loss:5.336451067705639e-05, Training time:84143.86088967323
batch reward last col mean 3.022447856437793e-07 first col mean 1.56014925778436e-06 all mean 3.7254261542329914e-07
rl training, epoch3, iter0, batch511/1133, batch loss:5.94641733187018e-07, Training time:84173.43042206764
batch reward last col mean 2.0797269826289266e-06 first col mean 2.231269490948762e-06 all mean 2.111748472088948e-06
rl training, epoch3, iter0, batch512/1133, batch loss:1.079779622159549e-06, Training time:84203.4284350872
batch reward last col mean 5.500327824847773e-05 first col mean 1.581363358127419e-05 all mean 5.2679293730761856e-05
rl training, epoch3, iter0, batch513/1133, batch loss:3.826895044767298e-05, Training time:84233.19053864479
batch reward last col mean 1.6189387679332867e-05 first col mean 1.1869969966937788e-05 all mean 1.5854900993872434e-05
rl training, epoch3, iter0, batch514/1133, batch loss:6.4010055211838335e-06, Training time:84263.0622844696
batch reward last col mean 1.031918145599775e-06 first col mean 4.1224557207897305e-06 all mean 1.3303646255735657e-06
rl training, epoch3, iter0, batch515/1133, batch loss:2.3960033104231115e-06, Training time:84292.55414891243
batch reward last col mean 2.4671126652719977e-07 first col mean 7.466021543223178e-07 all mean 3.599882916205388e-07
rl training, epoch3, iter0, batch516/1133, batch loss:9.911050256050657e-07, Training time:84321.851801157
batch reward last col mean 4.420674486027565e-06 first col mean 9.53791823121719e-06 all mean 4.934949174639769e-06
rl training, epoch3, iter0, batch517/1133, batch loss:1.9200822862330824e-05, Training time:84351.47486305237
batch reward last col mean 9.427749887436221e-07 first col mean 9.786424470803468e-07 all mean 1.0564147032710025e-06
rl training, epoch3, iter0, batch518/1133, batch loss:2.5825679585977923e-06, Training time:84381.61225891113
batch reward last col mean 2.0510460672085173e-05 first col mean 4.0268292650580406e-05 all mean 2.0540977857308462e-05
rl training, epoch3, iter0, batch519/1133, batch loss:6.781021056667669e-06, Training time:84411.8028831482
batch reward last col mean 4.7364428610308096e-05 first col mean 3.85150951842661e-06 all mean 4.744094258057885e-05
rl training, epoch3, iter0, batch520/1133, batch loss:3.603774530347437e-05, Training time:84441.6836013794
batch reward last col mean 4.400791112857405e-06 first col mean 4.29635383625282e-06 all mean 4.606164566212101e-06
rl training, epoch3, iter0, batch521/1133, batch loss:1.1389048268029e-05, Training time:84471.01669073105
batch reward last col mean 2.633159965625964e-05 first col mean 1.5585839037157712e-06 all mean 2.5957733669201843e-05
rl training, epoch3, iter0, batch522/1133, batch loss:1.7659642253420316e-05, Training time:84501.07588481903
batch reward last col mean 4.132743072204903e-07 first col mean 1.74731103470549e-05 all mean 1.7343102172162617e-06
rl training, epoch3, iter0, batch523/1133, batch loss:2.117652002198156e-06, Training time:84530.7256257534
batch reward last col mean 2.5566595240889e-07 first col mean 4.7141992354227114e-07 all mean 2.8200196311445325e-07
rl training, epoch3, iter0, batch524/1133, batch loss:4.2331666350037267e-07, Training time:84560.06666946411
batch reward last col mean 5.387845703808125e-06 first col mean 4.278067535778973e-06 all mean 5.074320597486803e-06
rl training, epoch3, iter0, batch525/1133, batch loss:2.1254954845062457e-06, Training time:84589.61837172508
batch reward last col mean 1.2972735703442595e-06 first col mean 1.6289423001580872e-06 all mean 1.6033702650020132e-06
rl training, epoch3, iter0, batch526/1133, batch loss:3.3938747492356924e-06, Training time:84619.15949177742
batch reward last col mean 7.35846379029681e-06 first col mean 0.000604651402682066 all mean 1.2803321624232922e-05
rl training, epoch3, iter0, batch527/1133, batch loss:4.4399308535503224e-05, Training time:84648.96707892418
batch reward last col mean 8.75457430993265e-07 first col mean 2.84715169982519e-05 all mean 2.25571511691669e-06
rl training, epoch3, iter0, batch528/1133, batch loss:1.0057186045742128e-05, Training time:84678.72510910034
batch reward last col mean 0.0009685063851065934 first col mean 1.0055262009700527e-06 all mean 0.0009422114235349
rl training, epoch3, iter0, batch529/1133, batch loss:0.0005648499936796725, Training time:84708.582300663
batch reward last col mean 4.1442274323344463e-07 first col mean 6.363569582390483e-07 all mean 8.284209798148368e-07
rl training, epoch3, iter0, batch530/1133, batch loss:8.267127668659668e-06, Training time:84738.04768538475
batch reward last col mean 8.090733172139153e-05 first col mean 6.5165386331500486e-06 all mean 9.456425323151052e-05
rl training, epoch3, iter0, batch531/1133, batch loss:6.950659007998183e-05, Training time:84767.59009623528
batch reward last col mean 9.962557214748813e-07 first col mean 6.726640549459262e-06 all mean 1.307726279264898e-06
rl training, epoch3, iter0, batch532/1133, batch loss:3.363293217262253e-06, Training time:84797.49477863312
batch reward last col mean 1.1650307669697213e-06 first col mean 3.943082629120909e-05 all mean 1.8223956885776715e-06
rl training, epoch3, iter0, batch533/1133, batch loss:3.5631266655400395e-05, Training time:84827.66117548943
batch reward last col mean 2.0558336188969406e-07 first col mean 1.2428027957867016e-06 all mean 5.266261382530502e-07
rl training, epoch3, iter0, batch534/1133, batch loss:1.5560816564175184e-06, Training time:84857.3642206192
batch reward last col mean 0.00010492463479749858 first col mean 4.2871568439295515e-05 all mean 0.00010862123599508777
rl training, epoch3, iter0, batch535/1133, batch loss:0.0001467116380808875, Training time:84887.45052862167
batch reward last col mean 7.334891415666789e-05 first col mean 7.384094351436943e-05 all mean 7.315210677916184e-05
rl training, epoch3, iter0, batch536/1133, batch loss:1.9602366592152975e-05, Training time:84917.42428469658
batch reward last col mean 7.633528002770618e-05 first col mean 0.00017967996245715767 all mean 8.431889727944508e-05
rl training, epoch3, iter0, batch537/1133, batch loss:8.563131996197626e-05, Training time:84946.59026169777
batch reward last col mean 4.633205890058889e-07 first col mean 2.5176614144584164e-06 all mean 9.367616939925938e-07
rl training, epoch3, iter0, batch538/1133, batch loss:1.5114342204469722e-05, Training time:84975.88933992386
batch reward last col mean 6.898189326420834e-07 first col mean 2.9977031772432383e-06 all mean 8.40218604025722e-07
rl training, epoch3, iter0, batch539/1133, batch loss:1.3355479495658074e-06, Training time:85005.50276565552
batch reward last col mean 9.132681952905841e-07 first col mean 7.69652433518786e-06 all mean 1.2018844017802621e-06
rl training, epoch3, iter0, batch540/1133, batch loss:3.5020786981476704e-06, Training time:85035.34206676483
batch reward last col mean 3.197874684701674e-05 first col mean 1.6127768276419374e-06 all mean 3.068392106797546e-05
rl training, epoch3, iter0, batch541/1133, batch loss:1.0956621736113448e-05, Training time:85065.50656056404
batch reward last col mean 6.005284376442432e-06 first col mean 5.295590199239086e-06 all mean 6.5987878770101815e-06
rl training, epoch3, iter0, batch542/1133, batch loss:1.4123907021712512e-05, Training time:85094.75275659561
batch reward last col mean 2.219018426785624e-07 first col mean 3.234085306758061e-05 all mean 6.21054198290949e-07
rl training, epoch3, iter0, batch543/1133, batch loss:7.628383400515304e-07, Training time:85124.56608438492
batch reward last col mean 1.7036365534295328e-05 first col mean 5.078123308521754e-07 all mean 1.7586380636203103e-05
rl training, epoch3, iter0, batch544/1133, batch loss:3.322264092275873e-05, Training time:85153.79121565819
batch reward last col mean 1.4511717381537892e-05 first col mean 0.0007156574865803123 all mean 2.2909533072379418e-05
rl training, epoch3, iter0, batch545/1133, batch loss:2.2456115402746946e-05, Training time:85183.63624477386
batch reward last col mean 2.874108758987859e-06 first col mean 0.00019337923731654882 all mean 4.959730176778976e-06
rl training, epoch3, iter0, batch546/1133, batch loss:1.4328097677207552e-05, Training time:85212.97981119156
batch reward last col mean 2.0175607460259926e-06 first col mean 2.7090477487945464e-06 all mean 2.199326218033093e-06
rl training, epoch3, iter0, batch547/1133, batch loss:4.828751116292551e-06, Training time:85242.58050322533
batch reward last col mean 3.1446239745491766e-07 first col mean 1.5115907444851473e-05 all mean 4.946487592860649e-07
rl training, epoch3, iter0, batch548/1133, batch loss:7.352627449108695e-07, Training time:85271.86226439476
batch reward last col mean 1.2383493412926327e-06 first col mean 1.9583709217840806e-05 all mean 3.803314484684961e-06
rl training, epoch3, iter0, batch549/1133, batch loss:3.0535633413819596e-05, Training time:85301.51719141006
batch reward last col mean 1.2183876378912828e-06 first col mean 3.307717270217836e-05 all mean 1.7215176058016368e-06
rl training, epoch3, iter0, batch550/1133, batch loss:3.981084773840848e-06, Training time:85331.32094717026
batch reward last col mean 1.8964911987495725e-06 first col mean 7.660125447728205e-06 all mean 4.397656084620394e-06
rl training, epoch3, iter0, batch551/1133, batch loss:2.2674252249998972e-05, Training time:85361.10283875465
batch reward last col mean 3.636246788119024e-07 first col mean 9.898251391859958e-07 all mean 4.892112883680966e-07
rl training, epoch3, iter0, batch552/1133, batch loss:1.456230506846623e-06, Training time:85390.86751294136
batch reward last col mean 3.3289461498497985e-07 first col mean 5.671874896506779e-05 all mean 9.62723220254702e-07
rl training, epoch3, iter0, batch553/1133, batch loss:1.2271220839465968e-06, Training time:85420.56942462921
batch reward last col mean 8.790028687144513e-07 first col mean 2.571413915575249e-06 all mean 1.1693114174704533e-06
rl training, epoch3, iter0, batch554/1133, batch loss:1.333112891188648e-06, Training time:85450.27919721603
batch reward last col mean 1.771839197317604e-05 first col mean 4.876018010691041e-06 all mean 1.699691165413242e-05
rl training, epoch3, iter0, batch555/1133, batch loss:2.3811024220776744e-05, Training time:85479.81817936897
batch reward last col mean 0.00013311579823493958 first col mean 6.147779458842706e-06 all mean 0.00012795838119927794
rl training, epoch3, iter0, batch556/1133, batch loss:0.0001378446613671258, Training time:85509.42307329178
batch reward last col mean 4.4306591462373035e-07 first col mean 0.00011907107545994222 all mean 1.7264293319385615e-06
rl training, epoch3, iter0, batch557/1133, batch loss:3.475213816273026e-06, Training time:85539.4273610115
batch reward last col mean 1.169252755062189e-05 first col mean 7.109502621460706e-05 all mean 1.409889773640316e-05
rl training, epoch3, iter0, batch558/1133, batch loss:6.669334106845781e-05, Training time:85569.09246492386
batch reward last col mean 1.3774497347185388e-06 first col mean 4.9457888962933794e-05 all mean 4.743799763673451e-06
rl training, epoch3, iter0, batch559/1133, batch loss:3.310654574306682e-05, Training time:85598.67797327042
batch reward last col mean 1.0607631111270166e-06 first col mean 1.1957182550759171e-06 all mean 1.301562633670983e-06
rl training, epoch3, iter0, batch560/1133, batch loss:6.7823957579093985e-06, Training time:85628.54854607582
batch reward last col mean 0.00023290705576073378 first col mean 9.241888619726524e-05 all mean 0.00023089781461749226
rl training, epoch3, iter0, batch561/1133, batch loss:0.0002761512005236, Training time:85657.76278996468
batch reward last col mean 7.950218900987238e-07 first col mean 2.9270657250890508e-05 all mean 1.8356394093643758e-06
rl training, epoch3, iter0, batch562/1133, batch loss:3.0105162295512855e-05, Training time:85686.97490739822
batch reward last col mean 1.9360240912646987e-06 first col mean 5.134449111210415e-06 all mean 2.053819116554223e-06
rl training, epoch3, iter0, batch563/1133, batch loss:1.4162848174237297e-06, Training time:85715.94871211052
batch reward last col mean 1.8143778106605168e-06 first col mean 5.140637995282304e-07 all mean 1.8303072693015565e-06
rl training, epoch3, iter0, batch564/1133, batch loss:2.0724835394503316e-06, Training time:85745.8435921669
batch reward last col mean 4.5654184077648097e-07 first col mean 3.4268748549948214e-06 all mean 5.375374030336388e-07
rl training, epoch3, iter0, batch565/1133, batch loss:8.919539027374412e-07, Training time:85775.292355299
batch reward last col mean 6.366289539982972e-07 first col mean 1.5395715990962344e-06 all mean 8.652232281747274e-07
rl training, epoch3, iter0, batch566/1133, batch loss:3.2758507586549968e-06, Training time:85804.5793941021
batch reward last col mean 2.3106883872969775e-06 first col mean 1.1058960808441043e-05 all mean 4.355404598754831e-06
rl training, epoch3, iter0, batch567/1133, batch loss:3.5154800571035594e-05, Training time:85834.4202773571
batch reward last col mean 3.3279195577051723e-07 first col mean 3.1326992029789835e-05 all mean 2.4263795239676256e-06
rl training, epoch3, iter0, batch568/1133, batch loss:6.804924851167016e-06, Training time:85863.26420879364
batch reward last col mean 3.4837736961890187e-07 first col mean 4.983705821359763e-07 all mean 3.985850014487369e-07
rl training, epoch3, iter0, batch569/1133, batch loss:4.6538468723156257e-07, Training time:85893.15842938423
batch reward last col mean 4.034893663629191e-07 first col mean 4.786465410688834e-07 all mean 1.168371454696171e-05
rl training, epoch3, iter0, batch570/1133, batch loss:0.00015932010137476027, Training time:85923.15876483917
batch reward last col mean 1.0918287216554745e-06 first col mean 2.6609243377606617e-06 all mean 1.3545213732868433e-06
rl training, epoch3, iter0, batch571/1133, batch loss:1.6105756230899715e-06, Training time:85952.62607216835
batch reward last col mean 6.542231858475134e-06 first col mean 6.700976427964633e-06 all mean 6.984869742154842e-06
rl training, epoch3, iter0, batch572/1133, batch loss:6.493209184554871e-06, Training time:85982.12719917297
batch reward last col mean 7.151292606977222e-07 first col mean 1.4956057157178293e-06 all mean 3.1125305213208776e-06
rl training, epoch3, iter0, batch573/1133, batch loss:6.067228241590783e-05, Training time:86012.20348358154
batch reward last col mean 2.504935400793329e-05 first col mean 4.834632363781566e-06 all mean 2.493950887583196e-05
rl training, epoch3, iter0, batch574/1133, batch loss:1.779826379788574e-05, Training time:86042.21963143349
batch reward last col mean 5.217214607000642e-07 first col mean 0.00011979388364125043 all mean 2.1598677903966745e-06
rl training, epoch3, iter0, batch575/1133, batch loss:6.792614385631168e-06, Training time:86071.88878679276
batch reward last col mean 1.0774471093100146e-06 first col mean 4.362141226010863e-06 all mean 1.7715130979922833e-06
rl training, epoch3, iter0, batch576/1133, batch loss:5.2857967602903955e-06, Training time:86101.55416798592
batch reward last col mean 3.10807848791228e-07 first col mean 0.00012147210509283468 all mean 1.6158121525222668e-06
rl training, epoch3, iter0, batch577/1133, batch loss:2.437258672216558e-06, Training time:86131.15241909027
batch reward last col mean 0.0001298589922953397 first col mean 8.077843813225627e-05 all mean 0.00012779365351889282
rl training, epoch3, iter0, batch578/1133, batch loss:8.963126310845837e-05, Training time:86160.90796136856
batch reward last col mean 1.0475711178514757e-06 first col mean 0.0008671829127706587 all mean 1.0309990102541633e-05
rl training, epoch3, iter0, batch579/1133, batch loss:1.4320681657409295e-05, Training time:86190.15957546234
batch reward last col mean 8.840427199174883e-07 first col mean 1.0337539606553037e-06 all mean 9.371829037263524e-07
rl training, epoch3, iter0, batch580/1133, batch loss:7.463715974154184e-07, Training time:86219.53857803345
batch reward last col mean 6.619311534450389e-07 first col mean 4.786448357663176e-07 all mean 2.7164810489921365e-06
rl training, epoch3, iter0, batch581/1133, batch loss:1.1708082638506312e-05, Training time:86247.17119312286
batch reward last col mean 0.0002490303886588663 first col mean 1.0982399771819473e-06 all mean 0.0002395741466898471
rl training, epoch3, iter0, batch582/1133, batch loss:0.00022502191131934524, Training time:86274.32762598991
batch reward last col mean 0.0002043766580754891 first col mean 4.065669145347783e-06 all mean 0.00019870675168931484
rl training, epoch3, iter0, batch583/1133, batch loss:6.58096614643e-05, Training time:86301.34884357452
batch reward last col mean 1.2061671441188082e-05 first col mean 2.168357923437725e-06 all mean 1.5201546375465114e-05
rl training, epoch3, iter0, batch584/1133, batch loss:5.935279659752268e-06, Training time:86328.4950003624
batch reward last col mean 4.881835025116743e-07 first col mean 0.00188635743688792 all mean 1.9603679902502336e-05
rl training, epoch3, iter0, batch585/1133, batch loss:6.171513814479113e-05, Training time:86355.42267990112
batch reward last col mean 2.8849535738117993e-07 first col mean 1.6465894532302627e-06 all mean 8.145141237037024e-07
rl training, epoch3, iter0, batch586/1133, batch loss:6.9904840529488865e-06, Training time:86382.51134705544
batch reward last col mean 1.7025513443513773e-06 first col mean 0.00016231852350756526 all mean 1.803060331440065e-05
rl training, epoch3, iter0, batch587/1133, batch loss:0.0007165502174757421, Training time:86409.72126364708
batch reward last col mean 4.7286484914366156e-05 first col mean 1.416049235558603e-05 all mean 4.6399873099289834e-05
rl training, epoch3, iter0, batch588/1133, batch loss:1.3039607438258827e-05, Training time:86436.80825304985
batch reward last col mean 2.9945948654130916e-07 first col mean 1.885072265395138e-06 all mean 1.2287932804611046e-06
rl training, epoch3, iter0, batch589/1133, batch loss:2.1483576801983872e-06, Training time:86464.30310940742
batch reward last col mean 0.0006714841001667082 first col mean 5.113164206704823e-06 all mean 0.0006679065991193056
rl training, epoch3, iter0, batch590/1133, batch loss:0.0002869265154004097, Training time:86491.78680062294
batch reward last col mean 2.5121689759544097e-06 first col mean 0.0001016078022075817 all mean 4.937187441100832e-06
rl training, epoch3, iter0, batch591/1133, batch loss:1.681763205851894e-05, Training time:86519.11023426056
batch reward last col mean 2.866803879442159e-05 first col mean 4.310891654313309e-06 all mean 5.0562808610266075e-05
rl training, epoch3, iter0, batch592/1133, batch loss:0.001226493390277028, Training time:86546.52125453949
batch reward last col mean 2.0552597561618313e-06 first col mean 4.748814717459027e-06 all mean 6.047715032764245e-06
rl training, epoch3, iter0, batch593/1133, batch loss:1.072814757208107e-05, Training time:86573.86648440361
batch reward last col mean 8.276352900793427e-07 first col mean 7.889729749877006e-05 all mean 5.767897619080031e-06
rl training, epoch3, iter0, batch594/1133, batch loss:9.967486221285071e-06, Training time:86601.16045117378
batch reward last col mean 3.1936889399730717e-07 first col mean 3.3318448799946054e-07 all mean 8.92757270776201e-06
rl training, epoch3, iter0, batch595/1133, batch loss:8.387931302422658e-05, Training time:86628.35093545914
batch reward last col mean 4.026221176900435e-06 first col mean 1.8993836192748859e-06 all mean 1.302359851251822e-05
rl training, epoch3, iter0, batch596/1133, batch loss:0.00012653392332140356, Training time:86655.61552000046
batch reward last col mean 3.8049199702072656e-07 first col mean 2.701530775084393e-06 all mean 8.525362886757648e-07
rl training, epoch3, iter0, batch597/1133, batch loss:2.6886980322160525e-06, Training time:86683.03479075432
batch reward last col mean 1.2355593753454741e-05 first col mean 5.289756700221915e-06 all mean 1.2859409252996556e-05
rl training, epoch3, iter0, batch598/1133, batch loss:7.0615624281344935e-06, Training time:86710.4295156002
batch reward last col mean 2.0265966668375768e-05 first col mean 1.6127160051837564e-06 all mean 1.8631393686519004e-05
rl training, epoch3, iter0, batch599/1133, batch loss:1.2509672160376795e-05, Training time:86737.89196491241
batch reward last col mean 1.2153578836660017e-06 first col mean 1.0560368082224159e-06 all mean 1.3632554782816442e-06
rl training, epoch3, iter0, batch600/1133, batch loss:1.073352109415282e-06, Training time:86765.11834549904
batch reward last col mean 9.806013622437604e-06 first col mean 1.8386945157544687e-06 all mean 9.85858787316829e-06
rl training, epoch3, iter0, batch601/1133, batch loss:4.4386479203240015e-06, Training time:86792.36454224586
batch reward last col mean 3.279981513060193e-07 first col mean 6.445387725761975e-07 all mean 5.755696292908397e-07
rl training, epoch3, iter0, batch602/1133, batch loss:8.121604651023517e-07, Training time:86819.79141283035
batch reward last col mean 1.5511201354456716e-06 first col mean 0.00029359289328567684 all mean 4.652258667192655e-06
rl training, epoch3, iter0, batch603/1133, batch loss:3.7496010918403044e-05, Training time:86846.9315354824
batch reward last col mean 4.163576249993639e-06 first col mean 2.5939743864000775e-05 all mean 6.622135515499394e-06
rl training, epoch3, iter0, batch604/1133, batch loss:3.193453812855296e-05, Training time:86874.50429868698
batch reward last col mean 5.217756893216574e-07 first col mean 4.833423008676618e-05 all mean 3.821557129413122e-06
rl training, epoch3, iter0, batch605/1133, batch loss:5.706629508495098e-06, Training time:86901.90121364594
batch reward last col mean 6.786230369471014e-05 first col mean 0.0003625483950600028 all mean 6.98804433341138e-05
rl training, epoch3, iter0, batch606/1133, batch loss:0.00022171359159983695, Training time:86929.46253728867
batch reward last col mean 3.745950039046875e-07 first col mean 1.2612500540853944e-05 all mean 4.8917613639787305e-06
rl training, epoch3, iter0, batch607/1133, batch loss:0.00014650405501015484, Training time:86956.99220705032
batch reward last col mean 1.709675302663527e-06 first col mean 1.3433325875666924e-05 all mean 2.2188939965417376e-06
rl training, epoch3, iter0, batch608/1133, batch loss:4.483139946387382e-06, Training time:86984.11243796349
batch reward last col mean 2.574621476014727e-06 first col mean 5.828268513141666e-06 all mean 3.2853702123247785e-06
rl training, epoch3, iter0, batch609/1133, batch loss:1.5270281437551603e-05, Training time:87011.84184765816
batch reward last col mean 8.151284419000149e-06 first col mean 5.60475314159703e-07 all mean 8.845091542752925e-06
rl training, epoch3, iter0, batch610/1133, batch loss:3.9622642361791804e-05, Training time:87039.39281392097
batch reward last col mean 2.0850854980380973e-06 first col mean 0.0005332889850251377 all mean 7.489761173928855e-06
rl training, epoch3, iter0, batch611/1133, batch loss:2.5727990760060493e-06, Training time:87067.50189232826
batch reward last col mean 1.9305725800222717e-05 first col mean 0.000300607702229172 all mean 3.208346606697887e-05
rl training, epoch3, iter0, batch612/1133, batch loss:8.300365880131721e-05, Training time:87095.07082939148
batch reward last col mean 5.083961696072947e-06 first col mean 4.111436737730401e-06 all mean 7.841322258173022e-06
rl training, epoch3, iter0, batch613/1133, batch loss:1.7201004084199667e-05, Training time:87122.4916138649
batch reward last col mean 1.0829728580574738e-06 first col mean 6.2777298808214255e-06 all mean 1.5190009889920475e-06
rl training, epoch3, iter0, batch614/1133, batch loss:9.712472319733934e-07, Training time:87149.9473953247
batch reward last col mean 1.17291222068161e-06 first col mean 9.595448318577837e-06 all mean 1.4548659237334505e-06
rl training, epoch3, iter0, batch615/1133, batch loss:1.5497149661314324e-06, Training time:87177.22786450386
batch reward last col mean 2.5807371457631234e-06 first col mean 1.7099706383305602e-05 all mean 3.2625612220726907e-06
rl training, epoch3, iter0, batch616/1133, batch loss:8.432749382336624e-06, Training time:87204.63390612602
batch reward last col mean 3.739298222171783e-07 first col mean 8.118370897136629e-05 all mean 1.291392663915758e-06
rl training, epoch3, iter0, batch617/1133, batch loss:5.757052576882415e-07, Training time:87231.92168092728
batch reward last col mean 5.505770559466328e-07 first col mean 1.822908870963147e-06 all mean 7.109608759492403e-07
rl training, epoch3, iter0, batch618/1133, batch loss:2.5686065328045515e-06, Training time:87259.1898932457
batch reward last col mean 2.063711690425407e-06 first col mean 9.043511681738892e-07 all mean 3.3076780709961895e-06
rl training, epoch3, iter0, batch619/1133, batch loss:2.223067349405028e-05, Training time:87286.62289142609
batch reward last col mean 1.3086870467304834e-06 first col mean 0.0002044585271505639 all mean 1.2343170055828523e-05
rl training, epoch3, iter0, batch620/1133, batch loss:2.571753429947421e-05, Training time:87313.92141366005
batch reward last col mean 4.149563210376073e-06 first col mean 1.4493677554128226e-05 all mean 4.3538393583730794e-06
rl training, epoch3, iter0, batch621/1133, batch loss:3.752800921574817e-06, Training time:87341.4811193943
batch reward last col mean 8.267160183095257e-07 first col mean 1.498372171226947e-06 all mean 8.861471201271343e-07
rl training, epoch3, iter0, batch622/1133, batch loss:1.727272433527105e-06, Training time:87368.81425499916
batch reward last col mean 3.720015229191631e-06 first col mean 1.1552618161658756e-05 all mean 3.82492635253584e-06
rl training, epoch3, iter0, batch623/1133, batch loss:3.4062297800119268e-06, Training time:87396.18016958237
batch reward last col mean 2.324197339476086e-06 first col mean 9.06197101357975e-07 all mean 2.003458803301328e-06
rl training, epoch3, iter0, batch624/1133, batch loss:1.4951530147300218e-06, Training time:87423.75151467323
batch reward last col mean 1.3300309547048528e-06 first col mean 9.619253251003101e-05 all mean 6.012774520058883e-06
rl training, epoch3, iter0, batch625/1133, batch loss:0.0001635576772969216, Training time:87451.1057753563
batch reward last col mean 1.6244608559645712e-05 first col mean 3.718231766924873e-07 all mean 1.569468258821871e-05
rl training, epoch3, iter0, batch626/1133, batch loss:5.282531674311031e-06, Training time:87478.46652793884
batch reward last col mean 2.21778714148968e-06 first col mean 4.3098007154185325e-06 all mean 2.272495521538076e-06
rl training, epoch3, iter0, batch627/1133, batch loss:8.074673019109468e-07, Training time:87505.81014943123
batch reward last col mean 0.0010273706866428256 first col mean 6.610184209421277e-05 all mean 0.0009873223025351763
rl training, epoch3, iter0, batch628/1133, batch loss:0.0007174730999395251, Training time:87533.12856578827
batch reward last col mean 1.2400405466905795e-06 first col mean 2.2355272903951118e-06 all mean 2.4523874344595242e-06
rl training, epoch3, iter0, batch629/1133, batch loss:3.416485196794383e-05, Training time:87560.60646867752
batch reward last col mean 2.252456170026562e-06 first col mean 2.105002295138547e-06 all mean 2.1481043859239435e-06
rl training, epoch3, iter0, batch630/1133, batch loss:2.3968657387740677e-06, Training time:87588.15464663506
batch reward last col mean 1.339644495601533e-05 first col mean 1.1960287338297348e-06 all mean 1.3175512322050054e-05
rl training, epoch3, iter0, batch631/1133, batch loss:6.04489105171524e-06, Training time:87615.49282312393
batch reward last col mean 5.899521511310013e-06 first col mean 1.125855851569213e-05 all mean 5.95549227000447e-06
rl training, epoch3, iter0, batch632/1133, batch loss:1.1037091098842211e-05, Training time:87642.91205739975
batch reward last col mean 1.7382022633682936e-05 first col mean 1.1288565474387724e-05 all mean 1.983530273719225e-05
rl training, epoch3, iter0, batch633/1133, batch loss:4.686235843109898e-05, Training time:87670.45504403114
batch reward last col mean 3.4746778965200065e-07 first col mean 4.877765604760498e-07 all mean 1.051251183525892e-05
rl training, epoch3, iter0, batch634/1133, batch loss:0.00011904465645784512, Training time:87697.93029308319
batch reward last col mean 1.218509879663543e-07 first col mean 8.458317779513891e-07 all mean 1.6045353845584032e-07
rl training, epoch3, iter0, batch635/1133, batch loss:1.6370169930723932e-07, Training time:87725.12128448486
batch reward last col mean 1.1658676157821901e-06 first col mean 3.953097802877892e-06 all mean 1.8880879224525415e-06
rl training, epoch3, iter0, batch636/1133, batch loss:2.7242467695032246e-05, Training time:87752.44096064568
batch reward last col mean 6.63299360894598e-05 first col mean 1.7856655176728964e-06 all mean 6.838463741587475e-05
rl training, epoch3, iter0, batch637/1133, batch loss:2.160665280825924e-05, Training time:87779.68362569809
batch reward last col mean 5.782358698525059e-07 first col mean 7.129764298952068e-07 all mean 8.28861516311008e-07
rl training, epoch3, iter0, batch638/1133, batch loss:2.4224011667683953e-06, Training time:87806.90250349045
batch reward last col mean 4.496022938837996e-06 first col mean 1.2345325558271725e-05 all mean 4.9676464186632074e-06
rl training, epoch3, iter0, batch639/1133, batch loss:9.409250196767971e-06, Training time:87834.47385644913
batch reward last col mean 7.756098625577579e-07 first col mean 1.5013940810604254e-06 all mean 9.92060904536629e-07
rl training, epoch3, iter0, batch640/1133, batch loss:5.585815870290389e-06, Training time:87862.00075769424
batch reward last col mean 0.00015678023919463158 first col mean 9.920962611431605e-07 all mean 0.0001494813768658787
rl training, epoch3, iter0, batch641/1133, batch loss:6.459338328568265e-05, Training time:87889.5156288147
batch reward last col mean 1.8071143585984828e-06 first col mean 2.176418092858512e-05 all mean 4.745837031805422e-06
rl training, epoch3, iter0, batch642/1133, batch loss:1.2779781172866933e-05, Training time:87916.84961724281
batch reward last col mean 2.292315002705436e-06 first col mean 2.8384188226482365e-06 all mean 2.280024637002498e-05
rl training, epoch3, iter0, batch643/1133, batch loss:0.0007160988752730191, Training time:87944.84834694862
batch reward last col mean 3.338054375490174e-05 first col mean 1.1492978728711023e-06 all mean 3.957347507821396e-05
rl training, epoch3, iter0, batch644/1133, batch loss:0.00014152287621982396, Training time:87972.48949718475
batch reward last col mean 5.504471118911169e-07 first col mean 5.07116169501387e-07 all mean 7.337679903685057e-07
rl training, epoch3, iter0, batch645/1133, batch loss:9.778452749742428e-07, Training time:88000.26542520523
batch reward last col mean 0.0008675918797962368 first col mean 0.0008750646957196295 all mean 0.0008681408362463117
rl training, epoch3, iter0, batch646/1133, batch loss:0.0005410095909610391, Training time:88027.57968711853
batch reward last col mean 0.006033787038177252 first col mean 8.079828148765955e-06 all mean 0.00585247902199626
rl training, epoch3, iter0, batch647/1133, batch loss:0.0025241360999643803, Training time:88054.56212234497
batch reward last col mean 5.601656312137493e-07 first col mean 4.6027098505874164e-06 all mean 8.070517765190743e-07
rl training, epoch3, iter0, batch648/1133, batch loss:4.136320512770908e-07, Training time:88081.70045614243
batch reward last col mean 0.00011663158511510119 first col mean 2.219579619122669e-05 all mean 0.00012438881094567478
rl training, epoch3, iter0, batch649/1133, batch loss:0.00012451497605070472, Training time:88109.17475795746
batch reward last col mean 1.4206273135641823e-06 first col mean 3.338188435009215e-06 all mean 1.5810368267921149e-06
rl training, epoch3, iter0, batch650/1133, batch loss:3.2782929793029325e-06, Training time:88136.50953507423
batch reward last col mean 5.829172096127877e-07 first col mean 9.537060577713419e-06 all mean 2.01750808628276e-05
rl training, epoch3, iter0, batch651/1133, batch loss:4.8535189307585824e-06, Training time:88163.8306555748
batch reward last col mean 1.0055922757601365e-05 first col mean 1.5063896171341185e-05 all mean 1.0085294888995122e-05
rl training, epoch3, iter0, batch652/1133, batch loss:1.064049774868181e-05, Training time:88191.32911109924
batch reward last col mean 1.584548044775147e-05 first col mean 3.9590781852894e-06 all mean 1.5120814168767538e-05
rl training, epoch3, iter0, batch653/1133, batch loss:9.15889995667385e-06, Training time:88218.60875701904
batch reward last col mean 8.858584124027402e-07 first col mean 3.1267268241208512e-06 all mean 9.936786682374077e-07
rl training, epoch3, iter0, batch654/1133, batch loss:1.617962197997258e-06, Training time:88246.25608706474
batch reward last col mean 4.789079412148567e-06 first col mean 1.7583701037438004e-06 all mean 4.791719220520463e-06
rl training, epoch3, iter0, batch655/1133, batch loss:2.732407665462233e-06, Training time:88273.52674794197
batch reward last col mean 1.2882257578894496e-05 first col mean 3.947062396036927e-06 all mean 2.1966554413666017e-05
rl training, epoch3, iter0, batch656/1133, batch loss:0.0005812409217469394, Training time:88300.86923003197
batch reward last col mean 9.697589848656207e-05 first col mean 5.6763037719065323e-05 all mean 9.570598922437057e-05
rl training, epoch3, iter0, batch657/1133, batch loss:2.0939136447850615e-05, Training time:88328.46463060379
batch reward last col mean 2.7807254809886217e-06 first col mean 1.743158463796135e-06 all mean 3.560630148058408e-06
rl training, epoch3, iter0, batch658/1133, batch loss:1.752983189362567e-05, Training time:88355.93764567375
batch reward last col mean 9.423598612556816e-07 first col mean 1.7750451206666185e-06 all mean 9.237969038622396e-07
rl training, epoch3, iter0, batch659/1133, batch loss:7.370304047071841e-07, Training time:88384.15433120728
batch reward last col mean 2.9495504350052215e-06 first col mean 2.0432739802345168e-06 all mean 8.607370546087623e-06
rl training, epoch3, iter0, batch660/1133, batch loss:0.00011113977961940691, Training time:88411.79061985016
batch reward last col mean 6.112348387432576e-07 first col mean 9.434147614229005e-07 all mean 2.375883468630491e-06
rl training, epoch3, iter0, batch661/1133, batch loss:2.2319019990391098e-05, Training time:88439.17309594154
batch reward last col mean 6.694293688269681e-07 first col mean 9.154819053946994e-06 all mean 1.07860796560999e-06
rl training, epoch3, iter0, batch662/1133, batch loss:3.469229795882711e-06, Training time:88466.78981804848
batch reward last col mean 3.3250779551963205e-07 first col mean 8.201561740861507e-07 all mean 2.4807229692669353e-06
rl training, epoch3, iter0, batch663/1133, batch loss:1.3084956663078628e-05, Training time:88494.14786624908
batch reward last col mean 1.3211782743383083e-06 first col mean 0.00020487434812821448 all mean 3.402569291210966e-06
rl training, epoch3, iter0, batch664/1133, batch loss:4.035128768009599e-06, Training time:88521.62858200073
batch reward last col mean 1.386113922308141e-06 first col mean 1.6415713162132306e-06 all mean 1.1376173461030703e-05
rl training, epoch3, iter0, batch665/1133, batch loss:0.00012034621613565832, Training time:88548.8791873455
batch reward last col mean 0.00016533177404198796 first col mean 1.7476422726758756e-05 all mean 0.0001630897168070078
rl training, epoch3, iter0, batch666/1133, batch loss:7.214762445073575e-05, Training time:88576.2957303524
batch reward last col mean 1.142786095442716e-05 first col mean 4.8191768655669875e-06 all mean 1.1097070455434732e-05
rl training, epoch3, iter0, batch667/1133, batch loss:7.826462933735456e-06, Training time:88603.71762180328
batch reward last col mean 5.4132691730046645e-05 first col mean 8.363415690837428e-05 all mean 5.3591051255352795e-05
rl training, epoch3, iter0, batch668/1133, batch loss:3.114602077403106e-05, Training time:88631.01882958412
batch reward last col mean 1.1286202607152518e-05 first col mean 1.245161001861561e-06 all mean 1.1166534022777341e-05
rl training, epoch3, iter0, batch669/1133, batch loss:2.064372347376775e-05, Training time:88658.64729738235
batch reward last col mean 6.181708886288106e-05 first col mean 3.660860784293618e-06 all mean 7.38376475055702e-05
rl training, epoch3, iter0, batch670/1133, batch loss:1.83522224688204e-05, Training time:88685.828166008
batch reward last col mean 9.622851939639077e-05 first col mean 0.001048895763233304 all mean 0.00010119586659129709
rl training, epoch3, iter0, batch671/1133, batch loss:7.490181451430544e-05, Training time:88713.38994312286
batch reward last col mean 2.517882933261717e-07 first col mean 1.1569213711482007e-06 all mean 4.5535978188127046e-07
rl training, epoch3, iter0, batch672/1133, batch loss:1.5887002291492536e-06, Training time:88741.00442314148
batch reward last col mean 2.6133860956178978e-05 first col mean 4.568599979393184e-05 all mean 2.5833694962784648e-05
rl training, epoch3, iter0, batch673/1133, batch loss:9.966050129150972e-06, Training time:88768.09633350372
batch reward last col mean 6.627300535910763e-06 first col mean 1.988672011066228e-05 all mean 6.850403224234469e-06
rl training, epoch3, iter0, batch674/1133, batch loss:5.206035439186962e-06, Training time:88795.67919874191
batch reward last col mean 8.760289915699104e-07 first col mean 2.8043345992045943e-06 all mean 1.0500358484932804e-06
rl training, epoch3, iter0, batch675/1133, batch loss:3.568506599549437e-06, Training time:88823.17516732216
batch reward last col mean 2.314525772817433e-06 first col mean 2.7603673515841365e-05 all mean 2.764361852314323e-06
rl training, epoch3, iter0, batch676/1133, batch loss:9.572356702847173e-07, Training time:88850.41721844673
batch reward last col mean 1.865737431216985e-06 first col mean 2.7566418793867342e-05 all mean 4.781544703291729e-06
rl training, epoch3, iter0, batch677/1133, batch loss:2.3862662601459306e-06, Training time:88878.00543498993
batch reward last col mean 8.704566880624043e-07 first col mean 3.688097058329731e-05 all mean 3.6412504869076656e-06
rl training, epoch3, iter0, batch678/1133, batch loss:7.492778240703046e-05, Training time:88905.95026063919
batch reward last col mean 5.390466867538635e-06 first col mean 0.0003504371561575681 all mean 2.5908231691573747e-05
rl training, epoch3, iter0, batch679/1133, batch loss:0.0005553168011829257, Training time:88933.36670851707
batch reward last col mean 4.291275672585471e-06 first col mean 3.639751639639144e-06 all mean 6.9666407398472074e-06
rl training, epoch3, iter0, batch680/1133, batch loss:3.1830353691475466e-05, Training time:88960.62593221664
batch reward last col mean 9.299333783019392e-07 first col mean 1.4552840639225906e-06 all mean 5.2144096116535366e-06
rl training, epoch3, iter0, batch681/1133, batch loss:1.6695008525857702e-05, Training time:88987.73006081581
batch reward last col mean 1.9293533171094168e-07 first col mean 1.9754500044655288e-06 all mean 2.3422404638040462e-07
rl training, epoch3, iter0, batch682/1133, batch loss:2.733779069785669e-07, Training time:89014.87393665314
batch reward last col mean 1.0981232207996072e-06 first col mean 8.296756277559325e-06 all mean 9.005671927297954e-06
rl training, epoch3, iter0, batch683/1133, batch loss:0.00030262829386629164, Training time:89041.97300243378
batch reward last col mean 5.208503353060223e-06 first col mean 1.05331237136852e-05 all mean 5.176666945772013e-06
rl training, epoch3, iter0, batch684/1133, batch loss:5.7541742535249796e-06, Training time:89069.236982584
batch reward last col mean 2.833931375789689e-06 first col mean 1.0430047723275493e-06 all mean 2.9419356906146277e-06
rl training, epoch3, iter0, batch685/1133, batch loss:1.229593976859178e-06, Training time:89096.3490831852
batch reward last col mean 6.602733719773823e-07 first col mean 2.801784376060823e-06 all mean 1.3381476492213551e-05
rl training, epoch3, iter0, batch686/1133, batch loss:0.00010790474334498867, Training time:89123.5040230751
batch reward last col mean 0.00019058305770158768 first col mean 0.0010541017400100827 all mean 0.0001976433559320867
rl training, epoch3, iter0, batch687/1133, batch loss:8.283155329991132e-05, Training time:89150.80025172234
batch reward last col mean 7.159101187426131e-07 first col mean 0.00046514978748746216 all mean 5.577278898272198e-06
rl training, epoch3, iter0, batch688/1133, batch loss:0.00013616522483062, Training time:89177.73645210266
batch reward last col mean 3.3174346754094586e-06 first col mean 9.738339485920733e-07 all mean 3.5613686577562476e-06
rl training, epoch3, iter0, batch689/1133, batch loss:4.09326639783103e-06, Training time:89204.71991848946
batch reward last col mean 1.958090069820173e-05 first col mean 6.105895408836659e-06 all mean 1.8407057723379694e-05
rl training, epoch3, iter0, batch690/1133, batch loss:1.2207950021547731e-05, Training time:89231.77326846123
batch reward last col mean 7.595231727464125e-05 first col mean 7.58882742957212e-05 all mean 7.629883475601673e-05
rl training, epoch3, iter0, batch691/1133, batch loss:5.8817691751755774e-05, Training time:89259.02403354645
batch reward last col mean 8.031257721086149e-07 first col mean 3.9583537727594376e-06 all mean 1.2036128964609816e-06
rl training, epoch3, iter0, batch692/1133, batch loss:1.2078706276952289e-05, Training time:89286.2077023983
batch reward last col mean 1.5134846762521192e-06 first col mean 1.1828193464680226e-06 all mean 1.581739979883423e-06
rl training, epoch3, iter0, batch693/1133, batch loss:1.6311164472426753e-06, Training time:89313.22092223167
batch reward last col mean 2.190902478105272e-06 first col mean 2.764566033874871e-06 all mean 2.797518391162157e-06
rl training, epoch3, iter0, batch694/1133, batch loss:2.0953961211489514e-05, Training time:89340.48415470123
batch reward last col mean 1.9793844785453985e-07 first col mean 2.1175621441216208e-05 all mean 2.6076282665599138e-05
rl training, epoch3, iter0, batch695/1133, batch loss:0.0007176113431341946, Training time:89367.57682490349
batch reward last col mean 2.967115904084494e-07 first col mean 8.866981806932017e-05 all mean 1.2876402024630806e-06
rl training, epoch3, iter0, batch696/1133, batch loss:1.8060599131786148e-06, Training time:89394.67146205902
batch reward last col mean 4.096837528777542e-06 first col mean 1.5647797226847615e-06 all mean 4.227517820254434e-06
rl training, epoch3, iter0, batch697/1133, batch loss:5.0250823733222205e-06, Training time:89421.80696606636
batch reward last col mean 1.92795550901792e-06 first col mean 6.250503793125972e-05 all mean 2.7385140128899366e-06
rl training, epoch3, iter0, batch698/1133, batch loss:7.532459221692989e-06, Training time:89448.6126396656
batch reward last col mean 3.795935015205032e-07 first col mean 3.4552908800833393e-07 all mean 1.2061640290994546e-06
rl training, epoch3, iter0, batch699/1133, batch loss:8.049113603192382e-06, Training time:89475.81599259377
batch reward last col mean 7.900517857706291e-07 first col mean 3.122806083410978e-05 all mean 1.4624846471633646e-06
rl training, epoch3, iter0, batch700/1133, batch loss:5.45582952327095e-06, Training time:89503.0935997963
batch reward last col mean 0.00030604697531089187 first col mean 0.0005986728356219828 all mean 0.00030807210714556277
rl training, epoch3, iter0, batch701/1133, batch loss:4.7792451368877664e-05, Training time:89530.37022042274
batch reward last col mean 4.175901153757877e-07 first col mean 6.267091521294788e-07 all mean 6.444990390264138e-07
rl training, epoch3, iter0, batch702/1133, batch loss:3.286257879153709e-06, Training time:89557.47181200981
batch reward last col mean 1.9064469597651623e-05 first col mean 1.0139187907043379e-06 all mean 1.9208911908208393e-05
rl training, epoch3, iter0, batch703/1133, batch loss:2.1745137928519398e-05, Training time:89584.35458540916
batch reward last col mean 4.85468319766369e-07 first col mean 5.307974788593128e-06 all mean 6.62977015508659e-07
rl training, epoch3, iter0, batch704/1133, batch loss:2.9342695597733837e-06, Training time:89611.56814169884
batch reward last col mean 9.349648280476686e-06 first col mean 1.0009253855969291e-05 all mean 9.236189725925215e-06
rl training, epoch3, iter0, batch705/1133, batch loss:2.717229790505371e-06, Training time:89638.75988793373
batch reward last col mean 9.554955795465503e-07 first col mean 3.6790315789403394e-05 all mean 1.924670868902467e-06
rl training, epoch3, iter0, batch706/1133, batch loss:2.610474894026993e-06, Training time:89665.83273148537
batch reward last col mean 5.923493517911993e-07 first col mean 2.3970837901288178e-06 all mean 6.648553608101793e-06
rl training, epoch3, iter0, batch707/1133, batch loss:4.240275302436203e-05, Training time:89692.75493693352
batch reward last col mean 5.9448716456245165e-06 first col mean 2.822788701450918e-06 all mean 6.069958999432856e-06
rl training, epoch3, iter0, batch708/1133, batch loss:3.7310262541723205e-06, Training time:89720.01809382439
batch reward last col mean 3.1159046898210363e-07 first col mean 4.914687679047347e-07 all mean 3.3113221320490993e-07
rl training, epoch3, iter0, batch709/1133, batch loss:6.020290470587497e-07, Training time:89747.36782169342
batch reward last col mean 0.00023381698701996356 first col mean 5.257705197436735e-06 all mean 0.00022920756600797176
rl training, epoch3, iter0, batch710/1133, batch loss:9.19910817174241e-05, Training time:89774.4771733284
batch reward last col mean 2.4006845933399745e-07 first col mean 6.792231033614371e-06 all mean 6.700381618429674e-06
rl training, epoch3, iter0, batch711/1133, batch loss:0.00010121265222551301, Training time:89801.89440870285
batch reward last col mean 0.0001789336820365861 first col mean 0.00016189324378501624 all mean 0.0001785418571671471
rl training, epoch3, iter0, batch712/1133, batch loss:4.67156023660209e-05, Training time:89829.212829113
batch reward last col mean 2.013614448515e-06 first col mean 1.0398359336249996e-05 all mean 2.0777297322638333e-06
rl training, epoch3, iter0, batch713/1133, batch loss:9.331064916295873e-07, Training time:89856.42986416817
batch reward last col mean 3.1664965263189515e-06 first col mean 2.795013460854534e-05 all mean 2.93103585136123e-05
rl training, epoch3, iter0, batch714/1133, batch loss:0.0011588216293603182, Training time:89883.80536460876
batch reward last col mean 7.732234621471434e-07 first col mean 9.118095931626158e-07 all mean 9.043458817359351e-07
rl training, epoch3, iter0, batch715/1133, batch loss:1.323399942521064e-06, Training time:89911.31936955452
batch reward last col mean 3.8125988339743344e-06 first col mean 3.9480364648625255e-06 all mean 6.417868462449405e-06
rl training, epoch3, iter0, batch716/1133, batch loss:6.527871846628841e-06, Training time:89938.71521925926
batch reward last col mean 1.010101641440997e-06 first col mean 1.0647330555002554e-06 all mean 4.2878714339167345e-06
rl training, epoch3, iter0, batch717/1133, batch loss:6.1198043113108724e-06, Training time:89966.11542391777
batch reward last col mean 2.165527803299483e-06 first col mean 0.0019144746474921703 all mean 2.2533862647833303e-05
rl training, epoch3, iter0, batch718/1133, batch loss:2.895993020501919e-05, Training time:89993.78206634521
batch reward last col mean 8.717134960534167e-07 first col mean 1.2800497643183917e-05 all mean 1.287428062823892e-06
rl training, epoch3, iter0, batch719/1133, batch loss:1.0553465472185053e-05, Training time:90021.33567357063
batch reward last col mean 6.817462576691469e-07 first col mean 3.273279162385734e-06 all mean 2.018490931732231e-06
rl training, epoch3, iter0, batch720/1133, batch loss:1.4664810805697925e-05, Training time:90048.90026760101
batch reward last col mean 1.7149384802905843e-05 first col mean 7.887450919952244e-06 all mean 1.5574967619613744e-05
rl training, epoch3, iter0, batch721/1133, batch loss:1.035386503644986e-05, Training time:90076.41084623337
batch reward last col mean 6.155854407552397e-06 first col mean 1.3711632163904142e-05 all mean 7.317844847420929e-06
rl training, epoch3, iter0, batch722/1133, batch loss:1.875531961559318e-05, Training time:90103.65199756622
batch reward last col mean 4.6061018110776786e-06 first col mean 7.21834585419856e-05 all mean 1.932666782522574e-05
rl training, epoch3, iter0, batch723/1133, batch loss:0.00012096488353563473, Training time:90131.06779193878
batch reward last col mean 9.267806490242947e-06 first col mean 0.00031678745290264487 all mean 1.2217005860293284e-05
rl training, epoch3, iter0, batch724/1133, batch loss:0.00011846027337014675, Training time:90158.69231295586
batch reward last col mean 3.2513701171410503e-06 first col mean 6.427246989915147e-05 all mean 3.892316271958407e-06
rl training, epoch3, iter0, batch725/1133, batch loss:4.048679329571314e-06, Training time:90185.8061261177
batch reward last col mean 5.945075258750876e-07 first col mean 3.1634190236218274e-06 all mean 2.4759660846029874e-06
rl training, epoch3, iter0, batch726/1133, batch loss:3.132802521577105e-05, Training time:90213.30778265
batch reward last col mean 1.0008438948716503e-05 first col mean 1.9069804693572223e-05 all mean 1.9183422409696504e-05
rl training, epoch3, iter0, batch727/1133, batch loss:0.0003528632805682719, Training time:90240.7764582634
batch reward last col mean 0.0043153525330126286 first col mean 4.4606490519072395e-06 all mean 0.004143459722399712
rl training, epoch3, iter0, batch728/1133, batch loss:0.001847406616434455, Training time:90267.9965043068
batch reward last col mean 2.0252766717021586e-06 first col mean 6.620863587158965e-06 all mean 2.5284764433308737e-06
rl training, epoch3, iter0, batch729/1133, batch loss:1.1728160643542651e-05, Training time:90295.674690485
batch reward last col mean 3.3376709325239062e-06 first col mean 6.3178840719047e-06 all mean 3.5916714296035934e-06
rl training, epoch3, iter0, batch730/1133, batch loss:2.9193413411121583e-06, Training time:90322.94573402405
batch reward last col mean 5.930524366704049e-06 first col mean 4.2901367123704404e-05 all mean 7.669834303669631e-06
rl training, epoch3, iter0, batch731/1133, batch loss:4.066119799972512e-05, Training time:90350.30279517174
batch reward last col mean 3.9185092646221165e-06 first col mean 0.00018291595915798098 all mean 5.383502866607159e-06
rl training, epoch3, iter0, batch732/1133, batch loss:2.9373034067248227e-06, Training time:90377.44079566002
batch reward last col mean 4.594618530973094e-06 first col mean 0.0004635435761883855 all mean 9.227604095940478e-06
rl training, epoch3, iter0, batch733/1133, batch loss:1.2090026757505257e-05, Training time:90404.68861627579
batch reward last col mean 1.586365328876127e-06 first col mean 1.2671820286414004e-06 all mean 8.764348422118928e-06
rl training, epoch3, iter0, batch734/1133, batch loss:2.6045507183880545e-05, Training time:90432.0997262001
batch reward last col mean 8.545086416233971e-08 first col mean 1.2622831491171382e-06 all mean 1.262223037201693e-07
rl training, epoch3, iter0, batch735/1133, batch loss:1.9685681706960168e-07, Training time:90459.31428456306
batch reward last col mean 3.5185249203095736e-07 first col mean 1.2747104847221635e-06 all mean 4.927421173306357e-07
rl training, epoch3, iter0, batch736/1133, batch loss:1.8217349406768335e-06, Training time:90486.81700921059
batch reward last col mean 2.94146502710646e-07 first col mean 3.530370304360986e-05 all mean 7.539179591731227e-07
rl training, epoch3, iter0, batch737/1133, batch loss:8.574592129662051e-07, Training time:90514.1175673008
batch reward last col mean 1.9896458525181515e-06 first col mean 5.657653309754096e-05 all mean 3.6665223888121545e-06
rl training, epoch3, iter0, batch738/1133, batch loss:2.6107107260031626e-05, Training time:90541.22435617447
batch reward last col mean 8.84877579210297e-07 first col mean 1.558722033223603e-05 all mean 2.2709389213559916e-06
rl training, epoch3, iter0, batch739/1133, batch loss:2.9241313313832507e-05, Training time:90568.60361146927
batch reward last col mean 4.531081685854588e-06 first col mean 2.4415285224677064e-06 all mean 4.461404387257062e-06
rl training, epoch3, iter0, batch740/1133, batch loss:2.3726806830381975e-06, Training time:90596.07286643982
batch reward last col mean 3.0583782063331455e-05 first col mean 6.703636245219968e-06 all mean 3.034573092008941e-05
rl training, epoch3, iter0, batch741/1133, batch loss:1.1797192200901918e-05, Training time:90623.58840966225
batch reward last col mean 4.5922593017166946e-07 first col mean 1.0150258276553359e-05 all mean 6.411478352674749e-07
rl training, epoch3, iter0, batch742/1133, batch loss:6.41824044578243e-07, Training time:90651.33140873909
batch reward last col mean 7.031309792182583e-07 first col mean 2.181132913392503e-06 all mean 1.1229404890400474e-06
rl training, epoch3, iter0, batch743/1133, batch loss:2.470276740496047e-06, Training time:90678.62277364731
batch reward last col mean 3.5695020983439463e-07 first col mean 0.00011556069512153044 all mean 1.541456867926172e-06
rl training, epoch3, iter0, batch744/1133, batch loss:8.077937536654645e-07, Training time:90705.98300385475
batch reward last col mean 5.188773570807825e-07 first col mean 7.686789467697963e-05 all mean 2.4452492652926594e-06
rl training, epoch3, iter0, batch745/1133, batch loss:1.2013662853860296e-05, Training time:90732.96105909348
batch reward last col mean 6.124857918621274e-07 first col mean 7.437524800479878e-06 all mean 8.255792636191472e-07
rl training, epoch3, iter0, batch746/1133, batch loss:3.6099877434025984e-06, Training time:90760.72954416275
batch reward last col mean 0.00021845159062650055 first col mean 8.505061487085186e-06 all mean 0.00020178347767796367
rl training, epoch3, iter0, batch747/1133, batch loss:0.00023244268959388137, Training time:90788.13631463051
batch reward last col mean 1.1354104572092183e-06 first col mean 1.1541812909854343e-06 all mean 1.3695521374756936e-06
rl training, epoch3, iter0, batch748/1133, batch loss:1.8550647382653551e-06, Training time:90815.40697669983
batch reward last col mean 2.533843996843643e-07 first col mean 5.343418933989597e-07 all mean 2.8300698318162176e-07
rl training, epoch3, iter0, batch749/1133, batch loss:4.941155111737316e-07, Training time:90843.00737929344
batch reward last col mean 2.7386190595279913e-06 first col mean 1.4634238141297828e-06 all mean 3.840868430415867e-06
rl training, epoch3, iter0, batch750/1133, batch loss:1.5517191059188917e-05, Training time:90870.53811407089
batch reward last col mean 7.574356459372211e-06 first col mean 4.807581353816204e-05 all mean 1.8755594282993115e-05
rl training, epoch3, iter0, batch751/1133, batch loss:0.0008239944581873715, Training time:90898.00527763367
batch reward last col mean 5.35368826604099e-06 first col mean 1.0509920684853569e-06 all mean 1.6969823263934813e-05
rl training, epoch3, iter0, batch752/1133, batch loss:0.00013171686441637576, Training time:90925.49646162987
batch reward last col mean 0.0005987150361761451 first col mean 8.098610123852268e-06 all mean 0.0005928717437200248
rl training, epoch3, iter0, batch753/1133, batch loss:0.0001236512907780707, Training time:90952.66829776764
batch reward last col mean 3.7412460187624674e-06 first col mean 0.00019801914459094405 all mean 6.898069841554388e-06
rl training, epoch3, iter0, batch754/1133, batch loss:5.9376620811235625e-06, Training time:90980.12711763382
batch reward last col mean 5.449329592011054e-07 first col mean 9.184926057059783e-06 all mean 6.555539471264638e-07
rl training, epoch3, iter0, batch755/1133, batch loss:5.246195087238448e-07, Training time:91007.65209960938
batch reward last col mean 1.8031594208878232e-06 first col mean 5.338943810784258e-05 all mean 4.6242235839599743e-05
rl training, epoch3, iter0, batch756/1133, batch loss:0.00031615624902769923, Training time:91035.01583385468
batch reward last col mean 0.00045979995047673583 first col mean 4.6486449718941e-05 all mean 0.00044312726822681725
rl training, epoch3, iter0, batch757/1133, batch loss:0.0002079906698781997, Training time:91062.46703600883
batch reward last col mean 4.199372938273882e-07 first col mean 3.99804503103951e-06 all mean 5.648057026519382e-07
rl training, epoch3, iter0, batch758/1133, batch loss:2.1393168481154134e-06, Training time:91089.57413554192
batch reward last col mean 1.3547389698942425e-06 first col mean 1.1397337402740959e-05 all mean 2.1867074337933445e-06
rl training, epoch3, iter0, batch759/1133, batch loss:1.5019584679976106e-05, Training time:91116.84978723526
batch reward last col mean 2.3852562662796117e-06 first col mean 1.4898174413247034e-05 all mean 7.4491413215582725e-06
rl training, epoch3, iter0, batch760/1133, batch loss:1.4793830814596731e-05, Training time:91144.1300702095
batch reward last col mean 1.7063979385056882e-06 first col mean 3.7489248825295363e-06 all mean 9.211657925334293e-06
rl training, epoch3, iter0, batch761/1133, batch loss:5.0501039368100464e-05, Training time:91171.47984266281
batch reward last col mean 5.334527486411389e-06 first col mean 6.776279406039976e-06 all mean 7.975735570653342e-06
rl training, epoch3, iter0, batch762/1133, batch loss:4.050519692100352e-06, Training time:91198.83956599236
batch reward last col mean 3.0189445965334016e-07 first col mean 7.369155355263501e-06 all mean 4.114733371807233e-07
rl training, epoch3, iter0, batch763/1133, batch loss:5.569006020778033e-07, Training time:91225.88665246964
batch reward last col mean 1.345991222478915e-06 first col mean 3.8107525597297354e-06 all mean 1.4853781067358796e-06
rl training, epoch3, iter0, batch764/1133, batch loss:1.110829316530726e-06, Training time:91253.13346767426
batch reward last col mean 0.00010718151315813884 first col mean 4.984854967915453e-06 all mean 9.959203453036025e-05
rl training, epoch3, iter0, batch765/1133, batch loss:8.50363721838221e-05, Training time:91280.62246990204
batch reward last col mean 9.10023954929784e-05 first col mean 0.0019717158284038305 all mean 0.00010688789188861847
rl training, epoch3, iter0, batch766/1133, batch loss:0.00010255706729367375, Training time:91308.3014228344
batch reward last col mean 3.629429784268723e-06 first col mean 3.0738469831703696e-06 all mean 3.6465075936575886e-06
rl training, epoch3, iter0, batch767/1133, batch loss:6.935755436643376e-07, Training time:91335.7487206459
batch reward last col mean 0.00029124808497726917 first col mean 1.24194912132225e-06 all mean 0.00028723524883389473
rl training, epoch3, iter0, batch768/1133, batch loss:7.033068686723709e-05, Training time:91363.21168065071
batch reward last col mean 4.300985165173188e-05 first col mean 8.728396210244682e-07 all mean 4.33455643360503e-05
rl training, epoch3, iter0, batch769/1133, batch loss:1.803470149752684e-05, Training time:91390.79111933708
batch reward last col mean 3.1207789561449317e-06 first col mean 1.6789030269137584e-05 all mean 3.32083914145187e-06
rl training, epoch3, iter0, batch770/1133, batch loss:3.3787118809414096e-06, Training time:91418.08624577522
batch reward last col mean 3.361955407399364e-07 first col mean 2.950349426100729e-06 all mean 1.2110715488233836e-06
rl training, epoch3, iter0, batch771/1133, batch loss:2.8858410132670542e-06, Training time:91445.49515247345
batch reward last col mean 5.222102004154294e-07 first col mean 1.1240630328757106e-06 all mean 6.540981303260196e-07
rl training, epoch3, iter0, batch772/1133, batch loss:3.4059839890687726e-06, Training time:91473.47110295296
batch reward last col mean 3.553084525265149e-06 first col mean 1.737627462716773e-05 all mean 4.038940005557379e-06
rl training, epoch3, iter0, batch773/1133, batch loss:7.271747108461568e-06, Training time:91503.29351115227
batch reward last col mean 1.1706946679623798e-05 first col mean 9.030001820065081e-06 all mean 1.1085478945460636e-05
rl training, epoch3, iter0, batch774/1133, batch loss:3.731393235284486e-06, Training time:91532.97839808464
batch reward last col mean 2.8993647447350668e-06 first col mean 0.00011904894927283749 all mean 2.3138229153119028e-05
rl training, epoch3, iter0, batch775/1133, batch loss:0.0010333837708458304, Training time:91562.57906270027
batch reward last col mean 8.89452678620728e-07 first col mean 6.55706571706105e-06 all mean 6.7695150391955394e-06
rl training, epoch3, iter0, batch776/1133, batch loss:7.762968743918464e-05, Training time:91592.23065710068
batch reward last col mean 0.0001635250955587253 first col mean 0.0007065011304803193 all mean 0.00015937915304675698
rl training, epoch3, iter0, batch777/1133, batch loss:0.00011711539991665632, Training time:91622.00990986824
batch reward last col mean 8.144460252879071e-07 first col mean 6.145951920188963e-05 all mean 4.148249445279362e-06
rl training, epoch3, iter0, batch778/1133, batch loss:1.065146079781698e-05, Training time:91651.73929786682
batch reward last col mean 0.000429310166509822 first col mean 0.0001096223495551385 all mean 0.00042351961019448936
rl training, epoch3, iter0, batch779/1133, batch loss:9.784923167899251e-05, Training time:91680.90221381187
batch reward last col mean 0.00013053198927082121 first col mean 2.484275864844676e-05 all mean 0.00012575151049531996
rl training, epoch3, iter0, batch780/1133, batch loss:9.829175542108715e-05, Training time:91710.2498345375
batch reward last col mean 1.6393693158534006e-06 first col mean 1.419319005435682e-06 all mean 1.6551266526221298e-06
rl training, epoch3, iter0, batch781/1133, batch loss:2.0933816813339945e-06, Training time:91740.65493917465
batch reward last col mean 6.250380465644412e-06 first col mean 1.0953321179840714e-05 all mean 6.342288997984724e-06
rl training, epoch3, iter0, batch782/1133, batch loss:7.507311238441616e-06, Training time:91770.74037003517
batch reward last col mean 7.196491651484394e-07 first col mean 1.872703796834685e-05 all mean 3.1958124964148737e-06
rl training, epoch3, iter0, batch783/1133, batch loss:2.6920577511191368e-05, Training time:91800.86524963379
batch reward last col mean 7.013812819423038e-07 first col mean 2.8860793463536538e-05 all mean 9.682107702246867e-07
rl training, epoch3, iter0, batch784/1133, batch loss:7.559719051641878e-06, Training time:91830.8347594738
batch reward last col mean 2.3317292288993485e-05 first col mean 1.5122257536859252e-05 all mean 2.259591201436706e-05
rl training, epoch3, iter0, batch785/1133, batch loss:4.939738573739305e-06, Training time:91861.71775221825
batch reward last col mean 1.9628314475994557e-06 first col mean 9.990669695980614e-07 all mean 3.842528712993953e-06
rl training, epoch3, iter0, batch786/1133, batch loss:4.755312329507433e-05, Training time:91890.99574351311
batch reward last col mean 5.915097972319927e-06 first col mean 8.073488402260409e-07 all mean 1.1395256478863303e-05
rl training, epoch3, iter0, batch787/1133, batch loss:0.00022758949489798397, Training time:91920.90037322044
batch reward last col mean 1.008742060548684e-06 first col mean 4.415406237967545e-06 all mean 3.1821402899367968e-06
rl training, epoch3, iter0, batch788/1133, batch loss:5.56061831957777e-06, Training time:91951.04496765137
batch reward last col mean 2.486516450517229e-07 first col mean 6.435740033339243e-06 all mean 4.792152026311669e-07
rl training, epoch3, iter0, batch789/1133, batch loss:5.351150775823044e-06, Training time:91981.21993732452
batch reward last col mean 1.1184632967342623e-05 first col mean 7.497470505768433e-06 all mean 1.0962300621031318e-05
rl training, epoch3, iter0, batch790/1133, batch loss:7.953651220304891e-06, Training time:92011.05977129936
batch reward last col mean 6.674959877273068e-05 first col mean 7.557657681900309e-06 all mean 6.482022581622005e-05
rl training, epoch3, iter0, batch791/1133, batch loss:1.1143200936203357e-05, Training time:92041.00331068039
batch reward last col mean 2.0032107386214193e-06 first col mean 0.00044463982339948416 all mean 6.586538347619353e-06
rl training, epoch3, iter0, batch792/1133, batch loss:5.87112617722596e-06, Training time:92071.09416627884
batch reward last col mean 7.142851245589554e-05 first col mean 7.423040369758382e-05 all mean 7.462865323759615e-05
rl training, epoch3, iter0, batch793/1133, batch loss:0.00028927676612511277, Training time:92102.00851535797
batch reward last col mean 6.8187841861799825e-06 first col mean 1.0355920494475868e-06 all mean 6.667248726444086e-06
rl training, epoch3, iter0, batch794/1133, batch loss:4.7890607675071806e-06, Training time:92132.198294878
batch reward last col mean 1.415447059116559e-06 first col mean 2.050828879873734e-05 all mean 4.213025022181682e-06
rl training, epoch3, iter0, batch795/1133, batch loss:9.334889000456315e-06, Training time:92161.91218805313
batch reward last col mean 1.0801732059917413e-05 first col mean 6.261083035496995e-05 all mean 1.0972462405334227e-05
rl training, epoch3, iter0, batch796/1133, batch loss:7.59691192797618e-06, Training time:92192.08693742752
batch reward last col mean 1.1830672974610934e-06 first col mean 3.250411828048527e-05 all mean 2.3544291252619587e-05
rl training, epoch3, iter0, batch797/1133, batch loss:0.0002101787831634283, Training time:92222.18959903717
batch reward last col mean 7.861913218221162e-07 first col mean 6.162703812151449e-06 all mean 8.774757702667557e-07
rl training, epoch3, iter0, batch798/1133, batch loss:8.621678375675401e-07, Training time:92253.16337132454
batch reward last col mean 3.2105666036841285e-07 first col mean 1.8735966023086803e-06 all mean 3.4790519976013456e-07
rl training, epoch3, iter0, batch799/1133, batch loss:2.5566365025042614e-07, Training time:92282.80595302582
batch reward last col mean 1.0449462934047915e-05 first col mean 2.6482036901143147e-06 all mean 1.0213297173322644e-05
rl training, epoch3, iter0, batch800/1133, batch loss:1.4976548300182912e-05, Training time:92312.83097815514
batch reward last col mean 7.02604268099094e-07 first col mean 2.868635192498914e-06 all mean 7.765233931422699e-07
rl training, epoch3, iter0, batch801/1133, batch loss:8.612789770268137e-07, Training time:92342.42975115776
batch reward last col mean 2.093212060572114e-05 first col mean 6.2961262301541865e-06 all mean 2.032920383499004e-05
rl training, epoch3, iter0, batch802/1133, batch loss:1.4116860256763175e-05, Training time:92373.13409948349
batch reward last col mean 4.4729490582540166e-06 first col mean 6.3546999626851175e-06 all mean 4.966899268765701e-06
rl training, epoch3, iter0, batch803/1133, batch loss:1.5734631233499385e-05, Training time:92403.45544075966
batch reward last col mean 2.1203234155109385e-06 first col mean 1.1309357432764955e-06 all mean 2.1921805455349386e-06
rl training, epoch3, iter0, batch804/1133, batch loss:2.3914824396342738e-06, Training time:92433.98156476021
batch reward last col mean 0.0001139539381256327 first col mean 1.0245124940411188e-05 all mean 0.00015283483662642539
rl training, epoch3, iter0, batch805/1133, batch loss:0.0012376090744510293, Training time:92464.74330711365
batch reward last col mean 1.3949338608654216e-05 first col mean 8.02082649897784e-06 all mean 1.3786501767754089e-05
rl training, epoch3, iter0, batch806/1133, batch loss:1.0134430340258405e-05, Training time:92494.02761936188
batch reward last col mean 9.414571832166985e-05 first col mean 4.248262825967686e-07 all mean 9.315840725321323e-05
rl training, epoch3, iter0, batch807/1133, batch loss:4.2260402551619336e-05, Training time:92524.60314941406
batch reward last col mean 0.0002762613876257092 first col mean 2.383243918302469e-05 all mean 0.0002924225409515202
rl training, epoch3, iter0, batch808/1133, batch loss:0.001083895331248641, Training time:92554.49497532845
batch reward last col mean 0.00014864790136925876 first col mean 0.0004376745782792568 all mean 0.00014944399299565703
rl training, epoch3, iter0, batch809/1133, batch loss:0.00029553452623076737, Training time:92584.2067258358
batch reward last col mean 9.211361771122029e-07 first col mean 3.2322135666618124e-05 all mean 1.474756345487549e-06
rl training, epoch3, iter0, batch810/1133, batch loss:5.7915522120310925e-06, Training time:92613.66431546211
batch reward last col mean 0.0018787527224048972 first col mean 9.693001629784703e-06 all mean 0.0018257360206916928
rl training, epoch3, iter0, batch811/1133, batch loss:0.001633012667298317, Training time:92643.45305347443
batch reward last col mean 0.00031129561830312014 first col mean 9.396968607688905e-07 all mean 0.00031072122510522604
rl training, epoch3, iter0, batch812/1133, batch loss:0.0005906762089580297, Training time:92674.103703022
batch reward last col mean 9.155164661933668e-07 first col mean 1.6757456251070835e-05 all mean 1.2980198107470642e-06
rl training, epoch3, iter0, batch813/1133, batch loss:2.1921455299889203e-06, Training time:92704.14321422577
batch reward last col mean 0.0011947153834626079 first col mean 1.070658618118614e-05 all mean 0.001118923770263791
rl training, epoch3, iter0, batch814/1133, batch loss:0.0002175056142732501, Training time:92734.50429749489
batch reward last col mean 3.385417358003906e-06 first col mean 7.261190330609679e-05 all mean 9.468549251323566e-06
rl training, epoch3, iter0, batch815/1133, batch loss:0.0002622386673465371, Training time:92764.79589033127
batch reward last col mean 3.646998266049195e-06 first col mean 0.00010331439989386126 all mean 5.100586349726655e-06
rl training, epoch3, iter0, batch816/1133, batch loss:2.1221479983069003e-05, Training time:92794.59369373322
batch reward last col mean 7.122127863112837e-05 first col mean 4.458403964235913e-06 all mean 7.062764052534476e-05
rl training, epoch3, iter0, batch817/1133, batch loss:1.6932806829572655e-05, Training time:92824.66989803314
batch reward last col mean 0.00017138288239948452 first col mean 1.8565867776487721e-06 all mean 0.00016724852321203798
rl training, epoch3, iter0, batch818/1133, batch loss:6.467052298830822e-05, Training time:92855.17433047295
batch reward last col mean 1.2999839782423805e-05 first col mean 1.371995676890947e-05 all mean 1.3290889910422266e-05
rl training, epoch3, iter0, batch819/1133, batch loss:8.720769073988777e-06, Training time:92885.15920567513
batch reward last col mean 0.00024547945940867066 first col mean 0.00021169026149436831 all mean 0.00024323578691110015
rl training, epoch3, iter0, batch820/1133, batch loss:0.00010342855239287019, Training time:92915.96847105026
batch reward last col mean 0.0022409057710319757 first col mean 0.0011283312924206257 all mean 0.0022088875994086266
rl training, epoch3, iter0, batch821/1133, batch loss:0.0003466267080511898, Training time:92945.99654126167
batch reward last col mean 1.0288980547557003e-06 first col mean 0.00019250265904702246 all mean 5.99685472479905e-06
rl training, epoch3, iter0, batch822/1133, batch loss:0.0001401174085913226, Training time:92975.62301516533
batch reward last col mean 1.3013074067202979e-06 first col mean 6.10657807555981e-05 all mean 3.365259999554837e-06
rl training, epoch3, iter0, batch823/1133, batch loss:1.9323751985211857e-05, Training time:93004.95281887054
batch reward last col mean 9.562210470903665e-05 first col mean 7.523258773289854e-06 all mean 9.309289453085512e-05
rl training, epoch3, iter0, batch824/1133, batch loss:3.5437591577647254e-05, Training time:93035.67605757713
batch reward last col mean 2.985548780998215e-05 first col mean 1.1752253158192616e-05 all mean 2.9413085940177552e-05
rl training, epoch3, iter0, batch825/1133, batch loss:1.9376717318664305e-05, Training time:93066.15778923035
batch reward last col mean 5.935653007327346e-06 first col mean 8.988057743408717e-06 all mean 7.89542082202388e-06
rl training, epoch3, iter0, batch826/1133, batch loss:4.648989033739781e-06, Training time:93095.94119787216
batch reward last col mean 2.2006879589753225e-05 first col mean 7.943684067868162e-06 all mean 2.1310208467184566e-05
rl training, epoch3, iter0, batch827/1133, batch loss:9.11806091608014e-06, Training time:93125.91105222702
batch reward last col mean 1.436154889233876e-06 first col mean 1.0239332368655596e-05 all mean 6.614178346353583e-06
rl training, epoch3, iter0, batch828/1133, batch loss:0.0003333315544296056, Training time:93155.99289441109
batch reward last col mean 2.0154507183178794e-06 first col mean 5.5898075515870005e-05 all mean 2.7742000838770764e-06
rl training, epoch3, iter0, batch829/1133, batch loss:3.5871382806362817e-06, Training time:93186.99526715279
batch reward last col mean 2.9482032459782204e-06 first col mean 2.3160323507909197e-06 all mean 6.98358599038329e-06
rl training, epoch3, iter0, batch830/1133, batch loss:8.105451342999004e-06, Training time:93217.68664503098
batch reward last col mean 7.205931069620419e-07 first col mean 2.5940112209354993e-06 all mean 2.623113459776505e-06
rl training, epoch3, iter0, batch831/1133, batch loss:6.676478733425029e-06, Training time:93247.16952872276
batch reward last col mean 2.2216256638785126e-06 first col mean 0.0009396123932674527 all mean 1.2101557331334334e-05
rl training, epoch3, iter0, batch832/1133, batch loss:6.71309680910781e-05, Training time:93276.68976807594
batch reward last col mean 4.544639068626566e-06 first col mean 4.2839033994823694e-05 all mean 4.837867891183123e-06
rl training, epoch3, iter0, batch833/1133, batch loss:3.5280843349028146e-06, Training time:93306.1652328968
batch reward last col mean 9.59831231739372e-06 first col mean 7.032022040220909e-07 all mean 1.3560313163907267e-05
rl training, epoch3, iter0, batch834/1133, batch loss:2.1149693566258065e-05, Training time:93335.94373869896
batch reward last col mean 4.740626991406316e-06 first col mean 2.154650928787305e-06 all mean 4.8151359806070104e-06
rl training, epoch3, iter0, batch835/1133, batch loss:5.469511961564422e-06, Training time:93366.16176962852
batch reward last col mean 1.7824262386056944e-06 first col mean 1.5471216102014296e-05 all mean 2.3956520180945517e-06
rl training, epoch3, iter0, batch836/1133, batch loss:4.045442437927704e-06, Training time:93396.15792870522
batch reward last col mean 1.0389699127699714e-06 first col mean 1.4258221199270338e-06 all mean 1.1685488061630167e-06
rl training, epoch3, iter0, batch837/1133, batch loss:1.2451669135771226e-06, Training time:93426.09299874306
batch reward last col mean 5.308545496518491e-06 first col mean 0.00031234469497576356 all mean 2.6142635761061683e-05
rl training, epoch3, iter0, batch838/1133, batch loss:0.0007096354383975267, Training time:93456.24761414528
batch reward last col mean 5.133585000294261e-05 first col mean 8.643831824883819e-05 all mean 5.1973649533465505e-05
rl training, epoch3, iter0, batch839/1133, batch loss:1.0873202882066835e-05, Training time:93487.0637383461
batch reward last col mean 1.1393819931981852e-06 first col mean 6.839939601377409e-07 all mean 1.7418113884559716e-06
rl training, epoch3, iter0, batch840/1133, batch loss:8.179980795830488e-06, Training time:93517.8592364788
batch reward last col mean 4.5597926146001555e-07 first col mean 1.033861826726934e-05 all mean 5.4977140280243475e-06
rl training, epoch3, iter0, batch841/1133, batch loss:4.215396984363906e-05, Training time:93548.11673259735
batch reward last col mean 9.069171937881038e-07 first col mean 7.612389936184627e-07 all mean 1.2034287237838726e-06
rl training, epoch3, iter0, batch842/1133, batch loss:1.7527953559692833e-06, Training time:93578.16042256355
batch reward last col mean 1.422642412762798e-06 first col mean 1.4546854799846187e-05 all mean 7.4049144132004585e-06
rl training, epoch3, iter0, batch843/1133, batch loss:0.00016259824042208493, Training time:93608.47045707703
batch reward last col mean 0.0001009114203043282 first col mean 7.626183651154861e-05 all mean 0.00010014784493250772
rl training, epoch3, iter0, batch844/1133, batch loss:3.537855081958696e-05, Training time:93638.71061444283
batch reward last col mean 1.8927656810774351e-06 first col mean 1.670328128966503e-05 all mean 2.2075107608543476e-06
rl training, epoch3, iter0, batch845/1133, batch loss:5.430330020317342e-06, Training time:93669.05665326118
batch reward last col mean 7.132810537768819e-07 first col mean 7.711013495281804e-06 all mean 1.4078200365474913e-06
rl training, epoch3, iter0, batch846/1133, batch loss:5.40006749361055e-06, Training time:93698.2744936943
batch reward last col mean 6.598089044018707e-07 first col mean 0.0001050421706167981 all mean 4.54131168226013e-06
rl training, epoch3, iter0, batch847/1133, batch loss:1.840720506152138e-05, Training time:93728.20730829239
batch reward last col mean 2.689837174330023e-06 first col mean 4.76765344501473e-05 all mean 8.978433470474556e-06
rl training, epoch3, iter0, batch848/1133, batch loss:0.000286615191726014, Training time:93758.87609696388
batch reward last col mean 9.098802138396422e-07 first col mean 0.0020013742614537477 all mean 2.126707840943709e-05
rl training, epoch3, iter0, batch849/1133, batch loss:0.0007553044124506414, Training time:93788.12123084068
batch reward last col mean 3.516156994010089e-06 first col mean 1.8930006262962706e-05 all mean 3.5022285373997875e-06
rl training, epoch3, iter0, batch850/1133, batch loss:2.9711081879213452e-06, Training time:93817.99890756607
batch reward last col mean 2.222559032816207e-06 first col mean 0.0005682024639099836 all mean 1.578627052367665e-05
rl training, epoch3, iter0, batch851/1133, batch loss:9.00944578461349e-05, Training time:93847.88949275017
batch reward last col mean 3.242263630909292e-07 first col mean 1.1265730790910311e-05 all mean 4.532709283466829e-07
rl training, epoch3, iter0, batch852/1133, batch loss:5.073377451481065e-07, Training time:93877.98191523552
batch reward last col mean 6.775653673685156e-07 first col mean 1.8740523955784738e-05 all mean 5.314796908351127e-06
rl training, epoch3, iter0, batch853/1133, batch loss:0.00015962732140906155, Training time:93907.73415279388
batch reward last col mean 3.0148021323839203e-06 first col mean 4.6121504055918194e-06 all mean 3.114281525995466e-06
rl training, epoch3, iter0, batch854/1133, batch loss:6.454933554778108e-06, Training time:93938.13899731636
batch reward last col mean 1.17902322926966e-06 first col mean 0.0008700807229615748 all mean 1.052718380378792e-05
rl training, epoch3, iter0, batch855/1133, batch loss:2.455800313327927e-05, Training time:93968.03147864342
batch reward last col mean 0.00012035286636091769 first col mean 4.481576615944505e-05 all mean 0.00011989049380645156
rl training, epoch3, iter0, batch856/1133, batch loss:4.725648250314407e-05, Training time:93998.18667507172
batch reward last col mean 3.7398865515569923e-07 first col mean 1.8582732081995346e-06 all mean 4.3073006850136153e-07
rl training, epoch3, iter0, batch857/1133, batch loss:9.685634267952992e-07, Training time:94028.83343601227
batch reward last col mean 3.2579785056441324e-06 first col mean 2.384857907600235e-06 all mean 3.7655247524526203e-06
rl training, epoch3, iter0, batch858/1133, batch loss:1.3869514987163711e-05, Training time:94058.49105262756
batch reward last col mean 3.784888349400717e-07 first col mean 2.690344899747288e-06 all mean 6.63821936086606e-07
rl training, epoch3, iter0, batch859/1133, batch loss:1.7305306982962065e-06, Training time:94088.99312663078
batch reward last col mean 1.5958883068378782e-06 first col mean 1.536783315714274e-06 all mean 8.016828360268846e-06
rl training, epoch3, iter0, batch860/1133, batch loss:7.18186201993376e-05, Training time:94119.14964985847
batch reward last col mean 4.757271199196111e-06 first col mean 4.872178578807507e-06 all mean 5.078430149296764e-06
rl training, epoch3, iter0, batch861/1133, batch loss:3.4927747947222088e-06, Training time:94149.76655077934
batch reward last col mean 5.783032293038559e-07 first col mean 5.356639303499833e-05 all mean 1.704777560007642e-06
rl training, epoch3, iter0, batch862/1133, batch loss:1.0438485332997516e-05, Training time:94179.59477114677
batch reward last col mean 2.4591104192950297e-06 first col mean 0.0004936982877552509 all mean 8.203491233871318e-06
rl training, epoch3, iter0, batch863/1133, batch loss:8.548032383259851e-06, Training time:94209.89746832848
batch reward last col mean 5.701510235667229e-05 first col mean 1.4361701232701307e-06 all mean 5.94789999013301e-05
rl training, epoch3, iter0, batch864/1133, batch loss:7.201515472843312e-06, Training time:94240.461779356
batch reward last col mean 5.078647518530488e-06 first col mean 7.445781193382572e-06 all mean 6.972365099500166e-06
rl training, epoch3, iter0, batch865/1133, batch loss:1.049899947247468e-05, Training time:94269.85999131203
batch reward last col mean 1.932330775389346e-07 first col mean 2.0160829080850817e-05 all mean 5.213918257140904e-07
rl training, epoch3, iter0, batch866/1133, batch loss:9.302895023211022e-07, Training time:94300.12413406372
batch reward last col mean 2.3898694053059444e-05 first col mean 2.6409977635921678e-06 all mean 5.1127462938893586e-05
rl training, epoch3, iter0, batch867/1133, batch loss:0.0008013861952349544, Training time:94329.42320466042
batch reward last col mean 2.746412292253808e-06 first col mean 1.9732604414457455e-05 all mean 2.989673703268636e-06
rl training, epoch3, iter0, batch868/1133, batch loss:2.917658093792852e-06, Training time:94359.12866973877
batch reward last col mean 0.0010604000417515635 first col mean 0.0010680407285690308 all mean 0.0010609630262479186
rl training, epoch3, iter0, batch869/1133, batch loss:0.00044315162813290954, Training time:94389.16770553589
batch reward last col mean 7.744400500087067e-05 first col mean 0.0003685501287691295 all mean 8.055624493863434e-05
rl training, epoch3, iter0, batch870/1133, batch loss:2.3411046640831046e-05, Training time:94420.16333079338
batch reward last col mean 4.4571157786776894e-07 first col mean 2.5162373276543804e-05 all mean 8.145872811837762e-07
rl training, epoch3, iter0, batch871/1133, batch loss:5.720180070056813e-06, Training time:94450.87865281105
batch reward last col mean 1.1359506970620714e-06 first col mean 6.5332010308338795e-06 all mean 2.5957109755836427e-05
rl training, epoch3, iter0, batch872/1133, batch loss:0.00040188388084061444, Training time:94480.47850489616
batch reward last col mean 2.3214802240545396e-06 first col mean 7.308163731067907e-06 all mean 2.858765810742625e-06
rl training, epoch3, iter0, batch873/1133, batch loss:2.4089813450700603e-05, Training time:94511.84466791153
batch reward last col mean 2.0280665921745822e-05 first col mean 4.831082151213195e-06 all mean 2.5788740458665416e-05
rl training, epoch3, iter0, batch874/1133, batch loss:1.704120404610876e-05, Training time:94541.06834101677
batch reward last col mean 6.095289108998259e-07 first col mean 0.00016447137750219554 all mean 2.365219415878528e-06
rl training, epoch3, iter0, batch875/1133, batch loss:9.880704055831302e-06, Training time:94572.13146805763
batch reward last col mean 8.102523133857176e-05 first col mean 2.1182928833241021e-07 all mean 7.790623203618452e-05
rl training, epoch3, iter0, batch876/1133, batch loss:3.845581886707805e-05, Training time:94601.89405822754
batch reward last col mean 3.039089961021091e-06 first col mean 1.8615083945405786e-06 all mean 3.0495998544211034e-06
rl training, epoch3, iter0, batch877/1133, batch loss:3.4218835480714915e-06, Training time:94631.48984408379
batch reward last col mean 1.7723722294249455e-06 first col mean 0.00012583316129166633 all mean 8.250139217125252e-06
rl training, epoch3, iter0, batch878/1133, batch loss:4.3988275137962773e-05, Training time:94661.61042022705
batch reward last col mean 3.0107203201623634e-06 first col mean 1.7391290612067678e-06 all mean 2.226464857812971e-05
rl training, epoch3, iter0, batch879/1133, batch loss:0.0004355555574875325, Training time:94691.16272187233
batch reward last col mean 1.787255132512655e-05 first col mean 5.3630992624675855e-06 all mean 1.754329241521191e-05
rl training, epoch3, iter0, batch880/1133, batch loss:1.265686205442762e-05, Training time:94722.00875473022
batch reward last col mean 2.3144814349507215e-06 first col mean 1.555298922539805e-06 all mean 4.427623480296461e-06
rl training, epoch3, iter0, batch881/1133, batch loss:1.6775309177319286e-06, Training time:94751.1152048111
batch reward last col mean 1.185296810035652e-06 first col mean 3.9604246921953745e-06 all mean 1.344009319836914e-06
rl training, epoch3, iter0, batch882/1133, batch loss:1.74503986727359e-06, Training time:94781.16920614243
batch reward last col mean 1.6441676962131169e-06 first col mean 6.751541150151752e-06 all mean 1.6711328498786315e-06
rl training, epoch3, iter0, batch883/1133, batch loss:3.5294169720145874e-06, Training time:94811.38039827347
batch reward last col mean 3.4737479381874437e-07 first col mean 1.1798532796092331e-05 all mean 3.634653694462031e-06
rl training, epoch3, iter0, batch884/1133, batch loss:2.692124098757631e-06, Training time:94840.81290197372
batch reward last col mean 7.612015906488523e-05 first col mean 0.00015226857794914395 all mean 7.642024866072461e-05
rl training, epoch3, iter0, batch885/1133, batch loss:7.897478644736111e-05, Training time:94870.82872748375
batch reward last col mean 9.550986987960641e-07 first col mean 2.1092177121317945e-05 all mean 1.256563905371877e-06
rl training, epoch3, iter0, batch886/1133, batch loss:1.5942218851705547e-06, Training time:94900.56471681595
batch reward last col mean 0.0007295140530914068 first col mean 5.355638131732121e-05 all mean 0.0007152873440645635
rl training, epoch3, iter0, batch887/1133, batch loss:0.0004024702066089958, Training time:94930.64358568192
batch reward last col mean 3.569126420188695e-06 first col mean 4.036398422613274e-06 all mean 4.419326614879537e-06
rl training, epoch3, iter0, batch888/1133, batch loss:2.2889837055117823e-05, Training time:94961.379124403
batch reward last col mean 1.9469594917609356e-05 first col mean 7.921881319816748e-07 all mean 1.8598815586301498e-05
rl training, epoch3, iter0, batch889/1133, batch loss:9.22355775401229e-06, Training time:94991.70803809166
batch reward last col mean 2.5821867893682793e-05 first col mean 0.00015281060768757015 all mean 2.632986070238985e-05
rl training, epoch3, iter0, batch890/1133, batch loss:5.687832071998855e-06, Training time:95022.45668816566
batch reward last col mean 2.1776932044303976e-06 first col mean 1.777152283466421e-05 all mean 1.6768055502325296e-05
rl training, epoch3, iter0, batch891/1133, batch loss:0.0004487968690227717, Training time:95052.12183260918
batch reward last col mean 1.617306588741485e-05 first col mean 3.5897189718525624e-06 all mean 1.612436244613491e-05
rl training, epoch3, iter0, batch892/1133, batch loss:1.1838445971079636e-05, Training time:95082.30649352074
batch reward last col mean 2.4206285161199048e-05 first col mean 0.0003572729474399239 all mean 2.877836777770426e-05
rl training, epoch3, iter0, batch893/1133, batch loss:1.802890074031893e-05, Training time:95112.80223584175
batch reward last col mean 3.541911610227544e-06 first col mean 7.439161890943069e-06 all mean 6.351837328111287e-06
rl training, epoch3, iter0, batch894/1133, batch loss:5.010757377021946e-05, Training time:95142.65706205368
batch reward last col mean 1.3823809240420815e-05 first col mean 0.0005321658100001514 all mean 5.003082696930505e-05
rl training, epoch3, iter0, batch895/1133, batch loss:0.0013307251501828432, Training time:95174.01262927055
batch reward last col mean 0.00046066471259109676 first col mean 0.001329266931861639 all mean 0.0004789345257449895
rl training, epoch3, iter0, batch896/1133, batch loss:0.00046531285624951124, Training time:95203.67806887627
batch reward last col mean 0.0002525135932955891 first col mean 2.5178882424370386e-05 all mean 0.0002516095992177725
rl training, epoch3, iter0, batch897/1133, batch loss:0.0001488692796556279, Training time:95233.1621272564
batch reward last col mean 0.0005747471004724503 first col mean 3.305324753455352e-06 all mean 0.0005525799933820963
rl training, epoch3, iter0, batch898/1133, batch loss:0.0002207003126386553, Training time:95263.65164446831
batch reward last col mean 3.3994029990935815e-07 first col mean 1.4628778899350436e-06 all mean 3.472132220849744e-06
rl training, epoch3, iter0, batch899/1133, batch loss:6.70877707307227e-05, Training time:95293.10187315941
batch reward last col mean 3.364464873811812e-06 first col mean 0.000193821731954813 all mean 6.208362719917204e-06
rl training, epoch3, iter0, batch900/1133, batch loss:8.432761205767747e-06, Training time:95323.56120371819
batch reward last col mean 1.0802662018249976e-06 first col mean 6.853938430140261e-07 all mean 3.0407525173359318e-06
rl training, epoch3, iter0, batch901/1133, batch loss:3.570061016944237e-05, Training time:95352.7425994873
batch reward last col mean 6.204304554557893e-07 first col mean 1.3570385817729402e-05 all mean 8.881947906047571e-07
rl training, epoch3, iter0, batch902/1133, batch loss:1.2710023611361976e-06, Training time:95382.42229270935
batch reward last col mean 1.0120898878085427e-05 first col mean 0.00020019097428303212 all mean 1.2345141840341967e-05
rl training, epoch3, iter0, batch903/1133, batch loss:8.258406523964368e-06, Training time:95412.16478610039
batch reward last col mean 4.483313659875421e-06 first col mean 1.8170881958212703e-05 all mean 5.388676527218195e-06
rl training, epoch3, iter0, batch904/1133, batch loss:3.085537173319608e-06, Training time:95442.35607099533
batch reward last col mean 6.574236977030523e-06 first col mean 4.518153673416236e-06 all mean 8.023383088584524e-06
rl training, epoch3, iter0, batch905/1133, batch loss:3.6612822441384196e-05, Training time:95472.94595122337
batch reward last col mean 1.5416717360494658e-06 first col mean 1.2433466736183618e-06 all mean 1.4868834341541515e-06
rl training, epoch3, iter0, batch906/1133, batch loss:1.5482612525374861e-06, Training time:95502.60309624672
batch reward last col mean 8.921394965000218e-07 first col mean 5.754762241849676e-06 all mean 4.236736003804253e-06
rl training, epoch3, iter0, batch907/1133, batch loss:2.84165253106039e-06, Training time:95531.16798114777
batch reward last col mean 3.931857463612687e-06 first col mean 4.538901976047782e-06 all mean 8.156321200658567e-06
rl training, epoch3, iter0, batch908/1133, batch loss:0.00012305293057579547, Training time:95560.14219403267
batch reward last col mean 2.447706265229499e-06 first col mean 8.699457976035774e-05 all mean 6.3365719142893795e-06
rl training, epoch3, iter0, batch909/1133, batch loss:5.3399489843286574e-05, Training time:95590.34334683418
batch reward last col mean 0.00011929752508876845 first col mean 0.00020248000510036945 all mean 0.00013094060705043375
rl training, epoch3, iter0, batch910/1133, batch loss:0.0007760211592540145, Training time:95620.35087275505
batch reward last col mean 2.83136955658847e-06 first col mean 4.314921170589514e-05 all mean 5.405537194747012e-06
rl training, epoch3, iter0, batch911/1133, batch loss:3.3153806725749746e-05, Training time:95650.76136732101
batch reward last col mean 4.593618086801143e-06 first col mean 1.2518379435277893e-06 all mean 4.9011700866685715e-06
rl training, epoch3, iter0, batch912/1133, batch loss:4.0019681364356074e-06, Training time:95681.9968111515
batch reward last col mean 5.626569873129483e-06 first col mean 1.0262474461342208e-06 all mean 6.068014499760466e-06
rl training, epoch3, iter0, batch913/1133, batch loss:6.610537184315035e-06, Training time:95710.26604533195
batch reward last col mean 0.0007296972326003015 first col mean 0.0007329101790674031 all mean 0.0007382279727607965
rl training, epoch3, iter0, batch914/1133, batch loss:0.0004978529177606106, Training time:95737.78713798523
batch reward last col mean 8.379010250791907e-05 first col mean 1.8981623725267127e-05 all mean 9.494191908743232e-05
rl training, epoch3, iter0, batch915/1133, batch loss:6.423336162697524e-05, Training time:95765.4273056984
batch reward last col mean 3.304751317045884e-07 first col mean 1.4487466160062468e-06 all mean 1.2781160876329523e-05
rl training, epoch3, iter0, batch916/1133, batch loss:0.00035374664003029466, Training time:95792.58569383621
batch reward last col mean 4.3452037061797455e-05 first col mean 3.602077640607604e-06 all mean 4.538410939858295e-05
rl training, epoch3, iter0, batch917/1133, batch loss:6.438967830035836e-05, Training time:95820.15240907669
batch reward last col mean 4.107289441890316e-06 first col mean 0.0012977349106222391 all mean 1.706558214209508e-05
rl training, epoch3, iter0, batch918/1133, batch loss:3.115170693490654e-05, Training time:95847.44888067245
batch reward last col mean 1.0068050869449507e-05 first col mean 3.077859946643002e-05 all mean 9.901669727696571e-06
rl training, epoch3, iter0, batch919/1133, batch loss:2.0791861970792525e-05, Training time:95874.89612674713
batch reward last col mean 8.692717528901994e-06 first col mean 1.9113167581963353e-06 all mean 8.514904948242474e-06
rl training, epoch3, iter0, batch920/1133, batch loss:5.495516234077513e-06, Training time:95902.26750516891
batch reward last col mean 4.077550693182275e-05 first col mean 1.1424689546402078e-05 all mean 4.076865661772899e-05
rl training, epoch3, iter0, batch921/1133, batch loss:6.460995791712776e-06, Training time:95929.45896482468
batch reward last col mean 2.0246752683306113e-06 first col mean 5.855615199834574e-06 all mean 2.2477918264485197e-06
rl training, epoch3, iter0, batch922/1133, batch loss:1.4663507954537636e-06, Training time:95956.72350549698
batch reward last col mean 3.1417643185704947e-05 first col mean 2.6893601898336783e-05 all mean 3.417895641177893e-05
rl training, epoch3, iter0, batch923/1133, batch loss:3.674057370517403e-05, Training time:95983.93808484077
batch reward last col mean 7.17866328159289e-07 first col mean 1.5131938653212273e-06 all mean 9.22724723295687e-07
rl training, epoch3, iter0, batch924/1133, batch loss:2.36935784414527e-06, Training time:96011.0851175785
batch reward last col mean 0.00013416982255876064 first col mean 0.00010735864634625614 all mean 0.0001327071076957509
rl training, epoch3, iter0, batch925/1133, batch loss:2.9619273846037686e-05, Training time:96038.56571865082
batch reward last col mean 1.2996387340535875e-05 first col mean 2.34968456425122e-06 all mean 4.320569496485405e-05
rl training, epoch3, iter0, batch926/1133, batch loss:0.0011538491817191243, Training time:96065.79640054703
batch reward last col mean 9.123510608333163e-06 first col mean 7.186808034020942e-06 all mean 9.595276424079202e-06
rl training, epoch3, iter0, batch927/1133, batch loss:6.7075966398988385e-06, Training time:96093.17103457451
batch reward last col mean 2.267789795951103e-06 first col mean 0.002448998624458909 all mean 4.195870133116841e-05
rl training, epoch3, iter0, batch928/1133, batch loss:0.0002737398608587682, Training time:96120.61323332787
batch reward last col mean 2.7458645490696654e-06 first col mean 8.353968951269053e-06 all mean 3.691494384838734e-06
rl training, epoch3, iter0, batch929/1133, batch loss:8.07053038442973e-06, Training time:96148.02828764915
batch reward last col mean 3.8691032386850566e-06 first col mean 6.358911832649028e-06 all mean 4.188027560303453e-06
rl training, epoch3, iter0, batch930/1133, batch loss:2.58418526755122e-06, Training time:96175.29634714127
batch reward last col mean 2.3284728740691207e-06 first col mean 1.7299385035585146e-06 all mean 3.0822980079392437e-06
rl training, epoch3, iter0, batch931/1133, batch loss:3.0300499929580837e-05, Training time:96203.26715111732
batch reward last col mean 3.836726136796642e-06 first col mean 7.803536391293164e-06 all mean 7.540194928878918e-06
rl training, epoch3, iter0, batch932/1133, batch loss:2.892365591833368e-05, Training time:96230.64971756935
batch reward last col mean 1.6308210604165652e-07 first col mean 1.6719827726774383e-06 all mean 3.250268036936177e-07
rl training, epoch3, iter0, batch933/1133, batch loss:1.6824666317916126e-06, Training time:96258.38017678261
batch reward last col mean 3.0479295674012974e-05 first col mean 1.2246538972249255e-05 all mean 2.9694294426008128e-05
rl training, epoch3, iter0, batch934/1133, batch loss:2.9699885999434628e-05, Training time:96285.53993606567
batch reward last col mean 4.504560365603538e-06 first col mean 3.5601847230282146e-06 all mean 4.567765699903248e-06
rl training, epoch3, iter0, batch935/1133, batch loss:1.8454378505339264e-06, Training time:96312.92093849182
batch reward last col mean 3.4317401969019556e-06 first col mean 2.7061099899583496e-05 all mean 3.5414743706496665e-06
rl training, epoch3, iter0, batch936/1133, batch loss:2.5890440156217664e-06, Training time:96340.22296094894
batch reward last col mean 3.7579075069515966e-06 first col mean 1.2576051631185692e-05 all mean 5.809337380924262e-06
rl training, epoch3, iter0, batch937/1133, batch loss:1.534769580757711e-05, Training time:96367.47668981552
batch reward last col mean 6.704136467305943e-05 first col mean 4.792943218490109e-05 all mean 6.627466063946486e-05
rl training, epoch3, iter0, batch938/1133, batch loss:1.220381454913877e-05, Training time:96394.80839538574
batch reward last col mean 3.97821804654086e-06 first col mean 0.0003178915358148515 all mean 1.9842102119582705e-05
rl training, epoch3, iter0, batch939/1133, batch loss:1.3681194104719907e-05, Training time:96422.02257823944
batch reward last col mean 1.4297670531959739e-05 first col mean 4.445619561010972e-05 all mean 1.6488007531734183e-05
rl training, epoch3, iter0, batch940/1133, batch loss:4.1802588384598494e-05, Training time:96449.3703751564
batch reward last col mean 0.0003076799039263278 first col mean 0.0003848339256364852 all mean 0.0003096149011980742
rl training, epoch3, iter0, batch941/1133, batch loss:0.0001505236723460257, Training time:96476.93063616753
batch reward last col mean 2.516953543363343e-07 first col mean 1.2694063116214238e-06 all mean 3.23963263326732e-07
rl training, epoch3, iter0, batch942/1133, batch loss:7.79210097334726e-07, Training time:96504.43869519234
batch reward last col mean 0.007641865871846676 first col mean 1.3361513993004337e-06 all mean 0.007042356301099062
rl training, epoch3, iter0, batch943/1133, batch loss:0.004727534018456936, Training time:96531.91550636292
batch reward last col mean 1.6079186480055796e-06 first col mean 6.783183835068485e-06 all mean 4.573704700305825e-06
rl training, epoch3, iter0, batch944/1133, batch loss:4.573186015477404e-05, Training time:96558.96687841415
batch reward last col mean 1.0168314474867657e-06 first col mean 0.0016091179568320513 all mean 2.0965933799743652e-05
rl training, epoch3, iter0, batch945/1133, batch loss:1.4345106137625407e-05, Training time:96586.22816562653
batch reward last col mean 0.0015675569884479046 first col mean 0.0015766744036227465 all mean 0.001585973659530282
rl training, epoch3, iter0, batch946/1133, batch loss:0.000496871187351644, Training time:96613.65612578392
batch reward last col mean 0.0001005456069833599 first col mean 0.0016481903148815036 all mean 0.00011763558723032475
rl training, epoch3, iter0, batch947/1133, batch loss:0.00022032040578778833, Training time:96641.02474212646
batch reward last col mean 0.001685352879576385 first col mean 0.0014353872975334525 all mean 0.0016898115864023566
rl training, epoch3, iter0, batch948/1133, batch loss:0.0011063150595873594, Training time:96668.6054353714
batch reward last col mean 1.4927454685675912e-05 first col mean 2.4039350137172733e-06 all mean 1.3473464605340268e-05
rl training, epoch3, iter0, batch949/1133, batch loss:9.702160241431557e-06, Training time:96695.9911763668
batch reward last col mean 2.223532646894455e-06 first col mean 4.05277614845545e-06 all mean 2.453089109621942e-06
rl training, epoch3, iter0, batch950/1133, batch loss:2.3242391762323678e-06, Training time:96723.25547933578
batch reward last col mean 1.731669499349664e-06 first col mean 2.5543884021317353e-06 all mean 3.4286811114725424e-06
rl training, epoch3, iter0, batch951/1133, batch loss:1.8928907593362965e-05, Training time:96750.50697040558
batch reward last col mean 5.913297172810417e-06 first col mean 7.926052057882771e-05 all mean 1.984680784516968e-05
rl training, epoch3, iter0, batch952/1133, batch loss:2.5937024474842474e-05, Training time:96777.71176457405
batch reward last col mean 4.445790636964375e-06 first col mean 5.181859251024434e-06 all mean 5.350772880774457e-06
rl training, epoch3, iter0, batch953/1133, batch loss:1.9857710867654532e-05, Training time:96805.47197389603
batch reward last col mean 1.4199754332366865e-06 first col mean 0.00022688602621201426 all mean 5.154818154551322e-06
rl training, epoch3, iter0, batch954/1133, batch loss:3.271002788096666e-05, Training time:96832.82809400558
batch reward last col mean 2.9030618406977737e-06 first col mean 1.6182031686184928e-05 all mean 1.4510924302157946e-05
rl training, epoch3, iter0, batch955/1133, batch loss:0.00010845118231372908, Training time:96860.15968155861
batch reward last col mean 3.354438831593143e-06 first col mean 1.5598770914948545e-05 all mean 6.1786304286215454e-06
rl training, epoch3, iter0, batch956/1133, batch loss:9.620298442314379e-06, Training time:96887.38684940338
batch reward last col mean 9.741994517753483e-07 first col mean 0.0022050661500543356 all mean 2.3397657059831545e-05
rl training, epoch3, iter0, batch957/1133, batch loss:2.2727377654518932e-05, Training time:96914.61657476425
batch reward last col mean 6.059322458895622e-06 first col mean 8.566820724809077e-06 all mean 2.1874175217817537e-05
rl training, epoch3, iter0, batch958/1133, batch loss:3.3388612791895866e-05, Training time:96942.36857962608
batch reward last col mean 1.1231022654101253e-05 first col mean 3.0995252018328756e-05 all mean 1.403477381245466e-05
rl training, epoch3, iter0, batch959/1133, batch loss:1.1634945622063242e-05, Training time:96969.71089529991
batch reward last col mean 1.2688506956237688e-07 first col mean 2.9805376016156515e-06 all mean 3.6574709838532726e-07
rl training, epoch3, iter0, batch960/1133, batch loss:1.591019213265099e-06, Training time:96996.92533874512
batch reward last col mean 0.00013244824367575347 first col mean 4.012076260551112e-06 all mean 0.0001295871043112129
rl training, epoch3, iter0, batch961/1133, batch loss:7.329447544179857e-05, Training time:97024.5232720375
batch reward last col mean 0.00012513843830674887 first col mean 2.334191231057048e-05 all mean 0.0001247878826688975
rl training, epoch3, iter0, batch962/1133, batch loss:3.955211286665872e-05, Training time:97051.6883456707
batch reward last col mean 8.296715918731934e-07 first col mean 1.2090903510397766e-05 all mean 9.513059922028333e-06
rl training, epoch3, iter0, batch963/1133, batch loss:2.1861549612367526e-05, Training time:97079.27027392387
batch reward last col mean 0.007776797283440828 first col mean 0.00014845107216387987 all mean 0.007669288199394941
rl training, epoch3, iter0, batch964/1133, batch loss:0.00465980963781476, Training time:97106.57376122475
batch reward last col mean 2.2004262064001523e-05 first col mean 0.00025147214182652533 all mean 2.7468649932416156e-05
rl training, epoch3, iter0, batch965/1133, batch loss:6.594243313884363e-05, Training time:97133.5744125843
batch reward last col mean 1.4018680303706788e-05 first col mean 6.022511570336064e-06 all mean 1.436001002730336e-05
rl training, epoch3, iter0, batch966/1133, batch loss:1.0185184692090843e-05, Training time:97160.97936153412
batch reward last col mean 7.079856459313305e-06 first col mean 3.739420571946539e-05 all mean 7.808134796505328e-06
rl training, epoch3, iter0, batch967/1133, batch loss:1.0397307960374746e-05, Training time:97188.0835223198
batch reward last col mean 1.6335038708348293e-06 first col mean 0.00014382346125785261 all mean 2.1661589926225133e-05
rl training, epoch3, iter0, batch968/1133, batch loss:0.0002501111011952162, Training time:97215.20632266998
batch reward last col mean 4.026874648843659e-06 first col mean 6.305702117970213e-05 all mean 4.74141916129156e-06
rl training, epoch3, iter0, batch969/1133, batch loss:6.009991466271458e-06, Training time:97242.69948410988
batch reward last col mean 1.160695092039532e-06 first col mean 2.948838073280058e-06 all mean 1.7267176417590235e-06
rl training, epoch3, iter0, batch970/1133, batch loss:7.498824743379373e-06, Training time:97270.02383351326
batch reward last col mean 1.9858875930367503e-06 first col mean 6.173922884045169e-06 all mean 3.427430328883929e-06
rl training, epoch3, iter0, batch971/1133, batch loss:2.3476479327655397e-05, Training time:97297.42299079895
batch reward last col mean 9.567389724907116e-07 first col mean 2.0565596514643403e-06 all mean 4.300030923332088e-06
rl training, epoch3, iter0, batch972/1133, batch loss:1.2221705219417345e-05, Training time:97324.58835053444
batch reward last col mean 0.00743923569098115 first col mean 0.0004891659482382238 all mean 0.007238361053168774
rl training, epoch3, iter0, batch973/1133, batch loss:0.0010903746588155627, Training time:97351.94726991653
batch reward last col mean 1.2156177717770333e-06 first col mean 3.3667729439912364e-05 all mean 1.2666909242398106e-05
rl training, epoch3, iter0, batch974/1133, batch loss:0.00012158858589828014, Training time:97379.44759583473
batch reward last col mean 3.3121591513918247e-06 first col mean 1.615129440324381e-05 all mean 3.913881300832145e-06
rl training, epoch3, iter0, batch975/1133, batch loss:9.203364243148826e-06, Training time:97406.88082742691
batch reward last col mean 2.714804395509418e-05 first col mean 9.370825864607468e-06 all mean 3.2540418033022434e-05
rl training, epoch3, iter0, batch976/1133, batch loss:0.0001446667010895908, Training time:97434.38372182846
batch reward last col mean 4.268907559890067e-06 first col mean 5.6725702961557545e-06 all mean 4.423746759130154e-06
rl training, epoch3, iter0, batch977/1133, batch loss:4.012150839116657e-06, Training time:97461.67055392265
batch reward last col mean 3.631381332525052e-05 first col mean 9.45376177696744e-06 all mean 3.915907655027695e-05
rl training, epoch3, iter0, batch978/1133, batch loss:5.11609687237069e-05, Training time:97489.00495886803
batch reward last col mean 1.4867715435684659e-05 first col mean 5.9164754929952323e-05 all mean 2.9324603019631468e-05
rl training, epoch3, iter0, batch979/1133, batch loss:2.7697366022039205e-05, Training time:97516.42498445511
batch reward last col mean 0.00017096809460781515 first col mean 6.143215432530269e-05 all mean 0.0001650303165661171
rl training, epoch3, iter0, batch980/1133, batch loss:0.00015874109521973878, Training time:97543.75478839874
batch reward last col mean 3.4059034078381956e-05 first col mean 6.521632167277858e-05 all mean 3.6559034924721345e-05
rl training, epoch3, iter0, batch981/1133, batch loss:1.7918691810336895e-05, Training time:97570.90854334831
batch reward last col mean 6.720399596815696e-07 first col mean 6.182792731124209e-07 all mean 3.17775338771753e-05
rl training, epoch3, iter0, batch982/1133, batch loss:0.0003553573042154312, Training time:97598.16334629059
batch reward last col mean 6.882473371661035e-06 first col mean 1.1589671885303687e-05 all mean 7.569160061393632e-06
rl training, epoch3, iter0, batch983/1133, batch loss:1.3716312423639465e-05, Training time:97625.37612557411
batch reward last col mean 0.0003657054912764579 first col mean 2.2093430743552744e-05 all mean 0.0003514861746225506
rl training, epoch3, iter0, batch984/1133, batch loss:0.00021613884018734097, Training time:97653.30837631226
batch reward last col mean 0.0020816861651837826 first col mean 8.217126014642417e-05 all mean 0.0020595502573996782
rl training, epoch3, iter0, batch985/1133, batch loss:0.000318670179694891, Training time:97681.01118516922
batch reward last col mean 1.8125114365830086e-05 first col mean 1.829391067076358e-06 all mean 1.812013033486437e-05
rl training, epoch3, iter0, batch986/1133, batch loss:3.450269650784321e-05, Training time:97708.51965689659
batch reward last col mean 2.8032409318257123e-05 first col mean 2.756642243184615e-05 all mean 2.6222633096040227e-05
rl training, epoch3, iter0, batch987/1133, batch loss:1.86215929716127e-05, Training time:97735.64813351631
batch reward last col mean 3.256457830502768e-06 first col mean 2.194374246755615e-06 all mean 3.253595878049964e-06
rl training, epoch3, iter0, batch988/1133, batch loss:3.639678425315651e-06, Training time:97763.00215911865
batch reward last col mean 1.1653785804810468e-05 first col mean 7.23351986380294e-05 all mean 2.9671286029042676e-05
rl training, epoch3, iter0, batch989/1133, batch loss:0.00030401948606595397, Training time:97790.06266069412
batch reward last col mean 0.0005003264523111284 first col mean 1.341652841801988e-05 all mean 0.0004967456334270537
rl training, epoch3, iter0, batch990/1133, batch loss:7.299225399037823e-05, Training time:97817.53555369377
batch reward last col mean 9.703544492367655e-07 first col mean 7.827817171346396e-06 all mean 9.853918527369387e-06
rl training, epoch3, iter0, batch991/1133, batch loss:3.041121999558527e-06, Training time:97844.82345509529
batch reward last col mean 8.538601832697168e-05 first col mean 0.0003317632945254445 all mean 0.00011077975068474188
rl training, epoch3, iter0, batch992/1133, batch loss:0.0007949096034280956, Training time:97872.01837396622
batch reward last col mean 6.835636554569646e-07 first col mean 2.6365910343884025e-06 all mean 7.086904929565208e-07
rl training, epoch3, iter0, batch993/1133, batch loss:5.64488857435208e-07, Training time:97899.38720059395
batch reward last col mean 9.877151569526177e-06 first col mean 0.000677975476719439 all mean 1.9225786672905087e-05
rl training, epoch3, iter0, batch994/1133, batch loss:0.00011406250996515155, Training time:97926.50161790848
batch reward last col mean 1.533651015961368e-06 first col mean 1.1188903954462148e-05 all mean 1.8751024981611408e-06
rl training, epoch3, iter0, batch995/1133, batch loss:3.368571242390317e-06, Training time:97953.96710324287
batch reward last col mean 4.124221050005872e-06 first col mean 2.068567482638173e-06 all mean 4.289149728720076e-06
rl training, epoch3, iter0, batch996/1133, batch loss:7.894032023614272e-06, Training time:97981.27774763107
batch reward last col mean 0.00013609010784421116 first col mean 0.0009562037885189056 all mean 0.00015651233843527734
rl training, epoch3, iter0, batch997/1133, batch loss:0.00036500787246041, Training time:98008.45650219917
batch reward last col mean 0.0006107783992774785 first col mean 2.019181465584552e-06 all mean 0.0006034767720848322
rl training, epoch3, iter0, batch998/1133, batch loss:0.00021541304886341095, Training time:98035.92457580566
batch reward last col mean 2.197934009018354e-06 first col mean 3.3960579912672983e-06 all mean 8.635563972347882e-06
rl training, epoch3, iter0, batch999/1133, batch loss:0.00011260710743954405, Training time:98063.1632862091
batch reward last col mean 2.2265953703026753e-06 first col mean 1.1762555004679598e-05 all mean 2.3297986899706302e-06
rl training, epoch3, iter0, batch1000/1133, batch loss:1.7269002228204045e-06, Training time:98090.5128288269
batch reward last col mean 2.1180189833103213e-06 first col mean 0.00022508898109663278 all mean 4.514519332587952e-06
rl training, epoch3, iter0, batch1001/1133, batch loss:4.5031774789094925e-06, Training time:98117.72235441208
batch reward last col mean 0.0002534970408305526 first col mean 0.0001248040935024619 all mean 0.00025228201411664486
rl training, epoch3, iter0, batch1002/1133, batch loss:0.00021278524945955724, Training time:98144.76063871384
batch reward last col mean 1.7302411379205296e-06 first col mean 0.00013384941848926246 all mean 3.937396741093835e-06
rl training, epoch3, iter0, batch1003/1133, batch loss:1.5010197785159107e-05, Training time:98171.9628932476
batch reward last col mean 7.46550940675661e-05 first col mean 8.492519555147737e-06 all mean 7.328227366087958e-05
rl training, epoch3, iter0, batch1004/1133, batch loss:3.258243668824434e-05, Training time:98199.15966892242
batch reward last col mean 2.355571723455796e-06 first col mean 4.758962313644588e-05 all mean 6.550694706675131e-06
rl training, epoch3, iter0, batch1005/1133, batch loss:4.823830386158079e-05, Training time:98226.54665899277
batch reward last col mean 1.720601517263276e-06 first col mean 0.00027943940949626267 all mean 5.028643954574363e-06
rl training, epoch3, iter0, batch1006/1133, batch loss:1.2061951565556228e-05, Training time:98254.09836149216
batch reward last col mean 2.4153393951564794e-06 first col mean 4.179555162409088e-06 all mean 4.700388672063127e-06
rl training, epoch3, iter0, batch1007/1133, batch loss:6.849901546956971e-05, Training time:98281.1041135788
batch reward last col mean 3.6167893995298073e-06 first col mean 0.0010767088970169425 all mean 1.831181907618884e-05
rl training, epoch3, iter0, batch1008/1133, batch loss:0.00010578594083199278, Training time:98308.61711621284
batch reward last col mean 8.314944716403261e-05 first col mean 0.0002451522450428456 all mean 8.617315324954689e-05
rl training, epoch3, iter0, batch1009/1133, batch loss:6.215360917849466e-05, Training time:98336.17139410973
batch reward last col mean 2.11873139051022e-05 first col mean 1.5343215636676177e-05 all mean 2.484851393091958e-05
rl training, epoch3, iter0, batch1010/1133, batch loss:5.3032974392408505e-05, Training time:98363.83895659447
batch reward last col mean 2.273286099807592e-06 first col mean 0.00037440788582898676 all mean 6.653827767877374e-06
rl training, epoch3, iter0, batch1011/1133, batch loss:1.4906020624039229e-05, Training time:98391.74767374992
batch reward last col mean 0.001806287677027285 first col mean 0.0011970528867095709 all mean 0.0017846785485744476
rl training, epoch3, iter0, batch1012/1133, batch loss:0.0004646895395126194, Training time:98419.28635931015
batch reward last col mean 3.920661583833862e-06 first col mean 0.00013883222709409893 all mean 5.903107194171753e-06
rl training, epoch3, iter0, batch1013/1133, batch loss:9.657579539634753e-06, Training time:98447.0860671997
batch reward last col mean 4.541945600067265e-06 first col mean 7.735854160273448e-05 all mean 1.4846375052002259e-05
rl training, epoch3, iter0, batch1014/1133, batch loss:0.00010828711674548686, Training time:98474.36742639542
batch reward last col mean 2.117489884767565e-06 first col mean 6.581556954188272e-05 all mean 6.505200417450396e-06
rl training, epoch3, iter0, batch1015/1133, batch loss:1.8335460481466725e-05, Training time:98501.64725112915
batch reward last col mean 6.1963564803591e-06 first col mean 1.6694551959517412e-05 all mean 6.49898993287934e-06
rl training, epoch3, iter0, batch1016/1133, batch loss:1.4730268048879225e-05, Training time:98529.00944757462
batch reward last col mean 0.001745477318763733 first col mean 1.173223836303805e-06 all mean 0.0016240301774814725
rl training, epoch3, iter0, batch1017/1133, batch loss:0.0007307660416699946, Training time:98556.1364107132
batch reward last col mean 0.0004981461097486317 first col mean 2.159104769816622e-05 all mean 0.0004698283737525344
rl training, epoch3, iter0, batch1018/1133, batch loss:0.0007256690296344459, Training time:98583.62684559822
batch reward last col mean 1.684105154708959e-05 first col mean 2.1997257135808468e-06 all mean 1.6038167814258486e-05
rl training, epoch3, iter0, batch1019/1133, batch loss:1.3309115274751093e-05, Training time:98611.4328801632
batch reward last col mean 6.687335553579032e-05 first col mean 0.00015153248386923224 all mean 0.00010738015407696366
rl training, epoch3, iter0, batch1020/1133, batch loss:0.0006668093847110868, Training time:98638.89372444153
batch reward last col mean 7.642138371011242e-05 first col mean 2.1321970052667893e-05 all mean 7.508392445743084e-05
rl training, epoch3, iter0, batch1021/1133, batch loss:3.0098268325673416e-05, Training time:98666.21563243866
batch reward last col mean 0.0004628807946573943 first col mean 0.001109011354856193 all mean 0.00046109160757623613
rl training, epoch3, iter0, batch1022/1133, batch loss:0.0004366427892819047, Training time:98693.76069450378
batch reward last col mean 9.758556188899092e-06 first col mean 0.0011584096355363727 all mean 4.753311077365652e-05
rl training, epoch3, iter0, batch1023/1133, batch loss:0.0004954992909915745, Training time:98720.97535562515
batch reward last col mean 0.0006565634394064546 first col mean 2.3603264708071947e-05 all mean 0.0006737167132087052
rl training, epoch3, iter0, batch1024/1133, batch loss:0.0003284652775619179, Training time:98748.21256780624
batch reward last col mean 0.0007246741442941129 first col mean 0.003160113235935569 all mean 0.0007903133518993855
rl training, epoch3, iter0, batch1025/1133, batch loss:0.002567466115579009, Training time:98775.75945305824
batch reward last col mean 1.4534925867337734e-06 first col mean 0.00017082475824281573 all mean 6.312302048172569e-06
rl training, epoch3, iter0, batch1026/1133, batch loss:6.336420483421534e-06, Training time:98803.04750800133
batch reward last col mean 0.00033669680124148726 first col mean 4.21159256802639e-06 all mean 0.00033130243537016213
rl training, epoch3, iter0, batch1027/1133, batch loss:0.0001913347514346242, Training time:98831.26702213287
batch reward last col mean 1.2385653462843038e-06 first col mean 8.3337299656705e-06 all mean 3.666918701128452e-06
rl training, epoch3, iter0, batch1028/1133, batch loss:9.266607230529189e-05, Training time:98859.55369901657
batch reward last col mean 0.00042723497608676553 first col mean 2.6256340788677335e-05 all mean 0.00042070960626006126
rl training, epoch3, iter0, batch1029/1133, batch loss:7.802819891367108e-05, Training time:98887.04876828194
batch reward last col mean 0.0005460142274387181 first col mean 0.00014676834689453244 all mean 0.0005428760778158903
rl training, epoch3, iter0, batch1030/1133, batch loss:0.00023915967904031277, Training time:98914.74852228165
batch reward last col mean 1.1224171885260148e-06 first col mean 1.8531345631345175e-06 all mean 1.1780916793213692e-06
rl training, epoch3, iter0, batch1031/1133, batch loss:1.0206408660451416e-06, Training time:98942.70444965363
batch reward last col mean 2.3329573650698876e-06 first col mean 0.00045017481897957623 all mean 7.181486125773517e-06
rl training, epoch3, iter0, batch1032/1133, batch loss:2.9761033147224225e-05, Training time:98970.25439143181
batch reward last col mean 5.357844565878622e-05 first col mean 1.0101356338054757e-06 all mean 5.308630716172047e-05
rl training, epoch3, iter0, batch1033/1133, batch loss:1.931262158905156e-05, Training time:98997.6688067913
batch reward last col mean 0.0004821208422072232 first col mean 0.00019852885452564806 all mean 0.0004792537656612694
rl training, epoch3, iter0, batch1034/1133, batch loss:3.1803996535018086e-05, Training time:99024.77807283401
batch reward last col mean 1.9327366317156702e-05 first col mean 9.843826774158515e-06 all mean 1.943227653100621e-05
rl training, epoch3, iter0, batch1035/1133, batch loss:1.0698254300223198e-05, Training time:99052.21657085419
batch reward last col mean 1.213722316606436e-05 first col mean 0.0002428238367429003 all mean 1.9886474547092803e-05
rl training, epoch3, iter0, batch1036/1133, batch loss:6.972960545681417e-05, Training time:99080.2939953804
batch reward last col mean 6.977433258725796e-06 first col mean 0.001353355124592781 all mean 3.988220851169899e-05
rl training, epoch3, iter0, batch1037/1133, batch loss:0.0009435677202418447, Training time:99108.03168439865
batch reward last col mean 9.839326958172023e-05 first col mean 0.0004284739843569696 all mean 0.00010881734488066286
rl training, epoch3, iter0, batch1038/1133, batch loss:0.0001904714881675318, Training time:99135.34569191933
batch reward last col mean 0.00016279173723887652 first col mean 2.608983777463436e-05 all mean 0.00016073850565589964
rl training, epoch3, iter0, batch1039/1133, batch loss:0.0001079791400115937, Training time:99163.05858492851
batch reward last col mean 3.3444594009779394e-05 first col mean 0.0012035771505907178 all mean 4.627222733688541e-05
rl training, epoch3, iter0, batch1040/1133, batch loss:0.00020577780378516763, Training time:99190.55537629128
batch reward last col mean 4.1409762729927024e-07 first col mean 0.00022272839851211756 all mean 6.755338290531654e-06
rl training, epoch3, iter0, batch1041/1133, batch loss:8.320671622641385e-05, Training time:99218.48019456863
batch reward last col mean 1.1303366591164377e-05 first col mean 7.119730980775785e-06 all mean 2.16399766941322e-05
rl training, epoch3, iter0, batch1042/1133, batch loss:8.453193731838837e-05, Training time:99246.34437966347
batch reward last col mean 5.224884262133855e-06 first col mean 1.388686359860003e-05 all mean 4.160801836405881e-06
rl training, epoch3, iter0, batch1043/1133, batch loss:4.379975962365279e-06, Training time:99273.6090683937
batch reward last col mean 0.0009570549009367824 first col mean 0.0042693172581493855 all mean 0.001111005200073123
rl training, epoch3, iter0, batch1044/1133, batch loss:0.0030709742568433285, Training time:99301.6446275711
batch reward last col mean 3.5286352613184135e-06 first col mean 2.8009746529278345e-05 all mean 9.95564550976269e-06
rl training, epoch3, iter0, batch1045/1133, batch loss:2.4718823624425568e-05, Training time:99329.21785569191
batch reward last col mean 3.397824548301287e-05 first col mean 3.786684828810394e-05 all mean 5.973702354822308e-05
rl training, epoch3, iter0, batch1046/1133, batch loss:0.0006439361604861915, Training time:99356.57810235023
batch reward last col mean 5.5253626669582445e-06 first col mean 1.2216909453854896e-05 all mean 1.0307933735020924e-05
rl training, epoch3, iter0, batch1047/1133, batch loss:5.5591594900761265e-06, Training time:99383.89474582672
batch reward last col mean 1.7269532690988854e-05 first col mean 0.002684445586055517 all mean 4.590668322634883e-05
rl training, epoch3, iter0, batch1048/1133, batch loss:6.0457685322035104e-05, Training time:99411.81574392319
batch reward last col mean 8.919800507101172e-07 first col mean 5.2292729378677905e-05 all mean 2.710574335651472e-06
rl training, epoch3, iter0, batch1049/1133, batch loss:3.628685954026878e-05, Training time:99439.87701129913
batch reward last col mean 2.1250963982311077e-05 first col mean 0.00010711394133977592 all mean 2.2414502382162027e-05
rl training, epoch3, iter0, batch1050/1133, batch loss:3.8779333408456296e-05, Training time:99467.54325222969
batch reward last col mean 1.7335257780359825e-06 first col mean 4.1790872273850255e-06 all mean 1.4201823432813399e-05
rl training, epoch3, iter0, batch1051/1133, batch loss:1.7630391084821895e-05, Training time:99495.66084122658
batch reward last col mean 6.7474375100573525e-06 first col mean 2.755244850050076e-06 all mean 6.875618055346422e-06
rl training, epoch3, iter0, batch1052/1133, batch loss:7.22771301298053e-06, Training time:99522.95831823349
batch reward last col mean 1.2779155440512113e-06 first col mean 1.6341468835889827e-06 all mean 3.8622770262009e-06
rl training, epoch3, iter0, batch1053/1133, batch loss:6.545060750795528e-05, Training time:99550.48556303978
batch reward last col mean 1.2989011338504497e-05 first col mean 0.0008797480841167271 all mean 2.1613714125123806e-05
rl training, epoch3, iter0, batch1054/1133, batch loss:2.1549421944655478e-05, Training time:99577.8847053051
batch reward last col mean 9.54199094849173e-07 first col mean 0.00023187398619484156 all mean 3.3693249861244112e-06
rl training, epoch3, iter0, batch1055/1133, batch loss:6.90420074533904e-06, Training time:99605.53757429123
batch reward last col mean 1.0893295439018402e-06 first col mean 3.704795381054282e-05 all mean 3.116628067800775e-05
rl training, epoch3, iter0, batch1056/1133, batch loss:0.0005779151106253266, Training time:99633.17440629005
batch reward last col mean 1.7135673715529265e-06 first col mean 9.73994588093774e-07 all mean 2.3124177914723987e-06
rl training, epoch3, iter0, batch1057/1133, batch loss:3.62318269253592e-06, Training time:99660.75326180458
batch reward last col mean 0.00013421944458968937 first col mean 3.490786184556782e-05 all mean 0.0001430131815141067
rl training, epoch3, iter0, batch1058/1133, batch loss:0.0004975273623131216, Training time:99687.90473389626
batch reward last col mean 1.1756940693885554e-05 first col mean 0.000207584336749278 all mean 1.9920998965972103e-05
rl training, epoch3, iter0, batch1059/1133, batch loss:2.398237120360136e-05, Training time:99716.15450000763
batch reward last col mean 6.580031595149194e-07 first col mean 7.797517355356831e-06 all mean 1.325483935943339e-06
rl training, epoch3, iter0, batch1060/1133, batch loss:6.418551947717788e-06, Training time:99743.91198563576
batch reward last col mean 0.00011337547766743228 first col mean 1.8318496586289257e-06 all mean 0.00011261493636993691
rl training, epoch3, iter0, batch1061/1133, batch loss:5.075916851637885e-05, Training time:99771.9125726223
batch reward last col mean 0.000259454915067181 first col mean 0.0012306717690080404 all mean 0.0002652954717632383
rl training, epoch3, iter0, batch1062/1133, batch loss:0.0004995310446247458, Training time:99799.16335272789
batch reward last col mean 2.8733807084790897e-06 first col mean 8.74108991411049e-06 all mean 3.741412456292892e-06
rl training, epoch3, iter0, batch1063/1133, batch loss:3.3720592909958214e-05, Training time:99826.60321259499
batch reward last col mean 2.8490542263170937e-06 first col mean 0.00010993280011462048 all mean 4.784493285114877e-06
rl training, epoch3, iter0, batch1064/1133, batch loss:1.3904206753068138e-05, Training time:99854.7318034172
batch reward last col mean 1.1217497558391187e-05 first col mean 0.00027584139024838805 all mean 1.3817190847476013e-05
rl training, epoch3, iter0, batch1065/1133, batch loss:1.1593291674216744e-05, Training time:99883.4317612648
batch reward last col mean 2.1870989712624578e-06 first col mean 7.0213650360528845e-06 all mean 2.9241712127259234e-06
rl training, epoch3, iter0, batch1066/1133, batch loss:3.902920070686378e-06, Training time:99910.74648857117
batch reward last col mean 1.3475682862917893e-05 first col mean 2.3959571990417317e-05 all mean 1.2704648725048173e-05
rl training, epoch3, iter0, batch1067/1133, batch loss:3.436112092458643e-05, Training time:99939.161226511
batch reward last col mean 5.188753220863873e-06 first col mean 0.00032720263698138297 all mean 8.384525244764518e-06
rl training, epoch3, iter0, batch1068/1133, batch loss:1.2695396435447037e-05, Training time:99966.93983340263
batch reward last col mean 2.1833167920704e-05 first col mean 2.477566340530757e-05 all mean 2.2268490283749998e-05
rl training, epoch3, iter0, batch1069/1133, batch loss:1.8974296835949644e-05, Training time:99994.62060689926
batch reward last col mean 0.004360203165560961 first col mean 0.0004762772296089679 all mean 0.004165107849985361
rl training, epoch3, iter0, batch1070/1133, batch loss:0.0024350385647267103, Training time:100021.74991750717
batch reward last col mean 0.00012624531518667936 first col mean 2.10309535759734e-05 all mean 0.0001256832474609837
rl training, epoch3, iter0, batch1071/1133, batch loss:4.0570801502326503e-05, Training time:100048.85500597954
batch reward last col mean 0.00034873929689638317 first col mean 2.656353171914816e-05 all mean 0.00034603665699250996
rl training, epoch3, iter0, batch1072/1133, batch loss:3.3002637792378664e-05, Training time:100077.38870000839
batch reward last col mean 0.0002077204262604937 first col mean 7.304852624656633e-05 all mean 0.00021778431255370378
rl training, epoch3, iter0, batch1073/1133, batch loss:0.00020024592231493443, Training time:100104.73284268379
batch reward last col mean 1.8265844801135245e-06 first col mean 0.00016580711235292256 all mean 9.64619994192617e-06
rl training, epoch3, iter0, batch1074/1133, batch loss:0.00013828312512487173, Training time:100132.23734283447
batch reward last col mean 0.00034048521774820983 first col mean 3.7357658584369346e-06 all mean 0.00033719377825036645
rl training, epoch3, iter0, batch1075/1133, batch loss:0.00024817039957270026, Training time:100159.54765892029
batch reward last col mean 1.7644612171352492e-06 first col mean 2.2871586224937346e-06 all mean 2.1598489183816127e-06
rl training, epoch3, iter0, batch1076/1133, batch loss:5.746440820075804e-06, Training time:100187.08219885826
batch reward last col mean 9.945748388417996e-06 first col mean 3.3145628549391404e-05 all mean 1.0463661055837292e-05
rl training, epoch3, iter0, batch1077/1133, batch loss:3.852368536172435e-06, Training time:100215.1503572464
batch reward last col mean 0.007265590131282806 first col mean 0.006521617528051138 all mean 0.007230339106172323
rl training, epoch3, iter0, batch1078/1133, batch loss:0.0026019036304205656, Training time:100242.83951425552
batch reward last col mean 7.934430868772324e-06 first col mean 5.6588483857922256e-05 all mean 1.2369160685921088e-05
rl training, epoch3, iter0, batch1079/1133, batch loss:5.597038762061857e-05, Training time:100270.50899291039
batch reward last col mean 6.700684753013775e-05 first col mean 0.0008101401617750525 all mean 9.381669224239886e-05
rl training, epoch3, iter0, batch1080/1133, batch loss:0.0012189869303256273, Training time:100298.2086019516
batch reward last col mean 0.00014286022633314133 first col mean 0.0008322333451360464 all mean 0.00016183906700462103
rl training, epoch3, iter0, batch1081/1133, batch loss:7.356994319707155e-05, Training time:100325.55740237236
batch reward last col mean 0.007643200922757387 first col mean 0.0023644445464015007 all mean 0.007515074219554663
rl training, epoch3, iter0, batch1082/1133, batch loss:0.005805603694170713, Training time:100353.33105635643
batch reward last col mean 1.8332253603148274e-05 first col mean 0.00035298915463499725 all mean 2.2698468455928378e-05
rl training, epoch3, iter0, batch1083/1133, batch loss:9.37922959565185e-06, Training time:100380.76831650734
batch reward last col mean 1.0693809599615633e-05 first col mean 0.00022258466924540699 all mean 1.4229262887965888e-05
rl training, epoch3, iter0, batch1084/1133, batch loss:3.5790108086075634e-05, Training time:100408.71037316322
batch reward last col mean 0.0005683030467480421 first col mean 0.0007692475919611752 all mean 0.0005775426398031414
rl training, epoch3, iter0, batch1085/1133, batch loss:0.0005583403981290758, Training time:100436.99314689636
batch reward last col mean 0.0004207669699098915 first col mean 2.4313099856954068e-05 all mean 0.0004116068594157696
rl training, epoch3, iter0, batch1086/1133, batch loss:0.0006011662189848721, Training time:100465.75529670715
batch reward last col mean 2.939010755653726e-06 first col mean 9.458478416490834e-06 all mean 4.7766484385647345e-06
rl training, epoch3, iter0, batch1087/1133, batch loss:1.5121303476917092e-05, Training time:100494.15031170845
batch reward last col mean 4.4560629248735495e-06 first col mean 3.7066165532451123e-06 all mean 5.518520083569456e-06
rl training, epoch3, iter0, batch1088/1133, batch loss:1.5076378076628316e-05, Training time:100523.48492527008
batch reward last col mean 2.865974238375202e-06 first col mean 5.253099516266957e-06 all mean 2.2327369151753373e-05
rl training, epoch3, iter0, batch1089/1133, batch loss:0.0008028997108340263, Training time:100551.09166502953
batch reward last col mean 4.682509825215675e-05 first col mean 1.0055259735963773e-05 all mean 4.894952871836722e-05
rl training, epoch3, iter0, batch1090/1133, batch loss:6.478672003140673e-05, Training time:100578.77698945999
batch reward last col mean 0.0005804746178910136 first col mean 0.0022785053588449955 all mean 0.0005751407006755471
rl training, epoch3, iter0, batch1091/1133, batch loss:0.0008236905559897423, Training time:100606.40940237045
batch reward last col mean 0.00011968588660238311 first col mean 7.56007939344272e-05 all mean 0.00012552575208246708
rl training, epoch3, iter0, batch1092/1133, batch loss:7.32636617613025e-05, Training time:100633.9096763134
batch reward last col mean 8.656127192807617e-07 first col mean 2.7180312827113084e-05 all mean 4.052892563777277e-06
rl training, epoch3, iter0, batch1093/1133, batch loss:2.388698521826882e-05, Training time:100661.30637931824
batch reward last col mean 0.0015480241272598505 first col mean 0.0007742978632450104 all mean 0.0015403582947328687
rl training, epoch3, iter0, batch1094/1133, batch loss:0.0006022370071150362, Training time:100688.8763680458
batch reward last col mean 0.0004200712719466537 first col mean 0.0004392437404021621 all mean 0.0004281342262402177
rl training, epoch3, iter0, batch1095/1133, batch loss:0.00010502707300474867, Training time:100716.13839650154
batch reward last col mean 0.0005183372413739562 first col mean 0.00022849556989967823 all mean 0.000489523634314537
rl training, epoch3, iter0, batch1096/1133, batch loss:0.0002637487486936152, Training time:100744.02819490433
batch reward last col mean 2.771432809822727e-05 first col mean 0.0029969054739922285 all mean 6.312294135568663e-05
rl training, epoch3, iter0, batch1097/1133, batch loss:6.0781781940022483e-05, Training time:100771.8874361515
batch reward last col mean 6.00655539528816e-06 first col mean 4.86226927023381e-05 all mean 1.6226491425186396e-05
rl training, epoch3, iter0, batch1098/1133, batch loss:2.422634861432016e-05, Training time:100799.1064760685
batch reward last col mean 4.461833668756299e-06 first col mean 1.7089323591790162e-05 all mean 4.846536739933072e-06
rl training, epoch3, iter0, batch1099/1133, batch loss:7.632904271304142e-06, Training time:100826.72238826752
batch reward last col mean 6.140793630038388e-06 first col mean 3.2876581826712936e-05 all mean 2.128130836354103e-05
rl training, epoch3, iter0, batch1100/1133, batch loss:1.5184362382569816e-05, Training time:100854.66005277634
batch reward last col mean 0.0001130979580921121 first col mean 0.0003487595240585506 all mean 0.00014873663894832134
rl training, epoch3, iter0, batch1101/1133, batch loss:0.0014809215208515525, Training time:100882.48693966866
batch reward last col mean 0.0009625852690078318 first col mean 0.0011467202566564083 all mean 0.0009651942527852952
rl training, epoch3, iter0, batch1102/1133, batch loss:0.00039113027742132545, Training time:100910.40051293373
batch reward last col mean 6.924446643097326e-05 first col mean 0.0005394310574047267 all mean 9.363183926325291e-05
rl training, epoch3, iter0, batch1103/1133, batch loss:7.761606684653088e-05, Training time:100938.84384560585
batch reward last col mean 5.486087502504233e-06 first col mean 0.00013417142326943576 all mean 2.6620404241839424e-05
rl training, epoch3, iter0, batch1104/1133, batch loss:1.624453580006957e-05, Training time:100967.76431441307
batch reward last col mean 1.1427868230384775e-05 first col mean 0.0003856638795696199 all mean 2.0843192032771185e-05
rl training, epoch3, iter0, batch1105/1133, batch loss:7.622628618264571e-05, Training time:100997.09727072716
batch reward last col mean 0.00014727990492247045 first col mean 0.0017297256272286177 all mean 0.00020174057863187045
rl training, epoch3, iter0, batch1106/1133, batch loss:0.00031288954778574407, Training time:101026.72963500023
batch reward last col mean 8.118333425954916e-06 first col mean 0.0012530615786090493 all mean 2.4086644771159627e-05
rl training, epoch3, iter0, batch1107/1133, batch loss:0.00010622893751133233, Training time:101056.16069030762
batch reward last col mean 3.670933801913634e-05 first col mean 0.00012127863010391593 all mean 3.794911754084751e-05
rl training, epoch3, iter0, batch1108/1133, batch loss:4.960093065164983e-05, Training time:101083.94048976898
batch reward last col mean 1.4958936844777782e-06 first col mean 5.471771873999387e-05 all mean 7.0906530709180515e-06
rl training, epoch3, iter0, batch1109/1133, batch loss:2.5377115889568813e-05, Training time:101111.89090800285
batch reward last col mean 9.585393854649737e-05 first col mean 0.0008038197993300855 all mean 0.0001116096245823428
rl training, epoch3, iter0, batch1110/1133, batch loss:0.00020380658679641783, Training time:101139.1651058197
batch reward last col mean 0.0008084994042292237 first col mean 4.607601658790372e-05 all mean 0.000810780213214457
rl training, epoch3, iter0, batch1111/1133, batch loss:0.0006383245345205069, Training time:101166.46156287193
batch reward last col mean 3.283116939201136e-06 first col mean 0.00010161471436731517 all mean 9.595811206963845e-06
rl training, epoch3, iter0, batch1112/1133, batch loss:6.444413884310052e-05, Training time:101193.96719670296
batch reward last col mean 6.022661182214506e-06 first col mean 0.002202709438279271 all mean 2.8489701435319148e-05
rl training, epoch3, iter0, batch1113/1133, batch loss:0.00011795365571742877, Training time:101221.75371456146
batch reward last col mean 0.00035635114181786776 first col mean 0.0004951026057824492 all mean 0.000357667391654104
rl training, epoch3, iter0, batch1114/1133, batch loss:5.529322152142413e-05, Training time:101249.1225476265
batch reward last col mean 0.00584003422409296 first col mean 0.00045608688378706574 all mean 0.005714226048439741
rl training, epoch3, iter0, batch1115/1133, batch loss:0.0016137697966769338, Training time:101277.21905398369
batch reward last col mean 5.652583422488533e-05 first col mean 0.00043356503010727465 all mean 6.280182424234226e-05
rl training, epoch3, iter0, batch1116/1133, batch loss:6.133408169262111e-05, Training time:101305.06727433205
batch reward last col mean 0.00011729053949238732 first col mean 0.0007406987133435905 all mean 0.00012475611583795398
rl training, epoch3, iter0, batch1117/1133, batch loss:6.668212154181674e-05, Training time:101332.55013275146
batch reward last col mean 0.0020836566109210253 first col mean 0.001863938057795167 all mean 0.0020006957929581404
rl training, epoch3, iter0, batch1118/1133, batch loss:0.0014308709651231766, Training time:101360.67687749863
batch reward last col mean 0.00036659036413766444 first col mean 0.0035329831298440695 all mean 0.00039511595969088376
rl training, epoch3, iter0, batch1119/1133, batch loss:0.00020136230159550905, Training time:101388.10150384903
batch reward last col mean 0.0007691162172704935 first col mean 0.00039236110751517117 all mean 0.000765652977861464
rl training, epoch3, iter0, batch1120/1133, batch loss:8.086414163699374e-05, Training time:101415.72690439224
batch reward last col mean 0.0038082017563283443 first col mean 0.0008799636270850897 all mean 0.0037732680793851614
rl training, epoch3, iter0, batch1121/1133, batch loss:0.0025308767799288034, Training time:101443.0181312561
batch reward last col mean 1.7709141957311658e-06 first col mean 3.520037353155203e-05 all mean 3.6019241633766796e-06
rl training, epoch3, iter0, batch1122/1133, batch loss:4.747977982333396e-06, Training time:101470.42131614685
batch reward last col mean 0.0009118180023506284 first col mean 0.0010735924588516355 all mean 0.0009454806568101048
rl training, epoch3, iter0, batch1123/1133, batch loss:0.0028932271525263786, Training time:101497.5996336937
batch reward last col mean 0.0006114163552410901 first col mean 0.0003542819758877158 all mean 0.000610251328907907
rl training, epoch3, iter0, batch1124/1133, batch loss:3.8762835174566135e-05, Training time:101525.11620473862
batch reward last col mean 0.0009717538487166166 first col mean 0.0014155613025650382 all mean 0.0009508716757409275
rl training, epoch3, iter0, batch1125/1133, batch loss:0.000618157850112766, Training time:101553.09812831879
batch reward last col mean 1.1865337000926957e-05 first col mean 0.003366579534485936 all mean 4.787250145454891e-05
rl training, epoch3, iter0, batch1126/1133, batch loss:0.00014377305342350155, Training time:101580.42242741585
batch reward last col mean 0.002158169401809573 first col mean 0.0014783291844651103 all mean 0.002181301126256585
rl training, epoch3, iter0, batch1127/1133, batch loss:0.0008906121365725994, Training time:101607.76517486572
batch reward last col mean 0.0028914250433444977 first col mean 0.0018810604233294725 all mean 0.002876527374610305
rl training, epoch3, iter0, batch1128/1133, batch loss:0.0005138837732374668, Training time:101635.60093593597
batch reward last col mean 6.445421604439616e-05 first col mean 0.0004644406435545534 all mean 9.87738894764334e-05
rl training, epoch3, iter0, batch1129/1133, batch loss:0.000343460327712819, Training time:101662.88750243187
batch reward last col mean 0.0022012104745954275 first col mean 0.0011080809636041522 all mean 0.0021968369837850332
rl training, epoch3, iter0, batch1130/1133, batch loss:0.0002958613622467965, Training time:101690.17512822151
batch reward last col mean 0.0042145028710365295 first col mean 0.002190728671848774 all mean 0.004193820059299469
rl training, epoch3, iter0, batch1131/1133, batch loss:0.001987084047868848, Training time:101717.68497419357
batch reward last col mean 0.0002493024221621454 first col mean 0.00250878999941051 all mean 0.00026438606437295675
rl training, epoch3, iter0, batch1132/1133, batch loss:0.0004500965296756476, Training time:101743.41929125786
rl training, epoch 3, iter 0, loss:0.00013432828162549367, Training time:101743.41958355904 
rl epoch 3, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.30142211295920773 Time: 173.20100831985474 s
cur_epoch: 1
D Training Loss: 0.29393036504393644 Time: 163.73960280418396 s
cur_epoch: 2
D Training Loss: 0.28641915721169425 Time: 161.05501246452332 s
cur_epoch: 3
D Training Loss: 0.27736144720035005 Time: 161.7517352104187 s
cur_epoch: 4
D Training Loss: 0.2754754806356628 Time: 162.38337469100952 s
rl epoch 4, begin RL for generator...
batch reward last col mean 9.572524959367001e-07 first col mean 3.20140975418326e-06 all mean 9.469492397329304e-06
rl training, epoch4, iter0, batch0/1133, batch loss:1.8407795323582832e-06, Training time:102593.06395864487
batch reward last col mean 2.8231295345904073e-07 first col mean 8.009770681383088e-06 all mean 2.96476491712383e-06
rl training, epoch4, iter0, batch1/1133, batch loss:6.485798076028004e-05, Training time:102620.61283445358
batch reward last col mean 3.6208564324624604e-06 first col mean 1.2144012089265743e-06 all mean 4.236095719534205e-06
rl training, epoch4, iter0, batch2/1133, batch loss:1.3236465747468174e-05, Training time:102648.12729740143
batch reward last col mean 8.064301937338314e-07 first col mean 1.3489241155184573e-06 all mean 6.083360858610831e-06
rl training, epoch4, iter0, batch3/1133, batch loss:1.2220799362694379e-05, Training time:102675.65871500969
batch reward last col mean 0.0002867895527742803 first col mean 0.00011658079165499657 all mean 0.0002800929360091686
rl training, epoch4, iter0, batch4/1133, batch loss:8.375775360036641e-05, Training time:102703.06363558769
batch reward last col mean 7.463165729859611e-06 first col mean 2.6601153876981698e-05 all mean 7.486934919143096e-06
rl training, epoch4, iter0, batch5/1133, batch loss:3.1337688142230036e-06, Training time:102730.60741305351
batch reward last col mean 3.1099597208594787e-07 first col mean 2.621300154714845e-06 all mean 4.45317880348739e-07
rl training, epoch4, iter0, batch6/1133, batch loss:4.1447897274338175e-06, Training time:102757.91385293007
batch reward last col mean 8.266271152024274e-07 first col mean 1.0593865908958833e-06 all mean 2.022907892751391e-06
rl training, epoch4, iter0, batch7/1133, batch loss:1.1900894605787471e-05, Training time:102785.43764710426
batch reward last col mean 9.202361752613797e-07 first col mean 8.10955214092246e-07 all mean 1.1166514468641253e-06
rl training, epoch4, iter0, batch8/1133, batch loss:1.2137184057792183e-06, Training time:102812.74252414703
batch reward last col mean 3.8087803204689408e-06 first col mean 3.622512667789124e-05 all mean 5.5648993111390155e-06
rl training, epoch4, iter0, batch9/1133, batch loss:1.887350663309917e-05, Training time:102840.14874196053
batch reward last col mean 4.830999955629522e-07 first col mean 3.78411527890421e-07 all mean 2.5851995815173723e-06
rl training, epoch4, iter0, batch10/1133, batch loss:2.780967770377174e-05, Training time:102867.45525860786
batch reward last col mean 1.4578367881767917e-06 first col mean 8.570188470002904e-07 all mean 2.5961080609704368e-06
rl training, epoch4, iter0, batch11/1133, batch loss:4.059518687427044e-05, Training time:102894.72609376907
batch reward last col mean 5.825826883665286e-05 first col mean 1.2118064205424162e-06 all mean 5.7172106608049944e-05
rl training, epoch4, iter0, batch12/1133, batch loss:1.2605319170688745e-05, Training time:102922.4738855362
batch reward last col mean 8.002572030818556e-06 first col mean 1.2921284451294923e-06 all mean 8.843035175232217e-06
rl training, epoch4, iter0, batch13/1133, batch loss:1.61997668328695e-05, Training time:102950.21914863586
batch reward last col mean 5.8459081628825516e-06 first col mean 1.1516870472405571e-05 all mean 1.4466571883531287e-05
rl training, epoch4, iter0, batch14/1133, batch loss:0.0003583310463000089, Training time:102978.10918521881
batch reward last col mean 1.8455062672728673e-05 first col mean 3.374691232238547e-06 all mean 1.8042241208604537e-05
rl training, epoch4, iter0, batch15/1133, batch loss:6.11393443250563e-06, Training time:103005.83540797234
batch reward last col mean 6.917346127011115e-06 first col mean 2.628846687002806e-06 all mean 6.672279596386943e-06
rl training, epoch4, iter0, batch16/1133, batch loss:2.6178643111052224e-06, Training time:103033.21790933609
batch reward last col mean 2.2565991457668133e-06 first col mean 0.00022119033383205533 all mean 2.2190315576153807e-05
rl training, epoch4, iter0, batch17/1133, batch loss:3.99812706746161e-05, Training time:103060.59207510948
batch reward last col mean 0.0052916016429662704 first col mean 0.0001013860892271623 all mean 0.004994384478777647
rl training, epoch4, iter0, batch18/1133, batch loss:0.002927338005974889, Training time:103088.0877020359
batch reward last col mean 1.3155829492461635e-06 first col mean 8.699198588146828e-07 all mean 1.4148952232062584e-06
rl training, epoch4, iter0, batch19/1133, batch loss:2.754513388936175e-06, Training time:103115.33074617386
batch reward last col mean 2.2387636988696613e-07 first col mean 1.996899754885817e-06 all mean 2.775639416086051e-07
rl training, epoch4, iter0, batch20/1133, batch loss:6.817223834332253e-07, Training time:103142.52187418938
batch reward last col mean 7.998127671271504e-07 first col mean 7.903339565018541e-07 all mean 8.844980357025634e-07
rl training, epoch4, iter0, batch21/1133, batch loss:1.1293541319901124e-06, Training time:103170.17180967331
batch reward last col mean 3.597226054807834e-07 first col mean 8.456301293335855e-05 all mean 1.3114024568494642e-06
rl training, epoch4, iter0, batch22/1133, batch loss:2.2130157049105037e-06, Training time:103198.05169534683
batch reward last col mean 1.187000179925235e-06 first col mean 0.0010833677370101213 all mean 1.4552040738635696e-05
rl training, epoch4, iter0, batch23/1133, batch loss:5.184026304050349e-05, Training time:103225.88005661964
batch reward last col mean 3.5168482099834364e-06 first col mean 1.4776036323382868e-06 all mean 1.3618228877021465e-05
rl training, epoch4, iter0, batch24/1133, batch loss:0.00022622683900408447, Training time:103253.1563038826
batch reward last col mean 2.8316017051110975e-06 first col mean 1.7948785853150184e-06 all mean 2.8749041121045593e-06
rl training, epoch4, iter0, batch25/1133, batch loss:1.2819887160731014e-06, Training time:103280.53248858452
batch reward last col mean 3.8033331293263473e-06 first col mean 0.0008210139349102974 all mean 1.2349189091764856e-05
rl training, epoch4, iter0, batch26/1133, batch loss:8.257213266915642e-06, Training time:103308.1417965889
batch reward last col mean 4.257548425812274e-06 first col mean 1.524792878626613e-06 all mean 3.808457768172957e-05
rl training, epoch4, iter0, batch27/1133, batch loss:0.001946225413121283, Training time:103335.45423340797
batch reward last col mean 1.428735799891001e-06 first col mean 1.3995360177432303e-06 all mean 2.073971472782432e-06
rl training, epoch4, iter0, batch28/1133, batch loss:1.1608771274040919e-05, Training time:103362.96563363075
batch reward last col mean 4.1718212742125615e-05 first col mean 1.1900040135515155e-06 all mean 3.577351526473649e-05
rl training, epoch4, iter0, batch29/1133, batch loss:3.6153855035081506e-05, Training time:103390.34708619118
batch reward last col mean 2.9789139261993114e-06 first col mean 1.8553236031948472e-06 all mean 2.9999764592503197e-06
rl training, epoch4, iter0, batch30/1133, batch loss:1.4711615676787915e-06, Training time:103417.54913830757
batch reward last col mean 5.510168648470426e-06 first col mean 9.785604788703495e-07 all mean 2.4932491214713082e-05
rl training, epoch4, iter0, batch31/1133, batch loss:0.0002713763096835464, Training time:103444.73183321953
batch reward last col mean 0.007144595496356487 first col mean 8.626998896943405e-05 all mean 0.006874914281070232
rl training, epoch4, iter0, batch32/1133, batch loss:0.0026447202544659376, Training time:103472.17563652992
batch reward last col mean 2.054651668004226e-05 first col mean 0.00025954030570574105 all mean 2.9620803616126068e-05
rl training, epoch4, iter0, batch33/1133, batch loss:6.312745972536504e-05, Training time:103499.43535518646
batch reward last col mean 1.1414031177992001e-06 first col mean 1.1738865168808843e-06 all mean 1.6949470591498539e-06
rl training, epoch4, iter0, batch34/1133, batch loss:2.820139707182534e-05, Training time:103527.16350913048
batch reward last col mean 2.184977802244248e-06 first col mean 8.259420383183169e-07 all mean 5.096226686873706e-06
rl training, epoch4, iter0, batch35/1133, batch loss:8.546699973521754e-05, Training time:103554.30461406708
batch reward last col mean 4.786914723808877e-05 first col mean 2.7888625481864437e-05 all mean 4.6325858420459554e-05
rl training, epoch4, iter0, batch36/1133, batch loss:1.733128920022864e-05, Training time:103581.8094792366
batch reward last col mean 1.6226661045948276e-06 first col mean 1.2178522865724517e-06 all mean 3.2492880563950166e-06
rl training, epoch4, iter0, batch37/1133, batch loss:2.699403376027476e-05, Training time:103609.12957215309
batch reward last col mean 2.2821556910912477e-07 first col mean 1.9662416889332235e-05 all mean 1.385527866659686e-06
rl training, epoch4, iter0, batch38/1133, batch loss:1.938641980814282e-05, Training time:103637.19831299782
batch reward last col mean 2.9621793146361597e-05 first col mean 2.7170544854016043e-05 all mean 2.8570239010150544e-05
rl training, epoch4, iter0, batch39/1133, batch loss:2.130402390321251e-05, Training time:103664.92899084091
batch reward last col mean 1.2425791737769032e-06 first col mean 5.047974809713196e-06 all mean 1.6326417608070187e-05
rl training, epoch4, iter0, batch40/1133, batch loss:0.0006555936415679753, Training time:103692.74865150452
batch reward last col mean 1.7212464626936708e-06 first col mean 5.7469846069579944e-05 all mean 2.8497665880422574e-06
rl training, epoch4, iter0, batch41/1133, batch loss:2.7788330044131726e-05, Training time:103720.16813850403
batch reward last col mean 1.4500622000923613e-06 first col mean 0.00045738829066976905 all mean 7.047805866022827e-06
rl training, epoch4, iter0, batch42/1133, batch loss:2.978101656481158e-05, Training time:103747.70216870308
batch reward last col mean 1.1029987035726663e-05 first col mean 2.8197177925903816e-06 all mean 1.0740340258053038e-05
rl training, epoch4, iter0, batch43/1133, batch loss:1.3022159691900015e-05, Training time:103774.77850079536
batch reward last col mean 7.730105608061422e-06 first col mean 1.4938033018552233e-05 all mean 7.954333341331221e-06
rl training, epoch4, iter0, batch44/1133, batch loss:3.6112917314312654e-06, Training time:103802.2176129818
batch reward last col mean 2.2493193682748824e-05 first col mean 4.545368574326858e-05 all mean 3.4780092391883954e-05
rl training, epoch4, iter0, batch45/1133, batch loss:0.0004740177537314594, Training time:103829.52553224564
batch reward last col mean 2.3388161935145035e-05 first col mean 0.0004170496540609747 all mean 2.7439115001470782e-05
rl training, epoch4, iter0, batch46/1133, batch loss:7.974888831085991e-06, Training time:103857.2172627449
batch reward last col mean 2.187756217608694e-05 first col mean 3.341326009831391e-05 all mean 3.0295665055746213e-05
rl training, epoch4, iter0, batch47/1133, batch loss:0.00040939150494523346, Training time:103884.68701386452
batch reward last col mean 3.769268914766144e-06 first col mean 9.494856385572348e-06 all mean 3.851385372399818e-06
rl training, epoch4, iter0, batch48/1133, batch loss:3.6941360122000333e-06, Training time:103911.80133247375
batch reward last col mean 4.436019025888527e-06 first col mean 1.8144381101592444e-05 all mean 5.445668193715392e-06
rl training, epoch4, iter0, batch49/1133, batch loss:3.338039823574945e-05, Training time:103938.96565461159
batch reward last col mean 8.291444828500971e-07 first col mean 1.498984875070164e-05 all mean 2.4496544028806966e-06
rl training, epoch4, iter0, batch50/1133, batch loss:2.8167520213173702e-05, Training time:103965.8642039299
batch reward last col mean 0.001275448128581047 first col mean 3.210113936802372e-05 all mean 0.0012520463205873966
rl training, epoch4, iter0, batch51/1133, batch loss:0.0005085461889393628, Training time:103993.27107596397
batch reward last col mean 6.71203961246647e-05 first col mean 1.3796409348287852e-06 all mean 6.733053305651993e-05
rl training, epoch4, iter0, batch52/1133, batch loss:7.706361793680117e-05, Training time:104021.5632660389
batch reward last col mean 5.332559157977812e-05 first col mean 5.7796616601990536e-05 all mean 5.347795377019793e-05
rl training, epoch4, iter0, batch53/1133, batch loss:7.8098646554281e-06, Training time:104049.05666685104
batch reward last col mean 0.006110766436904669 first col mean 2.7079386200057343e-06 all mean 0.006028791889548302
rl training, epoch4, iter0, batch54/1133, batch loss:0.004581304732710123, Training time:104076.4715616703
batch reward last col mean 2.946799031633418e-05 first col mean 1.2223922567500267e-06 all mean 2.6965861252392642e-05
rl training, epoch4, iter0, batch55/1133, batch loss:2.133945599780418e-05, Training time:104103.97881865501
batch reward last col mean 6.004447641316801e-07 first col mean 3.746085894817952e-06 all mean 1.2986446336071822e-06
rl training, epoch4, iter0, batch56/1133, batch loss:4.239043391862651e-06, Training time:104131.31643629074
batch reward last col mean 6.845485813755658e-07 first col mean 1.0054857284558238e-06 all mean 2.554354796302505e-05
rl training, epoch4, iter0, batch57/1133, batch loss:0.00014801979705225676, Training time:104158.98281741142
batch reward last col mean 2.3822085495339707e-06 first col mean 2.0630835933843628e-05 all mean 4.816979526367504e-06
rl training, epoch4, iter0, batch58/1133, batch loss:4.124560655327514e-05, Training time:104186.25395727158
batch reward last col mean 2.6817217076313682e-05 first col mean 4.159606760367751e-06 all mean 2.403196776867844e-05
rl training, epoch4, iter0, batch59/1133, batch loss:1.9644097847049125e-05, Training time:104213.63513803482
batch reward last col mean 1.1669193554553203e-05 first col mean 1.3244324691186193e-05 all mean 1.2202020116092172e-05
rl training, epoch4, iter0, batch60/1133, batch loss:7.322480541915866e-06, Training time:104241.08572101593
batch reward last col mean 9.302423791268666e-07 first col mean 0.00030277433688752353 all mean 2.0412495359778404e-05
rl training, epoch4, iter0, batch61/1133, batch loss:8.330604759976268e-05, Training time:104268.63381695747
batch reward last col mean 1.8071331169267069e-06 first col mean 7.0654955379723106e-06 all mean 1.8755933979264228e-06
rl training, epoch4, iter0, batch62/1133, batch loss:1.42650242196396e-06, Training time:104295.81523013115
batch reward last col mean 2.4553664843551815e-06 first col mean 6.387510802596807e-05 all mean 3.1372997000289615e-06
rl training, epoch4, iter0, batch63/1133, batch loss:3.366373221069807e-06, Training time:104323.7986292839
batch reward last col mean 6.809763135606772e-07 first col mean 5.090388731332496e-05 all mean 1.3223562973507796e-06
rl training, epoch4, iter0, batch64/1133, batch loss:2.3150334982346976e-06, Training time:104351.04843783379
batch reward last col mean 0.0003191297291778028 first col mean 8.096089004538953e-06 all mean 0.00029995007207617164
rl training, epoch4, iter0, batch65/1133, batch loss:4.9930764362215996e-05, Training time:104377.9719979763
batch reward last col mean 1.0471541145307128e-06 first col mean 0.00116805883590132 all mean 1.715333382890094e-05
rl training, epoch4, iter0, batch66/1133, batch loss:0.00015736790373921394, Training time:104405.67116212845
batch reward last col mean 1.4263359844335355e-06 first col mean 3.7106040053913603e-06 all mean 2.449510930091492e-06
rl training, epoch4, iter0, batch67/1133, batch loss:1.9053118194278795e-06, Training time:104432.92729115486
batch reward last col mean 6.745182326994836e-05 first col mean 5.3076644690008834e-05 all mean 6.905318150529638e-05
rl training, epoch4, iter0, batch68/1133, batch loss:6.82327154208906e-05, Training time:104460.17323279381
batch reward last col mean 9.82638230198063e-05 first col mean 0.0018967969808727503 all mean 0.0001201108461827971
rl training, epoch4, iter0, batch69/1133, batch loss:0.0009814886143431067, Training time:104487.70747709274
batch reward last col mean 1.9292926936032018e-06 first col mean 2.2882254597789142e-06 all mean 2.104125996993389e-05
rl training, epoch4, iter0, batch70/1133, batch loss:9.973831765819341e-05, Training time:104515.63295078278
batch reward last col mean 2.2106512915343046e-05 first col mean 1.4544264558935538e-05 all mean 2.160414805985056e-05
rl training, epoch4, iter0, batch71/1133, batch loss:9.251126357412431e-06, Training time:104543.07081055641
batch reward last col mean 0.00012518906441982836 first col mean 0.00011627472122199833 all mean 0.0001249620836460963
rl training, epoch4, iter0, batch72/1133, batch loss:4.5454355131369084e-05, Training time:104571.02690124512
batch reward last col mean 5.574869987867714e-07 first col mean 1.498948449807358e-06 all mean 2.0339625734777655e-06
rl training, epoch4, iter0, batch73/1133, batch loss:4.268772681825794e-05, Training time:104598.42919588089
batch reward last col mean 7.544990512542427e-05 first col mean 6.7324695010029245e-06 all mean 7.317012932617217e-05
rl training, epoch4, iter0, batch74/1133, batch loss:8.286452066386119e-05, Training time:104626.09065461159
batch reward last col mean 4.29518422606634e-06 first col mean 1.7665761333773844e-05 all mean 5.041790700488491e-06
rl training, epoch4, iter0, batch75/1133, batch loss:1.6227695596171543e-05, Training time:104653.35047125816
batch reward last col mean 5.3355193813331425e-05 first col mean 1.9731607608264312e-05 all mean 5.177043567528017e-05
rl training, epoch4, iter0, batch76/1133, batch loss:1.634009458939545e-05, Training time:104680.99936127663
batch reward last col mean 0.0001191713017760776 first col mean 3.7533100112341344e-06 all mean 0.00011778071348089725
rl training, epoch4, iter0, batch77/1133, batch loss:3.848057531286031e-05, Training time:104708.36093878746
batch reward last col mean 0.000705228594597429 first col mean 3.6432863907975843e-06 all mean 0.0006346211885102093
rl training, epoch4, iter0, batch78/1133, batch loss:0.00017680335440672934, Training time:104735.7520096302
batch reward last col mean 2.081581214952166e-06 first col mean 2.8727547487505944e-06 all mean 4.259660272509791e-06
rl training, epoch4, iter0, batch79/1133, batch loss:0.00010626353468978778, Training time:104762.92656207085
batch reward last col mean 3.010941782122245e-06 first col mean 4.372734110802412e-06 all mean 3.9141314118751325e-06
rl training, epoch4, iter0, batch80/1133, batch loss:1.0122920684807468e-05, Training time:104790.09159255028
batch reward last col mean 0.0010087286354973912 first col mean 0.0007904520025476813 all mean 0.0009642586810514331
rl training, epoch4, iter0, batch81/1133, batch loss:0.0008081155247054994, Training time:104817.22509789467
batch reward last col mean 0.00043759995605796576 first col mean 6.082871914259158e-05 all mean 0.00041080944356508553
rl training, epoch4, iter0, batch82/1133, batch loss:0.0003630724095273763, Training time:104844.78663825989
batch reward last col mean 8.940556313064008e-07 first col mean 6.268760444072541e-07 all mean 1.3965044672659133e-05
rl training, epoch4, iter0, batch83/1133, batch loss:0.0003328672319184989, Training time:104872.15689277649
batch reward last col mean 1.1280434364380199e-06 first col mean 0.0020042413379997015 all mean 2.171695996366907e-05
rl training, epoch4, iter0, batch84/1133, batch loss:2.4553612092859112e-05, Training time:104899.54571795464
batch reward last col mean 5.743050905948621e-07 first col mean 4.09079893870512e-06 all mean 6.627110906265443e-06
rl training, epoch4, iter0, batch85/1133, batch loss:4.1397994209546596e-05, Training time:104927.31904172897
batch reward last col mean 3.7479821912711486e-07 first col mean 5.572760983341141e-06 all mean 9.604743354429957e-06
rl training, epoch4, iter0, batch86/1133, batch loss:2.4388671135966433e-06, Training time:104955.14036035538
batch reward last col mean 9.559236787026748e-06 first col mean 1.988154281207244e-06 all mean 1.35513528221054e-05
rl training, epoch4, iter0, batch87/1133, batch loss:0.0002254607534268871, Training time:104983.23264241219
batch reward last col mean 1.180262302113988e-06 first col mean 0.000276668812148273 all mean 4.3860032747033983e-05
rl training, epoch4, iter0, batch88/1133, batch loss:0.00152150250505656, Training time:105010.7419705391
batch reward last col mean 6.69961536914343e-07 first col mean 3.911625753971748e-06 all mean 2.5292340524174506e-06
rl training, epoch4, iter0, batch89/1133, batch loss:9.402149885318067e-07, Training time:105038.57563447952
batch reward last col mean 2.4133452825481072e-05 first col mean 2.2920792616787367e-05 all mean 3.8524449337273836e-05
rl training, epoch4, iter0, batch90/1133, batch loss:0.0003955293504986912, Training time:105065.53764224052
batch reward last col mean 3.1288698210119037e-06 first col mean 1.862839553723461e-06 all mean 3.1881502309261123e-06
rl training, epoch4, iter0, batch91/1133, batch loss:4.630875992006622e-06, Training time:105092.93841695786
batch reward last col mean 7.467367595381802e-06 first col mean 8.270340913441032e-06 all mean 1.0453619324835017e-05
rl training, epoch4, iter0, batch92/1133, batch loss:4.5386103010969236e-05, Training time:105120.16899847984
batch reward last col mean 0.001762630883604288 first col mean 2.33866308008146e-06 all mean 0.0016714563826099038
rl training, epoch4, iter0, batch93/1133, batch loss:0.0008669298840686679, Training time:105148.26670122147
batch reward last col mean 1.2087916729797143e-06 first col mean 1.084942869056249e-05 all mean 1.3533787068809033e-06
rl training, epoch4, iter0, batch94/1133, batch loss:2.3478385173802963e-06, Training time:105175.9885172844
batch reward last col mean 0.004754797089844942 first col mean 0.0014048304874449968 all mean 0.004721564706414938
rl training, epoch4, iter0, batch95/1133, batch loss:0.0017020013183355331, Training time:105203.3490498066
batch reward last col mean 1.400193241352099e-06 first col mean 1.3990855222800747e-05 all mean 1.6565498981435667e-06
rl training, epoch4, iter0, batch96/1133, batch loss:2.363237399549689e-06, Training time:105230.51239490509
batch reward last col mean 0.00013387369108386338 first col mean 0.00013495988969225436 all mean 0.00014048592129256576
rl training, epoch4, iter0, batch97/1133, batch loss:0.00012338800297584385, Training time:105257.71130347252
batch reward last col mean 9.85392034635879e-07 first col mean 1.0616820873110555e-05 all mean 1.1976584346484742e-06
rl training, epoch4, iter0, batch98/1133, batch loss:2.105378143824055e-06, Training time:105285.37737584114
batch reward last col mean 4.6474508508254075e-07 first col mean 1.8955004634335637e-05 all mean 7.447396228599246e-07
rl training, epoch4, iter0, batch99/1133, batch loss:1.8283441249877797e-06, Training time:105312.78858089447
batch reward last col mean 3.6238077427697135e-06 first col mean 3.220969119865913e-06 all mean 3.5364255381864496e-06
rl training, epoch4, iter0, batch100/1133, batch loss:1.8417475757814827e-06, Training time:105340.13083148003
batch reward last col mean 0.0009179069311358035 first col mean 9.332690387964249e-05 all mean 0.0008734047878533602
rl training, epoch4, iter0, batch101/1133, batch loss:0.0006650296272709966, Training time:105367.8409152031
batch reward last col mean 3.240860905862064e-06 first col mean 2.4599894459242932e-05 all mean 3.377212124178186e-06
rl training, epoch4, iter0, batch102/1133, batch loss:4.673127932619536e-06, Training time:105394.90589547157
batch reward last col mean 0.00010863312490982935 first col mean 0.00027168693486601114 all mean 0.0001105389092117548
rl training, epoch4, iter0, batch103/1133, batch loss:3.345856021041982e-05, Training time:105422.01654362679
batch reward last col mean 0.0036418335512280464 first col mean 1.5220292652884382e-06 all mean 0.0035150167532265186
rl training, epoch4, iter0, batch104/1133, batch loss:0.002061164006590843, Training time:105449.05864095688
batch reward last col mean 6.160180055303499e-05 first col mean 2.9780276236124337e-06 all mean 5.8047811762662604e-05
rl training, epoch4, iter0, batch105/1133, batch loss:1.3156273780623451e-05, Training time:105476.43588495255
batch reward last col mean 2.6047753635793924e-05 first col mean 0.0009174475562758744 all mean 3.5197630495531484e-05
rl training, epoch4, iter0, batch106/1133, batch loss:1.6473264622618444e-05, Training time:105504.29920625687
batch reward last col mean 0.0033473693765699863 first col mean 5.255300493445247e-06 all mean 0.0032514631748199463
rl training, epoch4, iter0, batch107/1133, batch loss:0.001049067243002355, Training time:105531.57859611511
batch reward last col mean 5.420506568043493e-06 first col mean 1.352256617792591e-06 all mean 8.919188985601068e-06
rl training, epoch4, iter0, batch108/1133, batch loss:5.1262861234135926e-05, Training time:105559.03893613815
batch reward last col mean 2.8876233955088537e-06 first col mean 2.5584973627701402e-05 all mean 5.644254542858107e-06
rl training, epoch4, iter0, batch109/1133, batch loss:5.988506381982006e-05, Training time:105586.46069312096
batch reward last col mean 9.310941095463932e-06 first col mean 8.55841426528059e-06 all mean 2.7850212063640356e-05
rl training, epoch4, iter0, batch110/1133, batch loss:3.41246159223374e-05, Training time:105613.65201878548
batch reward last col mean 2.8632066459977068e-05 first col mean 4.302775414544158e-05 all mean 2.886587753891945e-05
rl training, epoch4, iter0, batch111/1133, batch loss:6.569883225893136e-06, Training time:105641.27325510979
batch reward last col mean 0.00038190706982277334 first col mean 0.0009723678813315928 all mean 0.0003886184422299266
rl training, epoch4, iter0, batch112/1133, batch loss:0.00038662811857648194, Training time:105668.60122346878
batch reward last col mean 5.944249892309017e-07 first col mean 1.3444468095258344e-05 all mean 2.1053533600934315e-06
rl training, epoch4, iter0, batch113/1133, batch loss:6.210410356288776e-05, Training time:105696.03293418884
batch reward last col mean 6.540153663081583e-07 first col mean 1.4215269175110734e-06 all mean 7.343584229602129e-07
rl training, epoch4, iter0, batch114/1133, batch loss:1.4044783256395021e-06, Training time:105723.3785161972
batch reward last col mean 3.1491847039433196e-05 first col mean 7.880935299908742e-06 all mean 4.550849916995503e-05
rl training, epoch4, iter0, batch115/1133, batch loss:0.00014055697829462588, Training time:105750.83167362213
batch reward last col mean 2.0832289919781033e-06 first col mean 4.329389412305318e-05 all mean 2.501547214706079e-06
rl training, epoch4, iter0, batch116/1133, batch loss:1.9760532268264797e-06, Training time:105778.61484098434
batch reward last col mean 1.2481501698857755e-06 first col mean 7.149269367801026e-05 all mean 1.549315857118927e-05
rl training, epoch4, iter0, batch117/1133, batch loss:0.0003320058749523014, Training time:105805.96269655228
batch reward last col mean 2.2124127099232282e-06 first col mean 1.8663393348106183e-05 all mean 3.78128606826067e-05
rl training, epoch4, iter0, batch118/1133, batch loss:7.963962707435712e-05, Training time:105833.60952925682
batch reward last col mean 3.700704610309913e-06 first col mean 1.4757488315808587e-06 all mean 3.584938667700044e-06
rl training, epoch4, iter0, batch119/1133, batch loss:2.3400791633321205e-06, Training time:105861.44453549385
batch reward last col mean 4.941770384903066e-05 first col mean 0.00034510091063566506 all mean 5.252994378679432e-05
rl training, epoch4, iter0, batch120/1133, batch loss:2.48533979174681e-05, Training time:105888.95253324509
batch reward last col mean 3.6556680242938455e-06 first col mean 1.5013657730378327e-06 all mean 3.819338417088147e-06
rl training, epoch4, iter0, batch121/1133, batch loss:4.393818471726263e-06, Training time:105916.0827562809
batch reward last col mean 1.3475342939273105e-06 first col mean 0.00010522839147597551 all mean 8.093421456578653e-06
rl training, epoch4, iter0, batch122/1133, batch loss:0.00014332192949950695, Training time:105943.45422697067
batch reward last col mean 4.617076228896622e-06 first col mean 3.824759915005416e-05 all mean 6.585675691894721e-06
rl training, epoch4, iter0, batch123/1133, batch loss:1.3835009667673148e-05, Training time:105970.74820327759
batch reward last col mean 9.385636303704814e-07 first col mean 3.4926033549709246e-05 all mean 1.0535245564824436e-05
rl training, epoch4, iter0, batch124/1133, batch loss:3.1992898584576324e-05, Training time:105998.7021651268
batch reward last col mean 1.4894621926941909e-06 first col mean 3.870141881634481e-05 all mean 5.904364115849603e-06
rl training, epoch4, iter0, batch125/1133, batch loss:8.345722744707018e-05, Training time:106026.77815246582
batch reward last col mean 3.2509931315871654e-06 first col mean 0.00042305560782551765 all mean 7.4826093623414636e-06
rl training, epoch4, iter0, batch126/1133, batch loss:3.512165494612418e-05, Training time:106054.59645915031
batch reward last col mean 3.07531954604201e-05 first col mean 0.0003244851541239768 all mean 3.370619015186094e-05
rl training, epoch4, iter0, batch127/1133, batch loss:3.047050631721504e-05, Training time:106082.341735363
batch reward last col mean 0.00012016684195259586 first col mean 0.0019445893121883273 all mean 0.00013866701920051128
rl training, epoch4, iter0, batch128/1133, batch loss:9.127488010562956e-05, Training time:106110.50744533539
batch reward last col mean 5.9309095377102494e-06 first col mean 1.3236954146123026e-06 all mean 4.5519776904257014e-05
rl training, epoch4, iter0, batch129/1133, batch loss:0.001766566769219935, Training time:106137.86335921288
batch reward last col mean 1.1948740166189964e-06 first col mean 0.00019141127995681018 all mean 3.813223884208128e-05
rl training, epoch4, iter0, batch130/1133, batch loss:7.911726424936205e-05, Training time:106165.68632411957
batch reward last col mean 0.0055580949410796165 first col mean 0.0021219428163021803 all mean 0.0053181336261332035
rl training, epoch4, iter0, batch131/1133, batch loss:0.002201120601966977, Training time:106193.29800200462
batch reward last col mean 1.679819069977384e-05 first col mean 0.00023783213691785932 all mean 3.686303170979954e-05
rl training, epoch4, iter0, batch132/1133, batch loss:0.0006425753235816956, Training time:106220.6987528801
batch reward last col mean 3.74313202655685e-07 first col mean 3.267333158873953e-05 all mean 1.6388763697250397e-06
rl training, epoch4, iter0, batch133/1133, batch loss:1.1486902621982154e-05, Training time:106248.16913175583
batch reward last col mean 9.28641929931473e-06 first col mean 0.0015323138795793056 all mean 2.5500747142359614e-05
rl training, epoch4, iter0, batch134/1133, batch loss:3.898801514878869e-05, Training time:106276.53824806213
batch reward last col mean 3.96024279325502e-06 first col mean 2.7152123948326334e-05 all mean 5.290092303766869e-06
rl training, epoch4, iter0, batch135/1133, batch loss:5.1111066568410024e-05, Training time:106303.58296084404
batch reward last col mean 4.184662884654244e-06 first col mean 2.1495393411896657e-06 all mean 4.673958301282255e-06
rl training, epoch4, iter0, batch136/1133, batch loss:3.593779183574952e-06, Training time:106330.88453221321
batch reward last col mean 2.2233318304643035e-05 first col mean 9.64611808740301e-06 all mean 2.4277194825117476e-05
rl training, epoch4, iter0, batch137/1133, batch loss:6.67232961859554e-05, Training time:106358.84985113144
batch reward last col mean 1.441165295545943e-06 first col mean 3.3982032618951052e-06 all mean 6.653101991105359e-06
rl training, epoch4, iter0, batch138/1133, batch loss:2.326235335203819e-05, Training time:106386.21468448639
batch reward last col mean 0.0015367066953331232 first col mean 0.0004280299472156912 all mean 0.0014930698089301586
rl training, epoch4, iter0, batch139/1133, batch loss:0.0018539071315899491, Training time:106413.55691742897
batch reward last col mean 9.355763177154586e-05 first col mean 3.5115731407131534e-06 all mean 0.00010067307448480278
rl training, epoch4, iter0, batch140/1133, batch loss:0.0004358873120509088, Training time:106440.79153132439
batch reward last col mean 3.4629218248483085e-07 first col mean 7.770867114231805e-07 all mean 4.861303750658408e-07
rl training, epoch4, iter0, batch141/1133, batch loss:9.202079809256247e-07, Training time:106468.87236189842
batch reward last col mean 5.225193035585107e-06 first col mean 1.218621400767006e-05 all mean 5.425324616226135e-06
rl training, epoch4, iter0, batch142/1133, batch loss:7.2844745773181785e-06, Training time:106496.40916228294
batch reward last col mean 0.0002740715863183141 first col mean 1.1251097475906136e-06 all mean 0.0002577573759481311
rl training, epoch4, iter0, batch143/1133, batch loss:0.00016191950999200344, Training time:106523.73372340202
batch reward last col mean 6.319636213447666e-06 first col mean 4.026915121357888e-06 all mean 3.136691520921886e-05
rl training, epoch4, iter0, batch144/1133, batch loss:0.0002788263373076916, Training time:106551.47834706306
batch reward last col mean 0.0004986526328139007 first col mean 4.4934429752174765e-05 all mean 0.00048462324775755405
rl training, epoch4, iter0, batch145/1133, batch loss:0.00019674518262036145, Training time:106578.56097650528
batch reward last col mean 1.2529823152362951e-06 first col mean 8.830168371787295e-05 all mean 2.2642150270257844e-06
rl training, epoch4, iter0, batch146/1133, batch loss:5.235025582805974e-06, Training time:106605.89753890038
batch reward last col mean 6.230120106920367e-06 first col mean 7.3222604441980366e-06 all mean 6.013451184117002e-06
rl training, epoch4, iter0, batch147/1133, batch loss:7.625666512467433e-06, Training time:106633.51556992531
batch reward last col mean 2.169444996980019e-06 first col mean 0.0016003232449293137 all mean 2.343622145417612e-05
rl training, epoch4, iter0, batch148/1133, batch loss:0.0001057670233421959, Training time:106661.1487774849
batch reward last col mean 9.415136332791008e-07 first col mean 3.748162998817861e-05 all mean 1.3351664165384136e-06
rl training, epoch4, iter0, batch149/1133, batch loss:1.4769531162528438e-06, Training time:106688.56491398811
batch reward last col mean 1.2562848041852703e-06 first col mean 2.386940650467295e-06 all mean 4.832518243347295e-06
rl training, epoch4, iter0, batch150/1133, batch loss:3.779019243665971e-05, Training time:106715.62919020653
batch reward last col mean 1.8821430785465054e-05 first col mean 7.867989188525826e-05 all mean 1.9903845895896666e-05
rl training, epoch4, iter0, batch151/1133, batch loss:3.058137372136116e-05, Training time:106742.89434504509
batch reward last col mean 3.4227575724798953e-06 first col mean 4.676249227486551e-05 all mean 4.09597987527377e-06
rl training, epoch4, iter0, batch152/1133, batch loss:4.300101409171475e-06, Training time:106769.96239066124
batch reward last col mean 6.650398063356988e-07 first col mean 3.354351065354422e-05 all mean 1.1115376992165693e-06
rl training, epoch4, iter0, batch153/1133, batch loss:3.193725206074305e-06, Training time:106798.10320067406
batch reward last col mean 0.00034515836159698665 first col mean 1.0269901395076886e-05 all mean 0.00032276890124194324
rl training, epoch4, iter0, batch154/1133, batch loss:0.0002671928086783737, Training time:106825.5735654831
batch reward last col mean 6.1791229200025555e-06 first col mean 2.0035263332829345e-06 all mean 2.0254790797480382e-05
rl training, epoch4, iter0, batch155/1133, batch loss:3.39031576004345e-05, Training time:106852.9023578167
batch reward last col mean 3.3931493817362934e-05 first col mean 7.09568485035561e-06 all mean 4.0172901208279654e-05
rl training, epoch4, iter0, batch156/1133, batch loss:0.00029051120509393513, Training time:106880.86530852318
batch reward last col mean 2.2828901364846388e-06 first col mean 1.3118949027557392e-05 all mean 5.091369530418888e-06
rl training, epoch4, iter0, batch157/1133, batch loss:3.416156323510222e-05, Training time:106908.12411284447
batch reward last col mean 7.69963548918895e-07 first col mean 0.00027114449767395854 all mean 5.187207079870859e-06
rl training, epoch4, iter0, batch158/1133, batch loss:1.9887536836904474e-05, Training time:106935.95194125175
batch reward last col mean 0.00375810987316072 first col mean 0.001875696936622262 all mean 0.0036968139465898275
rl training, epoch4, iter0, batch159/1133, batch loss:0.0010834827553480864, Training time:106963.94056534767
batch reward last col mean 0.006336963269859552 first col mean 0.00014221952005755156 all mean 0.0059731751680374146
rl training, epoch4, iter0, batch160/1133, batch loss:0.005916093476116657, Training time:106991.5391767025
batch reward last col mean 3.6594790344679495e-06 first col mean 3.742385160876438e-05 all mean 5.9501369833014905e-05
rl training, epoch4, iter0, batch161/1133, batch loss:0.00046306930016726255, Training time:107018.78607964516
batch reward last col mean 3.1216297884384403e-06 first col mean 4.611179974745028e-06 all mean 2.2955735403229482e-05
rl training, epoch4, iter0, batch162/1133, batch loss:0.0012837062822654843, Training time:107046.50139141083
batch reward last col mean 3.174148878315464e-05 first col mean 8.20781281163363e-07 all mean 3.001253389811609e-05
rl training, epoch4, iter0, batch163/1133, batch loss:1.7287045920966193e-05, Training time:107073.80775380135
batch reward last col mean 1.6520120880159084e-06 first col mean 4.2052297430927865e-06 all mean 1.0749011380539741e-05
rl training, epoch4, iter0, batch164/1133, batch loss:0.00025500348419882357, Training time:107101.12408423424
batch reward last col mean 6.686643246212043e-06 first col mean 0.0006711712339892983 all mean 1.3760717592958827e-05
rl training, epoch4, iter0, batch165/1133, batch loss:0.00041887929546646774, Training time:107128.78158760071
batch reward last col mean 1.7884370890897117e-06 first col mean 3.265904888394289e-05 all mean 2.64221216639271e-06
rl training, epoch4, iter0, batch166/1133, batch loss:6.797280093451263e-06, Training time:107156.16465783119
batch reward last col mean 5.568425422097789e-06 first col mean 0.00015698274364694953 all mean 6.8098083829681855e-06
rl training, epoch4, iter0, batch167/1133, batch loss:1.4661056411569007e-05, Training time:107183.83967494965
batch reward last col mean 1.2414417369654984e-06 first col mean 1.1084755897172727e-05 all mean 4.056435045640683e-06
rl training, epoch4, iter0, batch168/1133, batch loss:4.246136450092308e-05, Training time:107211.45825052261
batch reward last col mean 1.3766903066425584e-06 first col mean 4.271046236681286e-06 all mean 1.4989462897574413e-06
rl training, epoch4, iter0, batch169/1133, batch loss:2.4571138510509627e-06, Training time:107238.8278427124
batch reward last col mean 0.0001515831536380574 first col mean 0.0014988362090662122 all mean 0.00016971107106655836
rl training, epoch4, iter0, batch170/1133, batch loss:0.0001247940817847848, Training time:107266.44782829285
batch reward last col mean 7.145948984543793e-06 first col mean 3.9445363654522225e-05 all mean 8.094073564279824e-06
rl training, epoch4, iter0, batch171/1133, batch loss:7.5397251748654526e-06, Training time:107293.64561605453
batch reward last col mean 0.0007898685289546847 first col mean 3.950124664697796e-05 all mean 0.0007830411195755005
rl training, epoch4, iter0, batch172/1133, batch loss:0.0003175469464622438, Training time:107320.87003040314
batch reward last col mean 1.7415504771634005e-05 first col mean 0.0001001059208647348 all mean 2.1489462596946396e-05
rl training, epoch4, iter0, batch173/1133, batch loss:9.703282557893544e-05, Training time:107348.52743148804
batch reward last col mean 9.29559803353186e-07 first col mean 8.588839364165324e-07 all mean 1.0942532071567257e-06
rl training, epoch4, iter0, batch174/1133, batch loss:1.8169137092627352e-06, Training time:107376.26984286308
batch reward last col mean 1.5488494682358578e-06 first col mean 1.8902956071542576e-06 all mean 2.237466560472967e-06
rl training, epoch4, iter0, batch175/1133, batch loss:6.473507255577715e-06, Training time:107403.94292521477
batch reward last col mean 2.1824353098054416e-05 first col mean 0.001053379150107503 all mean 3.184944580425508e-05
rl training, epoch4, iter0, batch176/1133, batch loss:1.7818832930061035e-05, Training time:107431.67606210709
batch reward last col mean 0.004722977988421917 first col mean 1.5404644727823325e-05 all mean 0.0045995102263987064
rl training, epoch4, iter0, batch177/1133, batch loss:0.0026760173495858908, Training time:107458.85360193253
batch reward last col mean 0.0016298269620165229 first col mean 1.1404708857298829e-05 all mean 0.001523371902294457
rl training, epoch4, iter0, batch178/1133, batch loss:0.0020964606665074825, Training time:107486.4956150055
batch reward last col mean 1.0241633390251081e-05 first col mean 0.00022560784418601543 all mean 1.8319302398595028e-05
rl training, epoch4, iter0, batch179/1133, batch loss:6.807017052778974e-05, Training time:107513.91259813309
batch reward last col mean 3.899370312865358e-06 first col mean 0.0009843969019129872 all mean 2.158058123313822e-05
rl training, epoch4, iter0, batch180/1133, batch loss:0.00021113008551765233, Training time:107540.98493766785
batch reward last col mean 7.790999370627105e-05 first col mean 0.0014490003231912851 all mean 9.677648631623015e-05
rl training, epoch4, iter0, batch181/1133, batch loss:6.501745519926772e-05, Training time:107568.37674665451
batch reward last col mean 6.582943115063244e-07 first col mean 4.981419806426857e-06 all mean 7.70325004850747e-06
rl training, epoch4, iter0, batch182/1133, batch loss:3.28549649566412e-05, Training time:107595.59418559074
batch reward last col mean 9.672667147242464e-06 first col mean 0.000989991705864668 all mean 1.920046634040773e-05
rl training, epoch4, iter0, batch183/1133, batch loss:7.4631198003771715e-06, Training time:107623.78785443306
batch reward last col mean 7.08281913830433e-06 first col mean 1.8311939129489474e-06 all mean 3.644229582278058e-05
rl training, epoch4, iter0, batch184/1133, batch loss:0.0006004160968586802, Training time:107651.45954656601
batch reward last col mean 1.632857902222895e-06 first col mean 8.261632501671556e-06 all mean 1.922016053867992e-06
rl training, epoch4, iter0, batch185/1133, batch loss:4.598286068357993e-06, Training time:107679.16706967354
batch reward last col mean 6.846323117315478e-07 first col mean 7.867284693929832e-06 all mean 1.2672208868025336e-05
rl training, epoch4, iter0, batch186/1133, batch loss:2.0281684555811808e-05, Training time:107706.46245503426
batch reward last col mean 3.2135787478182465e-05 first col mean 1.6740247019697563e-06 all mean 2.926591878349427e-05
rl training, epoch4, iter0, batch187/1133, batch loss:2.7015434170607477e-05, Training time:107733.58209443092
batch reward last col mean 3.333209315314889e-05 first col mean 4.548636206891388e-05 all mean 4.4009990233462304e-05
rl training, epoch4, iter0, batch188/1133, batch loss:0.0002209304366260767, Training time:107760.96945977211
batch reward last col mean 2.038025741057936e-06 first col mean 1.522207412563148e-06 all mean 2.3900777250673855e-06
rl training, epoch4, iter0, batch189/1133, batch loss:5.6058138397929724e-06, Training time:107788.15430474281
batch reward last col mean 9.59690169111127e-06 first col mean 1.561492172186263e-05 all mean 1.1693490705511067e-05
rl training, epoch4, iter0, batch190/1133, batch loss:3.471801755949855e-05, Training time:107816.2253677845
batch reward last col mean 0.006197509355843067 first col mean 0.0020912240725010633 all mean 0.006045782007277012
rl training, epoch4, iter0, batch191/1133, batch loss:0.004151909612119198, Training time:107843.33028435707
batch reward last col mean 4.0304698813997675e-06 first col mean 3.0663839424960315e-05 all mean 1.0510568245081231e-05
rl training, epoch4, iter0, batch192/1133, batch loss:0.00032284745248034596, Training time:107870.44070196152
batch reward last col mean 2.6249904294672888e-06 first col mean 2.3841748770792037e-05 all mean 2.068287540168967e-05
rl training, epoch4, iter0, batch193/1133, batch loss:0.0005542018334381282, Training time:107897.60230016708
batch reward last col mean 8.05575609774678e-07 first col mean 1.41743794301874e-05 all mean 1.9883725599356694e-06
rl training, epoch4, iter0, batch194/1133, batch loss:1.0892731552303303e-05, Training time:107925.15026283264
batch reward last col mean 2.9113552955095656e-06 first col mean 0.00039150897646322846 all mean 1.0294120329490397e-05
rl training, epoch4, iter0, batch195/1133, batch loss:0.00018920880393125117, Training time:107952.4931550026
batch reward last col mean 0.0008152170921675861 first col mean 2.902583401009906e-05 all mean 0.0007626074366271496
rl training, epoch4, iter0, batch196/1133, batch loss:0.0002758003829512745, Training time:107979.61689162254
batch reward last col mean 1.723552486510016e-05 first col mean 1.5243113011820242e-05 all mean 1.723737659631297e-05
rl training, epoch4, iter0, batch197/1133, batch loss:1.0534655302762985e-05, Training time:108006.87833213806
batch reward last col mean 3.0139151931507513e-05 first col mean 0.0001708221243461594 all mean 3.223093881388195e-05
rl training, epoch4, iter0, batch198/1133, batch loss:4.4493310269899666e-05, Training time:108034.23657727242
batch reward last col mean 2.3542131657450227e-06 first col mean 8.68216302478686e-05 all mean 2.0192164811305702e-05
rl training, epoch4, iter0, batch199/1133, batch loss:0.00016175879864022136, Training time:108062.1142129898
batch reward last col mean 8.426728754784563e-07 first col mean 1.909284037537873e-06 all mean 2.657645381987095e-05
rl training, epoch4, iter0, batch200/1133, batch loss:0.0004279852728359401, Training time:108089.34303736687
batch reward last col mean 5.133651939104311e-06 first col mean 0.0002215182757936418 all mean 7.674068001506384e-06
rl training, epoch4, iter0, batch201/1133, batch loss:1.3589850823336747e-05, Training time:108116.58981394768
batch reward last col mean 4.714222450274974e-05 first col mean 3.933079642592929e-05 all mean 4.6771441702730954e-05
rl training, epoch4, iter0, batch202/1133, batch loss:2.0342453353805467e-05, Training time:108144.06749844551
batch reward last col mean 0.00028866028878837824 first col mean 0.0011125952005386353 all mean 0.00029731658287346363
rl training, epoch4, iter0, batch203/1133, batch loss:0.00010470567940501496, Training time:108172.08994245529
batch reward last col mean 0.000422574084950611 first col mean 0.0002622439933475107 all mean 0.0004174256173428148
rl training, epoch4, iter0, batch204/1133, batch loss:0.000500011257827282, Training time:108199.80723166466
batch reward last col mean 2.8230615498614497e-05 first col mean 0.0006704299012199044 all mean 3.3803025871748105e-05
rl training, epoch4, iter0, batch205/1133, batch loss:1.8834360162145458e-05, Training time:108227.94618487358
batch reward last col mean 3.655612317743362e-06 first col mean 0.0001543888938613236 all mean 1.2510276064858772e-05
rl training, epoch4, iter0, batch206/1133, batch loss:3.0119445000309497e-05, Training time:108255.46779179573
batch reward last col mean 0.00015559405437670648 first col mean 0.00010447002568980679 all mean 0.0001573433546582237
rl training, epoch4, iter0, batch207/1133, batch loss:0.0001344078336842358, Training time:108283.58615660667
batch reward last col mean 2.1789817765238695e-05 first col mean 5.428844451671466e-05 all mean 2.782914634735789e-05
rl training, epoch4, iter0, batch208/1133, batch loss:0.00019587109272833914, Training time:108311.06613492966
batch reward last col mean 0.0028148582205176353 first col mean 0.0007645596633665264 all mean 0.0027977486606687307
rl training, epoch4, iter0, batch209/1133, batch loss:0.0015379526885226369, Training time:108338.54557681084
batch reward last col mean 0.002565631875768304 first col mean 0.00011354683374520391 all mean 0.0025062602944672108
rl training, epoch4, iter0, batch210/1133, batch loss:0.0006343831773847342, Training time:108366.0565571785
batch reward last col mean 5.842903192387894e-06 first col mean 0.0012926678173244 all mean 2.3730362954665907e-05
rl training, epoch4, iter0, batch211/1133, batch loss:3.633946107584052e-05, Training time:108393.56621694565
batch reward last col mean 1.6353334331142833e-06 first col mean 1.662866816332098e-05 all mean 3.1005756682134233e-06
rl training, epoch4, iter0, batch212/1133, batch loss:7.827305125829298e-06, Training time:108421.03849840164
batch reward last col mean 5.29637190993526e-06 first col mean 5.074971795693273e-06 all mean 6.808932084823027e-06
rl training, epoch4, iter0, batch213/1133, batch loss:1.7791408026823774e-05, Training time:108448.39501857758
batch reward last col mean 0.00011861891107400879 first col mean 0.00035268458304926753 all mean 0.00012646678078453988
rl training, epoch4, iter0, batch214/1133, batch loss:0.0004007888783235103, Training time:108475.63416838646
batch reward last col mean 1.3785634109808598e-05 first col mean 6.685469998046756e-06 all mean 1.3482248505169991e-05
rl training, epoch4, iter0, batch215/1133, batch loss:1.1337493560859002e-05, Training time:108502.77400231361
batch reward last col mean 0.007693189661949873 first col mean 0.0027523860335350037 all mean 0.007779337000101805
rl training, epoch4, iter0, batch216/1133, batch loss:0.0049166008830070496, Training time:108530.0714070797
batch reward last col mean 8.77741115345998e-07 first col mean 2.1530009689740837e-05 all mean 2.2379188067134237e-06
rl training, epoch4, iter0, batch217/1133, batch loss:5.590349701378727e-06, Training time:108557.3191435337
batch reward last col mean 0.001852329820394516 first col mean 6.249694251891924e-06 all mean 0.001811544643715024
rl training, epoch4, iter0, batch218/1133, batch loss:0.00086973822908476, Training time:108584.67079353333
batch reward last col mean 1.027798316499684e-05 first col mean 2.4771588869043626e-06 all mean 6.998709432082251e-05
rl training, epoch4, iter0, batch219/1133, batch loss:0.00030317212804220617, Training time:108612.22599315643
batch reward last col mean 0.00016359437722712755 first col mean 5.193319884710945e-05 all mean 0.00016856288129929453
rl training, epoch4, iter0, batch220/1133, batch loss:0.000419007585151121, Training time:108639.41951346397
batch reward last col mean 7.684909178351518e-06 first col mean 0.0007534240139648318 all mean 1.5564010027446784e-05
rl training, epoch4, iter0, batch221/1133, batch loss:1.1573895790206734e-05, Training time:108666.7446820736
batch reward last col mean 9.087849548450322e-07 first col mean 4.121708570892224e-06 all mean 1.5618013549101306e-06
rl training, epoch4, iter0, batch222/1133, batch loss:3.4900574519269867e-06, Training time:108694.51211237907
batch reward last col mean 1.6663896531099454e-05 first col mean 0.00019526120740920305 all mean 4.227852696203627e-05
rl training, epoch4, iter0, batch223/1133, batch loss:5.8482448366703466e-05, Training time:108721.94906544685
batch reward last col mean 5.499359758687206e-06 first col mean 2.8950241812708555e-06 all mean 5.648976639349712e-06
rl training, epoch4, iter0, batch224/1133, batch loss:5.455503924167715e-06, Training time:108749.52720975876
batch reward last col mean 0.012256322428584099 first col mean 0.00014829427527729422 all mean 0.011952833272516727
rl training, epoch4, iter0, batch225/1133, batch loss:0.01137594785541296, Training time:108777.22501087189
batch reward last col mean 0.000984508660621941 first col mean 5.8258548961021006e-05 all mean 0.0009494985570199788
rl training, epoch4, iter0, batch226/1133, batch loss:0.0008349568233825266, Training time:108804.38409256935
batch reward last col mean 2.0826068066526204e-05 first col mean 3.393192173462012e-06 all mean 1.947670170920901e-05
rl training, epoch4, iter0, batch227/1133, batch loss:2.209573722211644e-05, Training time:108831.80603384972
batch reward last col mean 1.4390931028174236e-05 first col mean 3.2097523217089474e-05 all mean 1.5731446183053777e-05
rl training, epoch4, iter0, batch228/1133, batch loss:3.655231193988584e-05, Training time:108859.240827322
batch reward last col mean 0.00016238151874858886 first col mean 0.0005162834422662854 all mean 0.0002111785433953628
rl training, epoch4, iter0, batch229/1133, batch loss:0.0008379711071029305, Training time:108886.74568343163
batch reward last col mean 0.0001946130651049316 first col mean 0.0003343711723573506 all mean 0.00024033898080233485
rl training, epoch4, iter0, batch230/1133, batch loss:0.0014566890895366669, Training time:108914.15466022491
batch reward last col mean 3.295913984402432e-06 first col mean 0.00048536158283241093 all mean 8.324079317389987e-06
rl training, epoch4, iter0, batch231/1133, batch loss:8.022838301258162e-06, Training time:108941.24918699265
batch reward last col mean 4.506840923568234e-05 first col mean 0.00019292140495963395 all mean 5.619841249426827e-05
rl training, epoch4, iter0, batch232/1133, batch loss:0.00014625611947849393, Training time:108968.63520622253
batch reward last col mean 8.465563951176591e-06 first col mean 0.0006586855161003768 all mean 3.654761167126708e-05
rl training, epoch4, iter0, batch233/1133, batch loss:3.318339440738782e-05, Training time:108996.23748469353
batch reward last col mean 0.008080068044364452 first col mean 4.1558236262062564e-05 all mean 0.007763260509818792
rl training, epoch4, iter0, batch234/1133, batch loss:0.005472957156598568, Training time:109023.87328696251
batch reward last col mean 1.5757628716528416e-05 first col mean 0.0003579475451260805 all mean 4.0159815398510545e-05
rl training, epoch4, iter0, batch235/1133, batch loss:0.0003434368409216404, Training time:109051.28105401993
batch reward last col mean 1.2108687769796234e-05 first col mean 0.002387239597737789 all mean 3.582274803193286e-05
rl training, epoch4, iter0, batch236/1133, batch loss:1.7587331967661157e-05, Training time:109078.69383883476
batch reward last col mean 1.9352039089426398e-05 first col mean 0.00012766977306455374 all mean 2.1041892978246324e-05
rl training, epoch4, iter0, batch237/1133, batch loss:1.4932677004253492e-05, Training time:109106.07558941841
batch reward last col mean 0.003745801281183958 first col mean 0.00014468033623415977 all mean 0.0035171774215996265
rl training, epoch4, iter0, batch238/1133, batch loss:0.00601755827665329, Training time:109134.24599909782
batch reward last col mean 6.821500846854178e-06 first col mean 1.8100879970006645e-05 all mean 1.6775389667600393e-05
rl training, epoch4, iter0, batch239/1133, batch loss:4.497392365010455e-05, Training time:109161.77129220963
batch reward last col mean 0.0001324400946032256 first col mean 9.684483666205779e-05 all mean 0.00013005304208490998
rl training, epoch4, iter0, batch240/1133, batch loss:8.226521458709612e-05, Training time:109189.13050365448
batch reward last col mean 2.0917144865961745e-05 first col mean 2.3536747903563082e-05 all mean 2.467654849169776e-05
rl training, epoch4, iter0, batch241/1133, batch loss:1.6008481907192618e-05, Training time:109216.49503016472
batch reward last col mean 2.675578070920892e-05 first col mean 4.569901284412481e-05 all mean 6.137818854767829e-05
rl training, epoch4, iter0, batch242/1133, batch loss:0.000468005717266351, Training time:109244.42467021942
batch reward last col mean 0.0012927494244650006 first col mean 3.189696144545451e-06 all mean 0.0012289790902286768
rl training, epoch4, iter0, batch243/1133, batch loss:0.0011075339280068874, Training time:109272.36105751991
batch reward last col mean 4.181539225101005e-06 first col mean 0.001029390492476523 all mean 8.063847781158984e-05
rl training, epoch4, iter0, batch244/1133, batch loss:0.0016396811697632074, Training time:109300.14756846428
batch reward last col mean 6.144879876046616e-07 first col mean 0.001193211181089282 all mean 1.4307011042546947e-05
rl training, epoch4, iter0, batch245/1133, batch loss:2.9735854695900343e-05, Training time:109327.57181119919
batch reward last col mean 5.234460786596173e-06 first col mean 0.00020306173246353865 all mean 7.547409495600732e-06
rl training, epoch4, iter0, batch246/1133, batch loss:5.036151560489088e-05, Training time:109355.13831400871
batch reward last col mean 0.006525513716042042 first col mean 0.004304912406951189 all mean 0.0065293037332594395
rl training, epoch4, iter0, batch247/1133, batch loss:0.004475688096135855, Training time:109382.33122682571
batch reward last col mean 2.7414209398557432e-05 first col mean 5.220652383286506e-06 all mean 4.6495442802552134e-05
rl training, epoch4, iter0, batch248/1133, batch loss:3.192458825651556e-05, Training time:109409.62374329567
batch reward last col mean 1.404573936270026e-06 first col mean 0.00028553049196489155 all mean 2.0857247363892384e-05
rl training, epoch4, iter0, batch249/1133, batch loss:0.0008199169533327222, Training time:109436.82241749763
batch reward last col mean 4.467744929570472e-06 first col mean 5.1766688557108864e-05 all mean 1.5968109437380917e-05
rl training, epoch4, iter0, batch250/1133, batch loss:8.434973278781399e-05, Training time:109464.24785637856
batch reward last col mean 3.0066463295952417e-05 first col mean 3.401126014068723e-05 all mean 6.891657540109009e-05
rl training, epoch4, iter0, batch251/1133, batch loss:6.366852176142856e-05, Training time:109491.7490158081
batch reward last col mean 1.1389302017050795e-06 first col mean 5.589915599557571e-05 all mean 1.4490961802948732e-05
rl training, epoch4, iter0, batch252/1133, batch loss:0.00010394718265160918, Training time:109518.96703648567
batch reward last col mean 0.007749960292130709 first col mean 0.00580860860645771 all mean 0.0077313450165092945
rl training, epoch4, iter0, batch253/1133, batch loss:0.003471312578767538, Training time:109546.26848340034
batch reward last col mean 0.00013760532601736486 first col mean 0.0012373067438602448 all mean 0.0001723358582239598
rl training, epoch4, iter0, batch254/1133, batch loss:9.954327106243e-05, Training time:109574.02680683136
batch reward last col mean 0.00038422728539444506 first col mean 0.0029462678357958794 all mean 0.0004355883284006268
rl training, epoch4, iter0, batch255/1133, batch loss:0.0014486629515886307, Training time:109601.35974740982
batch reward last col mean 0.0003030149091500789 first col mean 6.865544855827466e-05 all mean 0.00039332234882749617
rl training, epoch4, iter0, batch256/1133, batch loss:0.00271399924531579, Training time:109628.61125254631
batch reward last col mean 0.0007490813732147217 first col mean 0.00024303434474859387 all mean 0.0007444936782121658
rl training, epoch4, iter0, batch257/1133, batch loss:0.0004917720798403025, Training time:109655.91751289368
batch reward last col mean 8.55610123835504e-05 first col mean 0.001149214105680585 all mean 0.0001502834929851815
rl training, epoch4, iter0, batch258/1133, batch loss:0.0008801798103377223, Training time:109683.09235358238
batch reward last col mean 2.2998208351054927e-06 first col mean 0.00024399398535024375 all mean 1.1594200259423815e-05
rl training, epoch4, iter0, batch259/1133, batch loss:0.00012207809777464718, Training time:109710.86046385765
batch reward last col mean 0.000492495542857796 first col mean 0.000602284912019968 all mean 0.0004939197679050267
rl training, epoch4, iter0, batch260/1133, batch loss:0.00033358274959027767, Training time:109738.17036414146
batch reward last col mean 0.005147167015820742 first col mean 0.0005568397464230657 all mean 0.004975547548383474
rl training, epoch4, iter0, batch261/1133, batch loss:0.005615712143480778, Training time:109766.00685977936
batch reward last col mean 0.0005103493458591402 first col mean 0.0005033608758822083 all mean 0.0005622436292469501
rl training, epoch4, iter0, batch262/1133, batch loss:0.0012392852222546935, Training time:109794.021078825
batch reward last col mean 0.0030123924370855093 first col mean 0.0026282172184437513 all mean 0.002953580114990473
rl training, epoch4, iter0, batch263/1133, batch loss:0.0010730338981375098, Training time:109821.14234781265
batch reward last col mean 2.1534158804570325e-05 first col mean 0.00028205226408317685 all mean 6.205647514434531e-05
rl training, epoch4, iter0, batch264/1133, batch loss:0.0010228886967524886, Training time:109848.47878289223
batch reward last col mean 0.004067138768732548 first col mean 0.0007084650569595397 all mean 0.004004645626991987
rl training, epoch4, iter0, batch265/1133, batch loss:0.002791664795950055, Training time:109875.81651568413
batch reward last col mean 0.008130623959004879 first col mean 0.007886133156716824 all mean 0.008148996159434319
rl training, epoch4, iter0, batch266/1133, batch loss:0.003007434541359544, Training time:109902.97443532944
batch reward last col mean 1.1430673112045042e-05 first col mean 0.003953763749450445 all mean 9.098594455281273e-05
rl training, epoch4, iter0, batch267/1133, batch loss:0.0005758164334110916, Training time:109930.17949104309
batch reward last col mean 0.00772132771089673 first col mean 0.004916823469102383 all mean 0.007677900604903698
rl training, epoch4, iter0, batch268/1133, batch loss:0.0070496005937457085, Training time:109957.40638184547
batch reward last col mean 0.004962532315403223 first col mean 0.0033919785637408495 all mean 0.004975899122655392
rl training, epoch4, iter0, batch269/1133, batch loss:0.002105706138536334, Training time:109984.43719792366
batch reward last col mean 0.0068902564235031605 first col mean 0.004882149863988161 all mean 0.006900238338857889
rl training, epoch4, iter0, batch270/1133, batch loss:0.005688409321010113, Training time:110011.80797886848
batch reward last col mean 0.001777010620571673 first col mean 0.0013097594492137432 all mean 0.0017612618394196033
rl training, epoch4, iter0, batch271/1133, batch loss:0.001350145204924047, Training time:110038.9075627327
batch reward last col mean 0.007882718928158283 first col mean 0.0007730554789304733 all mean 0.007632773369550705
rl training, epoch4, iter0, batch272/1133, batch loss:0.006171477492898703, Training time:110066.35773515701
batch reward last col mean 4.039155101054348e-05 first col mean 0.007048949599266052 all mean 0.00014624700997956097
rl training, epoch4, iter0, batch273/1133, batch loss:0.002012977609410882, Training time:110093.68770551682
batch reward last col mean 0.007544896099716425 first col mean 0.004883707966655493 all mean 0.00751891266554594
rl training, epoch4, iter0, batch274/1133, batch loss:0.0021089394576847553, Training time:110120.9382212162
batch reward last col mean 0.00637471117079258 first col mean 0.0023043788969516754 all mean 0.006091248709708452
rl training, epoch4, iter0, batch275/1133, batch loss:0.004437447991222143, Training time:110148.15818023682
batch reward last col mean 0.023361578583717346 first col mean 0.01856686919927597 all mean 0.023324882611632347
rl training, epoch4, iter0, batch276/1133, batch loss:0.0020319405011832714, Training time:110175.3665304184
batch reward last col mean 0.0005817142082378268 first col mean 0.0032299102749675512 all mean 0.0006618011393584311
rl training, epoch4, iter0, batch277/1133, batch loss:0.0012567989761009812, Training time:110202.85803508759
batch reward last col mean 1.7344455045531504e-05 first col mean 1.097405947803054e-05 all mean 6.25556567683816e-05
rl training, epoch4, iter0, batch278/1133, batch loss:0.0004237094835843891, Training time:110230.31591176987
batch reward last col mean 0.00776799488812685 first col mean 0.009085593745112419 all mean 0.007804680150002241
rl training, epoch4, iter0, batch279/1133, batch loss:0.0007089136634021997, Training time:110257.63393831253
batch reward last col mean 0.007410156074911356 first col mean 0.009349294938147068 all mean 0.007507605943828821
rl training, epoch4, iter0, batch280/1133, batch loss:0.002298132050782442, Training time:110285.03248333931
batch reward last col mean 0.040761902928352356 first col mean 0.03884906321763992 all mean 0.04058128595352173
rl training, epoch4, iter0, batch281/1133, batch loss:0.006343506276607513, Training time:110312.63874697685
batch reward last col mean 0.030779723078012466 first col mean 0.029041217640042305 all mean 0.030803555622696877
rl training, epoch4, iter0, batch282/1133, batch loss:0.0025937322061508894, Training time:110340.04197382927
batch reward last col mean 0.02634725719690323 first col mean 0.03548023849725723 all mean 0.02646440453827381
rl training, epoch4, iter0, batch283/1133, batch loss:0.005206583067774773, Training time:110367.58801007271
batch reward last col mean 0.04940744489431381 first col mean 0.0452851876616478 all mean 0.049442946910858154
rl training, epoch4, iter0, batch284/1133, batch loss:0.004292282275855541, Training time:110394.84752035141
batch reward last col mean 0.048594046384096146 first col mean 0.05489803105592728 all mean 0.04862676560878754
rl training, epoch4, iter0, batch285/1133, batch loss:0.0036930518690496683, Training time:110422.115046978
batch reward last col mean 0.07120994478464127 first col mean 0.06534402817487717 all mean 0.07111506909132004
rl training, epoch4, iter0, batch286/1133, batch loss:0.010467097163200378, Training time:110449.29725265503
batch reward last col mean 0.06574627757072449 first col mean 0.06738743931055069 all mean 0.06585321575403214
rl training, epoch4, iter0, batch287/1133, batch loss:0.012907557189464569, Training time:110476.65921974182
batch reward last col mean 0.02960902638733387 first col mean 0.028073038905858994 all mean 0.029451807960867882
rl training, epoch4, iter0, batch288/1133, batch loss:0.003039603354409337, Training time:110504.16109228134
batch reward last col mean 0.028783051297068596 first col mean 0.04377090930938721 all mean 0.029092254117131233
rl training, epoch4, iter0, batch289/1133, batch loss:0.008469993248581886, Training time:110531.37172102928
batch reward last col mean 0.052075326442718506 first col mean 0.06435155868530273 all mean 0.05225757509469986
rl training, epoch4, iter0, batch290/1133, batch loss:0.007152417674660683, Training time:110558.7263572216
batch reward last col mean 0.05099720507860184 first col mean 0.05679640918970108 all mean 0.05111575871706009
rl training, epoch4, iter0, batch291/1133, batch loss:0.008239541202783585, Training time:110586.59618854523
batch reward last col mean 0.07162211090326309 first col mean 0.08070263266563416 all mean 0.07172336429357529
rl training, epoch4, iter0, batch292/1133, batch loss:0.012958815321326256, Training time:110613.59562706947
batch reward last col mean 0.060731492936611176 first col mean 0.058456867933273315 all mean 0.06074085459113121
rl training, epoch4, iter0, batch293/1133, batch loss:0.0042177168652415276, Training time:110640.61957168579
batch reward last col mean 0.03833145275712013 first col mean 0.04094209522008896 all mean 0.03829050436615944
rl training, epoch4, iter0, batch294/1133, batch loss:0.010891037061810493, Training time:110667.77354383469
batch reward last col mean 0.08583727478981018 first col mean 0.07826363295316696 all mean 0.0852869376540184
rl training, epoch4, iter0, batch295/1133, batch loss:0.016976289451122284, Training time:110695.13626933098
batch reward last col mean 0.06811130046844482 first col mean 0.06302152574062347 all mean 0.06808102130889893
rl training, epoch4, iter0, batch296/1133, batch loss:0.013512756675481796, Training time:110722.90357351303
batch reward last col mean 0.07293251156806946 first col mean 0.07713918387889862 all mean 0.07298021018505096
rl training, epoch4, iter0, batch297/1133, batch loss:0.004344867542386055, Training time:110749.9405310154
batch reward last col mean 0.05655005946755409 first col mean 0.059579551219940186 all mean 0.056585390120744705
rl training, epoch4, iter0, batch298/1133, batch loss:0.009952890686690807, Training time:110777.60532927513
batch reward last col mean 0.05987106263637543 first col mean 0.05823328718543053 all mean 0.059761229902505875
rl training, epoch4, iter0, batch299/1133, batch loss:0.00597043801099062, Training time:110804.83748197556
batch reward last col mean 0.04935438558459282 first col mean 0.06384861469268799 all mean 0.049643851816654205
rl training, epoch4, iter0, batch300/1133, batch loss:0.006393964868038893, Training time:110832.16276144981
batch reward last col mean 0.09076371043920517 first col mean 0.09558521956205368 all mean 0.09084247052669525
rl training, epoch4, iter0, batch301/1133, batch loss:0.014657140709459782, Training time:110859.5279738903
batch reward last col mean 0.05793478339910507 first col mean 0.06393109261989594 all mean 0.0579918771982193
rl training, epoch4, iter0, batch302/1133, batch loss:0.01348988339304924, Training time:110886.45941996574
batch reward last col mean 0.06343240290880203 first col mean 0.059551022946834564 all mean 0.06339701265096664
rl training, epoch4, iter0, batch303/1133, batch loss:0.02665426954627037, Training time:110914.10632181168
batch reward last col mean 0.073551706969738 first col mean 0.07697778195142746 all mean 0.0736096128821373
rl training, epoch4, iter0, batch304/1133, batch loss:0.016287101432681084, Training time:110941.30307126045
batch reward last col mean 0.08796092122793198 first col mean 0.0822049006819725 all mean 0.08811569213867188
rl training, epoch4, iter0, batch305/1133, batch loss:0.018934786319732666, Training time:110968.79177379608
batch reward last col mean 0.06894848495721817 first col mean 0.07259023934602737 all mean 0.06912051141262054
rl training, epoch4, iter0, batch306/1133, batch loss:0.028078226372599602, Training time:110996.74419879913
batch reward last col mean 0.05652092024683952 first col mean 0.06385776400566101 all mean 0.05668419599533081
rl training, epoch4, iter0, batch307/1133, batch loss:0.012279579415917397, Training time:111023.7944996357
batch reward last col mean 0.12958279252052307 first col mean 0.11316918581724167 all mean 0.12902775406837463
rl training, epoch4, iter0, batch308/1133, batch loss:0.025296101346611977, Training time:111051.13189530373
batch reward last col mean 0.07840588688850403 first col mean 0.07987850159406662 all mean 0.07814723998308182
rl training, epoch4, iter0, batch309/1133, batch loss:0.02639557421207428, Training time:111078.79795145988
batch reward last col mean 0.13388660550117493 first col mean 0.12670083343982697 all mean 0.13388608396053314
rl training, epoch4, iter0, batch310/1133, batch loss:0.033814094960689545, Training time:111106.09992074966
batch reward last col mean 0.09902609884738922 first col mean 0.09364459663629532 all mean 0.0990300253033638
rl training, epoch4, iter0, batch311/1133, batch loss:0.02234024927020073, Training time:111133.33349204063
batch reward last col mean 0.1458311676979065 first col mean 0.15554629266262054 all mean 0.14602172374725342
rl training, epoch4, iter0, batch312/1133, batch loss:0.02385520190000534, Training time:111160.42946529388
batch reward last col mean 0.11458778381347656 first col mean 0.10826757550239563 all mean 0.11465606093406677
rl training, epoch4, iter0, batch313/1133, batch loss:0.03532576560974121, Training time:111188.27537155151
batch reward last col mean 0.11294837296009064 first col mean 0.11059154570102692 all mean 0.11288771778345108
rl training, epoch4, iter0, batch314/1133, batch loss:0.03258911520242691, Training time:111215.55247759819
batch reward last col mean 0.16938519477844238 first col mean 0.16366833448410034 all mean 0.16918540000915527
rl training, epoch4, iter0, batch315/1133, batch loss:0.03569154441356659, Training time:111243.26012730598
batch reward last col mean 0.17683382332324982 first col mean 0.1743396818637848 all mean 0.17685027420520782
rl training, epoch4, iter0, batch316/1133, batch loss:0.046703994274139404, Training time:111270.39623951912
batch reward last col mean 0.1700424998998642 first col mean 0.17034897208213806 all mean 0.17009510099887848
rl training, epoch4, iter0, batch317/1133, batch loss:0.04414231330156326, Training time:111297.42851161957
batch reward last col mean 0.146307572722435 first col mean 0.15113624930381775 all mean 0.14649994671344757
rl training, epoch4, iter0, batch318/1133, batch loss:0.06180940940976143, Training time:111325.10342359543
batch reward last col mean 0.1536502242088318 first col mean 0.15019409358501434 all mean 0.15364724397659302
rl training, epoch4, iter0, batch319/1133, batch loss:0.06384089589118958, Training time:111352.01566267014
batch reward last col mean 0.16188937425613403 first col mean 0.1667742133140564 all mean 0.16172124445438385
rl training, epoch4, iter0, batch320/1133, batch loss:0.07066190242767334, Training time:111379.14929676056
batch reward last col mean 0.14928610622882843 first col mean 0.14831869304180145 all mean 0.14917194843292236
rl training, epoch4, iter0, batch321/1133, batch loss:0.04211069643497467, Training time:111406.6267387867
batch reward last col mean 0.25223010778427124 first col mean 0.2540518045425415 all mean 0.2522532641887665
rl training, epoch4, iter0, batch322/1133, batch loss:0.08025878667831421, Training time:111434.1510746479
batch reward last col mean 0.16514018177986145 first col mean 0.18142744898796082 all mean 0.16540725529193878
rl training, epoch4, iter0, batch323/1133, batch loss:0.06739732623100281, Training time:111461.75316786766
batch reward last col mean 0.20416533946990967 first col mean 0.2108049839735031 all mean 0.20454178750514984
rl training, epoch4, iter0, batch324/1133, batch loss:0.07271548360586166, Training time:111488.84487009048
batch reward last col mean 0.20273339748382568 first col mean 0.22133579850196838 all mean 0.20293046534061432
rl training, epoch4, iter0, batch325/1133, batch loss:0.12702102959156036, Training time:111515.95802950859
batch reward last col mean 0.2577052712440491 first col mean 0.24113522469997406 all mean 0.2573944628238678
rl training, epoch4, iter0, batch326/1133, batch loss:0.08702775835990906, Training time:111543.35916519165
batch reward last col mean 0.23025387525558472 first col mean 0.24014770984649658 all mean 0.2307455688714981
rl training, epoch4, iter0, batch327/1133, batch loss:0.06701438128948212, Training time:111570.42429995537
batch reward last col mean 0.2344537079334259 first col mean 0.2311633676290512 all mean 0.23430004715919495
rl training, epoch4, iter0, batch328/1133, batch loss:0.09066318720579147, Training time:111598.1456811428
batch reward last col mean 0.24172404408454895 first col mean 0.2567673921585083 all mean 0.24212996661663055
rl training, epoch4, iter0, batch329/1133, batch loss:0.10335642099380493, Training time:111625.32976293564
batch reward last col mean 0.2769532799720764 first col mean 0.28384706377983093 all mean 0.2772711217403412
rl training, epoch4, iter0, batch330/1133, batch loss:0.11619492620229721, Training time:111652.36088299751
batch reward last col mean 0.2736649811267853 first col mean 0.26806503534317017 all mean 0.27336499094963074
rl training, epoch4, iter0, batch331/1133, batch loss:0.08995635062456131, Training time:111679.39268231392
batch reward last col mean 0.23028966784477234 first col mean 0.24205654859542847 all mean 0.23066067695617676
rl training, epoch4, iter0, batch332/1133, batch loss:0.12299520522356033, Training time:111706.11368918419
batch reward last col mean 0.25908711552619934 first col mean 0.27401024103164673 all mean 0.2590998411178589
rl training, epoch4, iter0, batch333/1133, batch loss:0.15320323407649994, Training time:111732.9656329155
batch reward last col mean 0.2753230333328247 first col mean 0.2898428440093994 all mean 0.2756465673446655
rl training, epoch4, iter0, batch334/1133, batch loss:0.12620019912719727, Training time:111759.88359427452
batch reward last col mean 0.32122257351875305 first col mean 0.3216795325279236 all mean 0.32110586762428284
rl training, epoch4, iter0, batch335/1133, batch loss:0.2008100152015686, Training time:111786.95159220695
batch reward last col mean 0.29852569103240967 first col mean 0.29712653160095215 all mean 0.2984232008457184
rl training, epoch4, iter0, batch336/1133, batch loss:0.15035243332386017, Training time:111813.92753911018
batch reward last col mean 0.3282068371772766 first col mean 0.33682847023010254 all mean 0.328341007232666
rl training, epoch4, iter0, batch337/1133, batch loss:0.15190213918685913, Training time:111840.75798487663
batch reward last col mean 0.3314689099788666 first col mean 0.3315463662147522 all mean 0.3311488628387451
rl training, epoch4, iter0, batch338/1133, batch loss:0.17669124901294708, Training time:111867.590477705
batch reward last col mean 0.30583128333091736 first col mean 0.3211001455783844 all mean 0.3060477375984192
rl training, epoch4, iter0, batch339/1133, batch loss:0.08408987522125244, Training time:111894.47472167015
batch reward last col mean 0.40062573552131653 first col mean 0.3941175043582916 all mean 0.400359570980072
rl training, epoch4, iter0, batch340/1133, batch loss:0.15975673496723175, Training time:111921.26644206047
batch reward last col mean 0.35492175817489624 first col mean 0.3425678014755249 all mean 0.35469433665275574
rl training, epoch4, iter0, batch341/1133, batch loss:0.12320269644260406, Training time:111948.12620425224
batch reward last col mean 0.3878973126411438 first col mean 0.3928065896034241 all mean 0.387847900390625
rl training, epoch4, iter0, batch342/1133, batch loss:0.1196986511349678, Training time:111974.86544060707
batch reward last col mean 0.38007229566574097 first col mean 0.38950955867767334 all mean 0.3801868259906769
rl training, epoch4, iter0, batch343/1133, batch loss:0.1061442494392395, Training time:112001.78105688095
batch reward last col mean 0.3048429787158966 first col mean 0.31213709712028503 all mean 0.3050098717212677
rl training, epoch4, iter0, batch344/1133, batch loss:0.060947075486183167, Training time:112028.61077427864
batch reward last col mean 0.291768878698349 first col mean 0.29510948061943054 all mean 0.29184049367904663
rl training, epoch4, iter0, batch345/1133, batch loss:0.07403282821178436, Training time:112055.55803775787
batch reward last col mean 0.31001585721969604 first col mean 0.30174604058265686 all mean 0.30986618995666504
rl training, epoch4, iter0, batch346/1133, batch loss:0.0799369215965271, Training time:112082.48703312874
batch reward last col mean 0.32876506447792053 first col mean 0.3480088412761688 all mean 0.3290632665157318
rl training, epoch4, iter0, batch347/1133, batch loss:0.09843773394823074, Training time:112109.20700240135
batch reward last col mean 0.31870290637016296 first col mean 0.3208528757095337 all mean 0.3188514709472656
rl training, epoch4, iter0, batch348/1133, batch loss:0.1124768778681755, Training time:112136.14582824707
batch reward last col mean 0.34476491808891296 first col mean 0.36322373151779175 all mean 0.3451134264469147
rl training, epoch4, iter0, batch349/1133, batch loss:0.10393340140581131, Training time:112163.47067713737
batch reward last col mean 0.42565956711769104 first col mean 0.4314357042312622 all mean 0.4258976876735687
rl training, epoch4, iter0, batch350/1133, batch loss:0.132160484790802, Training time:112190.4142882824
batch reward last col mean 0.36275380849838257 first col mean 0.3704095780849457 all mean 0.3630652129650116
rl training, epoch4, iter0, batch351/1133, batch loss:0.13092845678329468, Training time:112217.76837134361
batch reward last col mean 0.3629179298877716 first col mean 0.3706241846084595 all mean 0.3631229102611542
rl training, epoch4, iter0, batch352/1133, batch loss:0.12503725290298462, Training time:112244.53013110161
batch reward last col mean 0.3488582372665405 first col mean 0.35484734177589417 all mean 0.3488577604293823
rl training, epoch4, iter0, batch353/1133, batch loss:0.10821165144443512, Training time:112271.33692026138
batch reward last col mean 0.31226956844329834 first col mean 0.3171975612640381 all mean 0.3123627007007599
rl training, epoch4, iter0, batch354/1133, batch loss:0.11670893430709839, Training time:112298.28599524498
batch reward last col mean 0.33026841282844543 first col mean 0.3222481608390808 all mean 0.3300594389438629
rl training, epoch4, iter0, batch355/1133, batch loss:0.11882480978965759, Training time:112325.22115254402
batch reward last col mean 0.37747588753700256 first col mean 0.37866201996803284 all mean 0.37748444080352783
rl training, epoch4, iter0, batch356/1133, batch loss:0.12174253910779953, Training time:112352.10035991669
batch reward last col mean 0.3524383306503296 first col mean 0.3546106219291687 all mean 0.35242345929145813
rl training, epoch4, iter0, batch357/1133, batch loss:0.11005103588104248, Training time:112379.08182311058
batch reward last col mean 0.38949742913246155 first col mean 0.38536715507507324 all mean 0.3893933594226837
rl training, epoch4, iter0, batch358/1133, batch loss:0.13084293901920319, Training time:112405.84308576584
batch reward last col mean 0.4053959846496582 first col mean 0.402468204498291 all mean 0.40533438324928284
rl training, epoch4, iter0, batch359/1133, batch loss:0.15063732862472534, Training time:112432.63007235527
batch reward last col mean 0.4210937023162842 first col mean 0.4144793152809143 all mean 0.4208049178123474
rl training, epoch4, iter0, batch360/1133, batch loss:0.18451321125030518, Training time:112459.92314291
batch reward last col mean 0.3656948506832123 first col mean 0.3641883432865143 all mean 0.3657158613204956
rl training, epoch4, iter0, batch361/1133, batch loss:0.11141514033079147, Training time:112486.7443010807
batch reward last col mean 0.3681510090827942 first col mean 0.3801988959312439 all mean 0.3684290051460266
rl training, epoch4, iter0, batch362/1133, batch loss:0.10339916497468948, Training time:112513.10107040405
batch reward last col mean 0.33508536219596863 first col mean 0.3430919647216797 all mean 0.335174024105072
rl training, epoch4, iter0, batch363/1133, batch loss:0.12222525477409363, Training time:112539.60563087463
batch reward last col mean 0.40491628646850586 first col mean 0.4230361580848694 all mean 0.4050707519054413
rl training, epoch4, iter0, batch364/1133, batch loss:0.10775694251060486, Training time:112566.16158294678
batch reward last col mean 0.40014827251434326 first col mean 0.3994433581829071 all mean 0.40014639496803284
rl training, epoch4, iter0, batch365/1133, batch loss:0.09469281136989594, Training time:112592.64666199684
batch reward last col mean 0.3845177888870239 first col mean 0.3870162069797516 all mean 0.384507417678833
rl training, epoch4, iter0, batch366/1133, batch loss:0.11449968069791794, Training time:112619.10917663574
batch reward last col mean 0.32470592856407166 first col mean 0.3247194290161133 all mean 0.32471397519111633
rl training, epoch4, iter0, batch367/1133, batch loss:0.10757278650999069, Training time:112645.44948077202
batch reward last col mean 0.43901151418685913 first col mean 0.4315856397151947 all mean 0.4389248490333557
rl training, epoch4, iter0, batch368/1133, batch loss:0.1277499496936798, Training time:112672.0354795456
batch reward last col mean 0.33013734221458435 first col mean 0.33241623640060425 all mean 0.3300829827785492
rl training, epoch4, iter0, batch369/1133, batch loss:0.11010986566543579, Training time:112698.75527310371
batch reward last col mean 0.3517124652862549 first col mean 0.35976359248161316 all mean 0.3518058955669403
rl training, epoch4, iter0, batch370/1133, batch loss:0.09131644666194916, Training time:112725.87124586105
batch reward last col mean 0.3507215678691864 first col mean 0.3490104377269745 all mean 0.3507468104362488
rl training, epoch4, iter0, batch371/1133, batch loss:0.10676727443933487, Training time:112752.5153388977
batch reward last col mean 0.3279113173484802 first col mean 0.3375124931335449 all mean 0.32796263694763184
rl training, epoch4, iter0, batch372/1133, batch loss:0.07134535163640976, Training time:112779.30468320847
batch reward last col mean 0.3454921841621399 first col mean 0.3470003604888916 all mean 0.34556838870048523
rl training, epoch4, iter0, batch373/1133, batch loss:0.07427691668272018, Training time:112806.14691829681
batch reward last col mean 0.3780786395072937 first col mean 0.36577388644218445 all mean 0.3779989182949066
rl training, epoch4, iter0, batch374/1133, batch loss:0.12254352122545242, Training time:112833.1256980896
batch reward last col mean 0.4316384196281433 first col mean 0.43278300762176514 all mean 0.4317491054534912
rl training, epoch4, iter0, batch375/1133, batch loss:0.10180353373289108, Training time:112860.08585309982
batch reward last col mean 0.3168885111808777 first col mean 0.3073005676269531 all mean 0.31678056716918945
rl training, epoch4, iter0, batch376/1133, batch loss:0.09986330568790436, Training time:112887.46771216393
batch reward last col mean 0.4346785843372345 first col mean 0.4228513240814209 all mean 0.4344170391559601
rl training, epoch4, iter0, batch377/1133, batch loss:0.15393175184726715, Training time:112914.22704792023
batch reward last col mean 0.39558711647987366 first col mean 0.3984415531158447 all mean 0.3956782817840576
rl training, epoch4, iter0, batch378/1133, batch loss:0.13529488444328308, Training time:112941.09673810005
batch reward last col mean 0.3669535517692566 first col mean 0.36563897132873535 all mean 0.366910845041275
rl training, epoch4, iter0, batch379/1133, batch loss:0.14416570961475372, Training time:112967.85131025314
batch reward last col mean 0.4265235364437103 first col mean 0.4293077886104584 all mean 0.42675185203552246
rl training, epoch4, iter0, batch380/1133, batch loss:0.17281870543956757, Training time:112994.8292851448
batch reward last col mean 0.40371257066726685 first col mean 0.415080189704895 all mean 0.40386709570884705
rl training, epoch4, iter0, batch381/1133, batch loss:0.1081261858344078, Training time:113021.42790031433
batch reward last col mean 0.4119301438331604 first col mean 0.3965754210948944 all mean 0.4118150770664215
rl training, epoch4, iter0, batch382/1133, batch loss:0.1679711639881134, Training time:113048.21039772034
batch reward last col mean 0.4239162504673004 first col mean 0.4174725413322449 all mean 0.42372047901153564
rl training, epoch4, iter0, batch383/1133, batch loss:0.1577557623386383, Training time:113076.03433942795
batch reward last col mean 0.40763401985168457 first col mean 0.43016916513442993 all mean 0.40848642587661743
rl training, epoch4, iter0, batch384/1133, batch loss:0.1836468130350113, Training time:113102.93612408638
batch reward last col mean 0.4279433786869049 first col mean 0.4507374167442322 all mean 0.42876997590065
rl training, epoch4, iter0, batch385/1133, batch loss:0.18685469031333923, Training time:113130.00062823296
batch reward last col mean 0.3693573474884033 first col mean 0.35915523767471313 all mean 0.3689984679222107
rl training, epoch4, iter0, batch386/1133, batch loss:0.1669335663318634, Training time:113157.96509599686
batch reward last col mean 0.45390400290489197 first col mean 0.453563392162323 all mean 0.453197181224823
rl training, epoch4, iter0, batch387/1133, batch loss:0.17916852235794067, Training time:113185.00903105736
batch reward last col mean 0.3855116367340088 first col mean 0.3946346640586853 all mean 0.3860701024532318
rl training, epoch4, iter0, batch388/1133, batch loss:0.15240781009197235, Training time:113212.13986039162
batch reward last col mean 0.42677316069602966 first col mean 0.4235210716724396 all mean 0.42678555846214294
rl training, epoch4, iter0, batch389/1133, batch loss:0.1640130579471588, Training time:113239.27871274948
batch reward last col mean 0.44994354248046875 first col mean 0.44073837995529175 all mean 0.44972479343414307
rl training, epoch4, iter0, batch390/1133, batch loss:0.14505885541439056, Training time:113266.35530757904
batch reward last col mean 0.42913618683815 first col mean 0.42629969120025635 all mean 0.42914462089538574
rl training, epoch4, iter0, batch391/1133, batch loss:0.164187952876091, Training time:113293.54587697983
batch reward last col mean 0.447249174118042 first col mean 0.4539276957511902 all mean 0.4473685026168823
rl training, epoch4, iter0, batch392/1133, batch loss:0.15851393342018127, Training time:113320.91878080368
batch reward last col mean 0.4981669783592224 first col mean 0.49180513620376587 all mean 0.49831321835517883
rl training, epoch4, iter0, batch393/1133, batch loss:0.1908414512872696, Training time:113348.02353906631
batch reward last col mean 0.44687962532043457 first col mean 0.4540308117866516 all mean 0.44701841473579407
rl training, epoch4, iter0, batch394/1133, batch loss:0.15698769688606262, Training time:113375.11534881592
batch reward last col mean 0.4187375009059906 first col mean 0.4109240174293518 all mean 0.41883325576782227
rl training, epoch4, iter0, batch395/1133, batch loss:0.1560051590204239, Training time:113402.2594563961
batch reward last col mean 0.47477033734321594 first col mean 0.46821847558021545 all mean 0.4744332730770111
rl training, epoch4, iter0, batch396/1133, batch loss:0.20420648157596588, Training time:113429.33881807327
batch reward last col mean 0.46001726388931274 first col mean 0.456205278635025 all mean 0.4597182273864746
rl training, epoch4, iter0, batch397/1133, batch loss:0.18389643728733063, Training time:113456.31876182556
batch reward last col mean 0.43745678663253784 first col mean 0.4432525932788849 all mean 0.43747180700302124
rl training, epoch4, iter0, batch398/1133, batch loss:0.18501277267932892, Training time:113483.45708584785
batch reward last col mean 0.4986669719219208 first col mean 0.5098127722740173 all mean 0.49900951981544495
rl training, epoch4, iter0, batch399/1133, batch loss:0.18463224172592163, Training time:113510.47037744522
batch reward last col mean 0.4925026297569275 first col mean 0.49011021852493286 all mean 0.4924320876598358
rl training, epoch4, iter0, batch400/1133, batch loss:0.24329997599124908, Training time:113537.52553606033
batch reward last col mean 0.42316845059394836 first col mean 0.4392036199569702 all mean 0.42335355281829834
rl training, epoch4, iter0, batch401/1133, batch loss:0.14738568663597107, Training time:113564.685349226
batch reward last col mean 0.43385979533195496 first col mean 0.43435996770858765 all mean 0.4339445233345032
rl training, epoch4, iter0, batch402/1133, batch loss:0.19421087205410004, Training time:113591.67284798622
batch reward last col mean 0.4217631220817566 first col mean 0.4323631525039673 all mean 0.42183607816696167
rl training, epoch4, iter0, batch403/1133, batch loss:0.16798122227191925, Training time:113618.75538778305
batch reward last col mean 0.4654970169067383 first col mean 0.45095711946487427 all mean 0.46520310640335083
rl training, epoch4, iter0, batch404/1133, batch loss:0.17294667661190033, Training time:113646.31165361404
batch reward last col mean 0.5023436546325684 first col mean 0.5055651664733887 all mean 0.5024946331977844
rl training, epoch4, iter0, batch405/1133, batch loss:0.17249605059623718, Training time:113674.14771652222
batch reward last col mean 0.4045707583427429 first col mean 0.42046263813972473 all mean 0.4048265516757965
rl training, epoch4, iter0, batch406/1133, batch loss:0.12082919478416443, Training time:113701.25691914558
batch reward last col mean 0.4537796676158905 first col mean 0.45449864864349365 all mean 0.4537799060344696
rl training, epoch4, iter0, batch407/1133, batch loss:0.16642765700817108, Training time:113728.08723831177
batch reward last col mean 0.4421796202659607 first col mean 0.45583438873291016 all mean 0.44260141253471375
rl training, epoch4, iter0, batch408/1133, batch loss:0.1614726036787033, Training time:113755.2336602211
batch reward last col mean 0.4563038945198059 first col mean 0.45772480964660645 all mean 0.4569411277770996
rl training, epoch4, iter0, batch409/1133, batch loss:0.13695529103279114, Training time:113782.52221131325
batch reward last col mean 0.47431680560112 first col mean 0.4736475348472595 all mean 0.4743414521217346
rl training, epoch4, iter0, batch410/1133, batch loss:0.1290169209241867, Training time:113809.51531481743
batch reward last col mean 0.440646231174469 first col mean 0.4377373456954956 all mean 0.44032785296440125
rl training, epoch4, iter0, batch411/1133, batch loss:0.1500210165977478, Training time:113836.9175350666
batch reward last col mean 0.40152227878570557 first col mean 0.39475393295288086 all mean 0.4013376832008362
rl training, epoch4, iter0, batch412/1133, batch loss:0.161106675863266, Training time:113864.34652519226
batch reward last col mean 0.39431655406951904 first col mean 0.39956414699554443 all mean 0.39446020126342773
rl training, epoch4, iter0, batch413/1133, batch loss:0.13879436254501343, Training time:113891.58010935783
batch reward last col mean 0.41775113344192505 first col mean 0.4193037748336792 all mean 0.4176018536090851
rl training, epoch4, iter0, batch414/1133, batch loss:0.1110294908285141, Training time:113919.4834151268
batch reward last col mean 0.38553011417388916 first col mean 0.40780606865882874 all mean 0.3862013518810272
rl training, epoch4, iter0, batch415/1133, batch loss:0.09908058494329453, Training time:113947.46718287468
batch reward last col mean 0.4093460142612457 first col mean 0.40113750100135803 all mean 0.40947577357292175
rl training, epoch4, iter0, batch416/1133, batch loss:0.11802282929420471, Training time:113974.83450341225
batch reward last col mean 0.4343958795070648 first col mean 0.43752679228782654 all mean 0.4348759055137634
rl training, epoch4, iter0, batch417/1133, batch loss:0.1183532178401947, Training time:114002.10708427429
batch reward last col mean 0.37955453991889954 first col mean 0.4077697992324829 all mean 0.380111426115036
rl training, epoch4, iter0, batch418/1133, batch loss:0.13131624460220337, Training time:114029.50218558311
batch reward last col mean 0.42480191588401794 first col mean 0.41859301924705505 all mean 0.42451587319374084
rl training, epoch4, iter0, batch419/1133, batch loss:0.12081919610500336, Training time:114056.85898447037
batch reward last col mean 0.4277595281600952 first col mean 0.4542635381221771 all mean 0.4288189709186554
rl training, epoch4, iter0, batch420/1133, batch loss:0.12173350155353546, Training time:114084.44189023972
batch reward last col mean 0.45042768120765686 first col mean 0.4441557824611664 all mean 0.4498230218887329
rl training, epoch4, iter0, batch421/1133, batch loss:0.11190969496965408, Training time:114112.40630865097
batch reward last col mean 0.39530864357948303 first col mean 0.4068913757801056 all mean 0.39536964893341064
rl training, epoch4, iter0, batch422/1133, batch loss:0.096223846077919, Training time:114139.7272245884
batch reward last col mean 0.4411238133907318 first col mean 0.4466090500354767 all mean 0.44183045625686646
rl training, epoch4, iter0, batch423/1133, batch loss:0.12663011252880096, Training time:114167.70618081093
batch reward last col mean 0.4459531307220459 first col mean 0.4409860372543335 all mean 0.4454907476902008
rl training, epoch4, iter0, batch424/1133, batch loss:0.11277647316455841, Training time:114195.25442624092
batch reward last col mean 0.45666050910949707 first col mean 0.46440601348876953 all mean 0.4561426639556885
rl training, epoch4, iter0, batch425/1133, batch loss:0.1100064218044281, Training time:114223.11931538582
batch reward last col mean 0.4183811545372009 first col mean 0.42797017097473145 all mean 0.4182592034339905
rl training, epoch4, iter0, batch426/1133, batch loss:0.10845102369785309, Training time:114250.46907138824
batch reward last col mean 0.35486114025115967 first col mean 0.3586423397064209 all mean 0.35487601161003113
rl training, epoch4, iter0, batch427/1133, batch loss:0.0761200338602066, Training time:114277.61087226868
batch reward last col mean 0.4511256515979767 first col mean 0.44401514530181885 all mean 0.4508635103702545
rl training, epoch4, iter0, batch428/1133, batch loss:0.09068632870912552, Training time:114304.7412917614
batch reward last col mean 0.500766396522522 first col mean 0.4975101351737976 all mean 0.5004886984825134
rl training, epoch4, iter0, batch429/1133, batch loss:0.1335972547531128, Training time:114332.14786434174
batch reward last col mean 0.4146715998649597 first col mean 0.41593942046165466 all mean 0.4147852063179016
rl training, epoch4, iter0, batch430/1133, batch loss:0.09808353334665298, Training time:114359.47217679024
batch reward last col mean 0.36124294996261597 first col mean 0.3610711097717285 all mean 0.3613030016422272
rl training, epoch4, iter0, batch431/1133, batch loss:0.08848860114812851, Training time:114386.74511194229
batch reward last col mean 0.4319106936454773 first col mean 0.4447322487831116 all mean 0.4319411814212799
rl training, epoch4, iter0, batch432/1133, batch loss:0.11868000775575638, Training time:114413.90016961098
batch reward last col mean 0.5108668208122253 first col mean 0.5099807381629944 all mean 0.5112004280090332
rl training, epoch4, iter0, batch433/1133, batch loss:0.10405444353818893, Training time:114440.88419771194
batch reward last col mean 0.47935646772384644 first col mean 0.48668500781059265 all mean 0.4795346260070801
rl training, epoch4, iter0, batch434/1133, batch loss:0.14236845076084137, Training time:114468.1543829441
batch reward last col mean 0.5000741481781006 first col mean 0.4970383048057556 all mean 0.5000717639923096
rl training, epoch4, iter0, batch435/1133, batch loss:0.13567057251930237, Training time:114495.34914398193
batch reward last col mean 0.454706609249115 first col mean 0.450259268283844 all mean 0.4547410011291504
rl training, epoch4, iter0, batch436/1133, batch loss:0.1291695386171341, Training time:114522.52511405945
batch reward last col mean 0.42463958263397217 first col mean 0.4286240339279175 all mean 0.4245302677154541
rl training, epoch4, iter0, batch437/1133, batch loss:0.10929690301418304, Training time:114549.55426073074
batch reward last col mean 0.4619383215904236 first col mean 0.4745018780231476 all mean 0.46213579177856445
rl training, epoch4, iter0, batch438/1133, batch loss:0.09897303581237793, Training time:114576.61934423447
batch reward last col mean 0.44513311982154846 first col mean 0.4545661211013794 all mean 0.44531896710395813
rl training, epoch4, iter0, batch439/1133, batch loss:0.12111440300941467, Training time:114603.71191859245
batch reward last col mean 0.4640488028526306 first col mean 0.4683447778224945 all mean 0.463954359292984
rl training, epoch4, iter0, batch440/1133, batch loss:0.12370189279317856, Training time:114630.8646607399
batch reward last col mean 0.46908485889434814 first col mean 0.4635193943977356 all mean 0.4688177704811096
rl training, epoch4, iter0, batch441/1133, batch loss:0.13576722145080566, Training time:114658.14533877373
batch reward last col mean 0.4748168885707855 first col mean 0.46468496322631836 all mean 0.4746374189853668
rl training, epoch4, iter0, batch442/1133, batch loss:0.12029106914997101, Training time:114685.2658674717
batch reward last col mean 0.4559498727321625 first col mean 0.46519652009010315 all mean 0.4562027156352997
rl training, epoch4, iter0, batch443/1133, batch loss:0.10260982066392899, Training time:114712.43693208694
batch reward last col mean 0.5050127506256104 first col mean 0.512884259223938 all mean 0.5050654411315918
rl training, epoch4, iter0, batch444/1133, batch loss:0.1046590656042099, Training time:114739.53969812393
batch reward last col mean 0.44231337308883667 first col mean 0.4433829188346863 all mean 0.4422811269760132
rl training, epoch4, iter0, batch445/1133, batch loss:0.08425073325634003, Training time:114766.704631567
batch reward last col mean 0.4937034249305725 first col mean 0.5061972141265869 all mean 0.49383455514907837
rl training, epoch4, iter0, batch446/1133, batch loss:0.10359535366296768, Training time:114793.97804307938
batch reward last col mean 0.4600811004638672 first col mean 0.4523346424102783 all mean 0.4597935974597931
rl training, epoch4, iter0, batch447/1133, batch loss:0.09818913042545319, Training time:114821.03658652306
batch reward last col mean 0.4464101791381836 first col mean 0.44491732120513916 all mean 0.4464162588119507
rl training, epoch4, iter0, batch448/1133, batch loss:0.10536232590675354, Training time:114848.21376371384
batch reward last col mean 0.4891394376754761 first col mean 0.49129945039749146 all mean 0.489256888628006
rl training, epoch4, iter0, batch449/1133, batch loss:0.108877994120121, Training time:114876.08689689636
batch reward last col mean 0.42872849106788635 first col mean 0.43513232469558716 all mean 0.42889097332954407
rl training, epoch4, iter0, batch450/1133, batch loss:0.10536333918571472, Training time:114903.30711579323
batch reward last col mean 0.43550950288772583 first col mean 0.4407404065132141 all mean 0.4355425238609314
rl training, epoch4, iter0, batch451/1133, batch loss:0.10475575923919678, Training time:114931.10423469543
batch reward last col mean 0.494442343711853 first col mean 0.49314743280410767 all mean 0.4944046139717102
rl training, epoch4, iter0, batch452/1133, batch loss:0.09758547693490982, Training time:114957.99741744995
batch reward last col mean 0.4629650115966797 first col mean 0.47260257601737976 all mean 0.46312257647514343
rl training, epoch4, iter0, batch453/1133, batch loss:0.0852007195353508, Training time:114985.1208486557
batch reward last col mean 0.43351852893829346 first col mean 0.4308922588825226 all mean 0.43338221311569214
rl training, epoch4, iter0, batch454/1133, batch loss:0.0914989486336708, Training time:115012.38130545616
batch reward last col mean 0.5084125995635986 first col mean 0.5064693689346313 all mean 0.5083869099617004
rl training, epoch4, iter0, batch455/1133, batch loss:0.10680576413869858, Training time:115039.55781531334
batch reward last col mean 0.38630956411361694 first col mean 0.3811696469783783 all mean 0.3862154483795166
rl training, epoch4, iter0, batch456/1133, batch loss:0.05977986380457878, Training time:115066.65811371803
batch reward last col mean 0.44015470147132874 first col mean 0.44926294684410095 all mean 0.440294474363327
rl training, epoch4, iter0, batch457/1133, batch loss:0.07940036058425903, Training time:115093.39296412468
batch reward last col mean 0.36929869651794434 first col mean 0.37577947974205017 all mean 0.3693009316921234
rl training, epoch4, iter0, batch458/1133, batch loss:0.07057532668113708, Training time:115120.87410879135
batch reward last col mean 0.4478876292705536 first col mean 0.4509158134460449 all mean 0.44794556498527527
rl training, epoch4, iter0, batch459/1133, batch loss:0.11833587288856506, Training time:115148.50768876076
batch reward last col mean 0.4379187226295471 first col mean 0.43385016918182373 all mean 0.4379139244556427
rl training, epoch4, iter0, batch460/1133, batch loss:0.10382746905088425, Training time:115175.38108944893
batch reward last col mean 0.4333917796611786 first col mean 0.4353299140930176 all mean 0.43357208371162415
rl training, epoch4, iter0, batch461/1133, batch loss:0.10430115461349487, Training time:115202.1471426487
batch reward last col mean 0.43433451652526855 first col mean 0.43696820735931396 all mean 0.43437665700912476
rl training, epoch4, iter0, batch462/1133, batch loss:0.0917464941740036, Training time:115229.05919909477
batch reward last col mean 0.43744605779647827 first col mean 0.434865266084671 all mean 0.43727418780326843
rl training, epoch4, iter0, batch463/1133, batch loss:0.08882102370262146, Training time:115256.13237977028
batch reward last col mean 0.48119592666625977 first col mean 0.4839802384376526 all mean 0.4812670648097992
rl training, epoch4, iter0, batch464/1133, batch loss:0.11389785259962082, Training time:115283.48445415497
batch reward last col mean 0.43995651602745056 first col mean 0.4383563995361328 all mean 0.43998926877975464
rl training, epoch4, iter0, batch465/1133, batch loss:0.09704570472240448, Training time:115310.71179294586
batch reward last col mean 0.41977232694625854 first col mean 0.42398977279663086 all mean 0.41984060406684875
rl training, epoch4, iter0, batch466/1133, batch loss:0.09529098868370056, Training time:115337.87078547478
batch reward last col mean 0.47192078828811646 first col mean 0.4729008674621582 all mean 0.4718681871891022
rl training, epoch4, iter0, batch467/1133, batch loss:0.09172467887401581, Training time:115364.88383841515
batch reward last col mean 0.4388231635093689 first col mean 0.4300249218940735 all mean 0.43875476717948914
rl training, epoch4, iter0, batch468/1133, batch loss:0.1350834220647812, Training time:115392.09574580193
batch reward last col mean 0.48968905210494995 first col mean 0.49682652950286865 all mean 0.4897918701171875
rl training, epoch4, iter0, batch469/1133, batch loss:0.11414209753274918, Training time:115419.49739170074
batch reward last col mean 0.4228770136833191 first col mean 0.4233028292655945 all mean 0.4229714870452881
rl training, epoch4, iter0, batch470/1133, batch loss:0.0994955375790596, Training time:115446.91974282265
batch reward last col mean 0.4066343903541565 first col mean 0.4151202440261841 all mean 0.40698811411857605
rl training, epoch4, iter0, batch471/1133, batch loss:0.09303450584411621, Training time:115473.99042010307
batch reward last col mean 0.49474281072616577 first col mean 0.5020995736122131 all mean 0.4950217008590698
rl training, epoch4, iter0, batch472/1133, batch loss:0.12404671311378479, Training time:115501.33075761795
batch reward last col mean 0.4410906434059143 first col mean 0.4451562166213989 all mean 0.44106054306030273
rl training, epoch4, iter0, batch473/1133, batch loss:0.10628854483366013, Training time:115528.58908438683
batch reward last col mean 0.4641802906990051 first col mean 0.4584251642227173 all mean 0.46391621232032776
rl training, epoch4, iter0, batch474/1133, batch loss:0.13431255519390106, Training time:115556.35331082344
batch reward last col mean 0.46349745988845825 first col mean 0.4635767340660095 all mean 0.4637143611907959
rl training, epoch4, iter0, batch475/1133, batch loss:0.09449736773967743, Training time:115584.15401864052
batch reward last col mean 0.476217120885849 first col mean 0.4655259847640991 all mean 0.4762907028198242
rl training, epoch4, iter0, batch476/1133, batch loss:0.09051358699798584, Training time:115612.09659552574
batch reward last col mean 0.49466222524642944 first col mean 0.4841585159301758 all mean 0.4940907955169678
rl training, epoch4, iter0, batch477/1133, batch loss:0.10000943392515182, Training time:115640.31634879112
batch reward last col mean 0.4412817358970642 first col mean 0.43224209547042847 all mean 0.4385548233985901
rl training, epoch4, iter0, batch478/1133, batch loss:0.09160785377025604, Training time:115668.97378611565
batch reward last col mean 0.45413845777511597 first col mean 0.4373782277107239 all mean 0.4516393542289734
rl training, epoch4, iter0, batch479/1133, batch loss:0.07351132482290268, Training time:115697.34956121445
batch reward last col mean 0.37208160758018494 first col mean 0.37357375025749207 all mean 0.3697199523448944
rl training, epoch4, iter0, batch480/1133, batch loss:0.05790819600224495, Training time:115726.05660200119
batch reward last col mean 0.4974725842475891 first col mean 0.4767487049102783 all mean 0.493837833404541
rl training, epoch4, iter0, batch481/1133, batch loss:0.07497428357601166, Training time:115754.55624103546
batch reward last col mean 0.4632766842842102 first col mean 0.45891183614730835 all mean 0.46353331208229065
rl training, epoch4, iter0, batch482/1133, batch loss:0.07810710370540619, Training time:115782.97790527344
batch reward last col mean 0.4150182008743286 first col mean 0.40171539783477783 all mean 0.4158044755458832
rl training, epoch4, iter0, batch483/1133, batch loss:0.07747677713632584, Training time:115812.26154279709
batch reward last col mean 0.4727376699447632 first col mean 0.452064573764801 all mean 0.4706907570362091
rl training, epoch4, iter0, batch484/1133, batch loss:0.06709388643503189, Training time:115840.75855898857
batch reward last col mean 0.4771180748939514 first col mean 0.4747602343559265 all mean 0.4767717719078064
rl training, epoch4, iter0, batch485/1133, batch loss:0.08321994543075562, Training time:115869.08208966255
batch reward last col mean 0.47705981135368347 first col mean 0.47956669330596924 all mean 0.476640522480011
rl training, epoch4, iter0, batch486/1133, batch loss:0.08279623091220856, Training time:115898.15411639214
batch reward last col mean 0.4432128965854645 first col mean 0.42940035462379456 all mean 0.4399106502532959
rl training, epoch4, iter0, batch487/1133, batch loss:0.09582017362117767, Training time:115926.0385594368
batch reward last col mean 0.42504656314849854 first col mean 0.4041427969932556 all mean 0.4236079752445221
rl training, epoch4, iter0, batch488/1133, batch loss:0.08385207504034042, Training time:115954.74758529663
batch reward last col mean 0.42960885167121887 first col mean 0.4197738468647003 all mean 0.42837589979171753
rl training, epoch4, iter0, batch489/1133, batch loss:0.09343935549259186, Training time:115982.85022377968
batch reward last col mean 0.4445609152317047 first col mean 0.440105676651001 all mean 0.44359150528907776
rl training, epoch4, iter0, batch490/1133, batch loss:0.08840478211641312, Training time:116011.29941010475
batch reward last col mean 0.48042529821395874 first col mean 0.45767098665237427 all mean 0.4779326319694519
rl training, epoch4, iter0, batch491/1133, batch loss:0.09126297384500504, Training time:116039.96099066734
batch reward last col mean 0.5085759162902832 first col mean 0.49361154437065125 all mean 0.508001446723938
rl training, epoch4, iter0, batch492/1133, batch loss:0.10867733508348465, Training time:116067.58242416382
batch reward last col mean 0.5151597261428833 first col mean 0.5131018161773682 all mean 0.5149149298667908
rl training, epoch4, iter0, batch493/1133, batch loss:0.11459721624851227, Training time:116095.00177836418
batch reward last col mean 0.48822012543678284 first col mean 0.48500287532806396 all mean 0.4880028963088989
rl training, epoch4, iter0, batch494/1133, batch loss:0.09690873324871063, Training time:116122.84305787086
batch reward last col mean 0.4762073755264282 first col mean 0.48356854915618896 all mean 0.4764648675918579
rl training, epoch4, iter0, batch495/1133, batch loss:0.08806797862052917, Training time:116150.10831618309
batch reward last col mean 0.4733700752258301 first col mean 0.4794655442237854 all mean 0.4734084904193878
rl training, epoch4, iter0, batch496/1133, batch loss:0.092800572514534, Training time:116177.51332378387
batch reward last col mean 0.5627509951591492 first col mean 0.5655488967895508 all mean 0.5627921223640442
rl training, epoch4, iter0, batch497/1133, batch loss:0.11404572427272797, Training time:116204.6589243412
batch reward last col mean 0.471733033657074 first col mean 0.4711858332157135 all mean 0.4717830419540405
rl training, epoch4, iter0, batch498/1133, batch loss:0.10178915411233902, Training time:116231.7997264862
batch reward last col mean 0.4780699610710144 first col mean 0.47158336639404297 all mean 0.47782889008522034
rl training, epoch4, iter0, batch499/1133, batch loss:0.09676074236631393, Training time:116258.87783432007
batch reward last col mean 0.4559580683708191 first col mean 0.45689016580581665 all mean 0.4559369385242462
rl training, epoch4, iter0, batch500/1133, batch loss:0.07584506273269653, Training time:116286.81759643555
batch reward last col mean 0.48581522703170776 first col mean 0.48743700981140137 all mean 0.48578140139579773
rl training, epoch4, iter0, batch501/1133, batch loss:0.11255697906017303, Training time:116313.71184253693
batch reward last col mean 0.4846774637699127 first col mean 0.49354320764541626 all mean 0.48486706614494324
rl training, epoch4, iter0, batch502/1133, batch loss:0.09983471781015396, Training time:116341.15188479424
batch reward last col mean 0.44076016545295715 first col mean 0.4432765245437622 all mean 0.4408068358898163
rl training, epoch4, iter0, batch503/1133, batch loss:0.08237043023109436, Training time:116368.32592439651
batch reward last col mean 0.4838901460170746 first col mean 0.48571711778640747 all mean 0.48400139808654785
rl training, epoch4, iter0, batch504/1133, batch loss:0.08709418028593063, Training time:116395.44260954857
batch reward last col mean 0.44767582416534424 first col mean 0.44919973611831665 all mean 0.44768616557121277
rl training, epoch4, iter0, batch505/1133, batch loss:0.09616351872682571, Training time:116422.61867332458
batch reward last col mean 0.4713720679283142 first col mean 0.4660450220108032 all mean 0.47129714488983154
rl training, epoch4, iter0, batch506/1133, batch loss:0.10502929985523224, Training time:116449.66613507271
batch reward last col mean 0.47642841935157776 first col mean 0.46943947672843933 all mean 0.4763711094856262
rl training, epoch4, iter0, batch507/1133, batch loss:0.07362817972898483, Training time:116476.63150143623
batch reward last col mean 0.4970521628856659 first col mean 0.5040863752365112 all mean 0.49714791774749756
rl training, epoch4, iter0, batch508/1133, batch loss:0.09398460388183594, Training time:116503.72691845894
batch reward last col mean 0.5159597992897034 first col mean 0.5146262645721436 all mean 0.5159861445426941
rl training, epoch4, iter0, batch509/1133, batch loss:0.07955362647771835, Training time:116530.78747010231
batch reward last col mean 0.5263833999633789 first col mean 0.5291063785552979 all mean 0.5263978838920593
rl training, epoch4, iter0, batch510/1133, batch loss:0.07339141517877579, Training time:116557.92740607262
batch reward last col mean 0.4434964656829834 first col mean 0.4447687268257141 all mean 0.44353345036506653
rl training, epoch4, iter0, batch511/1133, batch loss:0.05969471484422684, Training time:116584.75604987144
batch reward last col mean 0.5134570598602295 first col mean 0.5096548795700073 all mean 0.513420581817627
rl training, epoch4, iter0, batch512/1133, batch loss:0.10518685728311539, Training time:116611.57593870163
batch reward last col mean 0.4618997573852539 first col mean 0.45892277359962463 all mean 0.4618285596370697
rl training, epoch4, iter0, batch513/1133, batch loss:0.1015469953417778, Training time:116638.51419997215
batch reward last col mean 0.4996036887168884 first col mean 0.4993112087249756 all mean 0.4996059536933899
rl training, epoch4, iter0, batch514/1133, batch loss:0.0705333799123764, Training time:116665.33054494858
batch reward last col mean 0.4702122211456299 first col mean 0.47185051441192627 all mean 0.47023987770080566
rl training, epoch4, iter0, batch515/1133, batch loss:0.06187322735786438, Training time:116692.23845171928
batch reward last col mean 0.46979647874832153 first col mean 0.47107288241386414 all mean 0.46980908513069153
rl training, epoch4, iter0, batch516/1133, batch loss:0.07704468071460724, Training time:116719.27107143402
batch reward last col mean 0.45861655473709106 first col mean 0.4527408480644226 all mean 0.4585317373275757
rl training, epoch4, iter0, batch517/1133, batch loss:0.09798620641231537, Training time:116746.06533455849
batch reward last col mean 0.4808499217033386 first col mean 0.47805851697921753 all mean 0.4808097183704376
rl training, epoch4, iter0, batch518/1133, batch loss:0.07464703917503357, Training time:116773.09213995934
batch reward last col mean 0.44736069440841675 first col mean 0.4515267610549927 all mean 0.4474239945411682
rl training, epoch4, iter0, batch519/1133, batch loss:0.060623396188020706, Training time:116800.15671896935
batch reward last col mean 0.48395538330078125 first col mean 0.4881773591041565 all mean 0.48399677872657776
rl training, epoch4, iter0, batch520/1133, batch loss:0.06575078517198563, Training time:116827.20896291733
batch reward last col mean 0.4877314269542694 first col mean 0.48562589287757874 all mean 0.48770973086357117
rl training, epoch4, iter0, batch521/1133, batch loss:0.06468983739614487, Training time:116854.06138586998
batch reward last col mean 0.4527480900287628 first col mean 0.45879027247428894 all mean 0.4528122842311859
rl training, epoch4, iter0, batch522/1133, batch loss:0.07534171640872955, Training time:116881.50122380257
batch reward last col mean 0.4130454659461975 first col mean 0.41280433535575867 all mean 0.4130479395389557
rl training, epoch4, iter0, batch523/1133, batch loss:0.10052820295095444, Training time:116908.53781843185
batch reward last col mean 0.501499593257904 first col mean 0.49683433771133423 all mean 0.5014578104019165
rl training, epoch4, iter0, batch524/1133, batch loss:0.11281595379114151, Training time:116936.11116194725
batch reward last col mean 0.42200618982315063 first col mean 0.41722312569618225 all mean 0.4219489097595215
rl training, epoch4, iter0, batch525/1133, batch loss:0.06582580506801605, Training time:116962.99917006493
batch reward last col mean 0.4665239453315735 first col mean 0.46641770005226135 all mean 0.46651560068130493
rl training, epoch4, iter0, batch526/1133, batch loss:0.08122191578149796, Training time:116989.9690785408
batch reward last col mean 0.4732528030872345 first col mean 0.4727366864681244 all mean 0.47325196862220764
rl training, epoch4, iter0, batch527/1133, batch loss:0.07528053969144821, Training time:117016.7939889431
batch reward last col mean 0.4763266444206238 first col mean 0.4706569314002991 all mean 0.4762694239616394
rl training, epoch4, iter0, batch528/1133, batch loss:0.10357367992401123, Training time:117044.00344467163
batch reward last col mean 0.4683384597301483 first col mean 0.46980565786361694 all mean 0.4683544635772705
rl training, epoch4, iter0, batch529/1133, batch loss:0.05803155526518822, Training time:117070.88615632057
batch reward last col mean 0.48387956619262695 first col mean 0.479079008102417 all mean 0.4838310778141022
rl training, epoch4, iter0, batch530/1133, batch loss:0.06165023148059845, Training time:117097.75454354286
batch reward last col mean 0.48404422402381897 first col mean 0.482854962348938 all mean 0.48403260111808777
rl training, epoch4, iter0, batch531/1133, batch loss:0.07341008633375168, Training time:117124.88141345978
batch reward last col mean 0.48535624146461487 first col mean 0.47971683740615845 all mean 0.485288143157959
rl training, epoch4, iter0, batch532/1133, batch loss:0.05289650335907936, Training time:117151.8868470192
batch reward last col mean 0.5065453052520752 first col mean 0.5065906643867493 all mean 0.5065458416938782
rl training, epoch4, iter0, batch533/1133, batch loss:0.07998628914356232, Training time:117178.7806315422
batch reward last col mean 0.5070779323577881 first col mean 0.5042805075645447 all mean 0.5070494413375854
rl training, epoch4, iter0, batch534/1133, batch loss:0.0750853419303894, Training time:117205.7548468113
batch reward last col mean 0.5370146036148071 first col mean 0.5369344353675842 all mean 0.5370125770568848
rl training, epoch4, iter0, batch535/1133, batch loss:0.08314410597085953, Training time:117232.7565972805
batch reward last col mean 0.4802779257297516 first col mean 0.48002588748931885 all mean 0.4802718460559845
rl training, epoch4, iter0, batch536/1133, batch loss:0.06812826544046402, Training time:117259.73933911324
batch reward last col mean 0.5225759744644165 first col mean 0.521324872970581 all mean 0.5225260853767395
rl training, epoch4, iter0, batch537/1133, batch loss:0.07981914281845093, Training time:117286.63810229301
batch reward last col mean 0.5028135776519775 first col mean 0.510068953037262 all mean 0.5028934478759766
rl training, epoch4, iter0, batch538/1133, batch loss:0.07510282099246979, Training time:117313.57263469696
batch reward last col mean 0.5189825296401978 first col mean 0.5187142491340637 all mean 0.5189906358718872
rl training, epoch4, iter0, batch539/1133, batch loss:0.06915658712387085, Training time:117340.61491322517
batch reward last col mean 0.4352770447731018 first col mean 0.432464063167572 all mean 0.43524858355522156
rl training, epoch4, iter0, batch540/1133, batch loss:0.042865265160799026, Training time:117367.4319767952
batch reward last col mean 0.4448503255844116 first col mean 0.4552272856235504 all mean 0.4449556767940521
rl training, epoch4, iter0, batch541/1133, batch loss:0.07745421677827835, Training time:117394.39810061455
batch reward last col mean 0.5009369850158691 first col mean 0.49958765506744385 all mean 0.5009233355522156
rl training, epoch4, iter0, batch542/1133, batch loss:0.06512252986431122, Training time:117421.6132721901
batch reward last col mean 0.505573570728302 first col mean 0.5041289925575256 all mean 0.5055341124534607
rl training, epoch4, iter0, batch543/1133, batch loss:0.08982602506875992, Training time:117449.19901633263
batch reward last col mean 0.46295166015625 first col mean 0.468036949634552 all mean 0.4629998207092285
rl training, epoch4, iter0, batch544/1133, batch loss:0.07538668811321259, Training time:117476.32926416397
batch reward last col mean 0.4188304543495178 first col mean 0.41622236371040344 all mean 0.4188072383403778
rl training, epoch4, iter0, batch545/1133, batch loss:0.06429476290941238, Training time:117503.21685934067
batch reward last col mean 0.4811403453350067 first col mean 0.48146361112594604 all mean 0.4811449646949768
rl training, epoch4, iter0, batch546/1133, batch loss:0.09841801971197128, Training time:117530.39192080498
batch reward last col mean 0.4025805592536926 first col mean 0.4042951464653015 all mean 0.4025944471359253
rl training, epoch4, iter0, batch547/1133, batch loss:0.06914890557527542, Training time:117557.37914419174
batch reward last col mean 0.4560757875442505 first col mean 0.45704999566078186 all mean 0.45610731840133667
rl training, epoch4, iter0, batch548/1133, batch loss:0.07681194692850113, Training time:117584.90047693253
batch reward last col mean 0.4907601475715637 first col mean 0.4909850060939789 all mean 0.4907614290714264
rl training, epoch4, iter0, batch549/1133, batch loss:0.09362298250198364, Training time:117612.15180253983
batch reward last col mean 0.5123392939567566 first col mean 0.5111614465713501 all mean 0.5123274326324463
rl training, epoch4, iter0, batch550/1133, batch loss:0.06645288318395615, Training time:117639.0749464035
batch reward last col mean 0.49061107635498047 first col mean 0.49170640110969543 all mean 0.4906085133552551
rl training, epoch4, iter0, batch551/1133, batch loss:0.11959635466337204, Training time:117666.15025305748
batch reward last col mean 0.460545152425766 first col mean 0.4519752264022827 all mean 0.46040332317352295
rl training, epoch4, iter0, batch552/1133, batch loss:0.08644426614046097, Training time:117693.15009856224
batch reward last col mean 0.48172497749328613 first col mean 0.4827950596809387 all mean 0.4817374646663666
rl training, epoch4, iter0, batch553/1133, batch loss:0.07401794195175171, Training time:117719.9360768795
batch reward last col mean 0.4630204439163208 first col mean 0.4562447667121887 all mean 0.4628765285015106
rl training, epoch4, iter0, batch554/1133, batch loss:0.0676519125699997, Training time:117746.87836527824
batch reward last col mean 0.4863300919532776 first col mean 0.4816463887691498 all mean 0.48628661036491394
rl training, epoch4, iter0, batch555/1133, batch loss:0.07518621534109116, Training time:117774.09054660797
batch reward last col mean 0.4585477113723755 first col mean 0.4640807509422302 all mean 0.45866620540618896
rl training, epoch4, iter0, batch556/1133, batch loss:0.1009146124124527, Training time:117801.10621523857
batch reward last col mean 0.49735552072525024 first col mean 0.49901676177978516 all mean 0.49736300110816956
rl training, epoch4, iter0, batch557/1133, batch loss:0.0901561751961708, Training time:117827.9752817154
batch reward last col mean 0.45326581597328186 first col mean 0.4533360004425049 all mean 0.45325329899787903
rl training, epoch4, iter0, batch558/1133, batch loss:0.07282926887273788, Training time:117855.50002503395
batch reward last col mean 0.47260284423828125 first col mean 0.47101470828056335 all mean 0.47254934906959534
rl training, epoch4, iter0, batch559/1133, batch loss:0.09621528536081314, Training time:117882.5963845253
batch reward last col mean 0.4440872371196747 first col mean 0.4466311037540436 all mean 0.4441361725330353
rl training, epoch4, iter0, batch560/1133, batch loss:0.07812979817390442, Training time:117910.12878870964
batch reward last col mean 0.4666350185871124 first col mean 0.46814659237861633 all mean 0.4666845202445984
rl training, epoch4, iter0, batch561/1133, batch loss:0.07667487859725952, Training time:117936.82248902321
batch reward last col mean 0.4581699073314667 first col mean 0.454156756401062 all mean 0.4581149220466614
rl training, epoch4, iter0, batch562/1133, batch loss:0.06700033694505692, Training time:117963.62833881378
batch reward last col mean 0.47553616762161255 first col mean 0.47973546385765076 all mean 0.47556886076927185
rl training, epoch4, iter0, batch563/1133, batch loss:0.08605969697237015, Training time:117990.60886192322
batch reward last col mean 0.5481200218200684 first col mean 0.5518001317977905 all mean 0.5482346415519714
rl training, epoch4, iter0, batch564/1133, batch loss:0.12079132348299026, Training time:118017.31108736992
batch reward last col mean 0.48302993178367615 first col mean 0.4794823229312897 all mean 0.48298564553260803
rl training, epoch4, iter0, batch565/1133, batch loss:0.08634026348590851, Training time:118044.24587154388
batch reward last col mean 0.4264131784439087 first col mean 0.4292166233062744 all mean 0.4264885485172272
rl training, epoch4, iter0, batch566/1133, batch loss:0.051315829157829285, Training time:118071.06853079796
batch reward last col mean 0.4503520429134369 first col mean 0.45684894919395447 all mean 0.45043230056762695
rl training, epoch4, iter0, batch567/1133, batch loss:0.10261142253875732, Training time:118097.9013531208
batch reward last col mean 0.5042657256126404 first col mean 0.5041990876197815 all mean 0.5042372941970825
rl training, epoch4, iter0, batch568/1133, batch loss:0.0982038676738739, Training time:118125.23575663567
batch reward last col mean 0.48360973596572876 first col mean 0.4857466220855713 all mean 0.48363128304481506
rl training, epoch4, iter0, batch569/1133, batch loss:0.09216367453336716, Training time:118152.85599184036
batch reward last col mean 0.49490469694137573 first col mean 0.49498820304870605 all mean 0.49493110179901123
rl training, epoch4, iter0, batch570/1133, batch loss:0.07708524167537689, Training time:118179.95931649208
batch reward last col mean 0.4439990222454071 first col mean 0.44143146276474 all mean 0.443973183631897
rl training, epoch4, iter0, batch571/1133, batch loss:0.06914740800857544, Training time:118206.92519688606
batch reward last col mean 0.4712851643562317 first col mean 0.4733599126338959 all mean 0.4713038504123688
rl training, epoch4, iter0, batch572/1133, batch loss:0.0945286825299263, Training time:118233.97252511978
batch reward last col mean 0.5085691213607788 first col mean 0.5060606598854065 all mean 0.5085780024528503
rl training, epoch4, iter0, batch573/1133, batch loss:0.08990912139415741, Training time:118260.99302721024
batch reward last col mean 0.41309812664985657 first col mean 0.41471368074417114 all mean 0.41309621930122375
rl training, epoch4, iter0, batch574/1133, batch loss:0.09263826161623001, Training time:118288.05443763733
batch reward last col mean 0.5134168863296509 first col mean 0.5194113254547119 all mean 0.5135302543640137
rl training, epoch4, iter0, batch575/1133, batch loss:0.07473720610141754, Training time:118315.31545114517
batch reward last col mean 0.5097076296806335 first col mean 0.5073906779289246 all mean 0.509684145450592
rl training, epoch4, iter0, batch576/1133, batch loss:0.08158830553293228, Training time:118342.42673254013
batch reward last col mean 0.47915181517601013 first col mean 0.47803178429603577 all mean 0.4791332185268402
rl training, epoch4, iter0, batch577/1133, batch loss:0.08329817652702332, Training time:118369.18682193756
batch reward last col mean 0.4813882112503052 first col mean 0.4819435477256775 all mean 0.4814506769180298
rl training, epoch4, iter0, batch578/1133, batch loss:0.07708066701889038, Training time:118396.16842865944
batch reward last col mean 0.47356653213500977 first col mean 0.4723113179206848 all mean 0.4735538065433502
rl training, epoch4, iter0, batch579/1133, batch loss:0.07100430876016617, Training time:118423.2005701065
batch reward last col mean 0.46556901931762695 first col mean 0.467756986618042 all mean 0.4655911326408386
rl training, epoch4, iter0, batch580/1133, batch loss:0.06955356895923615, Training time:118450.2964117527
batch reward last col mean 0.43941548466682434 first col mean 0.43858328461647034 all mean 0.43939194083213806
rl training, epoch4, iter0, batch581/1133, batch loss:0.07697897404432297, Training time:118477.25375413895
batch reward last col mean 0.5140951871871948 first col mean 0.5195373296737671 all mean 0.5141754150390625
rl training, epoch4, iter0, batch582/1133, batch loss:0.06194496899843216, Training time:118504.35670113564
batch reward last col mean 0.49785810708999634 first col mean 0.5069714784622192 all mean 0.4979478120803833
rl training, epoch4, iter0, batch583/1133, batch loss:0.06442797183990479, Training time:118531.3212275505
batch reward last col mean 0.40423017740249634 first col mean 0.4004305601119995 all mean 0.40421193838119507
rl training, epoch4, iter0, batch584/1133, batch loss:0.07800279557704926, Training time:118558.13845610619
batch reward last col mean 0.5042852163314819 first col mean 0.5005919933319092 all mean 0.5042479634284973
rl training, epoch4, iter0, batch585/1133, batch loss:0.07643173635005951, Training time:118585.48283529282
batch reward last col mean 0.4082818925380707 first col mean 0.4091515839099884 all mean 0.4083138704299927
rl training, epoch4, iter0, batch586/1133, batch loss:0.06669646501541138, Training time:118612.72164869308
batch reward last col mean 0.4354681968688965 first col mean 0.43500393629074097 all mean 0.43546175956726074
rl training, epoch4, iter0, batch587/1133, batch loss:0.05523066595196724, Training time:118639.67348217964
batch reward last col mean 0.42889219522476196 first col mean 0.4313580393791199 all mean 0.4289250671863556
rl training, epoch4, iter0, batch588/1133, batch loss:0.05012485384941101, Training time:118666.60538673401
batch reward last col mean 0.4404616355895996 first col mean 0.4379991888999939 all mean 0.44041651487350464
rl training, epoch4, iter0, batch589/1133, batch loss:0.07881039381027222, Training time:118693.5259039402
batch reward last col mean 0.45198655128479004 first col mean 0.45155155658721924 all mean 0.45193591713905334
rl training, epoch4, iter0, batch590/1133, batch loss:0.07812759280204773, Training time:118720.9823012352
batch reward last col mean 0.4433538019657135 first col mean 0.4461647570133209 all mean 0.4434134066104889
rl training, epoch4, iter0, batch591/1133, batch loss:0.06507731974124908, Training time:118748.88003897667
batch reward last col mean 0.531324028968811 first col mean 0.5343140363693237 all mean 0.5314162373542786
rl training, epoch4, iter0, batch592/1133, batch loss:0.09103669971227646, Training time:118775.78767442703
batch reward last col mean 0.4722040593624115 first col mean 0.45611923933029175 all mean 0.47201773524284363
rl training, epoch4, iter0, batch593/1133, batch loss:0.09200277179479599, Training time:118803.05942249298
batch reward last col mean 0.480862021446228 first col mean 0.4698389172554016 all mean 0.48072800040245056
rl training, epoch4, iter0, batch594/1133, batch loss:0.06909008324146271, Training time:118830.10955905914
batch reward last col mean 0.5034034252166748 first col mean 0.5109767913818359 all mean 0.5034907460212708
rl training, epoch4, iter0, batch595/1133, batch loss:0.08716905862092972, Training time:118857.34415388107
batch reward last col mean 0.4556009769439697 first col mean 0.448957622051239 all mean 0.4555242657661438
rl training, epoch4, iter0, batch596/1133, batch loss:0.08033343404531479, Training time:118884.45147752762
batch reward last col mean 0.5023906230926514 first col mean 0.4999138116836548 all mean 0.5023345351219177
rl training, epoch4, iter0, batch597/1133, batch loss:0.05100962147116661, Training time:118911.32225561142
batch reward last col mean 0.4864640533924103 first col mean 0.47955256700515747 all mean 0.48635414242744446
rl training, epoch4, iter0, batch598/1133, batch loss:0.10876018553972244, Training time:118938.17305517197
batch reward last col mean 0.5027832388877869 first col mean 0.504468560218811 all mean 0.502831220626831
rl training, epoch4, iter0, batch599/1133, batch loss:0.08962880074977875, Training time:118965.62043309212
batch reward last col mean 0.46737223863601685 first col mean 0.46854665875434875 all mean 0.46739593148231506
rl training, epoch4, iter0, batch600/1133, batch loss:0.07660409808158875, Training time:118992.66824197769
batch reward last col mean 0.5375131964683533 first col mean 0.5450112819671631 all mean 0.5375920534133911
rl training, epoch4, iter0, batch601/1133, batch loss:0.10139668732881546, Training time:119019.6893093586
batch reward last col mean 0.49461472034454346 first col mean 0.49278032779693604 all mean 0.49455657601356506
rl training, epoch4, iter0, batch602/1133, batch loss:0.1418621689081192, Training time:119046.60271167755
batch reward last col mean 0.5401464104652405 first col mean 0.529606282711029 all mean 0.5399690866470337
rl training, epoch4, iter0, batch603/1133, batch loss:0.1235818937420845, Training time:119073.41378831863
batch reward last col mean 0.45616811513900757 first col mean 0.4584278464317322 all mean 0.4562559723854065
rl training, epoch4, iter0, batch604/1133, batch loss:0.08119134604930878, Training time:119100.20088887215
batch reward last col mean 0.47589248418807983 first col mean 0.47311079502105713 all mean 0.475890189409256
rl training, epoch4, iter0, batch605/1133, batch loss:0.09704192727804184, Training time:119127.22161364555
batch reward last col mean 0.49274319410324097 first col mean 0.49664542078971863 all mean 0.492781400680542
rl training, epoch4, iter0, batch606/1133, batch loss:0.10453475266695023, Training time:119154.39447760582
batch reward last col mean 0.45188984274864197 first col mean 0.47469690442085266 all mean 0.452120304107666
rl training, epoch4, iter0, batch607/1133, batch loss:0.0794609785079956, Training time:119181.34354567528
batch reward last col mean 0.41471314430236816 first col mean 0.42126530408859253 all mean 0.41486382484436035
rl training, epoch4, iter0, batch608/1133, batch loss:0.10518884658813477, Training time:119208.38656878471
batch reward last col mean 0.455838143825531 first col mean 0.4733547866344452 all mean 0.4560399651527405
rl training, epoch4, iter0, batch609/1133, batch loss:0.11412086337804794, Training time:119235.48800754547
batch reward last col mean 0.44933611154556274 first col mean 0.455826073884964 all mean 0.449404776096344
rl training, epoch4, iter0, batch610/1133, batch loss:0.08104763925075531, Training time:119263.01308727264
batch reward last col mean 0.4868814945220947 first col mean 0.4913603663444519 all mean 0.4869235157966614
rl training, epoch4, iter0, batch611/1133, batch loss:0.12783844769001007, Training time:119290.03206133842
batch reward last col mean 0.48118990659713745 first col mean 0.4733603298664093 all mean 0.48110029101371765
rl training, epoch4, iter0, batch612/1133, batch loss:0.09063572436571121, Training time:119317.04170942307
batch reward last col mean 0.4617941677570343 first col mean 0.4690435230731964 all mean 0.46192508935928345
rl training, epoch4, iter0, batch613/1133, batch loss:0.12228122353553772, Training time:119344.15669035912
batch reward last col mean 0.4520150423049927 first col mean 0.4605022072792053 all mean 0.4520254135131836
rl training, epoch4, iter0, batch614/1133, batch loss:0.09108079969882965, Training time:119371.25732946396
batch reward last col mean 0.4907967448234558 first col mean 0.4936928451061249 all mean 0.4908257722854614
rl training, epoch4, iter0, batch615/1133, batch loss:0.08438127487897873, Training time:119398.42992758751
batch reward last col mean 0.4932667315006256 first col mean 0.49339526891708374 all mean 0.49325796961784363
rl training, epoch4, iter0, batch616/1133, batch loss:0.09987115114927292, Training time:119425.40406727791
batch reward last col mean 0.48090606927871704 first col mean 0.47803550958633423 all mean 0.48090440034866333
rl training, epoch4, iter0, batch617/1133, batch loss:0.05503346771001816, Training time:119452.31456422806
batch reward last col mean 0.5258175730705261 first col mean 0.5275337100028992 all mean 0.5259001851081848
rl training, epoch4, iter0, batch618/1133, batch loss:0.09640565514564514, Training time:119479.36870145798
batch reward last col mean 0.4745725691318512 first col mean 0.4690433740615845 all mean 0.4745043218135834
rl training, epoch4, iter0, batch619/1133, batch loss:0.09802020341157913, Training time:119506.7516348362
batch reward last col mean 0.444047749042511 first col mean 0.46529820561408997 all mean 0.4443545937538147
rl training, epoch4, iter0, batch620/1133, batch loss:0.09512383490800858, Training time:119533.94362592697
batch reward last col mean 0.4091687500476837 first col mean 0.40881550312042236 all mean 0.40916603803634644
rl training, epoch4, iter0, batch621/1133, batch loss:0.05530179291963577, Training time:119560.99525761604
batch reward last col mean 0.41623935103416443 first col mean 0.42342913150787354 all mean 0.4162793457508087
rl training, epoch4, iter0, batch622/1133, batch loss:0.08603786677122116, Training time:119587.89454078674
batch reward last col mean 0.49699342250823975 first col mean 0.49331483244895935 all mean 0.4968947470188141
rl training, epoch4, iter0, batch623/1133, batch loss:0.11105439811944962, Training time:119614.98849534988
batch reward last col mean 0.4903618097305298 first col mean 0.47971612215042114 all mean 0.49013572931289673
rl training, epoch4, iter0, batch624/1133, batch loss:0.12297917902469635, Training time:119642.2030787468
batch reward last col mean 0.5417081117630005 first col mean 0.537879467010498 all mean 0.5416700839996338
rl training, epoch4, iter0, batch625/1133, batch loss:0.08302624523639679, Training time:119669.32414841652
batch reward last col mean 0.46689218282699585 first col mean 0.4684903621673584 all mean 0.46683013439178467
rl training, epoch4, iter0, batch626/1133, batch loss:0.0741640254855156, Training time:119696.39551472664
batch reward last col mean 0.4229256510734558 first col mean 0.42403170466423035 all mean 0.42296379804611206
rl training, epoch4, iter0, batch627/1133, batch loss:0.09612151235342026, Training time:119723.64964151382
batch reward last col mean 0.47412562370300293 first col mean 0.468472957611084 all mean 0.47394877672195435
rl training, epoch4, iter0, batch628/1133, batch loss:0.10482863336801529, Training time:119750.81514120102
batch reward last col mean 0.45659124851226807 first col mean 0.4629230797290802 all mean 0.4567015767097473
rl training, epoch4, iter0, batch629/1133, batch loss:0.09115244448184967, Training time:119778.45287775993
batch reward last col mean 0.49225151538848877 first col mean 0.5009469985961914 all mean 0.4923518896102905
rl training, epoch4, iter0, batch630/1133, batch loss:0.09301638603210449, Training time:119805.75424695015
batch reward last col mean 0.40396153926849365 first col mean 0.41799676418304443 all mean 0.4040681719779968
rl training, epoch4, iter0, batch631/1133, batch loss:0.064814493060112, Training time:119832.77659344673
batch reward last col mean 0.47731807827949524 first col mean 0.4780191481113434 all mean 0.47731149196624756
rl training, epoch4, iter0, batch632/1133, batch loss:0.10163462162017822, Training time:119859.703125
batch reward last col mean 0.47828227281570435 first col mean 0.46911948919296265 all mean 0.4780465066432953
rl training, epoch4, iter0, batch633/1133, batch loss:0.06932907551527023, Training time:119886.71116638184
batch reward last col mean 0.46319088339805603 first col mean 0.47267624735832214 all mean 0.4633358120918274
rl training, epoch4, iter0, batch634/1133, batch loss:0.10101044178009033, Training time:119914.2086713314
batch reward last col mean 0.5048789381980896 first col mean 0.5116279721260071 all mean 0.5050051212310791
rl training, epoch4, iter0, batch635/1133, batch loss:0.10277434438467026, Training time:119941.89648032188
batch reward last col mean 0.5320940017700195 first col mean 0.5242841243743896 all mean 0.5319647789001465
rl training, epoch4, iter0, batch636/1133, batch loss:0.09330105036497116, Training time:119969.74887514114
batch reward last col mean 0.461645245552063 first col mean 0.45622900128364563 all mean 0.4615749716758728
rl training, epoch4, iter0, batch637/1133, batch loss:0.07009400427341461, Training time:119996.6909441948
batch reward last col mean 0.45516496896743774 first col mean 0.44242024421691895 all mean 0.45495790243148804
rl training, epoch4, iter0, batch638/1133, batch loss:0.0931864082813263, Training time:120023.73441767693
batch reward last col mean 0.4871251881122589 first col mean 0.4987049102783203 all mean 0.4871547222137451
rl training, epoch4, iter0, batch639/1133, batch loss:0.13225238025188446, Training time:120050.7608718872
batch reward last col mean 0.4890063405036926 first col mean 0.48334041237831116 all mean 0.48883479833602905
rl training, epoch4, iter0, batch640/1133, batch loss:0.11162369698286057, Training time:120077.9109287262
batch reward last col mean 0.48738235235214233 first col mean 0.4942021369934082 all mean 0.48740914463996887
rl training, epoch4, iter0, batch641/1133, batch loss:0.08483696728944778, Training time:120104.95485496521
batch reward last col mean 0.4563400149345398 first col mean 0.43723198771476746 all mean 0.45599114894866943
rl training, epoch4, iter0, batch642/1133, batch loss:0.1096910759806633, Training time:120131.84588718414
batch reward last col mean 0.4779171049594879 first col mean 0.47237223386764526 all mean 0.4778740108013153
rl training, epoch4, iter0, batch643/1133, batch loss:0.12386985868215561, Training time:120158.86215400696
batch reward last col mean 0.5393810272216797 first col mean 0.5297417044639587 all mean 0.5392996072769165
rl training, epoch4, iter0, batch644/1133, batch loss:0.11453966796398163, Training time:120185.99280643463
batch reward last col mean 0.4611768424510956 first col mean 0.46408477425575256 all mean 0.46134883165359497
rl training, epoch4, iter0, batch645/1133, batch loss:0.10192257165908813, Training time:120213.44342756271
batch reward last col mean 0.45476266741752625 first col mean 0.45729032158851624 all mean 0.4548155665397644
rl training, epoch4, iter0, batch646/1133, batch loss:0.09182114899158478, Training time:120240.66025280952
batch reward last col mean 0.4902209937572479 first col mean 0.49643027782440186 all mean 0.4902081787586212
rl training, epoch4, iter0, batch647/1133, batch loss:0.06886790692806244, Training time:120267.65922236443
batch reward last col mean 0.569252073764801 first col mean 0.5645437240600586 all mean 0.5692549347877502
rl training, epoch4, iter0, batch648/1133, batch loss:0.09937835484743118, Training time:120294.7263455391
batch reward last col mean 0.467244029045105 first col mean 0.47506749629974365 all mean 0.46736353635787964
rl training, epoch4, iter0, batch649/1133, batch loss:0.10086359828710556, Training time:120321.74946308136
batch reward last col mean 0.510030210018158 first col mean 0.5062885284423828 all mean 0.5099734663963318
rl training, epoch4, iter0, batch650/1133, batch loss:0.09680242836475372, Training time:120348.88464093208
batch reward last col mean 0.5003321170806885 first col mean 0.5018792152404785 all mean 0.5003761649131775
rl training, epoch4, iter0, batch651/1133, batch loss:0.13547706604003906, Training time:120375.94180488586
batch reward last col mean 0.5327287912368774 first col mean 0.534731388092041 all mean 0.5327401161193848
rl training, epoch4, iter0, batch652/1133, batch loss:0.11274059861898422, Training time:120402.84866142273
batch reward last col mean 0.5399052500724792 first col mean 0.5332560539245605 all mean 0.5399094223976135
rl training, epoch4, iter0, batch653/1133, batch loss:0.1341690868139267, Training time:120429.94933438301
batch reward last col mean 0.5376609563827515 first col mean 0.5389859676361084 all mean 0.5375904440879822
rl training, epoch4, iter0, batch654/1133, batch loss:0.10644374787807465, Training time:120456.96615839005
batch reward last col mean 0.5016770958900452 first col mean 0.500913143157959 all mean 0.50166255235672
rl training, epoch4, iter0, batch655/1133, batch loss:0.1369394063949585, Training time:120484.02176570892
batch reward last col mean 0.4507552981376648 first col mean 0.4430547058582306 all mean 0.4507014751434326
rl training, epoch4, iter0, batch656/1133, batch loss:0.08091063052415848, Training time:120511.0648765564
batch reward last col mean 0.5116897821426392 first col mean 0.5102205276489258 all mean 0.5116633176803589
rl training, epoch4, iter0, batch657/1133, batch loss:0.1193128451704979, Training time:120538.08575773239
batch reward last col mean 0.46851980686187744 first col mean 0.48754623532295227 all mean 0.46880286931991577
rl training, epoch4, iter0, batch658/1133, batch loss:0.103648342192173, Training time:120565.31388664246
batch reward last col mean 0.4916166365146637 first col mean 0.48576128482818604 all mean 0.4914983808994293
rl training, epoch4, iter0, batch659/1133, batch loss:0.10217167437076569, Training time:120592.83631324768
batch reward last col mean 0.46410274505615234 first col mean 0.46237969398498535 all mean 0.46410492062568665
rl training, epoch4, iter0, batch660/1133, batch loss:0.0849127545952797, Training time:120619.80202817917
batch reward last col mean 0.48846083879470825 first col mean 0.48007628321647644 all mean 0.4883274734020233
rl training, epoch4, iter0, batch661/1133, batch loss:0.08285915106534958, Training time:120647.36930465698
batch reward last col mean 0.49588704109191895 first col mean 0.48217740654945374 all mean 0.49575427174568176
rl training, epoch4, iter0, batch662/1133, batch loss:0.1080942302942276, Training time:120674.2621190548
batch reward last col mean 0.47093427181243896 first col mean 0.4784225821495056 all mean 0.47100597620010376
rl training, epoch4, iter0, batch663/1133, batch loss:0.05994340777397156, Training time:120701.85897064209
batch reward last col mean 0.5364742279052734 first col mean 0.5323294997215271 all mean 0.5363662838935852
rl training, epoch4, iter0, batch664/1133, batch loss:0.08569792658090591, Training time:120728.96191239357
batch reward last col mean 0.4299713969230652 first col mean 0.4301522970199585 all mean 0.4299847483634949
rl training, epoch4, iter0, batch665/1133, batch loss:0.11076446622610092, Training time:120756.1036977768
batch reward last col mean 0.5374273657798767 first col mean 0.5286087989807129 all mean 0.5373364686965942
rl training, epoch4, iter0, batch666/1133, batch loss:0.09401852637529373, Training time:120783.08568525314
batch reward last col mean 0.45692989230155945 first col mean 0.4615975320339203 all mean 0.45691433548927307
rl training, epoch4, iter0, batch667/1133, batch loss:0.1037420853972435, Training time:120810.05181288719
batch reward last col mean 0.48810720443725586 first col mean 0.48461878299713135 all mean 0.48806726932525635
rl training, epoch4, iter0, batch668/1133, batch loss:0.08856526762247086, Training time:120837.30824971199
batch reward last col mean 0.4643157124519348 first col mean 0.460394948720932 all mean 0.46429234743118286
rl training, epoch4, iter0, batch669/1133, batch loss:0.10730788856744766, Training time:120865.21368193626
batch reward last col mean 0.4927006959915161 first col mean 0.4979231059551239 all mean 0.4928237497806549
rl training, epoch4, iter0, batch670/1133, batch loss:0.07933223992586136, Training time:120893.87064361572
batch reward last col mean 0.4381794333457947 first col mean 0.4428265690803528 all mean 0.4382183253765106
rl training, epoch4, iter0, batch671/1133, batch loss:0.07066725939512253, Training time:120920.85779309273
batch reward last col mean 0.5119317770004272 first col mean 0.5069605708122253 all mean 0.5118975639343262
rl training, epoch4, iter0, batch672/1133, batch loss:0.10365242511034012, Training time:120947.74912118912
batch reward last col mean 0.49738335609436035 first col mean 0.49957722425460815 all mean 0.49738550186157227
rl training, epoch4, iter0, batch673/1133, batch loss:0.07132071256637573, Training time:120974.74570393562
batch reward last col mean 0.47915834188461304 first col mean 0.48516136407852173 all mean 0.47930312156677246
rl training, epoch4, iter0, batch674/1133, batch loss:0.10982482135295868, Training time:121001.89040398598
batch reward last col mean 0.5102349519729614 first col mean 0.49750131368637085 all mean 0.5100466012954712
rl training, epoch4, iter0, batch675/1133, batch loss:0.09728920459747314, Training time:121028.89971494675
batch reward last col mean 0.461081862449646 first col mean 0.4634057879447937 all mean 0.4611331522464752
rl training, epoch4, iter0, batch676/1133, batch loss:0.07840722054243088, Training time:121055.97229027748
batch reward last col mean 0.51955646276474 first col mean 0.5265001058578491 all mean 0.5196275115013123
rl training, epoch4, iter0, batch677/1133, batch loss:0.11227654665708542, Training time:121083.20513820648
batch reward last col mean 0.5000549554824829 first col mean 0.5075259804725647 all mean 0.5001635551452637
rl training, epoch4, iter0, batch678/1133, batch loss:0.11884091049432755, Training time:121110.39384412766
batch reward last col mean 0.4480910897254944 first col mean 0.4667106568813324 all mean 0.44845861196517944
rl training, epoch4, iter0, batch679/1133, batch loss:0.06471216678619385, Training time:121137.41864705086
batch reward last col mean 0.4441651701927185 first col mean 0.434928297996521 all mean 0.4440825581550598
rl training, epoch4, iter0, batch680/1133, batch loss:0.14554809033870697, Training time:121164.4898455143
batch reward last col mean 0.4522668719291687 first col mean 0.4659055173397064 all mean 0.45255428552627563
rl training, epoch4, iter0, batch681/1133, batch loss:0.09047309309244156, Training time:121191.50043773651
batch reward last col mean 0.514776349067688 first col mean 0.5160661339759827 all mean 0.5148212313652039
rl training, epoch4, iter0, batch682/1133, batch loss:0.11057402193546295, Training time:121218.42404723167
batch reward last col mean 0.44388189911842346 first col mean 0.44714438915252686 all mean 0.4439539313316345
rl training, epoch4, iter0, batch683/1133, batch loss:0.11130116134881973, Training time:121245.78842115402
batch reward last col mean 0.5445663928985596 first col mean 0.5464072227478027 all mean 0.5445737838745117
rl training, epoch4, iter0, batch684/1133, batch loss:0.10216986387968063, Training time:121272.99123883247
batch reward last col mean 0.5168024897575378 first col mean 0.5271518230438232 all mean 0.5168805122375488
rl training, epoch4, iter0, batch685/1133, batch loss:0.10318327695131302, Training time:121300.79508590698
batch reward last col mean 0.5350819230079651 first col mean 0.5334771871566772 all mean 0.5348397493362427
rl training, epoch4, iter0, batch686/1133, batch loss:0.13339512050151825, Training time:121327.87970161438
batch reward last col mean 0.49763885140419006 first col mean 0.5062201023101807 all mean 0.4979102313518524
rl training, epoch4, iter0, batch687/1133, batch loss:0.10920073091983795, Training time:121354.79810237885
batch reward last col mean 0.5002077221870422 first col mean 0.4890199899673462 all mean 0.5000848770141602
rl training, epoch4, iter0, batch688/1133, batch loss:0.1235257238149643, Training time:121381.8990559578
batch reward last col mean 0.46313127875328064 first col mean 0.45794689655303955 all mean 0.4632023572921753
rl training, epoch4, iter0, batch689/1133, batch loss:0.1210627555847168, Training time:121409.00059175491
batch reward last col mean 0.5027604103088379 first col mean 0.5099740624427795 all mean 0.502833366394043
rl training, epoch4, iter0, batch690/1133, batch loss:0.14771857857704163, Training time:121436.11520433426
batch reward last col mean 0.49247831106185913 first col mean 0.4989435076713562 all mean 0.49263739585876465
rl training, epoch4, iter0, batch691/1133, batch loss:0.1154700368642807, Training time:121463.15476417542
batch reward last col mean 0.5232048034667969 first col mean 0.5181839466094971 all mean 0.5230915546417236
rl training, epoch4, iter0, batch692/1133, batch loss:0.14022107422351837, Training time:121490.05432701111
batch reward last col mean 0.528956413269043 first col mean 0.5266495943069458 all mean 0.5290346741676331
rl training, epoch4, iter0, batch693/1133, batch loss:0.15826354920864105, Training time:121517.55578804016
batch reward last col mean 0.47303760051727295 first col mean 0.4537448287010193 all mean 0.4727095067501068
rl training, epoch4, iter0, batch694/1133, batch loss:0.09708312153816223, Training time:121544.76178336143
batch reward last col mean 0.5326312780380249 first col mean 0.5267530679702759 all mean 0.5324870347976685
rl training, epoch4, iter0, batch695/1133, batch loss:0.12012812495231628, Training time:121572.05213785172
batch reward last col mean 0.5060046911239624 first col mean 0.5059483051300049 all mean 0.5058761835098267
rl training, epoch4, iter0, batch696/1133, batch loss:0.1283390074968338, Training time:121598.98929786682
batch reward last col mean 0.4933456480503082 first col mean 0.515229344367981 all mean 0.49349886178970337
rl training, epoch4, iter0, batch697/1133, batch loss:0.14562423527240753, Training time:121625.91342020035
batch reward last col mean 0.4943678081035614 first col mean 0.51189786195755 all mean 0.4948282241821289
rl training, epoch4, iter0, batch698/1133, batch loss:0.11895234137773514, Training time:121652.97391939163
batch reward last col mean 0.5375292897224426 first col mean 0.5440555810928345 all mean 0.5377116203308105
rl training, epoch4, iter0, batch699/1133, batch loss:0.15112383663654327, Training time:121680.0468006134
batch reward last col mean 0.513714075088501 first col mean 0.5208832025527954 all mean 0.513831377029419
rl training, epoch4, iter0, batch700/1133, batch loss:0.12019843608140945, Training time:121707.15832614899
batch reward last col mean 0.5687220096588135 first col mean 0.554619550704956 all mean 0.5684880614280701
rl training, epoch4, iter0, batch701/1133, batch loss:0.12702174484729767, Training time:121734.24152708054
batch reward last col mean 0.4460803270339966 first col mean 0.4528834819793701 all mean 0.4462184011936188
rl training, epoch4, iter0, batch702/1133, batch loss:0.10104848444461823, Training time:121761.15239238739
batch reward last col mean 0.47031423449516296 first col mean 0.47537243366241455 all mean 0.47033458948135376
rl training, epoch4, iter0, batch703/1133, batch loss:0.13900110125541687, Training time:121788.64800834656
batch reward last col mean 0.51035076379776 first col mean 0.5087663531303406 all mean 0.5102494359016418
rl training, epoch4, iter0, batch704/1133, batch loss:0.13464301824569702, Training time:121815.82102179527
batch reward last col mean 0.4720926880836487 first col mean 0.47288984060287476 all mean 0.4721285104751587
rl training, epoch4, iter0, batch705/1133, batch loss:0.10884294658899307, Training time:121842.94382953644
batch reward last col mean 0.46711212396621704 first col mean 0.46479353308677673 all mean 0.4671062231063843
rl training, epoch4, iter0, batch706/1133, batch loss:0.13727179169654846, Training time:121870.13863015175
batch reward last col mean 0.5109580159187317 first col mean 0.5212537050247192 all mean 0.5110670328140259
rl training, epoch4, iter0, batch707/1133, batch loss:0.12102482467889786, Training time:121897.13235116005
batch reward last col mean 0.4481287896633148 first col mean 0.4464959502220154 all mean 0.4483235776424408
rl training, epoch4, iter0, batch708/1133, batch loss:0.10831163078546524, Training time:121924.21120762825
batch reward last col mean 0.44785383343696594 first col mean 0.4419001638889313 all mean 0.447804719209671
rl training, epoch4, iter0, batch709/1133, batch loss:0.11669456213712692, Training time:121951.31817030907
batch reward last col mean 0.4942110776901245 first col mean 0.4927598237991333 all mean 0.49382227659225464
rl training, epoch4, iter0, batch710/1133, batch loss:0.17483647167682648, Training time:121978.40309810638
batch reward last col mean 0.4750916361808777 first col mean 0.4926096498966217 all mean 0.4751736521720886
rl training, epoch4, iter0, batch711/1133, batch loss:0.14602413773536682, Training time:122005.59668421745
batch reward last col mean 0.4822002053260803 first col mean 0.4795202314853668 all mean 0.4821309447288513
rl training, epoch4, iter0, batch712/1133, batch loss:0.15177643299102783, Training time:122032.67256045341
batch reward last col mean 0.4776306748390198 first col mean 0.4719609022140503 all mean 0.47764062881469727
rl training, epoch4, iter0, batch713/1133, batch loss:0.1366872489452362, Training time:122060.20897054672
batch reward last col mean 0.5137993097305298 first col mean 0.49886491894721985 all mean 0.5135647654533386
rl training, epoch4, iter0, batch714/1133, batch loss:0.12404398620128632, Training time:122087.70450806618
batch reward last col mean 0.43582308292388916 first col mean 0.43177682161331177 all mean 0.4357231855392456
rl training, epoch4, iter0, batch715/1133, batch loss:0.13116835057735443, Training time:122114.83952832222
batch reward last col mean 0.49349576234817505 first col mean 0.49908310174942017 all mean 0.4937937557697296
rl training, epoch4, iter0, batch716/1133, batch loss:0.1625162810087204, Training time:122142.0826382637
batch reward last col mean 0.4831254482269287 first col mean 0.5000160932540894 all mean 0.48387959599494934
rl training, epoch4, iter0, batch717/1133, batch loss:0.13295726478099823, Training time:122169.02724695206
batch reward last col mean 0.47448402643203735 first col mean 0.48439091444015503 all mean 0.47471603751182556
rl training, epoch4, iter0, batch718/1133, batch loss:0.13189861178398132, Training time:122196.13958358765
batch reward last col mean 0.5264228582382202 first col mean 0.5291133522987366 all mean 0.5265989899635315
rl training, epoch4, iter0, batch719/1133, batch loss:0.22088372707366943, Training time:122223.20828127861
batch reward last col mean 0.4470658600330353 first col mean 0.4627310633659363 all mean 0.44776442646980286
rl training, epoch4, iter0, batch720/1133, batch loss:0.1642473042011261, Training time:122250.21267056465
batch reward last col mean 0.4907441735267639 first col mean 0.4914737641811371 all mean 0.4907805025577545
rl training, epoch4, iter0, batch721/1133, batch loss:0.16916796565055847, Training time:122277.25442552567
batch reward last col mean 0.5309807062149048 first col mean 0.5360082983970642 all mean 0.5313171148300171
rl training, epoch4, iter0, batch722/1133, batch loss:0.1762484759092331, Training time:122305.05198478699
batch reward last col mean 0.5290595293045044 first col mean 0.5409985780715942 all mean 0.5291536450386047
rl training, epoch4, iter0, batch723/1133, batch loss:0.18117859959602356, Training time:122332.14355301857
batch reward last col mean 0.5263944864273071 first col mean 0.5452525615692139 all mean 0.5266227126121521
rl training, epoch4, iter0, batch724/1133, batch loss:0.253205269575119, Training time:122359.20166015625
batch reward last col mean 0.41321542859077454 first col mean 0.43788376450538635 all mean 0.4135904014110565
rl training, epoch4, iter0, batch725/1133, batch loss:0.12746724486351013, Training time:122386.37646889687
batch reward last col mean 0.5193371772766113 first col mean 0.5263594388961792 all mean 0.5195193290710449
rl training, epoch4, iter0, batch726/1133, batch loss:0.16854393482208252, Training time:122413.34920287132
batch reward last col mean 0.4747048616409302 first col mean 0.4716656804084778 all mean 0.474607914686203
rl training, epoch4, iter0, batch727/1133, batch loss:0.2015998214483261, Training time:122440.81011986732
batch reward last col mean 0.48755404353141785 first col mean 0.4869005084037781 all mean 0.48754286766052246
rl training, epoch4, iter0, batch728/1133, batch loss:0.15050017833709717, Training time:122467.87727928162
batch reward last col mean 0.5473598837852478 first col mean 0.5437275767326355 all mean 0.5474786758422852
rl training, epoch4, iter0, batch729/1133, batch loss:0.17833173274993896, Training time:122494.85959935188
batch reward last col mean 0.5400153994560242 first col mean 0.5339600443840027 all mean 0.5398209095001221
rl training, epoch4, iter0, batch730/1133, batch loss:0.14965778589248657, Training time:122522.45035529137
batch reward last col mean 0.45020726323127747 first col mean 0.45273154973983765 all mean 0.4503518342971802
rl training, epoch4, iter0, batch731/1133, batch loss:0.17698140442371368, Training time:122549.47629833221
batch reward last col mean 0.4612405300140381 first col mean 0.45301201939582825 all mean 0.46123605966567993
rl training, epoch4, iter0, batch732/1133, batch loss:0.14508788287639618, Training time:122576.4225025177
batch reward last col mean 0.5004225373268127 first col mean 0.49066391587257385 all mean 0.500175416469574
rl training, epoch4, iter0, batch733/1133, batch loss:0.1291268765926361, Training time:122603.58736348152
batch reward last col mean 0.49028539657592773 first col mean 0.47977620363235474 all mean 0.4901164770126343
rl training, epoch4, iter0, batch734/1133, batch loss:0.10826261341571808, Training time:122630.60392951965
batch reward last col mean 0.501598596572876 first col mean 0.4912720322608948 all mean 0.5013670325279236
rl training, epoch4, iter0, batch735/1133, batch loss:0.1772879958152771, Training time:122658.1673309803
batch reward last col mean 0.4478961229324341 first col mean 0.4477330446243286 all mean 0.4478900134563446
rl training, epoch4, iter0, batch736/1133, batch loss:0.10424783080816269, Training time:122685.85993266106
batch reward last col mean 0.45447343587875366 first col mean 0.4577915668487549 all mean 0.4546077847480774
rl training, epoch4, iter0, batch737/1133, batch loss:0.1673654317855835, Training time:122712.7690141201
batch reward last col mean 0.5433840751647949 first col mean 0.5420706272125244 all mean 0.5434427857398987
rl training, epoch4, iter0, batch738/1133, batch loss:0.11934440582990646, Training time:122739.7982788086
batch reward last col mean 0.5565515160560608 first col mean 0.5456031560897827 all mean 0.5564882159233093
rl training, epoch4, iter0, batch739/1133, batch loss:0.1806294471025467, Training time:122766.83067846298
batch reward last col mean 0.4450951814651489 first col mean 0.4587365388870239 all mean 0.44540274143218994
rl training, epoch4, iter0, batch740/1133, batch loss:0.10952076315879822, Training time:122793.89431738853
batch reward last col mean 0.49571865797042847 first col mean 0.49170583486557007 all mean 0.49561068415641785
rl training, epoch4, iter0, batch741/1133, batch loss:0.1436239778995514, Training time:122821.52228426933
batch reward last col mean 0.5053210258483887 first col mean 0.4995940327644348 all mean 0.5053019523620605
rl training, epoch4, iter0, batch742/1133, batch loss:0.17889957129955292, Training time:122848.69576883316
batch reward last col mean 0.503050684928894 first col mean 0.5066422820091248 all mean 0.5029737949371338
rl training, epoch4, iter0, batch743/1133, batch loss:0.12049897015094757, Training time:122875.84117913246
batch reward last col mean 0.509627640247345 first col mean 0.5043225288391113 all mean 0.5095363855361938
rl training, epoch4, iter0, batch744/1133, batch loss:0.14367170631885529, Training time:122902.94150233269
batch reward last col mean 0.465583860874176 first col mean 0.47088757157325745 all mean 0.4657738506793976
rl training, epoch4, iter0, batch745/1133, batch loss:0.1286557912826538, Training time:122930.04739546776
batch reward last col mean 0.4878828823566437 first col mean 0.49388939142227173 all mean 0.48788556456565857
rl training, epoch4, iter0, batch746/1133, batch loss:0.1744232177734375, Training time:122956.99085736275
batch reward last col mean 0.5324839949607849 first col mean 0.5271120071411133 all mean 0.5323627591133118
rl training, epoch4, iter0, batch747/1133, batch loss:0.17529042065143585, Training time:122983.82761478424
batch reward last col mean 0.5438718795776367 first col mean 0.5489346981048584 all mean 0.5441144108772278
rl training, epoch4, iter0, batch748/1133, batch loss:0.17932665348052979, Training time:123010.76995563507
batch reward last col mean 0.5272862911224365 first col mean 0.5306798815727234 all mean 0.52749103307724
rl training, epoch4, iter0, batch749/1133, batch loss:0.16809068620204926, Training time:123038.0516462326
batch reward last col mean 0.5334166288375854 first col mean 0.5279579162597656 all mean 0.5332021117210388
rl training, epoch4, iter0, batch750/1133, batch loss:0.17193369567394257, Training time:123065.10599946976
batch reward last col mean 0.5593810081481934 first col mean 0.5709446668624878 all mean 0.559709906578064
rl training, epoch4, iter0, batch751/1133, batch loss:0.16997191309928894, Training time:123092.20717430115
batch reward last col mean 0.6200577616691589 first col mean 0.6078412532806396 all mean 0.619789719581604
rl training, epoch4, iter0, batch752/1133, batch loss:0.17057585716247559, Training time:123119.1106133461
batch reward last col mean 0.6130896806716919 first col mean 0.5910100936889648 all mean 0.6125942468643188
rl training, epoch4, iter0, batch753/1133, batch loss:0.23095417022705078, Training time:123146.15716981888
batch reward last col mean 0.5401026010513306 first col mean 0.5315552949905396 all mean 0.5402752757072449
rl training, epoch4, iter0, batch754/1133, batch loss:0.18491576611995697, Training time:123173.22955703735
batch reward last col mean 0.5326241850852966 first col mean 0.545753002166748 all mean 0.5328145027160645
rl training, epoch4, iter0, batch755/1133, batch loss:0.17668218910694122, Training time:123200.66334986687
batch reward last col mean 0.5096822381019592 first col mean 0.5197264552116394 all mean 0.5097177624702454
rl training, epoch4, iter0, batch756/1133, batch loss:0.1944156140089035, Training time:123227.67632079124
batch reward last col mean 0.5697920918464661 first col mean 0.5762939453125 all mean 0.5700903534889221
rl training, epoch4, iter0, batch757/1133, batch loss:0.22016000747680664, Training time:123254.62095475197
batch reward last col mean 0.5120185017585754 first col mean 0.5150759816169739 all mean 0.5119886994361877
rl training, epoch4, iter0, batch758/1133, batch loss:0.2366926074028015, Training time:123281.58525848389
batch reward last col mean 0.5496729612350464 first col mean 0.5476977825164795 all mean 0.5496792793273926
rl training, epoch4, iter0, batch759/1133, batch loss:0.23983214795589447, Training time:123308.5843038559
batch reward last col mean 0.5337063074111938 first col mean 0.5274031162261963 all mean 0.5337653160095215
rl training, epoch4, iter0, batch760/1133, batch loss:0.2102193832397461, Training time:123336.31731557846
batch reward last col mean 0.5689717531204224 first col mean 0.5703285336494446 all mean 0.5692023038864136
rl training, epoch4, iter0, batch761/1133, batch loss:0.22682102024555206, Training time:123363.3458249569
batch reward last col mean 0.54485684633255 first col mean 0.5393064618110657 all mean 0.5449724793434143
rl training, epoch4, iter0, batch762/1133, batch loss:0.1997980773448944, Training time:123390.26373410225
batch reward last col mean 0.4901171922683716 first col mean 0.4929157793521881 all mean 0.49023717641830444
rl training, epoch4, iter0, batch763/1133, batch loss:0.21362623572349548, Training time:123417.29194164276
batch reward last col mean 0.5467537641525269 first col mean 0.5515902042388916 all mean 0.5466447472572327
rl training, epoch4, iter0, batch764/1133, batch loss:0.22010479867458344, Training time:123444.31773519516
batch reward last col mean 0.5164440870285034 first col mean 0.5262961983680725 all mean 0.5163480043411255
rl training, epoch4, iter0, batch765/1133, batch loss:0.2673478424549103, Training time:123471.55842328072
batch reward last col mean 0.5453829169273376 first col mean 0.5483607649803162 all mean 0.5452832579612732
rl training, epoch4, iter0, batch766/1133, batch loss:0.24317209422588348, Training time:123498.70244646072
batch reward last col mean 0.5433991551399231 first col mean 0.5701409578323364 all mean 0.5433964729309082
rl training, epoch4, iter0, batch767/1133, batch loss:0.23853784799575806, Training time:123525.64756846428
batch reward last col mean 0.5115605592727661 first col mean 0.4938558042049408 all mean 0.5112708210945129
rl training, epoch4, iter0, batch768/1133, batch loss:0.22390702366828918, Training time:123552.74446058273
batch reward last col mean 0.5135797262191772 first col mean 0.5334548950195312 all mean 0.5147315859794617
rl training, epoch4, iter0, batch769/1133, batch loss:0.24610692262649536, Training time:123580.00383734703
batch reward last col mean 0.5914587378501892 first col mean 0.5735830068588257 all mean 0.5909661054611206
rl training, epoch4, iter0, batch770/1133, batch loss:0.2462925761938095, Training time:123607.59875035286
batch reward last col mean 0.5314385294914246 first col mean 0.5412002205848694 all mean 0.5317529439926147
rl training, epoch4, iter0, batch771/1133, batch loss:0.19366960227489471, Training time:123634.76786899567
batch reward last col mean 0.5148388147354126 first col mean 0.5350327491760254 all mean 0.5151979923248291
rl training, epoch4, iter0, batch772/1133, batch loss:0.2756926715373993, Training time:123661.94741272926
batch reward last col mean 0.5369776487350464 first col mean 0.5436079502105713 all mean 0.5375374555587769
rl training, epoch4, iter0, batch773/1133, batch loss:0.27362313866615295, Training time:123689.5658917427
batch reward last col mean 0.5073382258415222 first col mean 0.49514007568359375 all mean 0.5068466663360596
rl training, epoch4, iter0, batch774/1133, batch loss:0.2348991483449936, Training time:123716.9921746254
batch reward last col mean 0.5026686787605286 first col mean 0.5218602418899536 all mean 0.5040875673294067
rl training, epoch4, iter0, batch775/1133, batch loss:0.28843429684638977, Training time:123744.26662278175
batch reward last col mean 0.49664297699928284 first col mean 0.5146031379699707 all mean 0.49687811732292175
rl training, epoch4, iter0, batch776/1133, batch loss:0.2859143614768982, Training time:123771.3839879036
batch reward last col mean 0.48906874656677246 first col mean 0.49739664793014526 all mean 0.4897148311138153
rl training, epoch4, iter0, batch777/1133, batch loss:0.2851853370666504, Training time:123798.64337468147
batch reward last col mean 0.5189220905303955 first col mean 0.5169033408164978 all mean 0.5192111134529114
rl training, epoch4, iter0, batch778/1133, batch loss:0.2757267951965332, Training time:123825.94452428818
batch reward last col mean 0.5120022296905518 first col mean 0.5045067071914673 all mean 0.5121104121208191
rl training, epoch4, iter0, batch779/1133, batch loss:0.30800962448120117, Training time:123853.23028635979
batch reward last col mean 0.548175573348999 first col mean 0.5666056275367737 all mean 0.548312783241272
rl training, epoch4, iter0, batch780/1133, batch loss:0.3335604667663574, Training time:123881.27724552155
batch reward last col mean 0.5551931858062744 first col mean 0.5504546165466309 all mean 0.5548327565193176
rl training, epoch4, iter0, batch781/1133, batch loss:0.3952220380306244, Training time:123908.56833910942
batch reward last col mean 0.5578929781913757 first col mean 0.5427322387695312 all mean 0.5563544631004333
rl training, epoch4, iter0, batch782/1133, batch loss:0.2969892621040344, Training time:123935.92804217339
batch reward last col mean 0.5378820896148682 first col mean 0.5482062697410583 all mean 0.5375329852104187
rl training, epoch4, iter0, batch783/1133, batch loss:0.2944774627685547, Training time:123963.94693231583
batch reward last col mean 0.4997980296611786 first col mean 0.5100224614143372 all mean 0.5005558729171753
rl training, epoch4, iter0, batch784/1133, batch loss:0.33059805631637573, Training time:123991.70249581337
batch reward last col mean 0.4916365444660187 first col mean 0.522612452507019 all mean 0.49297645688056946
rl training, epoch4, iter0, batch785/1133, batch loss:0.3216729462146759, Training time:124019.43348670006
batch reward last col mean 0.5382380485534668 first col mean 0.557822585105896 all mean 0.538886547088623
rl training, epoch4, iter0, batch786/1133, batch loss:0.33348146080970764, Training time:124046.73859453201
batch reward last col mean 0.5026848316192627 first col mean 0.5099500417709351 all mean 0.5031681060791016
rl training, epoch4, iter0, batch787/1133, batch loss:0.3008432984352112, Training time:124074.19347167015
batch reward last col mean 0.5267409086227417 first col mean 0.5149224996566772 all mean 0.5265398025512695
rl training, epoch4, iter0, batch788/1133, batch loss:0.3166744112968445, Training time:124101.75571203232
batch reward last col mean 0.5246692895889282 first col mean 0.5231667160987854 all mean 0.5243693590164185
rl training, epoch4, iter0, batch789/1133, batch loss:0.2734629809856415, Training time:124129.44115781784
batch reward last col mean 0.49773386120796204 first col mean 0.494565486907959 all mean 0.49749401211738586
rl training, epoch4, iter0, batch790/1133, batch loss:0.3275326192378998, Training time:124157.00871300697
batch reward last col mean 0.5110082626342773 first col mean 0.5059590935707092 all mean 0.5119684934616089
rl training, epoch4, iter0, batch791/1133, batch loss:0.31627169251441956, Training time:124184.4428935051
batch reward last col mean 0.5474967956542969 first col mean 0.539757490158081 all mean 0.5485949516296387
rl training, epoch4, iter0, batch792/1133, batch loss:0.30685439705848694, Training time:124211.86631274223
batch reward last col mean 0.5338753461837769 first col mean 0.5298399925231934 all mean 0.532711923122406
rl training, epoch4, iter0, batch793/1133, batch loss:0.27504947781562805, Training time:124239.48313474655
batch reward last col mean 0.5056972503662109 first col mean 0.5089807510375977 all mean 0.5040446519851685
rl training, epoch4, iter0, batch794/1133, batch loss:0.27586376667022705, Training time:124267.13167190552
batch reward last col mean 0.5228471755981445 first col mean 0.5335323810577393 all mean 0.523062527179718
rl training, epoch4, iter0, batch795/1133, batch loss:0.2631877362728119, Training time:124294.68075990677
batch reward last col mean 0.5555558204650879 first col mean 0.5571507215499878 all mean 0.5558789372444153
rl training, epoch4, iter0, batch796/1133, batch loss:0.2603878080844879, Training time:124322.03942465782
batch reward last col mean 0.5809420347213745 first col mean 0.5872557163238525 all mean 0.5808863043785095
rl training, epoch4, iter0, batch797/1133, batch loss:0.33309081196784973, Training time:124349.83811187744
batch reward last col mean 0.5378701686859131 first col mean 0.5409554839134216 all mean 0.537647545337677
rl training, epoch4, iter0, batch798/1133, batch loss:0.3102741241455078, Training time:124377.41837763786
batch reward last col mean 0.5324249267578125 first col mean 0.5654078125953674 all mean 0.5334671139717102
rl training, epoch4, iter0, batch799/1133, batch loss:0.22986695170402527, Training time:124405.34965133667
batch reward last col mean 0.5559583306312561 first col mean 0.5379624366760254 all mean 0.5551117658615112
rl training, epoch4, iter0, batch800/1133, batch loss:0.31961897015571594, Training time:124432.71465587616
batch reward last col mean 0.5428433418273926 first col mean 0.523205041885376 all mean 0.5421025156974792
rl training, epoch4, iter0, batch801/1133, batch loss:0.22914999723434448, Training time:124460.60812592506
batch reward last col mean 0.5490535497665405 first col mean 0.570844292640686 all mean 0.5496683120727539
rl training, epoch4, iter0, batch802/1133, batch loss:0.2286316305398941, Training time:124487.79576015472
batch reward last col mean 0.5455434322357178 first col mean 0.5485864877700806 all mean 0.5456737279891968
rl training, epoch4, iter0, batch803/1133, batch loss:0.31598222255706787, Training time:124515.48427152634
batch reward last col mean 0.6045211553573608 first col mean 0.5836183428764343 all mean 0.6043276190757751
rl training, epoch4, iter0, batch804/1133, batch loss:0.25999075174331665, Training time:124543.09313106537
batch reward last col mean 0.5655869841575623 first col mean 0.568699061870575 all mean 0.5657530426979065
rl training, epoch4, iter0, batch805/1133, batch loss:0.23476892709732056, Training time:124570.60181164742
batch reward last col mean 0.5605584383010864 first col mean 0.5556266903877258 all mean 0.5609143376350403
rl training, epoch4, iter0, batch806/1133, batch loss:0.21525147557258606, Training time:124597.99532580376
batch reward last col mean 0.502569317817688 first col mean 0.5061739683151245 all mean 0.503028929233551
rl training, epoch4, iter0, batch807/1133, batch loss:0.24903690814971924, Training time:124625.1534883976
batch reward last col mean 0.5430847406387329 first col mean 0.5389441251754761 all mean 0.5427089929580688
rl training, epoch4, iter0, batch808/1133, batch loss:0.3511600196361542, Training time:124652.56021261215
batch reward last col mean 0.5869011282920837 first col mean 0.609207034111023 all mean 0.5873579382896423
rl training, epoch4, iter0, batch809/1133, batch loss:0.23660358786582947, Training time:124679.9891192913
batch reward last col mean 0.5468745827674866 first col mean 0.5418895483016968 all mean 0.547101616859436
rl training, epoch4, iter0, batch810/1133, batch loss:0.22887764871120453, Training time:124707.6062605381
batch reward last col mean 0.5827980041503906 first col mean 0.5884883999824524 all mean 0.5827347040176392
rl training, epoch4, iter0, batch811/1133, batch loss:0.26604682207107544, Training time:124735.24222517014
batch reward last col mean 0.5194123983383179 first col mean 0.5023857355117798 all mean 0.5187729597091675
rl training, epoch4, iter0, batch812/1133, batch loss:0.23436014354228973, Training time:124762.39088964462
batch reward last col mean 0.5475968718528748 first col mean 0.5490231513977051 all mean 0.5466143488883972
rl training, epoch4, iter0, batch813/1133, batch loss:0.297873854637146, Training time:124789.97904491425
batch reward last col mean 0.540219783782959 first col mean 0.5245358943939209 all mean 0.5399335026741028
rl training, epoch4, iter0, batch814/1133, batch loss:0.25166454911231995, Training time:124818.21862006187
batch reward last col mean 0.49902307987213135 first col mean 0.5092112421989441 all mean 0.49954161047935486
rl training, epoch4, iter0, batch815/1133, batch loss:0.2029792219400406, Training time:124845.590736866
batch reward last col mean 0.5628320574760437 first col mean 0.537705659866333 all mean 0.562217652797699
rl training, epoch4, iter0, batch816/1133, batch loss:0.22770339250564575, Training time:124872.74818944931
batch reward last col mean 0.5590778589248657 first col mean 0.5683157444000244 all mean 0.5590564012527466
rl training, epoch4, iter0, batch817/1133, batch loss:0.23559099435806274, Training time:124899.92891573906
batch reward last col mean 0.5713756084442139 first col mean 0.5629647970199585 all mean 0.5717167854309082
rl training, epoch4, iter0, batch818/1133, batch loss:0.21588659286499023, Training time:124927.83396840096
batch reward last col mean 0.5599361658096313 first col mean 0.5903053879737854 all mean 0.5605975985527039
rl training, epoch4, iter0, batch819/1133, batch loss:0.23840567469596863, Training time:124955.08504962921
batch reward last col mean 0.5100839138031006 first col mean 0.5144062638282776 all mean 0.5104308724403381
rl training, epoch4, iter0, batch820/1133, batch loss:0.18128812313079834, Training time:124982.36839556694
batch reward last col mean 0.6060982346534729 first col mean 0.5925189256668091 all mean 0.6055305004119873
rl training, epoch4, iter0, batch821/1133, batch loss:0.19551488757133484, Training time:125009.64476203918
batch reward last col mean 0.5663257837295532 first col mean 0.5607637166976929 all mean 0.566088080406189
rl training, epoch4, iter0, batch822/1133, batch loss:0.2527194619178772, Training time:125037.14579224586
batch reward last col mean 0.6324078440666199 first col mean 0.6494681239128113 all mean 0.6326035857200623
rl training, epoch4, iter0, batch823/1133, batch loss:0.2073775827884674, Training time:125064.62448978424
batch reward last col mean 0.5450035333633423 first col mean 0.5388095378875732 all mean 0.5448204278945923
rl training, epoch4, iter0, batch824/1133, batch loss:0.1810368299484253, Training time:125092.41926026344
batch reward last col mean 0.6050862669944763 first col mean 0.5928153991699219 all mean 0.6048700213432312
rl training, epoch4, iter0, batch825/1133, batch loss:0.2422521710395813, Training time:125119.98550081253
batch reward last col mean 0.57477205991745 first col mean 0.5847768187522888 all mean 0.5749607086181641
rl training, epoch4, iter0, batch826/1133, batch loss:0.18555045127868652, Training time:125147.59894800186
batch reward last col mean 0.5889182090759277 first col mean 0.5880488157272339 all mean 0.5881443023681641
rl training, epoch4, iter0, batch827/1133, batch loss:0.16844059526920319, Training time:125174.89245152473
batch reward last col mean 0.5678229928016663 first col mean 0.5687128305435181 all mean 0.5675871968269348
rl training, epoch4, iter0, batch828/1133, batch loss:0.19933375716209412, Training time:125201.96006417274
batch reward last col mean 0.5577775239944458 first col mean 0.5716114044189453 all mean 0.5571184158325195
rl training, epoch4, iter0, batch829/1133, batch loss:0.1615583449602127, Training time:125230.25624895096
batch reward last col mean 0.5399613380432129 first col mean 0.5822274684906006 all mean 0.5390814542770386
rl training, epoch4, iter0, batch830/1133, batch loss:0.1506684124469757, Training time:125259.25483632088
batch reward last col mean 0.5377212762832642 first col mean 0.5599889755249023 all mean 0.5349422693252563
rl training, epoch4, iter0, batch831/1133, batch loss:0.17009399831295013, Training time:125287.56234169006
batch reward last col mean 0.5747178196907043 first col mean 0.6141320466995239 all mean 0.5757527947425842
rl training, epoch4, iter0, batch832/1133, batch loss:0.14379365742206573, Training time:125315.71687293053
batch reward last col mean 0.5613654255867004 first col mean 0.5749818682670593 all mean 0.5603307485580444
rl training, epoch4, iter0, batch833/1133, batch loss:0.1870308220386505, Training time:125343.32772088051
batch reward last col mean 0.5204136967658997 first col mean 0.5433104634284973 all mean 0.5213527679443359
rl training, epoch4, iter0, batch834/1133, batch loss:0.14808852970600128, Training time:125371.1249961853
batch reward last col mean 0.5799437761306763 first col mean 0.5926488041877747 all mean 0.5803041458129883
rl training, epoch4, iter0, batch835/1133, batch loss:0.1809825748205185, Training time:125398.34402990341
batch reward last col mean 0.6513989567756653 first col mean 0.6508307456970215 all mean 0.6514062881469727
rl training, epoch4, iter0, batch836/1133, batch loss:0.2071470469236374, Training time:125425.61486554146
batch reward last col mean 0.5607030987739563 first col mean 0.5733602046966553 all mean 0.560965895652771
rl training, epoch4, iter0, batch837/1133, batch loss:0.19032518565654755, Training time:125452.94306993484
batch reward last col mean 0.5683973431587219 first col mean 0.5675153732299805 all mean 0.5685808658599854
rl training, epoch4, iter0, batch838/1133, batch loss:0.13491390645503998, Training time:125480.26152038574
batch reward last col mean 0.5576870441436768 first col mean 0.5478672981262207 all mean 0.5575059056282043
rl training, epoch4, iter0, batch839/1133, batch loss:0.22330936789512634, Training time:125508.0070002079
batch reward last col mean 0.6297812461853027 first col mean 0.6277662515640259 all mean 0.6308770179748535
rl training, epoch4, iter0, batch840/1133, batch loss:0.20737433433532715, Training time:125535.84734988213
batch reward last col mean 0.6084817051887512 first col mean 0.6181615591049194 all mean 0.6090078353881836
rl training, epoch4, iter0, batch841/1133, batch loss:0.17499539256095886, Training time:125562.9952032566
batch reward last col mean 0.6085255146026611 first col mean 0.6020004749298096 all mean 0.6085347533226013
rl training, epoch4, iter0, batch842/1133, batch loss:0.1701146960258484, Training time:125590.91813230515
batch reward last col mean 0.5684269666671753 first col mean 0.5553944110870361 all mean 0.5681300163269043
rl training, epoch4, iter0, batch843/1133, batch loss:0.22110532224178314, Training time:125618.96191883087
batch reward last col mean 0.5878689885139465 first col mean 0.5746405124664307 all mean 0.5870014429092407
rl training, epoch4, iter0, batch844/1133, batch loss:0.20590195059776306, Training time:125646.73381733894
batch reward last col mean 0.5428622364997864 first col mean 0.5558549761772156 all mean 0.5441765189170837
rl training, epoch4, iter0, batch845/1133, batch loss:0.18295010924339294, Training time:125674.77453446388
batch reward last col mean 0.5655706524848938 first col mean 0.5787085294723511 all mean 0.5663198828697205
rl training, epoch4, iter0, batch846/1133, batch loss:0.19932977855205536, Training time:125702.41248869896
batch reward last col mean 0.5234313607215881 first col mean 0.5291681289672852 all mean 0.523930013179779
rl training, epoch4, iter0, batch847/1133, batch loss:0.20580703020095825, Training time:125729.84769320488
batch reward last col mean 0.5941743850708008 first col mean 0.6090463399887085 all mean 0.5953873991966248
rl training, epoch4, iter0, batch848/1133, batch loss:0.18008475005626678, Training time:125757.33134675026
batch reward last col mean 0.5942466259002686 first col mean 0.5824182033538818 all mean 0.5944266319274902
rl training, epoch4, iter0, batch849/1133, batch loss:0.19596052169799805, Training time:125784.69941592216
batch reward last col mean 0.5719059705734253 first col mean 0.5643599033355713 all mean 0.5722254514694214
rl training, epoch4, iter0, batch850/1133, batch loss:0.17880268394947052, Training time:125812.06693911552
batch reward last col mean 0.5549297332763672 first col mean 0.5582534074783325 all mean 0.5551722049713135
rl training, epoch4, iter0, batch851/1133, batch loss:0.2100517600774765, Training time:125839.33023738861
batch reward last col mean 0.5394157767295837 first col mean 0.5515142679214478 all mean 0.5394262671470642
rl training, epoch4, iter0, batch852/1133, batch loss:0.16662362217903137, Training time:125866.50460290909
batch reward last col mean 0.5981431007385254 first col mean 0.5908353924751282 all mean 0.5974140167236328
rl training, epoch4, iter0, batch853/1133, batch loss:0.20797033607959747, Training time:125893.74828004837
batch reward last col mean 0.5840233564376831 first col mean 0.5849011540412903 all mean 0.5841035842895508
rl training, epoch4, iter0, batch854/1133, batch loss:0.2692602276802063, Training time:125921.27754735947
batch reward last col mean 0.5897728800773621 first col mean 0.5907420516014099 all mean 0.5893515944480896
rl training, epoch4, iter0, batch855/1133, batch loss:0.21336109936237335, Training time:125948.52339529991
batch reward last col mean 0.6121664047241211 first col mean 0.6064460873603821 all mean 0.6120266318321228
rl training, epoch4, iter0, batch856/1133, batch loss:0.18160293996334076, Training time:125975.6232202053
batch reward last col mean 0.5760607123374939 first col mean 0.5923035740852356 all mean 0.576357901096344
rl training, epoch4, iter0, batch857/1133, batch loss:0.14488297700881958, Training time:126002.67486572266
batch reward last col mean 0.6047676205635071 first col mean 0.5955928564071655 all mean 0.6046620011329651
rl training, epoch4, iter0, batch858/1133, batch loss:0.19024191796779633, Training time:126030.1686501503
batch reward last col mean 0.520152747631073 first col mean 0.5492395758628845 all mean 0.5206173062324524
rl training, epoch4, iter0, batch859/1133, batch loss:0.16373592615127563, Training time:126057.42264986038
batch reward last col mean 0.5724731683731079 first col mean 0.601306676864624 all mean 0.5730974674224854
rl training, epoch4, iter0, batch860/1133, batch loss:0.17460596561431885, Training time:126084.92534661293
batch reward last col mean 0.5813136100769043 first col mean 0.58046954870224 all mean 0.5813509225845337
rl training, epoch4, iter0, batch861/1133, batch loss:0.20597314834594727, Training time:126112.10425281525
batch reward last col mean 0.6187148094177246 first col mean 0.6230644583702087 all mean 0.6187863349914551
rl training, epoch4, iter0, batch862/1133, batch loss:0.14608041942119598, Training time:126139.68392705917
batch reward last col mean 0.556929349899292 first col mean 0.5636858940124512 all mean 0.557114839553833
rl training, epoch4, iter0, batch863/1133, batch loss:0.16904649138450623, Training time:126166.7880616188
batch reward last col mean 0.5633137226104736 first col mean 0.5616446137428284 all mean 0.5634315013885498
rl training, epoch4, iter0, batch864/1133, batch loss:0.1724940538406372, Training time:126194.0137526989
batch reward last col mean 0.5907020568847656 first col mean 0.584959864616394 all mean 0.5904226899147034
rl training, epoch4, iter0, batch865/1133, batch loss:0.16878831386566162, Training time:126221.16145563126
batch reward last col mean 0.5988908410072327 first col mean 0.6174985766410828 all mean 0.5991803407669067
rl training, epoch4, iter0, batch866/1133, batch loss:0.1976558119058609, Training time:126248.32639670372
batch reward last col mean 0.5504698157310486 first col mean 0.5434740781784058 all mean 0.5505655407905579
rl training, epoch4, iter0, batch867/1133, batch loss:0.17085057497024536, Training time:126275.8176870346
batch reward last col mean 0.5868521928787231 first col mean 0.5795396566390991 all mean 0.586656391620636
rl training, epoch4, iter0, batch868/1133, batch loss:0.18107730150222778, Training time:126302.97637319565
batch reward last col mean 0.5790823698043823 first col mean 0.583507776260376 all mean 0.5790931582450867
rl training, epoch4, iter0, batch869/1133, batch loss:0.15621700882911682, Training time:126330.59801602364
batch reward last col mean 0.612576425075531 first col mean 0.6204817891120911 all mean 0.6127685904502869
rl training, epoch4, iter0, batch870/1133, batch loss:0.16411109268665314, Training time:126357.88097262383
batch reward last col mean 0.5490683317184448 first col mean 0.5518773198127747 all mean 0.5489012002944946
rl training, epoch4, iter0, batch871/1133, batch loss:0.1636594831943512, Training time:126385.5592751503
batch reward last col mean 0.5625487565994263 first col mean 0.5640395283699036 all mean 0.5625166893005371
rl training, epoch4, iter0, batch872/1133, batch loss:0.1430509388446808, Training time:126412.74941182137
batch reward last col mean 0.6411716938018799 first col mean 0.6379126310348511 all mean 0.6410331130027771
rl training, epoch4, iter0, batch873/1133, batch loss:0.19270694255828857, Training time:126440.70106625557
batch reward last col mean 0.5644632577896118 first col mean 0.562443733215332 all mean 0.5645923614501953
rl training, epoch4, iter0, batch874/1133, batch loss:0.18370160460472107, Training time:126468.07327532768
batch reward last col mean 0.6554607152938843 first col mean 0.6624889373779297 all mean 0.6552595496177673
rl training, epoch4, iter0, batch875/1133, batch loss:0.16969959437847137, Training time:126495.38791155815
batch reward last col mean 0.5801631212234497 first col mean 0.5734049081802368 all mean 0.5798563361167908
rl training, epoch4, iter0, batch876/1133, batch loss:0.14553311467170715, Training time:126522.90995979309
batch reward last col mean 0.5528071522712708 first col mean 0.5680807828903198 all mean 0.552941083908081
rl training, epoch4, iter0, batch877/1133, batch loss:0.16302499175071716, Training time:126550.01533055305
batch reward last col mean 0.5721178650856018 first col mean 0.5823601484298706 all mean 0.5723825097084045
rl training, epoch4, iter0, batch878/1133, batch loss:0.14924246072769165, Training time:126577.23255181313
batch reward last col mean 0.6140478253364563 first col mean 0.6223602294921875 all mean 0.6142371296882629
rl training, epoch4, iter0, batch879/1133, batch loss:0.16235040128231049, Training time:126604.99479794502
batch reward last col mean 0.624550461769104 first col mean 0.6395803689956665 all mean 0.6249852776527405
rl training, epoch4, iter0, batch880/1133, batch loss:0.20240285992622375, Training time:126632.55089497566
batch reward last col mean 0.6066430807113647 first col mean 0.6072989106178284 all mean 0.6067413687705994
rl training, epoch4, iter0, batch881/1133, batch loss:0.1766873449087143, Training time:126659.83646202087
batch reward last col mean 0.5663361549377441 first col mean 0.5723700523376465 all mean 0.5665056109428406
rl training, epoch4, iter0, batch882/1133, batch loss:0.16749970614910126, Training time:126686.87581253052
batch reward last col mean 0.56425940990448 first col mean 0.5432859659194946 all mean 0.5640112161636353
rl training, epoch4, iter0, batch883/1133, batch loss:0.1465093493461609, Training time:126714.1602730751
batch reward last col mean 0.620471179485321 first col mean 0.6153533458709717 all mean 0.6201611757278442
rl training, epoch4, iter0, batch884/1133, batch loss:0.1848306953907013, Training time:126741.33167505264
batch reward last col mean 0.5988325476646423 first col mean 0.5985432863235474 all mean 0.5987661480903625
rl training, epoch4, iter0, batch885/1133, batch loss:0.18457567691802979, Training time:126769.12327075005
batch reward last col mean 0.6191741824150085 first col mean 0.6232184767723083 all mean 0.6192892789840698
rl training, epoch4, iter0, batch886/1133, batch loss:0.18451283872127533, Training time:126796.35611605644
batch reward last col mean 0.6044306755065918 first col mean 0.610946774482727 all mean 0.6046648621559143
rl training, epoch4, iter0, batch887/1133, batch loss:0.18229366838932037, Training time:126823.71270799637
batch reward last col mean 0.5965419411659241 first col mean 0.6180406808853149 all mean 0.5970922708511353
rl training, epoch4, iter0, batch888/1133, batch loss:0.15825465321540833, Training time:126851.00879526138
batch reward last col mean 0.55931556224823 first col mean 0.5672387480735779 all mean 0.5592808723449707
rl training, epoch4, iter0, batch889/1133, batch loss:0.17860740423202515, Training time:126878.16112828255
batch reward last col mean 0.6245675683021545 first col mean 0.6215957403182983 all mean 0.624708354473114
rl training, epoch4, iter0, batch890/1133, batch loss:0.21234150230884552, Training time:126905.57130503654
batch reward last col mean 0.5980015397071838 first col mean 0.6159283518791199 all mean 0.598348081111908
rl training, epoch4, iter0, batch891/1133, batch loss:0.1986725777387619, Training time:126932.78413963318
batch reward last col mean 0.6272519826889038 first col mean 0.63200843334198 all mean 0.6272806525230408
rl training, epoch4, iter0, batch892/1133, batch loss:0.1832137554883957, Training time:126959.94095778465
batch reward last col mean 0.626447856426239 first col mean 0.6205374002456665 all mean 0.6262943148612976
rl training, epoch4, iter0, batch893/1133, batch loss:0.21804998815059662, Training time:126987.17246437073
batch reward last col mean 0.6365755200386047 first col mean 0.6192997694015503 all mean 0.6360095739364624
rl training, epoch4, iter0, batch894/1133, batch loss:0.21295882761478424, Training time:127014.68506550789
batch reward last col mean 0.6074495911598206 first col mean 0.6056046485900879 all mean 0.6069458723068237
rl training, epoch4, iter0, batch895/1133, batch loss:0.17084068059921265, Training time:127042.0793876648
batch reward last col mean 0.5695125460624695 first col mean 0.5678279399871826 all mean 0.5688667893409729
rl training, epoch4, iter0, batch896/1133, batch loss:0.157008558511734, Training time:127069.66379094124
batch reward last col mean 0.5956964492797852 first col mean 0.5904909372329712 all mean 0.5950987935066223
rl training, epoch4, iter0, batch897/1133, batch loss:0.20666398108005524, Training time:127096.85143136978
batch reward last col mean 0.6190916895866394 first col mean 0.5994499325752258 all mean 0.6189273595809937
rl training, epoch4, iter0, batch898/1133, batch loss:0.1939913034439087, Training time:127124.33448886871
batch reward last col mean 0.6040957570075989 first col mean 0.6072779297828674 all mean 0.6042563319206238
rl training, epoch4, iter0, batch899/1133, batch loss:0.19610901176929474, Training time:127152.16575598717
batch reward last col mean 0.5887761116027832 first col mean 0.5924911499023438 all mean 0.5887517333030701
rl training, epoch4, iter0, batch900/1133, batch loss:0.19323505461215973, Training time:127179.61797881126
batch reward last col mean 0.620700478553772 first col mean 0.6389702558517456 all mean 0.6211524605751038
rl training, epoch4, iter0, batch901/1133, batch loss:0.1928434818983078, Training time:127206.93454194069
batch reward last col mean 0.5851846933364868 first col mean 0.6039677858352661 all mean 0.5854454636573792
rl training, epoch4, iter0, batch902/1133, batch loss:0.1884516477584839, Training time:127234.540848732
batch reward last col mean 0.572347104549408 first col mean 0.5640814304351807 all mean 0.5722517371177673
rl training, epoch4, iter0, batch903/1133, batch loss:0.1817469745874405, Training time:127261.79195737839
batch reward last col mean 0.6213846206665039 first col mean 0.630882740020752 all mean 0.6216707825660706
rl training, epoch4, iter0, batch904/1133, batch loss:0.19926492869853973, Training time:127289.2792544365
batch reward last col mean 0.6246548295021057 first col mean 0.6111893057823181 all mean 0.6242792010307312
rl training, epoch4, iter0, batch905/1133, batch loss:0.1794220358133316, Training time:127316.6565759182
batch reward last col mean 0.5750725865364075 first col mean 0.5991202592849731 all mean 0.5753814578056335
rl training, epoch4, iter0, batch906/1133, batch loss:0.16161885857582092, Training time:127343.87825345993
batch reward last col mean 0.577471911907196 first col mean 0.566981315612793 all mean 0.5770866870880127
rl training, epoch4, iter0, batch907/1133, batch loss:0.1552668809890747, Training time:127371.18219065666
batch reward last col mean 0.6361605525016785 first col mean 0.6330785751342773 all mean 0.6363035440444946
rl training, epoch4, iter0, batch908/1133, batch loss:0.20372046530246735, Training time:127398.4129884243
batch reward last col mean 0.6093646883964539 first col mean 0.579479992389679 all mean 0.6090403199195862
rl training, epoch4, iter0, batch909/1133, batch loss:0.18499352037906647, Training time:127425.78864192963
batch reward last col mean 0.6464591026306152 first col mean 0.6503398418426514 all mean 0.6465874314308167
rl training, epoch4, iter0, batch910/1133, batch loss:0.20887361466884613, Training time:127453.3713953495
batch reward last col mean 0.6492729783058167 first col mean 0.637782871723175 all mean 0.6489771604537964
rl training, epoch4, iter0, batch911/1133, batch loss:0.16894319653511047, Training time:127480.60755991936
batch reward last col mean 0.6071575880050659 first col mean 0.6003384590148926 all mean 0.6074865460395813
rl training, epoch4, iter0, batch912/1133, batch loss:0.1803673803806305, Training time:127507.79348301888
batch reward last col mean 0.6155405044555664 first col mean 0.6154043674468994 all mean 0.6152067184448242
rl training, epoch4, iter0, batch913/1133, batch loss:0.17290373146533966, Training time:127535.40504050255
batch reward last col mean 0.6177574396133423 first col mean 0.6357226371765137 all mean 0.6183841824531555
rl training, epoch4, iter0, batch914/1133, batch loss:0.1645040214061737, Training time:127562.72622942924
batch reward last col mean 0.6131383776664734 first col mean 0.6267403364181519 all mean 0.614139199256897
rl training, epoch4, iter0, batch915/1133, batch loss:0.21604272723197937, Training time:127590.16367864609
batch reward last col mean 0.6451760530471802 first col mean 0.623511016368866 all mean 0.6446149349212646
rl training, epoch4, iter0, batch916/1133, batch loss:0.14912395179271698, Training time:127617.45889878273
batch reward last col mean 0.6284143924713135 first col mean 0.6139987707138062 all mean 0.6277079582214355
rl training, epoch4, iter0, batch917/1133, batch loss:0.18158204853534698, Training time:127644.60292291641
batch reward last col mean 0.5959494113922119 first col mean 0.6035766005516052 all mean 0.5960835218429565
rl training, epoch4, iter0, batch918/1133, batch loss:0.1569616049528122, Training time:127672.11503362656
batch reward last col mean 0.6413536071777344 first col mean 0.637985110282898 all mean 0.6406334042549133
rl training, epoch4, iter0, batch919/1133, batch loss:0.17649760842323303, Training time:127699.74063110352
batch reward last col mean 0.6352317333221436 first col mean 0.6184279918670654 all mean 0.6345357298851013
rl training, epoch4, iter0, batch920/1133, batch loss:0.18154872953891754, Training time:127727.31325292587
batch reward last col mean 0.6204128265380859 first col mean 0.6446985006332397 all mean 0.6213359832763672
rl training, epoch4, iter0, batch921/1133, batch loss:0.17076018452644348, Training time:127754.903922081
batch reward last col mean 0.5721856951713562 first col mean 0.5563086271286011 all mean 0.5708863139152527
rl training, epoch4, iter0, batch922/1133, batch loss:0.16464126110076904, Training time:127782.6526567936
batch reward last col mean 0.5945563316345215 first col mean 0.594681978225708 all mean 0.5929005742073059
rl training, epoch4, iter0, batch923/1133, batch loss:0.1342623382806778, Training time:127810.81817412376
batch reward last col mean 0.659546971321106 first col mean 0.647240161895752 all mean 0.6587685346603394
rl training, epoch4, iter0, batch924/1133, batch loss:0.15417106449604034, Training time:127838.73048353195
batch reward last col mean 0.6028814315795898 first col mean 0.6028677225112915 all mean 0.6029956936836243
rl training, epoch4, iter0, batch925/1133, batch loss:0.1592843234539032, Training time:127866.6584572792
batch reward last col mean 0.6358802914619446 first col mean 0.6308454871177673 all mean 0.6356192827224731
rl training, epoch4, iter0, batch926/1133, batch loss:0.1697903275489807, Training time:127894.3579518795
batch reward last col mean 0.5559579133987427 first col mean 0.5925393104553223 all mean 0.556793749332428
rl training, epoch4, iter0, batch927/1133, batch loss:0.16302047669887543, Training time:127921.72926449776
batch reward last col mean 0.6460536122322083 first col mean 0.630447268486023 all mean 0.6454129219055176
rl training, epoch4, iter0, batch928/1133, batch loss:0.16076742112636566, Training time:127949.42652964592
batch reward last col mean 0.5979194641113281 first col mean 0.6063674688339233 all mean 0.5978689193725586
rl training, epoch4, iter0, batch929/1133, batch loss:0.15815691649913788, Training time:127977.33760166168
batch reward last col mean 0.5882930755615234 first col mean 0.6215846538543701 all mean 0.5890158414840698
rl training, epoch4, iter0, batch930/1133, batch loss:0.17613720893859863, Training time:128004.91368365288
batch reward last col mean 0.6206821799278259 first col mean 0.612462043762207 all mean 0.6204447746276855
rl training, epoch4, iter0, batch931/1133, batch loss:0.16880208253860474, Training time:128032.46777367592
batch reward last col mean 0.5987829566001892 first col mean 0.6047581434249878 all mean 0.5987659692764282
rl training, epoch4, iter0, batch932/1133, batch loss:0.15053878724575043, Training time:128059.78179359436
batch reward last col mean 0.6101255416870117 first col mean 0.6219017505645752 all mean 0.6107325553894043
rl training, epoch4, iter0, batch933/1133, batch loss:0.20618553459644318, Training time:128087.3022992611
batch reward last col mean 0.5760907530784607 first col mean 0.5930010080337524 all mean 0.5766143798828125
rl training, epoch4, iter0, batch934/1133, batch loss:0.17852702736854553, Training time:128114.84405970573
batch reward last col mean 0.6066212058067322 first col mean 0.5942552089691162 all mean 0.6065966486930847
rl training, epoch4, iter0, batch935/1133, batch loss:0.1993798166513443, Training time:128142.23518109322
batch reward last col mean 0.6457584500312805 first col mean 0.6241210699081421 all mean 0.645591676235199
rl training, epoch4, iter0, batch936/1133, batch loss:0.2035077065229416, Training time:128169.63396930695
batch reward last col mean 0.5537819862365723 first col mean 0.552274763584137 all mean 0.5538808703422546
rl training, epoch4, iter0, batch937/1133, batch loss:0.16756892204284668, Training time:128196.8552775383
batch reward last col mean 0.633549690246582 first col mean 0.6197993755340576 all mean 0.6331384181976318
rl training, epoch4, iter0, batch938/1133, batch loss:0.19865275919437408, Training time:128224.56339073181
batch reward last col mean 0.6091966032981873 first col mean 0.6248009204864502 all mean 0.6092987060546875
rl training, epoch4, iter0, batch939/1133, batch loss:0.19997745752334595, Training time:128251.77449131012
batch reward last col mean 0.5990585684776306 first col mean 0.5976446270942688 all mean 0.5991809964179993
rl training, epoch4, iter0, batch940/1133, batch loss:0.1783009171485901, Training time:128279.05613279343
batch reward last col mean 0.6334858536720276 first col mean 0.6283719539642334 all mean 0.6335555911064148
rl training, epoch4, iter0, batch941/1133, batch loss:0.18139433860778809, Training time:128306.8300333023
batch reward last col mean 0.6433855295181274 first col mean 0.6455823183059692 all mean 0.6434905529022217
rl training, epoch4, iter0, batch942/1133, batch loss:0.17990952730178833, Training time:128334.01706266403
batch reward last col mean 0.5790790319442749 first col mean 0.5966933369636536 all mean 0.5794273018836975
rl training, epoch4, iter0, batch943/1133, batch loss:0.1595248132944107, Training time:128361.55866193771
batch reward last col mean 0.554573655128479 first col mean 0.5572800636291504 all mean 0.5543169975280762
rl training, epoch4, iter0, batch944/1133, batch loss:0.19214433431625366, Training time:128388.90900969505
batch reward last col mean 0.608110249042511 first col mean 0.6210066676139832 all mean 0.6082066893577576
rl training, epoch4, iter0, batch945/1133, batch loss:0.20851102471351624, Training time:128416.31586003304
batch reward last col mean 0.63874351978302 first col mean 0.6251917481422424 all mean 0.6383172273635864
rl training, epoch4, iter0, batch946/1133, batch loss:0.22039435803890228, Training time:128443.6090991497
batch reward last col mean 0.5747795104980469 first col mean 0.5788183212280273 all mean 0.5747464895248413
rl training, epoch4, iter0, batch947/1133, batch loss:0.13928325474262238, Training time:128470.97406578064
batch reward last col mean 0.585393488407135 first col mean 0.5917288661003113 all mean 0.5854440331459045
rl training, epoch4, iter0, batch948/1133, batch loss:0.21009209752082825, Training time:128498.24865293503
batch reward last col mean 0.5630518794059753 first col mean 0.5922768115997314 all mean 0.5634949803352356
rl training, epoch4, iter0, batch949/1133, batch loss:0.19587542116641998, Training time:128525.54764294624
batch reward last col mean 0.6676102876663208 first col mean 0.6663318872451782 all mean 0.6675856113433838
rl training, epoch4, iter0, batch950/1133, batch loss:0.13974682986736298, Training time:128553.16610646248
batch reward last col mean 0.6241946220397949 first col mean 0.6516897082328796 all mean 0.6248460412025452
rl training, epoch4, iter0, batch951/1133, batch loss:0.1875765025615692, Training time:128580.43732047081
batch reward last col mean 0.582105278968811 first col mean 0.5678934454917908 all mean 0.5819458365440369
rl training, epoch4, iter0, batch952/1133, batch loss:0.14346973598003387, Training time:128607.80984902382
batch reward last col mean 0.6063749194145203 first col mean 0.614804744720459 all mean 0.6063755750656128
rl training, epoch4, iter0, batch953/1133, batch loss:0.1504306197166443, Training time:128635.01970744133
batch reward last col mean 0.6104227304458618 first col mean 0.6253673434257507 all mean 0.6106528639793396
rl training, epoch4, iter0, batch954/1133, batch loss:0.17426759004592896, Training time:128662.28059792519
batch reward last col mean 0.5812883377075195 first col mean 0.597058892250061 all mean 0.5815278887748718
rl training, epoch4, iter0, batch955/1133, batch loss:0.14582039415836334, Training time:128689.393232584
batch reward last col mean 0.6372379064559937 first col mean 0.6284649968147278 all mean 0.6368779540061951
rl training, epoch4, iter0, batch956/1133, batch loss:0.19698144495487213, Training time:128716.60354280472
batch reward last col mean 0.6180349588394165 first col mean 0.6063905954360962 all mean 0.6179764866828918
rl training, epoch4, iter0, batch957/1133, batch loss:0.15492650866508484, Training time:128744.58244609833
batch reward last col mean 0.6122553944587708 first col mean 0.6110249757766724 all mean 0.612354576587677
rl training, epoch4, iter0, batch958/1133, batch loss:0.1586247682571411, Training time:128771.87980914116
batch reward last col mean 0.6459295749664307 first col mean 0.6451480388641357 all mean 0.6457871198654175
rl training, epoch4, iter0, batch959/1133, batch loss:0.1612105816602707, Training time:128799.373909235
batch reward last col mean 0.6262325644493103 first col mean 0.6089048385620117 all mean 0.6259669065475464
rl training, epoch4, iter0, batch960/1133, batch loss:0.14817561209201813, Training time:128826.76118326187
batch reward last col mean 0.6348367929458618 first col mean 0.654580295085907 all mean 0.6351207494735718
rl training, epoch4, iter0, batch961/1133, batch loss:0.20588114857673645, Training time:128853.9745824337
batch reward last col mean 0.5780867338180542 first col mean 0.6012125015258789 all mean 0.5786313414573669
rl training, epoch4, iter0, batch962/1133, batch loss:0.20834235846996307, Training time:128881.05219173431
batch reward last col mean 0.6180639266967773 first col mean 0.6139901876449585 all mean 0.6179953217506409
rl training, epoch4, iter0, batch963/1133, batch loss:0.14548015594482422, Training time:128908.2637822628
batch reward last col mean 0.5289055109024048 first col mean 0.5485334992408752 all mean 0.5290522575378418
rl training, epoch4, iter0, batch964/1133, batch loss:0.13474702835083008, Training time:128935.87625050545
batch reward last col mean 0.6102190613746643 first col mean 0.6164731979370117 all mean 0.6105887293815613
rl training, epoch4, iter0, batch965/1133, batch loss:0.15145230293273926, Training time:128963.0505053997
batch reward last col mean 0.6382782459259033 first col mean 0.6293622255325317 all mean 0.6381469964981079
rl training, epoch4, iter0, batch966/1133, batch loss:0.1591063290834427, Training time:128990.85174655914
batch reward last col mean 0.6309613585472107 first col mean 0.6388479471206665 all mean 0.6311051845550537
rl training, epoch4, iter0, batch967/1133, batch loss:0.18716156482696533, Training time:129017.89540839195
batch reward last col mean 0.6251276731491089 first col mean 0.6301442384719849 all mean 0.6253344416618347
rl training, epoch4, iter0, batch968/1133, batch loss:0.18917877972126007, Training time:129045.82433485985
batch reward last col mean 0.6058554649353027 first col mean 0.6210638880729675 all mean 0.6059905886650085
rl training, epoch4, iter0, batch969/1133, batch loss:0.16990159451961517, Training time:129073.35990047455
batch reward last col mean 0.6362050771713257 first col mean 0.6373391151428223 all mean 0.6362761855125427
rl training, epoch4, iter0, batch970/1133, batch loss:0.16763617098331451, Training time:129100.50463080406
batch reward last col mean 0.5874947905540466 first col mean 0.60587477684021 all mean 0.5875880718231201
rl training, epoch4, iter0, batch971/1133, batch loss:0.1522018313407898, Training time:129127.62706160545
batch reward last col mean 0.6319186687469482 first col mean 0.6294282078742981 all mean 0.6319488883018494
rl training, epoch4, iter0, batch972/1133, batch loss:0.1968933790922165, Training time:129154.9628560543
batch reward last col mean 0.610431969165802 first col mean 0.6134450435638428 all mean 0.6103670001029968
rl training, epoch4, iter0, batch973/1133, batch loss:0.15193723142147064, Training time:129182.54755449295
batch reward last col mean 0.5848774909973145 first col mean 0.5926259160041809 all mean 0.585067093372345
rl training, epoch4, iter0, batch974/1133, batch loss:0.16390550136566162, Training time:129209.79845309258
batch reward last col mean 0.6136513352394104 first col mean 0.6161770224571228 all mean 0.6136487126350403
rl training, epoch4, iter0, batch975/1133, batch loss:0.15172401070594788, Training time:129237.53280186653
batch reward last col mean 0.6245899200439453 first col mean 0.6130868196487427 all mean 0.6243601441383362
rl training, epoch4, iter0, batch976/1133, batch loss:0.1622345894575119, Training time:129264.72902321815
batch reward last col mean 0.6128392219543457 first col mean 0.6285564303398132 all mean 0.6130222082138062
rl training, epoch4, iter0, batch977/1133, batch loss:0.1406642347574234, Training time:129291.8060157299
batch reward last col mean 0.5500818490982056 first col mean 0.5531394481658936 all mean 0.5502105355262756
rl training, epoch4, iter0, batch978/1133, batch loss:0.12838047742843628, Training time:129318.7790043354
batch reward last col mean 0.5712242722511292 first col mean 0.5728915929794312 all mean 0.571323573589325
rl training, epoch4, iter0, batch979/1133, batch loss:0.175270214676857, Training time:129346.69231319427
batch reward last col mean 0.6160849928855896 first col mean 0.6171631813049316 all mean 0.6160510778427124
rl training, epoch4, iter0, batch980/1133, batch loss:0.18183179199695587, Training time:129373.77351546288
batch reward last col mean 0.6753760576248169 first col mean 0.6710590124130249 all mean 0.6752963662147522
rl training, epoch4, iter0, batch981/1133, batch loss:0.15865732729434967, Training time:129401.04897284508
batch reward last col mean 0.5897766351699829 first col mean 0.6141190528869629 all mean 0.5903573632240295
rl training, epoch4, iter0, batch982/1133, batch loss:0.15942895412445068, Training time:129428.46233129501
batch reward last col mean 0.6329275369644165 first col mean 0.6324974298477173 all mean 0.6330221891403198
rl training, epoch4, iter0, batch983/1133, batch loss:0.1394278109073639, Training time:129455.8466603756
batch reward last col mean 0.6185880303382874 first col mean 0.6209166049957275 all mean 0.6185849905014038
rl training, epoch4, iter0, batch984/1133, batch loss:0.15625621378421783, Training time:129482.9563612938
batch reward last col mean 0.6475892066955566 first col mean 0.6423022747039795 all mean 0.6473459601402283
rl training, epoch4, iter0, batch985/1133, batch loss:0.16963939368724823, Training time:129510.24210977554
batch reward last col mean 0.5813738107681274 first col mean 0.5793394446372986 all mean 0.5813922882080078
rl training, epoch4, iter0, batch986/1133, batch loss:0.13591836392879486, Training time:129537.53167748451
batch reward last col mean 0.6120092272758484 first col mean 0.6141812205314636 all mean 0.6118603944778442
rl training, epoch4, iter0, batch987/1133, batch loss:0.16657869517803192, Training time:129564.64073371887
batch reward last col mean 0.548658549785614 first col mean 0.5506664514541626 all mean 0.5488067269325256
rl training, epoch4, iter0, batch988/1133, batch loss:0.16738572716712952, Training time:129591.79012298584
batch reward last col mean 0.6257674694061279 first col mean 0.6250246167182922 all mean 0.625725269317627
rl training, epoch4, iter0, batch989/1133, batch loss:0.16421492397785187, Training time:129619.0859708786
batch reward last col mean 0.5897682309150696 first col mean 0.5940886735916138 all mean 0.5897710919380188
rl training, epoch4, iter0, batch990/1133, batch loss:0.16676922142505646, Training time:129646.52899932861
batch reward last col mean 0.6499488949775696 first col mean 0.6569719910621643 all mean 0.64996337890625
rl training, epoch4, iter0, batch991/1133, batch loss:0.1542169451713562, Training time:129673.71605658531
batch reward last col mean 0.6125690340995789 first col mean 0.6076658964157104 all mean 0.6127543449401855
rl training, epoch4, iter0, batch992/1133, batch loss:0.16521725058555603, Training time:129700.78290605545
batch reward last col mean 0.6558718681335449 first col mean 0.6541743874549866 all mean 0.6558713316917419
rl training, epoch4, iter0, batch993/1133, batch loss:0.1733987033367157, Training time:129727.94798874855
batch reward last col mean 0.6334707736968994 first col mean 0.6289622783660889 all mean 0.6332276463508606
rl training, epoch4, iter0, batch994/1133, batch loss:0.17849081754684448, Training time:129755.83437633514
batch reward last col mean 0.6075572371482849 first col mean 0.6072272658348083 all mean 0.6074432134628296
rl training, epoch4, iter0, batch995/1133, batch loss:0.16094079613685608, Training time:129783.1171784401
batch reward last col mean 0.6275766491889954 first col mean 0.6138103604316711 all mean 0.6273901462554932
rl training, epoch4, iter0, batch996/1133, batch loss:0.19186440110206604, Training time:129810.79240083694
batch reward last col mean 0.5966053009033203 first col mean 0.6293038129806519 all mean 0.5972004532814026
rl training, epoch4, iter0, batch997/1133, batch loss:0.16524063050746918, Training time:129837.97175812721
batch reward last col mean 0.6655334234237671 first col mean 0.6659122109413147 all mean 0.6654393076896667
rl training, epoch4, iter0, batch998/1133, batch loss:0.17630383372306824, Training time:129865.35753726959
batch reward last col mean 0.5761121511459351 first col mean 0.5967128276824951 all mean 0.5760381817817688
rl training, epoch4, iter0, batch999/1133, batch loss:0.16307330131530762, Training time:129892.70286846161
batch reward last col mean 0.6079966425895691 first col mean 0.6035619378089905 all mean 0.6077907085418701
rl training, epoch4, iter0, batch1000/1133, batch loss:0.13814575970172882, Training time:129919.94725966454
batch reward last col mean 0.6647939085960388 first col mean 0.6596285700798035 all mean 0.6649362444877625
rl training, epoch4, iter0, batch1001/1133, batch loss:0.1687362939119339, Training time:129947.72954177856
batch reward last col mean 0.6529138684272766 first col mean 0.6499556303024292 all mean 0.6528398394584656
rl training, epoch4, iter0, batch1002/1133, batch loss:0.19017715752124786, Training time:129974.85712742805
batch reward last col mean 0.6212595105171204 first col mean 0.6100517511367798 all mean 0.6212924718856812
rl training, epoch4, iter0, batch1003/1133, batch loss:0.15393789112567902, Training time:130002.423838377
batch reward last col mean 0.645977258682251 first col mean 0.6537402868270874 all mean 0.645924985408783
rl training, epoch4, iter0, batch1004/1133, batch loss:0.18790483474731445, Training time:130029.8692677021
batch reward last col mean 0.6701629757881165 first col mean 0.6419726014137268 all mean 0.6697027087211609
rl training, epoch4, iter0, batch1005/1133, batch loss:0.1411803662776947, Training time:130057.2603032589
batch reward last col mean 0.6066445112228394 first col mean 0.6173266172409058 all mean 0.607122540473938
rl training, epoch4, iter0, batch1006/1133, batch loss:0.1555117815732956, Training time:130084.44923710823
batch reward last col mean 0.6170225143432617 first col mean 0.6232987642288208 all mean 0.6170339584350586
rl training, epoch4, iter0, batch1007/1133, batch loss:0.15424232184886932, Training time:130111.42288589478
batch reward last col mean 0.6501074433326721 first col mean 0.6460889577865601 all mean 0.65001380443573
rl training, epoch4, iter0, batch1008/1133, batch loss:0.1774623543024063, Training time:130138.83875393867
batch reward last col mean 0.6594219207763672 first col mean 0.6592122316360474 all mean 0.6596153378486633
rl training, epoch4, iter0, batch1009/1133, batch loss:0.1849036067724228, Training time:130166.12265825272
batch reward last col mean 0.6651018261909485 first col mean 0.6627854704856873 all mean 0.6650838851928711
rl training, epoch4, iter0, batch1010/1133, batch loss:0.18520735204219818, Training time:130193.95997953415
batch reward last col mean 0.5682390332221985 first col mean 0.5797203779220581 all mean 0.5683038234710693
rl training, epoch4, iter0, batch1011/1133, batch loss:0.161847785115242, Training time:130221.3912217617
batch reward last col mean 0.6283355951309204 first col mean 0.6472116708755493 all mean 0.6287715435028076
rl training, epoch4, iter0, batch1012/1133, batch loss:0.18632544577121735, Training time:130248.65521383286
batch reward last col mean 0.6350363492965698 first col mean 0.6329430937767029 all mean 0.6347075700759888
rl training, epoch4, iter0, batch1013/1133, batch loss:0.15897032618522644, Training time:130275.96112513542
batch reward last col mean 0.6186410188674927 first col mean 0.6355782747268677 all mean 0.6187654733657837
rl training, epoch4, iter0, batch1014/1133, batch loss:0.1923232078552246, Training time:130303.56008124352
batch reward last col mean 0.6044216752052307 first col mean 0.6044097542762756 all mean 0.6043232679367065
rl training, epoch4, iter0, batch1015/1133, batch loss:0.18153148889541626, Training time:130330.93628525734
batch reward last col mean 0.6765974164009094 first col mean 0.6755033135414124 all mean 0.6769827008247375
rl training, epoch4, iter0, batch1016/1133, batch loss:0.1705225259065628, Training time:130358.61087298393
batch reward last col mean 0.628851056098938 first col mean 0.6366603970527649 all mean 0.6292695999145508
rl training, epoch4, iter0, batch1017/1133, batch loss:0.17920386791229248, Training time:130385.91187167168
batch reward last col mean 0.6126852035522461 first col mean 0.6201778650283813 all mean 0.6130040287971497
rl training, epoch4, iter0, batch1018/1133, batch loss:0.15488970279693604, Training time:130413.27011752129
batch reward last col mean 0.6420462727546692 first col mean 0.6447370648384094 all mean 0.642143189907074
rl training, epoch4, iter0, batch1019/1133, batch loss:0.18066823482513428, Training time:130440.60884594917
batch reward last col mean 0.7111058235168457 first col mean 0.706034243106842 all mean 0.7111576795578003
rl training, epoch4, iter0, batch1020/1133, batch loss:0.183214470744133, Training time:130468.16245293617
batch reward last col mean 0.6643921136856079 first col mean 0.6815602779388428 all mean 0.6647441983222961
rl training, epoch4, iter0, batch1021/1133, batch loss:0.18815630674362183, Training time:130495.91529870033
batch reward last col mean 0.6672834157943726 first col mean 0.6658957600593567 all mean 0.6672412753105164
rl training, epoch4, iter0, batch1022/1133, batch loss:0.16883441805839539, Training time:130522.94766712189
batch reward last col mean 0.6626535654067993 first col mean 0.6712982654571533 all mean 0.6629615426063538
rl training, epoch4, iter0, batch1023/1133, batch loss:0.17342466115951538, Training time:130550.13292312622
batch reward last col mean 0.7492167353630066 first col mean 0.7354388236999512 all mean 0.7488179802894592
rl training, epoch4, iter0, batch1024/1133, batch loss:0.1838786005973816, Training time:130577.52554392815
batch reward last col mean 0.6649986505508423 first col mean 0.6659155488014221 all mean 0.6649817228317261
rl training, epoch4, iter0, batch1025/1133, batch loss:0.1889977753162384, Training time:130604.80569648743
batch reward last col mean 0.735938549041748 first col mean 0.7483469843864441 all mean 0.7360644340515137
rl training, epoch4, iter0, batch1026/1133, batch loss:0.18119917809963226, Training time:130632.1342933178
batch reward last col mean 0.6490702629089355 first col mean 0.6512263417243958 all mean 0.6491656303405762
rl training, epoch4, iter0, batch1027/1133, batch loss:0.18439431488513947, Training time:130659.29181337357
batch reward last col mean 0.6276840567588806 first col mean 0.6434025168418884 all mean 0.6279270052909851
rl training, epoch4, iter0, batch1028/1133, batch loss:0.16142059862613678, Training time:130686.56223607063
batch reward last col mean 0.5809205770492554 first col mean 0.5930575728416443 all mean 0.5811364650726318
rl training, epoch4, iter0, batch1029/1133, batch loss:0.14974363148212433, Training time:130713.71259474754
batch reward last col mean 0.6551181077957153 first col mean 0.6622273325920105 all mean 0.6553796529769897
rl training, epoch4, iter0, batch1030/1133, batch loss:0.1643485575914383, Training time:130740.71805548668
batch reward last col mean 0.6843498349189758 first col mean 0.6852313876152039 all mean 0.6844969391822815
rl training, epoch4, iter0, batch1031/1133, batch loss:0.16767214238643646, Training time:130767.93636703491
batch reward last col mean 0.648931622505188 first col mean 0.6459586024284363 all mean 0.6489733457565308
rl training, epoch4, iter0, batch1032/1133, batch loss:0.16811007261276245, Training time:130794.96150255203
batch reward last col mean 0.673101544380188 first col mean 0.6571242213249207 all mean 0.6726865172386169
rl training, epoch4, iter0, batch1033/1133, batch loss:0.18621698021888733, Training time:130822.10066986084
batch reward last col mean 0.6095247864723206 first col mean 0.6088684797286987 all mean 0.6095072627067566
rl training, epoch4, iter0, batch1034/1133, batch loss:0.14191918075084686, Training time:130849.40187764168
batch reward last col mean 0.6951909065246582 first col mean 0.6852853298187256 all mean 0.6948801875114441
rl training, epoch4, iter0, batch1035/1133, batch loss:0.16550478339195251, Training time:130876.64906167984
batch reward last col mean 0.739425778388977 first col mean 0.7314965724945068 all mean 0.7391659617424011
rl training, epoch4, iter0, batch1036/1133, batch loss:0.2044888585805893, Training time:130903.86638474464
batch reward last col mean 0.6290616989135742 first col mean 0.6452063918113708 all mean 0.6296008825302124
rl training, epoch4, iter0, batch1037/1133, batch loss:0.1232522502541542, Training time:130931.16729068756
batch reward last col mean 0.6622072458267212 first col mean 0.6542593836784363 all mean 0.6620489358901978
rl training, epoch4, iter0, batch1038/1133, batch loss:0.1538500040769577, Training time:130958.64890861511
batch reward last col mean 0.6447114944458008 first col mean 0.6431246399879456 all mean 0.6447163820266724
rl training, epoch4, iter0, batch1039/1133, batch loss:0.17802289128303528, Training time:130985.79363179207
batch reward last col mean 0.6331921219825745 first col mean 0.6197781562805176 all mean 0.6329667568206787
rl training, epoch4, iter0, batch1040/1133, batch loss:0.15128110349178314, Training time:131013.42073130608
batch reward last col mean 0.6506744623184204 first col mean 0.6489888429641724 all mean 0.6506587862968445
rl training, epoch4, iter0, batch1041/1133, batch loss:0.14726853370666504, Training time:131041.11185383797
batch reward last col mean 0.6115588545799255 first col mean 0.60821133852005 all mean 0.6114091277122498
rl training, epoch4, iter0, batch1042/1133, batch loss:0.1417222023010254, Training time:131068.25992012024
batch reward last col mean 0.6683055758476257 first col mean 0.6712900400161743 all mean 0.6682831645011902
rl training, epoch4, iter0, batch1043/1133, batch loss:0.1275051385164261, Training time:131095.43854498863
batch reward last col mean 0.596810519695282 first col mean 0.5811465978622437 all mean 0.5964964032173157
rl training, epoch4, iter0, batch1044/1133, batch loss:0.12361431866884232, Training time:131122.65811800957
batch reward last col mean 0.5894888639450073 first col mean 0.6082931160926819 all mean 0.589849054813385
rl training, epoch4, iter0, batch1045/1133, batch loss:0.15407657623291016, Training time:131149.9282040596
batch reward last col mean 0.6019954681396484 first col mean 0.5956950187683105 all mean 0.6019279956817627
rl training, epoch4, iter0, batch1046/1133, batch loss:0.15143196284770966, Training time:131177.05501317978
batch reward last col mean 0.6464649438858032 first col mean 0.6413816213607788 all mean 0.6462680101394653
rl training, epoch4, iter0, batch1047/1133, batch loss:0.1028301864862442, Training time:131204.0425810814
batch reward last col mean 0.6781479120254517 first col mean 0.6921720504760742 all mean 0.678310215473175
rl training, epoch4, iter0, batch1048/1133, batch loss:0.146650031208992, Training time:131231.1180856228
batch reward last col mean 0.6287298202514648 first col mean 0.6236036419868469 all mean 0.628592312335968
rl training, epoch4, iter0, batch1049/1133, batch loss:0.16687557101249695, Training time:131258.34357714653
batch reward last col mean 0.6048707365989685 first col mean 0.6227015256881714 all mean 0.6052691340446472
rl training, epoch4, iter0, batch1050/1133, batch loss:0.13439428806304932, Training time:131285.60522675514
batch reward last col mean 0.5988233685493469 first col mean 0.6225017309188843 all mean 0.5990702509880066
rl training, epoch4, iter0, batch1051/1133, batch loss:0.1334480196237564, Training time:131312.6403837204
batch reward last col mean 0.6729201078414917 first col mean 0.6662136316299438 all mean 0.6726820468902588
rl training, epoch4, iter0, batch1052/1133, batch loss:0.1617492139339447, Training time:131339.72437286377
batch reward last col mean 0.6534825563430786 first col mean 0.6481349468231201 all mean 0.6533508896827698
rl training, epoch4, iter0, batch1053/1133, batch loss:0.16524730622768402, Training time:131366.94954395294
batch reward last col mean 0.7064423561096191 first col mean 0.6966241002082825 all mean 0.7060869932174683
rl training, epoch4, iter0, batch1054/1133, batch loss:0.172027587890625, Training time:131394.0682053566
batch reward last col mean 0.6560236215591431 first col mean 0.6564550399780273 all mean 0.6560789346694946
rl training, epoch4, iter0, batch1055/1133, batch loss:0.1482188105583191, Training time:131421.42041921616
batch reward last col mean 0.7035560607910156 first col mean 0.698567271232605 all mean 0.7033842206001282
rl training, epoch4, iter0, batch1056/1133, batch loss:0.14021511375904083, Training time:131448.87175774574
batch reward last col mean 0.6922217011451721 first col mean 0.6860820055007935 all mean 0.6920566558837891
rl training, epoch4, iter0, batch1057/1133, batch loss:0.14896218478679657, Training time:131475.89656352997
batch reward last col mean 0.7004236578941345 first col mean 0.6965724229812622 all mean 0.7004269957542419
rl training, epoch4, iter0, batch1058/1133, batch loss:0.15390022099018097, Training time:131503.12772750854
batch reward last col mean 0.6597364544868469 first col mean 0.6758288741111755 all mean 0.6601722836494446
rl training, epoch4, iter0, batch1059/1133, batch loss:0.12126382440328598, Training time:131530.39290189743
batch reward last col mean 0.6175801753997803 first col mean 0.6426805853843689 all mean 0.6181738376617432
rl training, epoch4, iter0, batch1060/1133, batch loss:0.15355177223682404, Training time:131557.5904545784
batch reward last col mean 0.6987583637237549 first col mean 0.7009809017181396 all mean 0.6989085674285889
rl training, epoch4, iter0, batch1061/1133, batch loss:0.14941850304603577, Training time:131584.75316858292
batch reward last col mean 0.648183286190033 first col mean 0.6574749946594238 all mean 0.6484703421592712
rl training, epoch4, iter0, batch1062/1133, batch loss:0.17188231647014618, Training time:131612.7849764824
batch reward last col mean 0.6780662536621094 first col mean 0.673173189163208 all mean 0.6779770255088806
rl training, epoch4, iter0, batch1063/1133, batch loss:0.14420568943023682, Training time:131640.02602744102
batch reward last col mean 0.7360156178474426 first col mean 0.7195748090744019 all mean 0.7359360456466675
rl training, epoch4, iter0, batch1064/1133, batch loss:0.1660458892583847, Training time:131667.26150226593
batch reward last col mean 0.638156533241272 first col mean 0.6571547985076904 all mean 0.6385567784309387
rl training, epoch4, iter0, batch1065/1133, batch loss:0.14688566327095032, Training time:131694.42920446396
batch reward last col mean 0.7026318311691284 first col mean 0.7070231437683105 all mean 0.7026594281196594
rl training, epoch4, iter0, batch1066/1133, batch loss:0.1559526026248932, Training time:131721.62993240356
batch reward last col mean 0.651648998260498 first col mean 0.6435595750808716 all mean 0.6515823006629944
rl training, epoch4, iter0, batch1067/1133, batch loss:0.1428859829902649, Training time:131749.02728652954
batch reward last col mean 0.6341366767883301 first col mean 0.6399466395378113 all mean 0.6342287659645081
rl training, epoch4, iter0, batch1068/1133, batch loss:0.14466510713100433, Training time:131776.31386613846
batch reward last col mean 0.7200609445571899 first col mean 0.7336918115615845 all mean 0.7200437784194946
rl training, epoch4, iter0, batch1069/1133, batch loss:0.1678117960691452, Training time:131803.5214419365
batch reward last col mean 0.6875060796737671 first col mean 0.6888384819030762 all mean 0.6876338124275208
rl training, epoch4, iter0, batch1070/1133, batch loss:0.18154993653297424, Training time:131830.83588790894
batch reward last col mean 0.671623170375824 first col mean 0.6719828248023987 all mean 0.6713988780975342
rl training, epoch4, iter0, batch1071/1133, batch loss:0.15962864458560944, Training time:131858.46870470047
batch reward last col mean 0.6159765720367432 first col mean 0.6127375364303589 all mean 0.6159800887107849
rl training, epoch4, iter0, batch1072/1133, batch loss:0.1533050835132599, Training time:131885.9155974388
batch reward last col mean 0.6281766295433044 first col mean 0.6348775029182434 all mean 0.6283688545227051
rl training, epoch4, iter0, batch1073/1133, batch loss:0.14729297161102295, Training time:131913.36268281937
batch reward last col mean 0.6778385639190674 first col mean 0.6814348101615906 all mean 0.6776090860366821
rl training, epoch4, iter0, batch1074/1133, batch loss:0.1703357696533203, Training time:131941.32440662384
batch reward last col mean 0.6978382468223572 first col mean 0.6924199461936951 all mean 0.697542130947113
rl training, epoch4, iter0, batch1075/1133, batch loss:0.16085906326770782, Training time:131968.7483458519
batch reward last col mean 0.7057125568389893 first col mean 0.70079106092453 all mean 0.7053555846214294
rl training, epoch4, iter0, batch1076/1133, batch loss:0.1789591908454895, Training time:131996.13111567497
batch reward last col mean 0.6425328254699707 first col mean 0.6408270597457886 all mean 0.6420075297355652
rl training, epoch4, iter0, batch1077/1133, batch loss:0.15333938598632812, Training time:132023.51981258392
batch reward last col mean 0.5872724652290344 first col mean 0.5854569673538208 all mean 0.5873881578445435
rl training, epoch4, iter0, batch1078/1133, batch loss:0.14089223742485046, Training time:132050.97154188156
batch reward last col mean 0.6305465698242188 first col mean 0.6294630765914917 all mean 0.6305493116378784
rl training, epoch4, iter0, batch1079/1133, batch loss:0.1494635045528412, Training time:132078.86655902863
batch reward last col mean 0.639690637588501 first col mean 0.6515401005744934 all mean 0.6392815709114075
rl training, epoch4, iter0, batch1080/1133, batch loss:0.16634880006313324, Training time:132106.783162117
batch reward last col mean 0.6753262281417847 first col mean 0.6661024689674377 all mean 0.6752956509590149
rl training, epoch4, iter0, batch1081/1133, batch loss:0.1450347602367401, Training time:132134.4359190464
batch reward last col mean 0.6899266242980957 first col mean 0.6913015246391296 all mean 0.6897086501121521
rl training, epoch4, iter0, batch1082/1133, batch loss:0.17100559175014496, Training time:132161.8319633007
batch reward last col mean 0.6628074049949646 first col mean 0.6696720719337463 all mean 0.6632240414619446
rl training, epoch4, iter0, batch1083/1133, batch loss:0.16086049377918243, Training time:132189.428835392
batch reward last col mean 0.6190164089202881 first col mean 0.6284369230270386 all mean 0.6190100908279419
rl training, epoch4, iter0, batch1084/1133, batch loss:0.17659293115139008, Training time:132216.94972229004
batch reward last col mean 0.6561900973320007 first col mean 0.6579796671867371 all mean 0.656404435634613
rl training, epoch4, iter0, batch1085/1133, batch loss:0.1444508135318756, Training time:132244.33627820015
batch reward last col mean 0.6649519205093384 first col mean 0.6646380424499512 all mean 0.6648390293121338
rl training, epoch4, iter0, batch1086/1133, batch loss:0.16079963743686676, Training time:132271.64420223236
batch reward last col mean 0.6624791026115417 first col mean 0.6622989773750305 all mean 0.6625856161117554
rl training, epoch4, iter0, batch1087/1133, batch loss:0.1534336507320404, Training time:132298.80651569366
batch reward last col mean 0.596167266368866 first col mean 0.6180112957954407 all mean 0.5966496467590332
rl training, epoch4, iter0, batch1088/1133, batch loss:0.13662691414356232, Training time:132326.04083418846
batch reward last col mean 0.588890016078949 first col mean 0.6034427881240845 all mean 0.5892543792724609
rl training, epoch4, iter0, batch1089/1133, batch loss:0.13326521217823029, Training time:132353.2288825512
batch reward last col mean 0.6737110614776611 first col mean 0.6723294258117676 all mean 0.6739646792411804
rl training, epoch4, iter0, batch1090/1133, batch loss:0.15994350612163544, Training time:132380.41539931297
batch reward last col mean 0.6555838584899902 first col mean 0.6733555793762207 all mean 0.6556521058082581
rl training, epoch4, iter0, batch1091/1133, batch loss:0.14458851516246796, Training time:132407.61609697342
batch reward last col mean 0.6744832396507263 first col mean 0.675270676612854 all mean 0.6743911504745483
rl training, epoch4, iter0, batch1092/1133, batch loss:0.1532885730266571, Training time:132434.5597527027
batch reward last col mean 0.637275218963623 first col mean 0.6466369032859802 all mean 0.63753342628479
rl training, epoch4, iter0, batch1093/1133, batch loss:0.1287800520658493, Training time:132461.86183047295
batch reward last col mean 0.6566154956817627 first col mean 0.663016140460968 all mean 0.6567955613136292
rl training, epoch4, iter0, batch1094/1133, batch loss:0.1453990787267685, Training time:132489.15893650055
batch reward last col mean 0.653696596622467 first col mean 0.6585137844085693 all mean 0.6535283923149109
rl training, epoch4, iter0, batch1095/1133, batch loss:0.14631693065166473, Training time:132516.5792658329
batch reward last col mean 0.6345508098602295 first col mean 0.637475848197937 all mean 0.6344931125640869
rl training, epoch4, iter0, batch1096/1133, batch loss:0.1479468196630478, Training time:132544.07636761665
batch reward last col mean 0.6782841682434082 first col mean 0.6889535188674927 all mean 0.678284227848053
rl training, epoch4, iter0, batch1097/1133, batch loss:0.158940851688385, Training time:132571.17045736313
batch reward last col mean 0.7213945984840393 first col mean 0.712730884552002 all mean 0.7210286259651184
rl training, epoch4, iter0, batch1098/1133, batch loss:0.18216124176979065, Training time:132598.51040697098
batch reward last col mean 0.668167233467102 first col mean 0.6841639280319214 all mean 0.6684348583221436
rl training, epoch4, iter0, batch1099/1133, batch loss:0.16175539791584015, Training time:132626.2187538147
batch reward last col mean 0.6809271574020386 first col mean 0.6787657141685486 all mean 0.6811478734016418
rl training, epoch4, iter0, batch1100/1133, batch loss:0.15750662982463837, Training time:132653.41065764427
batch reward last col mean 0.6626877784729004 first col mean 0.669429361820221 all mean 0.6630675196647644
rl training, epoch4, iter0, batch1101/1133, batch loss:0.14869318902492523, Training time:132680.60182762146
batch reward last col mean 0.7002683877944946 first col mean 0.711471438407898 all mean 0.7001931667327881
rl training, epoch4, iter0, batch1102/1133, batch loss:0.1566009819507599, Training time:132707.61607289314
batch reward last col mean 0.7153527736663818 first col mean 0.7176382541656494 all mean 0.7154877185821533
rl training, epoch4, iter0, batch1103/1133, batch loss:0.16961941123008728, Training time:132735.78521823883
batch reward last col mean 0.6882861256599426 first col mean 0.6785194873809814 all mean 0.6880642771720886
rl training, epoch4, iter0, batch1104/1133, batch loss:0.16922535002231598, Training time:132763.16523241997
batch reward last col mean 0.6760949492454529 first col mean 0.6736324429512024 all mean 0.676022469997406
rl training, epoch4, iter0, batch1105/1133, batch loss:0.16294856369495392, Training time:132790.5963613987
batch reward last col mean 0.6761128306388855 first col mean 0.6832373738288879 all mean 0.6767023205757141
rl training, epoch4, iter0, batch1106/1133, batch loss:0.1702382117509842, Training time:132818.00333690643
batch reward last col mean 0.698352038860321 first col mean 0.7006885409355164 all mean 0.6985146999359131
rl training, epoch4, iter0, batch1107/1133, batch loss:0.1579253226518631, Training time:132845.27168297768
batch reward last col mean 0.6633688807487488 first col mean 0.6774277687072754 all mean 0.6635076403617859
rl training, epoch4, iter0, batch1108/1133, batch loss:0.1857025921344757, Training time:132873.24243998528
batch reward last col mean 0.6746894717216492 first col mean 0.6690407395362854 all mean 0.6745575666427612
rl training, epoch4, iter0, batch1109/1133, batch loss:0.1456705629825592, Training time:132900.79436516762
batch reward last col mean 0.6821205615997314 first col mean 0.6780411005020142 all mean 0.6818696856498718
rl training, epoch4, iter0, batch1110/1133, batch loss:0.16678063571453094, Training time:132928.16871380806
batch reward last col mean 0.6831377744674683 first col mean 0.6687235832214355 all mean 0.6828718185424805
rl training, epoch4, iter0, batch1111/1133, batch loss:0.18879978358745575, Training time:132955.75824165344
batch reward last col mean 0.6341471672058105 first col mean 0.6629807949066162 all mean 0.6342210173606873
rl training, epoch4, iter0, batch1112/1133, batch loss:0.17579956352710724, Training time:132983.16591334343
batch reward last col mean 0.6874923706054688 first col mean 0.6826286911964417 all mean 0.6865656971931458
rl training, epoch4, iter0, batch1113/1133, batch loss:0.1525334119796753, Training time:133011.03025221825
batch reward last col mean 0.6264650821685791 first col mean 0.6361100673675537 all mean 0.6260989308357239
rl training, epoch4, iter0, batch1114/1133, batch loss:0.12676627933979034, Training time:133038.8612318039
batch reward last col mean 0.6718963384628296 first col mean 0.66020268201828 all mean 0.6715548038482666
rl training, epoch4, iter0, batch1115/1133, batch loss:0.16121098399162292, Training time:133066.2209737301
batch reward last col mean 0.6495589017868042 first col mean 0.6556870937347412 all mean 0.6496063470840454
rl training, epoch4, iter0, batch1116/1133, batch loss:0.16212822496891022, Training time:133093.84881401062
batch reward last col mean 0.6966622471809387 first col mean 0.7004885077476501 all mean 0.6968082189559937
rl training, epoch4, iter0, batch1117/1133, batch loss:0.16180500388145447, Training time:133121.10169243813
batch reward last col mean 0.6430068612098694 first col mean 0.6566300988197327 all mean 0.6428836584091187
rl training, epoch4, iter0, batch1118/1133, batch loss:0.1574752777814865, Training time:133148.46539759636
batch reward last col mean 0.6915857791900635 first col mean 0.6993537545204163 all mean 0.6915064454078674
rl training, epoch4, iter0, batch1119/1133, batch loss:0.18012097477912903, Training time:133175.90475964546
batch reward last col mean 0.7328082919120789 first col mean 0.7303076386451721 all mean 0.7330000400543213
rl training, epoch4, iter0, batch1120/1133, batch loss:0.1618802696466446, Training time:133203.53232574463
batch reward last col mean 0.695235550403595 first col mean 0.6870067715644836 all mean 0.6950736045837402
rl training, epoch4, iter0, batch1121/1133, batch loss:0.16704866290092468, Training time:133231.0916273594
batch reward last col mean 0.6359449028968811 first col mean 0.6252790689468384 all mean 0.6354695558547974
rl training, epoch4, iter0, batch1122/1133, batch loss:0.16140058636665344, Training time:133258.54560732841
batch reward last col mean 0.6892887949943542 first col mean 0.6941359043121338 all mean 0.6893452405929565
rl training, epoch4, iter0, batch1123/1133, batch loss:0.17159366607666016, Training time:133286.03776478767
batch reward last col mean 0.647423505783081 first col mean 0.652084231376648 all mean 0.6471099257469177
rl training, epoch4, iter0, batch1124/1133, batch loss:0.1625487357378006, Training time:133313.66554141045
batch reward last col mean 0.6891297101974487 first col mean 0.6683550477027893 all mean 0.688359260559082
rl training, epoch4, iter0, batch1125/1133, batch loss:0.170070618391037, Training time:133341.1618127823
batch reward last col mean 0.6665289402008057 first col mean 0.6728568077087402 all mean 0.667025089263916
rl training, epoch4, iter0, batch1126/1133, batch loss:0.17672587931156158, Training time:133368.64582252502
batch reward last col mean 0.6473444700241089 first col mean 0.6768041253089905 all mean 0.648032546043396
rl training, epoch4, iter0, batch1127/1133, batch loss:0.15625670552253723, Training time:133396.43741226196
batch reward last col mean 0.6929404735565186 first col mean 0.6931432485580444 all mean 0.6925747990608215
rl training, epoch4, iter0, batch1128/1133, batch loss:0.16242195665836334, Training time:133423.86526370049
batch reward last col mean 0.6509366035461426 first col mean 0.6694667339324951 all mean 0.6516636610031128
rl training, epoch4, iter0, batch1129/1133, batch loss:0.1798686534166336, Training time:133451.23897767067
batch reward last col mean 0.6776784658432007 first col mean 0.6699938774108887 all mean 0.6772651076316833
rl training, epoch4, iter0, batch1130/1133, batch loss:0.15671195089817047, Training time:133479.16838622093
batch reward last col mean 0.6889427304267883 first col mean 0.6972328424453735 all mean 0.6889973878860474
rl training, epoch4, iter0, batch1131/1133, batch loss:0.1545019894838333, Training time:133506.61141228676
batch reward last col mean 0.6459053158760071 first col mean 0.6388255953788757 all mean 0.6453676223754883
rl training, epoch4, iter0, batch1132/1133, batch loss:0.1292029768228531, Training time:133531.732806921
rl training, epoch 4, iter 0, loss:0.10500870829953711, Training time:133531.73312711716 
rl epoch 4, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.2813757286790926 Time: 175.3068187236786 s
cur_epoch: 1
D Training Loss: 0.2663346196196822 Time: 175.8249204158783 s
cur_epoch: 2
D Training Loss: 0.25796997560959206 Time: 172.2423791885376 s
cur_epoch: 3
D Training Loss: 0.25446945386104425 Time: 166.3594012260437 s
cur_epoch: 4
D Training Loss: 0.2571042763021596 Time: 166.93719482421875 s
rl epoch 5, begin RL for generator...
batch reward last col mean 1.2956846148881596e-05 first col mean 0.001203724998049438 all mean 2.5289014956797473e-05
rl training, epoch5, iter0, batch0/1133, batch loss:2.3265307390829548e-05, Training time:134415.74299764633
batch reward last col mean 1.7966366385735455e-06 first col mean 1.599589950274094e-06 all mean 1.8340355154577992e-06
rl training, epoch5, iter0, batch1/1133, batch loss:5.593561240857525e-07, Training time:134443.1040506363
batch reward last col mean 3.0264533052104525e-05 first col mean 3.008522071468178e-06 all mean 2.9653649107785895e-05
rl training, epoch5, iter0, batch2/1133, batch loss:2.996847797476221e-05, Training time:134470.41442370415
batch reward last col mean 1.7461499737692066e-05 first col mean 6.422019396268297e-06 all mean 1.739423350954894e-05
rl training, epoch5, iter0, batch3/1133, batch loss:6.124234460003208e-06, Training time:134497.85600733757
batch reward last col mean 4.675132004194893e-05 first col mean 4.982328391633928e-05 all mean 4.76030727440957e-05
rl training, epoch5, iter0, batch4/1133, batch loss:2.536066858738195e-05, Training time:134525.5028450489
batch reward last col mean 6.247556939342758e-06 first col mean 7.1323047450277954e-06 all mean 6.1641267166123725e-06
rl training, epoch5, iter0, batch5/1133, batch loss:1.6141033256644732e-06, Training time:134553.39085364342
batch reward last col mean 7.261701739480486e-06 first col mean 2.6612242436385714e-05 all mean 8.309816621476784e-06
rl training, epoch5, iter0, batch6/1133, batch loss:2.463042619638145e-05, Training time:134580.73727464676
batch reward last col mean 6.7457913246471435e-06 first col mean 0.00011229443043703213 all mean 7.704940799158067e-06
rl training, epoch5, iter0, batch7/1133, batch loss:3.1140720238909125e-05, Training time:134608.07265090942
batch reward last col mean 3.842515070573427e-06 first col mean 5.329922714736313e-06 all mean 3.889937943313271e-06
rl training, epoch5, iter0, batch8/1133, batch loss:6.235307523638767e-07, Training time:134635.40537452698
batch reward last col mean 3.915488196071237e-05 first col mean 2.1407762687886134e-05 all mean 3.8764072087360546e-05
rl training, epoch5, iter0, batch9/1133, batch loss:6.2194412748795e-05, Training time:134663.3372988701
batch reward last col mean 9.050096423379728e-07 first col mean 6.042171662556939e-06 all mean 9.76811975306191e-07
rl training, epoch5, iter0, batch10/1133, batch loss:3.016413756995462e-06, Training time:134690.50554966927
batch reward last col mean 5.66399603485479e-06 first col mean 5.376030458137393e-06 all mean 5.675128250004491e-06
rl training, epoch5, iter0, batch11/1133, batch loss:7.053825470393349e-07, Training time:134717.83245038986
batch reward last col mean 4.368742338556331e-06 first col mean 7.42636848372058e-06 all mean 5.003195383324055e-06
rl training, epoch5, iter0, batch12/1133, batch loss:2.0693541955552064e-06, Training time:134745.53028821945
batch reward last col mean 6.633150042034686e-05 first col mean 6.69740402372554e-05 all mean 6.634950841544196e-05
rl training, epoch5, iter0, batch13/1133, batch loss:9.721021342556924e-05, Training time:134772.823097229
batch reward last col mean 2.5422368707950227e-06 first col mean 1.917605914059095e-05 all mean 1.2493635949795134e-05
rl training, epoch5, iter0, batch14/1133, batch loss:0.00045413413317874074, Training time:134800.0097527504
batch reward last col mean 4.13560837841942e-06 first col mean 0.0006452861125580966 all mean 1.0671217751223594e-05
rl training, epoch5, iter0, batch15/1133, batch loss:4.911677933705505e-06, Training time:134827.09837508202
batch reward last col mean 8.952456482802518e-06 first col mean 1.950203295564279e-05 all mean 9.071064596355427e-06
rl training, epoch5, iter0, batch16/1133, batch loss:7.647596476090257e-07, Training time:134854.39765572548
batch reward last col mean 8.092739335552324e-06 first col mean 6.228795882634586e-06 all mean 8.072442142292857e-06
rl training, epoch5, iter0, batch17/1133, batch loss:1.982292815227993e-06, Training time:134881.6759366989
batch reward last col mean 1.6060018879215932e-06 first col mean 2.1706491679651663e-06 all mean 1.6156002402567538e-06
rl training, epoch5, iter0, batch18/1133, batch loss:2.4910929141697125e-07, Training time:134908.75429081917
batch reward last col mean 1.1522490240167826e-05 first col mean 2.7171534384251572e-05 all mean 1.192458876175806e-05
rl training, epoch5, iter0, batch19/1133, batch loss:1.937667366291862e-05, Training time:134936.73744654655
batch reward last col mean 5.571116616920335e-06 first col mean 0.00010756287520052865 all mean 6.608207058889093e-06
rl training, epoch5, iter0, batch20/1133, batch loss:3.434288828429999e-06, Training time:134963.7103278637
batch reward last col mean 2.994934402522631e-05 first col mean 0.0005259879399091005 all mean 3.508327790768817e-05
rl training, epoch5, iter0, batch21/1133, batch loss:4.566460847854614e-05, Training time:134990.7400574684
batch reward last col mean 8.1588514149189e-06 first col mean 1.2879936548415571e-05 all mean 8.168161912180949e-06
rl training, epoch5, iter0, batch22/1133, batch loss:5.949195383436745e-06, Training time:135018.51210308075
batch reward last col mean 5.2739887905772775e-06 first col mean 0.000139457595651038 all mean 8.168842214217875e-06
rl training, epoch5, iter0, batch23/1133, batch loss:6.656142068095505e-05, Training time:135045.8384628296
batch reward last col mean 9.910709195537493e-06 first col mean 4.6691282477695495e-05 all mean 1.1950129191973247e-05
rl training, epoch5, iter0, batch24/1133, batch loss:1.4832520719210152e-05, Training time:135073.15279269218
batch reward last col mean 0.0001474632736062631 first col mean 2.7965522804151988e-06 all mean 0.00014437944628298283
rl training, epoch5, iter0, batch25/1133, batch loss:0.00024283422681037337, Training time:135100.41711974144
batch reward last col mean 8.695551514392719e-06 first col mean 1.4623659808421507e-05 all mean 8.761431672610343e-06
rl training, epoch5, iter0, batch26/1133, batch loss:2.791434326354647e-06, Training time:135127.7565433979
batch reward last col mean 8.958248145063408e-06 first col mean 1.0373578334110789e-05 all mean 1.7514528735773638e-05
rl training, epoch5, iter0, batch27/1133, batch loss:0.00026385526871308684, Training time:135155.00359988213
batch reward last col mean 1.3397767361311708e-05 first col mean 9.007876360556111e-05 all mean 1.404971226293128e-05
rl training, epoch5, iter0, batch28/1133, batch loss:1.717054510663729e-05, Training time:135182.1665391922
batch reward last col mean 1.7016111087286845e-05 first col mean 1.3970935469842516e-05 all mean 1.8083521354128607e-05
rl training, epoch5, iter0, batch29/1133, batch loss:5.849981607752852e-05, Training time:135209.82898831367
batch reward last col mean 2.612708613014547e-06 first col mean 4.013566649518907e-05 all mean 3.001553977810545e-06
rl training, epoch5, iter0, batch30/1133, batch loss:1.7324226746495697e-06, Training time:135237.0135064125
batch reward last col mean 8.971574061433785e-06 first col mean 2.545310780988075e-05 all mean 9.492331628280226e-06
rl training, epoch5, iter0, batch31/1133, batch loss:6.083169409976108e-06, Training time:135264.88149738312
batch reward last col mean 1.201767645397922e-05 first col mean 2.5147107862721896e-06 all mean 1.4917227417754475e-05
rl training, epoch5, iter0, batch32/1133, batch loss:0.00012581404007505625, Training time:135292.7659585476
batch reward last col mean 0.00011565608292585239 first col mean 3.0366350074473303e-06 all mean 0.00011362846271367744
rl training, epoch5, iter0, batch33/1133, batch loss:3.422278314246796e-05, Training time:135320.02632927895
batch reward last col mean 4.735569291369757e-06 first col mean 6.597025276278146e-06 all mean 5.010481800127309e-06
rl training, epoch5, iter0, batch34/1133, batch loss:1.8632936189533211e-06, Training time:135347.36912965775
batch reward last col mean 0.00023502505791839212 first col mean 7.352915417868644e-06 all mean 0.00023042467364575714
rl training, epoch5, iter0, batch35/1133, batch loss:0.00034418466384522617, Training time:135374.69998168945
batch reward last col mean 2.9961654490762157e-06 first col mean 2.109929027938051e-06 all mean 2.9895102215959923e-06
rl training, epoch5, iter0, batch36/1133, batch loss:7.769153853587341e-07, Training time:135401.8650174141
batch reward last col mean 5.133843842486385e-06 first col mean 4.34627800132148e-05 all mean 2.5304461814812385e-05
rl training, epoch5, iter0, batch37/1133, batch loss:1.263865124201402e-05, Training time:135429.29095220566
batch reward last col mean 1.114429505832959e-05 first col mean 1.120617253036471e-05 all mean 2.3891589080449194e-05
rl training, epoch5, iter0, batch38/1133, batch loss:5.556830274144886e-06, Training time:135457.0453569889
batch reward last col mean 1.7432845197618008e-05 first col mean 8.317520951095503e-06 all mean 1.7469374142820016e-05
rl training, epoch5, iter0, batch39/1133, batch loss:9.78304524323903e-06, Training time:135484.51555132866
batch reward last col mean 2.839783519448247e-06 first col mean 2.460349969624076e-05 all mean 3.0562985102733364e-06
rl training, epoch5, iter0, batch40/1133, batch loss:1.0405341299701831e-06, Training time:135511.70025229454
batch reward last col mean 2.364892679906916e-06 first col mean 2.5588888092897832e-05 all mean 2.6009188331954647e-06
rl training, epoch5, iter0, batch41/1133, batch loss:2.2285869363258826e-06, Training time:135539.4160001278
batch reward last col mean 5.416765998234041e-05 first col mean 4.227193494443782e-05 all mean 5.4240896133705974e-05
rl training, epoch5, iter0, batch42/1133, batch loss:4.1373528802068904e-05, Training time:135566.8344154358
batch reward last col mean 3.7485233406187035e-06 first col mean 3.12088832288282e-06 all mean 4.01393754145829e-06
rl training, epoch5, iter0, batch43/1133, batch loss:1.5711771084170323e-06, Training time:135594.5644443035
batch reward last col mean 0.00020417163614183664 first col mean 0.00020233483519405127 all mean 0.0002032909105764702
rl training, epoch5, iter0, batch44/1133, batch loss:0.0001706455077510327, Training time:135621.89041161537
batch reward last col mean 1.2419257018336793e-06 first col mean 8.387288289668504e-06 all mean 1.4261568139772862e-06
rl training, epoch5, iter0, batch45/1133, batch loss:2.850402552212472e-06, Training time:135649.16212940216
batch reward last col mean 7.594965609314386e-06 first col mean 5.739021617046092e-06 all mean 7.558280231023673e-06
rl training, epoch5, iter0, batch46/1133, batch loss:1.9944704945373815e-06, Training time:135676.74621415138
batch reward last col mean 8.317578249261715e-06 first col mean 0.00023509759921580553 all mean 1.060828708432382e-05
rl training, epoch5, iter0, batch47/1133, batch loss:2.9496554816432763e-06, Training time:135704.05995988846
batch reward last col mean 3.853487578453496e-05 first col mean 5.444871203508228e-05 all mean 3.8492933526868e-05
rl training, epoch5, iter0, batch48/1133, batch loss:2.1847505195182748e-05, Training time:135731.37460756302
batch reward last col mean 8.262725714303087e-06 first col mean 3.6188143894833047e-06 all mean 8.102113497443497e-06
rl training, epoch5, iter0, batch49/1133, batch loss:3.1978304377844324e-06, Training time:135758.92618894577
batch reward last col mean 0.00012112802505725995 first col mean 0.00013171420141588897 all mean 0.00012130374670960009
rl training, epoch5, iter0, batch50/1133, batch loss:0.0001237722026417032, Training time:135786.17210888863
batch reward last col mean 7.574372375529492e-06 first col mean 6.817808753112331e-06 all mean 1.2223571502545383e-05
rl training, epoch5, iter0, batch51/1133, batch loss:7.423901843139902e-05, Training time:135813.40843200684
batch reward last col mean 1.1591444490477443e-05 first col mean 6.003264843457146e-06 all mean 1.709635580482427e-05
rl training, epoch5, iter0, batch52/1133, batch loss:0.0008417833014391363, Training time:135840.88534545898
batch reward last col mean 7.214120705612004e-05 first col mean 0.00039562105666846037 all mean 0.00010768875654321164
rl training, epoch5, iter0, batch53/1133, batch loss:0.0001598127855686471, Training time:135868.25680541992
batch reward last col mean 8.793080269242637e-06 first col mean 7.415749223582679e-06 all mean 8.776652975939214e-06
rl training, epoch5, iter0, batch54/1133, batch loss:2.7240650979365455e-06, Training time:135895.45484137535
batch reward last col mean 4.2195688365609385e-06 first col mean 2.814023218888906e-06 all mean 4.302231445763027e-06
rl training, epoch5, iter0, batch55/1133, batch loss:1.439233642486215e-06, Training time:135922.65029597282
batch reward last col mean 5.9913213590334635e-06 first col mean 7.845546861062758e-06 all mean 6.025876245985273e-06
rl training, epoch5, iter0, batch56/1133, batch loss:2.013674020417966e-06, Training time:135949.95058751106
batch reward last col mean 2.1925643522990867e-06 first col mean 3.838430347968824e-05 all mean 2.5828946945694042e-06
rl training, epoch5, iter0, batch57/1133, batch loss:1.2436179304131656e-06, Training time:135977.23260116577
batch reward last col mean 8.500745934725273e-06 first col mean 1.0481576282472815e-05 all mean 8.502562195644714e-06
rl training, epoch5, iter0, batch58/1133, batch loss:6.681379090878181e-06, Training time:136005.1639971733
batch reward last col mean 9.853005167315132e-07 first col mean 4.278505002730526e-06 all mean 1.0498062010810827e-06
rl training, epoch5, iter0, batch59/1133, batch loss:1.3343649243324762e-06, Training time:136032.23145270348
batch reward last col mean 4.177859955234453e-05 first col mean 4.5934899389976636e-05 all mean 4.178255039732903e-05
rl training, epoch5, iter0, batch60/1133, batch loss:3.144736183458008e-05, Training time:136059.37964224815
batch reward last col mean 4.648035883292323e-06 first col mean 4.02540808863705e-06 all mean 4.63403466710588e-06
rl training, epoch5, iter0, batch61/1133, batch loss:1.3514226111510652e-06, Training time:136086.60653829575
batch reward last col mean 4.1412931750528514e-05 first col mean 7.129122968763113e-05 all mean 4.1704402974573895e-05
rl training, epoch5, iter0, batch62/1133, batch loss:4.1695395339047536e-05, Training time:136113.8597187996
batch reward last col mean 2.1043151718913577e-05 first col mean 5.8884966165351216e-06 all mean 2.010122625506483e-05
rl training, epoch5, iter0, batch63/1133, batch loss:7.083017408149317e-06, Training time:136141.16500878334
batch reward last col mean 3.7681415960832965e-06 first col mean 3.89034812542377e-06 all mean 3.77591004507849e-06
rl training, epoch5, iter0, batch64/1133, batch loss:1.0112179325005854e-06, Training time:136168.42124962807
batch reward last col mean 5.59632753720507e-05 first col mean 0.0001919791247928515 all mean 5.726935341954231e-05
rl training, epoch5, iter0, batch65/1133, batch loss:2.8840429877163842e-05, Training time:136196.10484170914
batch reward last col mean 4.027420800412074e-06 first col mean 4.954497853759676e-06 all mean 7.1856111389934085e-06
rl training, epoch5, iter0, batch66/1133, batch loss:2.2091107894084416e-06, Training time:136223.3570740223
batch reward last col mean 7.44804219721118e-06 first col mean 8.53294932312565e-06 all mean 7.378156169579597e-06
rl training, epoch5, iter0, batch67/1133, batch loss:4.929417173116235e-06, Training time:136251.02674865723
batch reward last col mean 0.0049834782257676125 first col mean 1.0052302059193607e-05 all mean 0.004853909835219383
rl training, epoch5, iter0, batch68/1133, batch loss:0.0022882919292896986, Training time:136278.3037698269
batch reward last col mean 4.7960702431737445e-06 first col mean 5.122480160935083e-06 all mean 4.80696917293244e-06
rl training, epoch5, iter0, batch69/1133, batch loss:1.3301076933203149e-06, Training time:136305.47008633614
batch reward last col mean 3.1032636798045132e-06 first col mean 4.472867294680327e-05 all mean 3.831909452856053e-06
rl training, epoch5, iter0, batch70/1133, batch loss:1.7807597032515332e-05, Training time:136332.62358617783
batch reward last col mean 1.6385625713155605e-05 first col mean 7.193315104814246e-05 all mean 1.704263013380114e-05
rl training, epoch5, iter0, batch71/1133, batch loss:8.023306691029575e-06, Training time:136359.83453440666
batch reward last col mean 3.141486558888573e-06 first col mean 2.597728780528996e-06 all mean 3.142951982226805e-06
rl training, epoch5, iter0, batch72/1133, batch loss:1.1278733609287883e-06, Training time:136387.10903859138
batch reward last col mean 8.099079423118383e-06 first col mean 0.00012471890659071505 all mean 1.2671727745328099e-05
rl training, epoch5, iter0, batch73/1133, batch loss:0.0003261513775214553, Training time:136415.9217016697
batch reward last col mean 1.1383293895050883e-05 first col mean 5.551993126573507e-06 all mean 1.1286468179605436e-05
rl training, epoch5, iter0, batch74/1133, batch loss:7.179200565587962e-06, Training time:136443.24124646187
batch reward last col mean 0.0009424859890714288 first col mean 1.8812474081641994e-05 all mean 0.0009512693504802883
rl training, epoch5, iter0, batch75/1133, batch loss:0.0038571723271161318, Training time:136470.50668406487
batch reward last col mean 2.7866479285876267e-05 first col mean 5.357681220630184e-05 all mean 2.800396759994328e-05
rl training, epoch5, iter0, batch76/1133, batch loss:1.304827856074553e-05, Training time:136497.6749932766
batch reward last col mean 0.006194264627993107 first col mean 0.006810574792325497 all mean 0.006203598342835903
rl training, epoch5, iter0, batch77/1133, batch loss:0.008982157334685326, Training time:136524.93347930908
batch reward last col mean 2.4906643375288695e-05 first col mean 1.8251254005008377e-05 all mean 2.4740193111938424e-05
rl training, epoch5, iter0, batch78/1133, batch loss:8.647732101962902e-06, Training time:136552.16839790344
batch reward last col mean 1.4627514246967621e-05 first col mean 1.367400363960769e-05 all mean 1.463507487642346e-05
rl training, epoch5, iter0, batch79/1133, batch loss:1.4156521501718089e-05, Training time:136580.429571867
batch reward last col mean 1.2502274330472574e-05 first col mean 1.2475782568799332e-05 all mean 1.2490970220824238e-05
rl training, epoch5, iter0, batch80/1133, batch loss:4.79478558190749e-06, Training time:136607.50033545494
batch reward last col mean 3.815146101260325e-06 first col mean 1.840321783674881e-05 all mean 4.088911737198941e-06
rl training, epoch5, iter0, batch81/1133, batch loss:5.198846793064149e-06, Training time:136635.02679085732
batch reward last col mean 3.2213567919825437e-06 first col mean 5.268802851787768e-06 all mean 3.37791698257206e-06
rl training, epoch5, iter0, batch82/1133, batch loss:1.924945308928727e-06, Training time:136662.26117157936
batch reward last col mean 1.4252291293814778e-05 first col mean 6.385195592883974e-05 all mean 1.4756213204236701e-05
rl training, epoch5, iter0, batch83/1133, batch loss:1.3011429018661147e-06, Training time:136689.9026799202
batch reward last col mean 2.921879513451131e-06 first col mean 8.013499609660357e-06 all mean 2.9761013138340786e-06
rl training, epoch5, iter0, batch84/1133, batch loss:1.1606855423451634e-06, Training time:136717.16235136986
batch reward last col mean 0.00025924784131348133 first col mean 0.0002915558288805187 all mean 0.00025843572802841663
rl training, epoch5, iter0, batch85/1133, batch loss:0.00014076216029934585, Training time:136744.31130886078
batch reward last col mean 7.129099685698748e-06 first col mean 7.5791740528075024e-06 all mean 7.337787792494055e-06
rl training, epoch5, iter0, batch86/1133, batch loss:1.1754870001823292e-06, Training time:136771.5359032154
batch reward last col mean 1.111489564209478e-05 first col mean 0.0017424063989892602 all mean 2.929767651949078e-05
rl training, epoch5, iter0, batch87/1133, batch loss:4.2801792005775496e-05, Training time:136798.91616368294
batch reward last col mean 1.525057632534299e-05 first col mean 1.2641253306355793e-05 all mean 1.5441342839039862e-05
rl training, epoch5, iter0, batch88/1133, batch loss:3.0962091841502115e-05, Training time:136826.39706921577
batch reward last col mean 0.0007603815174661577 first col mean 0.0005391070153564215 all mean 0.0007550674490630627
rl training, epoch5, iter0, batch89/1133, batch loss:0.0008540072594769299, Training time:136853.8814456463
batch reward last col mean 1.323491505900165e-05 first col mean 0.0007190275937318802 all mean 2.521532769605983e-05
rl training, epoch5, iter0, batch90/1133, batch loss:0.0001387766096740961, Training time:136880.8694922924
batch reward last col mean 0.0009450588840991259 first col mean 0.00046617508633062243 all mean 0.0009334380738437176
rl training, epoch5, iter0, batch91/1133, batch loss:0.00047927701962180436, Training time:136908.49746751785
batch reward last col mean 6.586898052773904e-06 first col mean 2.8773959002137417e-06 all mean 7.547585937572876e-06
rl training, epoch5, iter0, batch92/1133, batch loss:5.099363988847472e-05, Training time:136936.1016151905
batch reward last col mean 7.161936082411557e-05 first col mean 7.919667041278444e-06 all mean 7.097530033206567e-05
rl training, epoch5, iter0, batch93/1133, batch loss:5.780239007435739e-05, Training time:136963.2992284298
batch reward last col mean 4.080665348737966e-06 first col mean 3.235900294384919e-05 all mean 4.39419136455399e-06
rl training, epoch5, iter0, batch94/1133, batch loss:2.2405918116419343e-06, Training time:136990.45900058746
batch reward last col mean 1.3493062397174072e-05 first col mean 9.963538104784675e-06 all mean 1.358958616037853e-05
rl training, epoch5, iter0, batch95/1133, batch loss:2.1092811948619783e-05, Training time:137017.69089603424
batch reward last col mean 1.0901904715865385e-05 first col mean 1.1516888662299607e-05 all mean 1.1088241990364622e-05
rl training, epoch5, iter0, batch96/1133, batch loss:9.387255886394996e-06, Training time:137045.01626110077
batch reward last col mean 0.0018300783121958375 first col mean 3.166036094626179e-06 all mean 0.001788381952792406
rl training, epoch5, iter0, batch97/1133, batch loss:0.0023628550115972757, Training time:137072.23740649223
batch reward last col mean 3.699805529322475e-05 first col mean 2.354898606427014e-05 all mean 3.858761192532256e-05
rl training, epoch5, iter0, batch98/1133, batch loss:6.129670509835705e-05, Training time:137099.5397322178
batch reward last col mean 1.4059489330975339e-05 first col mean 6.982952527323505e-06 all mean 1.3974295143270865e-05
rl training, epoch5, iter0, batch99/1133, batch loss:4.832407284993678e-06, Training time:137127.02887797356
batch reward last col mean 1.5246745533659123e-05 first col mean 3.264381302869879e-05 all mean 1.5598345271428116e-05
rl training, epoch5, iter0, batch100/1133, batch loss:2.760087954811752e-05, Training time:137154.26195025444
batch reward last col mean 4.375854587124195e-06 first col mean 4.924957011098741e-06 all mean 4.393373274069745e-06
rl training, epoch5, iter0, batch101/1133, batch loss:9.65628828453191e-07, Training time:137181.81933569908
batch reward last col mean 0.007307023741304874 first col mean 0.005804525688290596 all mean 0.007272379472851753
rl training, epoch5, iter0, batch102/1133, batch loss:0.024641631171107292, Training time:137209.15233635902
batch reward last col mean 6.837623004685156e-06 first col mean 2.876211510738358e-06 all mean 6.787412075937027e-06
rl training, epoch5, iter0, batch103/1133, batch loss:3.5280161228001816e-06, Training time:137236.5241370201
batch reward last col mean 7.648376049473882e-05 first col mean 5.5286647693719715e-05 all mean 7.590913446620107e-05
rl training, epoch5, iter0, batch104/1133, batch loss:0.00012948329094797373, Training time:137263.8562719822
batch reward last col mean 2.0909152226522565e-05 first col mean 4.2769970605149865e-06 all mean 2.0750372641487047e-05
rl training, epoch5, iter0, batch105/1133, batch loss:1.8769938833429478e-05, Training time:137290.996250391
batch reward last col mean 7.501872460125014e-06 first col mean 7.470871423720382e-06 all mean 7.496646958315978e-06
rl training, epoch5, iter0, batch106/1133, batch loss:4.076075128978118e-06, Training time:137318.28841137886
batch reward last col mean 6.763954843336251e-06 first col mean 1.1461862413852941e-05 all mean 7.118675966921728e-06
rl training, epoch5, iter0, batch107/1133, batch loss:6.248744739423273e-06, Training time:137345.60067129135
batch reward last col mean 8.60607615322806e-05 first col mean 3.62445498467423e-05 all mean 8.464897837257013e-05
rl training, epoch5, iter0, batch108/1133, batch loss:0.0001387071533827111, Training time:137372.88656067848
batch reward last col mean 2.465182842570357e-05 first col mean 2.3628337658010423e-05 all mean 2.4665185264893807e-05
rl training, epoch5, iter0, batch109/1133, batch loss:1.698633968771901e-05, Training time:137400.97866225243
batch reward last col mean 3.9481647036154754e-06 first col mean 9.349110769107938e-06 all mean 4.913717475574231e-06
rl training, epoch5, iter0, batch110/1133, batch loss:1.7626522094360553e-05, Training time:137428.18266510963
batch reward last col mean 5.775953468400985e-05 first col mean 7.034267127892235e-06 all mean 5.647911530104466e-05
rl training, epoch5, iter0, batch111/1133, batch loss:6.209144339663908e-05, Training time:137456.1476700306
batch reward last col mean 8.640431769890711e-05 first col mean 4.262507900421042e-06 all mean 8.581236033933237e-05
rl training, epoch5, iter0, batch112/1133, batch loss:0.00010404980275779963, Training time:137483.62957024574
batch reward last col mean 0.00042803146061487496 first col mean 0.0007627462036907673 all mean 0.00043268041918054223
rl training, epoch5, iter0, batch113/1133, batch loss:0.0006077471771277487, Training time:137511.0143043995
batch reward last col mean 2.5053563149413094e-05 first col mean 0.00019924009393434972 all mean 2.6997011445928365e-05
rl training, epoch5, iter0, batch114/1133, batch loss:8.015752246137708e-05, Training time:137538.30080509186
batch reward last col mean 8.398588397540152e-05 first col mean 0.00012032812082907185 all mean 8.414317562710494e-05
rl training, epoch5, iter0, batch115/1133, batch loss:5.7382607337785885e-05, Training time:137565.52012634277
batch reward last col mean 5.565922037931159e-06 first col mean 6.0560381825780496e-05 all mean 6.178331204864662e-06
rl training, epoch5, iter0, batch116/1133, batch loss:7.543499123130459e-06, Training time:137592.80762958527
batch reward last col mean 2.258831045764964e-05 first col mean 9.509874871582724e-06 all mean 2.2424215785576962e-05
rl training, epoch5, iter0, batch117/1133, batch loss:7.267001365107717e-06, Training time:137620.7560055256
batch reward last col mean 0.0023978473618626595 first col mean 0.00012743857223540545 all mean 0.0023445237893611193
rl training, epoch5, iter0, batch118/1133, batch loss:0.01065211184322834, Training time:137648.00392246246
batch reward last col mean 1.377155331283575e-05 first col mean 6.668332207482308e-05 all mean 1.429931307939114e-05
rl training, epoch5, iter0, batch119/1133, batch loss:9.835146556724794e-06, Training time:137675.21508336067
batch reward last col mean 3.833646587736439e-06 first col mean 1.4044916497368831e-05 all mean 7.71587474446278e-06
rl training, epoch5, iter0, batch120/1133, batch loss:4.555190116661834e-06, Training time:137702.423101902
batch reward last col mean 0.0003429771459195763 first col mean 3.1325555028161034e-05 all mean 0.00033951603109017015
rl training, epoch5, iter0, batch121/1133, batch loss:0.0003428984200581908, Training time:137729.5856540203
batch reward last col mean 3.6533247111947276e-06 first col mean 3.423235466470942e-05 all mean 3.9476840356655885e-06
rl training, epoch5, iter0, batch122/1133, batch loss:2.0454449440876488e-06, Training time:137756.96758580208
batch reward last col mean 3.8209595913940575e-06 first col mean 6.5844933487824164e-06 all mean 3.884674697474111e-06
rl training, epoch5, iter0, batch123/1133, batch loss:2.6149157292820746e-06, Training time:137784.27322888374
batch reward last col mean 1.3348739230423234e-05 first col mean 0.00014533910143654794 all mean 1.4464253581536468e-05
rl training, epoch5, iter0, batch124/1133, batch loss:1.1836291378131136e-05, Training time:137811.53079080582
batch reward last col mean 0.0005756263271905482 first col mean 0.0007053692825138569 all mean 0.0005775538156740367
rl training, epoch5, iter0, batch125/1133, batch loss:0.00037598583730868995, Training time:137838.96195173264
batch reward last col mean 8.578758752264548e-06 first col mean 6.315061455097748e-06 all mean 8.557689398003276e-06
rl training, epoch5, iter0, batch126/1133, batch loss:9.825424967857543e-06, Training time:137866.3493180275
batch reward last col mean 3.2016600016504526e-05 first col mean 3.7854283618798945e-06 all mean 3.127207310171798e-05
rl training, epoch5, iter0, batch127/1133, batch loss:3.704791743075475e-05, Training time:137893.6463148594
batch reward last col mean 1.8169368559028953e-05 first col mean 2.1185664081713185e-05 all mean 1.8233226001029834e-05
rl training, epoch5, iter0, batch128/1133, batch loss:1.5785077266627923e-05, Training time:137921.01396632195
batch reward last col mean 1.4789639863010962e-05 first col mean 9.810365554585587e-06 all mean 1.4710548384755384e-05
rl training, epoch5, iter0, batch129/1133, batch loss:9.236123332811985e-06, Training time:137948.22396326065
batch reward last col mean 2.3806554963812232e-05 first col mean 6.973073323024437e-05 all mean 2.419283555354923e-05
rl training, epoch5, iter0, batch130/1133, batch loss:4.7156477194221225e-06, Training time:137975.46631669998
batch reward last col mean 0.0027973453979939222 first col mean 1.888789665827062e-05 all mean 0.002741224132478237
rl training, epoch5, iter0, batch131/1133, batch loss:0.002226821379736066, Training time:138002.8209886551
batch reward last col mean 4.989672561350744e-06 first col mean 0.00017245039634872228 all mean 7.419190751534188e-06
rl training, epoch5, iter0, batch132/1133, batch loss:0.0001157429869635962, Training time:138030.14119791985
batch reward last col mean 9.412068175151944e-05 first col mean 1.3658565876539797e-05 all mean 9.246262925444171e-05
rl training, epoch5, iter0, batch133/1133, batch loss:0.00014370465942192823, Training time:138057.49224734306
batch reward last col mean 0.000836857536341995 first col mean 0.0008645444177091122 all mean 0.0008371713338419795
rl training, epoch5, iter0, batch134/1133, batch loss:0.0006744978600181639, Training time:138084.68477654457
batch reward last col mean 8.429311856161803e-05 first col mean 9.908523497870192e-05 all mean 8.473946218146011e-05
rl training, epoch5, iter0, batch135/1133, batch loss:0.0001278373965760693, Training time:138111.9467101097
batch reward last col mean 1.5544223970209714e-06 first col mean 2.485307504684897e-06 all mean 1.5688875691921567e-06
rl training, epoch5, iter0, batch136/1133, batch loss:5.323848313310009e-07, Training time:138139.29803299904
batch reward last col mean 1.2025618161715101e-05 first col mean 0.0003542154736351222 all mean 1.72805339389015e-05
rl training, epoch5, iter0, batch137/1133, batch loss:1.2848347068938892e-05, Training time:138167.50243711472
batch reward last col mean 0.00010597051732474938 first col mean 0.0015647258842363954 all mean 0.00015110713138710707
rl training, epoch5, iter0, batch138/1133, batch loss:0.002250457415357232, Training time:138194.83392763138
batch reward last col mean 0.00013875287550035864 first col mean 0.00010820840543601662 all mean 0.0001373242848785594
rl training, epoch5, iter0, batch139/1133, batch loss:4.014441219624132e-05, Training time:138222.14397501945
batch reward last col mean 0.00018101317982655019 first col mean 1.7894105894811219e-06 all mean 0.00017891042807605118
rl training, epoch5, iter0, batch140/1133, batch loss:0.00011657478171400726, Training time:138249.62363767624
batch reward last col mean 3.386263870197581e-06 first col mean 4.8644133130437694e-06 all mean 3.3858927963592578e-06
rl training, epoch5, iter0, batch141/1133, batch loss:6.724291665705096e-07, Training time:138276.94187283516
batch reward last col mean 5.357320787879871e-06 first col mean 2.781081093417015e-05 all mean 5.6835765462892596e-06
rl training, epoch5, iter0, batch142/1133, batch loss:2.132455847458914e-06, Training time:138304.31663441658
batch reward last col mean 2.57154260907555e-06 first col mean 0.0009603899670764804 all mean 1.2279107977519743e-05
rl training, epoch5, iter0, batch143/1133, batch loss:3.690725498017855e-05, Training time:138331.63347125053
batch reward last col mean 2.1225014279480092e-05 first col mean 3.3098972380685154e-06 all mean 3.08151647914201e-05
rl training, epoch5, iter0, batch144/1133, batch loss:8.181660086847842e-05, Training time:138358.88339304924
batch reward last col mean 0.0005769183044321835 first col mean 0.0005824575200676918 all mean 0.0005786645924672484
rl training, epoch5, iter0, batch145/1133, batch loss:0.000649638706818223, Training time:138386.09795188904
batch reward last col mean 0.0009651365107856691 first col mean 0.0032352448906749487 all mean 0.0009633137378841639
rl training, epoch5, iter0, batch146/1133, batch loss:0.0017525881994515657, Training time:138414.01070070267
batch reward last col mean 2.442747700115433e-06 first col mean 9.082528777071275e-06 all mean 2.8555825792864198e-06
rl training, epoch5, iter0, batch147/1133, batch loss:9.065402082342189e-06, Training time:138441.33294296265
batch reward last col mean 9.961244359146804e-06 first col mean 3.075963832088746e-05 all mean 1.0157204087590799e-05
rl training, epoch5, iter0, batch148/1133, batch loss:5.542952749237884e-06, Training time:138468.60504627228
batch reward last col mean 6.760066753486171e-06 first col mean 0.00014078241656534374 all mean 8.13924998510629e-06
rl training, epoch5, iter0, batch149/1133, batch loss:4.518534296948928e-06, Training time:138495.78764629364
batch reward last col mean 0.00010688648035284132 first col mean 0.0014829175779595971 all mean 0.00012094892736058682
rl training, epoch5, iter0, batch150/1133, batch loss:0.002858755411580205, Training time:138523.30728054047
batch reward last col mean 1.929518020915566e-06 first col mean 2.568214313214412e-06 all mean 1.941166374308523e-06
rl training, epoch5, iter0, batch151/1133, batch loss:9.905958222589106e-07, Training time:138550.70828294754
batch reward last col mean 3.3890353279275587e-06 first col mean 1.2777516531059518e-05 all mean 3.4996214708371554e-06
rl training, epoch5, iter0, batch152/1133, batch loss:1.1600440075199003e-06, Training time:138578.07756352425
batch reward last col mean 8.569288183934987e-06 first col mean 2.133636735379696e-05 all mean 1.1879576959472615e-05
rl training, epoch5, iter0, batch153/1133, batch loss:1.1765380804718006e-05, Training time:138605.43445658684
batch reward last col mean 2.7830927137983963e-05 first col mean 4.959175385010894e-06 all mean 2.7184360078535974e-05
rl training, epoch5, iter0, batch154/1133, batch loss:5.221219907980412e-05, Training time:138633.39873170853
batch reward last col mean 3.080832539126277e-05 first col mean 3.358502726769075e-05 all mean 3.075102358707227e-05
rl training, epoch5, iter0, batch155/1133, batch loss:1.7202602975885384e-05, Training time:138660.50083470345
batch reward last col mean 6.324698006210383e-06 first col mean 1.4328474208014086e-05 all mean 6.4056152950797696e-06
rl training, epoch5, iter0, batch156/1133, batch loss:3.5571267744671786e-06, Training time:138687.99367117882
batch reward last col mean 3.489255686872639e-05 first col mean 0.0006793489446863532 all mean 4.1727569623617455e-05
rl training, epoch5, iter0, batch157/1133, batch loss:0.00011113694199593738, Training time:138715.2967967987
batch reward last col mean 3.835725237877341e-06 first col mean 7.913135050330311e-06 all mean 3.8885891626705416e-06
rl training, epoch5, iter0, batch158/1133, batch loss:1.2528050774562871e-06, Training time:138742.68017792702
batch reward last col mean 3.9221899896801915e-06 first col mean 4.865111623075791e-05 all mean 4.362681920611067e-06
rl training, epoch5, iter0, batch159/1133, batch loss:3.336337613291107e-06, Training time:138769.90949082375
batch reward last col mean 1.4711081348650623e-05 first col mean 2.780354225251358e-05 all mean 1.6178511941689067e-05
rl training, epoch5, iter0, batch160/1133, batch loss:2.2499016267829575e-05, Training time:138797.01124715805
batch reward last col mean 0.001564654870890081 first col mean 0.00022709670884069055 all mean 0.0015511744422838092
rl training, epoch5, iter0, batch161/1133, batch loss:0.0013550324365496635, Training time:138824.28261733055
batch reward last col mean 0.0026036857161670923 first col mean 0.0007823209743946791 all mean 0.0025834531988948584
rl training, epoch5, iter0, batch162/1133, batch loss:0.002405397826805711, Training time:138851.54694104195
batch reward last col mean 0.0008472743793390691 first col mean 2.43511804001173e-05 all mean 0.0008311555138789117
rl training, epoch5, iter0, batch163/1133, batch loss:0.0008339216001331806, Training time:138879.2849354744
batch reward last col mean 0.00010083361121360213 first col mean 8.03540024207905e-05 all mean 0.0001012503489619121
rl training, epoch5, iter0, batch164/1133, batch loss:0.00010426490916870534, Training time:138906.57861614227
batch reward last col mean 0.0004659332043956965 first col mean 0.00045623426558449864 all mean 0.0004657394310925156
rl training, epoch5, iter0, batch165/1133, batch loss:0.00033459049882367253, Training time:138933.78191542625
batch reward last col mean 2.8009462766931392e-05 first col mean 3.6961224395781755e-05 all mean 2.8500020562205464e-05
rl training, epoch5, iter0, batch166/1133, batch loss:3.943570118281059e-05, Training time:138961.21635508537
batch reward last col mean 1.1972298125328962e-05 first col mean 1.3620409845316317e-05 all mean 1.3453251085593365e-05
rl training, epoch5, iter0, batch167/1133, batch loss:1.6957577827270143e-05, Training time:138988.6408610344
batch reward last col mean 8.920163054426666e-06 first col mean 1.4146819012239575e-05 all mean 9.792624950932804e-06
rl training, epoch5, iter0, batch168/1133, batch loss:1.5550953321508132e-05, Training time:139016.01993322372
batch reward last col mean 0.0007048400002531707 first col mean 0.0005906524020247161 all mean 0.000703743367921561
rl training, epoch5, iter0, batch169/1133, batch loss:0.0008656435529701412, Training time:139043.26298761368
batch reward last col mean 4.9311882321489975e-05 first col mean 1.8439955965732224e-05 all mean 5.059268369222991e-05
rl training, epoch5, iter0, batch170/1133, batch loss:3.960759931942448e-05, Training time:139070.42974615097
batch reward last col mean 5.124003109813202e-06 first col mean 5.893999514228199e-06 all mean 1.485687153035542e-05
rl training, epoch5, iter0, batch171/1133, batch loss:1.9850718672387302e-05, Training time:139098.27914857864
batch reward last col mean 0.00029267824720591307 first col mean 0.00022730288037564605 all mean 0.0002905394940171391
rl training, epoch5, iter0, batch172/1133, batch loss:0.00046408316120505333, Training time:139125.6508486271
batch reward last col mean 6.656253390247002e-05 first col mean 1.337233970843954e-05 all mean 6.616990867769346e-05
rl training, epoch5, iter0, batch173/1133, batch loss:2.3779255570843816e-05, Training time:139153.14274168015
batch reward last col mean 1.4540586562361568e-05 first col mean 0.00041557959048077464 all mean 1.861493910837453e-05
rl training, epoch5, iter0, batch174/1133, batch loss:1.5531117242062464e-05, Training time:139180.47860980034
batch reward last col mean 0.0001376729051116854 first col mean 0.0003239987709093839 all mean 0.00013953539018984884
rl training, epoch5, iter0, batch175/1133, batch loss:0.00021553327678702772, Training time:139207.72058272362
batch reward last col mean 6.73680697218515e-05 first col mean 9.498382496531121e-06 all mean 8.415492629865184e-05
rl training, epoch5, iter0, batch176/1133, batch loss:0.0010434617288410664, Training time:139235.11112070084
batch reward last col mean 8.86603957042098e-05 first col mean 7.083949458319694e-05 all mean 8.836623601382598e-05
rl training, epoch5, iter0, batch177/1133, batch loss:5.873732879990712e-05, Training time:139262.36428380013
batch reward last col mean 4.0848381104297005e-06 first col mean 6.182323886605445e-06 all mean 4.184052613709355e-06
rl training, epoch5, iter0, batch178/1133, batch loss:9.542389989292133e-07, Training time:139289.75903344154
batch reward last col mean 5.1169958169339225e-05 first col mean 0.0032877775374799967 all mean 8.78849605214782e-05
rl training, epoch5, iter0, batch179/1133, batch loss:0.0008650448289699852, Training time:139316.96397709846
batch reward last col mean 0.0002369896974414587 first col mean 9.8867152701132e-05 all mean 0.0002333901938982308
rl training, epoch5, iter0, batch180/1133, batch loss:0.00016208998567890376, Training time:139343.98391199112
batch reward last col mean 0.000341000035405159 first col mean 0.00011819255450973287 all mean 0.00033553692628629506
rl training, epoch5, iter0, batch181/1133, batch loss:0.0005212356918491423, Training time:139371.37828493118
batch reward last col mean 0.00015533767873421311 first col mean 5.09722376591526e-05 all mean 0.00015412336506415159
rl training, epoch5, iter0, batch182/1133, batch loss:6.912002572789788e-05, Training time:139398.88707089424
batch reward last col mean 0.006117823999375105 first col mean 0.000886235386133194 all mean 0.006041082087904215
rl training, epoch5, iter0, batch183/1133, batch loss:0.012527274899184704, Training time:139426.07931399345
batch reward last col mean 1.4676816135761328e-05 first col mean 3.6386516057973495e-06 all mean 1.6077652617241256e-05
rl training, epoch5, iter0, batch184/1133, batch loss:3.8981681427685544e-05, Training time:139453.45508122444
batch reward last col mean 6.243026291485876e-05 first col mean 3.0787679861532524e-05 all mean 6.2096121837385e-05
rl training, epoch5, iter0, batch185/1133, batch loss:4.2714294977486134e-05, Training time:139480.84480810165
batch reward last col mean 0.0011161314323544502 first col mean 0.000856842496432364 all mean 0.001118435407988727
rl training, epoch5, iter0, batch186/1133, batch loss:0.0009104138589464128, Training time:139508.55905985832
batch reward last col mean 1.2592670827871189e-05 first col mean 0.00025634741177782416 all mean 1.5076965610205662e-05
rl training, epoch5, iter0, batch187/1133, batch loss:6.312324330792762e-06, Training time:139536.0891251564
batch reward last col mean 3.6448213904805016e-06 first col mean 9.346674778498709e-05 all mean 4.590843673213385e-06
rl training, epoch5, iter0, batch188/1133, batch loss:2.274343387398403e-06, Training time:139563.94199609756
batch reward last col mean 7.82992719905451e-05 first col mean 0.00015600069309584796 all mean 7.838536839699373e-05
rl training, epoch5, iter0, batch189/1133, batch loss:9.731029422255233e-05, Training time:139591.20696091652
batch reward last col mean 3.1397021302836947e-06 first col mean 6.558600489370292e-06 all mean 3.1769393444847083e-06
rl training, epoch5, iter0, batch190/1133, batch loss:1.4537688457494369e-06, Training time:139618.46595454216
batch reward last col mean 8.859222725732252e-05 first col mean 8.699672616785392e-05 all mean 8.859214722178876e-05
rl training, epoch5, iter0, batch191/1133, batch loss:4.317992352298461e-05, Training time:139645.6989519596
batch reward last col mean 1.83557622221997e-05 first col mean 5.8651385188568383e-05 all mean 1.9809609511867166e-05
rl training, epoch5, iter0, batch192/1133, batch loss:8.37526167742908e-05, Training time:139673.44885277748
batch reward last col mean 4.492617881624028e-05 first col mean 0.00014026857388671488 all mean 4.58955873909872e-05
rl training, epoch5, iter0, batch193/1133, batch loss:3.621646101237275e-05, Training time:139701.01641106606
batch reward last col mean 0.0009141344344243407 first col mean 0.0008200734155252576 all mean 0.0009208125993609428
rl training, epoch5, iter0, batch194/1133, batch loss:0.0006331792101264, Training time:139729.10453104973
batch reward last col mean 5.254541974863969e-06 first col mean 8.488195817335509e-06 all mean 6.622991350013763e-06
rl training, epoch5, iter0, batch195/1133, batch loss:1.7571486523593194e-06, Training time:139756.3772008419
batch reward last col mean 3.258499054936692e-05 first col mean 3.530666435835883e-05 all mean 3.256721902289428e-05
rl training, epoch5, iter0, batch196/1133, batch loss:1.2097905710106716e-05, Training time:139783.6903758049
batch reward last col mean 1.9804141629720107e-05 first col mean 1.2919870641781017e-05 all mean 2.057909114228096e-05
rl training, epoch5, iter0, batch197/1133, batch loss:4.330858064349741e-05, Training time:139810.98043370247
batch reward last col mean 5.656863322656136e-06 first col mean 1.3256247257231735e-05 all mean 5.854660685145063e-06
rl training, epoch5, iter0, batch198/1133, batch loss:6.764016688975971e-06, Training time:139838.35414671898
batch reward last col mean 6.24167932983255e-06 first col mean 1.2089267329429276e-05 all mean 6.444473456213018e-06
rl training, epoch5, iter0, batch199/1133, batch loss:1.956668938873918e-06, Training time:139865.7321395874
batch reward last col mean 0.0010512651642784476 first col mean 0.0020641530863940716 all mean 0.0010628097224980593
rl training, epoch5, iter0, batch200/1133, batch loss:0.0010207745945081115, Training time:139892.87461328506
batch reward last col mean 0.00024918228155002 first col mean 0.00048010400496423244 all mean 0.0002540779241826385
rl training, epoch5, iter0, batch201/1133, batch loss:0.0005427735741250217, Training time:139920.14771223068
batch reward last col mean 7.805115455994383e-05 first col mean 8.920094114728272e-05 all mean 7.76054585003294e-05
rl training, epoch5, iter0, batch202/1133, batch loss:7.991541497176513e-05, Training time:139948.35877609253
batch reward last col mean 6.887456493132049e-06 first col mean 0.00011852909665321931 all mean 8.04981027613394e-06
rl training, epoch5, iter0, batch203/1133, batch loss:1.3137603673385456e-05, Training time:139975.65114164352
batch reward last col mean 4.910404186375672e-06 first col mean 6.25280081294477e-05 all mean 5.497392976394622e-06
rl training, epoch5, iter0, batch204/1133, batch loss:3.313399065518752e-05, Training time:140003.44245791435
batch reward last col mean 1.869071820692625e-05 first col mean 2.7720085199689493e-05 all mean 1.8810185792972334e-05
rl training, epoch5, iter0, batch205/1133, batch loss:7.032378562144004e-06, Training time:140030.6476867199
batch reward last col mean 6.42689410597086e-05 first col mean 7.215835648821667e-05 all mean 6.910612137289718e-05
rl training, epoch5, iter0, batch206/1133, batch loss:0.00023947439331095666, Training time:140058.204300642
batch reward last col mean 0.00014328579709399492 first col mean 0.0002991823712363839 all mean 0.00015580312174279243
rl training, epoch5, iter0, batch207/1133, batch loss:0.0001617336383787915, Training time:140085.52756357193
batch reward last col mean 3.0644474463770166e-05 first col mean 1.1859576261485927e-05 all mean 4.1163588321069255e-05
rl training, epoch5, iter0, batch208/1133, batch loss:0.00034707473241724074, Training time:140112.8575129509
batch reward last col mean 4.821949460165342e-06 first col mean 3.3734362659743056e-05 all mean 5.116842203278793e-06
rl training, epoch5, iter0, batch209/1133, batch loss:1.0642292181728408e-05, Training time:140140.16131281853
batch reward last col mean 1.795860953279771e-05 first col mean 6.824239972047508e-05 all mean 1.8424891095492058e-05
rl training, epoch5, iter0, batch210/1133, batch loss:2.356810546189081e-05, Training time:140167.36722040176
batch reward last col mean 5.9305289141775575e-06 first col mean 0.00040874446858651936 all mean 1.0068965821119491e-05
rl training, epoch5, iter0, batch211/1133, batch loss:5.9171306929783896e-06, Training time:140194.54370379448
batch reward last col mean 2.4176482838811353e-05 first col mean 2.4653932996443473e-05 all mean 2.4143108021235093e-05
rl training, epoch5, iter0, batch212/1133, batch loss:2.141060758731328e-05, Training time:140222.06165981293
batch reward last col mean 1.0769394975795876e-05 first col mean 1.4443221516557969e-05 all mean 1.0779130207083654e-05
rl training, epoch5, iter0, batch213/1133, batch loss:8.745751074457075e-06, Training time:140249.40745711327
batch reward last col mean 0.0005269435932859778 first col mean 7.311509307328379e-06 all mean 0.0005205964553169906
rl training, epoch5, iter0, batch214/1133, batch loss:0.0004707219486590475, Training time:140276.73725533485
batch reward last col mean 0.0010709246853366494 first col mean 0.002519886242225766 all mean 0.0010836493456736207
rl training, epoch5, iter0, batch215/1133, batch loss:0.000791017257142812, Training time:140303.9299197197
batch reward last col mean 1.6088075426523574e-05 first col mean 3.143073263345286e-05 all mean 1.623066964384634e-05
rl training, epoch5, iter0, batch216/1133, batch loss:4.123810413148021e-06, Training time:140331.97559428215
batch reward last col mean 3.2682844903320074e-05 first col mean 1.042669919115724e-05 all mean 3.2265666959574446e-05
rl training, epoch5, iter0, batch217/1133, batch loss:2.615708945086226e-05, Training time:140359.255941391
batch reward last col mean 1.7015332559822127e-05 first col mean 0.0005462653934955597 all mean 2.452901389915496e-05
rl training, epoch5, iter0, batch218/1133, batch loss:0.00013032882998231798, Training time:140386.5545361042
batch reward last col mean 0.003713469486683607 first col mean 0.0032163546420633793 all mean 0.003714214079082012
rl training, epoch5, iter0, batch219/1133, batch loss:0.0022101483773440123, Training time:140414.50109291077
batch reward last col mean 4.786760200659046e-06 first col mean 6.631719588767737e-05 all mean 5.8587934290699195e-06
rl training, epoch5, iter0, batch220/1133, batch loss:2.223875890194904e-05, Training time:140442.21739530563
batch reward last col mean 0.0027011800557374954 first col mean 0.0034961034543812275 all mean 0.002709300024434924
rl training, epoch5, iter0, batch221/1133, batch loss:0.0017956123920157552, Training time:140469.7394323349
batch reward last col mean 0.004828647710382938 first col mean 4.010486918559764e-06 all mean 0.00466823810711503
rl training, epoch5, iter0, batch222/1133, batch loss:0.008910860866308212, Training time:140497.39443325996
batch reward last col mean 0.0023021777160465717 first col mean 3.5640274290926754e-05 all mean 0.00227353279478848
rl training, epoch5, iter0, batch223/1133, batch loss:0.0031810046639293432, Training time:140524.62122631073
batch reward last col mean 0.00035299448063597083 first col mean 0.00038938396028243005 all mean 0.000351979659171775
rl training, epoch5, iter0, batch224/1133, batch loss:0.00014655711129307747, Training time:140552.11394143105
batch reward last col mean 5.511823110282421e-05 first col mean 7.87560420576483e-05 all mean 6.625280366279185e-05
rl training, epoch5, iter0, batch225/1133, batch loss:5.5832413636380807e-05, Training time:140579.1632297039
batch reward last col mean 9.632335422793403e-05 first col mean 7.858447497710586e-05 all mean 0.0001153598859673366
rl training, epoch5, iter0, batch226/1133, batch loss:0.00011133220687042922, Training time:140606.23808073997
batch reward last col mean 0.0002042657433776185 first col mean 0.00020246363419573754 all mean 0.00020492705516517162
rl training, epoch5, iter0, batch227/1133, batch loss:0.00017818888591136783, Training time:140633.44473075867
batch reward last col mean 1.1301279300823808e-05 first col mean 1.0327325981052127e-05 all mean 1.166501078841975e-05
rl training, epoch5, iter0, batch228/1133, batch loss:7.485873538826127e-06, Training time:140660.63795614243
batch reward last col mean 0.0009165123337879777 first col mean 8.297399472212419e-05 all mean 0.0009024688042700291
rl training, epoch5, iter0, batch229/1133, batch loss:0.0007106676930561662, Training time:140687.9623413086
batch reward last col mean 1.2756458090734668e-05 first col mean 1.5042364793771412e-05 all mean 1.424086804036051e-05
rl training, epoch5, iter0, batch230/1133, batch loss:3.1024846975924447e-06, Training time:140715.3775806427
batch reward last col mean 0.00025944298249669373 first col mean 0.0003873365349136293 all mean 0.0002600157167762518
rl training, epoch5, iter0, batch231/1133, batch loss:0.0002600459265522659, Training time:140742.61763739586
batch reward last col mean 1.0399606253486127e-05 first col mean 3.0082159355515614e-05 all mean 1.0639811989676673e-05
rl training, epoch5, iter0, batch232/1133, batch loss:5.388095814851113e-06, Training time:140769.87585902214
batch reward last col mean 0.0031686394941061735 first col mean 0.0009645000100135803 all mean 0.003140305634588003
rl training, epoch5, iter0, batch233/1133, batch loss:0.004645220935344696, Training time:140797.16450047493
batch reward last col mean 9.054037946043536e-06 first col mean 1.4728786482010037e-05 all mean 9.22435265238164e-06
rl training, epoch5, iter0, batch234/1133, batch loss:1.021486968966201e-05, Training time:140824.64028525352
batch reward last col mean 1.771628376445733e-05 first col mean 6.715316703775898e-05 all mean 1.8199954865849577e-05
rl training, epoch5, iter0, batch235/1133, batch loss:2.4005141312954947e-05, Training time:140851.82025432587
batch reward last col mean 8.415334013989195e-05 first col mean 6.658938946202397e-05 all mean 8.411533053731546e-05
rl training, epoch5, iter0, batch236/1133, batch loss:0.00011270980758126825, Training time:140879.15876674652
batch reward last col mean 0.007109769154340029 first col mean 0.005975029431283474 all mean 0.007100572343915701
rl training, epoch5, iter0, batch237/1133, batch loss:0.008997256867587566, Training time:140906.45161628723
batch reward last col mean 0.00042173563269898295 first col mean 0.0004075153556186706 all mean 0.00042207035585306585
rl training, epoch5, iter0, batch238/1133, batch loss:0.00016765228065196425, Training time:140933.82274365425
batch reward last col mean 0.006489248480647802 first col mean 0.0048892865888774395 all mean 0.006472810171544552
rl training, epoch5, iter0, batch239/1133, batch loss:0.0074378387071192265, Training time:140961.16795802116
batch reward last col mean 3.3016433008015156e-05 first col mean 0.0009894795948639512 all mean 4.9841026338981465e-05
rl training, epoch5, iter0, batch240/1133, batch loss:0.00019430792599450797, Training time:140988.3497350216
batch reward last col mean 5.3152296459302306e-05 first col mean 1.1167474440298975e-05 all mean 5.302329009282403e-05
rl training, epoch5, iter0, batch241/1133, batch loss:6.975333963055164e-05, Training time:141015.55846452713
batch reward last col mean 0.0002934265648946166 first col mean 0.0001124689806601964 all mean 0.000293051271000877
rl training, epoch5, iter0, batch242/1133, batch loss:0.00016712573415134102, Training time:141043.05803442
batch reward last col mean 4.195471774437465e-06 first col mean 6.8908921093679965e-06 all mean 1.9754123059101403e-05
rl training, epoch5, iter0, batch243/1133, batch loss:2.3940092432894744e-06, Training time:141070.6667547226
batch reward last col mean 0.0007076559704728425 first col mean 0.0007489707786589861 all mean 0.0007087629055604339
rl training, epoch5, iter0, batch244/1133, batch loss:0.0004121404781471938, Training time:141097.8614692688
batch reward last col mean 0.00035235515679232776 first col mean 0.0002774916065391153 all mean 0.00035239511635154486
rl training, epoch5, iter0, batch245/1133, batch loss:0.00031197493080981076, Training time:141124.8862543106
batch reward last col mean 0.000384937331546098 first col mean 0.0004501008952502161 all mean 0.00038562880945391953
rl training, epoch5, iter0, batch246/1133, batch loss:0.00021530697995331138, Training time:141152.01804089546
batch reward last col mean 0.005758707877248526 first col mean 9.706400305731222e-05 all mean 0.005548104643821716
rl training, epoch5, iter0, batch247/1133, batch loss:0.006835080683231354, Training time:141179.2060124874
batch reward last col mean 4.1112027247436345e-05 first col mean 0.00023930457246024162 all mean 4.310913573135622e-05
rl training, epoch5, iter0, batch248/1133, batch loss:2.0200128346914425e-05, Training time:141206.38619852066
batch reward last col mean 1.1822588021459524e-05 first col mean 0.00016333810344804078 all mean 1.3314943316800054e-05
rl training, epoch5, iter0, batch249/1133, batch loss:6.096754987083841e-06, Training time:141233.6999168396
batch reward last col mean 4.560670731734717e-06 first col mean 4.7855421144049615e-05 all mean 5.0065336836269125e-06
rl training, epoch5, iter0, batch250/1133, batch loss:2.346648216189351e-06, Training time:141260.79430270195
batch reward last col mean 0.00026990086189471185 first col mean 0.0002611660456750542 all mean 0.00027010723715648055
rl training, epoch5, iter0, batch251/1133, batch loss:0.00015047829947434366, Training time:141288.73231625557
batch reward last col mean 0.0001222326682182029 first col mean 0.0019426597282290459 all mean 0.0001447647373424843
rl training, epoch5, iter0, batch252/1133, batch loss:0.0002393730537733063, Training time:141316.06101560593
batch reward last col mean 6.594491424039006e-05 first col mean 1.7612068404559977e-05 all mean 6.760589894838631e-05
rl training, epoch5, iter0, batch253/1133, batch loss:0.00017947003652807325, Training time:141343.3779554367
batch reward last col mean 0.00044970240560360253 first col mean 0.0004641201812773943 all mean 0.00044984708074480295
rl training, epoch5, iter0, batch254/1133, batch loss:0.0002386554260738194, Training time:141370.71108865738
batch reward last col mean 1.011899166769581e-05 first col mean 0.00014245232159737498 all mean 1.4357569853018504e-05
rl training, epoch5, iter0, batch255/1133, batch loss:5.051623156759888e-05, Training time:141398.21815156937
batch reward last col mean 0.0008460968965664506 first col mean 0.0008447397849522531 all mean 0.0008466746658086777
rl training, epoch5, iter0, batch256/1133, batch loss:0.00026395812164992094, Training time:141425.79114747047
batch reward last col mean 7.513178570661694e-05 first col mean 0.0001537901407573372 all mean 0.00010332243255106732
rl training, epoch5, iter0, batch257/1133, batch loss:0.00023284064081963152, Training time:141455.31269454956
batch reward last col mean 0.0011940153781324625 first col mean 0.0014132749056443572 all mean 0.0012045681942254305
rl training, epoch5, iter0, batch258/1133, batch loss:0.0009378469549119473, Training time:141484.23974204063
batch reward last col mean 0.0022439684253185987 first col mean 0.003357814159244299 all mean 0.002272623125463724
rl training, epoch5, iter0, batch259/1133, batch loss:0.005616377107799053, Training time:141512.37363815308
batch reward last col mean 2.6145131414523348e-05 first col mean 9.878433775156736e-05 all mean 2.69528609351255e-05
rl training, epoch5, iter0, batch260/1133, batch loss:1.353612242382951e-05, Training time:141539.7320315838
batch reward last col mean 0.0070715295150876045 first col mean 0.0011168704368174076 all mean 0.006932795513421297
rl training, epoch5, iter0, batch261/1133, batch loss:0.008456902578473091, Training time:141568.41458535194
batch reward last col mean 8.040963439270854e-05 first col mean 0.00014426306006498635 all mean 9.03770123841241e-05
rl training, epoch5, iter0, batch262/1133, batch loss:0.000431980675784871, Training time:141596.83525776863
batch reward last col mean 0.002113022143021226 first col mean 0.002213899977505207 all mean 0.0021148347295820713
rl training, epoch5, iter0, batch263/1133, batch loss:0.0008902978734113276, Training time:141624.15194129944
batch reward last col mean 4.79701702715829e-05 first col mean 0.0009884823812171817 all mean 5.749237607233226e-05
rl training, epoch5, iter0, batch264/1133, batch loss:0.00015180298942141235, Training time:141651.26607084274
batch reward last col mean 0.0022497388999909163 first col mean 0.0016580021474510431 all mean 0.0022440797183662653
rl training, epoch5, iter0, batch265/1133, batch loss:0.0014683951158076525, Training time:141678.26733469963
batch reward last col mean 0.0010181807447224855 first col mean 0.0002287110110046342 all mean 0.0009933777619153261
rl training, epoch5, iter0, batch266/1133, batch loss:0.0012254822067916393, Training time:141705.42555570602
batch reward last col mean 0.0014321525814011693 first col mean 0.0009780125692486763 all mean 0.0014203217579051852
rl training, epoch5, iter0, batch267/1133, batch loss:0.001473211799748242, Training time:141732.5966384411
batch reward last col mean 0.0010724839521571994 first col mean 0.0010406926739960909 all mean 0.0010726257460191846
rl training, epoch5, iter0, batch268/1133, batch loss:0.00018353301857132465, Training time:141759.79438376427
batch reward last col mean 0.001101599307730794 first col mean 0.0019006935181096196 all mean 0.0011100732954218984
rl training, epoch5, iter0, batch269/1133, batch loss:0.000514536106493324, Training time:141787.0222966671
batch reward last col mean 0.0004821467737201601 first col mean 0.0007783576147630811 all mean 0.0004909455310553312
rl training, epoch5, iter0, batch270/1133, batch loss:0.0005288979155011475, Training time:141814.44789862633
batch reward last col mean 0.00032651188666932285 first col mean 0.0003149741096422076 all mean 0.00034737904206849635
rl training, epoch5, iter0, batch271/1133, batch loss:0.0006906110211275518, Training time:141841.756636858
batch reward last col mean 0.005546538159251213 first col mean 0.004447644576430321 all mean 0.005586806684732437
rl training, epoch5, iter0, batch272/1133, batch loss:0.01026703417301178, Training time:141869.02689790726
batch reward last col mean 0.0008478472591377795 first col mean 0.0005663223564624786 all mean 0.0008291189442388713
rl training, epoch5, iter0, batch273/1133, batch loss:0.0006553870043717325, Training time:141896.3201467991
batch reward last col mean 0.002955865114927292 first col mean 0.0012033077655360103 all mean 0.0029293650295585394
rl training, epoch5, iter0, batch274/1133, batch loss:0.0017819887725636363, Training time:141923.5672237873
batch reward last col mean 0.0001512360613560304 first col mean 0.001336258021183312 all mean 0.00016596096975263208
rl training, epoch5, iter0, batch275/1133, batch loss:0.00036446514423005283, Training time:141950.84873342514
batch reward last col mean 0.0010008842218667269 first col mean 0.0004869232070632279 all mean 0.0009874723618850112
rl training, epoch5, iter0, batch276/1133, batch loss:0.0009930167580023408, Training time:141978.59744286537
batch reward last col mean 0.004565590526908636 first col mean 0.006470273248851299 all mean 0.004590225405991077
rl training, epoch5, iter0, batch277/1133, batch loss:0.004041712265461683, Training time:142005.93432474136
batch reward last col mean 0.003969826269894838 first col mean 0.005661400966346264 all mean 0.0039749653078615665
rl training, epoch5, iter0, batch278/1133, batch loss:0.0019788595382124186, Training time:142033.51727104187
batch reward last col mean 0.003152084071189165 first col mean 0.002951729344204068 all mean 0.003176884725689888
rl training, epoch5, iter0, batch279/1133, batch loss:0.0025570683646947145, Training time:142060.6885035038
batch reward last col mean 0.008048408664762974 first col mean 0.007958385162055492 all mean 0.008045049384236336
rl training, epoch5, iter0, batch280/1133, batch loss:0.002794003114104271, Training time:142087.7735939026
batch reward last col mean 0.003820545971393585 first col mean 0.005428154021501541 all mean 0.0038337470032274723
rl training, epoch5, iter0, batch281/1133, batch loss:0.0010672680800780654, Training time:142115.0774450302
batch reward last col mean 0.0016540685901418328 first col mean 0.0026042473036795855 all mean 0.0016642258269712329
rl training, epoch5, iter0, batch282/1133, batch loss:0.0005374814500100911, Training time:142142.24075889587
batch reward last col mean 0.0029462631791830063 first col mean 0.004754550289362669 all mean 0.0029646181501448154
rl training, epoch5, iter0, batch283/1133, batch loss:0.000593922974076122, Training time:142169.4581205845
batch reward last col mean 0.007494946476072073 first col mean 0.009662874042987823 all mean 0.007520842831581831
rl training, epoch5, iter0, batch284/1133, batch loss:0.0010006420779973269, Training time:142197.10015249252
batch reward last col mean 0.000584256078582257 first col mean 0.0003957807784900069 all mean 0.0005865658749826252
rl training, epoch5, iter0, batch285/1133, batch loss:0.0004012873105239123, Training time:142224.34091615677
batch reward last col mean 0.0037408419884741306 first col mean 0.004653037525713444 all mean 0.0037735733203589916
rl training, epoch5, iter0, batch286/1133, batch loss:0.0023462404496967793, Training time:142251.62651324272
batch reward last col mean 0.006978617515414953 first col mean 0.007136098109185696 all mean 0.006979860831052065
rl training, epoch5, iter0, batch287/1133, batch loss:0.001197064178995788, Training time:142278.86730098724
batch reward last col mean 0.008459563367068768 first col mean 0.012181495316326618 all mean 0.008497931063175201
rl training, epoch5, iter0, batch288/1133, batch loss:0.0021280371583998203, Training time:142306.04933977127
batch reward last col mean 0.009828000329434872 first col mean 0.008356314152479172 all mean 0.00981302559375763
rl training, epoch5, iter0, batch289/1133, batch loss:0.0109608368948102, Training time:142333.20299053192
batch reward last col mean 0.013102089986205101 first col mean 0.013154838234186172 all mean 0.013093623332679272
rl training, epoch5, iter0, batch290/1133, batch loss:0.00575672835111618, Training time:142360.11454749107
batch reward last col mean 0.012812918052077293 first col mean 0.018411055207252502 all mean 0.012861095368862152
rl training, epoch5, iter0, batch291/1133, batch loss:0.005237119738012552, Training time:142387.13099074364
batch reward last col mean 0.0055929129011929035 first col mean 0.007062556222081184 all mean 0.005652150139212608
rl training, epoch5, iter0, batch292/1133, batch loss:0.002410461660474539, Training time:142414.82272219658
batch reward last col mean 0.007429530844092369 first col mean 0.009071344509720802 all mean 0.007447364274412394
rl training, epoch5, iter0, batch293/1133, batch loss:0.00218942784704268, Training time:142442.16670560837
batch reward last col mean 0.004243865609169006 first col mean 0.007801445666700602 all mean 0.004372309893369675
rl training, epoch5, iter0, batch294/1133, batch loss:0.002884316025301814, Training time:142469.42989253998
batch reward last col mean 0.015906818211078644 first col mean 0.016014672815799713 all mean 0.01587732508778572
rl training, epoch5, iter0, batch295/1133, batch loss:0.004230229649692774, Training time:142496.57695436478
batch reward last col mean 0.01305374875664711 first col mean 0.0061174798756837845 all mean 0.01296822726726532
rl training, epoch5, iter0, batch296/1133, batch loss:0.009346193633973598, Training time:142523.7520301342
batch reward last col mean 0.023900732398033142 first col mean 0.022831140086054802 all mean 0.02395237423479557
rl training, epoch5, iter0, batch297/1133, batch loss:0.015153340995311737, Training time:142550.98569083214
batch reward last col mean 0.02605919912457466 first col mean 0.022207796573638916 all mean 0.02596920169889927
rl training, epoch5, iter0, batch298/1133, batch loss:0.014361761510372162, Training time:142578.26833295822
batch reward last col mean 0.01002406980842352 first col mean 0.02050969749689102 all mean 0.010191814042627811
rl training, epoch5, iter0, batch299/1133, batch loss:0.0078053963370621204, Training time:142605.39936995506
batch reward last col mean 0.04180923104286194 first col mean 0.034773118793964386 all mean 0.041497424244880676
rl training, epoch5, iter0, batch300/1133, batch loss:0.017313262447714806, Training time:142632.44173884392
batch reward last col mean 0.022870315238833427 first col mean 0.028700191527605057 all mean 0.023032428696751595
rl training, epoch5, iter0, batch301/1133, batch loss:0.012004013173282146, Training time:142659.6087448597
batch reward last col mean 0.03873072937130928 first col mean 0.03330153599381447 all mean 0.03863736242055893
rl training, epoch5, iter0, batch302/1133, batch loss:0.01897471770644188, Training time:142687.64707756042
batch reward last col mean 0.01359829492866993 first col mean 0.013663334771990776 all mean 0.013597914949059486
rl training, epoch5, iter0, batch303/1133, batch loss:0.004779149312525988, Training time:142714.8682975769
batch reward last col mean 0.025281617417931557 first col mean 0.03430548682808876 all mean 0.025412140414118767
rl training, epoch5, iter0, batch304/1133, batch loss:0.005471598356962204, Training time:142742.23990154266
batch reward last col mean 0.052040450274944305 first col mean 0.048370495438575745 all mean 0.05186498910188675
rl training, epoch5, iter0, batch305/1133, batch loss:0.02469584159553051, Training time:142769.32027459145
batch reward last col mean 0.02838195115327835 first col mean 0.03399975225329399 all mean 0.028589628636837006
rl training, epoch5, iter0, batch306/1133, batch loss:0.00995158776640892, Training time:142796.68123936653
batch reward last col mean 0.021673552691936493 first col mean 0.027959682047367096 all mean 0.021833635866642
rl training, epoch5, iter0, batch307/1133, batch loss:0.006241613999009132, Training time:142823.89869856834
batch reward last col mean 0.0360364094376564 first col mean 0.03224053233861923 all mean 0.03592667356133461
rl training, epoch5, iter0, batch308/1133, batch loss:0.012525757774710655, Training time:142851.64368963242
batch reward last col mean 0.03253276273608208 first col mean 0.032226696610450745 all mean 0.03256333991885185
rl training, epoch5, iter0, batch309/1133, batch loss:0.011174658313393593, Training time:142878.78694534302
batch reward last col mean 0.05048869550228119 first col mean 0.04487335681915283 all mean 0.050337180495262146
rl training, epoch5, iter0, batch310/1133, batch loss:0.02201983891427517, Training time:142905.92674303055
batch reward last col mean 0.020229415968060493 first col mean 0.02331709861755371 all mean 0.020283786579966545
rl training, epoch5, iter0, batch311/1133, batch loss:0.002751588122919202, Training time:142933.05051898956
batch reward last col mean 0.045889999717473984 first col mean 0.046502090990543365 all mean 0.04591989144682884
rl training, epoch5, iter0, batch312/1133, batch loss:0.024805936962366104, Training time:142960.23596692085
batch reward last col mean 0.039651863276958466 first col mean 0.040867019444704056 all mean 0.039671268314123154
rl training, epoch5, iter0, batch313/1133, batch loss:0.017718393355607986, Training time:142988.06525492668
batch reward last col mean 0.04305042698979378 first col mean 0.03838770091533661 all mean 0.04293499141931534
rl training, epoch5, iter0, batch314/1133, batch loss:0.01267703715711832, Training time:143015.37134885788
batch reward last col mean 0.02668595500290394 first col mean 0.032745156437158585 all mean 0.02674143947660923
rl training, epoch5, iter0, batch315/1133, batch loss:0.00654378067702055, Training time:143042.48571372032
batch reward last col mean 0.05297072231769562 first col mean 0.05760861188173294 all mean 0.053140196949243546
rl training, epoch5, iter0, batch316/1133, batch loss:0.030928272753953934, Training time:143069.5750632286
batch reward last col mean 0.07432220131158829 first col mean 0.06862358748912811 all mean 0.07416632771492004
rl training, epoch5, iter0, batch317/1133, batch loss:0.016568895429372787, Training time:143096.79967188835
batch reward last col mean 0.06700614094734192 first col mean 0.06928583234548569 all mean 0.0670485869050026
rl training, epoch5, iter0, batch318/1133, batch loss:0.030295243486762047, Training time:143124.10989451408
batch reward last col mean 0.03450823947787285 first col mean 0.03749094530940056 all mean 0.03458263352513313
rl training, epoch5, iter0, batch319/1133, batch loss:0.007256224285811186, Training time:143151.82013773918
batch reward last col mean 0.046634454280138016 first col mean 0.05270185321569443 all mean 0.046837497502565384
rl training, epoch5, iter0, batch320/1133, batch loss:0.007676452863961458, Training time:143179.08803987503
batch reward last col mean 0.052948929369449615 first col mean 0.05284919589757919 all mean 0.0529828742146492
rl training, epoch5, iter0, batch321/1133, batch loss:0.013991630636155605, Training time:143206.84700727463
batch reward last col mean 0.05688803270459175 first col mean 0.060006365180015564 all mean 0.05693597346544266
rl training, epoch5, iter0, batch322/1133, batch loss:0.007964473217725754, Training time:143234.1725242138
batch reward last col mean 0.07446526736021042 first col mean 0.07852634787559509 all mean 0.07453211396932602
rl training, epoch5, iter0, batch323/1133, batch loss:0.008470890112221241, Training time:143261.82568717003
batch reward last col mean 0.06887053698301315 first col mean 0.06236455589532852 all mean 0.06844165921211243
rl training, epoch5, iter0, batch324/1133, batch loss:0.027737192809581757, Training time:143289.28633069992
batch reward last col mean 0.07443837076425552 first col mean 0.07188069820404053 all mean 0.07440554350614548
rl training, epoch5, iter0, batch325/1133, batch loss:0.009457116946578026, Training time:143316.72968792915
batch reward last col mean 0.06779058277606964 first col mean 0.06740214675664902 all mean 0.06774469465017319
rl training, epoch5, iter0, batch326/1133, batch loss:0.007145003881305456, Training time:143344.21751761436
batch reward last col mean 0.08781133592128754 first col mean 0.07232975959777832 all mean 0.08745630830526352
rl training, epoch5, iter0, batch327/1133, batch loss:0.015207256190478802, Training time:143371.4735236168
batch reward last col mean 0.06497934460639954 first col mean 0.06205810606479645 all mean 0.06494880467653275
rl training, epoch5, iter0, batch328/1133, batch loss:0.01383549440652132, Training time:143398.67174983025
batch reward last col mean 0.049081962555646896 first col mean 0.054415445774793625 all mean 0.049229323863983154
rl training, epoch5, iter0, batch329/1133, batch loss:0.016601895913481712, Training time:143425.86916160583
batch reward last col mean 0.09022074937820435 first col mean 0.08071500062942505 all mean 0.08997077494859695
rl training, epoch5, iter0, batch330/1133, batch loss:0.013387295417487621, Training time:143452.8696887493
batch reward last col mean 0.06334594637155533 first col mean 0.06417766958475113 all mean 0.06337171792984009
rl training, epoch5, iter0, batch331/1133, batch loss:0.014813195914030075, Training time:143480.1393969059
batch reward last col mean 0.0436723530292511 first col mean 0.040755998343229294 all mean 0.043449487537145615
rl training, epoch5, iter0, batch332/1133, batch loss:0.014659219421446323, Training time:143507.88851976395
batch reward last col mean 0.08318281173706055 first col mean 0.07378464937210083 all mean 0.08304610103368759
rl training, epoch5, iter0, batch333/1133, batch loss:0.016864962875843048, Training time:143535.16340136528
batch reward last col mean 0.09260030090808868 first col mean 0.0935283824801445 all mean 0.09260528534650803
rl training, epoch5, iter0, batch334/1133, batch loss:0.0064943404868245125, Training time:143562.32781529427
batch reward last col mean 0.07554711401462555 first col mean 0.07165900617837906 all mean 0.07554709911346436
rl training, epoch5, iter0, batch335/1133, batch loss:0.011307832784950733, Training time:143589.67655444145
batch reward last col mean 0.07186844944953918 first col mean 0.06365199387073517 all mean 0.07178353518247604
rl training, epoch5, iter0, batch336/1133, batch loss:0.008121357299387455, Training time:143616.85093045235
batch reward last col mean 0.08038096874952316 first col mean 0.07511387765407562 all mean 0.08029427379369736
rl training, epoch5, iter0, batch337/1133, batch loss:0.012808135710656643, Training time:143643.8947303295
batch reward last col mean 0.07584068179130554 first col mean 0.07638037204742432 all mean 0.0758509710431099
rl training, epoch5, iter0, batch338/1133, batch loss:0.014047683216631413, Training time:143671.09330701828
batch reward last col mean 0.09581149369478226 first col mean 0.0955687165260315 all mean 0.09579350054264069
rl training, epoch5, iter0, batch339/1133, batch loss:0.00707479240372777, Training time:143698.30829834938
batch reward last col mean 0.07888439297676086 first col mean 0.08059832453727722 all mean 0.078898124396801
rl training, epoch5, iter0, batch340/1133, batch loss:0.00799220148473978, Training time:143725.16695809364
batch reward last col mean 0.07795530557632446 first col mean 0.07608994841575623 all mean 0.07800645381212234
rl training, epoch5, iter0, batch341/1133, batch loss:0.015529913827776909, Training time:143752.4299993515
batch reward last col mean 0.09751789271831512 first col mean 0.10561715811491013 all mean 0.09760290384292603
rl training, epoch5, iter0, batch342/1133, batch loss:0.02479712665081024, Training time:143779.5572462082
batch reward last col mean 0.06304259598255157 first col mean 0.06197461485862732 all mean 0.0630117729306221
rl training, epoch5, iter0, batch343/1133, batch loss:0.008191633969545364, Training time:143806.6444182396
batch reward last col mean 0.1007499098777771 first col mean 0.0976715162396431 all mean 0.10071093589067459
rl training, epoch5, iter0, batch344/1133, batch loss:0.010868248529732227, Training time:143833.61162018776
batch reward last col mean 0.12401880323886871 first col mean 0.12043419480323792 all mean 0.12401268631219864
rl training, epoch5, iter0, batch345/1133, batch loss:0.019938448444008827, Training time:143861.34443211555
batch reward last col mean 0.11280343681573868 first col mean 0.1173025369644165 all mean 0.11282230913639069
rl training, epoch5, iter0, batch346/1133, batch loss:0.014945418573915958, Training time:143888.47455334663
batch reward last col mean 0.09995826333761215 first col mean 0.10694105178117752 all mean 0.10004116594791412
rl training, epoch5, iter0, batch347/1133, batch loss:0.008090988732874393, Training time:143915.6285712719
batch reward last col mean 0.10670583695173264 first col mean 0.10702518373727798 all mean 0.10670509934425354
rl training, epoch5, iter0, batch348/1133, batch loss:0.014604068361222744, Training time:143942.7675189972
batch reward last col mean 0.10515749454498291 first col mean 0.10259336233139038 all mean 0.10514292865991592
rl training, epoch5, iter0, batch349/1133, batch loss:0.013587450608611107, Training time:143969.8615987301
batch reward last col mean 0.10962872207164764 first col mean 0.11204774677753448 all mean 0.10965179651975632
rl training, epoch5, iter0, batch350/1133, batch loss:0.020620107650756836, Training time:143996.84661245346
batch reward last col mean 0.11995097994804382 first col mean 0.12663280963897705 all mean 0.12001495063304901
rl training, epoch5, iter0, batch351/1133, batch loss:0.011525425128638744, Training time:144023.94818806648
batch reward last col mean 0.11144065111875534 first col mean 0.10488752275705338 all mean 0.1113712415099144
rl training, epoch5, iter0, batch352/1133, batch loss:0.027484193444252014, Training time:144051.25951957703
batch reward last col mean 0.10414041578769684 first col mean 0.10439816117286682 all mean 0.10415071249008179
rl training, epoch5, iter0, batch353/1133, batch loss:0.007980872876942158, Training time:144078.45598053932
batch reward last col mean 0.1052565723657608 first col mean 0.10785273462533951 all mean 0.10528190433979034
rl training, epoch5, iter0, batch354/1133, batch loss:0.002537839813157916, Training time:144105.428085804
batch reward last col mean 0.10105003416538239 first col mean 0.09962181001901627 all mean 0.10103563964366913
rl training, epoch5, iter0, batch355/1133, batch loss:0.004913165234029293, Training time:144132.24279379845
batch reward last col mean 0.11016705632209778 first col mean 0.1127355694770813 all mean 0.1101941391825676
rl training, epoch5, iter0, batch356/1133, batch loss:0.004143154248595238, Training time:144159.26639986038
batch reward last col mean 0.16312259435653687 first col mean 0.15937238931655884 all mean 0.16309742629528046
rl training, epoch5, iter0, batch357/1133, batch loss:0.008618639782071114, Training time:144186.2298426628
batch reward last col mean 0.14878101646900177 first col mean 0.15134623646736145 all mean 0.14881324768066406
rl training, epoch5, iter0, batch358/1133, batch loss:0.007327246479690075, Training time:144213.37376880646
batch reward last col mean 0.15106242895126343 first col mean 0.15135982632637024 all mean 0.1510709822177887
rl training, epoch5, iter0, batch359/1133, batch loss:0.006712405011057854, Training time:144240.714220047
batch reward last col mean 0.12240123748779297 first col mean 0.12286257743835449 all mean 0.122406005859375
rl training, epoch5, iter0, batch360/1133, batch loss:0.007883831858634949, Training time:144267.6996998787
batch reward last col mean 0.13045726716518402 first col mean 0.12744654715061188 all mean 0.13042685389518738
rl training, epoch5, iter0, batch361/1133, batch loss:0.012018959037959576, Training time:144295.03801178932
batch reward last col mean 0.13054338097572327 first col mean 0.13300324976444244 all mean 0.13057932257652283
rl training, epoch5, iter0, batch362/1133, batch loss:0.007505977060645819, Training time:144322.30465126038
batch reward last col mean 0.17106473445892334 first col mean 0.17022600769996643 all mean 0.17105732858181
rl training, epoch5, iter0, batch363/1133, batch loss:0.007904211059212685, Training time:144349.33429527283
batch reward last col mean 0.11568742990493774 first col mean 0.11411206424236298 all mean 0.11567198485136032
rl training, epoch5, iter0, batch364/1133, batch loss:0.015139135532081127, Training time:144376.603399992
batch reward last col mean 0.11937826871871948 first col mean 0.11742788553237915 all mean 0.11935851722955704
rl training, epoch5, iter0, batch365/1133, batch loss:0.00889902375638485, Training time:144403.49468255043
batch reward last col mean 0.15892496705055237 first col mean 0.15812218189239502 all mean 0.15892662107944489
rl training, epoch5, iter0, batch366/1133, batch loss:0.008906222879886627, Training time:144430.6149289608
batch reward last col mean 0.13773228228092194 first col mean 0.1374226063489914 all mean 0.13772642612457275
rl training, epoch5, iter0, batch367/1133, batch loss:0.005457790102809668, Training time:144457.70408535004
batch reward last col mean 0.12362711876630783 first col mean 0.1225668266415596 all mean 0.12361641973257065
rl training, epoch5, iter0, batch368/1133, batch loss:0.007191012613475323, Training time:144485.47451853752
batch reward last col mean 0.1752239167690277 first col mean 0.17785629630088806 all mean 0.17525050044059753
rl training, epoch5, iter0, batch369/1133, batch loss:0.012290684506297112, Training time:144512.597032547
batch reward last col mean 0.194351464509964 first col mean 0.19297045469284058 all mean 0.19433681666851044
rl training, epoch5, iter0, batch370/1133, batch loss:0.00723959831520915, Training time:144540.19387626648
batch reward last col mean 0.14434409141540527 first col mean 0.14459346234798431 all mean 0.14434625208377838
rl training, epoch5, iter0, batch371/1133, batch loss:0.008245433680713177, Training time:144567.64176893234
batch reward last col mean 0.14917540550231934 first col mean 0.15156222879886627 all mean 0.14921341836452484
rl training, epoch5, iter0, batch372/1133, batch loss:0.030364694073796272, Training time:144594.7295691967
batch reward last col mean 0.1856069713830948 first col mean 0.18420210480690002 all mean 0.18558718264102936
rl training, epoch5, iter0, batch373/1133, batch loss:0.011776088736951351, Training time:144622.08355355263
batch reward last col mean 0.18706324696540833 first col mean 0.1925657093524933 all mean 0.18710604310035706
rl training, epoch5, iter0, batch374/1133, batch loss:0.01399247907102108, Training time:144649.31464338303
batch reward last col mean 0.1860368251800537 first col mean 0.1817311942577362 all mean 0.18600143492221832
rl training, epoch5, iter0, batch375/1133, batch loss:0.017274929210543633, Training time:144676.43027114868
batch reward last col mean 0.15142928063869476 first col mean 0.1477954238653183 all mean 0.1513906568288803
rl training, epoch5, iter0, batch376/1133, batch loss:0.009886977262794971, Training time:144703.53550195694
batch reward last col mean 0.19209983944892883 first col mean 0.2005784809589386 all mean 0.19218656420707703
rl training, epoch5, iter0, batch377/1133, batch loss:0.02143642120063305, Training time:144730.65538406372
batch reward last col mean 0.14943766593933105 first col mean 0.14800454676151276 all mean 0.1494230031967163
rl training, epoch5, iter0, batch378/1133, batch loss:0.011855775490403175, Training time:144757.66256856918
batch reward last col mean 0.1691407561302185 first col mean 0.17261692881584167 all mean 0.16917870938777924
rl training, epoch5, iter0, batch379/1133, batch loss:0.01057584211230278, Training time:144784.75524306297
batch reward last col mean 0.13889724016189575 first col mean 0.14266374707221985 all mean 0.13893522322177887
rl training, epoch5, iter0, batch380/1133, batch loss:0.01929565519094467, Training time:144811.70127916336
batch reward last col mean 0.1657240092754364 first col mean 0.16685491800308228 all mean 0.16573961079120636
rl training, epoch5, iter0, batch381/1133, batch loss:0.013311739079654217, Training time:144839.01164579391
batch reward last col mean 0.15535786747932434 first col mean 0.15315568447113037 all mean 0.15533435344696045
rl training, epoch5, iter0, batch382/1133, batch loss:0.009961288422346115, Training time:144865.9719440937
batch reward last col mean 0.1589415818452835 first col mean 0.15848815441131592 all mean 0.15893703699111938
rl training, epoch5, iter0, batch383/1133, batch loss:0.009051667526364326, Training time:144893.02158880234
batch reward last col mean 0.16601090133190155 first col mean 0.1686318814754486 all mean 0.1660364717245102
rl training, epoch5, iter0, batch384/1133, batch loss:0.012391543947160244, Training time:144920.27527618408
batch reward last col mean 0.18307910859584808 first col mean 0.17976130545139313 all mean 0.18303602933883667
rl training, epoch5, iter0, batch385/1133, batch loss:0.01917123980820179, Training time:144947.27076101303
batch reward last col mean 0.12811033427715302 first col mean 0.13478222489356995 all mean 0.1282341629266739
rl training, epoch5, iter0, batch386/1133, batch loss:0.009293644689023495, Training time:144974.3629026413
batch reward last col mean 0.1571093499660492 first col mean 0.15655553340911865 all mean 0.15708671510219574
rl training, epoch5, iter0, batch387/1133, batch loss:0.01356128416955471, Training time:145001.41002321243
batch reward last col mean 0.16265146434307098 first col mean 0.16411876678466797 all mean 0.1626509130001068
rl training, epoch5, iter0, batch388/1133, batch loss:0.020359309390187263, Training time:145028.66657805443
batch reward last col mean 0.16965216398239136 first col mean 0.17819063365459442 all mean 0.16973842680454254
rl training, epoch5, iter0, batch389/1133, batch loss:0.009460791014134884, Training time:145055.7464852333
batch reward last col mean 0.15024228394031525 first col mean 0.15164926648139954 all mean 0.1502576470375061
rl training, epoch5, iter0, batch390/1133, batch loss:0.009052722714841366, Training time:145082.66730213165
batch reward last col mean 0.18792714178562164 first col mean 0.19421401619911194 all mean 0.18799079954624176
rl training, epoch5, iter0, batch391/1133, batch loss:0.00875933188945055, Training time:145109.89843726158
batch reward last col mean 0.19480162858963013 first col mean 0.19381466507911682 all mean 0.19474682211875916
rl training, epoch5, iter0, batch392/1133, batch loss:0.03021843731403351, Training time:145136.81798768044
batch reward last col mean 0.16791662573814392 first col mean 0.16416500508785248 all mean 0.16785946488380432
rl training, epoch5, iter0, batch393/1133, batch loss:0.015801725909113884, Training time:145163.80075740814
batch reward last col mean 0.18972373008728027 first col mean 0.18967536091804504 all mean 0.18972358107566833
rl training, epoch5, iter0, batch394/1133, batch loss:0.016741374507546425, Training time:145190.9423005581
batch reward last col mean 0.18823322653770447 first col mean 0.1885787546634674 all mean 0.18822243809700012
rl training, epoch5, iter0, batch395/1133, batch loss:0.012510145083069801, Training time:145218.1063492298
batch reward last col mean 0.18461215496063232 first col mean 0.18334951996803284 all mean 0.18459932506084442
rl training, epoch5, iter0, batch396/1133, batch loss:0.012132607400417328, Training time:145245.07626008987
batch reward last col mean 0.16881534457206726 first col mean 0.1649966835975647 all mean 0.16877661645412445
rl training, epoch5, iter0, batch397/1133, batch loss:0.009759836830198765, Training time:145272.11052393913
batch reward last col mean 0.13610588014125824 first col mean 0.13781122863292694 all mean 0.13605941832065582
rl training, epoch5, iter0, batch398/1133, batch loss:0.027155810967087746, Training time:145299.0761332512
batch reward last col mean 0.1796356737613678 first col mean 0.18279120326042175 all mean 0.1796591430902481
rl training, epoch5, iter0, batch399/1133, batch loss:0.011204990558326244, Training time:145326.07094168663
batch reward last col mean 0.1973280906677246 first col mean 0.19768618047237396 all mean 0.19733171164989471
rl training, epoch5, iter0, batch400/1133, batch loss:0.01913638412952423, Training time:145352.9465250969
batch reward last col mean 0.16938768327236176 first col mean 0.17522963881492615 all mean 0.1694713979959488
rl training, epoch5, iter0, batch401/1133, batch loss:0.015464426018297672, Training time:145380.03568387032
batch reward last col mean 0.16426418721675873 first col mean 0.16406479477882385 all mean 0.16428633034229279
rl training, epoch5, iter0, batch402/1133, batch loss:0.02050347626209259, Training time:145407.37719082832
batch reward last col mean 0.2126256227493286 first col mean 0.20537567138671875 all mean 0.21251516044139862
rl training, epoch5, iter0, batch403/1133, batch loss:0.020720433443784714, Training time:145434.70266866684
batch reward last col mean 0.13663004338741302 first col mean 0.14393968880176544 all mean 0.1367531269788742
rl training, epoch5, iter0, batch404/1133, batch loss:0.025927836075425148, Training time:145462.6875588894
batch reward last col mean 0.12485253810882568 first col mean 0.1271377056837082 all mean 0.124861940741539
rl training, epoch5, iter0, batch405/1133, batch loss:0.01187875121831894, Training time:145490.35945153236
batch reward last col mean 0.14148490130901337 first col mean 0.13823482394218445 all mean 0.14150691032409668
rl training, epoch5, iter0, batch406/1133, batch loss:0.014704372733831406, Training time:145517.5046288967
batch reward last col mean 0.18587012588977814 first col mean 0.18649131059646606 all mean 0.18583808839321136
rl training, epoch5, iter0, batch407/1133, batch loss:0.017825642600655556, Training time:145544.5644311905
batch reward last col mean 0.17044353485107422 first col mean 0.166184663772583 all mean 0.17035721242427826
rl training, epoch5, iter0, batch408/1133, batch loss:0.01853221096098423, Training time:145571.66852283478
batch reward last col mean 0.22775912284851074 first col mean 0.2217148095369339 all mean 0.22766940295696259
rl training, epoch5, iter0, batch409/1133, batch loss:0.05831423029303551, Training time:145598.70505070686
batch reward last col mean 0.1939563751220703 first col mean 0.17735248804092407 all mean 0.19371317327022552
rl training, epoch5, iter0, batch410/1133, batch loss:0.02533196099102497, Training time:145625.74444794655
batch reward last col mean 0.16683268547058105 first col mean 0.17616644501686096 all mean 0.16696348786354065
rl training, epoch5, iter0, batch411/1133, batch loss:0.022120334208011627, Training time:145652.95319986343
batch reward last col mean 0.21549004316329956 first col mean 0.20724427700042725 all mean 0.2153453677892685
rl training, epoch5, iter0, batch412/1133, batch loss:0.03230959177017212, Training time:145680.1143708229
batch reward last col mean 0.1811813861131668 first col mean 0.18579095602035522 all mean 0.18120069801807404
rl training, epoch5, iter0, batch413/1133, batch loss:0.034073565155267715, Training time:145707.2901418209
batch reward last col mean 0.20999589562416077 first col mean 0.19727885723114014 all mean 0.20973573625087738
rl training, epoch5, iter0, batch414/1133, batch loss:0.060005053877830505, Training time:145734.5353152752
batch reward last col mean 0.18875959515571594 first col mean 0.18318462371826172 all mean 0.18869134783744812
rl training, epoch5, iter0, batch415/1133, batch loss:0.039824478328228, Training time:145761.57595729828
batch reward last col mean 0.1733260154724121 first col mean 0.173195019364357 all mean 0.1732453852891922
rl training, epoch5, iter0, batch416/1133, batch loss:0.047471050173044205, Training time:145788.83308672905
batch reward last col mean 0.22219590842723846 first col mean 0.217009499669075 all mean 0.2220817357301712
rl training, epoch5, iter0, batch417/1133, batch loss:0.052282944321632385, Training time:145816.02339792252
batch reward last col mean 0.186967134475708 first col mean 0.18622858822345734 all mean 0.18699179589748383
rl training, epoch5, iter0, batch418/1133, batch loss:0.04066643491387367, Training time:145843.99433279037
batch reward last col mean 0.24023184180259705 first col mean 0.2194596379995346 all mean 0.23995141685009003
rl training, epoch5, iter0, batch419/1133, batch loss:0.049537792801856995, Training time:145871.2514514923
batch reward last col mean 0.2222929447889328 first col mean 0.2437334954738617 all mean 0.22258129715919495
rl training, epoch5, iter0, batch420/1133, batch loss:0.05079692602157593, Training time:145898.37082767487
batch reward last col mean 0.24900779128074646 first col mean 0.2532894015312195 all mean 0.2490645945072174
rl training, epoch5, iter0, batch421/1133, batch loss:0.04781259223818779, Training time:145925.67967557907
batch reward last col mean 0.2055475115776062 first col mean 0.21888688206672668 all mean 0.20580023527145386
rl training, epoch5, iter0, batch422/1133, batch loss:0.06486878544092178, Training time:145952.8147828579
batch reward last col mean 0.24744775891304016 first col mean 0.22773870825767517 all mean 0.24714285135269165
rl training, epoch5, iter0, batch423/1133, batch loss:0.05423509702086449, Training time:145979.99022197723
batch reward last col mean 0.21409086883068085 first col mean 0.22317872941493988 all mean 0.2141982913017273
rl training, epoch5, iter0, batch424/1133, batch loss:0.05220917612314224, Training time:146007.43872523308
batch reward last col mean 0.1923859715461731 first col mean 0.20483994483947754 all mean 0.192526176571846
rl training, epoch5, iter0, batch425/1133, batch loss:0.05074099451303482, Training time:146034.87892484665
batch reward last col mean 0.26655492186546326 first col mean 0.25883957743644714 all mean 0.2663474678993225
rl training, epoch5, iter0, batch426/1133, batch loss:0.0536842979490757, Training time:146062.34097886086
batch reward last col mean 0.24288155138492584 first col mean 0.2420920580625534 all mean 0.24291938543319702
rl training, epoch5, iter0, batch427/1133, batch loss:0.04652423411607742, Training time:146089.9349808693
batch reward last col mean 0.22940504550933838 first col mean 0.22589907050132751 all mean 0.22932499647140503
rl training, epoch5, iter0, batch428/1133, batch loss:0.039113979786634445, Training time:146117.18946409225
batch reward last col mean 0.23057995736598969 first col mean 0.23656247556209564 all mean 0.23059189319610596
rl training, epoch5, iter0, batch429/1133, batch loss:0.04538106545805931, Training time:146145.22300577164
batch reward last col mean 0.22627021372318268 first col mean 0.24327892065048218 all mean 0.22650331258773804
rl training, epoch5, iter0, batch430/1133, batch loss:0.03886650875210762, Training time:146172.26509928703
batch reward last col mean 0.22204606235027313 first col mean 0.22800315916538239 all mean 0.22217409312725067
rl training, epoch5, iter0, batch431/1133, batch loss:0.03848711773753166, Training time:146200.00489401817
batch reward last col mean 0.26040515303611755 first col mean 0.2583445906639099 all mean 0.26032695174217224
rl training, epoch5, iter0, batch432/1133, batch loss:0.03617747873067856, Training time:146228.25177907944
batch reward last col mean 0.22249725461006165 first col mean 0.22842110693454742 all mean 0.22256293892860413
rl training, epoch5, iter0, batch433/1133, batch loss:0.06314761191606522, Training time:146256.38260006905
batch reward last col mean 0.2369709312915802 first col mean 0.23954343795776367 all mean 0.23699241876602173
rl training, epoch5, iter0, batch434/1133, batch loss:0.04645124077796936, Training time:146283.49873280525
batch reward last col mean 0.22369638085365295 first col mean 0.22749008238315582 all mean 0.22371076047420502
rl training, epoch5, iter0, batch435/1133, batch loss:0.04081558436155319, Training time:146310.42894172668
batch reward last col mean 0.2575616240501404 first col mean 0.2486138790845871 all mean 0.25752878189086914
rl training, epoch5, iter0, batch436/1133, batch loss:0.057000767439603806, Training time:146337.46936893463
batch reward last col mean 0.2831657826900482 first col mean 0.27593737840652466 all mean 0.2829396426677704
rl training, epoch5, iter0, batch437/1133, batch loss:0.045791346579790115, Training time:146364.55339241028
batch reward last col mean 0.26998743414878845 first col mean 0.2654780149459839 all mean 0.2700197994709015
rl training, epoch5, iter0, batch438/1133, batch loss:0.0510106086730957, Training time:146391.8446276188
batch reward last col mean 0.24507935345172882 first col mean 0.24649891257286072 all mean 0.24533987045288086
rl training, epoch5, iter0, batch439/1133, batch loss:0.059579554945230484, Training time:146419.07741856575
batch reward last col mean 0.23680880665779114 first col mean 0.2471456527709961 all mean 0.2368614673614502
rl training, epoch5, iter0, batch440/1133, batch loss:0.042842961847782135, Training time:146446.26330971718
batch reward last col mean 0.26000046730041504 first col mean 0.2597346603870392 all mean 0.2598479092121124
rl training, epoch5, iter0, batch441/1133, batch loss:0.051962558180093765, Training time:146473.39839959145
batch reward last col mean 0.2666373550891876 first col mean 0.28598010540008545 all mean 0.2668008506298065
rl training, epoch5, iter0, batch442/1133, batch loss:0.0555269718170166, Training time:146500.58691692352
batch reward last col mean 0.2603514492511749 first col mean 0.2825285792350769 all mean 0.26087692379951477
rl training, epoch5, iter0, batch443/1133, batch loss:0.05246363580226898, Training time:146527.84043693542
batch reward last col mean 0.28560712933540344 first col mean 0.2865723967552185 all mean 0.2855585217475891
rl training, epoch5, iter0, batch444/1133, batch loss:0.028227120637893677, Training time:146555.4711458683
batch reward last col mean 0.24615280330181122 first col mean 0.2586365044116974 all mean 0.2464161068201065
rl training, epoch5, iter0, batch445/1133, batch loss:0.024358287453651428, Training time:146582.57168650627
batch reward last col mean 0.27828729152679443 first col mean 0.2883991301059723 all mean 0.2783251106739044
rl training, epoch5, iter0, batch446/1133, batch loss:0.05429979786276817, Training time:146609.78650522232
batch reward last col mean 0.2786514461040497 first col mean 0.26526445150375366 all mean 0.278457373380661
rl training, epoch5, iter0, batch447/1133, batch loss:0.06163012981414795, Training time:146636.88333559036
batch reward last col mean 0.2675465941429138 first col mean 0.25699126720428467 all mean 0.26746997237205505
rl training, epoch5, iter0, batch448/1133, batch loss:0.03344359248876572, Training time:146664.08247876167
batch reward last col mean 0.30208104848861694 first col mean 0.3039683401584625 all mean 0.3022400736808777
rl training, epoch5, iter0, batch449/1133, batch loss:0.02062988094985485, Training time:146691.2064180374
batch reward last col mean 0.265891432762146 first col mean 0.2865544855594635 all mean 0.2661004364490509
rl training, epoch5, iter0, batch450/1133, batch loss:0.02847708947956562, Training time:146719.50203943253
batch reward last col mean 0.25730034708976746 first col mean 0.2590150237083435 all mean 0.2571507692337036
rl training, epoch5, iter0, batch451/1133, batch loss:0.028043916448950768, Training time:146748.22781181335
batch reward last col mean 0.2834709584712982 first col mean 0.29209181666374207 all mean 0.28336912393569946
rl training, epoch5, iter0, batch452/1133, batch loss:0.0468471497297287, Training time:146776.36593461037
batch reward last col mean 0.31301701068878174 first col mean 0.3111262619495392 all mean 0.31287050247192383
rl training, epoch5, iter0, batch453/1133, batch loss:0.02748882956802845, Training time:146803.73469471931
batch reward last col mean 0.23499587178230286 first col mean 0.24850347638130188 all mean 0.23541860282421112
rl training, epoch5, iter0, batch454/1133, batch loss:0.03282979875802994, Training time:146831.27373886108
batch reward last col mean 0.2820779085159302 first col mean 0.3046663701534271 all mean 0.2823731303215027
rl training, epoch5, iter0, batch455/1133, batch loss:0.028850944712758064, Training time:146858.87924098969
batch reward last col mean 0.23705324530601501 first col mean 0.2544655501842499 all mean 0.23736251890659332
rl training, epoch5, iter0, batch456/1133, batch loss:0.029175125062465668, Training time:146886.52588748932
batch reward last col mean 0.35191941261291504 first col mean 0.35213762521743774 all mean 0.3518918752670288
rl training, epoch5, iter0, batch457/1133, batch loss:0.04435872659087181, Training time:146914.15333533287
batch reward last col mean 0.29655781388282776 first col mean 0.29184088110923767 all mean 0.2965129017829895
rl training, epoch5, iter0, batch458/1133, batch loss:0.04960241541266441, Training time:146941.4981045723
batch reward last col mean 0.30047979950904846 first col mean 0.30979281663894653 all mean 0.30070263147354126
rl training, epoch5, iter0, batch459/1133, batch loss:0.032868579030036926, Training time:146968.9254307747
batch reward last col mean 0.28214478492736816 first col mean 0.29054850339889526 all mean 0.2826227843761444
rl training, epoch5, iter0, batch460/1133, batch loss:0.03214206174015999, Training time:146996.163077116
batch reward last col mean 0.2628771662712097 first col mean 0.2715094983577728 all mean 0.26302415132522583
rl training, epoch5, iter0, batch461/1133, batch loss:0.021128572523593903, Training time:147023.4181149006
batch reward last col mean 0.29328012466430664 first col mean 0.29641246795654297 all mean 0.29336658120155334
rl training, epoch5, iter0, batch462/1133, batch loss:0.022556820884346962, Training time:147051.12488389015
batch reward last col mean 0.3268311619758606 first col mean 0.3270251154899597 all mean 0.3266699016094208
rl training, epoch5, iter0, batch463/1133, batch loss:0.0748191699385643, Training time:147078.38981962204
batch reward last col mean 0.30497220158576965 first col mean 0.31107163429260254 all mean 0.3052959740161896
rl training, epoch5, iter0, batch464/1133, batch loss:0.024634741246700287, Training time:147105.63828277588
batch reward last col mean 0.2854756712913513 first col mean 0.26899057626724243 all mean 0.28514623641967773
rl training, epoch5, iter0, batch465/1133, batch loss:0.03333084657788277, Training time:147132.65417671204
batch reward last col mean 0.33968624472618103 first col mean 0.35553601384162903 all mean 0.33964863419532776
rl training, epoch5, iter0, batch466/1133, batch loss:0.049486834555864334, Training time:147159.8774383068
batch reward last col mean 0.29506516456604004 first col mean 0.28252920508384705 all mean 0.2945705056190491
rl training, epoch5, iter0, batch467/1133, batch loss:0.047706007957458496, Training time:147187.37282776833
batch reward last col mean 0.2974795401096344 first col mean 0.30792513489723206 all mean 0.2975599765777588
rl training, epoch5, iter0, batch468/1133, batch loss:0.0401899516582489, Training time:147214.6034874916
batch reward last col mean 0.32380250096321106 first col mean 0.3190741240978241 all mean 0.3235827684402466
rl training, epoch5, iter0, batch469/1133, batch loss:0.04672855883836746, Training time:147241.7237792015
batch reward last col mean 0.3361690640449524 first col mean 0.34082305431365967 all mean 0.3359948396682739
rl training, epoch5, iter0, batch470/1133, batch loss:0.059863340109586716, Training time:147268.95399975777
batch reward last col mean 0.3306688070297241 first col mean 0.3188632130622864 all mean 0.33068153262138367
rl training, epoch5, iter0, batch471/1133, batch loss:0.0508774071931839, Training time:147296.13350343704
batch reward last col mean 0.281211793422699 first col mean 0.3023124635219574 all mean 0.28153303265571594
rl training, epoch5, iter0, batch472/1133, batch loss:0.03508932888507843, Training time:147323.48165655136
batch reward last col mean 0.2807005047798157 first col mean 0.29848840832710266 all mean 0.28115805983543396
rl training, epoch5, iter0, batch473/1133, batch loss:0.033863238990306854, Training time:147351.00334501266
batch reward last col mean 0.3428332209587097 first col mean 0.34054505825042725 all mean 0.34270137548446655
rl training, epoch5, iter0, batch474/1133, batch loss:0.06201808899641037, Training time:147378.13688015938
batch reward last col mean 0.3085760474205017 first col mean 0.31322503089904785 all mean 0.30874329805374146
rl training, epoch5, iter0, batch475/1133, batch loss:0.037293411791324615, Training time:147405.15231895447
batch reward last col mean 0.39265114068984985 first col mean 0.3892928957939148 all mean 0.39260756969451904
rl training, epoch5, iter0, batch476/1133, batch loss:0.05620501935482025, Training time:147432.96112394333
batch reward last col mean 0.30483120679855347 first col mean 0.3091328740119934 all mean 0.30478519201278687
rl training, epoch5, iter0, batch477/1133, batch loss:0.03628382831811905, Training time:147460.28372240067
batch reward last col mean 0.36963650584220886 first col mean 0.3765341639518738 all mean 0.37039995193481445
rl training, epoch5, iter0, batch478/1133, batch loss:0.06563559919595718, Training time:147487.48602890968
batch reward last col mean 0.3253385126590729 first col mean 0.3373537063598633 all mean 0.3263751268386841
rl training, epoch5, iter0, batch479/1133, batch loss:0.07572171092033386, Training time:147514.7937760353
batch reward last col mean 0.3346345126628876 first col mean 0.3606305718421936 all mean 0.33505627512931824
rl training, epoch5, iter0, batch480/1133, batch loss:0.05866783484816551, Training time:147542.14835095406
batch reward last col mean 0.3267578184604645 first col mean 0.3380993902683258 all mean 0.326604425907135
rl training, epoch5, iter0, batch481/1133, batch loss:0.07752203941345215, Training time:147569.48524045944
batch reward last col mean 0.3162240982055664 first col mean 0.323311984539032 all mean 0.31625157594680786
rl training, epoch5, iter0, batch482/1133, batch loss:0.0583173893392086, Training time:147596.77828669548
batch reward last col mean 0.32380878925323486 first col mean 0.33071649074554443 all mean 0.32416802644729614
rl training, epoch5, iter0, batch483/1133, batch loss:0.056885894387960434, Training time:147624.2098686695
batch reward last col mean 0.37302130460739136 first col mean 0.357250839471817 all mean 0.37243035435676575
rl training, epoch5, iter0, batch484/1133, batch loss:0.09267253428697586, Training time:147651.4219970703
batch reward last col mean 0.3024132549762726 first col mean 0.31621143221855164 all mean 0.30256178975105286
rl training, epoch5, iter0, batch485/1133, batch loss:0.08172578364610672, Training time:147678.67108106613
batch reward last col mean 0.3428645133972168 first col mean 0.3312563896179199 all mean 0.34322792291641235
rl training, epoch5, iter0, batch486/1133, batch loss:0.09867274761199951, Training time:147706.4280588627
batch reward last col mean 0.3052162230014801 first col mean 0.3120257258415222 all mean 0.30526840686798096
rl training, epoch5, iter0, batch487/1133, batch loss:0.06590398401021957, Training time:147733.82891273499
batch reward last col mean 0.33755141496658325 first col mean 0.33434242010116577 all mean 0.33722686767578125
rl training, epoch5, iter0, batch488/1133, batch loss:0.11682054400444031, Training time:147761.6088848114
batch reward last col mean 0.39489883184432983 first col mean 0.39248383045196533 all mean 0.3949469029903412
rl training, epoch5, iter0, batch489/1133, batch loss:0.09040424972772598, Training time:147789.0127286911
batch reward last col mean 0.4106302857398987 first col mean 0.42127886414527893 all mean 0.410970002412796
rl training, epoch5, iter0, batch490/1133, batch loss:0.13788986206054688, Training time:147816.52703809738
batch reward last col mean 0.3390539884567261 first col mean 0.35633569955825806 all mean 0.33907511830329895
rl training, epoch5, iter0, batch491/1133, batch loss:0.1545686572790146, Training time:147844.16446065903
batch reward last col mean 0.3658254146575928 first col mean 0.35343700647354126 all mean 0.3642611503601074
rl training, epoch5, iter0, batch492/1133, batch loss:0.1866360753774643, Training time:147872.2149643898
batch reward last col mean 0.3186790347099304 first col mean 0.30213305354118347 all mean 0.3189590871334076
rl training, epoch5, iter0, batch493/1133, batch loss:0.12867234647274017, Training time:147900.05696058273
batch reward last col mean 0.29041221737861633 first col mean 0.2920902371406555 all mean 0.2909327745437622
rl training, epoch5, iter0, batch494/1133, batch loss:0.10510463267564774, Training time:147927.60353541374
batch reward last col mean 0.37357717752456665 first col mean 0.367691308259964 all mean 0.37356215715408325
rl training, epoch5, iter0, batch495/1133, batch loss:0.1682150810956955, Training time:147955.11634492874
batch reward last col mean 0.40847933292388916 first col mean 0.4104152321815491 all mean 0.40849989652633667
rl training, epoch5, iter0, batch496/1133, batch loss:0.1185033768415451, Training time:147983.95715475082
batch reward last col mean 0.34036022424697876 first col mean 0.33366987109184265 all mean 0.33742061257362366
rl training, epoch5, iter0, batch497/1133, batch loss:0.1306881159543991, Training time:148012.32571530342
batch reward last col mean 0.3648083806037903 first col mean 0.36524590849876404 all mean 0.3639168441295624
rl training, epoch5, iter0, batch498/1133, batch loss:0.08034274727106094, Training time:148040.41543841362
batch reward last col mean 0.38305413722991943 first col mean 0.4012364149093628 all mean 0.38671451807022095
rl training, epoch5, iter0, batch499/1133, batch loss:0.11381687968969345, Training time:148069.16718888283
batch reward last col mean 0.351040244102478 first col mean 0.34245988726615906 all mean 0.3559684455394745
rl training, epoch5, iter0, batch500/1133, batch loss:0.12277131527662277, Training time:148098.07039141655
batch reward last col mean 0.3790644109249115 first col mean 0.3656488060951233 all mean 0.3710978329181671
rl training, epoch5, iter0, batch501/1133, batch loss:0.10781755298376083, Training time:148127.2451632023
batch reward last col mean 0.3317373991012573 first col mean 0.36210933327674866 all mean 0.3459315299987793
rl training, epoch5, iter0, batch502/1133, batch loss:0.08917581290006638, Training time:148155.6470720768
batch reward last col mean 0.4118138253688812 first col mean 0.42821183800697327 all mean 0.4161738455295563
rl training, epoch5, iter0, batch503/1133, batch loss:0.11454908549785614, Training time:148183.9651825428
batch reward last col mean 0.31905800104141235 first col mean 0.3242419362068176 all mean 0.31473836302757263
rl training, epoch5, iter0, batch504/1133, batch loss:0.09347105771303177, Training time:148212.2193558216
batch reward last col mean 0.38577568531036377 first col mean 0.37160155177116394 all mean 0.3843793272972107
rl training, epoch5, iter0, batch505/1133, batch loss:0.08273740112781525, Training time:148240.3032078743
batch reward last col mean 0.3704543709754944 first col mean 0.3560217022895813 all mean 0.36020946502685547
rl training, epoch5, iter0, batch506/1133, batch loss:0.07047698646783829, Training time:148268.406570673
batch reward last col mean 0.3345833420753479 first col mean 0.3409973084926605 all mean 0.3365926146507263
rl training, epoch5, iter0, batch507/1133, batch loss:0.0662200003862381, Training time:148296.36817216873
batch reward last col mean 0.35402923822402954 first col mean 0.3695967197418213 all mean 0.35590416193008423
rl training, epoch5, iter0, batch508/1133, batch loss:0.08383404463529587, Training time:148324.49207520485
batch reward last col mean 0.3253641724586487 first col mean 0.3638550043106079 all mean 0.33861953020095825
rl training, epoch5, iter0, batch509/1133, batch loss:0.07981039583683014, Training time:148352.38385653496
batch reward last col mean 0.38586127758026123 first col mean 0.36401230096817017 all mean 0.38484057784080505
rl training, epoch5, iter0, batch510/1133, batch loss:0.08050922304391861, Training time:148380.62034273148
batch reward last col mean 0.29760488867759705 first col mean 0.32072192430496216 all mean 0.3132477402687073
rl training, epoch5, iter0, batch511/1133, batch loss:0.06106198579072952, Training time:148408.5343720913
batch reward last col mean 0.35558590292930603 first col mean 0.3763672113418579 all mean 0.36377641558647156
rl training, epoch5, iter0, batch512/1133, batch loss:0.06766388565301895, Training time:148436.2812309265
batch reward last col mean 0.41580575704574585 first col mean 0.3926478624343872 all mean 0.40430188179016113
rl training, epoch5, iter0, batch513/1133, batch loss:0.07263311743736267, Training time:148464.32042193413
batch reward last col mean 0.3383598327636719 first col mean 0.3304801881313324 all mean 0.3374168574810028
rl training, epoch5, iter0, batch514/1133, batch loss:0.05336442589759827, Training time:148492.38985586166
batch reward last col mean 0.35119879245758057 first col mean 0.3512253761291504 all mean 0.3570917248725891
rl training, epoch5, iter0, batch515/1133, batch loss:0.04261781647801399, Training time:148520.02944135666
batch reward last col mean 0.32858896255493164 first col mean 0.3708914518356323 all mean 0.3341113030910492
rl training, epoch5, iter0, batch516/1133, batch loss:0.03595515713095665, Training time:148547.99865746498
batch reward last col mean 0.3276616930961609 first col mean 0.3895828127861023 all mean 0.3409564793109894
rl training, epoch5, iter0, batch517/1133, batch loss:0.03041679412126541, Training time:148575.88701677322
batch reward last col mean 0.3917234539985657 first col mean 0.3973754942417145 all mean 0.402599036693573
rl training, epoch5, iter0, batch518/1133, batch loss:0.02760724537074566, Training time:148603.64428305626
batch reward last col mean 0.3568752110004425 first col mean 0.3688734769821167 all mean 0.34970763325691223
rl training, epoch5, iter0, batch519/1133, batch loss:0.02632751129567623, Training time:148632.01194429398
batch reward last col mean 0.3344881534576416 first col mean 0.36259710788726807 all mean 0.3426499366760254
rl training, epoch5, iter0, batch520/1133, batch loss:0.016285406425595284, Training time:148660.20687103271
batch reward last col mean 0.43299055099487305 first col mean 0.44473686814308167 all mean 0.4258989989757538
rl training, epoch5, iter0, batch521/1133, batch loss:0.016755850985646248, Training time:148687.83701252937
batch reward last col mean 0.3697483539581299 first col mean 0.4196930229663849 all mean 0.3799059987068176
rl training, epoch5, iter0, batch522/1133, batch loss:0.014809953980147839, Training time:148715.83156585693
batch reward last col mean 0.4381410479545593 first col mean 0.44936662912368774 all mean 0.45077767968177795
rl training, epoch5, iter0, batch523/1133, batch loss:0.021867308765649796, Training time:148743.41224861145
batch reward last col mean 0.43009498715400696 first col mean 0.44897499680519104 all mean 0.44660326838493347
rl training, epoch5, iter0, batch524/1133, batch loss:0.011924291960895061, Training time:148770.94704294205
batch reward last col mean 0.4371725916862488 first col mean 0.48755499720573425 all mean 0.4564289450645447
rl training, epoch5, iter0, batch525/1133, batch loss:0.013642101548612118, Training time:148798.6140077114
batch reward last col mean 0.4214093089103699 first col mean 0.45546120405197144 all mean 0.4353298544883728
rl training, epoch5, iter0, batch526/1133, batch loss:0.010094216093420982, Training time:148826.13131284714
batch reward last col mean 0.516311526298523 first col mean 0.5148748159408569 all mean 0.5224456787109375
rl training, epoch5, iter0, batch527/1133, batch loss:0.012848933227360249, Training time:148853.76755070686
batch reward last col mean 0.47101444005966187 first col mean 0.4764197766780853 all mean 0.4739711284637451
rl training, epoch5, iter0, batch528/1133, batch loss:0.005950181279331446, Training time:148881.2628982067
batch reward last col mean 0.4720345139503479 first col mean 0.4831574857234955 all mean 0.4667746126651764
rl training, epoch5, iter0, batch529/1133, batch loss:0.009885445237159729, Training time:148908.50176739693
batch reward last col mean 0.4617069363594055 first col mean 0.46918970346450806 all mean 0.467480331659317
rl training, epoch5, iter0, batch530/1133, batch loss:0.006542070768773556, Training time:148935.53646492958
batch reward last col mean 0.4864751994609833 first col mean 0.5100088715553284 all mean 0.49237602949142456
rl training, epoch5, iter0, batch531/1133, batch loss:0.008481867611408234, Training time:148962.8236374855
batch reward last col mean 0.47406119108200073 first col mean 0.4943313002586365 all mean 0.4784921109676361
rl training, epoch5, iter0, batch532/1133, batch loss:0.006434377282857895, Training time:148989.9453060627
batch reward last col mean 0.5421739220619202 first col mean 0.5610577464103699 all mean 0.5483970046043396
rl training, epoch5, iter0, batch533/1133, batch loss:0.005588913802057505, Training time:149017.96684408188
batch reward last col mean 0.45595353841781616 first col mean 0.4691842198371887 all mean 0.45663583278656006
rl training, epoch5, iter0, batch534/1133, batch loss:0.0063854786567389965, Training time:149045.036755085
batch reward last col mean 0.5030266642570496 first col mean 0.5084050297737122 all mean 0.5034399628639221
rl training, epoch5, iter0, batch535/1133, batch loss:0.004780969582498074, Training time:149072.76508569717
batch reward last col mean 0.4658917188644409 first col mean 0.4983016550540924 all mean 0.4688740670681
rl training, epoch5, iter0, batch536/1133, batch loss:0.008069183677434921, Training time:149100.03527283669
batch reward last col mean 0.4989665150642395 first col mean 0.5127227306365967 all mean 0.49864456057548523
rl training, epoch5, iter0, batch537/1133, batch loss:0.0046722982078790665, Training time:149128.0067756176
batch reward last col mean 0.5221791863441467 first col mean 0.5098115801811218 all mean 0.5208590626716614
rl training, epoch5, iter0, batch538/1133, batch loss:0.005418639630079269, Training time:149155.82248592377
batch reward last col mean 0.5099937915802002 first col mean 0.4985155761241913 all mean 0.5151312351226807
rl training, epoch5, iter0, batch539/1133, batch loss:0.00555080221965909, Training time:149183.53966927528
batch reward last col mean 0.5417220592498779 first col mean 0.5302110910415649 all mean 0.5406275391578674
rl training, epoch5, iter0, batch540/1133, batch loss:0.0034497256856411695, Training time:149211.29474067688
batch reward last col mean 0.5169841051101685 first col mean 0.5297996997833252 all mean 0.5167805552482605
rl training, epoch5, iter0, batch541/1133, batch loss:0.0030734953470528126, Training time:149239.2369146347
batch reward last col mean 0.5109528303146362 first col mean 0.5181899070739746 all mean 0.5147097110748291
rl training, epoch5, iter0, batch542/1133, batch loss:0.003885958343744278, Training time:149266.98488926888
batch reward last col mean 0.6207942962646484 first col mean 0.621810793876648 all mean 0.6197008490562439
rl training, epoch5, iter0, batch543/1133, batch loss:0.003667948767542839, Training time:149294.6079597473
batch reward last col mean 0.5170209407806396 first col mean 0.520187497138977 all mean 0.5180871486663818
rl training, epoch5, iter0, batch544/1133, batch loss:0.0026396254543215036, Training time:149322.15706205368
batch reward last col mean 0.5564314126968384 first col mean 0.548204243183136 all mean 0.5556861162185669
rl training, epoch5, iter0, batch545/1133, batch loss:0.003946449141949415, Training time:149349.7281680107
batch reward last col mean 0.588353157043457 first col mean 0.5827339291572571 all mean 0.5906530022621155
rl training, epoch5, iter0, batch546/1133, batch loss:0.003718000603839755, Training time:149377.3491411209
batch reward last col mean 0.5990793704986572 first col mean 0.605211079120636 all mean 0.6028851866722107
rl training, epoch5, iter0, batch547/1133, batch loss:0.003502330742776394, Training time:149404.82417798042
batch reward last col mean 0.602271556854248 first col mean 0.5843355655670166 all mean 0.6011443734169006
rl training, epoch5, iter0, batch548/1133, batch loss:0.002574609126895666, Training time:149432.23023724556
batch reward last col mean 0.5428282022476196 first col mean 0.5475205183029175 all mean 0.5453669428825378
rl training, epoch5, iter0, batch549/1133, batch loss:0.003623556811362505, Training time:149459.6727731228
batch reward last col mean 0.5224252939224243 first col mean 0.5387213230133057 all mean 0.5222158432006836
rl training, epoch5, iter0, batch550/1133, batch loss:0.004364409018307924, Training time:149487.30649471283
batch reward last col mean 0.5312890410423279 first col mean 0.5358444452285767 all mean 0.5312709808349609
rl training, epoch5, iter0, batch551/1133, batch loss:0.0028199120424687862, Training time:149514.837692976
batch reward last col mean 0.5731323957443237 first col mean 0.5793550610542297 all mean 0.5727962255477905
rl training, epoch5, iter0, batch552/1133, batch loss:0.005024275742471218, Training time:149542.2339141369
batch reward last col mean 0.6028580665588379 first col mean 0.6236125826835632 all mean 0.6062325835227966
rl training, epoch5, iter0, batch553/1133, batch loss:0.0038374874275177717, Training time:149570.0781469345
batch reward last col mean 0.5740610361099243 first col mean 0.5795347690582275 all mean 0.5743166208267212
rl training, epoch5, iter0, batch554/1133, batch loss:0.0023932885378599167, Training time:149597.37073540688
batch reward last col mean 0.5574196577072144 first col mean 0.5617370009422302 all mean 0.5565053224563599
rl training, epoch5, iter0, batch555/1133, batch loss:0.004284136462956667, Training time:149624.56966161728
batch reward last col mean 0.649846613407135 first col mean 0.6518909931182861 all mean 0.6492562890052795
rl training, epoch5, iter0, batch556/1133, batch loss:0.003549724817276001, Training time:149652.03266763687
batch reward last col mean 0.5617096424102783 first col mean 0.5764761567115784 all mean 0.5610215067863464
rl training, epoch5, iter0, batch557/1133, batch loss:0.0018556108698248863, Training time:149679.25131559372
batch reward last col mean 0.5997499823570251 first col mean 0.586374819278717 all mean 0.599063515663147
rl training, epoch5, iter0, batch558/1133, batch loss:0.002502672839909792, Training time:149706.75049734116
batch reward last col mean 0.5544188022613525 first col mean 0.5684242844581604 all mean 0.5543835759162903
rl training, epoch5, iter0, batch559/1133, batch loss:0.002752535045146942, Training time:149734.32794189453
batch reward last col mean 0.5894716382026672 first col mean 0.588362991809845 all mean 0.5924702882766724
rl training, epoch5, iter0, batch560/1133, batch loss:0.0015581867191940546, Training time:149761.54992341995
batch reward last col mean 0.6051409244537354 first col mean 0.6007901430130005 all mean 0.604486882686615
rl training, epoch5, iter0, batch561/1133, batch loss:0.002424345351755619, Training time:149788.84418225288
batch reward last col mean 0.6166993379592896 first col mean 0.6249259114265442 all mean 0.618807852268219
rl training, epoch5, iter0, batch562/1133, batch loss:0.0029083865229040384, Training time:149816.0061724186
batch reward last col mean 0.6810813546180725 first col mean 0.6647415161132812 all mean 0.6806127429008484
rl training, epoch5, iter0, batch563/1133, batch loss:0.0024470402859151363, Training time:149843.5501601696
batch reward last col mean 0.5791066884994507 first col mean 0.5777100324630737 all mean 0.5796077847480774
rl training, epoch5, iter0, batch564/1133, batch loss:0.002765101147815585, Training time:149870.72526669502
batch reward last col mean 0.5911620855331421 first col mean 0.606510579586029 all mean 0.5928264856338501
rl training, epoch5, iter0, batch565/1133, batch loss:0.002540293149650097, Training time:149897.88323044777
batch reward last col mean 0.6120947003364563 first col mean 0.604272186756134 all mean 0.611545205116272
rl training, epoch5, iter0, batch566/1133, batch loss:0.002101703081279993, Training time:149924.90461874008
batch reward last col mean 0.5355291962623596 first col mean 0.5417289733886719 all mean 0.5352446436882019
rl training, epoch5, iter0, batch567/1133, batch loss:0.0023509864695370197, Training time:149952.35094499588
batch reward last col mean 0.6111061573028564 first col mean 0.6141748428344727 all mean 0.6106244325637817
rl training, epoch5, iter0, batch568/1133, batch loss:0.0018656571628525853, Training time:149979.69005036354
batch reward last col mean 0.6223527789115906 first col mean 0.6331518888473511 all mean 0.6227537393569946
rl training, epoch5, iter0, batch569/1133, batch loss:0.003770329523831606, Training time:150006.7743051052
batch reward last col mean 0.5761209726333618 first col mean 0.5630950927734375 all mean 0.5756018757820129
rl training, epoch5, iter0, batch570/1133, batch loss:0.002128508174791932, Training time:150033.83082413673
batch reward last col mean 0.5991451740264893 first col mean 0.6089671850204468 all mean 0.6005108952522278
rl training, epoch5, iter0, batch571/1133, batch loss:0.002684616483747959, Training time:150060.91138339043
batch reward last col mean 0.6003652811050415 first col mean 0.5926709771156311 all mean 0.5999249219894409
rl training, epoch5, iter0, batch572/1133, batch loss:0.0033090095967054367, Training time:150088.62014484406
batch reward last col mean 0.5635057687759399 first col mean 0.5367375612258911 all mean 0.562720000743866
rl training, epoch5, iter0, batch573/1133, batch loss:0.0021830995101481676, Training time:150115.74541068077
batch reward last col mean 0.5827709436416626 first col mean 0.59443199634552 all mean 0.5846968293190002
rl training, epoch5, iter0, batch574/1133, batch loss:0.0013021188788115978, Training time:150143.452075243
batch reward last col mean 0.6422544717788696 first col mean 0.6423795819282532 all mean 0.6449355483055115
rl training, epoch5, iter0, batch575/1133, batch loss:0.0027852754574269056, Training time:150171.17979884148
batch reward last col mean 0.6460017561912537 first col mean 0.650101900100708 all mean 0.6459210515022278
rl training, epoch5, iter0, batch576/1133, batch loss:0.001750680268742144, Training time:150198.1388411522
batch reward last col mean 0.6229107975959778 first col mean 0.6249257326126099 all mean 0.6223487257957458
rl training, epoch5, iter0, batch577/1133, batch loss:0.0017105709994211793, Training time:150225.39421248436
batch reward last col mean 0.6048905849456787 first col mean 0.6009317636489868 all mean 0.6043691635131836
rl training, epoch5, iter0, batch578/1133, batch loss:0.0013602373655885458, Training time:150252.5271935463
batch reward last col mean 0.505363404750824 first col mean 0.5150414705276489 all mean 0.5100192427635193
rl training, epoch5, iter0, batch579/1133, batch loss:0.001278580748476088, Training time:150279.58814835548
batch reward last col mean 0.647649347782135 first col mean 0.6594811677932739 all mean 0.6473289728164673
rl training, epoch5, iter0, batch580/1133, batch loss:0.0015284745022654533, Training time:150307.16515684128
batch reward last col mean 0.6386542916297913 first col mean 0.6191226243972778 all mean 0.6379004716873169
rl training, epoch5, iter0, batch581/1133, batch loss:0.002845924813300371, Training time:150334.16399240494
batch reward last col mean 0.5600507259368896 first col mean 0.5763174295425415 all mean 0.5599029064178467
rl training, epoch5, iter0, batch582/1133, batch loss:0.0012405747547745705, Training time:150361.3435266018
batch reward last col mean 0.5777972936630249 first col mean 0.5749214887619019 all mean 0.5771458148956299
rl training, epoch5, iter0, batch583/1133, batch loss:0.0009859048295766115, Training time:150388.0761256218
batch reward last col mean 0.5715295076370239 first col mean 0.574843168258667 all mean 0.5710344314575195
rl training, epoch5, iter0, batch584/1133, batch loss:0.0012299440568313003, Training time:150415.11597919464
batch reward last col mean 0.5780131816864014 first col mean 0.5911890864372253 all mean 0.5777893662452698
rl training, epoch5, iter0, batch585/1133, batch loss:0.0013788739452138543, Training time:150442.12310290337
batch reward last col mean 0.5768512487411499 first col mean 0.5805573463439941 all mean 0.5763220191001892
rl training, epoch5, iter0, batch586/1133, batch loss:0.0009415537351742387, Training time:150468.81699872017
batch reward last col mean 0.5733470320701599 first col mean 0.5657268762588501 all mean 0.5727100372314453
rl training, epoch5, iter0, batch587/1133, batch loss:0.002538298722356558, Training time:150496.096460104
batch reward last col mean 0.5560595989227295 first col mean 0.5566993355751038 all mean 0.5563477277755737
rl training, epoch5, iter0, batch588/1133, batch loss:0.002697818912565708, Training time:150523.38680148125
batch reward last col mean 0.6200132369995117 first col mean 0.6264871954917908 all mean 0.6217418909072876
rl training, epoch5, iter0, batch589/1133, batch loss:0.0013798368163406849, Training time:150550.69542312622
batch reward last col mean 0.5950328707695007 first col mean 0.5971494913101196 all mean 0.5956834554672241
rl training, epoch5, iter0, batch590/1133, batch loss:0.002096590120345354, Training time:150578.2750608921
batch reward last col mean 0.6243916749954224 first col mean 0.6227380037307739 all mean 0.6237945556640625
rl training, epoch5, iter0, batch591/1133, batch loss:0.001874350244179368, Training time:150605.95866823196
batch reward last col mean 0.6069664359092712 first col mean 0.6052446365356445 all mean 0.6065136194229126
rl training, epoch5, iter0, batch592/1133, batch loss:0.0015382471028715372, Training time:150634.77913546562
batch reward last col mean 0.5576058030128479 first col mean 0.557495653629303 all mean 0.5572936534881592
rl training, epoch5, iter0, batch593/1133, batch loss:0.0014118164544925094, Training time:150663.51674985886
batch reward last col mean 0.5768584609031677 first col mean 0.5703601837158203 all mean 0.5768069624900818
rl training, epoch5, iter0, batch594/1133, batch loss:0.0008387140114791691, Training time:150692.33180069923
batch reward last col mean 0.5984411239624023 first col mean 0.5992192625999451 all mean 0.5981361865997314
rl training, epoch5, iter0, batch595/1133, batch loss:0.002224924508482218, Training time:150719.68968153
batch reward last col mean 0.6572064757347107 first col mean 0.6409451961517334 all mean 0.6562973260879517
rl training, epoch5, iter0, batch596/1133, batch loss:0.002733866684138775, Training time:150747.82296848297
batch reward last col mean 0.5928747653961182 first col mean 0.6090437769889832 all mean 0.5927132368087769
rl training, epoch5, iter0, batch597/1133, batch loss:0.0023942526895552874, Training time:150775.78375172615
batch reward last col mean 0.5908046364784241 first col mean 0.6077048778533936 all mean 0.5917820930480957
rl training, epoch5, iter0, batch598/1133, batch loss:0.0013412849511951208, Training time:150803.27468585968
batch reward last col mean 0.6366944313049316 first col mean 0.6447398066520691 all mean 0.6369976997375488
rl training, epoch5, iter0, batch599/1133, batch loss:0.0021275277249515057, Training time:150831.21356892586
batch reward last col mean 0.5585206151008606 first col mean 0.557348906993866 all mean 0.5583966970443726
rl training, epoch5, iter0, batch600/1133, batch loss:0.0016872734995558858, Training time:150859.60765981674
batch reward last col mean 0.6206749677658081 first col mean 0.639746367931366 all mean 0.6222084760665894
rl training, epoch5, iter0, batch601/1133, batch loss:0.0026847422122955322, Training time:150887.66793489456
batch reward last col mean 0.6467981934547424 first col mean 0.647838830947876 all mean 0.6464830040931702
rl training, epoch5, iter0, batch602/1133, batch loss:0.0022384049370884895, Training time:150915.8276758194
batch reward last col mean 0.5750179290771484 first col mean 0.5736391544342041 all mean 0.5746292471885681
rl training, epoch5, iter0, batch603/1133, batch loss:0.0007563920225948095, Training time:150943.8492424488
batch reward last col mean 0.6025525331497192 first col mean 0.606631875038147 all mean 0.602090060710907
rl training, epoch5, iter0, batch604/1133, batch loss:0.0022220611572265625, Training time:150971.5763273239
batch reward last col mean 0.6373653411865234 first col mean 0.6373386383056641 all mean 0.6435148119926453
rl training, epoch5, iter0, batch605/1133, batch loss:0.0017772240098565817, Training time:150999.91497516632
batch reward last col mean 0.6144135594367981 first col mean 0.6267123222351074 all mean 0.6177167892456055
rl training, epoch5, iter0, batch606/1133, batch loss:0.002506104065105319, Training time:151027.21076989174
batch reward last col mean 0.602087676525116 first col mean 0.6184508800506592 all mean 0.6069488525390625
rl training, epoch5, iter0, batch607/1133, batch loss:0.0015919060679152608, Training time:151054.58080267906
batch reward last col mean 0.6454203128814697 first col mean 0.6476883888244629 all mean 0.6449849009513855
rl training, epoch5, iter0, batch608/1133, batch loss:0.0017616617260500789, Training time:151082.05127072334
batch reward last col mean 0.5984712839126587 first col mean 0.628479540348053 all mean 0.6030292510986328
rl training, epoch5, iter0, batch609/1133, batch loss:0.0021887782495468855, Training time:151109.5808119774
batch reward last col mean 0.6348683834075928 first col mean 0.629591166973114 all mean 0.6344820857048035
rl training, epoch5, iter0, batch610/1133, batch loss:0.0027643945068120956, Training time:151137.24311733246
batch reward last col mean 0.5662913918495178 first col mean 0.5673941373825073 all mean 0.5662571787834167
rl training, epoch5, iter0, batch611/1133, batch loss:0.0009541998151689768, Training time:151165.37098002434
batch reward last col mean 0.6262249946594238 first col mean 0.6267162561416626 all mean 0.6257868409156799
rl training, epoch5, iter0, batch612/1133, batch loss:0.0009776547085493803, Training time:151192.85726451874
batch reward last col mean 0.5702939033508301 first col mean 0.5634090304374695 all mean 0.5700279474258423
rl training, epoch5, iter0, batch613/1133, batch loss:0.0008336412138305604, Training time:151220.25912332535
batch reward last col mean 0.5977325439453125 first col mean 0.6047989130020142 all mean 0.5975019931793213
rl training, epoch5, iter0, batch614/1133, batch loss:0.0012044738978147507, Training time:151248.05681347847
batch reward last col mean 0.6115186810493469 first col mean 0.6247262358665466 all mean 0.6114538311958313
rl training, epoch5, iter0, batch615/1133, batch loss:0.0026517545338720083, Training time:151275.54689860344
batch reward last col mean 0.6147197484970093 first col mean 0.6193687319755554 all mean 0.6145328283309937
rl training, epoch5, iter0, batch616/1133, batch loss:0.0006203328957781196, Training time:151303.43754053116
batch reward last col mean 0.6508538722991943 first col mean 0.6538548469543457 all mean 0.6529457569122314
rl training, epoch5, iter0, batch617/1133, batch loss:0.002934260293841362, Training time:151330.79168963432
batch reward last col mean 0.5996507406234741 first col mean 0.6051467061042786 all mean 0.5991972088813782
rl training, epoch5, iter0, batch618/1133, batch loss:0.0023543720599263906, Training time:151358.55119466782
batch reward last col mean 0.6145676374435425 first col mean 0.6296600103378296 all mean 0.6173043847084045
rl training, epoch5, iter0, batch619/1133, batch loss:0.003129945369437337, Training time:151386.6486735344
batch reward last col mean 0.5693631768226624 first col mean 0.5726587772369385 all mean 0.5690481066703796
rl training, epoch5, iter0, batch620/1133, batch loss:0.003181000705808401, Training time:151414.24680900574
batch reward last col mean 0.5778406262397766 first col mean 0.5694398880004883 all mean 0.5774364471435547
rl training, epoch5, iter0, batch621/1133, batch loss:0.0021432284265756607, Training time:151441.24233937263
batch reward last col mean 0.6160576343536377 first col mean 0.6070312857627869 all mean 0.6154615879058838
rl training, epoch5, iter0, batch622/1133, batch loss:0.002067530993372202, Training time:151468.69303941727
batch reward last col mean 0.671052098274231 first col mean 0.6684317588806152 all mean 0.6705212593078613
rl training, epoch5, iter0, batch623/1133, batch loss:0.0013136330526322126, Training time:151496.23477101326
batch reward last col mean 0.6151135563850403 first col mean 0.6330425143241882 all mean 0.6160621047019958
rl training, epoch5, iter0, batch624/1133, batch loss:0.0009053930407389998, Training time:151524.04371881485
batch reward last col mean 0.5863152742385864 first col mean 0.5945318341255188 all mean 0.5863664150238037
rl training, epoch5, iter0, batch625/1133, batch loss:0.0005359449423849583, Training time:151552.38838148117
batch reward last col mean 0.577434778213501 first col mean 0.5911552309989929 all mean 0.580722451210022
rl training, epoch5, iter0, batch626/1133, batch loss:0.0017559680854901671, Training time:151581.1623761654
batch reward last col mean 0.6255218386650085 first col mean 0.6414591670036316 all mean 0.6253093481063843
rl training, epoch5, iter0, batch627/1133, batch loss:0.0022974563762545586, Training time:151608.39359474182
batch reward last col mean 0.6255210041999817 first col mean 0.630929708480835 all mean 0.6274062395095825
rl training, epoch5, iter0, batch628/1133, batch loss:0.0015675834147259593, Training time:151636.21280145645
batch reward last col mean 0.6003119349479675 first col mean 0.5952049493789673 all mean 0.5999868512153625
rl training, epoch5, iter0, batch629/1133, batch loss:0.002471956890076399, Training time:151663.8622982502
batch reward last col mean 0.5831257104873657 first col mean 0.5991544127464294 all mean 0.5850260853767395
rl training, epoch5, iter0, batch630/1133, batch loss:0.004238741006702185, Training time:151691.60618925095
batch reward last col mean 0.6557056307792664 first col mean 0.6601605415344238 all mean 0.6555265188217163
rl training, epoch5, iter0, batch631/1133, batch loss:0.0019447568338364363, Training time:151719.42186570168
batch reward last col mean 0.5453795194625854 first col mean 0.5609378218650818 all mean 0.5495662689208984
rl training, epoch5, iter0, batch632/1133, batch loss:0.0010812014807015657, Training time:151746.82456612587
batch reward last col mean 0.5952422618865967 first col mean 0.5953773260116577 all mean 0.5948166251182556
rl training, epoch5, iter0, batch633/1133, batch loss:0.0008045354625210166, Training time:151774.55233049393
batch reward last col mean 0.6031507849693298 first col mean 0.6173781156539917 all mean 0.6117497682571411
rl training, epoch5, iter0, batch634/1133, batch loss:0.0017373759765177965, Training time:151802.40447998047
batch reward last col mean 0.6445560455322266 first col mean 0.6403573751449585 all mean 0.6441630125045776
rl training, epoch5, iter0, batch635/1133, batch loss:0.0015002064174041152, Training time:151830.70393157005
batch reward last col mean 0.5880036354064941 first col mean 0.5835416913032532 all mean 0.5875784754753113
rl training, epoch5, iter0, batch636/1133, batch loss:0.0011037036310881376, Training time:151858.55452561378
batch reward last col mean 0.6144654750823975 first col mean 0.6256486773490906 all mean 0.6143730878829956
rl training, epoch5, iter0, batch637/1133, batch loss:0.0011403359239920974, Training time:151886.8402633667
batch reward last col mean 0.6003836989402771 first col mean 0.6049572825431824 all mean 0.6000549793243408
rl training, epoch5, iter0, batch638/1133, batch loss:0.0008301325724460185, Training time:151914.09107995033
batch reward last col mean 0.5753348469734192 first col mean 0.5884442329406738 all mean 0.5754530429840088
rl training, epoch5, iter0, batch639/1133, batch loss:0.001538048149086535, Training time:151941.46996331215
batch reward last col mean 0.6116687059402466 first col mean 0.6182737350463867 all mean 0.6113841533660889
rl training, epoch5, iter0, batch640/1133, batch loss:0.001680357614532113, Training time:151968.48511576653
batch reward last col mean 0.5990483164787292 first col mean 0.6046152114868164 all mean 0.5988607406616211
rl training, epoch5, iter0, batch641/1133, batch loss:0.0006595234735868871, Training time:151995.59193372726
batch reward last col mean 0.6746797561645508 first col mean 0.6530662775039673 all mean 0.674004077911377
rl training, epoch5, iter0, batch642/1133, batch loss:0.0026072252076119184, Training time:152022.52613949776
batch reward last col mean 0.5812127590179443 first col mean 0.589471697807312 all mean 0.5809786319732666
rl training, epoch5, iter0, batch643/1133, batch loss:0.0014570856001228094, Training time:152049.8031771183
batch reward last col mean 0.6026237607002258 first col mean 0.5849987268447876 all mean 0.6021351218223572
rl training, epoch5, iter0, batch644/1133, batch loss:0.002511864760890603, Training time:152077.24371099472
batch reward last col mean 0.6238349676132202 first col mean 0.6332284212112427 all mean 0.6254701614379883
rl training, epoch5, iter0, batch645/1133, batch loss:0.001309984247200191, Training time:152104.56924247742
batch reward last col mean 0.5480610132217407 first col mean 0.5549299716949463 all mean 0.5479353070259094
rl training, epoch5, iter0, batch646/1133, batch loss:0.001288958708755672, Training time:152131.6655204296
batch reward last col mean 0.6148523688316345 first col mean 0.6085988879203796 all mean 0.614552915096283
rl training, epoch5, iter0, batch647/1133, batch loss:0.0022747707553207874, Training time:152158.6356294155
batch reward last col mean 0.6091267466545105 first col mean 0.6177346706390381 all mean 0.6089300513267517
rl training, epoch5, iter0, batch648/1133, batch loss:0.0011874111369252205, Training time:152185.74682211876
batch reward last col mean 0.5817263722419739 first col mean 0.5921847820281982 all mean 0.5816602110862732
rl training, epoch5, iter0, batch649/1133, batch loss:0.0007305279723368585, Training time:152212.752256155
batch reward last col mean 0.6297492384910583 first col mean 0.6270532608032227 all mean 0.6326513290405273
rl training, epoch5, iter0, batch650/1133, batch loss:0.000777705863583833, Training time:152239.59368681908
batch reward last col mean 0.6303827166557312 first col mean 0.6338003873825073 all mean 0.6306934356689453
rl training, epoch5, iter0, batch651/1133, batch loss:0.0017970646731555462, Training time:152267.06121349335
batch reward last col mean 0.6275970339775085 first col mean 0.6313261985778809 all mean 0.6278142929077148
rl training, epoch5, iter0, batch652/1133, batch loss:0.0022356496192514896, Training time:152294.39089155197
batch reward last col mean 0.5772725939750671 first col mean 0.5800114870071411 all mean 0.5770524144172668
rl training, epoch5, iter0, batch653/1133, batch loss:0.001411269186064601, Training time:152321.69855380058
batch reward last col mean 0.5851719379425049 first col mean 0.5991699695587158 all mean 0.585034966468811
rl training, epoch5, iter0, batch654/1133, batch loss:0.0011264353524893522, Training time:152348.45785689354
batch reward last col mean 0.6537103652954102 first col mean 0.6453009247779846 all mean 0.6533976793289185
rl training, epoch5, iter0, batch655/1133, batch loss:0.0011045936262235045, Training time:152375.4225833416
batch reward last col mean 0.6281750202178955 first col mean 0.6253989934921265 all mean 0.6278221607208252
rl training, epoch5, iter0, batch656/1133, batch loss:0.0013530142605304718, Training time:152402.76903057098
batch reward last col mean 0.6588943600654602 first col mean 0.6605181097984314 all mean 0.6584498882293701
rl training, epoch5, iter0, batch657/1133, batch loss:0.0009755279752425849, Training time:152429.68415737152
batch reward last col mean 0.6252801418304443 first col mean 0.6291505694389343 all mean 0.625127375125885
rl training, epoch5, iter0, batch658/1133, batch loss:0.0012418609112501144, Training time:152456.95850658417
batch reward last col mean 0.6250274777412415 first col mean 0.6112565994262695 all mean 0.6246780157089233
rl training, epoch5, iter0, batch659/1133, batch loss:0.0022473742719739676, Training time:152483.81854248047
batch reward last col mean 0.6020371317863464 first col mean 0.6079004406929016 all mean 0.6020289063453674
rl training, epoch5, iter0, batch660/1133, batch loss:0.0018389023607596755, Training time:152510.9178495407
batch reward last col mean 0.6422786116600037 first col mean 0.642902135848999 all mean 0.6437703371047974
rl training, epoch5, iter0, batch661/1133, batch loss:0.0022334065288305283, Training time:152537.9129331112
batch reward last col mean 0.6484954357147217 first col mean 0.6417050361633301 all mean 0.6480592489242554
rl training, epoch5, iter0, batch662/1133, batch loss:0.001785134430974722, Training time:152565.13898777962
batch reward last col mean 0.5384735465049744 first col mean 0.525124192237854 all mean 0.5381015539169312
rl training, epoch5, iter0, batch663/1133, batch loss:0.001702364650554955, Training time:152592.31892371178
batch reward last col mean 0.5811622142791748 first col mean 0.5784989595413208 all mean 0.5808696150779724
rl training, epoch5, iter0, batch664/1133, batch loss:0.0009250706643797457, Training time:152619.16839408875
batch reward last col mean 0.5987204909324646 first col mean 0.5885686874389648 all mean 0.5982303023338318
rl training, epoch5, iter0, batch665/1133, batch loss:0.0020117470994591713, Training time:152646.2662434578
batch reward last col mean 0.5464845299720764 first col mean 0.5534290075302124 all mean 0.5462311506271362
rl training, epoch5, iter0, batch666/1133, batch loss:0.001395680708810687, Training time:152673.48812794685
batch reward last col mean 0.5967521071434021 first col mean 0.6000114679336548 all mean 0.6005806922912598
rl training, epoch5, iter0, batch667/1133, batch loss:0.0037590274587273598, Training time:152700.72955870628
batch reward last col mean 0.6781659126281738 first col mean 0.6642726063728333 all mean 0.6775752305984497
rl training, epoch5, iter0, batch668/1133, batch loss:0.0011255784193053842, Training time:152727.54851293564
batch reward last col mean 0.6291049718856812 first col mean 0.6399553418159485 all mean 0.629234254360199
rl training, epoch5, iter0, batch669/1133, batch loss:0.0014899042434990406, Training time:152755.95448946953
batch reward last col mean 0.6781662702560425 first col mean 0.6715890169143677 all mean 0.6777300834655762
rl training, epoch5, iter0, batch670/1133, batch loss:0.002112466609105468, Training time:152783.80394625664
batch reward last col mean 0.5981318950653076 first col mean 0.6068211793899536 all mean 0.5978880524635315
rl training, epoch5, iter0, batch671/1133, batch loss:0.0009225857793353498, Training time:152811.95745944977
batch reward last col mean 0.6020348072052002 first col mean 0.6175087690353394 all mean 0.6079133749008179
rl training, epoch5, iter0, batch672/1133, batch loss:0.002560369437560439, Training time:152840.31871056557
batch reward last col mean 0.6023077964782715 first col mean 0.6162952184677124 all mean 0.602019727230072
rl training, epoch5, iter0, batch673/1133, batch loss:0.0012523335171863437, Training time:152868.43740701675
batch reward last col mean 0.5949244499206543 first col mean 0.6140256524085999 all mean 0.5960190296173096
rl training, epoch5, iter0, batch674/1133, batch loss:0.0017696236027404666, Training time:152896.1942741871
batch reward last col mean 0.6146480441093445 first col mean 0.6219208240509033 all mean 0.6143164038658142
rl training, epoch5, iter0, batch675/1133, batch loss:0.0022234171628952026, Training time:152923.21342730522
batch reward last col mean 0.6569356918334961 first col mean 0.6563252210617065 all mean 0.6566365361213684
rl training, epoch5, iter0, batch676/1133, batch loss:0.0016224972205236554, Training time:152951.79620027542
batch reward last col mean 0.6236233115196228 first col mean 0.6330487132072449 all mean 0.6234613060951233
rl training, epoch5, iter0, batch677/1133, batch loss:0.0013494574232026935, Training time:152979.22248220444
batch reward last col mean 0.653803825378418 first col mean 0.6517422199249268 all mean 0.6534889340400696
rl training, epoch5, iter0, batch678/1133, batch loss:0.002044969005510211, Training time:153007.38482356071
batch reward last col mean 0.6020650863647461 first col mean 0.60439133644104 all mean 0.6018986701965332
rl training, epoch5, iter0, batch679/1133, batch loss:0.0019302498549222946, Training time:153035.166680336
batch reward last col mean 0.6294752955436707 first col mean 0.6326701641082764 all mean 0.6292928457260132
rl training, epoch5, iter0, batch680/1133, batch loss:0.001371240708976984, Training time:153062.85785746574
batch reward last col mean 0.6164538264274597 first col mean 0.6259248852729797 all mean 0.6162906289100647
rl training, epoch5, iter0, batch681/1133, batch loss:0.0021666609682142735, Training time:153089.97161459923
batch reward last col mean 0.6195707321166992 first col mean 0.641350507736206 all mean 0.6213192343711853
rl training, epoch5, iter0, batch682/1133, batch loss:0.0010800090385600924, Training time:153117.96894979477
batch reward last col mean 0.6393886804580688 first col mean 0.6406389474868774 all mean 0.6393116116523743
rl training, epoch5, iter0, batch683/1133, batch loss:0.001508044544607401, Training time:153145.15083551407
batch reward last col mean 0.5640945434570312 first col mean 0.5633829236030579 all mean 0.5639331936836243
rl training, epoch5, iter0, batch684/1133, batch loss:0.0020357861649245024, Training time:153173.93606829643
batch reward last col mean 0.679109513759613 first col mean 0.6846832633018494 all mean 0.678775429725647
rl training, epoch5, iter0, batch685/1133, batch loss:0.0010625733993947506, Training time:153201.4293987751
batch reward last col mean 0.6947065591812134 first col mean 0.696802020072937 all mean 0.6944314241409302
rl training, epoch5, iter0, batch686/1133, batch loss:0.002315326128154993, Training time:153228.67918634415
batch reward last col mean 0.604702353477478 first col mean 0.6029548645019531 all mean 0.6044249534606934
rl training, epoch5, iter0, batch687/1133, batch loss:0.0009748328011482954, Training time:153256.57223153114
batch reward last col mean 0.6726626753807068 first col mean 0.665412425994873 all mean 0.6724299192428589
rl training, epoch5, iter0, batch688/1133, batch loss:0.0015266428235918283, Training time:153283.98321127892
batch reward last col mean 0.6603863835334778 first col mean 0.6625509858131409 all mean 0.6601043343544006
rl training, epoch5, iter0, batch689/1133, batch loss:0.001197750330902636, Training time:153311.69700932503
batch reward last col mean 0.6219761371612549 first col mean 0.6313573718070984 all mean 0.621713399887085
rl training, epoch5, iter0, batch690/1133, batch loss:0.0023352510761469603, Training time:153339.16808223724
batch reward last col mean 0.6923690438270569 first col mean 0.6853011250495911 all mean 0.6921194195747375
rl training, epoch5, iter0, batch691/1133, batch loss:0.0017765278462320566, Training time:153366.8332180977
batch reward last col mean 0.645407497882843 first col mean 0.6626562476158142 all mean 0.6458672285079956
rl training, epoch5, iter0, batch692/1133, batch loss:0.0010144853731617332, Training time:153395.35402417183
batch reward last col mean 0.6334896087646484 first col mean 0.6273981332778931 all mean 0.6338902711868286
rl training, epoch5, iter0, batch693/1133, batch loss:0.002885787282139063, Training time:153423.47320866585
batch reward last col mean 0.6295230388641357 first col mean 0.6267335414886475 all mean 0.6291464567184448
rl training, epoch5, iter0, batch694/1133, batch loss:0.001531729125417769, Training time:153451.0850687027
batch reward last col mean 0.6358526945114136 first col mean 0.6353023052215576 all mean 0.6355969309806824
rl training, epoch5, iter0, batch695/1133, batch loss:0.0022028132807463408, Training time:153479.32717609406
batch reward last col mean 0.5967082381248474 first col mean 0.5970510840415955 all mean 0.5964663028717041
rl training, epoch5, iter0, batch696/1133, batch loss:0.00044524026452563703, Training time:153507.27581477165
batch reward last col mean 0.6317729353904724 first col mean 0.6382023096084595 all mean 0.631742537021637
rl training, epoch5, iter0, batch697/1133, batch loss:0.000773564912378788, Training time:153535.5139656067
batch reward last col mean 0.6046465039253235 first col mean 0.6040211915969849 all mean 0.6043915152549744
rl training, epoch5, iter0, batch698/1133, batch loss:0.0010294009698554873, Training time:153562.76125478745
batch reward last col mean 0.6479009985923767 first col mean 0.6530632972717285 all mean 0.647864818572998
rl training, epoch5, iter0, batch699/1133, batch loss:0.0021389410831034184, Training time:153590.43938159943
batch reward last col mean 0.6348652839660645 first col mean 0.6582962274551392 all mean 0.6348750591278076
rl training, epoch5, iter0, batch700/1133, batch loss:0.0020274852868169546, Training time:153617.77997803688
batch reward last col mean 0.5474382638931274 first col mean 0.567881166934967 all mean 0.5474551320075989
rl training, epoch5, iter0, batch701/1133, batch loss:0.0008214180124923587, Training time:153646.13993525505
batch reward last col mean 0.575411319732666 first col mean 0.5875012278556824 all mean 0.5755174160003662
rl training, epoch5, iter0, batch702/1133, batch loss:0.0021188692189753056, Training time:153674.17881250381
batch reward last col mean 0.6580027937889099 first col mean 0.6395399570465088 all mean 0.6574290990829468
rl training, epoch5, iter0, batch703/1133, batch loss:0.00231668958440423, Training time:153702.11207556725
batch reward last col mean 0.644117534160614 first col mean 0.6376522183418274 all mean 0.6438031196594238
rl training, epoch5, iter0, batch704/1133, batch loss:0.0012668996350839734, Training time:153729.9873661995
batch reward last col mean 0.6344103813171387 first col mean 0.6313291192054749 all mean 0.6339906454086304
rl training, epoch5, iter0, batch705/1133, batch loss:0.0018884084420278668, Training time:153757.73427844048
batch reward last col mean 0.6775664687156677 first col mean 0.66959148645401 all mean 0.6772257685661316
rl training, epoch5, iter0, batch706/1133, batch loss:0.0017259207088500261, Training time:153785.17918348312
batch reward last col mean 0.6222789883613586 first col mean 0.6257572174072266 all mean 0.6221213340759277
rl training, epoch5, iter0, batch707/1133, batch loss:0.0009329657186754048, Training time:153813.2848920822
batch reward last col mean 0.6288600564002991 first col mean 0.6287393569946289 all mean 0.6286183595657349
rl training, epoch5, iter0, batch708/1133, batch loss:0.0008196827839128673, Training time:153841.04330348969
batch reward last col mean 0.6444995999336243 first col mean 0.6481374502182007 all mean 0.6443660259246826
rl training, epoch5, iter0, batch709/1133, batch loss:0.001385604846291244, Training time:153868.42886281013
batch reward last col mean 0.6297179460525513 first col mean 0.6278077363967896 all mean 0.6294602155685425
rl training, epoch5, iter0, batch710/1133, batch loss:0.0016953526064753532, Training time:153895.8937046528
batch reward last col mean 0.6539206504821777 first col mean 0.6473994255065918 all mean 0.653586208820343
rl training, epoch5, iter0, batch711/1133, batch loss:0.0012334341881796718, Training time:153923.31993031502
batch reward last col mean 0.6161161661148071 first col mean 0.6173037886619568 all mean 0.6159182190895081
rl training, epoch5, iter0, batch712/1133, batch loss:0.0013399197487160563, Training time:153950.3282573223
batch reward last col mean 0.6117631196975708 first col mean 0.6082389950752258 all mean 0.6115601062774658
rl training, epoch5, iter0, batch713/1133, batch loss:0.0011709240498021245, Training time:153977.5271511078
batch reward last col mean 0.6372330188751221 first col mean 0.6387865543365479 all mean 0.6369161009788513
rl training, epoch5, iter0, batch714/1133, batch loss:0.001481277053244412, Training time:154005.83257889748
batch reward last col mean 0.5888364315032959 first col mean 0.5821870565414429 all mean 0.588570773601532
rl training, epoch5, iter0, batch715/1133, batch loss:0.002072190400213003, Training time:154032.946798563
batch reward last col mean 0.6560417413711548 first col mean 0.6316936016082764 all mean 0.6555131077766418
rl training, epoch5, iter0, batch716/1133, batch loss:0.0026005960535258055, Training time:154060.2770960331
batch reward last col mean 0.6684741973876953 first col mean 0.6654694676399231 all mean 0.6681766510009766
rl training, epoch5, iter0, batch717/1133, batch loss:0.0012418875703588128, Training time:154087.91302084923
batch reward last col mean 0.6852837204933167 first col mean 0.6850138902664185 all mean 0.6851139068603516
rl training, epoch5, iter0, batch718/1133, batch loss:0.004711426328867674, Training time:154115.0724747181
batch reward last col mean 0.615203320980072 first col mean 0.6025812029838562 all mean 0.6148074269294739
rl training, epoch5, iter0, batch719/1133, batch loss:0.0004097259952686727, Training time:154143.06140351295
batch reward last col mean 0.6465665102005005 first col mean 0.6597429513931274 all mean 0.646445095539093
rl training, epoch5, iter0, batch720/1133, batch loss:0.0009205023525282741, Training time:154171.07374811172
batch reward last col mean 0.6011853814125061 first col mean 0.6071962118148804 all mean 0.6016337275505066
rl training, epoch5, iter0, batch721/1133, batch loss:0.002867950825020671, Training time:154199.1020512581
batch reward last col mean 0.6539281606674194 first col mean 0.6588588953018188 all mean 0.6542137265205383
rl training, epoch5, iter0, batch722/1133, batch loss:0.0011288520181551576, Training time:154226.74469542503
batch reward last col mean 0.6285650134086609 first col mean 0.6444300413131714 all mean 0.6304958462715149
rl training, epoch5, iter0, batch723/1133, batch loss:0.0011273390846326947, Training time:154254.01752710342
batch reward last col mean 0.6304603815078735 first col mean 0.6280483603477478 all mean 0.6302942037582397
rl training, epoch5, iter0, batch724/1133, batch loss:0.0009338733507320285, Training time:154280.91194558144
batch reward last col mean 0.7008040547370911 first col mean 0.6942044496536255 all mean 0.7006849646568298
rl training, epoch5, iter0, batch725/1133, batch loss:0.001982073998078704, Training time:154308.60087156296
batch reward last col mean 0.6864848136901855 first col mean 0.6814618110656738 all mean 0.6861948370933533
rl training, epoch5, iter0, batch726/1133, batch loss:0.0010756782721728086, Training time:154336.10863542557
batch reward last col mean 0.6496678590774536 first col mean 0.6471890807151794 all mean 0.6494846343994141
rl training, epoch5, iter0, batch727/1133, batch loss:0.0011018902296200395, Training time:154365.00181865692
batch reward last col mean 0.6158952713012695 first col mean 0.6352951526641846 all mean 0.6204434633255005
rl training, epoch5, iter0, batch728/1133, batch loss:0.0009747187723405659, Training time:154392.91564893723
batch reward last col mean 0.6416122913360596 first col mean 0.6569764614105225 all mean 0.6418131589889526
rl training, epoch5, iter0, batch729/1133, batch loss:0.0013338440330699086, Training time:154420.8659338951
batch reward last col mean 0.5708280801773071 first col mean 0.5779190063476562 all mean 0.5773646235466003
rl training, epoch5, iter0, batch730/1133, batch loss:0.0007696368265897036, Training time:154448.162514925
batch reward last col mean 0.6160721778869629 first col mean 0.611706018447876 all mean 0.6157575249671936
rl training, epoch5, iter0, batch731/1133, batch loss:0.001958527835085988, Training time:154476.19301748276
batch reward last col mean 0.70066237449646 first col mean 0.7066633105278015 all mean 0.7005658149719238
rl training, epoch5, iter0, batch732/1133, batch loss:0.0009083572076633573, Training time:154504.58454537392
batch reward last col mean 0.6055135726928711 first col mean 0.61393141746521 all mean 0.6053298115730286
rl training, epoch5, iter0, batch733/1133, batch loss:0.0014864497352391481, Training time:154531.94912099838
batch reward last col mean 0.6371984481811523 first col mean 0.6158055067062378 all mean 0.6367905735969543
rl training, epoch5, iter0, batch734/1133, batch loss:0.0021314923651516438, Training time:154559.48043179512
batch reward last col mean 0.6715859174728394 first col mean 0.6572961807250977 all mean 0.6711400151252747
rl training, epoch5, iter0, batch735/1133, batch loss:0.0011656279675662518, Training time:154586.55856776237
batch reward last col mean 0.6785042881965637 first col mean 0.6794206500053406 all mean 0.6782921552658081
rl training, epoch5, iter0, batch736/1133, batch loss:0.0008670376846566796, Training time:154614.18873929977
batch reward last col mean 0.6852195262908936 first col mean 0.6744828224182129 all mean 0.6849966049194336
rl training, epoch5, iter0, batch737/1133, batch loss:0.0014421995729207993, Training time:154641.75822520256
batch reward last col mean 0.6614208221435547 first col mean 0.6706099510192871 all mean 0.6612672209739685
rl training, epoch5, iter0, batch738/1133, batch loss:0.0036072558723390102, Training time:154670.01950240135
batch reward last col mean 0.614651620388031 first col mean 0.6264901757240295 all mean 0.6157721281051636
rl training, epoch5, iter0, batch739/1133, batch loss:0.0022224870044738054, Training time:154697.65571284294
batch reward last col mean 0.6417227387428284 first col mean 0.6430603861808777 all mean 0.6423572301864624
rl training, epoch5, iter0, batch740/1133, batch loss:0.0022406703792512417, Training time:154726.19568681717
batch reward last col mean 0.5918716788291931 first col mean 0.6051424741744995 all mean 0.5918166637420654
rl training, epoch5, iter0, batch741/1133, batch loss:0.0020962480921298265, Training time:154753.80853056908
batch reward last col mean 0.6177830100059509 first col mean 0.6263749599456787 all mean 0.617946445941925
rl training, epoch5, iter0, batch742/1133, batch loss:0.004001082386821508, Training time:154780.89213347435
batch reward last col mean 0.6207785606384277 first col mean 0.62525475025177 all mean 0.6208862662315369
rl training, epoch5, iter0, batch743/1133, batch loss:0.001581207849085331, Training time:154808.5221748352
batch reward last col mean 0.6311249732971191 first col mean 0.6482908725738525 all mean 0.6311771273612976
rl training, epoch5, iter0, batch744/1133, batch loss:0.001953606493771076, Training time:154836.32147932053
batch reward last col mean 0.7074534893035889 first col mean 0.710884690284729 all mean 0.707175076007843
rl training, epoch5, iter0, batch745/1133, batch loss:0.00214285752736032, Training time:154864.64468336105
batch reward last col mean 0.6420332789421082 first col mean 0.6455996036529541 all mean 0.6417454481124878
rl training, epoch5, iter0, batch746/1133, batch loss:0.0020767170935869217, Training time:154892.09548854828
batch reward last col mean 0.671585202217102 first col mean 0.6674325466156006 all mean 0.6712331771850586
rl training, epoch5, iter0, batch747/1133, batch loss:0.001466534798964858, Training time:154919.86940979958
batch reward last col mean 0.6540518999099731 first col mean 0.6458844542503357 all mean 0.6537270545959473
rl training, epoch5, iter0, batch748/1133, batch loss:0.0010376917198300362, Training time:154947.15271520615
batch reward last col mean 0.6253023743629456 first col mean 0.6264531016349792 all mean 0.6251370310783386
rl training, epoch5, iter0, batch749/1133, batch loss:0.002269629156216979, Training time:154974.43858981133
batch reward last col mean 0.6460510492324829 first col mean 0.6542736887931824 all mean 0.6496037244796753
rl training, epoch5, iter0, batch750/1133, batch loss:0.001839033211581409, Training time:155003.3511044979
batch reward last col mean 0.6580339074134827 first col mean 0.6471284627914429 all mean 0.6576645970344543
rl training, epoch5, iter0, batch751/1133, batch loss:0.001041673356667161, Training time:155030.45324873924
batch reward last col mean 0.5514130592346191 first col mean 0.5676419138908386 all mean 0.5514816045761108
rl training, epoch5, iter0, batch752/1133, batch loss:0.001444418216124177, Training time:155057.58528065681
batch reward last col mean 0.6734217405319214 first col mean 0.6761041283607483 all mean 0.673162043094635
rl training, epoch5, iter0, batch753/1133, batch loss:0.0017672324320301414, Training time:155085.63549923897
batch reward last col mean 0.5870028734207153 first col mean 0.6038748621940613 all mean 0.5871657729148865
rl training, epoch5, iter0, batch754/1133, batch loss:0.0024678846821188927, Training time:155113.23634004593
batch reward last col mean 0.6228333711624146 first col mean 0.6358529329299927 all mean 0.6229752898216248
rl training, epoch5, iter0, batch755/1133, batch loss:0.0025565444957464933, Training time:155140.84208106995
batch reward last col mean 0.6314694881439209 first col mean 0.6446720957756042 all mean 0.6316187977790833
rl training, epoch5, iter0, batch756/1133, batch loss:0.001196152064949274, Training time:155168.3432662487
batch reward last col mean 0.6076364517211914 first col mean 0.6121774911880493 all mean 0.6074239611625671
rl training, epoch5, iter0, batch757/1133, batch loss:0.000990073080174625, Training time:155195.71290683746
batch reward last col mean 0.6156143546104431 first col mean 0.6384975910186768 all mean 0.6158086657524109
rl training, epoch5, iter0, batch758/1133, batch loss:0.0014732042327523232, Training time:155223.26586318016
batch reward last col mean 0.616327702999115 first col mean 0.6236832141876221 all mean 0.6210992336273193
rl training, epoch5, iter0, batch759/1133, batch loss:0.0037528506945818663, Training time:155250.68322372437
batch reward last col mean 0.6893861293792725 first col mean 0.697860598564148 all mean 0.6892883777618408
rl training, epoch5, iter0, batch760/1133, batch loss:0.0014919951790943742, Training time:155278.22880721092
batch reward last col mean 0.6629230380058289 first col mean 0.6527038812637329 all mean 0.6626659631729126
rl training, epoch5, iter0, batch761/1133, batch loss:0.0018244863022118807, Training time:155305.19301605225
batch reward last col mean 0.6950227618217468 first col mean 0.716067373752594 all mean 0.6951454281806946
rl training, epoch5, iter0, batch762/1133, batch loss:0.002154768444597721, Training time:155332.87893104553
batch reward last col mean 0.6309731602668762 first col mean 0.6371685862541199 all mean 0.6308212876319885
rl training, epoch5, iter0, batch763/1133, batch loss:0.0014272149419412017, Training time:155360.74107193947
batch reward last col mean 0.6210991740226746 first col mean 0.6254384517669678 all mean 0.6210938692092896
rl training, epoch5, iter0, batch764/1133, batch loss:0.0017807746771723032, Training time:155389.06082725525
batch reward last col mean 0.6330962181091309 first col mean 0.6315105557441711 all mean 0.6332234144210815
rl training, epoch5, iter0, batch765/1133, batch loss:0.0023484930861741304, Training time:155417.3843946457
batch reward last col mean 0.6438161134719849 first col mean 0.6365036368370056 all mean 0.6434713006019592
rl training, epoch5, iter0, batch766/1133, batch loss:0.0022878635209053755, Training time:155445.02777385712
batch reward last col mean 0.6606156229972839 first col mean 0.6493813991546631 all mean 0.6603415012359619
rl training, epoch5, iter0, batch767/1133, batch loss:0.002437401795759797, Training time:155472.23990941048
batch reward last col mean 0.6442223191261292 first col mean 0.6417480707168579 all mean 0.6441332101821899
rl training, epoch5, iter0, batch768/1133, batch loss:0.0015702623641118407, Training time:155499.28753900528
batch reward last col mean 0.6503351926803589 first col mean 0.6486608982086182 all mean 0.6501469612121582
rl training, epoch5, iter0, batch769/1133, batch loss:0.0017074292991310358, Training time:155526.74653053284
batch reward last col mean 0.6228907108306885 first col mean 0.6374941468238831 all mean 0.6227850914001465
rl training, epoch5, iter0, batch770/1133, batch loss:0.001449360977858305, Training time:155555.19174456596
batch reward last col mean 0.6359834671020508 first col mean 0.6289243698120117 all mean 0.6358930468559265
rl training, epoch5, iter0, batch771/1133, batch loss:0.0033657392486929893, Training time:155583.11838412285
batch reward last col mean 0.6300932765007019 first col mean 0.6324089765548706 all mean 0.6299495697021484
rl training, epoch5, iter0, batch772/1133, batch loss:0.0031261371914297342, Training time:155610.7121167183
batch reward last col mean 0.6831120252609253 first col mean 0.6854023337364197 all mean 0.6828981637954712
rl training, epoch5, iter0, batch773/1133, batch loss:0.001680126297287643, Training time:155638.50701522827
batch reward last col mean 0.6125215888023376 first col mean 0.6137819290161133 all mean 0.6126648783683777
rl training, epoch5, iter0, batch774/1133, batch loss:0.0017275628633797169, Training time:155666.0574541092
batch reward last col mean 0.6579474806785583 first col mean 0.6718239188194275 all mean 0.658161461353302
rl training, epoch5, iter0, batch775/1133, batch loss:0.002236003056168556, Training time:155693.94420957565
batch reward last col mean 0.6620513200759888 first col mean 0.6459625959396362 all mean 0.661648690700531
rl training, epoch5, iter0, batch776/1133, batch loss:0.001661423477344215, Training time:155721.97771453857
batch reward last col mean 0.6746006011962891 first col mean 0.6851475834846497 all mean 0.6746379733085632
rl training, epoch5, iter0, batch777/1133, batch loss:0.0018665308598428965, Training time:155750.07729935646
batch reward last col mean 0.6436382532119751 first col mean 0.6462170481681824 all mean 0.6435722708702087
rl training, epoch5, iter0, batch778/1133, batch loss:0.0013957906048744917, Training time:155777.77024650574
batch reward last col mean 0.6429901719093323 first col mean 0.6613608598709106 all mean 0.6430636048316956
rl training, epoch5, iter0, batch779/1133, batch loss:0.003204256296157837, Training time:155805.74770498276
batch reward last col mean 0.586064875125885 first col mean 0.6002316474914551 all mean 0.5859993100166321
rl training, epoch5, iter0, batch780/1133, batch loss:0.004524805583059788, Training time:155833.33333945274
batch reward last col mean 0.6812641024589539 first col mean 0.6864380836486816 all mean 0.6809724569320679
rl training, epoch5, iter0, batch781/1133, batch loss:0.002719779033213854, Training time:155860.24256014824
batch reward last col mean 0.569706916809082 first col mean 0.5650635957717896 all mean 0.5694413781166077
rl training, epoch5, iter0, batch782/1133, batch loss:0.0016038859030231833, Training time:155887.6583316326
batch reward last col mean 0.6873480081558228 first col mean 0.6727298498153687 all mean 0.6870280504226685
rl training, epoch5, iter0, batch783/1133, batch loss:0.001552301924675703, Training time:155915.27334928513
batch reward last col mean 0.6245896816253662 first col mean 0.6288601160049438 all mean 0.6246097683906555
rl training, epoch5, iter0, batch784/1133, batch loss:0.0032066022977232933, Training time:155942.84996175766
batch reward last col mean 0.6837804913520813 first col mean 0.7049401998519897 all mean 0.6840968132019043
rl training, epoch5, iter0, batch785/1133, batch loss:0.002135516842827201, Training time:155970.33936929703
batch reward last col mean 0.6813507080078125 first col mean 0.6801655292510986 all mean 0.6810992956161499
rl training, epoch5, iter0, batch786/1133, batch loss:0.0018472541123628616, Training time:155997.08618092537
batch reward last col mean 0.6855298280715942 first col mean 0.6863324642181396 all mean 0.6852297782897949
rl training, epoch5, iter0, batch787/1133, batch loss:0.0031953819561749697, Training time:156023.7477197647
batch reward last col mean 0.675527811050415 first col mean 0.6476198434829712 all mean 0.6790127158164978
rl training, epoch5, iter0, batch788/1133, batch loss:0.0016038871835917234, Training time:156050.348133564
batch reward last col mean 0.5718832015991211 first col mean 0.6113337874412537 all mean 0.5724048018455505
rl training, epoch5, iter0, batch789/1133, batch loss:0.0016939291963353753, Training time:156077.28585863113
batch reward last col mean 0.6906585693359375 first col mean 0.7212129831314087 all mean 0.6911433339118958
rl training, epoch5, iter0, batch790/1133, batch loss:0.0016341302543878555, Training time:156103.7349088192
batch reward last col mean 0.6807212233543396 first col mean 0.6661196351051331 all mean 0.6804238557815552
rl training, epoch5, iter0, batch791/1133, batch loss:0.0021386807784438133, Training time:156130.409709692
batch reward last col mean 0.624626874923706 first col mean 0.669931948184967 all mean 0.6251389980316162
rl training, epoch5, iter0, batch792/1133, batch loss:0.0016126577975228429, Training time:156156.98346853256
batch reward last col mean 0.5826719403266907 first col mean 0.5911885499954224 all mean 0.5864501595497131
rl training, epoch5, iter0, batch793/1133, batch loss:0.003009991254657507, Training time:156183.4805059433
batch reward last col mean 0.691349983215332 first col mean 0.724873960018158 all mean 0.6943199634552002
rl training, epoch5, iter0, batch794/1133, batch loss:0.004052033182233572, Training time:156210.21446943283
batch reward last col mean 0.6414352655410767 first col mean 0.6412909626960754 all mean 0.6411629915237427
rl training, epoch5, iter0, batch795/1133, batch loss:0.001442354521714151, Training time:156236.93153262138
batch reward last col mean 0.7209169268608093 first col mean 0.7022255659103394 all mean 0.7206894159317017
rl training, epoch5, iter0, batch796/1133, batch loss:0.003494401928037405, Training time:156263.35325670242
batch reward last col mean 0.660366415977478 first col mean 0.677502453327179 all mean 0.6604331135749817
rl training, epoch5, iter0, batch797/1133, batch loss:0.0014606212498620152, Training time:156289.7698252201
batch reward last col mean 0.6174719333648682 first col mean 0.609647274017334 all mean 0.6181398630142212
rl training, epoch5, iter0, batch798/1133, batch loss:0.00333258300088346, Training time:156316.39302635193
batch reward last col mean 0.6677240133285522 first col mean 0.6695613265037537 all mean 0.6676291823387146
rl training, epoch5, iter0, batch799/1133, batch loss:0.0018210401758551598, Training time:156343.02275896072
batch reward last col mean 0.6913204789161682 first col mean 0.6964420676231384 all mean 0.6912825703620911
rl training, epoch5, iter0, batch800/1133, batch loss:0.0029817125760018826, Training time:156369.790497303
batch reward last col mean 0.668573796749115 first col mean 0.6779642701148987 all mean 0.6685545444488525
rl training, epoch5, iter0, batch801/1133, batch loss:0.0023433363530784845, Training time:156396.26457428932
batch reward last col mean 0.7433072328567505 first col mean 0.7582411766052246 all mean 0.746001124382019
rl training, epoch5, iter0, batch802/1133, batch loss:0.0015594075666740537, Training time:156422.86609339714
batch reward last col mean 0.6655092239379883 first col mean 0.6786866784095764 all mean 0.6686201095581055
rl training, epoch5, iter0, batch803/1133, batch loss:0.0011848706053569913, Training time:156449.12426400185
batch reward last col mean 0.6602888107299805 first col mean 0.6637868285179138 all mean 0.6602128148078918
rl training, epoch5, iter0, batch804/1133, batch loss:0.001547813881188631, Training time:156475.73959255219
batch reward last col mean 0.7530752420425415 first col mean 0.7403436899185181 all mean 0.7527809739112854
rl training, epoch5, iter0, batch805/1133, batch loss:0.002208914840593934, Training time:156502.35314416885
batch reward last col mean 0.704086422920227 first col mean 0.7034578919410706 all mean 0.7039422988891602
rl training, epoch5, iter0, batch806/1133, batch loss:0.0015124647179618478, Training time:156528.90524578094
batch reward last col mean 0.7043689489364624 first col mean 0.7311217784881592 all mean 0.7046974301338196
rl training, epoch5, iter0, batch807/1133, batch loss:0.0012079791631549597, Training time:156555.48218297958
batch reward last col mean 0.6922732591629028 first col mean 0.6857985258102417 all mean 0.6921103596687317
rl training, epoch5, iter0, batch808/1133, batch loss:0.0024890827480703592, Training time:156581.98892998695
batch reward last col mean 0.667080283164978 first col mean 0.6686307191848755 all mean 0.6670272350311279
rl training, epoch5, iter0, batch809/1133, batch loss:0.0016184602864086628, Training time:156608.604511261
batch reward last col mean 0.7345485687255859 first col mean 0.720674991607666 all mean 0.7342590093612671
rl training, epoch5, iter0, batch810/1133, batch loss:0.0015225464012473822, Training time:156635.18355965614
batch reward last col mean 0.6570878028869629 first col mean 0.6544615030288696 all mean 0.657020092010498
rl training, epoch5, iter0, batch811/1133, batch loss:0.0013789533404633403, Training time:156661.72066020966
batch reward last col mean 0.6695271730422974 first col mean 0.6648429036140442 all mean 0.6694685220718384
rl training, epoch5, iter0, batch812/1133, batch loss:0.0025449779350310564, Training time:156688.0477654934
batch reward last col mean 0.6261101961135864 first col mean 0.6390314102172852 all mean 0.6261388063430786
rl training, epoch5, iter0, batch813/1133, batch loss:0.0014096914092078805, Training time:156714.895925045
batch reward last col mean 0.7259184122085571 first col mean 0.726022481918335 all mean 0.7257726788520813
rl training, epoch5, iter0, batch814/1133, batch loss:0.00153741508256644, Training time:156741.19679236412
batch reward last col mean 0.7062702178955078 first col mean 0.7017493844032288 all mean 0.7060034275054932
rl training, epoch5, iter0, batch815/1133, batch loss:0.0015351278707385063, Training time:156768.1217136383
batch reward last col mean 0.6725221872329712 first col mean 0.6555577516555786 all mean 0.672278881072998
rl training, epoch5, iter0, batch816/1133, batch loss:0.0019040588522329926, Training time:156794.3838543892
batch reward last col mean 0.7098806500434875 first col mean 0.7036479711532593 all mean 0.7096679210662842
rl training, epoch5, iter0, batch817/1133, batch loss:0.0010055985767394304, Training time:156820.67683768272
batch reward last col mean 0.6805985569953918 first col mean 0.6718565225601196 all mean 0.6802029609680176
rl training, epoch5, iter0, batch818/1133, batch loss:0.0016282700235024095, Training time:156847.1048514843
batch reward last col mean 0.6413540840148926 first col mean 0.6292487382888794 all mean 0.6454700827598572
rl training, epoch5, iter0, batch819/1133, batch loss:0.0030521778389811516, Training time:156874.12994647026
batch reward last col mean 0.7387439012527466 first col mean 0.730666995048523 all mean 0.7385925650596619
rl training, epoch5, iter0, batch820/1133, batch loss:0.0017824737587943673, Training time:156900.5335586071
batch reward last col mean 0.7551023960113525 first col mean 0.771889865398407 all mean 0.7551955580711365
rl training, epoch5, iter0, batch821/1133, batch loss:0.0018250254215672612, Training time:156926.97097349167
batch reward last col mean 0.6813801527023315 first col mean 0.6691960096359253 all mean 0.6811542510986328
rl training, epoch5, iter0, batch822/1133, batch loss:0.0015113292029127479, Training time:156953.37517356873
batch reward last col mean 0.676588773727417 first col mean 0.6803370118141174 all mean 0.6769090294837952
rl training, epoch5, iter0, batch823/1133, batch loss:0.0016548822168260813, Training time:156979.9755768776
batch reward last col mean 0.6846956610679626 first col mean 0.6887915134429932 all mean 0.6846166253089905
rl training, epoch5, iter0, batch824/1133, batch loss:0.001734275952912867, Training time:157006.67399144173
batch reward last col mean 0.6809598803520203 first col mean 0.683374285697937 all mean 0.6808951497077942
rl training, epoch5, iter0, batch825/1133, batch loss:0.0017613103846088052, Training time:157032.98351693153
batch reward last col mean 0.6840424537658691 first col mean 0.6910954713821411 all mean 0.683986485004425
rl training, epoch5, iter0, batch826/1133, batch loss:0.0018185994122177362, Training time:157059.14565205574
batch reward last col mean 0.6506035923957825 first col mean 0.6555291414260864 all mean 0.6505077481269836
rl training, epoch5, iter0, batch827/1133, batch loss:0.00177697220351547, Training time:157085.50906443596
batch reward last col mean 0.6568942070007324 first col mean 0.6686391234397888 all mean 0.6569388508796692
rl training, epoch5, iter0, batch828/1133, batch loss:0.0017701167380437255, Training time:157112.22902178764
batch reward last col mean 0.7099257707595825 first col mean 0.7066977024078369 all mean 0.7097134590148926
rl training, epoch5, iter0, batch829/1133, batch loss:0.0023973193019628525, Training time:157138.65797686577
batch reward last col mean 0.7213598489761353 first col mean 0.7155300974845886 all mean 0.7211270332336426
rl training, epoch5, iter0, batch830/1133, batch loss:0.0018594221910461783, Training time:157165.11240887642
batch reward last col mean 0.7271856665611267 first col mean 0.7368875741958618 all mean 0.7271884083747864
rl training, epoch5, iter0, batch831/1133, batch loss:0.0010627832962200046, Training time:157191.44398760796
batch reward last col mean 0.706100583076477 first col mean 0.7207058072090149 all mean 0.7061419486999512
rl training, epoch5, iter0, batch832/1133, batch loss:0.001923469826579094, Training time:157217.86834716797
batch reward last col mean 0.7483553886413574 first col mean 0.7477195858955383 all mean 0.7483320832252502
rl training, epoch5, iter0, batch833/1133, batch loss:0.0016769254580140114, Training time:157244.22055339813
batch reward last col mean 0.7261258363723755 first col mean 0.7257139682769775 all mean 0.7260655760765076
rl training, epoch5, iter0, batch834/1133, batch loss:0.0023683742620050907, Training time:157270.61814546585
batch reward last col mean 0.7018452882766724 first col mean 0.6935673952102661 all mean 0.7017898559570312
rl training, epoch5, iter0, batch835/1133, batch loss:0.0024561474565416574, Training time:157297.34400582314
batch reward last col mean 0.7003136873245239 first col mean 0.7131060361862183 all mean 0.7003320455551147
rl training, epoch5, iter0, batch836/1133, batch loss:0.0016986061818897724, Training time:157323.80479168892
batch reward last col mean 0.7336974143981934 first col mean 0.7170345783233643 all mean 0.7333219647407532
rl training, epoch5, iter0, batch837/1133, batch loss:0.0015297416830435395, Training time:157349.9970188141
batch reward last col mean 0.7095423936843872 first col mean 0.7203601002693176 all mean 0.7096577882766724
rl training, epoch5, iter0, batch838/1133, batch loss:0.003245312487706542, Training time:157376.4217031002
batch reward last col mean 0.6594957709312439 first col mean 0.6673998832702637 all mean 0.6596240401268005
rl training, epoch5, iter0, batch839/1133, batch loss:0.0013928095577284694, Training time:157402.8623330593
batch reward last col mean 0.7001544237136841 first col mean 0.7066597938537598 all mean 0.7003188729286194
rl training, epoch5, iter0, batch840/1133, batch loss:0.002741527743637562, Training time:157429.1488149166
batch reward last col mean 0.6508709788322449 first col mean 0.6802873611450195 all mean 0.6509925127029419
rl training, epoch5, iter0, batch841/1133, batch loss:0.002616274869069457, Training time:157455.56368851662
batch reward last col mean 0.6675692200660706 first col mean 0.6688524484634399 all mean 0.6720054149627686
rl training, epoch5, iter0, batch842/1133, batch loss:0.0015959888696670532, Training time:157481.7651193142
batch reward last col mean 0.6999746561050415 first col mean 0.7224803566932678 all mean 0.7000288367271423
rl training, epoch5, iter0, batch843/1133, batch loss:0.0012941996101289988, Training time:157508.17476511002
batch reward last col mean 0.6756000518798828 first col mean 0.6946152448654175 all mean 0.6778735518455505
rl training, epoch5, iter0, batch844/1133, batch loss:0.004254854749888182, Training time:157534.84189391136
batch reward last col mean 0.6819015741348267 first col mean 0.6967153549194336 all mean 0.6818581819534302
rl training, epoch5, iter0, batch845/1133, batch loss:0.0019169278675690293, Training time:157561.1461250782
batch reward last col mean 0.6114284992218018 first col mean 0.6243208646774292 all mean 0.6114796996116638
rl training, epoch5, iter0, batch846/1133, batch loss:0.001528615248389542, Training time:157587.2822816372
batch reward last col mean 0.7311548590660095 first col mean 0.7387183904647827 all mean 0.7311310172080994
rl training, epoch5, iter0, batch847/1133, batch loss:0.0019644552376121283, Training time:157613.1807820797
batch reward last col mean 0.7481023073196411 first col mean 0.7439439296722412 all mean 0.7518476843833923
rl training, epoch5, iter0, batch848/1133, batch loss:0.0032600436825305223, Training time:157639.66520547867
batch reward last col mean 0.6643102169036865 first col mean 0.6828600764274597 all mean 0.6644142270088196
rl training, epoch5, iter0, batch849/1133, batch loss:0.0027502805460244417, Training time:157666.23627328873
batch reward last col mean 0.6809681057929993 first col mean 0.7233067154884338 all mean 0.6814111471176147
rl training, epoch5, iter0, batch850/1133, batch loss:0.0011979553382843733, Training time:157692.6460559368
batch reward last col mean 0.7184945344924927 first col mean 0.7336491942405701 all mean 0.7185781598091125
rl training, epoch5, iter0, batch851/1133, batch loss:0.0015680167125537992, Training time:157718.93723201752
batch reward last col mean 0.7316505312919617 first col mean 0.7240148782730103 all mean 0.7316014170646667
rl training, epoch5, iter0, batch852/1133, batch loss:0.0022596237249672413, Training time:157745.13854002953
batch reward last col mean 0.6841424107551575 first col mean 0.6787760257720947 all mean 0.6840806603431702
rl training, epoch5, iter0, batch853/1133, batch loss:0.0023181349970400333, Training time:157771.51563191414
batch reward last col mean 0.733879029750824 first col mean 0.7414323091506958 all mean 0.7338473200798035
rl training, epoch5, iter0, batch854/1133, batch loss:0.003040092531591654, Training time:157797.88094210625
batch reward last col mean 0.6907835006713867 first col mean 0.6922550797462463 all mean 0.69080650806427
rl training, epoch5, iter0, batch855/1133, batch loss:0.0019806453492492437, Training time:157824.1783349514
batch reward last col mean 0.6561091542243958 first col mean 0.6786516904830933 all mean 0.6562524437904358
rl training, epoch5, iter0, batch856/1133, batch loss:0.0029351194389164448, Training time:157850.56992292404
batch reward last col mean 0.6898260712623596 first col mean 0.7188441157341003 all mean 0.6901190876960754
rl training, epoch5, iter0, batch857/1133, batch loss:0.002867710078135133, Training time:157876.6722099781
batch reward last col mean 0.7109963297843933 first col mean 0.7291852831840515 all mean 0.7150653004646301
rl training, epoch5, iter0, batch858/1133, batch loss:0.002550409873947501, Training time:157902.9428627491
batch reward last col mean 0.6998111605644226 first col mean 0.7128129005432129 all mean 0.699884831905365
rl training, epoch5, iter0, batch859/1133, batch loss:0.002558155218139291, Training time:157929.1729798317
batch reward last col mean 0.6751505136489868 first col mean 0.7018746137619019 all mean 0.6754055023193359
rl training, epoch5, iter0, batch860/1133, batch loss:0.0019132475135847926, Training time:157955.39442539215
batch reward last col mean 0.7264512181282043 first col mean 0.7274311780929565 all mean 0.7263941168785095
rl training, epoch5, iter0, batch861/1133, batch loss:0.0018067666096612811, Training time:157981.62616062164
batch reward last col mean 0.7221392393112183 first col mean 0.7197309732437134 all mean 0.7219864130020142
rl training, epoch5, iter0, batch862/1133, batch loss:0.0015037640696391463, Training time:158007.8044605255
batch reward last col mean 0.7026045918464661 first col mean 0.7073147892951965 all mean 0.7025303840637207
rl training, epoch5, iter0, batch863/1133, batch loss:0.0035419268533587456, Training time:158034.12631511688
batch reward last col mean 0.7632468342781067 first col mean 0.7761622071266174 all mean 0.7637429237365723
rl training, epoch5, iter0, batch864/1133, batch loss:0.003999033477157354, Training time:158060.3607532978
batch reward last col mean 0.7062121033668518 first col mean 0.7007449269294739 all mean 0.7060815095901489
rl training, epoch5, iter0, batch865/1133, batch loss:0.002455847803503275, Training time:158087.33534502983
batch reward last col mean 0.7372668385505676 first col mean 0.7392700910568237 all mean 0.737159788608551
rl training, epoch5, iter0, batch866/1133, batch loss:0.0031847325153648853, Training time:158113.59492230415
batch reward last col mean 0.726751983165741 first col mean 0.7277513146400452 all mean 0.7265763878822327
rl training, epoch5, iter0, batch867/1133, batch loss:0.0017722545890137553, Training time:158139.91308689117
batch reward last col mean 0.6971532106399536 first col mean 0.7085012197494507 all mean 0.6971492767333984
rl training, epoch5, iter0, batch868/1133, batch loss:0.0023553066421300173, Training time:158166.13752126694
batch reward last col mean 0.7240645885467529 first col mean 0.7407712340354919 all mean 0.728704571723938
rl training, epoch5, iter0, batch869/1133, batch loss:0.0019280818523839116, Training time:158192.2916522026
batch reward last col mean 0.7207201719284058 first col mean 0.7267767786979675 all mean 0.7206583023071289
rl training, epoch5, iter0, batch870/1133, batch loss:0.0015748419100418687, Training time:158218.75194597244
batch reward last col mean 0.6775441765785217 first col mean 0.6694509387016296 all mean 0.6774099469184875
rl training, epoch5, iter0, batch871/1133, batch loss:0.0010688203619793057, Training time:158244.91211247444
batch reward last col mean 0.7290204763412476 first col mean 0.7233432531356812 all mean 0.7325039505958557
rl training, epoch5, iter0, batch872/1133, batch loss:0.002578813349828124, Training time:158271.24036192894
batch reward last col mean 0.6766050457954407 first col mean 0.6816251277923584 all mean 0.6766552329063416
rl training, epoch5, iter0, batch873/1133, batch loss:0.0015685104299336672, Training time:158297.67900705338
batch reward last col mean 0.6883941888809204 first col mean 0.6934913396835327 all mean 0.6882965564727783
rl training, epoch5, iter0, batch874/1133, batch loss:0.0016463513020426035, Training time:158323.99877905846
batch reward last col mean 0.6521521806716919 first col mean 0.6330613493919373 all mean 0.6519670486450195
rl training, epoch5, iter0, batch875/1133, batch loss:0.003561333753168583, Training time:158350.2059018612
batch reward last col mean 0.7141082286834717 first col mean 0.7152210474014282 all mean 0.7142444252967834
rl training, epoch5, iter0, batch876/1133, batch loss:0.00251680426299572, Training time:158376.35690641403
batch reward last col mean 0.717574954032898 first col mean 0.7230775952339172 all mean 0.717535138130188
rl training, epoch5, iter0, batch877/1133, batch loss:0.0011044463608413935, Training time:158402.30536484718
batch reward last col mean 0.7082736492156982 first col mean 0.712348997592926 all mean 0.7082091569900513
rl training, epoch5, iter0, batch878/1133, batch loss:0.0021174149587750435, Training time:158428.45767617226
batch reward last col mean 0.6733264923095703 first col mean 0.6809126734733582 all mean 0.6732726693153381
rl training, epoch5, iter0, batch879/1133, batch loss:0.0009833918884396553, Training time:158455.0754354
batch reward last col mean 0.7802295088768005 first col mean 0.7894711494445801 all mean 0.780403196811676
rl training, epoch5, iter0, batch880/1133, batch loss:0.002067709807306528, Training time:158481.40467381477
batch reward last col mean 0.7027822136878967 first col mean 0.7080588340759277 all mean 0.7029834985733032
rl training, epoch5, iter0, batch881/1133, batch loss:0.0011845937697216868, Training time:158507.4753859043
batch reward last col mean 0.6621572375297546 first col mean 0.6735895276069641 all mean 0.6621467471122742
rl training, epoch5, iter0, batch882/1133, batch loss:0.0018372283084318042, Training time:158533.56604623795
batch reward last col mean 0.6854682564735413 first col mean 0.6706326603889465 all mean 0.6853471398353577
rl training, epoch5, iter0, batch883/1133, batch loss:0.001941382884979248, Training time:158559.84881806374
batch reward last col mean 0.7122107744216919 first col mean 0.7136756181716919 all mean 0.7121433019638062
rl training, epoch5, iter0, batch884/1133, batch loss:0.0012821212876588106, Training time:158586.13725328445
batch reward last col mean 0.7252845168113708 first col mean 0.7385016679763794 all mean 0.7255859375
rl training, epoch5, iter0, batch885/1133, batch loss:0.0026493826881051064, Training time:158612.41927933693
batch reward last col mean 0.6884179711341858 first col mean 0.6647015810012817 all mean 0.6880068778991699
rl training, epoch5, iter0, batch886/1133, batch loss:0.002789631951600313, Training time:158638.51905226707
batch reward last col mean 0.6850389242172241 first col mean 0.693713903427124 all mean 0.684990644454956
rl training, epoch5, iter0, batch887/1133, batch loss:0.0013242282439023256, Training time:158664.4662759304
batch reward last col mean 0.6954783797264099 first col mean 0.7072668075561523 all mean 0.69565349817276
rl training, epoch5, iter0, batch888/1133, batch loss:0.0014906276483088732, Training time:158690.55767965317
batch reward last col mean 0.7386350035667419 first col mean 0.7403266429901123 all mean 0.7404725551605225
rl training, epoch5, iter0, batch889/1133, batch loss:0.002099463948979974, Training time:158716.84740924835
batch reward last col mean 0.7266768217086792 first col mean 0.7411147952079773 all mean 0.7267115712165833
rl training, epoch5, iter0, batch890/1133, batch loss:0.0008355664322152734, Training time:158743.06146383286
batch reward last col mean 0.7446044683456421 first col mean 0.743025004863739 all mean 0.7444949746131897
rl training, epoch5, iter0, batch891/1133, batch loss:0.0008768210536800325, Training time:158769.09662628174
batch reward last col mean 0.687279224395752 first col mean 0.6961417198181152 all mean 0.6872584819793701
rl training, epoch5, iter0, batch892/1133, batch loss:0.0015774330822750926, Training time:158795.0251572132
batch reward last col mean 0.7098954916000366 first col mean 0.7081886529922485 all mean 0.709693193435669
rl training, epoch5, iter0, batch893/1133, batch loss:0.0031917865853756666, Training time:158821.14983558655
batch reward last col mean 0.7316307425498962 first col mean 0.7333289384841919 all mean 0.731593668460846
rl training, epoch5, iter0, batch894/1133, batch loss:0.0016503427177667618, Training time:158847.36376667023
batch reward last col mean 0.7629317045211792 first col mean 0.7532365918159485 all mean 0.7626885175704956
rl training, epoch5, iter0, batch895/1133, batch loss:0.0017834767932072282, Training time:158873.48319911957
batch reward last col mean 0.6939975023269653 first col mean 0.6974596977233887 all mean 0.6939005255699158
rl training, epoch5, iter0, batch896/1133, batch loss:0.0025698370300233364, Training time:158899.7422440052
batch reward last col mean 0.7140191793441772 first col mean 0.7120152711868286 all mean 0.7139995694160461
rl training, epoch5, iter0, batch897/1133, batch loss:0.0027674350421875715, Training time:158926.0447165966
batch reward last col mean 0.6922301650047302 first col mean 0.6894289255142212 all mean 0.6920645236968994
rl training, epoch5, iter0, batch898/1133, batch loss:0.001250438392162323, Training time:158951.93399596214
batch reward last col mean 0.6765958070755005 first col mean 0.6885323524475098 all mean 0.6767399311065674
rl training, epoch5, iter0, batch899/1133, batch loss:0.00293127098120749, Training time:158977.85351157188
batch reward last col mean 0.6893331408500671 first col mean 0.6921273469924927 all mean 0.6893830895423889
rl training, epoch5, iter0, batch900/1133, batch loss:0.001730468706227839, Training time:159004.29028081894
batch reward last col mean 0.7141373753547668 first col mean 0.7040997743606567 all mean 0.7139543294906616
rl training, epoch5, iter0, batch901/1133, batch loss:0.0018741308012977242, Training time:159030.307431221
batch reward last col mean 0.668390691280365 first col mean 0.6739068031311035 all mean 0.6683354377746582
rl training, epoch5, iter0, batch902/1133, batch loss:0.0008229429950006306, Training time:159056.01551270485
batch reward last col mean 0.6728792786598206 first col mean 0.6689593195915222 all mean 0.6727076172828674
rl training, epoch5, iter0, batch903/1133, batch loss:0.0024313314352184534, Training time:159082.07391572
batch reward last col mean 0.7287842035293579 first col mean 0.7321147918701172 all mean 0.7286776304244995
rl training, epoch5, iter0, batch904/1133, batch loss:0.001174433622509241, Training time:159108.052298069
batch reward last col mean 0.7019658088684082 first col mean 0.6958925724029541 all mean 0.7017965316772461
rl training, epoch5, iter0, batch905/1133, batch loss:0.0010682714637368917, Training time:159133.89443778992
batch reward last col mean 0.7164393067359924 first col mean 0.7340095043182373 all mean 0.716517448425293
rl training, epoch5, iter0, batch906/1133, batch loss:0.0019684252329170704, Training time:159159.83345746994
batch reward last col mean 0.720604658126831 first col mean 0.7086057066917419 all mean 0.7203017473220825
rl training, epoch5, iter0, batch907/1133, batch loss:0.0018441672436892986, Training time:159185.8790729046
batch reward last col mean 0.679267406463623 first col mean 0.6960974335670471 all mean 0.6794373989105225
rl training, epoch5, iter0, batch908/1133, batch loss:0.0015215675812214613, Training time:159211.83835840225
batch reward last col mean 0.7154018878936768 first col mean 0.7066432237625122 all mean 0.7151524424552917
rl training, epoch5, iter0, batch909/1133, batch loss:0.0018413426587358117, Training time:159237.7968916893
batch reward last col mean 0.7076972723007202 first col mean 0.7108402252197266 all mean 0.7076588869094849
rl training, epoch5, iter0, batch910/1133, batch loss:0.0030029290355741978, Training time:159263.80979156494
batch reward last col mean 0.6913076043128967 first col mean 0.7136555910110474 all mean 0.6928848028182983
rl training, epoch5, iter0, batch911/1133, batch loss:0.0016535226022824645, Training time:159289.99666643143
batch reward last col mean 0.7154914140701294 first col mean 0.7201367616653442 all mean 0.7154749035835266
rl training, epoch5, iter0, batch912/1133, batch loss:0.0016255676746368408, Training time:159315.89002633095
batch reward last col mean 0.7456022500991821 first col mean 0.7421290874481201 all mean 0.7447049617767334
rl training, epoch5, iter0, batch913/1133, batch loss:0.0032894695177674294, Training time:159341.8715825081
batch reward last col mean 0.7359493374824524 first col mean 0.7410802841186523 all mean 0.7359443306922913
rl training, epoch5, iter0, batch914/1133, batch loss:0.0028439692687243223, Training time:159368.32270002365
batch reward last col mean 0.7737951278686523 first col mean 0.7704448103904724 all mean 0.7737166285514832
rl training, epoch5, iter0, batch915/1133, batch loss:0.0016490211710333824, Training time:159394.36926221848
batch reward last col mean 0.6986530423164368 first col mean 0.7166969776153564 all mean 0.6987460255622864
rl training, epoch5, iter0, batch916/1133, batch loss:0.0013410956598818302, Training time:159420.3017244339
batch reward last col mean 0.6759276390075684 first col mean 0.6777697801589966 all mean 0.6759671568870544
rl training, epoch5, iter0, batch917/1133, batch loss:0.0012850080383941531, Training time:159446.21737480164
batch reward last col mean 0.6937527656555176 first col mean 0.698329508304596 all mean 0.6936405301094055
rl training, epoch5, iter0, batch918/1133, batch loss:0.0020703119225800037, Training time:159472.52688074112
batch reward last col mean 0.7308586835861206 first col mean 0.7281023263931274 all mean 0.7307337522506714
rl training, epoch5, iter0, batch919/1133, batch loss:0.001302120042964816, Training time:159498.6175415516
batch reward last col mean 0.7512586116790771 first col mean 0.7557897567749023 all mean 0.7519630789756775
rl training, epoch5, iter0, batch920/1133, batch loss:0.002568368334323168, Training time:159524.6225452423
batch reward last col mean 0.716793954372406 first col mean 0.7426855564117432 all mean 0.717106819152832
rl training, epoch5, iter0, batch921/1133, batch loss:0.004356095567345619, Training time:159550.87768530846
batch reward last col mean 0.7061861157417297 first col mean 0.7205164432525635 all mean 0.7063262462615967
rl training, epoch5, iter0, batch922/1133, batch loss:0.0022212781477719545, Training time:159577.43992996216
batch reward last col mean 0.7496954202651978 first col mean 0.7381031513214111 all mean 0.7494981288909912
rl training, epoch5, iter0, batch923/1133, batch loss:0.002932771807536483, Training time:159603.53454995155
batch reward last col mean 0.6600826382637024 first col mean 0.6693172454833984 all mean 0.6602457165718079
rl training, epoch5, iter0, batch924/1133, batch loss:0.0013730967184528708, Training time:159629.7174487114
batch reward last col mean 0.7623792886734009 first col mean 0.7779847383499146 all mean 0.7648509740829468
rl training, epoch5, iter0, batch925/1133, batch loss:0.0015827243914827704, Training time:159655.8592789173
batch reward last col mean 0.738646924495697 first col mean 0.7545337080955505 all mean 0.7396631836891174
rl training, epoch5, iter0, batch926/1133, batch loss:0.00208896491676569, Training time:159681.79478001595
batch reward last col mean 0.7732941508293152 first col mean 0.7685699462890625 all mean 0.7731826305389404
rl training, epoch5, iter0, batch927/1133, batch loss:0.0024898704141378403, Training time:159707.76651358604
batch reward last col mean 0.7708662748336792 first col mean 0.7557238340377808 all mean 0.7707750201225281
rl training, epoch5, iter0, batch928/1133, batch loss:0.002394234063103795, Training time:159734.01247501373
batch reward last col mean 0.6827974915504456 first col mean 0.6983942985534668 all mean 0.683099091053009
rl training, epoch5, iter0, batch929/1133, batch loss:0.0013642472913488746, Training time:159760.39592146873
batch reward last col mean 0.6953375935554504 first col mean 0.6901454925537109 all mean 0.6951472759246826
rl training, epoch5, iter0, batch930/1133, batch loss:0.0011615145485848188, Training time:159786.76690006256
batch reward last col mean 0.6792325973510742 first col mean 0.6684534549713135 all mean 0.6794931292533875
rl training, epoch5, iter0, batch931/1133, batch loss:0.0023896312341094017, Training time:159813.17835974693
batch reward last col mean 0.6829683780670166 first col mean 0.6875108480453491 all mean 0.6833817362785339
rl training, epoch5, iter0, batch932/1133, batch loss:0.002750617451965809, Training time:159839.1846523285
batch reward last col mean 0.7163240909576416 first col mean 0.7296557426452637 all mean 0.7163467407226562
rl training, epoch5, iter0, batch933/1133, batch loss:0.001323001109994948, Training time:159865.25678420067
batch reward last col mean 0.7056151628494263 first col mean 0.6985096335411072 all mean 0.7053692936897278
rl training, epoch5, iter0, batch934/1133, batch loss:0.0013305998872965574, Training time:159891.2885684967
batch reward last col mean 0.7081832885742188 first col mean 0.701458215713501 all mean 0.7079749703407288
rl training, epoch5, iter0, batch935/1133, batch loss:0.0020851173903793097, Training time:159917.20946335793
batch reward last col mean 0.6751682162284851 first col mean 0.6823529005050659 all mean 0.6752101182937622
rl training, epoch5, iter0, batch936/1133, batch loss:0.0015010158531367779, Training time:159943.18099808693
batch reward last col mean 0.7546202540397644 first col mean 0.7570303678512573 all mean 0.7552893161773682
rl training, epoch5, iter0, batch937/1133, batch loss:0.0021023317240178585, Training time:159969.61303281784
batch reward last col mean 0.7736961245536804 first col mean 0.78264981508255 all mean 0.7736559510231018
rl training, epoch5, iter0, batch938/1133, batch loss:0.001053965068422258, Training time:159995.63511371613
batch reward last col mean 0.709894597530365 first col mean 0.6988168358802795 all mean 0.7096983790397644
rl training, epoch5, iter0, batch939/1133, batch loss:0.0012533414410427213, Training time:160021.88234710693
batch reward last col mean 0.6701547503471375 first col mean 0.6737087965011597 all mean 0.670073390007019
rl training, epoch5, iter0, batch940/1133, batch loss:0.001757143996655941, Training time:160048.0762708187
batch reward last col mean 0.769529402256012 first col mean 0.7725563049316406 all mean 0.7718738317489624
rl training, epoch5, iter0, batch941/1133, batch loss:0.0019404585473239422, Training time:160074.0248401165
batch reward last col mean 0.7164260149002075 first col mean 0.7334460616111755 all mean 0.7154565453529358
rl training, epoch5, iter0, batch942/1133, batch loss:0.0030702531803399324, Training time:160099.92881131172
batch reward last col mean 0.7031063437461853 first col mean 0.7176897525787354 all mean 0.7032536864280701
rl training, epoch5, iter0, batch943/1133, batch loss:0.001610982115380466, Training time:160126.16407871246
batch reward last col mean 0.7533050775527954 first col mean 0.7451369762420654 all mean 0.7530990242958069
rl training, epoch5, iter0, batch944/1133, batch loss:0.0016330871731042862, Training time:160152.25824427605
batch reward last col mean 0.7057359218597412 first col mean 0.6994964480400085 all mean 0.7054669857025146
rl training, epoch5, iter0, batch945/1133, batch loss:0.0013729492202401161, Training time:160178.32737874985
batch reward last col mean 0.7285452485084534 first col mean 0.7330363988876343 all mean 0.7284784913063049
rl training, epoch5, iter0, batch946/1133, batch loss:0.001680929446592927, Training time:160204.30768346786
batch reward last col mean 0.7205999493598938 first col mean 0.7199150323867798 all mean 0.7204687595367432
rl training, epoch5, iter0, batch947/1133, batch loss:0.0010316800326108932, Training time:160230.5595881939
batch reward last col mean 0.7577521800994873 first col mean 0.759036660194397 all mean 0.7576670050621033
rl training, epoch5, iter0, batch948/1133, batch loss:0.0014286419609561563, Training time:160256.88243055344
batch reward last col mean 0.7007818818092346 first col mean 0.7093870639801025 all mean 0.7007108926773071
rl training, epoch5, iter0, batch949/1133, batch loss:0.00122923799790442, Training time:160282.8629336357
batch reward last col mean 0.7430663704872131 first col mean 0.744436502456665 all mean 0.7430101037025452
rl training, epoch5, iter0, batch950/1133, batch loss:0.001036686124280095, Training time:160309.1832089424
batch reward last col mean 0.6928576231002808 first col mean 0.6800616979598999 all mean 0.6926259994506836
rl training, epoch5, iter0, batch951/1133, batch loss:0.001477732788771391, Training time:160335.07847833633
batch reward last col mean 0.7281782031059265 first col mean 0.7276824712753296 all mean 0.7279795408248901
rl training, epoch5, iter0, batch952/1133, batch loss:0.001139380969107151, Training time:160360.8815894127
batch reward last col mean 0.7188747525215149 first col mean 0.7017693519592285 all mean 0.718622088432312
rl training, epoch5, iter0, batch953/1133, batch loss:0.0008962720166891813, Training time:160386.7771346569
batch reward last col mean 0.6758555769920349 first col mean 0.6683024168014526 all mean 0.6757157444953918
rl training, epoch5, iter0, batch954/1133, batch loss:0.0016918537439778447, Training time:160412.6837222576
batch reward last col mean 0.7102611660957336 first col mean 0.7132989168167114 all mean 0.7102653384208679
rl training, epoch5, iter0, batch955/1133, batch loss:0.0013343760510906577, Training time:160438.79392194748
batch reward last col mean 0.6415499448776245 first col mean 0.68248450756073 all mean 0.6423872113227844
rl training, epoch5, iter0, batch956/1133, batch loss:0.0014252874534577131, Training time:160464.97667741776
batch reward last col mean 0.7140496969223022 first col mean 0.7165402770042419 all mean 0.7140660285949707
rl training, epoch5, iter0, batch957/1133, batch loss:0.0005988639895804226, Training time:160491.1129179001
batch reward last col mean 0.6765551567077637 first col mean 0.6715520620346069 all mean 0.6765508055686951
rl training, epoch5, iter0, batch958/1133, batch loss:0.0018404811853542924, Training time:160517.07595992088
batch reward last col mean 0.6938740015029907 first col mean 0.6886299848556519 all mean 0.6937558650970459
rl training, epoch5, iter0, batch959/1133, batch loss:0.0009527591755613685, Training time:160543.01886701584
batch reward last col mean 0.7426270842552185 first col mean 0.7480505704879761 all mean 0.742608904838562
rl training, epoch5, iter0, batch960/1133, batch loss:0.0021370600443333387, Training time:160569.22256875038
batch reward last col mean 0.6876105070114136 first col mean 0.6929665207862854 all mean 0.6875981688499451
rl training, epoch5, iter0, batch961/1133, batch loss:0.0013216226361691952, Training time:160595.57498335838
batch reward last col mean 0.7382209300994873 first col mean 0.7263791561126709 all mean 0.7380581498146057
rl training, epoch5, iter0, batch962/1133, batch loss:0.0018801199039444327, Training time:160621.44927477837
batch reward last col mean 0.7366741299629211 first col mean 0.7446261048316956 all mean 0.7365590929985046
rl training, epoch5, iter0, batch963/1133, batch loss:0.001681964728049934, Training time:160647.57229828835
batch reward last col mean 0.7226714491844177 first col mean 0.7228869795799255 all mean 0.7226152420043945
rl training, epoch5, iter0, batch964/1133, batch loss:0.0017258473671972752, Training time:160674.1803882122
batch reward last col mean 0.7107993960380554 first col mean 0.719342052936554 all mean 0.7108969688415527
rl training, epoch5, iter0, batch965/1133, batch loss:0.0025922388304024935, Training time:160700.28884029388
batch reward last col mean 0.738150417804718 first col mean 0.7478180527687073 all mean 0.7382103204727173
rl training, epoch5, iter0, batch966/1133, batch loss:0.001543007674627006, Training time:160726.25674295425
batch reward last col mean 0.7468075752258301 first col mean 0.7539013028144836 all mean 0.7467217445373535
rl training, epoch5, iter0, batch967/1133, batch loss:0.0012435988755896688, Training time:160751.9756553173
batch reward last col mean 0.7400250434875488 first col mean 0.7481630444526672 all mean 0.7399951815605164
rl training, epoch5, iter0, batch968/1133, batch loss:0.0017875629710033536, Training time:160777.93147993088
batch reward last col mean 0.7632747888565063 first col mean 0.7628815174102783 all mean 0.7638194561004639
rl training, epoch5, iter0, batch969/1133, batch loss:0.0022682358976453543, Training time:160804.32021450996
batch reward last col mean 0.7258109450340271 first col mean 0.7386935353279114 all mean 0.7259097695350647
rl training, epoch5, iter0, batch970/1133, batch loss:0.002047482877969742, Training time:160830.83368182182
batch reward last col mean 0.6842923760414124 first col mean 0.6767550706863403 all mean 0.6840277910232544
rl training, epoch5, iter0, batch971/1133, batch loss:0.001522050821222365, Training time:160856.75348830223
batch reward last col mean 0.7523778080940247 first col mean 0.7370666265487671 all mean 0.7521319389343262
rl training, epoch5, iter0, batch972/1133, batch loss:0.0014840803341940045, Training time:160882.74741077423
batch reward last col mean 0.6844936013221741 first col mean 0.6975091099739075 all mean 0.6847250461578369
rl training, epoch5, iter0, batch973/1133, batch loss:0.0015336322830989957, Training time:160909.41234016418
batch reward last col mean 0.7437081933021545 first col mean 0.7493141293525696 all mean 0.7436602115631104
rl training, epoch5, iter0, batch974/1133, batch loss:0.0020004494581371546, Training time:160935.76727366447
batch reward last col mean 0.6928845047950745 first col mean 0.6982817053794861 all mean 0.6928448677062988
rl training, epoch5, iter0, batch975/1133, batch loss:0.0012112063122913241, Training time:160962.06331539154
batch reward last col mean 0.6492836475372314 first col mean 0.6426129341125488 all mean 0.6491151452064514
rl training, epoch5, iter0, batch976/1133, batch loss:0.0016453936696052551, Training time:160988.22480797768
batch reward last col mean 0.7097113132476807 first col mean 0.7305871248245239 all mean 0.7097973823547363
rl training, epoch5, iter0, batch977/1133, batch loss:0.0009200535714626312, Training time:161014.11794161797
batch reward last col mean 0.6883747577667236 first col mean 0.7166008949279785 all mean 0.6886000037193298
rl training, epoch5, iter0, batch978/1133, batch loss:0.0008504021679982543, Training time:161040.11694955826
batch reward last col mean 0.6999272108078003 first col mean 0.7083230018615723 all mean 0.7000183463096619
rl training, epoch5, iter0, batch979/1133, batch loss:0.001051320810802281, Training time:161066.06823468208
batch reward last col mean 0.6922951340675354 first col mean 0.7021723985671997 all mean 0.6952914595603943
rl training, epoch5, iter0, batch980/1133, batch loss:0.0007650088518857956, Training time:161092.09351706505
batch reward last col mean 0.7015101909637451 first col mean 0.7029106020927429 all mean 0.7014272809028625
rl training, epoch5, iter0, batch981/1133, batch loss:0.0018153410637751222, Training time:161118.16126942635
batch reward last col mean 0.704832136631012 first col mean 0.6932024955749512 all mean 0.7046305537223816
rl training, epoch5, iter0, batch982/1133, batch loss:0.0016967540141195059, Training time:161144.06947398186
batch reward last col mean 0.7025557160377502 first col mean 0.708716630935669 all mean 0.7025259733200073
rl training, epoch5, iter0, batch983/1133, batch loss:0.001828159554861486, Training time:161170.08392596245
batch reward last col mean 0.6300036907196045 first col mean 0.6214415431022644 all mean 0.6298472881317139
rl training, epoch5, iter0, batch984/1133, batch loss:0.0005619283765554428, Training time:161196.19066810608
batch reward last col mean 0.7414560914039612 first col mean 0.7431637644767761 all mean 0.7413887977600098
rl training, epoch5, iter0, batch985/1133, batch loss:0.0020899928640574217, Training time:161222.11674046516
batch reward last col mean 0.7100843787193298 first col mean 0.7234600186347961 all mean 0.7111591100692749
rl training, epoch5, iter0, batch986/1133, batch loss:0.0023778583854436874, Training time:161248.2518863678
batch reward last col mean 0.7089468836784363 first col mean 0.7132202386856079 all mean 0.7089458703994751
rl training, epoch5, iter0, batch987/1133, batch loss:0.0019689465407282114, Training time:161274.24262595177
batch reward last col mean 0.6943630576133728 first col mean 0.6933436393737793 all mean 0.6943025588989258
rl training, epoch5, iter0, batch988/1133, batch loss:0.0007109271828085184, Training time:161300.28064084053
batch reward last col mean 0.6981203556060791 first col mean 0.7161400318145752 all mean 0.6981946229934692
rl training, epoch5, iter0, batch989/1133, batch loss:0.0019317400874570012, Training time:161326.26212120056
batch reward last col mean 0.7429931163787842 first col mean 0.7306468486785889 all mean 0.7410780787467957
rl training, epoch5, iter0, batch990/1133, batch loss:0.0022341173607856035, Training time:161352.20518612862
batch reward last col mean 0.6990083456039429 first col mean 0.7037848234176636 all mean 0.6988702416419983
rl training, epoch5, iter0, batch991/1133, batch loss:0.001133395591750741, Training time:161378.49396252632
batch reward last col mean 0.7194328308105469 first col mean 0.7176790833473206 all mean 0.7193461656570435
rl training, epoch5, iter0, batch992/1133, batch loss:0.0011928833555430174, Training time:161404.5458419323
batch reward last col mean 0.6642916202545166 first col mean 0.658725380897522 all mean 0.6641247868537903
rl training, epoch5, iter0, batch993/1133, batch loss:0.0020886368583887815, Training time:161430.719830513
batch reward last col mean 0.6911608576774597 first col mean 0.7011202573776245 all mean 0.6911652088165283
rl training, epoch5, iter0, batch994/1133, batch loss:0.0007990084122866392, Training time:161457.15280723572
batch reward last col mean 0.6697505116462708 first col mean 0.6750940680503845 all mean 0.6697571277618408
rl training, epoch5, iter0, batch995/1133, batch loss:0.0009777883533388376, Training time:161483.29743623734
batch reward last col mean 0.6807847619056702 first col mean 0.6685245633125305 all mean 0.680513322353363
rl training, epoch5, iter0, batch996/1133, batch loss:0.001345277763903141, Training time:161509.64536333084
batch reward last col mean 0.6771149039268494 first col mean 0.6754652857780457 all mean 0.6770206093788147
rl training, epoch5, iter0, batch997/1133, batch loss:0.0011891165049746633, Training time:161535.46002316475
batch reward last col mean 0.7025144100189209 first col mean 0.7226632833480835 all mean 0.7026748061180115
rl training, epoch5, iter0, batch998/1133, batch loss:0.0016982685774564743, Training time:161561.54915738106
batch reward last col mean 0.733035683631897 first col mean 0.7184526920318604 all mean 0.7346066832542419
rl training, epoch5, iter0, batch999/1133, batch loss:0.0015164008364081383, Training time:161587.65479183197
batch reward last col mean 0.7268093228340149 first col mean 0.7161666750907898 all mean 0.7266004085540771
rl training, epoch5, iter0, batch1000/1133, batch loss:0.0012899090070277452, Training time:161613.76994872093
batch reward last col mean 0.6944366097450256 first col mean 0.6955677270889282 all mean 0.6943066716194153
rl training, epoch5, iter0, batch1001/1133, batch loss:0.001803206978365779, Training time:161640.40869140625
batch reward last col mean 0.6889260411262512 first col mean 0.7060345411300659 all mean 0.6890719532966614
rl training, epoch5, iter0, batch1002/1133, batch loss:0.0016237699892371893, Training time:161666.62111902237
batch reward last col mean 0.6687015891075134 first col mean 0.6766266822814941 all mean 0.6685982346534729
rl training, epoch5, iter0, batch1003/1133, batch loss:0.0015073355752974749, Training time:161692.63292241096
batch reward last col mean 0.6972575783729553 first col mean 0.705221951007843 all mean 0.6972463726997375
rl training, epoch5, iter0, batch1004/1133, batch loss:0.0017750118859112263, Training time:161718.58143258095
batch reward last col mean 0.6752643585205078 first col mean 0.6873230338096619 all mean 0.6753482818603516
rl training, epoch5, iter0, batch1005/1133, batch loss:0.00167850183788687, Training time:161745.05725121498
batch reward last col mean 0.6967751979827881 first col mean 0.7056530714035034 all mean 0.6966918110847473
rl training, epoch5, iter0, batch1006/1133, batch loss:0.001580316573381424, Training time:161770.9978401661
batch reward last col mean 0.7455697059631348 first col mean 0.7231343388557434 all mean 0.745206356048584
rl training, epoch5, iter0, batch1007/1133, batch loss:0.0014684617053717375, Training time:161796.80334806442
batch reward last col mean 0.684034526348114 first col mean 0.6819648742675781 all mean 0.683966338634491
rl training, epoch5, iter0, batch1008/1133, batch loss:0.001801550155505538, Training time:161823.1700644493
batch reward last col mean 0.7059730291366577 first col mean 0.7180548906326294 all mean 0.705991804599762
rl training, epoch5, iter0, batch1009/1133, batch loss:0.0008954991353675723, Training time:161849.30570793152
batch reward last col mean 0.6905851364135742 first col mean 0.7099884748458862 all mean 0.690674364566803
rl training, epoch5, iter0, batch1010/1133, batch loss:0.0011594375828281045, Training time:161875.42645668983
batch reward last col mean 0.6993767619132996 first col mean 0.7069204449653625 all mean 0.6994292140007019
rl training, epoch5, iter0, batch1011/1133, batch loss:0.0022480827756226063, Training time:161901.6223473549
batch reward last col mean 0.7019158601760864 first col mean 0.7059822082519531 all mean 0.7018427848815918
rl training, epoch5, iter0, batch1012/1133, batch loss:0.00044040658394806087, Training time:161927.35803198814
batch reward last col mean 0.6642991304397583 first col mean 0.6873680949211121 all mean 0.6652998328208923
rl training, epoch5, iter0, batch1013/1133, batch loss:0.0024120842572301626, Training time:161953.5215921402
batch reward last col mean 0.7228854298591614 first col mean 0.7299439311027527 all mean 0.7228894233703613
rl training, epoch5, iter0, batch1014/1133, batch loss:0.0021422705613076687, Training time:161979.55317425728
batch reward last col mean 0.708688497543335 first col mean 0.7200478315353394 all mean 0.7087246179580688
rl training, epoch5, iter0, batch1015/1133, batch loss:0.0009101078612729907, Training time:162005.532204628
batch reward last col mean 0.7453402876853943 first col mean 0.752000629901886 all mean 0.7453305125236511
rl training, epoch5, iter0, batch1016/1133, batch loss:0.0010840595932677388, Training time:162031.63674378395
batch reward last col mean 0.6847830414772034 first col mean 0.6803773641586304 all mean 0.6846544742584229
rl training, epoch5, iter0, batch1017/1133, batch loss:0.0012594332220032811, Training time:162057.71579360962
batch reward last col mean 0.6894861459732056 first col mean 0.7059513330459595 all mean 0.68955397605896
rl training, epoch5, iter0, batch1018/1133, batch loss:0.002412146655842662, Training time:162083.61325860023
batch reward last col mean 0.6901758909225464 first col mean 0.6896726489067078 all mean 0.6900646090507507
rl training, epoch5, iter0, batch1019/1133, batch loss:0.0015401614364236593, Training time:162109.65698480606
batch reward last col mean 0.7247889041900635 first col mean 0.736243724822998 all mean 0.7250639200210571
rl training, epoch5, iter0, batch1020/1133, batch loss:0.002358905738219619, Training time:162135.71830654144
batch reward last col mean 0.7027983665466309 first col mean 0.7078538537025452 all mean 0.7036409974098206
rl training, epoch5, iter0, batch1021/1133, batch loss:0.0011749768164008856, Training time:162161.77411699295
batch reward last col mean 0.6848065853118896 first col mean 0.6926714181900024 all mean 0.6848374009132385
rl training, epoch5, iter0, batch1022/1133, batch loss:0.0010138495126739144, Training time:162187.67280578613
batch reward last col mean 0.713021993637085 first col mean 0.7148091793060303 all mean 0.7129790186882019
rl training, epoch5, iter0, batch1023/1133, batch loss:0.0015848487382754683, Training time:162213.67834806442
batch reward last col mean 0.7290574908256531 first col mean 0.7259715795516968 all mean 0.7289313077926636
rl training, epoch5, iter0, batch1024/1133, batch loss:0.001312989741563797, Training time:162239.71718597412
batch reward last col mean 0.7247093915939331 first col mean 0.7145696878433228 all mean 0.7245022654533386
rl training, epoch5, iter0, batch1025/1133, batch loss:0.0015161025803536177, Training time:162265.80715370178
batch reward last col mean 0.7337750792503357 first col mean 0.7387444972991943 all mean 0.7337457537651062
rl training, epoch5, iter0, batch1026/1133, batch loss:0.0012665237300097942, Training time:162291.8368384838
batch reward last col mean 0.7171911001205444 first col mean 0.7137495875358582 all mean 0.7170302271842957
rl training, epoch5, iter0, batch1027/1133, batch loss:0.001078669331036508, Training time:162317.58696889877
batch reward last col mean 0.7618175745010376 first col mean 0.7703240513801575 all mean 0.7619470953941345
rl training, epoch5, iter0, batch1028/1133, batch loss:0.0023920598905533552, Training time:162343.42881560326
batch reward last col mean 0.6750891208648682 first col mean 0.6801968812942505 all mean 0.6750603914260864
rl training, epoch5, iter0, batch1029/1133, batch loss:0.0011053590569645166, Training time:162369.70125555992
batch reward last col mean 0.708753228187561 first col mean 0.71176677942276 all mean 0.7086661458015442
rl training, epoch5, iter0, batch1030/1133, batch loss:0.000680078228469938, Training time:162395.801548481
batch reward last col mean 0.7125592827796936 first col mean 0.7238110303878784 all mean 0.7126151919364929
rl training, epoch5, iter0, batch1031/1133, batch loss:0.0008592537487857044, Training time:162421.73954176903
batch reward last col mean 0.6600436568260193 first col mean 0.6445314288139343 all mean 0.6597957611083984
rl training, epoch5, iter0, batch1032/1133, batch loss:0.0016810472588986158, Training time:162447.77541279793
batch reward last col mean 0.6497728228569031 first col mean 0.6601548790931702 all mean 0.6497858166694641
rl training, epoch5, iter0, batch1033/1133, batch loss:0.0010011420818045735, Training time:162473.94270968437
batch reward last col mean 0.6710246801376343 first col mean 0.6907587647438049 all mean 0.6711723208427429
rl training, epoch5, iter0, batch1034/1133, batch loss:0.001109989476390183, Training time:162499.83436274529
batch reward last col mean 0.6808763146400452 first col mean 0.6785465478897095 all mean 0.6807346343994141
rl training, epoch5, iter0, batch1035/1133, batch loss:0.001391690457239747, Training time:162526.1687130928
batch reward last col mean 0.7132030725479126 first col mean 0.7092004418373108 all mean 0.7130236625671387
rl training, epoch5, iter0, batch1036/1133, batch loss:0.002224474912509322, Training time:162552.13633179665
batch reward last col mean 0.6797093152999878 first col mean 0.6999578475952148 all mean 0.6801220178604126
rl training, epoch5, iter0, batch1037/1133, batch loss:0.002077538752928376, Training time:162578.1249036789
batch reward last col mean 0.7344922423362732 first col mean 0.7482059597969055 all mean 0.7345556616783142
rl training, epoch5, iter0, batch1038/1133, batch loss:0.002690309891477227, Training time:162603.96497821808
batch reward last col mean 0.7329107522964478 first col mean 0.7353297472000122 all mean 0.7328982949256897
rl training, epoch5, iter0, batch1039/1133, batch loss:0.0019256733357906342, Training time:162629.88893270493
batch reward last col mean 0.7357769012451172 first col mean 0.7280258536338806 all mean 0.7355756759643555
rl training, epoch5, iter0, batch1040/1133, batch loss:0.0016900652553886175, Training time:162656.43173766136
batch reward last col mean 0.7145755290985107 first col mean 0.7241446375846863 all mean 0.7146106958389282
rl training, epoch5, iter0, batch1041/1133, batch loss:0.0017948056338354945, Training time:162682.3727531433
batch reward last col mean 0.7122385501861572 first col mean 0.70359206199646 all mean 0.7120802402496338
rl training, epoch5, iter0, batch1042/1133, batch loss:0.001626081531867385, Training time:162708.21807980537
batch reward last col mean 0.741912841796875 first col mean 0.7489097118377686 all mean 0.7419599890708923
rl training, epoch5, iter0, batch1043/1133, batch loss:0.0013811439275741577, Training time:162734.1312339306
batch reward last col mean 0.7237362861633301 first col mean 0.7083885073661804 all mean 0.7234875559806824
rl training, epoch5, iter0, batch1044/1133, batch loss:0.0013747565681114793, Training time:162760.07103800774
batch reward last col mean 0.6617071628570557 first col mean 0.6737052798271179 all mean 0.6617830991744995
rl training, epoch5, iter0, batch1045/1133, batch loss:0.0010062732035294175, Training time:162786.22008132935
batch reward last col mean 0.7561928629875183 first col mean 0.766075849533081 all mean 0.7564228773117065
rl training, epoch5, iter0, batch1046/1133, batch loss:0.0012458302080631256, Training time:162812.30803847313
batch reward last col mean 0.6662330627441406 first col mean 0.6864981055259705 all mean 0.6666693091392517
rl training, epoch5, iter0, batch1047/1133, batch loss:0.001633183448575437, Training time:162838.5617070198
batch reward last col mean 0.7621617913246155 first col mean 0.7538535594940186 all mean 0.7619607448577881
rl training, epoch5, iter0, batch1048/1133, batch loss:0.0014795296592637897, Training time:162864.90367221832
batch reward last col mean 0.7000590562820435 first col mean 0.7221170663833618 all mean 0.7002096176147461
rl training, epoch5, iter0, batch1049/1133, batch loss:0.001390224788337946, Training time:162890.96251296997
batch reward last col mean 0.7309311628341675 first col mean 0.7322704792022705 all mean 0.7308743596076965
rl training, epoch5, iter0, batch1050/1133, batch loss:0.0013369993539527059, Training time:162916.8516573906
batch reward last col mean 0.7130086421966553 first col mean 0.7008278965950012 all mean 0.7127728462219238
rl training, epoch5, iter0, batch1051/1133, batch loss:0.001592264510691166, Training time:162942.77939867973
batch reward last col mean 0.7491484880447388 first col mean 0.742469310760498 all mean 0.7490121722221375
rl training, epoch5, iter0, batch1052/1133, batch loss:0.0010810740059241652, Training time:162968.8059337139
batch reward last col mean 0.7469304203987122 first col mean 0.7555650472640991 all mean 0.7468682527542114
rl training, epoch5, iter0, batch1053/1133, batch loss:0.0015794549835845828, Training time:162994.82286453247
batch reward last col mean 0.6903745532035828 first col mean 0.685390830039978 all mean 0.6902962327003479
rl training, epoch5, iter0, batch1054/1133, batch loss:0.0025255612563341856, Training time:163021.12765407562
batch reward last col mean 0.697528064250946 first col mean 0.7023876905441284 all mean 0.6974673271179199
rl training, epoch5, iter0, batch1055/1133, batch loss:0.0024500638246536255, Training time:163047.09644389153
batch reward last col mean 0.6822991371154785 first col mean 0.6995580196380615 all mean 0.6824052333831787
rl training, epoch5, iter0, batch1056/1133, batch loss:0.0026629632338881493, Training time:163073.05324077606
batch reward last col mean 0.7320120930671692 first col mean 0.7270463109016418 all mean 0.7318793535232544
rl training, epoch5, iter0, batch1057/1133, batch loss:0.0016914507141336799, Training time:163098.83064937592
batch reward last col mean 0.6873487234115601 first col mean 0.6999331712722778 all mean 0.6873134970664978
rl training, epoch5, iter0, batch1058/1133, batch loss:0.0013209049357101321, Training time:163124.91383504868
batch reward last col mean 0.667264461517334 first col mean 0.6837167739868164 all mean 0.6673199534416199
rl training, epoch5, iter0, batch1059/1133, batch loss:0.0022229040041565895, Training time:163150.91572642326
batch reward last col mean 0.7199397683143616 first col mean 0.7162477374076843 all mean 0.7198532819747925
rl training, epoch5, iter0, batch1060/1133, batch loss:0.0022718266118317842, Training time:163176.840375185
batch reward last col mean 0.7137688398361206 first col mean 0.711226224899292 all mean 0.713720440864563
rl training, epoch5, iter0, batch1061/1133, batch loss:0.0012519543524831533, Training time:163202.98282003403
batch reward last col mean 0.7035653591156006 first col mean 0.7049533128738403 all mean 0.703546404838562
rl training, epoch5, iter0, batch1062/1133, batch loss:0.0011770843993872404, Training time:163228.9004061222
batch reward last col mean 0.6977969408035278 first col mean 0.7048715949058533 all mean 0.6977562308311462
rl training, epoch5, iter0, batch1063/1133, batch loss:0.0014969902113080025, Training time:163255.0559744835
batch reward last col mean 0.6890214681625366 first col mean 0.6856363415718079 all mean 0.6888946890830994
rl training, epoch5, iter0, batch1064/1133, batch loss:0.0015362916747108102, Training time:163280.98061800003
batch reward last col mean 0.7148932218551636 first col mean 0.7026246190071106 all mean 0.7176080346107483
rl training, epoch5, iter0, batch1065/1133, batch loss:0.003530520247295499, Training time:163306.9221625328
batch reward last col mean 0.7417859435081482 first col mean 0.7457292079925537 all mean 0.7442378997802734
rl training, epoch5, iter0, batch1066/1133, batch loss:0.0013250472256913781, Training time:163332.9993917942
batch reward last col mean 0.7076785564422607 first col mean 0.7218419909477234 all mean 0.7078098058700562
rl training, epoch5, iter0, batch1067/1133, batch loss:0.0012598837492987514, Training time:163358.6096251011
batch reward last col mean 0.7007325291633606 first col mean 0.7078240513801575 all mean 0.700954258441925
rl training, epoch5, iter0, batch1068/1133, batch loss:0.002112647285684943, Training time:163384.3994796276
batch reward last col mean 0.7512544393539429 first col mean 0.7535056471824646 all mean 0.7511780261993408
rl training, epoch5, iter0, batch1069/1133, batch loss:0.0016146998386830091, Training time:163410.31517338753
batch reward last col mean 0.7260314226150513 first col mean 0.7120760083198547 all mean 0.7257858514785767
rl training, epoch5, iter0, batch1070/1133, batch loss:0.0017617818666622043, Training time:163436.35492491722
batch reward last col mean 0.7461848258972168 first col mean 0.7447749376296997 all mean 0.7460814714431763
rl training, epoch5, iter0, batch1071/1133, batch loss:0.0021271719597280025, Training time:163462.4559214115
batch reward last col mean 0.6944339871406555 first col mean 0.7039374113082886 all mean 0.6943891048431396
rl training, epoch5, iter0, batch1072/1133, batch loss:0.0027636599261313677, Training time:163488.41066670418
batch reward last col mean 0.7123311758041382 first col mean 0.7079001665115356 all mean 0.7122218608856201
rl training, epoch5, iter0, batch1073/1133, batch loss:0.0020049079321324825, Training time:163514.54332065582
batch reward last col mean 0.7557118535041809 first col mean 0.764585554599762 all mean 0.755714476108551
rl training, epoch5, iter0, batch1074/1133, batch loss:0.0015905292239040136, Training time:163540.54252767563
batch reward last col mean 0.7875831127166748 first col mean 0.7910099625587463 all mean 0.7875797748565674
rl training, epoch5, iter0, batch1075/1133, batch loss:0.001555524067953229, Training time:163566.44474840164
batch reward last col mean 0.7218760848045349 first col mean 0.7170060276985168 all mean 0.7217137217521667
rl training, epoch5, iter0, batch1076/1133, batch loss:0.0018753347685560584, Training time:163592.75563120842
batch reward last col mean 0.7544636726379395 first col mean 0.7546311020851135 all mean 0.7544069886207581
rl training, epoch5, iter0, batch1077/1133, batch loss:0.0015940406592562795, Training time:163618.9165918827
batch reward last col mean 0.7285046577453613 first col mean 0.724996030330658 all mean 0.7283303737640381
rl training, epoch5, iter0, batch1078/1133, batch loss:0.0013269884511828423, Training time:163644.9846122265
batch reward last col mean 0.7027078866958618 first col mean 0.7255123257637024 all mean 0.7028794884681702
rl training, epoch5, iter0, batch1079/1133, batch loss:0.0007031236309558153, Training time:163670.93595957756
batch reward last col mean 0.6386948823928833 first col mean 0.6330326199531555 all mean 0.6385327577590942
rl training, epoch5, iter0, batch1080/1133, batch loss:0.0010553158354014158, Training time:163697.3158106804
batch reward last col mean 0.7144908308982849 first col mean 0.7136812210083008 all mean 0.7144596576690674
rl training, epoch5, iter0, batch1081/1133, batch loss:0.0014359571505337954, Training time:163723.11445879936
batch reward last col mean 0.7134178876876831 first col mean 0.7372848987579346 all mean 0.7142304182052612
rl training, epoch5, iter0, batch1082/1133, batch loss:0.0015806835144758224, Training time:163749.12314081192
batch reward last col mean 0.6854251623153687 first col mean 0.6929523944854736 all mean 0.6853606700897217
rl training, epoch5, iter0, batch1083/1133, batch loss:0.0011293001007288694, Training time:163775.17461919785
batch reward last col mean 0.7292950749397278 first col mean 0.7445138692855835 all mean 0.7293713688850403
rl training, epoch5, iter0, batch1084/1133, batch loss:0.0012716698693111539, Training time:163801.22750139236
batch reward last col mean 0.7147334218025208 first col mean 0.7130143046379089 all mean 0.7146550416946411
rl training, epoch5, iter0, batch1085/1133, batch loss:0.001077535911463201, Training time:163827.1252567768
batch reward last col mean 0.7292993664741516 first col mean 0.7199371457099915 all mean 0.7291540503501892
rl training, epoch5, iter0, batch1086/1133, batch loss:0.0007361280149780214, Training time:163853.17874455452
batch reward last col mean 0.7138556241989136 first col mean 0.7241834402084351 all mean 0.7138826251029968
rl training, epoch5, iter0, batch1087/1133, batch loss:0.003013996407389641, Training time:163879.03959226608
batch reward last col mean 0.6664714813232422 first col mean 0.6822231411933899 all mean 0.6666093468666077
rl training, epoch5, iter0, batch1088/1133, batch loss:0.002048686146736145, Training time:163904.9784154892
batch reward last col mean 0.7258268594741821 first col mean 0.7410095930099487 all mean 0.7260947227478027
rl training, epoch5, iter0, batch1089/1133, batch loss:0.0020029570441693068, Training time:163931.3090250492
batch reward last col mean 0.6876769661903381 first col mean 0.6967595815658569 all mean 0.6904650330543518
rl training, epoch5, iter0, batch1090/1133, batch loss:0.002161776414141059, Training time:163957.34698200226
batch reward last col mean 0.6678503155708313 first col mean 0.6727309226989746 all mean 0.6678450107574463
rl training, epoch5, iter0, batch1091/1133, batch loss:0.0015335462521761656, Training time:163983.4489967823
batch reward last col mean 0.7118474841117859 first col mean 0.707008957862854 all mean 0.711693525314331
rl training, epoch5, iter0, batch1092/1133, batch loss:0.0017450408777222037, Training time:164009.5303645134
batch reward last col mean 0.7239238023757935 first col mean 0.7328765392303467 all mean 0.723957896232605
rl training, epoch5, iter0, batch1093/1133, batch loss:0.0010489756241440773, Training time:164035.7969236374
batch reward last col mean 0.7338271141052246 first col mean 0.7379586696624756 all mean 0.7337640523910522
rl training, epoch5, iter0, batch1094/1133, batch loss:0.0009621431236155331, Training time:164061.76009655
batch reward last col mean 0.6990646123886108 first col mean 0.727015495300293 all mean 0.7034493684768677
rl training, epoch5, iter0, batch1095/1133, batch loss:0.0013387087965384126, Training time:164087.68110442162
batch reward last col mean 0.7214895486831665 first col mean 0.7122719287872314 all mean 0.7212892770767212
rl training, epoch5, iter0, batch1096/1133, batch loss:0.0009211041033267975, Training time:164113.65316295624
batch reward last col mean 0.6125922799110413 first col mean 0.6279302835464478 all mean 0.6126867532730103
rl training, epoch5, iter0, batch1097/1133, batch loss:0.0012752177426591516, Training time:164139.7385840416
batch reward last col mean 0.7068880796432495 first col mean 0.7127091288566589 all mean 0.7068790197372437
rl training, epoch5, iter0, batch1098/1133, batch loss:0.0011018173536285758, Training time:164165.57360339165
batch reward last col mean 0.7421950101852417 first col mean 0.741401195526123 all mean 0.7421491146087646
rl training, epoch5, iter0, batch1099/1133, batch loss:0.0009079161682166159, Training time:164191.43557190895
batch reward last col mean 0.7112644910812378 first col mean 0.7016006112098694 all mean 0.7111026644706726
rl training, epoch5, iter0, batch1100/1133, batch loss:0.0013804580084979534, Training time:164217.7845928669
batch reward last col mean 0.7422367930412292 first col mean 0.7349231243133545 all mean 0.7421087622642517
rl training, epoch5, iter0, batch1101/1133, batch loss:0.0025852543767541647, Training time:164243.76294136047
batch reward last col mean 0.6957682371139526 first col mean 0.6920247077941895 all mean 0.6956797242164612
rl training, epoch5, iter0, batch1102/1133, batch loss:0.0009756689541973174, Training time:164269.9208791256
batch reward last col mean 0.6814247369766235 first col mean 0.7017824053764343 all mean 0.6816056370735168
rl training, epoch5, iter0, batch1103/1133, batch loss:0.0012096675345674157, Training time:164295.81158828735
batch reward last col mean 0.7345729470252991 first col mean 0.7360897660255432 all mean 0.7345741391181946
rl training, epoch5, iter0, batch1104/1133, batch loss:0.0011706999503076077, Training time:164321.80990314484
batch reward last col mean 0.6819756627082825 first col mean 0.6988793611526489 all mean 0.6821857690811157
rl training, epoch5, iter0, batch1105/1133, batch loss:0.0019598877988755703, Training time:164347.8243010044
batch reward last col mean 0.6900880932807922 first col mean 0.7039207816123962 all mean 0.6901555061340332
rl training, epoch5, iter0, batch1106/1133, batch loss:0.0010736469412222505, Training time:164373.74494814873
batch reward last col mean 0.734856367111206 first col mean 0.7342015504837036 all mean 0.7347851395606995
rl training, epoch5, iter0, batch1107/1133, batch loss:0.0012910685036331415, Training time:164400.30995607376
batch reward last col mean 0.7462291717529297 first col mean 0.7453882694244385 all mean 0.7461378574371338
rl training, epoch5, iter0, batch1108/1133, batch loss:0.0012094697449356318, Training time:164426.21704149246
batch reward last col mean 0.7041157484054565 first col mean 0.7008903622627258 all mean 0.7043235898017883
rl training, epoch5, iter0, batch1109/1133, batch loss:0.0021401848644018173, Training time:164452.18939256668
batch reward last col mean 0.6839491724967957 first col mean 0.7034671306610107 all mean 0.6841038465499878
rl training, epoch5, iter0, batch1110/1133, batch loss:0.0011524602305144072, Training time:164478.15191054344
batch reward last col mean 0.772845983505249 first col mean 0.7732417583465576 all mean 0.7727997303009033
rl training, epoch5, iter0, batch1111/1133, batch loss:0.0017322722123935819, Training time:164504.09173703194
batch reward last col mean 0.5802057385444641 first col mean 0.6037958860397339 all mean 0.5814183354377747
rl training, epoch5, iter0, batch1112/1133, batch loss:0.0005605808109976351, Training time:164529.979783535
batch reward last col mean 0.7531026005744934 first col mean 0.7609009146690369 all mean 0.7530717849731445
rl training, epoch5, iter0, batch1113/1133, batch loss:0.0009158113971352577, Training time:164555.8887708187
batch reward last col mean 0.7354214787483215 first col mean 0.729371190071106 all mean 0.7352749705314636
rl training, epoch5, iter0, batch1114/1133, batch loss:0.0010014508152380586, Training time:164581.87786841393
batch reward last col mean 0.7640509605407715 first col mean 0.7633169293403625 all mean 0.7639813423156738
rl training, epoch5, iter0, batch1115/1133, batch loss:0.0011184436734765768, Training time:164607.82721304893
batch reward last col mean 0.7244261503219604 first col mean 0.7247139811515808 all mean 0.7243775725364685
rl training, epoch5, iter0, batch1116/1133, batch loss:0.0021602485794574022, Training time:164633.8406085968
batch reward last col mean 0.7103286981582642 first col mean 0.7055623531341553 all mean 0.7101689577102661
rl training, epoch5, iter0, batch1117/1133, batch loss:0.0012317558284848928, Training time:164659.67402672768
batch reward last col mean 0.7019610404968262 first col mean 0.7114120721817017 all mean 0.7020207643508911
rl training, epoch5, iter0, batch1118/1133, batch loss:0.0012982686748728156, Training time:164685.74198198318
batch reward last col mean 0.7084202766418457 first col mean 0.7315646409988403 all mean 0.708560585975647
rl training, epoch5, iter0, batch1119/1133, batch loss:0.00172707112506032, Training time:164711.68737769127
batch reward last col mean 0.7576383352279663 first col mean 0.7475287914276123 all mean 0.7574963569641113
rl training, epoch5, iter0, batch1120/1133, batch loss:0.002312860218808055, Training time:164737.78142261505
batch reward last col mean 0.7471234202384949 first col mean 0.7461865544319153 all mean 0.746794581413269
rl training, epoch5, iter0, batch1121/1133, batch loss:0.0020024580880999565, Training time:164763.61728692055
batch reward last col mean 0.7585359215736389 first col mean 0.766356348991394 all mean 0.7591967582702637
rl training, epoch5, iter0, batch1122/1133, batch loss:0.0020243688486516476, Training time:164789.42382001877
batch reward last col mean 0.7533597946166992 first col mean 0.7455821633338928 all mean 0.7531954050064087
rl training, epoch5, iter0, batch1123/1133, batch loss:0.001016352791339159, Training time:164815.45286679268
batch reward last col mean 0.6925508379936218 first col mean 0.6979790925979614 all mean 0.6925188899040222
rl training, epoch5, iter0, batch1124/1133, batch loss:0.0011498457752168179, Training time:164841.36006069183
batch reward last col mean 0.7226091623306274 first col mean 0.720852255821228 all mean 0.7224889993667603
rl training, epoch5, iter0, batch1125/1133, batch loss:0.0009490493685007095, Training time:164867.23411679268
batch reward last col mean 0.7156990170478821 first col mean 0.7295002937316895 all mean 0.715752899646759
rl training, epoch5, iter0, batch1126/1133, batch loss:0.0014026437420397997, Training time:164893.13511919975
batch reward last col mean 0.7134595513343811 first col mean 0.7190332412719727 all mean 0.7134910821914673
rl training, epoch5, iter0, batch1127/1133, batch loss:0.0014797801850363612, Training time:164918.89282560349
batch reward last col mean 0.6952521800994873 first col mean 0.7035646438598633 all mean 0.6952264904975891
rl training, epoch5, iter0, batch1128/1133, batch loss:0.00198511709459126, Training time:164944.82796502113
batch reward last col mean 0.7400636672973633 first col mean 0.7536278963088989 all mean 0.740193784236908
rl training, epoch5, iter0, batch1129/1133, batch loss:0.0008419286459684372, Training time:164970.8007235527
batch reward last col mean 0.7145361304283142 first col mean 0.7177554368972778 all mean 0.7145273089408875
rl training, epoch5, iter0, batch1130/1133, batch loss:0.002223833231255412, Training time:164996.75278663635
batch reward last col mean 0.7131505608558655 first col mean 0.7156398892402649 all mean 0.7131004929542542
rl training, epoch5, iter0, batch1131/1133, batch loss:0.0012122384505346417, Training time:165022.6923108101
batch reward last col mean 0.701568603515625 first col mean 0.7080392241477966 all mean 0.7015770077705383
rl training, epoch5, iter0, batch1132/1133, batch loss:0.003336760913953185, Training time:165046.80173826218
rl training, epoch 5, iter 0, loss:0.00855834303206032, Training time:165046.801987648 
rl epoch 5, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.26390869324305155 Time: 174.40454483032227 s
cur_epoch: 1
D Training Loss: 0.24249935470396505 Time: 174.70655488967896 s
cur_epoch: 2
D Training Loss: 0.2426316976376266 Time: 172.5029616355896 s
cur_epoch: 3
D Training Loss: 0.23190318198590182 Time: 174.55050373077393 s
cur_epoch: 4
D Training Loss: 0.23317873640362394 Time: 174.3578188419342 s
rl epoch 6, begin RL for generator...
batch reward last col mean 2.9253931188577553e-07 first col mean 1.4960724570300954e-07 all mean 3.034877522622992e-07
rl training, epoch6, iter0, batch0/1133, batch loss:3.794067726659023e-09, Training time:165943.47368240356
batch reward last col mean 1.2100340427423362e-06 first col mean 1.6967716476301575e-07 all mean 1.1995253998975386e-06
rl training, epoch6, iter0, batch1/1133, batch loss:1.365401391950627e-08, Training time:165969.6034731865
batch reward last col mean 1.2893430323401844e-07 first col mean 4.1012235669768415e-06 all mean 1.7280660813412396e-07
rl training, epoch6, iter0, batch2/1133, batch loss:8.263212891712612e-10, Training time:165995.56254458427
batch reward last col mean 1.5840838614167296e-06 first col mean 1.8004375306190923e-06 all mean 1.5884870663285255e-06
rl training, epoch6, iter0, batch3/1133, batch loss:5.2450221943445285e-08, Training time:166021.69030094147
batch reward last col mean 2.1939702037343523e-06 first col mean 1.878755824691325e-06 all mean 2.1930341063125525e-06
rl training, epoch6, iter0, batch4/1133, batch loss:1.489034140433887e-08, Training time:166047.74446058273
batch reward last col mean 3.169851197526441e-06 first col mean 2.9965362955408636e-06 all mean 3.1729196052765474e-06
rl training, epoch6, iter0, batch5/1133, batch loss:1.4272439230467171e-08, Training time:166073.71935486794
batch reward last col mean 2.111204821630963e-06 first col mean 1.2605466963577783e-06 all mean 2.0982618025300326e-06
rl training, epoch6, iter0, batch6/1133, batch loss:8.215377533815627e-08, Training time:166099.8887321949
batch reward last col mean 3.6245825185687863e-07 first col mean 8.291178232866514e-07 all mean 1.889402119559236e-05
rl training, epoch6, iter0, batch7/1133, batch loss:4.24452945013698e-10, Training time:166126.01917600632
batch reward last col mean 1.0183958920606528e-07 first col mean 1.0607344620439108e-06 all mean 2.535805606385111e-06
rl training, epoch6, iter0, batch8/1133, batch loss:2.96313418246541e-10, Training time:166152.0468864441
batch reward last col mean 3.043594887230938e-08 first col mean 1.676815912787788e-07 all mean 8.309969416586682e-06
rl training, epoch6, iter0, batch9/1133, batch loss:3.3443417479794846e-10, Training time:166178.00336885452
batch reward last col mean 5.425380095402943e-06 first col mean 2.885021103793406e-06 all mean 5.493548087542877e-06
rl training, epoch6, iter0, batch10/1133, batch loss:2.4776093709988345e-07, Training time:166203.97757554054
batch reward last col mean 2.1750101950601675e-06 first col mean 4.332033859100193e-05 all mean 1.3996267625770997e-05
rl training, epoch6, iter0, batch11/1133, batch loss:5.2047264276211536e-09, Training time:166229.98238778114
batch reward last col mean 9.59248973231297e-06 first col mean 4.5372189561021514e-06 all mean 9.541984582028817e-06
rl training, epoch6, iter0, batch12/1133, batch loss:2.9943106483187876e-07, Training time:166256.1451971531
batch reward last col mean 2.267104690645283e-07 first col mean 5.881973379473493e-07 all mean 2.3200738041850855e-07
rl training, epoch6, iter0, batch13/1133, batch loss:3.077248234006902e-09, Training time:166282.53778457642
batch reward last col mean 1.4322855577120208e-06 first col mean 1.909057345983456e-06 all mean 1.44944851854234e-06
rl training, epoch6, iter0, batch14/1133, batch loss:1.2479104860574353e-08, Training time:166308.5854856968
batch reward last col mean 1.672583266554284e-06 first col mean 6.277069815041614e-07 all mean 1.9845533643092494e-06
rl training, epoch6, iter0, batch15/1133, batch loss:3.904840184532077e-08, Training time:166334.5116839409
batch reward last col mean 8.056333058448217e-07 first col mean 1.2902364687761292e-06 all mean 8.407724862991017e-07
rl training, epoch6, iter0, batch16/1133, batch loss:3.2283582473979777e-09, Training time:166360.5370633602
batch reward last col mean 1.6855604201282404e-07 first col mean 2.57723996810455e-07 all mean 1.9714127574843587e-07
rl training, epoch6, iter0, batch17/1133, batch loss:1.3341647786546673e-09, Training time:166386.56223130226
batch reward last col mean 1.149971808445116e-06 first col mean 6.006758894727682e-07 all mean 1.144654675044876e-06
rl training, epoch6, iter0, batch18/1133, batch loss:1.491969214839628e-08, Training time:166412.62156271935
batch reward last col mean 3.867731720674783e-06 first col mean 8.399745183851337e-07 all mean 3.840930730802938e-06
rl training, epoch6, iter0, batch19/1133, batch loss:5.407436276527733e-08, Training time:166438.8025507927
batch reward last col mean 1.6813843103591353e-05 first col mean 0.0007506443653255701 all mean 2.4228742404375225e-05
rl training, epoch6, iter0, batch20/1133, batch loss:1.4516214719151321e-07, Training time:166464.72569990158
batch reward last col mean 3.827134150924394e-06 first col mean 7.537551027780864e-06 all mean 3.86465217161458e-06
rl training, epoch6, iter0, batch21/1133, batch loss:4.5465924358722987e-08, Training time:166490.8355536461
batch reward last col mean 7.197349987109192e-06 first col mean 4.207529400446219e-06 all mean 7.16715976523119e-06
rl training, epoch6, iter0, batch22/1133, batch loss:2.9289761727113728e-08, Training time:166516.96057605743
batch reward last col mean 3.993789505329914e-06 first col mean 1.6394283193221781e-06 all mean 3.971817477577133e-06
rl training, epoch6, iter0, batch23/1133, batch loss:6.26834335548665e-08, Training time:166542.94075250626
batch reward last col mean 9.731179488881025e-06 first col mean 7.554632247774862e-06 all mean 9.709198820928577e-06
rl training, epoch6, iter0, batch24/1133, batch loss:9.813957291271436e-08, Training time:166569.0118045807
batch reward last col mean 5.003128535463475e-06 first col mean 7.9765859481995e-06 all mean 5.033619345340412e-06
rl training, epoch6, iter0, batch25/1133, batch loss:1.2790372094784175e-09, Training time:166594.85754442215
batch reward last col mean 5.847114607604453e-06 first col mean 8.95718221727293e-06 all mean 5.878596311958972e-06
rl training, epoch6, iter0, batch26/1133, batch loss:8.482278701649193e-08, Training time:166621.11205482483
batch reward last col mean 1.3610996347779292e-06 first col mean 7.508322141802637e-07 all mean 1.3549379218602553e-06
rl training, epoch6, iter0, batch27/1133, batch loss:9.539313339246291e-09, Training time:166647.29246520996
batch reward last col mean 4.152840574533911e-06 first col mean 4.8204628910752945e-06 all mean 4.170408828940708e-06
rl training, epoch6, iter0, batch28/1133, batch loss:5.838467043162154e-09, Training time:166673.2825717926
batch reward last col mean 1.3137379028194118e-05 first col mean 6.66770210955292e-06 all mean 1.3089585991110653e-05
rl training, epoch6, iter0, batch29/1133, batch loss:1.7524835982385412e-07, Training time:166699.30824804306
batch reward last col mean 2.42067994804529e-06 first col mean 6.373914402502123e-06 all mean 2.5447093321417924e-06
rl training, epoch6, iter0, batch30/1133, batch loss:1.951135608635468e-08, Training time:166725.1941599846
batch reward last col mean 4.022877874376718e-06 first col mean 2.1277303403621772e-06 all mean 4.004433776572114e-06
rl training, epoch6, iter0, batch31/1133, batch loss:2.652174302397725e-08, Training time:166751.34588956833
batch reward last col mean 0.00010454829316586256 first col mean 1.2057364529027836e-06 all mean 0.00011449463636381552
rl training, epoch6, iter0, batch32/1133, batch loss:1.1833486496470869e-05, Training time:166777.3713707924
batch reward last col mean 1.522855939128931e-07 first col mean 5.244974232709865e-08 all mean 1.5457852953204565e-07
rl training, epoch6, iter0, batch33/1133, batch loss:4.831314792674846e-10, Training time:166803.38039159775
batch reward last col mean 0.00195495318621397 first col mean 1.0200769793300424e-05 all mean 0.0012876038672402501
rl training, epoch6, iter0, batch34/1133, batch loss:0.0002585714100860059, Training time:166830.0565583706
batch reward last col mean 7.171397555794101e-07 first col mean 5.596364189841552e-06 all mean 7.664337999813142e-07
rl training, epoch6, iter0, batch35/1133, batch loss:4.346347726169597e-09, Training time:166855.8995218277
batch reward last col mean 6.733346822329622e-07 first col mean 4.0165093651012285e-07 all mean 6.71544000852009e-07
rl training, epoch6, iter0, batch36/1133, batch loss:1.91436804186651e-08, Training time:166881.96329641342
batch reward last col mean 4.561982507311768e-07 first col mean 1.1144097697979305e-06 all mean 4.6286623955893447e-07
rl training, epoch6, iter0, batch37/1133, batch loss:4.976742129514378e-09, Training time:166908.052018404
batch reward last col mean 3.2594630283711012e-06 first col mean 1.8545164266470238e-06 all mean 3.2465757158206543e-06
rl training, epoch6, iter0, batch38/1133, batch loss:1.2822083839125753e-08, Training time:166934.55517840385
batch reward last col mean 4.779812456945365e-08 first col mean 1.380486622792887e-07 all mean 4.872340397810149e-08
rl training, epoch6, iter0, batch39/1133, batch loss:3.2274027200740463e-12, Training time:166960.43741893768
batch reward last col mean 7.241780508593365e-09 first col mean 0.00035701339947991073 all mean 3.737331098818686e-06
rl training, epoch6, iter0, batch40/1133, batch loss:1.7060633461518648e-10, Training time:166986.2347354889
batch reward last col mean 1.9754505046876147e-05 first col mean 8.054752242969698e-07 all mean 1.9563569367164746e-05
rl training, epoch6, iter0, batch41/1133, batch loss:6.303673671936849e-07, Training time:167012.1240260601
batch reward last col mean 0.00040519278263673186 first col mean 1.544219571769645e-06 all mean 0.00039704752271063626
rl training, epoch6, iter0, batch42/1133, batch loss:1.9348732166690752e-05, Training time:167038.21875667572
batch reward last col mean 5.653440439346014e-06 first col mean 7.161264875321649e-06 all mean 5.668706307915272e-06
rl training, epoch6, iter0, batch43/1133, batch loss:3.512313284659285e-08, Training time:167064.18453717232
batch reward last col mean 6.333680602210734e-08 first col mean 2.1886030481255148e-06 all mean 8.532523452231544e-07
rl training, epoch6, iter0, batch44/1133, batch loss:1.9163596057247823e-11, Training time:167090.12858867645
batch reward last col mean 4.559342414722778e-06 first col mean 1.082375320038409e-06 all mean 1.9083570805378258e-05
rl training, epoch6, iter0, batch45/1133, batch loss:4.883454707282908e-08, Training time:167116.0952489376
batch reward last col mean 2.9106918191246223e-06 first col mean 3.939218458981486e-06 all mean 2.921151462942362e-06
rl training, epoch6, iter0, batch46/1133, batch loss:6.80465861435664e-09, Training time:167142.05385279655
batch reward last col mean 2.1906492175816084e-09 first col mean 2.1778895131774334e-07 all mean 4.425434241284165e-09
rl training, epoch6, iter0, batch47/1133, batch loss:1.1869377009032789e-12, Training time:167168.0223789215
batch reward last col mean 7.2851651111705e-07 first col mean 5.78082278934744e-07 all mean 8.076282824731607e-07
rl training, epoch6, iter0, batch48/1133, batch loss:1.9304223997096415e-08, Training time:167194.0919072628
batch reward last col mean 8.776802928878169e-07 first col mean 5.473060582517064e-07 all mean 8.743932653487718e-07
rl training, epoch6, iter0, batch49/1133, batch loss:5.672974978665479e-09, Training time:167220.19299817085
batch reward last col mean 6.190356316437828e-07 first col mean 6.978010787861422e-06 all mean 6.832766530351364e-07
rl training, epoch6, iter0, batch50/1133, batch loss:4.027584932231321e-09, Training time:167246.41820120811
batch reward last col mean 0.00020931927429046482 first col mean 9.026366569742095e-07 all mean 0.00016204864368773997
rl training, epoch6, iter0, batch51/1133, batch loss:2.799919639073778e-05, Training time:167272.46973371506
batch reward last col mean 3.1655437737754255e-07 first col mean 1.1231130656597088e-06 all mean 6.009428830111574e-07
rl training, epoch6, iter0, batch52/1133, batch loss:8.23517087855663e-10, Training time:167298.6781232357
batch reward last col mean 1.0215555448667146e-05 first col mean 1.6116979168145917e-05 all mean 1.027994767355267e-05
rl training, epoch6, iter0, batch53/1133, batch loss:7.692183778829076e-09, Training time:167324.66536974907
batch reward last col mean 1.736195599733037e-06 first col mean 3.021431282945741e-08 all mean 1.7448788867113763e-06
rl training, epoch6, iter0, batch54/1133, batch loss:1.4449490493007033e-08, Training time:167350.49253058434
batch reward last col mean 6.670179573120549e-06 first col mean 1.067484504346794e-06 all mean 6.613638561248081e-06
rl training, epoch6, iter0, batch55/1133, batch loss:1.3393471931522072e-07, Training time:167376.32820034027
batch reward last col mean 7.116978395060869e-06 first col mean 1.5082478057593107e-06 all mean 7.0667897489329334e-06
rl training, epoch6, iter0, batch56/1133, batch loss:2.1732175170541268e-08, Training time:167402.26190900803
batch reward last col mean 3.0508351755997865e-07 first col mean 1.3734882031712914e-06 all mean 3.1599273597748834e-07
rl training, epoch6, iter0, batch57/1133, batch loss:6.407602892721798e-09, Training time:167428.65933728218
batch reward last col mean 2.965283101730165e-06 first col mean 6.981204947464903e-09 all mean 2.9321283818717347e-06
rl training, epoch6, iter0, batch58/1133, batch loss:9.73078257970883e-08, Training time:167454.93501091003
batch reward last col mean 8.756553171451742e-08 first col mean 8.605716175225098e-07 all mean 9.564835323772058e-08
rl training, epoch6, iter0, batch59/1133, batch loss:3.930021197362521e-09, Training time:167480.76320052147
batch reward last col mean 2.2399085537472274e-06 first col mean 1.1803425650214194e-06 all mean 5.686482836608775e-06
rl training, epoch6, iter0, batch60/1133, batch loss:2.7913557687497814e-08, Training time:167506.72793626785
batch reward last col mean 1.1684912806231296e-06 first col mean 7.0697133196517825e-06 all mean 1.2654937791012344e-06
rl training, epoch6, iter0, batch61/1133, batch loss:3.076516463806911e-08, Training time:167532.76248288155
batch reward last col mean 5.796785899292445e-06 first col mean 1.511320760982926e-06 all mean 5.77661285205977e-06
rl training, epoch6, iter0, batch62/1133, batch loss:4.033650213841611e-08, Training time:167558.8068139553
batch reward last col mean 4.674349440847436e-07 first col mean 5.342769782146206e-07 all mean 4.6831070221742266e-07
rl training, epoch6, iter0, batch63/1133, batch loss:8.094676928749323e-09, Training time:167584.79650902748
batch reward last col mean 2.1430068830596838e-09 first col mean 1.3010941984248348e-05 all mean 1.3408831023298262e-07
rl training, epoch6, iter0, batch64/1133, batch loss:7.100554085676114e-12, Training time:167610.84463572502
batch reward last col mean 9.208524716086686e-06 first col mean 0.0002946218301076442 all mean 1.2091502867406234e-05
rl training, epoch6, iter0, batch65/1133, batch loss:9.088476815577451e-08, Training time:167636.86754226685
batch reward last col mean 5.651787887472892e-06 first col mean 2.1752016436948907e-06 all mean 1.3124908036843408e-05
rl training, epoch6, iter0, batch66/1133, batch loss:4.664194364067953e-09, Training time:167663.13525795937
batch reward last col mean 1.260379605128037e-07 first col mean 3.877761173498584e-06 all mean 1.925347351061646e-05
rl training, epoch6, iter0, batch67/1133, batch loss:8.914031179863002e-10, Training time:167689.48250222206
batch reward last col mean 4.642280600819504e-06 first col mean 2.373278675804613e-06 all mean 4.619361789082177e-06
rl training, epoch6, iter0, batch68/1133, batch loss:3.5282678112480426e-08, Training time:167715.48033857346
batch reward last col mean 8.365323083125986e-07 first col mean 1.2914772185013135e-07 all mean 2.0503546238614945e-06
rl training, epoch6, iter0, batch69/1133, batch loss:3.089545685952544e-08, Training time:167741.37302327156
batch reward last col mean 2.3232502144310274e-08 first col mean 2.0254624644167052e-08 all mean 1.3930183229149407e-07
rl training, epoch6, iter0, batch70/1133, batch loss:1.3312192459480343e-09, Training time:167767.25484466553
batch reward last col mean 8.251881808973849e-06 first col mean 3.6604656088456977e-06 all mean 8.207496648537926e-06
rl training, epoch6, iter0, batch71/1133, batch loss:1.142483867511146e-07, Training time:167793.30652594566
batch reward last col mean 4.6425515165537945e-07 first col mean 5.937010428169742e-06 all mean 5.183871394365269e-07
rl training, epoch6, iter0, batch72/1133, batch loss:1.7571013088968357e-08, Training time:167819.29661345482
batch reward last col mean 9.078885199187425e-08 first col mean 2.0994099259041832e-07 all mean 9.260640609909387e-08
rl training, epoch6, iter0, batch73/1133, batch loss:4.5076281596223566e-10, Training time:167845.35926008224
batch reward last col mean 1.9689621240104316e-06 first col mean 5.517626959772315e-07 all mean 1.954655090230517e-06
rl training, epoch6, iter0, batch74/1133, batch loss:4.276051868146169e-08, Training time:167871.3555867672
batch reward last col mean 6.142318209612085e-09 first col mean 5.4904663038257695e-09 all mean 8.491190861548148e-09
rl training, epoch6, iter0, batch75/1133, batch loss:3.3658336534569955e-11, Training time:167897.1704981327
batch reward last col mean 1.182981691272289e-06 first col mean 1.6021873534555198e-06 all mean 3.0689318464283133e-06
rl training, epoch6, iter0, batch76/1133, batch loss:8.053117062090109e-10, Training time:167923.1218085289
batch reward last col mean 6.876066618133336e-05 first col mean 3.5298613511258736e-05 all mean 6.900583684910089e-05
rl training, epoch6, iter0, batch77/1133, batch loss:4.896837140222488e-07, Training time:167949.84714341164
batch reward last col mean 3.284396370872855e-06 first col mean 1.519037141406443e-06 all mean 3.335923111080774e-06
rl training, epoch6, iter0, batch78/1133, batch loss:7.460303663719969e-08, Training time:167975.97389268875
batch reward last col mean 1.5247845112753566e-05 first col mean 8.05622767074965e-06 all mean 1.5331333997892216e-05
rl training, epoch6, iter0, batch79/1133, batch loss:4.6581104129472806e-07, Training time:168001.8799381256
batch reward last col mean 3.653119165392127e-06 first col mean 6.729197593813296e-06 all mean 3.684260263980832e-06
rl training, epoch6, iter0, batch80/1133, batch loss:5.7704180989048837e-08, Training time:168027.69168901443
batch reward last col mean 5.694113269782974e-07 first col mean 3.199467073500273e-06 all mean 6.192082651068631e-07
rl training, epoch6, iter0, batch81/1133, batch loss:2.0856910865063583e-08, Training time:168053.691511631
batch reward last col mean 7.457954325218452e-07 first col mean 2.07182347367052e-05 all mean 1.092932393476076e-06
rl training, epoch6, iter0, batch82/1133, batch loss:2.7143811642815763e-09, Training time:168079.63618540764
batch reward last col mean 2.776875135168666e-06 first col mean 3.4150716601288877e-06 all mean 2.7832986688736128e-06
rl training, epoch6, iter0, batch83/1133, batch loss:1.148932593508789e-08, Training time:168105.71755814552
batch reward last col mean 1.0365204161644215e-07 first col mean 1.4028728401171975e-05 all mean 2.7051669349020813e-07
rl training, epoch6, iter0, batch84/1133, batch loss:1.0002697559130524e-09, Training time:168131.7584092617
batch reward last col mean 1.5211975551210344e-05 first col mean 6.520890565298032e-06 all mean 1.5126161088119261e-05
rl training, epoch6, iter0, batch85/1133, batch loss:7.827670600590864e-08, Training time:168158.31400728226
batch reward last col mean 0.0029431981965899467 first col mean 1.416434201928496e-06 all mean 0.002913550240918994
rl training, epoch6, iter0, batch86/1133, batch loss:0.00011878233635798097, Training time:168184.37917375565
batch reward last col mean 3.911987732863054e-06 first col mean 2.2554220322490437e-06 all mean 3.896769612765638e-06
rl training, epoch6, iter0, batch87/1133, batch loss:1.8718338878898066e-08, Training time:168210.64560556412
batch reward last col mean 6.776234386052238e-06 first col mean 3.2179113986785524e-06 all mean 6.7408127506496385e-06
rl training, epoch6, iter0, batch88/1133, batch loss:6.579224987035559e-08, Training time:168236.7810845375
batch reward last col mean 1.0702594366307494e-09 first col mean 1.6677764506312087e-05 all mean 1.7009607233831048e-07
rl training, epoch6, iter0, batch89/1133, batch loss:5.026123831367024e-13, Training time:168262.68623185158
batch reward last col mean 5.2299797971500084e-05 first col mean 1.327758491243003e-05 all mean 5.1905852160416543e-05
rl training, epoch6, iter0, batch90/1133, batch loss:3.931749574803689e-07, Training time:168288.66853117943
batch reward last col mean 4.249114837762136e-09 first col mean 7.0993128247209825e-06 all mean 3.794189638028911e-07
rl training, epoch6, iter0, batch91/1133, batch loss:1.1580555958623506e-11, Training time:168314.57023143768
batch reward last col mean 2.3513271116826218e-06 first col mean 1.0481726349098608e-06 all mean 2.338165359105915e-06
rl training, epoch6, iter0, batch92/1133, batch loss:1.1814866862636109e-09, Training time:168340.58309817314
batch reward last col mean 7.347786663558509e-07 first col mean 4.605550202541053e-06 all mean 7.752419151074719e-07
rl training, epoch6, iter0, batch93/1133, batch loss:1.6463660434951066e-09, Training time:168366.6796286106
batch reward last col mean 1.0867547217685569e-07 first col mean 2.1233746849702584e-07 all mean 4.658993930206634e-06
rl training, epoch6, iter0, batch94/1133, batch loss:1.7033352506246047e-10, Training time:168392.56904888153
batch reward last col mean 5.946280907664914e-06 first col mean 5.887152838113252e-06 all mean 5.946675628365483e-06
rl training, epoch6, iter0, batch95/1133, batch loss:3.0638346970590646e-08, Training time:168418.40153694153
batch reward last col mean 0.00010816370195243508 first col mean 9.162940841633826e-06 all mean 0.00010646515875123441
rl training, epoch6, iter0, batch96/1133, batch loss:9.084687917493284e-06, Training time:168444.76785230637
batch reward last col mean 1.5323322486437974e-06 first col mean 4.130738489038777e-06 all mean 1.959509063453879e-06
rl training, epoch6, iter0, batch97/1133, batch loss:6.336005942131351e-09, Training time:168470.81945180893
batch reward last col mean 1.3193465520089376e-06 first col mean 7.838956662453711e-05 all mean 2.2210699626157293e-06
rl training, epoch6, iter0, batch98/1133, batch loss:7.734776374945795e-09, Training time:168497.16882038116
batch reward last col mean 8.844281182973646e-07 first col mean 6.5711110437405296e-06 all mean 9.419130151400168e-07
rl training, epoch6, iter0, batch99/1133, batch loss:5.957640603071468e-09, Training time:168523.34474086761
batch reward last col mean 1.667999526944186e-06 first col mean 1.0621341317573751e-07 all mean 1.6534221458641696e-06
rl training, epoch6, iter0, batch100/1133, batch loss:1.0893471369399776e-07, Training time:168549.2063755989
batch reward last col mean 7.900933951532352e-07 first col mean 4.549849563773023e-06 all mean 2.7782775759988e-06
rl training, epoch6, iter0, batch101/1133, batch loss:1.136629457221261e-08, Training time:168575.17168307304
batch reward last col mean 1.5225987226585858e-06 first col mean 1.3183745295464178e-06 all mean 1.8568664472695673e-06
rl training, epoch6, iter0, batch102/1133, batch loss:9.415997759276706e-09, Training time:168601.18030452728
batch reward last col mean 1.0244632449030178e-06 first col mean 3.941291311093664e-07 all mean 1.0232137128696195e-06
rl training, epoch6, iter0, batch103/1133, batch loss:9.678277734792573e-09, Training time:168627.19873166084
batch reward last col mean 9.251352821593173e-07 first col mean 0.00050932023441419 all mean 6.055635822121985e-06
rl training, epoch6, iter0, batch104/1133, batch loss:1.9722929067711448e-08, Training time:168653.20204043388
batch reward last col mean 1.3354645034269197e-06 first col mean 1.5896382592472946e-06 all mean 1.338678771389823e-06
rl training, epoch6, iter0, batch105/1133, batch loss:7.941947544054528e-09, Training time:168679.13743758202
batch reward last col mean 0.00026950007304549217 first col mean 0.00015457248082384467 all mean 0.000268339179456234
rl training, epoch6, iter0, batch106/1133, batch loss:6.591397777810926e-06, Training time:168705.362231493
batch reward last col mean 5.706554340179082e-09 first col mean 3.260782978031784e-05 all mean 3.526525063080044e-07
rl training, epoch6, iter0, batch107/1133, batch loss:2.2772983152008486e-11, Training time:168731.26529669762
batch reward last col mean 2.3584652808494866e-05 first col mean 6.850484624010278e-06 all mean 2.341683102713432e-05
rl training, epoch6, iter0, batch108/1133, batch loss:2.7433006266619486e-07, Training time:168757.2660562992
batch reward last col mean 3.805755284247425e-07 first col mean 3.5225564261054387e-06 all mean 4.122004213513719e-07
rl training, epoch6, iter0, batch109/1133, batch loss:7.497176213178136e-09, Training time:168783.72385287285
batch reward last col mean 3.7192444324318785e-07 first col mean 3.0722151223017136e-07 all mean 3.703754316575214e-07
rl training, epoch6, iter0, batch110/1133, batch loss:6.508308114661077e-09, Training time:168809.61269927025
batch reward last col mean 2.7774894988397136e-06 first col mean 5.898179438190709e-07 all mean 2.7809880975837586e-06
rl training, epoch6, iter0, batch111/1133, batch loss:5.506751321604497e-08, Training time:168835.60573458672
batch reward last col mean 2.2393024323719146e-07 first col mean 5.887518454983365e-07 all mean 2.322378662711344e-07
rl training, epoch6, iter0, batch112/1133, batch loss:1.1886241990666235e-09, Training time:168861.58776307106
batch reward last col mean 9.327495718025602e-07 first col mean 3.095657348239911e-07 all mean 9.289074682783394e-07
rl training, epoch6, iter0, batch113/1133, batch loss:1.3598977943729551e-08, Training time:168887.62307167053
batch reward last col mean 2.988215328514343e-06 first col mean 2.4906221369747072e-06 all mean 2.9833313419658225e-06
rl training, epoch6, iter0, batch114/1133, batch loss:4.608404768902119e-09, Training time:168913.5663406849
batch reward last col mean 8.597619398642564e-07 first col mean 1.0738790301445533e-08 all mean 8.513334819326701e-07
rl training, epoch6, iter0, batch115/1133, batch loss:5.791913171293572e-09, Training time:168939.4390926361
batch reward last col mean 4.189081664662808e-06 first col mean 1.3235828646429582e-06 all mean 4.1672756196931005e-06
rl training, epoch6, iter0, batch116/1133, batch loss:1.601186383481945e-08, Training time:168965.4393222332
batch reward last col mean 6.7540181589720305e-06 first col mean 3.233207507946645e-06 all mean 6.747207407897804e-06
rl training, epoch6, iter0, batch117/1133, batch loss:2.770852347566688e-07, Training time:168991.4962222576
batch reward last col mean 9.992899094868335e-07 first col mean 8.164756764017511e-06 all mean 1.071682277142827e-06
rl training, epoch6, iter0, batch118/1133, batch loss:5.594374741235697e-09, Training time:169017.73319625854
batch reward last col mean 1.3120745734340744e-06 first col mean 2.4085532004392007e-06 all mean 1.3232086075731786e-06
rl training, epoch6, iter0, batch119/1133, batch loss:2.7561817717014492e-08, Training time:169043.66042613983
batch reward last col mean 6.96051711202017e-06 first col mean 3.737647602974903e-06 all mean 6.92799358148477e-06
rl training, epoch6, iter0, batch120/1133, batch loss:1.1275322897574824e-08, Training time:169069.51001906395
batch reward last col mean 3.3868720947793918e-06 first col mean 2.633120857353788e-06 all mean 3.3607618661335437e-06
rl training, epoch6, iter0, batch121/1133, batch loss:4.037446643678777e-08, Training time:169095.46602535248
batch reward last col mean 4.755373538500862e-06 first col mean 2.043440872512292e-06 all mean 4.732969046017388e-06
rl training, epoch6, iter0, batch122/1133, batch loss:1.0737083755429921e-07, Training time:169121.76876735687
batch reward last col mean 1.1078356692451052e-05 first col mean 6.739964533153397e-07 all mean 1.0975159057124984e-05
rl training, epoch6, iter0, batch123/1133, batch loss:2.534216037020087e-07, Training time:169148.1311314106
batch reward last col mean 2.389466544627794e-07 first col mean 1.993402293010149e-06 all mean 2.5790865265662433e-07
rl training, epoch6, iter0, batch124/1133, batch loss:1.315414721592134e-10, Training time:169174.0064675808
batch reward last col mean 1.8930006717710057e-06 first col mean 1.2256945183253265e-06 all mean 1.7541155102662742e-05
rl training, epoch6, iter0, batch125/1133, batch loss:8.06636979433506e-09, Training time:169199.89612913132
batch reward last col mean 2.5097943989749183e-07 first col mean 1.119428134188638e-06 all mean 1.2295335181988776e-05
rl training, epoch6, iter0, batch126/1133, batch loss:9.02710084460523e-09, Training time:169225.91527915
batch reward last col mean 0.005190111231058836 first col mean 0.003747959155589342 all mean 0.00517571996897459
rl training, epoch6, iter0, batch127/1133, batch loss:0.00024906432372517884, Training time:169251.92077708244
batch reward last col mean 7.401048378596897e-07 first col mean 1.1565425666049123e-06 all mean 8.166806537701632e-07
rl training, epoch6, iter0, batch128/1133, batch loss:2.7603475061255267e-08, Training time:169278.0951383114
batch reward last col mean 5.170910526430816e-07 first col mean 9.53922608459834e-07 all mean 5.235395974523271e-07
rl training, epoch6, iter0, batch129/1133, batch loss:1.3083838901195577e-08, Training time:169303.98537898064
batch reward last col mean 1.8364063407716458e-06 first col mean 7.614500191266416e-06 all mean 1.8948228444060078e-06
rl training, epoch6, iter0, batch130/1133, batch loss:2.2338292993140385e-08, Training time:169329.8445353508
batch reward last col mean 1.47513003412314e-06 first col mean 0.0006065209745429456 all mean 2.613725337141659e-05
rl training, epoch6, iter0, batch131/1133, batch loss:1.0363462976670235e-08, Training time:169355.88986873627
batch reward last col mean 5.455108293972444e-07 first col mean 1.2673332321355701e-06 all mean 5.533990474759776e-07
rl training, epoch6, iter0, batch132/1133, batch loss:8.60818361037019e-10, Training time:169381.90453362465
batch reward last col mean 2.9024390642007347e-06 first col mean 3.742587296073907e-06 all mean 3.046580104637542e-06
rl training, epoch6, iter0, batch133/1133, batch loss:1.6292007742890746e-08, Training time:169408.28382349014
batch reward last col mean 1.0487375448064995e-06 first col mean 1.8659127363207517e-06 all mean 1.243927727045957e-06
rl training, epoch6, iter0, batch134/1133, batch loss:2.1947862194338086e-08, Training time:169434.31316900253
batch reward last col mean 1.2987884474569e-06 first col mean 1.5734214287022041e-07 all mean 1.290683712795726e-06
rl training, epoch6, iter0, batch135/1133, batch loss:1.5892602789335797e-08, Training time:169460.2378938198
batch reward last col mean 3.483862656139536e-07 first col mean 1.6500048332090955e-06 all mean 3.6259632452129154e-07
rl training, epoch6, iter0, batch136/1133, batch loss:8.862669709230886e-09, Training time:169486.2325577736
batch reward last col mean 0.007020126096904278 first col mean 0.005263480823487043 all mean 0.007002548780292273
rl training, epoch6, iter0, batch137/1133, batch loss:0.0004516475019045174, Training time:169512.19152283669
batch reward last col mean 2.132514822505982e-07 first col mean 2.213676140172538e-07 all mean 1.716741962809465e-06
rl training, epoch6, iter0, batch138/1133, batch loss:4.316974777651694e-09, Training time:169538.17538833618
batch reward last col mean 5.472715542964579e-07 first col mean 2.5890810775308637e-06 all mean 5.679607397723885e-07
rl training, epoch6, iter0, batch139/1133, batch loss:2.76674971821933e-09, Training time:169564.1248357296
batch reward last col mean 4.2132938688155264e-05 first col mean 6.978763735787652e-07 all mean 4.171472028247081e-05
rl training, epoch6, iter0, batch140/1133, batch loss:1.5519054841206525e-06, Training time:169590.12171792984
batch reward last col mean 5.290468834573403e-06 first col mean 2.6845043521461776e-06 all mean 5.26423309565871e-06
rl training, epoch6, iter0, batch141/1133, batch loss:1.5786476126322668e-07, Training time:169616.69477844238
batch reward last col mean 7.487412858608877e-07 first col mean 5.1485262702044565e-06 all mean 3.2959342206595466e-06
rl training, epoch6, iter0, batch142/1133, batch loss:1.0236513858785656e-08, Training time:169643.05671453476
batch reward last col mean 4.143217665841803e-06 first col mean 5.312066605256405e-06 all mean 1.8422990251565352e-05
rl training, epoch6, iter0, batch143/1133, batch loss:1.6725421048136013e-08, Training time:169669.3115260601
batch reward last col mean 8.599862667324487e-06 first col mean 3.8171983760548756e-06 all mean 8.558514309697784e-06
rl training, epoch6, iter0, batch144/1133, batch loss:6.068680136195326e-08, Training time:169695.3595547676
batch reward last col mean 5.525651431526057e-06 first col mean 8.924967005441431e-06 all mean 5.56077702640323e-06
rl training, epoch6, iter0, batch145/1133, batch loss:2.6457717794414748e-08, Training time:169721.19666194916
batch reward last col mean 4.855026418226771e-06 first col mean 5.612312816083431e-05 all mean 5.3729045248473994e-06
rl training, epoch6, iter0, batch146/1133, batch loss:9.565182779169845e-08, Training time:169747.30790615082
batch reward last col mean 2.481887690919393e-07 first col mean 3.2000441478885477e-06 all mean 2.7806626690107805e-07
rl training, epoch6, iter0, batch147/1133, batch loss:3.8812411062849606e-09, Training time:169773.2636437416
batch reward last col mean 3.832965740002692e-05 first col mean 2.1188409391470486e-06 all mean 3.8098420191090554e-05
rl training, epoch6, iter0, batch148/1133, batch loss:1.1512045148265315e-06, Training time:169799.5851612091
batch reward last col mean 3.043031142624386e-07 first col mean 2.4882680804694246e-07 all mean 3.2290634521814354e-07
rl training, epoch6, iter0, batch149/1133, batch loss:1.0108414549847566e-08, Training time:169825.53260970116
batch reward last col mean 3.075367203564383e-05 first col mean 5.678022716892883e-06 all mean 3.052617103094235e-05
rl training, epoch6, iter0, batch150/1133, batch loss:1.0573747886155616e-06, Training time:169851.42530727386
batch reward last col mean 9.331589723160505e-08 first col mean 4.8846477511688136e-06 all mean 8.623050234746188e-06
rl training, epoch6, iter0, batch151/1133, batch loss:2.332519288827939e-09, Training time:169877.28515267372
batch reward last col mean 2.481370700024854e-07 first col mean 0.00019925995729863644 all mean 2.2664157768303994e-06
rl training, epoch6, iter0, batch152/1133, batch loss:2.985193869875502e-09, Training time:169903.87508916855
batch reward last col mean 1.2280421515242779e-06 first col mean 4.154337148065679e-05 all mean 1.6353443470507045e-06
rl training, epoch6, iter0, batch153/1133, batch loss:1.933474180759731e-08, Training time:169929.80788588524
batch reward last col mean 7.463840120180976e-06 first col mean 6.9370735218399204e-06 all mean 7.458536856574938e-06
rl training, epoch6, iter0, batch154/1133, batch loss:7.90077248069565e-09, Training time:169955.84294581413
batch reward last col mean 1.2981928421140765e-06 first col mean 5.010532277083257e-06 all mean 1.8794013385559083e-06
rl training, epoch6, iter0, batch155/1133, batch loss:7.693617298798472e-09, Training time:169981.61163640022
batch reward last col mean 2.293035095135565e-07 first col mean 2.166537342418451e-05 all mean 4.4835212520411005e-07
rl training, epoch6, iter0, batch156/1133, batch loss:8.849464494531389e-10, Training time:170007.59150791168
batch reward last col mean 4.349839377582043e-10 first col mean 8.557364594707906e-08 all mean 1.4472441023372085e-09
rl training, epoch6, iter0, batch157/1133, batch loss:3.919657838320073e-13, Training time:170033.86241459846
batch reward last col mean 1.0059338251267036e-07 first col mean 8.739999657336739e-07 all mean 1.0675226036482854e-07
rl training, epoch6, iter0, batch158/1133, batch loss:7.591267059403606e-10, Training time:170059.81761837006
batch reward last col mean 9.349143397230364e-07 first col mean 6.751912587787956e-05 all mean 1.61184709668305e-06
rl training, epoch6, iter0, batch159/1133, batch loss:4.853339952148872e-09, Training time:170085.7747285366
batch reward last col mean 1.4725832215845003e-06 first col mean 9.719437912281137e-07 all mean 1.468245955038583e-06
rl training, epoch6, iter0, batch160/1133, batch loss:1.4469451414811374e-08, Training time:170111.671595335
batch reward last col mean 1.276331295230193e-05 first col mean 3.700301476783352e-06 all mean 2.1524629119085148e-05
rl training, epoch6, iter0, batch161/1133, batch loss:1.8016675085164024e-06, Training time:170137.63006091118
batch reward last col mean 2.489293365215417e-06 first col mean 1.3160486105334712e-06 all mean 2.480246166669531e-06
rl training, epoch6, iter0, batch162/1133, batch loss:1.0784690473997216e-08, Training time:170164.0911412239
batch reward last col mean 7.45575823302147e-10 first col mean 8.801360991128604e-07 all mean 1.057136250892654e-05
rl training, epoch6, iter0, batch163/1133, batch loss:6.13639694613255e-11, Training time:170190.07973313332
batch reward last col mean 9.842354842248824e-08 first col mean 0.0002360410726396367 all mean 2.483431899236166e-06
rl training, epoch6, iter0, batch164/1133, batch loss:4.1608866352405016e-10, Training time:170216.12724161148
batch reward last col mean 5.18618264777615e-07 first col mean 3.171691332681803e-06 all mean 2.6383381737105083e-06
rl training, epoch6, iter0, batch165/1133, batch loss:9.559347979859467e-09, Training time:170241.99795365334
batch reward last col mean 1.5794827845638792e-07 first col mean 2.3153646111495618e-07 all mean 1.7096569138175255e-07
rl training, epoch6, iter0, batch166/1133, batch loss:1.4883726195957792e-10, Training time:170268.09246730804
batch reward last col mean 4.2434913893885096e-07 first col mean 9.295437308765031e-08 all mean 1.306747435592115e-05
rl training, epoch6, iter0, batch167/1133, batch loss:7.0484813541327185e-09, Training time:170294.13727474213
batch reward last col mean 2.5499566902453807e-09 first col mean 2.858185021992199e-09 all mean 1.9647422959678806e-06
rl training, epoch6, iter0, batch168/1133, batch loss:4.22511643727308e-11, Training time:170320.7533288002
batch reward last col mean 1.0382696018496063e-05 first col mean 4.678220193454763e-06 all mean 1.0333778845961206e-05
rl training, epoch6, iter0, batch169/1133, batch loss:1.3846805302364373e-07, Training time:170347.3352549076
batch reward last col mean 3.3885303309943993e-06 first col mean 9.619761840440333e-06 all mean 3.4611375667736866e-06
rl training, epoch6, iter0, batch170/1133, batch loss:2.0964840530268702e-08, Training time:170373.3604092598
batch reward last col mean 2.987934522025171e-07 first col mean 8.724321673980739e-07 all mean 3.390224776467221e-07
rl training, epoch6, iter0, batch171/1133, batch loss:1.6365870436629848e-08, Training time:170399.77024698257
batch reward last col mean 9.564456377120223e-06 first col mean 9.88011834124336e-06 all mean 1.3959794159745798e-05
rl training, epoch6, iter0, batch172/1133, batch loss:7.301685656102563e-08, Training time:170425.99567341805
batch reward last col mean 4.1760173985494475e-07 first col mean 2.637228817548021e-07 all mean 4.195274527774018e-07
rl training, epoch6, iter0, batch173/1133, batch loss:2.1814125505947857e-10, Training time:170452.0466003418
batch reward last col mean 2.3443204710815735e-08 first col mean 5.314191753313935e-07 all mean 2.868109483245007e-08
rl training, epoch6, iter0, batch174/1133, batch loss:5.792170996304913e-12, Training time:170478.48500180244
batch reward last col mean 1.340841095043288e-06 first col mean 1.1397829666748294e-06 all mean 1.9108834749204107e-05
rl training, epoch6, iter0, batch175/1133, batch loss:1.3101254303649057e-08, Training time:170504.4135541916
batch reward last col mean 3.2150535844266415e-05 first col mean 1.7255599232157692e-05 all mean 4.845523289986886e-05
rl training, epoch6, iter0, batch176/1133, batch loss:2.0384815968554904e-07, Training time:170530.49925112724
batch reward last col mean 9.906349305310869e-07 first col mean 1.2735675909425481e-06 all mean 1.2605086112671415e-06
rl training, epoch6, iter0, batch177/1133, batch loss:1.0918911996782299e-08, Training time:170557.0357210636
batch reward last col mean 2.4255987227661535e-06 first col mean 3.0698502087034285e-06 all mean 2.4321063847310143e-06
rl training, epoch6, iter0, batch178/1133, batch loss:3.076403487511925e-08, Training time:170583.53868937492
batch reward last col mean 1.4964109141146764e-05 first col mean 1.8305476260138676e-05 all mean 2.007606417464558e-05
rl training, epoch6, iter0, batch179/1133, batch loss:6.698219294776209e-07, Training time:170609.71114706993
batch reward last col mean 5.76611682845396e-07 first col mean 1.619940661612418e-07 all mean 1.708076069917297e-06
rl training, epoch6, iter0, batch180/1133, batch loss:5.276863834779988e-09, Training time:170635.6218738556
batch reward last col mean 3.13729827894349e-07 first col mean 3.529608250119054e-07 all mean 8.229656600633461e-07
rl training, epoch6, iter0, batch181/1133, batch loss:1.4188161756578666e-09, Training time:170661.85935735703
batch reward last col mean 3.8199637231173256e-08 first col mean 7.932975677249487e-06 all mean 5.551224603550509e-06
rl training, epoch6, iter0, batch182/1133, batch loss:1.3555675471010886e-09, Training time:170688.09629797935
batch reward last col mean 1.9574931684473995e-06 first col mean 8.445165917692066e-07 all mean 1.947165856108768e-06
rl training, epoch6, iter0, batch183/1133, batch loss:8.66083826878139e-09, Training time:170714.16572999954
batch reward last col mean 1.7265245233488713e-08 first col mean 5.810467769151728e-07 all mean 2.6135335673416193e-08
rl training, epoch6, iter0, batch184/1133, batch loss:1.573662311571411e-09, Training time:170740.1669676304
batch reward last col mean 5.569264089899661e-07 first col mean 6.176316560413397e-07 all mean 5.613804319182236e-07
rl training, epoch6, iter0, batch185/1133, batch loss:2.116261166307254e-09, Training time:170766.11335015297
batch reward last col mean 9.740688255988061e-09 first col mean 9.901162201231273e-08 all mean 1.0098040092998417e-07
rl training, epoch6, iter0, batch186/1133, batch loss:2.4946282019266963e-12, Training time:170792.0498664379
batch reward last col mean 3.240215664845891e-05 first col mean 1.9741226424230263e-05 all mean 3.227448178222403e-05
rl training, epoch6, iter0, batch187/1133, batch loss:2.3313533858981828e-07, Training time:170818.15410399437
batch reward last col mean 2.1352032035792945e-06 first col mean 3.2106470371218165e-06 all mean 2.146158976756851e-06
rl training, epoch6, iter0, batch188/1133, batch loss:1.5068122749539725e-08, Training time:170844.4666314125
batch reward last col mean 1.961369520131484e-07 first col mean 3.2318982903234428e-06 all mean 2.2680789868445572e-07
rl training, epoch6, iter0, batch189/1133, batch loss:1.4725616559463361e-10, Training time:170870.48545265198
batch reward last col mean 1.7093974520321353e-06 first col mean 2.427300614726846e-06 all mean 1.7169319335152977e-06
rl training, epoch6, iter0, batch190/1133, batch loss:1.2337852961508133e-09, Training time:170896.51896047592
batch reward last col mean 8.65775120928447e-07 first col mean 7.979478687047958e-05 all mean 1.6682892010067008e-06
rl training, epoch6, iter0, batch191/1133, batch loss:1.7874928204264506e-08, Training time:170922.46433901787
batch reward last col mean 6.888134976179572e-06 first col mean 7.278176283875837e-09 all mean 6.818983820267022e-06
rl training, epoch6, iter0, batch192/1133, batch loss:5.973772942979849e-08, Training time:170948.56610178947
batch reward last col mean 1.915919256134657e-06 first col mean 9.07527237359318e-07 all mean 1.9057379176956601e-06
rl training, epoch6, iter0, batch193/1133, batch loss:7.471548713056109e-08, Training time:170974.6970794201
batch reward last col mean 5.7735576319828397e-08 first col mean 2.1674113668268546e-06 all mean 2.1712668285545078e-07
rl training, epoch6, iter0, batch194/1133, batch loss:2.128603293627407e-09, Training time:171000.7236881256
batch reward last col mean 2.2787869369267355e-08 first col mean 1.9141459972615849e-07 all mean 1.0595604180707596e-05
rl training, epoch6, iter0, batch195/1133, batch loss:1.8961072989487349e-10, Training time:171026.56810474396
batch reward last col mean 7.691168661949632e-07 first col mean 1.2715457160084043e-05 all mean 8.898857117856096e-07
rl training, epoch6, iter0, batch196/1133, batch loss:7.191550910334854e-09, Training time:171052.64560556412
batch reward last col mean 2.624487706270884e-06 first col mean 1.0752341950137634e-06 all mean 2.9821196676493855e-06
rl training, epoch6, iter0, batch197/1133, batch loss:4.015010901525784e-08, Training time:171078.7140340805
batch reward last col mean 7.787261324665451e-07 first col mean 2.0183839296805672e-05 all mean 9.69426423580444e-07
rl training, epoch6, iter0, batch198/1133, batch loss:8.176219701283571e-09, Training time:171104.83292865753
batch reward last col mean 1.8606982621349744e-06 first col mean 1.7225693227373995e-06 all mean 1.8602349882712588e-06
rl training, epoch6, iter0, batch199/1133, batch loss:7.452978678657018e-09, Training time:171130.9295873642
batch reward last col mean 4.742997589346487e-06 first col mean 3.193699012626894e-05 all mean 5.021857759857085e-06
rl training, epoch6, iter0, batch200/1133, batch loss:6.032859545257452e-08, Training time:171156.9484539032
batch reward last col mean 5.020683147449745e-06 first col mean 3.289136884632171e-06 all mean 5.003832939109998e-06
rl training, epoch6, iter0, batch201/1133, batch loss:2.645960250902135e-08, Training time:171183.24998736382
batch reward last col mean 6.460492727455858e-07 first col mean 2.9715884011238813e-05 all mean 9.38422090257518e-07
rl training, epoch6, iter0, batch202/1133, batch loss:7.848666605525523e-09, Training time:171209.27587151527
batch reward last col mean 6.500056315417169e-07 first col mean 1.7356740045215702e-07 all mean 6.584932634723373e-07
rl training, epoch6, iter0, batch203/1133, batch loss:2.850025104805809e-09, Training time:171235.50753998756
batch reward last col mean 2.3634783019588212e-09 first col mean 1.3055965553121496e-07 all mean 1.4596984954096115e-08
rl training, epoch6, iter0, batch204/1133, batch loss:2.1991226548112586e-11, Training time:171261.58461880684
batch reward last col mean 0.0004690768546424806 first col mean 0.00012026544573018327 all mean 0.0004655544471461326
rl training, epoch6, iter0, batch205/1133, batch loss:1.0467094398336485e-05, Training time:171287.6570801735
batch reward last col mean 5.4524580264114775e-06 first col mean 2.1296352770150406e-06 all mean 1.673546648817137e-05
rl training, epoch6, iter0, batch206/1133, batch loss:1.9459506006569427e-07, Training time:171313.72907853127
batch reward last col mean 5.093783784104744e-06 first col mean 1.5769441006341367e-06 all mean 6.301216217252659e-06
rl training, epoch6, iter0, batch207/1133, batch loss:7.892705156109514e-08, Training time:171339.84539723396
batch reward last col mean 3.738756277016364e-05 first col mean 2.5401715902262367e-05 all mean 3.737304359674454e-05
rl training, epoch6, iter0, batch208/1133, batch loss:6.716729217259854e-07, Training time:171365.99643015862
batch reward last col mean 1.0539092727412935e-06 first col mean 9.500683518126607e-06 all mean 1.3231824596005026e-06
rl training, epoch6, iter0, batch209/1133, batch loss:7.485533082274287e-09, Training time:171392.41218328476
batch reward last col mean 1.377499575028196e-05 first col mean 1.4555968846252654e-05 all mean 1.378290107822977e-05
rl training, epoch6, iter0, batch210/1133, batch loss:5.76012233466372e-08, Training time:171418.23674941063
batch reward last col mean 2.407901320111705e-06 first col mean 1.1590086614887696e-06 all mean 2.4008049877011217e-06
rl training, epoch6, iter0, batch211/1133, batch loss:5.197512820132033e-08, Training time:171444.27245926857
batch reward last col mean 1.9711023924173787e-06 first col mean 1.7277458255193778e-06 all mean 2.0015647805848857e-06
rl training, epoch6, iter0, batch212/1133, batch loss:1.6815729253494283e-08, Training time:171470.39183568954
batch reward last col mean 3.744570130947977e-05 first col mean 1.5303374311770312e-05 all mean 3.7306446756701916e-05
rl training, epoch6, iter0, batch213/1133, batch loss:6.722576131323876e-07, Training time:171496.4764034748
batch reward last col mean 9.585352017893456e-06 first col mean 2.862429482775042e-06 all mean 9.777061677596066e-06
rl training, epoch6, iter0, batch214/1133, batch loss:1.5339378478529397e-07, Training time:171522.63267540932
batch reward last col mean 1.758170128596248e-06 first col mean 1.5987264987415983e-06 all mean 1.7587244656169787e-06
rl training, epoch6, iter0, batch215/1133, batch loss:3.1206675021877572e-09, Training time:171548.81306529045
batch reward last col mean 1.568394509376958e-06 first col mean 9.306506854045438e-07 all mean 1.580885282237432e-06
rl training, epoch6, iter0, batch216/1133, batch loss:4.421562671552692e-09, Training time:171574.80936908722
batch reward last col mean 8.884217250759718e-10 first col mean 3.055765773751773e-05 all mean 3.0956431373851956e-07
rl training, epoch6, iter0, batch217/1133, batch loss:3.839173770558979e-12, Training time:171600.80207538605
batch reward last col mean 5.6895994930528104e-05 first col mean 4.311737939133309e-06 all mean 5.64792389923241e-05
rl training, epoch6, iter0, batch218/1133, batch loss:6.050647698430112e-07, Training time:171626.84245181084
batch reward last col mean 3.133404788968619e-07 first col mean 5.264984679342888e-07 all mean 3.531136485435127e-07
rl training, epoch6, iter0, batch219/1133, batch loss:3.900165523873511e-09, Training time:171653.08249664307
batch reward last col mean 2.0302541869909874e-09 first col mean 4.250935035088332e-06 all mean 6.202659363907514e-08
rl training, epoch6, iter0, batch220/1133, batch loss:8.153722488857262e-12, Training time:171678.9030330181
batch reward last col mean 6.8067602114751935e-06 first col mean 1.8501229703815625e-07 all mean 6.740749540767865e-06
rl training, epoch6, iter0, batch221/1133, batch loss:1.0361316782336871e-07, Training time:171705.1855287552
batch reward last col mean 5.22948312209337e-06 first col mean 5.747749128204305e-06 all mean 5.234724085312337e-06
rl training, epoch6, iter0, batch222/1133, batch loss:2.824831479841805e-09, Training time:171731.51556873322
batch reward last col mean 8.754880582273472e-06 first col mean 3.0257269827416167e-06 all mean 9.806902198761236e-06
rl training, epoch6, iter0, batch223/1133, batch loss:6.598137503033286e-08, Training time:171757.63080263138
batch reward last col mean 1.2581788269017125e-06 first col mean 2.965731482618139e-07 all mean 1.4232311968953582e-06
rl training, epoch6, iter0, batch224/1133, batch loss:9.693224889417706e-09, Training time:171784.21783328056
batch reward last col mean 2.4707294414838543e-06 first col mean 0.0007222039857879281 all mean 9.744037924974691e-06
rl training, epoch6, iter0, batch225/1133, batch loss:1.6313929762645785e-08, Training time:171810.14697265625
batch reward last col mean 4.3028558138757944e-05 first col mean 3.8427719118772075e-05 all mean 4.29819556302391e-05
rl training, epoch6, iter0, batch226/1133, batch loss:3.113767661488964e-07, Training time:171836.23261404037
batch reward last col mean 4.048787559440825e-06 first col mean 3.0952010092732962e-06 all mean 1.718630301184021e-05
rl training, epoch6, iter0, batch227/1133, batch loss:4.6944713005814265e-08, Training time:171862.29327726364
batch reward last col mean 2.662552651599981e-05 first col mean 1.3146846868039574e-05 all mean 2.663504892552737e-05
rl training, epoch6, iter0, batch228/1133, batch loss:1.1750241668551098e-07, Training time:171888.40463542938
batch reward last col mean 1.8868281870254577e-07 first col mean 1.3189529454393778e-05 all mean 3.199611171567085e-07
rl training, epoch6, iter0, batch229/1133, batch loss:1.3204535243005466e-09, Training time:171914.7480955124
batch reward last col mean 1.2525387091955054e-06 first col mean 1.582814093126217e-06 all mean 1.2803674280803534e-06
rl training, epoch6, iter0, batch230/1133, batch loss:8.770937753865837e-09, Training time:171940.68321728706
batch reward last col mean 2.149394731532084e-06 first col mean 2.1375120923039503e-05 all mean 2.207890611316543e-05
rl training, epoch6, iter0, batch231/1133, batch loss:4.834087619087768e-08, Training time:171966.78118658066
batch reward last col mean 7.772961907903664e-06 first col mean 2.379126726737013e-06 all mean 7.911885404610075e-06
rl training, epoch6, iter0, batch232/1133, batch loss:5.691878754987556e-07, Training time:171993.4186205864
batch reward last col mean 4.879605626229022e-07 first col mean 5.086220880912151e-06 all mean 9.397609801453655e-07
rl training, epoch6, iter0, batch233/1133, batch loss:1.0403087280508316e-09, Training time:172019.5242984295
batch reward last col mean 4.218336471240036e-07 first col mean 8.524481245331117e-07 all mean 7.450748285009468e-07
rl training, epoch6, iter0, batch234/1133, batch loss:1.0640262892991359e-08, Training time:172045.72332119942
batch reward last col mean 2.117879489560437e-07 first col mean 6.880833325340063e-07 all mean 2.1676926564850874e-07
rl training, epoch6, iter0, batch235/1133, batch loss:8.757988778640424e-10, Training time:172071.61341619492
batch reward last col mean 3.4971474178746575e-06 first col mean 5.126707947056275e-07 all mean 3.4670206332521047e-06
rl training, epoch6, iter0, batch236/1133, batch loss:2.565855083958013e-08, Training time:172097.7918434143
batch reward last col mean 6.910929073455918e-07 first col mean 3.7914436688879505e-05 all mean 1.0673112456061062e-06
rl training, epoch6, iter0, batch237/1133, batch loss:1.4657028923892312e-09, Training time:172123.75131297112
batch reward last col mean 3.196739635313861e-05 first col mean 4.082860129983601e-07 all mean 3.164881854900159e-05
rl training, epoch6, iter0, batch238/1133, batch loss:2.1917894628131762e-06, Training time:172150.15090203285
batch reward last col mean 2.2545755200553685e-06 first col mean 4.248784989613341e-06 all mean 2.2749313757230993e-06
rl training, epoch6, iter0, batch239/1133, batch loss:3.3249387687561693e-09, Training time:172176.13946151733
batch reward last col mean 0.0004274602106306702 first col mean 1.4082895631872816e-06 all mean 0.0002710859989747405
rl training, epoch6, iter0, batch240/1133, batch loss:6.222947558853775e-05, Training time:172202.44605660439
batch reward last col mean 5.678890033777861e-07 first col mean 6.958013614166703e-07 all mean 5.693614752999565e-07
rl training, epoch6, iter0, batch241/1133, batch loss:1.7269096375116533e-08, Training time:172228.44116330147
batch reward last col mean 1.2110288480471354e-05 first col mean 2.778053385554813e-06 all mean 1.320822411798872e-05
rl training, epoch6, iter0, batch242/1133, batch loss:2.0955420154677995e-07, Training time:172254.5537557602
batch reward last col mean 9.08850233827252e-06 first col mean 1.4541416021529585e-05 all mean 2.008785850193817e-05
rl training, epoch6, iter0, batch243/1133, batch loss:3.1658856869398733e-07, Training time:172280.84631562233
batch reward last col mean 2.289470785399317e-06 first col mean 2.0125610262766713e-06 all mean 2.390077952441061e-06
rl training, epoch6, iter0, batch244/1133, batch loss:3.265651926653845e-08, Training time:172306.92093348503
batch reward last col mean 5.427779115052545e-07 first col mean 4.3875263600057224e-07 all mean 8.005530617083423e-06
rl training, epoch6, iter0, batch245/1133, batch loss:8.399964279703909e-09, Training time:172332.77222156525
batch reward last col mean 3.940808710467536e-06 first col mean 1.5505958117500995e-06 all mean 3.916764853784116e-06
rl training, epoch6, iter0, batch246/1133, batch loss:2.0660854360698977e-08, Training time:172358.8912949562
batch reward last col mean 6.891084325388874e-08 first col mean 1.2300151865929365e-06 all mean 1.4132791648080456e-07
rl training, epoch6, iter0, batch247/1133, batch loss:3.1131519584448597e-10, Training time:172384.9657034874
batch reward last col mean 3.872505476465449e-05 first col mean 1.3934947673988063e-05 all mean 3.847498373943381e-05
rl training, epoch6, iter0, batch248/1133, batch loss:7.193305577857245e-07, Training time:172411.25092959404
batch reward last col mean 8.712534054211574e-07 first col mean 4.737232188745111e-07 all mean 7.432789516315097e-06
rl training, epoch6, iter0, batch249/1133, batch loss:4.776026685249235e-07, Training time:172437.27363586426
batch reward last col mean 9.150285791292845e-07 first col mean 4.253241058904678e-06 all mean 1.773255348780367e-06
rl training, epoch6, iter0, batch250/1133, batch loss:1.7998502244154224e-08, Training time:172463.5761179924
batch reward last col mean 9.90002718026517e-07 first col mean 4.1865160937959445e-07 all mean 9.842844974627951e-07
rl training, epoch6, iter0, batch251/1133, batch loss:9.569435910350421e-09, Training time:172489.6244404316
batch reward last col mean 3.7233903640299104e-06 first col mean 0.0001449214032618329 all mean 5.1501842790457886e-06
rl training, epoch6, iter0, batch252/1133, batch loss:1.1881479133890593e-09, Training time:172515.67156648636
batch reward last col mean 4.947972342961293e-07 first col mean 2.645650283739087e-06 all mean 5.210217750573065e-07
rl training, epoch6, iter0, batch253/1133, batch loss:1.9956472030457917e-08, Training time:172541.8307762146
batch reward last col mean 6.813595064159017e-06 first col mean 4.70405302621657e-06 all mean 6.792812200728804e-06
rl training, epoch6, iter0, batch254/1133, batch loss:1.294775699989259e-07, Training time:172568.3571088314
batch reward last col mean 1.3209566986915888e-06 first col mean 5.500520273926668e-05 all mean 1.8632547380548203e-06
rl training, epoch6, iter0, batch255/1133, batch loss:1.1138865829707356e-08, Training time:172594.5013012886
batch reward last col mean 3.9816587360519407e-08 first col mean 8.324109757040787e-08 all mean 4.0914571286521095e-08
rl training, epoch6, iter0, batch256/1133, batch loss:2.0230042641067314e-10, Training time:172620.50222325325
batch reward last col mean 4.839981784243719e-07 first col mean 1.1933127552765654e-06 all mean 4.913346174362232e-07
rl training, epoch6, iter0, batch257/1133, batch loss:1.8767208620484865e-10, Training time:172646.57148694992
batch reward last col mean 1.4227702195057645e-05 first col mean 8.07639844424557e-06 all mean 1.4279376046033576e-05
rl training, epoch6, iter0, batch258/1133, batch loss:1.0033087249894379e-07, Training time:172672.92045235634
batch reward last col mean 2.2977086700848304e-05 first col mean 5.120341938891215e-06 all mean 1.4402617125597317e-05
rl training, epoch6, iter0, batch259/1133, batch loss:1.1847399719044915e-06, Training time:172699.42415761948
batch reward last col mean 4.1587359191908035e-06 first col mean 5.935931312706089e-06 all mean 4.208358404866885e-06
rl training, epoch6, iter0, batch260/1133, batch loss:6.668624763506159e-09, Training time:172725.358877182
batch reward last col mean 0.0002050698531093076 first col mean 0.00020992784993723035 all mean 0.00020581865101121366
rl training, epoch6, iter0, batch261/1133, batch loss:1.210199661727529e-05, Training time:172751.47345614433
batch reward last col mean 1.3898744555262965e-07 first col mean 3.411652187423897e-07 all mean 1.414620101058972e-07
rl training, epoch6, iter0, batch262/1133, batch loss:1.321346088101194e-10, Training time:172777.59688806534
batch reward last col mean 7.17290902230161e-07 first col mean 2.6752246640171506e-07 all mean 2.927513151007588e-06
rl training, epoch6, iter0, batch263/1133, batch loss:2.5207109732861e-09, Training time:172803.64034676552
batch reward last col mean 2.7924579626414925e-07 first col mean 5.0163245759904385e-05 all mean 1.0742445510913967e-06
rl training, epoch6, iter0, batch264/1133, batch loss:4.36503916345643e-10, Training time:172829.99587130547
batch reward last col mean 2.028068047366105e-05 first col mean 2.233843360954779e-06 all mean 2.8927741368534043e-05
rl training, epoch6, iter0, batch265/1133, batch loss:1.1858619330951115e-07, Training time:172856.671282053
batch reward last col mean 1.6373462131014094e-05 first col mean 3.461187588982284e-06 all mean 1.6215231880778447e-05
rl training, epoch6, iter0, batch266/1133, batch loss:8.252094971794577e-07, Training time:172884.09091329575
batch reward last col mean 4.310290478315437e-06 first col mean 2.254206492580124e-06 all mean 4.290984179533552e-06
rl training, epoch6, iter0, batch267/1133, batch loss:1.2921259440190624e-07, Training time:172910.67205953598
batch reward last col mean 0.00042071755160577595 first col mean 5.756166956416564e-07 all mean 0.0004164906276855618
rl training, epoch6, iter0, batch268/1133, batch loss:2.413127185718622e-05, Training time:172937.24181962013
batch reward last col mean 1.7118626374212909e-06 first col mean 3.4645632695173845e-05 all mean 1.0174741873925086e-05
rl training, epoch6, iter0, batch269/1133, batch loss:2.04455252728053e-09, Training time:172964.17949867249
batch reward last col mean 4.968918801750988e-05 first col mean 5.638381708195084e-07 all mean 4.9192971346201375e-05
rl training, epoch6, iter0, batch270/1133, batch loss:3.6722226468555164e-06, Training time:172991.15601730347
batch reward last col mean 1.4812329141022929e-07 first col mean 2.0034617591591086e-06 all mean 1.6723171825105965e-07
rl training, epoch6, iter0, batch271/1133, batch loss:3.281924731979302e-09, Training time:173017.19616818428
batch reward last col mean 8.613947102276143e-07 first col mean 1.8245016235596268e-06 all mean 8.711270425010298e-07
rl training, epoch6, iter0, batch272/1133, batch loss:7.347851749273104e-08, Training time:173043.81945991516
batch reward last col mean 1.7728972068198345e-07 first col mean 9.557538049875802e-08 all mean 1.4017987268744037e-06
rl training, epoch6, iter0, batch273/1133, batch loss:4.9820916281362315e-09, Training time:173071.19718837738
batch reward last col mean 2.6652067390386946e-05 first col mean 0.0002915239310823381 all mean 3.5189761547371745e-05
rl training, epoch6, iter0, batch274/1133, batch loss:1.925504420796642e-06, Training time:173097.39667129517
batch reward last col mean 1.7387624211551156e-06 first col mean 2.350965587538667e-06 all mean 1.7479475218351581e-06
rl training, epoch6, iter0, batch275/1133, batch loss:8.177807764297995e-09, Training time:173123.7207813263
batch reward last col mean 5.7104284678644035e-06 first col mean 3.914286935469136e-06 all mean 5.711171070288401e-06
rl training, epoch6, iter0, batch276/1133, batch loss:1.0218785817528442e-08, Training time:173150.71125531197
batch reward last col mean 1.994917511183303e-06 first col mean 6.936291470083233e-07 all mean 1.980191655093222e-06
rl training, epoch6, iter0, batch277/1133, batch loss:9.994129612778124e-08, Training time:173177.62577271461
batch reward last col mean 7.431600579366204e-08 first col mean 7.981947192092775e-07 all mean 8.1318745515091e-08
rl training, epoch6, iter0, batch278/1133, batch loss:3.9852459110534255e-09, Training time:173204.33048844337
batch reward last col mean 3.061815004912205e-05 first col mean 8.758830517763272e-06 all mean 3.040062620129902e-05
rl training, epoch6, iter0, batch279/1133, batch loss:4.4642709440267936e-07, Training time:173231.2086918354
batch reward last col mean 1.3688911622011801e-06 first col mean 4.510450708039571e-06 all mean 1.4006317314851913e-06
rl training, epoch6, iter0, batch280/1133, batch loss:1.0244544768056585e-07, Training time:173258.57868742943
batch reward last col mean 4.356431418273132e-06 first col mean 6.3762963691260666e-06 all mean 4.421872745297151e-06
rl training, epoch6, iter0, batch281/1133, batch loss:6.214833803142028e-08, Training time:173285.61742591858
batch reward last col mean 7.010497711235075e-07 first col mean 1.9181159132131143e-06 all mean 7.133936605896452e-07
rl training, epoch6, iter0, batch282/1133, batch loss:1.1618722872697163e-08, Training time:173312.36194872856
batch reward last col mean 1.5581015304633183e-06 first col mean 6.487250175268855e-06 all mean 1.6106135944937705e-06
rl training, epoch6, iter0, batch283/1133, batch loss:1.023396811739019e-09, Training time:173339.62672424316
batch reward last col mean 1.3101417835059692e-06 first col mean 4.894845187664032e-05 all mean 1.791780391613429e-06
rl training, epoch6, iter0, batch284/1133, batch loss:9.57883017349559e-09, Training time:173366.2020881176
batch reward last col mean 5.797684025310446e-06 first col mean 3.887188995577162e-06 all mean 5.778643753728829e-06
rl training, epoch6, iter0, batch285/1133, batch loss:5.466739594339742e-08, Training time:173393.30799508095
batch reward last col mean 6.762892007827759e-05 first col mean 2.4804428903735243e-05 all mean 8.453453483525664e-05
rl training, epoch6, iter0, batch286/1133, batch loss:2.5542414050505613e-07, Training time:173419.58628726006
batch reward last col mean 4.4273434696151526e-07 first col mean 3.744413277217973e-07 all mean 4.434733682501246e-07
rl training, epoch6, iter0, batch287/1133, batch loss:8.627784597869947e-10, Training time:173446.86229777336
batch reward last col mean 7.88366833148757e-06 first col mean 8.402043022215366e-06 all mean 7.948588063300122e-06
rl training, epoch6, iter0, batch288/1133, batch loss:6.679940156573139e-08, Training time:173473.46061968803
batch reward last col mean 2.4551125079597114e-06 first col mean 1.2463307257348788e-06 all mean 2.4429773475276306e-06
rl training, epoch6, iter0, batch289/1133, batch loss:6.6561809397569505e-09, Training time:173500.17422890663
batch reward last col mean 1.2621957239389303e-06 first col mean 7.96829738192173e-07 all mean 2.133937960024923e-05
rl training, epoch6, iter0, batch290/1133, batch loss:7.705644122779631e-09, Training time:173526.10179829597
batch reward last col mean 2.6233328753733076e-06 first col mean 1.23598820209736e-05 all mean 2.9702689516852843e-06
rl training, epoch6, iter0, batch291/1133, batch loss:2.9633184794874978e-08, Training time:173553.41299676895
batch reward last col mean 1.5264593002939364e-06 first col mean 1.9362994407856604e-06 all mean 1.5318303212552564e-06
rl training, epoch6, iter0, batch292/1133, batch loss:5.3420464496412023e-08, Training time:173579.93129873276
batch reward last col mean 1.916342862173792e-09 first col mean 1.4396505321201403e-06 all mean 9.455480665110372e-08
rl training, epoch6, iter0, batch293/1133, batch loss:3.0532625039381145e-12, Training time:173607.01350164413
batch reward last col mean 3.368783291080035e-05 first col mean 6.719354814777034e-07 all mean 3.3356405765516683e-05
rl training, epoch6, iter0, batch294/1133, batch loss:1.674939198892389e-06, Training time:173633.8419930935
batch reward last col mean 7.37928473881766e-07 first col mean 2.540789864724502e-06 all mean 2.1816144908370916e-06
rl training, epoch6, iter0, batch295/1133, batch loss:9.564310232690332e-09, Training time:173659.75847148895
batch reward last col mean 6.23220403213054e-05 first col mean 8.16707979538478e-05 all mean 6.251796003198251e-05
rl training, epoch6, iter0, batch296/1133, batch loss:5.979069328532205e-07, Training time:173686.58921337128
batch reward last col mean 3.382746172064799e-06 first col mean 1.430466568308475e-06 all mean 3.410119916225085e-06
rl training, epoch6, iter0, batch297/1133, batch loss:2.756733508135767e-08, Training time:173713.26649403572
batch reward last col mean 4.997311897625423e-09 first col mean 2.815498412189754e-08 all mean 8.229548598137626e-09
rl training, epoch6, iter0, batch298/1133, batch loss:2.8212384685366576e-12, Training time:173739.94146037102
batch reward last col mean 4.834091100747173e-07 first col mean 4.23246638092678e-06 all mean 1.0114658834936563e-06
rl training, epoch6, iter0, batch299/1133, batch loss:1.236902136270146e-08, Training time:173766.11754179
batch reward last col mean 1.98494103642588e-06 first col mean 2.1292767087288667e-06 all mean 5.300817520037526e-06
rl training, epoch6, iter0, batch300/1133, batch loss:5.543404313357314e-08, Training time:173792.75100970268
batch reward last col mean 6.348243459797231e-07 first col mean 3.470069600552961e-07 all mean 6.346076020236069e-07
rl training, epoch6, iter0, batch301/1133, batch loss:2.452511083106401e-09, Training time:173819.8453233242
batch reward last col mean 5.935739864071365e-07 first col mean 3.1565907647745917e-06 all mean 8.556118018532288e-07
rl training, epoch6, iter0, batch302/1133, batch loss:5.033225392025997e-09, Training time:173847.26147675514
batch reward last col mean 6.346675945678726e-05 first col mean 3.1496045949097606e-07 all mean 6.285063864197582e-05
rl training, epoch6, iter0, batch303/1133, batch loss:5.174466650714749e-07, Training time:173873.46591687202
batch reward last col mean 5.732229965360602e-06 first col mean 5.486755981110036e-06 all mean 5.729955773858819e-06
rl training, epoch6, iter0, batch304/1133, batch loss:1.3247655417103488e-08, Training time:173900.06277036667
batch reward last col mean 1.4368700931299827e-06 first col mean 8.739742952457163e-06 all mean 1.5108994375623297e-06
rl training, epoch6, iter0, batch305/1133, batch loss:2.754330763465873e-09, Training time:173926.8771123886
batch reward last col mean 5.6761909945635125e-06 first col mean 9.769123607838992e-07 all mean 5.982454240438528e-06
rl training, epoch6, iter0, batch306/1133, batch loss:6.291644893963166e-08, Training time:173953.15309023857
batch reward last col mean 1.184784309771203e-06 first col mean 1.247786940439255e-07 all mean 1.1805458370872657e-06
rl training, epoch6, iter0, batch307/1133, batch loss:2.1580358833261926e-08, Training time:173980.282238245
batch reward last col mean 1.132065904130286e-06 first col mean 8.848991797094641e-07 all mean 1.130012151406845e-06
rl training, epoch6, iter0, batch308/1133, batch loss:2.7947091307822802e-09, Training time:174007.1986324787
batch reward last col mean 3.9377252392114315e-07 first col mean 4.277561401977437e-06 all mean 4.331949980951322e-07
rl training, epoch6, iter0, batch309/1133, batch loss:1.4525493030603798e-09, Training time:174034.13829874992
batch reward last col mean 5.591810349869775e-06 first col mean 1.6169140508282e-05 all mean 5.69930489291437e-06
rl training, epoch6, iter0, batch310/1133, batch loss:1.2647449310065895e-08, Training time:174061.29121255875
batch reward last col mean 8.09171160653932e-06 first col mean 0.00010331420344300568 all mean 1.2099136256438214e-05
rl training, epoch6, iter0, batch311/1133, batch loss:9.743904172410112e-08, Training time:174088.26593995094
batch reward last col mean 1.097537727368092e-09 first col mean 1.7298000329901697e-06 all mean 6.293161192161278e-08
rl training, epoch6, iter0, batch312/1133, batch loss:1.5876458134278515e-12, Training time:174114.5974597931
batch reward last col mean 1.358813960905536e-06 first col mean 1.3938193887952366e-06 all mean 1.3592390359917772e-06
rl training, epoch6, iter0, batch313/1133, batch loss:5.421649240666682e-10, Training time:174141.56503152847
batch reward last col mean 2.4239472622866742e-05 first col mean 2.2233024310480687e-09 all mean 2.4014323571464047e-05
rl training, epoch6, iter0, batch314/1133, batch loss:3.291626455848018e-07, Training time:174168.0837202072
batch reward last col mean 4.1585749954720086e-08 first col mean 2.3803979232184247e-08 all mean 5.52595167846448e-07
rl training, epoch6, iter0, batch315/1133, batch loss:6.358292781172281e-10, Training time:174195.0511879921
batch reward last col mean 6.806681085436139e-07 first col mean 1.8311493477085605e-06 all mean 6.922915645191097e-07
rl training, epoch6, iter0, batch316/1133, batch loss:5.083496290581024e-09, Training time:174221.82121872902
batch reward last col mean 1.0198776863035164e-06 first col mean 4.613994804003596e-07 all mean 1.0158677241633995e-06
rl training, epoch6, iter0, batch317/1133, batch loss:2.805695231700156e-08, Training time:174248.8852956295
batch reward last col mean 2.246312931220018e-07 first col mean 9.617212981538614e-07 all mean 1.9734241504920647e-05
rl training, epoch6, iter0, batch318/1133, batch loss:6.823180354054159e-10, Training time:174275.17385745049
batch reward last col mean 3.725443093571812e-06 first col mean 3.1933475383993937e-06 all mean 3.7200763927103253e-06
rl training, epoch6, iter0, batch319/1133, batch loss:1.13807168133917e-07, Training time:174302.4927983284
batch reward last col mean 1.7995625967159867e-07 first col mean 1.35898781081778e-05 all mean 3.1528341537523374e-07
rl training, epoch6, iter0, batch320/1133, batch loss:2.0399772981960496e-09, Training time:174329.4536960125
batch reward last col mean 1.3332879689187394e-06 first col mean 1.6890809320102562e-06 all mean 1.3409966186372912e-06
rl training, epoch6, iter0, batch321/1133, batch loss:7.758994335915759e-09, Training time:174355.83562660217
batch reward last col mean 0.00019765603065025061 first col mean 5.03272576679592e-06 all mean 0.0001940205693244934
rl training, epoch6, iter0, batch322/1133, batch loss:1.3507633411791176e-05, Training time:174383.01968240738
batch reward last col mean 3.2414499173683e-07 first col mean 3.1131203286349773e-06 all mean 4.417051684413309e-07
rl training, epoch6, iter0, batch323/1133, batch loss:4.006531773015354e-10, Training time:174409.41966199875
batch reward last col mean 6.728623134222289e-07 first col mean 4.831889555134694e-07 all mean 6.914382311151712e-07
rl training, epoch6, iter0, batch324/1133, batch loss:2.6559325849717652e-09, Training time:174436.14918398857
batch reward last col mean 6.477113402070245e-06 first col mean 2.2201297156243527e-07 all mean 6.4139308051380794e-06
rl training, epoch6, iter0, batch325/1133, batch loss:7.425807524441552e-08, Training time:174462.47106790543
batch reward last col mean 1.0643788073139149e-06 first col mean 7.951497536851093e-06 all mean 2.319075974810403e-06
rl training, epoch6, iter0, batch326/1133, batch loss:2.5602830078241823e-08, Training time:174489.40350055695
batch reward last col mean 2.3743516521790298e-06 first col mean 3.878823463310255e-06 all mean 2.389559767834726e-06
rl training, epoch6, iter0, batch327/1133, batch loss:2.032127532913819e-08, Training time:174516.2774529457
batch reward last col mean 1.7103463960665977e-06 first col mean 7.283622380782617e-06 all mean 2.1014043340983335e-06
rl training, epoch6, iter0, batch328/1133, batch loss:4.2181169668253915e-09, Training time:174542.86975741386
batch reward last col mean 4.706569143309025e-06 first col mean 1.8902210285887122e-06 all mean 4.667928806156851e-06
rl training, epoch6, iter0, batch329/1133, batch loss:8.250051308777984e-08, Training time:174569.76471567154
batch reward last col mean 2.9898319553467445e-07 first col mean 4.251635800756048e-06 all mean 3.3892024475790095e-07
rl training, epoch6, iter0, batch330/1133, batch loss:4.680293486103437e-09, Training time:174595.73920464516
batch reward last col mean 4.1829243855318055e-06 first col mean 2.8270062557567144e-06 all mean 4.183273631497286e-06
rl training, epoch6, iter0, batch331/1133, batch loss:1.4291351213557846e-08, Training time:174623.39024043083
batch reward last col mean 7.574970368295908e-06 first col mean 8.990631613414735e-06 all mean 7.704462404944934e-06
rl training, epoch6, iter0, batch332/1133, batch loss:2.5425919147892273e-07, Training time:174651.40765237808
batch reward last col mean 5.190819329925489e-09 first col mean 4.333599008532474e-07 all mean 9.549970592104273e-09
rl training, epoch6, iter0, batch333/1133, batch loss:2.1019496906915514e-12, Training time:174679.24271035194
batch reward last col mean 3.374909738340648e-07 first col mean 1.4920516377969761e-07 all mean 3.4446389918230125e-07
rl training, epoch6, iter0, batch334/1133, batch loss:3.5167844192329767e-09, Training time:174706.24881529808
batch reward last col mean 1.0684829248930328e-05 first col mean 4.872286808677018e-06 all mean 1.0988364920194726e-05
rl training, epoch6, iter0, batch335/1133, batch loss:1.3371433738029737e-07, Training time:174733.16855597496
batch reward last col mean 2.8712825042020995e-06 first col mean 1.8287830698682228e-06 all mean 1.727295784803573e-05
rl training, epoch6, iter0, batch336/1133, batch loss:7.071554364301846e-08, Training time:174760.0239777565
batch reward last col mean 7.969681092845349e-08 first col mean 1.3873845091438852e-05 all mean 2.1903512958942883e-07
rl training, epoch6, iter0, batch337/1133, batch loss:1.9296021724901635e-10, Training time:174786.88702702522
batch reward last col mean 0.001542621641419828 first col mean 0.0018767376895993948 all mean 0.0015459966380149126
rl training, epoch6, iter0, batch338/1133, batch loss:9.466055780649185e-05, Training time:174812.97294831276
batch reward last col mean 3.931247192667797e-05 first col mean 5.214318662183359e-06 all mean 3.8904738175915554e-05
rl training, epoch6, iter0, batch339/1133, batch loss:8.197797001230356e-07, Training time:174839.38605332375
batch reward last col mean 1.5847438135097036e-06 first col mean 1.3081976248940919e-06 all mean 1.5819709915376734e-06
rl training, epoch6, iter0, batch340/1133, batch loss:1.0467294586646858e-08, Training time:174865.97903871536
batch reward last col mean 3.1658848911320092e-06 first col mean 4.9999848670267966e-06 all mean 3.1844228942645714e-06
rl training, epoch6, iter0, batch341/1133, batch loss:4.087282956533045e-09, Training time:174892.4414203167
batch reward last col mean 3.6015346260853676e-09 first col mean 1.0798291327773768e-07 all mean 1.0002047929447144e-05
rl training, epoch6, iter0, batch342/1133, batch loss:2.6559213162080653e-10, Training time:174918.20851421356
batch reward last col mean 6.584824352451335e-10 first col mean 6.890882104926277e-07 all mean 1.2412824617058504e-06
rl training, epoch6, iter0, batch343/1133, batch loss:5.154360445402961e-12, Training time:174944.2037870884
batch reward last col mean 0.006785597186535597 first col mean 4.756904309033416e-05 all mean 0.0004010647826362401
rl training, epoch6, iter0, batch344/1133, batch loss:0.0009839056292548776, Training time:174970.3917207718
batch reward last col mean 9.738385415403172e-06 first col mean 2.6235748009639792e-06 all mean 9.666530786489602e-06
rl training, epoch6, iter0, batch345/1133, batch loss:1.4619074306665425e-07, Training time:174996.54909610748
batch reward last col mean 3.086850483668968e-06 first col mean 1.749851435306482e-06 all mean 3.0733463063370436e-06
rl training, epoch6, iter0, batch346/1133, batch loss:1.633310375837027e-08, Training time:175023.5552535057
batch reward last col mean 8.609850738139357e-06 first col mean 7.739068678347394e-06 all mean 8.73613498697523e-06
rl training, epoch6, iter0, batch347/1133, batch loss:5.509548017812449e-08, Training time:175050.0452632904
batch reward last col mean 1.565072307130322e-05 first col mean 6.922169291101454e-07 all mean 1.546122439322062e-05
rl training, epoch6, iter0, batch348/1133, batch loss:6.517406063721864e-07, Training time:175076.70180392265
batch reward last col mean 4.7083362005651e-05 first col mean 5.2357125241542235e-05 all mean 4.713704765890725e-05
rl training, epoch6, iter0, batch349/1133, batch loss:4.707366315415129e-06, Training time:175103.4070608616
batch reward last col mean 4.9839518396765925e-06 first col mean 5.5283826441154815e-06 all mean 6.545619726239238e-06
rl training, epoch6, iter0, batch350/1133, batch loss:1.9244605908852463e-09, Training time:175130.27121281624
batch reward last col mean 1.1347707662423545e-08 first col mean 3.8601365304202773e-07 all mean 1.4564725461241324e-06
rl training, epoch6, iter0, batch351/1133, batch loss:2.3243077601486917e-11, Training time:175157.6842188835
batch reward last col mean 0.0017785343807190657 first col mean 2.8745577651534404e-07 all mean 0.0017426167614758015
rl training, epoch6, iter0, batch352/1133, batch loss:9.924828191287816e-05, Training time:175184.5907084942
batch reward last col mean 1.137681579166383e-06 first col mean 6.073676672713191e-09 all mean 1.1372513881724444e-06
rl training, epoch6, iter0, batch353/1133, batch loss:1.8808240298540113e-08, Training time:175212.19497799873
batch reward last col mean 1.0138170182472095e-05 first col mean 7.685903256060556e-06 all mean 1.0115802069776691e-05
rl training, epoch6, iter0, batch354/1133, batch loss:3.465255815626733e-08, Training time:175239.71042513847
batch reward last col mean 5.39242783759164e-09 first col mean 1.1609299832571196e-07 all mean 2.2601177818160068e-08
rl training, epoch6, iter0, batch355/1133, batch loss:1.9422350013009737e-12, Training time:175267.13582253456
batch reward last col mean 1.1144592804157583e-07 first col mean 2.811915145173316e-08 all mean 1.6634432540740818e-05
rl training, epoch6, iter0, batch356/1133, batch loss:1.6634109645252693e-09, Training time:175294.33715224266
batch reward last col mean 1.9918661564588547e-06 first col mean 1.1933231007787981e-06 all mean 8.922173947212286e-06
rl training, epoch6, iter0, batch357/1133, batch loss:1.8896791686984216e-08, Training time:175321.63876008987
batch reward last col mean 1.5460023860214278e-05 first col mean 8.929785508371424e-06 all mean 1.7288093658862635e-05
rl training, epoch6, iter0, batch358/1133, batch loss:8.024778708204394e-08, Training time:175348.631690979
batch reward last col mean 3.946127691278889e-08 first col mean 1.2346706057542178e-07 all mean 5.737450464948779e-06
rl training, epoch6, iter0, batch359/1133, batch loss:2.394662801386005e-10, Training time:175374.80975174904
batch reward last col mean 2.057702431557118e-06 first col mean 2.473849690431962e-06 all mean 4.426187842909712e-06
rl training, epoch6, iter0, batch360/1133, batch loss:6.420090681302781e-09, Training time:175402.0912513733
batch reward last col mean 5.186209364183014e-07 first col mean 5.76221680148592e-07 all mean 5.194665391172748e-07
rl training, epoch6, iter0, batch361/1133, batch loss:1.9407329077125723e-09, Training time:175428.4616844654
batch reward last col mean 2.8355145786918e-06 first col mean 2.9891969006712316e-06 all mean 1.2343822163529694e-05
rl training, epoch6, iter0, batch362/1133, batch loss:1.1361164453660422e-08, Training time:175455.13480734825
batch reward last col mean 1.6899150068638846e-05 first col mean 5.18683577865886e-07 all mean 1.673390215728432e-05
rl training, epoch6, iter0, batch363/1133, batch loss:2.8597531809282373e-07, Training time:175481.9970448017
batch reward last col mean 2.6265522592439083e-06 first col mean 6.90933575242525e-07 all mean 2.606266889415565e-06
rl training, epoch6, iter0, batch364/1133, batch loss:4.088488836373472e-08, Training time:175509.42236948013
batch reward last col mean 7.94905372458743e-06 first col mean 2.6988964236807078e-05 all mean 2.9022949092905037e-05
rl training, epoch6, iter0, batch365/1133, batch loss:3.065186859885216e-08, Training time:175536.52926707268
batch reward last col mean 4.925044549963786e-07 first col mean 2.3144549743392417e-07 all mean 4.898296310784644e-07
rl training, epoch6, iter0, batch366/1133, batch loss:1.196215304588577e-08, Training time:175562.69673633575
batch reward last col mean 1.695670221124601e-06 first col mean 3.0327851163747255e-06 all mean 1.709187699816539e-06
rl training, epoch6, iter0, batch367/1133, batch loss:1.1521718690232774e-08, Training time:175589.6844882965
batch reward last col mean 1.0299434052285505e-06 first col mean 1.3514614693121985e-05 all mean 1.1731173117368598e-06
rl training, epoch6, iter0, batch368/1133, batch loss:2.6027275890072588e-09, Training time:175616.18229222298
batch reward last col mean 9.068871804629453e-06 first col mean 4.082484792888863e-06 all mean 9.020217476063408e-06
rl training, epoch6, iter0, batch369/1133, batch loss:1.2624136047634238e-07, Training time:175642.89019155502
batch reward last col mean 4.045633431815077e-06 first col mean 1.9869798961735796e-07 all mean 4.006787094112951e-06
rl training, epoch6, iter0, batch370/1133, batch loss:8.09015432423621e-08, Training time:175668.87444329262
batch reward last col mean 4.188865659671137e-06 first col mean 3.0651174256490776e-06 all mean 1.2086036804248579e-05
rl training, epoch6, iter0, batch371/1133, batch loss:4.703095157765347e-08, Training time:175695.16354894638
batch reward last col mean 5.304551450535655e-06 first col mean 3.500452692151157e-07 all mean 5.2545065045706e-06
rl training, epoch6, iter0, batch372/1133, batch loss:1.1522131160290883e-07, Training time:175722.47943019867
batch reward last col mean 1.1490855911233666e-07 first col mean 7.803184416843578e-05 all mean 1.6341001582986792e-06
rl training, epoch6, iter0, batch373/1133, batch loss:6.444582201226012e-09, Training time:175749.57701945305
batch reward last col mean 1.2769636668963358e-05 first col mean 3.265913846917101e-06 all mean 1.310825246036984e-05
rl training, epoch6, iter0, batch374/1133, batch loss:6.641084127068098e-08, Training time:175775.89055752754
batch reward last col mean 6.076905947338673e-07 first col mean 8.887903959475807e-07 all mean 6.095498292779666e-07
rl training, epoch6, iter0, batch375/1133, batch loss:2.0458113425547708e-08, Training time:175802.9833805561
batch reward last col mean 3.3272126529482193e-06 first col mean 3.3004530450853053e-06 all mean 3.3287051337538287e-06
rl training, epoch6, iter0, batch376/1133, batch loss:2.6716952206129463e-08, Training time:175830.91967701912
batch reward last col mean 2.3351467461907305e-06 first col mean 2.5704846393637126e-06 all mean 2.3375594082608586e-06
rl training, epoch6, iter0, batch377/1133, batch loss:1.925681836212334e-08, Training time:175857.95002985
batch reward last col mean 2.360766757192323e-06 first col mean 1.5871620462348801e-06 all mean 2.367379693168914e-06
rl training, epoch6, iter0, batch378/1133, batch loss:7.606909768753667e-09, Training time:175885.08052635193
batch reward last col mean 2.220094074800727e-06 first col mean 7.817840923962649e-06 all mean 2.1765064957435243e-05
rl training, epoch6, iter0, batch379/1133, batch loss:7.348247343941239e-09, Training time:175912.14661741257
batch reward last col mean 1.3968117773544009e-09 first col mean 3.9546731045447814e-07 all mean 5.54321610835018e-09
rl training, epoch6, iter0, batch380/1133, batch loss:1.4154894704271337e-12, Training time:175938.72324967384
batch reward last col mean 8.195125701604411e-05 first col mean 1.307059847022174e-05 all mean 8.12569196568802e-05
rl training, epoch6, iter0, batch381/1133, batch loss:1.1748016959245433e-06, Training time:175965.5083720684
batch reward last col mean 4.147801973886089e-06 first col mean 6.053166998754023e-07 all mean 4.114406237931689e-06
rl training, epoch6, iter0, batch382/1133, batch loss:5.2712106679564386e-08, Training time:175991.6357872486
batch reward last col mean 4.953352217285101e-08 first col mean 3.428958507356583e-06 all mean 8.416785846065977e-08
rl training, epoch6, iter0, batch383/1133, batch loss:1.7753297720801697e-09, Training time:176018.45413088799
batch reward last col mean 9.74636122919037e-07 first col mean 4.783088911608502e-07 all mean 9.696503866507555e-07
rl training, epoch6, iter0, batch384/1133, batch loss:1.013757788825842e-08, Training time:176044.52319312096
batch reward last col mean 7.310245564440265e-07 first col mean 4.810189011550392e-07 all mean 9.344534191768616e-06
rl training, epoch6, iter0, batch385/1133, batch loss:6.411215558443928e-09, Training time:176070.39995217323
batch reward last col mean 4.296360657463083e-06 first col mean 2.0934139683959074e-05 all mean 4.397000793687766e-06
rl training, epoch6, iter0, batch386/1133, batch loss:1.7309956490407785e-07, Training time:176096.99840664864
batch reward last col mean 6.858350616312237e-07 first col mean 8.742650265958218e-07 all mean 7.871580578466819e-07
rl training, epoch6, iter0, batch387/1133, batch loss:1.8760161424324906e-08, Training time:176124.13861179352
batch reward last col mean 6.571349786099745e-06 first col mean 2.795395175780868e-06 all mean 6.811787443439243e-06
rl training, epoch6, iter0, batch388/1133, batch loss:4.023848987344536e-08, Training time:176151.37524795532
batch reward last col mean 6.30672639090335e-06 first col mean 0.0001339571172138676 all mean 9.55963241722202e-06
rl training, epoch6, iter0, batch389/1133, batch loss:2.0081006368855014e-07, Training time:176177.9745297432
batch reward last col mean 0.0003120295295957476 first col mean 3.544423918810935e-07 all mean 0.000309026800096035
rl training, epoch6, iter0, batch390/1133, batch loss:1.4570967323379591e-05, Training time:176204.4515786171
batch reward last col mean 6.579938053619117e-05 first col mean 1.3729769307246897e-05 all mean 8.375679317396134e-05
rl training, epoch6, iter0, batch391/1133, batch loss:4.943597105011577e-06, Training time:176231.40553832054
batch reward last col mean 5.367204266804038e-06 first col mean 8.460706908408611e-07 all mean 5.337874881661264e-06
rl training, epoch6, iter0, batch392/1133, batch loss:2.1650144788054604e-07, Training time:176257.36193728447
batch reward last col mean 1.3017444899787733e-08 first col mean 3.230178890589741e-06 all mean 5.594539743469795e-06
rl training, epoch6, iter0, batch393/1133, batch loss:7.047548677974191e-08, Training time:176283.5947687626
batch reward last col mean 5.831680482515367e-06 first col mean 5.4477395678986795e-06 all mean 6.168482741486514e-06
rl training, epoch6, iter0, batch394/1133, batch loss:1.9674962103977123e-08, Training time:176310.7530863285
batch reward last col mean 1.107773761610531e-09 first col mean 1.1838411362319334e-09 all mean 4.262809216726282e-09
rl training, epoch6, iter0, batch395/1133, batch loss:1.9904301189026252e-13, Training time:176337.73850750923
batch reward last col mean 1.2484593980843783e-06 first col mean 2.2648450794804376e-06 all mean 1.4418139926419826e-06
rl training, epoch6, iter0, batch396/1133, batch loss:5.9822489184568894e-09, Training time:176364.12769675255
batch reward last col mean 7.356040441663936e-05 first col mean 8.00326290573139e-07 all mean 8.529428305337206e-05
rl training, epoch6, iter0, batch397/1133, batch loss:1.118166665037279e-06, Training time:176391.02615451813
batch reward last col mean 5.345372642295843e-07 first col mean 1.1879355952260084e-06 all mean 5.411423558143724e-07
rl training, epoch6, iter0, batch398/1133, batch loss:2.1062185329157046e-09, Training time:176417.24079108238
batch reward last col mean 2.8626521952901385e-07 first col mean 8.562871698813979e-06 all mean 3.6986767781854724e-07
rl training, epoch6, iter0, batch399/1133, batch loss:3.6194620633978047e-09, Training time:176443.66050124168
batch reward last col mean 9.919375543177011e-07 first col mean 1.8034752429230139e-06 all mean 1.0505887075851206e-06
rl training, epoch6, iter0, batch400/1133, batch loss:1.078762523754051e-09, Training time:176469.98902368546
batch reward last col mean 2.4740173103054985e-05 first col mean 3.3994283512583934e-06 all mean 2.44205875787884e-05
rl training, epoch6, iter0, batch401/1133, batch loss:1.0628949667079723e-06, Training time:176496.396579504
batch reward last col mean 7.789253686496522e-10 first col mean 3.125160583294928e-05 all mean 3.1656111332267756e-07
rl training, epoch6, iter0, batch402/1133, batch loss:2.4400753639852724e-10, Training time:176522.80626010895
batch reward last col mean 5.429521365840628e-07 first col mean 1.7942561498784926e-06 all mean 5.960316684650024e-07
rl training, epoch6, iter0, batch403/1133, batch loss:5.735359742686796e-09, Training time:176548.77276659012
batch reward last col mean 3.840794793319446e-09 first col mean 2.9606121643155348e-06 all mean 3.401890324994383e-08
rl training, epoch6, iter0, batch404/1133, batch loss:2.5852377964069584e-12, Training time:176574.68922948837
batch reward last col mean 4.076018740306608e-06 first col mean 4.7035273382789455e-06 all mean 4.091087703272933e-06
rl training, epoch6, iter0, batch405/1133, batch loss:6.404832220141543e-08, Training time:176600.6375620365
batch reward last col mean 2.757082484095008e-06 first col mean 1.7246899233214208e-06 all mean 2.746761538219289e-06
rl training, epoch6, iter0, batch406/1133, batch loss:3.244818813641359e-08, Training time:176626.68579530716
batch reward last col mean 2.4740461412875447e-06 first col mean 6.874681730550947e-07 all mean 5.16016280016629e-06
rl training, epoch6, iter0, batch407/1133, batch loss:4.0948727075829083e-08, Training time:176654.30248332024
batch reward last col mean 2.3112695544114104e-06 first col mean 1.1353063200658653e-05 all mean 2.4029127416724805e-06
rl training, epoch6, iter0, batch408/1133, batch loss:1.7154041520583974e-09, Training time:176681.34110927582
batch reward last col mean 1.3181735084799584e-05 first col mean 1.2579769190779189e-06 all mean 1.3148687685315963e-05
rl training, epoch6, iter0, batch409/1133, batch loss:2.024972332037578e-07, Training time:176708.5301604271
batch reward last col mean 1.3881577615393326e-05 first col mean 4.6807454054942355e-06 all mean 1.3788657270197291e-05
rl training, epoch6, iter0, batch410/1133, batch loss:5.349964382617145e-08, Training time:176735.2881731987
batch reward last col mean 7.799203558533918e-06 first col mean 6.423651211662218e-05 all mean 8.3693830674747e-06
rl training, epoch6, iter0, batch411/1133, batch loss:4.0070240459044726e-08, Training time:176762.65499401093
batch reward last col mean 0.0004292936355341226 first col mean 5.428536951512797e-06 all mean 0.00014189926150720567
rl training, epoch6, iter0, batch412/1133, batch loss:4.17420596932061e-05, Training time:176788.8159673214
batch reward last col mean 2.9185929228958685e-09 first col mean 4.0223520159088366e-07 all mean 7.082990638451747e-09
rl training, epoch6, iter0, batch413/1133, batch loss:2.637324169815769e-12, Training time:176815.16150045395
batch reward last col mean 1.3783822971902282e-09 first col mean 1.2346689572950709e-06 all mean 1.4670012760120699e-08
rl training, epoch6, iter0, batch414/1133, batch loss:2.2784302656370103e-12, Training time:176841.19250774384
batch reward last col mean 1.8658994349607383e-06 first col mean 3.9401180401910096e-05 all mean 2.2453129986388376e-06
rl training, epoch6, iter0, batch415/1133, batch loss:9.60151425033473e-09, Training time:176867.0425286293
batch reward last col mean 1.112948484660592e-05 first col mean 9.183155270875432e-06 all mean 1.1502236702654045e-05
rl training, epoch6, iter0, batch416/1133, batch loss:1.5276405918029923e-08, Training time:176893.37212395668
batch reward last col mean 7.739009220131265e-07 first col mean 5.82161987949803e-07 all mean 7.719918357906863e-07
rl training, epoch6, iter0, batch417/1133, batch loss:9.305700654493876e-10, Training time:176919.31635904312
batch reward last col mean 1.716516067062912e-06 first col mean 2.380402520429925e-06 all mean 1.7447711115892162e-06
rl training, epoch6, iter0, batch418/1133, batch loss:7.341824925788387e-09, Training time:176945.13039684296
batch reward last col mean 0.00015178586181718856 first col mean 4.7584362619090825e-05 all mean 0.00015073428221512586
rl training, epoch6, iter0, batch419/1133, batch loss:2.6119578251382336e-06, Training time:176971.1699359417
batch reward last col mean 5.418253749667201e-06 first col mean 3.3026424262061482e-06 all mean 5.441645953396801e-06
rl training, epoch6, iter0, batch420/1133, batch loss:2.872281186228065e-07, Training time:176997.4331932068
batch reward last col mean 8.24639846541686e-06 first col mean 6.42241093373741e-06 all mean 1.6170499293366447e-05
rl training, epoch6, iter0, batch421/1133, batch loss:1.6600631980168146e-08, Training time:177023.88750219345
batch reward last col mean 9.110819121360691e-08 first col mean 9.10492872208124e-08 all mean 2.3450105857136805e-07
rl training, epoch6, iter0, batch422/1133, batch loss:3.0438946502231445e-11, Training time:177050.09414696693
batch reward last col mean 2.697296679343708e-07 first col mean 1.4596957953472156e-06 all mean 2.821962539201195e-07
rl training, epoch6, iter0, batch423/1133, batch loss:6.429333732071996e-10, Training time:177076.65864348412
batch reward last col mean 4.701198577095056e-07 first col mean 8.356105354323518e-07 all mean 2.5351291697006673e-06
rl training, epoch6, iter0, batch424/1133, batch loss:1.1332122795693067e-08, Training time:177102.85844802856
batch reward last col mean 4.831122623727424e-06 first col mean 3.5738705150833994e-07 all mean 4.776395144290291e-06
rl training, epoch6, iter0, batch425/1133, batch loss:3.345816139699309e-07, Training time:177129.09379434586
batch reward last col mean 1.4223093103282736e-07 first col mean 2.1106031908857403e-06 all mean 1.1439643685662304e-06
rl training, epoch6, iter0, batch426/1133, batch loss:8.994954114882603e-09, Training time:177155.46734905243
batch reward last col mean 9.165360665974731e-07 first col mean 5.489827685778437e-07 all mean 9.128254987444961e-07
rl training, epoch6, iter0, batch427/1133, batch loss:1.4322420582857376e-08, Training time:177182.09738373756
batch reward last col mean 2.3641521693207324e-05 first col mean 3.98322981709498e-07 all mean 3.640127761173062e-05
rl training, epoch6, iter0, batch428/1133, batch loss:6.207640126376646e-07, Training time:177207.9155509472
batch reward last col mean 2.412587036815239e-06 first col mean 1.2095017609681236e-06 all mean 2.4005760224099504e-06
rl training, epoch6, iter0, batch429/1133, batch loss:1.1790056930749415e-08, Training time:177234.4570531845
batch reward last col mean 3.967363682022551e-07 first col mean 1.692834672439858e-07 all mean 3.9453570366276836e-07
rl training, epoch6, iter0, batch430/1133, batch loss:2.7821913661796316e-09, Training time:177260.43721556664
batch reward last col mean 3.982147973147221e-06 first col mean 3.5907308415517036e-07 all mean 7.152669240895193e-06
rl training, epoch6, iter0, batch431/1133, batch loss:3.235729195694148e-07, Training time:177287.05588531494
batch reward last col mean 8.190239100258623e-07 first col mean 0.00012885709293186665 all mean 2.1123889837326715e-06
rl training, epoch6, iter0, batch432/1133, batch loss:2.599539783432192e-08, Training time:177313.29083538055
batch reward last col mean 3.8371663322323e-06 first col mean 3.275405617841898e-07 all mean 3.826720330835087e-06
rl training, epoch6, iter0, batch433/1133, batch loss:6.243343619871666e-08, Training time:177339.59047436714
batch reward last col mean 7.653292414033785e-06 first col mean 1.3198161468608305e-05 all mean 7.976368578965776e-06
rl training, epoch6, iter0, batch434/1133, batch loss:3.765281064715964e-08, Training time:177365.37824320793
batch reward last col mean 4.063166670675855e-06 first col mean 4.078931397089036e-06 all mean 4.237998837197665e-06
rl training, epoch6, iter0, batch435/1133, batch loss:1.0937406536015715e-08, Training time:177391.9178533554
batch reward last col mean 5.415975010691909e-06 first col mean 2.9635718874487793e-06 all mean 5.4306610763887875e-06
rl training, epoch6, iter0, batch436/1133, batch loss:2.2743318339735197e-08, Training time:177418.55186772346
batch reward last col mean 6.3309566940006334e-06 first col mean 3.7715728922194103e-06 all mean 6.516062967421021e-06
rl training, epoch6, iter0, batch437/1133, batch loss:9.907705589284888e-08, Training time:177444.63973140717
batch reward last col mean 1.429148255738255e-06 first col mean 1.1071699645981425e-06 all mean 1.5516632174694678e-06
rl training, epoch6, iter0, batch438/1133, batch loss:4.24507407004171e-09, Training time:177470.97166013718
batch reward last col mean 3.602017102366517e-07 first col mean 9.880843663268024e-07 all mean 3.665454642032273e-07
rl training, epoch6, iter0, batch439/1133, batch loss:1.4994634867093737e-08, Training time:177496.6702978611
batch reward last col mean 1.4957255700664973e-07 first col mean 0.0052560665644705296 all mean 9.311090980190784e-05
rl training, epoch6, iter0, batch440/1133, batch loss:0.00017359356570523232, Training time:177522.2834494114
batch reward last col mean 2.7081096050096676e-06 first col mean 6.977076736802701e-06 all mean 3.1534923436993267e-06
rl training, epoch6, iter0, batch441/1133, batch loss:3.201179765710549e-08, Training time:177548.09330773354
batch reward last col mean 3.752530517431296e-07 first col mean 3.221304893941124e-07 all mean 3.748188248664519e-07
rl training, epoch6, iter0, batch442/1133, batch loss:7.486585795746237e-10, Training time:177573.81931757927
batch reward last col mean 2.22014182327257e-06 first col mean 5.816700650029816e-07 all mean 2.300153937540017e-06
rl training, epoch6, iter0, batch443/1133, batch loss:6.778986261224418e-08, Training time:177599.59712696075
batch reward last col mean 1.6029820244511939e-06 first col mean 5.357898089641822e-07 all mean 2.86480121758359e-06
rl training, epoch6, iter0, batch444/1133, batch loss:1.0504690450829912e-08, Training time:177625.2837998867
batch reward last col mean 4.913611974188825e-06 first col mean 1.1821005500678439e-05 all mean 4.983185590390349e-06
rl training, epoch6, iter0, batch445/1133, batch loss:1.8683978808553547e-08, Training time:177650.9969985485
batch reward last col mean 4.0154625935429067e-07 first col mean 5.604204488918185e-06 all mean 4.5428672024172556e-07
rl training, epoch6, iter0, batch446/1133, batch loss:5.163381722184113e-09, Training time:177677.1218407154
batch reward last col mean 2.6632946514837386e-07 first col mean 7.652956992387772e-05 all mean 1.0377473245171132e-06
rl training, epoch6, iter0, batch447/1133, batch loss:2.083613059866707e-09, Training time:177703.3823826313
batch reward last col mean 2.713045205382514e-06 first col mean 9.607516403775662e-06 all mean 2.782707724691136e-06
rl training, epoch6, iter0, batch448/1133, batch loss:3.150590899281269e-08, Training time:177729.28977751732
batch reward last col mean 1.0277719866280677e-06 first col mean 2.0029582969982584e-07 all mean 1.0161957106902264e-06
rl training, epoch6, iter0, batch449/1133, batch loss:4.599845482289311e-08, Training time:177755.75469827652
batch reward last col mean 2.7959915769315558e-06 first col mean 1.8571244027043576e-06 all mean 2.7863113700732356e-06
rl training, epoch6, iter0, batch450/1133, batch loss:3.102939416521622e-08, Training time:177782.5605301857
batch reward last col mean 2.8893975468236022e-05 first col mean 1.560406190037611e-06 all mean 2.861788925656583e-05
rl training, epoch6, iter0, batch451/1133, batch loss:8.875423986864917e-07, Training time:177810.4076874256
batch reward last col mean 1.5721708734872664e-07 first col mean 2.3910959043860203e-06 all mean 1.867688297352288e-07
rl training, epoch6, iter0, batch452/1133, batch loss:1.2638568414047313e-08, Training time:177838.3435637951
batch reward last col mean 4.00749570417247e-07 first col mean 7.901361414042185e-07 all mean 4.0504556864107144e-07
rl training, epoch6, iter0, batch453/1133, batch loss:4.95976282266497e-09, Training time:177865.48303294182
batch reward last col mean 5.9504754972294904e-06 first col mean 3.3377516501786886e-06 all mean 7.220979114208603e-06
rl training, epoch6, iter0, batch454/1133, batch loss:1.5612836534728558e-07, Training time:177891.93926024437
batch reward last col mean 1.056701989909925e-06 first col mean 9.605539617041359e-07 all mean 1.0775579539767932e-06
rl training, epoch6, iter0, batch455/1133, batch loss:1.9294594366670026e-08, Training time:177918.7981250286
batch reward last col mean 1.028105543809943e-06 first col mean 1.0195884669883526e-06 all mean 1.4811837900197133e-05
rl training, epoch6, iter0, batch456/1133, batch loss:7.514955879805996e-10, Training time:177944.7709157467
batch reward last col mean 5.4526499297935516e-06 first col mean 5.4700135478924494e-06 all mean 5.470835731102852e-06
rl training, epoch6, iter0, batch457/1133, batch loss:2.3443210039886253e-08, Training time:177971.50121808052
batch reward last col mean 4.740990334539674e-06 first col mean 1.6552749002585188e-05 all mean 4.86389035359025e-06
rl training, epoch6, iter0, batch458/1133, batch loss:6.913928274343561e-08, Training time:177998.34130096436
batch reward last col mean 1.7218436596522224e-06 first col mean 0.000554799975361675 all mean 7.590565928694559e-06
rl training, epoch6, iter0, batch459/1133, batch loss:2.063071935509697e-09, Training time:178026.01191067696
batch reward last col mean 5.40587961950223e-07 first col mean 3.220784208224359e-07 all mean 4.684144641942112e-06
rl training, epoch6, iter0, batch460/1133, batch loss:4.6924810703785624e-09, Training time:178053.4474451542
batch reward last col mean 3.2406405807705596e-05 first col mean 8.342325600096956e-06 all mean 3.216442564735189e-05
rl training, epoch6, iter0, batch461/1133, batch loss:8.1570431120781e-07, Training time:178080.0658967495
batch reward last col mean 8.318373545534996e-09 first col mean 1.571280563439359e-06 all mean 2.610688021320584e-08
rl training, epoch6, iter0, batch462/1133, batch loss:1.3903629766595649e-12, Training time:178106.83396434784
batch reward last col mean 1.1830535662227248e-08 first col mean 2.8288566682022065e-05 all mean 2.975831705498422e-07
rl training, epoch6, iter0, batch463/1133, batch loss:5.1144019574955735e-12, Training time:178133.62385082245
batch reward last col mean 1.6764719475759193e-05 first col mean 1.7300440958933905e-05 all mean 1.728648021526169e-05
rl training, epoch6, iter0, batch464/1133, batch loss:4.97833696044836e-07, Training time:178160.97438693047
batch reward last col mean 1.0066194136015838e-06 first col mean 3.4615516142366687e-06 all mean 1.617394264030736e-05
rl training, epoch6, iter0, batch465/1133, batch loss:2.4438916668145794e-08, Training time:178188.5392894745
batch reward last col mean 1.4585342569262139e-06 first col mean 2.7851356207975186e-06 all mean 1.4722708101544413e-06
rl training, epoch6, iter0, batch466/1133, batch loss:7.372908950031842e-09, Training time:178214.74374961853
batch reward last col mean 2.610980800454854e-07 first col mean 3.9498565456597134e-05 all mean 8.551480163987435e-07
rl training, epoch6, iter0, batch467/1133, batch loss:4.261851149767182e-10, Training time:178241.76931595802
batch reward last col mean 1.815597715904005e-05 first col mean 7.5753205237560906e-06 all mean 1.8403294234303758e-05
rl training, epoch6, iter0, batch468/1133, batch loss:1.9903475845239882e-07, Training time:178268.90596318245
batch reward last col mean 5.844745487593173e-07 first col mean 2.108085209329147e-05 all mean 8.290802497867844e-07
rl training, epoch6, iter0, batch469/1133, batch loss:3.386829927620738e-09, Training time:178296.30109715462
batch reward last col mean 1.030520706990501e-06 first col mean 2.754640036073397e-07 all mean 1.0229116469417932e-06
rl training, epoch6, iter0, batch470/1133, batch loss:3.2309330322277674e-08, Training time:178322.8577258587
batch reward last col mean 1.6953001704678172e-06 first col mean 2.2968067696638172e-06 all mean 1.7121971040978679e-06
rl training, epoch6, iter0, batch471/1133, batch loss:6.220983728155716e-09, Training time:178349.12351703644
batch reward last col mean 4.741912562167272e-05 first col mean 7.982622264535166e-06 all mean 4.954016912961379e-05
rl training, epoch6, iter0, batch472/1133, batch loss:1.26122472465795e-06, Training time:178375.94234991074
batch reward last col mean 2.215965469076764e-05 first col mean 6.117413249739911e-06 all mean 2.1997926523908973e-05
rl training, epoch6, iter0, batch473/1133, batch loss:2.3605878141097492e-07, Training time:178402.12147450447
batch reward last col mean 6.186136488395277e-06 first col mean 6.423840204661246e-06 all mean 2.5103863663389347e-05
rl training, epoch6, iter0, batch474/1133, batch loss:3.0039475973353547e-07, Training time:178428.65711045265
batch reward last col mean 1.7088551373944938e-07 first col mean 8.832732873997884e-07 all mean 1.7827539977588458e-07
rl training, epoch6, iter0, batch475/1133, batch loss:6.863112300692364e-10, Training time:178455.34704089165
batch reward last col mean 1.3136859706719406e-06 first col mean 1.6343642528227065e-06 all mean 1.7923111954587512e-06
rl training, epoch6, iter0, batch476/1133, batch loss:7.012524450011881e-10, Training time:178482.29917025566
batch reward last col mean 2.653438514244044e-06 first col mean 4.452678331290372e-05 all mean 3.0793876248935703e-06
rl training, epoch6, iter0, batch477/1133, batch loss:1.853948816687989e-08, Training time:178508.50377464294
batch reward last col mean 8.179961810128589e-07 first col mean 6.79292668337439e-07 all mean 8.201171795008122e-07
rl training, epoch6, iter0, batch478/1133, batch loss:7.323168738082586e-09, Training time:178535.0128519535
batch reward last col mean 1.054310178005835e-05 first col mean 1.4544326631948934e-06 all mean 2.4043149096542038e-05
rl training, epoch6, iter0, batch479/1133, batch loss:1.7897610860018176e-07, Training time:178561.81863117218
batch reward last col mean 7.656089096030883e-09 first col mean 3.3333301416860195e-06 all mean 4.146841092733666e-08
rl training, epoch6, iter0, batch480/1133, batch loss:3.58168383840507e-10, Training time:178587.83505558968
batch reward last col mean 4.208407517580781e-06 first col mean 1.3608965900857584e-06 all mean 4.180880750936922e-06
rl training, epoch6, iter0, batch481/1133, batch loss:1.8404836055196938e-07, Training time:178614.9217631817
batch reward last col mean 1.6961925211944617e-05 first col mean 1.4406696209334768e-05 all mean 1.6936655811150558e-05
rl training, epoch6, iter0, batch482/1133, batch loss:8.576314058927892e-08, Training time:178641.50641345978
batch reward last col mean 1.5691792896177503e-06 first col mean 0.00012015411630272865 all mean 2.759722292466904e-06
rl training, epoch6, iter0, batch483/1133, batch loss:6.287518061753872e-08, Training time:178668.60469818115
batch reward last col mean 1.5767825516377343e-06 first col mean 9.539863867757958e-07 all mean 1.5254455547619727e-06
rl training, epoch6, iter0, batch484/1133, batch loss:1.7053729095550807e-08, Training time:178696.05946350098
batch reward last col mean 1.1815702691819752e-06 first col mean 2.411794412182644e-06 all mean 1.1940318245251547e-06
rl training, epoch6, iter0, batch485/1133, batch loss:4.2510141184948225e-08, Training time:178722.10775232315
batch reward last col mean 2.1376456516009057e-06 first col mean 3.89365686714882e-06 all mean 2.167831098631723e-06
rl training, epoch6, iter0, batch486/1133, batch loss:8.798790140929214e-09, Training time:178749.13873434067
batch reward last col mean 5.852994490851415e-06 first col mean 5.363356194720836e-06 all mean 5.8497735153650865e-06
rl training, epoch6, iter0, batch487/1133, batch loss:1.877735833488714e-08, Training time:178775.83845734596
batch reward last col mean 1.338730612587824e-06 first col mean 6.138378921605181e-06 all mean 1.3890226000512484e-06
rl training, epoch6, iter0, batch488/1133, batch loss:5.535645275500656e-10, Training time:178802.9115319252
batch reward last col mean 4.610034576302269e-09 first col mean 3.6438732422539033e-06 all mean 1.3799362363897671e-07
rl training, epoch6, iter0, batch489/1133, batch loss:6.527074453838155e-12, Training time:178829.1688156128
batch reward last col mean 2.1766793452115962e-06 first col mean 1.3054471992290928e-06 all mean 2.1146026483620517e-05
rl training, epoch6, iter0, batch490/1133, batch loss:1.748961331315968e-08, Training time:178856.08328056335
batch reward last col mean 7.242127139761578e-06 first col mean 2.5432780148548773e-06 all mean 7.143350103433477e-06
rl training, epoch6, iter0, batch491/1133, batch loss:3.942728028505371e-07, Training time:178882.9724023342
batch reward last col mean 3.071682286304167e-08 first col mean 5.779350544798945e-07 all mean 3.7956535692273974e-08
rl training, epoch6, iter0, batch492/1133, batch loss:1.5548735909920453e-11, Training time:178910.81492590904
batch reward last col mean 3.1941403904056642e-06 first col mean 9.925444828695618e-06 all mean 8.354033525392879e-06
rl training, epoch6, iter0, batch493/1133, batch loss:4.6239854611940245e-08, Training time:178938.96018481255
batch reward last col mean 5.773669727204833e-06 first col mean 3.577040160962497e-06 all mean 5.765527475887211e-06
rl training, epoch6, iter0, batch494/1133, batch loss:2.4072210891290524e-08, Training time:178965.91203451157
batch reward last col mean 1.4365988398878926e-08 first col mean 2.1555360945058055e-05 all mean 2.483505454620172e-07
rl training, epoch6, iter0, batch495/1133, batch loss:3.433452133716486e-11, Training time:178993.2641825676
batch reward last col mean 1.6726042417758435e-07 first col mean 4.828458486372256e-07 all mean 1.6182217450477765e-06
rl training, epoch6, iter0, batch496/1133, batch loss:2.065820847718669e-09, Training time:179020.3439552784
batch reward last col mean 4.206702215014957e-06 first col mean 6.993574515945511e-06 all mean 4.236465429130476e-06
rl training, epoch6, iter0, batch497/1133, batch loss:1.4305170736861328e-07, Training time:179047.34895682335
batch reward last col mean 1.0877223758143373e-05 first col mean 1.1441056813055184e-06 all mean 1.0779753210954368e-05
rl training, epoch6, iter0, batch498/1133, batch loss:1.1342658723378918e-07, Training time:179074.2895693779
batch reward last col mean 1.6308902104356093e-06 first col mean 9.588732154952595e-07 all mean 3.664544465209474e-06
rl training, epoch6, iter0, batch499/1133, batch loss:2.863672676767237e-08, Training time:179100.58719873428
batch reward last col mean 1.6642891296214657e-06 first col mean 9.181943028124806e-07 all mean 1.6856200772963348e-06
rl training, epoch6, iter0, batch500/1133, batch loss:7.884771235922017e-08, Training time:179127.11421823502
batch reward last col mean 1.7704227502690628e-05 first col mean 1.0052135124283268e-08 all mean 1.774432348611299e-05
rl training, epoch6, iter0, batch501/1133, batch loss:2.091953774652211e-07, Training time:179153.95108509064
batch reward last col mean 3.979839675594121e-07 first col mean 5.690291686732962e-07 all mean 3.9971806131688936e-07
rl training, epoch6, iter0, batch502/1133, batch loss:1.1561961166250967e-08, Training time:179181.12326693535
batch reward last col mean 7.255607670231257e-07 first col mean 1.2873512105215923e-06 all mean 7.505167332055862e-07
rl training, epoch6, iter0, batch503/1133, batch loss:6.048657130719448e-09, Training time:179208.10077118874
batch reward last col mean 1.6406023917170387e-07 first col mean 5.007431172998622e-05 all mean 6.497534741356503e-06
rl training, epoch6, iter0, batch504/1133, batch loss:1.0056195876018137e-09, Training time:179235.8739540577
batch reward last col mean 1.4705130524816923e-05 first col mean 7.507642294513062e-06 all mean 1.4633158571086824e-05
rl training, epoch6, iter0, batch505/1133, batch loss:2.6556011789580225e-07, Training time:179262.11618590355
batch reward last col mean 1.990951204788871e-06 first col mean 1.5768065964039124e-07 all mean 2.2223121050046757e-06
rl training, epoch6, iter0, batch506/1133, batch loss:5.806308323030862e-08, Training time:179288.77344489098
batch reward last col mean 1.788615008990746e-06 first col mean 3.0252882424974814e-05 all mean 1.0321837180526927e-05
rl training, epoch6, iter0, batch507/1133, batch loss:4.02142674715833e-08, Training time:179314.98754501343
batch reward last col mean 1.3147004596092415e-09 first col mean 4.79505104067357e-07 all mean 8.580584243134126e-09
rl training, epoch6, iter0, batch508/1133, batch loss:7.951869414671298e-13, Training time:179341.1473543644
batch reward last col mean 2.9381337299128063e-05 first col mean 8.38738378661219e-06 all mean 2.9169323170208372e-05
rl training, epoch6, iter0, batch509/1133, batch loss:3.118612426078471e-07, Training time:179368.01550245285
batch reward last col mean 1.2566481473186286e-06 first col mean 1.0155083600693615e-06 all mean 1.433144689144683e-06
rl training, epoch6, iter0, batch510/1133, batch loss:4.340053294527024e-08, Training time:179395.53224420547
batch reward last col mean 1.0563760497461772e-06 first col mean 2.472854703228222e-06 all mean 5.9833746490767226e-06
rl training, epoch6, iter0, batch511/1133, batch loss:1.6998901841702718e-08, Training time:179422.17776060104
batch reward last col mean 9.647336810303386e-06 first col mean 3.092351107625291e-05 all mean 9.862642400548793e-06
rl training, epoch6, iter0, batch512/1133, batch loss:5.63257849250931e-08, Training time:179448.49158525467
batch reward last col mean 2.699455876609136e-07 first col mean 6.734343060088577e-06 all mean 3.3548411693118396e-07
rl training, epoch6, iter0, batch513/1133, batch loss:3.30752070176743e-09, Training time:179475.71268439293
batch reward last col mean 4.193829227006063e-05 first col mean 2.3440121367457323e-05 all mean 4.17514456785284e-05
rl training, epoch6, iter0, batch514/1133, batch loss:2.098817049045465e-07, Training time:179501.9857096672
batch reward last col mean 1.5670436823711498e-06 first col mean 1.0899476592385327e-06 all mean 1.4274303339334438e-06
rl training, epoch6, iter0, batch515/1133, batch loss:8.27481088094828e-08, Training time:179528.95038557053
batch reward last col mean 1.3905115565648885e-06 first col mean 3.389852736290777e-06 all mean 1.411250195815228e-06
rl training, epoch6, iter0, batch516/1133, batch loss:2.8752524805497615e-09, Training time:179556.309735775
batch reward last col mean 1.6556076332108205e-07 first col mean 9.087264061236056e-07 all mean 1.7899927229336754e-07
rl training, epoch6, iter0, batch517/1133, batch loss:8.803227591336338e-10, Training time:179582.48744678497
batch reward last col mean 5.6377398323093075e-06 first col mean 5.25886707691825e-06 all mean 5.634742592519615e-06
rl training, epoch6, iter0, batch518/1133, batch loss:3.67827510672214e-08, Training time:179609.28424429893
batch reward last col mean 3.398365038265183e-07 first col mean 3.2742602229518525e-07 all mean 3.398363901396806e-07
rl training, epoch6, iter0, batch519/1133, batch loss:3.775134871375485e-09, Training time:179636.3085513115
batch reward last col mean 3.793659197981469e-05 first col mean 3.082296461798251e-05 all mean 3.786473098443821e-05
rl training, epoch6, iter0, batch520/1133, batch loss:1.7466079782479937e-07, Training time:179662.89648914337
batch reward last col mean 0.003851653076708317 first col mean 5.113806309964275e-06 all mean 0.0038127994630485773
rl training, epoch6, iter0, batch521/1133, batch loss:0.00026404857635498047, Training time:179689.8196606636
batch reward last col mean 3.733794926574774e-07 first col mean 5.298145424603717e-07 all mean 3.751171391286334e-07
rl training, epoch6, iter0, batch522/1133, batch loss:2.623807282553514e-10, Training time:179716.37416887283
batch reward last col mean 4.560267916531302e-05 first col mean 2.4645819962643145e-07 all mean 5.8053003158420324e-05
rl training, epoch6, iter0, batch523/1133, batch loss:4.81930101159378e-07, Training time:179742.70217561722
batch reward last col mean 1.9306930880702566e-06 first col mean 3.720407221408095e-06 all mean 1.948773160620476e-06
rl training, epoch6, iter0, batch524/1133, batch loss:2.6762378979583445e-09, Training time:179769.6127974987
batch reward last col mean 6.788427526771557e-07 first col mean 1.5153954109337064e-06 all mean 1.1020267720596166e-06
rl training, epoch6, iter0, batch525/1133, batch loss:2.5062911745976635e-09, Training time:179796.37163472176
batch reward last col mean 1.1525706895554322e-06 first col mean 1.3850235518475529e-06 all mean 1.1549781220310251e-06
rl training, epoch6, iter0, batch526/1133, batch loss:2.3608452970336202e-09, Training time:179824.060359478
batch reward last col mean 3.5489190963744477e-07 first col mean 1.8651827531357412e-06 all mean 5.811585197079694e-06
rl training, epoch6, iter0, batch527/1133, batch loss:1.595618215333161e-08, Training time:179851.89598846436
batch reward last col mean 3.4998287446796894e-05 first col mean 4.950319635099731e-06 all mean 3.474652476143092e-05
rl training, epoch6, iter0, batch528/1133, batch loss:3.4467328191567503e-07, Training time:179878.24963974953
batch reward last col mean 1.2001326012978097e-06 first col mean 2.6920051823253743e-06 all mean 1.215245447383495e-06
rl training, epoch6, iter0, batch529/1133, batch loss:1.0451314480519613e-08, Training time:179904.62116408348
batch reward last col mean 2.3818789163243537e-09 first col mean 6.014125574438367e-06 all mean 1.788577179695494e-07
rl training, epoch6, iter0, batch530/1133, batch loss:1.692526119256854e-08, Training time:179930.51743412018
batch reward last col mean 5.089933438284788e-06 first col mean 1.1304817235213704e-05 all mean 5.152937774255406e-06
rl training, epoch6, iter0, batch531/1133, batch loss:3.105299484218449e-08, Training time:179956.84954500198
batch reward last col mean 7.945941615616903e-05 first col mean 2.021934233198408e-05 all mean 7.886103412602097e-05
rl training, epoch6, iter0, batch532/1133, batch loss:4.855690804106416e-06, Training time:179983.56047081947
batch reward last col mean 3.55221175141196e-07 first col mean 4.254095983924344e-06 all mean 5.034481773691368e-07
rl training, epoch6, iter0, batch533/1133, batch loss:1.9377266458064923e-09, Training time:180009.97340512276
batch reward last col mean 2.1082782950543333e-06 first col mean 1.2985127796127927e-05 all mean 4.187990271020681e-06
rl training, epoch6, iter0, batch534/1133, batch loss:5.194189967028251e-08, Training time:180036.58792567253
batch reward last col mean 4.370676379039651e-06 first col mean 2.3674452677369118e-05 all mean 4.565717972582206e-06
rl training, epoch6, iter0, batch535/1133, batch loss:5.4570001850606786e-08, Training time:180063.2652440071
batch reward last col mean 2.800676099923294e-07 first col mean 6.376741339408909e-07 all mean 1.2466680345823988e-05
rl training, epoch6, iter0, batch536/1133, batch loss:2.60789212447321e-09, Training time:180090.09279084206
batch reward last col mean 3.674538675113581e-05 first col mean 1.351314494968392e-06 all mean 4.5849301386624575e-05
rl training, epoch6, iter0, batch537/1133, batch loss:1.6910200884012738e-06, Training time:180117.34766030312
batch reward last col mean 9.39107138719919e-08 first col mean 1.9036676803807495e-06 all mean 1.125097099929917e-07
rl training, epoch6, iter0, batch538/1133, batch loss:1.2459220322114106e-09, Training time:180144.27273344994
batch reward last col mean 7.132613433213919e-08 first col mean 1.4890122201904887e-06 all mean 6.018004228280915e-07
rl training, epoch6, iter0, batch539/1133, batch loss:3.741727816475304e-09, Training time:180171.53999352455
batch reward last col mean 0.0002076284436043352 first col mean 1.6896050283321529e-06 all mean 0.0002056234807241708
rl training, epoch6, iter0, batch540/1133, batch loss:2.0799465346499346e-05, Training time:180197.90203356743
batch reward last col mean 4.78603396913968e-06 first col mean 4.967885161022423e-07 all mean 4.745280421047937e-06
rl training, epoch6, iter0, batch541/1133, batch loss:2.9719704031094807e-08, Training time:180224.6273112297
batch reward last col mean 5.155352482688613e-07 first col mean 2.098110485349025e-07 all mean 1.8184242435381748e-05
rl training, epoch6, iter0, batch542/1133, batch loss:1.1248111775330472e-08, Training time:180251.5736656189
batch reward last col mean 1.185214728138817e-06 first col mean 2.1209937983712734e-07 all mean 9.358329407405108e-06
rl training, epoch6, iter0, batch543/1133, batch loss:9.016280699825074e-08, Training time:180278.4318227768
batch reward last col mean 4.982447876500373e-07 first col mean 1.0810797448357334e-06 all mean 5.043329451837053e-07
rl training, epoch6, iter0, batch544/1133, batch loss:4.417464616324196e-09, Training time:180305.00226068497
batch reward last col mean 1.9396898096601944e-06 first col mean 3.287394747530925e-06 all mean 1.6770936781540513e-05
rl training, epoch6, iter0, batch545/1133, batch loss:2.2174029723487365e-08, Training time:180331.50006389618
batch reward last col mean 1.043609699991066e-06 first col mean 2.409531134617282e-07 all mean 1.0407222816866124e-06
rl training, epoch6, iter0, batch546/1133, batch loss:1.0858469678964866e-08, Training time:180358.7075135708
batch reward last col mean 9.288267756346613e-05 first col mean 3.6670263625637745e-07 all mean 9.194828453473747e-05
rl training, epoch6, iter0, batch547/1133, batch loss:6.388012934621656e-06, Training time:180385.1621787548
batch reward last col mean 1.0652630635377136e-06 first col mean 9.239558380613744e-07 all mean 1.0639644187904196e-06
rl training, epoch6, iter0, batch548/1133, batch loss:1.9163985953696283e-09, Training time:180411.78453350067
batch reward last col mean 3.2793886930448934e-06 first col mean 1.1109373190265615e-06 all mean 3.2577472666162066e-06
rl training, epoch6, iter0, batch549/1133, batch loss:6.493682036534665e-08, Training time:180438.18592977524
batch reward last col mean 1.5631246697012102e-06 first col mean 1.2978974837096757e-06 all mean 1.5604856571371784e-06
rl training, epoch6, iter0, batch550/1133, batch loss:4.577693779594938e-09, Training time:180466.11670064926
batch reward last col mean 1.9960027657361934e-06 first col mean 8.749223638915282e-07 all mean 1.9886795143975178e-06
rl training, epoch6, iter0, batch551/1133, batch loss:4.4662236575732095e-08, Training time:180493.27687716484
batch reward last col mean 1.395073104504263e-05 first col mean 4.265099050826393e-05 all mean 1.4242099496186711e-05
rl training, epoch6, iter0, batch552/1133, batch loss:1.3465098902543104e-07, Training time:180521.12596464157
batch reward last col mean 5.5461746342189144e-06 first col mean 6.434853276005015e-06 all mean 5.55990527573158e-06
rl training, epoch6, iter0, batch553/1133, batch loss:1.2680050787139407e-08, Training time:180547.5948960781
batch reward last col mean 2.0318013582709682e-07 first col mean 1.7575592892171699e-06 all mean 3.1177575010588043e-07
rl training, epoch6, iter0, batch554/1133, batch loss:5.233421696004825e-09, Training time:180573.99462008476
batch reward last col mean 6.125939762569033e-06 first col mean 9.410331585968379e-06 all mean 6.164460501167923e-06
rl training, epoch6, iter0, batch555/1133, batch loss:1.4568226625044645e-08, Training time:180601.5547773838
batch reward last col mean 1.5571052927043638e-06 first col mean 1.6304111341014504e-06 all mean 1.5579871615045704e-06
rl training, epoch6, iter0, batch556/1133, batch loss:9.688708724198136e-10, Training time:180628.17219018936
batch reward last col mean 3.646272617174873e-08 first col mean 6.217910026862228e-07 all mean 5.387053292338351e-08
rl training, epoch6, iter0, batch557/1133, batch loss:1.4332675046802024e-09, Training time:180655.54685521126
batch reward last col mean 6.750821194145828e-05 first col mean 1.1347410691087134e-05 all mean 6.694150215480477e-05
rl training, epoch6, iter0, batch558/1133, batch loss:7.271548270182393e-07, Training time:180681.80631542206
batch reward last col mean 3.1790775665285764e-06 first col mean 1.6815017715998692e-06 all mean 3.3260319014516426e-06
rl training, epoch6, iter0, batch559/1133, batch loss:8.400827589127857e-09, Training time:180708.39635372162
batch reward last col mean 1.3406885273070657e-06 first col mean 4.845753664994845e-06 all mean 1.418980446032947e-06
rl training, epoch6, iter0, batch560/1133, batch loss:1.4222035105149189e-08, Training time:180735.34687805176
batch reward last col mean 8.644836952953483e-07 first col mean 4.475093192013446e-06 all mean 9.009556833916577e-07
rl training, epoch6, iter0, batch561/1133, batch loss:3.407620141615553e-08, Training time:180762.99268341064
batch reward last col mean 8.533708637514792e-07 first col mean 1.4524597418130725e-06 all mean 8.612740884927916e-07
rl training, epoch6, iter0, batch562/1133, batch loss:8.066519896487989e-09, Training time:180790.2953774929
batch reward last col mean 6.529098595109417e-09 first col mean 5.649344529956579e-07 all mean 9.244355396731407e-07
rl training, epoch6, iter0, batch563/1133, batch loss:2.7603665880837625e-11, Training time:180817.64389300346
batch reward last col mean 3.3081762467190856e-06 first col mean 3.377830353201716e-06 all mean 3.309322437416995e-06
rl training, epoch6, iter0, batch564/1133, batch loss:1.1917820508244859e-08, Training time:180844.93112063408
batch reward last col mean 0.00020308466628193855 first col mean 4.135365543334046e-06 all mean 0.00019903050269931555
rl training, epoch6, iter0, batch565/1133, batch loss:1.7593649317859672e-05, Training time:180872.2010781765
batch reward last col mean 1.1861320672323927e-06 first col mean 4.314689249440562e-06 all mean 1.2149407666584011e-06
rl training, epoch6, iter0, batch566/1133, batch loss:3.648510471521149e-08, Training time:180899.10247826576
batch reward last col mean 3.6570879728969885e-06 first col mean 1.704018359305337e-06 all mean 3.6375631680130027e-06
rl training, epoch6, iter0, batch567/1133, batch loss:6.415265829673444e-08, Training time:180926.08845829964
batch reward last col mean 1.5250998330884613e-06 first col mean 3.7074405554449186e-06 all mean 1.698878918432456e-06
rl training, epoch6, iter0, batch568/1133, batch loss:1.598342791453433e-08, Training time:180953.24835133553
batch reward last col mean 6.0175684666319285e-06 first col mean 1.1971231970164808e-06 all mean 6.019663942424813e-06
rl training, epoch6, iter0, batch569/1133, batch loss:2.3587897857169082e-08, Training time:180980.05490517616
batch reward last col mean 0.0014784525847062469 first col mean 0.00022429290402214974 all mean 0.0014673537807539105
rl training, epoch6, iter0, batch570/1133, batch loss:6.510981620522216e-05, Training time:181006.89939379692
batch reward last col mean 2.381577178312e-05 first col mean 6.531435019496712e-07 all mean 2.3585062081110664e-05
rl training, epoch6, iter0, batch571/1133, batch loss:1.2087858181075717e-07, Training time:181033.52465486526
batch reward last col mean 2.9065260605420917e-05 first col mean 6.2606191022496205e-06 all mean 3.963334529544227e-05
rl training, epoch6, iter0, batch572/1133, batch loss:3.729671504970611e-07, Training time:181060.28446435928
batch reward last col mean 1.7852065866463818e-05 first col mean 7.3420987973804586e-06 all mean 1.7772479623090476e-05
rl training, epoch6, iter0, batch573/1133, batch loss:3.1680292522651143e-07, Training time:181087.65016150475
batch reward last col mean 4.852215170103591e-06 first col mean 5.665768640028546e-06 all mean 4.875316335528623e-06
rl training, epoch6, iter0, batch574/1133, batch loss:3.243243895667547e-07, Training time:181114.52496743202
batch reward last col mean 1.3668053725268692e-05 first col mean 1.7685615603113547e-05 all mean 1.3707803191209678e-05
rl training, epoch6, iter0, batch575/1133, batch loss:1.8770539611523418e-07, Training time:181140.77098464966
batch reward last col mean 7.5383518378657755e-06 first col mean 2.786191089398926e-06 all mean 7.490503321605502e-06
rl training, epoch6, iter0, batch576/1133, batch loss:1.0258611382596428e-07, Training time:181167.63228702545
batch reward last col mean 1.4805243608861929e-06 first col mean 4.7345969278467237e-07 all mean 1.8753407857730053e-05
rl training, epoch6, iter0, batch577/1133, batch loss:2.383975150621609e-08, Training time:181194.28836488724
batch reward last col mean 2.4505618512193905e-06 first col mean 3.619755261752289e-06 all mean 2.544332119214232e-06
rl training, epoch6, iter0, batch578/1133, batch loss:5.035021732879841e-09, Training time:181220.24921393394
batch reward last col mean 1.2135041288274806e-05 first col mean 1.767647859196586e-06 all mean 1.2955506463185884e-05
rl training, epoch6, iter0, batch579/1133, batch loss:1.5437326794653927e-07, Training time:181246.2079820633
batch reward last col mean 7.650998668395914e-06 first col mean 7.419132543873275e-06 all mean 7.64874948799843e-06
rl training, epoch6, iter0, batch580/1133, batch loss:2.5298760419900646e-07, Training time:181271.896037817
batch reward last col mean 0.000259235966950655 first col mean 0.0007068641134537756 all mean 0.00027587456861510873
rl training, epoch6, iter0, batch581/1133, batch loss:1.5797631931491196e-05, Training time:181297.96474218369
batch reward last col mean 8.557239198125899e-06 first col mean 8.562605216866359e-06 all mean 8.984218766272534e-06
rl training, epoch6, iter0, batch582/1133, batch loss:4.808280777979235e-07, Training time:181324.1362581253
batch reward last col mean 8.984383021015674e-05 first col mean 1.1074760095652891e-06 all mean 8.713862189324573e-05
rl training, epoch6, iter0, batch583/1133, batch loss:6.136027423053747e-06, Training time:181350.1893696785
batch reward last col mean 2.3225029508466832e-06 first col mean 1.6561652955715545e-06 all mean 2.319076656931429e-06
rl training, epoch6, iter0, batch584/1133, batch loss:2.183873348826637e-08, Training time:181376.3083500862
batch reward last col mean 1.3477962568231305e-07 first col mean 4.0894360608945135e-06 all mean 1.7921355777161807e-07
rl training, epoch6, iter0, batch585/1133, batch loss:9.565985781279096e-10, Training time:181402.0990486145
batch reward last col mean 7.241662558499229e-08 first col mean 3.0928922569728456e-06 all mean 3.3942430377464916e-07
rl training, epoch6, iter0, batch586/1133, batch loss:2.0518929610968684e-10, Training time:181428.09420228004
batch reward last col mean 1.4577633464796236e-06 first col mean 1.0949764828183106e-06 all mean 1.4544353916789987e-06
rl training, epoch6, iter0, batch587/1133, batch loss:5.813072689875298e-09, Training time:181454.37173485756
batch reward last col mean 1.136579885496758e-05 first col mean 2.622352610615053e-07 all mean 1.1253671800659504e-05
rl training, epoch6, iter0, batch588/1133, batch loss:1.4423119409912033e-07, Training time:181480.57413125038
batch reward last col mean 2.7284982934361324e-05 first col mean 9.54475126491161e-06 all mean 2.711532033572439e-05
rl training, epoch6, iter0, batch589/1133, batch loss:4.379745632832055e-08, Training time:181506.39847517014
batch reward last col mean 4.0646992260917614e-07 first col mean 6.01293436375272e-07 all mean 9.07853120679647e-07
rl training, epoch6, iter0, batch590/1133, batch loss:1.1269699839999703e-08, Training time:181532.2890536785
batch reward last col mean 5.444071575766429e-06 first col mean 5.866336778126424e-06 all mean 5.449144737212919e-06
rl training, epoch6, iter0, batch591/1133, batch loss:3.801649484103109e-08, Training time:181558.29223370552
batch reward last col mean 3.5121823316330847e-07 first col mean 1.4902377643011278e-06 all mean 9.673923159425613e-06
rl training, epoch6, iter0, batch592/1133, batch loss:5.531957669724363e-10, Training time:181584.56955242157
batch reward last col mean 1.7480965652794112e-07 first col mean 3.644387561507756e-06 all mean 2.0987522475479636e-07
rl training, epoch6, iter0, batch593/1133, batch loss:1.2036099894530139e-09, Training time:181611.2242486477
batch reward last col mean 2.8285739972488955e-06 first col mean 3.4102536119462457e-06 all mean 3.027114189535496e-06
rl training, epoch6, iter0, batch594/1133, batch loss:1.573997465698085e-08, Training time:181637.4209947586
batch reward last col mean 2.761764221759222e-07 first col mean 3.881194459154358e-07 all mean 2.7804441060652607e-07
rl training, epoch6, iter0, batch595/1133, batch loss:2.997112558134063e-09, Training time:181663.69175314903
batch reward last col mean 9.766341463546269e-06 first col mean 6.871956429677084e-06 all mean 9.750751814863179e-06
rl training, epoch6, iter0, batch596/1133, batch loss:4.066587777629138e-08, Training time:181689.90197873116
batch reward last col mean 1.8706715536609408e-06 first col mean 5.540143683901988e-05 all mean 2.4146550003933953e-06
rl training, epoch6, iter0, batch597/1133, batch loss:2.8693973419535723e-08, Training time:181716.5042834282
batch reward last col mean 1.7197327224494074e-06 first col mean 4.056687430420425e-07 all mean 1.7011108184306067e-06
rl training, epoch6, iter0, batch598/1133, batch loss:3.827052097449268e-08, Training time:181742.79830789566
batch reward last col mean 2.21414757106686e-06 first col mean 7.847414735806524e-07 all mean 2.199668870161986e-06
rl training, epoch6, iter0, batch599/1133, batch loss:2.7455239859364156e-08, Training time:181769.27537727356
batch reward last col mean 8.287825039587915e-07 first col mean 2.095579958449889e-07 all mean 8.235352311203314e-07
rl training, epoch6, iter0, batch600/1133, batch loss:9.528217326248978e-09, Training time:181796.34268426895
batch reward last col mean 9.487691743359505e-10 first col mean 8.222258998102916e-07 all mean 9.593483341063802e-09
rl training, epoch6, iter0, batch601/1133, batch loss:1.6034349412455406e-12, Training time:181822.58469104767
batch reward last col mean 1.427497636541375e-06 first col mean 1.6119597603392322e-06 all mean 3.080520764342509e-05
rl training, epoch6, iter0, batch602/1133, batch loss:7.307323635075136e-09, Training time:181850.07129192352
batch reward last col mean 8.168455678969622e-06 first col mean 2.222506736870855e-05 all mean 2.487108031345997e-05
rl training, epoch6, iter0, batch603/1133, batch loss:5.373795985974539e-08, Training time:181877.15184545517
batch reward last col mean 3.504694063849456e-07 first col mean 9.563027560943738e-07 all mean 3.5764011840910825e-07
rl training, epoch6, iter0, batch604/1133, batch loss:1.7465856538834146e-09, Training time:181904.95606184006
batch reward last col mean 0.0001900359202409163 first col mean 5.6833025155356154e-05 all mean 0.00018869043560698628
rl training, epoch6, iter0, batch605/1133, batch loss:1.686238647380378e-05, Training time:181931.4374103546
batch reward last col mean 1.2334248822298832e-05 first col mean 4.773509317601565e-06 all mean 1.2258480637683533e-05
rl training, epoch6, iter0, batch606/1133, batch loss:1.8727028816556412e-07, Training time:181957.72376298904
batch reward last col mean 2.9051839192106854e-06 first col mean 3.5472444324113894e-06 all mean 2.9118893962731818e-06
rl training, epoch6, iter0, batch607/1133, batch loss:2.375675878241168e-09, Training time:181984.6641702652
batch reward last col mean 2.764604460026021e-06 first col mean 3.086258857365465e-06 all mean 2.2688607259624405e-06
rl training, epoch6, iter0, batch608/1133, batch loss:7.477893859686446e-08, Training time:182011.2051305771
batch reward last col mean 1.4180042171574314e-06 first col mean 3.4535605664132163e-07 all mean 1.4757455346625648e-06
rl training, epoch6, iter0, batch609/1133, batch loss:2.6050924972764733e-08, Training time:182037.34798145294
batch reward last col mean 2.3913505629025167e-06 first col mean 1.6952558326011058e-06 all mean 2.680319539649645e-06
rl training, epoch6, iter0, batch610/1133, batch loss:2.8187081113628665e-08, Training time:182064.2418525219
batch reward last col mean 1.0929361415890071e-08 first col mean 6.089578619139502e-06 all mean 7.390421075115228e-08
rl training, epoch6, iter0, batch611/1133, batch loss:3.1537659150870923e-09, Training time:182090.8875823021
batch reward last col mean 2.7686269277182873e-07 first col mean 1.046518605107849e-06 all mean 1.8471763496563653e-06
rl training, epoch6, iter0, batch612/1133, batch loss:6.308386257813936e-09, Training time:182117.54525113106
batch reward last col mean 6.081889978304389e-07 first col mean 1.2705085055131349e-06 all mean 6.148816851236916e-07
rl training, epoch6, iter0, batch613/1133, batch loss:7.677441460351986e-10, Training time:182144.50748944283
batch reward last col mean 2.5266081138397567e-06 first col mean 2.7777423383668065e-06 all mean 2.563398311394849e-06
rl training, epoch6, iter0, batch614/1133, batch loss:4.3365073310042135e-08, Training time:182171.75002908707
batch reward last col mean 3.729437878519093e-07 first col mean 1.1861252460221294e-06 all mean 3.8301109839267156e-07
rl training, epoch6, iter0, batch615/1133, batch loss:2.2157240486819774e-09, Training time:182197.9167649746
batch reward last col mean 2.1242717593850102e-06 first col mean 5.35886920260964e-06 all mean 2.1569421733147465e-06
rl training, epoch6, iter0, batch616/1133, batch loss:2.1806524586054365e-08, Training time:182224.11633872986
batch reward last col mean 1.518180738457886e-06 first col mean 6.887742529215757e-06 all mean 1.947171040228568e-05
rl training, epoch6, iter0, batch617/1133, batch loss:9.527401800824009e-08, Training time:182251.72372865677
batch reward last col mean 1.465102627662418e-06 first col mean 2.5415431082365103e-05 all mean 1.7124272062574164e-06
rl training, epoch6, iter0, batch618/1133, batch loss:2.830559964195345e-08, Training time:182279.1262383461
batch reward last col mean 1.4844281395198777e-06 first col mean 1.470882807552698e-06 all mean 1.4842999007669277e-06
rl training, epoch6, iter0, batch619/1133, batch loss:4.9948067903926585e-09, Training time:182305.94149374962
batch reward last col mean 0.00041255680844187737 first col mean 6.1130267567932606e-06 all mean 0.00041156800580210984
rl training, epoch6, iter0, batch620/1133, batch loss:9.809249604586512e-06, Training time:182332.40995669365
batch reward last col mean 1.5930947483866476e-05 first col mean 1.1754369552363642e-05 all mean 3.230018774047494e-05
rl training, epoch6, iter0, batch621/1133, batch loss:1.6871673835794354e-07, Training time:182359.27029895782
batch reward last col mean 7.607718544022646e-06 first col mean 5.086229521111818e-06 all mean 1.1309901310596615e-05
rl training, epoch6, iter0, batch622/1133, batch loss:4.443155887656758e-08, Training time:182387.34980273247
batch reward last col mean 9.829204827838112e-07 first col mean 6.0604893405979965e-06 all mean 1.2252513670318876e-06
rl training, epoch6, iter0, batch623/1133, batch loss:1.4290888472601182e-08, Training time:182414.66290426254
batch reward last col mean 2.2689373224693554e-07 first col mean 2.39648738897813e-06 all mean 2.529581308863271e-07
rl training, epoch6, iter0, batch624/1133, batch loss:4.578979417857454e-09, Training time:182440.79579854012
batch reward last col mean 7.237958925543353e-07 first col mean 1.5996054969491524e-07 all mean 4.809986648979248e-07
rl training, epoch6, iter0, batch625/1133, batch loss:8.857717403998322e-08, Training time:182466.89725971222
batch reward last col mean 9.813345513975946e-07 first col mean 7.359582809840504e-07 all mean 9.80745539891359e-07
rl training, epoch6, iter0, batch626/1133, batch loss:3.081255250947379e-09, Training time:182493.8473727703
batch reward last col mean 5.0614687552297255e-08 first col mean 5.341540145309409e-06 all mean 1.0486951396160293e-07
rl training, epoch6, iter0, batch627/1133, batch loss:6.450582845651809e-10, Training time:182520.7365064621
batch reward last col mean 4.074762305350532e-09 first col mean 1.3041103557043243e-06 all mean 1.717676605039742e-05
rl training, epoch6, iter0, batch628/1133, batch loss:1.1471177480126826e-10, Training time:182547.643553257
batch reward last col mean 1.797630829969421e-06 first col mean 9.392316542289336e-07 all mean 1.783194534255017e-06
rl training, epoch6, iter0, batch629/1133, batch loss:6.050703404980595e-08, Training time:182574.5059144497
batch reward last col mean 3.248806024203077e-05 first col mean 8.874763807398267e-06 all mean 3.224960892111994e-05
rl training, epoch6, iter0, batch630/1133, batch loss:1.3895404435970704e-06, Training time:182601.233117342
batch reward last col mean 1.1803178949776338e-06 first col mean 3.2541138352826238e-06 all mean 1.2016076880172477e-06
rl training, epoch6, iter0, batch631/1133, batch loss:7.200791074524204e-10, Training time:182627.9518544674
batch reward last col mean 2.8961026146134827e-06 first col mean 2.7499490897753276e-06 all mean 4.89889180244063e-06
rl training, epoch6, iter0, batch632/1133, batch loss:1.145343020425571e-08, Training time:182654.67595863342
batch reward last col mean 2.845590643119067e-07 first col mean 3.8488451536977664e-05 all mean 8.150606163326302e-07
rl training, epoch6, iter0, batch633/1133, batch loss:2.4509794194216283e-09, Training time:182681.3799624443
batch reward last col mean 1.1086547146987868e-07 first col mean 7.42989527680038e-08 all mean 1.1908540642480148e-07
rl training, epoch6, iter0, batch634/1133, batch loss:1.8743520624475707e-10, Training time:182708.05976200104
batch reward last col mean 4.7009390868879564e-07 first col mean 1.5112336271272397e-08 all mean 4.6558227495552273e-07
rl training, epoch6, iter0, batch635/1133, batch loss:6.467641977536687e-09, Training time:182734.5049686432
batch reward last col mean 1.5132784483284922e-06 first col mean 2.0096108528377954e-06 all mean 1.542395693832077e-06
rl training, epoch6, iter0, batch636/1133, batch loss:1.2181046393777706e-08, Training time:182761.07645368576
batch reward last col mean 1.9975630038970849e-07 first col mean 1.0571387321078873e-07 all mean 2.008947035392339e-07
rl training, epoch6, iter0, batch637/1133, batch loss:3.3653591025029073e-09, Training time:182787.63566708565
batch reward last col mean 7.2088059823727235e-06 first col mean 6.787940492358757e-06 all mean 7.2045563683786895e-06
rl training, epoch6, iter0, batch638/1133, batch loss:6.160363597018659e-08, Training time:182813.95202064514
batch reward last col mean 2.5549816200509667e-05 first col mean 6.06810658609902e-07 all mean 2.5361598090967163e-05
rl training, epoch6, iter0, batch639/1133, batch loss:1.1921115117274894e-07, Training time:182840.12095952034
batch reward last col mean 1.4684900406791712e-06 first col mean 2.4063876935542794e-06 all mean 1.4779508319406887e-06
rl training, epoch6, iter0, batch640/1133, batch loss:2.1395214488961756e-08, Training time:182866.29128837585
batch reward last col mean 1.8760144371299248e-07 first col mean 4.390467438497581e-06 all mean 2.381800214834584e-07
rl training, epoch6, iter0, batch641/1133, batch loss:4.656654506440816e-10, Training time:182892.41493749619
batch reward last col mean 9.629735359339975e-06 first col mean 1.049855836754432e-05 all mean 9.638645678933244e-06
rl training, epoch6, iter0, batch642/1133, batch loss:1.1018104117965777e-07, Training time:182918.27207374573
batch reward last col mean 1.7368330107458974e-09 first col mean 6.077647753954807e-07 all mean 2.12326881410263e-07
rl training, epoch6, iter0, batch643/1133, batch loss:6.914240447547515e-12, Training time:182944.6915719509
batch reward last col mean 1.7342779301543487e-06 first col mean 1.2934716551171732e-06 all mean 1.0628040399751626e-05
rl training, epoch6, iter0, batch644/1133, batch loss:1.4354926136661561e-08, Training time:182971.35840916634
batch reward last col mean 4.102598722965922e-06 first col mean 3.674314939416945e-05 all mean 4.433839876583079e-06
rl training, epoch6, iter0, batch645/1133, batch loss:3.247571456199694e-08, Training time:182998.300044775
batch reward last col mean 2.395140974442711e-09 first col mean 3.6330829971120693e-06 all mean 1.071021870302502e-06
rl training, epoch6, iter0, batch646/1133, batch loss:5.72952185695641e-10, Training time:183024.8227572441
batch reward last col mean 9.088842489290982e-05 first col mean 2.0902641608699923e-06 all mean 9.000715363072231e-05
rl training, epoch6, iter0, batch647/1133, batch loss:1.919619762702496e-06, Training time:183051.0727918148
batch reward last col mean 1.706365765130613e-06 first col mean 1.8648829609446693e-06 all mean 1.7088362938011414e-06
rl training, epoch6, iter0, batch648/1133, batch loss:2.089569184349216e-09, Training time:183077.42557573318
batch reward last col mean 1.581709398124076e-06 first col mean 1.967516254808288e-06 all mean 1.5862705140534672e-06
rl training, epoch6, iter0, batch649/1133, batch loss:1.178869557527662e-09, Training time:183104.41897392273
batch reward last col mean 5.86450923378834e-08 first col mean 2.408230648143217e-05 all mean 3.01309114547621e-07
rl training, epoch6, iter0, batch650/1133, batch loss:1.6161406657388966e-09, Training time:183131.03084683418
batch reward last col mean 5.629442057397682e-06 first col mean 3.942014700442087e-06 all mean 5.6728467825450934e-06
rl training, epoch6, iter0, batch651/1133, batch loss:1.629353540977263e-08, Training time:183158.07120203972
batch reward last col mean 2.361404312978266e-06 first col mean 3.859496246150229e-06 all mean 2.5691394966997905e-06
rl training, epoch6, iter0, batch652/1133, batch loss:1.269734184461413e-08, Training time:183185.34711909294
batch reward last col mean 1.9651368347695097e-05 first col mean 2.469191258569481e-06 all mean 1.9469065591692924e-05
rl training, epoch6, iter0, batch653/1133, batch loss:6.315056566563726e-07, Training time:183212.21258831024
batch reward last col mean 7.3825701107921304e-09 first col mean 1.084315954358317e-06 all mean 1.8370533538814016e-08
rl training, epoch6, iter0, batch654/1133, batch loss:6.257253742925073e-11, Training time:183238.58888983727
batch reward last col mean 4.828574674320407e-06 first col mean 1.0511292202863842e-05 all mean 4.886289843852865e-06
rl training, epoch6, iter0, batch655/1133, batch loss:1.5623458082814068e-08, Training time:183264.77431297302
batch reward last col mean 2.6003570383181795e-05 first col mean 1.281875370295893e-06 all mean 2.5754359739948995e-05
rl training, epoch6, iter0, batch656/1133, batch loss:4.193554730136384e-07, Training time:183291.11419820786
batch reward last col mean 1.978553200387978e-06 first col mean 3.5252069210400805e-06 all mean 2.017881570282043e-06
rl training, epoch6, iter0, batch657/1133, batch loss:1.166730534407634e-08, Training time:183317.54147458076
batch reward last col mean 1.1976658242929261e-06 first col mean 1.2797302133549238e-06 all mean 2.119162672897801e-06
rl training, epoch6, iter0, batch658/1133, batch loss:3.104727142044794e-09, Training time:183344.78899645805
batch reward last col mean 0.0030008757021278143 first col mean 0.002261874731630087 all mean 0.002985985018312931
rl training, epoch6, iter0, batch659/1133, batch loss:0.0002511096536181867, Training time:183371.6745557785
batch reward last col mean 3.5422597193246474e-06 first col mean 1.3417927675618557e-06 all mean 8.796399015409406e-06
rl training, epoch6, iter0, batch660/1133, batch loss:3.19584039232268e-08, Training time:183397.96527171135
batch reward last col mean 6.244428368518129e-05 first col mean 0.0008341614156961441 all mean 7.024146179901436e-05
rl training, epoch6, iter0, batch661/1133, batch loss:2.6651429152479977e-07, Training time:183424.46173381805
batch reward last col mean 2.0252251488273032e-05 first col mean 6.496105015685316e-06 all mean 2.8353633751976304e-05
rl training, epoch6, iter0, batch662/1133, batch loss:6.421075227081019e-07, Training time:183451.36098480225
batch reward last col mean 2.318290717084892e-05 first col mean 5.554067570301413e-07 all mean 4.144361810176633e-05
rl training, epoch6, iter0, batch663/1133, batch loss:9.545394732413115e-07, Training time:183478.07314753532
batch reward last col mean 3.1634218089493515e-07 first col mean 3.2124287372425897e-06 all mean 3.4544953564363823e-07
rl training, epoch6, iter0, batch664/1133, batch loss:6.501747584763962e-09, Training time:183504.7254691124
batch reward last col mean 4.848844810112496e-07 first col mean 6.388913789123762e-07 all mean 4.906904109702737e-07
rl training, epoch6, iter0, batch665/1133, batch loss:2.9201172035975276e-10, Training time:183530.81006336212
batch reward last col mean 2.7999158191960305e-07 first col mean 1.3359332115214784e-05 all mean 4.110351596864348e-07
rl training, epoch6, iter0, batch666/1133, batch loss:1.4758724020680347e-08, Training time:183557.23308372498
batch reward last col mean 7.060161806293763e-07 first col mean 1.2922884025101666e-06 all mean 7.123696832422866e-07
rl training, epoch6, iter0, batch667/1133, batch loss:1.3555407463172742e-08, Training time:183584.1768529415
batch reward last col mean 1.0137166555068688e-06 first col mean 1.2143559615651611e-05 all mean 2.045548717433121e-05
rl training, epoch6, iter0, batch668/1133, batch loss:5.311723683121272e-08, Training time:183610.88482928276
batch reward last col mean 1.2014371577606653e-06 first col mean 1.2398776334521244e-06 all mean 1.2578765336002107e-06
rl training, epoch6, iter0, batch669/1133, batch loss:9.807108902748496e-09, Training time:183638.05236434937
batch reward last col mean 1.742431550155743e-06 first col mean 2.6714213063883108e-08 all mean 1.7713334727886831e-06
rl training, epoch6, iter0, batch670/1133, batch loss:8.345191204739422e-09, Training time:183665.07024741173
batch reward last col mean 2.298199433425907e-06 first col mean 3.153897750962642e-06 all mean 2.309103592779138e-06
rl training, epoch6, iter0, batch671/1133, batch loss:3.952499216808292e-09, Training time:183691.57726359367
batch reward last col mean 1.4752539634343975e-08 first col mean 1.6906146811379585e-06 all mean 3.171812323898848e-08
rl training, epoch6, iter0, batch672/1133, batch loss:3.5569303578897316e-12, Training time:183717.65205407143
batch reward last col mean 2.4012374524318147e-06 first col mean 1.0626388757373206e-05 all mean 3.7830261589988368e-06
rl training, epoch6, iter0, batch673/1133, batch loss:1.488651779624206e-08, Training time:183743.7831246853
batch reward last col mean 1.7748754999047378e-06 first col mean 1.95651364265359e-06 all mean 1.8115698594556306e-06
rl training, epoch6, iter0, batch674/1133, batch loss:7.197015872151269e-09, Training time:183770.09187340736
batch reward last col mean 0.00016126591071952134 first col mean 0.00015531423559878021 all mean 0.0001612133055459708
rl training, epoch6, iter0, batch675/1133, batch loss:4.598392706611776e-07, Training time:183796.18060064316
batch reward last col mean 2.6145473839278566e-06 first col mean 6.115220458013937e-06 all mean 4.869224994763499e-06
rl training, epoch6, iter0, batch676/1133, batch loss:3.088410860385693e-09, Training time:183822.21164941788
batch reward last col mean 2.2242793420446105e-05 first col mean 1.1597099728533067e-05 all mean 2.214198320871219e-05
rl training, epoch6, iter0, batch677/1133, batch loss:1.7538317820253724e-07, Training time:183848.35398697853
batch reward last col mean 1.1513200348645114e-07 first col mean 5.194646064410335e-07 all mean 1.1955872025737335e-07
rl training, epoch6, iter0, batch678/1133, batch loss:4.2769904284867266e-10, Training time:183874.32358169556
batch reward last col mean 1.334383250650717e-05 first col mean 2.8237436708877794e-06 all mean 1.3407824553723913e-05
rl training, epoch6, iter0, batch679/1133, batch loss:8.949323841989099e-07, Training time:183900.70130562782
batch reward last col mean 2.734673898885376e-06 first col mean 1.358607391921396e-06 all mean 3.093467057624366e-06
rl training, epoch6, iter0, batch680/1133, batch loss:5.319922635749208e-08, Training time:183926.81163716316
batch reward last col mean 4.115281626582146e-06 first col mean 3.776148105316679e-06 all mean 4.1128150769509375e-06
rl training, epoch6, iter0, batch681/1133, batch loss:8.628917136377368e-09, Training time:183952.97067070007
batch reward last col mean 4.637323581846431e-05 first col mean 5.110693450660619e-07 all mean 3.7379839341156185e-05
rl training, epoch6, iter0, batch682/1133, batch loss:6.893502359162085e-06, Training time:183980.0203242302
batch reward last col mean 1.8482737118574732e-07 first col mean 5.175749720365275e-06 all mean 1.5740908565931022e-05
rl training, epoch6, iter0, batch683/1133, batch loss:8.478537316669588e-10, Training time:184007.39637041092
batch reward last col mean 2.1542520300954493e-07 first col mean 1.4350375465710385e-07 all mean 2.147648388017842e-07
rl training, epoch6, iter0, batch684/1133, batch loss:1.9617414359629493e-09, Training time:184034.34110283852
batch reward last col mean 0.007259294856339693 first col mean 4.926831024931744e-06 all mean 0.0071668485179543495
rl training, epoch6, iter0, batch685/1133, batch loss:0.0007372976397164166, Training time:184061.20988464355
batch reward last col mean 9.137593082186868e-08 first col mean 5.158649946679361e-05 all mean 6.131296572675637e-07
rl training, epoch6, iter0, batch686/1133, batch loss:1.2950717165338688e-09, Training time:184088.61682462692
batch reward last col mean 9.093420203498681e-07 first col mean 1.7367221971653635e-06 all mean 9.200276167575794e-07
rl training, epoch6, iter0, batch687/1133, batch loss:2.2127140120176136e-09, Training time:184115.76899576187
batch reward last col mean 1.6133328983869433e-07 first col mean 3.747197069969843e-06 all mean 1.1614411050686613e-05
rl training, epoch6, iter0, batch688/1133, batch loss:1.0426792762530113e-09, Training time:184143.289696455
batch reward last col mean 2.337967453058809e-05 first col mean 1.5566929505439475e-05 all mean 1.1756013009289745e-05
rl training, epoch6, iter0, batch689/1133, batch loss:3.715070988619118e-06, Training time:184171.5988354683
batch reward last col mean 2.2338126655085944e-06 first col mean 2.4146263513102895e-06 all mean 2.2574288323085057e-06
rl training, epoch6, iter0, batch690/1133, batch loss:4.48487575965828e-08, Training time:184199.27862119675
batch reward last col mean 3.817914148385171e-06 first col mean 2.4842720449669287e-06 all mean 5.88101147513953e-06
rl training, epoch6, iter0, batch691/1133, batch loss:9.486077345854937e-08, Training time:184226.56919050217
batch reward last col mean 5.075062148307552e-09 first col mean 1.6349309817087487e-06 all mean 2.2634768725993126e-08
rl training, epoch6, iter0, batch692/1133, batch loss:6.034824549805418e-12, Training time:184253.16439175606
batch reward last col mean 4.3580807869147975e-06 first col mean 5.737372703151777e-06 all mean 4.373918727651471e-06
rl training, epoch6, iter0, batch693/1133, batch loss:5.569756567069817e-08, Training time:184279.97742581367
batch reward last col mean 1.1136450694948508e-07 first col mean 4.307410677029111e-07 all mean 1.1545142086788474e-07
rl training, epoch6, iter0, batch694/1133, batch loss:1.5576413492368602e-09, Training time:184307.41206026077
batch reward last col mean 1.9332778720126953e-06 first col mean 4.778133870786405e-07 all mean 2.2293399979389505e-06
rl training, epoch6, iter0, batch695/1133, batch loss:7.613581232135402e-08, Training time:184333.79736304283
batch reward last col mean 9.495178346696775e-06 first col mean 3.402446054678876e-06 all mean 1.0231397027382627e-05
rl training, epoch6, iter0, batch696/1133, batch loss:1.379777074816957e-07, Training time:184361.2060494423
batch reward last col mean 9.303778369940119e-08 first col mean 1.7970703993341886e-05 all mean 2.810760975080484e-07
rl training, epoch6, iter0, batch697/1133, batch loss:6.839753763365763e-10, Training time:184387.99758410454
batch reward last col mean 7.056813956296537e-06 first col mean 1.0313614211554523e-06 all mean 6.99650308888522e-06
rl training, epoch6, iter0, batch698/1133, batch loss:1.8479443042451749e-07, Training time:184415.11597847939
batch reward last col mean 3.4621328381945204e-07 first col mean 4.626858753908891e-07 all mean 3.470237004421506e-07
rl training, epoch6, iter0, batch699/1133, batch loss:8.569517540024663e-09, Training time:184442.29271912575
batch reward last col mean 6.628686605836265e-06 first col mean 2.1025507521699183e-05 all mean 6.77640991852968e-06
rl training, epoch6, iter0, batch700/1133, batch loss:5.4051565001600466e-08, Training time:184469.1630077362
batch reward last col mean 6.544443067468819e-07 first col mean 5.928264727117494e-06 all mean 7.504924610657326e-07
rl training, epoch6, iter0, batch701/1133, batch loss:9.63679092080838e-09, Training time:184496.98958206177
batch reward last col mean 1.3627510270453058e-05 first col mean 6.4789046518853866e-06 all mean 1.3501872672350146e-05
rl training, epoch6, iter0, batch702/1133, batch loss:1.778891487447254e-07, Training time:184524.10999965668
batch reward last col mean 4.151450525569089e-07 first col mean 4.847923378292762e-07 all mean 1.2930620414408622e-06
rl training, epoch6, iter0, batch703/1133, batch loss:3.870097575742193e-09, Training time:184551.21194434166
batch reward last col mean 1.8284467842022423e-06 first col mean 7.662987400181009e-07 all mean 1.504745796410134e-05
rl training, epoch6, iter0, batch704/1133, batch loss:6.827652754282099e-08, Training time:184577.97383832932
batch reward last col mean 5.804326974612195e-07 first col mean 0.0008226425270549953 all mean 8.948028153099585e-06
rl training, epoch6, iter0, batch705/1133, batch loss:1.910686275863327e-09, Training time:184605.22573375702
batch reward last col mean 1.8650861193236778e-06 first col mean 1.655209075579478e-06 all mean 1.8618458170749363e-06
rl training, epoch6, iter0, batch706/1133, batch loss:3.300819173546188e-08, Training time:184631.6625471115
batch reward last col mean 0.00019611773313954473 first col mean 1.3293846734541148e-07 all mean 0.0001936432672664523
rl training, epoch6, iter0, batch707/1133, batch loss:2.463197597535327e-05, Training time:184658.31768846512
batch reward last col mean 3.656449189293198e-05 first col mean 4.62848947790917e-06 all mean 3.657109846244566e-05
rl training, epoch6, iter0, batch708/1133, batch loss:1.3098858744342579e-06, Training time:184685.56883859634
batch reward last col mean 0.00024007282627280802 first col mean 3.153480065520853e-06 all mean 0.0002354514435864985
rl training, epoch6, iter0, batch709/1133, batch loss:1.1848038411699235e-05, Training time:184712.23887872696
batch reward last col mean 3.2339860354113625e-06 first col mean 2.0645952645281795e-06 all mean 3.2223802008957136e-06
rl training, epoch6, iter0, batch710/1133, batch loss:1.1886720052700639e-08, Training time:184738.65719985962
batch reward last col mean 8.855271153151989e-05 first col mean 5.792270167148672e-05 all mean 8.841118687996641e-05
rl training, epoch6, iter0, batch711/1133, batch loss:4.2531737562967464e-06, Training time:184765.77785921097
batch reward last col mean 4.786652880284237e-06 first col mean 5.526479526452022e-06 all mean 4.803448973689228e-06
rl training, epoch6, iter0, batch712/1133, batch loss:1.61301770162936e-07, Training time:184792.45669698715
batch reward last col mean 2.708386773520033e-06 first col mean 6.020670298312325e-06 all mean 2.7492201297718566e-06
rl training, epoch6, iter0, batch713/1133, batch loss:4.272639131386313e-09, Training time:184819.49908709526
batch reward last col mean 4.3432128222775646e-06 first col mean 3.237738928874023e-05 all mean 4.6272903091448825e-06
rl training, epoch6, iter0, batch714/1133, batch loss:4.933119246430806e-09, Training time:184845.89724993706
batch reward last col mean 3.0388794129976304e-06 first col mean 9.712925930216443e-07 all mean 3.0194762530300068e-06
rl training, epoch6, iter0, batch715/1133, batch loss:5.105012235162576e-08, Training time:184873.16343069077
batch reward last col mean 1.5587645521009108e-06 first col mean 5.620107913273387e-06 all mean 1.6178228179342113e-06
rl training, epoch6, iter0, batch716/1133, batch loss:9.710286796860146e-09, Training time:184899.39142084122
batch reward last col mean 1.0209857403964406e-09 first col mean 5.177827461011475e-06 all mean 5.508393741138207e-08
rl training, epoch6, iter0, batch717/1133, batch loss:1.9940901360704366e-11, Training time:184926.2754266262
batch reward last col mean 2.0851164663326927e-05 first col mean 4.5885229837949737e-07 all mean 2.0646166376536712e-05
rl training, epoch6, iter0, batch718/1133, batch loss:6.051774903426121e-07, Training time:184952.7512731552
batch reward last col mean 2.0037273316120263e-06 first col mean 1.9633844203781337e-06 all mean 2.0223330920998706e-06
rl training, epoch6, iter0, batch719/1133, batch loss:1.7130709295543056e-08, Training time:184979.29191064835
batch reward last col mean 2.782614046736853e-06 first col mean 4.382163751870394e-07 all mean 6.815081633249065e-06
rl training, epoch6, iter0, batch720/1133, batch loss:1.3060180492630025e-07, Training time:185006.04526138306
batch reward last col mean 9.318538900515705e-07 first col mean 4.460866421140963e-06 all mean 2.267831405333709e-06
rl training, epoch6, iter0, batch721/1133, batch loss:7.433387794186785e-10, Training time:185032.850366354
batch reward last col mean 1.568348473313108e-08 first col mean 2.736619762799819e-06 all mean 4.31754401120088e-08
rl training, epoch6, iter0, batch722/1133, batch loss:1.1691998931528946e-11, Training time:185060.05452013016
batch reward last col mean 3.881797283611377e-07 first col mean 3.164935151289683e-06 all mean 4.900236376670364e-07
rl training, epoch6, iter0, batch723/1133, batch loss:4.843604628490539e-09, Training time:185086.73342108727
batch reward last col mean 2.716112021516892e-06 first col mean 7.435972656821832e-05 all mean 3.4572192362247733e-06
rl training, epoch6, iter0, batch724/1133, batch loss:6.706903832309763e-08, Training time:185113.1134428978
batch reward last col mean 4.432141395227518e-06 first col mean 3.680443569464842e-06 all mean 2.407734064036049e-05
rl training, epoch6, iter0, batch725/1133, batch loss:6.334452962164505e-08, Training time:185140.0287361145
batch reward last col mean 1.1219482075830456e-05 first col mean 3.846781055472093e-06 all mean 1.4257400835049339e-05
rl training, epoch6, iter0, batch726/1133, batch loss:6.172544431137794e-08, Training time:185167.6380507946
batch reward last col mean 5.752921788371168e-05 first col mean 1.5933879922158667e-06 all mean 5.696482185157947e-05
rl training, epoch6, iter0, batch727/1133, batch loss:4.2282007939320465e-07, Training time:185194.02106666565
batch reward last col mean 8.669478120282292e-06 first col mean 2.80980093521066e-05 all mean 8.86732686922187e-06
rl training, epoch6, iter0, batch728/1133, batch loss:1.231867372553097e-07, Training time:185220.67683434486
batch reward last col mean 7.492707482015248e-06 first col mean 1.0259457667416427e-05 all mean 7.524761258537183e-06
rl training, epoch6, iter0, batch729/1133, batch loss:7.59786811244112e-09, Training time:185247.24296855927
batch reward last col mean 1.0947372857117443e-06 first col mean 1.4713619975736947e-06 all mean 1.0985432936649886e-06
rl training, epoch6, iter0, batch730/1133, batch loss:1.07757358591698e-08, Training time:185274.0103008747
batch reward last col mean 2.069689571726485e-06 first col mean 9.30059286474716e-06 all mean 2.1439400370582007e-06
rl training, epoch6, iter0, batch731/1133, batch loss:2.71508060478709e-08, Training time:185300.42252373695
batch reward last col mean 2.3646482532058144e-06 first col mean 0.0001232532231369987 all mean 3.586764933061204e-06
rl training, epoch6, iter0, batch732/1133, batch loss:2.427359646617333e-08, Training time:185327.2376012802
batch reward last col mean 2.1557886142886673e-08 first col mean 1.1142926723550772e-06 all mean 9.471222028878401e-07
rl training, epoch6, iter0, batch733/1133, batch loss:6.496448518023001e-11, Training time:185354.1953113079
batch reward last col mean 1.4744628060725518e-05 first col mean 4.126103704038542e-06 all mean 1.4678870684292633e-05
rl training, epoch6, iter0, batch734/1133, batch loss:4.590095841194852e-07, Training time:185381.14055418968
batch reward last col mean 1.198759491671808e-07 first col mean 1.4306950106401928e-05 all mean 2.643407981395285e-07
rl training, epoch6, iter0, batch735/1133, batch loss:4.666212971571326e-10, Training time:185408.29459428787
batch reward last col mean 4.3609274143818766e-05 first col mean 0.00011118438851553947 all mean 4.431878915056586e-05
rl training, epoch6, iter0, batch736/1133, batch loss:6.32166532454903e-08, Training time:185435.97961068153
batch reward last col mean 0.00042443021084181964 first col mean 1.612149935681373e-05 all mean 0.00043249590089544654
rl training, epoch6, iter0, batch737/1133, batch loss:2.6686771889217198e-05, Training time:185463.06069612503
batch reward last col mean 5.1833923819799566e-09 first col mean 5.633388013848162e-07 all mean 1.0788478554957237e-08
rl training, epoch6, iter0, batch738/1133, batch loss:8.0831702442552e-11, Training time:185489.17012619972
batch reward last col mean 2.8938395644217962e-06 first col mean 1.0326388064640923e-06 all mean 2.8766928608092712e-06
rl training, epoch6, iter0, batch739/1133, batch loss:2.4370503837189972e-08, Training time:185516.25932312012
batch reward last col mean 4.464336234377697e-05 first col mean 1.6068936020019464e-05 all mean 4.417472882778384e-05
rl training, epoch6, iter0, batch740/1133, batch loss:2.526806838432094e-06, Training time:185543.03610515594
batch reward last col mean 2.0153420337010175e-06 first col mean 0.001425590948201716 all mean 1.641426933929324e-05
rl training, epoch6, iter0, batch741/1133, batch loss:4.1793612126639346e-08, Training time:185569.29265904427
batch reward last col mean 7.215524844284005e-10 first col mean 1.658293967921054e-06 all mean 1.3220216033005272e-07
rl training, epoch6, iter0, batch742/1133, batch loss:8.369440251954074e-09, Training time:185595.80525422096
batch reward last col mean 6.926975970600324e-07 first col mean 1.4460864576903987e-06 all mean 7.012517926341388e-07
rl training, epoch6, iter0, batch743/1133, batch loss:3.160084638409444e-09, Training time:185622.56998372078
batch reward last col mean 1.9962727026978655e-09 first col mean 3.4552185752545483e-06 all mean 3.693048356012696e-08
rl training, epoch6, iter0, batch744/1133, batch loss:4.9672550794799264e-11, Training time:185649.11038279533
batch reward last col mean 6.4314299379475415e-06 first col mean 3.1803858746570768e-06 all mean 6.420670160878217e-06
rl training, epoch6, iter0, batch745/1133, batch loss:3.141825288821565e-08, Training time:185676.12469768524
batch reward last col mean 1.3610893802251667e-05 first col mean 2.86047907138709e-06 all mean 1.350238289887784e-05
rl training, epoch6, iter0, batch746/1133, batch loss:1.4042781515399838e-07, Training time:185702.82974505424
batch reward last col mean 1.4355958644074462e-09 first col mean 4.4809853605443095e-09 all mean 1.4744478971095987e-09
rl training, epoch6, iter0, batch747/1133, batch loss:8.47248269805756e-13, Training time:185730.1029086113
batch reward last col mean 4.080759026692249e-06 first col mean 3.056742571061477e-06 all mean 1.6938507542363368e-05
rl training, epoch6, iter0, batch748/1133, batch loss:4.978260292887171e-08, Training time:185756.69050097466
batch reward last col mean 0.0005310343694873154 first col mean 8.922937922761776e-06 all mean 0.0005266982479952276
rl training, epoch6, iter0, batch749/1133, batch loss:2.0243804101482965e-05, Training time:185784.28776431084
batch reward last col mean 1.3245767149783205e-07 first col mean 1.0465118975844234e-06 all mean 2.4972680989776563e-07
rl training, epoch6, iter0, batch750/1133, batch loss:5.987955908892673e-09, Training time:185810.34851264954
batch reward last col mean 5.569426662077603e-07 first col mean 8.069482078099099e-07 all mean 1.2853308362537064e-05
rl training, epoch6, iter0, batch751/1133, batch loss:2.5339721432260376e-09, Training time:185837.2329237461
batch reward last col mean 0.0001630322221899405 first col mean 0.00011951565102208406 all mean 0.00017066748114302754
rl training, epoch6, iter0, batch752/1133, batch loss:3.99435657527647e-06, Training time:185864.0589287281
batch reward last col mean 7.353326054726494e-07 first col mean 3.1920143328534323e-07 all mean 7.377720976364799e-07
rl training, epoch6, iter0, batch753/1133, batch loss:1.567701857219106e-09, Training time:185890.89901161194
batch reward last col mean 6.548399687744677e-05 first col mean 4.327211718191393e-05 all mean 6.527258665300906e-05
rl training, epoch6, iter0, batch754/1133, batch loss:7.312423235816823e-07, Training time:185917.09332871437
batch reward last col mean 5.2417781262192875e-06 first col mean 5.247036369837588e-06 all mean 5.241909548203694e-06
rl training, epoch6, iter0, batch755/1133, batch loss:7.830277759524051e-09, Training time:185943.05055236816
batch reward last col mean 4.480516054172767e-06 first col mean 3.9315574440479395e-07 all mean 2.279065847687889e-05
rl training, epoch6, iter0, batch756/1133, batch loss:2.059101120721607e-07, Training time:185969.33952331543
batch reward last col mean 1.3334893083083443e-06 first col mean 2.008654973906232e-06 all mean 6.7945079536002595e-06
rl training, epoch6, iter0, batch757/1133, batch loss:7.67321406414112e-09, Training time:185995.54320931435
batch reward last col mean 7.208740839814709e-07 first col mean 0.00015698054630775005 all mean 1.0593998922558967e-05
rl training, epoch6, iter0, batch758/1133, batch loss:4.199011804928432e-09, Training time:186021.64552426338
batch reward last col mean 8.152352393153706e-07 first col mean 3.1737235985929146e-06 all mean 8.391025403398089e-07
rl training, epoch6, iter0, batch759/1133, batch loss:6.464477397827295e-09, Training time:186047.6635029316
batch reward last col mean 0.0001774633419699967 first col mean 2.2057984097045846e-05 all mean 0.00017589375784154981
rl training, epoch6, iter0, batch760/1133, batch loss:4.359289960120805e-06, Training time:186073.58158516884
batch reward last col mean 2.112777110596653e-06 first col mean 8.888242746252217e-07 all mean 2.1007815576012945e-06
rl training, epoch6, iter0, batch761/1133, batch loss:3.2265315752511015e-08, Training time:186099.64104437828
batch reward last col mean 5.668510993928066e-07 first col mean 6.672777089988813e-06 all mean 6.745636369487329e-07
rl training, epoch6, iter0, batch762/1133, batch loss:2.307426250069966e-09, Training time:186125.7719452381
batch reward last col mean 1.2785945955329225e-06 first col mean 3.1841059353610035e-06 all mean 1.877323848020751e-05
rl training, epoch6, iter0, batch763/1133, batch loss:1.0758815172096092e-08, Training time:186151.84721064568
batch reward last col mean 1.4793164382354007e-06 first col mean 1.3583005056716502e-05 all mean 4.097012606507633e-06
rl training, epoch6, iter0, batch764/1133, batch loss:2.8910647209556828e-09, Training time:186177.7407927513
batch reward last col mean 0.0018674340099096298 first col mean 2.502121787983924e-06 all mean 0.0018486803164705634
rl training, epoch6, iter0, batch765/1133, batch loss:0.00015962171892169863, Training time:186203.7424850464
batch reward last col mean 3.210695467714686e-06 first col mean 2.7577848413784523e-06 all mean 3.2061279853223823e-06
rl training, epoch6, iter0, batch766/1133, batch loss:4.280980547832769e-08, Training time:186229.95822429657
batch reward last col mean 1.7833287984103663e-06 first col mean 1.87017610642215e-06 all mean 2.000688709813403e-06
rl training, epoch6, iter0, batch767/1133, batch loss:3.862044017921562e-09, Training time:186256.1550643444
batch reward last col mean 2.4300513246089395e-07 first col mean 1.3853778000338934e-06 all mean 2.566246735113964e-07
rl training, epoch6, iter0, batch768/1133, batch loss:1.958871953533503e-09, Training time:186282.29407906532
batch reward last col mean 6.277244210650679e-06 first col mean 5.8736983191920444e-05 all mean 6.852248134237016e-06
rl training, epoch6, iter0, batch769/1133, batch loss:1.4561773298282787e-07, Training time:186308.3940806389
batch reward last col mean 9.770839824341238e-06 first col mean 1.2694454198936e-05 all mean 9.804809451452456e-06
rl training, epoch6, iter0, batch770/1133, batch loss:9.451341753674569e-08, Training time:186334.44280958176
batch reward last col mean 0.000215860505704768 first col mean 5.043531473347684e-06 all mean 0.00021624997316394
rl training, epoch6, iter0, batch771/1133, batch loss:1.0997557183145545e-05, Training time:186360.74509596825
batch reward last col mean 5.2567902457667515e-05 first col mean 1.271756445930805e-05 all mean 5.235102798906155e-05
rl training, epoch6, iter0, batch772/1133, batch loss:3.5505968298821244e-07, Training time:186386.8971736431
batch reward last col mean 1.2749550251101027e-06 first col mean 1.7156853573396802e-05 all mean 3.5582477266871138e-06
rl training, epoch6, iter0, batch773/1133, batch loss:2.0041428072659073e-08, Training time:186413.0539290905
batch reward last col mean 2.441034894218319e-06 first col mean 9.298830991610885e-05 all mean 3.3625624382693786e-06
rl training, epoch6, iter0, batch774/1133, batch loss:8.2796818290376e-09, Training time:186439.2018675804
batch reward last col mean 6.0697493609040976e-06 first col mean 5.999787390464917e-06 all mean 2.5616851416998543e-05
rl training, epoch6, iter0, batch775/1133, batch loss:9.007170120867158e-08, Training time:186465.28493404388
batch reward last col mean 3.6714385487357504e-07 first col mean 8.434058145212475e-07 all mean 3.7207578884590475e-07
rl training, epoch6, iter0, batch776/1133, batch loss:1.2041636576753945e-09, Training time:186491.334949255
batch reward last col mean 2.214983169324114e-06 first col mean 1.404283830197528e-05 all mean 1.8947210264741443e-05
rl training, epoch6, iter0, batch777/1133, batch loss:1.8312816152388223e-08, Training time:186517.3917069435
batch reward last col mean 1.8046602434651504e-08 first col mean 1.257799976883689e-05 all mean 2.923541615018621e-06
rl training, epoch6, iter0, batch778/1133, batch loss:1.949068018092248e-09, Training time:186543.4777879715
batch reward last col mean 3.0530667572747916e-05 first col mean 8.28126667329343e-06 all mean 3.03059696307173e-05
rl training, epoch6, iter0, batch779/1133, batch loss:3.025436967618589e-07, Training time:186569.49114203453
batch reward last col mean 5.606499325949699e-05 first col mean 7.688633559155278e-06 all mean 6.421993748517707e-05
rl training, epoch6, iter0, batch780/1133, batch loss:5.166280516277766e-06, Training time:186595.40734672546
batch reward last col mean 2.0544250389775698e-07 first col mean 9.785281918084365e-07 all mean 3.0242586035456043e-07
rl training, epoch6, iter0, batch781/1133, batch loss:3.5521130481441787e-09, Training time:186621.7143983841
batch reward last col mean 2.4423519207061872e-08 first col mean 2.705939914449118e-05 all mean 3.052541615033988e-07
rl training, epoch6, iter0, batch782/1133, batch loss:1.3472386539703507e-09, Training time:186648.02922391891
batch reward last col mean 1.7749639482644852e-06 first col mean 6.996328465902479e-06 all mean 4.2974124880856834e-06
rl training, epoch6, iter0, batch783/1133, batch loss:1.3887131444789702e-08, Training time:186674.23263931274
batch reward last col mean 2.7014139050152153e-06 first col mean 7.338143859669799e-06 all mean 2.751052306848578e-06
rl training, epoch6, iter0, batch784/1133, batch loss:1.2448157349354005e-07, Training time:186700.30327677727
batch reward last col mean 1.303958129028615e-06 first col mean 1.307935804106819e-06 all mean 1.310120637754153e-06
rl training, epoch6, iter0, batch785/1133, batch loss:1.0452847476472016e-08, Training time:186726.31891942024
batch reward last col mean 3.3320739021291956e-05 first col mean 6.951797217880085e-07 all mean 3.300385287730023e-05
rl training, epoch6, iter0, batch786/1133, batch loss:1.512089738753275e-06, Training time:186752.47933602333
batch reward last col mean 6.000465901934149e-09 first col mean 2.646245320647722e-06 all mean 5.688006154969116e-08
rl training, epoch6, iter0, batch787/1133, batch loss:7.178927591278139e-12, Training time:186778.4921708107
batch reward last col mean 9.68583790950106e-08 first col mean 0.0006380555569194257 all mean 6.53907500236528e-06
rl training, epoch6, iter0, batch788/1133, batch loss:1.2087606471311574e-09, Training time:186804.56430196762
batch reward last col mean 2.5079116312554106e-05 first col mean 6.628894880122971e-06 all mean 2.49550721491687e-05
rl training, epoch6, iter0, batch789/1133, batch loss:1.3291952427607612e-07, Training time:186830.68160653114
batch reward last col mean 2.8900676625198685e-06 first col mean 2.976469431814621e-06 all mean 2.8920155727973906e-06
rl training, epoch6, iter0, batch790/1133, batch loss:1.1141356281996195e-08, Training time:186856.7302157879
batch reward last col mean 4.3342570279492065e-05 first col mean 6.616554060201452e-07 all mean 4.247790639055893e-05
rl training, epoch6, iter0, batch791/1133, batch loss:3.0496205454255687e-06, Training time:186882.7935204506
batch reward last col mean 4.1543401607668784e-07 first col mean 8.237489964812994e-06 all mean 4.944741363033245e-07
rl training, epoch6, iter0, batch792/1133, batch loss:2.0058548155788003e-09, Training time:186908.9523308277
batch reward last col mean 7.87498356658034e-06 first col mean 8.47763885758468e-07 all mean 2.301786298630759e-05
rl training, epoch6, iter0, batch793/1133, batch loss:7.708814564466593e-08, Training time:186935.16602110863
batch reward last col mean 2.2027144552794198e-07 first col mean 7.825315719856007e-07 all mean 2.7484000497679517e-07
rl training, epoch6, iter0, batch794/1133, batch loss:1.184439213375299e-10, Training time:186961.2384443283
batch reward last col mean 9.325459515707735e-09 first col mean 4.248675031703897e-05 all mean 8.921825610741507e-06
rl training, epoch6, iter0, batch795/1133, batch loss:1.4506355838772578e-10, Training time:186987.24678826332
batch reward last col mean 0.00755827222019434 first col mean 9.797239499675925e-07 all mean 0.005725975148379803
rl training, epoch6, iter0, batch796/1133, batch loss:0.0010967095149680972, Training time:187012.98863959312
batch reward last col mean 9.633520221541403e-07 first col mean 8.688366506248713e-07 all mean 9.632192359276814e-07
rl training, epoch6, iter0, batch797/1133, batch loss:1.8813264279771147e-09, Training time:187039.11133909225
batch reward last col mean 2.6419959340273635e-06 first col mean 3.6190195373819734e-07 all mean 2.648103418323444e-06
rl training, epoch6, iter0, batch798/1133, batch loss:8.488468594691767e-09, Training time:187065.32595539093
batch reward last col mean 1.1359999916749075e-05 first col mean 8.41818837216124e-06 all mean 1.134935791924363e-05
rl training, epoch6, iter0, batch799/1133, batch loss:3.909323709194723e-08, Training time:187091.46819496155
batch reward last col mean 4.363356538306107e-07 first col mean 2.124997536157025e-06 all mean 4.534105642051145e-07
rl training, epoch6, iter0, batch800/1133, batch loss:2.790915276662531e-09, Training time:187117.52782011032
batch reward last col mean 3.758057118830038e-07 first col mean 1.23672689369414e-05 all mean 5.080814275970624e-07
rl training, epoch6, iter0, batch801/1133, batch loss:6.684781617138924e-09, Training time:187143.64809274673
batch reward last col mean 2.7805057811747247e-07 first col mean 7.76724045863375e-05 all mean 1.1064587397413561e-06
rl training, epoch6, iter0, batch802/1133, batch loss:2.459423997791532e-09, Training time:187169.79528665543
batch reward last col mean 1.4309664038592018e-05 first col mean 8.684543900017161e-06 all mean 1.4253381777962204e-05
rl training, epoch6, iter0, batch803/1133, batch loss:1.233251651910905e-07, Training time:187196.08155441284
batch reward last col mean 2.3526490622316487e-07 first col mean 3.490334563593933e-07 all mean 2.3703401552666037e-07
rl training, epoch6, iter0, batch804/1133, batch loss:9.124164757068343e-10, Training time:187222.27757453918
batch reward last col mean 7.53312679080409e-06 first col mean 2.4571523681515828e-05 all mean 1.8725731933955103e-05
rl training, epoch6, iter0, batch805/1133, batch loss:1.5569396794035129e-07, Training time:187248.45578861237
batch reward last col mean 2.078099896607455e-05 first col mean 9.751199286256451e-06 all mean 2.06696040550014e-05
rl training, epoch6, iter0, batch806/1133, batch loss:1.233821080859343e-07, Training time:187274.55763983727
batch reward last col mean 9.211109954776475e-07 first col mean 5.03339242641232e-06 all mean 9.688019417808391e-07
rl training, epoch6, iter0, batch807/1133, batch loss:5.646358047783906e-09, Training time:187300.69403123856
batch reward last col mean 1.067976700142026e-05 first col mean 0.00012236287875566632 all mean 1.1808097042376176e-05
rl training, epoch6, iter0, batch808/1133, batch loss:6.328381374487435e-08, Training time:187326.69911026955
batch reward last col mean 3.0344369861268206e-07 first col mean 4.629543582268525e-06 all mean 3.5936622566623555e-07
rl training, epoch6, iter0, batch809/1133, batch loss:8.614885887991974e-11, Training time:187352.74911499023
batch reward last col mean 0.004787651356309652 first col mean 5.630637360809487e-07 all mean 0.00469094468280673
rl training, epoch6, iter0, batch810/1133, batch loss:0.00042436187504790723, Training time:187378.8708524704
batch reward last col mean 2.243374638055684e-06 first col mean 9.613556812837487e-07 all mean 2.2322490167425713e-06
rl training, epoch6, iter0, batch811/1133, batch loss:1.795482695854389e-08, Training time:187405.1130566597
batch reward last col mean 4.597460701916134e-06 first col mean 4.765560879604891e-05 all mean 5.032401531934738e-06
rl training, epoch6, iter0, batch812/1133, batch loss:7.235443355568805e-09, Training time:187431.27304267883
batch reward last col mean 4.749549589178059e-06 first col mean 9.662364846008131e-07 all mean 4.71195289719617e-06
rl training, epoch6, iter0, batch813/1133, batch loss:2.142841566410425e-07, Training time:187457.34568619728
batch reward last col mean 1.6528800188098103e-05 first col mean 2.4784681045275647e-06 all mean 1.679655906627886e-05
rl training, epoch6, iter0, batch814/1133, batch loss:2.620323300561722e-07, Training time:187483.6251885891
batch reward last col mean 3.694195811476675e-06 first col mean 5.1022088882746175e-06 all mean 3.74442538486619e-06
rl training, epoch6, iter0, batch815/1133, batch loss:1.3920006480816483e-08, Training time:187509.52505230904
batch reward last col mean 5.690642865374684e-06 first col mean 4.22340144723421e-06 all mean 5.9455928749230225e-06
rl training, epoch6, iter0, batch816/1133, batch loss:1.2794999726395417e-08, Training time:187535.7583296299
batch reward last col mean 7.188620656961575e-05 first col mean 1.741618916639709e-06 all mean 7.163405098253861e-05
rl training, epoch6, iter0, batch817/1133, batch loss:1.0384065944890608e-06, Training time:187561.86754870415
batch reward last col mean 1.5349286286436836e-07 first col mean 6.03570333623793e-05 all mean 7.618567110512231e-07
rl training, epoch6, iter0, batch818/1133, batch loss:2.79616130249849e-09, Training time:187588.0175728798
batch reward last col mean 3.593949486457859e-06 first col mean 9.503764886176214e-06 all mean 3.653645990198129e-06
rl training, epoch6, iter0, batch819/1133, batch loss:1.2909780799930104e-08, Training time:187614.1211335659
batch reward last col mean 3.0319793040689547e-06 first col mean 7.169538002926856e-05 all mean 3.725554051925428e-06
rl training, epoch6, iter0, batch820/1133, batch loss:7.812427149644918e-09, Training time:187640.08565092087
batch reward last col mean 1.2888909850516939e-06 first col mean 2.425478442091844e-06 all mean 2.6311067813367117e-06
rl training, epoch6, iter0, batch821/1133, batch loss:1.3737051496320873e-09, Training time:187666.10447192192
batch reward last col mean 6.042435416020453e-06 first col mean 1.508058630861342e-05 all mean 1.3752524864685256e-05
rl training, epoch6, iter0, batch822/1133, batch loss:1.0092669100458806e-07, Training time:187692.33827376366
batch reward last col mean 4.043039680823313e-09 first col mean 1.3658527109328134e-07 all mean 1.4916069801529375e-07
rl training, epoch6, iter0, batch823/1133, batch loss:1.0927806402827311e-11, Training time:187718.5423233509
batch reward last col mean 2.054441239351945e-07 first col mean 9.492252388554334e-07 all mean 2.400753373876796e-07
rl training, epoch6, iter0, batch824/1133, batch loss:4.920149287990228e-10, Training time:187744.8674902916
batch reward last col mean 6.797657761126175e-07 first col mean 1.2465986856113886e-06 all mean 1.528873440292955e-06
rl training, epoch6, iter0, batch825/1133, batch loss:2.3198191811957258e-08, Training time:187770.83417105675
batch reward last col mean 2.0204883185215294e-05 first col mean 1.0026400559581816e-05 all mean 3.843880404019728e-05
rl training, epoch6, iter0, batch826/1133, batch loss:1.605671116067242e-07, Training time:187797.0344259739
batch reward last col mean 1.386850158269226e-06 first col mean 2.9975226425449364e-05 all mean 1.6757378489273833e-06
rl training, epoch6, iter0, batch827/1133, batch loss:5.026182847700511e-08, Training time:187823.43432617188
batch reward last col mean 9.706849596113898e-06 first col mean 8.937575330492109e-05 all mean 1.0512531844142359e-05
rl training, epoch6, iter0, batch828/1133, batch loss:2.8049859324141835e-08, Training time:187849.6833937168
batch reward last col mean 9.184207556245383e-06 first col mean 1.3763552487944253e-05 all mean 9.21032278711209e-06
rl training, epoch6, iter0, batch829/1133, batch loss:6.763452802260872e-07, Training time:187875.8591516018
batch reward last col mean 3.2299749364028685e-06 first col mean 1.1587240805965848e-05 all mean 3.964286406699102e-06
rl training, epoch6, iter0, batch830/1133, batch loss:5.486617382643999e-08, Training time:187901.90055441856
batch reward last col mean 3.6043566069565713e-06 first col mean 3.309103931314894e-06 all mean 3.6150386222288944e-06
rl training, epoch6, iter0, batch831/1133, batch loss:4.610302362095808e-09, Training time:187927.968832016
batch reward last col mean 3.1427384783455636e-06 first col mean 1.9863832676492166e-06 all mean 3.1358315482066246e-06
rl training, epoch6, iter0, batch832/1133, batch loss:1.0884264156629797e-08, Training time:187954.08343696594
batch reward last col mean 1.7247843970835675e-06 first col mean 1.0585522431938443e-05 all mean 1.8147723039874109e-06
rl training, epoch6, iter0, batch833/1133, batch loss:6.80382861162343e-09, Training time:187980.18122768402
batch reward last col mean 1.0743925571432555e-07 first col mean 2.6352981308264134e-07 all mean 8.383520935240085e-07
rl training, epoch6, iter0, batch834/1133, batch loss:1.8642305477101218e-09, Training time:188006.343811512
batch reward last col mean 6.266240689001279e-06 first col mean 4.2114461393794045e-06 all mean 6.293254045885988e-06
rl training, epoch6, iter0, batch835/1133, batch loss:1.889991940728919e-09, Training time:188032.37688088417
batch reward last col mean 6.37765260762535e-05 first col mean 1.7471656974521466e-05 all mean 6.330886390060186e-05
rl training, epoch6, iter0, batch836/1133, batch loss:1.0509984349482693e-06, Training time:188058.54688048363
batch reward last col mean 1.5040553762446507e-06 first col mean 5.46668979950482e-06 all mean 1.5440896277141292e-06
rl training, epoch6, iter0, batch837/1133, batch loss:1.9478060053756963e-08, Training time:188084.68444395065
batch reward last col mean 2.9901557354605757e-06 first col mean 0.0004662303254008293 all mean 7.823826308595017e-06
rl training, epoch6, iter0, batch838/1133, batch loss:2.8238536842195572e-08, Training time:188110.83402085304
batch reward last col mean 2.8743559596478008e-05 first col mean 3.066398130613379e-05 all mean 4.545602496364154e-05
rl training, epoch6, iter0, batch839/1133, batch loss:1.1123487411168753e-06, Training time:188137.1615741253
batch reward last col mean 1.78707814484369e-05 first col mean 5.894009063922567e-06 all mean 1.774988959368784e-05
rl training, epoch6, iter0, batch840/1133, batch loss:2.6119156615322936e-08, Training time:188163.2105231285
batch reward last col mean 5.601859243142826e-08 first col mean 8.123967063511373e-07 all mean 9.44372277444927e-06
rl training, epoch6, iter0, batch841/1133, batch loss:7.470536966813768e-10, Training time:188189.27584958076
batch reward last col mean 0.0002943904837593436 first col mean 4.446312686923193e-07 all mean 0.0002914213400799781
rl training, epoch6, iter0, batch842/1133, batch loss:8.963265827333089e-06, Training time:188215.44381189346
batch reward last col mean 8.034868415052188e-07 first col mean 1.3822970004184754e-06 all mean 5.1432871259748936e-06
rl training, epoch6, iter0, batch843/1133, batch loss:3.2732547783353994e-09, Training time:188241.62594127655
batch reward last col mean 2.3362758838629816e-07 first col mean 0.00130711798556149 all mean 2.9882477974751964e-05
rl training, epoch6, iter0, batch844/1133, batch loss:1.7262357099312453e-09, Training time:188267.71994376183
batch reward last col mean 6.9093766796868294e-06 first col mean 9.120416507357731e-06 all mean 6.933168606337858e-06
rl training, epoch6, iter0, batch845/1133, batch loss:2.841130175568196e-08, Training time:188293.82739067078
batch reward last col mean 0.0014181314036250114 first col mean 0.0010645712027326226 all mean 0.0014145723544061184
rl training, epoch6, iter0, batch846/1133, batch loss:7.544973777839914e-05, Training time:188320.0110988617
batch reward last col mean 3.915983143087942e-06 first col mean 4.926525434711948e-06 all mean 3.926967565348605e-06
rl training, epoch6, iter0, batch847/1133, batch loss:1.2109313551889045e-08, Training time:188346.26632261276
batch reward last col mean 3.136692157568177e-06 first col mean 9.968470067178714e-07 all mean 3.3145181532745482e-06
rl training, epoch6, iter0, batch848/1133, batch loss:3.010497451327865e-08, Training time:188372.42964553833
batch reward last col mean 5.028609351143132e-08 first col mean 2.542835488839046e-07 all mean 1.533550971544173e-06
rl training, epoch6, iter0, batch849/1133, batch loss:2.7404745139847364e-10, Training time:188398.52619814873
batch reward last col mean 3.5892871892428957e-06 first col mean 3.589211473808973e-06 all mean 3.6550929962686496e-06
rl training, epoch6, iter0, batch850/1133, batch loss:8.541666041139706e-09, Training time:188424.44996404648
batch reward last col mean 0.0014584417222067714 first col mean 0.0010621859692037106 all mean 0.0014605753822252154
rl training, epoch6, iter0, batch851/1133, batch loss:8.239204908022657e-05, Training time:188450.74707984924
batch reward last col mean 8.162458584592969e-07 first col mean 2.08437131732353e-06 all mean 1.368527364320471e-06
rl training, epoch6, iter0, batch852/1133, batch loss:7.983847361003882e-09, Training time:188476.90219974518
batch reward last col mean 3.1012543786346214e-06 first col mean 2.3689619865763234e-06 all mean 3.0920768949727062e-06
rl training, epoch6, iter0, batch853/1133, batch loss:1.600624841557874e-07, Training time:188503.06048178673
batch reward last col mean 0.00016786249761935323 first col mean 1.7468316855229205e-06 all mean 0.00017876400670502335
rl training, epoch6, iter0, batch854/1133, batch loss:2.355511696805479e-06, Training time:188529.16872692108
batch reward last col mean 1.2325079978836584e-06 first col mean 2.0837933334405534e-05 all mean 1.4295679875431233e-06
rl training, epoch6, iter0, batch855/1133, batch loss:3.855568664334896e-08, Training time:188555.2258963585
batch reward last col mean 1.614805000826891e-06 first col mean 9.84623511612881e-07 all mean 1.6109452189994045e-06
rl training, epoch6, iter0, batch856/1133, batch loss:8.896476444419932e-09, Training time:188581.5097784996
batch reward last col mean 5.514444296750298e-07 first col mean 0.00011163061572005972 all mean 2.025855428655632e-05
rl training, epoch6, iter0, batch857/1133, batch loss:9.773097886522919e-09, Training time:188607.61447048187
batch reward last col mean 0.00017729455430526286 first col mean 1.222841274284292e-05 all mean 0.00017677406140137464
rl training, epoch6, iter0, batch858/1133, batch loss:1.0328712050977629e-05, Training time:188633.87015390396
batch reward last col mean 1.0031106967289816e-07 first col mean 3.300259550087503e-06 all mean 1.8206790628028102e-05
rl training, epoch6, iter0, batch859/1133, batch loss:1.8333866369513174e-10, Training time:188660.20586037636
batch reward last col mean 1.1268692105659284e-05 first col mean 1.7158188256871654e-06 all mean 1.1172239283041563e-05
rl training, epoch6, iter0, batch860/1133, batch loss:2.006683956778943e-07, Training time:188686.17981219292
batch reward last col mean 4.115543561056256e-06 first col mean 3.787966306845192e-06 all mean 4.112261194677558e-06
rl training, epoch6, iter0, batch861/1133, batch loss:1.310409025734316e-08, Training time:188712.13474440575
batch reward last col mean 3.383120656508254e-06 first col mean 2.424581225568545e-06 all mean 1.4229216503736097e-05
rl training, epoch6, iter0, batch862/1133, batch loss:2.204007998329871e-08, Training time:188738.2626428604
batch reward last col mean 5.6664862313482445e-06 first col mean 1.684468315943377e-06 all mean 5.634228273265762e-06
rl training, epoch6, iter0, batch863/1133, batch loss:1.793732451460528e-08, Training time:188764.48948645592
batch reward last col mean 5.0871654821094126e-05 first col mean 6.664143938905909e-07 all mean 5.038988092564978e-05
rl training, epoch6, iter0, batch864/1133, batch loss:6.411735284928e-07, Training time:188790.51605844498
batch reward last col mean 3.208046337022097e-06 first col mean 0.000494192645419389 all mean 8.17123509477824e-06
rl training, epoch6, iter0, batch865/1133, batch loss:3.453373409456617e-08, Training time:188816.45767235756
batch reward last col mean 3.7920253816992044e-06 first col mean 0.00010514265159144998 all mean 4.848406661039917e-06
rl training, epoch6, iter0, batch866/1133, batch loss:2.6025949395602765e-08, Training time:188842.78535866737
batch reward last col mean 7.3456758400425315e-06 first col mean 1.490000886406051e-05 all mean 7.422065664286492e-06
rl training, epoch6, iter0, batch867/1133, batch loss:6.899789184444671e-08, Training time:188868.98306798935
batch reward last col mean 9.311644134868402e-06 first col mean 1.4442128303926438e-05 all mean 9.960856004909147e-06
rl training, epoch6, iter0, batch868/1133, batch loss:5.734442964921982e-08, Training time:188895.21356892586
batch reward last col mean 2.937004639491647e-09 first col mean 3.374834989244846e-08 all mean 3.343667120958571e-09
rl training, epoch6, iter0, batch869/1133, batch loss:2.1743815081798346e-11, Training time:188921.09602546692
batch reward last col mean 3.2931624446064234e-05 first col mean 1.9183421500201803e-06 all mean 3.2636235118843615e-05
rl training, epoch6, iter0, batch870/1133, batch loss:2.990081782172638e-07, Training time:188947.36443781853
batch reward last col mean 5.35848698746122e-07 first col mean 7.869537625992962e-07 all mean 4.661325419874629e-06
rl training, epoch6, iter0, batch871/1133, batch loss:6.632426607922071e-09, Training time:188973.4180841446
batch reward last col mean 1.7140968338935636e-05 first col mean 2.4544129701098427e-05 all mean 1.7243221009266563e-05
rl training, epoch6, iter0, batch872/1133, batch loss:5.142481995790149e-08, Training time:188999.7369532585
batch reward last col mean 2.872912546081352e-06 first col mean 2.6308680389774963e-06 all mean 9.295918971474748e-06
rl training, epoch6, iter0, batch873/1133, batch loss:6.06198611308173e-08, Training time:189026.0965845585
batch reward last col mean 2.5291647034464404e-06 first col mean 1.5360559473265312e-06 all mean 2.5253204967157217e-06
rl training, epoch6, iter0, batch874/1133, batch loss:7.519798828070634e-08, Training time:189052.19974327087
batch reward last col mean 2.3486395548388828e-06 first col mean 9.419533171239891e-07 all mean 2.3957468329172116e-06
rl training, epoch6, iter0, batch875/1133, batch loss:1.438436747491778e-08, Training time:189078.35436558723
batch reward last col mean 3.8785540823482734e-07 first col mean 2.2816742784925736e-05 all mean 6.144206849967304e-07
rl training, epoch6, iter0, batch876/1133, batch loss:2.9469546802829427e-09, Training time:189104.31683635712
batch reward last col mean 1.4451303513851599e-06 first col mean 6.275344276218675e-06 all mean 1.5203112297967891e-06
rl training, epoch6, iter0, batch877/1133, batch loss:1.7708837063423744e-08, Training time:189130.40792036057
batch reward last col mean 9.98403947960469e-07 first col mean 6.8059348450333346e-06 all mean 1.0570696531431167e-06
rl training, epoch6, iter0, batch878/1133, batch loss:2.5186508434416055e-10, Training time:189156.4533970356
batch reward last col mean 9.045090223480656e-07 first col mean 2.104326995322481e-06 all mean 9.190276841763989e-07
rl training, epoch6, iter0, batch879/1133, batch loss:2.6673436792634675e-09, Training time:189182.47754120827
batch reward last col mean 1.549856847304909e-06 first col mean 2.1856553757970687e-06 all mean 1.5774627399878227e-06
rl training, epoch6, iter0, batch880/1133, batch loss:6.920007233901515e-09, Training time:189208.42136120796
batch reward last col mean 3.2405512229161104e-07 first col mean 1.3116602985974168e-06 all mean 3.3433943258387444e-07
rl training, epoch6, iter0, batch881/1133, batch loss:3.753176880394449e-09, Training time:189234.48106765747
batch reward last col mean 8.825909389997832e-07 first col mean 1.4082593224884477e-06 all mean 8.881010558070557e-07
rl training, epoch6, iter0, batch882/1133, batch loss:3.6315195295344438e-09, Training time:189260.40607619286
batch reward last col mean 5.5308419177890755e-06 first col mean 5.39252141606994e-07 all mean 5.480933850776637e-06
rl training, epoch6, iter0, batch883/1133, batch loss:4.376283158080696e-08, Training time:189286.6543252468
batch reward last col mean 1.081177316564208e-07 first col mean 1.5121547392027423e-07 all mean 1.4151457435218617e-05
rl training, epoch6, iter0, batch884/1133, batch loss:4.859864732864594e-10, Training time:189312.7083978653
batch reward last col mean 5.965837317489786e-06 first col mean 5.991190846543759e-06 all mean 1.849938962550368e-05
rl training, epoch6, iter0, batch885/1133, batch loss:4.272938447513752e-09, Training time:189338.71315407753
batch reward last col mean 2.401447716238181e-07 first col mean 7.16043450665893e-06 all mean 3.1005200185063586e-07
rl training, epoch6, iter0, batch886/1133, batch loss:2.0914123766146986e-09, Training time:189364.7953042984
batch reward last col mean 1.212452662002761e-05 first col mean 5.691449587175157e-06 all mean 1.355975018668687e-05
rl training, epoch6, iter0, batch887/1133, batch loss:2.5841328010756115e-07, Training time:189391.04446172714
batch reward last col mean 7.247709277180547e-08 first col mean 8.138937346302555e-07 all mean 4.620839320068626e-07
rl training, epoch6, iter0, batch888/1133, batch loss:3.1797489086216046e-09, Training time:189417.20541596413
batch reward last col mean 5.647594207403017e-06 first col mean 1.6045925121943583e-06 all mean 5.6484900596842635e-06
rl training, epoch6, iter0, batch889/1133, batch loss:2.5763552002899814e-07, Training time:189443.36042523384
batch reward last col mean 2.2563632228411734e-05 first col mean 2.1681382349925116e-05 all mean 2.2614496629103087e-05
rl training, epoch6, iter0, batch890/1133, batch loss:4.129041997202876e-08, Training time:189469.2576174736
batch reward last col mean 2.9027924028923735e-06 first col mean 9.21010325782845e-07 all mean 2.8827766982431058e-06
rl training, epoch6, iter0, batch891/1133, batch loss:3.027210127015678e-08, Training time:189495.32019495964
batch reward last col mean 1.3565387234848458e-05 first col mean 6.367853984556859e-06 all mean 1.3587704415840562e-05
rl training, epoch6, iter0, batch892/1133, batch loss:1.663951252339757e-07, Training time:189521.65449094772
batch reward last col mean 1.2288194284337806e-06 first col mean 7.849936082493514e-06 all mean 1.96590895029658e-06
rl training, epoch6, iter0, batch893/1133, batch loss:1.188727871692663e-08, Training time:189547.74588394165
batch reward last col mean 6.302802376012551e-06 first col mean 7.248656856972957e-06 all mean 6.42669419903541e-06
rl training, epoch6, iter0, batch894/1133, batch loss:1.0964143370983948e-08, Training time:189574.04076838493
batch reward last col mean 9.691588047644473e-07 first col mean 4.0166114558815025e-06 all mean 9.756526196724735e-06
rl training, epoch6, iter0, batch895/1133, batch loss:1.641899949333947e-08, Training time:189600.06770014763
batch reward last col mean 6.36060576653108e-06 first col mean 7.593206100864336e-05 all mean 7.691607606830075e-06
rl training, epoch6, iter0, batch896/1133, batch loss:2.743176423791738e-07, Training time:189626.1361269951
batch reward last col mean 6.215964276634622e-06 first col mean 2.1526709588215454e-06 all mean 3.2061081583378837e-05
rl training, epoch6, iter0, batch897/1133, batch loss:4.3830645779507904e-08, Training time:189652.25470423698
batch reward last col mean 1.3296973975229776e-06 first col mean 1.0059412488772068e-05 all mean 1.417873704667727e-06
rl training, epoch6, iter0, batch898/1133, batch loss:2.001933268047651e-07, Training time:189678.44669485092
batch reward last col mean 1.1620401210166165e-06 first col mean 2.654979425642523e-06 all mean 1.1770970331781427e-06
rl training, epoch6, iter0, batch899/1133, batch loss:9.168475756382577e-09, Training time:189704.28700184822
batch reward last col mean 7.203686982393265e-05 first col mean 1.9288210751255974e-05 all mean 8.458264346700162e-05
rl training, epoch6, iter0, batch900/1133, batch loss:2.0125353330513462e-06, Training time:189730.36025071144
batch reward last col mean 8.135188181768171e-06 first col mean 2.2651200197287835e-05 all mean 1.5212225662253331e-05
rl training, epoch6, iter0, batch901/1133, batch loss:2.4493385097912324e-08, Training time:189756.5140645504
batch reward last col mean 1.4146856130992091e-07 first col mean 1.0047664545709267e-05 all mean 2.415548578937887e-07
rl training, epoch6, iter0, batch902/1133, batch loss:2.4700597123228363e-10, Training time:189782.62073111534
batch reward last col mean 6.247312853702169e-07 first col mean 1.8505786556488601e-06 all mean 1.8879400158766657e-05
rl training, epoch6, iter0, batch903/1133, batch loss:3.555035155144992e-09, Training time:189808.99649620056
batch reward last col mean 3.2188615932682296e-06 first col mean 1.4571487554349005e-06 all mean 3.201162144250702e-06
rl training, epoch6, iter0, batch904/1133, batch loss:9.77500320686886e-08, Training time:189835.84628415108
batch reward last col mean 3.098238721577218e-06 first col mean 3.5083182865491835e-06 all mean 3.1024321742734173e-06
rl training, epoch6, iter0, batch905/1133, batch loss:1.0310591491702326e-08, Training time:189861.76516127586
batch reward last col mean 6.168806976347696e-07 first col mean 1.1114556173197343e-06 all mean 6.228669349184202e-07
rl training, epoch6, iter0, batch906/1133, batch loss:1.2421069728318912e-09, Training time:189888.48078775406
batch reward last col mean 4.929803253617138e-06 first col mean 8.943841748987325e-06 all mean 4.971028829459101e-06
rl training, epoch6, iter0, batch907/1133, batch loss:7.917752498087793e-08, Training time:189915.2918767929
batch reward last col mean 1.7484013881130522e-07 first col mean 6.153995855129324e-07 all mean 1.7194466636283323e-05
rl training, epoch6, iter0, batch908/1133, batch loss:1.4886627930366103e-08, Training time:189942.053047657
batch reward last col mean 1.5704525822002324e-06 first col mean 1.9647595763672143e-06 all mean 1.5744966503916658e-06
rl training, epoch6, iter0, batch909/1133, batch loss:3.2335538691086185e-09, Training time:189969.39954209328
batch reward last col mean 2.310391209903173e-06 first col mean 7.535867325714207e-07 all mean 2.2992599042481743e-06
rl training, epoch6, iter0, batch910/1133, batch loss:1.0997434074511148e-08, Training time:189996.41423034668
batch reward last col mean 3.588705567381112e-06 first col mean 1.3714017086385866e-06 all mean 3.5664272672875086e-06
rl training, epoch6, iter0, batch911/1133, batch loss:2.4161538547673445e-08, Training time:190023.3410027027
batch reward last col mean 6.7471796683094e-06 first col mean 1.0421834303997457e-05 all mean 6.784738616261166e-06
rl training, epoch6, iter0, batch912/1133, batch loss:8.621880098758083e-09, Training time:190049.8811404705
batch reward last col mean 0.0006860190187580884 first col mean 4.558557066047797e-06 all mean 0.0006740393582731485
rl training, epoch6, iter0, batch913/1133, batch loss:3.1384344765683636e-05, Training time:190077.11247372627
batch reward last col mean 1.8671200450626202e-05 first col mean 4.847473519475898e-06 all mean 1.8532211470301263e-05
rl training, epoch6, iter0, batch914/1133, batch loss:1.5138421360916254e-07, Training time:190103.77863407135
batch reward last col mean 1.4088728676142637e-05 first col mean 4.461395747057395e-06 all mean 2.227800177934114e-05
rl training, epoch6, iter0, batch915/1133, batch loss:2.3756075506753405e-07, Training time:190131.48781776428
batch reward last col mean 0.00010593274782877415 first col mean 2.7740003361031995e-07 all mean 0.000112735120637808
rl training, epoch6, iter0, batch916/1133, batch loss:1.1937460158151225e-06, Training time:190158.91655611992
batch reward last col mean 1.0866307093237992e-05 first col mean 5.0659646149142645e-06 all mean 1.0807718354044482e-05
rl training, epoch6, iter0, batch917/1133, batch loss:4.465378822260391e-08, Training time:190185.49489879608
batch reward last col mean 3.043602191610262e-06 first col mean 4.1039173083845526e-05 all mean 3.435521648498252e-06
rl training, epoch6, iter0, batch918/1133, batch loss:1.9099021031365737e-08, Training time:190213.12634444237
batch reward last col mean 3.5580762869358296e-07 first col mean 4.568042186292587e-06 all mean 3.998129614046775e-07
rl training, epoch6, iter0, batch919/1133, batch loss:1.1988432468967858e-08, Training time:190240.00130414963
batch reward last col mean 4.206337109735614e-07 first col mean 4.927082954964135e-07 all mean 1.533176146040205e-05
rl training, epoch6, iter0, batch920/1133, batch loss:6.0551865743718736e-09, Training time:190266.2612042427
batch reward last col mean 2.340004584766575e-06 first col mean 0.00033171032555401325 all mean 5.667891400662484e-06
rl training, epoch6, iter0, batch921/1133, batch loss:4.303608491795785e-08, Training time:190292.7596871853
batch reward last col mean 2.4335520265594823e-07 first col mean 1.7163949451060034e-05 all mean 4.1428739905313705e-07
rl training, epoch6, iter0, batch922/1133, batch loss:4.7840340577920415e-09, Training time:190319.01804828644
batch reward last col mean 4.923649248667061e-05 first col mean 8.659240847919136e-06 all mean 4.8826757847564295e-05
rl training, epoch6, iter0, batch923/1133, batch loss:1.2569170166898402e-06, Training time:190345.4211142063
batch reward last col mean 6.865412160550477e-06 first col mean 7.2964062383107375e-06 all mean 6.880763976369053e-06
rl training, epoch6, iter0, batch924/1133, batch loss:8.776459736736797e-08, Training time:190371.39634394646
batch reward last col mean 4.876428647548892e-07 first col mean 1.9450735635473393e-06 all mean 5.025862606089504e-07
rl training, epoch6, iter0, batch925/1133, batch loss:1.3210912364058913e-08, Training time:190397.45064139366
batch reward last col mean 1.5297017625925946e-06 first col mean 1.9371505004528444e-06 all mean 1.5342822052843985e-06
rl training, epoch6, iter0, batch926/1133, batch loss:8.480085966766637e-09, Training time:190423.69395327568
batch reward last col mean 1.5323568902658735e-07 first col mean 3.9978871768653335e-07 all mean 1.5589301938234712e-07
rl training, epoch6, iter0, batch927/1133, batch loss:2.564054746301281e-09, Training time:190449.54904603958
batch reward last col mean 1.6588702465014649e-06 first col mean 4.002033165306784e-05 all mean 9.21457467484288e-06
rl training, epoch6, iter0, batch928/1133, batch loss:1.832274598712047e-08, Training time:190475.67458033562
batch reward last col mean 2.245387577204383e-06 first col mean 4.549317964119837e-06 all mean 2.7642615805234527e-06
rl training, epoch6, iter0, batch929/1133, batch loss:3.720447505628499e-09, Training time:190501.78294873238
batch reward last col mean 5.352962944016326e-06 first col mean 3.497984835121315e-06 all mean 5.319550382409943e-06
rl training, epoch6, iter0, batch930/1133, batch loss:3.943806348161161e-08, Training time:190527.9951004982
batch reward last col mean 3.522394536048523e-06 first col mean 4.073382342539844e-07 all mean 3.491585403025965e-06
rl training, epoch6, iter0, batch931/1133, batch loss:7.459870943193891e-09, Training time:190554.09864592552
batch reward last col mean 9.215390264216694e-07 first col mean 6.323363322735531e-06 all mean 9.897770496536396e-07
rl training, epoch6, iter0, batch932/1133, batch loss:4.3515266945348685e-09, Training time:190580.29172968864
batch reward last col mean 1.3343081263883505e-05 first col mean 1.067284756572917e-06 all mean 1.3192867299949285e-05
rl training, epoch6, iter0, batch933/1133, batch loss:3.1511149245488923e-07, Training time:190606.49052262306
batch reward last col mean 1.7899183148983866e-05 first col mean 5.296312792779645e-06 all mean 1.7772064893506467e-05
rl training, epoch6, iter0, batch934/1133, batch loss:2.7826976634059974e-07, Training time:190632.71592831612
batch reward last col mean 1.4819263014942408e-05 first col mean 7.3727119342947844e-06 all mean 1.4611660844821017e-05
rl training, epoch6, iter0, batch935/1133, batch loss:1.4371049701367156e-06, Training time:190658.87962937355
batch reward last col mean 1.526255886119543e-07 first col mean 2.263481292175129e-06 all mean 2.0877769202343188e-07
rl training, epoch6, iter0, batch936/1133, batch loss:5.39148059530703e-10, Training time:190685.07207345963
batch reward last col mean 1.1471994184830692e-05 first col mean 3.177364931161719e-07 all mean 1.1445665222709067e-05
rl training, epoch6, iter0, batch937/1133, batch loss:1.439857726381888e-07, Training time:190711.09459900856
batch reward last col mean 9.284451540914063e-10 first col mean 4.91814398628776e-06 all mean 1.1003934332620702e-06
rl training, epoch6, iter0, batch938/1133, batch loss:9.37959172137015e-12, Training time:190737.167617321
batch reward last col mean 1.971851126825186e-09 first col mean 2.968021703964041e-07 all mean 1.8827036285529175e-07
rl training, epoch6, iter0, batch939/1133, batch loss:7.960782033578084e-11, Training time:190763.15638947487
batch reward last col mean 1.795741695787001e-06 first col mean 0.00010177140211453661 all mean 1.7344364096061327e-05
rl training, epoch6, iter0, batch940/1133, batch loss:5.29259089887546e-08, Training time:190789.10800480843
batch reward last col mean 2.719574695220217e-06 first col mean 1.1138175750602386e-06 all mean 2.703464133446687e-06
rl training, epoch6, iter0, batch941/1133, batch loss:9.278300794335337e-09, Training time:190815.20892119408
batch reward last col mean 1.5883866808508174e-06 first col mean 4.0744439502304886e-06 all mean 1.6142067806868e-06
rl training, epoch6, iter0, batch942/1133, batch loss:3.810094462153302e-09, Training time:190841.40768170357
batch reward last col mean 6.061192380002467e-06 first col mean 5.842613518325379e-06 all mean 2.370427864661906e-05
rl training, epoch6, iter0, batch943/1133, batch loss:5.2372444159232145e-09, Training time:190867.63219070435
batch reward last col mean 6.11532959737815e-06 first col mean 4.614752469933592e-06 all mean 1.73069020092953e-05
rl training, epoch6, iter0, batch944/1133, batch loss:8.87647217950871e-08, Training time:190893.89327144623
batch reward last col mean 5.2878231144859456e-06 first col mean 0.0002372860035393387 all mean 1.093991977541009e-05
rl training, epoch6, iter0, batch945/1133, batch loss:3.9398351248109975e-08, Training time:190919.81756401062
batch reward last col mean 6.414646122721024e-06 first col mean 1.0418002602818888e-05 all mean 6.4550213210168295e-06
rl training, epoch6, iter0, batch946/1133, batch loss:1.584248110475528e-07, Training time:190945.97422242165
batch reward last col mean 1.592885200807359e-05 first col mean 1.7366879774272093e-06 all mean 1.5782943592057563e-05
rl training, epoch6, iter0, batch947/1133, batch loss:5.413588155533944e-07, Training time:190972.2186205387
batch reward last col mean 1.3942978966952069e-06 first col mean 6.514073334074055e-07 all mean 4.201185674901353e-06
rl training, epoch6, iter0, batch948/1133, batch loss:6.705433719389475e-08, Training time:190998.2689180374
batch reward last col mean 3.086932931495312e-09 first col mean 4.8247843551507685e-06 all mean 5.527971325136605e-08
rl training, epoch6, iter0, batch949/1133, batch loss:1.8031353320180354e-12, Training time:191024.27606105804
batch reward last col mean 8.55752801953713e-08 first col mean 2.0372101516841212e-06 all mean 2.0623525415430777e-05
rl training, epoch6, iter0, batch950/1133, batch loss:1.3147385402589862e-09, Training time:191050.27281713486
batch reward last col mean 7.80641221354017e-06 first col mean 0.0003237495257053524 all mean 1.0997767276421655e-05
rl training, epoch6, iter0, batch951/1133, batch loss:6.126363416569802e-08, Training time:191076.13292217255
batch reward last col mean 1.3081194992992096e-05 first col mean 3.3228272968699457e-06 all mean 1.3034952644375153e-05
rl training, epoch6, iter0, batch952/1133, batch loss:1.340776236702368e-07, Training time:191102.1938688755
batch reward last col mean 8.433012226305436e-06 first col mean 7.187502433225745e-06 all mean 8.506697668053675e-06
rl training, epoch6, iter0, batch953/1133, batch loss:9.521140498236491e-08, Training time:191128.44655942917
batch reward last col mean 2.352561478957682e-09 first col mean 1.3801145541947335e-05 all mean 1.4250902324874914e-07
rl training, epoch6, iter0, batch954/1133, batch loss:3.8373427699300855e-12, Training time:191154.39758324623
batch reward last col mean 6.688146186206723e-06 first col mean 1.3250680694909533e-06 all mean 1.6693327779648826e-05
rl training, epoch6, iter0, batch955/1133, batch loss:1.5485137794257753e-07, Training time:191180.55600643158
batch reward last col mean 3.244107062982948e-07 first col mean 3.696595456403884e-07 all mean 3.249741666877526e-07
rl training, epoch6, iter0, batch956/1133, batch loss:2.7893858334238075e-09, Training time:191206.59163308144
batch reward last col mean 2.335261095609553e-09 first col mean 2.778484940790804e-06 all mean 3.9097937332144284e-08
rl training, epoch6, iter0, batch957/1133, batch loss:9.695262171219299e-13, Training time:191232.7414932251
batch reward last col mean 5.224300821282668e-06 first col mean 7.030647338979179e-06 all mean 5.253242761682486e-06
rl training, epoch6, iter0, batch958/1133, batch loss:4.693551858281353e-08, Training time:191259.00513267517
batch reward last col mean 3.112986064479628e-07 first col mean 1.084943619389378e-06 all mean 5.190091201257019e-07
rl training, epoch6, iter0, batch959/1133, batch loss:2.0093371411178396e-09, Training time:191285.18215417862
batch reward last col mean 3.248434586566873e-05 first col mean 1.3470144040184096e-05 all mean 3.230316360713914e-05
rl training, epoch6, iter0, batch960/1133, batch loss:2.500793812032498e-07, Training time:191311.5157108307
batch reward last col mean 2.4739983928157017e-06 first col mean 1.978089358090074e-06 all mean 1.0002290764532518e-05
rl training, epoch6, iter0, batch961/1133, batch loss:8.733005429917284e-09, Training time:191337.65406274796
batch reward last col mean 1.0504267265787348e-05 first col mean 4.0008046198636293e-05 all mean 1.0802774340845644e-05
rl training, epoch6, iter0, batch962/1133, batch loss:3.93745835935988e-08, Training time:191363.94421505928
batch reward last col mean 8.580788744438905e-06 first col mean 5.224969754635822e-06 all mean 8.622460882179439e-06
rl training, epoch6, iter0, batch963/1133, batch loss:7.82317144398803e-08, Training time:191389.9668738842
batch reward last col mean 2.4600594770163298e-06 first col mean 2.286033304699231e-05 all mean 2.6663192329579033e-06
rl training, epoch6, iter0, batch964/1133, batch loss:3.615406996004822e-08, Training time:191416.20895528793
batch reward last col mean 1.3870353541278746e-06 first col mean 1.2429136404534802e-06 all mean 1.386830149385787e-06
rl training, epoch6, iter0, batch965/1133, batch loss:8.24677215405245e-09, Training time:191442.12943911552
batch reward last col mean 0.00012537797738332301 first col mean 1.6561151596761192e-06 all mean 0.00012412798241712153
rl training, epoch6, iter0, batch966/1133, batch loss:1.194299511553254e-05, Training time:191468.12842178345
batch reward last col mean 6.187893177411752e-06 first col mean 9.020672223414294e-06 all mean 2.1644240405294113e-05
rl training, epoch6, iter0, batch967/1133, batch loss:4.615601234547739e-09, Training time:191494.1437842846
batch reward last col mean 9.188262879433751e-07 first col mean 1.7765194115781924e-06 all mean 1.1056816902055289e-06
rl training, epoch6, iter0, batch968/1133, batch loss:8.762463643563478e-09, Training time:191520.1495900154
batch reward last col mean 5.695923164239503e-07 first col mean 2.574021891632583e-06 all mean 5.942977168160724e-07
rl training, epoch6, iter0, batch969/1133, batch loss:4.552899390830589e-09, Training time:191546.27701687813
batch reward last col mean 2.4041628421400674e-05 first col mean 8.29936470836401e-06 all mean 2.395455703663174e-05
rl training, epoch6, iter0, batch970/1133, batch loss:6.388529527612263e-07, Training time:191572.01740956306
batch reward last col mean 1.7890482922666706e-05 first col mean 5.395317543843703e-07 all mean 1.7877327991300263e-05
rl training, epoch6, iter0, batch971/1133, batch loss:3.501671699268627e-07, Training time:191598.1845254898
batch reward last col mean 1.2215746210131329e-06 first col mean 3.61383331437537e-06 all mean 1.592680973772076e-06
rl training, epoch6, iter0, batch972/1133, batch loss:1.3031445256217467e-08, Training time:191624.38803100586
batch reward last col mean 1.484561653342098e-05 first col mean 0.00014026854478288442 all mean 1.6112899174913764e-05
rl training, epoch6, iter0, batch973/1133, batch loss:2.2886709416525264e-07, Training time:191650.52166628838
batch reward last col mean 9.674333796283463e-07 first col mean 1.3358794603846036e-05 all mean 1.5645811117792618e-06
rl training, epoch6, iter0, batch974/1133, batch loss:4.4231672546857226e-08, Training time:191676.55257201195
batch reward last col mean 1.4711283711221768e-06 first col mean 5.02765715282294e-06 all mean 1.8409604081170983e-06
rl training, epoch6, iter0, batch975/1133, batch loss:3.3524503173509856e-09, Training time:191702.2218954563
batch reward last col mean 3.2049875642314873e-08 first col mean 1.2263589042049716e-06 all mean 4.433298528283558e-08
rl training, epoch6, iter0, batch976/1133, batch loss:1.859917914126541e-10, Training time:191728.394906044
batch reward last col mean 1.4779496950723114e-06 first col mean 3.268131331424229e-05 all mean 1.7938959899765905e-06
rl training, epoch6, iter0, batch977/1133, batch loss:3.4311642416184895e-09, Training time:191755.24462628365
batch reward last col mean 6.541739594467799e-07 first col mean 2.5860260848276084e-06 all mean 6.780766170777497e-07
rl training, epoch6, iter0, batch978/1133, batch loss:1.6090332399798513e-09, Training time:191781.4793560505
batch reward last col mean 3.111477298034515e-09 first col mean 1.3906159438192844e-05 all mean 1.4448868057570508e-07
rl training, epoch6, iter0, batch979/1133, batch loss:1.551206905980873e-11, Training time:191807.41886520386
batch reward last col mean 6.111940365371993e-06 first col mean 9.709176993055735e-06 all mean 6.358030077535659e-06
rl training, epoch6, iter0, batch980/1133, batch loss:1.178811892543763e-08, Training time:191833.4636349678
batch reward last col mean 1.1196325644391436e-08 first col mean 0.0002554179518483579 all mean 6.44233023194829e-06
rl training, epoch6, iter0, batch981/1133, batch loss:4.0374181775604256e-10, Training time:191859.43239998817
batch reward last col mean 1.0342888767667091e-09 first col mean 7.742613092887041e-07 all mean 8.860634004292933e-09
rl training, epoch6, iter0, batch982/1133, batch loss:3.656808363061703e-12, Training time:191885.53210234642
batch reward last col mean 2.525799754948821e-05 first col mean 4.605257709044963e-05 all mean 4.520887159742415e-05
rl training, epoch6, iter0, batch983/1133, batch loss:2.1878378220208106e-07, Training time:191911.8182475567
batch reward last col mean 2.8720776299451245e-06 first col mean 3.5774683055933565e-06 all mean 2.9707744033657946e-06
rl training, epoch6, iter0, batch984/1133, batch loss:2.4166787682133872e-08, Training time:191937.83399152756
batch reward last col mean 1.0166028914682101e-05 first col mean 3.7577488001261372e-06 all mean 1.0168212611461058e-05
rl training, epoch6, iter0, batch985/1133, batch loss:1.3212881810886756e-07, Training time:191963.94413471222
batch reward last col mean 4.0598970940664003e-07 first col mean 9.905126034936984e-07 all mean 3.0688215701957233e-06
rl training, epoch6, iter0, batch986/1133, batch loss:1.1422867096655409e-08, Training time:191990.10315585136
batch reward last col mean 0.0004841338377445936 first col mean 1.0548326372372685e-06 all mean 0.00047437933972105384
rl training, epoch6, iter0, batch987/1133, batch loss:1.988030635402538e-05, Training time:192016.30823230743
batch reward last col mean 4.857469684793614e-05 first col mean 7.4166700869682245e-06 all mean 4.8380348744103685e-05
rl training, epoch6, iter0, batch988/1133, batch loss:8.556781381230394e-07, Training time:192042.43597960472
batch reward last col mean 2.9312872356968e-05 first col mean 8.29979035188444e-06 all mean 2.9006323529756628e-05
rl training, epoch6, iter0, batch989/1133, batch loss:9.411689916305477e-07, Training time:192068.6496052742
batch reward last col mean 1.8180002371082082e-05 first col mean 1.8238888515043072e-05 all mean 1.8180722690885887e-05
rl training, epoch6, iter0, batch990/1133, batch loss:1.1822579182307891e-07, Training time:192094.6849515438
batch reward last col mean 9.441400834475644e-06 first col mean 2.7753640097216703e-06 all mean 9.374081855639815e-06
rl training, epoch6, iter0, batch991/1133, batch loss:2.135549124204772e-07, Training time:192120.8761498928
batch reward last col mean 8.802758202364203e-07 first col mean 1.0582390359559213e-06 all mean 8.821762094157748e-07
rl training, epoch6, iter0, batch992/1133, batch loss:3.6030392003283396e-09, Training time:192147.0357990265
batch reward last col mean 1.1005643045791658e-06 first col mean 1.168240123661235e-05 all mean 1.170410087070195e-05
rl training, epoch6, iter0, batch993/1133, batch loss:5.218170784360154e-09, Training time:192173.53374958038
batch reward last col mean 2.7100091756437905e-05 first col mean 1.5041534425108694e-05 all mean 2.709663749556057e-05
rl training, epoch6, iter0, batch994/1133, batch loss:5.454099323287664e-07, Training time:192199.61331415176
batch reward last col mean 1.6162186966539593e-06 first col mean 3.537617772053636e-07 all mean 2.1094865587656386e-06
rl training, epoch6, iter0, batch995/1133, batch loss:3.980996510222212e-08, Training time:192225.65680933
batch reward last col mean 9.154550753009971e-07 first col mean 5.112648864269431e-07 all mean 9.174906381304027e-07
rl training, epoch6, iter0, batch996/1133, batch loss:1.090324008856669e-08, Training time:192251.89684915543
batch reward last col mean 2.290056272613583e-06 first col mean 4.102441266695678e-07 all mean 2.27456757784239e-06
rl training, epoch6, iter0, batch997/1133, batch loss:1.168193630718406e-08, Training time:192278.0630326271
batch reward last col mean 0.0019669560715556145 first col mean 2.45287264988292e-05 all mean 0.0019473455613479018
rl training, epoch6, iter0, batch998/1133, batch loss:0.00013390208187047392, Training time:192304.42140865326
batch reward last col mean 0.00010737917182268575 first col mean 2.436361455693259e-06 all mean 0.0001063198724295944
rl training, epoch6, iter0, batch999/1133, batch loss:5.043140163252247e-07, Training time:192330.88497757912
batch reward last col mean 0.006315796636044979 first col mean 1.7965442111744778e-06 all mean 0.0061883265152573586
rl training, epoch6, iter0, batch1000/1133, batch loss:0.0004728176863864064, Training time:192356.9718492031
batch reward last col mean 4.3223824519600385e-08 first col mean 6.250367619031749e-07 all mean 4.987655088939391e-08
rl training, epoch6, iter0, batch1001/1133, batch loss:1.579614106184124e-09, Training time:192383.00992560387
batch reward last col mean 1.4066038147575455e-06 first col mean 1.0078351806441788e-05 all mean 2.2706044546794146e-06
rl training, epoch6, iter0, batch1002/1133, batch loss:7.2749042345776616e-09, Training time:192409.25706601143
batch reward last col mean 6.403682277777989e-07 first col mean 3.5584531588028767e-07 all mean 6.311852303042542e-07
rl training, epoch6, iter0, batch1003/1133, batch loss:3.5778665363750406e-08, Training time:192435.35773468018
batch reward last col mean 1.8516428099246696e-05 first col mean 3.0465846521110507e-06 all mean 1.9777326087933034e-05
rl training, epoch6, iter0, batch1004/1133, batch loss:9.596580952120348e-08, Training time:192461.57417154312
batch reward last col mean 7.894728071278223e-08 first col mean 1.3954934729554225e-05 all mean 6.376217811521201e-07
rl training, epoch6, iter0, batch1005/1133, batch loss:1.195879645310427e-10, Training time:192487.58916974068
batch reward last col mean 3.1027440854813904e-05 first col mean 3.611495230870787e-06 all mean 3.0751340091228485e-05
rl training, epoch6, iter0, batch1006/1133, batch loss:4.5292861727830314e-07, Training time:192513.80497574806
batch reward last col mean 3.359758693477488e-07 first col mean 1.7926909379184508e-07 all mean 5.06810295064497e-07
rl training, epoch6, iter0, batch1007/1133, batch loss:1.408838046224048e-09, Training time:192539.740981102
batch reward last col mean 1.2403358596202452e-05 first col mean 4.494975655688904e-06 all mean 1.2356912520772312e-05
rl training, epoch6, iter0, batch1008/1133, batch loss:9.590316096819151e-08, Training time:192565.9204800129
batch reward last col mean 2.2066817109589465e-05 first col mean 9.60986508289352e-05 all mean 4.067016197950579e-05
rl training, epoch6, iter0, batch1009/1133, batch loss:5.279860815221582e-08, Training time:192592.11782884598
batch reward last col mean 2.2431054791383076e-09 first col mean 7.825776265235618e-06 all mean 8.205270063399439e-08
rl training, epoch6, iter0, batch1010/1133, batch loss:1.0797095162384807e-10, Training time:192618.17917346954
batch reward last col mean 1.4889858448441373e-06 first col mean 1.5662508303648792e-06 all mean 4.945366981701227e-06
rl training, epoch6, iter0, batch1011/1133, batch loss:5.671675573637458e-09, Training time:192644.39580988884
batch reward last col mean 0.0066130985505878925 first col mean 1.380696289743355e-06 all mean 0.00642941752448678
rl training, epoch6, iter0, batch1012/1133, batch loss:0.0005292134010232985, Training time:192670.47954416275
batch reward last col mean 5.0429539442120586e-06 first col mean 6.136669526313199e-06 all mean 5.0595190259628e-06
rl training, epoch6, iter0, batch1013/1133, batch loss:2.1970693708794897e-08, Training time:192696.56075906754
batch reward last col mean 0.00033653114223852754 first col mean 7.293987209777697e-07 all mean 0.00018540100427344441
rl training, epoch6, iter0, batch1014/1133, batch loss:5.396970664151013e-05, Training time:192722.72772288322
batch reward last col mean 9.842346116784029e-06 first col mean 9.299894372816198e-06 all mean 9.864047569863033e-06
rl training, epoch6, iter0, batch1015/1133, batch loss:2.986675085026036e-08, Training time:192748.74857330322
batch reward last col mean 7.735461622360162e-07 first col mean 5.1029219321208075e-06 all mean 8.174458798748674e-07
rl training, epoch6, iter0, batch1016/1133, batch loss:3.5291924938007924e-09, Training time:192774.80761003494
batch reward last col mean 1.5560289057248156e-06 first col mean 7.898747753642965e-06 all mean 1.621286401132238e-06
rl training, epoch6, iter0, batch1017/1133, batch loss:6.277124953157909e-08, Training time:192800.91668081284
batch reward last col mean 9.928706276696175e-06 first col mean 1.2591901395353489e-05 all mean 3.28040769090876e-05
rl training, epoch6, iter0, batch1018/1133, batch loss:1.1196927118817257e-07, Training time:192827.26374077797
batch reward last col mean 9.726887583383359e-06 first col mean 7.605424343637424e-06 all mean 9.81225002760766e-06
rl training, epoch6, iter0, batch1019/1133, batch loss:1.8575687477095926e-07, Training time:192853.50265026093
batch reward last col mean 4.563008587865625e-06 first col mean 5.661399882228579e-06 all mean 4.600925876729889e-06
rl training, epoch6, iter0, batch1020/1133, batch loss:1.9140957263630298e-08, Training time:192879.55861592293
batch reward last col mean 3.127818445136654e-06 first col mean 5.55037877347786e-06 all mean 3.1529875741398428e-06
rl training, epoch6, iter0, batch1021/1133, batch loss:2.0998571770292074e-08, Training time:192905.73653793335
batch reward last col mean 4.2200654206681065e-06 first col mean 3.292562496426399e-06 all mean 5.962816885585198e-06
rl training, epoch6, iter0, batch1022/1133, batch loss:4.13541449972854e-08, Training time:192932.0055949688
batch reward last col mean 2.475971996318549e-06 first col mean 5.794486787635833e-05 all mean 3.0364708436536603e-06
rl training, epoch6, iter0, batch1023/1133, batch loss:3.271297899232195e-08, Training time:192958.17487215996
batch reward last col mean 5.0466329412302e-05 first col mean 1.125939775192819e-06 all mean 5.026823055231944e-05
rl training, epoch6, iter0, batch1024/1133, batch loss:2.3234491663970402e-07, Training time:192984.45763611794
batch reward last col mean 4.665039341489319e-06 first col mean 8.80686566233635e-05 all mean 5.507507921720389e-06
rl training, epoch6, iter0, batch1025/1133, batch loss:6.261995366685369e-08, Training time:193010.4958536625
batch reward last col mean 3.6427729810384335e-06 first col mean 6.9528859967249446e-06 all mean 3.7155828067625407e-06
rl training, epoch6, iter0, batch1026/1133, batch loss:2.5044930573869806e-09, Training time:193036.64745426178
batch reward last col mean 2.8578073397511616e-05 first col mean 5.033995421399595e-06 all mean 2.8350126740406267e-05
rl training, epoch6, iter0, batch1027/1133, batch loss:2.609555167509825e-07, Training time:193062.77077794075
batch reward last col mean 1.0077187653223518e-06 first col mean 1.3476635103870649e-05 all mean 1.147411694546463e-06
rl training, epoch6, iter0, batch1028/1133, batch loss:1.3823213684815983e-08, Training time:193088.8169286251
batch reward last col mean 4.24803481280378e-09 first col mean 9.747926696945797e-07 all mean 1.4085085098258787e-08
rl training, epoch6, iter0, batch1029/1133, batch loss:9.161071207186566e-12, Training time:193114.85791397095
batch reward last col mean 5.504003638634458e-06 first col mean 2.5443805498071015e-06 all mean 5.474920726555865e-06
rl training, epoch6, iter0, batch1030/1133, batch loss:6.515971051612723e-08, Training time:193141.03973174095
batch reward last col mean 7.988433935679495e-06 first col mean 3.5680257042258745e-06 all mean 7.94401694292901e-06
rl training, epoch6, iter0, batch1031/1133, batch loss:2.1300401442658767e-07, Training time:193167.2285346985
batch reward last col mean 3.120087965768903e-09 first col mean 2.7243585165592776e-09 all mean 1.1378913455928341e-07
rl training, epoch6, iter0, batch1032/1133, batch loss:1.621699823040057e-11, Training time:193193.26887750626
batch reward last col mean 3.3918647659447743e-06 first col mean 3.4667873478611e-06 all mean 3.3926405649253866e-06
rl training, epoch6, iter0, batch1033/1133, batch loss:2.3135847015964828e-08, Training time:193219.5038473606
batch reward last col mean 3.209308943041833e-06 first col mean 4.952903054800117e-06 all mean 3.3753228763089282e-06
rl training, epoch6, iter0, batch1034/1133, batch loss:1.4105766332761505e-08, Training time:193245.48605370522
batch reward last col mean 1.7820631910581142e-05 first col mean 1.7823007510742173e-05 all mean 3.526865111780353e-05
rl training, epoch6, iter0, batch1035/1133, batch loss:2.6065134051123096e-08, Training time:193271.4126956463
batch reward last col mean 3.01133923130692e-06 first col mean 0.0001114698825404048 all mean 4.10724032917642e-06
rl training, epoch6, iter0, batch1036/1133, batch loss:8.573601384398444e-09, Training time:193297.66844964027
batch reward last col mean 9.672832675278187e-06 first col mean 1.0519131137698423e-05 all mean 9.681386472948361e-06
rl training, epoch6, iter0, batch1037/1133, batch loss:1.0145357443036573e-08, Training time:193323.69991135597
batch reward last col mean 9.26882421481423e-06 first col mean 1.4318723515316378e-05 all mean 9.524073902866803e-06
rl training, epoch6, iter0, batch1038/1133, batch loss:2.045198232991652e-09, Training time:193350.0803115368
batch reward last col mean 1.1039754099329002e-05 first col mean 1.3195996871218085e-05 all mean 1.1535610610735603e-05
rl training, epoch6, iter0, batch1039/1133, batch loss:1.3668429232893686e-07, Training time:193376.13447618484
batch reward last col mean 3.957880380767165e-06 first col mean 7.990588528627995e-06 all mean 6.334584668366006e-06
rl training, epoch6, iter0, batch1040/1133, batch loss:1.2685112515953278e-08, Training time:193402.1544032097
batch reward last col mean 8.855507438454424e-09 first col mean 2.0697318632301176e-06 all mean 3.063917120016413e-08
rl training, epoch6, iter0, batch1041/1133, batch loss:4.746247665721182e-12, Training time:193428.18746948242
batch reward last col mean 1.6793155737104826e-06 first col mean 3.842846581392223e-06 all mean 2.618007101773401e-06
rl training, epoch6, iter0, batch1042/1133, batch loss:6.068367586209433e-09, Training time:193454.3539223671
batch reward last col mean 3.9713791011308786e-06 first col mean 3.3011170330610184e-07 all mean 3.935387212550268e-06
rl training, epoch6, iter0, batch1043/1133, batch loss:1.7201536195443623e-08, Training time:193480.4316380024
batch reward last col mean 1.3889249430576456e-06 first col mean 7.3179430728487205e-06 all mean 1.449140995646303e-06
rl training, epoch6, iter0, batch1044/1133, batch loss:6.325547197150172e-09, Training time:193506.4557583332
batch reward last col mean 6.199232302606106e-05 first col mean 1.800716927391477e-05 all mean 6.167058745631948e-05
rl training, epoch6, iter0, batch1045/1133, batch loss:9.351031167170731e-07, Training time:193532.45542144775
batch reward last col mean 1.845450242399238e-05 first col mean 2.5894041755236685e-06 all mean 1.829154098231811e-05
rl training, epoch6, iter0, batch1046/1133, batch loss:5.189907881231193e-08, Training time:193558.7206492424
batch reward last col mean 2.603403345347033e-06 first col mean 1.524645881545439e-06 all mean 5.5151654123619664e-06
rl training, epoch6, iter0, batch1047/1133, batch loss:1.3826166878061485e-07, Training time:193584.76737213135
batch reward last col mean 9.1673581437135e-07 first col mean 8.700228136149235e-06 all mean 1.0104806733579608e-06
rl training, epoch6, iter0, batch1048/1133, batch loss:1.213699007962532e-08, Training time:193611.00111198425
batch reward last col mean 1.4889213161950465e-05 first col mean 2.0328545815573307e-06 all mean 1.4759792065888178e-05
rl training, epoch6, iter0, batch1049/1133, batch loss:1.0643910854923888e-06, Training time:193637.07678318024
batch reward last col mean 1.8545213720244647e-07 first col mean 3.2384079986513825e-06 all mean 2.817458835124853e-07
rl training, epoch6, iter0, batch1050/1133, batch loss:2.490702089019692e-09, Training time:193662.98604559898
batch reward last col mean 1.3402956028585322e-05 first col mean 3.3965213788178517e-06 all mean 1.3305393622431438e-05
rl training, epoch6, iter0, batch1051/1133, batch loss:5.094425858942486e-08, Training time:193689.07411193848
batch reward last col mean 7.667343197681475e-06 first col mean 6.656310688413214e-06 all mean 7.697532964812126e-06
rl training, epoch6, iter0, batch1052/1133, batch loss:3.378075774662648e-08, Training time:193715.3911600113
batch reward last col mean 2.829528511938406e-06 first col mean 1.3790505363431294e-05 all mean 1.4500008546747267e-05
rl training, epoch6, iter0, batch1053/1133, batch loss:3.431052419955449e-08, Training time:193741.41006565094
batch reward last col mean 1.9898254777217517e-07 first col mean 0.00013380068412516266 all mean 1.9963645172538236e-05
rl training, epoch6, iter0, batch1054/1133, batch loss:5.15053555361078e-10, Training time:193767.71128439903
batch reward last col mean 1.3439522490443778e-06 first col mean 1.3035277333983686e-05 all mean 2.3653255993849598e-06
rl training, epoch6, iter0, batch1055/1133, batch loss:1.0459107357974062e-08, Training time:193793.87998890877
batch reward last col mean 1.584917185937229e-06 first col mean 2.245728182970197e-06 all mean 4.605411959346384e-06
rl training, epoch6, iter0, batch1056/1133, batch loss:1.090956547322719e-09, Training time:193819.92538833618
batch reward last col mean 8.038059604587033e-06 first col mean 5.260775424176245e-07 all mean 8.512992280884646e-06
rl training, epoch6, iter0, batch1057/1133, batch loss:3.5971311262983363e-07, Training time:193846.20144438744
batch reward last col mean 0.00013411864347290248 first col mean 8.954455552157015e-06 all mean 0.00013286119792610407
rl training, epoch6, iter0, batch1058/1133, batch loss:5.3319699873100035e-06, Training time:193872.2720284462
batch reward last col mean 8.519429684383795e-06 first col mean 5.4184324653760996e-06 all mean 8.698812962393276e-06
rl training, epoch6, iter0, batch1059/1133, batch loss:4.328040148493528e-08, Training time:193898.49396443367
batch reward last col mean 3.985668172390433e-06 first col mean 2.4984638002933934e-07 all mean 3.967026259488193e-06
rl training, epoch6, iter0, batch1060/1133, batch loss:9.455967386884367e-08, Training time:193924.3831691742
batch reward last col mean 1.3931447028880939e-05 first col mean 5.074035925645148e-06 all mean 1.3847944501321763e-05
rl training, epoch6, iter0, batch1061/1133, batch loss:4.880289949937833e-08, Training time:193950.53640937805
batch reward last col mean 1.0158908480661921e-05 first col mean 3.4237650652357843e-06 all mean 1.0091007425216958e-05
rl training, epoch6, iter0, batch1062/1133, batch loss:1.0190746735361245e-07, Training time:193976.63029837608
batch reward last col mean 9.27988367038779e-06 first col mean 6.059303632355295e-05 all mean 9.86099894362269e-06
rl training, epoch6, iter0, batch1063/1133, batch loss:2.389612347997172e-07, Training time:194002.74076747894
batch reward last col mean 1.3166877579351421e-06 first col mean 0.0008424439583905041 all mean 1.0330418263038155e-05
rl training, epoch6, iter0, batch1064/1133, batch loss:2.4305192525275743e-08, Training time:194029.22160935402
batch reward last col mean 5.7996402347271214e-08 first col mean 1.2026091553707374e-06 all mean 6.906780072313268e-06
rl training, epoch6, iter0, batch1065/1133, batch loss:3.335255405190196e-10, Training time:194055.17139959335
batch reward last col mean 1.3304166714078747e-05 first col mean 4.512915893428726e-06 all mean 1.8871432985179126e-05
rl training, epoch6, iter0, batch1066/1133, batch loss:3.6244901480131375e-07, Training time:194081.42385149002
batch reward last col mean 1.6625624255084404e-07 first col mean 2.576297447376419e-06 all mean 2.5080925070142257e-07
rl training, epoch6, iter0, batch1067/1133, batch loss:1.514996877949315e-10, Training time:194107.80293822289
batch reward last col mean 5.143812086316757e-05 first col mean 1.3201141882746015e-05 all mean 5.237289587967098e-05
rl training, epoch6, iter0, batch1068/1133, batch loss:7.249105919981957e-07, Training time:194133.9485423565
batch reward last col mean 7.173081257860758e-07 first col mean 5.815241820528172e-06 all mean 2.0351391867734492e-05
rl training, epoch6, iter0, batch1069/1133, batch loss:1.6728344931493666e-08, Training time:194159.98457574844
batch reward last col mean 2.087042503262637e-06 first col mean 7.949819291752647e-07 all mean 3.1482047688768944e-06
rl training, epoch6, iter0, batch1070/1133, batch loss:1.800447257949145e-08, Training time:194186.03307652473
batch reward last col mean 0.00020661301095969975 first col mean 2.131562723661773e-06 all mean 2.7684922315529548e-05
rl training, epoch6, iter0, batch1071/1133, batch loss:2.4907842089305632e-05, Training time:194212.03009486198
batch reward last col mean 5.044241024876328e-09 first col mean 3.3782848163355084e-07 all mean 1.0735299760256112e-08
rl training, epoch6, iter0, batch1072/1133, batch loss:1.8955097907946694e-11, Training time:194237.99952101707
batch reward last col mean 3.211527655366808e-05 first col mean 1.2864670679846313e-05 all mean 3.34892793034669e-05
rl training, epoch6, iter0, batch1073/1133, batch loss:1.8817259217485116e-07, Training time:194264.84085416794
batch reward last col mean 1.2815942227462074e-06 first col mean 1.8747285821518744e-06 all mean 1.1915265076822834e-06
rl training, epoch6, iter0, batch1074/1133, batch loss:2.685184519179984e-08, Training time:194291.2918896675
batch reward last col mean 1.412983351656294e-06 first col mean 3.5245302569819614e-06 all mean 1.9044799728362705e-06
rl training, epoch6, iter0, batch1075/1133, batch loss:7.087400888394768e-08, Training time:194317.98999786377
batch reward last col mean 2.874969595723087e-06 first col mean 3.5079283406957984e-06 all mean 8.373433956876397e-06
rl training, epoch6, iter0, batch1076/1133, batch loss:1.0432584929276345e-07, Training time:194344.57679200172
batch reward last col mean 0.007592213340103626 first col mean 9.17124816623982e-06 all mean 0.007433408871293068
rl training, epoch6, iter0, batch1077/1133, batch loss:0.0009677383350208402, Training time:194371.20880818367
batch reward last col mean 1.709215439404943e-06 first col mean 1.0503189287192072e-06 all mean 1.7190083099194453e-06
rl training, epoch6, iter0, batch1078/1133, batch loss:4.9130335355584975e-08, Training time:194397.92428016663
batch reward last col mean 9.800552334127133e-07 first col mean 5.712566689908272e-06 all mean 1.4025367818248924e-06
rl training, epoch6, iter0, batch1079/1133, batch loss:3.128410597241782e-08, Training time:194424.92323803902
batch reward last col mean 1.585550648997014e-06 first col mean 1.0041136420113617e-06 all mean 2.3947227418830153e-06
rl training, epoch6, iter0, batch1080/1133, batch loss:8.132910345182154e-09, Training time:194452.1045255661
batch reward last col mean 1.3944711554358946e-06 first col mean 9.356396617477003e-07 all mean 1.395510707880021e-06
rl training, epoch6, iter0, batch1081/1133, batch loss:3.15873371903308e-08, Training time:194479.39317536354
batch reward last col mean 3.0499582859278007e-09 first col mean 2.1016667517415044e-08 all mean 1.727425171793584e-07
rl training, epoch6, iter0, batch1082/1133, batch loss:9.263015701699295e-12, Training time:194506.03281879425
batch reward last col mean 3.9141150409705006e-06 first col mean 3.4953077374666464e-06 all mean 3.909900897269836e-06
rl training, epoch6, iter0, batch1083/1133, batch loss:4.9065618235033526e-09, Training time:194533.46597456932
batch reward last col mean 5.18157503393013e-06 first col mean 7.505991561629344e-06 all mean 5.606564172921935e-06
rl training, epoch6, iter0, batch1084/1133, batch loss:2.0092370434099394e-08, Training time:194561.48412418365
batch reward last col mean 9.884410246741027e-06 first col mean 6.593103876184614e-07 all mean 9.791352567845024e-06
rl training, epoch6, iter0, batch1085/1133, batch loss:2.721432963426196e-07, Training time:194588.9489350319
batch reward last col mean 7.201854259619722e-07 first col mean 1.087153805201524e-06 all mean 1.7758590047378675e-06
rl training, epoch6, iter0, batch1086/1133, batch loss:5.083039322784089e-09, Training time:194616.0586977005
batch reward last col mean 1.1945887763431529e-06 first col mean 1.0233524108116399e-06 all mean 5.621732270810753e-06
rl training, epoch6, iter0, batch1087/1133, batch loss:4.407179954313278e-09, Training time:194642.22619581223
batch reward last col mean 6.120640136941802e-06 first col mean 8.478093036501377e-07 all mean 7.072375410643872e-06
rl training, epoch6, iter0, batch1088/1133, batch loss:8.561714537336229e-08, Training time:194669.35569548607
batch reward last col mean 1.1992613508482464e-05 first col mean 1.692410296527669e-05 all mean 1.2042570233461447e-05
rl training, epoch6, iter0, batch1089/1133, batch loss:2.1384465753726545e-07, Training time:194696.2429959774
batch reward last col mean 0.0001136280334321782 first col mean 0.001177942962385714 all mean 0.00014889167505316436
rl training, epoch6, iter0, batch1090/1133, batch loss:7.484455636586063e-06, Training time:194722.78730010986
batch reward last col mean 1.5661699137581309e-07 first col mean 0.0007055251626297832 all mean 7.281627404154278e-06
rl training, epoch6, iter0, batch1091/1133, batch loss:1.4675806125907798e-09, Training time:194749.55078816414
batch reward last col mean 4.4985154090682045e-07 first col mean 2.285809159729979e-06 all mean 4.70021689125133e-07
rl training, epoch6, iter0, batch1092/1133, batch loss:6.084702186548441e-10, Training time:194776.2122900486
batch reward last col mean 8.890855838217249e-07 first col mean 1.7291665699303849e-06 all mean 9.039541737365653e-07
rl training, epoch6, iter0, batch1093/1133, batch loss:2.59482019204782e-10, Training time:194802.97493171692
batch reward last col mean 4.926115707348799e-06 first col mean 5.851468813489191e-06 all mean 8.97990230441792e-06
rl training, epoch6, iter0, batch1094/1133, batch loss:1.380974534725965e-08, Training time:194829.36972880363
batch reward last col mean 2.598883384052897e-06 first col mean 5.61745218874421e-06 all mean 2.641821765791974e-06
rl training, epoch6, iter0, batch1095/1133, batch loss:1.4336970721728903e-08, Training time:194855.39419674873
batch reward last col mean 3.108088276349008e-05 first col mean 2.0446190319489688e-05 all mean 3.09734714392107e-05
rl training, epoch6, iter0, batch1096/1133, batch loss:8.03220075340505e-07, Training time:194881.68419122696
batch reward last col mean 7.693643055972643e-07 first col mean 8.198959449146059e-07 all mean 9.701554972707527e-07
rl training, epoch6, iter0, batch1097/1133, batch loss:2.4486535021850386e-09, Training time:194907.89174628258
batch reward last col mean 3.574210131773725e-05 first col mean 2.2270047338679433e-05 all mean 3.560899494914338e-05
rl training, epoch6, iter0, batch1098/1133, batch loss:7.873912721834131e-08, Training time:194934.12835001945
batch reward last col mean 4.974333478457993e-07 first col mean 4.7095436457311735e-06 all mean 5.401242333391565e-07
rl training, epoch6, iter0, batch1099/1133, batch loss:2.4770223205905495e-08, Training time:194960.1862847805
batch reward last col mean 1.8350887103224522e-06 first col mean 2.3797051653673407e-06 all mean 1.8401843817628105e-06
rl training, epoch6, iter0, batch1100/1133, batch loss:1.1782645970015437e-08, Training time:194986.28993153572
batch reward last col mean 2.2113981685834005e-05 first col mean 6.90626302457531e-06 all mean 2.197427602368407e-05
rl training, epoch6, iter0, batch1101/1133, batch loss:1.5001361362010357e-06, Training time:195012.37487363815
batch reward last col mean 0.006944015622138977 first col mean 9.993050298362505e-07 all mean 0.0020370534621179104
rl training, epoch6, iter0, batch1102/1133, batch loss:0.000838112726341933, Training time:195038.77752041817
batch reward last col mean 1.028452629725507e-06 first col mean 1.6898335161386058e-05 all mean 2.192562988057034e-06
rl training, epoch6, iter0, batch1103/1133, batch loss:4.048745783080676e-09, Training time:195064.96675610542
batch reward last col mean 1.0373290706411353e-06 first col mean 0.00034697013325057924 all mean 9.65244271355914e-06
rl training, epoch6, iter0, batch1104/1133, batch loss:1.7218166448174088e-08, Training time:195091.10418653488
batch reward last col mean 1.1989062841166742e-05 first col mean 1.003665693133371e-05 all mean 3.8225447497097775e-05
rl training, epoch6, iter0, batch1105/1133, batch loss:6.184692580291085e-08, Training time:195117.19646763802
batch reward last col mean 2.068296225843369e-06 first col mean 1.895383138617035e-05 all mean 2.239077730337158e-06
rl training, epoch6, iter0, batch1106/1133, batch loss:6.2186771287997544e-09, Training time:195143.2916352749
batch reward last col mean 4.6899212975404225e-06 first col mean 0.0008039113599807024 all mean 1.316458929068176e-05
rl training, epoch6, iter0, batch1107/1133, batch loss:6.323273282760056e-08, Training time:195169.45802164078
batch reward last col mean 6.69972814648645e-06 first col mean 0.000967846717685461 all mean 1.64292778208619e-05
rl training, epoch6, iter0, batch1108/1133, batch loss:8.76109673697556e-09, Training time:195195.76498794556
batch reward last col mean 1.2281389899726491e-05 first col mean 4.426889063324779e-06 all mean 1.2202089237689506e-05
rl training, epoch6, iter0, batch1109/1133, batch loss:2.3042932184580422e-07, Training time:195221.95944070816
batch reward last col mean 1.5963552868925035e-05 first col mean 0.00034892887924797833 all mean 1.932831401063595e-05
rl training, epoch6, iter0, batch1110/1133, batch loss:7.971566446940415e-07, Training time:195248.11906433105
batch reward last col mean 0.0001647863391553983 first col mean 0.0015320315724238753 all mean 0.00020718818996101618
rl training, epoch6, iter0, batch1111/1133, batch loss:0.00018956871645059437, Training time:195274.2305574417
batch reward last col mean 1.3039059467701009e-06 first col mean 2.0678471628343686e-06 all mean 1.3123300277584349e-06
rl training, epoch6, iter0, batch1112/1133, batch loss:1.1232204499833642e-08, Training time:195300.90202140808
batch reward last col mean 3.178498175770983e-08 first col mean 5.873219834029442e-06 all mean 1.4670663404103834e-05
rl training, epoch6, iter0, batch1113/1133, batch loss:5.82543235871924e-10, Training time:195327.21390080452
batch reward last col mean 4.7312343554040126e-07 first col mean 1.536746094643604e-05 all mean 1.9971821529907174e-05
rl training, epoch6, iter0, batch1114/1133, batch loss:5.123426571884693e-09, Training time:195353.01557826996
batch reward last col mean 4.576802439260064e-06 first col mean 1.4755405572941527e-05 all mean 4.818361503566848e-06
rl training, epoch6, iter0, batch1115/1133, batch loss:3.7201562719246795e-08, Training time:195379.01115107536
batch reward last col mean 5.809581580251688e-06 first col mean 1.2758453067363007e-06 all mean 2.1202142306719907e-05
rl training, epoch6, iter0, batch1116/1133, batch loss:8.800105888440157e-08, Training time:195405.17632198334
batch reward last col mean 4.588599367139068e-08 first col mean 2.8692298656096682e-05 all mean 3.69483274198501e-07
rl training, epoch6, iter0, batch1117/1133, batch loss:8.586146238442893e-10, Training time:195431.2904367447
batch reward last col mean 4.6480593596243125e-07 first col mean 1.1217806559216115e-06 all mean 4.7160335725493496e-07
rl training, epoch6, iter0, batch1118/1133, batch loss:4.973046863199215e-09, Training time:195457.47928619385
batch reward last col mean 0.0003149477706756443 first col mean 1.8961046066579001e-07 all mean 0.0003086684155277908
rl training, epoch6, iter0, batch1119/1133, batch loss:2.0592446162481792e-05, Training time:195483.4599442482
batch reward last col mean 7.3359947236895096e-06 first col mean 1.0297162589267828e-05 all mean 7.647244274266995e-06
rl training, epoch6, iter0, batch1120/1133, batch loss:1.5951823684190458e-07, Training time:195509.58523917198
batch reward last col mean 0.0011680026073008776 first col mean 0.0013385930797085166 all mean 0.0011704124044626951
rl training, epoch6, iter0, batch1121/1133, batch loss:5.890449756407179e-05, Training time:195535.69464230537
batch reward last col mean 2.2787448870076332e-06 first col mean 5.67924985261925e-07 all mean 2.2614899535255972e-06
rl training, epoch6, iter0, batch1122/1133, batch loss:4.875860426523104e-08, Training time:195561.76118445396
batch reward last col mean 7.81686537720816e-07 first col mean 5.817561486765044e-06 all mean 8.185353181033861e-06
rl training, epoch6, iter0, batch1123/1133, batch loss:7.078481689681837e-10, Training time:195587.87899017334
batch reward last col mean 6.827867196079751e-07 first col mean 3.2739703783590812e-06 all mean 7.122876013454515e-07
rl training, epoch6, iter0, batch1124/1133, batch loss:9.040926340908584e-10, Training time:195613.9886701107
batch reward last col mean 5.025788141210796e-07 first col mean 1.0384470670032897e-06 all mean 2.5088950224017026e-06
rl training, epoch6, iter0, batch1125/1133, batch loss:1.8693789627377555e-08, Training time:195639.95202612877
batch reward last col mean 0.001503294799476862 first col mean 4.3821179133374244e-05 all mean 0.0014735441654920578
rl training, epoch6, iter0, batch1126/1133, batch loss:0.00010087949340231717, Training time:195666.00099897385
batch reward last col mean 9.207551165957284e-09 first col mean 9.013381259137532e-07 all mean 1.3109746532791178e-06
rl training, epoch6, iter0, batch1127/1133, batch loss:4.03442834695511e-11, Training time:195691.995398283
batch reward last col mean 1.204780687658058e-06 first col mean 3.4112342746084323e-06 all mean 1.2301220522203948e-06
rl training, epoch6, iter0, batch1128/1133, batch loss:1.189234577481102e-08, Training time:195718.12459778786
batch reward last col mean 7.526746685471153e-06 first col mean 1.640828713789233e-06 all mean 7.712875230936334e-06
rl training, epoch6, iter0, batch1129/1133, batch loss:1.662460249463038e-07, Training time:195744.17951083183
batch reward last col mean 3.4070828860421898e-06 first col mean 4.2619049054337665e-06 all mean 1.902954318211414e-05
rl training, epoch6, iter0, batch1130/1133, batch loss:1.0398565564173623e-07, Training time:195770.1124742031
batch reward last col mean 9.70090513874311e-06 first col mean 6.905008376634214e-06 all mean 9.68053973338101e-06
rl training, epoch6, iter0, batch1131/1133, batch loss:4.301305267517819e-08, Training time:195796.2533915043
batch reward last col mean 5.41421604793868e-06 first col mean 4.103185347048566e-06 all mean 9.297728865931276e-06
rl training, epoch6, iter0, batch1132/1133, batch loss:1.0606891009956598e-07, Training time:195820.6614024639
rl training, epoch 6, iter 0, loss:8.543666250056692e-06, Training time:195820.66165947914 
rl epoch 6, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.2275543036983272 Time: 169.45777463912964 s
cur_epoch: 1
D Training Loss: 0.22906011437038773 Time: 170.72216844558716 s
cur_epoch: 2
D Training Loss: 0.22761636255646003 Time: 169.60675692558289 s
cur_epoch: 3
D Training Loss: 0.22989174546731433 Time: 170.74446988105774 s
cur_epoch: 4
D Training Loss: 0.2263584648508049 Time: 170.62019038200378 s
rl epoch 7, begin RL for generator...
batch reward last col mean 7.65724980738014e-05 first col mean 4.2922580178128555e-05 all mean 9.046993363881484e-05
rl training, epoch7, iter0, batch0/1133, batch loss:2.910812497702864e-07, Training time:196697.9130795002
batch reward last col mean 6.692115448458935e-07 first col mean 1.6775125004642177e-06 all mean 6.797218929932569e-07
rl training, epoch7, iter0, batch1/1133, batch loss:4.688013532927471e-09, Training time:196724.00566148758
batch reward last col mean 2.1997384180849622e-07 first col mean 3.4034684404105064e-07 all mean 2.5263267389163957e-07
rl training, epoch7, iter0, batch2/1133, batch loss:2.4345025995131664e-10, Training time:196750.08192372322
batch reward last col mean 2.131911514879903e-06 first col mean 6.774310350010637e-06 all mean 2.1787996047351044e-06
rl training, epoch7, iter0, batch3/1133, batch loss:5.8870909924735315e-08, Training time:196776.15418601036
batch reward last col mean 1.0750169394668774e-06 first col mean 1.5449127204192337e-06 all mean 1.0787283599711373e-06
rl training, epoch7, iter0, batch4/1133, batch loss:1.1788658937916807e-08, Training time:196802.18918442726
batch reward last col mean 2.2023059500497766e-06 first col mean 2.977568692585919e-05 all mean 2.4808687157928944e-06
rl training, epoch7, iter0, batch5/1133, batch loss:1.0583462106694697e-08, Training time:196828.1848230362
batch reward last col mean 1.2358162166492548e-05 first col mean 1.9381222955416888e-05 all mean 1.250931109098019e-05
rl training, epoch7, iter0, batch6/1133, batch loss:7.77276198959953e-08, Training time:196854.1112792492
batch reward last col mean 1.7018329572238144e-06 first col mean 7.558968718512915e-06 all mean 1.7755826320353663e-06
rl training, epoch7, iter0, batch7/1133, batch loss:7.728614193069916e-09, Training time:196880.1533279419
batch reward last col mean 1.0016431017945138e-09 first col mean 2.246612666567671e-06 all mean 3.5960374589194544e-07
rl training, epoch7, iter0, batch8/1133, batch loss:5.711886584373882e-13, Training time:196905.96985077858
batch reward last col mean 2.93395476802516e-08 first col mean 2.5685415039333748e-06 all mean 1.1646996256331477e-07
rl training, epoch7, iter0, batch9/1133, batch loss:2.6027716440446547e-11, Training time:196931.92551136017
batch reward last col mean 1.2152417960820117e-09 first col mean 1.0832840189323178e-06 all mean 1.2223678957923312e-08
rl training, epoch7, iter0, batch10/1133, batch loss:1.2976071606107809e-11, Training time:196957.7585606575
batch reward last col mean 0.00011818837083410472 first col mean 3.904242839780636e-05 all mean 0.00011543159780558199
rl training, epoch7, iter0, batch11/1133, batch loss:3.412086243770318e-06, Training time:196983.78571510315
batch reward last col mean 6.765089044513672e-10 first col mean 1.3367318388191052e-05 all mean 4.6926473373787303e-07
rl training, epoch7, iter0, batch12/1133, batch loss:2.650215116806187e-11, Training time:197009.5964267254
batch reward last col mean 3.0685898764204467e-06 first col mean 6.136177034932189e-06 all mean 3.099597279287991e-06
rl training, epoch7, iter0, batch13/1133, batch loss:9.902537456696336e-09, Training time:197035.68572497368
batch reward last col mean 2.6143445097659423e-07 first col mean 2.604173459985759e-06 all mean 2.8509896310424665e-07
rl training, epoch7, iter0, batch14/1133, batch loss:1.5349202464598477e-10, Training time:197061.61092853546
batch reward last col mean 2.6002826416515745e-06 first col mean 4.807310688192956e-06 all mean 2.630826884342241e-06
rl training, epoch7, iter0, batch15/1133, batch loss:1.0828379970462265e-08, Training time:197087.89076805115
batch reward last col mean 8.3168524724897e-06 first col mean 1.119183139053348e-06 all mean 8.28736574476352e-06
rl training, epoch7, iter0, batch16/1133, batch loss:3.046453116439807e-07, Training time:197113.78006577492
batch reward last col mean 1.1931173503398895e-05 first col mean 1.5081488527357578e-05 all mean 1.2213696209073532e-05
rl training, epoch7, iter0, batch17/1133, batch loss:2.5983604245993774e-07, Training time:197139.973177433
batch reward last col mean 8.508694008924067e-06 first col mean 1.3919592447564355e-06 all mean 1.2831214007746894e-05
rl training, epoch7, iter0, batch18/1133, batch loss:3.6050295193490456e-07, Training time:197165.91888403893
batch reward last col mean 7.64329911362438e-07 first col mean 1.2102520940970862e-06 all mean 7.729773301434761e-07
rl training, epoch7, iter0, batch19/1133, batch loss:3.4848093299899574e-09, Training time:197191.94003009796
batch reward last col mean 6.50953688818845e-06 first col mean 7.270128662639763e-06 all mean 6.646108431596076e-06
rl training, epoch7, iter0, batch20/1133, batch loss:1.0698685493082394e-08, Training time:197218.07066488266
batch reward last col mean 6.363795046482323e-10 first col mean 3.076339112340065e-07 all mean 3.893926514564328e-09
rl training, epoch7, iter0, batch21/1133, batch loss:1.1047283557776358e-13, Training time:197244.29639697075
batch reward last col mean 8.261286893684883e-06 first col mean 1.6054467550929985e-06 all mean 8.676975994603708e-06
rl training, epoch7, iter0, batch22/1133, batch loss:1.1215053064006497e-07, Training time:197270.28223347664
batch reward last col mean 5.063290700491052e-06 first col mean 1.8624576114234515e-05 all mean 5.200435680308146e-06
rl training, epoch7, iter0, batch23/1133, batch loss:2.745072080756472e-08, Training time:197296.40622591972
batch reward last col mean 7.210878720798064e-06 first col mean 6.288005806709407e-06 all mean 7.2015564001048915e-06
rl training, epoch7, iter0, batch24/1133, batch loss:3.1325257054959366e-08, Training time:197322.63878965378
batch reward last col mean 4.078897575254814e-07 first col mean 3.286271748947911e-06 all mean 4.439822305357666e-07
rl training, epoch7, iter0, batch25/1133, batch loss:1.0252263482612989e-09, Training time:197348.7647843361
batch reward last col mean 6.088769168854924e-06 first col mean 1.9457665985100903e-06 all mean 6.046921043889597e-06
rl training, epoch7, iter0, batch26/1133, batch loss:2.0283930268760741e-07, Training time:197374.70034003258
batch reward last col mean 6.346956070046872e-05 first col mean 5.763760782429017e-05 all mean 6.341063999570906e-05
rl training, epoch7, iter0, batch27/1133, batch loss:2.6866149482884794e-07, Training time:197401.09589982033
batch reward last col mean 4.741695192933548e-06 first col mean 2.4337665308848955e-05 all mean 4.951036771672079e-06
rl training, epoch7, iter0, batch28/1133, batch loss:5.5604576942869244e-08, Training time:197427.1714258194
batch reward last col mean 8.181733392120805e-06 first col mean 1.5869507478782907e-05 all mean 8.925583642849233e-06
rl training, epoch7, iter0, batch29/1133, batch loss:5.404088909699567e-08, Training time:197453.34558320045
batch reward last col mean 1.1005769010807853e-05 first col mean 7.79794754635077e-06 all mean 1.2800283002434298e-05
rl training, epoch7, iter0, batch30/1133, batch loss:3.521537195183555e-08, Training time:197479.2925877571
batch reward last col mean 4.560300794764771e-07 first col mean 2.168515038647456e-06 all mean 6.262224019337737e-07
rl training, epoch7, iter0, batch31/1133, batch loss:1.3592359238145946e-08, Training time:197505.36109900475
batch reward last col mean 3.050186933251098e-06 first col mean 9.258088539354503e-06 all mean 3.2416280646430096e-06
rl training, epoch7, iter0, batch32/1133, batch loss:4.885874815840907e-08, Training time:197531.38536334038
batch reward last col mean 1.9773287363022973e-07 first col mean 2.823042279942456e-07 all mean 2.769914715372579e-07
rl training, epoch7, iter0, batch33/1133, batch loss:1.288559481338325e-09, Training time:197557.46124505997
batch reward last col mean 1.5194113984762225e-05 first col mean 6.767207310076628e-07 all mean 1.505403452028986e-05
rl training, epoch7, iter0, batch34/1133, batch loss:3.3846274050119973e-07, Training time:197583.43197321892
batch reward last col mean 1.603449959475256e-06 first col mean 2.0550203771563247e-05 all mean 2.291001692356076e-06
rl training, epoch7, iter0, batch35/1133, batch loss:3.3384651487722294e-08, Training time:197609.44413280487
batch reward last col mean 5.8108898883801885e-06 first col mean 2.398872084086179e-06 all mean 7.655443369003478e-06
rl training, epoch7, iter0, batch36/1133, batch loss:4.6701693179329595e-08, Training time:197635.36839032173
batch reward last col mean 2.863466397684533e-05 first col mean 1.552371759316884e-05 all mean 2.852464240277186e-05
rl training, epoch7, iter0, batch37/1133, batch loss:6.510010166493885e-07, Training time:197661.5956697464
batch reward last col mean 1.4423977745536831e-06 first col mean 3.0602552669733996e-06 all mean 1.458158521927544e-06
rl training, epoch7, iter0, batch38/1133, batch loss:1.206422162169929e-08, Training time:197687.5720627308
batch reward last col mean 1.2864281416113954e-05 first col mean 7.967099008965306e-06 all mean 1.3258565559226554e-05
rl training, epoch7, iter0, batch39/1133, batch loss:1.4047580521037162e-07, Training time:197713.5620458126
batch reward last col mean 7.486609092666185e-07 first col mean 3.680152360630018e-07 all mean 7.450733505720564e-07
rl training, epoch7, iter0, batch40/1133, batch loss:3.659149871992895e-09, Training time:197739.61965322495
batch reward last col mean 4.674170213547768e-06 first col mean 7.792259566485882e-06 all mean 4.802861894859234e-06
rl training, epoch7, iter0, batch41/1133, batch loss:1.893990297929804e-09, Training time:197765.7319767475
batch reward last col mean 3.502576646496891e-06 first col mean 4.736579739983426e-06 all mean 3.5150419535057154e-06
rl training, epoch7, iter0, batch42/1133, batch loss:2.2793464893311466e-09, Training time:197791.68844795227
batch reward last col mean 1.0072822078655008e-06 first col mean 1.209846686833771e-05 all mean 1.1193233149242587e-06
rl training, epoch7, iter0, batch43/1133, batch loss:3.2094655821879314e-09, Training time:197817.84998822212
batch reward last col mean 1.6762156519689597e-05 first col mean 1.401795316269272e-06 all mean 1.660700399952475e-05
rl training, epoch7, iter0, batch44/1133, batch loss:4.850685968449397e-07, Training time:197843.97357678413
batch reward last col mean 2.6499266823520884e-05 first col mean 3.6276624086895026e-06 all mean 4.49435283371713e-05
rl training, epoch7, iter0, batch45/1133, batch loss:3.5768943007497e-07, Training time:197870.1319129467
batch reward last col mean 1.1815164725703653e-05 first col mean 1.26370665043396e-07 all mean 1.1697177797032055e-05
rl training, epoch7, iter0, batch46/1133, batch loss:4.14779570689916e-08, Training time:197896.24686336517
batch reward last col mean 1.813058406696655e-05 first col mean 2.251483920190367e-06 all mean 1.7970340195461176e-05
rl training, epoch7, iter0, batch47/1133, batch loss:2.3090966294603277e-07, Training time:197922.86349725723
batch reward last col mean 1.0477554496901575e-05 first col mean 1.6813530237413943e-05 all mean 1.2734100891975686e-05
rl training, epoch7, iter0, batch48/1133, batch loss:1.8220147524061758e-07, Training time:197949.05729842186
batch reward last col mean 1.243929318661685e-06 first col mean 1.9507961042108946e-06 all mean 1.3858461898053065e-06
rl training, epoch7, iter0, batch49/1133, batch loss:7.737056328949166e-09, Training time:197974.85179185867
batch reward last col mean 3.483379487079219e-06 first col mean 8.437554015472415e-07 all mean 3.4567169677757192e-06
rl training, epoch7, iter0, batch50/1133, batch loss:9.96422144794451e-08, Training time:198000.90021038055
batch reward last col mean 8.070800504356157e-06 first col mean 5.453626172879922e-08 all mean 7.989830919541419e-06
rl training, epoch7, iter0, batch51/1133, batch loss:1.4031166983841104e-07, Training time:198026.834815979
batch reward last col mean 2.7989919999527046e-06 first col mean 2.6379073005955433e-06 all mean 8.647152753837872e-06
rl training, epoch7, iter0, batch52/1133, batch loss:1.7559445453230182e-08, Training time:198052.74760627747
batch reward last col mean 3.154879948397138e-07 first col mean 6.350767307594651e-07 all mean 7.956211334203545e-07
rl training, epoch7, iter0, batch53/1133, batch loss:1.0150941420761228e-08, Training time:198078.78138303757
batch reward last col mean 1.4482841379503952e-06 first col mean 3.5569471492635785e-06 all mean 3.5657249100040644e-06
rl training, epoch7, iter0, batch54/1133, batch loss:9.942032974663562e-09, Training time:198105.06250858307
batch reward last col mean 0.00010121606464963406 first col mean 1.0722528713813517e-06 all mean 9.954500274034217e-05
rl training, epoch7, iter0, batch55/1133, batch loss:1.0211831977358088e-05, Training time:198131.24560403824
batch reward last col mean 9.190409400616772e-06 first col mean 4.2544429561530706e-06 all mean 9.45155079534743e-06
rl training, epoch7, iter0, batch56/1133, batch loss:5.460914209720613e-08, Training time:198157.3841290474
batch reward last col mean 4.028896000818349e-06 first col mean 3.389933681319235e-06 all mean 4.108051598450402e-06
rl training, epoch7, iter0, batch57/1133, batch loss:2.0938857758778795e-08, Training time:198183.5022933483
batch reward last col mean 5.418200998974498e-06 first col mean 5.587306532106595e-06 all mean 6.269293862715131e-06
rl training, epoch7, iter0, batch58/1133, batch loss:3.988707586444207e-09, Training time:198209.47331643105
batch reward last col mean 4.476089827676333e-07 first col mean 1.3538110579247586e-06 all mean 2.5542033199599246e-06
rl training, epoch7, iter0, batch59/1133, batch loss:1.5395591468347902e-09, Training time:198235.62906837463
batch reward last col mean 2.188645176204318e-08 first col mean 7.895931048551574e-06 all mean 2.0273080735933036e-05
rl training, epoch7, iter0, batch60/1133, batch loss:1.497910684378212e-09, Training time:198261.51396870613
batch reward last col mean 7.376447683782317e-06 first col mean 5.419244189397432e-06 all mean 7.660320989089087e-06
rl training, epoch7, iter0, batch61/1133, batch loss:1.186455591550839e-07, Training time:198287.7842924595
batch reward last col mean 2.637186980791739e-06 first col mean 1.6556263062739163e-06 all mean 2.6708223686000565e-06
rl training, epoch7, iter0, batch62/1133, batch loss:3.368128531633374e-08, Training time:198313.72898483276
batch reward last col mean 3.218936626581126e-06 first col mean 5.2464606596913654e-06 all mean 4.090035417902982e-06
rl training, epoch7, iter0, batch63/1133, batch loss:6.767738813806545e-09, Training time:198339.89823198318
batch reward last col mean 6.1809614635421894e-06 first col mean 5.373688964027679e-06 all mean 7.253754120029043e-06
rl training, epoch7, iter0, batch64/1133, batch loss:1.4092023548073485e-07, Training time:198365.95350813866
batch reward last col mean 6.475180271081626e-05 first col mean 2.8140661015640944e-05 all mean 7.439113687723875e-05
rl training, epoch7, iter0, batch65/1133, batch loss:1.6449139366159216e-06, Training time:198392.22145819664
batch reward last col mean 5.79511106479913e-06 first col mean 4.036813152197283e-06 all mean 5.799388418381568e-06
rl training, epoch7, iter0, batch66/1133, batch loss:5.497066979387455e-08, Training time:198418.32287025452
batch reward last col mean 4.385782176541397e-06 first col mean 6.738422598573379e-06 all mean 4.40954545410932e-06
rl training, epoch7, iter0, batch67/1133, batch loss:2.4055713865323014e-08, Training time:198444.56488728523
batch reward last col mean 3.7406437058962183e-07 first col mean 3.600654849833518e-07 all mean 3.7716131373599637e-07
rl training, epoch7, iter0, batch68/1133, batch loss:8.401615403386131e-09, Training time:198470.50067567825
batch reward last col mean 5.803441354146344e-07 first col mean 0.0003671979939099401 all mean 4.283556336304173e-06
rl training, epoch7, iter0, batch69/1133, batch loss:2.5486533559160307e-05, Training time:198496.65037822723
batch reward last col mean 2.358486426601303e-06 first col mean 2.1054390799690736e-06 all mean 2.415319158899365e-06
rl training, epoch7, iter0, batch70/1133, batch loss:7.74148656290663e-09, Training time:198522.88041830063
batch reward last col mean 8.834841196403431e-07 first col mean 1.5694715784775326e-06 all mean 1.701634232631477e-06
rl training, epoch7, iter0, batch71/1133, batch loss:2.9126898670739365e-09, Training time:198549.03788089752
batch reward last col mean 9.472869351156987e-06 first col mean 1.0067391485790722e-05 all mean 9.478875654167496e-06
rl training, epoch7, iter0, batch72/1133, batch loss:1.62327911112925e-08, Training time:198575.1517572403
batch reward last col mean 9.061634045792744e-06 first col mean 2.9616560368594946e-06 all mean 8.998928024084307e-06
rl training, epoch7, iter0, batch73/1133, batch loss:1.1252954834617412e-07, Training time:198601.41898179054
batch reward last col mean 2.4371476683882065e-05 first col mean 1.400435849063797e-05 all mean 3.326672231196426e-05
rl training, epoch7, iter0, batch74/1133, batch loss:2.986074605360045e-07, Training time:198627.42988824844
batch reward last col mean 1.7435718291380908e-06 first col mean 3.3860717394418316e-06 all mean 1.7601233821551432e-06
rl training, epoch7, iter0, batch75/1133, batch loss:2.0384012699992127e-08, Training time:198653.9154305458
batch reward last col mean 4.4643256842391565e-06 first col mean 2.955601303256117e-06 all mean 4.648002231988357e-06
rl training, epoch7, iter0, batch76/1133, batch loss:1.1252722487142819e-07, Training time:198679.8779745102
batch reward last col mean 1.739917934173718e-06 first col mean 1.7454138969696942e-06 all mean 3.220768576284172e-06
rl training, epoch7, iter0, batch77/1133, batch loss:1.1596376303657507e-08, Training time:198706.01842284203
batch reward last col mean 6.977619705139659e-06 first col mean 7.87521457823459e-06 all mean 9.000597856356762e-06
rl training, epoch7, iter0, batch78/1133, batch loss:6.672613572789032e-09, Training time:198732.5288684368
batch reward last col mean 1.7421766251857207e-09 first col mean 1.2160137430328177e-06 all mean 5.286558007355779e-06
rl training, epoch7, iter0, batch79/1133, batch loss:1.3859507985714004e-10, Training time:198759.20140457153
batch reward last col mean 1.4006581068315427e-06 first col mean 1.7207690916620777e-06 all mean 1.5854990124353208e-05
rl training, epoch7, iter0, batch80/1133, batch loss:1.3443490765041588e-08, Training time:198785.72557783127
batch reward last col mean 9.888065505947452e-06 first col mean 6.586947620235151e-06 all mean 2.7283920644549653e-05
rl training, epoch7, iter0, batch81/1133, batch loss:6.542965991229721e-08, Training time:198812.17820167542
batch reward last col mean 4.516984517977107e-06 first col mean 8.110741305245028e-07 all mean 1.5853787772357464e-05
rl training, epoch7, iter0, batch82/1133, batch loss:1.4606037268549699e-08, Training time:198838.0430278778
batch reward last col mean 1.9728644474525936e-05 first col mean 3.9226993976626545e-05 all mean 1.993353907892015e-05
rl training, epoch7, iter0, batch83/1133, batch loss:9.068777728771238e-08, Training time:198864.92410993576
batch reward last col mean 4.3530658331292216e-06 first col mean 1.7123289580922574e-05 all mean 4.482055373955518e-06
rl training, epoch7, iter0, batch84/1133, batch loss:9.79803438383442e-09, Training time:198891.49695920944
batch reward last col mean 5.241753910922853e-07 first col mean 1.3022101484239101e-05 all mean 4.611734311765758e-06
rl training, epoch7, iter0, batch85/1133, batch loss:1.7418061659668638e-08, Training time:198918.6929423809
batch reward last col mean 2.5512290449114516e-06 first col mean 7.62830723033403e-07 all mean 2.5331896722491365e-06
rl training, epoch7, iter0, batch86/1133, batch loss:5.738672115285226e-08, Training time:198945.37056446075
batch reward last col mean 8.441430168204533e-07 first col mean 1.0127201676368713e-05 all mean 1.655731352911971e-06
rl training, epoch7, iter0, batch87/1133, batch loss:3.469915688114611e-09, Training time:198972.1490266323
batch reward last col mean 1.9094625258730957e-06 first col mean 9.552162509862683e-07 all mean 1.8998289306182414e-06
rl training, epoch7, iter0, batch88/1133, batch loss:5.134357383695942e-09, Training time:198998.09766674042
batch reward last col mean 2.6979247195413336e-05 first col mean 5.8814352087210864e-05 all mean 3.020434633072e-05
rl training, epoch7, iter0, batch89/1133, batch loss:2.5477990561739716e-07, Training time:199025.27396130562
batch reward last col mean 1.173871260107262e-05 first col mean 1.906714533106424e-05 all mean 1.213107316289097e-05
rl training, epoch7, iter0, batch90/1133, batch loss:1.614194502508326e-07, Training time:199052.2924849987
batch reward last col mean 9.491115633863956e-06 first col mean 6.297136678767856e-06 all mean 9.911478628055193e-06
rl training, epoch7, iter0, batch91/1133, batch loss:1.8743243401786458e-07, Training time:199079.53029489517
batch reward last col mean 0.007503597531467676 first col mean 6.119889803812839e-06 all mean 0.0074089290574193
rl training, epoch7, iter0, batch92/1133, batch loss:0.0008206884958781302, Training time:199106.86191630363
batch reward last col mean 2.5596680643502623e-05 first col mean 1.6335470718331635e-05 all mean 2.6804706067196093e-05
rl training, epoch7, iter0, batch93/1133, batch loss:4.3245572101113794e-07, Training time:199134.14897871017
batch reward last col mean 1.577395960339345e-05 first col mean 1.4621495211031288e-05 all mean 1.5763460396556184e-05
rl training, epoch7, iter0, batch94/1133, batch loss:2.447713143283181e-08, Training time:199161.3828406334
batch reward last col mean 1.4651007404609118e-05 first col mean 1.3118531569489278e-05 all mean 1.4657608517154586e-05
rl training, epoch7, iter0, batch95/1133, batch loss:1.6001251879060874e-08, Training time:199188.5097398758
batch reward last col mean 1.1503360838105436e-05 first col mean 5.5641539802309126e-06 all mean 1.145838359661866e-05
rl training, epoch7, iter0, batch96/1133, batch loss:2.2476493199974357e-07, Training time:199215.39230656624
batch reward last col mean 4.648944923246745e-06 first col mean 1.8313924101676093e-06 all mean 4.620638719643466e-06
rl training, epoch7, iter0, batch97/1133, batch loss:4.934126351940904e-08, Training time:199242.45667004585
batch reward last col mean 2.3358340968115954e-06 first col mean 6.630983989452943e-05 all mean 3.0026290005480405e-06
rl training, epoch7, iter0, batch98/1133, batch loss:4.91329963381304e-08, Training time:199268.29332470894
batch reward last col mean 6.619530381613004e-07 first col mean 6.775761676180991e-07 all mean 6.632133704442822e-07
rl training, epoch7, iter0, batch99/1133, batch loss:3.060372788521448e-10, Training time:199294.48717093468
batch reward last col mean 3.3409756724722683e-05 first col mean 4.569461907522054e-06 all mean 2.8734499210258946e-05
rl training, epoch7, iter0, batch100/1133, batch loss:1.881871753539599e-06, Training time:199320.46007442474
batch reward last col mean 2.5279607143602334e-05 first col mean 2.4329337975359522e-05 all mean 2.5290672056144103e-05
rl training, epoch7, iter0, batch101/1133, batch loss:1.8638742460552749e-07, Training time:199346.88312101364
batch reward last col mean 1.0101075531565584e-05 first col mean 1.314292057941202e-05 all mean 1.0139659025298897e-05
rl training, epoch7, iter0, batch102/1133, batch loss:3.683271643240005e-07, Training time:199373.06607174873
batch reward last col mean 2.890230007324135e-06 first col mean 0.0002527617325540632 all mean 5.421422883955529e-06
rl training, epoch7, iter0, batch103/1133, batch loss:3.763548761526181e-08, Training time:199399.10949993134
batch reward last col mean 5.100776252220385e-05 first col mean 3.3967731724260375e-05 all mean 5.083566065877676e-05
rl training, epoch7, iter0, batch104/1133, batch loss:3.9358013737000874e-07, Training time:199424.7769100666
batch reward last col mean 9.198234693030827e-06 first col mean 9.442206646781415e-05 all mean 1.2337994121480733e-05
rl training, epoch7, iter0, batch105/1133, batch loss:9.818116808446575e-08, Training time:199450.79440689087
batch reward last col mean 3.116772495559417e-05 first col mean 2.7520394723978825e-05 all mean 3.1580639188177884e-05
rl training, epoch7, iter0, batch106/1133, batch loss:5.547982482312364e-07, Training time:199476.87078380585
batch reward last col mean 7.2132570494432e-06 first col mean 3.1442009458260145e-06 all mean 7.172159712354187e-06
rl training, epoch7, iter0, batch107/1133, batch loss:1.2580410668761033e-07, Training time:199502.86986994743
batch reward last col mean 2.74753929261351e-05 first col mean 1.4913963241269812e-05 all mean 2.734856025199406e-05
rl training, epoch7, iter0, batch108/1133, batch loss:1.4478247294391622e-06, Training time:199528.88177919388
batch reward last col mean 4.695136158261448e-05 first col mean 3.833112714346498e-05 all mean 4.686431202571839e-05
rl training, epoch7, iter0, batch109/1133, batch loss:4.5647553292837983e-08, Training time:199555.04789733887
batch reward last col mean 5.182479435461573e-05 first col mean 4.2315205064369366e-06 all mean 6.383404252119362e-05
rl training, epoch7, iter0, batch110/1133, batch loss:2.5004133021866437e-06, Training time:199581.13369464874
batch reward last col mean 6.517357633128995e-06 first col mean 2.4959392703749472e-06 all mean 6.507644684461411e-06
rl training, epoch7, iter0, batch111/1133, batch loss:9.725973626473206e-08, Training time:199607.51148867607
batch reward last col mean 1.5530051314271986e-05 first col mean 1.0120865226781461e-05 all mean 1.5441153664141893e-05
rl training, epoch7, iter0, batch112/1133, batch loss:1.4313862095605145e-07, Training time:199633.7092437744
batch reward last col mean 1.7531147022964433e-06 first col mean 4.120567155041499e-06 all mean 1.782664867278072e-06
rl training, epoch7, iter0, batch113/1133, batch loss:1.2230754187214643e-08, Training time:199659.7298936844
batch reward last col mean 9.06443801795831e-07 first col mean 1.2546972811833257e-06 all mean 2.006675231314148e-06
rl training, epoch7, iter0, batch114/1133, batch loss:1.328858001414801e-08, Training time:199685.8849902153
batch reward last col mean 2.5946360437956173e-07 first col mean 8.558191098018142e-07 all mean 2.8690490694316395e-07
rl training, epoch7, iter0, batch115/1133, batch loss:2.0428865710186983e-08, Training time:199711.9801876545
batch reward last col mean 8.947167771111708e-07 first col mean 2.5776521397347096e-06 all mean 9.462372076995962e-07
rl training, epoch7, iter0, batch116/1133, batch loss:9.357124852726884e-09, Training time:199737.88241696358
batch reward last col mean 3.4923082239401992e-06 first col mean 0.00016759084246587008 all mean 5.153461643203627e-06
rl training, epoch7, iter0, batch117/1133, batch loss:1.2608814436987359e-08, Training time:199764.29521512985
batch reward last col mean 9.660692739998922e-06 first col mean 9.026767656905577e-06 all mean 9.654817404225469e-06
rl training, epoch7, iter0, batch118/1133, batch loss:1.6220070619965554e-08, Training time:199791.21761631966
batch reward last col mean 8.777317270869389e-05 first col mean 2.2849628294352442e-05 all mean 8.714793511899188e-05
rl training, epoch7, iter0, batch119/1133, batch loss:9.825564575294266e-07, Training time:199818.44394731522
batch reward last col mean 1.5174713553278707e-05 first col mean 7.6682790677296e-06 all mean 1.7112794012064114e-05
rl training, epoch7, iter0, batch120/1133, batch loss:6.387305262478549e-08, Training time:199845.0769777298
batch reward last col mean 1.5060668374644592e-05 first col mean 3.962554274039576e-06 all mean 1.5014486052677967e-05
rl training, epoch7, iter0, batch121/1133, batch loss:1.6380940337512584e-07, Training time:199871.60258221626
batch reward last col mean 0.00045758692431263626 first col mean 9.626791324990336e-06 all mean 0.00044886537943966687
rl training, epoch7, iter0, batch122/1133, batch loss:1.8724296751315705e-05, Training time:199898.5438055992
batch reward last col mean 5.938190497545293e-06 first col mean 6.946772828086978e-06 all mean 5.949727437837282e-06
rl training, epoch7, iter0, batch123/1133, batch loss:5.59764217200609e-08, Training time:199924.87884902954
batch reward last col mean 8.985708745967713e-07 first col mean 5.669248253070691e-07 all mean 1.7371570720570162e-05
rl training, epoch7, iter0, batch124/1133, batch loss:1.5388408769467787e-07, Training time:199952.02001976967
batch reward last col mean 5.519863043446094e-05 first col mean 1.229165900440421e-05 all mean 5.4765223467256874e-05
rl training, epoch7, iter0, batch125/1133, batch loss:2.5159448568956577e-07, Training time:199979.19115304947
batch reward last col mean 8.09233188192593e-06 first col mean 4.740594249597052e-06 all mean 2.0167246475466527e-05
rl training, epoch7, iter0, batch126/1133, batch loss:5.782442613622152e-08, Training time:200006.26764154434
batch reward last col mean 3.5216093237977475e-05 first col mean 3.849297354463488e-05 all mean 4.5255324948811904e-05
rl training, epoch7, iter0, batch127/1133, batch loss:2.583803926370365e-08, Training time:200033.24099612236
batch reward last col mean 7.561359234387055e-05 first col mean 1.0920113027168554e-06 all mean 7.738544081803411e-05
rl training, epoch7, iter0, batch128/1133, batch loss:3.408514203329105e-06, Training time:200060.12532186508
batch reward last col mean 5.9673246141755953e-05 first col mean 5.5782278650440276e-05 all mean 5.96353602304589e-05
rl training, epoch7, iter0, batch129/1133, batch loss:1.565299641015372e-07, Training time:200086.8609726429
batch reward last col mean 7.0446626523335e-06 first col mean 1.144745147030335e-05 all mean 7.1919116635399405e-06
rl training, epoch7, iter0, batch130/1133, batch loss:7.863768303195684e-08, Training time:200113.64162230492
batch reward last col mean 4.641206032829359e-06 first col mean 5.7346918765688315e-05 all mean 5.196223355596885e-06
rl training, epoch7, iter0, batch131/1133, batch loss:1.5963189881063045e-08, Training time:200141.6751844883
batch reward last col mean 6.697924163745483e-06 first col mean 1.1685375284287147e-05 all mean 6.7533214860304724e-06
rl training, epoch7, iter0, batch132/1133, batch loss:2.8014395070385945e-07, Training time:200168.27984309196
batch reward last col mean 1.1645171493768203e-09 first col mean 2.8643662517424673e-05 all mean 3.472220441835816e-06
rl training, epoch7, iter0, batch133/1133, batch loss:5.0601765833047097e-11, Training time:200194.99248623848
batch reward last col mean 8.830038922269523e-08 first col mean 5.218088972469559e-06 all mean 1.4011652638146188e-07
rl training, epoch7, iter0, batch134/1133, batch loss:1.2322726172797616e-09, Training time:200222.15209460258
batch reward last col mean 8.426857675658539e-06 first col mean 6.1690143411397e-06 all mean 8.625103873782791e-06
rl training, epoch7, iter0, batch135/1133, batch loss:4.2686661316793106e-08, Training time:200248.77603292465
batch reward last col mean 1.256943323824089e-05 first col mean 7.406933491438394e-06 all mean 1.2535337191366125e-05
rl training, epoch7, iter0, batch136/1133, batch loss:2.032530375117858e-07, Training time:200276.2825229168
batch reward last col mean 2.088058636218193e-06 first col mean 3.816416665358702e-06 all mean 3.1095669328351505e-06
rl training, epoch7, iter0, batch137/1133, batch loss:3.0659996763660047e-09, Training time:200303.25705981255
batch reward last col mean 7.566818112536566e-06 first col mean 1.3087867955619004e-05 all mean 7.622582870681072e-06
rl training, epoch7, iter0, batch138/1133, batch loss:5.172354633486975e-08, Training time:200330.40798163414
batch reward last col mean 6.633663815591717e-06 first col mean 6.079730155761354e-06 all mean 9.579262041370384e-06
rl training, epoch7, iter0, batch139/1133, batch loss:4.012386156659886e-08, Training time:200357.00893592834
batch reward last col mean 4.927448753733188e-05 first col mean 7.662011194042861e-05 all mean 5.11572761752177e-05
rl training, epoch7, iter0, batch140/1133, batch loss:1.3242307659311336e-06, Training time:200383.60241365433
batch reward last col mean 3.0783437523496104e-06 first col mean 5.7962824939750135e-06 all mean 5.275352123135235e-06
rl training, epoch7, iter0, batch141/1133, batch loss:4.3028283158719205e-08, Training time:200410.35685896873
batch reward last col mean 8.688499292475171e-06 first col mean 3.304142228444107e-05 all mean 1.2886631338915322e-05
rl training, epoch7, iter0, batch142/1133, batch loss:1.2572982655001397e-07, Training time:200436.83507466316
batch reward last col mean 1.0279043635819107e-05 first col mean 8.73397493705852e-06 all mean 1.0405144166725222e-05
rl training, epoch7, iter0, batch143/1133, batch loss:1.0021462060194608e-07, Training time:200463.7233171463
batch reward last col mean 1.501256429037312e-05 first col mean 1.8644910596776754e-05 all mean 1.6618872905382887e-05
rl training, epoch7, iter0, batch144/1133, batch loss:3.231120331292914e-07, Training time:200490.13602256775
batch reward last col mean 5.889238764211768e-06 first col mean 6.245055374165531e-06 all mean 5.8932951105816755e-06
rl training, epoch7, iter0, batch145/1133, batch loss:3.300116091509153e-08, Training time:200517.08676719666
batch reward last col mean 4.599883141054306e-06 first col mean 2.8573449526447803e-06 all mean 4.832188551517902e-06
rl training, epoch7, iter0, batch146/1133, batch loss:5.617604514895902e-08, Training time:200544.11665940285
batch reward last col mean 2.0185334506095387e-06 first col mean 1.3747070397585048e-06 all mean 2.046195049842936e-06
rl training, epoch7, iter0, batch147/1133, batch loss:2.027086232203601e-08, Training time:200570.167979002
batch reward last col mean 5.529699592443649e-06 first col mean 3.247717904741876e-05 all mean 5.801904535474023e-06
rl training, epoch7, iter0, batch148/1133, batch loss:1.2774063584686246e-08, Training time:200596.39600157738
batch reward last col mean 1.5839336811040994e-06 first col mean 2.3201719159260392e-06 all mean 1.7275408481509658e-06
rl training, epoch7, iter0, batch149/1133, batch loss:7.449267869219511e-09, Training time:200623.17615938187
batch reward last col mean 1.7463029507780448e-05 first col mean 2.2465178517450113e-06 all mean 1.7309634131379426e-05
rl training, epoch7, iter0, batch150/1133, batch loss:5.504414843926497e-07, Training time:200649.83311223984
batch reward last col mean 1.901505925161473e-06 first col mean 9.969838720280677e-05 all mean 4.9589307309361175e-06
rl training, epoch7, iter0, batch151/1133, batch loss:1.7625756854044994e-08, Training time:200677.13083910942
batch reward last col mean 9.73327496467391e-06 first col mean 1.0857510460482445e-05 all mean 9.82557685347274e-06
rl training, epoch7, iter0, batch152/1133, batch loss:4.86370623775656e-08, Training time:200703.28478646278
batch reward last col mean 3.5428085993771674e-06 first col mean 7.576672942377627e-06 all mean 3.5835553262586473e-06
rl training, epoch7, iter0, batch153/1133, batch loss:5.146285175783305e-09, Training time:200729.53390479088
batch reward last col mean 4.447136598173529e-05 first col mean 2.3391885406454094e-06 all mean 5.865091225132346e-05
rl training, epoch7, iter0, batch154/1133, batch loss:3.2411404049526027e-07, Training time:200755.79772663116
batch reward last col mean 6.110091135269613e-07 first col mean 2.083960907839355e-06 all mean 1.646041255298769e-06
rl training, epoch7, iter0, batch155/1133, batch loss:5.568671301858785e-09, Training time:200781.84121251106
batch reward last col mean 1.42217925258592e-06 first col mean 4.965665993950097e-06 all mean 1.4579884464183124e-06
rl training, epoch7, iter0, batch156/1133, batch loss:7.428437420742284e-09, Training time:200807.82560563087
batch reward last col mean 4.6825041977172077e-07 first col mean 9.399058399139903e-06 all mean 5.610590392279846e-07
rl training, epoch7, iter0, batch157/1133, batch loss:6.649778505618542e-09, Training time:200834.1215481758
batch reward last col mean 3.4510480872995686e-06 first col mean 7.156192623369861e-06 all mean 3.499855665722862e-06
rl training, epoch7, iter0, batch158/1133, batch loss:2.8413385422254578e-08, Training time:200860.4354736805
batch reward last col mean 1.2368533134576865e-05 first col mean 8.240547231253004e-07 all mean 1.2302864888624754e-05
rl training, epoch7, iter0, batch159/1133, batch loss:3.7863566149098915e-07, Training time:200886.84351301193
batch reward last col mean 1.420637454430107e-05 first col mean 1.5271369193214923e-05 all mean 1.4217133866623044e-05
rl training, epoch7, iter0, batch160/1133, batch loss:7.025845860653135e-08, Training time:200913.01189541817
batch reward last col mean 1.615778018049241e-07 first col mean 1.3266988389659673e-05 all mean 8.592453468736494e-07
rl training, epoch7, iter0, batch161/1133, batch loss:2.017634948003888e-09, Training time:200939.28821349144
batch reward last col mean 3.1775755360285984e-08 first col mean 3.348477912368253e-05 all mean 4.454284692201327e-07
rl training, epoch7, iter0, batch162/1133, batch loss:2.3510415836369702e-11, Training time:200965.3089683056
batch reward last col mean 1.0576413842500187e-06 first col mean 5.937462447036523e-06 all mean 3.4882855288742576e-06
rl training, epoch7, iter0, batch163/1133, batch loss:1.636053514886271e-09, Training time:200991.55305099487
batch reward last col mean 1.1627373623923631e-06 first col mean 3.1170296210802917e-07 all mean 1.3013032003073022e-06
rl training, epoch7, iter0, batch164/1133, batch loss:5.5876618887396035e-09, Training time:201017.8919045925
batch reward last col mean 5.278052412904799e-07 first col mean 1.3308395864441991e-05 all mean 6.646802148679853e-07
rl training, epoch7, iter0, batch165/1133, batch loss:6.9321521856124946e-09, Training time:201044.02899551392
batch reward last col mean 4.38789174950216e-06 first col mean 9.36503492994234e-05 all mean 5.289531600283226e-06
rl training, epoch7, iter0, batch166/1133, batch loss:2.8528111428727243e-08, Training time:201070.09888863564
batch reward last col mean 5.446788691187976e-07 first col mean 4.6948142085057043e-07 all mean 6.377650834110682e-07
rl training, epoch7, iter0, batch167/1133, batch loss:2.544849664332105e-09, Training time:201096.5193321705
batch reward last col mean 5.435589628177695e-06 first col mean 7.261714927153662e-06 all mean 5.456957751448499e-06
rl training, epoch7, iter0, batch168/1133, batch loss:1.7459804269037704e-08, Training time:201122.60776114464
batch reward last col mean 1.7222583892362309e-06 first col mean 1.300540816373541e-06 all mean 6.0986999415035825e-06
rl training, epoch7, iter0, batch169/1133, batch loss:8.393495676273233e-09, Training time:201148.7006471157
batch reward last col mean 2.860115955627407e-06 first col mean 2.13825569517212e-06 all mean 2.8755530365742743e-06
rl training, epoch7, iter0, batch170/1133, batch loss:2.975698087936962e-08, Training time:201175.01388382912
batch reward last col mean 4.180658834229689e-06 first col mean 3.245130983486888e-06 all mean 4.171235104877269e-06
rl training, epoch7, iter0, batch171/1133, batch loss:8.187289068928294e-09, Training time:201201.59067821503
batch reward last col mean 6.452601155615412e-06 first col mean 3.319215102237649e-05 all mean 6.845318694104208e-06
rl training, epoch7, iter0, batch172/1133, batch loss:2.1214271228586767e-08, Training time:201228.25663542747
batch reward last col mean 9.061066634785675e-07 first col mean 4.783012627740391e-06 all mean 1.3669613281308557e-06
rl training, epoch7, iter0, batch173/1133, batch loss:7.813276248214152e-09, Training time:201254.50889706612
batch reward last col mean 3.871779426845023e-06 first col mean 9.808124559640419e-06 all mean 3.93168465961935e-06
rl training, epoch7, iter0, batch174/1133, batch loss:2.1193478971781587e-07, Training time:201280.45864629745
batch reward last col mean 1.1299178368062712e-05 first col mean 1.4119616480456898e-06 all mean 1.1202923815289978e-05
rl training, epoch7, iter0, batch175/1133, batch loss:8.73417747015992e-08, Training time:201306.50077319145
batch reward last col mean 8.115213859127834e-06 first col mean 3.490883500489872e-06 all mean 8.22667425381951e-06
rl training, epoch7, iter0, batch176/1133, batch loss:4.654301335449418e-07, Training time:201332.5549197197
batch reward last col mean 5.8619647461455315e-05 first col mean 7.5159723564866e-06 all mean 5.751465505454689e-05
rl training, epoch7, iter0, batch177/1133, batch loss:2.918493692050106e-06, Training time:201358.7616429329
batch reward last col mean 7.471736807929119e-06 first col mean 7.945662218844518e-06 all mean 7.534391443186905e-06
rl training, epoch7, iter0, batch178/1133, batch loss:4.173305612198419e-08, Training time:201385.055457592
batch reward last col mean 4.819358764507342e-06 first col mean 3.6450398965826025e-06 all mean 4.807872755918652e-06
rl training, epoch7, iter0, batch179/1133, batch loss:5.9318530531982105e-08, Training time:201411.21447753906
batch reward last col mean 5.792354932054877e-05 first col mean 0.00024781381944194436 all mean 5.984175732010044e-05
rl training, epoch7, iter0, batch180/1133, batch loss:1.2174712082924088e-06, Training time:201437.63406682014
batch reward last col mean 6.6629772845772095e-06 first col mean 1.0613457561703399e-05 all mean 6.702916834910866e-06
rl training, epoch7, iter0, batch181/1133, batch loss:7.875161855963597e-09, Training time:201463.8955974579
batch reward last col mean 0.0020201834850013256 first col mean 7.3786914072115906e-06 all mean 0.0019977004267275333
rl training, epoch7, iter0, batch182/1133, batch loss:0.00022200090461410582, Training time:201489.9269940853
batch reward last col mean 6.330245923891198e-06 first col mean 0.002330346731469035 all mean 2.994813257828355e-05
rl training, epoch7, iter0, batch183/1133, batch loss:4.702514644350231e-08, Training time:201516.43818688393
batch reward last col mean 2.3984691779332934e-06 first col mean 2.24875384446932e-06 all mean 2.9917566735093715e-06
rl training, epoch7, iter0, batch184/1133, batch loss:5.518525014736042e-08, Training time:201542.22579169273
batch reward last col mean 5.819959369546268e-06 first col mean 3.6122951314609963e-06 all mean 6.251279501157114e-06
rl training, epoch7, iter0, batch185/1133, batch loss:2.0438524472865538e-07, Training time:201568.59856390953
batch reward last col mean 3.7196348330326146e-06 first col mean 4.726467182081251e-07 all mean 3.89343085771543e-06
rl training, epoch7, iter0, batch186/1133, batch loss:4.884844884145423e-08, Training time:201594.8088567257
batch reward last col mean 5.062215677753557e-07 first col mean 1.4276103684096597e-05 all mean 8.006862231013656e-07
rl training, epoch7, iter0, batch187/1133, batch loss:5.727090801599388e-09, Training time:201621.1814160347
batch reward last col mean 1.5852645447012037e-05 first col mean 1.173817327071447e-05 all mean 1.581108881509863e-05
rl training, epoch7, iter0, batch188/1133, batch loss:9.201047390661188e-08, Training time:201647.44452309608
batch reward last col mean 1.159611110779224e-05 first col mean 7.578931899843155e-07 all mean 1.1486636140034534e-05
rl training, epoch7, iter0, batch189/1133, batch loss:3.165552584505349e-07, Training time:201673.5919327736
batch reward last col mean 4.78626749345068e-10 first col mean 3.4980496366188163e-07 all mean 8.914206262033986e-09
rl training, epoch7, iter0, batch190/1133, batch loss:4.525853216502673e-12, Training time:201699.9469616413
batch reward last col mean 4.228994839650113e-06 first col mean 4.529761099547613e-06 all mean 4.359125341579784e-06
rl training, epoch7, iter0, batch191/1133, batch loss:6.085907333641671e-09, Training time:201726.06184124947
batch reward last col mean 1.3841150803273194e-06 first col mean 1.3393662356975256e-06 all mean 1.8309523511561565e-05
rl training, epoch7, iter0, batch192/1133, batch loss:3.0258732408583455e-08, Training time:201752.39922642708
batch reward last col mean 2.094179940570484e-09 first col mean 6.153036906653142e-07 all mean 2.051962511018246e-08
rl training, epoch7, iter0, batch193/1133, batch loss:1.103899957555221e-12, Training time:201778.8013484478
batch reward last col mean 0.00010420418402645737 first col mean 9.585799125488847e-05 all mean 0.00010104791726917028
rl training, epoch7, iter0, batch194/1133, batch loss:5.819396392325871e-06, Training time:201805.0195939541
batch reward last col mean 3.1868805763224373e-06 first col mean 1.102878559322562e-05 all mean 4.314372290536994e-06
rl training, epoch7, iter0, batch195/1133, batch loss:4.3169794849973187e-08, Training time:201831.16848111153
batch reward last col mean 3.6970191104046535e-06 first col mean 2.573101482994389e-06 all mean 3.6857729810435558e-06
rl training, epoch7, iter0, batch196/1133, batch loss:3.1049424364937295e-08, Training time:201857.7887070179
batch reward last col mean 1.3415683497441933e-06 first col mean 1.7006111647788202e-06 all mean 1.502570739830844e-06
rl training, epoch7, iter0, batch197/1133, batch loss:7.334311380446934e-09, Training time:201883.85107159615
batch reward last col mean 0.0001344912889180705 first col mean 0.0008875512867234647 all mean 0.00014211161760613322
rl training, epoch7, iter0, batch198/1133, batch loss:5.273365331959212e-06, Training time:201909.93656492233
batch reward last col mean 2.0040655726916157e-05 first col mean 1.762960346241016e-05 all mean 2.001630491577089e-05
rl training, epoch7, iter0, batch199/1133, batch loss:2.7923636025661835e-07, Training time:201936.17851281166
batch reward last col mean 2.616356869111769e-05 first col mean 2.004535599553492e-05 all mean 2.6853322196984664e-05
rl training, epoch7, iter0, batch200/1133, batch loss:1.6346449172033317e-07, Training time:201962.1718661785
batch reward last col mean 2.816288179019466e-05 first col mean 8.991823051474057e-06 all mean 2.7969503207714297e-05
rl training, epoch7, iter0, batch201/1133, batch loss:2.1500510172245413e-07, Training time:201988.72356057167
batch reward last col mean 4.5686258090427145e-05 first col mean 2.3855742256273516e-05 all mean 4.5837994548492134e-05
rl training, epoch7, iter0, batch202/1133, batch loss:2.0327466643266234e-07, Training time:202014.83293938637
batch reward last col mean 4.553261078399373e-06 first col mean 7.4050908551726025e-06 all mean 4.582067958835978e-06
rl training, epoch7, iter0, batch203/1133, batch loss:1.0781791459635315e-08, Training time:202041.29085755348
batch reward last col mean 1.9863280442677933e-07 first col mean 1.37543779032967e-07 all mean 3.23786622402622e-07
rl training, epoch7, iter0, batch204/1133, batch loss:1.765694368494053e-09, Training time:202067.330991745
batch reward last col mean 7.065569207043154e-06 first col mean 8.304679795401171e-06 all mean 7.419188477797434e-06
rl training, epoch7, iter0, batch205/1133, batch loss:3.7158404353476726e-08, Training time:202093.80533194542
batch reward last col mean 7.367468128904875e-07 first col mean 1.8948275055663544e-06 all mean 7.484119350920082e-07
rl training, epoch7, iter0, batch206/1133, batch loss:3.2293476781575237e-09, Training time:202119.76433253288
batch reward last col mean 3.4879248378416605e-09 first col mean 5.610018547486106e-07 all mean 9.58578993959236e-09
rl training, epoch7, iter0, batch207/1133, batch loss:9.592296575100523e-13, Training time:202145.84916114807
batch reward last col mean 1.9456640742987474e-09 first col mean 1.949237882215016e-09 all mean 1.9481425361789206e-09
rl training, epoch7, iter0, batch208/1133, batch loss:3.1680514873781707e-13, Training time:202171.8212337494
batch reward last col mean 8.267693374364171e-06 first col mean 3.996477062173653e-06 all mean 8.623937901575118e-06
rl training, epoch7, iter0, batch209/1133, batch loss:2.4826434241731477e-07, Training time:202198.1768629551
batch reward last col mean 3.6721015931107104e-05 first col mean 3.37401324941311e-05 all mean 3.671482772915624e-05
rl training, epoch7, iter0, batch210/1133, batch loss:1.1566017832365105e-07, Training time:202224.69312238693
batch reward last col mean 1.646887426431931e-06 first col mean 2.0150912405370036e-06 all mean 8.382287887798157e-06
rl training, epoch7, iter0, batch211/1133, batch loss:1.3229274564707794e-08, Training time:202251.30231785774
batch reward last col mean 4.9588902584218886e-06 first col mean 1.8274589592692791e-06 all mean 5.028836767451139e-06
rl training, epoch7, iter0, batch212/1133, batch loss:1.866572851838555e-08, Training time:202277.28773736954
batch reward last col mean 2.1326048226910643e-05 first col mean 1.1252504009462427e-05 all mean 2.235194006061647e-05
rl training, epoch7, iter0, batch213/1133, batch loss:2.628211177579942e-07, Training time:202303.56968951225
batch reward last col mean 1.392751755702193e-06 first col mean 5.404684998211451e-06 all mean 4.667136181524256e-06
rl training, epoch7, iter0, batch214/1133, batch loss:6.1291260955442795e-09, Training time:202329.64472794533
batch reward last col mean 5.453875928651541e-07 first col mean 7.686912795179524e-06 all mean 6.175296221044846e-07
rl training, epoch7, iter0, batch215/1133, batch loss:2.2109012398630057e-09, Training time:202356.03560590744
batch reward last col mean 3.870831278618425e-06 first col mean 3.642679303084151e-06 all mean 3.8685266190441325e-06
rl training, epoch7, iter0, batch216/1133, batch loss:5.0980588639504276e-08, Training time:202382.1941177845
batch reward last col mean 3.2771531550679356e-06 first col mean 1.481052322560572e-06 all mean 3.259294544477598e-06
rl training, epoch7, iter0, batch217/1133, batch loss:6.851383460571014e-08, Training time:202408.69708108902
batch reward last col mean 6.191608008521143e-06 first col mean 3.4833008157875156e-06 all mean 6.1642549553653225e-06
rl training, epoch7, iter0, batch218/1133, batch loss:9.169851722390376e-08, Training time:202434.851698637
batch reward last col mean 1.8428086150379386e-06 first col mean 4.625891506293556e-06 all mean 1.8874557099479716e-06
rl training, epoch7, iter0, batch219/1133, batch loss:1.4977558082662767e-09, Training time:202461.11776185036
batch reward last col mean 2.7136084099765867e-06 first col mean 1.6159726783371298e-06 all mean 3.1919444154482335e-06
rl training, epoch7, iter0, batch220/1133, batch loss:7.817488523187421e-08, Training time:202487.52272081375
batch reward last col mean 7.151408681238536e-06 first col mean 4.962099410477094e-06 all mean 2.5090888811973855e-05
rl training, epoch7, iter0, batch221/1133, batch loss:2.1849054121503286e-08, Training time:202513.7248556614
batch reward last col mean 4.049332801514538e-06 first col mean 2.1497876332432497e-06 all mean 4.030146101285936e-06
rl training, epoch7, iter0, batch222/1133, batch loss:5.532911728778345e-08, Training time:202539.81220269203
batch reward last col mean 2.6931702450383455e-06 first col mean 2.7509693154570414e-06 all mean 1.2204804988869e-05
rl training, epoch7, iter0, batch223/1133, batch loss:2.8176381228206537e-09, Training time:202566.04230999947
batch reward last col mean 1.0247692898701644e-06 first col mean 3.684570174300461e-06 all mean 1.065587980519922e-06
rl training, epoch7, iter0, batch224/1133, batch loss:3.455118147144276e-08, Training time:202592.29754829407
batch reward last col mean 8.689799869898707e-06 first col mean 1.0402890211480553e-06 all mean 8.773830813879613e-06
rl training, epoch7, iter0, batch225/1133, batch loss:8.511488545082102e-07, Training time:202618.5295341015
batch reward last col mean 3.5270619264338166e-05 first col mean 1.627630990697071e-05 all mean 3.5121749533573166e-05
rl training, epoch7, iter0, batch226/1133, batch loss:1.7480296321537026e-07, Training time:202644.51622223854
batch reward last col mean 3.840866611426463e-06 first col mean 3.899634066328872e-06 all mean 3.8416269489971455e-06
rl training, epoch7, iter0, batch227/1133, batch loss:1.1947476785678646e-08, Training time:202671.40724682808
batch reward last col mean 1.171294838897552e-09 first col mean 1.2063549092999892e-06 all mean 2.581816183067076e-08
rl training, epoch7, iter0, batch228/1133, batch loss:6.437583972840333e-12, Training time:202697.60038280487
batch reward last col mean 1.7218306993527221e-06 first col mean 6.611162916669855e-06 all mean 1.7712203543851501e-06
rl training, epoch7, iter0, batch229/1133, batch loss:2.215315930698125e-08, Training time:202723.63964271545
batch reward last col mean 3.603887535064132e-06 first col mean 1.3477289030561224e-05 all mean 3.7145337046240456e-06
rl training, epoch7, iter0, batch230/1133, batch loss:4.821342614036439e-08, Training time:202749.7807381153
batch reward last col mean 1.4058467058930546e-05 first col mean 2.408084401395172e-05 all mean 1.624274955247529e-05
rl training, epoch7, iter0, batch231/1133, batch loss:4.737293863854575e-07, Training time:202776.19044232368
batch reward last col mean 7.800765160936862e-06 first col mean 7.923964403744321e-06 all mean 7.811985597072635e-06
rl training, epoch7, iter0, batch232/1133, batch loss:5.4743600763629274e-09, Training time:202802.26115322113
batch reward last col mean 2.5399094738531858e-05 first col mean 1.1157768312841654e-05 all mean 2.5258097593905404e-05
rl training, epoch7, iter0, batch233/1133, batch loss:4.9027768511678005e-08, Training time:202828.51108670235
batch reward last col mean 2.2351491679728497e-06 first col mean 6.736801196893794e-07 all mean 2.2194881239556707e-06
rl training, epoch7, iter0, batch234/1133, batch loss:1.7848060807068578e-08, Training time:202854.7446899414
batch reward last col mean 1.8968592485180125e-05 first col mean 0.0018390899058431387 all mean 3.817845936282538e-05
rl training, epoch7, iter0, batch235/1133, batch loss:8.210992064050515e-08, Training time:202881.2519621849
batch reward last col mean 7.486993354177685e-07 first col mean 1.4176636113916175e-06 all mean 1.5957608638927923e-06
rl training, epoch7, iter0, batch236/1133, batch loss:1.9297936582063357e-09, Training time:202907.31846308708
batch reward last col mean 1.4970286343896078e-08 first col mean 1.1956180401284655e-07 all mean 1.6026906024535492e-08
rl training, epoch7, iter0, batch237/1133, batch loss:5.6637628614852886e-11, Training time:202933.41546463966
batch reward last col mean 1.2869575130025623e-06 first col mean 3.654126658148016e-06 all mean 1.6233778978858027e-06
rl training, epoch7, iter0, batch238/1133, batch loss:2.2690596068741797e-08, Training time:202959.45313334465
batch reward last col mean 1.4366848517965991e-05 first col mean 4.186794285487849e-06 all mean 1.4281298717833124e-05
rl training, epoch7, iter0, batch239/1133, batch loss:1.9246932936312078e-07, Training time:202985.4766151905
batch reward last col mean 9.279372648052231e-07 first col mean 1.5458503185072914e-05 all mean 1.07478228983382e-06
rl training, epoch7, iter0, batch240/1133, batch loss:1.7460491719134552e-08, Training time:203011.4884405136
batch reward last col mean 3.0410694762394996e-07 first col mean 1.691122520242061e-06 all mean 3.369573846612184e-07
rl training, epoch7, iter0, batch241/1133, batch loss:2.4193729242227846e-09, Training time:203037.6819844246
batch reward last col mean 4.659522801375715e-06 first col mean 9.427036275155842e-06 all mean 2.264047543576453e-05
rl training, epoch7, iter0, batch242/1133, batch loss:3.280731419863514e-08, Training time:203063.5936319828
batch reward last col mean 3.158045274176402e-06 first col mean 3.851125256915111e-06 all mean 3.5011696581932483e-06
rl training, epoch7, iter0, batch243/1133, batch loss:1.1995103577078225e-08, Training time:203089.95994758606
batch reward last col mean 7.041356639092555e-06 first col mean 6.326544735202333e-06 all mean 7.054060006339569e-06
rl training, epoch7, iter0, batch244/1133, batch loss:2.89041537371304e-08, Training time:203116.12555098534
batch reward last col mean 2.4250205115095014e-06 first col mean 4.7683174670964945e-06 all mean 2.4503642634954304e-06
rl training, epoch7, iter0, batch245/1133, batch loss:1.1134023480963151e-08, Training time:203142.6048605442
batch reward last col mean 9.757070074556395e-06 first col mean 0.0011444499250501394 all mean 6.015280450810678e-05
rl training, epoch7, iter0, batch246/1133, batch loss:0.00030803069239482284, Training time:203169.9482972622
batch reward last col mean 3.652465238701552e-05 first col mean 5.655895438394509e-05 all mean 3.672702223411761e-05
rl training, epoch7, iter0, batch247/1133, batch loss:9.990589688868567e-08, Training time:203197.21445965767
batch reward last col mean 3.3360465749865398e-06 first col mean 5.294379334941368e-08 all mean 3.961088168580318e-06
rl training, epoch7, iter0, batch248/1133, batch loss:8.893236014273498e-08, Training time:203224.12384796143
batch reward last col mean 1.5476853150175884e-05 first col mean 1.1363868907210417e-05 all mean 2.45440642174799e-05
rl training, epoch7, iter0, batch249/1133, batch loss:5.0329020950812264e-08, Training time:203251.37113380432
batch reward last col mean 3.0739833164261654e-05 first col mean 2.451156615279615e-05 all mean 3.084319178014994e-05
rl training, epoch7, iter0, batch250/1133, batch loss:1.9836407716411486e-07, Training time:203278.4705195427
batch reward last col mean 2.1001085315219825e-06 first col mean 4.5440545363817364e-05 all mean 2.5378913051099516e-06
rl training, epoch7, iter0, batch251/1133, batch loss:9.711159876246711e-09, Training time:203305.7701818943
batch reward last col mean 5.128691555000842e-06 first col mean 3.166579290336813e-06 all mean 5.11005873704562e-06
rl training, epoch7, iter0, batch252/1133, batch loss:1.788791514911736e-08, Training time:203332.453053236
batch reward last col mean 9.080714335141238e-06 first col mean 2.1894118162890663e-06 all mean 9.011107067635749e-06
rl training, epoch7, iter0, batch253/1133, batch loss:1.645161802343864e-07, Training time:203359.27665519714
batch reward last col mean 1.2525692000053823e-05 first col mean 2.0062481780769303e-05 all mean 1.2601822163560428e-05
rl training, epoch7, iter0, batch254/1133, batch loss:9.709549431136111e-08, Training time:203386.68387007713
batch reward last col mean 5.196079291636124e-05 first col mean 4.1717488784343004e-05 all mean 6.720946112181991e-05
rl training, epoch7, iter0, batch255/1133, batch loss:8.401378437383755e-08, Training time:203413.828373909
batch reward last col mean 2.1937119527137838e-05 first col mean 2.386519372521434e-05 all mean 2.1956710043014027e-05
rl training, epoch7, iter0, batch256/1133, batch loss:4.7686114612588426e-08, Training time:203440.77311706543
batch reward last col mean 3.177236294504837e-06 first col mean 1.4050309800950345e-05 all mean 3.321765461805626e-06
rl training, epoch7, iter0, batch257/1133, batch loss:8.172725607380471e-09, Training time:203467.9558160305
batch reward last col mean 4.522852577792946e-06 first col mean 2.4372025109187234e-06 all mean 4.6906343413866125e-06
rl training, epoch7, iter0, batch258/1133, batch loss:1.3199506376793124e-08, Training time:203495.00800013542
batch reward last col mean 5.447159765026299e-06 first col mean 6.594511432922445e-06 all mean 5.459138264996e-06
rl training, epoch7, iter0, batch259/1133, batch loss:7.058521322989009e-09, Training time:203522.09995412827
batch reward last col mean 1.0298535926267505e-05 first col mean 6.13103247815161e-06 all mean 1.0262154319207184e-05
rl training, epoch7, iter0, batch260/1133, batch loss:1.5697463595643057e-07, Training time:203548.59148597717
batch reward last col mean 3.6910514609189704e-06 first col mean 3.4871111438405933e-06 all mean 2.05869091587374e-05
rl training, epoch7, iter0, batch261/1133, batch loss:1.2642298941045738e-07, Training time:203575.2857336998
batch reward last col mean 8.865758900356013e-06 first col mean 7.108049885573564e-06 all mean 8.849306141200941e-06
rl training, epoch7, iter0, batch262/1133, batch loss:6.24419769224005e-08, Training time:203601.97045326233
batch reward last col mean 4.027677277917974e-05 first col mean 3.589387915781117e-06 all mean 3.950397149310447e-05
rl training, epoch7, iter0, batch263/1133, batch loss:2.4222581487265415e-06, Training time:203628.8167798519
batch reward last col mean 9.105157232625061e-07 first col mean 9.966410289052874e-06 all mean 1.0019894034485333e-06
rl training, epoch7, iter0, batch264/1133, batch loss:3.409193760628426e-10, Training time:203655.53846359253
batch reward last col mean 9.440331268706359e-06 first col mean 2.226447577413637e-06 all mean 2.276446502946783e-05
rl training, epoch7, iter0, batch265/1133, batch loss:4.656418752801983e-07, Training time:203682.19754242897
batch reward last col mean 1.9249275737820426e-06 first col mean 8.683077794557903e-06 all mean 2.0277277599234367e-06
rl training, epoch7, iter0, batch266/1133, batch loss:9.432564063160953e-09, Training time:203708.60826802254
batch reward last col mean 2.1685962110495893e-06 first col mean 3.855671820929274e-06 all mean 2.3864729428169085e-06
rl training, epoch7, iter0, batch267/1133, batch loss:4.05596090047311e-08, Training time:203734.83437490463
batch reward last col mean 2.8956201276741922e-05 first col mean 1.500158123235451e-05 all mean 4.773493856191635e-05
rl training, epoch7, iter0, batch268/1133, batch loss:2.561146743573772e-07, Training time:203761.16943335533
batch reward last col mean 1.9169558072462678e-05 first col mean 6.790633506170707e-06 all mean 3.3827243896666914e-05
rl training, epoch7, iter0, batch269/1133, batch loss:1.458875402704507e-07, Training time:203787.62441182137
batch reward last col mean 1.1046513463952579e-05 first col mean 9.812571988732088e-06 all mean 1.2263155440450646e-05
rl training, epoch7, iter0, batch270/1133, batch loss:9.714686655115656e-08, Training time:203814.09166574478
batch reward last col mean 1.0192552508669905e-05 first col mean 8.836805136525072e-06 all mean 1.3129994840710424e-05
rl training, epoch7, iter0, batch271/1133, batch loss:3.871309672831558e-08, Training time:203840.22648882866
batch reward last col mean 8.509771873832506e-07 first col mean 1.1101698191851028e-06 all mean 8.598975114182394e-07
rl training, epoch7, iter0, batch272/1133, batch loss:7.42611128146109e-09, Training time:203866.30398321152
batch reward last col mean 2.202879659307655e-05 first col mean 6.857334824417194e-07 all mean 2.1822172129759565e-05
rl training, epoch7, iter0, batch273/1133, batch loss:1.1200891094631515e-06, Training time:203892.46418309212
batch reward last col mean 2.0688371478172485e-06 first col mean 1.93793562175415e-06 all mean 2.4597916308266576e-06
rl training, epoch7, iter0, batch274/1133, batch loss:8.825005615165082e-09, Training time:203918.55696320534
batch reward last col mean 1.8373435523244552e-05 first col mean 2.458293920426513e-06 all mean 1.8212676877737977e-05
rl training, epoch7, iter0, batch275/1133, batch loss:3.165871831356526e-08, Training time:203944.7695543766
batch reward last col mean 1.6074883433248033e-06 first col mean 6.69630117045017e-06 all mean 1.8325298469790141e-06
rl training, epoch7, iter0, batch276/1133, batch loss:1.7710126698489148e-09, Training time:203970.79734301567
batch reward last col mean 4.894723133475054e-07 first col mean 4.034217454318423e-06 all mean 1.2110500392736867e-05
rl training, epoch7, iter0, batch277/1133, batch loss:2.36173741541279e-06, Training time:203997.24089336395
batch reward last col mean 5.883156063646311e-06 first col mean 6.09087055636337e-06 all mean 5.911966127314372e-06
rl training, epoch7, iter0, batch278/1133, batch loss:1.1916111475329672e-07, Training time:204023.419267416
batch reward last col mean 1.571018401591573e-06 first col mean 4.335154812906694e-07 all mean 2.250646275570034e-06
rl training, epoch7, iter0, batch279/1133, batch loss:7.277174862707625e-09, Training time:204050.10866618156
batch reward last col mean 1.6504556015206617e-06 first col mean 4.6220311560318805e-06 all mean 1.6807282463560114e-06
rl training, epoch7, iter0, batch280/1133, batch loss:2.603470683482101e-08, Training time:204076.32216715813
batch reward last col mean 9.598177712177858e-06 first col mean 6.180327545735054e-06 all mean 2.2492731659440324e-05
rl training, epoch7, iter0, batch281/1133, batch loss:1.074899600439494e-07, Training time:204102.55378770828
batch reward last col mean 1.307327693211846e-05 first col mean 1.2507569408626296e-05 all mean 1.3074573871563189e-05
rl training, epoch7, iter0, batch282/1133, batch loss:2.0640982256736606e-07, Training time:204128.78273129463
batch reward last col mean 8.228981641877908e-06 first col mean 5.494032393471571e-06 all mean 8.23207574285334e-06
rl training, epoch7, iter0, batch283/1133, batch loss:2.519204826967325e-07, Training time:204154.9650027752
batch reward last col mean 6.131685040600132e-06 first col mean 6.155114533612505e-06 all mean 6.132187536422862e-06
rl training, epoch7, iter0, batch284/1133, batch loss:3.428819184136955e-08, Training time:204181.4770810604
batch reward last col mean 6.527288860525005e-07 first col mean 5.8466575865168124e-06 all mean 8.567138252146833e-07
rl training, epoch7, iter0, batch285/1133, batch loss:1.1643537245475954e-09, Training time:204207.69648861885
batch reward last col mean 1.8542850739322603e-06 first col mean 9.881858204607852e-06 all mean 2.221571548943757e-06
rl training, epoch7, iter0, batch286/1133, batch loss:6.935044094547038e-09, Training time:204233.8653843403
batch reward last col mean 8.28214888315415e-06 first col mean 1.792558941815514e-05 all mean 1.0197343726758845e-05
rl training, epoch7, iter0, batch287/1133, batch loss:1.2027041407236538e-07, Training time:204260.20357203484
batch reward last col mean 1.7470572402089601e-06 first col mean 3.741802856893628e-06 all mean 2.312598553544376e-06
rl training, epoch7, iter0, batch288/1133, batch loss:1.0417902984727334e-08, Training time:204286.17763781548
batch reward last col mean 3.985992225352675e-05 first col mean 3.102066330029629e-05 all mean 3.983637725468725e-05
rl training, epoch7, iter0, batch289/1133, batch loss:2.147251962014707e-06, Training time:204312.3641924858
batch reward last col mean 1.862087992776651e-05 first col mean 6.630046300415415e-06 all mean 1.851224988058675e-05
rl training, epoch7, iter0, batch290/1133, batch loss:1.993651039811084e-07, Training time:204338.3731815815
batch reward last col mean 1.9804572275461396e-06 first col mean 7.611463388457196e-07 all mean 1.997794015551335e-06
rl training, epoch7, iter0, batch291/1133, batch loss:7.539794211197659e-08, Training time:204364.54635214806
batch reward last col mean 4.7315133997472e-06 first col mean 1.9359731595613994e-06 all mean 4.703276772488607e-06
rl training, epoch7, iter0, batch292/1133, batch loss:2.02267553817137e-08, Training time:204390.81087231636
batch reward last col mean 0.0010749874636530876 first col mean 4.671715578297153e-05 all mean 0.0006956927827559412
rl training, epoch7, iter0, batch293/1133, batch loss:0.00022607215214520693, Training time:204416.96012067795
batch reward last col mean 7.379031103482703e-06 first col mean 9.831960596784484e-06 all mean 7.446074505423894e-06
rl training, epoch7, iter0, batch294/1133, batch loss:9.611818896360091e-09, Training time:204443.0594959259
batch reward last col mean 4.244625415594783e-06 first col mean 3.816822754743043e-06 all mean 5.347430942492792e-06
rl training, epoch7, iter0, batch295/1133, batch loss:7.533544987836649e-08, Training time:204469.29849505424
batch reward last col mean 1.7242298781638965e-05 first col mean 1.9066517779720016e-05 all mean 1.726075424812734e-05
rl training, epoch7, iter0, batch296/1133, batch loss:2.041384874473806e-07, Training time:204495.39109826088
batch reward last col mean 6.088917871238664e-06 first col mean 4.537042968877358e-06 all mean 9.744952876644675e-06
rl training, epoch7, iter0, batch297/1133, batch loss:8.177023147482032e-08, Training time:204521.67699050903
batch reward last col mean 5.9149180742679164e-05 first col mean 3.736094367923215e-05 all mean 5.893006164114922e-05
rl training, epoch7, iter0, batch298/1133, batch loss:7.384431341961317e-07, Training time:204548.17602729797
batch reward last col mean 6.860864765201313e-09 first col mean 8.013174010557123e-06 all mean 8.790034655703494e-08
rl training, epoch7, iter0, batch299/1133, batch loss:3.873045287261512e-11, Training time:204574.37119174004
batch reward last col mean 1.5135271924648919e-09 first col mean 3.1788039223101805e-07 all mean 6.247456099117699e-07
rl training, epoch7, iter0, batch300/1133, batch loss:3.83860434757799e-12, Training time:204600.30339622498
batch reward last col mean 7.42098200134933e-06 first col mean 1.3848831258655991e-05 all mean 7.492106760764727e-06
rl training, epoch7, iter0, batch301/1133, batch loss:3.400733916691934e-08, Training time:204626.6316256523
batch reward last col mean 0.00016427866648882627 first col mean 0.0001647000026423484 all mean 0.00016428303206339478
rl training, epoch7, iter0, batch302/1133, batch loss:6.560149358847411e-06, Training time:204652.9986822605
batch reward last col mean 4.630663624993758e-06 first col mean 8.255603461293504e-06 all mean 7.75186617829604e-06
rl training, epoch7, iter0, batch303/1133, batch loss:1.7903143145758804e-07, Training time:204679.4484527111
batch reward last col mean 7.555271963610721e-07 first col mean 3.489429332148575e-07 all mean 7.514325375268527e-07
rl training, epoch7, iter0, batch304/1133, batch loss:1.0122584548355462e-08, Training time:204705.55374717712
batch reward last col mean 3.354947182288015e-07 first col mean 1.0458519454914494e-06 all mean 5.204701096772624e-07
rl training, epoch7, iter0, batch305/1133, batch loss:4.4944856725237514e-09, Training time:204731.9296298027
batch reward last col mean 1.801127291400917e-05 first col mean 8.446976607956458e-06 all mean 1.789886118785944e-05
rl training, epoch7, iter0, batch306/1133, batch loss:5.644984071295767e-07, Training time:204758.07820153236
batch reward last col mean 7.662494317628443e-05 first col mean 5.9435762523207814e-05 all mean 7.745604671072215e-05
rl training, epoch7, iter0, batch307/1133, batch loss:3.402978109079413e-06, Training time:204784.59039092064
batch reward last col mean 1.137798790296074e-05 first col mean 8.152145710482728e-06 all mean 1.7988621038966812e-05
rl training, epoch7, iter0, batch308/1133, batch loss:7.544101521261837e-08, Training time:204810.84450793266
batch reward last col mean 8.270289072243031e-06 first col mean 1.0245340490655508e-05 all mean 8.574449566367548e-06
rl training, epoch7, iter0, batch309/1133, batch loss:5.98382285943444e-08, Training time:204837.15021443367
batch reward last col mean 2.519107738407911e-06 first col mean 2.2237027224036865e-06 all mean 2.516774202376837e-06
rl training, epoch7, iter0, batch310/1133, batch loss:1.8304962878801234e-08, Training time:204863.44568276405
batch reward last col mean 1.9557779751266935e-07 first col mean 4.529898887994932e-06 all mean 4.88521379793383e-07
rl training, epoch7, iter0, batch311/1133, batch loss:5.823745929944835e-10, Training time:204889.76028633118
batch reward last col mean 2.763085376500385e-06 first col mean 1.431041891919449e-05 all mean 2.8798110633942997e-06
rl training, epoch7, iter0, batch312/1133, batch loss:8.352611047257597e-09, Training time:204915.94493055344
batch reward last col mean 6.772922461095732e-06 first col mean 7.5040379670099355e-06 all mean 7.770468982926104e-06
rl training, epoch7, iter0, batch313/1133, batch loss:6.427401899600227e-08, Training time:204942.51555418968
batch reward last col mean 1.7828022009780398e-06 first col mean 6.955322987778345e-06 all mean 2.2372826151695335e-06
rl training, epoch7, iter0, batch314/1133, batch loss:1.0134104400094657e-07, Training time:204968.70066189766
batch reward last col mean 1.094388062483631e-05 first col mean 1.672090911597479e-05 all mean 1.1005457963619847e-05
rl training, epoch7, iter0, batch315/1133, batch loss:5.481277298713394e-08, Training time:204994.98925852776
batch reward last col mean 1.1215017821086803e-06 first col mean 7.998187356861308e-06 all mean 2.010625394177623e-06
rl training, epoch7, iter0, batch316/1133, batch loss:8.055997646749802e-09, Training time:205021.35606312752
batch reward last col mean 6.724184459017124e-06 first col mean 1.0769766959128901e-05 all mean 7.937396730994806e-06
rl training, epoch7, iter0, batch317/1133, batch loss:2.5092083077993266e-08, Training time:205047.67001199722
batch reward last col mean 7.11395750840893e-06 first col mean 4.5953916014696006e-06 all mean 7.067903879942605e-06
rl training, epoch7, iter0, batch318/1133, batch loss:7.177416705417272e-08, Training time:205073.9111673832
batch reward last col mean 1.747938949847594e-05 first col mean 4.7868379624560475e-06 all mean 1.8339293092139997e-05
rl training, epoch7, iter0, batch319/1133, batch loss:5.2758817759013255e-08, Training time:205100.3133134842
batch reward last col mean 8.79530307429377e-06 first col mean 4.232477294863202e-06 all mean 2.621868952701334e-05
rl training, epoch7, iter0, batch320/1133, batch loss:4.003837830168777e-07, Training time:205126.47102093697
batch reward last col mean 2.4169441530830227e-05 first col mean 1.2792198504030239e-05 all mean 2.4167948140529916e-05
rl training, epoch7, iter0, batch321/1133, batch loss:3.1478313644583977e-07, Training time:205152.85115361214
batch reward last col mean 7.97622163872802e-08 first col mean 2.3643007551754636e-08 all mean 7.920050393295242e-08
rl training, epoch7, iter0, batch322/1133, batch loss:1.0628463664730248e-09, Training time:205179.10767769814
batch reward last col mean 5.331542070052819e-06 first col mean 2.20519577851519e-05 all mean 5.8530617934593465e-06
rl training, epoch7, iter0, batch323/1133, batch loss:7.973982008024905e-08, Training time:205205.77973222733
batch reward last col mean 1.7271011074626585e-06 first col mean 4.242570867063478e-06 all mean 1.752511252561817e-06
rl training, epoch7, iter0, batch324/1133, batch loss:2.695610312741792e-08, Training time:205232.11790132523
batch reward last col mean 8.277744427687139e-07 first col mean 4.819182140636258e-05 all mean 3.6466199162532575e-06
rl training, epoch7, iter0, batch325/1133, batch loss:3.5314611235293114e-09, Training time:205258.40722203255
batch reward last col mean 6.576747182407416e-06 first col mean 6.0452771322161425e-06 all mean 6.5713838921510614e-06
rl training, epoch7, iter0, batch326/1133, batch loss:1.230342547842156e-07, Training time:205284.52333331108
batch reward last col mean 0.00010378363367635757 first col mean 1.0590857527859043e-05 all mean 0.00010283870506100357
rl training, epoch7, iter0, batch327/1133, batch loss:3.9451606426155195e-06, Training time:205310.5660481453
batch reward last col mean 1.6343036577382009e-06 first col mean 3.4524007332947804e-06 all mean 1.6526829540453036e-06
rl training, epoch7, iter0, batch328/1133, batch loss:1.477435596086707e-08, Training time:205336.69922971725
batch reward last col mean 6.719989869452547e-06 first col mean 8.765223901718855e-05 all mean 7.549664132966427e-06
rl training, epoch7, iter0, batch329/1133, batch loss:8.807851514802678e-08, Training time:205363.01582932472
batch reward last col mean 1.7127003957284614e-06 first col mean 1.360458099952666e-06 all mean 1.7091614381570253e-06
rl training, epoch7, iter0, batch330/1133, batch loss:1.3987674130078176e-08, Training time:205389.2694387436
batch reward last col mean 1.2340233297436498e-05 first col mean 1.9619396880443674e-06 all mean 2.3175194655777887e-05
rl training, epoch7, iter0, batch331/1133, batch loss:7.873257459323213e-07, Training time:205415.76174902916
batch reward last col mean 3.855881459458033e-06 first col mean 3.5413631849223748e-06 all mean 3.856208877550671e-06
rl training, epoch7, iter0, batch332/1133, batch loss:1.3570732981804667e-08, Training time:205441.80983805656
batch reward last col mean 2.0198531274218112e-05 first col mean 7.523530075559393e-05 all mean 2.143344136129599e-05
rl training, epoch7, iter0, batch333/1133, batch loss:6.950565420993371e-07, Training time:205468.14333963394
batch reward last col mean 6.124206265667453e-05 first col mean 2.328393929929007e-05 all mean 6.0581623984035105e-05
rl training, epoch7, iter0, batch334/1133, batch loss:2.2936653749638936e-06, Training time:205494.3531317711
batch reward last col mean 7.779532097629271e-06 first col mean 7.796412319294177e-06 all mean 7.779926818329841e-06
rl training, epoch7, iter0, batch335/1133, batch loss:4.8129685126241384e-08, Training time:205520.7365143299
batch reward last col mean 0.0002899014507420361 first col mean 6.235999535419978e-06 all mean 0.0002871361211873591
rl training, epoch7, iter0, batch336/1133, batch loss:3.126181036350317e-05, Training time:205547.2298309803
batch reward last col mean 8.112475370580796e-06 first col mean 1.11347071651835e-05 all mean 8.143009836203419e-06
rl training, epoch7, iter0, batch337/1133, batch loss:4.505640660568133e-08, Training time:205573.89509153366
batch reward last col mean 1.0138850825569534e-07 first col mean 8.29645614430774e-08 all mean 2.8174324597785017e-06
rl training, epoch7, iter0, batch338/1133, batch loss:8.169811493985435e-10, Training time:205599.97281384468
batch reward last col mean 5.119558409205638e-06 first col mean 4.096248630958144e-06 all mean 6.2748376876697876e-06
rl training, epoch7, iter0, batch339/1133, batch loss:2.5549592663764997e-08, Training time:205626.11215543747
batch reward last col mean 7.217448728624731e-05 first col mean 1.1193833415745758e-05 all mean 7.178598752943799e-05
rl training, epoch7, iter0, batch340/1133, batch loss:1.5497414551646216e-06, Training time:205652.5340988636
batch reward last col mean 1.3778906122752232e-06 first col mean 3.282273610238917e-06 all mean 1.3905955711379647e-06
rl training, epoch7, iter0, batch341/1133, batch loss:2.5381250878808714e-08, Training time:205679.0159919262
batch reward last col mean 1.3038929864706006e-05 first col mean 1.7566508176969364e-05 all mean 2.0631137886084616e-05
rl training, epoch7, iter0, batch342/1133, batch loss:3.671634374313726e-08, Training time:205705.26216626167
batch reward last col mean 2.464115368638886e-06 first col mean 0.00010783144534798339 all mean 3.5284278965264093e-06
rl training, epoch7, iter0, batch343/1133, batch loss:1.2088165135537565e-07, Training time:205731.97016596794
batch reward last col mean 1.2181016245449428e-05 first col mean 9.355007023259532e-06 all mean 1.267364223167533e-05
rl training, epoch7, iter0, batch344/1133, batch loss:2.72083696017944e-07, Training time:205758.0531153679
batch reward last col mean 5.134350431035273e-06 first col mean 8.572032470510749e-07 all mean 5.64109586775885e-06
rl training, epoch7, iter0, batch345/1133, batch loss:3.195611242290397e-08, Training time:205784.66484856606
batch reward last col mean 3.785283524848637e-06 first col mean 0.00013234635116532445 all mean 5.137613243277883e-06
rl training, epoch7, iter0, batch346/1133, batch loss:2.065172211018762e-08, Training time:205811.22558164597
batch reward last col mean 1.2593613973876927e-05 first col mean 0.0005973422667011619 all mean 1.894559318316169e-05
rl training, epoch7, iter0, batch347/1133, batch loss:9.751963148119103e-08, Training time:205837.5135576725
batch reward last col mean 1.1093973171227844e-06 first col mean 3.2327538065146655e-05 all mean 1.5783211892994586e-06
rl training, epoch7, iter0, batch348/1133, batch loss:1.2373980950997066e-08, Training time:205863.53155946732
batch reward last col mean 3.521359417391068e-07 first col mean 8.61202863688959e-07 all mean 3.5729553360397404e-07
rl training, epoch7, iter0, batch349/1133, batch loss:4.6575996393016794e-09, Training time:205889.6405966282
batch reward last col mean 9.140434849541634e-05 first col mean 4.513130079430994e-06 all mean 8.998476550914347e-05
rl training, epoch7, iter0, batch350/1133, batch loss:4.94821051688632e-06, Training time:205915.82556390762
batch reward last col mean 2.95677764370339e-05 first col mean 7.554962394351605e-06 all mean 2.9537468435592018e-05
rl training, epoch7, iter0, batch351/1133, batch loss:1.0159179453239631e-07, Training time:205941.931681633
batch reward last col mean 9.978163689083885e-06 first col mean 4.782690666615963e-06 all mean 9.925685844791587e-06
rl training, epoch7, iter0, batch352/1133, batch loss:4.6103579620648816e-08, Training time:205968.17962622643
batch reward last col mean 6.351970569085097e-06 first col mean 2.5984680178225972e-05 all mean 6.550941634486662e-06
rl training, epoch7, iter0, batch353/1133, batch loss:3.416585059312638e-08, Training time:205994.3251698017
batch reward last col mean 6.924591957613302e-07 first col mean 1.8110242763214046e-06 all mean 9.05741580936592e-06
rl training, epoch7, iter0, batch354/1133, batch loss:3.9754684877379987e-08, Training time:206020.5025856495
batch reward last col mean 1.306866238337534e-06 first col mean 8.397121746384073e-06 all mean 1.4223770676835557e-06
rl training, epoch7, iter0, batch355/1133, batch loss:5.3211381967344096e-09, Training time:206046.57962822914
batch reward last col mean 6.941178071429022e-06 first col mean 2.1217351786617655e-06 all mean 9.8154505394632e-06
rl training, epoch7, iter0, batch356/1133, batch loss:4.918949159105068e-08, Training time:206072.9956729412
batch reward last col mean 5.2035711632925086e-06 first col mean 1.9715795133379288e-05 all mean 5.352955213311361e-06
rl training, epoch7, iter0, batch357/1133, batch loss:1.4420934668635255e-08, Training time:206099.494017601
batch reward last col mean 1.8710481526795775e-05 first col mean 2.6952320695272647e-05 all mean 1.8793738490785472e-05
rl training, epoch7, iter0, batch358/1133, batch loss:1.3216215677402943e-08, Training time:206125.62183332443
batch reward last col mean 3.2905754778767005e-05 first col mean 4.569763405015692e-06 all mean 3.498185469652526e-05
rl training, epoch7, iter0, batch359/1133, batch loss:2.536956458243367e-07, Training time:206152.05491900444
batch reward last col mean 6.910816409799736e-06 first col mean 7.388483481918229e-06 all mean 6.913628567417618e-06
rl training, epoch7, iter0, batch360/1133, batch loss:1.780549894192518e-07, Training time:206178.48611402512
batch reward last col mean 2.1098229829874526e-09 first col mean 1.9481939261822845e-07 all mean 1.6570891148148803e-07
rl training, epoch7, iter0, batch361/1133, batch loss:4.4963546774745566e-11, Training time:206204.90277385712
batch reward last col mean 9.189901675199508e-07 first col mean 1.1442063623690046e-05 all mean 2.7099065391666954e-06
rl training, epoch7, iter0, batch362/1133, batch loss:1.761223522578348e-08, Training time:206230.88909101486
batch reward last col mean 1.973842881852761e-05 first col mean 5.834942385263275e-06 all mean 2.4707940610824153e-05
rl training, epoch7, iter0, batch363/1133, batch loss:4.978941703370765e-08, Training time:206257.4202234745
batch reward last col mean 4.662590072257444e-06 first col mean 2.5566709155100398e-05 all mean 4.8738097575551365e-06
rl training, epoch7, iter0, batch364/1133, batch loss:2.2911606833986298e-07, Training time:206283.39356517792
batch reward last col mean 3.467399437795393e-06 first col mean 1.3300217688083649e-05 all mean 3.5722189295483986e-06
rl training, epoch7, iter0, batch365/1133, batch loss:1.3691522582348625e-08, Training time:206309.8958313465
batch reward last col mean 1.8626145902089775e-05 first col mean 3.3113942663476337e-06 all mean 1.8477414414519444e-05
rl training, epoch7, iter0, batch366/1133, batch loss:3.1080807616490347e-07, Training time:206336.05755901337
batch reward last col mean 1.3621413927467074e-05 first col mean 5.461161890707444e-06 all mean 1.6183537809411064e-05
rl training, epoch7, iter0, batch367/1133, batch loss:3.3510119124002813e-07, Training time:206362.30605006218
batch reward last col mean 1.6257756669801893e-06 first col mean 6.046127055014949e-06 all mean 1.6716596746846335e-06
rl training, epoch7, iter0, batch368/1133, batch loss:7.959311432159666e-09, Training time:206388.39584207535
batch reward last col mean 2.6860170692089014e-05 first col mean 5.92275318922475e-05 all mean 2.7314825274515897e-05
rl training, epoch7, iter0, batch369/1133, batch loss:6.984451772495959e-08, Training time:206414.78333044052
batch reward last col mean 9.635035894461907e-06 first col mean 4.039465238747653e-06 all mean 9.66643710853532e-06
rl training, epoch7, iter0, batch370/1133, batch loss:1.1915058450995275e-07, Training time:206440.9399652481
batch reward last col mean 3.6890475030304515e-07 first col mean 9.149931088359153e-07 all mean 1.228529799846001e-05
rl training, epoch7, iter0, batch371/1133, batch loss:4.324722802095948e-09, Training time:206467.09873056412
batch reward last col mean 4.272124442650238e-06 first col mean 3.133445261482848e-06 all mean 3.1391259653901216e-06
rl training, epoch7, iter0, batch372/1133, batch loss:2.7333067009749357e-07, Training time:206493.43460559845
batch reward last col mean 7.5235157055431046e-06 first col mean 6.440402103180531e-06 all mean 7.513782293244731e-06
rl training, epoch7, iter0, batch373/1133, batch loss:8.850490473832906e-08, Training time:206519.77167272568
batch reward last col mean 0.00043548730900511146 first col mean 1.3416348338068929e-05 all mean 0.00043196527985855937
rl training, epoch7, iter0, batch374/1133, batch loss:4.824842471862212e-05, Training time:206545.9561393261
batch reward last col mean 1.078073410099023e-06 first col mean 1.2811719898309093e-06 all mean 1.1236228374400525e-06
rl training, epoch7, iter0, batch375/1133, batch loss:2.4312054591746346e-09, Training time:206572.1059203148
batch reward last col mean 1.134755507337104e-06 first col mean 1.3466618611346348e-06 all mean 1.1322940736135934e-06
rl training, epoch7, iter0, batch376/1133, batch loss:3.3309390801150585e-08, Training time:206598.3272881508
batch reward last col mean 9.305924209002114e-08 first col mean 4.489931626494581e-08 all mean 9.458177373744547e-06
rl training, epoch7, iter0, batch377/1133, batch loss:1.4677344895019928e-09, Training time:206624.4156126976
batch reward last col mean 1.9604187855293276e-06 first col mean 2.2357688067131676e-05 all mean 2.1664345695171505e-06
rl training, epoch7, iter0, batch378/1133, batch loss:5.606889175169272e-09, Training time:206650.6604537964
batch reward last col mean 1.1250968782405835e-05 first col mean 4.661305865738541e-06 all mean 1.197529854835011e-05
rl training, epoch7, iter0, batch379/1133, batch loss:6.074122893551248e-08, Training time:206676.93981218338
batch reward last col mean 1.9384806364541873e-06 first col mean 2.23704228119459e-06 all mean 2.849246129699168e-06
rl training, epoch7, iter0, batch380/1133, batch loss:3.557109096163913e-08, Training time:206703.02184796333
batch reward last col mean 1.2999636282984284e-06 first col mean 3.22156006404839e-06 all mean 1.3193754284657189e-06
rl training, epoch7, iter0, batch381/1133, batch loss:9.34585209222405e-09, Training time:206729.24222803116
batch reward last col mean 3.3841865842987318e-06 first col mean 6.958891754038632e-05 all mean 5.590647106146207e-06
rl training, epoch7, iter0, batch382/1133, batch loss:2.7372305311246237e-08, Training time:206755.3634507656
batch reward last col mean 3.7265226637828164e-06 first col mean 2.0106861029489664e-06 all mean 3.7783593143103644e-06
rl training, epoch7, iter0, batch383/1133, batch loss:1.3805482979023509e-08, Training time:206781.5935139656
batch reward last col mean 5.261130354483612e-06 first col mean 1.0937779734376818e-05 all mean 5.318465809978079e-06
rl training, epoch7, iter0, batch384/1133, batch loss:1.213326328297626e-07, Training time:206807.7945420742
batch reward last col mean 0.002239849651232362 first col mean 6.966254659346305e-06 all mean 0.0012679927749559283
rl training, epoch7, iter0, batch385/1133, batch loss:0.00031480632605962455, Training time:206834.10879850388
batch reward last col mean 1.5158411770244129e-05 first col mean 9.546128239890095e-06 all mean 2.7425905500422232e-05
rl training, epoch7, iter0, batch386/1133, batch loss:1.1386690346171235e-07, Training time:206860.46154117584
batch reward last col mean 1.4136119716567919e-05 first col mean 3.3565840567462146e-05 all mean 3.076020584558137e-05
rl training, epoch7, iter0, batch387/1133, batch loss:2.0225348862368264e-07, Training time:206886.76294732094
batch reward last col mean 0.0011194474063813686 first col mean 9.478531865170226e-06 all mean 0.001097075524739921
rl training, epoch7, iter0, batch388/1133, batch loss:9.211119322571903e-05, Training time:206913.02004289627
batch reward last col mean 3.576487142709084e-05 first col mean 1.787525980034843e-05 all mean 3.5685119655681774e-05
rl training, epoch7, iter0, batch389/1133, batch loss:5.121476647218515e-07, Training time:206939.31879639626
batch reward last col mean 6.9936004365445115e-06 first col mean 7.814413947926369e-06 all mean 8.255184184235986e-06
rl training, epoch7, iter0, batch390/1133, batch loss:5.348940401717073e-09, Training time:206965.41708016396
batch reward last col mean 5.282955680740997e-05 first col mean 2.5825838747550733e-06 all mean 6.259015208343044e-05
rl training, epoch7, iter0, batch391/1133, batch loss:3.562217443686677e-06, Training time:206991.73130130768
batch reward last col mean 1.5498666471103206e-05 first col mean 0.0001339728623861447 all mean 1.6695385056664236e-05
rl training, epoch7, iter0, batch392/1133, batch loss:7.94828025618699e-08, Training time:207017.99853539467
batch reward last col mean 6.042035352038511e-07 first col mean 4.609797997545684e-06 all mean 6.447088480854291e-07
rl training, epoch7, iter0, batch393/1133, batch loss:3.332418341273069e-09, Training time:207044.26601743698
batch reward last col mean 4.376921424409375e-06 first col mean 4.464708638352022e-07 all mean 4.337240170571022e-06
rl training, epoch7, iter0, batch394/1133, batch loss:7.77118671635435e-08, Training time:207070.6367354393
batch reward last col mean 1.6572639083278773e-07 first col mean 1.3829283034283435e-06 all mean 1.432130716239044e-06
rl training, epoch7, iter0, batch395/1133, batch loss:8.282269980952606e-09, Training time:207096.9771885872
batch reward last col mean 8.783741577644832e-06 first col mean 0.00010741447476902977 all mean 9.779970241652336e-06
rl training, epoch7, iter0, batch396/1133, batch loss:6.047913814200001e-08, Training time:207123.2921743393
batch reward last col mean 6.394477622961858e-07 first col mean 7.650465704500675e-06 all mean 7.110352271411102e-07
rl training, epoch7, iter0, batch397/1133, batch loss:3.633470413433315e-09, Training time:207149.60825419426
batch reward last col mean 4.059671937284293e-06 first col mean 4.39715131506091e-06 all mean 4.063982942170696e-06
rl training, epoch7, iter0, batch398/1133, batch loss:2.7601430474533117e-08, Training time:207175.93811130524
batch reward last col mean 1.134841386374319e-05 first col mean 9.159056389762554e-06 all mean 1.5177788554865401e-05
rl training, epoch7, iter0, batch399/1133, batch loss:1.0756134116718385e-07, Training time:207202.22904610634
batch reward last col mean 3.5892926462111063e-06 first col mean 8.326985152962152e-06 all mean 3.743875822692644e-06
rl training, epoch7, iter0, batch400/1133, batch loss:4.647411060432205e-07, Training time:207228.49639558792
batch reward last col mean 1.519020770501811e-05 first col mean 1.804651583370287e-05 all mean 1.7125936210504733e-05
rl training, epoch7, iter0, batch401/1133, batch loss:9.847028792364654e-08, Training time:207254.84455633163
batch reward last col mean 3.1664087600802304e-06 first col mean 4.076827462995425e-05 all mean 3.5463442600303097e-06
rl training, epoch7, iter0, batch402/1133, batch loss:6.805809960042097e-08, Training time:207280.9804005623
batch reward last col mean 2.403604639766854e-07 first col mean 3.0341861929628067e-06 all mean 3.072699996664596e-07
rl training, epoch7, iter0, batch403/1133, batch loss:1.531376137009488e-09, Training time:207307.10119891167
batch reward last col mean 1.781423407010152e-06 first col mean 8.930205694923643e-06 all mean 2.1522597307921387e-05
rl training, epoch7, iter0, batch404/1133, batch loss:8.61582094557889e-09, Training time:207333.2278907299
batch reward last col mean 1.8628963516675867e-05 first col mean 1.1911075716852793e-06 all mean 1.790256646927446e-05
rl training, epoch7, iter0, batch405/1133, batch loss:2.1118139557074755e-06, Training time:207359.4278934002
batch reward last col mean 5.626820438919822e-06 first col mean 1.3004007087147329e-05 all mean 5.701419013348641e-06
rl training, epoch7, iter0, batch406/1133, batch loss:1.1736941418760694e-09, Training time:207385.5257487297
batch reward last col mean 2.8034938814869292e-09 first col mean 3.656707576737972e-06 all mean 5.303078509655279e-08
rl training, epoch7, iter0, batch407/1133, batch loss:8.063667789048878e-12, Training time:207411.57573747635
batch reward last col mean 5.256648364593275e-06 first col mean 7.952953637868632e-06 all mean 5.284392955218209e-06
rl training, epoch7, iter0, batch408/1133, batch loss:2.5475646481254444e-08, Training time:207437.809112072
batch reward last col mean 7.208651368273422e-06 first col mean 1.1826226000266615e-05 all mean 7.37329946787213e-06
rl training, epoch7, iter0, batch409/1133, batch loss:3.9157050935045845e-08, Training time:207464.26758170128
batch reward last col mean 1.438845345091977e-07 first col mean 7.787491540511837e-08 all mean 1.441894852405312e-07
rl training, epoch7, iter0, batch410/1133, batch loss:3.095996792268352e-10, Training time:207490.51918029785
batch reward last col mean 2.100644451275002e-06 first col mean 4.1328345105284825e-05 all mean 2.4968869638541946e-06
rl training, epoch7, iter0, batch411/1133, batch loss:1.9575002951910392e-08, Training time:207516.58837151527
batch reward last col mean 6.2184949456423055e-06 first col mean 3.88711623600102e-06 all mean 6.5228914536419325e-06
rl training, epoch7, iter0, batch412/1133, batch loss:5.8304937766706644e-08, Training time:207542.49536037445
batch reward last col mean 0.00018027250189334154 first col mean 1.4370683857123367e-05 all mean 0.00017698232841212302
rl training, epoch7, iter0, batch413/1133, batch loss:7.78998128225794e-06, Training time:207568.75085687637
batch reward last col mean 2.8629024200199638e-06 first col mean 3.24153074870992e-06 all mean 2.8667395781667437e-06
rl training, epoch7, iter0, batch414/1133, batch loss:9.558024061107062e-08, Training time:207595.45279192924
batch reward last col mean 1.3271728676045313e-05 first col mean 1.5104301382962149e-05 all mean 1.3287379260873422e-05
rl training, epoch7, iter0, batch415/1133, batch loss:1.092110224476528e-07, Training time:207622.0953514576
batch reward last col mean 2.8362344892229885e-05 first col mean 9.11175666260533e-05 all mean 2.9012961022090167e-05
rl training, epoch7, iter0, batch416/1133, batch loss:1.1183492887312241e-07, Training time:207649.2903470993
batch reward last col mean 2.065696094177838e-07 first col mean 2.867877446988132e-05 all mean 4.941790052725992e-07
rl training, epoch7, iter0, batch417/1133, batch loss:7.414008296180441e-10, Training time:207676.1370024681
batch reward last col mean 1.3986595149617642e-05 first col mean 1.418352076143492e-05 all mean 2.1216443201410584e-05
rl training, epoch7, iter0, batch418/1133, batch loss:1.1991529547117352e-08, Training time:207702.7179055214
batch reward last col mean 1.3800098713545594e-05 first col mean 1.2202302968944423e-05 all mean 1.3749545360042248e-05
rl training, epoch7, iter0, batch419/1133, batch loss:3.383082685104455e-07, Training time:207729.83796191216
batch reward last col mean 4.3908444240514655e-06 first col mean 6.567400305357296e-06 all mean 1.3019023754168302e-05
rl training, epoch7, iter0, batch420/1133, batch loss:1.0810924599979899e-08, Training time:207756.7649626732
batch reward last col mean 8.202017056646582e-07 first col mean 6.050532306289824e-07 all mean 8.379179234907497e-07
rl training, epoch7, iter0, batch421/1133, batch loss:9.712654014393252e-10, Training time:207783.2460296154
batch reward last col mean 1.2383728972054087e-05 first col mean 2.467337981215678e-05 all mean 1.2507866813393775e-05
rl training, epoch7, iter0, batch422/1133, batch loss:1.1930167431728478e-07, Training time:207809.61260676384
batch reward last col mean 2.72987699645455e-06 first col mean 2.4154271159204654e-05 all mean 2.9733721476077335e-06
rl training, epoch7, iter0, batch423/1133, batch loss:6.836278654276384e-09, Training time:207836.6763164997
batch reward last col mean 1.3941706129116938e-05 first col mean 1.0981833838741295e-05 all mean 1.391384648741223e-05
rl training, epoch7, iter0, batch424/1133, batch loss:8.032716891648306e-08, Training time:207863.84861326218
batch reward last col mean 4.067639565619174e-06 first col mean 2.598329410830047e-05 all mean 4.145968887314666e-06
rl training, epoch7, iter0, batch425/1133, batch loss:5.870415407116525e-07, Training time:207890.60124278069
batch reward last col mean 9.480650078330655e-07 first col mean 1.4525394362863153e-06 all mean 1.1323114676997648e-06
rl training, epoch7, iter0, batch426/1133, batch loss:3.1273579281787534e-09, Training time:207917.41317009926
batch reward last col mean 2.356122649871395e-06 first col mean 4.007724783150479e-06 all mean 2.372805056438665e-06
rl training, epoch7, iter0, batch427/1133, batch loss:1.0065056343933065e-08, Training time:207944.1750383377
batch reward last col mean 3.3987157621595543e-06 first col mean 1.7428571936761728e-06 all mean 4.6180780373106245e-06
rl training, epoch7, iter0, batch428/1133, batch loss:9.428203640027277e-08, Training time:207971.29632115364
batch reward last col mean 2.021607997448882e-06 first col mean 6.130197789389058e-07 all mean 2.0097811557207024e-06
rl training, epoch7, iter0, batch429/1133, batch loss:2.0059694350038626e-08, Training time:207998.10441756248
batch reward last col mean 8.96485801149538e-07 first col mean 1.223329127242323e-05 all mean 1.0109964705407037e-06
rl training, epoch7, iter0, batch430/1133, batch loss:6.547175690485574e-09, Training time:208024.26164722443
batch reward last col mean 0.0076418109238147736 first col mean 7.062197255436331e-06 all mean 0.003331954125314951
rl training, epoch7, iter0, batch431/1133, batch loss:0.0009934037225320935, Training time:208050.92785406113
batch reward last col mean 3.0335936571646016e-06 first col mean 4.8430401022869773e-08 all mean 3.0066935323702637e-06
rl training, epoch7, iter0, batch432/1133, batch loss:7.165829885025232e-08, Training time:208077.9346499443
batch reward last col mean 5.0695853133220226e-06 first col mean 2.476712779753143e-06 all mean 2.9550537874456495e-05
rl training, epoch7, iter0, batch433/1133, batch loss:1.6697849503088946e-07, Training time:208104.9273803234
batch reward last col mean 4.610824544215575e-05 first col mean 2.5928800823749043e-05 all mean 5.083366340841167e-05
rl training, epoch7, iter0, batch434/1133, batch loss:1.056516367725635e-07, Training time:208131.1022694111
batch reward last col mean 3.033347297787259e-07 first col mean 2.312848891961039e-06 all mean 1.0005140893554199e-06
rl training, epoch7, iter0, batch435/1133, batch loss:4.841100853525404e-09, Training time:208157.31571269035
batch reward last col mean 1.8975957573275082e-05 first col mean 1.1742489505195408e-06 all mean 3.432845915085636e-05
rl training, epoch7, iter0, batch436/1133, batch loss:6.414194899662107e-07, Training time:208183.3160955906
batch reward last col mean 9.565428626956418e-06 first col mean 1.404643444402609e-05 all mean 1.0294381354469806e-05
rl training, epoch7, iter0, batch437/1133, batch loss:2.994579872961367e-08, Training time:208209.8370757103
batch reward last col mean 7.186406492110109e-07 first col mean 3.4138081446144497e-06 all mean 7.642341302016575e-07
rl training, epoch7, iter0, batch438/1133, batch loss:6.43602993122272e-09, Training time:208235.80994296074
batch reward last col mean 3.7954223444103263e-06 first col mean 6.707645297865383e-06 all mean 3.82487496608519e-06
rl training, epoch7, iter0, batch439/1133, batch loss:2.706612711733669e-08, Training time:208262.2862253189
batch reward last col mean 2.0232969291100744e-06 first col mean 4.8902475100476295e-05 all mean 4.5215497266326565e-06
rl training, epoch7, iter0, batch440/1133, batch loss:4.571760747751341e-09, Training time:208288.35069155693
batch reward last col mean 1.4608687706640922e-05 first col mean 6.7166965891374275e-06 all mean 1.4815139365964569e-05
rl training, epoch7, iter0, batch441/1133, batch loss:2.8795477646781364e-07, Training time:208314.58903193474
batch reward last col mean 3.319310781080276e-05 first col mean 1.7832502635428682e-05 all mean 3.303803168819286e-05
rl training, epoch7, iter0, batch442/1133, batch loss:1.1252776630499284e-06, Training time:208340.7184894085
batch reward last col mean 1.1494198588479776e-06 first col mean 2.3583179427077994e-06 all mean 1.2172436072432902e-06
rl training, epoch7, iter0, batch443/1133, batch loss:2.030749568504575e-09, Training time:208366.98650193214
batch reward last col mean 9.471791031501198e-07 first col mean 3.805460551120632e-07 all mean 9.509535630058963e-07
rl training, epoch7, iter0, batch444/1133, batch loss:8.420944830334065e-09, Training time:208393.28800034523
batch reward last col mean 8.425193300354294e-06 first col mean 3.1374329410027713e-06 all mean 3.465128247626126e-05
rl training, epoch7, iter0, batch445/1133, batch loss:1.2494169254750886e-07, Training time:208419.65016245842
batch reward last col mean 1.7926362261277973e-07 first col mean 1.134965532401111e-05 all mean 4.585548936120176e-07
rl training, epoch7, iter0, batch446/1133, batch loss:1.7433920973530803e-09, Training time:208445.54908657074
batch reward last col mean 1.7118965445206413e-07 first col mean 1.7119320716574293e-07 all mean 1.7119023709710746e-07
rl training, epoch7, iter0, batch447/1133, batch loss:1.6151929793650766e-10, Training time:208471.63444137573
batch reward last col mean 2.571816594354459e-06 first col mean 3.918179572792724e-05 all mean 2.9412019557639724e-06
rl training, epoch7, iter0, batch448/1133, batch loss:1.0222402124782093e-07, Training time:208497.77958512306
batch reward last col mean 0.00028206591377966106 first col mean 5.535145191970514e-06 all mean 0.0002658074372448027
rl training, epoch7, iter0, batch449/1133, batch loss:3.34603973897174e-05, Training time:208524.04336166382
batch reward last col mean 2.003301915465272e-06 first col mean 3.3598553272895515e-06 all mean 2.7436499294708483e-06
rl training, epoch7, iter0, batch450/1133, batch loss:3.28800027205034e-08, Training time:208550.15281295776
batch reward last col mean 1.0927667062787805e-05 first col mean 4.507770427153446e-06 all mean 1.1913569323951378e-05
rl training, epoch7, iter0, batch451/1133, batch loss:7.656910128162053e-08, Training time:208576.4640636444
batch reward last col mean 1.8862941942643374e-05 first col mean 7.146402822399978e-06 all mean 2.1496018234756775e-05
rl training, epoch7, iter0, batch452/1133, batch loss:9.625525763112819e-07, Training time:208602.77515268326
batch reward last col mean 4.285629984224215e-06 first col mean 8.501652700942941e-06 all mean 4.623419044946786e-06
rl training, epoch7, iter0, batch453/1133, batch loss:2.411022492765369e-08, Training time:208628.98509526253
batch reward last col mean 1.5293100659619085e-05 first col mean 2.3062730178935453e-05 all mean 1.5372856069006957e-05
rl training, epoch7, iter0, batch454/1133, batch loss:9.423069258218675e-08, Training time:208655.3217921257
batch reward last col mean 8.14371333035524e-07 first col mean 3.1110259897104697e-06 all mean 1.4985844245529734e-05
rl training, epoch7, iter0, batch455/1133, batch loss:1.1232501861968558e-07, Training time:208681.61774873734
batch reward last col mean 1.2547885717140161e-06 first col mean 4.5781848712067585e-06 all mean 3.255501496823854e-06
rl training, epoch7, iter0, batch456/1133, batch loss:1.3241433727273488e-08, Training time:208707.97732257843
batch reward last col mean 0.000415126298321411 first col mean 1.806353247957304e-05 all mean 0.0004071885778103024
rl training, epoch7, iter0, batch457/1133, batch loss:2.8819116778322496e-05, Training time:208734.2027220726
batch reward last col mean 6.510468665510416e-06 first col mean 5.220369075686904e-06 all mean 6.533842224598629e-06
rl training, epoch7, iter0, batch458/1133, batch loss:8.729593048428796e-08, Training time:208760.20015597343
batch reward last col mean 5.869681444892194e-06 first col mean 1.7508031305624172e-05 all mean 6.137498075986514e-06
rl training, epoch7, iter0, batch459/1133, batch loss:8.956266128734569e-08, Training time:208786.45734071732
batch reward last col mean 1.7560387277626432e-06 first col mean 8.024483122426318e-07 all mean 7.290957910299767e-06
rl training, epoch7, iter0, batch460/1133, batch loss:2.075713290139447e-08, Training time:208812.77395033836
batch reward last col mean 2.2500735212815925e-06 first col mean 3.0779201551922597e-06 all mean 2.268286380058271e-06
rl training, epoch7, iter0, batch461/1133, batch loss:1.6755796750089758e-08, Training time:208839.1298210621
batch reward last col mean 1.2242333468748257e-05 first col mean 1.4666373317595571e-05 all mean 1.5576635632896796e-05
rl training, epoch7, iter0, batch462/1133, batch loss:4.187317514947608e-08, Training time:208865.46617937088
batch reward last col mean 2.0455336198210716e-05 first col mean 9.456068255531136e-06 all mean 2.034423414443154e-05
rl training, epoch7, iter0, batch463/1133, batch loss:9.185388449850507e-08, Training time:208892.0149013996
batch reward last col mean 1.0680158084142022e-05 first col mean 1.0044895134342369e-05 all mean 2.9526328944484703e-05
rl training, epoch7, iter0, batch464/1133, batch loss:1.2794623671652516e-07, Training time:208918.55129408836
batch reward last col mean 3.083392948610708e-05 first col mean 1.3331569789443165e-05 all mean 4.326639464125037e-05
rl training, epoch7, iter0, batch465/1133, batch loss:4.811772100765666e-07, Training time:208944.8925125599
batch reward last col mean 6.622683486057213e-07 first col mean 2.3817196961317677e-06 all mean 6.948271789042337e-07
rl training, epoch7, iter0, batch466/1133, batch loss:3.912877133416259e-09, Training time:208971.06895446777
batch reward last col mean 4.271574880476692e-07 first col mean 1.0548515660957491e-07 all mean 1.7287538867094554e-06
rl training, epoch7, iter0, batch467/1133, batch loss:4.4981494085050144e-09, Training time:208997.15044498444
batch reward last col mean 1.3852782103640493e-05 first col mean 8.029930540942587e-06 all mean 1.398101812810637e-05
rl training, epoch7, iter0, batch468/1133, batch loss:6.411841013687081e-08, Training time:209023.4844558239
batch reward last col mean 2.9173312213970348e-05 first col mean 1.3154994121578056e-05 all mean 4.110131703782827e-05
rl training, epoch7, iter0, batch469/1133, batch loss:3.790125049363269e-07, Training time:209049.83219337463
batch reward last col mean 4.615364014171064e-05 first col mean 1.4732413546880707e-05 all mean 1.0910605851677246e-05
rl training, epoch7, iter0, batch470/1133, batch loss:5.551346021093195e-06, Training time:209075.944658041
batch reward last col mean 5.530055659619393e-06 first col mean 3.7466975300048944e-06 all mean 6.661983661615523e-06
rl training, epoch7, iter0, batch471/1133, batch loss:3.22225837123824e-08, Training time:209102.34158849716
batch reward last col mean 3.4129388950532302e-06 first col mean 2.8085576104786014e-06 all mean 4.58663953395444e-06
rl training, epoch7, iter0, batch472/1133, batch loss:8.396748185646175e-09, Training time:209128.3072860241
batch reward last col mean 2.9869684112782124e-06 first col mean 9.525007840238686e-07 all mean 4.719689968624152e-06
rl training, epoch7, iter0, batch473/1133, batch loss:4.7284729021157546e-08, Training time:209154.91084194183
batch reward last col mean 5.30772422280279e-06 first col mean 2.8023134746035794e-06 all mean 5.283377049636329e-06
rl training, epoch7, iter0, batch474/1133, batch loss:7.458753614741909e-09, Training time:209181.27313637733
batch reward last col mean 9.266184974876523e-07 first col mean 6.383637810358778e-06 all mean 9.477024832449388e-06
rl training, epoch7, iter0, batch475/1133, batch loss:2.7036644922873165e-08, Training time:209207.49914336205
batch reward last col mean 2.409616718068719e-05 first col mean 2.674567986105103e-05 all mean 3.021220072696451e-05
rl training, epoch7, iter0, batch476/1133, batch loss:1.8396722367697294e-08, Training time:209233.83929085732
batch reward last col mean 1.1568197805900127e-05 first col mean 3.2921984711720143e-06 all mean 1.5151334082474932e-05
rl training, epoch7, iter0, batch477/1133, batch loss:2.084070587216047e-07, Training time:209260.03367972374
batch reward last col mean 2.8735432351822965e-05 first col mean 7.908032785053365e-06 all mean 3.315548019600101e-05
rl training, epoch7, iter0, batch478/1133, batch loss:7.420172778438427e-07, Training time:209286.15638661385
batch reward last col mean 9.489103831583634e-06 first col mean 9.932025932357647e-06 all mean 9.493610377830919e-06
rl training, epoch7, iter0, batch479/1133, batch loss:5.08889996808648e-08, Training time:209312.3695116043
batch reward last col mean 2.630105655043735e-06 first col mean 6.50531510473229e-05 all mean 3.376064569238224e-06
rl training, epoch7, iter0, batch480/1133, batch loss:2.8375756855325562e-08, Training time:209338.82784605026
batch reward last col mean 6.4806954469531775e-06 first col mean 4.419147899170639e-06 all mean 6.463679710577708e-06
rl training, epoch7, iter0, batch481/1133, batch loss:7.536547030895235e-08, Training time:209365.3092200756
batch reward last col mean 8.063156201387756e-06 first col mean 2.035453508142382e-05 all mean 8.184486432583071e-06
rl training, epoch7, iter0, batch482/1133, batch loss:1.9350073543478175e-08, Training time:209391.84890174866
batch reward last col mean 4.535076368483715e-05 first col mean 5.8453217206988484e-05 all mean 4.548918877844699e-05
rl training, epoch7, iter0, batch483/1133, batch loss:1.4148118054890801e-07, Training time:209418.21037054062
batch reward last col mean 1.7107526218751445e-05 first col mean 1.5286021152860485e-05 all mean 1.7135856978711672e-05
rl training, epoch7, iter0, batch484/1133, batch loss:1.3412920907285297e-07, Training time:209444.8443992138
batch reward last col mean 1.9920846170862205e-05 first col mean 7.981061571626924e-06 all mean 1.9800190784735605e-05
rl training, epoch7, iter0, batch485/1133, batch loss:3.2461468890687684e-07, Training time:209471.1132028103
batch reward last col mean 1.027429516398115e-05 first col mean 5.586002203017415e-07 all mean 1.020134732243605e-05
rl training, epoch7, iter0, batch486/1133, batch loss:4.0118811739375815e-07, Training time:209497.26709842682
batch reward last col mean 1.7972119792375452e-07 first col mean 3.063105168621405e-06 all mean 2.088489452489739e-07
rl training, epoch7, iter0, batch487/1133, batch loss:8.298136622286734e-10, Training time:209523.789812088
batch reward last col mean 3.863665824610507e-06 first col mean 3.9096623368095607e-05 all mean 4.391233687783824e-06
rl training, epoch7, iter0, batch488/1133, batch loss:9.8361798706037e-09, Training time:209550.4416050911
batch reward last col mean 1.9201885152142495e-05 first col mean 1.7244987247977406e-05 all mean 2.153235618607141e-05
rl training, epoch7, iter0, batch489/1133, batch loss:2.1140081116755027e-06, Training time:209576.8542113304
batch reward last col mean 2.325262721569743e-05 first col mean 2.7732456146623008e-05 all mean 2.3394852178171277e-05
rl training, epoch7, iter0, batch490/1133, batch loss:8.804531326234155e-09, Training time:209603.21730923653
batch reward last col mean 7.874042239564005e-06 first col mean 1.60231957124779e-06 all mean 1.8493352399673313e-05
rl training, epoch7, iter0, batch491/1133, batch loss:2.1861688992430572e-07, Training time:209629.9739420414
batch reward last col mean 1.4256030453907442e-06 first col mean 1.7752419125827146e-06 all mean 4.233921572449617e-06
rl training, epoch7, iter0, batch492/1133, batch loss:7.75647279738223e-09, Training time:209656.1610610485
batch reward last col mean 0.00010365105117671192 first col mean 0.0001021252028294839 all mean 0.00010363947512814775
rl training, epoch7, iter0, batch493/1133, batch loss:3.666943655389332e-07, Training time:209682.67746329308
batch reward last col mean 2.3948350644786842e-06 first col mean 4.628109309123829e-05 all mean 5.333951776265167e-06
rl training, epoch7, iter0, batch494/1133, batch loss:3.040763418837855e-09, Training time:209709.0221774578
batch reward last col mean 1.1121567240479635e-06 first col mean 1.5613868526997976e-05 all mean 1.2586501725309063e-06
rl training, epoch7, iter0, batch495/1133, batch loss:2.4503480133830635e-08, Training time:209735.49781537056
batch reward last col mean 7.682222644689318e-07 first col mean 1.1816772712336387e-05 all mean 1.318217982770875e-06
rl training, epoch7, iter0, batch496/1133, batch loss:4.257202590451925e-09, Training time:209761.73603844643
batch reward last col mean 8.844684089126531e-06 first col mean 8.531498679076321e-06 all mean 8.844654985296074e-06
rl training, epoch7, iter0, batch497/1133, batch loss:6.031704913311842e-08, Training time:209787.9960050583
batch reward last col mean 1.0079421372211073e-05 first col mean 5.130733825353673e-06 all mean 1.2821908057958353e-05
rl training, epoch7, iter0, batch498/1133, batch loss:6.605023372685537e-08, Training time:209814.24774360657
batch reward last col mean 5.761564807471586e-07 first col mean 8.994695690489607e-07 all mean 5.859466227775556e-07
rl training, epoch7, iter0, batch499/1133, batch loss:2.3667292570195286e-09, Training time:209840.5965590477
batch reward last col mean 1.0551202649367042e-06 first col mean 5.770509233116172e-06 all mean 1.1068971161876107e-06
rl training, epoch7, iter0, batch500/1133, batch loss:8.560163244908381e-09, Training time:209866.68168067932
batch reward last col mean 1.2383160537865479e-05 first col mean 1.8585327779874206e-05 all mean 1.2825306839658879e-05
rl training, epoch7, iter0, batch501/1133, batch loss:1.529935360622403e-07, Training time:209893.1188249588
batch reward last col mean 7.91406782809645e-05 first col mean 6.156801646284293e-06 all mean 8.579908171668649e-05
rl training, epoch7, iter0, batch502/1133, batch loss:4.805737262358889e-06, Training time:209919.25952672958
batch reward last col mean 2.0071629478479736e-05 first col mean 3.8599991967203096e-06 all mean 2.012272489082534e-05
rl training, epoch7, iter0, batch503/1133, batch loss:3.519368476645468e-07, Training time:209945.55799722672
batch reward last col mean 3.6883193388348445e-07 first col mean 1.1511616548887105e-06 all mean 1.0666960406524595e-05
rl training, epoch7, iter0, batch504/1133, batch loss:1.3791702224708047e-09, Training time:209971.6475789547
batch reward last col mean 2.213448397014872e-06 first col mean 8.083366083155852e-06 all mean 3.2867378649825696e-06
rl training, epoch7, iter0, batch505/1133, batch loss:1.166828234033801e-08, Training time:209998.19510483742
batch reward last col mean 2.4080982257146388e-05 first col mean 7.537039891758468e-06 all mean 2.3924421839183196e-05
rl training, epoch7, iter0, batch506/1133, batch loss:2.963392660149111e-07, Training time:210024.40902876854
batch reward last col mean 7.583044862258248e-06 first col mean 2.4776477403065655e-06 all mean 8.928751412895508e-06
rl training, epoch7, iter0, batch507/1133, batch loss:1.6819122095057537e-07, Training time:210050.92678833008
batch reward last col mean 2.9823306249454618e-05 first col mean 1.1868886758747976e-05 all mean 2.9921691748313606e-05
rl training, epoch7, iter0, batch508/1133, batch loss:6.842108746241138e-07, Training time:210077.21645069122
batch reward last col mean 4.50953712061164e-06 first col mean 0.0019436553120613098 all mean 2.4096796551020816e-05
rl training, epoch7, iter0, batch509/1133, batch loss:2.0099950148733114e-08, Training time:210103.83589196205
batch reward last col mean 9.895617040456273e-06 first col mean 0.00047927358536981046 all mean 3.875489710480906e-05
rl training, epoch7, iter0, batch510/1133, batch loss:4.788987644133158e-05, Training time:210129.93644046783
batch reward last col mean 1.2206573956063949e-05 first col mean 6.640404990321258e-06 all mean 3.0238135877880268e-05
rl training, epoch7, iter0, batch511/1133, batch loss:1.2708552503681858e-06, Training time:210156.16335320473
batch reward last col mean 3.704745904542506e-05 first col mean 1.2699605576926842e-05 all mean 3.565797669580206e-05
rl training, epoch7, iter0, batch512/1133, batch loss:2.00947988560074e-06, Training time:210182.46466064453
batch reward last col mean 2.6027895728475414e-05 first col mean 2.2610485757468268e-05 all mean 2.5993853341788054e-05
rl training, epoch7, iter0, batch513/1133, batch loss:1.3992881520152878e-07, Training time:210208.71391057968
batch reward last col mean 8.397949568461627e-05 first col mean 3.317095888633048e-06 all mean 8.421373058808967e-05
rl training, epoch7, iter0, batch514/1133, batch loss:5.497162874235073e-06, Training time:210235.06089115143
batch reward last col mean 1.2358642379695084e-05 first col mean 1.2432806215656456e-05 all mean 2.1628677131957375e-05
rl training, epoch7, iter0, batch515/1133, batch loss:1.4273930926123057e-09, Training time:210261.3331141472
batch reward last col mean 2.085132564388914e-06 first col mean 2.899730679928325e-05 all mean 4.006308245152468e-06
rl training, epoch7, iter0, batch516/1133, batch loss:4.530654607037832e-08, Training time:210287.34595060349
batch reward last col mean 6.421886610041838e-06 first col mean 1.0117419151356444e-05 all mean 1.0830475730472244e-05
rl training, epoch7, iter0, batch517/1133, batch loss:1.6291007653990164e-08, Training time:210313.880484581
batch reward last col mean 1.2530867024906911e-05 first col mean 6.553532330144662e-06 all mean 1.2473262358980719e-05
rl training, epoch7, iter0, batch518/1133, batch loss:2.8668960538880128e-08, Training time:210339.98111891747
batch reward last col mean 1.4077841115067713e-07 first col mean 2.1787279820273397e-06 all mean 2.246466266342395e-07
rl training, epoch7, iter0, batch519/1133, batch loss:5.295115457215616e-09, Training time:210366.3910534382
batch reward last col mean 1.259656983165769e-06 first col mean 4.080645339854527e-06 all mean 1.2881570228273631e-06
rl training, epoch7, iter0, batch520/1133, batch loss:9.654875121611894e-09, Training time:210392.62209796906
batch reward last col mean 0.00035776259028352797 first col mean 0.00019053375581279397 all mean 0.0003560734912753105
rl training, epoch7, iter0, batch521/1133, batch loss:1.7065869997168193e-06, Training time:210419.29107522964
batch reward last col mean 3.826344254775904e-06 first col mean 3.2159857710212236e-06 all mean 4.3293266571708955e-06
rl training, epoch7, iter0, batch522/1133, batch loss:1.3047548463873682e-07, Training time:210445.96925210953
batch reward last col mean 3.9235480642219045e-08 first col mean 2.1720620679843705e-06 all mean 2.183164298230622e-07
rl training, epoch7, iter0, batch523/1133, batch loss:6.309568978402069e-10, Training time:210472.02556848526
batch reward last col mean 1.862052704382222e-05 first col mean 9.770306860445999e-06 all mean 1.8516966520110145e-05
rl training, epoch7, iter0, batch524/1133, batch loss:9.928502322509303e-07, Training time:210498.095859766
batch reward last col mean 1.953967694134917e-05 first col mean 2.390538065810688e-05 all mean 1.9585339032346383e-05
rl training, epoch7, iter0, batch525/1133, batch loss:9.686432633770892e-08, Training time:210524.85251379013
batch reward last col mean 1.5946881831041537e-05 first col mean 4.590135176840704e-06 all mean 2.3759583200444467e-05
rl training, epoch7, iter0, batch526/1133, batch loss:3.071449157232564e-07, Training time:210550.98790049553
batch reward last col mean 2.044022494374076e-06 first col mean 1.9147155398968607e-06 all mean 1.0960888175759465e-05
rl training, epoch7, iter0, batch527/1133, batch loss:7.316202310647668e-09, Training time:210577.18115377426
batch reward last col mean 2.2970767531660385e-05 first col mean 2.415081144135911e-05 all mean 2.4710654543014243e-05
rl training, epoch7, iter0, batch528/1133, batch loss:9.191302524413913e-06, Training time:210603.65789961815
batch reward last col mean 3.734324127435684e-05 first col mean 1.016010855892091e-06 all mean 3.728595038410276e-05
rl training, epoch7, iter0, batch529/1133, batch loss:8.890379490367195e-07, Training time:210629.85785460472
batch reward last col mean 1.9499020709190518e-06 first col mean 1.0752603884611744e-05 all mean 2.520827365515288e-06
rl training, epoch7, iter0, batch530/1133, batch loss:6.627359550037681e-09, Training time:210656.3320274353
batch reward last col mean 7.749495978259802e-08 first col mean 1.2400738341966644e-05 all mean 2.579972715466283e-07
rl training, epoch7, iter0, batch531/1133, batch loss:8.803633932963351e-10, Training time:210682.83897066116
batch reward last col mean 2.3352374682872323e-06 first col mean 2.5198191906383727e-06 all mean 5.7751185522647575e-06
rl training, epoch7, iter0, batch532/1133, batch loss:6.691646348144786e-08, Training time:210709.41145062447
batch reward last col mean 4.085509317519609e-06 first col mean 3.607520193327218e-05 all mean 4.528737463260768e-06
rl training, epoch7, iter0, batch533/1133, batch loss:3.26926254956561e-08, Training time:210735.7603123188
batch reward last col mean 1.1469570381450467e-05 first col mean 7.114235813787673e-06 all mean 1.3319309800863266e-05
rl training, epoch7, iter0, batch534/1133, batch loss:8.707702647825499e-08, Training time:210761.88977098465
batch reward last col mean 3.3646513202256756e-06 first col mean 2.503777068341151e-06 all mean 3.3894009447976714e-06
rl training, epoch7, iter0, batch535/1133, batch loss:1.6765822508091333e-08, Training time:210788.47476124763
batch reward last col mean 1.4578932905351394e-06 first col mean 2.0722561657748884e-06 all mean 1.4539763242282788e-06
rl training, epoch7, iter0, batch536/1133, batch loss:9.626496932924056e-08, Training time:210814.73129796982
batch reward last col mean 2.584066169220023e-05 first col mean 4.030752461403608e-05 all mean 2.597246930235997e-05
rl training, epoch7, iter0, batch537/1133, batch loss:1.637318689517997e-07, Training time:210841.38382411003
batch reward last col mean 2.0319791929068742e-06 first col mean 0.00011882233957294375 all mean 3.2262810236716177e-06
rl training, epoch7, iter0, batch538/1133, batch loss:2.7829468507434285e-08, Training time:210867.77509951591
batch reward last col mean 4.339218321547378e-06 first col mean 3.055327169931843e-06 all mean 2.2324578822008334e-05
rl training, epoch7, iter0, batch539/1133, batch loss:2.9551296520935466e-08, Training time:210894.55805945396
batch reward last col mean 3.1365552786155604e-06 first col mean 4.9704781304171775e-06 all mean 3.822275175480172e-06
rl training, epoch7, iter0, batch540/1133, batch loss:2.693560396949124e-08, Training time:210920.88536405563
batch reward last col mean 1.2604310541064478e-05 first col mean 6.630302323173964e-06 all mean 1.2581598639371805e-05
rl training, epoch7, iter0, batch541/1133, batch loss:4.141341491958883e-08, Training time:210947.4623746872
batch reward last col mean 0.00011766235547838733 first col mean 1.7430613297619857e-05 all mean 0.00011680932948365808
rl training, epoch7, iter0, batch542/1133, batch loss:6.598214895348065e-06, Training time:210973.93029236794
batch reward last col mean 1.6244517610175535e-05 first col mean 1.573266854393296e-05 all mean 1.6419702660641633e-05
rl training, epoch7, iter0, batch543/1133, batch loss:3.0725834676559316e-07, Training time:211000.31574177742
batch reward last col mean 3.4084764592989814e-06 first col mean 4.414170689415187e-06 all mean 3.43485112352937e-06
rl training, epoch7, iter0, batch544/1133, batch loss:4.130539110747122e-08, Training time:211026.68871235847
batch reward last col mean 4.10366446885746e-05 first col mean 3.4593507734825835e-05 all mean 4.1015220631379634e-05
rl training, epoch7, iter0, batch545/1133, batch loss:1.653219641184478e-07, Training time:211052.9669687748
batch reward last col mean 2.365149157412816e-05 first col mean 9.110078281082679e-06 all mean 2.329400558664929e-05
rl training, epoch7, iter0, batch546/1133, batch loss:8.584279953538498e-07, Training time:211079.45073533058
batch reward last col mean 3.228968381563391e-08 first col mean 9.768249356056913e-07 all mean 4.211721105207289e-08
rl training, epoch7, iter0, batch547/1133, batch loss:2.442727686791102e-10, Training time:211105.6986105442
batch reward last col mean 4.433146386872977e-06 first col mean 1.6055526430136524e-05 all mean 5.746177976106992e-06
rl training, epoch7, iter0, batch548/1133, batch loss:2.2356556428348995e-07, Training time:211131.87287569046
batch reward last col mean 1.3948548257758375e-05 first col mean 2.5944689696189016e-05 all mean 1.4069637472857721e-05
rl training, epoch7, iter0, batch549/1133, batch loss:5.623933674314685e-08, Training time:211158.16143774986
batch reward last col mean 4.872272256761789e-07 first col mean 2.3040040559862973e-06 all mean 5.57599491912697e-07
rl training, epoch7, iter0, batch550/1133, batch loss:2.657691844376586e-10, Training time:211184.11331486702
batch reward last col mean 1.7033256881404668e-05 first col mean 7.720664143562317e-06 all mean 1.6939229681156576e-05
rl training, epoch7, iter0, batch551/1133, batch loss:5.326598540023042e-08, Training time:211210.2861685753
batch reward last col mean 4.202244326734217e-06 first col mean 1.2833957953262143e-05 all mean 4.3838190322276205e-06
rl training, epoch7, iter0, batch552/1133, batch loss:6.693391441103813e-08, Training time:211236.56951999664
batch reward last col mean 4.603182617302082e-07 first col mean 1.3171640603104606e-05 all mean 5.949112278358371e-07
rl training, epoch7, iter0, batch553/1133, batch loss:8.422601283086806e-09, Training time:211263.07084012032
batch reward last col mean 1.0068087021863903e-06 first col mean 4.382420115689456e-07 all mean 5.847235115652438e-06
rl training, epoch7, iter0, batch554/1133, batch loss:9.89118209560047e-09, Training time:211289.47311878204
batch reward last col mean 2.9922507138735455e-08 first col mean 4.759301361900725e-07 all mean 1.2636648989428068e-06
rl training, epoch7, iter0, batch555/1133, batch loss:1.5073003956089792e-10, Training time:211315.7526154518
batch reward last col mean 6.19082129560411e-06 first col mean 4.456230271898676e-06 all mean 6.650740488112206e-06
rl training, epoch7, iter0, batch556/1133, batch loss:2.0355400920379907e-08, Training time:211341.93156147003
batch reward last col mean 0.002437146147713065 first col mean 0.002418509451672435 all mean 0.00243685906752944
rl training, epoch7, iter0, batch557/1133, batch loss:0.0002775036555249244, Training time:211368.1877872944
batch reward last col mean 1.3183813280193135e-05 first col mean 9.580392543284688e-06 all mean 1.3181436770537402e-05
rl training, epoch7, iter0, batch558/1133, batch loss:2.3593186071479977e-08, Training time:211394.75512099266
batch reward last col mean 0.0048312111757695675 first col mean 4.493400774663314e-05 all mean 0.00127613905351609
rl training, epoch7, iter0, batch559/1133, batch loss:0.0007894706213846803, Training time:211421.2602570057
batch reward last col mean 9.198040061164647e-05 first col mean 5.9857666201423854e-05 all mean 9.165488154394552e-05
rl training, epoch7, iter0, batch560/1133, batch loss:4.489527043460839e-07, Training time:211447.5281496048
batch reward last col mean 4.250628933277767e-07 first col mean 3.142013838441926e-06 all mean 4.527447856617073e-07
rl training, epoch7, iter0, batch561/1133, batch loss:4.999614944267705e-09, Training time:211473.79390358925
batch reward last col mean 3.3462958981544944e-06 first col mean 3.088457560807001e-06 all mean 3.349224471094203e-06
rl training, epoch7, iter0, batch562/1133, batch loss:4.4954543199082764e-08, Training time:211499.85491871834
batch reward last col mean 9.728815712151118e-06 first col mean 7.361828011198668e-06 all mean 9.730752935865894e-06
rl training, epoch7, iter0, batch563/1133, batch loss:3.234189094314388e-08, Training time:211526.2011809349
batch reward last col mean 8.763957339397166e-06 first col mean 8.208799044950865e-06 all mean 8.722458005649969e-06
rl training, epoch7, iter0, batch564/1133, batch loss:3.062420717014902e-07, Training time:211552.413230896
batch reward last col mean 1.1545016604941338e-05 first col mean 1.1749025361496024e-05 all mean 1.3191292964620516e-05
rl training, epoch7, iter0, batch565/1133, batch loss:2.777680379040248e-07, Training time:211578.84718871117
batch reward last col mean 4.2333205783506855e-05 first col mean 3.3631651604082435e-05 all mean 4.192601045360789e-05
rl training, epoch7, iter0, batch566/1133, batch loss:1.4283475593401818e-06, Training time:211605.1023592949
batch reward last col mean 4.811788585357135e-06 first col mean 1.3116954505676404e-05 all mean 4.89595731778536e-06
rl training, epoch7, iter0, batch567/1133, batch loss:1.7602202362354546e-08, Training time:211631.2400097847
batch reward last col mean 2.2402618924388662e-05 first col mean 2.1242012735456228e-05 all mean 2.2442773115471937e-05
rl training, epoch7, iter0, batch568/1133, batch loss:8.026801623373103e-08, Training time:211657.3863852024
batch reward last col mean 3.3322344279440586e-06 first col mean 3.5831681088893674e-06 all mean 7.254245701915352e-06
rl training, epoch7, iter0, batch569/1133, batch loss:6.377192107720475e-10, Training time:211683.47066164017
batch reward last col mean 9.914248221321031e-05 first col mean 1.7497533235655283e-06 all mean 9.741906978888437e-05
rl training, epoch7, iter0, batch570/1133, batch loss:3.592857865442056e-06, Training time:211709.7316789627
batch reward last col mean 5.390135629568249e-05 first col mean 6.954947821213864e-06 all mean 5.301309283822775e-05
rl training, epoch7, iter0, batch571/1133, batch loss:1.4228932059268118e-06, Training time:211735.99194025993
batch reward last col mean 2.5195083708240418e-06 first col mean 6.5115441429952625e-06 all mean 4.550895937427413e-06
rl training, epoch7, iter0, batch572/1133, batch loss:1.8980651717015462e-08, Training time:211762.0014410019
batch reward last col mean 3.223156454623677e-05 first col mean 2.1566209397860803e-05 all mean 3.2286108762491494e-05
rl training, epoch7, iter0, batch573/1133, batch loss:8.152957065021837e-08, Training time:211788.2837767601
batch reward last col mean 1.862432782218093e-06 first col mean 8.376823097933084e-05 all mean 2.705624865484424e-06
rl training, epoch7, iter0, batch574/1133, batch loss:2.384158470647435e-08, Training time:211814.3068499565
batch reward last col mean 2.404494580332539e-06 first col mean 1.4881177776260301e-05 all mean 3.163751671309001e-06
rl training, epoch7, iter0, batch575/1133, batch loss:3.996879716083868e-09, Training time:211840.4224369526
batch reward last col mean 3.6042663396074204e-06 first col mean 2.168894525311771e-06 all mean 4.59954662801465e-06
rl training, epoch7, iter0, batch576/1133, batch loss:4.419517196652123e-08, Training time:211866.67578125
batch reward last col mean 2.507591671019327e-05 first col mean 1.6096888430183753e-05 all mean 2.5199076844728552e-05
rl training, epoch7, iter0, batch577/1133, batch loss:1.0857462484636926e-06, Training time:211892.87664461136
batch reward last col mean 1.5532399629591964e-05 first col mean 1.0302177543053403e-05 all mean 1.5506899217143655e-05
rl training, epoch7, iter0, batch578/1133, batch loss:3.4449016084181494e-08, Training time:211919.24148082733
batch reward last col mean 2.6179052383668022e-06 first col mean 4.5140359361539595e-06 all mean 1.0020193258242216e-05
rl training, epoch7, iter0, batch579/1133, batch loss:7.439029836575628e-09, Training time:211945.36626076698
batch reward last col mean 8.590900506533217e-07 first col mean 1.384047891406226e-06 all mean 1.1629565506154904e-06
rl training, epoch7, iter0, batch580/1133, batch loss:1.576322006258124e-08, Training time:211971.66317725182
batch reward last col mean 2.966161900985753e-06 first col mean 1.3550909898185637e-05 all mean 3.1882104849501047e-06
rl training, epoch7, iter0, batch581/1133, batch loss:5.5832721557180776e-08, Training time:211998.23352456093
batch reward last col mean 9.144866197630108e-09 first col mean 3.1086763101484394e-06 all mean 4.9526210688100036e-08
rl training, epoch7, iter0, batch582/1133, batch loss:1.127150976720781e-11, Training time:212025.06980752945
batch reward last col mean 5.477936610986944e-07 first col mean 9.424309246242046e-05 all mean 1.5026347455204814e-06
rl training, epoch7, iter0, batch583/1133, batch loss:2.900974127584277e-09, Training time:212052.17998862267
batch reward last col mean 5.860964158443949e-09 first col mean 5.293611593515379e-06 all mean 6.14736208603972e-08
rl training, epoch7, iter0, batch584/1133, batch loss:6.865028684410746e-11, Training time:212078.931296587
batch reward last col mean 1.462266573071247e-05 first col mean 1.4400000509340316e-05 all mean 1.464914657844929e-05
rl training, epoch7, iter0, batch585/1133, batch loss:9.58783772375682e-08, Training time:212105.58988261223
batch reward last col mean 9.819408660405315e-06 first col mean 1.0459230907144956e-05 all mean 1.02525182228419e-05
rl training, epoch7, iter0, batch586/1133, batch loss:1.3023043266002787e-07, Training time:212132.9134271145
batch reward last col mean 3.914453827746911e-06 first col mean 1.7435844711144455e-05 all mean 5.933578449912602e-06
rl training, epoch7, iter0, batch587/1133, batch loss:7.903179266577354e-08, Training time:212160.04519581795
batch reward last col mean 5.019924174121115e-06 first col mean 5.0102148634323385e-06 all mean 9.90183343674289e-06
rl training, epoch7, iter0, batch588/1133, batch loss:5.331896701932237e-08, Training time:212187.04220557213
batch reward last col mean 3.576845301722642e-06 first col mean 4.3938551243627444e-05 all mean 4.075785000168253e-06
rl training, epoch7, iter0, batch589/1133, batch loss:2.279173294539305e-08, Training time:212213.41454219818
batch reward last col mean 9.80871277533879e-07 first col mean 2.3745963062538067e-06 all mean 2.8887600365123944e-06
rl training, epoch7, iter0, batch590/1133, batch loss:1.6887547360511235e-08, Training time:212240.2035279274
batch reward last col mean 2.64769846580748e-06 first col mean 2.0800787297048373e-06 all mean 2.6739203349279705e-06
rl training, epoch7, iter0, batch591/1133, batch loss:8.625257841288203e-09, Training time:212267.38835263252
batch reward last col mean 0.00014803835074417293 first col mean 2.4205714908021037e-06 all mean 0.000146594422403723
rl training, epoch7, iter0, batch592/1133, batch loss:3.3894455100380583e-06, Training time:212294.12594532967
batch reward last col mean 1.7941647456609644e-05 first col mean 2.421765930193942e-05 all mean 1.800505015125964e-05
rl training, epoch7, iter0, batch593/1133, batch loss:1.889518870257234e-07, Training time:212320.84690213203
batch reward last col mean 3.5818893593386747e-06 first col mean 6.458507414208725e-06 all mean 4.0721211007621605e-06
rl training, epoch7, iter0, batch594/1133, batch loss:4.2500194474826e-09, Training time:212347.33435368538
batch reward last col mean 1.7630687807468348e-06 first col mean 4.289891876396723e-06 all mean 2.034717908827588e-06
rl training, epoch7, iter0, batch595/1133, batch loss:6.404194508036198e-09, Training time:212374.56158995628
batch reward last col mean 6.203335942700505e-06 first col mean 3.4459924336260883e-06 all mean 1.0363292858528439e-05
rl training, epoch7, iter0, batch596/1133, batch loss:1.0631222835399967e-07, Training time:212401.2479841709
batch reward last col mean 5.108322966407286e-06 first col mean 9.12625328055583e-05 all mean 6.838613444415387e-06
rl training, epoch7, iter0, batch597/1133, batch loss:1.5700422295594763e-08, Training time:212428.01559710503
batch reward last col mean 5.19787272423855e-06 first col mean 5.815521035401616e-06 all mean 5.208064067119267e-06
rl training, epoch7, iter0, batch598/1133, batch loss:1.3966104006613023e-07, Training time:212454.64871692657
batch reward last col mean 4.3260877191642066e-07 first col mean 6.58968128846027e-05 all mean 1.2849145605287049e-05
rl training, epoch7, iter0, batch599/1133, batch loss:9.668768008452844e-09, Training time:212481.70271873474
batch reward last col mean 0.00038108337321318686 first col mean 1.5890780559857376e-05 all mean 0.00037541970959864557
rl training, epoch7, iter0, batch600/1133, batch loss:9.892235539155081e-06, Training time:212509.1380827427
batch reward last col mean 6.22634070168715e-06 first col mean 4.293826350476593e-06 all mean 6.2077128859527875e-06
rl training, epoch7, iter0, batch601/1133, batch loss:1.0647752191061954e-07, Training time:212536.26326417923
batch reward last col mean 1.7314025171799585e-05 first col mean 5.066247103968635e-05 all mean 1.777600664354395e-05
rl training, epoch7, iter0, batch602/1133, batch loss:8.699858256022708e-08, Training time:212562.61889958382
batch reward last col mean 2.2970803911448456e-05 first col mean 1.9091690774075687e-05 all mean 2.3457696443074383e-05
rl training, epoch7, iter0, batch603/1133, batch loss:1.2779423741449136e-07, Training time:212588.94662117958
batch reward last col mean 7.256379467435181e-05 first col mean 4.486482430365868e-05 all mean 7.927184196887538e-05
rl training, epoch7, iter0, batch604/1133, batch loss:2.494935245067609e-07, Training time:212615.2852818966
batch reward last col mean 2.0245607856850256e-07 first col mean 1.3691562344320118e-05 all mean 3.425487307140429e-07
rl training, epoch7, iter0, batch605/1133, batch loss:3.2173912423161255e-09, Training time:212641.6567902565
batch reward last col mean 6.168986601551296e-06 first col mean 4.8559095375821926e-06 all mean 6.1650803218071815e-06
rl training, epoch7, iter0, batch606/1133, batch loss:1.4764095723762694e-08, Training time:212667.84346485138
batch reward last col mean 3.4388871426926926e-05 first col mean 9.836830031417776e-06 all mean 3.413505692151375e-05
rl training, epoch7, iter0, batch607/1133, batch loss:4.5656275915462174e-07, Training time:212693.99416279793
batch reward last col mean 7.106518751243129e-06 first col mean 2.133226917067077e-05 all mean 7.269229627127061e-06
rl training, epoch7, iter0, batch608/1133, batch loss:1.3042594559919962e-07, Training time:212720.23835587502
batch reward last col mean 4.462172455532709e-06 first col mean 1.924675416375976e-06 all mean 5.892011813557474e-06
rl training, epoch7, iter0, batch609/1133, batch loss:2.7892235721083125e-07, Training time:212746.39578318596
batch reward last col mean 2.254908622489893e-06 first col mean 2.2211115719983354e-05 all mean 3.2655584618623834e-06
rl training, epoch7, iter0, batch610/1133, batch loss:5.905091882141278e-08, Training time:212772.91761517525
batch reward last col mean 1.4587396890419768e-06 first col mean 0.00012088855874026194 all mean 5.6307467275473755e-06
rl training, epoch7, iter0, batch611/1133, batch loss:1.114033398863512e-08, Training time:212799.06345939636
batch reward last col mean 2.0690142264356837e-05 first col mean 9.486594535701443e-06 all mean 2.0568959371303208e-05
rl training, epoch7, iter0, batch612/1133, batch loss:7.012475862211431e-07, Training time:212825.5686018467
batch reward last col mean 1.2851858627982438e-05 first col mean 1.2545540812425315e-05 all mean 1.2908512871945277e-05
rl training, epoch7, iter0, batch613/1133, batch loss:5.2815718021292923e-08, Training time:212851.68136644363
batch reward last col mean 1.919287387863733e-05 first col mean 5.702451289835153e-06 all mean 2.0156732716714032e-05
rl training, epoch7, iter0, batch614/1133, batch loss:1.0697635843825992e-06, Training time:212877.8210990429
batch reward last col mean 4.009392796433531e-06 first col mean 4.0192626329371706e-06 all mean 4.0171798900701106e-06
rl training, epoch7, iter0, batch615/1133, batch loss:2.1887597512204593e-08, Training time:212904.18379855156
batch reward last col mean 2.10774305742234e-05 first col mean 9.701949238660745e-06 all mean 3.909944643964991e-05
rl training, epoch7, iter0, batch616/1133, batch loss:3.925004250504571e-07, Training time:212930.379976511
batch reward last col mean 7.667544196010567e-06 first col mean 4.970013833371922e-06 all mean 7.813998308847658e-06
rl training, epoch7, iter0, batch617/1133, batch loss:5.1056122885029254e-08, Training time:212956.7862918377
batch reward last col mean 1.826642687774438e-06 first col mean 2.4083426524157403e-06 all mean 1.932463192133582e-06
rl training, epoch7, iter0, batch618/1133, batch loss:9.821587809710763e-08, Training time:212982.78352618217
batch reward last col mean 1.0860410384339048e-06 first col mean 4.3192299926886335e-05 all mean 1.5113569133973215e-06
rl training, epoch7, iter0, batch619/1133, batch loss:4.252849628016975e-09, Training time:213009.05020046234
batch reward last col mean 9.65231492955354e-07 first col mean 8.336023711308371e-07 all mean 1.1090019143011887e-06
rl training, epoch7, iter0, batch620/1133, batch loss:3.5806946296901287e-09, Training time:213035.16957616806
batch reward last col mean 1.642253300815355e-05 first col mean 1.4153617939882679e-06 all mean 3.496794670354575e-05
rl training, epoch7, iter0, batch621/1133, batch loss:2.677037400644622e-07, Training time:213061.360673666
batch reward last col mean 3.89684237234178e-06 first col mean 9.46904856391484e-06 all mean 3.953130544687156e-06
rl training, epoch7, iter0, batch622/1133, batch loss:3.8202546903676193e-08, Training time:213087.6928770542
batch reward last col mean 2.0150675482000224e-05 first col mean 2.7693668016581796e-05 all mean 3.7806570617249236e-05
rl training, epoch7, iter0, batch623/1133, batch loss:8.114309224538374e-08, Training time:213114.21728038788
batch reward last col mean 0.0002021244290517643 first col mean 2.786334562188131e-06 all mean 0.00021645199740305543
rl training, epoch7, iter0, batch624/1133, batch loss:1.22148085210938e-05, Training time:213140.3001086712
batch reward last col mean 4.5538404265244026e-06 first col mean 5.287569365464151e-06 all mean 4.798906957148574e-06
rl training, epoch7, iter0, batch625/1133, batch loss:6.162071741755426e-08, Training time:213166.74926018715
batch reward last col mean 2.5303763322881423e-05 first col mean 1.627580786589533e-05 all mean 2.5710900445119478e-05
rl training, epoch7, iter0, batch626/1133, batch loss:3.560583934358874e-07, Training time:213193.05496001244
batch reward last col mean 2.6024185899586882e-06 first col mean 1.9243379938416183e-06 all mean 3.3784415336413076e-06
rl training, epoch7, iter0, batch627/1133, batch loss:2.1550768281031196e-08, Training time:213219.42781853676
batch reward last col mean 1.6495781665071263e-06 first col mean 2.0747643247887027e-06 all mean 2.3257092834683135e-05
rl training, epoch7, iter0, batch628/1133, batch loss:1.3921771824243478e-07, Training time:213245.4075100422
batch reward last col mean 5.18236993229948e-05 first col mean 1.0111987648997456e-05 all mean 5.134067760081962e-05
rl training, epoch7, iter0, batch629/1133, batch loss:1.8554125063019455e-06, Training time:213271.70364928246
batch reward last col mean 1.4532101886288729e-05 first col mean 9.105548883781012e-07 all mean 1.4409286450245418e-05
rl training, epoch7, iter0, batch630/1133, batch loss:2.2086729245529568e-07, Training time:213298.21399641037
batch reward last col mean 6.200316420290619e-06 first col mean 1.2510135093179997e-05 all mean 2.3462771423510276e-05
rl training, epoch7, iter0, batch631/1133, batch loss:3.530210435087611e-08, Training time:213324.55875825882
batch reward last col mean 3.2551790152268723e-09 first col mean 4.125883151573362e-06 all mean 5.158186766607287e-08
rl training, epoch7, iter0, batch632/1133, batch loss:9.311943577339221e-12, Training time:213350.51099181175
batch reward last col mean 1.6697827959433198e-05 first col mean 3.502078470773995e-05 all mean 1.6882924683159217e-05
rl training, epoch7, iter0, batch633/1133, batch loss:2.9644746746271267e-07, Training time:213377.10096502304
batch reward last col mean 4.3169094965378463e-07 first col mean 1.1939187061216217e-05 all mean 3.933442258130526e-06
rl training, epoch7, iter0, batch634/1133, batch loss:6.1328813139027716e-09, Training time:213403.24279737473
batch reward last col mean 4.549417553789681e-06 first col mean 7.626879778399598e-06 all mean 2.3963140847627074e-05
rl training, epoch7, iter0, batch635/1133, batch loss:9.679227019887549e-08, Training time:213429.72272491455
batch reward last col mean 2.5320816803287016e-06 first col mean 1.4628971257479861e-05 all mean 2.913020125561161e-06
rl training, epoch7, iter0, batch636/1133, batch loss:4.652823193396216e-08, Training time:213455.66145157814
batch reward last col mean 2.2888048079039436e-06 first col mean 2.409470653219614e-06 all mean 2.7418100216891617e-06
rl training, epoch7, iter0, batch637/1133, batch loss:1.7166655874589765e-09, Training time:213481.93121099472
batch reward last col mean 2.4667389880050905e-05 first col mean 1.791955583030358e-05 all mean 2.4570097593823448e-05
rl training, epoch7, iter0, batch638/1133, batch loss:9.334088986179268e-07, Training time:213508.35104441643
batch reward last col mean 3.81173731511808e-06 first col mean 4.4703938328893855e-06 all mean 1.0641192602633964e-05
rl training, epoch7, iter0, batch639/1133, batch loss:1.289741202725736e-08, Training time:213534.70370817184
batch reward last col mean 1.2415270020937896e-06 first col mean 4.503255695453845e-06 all mean 1.1348535736033227e-05
rl training, epoch7, iter0, batch640/1133, batch loss:2.5203858999844897e-09, Training time:213560.873939991
batch reward last col mean 3.39642815561092e-06 first col mean 6.494414606095233e-07 all mean 4.226496002956992e-06
rl training, epoch7, iter0, batch641/1133, batch loss:1.0080245260724041e-07, Training time:213587.06304383278
batch reward last col mean 4.391257562019746e-07 first col mean 1.4428364920604508e-06 all mean 4.973935574525967e-07
rl training, epoch7, iter0, batch642/1133, batch loss:9.954274071688474e-10, Training time:213613.33549404144
batch reward last col mean 7.0772716753708664e-06 first col mean 2.6030697881651577e-06 all mean 7.420770089083817e-06
rl training, epoch7, iter0, batch643/1133, batch loss:3.093748901505933e-08, Training time:213639.62777233124
batch reward last col mean 4.749155323224841e-06 first col mean 1.1605395229707938e-05 all mean 4.818517936655553e-06
rl training, epoch7, iter0, batch644/1133, batch loss:6.121443618667399e-08, Training time:213665.84143733978
batch reward last col mean 4.323015673435293e-06 first col mean 3.119766552117653e-05 all mean 2.2511867427965626e-05
rl training, epoch7, iter0, batch645/1133, batch loss:1.1607371419586343e-07, Training time:213692.1833035946
batch reward last col mean 2.2875403374200687e-05 first col mean 4.877407263847999e-06 all mean 2.4552771719754674e-05
rl training, epoch7, iter0, batch646/1133, batch loss:6.03125442921737e-07, Training time:213718.53758525848
batch reward last col mean 1.2171218259027228e-05 first col mean 5.363434411265189e-06 all mean 1.2403338587319013e-05
rl training, epoch7, iter0, batch647/1133, batch loss:1.5090108718140982e-07, Training time:213744.7189657688
batch reward last col mean 6.63484534015879e-05 first col mean 9.66924380918499e-06 all mean 6.521399336634204e-05
rl training, epoch7, iter0, batch648/1133, batch loss:2.604555675134179e-06, Training time:213770.71058869362
batch reward last col mean 1.0359192856412847e-05 first col mean 3.05824214592576e-05 all mean 1.0563465366431046e-05
rl training, epoch7, iter0, batch649/1133, batch loss:5.6374648949031325e-08, Training time:213797.5232243538
batch reward last col mean 1.7013433534884825e-05 first col mean 1.3977210983284749e-05 all mean 1.6982801753329113e-05
rl training, epoch7, iter0, batch650/1133, batch loss:1.2883222666459915e-07, Training time:213823.67746186256
batch reward last col mean 3.354509681230411e-05 first col mean 2.2092288418207318e-05 all mean 3.339086106279865e-05
rl training, epoch7, iter0, batch651/1133, batch loss:2.1137266514870134e-07, Training time:213850.33464837074
batch reward last col mean 3.6362364426167915e-06 first col mean 1.8324781194678508e-05 all mean 3.879393716488266e-06
rl training, epoch7, iter0, batch652/1133, batch loss:1.560856617288664e-07, Training time:213876.54478621483
batch reward last col mean 5.7351295254193246e-05 first col mean 6.530656264658319e-06 all mean 5.627382779493928e-05
rl training, epoch7, iter0, batch653/1133, batch loss:2.4511552965122974e-06, Training time:213903.00657320023
batch reward last col mean 2.1980911697028205e-05 first col mean 4.403297498356551e-05 all mean 2.220814894826617e-05
rl training, epoch7, iter0, batch654/1133, batch loss:4.0563168113294523e-07, Training time:213929.18426704407
batch reward last col mean 9.146755473921075e-06 first col mean 4.4549329913934343e-07 all mean 9.06420245883055e-06
rl training, epoch7, iter0, batch655/1133, batch loss:1.3166376788831258e-07, Training time:213955.47977089882
batch reward last col mean 2.4105597731249873e-06 first col mean 1.2053551472490653e-05 all mean 2.505912789274589e-06
rl training, epoch7, iter0, batch656/1133, batch loss:1.6642168532143842e-08, Training time:213981.80079603195
batch reward last col mean 8.469571071145765e-07 first col mean 1.5521894965786487e-05 all mean 1.0918879524979275e-06
rl training, epoch7, iter0, batch657/1133, batch loss:5.772337274834172e-09, Training time:214008.26921153069
batch reward last col mean 1.9077299384662183e-06 first col mean 5.3612027841154486e-05 all mean 2.4299954475281993e-06
rl training, epoch7, iter0, batch658/1133, batch loss:5.247235090877211e-09, Training time:214034.14932274818
batch reward last col mean 8.083045031526126e-06 first col mean 3.438511384956655e-06 all mean 8.0361442087451e-06
rl training, epoch7, iter0, batch659/1133, batch loss:1.8027753867499996e-07, Training time:214060.30729317665
batch reward last col mean 9.93672711047111e-06 first col mean 1.0876475244003814e-05 all mean 9.946229511115234e-06
rl training, epoch7, iter0, batch660/1133, batch loss:9.06647130705096e-08, Training time:214086.6697435379
batch reward last col mean 2.8367137929308228e-05 first col mean 2.2048501705285162e-05 all mean 2.833819598890841e-05
rl training, epoch7, iter0, batch661/1133, batch loss:2.983043145832198e-07, Training time:214113.0234901905
batch reward last col mean 8.265918586403131e-05 first col mean 6.108627712819725e-05 all mean 8.24510061647743e-05
rl training, epoch7, iter0, batch662/1133, batch loss:8.777884090704902e-07, Training time:214139.2937631607
batch reward last col mean 6.720921192027163e-06 first col mean 9.044209036801476e-06 all mean 6.663671229034662e-06
rl training, epoch7, iter0, batch663/1133, batch loss:2.0780657905561384e-07, Training time:214165.63099455833
batch reward last col mean 1.2937672181578819e-05 first col mean 1.0936227226920892e-05 all mean 1.3078875781502575e-05
rl training, epoch7, iter0, batch664/1133, batch loss:7.317490968716811e-08, Training time:214191.64265275002
batch reward last col mean 1.8530708985053934e-06 first col mean 1.323167566624761e-06 all mean 1.8495813947083661e-06
rl training, epoch7, iter0, batch665/1133, batch loss:4.13338252513995e-09, Training time:214218.10690903664
batch reward last col mean 2.1159328753128648e-05 first col mean 1.3043818398728035e-05 all mean 4.0432951209368184e-05
rl training, epoch7, iter0, batch666/1133, batch loss:1.6417747872310429e-07, Training time:214244.36068964005
batch reward last col mean 4.435619121068157e-05 first col mean 1.1361743418092374e-05 all mean 4.403079583426006e-05
rl training, epoch7, iter0, batch667/1133, batch loss:8.416590731030738e-07, Training time:214270.61877059937
batch reward last col mean 2.2110032659838907e-05 first col mean 3.144480842820485e-06 all mean 2.2780141080147587e-05
rl training, epoch7, iter0, batch668/1133, batch loss:9.499798352408106e-07, Training time:214297.00597023964
batch reward last col mean 4.583568625093903e-06 first col mean 8.362408152606804e-06 all mean 4.6267978177638724e-06
rl training, epoch7, iter0, batch669/1133, batch loss:4.618172511072771e-08, Training time:214323.24860405922
batch reward last col mean 2.021350383074605e-06 first col mean 4.335215635364875e-06 all mean 2.0513809886324452e-06
rl training, epoch7, iter0, batch670/1133, batch loss:6.744934388791535e-09, Training time:214349.4395980835
batch reward last col mean 5.67255265195854e-05 first col mean 2.3027991119306535e-05 all mean 5.631449676002376e-05
rl training, epoch7, iter0, batch671/1133, batch loss:1.991057388295303e-06, Training time:214375.876557827
batch reward last col mean 4.168485929767485e-07 first col mean 1.2844895991293015e-07 all mean 4.139479301557003e-07
rl training, epoch7, iter0, batch672/1133, batch loss:6.324436085947127e-09, Training time:214402.22028756142
batch reward last col mean 7.533109965152107e-06 first col mean 7.293363523785956e-06 all mean 7.677120265725534e-06
rl training, epoch7, iter0, batch673/1133, batch loss:2.5378428247790907e-08, Training time:214428.8413248062
batch reward last col mean 2.5633176846895367e-05 first col mean 7.451454621332232e-06 all mean 2.5461313271080144e-05
rl training, epoch7, iter0, batch674/1133, batch loss:2.5689533345030213e-07, Training time:214454.85098719597
batch reward last col mean 1.7366038491672953e-06 first col mean 1.2086569768143818e-05 all mean 1.972515747183934e-06
rl training, epoch7, iter0, batch675/1133, batch loss:8.44995806659199e-09, Training time:214481.0133845806
batch reward last col mean 1.500000598753104e-05 first col mean 8.401830200455151e-06 all mean 1.5021988474472892e-05
rl training, epoch7, iter0, batch676/1133, batch loss:1.1500203811465326e-07, Training time:214507.45387911797
batch reward last col mean 5.236207653069869e-05 first col mean 2.6230130970361643e-05 all mean 5.209811934037134e-05
rl training, epoch7, iter0, batch677/1133, batch loss:1.5099446670774341e-07, Training time:214533.56606054306
batch reward last col mean 8.627311558484507e-07 first col mean 1.5098009953362634e-06 all mean 8.693237987245084e-07
rl training, epoch7, iter0, batch678/1133, batch loss:8.361534575840324e-09, Training time:214559.78250432014
batch reward last col mean 1.3124667020747438e-05 first col mean 2.598216997284908e-05 all mean 1.6672402125550434e-05
rl training, epoch7, iter0, batch679/1133, batch loss:1.1381970033141897e-08, Training time:214586.2471191883
batch reward last col mean 7.838733040443913e-07 first col mean 1.7493056247985805e-06 all mean 8.181491466530133e-07
rl training, epoch7, iter0, batch680/1133, batch loss:5.501545441433109e-09, Training time:214612.48422384262
batch reward last col mean 9.316979412687942e-05 first col mean 5.1639657613122836e-05 all mean 9.275211050407961e-05
rl training, epoch7, iter0, batch681/1133, batch loss:2.7560298576645437e-07, Training time:214638.7764160633
batch reward last col mean 1.6608949238161586e-07 first col mean 0.00045480087283067405 all mean 1.3822655091644265e-05
rl training, epoch7, iter0, batch682/1133, batch loss:1.3002225962566172e-09, Training time:214665.05310440063
batch reward last col mean 4.9516253056935966e-05 first col mean 4.4755801354767755e-05 all mean 5.1021677791140974e-05
rl training, epoch7, iter0, batch683/1133, batch loss:3.586318086945539e-08, Training time:214691.404276371
batch reward last col mean 3.282099669377203e-06 first col mean 2.2306546725303633e-06 all mean 7.737362466286868e-06
rl training, epoch7, iter0, batch684/1133, batch loss:1.2871856469587328e-08, Training time:214717.70328235626
batch reward last col mean 0.0022412193939089775 first col mean 0.000122153724078089 all mean 0.002214208012446761
rl training, epoch7, iter0, batch685/1133, batch loss:0.0002372983581153676, Training time:214744.0773601532
batch reward last col mean 2.707163275772473e-06 first col mean 6.042229142622091e-05 all mean 3.343701109770336e-06
rl training, epoch7, iter0, batch686/1133, batch loss:3.0195820954759256e-08, Training time:214770.14545488358
batch reward last col mean 2.0314755602157675e-05 first col mean 4.290525976102799e-05 all mean 2.0543879145407118e-05
rl training, epoch7, iter0, batch687/1133, batch loss:4.9610807906219634e-08, Training time:214796.2889099121
batch reward last col mean 3.323762211948633e-05 first col mean 1.0296362233930267e-05 all mean 3.300561729702167e-05
rl training, epoch7, iter0, batch688/1133, batch loss:1.3625519841298228e-06, Training time:214822.71149134636
batch reward last col mean 8.952747521107085e-06 first col mean 8.504510333295912e-06 all mean 8.958837497630157e-06
rl training, epoch7, iter0, batch689/1133, batch loss:7.845238769732532e-08, Training time:214849.18572068214
batch reward last col mean 1.5417725080624223e-05 first col mean 4.103557876078412e-05 all mean 1.5776322470628656e-05
rl training, epoch7, iter0, batch690/1133, batch loss:5.982295903095292e-08, Training time:214875.40083050728
batch reward last col mean 1.1730642199836439e-06 first col mean 6.739212494721869e-07 all mean 1.4817054534432827e-06
rl training, epoch7, iter0, batch691/1133, batch loss:1.3592981851218155e-08, Training time:214901.44396162033
batch reward last col mean 3.906272013409762e-06 first col mean 2.4760292944847606e-06 all mean 3.903330252796877e-06
rl training, epoch7, iter0, batch692/1133, batch loss:4.6222879745982937e-08, Training time:214927.84684848785
batch reward last col mean 8.734202128835022e-05 first col mean 2.494362706784159e-05 all mean 8.667998918099329e-05
rl training, epoch7, iter0, batch693/1133, batch loss:5.721752813769854e-07, Training time:214954.2399213314
batch reward last col mean 1.1163192539243028e-05 first col mean 8.770138083491474e-05 all mean 2.72996931016678e-05
rl training, epoch7, iter0, batch694/1133, batch loss:4.50803767648722e-08, Training time:214980.38536190987
batch reward last col mean 2.3680473532294855e-05 first col mean 1.305804562434787e-05 all mean 2.3542823328170925e-05
rl training, epoch7, iter0, batch695/1133, batch loss:3.1502477781941707e-07, Training time:215006.66514992714
batch reward last col mean 2.9836307930963812e-06 first col mean 3.028414766959031e-06 all mean 5.665157459588954e-06
rl training, epoch7, iter0, batch696/1133, batch loss:5.306990402687006e-09, Training time:215032.96850085258
batch reward last col mean 0.0012796935625374317 first col mean 1.279036769119557e-05 all mean 0.0004915600875392556
rl training, epoch7, iter0, batch697/1133, batch loss:0.00018356375221628696, Training time:215059.1993470192
batch reward last col mean 8.279422218038235e-06 first col mean 5.900023552385392e-06 all mean 8.256789442384616e-06
rl training, epoch7, iter0, batch698/1133, batch loss:3.74029184513347e-07, Training time:215085.508559227
batch reward last col mean 8.4309620433487e-05 first col mean 8.93125070433598e-06 all mean 8.481767872581258e-05
rl training, epoch7, iter0, batch699/1133, batch loss:1.4210943390935427e-06, Training time:215112.03513121605
batch reward last col mean 3.4179950034740614e-06 first col mean 1.4016060958965681e-05 all mean 1.7864093024400063e-05
rl training, epoch7, iter0, batch700/1133, batch loss:4.082013393968964e-09, Training time:215138.43106865883
batch reward last col mean 1.8476870309314108e-06 first col mean 2.0719588064821437e-05 all mean 2.0484062588366214e-06
rl training, epoch7, iter0, batch701/1133, batch loss:1.932502513568579e-08, Training time:215164.6038122177
batch reward last col mean 8.309806389661389e-07 first col mean 2.305832140336861e-06 all mean 1.0352287063142285e-06
rl training, epoch7, iter0, batch702/1133, batch loss:1.2739628019176052e-08, Training time:215190.7895951271
batch reward last col mean 0.0003839349083136767 first col mean 3.051366365980357e-05 all mean 0.0003965111682191491
rl training, epoch7, iter0, batch703/1133, batch loss:3.0400946343434043e-05, Training time:215216.98384666443
batch reward last col mean 3.6454262044571806e-06 first col mean 1.0688844668038655e-05 all mean 4.1405742194911e-06
rl training, epoch7, iter0, batch704/1133, batch loss:2.5516834867289617e-08, Training time:215243.36287212372
batch reward last col mean 1.7760899936547503e-05 first col mean 1.5018802514532581e-05 all mean 4.311000884626992e-05
rl training, epoch7, iter0, batch705/1133, batch loss:3.1005967571218207e-07, Training time:215269.59155225754
batch reward last col mean 3.529629111653776e-06 first col mean 2.0876786948065273e-06 all mean 1.083215647668112e-05
rl training, epoch7, iter0, batch706/1133, batch loss:8.11496860819716e-08, Training time:215295.658731699
batch reward last col mean 8.480402357236017e-06 first col mean 8.738935321161989e-06 all mean 9.566324479237664e-06
rl training, epoch7, iter0, batch707/1133, batch loss:8.790167953520722e-07, Training time:215321.9419400692
batch reward last col mean 1.2429405842340202e-06 first col mean 4.549778623186285e-06 all mean 1.3420986988421646e-06
rl training, epoch7, iter0, batch708/1133, batch loss:2.095880979879894e-08, Training time:215348.12809324265
batch reward last col mean 5.614535893982975e-06 first col mean 6.177702289278386e-06 all mean 6.483131528511876e-06
rl training, epoch7, iter0, batch709/1133, batch loss:9.914691290191513e-09, Training time:215374.37252020836
batch reward last col mean 6.373227279254934e-07 first col mean 4.132107278564945e-05 all mean 1.0499434210942127e-06
rl training, epoch7, iter0, batch710/1133, batch loss:1.346782951827663e-08, Training time:215400.4553887844
batch reward last col mean 2.5797009584493935e-05 first col mean 4.087552042619791e-06 all mean 1.95535940292757e-05
rl training, epoch7, iter0, batch711/1133, batch loss:1.6260181610050495e-06, Training time:215426.5909461975
batch reward last col mean 1.0034759725385811e-05 first col mean 9.531755495117977e-06 all mean 1.0044871487480123e-05
rl training, epoch7, iter0, batch712/1133, batch loss:1.3561147227392212e-07, Training time:215452.79618382454
batch reward last col mean 9.35474417929072e-06 first col mean 5.362669071473647e-06 all mean 2.3346348825725727e-05
rl training, epoch7, iter0, batch713/1133, batch loss:2.3555523753771013e-08, Training time:215479.30794024467
batch reward last col mean 0.00011599292338360101 first col mean 1.4508403182844631e-05 all mean 0.00011497658852022141
rl training, epoch7, iter0, batch714/1133, batch loss:3.2735720196797047e-06, Training time:215505.5827012062
batch reward last col mean 4.91775900002267e-08 first col mean 1.829734719649423e-05 all mean 3.190587904100539e-06
rl training, epoch7, iter0, batch715/1133, batch loss:3.2648748149455287e-09, Training time:215532.06442713737
batch reward last col mean 1.506300122855464e-06 first col mean 2.1472826574608916e-06 all mean 5.137221251061419e-06
rl training, epoch7, iter0, batch716/1133, batch loss:2.268265397731284e-08, Training time:215558.12984323502
batch reward last col mean 2.2785094188293442e-05 first col mean 2.2964830350247212e-05 all mean 2.282664536323864e-05
rl training, epoch7, iter0, batch717/1133, batch loss:3.624413125180581e-08, Training time:215584.39812850952
batch reward last col mean 0.00017729079991113394 first col mean 0.00046637951163575053 all mean 0.00018345956050325185
rl training, epoch7, iter0, batch718/1133, batch loss:1.8779874153551646e-05, Training time:215610.75252580643
batch reward last col mean 3.7367926779552363e-06 first col mean 2.487802703399211e-06 all mean 5.282969596009934e-06
rl training, epoch7, iter0, batch719/1133, batch loss:6.144125563878333e-08, Training time:215637.1525771618
batch reward last col mean 1.6591812368460523e-07 first col mean 5.205647994444007e-06 all mean 8.373649507120717e-07
rl training, epoch7, iter0, batch720/1133, batch loss:3.9317835098806597e-10, Training time:215663.26519608498
batch reward last col mean 2.456231231917627e-05 first col mean 2.41161287704017e-05 all mean 2.4620241674710996e-05
rl training, epoch7, iter0, batch721/1133, batch loss:2.0832912639434653e-07, Training time:215689.44305419922
batch reward last col mean 4.1663844285722007e-07 first col mean 4.006971721537411e-05 all mean 8.935550681599125e-07
rl training, epoch7, iter0, batch722/1133, batch loss:4.882285242757689e-09, Training time:215715.65164327621
batch reward last col mean 3.481118619674817e-05 first col mean 9.591581147105899e-06 all mean 3.4561609936645254e-05
rl training, epoch7, iter0, batch723/1133, batch loss:1.2584207809140935e-07, Training time:215742.2668414116
batch reward last col mean 4.1474875615676865e-05 first col mean 6.86200246491353e-06 all mean 4.1710984078235924e-05
rl training, epoch7, iter0, batch724/1133, batch loss:9.787268027139362e-07, Training time:215768.43283820152
batch reward last col mean 2.3086509827408008e-05 first col mean 1.0243339602311607e-05 all mean 3.901464879163541e-05
rl training, epoch7, iter0, batch725/1133, batch loss:1.1980989711446455e-07, Training time:215794.92832255363
batch reward last col mean 3.9705064409645274e-05 first col mean 2.1096671844134107e-05 all mean 3.942582770832814e-05
rl training, epoch7, iter0, batch726/1133, batch loss:6.143209247966297e-07, Training time:215821.51578831673
batch reward last col mean 3.859043772536097e-06 first col mean 1.3030610261921538e-06 all mean 3.997777184849838e-06
rl training, epoch7, iter0, batch727/1133, batch loss:2.6238346606533014e-08, Training time:215847.5258245468
batch reward last col mean 1.453636559745064e-05 first col mean 1.700385837466456e-05 all mean 1.4561475836671889e-05
rl training, epoch7, iter0, batch728/1133, batch loss:6.692388865303656e-07, Training time:215873.48568320274
batch reward last col mean 1.0371128155384213e-05 first col mean 1.2896794032712933e-05 all mean 1.1892507245647721e-05
rl training, epoch7, iter0, batch729/1133, batch loss:1.136022298453554e-08, Training time:215899.74796032906
batch reward last col mean 5.537989181902958e-06 first col mean 3.807108441833407e-05 all mean 5.866605533810798e-06
rl training, epoch7, iter0, batch730/1133, batch loss:4.798412689410725e-08, Training time:215926.0856423378
batch reward last col mean 1.1207673196622636e-05 first col mean 2.9931391054560663e-07 all mean 1.109903951146407e-05
rl training, epoch7, iter0, batch731/1133, batch loss:1.9813182916550431e-07, Training time:215952.28485512733
batch reward last col mean 2.2375472326530144e-05 first col mean 1.0445502994116396e-05 all mean 2.2339989300235175e-05
rl training, epoch7, iter0, batch732/1133, batch loss:8.377810445381328e-08, Training time:215978.52021741867
batch reward last col mean 2.418992153252475e-07 first col mean 1.6465871794935083e-06 all mean 2.561020551183901e-07
rl training, epoch7, iter0, batch733/1133, batch loss:1.7171392086012816e-10, Training time:216004.87587475777
batch reward last col mean 3.955176907766145e-06 first col mean 1.3259683328215033e-05 all mean 3.257956632296555e-05
rl training, epoch7, iter0, batch734/1133, batch loss:7.790906586535584e-09, Training time:216030.98476743698
batch reward last col mean 3.217621269868687e-05 first col mean 9.560377293382771e-06 all mean 3.196334728272632e-05
rl training, epoch7, iter0, batch735/1133, batch loss:8.401047466577438e-07, Training time:216057.44530057907
batch reward last col mean 1.0158330951526295e-05 first col mean 8.734174480196089e-05 all mean 1.3323124221642502e-05
rl training, epoch7, iter0, batch736/1133, batch loss:3.444004050834337e-07, Training time:216083.72625136375
batch reward last col mean 1.5442175936186686e-05 first col mean 1.2938874078827212e-06 all mean 1.0492796718608588e-05
rl training, epoch7, iter0, batch737/1133, batch loss:1.6508219005118008e-06, Training time:216109.98199677467
batch reward last col mean 1.6054254956543446e-06 first col mean 1.923493982758373e-06 all mean 1.6428135722890147e-06
rl training, epoch7, iter0, batch738/1133, batch loss:2.7745656883126912e-09, Training time:216136.26042485237
batch reward last col mean 1.7033809854183346e-05 first col mean 1.5444411474163644e-05 all mean 1.7035459677572362e-05
rl training, epoch7, iter0, batch739/1133, batch loss:4.4571631718781646e-08, Training time:216162.65288996696
batch reward last col mean 3.10033283312805e-06 first col mean 1.2630511037059478e-06 all mean 5.808555215480737e-06
rl training, epoch7, iter0, batch740/1133, batch loss:1.1976911196143192e-07, Training time:216189.372423172
batch reward last col mean 1.2054939588779234e-06 first col mean 7.414782885462046e-05 all mean 3.2258192277367925e-06
rl training, epoch7, iter0, batch741/1133, batch loss:8.042065680058386e-09, Training time:216215.91374492645
batch reward last col mean 1.5302150586649077e-06 first col mean 2.173052280340926e-06 all mean 1.679782599239843e-06
rl training, epoch7, iter0, batch742/1133, batch loss:2.0526002231235907e-08, Training time:216241.9819495678
batch reward last col mean 4.434349193616072e-06 first col mean 4.0297127270605415e-06 all mean 4.439189524418907e-06
rl training, epoch7, iter0, batch743/1133, batch loss:4.758404159588281e-08, Training time:216268.49437475204
batch reward last col mean 7.9232868301915e-06 first col mean 7.740237379039172e-06 all mean 7.938565431686584e-06
rl training, epoch7, iter0, batch744/1133, batch loss:3.490964672892005e-08, Training time:216294.46056962013
batch reward last col mean 1.659851932345191e-06 first col mean 3.147331881336868e-06 all mean 1.2271612831682432e-05
rl training, epoch7, iter0, batch745/1133, batch loss:9.313147586453852e-09, Training time:216320.79009461403
batch reward last col mean 6.090339411457535e-06 first col mean 1.2677295671892352e-05 all mean 6.156753443065099e-06
rl training, epoch7, iter0, batch746/1133, batch loss:5.827738291941387e-08, Training time:216347.08646535873
batch reward last col mean 8.25480674393475e-06 first col mean 1.1994793567282613e-05 all mean 1.1356110007909592e-05
rl training, epoch7, iter0, batch747/1133, batch loss:1.1522205056735402e-07, Training time:216373.4306087494
batch reward last col mean 3.795651991822524e-06 first col mean 1.7834454411058687e-05 all mean 1.7835049220593646e-05
rl training, epoch7, iter0, batch748/1133, batch loss:2.7246884748421962e-09, Training time:216399.6175351143
batch reward last col mean 0.0004017568426206708 first col mean 3.5380187910050154e-05 all mean 0.00039417709922418
rl training, epoch7, iter0, batch749/1133, batch loss:2.7976366254733875e-05, Training time:216426.24660468102
batch reward last col mean 1.7329346519545652e-05 first col mean 1.2109936733395443e-06 all mean 1.7343636500299908e-05
rl training, epoch7, iter0, batch750/1133, batch loss:9.028703971125651e-07, Training time:216452.70290088654
batch reward last col mean 1.3133210813975893e-05 first col mean 4.064558652316919e-06 all mean 1.310050629399484e-05
rl training, epoch7, iter0, batch751/1133, batch loss:1.7818358344356966e-07, Training time:216479.61285877228
batch reward last col mean 3.1713011594547424e-06 first col mean 2.3071072064340115e-05 all mean 3.372309038240928e-06
rl training, epoch7, iter0, batch752/1133, batch loss:2.3119293146578457e-09, Training time:216505.9724764824
batch reward last col mean 7.5999737418896984e-06 first col mean 7.3367682489333674e-06 all mean 1.040729239321081e-05
rl training, epoch7, iter0, batch753/1133, batch loss:1.8829771875061851e-07, Training time:216532.80478096008
batch reward last col mean 1.405414423061302e-05 first col mean 3.0829258321318775e-05 all mean 1.430348856956698e-05
rl training, epoch7, iter0, batch754/1133, batch loss:7.903211241000463e-08, Training time:216559.40359592438
batch reward last col mean 5.965868012935971e-07 first col mean 2.3171494376583723e-06 all mean 3.799267005888396e-06
rl training, epoch7, iter0, batch755/1133, batch loss:1.4500008305162737e-08, Training time:216585.93985843658
batch reward last col mean 8.550923666916788e-06 first col mean 7.717667358519975e-06 all mean 8.542509021935984e-06
rl training, epoch7, iter0, batch756/1133, batch loss:7.585828143419349e-08, Training time:216612.9340929985
batch reward last col mean 3.0460038033197634e-05 first col mean 2.2122110749478452e-05 all mean 3.2032035960583016e-05
rl training, epoch7, iter0, batch757/1133, batch loss:6.550566808982694e-07, Training time:216640.272919178
batch reward last col mean 5.2835868700640276e-05 first col mean 3.1206982384901494e-05 all mean 5.379847061703913e-05
rl training, epoch7, iter0, batch758/1133, batch loss:5.204263402447395e-07, Training time:216667.1821732521
batch reward last col mean 1.984845039260108e-05 first col mean 3.216835466446355e-06 all mean 1.97416557057295e-05
rl training, epoch7, iter0, batch759/1133, batch loss:7.150496799113171e-07, Training time:216693.9073357582
batch reward last col mean 1.4728426322108135e-05 first col mean 1.1277329576842021e-05 all mean 1.479543607274536e-05
rl training, epoch7, iter0, batch760/1133, batch loss:1.2823001327433303e-08, Training time:216720.2409081459
batch reward last col mean 1.437092720379951e-07 first col mean 1.6360449080821127e-05 all mean 3.8727790752091096e-07
rl training, epoch7, iter0, batch761/1133, batch loss:3.61806556936628e-11, Training time:216747.00638461113
batch reward last col mean 4.843604256166145e-05 first col mean 3.0989198421593755e-05 all mean 5.188907016417943e-05
rl training, epoch7, iter0, batch762/1133, batch loss:1.3752434142588754e-06, Training time:216773.28550076485
batch reward last col mean 6.946337089175358e-05 first col mean 4.084795364178717e-06 all mean 6.868670607218519e-05
rl training, epoch7, iter0, batch763/1133, batch loss:1.1518194696691353e-05, Training time:216800.2446577549
batch reward last col mean 9.775403668754734e-06 first col mean 6.979003956075758e-06 all mean 6.741996003256645e-06
rl training, epoch7, iter0, batch764/1133, batch loss:8.905267918635218e-07, Training time:216827.11613702774
batch reward last col mean 2.891268377425149e-05 first col mean 4.7592155169695616e-05 all mean 2.910137118306011e-05
rl training, epoch7, iter0, batch765/1133, batch loss:7.942973923036334e-08, Training time:216853.76215052605
batch reward last col mean 2.058509835478617e-06 first col mean 1.504319016021327e-07 all mean 2.270560571560054e-06
rl training, epoch7, iter0, batch766/1133, batch loss:2.275509558558042e-08, Training time:216880.86438941956
batch reward last col mean 1.724438334349543e-05 first col mean 2.5757222829270177e-05 all mean 1.7830532669904642e-05
rl training, epoch7, iter0, batch767/1133, batch loss:2.353415879952081e-07, Training time:216908.16394925117
batch reward last col mean 7.871750312915538e-06 first col mean 9.146048250840977e-05 all mean 2.623194632178638e-05
rl training, epoch7, iter0, batch768/1133, batch loss:3.245848461119749e-07, Training time:216935.0258038044
batch reward last col mean 2.0849147404078394e-06 first col mean 4.153430836595362e-06 all mean 9.29912130231969e-06
rl training, epoch7, iter0, batch769/1133, batch loss:3.7251916182867717e-06, Training time:216961.6930141449
batch reward last col mean 8.167377018253319e-06 first col mean 1.0401575309515465e-05 all mean 8.592622180003673e-06
rl training, epoch7, iter0, batch770/1133, batch loss:3.075093601978551e-08, Training time:216988.35803818703
batch reward last col mean 1.5746069038868882e-05 first col mean 0.00019112312293145806 all mean 1.9390952729736455e-05
rl training, epoch7, iter0, batch771/1133, batch loss:3.443985860940302e-07, Training time:217014.97492098808
batch reward last col mean 2.9947432267363183e-06 first col mean 7.358835773629835e-06 all mean 3.038825298062875e-06
rl training, epoch7, iter0, batch772/1133, batch loss:1.6356318965904393e-08, Training time:217041.27861905098
batch reward last col mean 1.1583119885472115e-06 first col mean 1.6255279433607939e-06 all mean 2.2701030957250623e-06
rl training, epoch7, iter0, batch773/1133, batch loss:1.3987031532991523e-09, Training time:217067.78179430962
batch reward last col mean 7.037626346573234e-06 first col mean 3.526931777741993e-06 all mean 6.964731710468186e-06
rl training, epoch7, iter0, batch774/1133, batch loss:6.843242772447411e-08, Training time:217094.09064531326
batch reward last col mean 1.521393869552412e-06 first col mean 2.3337765924225096e-06 all mean 1.5296091078198515e-06
rl training, epoch7, iter0, batch775/1133, batch loss:2.317555569675278e-08, Training time:217120.957113266
batch reward last col mean 9.801435226108879e-06 first col mean 5.420032266556518e-06 all mean 9.74481736193411e-06
rl training, epoch7, iter0, batch776/1133, batch loss:3.928637681838154e-08, Training time:217147.6807694435
batch reward last col mean 6.603770998481195e-06 first col mean 7.16410750101204e-06 all mean 8.39371386973653e-06
rl training, epoch7, iter0, batch777/1133, batch loss:1.2399769389048743e-07, Training time:217174.09671211243
batch reward last col mean 4.504340012090324e-09 first col mean 1.7474281776230782e-05 all mean 1.8093432174737245e-07
rl training, epoch7, iter0, batch778/1133, batch loss:2.64611915712365e-10, Training time:217200.43271398544
batch reward last col mean 4.325002862515248e-07 first col mean 1.270039410883328e-05 all mean 5.724450602428988e-07
rl training, epoch7, iter0, batch779/1133, batch loss:2.6281357090596202e-09, Training time:217227.0090239048
batch reward last col mean 2.672108166734688e-06 first col mean 2.5882745831040666e-06 all mean 2.6716713819041615e-06
rl training, epoch7, iter0, batch780/1133, batch loss:1.583065944998907e-08, Training time:217253.86436009407
batch reward last col mean 8.404752406931948e-06 first col mean 4.6648160605400335e-06 all mean 8.367614100279752e-06
rl training, epoch7, iter0, batch781/1133, batch loss:5.3275332589919344e-08, Training time:217280.52649235725
batch reward last col mean 2.977314761665184e-05 first col mean 1.0038194886874408e-05 all mean 2.960842539323494e-05
rl training, epoch7, iter0, batch782/1133, batch loss:1.6987405615509488e-06, Training time:217306.94788575172
batch reward last col mean 8.365372195839882e-05 first col mean 7.041064964141697e-05 all mean 8.671628893353045e-05
rl training, epoch7, iter0, batch783/1133, batch loss:1.4016501381775015e-07, Training time:217333.85647630692
batch reward last col mean 3.0398110538953915e-05 first col mean 1.1607288797677029e-05 all mean 3.0597755539929494e-05
rl training, epoch7, iter0, batch784/1133, batch loss:4.130037893901317e-07, Training time:217361.03081011772
batch reward last col mean 2.8987278710701503e-06 first col mean 5.606329796137288e-05 all mean 3.5928230772697134e-06
rl training, epoch7, iter0, batch785/1133, batch loss:9.751988550021906e-09, Training time:217387.77492666245
batch reward last col mean 2.7511673579283524e-06 first col mean 8.260518370661885e-06 all mean 2.807311375363497e-06
rl training, epoch7, iter0, batch786/1133, batch loss:5.480705222993265e-09, Training time:217414.049441576
batch reward last col mean 3.4456206776667386e-07 first col mean 2.3945432985783555e-05 all mean 9.250727998733055e-06
rl training, epoch7, iter0, batch787/1133, batch loss:3.3141545063841704e-09, Training time:217440.30309462547
batch reward last col mean 7.719811037532054e-06 first col mean 0.0016247871099039912 all mean 2.4056091206148267e-05
rl training, epoch7, iter0, batch788/1133, batch loss:2.2043970204776997e-07, Training time:217466.71726608276
batch reward last col mean 7.259468020492932e-06 first col mean 7.833017662051134e-06 all mean 7.26912139725755e-06
rl training, epoch7, iter0, batch789/1133, batch loss:5.962277782600722e-09, Training time:217493.23733782768
batch reward last col mean 2.734251893343753e-06 first col mean 1.6548701751162298e-05 all mean 5.622910975944251e-06
rl training, epoch7, iter0, batch790/1133, batch loss:2.0363522423849645e-08, Training time:217519.4374577999
batch reward last col mean 2.568058334873058e-06 first col mean 1.0047790055978112e-05 all mean 3.130497589154402e-06
rl training, epoch7, iter0, batch791/1133, batch loss:2.216281558276023e-08, Training time:217545.6219625473
batch reward last col mean 3.6611687391996384e-05 first col mean 2.3437829440808855e-05 all mean 4.206694575259462e-05
rl training, epoch7, iter0, batch792/1133, batch loss:2.8880563718303165e-07, Training time:217572.0682003498
batch reward last col mean 1.857439383456949e-05 first col mean 1.63622826221399e-05 all mean 1.857894858403597e-05
rl training, epoch7, iter0, batch793/1133, batch loss:2.357199768709961e-08, Training time:217598.3875362873
batch reward last col mean 1.3374716218095273e-05 first col mean 9.828515430854168e-06 all mean 1.428054747520946e-05
rl training, epoch7, iter0, batch794/1133, batch loss:8.882054913783577e-08, Training time:217624.47696352005
batch reward last col mean 1.3187792546887067e-06 first col mean 3.541328987921588e-05 all mean 1.6631678363410174e-06
rl training, epoch7, iter0, batch795/1133, batch loss:5.642754263845973e-09, Training time:217650.65156555176
batch reward last col mean 0.00010137443314306438 first col mean 9.419114940101281e-05 all mean 0.00010129925794899464
rl training, epoch7, iter0, batch796/1133, batch loss:7.268363333423622e-07, Training time:217676.71581840515
batch reward last col mean 1.7564728693741927e-07 first col mean 2.678874079720117e-05 all mean 8.011383215489332e-06
rl training, epoch7, iter0, batch797/1133, batch loss:7.162794357640223e-09, Training time:217702.898771286
batch reward last col mean 0.00012891733786091208 first col mean 5.9459011936269235e-06 all mean 4.847639502258971e-05
rl training, epoch7, iter0, batch798/1133, batch loss:1.4788671251153573e-05, Training time:217728.96603012085
batch reward last col mean 1.8537376718086307e-06 first col mean 3.76383172806527e-06 all mean 3.855776594718918e-05
rl training, epoch7, iter0, batch799/1133, batch loss:1.8583246941261677e-08, Training time:217755.27676153183
batch reward last col mean 3.9098162233131006e-05 first col mean 2.3336888261837885e-05 all mean 3.968313831137493e-05
rl training, epoch7, iter0, batch800/1133, batch loss:1.736043913069807e-07, Training time:217781.43150806427
batch reward last col mean 5.7026700233109295e-05 first col mean 0.00022121066285762936 all mean 8.129004709189758e-05
rl training, epoch7, iter0, batch801/1133, batch loss:2.1992143217630655e-07, Training time:217807.9688835144
batch reward last col mean 9.905397746479139e-06 first col mean 6.656070127064595e-06 all mean 1.0163559636566788e-05
rl training, epoch7, iter0, batch802/1133, batch loss:3.8034752236626446e-08, Training time:217834.29231405258
batch reward last col mean 4.286666353436885e-06 first col mean 3.681436282931827e-06 all mean 4.355350483820075e-06
rl training, epoch7, iter0, batch803/1133, batch loss:2.292107659229714e-08, Training time:217860.7140235901
batch reward last col mean 1.1740290574380197e-05 first col mean 3.671287231554743e-06 all mean 1.189820068248082e-05
rl training, epoch7, iter0, batch804/1133, batch loss:1.0666030902939383e-07, Training time:217887.0713338852
batch reward last col mean 6.58552089589648e-05 first col mean 2.3446493287337944e-05 all mean 7.157233631005511e-05
rl training, epoch7, iter0, batch805/1133, batch loss:5.058736860519275e-07, Training time:217913.63414740562
batch reward last col mean 2.0565741579048336e-05 first col mean 2.063006286334712e-05 all mean 2.834037150023505e-05
rl training, epoch7, iter0, batch806/1133, batch loss:1.0787995563532604e-07, Training time:217939.80000662804
batch reward last col mean 5.584267910307972e-06 first col mean 6.398035452548356e-07 all mean 5.534324827749515e-06
rl training, epoch7, iter0, batch807/1133, batch loss:1.3220835626270855e-07, Training time:217966.08334708214
batch reward last col mean 7.040569585115009e-07 first col mean 2.3602058263350045e-06 all mean 8.058559615164995e-06
rl training, epoch7, iter0, batch808/1133, batch loss:1.200087917929693e-09, Training time:217992.18716192245
batch reward last col mean 7.016265954007395e-06 first col mean 8.508498467563186e-06 all mean 7.070267201925162e-06
rl training, epoch7, iter0, batch809/1133, batch loss:1.8569192405948343e-08, Training time:218018.31596279144
batch reward last col mean 1.1035990610253066e-05 first col mean 8.946254638431128e-06 all mean 1.1014883966709021e-05
rl training, epoch7, iter0, batch810/1133, batch loss:9.00598848829759e-08, Training time:218044.40887141228
batch reward last col mean 8.961068488133606e-06 first col mean 2.0954463252564892e-05 all mean 9.089171726373024e-06
rl training, epoch7, iter0, batch811/1133, batch loss:6.003726582548552e-08, Training time:218071.00185251236
batch reward last col mean 3.109241333731916e-06 first col mean 2.086432505166158e-05 all mean 3.47079117091198e-06
rl training, epoch7, iter0, batch812/1133, batch loss:2.3968240725480427e-08, Training time:218097.25213861465
batch reward last col mean 7.551470844191499e-06 first col mean 7.705320058448706e-06 all mean 7.561385700682877e-06
rl training, epoch7, iter0, batch813/1133, batch loss:8.281948993271726e-08, Training time:218123.75627064705
batch reward last col mean 4.5546690330411366e-07 first col mean 1.6459233620480518e-06 all mean 1.0154252777283546e-05
rl training, epoch7, iter0, batch814/1133, batch loss:1.0324435750774796e-09, Training time:218150.12646007538
batch reward last col mean 6.584427865163889e-07 first col mean 3.0403184609895106e-06 all mean 7.184383434832853e-07
rl training, epoch7, iter0, batch815/1133, batch loss:5.646921596991206e-09, Training time:218176.79736185074
batch reward last col mean 1.7504684365121648e-05 first col mean 7.327039929805323e-05 all mean 1.8116850696969777e-05
rl training, epoch7, iter0, batch816/1133, batch loss:1.5172803102814214e-07, Training time:218203.2440445423
batch reward last col mean 7.426840056723449e-06 first col mean 6.963083251321223e-06 all mean 7.66495486459462e-06
rl training, epoch7, iter0, batch817/1133, batch loss:6.672096475313083e-08, Training time:218229.5100288391
batch reward last col mean 6.493233286164468e-06 first col mean 5.3271032811608166e-06 all mean 9.915662303683348e-06
rl training, epoch7, iter0, batch818/1133, batch loss:2.1119654913803743e-09, Training time:218255.66058301926
batch reward last col mean 4.45686855528038e-05 first col mean 1.2807440725737251e-05 all mean 4.424789221957326e-05
rl training, epoch7, iter0, batch819/1133, batch loss:1.3100471107918565e-07, Training time:218282.0808339119
batch reward last col mean 4.4791577238356695e-06 first col mean 8.383023669011891e-06 all mean 4.520049060374731e-06
rl training, epoch7, iter0, batch820/1133, batch loss:3.466808706775737e-08, Training time:218308.17987823486
batch reward last col mean 1.6470476111862808e-06 first col mean 6.398763161996612e-06 all mean 3.97827943743323e-06
rl training, epoch7, iter0, batch821/1133, batch loss:8.125046413454129e-09, Training time:218334.2921040058
batch reward last col mean 7.539601938333362e-05 first col mean 1.0987939276674297e-05 all mean 7.474554877262563e-05
rl training, epoch7, iter0, batch822/1133, batch loss:4.299227839510422e-06, Training time:218360.62652349472
batch reward last col mean 1.3223216228652745e-05 first col mean 1.8479595382814296e-05 all mean 1.3282862710184418e-05
rl training, epoch7, iter0, batch823/1133, batch loss:9.811572709850225e-08, Training time:218386.8808259964
batch reward last col mean 3.535716678015888e-05 first col mean 3.857043702737428e-05 all mean 3.5528631997294724e-05
rl training, epoch7, iter0, batch824/1133, batch loss:1.4847050522348582e-07, Training time:218413.40211296082
batch reward last col mean 1.6707608665456064e-06 first col mean 8.718177014088724e-06 all mean 1.9937867818953237e-06
rl training, epoch7, iter0, batch825/1133, batch loss:3.2031890473405156e-09, Training time:218439.6188902855
batch reward last col mean 1.2257682101335377e-05 first col mean 9.47577973420266e-06 all mean 2.241676702396944e-05
rl training, epoch7, iter0, batch826/1133, batch loss:4.2444605696800863e-07, Training time:218465.85743165016
batch reward last col mean 5.0127029680879787e-05 first col mean 4.86140743305441e-05 all mean 5.5654236348345876e-05
rl training, epoch7, iter0, batch827/1133, batch loss:1.336723869371781e-07, Training time:218492.22934794426
batch reward last col mean 7.954162720125169e-05 first col mean 9.613695874577388e-05 all mean 7.970929436851293e-05
rl training, epoch7, iter0, batch828/1133, batch loss:7.172986329351261e-07, Training time:218518.41032600403
batch reward last col mean 2.386073538218625e-05 first col mean 3.4245340430061333e-06 all mean 2.4510874936822802e-05
rl training, epoch7, iter0, batch829/1133, batch loss:1.9857188249261526e-07, Training time:218544.77690577507
batch reward last col mean 5.486961981659988e-06 first col mean 7.371367246378213e-06 all mean 5.694087576557649e-06
rl training, epoch7, iter0, batch830/1133, batch loss:7.564400306137031e-08, Training time:218571.07607460022
batch reward last col mean 0.00010885469237109646 first col mean 4.479512426769361e-05 all mean 0.00010826827929122373
rl training, epoch7, iter0, batch831/1133, batch loss:1.6731353014165506e-07, Training time:218597.43809223175
batch reward last col mean 3.4519252949394286e-05 first col mean 8.131717913784087e-05 all mean 3.6752160667674616e-05
rl training, epoch7, iter0, batch832/1133, batch loss:1.1865413540590453e-07, Training time:218623.83586406708
batch reward last col mean 6.3929505813575815e-06 first col mean 6.617615781578934e-06 all mean 2.5351051590405405e-05
rl training, epoch7, iter0, batch833/1133, batch loss:5.103590083876952e-08, Training time:218650.35593509674
batch reward last col mean 0.0005715084262192249 first col mean 3.204860149708111e-06 all mean 0.0005602980381809175
rl training, epoch7, iter0, batch834/1133, batch loss:4.154417911195196e-05, Training time:218676.5325729847
batch reward last col mean 1.9347806301084347e-05 first col mean 1.799044548533857e-05 all mean 1.944756877492182e-05
rl training, epoch7, iter0, batch835/1133, batch loss:8.054365707721445e-08, Training time:218702.79441785812
batch reward last col mean 1.0100735380547121e-05 first col mean 1.0570460290182382e-05 all mean 1.1833973985631019e-05
rl training, epoch7, iter0, batch836/1133, batch loss:4.7430425809125154e-08, Training time:218729.18041419983
batch reward last col mean 1.3457487568757642e-07 first col mean 2.540684135965421e-06 all mean 1.6305934025240276e-07
rl training, epoch7, iter0, batch837/1133, batch loss:8.855443045518996e-10, Training time:218755.31309771538
batch reward last col mean 2.0748248061863706e-05 first col mean 2.4887596737244166e-05 all mean 2.0790430426131934e-05
rl training, epoch7, iter0, batch838/1133, batch loss:3.098596721429203e-07, Training time:218781.67361330986
batch reward last col mean 6.599591273470651e-08 first col mean 5.525318192667328e-05 all mean 6.223551167749974e-07
rl training, epoch7, iter0, batch839/1133, batch loss:4.5753938415771245e-09, Training time:218807.7138748169
batch reward last col mean 2.678343662410043e-06 first col mean 5.817958935949719e-06 all mean 2.8073434350517346e-06
rl training, epoch7, iter0, batch840/1133, batch loss:1.368354229924762e-08, Training time:218833.88659763336
batch reward last col mean 3.7397239793790504e-06 first col mean 3.788910817092983e-06 all mean 3.740197826118674e-06
rl training, epoch7, iter0, batch841/1133, batch loss:8.466812140284219e-09, Training time:218860.1549038887
batch reward last col mean 2.2549684217665344e-05 first col mean 1.1768423064495437e-05 all mean 2.3769040126353502e-05
rl training, epoch7, iter0, batch842/1133, batch loss:1.3664626408171898e-07, Training time:218886.47045326233
batch reward last col mean 2.04324487640406e-06 first col mean 2.4681548893568106e-06 all mean 2.047537009275402e-06
rl training, epoch7, iter0, batch843/1133, batch loss:7.188471329300228e-08, Training time:218912.74136471748
batch reward last col mean 7.322983947233297e-06 first col mean 3.47960963154037e-06 all mean 7.486127287847921e-06
rl training, epoch7, iter0, batch844/1133, batch loss:1.0928189908554486e-07, Training time:218938.9533343315
batch reward last col mean 8.174583854270168e-06 first col mean 1.1007448847522028e-05 all mean 1.197094297822332e-05
rl training, epoch7, iter0, batch845/1133, batch loss:6.160853160963597e-08, Training time:218965.30730438232
batch reward last col mean 6.038965693733189e-06 first col mean 6.380994364008075e-06 all mean 6.0495644902403e-06
rl training, epoch7, iter0, batch846/1133, batch loss:1.8043367910891561e-09, Training time:218991.63322138786
batch reward last col mean 1.0586516509647481e-05 first col mean 6.283202765189344e-06 all mean 1.4384462701855227e-05
rl training, epoch7, iter0, batch847/1133, batch loss:4.982854306945228e-08, Training time:219017.97890257835
batch reward last col mean 4.3171834818167554e-07 first col mean 5.640870767820161e-06 all mean 4.871162673225626e-07
rl training, epoch7, iter0, batch848/1133, batch loss:1.0489288548853892e-08, Training time:219044.08943009377
batch reward last col mean 1.1986213394266088e-05 first col mean 6.299530014075572e-06 all mean 1.2009096280962694e-05
rl training, epoch7, iter0, batch849/1133, batch loss:2.1241356762402575e-07, Training time:219070.50726675987
batch reward last col mean 4.735885795525974e-06 first col mean 1.4162292245600838e-06 all mean 1.4141892279440071e-05
rl training, epoch7, iter0, batch850/1133, batch loss:2.4322517333530413e-07, Training time:219096.79065680504
batch reward last col mean 3.6561839351634262e-06 first col mean 8.653746590425726e-06 all mean 3.7122349567653146e-06
rl training, epoch7, iter0, batch851/1133, batch loss:3.667335590762377e-08, Training time:219123.25967621803
batch reward last col mean 1.6283323702737107e-06 first col mean 5.738007985200966e-06 all mean 1.7554301621203194e-06
rl training, epoch7, iter0, batch852/1133, batch loss:3.569285311755266e-09, Training time:219149.27246761322
batch reward last col mean 5.566853724303655e-05 first col mean 5.511221388587728e-05 all mean 5.5802920542191714e-05
rl training, epoch7, iter0, batch853/1133, batch loss:4.1606978129493655e-07, Training time:219175.65381383896
batch reward last col mean 3.317923619761132e-05 first col mean 1.7774427760741673e-05 all mean 3.476668643997982e-05
rl training, epoch7, iter0, batch854/1133, batch loss:5.642138489747595e-07, Training time:219202.08869719505
batch reward last col mean 1.7295778889092617e-05 first col mean 1.9347316992934793e-05 all mean 1.7355156160192564e-05
rl training, epoch7, iter0, batch855/1133, batch loss:4.3067970523225085e-08, Training time:219228.39327168465
batch reward last col mean 8.100020932033658e-05 first col mean 6.013646270730533e-06 all mean 5.909012179472484e-05
rl training, epoch7, iter0, batch856/1133, batch loss:7.353765795414802e-06, Training time:219254.57685256004
batch reward last col mean 1.0105499313795008e-05 first col mean 3.401035428396426e-05 all mean 1.042840722220717e-05
rl training, epoch7, iter0, batch857/1133, batch loss:5.1259799960234886e-08, Training time:219280.97007918358
batch reward last col mean 3.4382662761345273e-07 first col mean 0.00010393927368568256 all mean 3.567066187315504e-06
rl training, epoch7, iter0, batch858/1133, batch loss:2.0085930696467358e-09, Training time:219307.21132588387
batch reward last col mean 7.597448075102875e-07 first col mean 1.9952563889091834e-05 all mean 1.3896150221626158e-06
rl training, epoch7, iter0, batch859/1133, batch loss:9.957605406896164e-09, Training time:219333.53118658066
batch reward last col mean 6.028466827956436e-07 first col mean 1.157456063083373e-05 all mean 1.7438374925404787e-05
rl training, epoch7, iter0, batch860/1133, batch loss:1.166881258285457e-09, Training time:219359.63498735428
batch reward last col mean 1.609120772627648e-05 first col mean 1.4036262655281462e-05 all mean 2.3745658836560324e-05
rl training, epoch7, iter0, batch861/1133, batch loss:3.7392094753840865e-08, Training time:219385.86187887192
batch reward last col mean 7.011945854173973e-06 first col mean 1.074406009138329e-05 all mean 7.049644409562461e-06
rl training, epoch7, iter0, batch862/1133, batch loss:4.251450036463211e-08, Training time:219412.10447478294
batch reward last col mean 3.441625722189201e-06 first col mean 1.985157905437518e-05 all mean 4.3591744542936794e-06
rl training, epoch7, iter0, batch863/1133, batch loss:9.073525930602955e-09, Training time:219438.847530365
batch reward last col mean 1.744107430567965e-05 first col mean 6.501473308162531e-06 all mean 1.8777043806039728e-05
rl training, epoch7, iter0, batch864/1133, batch loss:4.165655695942405e-07, Training time:219465.0355234146
batch reward last col mean 8.086587331490591e-05 first col mean 1.5220420209516305e-05 all mean 8.254741260316223e-05
rl training, epoch7, iter0, batch865/1133, batch loss:1.24897326259088e-06, Training time:219491.4773261547
batch reward last col mean 6.548135615958017e-07 first col mean 1.079047524399357e-05 all mean 7.613467118972039e-07
rl training, epoch7, iter0, batch866/1133, batch loss:1.4576145845879296e-09, Training time:219517.53452324867
batch reward last col mean 2.521504939068109e-06 first col mean 1.332812462351285e-05 all mean 3.3810167678893777e-06
rl training, epoch7, iter0, batch867/1133, batch loss:6.850108036360325e-09, Training time:219543.7620165348
batch reward last col mean 3.0209330361685716e-06 first col mean 6.2299063756654505e-06 all mean 3.076112534472486e-06
rl training, epoch7, iter0, batch868/1133, batch loss:7.840089466526479e-09, Training time:219570.13245368004
batch reward last col mean 1.2460147900128504e-06 first col mean 1.3052585018158425e-05 all mean 1.3652653478857246e-06
rl training, epoch7, iter0, batch869/1133, batch loss:9.043584547896444e-09, Training time:219596.50290298462
batch reward last col mean 9.147813216259237e-06 first col mean 7.0892710937187076e-06 all mean 4.212150815874338e-05
rl training, epoch7, iter0, batch870/1133, batch loss:2.5701442751824288e-08, Training time:219622.81196904182
batch reward last col mean 3.012994238815736e-05 first col mean 8.516483831044752e-06 all mean 3.05085486616008e-05
rl training, epoch7, iter0, batch871/1133, batch loss:1.1226001106479089e-07, Training time:219649.1431877613
batch reward last col mean 2.894879798986949e-06 first col mean 6.659261998720467e-06 all mean 2.048913984253886e-06
rl training, epoch7, iter0, batch872/1133, batch loss:1.9705402110048453e-07, Training time:219675.40757608414
batch reward last col mean 1.314551627729088e-05 first col mean 4.523911684373161e-06 all mean 1.305843034060672e-05
rl training, epoch7, iter0, batch873/1133, batch loss:3.8832698834312396e-08, Training time:219701.79674959183
batch reward last col mean 2.7326134386385093e-06 first col mean 2.7165083338331897e-06 all mean 3.1839688290347112e-06
rl training, epoch7, iter0, batch874/1133, batch loss:1.7924213224773666e-08, Training time:219727.96280050278
batch reward last col mean 7.532514246122446e-06 first col mean 4.916942543786718e-06 all mean 7.5821935752173886e-06
rl training, epoch7, iter0, batch875/1133, batch loss:8.559248243500406e-08, Training time:219754.45276355743
batch reward last col mean 1.1154494131915271e-05 first col mean 1.240726669493597e-05 all mean 1.5262972738128155e-05
rl training, epoch7, iter0, batch876/1133, batch loss:6.451812595287265e-08, Training time:219780.53496479988
batch reward last col mean 1.0940559604932787e-06 first col mean 3.9965329960978124e-06 all mean 2.104422947013518e-06
rl training, epoch7, iter0, batch877/1133, batch loss:5.189677021455452e-10, Training time:219806.83127355576
batch reward last col mean 1.097057611332275e-05 first col mean 5.939521543041337e-06 all mean 1.517033888376318e-05
rl training, epoch7, iter0, batch878/1133, batch loss:5.2410182860285204e-08, Training time:219832.9591667652
batch reward last col mean 1.8312721294932999e-06 first col mean 5.877042440260993e-06 all mean 1.8721389096754137e-06
rl training, epoch7, iter0, batch879/1133, batch loss:1.9401898754267677e-08, Training time:219859.28440499306
batch reward last col mean 1.3843752640241291e-05 first col mean 1.9690745830303058e-05 all mean 2.1463680241140537e-05
rl training, epoch7, iter0, batch880/1133, batch loss:3.0797817629490964e-08, Training time:219885.4967007637
batch reward last col mean 4.247267952450784e-06 first col mean 5.979058641969459e-06 all mean 2.0185090761515312e-05
rl training, epoch7, iter0, batch881/1133, batch loss:1.5871188807636827e-08, Training time:219911.92530488968
batch reward last col mean 6.235398359422106e-06 first col mean 4.9560385377844796e-06 all mean 8.253819032688625e-06
rl training, epoch7, iter0, batch882/1133, batch loss:2.1762415869375218e-08, Training time:219938.25313210487
batch reward last col mean 9.958242799257278e-07 first col mean 2.7025344024877995e-05 all mean 1.5093696674739476e-06
rl training, epoch7, iter0, batch883/1133, batch loss:2.1088342183617215e-09, Training time:219964.55722665787
batch reward last col mean 4.269753389962716e-06 first col mean 4.22023191504195e-07 all mean 4.884059762844117e-06
rl training, epoch7, iter0, batch884/1133, batch loss:1.2612655098109826e-07, Training time:219990.63849043846
batch reward last col mean 6.682493676635204e-06 first col mean 7.306431371034705e-07 all mean 7.970930710143875e-06
rl training, epoch7, iter0, batch885/1133, batch loss:7.098639542846286e-08, Training time:220016.77057003975
batch reward last col mean 6.063710316084325e-05 first col mean 7.214583456516266e-05 all mean 6.360917905112728e-05
rl training, epoch7, iter0, batch886/1133, batch loss:2.320444764336571e-06, Training time:220043.07195687294
batch reward last col mean 2.197433241235558e-05 first col mean 1.395160325046163e-05 all mean 2.1893365556024946e-05
rl training, epoch7, iter0, batch887/1133, batch loss:2.4923818386923813e-07, Training time:220069.45554947853
batch reward last col mean 4.411180634633638e-05 first col mean 7.455375907738926e-06 all mean 4.748161882162094e-05
rl training, epoch7, iter0, batch888/1133, batch loss:1.4588607655241503e-06, Training time:220095.78054714203
batch reward last col mean 3.2653471862431616e-05 first col mean 9.987612429540604e-06 all mean 3.243851097067818e-05
rl training, epoch7, iter0, batch889/1133, batch loss:1.0793562523758737e-06, Training time:220122.21330976486
batch reward last col mean 1.0067012226500083e-05 first col mean 1.5087278370629065e-05 all mean 1.4959090549382381e-05
rl training, epoch7, iter0, batch890/1133, batch loss:1.1438444147415794e-07, Training time:220149.1520075798
batch reward last col mean 1.804623934731353e-05 first col mean 5.560451972996816e-05 all mean 1.8434773664921522e-05
rl training, epoch7, iter0, batch891/1133, batch loss:1.5951735576891224e-07, Training time:220175.58009457588
batch reward last col mean 7.087982680786808e-07 first col mean 2.4267652406706475e-05 all mean 9.467940458307567e-07
rl training, epoch7, iter0, batch892/1133, batch loss:8.769736603575495e-10, Training time:220201.6634335518
batch reward last col mean 3.974548963014968e-05 first col mean 0.00021237347391434014 all mean 4.149035885347985e-05
rl training, epoch7, iter0, batch893/1133, batch loss:1.4918672519570464e-08, Training time:220228.26220583916
batch reward last col mean 0.00010004916839534417 first col mean 3.475829362287186e-05 all mean 9.864961612038314e-05
rl training, epoch7, iter0, batch894/1133, batch loss:4.301563876651926e-06, Training time:220254.56676602364
batch reward last col mean 4.717875526694115e-06 first col mean 2.4911629225243814e-05 all mean 5.300943939801073e-06
rl training, epoch7, iter0, batch895/1133, batch loss:2.2324925907923898e-08, Training time:220280.77266836166
batch reward last col mean 2.159050382033456e-05 first col mean 2.9663677196367644e-05 all mean 2.265561488457024e-05
rl training, epoch7, iter0, batch896/1133, batch loss:8.154809449933964e-08, Training time:220306.84664011002
batch reward last col mean 2.4897339244489558e-05 first col mean 7.664332770218607e-06 all mean 2.4635632144054398e-05
rl training, epoch7, iter0, batch897/1133, batch loss:5.837333105773723e-07, Training time:220333.2650141716
batch reward last col mean 2.890125756493944e-07 first col mean 3.7999172491254285e-05 all mean 1.550235174363479e-05
rl training, epoch7, iter0, batch898/1133, batch loss:2.3974380258806605e-09, Training time:220359.3701517582
batch reward last col mean 1.1712474588421173e-05 first col mean 1.4333549188449979e-05 all mean 1.1813369383162353e-05
rl training, epoch7, iter0, batch899/1133, batch loss:6.872962643456049e-08, Training time:220385.59719467163
batch reward last col mean 1.2495683222368825e-05 first col mean 0.0001662990398472175 all mean 1.4059226487006526e-05
rl training, epoch7, iter0, batch900/1133, batch loss:6.04324341679785e-08, Training time:220411.77689671516
batch reward last col mean 4.720556262327591e-06 first col mean 4.396575968712568e-05 all mean 5.176294507691637e-06
rl training, epoch7, iter0, batch901/1133, batch loss:1.642533575818561e-08, Training time:220438.00750875473
batch reward last col mean 1.1316169548081234e-05 first col mean 8.515889931004494e-06 all mean 1.1271184121142142e-05
rl training, epoch7, iter0, batch902/1133, batch loss:1.6764175825301209e-07, Training time:220464.17538022995
batch reward last col mean 1.873317341960501e-05 first col mean 9.72250745689962e-06 all mean 1.8663415175979026e-05
rl training, epoch7, iter0, batch903/1133, batch loss:1.877803867955663e-07, Training time:220490.59564065933
batch reward last col mean 7.554835519840708e-06 first col mean 9.933622095559258e-06 all mean 7.64587184676202e-06
rl training, epoch7, iter0, batch904/1133, batch loss:6.780552563867559e-09, Training time:220516.78389406204
batch reward last col mean 1.033643820846919e-05 first col mean 7.966873454279266e-06 all mean 1.1153309969813563e-05
rl training, epoch7, iter0, batch905/1133, batch loss:2.705635893107683e-08, Training time:220543.17837405205
batch reward last col mean 7.640826879651286e-06 first col mean 3.7964223338349257e-06 all mean 7.52409323467873e-06
rl training, epoch7, iter0, batch906/1133, batch loss:9.59103317654808e-07, Training time:220569.3537583351
batch reward last col mean 3.912010924977949e-06 first col mean 2.0807638065889478e-06 all mean 2.3387065084534697e-05
rl training, epoch7, iter0, batch907/1133, batch loss:1.4093586742092157e-07, Training time:220595.74771165848
batch reward last col mean 9.981450602936093e-06 first col mean 3.2596981327515095e-05 all mean 1.0211786502623e-05
rl training, epoch7, iter0, batch908/1133, batch loss:7.241407473657091e-08, Training time:220621.8324792385
batch reward last col mean 7.193281817308161e-06 first col mean 4.899956820736406e-06 all mean 7.827281478967052e-06
rl training, epoch7, iter0, batch909/1133, batch loss:2.1381072201620555e-07, Training time:220648.42558193207
batch reward last col mean 8.980934580904432e-06 first col mean 5.626211532216985e-06 all mean 1.2136340046708938e-05
rl training, epoch7, iter0, batch910/1133, batch loss:2.0097752795322776e-08, Training time:220674.92250299454
batch reward last col mean 1.6506362953805365e-05 first col mean 2.7258653062744997e-05 all mean 2.980025965371169e-05
rl training, epoch7, iter0, batch911/1133, batch loss:8.183473454437262e-08, Training time:220701.43560028076
batch reward last col mean 1.5491510566789657e-05 first col mean 5.5390687521139625e-06 all mean 1.539094046165701e-05
rl training, epoch7, iter0, batch912/1133, batch loss:1.9544029328244505e-07, Training time:220728.03201508522
batch reward last col mean 1.8509921574150212e-05 first col mean 1.6394560589105822e-05 all mean 1.849324871727731e-05
rl training, epoch7, iter0, batch913/1133, batch loss:1.8811945778907102e-08, Training time:220754.30565333366
batch reward last col mean 5.178412266104715e-06 first col mean 0.00038106777356006205 all mean 9.188122021441814e-06
rl training, epoch7, iter0, batch914/1133, batch loss:3.899558720377172e-08, Training time:220780.75239014626
batch reward last col mean 1.7380318240611814e-05 first col mean 1.6669258911861107e-05 all mean 1.7530684999655932e-05
rl training, epoch7, iter0, batch915/1133, batch loss:8.045667954093005e-08, Training time:220807.06090426445
batch reward last col mean 7.198528351182176e-07 first col mean 6.502769974758849e-05 all mean 1.369794176753203e-06
rl training, epoch7, iter0, batch916/1133, batch loss:1.5509690198811654e-09, Training time:220833.0632505417
batch reward last col mean 2.2146652554511093e-05 first col mean 2.2439828171627596e-05 all mean 3.300000025774352e-05
rl training, epoch7, iter0, batch917/1133, batch loss:3.968972350776312e-08, Training time:220859.66163897514
batch reward last col mean 2.939388286904432e-05 first col mean 6.16920897300588e-06 all mean 2.9161774364183657e-05
rl training, epoch7, iter0, batch918/1133, batch loss:4.528179999852e-07, Training time:220886.53276085854
batch reward last col mean 4.387013632367598e-07 first col mean 0.00023602432338520885 all mean 4.215713488520123e-06
rl training, epoch7, iter0, batch919/1133, batch loss:3.4218372579886136e-09, Training time:220913.32781910896
batch reward last col mean 9.931723070621956e-06 first col mean 3.267405918450095e-05 all mean 2.644555388542358e-05
rl training, epoch7, iter0, batch920/1133, batch loss:3.6848351214757713e-07, Training time:220940.39806437492
batch reward last col mean 1.6051817510742694e-06 first col mean 5.797939138574293e-06 all mean 1.6475312349939486e-06
rl training, epoch7, iter0, batch921/1133, batch loss:1.0014547413561559e-08, Training time:220967.26004338264
batch reward last col mean 2.697157469810918e-06 first col mean 8.060836080403533e-06 all mean 1.701102519291453e-05
rl training, epoch7, iter0, batch922/1133, batch loss:1.079711111628967e-07, Training time:220993.79075455666
batch reward last col mean 2.001382745220326e-05 first col mean 6.703686267428566e-06 all mean 1.988027543120552e-05
rl training, epoch7, iter0, batch923/1133, batch loss:8.340029467035492e-08, Training time:221020.64879131317
batch reward last col mean 2.59967509919079e-06 first col mean 0.0002849444281309843 all mean 1.4023428775544744e-05
rl training, epoch7, iter0, batch924/1133, batch loss:1.1455248305480836e-08, Training time:221047.19193792343
batch reward last col mean 3.786932666116627e-06 first col mean 2.2627382350037806e-06 all mean 7.122907391021727e-06
rl training, epoch7, iter0, batch925/1133, batch loss:6.517813488926549e-08, Training time:221074.35077881813
batch reward last col mean 1.4002438547322527e-05 first col mean 1.557048744871281e-05 all mean 2.0637569832615554e-05
rl training, epoch7, iter0, batch926/1133, batch loss:7.232416265878783e-08, Training time:221101.15938949585
batch reward last col mean 7.5211328294244595e-06 first col mean 6.261226189963054e-06 all mean 7.508310773118865e-06
rl training, epoch7, iter0, batch927/1133, batch loss:2.8082299152742962e-08, Training time:221127.68938732147
batch reward last col mean 0.0003696159110404551 first col mean 3.6845853173872456e-05 all mean 0.00036663448554463685
rl training, epoch7, iter0, batch928/1133, batch loss:1.904588316392619e-05, Training time:221154.36439990997
batch reward last col mean 4.93160996484221e-06 first col mean 1.5199520930764265e-05 all mean 5.0404987632646225e-06
rl training, epoch7, iter0, batch929/1133, batch loss:6.20068263401663e-08, Training time:221181.0144929886
batch reward last col mean 2.0568270429066615e-06 first col mean 2.7900848635908915e-06 all mean 3.274166829214664e-06
rl training, epoch7, iter0, batch930/1133, batch loss:2.0512556986318486e-08, Training time:221207.7148964405
batch reward last col mean 1.990157579712104e-05 first col mean 1.6042906281654723e-05 all mean 2.0309835235821083e-05
rl training, epoch7, iter0, batch931/1133, batch loss:7.079782449181948e-08, Training time:221234.4538986683
batch reward last col mean 1.0380676940258127e-06 first col mean 1.3660620425071102e-05 all mean 6.133939677965827e-06
rl training, epoch7, iter0, batch932/1133, batch loss:1.2836235185886835e-08, Training time:221261.6765897274
batch reward last col mean 2.169739445889718e-06 first col mean 1.6293646694975905e-05 all mean 1.711796357994899e-05
rl training, epoch7, iter0, batch933/1133, batch loss:3.068333143119162e-08, Training time:221288.44473409653
batch reward last col mean 1.428436917194631e-05 first col mean 1.6541660443181172e-05 all mean 1.7619315258343704e-05
rl training, epoch7, iter0, batch934/1133, batch loss:7.675272684082302e-08, Training time:221315.61979675293
batch reward last col mean 3.2513435144210234e-05 first col mean 1.6601066818111576e-05 all mean 3.411540455999784e-05
rl training, epoch7, iter0, batch935/1133, batch loss:8.972243676907965e-07, Training time:221342.94605898857
batch reward last col mean 1.3771714293397963e-06 first col mean 2.8389185899868608e-06 all mean 2.5302056201326195e-06
rl training, epoch7, iter0, batch936/1133, batch loss:3.929029990246136e-09, Training time:221369.6768093109
batch reward last col mean 1.5279134402135242e-07 first col mean 6.081152241677046e-05 all mean 4.424471626407467e-06
rl training, epoch7, iter0, batch937/1133, batch loss:2.666326736289193e-06, Training time:221396.43260979652
batch reward last col mean 3.995862243755255e-06 first col mean 8.723050086700823e-06 all mean 4.072153842571424e-06
rl training, epoch7, iter0, batch938/1133, batch loss:2.2736690752367394e-08, Training time:221422.84627723694
batch reward last col mean 2.3062768377712928e-05 first col mean 1.3257684258860536e-05 all mean 2.3030652300803922e-05
rl training, epoch7, iter0, batch939/1133, batch loss:1.6879039321793243e-07, Training time:221449.29675507545
batch reward last col mean 1.750538831402082e-05 first col mean 3.238040517317131e-05 all mean 1.770090420905035e-05
rl training, epoch7, iter0, batch940/1133, batch loss:8.483461755304234e-08, Training time:221475.3836967945
batch reward last col mean 0.00016119865176733583 first col mean 4.7021996579132974e-05 all mean 0.00016403687186539173
rl training, epoch7, iter0, batch941/1133, batch loss:2.0741235857713036e-06, Training time:221501.63153338432
batch reward last col mean 2.345541724935174e-05 first col mean 5.508914910024032e-06 all mean 2.35155184782343e-05
rl training, epoch7, iter0, batch942/1133, batch loss:6.356252697514719e-07, Training time:221528.01828455925
batch reward last col mean 3.1784600196260726e-06 first col mean 6.2242788771982305e-06 all mean 4.992018148186617e-06
rl training, epoch7, iter0, batch943/1133, batch loss:3.9346367830539464e-10, Training time:221554.24979615211
batch reward last col mean 1.1987563084403519e-05 first col mean 1.281040476897033e-05 all mean 1.2016509572276846e-05
rl training, epoch7, iter0, batch944/1133, batch loss:3.9034102172763596e-08, Training time:221580.87888932228
batch reward last col mean 7.143046332203085e-07 first col mean 0.00031416257843375206 all mean 2.361765109526459e-05
rl training, epoch7, iter0, batch945/1133, batch loss:1.295407159318529e-08, Training time:221607.03009533882
batch reward last col mean 4.676003300119191e-06 first col mean 9.134631909546442e-06 all mean 4.721569439425366e-06
rl training, epoch7, iter0, batch946/1133, batch loss:3.2129694460536484e-08, Training time:221633.583466053
batch reward last col mean 1.5814736116226413e-06 first col mean 3.880777967424365e-06 all mean 1.2108812370570377e-05
rl training, epoch7, iter0, batch947/1133, batch loss:4.322536710787972e-07, Training time:221659.87370181084
batch reward last col mean 7.646943231520709e-06 first col mean 6.4715591179265175e-06 all mean 2.179393413825892e-05
rl training, epoch7, iter0, batch948/1133, batch loss:1.0749806023113706e-07, Training time:221686.26527881622
batch reward last col mean 5.606223680842959e-07 first col mean 2.949532245111186e-06 all mean 7.34534808088938e-07
rl training, epoch7, iter0, batch949/1133, batch loss:3.5835292511166017e-09, Training time:221712.53439879417
batch reward last col mean 2.8870072128484026e-06 first col mean 3.516302740536048e-06 all mean 2.3550251171400305e-06
rl training, epoch7, iter0, batch950/1133, batch loss:2.5438325224058644e-07, Training time:221738.56516981125
batch reward last col mean 1.9809589502983727e-05 first col mean 1.9470922779873945e-05 all mean 1.905979479488451e-05
rl training, epoch7, iter0, batch951/1133, batch loss:1.1145854017513557e-07, Training time:221764.91228365898
batch reward last col mean 1.7846456103143282e-05 first col mean 1.359088400931796e-05 all mean 1.780489219527226e-05
rl training, epoch7, iter0, batch952/1133, batch loss:1.1057218074483899e-07, Training time:221791.3870766163
batch reward last col mean 4.471943975659087e-05 first col mean 3.215248943888582e-05 all mean 4.475510286283679e-05
rl training, epoch7, iter0, batch953/1133, batch loss:2.0372526421397197e-07, Training time:221817.77164530754
batch reward last col mean 8.928339411795605e-06 first col mean 2.179041985073127e-05 all mean 2.502501774870325e-05
rl training, epoch7, iter0, batch954/1133, batch loss:4.6066084280482755e-08, Training time:221843.8540275097
batch reward last col mean 3.081874456256628e-05 first col mean 2.3889369913376868e-05 all mean 3.313729393994436e-05
rl training, epoch7, iter0, batch955/1133, batch loss:1.3222923200828518e-07, Training time:221870.14202284813
batch reward last col mean 5.8110022109758575e-06 first col mean 4.175516733084805e-05 all mean 6.2736321524425875e-06
rl training, epoch7, iter0, batch956/1133, batch loss:2.913194796505536e-09, Training time:221896.36822104454
batch reward last col mean 1.6593603504588827e-05 first col mean 1.5311430615838617e-05 all mean 1.6580655938014388e-05
rl training, epoch7, iter0, batch957/1133, batch loss:3.1917966225591954e-07, Training time:221922.55093359947
batch reward last col mean 2.9920891392976046e-05 first col mean 2.165413934562821e-05 all mean 2.9792365239700302e-05
rl training, epoch7, iter0, batch958/1133, batch loss:1.5377902400359744e-06, Training time:221949.15161919594
batch reward last col mean 6.690393661301641e-07 first col mean 8.921807079786959e-07 all mean 6.713236757605046e-07
rl training, epoch7, iter0, batch959/1133, batch loss:7.29475368999033e-09, Training time:221975.33005070686
batch reward last col mean 7.143076459215081e-07 first col mean 6.586911354133917e-07 all mean 2.1021738575655036e-05
rl training, epoch7, iter0, batch960/1133, batch loss:8.649409188876689e-09, Training time:222001.70644068718
batch reward last col mean 2.2265035113377962e-06 first col mean 3.468968088782276e-06 all mean 2.2986655494605657e-06
rl training, epoch7, iter0, batch961/1133, batch loss:8.818595631510107e-09, Training time:222027.90006494522
batch reward last col mean 8.880860150384251e-06 first col mean 2.1011405806348193e-06 all mean 8.735349183552898e-06
rl training, epoch7, iter0, batch962/1133, batch loss:3.326800310787803e-07, Training time:222054.15632224083
batch reward last col mean 1.2295173519305536e-06 first col mean 4.423729023983469e-06 all mean 3.2720924991735956e-06
rl training, epoch7, iter0, batch963/1133, batch loss:3.3263813925543673e-09, Training time:222080.36215949059
batch reward last col mean 1.5908276509435382e-06 first col mean 3.562267011147924e-05 all mean 7.456043476850027e-06
rl training, epoch7, iter0, batch964/1133, batch loss:9.841623516138043e-09, Training time:222106.52158522606
batch reward last col mean 4.6632401790702716e-05 first col mean 1.453353343094932e-05 all mean 4.6320052206283435e-05
rl training, epoch7, iter0, batch965/1133, batch loss:8.019299002626212e-07, Training time:222133.70432257652
batch reward last col mean 4.3855170588358305e-06 first col mean 1.7021754956658697e-06 all mean 2.5544602976879105e-05
rl training, epoch7, iter0, batch966/1133, batch loss:4.199709735530632e-08, Training time:222160.16793560982
batch reward last col mean 3.3241308301512618e-06 first col mean 2.549850250943564e-06 all mean 3.316315087431576e-06
rl training, epoch7, iter0, batch967/1133, batch loss:3.132957004936543e-08, Training time:222186.46109509468
batch reward last col mean 5.182979293749668e-05 first col mean 4.817224544240162e-05 all mean 5.179283834877424e-05
rl training, epoch7, iter0, batch968/1133, batch loss:5.774529086011171e-07, Training time:222212.96337985992
batch reward last col mean 6.88755426381249e-06 first col mean 4.161045126238605e-06 all mean 6.950707756914198e-06
rl training, epoch7, iter0, batch969/1133, batch loss:3.962222905329327e-08, Training time:222239.43991184235
batch reward last col mean 1.9234310457250103e-05 first col mean 1.392831291013863e-05 all mean 1.9296629034215584e-05
rl training, epoch7, iter0, batch970/1133, batch loss:1.6534541202872788e-07, Training time:222265.61654233932
batch reward last col mean 3.499965532682836e-05 first col mean 3.575423761503771e-05 all mean 3.500738966977224e-05
rl training, epoch7, iter0, batch971/1133, batch loss:6.285269193995191e-08, Training time:222292.09709978104
batch reward last col mean 4.159063792030793e-06 first col mean 7.125375122996047e-05 all mean 2.1257359549053945e-05
rl training, epoch7, iter0, batch972/1133, batch loss:1.0814964923611115e-08, Training time:222318.22625541687
batch reward last col mean 1.0511809023228125e-06 first col mean 3.047600557692931e-06 all mean 8.080461157078389e-06
rl training, epoch7, iter0, batch973/1133, batch loss:2.40986386401687e-09, Training time:222344.52752804756
batch reward last col mean 9.377081369166262e-06 first col mean 1.0251891580992378e-05 all mean 2.6533069103606977e-05
rl training, epoch7, iter0, batch974/1133, batch loss:0.00014636936248280108, Training time:222370.8452026844
batch reward last col mean 0.00010141668462892994 first col mean 7.741859735688195e-05 all mean 0.00010302320151822641
rl training, epoch7, iter0, batch975/1133, batch loss:2.545112067764421e-07, Training time:222397.1964173317
batch reward last col mean 1.3374029549595434e-05 first col mean 1.3845833564118948e-05 all mean 3.30195834976621e-05
rl training, epoch7, iter0, batch976/1133, batch loss:3.132548226858489e-05, Training time:222423.289375782
batch reward last col mean 5.242407951300265e-06 first col mean 9.022736776387319e-06 all mean 5.2887767196807545e-06
rl training, epoch7, iter0, batch977/1133, batch loss:2.622192241119592e-08, Training time:222449.76292276382
batch reward last col mean 3.2071618534246227e-06 first col mean 0.0016977032646536827 all mean 2.05023698072182e-05
rl training, epoch7, iter0, batch978/1133, batch loss:6.870252367008334e-09, Training time:222476.05888986588
batch reward last col mean 3.399596380404546e-06 first col mean 4.505076958594145e-06 all mean 3.5414554986346047e-06
rl training, epoch7, iter0, batch979/1133, batch loss:2.619469796627527e-08, Training time:222502.2743792534
batch reward last col mean 3.278337601386738e-07 first col mean 1.2389762559905648e-05 all mean 2.743405502769747e-06
rl training, epoch7, iter0, batch980/1133, batch loss:8.567702103334796e-09, Training time:222528.6019694805
batch reward last col mean 5.792025149276014e-06 first col mean 9.721102287585381e-06 all mean 6.0496467995108105e-06
rl training, epoch7, iter0, batch981/1133, batch loss:7.404560875556854e-08, Training time:222555.14488506317
batch reward last col mean 4.402982085593976e-06 first col mean 1.807194530556444e-05 all mean 2.6248701033182442e-05
rl training, epoch7, iter0, batch982/1133, batch loss:2.0327201255554428e-08, Training time:222581.6094095707
batch reward last col mean 4.4433505536289886e-05 first col mean 2.6928260922431946e-05 all mean 5.1864481065422297e-05
rl training, epoch7, iter0, batch983/1133, batch loss:1.3538365237764083e-06, Training time:222607.80067181587
batch reward last col mean 4.1952243918785825e-06 first col mean 1.8266122197019286e-06 all mean 4.2368037611595355e-06
rl training, epoch7, iter0, batch984/1133, batch loss:1.5337657544023386e-07, Training time:222634.2708554268
batch reward last col mean 3.4142905747103214e-07 first col mean 1.575361420691479e-05 all mean 5.808722107758513e-07
rl training, epoch7, iter0, batch985/1133, batch loss:1.3606479276617733e-09, Training time:222660.5353422165
batch reward last col mean 2.6407651603221893e-06 first col mean 9.35159459913848e-06 all mean 5.228663667367073e-06
rl training, epoch7, iter0, batch986/1133, batch loss:4.8383452799782845e-09, Training time:222686.46327209473
batch reward last col mean 1.1471612197055947e-05 first col mean 1.311137657467043e-05 all mean 1.1475462997623254e-05
rl training, epoch7, iter0, batch987/1133, batch loss:9.598565497981326e-08, Training time:222712.71019411087
batch reward last col mean 5.795284323539818e-06 first col mean 1.760778104653582e-06 all mean 5.904464160266798e-06
rl training, epoch7, iter0, batch988/1133, batch loss:9.871511252868004e-08, Training time:222738.96953248978
batch reward last col mean 0.0003612334839999676 first col mean 0.0002734251320362091 all mean 0.00036034671938978136
rl training, epoch7, iter0, batch989/1133, batch loss:2.445519839966437e-07, Training time:222766.00433516502
batch reward last col mean 2.2408046788768843e-05 first col mean 3.8850521377753466e-05 all mean 2.257707092212513e-05
rl training, epoch7, iter0, batch990/1133, batch loss:8.061383738322547e-08, Training time:222792.75468349457
batch reward last col mean 7.545422704424709e-06 first col mean 1.2034219253109768e-05 all mean 7.602587174915243e-06
rl training, epoch7, iter0, batch991/1133, batch loss:1.697161522429269e-08, Training time:222818.90854001045
batch reward last col mean 5.445854912977666e-05 first col mean 2.577536406533909e-06 all mean 6.2599778175354e-05
rl training, epoch7, iter0, batch992/1133, batch loss:3.2389543775934726e-06, Training time:222844.906550169
batch reward last col mean 4.902345608570613e-05 first col mean 1.758886173774954e-05 all mean 6.333341298159212e-05
rl training, epoch7, iter0, batch993/1133, batch loss:8.803239097687765e-07, Training time:222871.23879885674
batch reward last col mean 5.1003189582843333e-05 first col mean 1.4084112081036437e-05 all mean 5.07893055328168e-05
rl training, epoch7, iter0, batch994/1133, batch loss:3.921347342838999e-06, Training time:222897.67638778687
batch reward last col mean 2.8985786570956407e-07 first col mean 5.907219247092144e-07 all mean 1.9055012216995237e-06
rl training, epoch7, iter0, batch995/1133, batch loss:7.144052016627711e-10, Training time:222923.71841979027
batch reward last col mean 1.2329755918472074e-05 first col mean 1.2124181921535637e-05 all mean 1.3649411812366452e-05
rl training, epoch7, iter0, batch996/1133, batch loss:3.609577703400646e-08, Training time:222950.1361398697
batch reward last col mean 1.0221562661172356e-05 first col mean 6.337629656627541e-06 all mean 1.0354749974794686e-05
rl training, epoch7, iter0, batch997/1133, batch loss:4.325990943243596e-08, Training time:222976.56984472275
batch reward last col mean 1.8422872472001472e-06 first col mean 3.60948070010636e-06 all mean 2.418287749605952e-06
rl training, epoch7, iter0, batch998/1133, batch loss:4.421178090296962e-09, Training time:223002.70674967766
batch reward last col mean 1.286479255213635e-05 first col mean 1.1499741958687082e-05 all mean 2.0753650460392237e-05
rl training, epoch7, iter0, batch999/1133, batch loss:5.962784399571319e-08, Training time:223029.0533490181
batch reward last col mean 4.668051587941591e-06 first col mean 2.4815844881231897e-05 all mean 1.0314022802049294e-05
rl training, epoch7, iter0, batch1000/1133, batch loss:5.707240546826142e-08, Training time:223055.21881604195
batch reward last col mean 4.825966607313603e-05 first col mean 2.4777287762844935e-05 all mean 4.80279850307852e-05
rl training, epoch7, iter0, batch1001/1133, batch loss:4.1464207356511906e-07, Training time:223081.88532233238
batch reward last col mean 5.626237111755472e-07 first col mean 4.1683206291054375e-06 all mean 1.2031725873384858e-06
rl training, epoch7, iter0, batch1002/1133, batch loss:1.8669319423736397e-09, Training time:223108.01024103165
batch reward last col mean 8.366712904717133e-07 first col mean 1.202652583742747e-06 all mean 1.4237442655939958e-06
rl training, epoch7, iter0, batch1003/1133, batch loss:2.7827609105912643e-09, Training time:223134.2238767147
batch reward last col mean 7.65729851082142e-07 first col mean 6.382165793183958e-06 all mean 5.093057552585378e-06
rl training, epoch7, iter0, batch1004/1133, batch loss:9.274840451212185e-09, Training time:223160.469799757
batch reward last col mean 7.270579772011843e-06 first col mean 5.10776089868159e-06 all mean 7.248764632095117e-06
rl training, epoch7, iter0, batch1005/1133, batch loss:5.8723770735014114e-08, Training time:223186.56890678406
batch reward last col mean 1.6131711788602843e-07 first col mean 1.5120355101316818e-06 all mean 1.8636225718182686e-07
rl training, epoch7, iter0, batch1006/1133, batch loss:8.690037578418242e-10, Training time:223212.69555974007
batch reward last col mean 1.0583112270978745e-05 first col mean 0.00014066808216739446 all mean 1.259102009498747e-05
rl training, epoch7, iter0, batch1007/1133, batch loss:1.9773823467517104e-08, Training time:223238.82767558098
batch reward last col mean 5.297723419062095e-06 first col mean 2.185269840992987e-05 all mean 5.4657475629937835e-06
rl training, epoch7, iter0, batch1008/1133, batch loss:1.8539375590265195e-09, Training time:223265.25463438034
batch reward last col mean 0.00031939774635247886 first col mean 4.786732461070642e-06 all mean 0.0003135133592877537
rl training, epoch7, iter0, batch1009/1133, batch loss:1.460304883948993e-05, Training time:223291.84487056732
batch reward last col mean 1.530283407191746e-05 first col mean 2.3224727556225844e-05 all mean 1.5968611478456296e-05
rl training, epoch7, iter0, batch1010/1133, batch loss:4.0420033542432066e-08, Training time:223318.05615758896
batch reward last col mean 3.4552670058474177e-06 first col mean 3.256966738263145e-05 all mean 1.4550039850291796e-05
rl training, epoch7, iter0, batch1011/1133, batch loss:8.500259163213286e-09, Training time:223344.374853611
batch reward last col mean 3.9306814869632944e-06 first col mean 4.3667082536558155e-06 all mean 1.0290244063071441e-05
rl training, epoch7, iter0, batch1012/1133, batch loss:7.289951042821485e-08, Training time:223370.74365901947
batch reward last col mean 9.141281043412164e-05 first col mean 2.852180477930233e-05 all mean 9.078406583284959e-05
rl training, epoch7, iter0, batch1013/1133, batch loss:7.888741038186708e-08, Training time:223397.20077204704
batch reward last col mean 8.672109288454521e-06 first col mean 8.409189467784017e-05 all mean 9.466384653933346e-06
rl training, epoch7, iter0, batch1014/1133, batch loss:6.331824664584929e-08, Training time:223423.92401099205
batch reward last col mean 5.933439695127163e-08 first col mean 6.407767614291515e-07 all mean 2.243365997856017e-06
rl training, epoch7, iter0, batch1015/1133, batch loss:1.007594230273412e-09, Training time:223450.37946891785
batch reward last col mean 8.731723937671632e-06 first col mean 8.976870049082208e-06 all mean 8.734198672755156e-06
rl training, epoch7, iter0, batch1016/1133, batch loss:2.718652503119756e-08, Training time:223476.78828024864
batch reward last col mean 7.6059814091422595e-06 first col mean 2.968238504763576e-06 all mean 8.347361472260673e-06
rl training, epoch7, iter0, batch1017/1133, batch loss:3.911021053681907e-07, Training time:223503.1565387249
batch reward last col mean 4.2071817006217316e-05 first col mean 1.4279364222602453e-05 all mean 5.301392957335338e-05
rl training, epoch7, iter0, batch1018/1133, batch loss:5.999509085086174e-07, Training time:223529.22892546654
batch reward last col mean 2.38031534536276e-05 first col mean 8.58265866554575e-06 all mean 2.3649412469239905e-05
rl training, epoch7, iter0, batch1019/1133, batch loss:2.533724341446941e-07, Training time:223555.427526474
batch reward last col mean 6.58957276300498e-07 first col mean 1.465704099246068e-05 all mean 8.719277388991031e-07
rl training, epoch7, iter0, batch1020/1133, batch loss:4.0283248958772333e-10, Training time:223581.53303217888
batch reward last col mean 1.4035636922926642e-05 first col mean 1.8783543055178598e-05 all mean 1.4083601854508743e-05
rl training, epoch7, iter0, batch1021/1133, batch loss:8.530554040930838e-09, Training time:223607.91142249107
batch reward last col mean 5.95459459873382e-05 first col mean 4.6261546231107786e-05 all mean 5.9497931943042204e-05
rl training, epoch7, iter0, batch1022/1133, batch loss:3.037127669358597e-07, Training time:223634.34587454796
batch reward last col mean 1.6999593981381622e-06 first col mean 2.9610066576424288e-06 all mean 2.670678895810852e-06
rl training, epoch7, iter0, batch1023/1133, batch loss:4.576360979058336e-08, Training time:223660.6514441967
batch reward last col mean 9.345958460471593e-06 first col mean 8.160885954566766e-06 all mean 2.1224102965788916e-05
rl training, epoch7, iter0, batch1024/1133, batch loss:1.7881285430121352e-07, Training time:223686.68066883087
batch reward last col mean 1.1161133443238214e-05 first col mean 1.7557532316914148e-07 all mean 1.1050167813664302e-05
rl training, epoch7, iter0, batch1025/1133, batch loss:3.9727748912810057e-07, Training time:223713.00018000603
batch reward last col mean 5.360591330827447e-06 first col mean 6.058980943635106e-05 all mean 5.919574959989404e-06
rl training, epoch7, iter0, batch1026/1133, batch loss:1.2705696939008249e-08, Training time:223739.34048318863
batch reward last col mean 4.130913850985962e-07 first col mean 3.6592675769497873e-06 all mean 1.3999907650941168e-06
rl training, epoch7, iter0, batch1027/1133, batch loss:1.2733544219045712e-09, Training time:223765.7256140709
batch reward last col mean 1.1761599125748035e-06 first col mean 9.452306812818279e-07 all mean 1.1821504131148686e-06
rl training, epoch7, iter0, batch1028/1133, batch loss:3.999704123458514e-09, Training time:223792.37293720245
batch reward last col mean 3.505207132548094e-05 first col mean 2.487730853317771e-05 all mean 4.464100857148878e-05
rl training, epoch7, iter0, batch1029/1133, batch loss:1.1739416549971793e-07, Training time:223818.6848204136
batch reward last col mean 2.0371993514345377e-07 first col mean 0.0001161559994216077 all mean 1.3749578329225187e-06
rl training, epoch7, iter0, batch1030/1133, batch loss:3.5863427783056068e-09, Training time:223844.8684642315
batch reward last col mean 4.57014721177984e-06 first col mean 2.877581664506579e-06 all mean 1.6990625226753764e-05
rl training, epoch7, iter0, batch1031/1133, batch loss:1.5819844634279434e-07, Training time:223871.25786972046
batch reward last col mean 2.2980415451456793e-05 first col mean 1.745295594446361e-05 all mean 2.3143189537222497e-05
rl training, epoch7, iter0, batch1032/1133, batch loss:8.126247763584615e-08, Training time:223897.51268601418
batch reward last col mean 8.101148523564916e-06 first col mean 8.5696538008051e-06 all mean 1.3968251550977584e-05
rl training, epoch7, iter0, batch1033/1133, batch loss:1.641283908782043e-08, Training time:223923.75082564354
batch reward last col mean 8.118909278209685e-08 first col mean 8.013576007215306e-06 all mean 1.0413477866677567e-05
rl training, epoch7, iter0, batch1034/1133, batch loss:6.262797502820661e-10, Training time:223949.89234972
batch reward last col mean 1.1993367934337584e-06 first col mean 1.749308103171643e-05 all mean 2.3588697786181e-06
rl training, epoch7, iter0, batch1035/1133, batch loss:1.4475066700825323e-09, Training time:223976.3589925766
batch reward last col mean 6.073391432437347e-06 first col mean 3.722295332408976e-06 all mean 1.114542374125449e-05
rl training, epoch7, iter0, batch1036/1133, batch loss:7.832773007976357e-08, Training time:224002.65120339394
batch reward last col mean 3.4125321235478623e-06 first col mean 9.111908184422646e-06 all mean 5.081440576759633e-06
rl training, epoch7, iter0, batch1037/1133, batch loss:6.153384468632339e-09, Training time:224028.87986183167
batch reward last col mean 1.5789648386999033e-05 first col mean 3.603308505262248e-05 all mean 1.6046273231040686e-05
rl training, epoch7, iter0, batch1038/1133, batch loss:1.7419371545202011e-07, Training time:224055.10092830658
batch reward last col mean 7.188396011770237e-06 first col mean 5.906184924242552e-06 all mean 7.2630577960808296e-06
rl training, epoch7, iter0, batch1039/1133, batch loss:1.44642470445433e-07, Training time:224081.25236225128
batch reward last col mean 4.561898549582111e-06 first col mean 1.9793028513959143e-06 all mean 4.558283762889914e-06
rl training, epoch7, iter0, batch1040/1133, batch loss:4.55313475811181e-08, Training time:224107.59847092628
batch reward last col mean 6.9946295297995675e-06 first col mean 8.083742613962386e-06 all mean 2.032047268585302e-05
rl training, epoch7, iter0, batch1041/1133, batch loss:1.1204448924218013e-08, Training time:224134.00262117386
batch reward last col mean 2.8369733627187088e-05 first col mean 4.550935045699589e-06 all mean 2.7900576242245734e-05
rl training, epoch7, iter0, batch1042/1133, batch loss:1.0459342547619599e-06, Training time:224160.1343383789
batch reward last col mean 5.728031101170927e-05 first col mean 7.07499566487968e-06 all mean 6.81810561218299e-05
rl training, epoch7, iter0, batch1043/1133, batch loss:2.8951324111403665e-06, Training time:224186.9534549713
batch reward last col mean 6.3475386014033575e-06 first col mean 3.506979192025028e-05 all mean 9.361191587231588e-06
rl training, epoch7, iter0, batch1044/1133, batch loss:5.7235833850199924e-08, Training time:224213.14027786255
batch reward last col mean 6.373601536324713e-06 first col mean 1.5985093341441825e-05 all mean 2.5578507120371796e-05
rl training, epoch7, iter0, batch1045/1133, batch loss:1.0422438379009691e-07, Training time:224239.534137249
batch reward last col mean 4.733677542390069e-06 first col mean 1.3945447790320031e-05 all mean 4.880405867879745e-06
rl training, epoch7, iter0, batch1046/1133, batch loss:1.0667196903568765e-08, Training time:224265.62810611725
batch reward last col mean 6.018984208822076e-07 first col mean 5.822667390020797e-06 all mean 6.546338795487827e-07
rl training, epoch7, iter0, batch1047/1133, batch loss:1.173068753246298e-09, Training time:224291.94960784912
batch reward last col mean 5.138157575856894e-06 first col mean 6.792009116907138e-06 all mean 5.502695785253309e-06
rl training, epoch7, iter0, batch1048/1133, batch loss:2.759996853285429e-08, Training time:224318.19356775284
batch reward last col mean 2.5965397071558982e-05 first col mean 1.4527541679854039e-05 all mean 4.173113848082721e-05
rl training, epoch7, iter0, batch1049/1133, batch loss:7.423854953003683e-08, Training time:224345.21903204918
batch reward last col mean 8.26270115794614e-06 first col mean 1.6807320207590237e-05 all mean 8.334393896802794e-06
rl training, epoch7, iter0, batch1050/1133, batch loss:1.4995349317814544e-07, Training time:224371.47178912163
batch reward last col mean 1.1873588846356142e-05 first col mean 1.1642920071608387e-05 all mean 1.3089207641314715e-05
rl training, epoch7, iter0, batch1051/1133, batch loss:2.6422648957691308e-08, Training time:224397.77750778198
batch reward last col mean 2.0885769117739983e-05 first col mean 4.649757102015428e-05 all mean 2.1048008420621045e-05
rl training, epoch7, iter0, batch1052/1133, batch loss:1.3009170061195618e-06, Training time:224424.19607520103
batch reward last col mean 2.7734962714021094e-05 first col mean 9.36712785915006e-06 all mean 7.831740731489845e-06
rl training, epoch7, iter0, batch1053/1133, batch loss:2.9221782824606635e-06, Training time:224450.52543973923
batch reward last col mean 1.859761687228456e-05 first col mean 1.8819026081473567e-05 all mean 1.9426785001996905e-05
rl training, epoch7, iter0, batch1054/1133, batch loss:2.794627285140905e-08, Training time:224476.64660668373
batch reward last col mean 1.4563209333573468e-05 first col mean 0.00011007473221980035 all mean 2.088026303681545e-05
rl training, epoch7, iter0, batch1055/1133, batch loss:9.401975376022165e-07, Training time:224503.37496709824
batch reward last col mean 8.164002792909741e-06 first col mean 1.4757581084268168e-05 all mean 8.235274435719475e-06
rl training, epoch7, iter0, batch1056/1133, batch loss:9.369688136473542e-09, Training time:224529.52863621712
batch reward last col mean 3.0048772359236864e-09 first col mean 3.3640563401604595e-07 all mean 8.604977665527258e-06
rl training, epoch7, iter0, batch1057/1133, batch loss:2.741047666621199e-10, Training time:224555.77164292336
batch reward last col mean 6.188239785842597e-05 first col mean 6.889618816785514e-05 all mean 6.217345071490854e-05
rl training, epoch7, iter0, batch1058/1133, batch loss:2.1743859690559475e-07, Training time:224582.1182539463
batch reward last col mean 2.2355071394031256e-07 first col mean 1.9133980458718725e-05 all mean 6.953944193810457e-06
rl training, epoch7, iter0, batch1059/1133, batch loss:6.57513328405912e-06, Training time:224608.65420651436
batch reward last col mean 4.962655111739878e-06 first col mean 5.807611159980297e-06 all mean 4.971241651219316e-06
rl training, epoch7, iter0, batch1060/1133, batch loss:1.358109091853521e-08, Training time:224635.12596178055
batch reward last col mean 2.3970816982910037e-05 first col mean 1.318846898357151e-05 all mean 2.384062099736184e-05
rl training, epoch7, iter0, batch1061/1133, batch loss:1.5811203866178403e-06, Training time:224661.30046892166
batch reward last col mean 2.6750709366751835e-05 first col mean 2.0115438019274734e-05 all mean 2.671640868356917e-05
rl training, epoch7, iter0, batch1062/1133, batch loss:2.159089405040504e-07, Training time:224687.56757307053
batch reward last col mean 0.006900645326822996 first col mean 2.3490447347285226e-05 all mean 0.006762339733541012
rl training, epoch7, iter0, batch1063/1133, batch loss:0.000436862901551649, Training time:224714.0381205082
batch reward last col mean 0.00032659847056493163 first col mean 0.00017136007954832166 all mean 0.00032504452974535525
rl training, epoch7, iter0, batch1064/1133, batch loss:5.12897304361104e-06, Training time:224740.36712121964
batch reward last col mean 2.989025233546272e-05 first col mean 0.00011968473700108007 all mean 3.204861786798574e-05
rl training, epoch7, iter0, batch1065/1133, batch loss:1.570879533119296e-07, Training time:224766.5896949768
batch reward last col mean 3.557075615390204e-05 first col mean 2.5396446289960295e-05 all mean 5.109579797135666e-05
rl training, epoch7, iter0, batch1066/1133, batch loss:2.3144788485751633e-07, Training time:224793.2203156948
batch reward last col mean 4.780420113092987e-06 first col mean 5.364856860978762e-06 all mean 4.922507287119515e-06
rl training, epoch7, iter0, batch1067/1133, batch loss:8.83656525729748e-09, Training time:224819.81792116165
batch reward last col mean 4.892854690297099e-07 first col mean 8.999942110676784e-06 all mean 7.067631941026775e-06
rl training, epoch7, iter0, batch1068/1133, batch loss:5.589561036245527e-10, Training time:224845.8791923523
batch reward last col mean 5.390349087974755e-06 first col mean 5.143926046002889e-06 all mean 5.4265756261884235e-06
rl training, epoch7, iter0, batch1069/1133, batch loss:2.273619870152288e-08, Training time:224872.60520744324
batch reward last col mean 3.445114998612553e-05 first col mean 5.527072516997578e-06 all mean 3.467130591161549e-05
rl training, epoch7, iter0, batch1070/1133, batch loss:2.0859600624589802e-07, Training time:224898.7749927044
batch reward last col mean 2.460409996274393e-05 first col mean 7.812821422703564e-05 all mean 2.5495708541711792e-05
rl training, epoch7, iter0, batch1071/1133, batch loss:1.1062785887361315e-07, Training time:224925.23878836632
batch reward last col mean 3.3902806535479613e-06 first col mean 1.2579113899846561e-05 all mean 7.009065484453458e-06
rl training, epoch7, iter0, batch1072/1133, batch loss:6.631349691588184e-08, Training time:224951.72451376915
batch reward last col mean 0.0010514938039705157 first col mean 0.0003697041829582304 all mean 0.0010403945343568921
rl training, epoch7, iter0, batch1073/1133, batch loss:2.976432369905524e-05, Training time:224978.21396136284
batch reward last col mean 0.0035988097079098225 first col mean 1.036642788676545e-05 all mean 0.003535313531756401
rl training, epoch7, iter0, batch1074/1133, batch loss:0.0003034446854144335, Training time:225004.78870129585
batch reward last col mean 4.002423884230666e-05 first col mean 1.4648622709501069e-05 all mean 3.9962826122064143e-05
rl training, epoch7, iter0, batch1075/1133, batch loss:2.2947292563912924e-06, Training time:225031.50432777405
batch reward last col mean 1.3049429981037974e-05 first col mean 2.879927160392981e-05 all mean 1.3154000043869019e-05
rl training, epoch7, iter0, batch1076/1133, batch loss:3.7458423207681335e-07, Training time:225057.9693338871
batch reward last col mean 1.60332047638434e-09 first col mean 2.3110974325391e-06 all mean 2.493539419390345e-08
rl training, epoch7, iter0, batch1077/1133, batch loss:1.2708359755156384e-12, Training time:225084.26756429672
batch reward last col mean 1.5287965652532876e-05 first col mean 6.022401976224501e-06 all mean 1.5465788237634115e-05
rl training, epoch7, iter0, batch1078/1133, batch loss:5.140165626471571e-08, Training time:225110.58620333672
batch reward last col mean 1.1670008461805992e-05 first col mean 2.3032982426229864e-05 all mean 1.1934814210690092e-05
rl training, epoch7, iter0, batch1079/1133, batch loss:1.906047764066443e-08, Training time:225137.3530983925
batch reward last col mean 2.9356556296988856e-06 first col mean 8.08647382655181e-06 all mean 3.8300877349684015e-06
rl training, epoch7, iter0, batch1080/1133, batch loss:4.936104858188628e-09, Training time:225163.73362851143
batch reward last col mean 2.3798811525921337e-05 first col mean 2.2863228878122754e-05 all mean 2.4683642550371587e-05
rl training, epoch7, iter0, batch1081/1133, batch loss:1.279653449870466e-08, Training time:225190.3394525051
batch reward last col mean 1.338910442427732e-05 first col mean 1.3560234947362915e-05 all mean 1.3808995390718337e-05
rl training, epoch7, iter0, batch1082/1133, batch loss:9.364851116799855e-09, Training time:225216.45556664467
batch reward last col mean 1.536414674774278e-05 first col mean 3.328756520204479e-06 all mean 1.5230219105433207e-05
rl training, epoch7, iter0, batch1083/1133, batch loss:1.8920826505564037e-07, Training time:225242.87360954285
batch reward last col mean 2.5734675546118524e-07 first col mean 1.4731090232089628e-05 all mean 6.88643353896623e-07
rl training, epoch7, iter0, batch1084/1133, batch loss:1.5742468439938762e-09, Training time:225269.24272727966
batch reward last col mean 9.273195610148832e-05 first col mean 7.831855327822268e-06 all mean 9.375923400511965e-05
rl training, epoch7, iter0, batch1085/1133, batch loss:9.506754850008292e-07, Training time:225295.8754210472
batch reward last col mean 1.8088716387865134e-05 first col mean 1.828855056373868e-05 all mean 1.901017276395578e-05
rl training, epoch7, iter0, batch1086/1133, batch loss:9.598673500477162e-08, Training time:225322.60056328773
batch reward last col mean 1.7358623153995723e-05 first col mean 2.272446363349445e-05 all mean 1.7415777620044537e-05
rl training, epoch7, iter0, batch1087/1133, batch loss:3.891612720963167e-08, Training time:225349.9457757473
batch reward last col mean 4.1102208342636004e-05 first col mean 0.0002565155446063727 all mean 4.37899652752094e-05
rl training, epoch7, iter0, batch1088/1133, batch loss:1.9883607365045464e-06, Training time:225376.44628286362
batch reward last col mean 5.4675118008162826e-05 first col mean 4.124407496419735e-05 all mean 5.4538122640224174e-05
rl training, epoch7, iter0, batch1089/1133, batch loss:2.449374960633577e-07, Training time:225402.9870736599
batch reward last col mean 8.86416728462791e-06 first col mean 1.9882618289557286e-05 all mean 1.502367013017647e-05
rl training, epoch7, iter0, batch1090/1133, batch loss:8.449091382090046e-08, Training time:225429.9463748932
batch reward last col mean 0.0005201558233238757 first col mean 2.2555748728336766e-05 all mean 0.0005187227507121861
rl training, epoch7, iter0, batch1091/1133, batch loss:3.364691656315699e-05, Training time:225457.18251538277
batch reward last col mean 7.144034952943912e-06 first col mean 4.3109266698593274e-05 all mean 1.2913701539218891e-05
rl training, epoch7, iter0, batch1092/1133, batch loss:9.392989497314375e-09, Training time:225484.65089273453
batch reward last col mean 4.147423533140682e-05 first col mean 4.3902913603233173e-05 all mean 4.868811447522603e-05
rl training, epoch7, iter0, batch1093/1133, batch loss:8.014755792373762e-08, Training time:225512.0357170105
batch reward last col mean 2.8317921533016488e-05 first col mean 9.897875315800775e-06 all mean 2.840380693669431e-05
rl training, epoch7, iter0, batch1094/1133, batch loss:1.0193746220465982e-06, Training time:225539.1403553486
batch reward last col mean 4.989163244317751e-06 first col mean 9.850520655163564e-06 all mean 5.039411007601302e-06
rl training, epoch7, iter0, batch1095/1133, batch loss:2.7419529757821692e-08, Training time:225565.95452451706
batch reward last col mean 1.4299364920589142e-05 first col mean 1.6201749531319365e-05 all mean 1.4433401702262927e-05
rl training, epoch7, iter0, batch1096/1133, batch loss:9.776793596927291e-09, Training time:225593.45113754272
batch reward last col mean 1.3204900824348442e-05 first col mean 1.3055298950348515e-05 all mean 1.3204693459556438e-05
rl training, epoch7, iter0, batch1097/1133, batch loss:1.1786021048010298e-07, Training time:225620.40119171143
batch reward last col mean 2.6468540454516187e-05 first col mean 5.2203617997292895e-06 all mean 2.6148762117372826e-05
rl training, epoch7, iter0, batch1098/1133, batch loss:8.525583439222828e-07, Training time:225647.69300413132
batch reward last col mean 9.11033566808328e-06 first col mean 0.00035443337401375175 all mean 2.8055996153852902e-05
rl training, epoch7, iter0, batch1099/1133, batch loss:3.06438380448526e-07, Training time:225674.76099658012
batch reward last col mean 1.2383011380734388e-06 first col mean 2.1518414996535284e-06 all mean 1.3387826811595005e-06
rl training, epoch7, iter0, batch1100/1133, batch loss:2.1950121720237803e-09, Training time:225701.74471712112
batch reward last col mean 1.7841672388385632e-06 first col mean 1.6139812260007602e-06 all mean 3.7609509035974042e-06
rl training, epoch7, iter0, batch1101/1133, batch loss:7.531025580931328e-09, Training time:225729.03036904335
batch reward last col mean 1.6366102499887347e-05 first col mean 1.0083366760227364e-05 all mean 1.631471786822658e-05
rl training, epoch7, iter0, batch1102/1133, batch loss:5.230237434261653e-07, Training time:225755.69385695457
batch reward last col mean 5.857903033756884e-06 first col mean 8.433242328464985e-06 all mean 5.893694833503105e-06
rl training, epoch7, iter0, batch1103/1133, batch loss:1.8404250567982672e-08, Training time:225782.57285428047
batch reward last col mean 4.479446215555072e-05 first col mean 4.083196836290881e-05 all mean 6.435497925849631e-05
rl training, epoch7, iter0, batch1104/1133, batch loss:4.489326599355081e-08, Training time:225809.1920876503
batch reward last col mean 1.0915971870417707e-05 first col mean 2.849894735845737e-05 all mean 1.112081554310862e-05
rl training, epoch7, iter0, batch1105/1133, batch loss:1.1784900380007457e-06, Training time:225836.0598332882
batch reward last col mean 1.4013681720825844e-05 first col mean 1.108965625462588e-05 all mean 1.9822286049020477e-05
rl training, epoch7, iter0, batch1106/1133, batch loss:5.334590014172136e-08, Training time:225862.88757252693
batch reward last col mean 2.27962555072736e-05 first col mean 3.337720045237802e-05 all mean 2.3154903828981332e-05
rl training, epoch7, iter0, batch1107/1133, batch loss:4.899870376107174e-08, Training time:225889.10343837738
batch reward last col mean 1.5276875274139456e-05 first col mean 1.9308874470880255e-05 all mean 1.8211003407486714e-05
rl training, epoch7, iter0, batch1108/1133, batch loss:6.101709004724398e-08, Training time:225915.75491070747
batch reward last col mean 1.6419355233665556e-05 first col mean 2.934078838734422e-05 all mean 2.8258838938199915e-05
rl training, epoch7, iter0, batch1109/1133, batch loss:2.8594696388495322e-08, Training time:225942.28055930138
batch reward last col mean 4.436491508386098e-05 first col mean 3.455313344602473e-05 all mean 6.0263493651291355e-05
rl training, epoch7, iter0, batch1110/1133, batch loss:6.231204565665394e-07, Training time:225968.67177057266
batch reward last col mean 3.869093052344397e-05 first col mean 9.296187272411771e-06 all mean 3.853839007206261e-05
rl training, epoch7, iter0, batch1111/1133, batch loss:1.4769401559533435e-06, Training time:225995.18759584427
batch reward last col mean 0.0007568724104203284 first col mean 0.000557407271116972 all mean 0.0007518946076743305
rl training, epoch7, iter0, batch1112/1133, batch loss:6.025898255757056e-05, Training time:226021.51896595955
batch reward last col mean 2.228768153145211e-06 first col mean 1.3219922948337626e-05 all mean 2.3397981294692727e-06
rl training, epoch7, iter0, batch1113/1133, batch loss:2.403319099286705e-09, Training time:226048.10518431664
batch reward last col mean 5.366478035284672e-06 first col mean 8.936909580370411e-06 all mean 5.472809334605699e-06
rl training, epoch7, iter0, batch1114/1133, batch loss:4.263553066152781e-08, Training time:226074.3723347187
batch reward last col mean 4.3412742343207356e-06 first col mean 1.1121117495349608e-05 all mean 4.421194262249628e-06
rl training, epoch7, iter0, batch1115/1133, batch loss:3.110503143943788e-08, Training time:226100.77169156075
batch reward last col mean 1.9149743820889853e-05 first col mean 1.0903132533712778e-05 all mean 1.9563296518754214e-05
rl training, epoch7, iter0, batch1116/1133, batch loss:8.574605203648389e-07, Training time:226126.96463775635
batch reward last col mean 4.549975074041868e-06 first col mean 3.903291144524701e-05 all mean 5.347760179574834e-06
rl training, epoch7, iter0, batch1117/1133, batch loss:9.373498421894055e-09, Training time:226153.78664660454
batch reward last col mean 7.443993581546238e-06 first col mean 3.6839157928625355e-06 all mean 7.428440312651219e-06
rl training, epoch7, iter0, batch1118/1133, batch loss:1.0901302971433324e-07, Training time:226180.17575788498
batch reward last col mean 1.6106498151202686e-05 first col mean 0.00017679922166280448 all mean 2.6700943635660224e-05
rl training, epoch7, iter0, batch1119/1133, batch loss:1.5489673899082845e-07, Training time:226206.7828183174
batch reward last col mean 4.4336852624837775e-06 first col mean 1.0045400813396554e-06 all mean 4.399052613734966e-06
rl training, epoch7, iter0, batch1120/1133, batch loss:1.2070645993844664e-07, Training time:226232.94934487343
batch reward last col mean 1.649254591029603e-05 first col mean 1.4528548490488902e-05 all mean 1.6498021068400703e-05
rl training, epoch7, iter0, batch1121/1133, batch loss:2.436245338799381e-08, Training time:226259.35761094093
batch reward last col mean 7.070085302984808e-06 first col mean 6.65463130644639e-06 all mean 2.2132198864710517e-05
rl training, epoch7, iter0, batch1122/1133, batch loss:4.768813965938534e-08, Training time:226285.66483545303
batch reward last col mean 2.5423687475267798e-05 first col mean 6.082207164581632e-06 all mean 2.308911098225508e-05
rl training, epoch7, iter0, batch1123/1133, batch loss:1.039145672621089e-06, Training time:226311.9255449772
batch reward last col mean 7.567115972051397e-06 first col mean 7.908785846666433e-06 all mean 7.583131719002267e-06
rl training, epoch7, iter0, batch1124/1133, batch loss:5.565851424194079e-08, Training time:226338.30477809906
batch reward last col mean 4.638589871319709e-06 first col mean 4.1295123082818463e-05 all mean 5.010281256545568e-06
rl training, epoch7, iter0, batch1125/1133, batch loss:2.396574316776423e-08, Training time:226364.76886177063
batch reward last col mean 3.5208720419177553e-06 first col mean 1.1530757547006942e-05 all mean 3.602479409892112e-06
rl training, epoch7, iter0, batch1126/1133, batch loss:2.5876667475444037e-09, Training time:226391.13613891602
batch reward last col mean 1.7414997273590416e-05 first col mean 1.70426101249177e-05 all mean 2.135811882908456e-05
rl training, epoch7, iter0, batch1127/1133, batch loss:1.4894955313593528e-07, Training time:226417.43410778046
batch reward last col mean 1.1027163054677658e-05 first col mean 1.1472574442450423e-05 all mean 1.1084664038207848e-05
rl training, epoch7, iter0, batch1128/1133, batch loss:1.503798188196015e-07, Training time:226443.56750440598
batch reward last col mean 7.680921498831594e-07 first col mean 0.00015727676509413868 all mean 2.354568323426065e-06
rl training, epoch7, iter0, batch1129/1133, batch loss:3.175968599222756e-09, Training time:226470.09797024727
batch reward last col mean 4.0275417632074095e-06 first col mean 6.654629032709636e-06 all mean 1.820630677684676e-05
rl training, epoch7, iter0, batch1130/1133, batch loss:2.9880604657250842e-09, Training time:226496.39351725578
batch reward last col mean 2.5324998205178417e-05 first col mean 3.053257751162164e-05 all mean 2.562674490036443e-05
rl training, epoch7, iter0, batch1131/1133, batch loss:1.1506443797770771e-07, Training time:226523.0623035431
batch reward last col mean 2.6150710255024023e-05 first col mean 4.1897084201991674e-07 all mean 2.5913621357176453e-05
rl training, epoch7, iter0, batch1132/1133, batch loss:1.385101739970196e-07, Training time:226547.59354019165
rl training, epoch 7, iter 0, loss:5.5479490635923755e-06, Training time:226547.59382271767 
rl epoch 7, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.22012397798151434 Time: 180.0700135231018 s
cur_epoch: 1
D Training Loss: 0.21262712694461222 Time: 180.6464343070984 s
cur_epoch: 2
D Training Loss: 0.21017724379489408 Time: 180.388121843338 s
cur_epoch: 3
D Training Loss: 0.21392492243702813 Time: 181.6894657611847 s
cur_epoch: 4
D Training Loss: 0.21249930252175572 Time: 179.1094844341278 s
rl epoch 8, begin RL for generator...
batch reward last col mean 1.4973588235989155e-07 first col mean 1.1106543752248399e-05 all mean 2.698305081594299e-07
rl training, epoch8, iter0, batch0/1133, batch loss:3.9155639841581547e-10, Training time:227476.79246115685
batch reward last col mean 1.4532778322973172e-06 first col mean 1.2578284440678544e-06 all mean 2.134301666956162e-06
rl training, epoch8, iter0, batch1/1133, batch loss:1.603461186050481e-08, Training time:227504.51257491112
batch reward last col mean 6.399252015398815e-06 first col mean 2.35806692217011e-05 all mean 8.02759313955903e-06
rl training, epoch8, iter0, batch2/1133, batch loss:7.42672625619889e-08, Training time:227532.6797389984
batch reward last col mean 9.75581588136265e-06 first col mean 5.210377366893226e-06 all mean 9.680742550699506e-06
rl training, epoch8, iter0, batch3/1133, batch loss:1.0861840138431944e-07, Training time:227559.98756694794
batch reward last col mean 2.0258962649677414e-06 first col mean 5.549993602471659e-07 all mean 2.467442072884296e-06
rl training, epoch8, iter0, batch4/1133, batch loss:7.662172265554545e-07, Training time:227587.815387249
batch reward last col mean 1.1411058949306607e-05 first col mean 0.0008962170104496181 all mean 2.5318508050986566e-05
rl training, epoch8, iter0, batch5/1133, batch loss:9.549444075673819e-05, Training time:227615.21278238297
batch reward last col mean 3.256222953496035e-07 first col mean 1.719048896120512e-06 all mean 3.4075301869052055e-07
rl training, epoch8, iter0, batch6/1133, batch loss:8.606206303163333e-10, Training time:227642.5368051529
batch reward last col mean 1.134524836743367e-06 first col mean 5.209583946452767e-07 all mean 2.105110979755409e-05
rl training, epoch8, iter0, batch7/1133, batch loss:1.3542192256466024e-08, Training time:227670.38016724586
batch reward last col mean 1.4685940641356865e-07 first col mean 5.397526820161147e-06 all mean 2.712269179028226e-06
rl training, epoch8, iter0, batch8/1133, batch loss:2.776389951275604e-10, Training time:227697.83244609833
batch reward last col mean 1.1400953781048884e-07 first col mean 1.2329800824772974e-07 all mean 2.911116609993769e-07
rl training, epoch8, iter0, batch9/1133, batch loss:1.905150481817941e-09, Training time:227725.08608603477
batch reward last col mean 1.9425522168603493e-06 first col mean 6.341228981909808e-07 all mean 2.0075101474503754e-06
rl training, epoch8, iter0, batch10/1133, batch loss:8.823082708886432e-08, Training time:227752.878834486
batch reward last col mean 1.1500720802359865e-06 first col mean 1.01947682651371e-06 all mean 1.1451196542111575e-06
rl training, epoch8, iter0, batch11/1133, batch loss:1.4512583357273456e-09, Training time:227780.07500100136
batch reward last col mean 4.14444230045774e-07 first col mean 1.0649235264281742e-05 all mean 5.257991801954631e-07
rl training, epoch8, iter0, batch12/1133, batch loss:7.913228405875827e-10, Training time:227807.22995376587
batch reward last col mean 3.097199396506767e-06 first col mean 2.1231659047771245e-05 all mean 5.021699507778976e-06
rl training, epoch8, iter0, batch13/1133, batch loss:7.166887172616043e-08, Training time:227835.11291074753
batch reward last col mean 1.611826883163303e-05 first col mean 8.970342605607584e-06 all mean 1.5899568097665906e-05
rl training, epoch8, iter0, batch14/1133, batch loss:4.288011723474483e-07, Training time:227862.4107067585
batch reward last col mean 1.358727246270064e-07 first col mean 1.6793667612091667e-07 all mean 1.2846947356592864e-05
rl training, epoch8, iter0, batch15/1133, batch loss:2.1628498991788092e-09, Training time:227889.99349570274
batch reward last col mean 3.80946346467681e-07 first col mean 2.049163185802172e-06 all mean 7.363437816820806e-06
rl training, epoch8, iter0, batch16/1133, batch loss:1.1012833978085723e-09, Training time:227917.50821185112
batch reward last col mean 9.052875498127833e-07 first col mean 7.413437970171799e-07 all mean 1.2975053778063739e-06
rl training, epoch8, iter0, batch17/1133, batch loss:1.2509770108692919e-08, Training time:227944.36259627342
batch reward last col mean 3.082597288539546e-07 first col mean 2.3229577550409886e-07 all mean 9.6250676051568e-07
rl training, epoch8, iter0, batch18/1133, batch loss:1.350658584975406e-09, Training time:227971.9548957348
batch reward last col mean 4.2031126668007346e-07 first col mean 6.72830424264248e-07 all mean 4.7418134840881976e-07
rl training, epoch8, iter0, batch19/1133, batch loss:1.8321114625408086e-09, Training time:227999.49265766144
batch reward last col mean 4.66231284690366e-08 first col mean 2.601378241706698e-07 all mean 4.8796927387684264e-08
rl training, epoch8, iter0, batch20/1133, batch loss:9.606215822799413e-11, Training time:228026.8001921177
batch reward last col mean 2.8091296826460166e-06 first col mean 2.8888527594972402e-05 all mean 1.2453431736503262e-05
rl training, epoch8, iter0, batch21/1133, batch loss:6.047274325737817e-08, Training time:228054.37591648102
batch reward last col mean 2.0419943211891223e-06 first col mean 1.2245183143022587e-06 all mean 2.9479082513717003e-05
rl training, epoch8, iter0, batch22/1133, batch loss:5.701895844367755e-08, Training time:228081.94802308083
batch reward last col mean 1.412615006302076e-06 first col mean 3.775226332436432e-06 all mean 1.426582002750365e-06
rl training, epoch8, iter0, batch23/1133, batch loss:3.3144706979015837e-09, Training time:228109.64187431335
batch reward last col mean 1.0810052941678805e-07 first col mean 6.814590278736432e-07 all mean 1.1905769952136325e-06
rl training, epoch8, iter0, batch24/1133, batch loss:1.2787407799308426e-09, Training time:228137.3448984623
batch reward last col mean 1.0384532060925267e-06 first col mean 1.250839204658405e-06 all mean 1.0414122471047449e-06
rl training, epoch8, iter0, batch25/1133, batch loss:3.245816770913734e-08, Training time:228165.24083518982
batch reward last col mean 4.3953587436362795e-08 first col mean 1.7111931811086833e-05 all mean 3.471868012638879e-06
rl training, epoch8, iter0, batch26/1133, batch loss:6.89593729341631e-11, Training time:228192.87313437462
batch reward last col mean 8.618174433649983e-06 first col mean 2.306887472514063e-05 all mean 9.070417036127765e-06
rl training, epoch8, iter0, batch27/1133, batch loss:2.1937014480499784e-06, Training time:228220.6668972969
batch reward last col mean 3.6926812754245475e-05 first col mean 1.4964784895710181e-06 all mean 3.536697113304399e-05
rl training, epoch8, iter0, batch28/1133, batch loss:2.383327455390827e-06, Training time:228247.98062586784
batch reward last col mean 8.629125431980356e-07 first col mean 3.6411017845239257e-06 all mean 3.144103175145574e-06
rl training, epoch8, iter0, batch29/1133, batch loss:1.3271038369566668e-05, Training time:228275.8137087822
batch reward last col mean 9.812850976231857e-07 first col mean 1.7413117348041851e-06 all mean 1.3388109891820932e-06
rl training, epoch8, iter0, batch30/1133, batch loss:5.6262217107416745e-09, Training time:228303.59394955635
batch reward last col mean 1.091229569283314e-05 first col mean 9.103043794311816e-07 all mean 1.1046261533920188e-05
rl training, epoch8, iter0, batch31/1133, batch loss:4.3401107063800737e-07, Training time:228331.31713104248
batch reward last col mean 2.286822336827754e-06 first col mean 1.8371064243183355e-06 all mean 2.432604787827586e-06
rl training, epoch8, iter0, batch32/1133, batch loss:1.793344317491119e-08, Training time:228358.51893281937
batch reward last col mean 3.8663372947667085e-07 first col mean 4.025496673421003e-05 all mean 7.916765412119275e-07
rl training, epoch8, iter0, batch33/1133, batch loss:6.989917533672951e-10, Training time:228385.6138072014
batch reward last col mean 2.9978394877616665e-07 first col mean 1.8421952745484305e-06 all mean 3.2154937912309833e-07
rl training, epoch8, iter0, batch34/1133, batch loss:8.151831432101631e-10, Training time:228412.18819999695
batch reward last col mean 9.830871931626461e-06 first col mean 2.1231289792922325e-06 all mean 9.891095032799058e-06
rl training, epoch8, iter0, batch35/1133, batch loss:3.963866674894234e-07, Training time:228439.06384134293
batch reward last col mean 6.305756414803909e-07 first col mean 9.800752422961523e-07 all mean 6.343225322780199e-07
rl training, epoch8, iter0, batch36/1133, batch loss:5.753969301025563e-09, Training time:228466.23512911797
batch reward last col mean 3.829306365332741e-07 first col mean 4.5156184569350444e-07 all mean 3.840730755655386e-07
rl training, epoch8, iter0, batch37/1133, batch loss:1.836752749895254e-09, Training time:228493.94315171242
batch reward last col mean 1.8733797446657263e-07 first col mean 2.752337877609534e-07 all mean 1.9631407610631868e-07
rl training, epoch8, iter0, batch38/1133, batch loss:2.4202211346135982e-09, Training time:228521.11765122414
batch reward last col mean 2.791366568999365e-07 first col mean 3.247372205805732e-06 all mean 3.134178996333503e-07
rl training, epoch8, iter0, batch39/1133, batch loss:5.842308414827357e-09, Training time:228548.89478111267
batch reward last col mean 5.443791906145634e-07 first col mean 1.292045726586366e-05 all mean 6.693996965623228e-07
rl training, epoch8, iter0, batch40/1133, batch loss:1.4592403951851907e-09, Training time:228576.02960515022
batch reward last col mean 4.5042889951218967e-07 first col mean 3.4473664527467918e-06 all mean 5.987886879665894e-07
rl training, epoch8, iter0, batch41/1133, batch loss:5.4082669009858364e-08, Training time:228603.0630815029
batch reward last col mean 2.1886476133659016e-06 first col mean 8.076534868450835e-05 all mean 3.0546877951564966e-06
rl training, epoch8, iter0, batch42/1133, batch loss:1.0844345865734795e-08, Training time:228630.4305639267
batch reward last col mean 5.1621082093333825e-06 first col mean 4.5365495680016465e-06 all mean 5.1853794502676465e-06
rl training, epoch8, iter0, batch43/1133, batch loss:9.239080611678219e-08, Training time:228657.52882051468
batch reward last col mean 2.806416705425363e-05 first col mean 4.3679188820533454e-05 all mean 2.8224323614267632e-05
rl training, epoch8, iter0, batch44/1133, batch loss:6.492517741207848e-07, Training time:228685.32658290863
batch reward last col mean 2.6608302050590282e-06 first col mean 6.735824626957765e-06 all mean 4.591409378917888e-06
rl training, epoch8, iter0, batch45/1133, batch loss:1.6370977462543124e-08, Training time:228712.6168179512
batch reward last col mean 1.2978125596418977e-06 first col mean 9.876057447399944e-07 all mean 1.300071971854777e-06
rl training, epoch8, iter0, batch46/1133, batch loss:2.4902442774532574e-08, Training time:228740.3270187378
batch reward last col mean 5.5238075447050505e-08 first col mean 7.567538773400884e-07 all mean 9.490696584180114e-08
rl training, epoch8, iter0, batch47/1133, batch loss:1.706395580391984e-09, Training time:228767.31273055077
batch reward last col mean 2.1554792795086541e-07 first col mean 4.576949379497819e-07 all mean 2.205827485113332e-07
rl training, epoch8, iter0, batch48/1133, batch loss:1.6433146510230756e-10, Training time:228794.56075930595
batch reward last col mean 3.8452574813163665e-07 first col mean 1.5444409484643984e-07 all mean 3.827350951723929e-07
rl training, epoch8, iter0, batch49/1133, batch loss:1.0977808884149454e-08, Training time:228822.10944104195
batch reward last col mean 3.78435129277932e-06 first col mean 5.3742542149848305e-06 all mean 1.276241277992085e-06
rl training, epoch8, iter0, batch50/1133, batch loss:4.3339719013602007e-07, Training time:228849.3338253498
batch reward last col mean 1.0199830740020843e-06 first col mean 2.7023000370718364e-07 all mean 1.0451271919009741e-06
rl training, epoch8, iter0, batch51/1133, batch loss:5.38652891179936e-08, Training time:228877.14060473442
batch reward last col mean 6.40716461930424e-05 first col mean 2.6574784897093195e-06 all mean 6.347414455376565e-05
rl training, epoch8, iter0, batch52/1133, batch loss:4.03987951358431e-06, Training time:228904.29978513718
batch reward last col mean 7.1914109867066145e-06 first col mean 7.064003966661403e-06 all mean 7.41020903660683e-06
rl training, epoch8, iter0, batch53/1133, batch loss:4.04654265651061e-09, Training time:228931.29957604408
batch reward last col mean 2.9333577344914374e-07 first col mean 1.6979003021333483e-06 all mean 9.025970030052122e-06
rl training, epoch8, iter0, batch54/1133, batch loss:1.2116082581670184e-09, Training time:228958.87519216537
batch reward last col mean 3.420016696509265e-07 first col mean 2.3111579139367677e-07 all mean 6.297464665294683e-07
rl training, epoch8, iter0, batch55/1133, batch loss:4.72077266167048e-09, Training time:228986.02119398117
batch reward last col mean 6.973386916797608e-05 first col mean 4.030766831419896e-06 all mean 6.882951856823638e-05
rl training, epoch8, iter0, batch56/1133, batch loss:1.9904005057469476e-06, Training time:229013.08658528328
batch reward last col mean 9.319694072473794e-06 first col mean 1.686467385297874e-06 all mean 1.6406616850872524e-05
rl training, epoch8, iter0, batch57/1133, batch loss:3.0897530223228387e-07, Training time:229039.79526352882
batch reward last col mean 1.3525279882742325e-06 first col mean 1.2896459793410031e-06 all mean 1.3391093034442747e-06
rl training, epoch8, iter0, batch58/1133, batch loss:4.893803051686518e-08, Training time:229066.27061605453
batch reward last col mean 1.6393927353419713e-06 first col mean 2.1103743108596973e-07 all mean 1.6353778846678324e-06
rl training, epoch8, iter0, batch59/1133, batch loss:1.2454503206527079e-08, Training time:229092.8148226738
batch reward last col mean 1.170695099972363e-06 first col mean 2.4261532871605596e-06 all mean 9.385133239447896e-07
rl training, epoch8, iter0, batch60/1133, batch loss:5.2700436015129526e-08, Training time:229119.16880369186
batch reward last col mean 2.5323181489511626e-06 first col mean 3.244644176447764e-06 all mean 1.888325459731277e-05
rl training, epoch8, iter0, batch61/1133, batch loss:6.55735661325707e-08, Training time:229145.8244125843
batch reward last col mean 4.0636609810462687e-07 first col mean 3.945116986869834e-06 all mean 2.014022902585566e-05
rl training, epoch8, iter0, batch62/1133, batch loss:1.2745580146855673e-09, Training time:229172.30386590958
batch reward last col mean 2.2519454887515167e-06 first col mean 2.3544023406429915e-06 all mean 2.247913016617531e-06
rl training, epoch8, iter0, batch63/1133, batch loss:1.8475559215858084e-07, Training time:229198.61386609077
batch reward last col mean 1.2010913508220256e-07 first col mean 7.968351383169647e-07 all mean 1.2781454472587939e-07
rl training, epoch8, iter0, batch64/1133, batch loss:2.493823370031123e-09, Training time:229225.00615763664
batch reward last col mean 3.9760252548148856e-05 first col mean 2.0468458387767896e-05 all mean 5.119948764331639e-05
rl training, epoch8, iter0, batch65/1133, batch loss:8.614591138211836e-07, Training time:229251.402023077
batch reward last col mean 2.174503151763929e-06 first col mean 8.536787390767131e-06 all mean 2.2582075871468987e-06
rl training, epoch8, iter0, batch66/1133, batch loss:1.0384498594362412e-08, Training time:229277.84226107597
batch reward last col mean 2.543145001254743e-07 first col mean 1.9517606233421247e-06 all mean 3.4885317745647626e-07
rl training, epoch8, iter0, batch67/1133, batch loss:4.1573877673783954e-09, Training time:229304.25617527962
batch reward last col mean 3.1544291800855717e-07 first col mean 5.314537361300609e-07 all mean 3.1835378422329086e-07
rl training, epoch8, iter0, batch68/1133, batch loss:1.1712586456269491e-09, Training time:229330.92882800102
batch reward last col mean 3.584975729609141e-07 first col mean 3.006933866345207e-06 all mean 2.8537940579553833e-06
rl training, epoch8, iter0, batch69/1133, batch loss:6.853702938514061e-09, Training time:229357.72535562515
batch reward last col mean 6.576390660484321e-06 first col mean 1.914357198984362e-06 all mean 6.3489083004242275e-06
rl training, epoch8, iter0, batch70/1133, batch loss:3.899191369782784e-07, Training time:229384.24496650696
batch reward last col mean 3.509811961066589e-07 first col mean 5.255205905996263e-07 all mean 7.079135002641124e-07
rl training, epoch8, iter0, batch71/1133, batch loss:2.5681273774225133e-10, Training time:229410.6400063038
batch reward last col mean 2.726481625359156e-06 first col mean 1.6519238670298364e-06 all mean 2.7258865884505212e-06
rl training, epoch8, iter0, batch72/1133, batch loss:3.5185557578643056e-08, Training time:229437.11285996437
batch reward last col mean 2.9561838346126024e-06 first col mean 8.262890332844108e-05 all mean 2.2708576580043882e-05
rl training, epoch8, iter0, batch73/1133, batch loss:1.622139507162501e-07, Training time:229463.6773557663
batch reward last col mean 1.4700584870297462e-05 first col mean 7.034520422166679e-06 all mean 1.4623165043303743e-05
rl training, epoch8, iter0, batch74/1133, batch loss:6.335645821309299e-07, Training time:229490.10846090317
batch reward last col mean 1.9732235614355886e-06 first col mean 6.207876026564918e-07 all mean 1.959703922693734e-06
rl training, epoch8, iter0, batch75/1133, batch loss:3.580924357038384e-08, Training time:229516.32964134216
batch reward last col mean 1.7037665429597837e-06 first col mean 9.625807706470368e-07 all mean 3.30623947775166e-06
rl training, epoch8, iter0, batch76/1133, batch loss:8.950886254410761e-09, Training time:229542.69478535652
batch reward last col mean 4.905653440800961e-06 first col mean 7.798140359227546e-06 all mean 4.9350710469298065e-06
rl training, epoch8, iter0, batch77/1133, batch loss:6.915814054764269e-08, Training time:229569.26064944267
batch reward last col mean 8.492058896081289e-07 first col mean 6.453709602283197e-07 all mean 2.077285353152547e-05
rl training, epoch8, iter0, batch78/1133, batch loss:2.2261739118789592e-08, Training time:229595.9856774807
batch reward last col mean 1.3353613326216873e-07 first col mean 7.051155535009457e-07 all mean 3.639290184764832e-07
rl training, epoch8, iter0, batch79/1133, batch loss:6.842942879003999e-10, Training time:229622.28725528717
batch reward last col mean 1.9107903881376842e-07 first col mean 3.268016968149823e-08 all mean 1.909193656501884e-07
rl training, epoch8, iter0, batch80/1133, batch loss:6.274108343973239e-09, Training time:229648.73972916603
batch reward last col mean 3.308148421865553e-08 first col mean 5.644834999429804e-08 all mean 5.876358954992611e-07
rl training, epoch8, iter0, batch81/1133, batch loss:6.160540411137561e-10, Training time:229675.3069779873
batch reward last col mean 5.597304698312655e-05 first col mean 1.7047400433511939e-06 all mean 5.536506068892777e-05
rl training, epoch8, iter0, batch82/1133, batch loss:2.6989291654899716e-06, Training time:229701.6749408245
batch reward last col mean 2.1412621720173775e-07 first col mean 1.2625255294551607e-06 all mean 2.2671656552120112e-07
rl training, epoch8, iter0, batch83/1133, batch loss:1.3372375429199224e-09, Training time:229728.04486107826
batch reward last col mean 2.119725422744523e-06 first col mean 5.37430514668813e-06 all mean 2.1719082724303007e-05
rl training, epoch8, iter0, batch84/1133, batch loss:6.282606790364298e-08, Training time:229755.4287030697
batch reward last col mean 6.558299787684518e-07 first col mean 1.5331856047851034e-05 all mean 5.576492185355164e-06
rl training, epoch8, iter0, batch85/1133, batch loss:1.719351550022452e-09, Training time:229782.28176522255
batch reward last col mean 4.103702622160199e-08 first col mean 6.022951311024372e-07 all mean 4.82640598420403e-06
rl training, epoch8, iter0, batch86/1133, batch loss:3.2522996207262622e-06, Training time:229809.3116080761
batch reward last col mean 1.6652749764034525e-05 first col mean 9.7265751719533e-07 all mean 3.2539064704906195e-05
rl training, epoch8, iter0, batch87/1133, batch loss:8.194482461476582e-07, Training time:229835.99922537804
batch reward last col mean 4.276365416444605e-06 first col mean 7.5965326686855406e-06 all mean 5.151788172952365e-06
rl training, epoch8, iter0, batch88/1133, batch loss:1.7055066336979507e-07, Training time:229862.96617341042
batch reward last col mean 1.4297123016149271e-05 first col mean 1.0511155778658576e-05 all mean 1.452559263270814e-05
rl training, epoch8, iter0, batch89/1133, batch loss:8.061060725594871e-07, Training time:229890.10716938972
batch reward last col mean 2.4399085305049084e-05 first col mean 2.0091260921617504e-06 all mean 2.418529948045034e-05
rl training, epoch8, iter0, batch90/1133, batch loss:1.2411150009938865e-06, Training time:229916.96098327637
batch reward last col mean 4.4662573372988845e-07 first col mean 2.772886489310622e-07 all mean 4.426392479217611e-07
rl training, epoch8, iter0, batch91/1133, batch loss:9.476397444529994e-09, Training time:229943.87820506096
batch reward last col mean 2.9975899451528676e-06 first col mean 6.162359795780503e-07 all mean 3.5835935250361217e-06
rl training, epoch8, iter0, batch92/1133, batch loss:5.560043447871976e-08, Training time:229970.80948662758
batch reward last col mean 6.894816806379822e-07 first col mean 5.405674414760142e-07 all mean 9.777201057659113e-07
rl training, epoch8, iter0, batch93/1133, batch loss:1.3991806602220436e-09, Training time:229997.69667625427
batch reward last col mean 3.573609774321085e-06 first col mean 1.0204037153016543e-06 all mean 3.5781702081294497e-06
rl training, epoch8, iter0, batch94/1133, batch loss:1.4066057474337867e-07, Training time:230024.7914803028
batch reward last col mean 1.1473705853859428e-05 first col mean 2.2041025658836588e-05 all mean 2.0024854165967554e-05
rl training, epoch8, iter0, batch95/1133, batch loss:7.737442615507462e-07, Training time:230052.2021112442
batch reward last col mean 1.9474658984108828e-05 first col mean 2.5348635972477496e-06 all mean 1.9434606656432152e-05
rl training, epoch8, iter0, batch96/1133, batch loss:9.289290119340876e-07, Training time:230079.04715108871
batch reward last col mean 1.5754291098346584e-06 first col mean 6.156926247058436e-06 all mean 2.4144410417648032e-06
rl training, epoch8, iter0, batch97/1133, batch loss:2.1887778700602212e-08, Training time:230105.62912654877
batch reward last col mean 1.1775535995184327e-06 first col mean 4.027086561109172e-06 all mean 1.2167109844085644e-06
rl training, epoch8, iter0, batch98/1133, batch loss:3.959974748113382e-08, Training time:230132.98380684853
batch reward last col mean 2.850727241821005e-06 first col mean 9.713826329971198e-06 all mean 3.5090840810880763e-06
rl training, epoch8, iter0, batch99/1133, batch loss:5.507558409334479e-09, Training time:230160.20793700218
batch reward last col mean 2.0269777678549872e-07 first col mean 8.513512739227735e-07 all mean 1.8863769355448312e-06
rl training, epoch8, iter0, batch100/1133, batch loss:8.952678172136075e-07, Training time:230187.1138613224
batch reward last col mean 1.1535095154613373e-06 first col mean 1.164494278782513e-06 all mean 1.153359789896058e-06
rl training, epoch8, iter0, batch101/1133, batch loss:5.861736873669088e-09, Training time:230214.25392651558
batch reward last col mean 6.00095333425088e-08 first col mean 2.3202057946036803e-06 all mean 1.0261049965265556e-07
rl training, epoch8, iter0, batch102/1133, batch loss:8.817532121119243e-11, Training time:230241.78106355667
batch reward last col mean 5.2868699640384875e-08 first col mean 1.9393775119169732e-07 all mean 5.442880635087022e-08
rl training, epoch8, iter0, batch103/1133, batch loss:2.519171815595911e-10, Training time:230268.44866776466
batch reward last col mean 0.0004036896280013025 first col mean 1.1876533108079457e-06 all mean 0.00040780421113595366
rl training, epoch8, iter0, batch104/1133, batch loss:1.6064781448221765e-05, Training time:230294.897908926
batch reward last col mean 7.691586461078259e-07 first col mean 5.836329250996641e-07 all mean 1.9212764527765103e-05
rl training, epoch8, iter0, batch105/1133, batch loss:1.632241719562444e-08, Training time:230321.30677604675
batch reward last col mean 1.415175916008593e-06 first col mean 1.182182472803106e-06 all mean 1.9286724182165926e-06
rl training, epoch8, iter0, batch106/1133, batch loss:1.1386870113483383e-08, Training time:230347.69609594345
batch reward last col mean 6.797190508223139e-07 first col mean 7.843341336410958e-06 all mean 7.520841336372541e-07
rl training, epoch8, iter0, batch107/1133, batch loss:1.6203152597427106e-08, Training time:230374.45336079597
batch reward last col mean 4.1695346908454667e-07 first col mean 1.924559910548851e-06 all mean 5.251774837233825e-06
rl training, epoch8, iter0, batch108/1133, batch loss:4.427460620348711e-09, Training time:230400.72166705132
batch reward last col mean 0.00025512053980492055 first col mean 0.0002545767347328365 all mean 0.0002557845728006214
rl training, epoch8, iter0, batch109/1133, batch loss:1.121603145293193e-05, Training time:230427.326887846
batch reward last col mean 3.313975867058616e-06 first col mean 0.00011842702951980755 all mean 5.021411652705865e-06
rl training, epoch8, iter0, batch110/1133, batch loss:7.120559786244485e-08, Training time:230454.13300013542
batch reward last col mean 1.356254642814747e-06 first col mean 8.097625823211274e-07 all mean 1.9743747543543577e-05
rl training, epoch8, iter0, batch111/1133, batch loss:1.169245233967331e-08, Training time:230480.57345986366
batch reward last col mean 5.29019303030509e-07 first col mean 3.2520858894713456e-06 all mean 9.529500857752282e-06
rl training, epoch8, iter0, batch112/1133, batch loss:6.781709860348428e-09, Training time:230507.26301813126
batch reward last col mean 2.2094652649684576e-06 first col mean 2.9949244435556466e-06 all mean 5.051652351539815e-06
rl training, epoch8, iter0, batch113/1133, batch loss:7.634116672150526e-10, Training time:230533.551705122
batch reward last col mean 5.435819616650406e-07 first col mean 1.0499435632027598e-07 all mean 4.01209831579763e-07
rl training, epoch8, iter0, batch114/1133, batch loss:5.248747569908119e-08, Training time:230560.11604690552
batch reward last col mean 5.6552989917690866e-06 first col mean 4.060728315380402e-06 all mean 5.520450031326618e-06
rl training, epoch8, iter0, batch115/1133, batch loss:1.2437924112873588e-07, Training time:230586.6536784172
batch reward last col mean 6.171858331072144e-07 first col mean 4.7601865844626445e-06 all mean 1.0546602879912825e-06
rl training, epoch8, iter0, batch116/1133, batch loss:1.0596622468383998e-09, Training time:230612.97675323486
batch reward last col mean 1.858925458009253e-07 first col mean 2.1456025933730416e-07 all mean 1.942817391409335e-07
rl training, epoch8, iter0, batch117/1133, batch loss:3.010657834146002e-10, Training time:230639.79579854012
batch reward last col mean 1.777640136424452e-06 first col mean 7.868809916544706e-06 all mean 1.910679429784068e-06
rl training, epoch8, iter0, batch118/1133, batch loss:1.0182897192123619e-08, Training time:230666.08569836617
batch reward last col mean 2.9047396310488693e-07 first col mean 6.495662091765553e-06 all mean 3.5861830838257447e-07
rl training, epoch8, iter0, batch119/1133, batch loss:1.6303275174323062e-08, Training time:230692.56067347527
batch reward last col mean 4.472357250051573e-05 first col mean 9.382340977026615e-06 all mean 6.0691640101140365e-05
rl training, epoch8, iter0, batch120/1133, batch loss:6.430502708099084e-07, Training time:230719.65085673332
batch reward last col mean 1.176401838165475e-06 first col mean 1.176931164081907e-06 all mean 1.2133139080106048e-06
rl training, epoch8, iter0, batch121/1133, batch loss:7.351252406806452e-08, Training time:230745.99135804176
batch reward last col mean 4.1432354009884875e-06 first col mean 7.815247045073193e-06 all mean 4.260018158674939e-06
rl training, epoch8, iter0, batch122/1133, batch loss:7.277804314753666e-08, Training time:230772.70534563065
batch reward last col mean 6.165246304590255e-06 first col mean 0.000437855051131919 all mean 3.0051087378524244e-05
rl training, epoch8, iter0, batch123/1133, batch loss:3.5405645348873804e-07, Training time:230799.37591433525
batch reward last col mean 2.2067419536142552e-07 first col mean 3.854760052490747e-06 all mean 6.079004037928826e-07
rl training, epoch8, iter0, batch124/1133, batch loss:6.677582931047255e-10, Training time:230826.00635576248
batch reward last col mean 7.00194746627858e-08 first col mean 3.6703170280816266e-07 all mean 7.395934886744726e-08
rl training, epoch8, iter0, batch125/1133, batch loss:5.578909001435761e-10, Training time:230852.7270359993
batch reward last col mean 1.1000782933479059e-06 first col mean 0.00037558487383648753 all mean 4.932000592816621e-06
rl training, epoch8, iter0, batch126/1133, batch loss:2.9207898322169967e-09, Training time:230879.08435940742
batch reward last col mean 7.043611560675345e-08 first col mean 8.914580575947184e-07 all mean 1.6480698832310736e-05
rl training, epoch8, iter0, batch127/1133, batch loss:3.257482616980667e-10, Training time:230906.12131595612
batch reward last col mean 4.1462357103227987e-07 first col mean 2.3912477331577975e-07 all mean 1.2330931440374115e-06
rl training, epoch8, iter0, batch128/1133, batch loss:2.7015525372320326e-09, Training time:230932.42981529236
batch reward last col mean 2.3482577660161041e-07 first col mean 8.882490760697692e-07 all mean 2.441951778564544e-07
rl training, epoch8, iter0, batch129/1133, batch loss:1.9714436749751485e-09, Training time:230958.99306321144
batch reward last col mean 6.929196274541027e-07 first col mean 8.577903258810693e-07 all mean 6.946512485228595e-07
rl training, epoch8, iter0, batch130/1133, batch loss:8.316233812699636e-10, Training time:230985.96685099602
batch reward last col mean 1.0405508874100633e-05 first col mean 2.7264914024272002e-06 all mean 1.032785621646326e-05
rl training, epoch8, iter0, batch131/1133, batch loss:1.4450606045102177e-07, Training time:231012.3071501255
batch reward last col mean 9.599274562788196e-06 first col mean 1.5205067711576703e-06 all mean 9.609419066691771e-06
rl training, epoch8, iter0, batch132/1133, batch loss:4.7330541974588414e-07, Training time:231039.04457950592
batch reward last col mean 3.384028104846948e-06 first col mean 6.053505217096244e-07 all mean 3.3984820220211986e-06
rl training, epoch8, iter0, batch133/1133, batch loss:8.77177512847993e-08, Training time:231065.686794281
batch reward last col mean 6.71290422360471e-07 first col mean 3.296103841421427e-06 all mean 1.9612518372014165e-05
rl training, epoch8, iter0, batch134/1133, batch loss:2.171700330677595e-08, Training time:231092.24696946144
batch reward last col mean 9.04144997093681e-07 first col mean 7.849934036130435e-07 all mean 1.0830628980329493e-06
rl training, epoch8, iter0, batch135/1133, batch loss:4.436863765278076e-09, Training time:231118.57602643967
batch reward last col mean 1.0086198898306975e-07 first col mean 7.451351962117769e-07 all mean 7.48877891965094e-06
rl training, epoch8, iter0, batch136/1133, batch loss:4.1203657152877327e-10, Training time:231144.83179807663
batch reward last col mean 4.305481979827164e-07 first col mean 1.228042947332142e-06 all mean 4.523844268078392e-07
rl training, epoch8, iter0, batch137/1133, batch loss:4.269868014716849e-09, Training time:231171.49643278122
batch reward last col mean 2.9584560934381443e-07 first col mean 8.659922059450764e-07 all mean 9.265825610782485e-06
rl training, epoch8, iter0, batch138/1133, batch loss:1.5644664452807433e-09, Training time:231197.7051641941
batch reward last col mean 4.93916650157189e-06 first col mean 2.4461527573294006e-05 all mean 5.135029368830146e-06
rl training, epoch8, iter0, batch139/1133, batch loss:2.7283780568154725e-08, Training time:231224.30673074722
batch reward last col mean 4.638876362150768e-06 first col mean 2.5716514073792496e-07 all mean 5.624327513942262e-06
rl training, epoch8, iter0, batch140/1133, batch loss:1.7752124392700352e-07, Training time:231250.86938810349
batch reward last col mean 1.8400449334876612e-05 first col mean 9.894190043269191e-06 all mean 2.0798850528080948e-05
rl training, epoch8, iter0, batch141/1133, batch loss:9.171493502435624e-07, Training time:231277.3047502041
batch reward last col mean 3.52898473465757e-06 first col mean 5.4169868235476315e-06 all mean 3.5481048143992666e-06
rl training, epoch8, iter0, batch142/1133, batch loss:7.776633736966687e-08, Training time:231303.88164687157
batch reward last col mean 5.803198064313619e-07 first col mean 3.2136617846845184e-06 all mean 6.071227289794479e-07
rl training, epoch8, iter0, batch143/1133, batch loss:4.228764449720757e-09, Training time:231330.3783159256
batch reward last col mean 2.211257378803566e-05 first col mean 1.7339428382001643e-07 all mean 2.1701156583731063e-05
rl training, epoch8, iter0, batch144/1133, batch loss:1.047483237925917e-06, Training time:231356.8801803589
batch reward last col mean 1.573082727190922e-06 first col mean 9.90717353488435e-07 all mean 1.6061471797002014e-06
rl training, epoch8, iter0, batch145/1133, batch loss:2.3057239673107688e-08, Training time:231383.2046906948
batch reward last col mean 4.2118819010283914e-07 first col mean 5.304375463310862e-07 all mean 5.468763902172213e-06
rl training, epoch8, iter0, batch146/1133, batch loss:1.7117438133595897e-08, Training time:231409.64928364754
batch reward last col mean 1.495794492711866e-07 first col mean 4.399772990382189e-07 all mean 1.783691118362185e-06
rl training, epoch8, iter0, batch147/1133, batch loss:2.1743711275945543e-09, Training time:231435.96698784828
batch reward last col mean 1.7897953057399718e-06 first col mean 5.928704922553152e-06 all mean 2.5545227799739223e-06
rl training, epoch8, iter0, batch148/1133, batch loss:1.0079991064060323e-08, Training time:231462.30736494064
batch reward last col mean 5.207600770518184e-05 first col mean 4.38743008999154e-05 all mean 7.134074985515326e-05
rl training, epoch8, iter0, batch149/1133, batch loss:2.468615775796934e-06, Training time:231488.76350164413
batch reward last col mean 2.275128139217486e-07 first col mean 7.128605375328334e-06 all mean 3.4631068501767004e-06
rl training, epoch8, iter0, batch150/1133, batch loss:1.0907410530336392e-09, Training time:231515.14193201065
batch reward last col mean 2.7483633857627865e-06 first col mean 3.3144424378406256e-05 all mean 4.628549504559487e-06
rl training, epoch8, iter0, batch151/1133, batch loss:1.6896878562988604e-08, Training time:231541.82627677917
batch reward last col mean 1.8677786783882766e-07 first col mean 2.235677527551161e-07 all mean 4.079210498275643e-07
rl training, epoch8, iter0, batch152/1133, batch loss:1.889333800519921e-09, Training time:231568.26805591583
batch reward last col mean 2.59421625514733e-07 first col mean 3.2912933534134936e-07 all mean 2.623523016609397e-07
rl training, epoch8, iter0, batch153/1133, batch loss:1.5869434932813675e-10, Training time:231594.4925096035
batch reward last col mean 2.092739578074543e-06 first col mean 1.3687837963516358e-05 all mean 2.579181455075741e-06
rl training, epoch8, iter0, batch154/1133, batch loss:3.5331012782080506e-08, Training time:231620.89759516716
batch reward last col mean 1.0104304237756878e-06 first col mean 6.285922609094996e-07 all mean 1.2228796549607068e-05
rl training, epoch8, iter0, batch155/1133, batch loss:1.2560240847392379e-08, Training time:231647.3372168541
batch reward last col mean 1.1363771079686558e-07 first col mean 1.937140950758476e-06 all mean 1.366526305446314e-07
rl training, epoch8, iter0, batch156/1133, batch loss:3.5331723657883174e-10, Training time:231673.85697245598
batch reward last col mean 2.9126058507245034e-06 first col mean 3.995873157691676e-06 all mean 2.9436218937917147e-06
rl training, epoch8, iter0, batch157/1133, batch loss:4.423988997359629e-08, Training time:231700.76310181618
batch reward last col mean 4.5708890894502474e-08 first col mean 1.3570729606726673e-07 all mean 4.699906952509991e-08
rl training, epoch8, iter0, batch158/1133, batch loss:1.929786712373538e-11, Training time:231727.47387099266
batch reward last col mean 9.807228025238146e-07 first col mean 4.008709879599337e-07 all mean 1.0040837423730409e-06
rl training, epoch8, iter0, batch159/1133, batch loss:1.1557872880985087e-08, Training time:231753.80504894257
batch reward last col mean 0.00018570199608802795 first col mean 3.147295501548797e-06 all mean 0.00017970496264752
rl training, epoch8, iter0, batch160/1133, batch loss:4.489732418733183e-06, Training time:231779.98168492317
batch reward last col mean 3.8088492146926e-06 first col mean 3.7650518152076984e-06 all mean 3.828043645626167e-06
rl training, epoch8, iter0, batch161/1133, batch loss:1.5069865355599177e-08, Training time:231806.83801484108
batch reward last col mean 4.428649390320061e-06 first col mean 1.5607768091285834e-06 all mean 1.2193275324534625e-05
rl training, epoch8, iter0, batch162/1133, batch loss:2.6446406309332815e-07, Training time:231833.0804183483
batch reward last col mean 6.662748637609184e-05 first col mean 3.474725963314995e-05 all mean 6.568508979398757e-05
rl training, epoch8, iter0, batch163/1133, batch loss:3.973379989474779e-06, Training time:231859.18713736534
batch reward last col mean 5.284593953547301e-06 first col mean 5.3264984671841376e-06 all mean 5.288414740789449e-06
rl training, epoch8, iter0, batch164/1133, batch loss:5.437130745633567e-09, Training time:231885.72449851036
batch reward last col mean 2.6406119104649406e-06 first col mean 9.093260473491682e-07 all mean 2.6251775580021786e-06
rl training, epoch8, iter0, batch165/1133, batch loss:2.2999174120741372e-08, Training time:231912.2861225605
batch reward last col mean 1.4389455600394285e-06 first col mean 9.91819251794368e-06 all mean 2.0030868199683027e-06
rl training, epoch8, iter0, batch166/1133, batch loss:2.2411887901085947e-09, Training time:231938.6761984825
batch reward last col mean 1.090551009497176e-07 first col mean 3.368139118720137e-07 all mean 6.577465228474466e-06
rl training, epoch8, iter0, batch167/1133, batch loss:1.418868134095419e-09, Training time:231964.9387319088
batch reward last col mean 5.701675490854541e-06 first col mean 4.536242158792447e-06 all mean 5.706402589567006e-06
rl training, epoch8, iter0, batch168/1133, batch loss:9.857536724666716e-07, Training time:231991.67028570175
batch reward last col mean 1.1278168585704407e-06 first col mean 1.4016268323757686e-06 all mean 1.2528220167951076e-06
rl training, epoch8, iter0, batch169/1133, batch loss:1.1234228480816455e-07, Training time:232018.2941570282
batch reward last col mean 3.951577696170716e-07 first col mean 3.261995061620837e-06 all mean 4.3336231669854897e-07
rl training, epoch8, iter0, batch170/1133, batch loss:6.434537347388414e-09, Training time:232044.57557296753
batch reward last col mean 4.684576560975984e-05 first col mean 9.014057695821975e-07 all mean 4.485153476707637e-05
rl training, epoch8, iter0, batch171/1133, batch loss:2.984398633998353e-06, Training time:232071.22440505028
batch reward last col mean 2.1567550447798567e-06 first col mean 3.938860754715279e-05 all mean 2.5387253117514774e-06
rl training, epoch8, iter0, batch172/1133, batch loss:3.765959633028615e-08, Training time:232098.20541715622
batch reward last col mean 2.3749141746520763e-06 first col mean 2.3517281988461036e-06 all mean 1.4777315300307237e-05
rl training, epoch8, iter0, batch173/1133, batch loss:9.954825941349554e-08, Training time:232124.57725930214
batch reward last col mean 2.3164841422840254e-06 first col mean 1.220259150613856e-06 all mean 2.3055122255755123e-06
rl training, epoch8, iter0, batch174/1133, batch loss:1.800565740950333e-08, Training time:232151.15702915192
batch reward last col mean 1.7494614439783618e-05 first col mean 5.1743609219556674e-06 all mean 1.7419069990864955e-05
rl training, epoch8, iter0, batch175/1133, batch loss:1.6412506909091462e-07, Training time:232178.1426744461
batch reward last col mean 3.7636841625499073e-06 first col mean 4.100205615031882e-07 all mean 3.695217856147792e-06
rl training, epoch8, iter0, batch176/1133, batch loss:4.905481887362839e-08, Training time:232204.53796625137
batch reward last col mean 3.331539483042434e-05 first col mean 1.0564794138190337e-05 all mean 1.5543757399427705e-05
rl training, epoch8, iter0, batch177/1133, batch loss:3.494316388241714e-06, Training time:232230.8562707901
batch reward last col mean 3.6481753795669647e-07 first col mean 4.889010369879543e-07 all mean 3.6988862461839744e-07
rl training, epoch8, iter0, batch178/1133, batch loss:3.752302912829464e-09, Training time:232257.50972652435
batch reward last col mean 3.570472273395353e-08 first col mean 3.383501621101459e-07 all mean 4.834203082282329e-08
rl training, epoch8, iter0, batch179/1133, batch loss:3.4508113033737686e-10, Training time:232283.96629285812
batch reward last col mean 0.0002439002855680883 first col mean 0.0002438933152006939 all mean 0.00024390265753027052
rl training, epoch8, iter0, batch180/1133, batch loss:1.5266004993463866e-05, Training time:232310.65963196754
batch reward last col mean 2.396864715592528e-07 first col mean 3.8137380897751427e-07 all mean 2.452586045365024e-07
rl training, epoch8, iter0, batch181/1133, batch loss:1.9858330535527102e-09, Training time:232336.96979284286
batch reward last col mean 7.008232205407694e-05 first col mean 1.7669244698481634e-05 all mean 6.891776865813881e-05
rl training, epoch8, iter0, batch182/1133, batch loss:1.7199723743033246e-06, Training time:232363.26495409012
batch reward last col mean 3.796667868982695e-08 first col mean 5.465258800541051e-05 all mean 6.124629408077453e-07
rl training, epoch8, iter0, batch183/1133, batch loss:3.2917348562477855e-06, Training time:232389.45939803123
batch reward last col mean 1.788997224139166e-06 first col mean 1.4528908423017128e-06 all mean 1.4732288036611862e-05
rl training, epoch8, iter0, batch184/1133, batch loss:1.2778382796341248e-08, Training time:232416.09074687958
batch reward last col mean 0.00011456064385129139 first col mean 1.1592084092626465e-06 all mean 0.00011584033927647397
rl training, epoch8, iter0, batch185/1133, batch loss:5.010720997233875e-06, Training time:232442.59500932693
batch reward last col mean 1.1531076182791367e-07 first col mean 1.6025390436880116e-07 all mean 1.899893868539948e-05
rl training, epoch8, iter0, batch186/1133, batch loss:4.848243140287423e-09, Training time:232468.90530371666
batch reward last col mean 4.6321585500663787e-07 first col mean 1.7504116556210647e-07 all mean 3.195444833181682e-06
rl training, epoch8, iter0, batch187/1133, batch loss:8.74912942094852e-09, Training time:232495.39534235
batch reward last col mean 3.288411676294345e-07 first col mean 6.443522124754963e-07 all mean 1.8484848624211736e-05
rl training, epoch8, iter0, batch188/1133, batch loss:1.4355695521217626e-09, Training time:232521.64194107056
batch reward last col mean 8.690660706633935e-07 first col mean 9.346920705866069e-06 all mean 9.537742471366073e-07
rl training, epoch8, iter0, batch189/1133, batch loss:2.1550773610101714e-08, Training time:232548.32779979706
batch reward last col mean 9.394004507612408e-08 first col mean 3.57060514488694e-07 all mean 1.0200457012388142e-07
rl training, epoch8, iter0, batch190/1133, batch loss:1.8069931662090255e-10, Training time:232574.9028918743
batch reward last col mean 6.613801133426023e-07 first col mean 1.6919705103646265e-06 all mean 6.781046977266669e-07
rl training, epoch8, iter0, batch191/1133, batch loss:6.157713894339167e-09, Training time:232601.23146796227
batch reward last col mean 0.0002624252228997648 first col mean 2.1274463506415486e-06 all mean 0.0002558116684667766
rl training, epoch8, iter0, batch192/1133, batch loss:2.1718908101320267e-05, Training time:232627.72128105164
batch reward last col mean 4.17084584114491e-06 first col mean 1.742824792927422e-06 all mean 4.15794920627377e-06
rl training, epoch8, iter0, batch193/1133, batch loss:1.793874915279048e-08, Training time:232653.94466876984
batch reward last col mean 1.1072934285039082e-06 first col mean 4.824879624720779e-07 all mean 1.221381262439536e-05
rl training, epoch8, iter0, batch194/1133, batch loss:1.6986469120183756e-08, Training time:232681.0812139511
batch reward last col mean 6.686230449304276e-07 first col mean 9.541339522911585e-07 all mean 7.240082595671993e-07
rl training, epoch8, iter0, batch195/1133, batch loss:1.4657605129642093e-09, Training time:232707.5613348484
batch reward last col mean 6.597501283067686e-07 first col mean 2.1060782273707446e-06 all mean 6.743817380083783e-07
rl training, epoch8, iter0, batch196/1133, batch loss:1.256965376228436e-08, Training time:232733.89077949524
batch reward last col mean 6.536263299494749e-07 first col mean 4.830422994928085e-07 all mean 6.518630470964126e-07
rl training, epoch8, iter0, batch197/1133, batch loss:1.430820906200836e-09, Training time:232760.1938471794
batch reward last col mean 1.0629247526594554e-06 first col mean 1.1786290770032792e-06 all mean 1.2981964800928836e-06
rl training, epoch8, iter0, batch198/1133, batch loss:4.242456608238854e-09, Training time:232786.4871993065
batch reward last col mean 1.2064923566867947e-06 first col mean 0.000437992624938488 all mean 5.620810952677857e-06
rl training, epoch8, iter0, batch199/1133, batch loss:1.4696223793464469e-08, Training time:232813.01884436607
batch reward last col mean 5.866549486199801e-07 first col mean 3.9141559682320803e-07 all mean 5.863150818186114e-07
rl training, epoch8, iter0, batch200/1133, batch loss:6.396415397347255e-09, Training time:232839.46480822563
batch reward last col mean 1.3360566981646116e-06 first col mean 7.850068868719973e-06 all mean 1.5035567457744037e-06
rl training, epoch8, iter0, batch201/1133, batch loss:2.9032363180192533e-09, Training time:232865.7695248127
batch reward last col mean 1.27427455254292e-07 first col mean 1.1353214404152823e-06 all mean 1.2918363836433855e-06
rl training, epoch8, iter0, batch202/1133, batch loss:3.944769511043944e-10, Training time:232892.03881931305
batch reward last col mean 3.5948705772170797e-06 first col mean 4.045682999276323e-06 all mean 3.619810740929097e-06
rl training, epoch8, iter0, batch203/1133, batch loss:9.773920339739561e-08, Training time:232918.79084134102
batch reward last col mean 1.599908046046039e-06 first col mean 5.048667617302272e-07 all mean 1.7542057548780576e-06
rl training, epoch8, iter0, batch204/1133, batch loss:9.366300623980806e-09, Training time:232945.31027007103
batch reward last col mean 1.0778176147141494e-06 first col mean 9.483213716521277e-07 all mean 1.0831191730176215e-06
rl training, epoch8, iter0, batch205/1133, batch loss:6.321501100359228e-09, Training time:232971.78716611862
batch reward last col mean 2.6940597308566794e-07 first col mean 1.3868390169591294e-07 all mean 2.6832199750970176e-07
rl training, epoch8, iter0, batch206/1133, batch loss:5.241652889509396e-09, Training time:232998.10238528252
batch reward last col mean 0.000504048599395901 first col mean 0.00024683133233338594 all mean 0.0005017576040700078
rl training, epoch8, iter0, batch207/1133, batch loss:3.110340185230598e-05, Training time:233024.61126422882
batch reward last col mean 9.376074672218238e-08 first col mean 4.082118891801656e-07 all mean 9.710046811051143e-08
rl training, epoch8, iter0, batch208/1133, batch loss:3.1940589062529057e-10, Training time:233050.79465937614
batch reward last col mean 2.4810103127492766e-07 first col mean 7.881436658863095e-07 all mean 2.120935732818907e-06
rl training, epoch8, iter0, batch209/1133, batch loss:1.9711423604462652e-09, Training time:233077.3610124588
batch reward last col mean 1.7112248542616726e-06 first col mean 6.891108341733343e-07 all mean 3.008957037309301e-06
rl training, epoch8, iter0, batch210/1133, batch loss:1.0612107104179813e-07, Training time:233103.84146213531
batch reward last col mean 4.344498734099034e-07 first col mean 1.0419109912618296e-06 all mean 4.783336748914735e-07
rl training, epoch8, iter0, batch211/1133, batch loss:2.226727913168247e-09, Training time:233130.6151342392
batch reward last col mean 1.1342088328092359e-05 first col mean 6.474733709183056e-06 all mean 1.320462797593791e-05
rl training, epoch8, iter0, batch212/1133, batch loss:5.069635449217458e-07, Training time:233156.94949674606
batch reward last col mean 1.1577569239307195e-05 first col mean 4.330547199060675e-06 all mean 1.1886843822139781e-05
rl training, epoch8, iter0, batch213/1133, batch loss:5.456994358610245e-07, Training time:233183.4253537655
batch reward last col mean 4.771318344864994e-07 first col mean 2.9363347948674345e-06 all mean 3.2191285299632e-06
rl training, epoch8, iter0, batch214/1133, batch loss:4.02072419092292e-06, Training time:233210.1028690338
batch reward last col mean 1.1315952406221186e-06 first col mean 1.3167859833629336e-06 all mean 1.1335461067574215e-06
rl training, epoch8, iter0, batch215/1133, batch loss:2.361319806354345e-09, Training time:233236.31340670586
batch reward last col mean 5.317483555700164e-06 first col mean 2.175594772779732e-06 all mean 1.3293035408423748e-05
rl training, epoch8, iter0, batch216/1133, batch loss:1.893338321679039e-07, Training time:233262.53294754028
batch reward last col mean 2.385072775723529e-06 first col mean 6.987405072322872e-07 all mean 2.2027676095603965e-05
rl training, epoch8, iter0, batch217/1133, batch loss:5.9574052357902474e-08, Training time:233289.1311635971
batch reward last col mean 3.165926329984359e-07 first col mean 3.517839104461018e-07 all mean 1.2833950677304529e-05
rl training, epoch8, iter0, batch218/1133, batch loss:1.3750830474279496e-09, Training time:233315.31803750992
batch reward last col mean 1.3650313235302747e-07 first col mean 2.008314368140418e-07 all mean 1.873531005003315e-06
rl training, epoch8, iter0, batch219/1133, batch loss:2.7945190606004644e-10, Training time:233341.76795315742
batch reward last col mean 1.5049029116198653e-06 first col mean 1.403622036377783e-06 all mean 1.520884211458906e-06
rl training, epoch8, iter0, batch220/1133, batch loss:2.2748711803188826e-09, Training time:233368.0498292446
batch reward last col mean 2.885034078303761e-08 first col mean 1.1464243243608507e-06 all mean 7.244931907735008e-07
rl training, epoch8, iter0, batch221/1133, batch loss:3.7994296597787525e-09, Training time:233394.29180169106
batch reward last col mean 7.647282131983957e-07 first col mean 4.361119408713421e-06 all mean 8.253042551586987e-07
rl training, epoch8, iter0, batch222/1133, batch loss:3.6912930490018425e-09, Training time:233420.8360168934
batch reward last col mean 9.90293870017922e-07 first col mean 1.496683580626268e-06 all mean 2.163901172025362e-06
rl training, epoch8, iter0, batch223/1133, batch loss:1.3569192880424907e-08, Training time:233447.84054255486
batch reward last col mean 4.044414652071282e-07 first col mean 3.404601011425257e-05 all mean 1.3765538824372925e-06
rl training, epoch8, iter0, batch224/1133, batch loss:1.6216105125366198e-09, Training time:233474.30532312393
batch reward last col mean 2.0628331185434945e-06 first col mean 2.068502453766996e-06 all mean 2.0705556380562484e-06
rl training, epoch8, iter0, batch225/1133, batch loss:3.5088856265019785e-08, Training time:233501.03373289108
batch reward last col mean 9.734793593452196e-07 first col mean 4.143403486978059e-07 all mean 2.1601601929432945e-06
rl training, epoch8, iter0, batch226/1133, batch loss:7.857606121319805e-09, Training time:233527.46361994743
batch reward last col mean 7.904159247118514e-07 first col mean 5.821110562465037e-07 all mean 7.883214721005061e-07
rl training, epoch8, iter0, batch227/1133, batch loss:3.989899521883444e-09, Training time:233554.0109386444
batch reward last col mean 2.6411007638671435e-06 first col mean 1.4891323871779605e-06 all mean 2.6616730792738963e-06
rl training, epoch8, iter0, batch228/1133, batch loss:3.8679750957726355e-08, Training time:233580.42957258224
batch reward last col mean 9.93674711935455e-06 first col mean 5.35455501449178e-06 all mean 9.795867299544625e-06
rl training, epoch8, iter0, batch229/1133, batch loss:2.8890502790090977e-07, Training time:233607.3075785637
batch reward last col mean 2.7781948119809385e-07 first col mean 3.2078369827104325e-07 all mean 2.8754507752637437e-07
rl training, epoch8, iter0, batch230/1133, batch loss:1.0819678486484463e-09, Training time:233633.9939544201
batch reward last col mean 8.156231956490956e-08 first col mean 4.802746389032109e-06 all mean 5.671855433320161e-06
rl training, epoch8, iter0, batch231/1133, batch loss:1.6080633491455387e-09, Training time:233660.36377072334
batch reward last col mean 8.680615792400204e-06 first col mean 3.6827257190452656e-06 all mean 8.648727998661343e-06
rl training, epoch8, iter0, batch232/1133, batch loss:2.9022618264207267e-07, Training time:233686.7051475048
batch reward last col mean 9.666297984267658e-08 first col mean 9.203286310821568e-08 all mean 1.1056478399495973e-07
rl training, epoch8, iter0, batch233/1133, batch loss:5.468774877392946e-10, Training time:233712.97795271873
batch reward last col mean 1.4026729786564829e-06 first col mean 3.201813524356112e-05 all mean 6.0460420172603335e-06
rl training, epoch8, iter0, batch234/1133, batch loss:3.5400852027578367e-08, Training time:233739.48974442482
batch reward last col mean 9.154564395430498e-07 first col mean 1.0719413694459945e-05 all mean 1.015787916003319e-06
rl training, epoch8, iter0, batch235/1133, batch loss:1.0653505855273693e-09, Training time:233765.85712003708
batch reward last col mean 6.942631216588779e-07 first col mean 2.117387793987291e-06 all mean 1.7568456314620562e-05
rl training, epoch8, iter0, batch236/1133, batch loss:3.6232747913089725e-09, Training time:233792.06417870522
batch reward last col mean 0.00017128292529378086 first col mean 3.324790668557398e-06 all mean 0.0001745720364851877
rl training, epoch8, iter0, batch237/1133, batch loss:1.5663566955481656e-05, Training time:233819.0508339405
batch reward last col mean 1.3310479971551104e-06 first col mean 7.139465196814854e-07 all mean 2.230178552053985e-06
rl training, epoch8, iter0, batch238/1133, batch loss:4.607485504237729e-09, Training time:233845.46039795876
batch reward last col mean 2.192343941942454e-07 first col mean 1.065205310624151e-07 all mean 3.9437080090465315e-07
rl training, epoch8, iter0, batch239/1133, batch loss:2.192059866956697e-09, Training time:233871.89681649208
batch reward last col mean 4.343106070336944e-07 first col mean 3.065194107421121e-07 all mean 4.810306108993245e-07
rl training, epoch8, iter0, batch240/1133, batch loss:2.4437436962898573e-08, Training time:233898.19265937805
batch reward last col mean 1.0971626807076973e-07 first col mean 3.903391188941896e-06 all mean 1.549288754176814e-05
rl training, epoch8, iter0, batch241/1133, batch loss:2.1755559576064343e-09, Training time:233924.59705996513
batch reward last col mean 2.9219430075499986e-07 first col mean 1.8117702893505339e-06 all mean 4.2122158561141987e-07
rl training, epoch8, iter0, batch242/1133, batch loss:3.373902546233154e-10, Training time:233951.0222029686
batch reward last col mean 1.8201272666829027e-07 first col mean 4.7479085196755477e-07 all mean 9.561209481034894e-06
rl training, epoch8, iter0, batch243/1133, batch loss:5.200719299658374e-10, Training time:233977.26416516304
batch reward last col mean 7.361707503150683e-06 first col mean 7.256055141624529e-06 all mean 7.99597182776779e-06
rl training, epoch8, iter0, batch244/1133, batch loss:1.1605891359067755e-07, Training time:234003.64120531082
batch reward last col mean 6.35230321677227e-08 first col mean 7.010365834503318e-07 all mean 8.443193166840501e-08
rl training, epoch8, iter0, batch245/1133, batch loss:2.7965049720357626e-10, Training time:234029.79458141327
batch reward last col mean 2.3297156985790934e-06 first col mean 1.4345337149279658e-06 all mean 2.4340795334865106e-06
rl training, epoch8, iter0, batch246/1133, batch loss:8.199553036547513e-08, Training time:234056.30824804306
batch reward last col mean 1.7742814861776424e-06 first col mean 1.5979950376276975e-06 all mean 1.7728553984852624e-06
rl training, epoch8, iter0, batch247/1133, batch loss:9.480691787189244e-09, Training time:234082.62407398224
batch reward last col mean 1.186628992400074e-06 first col mean 1.0790762416945654e-07 all mean 1.176061232399661e-06
rl training, epoch8, iter0, batch248/1133, batch loss:3.160326755846654e-08, Training time:234108.94027352333
batch reward last col mean 6.791202054046153e-07 first col mean 1.5905794725767919e-06 all mean 7.207528938124597e-07
rl training, epoch8, iter0, batch249/1133, batch loss:1.8154915348844725e-09, Training time:234135.48412895203
batch reward last col mean 1.2120774954382796e-05 first col mean 4.056278612551978e-06 all mean 1.20347995107295e-05
rl training, epoch8, iter0, batch250/1133, batch loss:5.672253422517315e-08, Training time:234161.89890050888
batch reward last col mean 6.794840601287433e-07 first col mean 1.3306213304531411e-06 all mean 6.924756803527998e-07
rl training, epoch8, iter0, batch251/1133, batch loss:2.4848409552191697e-08, Training time:234188.34588336945
batch reward last col mean 2.037808144450537e-07 first col mean 2.5902070888150774e-07 all mean 3.8234240491874516e-05
rl training, epoch8, iter0, batch252/1133, batch loss:3.5451646063222597e-09, Training time:234214.56674408913
batch reward last col mean 1.5055945823405636e-06 first col mean 2.0023248907818925e-06 all mean 7.11413065346278e-07
rl training, epoch8, iter0, batch253/1133, batch loss:1.5667080788261956e-07, Training time:234241.13972997665
batch reward last col mean 1.4997654943726957e-05 first col mean 1.542871723358985e-05 all mean 3.4510896512074396e-05
rl training, epoch8, iter0, batch254/1133, batch loss:2.438751209865586e-07, Training time:234267.57585978508
batch reward last col mean 1.5248836007231148e-06 first col mean 3.8320991734508425e-05 all mean 1.8832836303772638e-06
rl training, epoch8, iter0, batch255/1133, batch loss:5.89875348566693e-08, Training time:234294.18769717216
batch reward last col mean 1.0928373512797407e-06 first col mean 1.674905070103705e-05 all mean 2.9312525384739274e-06
rl training, epoch8, iter0, batch256/1133, batch loss:1.7998141643715826e-08, Training time:234320.5509428978
batch reward last col mean 2.340667379030492e-05 first col mean 0.0006294045597314835 all mean 2.985616447404027e-05
rl training, epoch8, iter0, batch257/1133, batch loss:4.261439130459621e-07, Training time:234346.9156768322
batch reward last col mean 4.938840447721304e-07 first col mean 6.09421874742111e-07 all mean 2.9176774205552647e-06
rl training, epoch8, iter0, batch258/1133, batch loss:5.228967925319239e-09, Training time:234373.30960202217
batch reward last col mean 3.652826663369524e-08 first col mean 1.0325005632694229e-06 all mean 6.809060323575977e-06
rl training, epoch8, iter0, batch259/1133, batch loss:3.053430008836955e-10, Training time:234399.64677906036
batch reward last col mean 7.746027222310659e-06 first col mean 0.0003543262428138405 all mean 3.100021058344282e-05
rl training, epoch8, iter0, batch260/1133, batch loss:2.99546227324754e-05, Training time:234426.03146791458
batch reward last col mean 4.532687398750568e-07 first col mean 7.878803671701462e-07 all mean 4.63100235492675e-07
rl training, epoch8, iter0, batch261/1133, batch loss:1.0198167643693523e-08, Training time:234452.48767900467
batch reward last col mean 9.544814929540735e-06 first col mean 8.201095624826849e-06 all mean 9.64550690696342e-06
rl training, epoch8, iter0, batch262/1133, batch loss:1.798841431366327e-08, Training time:234478.9840874672
batch reward last col mean 6.174106488288089e-07 first col mean 1.0215858310402837e-06 all mean 1.788220515663852e-06
rl training, epoch8, iter0, batch263/1133, batch loss:2.0445609094643657e-10, Training time:234505.20615434647
batch reward last col mean 6.542759365402162e-07 first col mean 6.089736075409746e-07 all mean 6.543265840264212e-07
rl training, epoch8, iter0, batch264/1133, batch loss:1.6605492092480745e-08, Training time:234531.57015109062
batch reward last col mean 1.91069329957827e-06 first col mean 5.2979832076971434e-08 all mean 1.905538283608621e-06
rl training, epoch8, iter0, batch265/1133, batch loss:1.185757270150134e-07, Training time:234558.0151093006
batch reward last col mean 2.8548737418532255e-07 first col mean 5.650719003824634e-07 all mean 1.8159574892706587e-06
rl training, epoch8, iter0, batch266/1133, batch loss:6.330651558528189e-10, Training time:234584.40411663055
batch reward last col mean 4.798707323061535e-06 first col mean 2.710418812057469e-06 all mean 4.897271992376773e-06
rl training, epoch8, iter0, batch267/1133, batch loss:1.5786753237989615e-08, Training time:234610.91784358025
batch reward last col mean 1.5015133669749048e-07 first col mean 4.144943090977904e-07 all mean 1.5549021270544472e-07
rl training, epoch8, iter0, batch268/1133, batch loss:4.316019541761307e-09, Training time:234637.44814777374
batch reward last col mean 2.2165336304169614e-06 first col mean 4.9027943305191e-07 all mean 6.808473244745983e-06
rl training, epoch8, iter0, batch269/1133, batch loss:3.4237359614053275e-08, Training time:234664.39789676666
batch reward last col mean 3.006084170920076e-06 first col mean 5.536121534532867e-07 all mean 2.9828797778463922e-06
rl training, epoch8, iter0, batch270/1133, batch loss:4.5045410956845444e-08, Training time:234690.6782054901
batch reward last col mean 5.113692509439716e-07 first col mean 4.46111755536549e-07 all mean 5.279415518089081e-07
rl training, epoch8, iter0, batch271/1133, batch loss:2.0727353167160345e-09, Training time:234717.16709160805
batch reward last col mean 3.0276153211161727e-06 first col mean 2.063907686533639e-06 all mean 3.052813099202467e-06
rl training, epoch8, iter0, batch272/1133, batch loss:2.610315164019994e-08, Training time:234743.76114726067
batch reward last col mean 8.975919030262958e-08 first col mean 2.256947055911951e-07 all mean 1.7988380932365544e-05
rl training, epoch8, iter0, batch273/1133, batch loss:2.750027316977821e-09, Training time:234770.00664663315
batch reward last col mean 5.455696054923465e-07 first col mean 1.1036681826226413e-06 all mean 5.512541179086838e-07
rl training, epoch8, iter0, batch274/1133, batch loss:5.302297489961916e-10, Training time:234796.5464141369
batch reward last col mean 9.810504479901283e-07 first col mean 1.7067269482140546e-06 all mean 1.1177066880918574e-06
rl training, epoch8, iter0, batch275/1133, batch loss:1.7105774574588395e-08, Training time:234822.9941661358
batch reward last col mean 5.239427991909906e-06 first col mean 5.470547876029741e-06 all mean 5.4129577620187774e-06
rl training, epoch8, iter0, batch276/1133, batch loss:6.163059396158133e-08, Training time:234849.33243227005
batch reward last col mean 5.630622013086395e-07 first col mean 7.588548214698676e-06 all mean 1.1493771125969943e-06
rl training, epoch8, iter0, batch277/1133, batch loss:2.0459403060613113e-08, Training time:234875.87336492538
batch reward last col mean 2.908074634433433e-07 first col mean 3.724522230186267e-06 all mean 3.2745097655606514e-07
rl training, epoch8, iter0, batch278/1133, batch loss:1.0858783872080835e-09, Training time:234902.30383634567
batch reward last col mean 2.4107094986902666e-07 first col mean 7.225180098657802e-08 all mean 2.5641764977990533e-07
rl training, epoch8, iter0, batch279/1133, batch loss:2.0346779816549088e-09, Training time:234928.67894482613
batch reward last col mean 2.2781534426030703e-05 first col mean 2.560945722507313e-05 all mean 2.3519034584751353e-05
rl training, epoch8, iter0, batch280/1133, batch loss:3.5442130297269614e-07, Training time:234955.03030514717
batch reward last col mean 3.713460318977013e-05 first col mean 3.288761263320339e-06 all mean 3.67327629646752e-05
rl training, epoch8, iter0, batch281/1133, batch loss:8.286341426355648e-07, Training time:234981.5328540802
batch reward last col mean 4.845252306040493e-07 first col mean 6.874749374219391e-07 all mean 7.693216730331187e-07
rl training, epoch8, iter0, batch282/1133, batch loss:9.800649181102017e-10, Training time:235008.05361437798
batch reward last col mean 4.51209689344978e-06 first col mean 1.952743559741066e-06 all mean 4.4533635445986874e-06
rl training, epoch8, iter0, batch283/1133, batch loss:1.140651662012715e-07, Training time:235034.17393112183
batch reward last col mean 3.3686628739815205e-06 first col mean 5.53705547190475e-07 all mean 3.3354574497934664e-06
rl training, epoch8, iter0, batch284/1133, batch loss:1.414033050650687e-07, Training time:235060.77055883408
batch reward last col mean 1.957348831638228e-05 first col mean 1.4917098269506823e-05 all mean 1.9357063138158992e-05
rl training, epoch8, iter0, batch285/1133, batch loss:1.1956173011640203e-06, Training time:235087.393761158
batch reward last col mean 1.917866484291153e-06 first col mean 2.8041506539011607e-06 all mean 1.9929648260585964e-06
rl training, epoch8, iter0, batch286/1133, batch loss:1.3236388873849592e-08, Training time:235113.9179840088
batch reward last col mean 2.4824389583955053e-06 first col mean 1.318128624916426e-06 all mean 2.472437472533784e-06
rl training, epoch8, iter0, batch287/1133, batch loss:2.9943564072709705e-08, Training time:235140.4204082489
batch reward last col mean 7.285110541488393e-07 first col mean 2.2091580831329338e-05 all mean 2.175768258894095e-06
rl training, epoch8, iter0, batch288/1133, batch loss:5.574988222178945e-07, Training time:235166.6401770115
batch reward last col mean 2.115604189611986e-07 first col mean 3.624927273904177e-07 all mean 2.1308420627974556e-07
rl training, epoch8, iter0, batch289/1133, batch loss:4.384288487813137e-09, Training time:235193.13110280037
batch reward last col mean 5.462399030875531e-07 first col mean 1.824494574975688e-06 all mean 6.579330147360452e-07
rl training, epoch8, iter0, batch290/1133, batch loss:4.515491536238869e-09, Training time:235219.48362135887
batch reward last col mean 4.817320586880669e-07 first col mean 1.5411123968078755e-05 all mean 6.322052854557114e-07
rl training, epoch8, iter0, batch291/1133, batch loss:1.6621612530798302e-08, Training time:235246.02844524384
batch reward last col mean 3.9302778986893827e-07 first col mean 2.3594679987581912e-07 all mean 4.2345919837316615e-07
rl training, epoch8, iter0, batch292/1133, batch loss:2.641924234936255e-09, Training time:235272.43098044395
batch reward last col mean 1.9866536604240537e-05 first col mean 2.8870215828646906e-05 all mean 1.9998544303234667e-05
rl training, epoch8, iter0, batch293/1133, batch loss:1.1142343225856166e-07, Training time:235298.42491412163
batch reward last col mean 2.8932415716553805e-06 first col mean 5.4412768804468215e-05 all mean 3.831755293504102e-06
rl training, epoch8, iter0, batch294/1133, batch loss:2.888694098146516e-06, Training time:235325.4186193943
batch reward last col mean 8.2254183553232e-07 first col mean 1.2562941265059635e-06 all mean 9.444797228752577e-07
rl training, epoch8, iter0, batch295/1133, batch loss:2.9624601438626996e-08, Training time:235351.78534555435
batch reward last col mean 1.2323732789809583e-06 first col mean 6.691565886285389e-06 all mean 3.195102181052789e-06
rl training, epoch8, iter0, batch296/1133, batch loss:4.276190068708274e-09, Training time:235378.37216997147
batch reward last col mean 3.350066322127532e-07 first col mean 4.051959194839583e-07 all mean 3.5222845440330275e-07
rl training, epoch8, iter0, batch297/1133, batch loss:3.5992000491091858e-09, Training time:235404.75645518303
batch reward last col mean 1.1824633929791162e-06 first col mean 3.236603561163065e-06 all mean 1.2054354101564968e-06
rl training, epoch8, iter0, batch298/1133, batch loss:8.006515450631468e-09, Training time:235431.43144249916
batch reward last col mean 1.6087072935988544e-06 first col mean 1.4585741610062541e-06 all mean 1.6259948552033165e-06
rl training, epoch8, iter0, batch299/1133, batch loss:7.548154101755244e-09, Training time:235458.1828277111
batch reward last col mean 2.302353095728904e-06 first col mean 6.686474534944864e-06 all mean 2.347371037103585e-06
rl training, epoch8, iter0, batch300/1133, batch loss:1.0387056192939781e-07, Training time:235484.87556529045
batch reward last col mean 1.5640808896932867e-06 first col mean 1.6248360452664201e-06 all mean 2.0918519112456124e-06
rl training, epoch8, iter0, batch301/1133, batch loss:1.8033224913338586e-09, Training time:235511.38708639145
batch reward last col mean 2.5919096060533775e-06 first col mean 9.323986773779325e-07 all mean 2.7765217964770272e-06
rl training, epoch8, iter0, batch302/1133, batch loss:6.702411781134288e-08, Training time:235538.20514011383
batch reward last col mean 3.5549151107261423e-06 first col mean 6.217439658939838e-05 all mean 4.324615929363063e-06
rl training, epoch8, iter0, batch303/1133, batch loss:1.2599892329490103e-07, Training time:235564.53725671768
batch reward last col mean 1.6932748394538066e-06 first col mean 8.683167607159703e-07 all mean 2.717932147788815e-06
rl training, epoch8, iter0, batch304/1133, batch loss:2.8004727425923193e-08, Training time:235591.0612692833
batch reward last col mean 4.3477834310579055e-07 first col mean 1.6355731986550381e-06 all mean 4.589402919918939e-07
rl training, epoch8, iter0, batch305/1133, batch loss:3.115600222258763e-09, Training time:235617.5720448494
batch reward last col mean 1.8247139621507813e-07 first col mean 1.8321679817745462e-06 all mean 9.612636858946644e-06
rl training, epoch8, iter0, batch306/1133, batch loss:1.5199314029601396e-10, Training time:235644.00371336937
batch reward last col mean 2.137037881766446e-06 first col mean 1.8139078292733757e-06 all mean 2.1371263301261934e-06
rl training, epoch8, iter0, batch307/1133, batch loss:8.519304373066916e-09, Training time:235670.41343665123
batch reward last col mean 3.951926785816795e-08 first col mean 5.4589463616139255e-06 all mean 1.3827572047375725e-06
rl training, epoch8, iter0, batch308/1133, batch loss:3.058150954693417e-11, Training time:235696.61960864067
batch reward last col mean 4.982052246305102e-07 first col mean 2.8322658636170672e-06 all mean 6.224796607057215e-07
rl training, epoch8, iter0, batch309/1133, batch loss:3.369521328622227e-09, Training time:235723.27717018127
batch reward last col mean 8.09729669981607e-07 first col mean 7.602588993904646e-07 all mean 5.460540251078783e-06
rl training, epoch8, iter0, batch310/1133, batch loss:4.011931409309e-08, Training time:235749.7238972187
batch reward last col mean 0.0005485157598741353 first col mean 0.00028888037195429206 all mean 0.0005466659786179662
rl training, epoch8, iter0, batch311/1133, batch loss:2.5831943275989033e-05, Training time:235776.61757445335
batch reward last col mean 1.3568894701165846e-06 first col mean 3.658038849607692e-07 all mean 1.142497239925433e-05
rl training, epoch8, iter0, batch312/1133, batch loss:2.7151834558480914e-08, Training time:235802.95691633224
batch reward last col mean 2.499673792044632e-05 first col mean 8.626171847936348e-07 all mean 2.7557114663068205e-05
rl training, epoch8, iter0, batch313/1133, batch loss:1.1520078260218725e-06, Training time:235829.3555355072
batch reward last col mean 2.8289782676438335e-06 first col mean 2.094805040542269e-06 all mean 2.859144387912238e-06
rl training, epoch8, iter0, batch314/1133, batch loss:8.161617159885282e-09, Training time:235856.15342235565
batch reward last col mean 5.331666557140124e-07 first col mean 3.1900626709102653e-06 all mean 5.601207817562681e-07
rl training, epoch8, iter0, batch315/1133, batch loss:4.8946699138241456e-08, Training time:235883.0969657898
batch reward last col mean 4.92593756007409e-07 first col mean 4.905418336420553e-06 all mean 4.71571820526151e-06
rl training, epoch8, iter0, batch316/1133, batch loss:7.408041291512291e-09, Training time:235909.41278886795
batch reward last col mean 1.6958923879428767e-05 first col mean 1.987912764889188e-05 all mean 3.530363392201252e-05
rl training, epoch8, iter0, batch317/1133, batch loss:4.0413655710835883e-07, Training time:235935.92768716812
batch reward last col mean 1.5145986935749534e-06 first col mean 4.1682119444885757e-07 all mean 1.5555707477687974e-06
rl training, epoch8, iter0, batch318/1133, batch loss:1.019560169623901e-08, Training time:235962.144520998
batch reward last col mean 1.5812310039109434e-07 first col mean 1.9193250864191214e-06 all mean 3.3962302836698655e-07
rl training, epoch8, iter0, batch319/1133, batch loss:5.939259084541959e-10, Training time:235988.89939951897
batch reward last col mean 8.177990196145402e-08 first col mean 4.906838512397371e-06 all mean 1.449037654310814e-07
rl training, epoch8, iter0, batch320/1133, batch loss:5.91004634120651e-10, Training time:236015.35245656967
batch reward last col mean 4.066789642820368e-06 first col mean 4.204263404972153e-06 all mean 4.336086021794472e-06
rl training, epoch8, iter0, batch321/1133, batch loss:5.934251756656295e-09, Training time:236042.27950549126
batch reward last col mean 9.121459356720152e-07 first col mean 1.5822105297047528e-06 all mean 9.286770819016965e-07
rl training, epoch8, iter0, batch322/1133, batch loss:4.3965201257378794e-08, Training time:236068.78580474854
batch reward last col mean 1.1637604657721567e-08 first col mean 7.800302910254686e-07 all mean 2.4339637860748553e-08
rl training, epoch8, iter0, batch323/1133, batch loss:8.977486115613331e-11, Training time:236095.02905130386
batch reward last col mean 4.719183834822616e-06 first col mean 2.4131427380780224e-06 all mean 4.703877948486479e-06
rl training, epoch8, iter0, batch324/1133, batch loss:1.995272747024046e-08, Training time:236121.51961159706
batch reward last col mean 8.651182952235104e-07 first col mean 1.1093545708718011e-06 all mean 8.853750728121668e-07
rl training, epoch8, iter0, batch325/1133, batch loss:5.220731069677242e-10, Training time:236148.09420967102
batch reward last col mean 2.886745278374292e-06 first col mean 1.7050447240762878e-06 all mean 1.4434115655603819e-05
rl training, epoch8, iter0, batch326/1133, batch loss:6.063129376343568e-08, Training time:236174.68663454056
batch reward last col mean 1.8991023580383626e-06 first col mean 1.9036651792703196e-06 all mean 5.23746530234348e-06
rl training, epoch8, iter0, batch327/1133, batch loss:6.15210726806481e-09, Training time:236200.94340229034
batch reward last col mean 4.0381564758718014e-07 first col mean 5.034355581301497e-07 all mean 4.849276251661649e-07
rl training, epoch8, iter0, batch328/1133, batch loss:3.6653646784401417e-10, Training time:236227.20030117035
batch reward last col mean 6.479505145762232e-07 first col mean 1.8279740743309958e-06 all mean 6.707858233312436e-07
rl training, epoch8, iter0, batch329/1133, batch loss:2.6923268059420025e-09, Training time:236254.23576784134
batch reward last col mean 4.5160064132687694e-07 first col mean 4.514038209890714e-07 all mean 4.581571317885391e-07
rl training, epoch8, iter0, batch330/1133, batch loss:3.2688449724815882e-09, Training time:236280.86465644836
batch reward last col mean 2.3921629690448754e-06 first col mean 2.3699445591773838e-05 all mean 3.141986553600873e-06
rl training, epoch8, iter0, batch331/1133, batch loss:2.0357193264430862e-08, Training time:236307.423828125
batch reward last col mean 1.419829459337052e-06 first col mean 1.6060581629062654e-06 all mean 1.422291575181589e-06
rl training, epoch8, iter0, batch332/1133, batch loss:4.290611865798155e-09, Training time:236333.9597079754
batch reward last col mean 1.4384129826794378e-05 first col mean 2.895582656492479e-05 all mean 1.4531708075082861e-05
rl training, epoch8, iter0, batch333/1133, batch loss:4.1311909626529086e-07, Training time:236360.3344347477
batch reward last col mean 4.745256774185691e-07 first col mean 3.6305798403191147e-06 all mean 5.19853585956298e-07
rl training, epoch8, iter0, batch334/1133, batch loss:2.3199955290209573e-09, Training time:236386.78724098206
batch reward last col mean 5.192927710595541e-05 first col mean 1.3944448255642783e-05 all mean 5.116463216836564e-05
rl training, epoch8, iter0, batch335/1133, batch loss:8.273951266346558e-07, Training time:236413.36087560654
batch reward last col mean 1.243653287019697e-06 first col mean 1.5594206388414023e-06 all mean 1.2474046116039972e-06
rl training, epoch8, iter0, batch336/1133, batch loss:2.2678334765657837e-09, Training time:236439.95945501328
batch reward last col mean 2.3000829685315693e-07 first col mean 3.984675913670799e-07 all mean 3.692550762934843e-07
rl training, epoch8, iter0, batch337/1133, batch loss:2.6911890493863666e-09, Training time:236466.67898917198
batch reward last col mean 1.2523948100806592e-07 first col mean 2.677330485312268e-06 all mean 1.5528469532455347e-07
rl training, epoch8, iter0, batch338/1133, batch loss:2.100316809361402e-09, Training time:236492.86421442032
batch reward last col mean 0.0005702906055375934 first col mean 2.7951043648499763e-06 all mean 0.0005646132049150765
rl training, epoch8, iter0, batch339/1133, batch loss:4.0671795431990176e-05, Training time:236519.56947040558
batch reward last col mean 9.342696102976333e-06 first col mean 5.958593646937516e-06 all mean 9.267087989428546e-06
rl training, epoch8, iter0, batch340/1133, batch loss:9.87481669767476e-08, Training time:236546.14981007576
batch reward last col mean 6.111420702836767e-07 first col mean 1.0961848602164537e-06 all mean 6.192418595674098e-07
rl training, epoch8, iter0, batch341/1133, batch loss:3.5960341371321647e-09, Training time:236572.82584881783
batch reward last col mean 6.459165888372809e-06 first col mean 2.53580765274819e-05 all mean 6.771233529434539e-06
rl training, epoch8, iter0, batch342/1133, batch loss:5.325205520989584e-08, Training time:236599.25680470467
batch reward last col mean 2.6077584607264725e-06 first col mean 3.4129200230381684e-06 all mean 3.2505654417036567e-06
rl training, epoch8, iter0, batch343/1133, batch loss:6.661266649388153e-09, Training time:236625.661318779
batch reward last col mean 4.4318508685137203e-07 first col mean 9.308620974479709e-06 all mean 1.0963091199300834e-06
rl training, epoch8, iter0, batch344/1133, batch loss:2.8557072262458405e-09, Training time:236652.17389321327
batch reward last col mean 3.9767195403328515e-07 first col mean 6.3335750155602e-07 all mean 4.4205549443177006e-07
rl training, epoch8, iter0, batch345/1133, batch loss:2.789245101553206e-08, Training time:236678.7721505165
batch reward last col mean 3.4071965728799114e-06 first col mean 4.184891167824389e-06 all mean 3.425657268962823e-06
rl training, epoch8, iter0, batch346/1133, batch loss:6.368303218096116e-08, Training time:236705.91910099983
batch reward last col mean 1.349300902120376e-07 first col mean 1.8216611579191522e-06 all mean 2.000273155999821e-07
rl training, epoch8, iter0, batch347/1133, batch loss:4.978309431358241e-10, Training time:236732.48179125786
batch reward last col mean 1.3206684343458619e-05 first col mean 6.554083142873424e-07 all mean 1.3014618161832914e-05
rl training, epoch8, iter0, batch348/1133, batch loss:1.1663669141626087e-07, Training time:236758.67501688004
batch reward last col mean 7.171088327595498e-06 first col mean 2.690028395591071e-06 all mean 1.3336385563889053e-05
rl training, epoch8, iter0, batch349/1133, batch loss:3.068408318540605e-07, Training time:236785.38009357452
batch reward last col mean 1.8696114523208962e-07 first col mean 6.688464395665505e-07 all mean 1.4387247574632056e-05
rl training, epoch8, iter0, batch350/1133, batch loss:1.973936986088276e-10, Training time:236812.2862291336
batch reward last col mean 1.3402703871179256e-06 first col mean 1.5163797115747002e-06 all mean 1.5885931134107523e-05
rl training, epoch8, iter0, batch351/1133, batch loss:5.1377391230289504e-08, Training time:236838.98222756386
batch reward last col mean 3.4330646485614125e-06 first col mean 4.240683210809948e-06 all mean 3.52254687641107e-06
rl training, epoch8, iter0, batch352/1133, batch loss:2.9023105696524e-08, Training time:236865.3590490818
batch reward last col mean 3.6191390790918376e-06 first col mean 4.2711094465630595e-06 all mean 3.670959586088429e-06
rl training, epoch8, iter0, batch353/1133, batch loss:2.2421258183413784e-09, Training time:236892.04546284676
batch reward last col mean 9.08360334506142e-07 first col mean 6.089891257943236e-07 all mean 1.664443152549211e-05
rl training, epoch8, iter0, batch354/1133, batch loss:8.436346732310085e-09, Training time:236919.04566979408
batch reward last col mean 4.884675036009867e-06 first col mean 4.023988367407583e-06 all mean 1.894676825031638e-05
rl training, epoch8, iter0, batch355/1133, batch loss:3.9487952108174795e-07, Training time:236945.53572273254
batch reward last col mean 1.8980827007908374e-06 first col mean 7.474390440620482e-05 all mean 2.6339700980315683e-06
rl training, epoch8, iter0, batch356/1133, batch loss:1.438461905145516e-09, Training time:236972.06997799873
batch reward last col mean 2.6750417418952566e-06 first col mean 2.0291536202421412e-05 all mean 2.8532776923384517e-06
rl training, epoch8, iter0, batch357/1133, batch loss:2.988519298696701e-08, Training time:236998.41889715195
batch reward last col mean 2.1806340555485804e-06 first col mean 1.2197024261695333e-06 all mean 4.0000404624152e-06
rl training, epoch8, iter0, batch358/1133, batch loss:1.2454154152408137e-08, Training time:237025.1400604248
batch reward last col mean 1.9072589907409565e-07 first col mean 3.099237630976859e-07 all mean 1.9191466549273173e-07
rl training, epoch8, iter0, batch359/1133, batch loss:1.5714370915631548e-09, Training time:237051.96576595306
batch reward last col mean 3.687431672005914e-06 first col mean 2.2735710444976576e-05 all mean 3.953010036639171e-06
rl training, epoch8, iter0, batch360/1133, batch loss:9.395846944926234e-08, Training time:237078.40569543839
batch reward last col mean 8.201150194508955e-07 first col mean 2.607906480989186e-06 all mean 1.3439120039038244e-06
rl training, epoch8, iter0, batch361/1133, batch loss:1.3202483550855959e-08, Training time:237105.21471261978
batch reward last col mean 1.1352550473020528e-06 first col mean 5.7806101949609e-07 all mean 1.1302599887130782e-06
rl training, epoch8, iter0, batch362/1133, batch loss:1.3321651337605545e-08, Training time:237132.15487122536
batch reward last col mean 3.8061912732700875e-07 first col mean 1.4230305396267795e-06 all mean 3.9174270227704255e-07
rl training, epoch8, iter0, batch363/1133, batch loss:9.517012067306041e-09, Training time:237158.37426042557
batch reward last col mean 4.114973853575066e-05 first col mean 8.436492862529121e-06 all mean 4.003704452770762e-05
rl training, epoch8, iter0, batch364/1133, batch loss:2.4051967102423077e-06, Training time:237185.15617752075
batch reward last col mean 1.049402058583837e-07 first col mean 1.1985392234237224e-07 all mean 1.783096740837209e-05
rl training, epoch8, iter0, batch365/1133, batch loss:2.4638155959877395e-09, Training time:237211.41386127472
batch reward last col mean 2.6644361241778824e-06 first col mean 1.123347374232253e-06 all mean 2.6489324227441102e-06
rl training, epoch8, iter0, batch366/1133, batch loss:3.954662730620839e-08, Training time:237238.31078457832
batch reward last col mean 1.6522508303751238e-05 first col mean 0.0027399153914302588 all mean 9.037072595674545e-05
rl training, epoch8, iter0, batch367/1133, batch loss:0.00026863833772949874, Training time:237265.45569300652
batch reward last col mean 8.484855698043248e-07 first col mean 8.734693892620271e-07 all mean 8.52831476549909e-07
rl training, epoch8, iter0, batch368/1133, batch loss:2.0571497838517416e-09, Training time:237293.10325694084
batch reward last col mean 1.602675041567636e-07 first col mean 2.2044855541025754e-06 all mean 1.633906504139304e-05
rl training, epoch8, iter0, batch369/1133, batch loss:6.7446479512511814e-09, Training time:237321.08726930618
batch reward last col mean 7.217453912744531e-06 first col mean 5.582924586633453e-06 all mean 9.275331649405416e-06
rl training, epoch8, iter0, batch370/1133, batch loss:5.603130404097101e-08, Training time:237348.50081324577
batch reward last col mean 1.9065928427153267e-06 first col mean 6.582079663530749e-07 all mean 1.9116989733447554e-06
rl training, epoch8, iter0, batch371/1133, batch loss:5.2378159587362916e-09, Training time:237375.61173343658
batch reward last col mean 7.206352279354178e-07 first col mean 0.003639005124568939 all mean 5.62648092454765e-05
rl training, epoch8, iter0, batch372/1133, batch loss:7.83069431520289e-09, Training time:237402.67298436165
batch reward last col mean 1.1212165418328368e-06 first col mean 1.5875502867856994e-06 all mean 1.927651737787528e-06
rl training, epoch8, iter0, batch373/1133, batch loss:1.2425200424104332e-08, Training time:237429.87062954903
batch reward last col mean 8.399913895118516e-06 first col mean 4.501712282944936e-06 all mean 8.392522431677207e-06
rl training, epoch8, iter0, batch374/1133, batch loss:4.816991250322644e-08, Training time:237456.4499950409
batch reward last col mean 5.2911911296860126e-08 first col mean 1.8068737972498639e-07 all mean 4.779233677254524e-06
rl training, epoch8, iter0, batch375/1133, batch loss:3.186675368027636e-10, Training time:237483.62522554398
batch reward last col mean 8.081605642473733e-07 first col mean 5.4562469813390635e-06 all mean 8.53739720696467e-07
rl training, epoch8, iter0, batch376/1133, batch loss:1.6409536840455985e-08, Training time:237510.6449854374
batch reward last col mean 4.970812369720079e-06 first col mean 5.825347102472733e-07 all mean 1.2105050700483844e-05
rl training, epoch8, iter0, batch377/1133, batch loss:7.145611391479179e-08, Training time:237537.8277914524
batch reward last col mean 8.980002348835114e-06 first col mean 6.61518242850434e-06 all mean 8.968608199211303e-06
rl training, epoch8, iter0, batch378/1133, batch loss:1.5127434949135932e-07, Training time:237564.3601038456
batch reward last col mean 4.571959834720474e-06 first col mean 5.5794625950511545e-06 all mean 7.345714038820006e-06
rl training, epoch8, iter0, batch379/1133, batch loss:6.324281542902099e-08, Training time:237591.3922481537
batch reward last col mean 6.708703494950896e-06 first col mean 1.1793449630204123e-05 all mean 1.0741519872681238e-05
rl training, epoch8, iter0, batch380/1133, batch loss:4.231813193200651e-07, Training time:237618.77695965767
batch reward last col mean 3.531391143951623e-07 first col mean 6.083851985749789e-06 all mean 9.524609367872472e-07
rl training, epoch8, iter0, batch381/1133, batch loss:2.676639576648654e-09, Training time:237646.2188255787
batch reward last col mean 2.421026692900341e-06 first col mean 4.411092959344387e-06 all mean 2.4397197648795554e-06
rl training, epoch8, iter0, batch382/1133, batch loss:2.2653187770060867e-08, Training time:237673.0953359604
batch reward last col mean 1.0627874189594877e-06 first col mean 1.1029937923012767e-06 all mean 1.4494404467768618e-06
rl training, epoch8, iter0, batch383/1133, batch loss:2.393369502584619e-09, Training time:237699.96601319313
batch reward last col mean 3.39421717399091e-07 first col mean 4.6101595785330574e-07 all mean 3.23725498674321e-06
rl training, epoch8, iter0, batch384/1133, batch loss:9.509466991630688e-09, Training time:237727.3906545639
batch reward last col mean 1.0810083949763793e-05 first col mean 5.025517566537019e-06 all mean 1.0734858733485453e-05
rl training, epoch8, iter0, batch385/1133, batch loss:1.902387367636038e-07, Training time:237754.82280135155
batch reward last col mean 2.8423589810699923e-06 first col mean 3.8618741200480144e-06 all mean 3.168413741150289e-06
rl training, epoch8, iter0, batch386/1133, batch loss:4.371381123746687e-08, Training time:237782.07317137718
batch reward last col mean 1.4533808098349255e-05 first col mean 4.5933416004118044e-07 all mean 1.9211081962566823e-05
rl training, epoch8, iter0, batch387/1133, batch loss:2.2182999259712233e-07, Training time:237809.14703941345
batch reward last col mean 0.00019161471573170274 first col mean 6.731357188982656e-06 all mean 0.00018784245185088366
rl training, epoch8, iter0, batch388/1133, batch loss:8.841264389047865e-06, Training time:237836.36883449554
batch reward last col mean 2.253468807111858e-07 first col mean 3.5617447338154307e-06 all mean 2.588907364042825e-07
rl training, epoch8, iter0, batch389/1133, batch loss:9.345915152891848e-10, Training time:237863.09768939018
batch reward last col mean 5.161464287084527e-06 first col mean 4.201865976938279e-06 all mean 1.6694182704668492e-05
rl training, epoch8, iter0, batch390/1133, batch loss:1.5882775983300235e-08, Training time:237890.70355463028
batch reward last col mean 5.054565832551816e-08 first col mean 3.180412022629753e-08 all mean 1.413285281159915e-05
rl training, epoch8, iter0, batch391/1133, batch loss:2.8171855959158165e-09, Training time:237917.84208869934
batch reward last col mean 1.6617875076008204e-07 first col mean 1.3548446986533236e-07 all mean 1.765487382954234e-07
rl training, epoch8, iter0, batch392/1133, batch loss:5.822035742397702e-09, Training time:237944.6099550724
batch reward last col mean 8.642100510769524e-06 first col mean 6.046786893421086e-07 all mean 9.085433703148738e-06
rl training, epoch8, iter0, batch393/1133, batch loss:2.840983199803304e-07, Training time:237971.63637828827
batch reward last col mean 7.435580755554838e-07 first col mean 2.0491357588525716e-07 all mean 7.35953108232934e-07
rl training, epoch8, iter0, batch394/1133, batch loss:1.1451188441924387e-08, Training time:237998.72778511047
batch reward last col mean 7.250579869833018e-07 first col mean 4.984611905456404e-07 all mean 7.323082513721602e-07
rl training, epoch8, iter0, batch395/1133, batch loss:5.016477899744132e-09, Training time:238026.31294202805
batch reward last col mean 7.12162145646289e-05 first col mean 3.759398396141478e-06 all mean 6.994182331254706e-05
rl training, epoch8, iter0, batch396/1133, batch loss:3.6898813959851395e-06, Training time:238054.08622312546
batch reward last col mean 1.822073318180628e-05 first col mean 0.0018607587553560734 all mean 3.667734199552797e-05
rl training, epoch8, iter0, batch397/1133, batch loss:6.325226991066302e-07, Training time:238081.66526341438
batch reward last col mean 6.874735845485702e-06 first col mean 8.804640856396873e-07 all mean 6.802129519201117e-06
rl training, epoch8, iter0, batch398/1133, batch loss:2.183999896487876e-07, Training time:238108.32238817215
batch reward last col mean 3.042488856408454e-07 first col mean 1.4902726661603083e-06 all mean 6.17511386735714e-06
rl training, epoch8, iter0, batch399/1133, batch loss:1.2679768346401943e-09, Training time:238134.81470441818
batch reward last col mean 7.53832466671156e-07 first col mean 1.011394843430935e-07 all mean 7.502167704842577e-07
rl training, epoch8, iter0, batch400/1133, batch loss:4.429484334877998e-09, Training time:238161.1909790039
batch reward last col mean 4.3143859329575207e-07 first col mean 2.847527184712817e-06 all mean 4.638368693576922e-07
rl training, epoch8, iter0, batch401/1133, batch loss:4.37145475373768e-09, Training time:238187.71002936363
batch reward last col mean 3.7174899603087397e-07 first col mean 1.4647760508523788e-05 all mean 5.18870649557357e-07
rl training, epoch8, iter0, batch402/1133, batch loss:1.109353719996875e-09, Training time:238214.38840007782
batch reward last col mean 1.4245684099023492e-07 first col mean 4.488117326673091e-07 all mean 1.4280590221460443e-05
rl training, epoch8, iter0, batch403/1133, batch loss:2.6194889812813926e-08, Training time:238240.43418598175
batch reward last col mean 3.1528668387181824e-06 first col mean 0.00028913855203427374 all mean 1.1164067473146133e-05
rl training, epoch8, iter0, batch404/1133, batch loss:4.857293678384167e-09, Training time:238266.98555088043
batch reward last col mean 1.1188660664629424e-06 first col mean 1.673073711572215e-06 all mean 1.1215163340239087e-06
rl training, epoch8, iter0, batch405/1133, batch loss:6.548296482833393e-08, Training time:238293.5560479164
batch reward last col mean 6.928466973477043e-06 first col mean 1.6017509096855065e-06 all mean 6.94762047714903e-06
rl training, epoch8, iter0, batch406/1133, batch loss:2.3895174194876745e-07, Training time:238319.8495066166
batch reward last col mean 1.8071327758661937e-06 first col mean 2.002905375775299e-06 all mean 1.8130688204109902e-06
rl training, epoch8, iter0, batch407/1133, batch loss:1.0446878029313211e-08, Training time:238346.20338773727
batch reward last col mean 7.64395826990949e-06 first col mean 1.3148210200597532e-06 all mean 1.590908686921466e-05
rl training, epoch8, iter0, batch408/1133, batch loss:1.3448301672269736e-07, Training time:238372.6149880886
batch reward last col mean 4.102119419258088e-06 first col mean 6.633856628468493e-07 all mean 4.348065886006225e-06
rl training, epoch8, iter0, batch409/1133, batch loss:4.2445574166549704e-08, Training time:238399.2666811943
batch reward last col mean 2.312745664312388e-06 first col mean 5.666441893481533e-07 all mean 2.605418330858811e-06
rl training, epoch8, iter0, batch410/1133, batch loss:2.5542959747326677e-08, Training time:238425.66965150833
batch reward last col mean 7.291609563253587e-06 first col mean 5.463291927298997e-06 all mean 7.496129455830669e-06
rl training, epoch8, iter0, batch411/1133, batch loss:1.2948591177064372e-07, Training time:238452.09855794907
batch reward last col mean 3.564750659279525e-05 first col mean 3.492092218948528e-05 all mean 3.5662400478031486e-05
rl training, epoch8, iter0, batch412/1133, batch loss:1.9209282982046716e-06, Training time:238478.40289473534
batch reward last col mean 6.372677489707712e-06 first col mean 6.3198417592502665e-06 all mean 8.380092367588077e-06
rl training, epoch8, iter0, batch413/1133, batch loss:1.6211478737204743e-07, Training time:238504.63581681252
batch reward last col mean 1.7458121703839424e-07 first col mean 2.8987682298975415e-07 all mean 2.0119608961977065e-05
rl training, epoch8, iter0, batch414/1133, batch loss:3.8390596257542597e-10, Training time:238530.9516224861
batch reward last col mean 9.462484058531118e-07 first col mean 8.23332868549187e-07 all mean 9.450093898522027e-07
rl training, epoch8, iter0, batch415/1133, batch loss:1.1170236291491165e-08, Training time:238557.34702444077
batch reward last col mean 2.683880211407086e-06 first col mean 2.026347374339821e-06 all mean 1.2666491784329992e-05
rl training, epoch8, iter0, batch416/1133, batch loss:8.179777921668574e-08, Training time:238583.78095388412
batch reward last col mean 3.213655759282119e-07 first col mean 2.055487811958301e-06 all mean 1.023932668431371e-06
rl training, epoch8, iter0, batch417/1133, batch loss:1.2856169462338585e-08, Training time:238610.0972366333
batch reward last col mean 1.6069838011389947e-06 first col mean 1.036774619933567e-06 all mean 1.6012301102819038e-06
rl training, epoch8, iter0, batch418/1133, batch loss:2.038385460423342e-08, Training time:238636.3976840973
batch reward last col mean 3.221177394152619e-05 first col mean 3.5815567116515012e-06 all mean 3.178268525516614e-05
rl training, epoch8, iter0, batch419/1133, batch loss:1.0738837090684683e-06, Training time:238662.82201981544
batch reward last col mean 4.88587090785586e-07 first col mean 1.7860539855973911e-06 all mean 7.062071745167486e-07
rl training, epoch8, iter0, batch420/1133, batch loss:5.0090682712777834e-09, Training time:238689.48001599312
batch reward last col mean 1.0826960306076217e-06 first col mean 5.304204023559578e-06 all mean 1.185043629448046e-06
rl training, epoch8, iter0, batch421/1133, batch loss:7.291779624551964e-09, Training time:238715.98099541664
batch reward last col mean 1.4567273183274665e-06 first col mean 9.526746680421638e-07 all mean 2.1484112949110568e-05
rl training, epoch8, iter0, batch422/1133, batch loss:9.502978848274779e-09, Training time:238742.58421087265
batch reward last col mean 2.8202504154251073e-07 first col mean 2.9784058597215335e-07 all mean 3.1977680237105233e-07
rl training, epoch8, iter0, batch423/1133, batch loss:1.7553722919672055e-09, Training time:238768.87902355194
batch reward last col mean 1.535319256618095e-06 first col mean 5.926090125285555e-06 all mean 2.0645773474825546e-05
rl training, epoch8, iter0, batch424/1133, batch loss:7.660849732360475e-10, Training time:238795.30513048172
batch reward last col mean 4.407928827276919e-06 first col mean 4.958699264534516e-07 all mean 4.650226401281543e-06
rl training, epoch8, iter0, batch425/1133, batch loss:3.919965507748202e-08, Training time:238821.6081969738
batch reward last col mean 3.9263036342163105e-06 first col mean 1.976420662685996e-06 all mean 3.917418780474691e-06
rl training, epoch8, iter0, batch426/1133, batch loss:2.5667945990903718e-08, Training time:238848.26487755775
batch reward last col mean 2.0745548681588843e-05 first col mean 4.453203928278526e-06 all mean 2.043645508820191e-05
rl training, epoch8, iter0, batch427/1133, batch loss:7.320712143155106e-07, Training time:238874.70673131943
batch reward last col mean 1.4282118172559422e-06 first col mean 3.2294290122081293e-06 all mean 1.639999709368567e-06
rl training, epoch8, iter0, batch428/1133, batch loss:1.5471051995064045e-08, Training time:238901.12949180603
batch reward last col mean 1.3872853514840244e-06 first col mean 1.6862435359144001e-06 all mean 1.399102075083647e-06
rl training, epoch8, iter0, batch429/1133, batch loss:7.58619744800626e-09, Training time:238927.61568665504
batch reward last col mean 4.0211551777247223e-07 first col mean 7.619273674208671e-07 all mean 1.1440289426900563e-06
rl training, epoch8, iter0, batch430/1133, batch loss:1.6292981408483342e-09, Training time:238953.94692230225
batch reward last col mean 3.652494342532009e-05 first col mean 2.9258790164021775e-06 all mean 3.647966150310822e-05
rl training, epoch8, iter0, batch431/1133, batch loss:1.5734387943666661e-06, Training time:238980.61115694046
batch reward last col mean 4.075899596500676e-06 first col mean 4.85711370856734e-06 all mean 4.083259227627423e-06
rl training, epoch8, iter0, batch432/1133, batch loss:2.4393809194833693e-09, Training time:239007.50754141808
batch reward last col mean 9.328736041425145e-07 first col mean 1.5439829439856112e-05 all mean 1.0805458714457927e-06
rl training, epoch8, iter0, batch433/1133, batch loss:3.073170162792849e-08, Training time:239033.82813358307
batch reward last col mean 6.21948720436194e-06 first col mean 3.0781616260355804e-06 all mean 6.298706466623116e-06
rl training, epoch8, iter0, batch434/1133, batch loss:2.0138116951784468e-07, Training time:239060.34200787544
batch reward last col mean 1.0431103873997927e-05 first col mean 6.333358669508016e-06 all mean 2.7646112357615493e-05
rl training, epoch8, iter0, batch435/1133, batch loss:5.097116968499904e-07, Training time:239086.93203020096
batch reward last col mean 2.593758154034731e-06 first col mean 1.5558749737465405e-06 all mean 2.6491393327887636e-06
rl training, epoch8, iter0, batch436/1133, batch loss:5.6094041411824946e-08, Training time:239113.42261695862
batch reward last col mean 1.4947777344787028e-06 first col mean 1.2125793546147179e-05 all mean 3.7958286611683434e-06
rl training, epoch8, iter0, batch437/1133, batch loss:1.620249001632601e-08, Training time:239139.92941713333
batch reward last col mean 2.791054498629819e-07 first col mean 3.04263676298433e-06 all mean 3.1588578508490173e-07
rl training, epoch8, iter0, batch438/1133, batch loss:2.0774058029360276e-09, Training time:239166.55528712273
batch reward last col mean 0.00030076433904469013 first col mean 1.1356516438354447e-07 all mean 0.00029696826823055744
rl training, epoch8, iter0, batch439/1133, batch loss:2.087950997520238e-05, Training time:239193.22708940506
batch reward last col mean 5.122505626786733e-06 first col mean 3.991039193351753e-06 all mean 5.503226020664442e-06
rl training, epoch8, iter0, batch440/1133, batch loss:2.3685787198246544e-07, Training time:239219.5980038643
batch reward last col mean 1.1430660379119217e-05 first col mean 1.1671944776026066e-05 all mean 1.1433116924308706e-05
rl training, epoch8, iter0, batch441/1133, batch loss:6.016974651856799e-08, Training time:239246.38737487793
batch reward last col mean 1.2063653684890596e-06 first col mean 1.5002698319221963e-06 all mean 3.2318844205292407e-06
rl training, epoch8, iter0, batch442/1133, batch loss:1.9723462862941687e-09, Training time:239272.90553975105
batch reward last col mean 1.9840035747620277e-05 first col mean 6.1785381149093155e-06 all mean 1.950374098669272e-05
rl training, epoch8, iter0, batch443/1133, batch loss:5.407192702477914e-07, Training time:239299.09899020195
batch reward last col mean 2.4517685233149678e-06 first col mean 0.00010143534018425271 all mean 4.142007583141094e-06
rl training, epoch8, iter0, batch444/1133, batch loss:5.807590408579699e-09, Training time:239325.6930334568
batch reward last col mean 6.064156332286075e-05 first col mean 5.7391087466385216e-05 all mean 6.061658859835006e-05
rl training, epoch8, iter0, batch445/1133, batch loss:1.3474968909577e-06, Training time:239352.43550372124
batch reward last col mean 1.803068471417646e-06 first col mean 1.83892348104564e-06 all mean 1.8339629832553328e-06
rl training, epoch8, iter0, batch446/1133, batch loss:9.267892231434871e-09, Training time:239379.01088786125
batch reward last col mean 1.1285314940323588e-06 first col mean 7.571379683213308e-07 all mean 1.1449643579908297e-06
rl training, epoch8, iter0, batch447/1133, batch loss:5.9892504289393855e-09, Training time:239405.4624876976
batch reward last col mean 1.5559135135845281e-06 first col mean 2.5822089355642674e-06 all mean 1.5876365750955301e-06
rl training, epoch8, iter0, batch448/1133, batch loss:7.666066004219374e-09, Training time:239431.65719032288
batch reward last col mean 7.424254704346822e-07 first col mean 2.1134401322342455e-06 all mean 7.594221074214147e-07
rl training, epoch8, iter0, batch449/1133, batch loss:9.129655254014324e-09, Training time:239458.55028152466
batch reward last col mean 2.317524092632084e-07 first col mean 6.328406470856862e-06 all mean 4.112142960366327e-06
rl training, epoch8, iter0, batch450/1133, batch loss:5.636713318324382e-10, Training time:239485.2795343399
batch reward last col mean 8.595594636062742e-07 first col mean 7.327338607865386e-06 all mean 9.291563856095308e-07
rl training, epoch8, iter0, batch451/1133, batch loss:2.870316206937673e-09, Training time:239511.902220726
batch reward last col mean 4.0258248645841377e-07 first col mean 9.886067573461332e-07 all mean 5.349231173568114e-07
rl training, epoch8, iter0, batch452/1133, batch loss:1.915812924968563e-10, Training time:239538.44715070724
batch reward last col mean 5.557976692216471e-06 first col mean 2.3151392269937787e-06 all mean 5.599972155323485e-06
rl training, epoch8, iter0, batch453/1133, batch loss:1.7674661023647786e-07, Training time:239564.8164651394
batch reward last col mean 3.7490415252250386e-06 first col mean 1.9866982256644405e-05 all mean 3.88822400054778e-06
rl training, epoch8, iter0, batch454/1133, batch loss:1.7402344099082256e-07, Training time:239591.56637978554
batch reward last col mean 4.637806227947294e-07 first col mean 7.52401092540822e-07 all mean 1.7597876649233513e-06
rl training, epoch8, iter0, batch455/1133, batch loss:2.1159163310358053e-09, Training time:239617.98733520508
batch reward last col mean 4.769913743984944e-07 first col mean 1.2289435744605726e-06 all mean 1.0419043974252418e-06
rl training, epoch8, iter0, batch456/1133, batch loss:9.08568420499023e-09, Training time:239644.30556941032
batch reward last col mean 3.3112673918367364e-06 first col mean 3.622406438807957e-06 all mean 4.052009444421856e-06
rl training, epoch8, iter0, batch457/1133, batch loss:5.935811397961288e-09, Training time:239670.7434105873
batch reward last col mean 2.996949888256495e-07 first col mean 4.944413376506418e-07 all mean 2.4020785076572793e-06
rl training, epoch8, iter0, batch458/1133, batch loss:1.7527973517061923e-09, Training time:239696.9052567482
batch reward last col mean 7.110486990313802e-07 first col mean 9.123994004767155e-07 all mean 8.994036306830822e-07
rl training, epoch8, iter0, batch459/1133, batch loss:6.024649668034954e-10, Training time:239723.28128242493
batch reward last col mean 1.7047017308868817e-07 first col mean 1.6987007711577462e-07 all mean 1.7060791890344262e-07
rl training, epoch8, iter0, batch460/1133, batch loss:6.467398838694294e-10, Training time:239749.74306678772
batch reward last col mean 3.846896106551867e-06 first col mean 1.726935920487449e-06 all mean 1.4551764252246358e-05
rl training, epoch8, iter0, batch461/1133, batch loss:2.5387150159872363e-08, Training time:239776.40381789207
batch reward last col mean 1.5253307594775833e-07 first col mean 5.605646038020495e-06 all mean 2.1960244112051441e-07
rl training, epoch8, iter0, batch462/1133, batch loss:1.015859063535629e-09, Training time:239803.3675584793
batch reward last col mean 2.6137174700124888e-06 first col mean 6.98738722348935e-06 all mean 2.944225798273692e-06
rl training, epoch8, iter0, batch463/1133, batch loss:8.305227083837963e-08, Training time:239830.07083654404
batch reward last col mean 1.6599635273450986e-05 first col mean 3.937134806619724e-06 all mean 7.776709026074968e-06
rl training, epoch8, iter0, batch464/1133, batch loss:1.318690124207933e-06, Training time:239856.51619029045
batch reward last col mean 1.7376280538883293e-06 first col mean 1.1646118309727171e-06 all mean 1.8639251493368647e-06
rl training, epoch8, iter0, batch465/1133, batch loss:1.0607982936505778e-08, Training time:239883.01138234138
batch reward last col mean 6.307214789558202e-06 first col mean 4.9769660108722746e-05 all mean 6.8624663072114345e-06
rl training, epoch8, iter0, batch466/1133, batch loss:2.90525804302888e-07, Training time:239909.62469291687
batch reward last col mean 2.1899680291426193e-07 first col mean 5.864638410457701e-07 all mean 2.2270462807227887e-07
rl training, epoch8, iter0, batch467/1133, batch loss:2.5787463275861455e-09, Training time:239936.16054153442
batch reward last col mean 0.00034156074980273843 first col mean 7.299688604689436e-07 all mean 0.0003383308940101415
rl training, epoch8, iter0, batch468/1133, batch loss:4.39686918980442e-05, Training time:239962.45412778854
batch reward last col mean 1.3527320561479428e-06 first col mean 7.043342975521227e-06 all mean 1.5302395695471205e-05
rl training, epoch8, iter0, batch469/1133, batch loss:2.9179111038502015e-07, Training time:239988.91046261787
batch reward last col mean 0.00013603614934254438 first col mean 1.1274285043327836e-06 all mean 0.00014730473048985004
rl training, epoch8, iter0, batch470/1133, batch loss:6.452880825236207e-06, Training time:240015.3572499752
batch reward last col mean 8.892834557627793e-08 first col mean 9.405891177038939e-08 all mean 2.3590773707837798e-06
rl training, epoch8, iter0, batch471/1133, batch loss:4.951785648188434e-10, Training time:240041.8711092472
batch reward last col mean 1.1201802863070043e-06 first col mean 8.795729513622064e-07 all mean 1.1823849490610883e-06
rl training, epoch8, iter0, batch472/1133, batch loss:2.8506788596338595e-10, Training time:240068.29821515083
batch reward last col mean 0.00011055375944124535 first col mean 8.331500430358574e-05 all mean 0.00011035087663913146
rl training, epoch8, iter0, batch473/1133, batch loss:1.844518351390434e-06, Training time:240094.74989151955
batch reward last col mean 5.9232910132323013e-08 first col mean 5.050828804087359e-07 all mean 1.699833410384599e-05
rl training, epoch8, iter0, batch474/1133, batch loss:9.269327527761106e-09, Training time:240121.14960336685
batch reward last col mean 7.973346782819135e-07 first col mean 6.468261517511564e-07 all mean 7.961809842527146e-07
rl training, epoch8, iter0, batch475/1133, batch loss:4.744597603689726e-09, Training time:240147.92736530304
batch reward last col mean 3.7136060200282373e-06 first col mean 3.706351344590075e-05 all mean 4.048382379551185e-06
rl training, epoch8, iter0, batch476/1133, batch loss:1.2264105464510067e-07, Training time:240174.45801115036
batch reward last col mean 1.2590738833750947e-06 first col mean 4.055116278323112e-07 all mean 5.80275445827283e-06
rl training, epoch8, iter0, batch477/1133, batch loss:2.6436310918143135e-08, Training time:240200.81442308426
batch reward last col mean 2.541462436056463e-06 first col mean 3.4247202620463213e-06 all mean 2.5590545646991814e-06
rl training, epoch8, iter0, batch478/1133, batch loss:8.234352755209784e-09, Training time:240226.97174072266
batch reward last col mean 2.3696627522440394e-06 first col mean 1.169765255326638e-06 all mean 6.492220109066693e-06
rl training, epoch8, iter0, batch479/1133, batch loss:6.055256562831346e-08, Training time:240253.43059897423
batch reward last col mean 5.503943611984141e-06 first col mean 2.2012711724528344e-06 all mean 5.50979621039005e-06
rl training, epoch8, iter0, batch480/1133, batch loss:2.8329417034456128e-08, Training time:240279.7128458023
batch reward last col mean 9.128612873610109e-06 first col mean 1.983818037842866e-06 all mean 8.966845598479267e-06
rl training, epoch8, iter0, batch481/1133, batch loss:2.965633996154793e-07, Training time:240306.2530629635
batch reward last col mean 5.075904709883616e-07 first col mean 1.927149469338474e-06 all mean 5.350380433810642e-06
rl training, epoch8, iter0, batch482/1133, batch loss:2.5711315299048465e-09, Training time:240333.0044488907
batch reward last col mean 4.422483641519648e-07 first col mean 4.4307031998869206e-07 all mean 1.0899067319769529e-06
rl training, epoch8, iter0, batch483/1133, batch loss:4.4886844241531776e-10, Training time:240359.23255324364
batch reward last col mean 7.114519462447788e-07 first col mean 1.8935785419671447e-06 all mean 2.048844180535525e-06
rl training, epoch8, iter0, batch484/1133, batch loss:6.056753432126527e-10, Training time:240385.64318037033
batch reward last col mean 7.185133199527627e-08 first col mean 9.474166517975391e-08 all mean 5.781089384981897e-07
rl training, epoch8, iter0, batch485/1133, batch loss:5.899591926095127e-09, Training time:240411.9810848236
batch reward last col mean 2.8664171622949652e-06 first col mean 3.1286645025829785e-06 all mean 3.845445462502539e-06
rl training, epoch8, iter0, batch486/1133, batch loss:1.4898902556126359e-08, Training time:240438.55567669868
batch reward last col mean 3.068332080147229e-05 first col mean 2.4851015041349456e-05 all mean 3.092917540925555e-05
rl training, epoch8, iter0, batch487/1133, batch loss:6.848946441095904e-07, Training time:240465.1505074501
batch reward last col mean 7.718121537436673e-07 first col mean 2.4225505512731615e-06 all mean 4.153157533437479e-06
rl training, epoch8, iter0, batch488/1133, batch loss:3.2893334722672307e-09, Training time:240491.56534647942
batch reward last col mean 1.218743545905454e-05 first col mean 7.715362926319358e-07 all mean 1.19614933282719e-05
rl training, epoch8, iter0, batch489/1133, batch loss:4.6603275904999464e-07, Training time:240518.27882528305
batch reward last col mean 1.7260242657357594e-06 first col mean 1.7455371335017844e-06 all mean 1.7640134046814637e-06
rl training, epoch8, iter0, batch490/1133, batch loss:1.3206935101095496e-08, Training time:240544.79188013077
batch reward last col mean 2.897632384701865e-06 first col mean 2.001378788918373e-06 all mean 3.2112925509864e-06
rl training, epoch8, iter0, batch491/1133, batch loss:9.111523979754566e-09, Training time:240571.61323356628
batch reward last col mean 7.479595296899788e-06 first col mean 1.9450130821496714e-06 all mean 7.423749138979474e-06
rl training, epoch8, iter0, batch492/1133, batch loss:2.241934140556623e-07, Training time:240598.20835661888
batch reward last col mean 1.9346675799170043e-06 first col mean 3.1234771995514166e-06 all mean 7.056891718093539e-06
rl training, epoch8, iter0, batch493/1133, batch loss:2.738393334311695e-08, Training time:240624.80946159363
batch reward last col mean 1.8225856024400855e-07 first col mean 1.105003320844844e-06 all mean 1.927966195580666e-07
rl training, epoch8, iter0, batch494/1133, batch loss:1.3532839293617371e-09, Training time:240651.40520048141
batch reward last col mean 2.432614110148279e-06 first col mean 4.694835297414102e-06 all mean 2.4545108772144886e-06
rl training, epoch8, iter0, batch495/1133, batch loss:1.9282682117705008e-08, Training time:240678.22524428368
batch reward last col mean 3.0330097615660634e-06 first col mean 0.00010211926564807072 all mean 4.056287707498996e-06
rl training, epoch8, iter0, batch496/1133, batch loss:1.3682412536297761e-08, Training time:240704.7615058422
batch reward last col mean 4.15466092817951e-06 first col mean 2.4864316401362885e-06 all mean 2.3784466975484975e-05
rl training, epoch8, iter0, batch497/1133, batch loss:1.2114077208025265e-07, Training time:240731.73071336746
batch reward last col mean 2.30831192311598e-05 first col mean 4.535813332040561e-06 all mean 2.308912735315971e-05
rl training, epoch8, iter0, batch498/1133, batch loss:2.2180843188834842e-06, Training time:240758.27340006828
batch reward last col mean 8.398597515224537e-07 first col mean 3.758948651011451e-06 all mean 5.235016487858957e-06
rl training, epoch8, iter0, batch499/1133, batch loss:3.1002973521765398e-09, Training time:240785.13372564316
batch reward last col mean 2.7190224500373006e-05 first col mean 2.0169138224446215e-05 all mean 2.7199059331906028e-05
rl training, epoch8, iter0, batch500/1133, batch loss:1.2423632824720698e-06, Training time:240812.04670763016
batch reward last col mean 7.837321618353599e-07 first col mean 1.6196893284359248e-06 all mean 1.4175098840496503e-05
rl training, epoch8, iter0, batch501/1133, batch loss:1.2160482398826389e-08, Training time:240839.49210596085
batch reward last col mean 9.460889486945234e-06 first col mean 8.35562968859449e-06 all mean 9.452242920815479e-06
rl training, epoch8, iter0, batch502/1133, batch loss:3.6482256859926565e-07, Training time:240866.0209326744
batch reward last col mean 1.140199037763523e-05 first col mean 1.3763895367446821e-05 all mean 3.071573519264348e-05
rl training, epoch8, iter0, batch503/1133, batch loss:2.418440772089525e-07, Training time:240892.88064074516
batch reward last col mean 3.0272221351879125e-07 first col mean 1.6498857803526334e-05 all mean 4.690678281349392e-07
rl training, epoch8, iter0, batch504/1133, batch loss:1.0589717991393854e-09, Training time:240919.54746556282
batch reward last col mean 1.4397916856978554e-05 first col mean 1.3804799891659059e-05 all mean 1.442821667296812e-05
rl training, epoch8, iter0, batch505/1133, batch loss:5.237859568296699e-07, Training time:240946.33591461182
batch reward last col mean 4.72760439151898e-05 first col mean 5.735413287766278e-05 all mean 5.3446245146915317e-05
rl training, epoch8, iter0, batch506/1133, batch loss:2.7277237677481025e-06, Training time:240973.0929532051
batch reward last col mean 3.2657251722412184e-05 first col mean 1.447228260076372e-05 all mean 3.24155917041935e-05
rl training, epoch8, iter0, batch507/1133, batch loss:2.3564059858927067e-07, Training time:240999.51272654533
batch reward last col mean 6.121377282397589e-06 first col mean 4.98268855153583e-06 all mean 6.464300440711668e-06
rl training, epoch8, iter0, batch508/1133, batch loss:2.803629399750207e-07, Training time:241026.3036930561
batch reward last col mean 1.049075876835559e-06 first col mean 1.1910583452845458e-06 all mean 1.2907232758152531e-06
rl training, epoch8, iter0, batch509/1133, batch loss:3.4480109878387566e-09, Training time:241053.03629112244
batch reward last col mean 4.324319161241874e-05 first col mean 1.3411590771283954e-06 all mean 4.4018433982273564e-05
rl training, epoch8, iter0, batch510/1133, batch loss:1.5012944913905812e-06, Training time:241079.5667769909
batch reward last col mean 5.99702389081358e-06 first col mean 8.909400639822707e-05 all mean 1.8648241166374646e-05
rl training, epoch8, iter0, batch511/1133, batch loss:4.971803946318687e-07, Training time:241105.88587927818
batch reward last col mean 6.398760888259858e-06 first col mean 6.307561761786928e-06 all mean 6.531047802127432e-06
rl training, epoch8, iter0, batch512/1133, batch loss:1.5212000903375156e-07, Training time:241132.29223537445
batch reward last col mean 8.001998139661737e-06 first col mean 6.661110774075496e-07 all mean 8.222695214499254e-06
rl training, epoch8, iter0, batch513/1133, batch loss:2.82625052250296e-07, Training time:241158.92631196976
batch reward last col mean 1.8758030364551814e-06 first col mean 1.2695278428509482e-06 all mean 2.1485523120645666e-06
rl training, epoch8, iter0, batch514/1133, batch loss:4.259087305058529e-08, Training time:241185.4701666832
batch reward last col mean 2.958045797640807e-06 first col mean 2.4193659555749036e-06 all mean 2.9526477192121092e-06
rl training, epoch8, iter0, batch515/1133, batch loss:4.6419312837997495e-09, Training time:241211.90704536438
batch reward last col mean 1.0923093896053615e-06 first col mean 6.258307507778227e-07 all mean 3.225252157790237e-06
rl training, epoch8, iter0, batch516/1133, batch loss:5.05492758762216e-09, Training time:241238.57323741913
batch reward last col mean 9.303027582063805e-06 first col mean 5.397941094997805e-06 all mean 1.0740312973211985e-05
rl training, epoch8, iter0, batch517/1133, batch loss:3.2115517001329863e-07, Training time:241264.94981598854
batch reward last col mean 6.630303346355504e-07 first col mean 4.2644887798815034e-06 all mean 6.919115094206063e-07
rl training, epoch8, iter0, batch518/1133, batch loss:2.270868471043741e-08, Training time:241291.2248866558
batch reward last col mean 9.177574611385353e-07 first col mean 1.2809570080207777e-06 all mean 9.286745807912666e-07
rl training, epoch8, iter0, batch519/1133, batch loss:3.831434725043437e-09, Training time:241317.99679851532
batch reward last col mean 1.8174417846239521e-06 first col mean 9.405470336787403e-06 all mean 7.119077963579912e-06
rl training, epoch8, iter0, batch520/1133, batch loss:7.771850718540918e-09, Training time:241344.58188176155
batch reward last col mean 4.81602967283834e-07 first col mean 5.377840807341272e-06 all mean 1.2943730325787328e-05
rl training, epoch8, iter0, batch521/1133, batch loss:8.674187590429483e-09, Training time:241371.74093699455
batch reward last col mean 4.894368430541363e-06 first col mean 4.710451321443543e-05 all mean 6.252879302337533e-06
rl training, epoch8, iter0, batch522/1133, batch loss:1.4900821270202869e-06, Training time:241398.53100037575
batch reward last col mean 1.1443216152429159e-07 first col mean 2.816249661918846e-06 all mean 1.77082147274632e-05
rl training, epoch8, iter0, batch523/1133, batch loss:1.77712303206512e-10, Training time:241424.55915665627
batch reward last col mean 8.339738087670412e-06 first col mean 0.0013335217954590917 all mean 2.6834168238565326e-05
rl training, epoch8, iter0, batch524/1133, batch loss:4.343606997281313e-05, Training time:241451.27665996552
batch reward last col mean 3.502936749555374e-07 first col mean 7.209133059404849e-07 all mean 3.572938283014082e-07
rl training, epoch8, iter0, batch525/1133, batch loss:2.5387194568793348e-09, Training time:241477.91771888733
batch reward last col mean 1.54363860929152e-05 first col mean 1.0505498721613549e-05 all mean 1.537442767585162e-05
rl training, epoch8, iter0, batch526/1133, batch loss:1.012780217024556e-06, Training time:241504.60059309006
batch reward last col mean 5.226002599556523e-07 first col mean 4.954900987286237e-07 all mean 1.0465200830367394e-06
rl training, epoch8, iter0, batch527/1133, batch loss:2.460494030742666e-09, Training time:241531.10437560081
batch reward last col mean 2.358445954087074e-07 first col mean 6.718895519952639e-07 all mean 1.443784299226536e-06
rl training, epoch8, iter0, batch528/1133, batch loss:4.330741043556685e-10, Training time:241557.28838658333
batch reward last col mean 1.2258431070222287e-06 first col mean 1.1527517926879227e-06 all mean 1.2515707794591435e-06
rl training, epoch8, iter0, batch529/1133, batch loss:9.198712902502848e-09, Training time:241583.69940686226
batch reward last col mean 2.0024885998282116e-06 first col mean 2.434714474475186e-07 all mean 2.233803797935252e-06
rl training, epoch8, iter0, batch530/1133, batch loss:5.295546756656222e-08, Training time:241610.0196735859
batch reward last col mean 1.4521358480124036e-06 first col mean 3.89443130188738e-06 all mean 1.488636030444468e-06
rl training, epoch8, iter0, batch531/1133, batch loss:6.9774892530460875e-09, Training time:241636.59803676605
batch reward last col mean 1.6793519534985535e-05 first col mean 5.502062094819848e-07 all mean 1.1946982340305112e-05
rl training, epoch8, iter0, batch532/1133, batch loss:2.1700557226722594e-06, Training time:241663.08253836632
batch reward last col mean 6.700620502897436e-08 first col mean 1.9018327179765038e-07 all mean 1.8265097878611414e-07
rl training, epoch8, iter0, batch533/1133, batch loss:3.3779454233773265e-10, Training time:241689.40144348145
batch reward last col mean 0.0001505802501924336 first col mean 0.00023922784021124244 all mean 0.00015214181621558964
rl training, epoch8, iter0, batch534/1133, batch loss:3.3943272228498245e-06, Training time:241716.2512192726
batch reward last col mean 1.0423717355934059e-07 first col mean 1.3088495620650065e-07 all mean 2.221696604465251e-06
rl training, epoch8, iter0, batch535/1133, batch loss:1.0102675640499825e-10, Training time:241742.60424923897
batch reward last col mean 6.69119856411271e-07 first col mean 1.8576548654891667e-06 all mean 6.966009209463664e-07
rl training, epoch8, iter0, batch536/1133, batch loss:2.3212980426734475e-09, Training time:241769.4697751999
batch reward last col mean 4.439281838131137e-06 first col mean 0.0010657717939466238 all mean 1.5269723007804714e-05
rl training, epoch8, iter0, batch537/1133, batch loss:7.277040481312724e-08, Training time:241796.15105819702
batch reward last col mean 5.3839708016312215e-06 first col mean 4.884065560872841e-07 all mean 5.940899427514523e-06
rl training, epoch8, iter0, batch538/1133, batch loss:1.5905614247913036e-07, Training time:241822.79554009438
batch reward last col mean 2.082569153571967e-06 first col mean 7.630760592292063e-06 all mean 2.14178248825192e-06
rl training, epoch8, iter0, batch539/1133, batch loss:1.1147532896771395e-09, Training time:241849.40683293343
batch reward last col mean 4.7586630103069183e-07 first col mean 2.7131932256452274e-07 all mean 4.762356127230305e-07
rl training, epoch8, iter0, batch540/1133, batch loss:1.4399458514446906e-08, Training time:241875.74254012108
batch reward last col mean 7.604867278132588e-07 first col mean 1.7362181097269058e-05 all mean 9.348432286060415e-07
rl training, epoch8, iter0, batch541/1133, batch loss:2.3929298542668676e-09, Training time:241902.35564613342
batch reward last col mean 1.312638687522849e-06 first col mean 7.866150895097235e-07 all mean 1.3073384934614296e-06
rl training, epoch8, iter0, batch542/1133, batch loss:4.9835993110036725e-08, Training time:241929.04327130318
batch reward last col mean 0.0004677720135077834 first col mean 0.00023396332107950002 all mean 0.0004760342126246542
rl training, epoch8, iter0, batch543/1133, batch loss:3.918789661838673e-05, Training time:241955.5557153225
batch reward last col mean 7.04987978679128e-05 first col mean 3.2324947824236006e-05 all mean 8.633738616481423e-05
rl training, epoch8, iter0, batch544/1133, batch loss:1.629722760299046e-06, Training time:241982.36568808556
batch reward last col mean 8.883119306801746e-08 first col mean 2.0688111135314102e-07 all mean 1.0234182354906807e-06
rl training, epoch8, iter0, batch545/1133, batch loss:4.1536918349294183e-10, Training time:242008.93009066582
batch reward last col mean 5.661069280904485e-06 first col mean 3.825364274234744e-06 all mean 5.647304988087853e-06
rl training, epoch8, iter0, batch546/1133, batch loss:3.534300319074646e-08, Training time:242035.7777633667
batch reward last col mean 9.890811725199455e-07 first col mean 3.6485103009908926e-06 all mean 5.040019004809437e-06
rl training, epoch8, iter0, batch547/1133, batch loss:1.0243686787703155e-08, Training time:242062.33235812187
batch reward last col mean 0.0005145317991264164 first col mean 0.0005134796374477446 all mean 0.000534186779987067
rl training, epoch8, iter0, batch548/1133, batch loss:9.073931323655415e-06, Training time:242088.80408406258
batch reward last col mean 0.00015391955093946308 first col mean 3.9612777982256375e-06 all mean 0.0001515387702966109
rl training, epoch8, iter0, batch549/1133, batch loss:3.5193681924283737e-06, Training time:242115.98374557495
batch reward last col mean 8.105546953629528e-07 first col mean 1.6610405282335705e-06 all mean 1.9257199710409623e-06
rl training, epoch8, iter0, batch550/1133, batch loss:3.7224894278153897e-09, Training time:242142.59035468102
batch reward last col mean 3.7099162000231445e-06 first col mean 1.0191756700805854e-06 all mean 4.486144462134689e-06
rl training, epoch8, iter0, batch551/1133, batch loss:3.026184813847976e-08, Training time:242169.52528905869
batch reward last col mean 1.5071557299961569e-06 first col mean 4.400070974952541e-05 all mean 1.956686446646927e-06
rl training, epoch8, iter0, batch552/1133, batch loss:2.3142398219988536e-07, Training time:242196.0791068077
batch reward last col mean 7.458639629476238e-06 first col mean 3.820349775196519e-06 all mean 7.352438842644915e-06
rl training, epoch8, iter0, batch553/1133, batch loss:3.378052610969462e-07, Training time:242222.76624655724
batch reward last col mean 1.8846474176825723e-06 first col mean 1.7371689864376094e-06 all mean 1.8834734873962589e-06
rl training, epoch8, iter0, batch554/1133, batch loss:1.0918281390104312e-08, Training time:242249.5348277092
batch reward last col mean 1.7059824131138157e-06 first col mean 1.1516489394125529e-05 all mean 4.893478035228327e-06
rl training, epoch8, iter0, batch555/1133, batch loss:1.1172256897395982e-08, Training time:242276.3617823124
batch reward last col mean 1.8388650460110512e-06 first col mean 3.343202479300089e-05 all mean 2.477262114553014e-06
rl training, epoch8, iter0, batch556/1133, batch loss:6.742766345269047e-08, Training time:242302.79799556732
batch reward last col mean 2.1541520254686475e-05 first col mean 2.1397732780314982e-05 all mean 2.1546251446125098e-05
rl training, epoch8, iter0, batch557/1133, batch loss:7.866287319302501e-07, Training time:242329.27873563766
batch reward last col mean 1.987448376894463e-05 first col mean 1.5901188817224465e-05 all mean 2.0572313587763347e-05
rl training, epoch8, iter0, batch558/1133, batch loss:6.037986111095961e-08, Training time:242355.61733078957
batch reward last col mean 2.653371666383464e-06 first col mean 2.1420505618152674e-06 all mean 2.0742534616147168e-05
rl training, epoch8, iter0, batch559/1133, batch loss:3.2057013044095584e-08, Training time:242381.78095149994
batch reward last col mean 5.4834770708112046e-05 first col mean 5.565478204516694e-05 all mean 5.665108255925588e-05
rl training, epoch8, iter0, batch560/1133, batch loss:3.679231895148405e-06, Training time:242407.94264888763
batch reward last col mean 1.7633790605486865e-07 first col mean 0.0024401515256613493 all mean 2.487984784238506e-05
rl training, epoch8, iter0, batch561/1133, batch loss:0.0003658645146060735, Training time:242434.12604117393
batch reward last col mean 5.692874765372835e-05 first col mean 1.1262143743806519e-05 all mean 5.651776154991239e-05
rl training, epoch8, iter0, batch562/1133, batch loss:1.636572164898098e-06, Training time:242460.27992916107
batch reward last col mean 1.0841438324860064e-06 first col mean 2.3194579057417286e-07 all mean 2.6316324692743365e-06
rl training, epoch8, iter0, batch563/1133, batch loss:2.107005592222322e-08, Training time:242486.262488842
batch reward last col mean 6.92661342327483e-06 first col mean 6.889434644108405e-06 all mean 6.92691628501052e-06
rl training, epoch8, iter0, batch564/1133, batch loss:5.2933859961967755e-08, Training time:242512.57491874695
batch reward last col mean 4.4215568095751223e-07 first col mean 7.470892796845874e-06 all mean 1.522388743069314e-06
rl training, epoch8, iter0, batch565/1133, batch loss:3.757256172853829e-10, Training time:242538.78208470345
batch reward last col mean 2.2617187767082214e-07 first col mean 4.843397505283065e-07 all mean 2.478379883541493e-07
rl training, epoch8, iter0, batch566/1133, batch loss:8.056096900688203e-10, Training time:242565.42471432686
batch reward last col mean 7.985054821801896e-07 first col mean 1.2233160305186175e-05 all mean 3.469927833066322e-05
rl training, epoch8, iter0, batch567/1133, batch loss:2.026070511362832e-08, Training time:242591.78469944
batch reward last col mean 4.856808118347544e-06 first col mean 4.1188187083207595e-07 all mean 4.812566658074502e-06
rl training, epoch8, iter0, batch568/1133, batch loss:1.425882487637864e-07, Training time:242618.10137486458
batch reward last col mean 8.984812666312791e-06 first col mean 8.588938726461492e-06 all mean 8.981321116152685e-06
rl training, epoch8, iter0, batch569/1133, batch loss:3.749567767385997e-08, Training time:242644.56193494797
batch reward last col mean 1.035399236570811e-06 first col mean 1.3875835520593682e-06 all mean 1.409641981808818e-06
rl training, epoch8, iter0, batch570/1133, batch loss:3.4650064151264814e-08, Training time:242670.71748280525
batch reward last col mean 7.182083550105745e-08 first col mean 5.2541508921422064e-06 all mean 1.9817787688225508e-05
rl training, epoch8, iter0, batch571/1133, batch loss:8.121464056820571e-10, Training time:242696.72155570984
batch reward last col mean 9.058103387360461e-07 first col mean 5.842142059009348e-07 all mean 1.2927213902003132e-05
rl training, epoch8, iter0, batch572/1133, batch loss:4.562066635571682e-08, Training time:242723.1297507286
batch reward last col mean 1.613242238818202e-05 first col mean 5.396507845034648e-07 all mean 1.638084177102428e-05
rl training, epoch8, iter0, batch573/1133, batch loss:3.693513406233251e-07, Training time:242749.10448265076
batch reward last col mean 1.676573901931988e-06 first col mean 3.2383504731114954e-05 all mean 1.9863200577674434e-06
rl training, epoch8, iter0, batch574/1133, batch loss:1.8667458689947125e-08, Training time:242775.23826813698
batch reward last col mean 3.5838263556797756e-06 first col mean 4.6247387217590585e-06 all mean 3.614968591136858e-06
rl training, epoch8, iter0, batch575/1133, batch loss:5.9042790212515683e-08, Training time:242801.2752737999
batch reward last col mean 2.348076293401391e-07 first col mean 5.112237886351068e-07 all mean 3.522458769111836e-07
rl training, epoch8, iter0, batch576/1133, batch loss:5.480531029000701e-10, Training time:242827.4452240467
batch reward last col mean 3.696291969390586e-06 first col mean 4.9975301408267114e-06 all mean 3.771083356696181e-06
rl training, epoch8, iter0, batch577/1133, batch loss:6.710416755595361e-08, Training time:242853.430778265
batch reward last col mean 4.451262793736532e-05 first col mean 2.026767106144689e-06 all mean 4.365082713775337e-05
rl training, epoch8, iter0, batch578/1133, batch loss:2.394901230218238e-06, Training time:242879.36565208435
batch reward last col mean 3.5728851344174473e-06 first col mean 0.0009720160160213709 all mean 1.3475461855705362e-05
rl training, epoch8, iter0, batch579/1133, batch loss:3.240812063154408e-09, Training time:242905.37795186043
batch reward last col mean 3.2466434163325175e-07 first col mean 8.225017609220231e-07 all mean 3.567024862149992e-07
rl training, epoch8, iter0, batch580/1133, batch loss:1.2787207959163993e-09, Training time:242932.02194070816
batch reward last col mean 2.39877772401087e-06 first col mean 2.2434373022406362e-05 all mean 5.777923888672376e-06
rl training, epoch8, iter0, batch581/1133, batch loss:4.385561780395619e-08, Training time:242959.17883062363
batch reward last col mean 3.188058326486498e-05 first col mean 1.013899873214541e-05 all mean 3.261561141698621e-05
rl training, epoch8, iter0, batch582/1133, batch loss:5.388896511249186e-07, Training time:242985.5128827095
batch reward last col mean 9.743726877786685e-06 first col mean 1.8523451217333786e-06 all mean 9.666490768722724e-06
rl training, epoch8, iter0, batch583/1133, batch loss:2.641226046762313e-07, Training time:243011.63423728943
batch reward last col mean 7.737029932286532e-07 first col mean 2.7649232379189925e-06 all mean 8.243340516855824e-07
rl training, epoch8, iter0, batch584/1133, batch loss:9.073018780725306e-09, Training time:243038.29471755028
batch reward last col mean 4.914528517474537e-07 first col mean 9.000747240861529e-07 all mean 4.977878234058153e-07
rl training, epoch8, iter0, batch585/1133, batch loss:6.154213805231734e-10, Training time:243064.9857969284
batch reward last col mean 1.064693009311668e-07 first col mean 1.2229447747813538e-06 all mean 3.687873117996787e-07
rl training, epoch8, iter0, batch586/1133, batch loss:5.677830428041375e-10, Training time:243091.66044545174
batch reward last col mean 3.9556360320602835e-07 first col mean 2.745230460732273e-07 all mean 2.1032434233347885e-05
rl training, epoch8, iter0, batch587/1133, batch loss:4.252858953890382e-09, Training time:243118.26800727844
batch reward last col mean 6.8477584136417136e-06 first col mean 1.132514444179833e-05 all mean 6.908982413733611e-06
rl training, epoch8, iter0, batch588/1133, batch loss:2.1275927508668246e-07, Training time:243145.38038563728
batch reward last col mean 2.0706568193418207e-06 first col mean 1.1358773917891085e-05 all mean 2.1906205347477226e-06
rl training, epoch8, iter0, batch589/1133, batch loss:1.710833608115081e-08, Training time:243171.90802526474
batch reward last col mean 4.1850950083244243e-07 first col mean 1.0661573242032318e-06 all mean 6.825803211540915e-07
rl training, epoch8, iter0, batch590/1133, batch loss:9.656581090311533e-10, Training time:243198.48762631416
batch reward last col mean 9.590580702933948e-07 first col mean 1.2059309710821253e-06 all mean 1.2657229717660812e-06
rl training, epoch8, iter0, batch591/1133, batch loss:7.132969326306693e-09, Training time:243224.90435814857
batch reward last col mean 0.0003710299788508564 first col mean 2.6407033146824688e-06 all mean 0.0003645330434665084
rl training, epoch8, iter0, batch592/1133, batch loss:1.1066164006479084e-05, Training time:243251.9855246544
batch reward last col mean 2.147142731701024e-05 first col mean 1.7302923879469745e-05 all mean 2.1532394384848885e-05
rl training, epoch8, iter0, batch593/1133, batch loss:1.235004418731478e-07, Training time:243278.7625555992
batch reward last col mean 7.710202771704644e-05 first col mean 6.166765160742216e-06 all mean 7.672642095712945e-05
rl training, epoch8, iter0, batch594/1133, batch loss:4.290606739232317e-06, Training time:243305.52106142044
batch reward last col mean 0.00015123147750273347 first col mean 0.00028966472018510103 all mean 0.0001527117274235934
rl training, epoch8, iter0, batch595/1133, batch loss:5.968877758277813e-06, Training time:243332.9237575531
batch reward last col mean 1.7766599285096163e-06 first col mean 8.274133506347425e-06 all mean 1.9032511318073375e-06
rl training, epoch8, iter0, batch596/1133, batch loss:1.0753797852203206e-08, Training time:243359.7220041752
batch reward last col mean 1.688096403995587e-06 first col mean 1.3103862102070707e-06 all mean 1.6812065268823062e-06
rl training, epoch8, iter0, batch597/1133, batch loss:1.2046963426826096e-08, Training time:243386.75340533257
batch reward last col mean 2.289889016537927e-05 first col mean 2.874012807296822e-06 all mean 2.2735601305612363e-05
rl training, epoch8, iter0, batch598/1133, batch loss:8.186482318706112e-07, Training time:243413.21560788155
batch reward last col mean 1.7682915540717659e-06 first col mean 5.102577915749862e-07 all mean 1.8982460687766434e-06
rl training, epoch8, iter0, batch599/1133, batch loss:3.762174927146589e-08, Training time:243440.089977026
batch reward last col mean 3.4476690871088067e-06 first col mean 4.925216217088746e-06 all mean 3.4961456094606547e-06
rl training, epoch8, iter0, batch600/1133, batch loss:2.4607949011823393e-09, Training time:243467.34288048744
