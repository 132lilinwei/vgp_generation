loaded D
Using device cuda:4
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.8821068348762533 Time: 137.49847602844238 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 1.105541514698005 Time: 109.51552700996399 s
cur_epoch: 1
D Training Loss: 0.9647568543716962 Time: 110.90195870399475 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.256172803473073 Time: 136.3607017993927 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 1.0567550704948478 Time: 111.60724520683289 s
cur_epoch: 1
D Training Loss: 0.9541768586856543 Time: 111.58354544639587 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.0440791488640726 Time: 137.72590804100037 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 1.0028434149585566 Time: 111.38531565666199 s
cur_epoch: 1
D Training Loss: 0.9087291778659567 Time: 110.8237612247467 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.9071818361846304 Time: 136.84425354003906 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.9376369066082684 Time: 113.26621222496033 s
cur_epoch: 1
D Training Loss: 0.86486625976512 Time: 113.01970148086548 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.802858270803386 Time: 136.62476420402527 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.8620644365383899 Time: 111.06573939323425 s
cur_epoch: 1
D Training Loss: 0.7931057231571437 Time: 112.29151725769043 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.7168546236413618 Time: 136.65348100662231 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.7875973874241088 Time: 110.89728260040283 s
cur_epoch: 1
D Training Loss: 0.733686063685253 Time: 109.73299074172974 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.6434147292706993 Time: 136.49685740470886 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.736444328489918 Time: 116.70580077171326 s
cur_epoch: 1
D Training Loss: 0.6841234241506218 Time: 115.9694607257843 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.5784063162471167 Time: 138.34514689445496 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6978905779907163 Time: 118.31439161300659 s
cur_epoch: 1
D Training Loss: 0.6518099259351695 Time: 118.42208218574524 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.52046740107692 Time: 138.01127243041992 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6429496601894695 Time: 115.87064790725708 s
cur_epoch: 1
D Training Loss: 0.6151198973617823 Time: 117.36278653144836 s
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.468434951627349 Time: 137.41913676261902 s
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6007287542007712 Time: 121.71496367454529 s
cur_epoch: 1
D Training Loss: 0.5765264656621591 Time: 119.1505994796753 s
begin rl....
rl epoch 0, begin RL for generator...
batch reward last col mean 0.14650513231754303 first col mean 0.11743546277284622 all mean 0.13781720399856567
0.3420363664627075 0.3420363664627075
rl training, epoch0, iter0, batch0/1133, batch loss:0.3420363664627075, Training time:3.4883947372436523
batch reward last col mean 0.1291077584028244 first col mean 0.15428955852985382 all mean 0.13539814949035645
0.34110960364341736 0.34110960364341736
rl training, epoch0, iter0, batch1/1133, batch loss:0.34110960364341736, Training time:6.850914239883423
batch reward last col mean 0.11614847928285599 first col mean 0.1384047120809555 all mean 0.12984800338745117
0.36520010232925415 0.36520010232925415
rl training, epoch0, iter0, batch2/1133, batch loss:0.36520010232925415, Training time:9.95405650138855
batch reward last col mean 0.1499961018562317 first col mean 0.12559780478477478 all mean 0.15320171415805817
0.3785296380519867 0.3785296380519867
rl training, epoch0, iter0, batch3/1133, batch loss:0.3785296380519867, Training time:13.266074419021606
batch reward last col mean 0.1394394338130951 first col mean 0.1395644247531891 all mean 0.139606311917305
0.3429085612297058 0.3429085612297058
rl training, epoch0, iter0, batch4/1133, batch loss:0.3429085612297058, Training time:16.367538452148438
batch reward last col mean 0.12219203263521194 first col mean 0.12930035591125488 all mean 0.1262817233800888
0.3413834571838379 0.3413834571838379
rl training, epoch0, iter0, batch5/1133, batch loss:0.3413834571838379, Training time:21.00504422187805
batch reward last col mean 0.15165457129478455 first col mean 0.1383400559425354 all mean 0.14794470369815826
0.3417559862136841 0.3417559862136841
rl training, epoch0, iter0, batch6/1133, batch loss:0.3417559862136841, Training time:24.406729459762573
batch reward last col mean 0.11559139937162399 first col mean 0.14720946550369263 all mean 0.11829425394535065
0.30603164434432983 0.30603161454200745
rl training, epoch0, iter0, batch7/1133, batch loss:0.30603161454200745, Training time:27.385562658309937
batch reward last col mean 0.13906270265579224 first col mean 0.16429048776626587 all mean 0.14258268475532532
0.344066858291626 0.344066858291626
rl training, epoch0, iter0, batch8/1133, batch loss:0.344066858291626, Training time:31.526079177856445
batch reward last col mean 0.12696212530136108 first col mean 0.14648088812828064 all mean 0.12688332796096802
0.292564332485199 0.292564332485199
rl training, epoch0, iter0, batch9/1133, batch loss:0.292564332485199, Training time:34.791189193725586
batch reward last col mean 0.16647377610206604 first col mean 0.13872379064559937 all mean 0.1609080284833908
0.31575092673301697 0.31575092673301697
rl training, epoch0, iter0, batch10/1133, batch loss:0.31575092673301697, Training time:38.80771827697754
batch reward last col mean 0.1306546926498413 first col mean 0.16710400581359863 all mean 0.13572220504283905
0.3608528971672058 0.3608528673648834
rl training, epoch0, iter0, batch11/1133, batch loss:0.3608528673648834, Training time:42.216851234436035
batch reward last col mean 0.14762835204601288 first col mean 0.14731693267822266 all mean 0.1449921876192093
0.31320199370384216 0.31320199370384216
rl training, epoch0, iter0, batch12/1133, batch loss:0.31320199370384216, Training time:45.13035988807678
batch reward last col mean 0.14462614059448242 first col mean 0.1667984426021576 all mean 0.14610420167446136
0.36130109429359436 0.36130109429359436
rl training, epoch0, iter0, batch13/1133, batch loss:0.36130109429359436, Training time:47.50053882598877
batch reward last col mean 0.11569461226463318 first col mean 0.14121583104133606 all mean 0.11864377558231354
0.25963035225868225 0.25963035225868225
rl training, epoch0, iter0, batch14/1133, batch loss:0.25963035225868225, Training time:50.44094371795654
batch reward last col mean 0.13616923987865448 first col mean 0.15911662578582764 all mean 0.1399558037519455
0.3702870011329651 0.3702870011329651
rl training, epoch0, iter0, batch15/1133, batch loss:0.3702870011329651, Training time:53.09636926651001
batch reward last col mean 0.16800807416439056 first col mean 0.14913612604141235 all mean 0.16730903089046478
0.36559510231018066 0.36559510231018066
rl training, epoch0, iter0, batch16/1133, batch loss:0.36559510231018066, Training time:55.73482275009155
batch reward last col mean 0.09229409694671631 first col mean 0.15968558192253113 all mean 0.10593995451927185
0.29114896059036255 0.29114896059036255
rl training, epoch0, iter0, batch17/1133, batch loss:0.29114896059036255, Training time:58.64937138557434
batch reward last col mean 0.14978696405887604 first col mean 0.14908385276794434 all mean 0.1503516286611557
0.3598358631134033 0.3598358631134033
rl training, epoch0, iter0, batch18/1133, batch loss:0.3598358631134033, Training time:61.320685386657715
batch reward last col mean 0.1335650533437729 first col mean 0.14903734624385834 all mean 0.1368805468082428
0.3242550790309906 0.3242550790309906
rl training, epoch0, iter0, batch19/1133, batch loss:0.3242550790309906, Training time:63.89089560508728
batch reward last col mean 0.14483767747879028 first col mean 0.15976612269878387 all mean 0.14623931050300598
0.31524398922920227 0.31524398922920227
rl training, epoch0, iter0, batch20/1133, batch loss:0.31524398922920227, Training time:66.6745502948761
batch reward last col mean 0.13654817640781403 first col mean 0.1377643495798111 all mean 0.1413826048374176
0.31056445837020874 0.31056445837020874
rl training, epoch0, iter0, batch21/1133, batch loss:0.31056445837020874, Training time:69.63588261604309
batch reward last col mean 0.15442325174808502 first col mean 0.15208975970745087 all mean 0.15732115507125854
0.3345717489719391 0.3345717489719391
rl training, epoch0, iter0, batch22/1133, batch loss:0.3345717489719391, Training time:72.40446329116821
batch reward last col mean 0.15381574630737305 first col mean 0.14115585386753082 all mean 0.15523070096969604
0.3864317834377289 0.3864317536354065
rl training, epoch0, iter0, batch23/1133, batch loss:0.3864317536354065, Training time:75.82939982414246
batch reward last col mean 0.13256992399692535 first col mean 0.17555320262908936 all mean 0.13907943665981293
0.32457929849624634 0.32457929849624634
rl training, epoch0, iter0, batch24/1133, batch loss:0.32457929849624634, Training time:78.82921504974365
batch reward last col mean 0.15501335263252258 first col mean 0.16551727056503296 all mean 0.1564904898405075
0.36230820417404175 0.36230820417404175
rl training, epoch0, iter0, batch25/1133, batch loss:0.36230820417404175, Training time:81.3980484008789
batch reward last col mean 0.14553731679916382 first col mean 0.1514182686805725 all mean 0.14365383982658386
0.29378628730773926 0.29378628730773926
rl training, epoch0, iter0, batch26/1133, batch loss:0.29378628730773926, Training time:83.85740947723389
batch reward last col mean 0.16704478859901428 first col mean 0.17755989730358124 all mean 0.1642449051141739
0.362650066614151 0.3626500070095062
rl training, epoch0, iter0, batch27/1133, batch loss:0.3626500070095062, Training time:86.62613487243652
batch reward last col mean 0.1648775041103363 first col mean 0.15532949566841125 all mean 0.16064904630184174
0.30730563402175903 0.30730563402175903
rl training, epoch0, iter0, batch28/1133, batch loss:0.30730563402175903, Training time:89.22604990005493
batch reward last col mean 0.12939849495887756 first col mean 0.17111757397651672 all mean 0.1363580822944641
0.3317403793334961 0.3317403495311737
rl training, epoch0, iter0, batch29/1133, batch loss:0.3317403495311737, Training time:91.9104368686676
batch reward last col mean 0.20036956667900085 first col mean 0.17997093498706818 all mean 0.19353154301643372
0.3869885206222534 0.3869885206222534
rl training, epoch0, iter0, batch30/1133, batch loss:0.3869885206222534, Training time:95.58111500740051
batch reward last col mean 0.15641745924949646 first col mean 0.15923520922660828 all mean 0.1589284986257553
0.3828307092189789 0.3828306794166565
rl training, epoch0, iter0, batch31/1133, batch loss:0.3828306794166565, Training time:98.54441380500793
batch reward last col mean 0.17515642940998077 first col mean 0.15512073040008545 all mean 0.17917275428771973
0.38883066177368164 0.38883066177368164
rl training, epoch0, iter0, batch32/1133, batch loss:0.38883066177368164, Training time:100.90663480758667
batch reward last col mean 0.14399978518486023 first col mean 0.16271473467350006 all mean 0.14950035512447357
0.32000732421875 0.32000732421875
rl training, epoch0, iter0, batch33/1133, batch loss:0.32000732421875, Training time:103.26308178901672
batch reward last col mean 0.18207614123821259 first col mean 0.14980162680149078 all mean 0.17060542106628418
0.34635505080223083 0.34635505080223083
rl training, epoch0, iter0, batch34/1133, batch loss:0.34635505080223083, Training time:105.21908259391785
batch reward last col mean 0.16815660893917084 first col mean 0.15217779576778412 all mean 0.16148483753204346
0.3500101566314697 0.3500101566314697
rl training, epoch0, iter0, batch35/1133, batch loss:0.3500101566314697, Training time:108.16556239128113
batch reward last col mean 0.17905165255069733 first col mean 0.15825799107551575 all mean 0.17235764861106873
0.3438720405101776 0.3438720107078552
rl training, epoch0, iter0, batch36/1133, batch loss:0.3438720107078552, Training time:111.70418524742126
batch reward last col mean 0.16139955818653107 first col mean 0.1764117181301117 all mean 0.1541602611541748
0.3589567542076111 0.3589567244052887
rl training, epoch0, iter0, batch37/1133, batch loss:0.3589567244052887, Training time:114.87220549583435
batch reward last col mean 0.16285957396030426 first col mean 0.17849473655223846 all mean 0.16465885937213898
0.3745735287666321 0.3745735287666321
rl training, epoch0, iter0, batch38/1133, batch loss:0.3745735287666321, Training time:117.37694954872131
batch reward last col mean 0.17191965878009796 first col mean 0.18521158397197723 all mean 0.17377106845378876
0.3500199317932129 0.3500199317932129
rl training, epoch0, iter0, batch39/1133, batch loss:0.3500199317932129, Training time:120.64530539512634
batch reward last col mean 0.15490970015525818 first col mean 0.16757644712924957 all mean 0.15742844343185425
0.3402409851551056 0.3402409851551056
rl training, epoch0, iter0, batch40/1133, batch loss:0.3402409851551056, Training time:123.53854298591614
batch reward last col mean 0.16116821765899658 first col mean 0.15542396903038025 all mean 0.15648818016052246
0.3787055015563965 0.3787055015563965
rl training, epoch0, iter0, batch41/1133, batch loss:0.3787055015563965, Training time:126.59206938743591
batch reward last col mean 0.17570000886917114 first col mean 0.17765800654888153 all mean 0.16831515729427338
0.3710046112537384 0.37100455164909363
rl training, epoch0, iter0, batch42/1133, batch loss:0.37100455164909363, Training time:128.95127534866333
batch reward last col mean 0.12866054475307465 first col mean 0.15973809361457825 all mean 0.12844142317771912
0.3065706193447113 0.3065706193447113
rl training, epoch0, iter0, batch43/1133, batch loss:0.3065706193447113, Training time:131.9626247882843
batch reward last col mean 0.16134977340698242 first col mean 0.16603083908557892 all mean 0.15884824097156525
0.3224430978298187 0.3224430978298187
rl training, epoch0, iter0, batch44/1133, batch loss:0.3224430978298187, Training time:134.80111837387085
batch reward last col mean 0.1464015543460846 first col mean 0.1799841672182083 all mean 0.14734677970409393
0.31272146105766296 0.31272146105766296
rl training, epoch0, iter0, batch45/1133, batch loss:0.31272146105766296, Training time:137.37708282470703
batch reward last col mean 0.17139177024364471 first col mean 0.15543672442436218 all mean 0.1653154194355011
0.34531497955322266 0.34531494975090027
rl training, epoch0, iter0, batch46/1133, batch loss:0.34531494975090027, Training time:140.16235041618347
batch reward last col mean 0.15594547986984253 first col mean 0.1651296317577362 all mean 0.15814636647701263
0.3201862871646881 0.3201862871646881
rl training, epoch0, iter0, batch47/1133, batch loss:0.3201862871646881, Training time:142.75036764144897
batch reward last col mean 0.16098275780677795 first col mean 0.1555750072002411 all mean 0.15541838109493256
0.31120091676712036 0.31120091676712036
rl training, epoch0, iter0, batch48/1133, batch loss:0.31120091676712036, Training time:145.27805972099304
batch reward last col mean 0.1584530621767044 first col mean 0.16899460554122925 all mean 0.15949343144893646
0.3651888370513916 0.3651888370513916
rl training, epoch0, iter0, batch49/1133, batch loss:0.3651888370513916, Training time:149.48533082008362
batch reward last col mean 0.2026040405035019 first col mean 0.18131184577941895 all mean 0.19084273278713226
0.3838416635990143 0.3838416635990143
rl training, epoch0, iter0, batch50/1133, batch loss:0.3838416635990143, Training time:152.36597299575806
batch reward last col mean 0.10897178947925568 first col mean 0.17079921066761017 all mean 0.12821908295154572
0.33260685205459595 0.33260685205459595
rl training, epoch0, iter0, batch51/1133, batch loss:0.33260685205459595, Training time:154.87676525115967
batch reward last col mean 0.1600402146577835 first col mean 0.15955530107021332 all mean 0.15727001428604126
0.3343729078769684 0.3343729078769684
rl training, epoch0, iter0, batch52/1133, batch loss:0.3343729078769684, Training time:158.31326961517334
batch reward last col mean 0.15406964719295502 first col mean 0.14860369265079498 all mean 0.15228737890720367
0.3099120855331421 0.3099120855331421
rl training, epoch0, iter0, batch53/1133, batch loss:0.3099120855331421, Training time:161.0616774559021
batch reward last col mean 0.1697174310684204 first col mean 0.1770024299621582 all mean 0.17539824545383453
0.33526965975761414 0.3352696895599365
rl training, epoch0, iter0, batch54/1133, batch loss:0.3352696895599365, Training time:164.57933616638184
batch reward last col mean 0.19049152731895447 first col mean 0.18733280897140503 all mean 0.19681118428707123
0.3745500445365906 0.3745500445365906
rl training, epoch0, iter0, batch55/1133, batch loss:0.3745500445365906, Training time:167.21283602714539
batch reward last col mean 0.13056960701942444 first col mean 0.18502557277679443 all mean 0.13790898025035858
0.3169659972190857 0.3169659972190857
rl training, epoch0, iter0, batch56/1133, batch loss:0.3169659972190857, Training time:170.1685049533844
batch reward last col mean 0.1256428211927414 first col mean 0.1846017986536026 all mean 0.13784025609493256
0.3361842632293701 0.3361842930316925
rl training, epoch0, iter0, batch57/1133, batch loss:0.3361842930316925, Training time:173.4999418258667
batch reward last col mean 0.15767213702201843 first col mean 0.18338660895824432 all mean 0.16543617844581604
0.32771340012550354 0.32771340012550354
rl training, epoch0, iter0, batch58/1133, batch loss:0.32771340012550354, Training time:176.57698249816895
batch reward last col mean 0.15560275316238403 first col mean 0.19985711574554443 all mean 0.15982429683208466
0.33181482553482056 0.33181482553482056
rl training, epoch0, iter0, batch59/1133, batch loss:0.33181482553482056, Training time:181.39341831207275
batch reward last col mean 0.18944966793060303 first col mean 0.19612234830856323 all mean 0.19065368175506592
0.33275172114372253 0.33275172114372253
rl training, epoch0, iter0, batch60/1133, batch loss:0.33275172114372253, Training time:184.2309374809265
batch reward last col mean 0.1811525672674179 first col mean 0.1963304579257965 all mean 0.1814451813697815
0.36069104075431824 0.3606910705566406
rl training, epoch0, iter0, batch61/1133, batch loss:0.3606910705566406, Training time:186.87611508369446
batch reward last col mean 0.18384604156017303 first col mean 0.1586948186159134 all mean 0.18250593543052673
0.3842650055885315 0.3842649757862091
rl training, epoch0, iter0, batch62/1133, batch loss:0.3842649757862091, Training time:189.95123624801636
batch reward last col mean 0.1873348355293274 first col mean 0.19422630965709686 all mean 0.17808055877685547
0.34921741485595703 0.34921741485595703
rl training, epoch0, iter0, batch63/1133, batch loss:0.34921741485595703, Training time:194.50184965133667
batch reward last col mean 0.1500268131494522 first col mean 0.16600942611694336 all mean 0.15464188158512115
0.3501277267932892 0.3501277267932892
rl training, epoch0, iter0, batch64/1133, batch loss:0.3501277267932892, Training time:198.60876512527466
batch reward last col mean 0.18264243006706238 first col mean 0.180031418800354 all mean 0.17767785489559174
0.34974050521850586 0.34974050521850586
rl training, epoch0, iter0, batch65/1133, batch loss:0.34974050521850586, Training time:202.4856240749359
batch reward last col mean 0.19584834575653076 first col mean 0.16775453090667725 all mean 0.189097061753273
0.3551454544067383 0.3551454544067383
rl training, epoch0, iter0, batch66/1133, batch loss:0.3551454544067383, Training time:207.54107761383057
batch reward last col mean 0.16994047164916992 first col mean 0.17858068645000458 all mean 0.17367026209831238
0.36670801043510437 0.366707980632782
rl training, epoch0, iter0, batch67/1133, batch loss:0.366707980632782, Training time:211.59698605537415
batch reward last col mean 0.16094347834587097 first col mean 0.1697845309972763 all mean 0.160610169172287
0.31766360998153687 0.31766360998153687
rl training, epoch0, iter0, batch68/1133, batch loss:0.31766360998153687, Training time:215.86114931106567
batch reward last col mean 0.1757066696882248 first col mean 0.17983439564704895 all mean 0.17497986555099487
0.41844117641448975 0.41844117641448975
rl training, epoch0, iter0, batch69/1133, batch loss:0.41844117641448975, Training time:219.61323261260986
batch reward last col mean 0.172121062874794 first col mean 0.18911457061767578 all mean 0.17843669652938843
0.3397274911403656 0.3397274911403656
rl training, epoch0, iter0, batch70/1133, batch loss:0.3397274911403656, Training time:223.09313821792603
batch reward last col mean 0.1791543960571289 first col mean 0.17958785593509674 all mean 0.17875932157039642
0.3463360667228699 0.3463360667228699
rl training, epoch0, iter0, batch71/1133, batch loss:0.3463360667228699, Training time:225.7377064228058
batch reward last col mean 0.1830124855041504 first col mean 0.1933155357837677 all mean 0.1849985122680664
0.3649987578392029 0.3649987578392029
rl training, epoch0, iter0, batch72/1133, batch loss:0.3649987578392029, Training time:228.8252158164978
batch reward last col mean 0.1743461638689041 first col mean 0.18745484948158264 all mean 0.17224372923374176
0.3519192934036255 0.3519192934036255
rl training, epoch0, iter0, batch73/1133, batch loss:0.3519192934036255, Training time:231.91124176979065
batch reward last col mean 0.1920880377292633 first col mean 0.182364359498024 all mean 0.18936650454998016
0.39549461007118225 0.395494669675827
rl training, epoch0, iter0, batch74/1133, batch loss:0.395494669675827, Training time:235.03237414360046
batch reward last col mean 0.1912016123533249 first col mean 0.1908217966556549 all mean 0.1901882141828537
0.38769835233688354 0.38769835233688354
rl training, epoch0, iter0, batch75/1133, batch loss:0.38769835233688354, Training time:237.94070720672607
batch reward last col mean 0.1854381114244461 first col mean 0.21510200202465057 all mean 0.19675560295581818
0.36730295419692993 0.36730295419692993
rl training, epoch0, iter0, batch76/1133, batch loss:0.36730295419692993, Training time:241.29518222808838
batch reward last col mean 0.19599458575248718 first col mean 0.18295274674892426 all mean 0.19201283156871796
0.3837532699108124 0.3837532699108124
rl training, epoch0, iter0, batch77/1133, batch loss:0.3837532699108124, Training time:245.50117301940918
batch reward last col mean 0.17931559681892395 first col mean 0.18398848176002502 all mean 0.18881677091121674
0.40450844168663025 0.40450844168663025
rl training, epoch0, iter0, batch78/1133, batch loss:0.40450844168663025, Training time:248.15752387046814
batch reward last col mean 0.16707023978233337 first col mean 0.18631978332996368 all mean 0.172112837433815
0.3052966594696045 0.3052966594696045
rl training, epoch0, iter0, batch79/1133, batch loss:0.3052966594696045, Training time:250.9124619960785
batch reward last col mean 0.2198268622159958 first col mean 0.16863495111465454 all mean 0.21395045518875122
0.3889671564102173 0.3889671564102173
rl training, epoch0, iter0, batch80/1133, batch loss:0.3889671564102173, Training time:253.94487524032593
batch reward last col mean 0.17280520498752594 first col mean 0.19667625427246094 all mean 0.175806924700737
0.3529333174228668 0.3529333174228668
rl training, epoch0, iter0, batch81/1133, batch loss:0.3529333174228668, Training time:258.1082797050476
batch reward last col mean 0.22210006415843964 first col mean 0.1848335713148117 all mean 0.21627134084701538
0.38941890001296997 0.38941890001296997
rl training, epoch0, iter0, batch82/1133, batch loss:0.38941890001296997, Training time:261.4375457763672
batch reward last col mean 0.2110816240310669 first col mean 0.17510908842086792 all mean 0.20496034622192383
0.3949635922908783 0.3949635922908783
rl training, epoch0, iter0, batch83/1133, batch loss:0.3949635922908783, Training time:265.6715557575226
batch reward last col mean 0.1915968656539917 first col mean 0.2174195945262909 all mean 0.1925107091665268
0.38942384719848633 0.38942384719848633
rl training, epoch0, iter0, batch84/1133, batch loss:0.38942384719848633, Training time:269.71966314315796
batch reward last col mean 0.16995908319950104 first col mean 0.19789323210716248 all mean 0.18177658319473267
0.3545605540275574 0.3545605540275574
rl training, epoch0, iter0, batch85/1133, batch loss:0.3545605540275574, Training time:272.75184321403503
batch reward last col mean 0.20092123746871948 first col mean 0.17013226449489594 all mean 0.1994166523218155
0.3855138123035431 0.3855138123035431
rl training, epoch0, iter0, batch86/1133, batch loss:0.3855138123035431, Training time:276.1356112957001
batch reward last col mean 0.19658474624156952 first col mean 0.21292316913604736 all mean 0.19270794093608856
0.375635027885437 0.375635027885437
rl training, epoch0, iter0, batch87/1133, batch loss:0.375635027885437, Training time:280.3282563686371
batch reward last col mean 0.1979827880859375 first col mean 0.20986849069595337 all mean 0.19729439914226532
0.41279664635658264 0.41279664635658264
rl training, epoch0, iter0, batch88/1133, batch loss:0.41279664635658264, Training time:285.3841736316681
batch reward last col mean 0.2074366956949234 first col mean 0.2059279978275299 all mean 0.20676466822624207
0.40666159987449646 0.40666159987449646
rl training, epoch0, iter0, batch89/1133, batch loss:0.40666159987449646, Training time:289.1834819316864
batch reward last col mean 0.1801837682723999 first col mean 0.20689766108989716 all mean 0.18219807744026184
0.35277649760246277 0.35277649760246277
rl training, epoch0, iter0, batch90/1133, batch loss:0.35277649760246277, Training time:293.0227749347687
batch reward last col mean 0.197381854057312 first col mean 0.1972685158252716 all mean 0.1950143575668335
0.3935210406780243 0.3935210406780243
rl training, epoch0, iter0, batch91/1133, batch loss:0.3935210406780243, Training time:299.80482506752014
batch reward last col mean 0.21342624723911285 first col mean 0.20879250764846802 all mean 0.21189217269420624
0.3564590811729431 0.3564590811729431
rl training, epoch0, iter0, batch92/1133, batch loss:0.3564590811729431, Training time:303.4209988117218
batch reward last col mean 0.20380434393882751 first col mean 0.21385109424591064 all mean 0.20037271082401276
0.37759581208229065 0.37759581208229065
rl training, epoch0, iter0, batch93/1133, batch loss:0.37759581208229065, Training time:307.2974946498871
batch reward last col mean 0.2159816473722458 first col mean 0.22992420196533203 all mean 0.21004755795001984
0.40980204939842224 0.40980204939842224
rl training, epoch0, iter0, batch94/1133, batch loss:0.40980204939842224, Training time:311.46383905410767
batch reward last col mean 0.21495363116264343 first col mean 0.2042163610458374 all mean 0.21779143810272217
0.4008427560329437 0.4008427858352661
rl training, epoch0, iter0, batch95/1133, batch loss:0.4008427858352661, Training time:316.7798476219177
batch reward last col mean 0.17208120226860046 first col mean 0.24169549345970154 all mean 0.18948620557785034
0.39658084511756897 0.39658084511756897
rl training, epoch0, iter0, batch96/1133, batch loss:0.39658084511756897, Training time:319.78059005737305
batch reward last col mean 0.20584793388843536 first col mean 0.22094564139842987 all mean 0.2170552760362625
0.4227374196052551 0.4227374196052551
rl training, epoch0, iter0, batch97/1133, batch loss:0.4227374196052551, Training time:322.79571652412415
batch reward last col mean 0.2299744188785553 first col mean 0.24428755044937134 all mean 0.23351866006851196
0.4480994641780853 0.4480994641780853
rl training, epoch0, iter0, batch98/1133, batch loss:0.4480994641780853, Training time:327.16887402534485
batch reward last col mean 0.23169749975204468 first col mean 0.24140521883964539 all mean 0.23779864609241486
0.4396074116230011 0.4396074116230011
rl training, epoch0, iter0, batch99/1133, batch loss:0.4396074116230011, Training time:330.4590997695923
batch reward last col mean 0.20741881430149078 first col mean 0.20280081033706665 all mean 0.20501011610031128
0.3831329941749573 0.3831329941749573
rl training, epoch0, iter0, batch100/1133, batch loss:0.3831329941749573, Training time:333.5212416648865
batch reward last col mean 0.20500367879867554 first col mean 0.2023642659187317 all mean 0.20588575303554535
0.3886728882789612 0.3886728882789612
rl training, epoch0, iter0, batch101/1133, batch loss:0.3886728882789612, Training time:336.99240255355835
batch reward last col mean 0.18362879753112793 first col mean 0.208366259932518 all mean 0.18974122405052185
0.4337945580482483 0.4337945580482483
rl training, epoch0, iter0, batch102/1133, batch loss:0.4337945580482483, Training time:341.136173248291
batch reward last col mean 0.19891101121902466 first col mean 0.23089301586151123 all mean 0.19879718124866486
0.36332371830940247 0.36332371830940247
rl training, epoch0, iter0, batch103/1133, batch loss:0.36332371830940247, Training time:345.44985127449036
batch reward last col mean 0.20661640167236328 first col mean 0.21832981705665588 all mean 0.2105688452720642
0.3896732032299042 0.38967323303222656
rl training, epoch0, iter0, batch104/1133, batch loss:0.38967323303222656, Training time:349.0119745731354
batch reward last col mean 0.22650790214538574 first col mean 0.24126674234867096 all mean 0.23372311890125275
0.45290085673332214 0.45290085673332214
rl training, epoch0, iter0, batch105/1133, batch loss:0.45290085673332214, Training time:353.12213468551636
batch reward last col mean 0.24691562354564667 first col mean 0.21620307862758636 all mean 0.2471190094947815
0.4822748601436615 0.4822748601436615
rl training, epoch0, iter0, batch106/1133, batch loss:0.4822748601436615, Training time:360.01794934272766
batch reward last col mean 0.1752733588218689 first col mean 0.20829889178276062 all mean 0.17681773006916046
0.37988176941871643 0.37988176941871643
rl training, epoch0, iter0, batch107/1133, batch loss:0.37988176941871643, Training time:367.7693340778351
batch reward last col mean 0.2100393921136856 first col mean 0.22194235026836395 all mean 0.20738966763019562
0.39033353328704834 0.39033353328704834
rl training, epoch0, iter0, batch108/1133, batch loss:0.39033353328704834, Training time:373.3586001396179
batch reward last col mean 0.19640478491783142 first col mean 0.2309652864933014 all mean 0.20192992687225342
0.36390426754951477 0.36390426754951477
rl training, epoch0, iter0, batch109/1133, batch loss:0.36390426754951477, Training time:379.45866680145264
batch reward last col mean 0.25983530282974243 first col mean 0.22987782955169678 all mean 0.24953575432300568
0.4685073494911194 0.468507319688797
rl training, epoch0, iter0, batch110/1133, batch loss:0.468507319688797, Training time:385.40493607521057
batch reward last col mean 0.2161315232515335 first col mean 0.20257391035556793 all mean 0.21195146441459656
0.43719637393951416 0.43719637393951416
rl training, epoch0, iter0, batch111/1133, batch loss:0.43719637393951416, Training time:393.1483597755432
batch reward last col mean 0.2295544296503067 first col mean 0.22475700080394745 all mean 0.21596714854240417
0.4123275876045227 0.4123276174068451
rl training, epoch0, iter0, batch112/1133, batch loss:0.4123276174068451, Training time:397.8725345134735
batch reward last col mean 0.2807117700576782 first col mean 0.23646607995033264 all mean 0.26965099573135376
0.47697505354881287 0.47697505354881287
rl training, epoch0, iter0, batch113/1133, batch loss:0.47697505354881287, Training time:403.7975814342499
batch reward last col mean 0.23185177147388458 first col mean 0.21294128894805908 all mean 0.22135592997074127
0.44772300124168396 0.4477229714393616
rl training, epoch0, iter0, batch114/1133, batch loss:0.4477229714393616, Training time:409.1802017688751
batch reward last col mean 0.2538650631904602 first col mean 0.22512200474739075 all mean 0.255913645029068
0.501848578453064 0.501848578453064
rl training, epoch0, iter0, batch115/1133, batch loss:0.501848578453064, Training time:413.8378267288208
batch reward last col mean 0.2272176295518875 first col mean 0.23257525265216827 all mean 0.22808365523815155
0.5372646450996399 0.5372646450996399
rl training, epoch0, iter0, batch116/1133, batch loss:0.5372646450996399, Training time:420.8555145263672
batch reward last col mean 0.1796906292438507 first col mean 0.23910126090049744 all mean 0.19457069039344788
0.41707733273506165 0.41707733273506165
rl training, epoch0, iter0, batch117/1133, batch loss:0.41707733273506165, Training time:426.74724078178406
batch reward last col mean 0.2092793881893158 first col mean 0.21376679837703705 all mean 0.21799805760383606
0.5000049471855164 0.5000049471855164
rl training, epoch0, iter0, batch118/1133, batch loss:0.5000049471855164, Training time:434.1313600540161
batch reward last col mean 0.21421438455581665 first col mean 0.21733225882053375 all mean 0.22443054616451263
0.4782218337059021 0.4782218337059021
rl training, epoch0, iter0, batch119/1133, batch loss:0.4782218337059021, Training time:440.93799781799316
batch reward last col mean 0.251950740814209 first col mean 0.2613047957420349 all mean 0.2428351789712906
0.48712289333343506 0.48712289333343506
rl training, epoch0, iter0, batch120/1133, batch loss:0.48712289333343506, Training time:448.4361979961395
batch reward last col mean 0.21437372267246246 first col mean 0.23028156161308289 all mean 0.22285138070583344
0.47983893752098083 0.4798389971256256
rl training, epoch0, iter0, batch121/1133, batch loss:0.4798389971256256, Training time:457.35944390296936
batch reward last col mean 0.20199733972549438 first col mean 0.22937433421611786 all mean 0.21342244744300842
0.47383320331573486 0.47383320331573486
rl training, epoch0, iter0, batch122/1133, batch loss:0.47383320331573486, Training time:464.75102162361145
batch reward last col mean 0.1945619136095047 first col mean 0.22978422045707703 all mean 0.19913004338741302
0.4178229868412018 0.4178229570388794
rl training, epoch0, iter0, batch123/1133, batch loss:0.4178229570388794, Training time:472.07969760894775
batch reward last col mean 0.22024455666542053 first col mean 0.24741876125335693 all mean 0.2277211993932724
0.45677369832992554 0.45677369832992554
rl training, epoch0, iter0, batch124/1133, batch loss:0.45677369832992554, Training time:481.0107886791229
batch reward last col mean 0.25530335307121277 first col mean 0.2329961657524109 all mean 0.24942389130592346
0.500417172908783 0.500417172908783
rl training, epoch0, iter0, batch125/1133, batch loss:0.500417172908783, Training time:492.289183139801
batch reward last col mean 0.25796422362327576 first col mean 0.26009440422058105 all mean 0.25497663021087646
0.4619245231151581 0.4619245231151581
rl training, epoch0, iter0, batch126/1133, batch loss:0.4619245231151581, Training time:508.5645492076874
batch reward last col mean 0.23413346707820892 first col mean 0.22772417962551117 all mean 0.23004485666751862
0.4133249819278717 0.4133249819278717
rl training, epoch0, iter0, batch127/1133, batch loss:0.4133249819278717, Training time:519.2002081871033
batch reward last col mean 0.23604826629161835 first col mean 0.2628307342529297 all mean 0.243228480219841
0.6052672266960144 0.6052672863006592
rl training, epoch0, iter0, batch128/1133, batch loss:0.6052672863006592, Training time:536.5319318771362
batch reward last col mean 0.2950007915496826 first col mean 0.2577509582042694 all mean 0.28631576895713806
0.5617198348045349 0.5617198348045349
rl training, epoch0, iter0, batch129/1133, batch loss:0.5617198348045349, Training time:560.9219710826874
batch reward last col mean 0.29102084040641785 first col mean 0.23909157514572144 all mean 0.2778213918209076
0.5245831608772278 0.5245831608772278
rl training, epoch0, iter0, batch130/1133, batch loss:0.5245831608772278, Training time:576.1752457618713
batch reward last col mean 0.22514566779136658 first col mean 0.22609221935272217 all mean 0.2273014932870865
0.482614666223526 0.4826147258281708
rl training, epoch0, iter0, batch131/1133, batch loss:0.4826147258281708, Training time:588.2599291801453
batch reward last col mean 0.2501934766769409 first col mean 0.2689792513847351 all mean 0.25502580404281616
0.5642918944358826 0.5642918944358826
rl training, epoch0, iter0, batch132/1133, batch loss:0.5642918944358826, Training time:614.8585638999939
batch reward last col mean 0.27833813428878784 first col mean 0.26513251662254333 all mean 0.2716892957687378
0.597693681716919 0.597693681716919
rl training, epoch0, iter0, batch133/1133, batch loss:0.597693681716919, Training time:640.9465355873108
batch reward last col mean 0.27686381340026855 first col mean 0.27256932854652405 all mean 0.2813403010368347
0.5355838537216187 0.5355838537216187
rl training, epoch0, iter0, batch134/1133, batch loss:0.5355838537216187, Training time:661.7384943962097
batch reward last col mean 0.2492179572582245 first col mean 0.22087706625461578 all mean 0.24799561500549316
0.5474578738212585 0.5474578738212585
rl training, epoch0, iter0, batch135/1133, batch loss:0.5474578738212585, Training time:686.8864660263062
batch reward last col mean 0.22158364951610565 first col mean 0.22463880479335785 all mean 0.22713004052639008
0.5396337509155273 0.5396337509155273
rl training, epoch0, iter0, batch136/1133, batch loss:0.5396337509155273, Training time:713.4644553661346
batch reward last col mean 0.27069538831710815 first col mean 0.25685036182403564 all mean 0.2724882662296295
0.609163761138916 0.609163761138916
rl training, epoch0, iter0, batch137/1133, batch loss:0.609163761138916, Training time:740.32350897789
batch reward last col mean 0.2833666205406189 first col mean 0.2597663402557373 all mean 0.2741425335407257
0.5603657960891724 0.5603657364845276
rl training, epoch0, iter0, batch138/1133, batch loss:0.5603657364845276, Training time:767.4106440544128
batch reward last col mean 0.24941614270210266 first col mean 0.24313795566558838 all mean 0.24917002022266388
0.6110854744911194 0.6110854744911194
rl training, epoch0, iter0, batch139/1133, batch loss:0.6110854744911194, Training time:793.9813401699066
batch reward last col mean 0.258044570684433 first col mean 0.2671535909175873 all mean 0.2586296796798706
0.5405439734458923 0.5405439734458923
rl training, epoch0, iter0, batch140/1133, batch loss:0.5405439734458923, Training time:820.8657214641571
batch reward last col mean 0.27953213453292847 first col mean 0.24123215675354004 all mean 0.2719458341598511
0.5752548575401306 0.5752548575401306
rl training, epoch0, iter0, batch141/1133, batch loss:0.5752548575401306, Training time:847.8753476142883
batch reward last col mean 0.19623993337154388 first col mean 0.23508203029632568 all mean 0.20986610651016235
0.486510694026947 0.486510694026947
rl training, epoch0, iter0, batch142/1133, batch loss:0.486510694026947, Training time:874.7990870475769
batch reward last col mean 0.2599368393421173 first col mean 0.2815842032432556 all mean 0.26370447874069214
0.5490996241569519 0.5490996241569519
rl training, epoch0, iter0, batch143/1133, batch loss:0.5490996241569519, Training time:902.0561683177948
batch reward last col mean 0.3083574175834656 first col mean 0.24191969633102417 all mean 0.29109740257263184
0.5454122424125671 0.5454122424125671
rl training, epoch0, iter0, batch144/1133, batch loss:0.5454122424125671, Training time:929.6126890182495
batch reward last col mean 0.2888438105583191 first col mean 0.2667067348957062 all mean 0.2921079695224762
0.5818187594413757 0.5818187594413757
rl training, epoch0, iter0, batch145/1133, batch loss:0.5818187594413757, Training time:956.9547991752625
batch reward last col mean 0.23277680575847626 first col mean 0.23196761310100555 all mean 0.23431891202926636
0.5378426909446716 0.5378426909446716
rl training, epoch0, iter0, batch146/1133, batch loss:0.5378426909446716, Training time:984.524405002594
batch reward last col mean 0.2570108473300934 first col mean 0.29045671224594116 all mean 0.2567470371723175
0.540474534034729 0.5404745936393738
rl training, epoch0, iter0, batch147/1133, batch loss:0.5404745936393738, Training time:1011.9162900447845
batch reward last col mean 0.27486807107925415 first col mean 0.2758539319038391 all mean 0.2739095687866211
0.6405048966407776 0.6405048966407776
rl training, epoch0, iter0, batch148/1133, batch loss:0.6405048966407776, Training time:1039.1672010421753
batch reward last col mean 0.253905713558197 first col mean 0.2857683598995209 all mean 0.260823518037796
0.6013309359550476 0.6013309359550476
rl training, epoch0, iter0, batch149/1133, batch loss:0.6013309359550476, Training time:1066.63183927536
batch reward last col mean 0.2071978896856308 first col mean 0.2714653015136719 all mean 0.22974006831645966
0.5541914105415344 0.5541914105415344
rl training, epoch0, iter0, batch150/1133, batch loss:0.5541914105415344, Training time:1094.4039115905762
batch reward last col mean 0.26493242383003235 first col mean 0.3059566617012024 all mean 0.27240443229675293
0.5316035747528076 0.5316035151481628
rl training, epoch0, iter0, batch151/1133, batch loss:0.5316035151481628, Training time:1122.9781093597412
batch reward last col mean 0.23989927768707275 first col mean 0.25119343400001526 all mean 0.25637951493263245
0.661908745765686 0.661908745765686
rl training, epoch0, iter0, batch152/1133, batch loss:0.661908745765686, Training time:1150.795982837677
batch reward last col mean 0.2597055435180664 first col mean 0.28266823291778564 all mean 0.2587299942970276
0.5744388103485107 0.5744388103485107
rl training, epoch0, iter0, batch153/1133, batch loss:0.5744388103485107, Training time:1178.2983877658844
batch reward last col mean 0.26290521025657654 first col mean 0.2718038260936737 all mean 0.2785013020038605
0.6390629410743713 0.6390629410743713
rl training, epoch0, iter0, batch154/1133, batch loss:0.6390629410743713, Training time:1206.4180500507355
batch reward last col mean 0.2239532172679901 first col mean 0.25615304708480835 all mean 0.23142188787460327
0.5662030577659607 0.5662030577659607
rl training, epoch0, iter0, batch155/1133, batch loss:0.5662030577659607, Training time:1234.8881084918976
batch reward last col mean 0.24238501489162445 first col mean 0.22641365230083466 all mean 0.2508969306945801
0.5758507251739502 0.5758507251739502
rl training, epoch0, iter0, batch156/1133, batch loss:0.5758507251739502, Training time:1263.4246671199799
batch reward last col mean 0.349675714969635 first col mean 0.28922444581985474 all mean 0.29075881838798523
0.6439970135688782 0.6439970135688782
rl training, epoch0, iter0, batch157/1133, batch loss:0.6439970135688782, Training time:1291.3162384033203
batch reward last col mean 0.25379422307014465 first col mean 0.3130077123641968 all mean 0.2595125734806061
0.6910719275474548 0.6910718679428101
rl training, epoch0, iter0, batch158/1133, batch loss:0.6910718679428101, Training time:1320.300255060196
batch reward last col mean 0.2262791246175766 first col mean 0.2504618167877197 all mean 0.23366007208824158
0.6097963452339172 0.6097963452339172
rl training, epoch0, iter0, batch159/1133, batch loss:0.6097963452339172, Training time:1348.5836436748505
batch reward last col mean 0.2374206781387329 first col mean 0.274196982383728 all mean 0.25444942712783813
0.6451972723007202 0.6451972723007202
rl training, epoch0, iter0, batch160/1133, batch loss:0.6451972723007202, Training time:1376.527134180069
batch reward last col mean 0.23533430695533752 first col mean 0.2765495479106903 all mean 0.2615041732788086
0.692204475402832 0.692204475402832
rl training, epoch0, iter0, batch161/1133, batch loss:0.692204475402832, Training time:1405.2089667320251
batch reward last col mean 0.26036491990089417 first col mean 0.3017878532409668 all mean 0.27431821823120117
0.677079975605011 0.6770799160003662
rl training, epoch0, iter0, batch162/1133, batch loss:0.6770799160003662, Training time:1433.390308856964
batch reward last col mean 0.20547333359718323 first col mean 0.2933359444141388 all mean 0.25373944640159607
0.7303999066352844 0.7303998470306396
rl training, epoch0, iter0, batch163/1133, batch loss:0.7303998470306396, Training time:1461.9755108356476
batch reward last col mean 0.2511518597602844 first col mean 0.30167484283447266 all mean 0.27648332715034485
0.7234188318252563 0.7234188318252563
rl training, epoch0, iter0, batch164/1133, batch loss:0.7234188318252563, Training time:1490.162917137146
batch reward last col mean 0.29250672459602356 first col mean 0.3348037600517273 all mean 0.3129802346229553
0.824299156665802 0.824299156665802
rl training, epoch0, iter0, batch165/1133, batch loss:0.824299156665802, Training time:1518.428605556488
batch reward last col mean 0.28304293751716614 first col mean 0.3090224266052246 all mean 0.2920170724391937
0.7909033894538879 0.7909033298492432
rl training, epoch0, iter0, batch166/1133, batch loss:0.7909033298492432, Training time:1547.0577454566956
batch reward last col mean 0.2595806121826172 first col mean 0.3120150566101074 all mean 0.2845720648765564
0.8434250354766846 0.8434250354766846
rl training, epoch0, iter0, batch167/1133, batch loss:0.8434250354766846, Training time:1575.2794501781464
batch reward last col mean 0.34290868043899536 first col mean 0.3605007529258728 all mean 0.3327530324459076
0.82028728723526 0.82028728723526
rl training, epoch0, iter0, batch168/1133, batch loss:0.82028728723526, Training time:1603.4567954540253
batch reward last col mean 0.3023076355457306 first col mean 0.34564530849456787 all mean 0.30841752886772156
0.813098132610321 0.813098132610321
rl training, epoch0, iter0, batch169/1133, batch loss:0.813098132610321, Training time:1631.783192873001
batch reward last col mean 0.3721647262573242 first col mean 0.28593650460243225 all mean 0.32903027534484863
0.8094790577888489 0.8094790577888489
rl training, epoch0, iter0, batch170/1133, batch loss:0.8094790577888489, Training time:1660.5987873077393
batch reward last col mean 0.34883639216423035 first col mean 0.39566779136657715 all mean 0.35709866881370544
0.9705764651298523 0.9705764651298523
rl training, epoch0, iter0, batch171/1133, batch loss:0.9705764651298523, Training time:1688.5895855426788
batch reward last col mean 0.3782241940498352 first col mean 0.3856791853904724 all mean 0.3673023283481598
0.8905713558197021 0.8905713558197021
rl training, epoch0, iter0, batch172/1133, batch loss:0.8905713558197021, Training time:1717.1656885147095
batch reward last col mean 0.34903669357299805 first col mean 0.3909815847873688 all mean 0.41487565636634827
0.9847787618637085 0.9847787618637085
rl training, epoch0, iter0, batch173/1133, batch loss:0.9847787618637085, Training time:1745.544907093048
batch reward last col mean 0.3836413621902466 first col mean 0.3875041902065277 all mean 0.38365477323532104
0.9118002653121948 0.9118002653121948
rl training, epoch0, iter0, batch174/1133, batch loss:0.9118002653121948, Training time:1773.6895198822021
batch reward last col mean 0.37095513939857483 first col mean 0.3991979658603668 all mean 0.4106457531452179
0.9778702855110168 0.9778702855110168
rl training, epoch0, iter0, batch175/1133, batch loss:0.9778702855110168, Training time:1801.7717189788818
batch reward last col mean 0.35763680934906006 first col mean 0.4304417073726654 all mean 0.37488895654678345
1.0122472047805786 1.012247085571289
rl training, epoch0, iter0, batch176/1133, batch loss:1.012247085571289, Training time:1830.0089774131775
batch reward last col mean 0.3934820294380188 first col mean 0.40634021162986755 all mean 0.40447500348091125
1.0355710983276367 1.0355710983276367
rl training, epoch0, iter0, batch177/1133, batch loss:1.0355710983276367, Training time:1858.620525598526
batch reward last col mean 0.38355690240859985 first col mean 0.3829442858695984 all mean 0.37838196754455566
1.0417712926864624 1.0417712926864624
rl training, epoch0, iter0, batch178/1133, batch loss:1.0417712926864624, Training time:1886.6892647743225
batch reward last col mean 0.4024617075920105 first col mean 0.43924224376678467 all mean 0.42839986085891724
1.093137264251709 1.093137264251709
rl training, epoch0, iter0, batch179/1133, batch loss:1.093137264251709, Training time:1914.9100422859192
batch reward last col mean 0.39389368891716003 first col mean 0.45473670959472656 all mean 0.4504367411136627
1.1089881658554077 1.1089881658554077
rl training, epoch0, iter0, batch180/1133, batch loss:1.1089881658554077, Training time:1943.2830722332
batch reward last col mean 0.4848921298980713 first col mean 0.485245019197464 all mean 0.4677138924598694
1.2177205085754395 1.2177205085754395
rl training, epoch0, iter0, batch181/1133, batch loss:1.2177205085754395, Training time:1971.9583775997162
batch reward last col mean 0.4784192144870758 first col mean 0.4661030173301697 all mean 0.46790844202041626
1.1375601291656494 1.137560248374939
rl training, epoch0, iter0, batch182/1133, batch loss:1.137560248374939, Training time:2000.427190065384
batch reward last col mean 0.43229538202285767 first col mean 0.4887896776199341 all mean 0.4682808220386505
1.1423364877700806 1.1423364877700806
rl training, epoch0, iter0, batch183/1133, batch loss:1.1423364877700806, Training time:2028.299860239029
batch reward last col mean 0.5205146074295044 first col mean 0.5209092497825623 all mean 0.5188791751861572
1.2228755950927734 1.2228755950927734
rl training, epoch0, iter0, batch184/1133, batch loss:1.2228755950927734, Training time:2056.928411960602
batch reward last col mean 0.5145495533943176 first col mean 0.5280957818031311 all mean 0.5399840474128723
1.2444977760314941 1.2444977760314941
rl training, epoch0, iter0, batch185/1133, batch loss:1.2444977760314941, Training time:2085.47443819046
batch reward last col mean 0.47780653834342957 first col mean 0.554763913154602 all mean 0.5439331531524658
1.2470436096191406 1.2470436096191406
rl training, epoch0, iter0, batch186/1133, batch loss:1.2470436096191406, Training time:2113.60985660553
batch reward last col mean 0.5546454191207886 first col mean 0.590182363986969 all mean 0.5957372188568115
1.2718385457992554 1.2718385457992554
rl training, epoch0, iter0, batch187/1133, batch loss:1.2718385457992554, Training time:2141.946610927582
batch reward last col mean 0.5840052366256714 first col mean 0.5614911317825317 all mean 0.5780138969421387
1.24277663230896 1.24277663230896
rl training, epoch0, iter0, batch188/1133, batch loss:1.24277663230896, Training time:2170.0760600566864
batch reward last col mean 0.5762410759925842 first col mean 0.5999649167060852 all mean 0.6252579092979431
1.243338704109192 1.243338704109192
rl training, epoch0, iter0, batch189/1133, batch loss:1.243338704109192, Training time:2198.4009776115417
batch reward last col mean 0.651282548904419 first col mean 0.6020376682281494 all mean 0.6332451105117798
1.2560676336288452 1.2560676336288452
rl training, epoch0, iter0, batch190/1133, batch loss:1.2560676336288452, Training time:2227.1325573921204
batch reward last col mean 0.6225537657737732 first col mean 0.6173785328865051 all mean 0.631755530834198
1.203235387802124 1.203235387802124
rl training, epoch0, iter0, batch191/1133, batch loss:1.203235387802124, Training time:2255.4908220767975
batch reward last col mean 0.5945501327514648 first col mean 0.5970942378044128 all mean 0.59722900390625
1.114845871925354 1.114845871925354
rl training, epoch0, iter0, batch192/1133, batch loss:1.114845871925354, Training time:2283.4509885311127
batch reward last col mean 0.6422154903411865 first col mean 0.6563997268676758 all mean 0.6476950645446777
1.2209100723266602 1.2209100723266602
rl training, epoch0, iter0, batch193/1133, batch loss:1.2209100723266602, Training time:2312.1281707286835
batch reward last col mean 0.6173607707023621 first col mean 0.6788423657417297 all mean 0.6645829081535339
1.1059385538101196 1.1059385538101196
rl training, epoch0, iter0, batch194/1133, batch loss:1.1059385538101196, Training time:2340.1477427482605
batch reward last col mean 0.7224570512771606 first col mean 0.7254945039749146 all mean 0.7187737226486206
1.153429627418518 1.1534295082092285
rl training, epoch0, iter0, batch195/1133, batch loss:1.1534295082092285, Training time:2368.4930641651154
batch reward last col mean 0.7292962074279785 first col mean 0.7036581635475159 all mean 0.7048004865646362
1.0857336521148682 1.0857336521148682
rl training, epoch0, iter0, batch196/1133, batch loss:1.0857336521148682, Training time:2396.414088010788
batch reward last col mean 0.7029805183410645 first col mean 0.7361156940460205 all mean 0.7364572882652283
1.0304327011108398 1.0304327011108398
rl training, epoch0, iter0, batch197/1133, batch loss:1.0304327011108398, Training time:2424.5200877189636
batch reward last col mean 0.7257842421531677 first col mean 0.7324974536895752 all mean 0.7379382848739624
1.007965087890625 1.007965087890625
rl training, epoch0, iter0, batch198/1133, batch loss:1.007965087890625, Training time:2452.7870221138
batch reward last col mean 0.735742449760437 first col mean 0.7803207039833069 all mean 0.7570406198501587
0.9969626069068909 0.9969626069068909
rl training, epoch0, iter0, batch199/1133, batch loss:0.9969626069068909, Training time:2480.609201192856
batch reward last col mean 0.8019399642944336 first col mean 0.8136045336723328 all mean 0.8044284582138062
0.9829640984535217 0.982964038848877
rl training, epoch0, iter0, batch200/1133, batch loss:0.982964038848877, Training time:2509.115463733673
batch reward last col mean 0.8197748064994812 first col mean 0.7755486369132996 all mean 0.8077831864356995
0.9529116153717041 0.9529116153717041
rl training, epoch0, iter0, batch201/1133, batch loss:0.9529116153717041, Training time:2537.708079814911
batch reward last col mean 0.8138930797576904 first col mean 0.8271265029907227 all mean 0.8226020932197571
0.950360894203186 0.950360894203186
rl training, epoch0, iter0, batch202/1133, batch loss:0.950360894203186, Training time:2565.527754545212
batch reward last col mean 0.854428768157959 first col mean 0.8184290528297424 all mean 0.8256880640983582
0.8453426361083984 0.8453425765037537
rl training, epoch0, iter0, batch203/1133, batch loss:0.8453425765037537, Training time:2593.5764598846436
batch reward last col mean 0.8282362818717957 first col mean 0.8197416067123413 all mean 0.839134156703949
0.7721030116081238 0.7721030116081238
rl training, epoch0, iter0, batch204/1133, batch loss:0.7721030116081238, Training time:2621.600197792053
batch reward last col mean 0.8191592693328857 first col mean 0.8515810966491699 all mean 0.8239174485206604
0.703073263168335 0.703073263168335
rl training, epoch0, iter0, batch205/1133, batch loss:0.703073263168335, Training time:2649.6945486068726
batch reward last col mean 0.8882266879081726 first col mean 0.8644728660583496 all mean 0.8684350252151489
0.7029864192008972 0.7029864192008972
rl training, epoch0, iter0, batch206/1133, batch loss:0.7029864192008972, Training time:2677.0596623420715
batch reward last col mean 0.8953638076782227 first col mean 0.8871942162513733 all mean 0.8953957557678223
0.6903545260429382 0.6903545260429382
rl training, epoch0, iter0, batch207/1133, batch loss:0.6903545260429382, Training time:2704.952115058899
batch reward last col mean 0.859107255935669 first col mean 0.8889731168746948 all mean 0.8866774439811707
0.6939762234687805 0.6939762234687805
rl training, epoch0, iter0, batch208/1133, batch loss:0.6939762234687805, Training time:2732.832130908966
batch reward last col mean 0.891528844833374 first col mean 0.8697528839111328 all mean 0.8703582286834717
0.669489860534668 0.669489860534668
rl training, epoch0, iter0, batch209/1133, batch loss:0.669489860534668, Training time:2760.7066004276276
batch reward last col mean 0.8560237288475037 first col mean 0.8744153380393982 all mean 0.8590948581695557
0.6664437651634216 0.6664437651634216
rl training, epoch0, iter0, batch210/1133, batch loss:0.6664437651634216, Training time:2788.3457691669464
batch reward last col mean 0.8715858459472656 first col mean 0.8669160604476929 all mean 0.8852241039276123
0.7155604958534241 0.7155604958534241
rl training, epoch0, iter0, batch211/1133, batch loss:0.7155604958534241, Training time:2815.961302280426
batch reward last col mean 0.8568836450576782 first col mean 0.8546150922775269 all mean 0.8369808197021484
0.6436306238174438 0.6436305642127991
rl training, epoch0, iter0, batch212/1133, batch loss:0.6436305642127991, Training time:2843.9713451862335
batch reward last col mean 0.8524563908576965 first col mean 0.8246371746063232 all mean 0.8213856816291809
0.5597490668296814 0.5597490668296814
rl training, epoch0, iter0, batch213/1133, batch loss:0.5597490668296814, Training time:2871.284102678299
batch reward last col mean 0.8272548317909241 first col mean 0.8475462794303894 all mean 0.8005685806274414
0.5189325213432312 0.5189325213432312
rl training, epoch0, iter0, batch214/1133, batch loss:0.5189325213432312, Training time:2899.2365353107452
batch reward last col mean 0.781323254108429 first col mean 0.7841680645942688 all mean 0.7740733027458191
0.40292030572891235 0.40292030572891235
rl training, epoch0, iter0, batch215/1133, batch loss:0.40292030572891235, Training time:2926.709148168564
batch reward last col mean 0.8499894142150879 first col mean 0.8593891859054565 all mean 0.8516629934310913
0.3820064961910248 0.38200655579566956
rl training, epoch0, iter0, batch216/1133, batch loss:0.38200655579566956, Training time:2954.5001091957092
batch reward last col mean 0.8223721981048584 first col mean 0.8381319046020508 all mean 0.8112214803695679
0.3286343514919281 0.3286343514919281
rl training, epoch0, iter0, batch217/1133, batch loss:0.3286343514919281, Training time:2982.0956468582153
batch reward last col mean 0.8366430997848511 first col mean 0.840813934803009 all mean 0.8497699499130249
0.2914857268333435 0.2914857268333435
rl training, epoch0, iter0, batch218/1133, batch loss:0.2914857268333435, Training time:3009.9834756851196
batch reward last col mean 0.8039253950119019 first col mean 0.8053857088088989 all mean 0.8082947134971619
0.2514377236366272 0.2514377236366272
rl training, epoch0, iter0, batch219/1133, batch loss:0.2514377236366272, Training time:3037.822684764862
batch reward last col mean 0.831505298614502 first col mean 0.8288812041282654 all mean 0.8353865146636963
0.25018781423568726 0.25018781423568726
rl training, epoch0, iter0, batch220/1133, batch loss:0.25018781423568726, Training time:3065.4883563518524
batch reward last col mean 0.8366515636444092 first col mean 0.8448077440261841 all mean 0.8562091588973999
0.2266741245985031 0.2266741245985031
rl training, epoch0, iter0, batch221/1133, batch loss:0.2266741245985031, Training time:3093.719652414322
batch reward last col mean 0.8259362578392029 first col mean 0.8271079063415527 all mean 0.8432144522666931
0.20685163140296936 0.20685163140296936
rl training, epoch0, iter0, batch222/1133, batch loss:0.20685163140296936, Training time:3121.6003773212433
batch reward last col mean 0.8701581954956055 first col mean 0.8714315891265869 all mean 0.8763430714607239
0.22133681178092957 0.22133681178092957
rl training, epoch0, iter0, batch223/1133, batch loss:0.22133681178092957, Training time:3149.3765506744385
batch reward last col mean 0.8745073080062866 first col mean 0.8542467355728149 all mean 0.8685575723648071
0.19701716303825378 0.1970171332359314
rl training, epoch0, iter0, batch224/1133, batch loss:0.1970171332359314, Training time:3177.4992821216583
batch reward last col mean 0.8120783567428589 first col mean 0.8240019083023071 all mean 0.8278440237045288
0.17881575226783752 0.17881575226783752
rl training, epoch0, iter0, batch225/1133, batch loss:0.17881575226783752, Training time:3205.3949241638184
batch reward last col mean 0.8100697994232178 first col mean 0.8457562327384949 all mean 0.8198421597480774
0.17262645065784454 0.17262645065784454
rl training, epoch0, iter0, batch226/1133, batch loss:0.17262645065784454, Training time:3232.8054163455963
batch reward last col mean 0.8378851413726807 first col mean 0.831337571144104 all mean 0.856255054473877
0.2024691253900528 0.2024691253900528
rl training, epoch0, iter0, batch227/1133, batch loss:0.2024691253900528, Training time:3260.2142605781555
batch reward last col mean 0.7926436066627502 first col mean 0.824630856513977 all mean 0.7991549372673035
0.18820475041866302 0.18820475041866302
rl training, epoch0, iter0, batch228/1133, batch loss:0.18820475041866302, Training time:3287.5795147418976
batch reward last col mean 0.8514893651008606 first col mean 0.8616864681243896 all mean 0.8472758531570435
0.1833009421825409 0.1833009421825409
rl training, epoch0, iter0, batch229/1133, batch loss:0.1833009421825409, Training time:3314.967354774475
batch reward last col mean 0.8017411231994629 first col mean 0.8304595947265625 all mean 0.8157706260681152
0.18191878497600555 0.18191878497600555
rl training, epoch0, iter0, batch230/1133, batch loss:0.18191878497600555, Training time:3342.456695795059
batch reward last col mean 0.8478729724884033 first col mean 0.8213672637939453 all mean 0.8376341462135315
0.1752016544342041 0.1752016395330429
rl training, epoch0, iter0, batch231/1133, batch loss:0.1752016395330429, Training time:3370.047310113907
batch reward last col mean 0.8008188009262085 first col mean 0.8277101516723633 all mean 0.8192338943481445
0.18961934745311737 0.18961934745311737
rl training, epoch0, iter0, batch232/1133, batch loss:0.18961934745311737, Training time:3397.6796934604645
batch reward last col mean 0.8271083831787109 first col mean 0.8124045729637146 all mean 0.8311166763305664
0.20862118899822235 0.20862118899822235
rl training, epoch0, iter0, batch233/1133, batch loss:0.20862118899822235, Training time:3425.43119096756
batch reward last col mean 0.869157612323761 first col mean 0.8927092552185059 all mean 0.8785921335220337
0.22924067080020905 0.22924067080020905
rl training, epoch0, iter0, batch234/1133, batch loss:0.22924067080020905, Training time:3452.8184657096863
batch reward last col mean 0.862085223197937 first col mean 0.830512285232544 all mean 0.8454179167747498
0.21533150970935822 0.21533150970935822
rl training, epoch0, iter0, batch235/1133, batch loss:0.21533150970935822, Training time:3480.5815420150757
batch reward last col mean 0.8712359666824341 first col mean 0.8631305694580078 all mean 0.854705810546875
0.252701997756958 0.252701997756958
rl training, epoch0, iter0, batch236/1133, batch loss:0.252701997756958, Training time:3508.1050152778625
batch reward last col mean 0.7851188778877258 first col mean 0.8240296840667725 all mean 0.8028687238693237
0.24760662019252777 0.24760663509368896
rl training, epoch0, iter0, batch237/1133, batch loss:0.24760663509368896, Training time:3535.5004708766937
batch reward last col mean 0.8504666090011597 first col mean 0.8435802459716797 all mean 0.8264039754867554
0.23867923021316528 0.23867923021316528
rl training, epoch0, iter0, batch238/1133, batch loss:0.23867923021316528, Training time:3562.8858087062836
batch reward last col mean 0.827303409576416 first col mean 0.8309047818183899 all mean 0.8207969069480896
0.25003087520599365 0.25003084540367126
rl training, epoch0, iter0, batch239/1133, batch loss:0.25003084540367126, Training time:3590.59468626976
batch reward last col mean 0.8519609570503235 first col mean 0.8288201093673706 all mean 0.8337416052818298
0.26877108216285706 0.26877108216285706
rl training, epoch0, iter0, batch240/1133, batch loss:0.26877108216285706, Training time:3617.7740018367767
batch reward last col mean 0.8538561463356018 first col mean 0.8743953704833984 all mean 0.8621343970298767
0.2738366425037384 0.2738366425037384
rl training, epoch0, iter0, batch241/1133, batch loss:0.2738366425037384, Training time:3645.326422929764
batch reward last col mean 0.8447800874710083 first col mean 0.8547022342681885 all mean 0.8439594507217407
0.27488216757774353 0.27488216757774353
rl training, epoch0, iter0, batch242/1133, batch loss:0.27488216757774353, Training time:3673.0872020721436
batch reward last col mean 0.8598451018333435 first col mean 0.8490602374076843 all mean 0.8457297682762146
0.2766568958759308 0.2766568958759308
rl training, epoch0, iter0, batch243/1133, batch loss:0.2766568958759308, Training time:3700.4273765087128
batch reward last col mean 0.8690986037254333 first col mean 0.8663023114204407 all mean 0.8646855354309082
0.2655927538871765 0.2655927538871765
rl training, epoch0, iter0, batch244/1133, batch loss:0.2655927538871765, Training time:3727.984847545624
batch reward last col mean 0.896216094493866 first col mean 0.8967401385307312 all mean 0.8933814167976379
0.265460729598999 0.265460729598999
rl training, epoch0, iter0, batch245/1133, batch loss:0.265460729598999, Training time:3755.591330766678
batch reward last col mean 0.8462151885032654 first col mean 0.875659704208374 all mean 0.871878981590271
0.24268105626106262 0.24268105626106262
rl training, epoch0, iter0, batch246/1133, batch loss:0.24268105626106262, Training time:3783.0085110664368
batch reward last col mean 0.8952586650848389 first col mean 0.8574309945106506 all mean 0.8871957659721375
0.23904365301132202 0.23904363811016083
rl training, epoch0, iter0, batch247/1133, batch loss:0.23904363811016083, Training time:3810.779511451721
batch reward last col mean 0.8918632864952087 first col mean 0.8737947344779968 all mean 0.8835098743438721
0.22553913295269012 0.22553913295269012
rl training, epoch0, iter0, batch248/1133, batch loss:0.22553913295269012, Training time:3839.104465484619
batch reward last col mean 0.8580806851387024 first col mean 0.8354518413543701 all mean 0.8456363677978516
0.21538451313972473 0.21538451313972473
rl training, epoch0, iter0, batch249/1133, batch loss:0.21538451313972473, Training time:3867.831372022629
batch reward last col mean 0.8507744073867798 first col mean 0.8573574423789978 all mean 0.8554884195327759
0.22655411064624786 0.22655411064624786
rl training, epoch0, iter0, batch250/1133, batch loss:0.22655411064624786, Training time:3896.0367312431335
batch reward last col mean 0.827218770980835 first col mean 0.8497359752655029 all mean 0.8352177143096924
0.21734154224395752 0.21734154224395752
rl training, epoch0, iter0, batch251/1133, batch loss:0.21734154224395752, Training time:3924.2889354228973
batch reward last col mean 0.8562309741973877 first col mean 0.8574594259262085 all mean 0.8530415296554565
0.21773025393486023 0.21773023903369904
rl training, epoch0, iter0, batch252/1133, batch loss:0.21773023903369904, Training time:3952.4214313030243
batch reward last col mean 0.8629551529884338 first col mean 0.8543524742126465 all mean 0.8574528694152832
0.2172183096408844 0.2172182947397232
rl training, epoch0, iter0, batch253/1133, batch loss:0.2172182947397232, Training time:3980.3802223205566
batch reward last col mean 0.8554857969284058 first col mean 0.850346565246582 all mean 0.8443488478660583
0.19269125163555145 0.19269123673439026
rl training, epoch0, iter0, batch254/1133, batch loss:0.19269123673439026, Training time:4009.5279326438904
batch reward last col mean 0.8313718438148499 first col mean 0.8421196937561035 all mean 0.8495113253593445
0.20499688386917114 0.20499688386917114
rl training, epoch0, iter0, batch255/1133, batch loss:0.20499688386917114, Training time:4037.2582788467407
batch reward last col mean 0.8148223161697388 first col mean 0.8353403210639954 all mean 0.8364530801773071
0.202714204788208 0.202714204788208
rl training, epoch0, iter0, batch256/1133, batch loss:0.202714204788208, Training time:4064.6501801013947
batch reward last col mean 0.8731573224067688 first col mean 0.8589222431182861 all mean 0.8801553249359131
0.2170625925064087 0.2170625776052475
rl training, epoch0, iter0, batch257/1133, batch loss:0.2170625776052475, Training time:4092.1594853401184
batch reward last col mean 0.8439276218414307 first col mean 0.8296860456466675 all mean 0.8357893228530884
0.212710440158844 0.212710440158844
rl training, epoch0, iter0, batch258/1133, batch loss:0.212710440158844, Training time:4120.009901046753
batch reward last col mean 0.8626998066902161 first col mean 0.8586041927337646 all mean 0.8509472012519836
0.20878945291042328 0.20878943800926208
rl training, epoch0, iter0, batch259/1133, batch loss:0.20878943800926208, Training time:4147.498405694962
batch reward last col mean 0.8453393578529358 first col mean 0.8833844661712646 all mean 0.8598726987838745
0.21650227904319763 0.21650227904319763
rl training, epoch0, iter0, batch260/1133, batch loss:0.21650227904319763, Training time:4175.055857419968
batch reward last col mean 0.871629536151886 first col mean 0.8431476354598999 all mean 0.8605571985244751
0.202495276927948 0.202495276927948
rl training, epoch0, iter0, batch261/1133, batch loss:0.202495276927948, Training time:4203.303475141525
batch reward last col mean 0.8923360109329224 first col mean 0.8551928997039795 all mean 0.8848869204521179
0.17410670220851898 0.17410670220851898
rl training, epoch0, iter0, batch262/1133, batch loss:0.17410670220851898, Training time:4230.75922369957
batch reward last col mean 0.8435728549957275 first col mean 0.8120289444923401 all mean 0.8259366154670715
0.17326539754867554 0.17326536774635315
rl training, epoch0, iter0, batch263/1133, batch loss:0.17326536774635315, Training time:4258.985299110413
batch reward last col mean 0.8387420773506165 first col mean 0.8464956283569336 all mean 0.8354299664497375
0.1840517222881317 0.1840517222881317
rl training, epoch0, iter0, batch264/1133, batch loss:0.1840517222881317, Training time:4286.5844259262085
batch reward last col mean 0.8521571159362793 first col mean 0.8744677901268005 all mean 0.8602028489112854
0.18769195675849915 0.18769195675849915
rl training, epoch0, iter0, batch265/1133, batch loss:0.18769195675849915, Training time:4314.49646282196
batch reward last col mean 0.8325889110565186 first col mean 0.8114043474197388 all mean 0.8414822220802307
0.19078026711940765 0.19078025221824646
rl training, epoch0, iter0, batch266/1133, batch loss:0.19078025221824646, Training time:4342.157113790512
batch reward last col mean 0.8615099787712097 first col mean 0.8819523453712463 all mean 0.8699651956558228
0.21396790444850922 0.21396790444850922
rl training, epoch0, iter0, batch267/1133, batch loss:0.21396790444850922, Training time:4370.105671405792
batch reward last col mean 0.8580464124679565 first col mean 0.8536753058433533 all mean 0.8411633968353271
0.21065062284469604 0.21065059304237366
rl training, epoch0, iter0, batch268/1133, batch loss:0.21065059304237366, Training time:4397.782640457153
batch reward last col mean 0.842747151851654 first col mean 0.8324916958808899 all mean 0.8197529911994934
0.22279326617717743 0.22279326617717743
rl training, epoch0, iter0, batch269/1133, batch loss:0.22279326617717743, Training time:4425.843730211258
batch reward last col mean 0.8820786476135254 first col mean 0.8666248321533203 all mean 0.8686227798461914
0.19592133164405823 0.19592133164405823
rl training, epoch0, iter0, batch270/1133, batch loss:0.19592133164405823, Training time:4453.26974439621
batch reward last col mean 0.854062557220459 first col mean 0.8380895256996155 all mean 0.8402256965637207
0.1745472401380539 0.1745472401380539
rl training, epoch0, iter0, batch271/1133, batch loss:0.1745472401380539, Training time:4480.8970692157745
batch reward last col mean 0.7981606125831604 first col mean 0.8186951279640198 all mean 0.8073140382766724
0.15460070967674255 0.15460069477558136
rl training, epoch0, iter0, batch272/1133, batch loss:0.15460069477558136, Training time:4508.726536273956
batch reward last col mean 0.8394883275032043 first col mean 0.854645848274231 all mean 0.8404764533042908
0.1343095600605011 0.1343095451593399
rl training, epoch0, iter0, batch273/1133, batch loss:0.1343095451593399, Training time:4536.415155887604
batch reward last col mean 0.8901815414428711 first col mean 0.8901892900466919 all mean 0.8911601305007935
0.1518593281507492 0.151859313249588
rl training, epoch0, iter0, batch274/1133, batch loss:0.151859313249588, Training time:4564.364133119583
batch reward last col mean 0.8487958908081055 first col mean 0.8438605070114136 all mean 0.8473963737487793
0.12478648871183395 0.12478647381067276
rl training, epoch0, iter0, batch275/1133, batch loss:0.12478647381067276, Training time:4592.470017671585
batch reward last col mean 0.8263681530952454 first col mean 0.8426836729049683 all mean 0.8328439593315125
0.11869841814041138 0.11869840323925018
rl training, epoch0, iter0, batch276/1133, batch loss:0.11869840323925018, Training time:4620.211977481842
batch reward last col mean 0.8297446966171265 first col mean 0.8068178296089172 all mean 0.8167546391487122
0.11495830118656158 0.11495829373598099
rl training, epoch0, iter0, batch277/1133, batch loss:0.11495829373598099, Training time:4647.588944911957
batch reward last col mean 0.882756769657135 first col mean 0.8600014448165894 all mean 0.8711245656013489
0.12178453058004379 0.1217845231294632
rl training, epoch0, iter0, batch278/1133, batch loss:0.1217845231294632, Training time:4676.048451185226
batch reward last col mean 0.8718459606170654 first col mean 0.8787498474121094 all mean 0.8666056394577026
0.11037975549697876 0.11037975549697876
rl training, epoch0, iter0, batch279/1133, batch loss:0.11037975549697876, Training time:4703.326243877411
batch reward last col mean 0.8611510992050171 first col mean 0.8548327088356018 all mean 0.8519768118858337
0.09955789893865585 0.09955789893865585
rl training, epoch0, iter0, batch280/1133, batch loss:0.09955789893865585, Training time:4730.9602382183075
batch reward last col mean 0.8334916830062866 first col mean 0.8374751806259155 all mean 0.8332690596580505
0.1118144616484642 0.1118144616484642
rl training, epoch0, iter0, batch281/1133, batch loss:0.1118144616484642, Training time:4759.012713670731
batch reward last col mean 0.8300197124481201 first col mean 0.8665316104888916 all mean 0.83237624168396
0.10594750195741653 0.10594749450683594
rl training, epoch0, iter0, batch282/1133, batch loss:0.10594749450683594, Training time:4786.709674835205
batch reward last col mean 0.863357663154602 first col mean 0.8469119071960449 all mean 0.8580477833747864
0.10041473805904388 0.10041473805904388
rl training, epoch0, iter0, batch283/1133, batch loss:0.10041473805904388, Training time:4814.3010375499725
batch reward last col mean 0.8436692953109741 first col mean 0.8444492816925049 all mean 0.8453852534294128
0.09274537861347198 0.09274537116289139
rl training, epoch0, iter0, batch284/1133, batch loss:0.09274537116289139, Training time:4842.280656814575
batch reward last col mean 0.8176206350326538 first col mean 0.8276991248130798 all mean 0.8143828511238098
0.10252590477466583 0.10252588987350464
rl training, epoch0, iter0, batch285/1133, batch loss:0.10252588987350464, Training time:4869.8001000881195
batch reward last col mean 0.8446358442306519 first col mean 0.8374626636505127 all mean 0.8440374732017517
0.09090667963027954 0.09090667963027954
rl training, epoch0, iter0, batch286/1133, batch loss:0.09090667963027954, Training time:4897.528979539871
batch reward last col mean 0.8358072638511658 first col mean 0.8238627910614014 all mean 0.8378050327301025
0.09841828793287277 0.09841828048229218
rl training, epoch0, iter0, batch287/1133, batch loss:0.09841828048229218, Training time:4925.052561759949
batch reward last col mean 0.8597797155380249 first col mean 0.8682610392570496 all mean 0.863793134689331
0.09624001383781433 0.09624001383781433
rl training, epoch0, iter0, batch288/1133, batch loss:0.09624001383781433, Training time:4952.336883544922
batch reward last col mean 0.882759690284729 first col mean 0.8730310201644897 all mean 0.8737634420394897
0.09966174513101578 0.09966172277927399
rl training, epoch0, iter0, batch289/1133, batch loss:0.09966172277927399, Training time:4979.843936920166
batch reward last col mean 0.8104802370071411 first col mean 0.8410742878913879 all mean 0.8160752654075623
0.10499945282936096 0.10499944537878036
rl training, epoch0, iter0, batch290/1133, batch loss:0.10499944537878036, Training time:5007.787299871445
batch reward last col mean 0.8405109643936157 first col mean 0.8410018086433411 all mean 0.8436757326126099
0.10430192947387695 0.10430192947387695
rl training, epoch0, iter0, batch291/1133, batch loss:0.10430192947387695, Training time:5035.471961975098
batch reward last col mean 0.8729676008224487 first col mean 0.8447925448417664 all mean 0.8662290573120117
0.09705407172441483 0.09705407172441483
rl training, epoch0, iter0, batch292/1133, batch loss:0.09705407172441483, Training time:5062.902540206909
batch reward last col mean 0.8558034300804138 first col mean 0.8749865889549255 all mean 0.8658671379089355
0.09484169632196426 0.09484169632196426
rl training, epoch0, iter0, batch293/1133, batch loss:0.09484169632196426, Training time:5090.538360834122
batch reward last col mean 0.9064626097679138 first col mean 0.8772168755531311 all mean 0.9042550325393677
0.09955889731645584 0.09955888986587524
rl training, epoch0, iter0, batch294/1133, batch loss:0.09955888986587524, Training time:5118.0654733181
batch reward last col mean 0.8330549001693726 first col mean 0.8419154286384583 all mean 0.8311823606491089
0.09031735360622406 0.09031734615564346
rl training, epoch0, iter0, batch295/1133, batch loss:0.09031734615564346, Training time:5146.289111852646
batch reward last col mean 0.8551117181777954 first col mean 0.8661031723022461 all mean 0.8554292917251587
0.10081747174263 0.10081747174263
rl training, epoch0, iter0, batch296/1133, batch loss:0.10081747174263, Training time:5174.08845448494
batch reward last col mean 0.8449472784996033 first col mean 0.831093966960907 all mean 0.8479534983634949
0.08908959478139877 0.08908958733081818
rl training, epoch0, iter0, batch297/1133, batch loss:0.08908958733081818, Training time:5201.614840269089
batch reward last col mean 0.8404343724250793 first col mean 0.8365147709846497 all mean 0.8455360531806946
0.08951479941606522 0.08951479941606522
rl training, epoch0, iter0, batch298/1133, batch loss:0.08951479941606522, Training time:5229.135024309158
batch reward last col mean 0.8692607879638672 first col mean 0.8540146350860596 all mean 0.866058886051178
0.09425746649503708 0.09425746649503708
rl training, epoch0, iter0, batch299/1133, batch loss:0.09425746649503708, Training time:5257.024563074112
batch reward last col mean 0.8484236001968384 first col mean 0.8704884052276611 all mean 0.8515127897262573
0.10035432130098343 0.10035431385040283
rl training, epoch0, iter0, batch300/1133, batch loss:0.10035431385040283, Training time:5284.7305471897125
batch reward last col mean 0.8396899104118347 first col mean 0.8437619209289551 all mean 0.839561939239502
0.0950782522559166 0.095078244805336
rl training, epoch0, iter0, batch301/1133, batch loss:0.095078244805336, Training time:5312.2435212135315
batch reward last col mean 0.8222858309745789 first col mean 0.8300882577896118 all mean 0.8234548568725586
0.09194310754537582 0.09194308519363403
rl training, epoch0, iter0, batch302/1133, batch loss:0.09194308519363403, Training time:5339.960787773132
batch reward last col mean 0.844078004360199 first col mean 0.8752782344818115 all mean 0.8477814197540283
0.09395688772201538 0.09395687282085419
rl training, epoch0, iter0, batch303/1133, batch loss:0.09395687282085419, Training time:5368.07879281044
batch reward last col mean 0.8463745713233948 first col mean 0.8463954925537109 all mean 0.8442479968070984
0.09175722301006317 0.09175722301006317
rl training, epoch0, iter0, batch304/1133, batch loss:0.09175722301006317, Training time:5397.054673433304
batch reward last col mean 0.8661654591560364 first col mean 0.8882009983062744 all mean 0.8686921000480652
0.09139076620340347 0.09139075130224228
rl training, epoch0, iter0, batch305/1133, batch loss:0.09139075130224228, Training time:5424.5336310863495
batch reward last col mean 0.8617690801620483 first col mean 0.8600067496299744 all mean 0.8655168414115906
0.1052408218383789 0.1052408292889595
rl training, epoch0, iter0, batch306/1133, batch loss:0.1052408292889595, Training time:5451.733706235886
batch reward last col mean 0.8438297510147095 first col mean 0.8567516207695007 all mean 0.851661205291748
0.10159311443567276 0.10159311443567276
rl training, epoch0, iter0, batch307/1133, batch loss:0.10159311443567276, Training time:5479.340672969818
batch reward last col mean 0.874340832233429 first col mean 0.859026312828064 all mean 0.8729979991912842
0.08669031411409378 0.08669031411409378
rl training, epoch0, iter0, batch308/1133, batch loss:0.08669031411409378, Training time:5506.955006122589
batch reward last col mean 0.8997765779495239 first col mean 0.8785179853439331 all mean 0.8982568383216858
0.09813017398118973 0.09813017398118973
rl training, epoch0, iter0, batch309/1133, batch loss:0.09813017398118973, Training time:5534.228417396545
batch reward last col mean 0.8395722508430481 first col mean 0.8437787890434265 all mean 0.8431253433227539
0.09510744363069534 0.09510744363069534
rl training, epoch0, iter0, batch310/1133, batch loss:0.09510744363069534, Training time:5561.668445587158
batch reward last col mean 0.8875910639762878 first col mean 0.8594410419464111 all mean 0.8882761597633362
0.10069859772920609 0.1006985753774643
rl training, epoch0, iter0, batch311/1133, batch loss:0.1006985753774643, Training time:5589.146349906921
batch reward last col mean 0.8618221879005432 first col mean 0.8537513017654419 all mean 0.8618615865707397
0.10013393312692642 0.10013393312692642
rl training, epoch0, iter0, batch312/1133, batch loss:0.10013393312692642, Training time:5616.529003620148
batch reward last col mean 0.87372887134552 first col mean 0.8551453351974487 all mean 0.8710260987281799
0.0997282862663269 0.0997282862663269
rl training, epoch0, iter0, batch313/1133, batch loss:0.0997282862663269, Training time:5644.580275774002
batch reward last col mean 0.9093794822692871 first col mean 0.8841380476951599 all mean 0.90913987159729
0.09992530941963196 0.09992530196905136
rl training, epoch0, iter0, batch314/1133, batch loss:0.09992530196905136, Training time:5672.099406719208
batch reward last col mean 0.859138548374176 first col mean 0.8832583427429199 all mean 0.8677058219909668
0.09357567876577377 0.09357566386461258
rl training, epoch0, iter0, batch315/1133, batch loss:0.09357566386461258, Training time:5699.33612704277
batch reward last col mean 0.8640725016593933 first col mean 0.8795928359031677 all mean 0.8655248880386353
0.10362469404935837 0.10362469404935837
rl training, epoch0, iter0, batch316/1133, batch loss:0.10362469404935837, Training time:5726.837601423264
batch reward last col mean 0.8470500111579895 first col mean 0.8607785105705261 all mean 0.8535418510437012
0.09134367108345032 0.09134367108345032
rl training, epoch0, iter0, batch317/1133, batch loss:0.09134367108345032, Training time:5754.57840180397
batch reward last col mean 0.8884224891662598 first col mean 0.8984623551368713 all mean 0.8885142803192139
0.10257665812969208 0.10257665812969208
rl training, epoch0, iter0, batch318/1133, batch loss:0.10257665812969208, Training time:5782.31768321991
batch reward last col mean 0.8682870864868164 first col mean 0.8702679872512817 all mean 0.8682548403739929
0.10139263421297073 0.10139261186122894
rl training, epoch0, iter0, batch319/1133, batch loss:0.10139261186122894, Training time:5810.064377784729
batch reward last col mean 0.8918591141700745 first col mean 0.8772855401039124 all mean 0.8981379270553589
0.08878697454929352 0.08878695964813232
rl training, epoch0, iter0, batch320/1133, batch loss:0.08878695964813232, Training time:5837.4481501579285
batch reward last col mean 0.8552382588386536 first col mean 0.8676391839981079 all mean 0.8520088791847229
0.09494070708751678 0.09494069218635559
rl training, epoch0, iter0, batch321/1133, batch loss:0.09494069218635559, Training time:5864.73402094841
batch reward last col mean 0.8984071016311646 first col mean 0.893412709236145 all mean 0.8988921642303467
0.08666277676820755 0.08666276931762695
rl training, epoch0, iter0, batch322/1133, batch loss:0.08666276931762695, Training time:5892.263132095337
batch reward last col mean 0.8781898021697998 first col mean 0.8849772214889526 all mean 0.8733578324317932
0.09098897874355316 0.09098897874355316
rl training, epoch0, iter0, batch323/1133, batch loss:0.09098897874355316, Training time:5920.08589887619
batch reward last col mean 0.8758001327514648 first col mean 0.8778347969055176 all mean 0.8688175082206726
0.09336836636066437 0.09336835145950317
rl training, epoch0, iter0, batch324/1133, batch loss:0.09336835145950317, Training time:5947.482880830765
batch reward last col mean 0.8621902465820312 first col mean 0.8447877764701843 all mean 0.8607571721076965
0.08585525304079056 0.08585524559020996
rl training, epoch0, iter0, batch325/1133, batch loss:0.08585524559020996, Training time:5974.729726552963
batch reward last col mean 0.87382572889328 first col mean 0.8805503249168396 all mean 0.8731337189674377
0.09422311186790466 0.09422309696674347
rl training, epoch0, iter0, batch326/1133, batch loss:0.09422309696674347, Training time:6002.113962650299
batch reward last col mean 0.8535066843032837 first col mean 0.8803004622459412 all mean 0.8588898777961731
0.0934537872672081 0.0934537872672081
rl training, epoch0, iter0, batch327/1133, batch loss:0.0934537872672081, Training time:6029.494926691055
batch reward last col mean 0.844341516494751 first col mean 0.8643808960914612 all mean 0.8457019925117493
0.08104559034109116 0.08104559779167175
rl training, epoch0, iter0, batch328/1133, batch loss:0.08104559779167175, Training time:6056.759424448013
batch reward last col mean 0.868140697479248 first col mean 0.851235568523407 all mean 0.8687646985054016
0.08424137532711029 0.0842413678765297
rl training, epoch0, iter0, batch329/1133, batch loss:0.0842413678765297, Training time:6084.240576267242
batch reward last col mean 0.8871817588806152 first col mean 0.8681014776229858 all mean 0.887904167175293
0.08806107938289642 0.08806107193231583
rl training, epoch0, iter0, batch330/1133, batch loss:0.08806107193231583, Training time:6111.516054153442
batch reward last col mean 0.8480938673019409 first col mean 0.86091148853302 all mean 0.8508471846580505
0.0950482189655304 0.0950482189655304
rl training, epoch0, iter0, batch331/1133, batch loss:0.0950482189655304, Training time:6138.921564340591
batch reward last col mean 0.8492041230201721 first col mean 0.8644274473190308 all mean 0.8564543128013611
0.07931758463382721 0.07931758463382721
rl training, epoch0, iter0, batch332/1133, batch loss:0.07931758463382721, Training time:6166.318094968796
batch reward last col mean 0.8614274859428406 first col mean 0.880862832069397 all mean 0.8619340062141418
0.08703885972499847 0.08703885972499847
rl training, epoch0, iter0, batch333/1133, batch loss:0.08703885972499847, Training time:6193.571583032608
batch reward last col mean 0.8837764263153076 first col mean 0.8685897588729858 all mean 0.889924943447113
0.08671408891677856 0.08671408891677856
rl training, epoch0, iter0, batch334/1133, batch loss:0.08671408891677856, Training time:6220.982884645462
batch reward last col mean 0.8618334531784058 first col mean 0.867059588432312 all mean 0.8621869087219238
0.088105209171772 0.088105209171772
rl training, epoch0, iter0, batch335/1133, batch loss:0.088105209171772, Training time:6248.362656831741
batch reward last col mean 0.8840523362159729 first col mean 0.8858640193939209 all mean 0.8849955797195435
0.0867820605635643 0.0867820605635643
rl training, epoch0, iter0, batch336/1133, batch loss:0.0867820605635643, Training time:6275.597589254379
batch reward last col mean 0.857475757598877 first col mean 0.8624695539474487 all mean 0.8571099042892456
0.0795852392911911 0.0795852467417717
rl training, epoch0, iter0, batch337/1133, batch loss:0.0795852467417717, Training time:6303.246047735214
batch reward last col mean 0.8644707202911377 first col mean 0.858919620513916 all mean 0.8653972744941711
0.08809425681829453 0.08809424936771393
rl training, epoch0, iter0, batch338/1133, batch loss:0.08809424936771393, Training time:6330.852200508118
batch reward last col mean 0.8682351112365723 first col mean 0.874591052532196 all mean 0.8708139061927795
0.09287117421627045 0.09287117421627045
rl training, epoch0, iter0, batch339/1133, batch loss:0.09287117421627045, Training time:6358.08912730217
batch reward last col mean 0.8944679498672485 first col mean 0.9054176807403564 all mean 0.8937006592750549
0.08714927732944489 0.08714926987886429
rl training, epoch0, iter0, batch340/1133, batch loss:0.08714926987886429, Training time:6385.242586374283
batch reward last col mean 0.8667997717857361 first col mean 0.8671772480010986 all mean 0.8588266372680664
0.09224189817905426 0.09224187582731247
rl training, epoch0, iter0, batch341/1133, batch loss:0.09224187582731247, Training time:6412.780388593674
batch reward last col mean 0.9102190136909485 first col mean 0.8826863169670105 all mean 0.902566134929657
0.07863219827413559 0.07863219827413559
rl training, epoch0, iter0, batch342/1133, batch loss:0.07863219827413559, Training time:6440.388786554337
batch reward last col mean 0.8445634841918945 first col mean 0.8538175821304321 all mean 0.8472809195518494
0.0871330127120018 0.0871330127120018
rl training, epoch0, iter0, batch343/1133, batch loss:0.0871330127120018, Training time:6467.801792621613
batch reward last col mean 0.8842962980270386 first col mean 0.8740140795707703 all mean 0.8820393085479736
0.08501073718070984 0.08501072973012924
rl training, epoch0, iter0, batch344/1133, batch loss:0.08501072973012924, Training time:6495.579303264618
batch reward last col mean 0.8550249338150024 first col mean 0.8624631762504578 all mean 0.8509266972541809
0.09185023605823517 0.09185021370649338
rl training, epoch0, iter0, batch345/1133, batch loss:0.09185021370649338, Training time:6522.940741062164
batch reward last col mean 0.8757439851760864 first col mean 0.8770899176597595 all mean 0.8706037998199463
0.09735041856765747 0.09735041111707687
rl training, epoch0, iter0, batch346/1133, batch loss:0.09735041111707687, Training time:6550.343946218491
batch reward last col mean 0.8755922317504883 first col mean 0.8630416989326477 all mean 0.863979160785675
0.102667897939682 0.1026679053902626
rl training, epoch0, iter0, batch347/1133, batch loss:0.1026679053902626, Training time:6578.056859493256
batch reward last col mean 0.8797534704208374 first col mean 0.8854634761810303 all mean 0.8902463316917419
0.09445610642433167 0.09445610642433167
rl training, epoch0, iter0, batch348/1133, batch loss:0.09445610642433167, Training time:6605.321532249451
batch reward last col mean 0.8788760304450989 first col mean 0.8915195465087891 all mean 0.8857153058052063
0.10122351348400116 0.10122353583574295
rl training, epoch0, iter0, batch349/1133, batch loss:0.10122353583574295, Training time:6633.261944770813
batch reward last col mean 0.8402650356292725 first col mean 0.8515428900718689 all mean 0.842043936252594
0.08462689816951752 0.08462689816951752
rl training, epoch0, iter0, batch350/1133, batch loss:0.08462689816951752, Training time:6660.433400392532
batch reward last col mean 0.8866803050041199 first col mean 0.8872886896133423 all mean 0.880683958530426
0.10445404797792435 0.10445404797792435
rl training, epoch0, iter0, batch351/1133, batch loss:0.10445404797792435, Training time:6687.829909324646
batch reward last col mean 0.8506931066513062 first col mean 0.8638214468955994 all mean 0.854407548904419
0.09562649577856064 0.09562648087739944
rl training, epoch0, iter0, batch352/1133, batch loss:0.09562648087739944, Training time:6715.253710746765
batch reward last col mean 0.8896360993385315 first col mean 0.8627938032150269 all mean 0.8823021650314331
0.10305600613355637 0.10305600613355637
rl training, epoch0, iter0, batch353/1133, batch loss:0.10305600613355637, Training time:6742.978261232376
batch reward last col mean 0.8358115553855896 first col mean 0.8551352024078369 all mean 0.8344293236732483
0.08671344071626663 0.08671341836452484
rl training, epoch0, iter0, batch354/1133, batch loss:0.08671341836452484, Training time:6770.319106340408
batch reward last col mean 0.869472861289978 first col mean 0.8531171679496765 all mean 0.8677746653556824
0.09551385045051575 0.09551383554935455
rl training, epoch0, iter0, batch355/1133, batch loss:0.09551383554935455, Training time:6797.549483299255
batch reward last col mean 0.856480062007904 first col mean 0.8549941778182983 all mean 0.85747891664505
0.08347394317388535 0.08347394317388535
rl training, epoch0, iter0, batch356/1133, batch loss:0.08347394317388535, Training time:6824.774785518646
batch reward last col mean 0.9139000177383423 first col mean 0.9113380908966064 all mean 0.9157540798187256
0.10099443048238754 0.10099443048238754
rl training, epoch0, iter0, batch357/1133, batch loss:0.10099443048238754, Training time:6852.3460075855255
batch reward last col mean 0.9003185033798218 first col mean 0.9030734896659851 all mean 0.9015032649040222
0.09050506353378296 0.09050506353378296
rl training, epoch0, iter0, batch358/1133, batch loss:0.09050506353378296, Training time:6880.072762012482
batch reward last col mean 0.8753997087478638 first col mean 0.9065914154052734 all mean 0.8795021772384644
0.07642777264118195 0.07642775774002075
rl training, epoch0, iter0, batch359/1133, batch loss:0.07642775774002075, Training time:6908.064186811447
batch reward last col mean 0.7968682050704956 first col mean 0.8275140523910522 all mean 0.7942047119140625
0.08899994939565659 0.08899994939565659
rl training, epoch0, iter0, batch360/1133, batch loss:0.08899994939565659, Training time:6936.239083528519
batch reward last col mean 0.8800655007362366 first col mean 0.8768969774246216 all mean 0.88080894947052
0.08014634996652603 0.08014634996652603
rl training, epoch0, iter0, batch361/1133, batch loss:0.08014634996652603, Training time:6964.984085798264
batch reward last col mean 0.8886467814445496 first col mean 0.8915013074874878 all mean 0.8915627002716064
0.08695639669895172 0.08695639669895172
rl training, epoch0, iter0, batch362/1133, batch loss:0.08695639669895172, Training time:6992.392232179642
batch reward last col mean 0.8799193501472473 first col mean 0.8874269723892212 all mean 0.8819763660430908
0.07982192188501358 0.07982192188501358
rl training, epoch0, iter0, batch363/1133, batch loss:0.07982192188501358, Training time:7020.474651813507
batch reward last col mean 0.9007753133773804 first col mean 0.8959635496139526 all mean 0.8961044549942017
0.08561968803405762 0.08561968803405762
rl training, epoch0, iter0, batch364/1133, batch loss:0.08561968803405762, Training time:7048.576371431351
batch reward last col mean 0.877445638179779 first col mean 0.8433754444122314 all mean 0.8611326813697815
0.0696653351187706 0.06966532766819
rl training, epoch0, iter0, batch365/1133, batch loss:0.06966532766819, Training time:7076.447670459747
batch reward last col mean 0.9191393852233887 first col mean 0.9047588109970093 all mean 0.9154820442199707
0.07293713092803955 0.07293712347745895
rl training, epoch0, iter0, batch366/1133, batch loss:0.07293712347745895, Training time:7104.307002544403
batch reward last col mean 0.9123051166534424 first col mean 0.8973433971405029 all mean 0.908777117729187
0.08204425126314163 0.08204425126314163
rl training, epoch0, iter0, batch367/1133, batch loss:0.08204425126314163, Training time:7132.657338619232
batch reward last col mean 0.8485004305839539 first col mean 0.8653080463409424 all mean 0.8514226078987122
0.07669280469417572 0.07669281214475632
rl training, epoch0, iter0, batch368/1133, batch loss:0.07669281214475632, Training time:7160.38044834137
batch reward last col mean 0.8262372612953186 first col mean 0.8352041244506836 all mean 0.8278406858444214
0.06604398787021637 0.06604398787021637
rl training, epoch0, iter0, batch369/1133, batch loss:0.06604398787021637, Training time:7188.375662088394
batch reward last col mean 0.8453441262245178 first col mean 0.8571743965148926 all mean 0.8482070565223694
0.074486643075943 0.0744866356253624
rl training, epoch0, iter0, batch370/1133, batch loss:0.0744866356253624, Training time:7216.129884958267
batch reward last col mean 0.87200927734375 first col mean 0.8767650723457336 all mean 0.8716346025466919
0.06826978921890259 0.06826978176832199
rl training, epoch0, iter0, batch371/1133, batch loss:0.06826978176832199, Training time:7244.206669092178
batch reward last col mean 0.8776079416275024 first col mean 0.8902460336685181 all mean 0.8805155158042908
0.07908366620540619 0.07908367365598679
rl training, epoch0, iter0, batch372/1133, batch loss:0.07908367365598679, Training time:7271.845387458801
batch reward last col mean 0.8323984146118164 first col mean 0.8452169299125671 all mean 0.8381328582763672
0.0748983845114708 0.0748983770608902
rl training, epoch0, iter0, batch373/1133, batch loss:0.0748983770608902, Training time:7299.28088259697
batch reward last col mean 0.8847000002861023 first col mean 0.8639076352119446 all mean 0.8833581209182739
0.07351619750261307 0.07351619005203247
rl training, epoch0, iter0, batch374/1133, batch loss:0.07351619005203247, Training time:7327.023527622223
batch reward last col mean 0.8900302648544312 first col mean 0.8806426525115967 all mean 0.887044370174408
0.07111334800720215 0.07111334800720215
rl training, epoch0, iter0, batch375/1133, batch loss:0.07111334800720215, Training time:7354.306866407394
batch reward last col mean 0.8764710426330566 first col mean 0.8579117655754089 all mean 0.8792861700057983
0.08452356606721878 0.08452356606721878
rl training, epoch0, iter0, batch376/1133, batch loss:0.08452356606721878, Training time:7381.43396282196
batch reward last col mean 0.8828080892562866 first col mean 0.8855223655700684 all mean 0.8818822503089905
0.06585591286420822 0.06585590541362762
rl training, epoch0, iter0, batch377/1133, batch loss:0.06585590541362762, Training time:7409.10263967514
batch reward last col mean 0.8673020601272583 first col mean 0.875208854675293 all mean 0.8683058619499207
0.07627557218074799 0.07627556473016739
rl training, epoch0, iter0, batch378/1133, batch loss:0.07627556473016739, Training time:7436.505112171173
batch reward last col mean 0.8676804304122925 first col mean 0.8632597327232361 all mean 0.8674727082252502
0.06887583434581757 0.06887583434581757
rl training, epoch0, iter0, batch379/1133, batch loss:0.06887583434581757, Training time:7464.150230884552
batch reward last col mean 0.910165548324585 first col mean 0.8973475098609924 all mean 0.909860372543335
0.07598317414522171 0.07598316669464111
rl training, epoch0, iter0, batch380/1133, batch loss:0.07598316669464111, Training time:7491.767040491104
batch reward last col mean 0.8812257051467896 first col mean 0.8828234672546387 all mean 0.8801367878913879
0.0622125007212162 0.06221248209476471
rl training, epoch0, iter0, batch381/1133, batch loss:0.06221248209476471, Training time:7519.265189170837
batch reward last col mean 0.8577401041984558 first col mean 0.8764298558235168 all mean 0.8577806949615479
0.0678187757730484 0.06781876087188721
rl training, epoch0, iter0, batch382/1133, batch loss:0.06781876087188721, Training time:7547.071792840958
batch reward last col mean 0.9180801510810852 first col mean 0.9163569211959839 all mean 0.9172484874725342
0.06314660608768463 0.06314659863710403
rl training, epoch0, iter0, batch383/1133, batch loss:0.06314659863710403, Training time:7575.162164926529
batch reward last col mean 0.9046779870986938 first col mean 0.8929950594902039 all mean 0.9062638878822327
0.07320097088813782 0.07320095598697662
rl training, epoch0, iter0, batch384/1133, batch loss:0.07320095598697662, Training time:7602.6708080768585
batch reward last col mean 0.9133502244949341 first col mean 0.904241144657135 all mean 0.9145751595497131
0.06727290898561478 0.06727289408445358
rl training, epoch0, iter0, batch385/1133, batch loss:0.06727289408445358, Training time:7630.781051158905
batch reward last col mean 0.8804425597190857 first col mean 0.8862388730049133 all mean 0.878449559211731
0.07141296565532684 0.07141295075416565
rl training, epoch0, iter0, batch386/1133, batch loss:0.07141295075416565, Training time:7658.481457233429
batch reward last col mean 0.8677334189414978 first col mean 0.8493462800979614 all mean 0.8666913509368896
0.06633399426937103 0.06633397936820984
rl training, epoch0, iter0, batch387/1133, batch loss:0.06633397936820984, Training time:7685.921658039093
batch reward last col mean 0.8479648232460022 first col mean 0.8683375716209412 all mean 0.8506037592887878
0.06976322084665298 0.06976320594549179
rl training, epoch0, iter0, batch388/1133, batch loss:0.06976320594549179, Training time:7714.06396818161
batch reward last col mean 0.8945889472961426 first col mean 0.9059277772903442 all mean 0.8956188559532166
0.06729701906442642 0.06729701161384583
rl training, epoch0, iter0, batch389/1133, batch loss:0.06729701161384583, Training time:7741.898910045624
batch reward last col mean 0.8854833841323853 first col mean 0.8952646255493164 all mean 0.8892319798469543
0.0765891820192337 0.07658916711807251
rl training, epoch0, iter0, batch390/1133, batch loss:0.07658916711807251, Training time:7769.760854005814
batch reward last col mean 0.8881330490112305 first col mean 0.8977512121200562 all mean 0.892033576965332
0.06452769786119461 0.06452768296003342
rl training, epoch0, iter0, batch391/1133, batch loss:0.06452768296003342, Training time:7797.5949165821075
batch reward last col mean 0.8693341016769409 first col mean 0.8722290396690369 all mean 0.8687092065811157
0.07761765271425247 0.07761764526367188
rl training, epoch0, iter0, batch392/1133, batch loss:0.07761764526367188, Training time:7825.320991516113
batch reward last col mean 0.8887861967086792 first col mean 0.8666136264801025 all mean 0.8886162042617798
0.06703925132751465 0.06703924387693405
rl training, epoch0, iter0, batch393/1133, batch loss:0.06703924387693405, Training time:7852.766373634338
batch reward last col mean 0.8976370692253113 first col mean 0.9076747298240662 all mean 0.8972325325012207
0.07283951342105865 0.07283949851989746
rl training, epoch0, iter0, batch394/1133, batch loss:0.07283949851989746, Training time:7880.485903501511
batch reward last col mean 0.8871192932128906 first col mean 0.8901470899581909 all mean 0.8868443369865417
0.08004182577133179 0.0800418108701706
rl training, epoch0, iter0, batch395/1133, batch loss:0.0800418108701706, Training time:7908.2131934165955
batch reward last col mean 0.8896410465240479 first col mean 0.8711981177330017 all mean 0.8900420665740967
0.0822870135307312 0.0822870060801506
rl training, epoch0, iter0, batch396/1133, batch loss:0.0822870060801506, Training time:7935.491480588913
batch reward last col mean 0.9024137258529663 first col mean 0.9117453694343567 all mean 0.9023929834365845
0.07181020081043243 0.07181018590927124
rl training, epoch0, iter0, batch397/1133, batch loss:0.07181018590927124, Training time:7963.380401611328
batch reward last col mean 0.8802515864372253 first col mean 0.8789710998535156 all mean 0.8805336356163025
0.0803525447845459 0.0803525298833847
rl training, epoch0, iter0, batch398/1133, batch loss:0.0803525298833847, Training time:7991.4662227630615
batch reward last col mean 0.8883390426635742 first col mean 0.8911726474761963 all mean 0.884850263595581
0.0699974074959755 0.0699973851442337
rl training, epoch0, iter0, batch399/1133, batch loss:0.0699973851442337, Training time:8019.516518115997
batch reward last col mean 0.871233344078064 first col mean 0.8901662826538086 all mean 0.8707115650177002
0.0830698311328888 0.0830698311328888
rl training, epoch0, iter0, batch400/1133, batch loss:0.0830698311328888, Training time:8047.374834537506
batch reward last col mean 0.893247663974762 first col mean 0.904682457447052 all mean 0.8936168551445007
0.07536062598228455 0.07536061853170395
rl training, epoch0, iter0, batch401/1133, batch loss:0.07536061853170395, Training time:8075.046024560928
batch reward last col mean 0.9179139733314514 first col mean 0.9170240163803101 all mean 0.9173786640167236
0.08266855776309967 0.08266855776309967
rl training, epoch0, iter0, batch402/1133, batch loss:0.08266855776309967, Training time:8103.433196544647
batch reward last col mean 0.8644254207611084 first col mean 0.8558055758476257 all mean 0.8674389123916626
0.08660072833299637 0.08660072088241577
rl training, epoch0, iter0, batch403/1133, batch loss:0.08660072088241577, Training time:8131.165077924728
batch reward last col mean 0.8955720663070679 first col mean 0.8877883553504944 all mean 0.8947057127952576
0.08392619341611862 0.08392617851495743
rl training, epoch0, iter0, batch404/1133, batch loss:0.08392617851495743, Training time:8159.3022203445435
batch reward last col mean 0.8980900049209595 first col mean 0.8926688432693481 all mean 0.8970026969909668
0.0755331888794899 0.0755331814289093
rl training, epoch0, iter0, batch405/1133, batch loss:0.0755331814289093, Training time:8186.866626739502
batch reward last col mean 0.8349592685699463 first col mean 0.8507782220840454 all mean 0.8386489152908325
0.07424581050872803 0.07424580305814743
rl training, epoch0, iter0, batch406/1133, batch loss:0.07424580305814743, Training time:8214.628043413162
batch reward last col mean 0.8695437908172607 first col mean 0.867098867893219 all mean 0.8688833713531494
0.07631764560937881 0.07631763070821762
rl training, epoch0, iter0, batch407/1133, batch loss:0.07631763070821762, Training time:8242.287311553955
batch reward last col mean 0.8496565818786621 first col mean 0.8459330797195435 all mean 0.8514365553855896
0.06755288690328598 0.06755288690328598
rl training, epoch0, iter0, batch408/1133, batch loss:0.06755288690328598, Training time:8269.728491783142
batch reward last col mean 0.8588230609893799 first col mean 0.891253650188446 all mean 0.861172616481781
0.07847864180803299 0.0784786269068718
rl training, epoch0, iter0, batch409/1133, batch loss:0.0784786269068718, Training time:8297.352807760239
batch reward last col mean 0.9063187837600708 first col mean 0.8951982259750366 all mean 0.9046885967254639
0.0798611268401146 0.079861119389534
rl training, epoch0, iter0, batch410/1133, batch loss:0.079861119389534, Training time:8324.836099624634
batch reward last col mean 0.872382640838623 first col mean 0.9008183479309082 all mean 0.8751389980316162
0.07515641301870346 0.07515639066696167
rl training, epoch0, iter0, batch411/1133, batch loss:0.07515639066696167, Training time:8352.169669389725
batch reward last col mean 0.9078789353370667 first col mean 0.9025214910507202 all mean 0.9070097208023071
0.06633047759532928 0.06633047014474869
rl training, epoch0, iter0, batch412/1133, batch loss:0.06633047014474869, Training time:8379.865292310715
batch reward last col mean 0.9206794500350952 first col mean 0.9226832389831543 all mean 0.9210970997810364
0.07208644598722458 0.07208643108606339
rl training, epoch0, iter0, batch413/1133, batch loss:0.07208643108606339, Training time:8407.909550666809
batch reward last col mean 0.9014788866043091 first col mean 0.9137036204338074 all mean 0.9007183313369751
0.06480605155229568 0.0648060292005539
rl training, epoch0, iter0, batch414/1133, batch loss:0.0648060292005539, Training time:8435.502880811691
batch reward last col mean 0.8987194299697876 first col mean 0.9089397192001343 all mean 0.9007757306098938
0.08213339000940323 0.08213336765766144
rl training, epoch0, iter0, batch415/1133, batch loss:0.08213336765766144, Training time:8463.627241373062
batch reward last col mean 0.8657464385032654 first col mean 0.8721039295196533 all mean 0.85882169008255
0.07345442473888397 0.07345440238714218
rl training, epoch0, iter0, batch416/1133, batch loss:0.07345440238714218, Training time:8491.782116174698
batch reward last col mean 0.9035252332687378 first col mean 0.9117075204849243 all mean 0.899142324924469
0.07073178142309189 0.07073178142309189
rl training, epoch0, iter0, batch417/1133, batch loss:0.07073178142309189, Training time:8519.336076974869
batch reward last col mean 0.8515220880508423 first col mean 0.8858944177627563 all mean 0.8570493459701538
0.07507357001304626 0.07507354766130447
rl training, epoch0, iter0, batch418/1133, batch loss:0.07507354766130447, Training time:8546.738751411438
batch reward last col mean 0.9031293392181396 first col mean 0.8954946994781494 all mean 0.9036314487457275
0.07043430954217911 0.07043430209159851
rl training, epoch0, iter0, batch419/1133, batch loss:0.07043430209159851, Training time:8574.383968114853
batch reward last col mean 0.8970706462860107 first col mean 0.8874140977859497 all mean 0.8982914090156555
0.07516427338123322 0.07516426593065262
rl training, epoch0, iter0, batch420/1133, batch loss:0.07516426593065262, Training time:8601.784643173218
batch reward last col mean 0.8238375186920166 first col mean 0.8626142144203186 all mean 0.8274173140525818
0.07995763421058655 0.07995762676000595
rl training, epoch0, iter0, batch421/1133, batch loss:0.07995762676000595, Training time:8629.196526765823
batch reward last col mean 0.8718200325965881 first col mean 0.8740634918212891 all mean 0.8754611015319824
0.07903280109167099 0.0790327861905098
rl training, epoch0, iter0, batch422/1133, batch loss:0.0790327861905098, Training time:8656.712531328201
batch reward last col mean 0.8643256425857544 first col mean 0.8776545524597168 all mean 0.8653368949890137
0.07827083021402359 0.07827083021402359
rl training, epoch0, iter0, batch423/1133, batch loss:0.07827083021402359, Training time:8684.169430732727
batch reward last col mean 0.8647571206092834 first col mean 0.8668181896209717 all mean 0.868537187576294
0.07367152720689774 0.07367150485515594
rl training, epoch0, iter0, batch424/1133, batch loss:0.07367150485515594, Training time:8711.609450817108
batch reward last col mean 0.8827121257781982 first col mean 0.9019374847412109 all mean 0.8855669498443604
0.08651427179574966 0.08651424944400787
rl training, epoch0, iter0, batch425/1133, batch loss:0.08651424944400787, Training time:8739.070618391037
batch reward last col mean 0.8833982348442078 first col mean 0.8814927935600281 all mean 0.8842315673828125
0.07907614856958389 0.0790761411190033
rl training, epoch0, iter0, batch426/1133, batch loss:0.0790761411190033, Training time:8766.643680334091
batch reward last col mean 0.9053753018379211 first col mean 0.8838844299316406 all mean 0.9033278822898865
0.08260806649923325 0.08260805904865265
rl training, epoch0, iter0, batch427/1133, batch loss:0.08260805904865265, Training time:8794.23192691803
batch reward last col mean 0.8961224555969238 first col mean 0.8670790791511536 all mean 0.8924097418785095
0.07967381179332733 0.07967379689216614
rl training, epoch0, iter0, batch428/1133, batch loss:0.07967379689216614, Training time:8821.768218278885
batch reward last col mean 0.9007235169410706 first col mean 0.8852438926696777 all mean 0.8971692323684692
0.07532909512519836 0.07532908022403717
rl training, epoch0, iter0, batch429/1133, batch loss:0.07532908022403717, Training time:8849.206335783005
batch reward last col mean 0.8887805938720703 first col mean 0.8808296918869019 all mean 0.8910730481147766
0.0667918249964714 0.06679181009531021
rl training, epoch0, iter0, batch430/1133, batch loss:0.06679181009531021, Training time:8877.477205753326
batch reward last col mean 0.8618115782737732 first col mean 0.8668632507324219 all mean 0.8662462830543518
0.07706266641616821 0.07706263661384583
rl training, epoch0, iter0, batch431/1133, batch loss:0.07706263661384583, Training time:8905.681586503983
batch reward last col mean 0.8779807090759277 first col mean 0.8855551481246948 all mean 0.879767656326294
0.057360533624887466 0.05736052244901657
rl training, epoch0, iter0, batch432/1133, batch loss:0.05736052244901657, Training time:8934.128753185272
batch reward last col mean 0.8677011728286743 first col mean 0.8909000754356384 all mean 0.8703934550285339
0.075406014919281 0.07540600001811981
rl training, epoch0, iter0, batch433/1133, batch loss:0.07540600001811981, Training time:8962.061846971512
batch reward last col mean 0.9126599431037903 first col mean 0.8922485113143921 all mean 0.9099136590957642
0.05869293212890625 0.058692920953035355
rl training, epoch0, iter0, batch434/1133, batch loss:0.058692920953035355, Training time:8990.02620768547
batch reward last col mean 0.8431326150894165 first col mean 0.8821730613708496 all mean 0.8486360311508179
0.06377801299095154 0.06377799808979034
rl training, epoch0, iter0, batch435/1133, batch loss:0.06377799808979034, Training time:9018.089707612991
batch reward last col mean 0.9083660840988159 first col mean 0.8824800848960876 all mean 0.90462726354599
0.0696689635515213 0.06966894119977951
rl training, epoch0, iter0, batch436/1133, batch loss:0.06966894119977951, Training time:9045.76440358162
batch reward last col mean 0.8927217721939087 first col mean 0.8877741098403931 all mean 0.891700804233551
0.059518951922655106 0.05951894074678421
rl training, epoch0, iter0, batch437/1133, batch loss:0.05951894074678421, Training time:9073.687976360321
batch reward last col mean 0.9306354522705078 first col mean 0.9331600069999695 all mean 0.9306246638298035
0.054293978959321976 0.05429396033287048
rl training, epoch0, iter0, batch438/1133, batch loss:0.05429396033287048, Training time:9101.910048246384
batch reward last col mean 0.9023628830909729 first col mean 0.8945261836051941 all mean 0.9001365900039673
0.05650937557220459 0.0565093532204628
rl training, epoch0, iter0, batch439/1133, batch loss:0.0565093532204628, Training time:9129.498222112656
batch reward last col mean 0.9238312244415283 first col mean 0.9102720618247986 all mean 0.9226656556129456
0.05942147970199585 0.05942146107554436
rl training, epoch0, iter0, batch440/1133, batch loss:0.05942146107554436, Training time:9157.51186966896
batch reward last col mean 0.8699322938919067 first col mean 0.8799702525138855 all mean 0.8715230226516724
0.05924815312027931 0.05924813449382782
rl training, epoch0, iter0, batch441/1133, batch loss:0.05924813449382782, Training time:9184.944949865341
batch reward last col mean 0.9068441390991211 first col mean 0.9115259051322937 all mean 0.9087201356887817
0.05029388517141342 0.050293855369091034
rl training, epoch0, iter0, batch442/1133, batch loss:0.050293855369091034, Training time:9212.837199687958
batch reward last col mean 0.9195850491523743 first col mean 0.9249762892723083 all mean 0.9206385016441345
0.050247520208358765 0.05024750158190727
rl training, epoch0, iter0, batch443/1133, batch loss:0.05024750158190727, Training time:9240.456188678741
batch reward last col mean 0.8964967727661133 first col mean 0.9069799184799194 all mean 0.8998693823814392
0.06115151569247246 0.06115148589015007
rl training, epoch0, iter0, batch444/1133, batch loss:0.06115148589015007, Training time:9268.2247838974
batch reward last col mean 0.8890889286994934 first col mean 0.8922580480575562 all mean 0.8888916373252869
0.06045744940638542 0.06045743077993393
rl training, epoch0, iter0, batch445/1133, batch loss:0.06045743077993393, Training time:9296.33649134636
batch reward last col mean 0.9101300835609436 first col mean 0.9087690711021423 all mean 0.9108633399009705
0.05440118536353111 0.05440116673707962
rl training, epoch0, iter0, batch446/1133, batch loss:0.05440116673707962, Training time:9324.374964475632
batch reward last col mean 0.8954129219055176 first col mean 0.8972963094711304 all mean 0.8933953046798706
0.06040801480412483 0.06040799245238304
rl training, epoch0, iter0, batch447/1133, batch loss:0.06040799245238304, Training time:9352.125227689743
batch reward last col mean 0.8909620642662048 first col mean 0.8987308740615845 all mean 0.8892805576324463
0.057095788419246674 0.05709577351808548
rl training, epoch0, iter0, batch448/1133, batch loss:0.05709577351808548, Training time:9379.338658809662
batch reward last col mean 0.9133031368255615 first col mean 0.921076774597168 all mean 0.9136399030685425
0.04757499322295189 0.0475749745965004
rl training, epoch0, iter0, batch449/1133, batch loss:0.0475749745965004, Training time:9406.838728904724
batch reward last col mean 0.9202187061309814 first col mean 0.9199243783950806 all mean 0.9210951328277588
0.05349881201982498 0.05349879711866379
rl training, epoch0, iter0, batch450/1133, batch loss:0.05349879711866379, Training time:9434.14921092987
batch reward last col mean 0.9005657434463501 first col mean 0.9056704044342041 all mean 0.8930129408836365
0.04891546443104744 0.04891545698046684
rl training, epoch0, iter0, batch451/1133, batch loss:0.04891545698046684, Training time:9462.06601691246
batch reward last col mean 0.8801409006118774 first col mean 0.8932747840881348 all mean 0.8817201852798462
0.05039283633232117 0.050392813980579376
rl training, epoch0, iter0, batch452/1133, batch loss:0.050392813980579376, Training time:9489.638199567795
batch reward last col mean 0.9029965400695801 first col mean 0.8984477519989014 all mean 0.9032289981842041
0.04834386706352234 0.04834384098649025
rl training, epoch0, iter0, batch453/1133, batch loss:0.04834384098649025, Training time:9517.335033416748
batch reward last col mean 0.8642119765281677 first col mean 0.879046618938446 all mean 0.8651779890060425
0.047098308801651 0.0470983050763607
rl training, epoch0, iter0, batch454/1133, batch loss:0.0470983050763607, Training time:9545.565519809723
batch reward last col mean 0.8883579969406128 first col mean 0.9036625027656555 all mean 0.8884615898132324
0.04197653755545616 0.04197651520371437
rl training, epoch0, iter0, batch455/1133, batch loss:0.04197651520371437, Training time:9573.451167106628
batch reward last col mean 0.9087246060371399 first col mean 0.9097007513046265 all mean 0.9087234139442444
0.04628333821892738 0.04628331586718559
rl training, epoch0, iter0, batch456/1133, batch loss:0.04628331586718559, Training time:9601.384263515472
batch reward last col mean 0.8880613446235657 first col mean 0.8878835439682007 all mean 0.8885095119476318
0.04538756608963013 0.045387543737888336
rl training, epoch0, iter0, batch457/1133, batch loss:0.045387543737888336, Training time:9629.370273590088
batch reward last col mean 0.9294401407241821 first col mean 0.9203000068664551 all mean 0.9279682040214539
0.052036091685295105 0.052036065608263016
rl training, epoch0, iter0, batch458/1133, batch loss:0.052036065608263016, Training time:9657.101443052292
batch reward last col mean 0.8892186880111694 first col mean 0.8871325850486755 all mean 0.8878692984580994
0.05571833252906799 0.055718306452035904
rl training, epoch0, iter0, batch459/1133, batch loss:0.055718306452035904, Training time:9684.89783334732
batch reward last col mean 0.879108190536499 first col mean 0.9067044258117676 all mean 0.8809099793434143
0.04391765594482422 0.04391762614250183
rl training, epoch0, iter0, batch460/1133, batch loss:0.04391762614250183, Training time:9713.224598884583
batch reward last col mean 0.8488758206367493 first col mean 0.8619335889816284 all mean 0.8491711616516113
0.05455479770898819 0.054554786533117294
rl training, epoch0, iter0, batch461/1133, batch loss:0.054554786533117294, Training time:9740.813154697418
batch reward last col mean 0.8805187940597534 first col mean 0.8931763172149658 all mean 0.8802700042724609
0.05083359777927399 0.050833575427532196
rl training, epoch0, iter0, batch462/1133, batch loss:0.050833575427532196, Training time:9768.37719154358
batch reward last col mean 0.9069084525108337 first col mean 0.916719913482666 all mean 0.9064457416534424
0.0553738959133625 0.05537387728691101
rl training, epoch0, iter0, batch463/1133, batch loss:0.05537387728691101, Training time:9796.105973482132
batch reward last col mean 0.9166132807731628 first col mean 0.9167681932449341 all mean 0.9162271022796631
0.052370768040418625 0.052370745688676834
rl training, epoch0, iter0, batch464/1133, batch loss:0.052370745688676834, Training time:9823.951341629028
batch reward last col mean 0.9012498259544373 first col mean 0.8948284387588501 all mean 0.9011300802230835
0.05216669291257858 0.05216667056083679
rl training, epoch0, iter0, batch465/1133, batch loss:0.05216667056083679, Training time:9852.22484946251
batch reward last col mean 0.9226751327514648 first col mean 0.9226363897323608 all mean 0.9227862358093262
0.05765311419963837 0.05765308067202568
rl training, epoch0, iter0, batch466/1133, batch loss:0.05765308067202568, Training time:9879.786230802536
batch reward last col mean 0.8982087969779968 first col mean 0.900300920009613 all mean 0.898318350315094
0.0512455552816391 0.051245540380477905
rl training, epoch0, iter0, batch467/1133, batch loss:0.051245540380477905, Training time:9908.081485033035
batch reward last col mean 0.8903176784515381 first col mean 0.8846427798271179 all mean 0.8893551230430603
0.04819003865122795 0.04819002002477646
rl training, epoch0, iter0, batch468/1133, batch loss:0.04819002002477646, Training time:9935.523352861404
batch reward last col mean 0.9328657984733582 first col mean 0.9404152631759644 all mean 0.9327966570854187
0.05880221351981163 0.05880219489336014
rl training, epoch0, iter0, batch469/1133, batch loss:0.05880219489336014, Training time:9963.357518434525
batch reward last col mean 0.8890881538391113 first col mean 0.8943390250205994 all mean 0.8886932730674744
0.05673960596323013 0.056739576160907745
rl training, epoch0, iter0, batch470/1133, batch loss:0.056739576160907745, Training time:9990.9604742527
batch reward last col mean 0.9159989356994629 first col mean 0.8951549530029297 all mean 0.9122585654258728
0.048189081251621246 0.048189058899879456
rl training, epoch0, iter0, batch471/1133, batch loss:0.048189058899879456, Training time:10018.540387630463
batch reward last col mean 0.8947280645370483 first col mean 0.8913677930831909 all mean 0.8970382213592529
0.05384835973381996 0.05384833738207817
rl training, epoch0, iter0, batch472/1133, batch loss:0.05384833738207817, Training time:10045.852015972137
batch reward last col mean 0.9337474703788757 first col mean 0.9467766880989075 all mean 0.9342635869979858
0.0582905039191246 0.05829049274325371
rl training, epoch0, iter0, batch473/1133, batch loss:0.05829049274325371, Training time:10073.69743180275
batch reward last col mean 0.9219561815261841 first col mean 0.9247662425041199 all mean 0.9233572483062744
0.05476576089859009 0.0547657385468483
rl training, epoch0, iter0, batch474/1133, batch loss:0.0547657385468483, Training time:10101.445236206055
batch reward last col mean 0.9048728346824646 first col mean 0.9060534238815308 all mean 0.9061485528945923
0.05365787819027901 0.053657859563827515
rl training, epoch0, iter0, batch475/1133, batch loss:0.053657859563827515, Training time:10128.996557235718
batch reward last col mean 0.8544293642044067 first col mean 0.871367335319519 all mean 0.8562759160995483
0.051174577325582504 0.05117456987500191
rl training, epoch0, iter0, batch476/1133, batch loss:0.05117456987500191, Training time:10156.964064598083
batch reward last col mean 0.8946905136108398 first col mean 0.8845298290252686 all mean 0.8910556435585022
0.0510108545422554 0.05101083964109421
rl training, epoch0, iter0, batch477/1133, batch loss:0.05101083964109421, Training time:10184.48695230484
batch reward last col mean 0.8992255926132202 first col mean 0.9093392491340637 all mean 0.9006185531616211
0.05364353582262993 0.053643517196178436
rl training, epoch0, iter0, batch478/1133, batch loss:0.053643517196178436, Training time:10212.484856128693
batch reward last col mean 0.8873017430305481 first col mean 0.8929018378257751 all mean 0.885447084903717
0.05148964002728462 0.05148962140083313
rl training, epoch0, iter0, batch479/1133, batch loss:0.05148962140083313, Training time:10240.142641067505
batch reward last col mean 0.9118998646736145 first col mean 0.9187756180763245 all mean 0.9101299047470093
0.06266205757856369 0.0626620352268219
rl training, epoch0, iter0, batch480/1133, batch loss:0.0626620352268219, Training time:10267.53517961502
batch reward last col mean 0.8865772485733032 first col mean 0.8975735306739807 all mean 0.8874792456626892
0.04901675134897232 0.04901673272252083
rl training, epoch0, iter0, batch481/1133, batch loss:0.04901673272252083, Training time:10295.53419828415
batch reward last col mean 0.9252129793167114 first col mean 0.9355583190917969 all mean 0.9248476624488831
0.05612105876207352 0.056121040135622025
rl training, epoch0, iter0, batch482/1133, batch loss:0.056121040135622025, Training time:10323.564274311066
batch reward last col mean 0.9051364064216614 first col mean 0.9002746939659119 all mean 0.9036655426025391
0.047721102833747864 0.047721076756715775
rl training, epoch0, iter0, batch483/1133, batch loss:0.047721076756715775, Training time:10351.135959625244
batch reward last col mean 0.8945925235748291 first col mean 0.8922059535980225 all mean 0.8945701122283936
0.054484155029058456 0.054484136402606964
rl training, epoch0, iter0, batch484/1133, batch loss:0.054484136402606964, Training time:10378.71814584732
batch reward last col mean 0.8926624059677124 first col mean 0.8757562041282654 all mean 0.8908730149269104
0.05346743017435074 0.053467411547899246
rl training, epoch0, iter0, batch485/1133, batch loss:0.053467411547899246, Training time:10406.62453174591
batch reward last col mean 0.8595616817474365 first col mean 0.855212926864624 all mean 0.8598145842552185
0.049766600131988525 0.04976657032966614
rl training, epoch0, iter0, batch486/1133, batch loss:0.04976657032966614, Training time:10434.812227010727
batch reward last col mean 0.8829626441001892 first col mean 0.8689565658569336 all mean 0.8807945847511292
0.053761646151542664 0.05376162752509117
rl training, epoch0, iter0, batch487/1133, batch loss:0.05376162752509117, Training time:10462.286518573761
batch reward last col mean 0.8981485366821289 first col mean 0.9049570560455322 all mean 0.8983932137489319
0.057106416672468185 0.05710640177130699
rl training, epoch0, iter0, batch488/1133, batch loss:0.05710640177130699, Training time:10489.709491729736
batch reward last col mean 0.8783478736877441 first col mean 0.8800041675567627 all mean 0.8779844045639038
0.05594286322593689 0.0559428445994854
rl training, epoch0, iter0, batch489/1133, batch loss:0.0559428445994854, Training time:10517.203005313873
batch reward last col mean 0.8643847107887268 first col mean 0.8731532096862793 all mean 0.8676562309265137
0.05871943384408951 0.058719418942928314
rl training, epoch0, iter0, batch490/1133, batch loss:0.058719418942928314, Training time:10544.590988397598
batch reward last col mean 0.917496919631958 first col mean 0.9074967503547668 all mean 0.9191697239875793
0.0628318339586258 0.062831811606884
rl training, epoch0, iter0, batch491/1133, batch loss:0.062831811606884, Training time:10572.562911510468
batch reward last col mean 0.907172679901123 first col mean 0.9004004001617432 all mean 0.9065144658088684
0.06628134101629257 0.06628132611513138
rl training, epoch0, iter0, batch492/1133, batch loss:0.06628132611513138, Training time:10600.280358314514
batch reward last col mean 0.9043546915054321 first col mean 0.8957878351211548 all mean 0.9028886556625366
0.055315565317869186 0.05531555786728859
rl training, epoch0, iter0, batch493/1133, batch loss:0.05531555786728859, Training time:10627.89886212349
batch reward last col mean 0.8756073117256165 first col mean 0.8762788772583008 all mean 0.876335084438324
0.056708257645368576 0.056708235293626785
rl training, epoch0, iter0, batch494/1133, batch loss:0.056708235293626785, Training time:10656.209595680237
batch reward last col mean 0.894305944442749 first col mean 0.897665798664093 all mean 0.8952216506004333
0.06101049482822418 0.061010487377643585
rl training, epoch0, iter0, batch495/1133, batch loss:0.061010487377643585, Training time:10684.668855428696
batch reward last col mean 0.8924994468688965 first col mean 0.885988712310791 all mean 0.8912902474403381
0.05431317165493965 0.054313164204359055
rl training, epoch0, iter0, batch496/1133, batch loss:0.054313164204359055, Training time:10713.089903354645
batch reward last col mean 0.8778772950172424 first col mean 0.868683934211731 all mean 0.8777544498443604
0.06342311203479767 0.06342308223247528
rl training, epoch0, iter0, batch497/1133, batch loss:0.06342308223247528, Training time:10741.601279735565
batch reward last col mean 0.9032422304153442 first col mean 0.9029973745346069 all mean 0.9028764367103577
0.06710059195756912 0.06710056960582733
rl training, epoch0, iter0, batch498/1133, batch loss:0.06710056960582733, Training time:10769.73825263977
batch reward last col mean 0.9129970073699951 first col mean 0.8976365923881531 all mean 0.9118297696113586
0.06481485813856125 0.06481484323740005
rl training, epoch0, iter0, batch499/1133, batch loss:0.06481484323740005, Training time:10797.236416816711
batch reward last col mean 0.8799608945846558 first col mean 0.885339081287384 all mean 0.88230299949646
0.0669277086853981 0.06692769378423691
rl training, epoch0, iter0, batch500/1133, batch loss:0.06692769378423691, Training time:10824.849920272827
batch reward last col mean 0.8953853845596313 first col mean 0.8965723514556885 all mean 0.8964979648590088
0.07191318273544312 0.07191316783428192
rl training, epoch0, iter0, batch501/1133, batch loss:0.07191316783428192, Training time:10852.871640205383
batch reward last col mean 0.846442461013794 first col mean 0.8559162616729736 all mean 0.8491613268852234
0.0685247853398323 0.06852477043867111
rl training, epoch0, iter0, batch502/1133, batch loss:0.06852477043867111, Training time:10880.739432811737
batch reward last col mean 0.9099088311195374 first col mean 0.9083139300346375 all mean 0.9111035466194153
0.07336597144603729 0.0733659565448761
rl training, epoch0, iter0, batch503/1133, batch loss:0.0733659565448761, Training time:10908.727885961533
batch reward last col mean 0.8683611750602722 first col mean 0.8622955083847046 all mean 0.8653962016105652
0.06840821355581284 0.06840820610523224
rl training, epoch0, iter0, batch504/1133, batch loss:0.06840820610523224, Training time:10936.167559623718
batch reward last col mean 0.9168802499771118 first col mean 0.9237562417984009 all mean 0.9179855585098267
0.07515311986207962 0.07515309751033783
rl training, epoch0, iter0, batch505/1133, batch loss:0.07515309751033783, Training time:10963.886361837387
batch reward last col mean 0.8982505202293396 first col mean 0.8947288990020752 all mean 0.8988671898841858
0.07267773896455765 0.07267773151397705
rl training, epoch0, iter0, batch506/1133, batch loss:0.07267773151397705, Training time:10992.0615234375
batch reward last col mean 0.9163339138031006 first col mean 0.9214062094688416 all mean 0.9150063991546631
0.07975596189498901 0.07975594699382782
rl training, epoch0, iter0, batch507/1133, batch loss:0.07975594699382782, Training time:11020.680079936981
batch reward last col mean 0.9013504981994629 first col mean 0.9041121006011963 all mean 0.8996137976646423
0.08049685508012772 0.08049684762954712
rl training, epoch0, iter0, batch508/1133, batch loss:0.08049684762954712, Training time:11048.513135910034
batch reward last col mean 0.8833887577056885 first col mean 0.8975446820259094 all mean 0.8860807418823242
0.07178038358688354 0.07178037613630295
rl training, epoch0, iter0, batch509/1133, batch loss:0.07178037613630295, Training time:11077.142858743668
batch reward last col mean 0.9151000380516052 first col mean 0.9185961484909058 all mean 0.912144124507904
0.08077289909124374 0.08077288419008255
rl training, epoch0, iter0, batch510/1133, batch loss:0.08077288419008255, Training time:11104.71610546112
batch reward last col mean 0.9170666933059692 first col mean 0.9016698002815247 all mean 0.9146857261657715
0.07813964784145355 0.07813964039087296
rl training, epoch0, iter0, batch511/1133, batch loss:0.07813964039087296, Training time:11132.190983772278
batch reward last col mean 0.8755556344985962 first col mean 0.8927270174026489 all mean 0.8781999349594116
0.0732378214597702 0.07323780655860901
rl training, epoch0, iter0, batch512/1133, batch loss:0.07323780655860901, Training time:11159.975281953812
batch reward last col mean 0.880827784538269 first col mean 0.880711019039154 all mean 0.8840312957763672
0.07440519332885742 0.07440518587827682
rl training, epoch0, iter0, batch513/1133, batch loss:0.07440518587827682, Training time:11187.5410592556
batch reward last col mean 0.8837249875068665 first col mean 0.9142651557922363 all mean 0.8860464096069336
0.07991728186607361 0.0799172893166542
rl training, epoch0, iter0, batch514/1133, batch loss:0.0799172893166542, Training time:11215.789388418198
batch reward last col mean 0.914502739906311 first col mean 0.9054453372955322 all mean 0.9129599332809448
0.07348140329122543 0.07348139584064484
rl training, epoch0, iter0, batch515/1133, batch loss:0.07348139584064484, Training time:11243.579439640045
batch reward last col mean 0.9251887798309326 first col mean 0.9151269197463989 all mean 0.9223793148994446
0.07048679888248444 0.07048679143190384
rl training, epoch0, iter0, batch516/1133, batch loss:0.07048679143190384, Training time:11270.934991121292
batch reward last col mean 0.91319340467453 first col mean 0.9124099016189575 all mean 0.9135479927062988
0.07443446666002274 0.07443445175886154
rl training, epoch0, iter0, batch517/1133, batch loss:0.07443445175886154, Training time:11298.324565887451
batch reward last col mean 0.8681600093841553 first col mean 0.8700219988822937 all mean 0.8638405799865723
0.08044786006212234 0.08044784516096115
rl training, epoch0, iter0, batch518/1133, batch loss:0.08044784516096115, Training time:11326.04236984253
batch reward last col mean 0.8771975040435791 first col mean 0.8700169920921326 all mean 0.8716850876808167
0.06822296231985092 0.06822295486927032
rl training, epoch0, iter0, batch519/1133, batch loss:0.06822295486927032, Training time:11353.185754776001
batch reward last col mean 0.8565245866775513 first col mean 0.8791062831878662 all mean 0.8635929226875305
0.07275150716304779 0.072751484811306
rl training, epoch0, iter0, batch520/1133, batch loss:0.072751484811306, Training time:11380.92394065857
batch reward last col mean 0.8733841180801392 first col mean 0.8843418955802917 all mean 0.8721879720687866
0.07074636965990067 0.07074636220932007
rl training, epoch0, iter0, batch521/1133, batch loss:0.07074636220932007, Training time:11408.599598169327
batch reward last col mean 0.8952274918556213 first col mean 0.910425066947937 all mean 0.8971315026283264
0.07892334461212158 0.07892332226037979
rl training, epoch0, iter0, batch522/1133, batch loss:0.07892332226037979, Training time:11436.3039290905
batch reward last col mean 0.873416006565094 first col mean 0.8734481930732727 all mean 0.8804594278335571
0.07261808216571808 0.07261806726455688
rl training, epoch0, iter0, batch523/1133, batch loss:0.07261806726455688, Training time:11464.28157377243
batch reward last col mean 0.8900918960571289 first col mean 0.8990361094474792 all mean 0.8896331787109375
0.07796039432287216 0.07796037197113037
rl training, epoch0, iter0, batch524/1133, batch loss:0.07796037197113037, Training time:11492.098633050919
batch reward last col mean 0.8913756012916565 first col mean 0.8990472555160522 all mean 0.898255467414856
0.08389009535312653 0.08389008045196533
rl training, epoch0, iter0, batch525/1133, batch loss:0.08389008045196533, Training time:11520.3379175663
batch reward last col mean 0.9065036177635193 first col mean 0.9029825329780579 all mean 0.9021667242050171
0.09221939742565155 0.09221938252449036
rl training, epoch0, iter0, batch526/1133, batch loss:0.09221938252449036, Training time:11547.856792211533
batch reward last col mean 0.8774985074996948 first col mean 0.8948938846588135 all mean 0.8871158361434937
0.07555510103702545 0.07555508613586426
rl training, epoch0, iter0, batch527/1133, batch loss:0.07555508613586426, Training time:11575.585118055344
batch reward last col mean 0.8812902569770813 first col mean 0.8765770196914673 all mean 0.887540876865387
0.09128458052873611 0.09128456562757492
rl training, epoch0, iter0, batch528/1133, batch loss:0.09128456562757492, Training time:11603.225453138351
batch reward last col mean 0.8771795630455017 first col mean 0.8844155669212341 all mean 0.8772775530815125
0.08699292689561844 0.08699291944503784
rl training, epoch0, iter0, batch529/1133, batch loss:0.08699291944503784, Training time:11630.795074939728
batch reward last col mean 0.8575724363327026 first col mean 0.8853979110717773 all mean 0.8736224174499512
0.09175807237625122 0.09175806492567062
rl training, epoch0, iter0, batch530/1133, batch loss:0.09175806492567062, Training time:11658.828217029572
batch reward last col mean 0.8918595910072327 first col mean 0.8943814039230347 all mean 0.8969531059265137
0.09939266741275787 0.09939265996217728
rl training, epoch0, iter0, batch531/1133, batch loss:0.09939265996217728, Training time:11686.20772767067
batch reward last col mean 0.8911305665969849 first col mean 0.8993552923202515 all mean 0.9016205072402954
0.10807044059038162 0.10807043313980103
rl training, epoch0, iter0, batch532/1133, batch loss:0.10807043313980103, Training time:11713.874552249908
batch reward last col mean 0.9236504435539246 first col mean 0.9161093235015869 all mean 0.9147010445594788
0.12119241803884506 0.12119241058826447
rl training, epoch0, iter0, batch533/1133, batch loss:0.12119241058826447, Training time:11741.789306402206
batch reward last col mean 0.8876571655273438 first col mean 0.8895355463027954 all mean 0.8894069790840149
0.11281655728816986 0.11281654983758926
rl training, epoch0, iter0, batch534/1133, batch loss:0.11281654983758926, Training time:11769.673147678375
batch reward last col mean 0.8628903031349182 first col mean 0.8856619000434875 all mean 0.8633735775947571
0.12303028255701065 0.12303026765584946
rl training, epoch0, iter0, batch535/1133, batch loss:0.12303026765584946, Training time:11797.711520910263
batch reward last col mean 0.9146802425384521 first col mean 0.88695228099823 all mean 0.9112103581428528
0.1241542175412178 0.12415420264005661
rl training, epoch0, iter0, batch536/1133, batch loss:0.12415420264005661, Training time:11825.606254577637
batch reward last col mean 0.8767716288566589 first col mean 0.8883152008056641 all mean 0.8785853385925293
0.11565359681844711 0.11565356701612473
rl training, epoch0, iter0, batch537/1133, batch loss:0.11565356701612473, Training time:11852.91409277916
batch reward last col mean 0.8771408796310425 first col mean 0.8765295743942261 all mean 0.875663697719574
0.12847788631916046 0.12847787141799927
rl training, epoch0, iter0, batch538/1133, batch loss:0.12847787141799927, Training time:11880.539631128311
batch reward last col mean 0.878587007522583 first col mean 0.8987559676170349 all mean 0.8917067050933838
0.11260875314474106 0.11260872334241867
rl training, epoch0, iter0, batch539/1133, batch loss:0.11260872334241867, Training time:11908.604517936707
batch reward last col mean 0.8816072344779968 first col mean 0.8702989220619202 all mean 0.8744524717330933
0.10443658381700516 0.10443656891584396
rl training, epoch0, iter0, batch540/1133, batch loss:0.10443656891584396, Training time:11936.004722833633
batch reward last col mean 0.8981702923774719 first col mean 0.8937192559242249 all mean 0.8907634019851685
0.10417737066745758 0.10417735576629639
rl training, epoch0, iter0, batch541/1133, batch loss:0.10417735576629639, Training time:11963.586948871613
batch reward last col mean 0.9165866374969482 first col mean 0.9139639139175415 all mean 0.9230448603630066
0.1170962005853653 0.1170961782336235
rl training, epoch0, iter0, batch542/1133, batch loss:0.1170961782336235, Training time:11991.273694038391
batch reward last col mean 0.9054156541824341 first col mean 0.8992229700088501 all mean 0.8992639183998108
0.10945127159357071 0.10945125669240952
rl training, epoch0, iter0, batch543/1133, batch loss:0.10945125669240952, Training time:12018.66840004921
batch reward last col mean 0.8938109278678894 first col mean 0.894269585609436 all mean 0.9039996862411499
0.12164654582738876 0.12164652347564697
rl training, epoch0, iter0, batch544/1133, batch loss:0.12164652347564697, Training time:12046.805911302567
batch reward last col mean 0.9235652089118958 first col mean 0.9070799946784973 all mean 0.9100859761238098
0.12160248309373856 0.12160247564315796
rl training, epoch0, iter0, batch545/1133, batch loss:0.12160247564315796, Training time:12074.465067625046
batch reward last col mean 0.910004734992981 first col mean 0.9094717502593994 all mean 0.9131574630737305
0.13333037495613098 0.1333303600549698
rl training, epoch0, iter0, batch546/1133, batch loss:0.1333303600549698, Training time:12102.220123529434
batch reward last col mean 0.8765519857406616 first col mean 0.8882029056549072 all mean 0.8747056722640991
0.13110698759555817 0.13110695779323578
rl training, epoch0, iter0, batch547/1133, batch loss:0.13110695779323578, Training time:12129.57329416275
batch reward last col mean 0.923558235168457 first col mean 0.9216002225875854 all mean 0.9109057784080505
0.15488886833190918 0.15488885343074799
rl training, epoch0, iter0, batch548/1133, batch loss:0.15488885343074799, Training time:12157.487047672272
batch reward last col mean 0.8771693110466003 first col mean 0.8810737133026123 all mean 0.8807257413864136
0.15943005681037903 0.15943005681037903
rl training, epoch0, iter0, batch549/1133, batch loss:0.15943005681037903, Training time:12185.637016773224
batch reward last col mean 0.8868159651756287 first col mean 0.8962012529373169 all mean 0.8803579807281494
0.17801934480667114 0.17801931500434875
rl training, epoch0, iter0, batch550/1133, batch loss:0.17801931500434875, Training time:12213.291490077972
batch reward last col mean 0.9078580141067505 first col mean 0.895131528377533 all mean 0.8931858539581299
0.20529188215732574 0.20529186725616455
rl training, epoch0, iter0, batch551/1133, batch loss:0.20529186725616455, Training time:12241.109266281128
batch reward last col mean 0.8972711563110352 first col mean 0.907622218132019 all mean 0.8958143591880798
0.21891821920871735 0.21891818940639496
rl training, epoch0, iter0, batch552/1133, batch loss:0.21891818940639496, Training time:12268.373378276825
batch reward last col mean 0.8979217410087585 first col mean 0.9000952243804932 all mean 0.9006413817405701
0.26361122727394104 0.26361119747161865
rl training, epoch0, iter0, batch553/1133, batch loss:0.26361119747161865, Training time:12296.067806482315
batch reward last col mean 0.9167792797088623 first col mean 0.9210309386253357 all mean 0.9206759333610535
0.2996559739112854 0.299655944108963
rl training, epoch0, iter0, batch554/1133, batch loss:0.299655944108963, Training time:12324.016989707947
batch reward last col mean 0.9128080606460571 first col mean 0.8952604532241821 all mean 0.9013590216636658
0.32169628143310547 0.32169628143310547
rl training, epoch0, iter0, batch555/1133, batch loss:0.32169628143310547, Training time:12351.28501367569
batch reward last col mean 0.8691965341567993 first col mean 0.8714746832847595 all mean 0.8607884645462036
0.29516369104385376 0.29516369104385376
rl training, epoch0, iter0, batch556/1133, batch loss:0.29516369104385376, Training time:12378.954096078873
batch reward last col mean 0.9098675847053528 first col mean 0.910820722579956 all mean 0.9160314798355103
0.2803029417991638 0.2803029417991638
rl training, epoch0, iter0, batch557/1133, batch loss:0.2803029417991638, Training time:12406.857348442078
batch reward last col mean 0.8971654176712036 first col mean 0.9145718812942505 all mean 0.914950430393219
0.20944610238075256 0.20944607257843018
rl training, epoch0, iter0, batch558/1133, batch loss:0.20944607257843018, Training time:12434.396194696426
batch reward last col mean 0.923064112663269 first col mean 0.9149778485298157 all mean 0.9225658178329468
0.17158308625221252 0.17158304154872894
rl training, epoch0, iter0, batch559/1133, batch loss:0.17158304154872894, Training time:12461.811158657074
batch reward last col mean 0.8750618696212769 first col mean 0.8929529190063477 all mean 0.8818774223327637
0.12443538755178452 0.12443537265062332
rl training, epoch0, iter0, batch560/1133, batch loss:0.12443537265062332, Training time:12490.148711204529
batch reward last col mean 0.8969078063964844 first col mean 0.9125425815582275 all mean 0.9011566638946533
0.1040787473320961 0.10407872498035431
rl training, epoch0, iter0, batch561/1133, batch loss:0.10407872498035431, Training time:12518.132493972778
batch reward last col mean 0.9238234758377075 first col mean 0.9261557459831238 all mean 0.9266887903213501
0.10056354850530624 0.10056354105472565
rl training, epoch0, iter0, batch562/1133, batch loss:0.10056354105472565, Training time:12545.58125424385
batch reward last col mean 0.9332292079925537 first col mean 0.9110812544822693 all mean 0.9238392114639282
0.09915055334568024 0.09915053099393845
rl training, epoch0, iter0, batch563/1133, batch loss:0.09915053099393845, Training time:12573.4757437706
batch reward last col mean 0.9097594618797302 first col mean 0.9163036346435547 all mean 0.9098376631736755
0.09324438869953156 0.09324436634778976
rl training, epoch0, iter0, batch564/1133, batch loss:0.09324436634778976, Training time:12601.20578289032
batch reward last col mean 0.8794189691543579 first col mean 0.8924650549888611 all mean 0.884742021560669
0.08804267644882202 0.08804267644882202
rl training, epoch0, iter0, batch565/1133, batch loss:0.08804267644882202, Training time:12629.030864238739
batch reward last col mean 0.9038793444633484 first col mean 0.9052601456642151 all mean 0.9041653871536255
0.0875210165977478 0.08752098679542542
rl training, epoch0, iter0, batch566/1133, batch loss:0.08752098679542542, Training time:12656.874259710312
batch reward last col mean 0.926659882068634 first col mean 0.9134439826011658 all mean 0.9269621968269348
0.09282528609037399 0.0928252637386322
rl training, epoch0, iter0, batch567/1133, batch loss:0.0928252637386322, Training time:12684.53348660469
batch reward last col mean 0.9091073274612427 first col mean 0.9260011315345764 all mean 0.8997523784637451
0.0768522173166275 0.07685220241546631
rl training, epoch0, iter0, batch568/1133, batch loss:0.07685220241546631, Training time:12712.033328771591
batch reward last col mean 0.9104833006858826 first col mean 0.8929409980773926 all mean 0.9083281755447388
0.07474229484796524 0.07474227994680405
rl training, epoch0, iter0, batch569/1133, batch loss:0.07474227994680405, Training time:12739.84466290474
batch reward last col mean 0.911949872970581 first col mean 0.8943735957145691 all mean 0.913766086101532
0.07623859494924545 0.07623858004808426
rl training, epoch0, iter0, batch570/1133, batch loss:0.07623858004808426, Training time:12767.58763051033
batch reward last col mean 0.8804082870483398 first col mean 0.9035316705703735 all mean 0.8845774531364441
0.08258961886167526 0.08258961141109467
rl training, epoch0, iter0, batch571/1133, batch loss:0.08258961141109467, Training time:12795.325306653976
batch reward last col mean 0.9114876985549927 first col mean 0.9195983409881592 all mean 0.9119833707809448
0.08263874799013138 0.08263873308897018
rl training, epoch0, iter0, batch572/1133, batch loss:0.08263873308897018, Training time:12824.030893802643
batch reward last col mean 0.9244070053100586 first col mean 0.9104750156402588 all mean 0.9233173131942749
0.07100673764944077 0.07100671529769897
rl training, epoch0, iter0, batch573/1133, batch loss:0.07100671529769897, Training time:12851.644710302353
batch reward last col mean 0.9168536067008972 first col mean 0.9183057546615601 all mean 0.9155595302581787
0.06744760274887085 0.06744758784770966
rl training, epoch0, iter0, batch574/1133, batch loss:0.06744758784770966, Training time:12879.365302324295
batch reward last col mean 0.9315246343612671 first col mean 0.925849437713623 all mean 0.9323499202728271
0.0771298035979271 0.0771297961473465
rl training, epoch0, iter0, batch575/1133, batch loss:0.0771297961473465, Training time:12907.168453216553
batch reward last col mean 0.9205094575881958 first col mean 0.9215760231018066 all mean 0.9187732934951782
0.07566098868846893 0.07566097378730774
rl training, epoch0, iter0, batch576/1133, batch loss:0.07566097378730774, Training time:12934.792105674744
batch reward last col mean 0.8864939212799072 first col mean 0.8931230306625366 all mean 0.8882346153259277
0.06950535625219345 0.06950534880161285
rl training, epoch0, iter0, batch577/1133, batch loss:0.06950534880161285, Training time:12962.21100306511
batch reward last col mean 0.902930736541748 first col mean 0.8882266879081726 all mean 0.9012330770492554
0.06596748530864716 0.06596747040748596
rl training, epoch0, iter0, batch578/1133, batch loss:0.06596747040748596, Training time:12989.703659534454
batch reward last col mean 0.9129378199577332 first col mean 0.916815996170044 all mean 0.9148851037025452
0.06550388038158417 0.06550386548042297
rl training, epoch0, iter0, batch579/1133, batch loss:0.06550386548042297, Training time:13017.165622711182
batch reward last col mean 0.9135841727256775 first col mean 0.9425466656684875 all mean 0.9197117686271667
0.0764351561665535 0.0764351487159729
rl training, epoch0, iter0, batch580/1133, batch loss:0.0764351487159729, Training time:13045.531913995743
batch reward last col mean 0.8935432434082031 first col mean 0.9053375720977783 all mean 0.8971127867698669
0.06850741058588028 0.06850740313529968
rl training, epoch0, iter0, batch581/1133, batch loss:0.06850740313529968, Training time:13073.162193536758
batch reward last col mean 0.8607419729232788 first col mean 0.9043236970901489 all mean 0.8693652749061584
0.06997667998075485 0.06997666507959366
rl training, epoch0, iter0, batch582/1133, batch loss:0.06997666507959366, Training time:13100.696756839752
batch reward last col mean 0.9454402923583984 first col mean 0.9365171790122986 all mean 0.9440183043479919
0.06790142506361008 0.06790141761302948
rl training, epoch0, iter0, batch583/1133, batch loss:0.06790141761302948, Training time:13129.092388391495
batch reward last col mean 0.9248786568641663 first col mean 0.9194493889808655 all mean 0.9228807091712952
0.06762053817510605 0.06762053072452545
rl training, epoch0, iter0, batch584/1133, batch loss:0.06762053072452545, Training time:13157.762102842331
batch reward last col mean 0.9321538209915161 first col mean 0.9429199695587158 all mean 0.9324229955673218
0.07225164771080017 0.07225164026021957
rl training, epoch0, iter0, batch585/1133, batch loss:0.07225164026021957, Training time:13186.069219112396
batch reward last col mean 0.9270887970924377 first col mean 0.9217965006828308 all mean 0.9296095967292786
0.06263744831085205 0.06263742595911026
rl training, epoch0, iter0, batch586/1133, batch loss:0.06263742595911026, Training time:13213.694982767105
batch reward last col mean 0.8976577520370483 first col mean 0.9231192469596863 all mean 0.8973117470741272
0.06423620134592056 0.06423619389533997
rl training, epoch0, iter0, batch587/1133, batch loss:0.06423619389533997, Training time:13241.359703302383
batch reward last col mean 0.9212300777435303 first col mean 0.915580689907074 all mean 0.9233472347259521
0.06929684430360794 0.06929682940244675
rl training, epoch0, iter0, batch588/1133, batch loss:0.06929682940244675, Training time:13268.760164022446
batch reward last col mean 0.9054558277130127 first col mean 0.9225122928619385 all mean 0.9027962684631348
0.07273181527853012 0.07273180782794952
rl training, epoch0, iter0, batch589/1133, batch loss:0.07273180782794952, Training time:13296.52483677864
batch reward last col mean 0.9243004322052002 first col mean 0.9202210903167725 all mean 0.9183312058448792
0.06640125066041946 0.06640122830867767
rl training, epoch0, iter0, batch590/1133, batch loss:0.06640122830867767, Training time:13324.086436986923
batch reward last col mean 0.9241967797279358 first col mean 0.9305963516235352 all mean 0.9266728758811951
0.07216240465641022 0.07216239720582962
rl training, epoch0, iter0, batch591/1133, batch loss:0.07216239720582962, Training time:13351.241426944733
batch reward last col mean 0.8998223543167114 first col mean 0.9110031127929688 all mean 0.9030497670173645
0.07759024202823639 0.07759024202823639
rl training, epoch0, iter0, batch592/1133, batch loss:0.07759024202823639, Training time:13378.38882780075
batch reward last col mean 0.9204436540603638 first col mean 0.9217120409011841 all mean 0.9208027124404907
0.07030260562896729 0.07030259817838669
rl training, epoch0, iter0, batch593/1133, batch loss:0.07030259817838669, Training time:13405.937304496765
batch reward last col mean 0.9418447613716125 first col mean 0.9310373067855835 all mean 0.9380252957344055
0.08304264396429062 0.08304262906312943
rl training, epoch0, iter0, batch594/1133, batch loss:0.08304262906312943, Training time:13433.374789237976
batch reward last col mean 0.9185019135475159 first col mean 0.92710280418396 all mean 0.9140588045120239
0.07349462062120438 0.07349460572004318
rl training, epoch0, iter0, batch595/1133, batch loss:0.07349460572004318, Training time:13461.032413959503
batch reward last col mean 0.9215818643569946 first col mean 0.9102489352226257 all mean 0.9290534853935242
0.0811406746506691 0.0811406597495079
rl training, epoch0, iter0, batch596/1133, batch loss:0.0811406597495079, Training time:13488.765480995178
batch reward last col mean 0.8941614627838135 first col mean 0.9310131669044495 all mean 0.9028056859970093
0.08374501019716263 0.08374501019716263
rl training, epoch0, iter0, batch597/1133, batch loss:0.08374501019716263, Training time:13516.188264369965
batch reward last col mean 0.9123724699020386 first col mean 0.9174338579177856 all mean 0.9135604500770569
0.07717207074165344 0.07717206329107285
rl training, epoch0, iter0, batch598/1133, batch loss:0.07717206329107285, Training time:13543.740881681442
batch reward last col mean 0.9453309178352356 first col mean 0.9427831172943115 all mean 0.9399139881134033
0.08490737527608871 0.08490736782550812
rl training, epoch0, iter0, batch599/1133, batch loss:0.08490736782550812, Training time:13571.772592067719
batch reward last col mean 0.9225479364395142 first col mean 0.9204949140548706 all mean 0.9128623008728027
0.08560493588447571 0.08560492843389511
rl training, epoch0, iter0, batch600/1133, batch loss:0.08560492843389511, Training time:13599.718606710434
batch reward last col mean 0.9199249744415283 first col mean 0.94668048620224 all mean 0.9285708069801331
0.07974858582019806 0.07974858582019806
rl training, epoch0, iter0, batch601/1133, batch loss:0.07974858582019806, Training time:13627.536134004593
batch reward last col mean 0.9294084906578064 first col mean 0.9369076490402222 all mean 0.9354861974716187
0.07504662126302719 0.0750466138124466
rl training, epoch0, iter0, batch602/1133, batch loss:0.0750466138124466, Training time:13655.04105758667
batch reward last col mean 0.9076634049415588 first col mean 0.9359060525894165 all mean 0.9207398295402527
0.06450307369232178 0.06450305879116058
rl training, epoch0, iter0, batch603/1133, batch loss:0.06450305879116058, Training time:13682.519441127777
batch reward last col mean 0.9147148728370667 first col mean 0.9382905960083008 all mean 0.921173095703125
0.0672229677438736 0.067222960293293
rl training, epoch0, iter0, batch604/1133, batch loss:0.067222960293293, Training time:13709.844923734665
batch reward last col mean 0.9635410308837891 first col mean 0.9508184790611267 all mean 0.962445855140686
0.061423927545547485 0.06142391636967659
rl training, epoch0, iter0, batch605/1133, batch loss:0.06142391636967659, Training time:13737.527463197708
RL early break
rl training, epoch 0, iter 0, loss:0.2626329105986719, Training time:13737.53113436699 
rl epoch 0, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.24078350405012308 Time: 183.44137716293335 s
cur_epoch: 1
D Training Loss: 0.2459946091024621 Time: 194.27616214752197 s
cur_epoch: 2
D Training Loss: 0.24658546535608944 Time: 194.73980045318604 s
cur_epoch: 3
D Training Loss: 0.2467741592271814 Time: 197.47359418869019 s
cur_epoch: 4
D Training Loss: 0.2456291674752206 Time: 196.7913944721222 s
rl epoch 1, begin RL for generator...
batch reward last col mean 2.651590724767061e-09 first col mean 2.1510526693191423e-09 all mean 9.963430784409866e-06
5.0577373400528813e-08 5.057734497881938e-08
rl training, epoch1, iter0, batch0/1133, batch loss:5.057734497881938e-08, Training time:14731.577961444855
batch reward last col mean 6.283736309065091e-10 first col mean 3.931791003886076e-10 all mean 1.115114489635971e-08
3.883763796674877e-11 3.883460220066581e-11
rl training, epoch1, iter0, batch1/1133, batch loss:3.883460220066581e-11, Training time:14758.99020767212
batch reward last col mean 6.250403750129863e-09 first col mean 3.4738893983643493e-09 all mean 1.9192257241229527e-06
5.8500089217261575e-09 5.8500830846242025e-09
rl training, epoch1, iter0, batch2/1133, batch loss:5.8500830846242025e-09, Training time:14786.497027635574
batch reward last col mean 1.070243005329985e-09 first col mean 1.0608316447502375e-09 all mean 9.033784387213473e-09
7.979939625757382e-11 7.979590599394015e-11
rl training, epoch1, iter0, batch3/1133, batch loss:7.979590599394015e-11, Training time:14814.621576309204
batch reward last col mean 4.027420175134466e-09 first col mean 1.6077611464382358e-09 all mean 3.361637412879759e-09
2.085490807823831e-10 2.085494554826539e-10
rl training, epoch1, iter0, batch4/1133, batch loss:2.085494554826539e-10, Training time:14841.868201732635
batch reward last col mean 3.212007770869718e-09 first col mean 2.9041635762894202e-09 all mean 2.0051950855304312e-07
4.96436996400007e-07 4.96436996400007e-07
rl training, epoch1, iter0, batch5/1133, batch loss:4.96436996400007e-07, Training time:14869.929193019867
batch reward last col mean 1.8534789258950468e-09 first col mean 1.7967811682950696e-09 all mean 1.0721107557287723e-08
6.681116077045246e-11 6.68103350420779e-11
rl training, epoch1, iter0, batch6/1133, batch loss:6.68103350420779e-11, Training time:14897.518711328506
batch reward last col mean 8.756964597900208e-10 first col mean 1.6175720762845458e-09 all mean 4.643859075059709e-09
5.305535524802174e-11 5.3053051535245643e-11
rl training, epoch1, iter0, batch7/1133, batch loss:5.3053051535245643e-11, Training time:14925.076312065125
batch reward last col mean 5.5759441508485e-10 first col mean 6.896125337441106e-10 all mean 3.001809689706647e-09
2.924929048964131e-11 2.925019601529577e-11
rl training, epoch1, iter0, batch8/1133, batch loss:2.925019601529577e-11, Training time:14952.913261413574
batch reward last col mean 2.1383603776570226e-09 first col mean 2.9503697263066897e-09 all mean 3.9236238080775365e-05
8.222394535550848e-05 8.22239599074237e-05
rl training, epoch1, iter0, batch9/1133, batch loss:8.22239599074237e-05, Training time:14980.473326444626
batch reward last col mean 9.531364586479185e-10 first col mean 7.588458195151304e-10 all mean 2.259815346405958e-06
2.6296104849166113e-08 2.629717954505395e-08
rl training, epoch1, iter0, batch10/1133, batch loss:2.629717954505395e-08, Training time:15008.404012680054
batch reward last col mean 9.071789541792441e-09 first col mean 7.0550063568930454e-09 all mean 2.0261455574654974e-05
3.0162706025294028e-05 3.016270238731522e-05
rl training, epoch1, iter0, batch11/1133, batch loss:3.016270238731522e-05, Training time:15035.74992775917
batch reward last col mean 3.0595104227870706e-09 first col mean 3.2773259661667e-09 all mean 3.079063670696769e-09
2.3917018365793297e-10 2.391702114135086e-10
rl training, epoch1, iter0, batch12/1133, batch loss:2.391702114135086e-10, Training time:15063.787814378738
batch reward last col mean 1.495381152238906e-09 first col mean 1.3279848332103938e-09 all mean 5.9270576002745656e-08
1.2883678845998503e-10 1.2884211753050323e-10
rl training, epoch1, iter0, batch13/1133, batch loss:1.2884211753050323e-10, Training time:15091.240780591965
batch reward last col mean 1.098537039112557e-09 first col mean 8.001685425362837e-10 all mean 2.2097217424743576e-06
1.1903951602221241e-08 1.1902992369527965e-08
rl training, epoch1, iter0, batch14/1133, batch loss:1.1902992369527965e-08, Training time:15118.685222864151
batch reward last col mean 1.4315728602554145e-09 first col mean 1.190303411391369e-09 all mean 1.7899070371640846e-05
1.5842159939438716e-07 1.5842749689909397e-07
rl training, epoch1, iter0, batch15/1133, batch loss:1.5842749689909397e-07, Training time:15146.488730669022
batch reward last col mean 1.8133031742806338e-09 first col mean 1.3529726228256322e-09 all mean 5.23350490766461e-06
6.464206308010034e-06 6.4642094912414905e-06
rl training, epoch1, iter0, batch16/1133, batch loss:6.4642094912414905e-06, Training time:15174.337893009186
batch reward last col mean 1.7760356518792264e-09 first col mean 2.9087592334775536e-09 all mean 2.394690890028528e-09
1.0634958885757939e-10 1.0634992886338068e-10
rl training, epoch1, iter0, batch17/1133, batch loss:1.0634992886338068e-10, Training time:15202.151983976364
batch reward last col mean 2.9699327441790047e-09 first col mean 1.6493145738039061e-09 all mean 2.029940515058115e-05
2.0507275166892214e-07 2.050659873020777e-07
rl training, epoch1, iter0, batch18/1133, batch loss:2.050659873020777e-07, Training time:15229.530529022217
batch reward last col mean 8.135564222300218e-09 first col mean 6.9216588016729474e-09 all mean 2.5835007022578793e-08
2.8799335138884885e-10 2.8798854967426735e-10
rl training, epoch1, iter0, batch19/1133, batch loss:2.8798854967426735e-10, Training time:15257.407091379166
batch reward last col mean 9.859357774644195e-10 first col mean 1.711328190268091e-09 all mean 6.855941023786727e-07
5.818533281853888e-07 5.818533281853888e-07
rl training, epoch1, iter0, batch20/1133, batch loss:5.818533281853888e-07, Training time:15285.224631786346
batch reward last col mean 8.028731013354218e-10 first col mean 3.5910283635587348e-09 all mean 1.2743339539156295e-05
1.2470013643905986e-07 1.2469537580273027e-07
rl training, epoch1, iter0, batch21/1133, batch loss:1.2469537580273027e-07, Training time:15313.109894990921
batch reward last col mean 1.7104409000268106e-09 first col mean 7.451318673190599e-09 all mean 2.019714617773616e-09
1.0535755601281949e-10 1.0535755601281949e-10
rl training, epoch1, iter0, batch22/1133, batch loss:1.0535755601281949e-10, Training time:15341.041193723679
batch reward last col mean 9.634040232242569e-10 first col mean 1.1700431734595895e-09 all mean 1.5624472826658575e-09
1.6733697760784594e-09 1.673369665056157e-09
rl training, epoch1, iter0, batch23/1133, batch loss:1.673369665056157e-09, Training time:15368.597362041473
batch reward last col mean 6.645189953857766e-10 first col mean 1.019549888958693e-09 all mean 1.8339990504046e-07
4.521112089150847e-07 4.52111095228247e-07
rl training, epoch1, iter0, batch24/1133, batch loss:4.52111095228247e-07, Training time:15396.333672761917
batch reward last col mean 4.8464459112551594e-09 first col mean 8.425399045108861e-09 all mean 6.6212860474479385e-06
8.753161750973959e-08 8.75295214086691e-08
rl training, epoch1, iter0, batch25/1133, batch loss:8.75295214086691e-08, Training time:15424.062022209167
batch reward last col mean 8.165433884599338e-10 first col mean 7.804945578726574e-10 all mean 3.6707257233814516e-09
6.704637539600711e-11 6.704670152402059e-11
rl training, epoch1, iter0, batch26/1133, batch loss:6.704670152402059e-11, Training time:15451.584990978241
batch reward last col mean 4.565236189080224e-09 first col mean 3.908007695230253e-09 all mean 2.9732204254173666e-08
2.103999335867357e-10 2.1038333575251755e-10
rl training, epoch1, iter0, batch27/1133, batch loss:2.1038333575251755e-10, Training time:15478.972439289093
batch reward last col mean 1.9453323396589894e-09 first col mean 2.3998492082455414e-09 all mean 2.927408981889812e-09
3.177753338245992e-10 3.1777488973538937e-10
rl training, epoch1, iter0, batch28/1133, batch loss:3.1777488973538937e-10, Training time:15506.900347709656
batch reward last col mean 1.4795272784695612e-09 first col mean 2.917430075299876e-09 all mean 2.984020808227683e-09
1.053190451516528e-10 1.0531874677921493e-10
rl training, epoch1, iter0, batch29/1133, batch loss:1.0531874677921493e-10, Training time:15534.648906946182
batch reward last col mean 2.8416677899656406e-09 first col mean 2.2771602381510547e-09 all mean 3.1105786835183835e-09
6.884792735917244e-11 6.884752490332602e-11
rl training, epoch1, iter0, batch30/1133, batch loss:6.884752490332602e-11, Training time:15562.677125692368
batch reward last col mean 3.741383203248461e-09 first col mean 3.0713427356943157e-09 all mean 4.144397735217353e-06
4.879583670458487e-08 4.8795644858046217e-08
rl training, epoch1, iter0, batch31/1133, batch loss:4.8795644858046217e-08, Training time:15590.2679104805
batch reward last col mean 2.0503676534389115e-09 first col mean 1.5711727474609916e-09 all mean 2.395185383363696e-09
6.334709840016828e-11 6.334682084441212e-11
rl training, epoch1, iter0, batch32/1133, batch loss:6.334682084441212e-11, Training time:15617.825905561447
batch reward last col mean 1.7930622320250222e-08 first col mean 2.74250169240986e-06 all mean 1.9755376342800446e-05
1.0838760317710694e-05 1.083876850316301e-05
rl training, epoch1, iter0, batch33/1133, batch loss:1.083876850316301e-05, Training time:15645.589612722397
batch reward last col mean 1.7650747530240096e-09 first col mean 8.892081515554651e-10 all mean 1.0961979569401592e-05
3.746459924514056e-06 3.7464565139089245e-06
rl training, epoch1, iter0, batch34/1133, batch loss:3.7464565139089245e-06, Training time:15673.482593536377
batch reward last col mean 6.860959578247616e-10 first col mean 1.3359068296026066e-09 all mean 1.499825486028783e-09
3.847875837403869e-11 3.8478692454546604e-11
rl training, epoch1, iter0, batch35/1133, batch loss:3.8478692454546604e-11, Training time:15701.07424902916
batch reward last col mean 9.59168300340707e-10 first col mean 3.814781823763269e-10 all mean 3.1271710554392484e-08
3.937433018519343e-11 3.9360455866832567e-11
rl training, epoch1, iter0, batch36/1133, batch loss:3.9360455866832567e-11, Training time:15728.884397983551
batch reward last col mean 1.1809928590622576e-09 first col mean 0.001816987176425755 all mean 1.8369870304013602e-05
4.438732617018104e-07 4.4386939634932787e-07
rl training, epoch1, iter0, batch37/1133, batch loss:4.4386939634932787e-07, Training time:15756.52485370636
batch reward last col mean 1.462158172316208e-09 first col mean 0.0013183519477024674 all mean 1.3351873349165544e-05
3.69311976555764e-07 3.693083385769569e-07
rl training, epoch1, iter0, batch38/1133, batch loss:3.693083385769569e-07, Training time:15784.245622873306
batch reward last col mean 1.0633619318412002e-08 first col mean 7.843545812846742e-10 all mean 1.247311254282124e-09
8.373881033030273e-10 8.373881033030273e-10
rl training, epoch1, iter0, batch39/1133, batch loss:8.373881033030273e-10, Training time:15812.04176235199
batch reward last col mean 0.0010171127505600452 first col mean 7.55849050015911e-10 all mean 0.000965743965934962
6.558436143677682e-05 6.55843541608192e-05
rl training, epoch1, iter0, batch40/1133, batch loss:6.55843541608192e-05, Training time:15839.90019774437
batch reward last col mean 3.763210187912591e-09 first col mean 7.260678280829325e-09 all mean 6.8984884471490204e-09
1.4163795136745705e-10 1.4163867301242306e-10
rl training, epoch1, iter0, batch41/1133, batch loss:1.4163867301242306e-10, Training time:15867.52537035942
batch reward last col mean 1.336153188091771e-09 first col mean 2.4626862771270908e-09 all mean 1.3101584706021185e-08
7.730445450437884e-11 7.730500961589115e-11
rl training, epoch1, iter0, batch42/1133, batch loss:7.730500961589115e-11, Training time:15895.321303367615
batch reward last col mean 1.1673055411165478e-08 first col mean 6.702410626502342e-09 all mean 3.380741020464484e-08
2.9221011721425327e-10 2.922025399421102e-10
rl training, epoch1, iter0, batch43/1133, batch loss:2.922025399421102e-10, Training time:15922.738710165024
batch reward last col mean 9.98612414981892e-10 first col mean 1.6462227137026275e-09 all mean 9.365708137920592e-06
4.776609898726747e-07 4.776650257554138e-07
rl training, epoch1, iter0, batch44/1133, batch loss:4.776650257554138e-07, Training time:15950.433673858643
batch reward last col mean 1.8212654717686405e-09 first col mean 1.4241969825690148e-09 all mean 2.957817546445085e-09
1.242321384653522e-10 1.2423256867677424e-10
rl training, epoch1, iter0, batch45/1133, batch loss:1.2423256867677424e-10, Training time:15978.484961271286
batch reward last col mean 1.9438104459368333e-09 first col mean 1.8495502907001082e-09 all mean 4.409148743889091e-07
1.1920840314871839e-08 1.1920732845283055e-08
rl training, epoch1, iter0, batch46/1133, batch loss:1.1920732845283055e-08, Training time:16006.395133972168
batch reward last col mean 6.218560333337564e-09 first col mean 4.746603554650619e-09 all mean 1.5993295164662413e-05
3.966889835282927e-06 3.966883014072664e-06
rl training, epoch1, iter0, batch47/1133, batch loss:3.966883014072664e-06, Training time:16034.298211574554
batch reward last col mean 1.2397692872312405e-09 first col mean 1.2652368042154194e-09 all mean 4.475245077628642e-06
7.144939900172176e-06 7.144940809666878e-06
rl training, epoch1, iter0, batch48/1133, batch loss:7.144940809666878e-06, Training time:16061.690242290497
batch reward last col mean 3.483682453619963e-09 first col mean 0.0009151902631856501 all mean 9.248043170373421e-06
2.6886977977369497e-08 2.6891546767160435e-08
rl training, epoch1, iter0, batch49/1133, batch loss:2.6891546767160435e-08, Training time:16089.195430994034
batch reward last col mean 9.09381348002114e-10 first col mean 7.926826972592949e-10 all mean 3.887504540500686e-09
7.438658716774071e-11 7.438562266148807e-11
rl training, epoch1, iter0, batch50/1133, batch loss:7.438562266148807e-11, Training time:16116.798039197922
batch reward last col mean 9.267473011220773e-09 first col mean 2.435569612657673e-08 all mean 1.5704925360182642e-08
5.234249145225078e-10 5.234294664369088e-10
rl training, epoch1, iter0, batch51/1133, batch loss:5.234294664369088e-10, Training time:16144.895557641983
batch reward last col mean 3.5734688541566584e-09 first col mean 2.242991570255981e-09 all mean 3.459119657378551e-09
1.7553083986321383e-10 1.7553088149657725e-10
rl training, epoch1, iter0, batch52/1133, batch loss:1.7553088149657725e-10, Training time:16172.772376060486
batch reward last col mean 2.1348620649064287e-09 first col mean 1.4832076677961936e-09 all mean 3.758900302130996e-09
8.203483031765657e-11 8.20347054175663e-11
rl training, epoch1, iter0, batch53/1133, batch loss:8.20347054175663e-11, Training time:16200.008342027664
batch reward last col mean 3.940554549330955e-09 first col mean 3.61378882374197e-09 all mean 2.328704518106406e-08
1.9277428264796725e-10 1.927734777362744e-10
rl training, epoch1, iter0, batch54/1133, batch loss:1.927734777362744e-10, Training time:16227.704855203629
batch reward last col mean 1.5876622239119342e-09 first col mean 2.020913658640211e-09 all mean 1.6859196261265197e-09
1.270683003262718e-10 1.2706831420405962e-10
rl training, epoch1, iter0, batch55/1133, batch loss:1.2706831420405962e-10, Training time:16255.50688290596
batch reward last col mean 1.3998124881453577e-09 first col mean 1.0321697274662256e-08 all mean 2.57383092616692e-09
2.513907970680407e-10 2.5139074155688945e-10
rl training, epoch1, iter0, batch56/1133, batch loss:2.5139074155688945e-10, Training time:16283.587924718857
batch reward last col mean 1.8906098908644253e-09 first col mean 1.6958747739437285e-09 all mean 2.2993216219902024e-08
1.6497576915686096e-10 1.6498433175193838e-10
rl training, epoch1, iter0, batch57/1133, batch loss:1.6498433175193838e-10, Training time:16311.28738951683
batch reward last col mean 9.227142383494424e-10 first col mean 1.347504219317841e-09 all mean 1.712364451122994e-06
2.6826822363545944e-07 2.682679109966557e-07
rl training, epoch1, iter0, batch58/1133, batch loss:2.682679109966557e-07, Training time:16338.992988109589
batch reward last col mean 1.2065349830336913e-09 first col mean 7.267041413072661e-10 all mean 1.3252547947928406e-09
9.14189904333007e-11 9.141903206666413e-11
rl training, epoch1, iter0, batch59/1133, batch loss:9.141903206666413e-11, Training time:16366.476101636887
batch reward last col mean 1.1695443502546254e-09 first col mean 1.3625878203527009e-09 all mean 3.1573545999918906e-09
8.270631401963158e-11 8.270632095852548e-11
rl training, epoch1, iter0, batch60/1133, batch loss:8.270632095852548e-11, Training time:16395.231752872467
batch reward last col mean 7.814637825731552e-10 first col mean 8.557982100754202e-10 all mean 3.5755358567257645e-06
7.55751443648478e-08 7.557453329809505e-08
rl training, epoch1, iter0, batch61/1133, batch loss:7.557453329809505e-08, Training time:16423.818974733353
batch reward last col mean 4.032600919856577e-09 first col mean 6.982025180235496e-09 all mean 6.087218480388401e-07
3.7443839140394175e-09 3.744418108908576e-09
rl training, epoch1, iter0, batch62/1133, batch loss:3.744418108908576e-09, Training time:16452.023068666458
batch reward last col mean 6.423941933952904e-10 first col mean 1.0535252670251793e-09 all mean 1.671425025051576e-06
7.657333185306925e-07 7.657334890609491e-07
rl training, epoch1, iter0, batch63/1133, batch loss:7.657334890609491e-07, Training time:16479.825980186462
batch reward last col mean 1.992785492177518e-09 first col mean 1.7066507096430428e-09 all mean 3.0686808649704744e-09
3.7213340742248135e-10 3.7213340742248135e-10
rl training, epoch1, iter0, batch64/1133, batch loss:3.7213340742248135e-10, Training time:16507.46409678459
batch reward last col mean 6.511867933767235e-09 first col mean 6.455143974903876e-09 all mean 5.053230722751323e-09
3.9173447818896534e-10 3.917342561443604e-10
rl training, epoch1, iter0, batch65/1133, batch loss:3.917342561443604e-10, Training time:16535.24548959732
batch reward last col mean 3.504074364002463e-09 first col mean 3.2015397000151324e-09 all mean 1.2211823552377155e-08
3.951738380969516e-10 3.9517125682841936e-10
rl training, epoch1, iter0, batch66/1133, batch loss:3.9517125682841936e-10, Training time:16563.736572742462
batch reward last col mean 7.560455372868091e-09 first col mean 1.0808797412664717e-08 all mean 1.4022072392094742e-08
2.1373182335082674e-08 2.1373182335082674e-08
rl training, epoch1, iter0, batch67/1133, batch loss:2.1373182335082674e-08, Training time:16592.14460659027
batch reward last col mean 2.4869002412941654e-09 first col mean 1.4927115099538923e-09 all mean 1.762499232427217e-05
2.776891597022768e-05 2.7768914151238278e-05
rl training, epoch1, iter0, batch68/1133, batch loss:2.7768914151238278e-05, Training time:16620.020545721054
batch reward last col mean 6.997008306086627e-09 first col mean 4.019208077465919e-09 all mean 6.899738558274748e-09
1.332278731780434e-10 1.3322788705583122e-10
rl training, epoch1, iter0, batch69/1133, batch loss:1.3322788705583122e-10, Training time:16647.35976099968
batch reward last col mean 1.1606222649618303e-09 first col mean 2.2722652648354824e-09 all mean 3.0253725071816007e-06
8.222757969633676e-06 8.222757969633676e-06
rl training, epoch1, iter0, batch70/1133, batch loss:8.222757969633676e-06, Training time:16675.08797597885
batch reward last col mean 3.841691409434134e-08 first col mean 2.7692359516606757e-09 all mean 1.2247480363214436e-08
2.91535950935895e-09 2.9153581770913206e-09
rl training, epoch1, iter0, batch71/1133, batch loss:2.9153581770913206e-09, Training time:16703.142539978027
batch reward last col mean 7.547645841654571e-10 first col mean 8.874312951157037e-10 all mean 1.0091066870998588e-09
3.704699741424733e-11 3.704696618922476e-11
rl training, epoch1, iter0, batch72/1133, batch loss:3.704696618922476e-11, Training time:16730.743805885315
batch reward last col mean 2.5132862901955377e-08 first col mean 9.554621094309823e-09 all mean 3.075151155940148e-08
8.999088141337097e-10 8.99911756224725e-10
rl training, epoch1, iter0, batch73/1133, batch loss:8.99911756224725e-10, Training time:16759.222202301025
batch reward last col mean 3.0675140205715934e-09 first col mean 2.9596769479667273e-09 all mean 4.518388774243931e-09
3.228155243117925e-10 3.2281577411197304e-10
rl training, epoch1, iter0, batch74/1133, batch loss:3.2281577411197304e-10, Training time:16787.299669504166
batch reward last col mean 3.2370786051671985e-09 first col mean 2.3870743159903896e-09 all mean 8.628076919592331e-09
1.3085833805437375e-10 1.308568392532905e-10
rl training, epoch1, iter0, batch75/1133, batch loss:1.308568392532905e-10, Training time:16814.96763086319
batch reward last col mean 2.3693329520568795e-09 first col mean 2.3320345654553876e-09 all mean 6.269234464895135e-09
1.276563021956889e-10 1.276580785525283e-10
rl training, epoch1, iter0, batch76/1133, batch loss:1.276580785525283e-10, Training time:16842.749889612198
batch reward last col mean 1.1568639379788692e-09 first col mean 1.6043132378129599e-09 all mean 1.365445534418086e-09
1.193839055391166e-10 1.1938386390575317e-10
rl training, epoch1, iter0, batch77/1133, batch loss:1.1938386390575317e-10, Training time:16870.74787092209
batch reward last col mean 8.78587091968086e-10 first col mean 9.710812154395398e-10 all mean 2.2572978650714504e-06
1.2533218018973002e-08 1.2534187021628895e-08
rl training, epoch1, iter0, batch78/1133, batch loss:1.2534187021628895e-08, Training time:16898.348962068558
batch reward last col mean 1.3556827882510447e-09 first col mean 3.6539200554130957e-09 all mean 1.6584783546491622e-09
6.645970579421956e-11 6.64597682442647e-11
rl training, epoch1, iter0, batch79/1133, batch loss:6.64597682442647e-11, Training time:16926.584686756134
batch reward last col mean 6.611208025475435e-09 first col mean 3.040216522975925e-09 all mean 9.941027556692461e-09
3.103100831847172e-10 3.103100554291416e-10
rl training, epoch1, iter0, batch80/1133, batch loss:3.103100554291416e-10, Training time:16954.7409555912
batch reward last col mean 4.6363868300147715e-10 first col mean 5.479400488894726e-09 all mean 2.446149949264509e-09
2.4127779635341184e-11 2.4128723324912116e-11
rl training, epoch1, iter0, batch81/1133, batch loss:2.4128723324912116e-11, Training time:16983.264259815216
batch reward last col mean 3.56736262752122e-09 first col mean 2.3978916630085223e-09 all mean 9.385734855982264e-09
2.2255539633420085e-09 2.2255535192527987e-09
rl training, epoch1, iter0, batch82/1133, batch loss:2.2255535192527987e-09, Training time:17010.705953359604
batch reward last col mean 7.001377255733132e-09 first col mean 3.4911435964346538e-09 all mean 2.281671811488195e-07
3.0883515478308254e-07 3.088351263613731e-07
rl training, epoch1, iter0, batch83/1133, batch loss:3.088351263613731e-07, Training time:17038.34678220749
batch reward last col mean 6.078220149419167e-09 first col mean 5.288455895424704e-09 all mean 9.365356135049296e-08
4.4955181244255016e-10 4.495558370010144e-10
rl training, epoch1, iter0, batch84/1133, batch loss:4.495558370010144e-10, Training time:17066.010823965073
batch reward last col mean 6.267030228102044e-10 first col mean 6.843527966537977e-10 all mean 1.3029278989051818e-06
9.130884492947189e-09 9.130652678379647e-09
rl training, epoch1, iter0, batch85/1133, batch loss:9.130652678379647e-09, Training time:17094.163553476334
batch reward last col mean 1.148747652557347e-09 first col mean 1.8469069607007782e-09 all mean 1.978441188654756e-09
5.457024415678191e-11 5.4570112317797737e-11
rl training, epoch1, iter0, batch86/1133, batch loss:5.4570112317797737e-11, Training time:17121.457271575928
batch reward last col mean 3.2086275858489444e-09 first col mean 0.00045573702664114535 all mean 4.610013547790004e-06
2.1042461995079975e-08 2.1041214992578716e-08
rl training, epoch1, iter0, batch87/1133, batch loss:2.1041214992578716e-08, Training time:17149.815613746643
batch reward last col mean 1.5116456975050596e-09 first col mean 1.3649070762511428e-09 all mean 2.5824433702581473e-09
9.490312008475499e-11 9.490246782872802e-11
rl training, epoch1, iter0, batch88/1133, batch loss:9.490246782872802e-11, Training time:17178.140493392944
batch reward last col mean 9.696781155810186e-10 first col mean 1.018713113865033e-09 all mean 1.8437839344187523e-07
9.62736140808218e-11 9.6300245555625e-11
rl training, epoch1, iter0, batch89/1133, batch loss:9.6300245555625e-11, Training time:17206.138305187225
batch reward last col mean 3.349113875117382e-09 first col mean 0.00030914731905795634 all mean 7.042347533570137e-06
2.4398777895839885e-05 2.439877971482929e-05
rl training, epoch1, iter0, batch90/1133, batch loss:2.439877971482929e-05, Training time:17233.99325275421
batch reward last col mean 5.505547573392278e-09 first col mean 9.24965082305107e-09 all mean 5.722458062962232e-09
1.7195654622437218e-10 1.7195662949109902e-10
rl training, epoch1, iter0, batch91/1133, batch loss:1.7195662949109902e-10, Training time:17261.68614244461
batch reward last col mean 2.538627530412896e-09 first col mean 2.0620967156048664e-09 all mean 6.473290170561086e-08
1.624428508373299e-10 1.6246527734242733e-10
rl training, epoch1, iter0, batch92/1133, batch loss:1.6246527734242733e-10, Training time:17289.690997600555
batch reward last col mean 1.4161792849520793e-09 first col mean 1.590294229636413e-09 all mean 6.791617934709393e-09
9.194938560552757e-11 9.194665168132943e-11
rl training, epoch1, iter0, batch93/1133, batch loss:9.194665168132943e-11, Training time:17317.628010749817
batch reward last col mean 2.277019905960742e-09 first col mean 1.4918222213111676e-09 all mean 1.4082329471420962e-06
3.289810024398321e-07 3.289813150786358e-07
rl training, epoch1, iter0, batch94/1133, batch loss:3.289813150786358e-07, Training time:17345.45937347412
batch reward last col mean 1.3344708671425565e-09 first col mean 2.0331243355542483e-09 all mean 3.5297098577302677e-09
5.8571703043242e-11 5.85709883371699e-11
rl training, epoch1, iter0, batch95/1133, batch loss:5.85709883371699e-11, Training time:17373.838536977768
batch reward last col mean 2.4113608887432747e-09 first col mean 2.7395119506223864e-09 all mean 8.35433183965506e-06
5.189302555663744e-06 5.189304829400498e-06
rl training, epoch1, iter0, batch96/1133, batch loss:5.189304829400498e-06, Training time:17401.86967921257
batch reward last col mean 1.8786967537209875e-09 first col mean 2.913185692676734e-09 all mean 2.6191064872449488e-09
1.0017926072025674e-10 1.0017935092587749e-10
rl training, epoch1, iter0, batch97/1133, batch loss:1.0017935092587749e-10, Training time:17430.078320503235
batch reward last col mean 1.9894312863755204e-09 first col mean 2.82262524464727e-09 all mean 6.323178695311071e-06
4.1310657252324745e-05 4.1310657252324745e-05
rl training, epoch1, iter0, batch98/1133, batch loss:4.1310657252324745e-05, Training time:17457.630063295364
batch reward last col mean 2.280900357476412e-09 first col mean 1.5093432059742895e-09 all mean 4.800193892151583e-06
5.708680873794947e-06 5.7086822380369995e-06
rl training, epoch1, iter0, batch99/1133, batch loss:5.7086822380369995e-06, Training time:17485.1931746006
batch reward last col mean 1.3541676668893388e-09 first col mean 1.4541757797914556e-09 all mean 1.2978431662702405e-08
6.144131037277845e-11 6.145089992415365e-11
rl training, epoch1, iter0, batch100/1133, batch loss:6.145089992415365e-11, Training time:17513.049347639084
batch reward last col mean 2.608036897555621e-09 first col mean 2.213139227436045e-09 all mean 2.58462651281377e-09
1.0980370085400537e-10 1.0980365922064195e-10
rl training, epoch1, iter0, batch101/1133, batch loss:1.0980365922064195e-10, Training time:17540.496982574463
batch reward last col mean 5.5037263635426825e-09 first col mean 4.984154866605195e-09 all mean 7.261705459171708e-09
1.434157098634259e-10 1.4341368370640595e-10
rl training, epoch1, iter0, batch102/1133, batch loss:1.4341368370640595e-10, Training time:17568.38483262062
batch reward last col mean 2.1611010758704197e-09 first col mean 1.8448217398159272e-09 all mean 8.565841369545524e-09
8.196835571405714e-11 8.196503198387717e-11
rl training, epoch1, iter0, batch103/1133, batch loss:8.196503198387717e-11, Training time:17596.16121530533
batch reward last col mean 9.92950832667816e-10 first col mean 8.431448872414649e-10 all mean 6.552544284943451e-09
4.702691708269313e-11 4.702754852203839e-11
rl training, epoch1, iter0, batch104/1133, batch loss:4.702754852203839e-11, Training time:17623.509388446808
batch reward last col mean 2.2298185520241987e-09 first col mean 5.55135981628041e-09 all mean 1.9532315320702764e-08
1.8758065933877077e-10 1.8757598252427954e-10
rl training, epoch1, iter0, batch105/1133, batch loss:1.8757598252427954e-10, Training time:17651.252284526825
batch reward last col mean 1.6973233929462594e-09 first col mean 1.6772987443403053e-09 all mean 3.471677390010086e-09
1.0940088418509575e-10 1.0940077316279329e-10
rl training, epoch1, iter0, batch106/1133, batch loss:1.0940077316279329e-10, Training time:17679.305340528488
batch reward last col mean 8.272923457397496e-10 first col mean 6.527339224682294e-10 all mean 1.8300545434613014e-06
1.168110884464113e-05 1.168110884464113e-05
rl training, epoch1, iter0, batch107/1133, batch loss:1.168110884464113e-05, Training time:17707.275109767914
batch reward last col mean 9.592225902466112e-10 first col mean 9.92285920098368e-10 all mean 1.373261859782815e-08
7.18267598176503e-11 7.183415667855186e-11
rl training, epoch1, iter0, batch108/1133, batch loss:7.183415667855186e-11, Training time:17735.450115442276
batch reward last col mean 5.264215174882736e-10 first col mean 7.458105244495528e-10 all mean 2.271438688694616e-06
1.2331085599726066e-05 1.2331085599726066e-05
rl training, epoch1, iter0, batch109/1133, batch loss:1.2331085599726066e-05, Training time:17763.491666793823
batch reward last col mean 1.4903200895588498e-09 first col mean 9.734646422288051e-10 all mean 1.874951340141706e-05
4.379971869639121e-07 4.3800295657092647e-07
rl training, epoch1, iter0, batch110/1133, batch loss:4.3800295657092647e-07, Training time:17791.582045793533
batch reward last col mean 8.08544520225496e-09 first col mean 4.271899278762703e-09 all mean 1.8365739151704474e-08
6.422221088264735e-10 6.422178899789799e-10
rl training, epoch1, iter0, batch111/1133, batch loss:6.422178899789799e-10, Training time:17819.3660800457
batch reward last col mean 1.0358933710818974e-09 first col mean 1.2942141802696483e-09 all mean 1.4362758760100292e-09
3.338414614195706e-11 3.338410450859364e-11
rl training, epoch1, iter0, batch112/1133, batch loss:3.338410450859364e-11, Training time:17847.40884923935
batch reward last col mean 9.732282757468624e-10 first col mean 0.00025956748868338764 all mean 2.6277496090187924e-06
7.077023411738992e-08 7.076992147858618e-08
rl training, epoch1, iter0, batch113/1133, batch loss:7.076992147858618e-08, Training time:17874.744688272476
batch reward last col mean 2.6227686689139773e-09 first col mean 3.0653548588333024e-09 all mean 2.5331662101280017e-08
2.1697726948488594e-10 2.1697021956867957e-10
rl training, epoch1, iter0, batch114/1133, batch loss:2.1697021956867957e-10, Training time:17902.94789004326
batch reward last col mean 1.8783510302711193e-09 first col mean 1.1141400024783366e-09 all mean 1.9439940768251063e-09
5.7728193753048274e-11 5.772809660853362e-11
rl training, epoch1, iter0, batch115/1133, batch loss:5.772809660853362e-11, Training time:17930.635897636414
batch reward last col mean 8.274785856521305e-10 first col mean 9.52212197979918e-10 all mean 1.5709170838817954e-05
1.7028760339599103e-05 1.7028762158588506e-05
rl training, epoch1, iter0, batch116/1133, batch loss:1.7028762158588506e-05, Training time:17958.203803300858
batch reward last col mean 1.2149440342668072e-09 first col mean 0.00033412588527426124 all mean 1.8276614355272613e-05
6.814205698901787e-05 6.814204971306026e-05
rl training, epoch1, iter0, batch117/1133, batch loss:6.814204971306026e-05, Training time:17985.986911535263
batch reward last col mean 5.949383763415028e-10 first col mean 4.833626277012115e-10 all mean 7.599205154029676e-10
4.0006314233620444e-11 4.0006265661363116e-11
rl training, epoch1, iter0, batch118/1133, batch loss:4.0006265661363116e-11, Training time:18014.630588293076
batch reward last col mean 2.469408677541196e-09 first col mean 3.703619995576446e-06 all mean 5.001620806410756e-08
1.2243903668718303e-08 1.2243891234220428e-08
rl training, epoch1, iter0, batch119/1133, batch loss:1.2243891234220428e-08, Training time:18042.363077878952
batch reward last col mean 8.099938497707626e-09 first col mean 1.1829100365901013e-08 all mean 2.441555579935084e-08
1.4029092332279447e-09 1.4029098993617595e-09
rl training, epoch1, iter0, batch120/1133, batch loss:1.4029098993617595e-09, Training time:18070.509151935577
batch reward last col mean 2.1113728543298294e-09 first col mean 2.0168138270548752e-09 all mean 1.2383717148622964e-05
2.3617452882263024e-08 2.361204387568705e-08
rl training, epoch1, iter0, batch121/1133, batch loss:2.361204387568705e-08, Training time:18098.524943113327
batch reward last col mean 8.645741345070235e-10 first col mean 2.3088708722696083e-09 all mean 5.780813353339909e-06
5.753648292738944e-05 5.753648292738944e-05
rl training, epoch1, iter0, batch122/1133, batch loss:5.753648292738944e-05, Training time:18126.086221456528
batch reward last col mean 3.884047306002003e-09 first col mean 2.260733600323306e-09 all mean 5.915566703151853e-09
1.0413458984004365e-09 1.0413446771551094e-09
rl training, epoch1, iter0, batch123/1133, batch loss:1.0413446771551094e-09, Training time:18154.079761981964
batch reward last col mean 1.3916656715906583e-09 first col mean 1.1487428785983411e-09 all mean 1.7383092298928204e-08
6.773059890718969e-11 6.772667149324008e-11
rl training, epoch1, iter0, batch124/1133, batch loss:6.772667149324008e-11, Training time:18181.95729970932
batch reward last col mean 2.4174240387253576e-09 first col mean 2.5374695677982118e-09 all mean 3.0789202298819873e-09
2.561138245926742e-10 2.561140466372791e-10
rl training, epoch1, iter0, batch125/1133, batch loss:2.561140466372791e-10, Training time:18210.108522176743
batch reward last col mean 9.577978410391097e-10 first col mean 0.0018743315013125539 all mean 1.8935934349428862e-05
0.0001312454987782985 0.0001312454987782985
rl training, epoch1, iter0, batch126/1133, batch loss:0.0001312454987782985, Training time:18237.707046985626
batch reward last col mean 1.550130468430666e-09 first col mean 1.5906629347028911e-09 all mean 4.7064313548617065e-06
1.4070457021730931e-09 1.4043795015794558e-09
rl training, epoch1, iter0, batch127/1133, batch loss:1.4043795015794558e-09, Training time:18265.58125424385
batch reward last col mean 3.4331872900139615e-09 first col mean 0.00014321353228297085 all mean 1.497985863352369e-06
4.9984261174529365e-09 4.998697900049365e-09
rl training, epoch1, iter0, batch128/1133, batch loss:4.998697900049365e-09, Training time:18293.372623205185
batch reward last col mean 8.937662832053661e-10 first col mean 1.853346476288209e-09 all mean 4.071571595432033e-07
8.150934371897733e-10 8.151731512029414e-10
rl training, epoch1, iter0, batch129/1133, batch loss:8.151731512029414e-10, Training time:18321.80261349678
batch reward last col mean 8.77332873017167e-10 first col mean 1.349478306877927e-09 all mean 3.428428652085813e-09
3.897135739117097e-11 3.8970660032333626e-11
rl training, epoch1, iter0, batch130/1133, batch loss:3.8970660032333626e-11, Training time:18349.4821164608
batch reward last col mean 8.526344630332972e-10 first col mean 1.21273635578234e-09 all mean 2.1866258066438604e-06
3.0422270924646e-08 3.0421308139239045e-08
rl training, epoch1, iter0, batch131/1133, batch loss:3.0421308139239045e-08, Training time:18376.473227262497
batch reward last col mean 8.846436361231724e-10 first col mean 1.1848355629950902e-09 all mean 1.883940559110897e-09
7.401703555620642e-11 7.401644575022459e-11
rl training, epoch1, iter0, batch132/1133, batch loss:7.401644575022459e-11, Training time:18403.692854881287
batch reward last col mean 3.7238194749988907e-09 first col mean 2.3767616763592514e-09 all mean 3.624508027044726e-09
2.2991350490109141e-10 2.2991350490109141e-10
rl training, epoch1, iter0, batch133/1133, batch loss:2.2991350490109141e-10, Training time:18431.189052581787
batch reward last col mean 8.68607230586349e-09 first col mean 1.2406085048155546e-09 all mean 6.776726877433248e-07
1.6746871667194796e-09 1.6749693854123393e-09
rl training, epoch1, iter0, batch134/1133, batch loss:1.6749693854123393e-09, Training time:18458.399641513824
batch reward last col mean 9.611929030484134e-10 first col mean 1.5109051787476346e-09 all mean 2.9668674415006535e-06
3.099299039632797e-09 3.100142142997697e-09
rl training, epoch1, iter0, batch135/1133, batch loss:3.100142142997697e-09, Training time:18486.32200050354
batch reward last col mean 2.267050103199608e-09 first col mean 2.2310426839311503e-09 all mean 2.2317362891044468e-06
3.0106284611974843e-06 3.010627779076458e-06
rl training, epoch1, iter0, batch136/1133, batch loss:3.010627779076458e-06, Training time:18513.91236281395
batch reward last col mean 1.625393819537635e-09 first col mean 1.2220804368467952e-09 all mean 3.7145659007364884e-05
0.00019404506019782275 0.00019404504564590752
rl training, epoch1, iter0, batch137/1133, batch loss:0.00019404504564590752, Training time:18541.234132528305
batch reward last col mean 1.786852221741242e-09 first col mean 1.9563139996847667e-09 all mean 1.6443871572846547e-05
3.961462979873431e-08 3.9607488844239924e-08
rl training, epoch1, iter0, batch138/1133, batch loss:3.9607488844239924e-08, Training time:18568.69531750679
batch reward last col mean 5.748057585464039e-09 first col mean 5.7470761483102706e-09 all mean 1.1332724092483204e-08
2.653919028983154e-10 2.6538993225244667e-10
rl training, epoch1, iter0, batch139/1133, batch loss:2.6538993225244667e-10, Training time:18596.10310602188
batch reward last col mean 5.280925030604067e-09 first col mean 6.656837747698319e-09 all mean 5.4790927350722995e-08
4.5901399348124983e-10 4.590229585321737e-10
rl training, epoch1, iter0, batch140/1133, batch loss:4.590229585321737e-10, Training time:18623.63178563118
batch reward last col mean 1.339870214778216e-09 first col mean 1.338230970482357e-09 all mean 1.728056986394222e-06
2.2471078864327865e-06 2.247108113806462e-06
rl training, epoch1, iter0, batch141/1133, batch loss:2.247108113806462e-06, Training time:18651.1187376976
batch reward last col mean 1.9434338582868804e-09 first col mean 3.823915850631465e-09 all mean 5.2774189462923005e-09
2.897005968449662e-10 2.8970126297878096e-10
rl training, epoch1, iter0, batch142/1133, batch loss:2.8970126297878096e-10, Training time:18678.5385119915
batch reward last col mean 1.1975090918880937e-09 first col mean 1.0654939153198484e-09 all mean 1.9544628230505623e-05
2.6919829565486e-07 2.692026157546934e-07
rl training, epoch1, iter0, batch143/1133, batch loss:2.692026157546934e-07, Training time:18705.98012447357
batch reward last col mean 0.0005909850588068366 first col mean 6.124046336708489e-08 all mean 0.0005817677010782063
0.00012904278992209584 0.00012904278992209584
rl training, epoch1, iter0, batch144/1133, batch loss:0.00012904278992209584, Training time:18733.394355535507
batch reward last col mean 1.020658890737991e-09 first col mean 8.297805775825395e-10 all mean 5.971576229057973e-07
3.037342821698985e-06 3.0373430490726605e-06
rl training, epoch1, iter0, batch145/1133, batch loss:3.0373430490726605e-06, Training time:18760.66038417816
batch reward last col mean 7.633252252503553e-09 first col mean 1.861605269937172e-08 all mean 7.847392069493253e-09
7.130039336722405e-10 7.130038781610892e-10
rl training, epoch1, iter0, batch146/1133, batch loss:7.130038781610892e-10, Training time:18788.09341263771
batch reward last col mean 1.5766945526962672e-09 first col mean 4.329892000498603e-09 all mean 2.5499986122667906e-07
6.954902764810811e-10 6.956256681789341e-10
rl training, epoch1, iter0, batch147/1133, batch loss:6.956256681789341e-10, Training time:18815.563275575638
batch reward last col mean 1.6722654372358647e-09 first col mean 2.831323397955998e-09 all mean 3.0750632618037343e-07
9.181753690690186e-10 9.182324345324844e-10
rl training, epoch1, iter0, batch148/1133, batch loss:9.182324345324844e-10, Training time:18843.349642515182
batch reward last col mean 1.743341360160855e-09 first col mean 4.350127369434631e-09 all mean 3.8511815958486295e-09
2.360631412567926e-10 2.360627804343096e-10
rl training, epoch1, iter0, batch149/1133, batch loss:2.360627804343096e-10, Training time:18870.850142002106
batch reward last col mean 1.5530060570867477e-09 first col mean 1.674246297156401e-09 all mean 4.0228407272024924e-09
8.456930988831601e-11 8.456738087581073e-11
rl training, epoch1, iter0, batch150/1133, batch loss:8.456738087581073e-11, Training time:18898.144438505173
batch reward last col mean 7.041236038674015e-09 first col mean 7.228043941154283e-09 all mean 6.914848427186371e-08
3.127570702421423e-10 3.1271940592603187e-10
rl training, epoch1, iter0, batch151/1133, batch loss:3.1271940592603187e-10, Training time:18925.554778814316
batch reward last col mean 1.7851802258661564e-09 first col mean 1.2112626457394526e-09 all mean 2.919192887418376e-09
9.15448897242932e-11 9.15447023741578e-11
rl training, epoch1, iter0, batch152/1133, batch loss:9.15447023741578e-11, Training time:18952.873050689697
batch reward last col mean 1.1250346210189832e-09 first col mean 2.6992070800702095e-09 all mean 2.0355339636068948e-09
6.50855688788532e-11 6.508552724548977e-11
rl training, epoch1, iter0, batch153/1133, batch loss:6.508552724548977e-11, Training time:18980.167900562286
batch reward last col mean 8.00704214043435e-09 first col mean 2.1629176227833113e-09 all mean 2.7521744414116256e-05
6.540559115819633e-05 6.540559115819633e-05
rl training, epoch1, iter0, batch154/1133, batch loss:6.540559115819633e-05, Training time:19007.877519845963
batch reward last col mean 4.229192107629842e-09 first col mean 3.736596809744697e-09 all mean 7.259763012967824e-09
1.2012525696381005e-10 1.2012656147586398e-10
rl training, epoch1, iter0, batch155/1133, batch loss:1.2012656147586398e-10, Training time:19035.647536993027
batch reward last col mean 5.03355190861754e-10 first col mean 0.00011023227853002027 all mean 1.789936504792422e-05
9.465041512157768e-05 9.465041512157768e-05
rl training, epoch1, iter0, batch156/1133, batch loss:9.465041512157768e-05, Training time:19063.697075366974
batch reward last col mean 1.5483312409969585e-09 first col mean 7.869243563618511e-05 all mean 1.8908664060290903e-05
1.2891391065750213e-07 1.2891094058886665e-07
rl training, epoch1, iter0, batch157/1133, batch loss:1.2891094058886665e-07, Training time:19091.118356227875
batch reward last col mean 3.4906446622073872e-09 first col mean 3.2932856441902914e-09 all mean 5.9746163572071964e-09
9.715452053971063e-11 9.715431237289351e-11
rl training, epoch1, iter0, batch158/1133, batch loss:9.715431237289351e-11, Training time:19118.792636156082
batch reward last col mean 1.315989095473924e-09 first col mean 3.3934459686690843e-09 all mean 8.11130096423085e-09
2.517491770603897e-10 2.5174784479276013e-10
rl training, epoch1, iter0, batch159/1133, batch loss:2.5174784479276013e-10, Training time:19146.679358959198
batch reward last col mean 1.5622433346962339e-09 first col mean 2.039641788798008e-09 all mean 2.0958250956937263e-07
3.2388440818209574e-09 3.2388638437907957e-09
rl training, epoch1, iter0, batch160/1133, batch loss:3.2388638437907957e-09, Training time:19174.923360347748
batch reward last col mean 9.412357560023565e-10 first col mean 1.4977985518527248e-09 all mean 1.3290800682241866e-09
1.3146388144757992e-10 1.314640063476702e-10
rl training, epoch1, iter0, batch161/1133, batch loss:1.314640063476702e-10, Training time:19202.610495090485
batch reward last col mean 1.7863124313066692e-08 first col mean 0.0005398261127993464 all mean 5.46060573469731e-06
2.5930052061085007e-07 2.5929861635631823e-07
rl training, epoch1, iter0, batch162/1133, batch loss:2.5929861635631823e-07, Training time:19230.539059877396
batch reward last col mean 3.7001596231434064e-10 first col mean 5.912077494230061e-10 all mean 2.9074257668071368e-08
1.4949302906686057e-09 1.4949407267650372e-09
rl training, epoch1, iter0, batch163/1133, batch loss:1.4949407267650372e-09, Training time:19258.316465377808
batch reward last col mean 1.0030205555011662e-09 first col mean 1.4925107816310401e-09 all mean 7.1303372095599116e-09
1.9193338030021323e-09 1.9193358014035766e-09
rl training, epoch1, iter0, batch164/1133, batch loss:1.9193358014035766e-09, Training time:19286.263468265533
batch reward last col mean 5.694880567119753e-09 first col mean 4.122341135115448e-09 all mean 1.0071341982609283e-08
1.2653254832795113e-10 1.2653299241716098e-10
rl training, epoch1, iter0, batch165/1133, batch loss:1.2653299241716098e-10, Training time:19314.82299733162
batch reward last col mean 2.4043482760305324e-09 first col mean 1.3613247418220453e-08 all mean 6.3803544669838175e-09
3.7640413008688256e-10 3.764019096408333e-10
rl training, epoch1, iter0, batch166/1133, batch loss:3.764019096408333e-10, Training time:19342.560217618942
batch reward last col mean 1.0157994445592067e-09 first col mean 8.800646877915597e-10 all mean 2.39892039566314e-09
4.205824577496742e-11 4.2058082710960676e-11
rl training, epoch1, iter0, batch167/1133, batch loss:4.2058082710960676e-11, Training time:19370.378801345825
batch reward last col mean 8.137415186126873e-10 first col mean 7.047194494624875e-10 all mean 1.0473386602427581e-09
5.0978807980550656e-11 5.097884961391408e-11
rl training, epoch1, iter0, batch168/1133, batch loss:5.097884961391408e-11, Training time:19398.58122611046
batch reward last col mean 1.6097140287385514e-09 first col mean 2.0810786427460926e-09 all mean 2.154042277879853e-09
1.695067142204465e-10 1.6950657544256842e-10
rl training, epoch1, iter0, batch169/1133, batch loss:1.6950657544256842e-10, Training time:19426.527733564377
batch reward last col mean 2.5246162937975214e-09 first col mean 6.2860170402245785e-09 all mean 9.853936333570346e-09
2.8850612565634037e-08 2.8850614341990877e-08
rl training, epoch1, iter0, batch170/1133, batch loss:2.8850614341990877e-08, Training time:19454.045134067535
batch reward last col mean 1.1163171498296265e-09 first col mean 9.406283529855841e-10 all mean 8.01937949290732e-06
5.483914264914347e-06 5.483916538651101e-06
rl training, epoch1, iter0, batch171/1133, batch loss:5.483916538651101e-06, Training time:19482.177469730377
batch reward last col mean 6.393002127680347e-09 first col mean 1.2628217360699523e-09 all mean 5.591267004945166e-09
4.478733217627706e-10 4.47873294007195e-10
rl training, epoch1, iter0, batch172/1133, batch loss:4.47873294007195e-10, Training time:19510.258568048477
batch reward last col mean 1.7085244330417027e-09 first col mean 2.6545035058944677e-09 all mean 6.265085339407506e-09
1.5284792875824849e-10 1.5284951082605858e-10
rl training, epoch1, iter0, batch173/1133, batch loss:1.5284951082605858e-10, Training time:19538.13613677025
batch reward last col mean 9.869686401486888e-09 first col mean 4.9500181731332304e-09 all mean 1.592098669789266e-05
1.689907804802715e-07 1.6899419108540314e-07
rl training, epoch1, iter0, batch174/1133, batch loss:1.6899419108540314e-07, Training time:19566.95596051216
batch reward last col mean 9.391503130729006e-10 first col mean 1.887112688336856e-09 all mean 4.498460715041119e-09
1.592194154298454e-10 1.5921987339684307e-10
rl training, epoch1, iter0, batch175/1133, batch loss:1.5921987339684307e-10, Training time:19594.616844177246
batch reward last col mean 2.5307169693178366e-09 first col mean 2.758030470673134e-09 all mean 3.3265250554137538e-09
6.454423800983378e-11 6.454473761019486e-11
rl training, epoch1, iter0, batch176/1133, batch loss:6.454473761019486e-11, Training time:19622.261251926422
batch reward last col mean 1.5722071422530348e-09 first col mean 1.2405511062851815e-09 all mean 1.7870080171178415e-07
5.168236043573415e-07 5.168235475139227e-07
rl training, epoch1, iter0, batch177/1133, batch loss:5.168235475139227e-07, Training time:19650.75382876396
batch reward last col mean 4.706082847860671e-07 first col mean 2.5448394502802785e-09 all mean 1.90190387883149e-08
3.391759406667916e-08 3.391758340853812e-08
rl training, epoch1, iter0, batch178/1133, batch loss:3.391758340853812e-08, Training time:19679.588848114014
batch reward last col mean 1.6080299314324975e-09 first col mean 1.8186766537198196e-09 all mean 1.8911603394400345e-09
1.1612950878703288e-10 1.1612950878703288e-10
rl training, epoch1, iter0, batch179/1133, batch loss:1.1612950878703288e-10, Training time:19707.42180275917
batch reward last col mean 1.2212791888899233e-09 first col mean 1.7672823204861743e-09 all mean 1.4596284181322972e-09
4.3402996474650735e-11 4.3403048516355014e-11
rl training, epoch1, iter0, batch180/1133, batch loss:4.3403048516355014e-11, Training time:19735.26859498024
batch reward last col mean 7.90447485243817e-10 first col mean 9.709868464824467e-10 all mean 1.613131280464586e-05
3.3451976833021035e-07 3.345184040881577e-07
rl training, epoch1, iter0, batch181/1133, batch loss:3.345184040881577e-07, Training time:19762.919835567474
batch reward last col mean 7.759474729418514e-10 first col mean 1.5791793428476808e-09 all mean 1.777688339643646e-05
2.515446067263838e-05 2.515445521567017e-05
rl training, epoch1, iter0, batch182/1133, batch loss:2.515445521567017e-05, Training time:19790.545729637146
batch reward last col mean 7.292152215399028e-09 first col mean 3.660900471658124e-09 all mean 4.365505787973234e-07
5.531032298833338e-10 5.532622693316114e-10
rl training, epoch1, iter0, batch183/1133, batch loss:5.532622693316114e-10, Training time:19818.109041929245
batch reward last col mean 7.098156507012732e-10 first col mean 7.470444263191212e-10 all mean 1.2584989717012718e-09
5.877692083045005e-11 5.877692776934396e-11
rl training, epoch1, iter0, batch184/1133, batch loss:5.877692776934396e-11, Training time:19845.94800877571
batch reward last col mean 9.130774469845448e-10 first col mean 1.050551312609116e-09 all mean 7.455004613632354e-09
6.78888473215622e-11 6.788328232865126e-11
rl training, epoch1, iter0, batch185/1133, batch loss:6.788328232865126e-11, Training time:19873.78199529648
batch reward last col mean 6.964949061938341e-09 first col mean 4.771202544162634e-09 all mean 4.240171946889859e-08
5.023133575754457e-10 5.023284010974294e-10
rl training, epoch1, iter0, batch186/1133, batch loss:5.023284010974294e-10, Training time:19901.73948740959
batch reward last col mean 6.005468344838505e-10 first col mean 1.0962082352961033e-09 all mean 1.0041907749780421e-08
8.384521549276158e-11 8.385097477470183e-11
rl training, epoch1, iter0, batch187/1133, batch loss:8.385097477470183e-11, Training time:19930.164798736572
batch reward last col mean 7.898512954795933e-10 first col mean 8.734356016226741e-10 all mean 9.714352877665533e-09
6.196932550439627e-11 6.196549523496131e-11
rl training, epoch1, iter0, batch188/1133, batch loss:6.196549523496131e-11, Training time:19957.859313249588
batch reward last col mean 8.818447083669412e-10 first col mean 9.537931555669843e-10 all mean 1.97148006009229e-06
3.233493828247447e-08 3.23356204035008e-08
rl training, epoch1, iter0, batch189/1133, batch loss:3.23356204035008e-08, Training time:19986.390758514404
batch reward last col mean 1.706124352907068e-09 first col mean 2.2656845288793193e-09 all mean 2.100868368160036e-09
1.0566861274874384e-10 1.0566863356542555e-10
rl training, epoch1, iter0, batch190/1133, batch loss:1.0566863356542555e-10, Training time:20014.461614370346
batch reward last col mean 6.266283603117984e-10 first col mean 1.936886429021456e-09 all mean 2.8101398985569404e-09
5.369177324965335e-10 5.369187316972557e-10
rl training, epoch1, iter0, batch191/1133, batch loss:5.369187316972557e-10, Training time:20042.247398376465
batch reward last col mean 9.85294734690001e-10 first col mean 0.000582291220780462 all mean 5.883221547264839e-06
3.538183079854207e-07 3.5381629004405113e-07
rl training, epoch1, iter0, batch192/1133, batch loss:3.5381629004405113e-07, Training time:20070.274958372116
batch reward last col mean 1.8493357956117507e-09 first col mean 1.8672547952292007e-09 all mean 3.9755843062039276e-08
1.2938304594367622e-10 1.2939264937283923e-10
rl training, epoch1, iter0, batch193/1133, batch loss:1.2939264937283923e-10, Training time:20098.121277809143
batch reward last col mean 2.656119324484507e-09 first col mean 0.00024292003945447505 all mean 2.4559883513575187e-06
1.3662940112624256e-08 1.366348900688763e-08
rl training, epoch1, iter0, batch194/1133, batch loss:1.366348900688763e-08, Training time:20125.96072602272
batch reward last col mean 1.6091372678772586e-09 first col mean 1.3417496003143015e-09 all mean 1.3367203791858628e-05
3.6245882029106724e-07 3.624564328674751e-07
rl training, epoch1, iter0, batch195/1133, batch loss:3.624564328674751e-07, Training time:20154.145679473877
batch reward last col mean 1.0731386890228123e-09 first col mean 1.2273820848562877e-09 all mean 4.065809022790745e-09
8.331205170186706e-11 8.331298151365019e-11
rl training, epoch1, iter0, batch196/1133, batch loss:8.331298151365019e-11, Training time:20182.158383846283
batch reward last col mean 5.761996213493603e-09 first col mean 9.347659783998097e-07 all mean 3.7170372024775133e-07
2.424070771667175e-06 2.424070771667175e-06
rl training, epoch1, iter0, batch197/1133, batch loss:2.424070771667175e-06, Training time:20209.423728704453
batch reward last col mean 3.3548819278195197e-09 first col mean 2.044960423219777e-09 all mean 1.621806511309387e-08
1.01686416231761e-10 1.0167609115763199e-10
rl training, epoch1, iter0, batch198/1133, batch loss:1.0167609115763199e-10, Training time:20237.813675165176
batch reward last col mean 2.4684212451830945e-09 first col mean 2.3159674178430123e-09 all mean 3.227386713433589e-08
7.30600691056793e-10 7.305823168657355e-10
rl training, epoch1, iter0, batch199/1133, batch loss:7.305823168657355e-10, Training time:20266.014409303665
batch reward last col mean 3.903451428755034e-08 first col mean 3.760536770869294e-09 all mean 1.3839517087887998e-08
4.240428896906678e-09 4.240432893709567e-09
rl training, epoch1, iter0, batch200/1133, batch loss:4.240432893709567e-09, Training time:20293.43390059471
batch reward last col mean 4.9072718111276e-10 first col mean 0.0003897396381944418 all mean 3.9376864151563495e-06
1.7936991980604944e-06 1.793700562302547e-06
rl training, epoch1, iter0, batch201/1133, batch loss:1.793700562302547e-06, Training time:20321.457245588303
batch reward last col mean 4.265593656072042e-09 first col mean 4.84857753946244e-09 all mean 8.184699140656448e-09
6.917030836994797e-10 6.917011408091867e-10
rl training, epoch1, iter0, batch202/1133, batch loss:6.917011408091867e-10, Training time:20349.112357378006
batch reward last col mean 4.943723652672816e-09 first col mean 4.740298820138378e-09 all mean 5.322620836523129e-06
3.083197589148767e-05 3.083197589148767e-05
rl training, epoch1, iter0, batch203/1133, batch loss:3.083197589148767e-05, Training time:20376.802856445312
batch reward last col mean 7.137461732753536e-10 first col mean 8.892730440912544e-10 all mean 3.6738103972311364e-06
1.5172357052506413e-05 1.517235523351701e-05
rl training, epoch1, iter0, batch204/1133, batch loss:1.517235523351701e-05, Training time:20404.731704711914
batch reward last col mean 8.182442501336595e-10 first col mean 8.404116291771402e-10 all mean 1.8923541574622504e-05
9.795630973030711e-08 9.795273570034624e-08
rl training, epoch1, iter0, batch205/1133, batch loss:9.795273570034624e-08, Training time:20431.97658586502
batch reward last col mean 2.018260225611357e-09 first col mean 1.8035839488561578e-09 all mean 2.7390438805952044e-09
6.839262489677367e-11 6.839242366885045e-11
rl training, epoch1, iter0, batch206/1133, batch loss:6.839242366885045e-11, Training time:20460.03679060936
batch reward last col mean 9.469086625912837e-10 first col mean 2.1884307699338024e-09 all mean 1.5864093372286447e-09
3.7340758263226803e-10 3.734073605876631e-10
rl training, epoch1, iter0, batch207/1133, batch loss:3.734073605876631e-10, Training time:20488.59145975113
batch reward last col mean 3.4905407453322823e-09 first col mean 4.196059499861349e-09 all mean 4.898878191994527e-09
2.3897198109246176e-10 2.3897231415936915e-10
rl training, epoch1, iter0, batch208/1133, batch loss:2.3897231415936915e-10, Training time:20516.503722667694
batch reward last col mean 4.664383101982139e-09 first col mean 0.0005160302971489727 all mean 5.217250873101875e-06
7.555319143648376e-07 7.555298680017586e-07
rl training, epoch1, iter0, batch209/1133, batch loss:7.555298680017586e-07, Training time:20544.169842004776
batch reward last col mean 7.67528973710796e-09 first col mean 2.752971184349917e-09 all mean 5.377832167141605e-06
1.4732735564848554e-07 1.4732688669027993e-07
rl training, epoch1, iter0, batch210/1133, batch loss:1.4732688669027993e-07, Training time:20571.8528983593
batch reward last col mean 3.3637104934314266e-05 first col mean 1.9883341639825858e-09 all mean 3.295987698948011e-05
3.08378116642416e-06 3.08378116642416e-06
rl training, epoch1, iter0, batch211/1133, batch loss:3.08378116642416e-06, Training time:20599.32830142975
batch reward last col mean 6.291137055747242e-10 first col mean 8.271459073228016e-10 all mean 1.5873139469491093e-09
7.417348679705782e-11 7.417359088046638e-11
rl training, epoch1, iter0, batch212/1133, batch loss:7.417359088046638e-11, Training time:20627.06920146942
batch reward last col mean 3.2273426153750506e-09 first col mean 1.9266281903185245e-09 all mean 5.160540883508702e-09
1.37030067848265e-10 1.3702947110338926e-10
rl training, epoch1, iter0, batch213/1133, batch loss:1.3702947110338926e-10, Training time:20654.743784427643
batch reward last col mean 5.673975733699876e-10 first col mean 9.563722036531885e-10 all mean 2.562771896919003e-07
2.2806567745448092e-10 2.2812546296435698e-10
rl training, epoch1, iter0, batch214/1133, batch loss:2.2812546296435698e-10, Training time:20682.58721756935
batch reward last col mean 1.2137314486793116e-09 first col mean 1.0153287099967656e-09 all mean 1.2812296779074472e-09
3.706443485462785e-11 3.7064410568499184e-11
rl training, epoch1, iter0, batch215/1133, batch loss:3.7064410568499184e-11, Training time:20710.14273738861
batch reward last col mean 0.0002698052558116615 first col mean 4.5542787319163835e-09 all mean 0.0002534718078095466
2.0525572836049832e-05 2.0525572836049832e-05
rl training, epoch1, iter0, batch216/1133, batch loss:2.0525572836049832e-05, Training time:20737.813725471497
batch reward last col mean 1.6043079087424417e-09 first col mean 2.1848709508276443e-09 all mean 5.82684620553664e-08
2.447493443469284e-07 2.447493443469284e-07
rl training, epoch1, iter0, batch217/1133, batch loss:2.447493443469284e-07, Training time:20765.518818855286
batch reward last col mean 1.5747291248757733e-09 first col mean 0.0003916237619705498 all mean 3.96238192479359e-06
1.4490673265754594e-06 1.4490672128886217e-06
rl training, epoch1, iter0, batch218/1133, batch loss:1.4490672128886217e-06, Training time:20794.039749622345
batch reward last col mean 1.1090914853184586e-09 first col mean 9.006735357530715e-10 all mean 3.128250991579762e-09
8.285148955788912e-11 8.285173241917576e-11
rl training, epoch1, iter0, batch219/1133, batch loss:8.285173241917576e-11, Training time:20822.054280996323
batch reward last col mean 1.8563970360929716e-09 first col mean 1.228943524722581e-08 all mean 5.065248387836618e-06
1.1818608072644565e-05 1.1818608982139267e-05
rl training, epoch1, iter0, batch220/1133, batch loss:1.1818608982139267e-05, Training time:20849.824683904648
batch reward last col mean 6.859041112861064e-10 first col mean 8.051595501434861e-10 all mean 1.1545736924745142e-05
3.6200137401465327e-05 3.6200137401465327e-05
rl training, epoch1, iter0, batch221/1133, batch loss:3.6200137401465327e-05, Training time:20877.702699899673
batch reward last col mean 2.65349009431759e-09 first col mean 1.5662552366180194e-09 all mean 3.4618286015586364e-09
1.2625922529707623e-10 1.262589893746835e-10
rl training, epoch1, iter0, batch222/1133, batch loss:1.262589893746835e-10, Training time:20906.3322122097
batch reward last col mean 0.0013182562543079257 first col mean 1.6208128172934266e-09 all mean 0.0012522926554083824
8.050793258007616e-05 8.050793258007616e-05
rl training, epoch1, iter0, batch223/1133, batch loss:8.050793258007616e-05, Training time:20934.522320747375
batch reward last col mean 2.192761749952865e-09 first col mean 7.95390686647579e-09 all mean 1.8146592992707156e-05
3.1402611057274044e-05 3.140261469525285e-05
rl training, epoch1, iter0, batch224/1133, batch loss:3.140261469525285e-05, Training time:20962.86254811287
batch reward last col mean 9.768829078993235e-10 first col mean 1.0151761653531821e-09 all mean 6.6849876745322945e-09
5.496893218381871e-11 5.49688246309632e-11
rl training, epoch1, iter0, batch225/1133, batch loss:5.49688246309632e-11, Training time:20991.25277042389
batch reward last col mean 1.0591901800083292e-09 first col mean 1.5973535827384922e-09 all mean 6.0544076418977966e-09
8.124516337471022e-11 8.124862588276827e-11
rl training, epoch1, iter0, batch226/1133, batch loss:8.124862588276827e-11, Training time:21018.959166288376
batch reward last col mean 2.4707942358759283e-09 first col mean 5.8654756607268155e-09 all mean 1.562871965177237e-08
3.0516356108734044e-10 3.0516605908914585e-10
rl training, epoch1, iter0, batch227/1133, batch loss:3.0516605908914585e-10, Training time:21046.73829102516
batch reward last col mean 7.296591109096084e-10 first col mean 8.067858603411082e-10 all mean 1.351379896874505e-09
3.434881892805386e-11 3.434832279713973e-11
rl training, epoch1, iter0, batch228/1133, batch loss:3.434832279713973e-11, Training time:21074.87012243271
batch reward last col mean 2.1450425879976365e-09 first col mean 1.7216572611999936e-09 all mean 1.1153199253044477e-08
6.070896563237227e-11 6.07072378477902e-11
rl training, epoch1, iter0, batch229/1133, batch loss:6.07072378477902e-11, Training time:21102.629336595535
batch reward last col mean 1.7848800215602978e-09 first col mean 1.6921486434284816e-09 all mean 1.9081043411972587e-09
1.0118395704639127e-10 1.0118385296298271e-10
rl training, epoch1, iter0, batch230/1133, batch loss:1.0118385296298271e-10, Training time:21130.325093984604
batch reward last col mean 7.977993821128848e-10 first col mean 8.247130756089405e-10 all mean 1.778340811142698e-05
3.7191490775967395e-08 3.7183259138373614e-08
rl training, epoch1, iter0, batch231/1133, batch loss:3.7183259138373614e-08, Training time:21157.906826257706
batch reward last col mean 3.773992673927751e-09 first col mean 2.6164497235470208e-09 all mean 4.627444205596021e-09
1.1668538357767488e-10 1.1668513377749434e-10
rl training, epoch1, iter0, batch232/1133, batch loss:1.1668513377749434e-10, Training time:21185.446619987488
batch reward last col mean 6.310901135009317e-09 first col mean 1.3016967503887145e-09 all mean 8.131599393834676e-09
1.7387218054221165e-10 1.738724580979678e-10
rl training, epoch1, iter0, batch233/1133, batch loss:1.738724580979678e-10, Training time:21212.993311166763
batch reward last col mean 1.0388466753497028e-09 first col mean 1.3330394565969073e-09 all mean 1.2769320045791233e-09
1.4100727530053092e-10 1.4100731693389434e-10
rl training, epoch1, iter0, batch234/1133, batch loss:1.4100731693389434e-10, Training time:21241.225862026215
batch reward last col mean 0.000667607702780515 first col mean 0.0005981734720990062 all mean 0.0006534197018481791
5.855308336322196e-05 5.8553076087264344e-05
rl training, epoch1, iter0, batch235/1133, batch loss:5.8553076087264344e-05, Training time:21268.907796382904
batch reward last col mean 2.051343983566767e-09 first col mean 2.7491053877781724e-09 all mean 3.087717859173722e-09
2.3354460032543045e-10 2.3354404521391814e-10
rl training, epoch1, iter0, batch236/1133, batch loss:2.3354404521391814e-10, Training time:21296.11506152153
batch reward last col mean 4.669576725291336e-09 first col mean 2.0916524068326225e-09 all mean 1.2206709421036521e-08
3.0385757798789825e-10 3.038543305855512e-10
rl training, epoch1, iter0, batch237/1133, batch loss:3.038543305855512e-10, Training time:21324.035397052765
batch reward last col mean 6.715312195204604e-10 first col mean 8.298344233992339e-10 all mean 6.940713774383767e-06
1.1313959475955926e-05 1.1313958566461224e-05
rl training, epoch1, iter0, batch238/1133, batch loss:1.1313958566461224e-05, Training time:21351.83624434471
batch reward last col mean 1.7953061259845526e-09 first col mean 1.3993950442880987e-09 all mean 2.181778979704063e-09
1.0012549123139536e-10 1.0012533857572947e-10
rl training, epoch1, iter0, batch239/1133, batch loss:1.0012533857572947e-10, Training time:21379.77709531784
batch reward last col mean 1.397196136565526e-09 first col mean 2.754269257110309e-09 all mean 3.0100932857379803e-09
6.544792485740913e-11 6.544848690781535e-11
rl training, epoch1, iter0, batch240/1133, batch loss:6.544848690781535e-11, Training time:21407.44173002243
batch reward last col mean 1.0634952918309182e-09 first col mean 1.4543812820733137e-09 all mean 1.2824356417695526e-05
9.641875919896847e-08 9.642371878726408e-08
rl training, epoch1, iter0, batch241/1133, batch loss:9.642371878726408e-08, Training time:21435.67248916626
batch reward last col mean 2.6041595546644203e-09 first col mean 1.467309163061259e-09 all mean 4.859568747406229e-08
2.396381704183881e-10 2.396748077782007e-10
rl training, epoch1, iter0, batch242/1133, batch loss:2.396748077782007e-10, Training time:21463.39551758766
batch reward last col mean 0.006176662631332874 first col mean 8.225761405356025e-09 all mean 0.005869617220014334
0.0004240347188897431 0.0004240347188897431
rl training, epoch1, iter0, batch243/1133, batch loss:0.0004240347188897431, Training time:21491.436211586
batch reward last col mean 1.7061265733531172e-09 first col mean 0.0005515391239896417 all mean 5.5802674978622235e-06
2.6389043839003534e-08 2.6388830676182806e-08
rl training, epoch1, iter0, batch244/1133, batch loss:2.6388830676182806e-08, Training time:21519.830315828323
batch reward last col mean 1.1047619485893279e-09 first col mean 3.921241997772995e-09 all mean 2.5035065132072987e-09
4.3931545901099156e-11 4.393107058686674e-11
rl training, epoch1, iter0, batch245/1133, batch loss:4.393107058686674e-11, Training time:21548.12835907936
batch reward last col mean 1.0894675162020917e-09 first col mean 1.1773483299393206e-09 all mean 1.2952424022216746e-08
5.84345594134561e-09 5.843457717702449e-09
rl training, epoch1, iter0, batch246/1133, batch loss:5.843457717702449e-09, Training time:21575.997198343277
batch reward last col mean 5.197399843837047e-09 first col mean 5.108541589748938e-09 all mean 5.856536144932534e-09
2.1310751774361592e-10 2.1310794795503796e-10
rl training, epoch1, iter0, batch247/1133, batch loss:2.1310794795503796e-10, Training time:21603.946997880936
batch reward last col mean 1.0830301100384077e-09 first col mean 1.5038388312405004e-09 all mean 1.2445341424083267e-09
7.657604411681618e-11 7.657605105571008e-11
rl training, epoch1, iter0, batch248/1133, batch loss:7.657605105571008e-11, Training time:21631.38616681099
batch reward last col mean 4.700134725865723e-10 first col mean 0.00020356650929898024 all mean 2.060131464531878e-06
1.5829156652102938e-08 1.5828963029207443e-08
rl training, epoch1, iter0, batch249/1133, batch loss:1.5828963029207443e-08, Training time:21659.366397619247
batch reward last col mean 2.757850170453935e-09 first col mean 3.4883456123679935e-09 all mean 3.5612275350871414e-09
1.3743421678480416e-10 1.3743385596232116e-10
rl training, epoch1, iter0, batch250/1133, batch loss:1.3743385596232116e-10, Training time:21687.942150115967
batch reward last col mean 1.1633295438073787e-09 first col mean 8.711960597374002e-10 all mean 1.0116974813456636e-08
1.7038043198525088e-10 1.70384539810442e-10
rl training, epoch1, iter0, batch251/1133, batch loss:1.70384539810442e-10, Training time:21715.771867513657
batch reward last col mean 2.033309520754756e-09 first col mean 7.26232096681656e-09 all mean 1.1545757239161958e-08
7.70653763026985e-10 7.706499882687012e-10
rl training, epoch1, iter0, batch252/1133, batch loss:7.706499882687012e-10, Training time:21743.73614883423
batch reward last col mean 5.893747356822132e-07 first col mean 2.0572392678275264e-09 all mean 8.93700136117559e-09
4.130406239255535e-08 4.130406239255535e-08
rl training, epoch1, iter0, batch253/1133, batch loss:4.130406239255535e-08, Training time:21771.655454158783
batch reward last col mean 1.2647528579989853e-09 first col mean 1.6479670961189186e-09 all mean 1.5685298615508714e-09
7.955665987102734e-11 7.955663211545172e-11
rl training, epoch1, iter0, batch254/1133, batch loss:7.955663211545172e-11, Training time:21799.791692495346
batch reward last col mean 3.5421863220364003e-09 first col mean 4.142760801073564e-09 all mean 2.7532917101780185e-07
1.639604718661758e-08 1.63959263943525e-08
rl training, epoch1, iter0, batch255/1133, batch loss:1.63959263943525e-08, Training time:21828.0942132473
batch reward last col mean 4.814788123752578e-09 first col mean 9.960270830333684e-09 all mean 4.50318657385651e-06
3.285292905275128e-06 3.285293587396154e-06
rl training, epoch1, iter0, batch256/1133, batch loss:3.285293587396154e-06, Training time:21856.188831806183
batch reward last col mean 2.1391424187555685e-09 first col mean 1.992255249660957e-09 all mean 2.3777868563001903e-08
3.653005120618502e-10 3.653040092643778e-10
rl training, epoch1, iter0, batch257/1133, batch loss:3.653040092643778e-10, Training time:21884.110528230667
batch reward last col mean 5.8958935511554955e-09 first col mean 4.564658873107419e-09 all mean 2.0867616967734648e-07
1.7626359261058155e-09 1.7627113102491876e-09
rl training, epoch1, iter0, batch258/1133, batch loss:1.7627113102491876e-09, Training time:21911.8675801754
batch reward last col mean 1.0134746375456416e-09 first col mean 1.7458556822447235e-09 all mean 6.712946998277403e-08
1.3946421795196784e-10 1.3948661670148965e-10
rl training, epoch1, iter0, batch259/1133, batch loss:1.3948661670148965e-10, Training time:21939.534742355347
batch reward last col mean 2.4150663691102636e-09 first col mean 2.8734818968700893e-09 all mean 2.674781951483851e-09
1.8119625244672477e-10 1.8119601652433204e-10
rl training, epoch1, iter0, batch260/1133, batch loss:1.8119601652433204e-10, Training time:21967.290187358856
batch reward last col mean 8.22343704243167e-09 first col mean 3.1007063583388117e-09 all mean 1.9658116798382252e-05
1.0616524548368034e-07 1.0616845713684597e-07
rl training, epoch1, iter0, batch261/1133, batch loss:1.0616845713684597e-07, Training time:21994.940277576447
batch reward last col mean 7.836553628237652e-10 first col mean 7.605303835589439e-05 all mean 7.723032808826247e-07
7.381340338952214e-08 7.381350286550514e-08
rl training, epoch1, iter0, batch262/1133, batch loss:7.381350286550514e-08, Training time:22022.855501413345
batch reward last col mean 4.755895233188312e-09 first col mean 3.602800946467255e-09 all mean 5.0254027605944884e-09
3.6831040994833586e-10 3.6831035443718463e-10
rl training, epoch1, iter0, batch263/1133, batch loss:3.6831035443718463e-10, Training time:22050.88399362564
batch reward last col mean 1.0345839655201416e-05 first col mean 2.7594810880771092e-09 all mean 9.93524918158073e-06
9.344778391096042e-07 9.344778391096042e-07
rl training, epoch1, iter0, batch264/1133, batch loss:9.344778391096042e-07, Training time:22078.398378133774
batch reward last col mean 1.587266318381353e-09 first col mean 2.1715151898860086e-09 all mean 2.3512557163485326e-06
4.5743640839646105e-06 4.57436362921726e-06
rl training, epoch1, iter0, batch265/1133, batch loss:4.57436362921726e-06, Training time:22106.301146507263
batch reward last col mean 1.8892885034205165e-09 first col mean 1.4031598105646026e-09 all mean 2.672679855209026e-09
6.872244440181419e-11 6.872252766854103e-11
rl training, epoch1, iter0, batch266/1133, batch loss:6.872252766854103e-11, Training time:22133.730267047882
batch reward last col mean 9.521979871252029e-10 first col mean 1.4641936552095558e-09 all mean 3.8798045665089376e-08
2.447773650438023e-10 2.4478488680479416e-10
rl training, epoch1, iter0, batch267/1133, batch loss:2.4478488680479416e-10, Training time:22161.771082639694
batch reward last col mean 1.9137407214486757e-09 first col mean 1.7252317352500768e-09 all mean 1.9931207795309547e-09
1.8809150070797642e-10 1.88091459074613e-10
rl training, epoch1, iter0, batch268/1133, batch loss:1.88091459074613e-10, Training time:22189.666497945786
batch reward last col mean 4.238092099484447e-09 first col mean 4.815054577278488e-09 all mean 9.050161509094323e-09
2.940837851017619e-10 2.940835908127326e-10
rl training, epoch1, iter0, batch269/1133, batch loss:2.940835908127326e-10, Training time:22217.058387041092
batch reward last col mean 2.4425050426657435e-08 first col mean 8.066421308683402e-09 all mean 2.8089601755709737e-08
6.212438896646688e-10 6.21247053800289e-10
rl training, epoch1, iter0, batch270/1133, batch loss:6.21247053800289e-10, Training time:22244.95814347267
batch reward last col mean 3.90775101166696e-09 first col mean 2.480421423811663e-09 all mean 6.154482701248298e-09
1.11254505608116e-10 1.1125558113667111e-10
rl training, epoch1, iter0, batch271/1133, batch loss:1.1125558113667111e-10, Training time:22272.675025701523
batch reward last col mean 2.7745561403946795e-09 first col mean 1.3136773890920495e-09 all mean 8.004581104614772e-06
4.399876343086362e-05 4.399876343086362e-05
rl training, epoch1, iter0, batch272/1133, batch loss:4.399876343086362e-05, Training time:22300.40553331375
batch reward last col mean 1.2285740424999858e-08 first col mean 5.313176121291008e-09 all mean 5.620376164472418e-09
5.678112979801142e-10 5.678137404707684e-10
rl training, epoch1, iter0, batch273/1133, batch loss:5.678137404707684e-10, Training time:22327.90838766098
batch reward last col mean 3.80746234540652e-09 first col mean 3.2527169846474635e-09 all mean 4.871918424242949e-09
1.7160615983780048e-10 1.7160588228204432e-10
rl training, epoch1, iter0, batch274/1133, batch loss:1.7160588228204432e-10, Training time:22355.29784321785
batch reward last col mean 8.576492849243778e-10 first col mean 4.729600044939275e-10 all mean 8.814978080806668e-09
3.137963847099634e-11 3.137288345778089e-11
rl training, epoch1, iter0, batch275/1133, batch loss:3.137288345778089e-11, Training time:22382.7439289093
batch reward last col mean 1.3154756173250348e-09 first col mean 9.34918253925332e-10 all mean 1.0498197866581904e-08
5.774334829733441e-11 5.773915720541645e-11
rl training, epoch1, iter0, batch276/1133, batch loss:5.773915720541645e-11, Training time:22410.489546775818
batch reward last col mean 7.721927541837204e-10 first col mean 1.0338030431711331e-09 all mean 5.285857973547081e-09
6.460652152151525e-11 6.460310064682062e-11
rl training, epoch1, iter0, batch277/1133, batch loss:6.460310064682062e-11, Training time:22438.43949151039
batch reward last col mean 1.8532930745607246e-09 first col mean 1.3975298696067284e-09 all mean 1.2646252798731439e-05
6.442170956688642e-07 6.442189715016866e-07
rl training, epoch1, iter0, batch278/1133, batch loss:6.442189715016866e-07, Training time:22466.11953997612
batch reward last col mean 7.344945207599096e-10 first col mean 6.606259983499285e-10 all mean 9.190096534439363e-06
8.984248012211538e-08 8.98460115195121e-08
rl training, epoch1, iter0, batch279/1133, batch loss:8.98460115195121e-08, Training time:22493.72786617279
batch reward last col mean 1.194408794091828e-09 first col mean 2.672001286896375e-09 all mean 2.102714002916173e-09
4.7960913018840756e-11 4.7960874854924285e-11
rl training, epoch1, iter0, batch280/1133, batch loss:4.7960874854924285e-11, Training time:22522.067512750626
batch reward last col mean 1.5973339984043378e-08 first col mean 6.953221998173831e-09 all mean 2.330093096247765e-08
1.0580800680060065e-09 1.0580731846232538e-09
rl training, epoch1, iter0, batch281/1133, batch loss:1.0580731846232538e-09, Training time:22549.903651714325
batch reward last col mean 1.5696609567683595e-09 first col mean 1.4355556743339548e-09 all mean 1.3098514500597958e-05
1.644746561169086e-08 1.6443603811922003e-08
rl training, epoch1, iter0, batch282/1133, batch loss:1.6443603811922003e-08, Training time:22577.459523916245
batch reward last col mean 8.869408674172519e-08 first col mean 1.6256263002389915e-09 all mean 2.5228041877767282e-09
7.226135245730347e-09 7.226135245730347e-09
rl training, epoch1, iter0, batch283/1133, batch loss:7.226135245730347e-09, Training time:22605.652487277985
batch reward last col mean 4.0992764738234655e-09 first col mean 2.5788686741634592e-09 all mean 1.2134953976783436e-05
4.373171032057144e-05 4.3731713958550245e-05
rl training, epoch1, iter0, batch284/1133, batch loss:4.3731713958550245e-05, Training time:22633.733870267868
batch reward last col mean 1.491764489713887e-09 first col mean 4.327839420170676e-09 all mean 8.57099351492252e-08
3.084865056734998e-07 3.084865340952092e-07
rl training, epoch1, iter0, batch285/1133, batch loss:3.084865340952092e-07, Training time:22661.368760824203
batch reward last col mean 2.604235049830095e-09 first col mean 2.265575504978301e-09 all mean 1.680077588162021e-08
1.5432118083413826e-10 1.5432553845950991e-10
rl training, epoch1, iter0, batch286/1133, batch loss:1.5432553845950991e-10, Training time:22689.538713932037
batch reward last col mean 1.7904379090438738e-09 first col mean 1.4127788938722574e-09 all mean 2.918999486567486e-09
1.0406996792111656e-10 1.0406964179310307e-10
rl training, epoch1, iter0, batch287/1133, batch loss:1.0406964179310307e-10, Training time:22717.45674777031
batch reward last col mean 2.690266454052903e-09 first col mean 1.0834610986165671e-09 all mean 1.897905832493052e-09
3.6222502775018484e-10 3.6222466692770183e-10
rl training, epoch1, iter0, batch288/1133, batch loss:3.6222466692770183e-10, Training time:22745.59281229973
batch reward last col mean 2.9173272686477958e-09 first col mean 2.2640935792850314e-09 all mean 3.0396833938795e-09
8.602344531150052e-11 8.602343837260662e-11
rl training, epoch1, iter0, batch289/1133, batch loss:8.602343837260662e-11, Training time:22773.208172559738
batch reward last col mean 2.9684170677057864e-09 first col mean 2.071460336594555e-09 all mean 1.4780552781701317e-08
2.0315372994961223e-10 2.031439183536321e-10
rl training, epoch1, iter0, batch290/1133, batch loss:2.031439183536321e-10, Training time:22800.75717306137
batch reward last col mean 4.770780659413276e-09 first col mean 2.1690518270389703e-09 all mean 6.931794160891513e-08
2.689331424221564e-09 2.689301448199899e-09
rl training, epoch1, iter0, batch291/1133, batch loss:2.689301448199899e-09, Training time:22828.797142267227
batch reward last col mean 5.221598264881777e-09 first col mean 3.917343782688931e-09 all mean 9.438917203397068e-09
1.256090231827045e-10 1.2560764928171153e-10
rl training, epoch1, iter0, batch292/1133, batch loss:1.2560764928171153e-10, Training time:22856.394310235977
batch reward last col mean 4.828318300731382e-10 first col mean 3.751760959858075e-05 all mean 8.726086889510043e-06
1.2105044788768282e-06 1.2105068663004204e-06
rl training, epoch1, iter0, batch293/1133, batch loss:1.2105068663004204e-06, Training time:22883.97768831253
batch reward last col mean 2.2381472231103317e-09 first col mean 0.0014872741885483265 all mean 3.407715485082008e-05
6.413717346731573e-05 6.413717346731573e-05
rl training, epoch1, iter0, batch294/1133, batch loss:6.413717346731573e-05, Training time:22912.643617153168
batch reward last col mean 1.1470216998432647e-09 first col mean 2.6783497641957865e-09 all mean 1.345330402635625e-09
7.647887184658586e-11 7.647878164096511e-11
rl training, epoch1, iter0, batch295/1133, batch loss:7.647878164096511e-11, Training time:22940.972671985626
batch reward last col mean 2.9674620236619376e-05 first col mean 1.4691201588590275e-09 all mean 2.6082847398356535e-05
2.5852236831269693e-06 2.5852236831269693e-06
rl training, epoch1, iter0, batch296/1133, batch loss:2.5852236831269693e-06, Training time:22968.704496383667
batch reward last col mean 1.2313892128190673e-09 first col mean 1.2076875055555547e-09 all mean 1.3775194318554895e-09
1.3430324907748314e-10 1.3430327683305876e-10
rl training, epoch1, iter0, batch297/1133, batch loss:1.3430327683305876e-10, Training time:22996.640575408936
batch reward last col mean 0.002243987750262022 first col mean 0.0014833734603598714 all mean 0.0021683056838810444
0.00020867917919531465 0.0002086792082991451
rl training, epoch1, iter0, batch298/1133, batch loss:0.0002086792082991451, Training time:23024.846705675125
batch reward last col mean 1.8581650662596871e-09 first col mean 9.866382155720999e-10 all mean 1.97857663586376e-09
6.404153596317741e-11 6.404147351313227e-11
rl training, epoch1, iter0, batch299/1133, batch loss:6.404147351313227e-11, Training time:23052.984291791916
batch reward last col mean 4.954645582699868e-09 first col mean 2.972570856130119e-09 all mean 5.138654390890451e-09
1.4342482757001562e-10 1.4342482757001562e-10
rl training, epoch1, iter0, batch300/1133, batch loss:1.4342482757001562e-10, Training time:23081.401073932648
batch reward last col mean 2.6650339712830373e-09 first col mean 7.279290503703351e-09 all mean 1.2691998563241214e-08
1.7021080378487596e-10 1.702099711176075e-10
rl training, epoch1, iter0, batch301/1133, batch loss:1.702099711176075e-10, Training time:23110.836213111877
batch reward last col mean 1.090466161812742e-09 first col mean 1.2447579633700911e-09 all mean 5.4852093853696715e-06
2.602347194624599e-05 2.602347194624599e-05
rl training, epoch1, iter0, batch302/1133, batch loss:2.602347194624599e-05, Training time:23139.30566430092
batch reward last col mean 7.748202635049495e-10 first col mean 2.8196258661239426e-09 all mean 2.467164250674614e-09
9.243958376536909e-11 9.243911885947753e-11
rl training, epoch1, iter0, batch303/1133, batch loss:9.243911885947753e-11, Training time:23167.12042760849
batch reward last col mean 9.173772852477668e-10 first col mean 1.3438758994510636e-09 all mean 4.515613660771578e-09
4.435565803539987e-11 4.4357763989699706e-11
rl training, epoch1, iter0, batch304/1133, batch loss:4.4357763989699706e-11, Training time:23194.777799844742
batch reward last col mean 1.0582419385229969e-09 first col mean 1.6312533546170016e-09 all mean 7.892865141911898e-06
8.375587867703871e-08 8.375885585110154e-08
rl training, epoch1, iter0, batch305/1133, batch loss:8.375885585110154e-08, Training time:23222.43139743805
batch reward last col mean 7.536914425898544e-10 first col mean 7.314372441058481e-10 all mean 3.645812318708863e-09
8.766604803200906e-11 8.766712356056416e-11
rl training, epoch1, iter0, batch306/1133, batch loss:8.766712356056416e-11, Training time:23250.01540827751
batch reward last col mean 1.4140335569123863e-09 first col mean 0.0007574944756925106 all mean 7.654055480088573e-06
5.588829662883654e-05 5.588829662883654e-05
rl training, epoch1, iter0, batch307/1133, batch loss:5.588829662883654e-05, Training time:23277.72979950905
batch reward last col mean 6.498873661442417e-10 first col mean 7.189462358780929e-10 all mean 8.179205090996788e-10
4.4515446884219045e-11 4.451536708693915e-11
rl training, epoch1, iter0, batch308/1133, batch loss:4.451536708693915e-11, Training time:23305.289662599564
batch reward last col mean 1.923587511498681e-09 first col mean 0.00040029833326116204 all mean 4.046059530082857e-06
1.5956366894442908e-08 1.595760323880313e-08
rl training, epoch1, iter0, batch309/1133, batch loss:1.595760323880313e-08, Training time:23333.30291390419
batch reward last col mean 8.531518269627725e-10 first col mean 1.0493992341764624e-09 all mean 1.0124548680323642e-05
1.1822084644563802e-07 1.1822116618986911e-07
rl training, epoch1, iter0, batch310/1133, batch loss:1.1822116618986911e-07, Training time:23361.376930236816
batch reward last col mean 1.1210252726101544e-09 first col mean 1.9266250816940556e-09 all mean 2.778520080681801e-09
8.301435927560163e-11 8.301444254232848e-11
rl training, epoch1, iter0, batch311/1133, batch loss:8.301444254232848e-11, Training time:23388.901445388794
batch reward last col mean 3.1129046007549732e-09 first col mean 2.34251240627259e-09 all mean 3.4719340735733795e-09
8.44996642102025e-11 8.449990707148913e-11
rl training, epoch1, iter0, batch312/1133, batch loss:8.449990707148913e-11, Training time:23417.188812732697
batch reward last col mean 1.0693954610729861e-09 first col mean 1.5010560572292775e-09 all mean 4.386340624051854e-09
6.274480240930913e-11 6.274533670413973e-11
rl training, epoch1, iter0, batch313/1133, batch loss:6.274533670413973e-11, Training time:23445.646924972534
batch reward last col mean 3.5515272944763865e-09 first col mean 3.428061834398477e-09 all mean 4.692923994298326e-06
4.1640350900706835e-06 4.164035999565385e-06
rl training, epoch1, iter0, batch314/1133, batch loss:4.164035999565385e-06, Training time:23472.97064757347
batch reward last col mean 8.619200908555058e-10 first col mean 9.00024332839422e-10 all mean 1.2665364312880456e-09
6.001821956092002e-11 6.001825425538954e-11
rl training, epoch1, iter0, batch315/1133, batch loss:6.001825425538954e-11, Training time:23500.806170463562
batch reward last col mean 2.0204971029613716e-09 first col mean 2.5187869567844245e-09 all mean 3.0345909181050956e-06
1.0915818471346483e-08 1.0915195858274274e-08
rl training, epoch1, iter0, batch316/1133, batch loss:1.0915195858274274e-08, Training time:23528.291032075882
batch reward last col mean 5.049366258447208e-09 first col mean 3.903069423216721e-09 all mean 7.053892137065532e-09
1.4621361066335936e-10 1.46212986162908e-10
rl training, epoch1, iter0, batch317/1133, batch loss:1.46212986162908e-10, Training time:23555.958916902542
batch reward last col mean 1.7985827271971289e-09 first col mean 2.858469239086503e-09 all mean 2.2631454488220015e-09
1.9561016695313072e-10 1.956101530753429e-10
rl training, epoch1, iter0, batch318/1133, batch loss:1.956101530753429e-10, Training time:23583.526166915894
batch reward last col mean 2.0602803907365796e-09 first col mean 2.7315705253272426e-09 all mean 2.1220534662802493e-08
2.1167180508374628e-10 2.116714858946267e-10
rl training, epoch1, iter0, batch319/1133, batch loss:2.116714858946267e-10, Training time:23611.133906126022
batch reward last col mean 1.0820594420479779e-09 first col mean 0.0005176574341021478 all mean 7.82787537900731e-06
4.2958323120956265e-08 4.2958536283776994e-08
rl training, epoch1, iter0, batch320/1133, batch loss:4.2958536283776994e-08, Training time:23638.521971464157
batch reward last col mean 1.751318645659694e-09 first col mean 1.6366945576606895e-09 all mean 1.7678821677691303e-05
5.5623491789447144e-05 5.562348451348953e-05
rl training, epoch1, iter0, batch321/1133, batch loss:5.562348451348953e-05, Training time:23665.897929906845
batch reward last col mean 3.775935120131635e-09 first col mean 0.0001733430108288303 all mean 2.0209130525472574e-05
1.3649780328250927e-07 1.3650037544721272e-07
rl training, epoch1, iter0, batch322/1133, batch loss:1.3650037544721272e-07, Training time:23693.38468813896
batch reward last col mean 5.551160864314397e-09 first col mean 3.6664358216143e-09 all mean 5.716958462187449e-09
9.100627890168411e-11 9.100635522951706e-11
rl training, epoch1, iter0, batch323/1133, batch loss:9.100635522951706e-11, Training time:23720.65919113159
batch reward last col mean 3.962382866262715e-09 first col mean 4.008743559325012e-09 all mean 6.46348619071091e-09
2.30608199203175e-10 2.3060996168222658e-10
rl training, epoch1, iter0, batch324/1133, batch loss:2.3060996168222658e-10, Training time:23748.13952064514
batch reward last col mean 2.221741013386236e-09 first col mean 2.6986199941347877e-09 all mean 6.627171700301915e-08
1.2409065441865152e-10 1.240641339661508e-10
rl training, epoch1, iter0, batch325/1133, batch loss:1.240641339661508e-10, Training time:23775.69807291031
batch reward last col mean 1.998987197993074e-09 first col mean 1.7725694245740442e-09 all mean 7.227868081827182e-09
1.6439684336067018e-10 1.6439202776830086e-10
rl training, epoch1, iter0, batch326/1133, batch loss:1.6439202776830086e-10, Training time:23803.3257188797
batch reward last col mean 2.3885844413484847e-09 first col mean 3.6393847935300982e-09 all mean 1.2820750328046415e-07
1.2287267869837137e-09 1.2287543205147244e-09
rl training, epoch1, iter0, batch327/1133, batch loss:1.2287543205147244e-09, Training time:23830.835785865784
batch reward last col mean 1.1691290158211132e-09 first col mean 1.1695441282100205e-09 all mean 7.828453441049987e-09
3.2106423075717316e-10 3.2106631242534434e-10
rl training, epoch1, iter0, batch328/1133, batch loss:3.2106631242534434e-10, Training time:23858.27973794937
batch reward last col mean 1.758381107386242e-09 first col mean 0.000900571933016181 all mean 9.098718692257535e-06
2.5308843760285527e-05 2.5308843760285527e-05
rl training, epoch1, iter0, batch329/1133, batch loss:2.5308843760285527e-05, Training time:23885.631089687347
batch reward last col mean 2.6514774820185494e-09 first col mean 2.4779265306307252e-09 all mean 2.446732651151251e-06
1.6269829927750834e-08 1.6268842273348127e-08
rl training, epoch1, iter0, batch330/1133, batch loss:1.6268842273348127e-08, Training time:23912.879096508026
batch reward last col mean 8.938970119665157e-10 first col mean 8.538512674682863e-10 all mean 6.205923597235596e-08
3.2110700765031197e-09 3.2110609726743178e-09
rl training, epoch1, iter0, batch331/1133, batch loss:3.2110609726743178e-09, Training time:23940.06308364868
batch reward last col mean 2.0102763897966724e-09 first col mean 1.6233917543573284e-09 all mean 2.1553069018409587e-06
1.0436430386562279e-07 1.0436519914946984e-07
rl training, epoch1, iter0, batch332/1133, batch loss:1.0436519914946984e-07, Training time:23967.187509298325
batch reward last col mean 1.2516673253415433e-09 first col mean 2.1161294938565334e-09 all mean 2.213334626688379e-09
1.0500957742243244e-10 1.0500924435552506e-10
rl training, epoch1, iter0, batch333/1133, batch loss:1.0500924435552506e-10, Training time:23994.692833662033
batch reward last col mean 1.4656986735417377e-09 first col mean 1.3630615525173084e-09 all mean 2.8738247337400935e-09
9.623351421295112e-11 9.623251501222896e-11
rl training, epoch1, iter0, batch334/1133, batch loss:9.623251501222896e-11, Training time:24022.091620206833
batch reward last col mean 9.841573112012725e-10 first col mean 2.6211013359755952e-09 all mean 1.2405743099463962e-09
6.561494403367618e-11 6.561488852252495e-11
rl training, epoch1, iter0, batch335/1133, batch loss:6.561488852252495e-11, Training time:24049.42049908638
batch reward last col mean 1.263632753989441e-09 first col mean 1.1669221144927633e-09 all mean 5.319510609780309e-09
1.19145943111576e-10 1.1914440267712934e-10
rl training, epoch1, iter0, batch336/1133, batch loss:1.1914440267712934e-10, Training time:24077.212220668793
batch reward last col mean 1.5716384860198218e-09 first col mean 1.111021052935257e-09 all mean 5.469623420850667e-09
1.8087090158935837e-10 1.8086933339933609e-10
rl training, epoch1, iter0, batch337/1133, batch loss:1.8086933339933609e-10, Training time:24105.05647277832
batch reward last col mean 1.4363092937230704e-09 first col mean 1.3764764883461567e-09 all mean 8.57020410194309e-09
8.80859413188162e-11 8.808617724120893e-11
rl training, epoch1, iter0, batch338/1133, batch loss:8.808617724120893e-11, Training time:24132.63431096077
batch reward last col mean 1.8773287369100444e-09 first col mean 2.191003156681859e-09 all mean 1.350028469460085e-06
5.700817382603418e-07 5.700820224774361e-07
rl training, epoch1, iter0, batch339/1133, batch loss:5.700820224774361e-07, Training time:24160.717490673065
batch reward last col mean 8.628838199520317e-10 first col mean 8.637767168195865e-10 all mean 6.699648906760558e-07
7.951036309350457e-07 7.951038014653022e-07
rl training, epoch1, iter0, batch340/1133, batch loss:7.951038014653022e-07, Training time:24188.588624238968
batch reward last col mean 1.2519866254834255e-09 first col mean 0.0011499770916998386 all mean 1.1620245459198486e-05
2.0939955547305544e-08 2.092954431986982e-08
rl training, epoch1, iter0, batch341/1133, batch loss:2.092954431986982e-08, Training time:24216.22260904312
batch reward last col mean 1.003826621825965e-08 first col mean 2.9363871334453506e-09 all mean 2.7514249723026296e-07
1.417274964055082e-09 1.4173240359127703e-09
rl training, epoch1, iter0, batch342/1133, batch loss:1.4173240359127703e-09, Training time:24243.93650984764
batch reward last col mean 7.275101410186835e-09 first col mean 4.7174877337852195e-09 all mean 8.382612826096647e-09
4.702124800637364e-10 4.70212868641795e-10
rl training, epoch1, iter0, batch343/1133, batch loss:4.70212868641795e-10, Training time:24271.74256181717
batch reward last col mean 3.031605633196932e-09 first col mean 5.7113975344691426e-05 all mean 1.1206127965124324e-05
1.2942152238792914e-07 1.2941897864493512e-07
rl training, epoch1, iter0, batch344/1133, batch loss:1.2941897864493512e-07, Training time:24299.653741121292
batch reward last col mean 2.816710864550487e-09 first col mean 1.3193021120017079e-09 all mean 5.749060960624774e-07
7.750526265226654e-08 7.750532660111276e-08
rl training, epoch1, iter0, batch345/1133, batch loss:7.750532660111276e-08, Training time:24328.043784856796
batch reward last col mean 1.6260494062336761e-09 first col mean 1.5632968253243007e-09 all mean 1.0613561016725725e-06
1.4067896927372203e-06 1.4067892379898694e-06
rl training, epoch1, iter0, batch346/1133, batch loss:1.4067892379898694e-06, Training time:24355.441719532013
batch reward last col mean 1.4064688302894979e-09 first col mean 1.592650455961575e-09 all mean 1.0378065553595661e-06
8.155137038556859e-06 8.155137038556859e-06
rl training, epoch1, iter0, batch347/1133, batch loss:8.155137038556859e-06, Training time:24383.13508462906
batch reward last col mean 1.971812935153139e-09 first col mean 2.273024435339721e-09 all mean 2.2604853544549997e-09
1.2898943024808318e-10 1.289894718814466e-10
rl training, epoch1, iter0, batch348/1133, batch loss:1.289894718814466e-10, Training time:24411.61975979805
batch reward last col mean 0.006982018705457449 first col mean 1.0559583207836454e-09 all mean 0.006629405077546835
0.00033655116567388177 0.00033655116567388177
rl training, epoch1, iter0, batch349/1133, batch loss:0.00033655116567388177, Training time:24439.743015766144
batch reward last col mean 6.241685834851296e-09 first col mean 5.457668539321503e-09 all mean 1.3802396559015051e-08
2.5124757829786404e-10 2.5125010405524506e-10
rl training, epoch1, iter0, batch350/1133, batch loss:2.5125010405524506e-10, Training time:24467.078322172165
batch reward last col mean 1.5328151192761652e-08 first col mean 1.0856551213578314e-08 all mean 3.934300366381649e-06
1.8780739992507733e-05 1.8780739992507733e-05
rl training, epoch1, iter0, batch351/1133, batch loss:1.8780739992507733e-05, Training time:24495.242161035538
batch reward last col mean 1.8823462788475354e-09 first col mean 1.9373285198298618e-09 all mean 2.348888727965459e-08
1.58946272810212e-10 1.589563897175239e-10
rl training, epoch1, iter0, batch352/1133, batch loss:1.589563897175239e-10, Training time:24522.85836338997
batch reward last col mean 3.349751054315675e-08 first col mean 1.4359744504588434e-09 all mean 1.0076265155589681e-08
2.304381219175866e-08 2.304381219175866e-08
rl training, epoch1, iter0, batch353/1133, batch loss:2.304381219175866e-08, Training time:24550.727093696594
batch reward last col mean 1.6655229417850137e-09 first col mean 1.9906598591745706e-09 all mean 4.539546072379608e-09
5.7599942177022356e-11 5.7600136466051666e-11
rl training, epoch1, iter0, batch354/1133, batch loss:5.7600136466051666e-11, Training time:24578.635125637054
batch reward last col mean 3.599617457439308e-07 first col mean 2.6548587772623478e-09 all mean 8.528520112349725e-09
3.659742020545309e-08 3.659742375816677e-08
rl training, epoch1, iter0, batch355/1133, batch loss:3.659742375816677e-08, Training time:24607.522896528244
batch reward last col mean 1.894632450927247e-09 first col mean 1.7310562983041677e-09 all mean 2.012398025996731e-09
8.026924958048909e-11 8.026918713044395e-11
rl training, epoch1, iter0, batch356/1133, batch loss:8.026918713044395e-11, Training time:24635.377495527267
batch reward last col mean 2.0616812701490517e-09 first col mean 1.489663392639784e-09 all mean 7.723219823674299e-07
7.126575329863272e-09 7.126628620568454e-09
rl training, epoch1, iter0, batch357/1133, batch loss:7.126628620568454e-09, Training time:24662.617028474808
batch reward last col mean 3.847840268633718e-09 first col mean 2.1256507665157187e-09 all mean 3.744876408973141e-09
1.3809201004910676e-10 1.380918851490165e-10
rl training, epoch1, iter0, batch358/1133, batch loss:1.380918851490165e-10, Training time:24690.47362947464
batch reward last col mean 8.475256052520308e-10 first col mean 8.088469893863248e-10 all mean 1.9413337604134995e-09
5.865815472239078e-11 5.865727348286498e-11
rl training, epoch1, iter0, batch359/1133, batch loss:5.865727348286498e-11, Training time:24718.057940006256
batch reward last col mean 1.684783090816211e-09 first col mean 4.243987383745207e-09 all mean 6.618904091482136e-09
8.3423476460176e-11 8.342372626035655e-11
rl training, epoch1, iter0, batch360/1133, batch loss:8.342372626035655e-11, Training time:24745.57404255867
batch reward last col mean 2.59808841107656e-09 first col mean 1.2361640600033752e-08 all mean 4.6244803542094814e-09
2.1342586031813937e-10 2.1342511091759775e-10
rl training, epoch1, iter0, batch361/1133, batch loss:2.1342511091759775e-10, Training time:24773.773529291153
batch reward last col mean 8.577354382310887e-10 first col mean 8.49867137731053e-06 all mean 1.60669533215696e-05
1.2510879798810493e-07 1.251048473704941e-07
rl training, epoch1, iter0, batch362/1133, batch loss:1.251048473704941e-07, Training time:24801.480902194977
batch reward last col mean 2.919716468596789e-09 first col mean 2.018407663229027e-09 all mean 1.904763666971121e-05
7.760247171972878e-06 7.760248990962282e-06
rl training, epoch1, iter0, batch363/1133, batch loss:7.760248990962282e-06, Training time:24829.26218509674
batch reward last col mean 2.378540475689306e-09 first col mean 9.055382577116688e-08 all mean 3.4287412908895476e-09
7.767148035853211e-11 7.76718273032273e-11
rl training, epoch1, iter0, batch364/1133, batch loss:7.76718273032273e-11, Training time:24857.20956134796
batch reward last col mean 2.2683115386001873e-09 first col mean 4.5991466322448105e-05 all mean 4.700142994806811e-07
8.246560412317194e-08 8.246546201462479e-08
rl training, epoch1, iter0, batch365/1133, batch loss:8.246546201462479e-08, Training time:24884.959638357162
batch reward last col mean 2.6168325284459115e-09 first col mean 3.69444030923205e-09 all mean 9.444670823199885e-09
1.0112848058962953e-10 1.0112873038981007e-10
rl training, epoch1, iter0, batch366/1133, batch loss:1.0112873038981007e-10, Training time:24912.866074085236
batch reward last col mean 9.743961193464656e-10 first col mean 1.1042732284138879e-09 all mean 1.4121500413466492e-08
6.170905453295461e-11 6.16998049873807e-11
rl training, epoch1, iter0, batch367/1133, batch loss:6.16998049873807e-11, Training time:24940.84868979454
batch reward last col mean 3.3113107811288955e-09 first col mean 5.880398390445407e-09 all mean 1.5455389075214043e-05
4.533462561084889e-05 4.5334618334891275e-05
rl training, epoch1, iter0, batch368/1133, batch loss:4.5334618334891275e-05, Training time:24968.33287358284
batch reward last col mean 1.6699009952603205e-09 first col mean 1.8230817966369273e-09 all mean 7.2174693741544615e-06
1.5063790669955779e-05 1.5063790669955779e-05
rl training, epoch1, iter0, batch369/1133, batch loss:1.5063790669955779e-05, Training time:24995.797810316086
batch reward last col mean 1.4361483113844997e-09 first col mean 1.0514304982223166e-09 all mean 3.450465468901598e-09
6.714969552623629e-11 6.715013267655223e-11
rl training, epoch1, iter0, batch370/1133, batch loss:6.715013267655223e-11, Training time:25023.53829240799
batch reward last col mean 1.043453101701175e-09 first col mean 1.628965629052459e-09 all mean 1.5277713538708326e-09
9.737155526323704e-11 9.73716662855395e-11
rl training, epoch1, iter0, batch371/1133, batch loss:9.73716662855395e-11, Training time:25051.987735271454
batch reward last col mean 3.257842884352158e-09 first col mean 2.9448881111449055e-09 all mean 1.1788757525721394e-08
1.7243562133728574e-10 1.7243113881182381e-10
rl training, epoch1, iter0, batch372/1133, batch loss:1.7243113881182381e-10, Training time:25079.482362747192
batch reward last col mean 9.940701595212431e-10 first col mean 2.210911675959437e-09 all mean 1.921153670991771e-05
1.7978829419007525e-05 1.797882760001812e-05
rl training, epoch1, iter0, batch373/1133, batch loss:1.797882760001812e-05, Training time:25107.16133737564
batch reward last col mean 3.640454826481232e-09 first col mean 9.169673909070752e-10 all mean 2.925204171333462e-06
7.15311898602522e-08 7.152982561819954e-08
rl training, epoch1, iter0, batch374/1133, batch loss:7.152982561819954e-08, Training time:25134.64336013794
batch reward last col mean 9.049333504762558e-10 first col mean 2.576197948656045e-05 all mean 2.616867220694985e-07
8.260558388428763e-07 8.260557819994574e-07
rl training, epoch1, iter0, batch375/1133, batch loss:8.260557819994574e-07, Training time:25162.436949014664
batch reward last col mean 6.790216167118501e-10 first col mean 1.0278462525548093e-09 all mean 1.215313183422495e-09
8.91688875515051e-11 8.916875571252092e-11
rl training, epoch1, iter0, batch376/1133, batch loss:8.916875571252092e-11, Training time:25189.974845647812
batch reward last col mean 2.0696970803868453e-09 first col mean 3.2478795208845668e-09 all mean 8.170285781261555e-09
5.926845125792113e-10 5.92683013778128e-10
rl training, epoch1, iter0, batch377/1133, batch loss:5.92683013778128e-10, Training time:25218.176983118057
batch reward last col mean 1.8114637567734349e-09 first col mean 1.982483288642811e-09 all mean 1.8578178995198869e-09
5.488113782869952e-11 5.488109966478305e-11
rl training, epoch1, iter0, batch378/1133, batch loss:5.488109966478305e-11, Training time:25246.048223733902
batch reward last col mean 2.571852952826248e-09 first col mean 1.556758943976888e-09 all mean 2.353310992475599e-05
9.666472033131868e-05 9.666472033131868e-05
rl training, epoch1, iter0, batch379/1133, batch loss:9.666472033131868e-05, Training time:25273.741038799286
batch reward last col mean 2.8083890768471065e-09 first col mean 3.413432869692201e-09 all mean 2.942605714650881e-09
1.7589729672806698e-10 1.7589725509470355e-10
rl training, epoch1, iter0, batch380/1133, batch loss:1.7589725509470355e-10, Training time:25302.09782075882
batch reward last col mean 2.01462246884887e-09 first col mean 1.457641785052033e-09 all mean 2.021313116884471e-09
9.7228870787891e-11 9.722889160457271e-11
rl training, epoch1, iter0, batch381/1133, batch loss:9.722889160457271e-11, Training time:25329.64896440506
batch reward last col mean 5.601241248598399e-09 first col mean 4.252344698585375e-09 all mean 2.339163802389521e-05
1.8781113908517e-07 1.8780967536713433e-07
rl training, epoch1, iter0, batch382/1133, batch loss:1.8780967536713433e-07, Training time:25357.607707738876
batch reward last col mean 1.951384831500036e-09 first col mean 3.607572685027094e-09 all mean 5.864274044142803e-06
2.7235755624133162e-06 2.7235755624133162e-06
rl training, epoch1, iter0, batch383/1133, batch loss:2.7235755624133162e-06, Training time:25385.597184419632
batch reward last col mean 2.441655988505431e-09 first col mean 2.4834645451221604e-09 all mean 2.7972899260930717e-05
1.371199596178485e-05 1.371199050481664e-05
rl training, epoch1, iter0, batch384/1133, batch loss:1.371199050481664e-05, Training time:25413.746464967728
batch reward last col mean 2.9107027899044624e-09 first col mean 4.7807908742925065e-09 all mean 4.2860852644821534e-09
1.2783286928996773e-10 1.2783259173421158e-10
rl training, epoch1, iter0, batch385/1133, batch loss:1.2783259173421158e-10, Training time:25442.523226499557
batch reward last col mean 3.738790166352146e-09 first col mean 2.970580448291571e-09 all mean 3.158114486723207e-05
4.920461287838407e-05 4.9204616516362876e-05
rl training, epoch1, iter0, batch386/1133, batch loss:4.9204616516362876e-05, Training time:25470.203473091125
batch reward last col mean 2.1525263793620297e-09 first col mean 2.290306833074851e-09 all mean 1.9420658645685762e-05
5.619828152703121e-05 5.619828152703121e-05
rl training, epoch1, iter0, batch387/1133, batch loss:5.619828152703121e-05, Training time:25498.682213544846
batch reward last col mean 2.3706838714332434e-09 first col mean 3.584520680277592e-09 all mean 3.2844469366466456e-09
8.820177921364802e-11 8.820135594111989e-11
rl training, epoch1, iter0, batch388/1133, batch loss:8.820135594111989e-11, Training time:25526.70487833023
batch reward last col mean 6.294344490065384e-10 first col mean 1.41820588606123e-09 all mean 1.6553681092545958e-08
4.62127475175933e-10 4.6212716986460123e-10
rl training, epoch1, iter0, batch389/1133, batch loss:4.6212716986460123e-10, Training time:25554.088452339172
batch reward last col mean 9.945023693447297e-10 first col mean 1.145891159737289e-09 all mean 1.4741379672500443e-08
4.379614379490526e-11 4.379752810423909e-11
rl training, epoch1, iter0, batch390/1133, batch loss:4.379752810423909e-11, Training time:25581.68582224846
batch reward last col mean 2.2880897176946746e-09 first col mean 2.2658164233746447e-09 all mean 1.8905848264694214e-05
2.5532430299790576e-05 2.5532424842822365e-05
rl training, epoch1, iter0, batch391/1133, batch loss:2.5532424842822365e-05, Training time:25609.413239240646
batch reward last col mean 9.652032506579644e-10 first col mean 2.5825941385448914e-09 all mean 1.4789555358163398e-08
4.2830905488955295e-11 4.283565169238557e-11
rl training, epoch1, iter0, batch392/1133, batch loss:4.283565169238557e-11, Training time:25637.01824426651
batch reward last col mean 1.9784716087656307e-09 first col mean 9.828617031359954e-09 all mean 4.8182697831578025e-09
1.2574695451572637e-10 1.2574757901617772e-10
rl training, epoch1, iter0, batch393/1133, batch loss:1.2574757901617772e-10, Training time:25664.924530506134
batch reward last col mean 2.1515345061118296e-09 first col mean 0.0014911352191120386 all mean 1.5063988939800765e-05
1.6039605554851732e-07 1.603989403520245e-07
rl training, epoch1, iter0, batch394/1133, batch loss:1.603989403520245e-07, Training time:25692.687509059906
batch reward last col mean 8.027147835321102e-09 first col mean 6.3293446039836e-09 all mean 1.0150070295367186e-07
7.508226929076045e-09 7.508245580822859e-09
rl training, epoch1, iter0, batch395/1133, batch loss:7.508245580822859e-09, Training time:25720.423840761185
batch reward last col mean 4.884181947772959e-09 first col mean 0.000575559854041785 all mean 5.818512363475747e-06
3.9784040950507915e-08 3.9782978689117954e-08
rl training, epoch1, iter0, batch396/1133, batch loss:3.9782978689117954e-08, Training time:25747.96756196022
batch reward last col mean 3.0707452136624624e-09 first col mean 5.2213393608724346e-09 all mean 1.4009896403877065e-05
2.005923107617491e-07 2.0058861593952315e-07
rl training, epoch1, iter0, batch397/1133, batch loss:2.0058861593952315e-07, Training time:25775.578159332275
batch reward last col mean 1.4234736722684715e-09 first col mean 2.9331481528060976e-06 all mean 3.887086208465007e-08
2.0653321541885816e-07 2.065332438405676e-07
rl training, epoch1, iter0, batch398/1133, batch loss:2.065332438405676e-07, Training time:25803.045792102814
batch reward last col mean 9.46924094691326e-10 first col mean 1.0789528159804718e-09 all mean 4.267522335510421e-09
5.666719177233048e-11 5.6665901138064356e-11
rl training, epoch1, iter0, batch399/1133, batch loss:5.6665901138064356e-11, Training time:25830.864169359207
batch reward last col mean 3.790306735140803e-09 first col mean 6.986406564379877e-09 all mean 4.54119675197262e-09
9.544531137661849e-11 9.544540852113315e-11
rl training, epoch1, iter0, batch400/1133, batch loss:9.544540852113315e-11, Training time:25858.708896160126
batch reward last col mean 9.794575150934293e-10 first col mean 1.0981779929863933e-09 all mean 2.535627041666544e-09
2.997809292470954e-11 2.9977721693885684e-11
rl training, epoch1, iter0, batch401/1133, batch loss:2.9977721693885684e-11, Training time:25886.26197195053
batch reward last col mean 1.33992386963655e-07 first col mean 1.2403914562142404e-09 all mean 4.509184137191369e-09
1.1166513935734201e-08 1.1166513047555782e-08
rl training, epoch1, iter0, batch402/1133, batch loss:1.1166513047555782e-08, Training time:25914.638535499573
batch reward last col mean 1.3583736357958287e-09 first col mean 0.00019587729184422642 all mean 1.9826454717986053e-06
1.945312888551598e-08 1.945242011913706e-08
rl training, epoch1, iter0, batch403/1133, batch loss:1.945242011913706e-08, Training time:25942.07480430603
batch reward last col mean 1.5554866283906676e-09 first col mean 2.4985971069924062e-09 all mean 5.4998259280125694e-09
7.73161118461374e-11 7.731517509546038e-11
rl training, epoch1, iter0, batch404/1133, batch loss:7.731517509546038e-11, Training time:25969.977870941162
batch reward last col mean 3.988375851804449e-09 first col mean 1.940813731948765e-09 all mean 3.99921296079242e-09
1.2336218158104373e-10 1.2336226484777058e-10
rl training, epoch1, iter0, batch405/1133, batch loss:1.2336226484777058e-10, Training time:25998.078805923462
batch reward last col mean 2.4481896510053502e-09 first col mean 1.6253001167143566e-09 all mean 3.6658476254558536e-09
1.2709878982608558e-10 1.2709824859236107e-10
rl training, epoch1, iter0, batch406/1133, batch loss:1.2709824859236107e-10, Training time:26026.01416039467
batch reward last col mean 1.8128519796434261e-09 first col mean 0.0012229608837515116 all mean 1.2355247235973366e-05
1.257679116406507e-07 1.2577162067373138e-07
rl training, epoch1, iter0, batch407/1133, batch loss:1.2577162067373138e-07, Training time:26053.39285135269
batch reward last col mean 2.1925050663895718e-09 first col mean 1.8734394036101776e-09 all mean 2.5491299311397597e-06
6.023381238229319e-10 6.027389698459729e-10
rl training, epoch1, iter0, batch408/1133, batch loss:6.027389698459729e-10, Training time:26081.151903629303
batch reward last col mean 2.292209089205244e-09 first col mean 3.4589258124384514e-09 all mean 3.620868665166199e-05
1.0218230954706087e-06 1.0218298029940343e-06
rl training, epoch1, iter0, batch409/1133, batch loss:1.0218298029940343e-06, Training time:26108.93389582634
batch reward last col mean 1.375007996351485e-09 first col mean 5.1486822485458106e-05 all mean 5.215911755840352e-07
2.4365829176531406e-07 2.436580643916386e-07
rl training, epoch1, iter0, batch410/1133, batch loss:2.436580643916386e-07, Training time:26136.62780404091
batch reward last col mean 1.0880803813506645e-08 first col mean 1.006477479137402e-08 all mean 3.909940815560731e-08
3.036584039772805e-10 3.0366137382387137e-10
rl training, epoch1, iter0, batch411/1133, batch loss:3.0366137382387137e-10, Training time:26164.565908670425
batch reward last col mean 1.274227390268834e-09 first col mean 3.814359661191702e-05 all mean 5.943820156062429e-07
7.195793614300783e-07 7.195792477432406e-07
rl training, epoch1, iter0, batch412/1133, batch loss:7.195792477432406e-07, Training time:26192.31093597412
batch reward last col mean 2.764970030710856e-09 first col mean 0.0018796799704432487 all mean 2.2816966520622373e-05
3.7611357583955396e-07 3.761133484658785e-07
rl training, epoch1, iter0, batch413/1133, batch loss:3.761133484658785e-07, Training time:26220.117290735245
batch reward last col mean 1.145366912425061e-09 first col mean 2.449321190312048e-09 all mean 7.950740155138192e-07
1.755800482783343e-08 1.755785561385892e-08
rl training, epoch1, iter0, batch414/1133, batch loss:1.755785561385892e-08, Training time:26247.77803993225
batch reward last col mean 8.68303762224798e-10 first col mean 2.089216577516595e-09 all mean 3.1712108494730273e-09
6.047338324544071e-11 6.047342487880414e-11
rl training, epoch1, iter0, batch415/1133, batch loss:6.047342487880414e-11, Training time:26275.797658205032
batch reward last col mean 3.874999432440518e-09 first col mean 0.00035863660741597414 all mean 2.0389212295413017e-05
2.8249993988538336e-07 2.825058800226543e-07
rl training, epoch1, iter0, batch416/1133, batch loss:2.825058800226543e-07, Training time:26302.966339111328
batch reward last col mean 1.091112089568469e-09 first col mean 1.3720248270843172e-09 all mean 1.5443787560798228e-05
2.4387318831031735e-07 2.4387225039390614e-07
rl training, epoch1, iter0, batch417/1133, batch loss:2.4387225039390614e-07, Training time:26330.72770547867
batch reward last col mean 8.292762032624523e-09 first col mean 7.788157674326612e-09 all mean 7.825854630993945e-09
1.9140926343919062e-10 1.9140859730537585e-10
rl training, epoch1, iter0, batch418/1133, batch loss:1.9140859730537585e-10, Training time:26358.455171346664
batch reward last col mean 1.4934186109982761e-09 first col mean 1.8517520850025448e-09 all mean 1.966678428289015e-05
4.015112790511921e-05 4.0151120629161596e-05
rl training, epoch1, iter0, batch419/1133, batch loss:4.0151120629161596e-05, Training time:26386.01048898697
batch reward last col mean 2.7896969179153075e-09 first col mean 3.1230191765985182e-09 all mean 3.4528838455116784e-08
2.2331833604560813e-10 2.2330455540231497e-10
rl training, epoch1, iter0, batch420/1133, batch loss:2.2330455540231497e-10, Training time:26414.01040172577
batch reward last col mean 2.1611166189927644e-09 first col mean 1.7624663950499553e-09 all mean 2.5639881329198033e-09
1.4979668894188336e-10 1.4979650853064186e-10
rl training, epoch1, iter0, batch421/1133, batch loss:1.4979650853064186e-10, Training time:26441.516133785248
batch reward last col mean 1.8756114439355542e-09 first col mean 1.1981571290675674e-09 all mean 1.7866304915514775e-05
5.0466525863157585e-05 5.0466525863157585e-05
rl training, epoch1, iter0, batch422/1133, batch loss:5.0466525863157585e-05, Training time:26469.010584115982
batch reward last col mean 6.142125696939615e-10 first col mean 6.330040935864645e-10 all mean 1.1364734708863011e-09
1.5265068376013602e-10 1.526504755933189e-10
rl training, epoch1, iter0, batch423/1133, batch loss:1.526504755933189e-10, Training time:26496.65338730812
batch reward last col mean 1.3822959443743343e-09 first col mean 5.2751887302804334e-09 all mean 2.285443952132482e-05
7.923073098936584e-06 7.923068551463075e-06
rl training, epoch1, iter0, batch424/1133, batch loss:7.923068551463075e-06, Training time:26523.979882240295
batch reward last col mean 2.2678137145959454e-09 first col mean 2.5431252659302572e-09 all mean 6.854509404519149e-09
3.3305797009219873e-10 3.3305946889328197e-10
rl training, epoch1, iter0, batch425/1133, batch loss:3.3305946889328197e-10, Training time:26551.52952003479
batch reward last col mean 3.698355399706088e-09 first col mean 2.0449686388701593e-09 all mean 3.808938942029272e-09
1.7202594904119906e-10 1.7202582414110879e-10
rl training, epoch1, iter0, batch426/1133, batch loss:1.7202582414110879e-10, Training time:26579.858223199844
batch reward last col mean 4.531671926599756e-09 first col mean 2.2771160512746746e-09 all mean 2.5892811450489717e-08
1.6664084001583035e-10 1.6664708502034387e-10
rl training, epoch1, iter0, batch427/1133, batch loss:1.6664708502034387e-10, Training time:26608.36342906952
batch reward last col mean 1.286806217137837e-09 first col mean 1.6162420291010449e-09 all mean 6.226494431160745e-09
1.0288846163941656e-10 1.028874693775883e-10
rl training, epoch1, iter0, batch428/1133, batch loss:1.028874693775883e-10, Training time:26636.19186782837
batch reward last col mean 8.303949194932159e-10 first col mean 1.5177958889722731e-09 all mean 1.6710420824850303e-09
1.220444162397527e-10 1.2204437460638928e-10
rl training, epoch1, iter0, batch429/1133, batch loss:1.2204437460638928e-10, Training time:26663.93068432808
batch reward last col mean 9.303369186142163e-10 first col mean 1.6820007608941978e-09 all mean 2.4543436172308475e-09
3.9821711900200896e-11 3.982173965577651e-11
rl training, epoch1, iter0, batch430/1133, batch loss:3.982173965577651e-11, Training time:26691.859927415848
batch reward last col mean 3.4038685758908116e-10 first col mean 6.343583436319022e-10 all mean 1.218293073179666e-05
7.459422340616584e-05 7.459422340616584e-05
rl training, epoch1, iter0, batch431/1133, batch loss:7.459422340616584e-05, Training time:26719.594727754593
batch reward last col mean 1.6606892527804007e-09 first col mean 1.981316666288535e-09 all mean 9.484586371399928e-06
5.042638804297894e-06 5.042636075813789e-06
rl training, epoch1, iter0, batch432/1133, batch loss:5.042636075813789e-06, Training time:26747.69468355179
batch reward last col mean 8.267766471448112e-10 first col mean 1.4007670579019305e-09 all mean 1.1524967646892037e-09
8.403619466967882e-11 8.403620160857272e-11
rl training, epoch1, iter0, batch433/1133, batch loss:8.403620160857272e-11, Training time:26775.259521007538
batch reward last col mean 3.2429747776063778e-09 first col mean 2.0803438971483956e-09 all mean 5.237708933236718e-08
1.1628242813088718e-09 1.1628068508073852e-09
rl training, epoch1, iter0, batch434/1133, batch loss:1.1628068508073852e-09, Training time:26802.759870529175
batch reward last col mean 2.140061683419958e-09 first col mean 1.6537441416275556e-09 all mean 3.2391451743052357e-09
9.238160930680195e-11 9.238113052312258e-11
rl training, epoch1, iter0, batch435/1133, batch loss:9.238113052312258e-11, Training time:26830.771775722504
batch reward last col mean 1.7190616707907225e-09 first col mean 4.1414853768628745e-09 all mean 4.236967221515897e-09
1.9972412612645485e-10 1.997236959150328e-10
rl training, epoch1, iter0, batch436/1133, batch loss:1.997236959150328e-10, Training time:26858.43258047104
batch reward last col mean 1.6836876337578133e-09 first col mean 1.2379258729211529e-09 all mean 5.835796734743326e-09
7.416579850261229e-11 7.416573605256715e-11
rl training, epoch1, iter0, batch437/1133, batch loss:7.416573605256715e-11, Training time:26885.80786395073
batch reward last col mean 1.4276727577922088e-09 first col mean 0.0017644062172621489 all mean 1.782695653673727e-05
3.388602749510028e-07 3.388668119441718e-07
rl training, epoch1, iter0, batch438/1133, batch loss:3.388668119441718e-07, Training time:26913.9006524086
batch reward last col mean 1.3905159246263565e-09 first col mean 1.8360091225133601e-09 all mean 1.5870869063405735e-09
8.22948792444933e-11 8.229468495546399e-11
rl training, epoch1, iter0, batch439/1133, batch loss:8.229468495546399e-11, Training time:26941.513771772385
batch reward last col mean 2.7860038720461944e-09 first col mean 7.875662788592308e-09 all mean 1.2732795084957615e-07
2.1005799877293896e-10 2.1008463024774215e-10
rl training, epoch1, iter0, batch440/1133, batch loss:2.1008463024774215e-10, Training time:26969.27545619011
batch reward last col mean 1.1381258158138507e-09 first col mean 4.077834070415065e-09 all mean 1.98278620189285e-08
7.99421570607528e-11 7.992586453786643e-11
rl training, epoch1, iter0, batch441/1133, batch loss:7.992586453786643e-11, Training time:26996.91146826744
batch reward last col mean 3.9207015412046076e-09 first col mean 5.216530318818968e-09 all mean 2.2811248001630702e-08
1.1453004516992493e-10 1.1452599285588505e-10
rl training, epoch1, iter0, batch442/1133, batch loss:1.1452599285588505e-10, Training time:27024.360363721848
batch reward last col mean 0.00015501424786634743 first col mean 1.1540187472292018e-08 all mean 0.00014875542547088116
8.388175047002733e-06 8.38817322801333e-06
rl training, epoch1, iter0, batch443/1133, batch loss:8.38817322801333e-06, Training time:27051.844045639038
batch reward last col mean 5.216650666994838e-09 first col mean 3.1520266396967145e-09 all mean 7.717903649506752e-09
7.070479618453973e-11 7.070638519124373e-11
rl training, epoch1, iter0, batch444/1133, batch loss:7.070638519124373e-11, Training time:27079.550530433655
batch reward last col mean 0.006970479618757963 first col mean 9.010874268966518e-10 all mean 0.0066888462752103806
0.00024784362176433206 0.0002478436508681625
rl training, epoch1, iter0, batch445/1133, batch loss:0.0002478436508681625, Training time:27107.147613048553
batch reward last col mean 4.955458265953894e-09 first col mean 3.299935968925638e-08 all mean 1.9031045184192408e-08
2.3921220559941503e-10 2.392125109107468e-10
rl training, epoch1, iter0, batch446/1133, batch loss:2.392125109107468e-10, Training time:27134.869970321655
batch reward last col mean 1.539749439061211e-09 first col mean 2.483725891622157e-09 all mean 1.9372544457496588e-08
2.1157344765043717e-09 2.115739583530285e-09
rl training, epoch1, iter0, batch447/1133, batch loss:2.115739583530285e-09, Training time:27162.512823820114
batch reward last col mean 2.9550970559455436e-09 first col mean 2.9549731550559954e-09 all mean 3.36193215844105e-06
3.553655147925383e-08 3.5536213971454345e-08
rl training, epoch1, iter0, batch448/1133, batch loss:3.5536213971454345e-08, Training time:27190.343896865845
batch reward last col mean 3.1731823835201567e-09 first col mean 1.3240488705434927e-09 all mean 8.692475184091109e-09
4.4841114155147466e-10 4.484133897530995e-10
rl training, epoch1, iter0, batch449/1133, batch loss:4.484133897530995e-10, Training time:27218.259839057922
batch reward last col mean 1.3016658861886299e-09 first col mean 1.74624370519183e-09 all mean 4.967336764138963e-09
1.1273036670811365e-10 1.1273054018046125e-10
rl training, epoch1, iter0, batch450/1133, batch loss:1.1273054018046125e-10, Training time:27246.305616140366
batch reward last col mean 2.2490682649589644e-09 first col mean 2.086305350701423e-09 all mean 9.018044977437967e-09
9.112991611326393e-11 9.112907650710156e-11
rl training, epoch1, iter0, batch451/1133, batch loss:9.112907650710156e-11, Training time:27274.125502347946
batch reward last col mean 2.6600013303124115e-09 first col mean 5.818260095935557e-09 all mean 8.700484613655135e-06
5.314344875273491e-08 5.3144770362223426e-08
rl training, epoch1, iter0, batch452/1133, batch loss:5.3144770362223426e-08, Training time:27301.74350619316
batch reward last col mean 3.654654356921583e-09 first col mean 4.658608609986459e-09 all mean 2.885519911899337e-08
2.1160230512240474e-10 2.1161752905562992e-10
rl training, epoch1, iter0, batch453/1133, batch loss:2.1161752905562992e-10, Training time:27329.523488521576
batch reward last col mean 2.0797343847078764e-09 first col mean 2.649250818720361e-09 all mean 9.344000240218975e-09
7.561258563715256e-11 7.561002518530202e-11
rl training, epoch1, iter0, batch454/1133, batch loss:7.561002518530202e-11, Training time:27357.030171632767
batch reward last col mean 1.7049566736204724e-07 first col mean 4.11863254612399e-09 all mean 1.6615773347439244e-05
3.861166533170035e-06 3.861160621454474e-06
rl training, epoch1, iter0, batch455/1133, batch loss:3.861160621454474e-06, Training time:27384.794350862503
batch reward last col mean 5.060242891374855e-09 first col mean 2.328532255901905e-09 all mean 5.454701579310495e-09
2.4119664598920565e-10 2.411965904780544e-10
rl training, epoch1, iter0, batch456/1133, batch loss:2.411965904780544e-10, Training time:27412.491955280304
batch reward last col mean 1.193931620235844e-09 first col mean 7.702967708134167e-10 all mean 1.8545131652558666e-08
3.5819902599598663e-10 3.581853147416325e-10
rl training, epoch1, iter0, batch457/1133, batch loss:3.581853147416325e-10, Training time:27440.0367000103
batch reward last col mean 3.931371672649675e-09 first col mean 2.109812768935626e-09 all mean 3.985182850385627e-09
1.9893241220980684e-10 1.9893243996538246e-10
rl training, epoch1, iter0, batch458/1133, batch loss:1.9893243996538246e-10, Training time:27467.78662967682
batch reward last col mean 1.9627006686562254e-09 first col mean 2.2242929720306392e-09 all mean 1.4434377249017416e-08
2.2567619994973143e-10 2.2566964963388614e-10
rl training, epoch1, iter0, batch459/1133, batch loss:2.2566964963388614e-10, Training time:27496.264087200165
batch reward last col mean 1.6849505124483244e-09 first col mean 4.791901986322955e-09 all mean 1.7621505321585573e-05
1.031508782034507e-05 1.0315085091860965e-05
rl training, epoch1, iter0, batch460/1133, batch loss:1.0315085091860965e-05, Training time:27524.032534837723
batch reward last col mean 9.468454909011825e-10 first col mean 1.0031451225245291e-08 all mean 1.8796759832184762e-05
9.695950353716398e-08 9.696334046793709e-08
rl training, epoch1, iter0, batch461/1133, batch loss:9.696334046793709e-08, Training time:27551.53423333168
batch reward last col mean 8.428053843090311e-05 first col mean 7.785360134349162e-10 all mean 8.002470713108778e-05
5.575765044341097e-06 5.575765044341097e-06
rl training, epoch1, iter0, batch462/1133, batch loss:5.575765044341097e-06, Training time:27579.204252958298
batch reward last col mean 5.374231477617286e-05 first col mean 7.539833646319494e-09 all mean 5.508641720552987e-07
3.626089664976462e-06 3.6260901197238127e-06
rl training, epoch1, iter0, batch463/1133, batch loss:3.6260901197238127e-06, Training time:27606.87459564209
batch reward last col mean 9.36166921761128e-10 first col mean 8.069274137767479e-10 all mean 2.349863192918633e-09
4.7558720850382485e-11 4.755781879417498e-11
rl training, epoch1, iter0, batch464/1133, batch loss:4.755781879417498e-11, Training time:27634.372174739838
batch reward last col mean 9.094858199887312e-10 first col mean 1.3397521980706983e-09 all mean 2.252567021798768e-09
6.329799878690423e-11 6.329783225345054e-11
rl training, epoch1, iter0, batch465/1133, batch loss:6.329783225345054e-11, Training time:27662.013462781906
batch reward last col mean 1.2879383115560472e-09 first col mean 2.4453843394667274e-09 all mean 5.377733486966463e-06
6.917019135244118e-08 6.917071004863828e-08
rl training, epoch1, iter0, batch466/1133, batch loss:6.917071004863828e-08, Training time:27690.394835710526
batch reward last col mean 1.3351008076867288e-09 first col mean 1.8736596718582632e-09 all mean 1.5097167306521442e-05
5.48148307188967e-07 5.481422817865678e-07
rl training, epoch1, iter0, batch467/1133, batch loss:5.481422817865678e-07, Training time:27717.83877468109
batch reward last col mean 4.981104417822735e-09 first col mean 8.063118730206043e-05 all mean 8.167255032276444e-07
2.349187866457214e-08 2.349170458160188e-08
rl training, epoch1, iter0, batch468/1133, batch loss:2.349170458160188e-08, Training time:27746.342715740204
batch reward last col mean 4.551165666555335e-09 first col mean 3.2577731623462114e-09 all mean 1.6479178157169372e-05
3.142017988011503e-07 3.142017988011503e-07
rl training, epoch1, iter0, batch469/1133, batch loss:3.142017988011503e-07, Training time:27774.021719932556
batch reward last col mean 2.7261659596433674e-09 first col mean 0.0014686892973259091 all mean 1.4876577552058734e-05
8.040547072596382e-07 8.040611305659695e-07
rl training, epoch1, iter0, batch470/1133, batch loss:8.040611305659695e-07, Training time:27801.388588905334
batch reward last col mean 9.69598068500943e-10 first col mean 1.134224492105318e-09 all mean 7.571500646008644e-06
4.201032879791455e-06 4.201030606054701e-06
rl training, epoch1, iter0, batch471/1133, batch loss:4.201030606054701e-06, Training time:27828.846700429916
batch reward last col mean 2.9811948465408022e-09 first col mean 7.438138549531459e-09 all mean 3.472651499691892e-08
2.6696456156827253e-10 2.669783838449291e-10
rl training, epoch1, iter0, batch472/1133, batch loss:2.669783838449291e-10, Training time:27856.483783960342
batch reward last col mean 5.506529010546046e-09 first col mean 5.467673425130215e-09 all mean 8.841947618520862e-09
1.3512511942703753e-10 1.3512396757064948e-10
rl training, epoch1, iter0, batch473/1133, batch loss:1.3512396757064948e-10, Training time:27884.1705391407
batch reward last col mean 6.1206728574347835e-09 first col mean 3.128031877963622e-08 all mean 8.08831579490743e-09
2.5398089187333994e-10 2.539811971846717e-10
rl training, epoch1, iter0, batch474/1133, batch loss:2.539811971846717e-10, Training time:27911.682314157486
batch reward last col mean 1.0312901643771966e-09 first col mean 1.38594447030016e-09 all mean 1.3372761786811793e-09
6.820154857534177e-11 6.820161796428081e-11
rl training, epoch1, iter0, batch475/1133, batch loss:6.820161796428081e-11, Training time:27939.732280492783
batch reward last col mean 0.00015961063036229461 first col mean 2.109804331240639e-09 all mean 0.00015155853179749101
5.328343831934035e-06 5.328343831934035e-06
rl training, epoch1, iter0, batch476/1133, batch loss:5.328343831934035e-06, Training time:27967.614373922348
batch reward last col mean 1.2288661199733042e-09 first col mean 1.619558931409415e-09 all mean 3.7596250876958948e-06
3.2288344442577e-08 3.228664979815221e-08
rl training, epoch1, iter0, batch477/1133, batch loss:3.228664979815221e-08, Training time:27996.03395342827
batch reward last col mean 2.035142276923807e-09 first col mean 1.019091921961035e-09 all mean 2.9661717526607845e-09
1.1172995861841173e-10 1.1172940350689942e-10
rl training, epoch1, iter0, batch478/1133, batch loss:1.1172940350689942e-10, Training time:28023.800961732864
batch reward last col mean 0.00162217253819108 first col mean 9.214623730713356e-08 all mean 0.0015566563233733177
0.00012103305925847962 0.00012103305925847962
rl training, epoch1, iter0, batch479/1133, batch loss:0.00012103305925847962, Training time:28051.301252365112
batch reward last col mean 1.6327768026513922e-09 first col mean 1.761593537707995e-09 all mean 3.1677156897558234e-08
8.117654465289448e-11 8.116275013181351e-11
rl training, epoch1, iter0, batch480/1133, batch loss:8.116275013181351e-11, Training time:28079.03979063034
batch reward last col mean 2.4311495039341935e-09 first col mean 1.1340314243213356e-09 all mean 2.4603625803365503e-08
1.784438552476786e-08 1.7844390853838377e-08
rl training, epoch1, iter0, batch481/1133, batch loss:1.7844390853838377e-08, Training time:28107.217619657516
batch reward last col mean 9.350982210776237e-10 first col mean 5.446224804472877e-09 all mean 8.234824235842098e-06
1.0181028073930065e-06 1.0181006473430898e-06
rl training, epoch1, iter0, batch482/1133, batch loss:1.0181006473430898e-06, Training time:28134.693556070328
batch reward last col mean 2.5717836749095113e-09 first col mean 2.733480108929598e-09 all mean 1.0726290966545093e-08
7.05129066247423e-09 7.0512951033663285e-09
rl training, epoch1, iter0, batch483/1133, batch loss:7.0512951033663285e-09, Training time:28162.794887781143
batch reward last col mean 7.361010689876935e-10 first col mean 1.189844445192989e-09 all mean 1.2872656274254268e-09
4.9973532256775144e-11 4.997368491244103e-11
rl training, epoch1, iter0, batch484/1133, batch loss:4.997368491244103e-11, Training time:28190.470957040787
batch reward last col mean 1.0965315322408742e-09 first col mean 1.9590031818950138e-09 all mean 3.876351399867417e-07
2.3894001444091373e-08 2.3893944600672512e-08
rl training, epoch1, iter0, batch485/1133, batch loss:2.3893944600672512e-08, Training time:28218.314016342163
batch reward last col mean 2.474097593463398e-09 first col mean 4.211336612769401e-09 all mean 6.898440485514357e-09
2.5730934050116616e-10 2.573111446135812e-10
rl training, epoch1, iter0, batch486/1133, batch loss:2.573111446135812e-10, Training time:28246.502274274826
batch reward last col mean 5.057625873661209e-09 first col mean 4.956082211293733e-09 all mean 9.207489028995042e-07
3.233768666177639e-06 3.233768666177639e-06
rl training, epoch1, iter0, batch487/1133, batch loss:3.233768666177639e-06, Training time:28274.514839410782
batch reward last col mean 0.0015582165215164423 first col mean 1.1902466789948107e-09 all mean 0.0014991734642535448
7.595158967887983e-05 7.595159695483744e-05
rl training, epoch1, iter0, batch488/1133, batch loss:7.595159695483744e-05, Training time:28301.893731594086
batch reward last col mean 2.480420757677848e-09 first col mean 0.001833430491387844 all mean 1.853106550697703e-05
5.736504817832611e-07 5.736444563808618e-07
rl training, epoch1, iter0, batch489/1133, batch loss:5.736444563808618e-07, Training time:28329.741300582886
batch reward last col mean 1.2567015206244037e-09 first col mean 0.001184434979222715 all mean 1.2000324204564095e-05
8.681738108862191e-06 8.6817426563357e-06
rl training, epoch1, iter0, batch490/1133, batch loss:8.6817426563357e-06, Training time:28357.21658205986
batch reward last col mean 3.84306542144941e-09 first col mean 2.8729030265850497e-09 all mean 2.953474449896021e-06
3.388014135907724e-08 3.388023372963289e-08
rl training, epoch1, iter0, batch491/1133, batch loss:3.388023372963289e-08, Training time:28385.319974660873
batch reward last col mean 1.1459486692899645e-09 first col mean 1.207680844217407e-09 all mean 3.570910456218712e-09
7.831014309234163e-11 7.83097198198135e-11
rl training, epoch1, iter0, batch492/1133, batch loss:7.83097198198135e-11, Training time:28413.3113322258
batch reward last col mean 3.199823517263667e-09 first col mean 2.4239819040872135e-09 all mean 3.2459515075800027e-09
1.4596482356132867e-10 1.4596478192796525e-10
rl training, epoch1, iter0, batch493/1133, batch loss:1.4596478192796525e-10, Training time:28440.946907281876
batch reward last col mean 0.0010081586660817266 first col mean 0.0006128298118710518 all mean 0.000979074975475669
5.371311635826714e-05 5.371310908230953e-05
rl training, epoch1, iter0, batch494/1133, batch loss:5.371310908230953e-05, Training time:28468.268845558167
batch reward last col mean 5.147232862157125e-09 first col mean 2.5867463726569895e-09 all mean 5.0561880016175564e-06
1.4599224940070599e-08 1.4600122000274496e-08
rl training, epoch1, iter0, batch495/1133, batch loss:1.4600122000274496e-08, Training time:28495.848315238953
batch reward last col mean 5.177121842336874e-09 first col mean 6.151818610078408e-09 all mean 8.090180926956236e-06
7.51943076693351e-08 7.51914583929647e-08
rl training, epoch1, iter0, batch496/1133, batch loss:7.51914583929647e-08, Training time:28523.36843562126
batch reward last col mean 2.4179691582304486e-09 first col mean 3.992873644165229e-06 all mean 4.3387668569039306e-08
1.133231908312382e-08 1.1332306648625945e-08
rl training, epoch1, iter0, batch497/1133, batch loss:1.1332306648625945e-08, Training time:28550.866670370102
batch reward last col mean 2.120594366772366e-09 first col mean 2.6277062747936952e-09 all mean 3.846739815571709e-09
9.676250078971549e-11 9.676268120095699e-11
rl training, epoch1, iter0, batch498/1133, batch loss:9.676268120095699e-11, Training time:28578.32513165474
batch reward last col mean 9.071358664236584e-10 first col mean 8.243771221216889e-10 all mean 3.0518847324856324e-06
1.612290745356404e-08 1.612266764539072e-08
rl training, epoch1, iter0, batch499/1133, batch loss:1.612266764539072e-08, Training time:28605.7336704731
batch reward last col mean 1.2404455240755397e-09 first col mean 1.1625155282857236e-09 all mean 4.29634283705127e-09
7.18301459978754e-11 7.183016681455712e-11
rl training, epoch1, iter0, batch500/1133, batch loss:7.183016681455712e-11, Training time:28633.043408870697
batch reward last col mean 1.6922755419201962e-09 first col mean 9.021481894855299e-10 all mean 1.729517498461064e-05
1.0867549349313776e-07 1.0867752564536204e-07
rl training, epoch1, iter0, batch501/1133, batch loss:1.0867752564536204e-07, Training time:28660.53455400467
batch reward last col mean 1.893092793636697e-09 first col mean 2.973180812659848e-09 all mean 1.0751258550101284e-08
1.5991488688804623e-10 1.5991505342149992e-10
rl training, epoch1, iter0, batch502/1133, batch loss:1.5991505342149992e-10, Training time:28687.75656270981
batch reward last col mean 4.767739092415013e-09 first col mean 5.159487045602873e-05 all mean 5.30529518982803e-07
1.7824172360292323e-08 1.7823927223048486e-08
rl training, epoch1, iter0, batch503/1133, batch loss:1.7823927223048486e-08, Training time:28715.452743291855
batch reward last col mean 1.1656842158203062e-09 first col mean 1.0416588702710783e-09 all mean 6.360704901453573e-06
1.3400816101238888e-07 1.3400781995187572e-07
rl training, epoch1, iter0, batch504/1133, batch loss:1.3400781995187572e-07, Training time:28742.994418621063
batch reward last col mean 2.8840938526286664e-09 first col mean 1.1656564602446906e-09 all mean 1.4149713623012872e-09
2.1588920928738986e-10 2.158891121428752e-10
rl training, epoch1, iter0, batch505/1133, batch loss:2.158891121428752e-10, Training time:28770.536051273346
batch reward last col mean 7.881339136872612e-09 first col mean 7.088647002717607e-09 all mean 3.557141781129758e-08
2.3554161399097495e-10 2.355224903993758e-10
rl training, epoch1, iter0, batch506/1133, batch loss:2.355224903993758e-10, Training time:28798.15706896782
batch reward last col mean 2.7314968065184075e-09 first col mean 2.798210330112738e-09 all mean 3.033501227989177e-09
9.132851419568766e-11 9.132824357882541e-11
rl training, epoch1, iter0, batch507/1133, batch loss:9.132824357882541e-11, Training time:28825.82431769371
batch reward last col mean 1.7534549368036778e-09 first col mean 1.3787314623314728e-09 all mean 3.5526144248620994e-09
7.169314447663666e-11 7.169360244363432e-11
rl training, epoch1, iter0, batch508/1133, batch loss:7.169360244363432e-11, Training time:28853.297605514526
batch reward last col mean 3.464560194288424e-09 first col mean 1.917065839407428e-09 all mean 6.211970049463389e-09
2.3225363299239632e-10 2.3225327216991332e-10
rl training, epoch1, iter0, batch509/1133, batch loss:2.3225327216991332e-10, Training time:28880.720838069916
batch reward last col mean 2.441875146530492e-09 first col mean 7.51469775295277e-10 all mean 2.417129829623832e-09
1.405856403513539e-10 1.405863481185321e-10
rl training, epoch1, iter0, batch510/1133, batch loss:1.405863481185321e-10, Training time:28907.990334033966
batch reward last col mean 1.5493080152140237e-09 first col mean 0.000287802453385666 all mean 2.9110453851899365e-06
2.892665179388132e-06 2.892665179388132e-06
rl training, epoch1, iter0, batch511/1133, batch loss:2.892665179388132e-06, Training time:28935.399354219437
batch reward last col mean 2.8999393997253264e-09 first col mean 3.670941328692834e-09 all mean 2.30273489165711e-08
1.267003169047598e-10 1.267013993722088e-10
rl training, epoch1, iter0, batch512/1133, batch loss:1.267013993722088e-10, Training time:28963.255294322968
batch reward last col mean 2.2439166080800987e-09 first col mean 3.08172598550982e-09 all mean 2.365845519491927e-09
1.9785491023327495e-09 1.9785493243773544e-09
rl training, epoch1, iter0, batch513/1133, batch loss:1.9785493243773544e-09, Training time:28990.956117153168
batch reward last col mean 1.182048903203281e-09 first col mean 8.570820164699455e-10 all mean 1.5250271644617897e-05
1.9594475816120394e-05 1.95944794540992e-05
rl training, epoch1, iter0, batch514/1133, batch loss:1.95944794540992e-05, Training time:29018.52874302864
batch reward last col mean 2.9275852853061224e-09 first col mean 3.5709066814604284e-09 all mean 1.0377755643276032e-05
3.647024414021871e-06 3.647022367658792e-06
rl training, epoch1, iter0, batch515/1133, batch loss:3.647022367658792e-06, Training time:29045.976920843124
batch reward last col mean 1.198027899107501e-09 first col mean 1.197495214100286e-09 all mean 1.3509496854524627e-09
7.519395522903594e-11 7.519387196230909e-11
rl training, epoch1, iter0, batch516/1133, batch loss:7.519387196230909e-11, Training time:29073.71460556984
batch reward last col mean 5.337360553525627e-10 first col mean 1.0183550669395913e-09 all mean 5.362122465157881e-06
2.5683261739573027e-08 2.5684460780439622e-08
rl training, epoch1, iter0, batch517/1133, batch loss:2.5684460780439622e-08, Training time:29101.29225373268
batch reward last col mean 1.774308477919817e-09 first col mean 1.6359359422679631e-09 all mean 4.863093483464809e-09
1.0511796988410538e-10 1.0511753273378943e-10
rl training, epoch1, iter0, batch518/1133, batch loss:1.0511753273378943e-10, Training time:29128.778727054596
batch reward last col mean 1.1178903358555203e-09 first col mean 9.240058163051401e-10 all mean 1.7641433869286516e-09
5.0771005455363394e-11 5.077069320513772e-11
rl training, epoch1, iter0, batch519/1133, batch loss:5.077069320513772e-11, Training time:29156.61638689041
batch reward last col mean 4.606272030471814e-10 first col mean 4.461306324365921e-10 all mean 9.479904639064785e-10
5.578842596221101e-11 5.5788651476262885e-11
rl training, epoch1, iter0, batch520/1133, batch loss:5.5788651476262885e-11, Training time:29184.37977385521
batch reward last col mean 9.015744817375548e-10 first col mean 1.1243135311644892e-09 all mean 8.941868911982453e-10
5.062729055427262e-11 5.0627300962613475e-11
rl training, epoch1, iter0, batch521/1133, batch loss:5.0627300962613475e-11, Training time:29211.873636722565
batch reward last col mean 1.3092558148741773e-09 first col mean 1.8200323470551893e-09 all mean 3.5161110645276494e-06
1.4403922250494361e-05 1.4403919522010256e-05
rl training, epoch1, iter0, batch522/1133, batch loss:1.4403919522010256e-05, Training time:29240.17434310913
batch reward last col mean 7.360245746212968e-10 first col mean 1.2798566650928933e-09 all mean 4.155084720736113e-09
4.130304778748872e-11 4.130190286999458e-11
rl training, epoch1, iter0, batch523/1133, batch loss:4.130190286999458e-11, Training time:29268.01453280449
batch reward last col mean 1.5543297759990082e-09 first col mean 2.127015896746798e-09 all mean 2.814642741100215e-09
1.0771612768412098e-10 1.0771659259001254e-10
rl training, epoch1, iter0, batch524/1133, batch loss:1.0771659259001254e-10, Training time:29296.19419145584
batch reward last col mean 7.526121947876163e-10 first col mean 9.133234168956506e-10 all mean 3.6411795800717073e-09
3.849191104743355e-11 3.849194921135002e-11
rl training, epoch1, iter0, batch525/1133, batch loss:3.849194921135002e-11, Training time:29324.003418922424
batch reward last col mean 9.540597201151968e-10 first col mean 1.109901948126435e-09 all mean 1.9256476662121713e-05
5.3170660976320505e-05 5.317066825227812e-05
rl training, epoch1, iter0, batch526/1133, batch loss:5.317066825227812e-05, Training time:29352.199256181717
batch reward last col mean 3.672141035693244e-09 first col mean 3.38178907099973e-09 all mean 2.4946038124085135e-08
1.8494042408612188e-10 1.849550235188957e-10
rl training, epoch1, iter0, batch527/1133, batch loss:1.849550235188957e-10, Training time:29379.803313970566
batch reward last col mean 1.8817680746963106e-09 first col mean 2.3509483249029017e-09 all mean 3.3987141989655356e-09
1.4610122833769168e-10 1.4610129772663072e-10
rl training, epoch1, iter0, batch528/1133, batch loss:1.4610129772663072e-10, Training time:29407.41653251648
batch reward last col mean 1.2123511083927951e-09 first col mean 1.2468099885865058e-09 all mean 6.495913584814161e-09
6.693244569699885e-11 6.692924686690915e-11
rl training, epoch1, iter0, batch529/1133, batch loss:6.692924686690915e-11, Training time:29435.278640270233
batch reward last col mean 2.5743396303568034e-09 first col mean 1.22097021382217e-09 all mean 2.685777156230529e-09
1.360309365150414e-10 1.3603139448203905e-10
rl training, epoch1, iter0, batch530/1133, batch loss:1.3603139448203905e-10, Training time:29462.64028072357
batch reward last col mean 2.5892756827516905e-09 first col mean 2.949314570344086e-09 all mean 2.415515787390632e-08
1.9263879380559956e-09 1.926386383743761e-09
rl training, epoch1, iter0, batch531/1133, batch loss:1.926386383743761e-09, Training time:29490.604825735092
batch reward last col mean 2.109185048837503e-09 first col mean 3.832268280490325e-09 all mean 9.84500925227394e-09
1.2446842168056804e-10 1.2447026742634648e-10
rl training, epoch1, iter0, batch532/1133, batch loss:1.2447026742634648e-10, Training time:29518.80100631714
batch reward last col mean 1.9009460672236855e-09 first col mean 2.561379774945749e-09 all mean 1.536744548502611e-06
5.842344386053355e-09 5.8430429383804494e-09
rl training, epoch1, iter0, batch533/1133, batch loss:5.8430429383804494e-09, Training time:29546.81374692917
batch reward last col mean 7.931033607633253e-10 first col mean 3.0412218620767817e-05 all mean 3.0815471063760924e-07
2.2473946259538025e-08 2.247390362697388e-08
rl training, epoch1, iter0, batch534/1133, batch loss:2.247390362697388e-08, Training time:29574.24446105957
batch reward last col mean 4.101714967674752e-09 first col mean 2.4801121156770023e-09 all mean 7.2390040628533825e-09
1.2945762517535542e-10 1.2945799987562623e-10
rl training, epoch1, iter0, batch535/1133, batch loss:1.2945799987562623e-10, Training time:29601.85919523239
batch reward last col mean 1.5673136122273945e-09 first col mean 3.122655023446441e-09 all mean 5.955794080136911e-09
1.461463727814305e-10 1.461472470820624e-10
rl training, epoch1, iter0, batch536/1133, batch loss:1.461472470820624e-10, Training time:29629.07322359085
batch reward last col mean 2.8102726812306855e-09 first col mean 2.09653272520427e-09 all mean 2.228727868924807e-09
1.258068371701171e-10 1.2580678165896586e-10
rl training, epoch1, iter0, batch537/1133, batch loss:1.2580678165896586e-10, Training time:29656.655190467834
batch reward last col mean 0.007176752667874098 first col mean 1.3442884583270143e-09 all mean 0.006745207589119673
0.0004897399339824915 0.0004897399339824915
rl training, epoch1, iter0, batch538/1133, batch loss:0.0004897399339824915, Training time:29684.444202661514
batch reward last col mean 1.3122460895687027e-09 first col mean 1.2100507262857718e-09 all mean 9.579744983057026e-06
7.328639185288921e-05 7.328639185288921e-05
rl training, epoch1, iter0, batch539/1133, batch loss:7.328639185288921e-05, Training time:29711.904490947723
batch reward last col mean 2.9169899828929147e-09 first col mean 2.444801916468009e-09 all mean 2.894204271797207e-06
2.2574445210921112e-06 2.257444293718436e-06
rl training, epoch1, iter0, batch540/1133, batch loss:2.257444293718436e-06, Training time:29739.586136102676
batch reward last col mean 1.546584904588144e-08 first col mean 1.6181542772386592e-09 all mean 2.7855146527144825e-06
1.225561252482521e-08 1.2256722747849835e-08
rl training, epoch1, iter0, batch541/1133, batch loss:1.2256722747849835e-08, Training time:29767.511540412903
batch reward last col mean 3.773686252372954e-09 first col mean 8.182580835125464e-09 all mean 1.607897814892567e-08
2.586301728335627e-10 2.5862992303338217e-10
rl training, epoch1, iter0, batch542/1133, batch loss:2.5862992303338217e-10, Training time:29795.280215501785
batch reward last col mean 1.1896039708858552e-09 first col mean 1.100548097099363e-09 all mean 9.121445714299625e-07
1.3808231891232481e-08 1.3808636012413444e-08
rl training, epoch1, iter0, batch543/1133, batch loss:1.3808636012413444e-08, Training time:29822.99107336998
batch reward last col mean 8.725370981288449e-10 first col mean 4.155405797234835e-09 all mean 1.3463989922968267e-09
6.055331236431982e-11 6.055322215869907e-11
rl training, epoch1, iter0, batch544/1133, batch loss:6.055322215869907e-11, Training time:29850.619616270065
batch reward last col mean 1.2588210474007155e-09 first col mean 1.2968260909573814e-09 all mean 2.8468650270951912e-05
5.1868199079763144e-05 5.186820635572076e-05
rl training, epoch1, iter0, batch545/1133, batch loss:5.186820635572076e-05, Training time:29878.474960565567
batch reward last col mean 7.176786720464179e-09 first col mean 0.0018583193887025118 all mean 1.9072514987783507e-05
3.0002975108800456e-06 3.0002997846168e-06
rl training, epoch1, iter0, batch546/1133, batch loss:3.0002997846168e-06, Training time:29906.694691181183
batch reward last col mean 1.405190630521247e-09 first col mean 1.2257157511186278e-09 all mean 7.668322723475285e-06
1.9257522581028752e-05 1.925752621900756e-05
rl training, epoch1, iter0, batch547/1133, batch loss:1.925752621900756e-05, Training time:29934.387250185013
batch reward last col mean 2.253630837500964e-09 first col mean 4.30552393737571e-09 all mean 2.0051326998782315e-07
1.9290902208979332e-10 1.9305906873157141e-10
rl training, epoch1, iter0, batch548/1133, batch loss:1.9305906873157141e-10, Training time:29962.089838266373
batch reward last col mean 7.921523992315826e-10 first col mean 7.434371451786603e-10 all mean 2.654040098803989e-09
4.325897973167514e-11 4.325876462596412e-11
rl training, epoch1, iter0, batch549/1133, batch loss:4.325876462596412e-11, Training time:29989.979607343674
batch reward last col mean 1.4085200783497953e-09 first col mean 1.915704039845423e-09 all mean 6.300003718706648e-08
1.2642602242873835e-10 1.2645963443080888e-10
rl training, epoch1, iter0, batch550/1133, batch loss:1.2645963443080888e-10, Training time:30017.64043688774
batch reward last col mean 4.97300334245665e-09 first col mean 4.010340504123633e-09 all mean 5.0955799579810446e-09
1.8926332723268047e-10 1.8926329947710485e-10
rl training, epoch1, iter0, batch551/1133, batch loss:1.8926329947710485e-10, Training time:30044.98021864891
batch reward last col mean 9.061702499479907e-09 first col mean 1.683909123251226e-09 all mean 4.076618154158496e-09
5.131443603367813e-10 5.131444713590838e-10
rl training, epoch1, iter0, batch552/1133, batch loss:5.131444713590838e-10, Training time:30072.412984132767
batch reward last col mean 5.588829399272299e-09 first col mean 2.8670832374899646e-09 all mean 5.757056609212441e-09
9.823327568048157e-11 9.82331577192852e-11
rl training, epoch1, iter0, batch553/1133, batch loss:9.82331577192852e-11, Training time:30100.016426563263
batch reward last col mean 6.109825423372683e-10 first col mean 0.0006704254192300141 all mean 6.773422228434356e-06
2.494944624231721e-07 2.4949582666522474e-07
rl training, epoch1, iter0, batch554/1133, batch loss:2.4949582666522474e-07, Training time:30127.96942090988
batch reward last col mean 3.2644007497140137e-09 first col mean 2.8762714432417624e-09 all mean 1.5747074257888016e-06
4.125649013531074e-07 4.1256427607549995e-07
rl training, epoch1, iter0, batch555/1133, batch loss:4.1256427607549995e-07, Training time:30155.879574775696
batch reward last col mean 1.343178457346994e-09 first col mean 1.7126586815408018e-09 all mean 3.3112244057775797e-09
9.57689066938272e-11 9.576861526028324e-11
rl training, epoch1, iter0, batch556/1133, batch loss:9.576861526028324e-11, Training time:30183.4037399292
batch reward last col mean 7.892378306451064e-09 first col mean 1.0863527855065058e-09 all mean 1.7110736161285445e-09
5.3646898034998e-10 5.364691468834337e-10
rl training, epoch1, iter0, batch557/1133, batch loss:5.364691468834337e-10, Training time:30211.181818962097
batch reward last col mean 0.0001075054969987832 first col mean 1.1555603141033544e-09 all mean 0.00010161427053390071
6.098412541177822e-06 6.098413450672524e-06
rl training, epoch1, iter0, batch558/1133, batch loss:6.098413450672524e-06, Training time:30238.82574915886
batch reward last col mean 2.146761657328966e-09 first col mean 5.400072833339209e-09 all mean 3.776813972677928e-09
1.6119640344758324e-10 1.6119601486952462e-10
rl training, epoch1, iter0, batch559/1133, batch loss:1.6119601486952462e-10, Training time:30266.472743988037
batch reward last col mean 2.253517816797057e-09 first col mean 0.0002441174874547869 all mean 2.4764115096331807e-06
3.387792091302799e-08 3.387787117503649e-08
rl training, epoch1, iter0, batch560/1133, batch loss:3.387787117503649e-08, Training time:30294.166826486588
batch reward last col mean 2.1896913171559618e-09 first col mean 2.6080222596647218e-05 all mean 2.743369975632959e-07
5.398846258941603e-09 5.3987383452636095e-09
rl training, epoch1, iter0, batch561/1133, batch loss:5.3987383452636095e-09, Training time:30321.834729909897
batch reward last col mean 4.822242605229121e-10 first col mean 1.196814980453098e-09 all mean 1.0043871043308172e-05
1.2847003745264374e-05 1.2847001016780268e-05
rl training, epoch1, iter0, batch562/1133, batch loss:1.2847001016780268e-05, Training time:30349.58747768402
batch reward last col mean 3.851555518963323e-08 first col mean 2.8258111406387343e-09 all mean 6.58049384583137e-06
5.8787712475805165e-08 5.878866815578476e-08
rl training, epoch1, iter0, batch563/1133, batch loss:5.878866815578476e-08, Training time:30377.223467111588
batch reward last col mean 2.113775376955118e-09 first col mean 0.0014718335587531328 all mean 1.4881696188240312e-05
1.012725078908261e-06 1.012718939819024e-06
rl training, epoch1, iter0, batch564/1133, batch loss:1.012718939819024e-06, Training time:30405.045501232147
batch reward last col mean 1.2364158585853602e-09 first col mean 0.0006000567809678614 all mean 2.4786089852568693e-05
1.596175280837997e-07 1.5961947497089568e-07
rl training, epoch1, iter0, batch565/1133, batch loss:1.5961947497089568e-07, Training time:30432.662947177887
batch reward last col mean 1.4410950210930196e-09 first col mean 2.9430493597715213e-09 all mean 1.2160022322404984e-08
9.4058330568636e-11 9.405335538170689e-11
rl training, epoch1, iter0, batch566/1133, batch loss:9.405335538170689e-11, Training time:30460.52972149849
batch reward last col mean 4.709626022503244e-09 first col mean 0.0014507174491882324 all mean 1.83774100150913e-05
2.06291517201862e-07 2.0629211405776005e-07
rl training, epoch1, iter0, batch567/1133, batch loss:2.0629211405776005e-07, Training time:30488.272436857224
batch reward last col mean 2.5799729019837514e-09 first col mean 1.1604292637912295e-07 all mean 1.8577345599624095e-06
3.0988396702014143e-06 3.0988403523224406e-06
rl training, epoch1, iter0, batch568/1133, batch loss:3.0988403523224406e-06, Training time:30515.698694229126
batch reward last col mean 9.185819882517876e-10 first col mean 2.1560730978364973e-09 all mean 3.5253657770795144e-09
8.036396548227742e-11 8.036513121645328e-11
rl training, epoch1, iter0, batch569/1133, batch loss:8.036513121645328e-11, Training time:30543.12736773491
batch reward last col mean 1.3803691523150974e-09 first col mean 0.0018129749223589897 all mean 1.87436853593681e-05
1.5113348581508035e-06 1.5113433846636326e-06
rl training, epoch1, iter0, batch570/1133, batch loss:1.5113433846636326e-06, Training time:30571.194756746292
batch reward last col mean 2.578655733387336e-09 first col mean 2.8400337637179973e-09 all mean 2.7639222022202148e-09
1.149452061310896e-10 1.1494511592546885e-10
rl training, epoch1, iter0, batch571/1133, batch loss:1.1494511592546885e-10, Training time:30598.779277563095
batch reward last col mean 1.362177148855892e-09 first col mean 0.001765870489180088 all mean 1.789274210750591e-05
2.844198388629593e-05 2.844198388629593e-05
rl training, epoch1, iter0, batch572/1133, batch loss:2.844198388629593e-05, Training time:30626.32968688011
batch reward last col mean 1.6676564573714359e-09 first col mean 0.0011180060682818294 all mean 1.1510051081131678e-05
1.3282536883707508e-06 1.3282530062497244e-06
rl training, epoch1, iter0, batch573/1133, batch loss:1.3282530062497244e-06, Training time:30654.316044569016
batch reward last col mean 2.6099904459897516e-09 first col mean 1.830557039284031e-08 all mean 3.824556671361279e-08
1.4636349077168376e-10 1.4636666878509175e-10
rl training, epoch1, iter0, batch574/1133, batch loss:1.4636666878509175e-10, Training time:30682.32959675789
batch reward last col mean 1.3094631157173353e-08 first col mean 2.2825638552603777e-06 all mean 1.3474510524247307e-05
2.7437213248049375e-06 2.7437238259153673e-06
rl training, epoch1, iter0, batch575/1133, batch loss:2.7437238259153673e-06, Training time:30710.198645353317
batch reward last col mean 1.0415608375780039e-09 first col mean 8.58956128446664e-10 all mean 6.526853212562855e-06
1.435730609955499e-07 1.435739136468328e-07
rl training, epoch1, iter0, batch576/1133, batch loss:1.435739136468328e-07, Training time:30737.71395254135
batch reward last col mean 9.75573621886383e-10 first col mean 1.0523915072724321e-09 all mean 5.793614032967298e-09
9.60770074609485e-11 9.60761262214227e-11
rl training, epoch1, iter0, batch577/1133, batch loss:9.60761262214227e-11, Training time:30765.118992328644
batch reward last col mean 1.3628052020209225e-09 first col mean 9.655092725324721e-09 all mean 1.3793444850307424e-05
7.171821380325127e-06 7.17182774678804e-06
rl training, epoch1, iter0, batch578/1133, batch loss:7.17182774678804e-06, Training time:30793.02769470215
batch reward last col mean 3.878153265191031e-08 first col mean 1.046856379360861e-08 all mean 4.666553081733582e-07
1.6615869071756606e-06 1.6615869071756606e-06
rl training, epoch1, iter0, batch579/1133, batch loss:1.6615869071756606e-06, Training time:30820.580355405807
batch reward last col mean 1.8167535253965639e-09 first col mean 2.129351805990609e-09 all mean 1.7934642215777785e-08
1.094420110092642e-10 1.0944176814797757e-10
rl training, epoch1, iter0, batch580/1133, batch loss:1.0944176814797757e-10, Training time:30848.03029203415
batch reward last col mean 1.242064495698969e-08 first col mean 0.001475250581279397 all mean 3.30856055370532e-05
2.776162091322476e-07 2.776159249151533e-07
rl training, epoch1, iter0, batch581/1133, batch loss:2.776159249151533e-07, Training time:30875.532949447632
batch reward last col mean 1.0874547928807488e-09 first col mean 0.0019097188487648964 all mean 1.929595418914687e-05
7.621107215527445e-05 7.621106487931684e-05
rl training, epoch1, iter0, batch582/1133, batch loss:7.621106487931684e-05, Training time:30903.810787439346
batch reward last col mean 2.843278501529767e-09 first col mean 5.977233286103001e-08 all mean 2.1382403403436e-08
4.534316477844413e-09 4.534306707881797e-09
rl training, epoch1, iter0, batch583/1133, batch loss:4.534306707881797e-09, Training time:30932.31723666191
batch reward last col mean 0.006839617621153593 first col mean 2.8216557979021673e-09 all mean 0.006580546498298645
0.0006227160920388997 0.0006227160920388997
rl training, epoch1, iter0, batch584/1133, batch loss:0.0006227160920388997, Training time:30960.051839351654
batch reward last col mean 1.1801838395442132e-09 first col mean 1.814776107167404e-09 all mean 8.914586942410097e-06
5.596699338639155e-06 5.59670206712326e-06
rl training, epoch1, iter0, batch585/1133, batch loss:5.59670206712326e-06, Training time:30988.016605615616
batch reward last col mean 0.0005178253632038832 first col mean 1.770109214760396e-08 all mean 0.0004812168190255761
3.301899050711654e-05 3.301899050711654e-05
rl training, epoch1, iter0, batch586/1133, batch loss:3.301899050711654e-05, Training time:31015.998124837875
batch reward last col mean 8.709523102723438e-10 first col mean 1.0617103862742283e-09 all mean 7.760220022134945e-09
4.1688461710487346e-11 4.168763251266583e-11
rl training, epoch1, iter0, batch587/1133, batch loss:4.168763251266583e-11, Training time:31043.82343506813
batch reward last col mean 2.1723214338464913e-09 first col mean 1.7478554159566784e-09 all mean 2.4393951303380845e-09
1.0306500097811977e-10 1.0306499403922587e-10
rl training, epoch1, iter0, batch588/1133, batch loss:1.0306499403922587e-10, Training time:31071.647267580032
batch reward last col mean 1.0708817832494333e-08 first col mean 0.001266979263164103 all mean 1.3557201782532502e-05
3.662490416900255e-05 3.662490416900255e-05
rl training, epoch1, iter0, batch589/1133, batch loss:3.662490416900255e-05, Training time:31099.58554458618
batch reward last col mean 2.8596798262725542e-09 first col mean 3.6820368976009377e-09 all mean 3.5872592007990534e-08
1.3050164504591066e-08 1.3050166280947906e-08
rl training, epoch1, iter0, batch590/1133, batch loss:1.3050166280947906e-08, Training time:31127.52282500267
batch reward last col mean 3.541678283980332e-09 first col mean 2.3184036912482497e-09 all mean 3.079917223658413e-05
0.00017337393364869058 0.00017337393364869058
rl training, epoch1, iter0, batch591/1133, batch loss:0.00017337393364869058, Training time:31155.32955098152
batch reward last col mean 1.1950905820512503e-09 first col mean 2.5641048750912887e-07 all mean 8.142023055768277e-09
1.673230720644625e-10 1.6732312757561374e-10
rl training, epoch1, iter0, batch592/1133, batch loss:1.6732312757561374e-10, Training time:31182.870752811432
batch reward last col mean 1.216345579813094e-09 first col mean 4.377714635239727e-09 all mean 3.143735011690296e-05
4.282510053599253e-05 4.282510417397134e-05
rl training, epoch1, iter0, batch593/1133, batch loss:4.282510417397134e-05, Training time:31210.308875322342
batch reward last col mean 5.116139050187485e-07 first col mean 7.1554211444890825e-09 all mean 1.4194056596750215e-08
3.856194297213733e-08 3.856193586670997e-08
rl training, epoch1, iter0, batch594/1133, batch loss:3.856193586670997e-08, Training time:31238.372133016586
batch reward last col mean 3.988670727039789e-09 first col mean 4.293545519118425e-09 all mean 2.13966382034414e-06
3.9371901294771305e-08 3.937239156925898e-08
rl training, epoch1, iter0, batch595/1133, batch loss:3.937239156925898e-08, Training time:31266.385296821594
batch reward last col mean 0.006216645240783691 first col mean 2.5225168620579552e-09 all mean 0.005921990144997835
0.00024153754930011928 0.00024153759295586497
rl training, epoch1, iter0, batch596/1133, batch loss:0.00024153759295586497, Training time:31293.730899333954
batch reward last col mean 1.7590111383469775e-05 first col mean 1.183880882216215e-09 all mean 1.670375968387816e-05
1.299964992540481e-06 1.299964992540481e-06
rl training, epoch1, iter0, batch597/1133, batch loss:1.299964992540481e-06, Training time:31321.842592716217
batch reward last col mean 1.1147960776725085e-08 first col mean 3.2612448297442143e-09 all mean 2.5794456348648964e-08
3.6740624431708113e-10 3.674015813803777e-10
rl training, epoch1, iter0, batch598/1133, batch loss:3.674015813803777e-10, Training time:31349.697869300842
batch reward last col mean 1.18710197227756e-09 first col mean 2.23203633353819e-09 all mean 3.0155240438034525e-06
2.3292592299384296e-09 2.3276838234664865e-09
rl training, epoch1, iter0, batch599/1133, batch loss:2.3276838234664865e-09, Training time:31377.02800989151
batch reward last col mean 1.6465402374876703e-09 first col mean 0.00035989953903481364 all mean 1.434776004316518e-05
1.9795188563875854e-05 1.979518674488645e-05
rl training, epoch1, iter0, batch600/1133, batch loss:1.979518674488645e-05, Training time:31404.91651582718
batch reward last col mean 1.3996468428700837e-09 first col mean 2.0013817270125855e-09 all mean 7.081623731863829e-09
5.4615145739234094e-11 5.4618486816648826e-11
rl training, epoch1, iter0, batch601/1133, batch loss:5.4618486816648826e-11, Training time:31432.83115005493
batch reward last col mean 2.440069479803242e-09 first col mean 2.4063679937569304e-09 all mean 6.401339305739384e-06
3.6674955481430516e-05 3.6674955481430516e-05
rl training, epoch1, iter0, batch602/1133, batch loss:3.6674955481430516e-05, Training time:31460.599406957626
batch reward last col mean 8.419037134110852e-10 first col mean 6.442776312454157e-10 all mean 8.876778338162694e-06
2.1566314956089627e-08 2.1570377484181336e-08
rl training, epoch1, iter0, batch603/1133, batch loss:2.1570377484181336e-08, Training time:31488.12755203247
batch reward last col mean 3.370647316813802e-09 first col mean 4.456137681074779e-09 all mean 1.2204988024677732e-06
4.537428139883559e-06 4.537428139883559e-06
rl training, epoch1, iter0, batch604/1133, batch loss:4.537428139883559e-06, Training time:31515.504766225815
batch reward last col mean 6.571366228946829e-10 first col mean 1.0800683680756151e-09 all mean 8.868771828041133e-10
6.852203526808154e-11 6.852201445139983e-11
rl training, epoch1, iter0, batch605/1133, batch loss:6.852201445139983e-11, Training time:31543.679772138596
batch reward last col mean 3.2908689107102873e-09 first col mean 0.0017924930434674025 all mean 1.8155082216253504e-05
2.1107468910486205e-06 2.110743025696138e-06
rl training, epoch1, iter0, batch606/1133, batch loss:2.110743025696138e-06, Training time:31571.195766687393
batch reward last col mean 3.3580451752612817e-09 first col mean 2.292333434184002e-09 all mean 1.1509549757704463e-08
9.422781999113283e-11 9.4224919533481e-11
rl training, epoch1, iter0, batch607/1133, batch loss:9.4224919533481e-11, Training time:31598.68720960617
batch reward last col mean 8.762824910135691e-10 first col mean 1.3494263484403746e-09 all mean 7.739452634325517e-09
9.081097651630898e-09 9.081098539809318e-09
rl training, epoch1, iter0, batch608/1133, batch loss:9.081098539809318e-09, Training time:31626.610024690628
batch reward last col mean 2.352386951898211e-09 first col mean 1.5678813802821878e-09 all mean 5.862696070835227e-06
9.478593909761912e-09 9.476869067270854e-09
rl training, epoch1, iter0, batch609/1133, batch loss:9.476869067270854e-09, Training time:31654.40450692177
batch reward last col mean 1.0021627971923408e-09 first col mean 0.0012969218660145998 all mean 1.3147784557077102e-05
1.0778865089378087e-06 1.0778844625747297e-06
rl training, epoch1, iter0, batch610/1133, batch loss:1.0778844625747297e-06, Training time:31682.137800216675
batch reward last col mean 1.590689802100087e-09 first col mean 9.009472279331021e-08 all mean 4.653087692929603e-09
1.0908454695091052e-10 1.090832563166444e-10
rl training, epoch1, iter0, batch611/1133, batch loss:1.090832563166444e-10, Training time:31709.827967643738
batch reward last col mean 3.9273981289333904e-10 first col mean 9.916482079930233e-10 all mean 6.800611740409579e-10
7.75357972271351e-11 7.753590131054366e-11
rl training, epoch1, iter0, batch612/1133, batch loss:7.753590131054366e-11, Training time:31737.64290523529
batch reward last col mean 9.93824800232801e-10 first col mean 4.167122469311835e-08 all mean 6.484537493633979e-07
1.65895885917422e-09 1.6590112617009822e-09
rl training, epoch1, iter0, batch613/1133, batch loss:1.6590112617009822e-09, Training time:31765.209106206894
batch reward last col mean 5.523894675008023e-09 first col mean 8.143519192316262e-10 all mean 1.595687915134647e-09
2.8895752457458457e-10 2.8895785764149196e-10
rl training, epoch1, iter0, batch614/1133, batch loss:2.8895785764149196e-10, Training time:31792.633329868317
batch reward last col mean 6.670456187407581e-09 first col mean 4.857514834810672e-09 all mean 3.8714166095132896e-08
4.5363193756919884e-10 4.5365383671835957e-10
rl training, epoch1, iter0, batch615/1133, batch loss:4.5365383671835957e-10, Training time:31820.280027627945
batch reward last col mean 4.0087849706438305e-10 first col mean 4.732100267190731e-10 all mean 7.985921368636184e-10
1.9524000471893288e-11 1.9524009145510668e-11
rl training, epoch1, iter0, batch616/1133, batch loss:1.9524009145510668e-11, Training time:31847.8503344059
batch reward last col mean 1.2787694236848779e-09 first col mean 0.001439070445485413 all mean 2.8065809601685032e-05
2.6297865929336695e-07 2.629789150887518e-07
rl training, epoch1, iter0, batch617/1133, batch loss:2.629789150887518e-07, Training time:31875.58027601242
batch reward last col mean 1.202699051461309e-09 first col mean 1.3372791762833458e-09 all mean 1.2742518151753757e-07
1.5731894675852232e-09 1.5731699276599898e-09
rl training, epoch1, iter0, batch618/1133, batch loss:1.5731699276599898e-09, Training time:31903.107572555542
batch reward last col mean 1.2469227872458077e-09 first col mean 1.1522123255502947e-09 all mean 7.411917977151461e-06
5.141318126788974e-08 5.141131609320837e-08
rl training, epoch1, iter0, batch619/1133, batch loss:5.141131609320837e-08, Training time:31931.005165576935
batch reward last col mean 4.258175145821497e-09 first col mean 0.00010463011130923405 all mean 1.1934843087146874e-06
1.4638453649240546e-07 1.4638430911873002e-07
rl training, epoch1, iter0, batch620/1133, batch loss:1.4638430911873002e-07, Training time:31958.3558883667
batch reward last col mean 4.2505665653891356e-09 first col mean 5.857740514869647e-09 all mean 2.342565252888562e-08
1.86283960479372e-10 1.8629633946609658e-10
rl training, epoch1, iter0, batch621/1133, batch loss:1.8629633946609658e-10, Training time:31986.2210521698
batch reward last col mean 8.904190718084237e-10 first col mean 7.844173088855655e-10 all mean 1.0192876542802765e-09
3.979985785385054e-11 3.979980581214626e-11
rl training, epoch1, iter0, batch622/1133, batch loss:3.979980581214626e-11, Training time:32014.35059595108
batch reward last col mean 3.785235236364315e-09 first col mean 8.52625259284423e-09 all mean 1.4494009519694373e-05
1.0039208575562952e-07 1.0038727538130843e-07
rl training, epoch1, iter0, batch623/1133, batch loss:1.0038727538130843e-07, Training time:32041.78963112831
batch reward last col mean 2.58444976530825e-09 first col mean 2.088626605001309e-09 all mean 1.1621663134064875e-06
7.521004476984672e-07 7.521006750721426e-07
rl training, epoch1, iter0, batch624/1133, batch loss:7.521006750721426e-07, Training time:32069.809873104095
batch reward last col mean 2.3923001357673e-09 first col mean 2.0722703553133215e-09 all mean 1.8083090253639966e-05
5.910860636504367e-07 5.910897016292438e-07
rl training, epoch1, iter0, batch625/1133, batch loss:5.910897016292438e-07, Training time:32097.314429044724
batch reward last col mean 2.7493426387081854e-05 first col mean 1.4914213197769755e-09 all mean 2.6677373170969076e-05
1.2078877489329898e-06 1.207887635246152e-06
rl training, epoch1, iter0, batch626/1133, batch loss:1.207887635246152e-06, Training time:32125.477863311768
batch reward last col mean 0.0012598545290529728 first col mean 2.6532034347326316e-09 all mean 0.0012216795003041625
7.255856326082721e-05 7.255857053678483e-05
rl training, epoch1, iter0, batch627/1133, batch loss:7.255857053678483e-05, Training time:32153.2582154274
batch reward last col mean 2.497080764385373e-09 first col mean 0.00014565701712854207 all mean 2.0943343770341016e-05
0.00017494744679424912 0.00017494741769041866
rl training, epoch1, iter0, batch628/1133, batch loss:0.00017494741769041866, Training time:32180.847230196
batch reward last col mean 7.06230309788225e-08 first col mean 1.3500576212521764e-09 all mean 2.7059068319346125e-09
4.058082314628564e-09 4.058081870539354e-09
rl training, epoch1, iter0, batch629/1133, batch loss:4.058081870539354e-09, Training time:32208.538734912872
batch reward last col mean 1.1160441459878712e-09 first col mean 1.4482920418501521e-09 all mean 1.7607771951588802e-05
1.628953032195568e-05 1.628951940801926e-05
rl training, epoch1, iter0, batch630/1133, batch loss:1.628951940801926e-05, Training time:32236.63139653206
batch reward last col mean 3.225846256782461e-09 first col mean 2.79333223218714e-09 all mean 3.0082113880780526e-05
1.7187318235301063e-06 1.7187322782774572e-06
rl training, epoch1, iter0, batch631/1133, batch loss:1.7187322782774572e-06, Training time:32264.42741036415
batch reward last col mean 7.37122807237256e-10 first col mean 1.1529942556265382e-09 all mean 1.593240085639991e-05
1.1223318097108859e-07 1.122352912830138e-07
rl training, epoch1, iter0, batch632/1133, batch loss:1.122352912830138e-07, Training time:32291.830228805542
batch reward last col mean 9.452580052027315e-09 first col mean 0.00035000062780454755 all mean 8.190849257516675e-06
2.7077776394435205e-05 2.7077778213424608e-05
rl training, epoch1, iter0, batch633/1133, batch loss:2.7077778213424608e-05, Training time:32319.446960687637
batch reward last col mean 1.3618172145513086e-09 first col mean 1.622210921148337e-09 all mean 7.137586965910714e-09
1.0895281205014484e-10 1.0895602475802235e-10
rl training, epoch1, iter0, batch634/1133, batch loss:1.0895602475802235e-10, Training time:32347.471735715866
batch reward last col mean 2.634074514062945e-09 first col mean 4.009359066969864e-09 all mean 3.811916394624859e-05
8.532728315913118e-06 8.532717401976697e-06
rl training, epoch1, iter0, batch635/1133, batch loss:8.532717401976697e-06, Training time:32374.89128613472
batch reward last col mean 3.076471966068084e-09 first col mean 0.00011494930367916822 all mean 1.6605723430984654e-05
1.0207269951933995e-05 1.0207275408902206e-05
rl training, epoch1, iter0, batch636/1133, batch loss:1.0207275408902206e-05, Training time:32402.481161355972
batch reward last col mean 2.131413268102733e-09 first col mean 1.7470667135199847e-09 all mean 2.584476188616236e-09
1.7199185131655526e-10 1.7199187907213087e-10
rl training, epoch1, iter0, batch637/1133, batch loss:1.7199187907213087e-10, Training time:32430.714570760727
batch reward last col mean 1.737703536619506e-09 first col mean 0.0016897909808903933 all mean 1.8420820197206922e-05
3.87795398637536e-06 3.877950803143904e-06
rl training, epoch1, iter0, batch638/1133, batch loss:3.877950803143904e-06, Training time:32458.447561502457
batch reward last col mean 2.047030989160703e-09 first col mean 2.124050935137234e-09 all mean 3.578593421593723e-08
2.9145014179832174e-10 2.9145724722567934e-10
rl training, epoch1, iter0, batch639/1133, batch loss:2.9145724722567934e-10, Training time:32486.208976507187
batch reward last col mean 8.75064021244043e-10 first col mean 0.00015363856800831854 all mean 1.5551505612165784e-06
1.173939345733288e-08 1.1739549776734748e-08
rl training, epoch1, iter0, batch640/1133, batch loss:1.1739549776734748e-08, Training time:32513.932753562927
batch reward last col mean 0.002115502255037427 first col mean 7.774728638665351e-10 all mean 0.0020353104919195175
8.373528544325382e-05 8.373528544325382e-05
rl training, epoch1, iter0, batch641/1133, batch loss:8.373528544325382e-05, Training time:32541.600539684296
batch reward last col mean 1.1622776074915464e-09 first col mean 9.552852953120805e-10 all mean 6.336895808090048e-07
5.229451289778808e-07 5.229452426647185e-07
rl training, epoch1, iter0, batch642/1133, batch loss:5.229452426647185e-07, Training time:32569.539353370667
batch reward last col mean 1.6926164914110586e-09 first col mean 2.5827238125941676e-09 all mean 2.971939805362922e-09
1.6737167207736547e-10 1.6737093655461166e-10
rl training, epoch1, iter0, batch643/1133, batch loss:1.6737093655461166e-10, Training time:32597.49427342415
batch reward last col mean 1.005421412791918e-09 first col mean 1.6184258377904825e-09 all mean 1.8558928616130288e-07
9.866176764461443e-10 9.866198968921935e-10
rl training, epoch1, iter0, batch644/1133, batch loss:9.866198968921935e-10, Training time:32625.533601284027
batch reward last col mean 2.739261928397241e-09 first col mean 4.824684651794087e-09 all mean 1.797237382561434e-05
7.333098324124876e-07 7.333015332733339e-07
rl training, epoch1, iter0, batch645/1133, batch loss:7.333015332733339e-07, Training time:32653.945222854614
batch reward last col mean 0.002354053547605872 first col mean 3.225751788704656e-05 all mean 0.0022616563364863396
0.00016503776714671403 0.00016503776714671403
rl training, epoch1, iter0, batch646/1133, batch loss:0.00016503776714671403, Training time:32681.621888399124
batch reward last col mean 1.796104598383863e-09 first col mean 2.6137783049051677e-09 all mean 3.5589205253927503e-06
1.8958822920467355e-06 1.895881723612547e-06
rl training, epoch1, iter0, batch647/1133, batch loss:1.895881723612547e-06, Training time:32710.113642692566
batch reward last col mean 1.4792688185494285e-09 first col mean 2.3173996055447788e-09 all mean 1.812791742850095e-05
1.792121838661842e-05 1.7921222024597228e-05
rl training, epoch1, iter0, batch648/1133, batch loss:1.7921222024597228e-05, Training time:32737.595271348953
batch reward last col mean 6.8030137079233555e-09 first col mean 8.418948205246579e-09 all mean 7.073796659540221e-09
4.6384487917272565e-10 4.6384471263927196e-10
rl training, epoch1, iter0, batch649/1133, batch loss:4.6384471263927196e-10, Training time:32765.632656812668
batch reward last col mean 1.7971932830818105e-09 first col mean 3.2365865543226846e-09 all mean 2.1629477487294935e-05
9.464443428441882e-05 9.464442700846121e-05
rl training, epoch1, iter0, batch650/1133, batch loss:9.464442700846121e-05, Training time:32793.40299344063
batch reward last col mean 1.6887333753601297e-09 first col mean 2.0339470108154956e-09 all mean 3.307206668523577e-07
1.2585096555994824e-06 1.25850976928632e-06
rl training, epoch1, iter0, batch651/1133, batch loss:1.25850976928632e-06, Training time:32820.950741291046
batch reward last col mean 2.589585434975561e-09 first col mean 2.2397614873881366e-09 all mean 9.090338153328048e-07
2.628021000816716e-08 2.6279895593006586e-08
rl training, epoch1, iter0, batch652/1133, batch loss:2.6279895593006586e-08, Training time:32849.13245892525
batch reward last col mean 8.476251367461884e-10 first col mean 1.3919936314721326e-09 all mean 5.3850222059281805e-09
6.082704478993506e-11 6.08281758296414e-11
rl training, epoch1, iter0, batch653/1133, batch loss:6.08281758296414e-11, Training time:32876.985218048096
batch reward last col mean 4.771697259542407e-09 first col mean 1.4090991706794398e-09 all mean 1.7303096733201073e-09
2.409080157583787e-10 2.4090787698050065e-10
rl training, epoch1, iter0, batch654/1133, batch loss:2.4090787698050065e-10, Training time:32904.95038843155
batch reward last col mean 8.64204878325836e-07 first col mean 0.0004095376643817872 all mean 1.2824512850784231e-05
1.0767250842036447e-06 1.0767267895062105e-06
rl training, epoch1, iter0, batch655/1133, batch loss:1.0767267895062105e-06, Training time:32932.94585633278
batch reward last col mean 1.0117052751112965e-09 first col mean 1.0243235148976737e-09 all mean 1.2550648298415013e-09
3.789544372745368e-11 3.78954784219232e-11
rl training, epoch1, iter0, batch656/1133, batch loss:3.78954784219232e-11, Training time:32961.197479486465
batch reward last col mean 4.5530526016079875e-09 first col mean 7.327663809064688e-09 all mean 2.795804539346136e-05
1.465497916797176e-05 1.4654970982519444e-05
rl training, epoch1, iter0, batch657/1133, batch loss:1.4654970982519444e-05, Training time:32989.149872779846
batch reward last col mean 5.288914861623084e-10 first col mean 9.23874476921327e-10 all mean 9.439470886718482e-06
6.083570042392239e-06 6.083573680371046e-06
rl training, epoch1, iter0, batch658/1133, batch loss:6.083573680371046e-06, Training time:33017.109691381454
batch reward last col mean 0.0012616269523277879 first col mean 9.12022513066546e-10 all mean 0.001236142124980688
9.727665019454435e-05 9.727665019454435e-05
rl training, epoch1, iter0, batch659/1133, batch loss:9.727665019454435e-05, Training time:33045.411492586136
batch reward last col mean 1.9359847058808555e-09 first col mean 2.9038096371891697e-09 all mean 2.999751336218992e-09
1.3252539343699965e-10 1.3252540731478746e-10
rl training, epoch1, iter0, batch660/1133, batch loss:1.3252540731478746e-10, Training time:33073.10836195946
batch reward last col mean 3.7351522763628964e-08 first col mean 1.1112755160525012e-09 all mean 1.4484692655969411e-05
1.440817413822515e-05 1.440816959075164e-05
rl training, epoch1, iter0, batch661/1133, batch loss:1.440816959075164e-05, Training time:33101.060106515884
batch reward last col mean 0.0004992068279534578 first col mean 0.0003035233239643276 all mean 0.000477065856102854
2.9500748496502638e-05 2.9500752134481445e-05
rl training, epoch1, iter0, batch662/1133, batch loss:2.9500752134481445e-05, Training time:33128.689643383026
batch reward last col mean 5.22520338108734e-09 first col mean 0.0002953195944428444 all mean 1.3889504771213979e-05
5.406839591159951e-06 5.406839591159951e-06
rl training, epoch1, iter0, batch663/1133, batch loss:5.406839591159951e-06, Training time:33156.44720363617
batch reward last col mean 8.44277425748885e-10 first col mean 9.962791702733398e-10 all mean 1.13879096375058e-07
7.660081458027435e-09 7.660070799886398e-09
rl training, epoch1, iter0, batch664/1133, batch loss:7.660070799886398e-09, Training time:33184.14748239517
batch reward last col mean 2.052199299384938e-09 first col mean 1.624910872521923e-09 all mean 7.04243518612202e-07
5.1520387955861224e-09 5.152110738038118e-09
rl training, epoch1, iter0, batch665/1133, batch loss:5.152110738038118e-09, Training time:33212.08056616783
batch reward last col mean 0.0005653742700815201 first col mean 5.066453923063818e-09 all mean 0.0005368571728467941
4.5851840695831925e-05 4.5851840695831925e-05
rl training, epoch1, iter0, batch666/1133, batch loss:4.5851840695831925e-05, Training time:33239.75213551521
batch reward last col mean 1.9551116281490977e-09 first col mean 1.2965608586767985e-09 all mean 6.060338364477502e-06
2.622160354803782e-05 2.6221601729048416e-05
rl training, epoch1, iter0, batch667/1133, batch loss:2.6221601729048416e-05, Training time:33267.74014091492
batch reward last col mean 0.0006243856041692197 first col mean 3.6491762944734774e-09 all mean 0.0005928517202846706
2.7169025997864082e-05 2.716902963584289e-05
rl training, epoch1, iter0, batch668/1133, batch loss:2.716902963584289e-05, Training time:33295.34363102913
batch reward last col mean 2.8040558319730735e-08 first col mean 1.7856889300560397e-09 all mean 6.051180001520606e-09
1.5507002348869037e-09 1.5506984585300643e-09
rl training, epoch1, iter0, batch669/1133, batch loss:1.5506984585300643e-09, Training time:33322.82052707672
batch reward last col mean 1.11034625938089e-09 first col mean 6.895892745717447e-09 all mean 1.6326895391216567e-09
1.0354380547417108e-10 1.0354361812403567e-10
rl training, epoch1, iter0, batch670/1133, batch loss:1.0354361812403567e-10, Training time:33350.88644742966
batch reward last col mean 4.14305006968263e-10 first col mean 4.441405690158717e-05 all mean 4.5580901542052743e-07
8.035550891349885e-09 8.035751619672737e-09
rl training, epoch1, iter0, batch671/1133, batch loss:8.035751619672737e-09, Training time:33379.254383563995
batch reward last col mean 5.53797185887106e-09 first col mean 9.554236513054093e-09 all mean 2.4542953269701684e-07
1.7142637309675024e-09 1.7142394170832631e-09
rl training, epoch1, iter0, batch672/1133, batch loss:1.7142394170832631e-09, Training time:33406.857610702515
batch reward last col mean 7.170298799152874e-10 first col mean 1.0762444269118987e-09 all mean 1.3264685549074784e-05
3.427002957323566e-05 3.427002957323566e-05
rl training, epoch1, iter0, batch673/1133, batch loss:3.427002957323566e-05, Training time:33434.6975338459
batch reward last col mean 2.120673947558771e-08 first col mean 1.7436315502550315e-08 all mean 2.5029497919604182e-05
4.730389264295809e-05 4.730389264295809e-05
rl training, epoch1, iter0, batch674/1133, batch loss:4.730389264295809e-05, Training time:33462.39070558548
batch reward last col mean 3.803927395296114e-09 first col mean 7.281165004258128e-09 all mean 1.4173498357195058e-06
1.9322049737979796e-08 1.932171400653715e-08
rl training, epoch1, iter0, batch675/1133, batch loss:1.932171400653715e-08, Training time:33489.974731206894
batch reward last col mean 1.8122692235778004e-09 first col mean 1.5966850064330629e-09 all mean 3.143219906576178e-09
1.23523552497673e-10 1.2352403822024627e-10
rl training, epoch1, iter0, batch676/1133, batch loss:1.2352403822024627e-10, Training time:33517.97292637825
batch reward last col mean 2.4455846237003698e-09 first col mean 1.7718936318189549e-09 all mean 2.8912492400223755e-09
1.968303853239206e-10 1.9683081553534265e-10
rl training, epoch1, iter0, batch677/1133, batch loss:1.9683081553534265e-10, Training time:33545.8991754055
batch reward last col mean 0.001244890969246626 first col mean 0.00041674578096717596 all mean 0.0011865852866321802
6.955565913813189e-05 6.95556664140895e-05
rl training, epoch1, iter0, batch678/1133, batch loss:6.95556664140895e-05, Training time:33573.60457611084
batch reward last col mean 1.1755516560185697e-09 first col mean 4.567869837046601e-05 all mean 5.078469712316291e-06
2.1672617478429856e-08 2.1668915550776546e-08
rl training, epoch1, iter0, batch679/1133, batch loss:2.1668915550776546e-08, Training time:33601.36308550835
batch reward last col mean 3.2636489066817376e-09 first col mean 3.5784741836408784e-09 all mean 1.8281525626662187e-05
3.886133015384985e-07 3.8862066276124096e-07
rl training, epoch1, iter0, batch680/1133, batch loss:3.8862066276124096e-07, Training time:33628.588683605194
batch reward last col mean 2.4519708485826186e-09 first col mean 1.9260415484723126e-09 all mean 6.873741575930126e-09
9.312431381580666e-11 9.312229459768062e-11
rl training, epoch1, iter0, batch681/1133, batch loss:9.312229459768062e-11, Training time:33655.8580288887
batch reward last col mean 2.5269701886543317e-09 first col mean 0.00130847271066159 all mean 2.5322575311292894e-05
2.9414836717478465e-06 2.9414827622531448e-06
rl training, epoch1, iter0, batch682/1133, batch loss:2.9414827622531448e-06, Training time:33683.45598697662
batch reward last col mean 1.848177944019369e-09 first col mean 1.6324595009109544e-09 all mean 2.2491736672236584e-05
3.151081546093337e-05 3.1510811822954565e-05
rl training, epoch1, iter0, batch683/1133, batch loss:3.1510811822954565e-05, Training time:33710.70380735397
batch reward last col mean 9.129583755651538e-10 first col mean 7.030813867459074e-05 all mean 7.1124031819636e-07
4.425177166922367e-07 4.425178872224933e-07
rl training, epoch1, iter0, batch684/1133, batch loss:4.425178872224933e-07, Training time:33738.03569769859
batch reward last col mean 1.0606632239174019e-09 first col mean 1.6930323809560832e-09 all mean 2.4291599402204156e-05
7.208205352071673e-05 7.208204624475911e-05
rl training, epoch1, iter0, batch685/1133, batch loss:7.208204624475911e-05, Training time:33765.30038738251
batch reward last col mean 8.067244094966952e-10 first col mean 8.643996629587036e-10 all mean 1.5255475771525084e-09
5.7020107385730157e-11 5.7020031057897214e-11
rl training, epoch1, iter0, batch686/1133, batch loss:5.7020031057897214e-11, Training time:33792.46238565445
batch reward last col mean 2.319380291737616e-05 first col mean 0.0003649643331300467 all mean 2.598810533527285e-05
1.0518282351767994e-06 1.0518299404793652e-06
rl training, epoch1, iter0, batch687/1133, batch loss:1.0518299404793652e-06, Training time:33820.03948402405
batch reward last col mean 4.485238291884741e-10 first col mean 4.192705546302022e-06 all mean 1.892000909720082e-05
1.6975467076463246e-07 1.6976071037788643e-07
rl training, epoch1, iter0, batch688/1133, batch loss:1.6976071037788643e-07, Training time:33847.639353752136
batch reward last col mean 5.754772214316972e-09 first col mean 9.60554213946807e-09 all mean 1.2420773742860547e-08
5.039862971401021e-10 5.039886841196051e-10
rl training, epoch1, iter0, batch689/1133, batch loss:5.039886841196051e-10, Training time:33875.285012722015
batch reward last col mean 2.8302329369012114e-09 first col mean 3.782688828835035e-09 all mean 7.291392194019863e-06
2.3015505234980083e-07 2.3015286387817468e-07
rl training, epoch1, iter0, batch690/1133, batch loss:2.3015286387817468e-07, Training time:33903.23184299469
batch reward last col mean 5.391506130436596e-10 first col mean 1.1266965138645446e-09 all mean 8.558811828152102e-07
8.629978083263268e-07 8.629980925434211e-07
rl training, epoch1, iter0, batch691/1133, batch loss:8.629980925434211e-07, Training time:33931.020330905914
batch reward last col mean 6.871264890406792e-09 first col mean 4.7025094929153965e-09 all mean 7.90591982990918e-08
4.3770465030235073e-10 4.376676521200551e-10
rl training, epoch1, iter0, batch692/1133, batch loss:4.376676521200551e-10, Training time:33959.00229072571
batch reward last col mean 3.560382211276192e-09 first col mean 3.1659443955334154e-09 all mean 8.183226896107954e-07
9.220180174907e-09 9.220009644650418e-09
rl training, epoch1, iter0, batch693/1133, batch loss:9.220009644650418e-09, Training time:33986.4930999279
batch reward last col mean 1.209689015624349e-09 first col mean 0.001639551017433405 all mean 2.5723966246005148e-05
2.0087695702386554e-06 2.0087727534701116e-06
rl training, epoch1, iter0, batch694/1133, batch loss:2.0087727534701116e-06, Training time:34013.80307006836
batch reward last col mean 8.376848659175096e-10 first col mean 0.00035473599564284086 all mean 3.5846014725393616e-06
6.684361864017774e-08 6.684263098577503e-08
rl training, epoch1, iter0, batch695/1133, batch loss:6.684263098577503e-08, Training time:34041.18505239487
batch reward last col mean 2.491702844054089e-09 first col mean 3.1155693580586785e-09 all mean 8.91230047272984e-06
1.0165924322791398e-05 1.0165924322791398e-05
rl training, epoch1, iter0, batch696/1133, batch loss:1.0165924322791398e-05, Training time:34068.90760731697
batch reward last col mean 1.54436711454764e-05 first col mean 5.1946091872423494e-09 all mean 1.3018077879678458e-05
8.31446686788695e-06 8.314467777381651e-06
rl training, epoch1, iter0, batch697/1133, batch loss:8.314467777381651e-06, Training time:34096.59187054634
batch reward last col mean 1.2260135129338323e-09 first col mean 1.2379575142773547e-09 all mean 3.532274058670737e-05
3.1166769076662604e-06 3.1166871394816553e-06
rl training, epoch1, iter0, batch698/1133, batch loss:3.1166871394816553e-06, Training time:34124.581747055054
batch reward last col mean 8.366089154776546e-09 first col mean 0.0009765435825102031 all mean 2.422951365588233e-05
1.5625544619979337e-05 1.5625544619979337e-05
rl training, epoch1, iter0, batch699/1133, batch loss:1.5625544619979337e-05, Training time:34152.45677423477
batch reward last col mean 2.9445256899407468e-08 first col mean 0.00019139940559398383 all mean 1.5328972949646413e-05
4.1839350160444155e-05 4.1839350160444155e-05
rl training, epoch1, iter0, batch700/1133, batch loss:4.1839350160444155e-05, Training time:34180.21677803993
batch reward last col mean 3.109069224294103e-09 first col mean 1.6056462825986273e-09 all mean 3.018802274823429e-08
6.067885083282931e-10 6.067839564138922e-10
rl training, epoch1, iter0, batch701/1133, batch loss:6.067839564138922e-10, Training time:34208.07446551323
batch reward last col mean 1.817570427498083e-09 first col mean 7.447976258845301e-06 all mean 1.2043395145155955e-05
2.233011764474213e-05 2.2330119463731535e-05
rl training, epoch1, iter0, batch702/1133, batch loss:2.2330119463731535e-05, Training time:34236.841400146484
batch reward last col mean 1.9008963292321823e-09 first col mean 2.403665710914993e-09 all mean 1.1731403901649173e-05
4.5892786459944546e-08 4.589724511561144e-08
rl training, epoch1, iter0, batch703/1133, batch loss:4.589724511561144e-08, Training time:34264.67950606346
batch reward last col mean 5.635346411736464e-09 first col mean 4.601010239468906e-09 all mean 6.132479413167857e-09
3.054965169724255e-10 3.054965169724255e-10
rl training, epoch1, iter0, batch704/1133, batch loss:3.054965169724255e-10, Training time:34292.27894806862
batch reward last col mean 5.127665403392712e-09 first col mean 3.798740433325065e-09 all mean 1.3907230140830507e-06
1.382227576840478e-08 1.3822505806615482e-08
rl training, epoch1, iter0, batch705/1133, batch loss:1.3822505806615482e-08, Training time:34320.43036341667
batch reward last col mean 6.907725502713902e-10 first col mean 8.388715277973802e-10 all mean 8.389011782128364e-06
3.315303911222145e-05 3.315303911222145e-05
rl training, epoch1, iter0, batch706/1133, batch loss:3.315303911222145e-05, Training time:34348.55415201187
batch reward last col mean 4.4056885917242994e-10 first col mean 6.903195792773431e-10 all mean 6.35385504210717e-07
2.0086556418164037e-08 2.008668964492699e-08
rl training, epoch1, iter0, batch707/1133, batch loss:2.008668964492699e-08, Training time:34375.924672842026
batch reward last col mean 4.629215233364903e-09 first col mean 5.956711124355252e-09 all mean 5.581130224641129e-09
3.558794925417885e-10 3.5587904845257867e-10
rl training, epoch1, iter0, batch708/1133, batch loss:3.5587904845257867e-10, Training time:34403.760998010635
batch reward last col mean 5.974767347538545e-10 first col mean 0.0004677771939896047 all mean 2.4448603653581813e-05
3.564977305359207e-05 3.564977305359207e-05
rl training, epoch1, iter0, batch709/1133, batch loss:3.564977305359207e-05, Training time:34431.249719142914
batch reward last col mean 2.3012671768185555e-09 first col mean 5.600827357454818e-09 all mean 2.9102233956024293e-09
1.74941880426438e-10 1.7494194981537703e-10
rl training, epoch1, iter0, batch710/1133, batch loss:1.7494194981537703e-10, Training time:34458.97207355499
batch reward last col mean 1.4981395013435872e-09 first col mean 1.9349395419254733e-09 all mean 1.96656819753116e-05
8.742867976252455e-06 8.742864338273648e-06
rl training, epoch1, iter0, batch711/1133, batch loss:8.742864338273648e-06, Training time:34487.22425985336
batch reward last col mean 1.0921907822591947e-09 first col mean 0.0002995418035425246 all mean 2.2021356926416047e-05
1.542427128242707e-07 1.5423330523844925e-07
rl training, epoch1, iter0, batch712/1133, batch loss:1.5423330523844925e-07, Training time:34515.07186627388
batch reward last col mean 4.307921130930481e-09 first col mean 2.653579134204165e-09 all mean 1.2876613254775293e-05
1.4340896825615346e-07 1.434099488051288e-07
rl training, epoch1, iter0, batch713/1133, batch loss:1.434099488051288e-07, Training time:34543.10111498833
batch reward last col mean 3.7501179939170015e-10 first col mean 1.1560743473637558e-09 all mean 5.229110477955601e-09
8.875895157745006e-11 8.875779278216811e-11
rl training, epoch1, iter0, batch714/1133, batch loss:8.875779278216811e-11, Training time:34571.43985581398
batch reward last col mean 7.282960901022761e-09 first col mean 0.0009424500167369843 all mean 2.766827128652949e-05
2.519924601074308e-05 2.51992551056901e-05
rl training, epoch1, iter0, batch715/1133, batch loss:2.51992551056901e-05, Training time:34599.361729860306
batch reward last col mean 5.644366751766938e-09 first col mean 1.626653811648282e-09 all mean 5.010828196816419e-09
1.4796868175181999e-09 1.4796850411613605e-09
rl training, epoch1, iter0, batch716/1133, batch loss:1.4796850411613605e-09, Training time:34627.02983999252
batch reward last col mean 3.1820541757099363e-09 first col mean 1.131628235562232e-09 all mean 1.1283912471071744e-07
2.8882982117117706e-10 2.8881919078571627e-10
rl training, epoch1, iter0, batch717/1133, batch loss:2.8881919078571627e-10, Training time:34654.890873909
batch reward last col mean 8.464959844189934e-10 first col mean 1.481909150946592e-09 all mean 1.209005949931452e-05
1.1674207598844077e-05 1.1674200322886463e-05
rl training, epoch1, iter0, batch718/1133, batch loss:1.1674200322886463e-05, Training time:34682.79560637474
batch reward last col mean 8.891204439365197e-10 first col mean 1.3671358489730778e-09 all mean 9.952270119129025e-10
3.9236246196505675e-11 3.923627742152824e-11
rl training, epoch1, iter0, batch719/1133, batch loss:3.923627742152824e-11, Training time:34710.99572467804
batch reward last col mean 2.341261851057652e-09 first col mean 2.001102172854985e-09 all mean 1.7438906070310622e-06
1.126009283325402e-05 1.126009283325402e-05
rl training, epoch1, iter0, batch720/1133, batch loss:1.126009283325402e-05, Training time:34738.62978720665
batch reward last col mean 4.133835496133997e-09 first col mean 5.525369051184725e-09 all mean 1.0116148807526315e-08
1.1775430630578398e-10 1.177537789498473e-10
rl training, epoch1, iter0, batch721/1133, batch loss:1.177537789498473e-10, Training time:34766.32364988327
batch reward last col mean 3.3503451124516914e-09 first col mean 0.00037072374834679067 all mean 2.7948473871219903e-05
0.00010953671153401956 0.00010953671153401956
rl training, epoch1, iter0, batch722/1133, batch loss:0.00010953671153401956, Training time:34793.99684500694
batch reward last col mean 7.289454817538399e-09 first col mean 0.00017860809748526663 all mean 3.449804717092775e-05
1.6042005881899968e-05 1.604200224392116e-05
rl training, epoch1, iter0, batch723/1133, batch loss:1.604200224392116e-05, Training time:34821.53275680542
batch reward last col mean 1.2277447947184328e-09 first col mean 7.18652692910382e-10 all mean 3.0560924901834596e-09
1.0249656678951169e-10 1.0249501941617112e-10
rl training, epoch1, iter0, batch724/1133, batch loss:1.0249501941617112e-10, Training time:34849.13952469826
batch reward last col mean 7.241124366785812e-10 first col mean 7.926254652623754e-10 all mean 1.407989058677117e-09
6.649751582710195e-11 6.649773787170687e-11
rl training, epoch1, iter0, batch725/1133, batch loss:6.649773787170687e-11, Training time:34877.15998673439
batch reward last col mean 2.633213203040441e-09 first col mean 2.769425133664072e-09 all mean 2.0442275854293257e-05
1.3592864434031071e-06 1.3592858749689185e-06
rl training, epoch1, iter0, batch726/1133, batch loss:1.3592858749689185e-06, Training time:34904.88498878479
batch reward last col mean 1.6655408163757102e-09 first col mean 1.6875648656267117e-09 all mean 2.5465869839536026e-06
5.714708777304622e-07 5.714709345738811e-07
rl training, epoch1, iter0, batch727/1133, batch loss:5.714709345738811e-07, Training time:34932.581577301025
batch reward last col mean 1.2787876313424817e-09 first col mean 1.584792963527093e-09 all mean 1.9038097764934037e-09
6.346335956752824e-11 6.346317221739284e-11
rl training, epoch1, iter0, batch728/1133, batch loss:6.346317221739284e-11, Training time:34960.73786115646
batch reward last col mean 9.813598822461245e-10 first col mean 1.3678008725648283e-09 all mean 1.3946210852822105e-09
7.7313613844332e-11 7.7313613844332e-11
rl training, epoch1, iter0, batch729/1133, batch loss:7.7313613844332e-11, Training time:34988.411512851715
batch reward last col mean 2.302237067652868e-09 first col mean 1.3890701922036897e-09 all mean 1.0980043043673504e-05
2.3374262525521772e-07 2.3374327895453462e-07
rl training, epoch1, iter0, batch730/1133, batch loss:2.3374327895453462e-07, Training time:35016.45154118538
batch reward last col mean 1.914539415892591e-09 first col mean 0.0017033284530043602 all mean 1.7207719793077558e-05
2.0066528350071167e-07 2.0066477190994192e-07
rl training, epoch1, iter0, batch731/1133, batch loss:2.0066477190994192e-07, Training time:35044.77435827255
batch reward last col mean 1.797353044175054e-09 first col mean 0.0005383309326134622 all mean 5.473468718264485e-06
7.60714797820583e-08 7.607271612641853e-08
rl training, epoch1, iter0, batch732/1133, batch loss:7.607271612641853e-08, Training time:35072.31643342972
batch reward last col mean 1.7012893316348254e-09 first col mean 2.5658408731032978e-09 all mean 1.7580374333192594e-05
0.0001694171951385215 0.0001694171951385215
rl training, epoch1, iter0, batch733/1133, batch loss:0.0001694171951385215, Training time:35100.18217277527
batch reward last col mean 3.9258285511323265e-09 first col mean 0.0003420876164454967 all mean 3.517639561323449e-05
4.5986280383658595e-06 4.5986321310920175e-06
rl training, epoch1, iter0, batch734/1133, batch loss:4.5986321310920175e-06, Training time:35127.973014354706
batch reward last col mean 5.305112154019298e-07 first col mean 0.0011345497332513332 all mean 1.1480501598271076e-05
6.643718819532296e-08 6.643678318596358e-08
rl training, epoch1, iter0, batch735/1133, batch loss:6.643678318596358e-08, Training time:35155.58195614815
batch reward last col mean 1.6387901036196695e-09 first col mean 1.7831394139022905e-09 all mean 1.904030614241492e-05
1.2595494808920193e-05 1.2595494808920193e-05
rl training, epoch1, iter0, batch736/1133, batch loss:1.2595494808920193e-05, Training time:35183.54215979576
batch reward last col mean 2.849797509085761e-09 first col mean 2.5765363176333267e-09 all mean 2.08498167921789e-05
4.2284322262275964e-05 4.228431498631835e-05
rl training, epoch1, iter0, batch737/1133, batch loss:4.228431498631835e-05, Training time:35211.250279188156
batch reward last col mean 1.8432355641806453e-09 first col mean 1.4410114212992653e-09 all mean 1.7862586901173927e-05
6.70890585752204e-05 6.70890585752204e-05
rl training, epoch1, iter0, batch738/1133, batch loss:6.70890585752204e-05, Training time:35238.94663095474
batch reward last col mean 7.774150212469522e-10 first col mean 1.3809463572656e-09 all mean 1.824997343646828e-05
5.389871304828375e-08 5.389983925851993e-08
rl training, epoch1, iter0, batch739/1133, batch loss:5.389983925851993e-08, Training time:35266.8769056797
batch reward last col mean 1.7275049168929968e-09 first col mean 0.001943626208230853 all mean 1.965636693057604e-05
2.7333786078997946e-07 2.733314374836482e-07
rl training, epoch1, iter0, batch740/1133, batch loss:2.733314374836482e-07, Training time:35294.723917245865
batch reward last col mean 9.928204036668831e-08 first col mean 3.755565636254232e-09 all mean 7.962064785260736e-09
8.40695246751011e-09 8.40695069115327e-09
rl training, epoch1, iter0, batch741/1133, batch loss:8.40695069115327e-09, Training time:35322.36399078369
batch reward last col mean 1.8105630328335565e-09 first col mean 1.927470849594215e-09 all mean 1.3538954590330832e-05
8.810930296476727e-08 8.810712159856848e-08
rl training, epoch1, iter0, batch742/1133, batch loss:8.810712159856848e-08, Training time:35349.89508533478
batch reward last col mean 6.999357204939827e-10 first col mean 1.0774650061051716e-09 all mean 4.9421398529148064e-08
4.49604971308748e-11 4.496780031670866e-11
rl training, epoch1, iter0, batch743/1133, batch loss:4.496780031670866e-11, Training time:35377.61612558365
batch reward last col mean 9.919165488980752e-10 first col mean 3.543921267556982e-10 all mean 7.98793371359352e-06
6.181457865750417e-05 6.181457865750417e-05
rl training, epoch1, iter0, batch744/1133, batch loss:6.181457865750417e-05, Training time:35405.19157242775
batch reward last col mean 2.4255610853174403e-09 first col mean 2.125196685298647e-09 all mean 1.1854178410430904e-05
9.18408841243945e-06 9.18408841243945e-06
rl training, epoch1, iter0, batch745/1133, batch loss:9.18408841243945e-06, Training time:35433.29423093796
batch reward last col mean 1.1206476857594794e-09 first col mean 0.001055413857102394 all mean 1.7856536942417733e-05
7.110030253443256e-08 7.109797195425926e-08
rl training, epoch1, iter0, batch746/1133, batch loss:7.109797195425926e-08, Training time:35461.36857008934
batch reward last col mean 3.343469279215583e-09 first col mean 3.035826923181162e-09 all mean 8.806894697954704e-07
1.0037227184511721e-05 1.0037227184511721e-05
rl training, epoch1, iter0, batch747/1133, batch loss:1.0037227184511721e-05, Training time:35489.19210100174
batch reward last col mean 1.363324830805368e-08 first col mean 0.0008060054969973862 all mean 2.4386647055507638e-05
1.9427923234616173e-06 1.9427841380093014e-06
rl training, epoch1, iter0, batch748/1133, batch loss:1.9427841380093014e-06, Training time:35517.17473983765
batch reward last col mean 2.2848591907376203e-09 first col mean 1.5091694560709357e-09 all mean 1.0680869308998808e-05
1.2828212447857368e-07 1.2827685225147434e-07
rl training, epoch1, iter0, batch749/1133, batch loss:1.2827685225147434e-07, Training time:35545.082971811295
batch reward last col mean 2.7268463043128577e-09 first col mean 2.38858333112546e-09 all mean 2.7926359962293645e-06
1.3140041943415781e-08 1.313966180305215e-08
rl training, epoch1, iter0, batch750/1133, batch loss:1.313966180305215e-08, Training time:35573.120126485825
batch reward last col mean 2.4260187192481908e-09 first col mean 2.444532132273025e-09 all mean 1.2072814570274204e-05
5.488549049914582e-06 5.48854814041988e-06
rl training, epoch1, iter0, batch751/1133, batch loss:5.48854814041988e-06, Training time:35600.86686372757
batch reward last col mean 1.7108593430847918e-09 first col mean 1.7329915280583919e-09 all mean 9.205261449096724e-06
5.7360077335033566e-05 5.736007369705476e-05
rl training, epoch1, iter0, batch752/1133, batch loss:5.736007369705476e-05, Training time:35628.590985774994
batch reward last col mean 4.098846595468331e-09 first col mean 3.4842382312660902e-09 all mean 6.85791334831265e-09
1.9124694883299043e-10 1.912463798436903e-10
rl training, epoch1, iter0, batch753/1133, batch loss:1.912463798436903e-10, Training time:35656.4821870327
batch reward last col mean 1.7202548274752871e-09 first col mean 1.4630960887274114e-09 all mean 6.187091003084788e-06
3.191304642768955e-08 3.1912943398992866e-08
rl training, epoch1, iter0, batch754/1133, batch loss:3.1912943398992866e-08, Training time:35684.242480516434
batch reward last col mean 8.569843501504693e-09 first col mean 4.1333314548808175e-09 all mean 3.001074446729035e-06
3.1617679585593805e-09 3.161005679430673e-09
rl training, epoch1, iter0, batch755/1133, batch loss:3.161005679430673e-09, Training time:35711.59314894676
batch reward last col mean 3.14863379813346e-09 first col mean 2.4111399543613743e-09 all mean 1.0191369526069138e-08
1.0868090455362633e-10 1.0868281968834381e-10
rl training, epoch1, iter0, batch756/1133, batch loss:1.0868281968834381e-10, Training time:35739.137900829315
batch reward last col mean 8.53836779057815e-10 first col mean 0.0003710453456733376 all mean 3.7497918583540013e-06
2.269257670661773e-08 2.2691796885965232e-08
rl training, epoch1, iter0, batch757/1133, batch loss:2.2691796885965232e-08, Training time:35767.23073101044
batch reward last col mean 4.51821380309525e-09 first col mean 4.703364808733568e-09 all mean 5.991585203446448e-05
0.00012207412510178983 0.00012207412510178983
rl training, epoch1, iter0, batch758/1133, batch loss:0.00012207412510178983, Training time:35794.69898605347
batch reward last col mean 5.8753846232662e-10 first col mean 2.0296737623937133e-09 all mean 4.812225142813986e-06
1.5543845677257195e-07 1.554381157120588e-07
rl training, epoch1, iter0, batch759/1133, batch loss:1.554381157120588e-07, Training time:35822.29183936119
batch reward last col mean 0.007231268100440502 first col mean 4.3509227332094724e-09 all mean 0.006957381498068571
0.00010987179121002555 0.00010987181303789839
rl training, epoch1, iter0, batch760/1133, batch loss:0.00010987181303789839, Training time:35849.98410606384
batch reward last col mean 1.8428777392998086e-09 first col mean 1.7899560722511865e-09 all mean 1.7845097318058833e-05
5.0911872676806524e-05 5.0911872676806524e-05
rl training, epoch1, iter0, batch761/1133, batch loss:5.0911872676806524e-05, Training time:35878.090373277664
batch reward last col mean 0.0002049337635980919 first col mean 1.5254756347005127e-09 all mean 0.0001966542040463537
6.167274023027858e-06 6.167273568280507e-06
rl training, epoch1, iter0, batch762/1133, batch loss:6.167273568280507e-06, Training time:35905.697001218796
batch reward last col mean 4.022886024301897e-09 first col mean 2.434513035609598e-09 all mean 7.621121653755836e-07
6.517975066344661e-07 6.517975066344661e-07
rl training, epoch1, iter0, batch763/1133, batch loss:6.517975066344661e-07, Training time:35933.898617982864
batch reward last col mean 0.007096524816006422 first col mean 1.5807031239489788e-09 all mean 0.00680979760363698
0.0001977191714104265 0.00019771915685851127
rl training, epoch1, iter0, batch764/1133, batch loss:0.00019771915685851127, Training time:35961.42657971382
batch reward last col mean 1.7894710158117277e-09 first col mean 8.263230100169494e-10 all mean 6.585937573078127e-09
1.8766904696931874e-10 1.8766947718074078e-10
rl training, epoch1, iter0, batch765/1133, batch loss:1.8766947718074078e-10, Training time:35989.74010205269
batch reward last col mean 1.273377181476576e-09 first col mean 2.087297668040833e-09 all mean 1.9193513445259214e-09
8.186257921538598e-11 8.18628012599909e-11
rl training, epoch1, iter0, batch766/1133, batch loss:8.18628012599909e-11, Training time:36017.131311655045
batch reward last col mean 1.9490995484261475e-09 first col mean 2.024503009678824e-09 all mean 2.4512187835057375e-09
1.0082302354108563e-10 1.0082294027435879e-10
rl training, epoch1, iter0, batch767/1133, batch loss:1.0082294027435879e-10, Training time:36045.09092140198
batch reward last col mean 1.3754637429030936e-09 first col mean 1.6920933987307762e-08 all mean 1.6125810361700132e-05
7.338681371038547e-06 7.338687737501459e-06
rl training, epoch1, iter0, batch768/1133, batch loss:7.338687737501459e-06, Training time:36072.563668489456
batch reward last col mean 4.499687289438725e-10 first col mean 5.87430215581719e-10 all mean 2.713855140612509e-09
3.500857589933126e-11 3.500912060250272e-11
rl training, epoch1, iter0, batch769/1133, batch loss:3.500912060250272e-11, Training time:36100.81603765488
batch reward last col mean 4.682729759508675e-10 first col mean 6.153360043725797e-10 all mean 1.715542566671502e-05
1.7606113033252768e-05 1.7606111214263365e-05
rl training, epoch1, iter0, batch770/1133, batch loss:1.7606111214263365e-05, Training time:36128.919639110565
batch reward last col mean 1.2818475170206511e-09 first col mean 1.2108409830347e-09 all mean 2.4470806238241494e-05
7.5143915978515e-08 7.513279598470035e-08
rl training, epoch1, iter0, batch771/1133, batch loss:7.513279598470035e-08, Training time:36156.4608669281
batch reward last col mean 3.6168239514466904e-09 first col mean 3.3383578124102087e-09 all mean 4.548180054797513e-09
1.0896071822585895e-09 1.0896074043031945e-09
rl training, epoch1, iter0, batch772/1133, batch loss:1.0896074043031945e-09, Training time:36184.53323149681
batch reward last col mean 5.118379053925537e-10 first col mean 0.0020382634829729795 all mean 4.0117283788276836e-05
7.068883292049577e-07 7.068830427670036e-07
rl training, epoch1, iter0, batch773/1133, batch loss:7.068830427670036e-07, Training time:36212.5319981575
batch reward last col mean 2.9146070001928592e-09 first col mean 2.438573343255257e-09 all mean 4.22211998696298e-09
2.454798586626339e-10 2.454796643736046e-10
rl training, epoch1, iter0, batch774/1133, batch loss:2.454796643736046e-10, Training time:36240.14760351181
batch reward last col mean 1.0933163263615597e-09 first col mean 1.5608045966786221e-09 all mean 1.0061297871288843e-05
1.4653829794042394e-07 1.465344183770867e-07
rl training, epoch1, iter0, batch775/1133, batch loss:1.465344183770867e-07, Training time:36267.646268606186
batch reward last col mean 1.1657345089233218e-09 first col mean 1.1180516512609984e-09 all mean 2.3129535975385807e-07
6.621146741991879e-09 6.6212431093504165e-09
rl training, epoch1, iter0, batch776/1133, batch loss:6.6212431093504165e-09, Training time:36295.100002765656
batch reward last col mean 1.0319989307561173e-08 first col mean 0.0021779818926006556 all mean 4.1320439777337015e-05
6.290236456152343e-07 6.290336500569538e-07
rl training, epoch1, iter0, batch777/1133, batch loss:6.290336500569538e-07, Training time:36323.06362223625
batch reward last col mean 0.007599314674735069 first col mean 6.18841568211792e-07 all mean 0.0072155180387198925
0.00018919336434919387 0.00018919333524536341
rl training, epoch1, iter0, batch778/1133, batch loss:0.00018919333524536341, Training time:36350.79919195175
batch reward last col mean 2.854151359699131e-09 first col mean 2.7425088866550595e-09 all mean 3.828815664519425e-08
1.6298128124869748e-10 1.6298329352792962e-10
rl training, epoch1, iter0, batch779/1133, batch loss:1.6298329352792962e-10, Training time:36378.64907169342
batch reward last col mean 0.0036638141609728336 first col mean 0.0008234635461121798 all mean 0.0035611854400485754
0.0002824859111569822 0.0002824859111569822
rl training, epoch1, iter0, batch780/1133, batch loss:0.0002824859111569822, Training time:36407.25590252876
batch reward last col mean 2.2451758230346286e-09 first col mean 0.0013152367901057005 all mean 2.565500653872732e-05
1.4394559855190892e-07 1.4394345271284692e-07
rl training, epoch1, iter0, batch781/1133, batch loss:1.4394345271284692e-07, Training time:36435.18195652962
batch reward last col mean 5.876624187273194e-10 first col mean 7.105281363273264e-10 all mean 3.987464151578024e-05
6.166689854580909e-05 6.16669058217667e-05
rl training, epoch1, iter0, batch782/1133, batch loss:6.16669058217667e-05, Training time:36463.30091166496
batch reward last col mean 9.128658384760513e-10 first col mean 8.286903940835089e-10 all mean 2.026472611760255e-05
0.00016568189312238246 0.00016568187857046723
rl training, epoch1, iter0, batch783/1133, batch loss:0.00016568187857046723, Training time:36491.74417066574
batch reward last col mean 1.3700871548394389e-09 first col mean 1.7871044644124368e-09 all mean 1.5784636930860074e-09
1.504989743938978e-10 1.5049904378283685e-10
rl training, epoch1, iter0, batch784/1133, batch loss:1.5049904378283685e-10, Training time:36519.29278302193
batch reward last col mean 7.207394681074675e-10 first col mean 9.876981454937095e-10 all mean 5.8049812651006505e-05
0.00015384613652713597 0.0001538461510790512
rl training, epoch1, iter0, batch785/1133, batch loss:0.0001538461510790512, Training time:36546.77006864548
batch reward last col mean 0.005521008744835854 first col mean 9.007701251562139e-10 all mean 0.005370799917727709
0.00018842903955373913 0.00018842903955373913
rl training, epoch1, iter0, batch786/1133, batch loss:0.00018842903955373913, Training time:36574.48693037033
batch reward last col mean 1.0800036420732795e-09 first col mean 0.0009113450651057065 all mean 3.590292180888355e-05
0.00013540819054469466 0.0001354081614408642
rl training, epoch1, iter0, batch787/1133, batch loss:0.0001354081614408642, Training time:36602.096737384796
batch reward last col mean 9.79995640193465e-10 first col mean 1.8453911732052575e-09 all mean 6.369042466758401e-07
9.836039680521935e-07 9.836039680521935e-07
rl training, epoch1, iter0, batch788/1133, batch loss:9.836039680521935e-07, Training time:36629.76822185516
batch reward last col mean 0.00011949713370995596 first col mean 2.3767765014781617e-05 all mean 0.00012175289157312363
1.138948391599115e-05 1.1389484825485852e-05
rl training, epoch1, iter0, batch789/1133, batch loss:1.1389484825485852e-05, Training time:36657.29464554787
batch reward last col mean 2.629454209923665e-09 first col mean 2.123768716444374e-09 all mean 3.822023791144602e-05
8.269312274933327e-06 8.26930317998631e-06
rl training, epoch1, iter0, batch790/1133, batch loss:8.26930317998631e-06, Training time:36684.95425486565
batch reward last col mean 0.000977898365817964 first col mean 5.792461706732865e-06 all mean 0.0009745210991241038
5.496691301232204e-05 5.4966905736364424e-05
rl training, epoch1, iter0, batch791/1133, batch loss:5.4966905736364424e-05, Training time:36712.57084226608
batch reward last col mean 8.26405721632284e-10 first col mean 0.0002518282562959939 all mean 4.341819931141799e-06
1.4688811461383011e-05 1.468881055188831e-05
rl training, epoch1, iter0, batch792/1133, batch loss:1.468881055188831e-05, Training time:36740.232659101486
batch reward last col mean 5.7689408805572384e-09 first col mean 0.0018508705543354154 all mean 3.8044829125283286e-05
9.378094887324551e-07 9.377988590131281e-07
rl training, epoch1, iter0, batch793/1133, batch loss:9.377988590131281e-07, Training time:36767.68802833557
batch reward last col mean 1.7227453907864287e-09 first col mean 0.0009428388439118862 all mean 1.791302565834485e-05
1.4144430906526395e-06 1.414443318026315e-06
rl training, epoch1, iter0, batch794/1133, batch loss:1.414443318026315e-06, Training time:36795.198127269745
batch reward last col mean 6.072070846130373e-09 first col mean 0.001799972727894783 all mean 2.1123585611348972e-05
9.024338396557141e-06 9.024338396557141e-06
rl training, epoch1, iter0, batch795/1133, batch loss:9.024338396557141e-06, Training time:36822.92181944847
batch reward last col mean 3.569847972784146e-09 first col mean 1.1339198469073608e-09 all mean 3.1923133064992726e-05
4.4907585106557235e-05 4.4907585106557235e-05
rl training, epoch1, iter0, batch796/1133, batch loss:4.4907585106557235e-05, Training time:36850.83958244324
batch reward last col mean 0.00010148469300474972 first col mean 8.965730935450722e-10 all mean 0.00010464803199283779
1.0234811270493083e-05 1.023481490847189e-05
rl training, epoch1, iter0, batch797/1133, batch loss:1.023481490847189e-05, Training time:36878.47932243347
batch reward last col mean 1.826779061353534e-09 first col mean 1.7935507523603178e-09 all mean 5.141064684721641e-05
0.00012644138769246638 0.0001264414022443816
rl training, epoch1, iter0, batch798/1133, batch loss:0.0001264414022443816, Training time:36906.042054891586
batch reward last col mean 8.740006496310571e-10 first col mean 8.778450188984266e-10 all mean 2.502398729120614e-06
4.072763658768963e-06 4.072763658768963e-06
rl training, epoch1, iter0, batch799/1133, batch loss:4.072763658768963e-06, Training time:36933.52129530907
batch reward last col mean 0.006332650780677795 first col mean 6.323337584035471e-05 all mean 0.006032890640199184
0.0002979347773361951 0.00029793474823236465
rl training, epoch1, iter0, batch800/1133, batch loss:0.00029793474823236465, Training time:36960.9505944252
batch reward last col mean 5.271816871932344e-10 first col mean 9.037401937916911e-10 all mean 6.912496246513911e-07
7.271200530567512e-09 7.271361290861478e-09
rl training, epoch1, iter0, batch801/1133, batch loss:7.271361290861478e-09, Training time:36988.53474378586
batch reward last col mean 1.4469709874731507e-09 first col mean 0.0012330164900049567 all mean 2.4910910724429414e-05
1.9649480691441568e-06 1.964944658539025e-06
rl training, epoch1, iter0, batch802/1133, batch loss:1.964944658539025e-06, Training time:37016.16179394722
batch reward last col mean 7.71180896919077e-10 first col mean 6.530179234687239e-05 all mean 1.9876448277500458e-05
5.836795935465489e-06 5.836792752234032e-06
rl training, epoch1, iter0, batch803/1133, batch loss:5.836792752234032e-06, Training time:37043.59615421295
batch reward last col mean 2.7755520104477682e-09 first col mean 0.0010299402056261897 all mean 1.040812912833644e-05
1.2182345017208718e-06 1.2182375712654903e-06
rl training, epoch1, iter0, batch804/1133, batch loss:1.2182375712654903e-06, Training time:37071.25360560417
batch reward last col mean 4.313315815629437e-10 first col mean 7.091331410968849e-10 all mean 5.747670117628445e-10
2.978063975977996e-11 2.9780580779181776e-11
rl training, epoch1, iter0, batch805/1133, batch loss:2.9780580779181776e-11, Training time:37098.80474472046
batch reward last col mean 3.3243701125229563e-09 first col mean 0.0018899713177233934 all mean 3.8324007618939504e-05
0.00011540094419615343 0.0001154009296442382
rl training, epoch1, iter0, batch806/1133, batch loss:0.0001154009296442382, Training time:37126.45255279541
batch reward last col mean 9.063445549628568e-10 first col mean 0.002158165443688631 all mean 5.6790744565660134e-05
1.743557550071273e-05 1.7435591871617362e-05
rl training, epoch1, iter0, batch807/1133, batch loss:1.7435591871617362e-05, Training time:37154.00721549988
batch reward last col mean 7.745283303606243e-10 first col mean 2.2710307803208707e-06 all mean 2.4013154131807823e-08
1.3831862322177813e-09 1.3831937817343487e-09
rl training, epoch1, iter0, batch808/1133, batch loss:1.3831937817343487e-09, Training time:37181.57984948158
batch reward last col mean 1.6045893502791841e-09 first col mean 1.938373017651429e-09 all mean 2.7508456241776003e-06
9.095604980302596e-08 9.095523267887984e-08
rl training, epoch1, iter0, batch809/1133, batch loss:9.095523267887984e-08, Training time:37209.10526704788
batch reward last col mean 7.895646358946351e-10 first col mean 0.0002180837036576122 all mean 5.42409616173245e-05
0.0001827502273954451 0.0001827502273954451
rl training, epoch1, iter0, batch810/1133, batch loss:0.0001827502273954451, Training time:37236.59309840202
batch reward last col mean 0.002068673260509968 first col mean 0.002756732515990734 all mean 0.0020487613510340452
0.00013250707706902176 0.000132507091620937
rl training, epoch1, iter0, batch811/1133, batch loss:0.000132507091620937, Training time:37264.26026678085
batch reward last col mean 2.648042674024964e-08 first col mean 1.481110789569584e-09 all mean 1.711466393317096e-05
2.4142267648130655e-05 2.4142271286109462e-05
rl training, epoch1, iter0, batch812/1133, batch loss:2.4142271286109462e-05, Training time:37291.688945531845
batch reward last col mean 5.812617498435202e-09 first col mean 0.00015864937449805439 all mean 2.101698555634357e-05
5.090524837214616e-07 5.090525974082993e-07
rl training, epoch1, iter0, batch813/1133, batch loss:5.090525974082993e-07, Training time:37319.42491841316
batch reward last col mean 5.503106859094942e-10 first col mean 0.0012332939077168703 all mean 1.4957887287891936e-05
1.8798465362124261e-07 1.879875384247498e-07
rl training, epoch1, iter0, batch814/1133, batch loss:1.879875384247498e-07, Training time:37347.008276224136
batch reward last col mean 4.089299565634974e-09 first col mean 2.353059080917319e-09 all mean 1.162945591204334e-05
1.885770188891911e-07 1.8857605255107046e-07
rl training, epoch1, iter0, batch815/1133, batch loss:1.8857605255107046e-07, Training time:37374.63936519623
batch reward last col mean 0.007661841344088316 first col mean 2.55009235949899e-09 all mean 0.0072761219926178455
0.00017087541345972568 0.00017087541345972568
rl training, epoch1, iter0, batch816/1133, batch loss:0.00017087541345972568, Training time:37402.31625080109
batch reward last col mean 1.4374554879736934e-09 first col mean 0.0018927269848063588 all mean 3.450465010246262e-05
3.978921813541092e-05 3.978921813541092e-05
rl training, epoch1, iter0, batch817/1133, batch loss:3.978921813541092e-05, Training time:37429.744180202484
batch reward last col mean 1.4040517637425864e-09 first col mean 3.664851828943938e-05 all mean 9.584145118424203e-06
1.0271058272337541e-05 1.0271058272337541e-05
rl training, epoch1, iter0, batch818/1133, batch loss:1.0271058272337541e-05, Training time:37457.26961708069
batch reward last col mean 3.368957186467014e-05 first col mean 1.0043991416353037e-08 all mean 3.599291812861338e-05
6.295339289863477e-07 6.295332468653214e-07
rl training, epoch1, iter0, batch819/1133, batch loss:6.295332468653214e-07, Training time:37485.640352487564
batch reward last col mean 2.645949237489731e-09 first col mean 0.0007365092169493437 all mean 2.9697133868467063e-05
6.25444226898253e-05 6.25444226898253e-05
rl training, epoch1, iter0, batch820/1133, batch loss:6.25444226898253e-05, Training time:37513.516649246216
batch reward last col mean 1.2295356954794556e-09 first col mean 0.0006094963755458593 all mean 6.15833369010943e-06
1.5388796725801512e-07 1.5388732776955294e-07
rl training, epoch1, iter0, batch821/1133, batch loss:1.5388732776955294e-07, Training time:37541.22509121895
batch reward last col mean 1.204000343868472e-09 first col mean 0.0018738710787147284 all mean 7.098133210092783e-05
1.5872086805757135e-05 1.5872092262725346e-05
rl training, epoch1, iter0, batch822/1133, batch loss:1.5872092262725346e-05, Training time:37569.652695417404
batch reward last col mean 2.519043418303113e-09 first col mean 1.885643419186067e-09 all mean 2.3329685063799843e-05
3.6392683000485704e-07 3.639237320385291e-07
rl training, epoch1, iter0, batch823/1133, batch loss:3.639237320385291e-07, Training time:37597.43575334549
batch reward last col mean 2.65043875735671e-09 first col mean 1.8229351361753743e-09 all mean 6.308908268692903e-06
4.5803286496948203e-08 4.5801652248655955e-08
rl training, epoch1, iter0, batch824/1133, batch loss:4.5801652248655955e-08, Training time:37625.6670691967
batch reward last col mean 3.2986637865661805e-09 first col mean 0.0017859749495983124 all mean 5.595902621280402e-05
0.0002499961119610816 0.0002499961119610816
rl training, epoch1, iter0, batch825/1133, batch loss:0.0002499961119610816, Training time:37654.4316341877
batch reward last col mean 1.2420516837252649e-09 first col mean 0.002404249971732497 all mean 7.518516213167459e-05
4.3141099581589515e-07 4.3141773176103015e-07
rl training, epoch1, iter0, batch826/1133, batch loss:4.3141773176103015e-07, Training time:37682.344661951065
batch reward last col mean 0.0013607287546619773 first col mean 2.020301037575223e-09 all mean 0.0013327671913430095
0.00010047805699286982 0.00010047805699286982
rl training, epoch1, iter0, batch827/1133, batch loss:0.00010047805699286982, Training time:37710.87483048439
batch reward last col mean 1.45149703367764e-09 first col mean 1.3617182936798145e-09 all mean 2.562248846516013e-05
6.05489162808226e-07 6.054817163203552e-07
rl training, epoch1, iter0, batch828/1133, batch loss:6.054817163203552e-07, Training time:37738.73257446289
batch reward last col mean 1.3684915423084476e-09 first col mean 2.6360185145790638e-09 all mean 5.088844456935249e-09
1.251343056951626e-10 1.2513434732852602e-10
rl training, epoch1, iter0, batch829/1133, batch loss:1.2513434732852602e-10, Training time:37766.655744314194
batch reward last col mean 1.0546897799557087e-09 first col mean 1.0108770487349261e-09 all mean 2.2019531797923264e-07
4.823645927132247e-09 4.823715205048984e-09
rl training, epoch1, iter0, batch830/1133, batch loss:4.823715205048984e-09, Training time:37794.484956502914
batch reward last col mean 7.616704489343817e-10 first col mean 0.0023881825618445873 all mean 7.269967318279669e-05
3.937199653591961e-05 3.937198925996199e-05
rl training, epoch1, iter0, batch831/1133, batch loss:3.937198925996199e-05, Training time:37822.36846423149
batch reward last col mean 2.0126429411959634e-09 first col mean 3.758990896329806e-09 all mean 5.172818782739341e-05
1.3704579032491893e-05 1.3704571756534278e-05
rl training, epoch1, iter0, batch832/1133, batch loss:1.3704571756534278e-05, Training time:37849.853363752365
batch reward last col mean 4.896366090356707e-10 first col mean 7.685519813094288e-05 all mean 7.404261123156175e-05
8.790310857875738e-06 8.790299943939317e-06
rl training, epoch1, iter0, batch833/1133, batch loss:8.790299943939317e-06, Training time:37877.42658114433
batch reward last col mean 1.5676306919232275e-09 first col mean 6.938594742678106e-05 all mean 3.433742676861584e-05
2.5257410015910864e-05 2.5257420929847285e-05
rl training, epoch1, iter0, batch834/1133, batch loss:2.5257420929847285e-05, Training time:37905.066267967224
batch reward last col mean 0.007659093476831913 first col mean 5.978550543517258e-09 all mean 0.0072985682636499405
0.00027432668139226735 0.0002743267104960978
rl training, epoch1, iter0, batch835/1133, batch loss:0.0002743267104960978, Training time:37932.76353621483
batch reward last col mean 0.00755977863445878 first col mean 0.0032266078051179647 all mean 0.0071962070651352406
0.00038408467662520707 0.0003840847057290375
rl training, epoch1, iter0, batch836/1133, batch loss:0.0003840847057290375, Training time:37960.25841474533
batch reward last col mean 4.650475560197265e-09 first col mean 0.00021646925597451627 all mean 4.528756835497916e-05
3.085783828282729e-05 3.085783828282729e-05
rl training, epoch1, iter0, batch837/1133, batch loss:3.085783828282729e-05, Training time:37987.94194531441
batch reward last col mean 5.596677565833375e-10 first col mean 0.001124114729464054 all mean 9.531554678687826e-05
6.861642032163218e-05 6.861640576971695e-05
rl training, epoch1, iter0, batch838/1133, batch loss:6.861640576971695e-05, Training time:38015.80050158501
batch reward last col mean 1.7234662585963179e-09 first col mean 0.0030558258295059204 all mean 8.315910963574424e-05
1.8588414604892023e-05 1.8588410966913216e-05
rl training, epoch1, iter0, batch839/1133, batch loss:1.8588410966913216e-05, Training time:38043.344459056854
batch reward last col mean 3.0367164338684915e-09 first col mean 0.004230838268995285 all mean 0.0002096850221278146
0.00022775614343117923 0.00022775609977543354
rl training, epoch1, iter0, batch840/1133, batch loss:0.00022775609977543354, Training time:38070.94395494461
batch reward last col mean 8.437804899230628e-10 first col mean 0.0016557197086513042 all mean 8.668766531627625e-05
0.00020329018298070878 0.00020329016842879355
rl training, epoch1, iter0, batch841/1133, batch loss:0.00020329016842879355, Training time:38098.557911872864
batch reward last col mean 1.248464887027012e-09 first col mean 2.517786867883842e-09 all mean 4.2595544073265046e-05
2.4470375137752853e-05 2.447037331876345e-05
rl training, epoch1, iter0, batch842/1133, batch loss:2.447037331876345e-05, Training time:38126.53864860535
batch reward last col mean 3.5713596524544755e-09 first col mean 4.907327877390344e-09 all mean 2.2668817109661177e-05
4.767034624819644e-05 4.7670338972238824e-05
rl training, epoch1, iter0, batch843/1133, batch loss:4.7670338972238824e-05, Training time:38154.3847424984
batch reward last col mean 1.1401303234848115e-09 first col mean 1.0566061359185142e-09 all mean 4.047614856972359e-05
7.038338026177371e-06 7.0383439378929324e-06
rl training, epoch1, iter0, batch844/1133, batch loss:7.0383439378929324e-06, Training time:38181.96402716637
batch reward last col mean 0.00239585735835135 first col mean 9.994600702611933e-10 all mean 0.0023215808905661106
7.415896834572777e-05 7.4158982897643e-05
rl training, epoch1, iter0, batch845/1133, batch loss:7.4158982897643e-05, Training time:38209.52911949158
batch reward last col mean 1.2469796306646685e-09 first col mean 0.0016418539453297853 all mean 5.2187413530191407e-05
1.5111818356672302e-06 1.5111743323359406e-06
rl training, epoch1, iter0, batch846/1133, batch loss:1.5111743323359406e-06, Training time:38237.081711530685
batch reward last col mean 2.6924635854186363e-09 first col mean 0.004088672809302807 all mean 0.00014780170749872923
0.000147965649375692 0.00014796563482377678
rl training, epoch1, iter0, batch847/1133, batch loss:0.00014796563482377678, Training time:38264.60294175148
batch reward last col mean 7.84947395970903e-09 first col mean 0.0016340420115739107 all mean 2.993004454765469e-05
7.245890628837515e-06 7.245893812068971e-06
rl training, epoch1, iter0, batch848/1133, batch loss:7.245893812068971e-06, Training time:38292.21188235283
batch reward last col mean 2.09321537880669e-09 first col mean 2.7577145012003257e-09 all mean 8.842597162583843e-05
8.090841583907604e-05 8.090842311503366e-05
rl training, epoch1, iter0, batch849/1133, batch loss:8.090842311503366e-05, Training time:38320.042712926865
batch reward last col mean 0.005722967442125082 first col mean 0.0035288208164274693 all mean 0.005529525224119425
0.0001908020640257746 0.0001908020640257746
rl training, epoch1, iter0, batch850/1133, batch loss:0.0001908020640257746, Training time:38348.11866188049
batch reward last col mean 2.048710756596961e-09 first col mean 0.00046740908874198794 all mean 1.2870974387624301e-05
1.174064720999013e-07 1.1740576155716553e-07
rl training, epoch1, iter0, batch851/1133, batch loss:1.1740576155716553e-07, Training time:38376.246759176254
batch reward last col mean 3.724105912539244e-09 first col mean 0.0029401748906821012 all mean 0.0001990289456443861
3.6937872209819034e-05 3.693786493386142e-05
rl training, epoch1, iter0, batch852/1133, batch loss:3.693786493386142e-05, Training time:38404.67578935623
batch reward last col mean 3.80660392096388e-10 first col mean 2.7680515657380056e-09 all mean 5.4602831369265914e-05
9.647604747442529e-05 9.647604747442529e-05
rl training, epoch1, iter0, batch853/1133, batch loss:9.647604747442529e-05, Training time:38433.01601648331
batch reward last col mean 0.007753067649900913 first col mean 0.005284486338496208 all mean 0.007566483225673437
0.00034728588070720434 0.00034728582249954343
rl training, epoch1, iter0, batch854/1133, batch loss:0.00034728582249954343, Training time:38460.53689002991
batch reward last col mean 1.922131120934978e-09 first col mean 0.002240220084786415 all mean 9.999045869335532e-05
1.9923287254641764e-05 1.9923283616662957e-05
rl training, epoch1, iter0, batch855/1133, batch loss:1.9923283616662957e-05, Training time:38488.405672073364
batch reward last col mean 1.779788316724762e-09 first col mean 0.003995842766016722 all mean 4.7370347601827234e-05
2.107354339386802e-05 2.107355248881504e-05
rl training, epoch1, iter0, batch856/1133, batch loss:2.107355248881504e-05, Training time:38516.45712137222
batch reward last col mean 0.005546668078750372 first col mean 3.815656679506674e-09 all mean 0.005329855717718601
0.00010949502029689029 0.00010949504212476313
rl training, epoch1, iter0, batch857/1133, batch loss:0.00010949504212476313, Training time:38544.305852651596
batch reward last col mean 0.0005778363556601107 first col mean 0.0013430655235424638 all mean 0.0006388192414306104
4.916347097605467e-05 4.916345642413944e-05
rl training, epoch1, iter0, batch858/1133, batch loss:4.916345642413944e-05, Training time:38572.11570477486
batch reward last col mean 2.1498762770022495e-09 first col mean 0.0018478718120604753 all mean 7.673302752664313e-05
2.365688851568848e-05 2.365688851568848e-05
rl training, epoch1, iter0, batch859/1133, batch loss:2.365688851568848e-05, Training time:38599.849633693695
batch reward last col mean 3.470099096958279e-09 first col mean 0.0017034107586368918 all mean 0.00012422158033587039
0.00011688834638334811 0.00011688836821122095
rl training, epoch1, iter0, batch860/1133, batch loss:0.00011688836821122095, Training time:38627.41182136536
batch reward last col mean 0.0021711443550884724 first col mean 0.001946349861100316 all mean 0.0021997769363224506
6.065501656848937e-05 6.065500929253176e-05
rl training, epoch1, iter0, batch861/1133, batch loss:6.065500929253176e-05, Training time:38654.989737033844
batch reward last col mean 0.00877936091274023 first col mean 0.003845133585855365 all mean 0.00856788456439972
0.00026197105762548745 0.00026197105762548745
rl training, epoch1, iter0, batch862/1133, batch loss:0.00026197105762548745, Training time:38682.66228365898
batch reward last col mean 0.006379958242177963 first col mean 0.000573775905650109 all mean 0.006298558786511421
0.00022864050697535276 0.000228640521527268
rl training, epoch1, iter0, batch863/1133, batch loss:0.000228640521527268, Training time:38710.180520772934
batch reward last col mean 0.007535269483923912 first col mean 0.0019279139814898372 all mean 0.007245542481541634
0.0001621122646611184 0.00016211230831686407
rl training, epoch1, iter0, batch864/1133, batch loss:0.00016211230831686407, Training time:38738.16820549965
batch reward last col mean 0.013134542852640152 first col mean 0.00534221064299345 all mean 0.012718051671981812
0.0003225298714824021 0.00032252990058623254
rl training, epoch1, iter0, batch865/1133, batch loss:0.00032252990058623254, Training time:38765.75387620926
batch reward last col mean 2.310758695500681e-09 first col mean 0.005975035950541496 all mean 0.0003667886194307357
0.00015740249364171177 0.00015740252274554223
rl training, epoch1, iter0, batch866/1133, batch loss:0.00015740252274554223, Training time:38793.41827702522
batch reward last col mean 0.0023768129758536816 first col mean 0.0017335150623694062 all mean 0.002335761208087206
0.00017346655658911914 0.00017346655658911914
rl training, epoch1, iter0, batch867/1133, batch loss:0.00017346655658911914, Training time:38821.00859045982
batch reward last col mean 0.010896981693804264 first col mean 0.010840579867362976 all mean 0.010726483538746834
0.0002985215687658638 0.00029852151055820286
rl training, epoch1, iter0, batch868/1133, batch loss:0.00029852151055820286, Training time:38848.51565885544
batch reward last col mean 1.5476775416800592e-09 first col mean 0.0047415574081242085 all mean 0.00025381508748978376
0.0005644795601256192 0.0005644795601256192
rl training, epoch1, iter0, batch869/1133, batch loss:0.0005644795601256192, Training time:38875.955184459686
batch reward last col mean 0.027242060750722885 first col mean 0.005831445567309856 all mean 0.026523498818278313
0.000645389489363879 0.000645389489363879
rl training, epoch1, iter0, batch870/1133, batch loss:0.000645389489363879, Training time:38903.50734782219
batch reward last col mean 4.3806620553255016e-09 first col mean 0.0035588026512414217 all mean 0.00015401520067825913
0.00011658495350275189 0.00011658494622679427
rl training, epoch1, iter0, batch871/1133, batch loss:0.00011658494622679427, Training time:38931.32158827782
batch reward last col mean 0.007740441244095564 first col mean 0.007075930945575237 all mean 0.00767714437097311
0.00022053520660847425 0.00022053519205655903
rl training, epoch1, iter0, batch872/1133, batch loss:0.00022053519205655903, Training time:38958.866072654724
batch reward last col mean 0.010505526326596737 first col mean 0.01703304424881935 all mean 0.010913942940533161
0.0005226939101703465 0.0005226937937550247
rl training, epoch1, iter0, batch873/1133, batch loss:0.0005226937937550247, Training time:38986.64977145195
batch reward last col mean 0.013261748477816582 first col mean 0.009069891646504402 all mean 0.012974631041288376
0.0005206679925322533 0.0005206681089475751
rl training, epoch1, iter0, batch874/1133, batch loss:0.0005206681089475751, Training time:39014.24707651138
batch reward last col mean 0.011084800586104393 first col mean 0.009567690081894398 all mean 0.011156275868415833
0.00027027694159187376 0.0002702769706957042
rl training, epoch1, iter0, batch875/1133, batch loss:0.0002702769706957042, Training time:39041.55110621452
batch reward last col mean 0.025824198499321938 first col mean 0.015093686990439892 all mean 0.02524498663842678
0.0006007968331687152 0.0006007967749610543
rl training, epoch1, iter0, batch876/1133, batch loss:0.0006007967749610543, Training time:39069.16674780846
batch reward last col mean 0.006676282733678818 first col mean 0.005210729781538248 all mean 0.006692580413073301
9.189934644382447e-05 9.189932461595163e-05
rl training, epoch1, iter0, batch877/1133, batch loss:9.189932461595163e-05, Training time:39096.696417331696
batch reward last col mean 0.0020516919903457165 first col mean 0.0033696035388857126 all mean 0.0020767005626112223
4.220563641865738e-05 4.2205625504720956e-05
rl training, epoch1, iter0, batch878/1133, batch loss:4.2205625504720956e-05, Training time:39124.25758814812
batch reward last col mean 0.02102218195796013 first col mean 0.014259574934840202 all mean 0.021235624328255653
0.0007919673807919025 0.0007919671479612589
rl training, epoch1, iter0, batch879/1133, batch loss:0.0007919671479612589, Training time:39151.9043006897
batch reward last col mean 0.02152392268180847 first col mean 0.0344056636095047 all mean 0.021797440946102142
0.0005204726476222277 0.0005204725894145668
rl training, epoch1, iter0, batch880/1133, batch loss:0.0005204725894145668, Training time:39179.56209754944
batch reward last col mean 0.013045680709183216 first col mean 0.008347682654857635 all mean 0.013041626662015915
0.00033968218485824764 0.00033968209754675627
rl training, epoch1, iter0, batch881/1133, batch loss:0.00033968209754675627, Training time:39207.50178360939
batch reward last col mean 0.010192410089075565 first col mean 0.017502600327134132 all mean 0.010477527976036072
0.0003479784063529223 0.0003479784936644137
rl training, epoch1, iter0, batch882/1133, batch loss:0.0003479784936644137, Training time:39235.02096128464
batch reward last col mean 0.00319104827940464 first col mean 0.006637669168412685 all mean 0.0032999117393046618
0.0001426699891453609 0.0001426699891453609
rl training, epoch1, iter0, batch883/1133, batch loss:0.0001426699891453609, Training time:39262.50526094437
batch reward last col mean 0.018207423388957977 first col mean 0.01533074676990509 all mean 0.01817552000284195
0.000615434255450964 0.0006154343718662858
rl training, epoch1, iter0, batch884/1133, batch loss:0.0006154343718662858, Training time:39290.15006709099
batch reward last col mean 0.04578639566898346 first col mean 0.03361428901553154 all mean 0.045134443789720535
0.00108725402969867 0.00108725402969867
rl training, epoch1, iter0, batch885/1133, batch loss:0.00108725402969867, Training time:39317.61124062538
batch reward last col mean 0.022124886512756348 first col mean 0.01715175434947014 all mean 0.021913278847932816
0.0008783818338997662 0.0008783818338997662
rl training, epoch1, iter0, batch886/1133, batch loss:0.0008783818338997662, Training time:39345.13537144661
batch reward last col mean 0.022127842530608177 first col mean 0.02783934585750103 all mean 0.0228569395840168
0.0007594017661176622 0.000759401882532984
rl training, epoch1, iter0, batch887/1133, batch loss:0.000759401882532984, Training time:39372.82396578789
batch reward last col mean 0.03406636416912079 first col mean 0.03102896921336651 all mean 0.03399688005447388
0.0005658689769916236 0.0005658688605763018
rl training, epoch1, iter0, batch888/1133, batch loss:0.0005658688605763018, Training time:39400.53258180618
batch reward last col mean 0.0298940297216177 first col mean 0.014828138053417206 all mean 0.029498567804694176
0.0007665756857022643 0.0007665757439099252
rl training, epoch1, iter0, batch889/1133, batch loss:0.0007665757439099252, Training time:39428.3641064167
batch reward last col mean 0.024213353171944618 first col mean 0.020416688174009323 all mean 0.024125799536705017
0.000381927820853889 0.000381927820853889
rl training, epoch1, iter0, batch890/1133, batch loss:0.000381927820853889, Training time:39455.83018565178
batch reward last col mean 0.059633590281009674 first col mean 0.06378685683012009 all mean 0.05988941714167595
0.0007832725532352924 0.0007832727278582752
rl training, epoch1, iter0, batch891/1133, batch loss:0.0007832727278582752, Training time:39483.663286447525
batch reward last col mean 0.01717504672706127 first col mean 0.01905060186982155 all mean 0.017294976860284805
0.0007078993949107826 0.0007078993949107826
rl training, epoch1, iter0, batch892/1133, batch loss:0.0007078993949107826, Training time:39511.0622048378
batch reward last col mean 0.019159473478794098 first col mean 0.022934794425964355 all mean 0.01919046975672245
0.0012151252012699842 0.0012151252012699842
rl training, epoch1, iter0, batch893/1133, batch loss:0.0012151252012699842, Training time:39538.65155673027
batch reward last col mean 0.023879429325461388 first col mean 0.021158454939723015 all mean 0.023711400106549263
0.0008556016837246716 0.0008556016837246716
rl training, epoch1, iter0, batch894/1133, batch loss:0.0008556016837246716, Training time:39566.23441386223
batch reward last col mean 0.01855779066681862 first col mean 0.011585990898311138 all mean 0.01821122318506241
0.00038521832902915776 0.00038521832902915776
rl training, epoch1, iter0, batch895/1133, batch loss:0.00038521832902915776, Training time:39593.89229130745
batch reward last col mean 0.027235958725214005 first col mean 0.02545921318233013 all mean 0.02707335166633129
0.0009609180851839483 0.0009609180851839483
rl training, epoch1, iter0, batch896/1133, batch loss:0.0009609180851839483, Training time:39621.380610466
batch reward last col mean 0.03804894909262657 first col mean 0.03213569521903992 all mean 0.038040824234485626
0.0004237691464368254 0.00042376923374831676
rl training, epoch1, iter0, batch897/1133, batch loss:0.00042376923374831676, Training time:39648.89153671265
batch reward last col mean 0.03791765868663788 first col mean 0.04944194108247757 all mean 0.03837161883711815
0.0008571372600272298 0.000857137085404247
rl training, epoch1, iter0, batch898/1133, batch loss:0.000857137085404247, Training time:39676.41826748848
batch reward last col mean 0.012354414910078049 first col mean 0.012813755311071873 all mean 0.012452363967895508
0.0003462396271061152 0.0003462396562099457
rl training, epoch1, iter0, batch899/1133, batch loss:0.0003462396562099457, Training time:39704.05790376663
batch reward last col mean 0.031494200229644775 first col mean 0.0341835655272007 all mean 0.031562477350234985
0.0016165297711268067 0.0016165297711268067
rl training, epoch1, iter0, batch900/1133, batch loss:0.0016165297711268067, Training time:39731.62467074394
batch reward last col mean 0.02748032659292221 first col mean 0.028711074963212013 all mean 0.027721896767616272
0.0008187650237232447 0.0008187650237232447
rl training, epoch1, iter0, batch901/1133, batch loss:0.0008187650237232447, Training time:39759.23269057274
batch reward last col mean 0.027840472757816315 first col mean 0.027950193732976913 all mean 0.02792709320783615
0.00041482169763185084 0.00041482175583951175
rl training, epoch1, iter0, batch902/1133, batch loss:0.00041482175583951175, Training time:39786.681116342545
batch reward last col mean 0.042395949363708496 first col mean 0.03779929131269455 all mean 0.041998255997896194
0.0011982908472418785 0.0011982907308265567
rl training, epoch1, iter0, batch903/1133, batch loss:0.0011982907308265567, Training time:39814.259061574936
batch reward last col mean 0.03355550765991211 first col mean 0.038756757974624634 all mean 0.03377719968557358
0.0008934600627981126 0.0008934600627981126
rl training, epoch1, iter0, batch904/1133, batch loss:0.0008934600627981126, Training time:39841.75745868683
batch reward last col mean 0.04895017296075821 first col mean 0.0554671585559845 all mean 0.04925570264458656
0.0012681359658017755 0.0012681360822170973
rl training, epoch1, iter0, batch905/1133, batch loss:0.0012681360822170973, Training time:39869.25766539574
batch reward last col mean 0.009426864795386791 first col mean 0.01878020539879799 all mean 0.009692438878118992
0.00011472500045783818 0.00011472494225017726
rl training, epoch1, iter0, batch906/1133, batch loss:0.00011472494225017726, Training time:39896.92605161667
batch reward last col mean 0.03740062564611435 first col mean 0.028766151517629623 all mean 0.036927368491888046
0.0005860124947503209 0.0005860124947503209
rl training, epoch1, iter0, batch907/1133, batch loss:0.0005860124947503209, Training time:39924.450786828995
batch reward last col mean 0.03462910279631615 first col mean 0.024679571390151978 all mean 0.03436024487018585
0.0007685446180403233 0.0007685447344556451
rl training, epoch1, iter0, batch908/1133, batch loss:0.0007685447344556451, Training time:39951.990731716156
batch reward last col mean 0.009332899004220963 first col mean 0.013982119038701057 all mean 0.009369716048240662
0.00030486559262499213 0.00030486559262499213
rl training, epoch1, iter0, batch909/1133, batch loss:0.00030486559262499213, Training time:39979.75839161873
batch reward last col mean 0.026485329493880272 first col mean 0.0347759909927845 all mean 0.026642370969057083
0.000647441775072366 0.0006474417168647051
rl training, epoch1, iter0, batch910/1133, batch loss:0.0006474417168647051, Training time:40007.52209210396
batch reward last col mean 0.021880686283111572 first col mean 0.015737470239400864 all mean 0.021783502772450447
9.920123557094485e-05 9.920109005179256e-05
rl training, epoch1, iter0, batch911/1133, batch loss:9.920109005179256e-05, Training time:40034.94264936447
batch reward last col mean 0.03954022377729416 first col mean 0.045802127569913864 all mean 0.03976050391793251
0.00038575674989260733 0.00038575695361942053
rl training, epoch1, iter0, batch912/1133, batch loss:0.00038575695361942053, Training time:40062.772317647934
batch reward last col mean 0.06737173348665237 first col mean 0.060079511255025864 all mean 0.06725134700536728
0.0010042006615549326 0.0010042005451396108
rl training, epoch1, iter0, batch913/1133, batch loss:0.0010042005451396108, Training time:40090.17766213417
batch reward last col mean 0.024659764021635056 first col mean 0.03951128199696541 all mean 0.025240955874323845
0.0005649865488521755 0.0005649865488521755
rl training, epoch1, iter0, batch914/1133, batch loss:0.0005649865488521755, Training time:40117.736533641815
batch reward last col mean 0.03898393362760544 first col mean 0.03643627464771271 all mean 0.03902554139494896
0.00035804026992991567 0.0003580400953069329
rl training, epoch1, iter0, batch915/1133, batch loss:0.0003580400953069329, Training time:40145.36143660545
batch reward last col mean 0.030835816636681557 first col mean 0.031212380155920982 all mean 0.030790438875555992
0.0004225254524499178 0.0004225254524499178
rl training, epoch1, iter0, batch916/1133, batch loss:0.0004225254524499178, Training time:40172.83723735809
batch reward last col mean 0.030700113624334335 first col mean 0.028378978371620178 all mean 0.030690347775816917
0.0005224853521212935 0.0005224855267442763
rl training, epoch1, iter0, batch917/1133, batch loss:0.0005224855267442763, Training time:40200.41998052597
batch reward last col mean 0.03061184287071228 first col mean 0.021686898544430733 all mean 0.030229652300477028
0.0006361693376675248 0.0006361694540828466
rl training, epoch1, iter0, batch918/1133, batch loss:0.0006361694540828466, Training time:40227.89398956299
batch reward last col mean 0.021745147183537483 first col mean 0.017747867852449417 all mean 0.021619021892547607
0.00018328662554267794 0.00018328662554267794
rl training, epoch1, iter0, batch919/1133, batch loss:0.00018328662554267794, Training time:40255.6251373291
batch reward last col mean 0.029948171228170395 first col mean 0.04054541140794754 all mean 0.030459823086857796
0.0004295629623811692 0.0004295630205888301
rl training, epoch1, iter0, batch920/1133, batch loss:0.0004295630205888301, Training time:40283.22506761551
batch reward last col mean 0.06148042902350426 first col mean 0.05527505278587341 all mean 0.06116439774632454
0.0012444445164874196 0.0012444445164874196
rl training, epoch1, iter0, batch921/1133, batch loss:0.0012444445164874196, Training time:40310.63952231407
batch reward last col mean 0.04538877308368683 first col mean 0.03977496922016144 all mean 0.04530148580670357
0.0010939002968370914 0.0010939002968370914
rl training, epoch1, iter0, batch922/1133, batch loss:0.0010939002968370914, Training time:40338.394595623016
batch reward last col mean 0.017384592443704605 first col mean 0.012737846001982689 all mean 0.017397016286849976
0.0005639512091875076 0.0005639510927721858
rl training, epoch1, iter0, batch923/1133, batch loss:0.0005639510927721858, Training time:40365.75449824333
batch reward last col mean 0.02947128936648369 first col mean 0.03730190172791481 all mean 0.029626278206706047
0.0004438428150024265 0.0004438426694832742
rl training, epoch1, iter0, batch924/1133, batch loss:0.0004438426694832742, Training time:40393.308520793915
batch reward last col mean 0.05363738536834717 first col mean 0.056076183915138245 all mean 0.0537199042737484
0.0017401236109435558 0.0017401236109435558
rl training, epoch1, iter0, batch925/1133, batch loss:0.0017401236109435558, Training time:40420.73404479027
batch reward last col mean 0.044621311128139496 first col mean 0.05580325424671173 all mean 0.044914331287145615
0.0014650046359747648 0.0014650044031441212
rl training, epoch1, iter0, batch926/1133, batch loss:0.0014650044031441212, Training time:40448.21876215935
batch reward last col mean 0.026891952380537987 first col mean 0.032636720687150955 all mean 0.02706475742161274
0.00033631219412200153 0.00033631219412200153
rl training, epoch1, iter0, batch927/1133, batch loss:0.00033631219412200153, Training time:40475.821123600006
batch reward last col mean 0.05898786708712578 first col mean 0.0692310631275177 all mean 0.05937756597995758
0.0015276361955329776 0.0015276361955329776
rl training, epoch1, iter0, batch928/1133, batch loss:0.0015276361955329776, Training time:40503.403158426285
batch reward last col mean 0.02259291149675846 first col mean 0.03550143539905548 all mean 0.02311057038605213
0.0004874098231084645 0.00048740991041995585
rl training, epoch1, iter0, batch929/1133, batch loss:0.00048740991041995585, Training time:40530.87981629372
batch reward last col mean 0.030796244740486145 first col mean 0.040387749671936035 all mean 0.031178977340459824
0.000392884569009766 0.000392884569009766
rl training, epoch1, iter0, batch930/1133, batch loss:0.000392884569009766, Training time:40558.62932896614
batch reward last col mean 0.019473008811473846 first col mean 0.033733297139406204 all mean 0.02012592926621437
0.000814977684058249 0.0008149777422659099
rl training, epoch1, iter0, batch931/1133, batch loss:0.0008149777422659099, Training time:40586.14274430275
batch reward last col mean 0.07877996563911438 first col mean 0.07222159951925278 all mean 0.07834137231111526
0.0013518803752958775 0.0013518804917111993
rl training, epoch1, iter0, batch932/1133, batch loss:0.0013518804917111993, Training time:40613.57957339287
batch reward last col mean 0.05758414417505264 first col mean 0.049899354577064514 all mean 0.057381730526685715
0.0010602409020066261 0.0010602405527606606
rl training, epoch1, iter0, batch933/1133, batch loss:0.0010602405527606606, Training time:40641.00800156593
batch reward last col mean 0.07137633860111237 first col mean 0.06863921880722046 all mean 0.07132938504219055
0.0018282552482560277 0.0018282554810866714
rl training, epoch1, iter0, batch934/1133, batch loss:0.0018282554810866714, Training time:40668.52131295204
batch reward last col mean 0.07231523841619492 first col mean 0.05841220170259476 all mean 0.07167835533618927
0.0028223313856869936 0.0028223313856869936
rl training, epoch1, iter0, batch935/1133, batch loss:0.0028223313856869936, Training time:40695.9882106781
batch reward last col mean 0.023194726556539536 first col mean 0.028827093541622162 all mean 0.023388369008898735
0.0009946847567334771 0.0009946847567334771
rl training, epoch1, iter0, batch936/1133, batch loss:0.0009946847567334771, Training time:40723.744213581085
batch reward last col mean 0.03694997355341911 first col mean 0.04272744804620743 all mean 0.0371762253344059
0.0007381599280051887 0.0007381599280051887
rl training, epoch1, iter0, batch937/1133, batch loss:0.0007381599280051887, Training time:40751.23386669159
batch reward last col mean 0.020741838961839676 first col mean 0.02694644033908844 all mean 0.020976722240447998
0.001298721181228757 0.001298721064813435
rl training, epoch1, iter0, batch938/1133, batch loss:0.001298721064813435, Training time:40778.629697322845
batch reward last col mean 0.0939801037311554 first col mean 0.09208168089389801 all mean 0.0937548577785492
0.002119210548698902 0.002119210548698902
rl training, epoch1, iter0, batch939/1133, batch loss:0.002119210548698902, Training time:40806.125992298126
batch reward last col mean 0.06369122862815857 first col mean 0.06260485202074051 all mean 0.06390074640512466
0.001809211797080934 0.001809211797080934
rl training, epoch1, iter0, batch940/1133, batch loss:0.001809211797080934, Training time:40833.59771847725
batch reward last col mean 0.05585424229502678 first col mean 0.055619142949581146 all mean 0.05572935566306114
0.0016584147233515978 0.001658415189012885
rl training, epoch1, iter0, batch941/1133, batch loss:0.001658415189012885, Training time:40860.882459402084
batch reward last col mean 0.04315996170043945 first col mean 0.04471667483448982 all mean 0.043177731335163116
0.00041539681842550635 0.00041539681842550635
rl training, epoch1, iter0, batch942/1133, batch loss:0.00041539681842550635, Training time:40888.43615746498
batch reward last col mean 0.030582750216126442 first col mean 0.03081148862838745 all mean 0.03059229999780655
0.0004055544559378177 0.0004055543686263263
rl training, epoch1, iter0, batch943/1133, batch loss:0.0004055543686263263, Training time:40915.99462509155
batch reward last col mean 0.029293015599250793 first col mean 0.037371568381786346 all mean 0.029475318267941475
0.00043946405639871955 0.0004394641437102109
rl training, epoch1, iter0, batch944/1133, batch loss:0.0004394641437102109, Training time:40943.40303993225
batch reward last col mean 0.05654751509428024 first col mean 0.06160556897521019 all mean 0.056942179799079895
0.001115590101107955 0.0011155899846926332
rl training, epoch1, iter0, batch945/1133, batch loss:0.0011155899846926332, Training time:40970.86642193794
batch reward last col mean 0.05751825496554375 first col mean 0.07833082973957062 all mean 0.058369532227516174
0.00132159108761698 0.0013215908547863364
rl training, epoch1, iter0, batch946/1133, batch loss:0.0013215908547863364, Training time:40998.30853700638
batch reward last col mean 0.060167327523231506 first col mean 0.06839291751384735 all mean 0.06031199172139168
0.0013731938088312745 0.0013731938088312745
rl training, epoch1, iter0, batch947/1133, batch loss:0.0013731938088312745, Training time:41025.62375473976
batch reward last col mean 0.0582544207572937 first col mean 0.057252950966358185 all mean 0.05825062096118927
0.0010151335736736655 0.0010151336900889874
rl training, epoch1, iter0, batch948/1133, batch loss:0.0010151336900889874, Training time:41053.03268456459
batch reward last col mean 0.057062990963459015 first col mean 0.07580649852752686 all mean 0.057562924921512604
0.0016119213541969657 0.0016119215870276093
rl training, epoch1, iter0, batch949/1133, batch loss:0.0016119215870276093, Training time:41080.59956359863
batch reward last col mean 0.03992817923426628 first col mean 0.046417899429798126 all mean 0.04027217626571655
0.000985625316388905 0.0009856250835582614
rl training, epoch1, iter0, batch950/1133, batch loss:0.0009856250835582614, Training time:41108.01844930649
batch reward last col mean 0.06713902950286865 first col mean 0.06779292225837708 all mean 0.06696078926324844
0.0015541049651801586 0.0015541049651801586
rl training, epoch1, iter0, batch951/1133, batch loss:0.0015541049651801586, Training time:41135.54001545906
batch reward last col mean 0.06345954537391663 first col mean 0.0733974352478981 all mean 0.06387374550104141
0.0010011824779212475 0.0010011820122599602
rl training, epoch1, iter0, batch952/1133, batch loss:0.0010011820122599602, Training time:41163.060396909714
batch reward last col mean 0.06959158927202225 first col mean 0.06370051205158234 all mean 0.06936284899711609
0.0016416340367868543 0.0016416340367868543
rl training, epoch1, iter0, batch953/1133, batch loss:0.0016416340367868543, Training time:41190.311561346054
batch reward last col mean 0.08085568994283676 first col mean 0.091334268450737 all mean 0.08131682127714157
0.0013060272904112935 0.0013060277560725808
rl training, epoch1, iter0, batch954/1133, batch loss:0.0013060277560725808, Training time:41217.616596221924
batch reward last col mean 0.08265572786331177 first col mean 0.09438685327768326 all mean 0.08324683457612991
0.001656991196796298 0.001656991196796298
rl training, epoch1, iter0, batch955/1133, batch loss:0.001656991196796298, Training time:41244.93080210686
batch reward last col mean 0.05167081952095032 first col mean 0.054481156170368195 all mean 0.05150908604264259
0.0004882864304818213 0.0004882864304818213
rl training, epoch1, iter0, batch956/1133, batch loss:0.0004882864304818213, Training time:41272.269832372665
batch reward last col mean 0.04192347824573517 first col mean 0.03948058933019638 all mean 0.0417197048664093
0.0009734618943184614 0.000973461486864835
rl training, epoch1, iter0, batch957/1133, batch loss:0.000973461486864835, Training time:41299.67334485054
batch reward last col mean 0.09283506870269775 first col mean 0.10148002952337265 all mean 0.09316644817590714
0.0011449813609942794 0.0011449814774096012
rl training, epoch1, iter0, batch958/1133, batch loss:0.0011449814774096012, Training time:41327.2132935524
batch reward last col mean 0.1043868139386177 first col mean 0.09360846877098083 all mean 0.10385342687368393
0.002148064784705639 0.0021480650175362825
rl training, epoch1, iter0, batch959/1133, batch loss:0.0021480650175362825, Training time:41354.436549425125
batch reward last col mean 0.06175029277801514 first col mean 0.06292253732681274 all mean 0.061983272433280945
0.0020073638297617435 0.0020073638297617435
rl training, epoch1, iter0, batch960/1133, batch loss:0.0020073638297617435, Training time:41382.014045238495
batch reward last col mean 0.050108276307582855 first col mean 0.05716048926115036 all mean 0.05038706585764885
0.0004188913444522768 0.0004188913444522768
rl training, epoch1, iter0, batch961/1133, batch loss:0.0004188913444522768, Training time:41409.34108710289
batch reward last col mean 0.05821199715137482 first col mean 0.06755471229553223 all mean 0.05852755159139633
0.0013289849739521742 0.001328985090367496
rl training, epoch1, iter0, batch962/1133, batch loss:0.001328985090367496, Training time:41436.70743250847
batch reward last col mean 0.09648269414901733 first col mean 0.09277011454105377 all mean 0.0964028611779213
0.003472462296485901 0.003472462296485901
rl training, epoch1, iter0, batch963/1133, batch loss:0.003472462296485901, Training time:41464.08243846893
batch reward last col mean 0.04720204696059227 first col mean 0.055795490741729736 all mean 0.047443099319934845
0.0007900515338405967 0.0007900516502559185
rl training, epoch1, iter0, batch964/1133, batch loss:0.0007900516502559185, Training time:41491.45253062248
batch reward last col mean 0.055162932723760605 first col mean 0.051224544644355774 all mean 0.05496581271290779
0.0005121968570165336 0.0005121967988088727
rl training, epoch1, iter0, batch965/1133, batch loss:0.0005121967988088727, Training time:41518.92073440552
batch reward last col mean 0.09916621446609497 first col mean 0.10003302991390228 all mean 0.0992811769247055
0.0010920780478045344 0.001092077698558569
rl training, epoch1, iter0, batch966/1133, batch loss:0.001092077698558569, Training time:41546.25165319443
batch reward last col mean 0.09809093922376633 first col mean 0.10222825407981873 all mean 0.09823061525821686
0.0015561198815703392 0.0015561201144009829
rl training, epoch1, iter0, batch967/1133, batch loss:0.0015561201144009829, Training time:41573.6612944603
batch reward last col mean 0.07222365587949753 first col mean 0.07474236935377121 all mean 0.07232702523469925
0.0007377926958724856 0.0007377927540801466
rl training, epoch1, iter0, batch968/1133, batch loss:0.0007377927540801466, Training time:41600.97528004646
batch reward last col mean 0.07465211302042007 first col mean 0.07058195024728775 all mean 0.07435976713895798
0.0016894410364329815 0.0016894409200176597
rl training, epoch1, iter0, batch969/1133, batch loss:0.0016894409200176597, Training time:41628.306540727615
batch reward last col mean 0.0680769756436348 first col mean 0.07841797173023224 all mean 0.06841668486595154
0.0007632753113284707 0.0007632755441591144
rl training, epoch1, iter0, batch970/1133, batch loss:0.0007632755441591144, Training time:41655.758066892624
batch reward last col mean 0.07410143315792084 first col mean 0.07881668955087662 all mean 0.07422199845314026
0.0011043509002774954 0.001104351133108139
rl training, epoch1, iter0, batch971/1133, batch loss:0.001104351133108139, Training time:41683.179693222046
batch reward last col mean 0.05548890307545662 first col mean 0.06220441311597824 all mean 0.055793747305870056
0.0011835386976599693 0.0011835388140752912
rl training, epoch1, iter0, batch972/1133, batch loss:0.0011835388140752912, Training time:41710.53541111946
batch reward last col mean 0.08685490489006042 first col mean 0.0946756899356842 all mean 0.08716760575771332
0.0029863850213587284 0.002986384555697441
rl training, epoch1, iter0, batch973/1133, batch loss:0.002986384555697441, Training time:41738.0998647213
batch reward last col mean 0.021578408777713776 first col mean 0.024892661720514297 all mean 0.0217051412910223
0.00023839710047468543 0.00023839710047468543
rl training, epoch1, iter0, batch974/1133, batch loss:0.00023839710047468543, Training time:41765.67870569229
batch reward last col mean 0.07580854743719101 first col mean 0.06981589645147324 all mean 0.07535748183727264
0.001260527758859098 0.0012605275260284543
rl training, epoch1, iter0, batch975/1133, batch loss:0.0012605275260284543, Training time:41793.138644218445
batch reward last col mean 0.07797344774007797 first col mean 0.058673251420259476 all mean 0.07712090015411377
0.002114230301231146 0.0021142305340617895
rl training, epoch1, iter0, batch976/1133, batch loss:0.0021142305340617895, Training time:41820.44863963127
batch reward last col mean 0.03389792889356613 first col mean 0.0428253635764122 all mean 0.03396683931350708
0.00027933818637393415 0.00027933833189308643
rl training, epoch1, iter0, batch977/1133, batch loss:0.00027933833189308643, Training time:41847.901829242706
batch reward last col mean 0.04289736598730087 first col mean 0.04240946099162102 all mean 0.042810603976249695
0.0005044222925789654 0.0005044221179559827
rl training, epoch1, iter0, batch978/1133, batch loss:0.0005044221179559827, Training time:41875.28011107445
batch reward last col mean 0.0966554507613182 first col mean 0.08874037116765976 all mean 0.09639260172843933
0.0016761842416599393 0.0016761838924139738
rl training, epoch1, iter0, batch979/1133, batch loss:0.0016761838924139738, Training time:41902.66920757294
batch reward last col mean 0.061930932104587555 first col mean 0.06334314495325089 all mean 0.061839401721954346
0.0010464739752933383 0.0010464740917086601
rl training, epoch1, iter0, batch980/1133, batch loss:0.0010464740917086601, Training time:41929.84557771683
batch reward last col mean 0.07341662049293518 first col mean 0.07690291106700897 all mean 0.07344682514667511
0.0007449842523783445 0.0007449840777553618
rl training, epoch1, iter0, batch981/1133, batch loss:0.0007449840777553618, Training time:41957.32880806923
batch reward last col mean 0.12037880718708038 first col mean 0.11700162291526794 all mean 0.12034185230731964
0.0034473652485758066 0.0034473645500838757
rl training, epoch1, iter0, batch982/1133, batch loss:0.0034473645500838757, Training time:41984.87363266945
batch reward last col mean 0.05709843337535858 first col mean 0.06138797104358673 all mean 0.0572957880795002
0.0029078254010528326 0.002907825168222189
rl training, epoch1, iter0, batch983/1133, batch loss:0.002907825168222189, Training time:42010.992585897446
batch reward last col mean 0.10408342629671097 first col mean 0.09949100017547607 all mean 0.10394474864006042
0.0023179526906460524 0.0023179526906460524
rl training, epoch1, iter0, batch984/1133, batch loss:0.0023179526906460524, Training time:42038.306492328644
batch reward last col mean 0.07888683676719666 first col mean 0.0903216153383255 all mean 0.07920091599225998
0.0036936078686267138 0.0036936078686267138
rl training, epoch1, iter0, batch985/1133, batch loss:0.0036936078686267138, Training time:42064.61827278137
batch reward last col mean 0.09430365264415741 first col mean 0.07597361505031586 all mean 0.09353826195001602
0.001969666685909033 0.0019696669187396765
rl training, epoch1, iter0, batch986/1133, batch loss:0.0019696669187396765, Training time:42091.83588171005
batch reward last col mean 0.08510083705186844 first col mean 0.09079159796237946 all mean 0.08513562381267548
0.001939018489792943 0.0019390182569622993
rl training, epoch1, iter0, batch987/1133, batch loss:0.0019390182569622993, Training time:42119.13020634651
batch reward last col mean 0.10228122770786285 first col mean 0.090043805539608 all mean 0.10199344158172607
0.0030268323607742786 0.0030268325936049223
rl training, epoch1, iter0, batch988/1133, batch loss:0.0030268325936049223, Training time:42146.38100743294
batch reward last col mean 0.06871005892753601 first col mean 0.05873484909534454 all mean 0.06841148436069489
0.0023242917377501726 0.002324291504919529
rl training, epoch1, iter0, batch989/1133, batch loss:0.002324291504919529, Training time:42173.68228316307
batch reward last col mean 0.09770899266004562 first col mean 0.10101018846035004 all mean 0.09790486097335815
0.0014545146841555834 0.001454514334909618
rl training, epoch1, iter0, batch990/1133, batch loss:0.001454514334909618, Training time:42200.69431376457
batch reward last col mean 0.08160147070884705 first col mean 0.09479646384716034 all mean 0.08222272992134094
0.003836404299363494 0.003836404299363494
rl training, epoch1, iter0, batch991/1133, batch loss:0.003836404299363494, Training time:42227.82254242897
batch reward last col mean 0.08773887902498245 first col mean 0.07940733432769775 all mean 0.08766604214906693
0.003429170697927475 0.003429170697927475
rl training, epoch1, iter0, batch992/1133, batch loss:0.003429170697927475, Training time:42254.18828725815
batch reward last col mean 0.0923774465918541 first col mean 0.08212269842624664 all mean 0.09208285808563232
0.0021836559753865004 0.002183656208217144
rl training, epoch1, iter0, batch993/1133, batch loss:0.002183656208217144, Training time:42281.88722872734
batch reward last col mean 0.06836443394422531 first col mean 0.07410173118114471 all mean 0.06878221780061722
0.001136757549829781 0.0011367570841684937
rl training, epoch1, iter0, batch994/1133, batch loss:0.0011367570841684937, Training time:42309.17442154884
batch reward last col mean 0.06517694890499115 first col mean 0.06143874675035477 all mean 0.06478369981050491
0.0033628707751631737 0.0033628714736551046
rl training, epoch1, iter0, batch995/1133, batch loss:0.0033628714736551046, Training time:42336.40511274338
batch reward last col mean 0.10480088740587234 first col mean 0.09512244164943695 all mean 0.10444647073745728
0.003245390485972166 0.003245390485972166
rl training, epoch1, iter0, batch996/1133, batch loss:0.003245390485972166, Training time:42362.54903841019
batch reward last col mean 0.06737419217824936 first col mean 0.07276946306228638 all mean 0.06721305102109909
0.002774324733763933 0.0027743240352720022
rl training, epoch1, iter0, batch997/1133, batch loss:0.0027743240352720022, Training time:42389.99262881279
batch reward last col mean 0.08632960915565491 first col mean 0.06897176802158356 all mean 0.08585935831069946
0.0028079068288207054 0.0028079061303287745
rl training, epoch1, iter0, batch998/1133, batch loss:0.0028079061303287745, Training time:42416.045746803284
batch reward last col mean 0.061146073043346405 first col mean 0.06373385339975357 all mean 0.06105128675699234
0.0016864999197423458 0.0016864999197423458
rl training, epoch1, iter0, batch999/1133, batch loss:0.0016864999197423458, Training time:42443.30391788483
batch reward last col mean 0.06469208747148514 first col mean 0.06766792386770248 all mean 0.06468227505683899
0.0026942314580082893 0.0026942314580082893
rl training, epoch1, iter0, batch1000/1133, batch loss:0.0026942314580082893, Training time:42470.50169610977
batch reward last col mean 0.09046566486358643 first col mean 0.07915448397397995 all mean 0.09019582718610764
0.004246607422828674 0.004246607422828674
rl training, epoch1, iter0, batch1001/1133, batch loss:0.004246607422828674, Training time:42496.65363717079
batch reward last col mean 0.13350564241409302 first col mean 0.11489822715520859 all mean 0.1327841877937317
0.004067046567797661 0.004067046567797661
rl training, epoch1, iter0, batch1002/1133, batch loss:0.004067046567797661, Training time:42522.8328461647
batch reward last col mean 0.09998995065689087 first col mean 0.0870656669139862 all mean 0.09967011958360672
0.005010558292269707 0.005010558292269707
rl training, epoch1, iter0, batch1003/1133, batch loss:0.005010558292269707, Training time:42550.662388563156
batch reward last col mean 0.07492130994796753 first col mean 0.09233991801738739 all mean 0.07560620456933975
0.0034816719125956297 0.0034816714469343424
rl training, epoch1, iter0, batch1004/1133, batch loss:0.0034816714469343424, Training time:42577.74477934837
batch reward last col mean 0.06866709142923355 first col mean 0.0708354040980339 all mean 0.06881130486726761
0.0011219426523894072 0.0011219432344660163
rl training, epoch1, iter0, batch1005/1133, batch loss:0.0011219432344660163, Training time:42605.08249425888
batch reward last col mean 0.052375905215740204 first col mean 0.05376145616173744 all mean 0.05254398658871651
0.002048053778707981 0.002048053313046694
rl training, epoch1, iter0, batch1006/1133, batch loss:0.002048053313046694, Training time:42632.27339100838
batch reward last col mean 0.07130595296621323 first col mean 0.06716887652873993 all mean 0.07130523025989532
0.0026510984171181917 0.002651098184287548
rl training, epoch1, iter0, batch1007/1133, batch loss:0.002651098184287548, Training time:42659.5459048748
batch reward last col mean 0.0755021870136261 first col mean 0.0891554057598114 all mean 0.07587023079395294
0.003570451634004712 0.0035704514011740685
rl training, epoch1, iter0, batch1008/1133, batch loss:0.0035704514011740685, Training time:42685.84094238281
batch reward last col mean 0.07860203087329865 first col mean 0.0719783753156662 all mean 0.07859564572572708
0.001927201054058969 0.0019272011704742908
rl training, epoch1, iter0, batch1009/1133, batch loss:0.0019272011704742908, Training time:42713.01380801201
batch reward last col mean 0.08783087879419327 first col mean 0.08742187917232513 all mean 0.08782949298620224
0.0034242526162415743 0.003424252849072218
rl training, epoch1, iter0, batch1010/1133, batch loss:0.003424252849072218, Training time:42738.9231004715
batch reward last col mean 0.11394962668418884 first col mean 0.11805853247642517 all mean 0.11395263671875
0.004950501024723053 0.004950500559061766
rl training, epoch1, iter0, batch1011/1133, batch loss:0.004950500559061766, Training time:42765.067170381546
batch reward last col mean 0.11263412237167358 first col mean 0.08942341059446335 all mean 0.11178619414567947
0.0060490453615784645 0.006049044895917177
rl training, epoch1, iter0, batch1012/1133, batch loss:0.006049044895917177, Training time:42790.987713098526
batch reward last col mean 0.10430024564266205 first col mean 0.08340035378932953 all mean 0.10360556095838547
0.0035840512719005346 0.0035840515047311783
rl training, epoch1, iter0, batch1013/1133, batch loss:0.0035840515047311783, Training time:42817.01117014885
batch reward last col mean 0.16407804191112518 first col mean 0.15777289867401123 all mean 0.1641015261411667
0.005295163951814175 0.0052951630204916
rl training, epoch1, iter0, batch1014/1133, batch loss:0.0052951630204916, Training time:42843.05438899994
batch reward last col mean 0.11288194358348846 first col mean 0.11473897844552994 all mean 0.11297609657049179
0.003408376593142748 0.003408376593142748
rl training, epoch1, iter0, batch1015/1133, batch loss:0.003408376593142748, Training time:42869.22650742531
batch reward last col mean 0.08022084087133408 first col mean 0.10541971027851105 all mean 0.08096062391996384
0.004772224463522434 0.004772223997861147
rl training, epoch1, iter0, batch1016/1133, batch loss:0.004772223997861147, Training time:42895.31572294235
batch reward last col mean 0.106380894780159 first col mean 0.11840634793043137 all mean 0.10682401061058044
0.005407624877989292 0.00540762348100543
rl training, epoch1, iter0, batch1017/1133, batch loss:0.00540762348100543, Training time:42921.44284415245
batch reward last col mean 0.07789519429206848 first col mean 0.10493351519107819 all mean 0.07886043936014175
0.0025338882114738226 0.0025338882114738226
rl training, epoch1, iter0, batch1018/1133, batch loss:0.0025338882114738226, Training time:42947.45073699951
batch reward last col mean 0.1210491955280304 first col mean 0.1354409158229828 all mean 0.1216830238699913
0.004868004005402327 0.004868003539741039
rl training, epoch1, iter0, batch1019/1133, batch loss:0.004868003539741039, Training time:42973.49168467522
batch reward last col mean 0.1516246199607849 first col mean 0.13417959213256836 all mean 0.15129540860652924
0.009645134210586548 0.009645134210586548
rl training, epoch1, iter0, batch1020/1133, batch loss:0.009645134210586548, Training time:42999.5822057724
batch reward last col mean 0.12188321352005005 first col mean 0.11473945528268814 all mean 0.12191512435674667
0.0038659442216157913 0.0038659439887851477
rl training, epoch1, iter0, batch1021/1133, batch loss:0.0038659439887851477, Training time:43025.65431976318
batch reward last col mean 0.10705368965864182 first col mean 0.1090327650308609 all mean 0.10753587633371353
0.0042307376861572266 0.0042307376861572266
rl training, epoch1, iter0, batch1022/1133, batch loss:0.0042307376861572266, Training time:43051.57232880592
batch reward last col mean 0.10853881388902664 first col mean 0.11211865395307541 all mean 0.1084710881114006
0.004969540983438492 0.004969540983438492
rl training, epoch1, iter0, batch1023/1133, batch loss:0.004969540983438492, Training time:43077.61249804497
batch reward last col mean 0.0972135066986084 first col mean 0.09640336036682129 all mean 0.09726310521364212
0.0037948060780763626 0.0037948067765682936
rl training, epoch1, iter0, batch1024/1133, batch loss:0.0037948067765682936, Training time:43103.520374536514
batch reward last col mean 0.12266828119754791 first col mean 0.12935614585876465 all mean 0.12263933569192886
0.009596290998160839 0.009596290998160839
rl training, epoch1, iter0, batch1025/1133, batch loss:0.009596290998160839, Training time:43129.333319664
batch reward last col mean 0.12654678523540497 first col mean 0.1405315399169922 all mean 0.12707599997520447
0.008418346755206585 0.008418346755206585
rl training, epoch1, iter0, batch1026/1133, batch loss:0.008418346755206585, Training time:43155.760308504105
batch reward last col mean 0.13739827275276184 first col mean 0.1377163529396057 all mean 0.13765612244606018
0.009474994614720345 0.009474994614720345
rl training, epoch1, iter0, batch1027/1133, batch loss:0.009474994614720345, Training time:43181.730754613876
batch reward last col mean 0.09673221409320831 first col mean 0.08751468360424042 all mean 0.09675823897123337
0.009311078116297722 0.009311078116297722
rl training, epoch1, iter0, batch1028/1133, batch loss:0.009311078116297722, Training time:43207.64178800583
batch reward last col mean 0.1628250777721405 first col mean 0.15597882866859436 all mean 0.16275443136692047
0.009343852289021015 0.009343852289021015
rl training, epoch1, iter0, batch1029/1133, batch loss:0.009343852289021015, Training time:43233.50634241104
batch reward last col mean 0.1270240694284439 first col mean 0.13824456930160522 all mean 0.12757474184036255
0.009894220158457756 0.009894218295812607
rl training, epoch1, iter0, batch1030/1133, batch loss:0.009894218295812607, Training time:43259.49555373192
batch reward last col mean 0.13835638761520386 first col mean 0.1436759978532791 all mean 0.13867251574993134
0.009448940865695477 0.009448940865695477
rl training, epoch1, iter0, batch1031/1133, batch loss:0.009448940865695477, Training time:43285.26859545708
batch reward last col mean 0.14735211431980133 first col mean 0.14752663671970367 all mean 0.14739279448986053
0.0070862481370568275 0.0070862481370568275
rl training, epoch1, iter0, batch1032/1133, batch loss:0.0070862481370568275, Training time:43311.042464494705
batch reward last col mean 0.1724972426891327 first col mean 0.18174880743026733 all mean 0.17246149480342865
0.012932753190398216 0.012932753190398216
rl training, epoch1, iter0, batch1033/1133, batch loss:0.012932753190398216, Training time:43336.83581447601
batch reward last col mean 0.14558348059654236 first col mean 0.15784485638141632 all mean 0.146412655711174
0.020951643586158752 0.020951641723513603
rl training, epoch1, iter0, batch1034/1133, batch loss:0.020951641723513603, Training time:43362.61110162735
batch reward last col mean 0.15527674555778503 first col mean 0.1548040211200714 all mean 0.15501821041107178
0.006487246602773666 0.006487246602773666
rl training, epoch1, iter0, batch1035/1133, batch loss:0.006487246602773666, Training time:43388.44340801239
batch reward last col mean 0.10483139008283615 first col mean 0.11479610204696655 all mean 0.10506530106067657
0.008699044585227966 0.008699042722582817
rl training, epoch1, iter0, batch1036/1133, batch loss:0.008699042722582817, Training time:43414.047095537186
batch reward last col mean 0.12079931795597076 first col mean 0.137399822473526 all mean 0.12152985483407974
0.0127881383523345 0.0127881383523345
rl training, epoch1, iter0, batch1037/1133, batch loss:0.0127881383523345, Training time:43439.72358798981
batch reward last col mean 0.14160268008708954 first col mean 0.13487258553504944 all mean 0.14171428978443146
0.013004484586417675 0.0130044836550951
rl training, epoch1, iter0, batch1038/1133, batch loss:0.0130044836550951, Training time:43465.55050563812
batch reward last col mean 0.09253790974617004 first col mean 0.10820358991622925 all mean 0.09328686445951462
0.00923007633537054 0.009230075404047966
rl training, epoch1, iter0, batch1039/1133, batch loss:0.009230075404047966, Training time:43491.42693567276
batch reward last col mean 0.10502392798662186 first col mean 0.11388079822063446 all mean 0.10488412529230118
0.018157100304961205 0.018157096579670906
rl training, epoch1, iter0, batch1040/1133, batch loss:0.018157096579670906, Training time:43517.64039993286
batch reward last col mean 0.13112375140190125 first col mean 0.1312507688999176 all mean 0.13129088282585144
0.010132202878594398 0.010132200084626675
rl training, epoch1, iter0, batch1041/1133, batch loss:0.010132200084626675, Training time:43543.49182295799
batch reward last col mean 0.12361204624176025 first col mean 0.12567465007305145 all mean 0.1234716922044754
0.020824551582336426 0.020824549719691277
rl training, epoch1, iter0, batch1042/1133, batch loss:0.020824549719691277, Training time:43569.292086839676
batch reward last col mean 0.120728999376297 first col mean 0.11149626225233078 all mean 0.12039604783058167
0.01789296232163906 0.017892960458993912
rl training, epoch1, iter0, batch1043/1133, batch loss:0.017892960458993912, Training time:43594.94312810898
batch reward last col mean 0.10790689289569855 first col mean 0.1086391806602478 all mean 0.10809347033500671
0.014100699685513973 0.014100699685513973
rl training, epoch1, iter0, batch1044/1133, batch loss:0.014100699685513973, Training time:43620.980110645294
batch reward last col mean 0.11459863930940628 first col mean 0.11070413142442703 all mean 0.11434366554021835
0.02058953419327736 0.02058953233063221
rl training, epoch1, iter0, batch1045/1133, batch loss:0.02058953233063221, Training time:43646.9707839489
batch reward last col mean 0.12644056975841522 first col mean 0.12441900372505188 all mean 0.1261967420578003
0.015606807544827461 0.015606807544827461
rl training, epoch1, iter0, batch1046/1133, batch loss:0.015606807544827461, Training time:43672.88699436188
batch reward last col mean 0.1594170480966568 first col mean 0.15926770865917206 all mean 0.15957893431186676
0.0236322320997715 0.0236322283744812
rl training, epoch1, iter0, batch1047/1133, batch loss:0.0236322283744812, Training time:43698.5226187706
batch reward last col mean 0.1617031991481781 first col mean 0.16541588306427002 all mean 0.16195881366729736
0.027295347303152084 0.027295347303152084
rl training, epoch1, iter0, batch1048/1133, batch loss:0.027295347303152084, Training time:43724.34887313843
batch reward last col mean 0.1259773224592209 first col mean 0.12093120068311691 all mean 0.12583352625370026
0.018768180161714554 0.018768178299069405
rl training, epoch1, iter0, batch1049/1133, batch loss:0.018768178299069405, Training time:43750.11587500572
batch reward last col mean 0.1219467744231224 first col mean 0.12609121203422546 all mean 0.12225786596536636
0.022018341347575188 0.02201833948493004
rl training, epoch1, iter0, batch1050/1133, batch loss:0.02201833948493004, Training time:43775.82166814804
batch reward last col mean 0.13113811612129211 first col mean 0.13087329268455505 all mean 0.13115401566028595
0.023042308166623116 0.023042310029268265
rl training, epoch1, iter0, batch1051/1133, batch loss:0.023042310029268265, Training time:43801.6293156147
batch reward last col mean 0.12304379791021347 first col mean 0.12768062949180603 all mean 0.12336092442274094
0.025665223598480225 0.025665227323770523
rl training, epoch1, iter0, batch1052/1133, batch loss:0.025665227323770523, Training time:43827.29624629021
batch reward last col mean 0.12832173705101013 first col mean 0.1430838406085968 all mean 0.12881290912628174
0.01424438413232565 0.01424438413232565
rl training, epoch1, iter0, batch1053/1133, batch loss:0.01424438413232565, Training time:43853.23413157463
batch reward last col mean 0.16667112708091736 first col mean 0.17048954963684082 all mean 0.16673514246940613
0.04149866849184036 0.041498664766550064
rl training, epoch1, iter0, batch1054/1133, batch loss:0.041498664766550064, Training time:43878.88645362854
batch reward last col mean 0.09768223762512207 first col mean 0.1247907280921936 all mean 0.09823471307754517
0.019868791103363037 0.019868789240717888
rl training, epoch1, iter0, batch1055/1133, batch loss:0.019868789240717888, Training time:43904.3310611248
batch reward last col mean 0.12884946167469025 first col mean 0.1227664202451706 all mean 0.12890829145908356
0.025527410209178925 0.025527410209178925
rl training, epoch1, iter0, batch1056/1133, batch loss:0.025527410209178925, Training time:43930.17181348801
batch reward last col mean 0.19561585783958435 first col mean 0.1987065076828003 all mean 0.19525693356990814
0.041492145508527756 0.041492149233818054
rl training, epoch1, iter0, batch1057/1133, batch loss:0.041492149233818054, Training time:43956.054733753204
batch reward last col mean 0.17170587182044983 first col mean 0.19174115359783173 all mean 0.17234675586223602
0.061724040657281876 0.061724040657281876
rl training, epoch1, iter0, batch1058/1133, batch loss:0.061724040657281876, Training time:43981.65026497841
batch reward last col mean 0.11821510642766953 first col mean 0.1240609735250473 all mean 0.11834927648305893
0.02441478706896305 0.02441478706896305
rl training, epoch1, iter0, batch1059/1133, batch loss:0.02441478706896305, Training time:44007.47485804558
batch reward last col mean 0.20794275403022766 first col mean 0.21838639676570892 all mean 0.20843234658241272
0.03885083273053169 0.03885083273053169
rl training, epoch1, iter0, batch1060/1133, batch loss:0.03885083273053169, Training time:44033.34079051018
batch reward last col mean 0.22939616441726685 first col mean 0.22194084525108337 all mean 0.22917897999286652
0.03507668524980545 0.03507668524980545
rl training, epoch1, iter0, batch1061/1133, batch loss:0.03507668524980545, Training time:44059.085000276566
batch reward last col mean 0.22025039792060852 first col mean 0.23747952282428741 all mean 0.22061407566070557
0.04860119894146919 0.04860119894146919
rl training, epoch1, iter0, batch1062/1133, batch loss:0.04860119894146919, Training time:44084.79353475571
batch reward last col mean 0.1845860779285431 first col mean 0.2323896586894989 all mean 0.18663522601127625
0.05697865039110184 0.05697865039110184
rl training, epoch1, iter0, batch1063/1133, batch loss:0.05697865039110184, Training time:44110.48262119293
batch reward last col mean 0.22790876030921936 first col mean 0.25457844138145447 all mean 0.2293778955936432
0.056534476578235626 0.05653447285294533
rl training, epoch1, iter0, batch1064/1133, batch loss:0.05653447285294533, Training time:44136.34007000923
batch reward last col mean 0.29002878069877625 first col mean 0.27805355191230774 all mean 0.2901262640953064
0.09545131027698517 0.09545131027698517
rl training, epoch1, iter0, batch1065/1133, batch loss:0.09545131027698517, Training time:44162.103917360306
batch reward last col mean 0.2754490077495575 first col mean 0.2801174521446228 all mean 0.2760634422302246
0.12868145108222961 0.12868145108222961
rl training, epoch1, iter0, batch1066/1133, batch loss:0.12868145108222961, Training time:44187.49561572075
batch reward last col mean 0.30945509672164917 first col mean 0.3106539249420166 all mean 0.30950433015823364
0.12687712907791138 0.12687712907791138
rl training, epoch1, iter0, batch1067/1133, batch loss:0.12687712907791138, Training time:44212.9213309288
batch reward last col mean 0.3086353540420532 first col mean 0.3315862715244293 all mean 0.3095092475414276
0.15756657719612122 0.15756657719612122
rl training, epoch1, iter0, batch1068/1133, batch loss:0.15756657719612122, Training time:44238.42795300484
batch reward last col mean 0.2652302384376526 first col mean 0.2827765941619873 all mean 0.26599985361099243
0.12319263815879822 0.12319263815879822
rl training, epoch1, iter0, batch1069/1133, batch loss:0.12319263815879822, Training time:44263.38905930519
batch reward last col mean 0.2625918984413147 first col mean 0.27147039771080017 all mean 0.26337501406669617
0.13369683921337128 0.13369683921337128
rl training, epoch1, iter0, batch1070/1133, batch loss:0.13369683921337128, Training time:44286.90166759491
batch reward last col mean 0.2971293330192566 first col mean 0.312764972448349 all mean 0.301960825920105
0.12089668214321136 0.12089668214321136
rl training, epoch1, iter0, batch1071/1133, batch loss:0.12089668214321136, Training time:44288.277980566025
batch reward last col mean 0.3097257912158966 first col mean 0.315981388092041 all mean 0.3076125383377075
0.1739177256822586 0.17391769587993622
rl training, epoch1, iter0, batch1072/1133, batch loss:0.17391769587993622, Training time:44289.726363658905
batch reward last col mean 0.3468724489212036 first col mean 0.31579381227493286 all mean 0.3455654978752136
0.11334970593452454 0.11334969848394394
rl training, epoch1, iter0, batch1073/1133, batch loss:0.11334969848394394, Training time:44314.32959961891
batch reward last col mean 0.23560196161270142 first col mean 0.24368585646152496 all mean 0.2380150407552719
0.09244108945131302 0.09244108945131302
rl training, epoch1, iter0, batch1074/1133, batch loss:0.09244108945131302, Training time:44315.78036284447
batch reward last col mean 0.30178725719451904 first col mean 0.29349517822265625 all mean 0.2993306517601013
0.143040269613266 0.143040269613266
rl training, epoch1, iter0, batch1075/1133, batch loss:0.143040269613266, Training time:44317.09340214729
batch reward last col mean 0.30926212668418884 first col mean 0.3051258623600006 all mean 0.30802854895591736
0.1027437075972557 0.10274370014667511
rl training, epoch1, iter0, batch1076/1133, batch loss:0.10274370014667511, Training time:44319.26756978035
batch reward last col mean 0.28525930643081665 first col mean 0.29592442512512207 all mean 0.2869502305984497
0.1350969523191452 0.1350969672203064
rl training, epoch1, iter0, batch1077/1133, batch loss:0.1350969672203064, Training time:44320.61974072456
batch reward last col mean 0.3192112147808075 first col mean 0.3262064754962921 all mean 0.3208976089954376
0.17658860981464386 0.17658860981464386
rl training, epoch1, iter0, batch1078/1133, batch loss:0.17658860981464386, Training time:44321.79918241501
batch reward last col mean 0.3692684471607208 first col mean 0.340414434671402 all mean 0.36238133907318115
0.20691917836666107 0.20691919326782227
rl training, epoch1, iter0, batch1079/1133, batch loss:0.20691919326782227, Training time:44323.53379917145
batch reward last col mean 0.3040609061717987 first col mean 0.32360732555389404 all mean 0.3085359036922455
0.2045545130968094 0.2045545130968094
rl training, epoch1, iter0, batch1080/1133, batch loss:0.2045545130968094, Training time:44324.974798202515
batch reward last col mean 0.31087586283683777 first col mean 0.30873599648475647 all mean 0.3086576461791992
0.2123834192752838 0.2123834192752838
rl training, epoch1, iter0, batch1081/1133, batch loss:0.2123834192752838, Training time:44327.180896282196
batch reward last col mean 0.3545231223106384 first col mean 0.34040430188179016 all mean 0.3526934087276459
0.1939455270767212 0.1939454972743988
rl training, epoch1, iter0, batch1082/1133, batch loss:0.1939454972743988, Training time:44329.92901659012
batch reward last col mean 0.28656986355781555 first col mean 0.292192280292511 all mean 0.28787723183631897
0.13828690350055695 0.13828690350055695
rl training, epoch1, iter0, batch1083/1133, batch loss:0.13828690350055695, Training time:44338.51950645447
batch reward last col mean 0.2829445004463196 first col mean 0.2955954670906067 all mean 0.2816551625728607
0.1529088318347931 0.1529088169336319
rl training, epoch1, iter0, batch1084/1133, batch loss:0.1529088169336319, Training time:44352.841968774796
batch reward last col mean 0.2129051685333252 first col mean 0.22602880001068115 all mean 0.21310614049434662
0.12220077216625214 0.12220078706741333
rl training, epoch1, iter0, batch1085/1133, batch loss:0.12220078706741333, Training time:44373.09272480011
batch reward last col mean 0.2681427299976349 first col mean 0.2567184567451477 all mean 0.26163816452026367
0.1820303052663803 0.1820303052663803
rl training, epoch1, iter0, batch1086/1133, batch loss:0.1820303052663803, Training time:44375.26466488838
batch reward last col mean 0.30949893593788147 first col mean 0.3114055097103119 all mean 0.30951789021492004
0.2255735993385315 0.2255735993385315
rl training, epoch1, iter0, batch1087/1133, batch loss:0.2255735993385315, Training time:44378.01312208176
batch reward last col mean 0.3191593289375305 first col mean 0.3180012106895447 all mean 0.32017576694488525
0.20235809683799744 0.20235808193683624
rl training, epoch1, iter0, batch1088/1133, batch loss:0.20235808193683624, Training time:44382.717765808105
batch reward last col mean 0.24914199113845825 first col mean 0.25715571641921997 all mean 0.2490590661764145
0.285481721162796 0.285481721162796
rl training, epoch1, iter0, batch1089/1133, batch loss:0.285481721162796, Training time:44390.177649497986
batch reward last col mean 0.3090665936470032 first col mean 0.30633753538131714 all mean 0.30880266427993774
0.28268250823020935 0.28268253803253174
rl training, epoch1, iter0, batch1090/1133, batch loss:0.28268253803253174, Training time:44409.501871585846
batch reward last col mean 0.24403081834316254 first col mean 0.25369793176651 all mean 0.24593694508075714
0.19307897984981537 0.19307897984981537
rl training, epoch1, iter0, batch1091/1133, batch loss:0.19307897984981537, Training time:44430.363367557526
batch reward last col mean 0.29830390214920044 first col mean 0.31505072116851807 all mean 0.2984907925128937
0.2490958720445633 0.2490958720445633
rl training, epoch1, iter0, batch1092/1133, batch loss:0.2490958720445633, Training time:44446.66364097595
batch reward last col mean 0.3002631664276123 first col mean 0.27026060223579407 all mean 0.2985422909259796
0.26115450263023376 0.26115450263023376
rl training, epoch1, iter0, batch1093/1133, batch loss:0.26115450263023376, Training time:44473.237293720245
batch reward last col mean 0.33129388093948364 first col mean 0.3420258164405823 all mean 0.32915088534355164
0.21480385959148407 0.21480384469032288
rl training, epoch1, iter0, batch1094/1133, batch loss:0.21480384469032288, Training time:44500.00057721138
batch reward last col mean 0.3516274690628052 first col mean 0.32837289571762085 all mean 0.34771183133125305
0.2508128881454468 0.2508128881454468
rl training, epoch1, iter0, batch1095/1133, batch loss:0.2508128881454468, Training time:44518.97077202797
batch reward last col mean 0.2540895938873291 first col mean 0.2783590853214264 all mean 0.2535630464553833
0.20493435859680176 0.20493434369564056
rl training, epoch1, iter0, batch1096/1133, batch loss:0.20493434369564056, Training time:44544.13758802414
batch reward last col mean 0.36479756236076355 first col mean 0.33921319246292114 all mean 0.3639069199562073
0.4244539141654968 0.4244539439678192
rl training, epoch1, iter0, batch1097/1133, batch loss:0.4244539439678192, Training time:44552.86094546318
batch reward last col mean 0.3951827585697174 first col mean 0.3395707309246063 all mean 0.386172890663147
0.3820335865020752 0.3820335566997528
rl training, epoch1, iter0, batch1098/1133, batch loss:0.3820335566997528, Training time:44559.45279097557
batch reward last col mean 0.34020543098449707 first col mean 0.3595542311668396 all mean 0.33870723843574524
0.2668779194355011 0.2668779194355011
rl training, epoch1, iter0, batch1099/1133, batch loss:0.2668779194355011, Training time:44567.75298976898
batch reward last col mean 0.33652326464653015 first col mean 0.3423818051815033 all mean 0.3269980251789093
0.3328298330307007 0.33282986283302307
rl training, epoch1, iter0, batch1100/1133, batch loss:0.33282986283302307, Training time:44572.8228430748
batch reward last col mean 0.33265283703804016 first col mean 0.3103936016559601 all mean 0.3328770697116852
0.30311790108680725 0.30311787128448486
rl training, epoch1, iter0, batch1101/1133, batch loss:0.30311787128448486, Training time:44580.561980724335
batch reward last col mean 0.29296213388442993 first col mean 0.2803422212600708 all mean 0.2922941744327545
0.2930621802806854 0.2930622100830078
rl training, epoch1, iter0, batch1102/1133, batch loss:0.2930622100830078, Training time:44586.15091872215
batch reward last col mean 0.3035878837108612 first col mean 0.3070245683193207 all mean 0.3020245134830475
0.2780986428260803 0.2780986428260803
rl training, epoch1, iter0, batch1103/1133, batch loss:0.2780986428260803, Training time:44593.32988238335
batch reward last col mean 0.3001592755317688 first col mean 0.31647711992263794 all mean 0.3002750277519226
0.3785724937915802 0.3785724937915802
rl training, epoch1, iter0, batch1104/1133, batch loss:0.3785724937915802, Training time:44608.862385988235
batch reward last col mean 0.2450593113899231 first col mean 0.2624179422855377 all mean 0.2430696189403534
0.25709640979766846 0.25709640979766846
rl training, epoch1, iter0, batch1105/1133, batch loss:0.25709640979766846, Training time:44613.250611543655
batch reward last col mean 0.31807488203048706 first col mean 0.3188773989677429 all mean 0.3190549910068512
0.33412525057792664 0.334125280380249
rl training, epoch1, iter0, batch1106/1133, batch loss:0.334125280380249, Training time:44635.71860289574
batch reward last col mean 0.32268255949020386 first col mean 0.3583105504512787 all mean 0.32206305861473083
0.30520176887512207 0.30520176887512207
rl training, epoch1, iter0, batch1107/1133, batch loss:0.30520176887512207, Training time:44661.18930435181
batch reward last col mean 0.3464723825454712 first col mean 0.31146398186683655 all mean 0.34143272042274475
0.42613762617111206 0.42613765597343445
rl training, epoch1, iter0, batch1108/1133, batch loss:0.42613765597343445, Training time:44672.371530056
batch reward last col mean 0.33172887563705444 first col mean 0.3086667060852051 all mean 0.33071351051330566
0.4398186504840851 0.4398186504840851
rl training, epoch1, iter0, batch1109/1133, batch loss:0.4398186504840851, Training time:44697.0917801857
batch reward last col mean 0.2693328261375427 first col mean 0.26420772075653076 all mean 0.26638421416282654
0.24414312839508057 0.24414311349391937
rl training, epoch1, iter0, batch1110/1133, batch loss:0.24414311349391937, Training time:44723.55965280533
batch reward last col mean 0.33088505268096924 first col mean 0.32536232471466064 all mean 0.32781898975372314
0.24189740419387817 0.24189740419387817
rl training, epoch1, iter0, batch1111/1133, batch loss:0.24189740419387817, Training time:44750.03938746452
batch reward last col mean 0.3039170801639557 first col mean 0.3334156274795532 all mean 0.3045506775379181
0.3536764979362488 0.3536764979362488
rl training, epoch1, iter0, batch1112/1133, batch loss:0.3536764979362488, Training time:44776.401371479034
batch reward last col mean 0.2829172611236572 first col mean 0.31612250208854675 all mean 0.28237098455429077
0.343618243932724 0.343618243932724
rl training, epoch1, iter0, batch1113/1133, batch loss:0.343618243932724, Training time:44794.59468626976
batch reward last col mean 0.28472498059272766 first col mean 0.29575979709625244 all mean 0.2867295742034912
0.3761844336986542 0.37618446350097656
rl training, epoch1, iter0, batch1114/1133, batch loss:0.37618446350097656, Training time:44803.82692337036
batch reward last col mean 0.33437949419021606 first col mean 0.3450290262699127 all mean 0.3303239643573761
0.39027541875839233 0.39027541875839233
rl training, epoch1, iter0, batch1115/1133, batch loss:0.39027541875839233, Training time:44809.608221530914
batch reward last col mean 0.37987199425697327 first col mean 0.3391815423965454 all mean 0.3774983882904053
0.45936286449432373 0.45936286449432373
rl training, epoch1, iter0, batch1116/1133, batch loss:0.45936286449432373, Training time:44813.52122879028
batch reward last col mean 0.3583337664604187 first col mean 0.3576139211654663 all mean 0.36057958006858826
0.4421372413635254 0.442137211561203
rl training, epoch1, iter0, batch1117/1133, batch loss:0.442137211561203, Training time:44815.65510034561
batch reward last col mean 0.2963131070137024 first col mean 0.39302268624305725 all mean 0.3051961362361908
0.36542150378227234 0.36542150378227234
rl training, epoch1, iter0, batch1118/1133, batch loss:0.36542150378227234, Training time:44817.71260762215
batch reward last col mean 0.3595331907272339 first col mean 0.33911433815956116 all mean 0.35131171345710754
0.33858582377433777 0.33858582377433777
rl training, epoch1, iter0, batch1119/1133, batch loss:0.33858582377433777, Training time:44820.330637931824
batch reward last col mean 0.35081756114959717 first col mean 0.42579787969589233 all mean 0.3580370247364044
0.3765126168727875 0.3765126168727875
rl training, epoch1, iter0, batch1120/1133, batch loss:0.3765126168727875, Training time:44822.90312027931
batch reward last col mean 0.37523818016052246 first col mean 0.3681148588657379 all mean 0.3693133294582367
0.3672279715538025 0.3672279715538025
rl training, epoch1, iter0, batch1121/1133, batch loss:0.3672279715538025, Training time:44824.47737812996
batch reward last col mean 0.38842737674713135 first col mean 0.39069631695747375 all mean 0.3907926082611084
0.33525922894477844 0.33525922894477844
rl training, epoch1, iter0, batch1122/1133, batch loss:0.33525922894477844, Training time:44825.504472732544
batch reward last col mean 0.3999272584915161 first col mean 0.3367636203765869 all mean 0.38800764083862305
0.34289732575416565 0.34289729595184326
rl training, epoch1, iter0, batch1123/1133, batch loss:0.34289729595184326, Training time:44826.793006658554
batch reward last col mean 0.3009527027606964 first col mean 0.3115661144256592 all mean 0.30196964740753174
0.33140289783477783 0.33140289783477783
rl training, epoch1, iter0, batch1124/1133, batch loss:0.33140289783477783, Training time:44827.93051528931
batch reward last col mean 0.36260560154914856 first col mean 0.395474910736084 all mean 0.3703644573688507
0.30059754848480225 0.30059754848480225
rl training, epoch1, iter0, batch1125/1133, batch loss:0.30059754848480225, Training time:44828.677688360214
batch reward last col mean 0.364017516374588 first col mean 0.35180261731147766 all mean 0.35577455163002014
0.300929456949234 0.300929456949234
rl training, epoch1, iter0, batch1126/1133, batch loss:0.300929456949234, Training time:44829.84966945648
batch reward last col mean 0.3534460663795471 first col mean 0.38972440361976624 all mean 0.36298099160194397
0.28313809633255005 0.28313809633255005
rl training, epoch1, iter0, batch1127/1133, batch loss:0.28313809633255005, Training time:44830.69419455528
batch reward last col mean 0.3807525038719177 first col mean 0.3862709403038025 all mean 0.3760041892528534
0.2914188802242279 0.2914188504219055
rl training, epoch1, iter0, batch1128/1133, batch loss:0.2914188504219055, Training time:44831.503363609314
batch reward last col mean 0.3034665584564209 first col mean 0.343315064907074 all mean 0.3085041046142578
0.182161346077919 0.182161346077919
rl training, epoch1, iter0, batch1129/1133, batch loss:0.182161346077919, Training time:44832.97740316391
batch reward last col mean 0.3524271249771118 first col mean 0.36941367387771606 all mean 0.3530864715576172
0.3181764781475067 0.3181764781475067
rl training, epoch1, iter0, batch1130/1133, batch loss:0.3181764781475067, Training time:44833.96591877937
batch reward last col mean 0.30378326773643494 first col mean 0.3319754898548126 all mean 0.3080928325653076
0.17395690083503723 0.17395690083503723
rl training, epoch1, iter0, batch1131/1133, batch loss:0.17395690083503723, Training time:44835.102113723755
batch reward last col mean 0.33201122283935547 first col mean 0.3226315677165985 all mean 0.3320711553096771
0.2171909362077713 0.2171909213066101
rl training, epoch1, iter0, batch1132/1133, batch loss:0.2171909213066101, Training time:44835.94128704071
rl training, epoch 1, iter 0, loss:0.016375039389289005, Training time:44835.941415548325 
rl epoch 1, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.26816102747936116 Time: 102.63642144203186 s
cur_epoch: 1
D Training Loss: 0.25063146793489843 Time: 102.21450424194336 s
cur_epoch: 2
D Training Loss: 0.2478570646005506 Time: 104.37445497512817 s
cur_epoch: 3
D Training Loss: 0.2467904453480654 Time: 102.85920977592468 s
cur_epoch: 4
D Training Loss: 0.2434915627985009 Time: 102.66000032424927 s
rl epoch 2, begin RL for generator...
batch reward last col mean 0.005508015397936106 first col mean 0.0008665215573273599 all mean 0.0032696120906621218
0.013007712550461292 0.013007711619138718
rl training, epoch2, iter0, batch0/1133, batch loss:0.013007711619138718, Training time:45352.56800031662
batch reward last col mean 0.001836524810642004 first col mean 0.002481030533090234 all mean 0.0020349544938653708
0.004315361380577087 0.004315361380577087
rl training, epoch2, iter0, batch1/1133, batch loss:0.004315361380577087, Training time:45353.62523031235
batch reward last col mean 0.005277913995087147 first col mean 0.0018332790350541472 all mean 0.0038189152255654335
0.007959000766277313 0.007959001697599888
rl training, epoch2, iter0, batch2/1133, batch loss:0.007959001697599888, Training time:45355.45843267441
batch reward last col mean 2.3643327949685045e-05 first col mean 0.0010494651505723596 all mean 0.00024319352814927697
0.000763633637689054 0.000763633637689054
rl training, epoch2, iter0, batch3/1133, batch loss:0.000763633637689054, Training time:45356.645740270615
batch reward last col mean 0.00010021345224231482 first col mean 0.0005282122874632478 all mean 0.0012851833598688245
0.01030800212174654 0.01030800212174654
rl training, epoch2, iter0, batch4/1133, batch loss:0.01030800212174654, Training time:45358.30581212044
batch reward last col mean 0.00011468187585705891 first col mean 0.00017397610645275563 all mean 0.00034213243634440005
0.0039984434843063354 0.0039984434843063354
rl training, epoch2, iter0, batch5/1133, batch loss:0.0039984434843063354, Training time:45360.64463400841
batch reward last col mean 0.0020964685827493668 first col mean 0.0015765830175951123 all mean 0.0018625411903485656
0.00769161619246006 0.00769161619246006
rl training, epoch2, iter0, batch6/1133, batch loss:0.00769161619246006, Training time:45362.13529920578
batch reward last col mean 0.00048570334911346436 first col mean 0.004191820044070482 all mean 0.000805758754722774
0.004766847938299179 0.004766847938299179
rl training, epoch2, iter0, batch7/1133, batch loss:0.004766847938299179, Training time:45363.8878030777
batch reward last col mean 0.0058069112710654736 first col mean 0.00018551404355093837 all mean 0.0030504423193633556
0.010769523680210114 0.010769523680210114
rl training, epoch2, iter0, batch8/1133, batch loss:0.010769523680210114, Training time:45365.377069711685
batch reward last col mean 0.006990227848291397 first col mean 0.0001241171412402764 all mean 0.005340625066310167
0.0048837810754776 0.0048837810754776
rl training, epoch2, iter0, batch9/1133, batch loss:0.0048837810754776, Training time:45366.682574272156
batch reward last col mean 0.00028493907302618027 first col mean 0.002231271006166935 all mean 0.0004909223644062877
0.0016377050196751952 0.0016377050196751952
rl training, epoch2, iter0, batch10/1133, batch loss:0.0016377050196751952, Training time:45369.48370671272
batch reward last col mean 0.0047300648875534534 first col mean 0.0012232029112055898 all mean 0.00452468590810895
0.002851524157449603 0.002851524855941534
rl training, epoch2, iter0, batch11/1133, batch loss:0.002851524855941534, Training time:45371.33453774452
batch reward last col mean 0.0001614033681107685 first col mean 0.0008349360432475805 all mean 0.0002956111857201904
0.0014199730940163136 0.0014199730940163136
rl training, epoch2, iter0, batch12/1133, batch loss:0.0014199730940163136, Training time:45372.99256634712
batch reward last col mean 0.00030858133686706424 first col mean 0.002646717708557844 all mean 0.0006038052379153669
0.0025143579114228487 0.0025143579114228487
rl training, epoch2, iter0, batch13/1133, batch loss:0.0025143579114228487, Training time:45375.55147981644
batch reward last col mean 0.00015652905858587474 first col mean 0.00031837247661314905 all mean 0.00037306107697077096
0.0014400972286239266 0.0014400975778698921
rl training, epoch2, iter0, batch14/1133, batch loss:0.0014400975778698921, Training time:45377.251214027405
batch reward last col mean 0.0023470676969736814 first col mean 0.0031964320223778486 all mean 0.002481013536453247
0.004548041149973869 0.004548041615635157
rl training, epoch2, iter0, batch15/1133, batch loss:0.004548041615635157, Training time:45379.76653909683
batch reward last col mean 1.3835052413924132e-05 first col mean 0.0018067164346575737 all mean 0.00040329177863895893
0.0022555808536708355 0.0022555808536708355
rl training, epoch2, iter0, batch16/1133, batch loss:0.0022555808536708355, Training time:45382.488454818726
batch reward last col mean 9.095391578739509e-05 first col mean 0.00016099638014566153 all mean 0.00020503951236605644
0.0009277292992919683 0.0009277292410843074
rl training, epoch2, iter0, batch17/1133, batch loss:0.0009277292410843074, Training time:45384.55702781677
batch reward last col mean 0.0022767919581383467 first col mean 0.0038016962353140116 all mean 0.0026160289999097586
0.00588978361338377 0.005889783147722483
rl training, epoch2, iter0, batch18/1133, batch loss:0.005889783147722483, Training time:45387.624809503555
batch reward last col mean 7.99848567112349e-05 first col mean 0.00017828578711487353 all mean 0.00038551591569557786
0.004207945894449949 0.004207945894449949
rl training, epoch2, iter0, batch19/1133, batch loss:0.004207945894449949, Training time:45393.42864441872
batch reward last col mean 3.9881902921479195e-05 first col mean 0.0012967983493581414 all mean 0.0005894567002542317
0.0026539580430835485 0.0026539575774222612
rl training, epoch2, iter0, batch20/1133, batch loss:0.0026539575774222612, Training time:45395.4128036499
batch reward last col mean 3.871150693157688e-05 first col mean 0.0019138712668791413 all mean 0.00032227023621089756
0.0008450250024907291 0.0008450252353213727
rl training, epoch2, iter0, batch21/1133, batch loss:0.0008450252353213727, Training time:45397.62313246727
batch reward last col mean 0.004033289849758148 first col mean 0.0005490422481670976 all mean 0.003243708750233054
0.006068826653063297 0.006068826653063297
rl training, epoch2, iter0, batch22/1133, batch loss:0.006068826653063297, Training time:45402.02711367607
batch reward last col mean 0.0016193913761526346 first col mean 0.00399641552940011 all mean 0.0008957342361100018
0.0044875238090753555 0.0044875238090753555
rl training, epoch2, iter0, batch23/1133, batch loss:0.0044875238090753555, Training time:45406.93690896034
batch reward last col mean 0.000596786558162421 first col mean 0.00032029408612288535 all mean 0.00090918003115803
0.0034239557571709156 0.0034239557571709156
rl training, epoch2, iter0, batch24/1133, batch loss:0.0034239557571709156, Training time:45409.254969358444
batch reward last col mean 0.001973520265892148 first col mean 0.00048786099068820477 all mean 0.0016962221125140786
0.0036730619613081217 0.0036730619613081217
rl training, epoch2, iter0, batch25/1133, batch loss:0.0036730619613081217, Training time:45411.22508907318
batch reward last col mean 0.003450402757152915 first col mean 0.0007996176718734205 all mean 0.00313776358962059
0.004110603593289852 0.004110603593289852
rl training, epoch2, iter0, batch26/1133, batch loss:0.004110603593289852, Training time:45414.24938106537
batch reward last col mean 0.002449699444696307 first col mean 0.0012557721929624677 all mean 0.00251714326441288
0.004944075830280781 0.004944075830280781
rl training, epoch2, iter0, batch27/1133, batch loss:0.004944075830280781, Training time:45419.992227077484
batch reward last col mean 0.004078991711139679 first col mean 0.0023856363259255886 all mean 0.003517808858305216
0.00414743646979332 0.00414743646979332
rl training, epoch2, iter0, batch28/1133, batch loss:0.00414743646979332, Training time:45422.45433759689
batch reward last col mean 0.000871029740665108 first col mean 0.005588902626186609 all mean 0.0011070762993767858
0.0017394083552062511 0.0017394083552062511
rl training, epoch2, iter0, batch29/1133, batch loss:0.0017394083552062511, Training time:45425.86372947693
batch reward last col mean 0.00015165131480898708 first col mean 0.0025645156856626272 all mean 0.00028769197524525225
0.0013696490786969662 0.0013696493115276098
rl training, epoch2, iter0, batch30/1133, batch loss:0.0013696493115276098, Training time:45434.96142697334
batch reward last col mean 0.001014641486108303 first col mean 0.006441205739974976 all mean 0.0014188813511282206
0.004707626067101955 0.004707625601440668
rl training, epoch2, iter0, batch31/1133, batch loss:0.004707625601440668, Training time:45438.874455451965
batch reward last col mean 0.0004205259319860488 first col mean 0.0020372404251247644 all mean 0.0009215379832312465
0.0038497624918818474 0.0038497624918818474
rl training, epoch2, iter0, batch32/1133, batch loss:0.0038497624918818474, Training time:45441.20540928841
batch reward last col mean 0.00046967979869805276 first col mean 0.0035056069027632475 all mean 0.001270167762413621
0.008202992379665375 0.008202992379665375
rl training, epoch2, iter0, batch33/1133, batch loss:0.008202992379665375, Training time:45446.32393169403
batch reward last col mean 0.0046571712009608746 first col mean 0.0036413944326341152 all mean 0.004193274304270744
0.008344398811459541 0.008344398811459541
rl training, epoch2, iter0, batch34/1133, batch loss:0.008344398811459541, Training time:45448.41198539734
batch reward last col mean 0.00010967774869641289 first col mean 0.0020042937248945236 all mean 0.0006036542472429574
0.004663678351789713 0.004663678351789713
rl training, epoch2, iter0, batch35/1133, batch loss:0.004663678351789713, Training time:45452.73976755142
batch reward last col mean 0.0014604051830247045 first col mean 0.0027474514208734035 all mean 0.002537124091759324
0.00984907615929842 0.009849075227975845
rl training, epoch2, iter0, batch36/1133, batch loss:0.009849075227975845, Training time:45455.55838561058
batch reward last col mean 0.001303787576034665 first col mean 0.008636747486889362 all mean 0.0029657790437340736
0.008270515128970146 0.008270515128970146
rl training, epoch2, iter0, batch37/1133, batch loss:0.008270515128970146, Training time:45457.88565802574
batch reward last col mean 0.006419996730983257 first col mean 0.00382546940818429 all mean 0.0062955268658697605
0.01187521405518055 0.011875214986503124
rl training, epoch2, iter0, batch38/1133, batch loss:0.011875214986503124, Training time:45461.44134068489
batch reward last col mean 0.0006304336711764336 first col mean 0.00840588565915823 all mean 0.002293979749083519
0.009618132375180721 0.009618133306503296
rl training, epoch2, iter0, batch39/1133, batch loss:0.009618133306503296, Training time:45465.37045097351
batch reward last col mean 0.003118806052953005 first col mean 0.015259302221238613 all mean 0.004457714036107063
0.010801884345710278 0.010801886208355427
rl training, epoch2, iter0, batch40/1133, batch loss:0.010801886208355427, Training time:45468.3705470562
batch reward last col mean 0.012293504551053047 first col mean 0.00994487851858139 all mean 0.0122245904058218
0.013133244588971138 0.013133245520293713
rl training, epoch2, iter0, batch41/1133, batch loss:0.013133245520293713, Training time:45472.17009162903
batch reward last col mean 0.01794588938355446 first col mean 0.009453670121729374 all mean 0.015811016783118248
0.02267327718436718 0.02267327718436718
rl training, epoch2, iter0, batch42/1133, batch loss:0.02267327718436718, Training time:45476.71560883522
batch reward last col mean 0.02501469850540161 first col mean 0.016283510252833366 all mean 0.025301288813352585
0.050461117178201675 0.050461117178201675
rl training, epoch2, iter0, batch43/1133, batch loss:0.050461117178201675, Training time:45480.50006723404
batch reward last col mean 0.03065531887114048 first col mean 0.02090277522802353 all mean 0.026008745655417442
0.056659262627363205 0.056659262627363205
rl training, epoch2, iter0, batch44/1133, batch loss:0.056659262627363205, Training time:45483.583053827286
batch reward last col mean 0.0015754244523122907 first col mean 0.010023152455687523 all mean 0.004526942502707243
0.027242623269557953 0.027242623269557953
rl training, epoch2, iter0, batch45/1133, batch loss:0.027242623269557953, Training time:45487.56588792801
batch reward last col mean 0.03065885417163372 first col mean 0.012382246553897858 all mean 0.023439917713403702
0.07053299248218536 0.07053299248218536
rl training, epoch2, iter0, batch46/1133, batch loss:0.07053299248218536, Training time:45492.218579530716
batch reward last col mean 0.03348960727453232 first col mean 0.03581847995519638 all mean 0.03262766823172569
0.044606827199459076 0.04460682347416878
rl training, epoch2, iter0, batch47/1133, batch loss:0.04460682347416878, Training time:45496.17711830139
batch reward last col mean 0.02371734008193016 first col mean 0.04622665047645569 all mean 0.02661195397377014
0.056553009897470474 0.056553009897470474
rl training, epoch2, iter0, batch48/1133, batch loss:0.056553009897470474, Training time:45500.468640089035
batch reward last col mean 0.025067605078220367 first col mean 0.011649545282125473 all mean 0.02496989257633686
0.04924356937408447 0.049243565648794174
rl training, epoch2, iter0, batch49/1133, batch loss:0.049243565648794174, Training time:45508.68193888664
batch reward last col mean 0.033542536199092865 first col mean 0.03495265543460846 all mean 0.03388009965419769
0.044681746512651443 0.044681746512651443
rl training, epoch2, iter0, batch50/1133, batch loss:0.044681746512651443, Training time:45512.39518237114
batch reward last col mean 0.05155743658542633 first col mean 0.0457957461476326 all mean 0.05215728282928467
0.11762238293886185 0.11762238293886185
rl training, epoch2, iter0, batch51/1133, batch loss:0.11762238293886185, Training time:45515.747628450394
batch reward last col mean 0.04789610207080841 first col mean 0.030369045212864876 all mean 0.045367784798145294
0.11519437283277512 0.11519437283277512
rl training, epoch2, iter0, batch52/1133, batch loss:0.11519437283277512, Training time:45523.51431298256
batch reward last col mean 0.06147968769073486 first col mean 0.05115167051553726 all mean 0.06156306341290474
0.09546070545911789 0.0954606905579567
rl training, epoch2, iter0, batch53/1133, batch loss:0.0954606905579567, Training time:45533.89826011658
batch reward last col mean 0.09022589772939682 first col mean 0.09856928139925003 all mean 0.09252528846263885
0.16385842859745026 0.16385842859745026
rl training, epoch2, iter0, batch54/1133, batch loss:0.16385842859745026, Training time:45554.16714477539
batch reward last col mean 0.10947508364915848 first col mean 0.11258070915937424 all mean 0.11048432439565659
0.2203945368528366 0.2203945368528366
rl training, epoch2, iter0, batch55/1133, batch loss:0.2203945368528366, Training time:45581.04386615753
batch reward last col mean 0.1639018952846527 first col mean 0.13157543540000916 all mean 0.16460414230823517
0.3752424120903015 0.3752424120903015
rl training, epoch2, iter0, batch56/1133, batch loss:0.3752424120903015, Training time:45607.93592762947
batch reward last col mean 0.24170330166816711 first col mean 0.2689545154571533 all mean 0.25669315457344055
0.4266453683376312 0.4266453981399536
rl training, epoch2, iter0, batch57/1133, batch loss:0.4266453981399536, Training time:45635.07516479492
batch reward last col mean 0.36845076084136963 first col mean 0.44586580991744995 all mean 0.40051698684692383
0.44714412093162537 0.44714412093162537
rl training, epoch2, iter0, batch58/1133, batch loss:0.44714412093162537, Training time:45663.29042315483
batch reward last col mean 0.43667060136795044 first col mean 0.4812101721763611 all mean 0.481533944606781
0.44858238101005554 0.44858238101005554
rl training, epoch2, iter0, batch59/1133, batch loss:0.44858238101005554, Training time:45691.60756421089
batch reward last col mean 0.5792719125747681 first col mean 0.6213412284851074 all mean 0.6053014397621155
0.45583727955818176 0.45583727955818176
rl training, epoch2, iter0, batch60/1133, batch loss:0.45583727955818176, Training time:45719.87748670578
batch reward last col mean 0.640180766582489 first col mean 0.6416869759559631 all mean 0.652729868888855
0.4137882888317108 0.4137882888317108
rl training, epoch2, iter0, batch61/1133, batch loss:0.4137882888317108, Training time:45748.04034805298
batch reward last col mean 0.6780182719230652 first col mean 0.7047611474990845 all mean 0.7129874229431152
0.36602839827537537 0.36602839827537537
rl training, epoch2, iter0, batch62/1133, batch loss:0.36602839827537537, Training time:45776.530319690704
batch reward last col mean 0.6830154657363892 first col mean 0.6985546350479126 all mean 0.6963750720024109
0.3079703748226166 0.3079703748226166
rl training, epoch2, iter0, batch63/1133, batch loss:0.3079703748226166, Training time:45804.78005814552
batch reward last col mean 0.6189677715301514 first col mean 0.6459659337997437 all mean 0.6464773416519165
0.21953974664211273 0.21953974664211273
rl training, epoch2, iter0, batch64/1133, batch loss:0.21953974664211273, Training time:45833.10650086403
batch reward last col mean 0.6782105565071106 first col mean 0.6690704822540283 all mean 0.677427351474762
0.1875878870487213 0.1875879168510437
rl training, epoch2, iter0, batch65/1133, batch loss:0.1875879168510437, Training time:45861.544845342636
batch reward last col mean 0.6958616971969604 first col mean 0.7402710914611816 all mean 0.704281747341156
0.15645453333854675 0.15645453333854675
rl training, epoch2, iter0, batch66/1133, batch loss:0.15645453333854675, Training time:45889.800476789474
batch reward last col mean 0.7199732661247253 first col mean 0.7079426050186157 all mean 0.7046283483505249
0.18446968495845795 0.18446968495845795
rl training, epoch2, iter0, batch67/1133, batch loss:0.18446968495845795, Training time:45917.959934949875
batch reward last col mean 0.715935468673706 first col mean 0.7169964909553528 all mean 0.6988086700439453
0.23392125964164734 0.23392125964164734
rl training, epoch2, iter0, batch68/1133, batch loss:0.23392125964164734, Training time:45946.245921850204
batch reward last col mean 0.8779810667037964 first col mean 0.8362326622009277 all mean 0.8471779823303223
0.3350352942943573 0.3350353538990021
rl training, epoch2, iter0, batch69/1133, batch loss:0.3350353538990021, Training time:45974.54203391075
batch reward last col mean 0.7718849182128906 first col mean 0.8083487153053284 all mean 0.809122622013092
0.3443162739276886 0.3443162739276886
rl training, epoch2, iter0, batch70/1133, batch loss:0.3443162739276886, Training time:46002.72807741165
batch reward last col mean 0.8530766367912292 first col mean 0.8437746167182922 all mean 0.8481727838516235
0.3929193615913391 0.3929193317890167
rl training, epoch2, iter0, batch71/1133, batch loss:0.3929193317890167, Training time:46031.148213624954
batch reward last col mean 0.8747397661209106 first col mean 0.8530557155609131 all mean 0.867926836013794
0.40659770369529724 0.40659770369529724
rl training, epoch2, iter0, batch72/1133, batch loss:0.40659770369529724, Training time:46059.388892650604
batch reward last col mean 0.8691613078117371 first col mean 0.8787170648574829 all mean 0.8626754283905029
0.4179059565067291 0.4179059565067291
rl training, epoch2, iter0, batch73/1133, batch loss:0.4179059565067291, Training time:46087.5000474453
batch reward last col mean 0.9315177798271179 first col mean 0.8951540589332581 all mean 0.9296093583106995
0.4259219169616699 0.42592188715934753
rl training, epoch2, iter0, batch74/1133, batch loss:0.42592188715934753, Training time:46115.679951667786
batch reward last col mean 0.9354124665260315 first col mean 0.9439499378204346 all mean 0.943260669708252
0.42581233382225037 0.42581233382225037
rl training, epoch2, iter0, batch75/1133, batch loss:0.42581233382225037, Training time:46143.98628902435
batch reward last col mean 0.9557785987854004 first col mean 0.9686397910118103 all mean 0.9569488167762756
0.4152337908744812 0.4152337908744812
rl training, epoch2, iter0, batch76/1133, batch loss:0.4152337908744812, Training time:46172.432807445526
RL early break
rl training, epoch 2, iter 0, loss:0.11362436326529056, Training time:46172.43701148033 
rl epoch 2, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.26204021803094346 Time: 184.6670105457306 s
cur_epoch: 1
D Training Loss: 0.2322426277417476 Time: 186.64257168769836 s
cur_epoch: 2
D Training Loss: 0.23193152692737773 Time: 184.73313426971436 s
cur_epoch: 3
D Training Loss: 0.23335150181458045 Time: 187.55787873268127 s
cur_epoch: 4
D Training Loss: 0.2275798773657718 Time: 186.2910327911377 s
rl epoch 3, begin RL for generator...
batch reward last col mean 8.405923179743979e-11 first col mean 3.2536261879156925e-11 all mean 6.839791694801534e-06
2.719507392612286e-05 2.7195070288144052e-05
rl training, epoch3, iter0, batch0/1133, batch loss:2.7195070288144052e-05, Training time:47130.561104774475
batch reward last col mean 1.636154753348329e-11 first col mean 4.900936323437577e-10 all mean 1.0430941527195259e-10
4.4006808613827886e-11 4.400681902216874e-11
rl training, epoch3, iter0, batch1/1133, batch loss:4.400681902216874e-11, Training time:47158.76953458786
batch reward last col mean 2.043902685988641e-10 first col mean 6.63157515012891e-11 all mean 2.8149695936008357e-05
3.16476944135502e-05 3.16476944135502e-05
rl training, epoch3, iter0, batch2/1133, batch loss:3.16476944135502e-05, Training time:47186.847121953964
batch reward last col mean 2.2038910627020236e-11 first col mean 1.8905080625963855e-11 all mean 4.2224373997257203e-10
2.150567224301625e-10 2.1505676406352592e-10
rl training, epoch3, iter0, batch3/1133, batch loss:2.1505676406352592e-10, Training time:47215.0407371521
batch reward last col mean 1.950435993269828e-11 first col mean 1.4743379850301608e-09 all mean 2.7103379540704964e-09
9.595239047754944e-10 9.59523793753192e-10
rl training, epoch3, iter0, batch4/1133, batch loss:9.59523793753192e-10, Training time:47243.21604537964
batch reward last col mean 3.2478329053953203e-11 first col mean 1.2851545348746551e-11 all mean 6.393681140082208e-10
5.024198279635073e-10 5.024200500081122e-10
rl training, epoch3, iter0, batch5/1133, batch loss:5.024200500081122e-10, Training time:47271.33769321442
batch reward last col mean 0.0012811875203624368 first col mean 1.1276896429990302e-06 all mean 0.0012553164269775152
6.44911197014153e-05 6.44911197014153e-05
rl training, epoch3, iter0, batch6/1133, batch loss:6.44911197014153e-05, Training time:47299.58871459961
batch reward last col mean 4.92151458475476e-13 first col mean 4.06711220257705e-10 all mean 1.789164889487438e-05
6.968582601984963e-05 6.968583329580724e-05
rl training, epoch3, iter0, batch7/1133, batch loss:6.968583329580724e-05, Training time:47328.031105041504
batch reward last col mean 3.0348004664837447e-10 first col mean 4.259118405181006e-11 all mean 8.885426616700443e-09
1.142411054644299e-09 1.1424143853133728e-09
rl training, epoch3, iter0, batch8/1133, batch loss:1.1424143853133728e-09, Training time:47356.0266160965
batch reward last col mean 3.6807668024607665e-10 first col mean 4.964110233984798e-10 all mean 3.32513988565708e-10
1.790717713001655e-10 1.7907172966680207e-10
rl training, epoch3, iter0, batch9/1133, batch loss:1.7907172966680207e-10, Training time:47384.278748989105
batch reward last col mean 5.7820775944961156e-11 first col mean 5.8419438175860705e-08 all mean 7.971320825639339e-10
1.9594446898363316e-10 1.9594464939487466e-10
rl training, epoch3, iter0, batch10/1133, batch loss:1.9594464939487466e-10, Training time:47412.50679039955
batch reward last col mean 1.2261325288420721e-10 first col mean 1.180422010138571e-10 all mean 1.9156907171691273e-07
5.096935651316414e-10 5.095630029039455e-10
rl training, epoch3, iter0, batch11/1133, batch loss:5.095630029039455e-10, Training time:47440.573162555695
batch reward last col mean 8.793398301176758e-12 first col mean 2.6809144401340745e-05 all mean 2.7114836598229886e-07
5.613663311976325e-09 5.6137761106356265e-09
rl training, epoch3, iter0, batch12/1133, batch loss:5.6137761106356265e-09, Training time:47468.992886304855
batch reward last col mean 5.774286049309296e-10 first col mean 1.2361593970666718e-09 all mean 3.9779246563398374e-10
1.0408078565671275e-10 1.0408081341228836e-10
rl training, epoch3, iter0, batch13/1133, batch loss:1.0408081341228836e-10, Training time:47497.07398366928
batch reward last col mean 1.0431653318931922e-09 first col mean 3.258257441629553e-09 all mean 1.4062911724010974e-08
9.326322825131683e-09 9.326322825131683e-09
rl training, epoch3, iter0, batch14/1133, batch loss:9.326322825131683e-09, Training time:47525.19868183136
batch reward last col mean 1.5593044910833243e-10 first col mean 1.1312173420208183e-11 all mean 1.9791766003862676e-09
4.523221797114729e-09 4.5232213530255194e-09
rl training, epoch3, iter0, batch15/1133, batch loss:4.5232213530255194e-09, Training time:47553.295191049576
batch reward last col mean 1.058989229640872e-09 first col mean 3.385190391891335e-11 all mean 1.9296678033242642e-08
6.4900933516298664e-09 6.490092019362237e-09
rl training, epoch3, iter0, batch16/1133, batch loss:6.490092019362237e-09, Training time:47581.332362651825
batch reward last col mean 3.328644859745822e-10 first col mean 5.46458781003345e-11 all mean 7.916342497082951e-07
5.309020334465231e-09 5.3092970020429675e-09
rl training, epoch3, iter0, batch17/1133, batch loss:5.3092970020429675e-09, Training time:47609.41394472122
batch reward last col mean 4.529444180834119e-11 first col mean 7.126766288223507e-09 all mean 4.765311132359784e-07
1.4742857956662192e-07 1.4742852272320306e-07
rl training, epoch3, iter0, batch18/1133, batch loss:1.4742852272320306e-07, Training time:47637.59327507019
batch reward last col mean 5.933235153188221e-11 first col mean 3.492654498948866e-10 all mean 7.487938802341887e-08
3.279593485672194e-08 3.2795959725717694e-08
rl training, epoch3, iter0, batch19/1133, batch loss:3.2795959725717694e-08, Training time:47665.642547130585
batch reward last col mean 6.007616626391155e-11 first col mean 1.2946473060271302e-10 all mean 5.40323785713781e-09
5.823921345182725e-10 5.823930782078435e-10
rl training, epoch3, iter0, batch20/1133, batch loss:5.823930782078435e-10, Training time:47693.63184642792
batch reward last col mean 2.1004114003631003e-09 first col mean 5.963445293133418e-09 all mean 5.058679697356183e-09
8.327881162450979e-10 8.327901146465422e-10
rl training, epoch3, iter0, batch21/1133, batch loss:8.327901146465422e-10, Training time:47721.64160847664
batch reward last col mean 5.384366841276744e-10 first col mean 9.634840703043324e-10 all mean 4.061248404241269e-08
7.345260399915787e-08 7.345259689373052e-08
rl training, epoch3, iter0, batch22/1133, batch loss:7.345259689373052e-08, Training time:47749.82731795311
batch reward last col mean 1.5476461778796136e-10 first col mean 1.0391394411612964e-09 all mean 6.207260927482139e-09
3.944785831322406e-09 3.9447871635900356e-09
rl training, epoch3, iter0, batch23/1133, batch loss:3.9447871635900356e-09, Training time:47778.16207718849
batch reward last col mean 1.4475780290013063e-06 first col mean 2.1057817989333927e-10 all mean 1.2212068440931034e-06
1.586234645856166e-07 1.586234645856166e-07
rl training, epoch3, iter0, batch24/1133, batch loss:1.586234645856166e-07, Training time:47806.35475206375
batch reward last col mean 1.7271909596994206e-11 first col mean 4.6037529344289396e-10 all mean 6.859958712190917e-10
3.9815725716429995e-10 3.981573126754512e-10
rl training, epoch3, iter0, batch25/1133, batch loss:3.981573126754512e-10, Training time:47834.41634225845
batch reward last col mean 1.5608982856241127e-11 first col mean 2.6566299160535323e-10 all mean 2.4675865795131813e-09
1.4027778938441315e-09 1.4027778938441315e-09
rl training, epoch3, iter0, batch26/1133, batch loss:1.4027778938441315e-09, Training time:47862.6578938961
batch reward last col mean 7.514525807161831e-11 first col mean 2.4915031815453403e-08 all mean 2.322792180819988e-09
1.9350297753017998e-10 1.9350235302972862e-10
rl training, epoch3, iter0, batch27/1133, batch loss:1.9350235302972862e-10, Training time:47890.86354017258
batch reward last col mean 2.6264274088916295e-10 first col mean 2.094505402450153e-10 all mean 9.774302478504637e-10
3.3508595898013027e-10 3.350858479578278e-10
rl training, epoch3, iter0, batch28/1133, batch loss:3.350858479578278e-10, Training time:47918.86680173874
batch reward last col mean 4.484138393934245e-09 first col mean 4.573934564433557e-09 all mean 1.5893303498160094e-05
5.163488458492793e-05 5.163487367099151e-05
rl training, epoch3, iter0, batch29/1133, batch loss:5.163487367099151e-05, Training time:47946.93151855469
batch reward last col mean 1.1934242927225114e-08 first col mean 2.323036554785496e-11 all mean 1.0289994861523155e-05
3.03193239403754e-08 3.031381368145958e-08
rl training, epoch3, iter0, batch30/1133, batch loss:3.031381368145958e-08, Training time:47974.93707203865
batch reward last col mean 4.1819088636430024e-08 first col mean 1.1452412351786734e-08 all mean 8.60731663721026e-09
4.432391342845676e-09 4.432391786934886e-09
rl training, epoch3, iter0, batch31/1133, batch loss:4.432391786934886e-09, Training time:48003.2412879467
batch reward last col mean 1.4743893606006253e-10 first col mean 5.906364841656853e-10 all mean 1.2037165042499964e-08
4.605989811778954e-09 4.605991144046584e-09
rl training, epoch3, iter0, batch32/1133, batch loss:4.605991144046584e-09, Training time:48031.481185913086
batch reward last col mean 6.56375301333334e-11 first col mean 1.7305859523197853e-10 all mean 3.729498931903663e-09
4.245051421492008e-09 4.245051421492008e-09
rl training, epoch3, iter0, batch33/1133, batch loss:4.245051421492008e-09, Training time:48059.71824622154
batch reward last col mean 6.872212521269461e-11 first col mean 1.926541565167028e-10 all mean 7.517627409470151e-09
2.3153641504070066e-10 2.3153559625122e-10
rl training, epoch3, iter0, batch34/1133, batch loss:2.3153559625122e-10, Training time:48087.850890398026
batch reward last col mean 8.534816603456008e-11 first col mean 4.2543044642684436e-09 all mean 1.1210938843930762e-09
3.563934425354631e-10 3.563934425354631e-10
rl training, epoch3, iter0, batch35/1133, batch loss:3.563934425354631e-10, Training time:48115.968213796616
batch reward last col mean 1.9486961377879197e-08 first col mean 4.4358416939616063e-10 all mean 1.5576736345224163e-08
5.3566981961239435e-09 5.356697752034734e-09
rl training, epoch3, iter0, batch36/1133, batch loss:5.356697752034734e-09, Training time:48144.055008888245
batch reward last col mean 1.1418010981145699e-09 first col mean 4.391869923292546e-10 all mean 4.4472114879567926e-10
3.1088220886488216e-10 3.1088220886488216e-10
rl training, epoch3, iter0, batch37/1133, batch loss:3.1088220886488216e-10, Training time:48172.143007040024
batch reward last col mean 1.8293055958906734e-10 first col mean 1.078531014497841e-10 all mean 7.900895049317569e-09
2.0356141217092727e-09 2.035612789441643e-09
rl training, epoch3, iter0, batch38/1133, batch loss:2.035612789441643e-09, Training time:48200.37549495697
batch reward last col mean 4.038761269864466e-10 first col mean 6.314658573813858e-09 all mean 4.065589642721079e-09
8.040540455667156e-10 8.040540455667156e-10
rl training, epoch3, iter0, batch39/1133, batch loss:8.040540455667156e-10, Training time:48228.44394373894
batch reward last col mean 6.902130950114937e-11 first col mean 3.6339308451260877e-08 all mean 1.4750204391233979e-09
2.447842761821306e-10 2.44784248426555e-10
rl training, epoch3, iter0, batch40/1133, batch loss:2.44784248426555e-10, Training time:48256.76891422272
batch reward last col mean 1.553256967490313e-10 first col mean 1.6114068968064998e-09 all mean 4.740595471730558e-09
1.266507232422498e-09 1.2665066773109857e-09
rl training, epoch3, iter0, batch41/1133, batch loss:1.2665066773109857e-09, Training time:48284.9033331871
batch reward last col mean 1.1468375554768429e-10 first col mean 7.750308034237818e-11 all mean 2.0842112757879505e-10
1.3789284991627682e-10 1.378928082829134e-10
rl training, epoch3, iter0, batch42/1133, batch loss:1.378928082829134e-10, Training time:48312.95806860924
batch reward last col mean 3.256847222465886e-11 first col mean 1.082924083739556e-09 all mean 6.347384284843827e-10
2.093780981926585e-10 2.0937818145938536e-10
rl training, epoch3, iter0, batch43/1133, batch loss:2.0937818145938536e-10, Training time:48341.34252738953
batch reward last col mean 2.3885084882158125e-11 first col mean 8.172078196366783e-06 all mean 8.587672084559017e-08
1.3391934317041887e-07 1.3391935738127358e-07
rl training, epoch3, iter0, batch44/1133, batch loss:1.3391935738127358e-07, Training time:48369.63912510872
batch reward last col mean 1.1081573159099634e-11 first col mean 7.189820960817883e-10 all mean 4.975055034606157e-09
1.0745027090308668e-10 1.0744830719611187e-10
rl training, epoch3, iter0, batch45/1133, batch loss:1.0744830719611187e-10, Training time:48397.683973789215
batch reward last col mean 3.0247821608542225e-11 first col mean 0.0011360843200236559 all mean 1.1480657121865079e-05
9.77762582010655e-08 9.778035092722348e-08
rl training, epoch3, iter0, batch46/1133, batch loss:9.778035092722348e-08, Training time:48425.769357681274
batch reward last col mean 1.3486778360771723e-10 first col mean 4.708287093535546e-10 all mean 9.565114256204765e-10
9.532885592022922e-11 9.532905714815243e-11
rl training, epoch3, iter0, batch47/1133, batch loss:9.532905714815243e-11, Training time:48453.839962244034
batch reward last col mean 8.135457862934459e-10 first col mean 3.1571710523703445e-11 all mean 1.6645528289060962e-09
6.713097300270476e-10 6.713092304266866e-10
rl training, epoch3, iter0, batch48/1133, batch loss:6.713092304266866e-10, Training time:48482.1413192749
batch reward last col mean 1.278861912201723e-11 first col mean 2.447207103628557e-09 all mean 2.186547831684038e-08
2.13746442767615e-09 2.1374626513193107e-09
rl training, epoch3, iter0, batch49/1133, batch loss:2.1374626513193107e-09, Training time:48510.160646915436
batch reward last col mean 2.005261408311032e-12 first col mean 4.787790164328953e-09 all mean 1.342520983271811e-09
3.905983314567152e-10 3.9059824818998834e-10
rl training, epoch3, iter0, batch50/1133, batch loss:3.9059824818998834e-10, Training time:48538.113996982574
batch reward last col mean 3.0674535134167513e-10 first col mean 1.3470938808879396e-09 all mean 1.0985935494645105e-09
7.080223629607474e-10 7.080222519384449e-10
rl training, epoch3, iter0, batch51/1133, batch loss:7.080222519384449e-10, Training time:48566.25915503502
batch reward last col mean 3.0222174762783993e-10 first col mean 3.931862335715408e-10 all mean 4.9583586125834245e-09
1.4185970176328055e-09 1.4185979058112252e-09
rl training, epoch3, iter0, batch52/1133, batch loss:1.4185979058112252e-09, Training time:48594.21059799194
batch reward last col mean 4.674189854614319e-11 first col mean 5.57899504372017e-10 all mean 2.3189089537467567e-10
5.94699567368906e-11 5.947000530914792e-11
rl training, epoch3, iter0, batch53/1133, batch loss:5.947000530914792e-11, Training time:48622.17948961258
batch reward last col mean 5.209472853096031e-10 first col mean 1.550337858091666e-09 all mean 1.0093967439672724e-08
3.6768599276371106e-09 3.6768605937709253e-09
rl training, epoch3, iter0, batch54/1133, batch loss:3.6768605937709253e-09, Training time:48650.30566692352
batch reward last col mean 1.3802969878184967e-10 first col mean 1.143508288059536e-09 all mean 4.318204460673769e-09
2.028421652866541e-09 2.028422096955751e-09
rl training, epoch3, iter0, batch55/1133, batch loss:2.028422096955751e-09, Training time:48678.39512705803
batch reward last col mean 1.4842844731077776e-09 first col mean 8.501488402146151e-10 all mean 9.59408197331868e-09
7.302174420686924e-09 7.302174420686924e-09
rl training, epoch3, iter0, batch56/1133, batch loss:7.302174420686924e-09, Training time:48706.43358659744
batch reward last col mean 1.4220292721134342e-09 first col mean 3.3230107554516053e-09 all mean 1.5227508143311752e-09
5.336809882905413e-10 5.336810438016926e-10
rl training, epoch3, iter0, batch57/1133, batch loss:5.336810438016926e-10, Training time:48734.421822309494
batch reward last col mean 3.3793445819441104e-10 first col mean 2.907833973608831e-09 all mean 2.7485607123622913e-09
4.4648476582587193e-10 4.4648554298198917e-10
rl training, epoch3, iter0, batch58/1133, batch loss:4.4648554298198917e-10, Training time:48762.51478767395
batch reward last col mean 1.5957570820290812e-09 first col mean 2.460411041571575e-10 all mean 9.927749289317944e-09
6.467842705859539e-09 6.467843594037959e-09
rl training, epoch3, iter0, batch59/1133, batch loss:6.467843594037959e-09, Training time:48790.575404405594
batch reward last col mean 1.3624847777782279e-11 first col mean 4.6320779802044854e-05 all mean 4.723445954368799e-07
1.1568851050469675e-06 1.1568851050469675e-06
rl training, epoch3, iter0, batch60/1133, batch loss:1.1568851050469675e-06, Training time:48818.60683083534
batch reward last col mean 2.7706814620387377e-10 first col mean 9.057634503539802e-11 all mean 9.187624883111312e-09
3.60301621871173e-10 3.6029554340011316e-10
rl training, epoch3, iter0, batch61/1133, batch loss:3.6029554340011316e-10, Training time:48846.920170784
batch reward last col mean 4.028528621802252e-10 first col mean 2.5285018523391045e-10 all mean 2.1045684661658015e-06
3.642783497070923e-07 3.6427934446692234e-07
rl training, epoch3, iter0, batch62/1133, batch loss:3.6427934446692234e-07, Training time:48874.919869184494
batch reward last col mean 1.1942277722276629e-10 first col mean 1.8011231617265366e-08 all mean 3.921140745433149e-09
9.881347962092946e-10 9.881347962092946e-10
rl training, epoch3, iter0, batch63/1133, batch loss:9.881347962092946e-10, Training time:48902.903847932816
batch reward last col mean 1.3300840984165063e-10 first col mean 4.741157466625623e-10 all mean 7.080040553830713e-09
1.0598715655119051e-10 1.0598674021755627e-10
rl training, epoch3, iter0, batch64/1133, batch loss:1.0598674021755627e-10, Training time:48930.89812850952
batch reward last col mean 1.9283850904994182e-10 first col mean 2.129326048816438e-09 all mean 1.1039981373528462e-08
1.9948815932480102e-08 1.9948815932480102e-08
rl training, epoch3, iter0, batch65/1133, batch loss:1.9948815932480102e-08, Training time:48958.97913789749
batch reward last col mean 1.8610255697604217e-11 first col mean 3.006560556073623e-09 all mean 5.40504441204348e-09
7.522595879549954e-10 7.522589218211806e-10
rl training, epoch3, iter0, batch66/1133, batch loss:7.522589218211806e-10, Training time:48986.97095108032
batch reward last col mean 1.2483862034395887e-11 first col mean 3.591246411360771e-08 all mean 7.785979860841508e-09
3.2560423246508208e-09 3.256041880561611e-09
rl training, epoch3, iter0, batch67/1133, batch loss:3.256041880561611e-09, Training time:49015.033458948135
batch reward last col mean 5.465545377392189e-11 first col mean 1.0858534071900294e-09 all mean 5.199661146093604e-08
2.4366060280556212e-09 2.4366109130369296e-09
rl training, epoch3, iter0, batch68/1133, batch loss:2.4366109130369296e-09, Training time:49043.52327179909
batch reward last col mean 3.7943753694591464e-10 first col mean 7.591817452468064e-11 all mean 3.4854246155902047e-09
7.225942066924063e-10 7.225938181143476e-10
rl training, epoch3, iter0, batch69/1133, batch loss:7.225938181143476e-10, Training time:49071.54613351822
batch reward last col mean 3.081663535464685e-10 first col mean 4.682486842710887e-09 all mean 8.332388112819444e-10
7.387466333108605e-11 7.387463557551044e-11
rl training, epoch3, iter0, batch70/1133, batch loss:7.387463557551044e-11, Training time:49099.70196056366
batch reward last col mean 4.9504140370304484e-11 first col mean 5.687684698219009e-11 all mean 2.2898710483332252e-08
9.190835648098528e-09 9.190833871741688e-09
rl training, epoch3, iter0, batch71/1133, batch loss:9.190833871741688e-09, Training time:49127.76986241341
batch reward last col mean 6.286794973497933e-10 first col mean 3.033520309947413e-11 all mean 1.8789688027709417e-08
5.950867354442835e-09 5.950867354442835e-09
rl training, epoch3, iter0, batch72/1133, batch loss:5.950867354442835e-09, Training time:49155.94798707962
batch reward last col mean 9.92506521413361e-10 first col mean 7.427569115314725e-10 all mean 7.760416198543396e-10
1.7240114891237113e-10 1.7240124605688578e-10
rl training, epoch3, iter0, batch73/1133, batch loss:1.7240124605688578e-10, Training time:49183.91394495964
batch reward last col mean 8.023487794162065e-07 first col mean 8.032247644784718e-10 all mean 2.746127734098991e-07
8.842386733931562e-08 8.842386733931562e-08
rl training, epoch3, iter0, batch74/1133, batch loss:8.842386733931562e-08, Training time:49211.87831950188
batch reward last col mean 2.876159612696938e-07 first col mean 2.0362022041808814e-06 all mean 1.2319644611125113e-06
7.709976443948108e-07 7.709971896474599e-07
rl training, epoch3, iter0, batch75/1133, batch loss:7.709971896474599e-07, Training time:49240.08726096153
batch reward last col mean 1.0856631565969721e-11 first col mean 1.3966174883250915e-09 all mean 7.593563999819253e-09
1.826208695376863e-08 1.826208873012547e-08
rl training, epoch3, iter0, batch76/1133, batch loss:1.826208873012547e-08, Training time:49268.35966157913
batch reward last col mean 8.60571969241164e-09 first col mean 3.0550864948963863e-07 all mean 8.886212299330509e-08
2.953297606467231e-09 2.9533135936787858e-09
rl training, epoch3, iter0, batch77/1133, batch loss:2.9533135936787858e-09, Training time:49296.37783408165
batch reward last col mean 9.369083286969726e-11 first col mean 3.174861262777995e-08 all mean 1.4056320551958379e-09
2.820899347444339e-10 2.820899625000095e-10
rl training, epoch3, iter0, batch78/1133, batch loss:2.820899625000095e-10, Training time:49324.437267780304
batch reward last col mean 1.1229674135027068e-10 first col mean 6.503313443317893e-10 all mean 3.978739115950702e-09
3.3671976318316865e-09 3.3671971877424767e-09
rl training, epoch3, iter0, batch79/1133, batch loss:3.3671971877424767e-09, Training time:49352.45064377785
batch reward last col mean 3.5574615475653104e-10 first col mean 4.935451158871729e-09 all mean 1.084243583804323e-09
2.982921409877548e-10 2.982921132321792e-10
rl training, epoch3, iter0, batch80/1133, batch loss:2.982921132321792e-10, Training time:49380.489725112915
batch reward last col mean 3.037780790804412e-11 first col mean 3.635520773315193e-09 all mean 1.9036482612477812e-08
6.114970751980309e-10 6.11486306034692e-10
rl training, epoch3, iter0, batch81/1133, batch loss:6.11486306034692e-10, Training time:49408.63708233833
batch reward last col mean 5.858695473204278e-11 first col mean 1.335377364242163e-10 all mean 5.4971276419735204e-09
5.213619047594875e-08 5.213619047594875e-08
rl training, epoch3, iter0, batch82/1133, batch loss:5.213619047594875e-08, Training time:49436.532453775406
batch reward last col mean 3.406560103447198e-11 first col mean 0.0005105509189888835 all mean 5.157323812454706e-06
2.19243844412631e-07 2.192435601955367e-07
rl training, epoch3, iter0, batch83/1133, batch loss:2.192435601955367e-07, Training time:49464.4763777256
batch reward last col mean 4.3602801924613743e-11 first col mean 2.1553805962248873e-10 all mean 3.1367325403763857e-10
1.0017826845842848e-10 1.0017817131391382e-10
rl training, epoch3, iter0, batch84/1133, batch loss:1.0017817131391382e-10, Training time:49492.5246090889
batch reward last col mean 1.4779320822722042e-10 first col mean 2.1322419385683133e-09 all mean 5.858396434632596e-09
1.860286258370536e-09 1.8602872575712581e-09
rl training, epoch3, iter0, batch85/1133, batch loss:1.8602872575712581e-09, Training time:49520.625139951706
batch reward last col mean 8.14894957068546e-11 first col mean 3.850448571096621e-10 all mean 5.061719043908397e-09
2.342757765561032e-09 2.3427564332934026e-09
rl training, epoch3, iter0, batch86/1133, batch loss:2.3427564332934026e-09, Training time:49548.77731466293
batch reward last col mean 8.083268776548636e-11 first col mean 1.183238285129562e-09 all mean 1.2433037227310706e-05
3.160459982609609e-06 3.160456344630802e-06
rl training, epoch3, iter0, batch87/1133, batch loss:3.160456344630802e-06, Training time:49576.82340335846
batch reward last col mean 2.653004552155558e-11 first col mean 2.718180402982995e-10 all mean 1.7070846070055268e-08
2.7998028340192604e-09 2.799798837216372e-09
rl training, epoch3, iter0, batch88/1133, batch loss:2.799798837216372e-09, Training time:49604.91797852516
batch reward last col mean 4.206281156715619e-11 first col mean 6.911964750555555e-11 all mean 7.7865340841754e-09
9.50588052717194e-10 9.50590717252453e-10
rl training, epoch3, iter0, batch89/1133, batch loss:9.50590717252453e-10, Training time:49632.93799805641
batch reward last col mean 1.420022988085634e-10 first col mean 9.769644648827125e-09 all mean 3.051273012033562e-08
2.9711033633361694e-10 2.971204116075654e-10
rl training, epoch3, iter0, batch90/1133, batch loss:2.971204116075654e-10, Training time:49661.20080494881
batch reward last col mean 1.6089973103872168e-11 first col mean 1.3304946033798615e-10 all mean 2.1285875839716084e-10
4.959969934770214e-11 4.959966465323262e-11
rl training, epoch3, iter0, batch91/1133, batch loss:4.959966465323262e-11, Training time:49689.356773138046
batch reward last col mean 4.823676458265425e-10 first col mean 1.546356098724999e-10 all mean 1.1681606792990351e-09
2.9225710740377053e-10 2.9225716291492176e-10
rl training, epoch3, iter0, batch92/1133, batch loss:2.9225716291492176e-10, Training time:49717.42107605934
batch reward last col mean 1.0800015395884266e-11 first col mean 6.316316913945741e-11 all mean 3.5211145110736197e-10
1.1241019226559956e-10 1.1241019226559956e-10
rl training, epoch3, iter0, batch93/1133, batch loss:1.1241019226559956e-10, Training time:49745.620933532715
batch reward last col mean 1.9472214118909648e-10 first col mean 2.1139578976203666e-10 all mean 2.894992023882992e-09
4.4998702541931834e-09 4.4998698101039736e-09
rl training, epoch3, iter0, batch94/1133, batch loss:4.4998698101039736e-09, Training time:49773.6694111824
batch reward last col mean 2.755650568841972e-11 first col mean 2.5357467237085984e-09 all mean 4.118823060395016e-10
2.8497521009640536e-10 2.8497521009640536e-10
rl training, epoch3, iter0, batch95/1133, batch loss:2.8497521009640536e-10, Training time:49801.68237066269
batch reward last col mean 5.5928400799487576e-11 first col mean 2.231600504387643e-08 all mean 3.789691060962497e-10
3.4592256142884636e-11 3.459214165113522e-11
rl training, epoch3, iter0, batch96/1133, batch loss:3.459214165113522e-11, Training time:49830.12568426132
batch reward last col mean 1.123337187158846e-10 first col mean 7.671085988647519e-09 all mean 3.939214465731311e-08
8.702477849453771e-09 8.702468967669574e-09
rl training, epoch3, iter0, batch97/1133, batch loss:8.702468967669574e-09, Training time:49858.47426509857
batch reward last col mean 2.0370753694987087e-10 first col mean 2.617224437173604e-09 all mean 1.3977202728554516e-09
1.6071920183602373e-10 1.6071978470311166e-10
rl training, epoch3, iter0, batch98/1133, batch loss:1.6071978470311166e-10, Training time:49886.55788612366
batch reward last col mean 1.1624469442583774e-10 first col mean 1.8644097377062963e-09 all mean 1.484172003074491e-06
1.8555917691287505e-08 1.8556566061533886e-08
rl training, epoch3, iter0, batch99/1133, batch loss:1.8556566061533886e-08, Training time:49914.61109876633
batch reward last col mean 1.197201804359338e-08 first col mean 9.651356380757647e-10 all mean 5.579420037093996e-09
1.2303945640113056e-09 1.2303945640113056e-09
rl training, epoch3, iter0, batch100/1133, batch loss:1.2303945640113056e-09, Training time:49942.730674505234
batch reward last col mean 7.153959282607536e-12 first col mean 5.8089071899303235e-06 all mean 1.148761086255945e-07
2.9406845669655013e-07 2.9406845669655013e-07
rl training, epoch3, iter0, batch101/1133, batch loss:2.9406845669655013e-07, Training time:49970.85949230194
batch reward last col mean 2.649360592021921e-11 first col mean 9.826846003591072e-10 all mean 6.565737953323492e-10
2.545517963081778e-10 2.5455182406375343e-10
rl training, epoch3, iter0, batch102/1133, batch loss:2.5455182406375343e-10, Training time:49999.13371372223
batch reward last col mean 1.186411768827611e-08 first col mean 4.090569896697538e-11 all mean 3.5203329140642836e-09
1.1044197778531384e-09 1.1044203329646507e-09
rl training, epoch3, iter0, batch103/1133, batch loss:1.1044203329646507e-09, Training time:50027.229172468185
batch reward last col mean 3.4896705750769863e-12 first col mean 3.203195000911485e-11 all mean 3.615488464170369e-10
1.1188783927140733e-10 1.1188787396587685e-10
rl training, epoch3, iter0, batch104/1133, batch loss:1.1188787396587685e-10, Training time:50055.19709086418
batch reward last col mean 9.677821877218662e-10 first col mean 4.14795892078601e-10 all mean 1.5042212808680233e-08
2.2169238889091503e-08 2.2169237112734663e-08
rl training, epoch3, iter0, batch105/1133, batch loss:2.2169237112734663e-08, Training time:50083.397431612015
batch reward last col mean 0.0058708470314741135 first col mean 8.667488771152421e-08 all mean 0.005692944396287203
0.0003000714350491762 0.0003000714350491762
rl training, epoch3, iter0, batch106/1133, batch loss:0.0003000714350491762, Training time:50111.740411520004
batch reward last col mean 5.72781336249939e-11 first col mean 3.851585023140203e-11 all mean 3.747234522677445e-09
6.802206575784453e-10 6.802199914446305e-10
rl training, epoch3, iter0, batch107/1133, batch loss:6.802199914446305e-10, Training time:50139.85442352295
batch reward last col mean 3.366218137568211e-10 first col mean 1.4118653468564446e-10 all mean 2.6569448863256184e-09
6.479527470126811e-10 6.479519698565639e-10
rl training, epoch3, iter0, batch108/1133, batch loss:6.479519698565639e-10, Training time:50168.114304065704
batch reward last col mean 2.730960457775211e-10 first col mean 2.102287455230112e-09 all mean 2.03084073291393e-06
1.6377205147577456e-09 1.6362607935249684e-09
rl training, epoch3, iter0, batch109/1133, batch loss:1.6362607935249684e-09, Training time:50196.36443686485
batch reward last col mean 8.226478530559689e-05 first col mean 7.467946261385805e-09 all mean 8.060433901846409e-05
6.354969627864193e-06 6.354969627864193e-06
rl training, epoch3, iter0, batch110/1133, batch loss:6.354969627864193e-06, Training time:50224.556158065796
batch reward last col mean 5.046827539212373e-11 first col mean 3.953530003375505e-10 all mean 3.7771138994280307e-10
1.8324401718228245e-10 1.8324401718228245e-10
rl training, epoch3, iter0, batch111/1133, batch loss:1.8324401718228245e-10, Training time:50252.661162376404
batch reward last col mean 1.9848119675591747e-11 first col mean 3.093726316794054e-11 all mean 9.113546722838706e-11
9.988966598317717e-11 9.988965904428326e-11
rl training, epoch3, iter0, batch112/1133, batch loss:9.988965904428326e-11, Training time:50281.799065351486
batch reward last col mean 2.0240508921687272e-11 first col mean 1.3775805385307649e-08 all mean 4.970756584121716e-10
1.414558192802673e-10 1.4145577764690387e-10
rl training, epoch3, iter0, batch113/1133, batch loss:1.4145577764690387e-10, Training time:50309.94987654686
batch reward last col mean 1.70296399204517e-09 first col mean 1.174405295234493e-10 all mean 3.338604130931344e-07
9.363603226120176e-08 9.363598962863762e-08
rl training, epoch3, iter0, batch114/1133, batch loss:9.363598962863762e-08, Training time:50337.975397109985
batch reward last col mean 2.9720819555434375e-11 first col mean 9.197979045083571e-10 all mean 2.0973340397745233e-08
3.2115592407677696e-09 3.211567012328942e-09
rl training, epoch3, iter0, batch115/1133, batch loss:3.211567012328942e-09, Training time:50366.10146331787
batch reward last col mean 1.8226641029794877e-10 first col mean 3.749118704376997e-08 all mean 9.189367489170763e-09
3.0424800456785306e-09 3.0424804897677404e-09
rl training, epoch3, iter0, batch116/1133, batch loss:3.0424804897677404e-09, Training time:50394.222083091736
batch reward last col mean 3.004624327118677e-10 first col mean 8.930311196309049e-06 all mean 1.0765986502292435e-07
9.395299827019699e-08 9.395299827019699e-08
rl training, epoch3, iter0, batch117/1133, batch loss:9.395299827019699e-08, Training time:50422.353283405304
batch reward last col mean 1.3599319587109804e-11 first col mean 3.8593412909904146e-09 all mean 1.0073535339216733e-09
2.8532798346248e-10 2.8532790019575316e-10
rl training, epoch3, iter0, batch118/1133, batch loss:2.8532790019575316e-10, Training time:50450.6159696579
batch reward last col mean 3.666143499891916e-10 first col mean 3.3231298268709963e-10 all mean 3.637089240893232e-10
6.25282603472499e-11 6.252817014162915e-11
rl training, epoch3, iter0, batch119/1133, batch loss:6.252817014162915e-11, Training time:50478.64738750458
batch reward last col mean 1.8108378685433024e-10 first col mean 8.395025230534259e-10 all mean 2.953123745541575e-09
8.574244092507399e-10 8.574242427172862e-10
rl training, epoch3, iter0, batch120/1133, batch loss:8.574242427172862e-10, Training time:50506.86216711998
batch reward last col mean 8.993086136888095e-11 first col mean 1.7120743711629416e-10 all mean 2.7042155181788985e-09
3.529021519455e-10 3.529020964343488e-10
rl training, epoch3, iter0, batch121/1133, batch loss:3.529020964343488e-10, Training time:50534.94397902489
batch reward last col mean 1.0982314233368151e-12 first col mean 2.1217267942574836e-09 all mean 1.302176477757655e-09
1.7086156101076e-10 1.7086206061112108e-10
rl training, epoch3, iter0, batch122/1133, batch loss:1.7086206061112108e-10, Training time:50563.12930941582
batch reward last col mean 2.886688110770308e-11 first col mean 1.6976217653841275e-10 all mean 7.527528822492968e-09
2.2269848187761454e-09 2.2269848187761454e-09
rl training, epoch3, iter0, batch123/1133, batch loss:2.2269848187761454e-09, Training time:50591.50965452194
batch reward last col mean 9.837858826189372e-12 first col mean 7.402283230817375e-10 all mean 1.2041110331040272e-09
4.070676240530702e-09 4.070675796441492e-09
rl training, epoch3, iter0, batch124/1133, batch loss:4.070675796441492e-09, Training time:50620.54309153557
batch reward last col mean 2.4068147475020396e-09 first col mean 1.4202382325745333e-10 all mean 8.602062848694914e-07
2.79284279258718e-07 2.7928402346333314e-07
rl training, epoch3, iter0, batch125/1133, batch loss:2.7928402346333314e-07, Training time:50649.4508228302
batch reward last col mean 3.783121038658521e-11 first col mean 3.950897942139875e-10 all mean 3.3389244702419774e-09
6.903602134400444e-10 6.903602134400444e-10
rl training, epoch3, iter0, batch126/1133, batch loss:6.903602134400444e-10, Training time:50677.98976492882
batch reward last col mean 6.243275341155652e-10 first col mean 1.9141328522209733e-09 all mean 4.123537511446784e-09
1.0040112075060392e-09 1.0040108744391318e-09
rl training, epoch3, iter0, batch127/1133, batch loss:1.0040108744391318e-09, Training time:50706.6522963047
batch reward last col mean 3.883202093213356e-11 first col mean 6.278498432266133e-08 all mean 1.8992524886130013e-08
3.0446460907995743e-09 3.0446514198700925e-09
rl training, epoch3, iter0, batch128/1133, batch loss:3.0446514198700925e-09, Training time:50734.89406013489
batch reward last col mean 3.817712118658889e-11 first col mean 9.943257328615118e-10 all mean 2.0854111326684688e-08
7.451351535792128e-09 7.451351535792128e-09
rl training, epoch3, iter0, batch129/1133, batch loss:7.451351535792128e-09, Training time:50763.64120101929
batch reward last col mean 1.938649241139956e-11 first col mean 7.648760097511698e-11 all mean 2.544976895890727e-09
4.216716698035583e-10 4.2167244695967554e-10
rl training, epoch3, iter0, batch130/1133, batch loss:4.2167244695967554e-10, Training time:50792.75428009033
batch reward last col mean 2.8980606109341167e-11 first col mean 2.4452835312160914e-09 all mean 1.0812229334078438e-08
7.072962215914913e-09 7.072964436360962e-09
rl training, epoch3, iter0, batch131/1133, batch loss:7.072964436360962e-09, Training time:50821.058347940445
batch reward last col mean 2.2403152943883953e-10 first col mean 5.974329919666843e-10 all mean 1.5386583118726094e-09
4.341128290175078e-10 4.341128290175078e-10
rl training, epoch3, iter0, batch132/1133, batch loss:4.341128290175078e-10, Training time:50849.321414232254
batch reward last col mean 1.6144202641399374e-10 first col mean 7.628737512277439e-05 all mean 8.092877123999642e-07
4.1835967579118005e-08 4.183606705510101e-08
rl training, epoch3, iter0, batch133/1133, batch loss:4.183606705510101e-08, Training time:50878.136487960815
batch reward last col mean 7.244813776674519e-11 first col mean 0.00011521596752572805 all mean 1.1951644864893751e-06
1.994852027564775e-06 1.994852027564775e-06
rl training, epoch3, iter0, batch134/1133, batch loss:1.994852027564775e-06, Training time:50906.77329277992
batch reward last col mean 1.1979853220545067e-10 first col mean 5.164191851925182e-10 all mean 3.1652336307530504e-09
5.319018558935795e-10 5.319013562932184e-10
rl training, epoch3, iter0, batch135/1133, batch loss:5.319013562932184e-10, Training time:50934.94163131714
batch reward last col mean 3.6808341097316344e-11 first col mean 3.818032112690162e-09 all mean 1.2922497516498765e-09
5.945289816011723e-10 5.945290371123235e-10
rl training, epoch3, iter0, batch136/1133, batch loss:5.945290371123235e-10, Training time:50963.03640413284
batch reward last col mean 1.0315195919652353e-10 first col mean 1.20195564612402e-09 all mean 1.702029739369948e-09
2.9810691692944147e-09 2.9810691692944147e-09
rl training, epoch3, iter0, batch137/1133, batch loss:2.9810691692944147e-09, Training time:50991.39728665352
batch reward last col mean 1.273641601073905e-07 first col mean 9.45524436524181e-10 all mean 9.460082139867154e-08
3.0989234289791057e-08 3.098925560607313e-08
rl training, epoch3, iter0, batch138/1133, batch loss:3.098925560607313e-08, Training time:51019.684473991394
batch reward last col mean 3.132725190369001e-10 first col mean 6.375622807475168e-10 all mean 5.194483065906752e-09
6.14772499574201e-09 6.14772499574201e-09
rl training, epoch3, iter0, batch139/1133, batch loss:6.14772499574201e-09, Training time:51048.177827596664
batch reward last col mean 1.860487874871808e-10 first col mean 1.5054996138630372e-10 all mean 9.396325384436466e-11
5.994674895370977e-11 5.994674895370977e-11
rl training, epoch3, iter0, batch140/1133, batch loss:5.994674895370977e-11, Training time:51076.37051987648
batch reward last col mean 4.6149941507200865e-11 first col mean 5.4433631213601785e-11 all mean 2.6325031043938907e-09
7.989784389650367e-10 7.98978272431583e-10
rl training, epoch3, iter0, batch141/1133, batch loss:7.98978272431583e-10, Training time:51104.69360232353
batch reward last col mean 1.7397148999176437e-10 first col mean 1.2181289310575494e-09 all mean 4.22493373619659e-09
6.790846218684976e-10 6.790834006231705e-10
rl training, epoch3, iter0, batch142/1133, batch loss:6.790834006231705e-10, Training time:51133.54003381729
batch reward last col mean 3.512251467441274e-08 first col mean 2.7481039666099605e-09 all mean 3.051090686767566e-07
2.8237354854354635e-07 2.8237363380867464e-07
rl training, epoch3, iter0, batch143/1133, batch loss:2.8237363380867464e-07, Training time:51162.37931227684
batch reward last col mean 7.301851831509332e-12 first col mean 1.6075137054816224e-10 all mean 3.3126019616247504e-07
2.040223705535027e-07 2.0402249845119513e-07
rl training, epoch3, iter0, batch144/1133, batch loss:2.0402249845119513e-07, Training time:51191.38440132141
batch reward last col mean 8.416078250972348e-11 first col mean 7.184104006130454e-11 all mean 1.8761889819529642e-08
4.4878159521921646e-10 4.487877569570031e-10
rl training, epoch3, iter0, batch145/1133, batch loss:4.487877569570031e-10, Training time:51219.857315301895
batch reward last col mean 8.611409502146117e-11 first col mean 1.4344191112680704e-10 all mean 3.860978203817922e-10
1.4794805658358e-10 1.4794805658358e-10
rl training, epoch3, iter0, batch146/1133, batch loss:1.4794805658358e-10, Training time:51248.44304442406
batch reward last col mean 6.588245921035352e-11 first col mean 2.3267457405218295e-11 all mean 1.4616671206724163e-09
1.1984153669430953e-09 1.1984153669430953e-09
rl training, epoch3, iter0, batch147/1133, batch loss:1.1984153669430953e-09, Training time:51276.917498111725
batch reward last col mean 7.455518841181785e-11 first col mean 3.830521178027624e-10 all mean 5.3577707603835734e-08
1.5274227394002082e-07 1.527422455183114e-07
rl training, epoch3, iter0, batch148/1133, batch loss:1.527422455183114e-07, Training time:51305.37552237511
batch reward last col mean 4.52401102690736e-11 first col mean 1.3841860990737587e-08 all mean 1.0181328002900614e-09
8.684118979473965e-10 8.684118424362453e-10
rl training, epoch3, iter0, batch149/1133, batch loss:8.684118424362453e-10, Training time:51333.39561796188
batch reward last col mean 3.820024505052366e-11 first col mean 3.1984287440778303e-10 all mean 1.4966189155529719e-05
5.263988214210258e-07 5.264000151328219e-07
rl training, epoch3, iter0, batch150/1133, batch loss:5.264000151328219e-07, Training time:51361.60131692886
batch reward last col mean 9.243387999458008e-11 first col mean 3.9042133970212944e-09 all mean 2.503577123391665e-09
5.77887182551251e-10 5.778876266404609e-10
rl training, epoch3, iter0, batch151/1133, batch loss:5.778876266404609e-10, Training time:51389.6978096962
batch reward last col mean 3.060508788621519e-07 first col mean 5.344152897990284e-10 all mean 2.7212158215661475e-07
1.6341381581241876e-07 1.6341380160156405e-07
rl training, epoch3, iter0, batch152/1133, batch loss:1.6341380160156405e-07, Training time:51417.74330496788
batch reward last col mean 5.671235037141287e-09 first col mean 2.0902918285159444e-10 all mean 3.230339729043408e-08
4.3380683933946784e-08 4.338068748666046e-08
rl training, epoch3, iter0, batch153/1133, batch loss:4.338068748666046e-08, Training time:51445.80320477486
batch reward last col mean 1.0121261606599319e-09 first col mean 2.4889492689084136e-09 all mean 2.8845290600543194e-08
1.3977605739512455e-08 1.3977604851334036e-08
rl training, epoch3, iter0, batch154/1133, batch loss:1.3977604851334036e-08, Training time:51473.946871995926
batch reward last col mean 2.0807761763608212e-11 first col mean 4.005557691089123e-11 all mean 1.1696037471864429e-09
7.140015800821686e-10 7.140016355933199e-10
rl training, epoch3, iter0, batch155/1133, batch loss:7.140016355933199e-10, Training time:51502.01496863365
batch reward last col mean 1.3067112669684633e-10 first col mean 4.032334466330667e-09 all mean 1.8395006406990433e-08
6.083772152720712e-09 6.083769488185453e-09
rl training, epoch3, iter0, batch156/1133, batch loss:6.083769488185453e-09, Training time:51530.08999490738
batch reward last col mean 1.1014121559238532e-10 first col mean 1.100723939079229e-11 all mean 4.156168742497357e-10
1.6392635859840965e-10 1.639264279873487e-10
rl training, epoch3, iter0, batch157/1133, batch loss:1.639264279873487e-10, Training time:51558.13315320015
batch reward last col mean 8.943095708424664e-10 first col mean 3.8336767094193647e-10 all mean 3.764030420683184e-09
1.62862212604864e-09 1.6286225701378498e-09
rl training, epoch3, iter0, batch158/1133, batch loss:1.6286225701378498e-09, Training time:51586.228515625
