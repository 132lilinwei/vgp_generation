loaded G
loaded D
Using device cuda:4
begin rl....
rl epoch 0, begin RL for generator...
batch reward last col mean 0.3020695149898529 first col mean 0.29973679780960083 all mean 0.3054563105106354
1.0893746614456177 1.0893746614456177
rl training, epoch0, iter0, batch0/1133, batch loss:1.0893746614456177, Training time:2.3562209606170654
batch reward last col mean 0.3172731399536133 first col mean 0.33162057399749756 all mean 0.32332709431648254
1.0404406785964966 1.0404406785964966
rl training, epoch0, iter0, batch1/1133, batch loss:1.0404406785964966, Training time:4.573777198791504
batch reward last col mean 0.34401071071624756 first col mean 0.3115702271461487 all mean 0.3418087363243103
1.1368006467819214 1.1368006467819214
rl training, epoch0, iter0, batch2/1133, batch loss:1.1368006467819214, Training time:7.217822074890137
batch reward last col mean 0.2782728970050812 first col mean 0.31093862652778625 all mean 0.284453421831131
1.0189826488494873 1.0189826488494873
rl training, epoch0, iter0, batch3/1133, batch loss:1.0189826488494873, Training time:9.754188060760498
batch reward last col mean 0.35970747470855713 first col mean 0.3170449733734131 all mean 0.35159242153167725
1.185288667678833 1.185288667678833
rl training, epoch0, iter0, batch4/1133, batch loss:1.185288667678833, Training time:12.022058248519897
batch reward last col mean 0.34336057305336 first col mean 0.3241289258003235 all mean 0.33411872386932373
1.0734169483184814 1.0734169483184814
rl training, epoch0, iter0, batch5/1133, batch loss:1.0734169483184814, Training time:15.559762001037598
batch reward last col mean 0.3328503668308258 first col mean 0.3278590738773346 all mean 0.33033961057662964
0.999036967754364 0.9990369081497192
rl training, epoch0, iter0, batch6/1133, batch loss:0.9990369081497192, Training time:18.389214992523193
batch reward last col mean 0.3192048966884613 first col mean 0.3160787522792816 all mean 0.3155353367328644
1.010102391242981 1.010102391242981
rl training, epoch0, iter0, batch7/1133, batch loss:1.010102391242981, Training time:20.60624623298645
batch reward last col mean 0.3580690622329712 first col mean 0.33547139167785645 all mean 0.3528217375278473
1.1070809364318848 1.1070809364318848
rl training, epoch0, iter0, batch8/1133, batch loss:1.1070809364318848, Training time:23.238401889801025
batch reward last col mean 0.3160066604614258 first col mean 0.2986525893211365 all mean 0.3157176375389099
0.9715781807899475 0.9715781807899475
rl training, epoch0, iter0, batch9/1133, batch loss:0.9715781807899475, Training time:25.395418882369995
batch reward last col mean 0.33116787672042847 first col mean 0.34424200654029846 all mean 0.3345632553100586
1.072202205657959 1.072202205657959
rl training, epoch0, iter0, batch10/1133, batch loss:1.072202205657959, Training time:28.067144870758057
batch reward last col mean 0.2807796597480774 first col mean 0.31157952547073364 all mean 0.296397864818573
0.9148266315460205 0.9148266315460205
rl training, epoch0, iter0, batch11/1133, batch loss:0.9148266315460205, Training time:30.728986024856567
batch reward last col mean 0.3038724362850189 first col mean 0.306174099445343 all mean 0.3087042272090912
0.9978287816047668 0.9978287816047668
rl training, epoch0, iter0, batch12/1133, batch loss:0.9978287816047668, Training time:35.38215184211731
batch reward last col mean 0.33958113193511963 first col mean 0.33572569489479065 all mean 0.3277337849140167
1.0163352489471436 1.0163352489471436
rl training, epoch0, iter0, batch13/1133, batch loss:1.0163352489471436, Training time:38.47268223762512
batch reward last col mean 0.30132168531417847 first col mean 0.31036391854286194 all mean 0.3086763918399811
0.9370853304862976 0.9370853304862976
rl training, epoch0, iter0, batch14/1133, batch loss:0.9370853304862976, Training time:41.05682134628296
batch reward last col mean 0.3138796091079712 first col mean 0.3258335590362549 all mean 0.31535330414772034
0.9662280082702637 0.9662280082702637
rl training, epoch0, iter0, batch15/1133, batch loss:0.9662280082702637, Training time:44.35882568359375
batch reward last col mean 0.2825220823287964 first col mean 0.34561923146247864 all mean 0.289206862449646
0.9869941473007202 0.9869941473007202
rl training, epoch0, iter0, batch16/1133, batch loss:0.9869941473007202, Training time:48.3961079120636
batch reward last col mean 0.31696340441703796 first col mean 0.3461548089981079 all mean 0.31769806146621704
0.9834471940994263 0.983447253704071
rl training, epoch0, iter0, batch17/1133, batch loss:0.983447253704071, Training time:51.31969618797302
batch reward last col mean 0.3118853271007538 first col mean 0.32223406434059143 all mean 0.3084646165370941
0.9851812720298767 0.9851812720298767
rl training, epoch0, iter0, batch18/1133, batch loss:0.9851812720298767, Training time:54.09825682640076
batch reward last col mean 0.33441734313964844 first col mean 0.32702407240867615 all mean 0.33171597123146057
0.9589502215385437 0.9589502215385437
rl training, epoch0, iter0, batch19/1133, batch loss:0.9589502215385437, Training time:56.52771806716919
batch reward last col mean 0.35126373171806335 first col mean 0.3390965163707733 all mean 0.3519931435585022
1.0039352178573608 1.0039350986480713
rl training, epoch0, iter0, batch20/1133, batch loss:1.0039350986480713, Training time:60.02438759803772
batch reward last col mean 0.3264821767807007 first col mean 0.32861602306365967 all mean 0.32313066720962524
0.8971784710884094 0.8971784710884094
rl training, epoch0, iter0, batch21/1133, batch loss:0.8971784710884094, Training time:62.42495894432068
batch reward last col mean 0.31624430418014526 first col mean 0.3363628387451172 all mean 0.3265022933483124
1.0209934711456299 1.0209934711456299
rl training, epoch0, iter0, batch22/1133, batch loss:1.0209934711456299, Training time:65.74672508239746
batch reward last col mean 0.3507382869720459 first col mean 0.34119048714637756 all mean 0.35116681456565857
1.013708233833313 1.013708233833313
rl training, epoch0, iter0, batch23/1133, batch loss:1.013708233833313, Training time:67.99430751800537
batch reward last col mean 0.35274994373321533 first col mean 0.35954123735427856 all mean 0.34855642914772034
1.0106050968170166 1.0106050968170166
rl training, epoch0, iter0, batch24/1133, batch loss:1.0106050968170166, Training time:70.24440932273865
batch reward last col mean 0.3433467745780945 first col mean 0.3516879677772522 all mean 0.3431534767150879
0.9406868815422058 0.9406868815422058
rl training, epoch0, iter0, batch25/1133, batch loss:0.9406868815422058, Training time:72.40276670455933
batch reward last col mean 0.30296769738197327 first col mean 0.33571821451187134 all mean 0.3153105080127716
1.0225085020065308 1.0225085020065308
rl training, epoch0, iter0, batch26/1133, batch loss:1.0225085020065308, Training time:74.66150617599487
batch reward last col mean 0.3302531838417053 first col mean 0.3169393539428711 all mean 0.33349958062171936
0.9801744818687439 0.9801744222640991
rl training, epoch0, iter0, batch27/1133, batch loss:0.9801744222640991, Training time:76.96276640892029
batch reward last col mean 0.32309260964393616 first col mean 0.35024699568748474 all mean 0.3379334807395935
0.9431239366531372 0.9431238770484924
rl training, epoch0, iter0, batch28/1133, batch loss:0.9431238770484924, Training time:78.77622556686401
batch reward last col mean 0.3472985625267029 first col mean 0.3669753074645996 all mean 0.3499286472797394
1.0230339765548706 1.0230339765548706
rl training, epoch0, iter0, batch29/1133, batch loss:1.0230339765548706, Training time:81.5051474571228
batch reward last col mean 0.3515598177909851 first col mean 0.3473255932331085 all mean 0.35185879468917847
0.9993124604225159 0.9993125796318054
rl training, epoch0, iter0, batch30/1133, batch loss:0.9993125796318054, Training time:84.03718042373657
batch reward last col mean 0.3689620792865753 first col mean 0.3594249486923218 all mean 0.3669557571411133
1.039202094078064 1.039202094078064
rl training, epoch0, iter0, batch31/1133, batch loss:1.039202094078064, Training time:87.17044878005981
batch reward last col mean 0.3843269348144531 first col mean 0.34956228733062744 all mean 0.3665011525154114
1.0387375354766846 1.038737416267395
rl training, epoch0, iter0, batch32/1133, batch loss:1.038737416267395, Training time:89.73472046852112
batch reward last col mean 0.34169626235961914 first col mean 0.34644070267677307 all mean 0.35350021719932556
1.0221550464630127 1.0221550464630127
rl training, epoch0, iter0, batch33/1133, batch loss:1.0221550464630127, Training time:92.71565103530884
batch reward last col mean 0.41282498836517334 first col mean 0.3300837278366089 all mean 0.3929162621498108
1.0072553157806396 1.0072553157806396
rl training, epoch0, iter0, batch34/1133, batch loss:1.0072553157806396, Training time:95.59423804283142
batch reward last col mean 0.41369378566741943 first col mean 0.325643390417099 all mean 0.3920530080795288
1.0278408527374268 1.0278408527374268
rl training, epoch0, iter0, batch35/1133, batch loss:1.0278408527374268, Training time:98.13185477256775
batch reward last col mean 0.2888124883174896 first col mean 0.342039555311203 all mean 0.3064435124397278
0.8846144676208496 0.8846144676208496
rl training, epoch0, iter0, batch36/1133, batch loss:0.8846144676208496, Training time:100.56734895706177
batch reward last col mean 0.31555745005607605 first col mean 0.36458495259284973 all mean 0.3248276114463806
0.9331749081611633 0.9331749081611633
rl training, epoch0, iter0, batch37/1133, batch loss:0.9331749081611633, Training time:103.40951442718506
batch reward last col mean 0.327961266040802 first col mean 0.32153958082199097 all mean 0.3267996311187744
0.9237252473831177 0.9237252473831177
rl training, epoch0, iter0, batch38/1133, batch loss:0.9237252473831177, Training time:105.42246294021606
batch reward last col mean 0.2767750024795532 first col mean 0.31996333599090576 all mean 0.29244816303253174
0.9026289582252502 0.9026289582252502
rl training, epoch0, iter0, batch39/1133, batch loss:0.9026289582252502, Training time:108.83028173446655
batch reward last col mean 0.30995047092437744 first col mean 0.38333389163017273 all mean 0.3179973363876343
0.9365341663360596 0.9365341067314148
rl training, epoch0, iter0, batch40/1133, batch loss:0.9365341067314148, Training time:111.62009716033936
batch reward last col mean 0.4077036678791046 first col mean 0.3749943673610687 all mean 0.3962661027908325
1.025583028793335 1.025583028793335
rl training, epoch0, iter0, batch41/1133, batch loss:1.025583028793335, Training time:113.61833930015564
batch reward last col mean 0.40587708353996277 first col mean 0.34808751940727234 all mean 0.3922439515590668
0.9744064807891846 0.9744064807891846
rl training, epoch0, iter0, batch42/1133, batch loss:0.9744064807891846, Training time:115.8255410194397
batch reward last col mean 0.40127652883529663 first col mean 0.3663597106933594 all mean 0.3969639837741852
1.0595076084136963 1.0595076084136963
rl training, epoch0, iter0, batch43/1133, batch loss:1.0595076084136963, Training time:118.21184277534485
batch reward last col mean 0.4137815237045288 first col mean 0.34205132722854614 all mean 0.3995799720287323
1.0214546918869019 1.0214546918869019
rl training, epoch0, iter0, batch44/1133, batch loss:1.0214546918869019, Training time:120.6338517665863
batch reward last col mean 0.35767611861228943 first col mean 0.3683392405509949 all mean 0.3617229163646698
0.9887371063232422 0.9887371063232422
rl training, epoch0, iter0, batch45/1133, batch loss:0.9887371063232422, Training time:122.92257523536682
batch reward last col mean 0.37838172912597656 first col mean 0.37052568793296814 all mean 0.37000223994255066
0.9732306599617004 0.9732306599617004
rl training, epoch0, iter0, batch46/1133, batch loss:0.9732306599617004, Training time:125.6009955406189
batch reward last col mean 0.3537997007369995 first col mean 0.3686142563819885 all mean 0.35470086336135864
0.9995793700218201 0.9995792508125305
rl training, epoch0, iter0, batch47/1133, batch loss:0.9995792508125305, Training time:127.5551688671112
batch reward last col mean 0.36050453782081604 first col mean 0.35475921630859375 all mean 0.36414358019828796
1.0191638469696045 1.0191638469696045
rl training, epoch0, iter0, batch48/1133, batch loss:1.0191638469696045, Training time:131.5349316596985
batch reward last col mean 0.27805718779563904 first col mean 0.3483247756958008 all mean 0.2965397834777832
0.848439633846283 0.848439633846283
rl training, epoch0, iter0, batch49/1133, batch loss:0.848439633846283, Training time:133.47416496276855
batch reward last col mean 0.32135581970214844 first col mean 0.35835498571395874 all mean 0.3220140337944031
0.8041862845420837 0.8041862845420837
rl training, epoch0, iter0, batch50/1133, batch loss:0.8041862845420837, Training time:136.3572609424591
batch reward last col mean 0.34209302067756653 first col mean 0.34370675683021545 all mean 0.3392859399318695
0.9247149229049683 0.924714982509613
rl training, epoch0, iter0, batch51/1133, batch loss:0.924714982509613, Training time:138.20465230941772
batch reward last col mean 0.36410805583000183 first col mean 0.3700043559074402 all mean 0.3652917146682739
1.0101252794265747 1.0101252794265747
rl training, epoch0, iter0, batch52/1133, batch loss:1.0101252794265747, Training time:140.2373185157776
batch reward last col mean 0.33759641647338867 first col mean 0.3654577136039734 all mean 0.34785154461860657
0.9275230169296265 0.9275228977203369
rl training, epoch0, iter0, batch53/1133, batch loss:0.9275228977203369, Training time:141.91501879692078
batch reward last col mean 0.340753436088562 first col mean 0.33812564611434937 all mean 0.33717265725135803
0.8887549042701721 0.8887548446655273
rl training, epoch0, iter0, batch54/1133, batch loss:0.8887548446655273, Training time:144.11174869537354
batch reward last col mean 0.2951868176460266 first col mean 0.3162170648574829 all mean 0.3009856343269348
0.7951101064682007 0.7951101064682007
rl training, epoch0, iter0, batch55/1133, batch loss:0.7951101064682007, Training time:146.7050654888153
batch reward last col mean 0.35975009202957153 first col mean 0.3640627861022949 all mean 0.36085739731788635
0.898725152015686 0.898725152015686
rl training, epoch0, iter0, batch56/1133, batch loss:0.898725152015686, Training time:148.95383191108704
batch reward last col mean 0.3177413046360016 first col mean 0.35784322023391724 all mean 0.3247726559638977
0.8983889818191528 0.8983889818191528
rl training, epoch0, iter0, batch57/1133, batch loss:0.8983889818191528, Training time:150.8282973766327
batch reward last col mean 0.3494717478752136 first col mean 0.3551046550273895 all mean 0.35442009568214417
0.9726618528366089 0.9726618528366089
rl training, epoch0, iter0, batch58/1133, batch loss:0.9726618528366089, Training time:152.99523067474365
batch reward last col mean 0.37985190749168396 first col mean 0.3828672468662262 all mean 0.37509647011756897
0.9576892852783203 0.9576892852783203
rl training, epoch0, iter0, batch59/1133, batch loss:0.9576892852783203, Training time:155.8718843460083
batch reward last col mean 0.3675816059112549 first col mean 0.36190590262413025 all mean 0.3602217733860016
0.8689519166946411 0.8689519166946411
rl training, epoch0, iter0, batch60/1133, batch loss:0.8689519166946411, Training time:158.86223649978638
batch reward last col mean 0.33881261944770813 first col mean 0.3649803102016449 all mean 0.3462882339954376
0.8846712112426758 0.8846712112426758
rl training, epoch0, iter0, batch61/1133, batch loss:0.8846712112426758, Training time:161.24016880989075
batch reward last col mean 0.35152751207351685 first col mean 0.3930845260620117 all mean 0.3492121696472168
0.8529446125030518 0.852944552898407
rl training, epoch0, iter0, batch62/1133, batch loss:0.852944552898407, Training time:163.72435569763184
batch reward last col mean 0.37267786264419556 first col mean 0.37919217348098755 all mean 0.37177467346191406
0.9817044734954834 0.9817044734954834
rl training, epoch0, iter0, batch63/1133, batch loss:0.9817044734954834, Training time:165.7235038280487
batch reward last col mean 0.3143131136894226 first col mean 0.3333798050880432 all mean 0.3133113384246826
0.7289078235626221 0.7289078235626221
rl training, epoch0, iter0, batch64/1133, batch loss:0.7289078235626221, Training time:168.048499584198
batch reward last col mean 0.4187334179878235 first col mean 0.4005749523639679 all mean 0.4154549539089203
0.9945650100708008 0.9945650100708008
rl training, epoch0, iter0, batch65/1133, batch loss:0.9945650100708008, Training time:170.76276111602783
batch reward last col mean 0.341301828622818 first col mean 0.3622293472290039 all mean 0.34438714385032654
0.8570437431335449 0.8570437431335449
rl training, epoch0, iter0, batch66/1133, batch loss:0.8570437431335449, Training time:173.37730765342712
batch reward last col mean 0.34372079372406006 first col mean 0.3620416522026062 all mean 0.3511451184749603
0.9799038767814636 0.9799038171768188
rl training, epoch0, iter0, batch67/1133, batch loss:0.9799038171768188, Training time:176.1445586681366
batch reward last col mean 0.41192880272865295 first col mean 0.34787851572036743 all mean 0.40339046716690063
0.9299007654190063 0.9299007654190063
rl training, epoch0, iter0, batch68/1133, batch loss:0.9299007654190063, Training time:179.40322518348694
batch reward last col mean 0.3771640658378601 first col mean 0.3640286326408386 all mean 0.36836835741996765
0.8558758497238159 0.8558758497238159
rl training, epoch0, iter0, batch69/1133, batch loss:0.8558758497238159, Training time:181.5694580078125
batch reward last col mean 0.3640497326850891 first col mean 0.36088109016418457 all mean 0.3630407154560089
0.9727696776390076 0.9727697968482971
rl training, epoch0, iter0, batch70/1133, batch loss:0.9727697968482971, Training time:183.357164144516
batch reward last col mean 0.3921498656272888 first col mean 0.3610055446624756 all mean 0.3881154954433441
0.9306153059005737 0.9306153059005737
rl training, epoch0, iter0, batch71/1133, batch loss:0.9306153059005737, Training time:185.20468068122864
batch reward last col mean 0.3871912658214569 first col mean 0.3825399875640869 all mean 0.39017951488494873
0.9510164260864258 0.9510164260864258
rl training, epoch0, iter0, batch72/1133, batch loss:0.9510164260864258, Training time:187.43840289115906
batch reward last col mean 0.32102951407432556 first col mean 0.3503219783306122 all mean 0.33707448840141296
0.8683605194091797 0.8683604598045349
rl training, epoch0, iter0, batch73/1133, batch loss:0.8683604598045349, Training time:189.85702109336853
batch reward last col mean 0.3541713356971741 first col mean 0.3550918698310852 all mean 0.34796765446662903
0.8376812934875488 0.8376812934875488
rl training, epoch0, iter0, batch74/1133, batch loss:0.8376812934875488, Training time:192.1705243587494
batch reward last col mean 0.2895468473434448 first col mean 0.36010071635246277 all mean 0.296896755695343
0.8181189298629761 0.8181189298629761
rl training, epoch0, iter0, batch75/1133, batch loss:0.8181189298629761, Training time:194.60881853103638
batch reward last col mean 0.37879446148872375 first col mean 0.3621441721916199 all mean 0.37404876947402954
0.8889085054397583 0.8889085054397583
rl training, epoch0, iter0, batch76/1133, batch loss:0.8889085054397583, Training time:197.46706914901733
batch reward last col mean 0.3665164113044739 first col mean 0.3614196181297302 all mean 0.3615082800388336
0.8877692818641663 0.8877692818641663
rl training, epoch0, iter0, batch77/1133, batch loss:0.8877692818641663, Training time:199.71455597877502
batch reward last col mean 0.34513145685195923 first col mean 0.3680568039417267 all mean 0.34975090622901917
0.7250185012817383 0.7250185012817383
rl training, epoch0, iter0, batch78/1133, batch loss:0.7250185012817383, Training time:201.9103066921234
batch reward last col mean 0.39651936292648315 first col mean 0.36400508880615234 all mean 0.38420161604881287
0.9832849502563477 0.9832849502563477
rl training, epoch0, iter0, batch79/1133, batch loss:0.9832849502563477, Training time:203.982994556427
batch reward last col mean 0.3837478756904602 first col mean 0.38193872570991516 all mean 0.379075825214386
0.9143049120903015 0.9143049120903015
rl training, epoch0, iter0, batch80/1133, batch loss:0.9143049120903015, Training time:206.9507532119751
batch reward last col mean 0.35056763887405396 first col mean 0.35463160276412964 all mean 0.34687379002571106
0.8530229330062866 0.8530229330062866
rl training, epoch0, iter0, batch81/1133, batch loss:0.8530229330062866, Training time:209.14268946647644
batch reward last col mean 0.3275936543941498 first col mean 0.338530570268631 all mean 0.3329651653766632
0.9152221083641052 0.9152221083641052
rl training, epoch0, iter0, batch82/1133, batch loss:0.9152221083641052, Training time:212.12947821617126
batch reward last col mean 0.37974029779434204 first col mean 0.366212397813797 all mean 0.3766939640045166
0.9343976378440857 0.9343976378440857
rl training, epoch0, iter0, batch83/1133, batch loss:0.9343976378440857, Training time:213.9578995704651
batch reward last col mean 0.3422715961933136 first col mean 0.3547717332839966 all mean 0.3423287272453308
0.7964856624603271 0.7964856624603271
rl training, epoch0, iter0, batch84/1133, batch loss:0.7964856624603271, Training time:216.8008897304535
batch reward last col mean 0.3641052544116974 first col mean 0.34739747643470764 all mean 0.3605857789516449
0.915910542011261 0.915910542011261
rl training, epoch0, iter0, batch85/1133, batch loss:0.915910542011261, Training time:219.41753244400024
batch reward last col mean 0.41397625207901 first col mean 0.38481101393699646 all mean 0.4040698707103729
0.960123598575592 0.960123598575592
rl training, epoch0, iter0, batch86/1133, batch loss:0.960123598575592, Training time:221.58028888702393
batch reward last col mean 0.39451858401298523 first col mean 0.3809109926223755 all mean 0.3889347314834595
0.8214442133903503 0.8214442133903503
rl training, epoch0, iter0, batch87/1133, batch loss:0.8214442133903503, Training time:224.43140649795532
batch reward last col mean 0.41008782386779785 first col mean 0.3931393623352051 all mean 0.4014924466609955
1.0100224018096924 1.0100224018096924
rl training, epoch0, iter0, batch88/1133, batch loss:1.0100224018096924, Training time:227.06349301338196
batch reward last col mean 0.38324129581451416 first col mean 0.37270334362983704 all mean 0.3877856731414795
0.923311173915863 0.923311173915863
rl training, epoch0, iter0, batch89/1133, batch loss:0.923311173915863, Training time:230.50198817253113
batch reward last col mean 0.35867786407470703 first col mean 0.39958760142326355 all mean 0.3648926317691803
0.8262158632278442 0.8262158632278442
rl training, epoch0, iter0, batch90/1133, batch loss:0.8262158632278442, Training time:232.84280610084534
batch reward last col mean 0.33310383558273315 first col mean 0.3503647446632385 all mean 0.33679115772247314
0.7952260375022888 0.7952260375022888
rl training, epoch0, iter0, batch91/1133, batch loss:0.7952260375022888, Training time:235.6646499633789
batch reward last col mean 0.3628602623939514 first col mean 0.35712456703186035 all mean 0.35926344990730286
0.869225800037384 0.8692257404327393
rl training, epoch0, iter0, batch92/1133, batch loss:0.8692257404327393, Training time:238.12480187416077
batch reward last col mean 0.3700575828552246 first col mean 0.3913869559764862 all mean 0.3676185607910156
0.8983206748962402 0.8983206748962402
rl training, epoch0, iter0, batch93/1133, batch loss:0.8983206748962402, Training time:241.12895584106445
batch reward last col mean 0.4035867750644684 first col mean 0.37062323093414307 all mean 0.40029335021972656
0.9425728917121887 0.9425729513168335
rl training, epoch0, iter0, batch94/1133, batch loss:0.9425729513168335, Training time:243.47034740447998
batch reward last col mean 0.4269784092903137 first col mean 0.4111555218696594 all mean 0.41663235425949097
0.9385101795196533 0.9385101795196533
rl training, epoch0, iter0, batch95/1133, batch loss:0.9385101795196533, Training time:246.34658646583557
batch reward last col mean 0.36689305305480957 first col mean 0.37210094928741455 all mean 0.36518633365631104
0.9095695614814758 0.9095695614814758
rl training, epoch0, iter0, batch96/1133, batch loss:0.9095695614814758, Training time:248.85046195983887
batch reward last col mean 0.37337711453437805 first col mean 0.38664525747299194 all mean 0.38216179609298706
0.9269207119941711 0.9269206523895264
rl training, epoch0, iter0, batch97/1133, batch loss:0.9269206523895264, Training time:251.50506472587585
batch reward last col mean 0.3498215079307556 first col mean 0.3727787137031555 all mean 0.3508601784706116
0.8492081761360168 0.8492081761360168
rl training, epoch0, iter0, batch98/1133, batch loss:0.8492081761360168, Training time:255.41174745559692
batch reward last col mean 0.35317128896713257 first col mean 0.38401520252227783 all mean 0.3618510961532593
0.9676415324211121 0.9676414728164673
rl training, epoch0, iter0, batch99/1133, batch loss:0.9676414728164673, Training time:258.4247205257416
batch reward last col mean 0.3699391484260559 first col mean 0.3907681703567505 all mean 0.3679170608520508
0.9770447015762329 0.9770447015762329
rl training, epoch0, iter0, batch100/1133, batch loss:0.9770447015762329, Training time:261.99500274658203
batch reward last col mean 0.40566232800483704 first col mean 0.3991174101829529 all mean 0.403787761926651
0.9477415084838867 0.9477415084838867
rl training, epoch0, iter0, batch101/1133, batch loss:0.9477415084838867, Training time:265.22915410995483
batch reward last col mean 0.37986689805984497 first col mean 0.42847153544425964 all mean 0.38512057065963745
0.9606830477714539 0.9606831669807434
rl training, epoch0, iter0, batch102/1133, batch loss:0.9606831669807434, Training time:268.1629846096039
batch reward last col mean 0.3972611725330353 first col mean 0.3924018144607544 all mean 0.3961127996444702
0.9831660985946655 0.9831660985946655
rl training, epoch0, iter0, batch103/1133, batch loss:0.9831660985946655, Training time:271.24811267852783
batch reward last col mean 0.3684863746166229 first col mean 0.37966978549957275 all mean 0.36599329113960266
0.9462512731552124 0.9462512731552124
rl training, epoch0, iter0, batch104/1133, batch loss:0.9462512731552124, Training time:274.22921895980835
batch reward last col mean 0.3666771352291107 first col mean 0.4079727232456207 all mean 0.3705418109893799
0.9128562808036804 0.91285640001297
rl training, epoch0, iter0, batch105/1133, batch loss:0.91285640001297, Training time:278.1837377548218
batch reward last col mean 0.39061489701271057 first col mean 0.4032360315322876 all mean 0.39752256870269775
0.9321646690368652 0.9321646690368652
rl training, epoch0, iter0, batch106/1133, batch loss:0.9321646690368652, Training time:281.03843092918396
batch reward last col mean 0.3112019896507263 first col mean 0.38011598587036133 all mean 0.32518744468688965
0.9071457982063293 0.9071457982063293
rl training, epoch0, iter0, batch107/1133, batch loss:0.9071457982063293, Training time:284.6215875148773
batch reward last col mean 0.40765494108200073 first col mean 0.3948083519935608 all mean 0.3958735466003418
0.9862854480743408 0.9862854480743408
rl training, epoch0, iter0, batch108/1133, batch loss:0.9862854480743408, Training time:287.2125725746155
batch reward last col mean 0.4169113039970398 first col mean 0.397795170545578 all mean 0.4136735200881958
1.023200273513794 1.023200273513794
rl training, epoch0, iter0, batch109/1133, batch loss:1.023200273513794, Training time:290.09679079055786
batch reward last col mean 0.38812798261642456 first col mean 0.3926033079624176 all mean 0.3852390944957733
0.9078139662742615 0.9078139662742615
rl training, epoch0, iter0, batch110/1133, batch loss:0.9078139662742615, Training time:293.09034514427185
batch reward last col mean 0.38690510392189026 first col mean 0.3991178870201111 all mean 0.3870885968208313
1.0126937627792358 1.0126937627792358
rl training, epoch0, iter0, batch111/1133, batch loss:1.0126937627792358, Training time:298.178750038147
batch reward last col mean 0.3525318503379822 first col mean 0.3942304849624634 all mean 0.3621571362018585
0.9808468818664551 0.9808467626571655
rl training, epoch0, iter0, batch112/1133, batch loss:0.9808467626571655, Training time:302.6156532764435
batch reward last col mean 0.43162646889686584 first col mean 0.3979794383049011 all mean 0.4241180419921875
1.0280803442001343 1.0280803442001343
rl training, epoch0, iter0, batch113/1133, batch loss:1.0280803442001343, Training time:305.8026714324951
batch reward last col mean 0.35791489481925964 first col mean 0.40428006649017334 all mean 0.36775216460227966
0.942892849445343 0.942892849445343
rl training, epoch0, iter0, batch114/1133, batch loss:0.942892849445343, Training time:309.7418806552887
batch reward last col mean 0.3725641071796417 first col mean 0.3572431802749634 all mean 0.3785760998725891
0.953262209892273 0.953262209892273
rl training, epoch0, iter0, batch115/1133, batch loss:0.953262209892273, Training time:315.6668255329132
batch reward last col mean 0.4002416133880615 first col mean 0.40112102031707764 all mean 0.4019813537597656
0.9826474785804749 0.9826474785804749
rl training, epoch0, iter0, batch116/1133, batch loss:0.9826474785804749, Training time:319.32025718688965
batch reward last col mean 0.4158904552459717 first col mean 0.3949638605117798 all mean 0.4076627194881439
1.0613900423049927 1.0613900423049927
rl training, epoch0, iter0, batch117/1133, batch loss:1.0613900423049927, Training time:323.63859391212463
batch reward last col mean 0.4323534369468689 first col mean 0.3866520822048187 all mean 0.4225238561630249
0.9971976280212402 0.9971976280212402
rl training, epoch0, iter0, batch118/1133, batch loss:0.9971976280212402, Training time:327.666629076004
batch reward last col mean 0.38362401723861694 first col mean 0.3861265480518341 all mean 0.3862200677394867
0.9034276008605957 0.9034276604652405
rl training, epoch0, iter0, batch119/1133, batch loss:0.9034276604652405, Training time:334.3399250507355
batch reward last col mean 0.40314581990242004 first col mean 0.4455461800098419 all mean 0.40639081597328186
1.007158637046814 1.007158637046814
rl training, epoch0, iter0, batch120/1133, batch loss:1.007158637046814, Training time:339.1275668144226
batch reward last col mean 0.3750132620334625 first col mean 0.37455329298973083 all mean 0.3815059959888458
0.9719941020011902 0.9719941020011902
rl training, epoch0, iter0, batch121/1133, batch loss:0.9719941020011902, Training time:344.2523899078369
batch reward last col mean 0.41056057810783386 first col mean 0.39405593276023865 all mean 0.4089566767215729
1.0458447933197021 1.0458447933197021
rl training, epoch0, iter0, batch122/1133, batch loss:1.0458447933197021, Training time:350.18023800849915
batch reward last col mean 0.39812278747558594 first col mean 0.41997507214546204 all mean 0.3991473913192749
1.0457442998886108 1.0457441806793213
rl training, epoch0, iter0, batch123/1133, batch loss:1.0457441806793213, Training time:356.3863015174866
batch reward last col mean 0.35499560832977295 first col mean 0.3847423791885376 all mean 0.36060386896133423
0.9508640766143799 0.9508640766143799
rl training, epoch0, iter0, batch124/1133, batch loss:0.9508640766143799, Training time:362.81437706947327
batch reward last col mean 0.3635561764240265 first col mean 0.3929020166397095 all mean 0.3662051856517792
0.9949037432670593 0.9949037432670593
rl training, epoch0, iter0, batch125/1133, batch loss:0.9949037432670593, Training time:368.33519744873047
batch reward last col mean 0.39214980602264404 first col mean 0.36924076080322266 all mean 0.3849790692329407
0.8821725249290466 0.8821725249290466
rl training, epoch0, iter0, batch126/1133, batch loss:0.8821725249290466, Training time:372.45956778526306
batch reward last col mean 0.3767211139202118 first col mean 0.40755200386047363 all mean 0.3841513991355896
0.9433420896530151 0.9433420896530151
rl training, epoch0, iter0, batch127/1133, batch loss:0.9433420896530151, Training time:378.07030487060547
batch reward last col mean 0.3635711669921875 first col mean 0.40977469086647034 all mean 0.3734510838985443
0.932477593421936 0.9324775338172913
rl training, epoch0, iter0, batch128/1133, batch loss:0.9324775338172913, Training time:382.0191719532013
batch reward last col mean 0.41713276505470276 first col mean 0.40326085686683655 all mean 0.4160459041595459
0.9546123147010803 0.9546123147010803
rl training, epoch0, iter0, batch129/1133, batch loss:0.9546123147010803, Training time:387.9511950016022
batch reward last col mean 0.39808008074760437 first col mean 0.3784247040748596 all mean 0.4000655710697174
1.0024067163467407 1.0024067163467407
rl training, epoch0, iter0, batch130/1133, batch loss:1.0024067163467407, Training time:393.6774899959564
batch reward last col mean 0.41253042221069336 first col mean 0.40737438201904297 all mean 0.40229788422584534
0.8994224667549133 0.8994224667549133
rl training, epoch0, iter0, batch131/1133, batch loss:0.8994224667549133, Training time:398.89456367492676
batch reward last col mean 0.3486948311328888 first col mean 0.40710026025772095 all mean 0.35165444016456604
0.8216136693954468 0.8216136693954468
rl training, epoch0, iter0, batch132/1133, batch loss:0.8216136693954468, Training time:402.3469591140747
batch reward last col mean 0.37537825107574463 first col mean 0.41040298342704773 all mean 0.38391607999801636
1.0257821083068848 1.0257821083068848
rl training, epoch0, iter0, batch133/1133, batch loss:1.0257821083068848, Training time:406.88994216918945
batch reward last col mean 0.44147008657455444 first col mean 0.3853447735309601 all mean 0.43393000960350037
1.048001766204834 1.0480018854141235
rl training, epoch0, iter0, batch134/1133, batch loss:1.0480018854141235, Training time:410.6042990684509
batch reward last col mean 0.35537201166152954 first col mean 0.3950158953666687 all mean 0.3702174723148346
0.9770849943161011 0.9770849347114563
rl training, epoch0, iter0, batch135/1133, batch loss:0.9770849347114563, Training time:414.46516847610474
batch reward last col mean 0.3810490667819977 first col mean 0.38774576783180237 all mean 0.38514095544815063
0.9652612805366516 0.9652612805366516
rl training, epoch0, iter0, batch136/1133, batch loss:0.9652612805366516, Training time:418.99328804016113
batch reward last col mean 0.4440213441848755 first col mean 0.4149002432823181 all mean 0.4297422468662262
1.028757095336914 1.028757095336914
rl training, epoch0, iter0, batch137/1133, batch loss:1.028757095336914, Training time:422.278639793396
batch reward last col mean 0.4289599061012268 first col mean 0.4367290735244751 all mean 0.42649802565574646
1.0545929670333862 1.0545929670333862
rl training, epoch0, iter0, batch138/1133, batch loss:1.0545929670333862, Training time:425.6832287311554
batch reward last col mean 0.37553495168685913 first col mean 0.39973822236061096 all mean 0.37643060088157654
0.9389267563819885 0.9389267563819885
rl training, epoch0, iter0, batch139/1133, batch loss:0.9389267563819885, Training time:429.3589246273041
batch reward last col mean 0.38629162311553955 first col mean 0.39180511236190796 all mean 0.3870982229709625
0.887215793132782 0.887215793132782
rl training, epoch0, iter0, batch140/1133, batch loss:0.887215793132782, Training time:431.9420702457428
batch reward last col mean 0.4606800675392151 first col mean 0.4093708395957947 all mean 0.4559684097766876
1.0441739559173584 1.0441739559173584
rl training, epoch0, iter0, batch141/1133, batch loss:1.0441739559173584, Training time:435.40821957588196
batch reward last col mean 0.3964226543903351 first col mean 0.4080568552017212 all mean 0.4003245532512665
0.931748628616333 0.931748628616333
rl training, epoch0, iter0, batch142/1133, batch loss:0.931748628616333, Training time:438.5315754413605
batch reward last col mean 0.4093002676963806 first col mean 0.37226438522338867 all mean 0.40183931589126587
0.9040867686271667 0.9040867686271667
rl training, epoch0, iter0, batch143/1133, batch loss:0.9040867686271667, Training time:442.91531252861023
batch reward last col mean 0.38086363673210144 first col mean 0.40198901295661926 all mean 0.3825242817401886
0.9535849094390869 0.9535849094390869
rl training, epoch0, iter0, batch144/1133, batch loss:0.9535849094390869, Training time:446.8024032115936
batch reward last col mean 0.4052096903324127 first col mean 0.4203624725341797 all mean 0.4044492244720459
0.9244352579116821 0.9244352579116821
rl training, epoch0, iter0, batch145/1133, batch loss:0.9244352579116821, Training time:449.5946650505066
batch reward last col mean 0.43540382385253906 first col mean 0.41826093196868896 all mean 0.428923100233078
0.9442388415336609 0.9442389011383057
rl training, epoch0, iter0, batch146/1133, batch loss:0.9442389011383057, Training time:452.56891536712646
batch reward last col mean 0.3885989487171173 first col mean 0.37706440687179565 all mean 0.39280927181243896
0.9304404854774475 0.9304404854774475
rl training, epoch0, iter0, batch147/1133, batch loss:0.9304404854774475, Training time:455.53321719169617
batch reward last col mean 0.38692599534988403 first col mean 0.38730382919311523 all mean 0.39257845282554626
0.9719086289405823 0.9719086289405823
rl training, epoch0, iter0, batch148/1133, batch loss:0.9719086289405823, Training time:460.59830379486084
batch reward last col mean 0.39231395721435547 first col mean 0.41393041610717773 all mean 0.39194178581237793
1.0166672468185425 1.0166672468185425
rl training, epoch0, iter0, batch149/1133, batch loss:1.0166672468185425, Training time:464.7063739299774
batch reward last col mean 0.4099597930908203 first col mean 0.4166385531425476 all mean 0.4060063660144806
0.9725340604782104 0.9725340604782104
rl training, epoch0, iter0, batch150/1133, batch loss:0.9725340604782104, Training time:468.6225280761719
batch reward last col mean 0.3966473639011383 first col mean 0.41404223442077637 all mean 0.405204176902771
0.9785233736038208 0.9785233736038208
rl training, epoch0, iter0, batch151/1133, batch loss:0.9785233736038208, Training time:471.4328353404999
batch reward last col mean 0.3887494206428528 first col mean 0.41519057750701904 all mean 0.39387765526771545
0.9181982278823853 0.91819828748703
rl training, epoch0, iter0, batch152/1133, batch loss:0.91819828748703, Training time:474.31839323043823
batch reward last col mean 0.4203032851219177 first col mean 0.41962671279907227 all mean 0.4191204011440277
0.9860438704490662 0.9860438704490662
rl training, epoch0, iter0, batch153/1133, batch loss:0.9860438704490662, Training time:476.803254365921
batch reward last col mean 0.4320833086967468 first col mean 0.4282374680042267 all mean 0.4357733428478241
0.9517837166786194 0.9517837166786194
rl training, epoch0, iter0, batch154/1133, batch loss:0.9517837166786194, Training time:479.5408661365509
batch reward last col mean 0.3954334259033203 first col mean 0.4034309983253479 all mean 0.3972313404083252
0.9553290605545044 0.9553290605545044
rl training, epoch0, iter0, batch155/1133, batch loss:0.9553290605545044, Training time:483.21360182762146
batch reward last col mean 0.40556007623672485 first col mean 0.4146832227706909 all mean 0.4143311679363251
0.919721782207489 0.919721782207489
rl training, epoch0, iter0, batch156/1133, batch loss:0.919721782207489, Training time:485.72362089157104
batch reward last col mean 0.41398563981056213 first col mean 0.41978883743286133 all mean 0.4126347303390503
0.9039111137390137 0.9039110541343689
rl training, epoch0, iter0, batch157/1133, batch loss:0.9039110541343689, Training time:488.58468317985535
batch reward last col mean 0.4537200927734375 first col mean 0.4008036255836487 all mean 0.44878172874450684
0.9538809061050415 0.953880786895752
rl training, epoch0, iter0, batch158/1133, batch loss:0.953880786895752, Training time:491.6624164581299
batch reward last col mean 0.3751823604106903 first col mean 0.3982483148574829 all mean 0.3728426694869995
0.8962698578834534 0.8962698578834534
rl training, epoch0, iter0, batch159/1133, batch loss:0.8962698578834534, Training time:494.2479920387268
batch reward last col mean 0.44791746139526367 first col mean 0.4035007953643799 all mean 0.4440979063510895
0.9245609641075134 0.9245609641075134
rl training, epoch0, iter0, batch160/1133, batch loss:0.9245609641075134, Training time:497.41229915618896
batch reward last col mean 0.419656902551651 first col mean 0.38553503155708313 all mean 0.41183486580848694
0.8749885559082031 0.8749885559082031
rl training, epoch0, iter0, batch161/1133, batch loss:0.8749885559082031, Training time:500.50499963760376
batch reward last col mean 0.39485594630241394 first col mean 0.3935782015323639 all mean 0.39447021484375
0.9214650392532349 0.9214650392532349
rl training, epoch0, iter0, batch162/1133, batch loss:0.9214650392532349, Training time:503.732524394989
batch reward last col mean 0.3972725570201874 first col mean 0.3998556137084961 all mean 0.39871862530708313
0.9605787396430969 0.9605787396430969
rl training, epoch0, iter0, batch163/1133, batch loss:0.9605787396430969, Training time:506.53739166259766
batch reward last col mean 0.42651933431625366 first col mean 0.3775125741958618 all mean 0.42397797107696533
0.9152882695198059 0.9152882695198059
rl training, epoch0, iter0, batch164/1133, batch loss:0.9152882695198059, Training time:510.4480881690979
batch reward last col mean 0.38617247343063354 first col mean 0.4100915193557739 all mean 0.38696011900901794
0.8860644102096558 0.8860644102096558
rl training, epoch0, iter0, batch165/1133, batch loss:0.8860644102096558, Training time:515.9101765155792
batch reward last col mean 0.3841485381126404 first col mean 0.41668757796287537 all mean 0.3977503478527069
0.9044568538665771 0.9044569134712219
rl training, epoch0, iter0, batch166/1133, batch loss:0.9044569134712219, Training time:518.8704161643982
batch reward last col mean 0.4740088880062103 first col mean 0.41103869676589966 all mean 0.46760988235473633
0.9803648591041565 0.9803648591041565
rl training, epoch0, iter0, batch167/1133, batch loss:0.9803648591041565, Training time:522.2453348636627
batch reward last col mean 0.37584587931632996 first col mean 0.41351965069770813 all mean 0.3780738115310669
0.8861122131347656 0.8861122131347656
rl training, epoch0, iter0, batch168/1133, batch loss:0.8861122131347656, Training time:524.8952083587646
batch reward last col mean 0.4206106662750244 first col mean 0.40722227096557617 all mean 0.41915300488471985
0.9298499822616577 0.9298499822616577
rl training, epoch0, iter0, batch169/1133, batch loss:0.9298499822616577, Training time:528.4406850337982
batch reward last col mean 0.45648428797721863 first col mean 0.41993096470832825 all mean 0.44669368863105774
0.9220711588859558 0.9220711588859558
rl training, epoch0, iter0, batch170/1133, batch loss:0.9220711588859558, Training time:532.3078198432922
batch reward last col mean 0.3740723133087158 first col mean 0.4092763364315033 all mean 0.378741055727005
0.8998959064483643 0.8998958468437195
rl training, epoch0, iter0, batch171/1133, batch loss:0.8998958468437195, Training time:536.0348291397095
batch reward last col mean 0.3617982864379883 first col mean 0.4153764247894287 all mean 0.37265199422836304
0.8539187908172607 0.8539188504219055
rl training, epoch0, iter0, batch172/1133, batch loss:0.8539188504219055, Training time:539.8009212017059
batch reward last col mean 0.38008004426956177 first col mean 0.3710331618785858 all mean 0.37601184844970703
0.8115305304527283 0.8115305304527283
rl training, epoch0, iter0, batch173/1133, batch loss:0.8115305304527283, Training time:543.0639011859894
batch reward last col mean 0.40090808272361755 first col mean 0.41448354721069336 all mean 0.399976909160614
0.9244902729988098 0.9244902729988098
rl training, epoch0, iter0, batch174/1133, batch loss:0.9244902729988098, Training time:546.5819511413574
batch reward last col mean 0.3886089324951172 first col mean 0.4194370210170746 all mean 0.3933492600917816
0.8970972299575806 0.8970972299575806
rl training, epoch0, iter0, batch175/1133, batch loss:0.8970972299575806, Training time:550.825311422348
batch reward last col mean 0.37286612391471863 first col mean 0.41205132007598877 all mean 0.37343931198120117
0.9151415228843689 0.9151414632797241
rl training, epoch0, iter0, batch176/1133, batch loss:0.9151414632797241, Training time:556.2581684589386
batch reward last col mean 0.4011816382408142 first col mean 0.39556413888931274 all mean 0.4036344885826111
0.8817352652549744 0.8817352652549744
rl training, epoch0, iter0, batch177/1133, batch loss:0.8817352652549744, Training time:560.9659140110016
batch reward last col mean 0.412156879901886 first col mean 0.4157997965812683 all mean 0.4171907305717468
0.8465554714202881 0.8465554714202881
rl training, epoch0, iter0, batch178/1133, batch loss:0.8465554714202881, Training time:564.8142304420471
batch reward last col mean 0.4094012379646301 first col mean 0.42243608832359314 all mean 0.4076528549194336
0.9608191847801208 0.9608192443847656
rl training, epoch0, iter0, batch179/1133, batch loss:0.9608192443847656, Training time:568.1786868572235
batch reward last col mean 0.419068306684494 first col mean 0.4080410599708557 all mean 0.42183172702789307
0.9472034573554993 0.9472034573554993
rl training, epoch0, iter0, batch180/1133, batch loss:0.9472034573554993, Training time:573.2741301059723
batch reward last col mean 0.3972204625606537 first col mean 0.39599794149398804 all mean 0.3994373381137848
0.8975651264190674 0.8975651264190674
rl training, epoch0, iter0, batch181/1133, batch loss:0.8975651264190674, Training time:576.6978619098663
batch reward last col mean 0.45289623737335205 first col mean 0.41322386264801025 all mean 0.44252702593803406
0.9616478681564331 0.9616478085517883
rl training, epoch0, iter0, batch182/1133, batch loss:0.9616478085517883, Training time:580.9309403896332
batch reward last col mean 0.3869924545288086 first col mean 0.4138193726539612 all mean 0.3831353187561035
0.9046804308891296 0.9046804308891296
rl training, epoch0, iter0, batch183/1133, batch loss:0.9046804308891296, Training time:584.9047393798828
batch reward last col mean 0.4467650055885315 first col mean 0.44565463066101074 all mean 0.44926100969314575
1.0044804811477661 1.0044806003570557
rl training, epoch0, iter0, batch184/1133, batch loss:1.0044806003570557, Training time:588.8897240161896
batch reward last col mean 0.4423409700393677 first col mean 0.4277765154838562 all mean 0.4413713812828064
0.9074536561965942 0.9074536561965942
rl training, epoch0, iter0, batch185/1133, batch loss:0.9074536561965942, Training time:594.1657342910767
batch reward last col mean 0.42162686586380005 first col mean 0.42374345660209656 all mean 0.42643287777900696
0.9670653939247131 0.9670653939247131
rl training, epoch0, iter0, batch186/1133, batch loss:0.9670653939247131, Training time:597.018622636795
batch reward last col mean 0.3929208219051361 first col mean 0.3981899619102478 all mean 0.39432626962661743
0.8367758989334106 0.8367758989334106
rl training, epoch0, iter0, batch187/1133, batch loss:0.8367758989334106, Training time:600.4659526348114
batch reward last col mean 0.4356051981449127 first col mean 0.44017282128334045 all mean 0.4344594180583954
0.9649350047111511 0.9649350047111511
rl training, epoch0, iter0, batch188/1133, batch loss:0.9649350047111511, Training time:603.0602495670319
batch reward last col mean 0.40601205825805664 first col mean 0.4082890450954437 all mean 0.4146145284175873
1.034375548362732 1.034375548362732
rl training, epoch0, iter0, batch189/1133, batch loss:1.034375548362732, Training time:605.915379524231
batch reward last col mean 0.4519369304180145 first col mean 0.435097336769104 all mean 0.44935378432273865
1.076197624206543 1.0761975049972534
rl training, epoch0, iter0, batch190/1133, batch loss:1.0761975049972534, Training time:608.4982953071594
batch reward last col mean 0.3917115032672882 first col mean 0.40340352058410645 all mean 0.4010326862335205
0.966604471206665 0.966604471206665
rl training, epoch0, iter0, batch191/1133, batch loss:0.966604471206665, Training time:611.6262209415436
batch reward last col mean 0.4294763207435608 first col mean 0.41216856241226196 all mean 0.4318713843822479
0.9616994261741638 0.9616994261741638
rl training, epoch0, iter0, batch192/1133, batch loss:0.9616994261741638, Training time:614.7034995555878
batch reward last col mean 0.4130988121032715 first col mean 0.4437050521373749 all mean 0.4225284457206726
0.9448832273483276 0.9448832273483276
rl training, epoch0, iter0, batch193/1133, batch loss:0.9448832273483276, Training time:617.5873916149139
batch reward last col mean 0.4271785020828247 first col mean 0.4369908273220062 all mean 0.4238426983356476
1.0182597637176514 1.0182597637176514
rl training, epoch0, iter0, batch194/1133, batch loss:1.0182597637176514, Training time:621.2466371059418
batch reward last col mean 0.4480632543563843 first col mean 0.46234095096588135 all mean 0.44079479575157166
0.9652475714683533 0.9652475118637085
rl training, epoch0, iter0, batch195/1133, batch loss:0.9652475118637085, Training time:624.2374408245087
batch reward last col mean 0.38046929240226746 first col mean 0.43585851788520813 all mean 0.3890193700790405
0.8857191801071167 0.8857191801071167
rl training, epoch0, iter0, batch196/1133, batch loss:0.8857191801071167, Training time:629.3780417442322
batch reward last col mean 0.41807690262794495 first col mean 0.4313024878501892 all mean 0.4172554016113281
0.997265100479126 0.9972649812698364
rl training, epoch0, iter0, batch197/1133, batch loss:0.9972649812698364, Training time:632.6693518161774
batch reward last col mean 0.4221523106098175 first col mean 0.4065753221511841 all mean 0.4195154011249542
0.98046875 0.9804688692092896
rl training, epoch0, iter0, batch198/1133, batch loss:0.9804688692092896, Training time:636.369647026062
batch reward last col mean 0.4272039532661438 first col mean 0.40417465567588806 all mean 0.42195791006088257
0.9805525541305542 0.9805525541305542
rl training, epoch0, iter0, batch199/1133, batch loss:0.9805525541305542, Training time:640.5919086933136
batch reward last col mean 0.40695682168006897 first col mean 0.38224363327026367 all mean 0.4023761749267578
0.8983309268951416 0.8983309268951416
rl training, epoch0, iter0, batch200/1133, batch loss:0.8983309268951416, Training time:645.9011900424957
batch reward last col mean 0.3970394432544708 first col mean 0.41482073068618774 all mean 0.4007906913757324
0.9406872987747192 0.9406872987747192
rl training, epoch0, iter0, batch201/1133, batch loss:0.9406872987747192, Training time:650.8535828590393
batch reward last col mean 0.43443843722343445 first col mean 0.4589289128780365 all mean 0.4404287040233612
1.035207986831665 1.035207986831665
rl training, epoch0, iter0, batch202/1133, batch loss:1.035207986831665, Training time:655.5920307636261
batch reward last col mean 0.41436538100242615 first col mean 0.4174339473247528 all mean 0.4134897291660309
0.9734839797019958 0.9734839797019958
rl training, epoch0, iter0, batch203/1133, batch loss:0.9734839797019958, Training time:661.7695786952972
batch reward last col mean 0.4655352830886841 first col mean 0.44763386249542236 all mean 0.45844507217407227
1.0834537744522095 1.0834537744522095
rl training, epoch0, iter0, batch204/1133, batch loss:1.0834537744522095, Training time:668.6751024723053
batch reward last col mean 0.4219608008861542 first col mean 0.4606836438179016 all mean 0.43030890822410583
0.9722597599029541 0.9722597599029541
rl training, epoch0, iter0, batch205/1133, batch loss:0.9722597599029541, Training time:672.6999855041504
batch reward last col mean 0.4418947398662567 first col mean 0.44265496730804443 all mean 0.44136911630630493
1.0023307800292969 1.0023307800292969
rl training, epoch0, iter0, batch206/1133, batch loss:1.0023307800292969, Training time:680.0380392074585
batch reward last col mean 0.42152681946754456 first col mean 0.4360619783401489 all mean 0.4252205491065979
0.972366213798523 0.9723661541938782
rl training, epoch0, iter0, batch207/1133, batch loss:0.9723661541938782, Training time:685.6782364845276
batch reward last col mean 0.4410998225212097 first col mean 0.43501171469688416 all mean 0.4320725202560425
1.0296307802200317 1.0296307802200317
rl training, epoch0, iter0, batch208/1133, batch loss:1.0296307802200317, Training time:691.4330141544342
batch reward last col mean 0.394979327917099 first col mean 0.42342501878738403 all mean 0.3995903432369232
0.9874784350395203 0.9874784350395203
rl training, epoch0, iter0, batch209/1133, batch loss:0.9874784350395203, Training time:699.6430125236511
batch reward last col mean 0.40384766459465027 first col mean 0.40547677874565125 all mean 0.40657514333724976
1.012344479560852 1.012344479560852
rl training, epoch0, iter0, batch210/1133, batch loss:1.012344479560852, Training time:705.7496418952942
batch reward last col mean 0.4248567223548889 first col mean 0.4136965870857239 all mean 0.4236581027507782
0.9737155437469482 0.9737155437469482
rl training, epoch0, iter0, batch211/1133, batch loss:0.9737155437469482, Training time:715.1524727344513
batch reward last col mean 0.4909045696258545 first col mean 0.4522421061992645 all mean 0.47887352108955383
1.1110531091690063 1.1110531091690063
rl training, epoch0, iter0, batch212/1133, batch loss:1.1110531091690063, Training time:720.922438621521
batch reward last col mean 0.43028101325035095 first col mean 0.4254920482635498 all mean 0.4246448576450348
0.9955441355705261 0.9955440163612366
rl training, epoch0, iter0, batch213/1133, batch loss:0.9955440163612366, Training time:729.7670278549194
batch reward last col mean 0.41765621304512024 first col mean 0.4172102212905884 all mean 0.41614243388175964
0.8871310353279114 0.8871310353279114
rl training, epoch0, iter0, batch214/1133, batch loss:0.8871310353279114, Training time:741.9406208992004
batch reward last col mean 0.39416730403900146 first col mean 0.3857501745223999 all mean 0.3979038596153259
0.8846797943115234 0.8846797943115234
rl training, epoch0, iter0, batch215/1133, batch loss:0.8846797943115234, Training time:750.1923208236694
batch reward last col mean 0.39046528935432434 first col mean 0.42841821908950806 all mean 0.3931073248386383
1.029178500175476 1.029178500175476
rl training, epoch0, iter0, batch216/1133, batch loss:1.029178500175476, Training time:757.9145741462708
batch reward last col mean 0.44199201464653015 first col mean 0.4164327085018158 all mean 0.44303590059280396
1.0431653261184692 1.0431653261184692
rl training, epoch0, iter0, batch217/1133, batch loss:1.0431653261184692, Training time:766.7081155776978
batch reward last col mean 0.3837122917175293 first col mean 0.4390716254711151 all mean 0.39775896072387695
1.0036449432373047 1.0036450624465942
rl training, epoch0, iter0, batch218/1133, batch loss:1.0036450624465942, Training time:774.0532929897308
batch reward last col mean 0.4854167103767395 first col mean 0.4446922838687897 all mean 0.47703075408935547
1.0266273021697998 1.0266273021697998
rl training, epoch0, iter0, batch219/1133, batch loss:1.0266273021697998, Training time:783.4813017845154
batch reward last col mean 0.44774505496025085 first col mean 0.43642574548721313 all mean 0.4411109387874603
0.9996203780174255 0.9996203780174255
rl training, epoch0, iter0, batch220/1133, batch loss:0.9996203780174255, Training time:791.0078885555267
batch reward last col mean 0.37684038281440735 first col mean 0.4103630781173706 all mean 0.3781760334968567
0.8658537268638611 0.8658537268638611
rl training, epoch0, iter0, batch221/1133, batch loss:0.8658537268638611, Training time:802.0687804222107
batch reward last col mean 0.41184893250465393 first col mean 0.42578595876693726 all mean 0.41607946157455444
0.9298261404037476 0.9298261404037476
rl training, epoch0, iter0, batch222/1133, batch loss:0.9298261404037476, Training time:809.001825094223
batch reward last col mean 0.4774770140647888 first col mean 0.4486219882965088 all mean 0.47232586145401
1.0525151491165161 1.0525151491165161
rl training, epoch0, iter0, batch223/1133, batch loss:1.0525151491165161, Training time:816.9496133327484
batch reward last col mean 0.3950703740119934 first col mean 0.44239234924316406 all mean 0.4041158854961395
1.0317394733428955 1.0317394733428955
rl training, epoch0, iter0, batch224/1133, batch loss:1.0317394733428955, Training time:826.309410572052
batch reward last col mean 0.42706528306007385 first col mean 0.4144107401371002 all mean 0.4282550513744354
0.9993917942047119 0.9993916749954224
rl training, epoch0, iter0, batch225/1133, batch loss:0.9993916749954224, Training time:833.0209009647369
batch reward last col mean 0.48769211769104004 first col mean 0.4785459339618683 all mean 0.48078522086143494
1.1617015600204468 1.1617015600204468
rl training, epoch0, iter0, batch226/1133, batch loss:1.1617015600204468, Training time:840.8045852184296
batch reward last col mean 0.39905622601509094 first col mean 0.43134957551956177 all mean 0.39741331338882446
0.9750474095344543 0.9750474095344543
rl training, epoch0, iter0, batch227/1133, batch loss:0.9750474095344543, Training time:848.0662822723389
batch reward last col mean 0.3897903859615326 first col mean 0.4227973222732544 all mean 0.39704978466033936
0.9394188523292542 0.9394188523292542
rl training, epoch0, iter0, batch228/1133, batch loss:0.9394188523292542, Training time:856.9904820919037
batch reward last col mean 0.4540374279022217 first col mean 0.44164735078811646 all mean 0.45193517208099365
0.9841148853302002 0.9841148853302002
rl training, epoch0, iter0, batch229/1133, batch loss:0.9841148853302002, Training time:863.2184016704559
batch reward last col mean 0.41195741295814514 first col mean 0.42843759059906006 all mean 0.4085068106651306
0.9447627067565918 0.9447627067565918
rl training, epoch0, iter0, batch230/1133, batch loss:0.9447627067565918, Training time:870.1709609031677
batch reward last col mean 0.4333888590335846 first col mean 0.4511221647262573 all mean 0.43476226925849915
1.0467325448989868 1.0467325448989868
rl training, epoch0, iter0, batch231/1133, batch loss:1.0467325448989868, Training time:878.2037518024445
batch reward last col mean 0.45186978578567505 first col mean 0.45142361521720886 all mean 0.45025184750556946
1.0740675926208496 1.0740675926208496
rl training, epoch0, iter0, batch232/1133, batch loss:1.0740675926208496, Training time:887.082008600235
batch reward last col mean 0.4328330159187317 first col mean 0.40933868288993835 all mean 0.42345693707466125
0.9824733734130859 0.9824733734130859
rl training, epoch0, iter0, batch233/1133, batch loss:0.9824733734130859, Training time:895.000661611557
batch reward last col mean 0.4438003897666931 first col mean 0.4656286835670471 all mean 0.4518510103225708
1.0460745096206665 1.0460745096206665
rl training, epoch0, iter0, batch234/1133, batch loss:1.0460745096206665, Training time:904.6714174747467
batch reward last col mean 0.4575531482696533 first col mean 0.43958166241645813 all mean 0.45476946234703064
1.0218371152877808 1.0218371152877808
rl training, epoch0, iter0, batch235/1133, batch loss:1.0218371152877808, Training time:911.8673284053802
batch reward last col mean 0.47315162420272827 first col mean 0.46479731798171997 all mean 0.47512781620025635
1.0414035320281982 1.0414035320281982
rl training, epoch0, iter0, batch236/1133, batch loss:1.0414035320281982, Training time:920.0130152702332
batch reward last col mean 0.3989989161491394 first col mean 0.4396328032016754 all mean 0.3976989686489105
0.895633339881897 0.895633339881897
rl training, epoch0, iter0, batch237/1133, batch loss:0.895633339881897, Training time:929.4086785316467
batch reward last col mean 0.4094785153865814 first col mean 0.44162553548812866 all mean 0.41689619421958923
0.9485329985618591 0.9485329389572144
rl training, epoch0, iter0, batch238/1133, batch loss:0.9485329389572144, Training time:936.9000256061554
batch reward last col mean 0.41032397747039795 first col mean 0.44340431690216064 all mean 0.41215047240257263
0.9911128282546997 0.9911128282546997
rl training, epoch0, iter0, batch239/1133, batch loss:0.9911128282546997, Training time:944.7348771095276
batch reward last col mean 0.41497305035591125 first col mean 0.4626469910144806 all mean 0.4199802875518799
0.9640060067176819 0.9640060067176819
rl training, epoch0, iter0, batch240/1133, batch loss:0.9640060067176819, Training time:953.9804124832153
batch reward last col mean 0.502500057220459 first col mean 0.4462020993232727 all mean 0.4933641850948334
1.0341941118240356 1.0341941118240356
rl training, epoch0, iter0, batch241/1133, batch loss:1.0341941118240356, Training time:963.9597790241241
batch reward last col mean 0.42289525270462036 first col mean 0.3853958249092102 all mean 0.41830289363861084
0.9762857556343079 0.9762857556343079
rl training, epoch0, iter0, batch242/1133, batch loss:0.9762857556343079, Training time:971.3665385246277
batch reward last col mean 0.4359191656112671 first col mean 0.444840669631958 all mean 0.4391113817691803
1.0255541801452637 1.0255541801452637
rl training, epoch0, iter0, batch243/1133, batch loss:1.0255541801452637, Training time:983.3576958179474
batch reward last col mean 0.40937861800193787 first col mean 0.4101320207118988 all mean 0.41280749440193176
0.9147143363952637 0.9147142171859741
rl training, epoch0, iter0, batch244/1133, batch loss:0.9147142171859741, Training time:989.871250629425
batch reward last col mean 0.45319727063179016 first col mean 0.4127025902271271 all mean 0.44860029220581055
1.0038384199142456 1.0038384199142456
rl training, epoch0, iter0, batch245/1133, batch loss:1.0038384199142456, Training time:999.075300693512
batch reward last col mean 0.4245171546936035 first col mean 0.42676183581352234 all mean 0.4265308082103729
0.9847378134727478 0.984737753868103
rl training, epoch0, iter0, batch246/1133, batch loss:0.984737753868103, Training time:1007.9730362892151
batch reward last col mean 0.4461137652397156 first col mean 0.43594223260879517 all mean 0.43961387872695923
0.9551079273223877 0.9551079273223877
rl training, epoch0, iter0, batch247/1133, batch loss:0.9551079273223877, Training time:1017.6815159320831
batch reward last col mean 0.44550201296806335 first col mean 0.44560909271240234 all mean 0.44560232758522034
0.9467485547065735 0.9467485547065735
rl training, epoch0, iter0, batch248/1133, batch loss:0.9467485547065735, Training time:1025.4566197395325
batch reward last col mean 0.413978636264801 first col mean 0.4245642125606537 all mean 0.417696088552475
0.9283798336982727 0.9283798933029175
rl training, epoch0, iter0, batch249/1133, batch loss:0.9283798933029175, Training time:1034.9729120731354
batch reward last col mean 0.48971542716026306 first col mean 0.465197890996933 all mean 0.48698678612709045
1.04661226272583 1.0466121435165405
rl training, epoch0, iter0, batch250/1133, batch loss:1.0466121435165405, Training time:1042.1406121253967
batch reward last col mean 0.4201148748397827 first col mean 0.44242340326309204 all mean 0.4232625365257263
1.021616816520691 1.0216169357299805
rl training, epoch0, iter0, batch251/1133, batch loss:1.0216169357299805, Training time:1050.4334177970886
batch reward last col mean 0.41092348098754883 first col mean 0.44095897674560547 all mean 0.40563827753067017
0.8321954607963562 0.8321953415870667
rl training, epoch0, iter0, batch252/1133, batch loss:0.8321953415870667, Training time:1058.734272480011
batch reward last col mean 0.4478474259376526 first col mean 0.4305945634841919 all mean 0.44121283292770386
0.8885555267333984 0.8885555267333984
rl training, epoch0, iter0, batch253/1133, batch loss:0.8885555267333984, Training time:1067.1927387714386
batch reward last col mean 0.421241819858551 first col mean 0.42633292078971863 all mean 0.4229624569416046
0.9148136377334595 0.9148135781288147
rl training, epoch0, iter0, batch254/1133, batch loss:0.9148135781288147, Training time:1073.3107504844666
batch reward last col mean 0.41700804233551025 first col mean 0.43414759635925293 all mean 0.4208601713180542
0.9487852454185486 0.9487852454185486
rl training, epoch0, iter0, batch255/1133, batch loss:0.9487852454185486, Training time:1079.3848776817322
batch reward last col mean 0.4287206828594208 first col mean 0.4598945677280426 all mean 0.4382074475288391
0.9889267683029175 0.9889267683029175
rl training, epoch0, iter0, batch256/1133, batch loss:0.9889267683029175, Training time:1087.7073230743408
batch reward last col mean 0.4178798794746399 first col mean 0.3974045217037201 all mean 0.40993809700012207
0.8748507499694824 0.8748507499694824
rl training, epoch0, iter0, batch257/1133, batch loss:0.8748507499694824, Training time:1094.416429758072
batch reward last col mean 0.4201390743255615 first col mean 0.4569973349571228 all mean 0.42536112666130066
0.9506123065948486 0.9506123065948486
rl training, epoch0, iter0, batch258/1133, batch loss:0.9506123065948486, Training time:1099.6305730342865
batch reward last col mean 0.4551510214805603 first col mean 0.4192720353603363 all mean 0.4488667845726013
0.9867725372314453 0.9867725372314453
rl training, epoch0, iter0, batch259/1133, batch loss:0.9867725372314453, Training time:1106.155268907547
batch reward last col mean 0.5051265358924866 first col mean 0.43268945813179016 all mean 0.4904070198535919
1.0116149187088013 1.0116149187088013
rl training, epoch0, iter0, batch260/1133, batch loss:1.0116149187088013, Training time:1112.323059797287
batch reward last col mean 0.4533947706222534 first col mean 0.4378746747970581 all mean 0.454924076795578
1.0308756828308105 1.0308756828308105
rl training, epoch0, iter0, batch261/1133, batch loss:1.0308756828308105, Training time:1119.6566989421844
batch reward last col mean 0.41391244530677795 first col mean 0.4118739366531372 all mean 0.41708096861839294
1.0273315906524658 1.0273315906524658
rl training, epoch0, iter0, batch262/1133, batch loss:1.0273315906524658, Training time:1128.698984861374
batch reward last col mean 0.3837081491947174 first col mean 0.38982000946998596 all mean 0.3929207921028137
0.8659268021583557 0.8659268021583557
rl training, epoch0, iter0, batch263/1133, batch loss:0.8659268021583557, Training time:1135.8734514713287
batch reward last col mean 0.4161136746406555 first col mean 0.4433620572090149 all mean 0.4241454303264618
0.956572949886322 0.956572949886322
rl training, epoch0, iter0, batch264/1133, batch loss:0.956572949886322, Training time:1142.0913009643555
batch reward last col mean 0.356388121843338 first col mean 0.4146372973918915 all mean 0.37126344442367554
0.8055450320243835 0.8055450320243835
rl training, epoch0, iter0, batch265/1133, batch loss:0.8055450320243835, Training time:1147.352926492691
batch reward last col mean 0.44602108001708984 first col mean 0.43542468547821045 all mean 0.44460517168045044
0.9599065184593201 0.9599065184593201
rl training, epoch0, iter0, batch266/1133, batch loss:0.9599065184593201, Training time:1156.9908049106598
batch reward last col mean 0.41945600509643555 first col mean 0.427725613117218 all mean 0.4275413453578949
0.9266723394393921 0.9266723394393921
rl training, epoch0, iter0, batch267/1133, batch loss:0.9266723394393921, Training time:1163.2116882801056
batch reward last col mean 0.3973432183265686 first col mean 0.435903400182724 all mean 0.40883058309555054
0.9681982398033142 0.9681982398033142
rl training, epoch0, iter0, batch268/1133, batch loss:0.9681982398033142, Training time:1169.9952347278595
batch reward last col mean 0.41241154074668884 first col mean 0.43382227420806885 all mean 0.4157705008983612
0.9832432270050049 0.9832431674003601
rl training, epoch0, iter0, batch269/1133, batch loss:0.9832431674003601, Training time:1179.1432435512543
batch reward last col mean 0.3986319601535797 first col mean 0.46828266978263855 all mean 0.4099082350730896
0.962092399597168 0.962092399597168
rl training, epoch0, iter0, batch270/1133, batch loss:0.962092399597168, Training time:1186.2930612564087
batch reward last col mean 0.4228043854236603 first col mean 0.4493159353733063 all mean 0.42978814244270325
0.9684605002403259 0.9684605002403259
rl training, epoch0, iter0, batch271/1133, batch loss:0.9684605002403259, Training time:1194.500592470169
batch reward last col mean 0.42057400941848755 first col mean 0.444391131401062 all mean 0.42097094655036926
0.9158042669296265 0.9158042669296265
rl training, epoch0, iter0, batch272/1133, batch loss:0.9158042669296265, Training time:1202.814965248108
batch reward last col mean 0.4403843879699707 first col mean 0.4343899190425873 all mean 0.43920204043388367
0.9719039797782898 0.9719039797782898
rl training, epoch0, iter0, batch273/1133, batch loss:0.9719039797782898, Training time:1212.3586173057556
batch reward last col mean 0.42987459897994995 first col mean 0.4505354166030884 all mean 0.43948227167129517
0.9661945104598999 0.9661945104598999
rl training, epoch0, iter0, batch274/1133, batch loss:0.9661945104598999, Training time:1219.9215042591095
batch reward last col mean 0.47638627886772156 first col mean 0.43934452533721924 all mean 0.47047632932662964
1.0605958700180054 1.0605958700180054
rl training, epoch0, iter0, batch275/1133, batch loss:1.0605958700180054, Training time:1228.2596673965454
batch reward last col mean 0.4032566547393799 first col mean 0.452046662569046 all mean 0.4083308279514313
0.8708574771881104 0.8708574771881104
rl training, epoch0, iter0, batch276/1133, batch loss:0.8708574771881104, Training time:1237.595444202423
batch reward last col mean 0.4238166809082031 first col mean 0.3859127163887024 all mean 0.41718700528144836
0.9184840321540833 0.9184840321540833
rl training, epoch0, iter0, batch277/1133, batch loss:0.9184840321540833, Training time:1245.3212633132935
batch reward last col mean 0.48169276118278503 first col mean 0.4731122553348541 all mean 0.46991226077079773
0.9996554851531982 0.9996554851531982
rl training, epoch0, iter0, batch278/1133, batch loss:0.9996554851531982, Training time:1254.959035396576
batch reward last col mean 0.42021578550338745 first col mean 0.40809017419815063 all mean 0.4233234226703644
0.9490991830825806 0.9490991830825806
rl training, epoch0, iter0, batch279/1133, batch loss:0.9490991830825806, Training time:1264.4549255371094
batch reward last col mean 0.4755138158798218 first col mean 0.4460201859474182 all mean 0.4709068834781647
0.9929525256156921 0.9929525256156921
rl training, epoch0, iter0, batch280/1133, batch loss:0.9929525256156921, Training time:1273.3882477283478
batch reward last col mean 0.4507564306259155 first col mean 0.3882606029510498 all mean 0.4486105442047119
0.9735975861549377 0.9735975861549377
rl training, epoch0, iter0, batch281/1133, batch loss:0.9735975861549377, Training time:1280.9984195232391
batch reward last col mean 0.4257301092147827 first col mean 0.43958696722984314 all mean 0.42698660492897034
0.9539241790771484 0.9539241790771484
rl training, epoch0, iter0, batch282/1133, batch loss:0.9539241790771484, Training time:1290.8932304382324
batch reward last col mean 0.42519670724868774 first col mean 0.43146854639053345 all mean 0.4259272813796997
0.9805670380592346 0.9805670380592346
rl training, epoch0, iter0, batch283/1133, batch loss:0.9805670380592346, Training time:1299.0248334407806
batch reward last col mean 0.4380662739276886 first col mean 0.4248890280723572 all mean 0.4422806203365326
0.999518096446991 0.999518096446991
rl training, epoch0, iter0, batch284/1133, batch loss:0.999518096446991, Training time:1309.8937265872955
batch reward last col mean 0.4269268214702606 first col mean 0.4512840211391449 all mean 0.42686545848846436
0.910171627998352 0.910171627998352
rl training, epoch0, iter0, batch285/1133, batch loss:0.910171627998352, Training time:1317.4879698753357
batch reward last col mean 0.4181760847568512 first col mean 0.47834935784339905 all mean 0.42556092143058777
0.9642157554626465 0.9642157554626465
rl training, epoch0, iter0, batch286/1133, batch loss:0.9642157554626465, Training time:1326.4157929420471
batch reward last col mean 0.44320154190063477 first col mean 0.4403759837150574 all mean 0.43856218457221985
0.9187309741973877 0.9187309741973877
rl training, epoch0, iter0, batch287/1133, batch loss:0.9187309741973877, Training time:1339.8249735832214
batch reward last col mean 0.37307316064834595 first col mean 0.43070846796035767 all mean 0.38455089926719666
0.80201655626297 0.80201655626297
rl training, epoch0, iter0, batch288/1133, batch loss:0.80201655626297, Training time:1353.240956544876
batch reward last col mean 0.39315998554229736 first col mean 0.4517551064491272 all mean 0.40058040618896484
0.8548526763916016 0.8548526763916016
rl training, epoch0, iter0, batch289/1133, batch loss:0.8548526763916016, Training time:1364.1559057235718
batch reward last col mean 0.3881775736808777 first col mean 0.45579272508621216 all mean 0.4002052843570709
0.9302639961242676 0.930263876914978
rl training, epoch0, iter0, batch290/1133, batch loss:0.930263876914978, Training time:1371.798434972763
batch reward last col mean 0.44098764657974243 first col mean 0.4295904040336609 all mean 0.43671712279319763
0.9340394735336304 0.9340394735336304
rl training, epoch0, iter0, batch291/1133, batch loss:0.9340394735336304, Training time:1381.925270318985
batch reward last col mean 0.3950519263744354 first col mean 0.47527170181274414 all mean 0.4117102026939392
0.9819429516792297 0.9819429516792297
rl training, epoch0, iter0, batch292/1133, batch loss:0.9819429516792297, Training time:1390.9235417842865
batch reward last col mean 0.4255201816558838 first col mean 0.4670875668525696 all mean 0.43084266781806946
0.9048629999160767 0.9048629999160767
rl training, epoch0, iter0, batch293/1133, batch loss:0.9048629999160767, Training time:1401.2661612033844
batch reward last col mean 0.42349773645401 first col mean 0.44832372665405273 all mean 0.4194685220718384
0.9249665141105652 0.9249665141105652
rl training, epoch0, iter0, batch294/1133, batch loss:0.9249665141105652, Training time:1410.5858607292175
batch reward last col mean 0.4687895178794861 first col mean 0.46085771918296814 all mean 0.46341824531555176
1.0060285329818726 1.006028652191162
rl training, epoch0, iter0, batch295/1133, batch loss:1.006028652191162, Training time:1423.667234659195
batch reward last col mean 0.45283418893814087 first col mean 0.4451135993003845 all mean 0.4401969313621521
0.9325182437896729 0.9325183033943176
rl training, epoch0, iter0, batch296/1133, batch loss:0.9325183033943176, Training time:1433.5630741119385
batch reward last col mean 0.4323993921279907 first col mean 0.4243646264076233 all mean 0.43230634927749634
0.9218408465385437 0.9218408465385437
rl training, epoch0, iter0, batch297/1133, batch loss:0.9218408465385437, Training time:1444.727877855301
batch reward last col mean 0.4585379958152771 first col mean 0.4558822810649872 all mean 0.45513343811035156
0.8933432102203369 0.8933432102203369
rl training, epoch0, iter0, batch298/1133, batch loss:0.8933432102203369, Training time:1455.7108135223389
batch reward last col mean 0.4077451825141907 first col mean 0.43712401390075684 all mean 0.41143301129341125
0.8365699648857117 0.8365699648857117
rl training, epoch0, iter0, batch299/1133, batch loss:0.8365699648857117, Training time:1467.2554202079773
batch reward last col mean 0.4181581735610962 first col mean 0.4582810401916504 all mean 0.41653287410736084
0.8568133115768433 0.8568133115768433
rl training, epoch0, iter0, batch300/1133, batch loss:0.8568133115768433, Training time:1480.5607883930206
batch reward last col mean 0.42739447951316833 first col mean 0.45589882135391235 all mean 0.4232903718948364
0.9120859503746033 0.9120859503746033
rl training, epoch0, iter0, batch301/1133, batch loss:0.9120859503746033, Training time:1491.6266496181488
batch reward last col mean 0.43757879734039307 first col mean 0.4495919346809387 all mean 0.4451165199279785
0.8782749176025391 0.8782749176025391
rl training, epoch0, iter0, batch302/1133, batch loss:0.8782749176025391, Training time:1506.7243497371674
batch reward last col mean 0.43404656648635864 first col mean 0.4410731792449951 all mean 0.4331777095794678
0.823390007019043 0.823390007019043
rl training, epoch0, iter0, batch303/1133, batch loss:0.823390007019043, Training time:1521.352468252182
batch reward last col mean 0.4068942666053772 first col mean 0.4622008800506592 all mean 0.41521984338760376
0.9410588145256042 0.9410588145256042
rl training, epoch0, iter0, batch304/1133, batch loss:0.9410588145256042, Training time:1539.3671700954437
batch reward last col mean 0.4106655716896057 first col mean 0.4166399836540222 all mean 0.41029515862464905
0.8421026468276978 0.8421026468276978
rl training, epoch0, iter0, batch305/1133, batch loss:0.8421026468276978, Training time:1553.7591624259949
batch reward last col mean 0.46877244114875793 first col mean 0.43732428550720215 all mean 0.46656495332717896
0.9112027883529663 0.9112027883529663
rl training, epoch0, iter0, batch306/1133, batch loss:0.9112027883529663, Training time:1568.7928216457367
batch reward last col mean 0.44456201791763306 first col mean 0.4625081419944763 all mean 0.4447585642337799
0.8455920219421387 0.8455920219421387
rl training, epoch0, iter0, batch307/1133, batch loss:0.8455920219421387, Training time:1582.6672163009644
batch reward last col mean 0.44600996375083923 first col mean 0.4256843030452728 all mean 0.4523079991340637
0.9288804531097412 0.9288804531097412
rl training, epoch0, iter0, batch308/1133, batch loss:0.9288804531097412, Training time:1598.5648128986359
batch reward last col mean 0.4028298556804657 first col mean 0.396436870098114 all mean 0.40328067541122437
0.8436875343322754 0.8436874747276306
rl training, epoch0, iter0, batch309/1133, batch loss:0.8436874747276306, Training time:1612.7758355140686
batch reward last col mean 0.4654337167739868 first col mean 0.42869657278060913 all mean 0.46005725860595703
0.8714519143104553 0.8714519143104553
rl training, epoch0, iter0, batch310/1133, batch loss:0.8714519143104553, Training time:1626.8173456192017
batch reward last col mean 0.35455793142318726 first col mean 0.38175344467163086 all mean 0.3546335697174072
0.8157749772071838 0.8157749176025391
rl training, epoch0, iter0, batch311/1133, batch loss:0.8157749176025391, Training time:1637.767646074295
batch reward last col mean 0.39781704545021057 first col mean 0.41357776522636414 all mean 0.40198513865470886
0.8273596167564392 0.8273596167564392
rl training, epoch0, iter0, batch312/1133, batch loss:0.8273596167564392, Training time:1652.7913727760315
batch reward last col mean 0.4100901782512665 first col mean 0.4115593433380127 all mean 0.4228071868419647
0.901732861995697 0.901732861995697
rl training, epoch0, iter0, batch313/1133, batch loss:0.901732861995697, Training time:1665.2193493843079
batch reward last col mean 0.42667439579963684 first col mean 0.4129865765571594 all mean 0.42455264925956726
0.8535670042037964 0.8535670042037964
rl training, epoch0, iter0, batch314/1133, batch loss:0.8535670042037964, Training time:1681.6944015026093
batch reward last col mean 0.42833179235458374 first col mean 0.4707998037338257 all mean 0.4406461715698242
0.9230127930641174 0.9230127930641174
rl training, epoch0, iter0, batch315/1133, batch loss:0.9230127930641174, Training time:1697.1442413330078
batch reward last col mean 0.46069514751434326 first col mean 0.4198194146156311 all mean 0.44845709204673767
0.9010699391365051 0.9010698795318604
rl training, epoch0, iter0, batch316/1133, batch loss:0.9010698795318604, Training time:1713.508399963379
batch reward last col mean 0.44373619556427 first col mean 0.47845029830932617 all mean 0.44656550884246826
0.9335887432098389 0.9335887432098389
rl training, epoch0, iter0, batch317/1133, batch loss:0.9335887432098389, Training time:1727.5045981407166
batch reward last col mean 0.46557965874671936 first col mean 0.45910966396331787 all mean 0.448456346988678
0.9262928366661072 0.9262928366661072
rl training, epoch0, iter0, batch318/1133, batch loss:0.9262928366661072, Training time:1744.5218660831451
batch reward last col mean 0.45113709568977356 first col mean 0.4203377962112427 all mean 0.4467168152332306
0.9191562533378601 0.9191561937332153
rl training, epoch0, iter0, batch319/1133, batch loss:0.9191561937332153, Training time:1761.2843012809753
batch reward last col mean 0.49758246541023254 first col mean 0.4703328609466553 all mean 0.49104738235473633
0.9655628800392151 0.9655628800392151
rl training, epoch0, iter0, batch320/1133, batch loss:0.9655628800392151, Training time:1776.6328694820404
batch reward last col mean 0.4592994153499603 first col mean 0.4822916090488434 all mean 0.46255701780319214
0.9583947658538818 0.9583947658538818
rl training, epoch0, iter0, batch321/1133, batch loss:0.9583947658538818, Training time:1794.3924810886383
batch reward last col mean 0.43949246406555176 first col mean 0.4724450409412384 all mean 0.4455941319465637
0.9445111155509949 0.9445111155509949
rl training, epoch0, iter0, batch322/1133, batch loss:0.9445111155509949, Training time:1814.9091744422913
batch reward last col mean 0.40280625224113464 first col mean 0.4076641798019409 all mean 0.4007761776447296
0.8268916010856628 0.8268915414810181
rl training, epoch0, iter0, batch323/1133, batch loss:0.8268915414810181, Training time:1833.2006306648254
batch reward last col mean 0.4235271215438843 first col mean 0.4227549433708191 all mean 0.39939507842063904
0.8225124478340149 0.8225124478340149
rl training, epoch0, iter0, batch324/1133, batch loss:0.8225124478340149, Training time:1851.9126245975494
batch reward last col mean 0.4323812425136566 first col mean 0.4136286675930023 all mean 0.42337992787361145
0.8396323323249817 0.8396323323249817
rl training, epoch0, iter0, batch325/1133, batch loss:0.8396323323249817, Training time:1870.652093887329
batch reward last col mean 0.46242809295654297 first col mean 0.4324268400669098 all mean 0.44104889035224915
0.8840657472610474 0.8840657472610474
rl training, epoch0, iter0, batch326/1133, batch loss:0.8840657472610474, Training time:1888.5242335796356
batch reward last col mean 0.4599837362766266 first col mean 0.44952982664108276 all mean 0.4608750641345978
0.8409385681152344 0.8409385681152344
rl training, epoch0, iter0, batch327/1133, batch loss:0.8409385681152344, Training time:1905.7154245376587
batch reward last col mean 0.4660486578941345 first col mean 0.4165816903114319 all mean 0.4672120213508606
0.8509785532951355 0.8509785532951355
rl training, epoch0, iter0, batch328/1133, batch loss:0.8509785532951355, Training time:1922.9575562477112
batch reward last col mean 0.4346151053905487 first col mean 0.46921417117118835 all mean 0.43902602791786194
0.8957061171531677 0.8957061171531677
rl training, epoch0, iter0, batch329/1133, batch loss:0.8957061171531677, Training time:1940.5611786842346
batch reward last col mean 0.44253063201904297 first col mean 0.4456999897956848 all mean 0.4602048993110657
0.9397065043449402 0.9397064447402954
rl training, epoch0, iter0, batch330/1133, batch loss:0.9397064447402954, Training time:1957.9512531757355
batch reward last col mean 0.4085537791252136 first col mean 0.47399571537971497 all mean 0.43073421716690063
0.8991367816925049 0.8991367816925049
rl training, epoch0, iter0, batch331/1133, batch loss:0.8991367816925049, Training time:1975.1405491828918
batch reward last col mean 0.4218822121620178 first col mean 0.43544721603393555 all mean 0.4236393868923187
0.8945068717002869 0.8945068717002869
rl training, epoch0, iter0, batch332/1133, batch loss:0.8945068717002869, Training time:1992.569587469101
batch reward last col mean 0.4485594928264618 first col mean 0.47406119108200073 all mean 0.4712080657482147
1.0055640935897827 1.0055640935897827
rl training, epoch0, iter0, batch333/1133, batch loss:1.0055640935897827, Training time:2010.1806237697601
batch reward last col mean 0.3816642165184021 first col mean 0.444658100605011 all mean 0.4093721807003021
0.9066656231880188 0.9066656231880188
rl training, epoch0, iter0, batch334/1133, batch loss:0.9066656231880188, Training time:2027.4744081497192
batch reward last col mean 0.43054136633872986 first col mean 0.49488991498947144 all mean 0.45159897208213806
0.9384075999259949 0.9384075999259949
rl training, epoch0, iter0, batch335/1133, batch loss:0.9384075999259949, Training time:2045.1548545360565
batch reward last col mean 0.4444490075111389 first col mean 0.4628816246986389 all mean 0.4319632053375244
0.9059328436851501 0.9059328436851501
rl training, epoch0, iter0, batch336/1133, batch loss:0.9059328436851501, Training time:2062.2711324691772
batch reward last col mean 0.44373631477355957 first col mean 0.4719146490097046 all mean 0.4567488729953766
1.0481058359146118 1.0481058359146118
rl training, epoch0, iter0, batch337/1133, batch loss:1.0481058359146118, Training time:2079.4135932922363
batch reward last col mean 0.5251246094703674 first col mean 0.4962195158004761 all mean 0.5156729817390442
1.0463510751724243 1.0463510751724243
rl training, epoch0, iter0, batch338/1133, batch loss:1.0463510751724243, Training time:2096.440531730652
batch reward last col mean 0.4937359690666199 first col mean 0.4799177050590515 all mean 0.5019312500953674
1.038411021232605 1.0384111404418945
rl training, epoch0, iter0, batch339/1133, batch loss:1.0384111404418945, Training time:2115.9338245391846
batch reward last col mean 0.47323960065841675 first col mean 0.4745495319366455 all mean 0.46333810687065125
1.0262566804885864 1.0262565612792969
rl training, epoch0, iter0, batch340/1133, batch loss:1.0262565612792969, Training time:2136.001636505127
batch reward last col mean 0.42860841751098633 first col mean 0.47751253843307495 all mean 0.44759899377822876
1.0192983150482178 1.0192983150482178
rl training, epoch0, iter0, batch341/1133, batch loss:1.0192983150482178, Training time:2156.494223833084
batch reward last col mean 0.4714468717575073 first col mean 0.49812477827072144 all mean 0.4705018401145935
1.064451813697815 1.064451813697815
rl training, epoch0, iter0, batch342/1133, batch loss:1.064451813697815, Training time:2177.4739940166473
batch reward last col mean 0.48060983419418335 first col mean 0.5037354230880737 all mean 0.5073094964027405
1.100510835647583 1.100510835647583
rl training, epoch0, iter0, batch343/1133, batch loss:1.100510835647583, Training time:2194.5459990501404
batch reward last col mean 0.528498649597168 first col mean 0.5005164742469788 all mean 0.5011307597160339
1.0439404249191284 1.043940544128418
rl training, epoch0, iter0, batch344/1133, batch loss:1.043940544128418, Training time:2211.8164353370667
batch reward last col mean 0.5067528486251831 first col mean 0.5343225002288818 all mean 0.49835440516471863
1.1071546077728271 1.1071546077728271
rl training, epoch0, iter0, batch345/1133, batch loss:1.1071546077728271, Training time:2228.8336987495422
batch reward last col mean 0.44657161831855774 first col mean 0.484871506690979 all mean 0.46533676981925964
1.0352281332015991 1.0352281332015991
rl training, epoch0, iter0, batch346/1133, batch loss:1.0352281332015991, Training time:2245.880985021591
batch reward last col mean 0.5068776607513428 first col mean 0.5069646835327148 all mean 0.49469438195228577
1.093403935432434 1.093403935432434
rl training, epoch0, iter0, batch347/1133, batch loss:1.093403935432434, Training time:2262.8487594127655
batch reward last col mean 0.45321035385131836 first col mean 0.49986833333969116 all mean 0.47693413496017456
1.0341341495513916 1.0341341495513916
rl training, epoch0, iter0, batch348/1133, batch loss:1.0341341495513916, Training time:2279.815081834793
batch reward last col mean 0.48663783073425293 first col mean 0.4925135374069214 all mean 0.505524754524231
1.0785713195800781 1.0785713195800781
rl training, epoch0, iter0, batch349/1133, batch loss:1.0785713195800781, Training time:2297.531176805496
batch reward last col mean 0.5288892984390259 first col mean 0.5028079152107239 all mean 0.4928949177265167
1.098223090171814 1.098223090171814
rl training, epoch0, iter0, batch350/1133, batch loss:1.098223090171814, Training time:2315.207958459854
batch reward last col mean 0.5077048540115356 first col mean 0.4988451302051544 all mean 0.5285603404045105
1.165091872215271 1.165091872215271
rl training, epoch0, iter0, batch351/1133, batch loss:1.165091872215271, Training time:2335.391075372696
batch reward last col mean 0.5311440825462341 first col mean 0.5090466141700745 all mean 0.5368738770484924
1.2720422744750977 1.2720422744750977
rl training, epoch0, iter0, batch352/1133, batch loss:1.2720422744750977, Training time:2353.4903604984283
batch reward last col mean 0.4725830852985382 first col mean 0.5100782513618469 all mean 0.48780521750450134
1.1448066234588623 1.1448066234588623
rl training, epoch0, iter0, batch353/1133, batch loss:1.1448066234588623, Training time:2373.1239337921143
batch reward last col mean 0.5370395183563232 first col mean 0.4991092085838318 all mean 0.5152438282966614
1.1902559995651245 1.1902559995651245
rl training, epoch0, iter0, batch354/1133, batch loss:1.1902559995651245, Training time:2393.436532497406
batch reward last col mean 0.4057422876358032 first col mean 0.5088123679161072 all mean 0.46006128191947937
1.1151108741760254 1.1151107549667358
rl training, epoch0, iter0, batch355/1133, batch loss:1.1151107549667358, Training time:2411.6040704250336
batch reward last col mean 0.509129524230957 first col mean 0.533927321434021 all mean 0.5166897177696228
1.1572555303573608 1.1572556495666504
rl training, epoch0, iter0, batch356/1133, batch loss:1.1572556495666504, Training time:2429.484272956848
batch reward last col mean 0.550597071647644 first col mean 0.489530086517334 all mean 0.5073425769805908
1.1877129077911377 1.1877129077911377
rl training, epoch0, iter0, batch357/1133, batch loss:1.1877129077911377, Training time:2446.929217815399
batch reward last col mean 0.49626198410987854 first col mean 0.4823709726333618 all mean 0.5001076459884644
1.1456900835037231 1.1456900835037231
rl training, epoch0, iter0, batch358/1133, batch loss:1.1456900835037231, Training time:2464.202120780945
batch reward last col mean 0.4757023751735687 first col mean 0.5136885046958923 all mean 0.4944460391998291
1.1261048316955566 1.1261048316955566
rl training, epoch0, iter0, batch359/1133, batch loss:1.1261048316955566, Training time:2481.718440771103
batch reward last col mean 0.4791587293148041 first col mean 0.48017728328704834 all mean 0.4912380576133728
1.192275881767273 1.192275881767273
rl training, epoch0, iter0, batch360/1133, batch loss:1.192275881767273, Training time:2499.0065512657166
batch reward last col mean 0.51680588722229 first col mean 0.5207221508026123 all mean 0.48372718691825867
1.1522557735443115 1.1522557735443115
rl training, epoch0, iter0, batch361/1133, batch loss:1.1522557735443115, Training time:2516.362800836563
batch reward last col mean 0.4764644503593445 first col mean 0.4884757995605469 all mean 0.4794502258300781
1.0971527099609375 1.0971527099609375
rl training, epoch0, iter0, batch362/1133, batch loss:1.0971527099609375, Training time:2534.442179918289
batch reward last col mean 0.445028692483902 first col mean 0.4971829652786255 all mean 0.45043113827705383
1.0723944902420044 1.0723944902420044
rl training, epoch0, iter0, batch363/1133, batch loss:1.0723944902420044, Training time:2552.028745651245
batch reward last col mean 0.4415701627731323 first col mean 0.48277029395103455 all mean 0.46203240752220154
1.1881773471832275 1.1881773471832275
rl training, epoch0, iter0, batch364/1133, batch loss:1.1881773471832275, Training time:2569.3693885803223
batch reward last col mean 0.4630151391029358 first col mean 0.5356021523475647 all mean 0.47564658522605896
1.1298080682754517 1.1298080682754517
rl training, epoch0, iter0, batch365/1133, batch loss:1.1298080682754517, Training time:2588.3638665676117
batch reward last col mean 0.45119792222976685 first col mean 0.5049360394477844 all mean 0.504857063293457
1.1899709701538086 1.1899709701538086
rl training, epoch0, iter0, batch366/1133, batch loss:1.1899709701538086, Training time:2606.8822314739227
batch reward last col mean 0.522834300994873 first col mean 0.508276641368866 all mean 0.5058983564376831
1.1976045370101929 1.1976045370101929
rl training, epoch0, iter0, batch367/1133, batch loss:1.1976045370101929, Training time:2625.223871231079
batch reward last col mean 0.5123582482337952 first col mean 0.5205817818641663 all mean 0.5193274617195129
1.2631031274795532 1.2631031274795532
rl training, epoch0, iter0, batch368/1133, batch loss:1.2631031274795532, Training time:2645.556986808777
batch reward last col mean 0.529003381729126 first col mean 0.5154533386230469 all mean 0.518545925617218
1.2052851915359497 1.2052851915359497
rl training, epoch0, iter0, batch369/1133, batch loss:1.2052851915359497, Training time:2664.0063378810883
batch reward last col mean 0.5625895261764526 first col mean 0.5449627637863159 all mean 0.5296751856803894
1.2367161512374878 1.2367161512374878
rl training, epoch0, iter0, batch370/1133, batch loss:1.2367161512374878, Training time:2681.665702819824
batch reward last col mean 0.6132283210754395 first col mean 0.587547779083252 all mean 0.5583767294883728
1.3107563257217407 1.3107563257217407
rl training, epoch0, iter0, batch371/1133, batch loss:1.3107563257217407, Training time:2698.8433339595795
batch reward last col mean 0.5419654846191406 first col mean 0.5701581239700317 all mean 0.5364403128623962
1.2663295269012451 1.2663296461105347
rl training, epoch0, iter0, batch372/1133, batch loss:1.2663296461105347, Training time:2716.2972803115845
batch reward last col mean 0.5797998309135437 first col mean 0.5863025188446045 all mean 0.5771995186805725
1.2863799333572388 1.2863799333572388
rl training, epoch0, iter0, batch373/1133, batch loss:1.2863799333572388, Training time:2733.4918508529663
batch reward last col mean 0.5762583613395691 first col mean 0.5795179009437561 all mean 0.5859788656234741
1.280030369758606 1.280030369758606
rl training, epoch0, iter0, batch374/1133, batch loss:1.280030369758606, Training time:2750.9796855449677
batch reward last col mean 0.6239696741104126 first col mean 0.6250400543212891 all mean 0.6311424374580383
1.3576645851135254 1.3576645851135254
rl training, epoch0, iter0, batch375/1133, batch loss:1.3576645851135254, Training time:2768.306407690048
batch reward last col mean 0.5958577394485474 first col mean 0.6311248540878296 all mean 0.6048685312271118
1.326327919960022 1.326327919960022
rl training, epoch0, iter0, batch376/1133, batch loss:1.326327919960022, Training time:2785.3281016349792
batch reward last col mean 0.6177608370780945 first col mean 0.6446347236633301 all mean 0.6171557307243347
1.2942925691604614 1.2942925691604614
rl training, epoch0, iter0, batch377/1133, batch loss:1.2942925691604614, Training time:2802.6287887096405
batch reward last col mean 0.6570760607719421 first col mean 0.6568670272827148 all mean 0.6480686664581299
1.3320095539093018 1.3320095539093018
rl training, epoch0, iter0, batch378/1133, batch loss:1.3320095539093018, Training time:2819.971440553665
batch reward last col mean 0.6919739246368408 first col mean 0.653339147567749 all mean 0.6545301675796509
1.3369914293289185 1.3369914293289185
rl training, epoch0, iter0, batch379/1133, batch loss:1.3369914293289185, Training time:2836.8149230480194
batch reward last col mean 0.6605932116508484 first col mean 0.6873794198036194 all mean 0.6403329968452454
1.2846790552139282 1.2846790552139282
rl training, epoch0, iter0, batch380/1133, batch loss:1.2846790552139282, Training time:2853.9657735824585
batch reward last col mean 0.6448933482170105 first col mean 0.6792634725570679 all mean 0.6531821489334106
1.309749960899353 1.309749960899353
rl training, epoch0, iter0, batch381/1133, batch loss:1.309749960899353, Training time:2870.9899480342865
batch reward last col mean 0.6478801369667053 first col mean 0.6789547801017761 all mean 0.6712267398834229
1.2907243967056274 1.2907243967056274
rl training, epoch0, iter0, batch382/1133, batch loss:1.2907243967056274, Training time:2888.387507200241
batch reward last col mean 0.6451130509376526 first col mean 0.6423911452293396 all mean 0.6640820503234863
1.2789911031723022 1.2789911031723022
rl training, epoch0, iter0, batch383/1133, batch loss:1.2789911031723022, Training time:2907.3830609321594
batch reward last col mean 0.6823716759681702 first col mean 0.6497071385383606 all mean 0.6812841892242432
1.2705354690551758 1.2705354690551758
rl training, epoch0, iter0, batch384/1133, batch loss:1.2705354690551758, Training time:2927.758139848709
batch reward last col mean 0.6943891048431396 first col mean 0.7089585065841675 all mean 0.6823645830154419
1.2190393209457397 1.2190393209457397
rl training, epoch0, iter0, batch385/1133, batch loss:1.2190393209457397, Training time:2947.1865928173065
batch reward last col mean 0.7074500322341919 first col mean 0.6861644983291626 all mean 0.6872674226760864
1.2469230890274048 1.2469230890274048
rl training, epoch0, iter0, batch386/1133, batch loss:1.2469230890274048, Training time:2965.6592285633087
batch reward last col mean 0.6967434287071228 first col mean 0.6807262897491455 all mean 0.689295768737793
1.223582148551941 1.223582148551941
rl training, epoch0, iter0, batch387/1133, batch loss:1.223582148551941, Training time:2983.235407590866
batch reward last col mean 0.6763957738876343 first col mean 0.6775771379470825 all mean 0.6828566789627075
1.239424705505371 1.239424705505371
rl training, epoch0, iter0, batch388/1133, batch loss:1.239424705505371, Training time:3001.241608142853
batch reward last col mean 0.6782462000846863 first col mean 0.7152652740478516 all mean 0.700709342956543
1.2457125186920166 1.2457125186920166
rl training, epoch0, iter0, batch389/1133, batch loss:1.2457125186920166, Training time:3018.4063704013824
batch reward last col mean 0.7105140686035156 first col mean 0.7089757323265076 all mean 0.6946081519126892
1.2043286561965942 1.2043286561965942
rl training, epoch0, iter0, batch390/1133, batch loss:1.2043286561965942, Training time:3035.501134634018
batch reward last col mean 0.7264952659606934 first col mean 0.7401655316352844 all mean 0.717488169670105
1.24810791015625 1.24810791015625
rl training, epoch0, iter0, batch391/1133, batch loss:1.24810791015625, Training time:3052.558266878128
batch reward last col mean 0.6768847703933716 first col mean 0.7172748446464539 all mean 0.7218217849731445
1.2398943901062012 1.2398943901062012
rl training, epoch0, iter0, batch392/1133, batch loss:1.2398943901062012, Training time:3069.506369829178
batch reward last col mean 0.7050350904464722 first col mean 0.712893009185791 all mean 0.7109840512275696
1.1871769428253174 1.1871769428253174
rl training, epoch0, iter0, batch393/1133, batch loss:1.1871769428253174, Training time:3086.398583173752
batch reward last col mean 0.7577028274536133 first col mean 0.743402361869812 all mean 0.7515076994895935
1.2366470098495483 1.2366470098495483
rl training, epoch0, iter0, batch394/1133, batch loss:1.2366470098495483, Training time:3103.094842672348
batch reward last col mean 0.7092845439910889 first col mean 0.7342287302017212 all mean 0.739528477191925
1.2251858711242676 1.2251858711242676
rl training, epoch0, iter0, batch395/1133, batch loss:1.2251858711242676, Training time:3120.0255913734436
batch reward last col mean 0.7484031319618225 first col mean 0.7296020984649658 all mean 0.7418918609619141
1.1978697776794434 1.1978697776794434
rl training, epoch0, iter0, batch396/1133, batch loss:1.1978697776794434, Training time:3136.6832451820374
batch reward last col mean 0.7829582691192627 first col mean 0.7632772326469421 all mean 0.7611668705940247
1.2427103519439697 1.2427103519439697
rl training, epoch0, iter0, batch397/1133, batch loss:1.2427103519439697, Training time:3153.6959869861603
batch reward last col mean 0.6900685429573059 first col mean 0.705151379108429 all mean 0.7249871492385864
1.1947065591812134 1.1947065591812134
rl training, epoch0, iter0, batch398/1133, batch loss:1.1947065591812134, Training time:3172.004469871521
batch reward last col mean 0.7919735908508301 first col mean 0.7655124664306641 all mean 0.7703831195831299
1.2445985078811646 1.2445985078811646
rl training, epoch0, iter0, batch399/1133, batch loss:1.2445985078811646, Training time:3190.2048201560974
batch reward last col mean 0.7147195339202881 first col mean 0.7568082809448242 all mean 0.7437523603439331
1.1886348724365234 1.1886348724365234
rl training, epoch0, iter0, batch400/1133, batch loss:1.1886348724365234, Training time:3207.1449851989746
batch reward last col mean 0.7026875615119934 first col mean 0.7285356521606445 all mean 0.7303223013877869
1.1720260381698608 1.1720260381698608
rl training, epoch0, iter0, batch401/1133, batch loss:1.1720260381698608, Training time:3225.048721551895
batch reward last col mean 0.7194307446479797 first col mean 0.7124276757240295 all mean 0.7156077027320862
1.1478956937789917 1.1478956937789917
rl training, epoch0, iter0, batch402/1133, batch loss:1.1478956937789917, Training time:3243.5805575847626
batch reward last col mean 0.7100075483322144 first col mean 0.7411938905715942 all mean 0.698123037815094
1.1066378355026245 1.1066378355026245
rl training, epoch0, iter0, batch403/1133, batch loss:1.1066378355026245, Training time:3260.8718521595
batch reward last col mean 0.6930064558982849 first col mean 0.712954044342041 all mean 0.7073127031326294
1.1194669008255005 1.1194669008255005
rl training, epoch0, iter0, batch404/1133, batch loss:1.1194669008255005, Training time:3277.69330906868
batch reward last col mean 0.7001391649246216 first col mean 0.708301842212677 all mean 0.7183387875556946
1.1682833433151245 1.1682833433151245
rl training, epoch0, iter0, batch405/1133, batch loss:1.1682833433151245, Training time:3294.377218723297
batch reward last col mean 0.6624606847763062 first col mean 0.7113351225852966 all mean 0.715728223323822
1.1363801956176758 1.1363801956176758
rl training, epoch0, iter0, batch406/1133, batch loss:1.1363801956176758, Training time:3310.9316070079803
batch reward last col mean 0.7052528858184814 first col mean 0.6858034133911133 all mean 0.7013489603996277
1.1154032945632935 1.1154032945632935
rl training, epoch0, iter0, batch407/1133, batch loss:1.1154032945632935, Training time:3327.3096590042114
batch reward last col mean 0.7102227210998535 first col mean 0.7134068608283997 all mean 0.7195326089859009
1.1474361419677734 1.1474361419677734
rl training, epoch0, iter0, batch408/1133, batch loss:1.1474361419677734, Training time:3344.3262572288513
batch reward last col mean 0.7271398901939392 first col mean 0.6984639167785645 all mean 0.7122035026550293
1.1178454160690308 1.1178454160690308
rl training, epoch0, iter0, batch409/1133, batch loss:1.1178454160690308, Training time:3361.23748755455
batch reward last col mean 0.7379469871520996 first col mean 0.7059972286224365 all mean 0.7233177423477173
1.1410889625549316 1.1410889625549316
rl training, epoch0, iter0, batch410/1133, batch loss:1.1410889625549316, Training time:3378.047055244446
batch reward last col mean 0.7095200419425964 first col mean 0.6839578151702881 all mean 0.6868728995323181
1.1131144762039185 1.1131144762039185
rl training, epoch0, iter0, batch411/1133, batch loss:1.1131144762039185, Training time:3395.0047795772552
batch reward last col mean 0.7653862237930298 first col mean 0.739141047000885 all mean 0.7493418455123901
1.1882259845733643 1.1882258653640747
rl training, epoch0, iter0, batch412/1133, batch loss:1.1882258653640747, Training time:3411.8658916950226
batch reward last col mean 0.7298621535301208 first col mean 0.7272284030914307 all mean 0.7164822816848755
1.1518418788909912 1.1518418788909912
rl training, epoch0, iter0, batch413/1133, batch loss:1.1518418788909912, Training time:3428.8420536518097
batch reward last col mean 0.684520959854126 first col mean 0.6962745785713196 all mean 0.7026036381721497
1.1407816410064697 1.1407816410064697
rl training, epoch0, iter0, batch414/1133, batch loss:1.1407816410064697, Training time:3445.6358819007874
batch reward last col mean 0.7481260299682617 first col mean 0.6903376579284668 all mean 0.6961764097213745
1.0844528675079346 1.0844528675079346
rl training, epoch0, iter0, batch415/1133, batch loss:1.0844528675079346, Training time:3462.419953584671
batch reward last col mean 0.7324920892715454 first col mean 0.7336762547492981 all mean 0.7295448780059814
1.138469934463501 1.138469934463501
rl training, epoch0, iter0, batch416/1133, batch loss:1.138469934463501, Training time:3479.2354481220245
batch reward last col mean 0.6679137945175171 first col mean 0.6735803484916687 all mean 0.6678133010864258
1.0175535678863525 1.0175535678863525
rl training, epoch0, iter0, batch417/1133, batch loss:1.0175535678863525, Training time:3496.2737963199615
batch reward last col mean 0.7102400660514832 first col mean 0.7216025590896606 all mean 0.7200551629066467
1.1071864366531372 1.1071864366531372
rl training, epoch0, iter0, batch418/1133, batch loss:1.1071864366531372, Training time:3514.366439342499
batch reward last col mean 0.705991268157959 first col mean 0.6972059011459351 all mean 0.7056388258934021
1.0743067264556885 1.0743067264556885
rl training, epoch0, iter0, batch419/1133, batch loss:1.0743067264556885, Training time:3534.6437389850616
batch reward last col mean 0.6862777471542358 first col mean 0.7090602517127991 all mean 0.7074122428894043
1.0628591775894165 1.0628591775894165
rl training, epoch0, iter0, batch420/1133, batch loss:1.0628591775894165, Training time:3554.5639278888702
batch reward last col mean 0.6973376870155334 first col mean 0.6653618216514587 all mean 0.6826672554016113
1.0223922729492188 1.0223922729492188
rl training, epoch0, iter0, batch421/1133, batch loss:1.0223922729492188, Training time:3572.552664756775
batch reward last col mean 0.6742969751358032 first col mean 0.6633239388465881 all mean 0.6773496866226196
1.0303943157196045 1.030394196510315
rl training, epoch0, iter0, batch422/1133, batch loss:1.030394196510315, Training time:3591.9710319042206
batch reward last col mean 0.7320237159729004 first col mean 0.7164692878723145 all mean 0.7295489311218262
1.1069749593734741 1.1069748401641846
rl training, epoch0, iter0, batch423/1133, batch loss:1.1069748401641846, Training time:3609.4087584018707
batch reward last col mean 0.6862931847572327 first col mean 0.6783243417739868 all mean 0.6917717456817627
1.0206576585769653 1.0206576585769653
rl training, epoch0, iter0, batch424/1133, batch loss:1.0206576585769653, Training time:3626.279350042343
batch reward last col mean 0.672489583492279 first col mean 0.6689951419830322 all mean 0.6694452166557312
0.9967419505119324 0.9967419505119324
rl training, epoch0, iter0, batch425/1133, batch loss:0.9967419505119324, Training time:3643.2154548168182
batch reward last col mean 0.7768228650093079 first col mean 0.7009944319725037 all mean 0.7295689582824707
1.1127588748931885 1.1127588748931885
rl training, epoch0, iter0, batch426/1133, batch loss:1.1127588748931885, Training time:3660.1791365146637
batch reward last col mean 0.7310508489608765 first col mean 0.6887547969818115 all mean 0.6985391974449158
1.0599300861358643 1.0599300861358643
rl training, epoch0, iter0, batch427/1133, batch loss:1.0599300861358643, Training time:3677.0650701522827
batch reward last col mean 0.7436839938163757 first col mean 0.6789816617965698 all mean 0.6956695318222046
1.1134250164031982 1.1134248971939087
rl training, epoch0, iter0, batch428/1133, batch loss:1.1134248971939087, Training time:3693.948540687561
batch reward last col mean 0.7219635844230652 first col mean 0.6544554233551025 all mean 0.6957849860191345
1.0994457006454468 1.0994455814361572
rl training, epoch0, iter0, batch429/1133, batch loss:1.0994455814361572, Training time:3710.670354127884
batch reward last col mean 0.7131060361862183 first col mean 0.7182729840278625 all mean 0.7132336497306824
1.1726819276809692 1.1726819276809692
rl training, epoch0, iter0, batch430/1133, batch loss:1.1726819276809692, Training time:3727.561883211136
batch reward last col mean 0.6366300582885742 first col mean 0.6776375770568848 all mean 0.6759359836578369
1.1125835180282593 1.1125835180282593
rl training, epoch0, iter0, batch431/1133, batch loss:1.1125835180282593, Training time:3744.7714676856995
batch reward last col mean 0.714794397354126 first col mean 0.7419843673706055 all mean 0.7548714876174927
1.2518712282180786 1.251871109008789
rl training, epoch0, iter0, batch432/1133, batch loss:1.251871109008789, Training time:3761.379625082016
batch reward last col mean 0.7222595810890198 first col mean 0.7018409967422485 all mean 0.7173011302947998
1.1807317733764648 1.1807317733764648
rl training, epoch0, iter0, batch433/1133, batch loss:1.1807317733764648, Training time:3778.899502515793
batch reward last col mean 0.7250297665596008 first col mean 0.7050461769104004 all mean 0.7187955975532532
1.2524175643920898 1.2524175643920898
rl training, epoch0, iter0, batch434/1133, batch loss:1.2524175643920898, Training time:3796.6373159885406
batch reward last col mean 0.7291904091835022 first col mean 0.6907768249511719 all mean 0.7037031650543213
1.224352240562439 1.224352240562439
rl training, epoch0, iter0, batch435/1133, batch loss:1.224352240562439, Training time:3814.6389496326447
batch reward last col mean 0.716686487197876 first col mean 0.7020690441131592 all mean 0.7310569286346436
1.3025709390640259 1.3025709390640259
rl training, epoch0, iter0, batch436/1133, batch loss:1.3025709390640259, Training time:3835.446287870407
batch reward last col mean 0.6879903674125671 first col mean 0.7306288480758667 all mean 0.7215062975883484
1.2956218719482422 1.2956218719482422
rl training, epoch0, iter0, batch437/1133, batch loss:1.2956218719482422, Training time:3855.736322402954
batch reward last col mean 0.7578088045120239 first col mean 0.7140108346939087 all mean 0.7374318242073059
1.3321672677993774 1.332167387008667
rl training, epoch0, iter0, batch438/1133, batch loss:1.332167387008667, Training time:3872.7945466041565
batch reward last col mean 0.7626673579216003 first col mean 0.7237027883529663 all mean 0.7565736174583435
1.3669860363006592 1.3669860363006592
rl training, epoch0, iter0, batch439/1133, batch loss:1.3669860363006592, Training time:3890.063666343689
batch reward last col mean 0.7303469777107239 first col mean 0.6981650590896606 all mean 0.7008538842201233
1.3053066730499268 1.3053066730499268
rl training, epoch0, iter0, batch440/1133, batch loss:1.3053066730499268, Training time:3908.0994379520416
batch reward last col mean 0.699735164642334 first col mean 0.6907716989517212 all mean 0.7300993204116821
1.3777998685836792 1.3777998685836792
rl training, epoch0, iter0, batch441/1133, batch loss:1.3777998685836792, Training time:3925.168025970459
batch reward last col mean 0.724920928478241 first col mean 0.7468968033790588 all mean 0.7523736953735352
1.3833730220794678 1.3833730220794678
rl training, epoch0, iter0, batch442/1133, batch loss:1.3833730220794678, Training time:3943.7088119983673
batch reward last col mean 0.7256038188934326 first col mean 0.737258791923523 all mean 0.7274441123008728
1.3232935667037964 1.3232935667037964
rl training, epoch0, iter0, batch443/1133, batch loss:1.3232935667037964, Training time:3964.4450058937073
batch reward last col mean 0.691468358039856 first col mean 0.6894692182540894 all mean 0.6897122263908386
1.2569409608840942 1.2569409608840942
rl training, epoch0, iter0, batch444/1133, batch loss:1.2569409608840942, Training time:3983.334882259369
batch reward last col mean 0.7095252275466919 first col mean 0.7044306993484497 all mean 0.7270336151123047
1.3010907173156738 1.3010907173156738
rl training, epoch0, iter0, batch445/1133, batch loss:1.3010907173156738, Training time:4000.678164958954
batch reward last col mean 0.7007390260696411 first col mean 0.7042953968048096 all mean 0.7368782162666321
1.3275277614593506 1.3275277614593506
rl training, epoch0, iter0, batch446/1133, batch loss:1.3275277614593506, Training time:4017.5788581371307
batch reward last col mean 0.6832266449928284 first col mean 0.7855504155158997 all mean 0.7435032725334167
1.3887866735458374 1.3887866735458374
rl training, epoch0, iter0, batch447/1133, batch loss:1.3887866735458374, Training time:4034.3950097560883
batch reward last col mean 0.7584763169288635 first col mean 0.750636100769043 all mean 0.7518697381019592
1.3629390001296997 1.3629390001296997
rl training, epoch0, iter0, batch448/1133, batch loss:1.3629390001296997, Training time:4051.6992123126984
batch reward last col mean 0.7250628471374512 first col mean 0.7314619421958923 all mean 0.7417704463005066
1.3343453407287598 1.3343452215194702
rl training, epoch0, iter0, batch449/1133, batch loss:1.3343452215194702, Training time:4069.000104904175
batch reward last col mean 0.7121152877807617 first col mean 0.7366523146629333 all mean 0.7379887104034424
1.28887939453125 1.28887939453125
rl training, epoch0, iter0, batch450/1133, batch loss:1.28887939453125, Training time:4085.836719751358
batch reward last col mean 0.6642120480537415 first col mean 0.7295342683792114 all mean 0.7122360467910767
1.3035151958465576 1.303515076637268
rl training, epoch0, iter0, batch451/1133, batch loss:1.303515076637268, Training time:4102.781623840332
batch reward last col mean 0.7482102513313293 first col mean 0.7357392311096191 all mean 0.7534489631652832
1.3063023090362549 1.3063023090362549
rl training, epoch0, iter0, batch452/1133, batch loss:1.3063023090362549, Training time:4119.744718313217
batch reward last col mean 0.7584989666938782 first col mean 0.7580410838127136 all mean 0.7559412717819214
1.328423023223877 1.328423023223877
rl training, epoch0, iter0, batch453/1133, batch loss:1.328423023223877, Training time:4136.724756240845
batch reward last col mean 0.7506976127624512 first col mean 0.7235310077667236 all mean 0.7415326833724976
1.2938648462295532 1.2938648462295532
rl training, epoch0, iter0, batch454/1133, batch loss:1.2938648462295532, Training time:4153.466995477676
batch reward last col mean 0.7355948090553284 first col mean 0.7495828866958618 all mean 0.7425085306167603
1.2928229570388794 1.2928229570388794
rl training, epoch0, iter0, batch455/1133, batch loss:1.2928229570388794, Training time:4170.3890697956085
batch reward last col mean 0.7011908292770386 first col mean 0.7176218032836914 all mean 0.7039282917976379
1.2397427558898926 1.2397427558898926
rl training, epoch0, iter0, batch456/1133, batch loss:1.2397427558898926, Training time:4187.2456407547
batch reward last col mean 0.7497142553329468 first col mean 0.7550883889198303 all mean 0.7494925856590271
1.346949577331543 1.346949577331543
rl training, epoch0, iter0, batch457/1133, batch loss:1.346949577331543, Training time:4204.22708106041
batch reward last col mean 0.7550972104072571 first col mean 0.7488613724708557 all mean 0.7611586451530457
1.3309811353683472 1.3309811353683472
rl training, epoch0, iter0, batch458/1133, batch loss:1.3309811353683472, Training time:4221.220092058182
batch reward last col mean 0.7630972862243652 first col mean 0.7613168954849243 all mean 0.744994580745697
1.2795666456222534 1.2795666456222534
rl training, epoch0, iter0, batch459/1133, batch loss:1.2795666456222534, Training time:4238.897146701813
batch reward last col mean 0.7773727178573608 first col mean 0.7587617635726929 all mean 0.7698938250541687
1.3719024658203125 1.3719027042388916
rl training, epoch0, iter0, batch460/1133, batch loss:1.3719027042388916, Training time:4257.654242992401
batch reward last col mean 0.778527021408081 first col mean 0.7633264064788818 all mean 0.7677401304244995
1.3423657417297363 1.3423657417297363
rl training, epoch0, iter0, batch461/1133, batch loss:1.3423657417297363, Training time:4276.503308057785
batch reward last col mean 0.7583943009376526 first col mean 0.7402312755584717 all mean 0.7475060224533081
1.3292934894561768 1.3292932510375977
rl training, epoch0, iter0, batch462/1133, batch loss:1.3292932510375977, Training time:4293.617232084274
batch reward last col mean 0.7649153470993042 first col mean 0.7216230630874634 all mean 0.7469508647918701
1.310291051864624 1.310291051864624
rl training, epoch0, iter0, batch463/1133, batch loss:1.310291051864624, Training time:4313.651351213455
batch reward last col mean 0.7899269461631775 first col mean 0.785452663898468 all mean 0.7726998329162598
1.3532741069793701 1.3532741069793701
rl training, epoch0, iter0, batch464/1133, batch loss:1.3532741069793701, Training time:4330.585309505463
batch reward last col mean 0.754903256893158 first col mean 0.794926106929779 all mean 0.7841046452522278
1.3912806510925293 1.3912805318832397
rl training, epoch0, iter0, batch465/1133, batch loss:1.3912805318832397, Training time:4347.420713186264
batch reward last col mean 0.7315217852592468 first col mean 0.7566236257553101 all mean 0.7459669709205627
1.3325393199920654 1.3325393199920654
rl training, epoch0, iter0, batch466/1133, batch loss:1.3325393199920654, Training time:4364.7650578022
batch reward last col mean 0.7454793453216553 first col mean 0.7683915495872498 all mean 0.7768216133117676
1.3601250648498535 1.3601250648498535
rl training, epoch0, iter0, batch467/1133, batch loss:1.3601250648498535, Training time:4381.560141324997
batch reward last col mean 0.8119522929191589 first col mean 0.7927740216255188 all mean 0.7831666469573975
1.3786211013793945 1.3786211013793945
rl training, epoch0, iter0, batch468/1133, batch loss:1.3786211013793945, Training time:4398.744774103165
batch reward last col mean 0.8255197405815125 first col mean 0.7896815538406372 all mean 0.7863526940345764
1.3940554857254028 1.3940554857254028
rl training, epoch0, iter0, batch469/1133, batch loss:1.3940554857254028, Training time:4416.127071380615
batch reward last col mean 0.8159163594245911 first col mean 0.8107947111129761 all mean 0.7978023886680603
1.396680235862732 1.396680235862732
rl training, epoch0, iter0, batch470/1133, batch loss:1.396680235862732, Training time:4432.869887113571
batch reward last col mean 0.8011025190353394 first col mean 0.8154311180114746 all mean 0.8006765842437744
1.3851165771484375 1.3851165771484375
rl training, epoch0, iter0, batch471/1133, batch loss:1.3851165771484375, Training time:4449.703601360321
batch reward last col mean 0.7740628123283386 first col mean 0.7833125591278076 all mean 0.7913429737091064
1.4147058725357056 1.4147058725357056
rl training, epoch0, iter0, batch472/1133, batch loss:1.4147058725357056, Training time:4466.944212675095
batch reward last col mean 0.7807415723800659 first col mean 0.7997602224349976 all mean 0.7863325476646423
1.4022741317749023 1.4022741317749023
rl training, epoch0, iter0, batch473/1133, batch loss:1.4022741317749023, Training time:4483.776435375214
batch reward last col mean 0.7843899726867676 first col mean 0.7712202072143555 all mean 0.7847203612327576
1.3779886960983276 1.3779886960983276
rl training, epoch0, iter0, batch474/1133, batch loss:1.3779886960983276, Training time:4500.7657771110535
batch reward last col mean 0.8104459047317505 first col mean 0.783972442150116 all mean 0.7709991931915283
1.377185344696045 1.377185344696045
rl training, epoch0, iter0, batch475/1133, batch loss:1.377185344696045, Training time:4517.877864360809
batch reward last col mean 0.8202917575836182 first col mean 0.8413769602775574 all mean 0.8124139308929443
1.442452073097229 1.442452073097229
rl training, epoch0, iter0, batch476/1133, batch loss:1.442452073097229, Training time:4534.8898775577545
batch reward last col mean 0.7720693349838257 first col mean 0.7874658703804016 all mean 0.7958025932312012
1.3826713562011719 1.3826713562011719
rl training, epoch0, iter0, batch477/1133, batch loss:1.3826713562011719, Training time:4551.624579906464
batch reward last col mean 0.7995914220809937 first col mean 0.7892155647277832 all mean 0.7826487421989441
1.3780359029769897 1.3780359029769897
rl training, epoch0, iter0, batch478/1133, batch loss:1.3780359029769897, Training time:4568.350749969482
batch reward last col mean 0.760076642036438 first col mean 0.808024525642395 all mean 0.7930731773376465
1.3903756141662598 1.3903756141662598
rl training, epoch0, iter0, batch479/1133, batch loss:1.3903756141662598, Training time:4588.309084177017
batch reward last col mean 0.7829333543777466 first col mean 0.7912695407867432 all mean 0.7959813475608826
1.3907225131988525 1.3907225131988525
rl training, epoch0, iter0, batch480/1133, batch loss:1.3907225131988525, Training time:4606.152205705643
batch reward last col mean 0.7586265206336975 first col mean 0.8023550510406494 all mean 0.8107355237007141
1.4523056745529175 1.4523056745529175
rl training, epoch0, iter0, batch481/1133, batch loss:1.4523056745529175, Training time:4625.1900639534
batch reward last col mean 0.7855956554412842 first col mean 0.780811607837677 all mean 0.8112549185752869
1.4073207378387451 1.4073207378387451
rl training, epoch0, iter0, batch482/1133, batch loss:1.4073207378387451, Training time:4642.777640104294
batch reward last col mean 0.81882244348526 first col mean 0.7998717427253723 all mean 0.8182540535926819
1.4109342098236084 1.4109342098236084
rl training, epoch0, iter0, batch483/1133, batch loss:1.4109342098236084, Training time:4659.251579523087
batch reward last col mean 0.7758700251579285 first col mean 0.7848206162452698 all mean 0.7986755967140198
1.4117916822433472 1.4117916822433472
rl training, epoch0, iter0, batch484/1133, batch loss:1.4117916822433472, Training time:4675.6663699150085
batch reward last col mean 0.799920380115509 first col mean 0.8326317071914673 all mean 0.8204303979873657
1.4403764009475708 1.4403764009475708
rl training, epoch0, iter0, batch485/1133, batch loss:1.4403764009475708, Training time:4692.078999757767
batch reward last col mean 0.7646380662918091 first col mean 0.7733681201934814 all mean 0.7780548334121704
1.3676215410232544 1.3676215410232544
rl training, epoch0, iter0, batch486/1133, batch loss:1.3676215410232544, Training time:4708.680949926376
batch reward last col mean 0.7416188716888428 first col mean 0.8120068907737732 all mean 0.7947697639465332
1.3920332193374634 1.3920332193374634
rl training, epoch0, iter0, batch487/1133, batch loss:1.3920332193374634, Training time:4725.050085067749
batch reward last col mean 0.8435710072517395 first col mean 0.8269143104553223 all mean 0.8131322860717773
1.427878737449646 1.427878975868225
rl training, epoch0, iter0, batch488/1133, batch loss:1.427878975868225, Training time:4741.4603662490845
batch reward last col mean 0.7774859666824341 first col mean 0.8247138261795044 all mean 0.8144247531890869
1.4128444194793701 1.4128444194793701
rl training, epoch0, iter0, batch489/1133, batch loss:1.4128444194793701, Training time:4757.790699720383
batch reward last col mean 0.7784571647644043 first col mean 0.8210539221763611 all mean 0.8129104375839233
1.4209669828414917 1.4209669828414917
rl training, epoch0, iter0, batch490/1133, batch loss:1.4209669828414917, Training time:4774.411777973175
batch reward last col mean 0.8060904145240784 first col mean 0.8203318119049072 all mean 0.8215723633766174
1.4316706657409668 1.4316706657409668
rl training, epoch0, iter0, batch491/1133, batch loss:1.4316706657409668, Training time:4791.6178023815155
batch reward last col mean 0.7979011535644531 first col mean 0.8035141229629517 all mean 0.8194856643676758
1.417152762413025 1.417152762413025
rl training, epoch0, iter0, batch492/1133, batch loss:1.417152762413025, Training time:4808.92590212822
batch reward last col mean 0.8649795055389404 first col mean 0.7997310161590576 all mean 0.8219587802886963
1.4359349012374878 1.4359349012374878
rl training, epoch0, iter0, batch493/1133, batch loss:1.4359349012374878, Training time:4826.892137765884
batch reward last col mean 0.8211113214492798 first col mean 0.8288778066635132 all mean 0.8138136267662048
1.43870210647583 1.4387019872665405
rl training, epoch0, iter0, batch494/1133, batch loss:1.4387019872665405, Training time:4845.068845748901
batch reward last col mean 0.7686339616775513 first col mean 0.7956801652908325 all mean 0.7985454797744751
1.4014770984649658 1.4014770984649658
rl training, epoch0, iter0, batch495/1133, batch loss:1.4014770984649658, Training time:4862.871869087219
batch reward last col mean 0.7782868146896362 first col mean 0.8054225444793701 all mean 0.7963882088661194
1.4246037006378174 1.4246037006378174
rl training, epoch0, iter0, batch496/1133, batch loss:1.4246037006378174, Training time:4881.180988788605
batch reward last col mean 0.7888950109481812 first col mean 0.8358728289604187 all mean 0.818257212638855
1.4495811462402344 1.4495811462402344
rl training, epoch0, iter0, batch497/1133, batch loss:1.4495811462402344, Training time:4897.925955295563
batch reward last col mean 0.8296049237251282 first col mean 0.8160613775253296 all mean 0.8224108815193176
1.4102874994277954 1.4102874994277954
rl training, epoch0, iter0, batch498/1133, batch loss:1.4102874994277954, Training time:4914.446444034576
batch reward last col mean 0.7917036414146423 first col mean 0.8455200791358948 all mean 0.8266096115112305
1.4405484199523926 1.4405484199523926
rl training, epoch0, iter0, batch499/1133, batch loss:1.4405484199523926, Training time:4931.080687046051
batch reward last col mean 0.7981082201004028 first col mean 0.8420059680938721 all mean 0.8243297934532166
1.413922905921936 1.413922905921936
rl training, epoch0, iter0, batch500/1133, batch loss:1.413922905921936, Training time:4947.634037017822
batch reward last col mean 0.7850437760353088 first col mean 0.8016495704650879 all mean 0.8110394477844238
1.4245046377182007 1.4245043992996216
rl training, epoch0, iter0, batch501/1133, batch loss:1.4245043992996216, Training time:4964.05441403389
batch reward last col mean 0.8938288688659668 first col mean 0.8712128400802612 all mean 0.8499356508255005
1.4489625692367554 1.4489625692367554
rl training, epoch0, iter0, batch502/1133, batch loss:1.4489625692367554, Training time:4980.451471328735
batch reward last col mean 0.8416450619697571 first col mean 0.839198887348175 all mean 0.8383097052574158
1.4353580474853516 1.4353580474853516
rl training, epoch0, iter0, batch503/1133, batch loss:1.4353580474853516, Training time:4996.857305765152
batch reward last col mean 0.7903745770454407 first col mean 0.8049983382225037 all mean 0.819141685962677
1.4460623264312744 1.4460623264312744
rl training, epoch0, iter0, batch504/1133, batch loss:1.4460623264312744, Training time:5013.467242240906
batch reward last col mean 0.7751123309135437 first col mean 0.7963249683380127 all mean 0.7970242500305176
1.4098097085952759 1.4098097085952759
rl training, epoch0, iter0, batch505/1133, batch loss:1.4098097085952759, Training time:5030.2873158454895
batch reward last col mean 0.83018958568573 first col mean 0.8464882373809814 all mean 0.8411139249801636
1.4393794536590576 1.4393794536590576
rl training, epoch0, iter0, batch506/1133, batch loss:1.4393794536590576, Training time:5046.749034643173
batch reward last col mean 0.7930101752281189 first col mean 0.8096010684967041 all mean 0.8303174376487732
1.4189947843551636 1.4189947843551636
rl training, epoch0, iter0, batch507/1133, batch loss:1.4189947843551636, Training time:5063.340981006622
batch reward last col mean 0.8556187748908997 first col mean 0.8618346452713013 all mean 0.8600785732269287
1.4888100624084473 1.4888098239898682
rl training, epoch0, iter0, batch508/1133, batch loss:1.4888098239898682, Training time:5080.066723108292
batch reward last col mean 0.8525781631469727 first col mean 0.8380439877510071 all mean 0.8494496941566467
1.4195317029953003 1.4195317029953003
rl training, epoch0, iter0, batch509/1133, batch loss:1.4195317029953003, Training time:5097.24076795578
batch reward last col mean 0.8274296522140503 first col mean 0.806946337223053 all mean 0.818450927734375
1.3871842622756958 1.3871842622756958
rl training, epoch0, iter0, batch510/1133, batch loss:1.3871842622756958, Training time:5114.486374616623
batch reward last col mean 0.8452835083007812 first col mean 0.8465749621391296 all mean 0.8446312546730042
1.4163254499435425 1.4163254499435425
rl training, epoch0, iter0, batch511/1133, batch loss:1.4163254499435425, Training time:5133.104746341705
batch reward last col mean 0.8489053249359131 first col mean 0.8665564060211182 all mean 0.8687005639076233
1.4673924446105957 1.4673924446105957
rl training, epoch0, iter0, batch512/1133, batch loss:1.4673924446105957, Training time:5150.571088790894
batch reward last col mean 0.8282668590545654 first col mean 0.8361018300056458 all mean 0.8368696570396423
1.371266484260559 1.371266484260559
rl training, epoch0, iter0, batch513/1133, batch loss:1.371266484260559, Training time:5169.019055843353
batch reward last col mean 0.8306488394737244 first col mean 0.8076411485671997 all mean 0.8129767179489136
1.3698225021362305 1.3698225021362305
rl training, epoch0, iter0, batch514/1133, batch loss:1.3698225021362305, Training time:5188.054735898972
batch reward last col mean 0.7997744083404541 first col mean 0.839011549949646 all mean 0.845805287361145
1.4281553030014038 1.4281553030014038
rl training, epoch0, iter0, batch515/1133, batch loss:1.4281553030014038, Training time:5206.120927810669
batch reward last col mean 0.8510288000106812 first col mean 0.8582358956336975 all mean 0.8436558246612549
1.3944686651229858 1.3944686651229858
rl training, epoch0, iter0, batch516/1133, batch loss:1.3944686651229858, Training time:5223.303448677063
batch reward last col mean 0.8557729721069336 first col mean 0.8463395833969116 all mean 0.8459890484809875
1.386713981628418 1.386713981628418
rl training, epoch0, iter0, batch517/1133, batch loss:1.386713981628418, Training time:5240.034448385239
batch reward last col mean 0.8166310787200928 first col mean 0.8560975790023804 all mean 0.846525251865387
1.4024986028671265 1.402498483657837
rl training, epoch0, iter0, batch518/1133, batch loss:1.402498483657837, Training time:5256.961487293243
batch reward last col mean 0.8425990343093872 first col mean 0.8438014984130859 all mean 0.8522696495056152
1.429502248764038 1.429502010345459
rl training, epoch0, iter0, batch519/1133, batch loss:1.429502010345459, Training time:5274.083160877228
batch reward last col mean 0.8874025344848633 first col mean 0.8507199287414551 all mean 0.8493925333023071
1.3783762454986572 1.3783762454986572
rl training, epoch0, iter0, batch520/1133, batch loss:1.3783762454986572, Training time:5290.484732866287
batch reward last col mean 0.8264601230621338 first col mean 0.8388010263442993 all mean 0.8530885577201843
1.4279016256332397 1.4279016256332397
rl training, epoch0, iter0, batch521/1133, batch loss:1.4279016256332397, Training time:5306.857617855072
batch reward last col mean 0.847642719745636 first col mean 0.863048791885376 all mean 0.8534240126609802
1.419249415397644 1.419249415397644
rl training, epoch0, iter0, batch522/1133, batch loss:1.419249415397644, Training time:5323.2347939014435
batch reward last col mean 0.8458224534988403 first col mean 0.8336583971977234 all mean 0.8511056900024414
1.3987675905227661 1.3987674713134766
rl training, epoch0, iter0, batch523/1133, batch loss:1.3987674713134766, Training time:5339.575113534927
batch reward last col mean 0.863741397857666 first col mean 0.8743444085121155 all mean 0.8542367815971375
1.4137321710586548 1.4137321710586548
rl training, epoch0, iter0, batch524/1133, batch loss:1.4137321710586548, Training time:5356.059339523315
batch reward last col mean 0.8129025101661682 first col mean 0.8509153127670288 all mean 0.8380376696586609
1.418664813041687 1.418664813041687
rl training, epoch0, iter0, batch525/1133, batch loss:1.418664813041687, Training time:5372.920866966248
batch reward last col mean 0.8187516331672668 first col mean 0.8551833629608154 all mean 0.8424829244613647
1.392076015472412 1.392076015472412
rl training, epoch0, iter0, batch526/1133, batch loss:1.392076015472412, Training time:5389.600818395615
batch reward last col mean 0.7952597141265869 first col mean 0.8510887026786804 all mean 0.842534065246582
1.394455075263977 1.394455075263977
rl training, epoch0, iter0, batch527/1133, batch loss:1.394455075263977, Training time:5407.189425468445
batch reward last col mean 0.7925799489021301 first col mean 0.8480494022369385 all mean 0.8397653102874756
1.4244202375411987 1.4244202375411987
rl training, epoch0, iter0, batch528/1133, batch loss:1.4244202375411987, Training time:5423.531442403793
batch reward last col mean 0.8736454248428345 first col mean 0.8596659898757935 all mean 0.8673931360244751
1.4269893169403076 1.4269893169403076
rl training, epoch0, iter0, batch529/1133, batch loss:1.4269893169403076, Training time:5441.418411970139
batch reward last col mean 0.8460317850112915 first col mean 0.8375622034072876 all mean 0.8481266498565674
1.4089435338974 1.4089435338974
rl training, epoch0, iter0, batch530/1133, batch loss:1.4089435338974, Training time:5460.467104673386
batch reward last col mean 0.829034149646759 first col mean 0.8552585244178772 all mean 0.8471683263778687
1.4214544296264648 1.4214544296264648
rl training, epoch0, iter0, batch531/1133, batch loss:1.4214544296264648, Training time:5478.956652164459
batch reward last col mean 0.9067138433456421 first col mean 0.8714234828948975 all mean 0.8793217539787292
1.4721622467041016 1.472162127494812
rl training, epoch0, iter0, batch532/1133, batch loss:1.472162127494812, Training time:5496.520699501038
batch reward last col mean 0.8783207535743713 first col mean 0.8877338767051697 all mean 0.8848867416381836
1.4954242706298828 1.4954242706298828
rl training, epoch0, iter0, batch533/1133, batch loss:1.4954242706298828, Training time:5514.065446615219
batch reward last col mean 0.7983412742614746 first col mean 0.8226076364517212 all mean 0.8227851986885071
1.4028561115264893 1.4028558731079102
rl training, epoch0, iter0, batch534/1133, batch loss:1.4028558731079102, Training time:5531.591681957245
batch reward last col mean 0.8632233142852783 first col mean 0.8221363425254822 all mean 0.8436145186424255
1.4721187353134155 1.472118616104126
rl training, epoch0, iter0, batch535/1133, batch loss:1.472118616104126, Training time:5548.276352882385
batch reward last col mean 0.8566337823867798 first col mean 0.8673045039176941 all mean 0.8586415648460388
1.4687665700912476 1.4687665700912476
rl training, epoch0, iter0, batch536/1133, batch loss:1.4687665700912476, Training time:5565.042631864548
batch reward last col mean 0.8528740406036377 first col mean 0.8509001135826111 all mean 0.8429310321807861
1.4213664531707764 1.4213664531707764
rl training, epoch0, iter0, batch537/1133, batch loss:1.4213664531707764, Training time:5581.9573011398315
batch reward last col mean 0.8370130062103271 first col mean 0.8560278415679932 all mean 0.8473732471466064
1.4558664560317993 1.4558664560317993
rl training, epoch0, iter0, batch538/1133, batch loss:1.4558664560317993, Training time:5598.800452470779
batch reward last col mean 0.8631649613380432 first col mean 0.854518473148346 all mean 0.839113712310791
1.4622464179992676 1.4622464179992676
rl training, epoch0, iter0, batch539/1133, batch loss:1.4622464179992676, Training time:5615.8411638736725
batch reward last col mean 0.8593660593032837 first col mean 0.8538244366645813 all mean 0.8441077470779419
1.4324885606765747 1.4324885606765747
rl training, epoch0, iter0, batch540/1133, batch loss:1.4324885606765747, Training time:5632.851599693298
batch reward last col mean 0.8096554279327393 first col mean 0.8501207828521729 all mean 0.8328783512115479
1.4491381645202637 1.4491381645202637
rl training, epoch0, iter0, batch541/1133, batch loss:1.4491381645202637, Training time:5649.637205839157
batch reward last col mean 0.8330256938934326 first col mean 0.864624559879303 all mean 0.840976357460022
1.493420124053955 1.4934200048446655
rl training, epoch0, iter0, batch542/1133, batch loss:1.4934200048446655, Training time:5667.067430019379
batch reward last col mean 0.8613795042037964 first col mean 0.8435796499252319 all mean 0.8511555790901184
1.4654953479766846 1.4654953479766846
rl training, epoch0, iter0, batch543/1133, batch loss:1.4654953479766846, Training time:5684.536487340927
batch reward last col mean 0.8580044507980347 first col mean 0.8280876874923706 all mean 0.8614643812179565
1.4371652603149414 1.4371651411056519
rl training, epoch0, iter0, batch544/1133, batch loss:1.4371651411056519, Training time:5702.610120773315
batch reward last col mean 0.8493318557739258 first col mean 0.8862919807434082 all mean 0.8671954870223999
1.456065058708191 1.456065058708191
rl training, epoch0, iter0, batch545/1133, batch loss:1.456065058708191, Training time:5720.091736078262
batch reward last col mean 0.8541960716247559 first col mean 0.8715051412582397 all mean 0.8563135266304016
1.488792896270752 1.488792896270752
rl training, epoch0, iter0, batch546/1133, batch loss:1.488792896270752, Training time:5740.41006231308
batch reward last col mean 0.8525478839874268 first col mean 0.8412640690803528 all mean 0.8326276540756226
1.4239180088043213 1.4239178895950317
rl training, epoch0, iter0, batch547/1133, batch loss:1.4239178895950317, Training time:5758.371443033218
batch reward last col mean 0.8431195020675659 first col mean 0.8342884182929993 all mean 0.8491378426551819
1.4174811840057373 1.4174811840057373
rl training, epoch0, iter0, batch548/1133, batch loss:1.4174811840057373, Training time:5776.740825891495
batch reward last col mean 0.8541045784950256 first col mean 0.8339362740516663 all mean 0.8448389172554016
1.401282548904419 1.401282548904419
rl training, epoch0, iter0, batch549/1133, batch loss:1.401282548904419, Training time:5793.388095378876
batch reward last col mean 0.8012091517448425 first col mean 0.8389583230018616 all mean 0.8558838367462158
1.4129465818405151 1.4129465818405151
rl training, epoch0, iter0, batch550/1133, batch loss:1.4129465818405151, Training time:5810.421709537506
batch reward last col mean 0.8394750952720642 first col mean 0.8172221183776855 all mean 0.8361506462097168
1.416899561882019 1.4168998003005981
rl training, epoch0, iter0, batch551/1133, batch loss:1.4168998003005981, Training time:5827.285049200058
batch reward last col mean 0.8377256393432617 first col mean 0.8799960613250732 all mean 0.855470597743988
1.4306354522705078 1.4306355714797974
rl training, epoch0, iter0, batch552/1133, batch loss:1.4306355714797974, Training time:5844.143324613571
batch reward last col mean 0.8174113035202026 first col mean 0.866358757019043 all mean 0.860470712184906
1.4450831413269043 1.4450831413269043
rl training, epoch0, iter0, batch553/1133, batch loss:1.4450831413269043, Training time:5861.208589315414
batch reward last col mean 0.818475604057312 first col mean 0.8559044003486633 all mean 0.8281360864639282
1.3735743761062622 1.3735742568969727
rl training, epoch0, iter0, batch554/1133, batch loss:1.3735742568969727, Training time:5877.9924874305725
batch reward last col mean 0.8427410125732422 first col mean 0.8665750622749329 all mean 0.8595802783966064
1.4156217575073242 1.4156217575073242
rl training, epoch0, iter0, batch555/1133, batch loss:1.4156217575073242, Training time:5894.8567070961
batch reward last col mean 0.8250998258590698 first col mean 0.8564014434814453 all mean 0.8479548692703247
1.4079140424728394 1.4079140424728394
rl training, epoch0, iter0, batch556/1133, batch loss:1.4079140424728394, Training time:5911.909444570541
batch reward last col mean 0.8562750220298767 first col mean 0.8705357313156128 all mean 0.8715497255325317
1.4060499668121338 1.4060499668121338
rl training, epoch0, iter0, batch557/1133, batch loss:1.4060499668121338, Training time:5928.887601852417
batch reward last col mean 0.8813275098800659 first col mean 0.8567524552345276 all mean 0.8686051964759827
1.4182751178741455 1.4182751178741455
rl training, epoch0, iter0, batch558/1133, batch loss:1.4182751178741455, Training time:5945.785457849503
batch reward last col mean 0.8772105574607849 first col mean 0.8612550497055054 all mean 0.8811232447624207
1.4120965003967285 1.4120967388153076
rl training, epoch0, iter0, batch559/1133, batch loss:1.4120967388153076, Training time:5963.934465646744
batch reward last col mean 0.8553303480148315 first col mean 0.8631670475006104 all mean 0.854012668132782
1.3588767051696777 1.3588767051696777
rl training, epoch0, iter0, batch560/1133, batch loss:1.3588767051696777, Training time:5981.122009277344
batch reward last col mean 0.8217263221740723 first col mean 0.863966166973114 all mean 0.8452231884002686
1.3574124574661255 1.3574124574661255
rl training, epoch0, iter0, batch561/1133, batch loss:1.3574124574661255, Training time:5998.350388050079
batch reward last col mean 0.8557525277137756 first col mean 0.8553715944290161 all mean 0.8479985594749451
1.340795636177063 1.340795636177063
rl training, epoch0, iter0, batch562/1133, batch loss:1.340795636177063, Training time:6015.960838794708
batch reward last col mean 0.8758807182312012 first col mean 0.8710668087005615 all mean 0.8685452342033386
1.4015840291976929 1.4015840291976929
rl training, epoch0, iter0, batch563/1133, batch loss:1.4015840291976929, Training time:6032.866373300552
batch reward last col mean 0.8966214656829834 first col mean 0.8821920156478882 all mean 0.8882887363433838
1.41232430934906 1.41232430934906
rl training, epoch0, iter0, batch564/1133, batch loss:1.41232430934906, Training time:6049.808722496033
batch reward last col mean 0.8577682375907898 first col mean 0.8648304343223572 all mean 0.859258234500885
1.3653576374053955 1.3653576374053955
rl training, epoch0, iter0, batch565/1133, batch loss:1.3653576374053955, Training time:6066.5997133255005
batch reward last col mean 0.8357911109924316 first col mean 0.8455713987350464 all mean 0.8562914133071899
1.3436912298202515 1.3436912298202515
rl training, epoch0, iter0, batch566/1133, batch loss:1.3436912298202515, Training time:6083.500367164612
batch reward last col mean 0.8119511008262634 first col mean 0.856809139251709 all mean 0.8479984402656555
1.3406760692596436 1.3406760692596436
rl training, epoch0, iter0, batch567/1133, batch loss:1.3406760692596436, Training time:6100.328914880753
batch reward last col mean 0.8615607023239136 first col mean 0.8571701645851135 all mean 0.8583223223686218
1.3726365566253662 1.372636318206787
rl training, epoch0, iter0, batch568/1133, batch loss:1.372636318206787, Training time:6117.168118476868
batch reward last col mean 0.8293745517730713 first col mean 0.8561845421791077 all mean 0.8517599105834961
1.3317734003067017 1.3317734003067017
rl training, epoch0, iter0, batch569/1133, batch loss:1.3317734003067017, Training time:6134.250406265259
batch reward last col mean 0.8562547564506531 first col mean 0.8558782339096069 all mean 0.8509750962257385
1.3206844329833984 1.3206844329833984
rl training, epoch0, iter0, batch570/1133, batch loss:1.3206844329833984, Training time:6151.32181596756
batch reward last col mean 0.8292295932769775 first col mean 0.8626706004142761 all mean 0.8525901436805725
1.350281000137329 1.350281000137329
rl training, epoch0, iter0, batch571/1133, batch loss:1.350281000137329, Training time:6168.18708729744
batch reward last col mean 0.8793178200721741 first col mean 0.8405325412750244 all mean 0.8501604795455933
1.3624292612075806 1.3624292612075806
rl training, epoch0, iter0, batch572/1133, batch loss:1.3624292612075806, Training time:6184.843813419342
batch reward last col mean 0.8713332414627075 first col mean 0.8687433004379272 all mean 0.8609588146209717
1.2924163341522217 1.2924163341522217
rl training, epoch0, iter0, batch573/1133, batch loss:1.2924163341522217, Training time:6202.859100103378
batch reward last col mean 0.8406121730804443 first col mean 0.8479511737823486 all mean 0.8499022126197815
1.296415090560913 1.2964152097702026
rl training, epoch0, iter0, batch574/1133, batch loss:1.2964152097702026, Training time:6220.242192745209
batch reward last col mean 0.8585289716720581 first col mean 0.8430269956588745 all mean 0.8437062501907349
1.3098363876342773 1.3098363876342773
rl training, epoch0, iter0, batch575/1133, batch loss:1.3098363876342773, Training time:6237.071526765823
batch reward last col mean 0.8408331871032715 first col mean 0.8776699900627136 all mean 0.851634681224823
1.3114473819732666 1.3114473819732666
rl training, epoch0, iter0, batch576/1133, batch loss:1.3114473819732666, Training time:6254.234122753143
batch reward last col mean 0.8035545349121094 first col mean 0.8509500026702881 all mean 0.8404083847999573
1.2950519323349 1.2950519323349
rl training, epoch0, iter0, batch577/1133, batch loss:1.2950519323349, Training time:6270.699642658234
batch reward last col mean 0.8488520383834839 first col mean 0.8628991842269897 all mean 0.8598479628562927
1.3102189302444458 1.3102189302444458
rl training, epoch0, iter0, batch578/1133, batch loss:1.3102189302444458, Training time:6288.260532855988
batch reward last col mean 0.8651043176651001 first col mean 0.859352707862854 all mean 0.8637598156929016
1.36466383934021 1.36466383934021
rl training, epoch0, iter0, batch579/1133, batch loss:1.36466383934021, Training time:6304.8097586631775
batch reward last col mean 0.9138072729110718 first col mean 0.8680875301361084 all mean 0.8768302202224731
1.306480050086975 1.306480050086975
rl training, epoch0, iter0, batch580/1133, batch loss:1.306480050086975, Training time:6322.11701798439
batch reward last col mean 0.8676924705505371 first col mean 0.8602637052536011 all mean 0.8500105738639832
1.2993005514144897 1.2993005514144897
rl training, epoch0, iter0, batch581/1133, batch loss:1.2993005514144897, Training time:6338.791735649109
batch reward last col mean 0.8484289646148682 first col mean 0.8686485290527344 all mean 0.8628275990486145
1.3321812152862549 1.3321812152862549
rl training, epoch0, iter0, batch582/1133, batch loss:1.3321812152862549, Training time:6355.688764095306
batch reward last col mean 0.8429747223854065 first col mean 0.8527916669845581 all mean 0.848513662815094
1.292799949645996 1.292799949645996
rl training, epoch0, iter0, batch583/1133, batch loss:1.292799949645996, Training time:6372.810327768326
batch reward last col mean 0.837726891040802 first col mean 0.8271132707595825 all mean 0.8427828550338745
1.2928982973098755 1.2928982973098755
rl training, epoch0, iter0, batch584/1133, batch loss:1.2928982973098755, Training time:6389.686619520187
batch reward last col mean 0.8365138173103333 first col mean 0.8493441343307495 all mean 0.8425824642181396
1.303171992301941 1.3031721115112305
rl training, epoch0, iter0, batch585/1133, batch loss:1.3031721115112305, Training time:6406.463064908981
batch reward last col mean 0.875633716583252 first col mean 0.8558096289634705 all mean 0.8573880195617676
1.3401153087615967 1.3401153087615967
rl training, epoch0, iter0, batch586/1133, batch loss:1.3401153087615967, Training time:6424.039390087128
batch reward last col mean 0.7987250089645386 first col mean 0.823113203048706 all mean 0.8152546882629395
1.312281847000122 1.312281847000122
rl training, epoch0, iter0, batch587/1133, batch loss:1.312281847000122, Training time:6441.793480157852
batch reward last col mean 0.8654280304908752 first col mean 0.8376438617706299 all mean 0.8441522121429443
1.3434337377548218 1.3434337377548218
rl training, epoch0, iter0, batch588/1133, batch loss:1.3434337377548218, Training time:6459.515900850296
batch reward last col mean 0.8288865685462952 first col mean 0.8201072216033936 all mean 0.8263781070709229
1.3116483688354492 1.3116483688354492
rl training, epoch0, iter0, batch589/1133, batch loss:1.3116483688354492, Training time:6477.693028450012
batch reward last col mean 0.8399389386177063 first col mean 0.8423169851303101 all mean 0.8619818091392517
1.3503718376159668 1.3503718376159668
rl training, epoch0, iter0, batch590/1133, batch loss:1.3503718376159668, Training time:6496.434260606766
batch reward last col mean 0.8505293130874634 first col mean 0.8584438562393188 all mean 0.8615378737449646
1.356162428855896 1.356162428855896
rl training, epoch0, iter0, batch591/1133, batch loss:1.356162428855896, Training time:6513.914725065231
batch reward last col mean 0.8852449655532837 first col mean 0.8387933373451233 all mean 0.8636440634727478
1.3110125064849854 1.3110125064849854
rl training, epoch0, iter0, batch592/1133, batch loss:1.3110125064849854, Training time:6532.273181438446
batch reward last col mean 0.87930828332901 first col mean 0.8563532829284668 all mean 0.8600998520851135
1.3522485494613647 1.3522486686706543
rl training, epoch0, iter0, batch593/1133, batch loss:1.3522486686706543, Training time:6550.730998754501
batch reward last col mean 0.8649533987045288 first col mean 0.8632907271385193 all mean 0.8469943404197693
1.33890700340271 1.33890700340271
rl training, epoch0, iter0, batch594/1133, batch loss:1.33890700340271, Training time:6570.233273983002
batch reward last col mean 0.8213120102882385 first col mean 0.84028160572052 all mean 0.8406856656074524
1.3804253339767456 1.3804253339767456
rl training, epoch0, iter0, batch595/1133, batch loss:1.3804253339767456, Training time:6590.350486040115
batch reward last col mean 0.8407202363014221 first col mean 0.876735270023346 all mean 0.8722113966941833
1.4349812269210815 1.4349812269210815
rl training, epoch0, iter0, batch596/1133, batch loss:1.4349812269210815, Training time:6609.719158172607
batch reward last col mean 0.8708736896514893 first col mean 0.8483703136444092 all mean 0.8592218160629272
1.3830792903900146 1.3830792903900146
rl training, epoch0, iter0, batch597/1133, batch loss:1.3830792903900146, Training time:6628.835575580597
batch reward last col mean 0.8197591304779053 first col mean 0.8543169498443604 all mean 0.8576764464378357
1.4382612705230713 1.4382612705230713
rl training, epoch0, iter0, batch598/1133, batch loss:1.4382612705230713, Training time:6646.40389752388
batch reward last col mean 0.8412913084030151 first col mean 0.8317245841026306 all mean 0.8379206657409668
1.4145481586456299 1.4145481586456299
rl training, epoch0, iter0, batch599/1133, batch loss:1.4145481586456299, Training time:6665.486803770065
batch reward last col mean 0.8499249219894409 first col mean 0.869210422039032 all mean 0.8523686528205872
1.4563261270523071 1.4563261270523071
rl training, epoch0, iter0, batch600/1133, batch loss:1.4563261270523071, Training time:6685.11220407486
batch reward last col mean 0.8440961837768555 first col mean 0.8499739766120911 all mean 0.8464553356170654
1.4605249166488647 1.4605249166488647
rl training, epoch0, iter0, batch601/1133, batch loss:1.4605249166488647, Training time:6704.42872428894
batch reward last col mean 0.8553231358528137 first col mean 0.8210618495941162 all mean 0.8459905982017517
1.4736744165420532 1.4736744165420532
rl training, epoch0, iter0, batch602/1133, batch loss:1.4736744165420532, Training time:6724.204779148102
batch reward last col mean 0.8612855076789856 first col mean 0.8688517212867737 all mean 0.8688797354698181
1.4634636640548706 1.4634636640548706
rl training, epoch0, iter0, batch603/1133, batch loss:1.4634636640548706, Training time:6741.188167095184
batch reward last col mean 0.879440426826477 first col mean 0.8539989590644836 all mean 0.8596675395965576
1.5018151998519897 1.5018151998519897
rl training, epoch0, iter0, batch604/1133, batch loss:1.5018151998519897, Training time:6759.347884893417
batch reward last col mean 0.8701686859130859 first col mean 0.8668413758277893 all mean 0.859285295009613
1.491706371307373 1.491706371307373
rl training, epoch0, iter0, batch605/1133, batch loss:1.491706371307373, Training time:6776.968576431274
batch reward last col mean 0.8917699456214905 first col mean 0.8729814291000366 all mean 0.869653582572937
1.5193512439727783 1.5193512439727783
rl training, epoch0, iter0, batch606/1133, batch loss:1.5193512439727783, Training time:6794.927850008011
batch reward last col mean 0.8713991045951843 first col mean 0.8636575937271118 all mean 0.865966260433197
1.4848450422286987 1.4848450422286987
rl training, epoch0, iter0, batch607/1133, batch loss:1.4848450422286987, Training time:6813.423704624176
batch reward last col mean 0.8668560981750488 first col mean 0.8585414290428162 all mean 0.8593053817749023
1.4731167554855347 1.4731167554855347
rl training, epoch0, iter0, batch608/1133, batch loss:1.4731167554855347, Training time:6829.9580800533295
batch reward last col mean 0.8838199377059937 first col mean 0.8755800724029541 all mean 0.8648543953895569
1.513009786605835 1.513009786605835
rl training, epoch0, iter0, batch609/1133, batch loss:1.513009786605835, Training time:6846.685384273529
batch reward last col mean 0.8975175619125366 first col mean 0.8510857224464417 all mean 0.8584505915641785
1.5045169591903687 1.5045169591903687
rl training, epoch0, iter0, batch610/1133, batch loss:1.5045169591903687, Training time:6864.363045692444
batch reward last col mean 0.8512558937072754 first col mean 0.8467154502868652 all mean 0.8504180908203125
1.4726264476776123 1.4726264476776123
rl training, epoch0, iter0, batch611/1133, batch loss:1.4726264476776123, Training time:6881.800324201584
batch reward last col mean 0.8830955028533936 first col mean 0.860969066619873 all mean 0.8651594519615173
1.5151604413986206 1.5151604413986206
rl training, epoch0, iter0, batch612/1133, batch loss:1.5151604413986206, Training time:6899.262144565582
batch reward last col mean 0.8346695303916931 first col mean 0.8395155668258667 all mean 0.8379137516021729
1.5016801357269287 1.5016801357269287
rl training, epoch0, iter0, batch613/1133, batch loss:1.5016801357269287, Training time:6915.985647201538
batch reward last col mean 0.8847082853317261 first col mean 0.8479228019714355 all mean 0.8705881834030151
1.5596354007720947 1.5596354007720947
rl training, epoch0, iter0, batch614/1133, batch loss:1.5596354007720947, Training time:6934.2613298892975
batch reward last col mean 0.8542251586914062 first col mean 0.8399529457092285 all mean 0.8400970101356506
1.533575415611267 1.533575415611267
rl training, epoch0, iter0, batch615/1133, batch loss:1.533575415611267, Training time:6952.219127655029
batch reward last col mean 0.8867314457893372 first col mean 0.8462086915969849 all mean 0.8609340190887451
1.5554214715957642 1.5554214715957642
rl training, epoch0, iter0, batch616/1133, batch loss:1.5554214715957642, Training time:6970.184193134308
batch reward last col mean 0.8805385828018188 first col mean 0.8766998052597046 all mean 0.8642911911010742
1.5433032512664795 1.5433032512664795
rl training, epoch0, iter0, batch617/1133, batch loss:1.5433032512664795, Training time:6989.846451044083
batch reward last col mean 0.8258672952651978 first col mean 0.8694791793823242 all mean 0.8585171103477478
1.5119231939315796 1.5119231939315796
rl training, epoch0, iter0, batch618/1133, batch loss:1.5119231939315796, Training time:7010.996990442276
batch reward last col mean 0.8521332740783691 first col mean 0.8685705065727234 all mean 0.8616449236869812
1.5437370538711548 1.5437370538711548
rl training, epoch0, iter0, batch619/1133, batch loss:1.5437370538711548, Training time:7030.247678041458
batch reward last col mean 0.8686190843582153 first col mean 0.8656874895095825 all mean 0.8569775223731995
1.549035906791687 1.549035906791687
rl training, epoch0, iter0, batch620/1133, batch loss:1.549035906791687, Training time:7046.891407489777
batch reward last col mean 0.8341301679611206 first col mean 0.825705885887146 all mean 0.8426775932312012
1.5073909759521484 1.5073908567428589
rl training, epoch0, iter0, batch621/1133, batch loss:1.5073908567428589, Training time:7066.479515075684
batch reward last col mean 0.8438782095909119 first col mean 0.8526042699813843 all mean 0.8630528450012207
1.5026799440383911 1.5026799440383911
rl training, epoch0, iter0, batch622/1133, batch loss:1.5026799440383911, Training time:7083.595537185669
batch reward last col mean 0.8764663934707642 first col mean 0.8840607404708862 all mean 0.883357048034668
1.5774612426757812 1.5774612426757812
rl training, epoch0, iter0, batch623/1133, batch loss:1.5774612426757812, Training time:7102.558005809784
batch reward last col mean 0.8561211228370667 first col mean 0.8550829887390137 all mean 0.861842930316925
1.5197817087173462 1.5197817087173462
rl training, epoch0, iter0, batch624/1133, batch loss:1.5197817087173462, Training time:7122.384282112122
batch reward last col mean 0.81961989402771 first col mean 0.8679393529891968 all mean 0.849419355392456
1.5201438665390015 1.5201438665390015
rl training, epoch0, iter0, batch625/1133, batch loss:1.5201438665390015, Training time:7140.975418806076
batch reward last col mean 0.9006854295730591 first col mean 0.8940886855125427 all mean 0.8983744382858276
1.5635948181152344 1.5635944604873657
rl training, epoch0, iter0, batch626/1133, batch loss:1.5635944604873657, Training time:7158.731600522995
batch reward last col mean 0.8652889132499695 first col mean 0.8914942741394043 all mean 0.8840171694755554
1.550196886062622 1.550196886062622
rl training, epoch0, iter0, batch627/1133, batch loss:1.550196886062622, Training time:7176.768788099289
batch reward last col mean 0.8480701446533203 first col mean 0.8819279670715332 all mean 0.8717660903930664
1.5230859518051147 1.5230859518051147
rl training, epoch0, iter0, batch628/1133, batch loss:1.5230859518051147, Training time:7194.329596996307
batch reward last col mean 0.8263620138168335 first col mean 0.8413355946540833 all mean 0.8572429418563843
1.534489393234253 1.534489393234253
rl training, epoch0, iter0, batch629/1133, batch loss:1.534489393234253, Training time:7212.929017782211
batch reward last col mean 0.8526085615158081 first col mean 0.8596184253692627 all mean 0.8669372797012329
1.55440354347229 1.55440354347229
rl training, epoch0, iter0, batch630/1133, batch loss:1.55440354347229, Training time:7231.968650341034
batch reward last col mean 0.863419771194458 first col mean 0.8786397576332092 all mean 0.886772871017456
1.5615191459655762 1.5615191459655762
rl training, epoch0, iter0, batch631/1133, batch loss:1.5615191459655762, Training time:7250.825746059418
batch reward last col mean 0.8600270748138428 first col mean 0.8729975819587708 all mean 0.8816870450973511
1.592660903930664 1.592660903930664
rl training, epoch0, iter0, batch632/1133, batch loss:1.592660903930664, Training time:7267.841824531555
batch reward last col mean 0.8581216335296631 first col mean 0.8703107833862305 all mean 0.8835498690605164
1.5633913278579712 1.5633913278579712
rl training, epoch0, iter0, batch633/1133, batch loss:1.5633913278579712, Training time:7284.529527425766
batch reward last col mean 0.8634493947029114 first col mean 0.8634114265441895 all mean 0.8654347658157349
1.565506935119629 1.565506935119629
rl training, epoch0, iter0, batch634/1133, batch loss:1.565506935119629, Training time:7303.54292178154
batch reward last col mean 0.866096019744873 first col mean 0.8596718311309814 all mean 0.8744825124740601
1.555286169052124 1.555286169052124
rl training, epoch0, iter0, batch635/1133, batch loss:1.555286169052124, Training time:7322.796415090561
batch reward last col mean 0.8191167712211609 first col mean 0.8772796392440796 all mean 0.8664390444755554
1.5709608793258667 1.5709608793258667
rl training, epoch0, iter0, batch636/1133, batch loss:1.5709608793258667, Training time:7341.368781328201
batch reward last col mean 0.8642398715019226 first col mean 0.8937502503395081 all mean 0.8768510818481445
1.5861515998840332 1.5861514806747437
rl training, epoch0, iter0, batch637/1133, batch loss:1.5861514806747437, Training time:7359.092840909958
batch reward last col mean 0.8816357254981995 first col mean 0.8772311210632324 all mean 0.8689885139465332
1.548377513885498 1.548377513885498
rl training, epoch0, iter0, batch638/1133, batch loss:1.548377513885498, Training time:7377.755708932877
batch reward last col mean 0.8343676328659058 first col mean 0.8743895292282104 all mean 0.84569251537323
1.5423884391784668 1.5423884391784668
rl training, epoch0, iter0, batch639/1133, batch loss:1.5423884391784668, Training time:7394.796542882919
batch reward last col mean 0.8676515817642212 first col mean 0.8786134719848633 all mean 0.8768751621246338
1.583217978477478 1.583217978477478
rl training, epoch0, iter0, batch640/1133, batch loss:1.583217978477478, Training time:7411.789865732193
batch reward last col mean 0.8810381293296814 first col mean 0.8907675743103027 all mean 0.8870395421981812
1.6118191480636597 1.6118191480636597
rl training, epoch0, iter0, batch641/1133, batch loss:1.6118191480636597, Training time:7428.485900878906
batch reward last col mean 0.8397997617721558 first col mean 0.8807225227355957 all mean 0.8735799193382263
1.612313985824585 1.612313985824585
rl training, epoch0, iter0, batch642/1133, batch loss:1.612313985824585, Training time:7445.292410373688
batch reward last col mean 0.9084738492965698 first col mean 0.8707689642906189 all mean 0.8924213647842407
1.6164029836654663 1.6164029836654663
rl training, epoch0, iter0, batch643/1133, batch loss:1.6164029836654663, Training time:7462.250551939011
batch reward last col mean 0.8581154346466064 first col mean 0.8624229431152344 all mean 0.8761807084083557
1.597677230834961 1.597677230834961
rl training, epoch0, iter0, batch644/1133, batch loss:1.597677230834961, Training time:7479.040011644363
batch reward last col mean 0.8777700662612915 first col mean 0.8648202419281006 all mean 0.8603654503822327
1.5873851776123047 1.5873851776123047
rl training, epoch0, iter0, batch645/1133, batch loss:1.5873851776123047, Training time:7495.745292901993
batch reward last col mean 0.8504204154014587 first col mean 0.8618063926696777 all mean 0.8724146485328674
1.6135220527648926 1.6135220527648926
rl training, epoch0, iter0, batch646/1133, batch loss:1.6135220527648926, Training time:7512.497205018997
batch reward last col mean 0.8496363162994385 first col mean 0.8683242797851562 all mean 0.8693493008613586
1.645137906074524 1.645137906074524
rl training, epoch0, iter0, batch647/1133, batch loss:1.645137906074524, Training time:7528.9744784832
batch reward last col mean 0.8369541764259338 first col mean 0.8536323308944702 all mean 0.8637490272521973
1.6181989908218384 1.6181987524032593
rl training, epoch0, iter0, batch648/1133, batch loss:1.6181987524032593, Training time:7545.953261613846
batch reward last col mean 0.8658621311187744 first col mean 0.8716329336166382 all mean 0.8698257803916931
1.637744665145874 1.637744665145874
rl training, epoch0, iter0, batch649/1133, batch loss:1.637744665145874, Training time:7562.777287006378
batch reward last col mean 0.8721933960914612 first col mean 0.8965985178947449 all mean 0.8766164779663086
1.6389657258987427 1.6389654874801636
rl training, epoch0, iter0, batch650/1133, batch loss:1.6389654874801636, Training time:7579.614328145981
batch reward last col mean 0.8570389151573181 first col mean 0.8700268268585205 all mean 0.8556225895881653
1.6082842350006104 1.6082842350006104
rl training, epoch0, iter0, batch651/1133, batch loss:1.6082842350006104, Training time:7596.3095552921295
batch reward last col mean 0.8273283243179321 first col mean 0.8682698011398315 all mean 0.859926700592041
1.6318902969360352 1.6318902969360352
rl training, epoch0, iter0, batch652/1133, batch loss:1.6318902969360352, Training time:7613.042666912079
batch reward last col mean 0.8621249198913574 first col mean 0.8823161721229553 all mean 0.8838633298873901
1.65605890750885 1.65605890750885
rl training, epoch0, iter0, batch653/1133, batch loss:1.65605890750885, Training time:7629.592427492142
batch reward last col mean 0.8439851403236389 first col mean 0.8620826601982117 all mean 0.8664835691452026
1.6416093111038208 1.6416093111038208
rl training, epoch0, iter0, batch654/1133, batch loss:1.6416093111038208, Training time:7645.947377443314
batch reward last col mean 0.8825433850288391 first col mean 0.9025934934616089 all mean 0.890895664691925
1.6755033731460571 1.6755033731460571
rl training, epoch0, iter0, batch655/1133, batch loss:1.6755033731460571, Training time:7662.3325164318085
batch reward last col mean 0.8465288877487183 first col mean 0.8437210917472839 all mean 0.8566155433654785
1.6128101348876953 1.6128101348876953
rl training, epoch0, iter0, batch656/1133, batch loss:1.6128101348876953, Training time:7678.924077510834
batch reward last col mean 0.9057422876358032 first col mean 0.8710671067237854 all mean 0.8877982497215271
1.620193362236023 1.620193362236023
rl training, epoch0, iter0, batch657/1133, batch loss:1.620193362236023, Training time:7695.251213312149
batch reward last col mean 0.8577539920806885 first col mean 0.8579992055892944 all mean 0.8616434931755066
1.622573971748352 1.622573971748352
rl training, epoch0, iter0, batch658/1133, batch loss:1.622573971748352, Training time:7711.4985201358795
batch reward last col mean 0.8468518257141113 first col mean 0.8832153677940369 all mean 0.8779805302619934
1.686327576637268 1.686327576637268
rl training, epoch0, iter0, batch659/1133, batch loss:1.686327576637268, Training time:7727.916394472122
batch reward last col mean 0.838860034942627 first col mean 0.8808931112289429 all mean 0.859589695930481
1.6386526823043823 1.6386526823043823
rl training, epoch0, iter0, batch660/1133, batch loss:1.6386526823043823, Training time:7744.388179540634
batch reward last col mean 0.8598717451095581 first col mean 0.8723461031913757 all mean 0.8592404723167419
1.6138520240783691 1.6138520240783691
rl training, epoch0, iter0, batch661/1133, batch loss:1.6138520240783691, Training time:7761.262367486954
batch reward last col mean 0.8416978120803833 first col mean 0.8733816146850586 all mean 0.8670694231987
1.6464784145355225 1.6464784145355225
rl training, epoch0, iter0, batch662/1133, batch loss:1.6464784145355225, Training time:7778.312032699585
batch reward last col mean 0.8508251905441284 first col mean 0.8454070091247559 all mean 0.847922682762146
1.6190028190612793 1.6190028190612793
rl training, epoch0, iter0, batch663/1133, batch loss:1.6190028190612793, Training time:7794.843296051025
batch reward last col mean 0.8532882332801819 first col mean 0.8700987696647644 all mean 0.8697521090507507
1.604345440864563 1.604345440864563
rl training, epoch0, iter0, batch664/1133, batch loss:1.604345440864563, Training time:7812.919533967972
batch reward last col mean 0.8784223794937134 first col mean 0.8646205067634583 all mean 0.8734385967254639
1.6040359735488892 1.6040360927581787
rl training, epoch0, iter0, batch665/1133, batch loss:1.6040360927581787, Training time:7830.390198707581
batch reward last col mean 0.8351913690567017 first col mean 0.87607342004776 all mean 0.8610785603523254
1.631689429283142 1.631689429283142
rl training, epoch0, iter0, batch666/1133, batch loss:1.631689429283142, Training time:7848.588850021362
batch reward last col mean 0.8759937882423401 first col mean 0.8742820620536804 all mean 0.8855869770050049
1.6491703987121582 1.6491703987121582
rl training, epoch0, iter0, batch667/1133, batch loss:1.6491703987121582, Training time:7867.696994304657
batch reward last col mean 0.8792785406112671 first col mean 0.8813320398330688 all mean 0.8851680755615234
1.6473166942596436 1.6473166942596436
rl training, epoch0, iter0, batch668/1133, batch loss:1.6473166942596436, Training time:7884.869878530502
batch reward last col mean 0.8350636959075928 first col mean 0.8510406613349915 all mean 0.8581402897834778
1.6352328062057495 1.6352328062057495
rl training, epoch0, iter0, batch669/1133, batch loss:1.6352328062057495, Training time:7901.142069816589
batch reward last col mean 0.884448230266571 first col mean 0.8634456992149353 all mean 0.8748446106910706
1.6346489191055298 1.6346489191055298
rl training, epoch0, iter0, batch670/1133, batch loss:1.6346489191055298, Training time:7917.646199941635
batch reward last col mean 0.8585308194160461 first col mean 0.8864960074424744 all mean 0.8649880886077881
1.627118706703186 1.627118706703186
rl training, epoch0, iter0, batch671/1133, batch loss:1.627118706703186, Training time:7933.985064029694
batch reward last col mean 0.8562489748001099 first col mean 0.8458749055862427 all mean 0.8650907278060913
1.6350245475769043 1.6350245475769043
rl training, epoch0, iter0, batch672/1133, batch loss:1.6350245475769043, Training time:7950.390818357468
batch reward last col mean 0.8747530579566956 first col mean 0.8651935458183289 all mean 0.8595491647720337
1.6499019861221313 1.6499019861221313
rl training, epoch0, iter0, batch673/1133, batch loss:1.6499019861221313, Training time:7966.620469331741
batch reward last col mean 0.8512036800384521 first col mean 0.8754642009735107 all mean 0.863883376121521
1.6576008796691895 1.6576008796691895
rl training, epoch0, iter0, batch674/1133, batch loss:1.6576008796691895, Training time:7983.017859220505
batch reward last col mean 0.8650386333465576 first col mean 0.8712280988693237 all mean 0.8769708275794983
1.6850011348724365 1.6850011348724365
rl training, epoch0, iter0, batch675/1133, batch loss:1.6850011348724365, Training time:7999.558161497116
batch reward last col mean 0.8698803782463074 first col mean 0.8513051867485046 all mean 0.8511052131652832
1.6389507055282593 1.6389507055282593
rl training, epoch0, iter0, batch676/1133, batch loss:1.6389507055282593, Training time:8016.184817790985
batch reward last col mean 0.8744372725486755 first col mean 0.8602279424667358 all mean 0.8542773127555847
1.6805026531219482 1.6805026531219482
rl training, epoch0, iter0, batch677/1133, batch loss:1.6805026531219482, Training time:8033.1517033576965
batch reward last col mean 0.8406950235366821 first col mean 0.8711704611778259 all mean 0.8715907335281372
1.6924527883529663 1.6924527883529663
rl training, epoch0, iter0, batch678/1133, batch loss:1.6924527883529663, Training time:8050.165868997574
batch reward last col mean 0.8596551418304443 first col mean 0.8636634349822998 all mean 0.8686020374298096
1.6984400749206543 1.6984400749206543
rl training, epoch0, iter0, batch679/1133, batch loss:1.6984400749206543, Training time:8066.599786520004
batch reward last col mean 0.8372284173965454 first col mean 0.8583163022994995 all mean 0.8611224889755249
1.710661768913269 1.710661768913269
rl training, epoch0, iter0, batch680/1133, batch loss:1.710661768913269, Training time:8083.912140130997
batch reward last col mean 0.8432243466377258 first col mean 0.8594537377357483 all mean 0.8404633402824402
1.7010221481323242 1.7010221481323242
rl training, epoch0, iter0, batch681/1133, batch loss:1.7010221481323242, Training time:8101.000629663467
batch reward last col mean 0.8352471590042114 first col mean 0.8568330407142639 all mean 0.8507610559463501
1.754201889038086 1.754201889038086
rl training, epoch0, iter0, batch682/1133, batch loss:1.754201889038086, Training time:8118.066481590271
batch reward last col mean 0.87391597032547 first col mean 0.8493816256523132 all mean 0.8512965440750122
1.703269124031067 1.703269124031067
rl training, epoch0, iter0, batch683/1133, batch loss:1.703269124031067, Training time:8135.748364448547
batch reward last col mean 0.8142919540405273 first col mean 0.8497974872589111 all mean 0.8533575534820557
1.7466824054718018 1.7466824054718018
rl training, epoch0, iter0, batch684/1133, batch loss:1.7466824054718018, Training time:8153.774289369583
batch reward last col mean 0.8272525072097778 first col mean 0.8709211945533752 all mean 0.8232137560844421
1.683525800704956 1.683525800704956
rl training, epoch0, iter0, batch685/1133, batch loss:1.683525800704956, Training time:8170.8904020786285
batch reward last col mean 0.8443636894226074 first col mean 0.8532029390335083 all mean 0.841404139995575
1.7355141639709473 1.7355141639709473
rl training, epoch0, iter0, batch686/1133, batch loss:1.7355141639709473, Training time:8187.820641279221
batch reward last col mean 0.811335027217865 first col mean 0.8341415524482727 all mean 0.8236374258995056
1.7111541032791138 1.7111538648605347
rl training, epoch0, iter0, batch687/1133, batch loss:1.7111538648605347, Training time:8205.119946956635
batch reward last col mean 0.7908517122268677 first col mean 0.7927548885345459 all mean 0.8112137913703918
1.732236385345459 1.732236385345459
rl training, epoch0, iter0, batch688/1133, batch loss:1.732236385345459, Training time:8221.975034952164
batch reward last col mean 0.8845751285552979 first col mean 0.8481618762016296 all mean 0.8508642911911011
1.740454077720642 1.7404539585113525
rl training, epoch0, iter0, batch689/1133, batch loss:1.7404539585113525, Training time:8238.880805253983
batch reward last col mean 0.8247552514076233 first col mean 0.8489015102386475 all mean 0.8424930572509766
1.7745506763458252 1.7745506763458252
rl training, epoch0, iter0, batch690/1133, batch loss:1.7745506763458252, Training time:8255.205786705017
batch reward last col mean 0.8360182046890259 first col mean 0.8139452338218689 all mean 0.8122435212135315
1.6816200017929077 1.6816200017929077
rl training, epoch0, iter0, batch691/1133, batch loss:1.6816200017929077, Training time:8272.373519420624
batch reward last col mean 0.8304948806762695 first col mean 0.8749904632568359 all mean 0.8579756617546082
1.7726292610168457 1.7726292610168457
rl training, epoch0, iter0, batch692/1133, batch loss:1.7726292610168457, Training time:8288.945467472076
batch reward last col mean 0.8501912355422974 first col mean 0.8649080991744995 all mean 0.8460893630981445
1.741761326789856 1.741761326789856
rl training, epoch0, iter0, batch693/1133, batch loss:1.741761326789856, Training time:8305.497066020966
batch reward last col mean 0.8335120677947998 first col mean 0.838212788105011 all mean 0.8320543766021729
1.738256812095642 1.738256812095642
rl training, epoch0, iter0, batch694/1133, batch loss:1.738256812095642, Training time:8322.00288105011
batch reward last col mean 0.8740277886390686 first col mean 0.8512312173843384 all mean 0.8590081930160522
1.7611801624298096 1.7611801624298096
rl training, epoch0, iter0, batch695/1133, batch loss:1.7611801624298096, Training time:8339.113622665405
batch reward last col mean 0.8058956861495972 first col mean 0.8464534878730774 all mean 0.8082054853439331
1.670021653175354 1.6700217723846436
rl training, epoch0, iter0, batch696/1133, batch loss:1.6700217723846436, Training time:8357.780737876892
batch reward last col mean 0.8184893131256104 first col mean 0.8428267240524292 all mean 0.8229222893714905
1.7009800672531128 1.7009800672531128
rl training, epoch0, iter0, batch697/1133, batch loss:1.7009800672531128, Training time:8375.397434949875
batch reward last col mean 0.7807901501655579 first col mean 0.824368953704834 all mean 0.838784396648407
1.7255204916000366 1.7255202531814575
rl training, epoch0, iter0, batch698/1133, batch loss:1.7255202531814575, Training time:8391.807170629501
batch reward last col mean 0.8107424974441528 first col mean 0.8634690046310425 all mean 0.8445015549659729
1.703132152557373 1.703132152557373
rl training, epoch0, iter0, batch699/1133, batch loss:1.703132152557373, Training time:8408.997302532196
batch reward last col mean 0.8563860654830933 first col mean 0.8301076889038086 all mean 0.8467989563941956
1.7227296829223633 1.7227296829223633
rl training, epoch0, iter0, batch700/1133, batch loss:1.7227296829223633, Training time:8425.82521367073
batch reward last col mean 0.8279523849487305 first col mean 0.8604850769042969 all mean 0.8545328974723816
1.6917493343353271 1.6917493343353271
rl training, epoch0, iter0, batch701/1133, batch loss:1.6917493343353271, Training time:8443.157942533493
batch reward last col mean 0.8663367033004761 first col mean 0.8656101822853088 all mean 0.8638689517974854
1.6731363534927368 1.6731363534927368
rl training, epoch0, iter0, batch702/1133, batch loss:1.6731363534927368, Training time:8460.225406646729
batch reward last col mean 0.8007798790931702 first col mean 0.8489927053451538 all mean 0.8391595482826233
1.6456375122070312 1.6456375122070312
rl training, epoch0, iter0, batch703/1133, batch loss:1.6456375122070312, Training time:8476.883382558823
batch reward last col mean 0.8934522271156311 first col mean 0.8562401533126831 all mean 0.8702524304389954
1.6570103168487549 1.6570103168487549
rl training, epoch0, iter0, batch704/1133, batch loss:1.6570103168487549, Training time:8493.826347589493
batch reward last col mean 0.8391865491867065 first col mean 0.8325205445289612 all mean 0.8524541258811951
1.652510166168213 1.652510166168213
rl training, epoch0, iter0, batch705/1133, batch loss:1.652510166168213, Training time:8511.011738061905
batch reward last col mean 0.8727076649665833 first col mean 0.855743944644928 all mean 0.850011944770813
1.6177202463150024 1.617720127105713
rl training, epoch0, iter0, batch706/1133, batch loss:1.617720127105713, Training time:8528.057062625885
batch reward last col mean 0.8596351146697998 first col mean 0.8340463638305664 all mean 0.8561298847198486
1.6042191982269287 1.6042194366455078
rl training, epoch0, iter0, batch707/1133, batch loss:1.6042194366455078, Training time:8545.288313865662
batch reward last col mean 0.8574253916740417 first col mean 0.8614571690559387 all mean 0.8605530858039856
1.6181894540786743 1.6181894540786743
rl training, epoch0, iter0, batch708/1133, batch loss:1.6181894540786743, Training time:8562.772130966187
batch reward last col mean 0.8606814742088318 first col mean 0.8587307929992676 all mean 0.8733485341072083
1.5875978469848633 1.5875978469848633
rl training, epoch0, iter0, batch709/1133, batch loss:1.5875978469848633, Training time:8579.296674728394
batch reward last col mean 0.8534378409385681 first col mean 0.8505879044532776 all mean 0.8558170795440674
1.5438423156738281 1.5438423156738281
rl training, epoch0, iter0, batch710/1133, batch loss:1.5438423156738281, Training time:8596.450077295303
batch reward last col mean 0.8369662761688232 first col mean 0.8698517084121704 all mean 0.8571186065673828
1.5589367151260376 1.5589367151260376
rl training, epoch0, iter0, batch711/1133, batch loss:1.5589367151260376, Training time:8613.64314198494
batch reward last col mean 0.8859500288963318 first col mean 0.8728891611099243 all mean 0.8752861618995667
1.576299786567688 1.576299786567688
rl training, epoch0, iter0, batch712/1133, batch loss:1.576299786567688, Training time:8630.461173295975
batch reward last col mean 0.8772077560424805 first col mean 0.8847283124923706 all mean 0.88422030210495
1.5635923147201538 1.5635923147201538
rl training, epoch0, iter0, batch713/1133, batch loss:1.5635923147201538, Training time:8646.985871553421
batch reward last col mean 0.8323732018470764 first col mean 0.8809113502502441 all mean 0.8749944567680359
1.5717908143997192 1.5717910528182983
rl training, epoch0, iter0, batch714/1133, batch loss:1.5717910528182983, Training time:8664.658790111542
batch reward last col mean 0.8748823404312134 first col mean 0.8824556469917297 all mean 0.8825956583023071
1.5711904764175415 1.5711904764175415
rl training, epoch0, iter0, batch715/1133, batch loss:1.5711904764175415, Training time:8681.6944937706
batch reward last col mean 0.8834109902381897 first col mean 0.8687252998352051 all mean 0.8704760670661926
1.555168628692627 1.555168628692627
rl training, epoch0, iter0, batch716/1133, batch loss:1.555168628692627, Training time:8698.835735082626
batch reward last col mean 0.8967211246490479 first col mean 0.8789986371994019 all mean 0.8899707198143005
1.566942572593689 1.566942572593689
rl training, epoch0, iter0, batch717/1133, batch loss:1.566942572593689, Training time:8715.569965600967
batch reward last col mean 0.9053229093551636 first col mean 0.8744660019874573 all mean 0.8897815942764282
1.5642668008804321 1.5642666816711426
rl training, epoch0, iter0, batch718/1133, batch loss:1.5642666816711426, Training time:8732.679374217987
batch reward last col mean 0.9082542061805725 first col mean 0.8914231657981873 all mean 0.8888730406761169
1.5681358575820923 1.5681358575820923
rl training, epoch0, iter0, batch719/1133, batch loss:1.5681358575820923, Training time:8749.433547973633
batch reward last col mean 0.8492875099182129 first col mean 0.8742814064025879 all mean 0.8564613461494446
1.523185133934021 1.523185133934021
rl training, epoch0, iter0, batch720/1133, batch loss:1.523185133934021, Training time:8765.917181968689
batch reward last col mean 0.8757513761520386 first col mean 0.8748419880867004 all mean 0.8795742392539978
1.5405555963516235 1.5405555963516235
rl training, epoch0, iter0, batch721/1133, batch loss:1.5405555963516235, Training time:8783.05501627922
batch reward last col mean 0.9102476835250854 first col mean 0.8814089298248291 all mean 0.8857922554016113
1.558330774307251 1.5583306550979614
rl training, epoch0, iter0, batch722/1133, batch loss:1.5583306550979614, Training time:8799.592834949493
batch reward last col mean 0.8779543042182922 first col mean 0.8793442249298096 all mean 0.8800617456436157
1.5434372425079346 1.5434370040893555
rl training, epoch0, iter0, batch723/1133, batch loss:1.5434370040893555, Training time:8817.456332683563
batch reward last col mean 0.8691973686218262 first col mean 0.8703272342681885 all mean 0.874855101108551
1.495038628578186 1.495038628578186
rl training, epoch0, iter0, batch724/1133, batch loss:1.495038628578186, Training time:8833.897023200989
batch reward last col mean 0.845822811126709 first col mean 0.884068489074707 all mean 0.8847156763076782
1.555635690689087 1.555635690689087
rl training, epoch0, iter0, batch725/1133, batch loss:1.555635690689087, Training time:8850.482632637024
batch reward last col mean 0.8623847961425781 first col mean 0.8818688988685608 all mean 0.8733373880386353
1.4908303022384644 1.4908303022384644
rl training, epoch0, iter0, batch726/1133, batch loss:1.4908303022384644, Training time:8867.238825559616
batch reward last col mean 0.854360044002533 first col mean 0.884003758430481 all mean 0.8827821612358093
1.5181910991668701 1.5181910991668701
rl training, epoch0, iter0, batch727/1133, batch loss:1.5181910991668701, Training time:8883.624230861664
batch reward last col mean 0.8434371948242188 first col mean 0.8847454190254211 all mean 0.8717105984687805
1.4988654851913452 1.4988657236099243
rl training, epoch0, iter0, batch728/1133, batch loss:1.4988657236099243, Training time:8901.25178861618
batch reward last col mean 0.8796546459197998 first col mean 0.8829493522644043 all mean 0.8908928632736206
1.511286973953247 1.511286973953247
rl training, epoch0, iter0, batch729/1133, batch loss:1.511286973953247, Training time:8917.750487327576
batch reward last col mean 0.911076545715332 first col mean 0.916054904460907 all mean 0.8992799520492554
1.525742769241333 1.525742769241333
rl training, epoch0, iter0, batch730/1133, batch loss:1.525742769241333, Training time:8935.066374063492
batch reward last col mean 0.8703903555870056 first col mean 0.8912313580513 all mean 0.8879650235176086
1.514524221420288 1.514524221420288
rl training, epoch0, iter0, batch731/1133, batch loss:1.514524221420288, Training time:8951.885949373245
batch reward last col mean 0.8771054744720459 first col mean 0.8752480745315552 all mean 0.882050633430481
1.4948190450668335 1.4948190450668335
rl training, epoch0, iter0, batch732/1133, batch loss:1.4948190450668335, Training time:8968.51715183258
batch reward last col mean 0.8942723870277405 first col mean 0.8799031972885132 all mean 0.8785508275032043
1.4962272644042969 1.4962272644042969
rl training, epoch0, iter0, batch733/1133, batch loss:1.4962272644042969, Training time:8984.917376041412
batch reward last col mean 0.8803388476371765 first col mean 0.8687601089477539 all mean 0.8693624138832092
1.476090908050537 1.476090908050537
rl training, epoch0, iter0, batch734/1133, batch loss:1.476090908050537, Training time:9001.494433641434
batch reward last col mean 0.8939422369003296 first col mean 0.8887524008750916 all mean 0.8876044750213623
1.4731106758117676 1.4731106758117676
rl training, epoch0, iter0, batch735/1133, batch loss:1.4731106758117676, Training time:9019.590567111969
batch reward last col mean 0.8724777698516846 first col mean 0.8947978019714355 all mean 0.8969863653182983
1.478035569190979 1.478035569190979
rl training, epoch0, iter0, batch736/1133, batch loss:1.478035569190979, Training time:9036.136899709702
batch reward last col mean 0.8766781687736511 first col mean 0.8855170011520386 all mean 0.8720248937606812
1.4548461437225342 1.4548461437225342
rl training, epoch0, iter0, batch737/1133, batch loss:1.4548461437225342, Training time:9053.588909864426
batch reward last col mean 0.8995103240013123 first col mean 0.8630607724189758 all mean 0.8878731727600098
1.4926096200942993 1.4926096200942993
rl training, epoch0, iter0, batch738/1133, batch loss:1.4926096200942993, Training time:9070.455019712448
batch reward last col mean 0.8892646431922913 first col mean 0.8997209072113037 all mean 0.8996415734291077
1.5299861431121826 1.5299861431121826
rl training, epoch0, iter0, batch739/1133, batch loss:1.5299861431121826, Training time:9087.008200645447
batch reward last col mean 0.9151579737663269 first col mean 0.9162205457687378 all mean 0.9108173847198486
1.475905179977417 1.475905179977417
rl training, epoch0, iter0, batch740/1133, batch loss:1.475905179977417, Training time:9103.70071387291
batch reward last col mean 0.8771361112594604 first col mean 0.8545688390731812 all mean 0.8651455044746399
1.4533518552780151 1.4533518552780151
rl training, epoch0, iter0, batch741/1133, batch loss:1.4533518552780151, Training time:9120.575564861298
batch reward last col mean 0.8697600960731506 first col mean 0.8862804174423218 all mean 0.8773723840713501
1.4771372079849243 1.4771372079849243
rl training, epoch0, iter0, batch742/1133, batch loss:1.4771372079849243, Training time:9137.341445207596
batch reward last col mean 0.8950462937355042 first col mean 0.904821515083313 all mean 0.9142842292785645
1.5045100450515747 1.5045100450515747
rl training, epoch0, iter0, batch743/1133, batch loss:1.5045100450515747, Training time:9154.280881166458
batch reward last col mean 0.88182133436203 first col mean 0.9008097648620605 all mean 0.891075611114502
1.4412498474121094 1.4412498474121094
rl training, epoch0, iter0, batch744/1133, batch loss:1.4412498474121094, Training time:9170.39445066452
batch reward last col mean 0.8989819288253784 first col mean 0.8873825073242188 all mean 0.8992577195167542
1.4630402326583862 1.4630402326583862
rl training, epoch0, iter0, batch745/1133, batch loss:1.4630402326583862, Training time:9186.993926286697
batch reward last col mean 0.8782597184181213 first col mean 0.8687836527824402 all mean 0.8784459233283997
1.434430480003357 1.434430480003357
rl training, epoch0, iter0, batch746/1133, batch loss:1.434430480003357, Training time:9203.990504264832
batch reward last col mean 0.8486706614494324 first col mean 0.8930726051330566 all mean 0.87842857837677
1.4651802778244019 1.4651802778244019
rl training, epoch0, iter0, batch747/1133, batch loss:1.4651802778244019, Training time:9220.549580097198
batch reward last col mean 0.863654375076294 first col mean 0.8862209320068359 all mean 0.8968498706817627
1.4778008460998535 1.4778008460998535
rl training, epoch0, iter0, batch748/1133, batch loss:1.4778008460998535, Training time:9239.060801029205
batch reward last col mean 0.8794553279876709 first col mean 0.8901903629302979 all mean 0.8917380571365356
1.449249029159546 1.449249029159546
rl training, epoch0, iter0, batch749/1133, batch loss:1.449249029159546, Training time:9257.023246765137
batch reward last col mean 0.8988134860992432 first col mean 0.9089347124099731 all mean 0.9083893299102783
1.4638900756835938 1.4638900756835938
rl training, epoch0, iter0, batch750/1133, batch loss:1.4638900756835938, Training time:9273.62293601036
batch reward last col mean 0.8884859085083008 first col mean 0.8778706789016724 all mean 0.8883136510848999
1.445845603942871 1.445845603942871
rl training, epoch0, iter0, batch751/1133, batch loss:1.445845603942871, Training time:9290.903643608093
batch reward last col mean 0.8841534852981567 first col mean 0.8975419402122498 all mean 0.893485426902771
1.4530839920043945 1.453084111213684
rl training, epoch0, iter0, batch752/1133, batch loss:1.453084111213684, Training time:9307.638646364212
batch reward last col mean 0.9114629030227661 first col mean 0.8751274347305298 all mean 0.8891674280166626
1.430920958518982 1.430920958518982
rl training, epoch0, iter0, batch753/1133, batch loss:1.430920958518982, Training time:9325.759838581085
batch reward last col mean 0.9018831253051758 first col mean 0.9131580591201782 all mean 0.9085504412651062
1.4714480638504028 1.4714478254318237
rl training, epoch0, iter0, batch754/1133, batch loss:1.4714478254318237, Training time:9343.497693777084
batch reward last col mean 0.8948978185653687 first col mean 0.8935277462005615 all mean 0.902012825012207
1.458486557006836 1.458486557006836
rl training, epoch0, iter0, batch755/1133, batch loss:1.458486557006836, Training time:9360.81620502472
batch reward last col mean 0.8732755780220032 first col mean 0.8862720727920532 all mean 0.8931460976600647
1.444525122642517 1.444525122642517
rl training, epoch0, iter0, batch756/1133, batch loss:1.444525122642517, Training time:9378.709077596664
batch reward last col mean 0.8924025297164917 first col mean 0.9116448163986206 all mean 0.905966579914093
1.4396072626113892 1.4396072626113892
rl training, epoch0, iter0, batch757/1133, batch loss:1.4396072626113892, Training time:9395.768407583237
batch reward last col mean 0.8938682079315186 first col mean 0.8926552534103394 all mean 0.8945674896240234
1.4367438554763794 1.4367438554763794
rl training, epoch0, iter0, batch758/1133, batch loss:1.4367438554763794, Training time:9412.28462934494
batch reward last col mean 0.8527891039848328 first col mean 0.8887638449668884 all mean 0.8953502774238586
1.4342025518417358 1.4342025518417358
rl training, epoch0, iter0, batch759/1133, batch loss:1.4342025518417358, Training time:9430.063544750214
batch reward last col mean 0.8893241882324219 first col mean 0.9083887338638306 all mean 0.9004635214805603
1.42856764793396 1.42856764793396
rl training, epoch0, iter0, batch760/1133, batch loss:1.42856764793396, Training time:9446.6736972332
batch reward last col mean 0.868049681186676 first col mean 0.9080120325088501 all mean 0.9023593664169312
1.4406814575195312 1.4406814575195312
rl training, epoch0, iter0, batch761/1133, batch loss:1.4406814575195312, Training time:9463.0659096241
batch reward last col mean 0.8944013714790344 first col mean 0.8970353603363037 all mean 0.895173966884613
1.4357725381851196 1.43577241897583
rl training, epoch0, iter0, batch762/1133, batch loss:1.43577241897583, Training time:9479.889225244522
batch reward last col mean 0.8663504123687744 first col mean 0.9027403593063354 all mean 0.8984341025352478
1.4526976346969604 1.4526976346969604
rl training, epoch0, iter0, batch763/1133, batch loss:1.4526976346969604, Training time:9497.41333436966
batch reward last col mean 0.8779646158218384 first col mean 0.9010035991668701 all mean 0.8912160992622375
1.4236854314804077 1.4236854314804077
rl training, epoch0, iter0, batch764/1133, batch loss:1.4236854314804077, Training time:9514.107672691345
batch reward last col mean 0.916374683380127 first col mean 0.9072129130363464 all mean 0.9137886166572571
1.4405148029327393 1.4405148029327393
rl training, epoch0, iter0, batch765/1133, batch loss:1.4405148029327393, Training time:9531.165825605392
batch reward last col mean 0.9419323801994324 first col mean 0.8998079299926758 all mean 0.9044386744499207
1.4665082693099976 1.4665082693099976
rl training, epoch0, iter0, batch766/1133, batch loss:1.4665082693099976, Training time:9548.851200819016
batch reward last col mean 0.9164153933525085 first col mean 0.9257503151893616 all mean 0.9172828197479248
1.4631150960922241 1.4631150960922241
rl training, epoch0, iter0, batch767/1133, batch loss:1.4631150960922241, Training time:9565.710499286652
batch reward last col mean 0.9179070591926575 first col mean 0.909325897693634 all mean 0.9181382656097412
1.4440938234329224 1.444093942642212
rl training, epoch0, iter0, batch768/1133, batch loss:1.444093942642212, Training time:9582.847075939178
batch reward last col mean 0.9003092050552368 first col mean 0.9015523195266724 all mean 0.9016978740692139
1.4467968940734863 1.4467968940734863
rl training, epoch0, iter0, batch769/1133, batch loss:1.4467968940734863, Training time:9599.921490192413
batch reward last col mean 0.9006229639053345 first col mean 0.9124298095703125 all mean 0.9060800075531006
1.437116026878357 1.4371159076690674
rl training, epoch0, iter0, batch770/1133, batch loss:1.4371159076690674, Training time:9618.020138502121
batch reward last col mean 0.8767301440238953 first col mean 0.9292795658111572 all mean 0.9096653461456299
1.4701279401779175 1.4701279401779175
rl training, epoch0, iter0, batch771/1133, batch loss:1.4701279401779175, Training time:9634.985093593597
batch reward last col mean 0.8904683589935303 first col mean 0.8922977447509766 all mean 0.8915619254112244
1.4330081939697266 1.4330081939697266
rl training, epoch0, iter0, batch772/1133, batch loss:1.4330081939697266, Training time:9651.165664434433
batch reward last col mean 0.8957158923149109 first col mean 0.9037610292434692 all mean 0.8989317417144775
1.4411563873291016 1.4411563873291016
rl training, epoch0, iter0, batch773/1133, batch loss:1.4411563873291016, Training time:9667.328420877457
batch reward last col mean 0.8903141617774963 first col mean 0.8928279876708984 all mean 0.8993895053863525
1.4416649341583252 1.4416649341583252
rl training, epoch0, iter0, batch774/1133, batch loss:1.4416649341583252, Training time:9684.090160131454
batch reward last col mean 0.904419481754303 first col mean 0.9024558067321777 all mean 0.90639328956604
1.4469175338745117 1.4469174146652222
rl training, epoch0, iter0, batch775/1133, batch loss:1.4469174146652222, Training time:9700.509021043777
batch reward last col mean 0.856784999370575 first col mean 0.8922802209854126 all mean 0.8790793418884277
1.4424538612365723 1.4424538612365723
rl training, epoch0, iter0, batch776/1133, batch loss:1.4424538612365723, Training time:9717.736624240875
batch reward last col mean 0.8903477191925049 first col mean 0.927268385887146 all mean 0.9187424778938293
1.480947494506836 1.480947494506836
rl training, epoch0, iter0, batch777/1133, batch loss:1.480947494506836, Training time:9734.281529903412
batch reward last col mean 0.9264929890632629 first col mean 0.9073823690414429 all mean 0.9161640405654907
1.4550058841705322 1.4550058841705322
rl training, epoch0, iter0, batch778/1133, batch loss:1.4550058841705322, Training time:9751.450228691101
batch reward last col mean 0.904957115650177 first col mean 0.8940336108207703 all mean 0.8934687376022339
1.4547804594039917 1.4547803401947021
rl training, epoch0, iter0, batch779/1133, batch loss:1.4547803401947021, Training time:9769.435219287872
batch reward last col mean 0.894787073135376 first col mean 0.9064487218856812 all mean 0.9081278443336487
1.4886949062347412 1.4886949062347412
rl training, epoch0, iter0, batch780/1133, batch loss:1.4886949062347412, Training time:9787.374137878418
batch reward last col mean 0.9189225435256958 first col mean 0.9158278703689575 all mean 0.9123884439468384
1.492020845413208 1.492020845413208
rl training, epoch0, iter0, batch781/1133, batch loss:1.492020845413208, Training time:9804.537402629852
batch reward last col mean 0.9087108969688416 first col mean 0.8929139971733093 all mean 0.9025112986564636
1.4687167406082153 1.4687167406082153
rl training, epoch0, iter0, batch782/1133, batch loss:1.4687167406082153, Training time:9821.341153860092
batch reward last col mean 0.8846615552902222 first col mean 0.9081614017486572 all mean 0.8984775543212891
1.4696346521377563 1.4696346521377563
rl training, epoch0, iter0, batch783/1133, batch loss:1.4696346521377563, Training time:9838.92509675026
batch reward last col mean 0.9204409718513489 first col mean 0.9248963594436646 all mean 0.9155248999595642
1.537133812904358 1.5371336936950684
rl training, epoch0, iter0, batch784/1133, batch loss:1.5371336936950684, Training time:9856.04639673233
batch reward last col mean 0.8706472516059875 first col mean 0.901197612285614 all mean 0.905185878276825
1.493025302886963 1.493025302886963
rl training, epoch0, iter0, batch785/1133, batch loss:1.493025302886963, Training time:9872.680800437927
batch reward last col mean 0.8908145427703857 first col mean 0.8901376724243164 all mean 0.8998604416847229
1.4990886449813843 1.4990886449813843
rl training, epoch0, iter0, batch786/1133, batch loss:1.4990886449813843, Training time:9889.731834411621
batch reward last col mean 0.9317638278007507 first col mean 0.9188903570175171 all mean 0.9202324151992798
1.537490725517273 1.5374908447265625
rl training, epoch0, iter0, batch787/1133, batch loss:1.5374908447265625, Training time:9907.060942649841
batch reward last col mean 0.9092773795127869 first col mean 0.8955053091049194 all mean 0.8935489654541016
1.5256798267364502 1.5256798267364502
rl training, epoch0, iter0, batch788/1133, batch loss:1.5256798267364502, Training time:9923.59847664833
batch reward last col mean 0.879326581954956 first col mean 0.8987519145011902 all mean 0.904350757598877
1.5370361804962158 1.5370361804962158
rl training, epoch0, iter0, batch789/1133, batch loss:1.5370361804962158, Training time:9940.078236341476
batch reward last col mean 0.9192394018173218 first col mean 0.9136332273483276 all mean 0.9105724096298218
1.491155743598938 1.491155743598938
rl training, epoch0, iter0, batch790/1133, batch loss:1.491155743598938, Training time:9956.467591762543
batch reward last col mean 0.8623446226119995 first col mean 0.8858890533447266 all mean 0.8872118592262268
1.4897944927215576 1.4897944927215576
rl training, epoch0, iter0, batch791/1133, batch loss:1.4897944927215576, Training time:9973.355484485626
batch reward last col mean 0.9032248854637146 first col mean 0.9272058010101318 all mean 0.9025058150291443
1.5399941205978394 1.5399941205978394
rl training, epoch0, iter0, batch792/1133, batch loss:1.5399941205978394, Training time:9989.904591798782
batch reward last col mean 0.8737760782241821 first col mean 0.9201986789703369 all mean 0.8960254788398743
1.5278836488723755 1.5278836488723755
rl training, epoch0, iter0, batch793/1133, batch loss:1.5278836488723755, Training time:10006.702809095383
batch reward last col mean 0.8817722201347351 first col mean 0.8979471325874329 all mean 0.9021393060684204
1.4729050397872925 1.4729050397872925
rl training, epoch0, iter0, batch794/1133, batch loss:1.4729050397872925, Training time:10023.822267055511
batch reward last col mean 0.9287869334220886 first col mean 0.9129651784896851 all mean 0.9055007696151733
1.5224003791809082 1.5224003791809082
rl training, epoch0, iter0, batch795/1133, batch loss:1.5224003791809082, Training time:10040.755141735077
batch reward last col mean 0.9045324325561523 first col mean 0.8965902924537659 all mean 0.90742027759552
1.494954228401184 1.494954228401184
rl training, epoch0, iter0, batch796/1133, batch loss:1.494954228401184, Training time:10057.644274950027
batch reward last col mean 0.8891065120697021 first col mean 0.8956639766693115 all mean 0.8920291662216187
1.4851065874099731 1.4851065874099731
rl training, epoch0, iter0, batch797/1133, batch loss:1.4851065874099731, Training time:10075.591244220734
batch reward last col mean 0.8925945162773132 first col mean 0.8952141404151917 all mean 0.9027501344680786
1.4849810600280762 1.4849810600280762
rl training, epoch0, iter0, batch798/1133, batch loss:1.4849810600280762, Training time:10093.217584133148
batch reward last col mean 0.9123334884643555 first col mean 0.9009383916854858 all mean 0.911838710308075
1.4880434274673462 1.4880435466766357
rl training, epoch0, iter0, batch799/1133, batch loss:1.4880435466766357, Training time:10109.918469190598
batch reward last col mean 0.9175218343734741 first col mean 0.8976309299468994 all mean 0.9092852473258972
1.4657965898513794 1.4657965898513794
rl training, epoch0, iter0, batch800/1133, batch loss:1.4657965898513794, Training time:10127.021342992783
batch reward last col mean 0.8961164355278015 first col mean 0.8992044925689697 all mean 0.8943483233451843
1.4350061416625977 1.4350061416625977
rl training, epoch0, iter0, batch801/1133, batch loss:1.4350061416625977, Training time:10143.573629617691
batch reward last col mean 0.9135259389877319 first col mean 0.9220141172409058 all mean 0.9074364304542542
1.4440245628356934 1.4440245628356934
rl training, epoch0, iter0, batch802/1133, batch loss:1.4440245628356934, Training time:10160.211076021194
batch reward last col mean 0.8978709578514099 first col mean 0.8984146118164062 all mean 0.8968437910079956
1.4288724660873413 1.4288724660873413
rl training, epoch0, iter0, batch803/1133, batch loss:1.4288724660873413, Training time:10177.163676738739
batch reward last col mean 0.9171366691589355 first col mean 0.8975305557250977 all mean 0.9121407270431519
1.4307618141174316 1.4307618141174316
rl training, epoch0, iter0, batch804/1133, batch loss:1.4307618141174316, Training time:10193.675290346146
batch reward last col mean 0.9068549275398254 first col mean 0.8978416919708252 all mean 0.8914666771888733
1.4407514333724976 1.4407514333724976
rl training, epoch0, iter0, batch805/1133, batch loss:1.4407514333724976, Training time:10210.966144800186
batch reward last col mean 0.9136722683906555 first col mean 0.8979112505912781 all mean 0.89166659116745
1.3876477479934692 1.3876477479934692
rl training, epoch0, iter0, batch806/1133, batch loss:1.3876477479934692, Training time:10227.416640043259
batch reward last col mean 0.888037919998169 first col mean 0.9047943353652954 all mean 0.8876100182533264
1.3626794815063477 1.3626794815063477
rl training, epoch0, iter0, batch807/1133, batch loss:1.3626794815063477, Training time:10244.759407758713
batch reward last col mean 0.9142988920211792 first col mean 0.8804244995117188 all mean 0.8935497403144836
1.3623284101486206 1.3623284101486206
rl training, epoch0, iter0, batch808/1133, batch loss:1.3623284101486206, Training time:10261.254734754562
batch reward last col mean 0.8799580931663513 first col mean 0.8921172618865967 all mean 0.9029535055160522
1.3961760997772217 1.3961760997772217
rl training, epoch0, iter0, batch809/1133, batch loss:1.3961760997772217, Training time:10279.501890420914
batch reward last col mean 0.8595272898674011 first col mean 0.891049861907959 all mean 0.9000179171562195
1.385603427886963 1.385603427886963
rl training, epoch0, iter0, batch810/1133, batch loss:1.385603427886963, Training time:10296.501136779785
batch reward last col mean 0.8891136050224304 first col mean 0.9160275459289551 all mean 0.9012836217880249
1.3676893711090088 1.3676893711090088
rl training, epoch0, iter0, batch811/1133, batch loss:1.3676893711090088, Training time:10315.048267364502
batch reward last col mean 0.9230022430419922 first col mean 0.9151246547698975 all mean 0.9073938131332397
1.3776990175247192 1.3776990175247192
rl training, epoch0, iter0, batch812/1133, batch loss:1.3776990175247192, Training time:10332.96279668808
batch reward last col mean 0.9180793762207031 first col mean 0.9180948734283447 all mean 0.8990697264671326
1.3688029050827026 1.3688029050827026
rl training, epoch0, iter0, batch813/1133, batch loss:1.3688029050827026, Training time:10350.390416383743
batch reward last col mean 0.8670235276222229 first col mean 0.9075527787208557 all mean 0.9001438617706299
1.3680557012557983 1.3680557012557983
rl training, epoch0, iter0, batch814/1133, batch loss:1.3680557012557983, Training time:10367.256126642227
batch reward last col mean 0.8724840879440308 first col mean 0.8981640934944153 all mean 0.89354407787323
1.3457683324813843 1.3457683324813843
rl training, epoch0, iter0, batch815/1133, batch loss:1.3457683324813843, Training time:10384.490399599075
batch reward last col mean 0.8731476068496704 first col mean 0.88789302110672 all mean 0.8936088681221008
1.319400429725647 1.3194003105163574
rl training, epoch0, iter0, batch816/1133, batch loss:1.3194003105163574, Training time:10401.129619598389
batch reward last col mean 0.8776374459266663 first col mean 0.8972872495651245 all mean 0.8882037997245789
1.335816502571106 1.335816502571106
rl training, epoch0, iter0, batch817/1133, batch loss:1.335816502571106, Training time:10417.612927675247
batch reward last col mean 0.8649263381958008 first col mean 0.883921205997467 all mean 0.8981368541717529
1.324394702911377 1.324394702911377
rl training, epoch0, iter0, batch818/1133, batch loss:1.324394702911377, Training time:10433.896760702133
batch reward last col mean 0.9119815826416016 first col mean 0.8972444534301758 all mean 0.892920732498169
1.3587934970855713 1.3587933778762817
rl training, epoch0, iter0, batch819/1133, batch loss:1.3587933778762817, Training time:10451.33360695839
batch reward last col mean 0.9359344840049744 first col mean 0.8995861411094666 all mean 0.9024721384048462
1.3516016006469727 1.3516016006469727
rl training, epoch0, iter0, batch820/1133, batch loss:1.3516016006469727, Training time:10467.929306268692
batch reward last col mean 0.9066365957260132 first col mean 0.9075462818145752 all mean 0.9086374640464783
1.3179479837417603 1.3179479837417603
rl training, epoch0, iter0, batch821/1133, batch loss:1.3179479837417603, Training time:10484.808964252472
batch reward last col mean 0.8812682628631592 first col mean 0.9085491895675659 all mean 0.8999330997467041
1.3276253938674927 1.3276253938674927
rl training, epoch0, iter0, batch822/1133, batch loss:1.3276253938674927, Training time:10502.224115848541
batch reward last col mean 0.9171760678291321 first col mean 0.9072322249412537 all mean 0.9055013656616211
1.346825122833252 1.346825122833252
rl training, epoch0, iter0, batch823/1133, batch loss:1.346825122833252, Training time:10519.833656549454
batch reward last col mean 0.872451663017273 first col mean 0.9132446050643921 all mean 0.9046941995620728
1.3585783243179321 1.3585783243179321
rl training, epoch0, iter0, batch824/1133, batch loss:1.3585783243179321, Training time:10536.484543561935
batch reward last col mean 0.8977702260017395 first col mean 0.9220402240753174 all mean 0.9149987697601318
1.3717248439788818 1.3717249631881714
rl training, epoch0, iter0, batch825/1133, batch loss:1.3717249631881714, Training time:10553.38173532486
batch reward last col mean 0.9044263958930969 first col mean 0.9040125012397766 all mean 0.8851674199104309
1.3133037090301514 1.3133035898208618
rl training, epoch0, iter0, batch826/1133, batch loss:1.3133035898208618, Training time:10570.778574228287
batch reward last col mean 0.8915470838546753 first col mean 0.9141880869865417 all mean 0.9173007607460022
1.3199412822723389 1.3199412822723389
rl training, epoch0, iter0, batch827/1133, batch loss:1.3199412822723389, Training time:10588.020442724228
batch reward last col mean 0.8909689784049988 first col mean 0.9097263813018799 all mean 0.9123250246047974
1.3830469846725464 1.3830469846725464
rl training, epoch0, iter0, batch828/1133, batch loss:1.3830469846725464, Training time:10604.522077798843
batch reward last col mean 0.8925803899765015 first col mean 0.922857940196991 all mean 0.921866774559021
1.361631155014038 1.361631155014038
rl training, epoch0, iter0, batch829/1133, batch loss:1.361631155014038, Training time:10622.321525096893
batch reward last col mean 0.8891565203666687 first col mean 0.9021950364112854 all mean 0.9026464819908142
1.3571943044662476 1.3571943044662476
rl training, epoch0, iter0, batch830/1133, batch loss:1.3571943044662476, Training time:10640.153974056244
batch reward last col mean 0.9007589221000671 first col mean 0.8999010324478149 all mean 0.9109771251678467
1.323661208152771 1.32366144657135
rl training, epoch0, iter0, batch831/1133, batch loss:1.32366144657135, Training time:10657.421342611313
batch reward last col mean 0.8987832069396973 first col mean 0.9102696776390076 all mean 0.9068740010261536
1.3324381113052368 1.3324381113052368
rl training, epoch0, iter0, batch832/1133, batch loss:1.3324381113052368, Training time:10674.431234836578
batch reward last col mean 0.9239965677261353 first col mean 0.9064733982086182 all mean 0.9237692952156067
1.3374695777893066 1.3374695777893066
rl training, epoch0, iter0, batch833/1133, batch loss:1.3374695777893066, Training time:10690.909316778183
batch reward last col mean 0.8977921009063721 first col mean 0.9057102203369141 all mean 0.9019060134887695
1.3016608953475952 1.3016608953475952
rl training, epoch0, iter0, batch834/1133, batch loss:1.3016608953475952, Training time:10707.39519238472
batch reward last col mean 0.8886913657188416 first col mean 0.8895061016082764 all mean 0.8845083117485046
1.2843061685562134 1.2843061685562134
rl training, epoch0, iter0, batch835/1133, batch loss:1.2843061685562134, Training time:10724.731731653214
batch reward last col mean 0.9086563587188721 first col mean 0.9088252186775208 all mean 0.9118292927742004
1.315662145614624 1.315662145614624
rl training, epoch0, iter0, batch836/1133, batch loss:1.315662145614624, Training time:10741.814518928528
batch reward last col mean 0.9047040939331055 first col mean 0.9137013554573059 all mean 0.9087501168251038
1.2791943550109863 1.2791943550109863
rl training, epoch0, iter0, batch837/1133, batch loss:1.2791943550109863, Training time:10758.550926208496
batch reward last col mean 0.9439421892166138 first col mean 0.8983805775642395 all mean 0.907767117023468
1.307540774345398 1.307540774345398
rl training, epoch0, iter0, batch838/1133, batch loss:1.307540774345398, Training time:10775.028450489044
batch reward last col mean 0.8670489192008972 first col mean 0.9085937738418579 all mean 0.9056991338729858
1.2767804861068726 1.276780605316162
rl training, epoch0, iter0, batch839/1133, batch loss:1.276780605316162, Training time:10792.447675943375
batch reward last col mean 0.899318277835846 first col mean 0.9144634008407593 all mean 0.924216091632843
1.2865389585494995 1.2865389585494995
rl training, epoch0, iter0, batch840/1133, batch loss:1.2865389585494995, Training time:10809.247302293777
batch reward last col mean 0.8805196285247803 first col mean 0.9140559434890747 all mean 0.9088174104690552
1.269026517868042 1.269026517868042
rl training, epoch0, iter0, batch841/1133, batch loss:1.269026517868042, Training time:10826.838214159012
batch reward last col mean 0.8781657218933105 first col mean 0.9259761571884155 all mean 0.9208346009254456
1.2952492237091064 1.2952492237091064
rl training, epoch0, iter0, batch842/1133, batch loss:1.2952492237091064, Training time:10843.431896686554
batch reward last col mean 0.8792455792427063 first col mean 0.9125990867614746 all mean 0.9056451916694641
1.2706563472747803 1.2706564664840698
rl training, epoch0, iter0, batch843/1133, batch loss:1.2706564664840698, Training time:10860.156399726868
batch reward last col mean 0.9277039766311646 first col mean 0.9083530902862549 all mean 0.9143626093864441
1.240705966949463 1.240705966949463
rl training, epoch0, iter0, batch844/1133, batch loss:1.240705966949463, Training time:10876.523329734802
batch reward last col mean 0.9006239771842957 first col mean 0.9087221622467041 all mean 0.9020536541938782
1.2413161993026733 1.2413161993026733
rl training, epoch0, iter0, batch845/1133, batch loss:1.2413161993026733, Training time:10893.192065000534
batch reward last col mean 0.9413921236991882 first col mean 0.9286345839500427 all mean 0.9193321466445923
1.25419282913208 1.25419282913208
rl training, epoch0, iter0, batch846/1133, batch loss:1.25419282913208, Training time:10909.961678743362
batch reward last col mean 0.9226360321044922 first col mean 0.8949615955352783 all mean 0.9093532562255859
1.2106727361679077 1.2106727361679077
rl training, epoch0, iter0, batch847/1133, batch loss:1.2106727361679077, Training time:10926.779707431793
batch reward last col mean 0.8840624094009399 first col mean 0.9107392430305481 all mean 0.9186728596687317
1.2456386089324951 1.2456386089324951
rl training, epoch0, iter0, batch848/1133, batch loss:1.2456386089324951, Training time:10943.608481884003
batch reward last col mean 0.8794829249382019 first col mean 0.9107465744018555 all mean 0.908286452293396
1.232107162475586 1.232107162475586
rl training, epoch0, iter0, batch849/1133, batch loss:1.232107162475586, Training time:10960.020468711853
batch reward last col mean 0.9091383218765259 first col mean 0.9039120078086853 all mean 0.9176589250564575
1.212980031967163 1.212980031967163
rl training, epoch0, iter0, batch850/1133, batch loss:1.212980031967163, Training time:10976.588646173477
batch reward last col mean 0.9091384410858154 first col mean 0.9120693206787109 all mean 0.9118949770927429
1.1963251829147339 1.1963251829147339
rl training, epoch0, iter0, batch851/1133, batch loss:1.1963251829147339, Training time:10992.996020793915
batch reward last col mean 0.891679048538208 first col mean 0.9035428762435913 all mean 0.8849844932556152
1.1662744283676147 1.1662744283676147
rl training, epoch0, iter0, batch852/1133, batch loss:1.1662744283676147, Training time:11009.151664018631
batch reward last col mean 0.9339072704315186 first col mean 0.9175620675086975 all mean 0.9033365249633789
1.1971993446350098 1.1971993446350098
rl training, epoch0, iter0, batch853/1133, batch loss:1.1971993446350098, Training time:11025.4056661129
batch reward last col mean 0.917860746383667 first col mean 0.904951810836792 all mean 0.9089691638946533
1.2158653736114502 1.2158653736114502
rl training, epoch0, iter0, batch854/1133, batch loss:1.2158653736114502, Training time:11041.80192232132
batch reward last col mean 0.8781439661979675 first col mean 0.9027662873268127 all mean 0.9034771919250488
1.185284972190857 1.185284972190857
rl training, epoch0, iter0, batch855/1133, batch loss:1.185284972190857, Training time:11058.60984659195
batch reward last col mean 0.8788532018661499 first col mean 0.9053007364273071 all mean 0.9051985144615173
1.1905096769332886 1.1905096769332886
rl training, epoch0, iter0, batch856/1133, batch loss:1.1905096769332886, Training time:11075.24558210373
batch reward last col mean 0.9160917401313782 first col mean 0.9132928252220154 all mean 0.9115220904350281
1.1661592721939087 1.1661592721939087
rl training, epoch0, iter0, batch857/1133, batch loss:1.1661592721939087, Training time:11091.878697872162
batch reward last col mean 0.8415510058403015 first col mean 0.9168498516082764 all mean 0.8973944783210754
1.1949630975723267 1.1949630975723267
rl training, epoch0, iter0, batch858/1133, batch loss:1.1949630975723267, Training time:11109.039447069168
batch reward last col mean 0.9130135178565979 first col mean 0.9214293956756592 all mean 0.9131897687911987
1.2021921873092651 1.2021923065185547
rl training, epoch0, iter0, batch859/1133, batch loss:1.2021923065185547, Training time:11125.917868375778
batch reward last col mean 0.9068030118942261 first col mean 0.918358325958252 all mean 0.9179334044456482
1.1791988611221313 1.1791988611221313
rl training, epoch0, iter0, batch860/1133, batch loss:1.1791988611221313, Training time:11143.47816324234
batch reward last col mean 0.891319990158081 first col mean 0.9348918199539185 all mean 0.9173378944396973
1.2083501815795898 1.2083501815795898
rl training, epoch0, iter0, batch861/1133, batch loss:1.2083501815795898, Training time:11160.7831158638
batch reward last col mean 0.9283969402313232 first col mean 0.9123168587684631 all mean 0.916968584060669
1.1879363059997559 1.1879363059997559
rl training, epoch0, iter0, batch862/1133, batch loss:1.1879363059997559, Training time:11177.606562614441
batch reward last col mean 0.8820251822471619 first col mean 0.890493631362915 all mean 0.8928971886634827
1.16386079788208 1.1638606786727905
rl training, epoch0, iter0, batch863/1133, batch loss:1.1638606786727905, Training time:11195.28994512558
batch reward last col mean 0.9092967510223389 first col mean 0.9108412265777588 all mean 0.9119362235069275
1.188938856124878 1.188938856124878
rl training, epoch0, iter0, batch864/1133, batch loss:1.188938856124878, Training time:11212.286600589752
batch reward last col mean 0.908684253692627 first col mean 0.9347807765007019 all mean 0.9240732789039612
1.2087303400039673 1.2087303400039673
rl training, epoch0, iter0, batch865/1133, batch loss:1.2087303400039673, Training time:11228.658199071884
batch reward last col mean 0.8964968323707581 first col mean 0.9138379096984863 all mean 0.9068395495414734
1.1677619218826294 1.1677619218826294
rl training, epoch0, iter0, batch866/1133, batch loss:1.1677619218826294, Training time:11245.043174982071
batch reward last col mean 0.9196096062660217 first col mean 0.9170330166816711 all mean 0.9232490658760071
1.1998822689056396 1.1998822689056396
rl training, epoch0, iter0, batch867/1133, batch loss:1.1998822689056396, Training time:11261.703593492508
batch reward last col mean 0.9442778825759888 first col mean 0.9272058010101318 all mean 0.9288623929023743
1.2141098976135254 1.214110016822815
rl training, epoch0, iter0, batch868/1133, batch loss:1.214110016822815, Training time:11278.037032604218
batch reward last col mean 0.9051127433776855 first col mean 0.9253320097923279 all mean 0.9263871908187866
1.2205086946487427 1.2205086946487427
rl training, epoch0, iter0, batch869/1133, batch loss:1.2205086946487427, Training time:11294.394077539444
batch reward last col mean 0.9321123361587524 first col mean 0.9269016981124878 all mean 0.9398859143257141
1.2196975946426392 1.2196975946426392
rl training, epoch0, iter0, batch870/1133, batch loss:1.2196975946426392, Training time:11310.74933385849
batch reward last col mean 0.9020667672157288 first col mean 0.9067848920822144 all mean 0.9097155928611755
1.1929746866226196 1.1929746866226196
rl training, epoch0, iter0, batch871/1133, batch loss:1.1929746866226196, Training time:11328.477917194366
batch reward last col mean 0.9047653079032898 first col mean 0.9161660075187683 all mean 0.9139143228530884
1.210411548614502 1.210411548614502
rl training, epoch0, iter0, batch872/1133, batch loss:1.210411548614502, Training time:11345.569762468338
batch reward last col mean 0.9279036521911621 first col mean 0.9281962513923645 all mean 0.9310062527656555
1.1988561153411865 1.1988561153411865
rl training, epoch0, iter0, batch873/1133, batch loss:1.1988561153411865, Training time:11364.060978651047
batch reward last col mean 0.9051822423934937 first col mean 0.932796061038971 all mean 0.9383000135421753
1.204018473625183 1.204018473625183
rl training, epoch0, iter0, batch874/1133, batch loss:1.204018473625183, Training time:11380.899687290192
batch reward last col mean 0.9178357124328613 first col mean 0.9282388687133789 all mean 0.931602418422699
1.1960713863372803 1.1960713863372803
rl training, epoch0, iter0, batch875/1133, batch loss:1.1960713863372803, Training time:11398.003901481628
batch reward last col mean 0.9179905652999878 first col mean 0.9216346740722656 all mean 0.924780011177063
1.190916895866394 1.190916895866394
rl training, epoch0, iter0, batch876/1133, batch loss:1.190916895866394, Training time:11414.897764444351
batch reward last col mean 0.9446085691452026 first col mean 0.9226363301277161 all mean 0.9214377403259277
1.2004380226135254 1.2004380226135254
rl training, epoch0, iter0, batch877/1133, batch loss:1.2004380226135254, Training time:11432.980846643448
batch reward last col mean 0.9278075695037842 first col mean 0.9159790277481079 all mean 0.9254274368286133
1.1740127801895142 1.1740127801895142
rl training, epoch0, iter0, batch878/1133, batch loss:1.1740127801895142, Training time:11449.388945102692
batch reward last col mean 0.9123268127441406 first col mean 0.926529586315155 all mean 0.9195806980133057
1.1640197038650513 1.1640197038650513
rl training, epoch0, iter0, batch879/1133, batch loss:1.1640197038650513, Training time:11465.976259469986
batch reward last col mean 0.9324713349342346 first col mean 0.9399547576904297 all mean 0.9307531714439392
1.200482726097107 1.200482726097107
rl training, epoch0, iter0, batch880/1133, batch loss:1.200482726097107, Training time:11483.056554555893
batch reward last col mean 0.9326263666152954 first col mean 0.9267698526382446 all mean 0.9188388586044312
1.1919810771942139 1.1919810771942139
rl training, epoch0, iter0, batch881/1133, batch loss:1.1919810771942139, Training time:11499.594849348068
batch reward last col mean 0.9343811869621277 first col mean 0.9189884662628174 all mean 0.9233737587928772
1.1762676239013672 1.1762675046920776
rl training, epoch0, iter0, batch882/1133, batch loss:1.1762675046920776, Training time:11516.039123296738
batch reward last col mean 0.9205245971679688 first col mean 0.9291300773620605 all mean 0.9268402457237244
1.1861259937286377 1.1861259937286377
rl training, epoch0, iter0, batch883/1133, batch loss:1.1861259937286377, Training time:11532.570356607437
batch reward last col mean 0.8861355781555176 first col mean 0.9256268739700317 all mean 0.9126453399658203
1.1466397047042847 1.1466397047042847
rl training, epoch0, iter0, batch884/1133, batch loss:1.1466397047042847, Training time:11549.11476778984
batch reward last col mean 0.9240520000457764 first col mean 0.9159711003303528 all mean 0.9215114712715149
1.1318613290786743 1.1318613290786743
rl training, epoch0, iter0, batch885/1133, batch loss:1.1318613290786743, Training time:11566.194040775299
batch reward last col mean 0.9324204325675964 first col mean 0.9176949262619019 all mean 0.9326551556587219
1.1711827516555786 1.1711827516555786
rl training, epoch0, iter0, batch886/1133, batch loss:1.1711827516555786, Training time:11582.83171248436
batch reward last col mean 0.9029494524002075 first col mean 0.9157422184944153 all mean 0.9218193292617798
1.152178406715393 1.152178406715393
rl training, epoch0, iter0, batch887/1133, batch loss:1.152178406715393, Training time:11601.018594264984
batch reward last col mean 0.9292646050453186 first col mean 0.9312861561775208 all mean 0.9244885444641113
1.167873501777649 1.167873501777649
rl training, epoch0, iter0, batch888/1133, batch loss:1.167873501777649, Training time:11618.213917016983
batch reward last col mean 0.918980062007904 first col mean 0.9162458181381226 all mean 0.9271242022514343
1.1620187759399414 1.1620187759399414
rl training, epoch0, iter0, batch889/1133, batch loss:1.1620187759399414, Training time:11636.342071294785
batch reward last col mean 0.9279137253761292 first col mean 0.9161505103111267 all mean 0.9274094104766846
1.1645692586898804 1.1645692586898804
rl training, epoch0, iter0, batch890/1133, batch loss:1.1645692586898804, Training time:11653.02761387825
batch reward last col mean 0.921507716178894 first col mean 0.9228626489639282 all mean 0.9292129278182983
1.1596746444702148 1.1596746444702148
rl training, epoch0, iter0, batch891/1133, batch loss:1.1596746444702148, Training time:11669.4680621624
batch reward last col mean 0.9420073628425598 first col mean 0.938773512840271 all mean 0.9362375140190125
1.148406744003296 1.148406744003296
rl training, epoch0, iter0, batch892/1133, batch loss:1.148406744003296, Training time:11686.472341537476
batch reward last col mean 0.9283764362335205 first col mean 0.9362279176712036 all mean 0.9339427947998047
1.171481966972351 1.171481966972351
rl training, epoch0, iter0, batch893/1133, batch loss:1.171481966972351, Training time:11703.657717943192
batch reward last col mean 0.934368371963501 first col mean 0.9284323453903198 all mean 0.9371806383132935
1.1523362398147583 1.1523362398147583
rl training, epoch0, iter0, batch894/1133, batch loss:1.1523362398147583, Training time:11720.409915447235
batch reward last col mean 0.9076091647148132 first col mean 0.9132248759269714 all mean 0.918232798576355
1.1438370943069458 1.1438370943069458
rl training, epoch0, iter0, batch895/1133, batch loss:1.1438370943069458, Training time:11737.215136528015
batch reward last col mean 0.9300051927566528 first col mean 0.9240059852600098 all mean 0.9329516291618347
1.1154099702835083 1.1154099702835083
rl training, epoch0, iter0, batch896/1133, batch loss:1.1154099702835083, Training time:11753.529559373856
batch reward last col mean 0.9254944324493408 first col mean 0.9397971034049988 all mean 0.9367472529411316
1.1447057723999023 1.1447057723999023
rl training, epoch0, iter0, batch897/1133, batch loss:1.1447057723999023, Training time:11770.141691684723
batch reward last col mean 0.9297000765800476 first col mean 0.9230601191520691 all mean 0.9263802170753479
1.1523231267929077 1.1523231267929077
rl training, epoch0, iter0, batch898/1133, batch loss:1.1523231267929077, Training time:11786.703772068024
batch reward last col mean 0.9428912997245789 first col mean 0.9275355935096741 all mean 0.9363639950752258
1.157967209815979 1.157967209815979
rl training, epoch0, iter0, batch899/1133, batch loss:1.157967209815979, Training time:11803.075228452682
batch reward last col mean 0.9374448657035828 first col mean 0.9178417921066284 all mean 0.9275951981544495
1.133467674255371 1.133467674255371
rl training, epoch0, iter0, batch900/1133, batch loss:1.133467674255371, Training time:11820.313940286636
batch reward last col mean 0.9021539092063904 first col mean 0.9091203212738037 all mean 0.9236165881156921
1.1486903429031372 1.1486903429031372
rl training, epoch0, iter0, batch901/1133, batch loss:1.1486903429031372, Training time:11837.81583237648
batch reward last col mean 0.9236866235733032 first col mean 0.9358844757080078 all mean 0.9286358952522278
1.1379526853561401 1.1379526853561401
rl training, epoch0, iter0, batch902/1133, batch loss:1.1379526853561401, Training time:11854.481626033783
batch reward last col mean 0.9384223222732544 first col mean 0.9236853122711182 all mean 0.9386042356491089
1.1583058834075928 1.1583058834075928
rl training, epoch0, iter0, batch903/1133, batch loss:1.1583058834075928, Training time:11871.729333639145
batch reward last col mean 0.9270206689834595 first col mean 0.931046187877655 all mean 0.9343103170394897
1.16771399974823 1.16771399974823
rl training, epoch0, iter0, batch904/1133, batch loss:1.16771399974823, Training time:11888.529792070389
batch reward last col mean 0.9337950944900513 first col mean 0.9374118447303772 all mean 0.9303299188613892
1.1562222242355347 1.1562222242355347
rl training, epoch0, iter0, batch905/1133, batch loss:1.1562222242355347, Training time:11905.859827041626
batch reward last col mean 0.9131009578704834 first col mean 0.9352150559425354 all mean 0.931396484375
1.1638953685760498 1.1638953685760498
rl training, epoch0, iter0, batch906/1133, batch loss:1.1638953685760498, Training time:11922.278619289398
batch reward last col mean 0.9324164390563965 first col mean 0.9406301975250244 all mean 0.9442724585533142
1.1422818899154663 1.1422817707061768
rl training, epoch0, iter0, batch907/1133, batch loss:1.1422817707061768, Training time:11938.811686038971
batch reward last col mean 0.9363649487495422 first col mean 0.940071165561676 all mean 0.9381337761878967
1.1666944026947021 1.1666942834854126
rl training, epoch0, iter0, batch908/1133, batch loss:1.1666942834854126, Training time:11955.266350030899
batch reward last col mean 0.9508134126663208 first col mean 0.9481958150863647 all mean 0.9368235468864441
1.1884688138961792 1.1884688138961792
rl training, epoch0, iter0, batch909/1133, batch loss:1.1884688138961792, Training time:11971.920689344406
batch reward last col mean 0.9238530397415161 first col mean 0.924944281578064 all mean 0.9306952953338623
1.1771187782287598 1.1771187782287598
rl training, epoch0, iter0, batch910/1133, batch loss:1.1771187782287598, Training time:11988.555751800537
batch reward last col mean 0.9271431565284729 first col mean 0.9284834265708923 all mean 0.9340381026268005
1.1567176580429077 1.1567176580429077
rl training, epoch0, iter0, batch911/1133, batch loss:1.1567176580429077, Training time:12005.30304813385
batch reward last col mean 0.9421652555465698 first col mean 0.9391782879829407 all mean 0.9293115735054016
1.173589825630188 1.173589825630188
rl training, epoch0, iter0, batch912/1133, batch loss:1.173589825630188, Training time:12022.331533670425
batch reward last col mean 0.9141248464584351 first col mean 0.9252049326896667 all mean 0.9243913292884827
1.1697914600372314 1.1697914600372314
rl training, epoch0, iter0, batch913/1133, batch loss:1.1697914600372314, Training time:12039.568846940994
batch reward last col mean 0.920923113822937 first col mean 0.932067334651947 all mean 0.9357026219367981
1.1802380084991455 1.1802380084991455
rl training, epoch0, iter0, batch914/1133, batch loss:1.1802380084991455, Training time:12057.137803316116
batch reward last col mean 0.9280446171760559 first col mean 0.9269863367080688 all mean 0.9285407662391663
1.169350266456604 1.169350266456604
rl training, epoch0, iter0, batch915/1133, batch loss:1.169350266456604, Training time:12075.099027872086
batch reward last col mean 0.9582107067108154 first col mean 0.9402700066566467 all mean 0.9423732757568359
1.1799949407577515 1.1799949407577515
rl training, epoch0, iter0, batch916/1133, batch loss:1.1799949407577515, Training time:12092.786674022675
batch reward last col mean 0.9235836267471313 first col mean 0.9391419291496277 all mean 0.9364640712738037
1.1728843450546265 1.1728843450546265
rl training, epoch0, iter0, batch917/1133, batch loss:1.1728843450546265, Training time:12109.554129123688
batch reward last col mean 0.9134735465049744 first col mean 0.9265466928482056 all mean 0.9285870790481567
1.2016897201538086 1.2016898393630981
rl training, epoch0, iter0, batch918/1133, batch loss:1.2016898393630981, Training time:12126.978159189224
batch reward last col mean 0.9215558171272278 first col mean 0.9328815937042236 all mean 0.9306827187538147
1.2175769805908203 1.2175769805908203
rl training, epoch0, iter0, batch919/1133, batch loss:1.2175769805908203, Training time:12143.60239315033
batch reward last col mean 0.920892596244812 first col mean 0.9338089227676392 all mean 0.9301789999008179
1.2042038440704346 1.2042038440704346
rl training, epoch0, iter0, batch920/1133, batch loss:1.2042038440704346, Training time:12160.278708696365
batch reward last col mean 0.9469373226165771 first col mean 0.9377506375312805 all mean 0.9319086074829102
1.2060104608535767 1.2060104608535767
rl training, epoch0, iter0, batch921/1133, batch loss:1.2060104608535767, Training time:12176.66779255867
batch reward last col mean 0.8845189809799194 first col mean 0.9294551014900208 all mean 0.9176114797592163
1.1618983745574951 1.1618983745574951
rl training, epoch0, iter0, batch922/1133, batch loss:1.1618983745574951, Training time:12193.05015707016
batch reward last col mean 0.9208031296730042 first col mean 0.9136770963668823 all mean 0.9275665283203125
1.1879554986953735 1.1879554986953735
rl training, epoch0, iter0, batch923/1133, batch loss:1.1879554986953735, Training time:12209.538114786148
batch reward last col mean 0.9494060277938843 first col mean 0.9303797483444214 all mean 0.9387257695198059
1.1835286617279053 1.1835286617279053
rl training, epoch0, iter0, batch924/1133, batch loss:1.1835286617279053, Training time:12225.981265068054
batch reward last col mean 0.9255498051643372 first col mean 0.9229499101638794 all mean 0.9295662641525269
1.1659921407699585 1.1659921407699585
rl training, epoch0, iter0, batch925/1133, batch loss:1.1659921407699585, Training time:12243.88119316101
batch reward last col mean 0.9244855642318726 first col mean 0.9183937311172485 all mean 0.9261099100112915
1.161496639251709 1.1614965200424194
rl training, epoch0, iter0, batch926/1133, batch loss:1.1614965200424194, Training time:12260.481951236725
batch reward last col mean 0.926069438457489 first col mean 0.9229285717010498 all mean 0.9290416836738586
1.150822401046753 1.150822401046753
rl training, epoch0, iter0, batch927/1133, batch loss:1.150822401046753, Training time:12277.072373867035
batch reward last col mean 0.9131429195404053 first col mean 0.9194357395172119 all mean 0.9195725917816162
1.1543152332305908 1.1543152332305908
rl training, epoch0, iter0, batch928/1133, batch loss:1.1543152332305908, Training time:12294.238886833191
batch reward last col mean 0.9163609147071838 first col mean 0.9174031615257263 all mean 0.9153266549110413
1.1307761669158936 1.1307761669158936
rl training, epoch0, iter0, batch929/1133, batch loss:1.1307761669158936, Training time:12311.38627076149
batch reward last col mean 0.9222763776779175 first col mean 0.9394672513008118 all mean 0.9385657906532288
1.1618785858154297 1.1618785858154297
rl training, epoch0, iter0, batch930/1133, batch loss:1.1618785858154297, Training time:12327.953698635101
batch reward last col mean 0.9357367753982544 first col mean 0.9331827759742737 all mean 0.9315617084503174
1.1257985830307007 1.1257985830307007
rl training, epoch0, iter0, batch931/1133, batch loss:1.1257985830307007, Training time:12344.606705188751
batch reward last col mean 0.9134647846221924 first col mean 0.9266129732131958 all mean 0.9200853109359741
1.068142056465149 1.068142056465149
rl training, epoch0, iter0, batch932/1133, batch loss:1.068142056465149, Training time:12361.180125236511
batch reward last col mean 0.9269226789474487 first col mean 0.9209588766098022 all mean 0.9235616326332092
1.1073040962219238 1.1073042154312134
rl training, epoch0, iter0, batch933/1133, batch loss:1.1073042154312134, Training time:12377.807614088058
batch reward last col mean 0.9446801543235779 first col mean 0.9347004890441895 all mean 0.930846095085144
1.1283338069915771 1.1283338069915771
rl training, epoch0, iter0, batch934/1133, batch loss:1.1283338069915771, Training time:12394.259619474411
batch reward last col mean 0.8993040919303894 first col mean 0.932815670967102 all mean 0.9214600920677185
1.100015640258789 1.100015640258789
rl training, epoch0, iter0, batch935/1133, batch loss:1.100015640258789, Training time:12410.528367757797
batch reward last col mean 0.9143078923225403 first col mean 0.9357613921165466 all mean 0.9294334053993225
1.1169089078903198 1.1169089078903198
rl training, epoch0, iter0, batch936/1133, batch loss:1.1169089078903198, Training time:12426.885078907013
batch reward last col mean 0.9406443238258362 first col mean 0.9262070059776306 all mean 0.913676381111145
1.0627468824386597 1.0627467632293701
rl training, epoch0, iter0, batch937/1133, batch loss:1.0627467632293701, Training time:12444.961244344711
batch reward last col mean 0.9452416300773621 first col mean 0.9246504306793213 all mean 0.9322333931922913
1.0775668621063232 1.0775668621063232
rl training, epoch0, iter0, batch938/1133, batch loss:1.0775668621063232, Training time:12461.96386051178
batch reward last col mean 0.9239420890808105 first col mean 0.931964635848999 all mean 0.9290324449539185
1.071929931640625 1.0719298124313354
rl training, epoch0, iter0, batch939/1133, batch loss:1.0719298124313354, Training time:12478.402133226395
batch reward last col mean 0.934490442276001 first col mean 0.9177235960960388 all mean 0.9258580207824707
1.0853466987609863 1.0853466987609863
rl training, epoch0, iter0, batch940/1133, batch loss:1.0853466987609863, Training time:12494.838474273682
batch reward last col mean 0.9113782644271851 first col mean 0.9186562299728394 all mean 0.9201779365539551
1.065654993057251 1.065654993057251
rl training, epoch0, iter0, batch941/1133, batch loss:1.065654993057251, Training time:12512.043586492538
batch reward last col mean 0.925233781337738 first col mean 0.9231964945793152 all mean 0.9175062775611877
1.0648798942565918 1.0648798942565918
rl training, epoch0, iter0, batch942/1133, batch loss:1.0648798942565918, Training time:12528.580681562424
batch reward last col mean 0.9168524742126465 first col mean 0.9303371906280518 all mean 0.9246976971626282
1.0510261058807373 1.0510261058807373
rl training, epoch0, iter0, batch943/1133, batch loss:1.0510261058807373, Training time:12545.156318426132
batch reward last col mean 0.930636465549469 first col mean 0.9251471757888794 all mean 0.9366155862808228
1.0785036087036133 1.0785036087036133
rl training, epoch0, iter0, batch944/1133, batch loss:1.0785036087036133, Training time:12561.855523347855
batch reward last col mean 0.9279685020446777 first col mean 0.9391415119171143 all mean 0.939735472202301
1.0590465068817139 1.0590465068817139
rl training, epoch0, iter0, batch945/1133, batch loss:1.0590465068817139, Training time:12579.147821187973
batch reward last col mean 0.921252965927124 first col mean 0.9189687967300415 all mean 0.92828768491745
1.066329836845398 1.066329836845398
rl training, epoch0, iter0, batch946/1133, batch loss:1.066329836845398, Training time:12596.422463655472
batch reward last col mean 0.9167901873588562 first col mean 0.9343200922012329 all mean 0.9294130802154541
1.074821949005127 1.074821949005127
rl training, epoch0, iter0, batch947/1133, batch loss:1.074821949005127, Training time:12613.107394218445
batch reward last col mean 0.9133731126785278 first col mean 0.9198553562164307 all mean 0.9155147075653076
1.0208473205566406 1.0208473205566406
rl training, epoch0, iter0, batch948/1133, batch loss:1.0208473205566406, Training time:12629.506459474564
batch reward last col mean 0.9263681173324585 first col mean 0.9393982291221619 all mean 0.9273470640182495
1.0765730142593384 1.0765730142593384
rl training, epoch0, iter0, batch949/1133, batch loss:1.0765730142593384, Training time:12645.895612001419
batch reward last col mean 0.9217632412910461 first col mean 0.9278512001037598 all mean 0.926904022693634
1.0440843105316162 1.0440843105316162
rl training, epoch0, iter0, batch950/1133, batch loss:1.0440843105316162, Training time:12662.453479766846
batch reward last col mean 0.948725163936615 first col mean 0.9497642517089844 all mean 0.9394307136535645
1.078783392906189 1.078783392906189
rl training, epoch0, iter0, batch951/1133, batch loss:1.078783392906189, Training time:12678.880685567856
batch reward last col mean 0.9605935215950012 first col mean 0.936434268951416 all mean 0.938910722732544
1.0407658815383911 1.0407658815383911
rl training, epoch0, iter0, batch952/1133, batch loss:1.0407658815383911, Training time:12696.062076330185
batch reward last col mean 0.9425989985466003 first col mean 0.948341429233551 all mean 0.9401108622550964
1.0493768453598022 1.0493767261505127
rl training, epoch0, iter0, batch953/1133, batch loss:1.0493767261505127, Training time:12712.622504234314
batch reward last col mean 0.9355714321136475 first col mean 0.9355481863021851 all mean 0.9416491389274597
1.0447227954864502 1.0447229146957397
rl training, epoch0, iter0, batch954/1133, batch loss:1.0447229146957397, Training time:12729.486248731613
batch reward last col mean 0.9399915337562561 first col mean 0.9386404156684875 all mean 0.9407212138175964
1.0597164630889893 1.0597164630889893
rl training, epoch0, iter0, batch955/1133, batch loss:1.0597164630889893, Training time:12746.03641986847
batch reward last col mean 0.9315297603607178 first col mean 0.9340579509735107 all mean 0.9477115273475647
1.0507681369781494 1.0507681369781494
rl training, epoch0, iter0, batch956/1133, batch loss:1.0507681369781494, Training time:12763.06741976738
batch reward last col mean 0.9317351579666138 first col mean 0.9443285465240479 all mean 0.9480709433555603
1.0400159358978271 1.0400159358978271
rl training, epoch0, iter0, batch957/1133, batch loss:1.0400159358978271, Training time:12780.855549097061
batch reward last col mean 0.9308615922927856 first col mean 0.9439053535461426 all mean 0.9287571907043457
0.9960083365440369 0.9960083365440369
rl training, epoch0, iter0, batch958/1133, batch loss:0.9960083365440369, Training time:12798.163192033768
batch reward last col mean 0.9566524028778076 first col mean 0.9498863220214844 all mean 0.9502579569816589
1.0201815366744995 1.0201815366744995
rl training, epoch0, iter0, batch959/1133, batch loss:1.0201815366744995, Training time:12814.989580631256
RL early break
rl training, epoch 0, iter 0, loss:1.2146471364423632, Training time:12814.995211601257 
rl epoch 0, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.49705738321091364 Time: 140.9302999973297 s
loss of true 0.20852172268194533 loss of gen 0.00976210799639225 loss of other 0.2787735530644629 first score 0.9330147504806519
cur_epoch: 1
D Training Loss: 0.4781236192186849 Time: 149.15919375419617 s
loss of true 0.2038071054278068 loss of gen 0.0002957562170960364 loss of other 0.274020757069129 first score 0.0023672119714319706
cur_epoch: 2
D Training Loss: 0.46955297252086026 Time: 143.46008133888245 s
loss of true 0.19836411984195146 loss of gen 0.00036283077085672114 loss of other 0.2708260217337932 first score 1.0482550351298414e-05
cur_epoch: 3
D Training Loss: 0.45784918010392656 Time: 151.95909690856934 s
loss of true 0.19253956136562503 loss of gen 0.00029087057459107056 loss of other 0.26501874822304505 first score 5.8621488278731704e-05
cur_epoch: 4
D Training Loss: 0.4509032596714814 Time: 144.57018971443176 s
loss of true 0.18894815006986299 loss of gen 0.00022434730246508736 loss of other 0.2617307627953372 first score 2.1830323930771556e-06
rl epoch 1, begin RL for generator...
batch reward last col mean 4.74901662528282e-06 first col mean 0.0026102669071406126 all mean 9.348875755677e-05
0.00013202973059378564 0.00013202973059378564
rl training, epoch1, iter0, batch0/1133, batch loss:0.00013202973059378564, Training time:13561.566794395447
batch reward last col mean 1.4393252058653161e-05 first col mean 2.9627290132339112e-06 all mean 5.2379502449184656e-05
9.380550181958824e-05 9.380550909554586e-05
rl training, epoch1, iter0, batch1/1133, batch loss:9.380550909554586e-05, Training time:13578.600415706635
batch reward last col mean 2.196939749410376e-05 first col mean 6.260345344344387e-06 all mean 5.891060209251009e-05
2.3894823243608698e-05 2.389482870057691e-05
rl training, epoch1, iter0, batch2/1133, batch loss:2.389482870057691e-05, Training time:13595.367722511292
batch reward last col mean 8.778908977546962e-07 first col mean 9.198258794640424e-07 all mean 5.316795068210922e-05
7.926963735371828e-05 7.926963735371828e-05
rl training, epoch1, iter0, batch3/1133, batch loss:7.926963735371828e-05, Training time:13613.589295625687
batch reward last col mean 0.00012694347242359072 first col mean 3.843905687972438e-06 all mean 0.00013457082968670875
0.0002642994513735175 0.00026429948047734797
rl training, epoch1, iter0, batch4/1133, batch loss:0.00026429948047734797, Training time:13630.358595609665
batch reward last col mean 3.8068437788751908e-06 first col mean 1.6586831407039426e-05 all mean 7.545908738393337e-05
6.616334576392546e-05 6.616335303988308e-05
rl training, epoch1, iter0, batch5/1133, batch loss:6.616335303988308e-05, Training time:13647.988634586334
batch reward last col mean 2.3365364540950395e-05 first col mean 1.7925338397617452e-05 all mean 3.1834581022849306e-05
3.3296637411694974e-05 3.3296637411694974e-05
rl training, epoch1, iter0, batch6/1133, batch loss:3.3296637411694974e-05, Training time:13664.719171524048
batch reward last col mean 1.5363461898232345e-06 first col mean 8.861733476805966e-06 all mean 5.843452163389884e-05
5.699137182091363e-05 5.699137182091363e-05
rl training, epoch1, iter0, batch7/1133, batch loss:5.699137182091363e-05, Training time:13681.550265789032
batch reward last col mean 0.00014233998081181198 first col mean 3.55729684997641e-06 all mean 6.747827137587592e-05
6.548874807776883e-05 6.548874807776883e-05
rl training, epoch1, iter0, batch8/1133, batch loss:6.548874807776883e-05, Training time:13698.312944173813
batch reward last col mean 1.2122040971007664e-06 first col mean 8.820277798804455e-06 all mean 6.530649989144877e-05
0.0001994072226807475 0.0001994072226807475
rl training, epoch1, iter0, batch9/1133, batch loss:0.0001994072226807475, Training time:13715.109072446823
batch reward last col mean 2.787066705423058e-06 first col mean 0.0012467727065086365 all mean 4.826693839277141e-05
0.00010353082325309515 0.00010353081597713754
rl training, epoch1, iter0, batch10/1133, batch loss:0.00010353081597713754, Training time:13731.645045518875
batch reward last col mean 0.004226397257298231 first col mean 3.1155648230196675e-06 all mean 0.0037666463758796453
0.0003155248414259404 0.0003155248414259404
rl training, epoch1, iter0, batch11/1133, batch loss:0.0003155248414259404, Training time:13748.271819591522
batch reward last col mean 0.00012924830662086606 first col mean 3.7934541978756897e-06 all mean 0.0001468540431233123
0.00019076501484960318 0.00019076501484960318
rl training, epoch1, iter0, batch12/1133, batch loss:0.00019076501484960318, Training time:13764.861110687256
batch reward last col mean 5.481111656990834e-06 first col mean 0.0012477722484618425 all mean 6.386512541212142e-05
8.616191189503297e-05 8.616191189503297e-05
rl training, epoch1, iter0, batch13/1133, batch loss:8.616191189503297e-05, Training time:13782.19963812828
batch reward last col mean 3.592167922761291e-05 first col mean 1.1746683412638959e-05 all mean 9.921049058903009e-05
0.0002852321485988796 0.0002852321485988796
rl training, epoch1, iter0, batch14/1133, batch loss:0.0002852321485988796, Training time:13798.711691617966
batch reward last col mean 5.12508449901361e-05 first col mean 3.0368223633558955e-06 all mean 0.00013345107436180115
0.00010953182936646044 0.00010953182936646044
rl training, epoch1, iter0, batch15/1133, batch loss:0.00010953182936646044, Training time:13815.171180725098
batch reward last col mean 3.78511322196573e-05 first col mean 7.686530807404779e-06 all mean 5.532210343517363e-05
0.00010114725591847673 0.00010114727774634957
rl training, epoch1, iter0, batch16/1133, batch loss:0.00010114727774634957, Training time:13831.79818558693
batch reward last col mean 1.2714971489913296e-05 first col mean 1.052006336976774e-05 all mean 4.188618186162785e-05
5.4408526921179146e-05 5.440853419713676e-05
rl training, epoch1, iter0, batch17/1133, batch loss:5.440853419713676e-05, Training time:13848.980063676834
batch reward last col mean 6.522615421999944e-06 first col mean 1.2148712812631857e-05 all mean 9.256507473764941e-05
0.00010310696961823851 0.00010310696961823851
rl training, epoch1, iter0, batch18/1133, batch loss:0.00010310696961823851, Training time:13865.938201904297
batch reward last col mean 2.504202939235256e-06 first col mean 1.5059238194226054e-06 all mean 0.00011017964425263926
0.0002901470579672605 0.0002901470579672605
rl training, epoch1, iter0, batch19/1133, batch loss:0.0002901470579672605, Training time:13883.238446950912
batch reward last col mean 4.25909020123072e-05 first col mean 4.340263330959715e-06 all mean 8.792142034508288e-05
0.00010955613834084943 0.00010955615289276466
rl training, epoch1, iter0, batch20/1133, batch loss:0.00010955615289276466, Training time:13901.17669057846
batch reward last col mean 0.007225003559142351 first col mean 5.836098353029229e-06 all mean 0.0002374525211052969
0.000752390653360635 0.0007523905369453132
rl training, epoch1, iter0, batch21/1133, batch loss:0.0007523905369453132, Training time:13917.936387777328
batch reward last col mean 9.219715866493061e-05 first col mean 0.0006005658651702106 all mean 0.00023562532442156225
0.0005218447768129408 0.0005218447768129408
rl training, epoch1, iter0, batch22/1133, batch loss:0.0005218447768129408, Training time:13934.745319366455
batch reward last col mean 2.1790547179989517e-05 first col mean 1.0199057214776985e-05 all mean 4.9018395657185465e-05
6.396227399818599e-05 6.39622812741436e-05
rl training, epoch1, iter0, batch23/1133, batch loss:6.39622812741436e-05, Training time:13951.388236045837
batch reward last col mean 0.00015117402654141188 first col mean 5.357808549888432e-05 all mean 9.289602166973054e-05
0.00010525222751311958 0.00010525222751311958
rl training, epoch1, iter0, batch24/1133, batch loss:0.00010525222751311958, Training time:13968.200052499771
batch reward last col mean 0.004383806139230728 first col mean 4.144410013395827e-06 all mean 0.0033889494370669127
0.000564036366995424 0.000564036366995424
rl training, epoch1, iter0, batch25/1133, batch loss:0.000564036366995424, Training time:13984.758486270905
batch reward last col mean 1.4118500075710472e-05 first col mean 1.4689322597405408e-05 all mean 0.00010371859389124438
6.204539386089891e-05 6.20453865849413e-05
rl training, epoch1, iter0, batch26/1133, batch loss:6.20453865849413e-05, Training time:14001.287719011307
batch reward last col mean 2.602575477794744e-06 first col mean 5.1831248129019514e-05 all mean 4.883127985522151e-05
1.492089813837083e-05 1.4920906323823147e-05
rl training, epoch1, iter0, batch27/1133, batch loss:1.4920906323823147e-05, Training time:14017.744678020477
batch reward last col mean 6.139561719464837e-06 first col mean 2.570617652963847e-06 all mean 9.735872299643233e-05
7.33164488337934e-05 7.331644155783579e-05
rl training, epoch1, iter0, batch28/1133, batch loss:7.331644155783579e-05, Training time:14034.370053052902
batch reward last col mean 8.100526611087844e-05 first col mean 3.2502226531505585e-05 all mean 8.005609561223537e-05
0.0001425604277756065 0.00014256041322369128
rl training, epoch1, iter0, batch29/1133, batch loss:0.00014256041322369128, Training time:14050.922680854797
batch reward last col mean 0.0023116020020097494 first col mean 3.3253854780923575e-06 all mean 0.0010109363356605172
0.0002583204477559775 0.0002583204477559775
rl training, epoch1, iter0, batch30/1133, batch loss:0.0002583204477559775, Training time:14068.479226589203
batch reward last col mean 1.3027186469116714e-05 first col mean 6.226488949323539e-06 all mean 0.0003852960653603077
0.0003919921291526407 0.0003919921291526407
rl training, epoch1, iter0, batch31/1133, batch loss:0.0003919921291526407, Training time:14085.653678894043
batch reward last col mean 0.0002292077842867002 first col mean 6.657656194875017e-05 all mean 0.00031208054861053824
0.0003557872259989381 0.0003557871968951076
rl training, epoch1, iter0, batch32/1133, batch loss:0.0003557871968951076, Training time:14103.005156993866
batch reward last col mean 9.666482947068289e-05 first col mean 2.158802089979872e-05 all mean 5.666954893968068e-05
7.839431054890156e-05 7.839431054890156e-05
rl training, epoch1, iter0, batch33/1133, batch loss:7.839431054890156e-05, Training time:14120.52630019188
batch reward last col mean 1.2423355656210333e-05 first col mean 2.606619773359853e-06 all mean 9.675350156612694e-05
0.00011015625204890966 0.00011015624477295205
rl training, epoch1, iter0, batch34/1133, batch loss:0.00011015624477295205, Training time:14137.077414751053
batch reward last col mean 5.71005220990628e-05 first col mean 3.273224365329952e-06 all mean 0.0004473286389838904
0.0004992092726752162 0.0004992092726752162
rl training, epoch1, iter0, batch35/1133, batch loss:0.0004992092726752162, Training time:14153.884703874588
batch reward last col mean 0.0010528258280828595 first col mean 6.635986210312694e-05 all mean 0.0007693056832067668
0.0003847148909699172 0.0003847149491775781
rl training, epoch1, iter0, batch36/1133, batch loss:0.0003847149491775781, Training time:14170.653285503387
batch reward last col mean 4.926790552417515e-06 first col mean 1.743315442581661e-05 all mean 7.992640166776255e-05
8.72615200933069e-05 8.72615200933069e-05
rl training, epoch1, iter0, batch37/1133, batch loss:8.72615200933069e-05, Training time:14187.619041204453
batch reward last col mean 4.537244876701152e-06 first col mean 0.00040476370486430824 all mean 9.466408664593473e-05
0.00014025629207026213 0.00014025629207026213
rl training, epoch1, iter0, batch38/1133, batch loss:0.00014025629207026213, Training time:14204.385699510574
batch reward last col mean 1.4310920960269868e-05 first col mean 1.677290492807515e-05 all mean 0.00027100450824946165
0.00023605591559316963 0.00023605591559316963
rl training, epoch1, iter0, batch39/1133, batch loss:0.00023605591559316963, Training time:14221.050299167633
batch reward last col mean 0.00010400776955066249 first col mean 4.167801307630725e-06 all mean 0.00016759124991949648
0.0002299643529113382 0.00022996430925559253
rl training, epoch1, iter0, batch40/1133, batch loss:0.00022996430925559253, Training time:14237.880564689636
batch reward last col mean 4.0124254155671224e-05 first col mean 3.564228973118588e-05 all mean 0.00023954134667292237
0.0003207592817489058 0.0003207592817489058
rl training, epoch1, iter0, batch41/1133, batch loss:0.0003207592817489058, Training time:14254.330374956131
batch reward last col mean 7.170045137172565e-06 first col mean 1.684453854977619e-05 all mean 0.00010223558638244867
0.00010681263665901497 0.00010681262210709974
rl training, epoch1, iter0, batch42/1133, batch loss:0.00010681262210709974, Training time:14270.808190107346
batch reward last col mean 7.99280678620562e-05 first col mean 3.7075847103551496e-06 all mean 6.460860458901152e-05
0.00014161758008413017 0.0001416175946360454
rl training, epoch1, iter0, batch43/1133, batch loss:0.0001416175946360454, Training time:14287.08470416069
batch reward last col mean 0.00011583072773646563 first col mean 0.00028496116283349693 all mean 0.0001535748306196183
0.00017957249656319618 0.00017957246745936573
rl training, epoch1, iter0, batch44/1133, batch loss:0.00017957246745936573, Training time:14303.61771440506
batch reward last col mean 5.733666057494702e-06 first col mean 9.822984793572687e-06 all mean 5.688139935955405e-05
7.697864202782512e-05 7.69786347518675e-05
rl training, epoch1, iter0, batch45/1133, batch loss:7.69786347518675e-05, Training time:14320.525483131409
batch reward last col mean 1.1140860806335695e-05 first col mean 0.0014122850261628628 all mean 8.217920549213886e-05
4.9573594878893346e-05 4.957359124091454e-05
rl training, epoch1, iter0, batch46/1133, batch loss:4.957359124091454e-05, Training time:14337.878307819366
batch reward last col mean 9.688388672657311e-06 first col mean 3.3130706924566766e-06 all mean 7.164093403844163e-05
0.00011314812581986189 0.00011314812581986189
rl training, epoch1, iter0, batch47/1133, batch loss:0.00011314812581986189, Training time:14354.500592708588
batch reward last col mean 2.3468403014703654e-05 first col mean 4.041194188175723e-06 all mean 4.6433982788585126e-05
3.9793565520085394e-05 3.979355460614897e-05
rl training, epoch1, iter0, batch48/1133, batch loss:3.979355460614897e-05, Training time:14371.576623439789
batch reward last col mean 4.12568215324427e-06 first col mean 0.00012091580720152706 all mean 6.551888509420678e-05
8.099358092295006e-05 8.099358092295006e-05
rl training, epoch1, iter0, batch49/1133, batch loss:8.099358092295006e-05, Training time:14388.365056037903
batch reward last col mean 2.7816543024528073e-06 first col mean 1.7192029190482572e-05 all mean 8.792390872258693e-05
8.406272536376491e-05 8.406273991568014e-05
rl training, epoch1, iter0, batch50/1133, batch loss:8.406273991568014e-05, Training time:14405.010110855103
batch reward last col mean 0.0011736401356756687 first col mean 1.6920037523959763e-05 all mean 0.00015345447172876447
0.00040992803405970335 0.00040992803405970335
rl training, epoch1, iter0, batch51/1133, batch loss:0.00040992803405970335, Training time:14421.655684709549
batch reward last col mean 3.3769911169656552e-06 first col mean 2.6812062060344033e-05 all mean 6.020901128067635e-05
7.920082862256095e-05 7.920082134660333e-05
rl training, epoch1, iter0, batch52/1133, batch loss:7.920082134660333e-05, Training time:14438.081293821335
batch reward last col mean 5.36011066287756e-05 first col mean 2.258845415781252e-05 all mean 6.802959251217544e-05
0.00011243583867326379 0.00011243582412134856
rl training, epoch1, iter0, batch53/1133, batch loss:0.00011243582412134856, Training time:14454.65578508377
batch reward last col mean 8.193865141947754e-06 first col mean 9.49255918385461e-05 all mean 0.00010156750067835674
0.00019521638751029968 0.00019521637295838445
rl training, epoch1, iter0, batch54/1133, batch loss:0.00019521637295838445, Training time:14471.411472558975
batch reward last col mean 1.1121566785732284e-05 first col mean 1.1379310308257118e-05 all mean 6.273606413742527e-05
6.0336707974784076e-05 6.0336707974784076e-05
rl training, epoch1, iter0, batch55/1133, batch loss:6.0336707974784076e-05, Training time:14488.091992616653
batch reward last col mean 1.6299080016324297e-05 first col mean 1.7348467736155726e-05 all mean 6.823216244811192e-05
8.078651444520801e-05 8.078651444520801e-05
rl training, epoch1, iter0, batch56/1133, batch loss:8.078651444520801e-05, Training time:14505.53480553627
batch reward last col mean 0.0010426733642816544 first col mean 1.2185502782813273e-05 all mean 0.000906666275113821
0.0002474387001711875 0.000247438729275018
rl training, epoch1, iter0, batch57/1133, batch loss:0.000247438729275018, Training time:14522.76898431778
batch reward last col mean 1.053868982126005e-05 first col mean 6.829074209235841e-06 all mean 9.426576434634626e-05
0.00025546798133291304 0.00025546798133291304
rl training, epoch1, iter0, batch58/1133, batch loss:0.00025546798133291304, Training time:14541.294646978378
batch reward last col mean 2.5003537302836776e-05 first col mean 0.00047923275269567966 all mean 0.00014169476344250143
0.00021149154054000974 0.00021149154054000974
rl training, epoch1, iter0, batch59/1133, batch loss:0.00021149154054000974, Training time:14558.701734781265
batch reward last col mean 8.922395863919519e-06 first col mean 1.5497023923671804e-05 all mean 0.00012163486098870635
9.194208541885018e-05 9.194208541885018e-05
rl training, epoch1, iter0, batch60/1133, batch loss:9.194208541885018e-05, Training time:14576.865401268005
batch reward last col mean 3.407833446544828e-06 first col mean 6.957900041015819e-06 all mean 5.527172834263183e-05
5.847503416589461e-05 5.8475030527915806e-05
rl training, epoch1, iter0, batch61/1133, batch loss:5.8475030527915806e-05, Training time:14594.51987862587
batch reward last col mean 5.3323865358834155e-06 first col mean 8.380572580790613e-06 all mean 7.17750153853558e-05
0.00010669472248991951 0.00010669472248991951
rl training, epoch1, iter0, batch62/1133, batch loss:0.00010669472248991951, Training time:14610.86752653122
batch reward last col mean 6.902734185132431e-06 first col mean 9.628911357140169e-06 all mean 4.5459568354999647e-05
5.2520281315082684e-05 5.2520281315082684e-05
rl training, epoch1, iter0, batch63/1133, batch loss:5.2520281315082684e-05, Training time:14627.256092309952
batch reward last col mean 2.8946187740075402e-05 first col mean 0.0009017036645673215 all mean 7.091859879437834e-05
0.00011621409794315696 0.0001162141197710298
rl training, epoch1, iter0, batch64/1133, batch loss:0.0001162141197710298, Training time:14643.886744499207
batch reward last col mean 6.720344390487298e-05 first col mean 1.1102587450295687e-05 all mean 0.00011131056089652702
0.0001117649080697447 0.00011176490079378709
rl training, epoch1, iter0, batch65/1133, batch loss:0.00011176490079378709, Training time:14660.379117250443
batch reward last col mean 0.005636317189782858 first col mean 0.0002070550835924223 all mean 0.004912989214062691
0.0005697185406461358 0.0005697185406461358
rl training, epoch1, iter0, batch66/1133, batch loss:0.0005697185406461358, Training time:14677.082369089127
batch reward last col mean 1.3687969840248115e-05 first col mean 9.334293281426653e-06 all mean 6.463469617301598e-05
0.00011644894402706996 0.00011644894402706996
rl training, epoch1, iter0, batch67/1133, batch loss:0.00011644894402706996, Training time:14693.957052469254
batch reward last col mean 1.8565551727078855e-05 first col mean 5.357704594644019e-06 all mean 8.879380038706586e-05
0.00012655059981625527 0.00012655059981625527
rl training, epoch1, iter0, batch68/1133, batch loss:0.00012655059981625527, Training time:14711.328123092651
batch reward last col mean 9.09072878130246e-06 first col mean 2.3117554519558325e-06 all mean 0.00021398856188170612
0.00034259530366398394 0.00034259530366398394
rl training, epoch1, iter0, batch69/1133, batch loss:0.00034259530366398394, Training time:14728.078229427338
batch reward last col mean 3.7542345125984866e-06 first col mean 0.00022765020548831671 all mean 0.00014386173279490322
0.00019921862985938787 0.0001992186444113031
rl training, epoch1, iter0, batch70/1133, batch loss:0.0001992186444113031, Training time:14744.779081344604
batch reward last col mean 1.0530449799261987e-05 first col mean 8.233283551817294e-06 all mean 9.579350444255397e-05
0.00017519503307994455 0.00017519503307994455
rl training, epoch1, iter0, batch71/1133, batch loss:0.00017519503307994455, Training time:14761.124129533768
batch reward last col mean 3.589718107832596e-05 first col mean 8.950150368036702e-05 all mean 7.848080713301897e-05
0.00010063007357530296 0.00010063007357530296
rl training, epoch1, iter0, batch72/1133, batch loss:0.00010063007357530296, Training time:14777.51219367981
batch reward last col mean 8.642621105536819e-05 first col mean 6.939392915228382e-05 all mean 9.578267781762406e-05
4.95498716190923e-05 4.95498716190923e-05
rl training, epoch1, iter0, batch73/1133, batch loss:4.95498716190923e-05, Training time:14794.279496908188
batch reward last col mean 0.0006540178437717259 first col mean 9.375570698466618e-06 all mean 0.00014257602742873132
0.0001376083673676476 0.00013760838191956282
rl training, epoch1, iter0, batch74/1133, batch loss:0.00013760838191956282, Training time:14812.817604064941
batch reward last col mean 6.488195140263997e-06 first col mean 0.0007444777875207365 all mean 0.00013144698459655046
6.714276969432831e-05 6.714277697028592e-05
rl training, epoch1, iter0, batch75/1133, batch loss:6.714277697028592e-05, Training time:14830.752940416336
batch reward last col mean 1.797897880351229e-06 first col mean 1.1653869478323031e-05 all mean 8.392267773160711e-05
0.0001611655025044456 0.0001611655025044456
rl training, epoch1, iter0, batch76/1133, batch loss:0.0001611655025044456, Training time:14848.910389184952
batch reward last col mean 7.987624485394917e-06 first col mean 4.460890977497911e-06 all mean 0.00011364366946509108
0.00028685317374765873 0.00028685314464382827
rl training, epoch1, iter0, batch77/1133, batch loss:0.00028685314464382827, Training time:14866.814358711243
batch reward last col mean 0.0003996654413640499 first col mean 0.001275747548788786 all mean 0.00023366993991658092
0.0003379017289262265 0.0003379017289262265
rl training, epoch1, iter0, batch78/1133, batch loss:0.0003379017289262265, Training time:14884.069073200226
batch reward last col mean 2.855979255400598e-05 first col mean 8.156489457178395e-06 all mean 5.2671988669317216e-05
0.0001617108064237982 0.0001617108064237982
rl training, epoch1, iter0, batch79/1133, batch loss:0.0001617108064237982, Training time:14900.614739656448
batch reward last col mean 3.0685455385537352e-06 first col mean 3.604745188567904e-06 all mean 6.485576886916533e-05
0.00010505903628654778 0.00010505902901059017
rl training, epoch1, iter0, batch80/1133, batch loss:0.00010505902901059017, Training time:14917.035584449768
batch reward last col mean 8.072082709986717e-05 first col mean 3.526404907461256e-05 all mean 0.00017058054800145328
0.00020539997785817832 0.00020539993420243263
rl training, epoch1, iter0, batch81/1133, batch loss:0.00020539993420243263, Training time:14933.497324705124
batch reward last col mean 9.686068551673088e-07 first col mean 5.6843055062927306e-06 all mean 0.0001723908935673535
0.0004183250421192497 0.0004183250421192497
rl training, epoch1, iter0, batch82/1133, batch loss:0.0004183250421192497, Training time:14949.88901925087
batch reward last col mean 0.00038138480158522725 first col mean 2.1797752197016962e-05 all mean 0.00011428105790400878
0.00013087043771520257 0.0001308704522671178
rl training, epoch1, iter0, batch83/1133, batch loss:0.0001308704522671178, Training time:14966.37719297409
batch reward last col mean 7.904774975031614e-06 first col mean 1.0031169040303212e-05 all mean 7.297233969438821e-05
0.00024691736325621605 0.0002469173341523856
rl training, epoch1, iter0, batch84/1133, batch loss:0.0002469173341523856, Training time:14984.475680112839
batch reward last col mean 1.370531663269503e-05 first col mean 6.1843620642321184e-06 all mean 2.6309420718462206e-05
1.8224447558168322e-05 1.8224447558168322e-05
rl training, epoch1, iter0, batch85/1133, batch loss:1.8224447558168322e-05, Training time:15002.524866819382
batch reward last col mean 3.6829601413046475e-06 first col mean 3.7810427784279454e-06 all mean 0.00014346126408781856
3.9654725696891546e-05 3.965471842093393e-05
rl training, epoch1, iter0, batch86/1133, batch loss:3.965471842093393e-05, Training time:15020.065089225769
batch reward last col mean 7.107515557436273e-05 first col mean 0.000821968074887991 all mean 0.00013279620907269418
0.00016592680185567588 0.00016592680185567588
rl training, epoch1, iter0, batch87/1133, batch loss:0.00016592680185567588, Training time:15039.292031288147
batch reward last col mean 3.4821532608475536e-05 first col mean 5.18573506269604e-06 all mean 6.165521335788071e-05
0.00013433466665446758 0.00013433466665446758
rl training, epoch1, iter0, batch88/1133, batch loss:0.00013433466665446758, Training time:15058.072832345963
batch reward last col mean 1.3005878827243578e-05 first col mean 5.529680038307561e-06 all mean 0.00012993735435884446
0.0004998296499252319 0.0004998296499252319
rl training, epoch1, iter0, batch89/1133, batch loss:0.0004998296499252319, Training time:15076.173552513123
batch reward last col mean 0.0003668558201752603 first col mean 4.640983206627425e-06 all mean 4.418320895638317e-05
8.761101344134659e-05 8.761099888943136e-05
rl training, epoch1, iter0, batch90/1133, batch loss:8.761099888943136e-05, Training time:15092.798800945282
batch reward last col mean 5.707531272491906e-06 first col mean 1.0843373274838086e-05 all mean 8.305063238367438e-05
0.00026415957836434245 0.00026415957836434245
rl training, epoch1, iter0, batch91/1133, batch loss:0.00026415957836434245, Training time:15109.316047668457
batch reward last col mean 8.88620525074657e-06 first col mean 6.726412721036468e-06 all mean 4.5280754420673475e-05
6.203288648976013e-05 6.203288648976013e-05
rl training, epoch1, iter0, batch92/1133, batch loss:6.203288648976013e-05, Training time:15125.836952924728
batch reward last col mean 0.006413656286895275 first col mean 2.2412671114580007e-06 all mean 0.00017770021804608405
0.0005940153496339917 0.0005940153496339917
rl training, epoch1, iter0, batch93/1133, batch loss:0.0005940153496339917, Training time:15142.581902503967
batch reward last col mean 5.21127185493242e-05 first col mean 2.697552554309368e-05 all mean 4.093886673217639e-05
6.206497346283868e-05 6.20649807387963e-05
rl training, epoch1, iter0, batch94/1133, batch loss:6.20649807387963e-05, Training time:15159.610431432724
batch reward last col mean 2.3378045170829864e-06 first col mean 0.0024137794971466064 all mean 0.00010528020357014611
0.00017125956946983933 0.00017125956946983933
rl training, epoch1, iter0, batch95/1133, batch loss:0.00017125956946983933, Training time:15175.89307141304
batch reward last col mean 5.645485089189606e-06 first col mean 0.0002779735950753093 all mean 0.00015371950576081872
0.00012993540440220386 0.00012993540440220386
rl training, epoch1, iter0, batch96/1133, batch loss:0.00012993540440220386, Training time:15192.466314792633
batch reward last col mean 9.176460480375681e-06 first col mean 4.574426384351682e-06 all mean 0.0001492492010584101
0.0004438244504854083 0.0004438244504854083
rl training, epoch1, iter0, batch97/1133, batch loss:0.0004438244504854083, Training time:15208.856111764908
batch reward last col mean 6.2652652559336275e-06 first col mean 0.00014779160846956074 all mean 7.441556954290718e-05
3.1670977477915585e-05 3.167098111589439e-05
rl training, epoch1, iter0, batch98/1133, batch loss:3.167098111589439e-05, Training time:15225.623337984085
batch reward last col mean 2.98931663564872e-05 first col mean 2.398544893367216e-06 all mean 0.00010055168240796775
0.00014812943118158728 0.0001481294457335025
rl training, epoch1, iter0, batch99/1133, batch loss:0.0001481294457335025, Training time:15242.322280406952
batch reward last col mean 1.1456753782113083e-05 first col mean 3.6362098398967646e-06 all mean 0.00014338137407321483
0.00033827126026153564 0.00033827126026153564
rl training, epoch1, iter0, batch100/1133, batch loss:0.00033827126026153564, Training time:15259.955760717392
batch reward last col mean 2.1000680590077536e-06 first col mean 4.207487563689938e-06 all mean 3.670412479550578e-05
4.0525581425754353e-05 4.052558506373316e-05
rl training, epoch1, iter0, batch101/1133, batch loss:4.052558506373316e-05, Training time:15277.00632405281
batch reward last col mean 1.9840595086861867e-06 first col mean 5.381562004913576e-06 all mean 6.0597398260142654e-05
9.864331514108926e-05 9.864330058917403e-05
rl training, epoch1, iter0, batch102/1133, batch loss:9.864330058917403e-05, Training time:15294.072117090225
batch reward last col mean 1.5322062608902343e-05 first col mean 4.187751983408816e-06 all mean 0.00012488733045756817
0.000127104896819219 0.00012710491137113422
rl training, epoch1, iter0, batch103/1133, batch loss:0.00012710491137113422, Training time:15311.275780439377
batch reward last col mean 2.9090235329931602e-05 first col mean 5.065875484433491e-06 all mean 9.291304741054773e-05
9.681153460405767e-05 9.681152005214244e-05
rl training, epoch1, iter0, batch104/1133, batch loss:9.681152005214244e-05, Training time:15327.970203399658
batch reward last col mean 9.751200195751153e-06 first col mean 1.740587322274223e-05 all mean 0.00015074909606482834
0.00024349459272343665 0.00024349454906769097
rl training, epoch1, iter0, batch105/1133, batch loss:0.00024349454906769097, Training time:15345.01137471199
batch reward last col mean 9.449238859815523e-06 first col mean 1.4203536920831539e-05 all mean 6.92591565893963e-05
0.00010684695007512346 0.00010684695007512346
rl training, epoch1, iter0, batch106/1133, batch loss:0.00010684695007512346, Training time:15363.401085138321
batch reward last col mean 0.006597368977963924 first col mean 0.00094090640777722 all mean 0.005742795765399933
0.0005524278385564685 0.0005524278385564685
rl training, epoch1, iter0, batch107/1133, batch loss:0.0005524278385564685, Training time:15381.458003282547
batch reward last col mean 5.808859714306891e-05 first col mean 2.0915113054797985e-05 all mean 0.00010663350258255377
0.00011296047159703448 0.0001129604788729921
rl training, epoch1, iter0, batch108/1133, batch loss:0.0001129604788729921, Training time:15399.085520267487
batch reward last col mean 4.3910526983381715e-06 first col mean 0.00014208444918040186 all mean 3.752806514967233e-05
3.392561120563187e-05 3.3925614843610674e-05
rl training, epoch1, iter0, batch109/1133, batch loss:3.3925614843610674e-05, Training time:15415.7874584198
batch reward last col mean 0.0021339072845876217 first col mean 4.901424745185068e-06 all mean 0.0007665423909202218
0.0003051092498935759 0.00030510922078974545
rl training, epoch1, iter0, batch110/1133, batch loss:0.00030510922078974545, Training time:15432.55691075325
batch reward last col mean 4.398571036290377e-06 first col mean 8.613779209554195e-05 all mean 4.229199839755893e-05
3.6263470974517986e-05 3.6263470974517986e-05
rl training, epoch1, iter0, batch111/1133, batch loss:3.6263470974517986e-05, Training time:15449.474138975143
batch reward last col mean 1.2371880075079389e-05 first col mean 0.0015670707216486335 all mean 4.6382960135815665e-05
6.149990804260597e-05 6.14999225945212e-05
rl training, epoch1, iter0, batch112/1133, batch loss:6.14999225945212e-05, Training time:15466.228080511093
batch reward last col mean 3.3102219276770484e-06 first col mean 3.226147327950457e-06 all mean 0.00010003798524849117
0.00018917176930699497 0.0001891717256512493
rl training, epoch1, iter0, batch113/1133, batch loss:0.0001891717256512493, Training time:15482.651092290878
batch reward last col mean 0.00016662973212078214 first col mean 1.5459299902431667e-06 all mean 6.398279219865799e-05
7.457822357537225e-05 7.457823085132986e-05
rl training, epoch1, iter0, batch114/1133, batch loss:7.457823085132986e-05, Training time:15499.074380397797
batch reward last col mean 0.0017504050629213452 first col mean 5.106809567223536e-06 all mean 0.0012925296323373914
0.0002974655944854021 0.0002974655944854021
rl training, epoch1, iter0, batch115/1133, batch loss:0.0002974655944854021, Training time:15515.426755428314
batch reward last col mean 0.0001598637318238616 first col mean 3.926979843527079e-06 all mean 0.00014262205513659865
0.00010732191731221974 0.00010732191003626212
rl training, epoch1, iter0, batch116/1133, batch loss:0.00010732191003626212, Training time:15532.281548976898
batch reward last col mean 4.318072114983806e-06 first col mean 7.394434305751929e-06 all mean 9.241609222954139e-05
5.1587681809905916e-05 5.158767817192711e-05
rl training, epoch1, iter0, batch117/1133, batch loss:5.158767817192711e-05, Training time:15548.679248809814
batch reward last col mean 1.5273975577656529e-06 first col mean 1.141515440394869e-05 all mean 0.00010638754611136392
9.806321759242564e-05 9.806321759242564e-05
rl training, epoch1, iter0, batch118/1133, batch loss:9.806321759242564e-05, Training time:15567.53309559822
batch reward last col mean 1.2800650438293815e-05 first col mean 3.5558302897698013e-06 all mean 6.907375063747168e-05
0.000132064800709486 0.000132064800709486
rl training, epoch1, iter0, batch119/1133, batch loss:0.000132064800709486, Training time:15585.954126358032
batch reward last col mean 8.85601002664771e-06 first col mean 3.705889321281575e-05 all mean 6.59260549582541e-05
7.800940511515364e-05 7.800940511515364e-05
rl training, epoch1, iter0, batch120/1133, batch loss:7.800940511515364e-05, Training time:15605.391177415848
batch reward last col mean 2.4279297576867975e-05 first col mean 3.101699621765874e-05 all mean 2.4458737243548967e-05
3.3812480978667736e-05 3.3812480978667736e-05
rl training, epoch1, iter0, batch121/1133, batch loss:3.3812480978667736e-05, Training time:15622.938339471817
batch reward last col mean 0.00012471432273741812 first col mean 6.629428389715031e-05 all mean 6.0638587456196547e-05
0.00011670609819702804 0.00011670608364511281
rl training, epoch1, iter0, batch122/1133, batch loss:0.00011670608364511281, Training time:15640.30690574646
batch reward last col mean 0.0002460378163959831 first col mean 6.61049352856935e-06 all mean 0.0003203818923793733
0.0003864587051793933 0.0003864587051793933
rl training, epoch1, iter0, batch123/1133, batch loss:0.0003864587051793933, Training time:15656.897912979126
batch reward last col mean 3.644467142294161e-05 first col mean 0.00010768459469545633 all mean 0.00010176936484640464
0.00011996832472505048 0.00011996834655292332
rl training, epoch1, iter0, batch124/1133, batch loss:0.00011996834655292332, Training time:15673.399127960205
batch reward last col mean 7.599347736686468e-05 first col mean 1.3540276086132508e-05 all mean 2.9615201128763147e-05
2.4513821699656546e-05 2.4513821699656546e-05
rl training, epoch1, iter0, batch125/1133, batch loss:2.4513821699656546e-05, Training time:15689.99034357071
batch reward last col mean 0.002909268019720912 first col mean 3.611313150031492e-05 all mean 0.00016441337356809527
0.00029122529667802155 0.00029122529667802155
rl training, epoch1, iter0, batch126/1133, batch loss:0.00029122529667802155, Training time:15706.44868183136
batch reward last col mean 2.698546086321585e-05 first col mean 7.886588718974963e-05 all mean 0.00013491231948137283
0.00010366613423684612 0.0001036661269608885
rl training, epoch1, iter0, batch127/1133, batch loss:0.0001036661269608885, Training time:15722.951220989227
batch reward last col mean 6.39615063846577e-06 first col mean 3.220992311980808e-06 all mean 9.49293898884207e-05
0.00019955544848926365 0.00019955543393734843
rl training, epoch1, iter0, batch128/1133, batch loss:0.00019955543393734843, Training time:15739.548649787903
batch reward last col mean 2.7313767532177735e-06 first col mean 3.2731770716054598e-06 all mean 0.00010687315807444975
0.00011173677194165066 0.00011173677194165066
rl training, epoch1, iter0, batch129/1133, batch loss:0.00011173677194165066, Training time:15755.999912023544
batch reward last col mean 0.00043806995381601155 first col mean 1.3841328836861067e-05 all mean 7.889545668149367e-05
0.00011326587264193222 0.00011326587264193222
rl training, epoch1, iter0, batch130/1133, batch loss:0.00011326587264193222, Training time:15772.552686929703
batch reward last col mean 3.177311009494588e-05 first col mean 3.539230965543538e-05 all mean 0.00010590813326416537
0.00020482084073591977 0.00020482084073591977
rl training, epoch1, iter0, batch131/1133, batch loss:0.00020482084073591977, Training time:15789.867458343506
batch reward last col mean 0.006635488010942936 first col mean 8.883894042810425e-05 all mean 0.006242891773581505
0.0007752074161544442 0.0007752072415314615
rl training, epoch1, iter0, batch132/1133, batch loss:0.0007752072415314615, Training time:15807.143475532532
batch reward last col mean 0.00034950775443576276 first col mean 0.00029808844556100667 all mean 7.59495233069174e-05
7.839316822355613e-05 7.839318277547136e-05
rl training, epoch1, iter0, batch133/1133, batch loss:7.839318277547136e-05, Training time:15825.235955238342
batch reward last col mean 2.9842325602658093e-05 first col mean 1.954747858690098e-05 all mean 0.00010117208148585632
7.035297312540933e-05 7.035296584945172e-05
rl training, epoch1, iter0, batch134/1133, batch loss:7.035296584945172e-05, Training time:15842.070886611938
batch reward last col mean 9.455302460992243e-07 first col mean 9.852718903857749e-06 all mean 7.408043893519789e-05
9.140398469753563e-05 9.140399197349325e-05
rl training, epoch1, iter0, batch135/1133, batch loss:9.140399197349325e-05, Training time:15859.007597923279
batch reward last col mean 1.3929411579738371e-05 first col mean 1.4090699551161379e-05 all mean 8.998015255201608e-05
0.0002321172651136294 0.0002321172651136294
rl training, epoch1, iter0, batch136/1133, batch loss:0.0002321172651136294, Training time:15875.803622245789
batch reward last col mean 0.00040545142837800086 first col mean 3.428084710321855e-06 all mean 0.00010365265916334465
0.0002514979860279709 0.00025149795692414045
rl training, epoch1, iter0, batch137/1133, batch loss:0.00025149795692414045, Training time:15892.614050865173
batch reward last col mean 4.747801358462311e-05 first col mean 1.2631401659746189e-05 all mean 5.028028681408614e-05
6.96850402164273e-05 6.96850402164273e-05
rl training, epoch1, iter0, batch138/1133, batch loss:6.96850402164273e-05, Training time:15909.346742868423
batch reward last col mean 4.3125364754814655e-05 first col mean 1.2533999324659817e-05 all mean 6.793066131649539e-05
7.125057163648307e-05 7.125057163648307e-05
rl training, epoch1, iter0, batch139/1133, batch loss:7.125057163648307e-05, Training time:15925.853940963745
batch reward last col mean 1.3662745004694443e-05 first col mean 0.0014048448065295815 all mean 8.308715041493997e-05
0.00018601652118377388 0.00018601652118377388
rl training, epoch1, iter0, batch140/1133, batch loss:0.00018601652118377388, Training time:15942.522681713104
batch reward last col mean 0.0009599009063094854 first col mean 2.60574120147794e-06 all mean 0.0003273569163866341
0.00037975781015120447 0.00037975781015120447
rl training, epoch1, iter0, batch141/1133, batch loss:0.00037975781015120447, Training time:15959.151456832886
batch reward last col mean 0.00019368284847587347 first col mean 3.559954711818136e-05 all mean 6.89766020514071e-05
0.00012937649444211274 0.00012937649444211274
rl training, epoch1, iter0, batch142/1133, batch loss:0.00012937649444211274, Training time:15975.990236520767
batch reward last col mean 4.555524355964735e-06 first col mean 3.3704034194670385e-06 all mean 6.321536056930199e-05
2.7916821636608802e-05 2.7916821636608802e-05
rl training, epoch1, iter0, batch143/1133, batch loss:2.7916821636608802e-05, Training time:15992.853898763657
batch reward last col mean 3.049845417990582e-06 first col mean 9.013704584504012e-06 all mean 0.00011619285214692354
0.00025288667529821396 0.00025288667529821396
rl training, epoch1, iter0, batch144/1133, batch loss:0.00025288667529821396, Training time:16009.779829263687
batch reward last col mean 3.059135633520782e-05 first col mean 4.436567451193696e-06 all mean 3.9619862945983186e-05
2.6676934794522822e-05 2.6676940251491033e-05
rl training, epoch1, iter0, batch145/1133, batch loss:2.6676940251491033e-05, Training time:16026.457959890366
batch reward last col mean 0.0003691681777127087 first col mean 1.1376183465472423e-05 all mean 0.00018164176435675472
0.00015153679123613983 0.00015153679123613983
rl training, epoch1, iter0, batch146/1133, batch loss:0.00015153679123613983, Training time:16043.169316291809
batch reward last col mean 6.344157736748457e-05 first col mean 6.0451904573710635e-05 all mean 0.00012689927825704217
0.0002360635990044102 0.0002360635990044102
rl training, epoch1, iter0, batch147/1133, batch loss:0.0002360635990044102, Training time:16060.003963470459
batch reward last col mean 5.653930566040799e-05 first col mean 0.0016585785197094083 all mean 7.418208406306803e-05
0.00011766576790250838 0.00011766576062655076
rl training, epoch1, iter0, batch148/1133, batch loss:0.00011766576062655076, Training time:16076.771687984467
batch reward last col mean 1.2129130482207984e-05 first col mean 3.4260592656210065e-05 all mean 4.865691880695522e-05
5.813649113406427e-05 5.813649477204308e-05
rl training, epoch1, iter0, batch149/1133, batch loss:5.813649477204308e-05, Training time:16093.329533100128
batch reward last col mean 1.0852246532522258e-06 first col mean 1.7230780940735713e-05 all mean 0.00011157116387039423
0.0001262303558178246 0.0001262303558178246
rl training, epoch1, iter0, batch150/1133, batch loss:0.0001262303558178246, Training time:16110.114476919174
batch reward last col mean 0.0002874399069696665 first col mean 1.0367548384238034e-05 all mean 0.00015990217798389494
0.0003495370037853718 0.00034953694557771087
rl training, epoch1, iter0, batch151/1133, batch loss:0.00034953694557771087, Training time:16126.904490470886
batch reward last col mean 6.495961861219257e-05 first col mean 9.361961019749288e-06 all mean 4.921734580420889e-05
8.070051990216598e-05 8.070051262620836e-05
rl training, epoch1, iter0, batch152/1133, batch loss:8.070051262620836e-05, Training time:16143.533257484436
batch reward last col mean 0.0020905237179249525 first col mean 0.0008184370817616582 all mean 0.00015444848395418376
0.0002975968236569315 0.0002975968236569315
rl training, epoch1, iter0, batch153/1133, batch loss:0.0002975968236569315, Training time:16160.104743003845
batch reward last col mean 1.765951674315147e-05 first col mean 7.001621270319447e-06 all mean 3.79099728888832e-05
5.3724896133644506e-05 5.3724896133644506e-05
rl training, epoch1, iter0, batch154/1133, batch loss:5.3724896133644506e-05, Training time:16176.85426735878
batch reward last col mean 3.965792348026298e-05 first col mean 4.1692660488479305e-06 all mean 7.909186388133094e-05
0.0002924259752035141 0.0002924259752035141
rl training, epoch1, iter0, batch155/1133, batch loss:0.0002924259752035141, Training time:16193.646776676178
batch reward last col mean 3.353782449266873e-05 first col mean 0.0007050287094898522 all mean 5.914137727813795e-05
6.293769547482952e-05 6.293769547482952e-05
rl training, epoch1, iter0, batch156/1133, batch loss:6.293769547482952e-05, Training time:16210.301642417908
batch reward last col mean 7.626730621268507e-06 first col mean 4.9226505325350445e-06 all mean 9.53982598730363e-05
0.00041892853914760053 0.0004189285100437701
rl training, epoch1, iter0, batch157/1133, batch loss:0.0004189285100437701, Training time:16226.984112024307
batch reward last col mean 0.0026681828312575817 first col mean 5.9712536312872544e-05 all mean 0.0003003811580128968
0.0007071816944517195 0.0007071818108670413
rl training, epoch1, iter0, batch158/1133, batch loss:0.0007071818108670413, Training time:16243.756982564926
batch reward last col mean 1.2482453712436836e-05 first col mean 2.2216697743715486e-06 all mean 7.078174530761316e-05
6.038902574800886e-05 6.038902938598767e-05
rl training, epoch1, iter0, batch159/1133, batch loss:6.038902938598767e-05, Training time:16260.482105016708
batch reward last col mean 0.0005811910377815366 first col mean 5.0828393796109594e-06 all mean 9.658385533839464e-05
8.373340824618936e-05 8.373341552214697e-05
rl training, epoch1, iter0, batch160/1133, batch loss:8.373341552214697e-05, Training time:16277.115317821503
batch reward last col mean 3.0736315238755196e-05 first col mean 0.000123230493045412 all mean 9.012483496917412e-05
6.237044726731256e-05 6.237045454327017e-05
rl training, epoch1, iter0, batch161/1133, batch loss:6.237045454327017e-05, Training time:16293.820920705795
batch reward last col mean 0.00039484401349909604 first col mean 1.956592132046353e-05 all mean 9.062912431545556e-05
9.997655433835462e-05 9.997655433835462e-05
rl training, epoch1, iter0, batch162/1133, batch loss:9.997655433835462e-05, Training time:16310.707869529724
batch reward last col mean 6.705559644615278e-05 first col mean 1.0730355825216975e-05 all mean 0.0001199423786601983
0.00010054948506876826 0.00010054948506876826
rl training, epoch1, iter0, batch163/1133, batch loss:0.00010054948506876826, Training time:16327.345018148422
batch reward last col mean 1.529056362414849e-06 first col mean 1.0378314982517622e-05 all mean 7.546235428890213e-05
2.9034950784989633e-05 2.903495442296844e-05
rl training, epoch1, iter0, batch164/1133, batch loss:2.903495442296844e-05, Training time:16343.983158826828
batch reward last col mean 0.00022416835417971015 first col mean 6.275894975260599e-06 all mean 0.00016558451170567423
0.00020947748271282762 0.00020947749726474285
rl training, epoch1, iter0, batch165/1133, batch loss:0.00020947749726474285, Training time:16360.553439378738
batch reward last col mean 8.337680628756061e-05 first col mean 6.751067303412128e-06 all mean 0.00018735055346041918
0.0002304275258211419 0.00023042749671731144
rl training, epoch1, iter0, batch166/1133, batch loss:0.00023042749671731144, Training time:16377.193027734756
batch reward last col mean 8.234167034970596e-05 first col mean 0.0007392328698188066 all mean 0.00022244513093028218
0.0002533083315938711 0.0002533083315938711
rl training, epoch1, iter0, batch167/1133, batch loss:0.0002533083315938711, Training time:16393.773304224014
batch reward last col mean 1.9099511519016232e-06 first col mean 4.688512490247376e-05 all mean 6.260150257730857e-05
7.759706932120025e-05 7.759706932120025e-05
rl training, epoch1, iter0, batch168/1133, batch loss:7.759706932120025e-05, Training time:16410.36806344986
batch reward last col mean 2.2546020773006603e-05 first col mean 7.3124556365655735e-06 all mean 9.571224654791877e-05
0.00015679321950301528 0.00015679321950301528
rl training, epoch1, iter0, batch169/1133, batch loss:0.00015679321950301528, Training time:16427.180742263794
batch reward last col mean 2.9432994779199362e-05 first col mean 2.523338480386883e-06 all mean 5.03113042213954e-05
8.26938048703596e-05 8.269379759440199e-05
rl training, epoch1, iter0, batch170/1133, batch loss:8.269379759440199e-05, Training time:16444.00222682953
batch reward last col mean 0.001789458910934627 first col mean 2.9385996640485246e-06 all mean 0.00047293855459429324
0.0002680067846085876 0.0002680067846085876
rl training, epoch1, iter0, batch171/1133, batch loss:0.0002680067846085876, Training time:16460.616737365723
batch reward last col mean 6.005704199196771e-05 first col mean 1.8780632672132924e-05 all mean 0.00014792673755437136
0.00015314071788452566 0.00015314071788452566
rl training, epoch1, iter0, batch172/1133, batch loss:0.00015314071788452566, Training time:16477.166449308395
batch reward last col mean 0.00015625625383108854 first col mean 0.00011752264981623739 all mean 0.00011834147881017998
0.00016575738845858723 0.00016575738845858723
rl training, epoch1, iter0, batch173/1133, batch loss:0.00016575738845858723, Training time:16493.925802469254
batch reward last col mean 1.8156442820327356e-06 first col mean 6.087357633077772e-06 all mean 0.00011130627535749227
7.632957567693666e-05 7.632956840097904e-05
rl training, epoch1, iter0, batch174/1133, batch loss:7.632956840097904e-05, Training time:16510.77721118927
batch reward last col mean 0.00013886086526326835 first col mean 2.9006097975070588e-05 all mean 0.00020191047224216163
6.278231739997864e-05 6.278232467593625e-05
rl training, epoch1, iter0, batch175/1133, batch loss:6.278232467593625e-05, Training time:16527.78637290001
batch reward last col mean 0.0001105816409108229 first col mean 7.313522473850753e-06 all mean 5.18461165484041e-05
5.702575435861945e-05 5.702576527255587e-05
rl training, epoch1, iter0, batch176/1133, batch loss:5.702576527255587e-05, Training time:16544.32222867012
batch reward last col mean 1.55213892867323e-05 first col mean 2.5663513952167705e-05 all mean 0.0001323309843428433
0.0006385088781826198 0.0006385088781826198
rl training, epoch1, iter0, batch177/1133, batch loss:0.0006385088781826198, Training time:16561.27423930168
batch reward last col mean 1.3243396097095683e-05 first col mean 1.2841621355619282e-05 all mean 9.076068818103522e-05
6.885428592795506e-05 6.885428592795506e-05
rl training, epoch1, iter0, batch178/1133, batch loss:6.885428592795506e-05, Training time:16578.10369157791
batch reward last col mean 7.391171675408259e-05 first col mean 0.0032808026298880577 all mean 0.00014147137699183077
0.00010450094850966707 0.00010450094123370945
rl training, epoch1, iter0, batch179/1133, batch loss:0.00010450094123370945, Training time:16595.167132616043
batch reward last col mean 2.920206134149339e-05 first col mean 3.154774822178297e-05 all mean 3.4166663681389764e-05
8.35601967992261e-05 8.35601967992261e-05
rl training, epoch1, iter0, batch180/1133, batch loss:8.35601967992261e-05, Training time:16611.863654613495
batch reward last col mean 0.0034048978704959154 first col mean 6.0158899941598065e-06 all mean 0.00015525978233199567
0.000262967252638191 0.000262967252638191
rl training, epoch1, iter0, batch181/1133, batch loss:0.000262967252638191, Training time:16628.543746709824
batch reward last col mean 3.7912836887699086e-06 first col mean 0.0013822263572365046 all mean 0.0001112557656597346
0.00014546254533343017 0.00014546251622959971
rl training, epoch1, iter0, batch182/1133, batch loss:0.00014546251622959971, Training time:16645.04738521576
batch reward last col mean 2.623058207973372e-06 first col mean 0.00046935409773141146 all mean 0.00010449536785017699
0.0002514395455364138 0.0002514396037440747
rl training, epoch1, iter0, batch183/1133, batch loss:0.0002514396037440747, Training time:16661.604444026947
batch reward last col mean 7.517860649386421e-05 first col mean 7.966238626977429e-06 all mean 5.62374152650591e-05
0.00013384570775087923 0.00013384572230279446
rl training, epoch1, iter0, batch184/1133, batch loss:0.00013384572230279446, Training time:16678.34447836876
batch reward last col mean 6.52173112030141e-05 first col mean 0.0008717838791199028 all mean 9.985030919779092e-05
8.298481407109648e-05 8.298481407109648e-05
rl training, epoch1, iter0, batch185/1133, batch loss:8.298481407109648e-05, Training time:16694.99673461914
batch reward last col mean 9.419417619938031e-05 first col mean 3.203360165571212e-06 all mean 8.719562174519524e-05
0.00011891064787050709 0.00011891063331859186
rl training, epoch1, iter0, batch186/1133, batch loss:0.00011891063331859186, Training time:16711.615248680115
batch reward last col mean 0.00010039744665846229 first col mean 6.825759101047879e-06 all mean 8.744579099584371e-05
7.91332931839861e-05 7.913330045994371e-05
rl training, epoch1, iter0, batch187/1133, batch loss:7.913330045994371e-05, Training time:16728.337485790253
batch reward last col mean 1.0341294910176657e-05 first col mean 2.131056498910766e-05 all mean 9.334032802144065e-05
0.00013734841195400804 0.00013734842650592327
rl training, epoch1, iter0, batch188/1133, batch loss:0.00013734842650592327, Training time:16745.247721672058
batch reward last col mean 4.609621100826189e-06 first col mean 3.102126356679946e-05 all mean 9.359625983051956e-05
8.851163875078782e-05 8.851163875078782e-05
rl training, epoch1, iter0, batch189/1133, batch loss:8.851163875078782e-05, Training time:16761.952682971954
batch reward last col mean 4.00798671762459e-05 first col mean 8.026153409446124e-06 all mean 7.74871077737771e-05
8.609049837104976e-05 8.609049837104976e-05
rl training, epoch1, iter0, batch190/1133, batch loss:8.609049837104976e-05, Training time:16778.620228528976
batch reward last col mean 6.31267175776884e-05 first col mean 2.6246041670674458e-05 all mean 0.0001283943565795198
0.00031099445186555386 0.00031099445186555386
rl training, epoch1, iter0, batch191/1133, batch loss:0.00031099445186555386, Training time:16795.266562461853
batch reward last col mean 0.00018768633890431374 first col mean 8.215235720854253e-05 all mean 0.00016701518325135112
0.00014570614439435303 0.00014570614439435303
rl training, epoch1, iter0, batch192/1133, batch loss:0.00014570614439435303, Training time:16812.155086517334
batch reward last col mean 2.0227282220730558e-05 first col mean 3.842982096102787e-06 all mean 9.308390144724399e-05
0.00010953126911772415 0.00010953126911772415
rl training, epoch1, iter0, batch193/1133, batch loss:0.00010953126911772415, Training time:16829.013824224472
batch reward last col mean 0.0031439883168786764 first col mean 3.8490590668516234e-05 all mean 0.00020586243772413582
0.00042189680971205235 0.00042189680971205235
rl training, epoch1, iter0, batch194/1133, batch loss:0.00042189680971205235, Training time:16845.856556653976
batch reward last col mean 0.0001937310298671946 first col mean 1.3779686014459003e-06 all mean 0.00019497759058140218
0.000267025432549417 0.000267025432549417
rl training, epoch1, iter0, batch195/1133, batch loss:0.000267025432549417, Training time:16862.56054162979
batch reward last col mean 2.3147513275034726e-05 first col mean 4.9450380174675956e-05 all mean 0.00014425745757762343
0.0001838180178310722 0.0001838180178310722
rl training, epoch1, iter0, batch196/1133, batch loss:0.0001838180178310722, Training time:16879.335908651352
batch reward last col mean 0.0019167977152392268 first col mean 1.749102011672221e-05 all mean 7.640552939847112e-05
0.00020282792684156448 0.00020282792684156448
rl training, epoch1, iter0, batch197/1133, batch loss:0.00020282792684156448, Training time:16896.215824127197
batch reward last col mean 1.7402895537088625e-05 first col mean 2.4992718863359187e-06 all mean 9.6468924311921e-05
9.101048635784537e-05 9.101047908188775e-05
rl training, epoch1, iter0, batch198/1133, batch loss:9.101047908188775e-05, Training time:16912.94438290596
batch reward last col mean 0.00010531352018006146 first col mean 9.039910764840897e-06 all mean 9.75024959188886e-05
0.0001960674417205155 0.0001960674417205155
rl training, epoch1, iter0, batch199/1133, batch loss:0.0001960674417205155, Training time:16929.714375257492
batch reward last col mean 3.6769499274669215e-05 first col mean 0.00010019259934779257 all mean 0.00014911810285411775
0.0003435210674069822 0.00034352100919932127
rl training, epoch1, iter0, batch200/1133, batch loss:0.00034352100919932127, Training time:16946.50108551979
batch reward last col mean 1.4934058526705485e-05 first col mean 7.73048941482557e-06 all mean 6.708868022542447e-05
0.00019733353110495955 0.00019733353110495955
rl training, epoch1, iter0, batch201/1133, batch loss:0.00019733353110495955, Training time:16962.99038529396
batch reward last col mean 1.1348402949806768e-05 first col mean 1.3299513739184476e-06 all mean 8.425443957094103e-05
8.470889588352293e-05 8.470889588352293e-05
rl training, epoch1, iter0, batch202/1133, batch loss:8.470889588352293e-05, Training time:16979.57224535942
batch reward last col mean 0.00017312496493104845 first col mean 5.326105110725621e-06 all mean 0.00010450865374878049
0.00022064823133405298 0.00022064823133405298
rl training, epoch1, iter0, batch203/1133, batch loss:0.00022064823133405298, Training time:16996.489054441452
batch reward last col mean 0.000488785735797137 first col mean 0.0010652447817847133 all mean 0.00019940637866966426
0.0002543866285122931 0.0002543866285122931
rl training, epoch1, iter0, batch204/1133, batch loss:0.0002543866285122931, Training time:17013.02103638649
batch reward last col mean 4.845558578381315e-05 first col mean 5.5228218116099015e-05 all mean 7.201974221970886e-05
8.779052586760372e-05 8.779052586760372e-05
rl training, epoch1, iter0, batch205/1133, batch loss:8.779052586760372e-05, Training time:17029.445969104767
batch reward last col mean 2.0318591850809753e-05 first col mean 6.223550826689461e-06 all mean 9.745368879521266e-05
8.30817298265174e-05 8.308172255055979e-05
rl training, epoch1, iter0, batch206/1133, batch loss:8.308172255055979e-05, Training time:17046.176016807556
batch reward last col mean 2.8823737011407502e-05 first col mean 9.107992809731513e-06 all mean 7.772076787659898e-05
5.246037835604511e-05 5.246038926998153e-05
rl training, epoch1, iter0, batch207/1133, batch loss:5.246038926998153e-05, Training time:17063.166570663452
batch reward last col mean 6.641127583861817e-06 first col mean 1.906848956423346e-05 all mean 0.0001316318375756964
0.00021936943812761456 0.00021936942357569933
rl training, epoch1, iter0, batch208/1133, batch loss:0.00021936942357569933, Training time:17079.7352104187
batch reward last col mean 1.5165845979936421e-05 first col mean 1.0698619007598609e-05 all mean 0.00014389895659405738
0.00022357443231157959 0.0002235743886558339
rl training, epoch1, iter0, batch209/1133, batch loss:0.0002235743886558339, Training time:17096.371804475784
batch reward last col mean 0.0036349173169583082 first col mean 4.0430386434309185e-06 all mean 0.0006551845581270754
0.0009989299578592181 0.0009989299578592181
rl training, epoch1, iter0, batch210/1133, batch loss:0.0009989299578592181, Training time:17113.165897130966
batch reward last col mean 6.989981920924038e-05 first col mean 1.5157122106757015e-05 all mean 0.00017691963876131922
0.00036200854810886085 0.00036200854810886085
rl training, epoch1, iter0, batch211/1133, batch loss:0.00036200854810886085, Training time:17130.37652873993
batch reward last col mean 1.6316562323481776e-06 first col mean 0.0009505990310572088 all mean 0.00012242203229106963
0.00030084935133345425 0.00030084940954111516
rl training, epoch1, iter0, batch212/1133, batch loss:0.00030084940954111516, Training time:17147.11357831955
batch reward last col mean 0.00011003374675055966 first col mean 2.150116597476881e-05 all mean 0.00013815294369123876
0.00018311738676857203 0.00018311738676857203
rl training, epoch1, iter0, batch213/1133, batch loss:0.00018311738676857203, Training time:17163.620859622955
batch reward last col mean 2.9113456548657268e-05 first col mean 0.0001063765084836632 all mean 0.00010501632641535252
5.965646050754003e-05 5.965646414551884e-05
rl training, epoch1, iter0, batch214/1133, batch loss:5.965646414551884e-05, Training time:17180.33490037918
batch reward last col mean 4.3349136831238866e-05 first col mean 6.070365088817198e-06 all mean 0.00010115578334080055
0.0001326489436905831 0.0001326489436905831
rl training, epoch1, iter0, batch215/1133, batch loss:0.0001326489436905831, Training time:17196.964777231216
batch reward last col mean 4.548279321170412e-06 first col mean 0.00011773856385843828 all mean 7.720007852185518e-05
0.0001198572208522819 0.00011985722812823951
rl training, epoch1, iter0, batch216/1133, batch loss:0.00011985722812823951, Training time:17213.62380385399
batch reward last col mean 1.0899460676228045e-06 first col mean 6.190360181790311e-06 all mean 8.685657667228952e-05
0.00013083555677440017 0.00013083554222248495
rl training, epoch1, iter0, batch217/1133, batch loss:0.00013083554222248495, Training time:17230.085415124893
batch reward last col mean 9.115199645748362e-06 first col mean 0.0007196363876573741 all mean 7.124635885702446e-05
9.715724445413798e-05 9.715723717818037e-05
rl training, epoch1, iter0, batch218/1133, batch loss:9.715723717818037e-05, Training time:17246.801314353943
batch reward last col mean 8.541606803191826e-05 first col mean 2.600520474516088e-06 all mean 6.403643055818975e-05
9.277474600821733e-05 9.277474600821733e-05
rl training, epoch1, iter0, batch219/1133, batch loss:9.277474600821733e-05, Training time:17263.33137345314
batch reward last col mean 0.00013783293252345175 first col mean 0.00010982478124788031 all mean 0.00044434855226427317
0.0007649569888599217 0.0007649569888599217
rl training, epoch1, iter0, batch220/1133, batch loss:0.0007649569888599217, Training time:17279.83025455475
batch reward last col mean 5.5408410844393075e-05 first col mean 7.460630058631068e-06 all mean 0.00010121549712494016
0.00010807429498527199 0.00010807428043335676
rl training, epoch1, iter0, batch221/1133, batch loss:0.00010807428043335676, Training time:17296.845018148422
batch reward last col mean 7.371746960416203e-06 first col mean 1.3051885616732761e-05 all mean 7.182422268670052e-05
7.42934862500988e-05 7.429349352605641e-05
rl training, epoch1, iter0, batch222/1133, batch loss:7.429349352605641e-05, Training time:17313.765490055084
batch reward last col mean 5.02264538226882e-06 first col mean 0.00011402236123103648 all mean 0.00018766555876936764
0.00032058116630651057 0.00032058116630651057
rl training, epoch1, iter0, batch223/1133, batch loss:0.00032058116630651057, Training time:17330.539803028107
batch reward last col mean 8.905981303541921e-06 first col mean 0.0015127224614843726 all mean 8.843950490700081e-05
0.00017421806114725769 0.00017421806114725769
rl training, epoch1, iter0, batch224/1133, batch loss:0.00017421806114725769, Training time:17347.151661157608
batch reward last col mean 0.00011122659634565935 first col mean 0.00011275250290054828 all mean 7.337301940424368e-05
5.3144842240726575e-05 5.3144842240726575e-05
rl training, epoch1, iter0, batch225/1133, batch loss:5.3144842240726575e-05, Training time:17363.655116558075
batch reward last col mean 2.4893090085242875e-05 first col mean 6.570213008671999e-05 all mean 0.00012240449723321944
0.000142834716825746 0.000142834716825746
rl training, epoch1, iter0, batch226/1133, batch loss:0.000142834716825746, Training time:17380.853922367096
batch reward last col mean 0.00027279939968138933 first col mean 8.518229151377454e-06 all mean 6.92961475579068e-05
5.335731111699715e-05 5.335731475497596e-05
rl training, epoch1, iter0, batch227/1133, batch loss:5.335731475497596e-05, Training time:17397.978196382523
batch reward last col mean 5.8124801398662385e-06 first col mean 0.002134073292836547 all mean 0.00013993424363434315
0.00026390893617644906 0.0002639089652802795
rl training, epoch1, iter0, batch228/1133, batch loss:0.0002639089652802795, Training time:17414.63724255562
batch reward last col mean 2.166136255254969e-05 first col mean 0.0009349686442874372 all mean 9.493401739746332e-05
0.00010666813614079729 0.00010666812886483967
rl training, epoch1, iter0, batch229/1133, batch loss:0.00010666812886483967, Training time:17431.43773293495
batch reward last col mean 3.873883542837575e-05 first col mean 1.9720990167115815e-05 all mean 0.0001491127914050594
0.00017027177091222256 0.00017027175636030734
rl training, epoch1, iter0, batch230/1133, batch loss:0.00017027175636030734, Training time:17448.726747751236
batch reward last col mean 6.977443263167515e-06 first col mean 1.00064371508779e-05 all mean 7.57824964239262e-05
0.00018104372429661453 0.00018104372429661453
rl training, epoch1, iter0, batch231/1133, batch loss:0.00018104372429661453, Training time:17465.52964925766
batch reward last col mean 0.002734103938564658 first col mean 2.806285920087248e-05 all mean 0.00028141718939878047
0.0002894324134103954 0.0002894324134103954
rl training, epoch1, iter0, batch232/1133, batch loss:0.0002894324134103954, Training time:17482.215923309326
batch reward last col mean 2.767862497421447e-06 first col mean 2.836217390722595e-06 all mean 6.556958396686241e-05
9.352926281280816e-05 9.352926281280816e-05
rl training, epoch1, iter0, batch233/1133, batch loss:9.352926281280816e-05, Training time:17499.085099697113
batch reward last col mean 4.463120785658248e-05 first col mean 1.2686905392911285e-05 all mean 9.284198313253e-05
0.00012049020733684301 0.00012049020733684301
rl training, epoch1, iter0, batch234/1133, batch loss:0.00012049020733684301, Training time:17516.25408935547
batch reward last col mean 2.7745885745389387e-05 first col mean 5.4108597396407276e-05 all mean 9.385923476656899e-05
0.00012789866013918072 0.00012789867469109595
rl training, epoch1, iter0, batch235/1133, batch loss:0.00012789867469109595, Training time:17533.01520705223
batch reward last col mean 1.0439843208587263e-05 first col mean 8.035412975004874e-06 all mean 0.0001296673872275278
0.00041475635953247547 0.00041475635953247547
rl training, epoch1, iter0, batch236/1133, batch loss:0.00041475635953247547, Training time:17549.603912830353
batch reward last col mean 4.056770194438286e-05 first col mean 2.3512324332841672e-05 all mean 0.00017695667338557541
0.0002380447112955153 0.00023804472584743053
rl training, epoch1, iter0, batch237/1133, batch loss:0.00023804472584743053, Training time:17566.5691614151
batch reward last col mean 2.7903956834052224e-06 first col mean 3.787281002587406e-06 all mean 0.0001203460487886332
0.00012073483230778947 0.00012073483230778947
rl training, epoch1, iter0, batch238/1133, batch loss:0.00012073483230778947, Training time:17583.276789665222
batch reward last col mean 3.649311838671565e-05 first col mean 2.1856392777408473e-05 all mean 0.00016656423395033926
0.00032187532633543015 0.00032187532633543015
rl training, epoch1, iter0, batch239/1133, batch loss:0.00032187532633543015, Training time:17599.90442252159
batch reward last col mean 0.0008500577532686293 first col mean 5.214778866502456e-06 all mean 0.00010786755592562258
0.0002292046556249261 0.0002292046556249261
rl training, epoch1, iter0, batch240/1133, batch loss:0.0002292046556249261, Training time:17616.700728416443
batch reward last col mean 3.338840906508267e-05 first col mean 1.878191324067302e-05 all mean 0.00012225065438542515
0.00021295694750733674 0.00021295696205925196
rl training, epoch1, iter0, batch241/1133, batch loss:0.00021295696205925196, Training time:17633.519201755524
batch reward last col mean 4.9811678763944656e-06 first col mean 0.0014841193333268166 all mean 8.600430010119453e-05
3.526495856931433e-05 3.5264976759208366e-05
rl training, epoch1, iter0, batch242/1133, batch loss:3.5264976759208366e-05, Training time:17650.10180258751
batch reward last col mean 0.004784694407135248 first col mean 2.605082408990711e-05 all mean 0.0002703147765714675
0.0004858152533415705 0.0004858152533415705
rl training, epoch1, iter0, batch243/1133, batch loss:0.0004858152533415705, Training time:17666.555082798004
batch reward last col mean 1.1056542462029029e-05 first col mean 0.00023243438045028597 all mean 7.183987327152863e-05
6.390419730450958e-05 6.390419730450958e-05
rl training, epoch1, iter0, batch244/1133, batch loss:6.390419730450958e-05, Training time:17683.19462800026
batch reward last col mean 0.0001241318677784875 first col mean 1.3747498996963259e-05 all mean 0.00011418895155657083
0.0001169659590232186 0.00011696595174726099
rl training, epoch1, iter0, batch245/1133, batch loss:0.00011696595174726099, Training time:17699.85491156578
batch reward last col mean 8.796927431831136e-06 first col mean 6.525307526317192e-06 all mean 8.010446617845446e-05
6.351980118779466e-05 6.351980846375227e-05
rl training, epoch1, iter0, batch246/1133, batch loss:6.351980846375227e-05, Training time:17716.595497608185
batch reward last col mean 1.3776118066743948e-05 first col mean 1.8321514971830766e-06 all mean 0.00011929260654142126
0.00010728731285780668 0.00010728732740972191
rl training, epoch1, iter0, batch247/1133, batch loss:0.00010728732740972191, Training time:17733.21846318245
batch reward last col mean 9.27635937841842e-06 first col mean 1.6432086340500973e-05 all mean 0.00015430002531502396
0.0003831058565992862 0.0003831058565992862
rl training, epoch1, iter0, batch248/1133, batch loss:0.0003831058565992862, Training time:17750.075522184372
batch reward last col mean 5.4404144975706e-06 first col mean 2.18415038943931e-06 all mean 0.0002358004858251661
0.0003254452021792531 0.0003254452021792531
rl training, epoch1, iter0, batch249/1133, batch loss:0.0003254452021792531, Training time:17766.9809756279
batch reward last col mean 2.57026022154605e-06 first col mean 4.556382464215858e-06 all mean 5.881742254132405e-05
6.74272669130005e-05 6.74272669130005e-05
rl training, epoch1, iter0, batch250/1133, batch loss:6.74272669130005e-05, Training time:17783.738604068756
batch reward last col mean 8.132375114655588e-06 first col mean 2.851213139365427e-06 all mean 0.0001498813508078456
0.00010320640285499394 0.00010320640285499394
rl training, epoch1, iter0, batch251/1133, batch loss:0.00010320640285499394, Training time:17800.33883333206
batch reward last col mean 0.0004052815493196249 first col mean 0.00029020223882980645 all mean 0.00011606693442445248
0.0002477859961800277 0.0002477859961800277
rl training, epoch1, iter0, batch252/1133, batch loss:0.0002477859961800277, Training time:17816.84671521187
batch reward last col mean 8.813004387775436e-05 first col mean 1.473110660299426e-05 all mean 0.00016742147272452712
0.00023642113956157118 0.00023642118321731687
rl training, epoch1, iter0, batch253/1133, batch loss:0.00023642118321731687, Training time:17834.007187366486
batch reward last col mean 0.0001247273903572932 first col mean 6.505721103167161e-05 all mean 0.00010606473369989544
0.00014684678171761334 0.00014684678171761334
rl training, epoch1, iter0, batch254/1133, batch loss:0.00014684678171761334, Training time:17850.95253443718
batch reward last col mean 1.3334349205251783e-05 first col mean 8.624983820482157e-06 all mean 0.0001419109757989645
0.00018754569464363158 0.00018754569464363158
rl training, epoch1, iter0, batch255/1133, batch loss:0.00018754569464363158, Training time:17867.53406381607
batch reward last col mean 7.905394159024581e-05 first col mean 6.601135100936517e-05 all mean 0.00030088695348240435
0.0003932956897187978 0.00039329571882262826
rl training, epoch1, iter0, batch256/1133, batch loss:0.00039329571882262826, Training time:17884.223279476166
batch reward last col mean 0.0007170414319261909 first col mean 1.803360828489531e-05 all mean 0.00011277366138529032
0.00018541996541898698 0.00018541996541898698
rl training, epoch1, iter0, batch257/1133, batch loss:0.00018541996541898698, Training time:17901.073636054993
batch reward last col mean 8.98089274414815e-06 first col mean 4.626795998774469e-06 all mean 0.00014813701272942126
0.00025254872161895037 0.00025254872161895037
rl training, epoch1, iter0, batch258/1133, batch loss:0.00025254872161895037, Training time:17917.90173316002
batch reward last col mean 0.0007455471786670387 first col mean 9.007479820866138e-05 all mean 0.00015176470333244652
0.0002960280398838222 0.0002960280398838222
rl training, epoch1, iter0, batch259/1133, batch loss:0.0002960280398838222, Training time:17934.989719867706
batch reward last col mean 2.415143717371393e-05 first col mean 0.000766363344155252 all mean 0.00010623468551784754
0.00022187185822986066 0.00022187185822986066
rl training, epoch1, iter0, batch260/1133, batch loss:0.00022187185822986066, Training time:17951.827065229416
batch reward last col mean 1.9538336346158758e-05 first col mean 1.0816189387696795e-05 all mean 0.00020539702381938696
0.0002778747584670782 0.0002778747584670782
rl training, epoch1, iter0, batch261/1133, batch loss:0.0002778747584670782, Training time:17968.887620687485
batch reward last col mean 4.88358909933595e-06 first col mean 6.510141247417778e-05 all mean 7.758860010653734e-05
6.79244112689048e-05 6.792442582082003e-05
rl training, epoch1, iter0, batch262/1133, batch loss:6.792442582082003e-05, Training time:17985.685441970825
batch reward last col mean 1.7829273929237388e-05 first col mean 2.7351929929864127e-06 all mean 0.00014358018233906478
0.00022523345251102 0.00022523345251102
rl training, epoch1, iter0, batch263/1133, batch loss:0.00022523345251102, Training time:18002.443258285522
batch reward last col mean 0.00018086617637891322 first col mean 6.84342667227611e-05 all mean 0.00022544132662005723
0.0003954211133532226 0.0003954211133532226
rl training, epoch1, iter0, batch264/1133, batch loss:0.0003954211133532226, Training time:18019.020189762115
batch reward last col mean 0.0001818698801798746 first col mean 0.0005466325674206018 all mean 9.313433838542551e-05
6.566756928805262e-05 6.566756928805262e-05
rl training, epoch1, iter0, batch265/1133, batch loss:6.566756928805262e-05, Training time:18035.789308547974
batch reward last col mean 2.1253388240438653e-06 first col mean 1.8821872799890116e-05 all mean 8.598899148637429e-05
2.594590296212118e-05 2.5945906600099988e-05
rl training, epoch1, iter0, batch266/1133, batch loss:2.5945906600099988e-05, Training time:18052.527786016464
batch reward last col mean 1.4050054232939146e-05 first col mean 6.904240763105918e-06 all mean 0.000168821046827361
0.00020747036614920944 0.00020747036614920944
rl training, epoch1, iter0, batch267/1133, batch loss:0.00020747036614920944, Training time:18069.182037830353
batch reward last col mean 6.877948180772364e-05 first col mean 3.540545731084421e-05 all mean 0.0003483542241156101
0.00029218135750852525 0.00029218135750852525
rl training, epoch1, iter0, batch268/1133, batch loss:0.00029218135750852525, Training time:18085.662647247314
batch reward last col mean 9.997164852393325e-06 first col mean 1.3230360309535172e-05 all mean 7.034908776404336e-05
0.00016866876103449613 0.00016866876103449613
rl training, epoch1, iter0, batch269/1133, batch loss:0.00016866876103449613, Training time:18102.604629278183
batch reward last col mean 5.5661203077761456e-05 first col mean 8.848362631397322e-05 all mean 0.00014176873082760721
0.00018053971871268004 0.0001805397041607648
rl training, epoch1, iter0, batch270/1133, batch loss:0.0001805397041607648, Training time:18119.34236550331
batch reward last col mean 1.255344341188902e-05 first col mean 8.636160600872245e-06 all mean 0.00020757742458954453
0.000225054012844339 0.00022505404194816947
rl training, epoch1, iter0, batch271/1133, batch loss:0.00022505404194816947, Training time:18136.085013628006
batch reward last col mean 8.116507524391636e-05 first col mean 5.463923571369378e-06 all mean 0.00023782459902577102
0.0003941449394915253 0.00039414496859535575
rl training, epoch1, iter0, batch272/1133, batch loss:0.00039414496859535575, Training time:18152.833434581757
batch reward last col mean 0.0007137582870200276 first col mean 7.348669169005007e-05 all mean 0.000154766152263619
0.00032384408405050635 0.00032384408405050635
rl training, epoch1, iter0, batch273/1133, batch loss:0.00032384408405050635, Training time:18169.537545681
batch reward last col mean 1.6175659766304307e-05 first col mean 2.874588972190395e-05 all mean 0.00010001995542552322
0.00014157565601635724 0.00014157565601635724
rl training, epoch1, iter0, batch274/1133, batch loss:0.00014157565601635724, Training time:18186.233972787857
batch reward last col mean 4.888140210823622e-06 first col mean 8.642687134852167e-06 all mean 0.00014644084149040282
7.362452743109316e-05 7.362452743109316e-05
rl training, epoch1, iter0, batch275/1133, batch loss:7.362452743109316e-05, Training time:18202.757390975952
batch reward last col mean 0.00011480515968287364 first col mean 2.403021198915667e-06 all mean 0.00020396066247485578
0.0004323390603531152 0.0004323390603531152
rl training, epoch1, iter0, batch276/1133, batch loss:0.0004323390603531152, Training time:18219.37918996811
batch reward last col mean 7.850094334571622e-06 first col mean 3.953323812311282e-06 all mean 8.558454283047467e-05
0.00012022522423649207 0.00012022520968457684
rl training, epoch1, iter0, batch277/1133, batch loss:0.00012022520968457684, Training time:18236.207560777664
batch reward last col mean 6.9732491283502895e-06 first col mean 8.363551387446932e-06 all mean 0.00040970780537463725
0.0005036311922594905 0.0005036311922594905
rl training, epoch1, iter0, batch278/1133, batch loss:0.0005036311922594905, Training time:18253.000172138214
batch reward last col mean 3.655232831079047e-06 first col mean 8.025558599911164e-06 all mean 8.766957034822553e-05
4.213358988636173e-05 4.213359352434054e-05
rl training, epoch1, iter0, batch279/1133, batch loss:4.213359352434054e-05, Training time:18269.556659460068
batch reward last col mean 3.525133433868177e-05 first col mean 6.0486803704407066e-05 all mean 0.00015912165690679103
0.00020906855934299529 0.00020906855934299529
rl training, epoch1, iter0, batch280/1133, batch loss:0.00020906855934299529, Training time:18286.027980804443
batch reward last col mean 1.1852620446006767e-05 first col mean 1.939975845743902e-05 all mean 0.00010349961667088792
0.00019701487326528877 0.00019701487326528877
rl training, epoch1, iter0, batch281/1133, batch loss:0.00019701487326528877, Training time:18302.52327489853
batch reward last col mean 4.407791948324302e-06 first col mean 7.025327067822218e-05 all mean 0.00012048090138705447
0.0002361689694225788 0.0002361689694225788
rl training, epoch1, iter0, batch282/1133, batch loss:0.0002361689694225788, Training time:18319.062896966934
batch reward last col mean 4.977275602868758e-05 first col mean 2.946240419987589e-05 all mean 0.00016405395581386983
0.00029795526643283665 0.00029795526643283665
rl training, epoch1, iter0, batch283/1133, batch loss:0.00029795526643283665, Training time:18335.46192383766
batch reward last col mean 5.32977765033138e-06 first col mean 1.6848997574925306e-06 all mean 6.305094575509429e-05
9.787144517758861e-05 9.7871437901631e-05
rl training, epoch1, iter0, batch284/1133, batch loss:9.7871437901631e-05, Training time:18351.932704925537
batch reward last col mean 9.668056918599177e-06 first col mean 7.326943159569055e-05 all mean 0.00020772777497768402
0.00032376483432017267 0.0003237647470086813
rl training, epoch1, iter0, batch285/1133, batch loss:0.0003237647470086813, Training time:18368.621391773224
batch reward last col mean 0.004713252652436495 first col mean 1.586794860486407e-05 all mean 0.0003589088737498969
0.0006013094098307192 0.0006013094098307192
rl training, epoch1, iter0, batch286/1133, batch loss:0.0006013094098307192, Training time:18385.583288908005
batch reward last col mean 4.426310624694452e-06 first col mean 6.851182661193889e-06 all mean 8.958357648225501e-05
0.00017854248289950192 0.00017854248289950192
rl training, epoch1, iter0, batch287/1133, batch loss:0.00017854248289950192, Training time:18402.30501818657
batch reward last col mean 1.1573994925129227e-05 first col mean 4.9888421926880255e-05 all mean 0.00010950721480185166
0.00013390934327617288 0.00013390934327617288
rl training, epoch1, iter0, batch288/1133, batch loss:0.00013390934327617288, Training time:18419.003603219986
batch reward last col mean 0.0010137517238035798 first col mean 5.7662787185108755e-06 all mean 0.00012948950461577624
0.00020757116726599634 0.00020757113816216588
rl training, epoch1, iter0, batch289/1133, batch loss:0.00020757113816216588, Training time:18435.87399148941
batch reward last col mean 2.678714008652605e-05 first col mean 6.621949978580233e-06 all mean 0.00013201874389778823
0.0001913488085847348 0.0001913488085847348
rl training, epoch1, iter0, batch290/1133, batch loss:0.0001913488085847348, Training time:18452.626752376556
batch reward last col mean 0.0010591361206024885 first col mean 4.8224224883597344e-05 all mean 0.0001819887402234599
0.00023529422469437122 0.00023529422469437122
rl training, epoch1, iter0, batch291/1133, batch loss:0.00023529422469437122, Training time:18469.181302547455
batch reward last col mean 3.06979964079801e-05 first col mean 0.00016250011685770005 all mean 0.00036991274100728333
0.0003309792373329401 0.0003309791791252792
rl training, epoch1, iter0, batch292/1133, batch loss:0.0003309791791252792, Training time:18485.9303920269
batch reward last col mean 1.1845591870951466e-05 first col mean 2.013830453506671e-05 all mean 0.00012027902994304895
0.0002003545087063685 0.00020035447960253805
rl training, epoch1, iter0, batch293/1133, batch loss:0.00020035447960253805, Training time:18502.660756111145
batch reward last col mean 9.099995077122003e-05 first col mean 0.0001346328790532425 all mean 0.00015955945127643645
0.00025905593065544963 0.00025905593065544963
rl training, epoch1, iter0, batch294/1133, batch loss:0.00025905593065544963, Training time:18519.593504190445
batch reward last col mean 1.078170862456318e-05 first col mean 4.9419440983911045e-06 all mean 0.0002599558501970023
0.00030298990895971656 0.00030298990895971656
rl training, epoch1, iter0, batch295/1133, batch loss:0.00030298990895971656, Training time:18536.339309215546
batch reward last col mean 5.958099791314453e-06 first col mean 2.3366812456515618e-05 all mean 0.00014330445264931768
0.00011238660954404622 0.00011238661682000384
rl training, epoch1, iter0, batch296/1133, batch loss:0.00011238661682000384, Training time:18553.124280691147
batch reward last col mean 0.0011083877179771662 first col mean 5.064564538770355e-05 all mean 0.00015790812904015183
0.00016124117246363312 0.0001612411579117179
rl training, epoch1, iter0, batch297/1133, batch loss:0.0001612411579117179, Training time:18570.285556554794
batch reward last col mean 1.429891290172236e-05 first col mean 4.832744707528036e-06 all mean 0.00015641583013348281
0.0002694662834983319 0.00026946631260216236
rl training, epoch1, iter0, batch298/1133, batch loss:0.00026946631260216236, Training time:18587.267577648163
batch reward last col mean 3.483330146991648e-05 first col mean 0.00015175870794337243 all mean 0.00016385952767450362
0.0003290415625087917 0.0003290415625087917
rl training, epoch1, iter0, batch299/1133, batch loss:0.0003290415625087917, Training time:18604.14843440056
batch reward last col mean 3.6607050333259394e-06 first col mean 0.0014127535978332162 all mean 0.00010138245852431282
0.00012615324521902949 0.00012615324521902949
rl training, epoch1, iter0, batch300/1133, batch loss:0.00012615324521902949, Training time:18620.827985048294
batch reward last col mean 7.14712223270908e-06 first col mean 1.6022162526496686e-05 all mean 9.890725777950138e-05
4.37861199316103e-05 4.37861199316103e-05
rl training, epoch1, iter0, batch301/1133, batch loss:4.37861199316103e-05, Training time:18637.528450012207
batch reward last col mean 2.6608740881783888e-06 first col mean 1.0008419849327765e-05 all mean 0.00012145267828600481
0.00013326058979146183 0.00013326058979146183
rl training, epoch1, iter0, batch302/1133, batch loss:0.00013326058979146183, Training time:18654.403140068054
batch reward last col mean 0.0018450012430548668 first col mean 5.509583388629835e-06 all mean 0.0003244600957259536
0.0008131461217999458 0.0008131461217999458
rl training, epoch1, iter0, batch303/1133, batch loss:0.0008131461217999458, Training time:18671.203523397446
batch reward last col mean 0.00011079018440796062 first col mean 6.704329280182719e-05 all mean 0.00018546957289800048
0.00032115535577759147 0.0003211553848814219
rl training, epoch1, iter0, batch304/1133, batch loss:0.0003211553848814219, Training time:18688.32370710373
batch reward last col mean 2.943073741334956e-05 first col mean 4.940155577060068e-06 all mean 0.00010581040987744927
0.00011329154949635267 0.00011329157132422552
rl training, epoch1, iter0, batch305/1133, batch loss:0.00011329157132422552, Training time:18705.140607357025
batch reward last col mean 1.1701616131176706e-05 first col mean 7.869262844906189e-06 all mean 0.00011786824325099587
0.00012839706323575228 0.00012839706323575228
rl training, epoch1, iter0, batch306/1133, batch loss:0.00012839706323575228, Training time:18721.825114011765
batch reward last col mean 0.0012553991982713342 first col mean 3.023918452527141e-06 all mean 0.0001133273690356873
0.00015756460197735578 0.00015756460197735578
rl training, epoch1, iter0, batch307/1133, batch loss:0.00015756460197735578, Training time:18738.7778069973
batch reward last col mean 5.787466579931788e-05 first col mean 2.010405842156615e-05 all mean 6.295843922998756e-05
5.337949187378399e-05 5.3379488235805184e-05
rl training, epoch1, iter0, batch308/1133, batch loss:5.3379488235805184e-05, Training time:18755.284836530685
batch reward last col mean 4.1615439840825275e-06 first col mean 0.0004052487201988697 all mean 0.00012328427692409605
7.482360524591058e-05 7.48236125218682e-05
rl training, epoch1, iter0, batch309/1133, batch loss:7.48236125218682e-05, Training time:18771.92012500763
batch reward last col mean 1.3306900655152276e-05 first col mean 2.7398835300118662e-05 all mean 0.00016201809921767563
0.00019356649136170745 0.00019356649136170745
rl training, epoch1, iter0, batch310/1133, batch loss:0.00019356649136170745, Training time:18788.523750543594
batch reward last col mean 0.00020315323490649462 first col mean 6.781152478652075e-05 all mean 0.00012979982420802116
0.0001436056918464601 0.0001436056918464601
rl training, epoch1, iter0, batch311/1133, batch loss:0.0001436056918464601, Training time:18805.107696294785
batch reward last col mean 1.1858303878398146e-05 first col mean 4.251713107805699e-06 all mean 0.00023103818239178509
0.00048825799603946507 0.0004882579669356346
rl training, epoch1, iter0, batch312/1133, batch loss:0.0004882579669356346, Training time:18821.545709609985
batch reward last col mean 2.512234823370818e-05 first col mean 1.288212661165744e-05 all mean 8.253219857579097e-05
5.9847192460438237e-05 5.984721065033227e-05
rl training, epoch1, iter0, batch313/1133, batch loss:5.984721065033227e-05, Training time:18838.303121566772
batch reward last col mean 4.9410140491090715e-05 first col mean 5.116289230500115e-06 all mean 0.00016225084254983813
7.877730240579695e-05 7.877729512983933e-05
rl training, epoch1, iter0, batch314/1133, batch loss:7.877729512983933e-05, Training time:18855.12989640236
batch reward last col mean 0.00023345358204096556 first col mean 1.989551128644962e-05 all mean 0.00010534471948631108
8.571231592213735e-05 8.571232319809496e-05
rl training, epoch1, iter0, batch315/1133, batch loss:8.571232319809496e-05, Training time:18871.801094532013
batch reward last col mean 1.27722232718952e-05 first col mean 1.4478015145868994e-05 all mean 0.0001532155292807147
0.00013770395889878273 0.00013770395889878273
rl training, epoch1, iter0, batch316/1133, batch loss:0.00013770395889878273, Training time:18888.47493505478
batch reward last col mean 1.5771531252539717e-05 first col mean 0.0003593157744035125 all mean 7.530801667599007e-05
9.119456080952659e-05 9.119456080952659e-05
rl training, epoch1, iter0, batch317/1133, batch loss:9.119456080952659e-05, Training time:18905.401656866074
batch reward last col mean 0.00026495082420296967 first col mean 8.123934094328433e-06 all mean 5.798618440167047e-05
7.945533434394747e-05 7.945532706798986e-05
rl training, epoch1, iter0, batch318/1133, batch loss:7.945532706798986e-05, Training time:18922.108051538467
batch reward last col mean 4.5113571104593575e-05 first col mean 3.949758320231922e-05 all mean 7.490141433663666e-05
9.970437531592324e-05 9.970437531592324e-05
rl training, epoch1, iter0, batch319/1133, batch loss:9.970437531592324e-05, Training time:18938.74702143669
batch reward last col mean 0.005752860568463802 first col mean 3.196043962816475e-06 all mean 0.005557481665164232
0.0005047963350079954 0.0005047962768003345
rl training, epoch1, iter0, batch320/1133, batch loss:0.0005047962768003345, Training time:18955.534016370773
batch reward last col mean 0.0015590358525514603 first col mean 2.1193796783336438e-05 all mean 0.00018000206910073757
0.0003999417822342366 0.00039994175313040614
rl training, epoch1, iter0, batch321/1133, batch loss:0.00039994175313040614, Training time:18972.41908621788
batch reward last col mean 0.006535489112138748 first col mean 6.46864646114409e-06 all mean 0.00034732717904262245
0.000700963893905282 0.000700963893905282
rl training, epoch1, iter0, batch322/1133, batch loss:0.000700963893905282, Training time:18989.234506607056
batch reward last col mean 0.00010299148561898619 first col mean 9.478131687501445e-05 all mean 0.0001316671841777861
0.00022810364316683263 0.00022810361406300217
rl training, epoch1, iter0, batch323/1133, batch loss:0.00022810361406300217, Training time:19005.94858455658
batch reward last col mean 1.8331335013499483e-05 first col mean 3.609979467000812e-05 all mean 0.00026239181170240045
0.00044313352555036545 0.00044313352555036545
rl training, epoch1, iter0, batch324/1133, batch loss:0.00044313352555036545, Training time:19022.537216186523
batch reward last col mean 3.304019628558308e-05 first col mean 2.9321414331207052e-05 all mean 0.00014163456216920167
9.868774941423908e-05 9.868775669019669e-05
rl training, epoch1, iter0, batch325/1133, batch loss:9.868775669019669e-05, Training time:19039.14026761055
batch reward last col mean 1.614822213014122e-05 first col mean 2.1815871150465682e-05 all mean 0.00010183949052589014
0.00012239045463502407 0.00012239048373885453
rl training, epoch1, iter0, batch326/1133, batch loss:0.00012239048373885453, Training time:19055.755402088165
batch reward last col mean 0.0003810096823144704 first col mean 5.852346021129051e-06 all mean 0.0004599957319442183
0.00015355141658801585 0.00015355141658801585
rl training, epoch1, iter0, batch327/1133, batch loss:0.00015355141658801585, Training time:19072.415352106094
batch reward last col mean 5.154347309144214e-05 first col mean 7.185224603745155e-06 all mean 0.0001482327643316239
6.93209221935831e-05 6.932091491762549e-05
rl training, epoch1, iter0, batch328/1133, batch loss:6.932091491762549e-05, Training time:19089.141539096832
batch reward last col mean 3.932004347007023e-06 first col mean 1.0785795893752947e-05 all mean 0.00018687100964598358
0.0002763404918368906 0.0002763404918368906
rl training, epoch1, iter0, batch329/1133, batch loss:0.0002763404918368906, Training time:19105.957902669907
batch reward last col mean 2.3399396013701335e-05 first col mean 1.1517111488501541e-05 all mean 0.0001805421052267775
0.0002892063348554075 0.0002892063348554075
rl training, epoch1, iter0, batch330/1133, batch loss:0.0002892063348554075, Training time:19122.70027065277
batch reward last col mean 2.36808045883663e-05 first col mean 2.0001622033305466e-05 all mean 0.00018417522369418293
0.00018213206203654408 0.00018213206203654408
rl training, epoch1, iter0, batch331/1133, batch loss:0.00018213206203654408, Training time:19139.26392841339
batch reward last col mean 5.900357336940942e-06 first col mean 0.0016548223793506622 all mean 0.00024277801276184618
0.00030919071286916733 0.0003091907419729978
rl training, epoch1, iter0, batch332/1133, batch loss:0.0003091907419729978, Training time:19156.136211633682
batch reward last col mean 4.6416120312642306e-05 first col mean 5.7961474340118e-06 all mean 0.00023169865016825497
0.0004532571183517575 0.0004532571183517575
rl training, epoch1, iter0, batch333/1133, batch loss:0.0004532571183517575, Training time:19173.034635782242
batch reward last col mean 7.942808224470355e-06 first col mean 0.00048539991257712245 all mean 0.0001639521651668474
0.0002820443478412926 0.0002820443769451231
rl training, epoch1, iter0, batch334/1133, batch loss:0.0002820443769451231, Training time:19189.636631965637
batch reward last col mean 0.004712651018053293 first col mean 1.3013375792070292e-05 all mean 0.0030961958691477776
0.0005299627664498985 0.0005299627664498985
rl training, epoch1, iter0, batch335/1133, batch loss:0.0005299627664498985, Training time:19206.279026031494
batch reward last col mean 0.0014836260816082358 first col mean 1.5100922610145062e-05 all mean 0.00010825078061316162
0.00029528941377066076 0.00029528941377066076
rl training, epoch1, iter0, batch336/1133, batch loss:0.00029528941377066076, Training time:19223.025880098343
batch reward last col mean 3.2012474548537284e-05 first col mean 0.0001447183167329058 all mean 0.0005776872276328504
0.000919091107789427 0.000919091107789427
rl training, epoch1, iter0, batch337/1133, batch loss:0.000919091107789427, Training time:19239.971970319748
batch reward last col mean 2.5844634365057573e-05 first col mean 4.76446257380303e-06 all mean 6.35904143564403e-05
0.00011673283734126016 0.00011673283734126016
rl training, epoch1, iter0, batch338/1133, batch loss:0.00011673283734126016, Training time:19256.60505962372
batch reward last col mean 4.5893459173385054e-05 first col mean 0.00032971310429275036 all mean 0.00036553340032696724
0.0004784342891070992 0.0004784342891070992
rl training, epoch1, iter0, batch339/1133, batch loss:0.0004784342891070992, Training time:19273.26316690445
batch reward last col mean 7.328624633373693e-06 first col mean 0.0002950707857962698 all mean 0.00012436750694178045
0.0002538544649723917 0.00025385443586856127
rl training, epoch1, iter0, batch340/1133, batch loss:0.00025385443586856127, Training time:19290.16379904747
batch reward last col mean 3.7123431866348255e-06 first col mean 2.6598588647175347e-06 all mean 0.0001690454373601824
0.00033963689929805696 0.0003396368701942265
rl training, epoch1, iter0, batch341/1133, batch loss:0.0003396368701942265, Training time:19306.87227511406
batch reward last col mean 0.00016295333625748754 first col mean 0.001661280170083046 all mean 0.00015071945381350815
0.00032328697852790356 0.000323287007631734
rl training, epoch1, iter0, batch342/1133, batch loss:0.000323287007631734, Training time:19323.40967464447
batch reward last col mean 0.00017797485634218901 first col mean 3.9570364606333897e-05 all mean 0.00015730161976534873
0.00015764794079586864 0.00015764794079586864
rl training, epoch1, iter0, batch343/1133, batch loss:0.00015764794079586864, Training time:19340.048597335815
batch reward last col mean 1.39849835250061e-05 first col mean 0.001146982074715197 all mean 0.00028457489679567516
0.00036312639713287354 0.00036312639713287354
rl training, epoch1, iter0, batch344/1133, batch loss:0.00036312639713287354, Training time:19356.841243505478
batch reward last col mean 5.821328159072436e-06 first col mean 6.102178758737864e-06 all mean 7.36653310013935e-05
0.00013307611516211182 0.00013307611516211182
rl training, epoch1, iter0, batch345/1133, batch loss:0.00013307611516211182, Training time:19373.886406183243
batch reward last col mean 7.331764209084213e-05 first col mean 1.992952820728533e-05 all mean 0.00013709561608266085
0.00012936814164277166 0.00012936814164277166
rl training, epoch1, iter0, batch346/1133, batch loss:0.00012936814164277166, Training time:19390.41539669037
batch reward last col mean 3.240088699385524e-05 first col mean 0.001608288032002747 all mean 0.00015231822908390313
0.00014277157606557012 0.00014277157606557012
rl training, epoch1, iter0, batch347/1133, batch loss:0.00014277157606557012, Training time:19407.13586449623
batch reward last col mean 1.342563427897403e-05 first col mean 1.7715130525175482e-05 all mean 0.0001058431007550098
0.00010454596485942602 0.00010454597941134125
rl training, epoch1, iter0, batch348/1133, batch loss:0.00010454597941134125, Training time:19423.876559257507
batch reward last col mean 0.0002492463099770248 first col mean 3.550688415998593e-05 all mean 0.00022116680338513106
0.0003592671127989888 0.0003592671419028193
rl training, epoch1, iter0, batch349/1133, batch loss:0.0003592671419028193, Training time:19440.451318740845
batch reward last col mean 0.0009463502210564911 first col mean 1.4662748981209006e-05 all mean 0.0010619743261486292
0.0003317698137834668 0.0003317697555758059
rl training, epoch1, iter0, batch350/1133, batch loss:0.0003317697555758059, Training time:19456.91373705864
batch reward last col mean 5.238889571046457e-05 first col mean 5.635198704112554e-06 all mean 9.403938747709617e-05
5.023001358495094e-05 5.02299953950569e-05
rl training, epoch1, iter0, batch351/1133, batch loss:5.02299953950569e-05, Training time:19474.05242919922
batch reward last col mean 3.409888449823484e-05 first col mean 4.705277024186216e-05 all mean 7.757615821901709e-05
6.5357715357095e-05 6.5357715357095e-05
rl training, epoch1, iter0, batch352/1133, batch loss:6.5357715357095e-05, Training time:19490.911140441895
batch reward last col mean 2.7727401175070554e-06 first col mean 2.9336617444641888e-05 all mean 9.828074689721689e-05
5.493711796589196e-05 5.4937107051955536e-05
rl training, epoch1, iter0, batch353/1133, batch loss:5.4937107051955536e-05, Training time:19507.642404556274
batch reward last col mean 8.475024515064433e-06 first col mean 6.556417247338686e-06 all mean 0.00014232766989152879
0.00023069888993632048 0.00023069888993632048
rl training, epoch1, iter0, batch354/1133, batch loss:0.00023069888993632048, Training time:19524.51976299286
batch reward last col mean 0.00025181102682836354 first col mean 1.585412974236533e-05 all mean 7.697783439652994e-05
6.773335189791396e-05 6.773336644982919e-05
rl training, epoch1, iter0, batch355/1133, batch loss:6.773336644982919e-05, Training time:19541.3585832119
batch reward last col mean 3.048999496968463e-05 first col mean 7.439435285050422e-05 all mean 0.00020556847448460758
0.00020767966634593904 0.00020767966634593904
rl training, epoch1, iter0, batch356/1133, batch loss:0.00020767966634593904, Training time:19558.194704294205
batch reward last col mean 0.00023362284991890192 first col mean 1.5990244719432667e-05 all mean 0.00015964126214385033
0.0003089245583396405 0.0003089245583396405
rl training, epoch1, iter0, batch357/1133, batch loss:0.0003089245583396405, Training time:19574.845782756805
batch reward last col mean 0.00010067909897770733 first col mean 1.0720506907091476e-05 all mean 0.00015536800492554903
0.0004290383658371866 0.0004290383658371866
rl training, epoch1, iter0, batch358/1133, batch loss:0.0004290383658371866, Training time:19591.757551670074
batch reward last col mean 0.00019804484327323735 first col mean 0.0010783661855384707 all mean 0.00022314529633149505
0.00029162762803025544 0.00029162762803025544
rl training, epoch1, iter0, batch359/1133, batch loss:0.00029162762803025544, Training time:19608.610356092453
batch reward last col mean 0.0012066009221598506 first col mean 0.00011561388237169012 all mean 0.00034299682010896504
0.0007641708943992853 0.0007641708361916244
rl training, epoch1, iter0, batch360/1133, batch loss:0.0007641708361916244, Training time:19625.313979625702
batch reward last col mean 3.932281288143713e-06 first col mean 2.39358632825315e-06 all mean 0.00013273945660330355
9.254472388420254e-05 9.254471660824493e-05
rl training, epoch1, iter0, batch361/1133, batch loss:9.254471660824493e-05, Training time:19641.982923269272
batch reward last col mean 1.8119008018402383e-05 first col mean 5.551028152694926e-05 all mean 0.00011166014883201569
0.00033583000185899436 0.00033583000185899436
rl training, epoch1, iter0, batch362/1133, batch loss:0.00033583000185899436, Training time:19658.642256975174
batch reward last col mean 1.992772695302847e-06 first col mean 1.1120224371552467e-05 all mean 6.920695886947215e-05
0.00021714690956287086 0.00021714686590712517
rl training, epoch1, iter0, batch363/1133, batch loss:0.00021714686590712517, Training time:19675.333662986755
batch reward last col mean 1.3491664503817447e-05 first col mean 0.0002277913736179471 all mean 0.00010961943189613521
0.00014928163727745414 0.00014928163727745414
rl training, epoch1, iter0, batch364/1133, batch loss:0.00014928163727745414, Training time:19691.8749063015
batch reward last col mean 1.5933497707010247e-05 first col mean 1.009403513307916e-05 all mean 0.00017159742128569633
0.00032537325751036406 0.0003253732866141945
rl training, epoch1, iter0, batch365/1133, batch loss:0.0003253732866141945, Training time:19708.497408151627
batch reward last col mean 6.278674118220806e-05 first col mean 4.276055915397592e-05 all mean 0.00011404159886296839
9.269513248000294e-05 9.269512520404533e-05
rl training, epoch1, iter0, batch366/1133, batch loss:9.269512520404533e-05, Training time:19725.38434290886
batch reward last col mean 2.774973472696729e-05 first col mean 4.827756492886692e-05 all mean 8.071507181739435e-05
8.54198369779624e-05 8.54198369779624e-05
rl training, epoch1, iter0, batch367/1133, batch loss:8.54198369779624e-05, Training time:19742.18537712097
batch reward last col mean 2.228864104836248e-05 first col mean 7.661939162062481e-05 all mean 0.00020736971055157483
0.00016026050434447825 0.00016026048979256302
rl training, epoch1, iter0, batch368/1133, batch loss:0.00016026048979256302, Training time:19759.12891483307
batch reward last col mean 0.005048613995313644 first col mean 1.965052251762245e-05 all mean 0.00025383345200680196
0.000649508205242455 0.000649508205242455
rl training, epoch1, iter0, batch369/1133, batch loss:0.000649508205242455, Training time:19775.80498957634
batch reward last col mean 0.00011339173943269998 first col mean 2.8211356038809754e-05 all mean 0.0001525410480098799
0.0002764558303169906 0.0002764558303169906
rl training, epoch1, iter0, batch370/1133, batch loss:0.0002764558303169906, Training time:19792.596316337585
batch reward last col mean 0.00011449692829046398 first col mean 2.687102323761792e-06 all mean 0.0001581855322001502
0.00023812054132577032 0.00023812055587768555
rl training, epoch1, iter0, batch371/1133, batch loss:0.00023812055587768555, Training time:19809.69812655449
batch reward last col mean 5.1615916163427755e-05 first col mean 4.968690973328194e-06 all mean 0.00012668663111981004
0.0002572606026660651 0.00025726057356223464
rl training, epoch1, iter0, batch372/1133, batch loss:0.00025726057356223464, Training time:19826.35430407524
batch reward last col mean 0.0007042627548798919 first col mean 1.4327225471788552e-05 all mean 0.00020409413264133036
0.0002993406669702381 0.00029934069607406855
rl training, epoch1, iter0, batch373/1133, batch loss:0.00029934069607406855, Training time:19843.164048194885
batch reward last col mean 0.0001619903341634199 first col mean 8.312827048939653e-06 all mean 0.00011927518789889291
8.971810166258365e-05 8.971811621449888e-05
rl training, epoch1, iter0, batch374/1133, batch loss:8.971811621449888e-05, Training time:19860.029512405396
batch reward last col mean 0.00015530872042290866 first col mean 3.5444143122731475e-06 all mean 0.0002594729885458946
0.0001497526391176507 0.00014975265366956592
rl training, epoch1, iter0, batch375/1133, batch loss:0.00014975265366956592, Training time:19876.661160230637
batch reward last col mean 3.645738388513564e-06 first col mean 7.634711437276565e-06 all mean 8.873439946910366e-05
0.0002191381063312292 0.00021913809177931398
rl training, epoch1, iter0, batch376/1133, batch loss:0.00021913809177931398, Training time:19893.21063399315
batch reward last col mean 3.510209353407845e-05 first col mean 0.0006878962158225477 all mean 9.004709863802418e-05
0.00020753001444973052 0.00020753001444973052
rl training, epoch1, iter0, batch377/1133, batch loss:0.00020753001444973052, Training time:19909.975749969482
batch reward last col mean 0.00013454184227157384 first col mean 3.264254337409511e-05 all mean 8.294664439745247e-05
4.6865308831911534e-05 4.6865308831911534e-05
rl training, epoch1, iter0, batch378/1133, batch loss:4.6865308831911534e-05, Training time:19926.78636074066
batch reward last col mean 2.2582104065804742e-05 first col mean 2.7149175366503187e-05 all mean 8.855073247104883e-05
9.678699279902503e-05 9.678698552306741e-05
rl training, epoch1, iter0, batch379/1133, batch loss:9.678698552306741e-05, Training time:19943.33495426178
batch reward last col mean 3.20611661663861e-06 first col mean 2.39455075643491e-05 all mean 0.0002177236310672015
0.00035194060183130205 0.00035194060183130205
rl training, epoch1, iter0, batch380/1133, batch loss:0.00035194060183130205, Training time:19959.907158851624
batch reward last col mean 0.0006666106637567282 first col mean 0.0009031512890942395 all mean 0.00046600287896580994
0.000860685424413532 0.000860685424413532
rl training, epoch1, iter0, batch381/1133, batch loss:0.000860685424413532, Training time:19976.69584298134
batch reward last col mean 5.2237075578887016e-05 first col mean 1.3753654457104858e-05 all mean 0.00021894277597311884
0.00039076487882994115 0.00039076487882994115
rl training, epoch1, iter0, batch382/1133, batch loss:0.00039076487882994115, Training time:19993.437007665634
batch reward last col mean 9.10995076992549e-05 first col mean 7.623619239893742e-06 all mean 0.0002321127540199086
0.00028732273494824767 0.00028732273494824767
rl training, epoch1, iter0, batch383/1133, batch loss:0.00028732273494824767, Training time:20010.379051923752
batch reward last col mean 0.007286233361810446 first col mean 1.8930042642750777e-05 all mean 0.00047032165457494557
0.0006324810674414039 0.0006324811256490648
rl training, epoch1, iter0, batch384/1133, batch loss:0.0006324811256490648, Training time:20027.141385555267
batch reward last col mean 6.655132438027067e-06 first col mean 4.113161048735492e-05 all mean 0.00019557842460926622
0.0002549965283833444 0.0002549965283833444
rl training, epoch1, iter0, batch385/1133, batch loss:0.0002549965283833444, Training time:20043.874470472336
batch reward last col mean 0.004633515607565641 first col mean 3.8478028727695346e-05 all mean 0.0028193898033350706
0.0012538073351606727 0.0012538073351606727
rl training, epoch1, iter0, batch386/1133, batch loss:0.0012538073351606727, Training time:20060.512989282608
batch reward last col mean 7.193034252850339e-05 first col mean 1.1155236279591918e-05 all mean 9.660520299803466e-05
0.0002197728172177449 0.0002197728172177449
rl training, epoch1, iter0, batch387/1133, batch loss:0.0002197728172177449, Training time:20077.54633450508
batch reward last col mean 5.261054320726544e-05 first col mean 6.569086690433323e-05 all mean 0.00012078534928150475
0.000155585294123739 0.00015558530867565423
rl training, epoch1, iter0, batch388/1133, batch loss:0.00015558530867565423, Training time:20094.40242767334
batch reward last col mean 6.459956239268649e-06 first col mean 0.0011600346770137548 all mean 0.00011544293374754488
0.0002325694658793509 0.0002325694658793509
rl training, epoch1, iter0, batch389/1133, batch loss:0.0002325694658793509, Training time:20111.33748292923
batch reward last col mean 0.00013503148511517793 first col mean 0.0009923053439706564 all mean 0.00019861462351400405
0.0002666647487785667 0.0002666647487785667
rl training, epoch1, iter0, batch390/1133, batch loss:0.0002666647487785667, Training time:20128.059165239334
batch reward last col mean 5.781817435490666e-06 first col mean 0.0003374443913344294 all mean 0.00029113912023603916
0.0003103846393059939 0.00031038461020216346
rl training, epoch1, iter0, batch391/1133, batch loss:0.00031038461020216346, Training time:20144.86128425598
batch reward last col mean 6.235284672584385e-05 first col mean 8.899062231648713e-05 all mean 0.00030303618405014277
0.0005311373970471323 0.0005311373970471323
rl training, epoch1, iter0, batch392/1133, batch loss:0.0005311373970471323, Training time:20161.631423950195
batch reward last col mean 0.0005237215082161129 first col mean 7.2689576882112306e-06 all mean 0.0004537457716651261
0.0005229655071161687 0.0005229655071161687
rl training, epoch1, iter0, batch393/1133, batch loss:0.0005229655071161687, Training time:20178.35590004921
batch reward last col mean 6.930431845830753e-05 first col mean 4.145577804592904e-06 all mean 0.0001577098882989958
0.00017574075900483876 0.00017574075900483876
rl training, epoch1, iter0, batch394/1133, batch loss:0.00017574075900483876, Training time:20195.055682897568
batch reward last col mean 0.0003044412296731025 first col mean 0.0012819545809179544 all mean 0.0001517849013907835
0.00015985810023266822 0.00015985807112883776
rl training, epoch1, iter0, batch395/1133, batch loss:0.00015985807112883776, Training time:20211.56199836731
batch reward last col mean 1.3180148926039692e-05 first col mean 9.262162348022684e-05 all mean 8.330362470587716e-05
0.00010654192738002166 0.00010654192738002166
rl training, epoch1, iter0, batch396/1133, batch loss:0.00010654192738002166, Training time:20228.454043626785
batch reward last col mean 0.00020624138414859772 first col mean 6.311521428870037e-05 all mean 0.00041579402750357985
0.00037817229167558253 0.00037817229167558253
rl training, epoch1, iter0, batch397/1133, batch loss:0.00037817229167558253, Training time:20245.09072947502
batch reward last col mean 2.248527562187519e-05 first col mean 4.707348853116855e-05 all mean 8.236044232035056e-05
0.0001644006697461009 0.0001644006697461009
rl training, epoch1, iter0, batch398/1133, batch loss:0.0001644006697461009, Training time:20261.77784180641
batch reward last col mean 0.0005644552875310183 first col mean 1.1919302778551355e-05 all mean 0.00028677762020379305
0.0003598856565076858 0.00035988559830002487
rl training, epoch1, iter0, batch399/1133, batch loss:0.00035988559830002487, Training time:20278.435787916183
batch reward last col mean 9.188949479721487e-05 first col mean 3.321533586131409e-05 all mean 0.00010480997298145667
0.00010391787509433925 0.0001039178969222121
rl training, epoch1, iter0, batch400/1133, batch loss:0.0001039178969222121, Training time:20295.19175028801
batch reward last col mean 1.7744607248459943e-05 first col mean 0.0002847102878149599 all mean 0.00030182042974047363
0.000517449458129704 0.000517449458129704
rl training, epoch1, iter0, batch401/1133, batch loss:0.000517449458129704, Training time:20312.14355325699
batch reward last col mean 2.7742538804886863e-05 first col mean 0.00010670976917026564 all mean 0.0002151907974621281
0.0002485791046638042 0.0002485791046638042
rl training, epoch1, iter0, batch402/1133, batch loss:0.0002485791046638042, Training time:20328.70812678337
batch reward last col mean 0.00013538319035433233 first col mean 1.7585329260327853e-05 all mean 8.380142389796674e-05
9.390812192577869e-05 9.390811464982107e-05
rl training, epoch1, iter0, batch403/1133, batch loss:9.390811464982107e-05, Training time:20345.190063238144
batch reward last col mean 5.592514753516298e-06 first col mean 6.27619829174364e-06 all mean 0.0001313840039074421
0.0002792260202113539 0.0002792260202113539
rl training, epoch1, iter0, batch404/1133, batch loss:0.0002792260202113539, Training time:20361.92106819153
batch reward last col mean 3.9557107811560854e-06 first col mean 1.9370751033420675e-05 all mean 5.742612120229751e-05
7.595481292810291e-05 7.595482020406052e-05
rl training, epoch1, iter0, batch405/1133, batch loss:7.595482020406052e-05, Training time:20378.530062437057
batch reward last col mean 9.580492587701883e-06 first col mean 1.8606522644404322e-05 all mean 0.0002634751726873219
0.0004770912928506732 0.0004770912928506732
rl training, epoch1, iter0, batch406/1133, batch loss:0.0004770912928506732, Training time:20395.469920635223
batch reward last col mean 0.0005277430173009634 first col mean 9.599217446520925e-05 all mean 0.0002054286451311782
0.00023447824059985578 0.0002344781969441101
rl training, epoch1, iter0, batch407/1133, batch loss:0.0002344781969441101, Training time:20412.32879924774
batch reward last col mean 1.148478258983232e-05 first col mean 4.375901698949747e-05 all mean 0.00013716328248847276
0.0001290672953473404 0.0001290672953473404
rl training, epoch1, iter0, batch408/1133, batch loss:0.0001290672953473404, Training time:20429.3807220459
batch reward last col mean 3.2404092053184286e-05 first col mean 8.325192538904957e-06 all mean 0.0001557436044095084
0.00012361147673800588 0.00012361147673800588
rl training, epoch1, iter0, batch409/1133, batch loss:0.00012361147673800588, Training time:20446.151417970657
batch reward last col mean 0.004409406334161758 first col mean 8.537815119780134e-06 all mean 0.003068479709327221
0.0004891504650004208 0.0004891504650004208
rl training, epoch1, iter0, batch410/1133, batch loss:0.0004891504650004208, Training time:20463.065369606018
batch reward last col mean 1.2034181963826995e-05 first col mean 3.628103877417743e-05 all mean 0.00013669517647940665
0.0001823500933824107 0.0001823500933824107
rl training, epoch1, iter0, batch411/1133, batch loss:0.0001823500933824107, Training time:20479.93979549408
batch reward last col mean 0.0003691197489388287 first col mean 1.5637382603017613e-05 all mean 0.00023208932543639094
0.00046612645382992923 0.0004661264247260988
rl training, epoch1, iter0, batch412/1133, batch loss:0.0004661264247260988, Training time:20496.84411597252
batch reward last col mean 7.1335780376102775e-06 first col mean 3.3131082091131248e-06 all mean 0.00011646239727269858
0.00015222678484860808 0.00015222678484860808
rl training, epoch1, iter0, batch413/1133, batch loss:0.00015222678484860808, Training time:20513.891416072845
batch reward last col mean 1.9552026060409844e-05 first col mean 9.787068847799674e-06 all mean 0.0001183704225695692
9.152819256996736e-05 9.152819256996736e-05
rl training, epoch1, iter0, batch414/1133, batch loss:9.152819256996736e-05, Training time:20530.809187173843
batch reward last col mean 0.00545890536159277 first col mean 5.688580858986825e-05 all mean 0.0003209699643775821
0.000442322256276384 0.0004423223144840449
rl training, epoch1, iter0, batch415/1133, batch loss:0.0004423223144840449, Training time:20547.70547771454
batch reward last col mean 0.00013226504961494356 first col mean 1.9477211026242003e-05 all mean 7.914392335806042e-05
7.135018677217886e-05 7.135019404813647e-05
rl training, epoch1, iter0, batch416/1133, batch loss:7.135019404813647e-05, Training time:20564.548452615738
batch reward last col mean 0.00013023792416788638 first col mean 0.002350845839828253 all mean 0.0002627655630931258
0.00042613950790837407 0.00042613950790837407
rl training, epoch1, iter0, batch417/1133, batch loss:0.00042613950790837407, Training time:20581.355269432068
batch reward last col mean 8.560382411815226e-06 first col mean 1.6565085388720036e-05 all mean 0.00018214595911558717
0.00016625084390398115 0.00016625084390398115
rl training, epoch1, iter0, batch418/1133, batch loss:0.00016625084390398115, Training time:20598.135625600815
batch reward last col mean 2.929078800661955e-05 first col mean 3.795345764956437e-05 all mean 9.283352119382471e-05
0.00014250889944378287 0.0001425089139956981
rl training, epoch1, iter0, batch419/1133, batch loss:0.0001425089139956981, Training time:20615.17627477646
batch reward last col mean 3.407633994356729e-05 first col mean 1.0118177669937722e-05 all mean 9.474629769101739e-05
0.00014636709238402545 0.00014636709238402545
rl training, epoch1, iter0, batch420/1133, batch loss:0.00014636709238402545, Training time:20631.760702848434
batch reward last col mean 2.120293356711045e-05 first col mean 4.463970253709704e-05 all mean 0.0001220932463183999
0.00014511530753225088 0.0001451153220841661
rl training, epoch1, iter0, batch421/1133, batch loss:0.0001451153220841661, Training time:20648.548020601273
batch reward last col mean 1.6347214113920927e-05 first col mean 0.00023912252800073475 all mean 0.00017978691903408617
0.00026344621437601745 0.0002634462434798479
rl training, epoch1, iter0, batch422/1133, batch loss:0.0002634462434798479, Training time:20665.751237392426
batch reward last col mean 6.9035286287544295e-06 first col mean 1.1617345990089234e-05 all mean 8.433107723249123e-05
0.0002416178904240951 0.0002416178904240951
rl training, epoch1, iter0, batch423/1133, batch loss:0.0002416178904240951, Training time:20682.612711191177
batch reward last col mean 1.6210224202950485e-05 first col mean 1.779764897946734e-05 all mean 0.00028090292471461
0.0003504133492242545 0.0003504133492242545
rl training, epoch1, iter0, batch424/1133, batch loss:0.0003504133492242545, Training time:20699.431900262833
batch reward last col mean 6.780179683119059e-05 first col mean 0.00036210138932801783 all mean 0.0002186038764193654
0.0004295005346648395 0.0004295005346648395
rl training, epoch1, iter0, batch425/1133, batch loss:0.0004295005346648395, Training time:20716.058646917343
batch reward last col mean 0.00023173150839284062 first col mean 0.0015383826103061438 all mean 0.00014264513447415084
0.00034145815880037844 0.00034145815880037844
rl training, epoch1, iter0, batch426/1133, batch loss:0.00034145815880037844, Training time:20732.797598838806
batch reward last col mean 0.0004074535390827805 first col mean 0.0019301290158182383 all mean 0.00024886138271540403
0.0002565316972322762 0.0002565316972322762
rl training, epoch1, iter0, batch427/1133, batch loss:0.0002565316972322762, Training time:20749.67692708969
batch reward last col mean 0.0025157975032925606 first col mean 1.5008205082267523e-05 all mean 0.002517496468499303
0.00040684398845769465 0.00040684398845769465
rl training, epoch1, iter0, batch428/1133, batch loss:0.00040684398845769465, Training time:20766.527411222458
batch reward last col mean 8.580773283028975e-05 first col mean 0.0012699475046247244 all mean 0.0001631813356652856
0.0002558110863901675 0.000255811057286337
rl training, epoch1, iter0, batch429/1133, batch loss:0.000255811057286337, Training time:20783.188716888428
batch reward last col mean 5.9430894907563925e-06 first col mean 0.0001345569035038352 all mean 0.00021758751245215535
0.00021915714023634791 0.00021915716934017837
rl training, epoch1, iter0, batch430/1133, batch loss:0.00021915716934017837, Training time:20799.80659675598
batch reward last col mean 1.2865567441622261e-05 first col mean 4.4822547351941466e-05 all mean 0.00015435123350471258
0.00013672016211785376 0.00013672014756593853
rl training, epoch1, iter0, batch431/1133, batch loss:0.00013672014756593853, Training time:20816.91656923294
batch reward last col mean 0.00010481105709914118 first col mean 0.00034393667010590434 all mean 0.00029369298135861754
0.0005445787683129311 0.0005445787683129311
rl training, epoch1, iter0, batch432/1133, batch loss:0.0005445787683129311, Training time:20833.98900294304
batch reward last col mean 1.2202756806800608e-05 first col mean 2.561986184446141e-05 all mean 0.0003051859966944903
0.0005635315901599824 0.0005635316483676434
rl training, epoch1, iter0, batch433/1133, batch loss:0.0005635316483676434, Training time:20850.530599355698
batch reward last col mean 2.278168176417239e-05 first col mean 4.9215209401154425e-06 all mean 0.00023490343301091343
0.00047455201274715364 0.00047455192543566227
rl training, epoch1, iter0, batch434/1133, batch loss:0.00047455192543566227, Training time:20867.195684432983
batch reward last col mean 4.4803591663367115e-06 first col mean 6.899206346133724e-05 all mean 9.73824571701698e-05
0.00021220502094365656 0.00021220502094365656
rl training, epoch1, iter0, batch435/1133, batch loss:0.00021220502094365656, Training time:20884.074862957
batch reward last col mean 4.066384644829668e-05 first col mean 0.0019797408021986485 all mean 0.0002542314468882978
0.00034433644032105803 0.0003443364112172276
rl training, epoch1, iter0, batch436/1133, batch loss:0.0003443364112172276, Training time:20900.922676324844
batch reward last col mean 0.00021124558406881988 first col mean 2.668581328180153e-05 all mean 0.0002741337229963392
0.0004209715989418328 0.0004209716571494937
rl training, epoch1, iter0, batch437/1133, batch loss:0.0004209716571494937, Training time:20917.39942216873
batch reward last col mean 5.4781583457952365e-05 first col mean 1.0912763173109852e-05 all mean 0.00014026204007677734
0.00015310956223402172 0.0001531095476821065
rl training, epoch1, iter0, batch438/1133, batch loss:0.0001531095476821065, Training time:20933.918056964874
batch reward last col mean 0.0015219118213281035 first col mean 8.416461241722573e-06 all mean 0.0013119577197358012
0.0003857542760670185 0.0003857542760670185
rl training, epoch1, iter0, batch439/1133, batch loss:0.0003857542760670185, Training time:20950.499945878983
batch reward last col mean 7.960727816680446e-05 first col mean 7.014014954620507e-06 all mean 0.0001236558164237067
0.0001125451090047136 0.00011254510172875598
rl training, epoch1, iter0, batch440/1133, batch loss:0.00011254510172875598, Training time:20967.21963787079
batch reward last col mean 4.0673261537449434e-05 first col mean 4.233084473526105e-05 all mean 8.184514445019886e-05
8.020952373044565e-05 8.020952373044565e-05
rl training, epoch1, iter0, batch441/1133, batch loss:8.020952373044565e-05, Training time:20984.081681489944
batch reward last col mean 0.0001006021338980645 first col mean 1.73952903423924e-05 all mean 0.0003655586624518037
0.0007462006178684533 0.0007462006178684533
rl training, epoch1, iter0, batch442/1133, batch loss:0.0007462006178684533, Training time:21000.72990345955
batch reward last col mean 1.1115756024082657e-05 first col mean 9.265271728509106e-06 all mean 0.00032407979597337544
0.00039025250589475036 0.0003902525349985808
rl training, epoch1, iter0, batch443/1133, batch loss:0.0003902525349985808, Training time:21017.614047288895
batch reward last col mean 0.004970455542206764 first col mean 1.643489667912945e-05 all mean 0.0005990835488773882
0.0007243044092319906 0.0007243044092319906
rl training, epoch1, iter0, batch444/1133, batch loss:0.0007243044092319906, Training time:21034.46288228035
batch reward last col mean 0.0023366124369204044 first col mean 6.714146729791537e-05 all mean 0.0002755338209681213
0.00031395917176268995 0.0003139591426588595
rl training, epoch1, iter0, batch445/1133, batch loss:0.0003139591426588595, Training time:21050.97635245323
batch reward last col mean 4.000249464297667e-05 first col mean 6.32070032224874e-06 all mean 0.00036368408473208547
0.000778860819991678 0.0007788608781993389
rl training, epoch1, iter0, batch446/1133, batch loss:0.0007788608781993389, Training time:21067.669892072678
batch reward last col mean 4.215542048768839e-06 first col mean 0.00014227830979507416 all mean 0.0001627359597478062
0.0002780594222713262 0.0002780594222713262
rl training, epoch1, iter0, batch447/1133, batch loss:0.0002780594222713262, Training time:21084.514127016068
batch reward last col mean 0.00019291155331302434 first col mean 0.0002016986982198432 all mean 0.00039706387906335294
0.0005297218449413776 0.0005297219031490386
rl training, epoch1, iter0, batch448/1133, batch loss:0.0005297219031490386, Training time:21101.188521146774
batch reward last col mean 0.0012731007300317287 first col mean 1.5109896594367456e-05 all mean 0.0011050394969061017
0.0002928025205619633 0.0002928025205619633
rl training, epoch1, iter0, batch449/1133, batch loss:0.0002928025205619633, Training time:21117.902346611023
batch reward last col mean 1.1117490430478938e-05 first col mean 0.000511939637362957 all mean 7.927765545900911e-05
0.00023011919984128326 0.0002301192143931985
rl training, epoch1, iter0, batch450/1133, batch loss:0.0002301192143931985, Training time:21134.627587795258
batch reward last col mean 6.151833804324269e-05 first col mean 1.0306886906619184e-05 all mean 0.00018161065236199647
0.00015250883006956428 0.00015250883006956428
rl training, epoch1, iter0, batch451/1133, batch loss:0.00015250883006956428, Training time:21151.421124458313
batch reward last col mean 0.00012118826271034777 first col mean 0.00020419519569259137 all mean 0.00012183768558315933
0.0002120303106494248 0.0002120303106494248
rl training, epoch1, iter0, batch452/1133, batch loss:0.0002120303106494248, Training time:21168.09790945053
batch reward last col mean 3.7878660805290565e-05 first col mean 8.780541065789293e-06 all mean 0.0001410276599926874
0.00015435002569574863 0.00015435002569574863
rl training, epoch1, iter0, batch453/1133, batch loss:0.00015435002569574863, Training time:21184.816389083862
batch reward last col mean 1.5563793567707762e-05 first col mean 1.436075399396941e-05 all mean 0.00017653101531323045
0.00016603920084889978 0.00016603920084889978
rl training, epoch1, iter0, batch454/1133, batch loss:0.00016603920084889978, Training time:21201.359900951385
batch reward last col mean 3.716438732226379e-05 first col mean 3.7979920307407156e-05 all mean 8.004646224435419e-05
7.572484173579141e-05 7.572484173579141e-05
rl training, epoch1, iter0, batch455/1133, batch loss:7.572484173579141e-05, Training time:21218.18929553032
batch reward last col mean 4.944644388160668e-06 first col mean 0.00044388824608176947 all mean 0.00011179942521266639
0.0001229378249263391 0.00012293781037442386
rl training, epoch1, iter0, batch456/1133, batch loss:0.00012293781037442386, Training time:21234.74281358719
batch reward last col mean 5.790991417597979e-05 first col mean 0.00023572464124299586 all mean 0.00020792738359887153
0.00021491925872396678 0.00021491925872396678
rl training, epoch1, iter0, batch457/1133, batch loss:0.00021491925872396678, Training time:21251.205497980118
batch reward last col mean 1.524469735159073e-05 first col mean 3.808919427683577e-05 all mean 0.00014146701141726226
0.0002285610098624602 0.00022856099531054497
rl training, epoch1, iter0, batch458/1133, batch loss:0.00022856099531054497, Training time:21267.845795869827
batch reward last col mean 9.575128387950826e-06 first col mean 1.6303325537592173e-05 all mean 0.0001249766064574942
0.0001727436319924891 0.00017274364654440433
rl training, epoch1, iter0, batch459/1133, batch loss:0.00017274364654440433, Training time:21284.674773931503
batch reward last col mean 1.6266038073808886e-05 first col mean 0.00039362479583360255 all mean 0.0002716252056416124
0.0003543907077983022 0.0003543906786944717
rl training, epoch1, iter0, batch460/1133, batch loss:0.0003543906786944717, Training time:21301.338091611862
batch reward last col mean 9.288663932238705e-06 first col mean 7.19269610272022e-06 all mean 0.00012198489275760949
0.000283410947304219 0.00028341091820038855
rl training, epoch1, iter0, batch461/1133, batch loss:0.00028341091820038855, Training time:21317.93988776207
batch reward last col mean 0.00022995422477833927 first col mean 6.433935050154105e-05 all mean 0.0003295837377663702
0.00027917278930544853 0.00027917284751310945
rl training, epoch1, iter0, batch462/1133, batch loss:0.00027917284751310945, Training time:21334.980321407318
batch reward last col mean 3.8586844311794266e-05 first col mean 0.0015813594218343496 all mean 0.0002107922191498801
0.00014279528113547713 0.0001427952665835619
rl training, epoch1, iter0, batch463/1133, batch loss:0.0001427952665835619, Training time:21351.653431415558
batch reward last col mean 1.0512508197280113e-05 first col mean 5.144658643985167e-05 all mean 8.496162627125159e-05
0.00020834467431996018 0.00020834467431996018
rl training, epoch1, iter0, batch464/1133, batch loss:0.00020834467431996018, Training time:21368.289950847626
batch reward last col mean 1.2966444046469405e-05 first col mean 0.00036741909570991993 all mean 0.0002293927245773375
0.0003858074778690934 0.0003858074778690934
rl training, epoch1, iter0, batch465/1133, batch loss:0.0003858074778690934, Training time:21385.155666589737
batch reward last col mean 0.0007711333455517888 first col mean 4.264759263605811e-05 all mean 0.00032390974229201674
0.0006032548262737691 0.00060325488448143
rl training, epoch1, iter0, batch466/1133, batch loss:0.00060325488448143, Training time:21402.00177025795
batch reward last col mean 1.2902175512863323e-05 first col mean 9.686337762104813e-06 all mean 0.00015800277469679713
0.0002871639735531062 0.0002871639735531062
rl training, epoch1, iter0, batch467/1133, batch loss:0.0002871639735531062, Training time:21418.524163484573
batch reward last col mean 3.489488153718412e-05 first col mean 7.084209755703341e-06 all mean 0.00015450759383384138
0.0003001994627993554 0.0003001994627993554
rl training, epoch1, iter0, batch468/1133, batch loss:0.0003001994627993554, Training time:21435.038367509842
batch reward last col mean 9.187738760374486e-05 first col mean 9.916963608702645e-05 all mean 0.00030213617719709873
0.0005963193252682686 0.0005963193252682686
rl training, epoch1, iter0, batch469/1133, batch loss:0.0005963193252682686, Training time:21452.056119441986
batch reward last col mean 7.409531463054009e-06 first col mean 2.8846505301771685e-05 all mean 0.00013451074482873082
0.000188611084013246 0.000188611084013246
rl training, epoch1, iter0, batch470/1133, batch loss:0.000188611084013246, Training time:21468.902617692947
batch reward last col mean 1.1520113730512094e-05 first col mean 5.428112126537599e-05 all mean 0.0001757010177243501
0.0003202449297532439 0.0003202449297532439
rl training, epoch1, iter0, batch471/1133, batch loss:0.0003202449297532439, Training time:21485.335030555725
batch reward last col mean 1.7300348190474324e-05 first col mean 0.0006972262053750455 all mean 0.0001650549384066835
0.00012566853547468781 0.00012566855002660304
rl training, epoch1, iter0, batch472/1133, batch loss:0.00012566855002660304, Training time:21501.91042160988
batch reward last col mean 7.046623068163171e-05 first col mean 0.0008013872429728508 all mean 0.00033060048008337617
0.0007597774965688586 0.0007597774965688586
rl training, epoch1, iter0, batch473/1133, batch loss:0.0007597774965688586, Training time:21518.624908924103
batch reward last col mean 4.218571848468855e-05 first col mean 2.7562628019950353e-05 all mean 0.00023876235354691744
0.0002680385368876159 0.0002680385368876159
rl training, epoch1, iter0, batch474/1133, batch loss:0.0002680385368876159, Training time:21535.411265850067
batch reward last col mean 0.0005345395184122026 first col mean 4.6015720727154985e-05 all mean 0.00036781447124667466
0.0006722617545165122 0.0006722616963088512
rl training, epoch1, iter0, batch475/1133, batch loss:0.0006722616963088512, Training time:21552.22760105133
batch reward last col mean 1.1697981790348422e-05 first col mean 2.9293909392436035e-05 all mean 0.0002602352760732174
0.0003785401349887252 0.0003785401349887252
rl training, epoch1, iter0, batch476/1133, batch loss:0.0003785401349887252, Training time:21568.936303138733
batch reward last col mean 3.5676148399943486e-05 first col mean 3.1297931855078787e-05 all mean 0.00013583505642600358
0.00016071363643277436 0.00016071363643277436
rl training, epoch1, iter0, batch477/1133, batch loss:0.00016071363643277436, Training time:21585.75360393524
batch reward last col mean 3.8835669329273514e-06 first col mean 3.065783403144451e-06 all mean 0.000199188434635289
0.0005314912414178252 0.0005314912414178252
rl training, epoch1, iter0, batch478/1133, batch loss:0.0005314912414178252, Training time:21602.51691508293
batch reward last col mean 1.1641735909506679e-05 first col mean 0.0013160330709069967 all mean 0.00020995821978431195
0.00035708246286958456 0.00035708246286958456
rl training, epoch1, iter0, batch479/1133, batch loss:0.00035708246286958456, Training time:21619.073427200317
batch reward last col mean 3.3240969059988856e-05 first col mean 0.0002624302578624338 all mean 0.00013638363452628255
0.00026485949638299644 0.00026485949638299644
rl training, epoch1, iter0, batch480/1133, batch loss:0.00026485949638299644, Training time:21635.87948179245
batch reward last col mean 0.0018761573592200875 first col mean 0.002214754233136773 all mean 0.0005740687483921647
0.0007231971248984337 0.0007231971248984337
rl training, epoch1, iter0, batch481/1133, batch loss:0.0007231971248984337, Training time:21653.047872781754
batch reward last col mean 3.4835147744161077e-06 first col mean 0.0014254961861297488 all mean 0.00024888935149647295
0.00033889373298734426 0.0003388937620911747
rl training, epoch1, iter0, batch482/1133, batch loss:0.0003388937620911747, Training time:21669.80033993721
batch reward last col mean 0.00015331516624428332 first col mean 1.6847146980580874e-05 all mean 0.00028495947481133044
0.0004885062226094306 0.0004885062226094306
rl training, epoch1, iter0, batch483/1133, batch loss:0.0004885062226094306, Training time:21686.456533432007
batch reward last col mean 0.0015614349395036697 first col mean 1.842555866460316e-05 all mean 0.0014229100197553635
0.0021424435544759035 0.0021424435544759035
rl training, epoch1, iter0, batch484/1133, batch loss:0.0021424435544759035, Training time:21703.206234693527
batch reward last col mean 6.54704199405387e-05 first col mean 1.1899332093889825e-05 all mean 0.00020270474487915635
0.0003077764413319528 0.0003077764413319528
rl training, epoch1, iter0, batch485/1133, batch loss:0.0003077764413319528, Training time:21720.00157213211
batch reward last col mean 0.000232163947657682 first col mean 0.00017924800340551883 all mean 0.000284486886812374
0.00031565577955916524 0.00031565577955916524
rl training, epoch1, iter0, batch486/1133, batch loss:0.00031565577955916524, Training time:21736.658218860626
batch reward last col mean 0.004119778051972389 first col mean 4.6747347369091585e-05 all mean 0.001594241475686431
0.0025482100900262594 0.0025482100900262594
rl training, epoch1, iter0, batch487/1133, batch loss:0.0025482100900262594, Training time:21753.621968984604
batch reward last col mean 5.274150680634193e-06 first col mean 1.0874845429498237e-05 all mean 0.00011972298671025783
0.00012440695718396455 0.0001244069280801341
rl training, epoch1, iter0, batch488/1133, batch loss:0.0001244069280801341, Training time:21770.541985034943
batch reward last col mean 1.599265669938177e-05 first col mean 0.00016201304970309138 all mean 0.0002526442112866789
0.00036603768239729106 0.00036603768239729106
rl training, epoch1, iter0, batch489/1133, batch loss:0.00036603768239729106, Training time:21787.185796499252
batch reward last col mean 3.180194471497089e-05 first col mean 0.0006186969112604856 all mean 0.00040072534466162324
0.0007366967620328069 0.000736696703825146
rl training, epoch1, iter0, batch490/1133, batch loss:0.000736696703825146, Training time:21803.72216439247
batch reward last col mean 0.00010831296822289005 first col mean 0.001829434186220169 all mean 0.00040664905100129545
0.00047984818229451776 0.00047984818229451776
rl training, epoch1, iter0, batch491/1133, batch loss:0.00047984818229451776, Training time:21820.39998483658
batch reward last col mean 2.3562472051708028e-05 first col mean 0.0019021822372451425 all mean 0.0001600277901161462
0.00012394752411637455 0.00012394753866828978
rl training, epoch1, iter0, batch492/1133, batch loss:0.00012394753866828978, Training time:21837.191567659378
batch reward last col mean 3.2248431125481147e-06 first col mean 0.0018318204674869776 all mean 0.0003185834502801299
0.00038603218854404986 0.0003860321012325585
rl training, epoch1, iter0, batch493/1133, batch loss:0.0003860321012325585, Training time:21853.740028619766
batch reward last col mean 2.6170757337240502e-05 first col mean 0.00022635579807683825 all mean 0.00014087604358792305
0.0004252372309565544 0.0004252372309565544
rl training, epoch1, iter0, batch494/1133, batch loss:0.0004252372309565544, Training time:21870.300654411316
batch reward last col mean 3.78799086320214e-05 first col mean 4.3677187932189554e-05 all mean 9.082371252588928e-05
0.0003616469621192664 0.0003616469039116055
rl training, epoch1, iter0, batch495/1133, batch loss:0.0003616469039116055, Training time:21887.07028412819
batch reward last col mean 0.0006625595269724727 first col mean 0.0005618610884994268 all mean 0.0001465022360207513
0.00018560141324996948 0.00018560141324996948
rl training, epoch1, iter0, batch496/1133, batch loss:0.00018560141324996948, Training time:21903.742082357407
batch reward last col mean 0.0001227595639647916 first col mean 7.695297244936228e-05 all mean 0.0002473881468176842
0.0003071693645324558 0.0003071693645324558
rl training, epoch1, iter0, batch497/1133, batch loss:0.0003071693645324558, Training time:21920.429359436035
batch reward last col mean 4.682824874180369e-05 first col mean 0.00022344989702105522 all mean 0.000237035405007191
0.0003728063602466136 0.0003728063893504441
rl training, epoch1, iter0, batch498/1133, batch loss:0.0003728063893504441, Training time:21937.18321299553
batch reward last col mean 0.0001974506740225479 first col mean 7.04167687217705e-05 all mean 0.00016455013246741146
0.0002631537208799273 0.00026315374998375773
rl training, epoch1, iter0, batch499/1133, batch loss:0.00026315374998375773, Training time:21954.072289466858
batch reward last col mean 3.1135107292357134e-06 first col mean 0.00018672767328098416 all mean 0.00018567008373793215
0.0003136124578304589 0.0003136124578304589
rl training, epoch1, iter0, batch500/1133, batch loss:0.0003136124578304589, Training time:21970.820957660675
batch reward last col mean 2.6550264010438696e-05 first col mean 0.001890096114948392 all mean 0.00028398941503837705
0.0003427120391279459 0.000342711980920285
rl training, epoch1, iter0, batch501/1133, batch loss:0.000342711980920285, Training time:21987.350343465805
batch reward last col mean 2.9928763979114592e-05 first col mean 0.0002604554465506226 all mean 0.0002939752012025565
0.000491816783323884 0.000491816783323884
rl training, epoch1, iter0, batch502/1133, batch loss:0.000491816783323884, Training time:22003.920328378677
batch reward last col mean 0.000310491188429296 first col mean 9.257916099159047e-05 all mean 0.00048814676119945943
0.0006598014151677489 0.0006598014151677489
rl training, epoch1, iter0, batch503/1133, batch loss:0.0006598014151677489, Training time:22020.756286382675
batch reward last col mean 1.364961099170614e-05 first col mean 6.239544018171728e-05 all mean 0.0002091734204441309
0.0002492218336556107 0.00024922186275944114
rl training, epoch1, iter0, batch504/1133, batch loss:0.00024922186275944114, Training time:22037.46879529953
batch reward last col mean 0.005249617155641317 first col mean 0.0009637097828090191 all mean 0.0003125799121335149
0.0004013001162093133 0.0004013001744169742
rl training, epoch1, iter0, batch505/1133, batch loss:0.0004013001744169742, Training time:22054.188614606857
batch reward last col mean 0.0007901461212895811 first col mean 0.0007482144865207374 all mean 0.0002508200122974813
0.00036369217559695244 0.00036369217559695244
rl training, epoch1, iter0, batch506/1133, batch loss:0.00036369217559695244, Training time:22071.133936405182
batch reward last col mean 2.3867036361480132e-05 first col mean 5.04606869071722e-05 all mean 0.00031272578053176403
0.0005969938938505948 0.0005969938938505948
rl training, epoch1, iter0, batch507/1133, batch loss:0.0005969938938505948, Training time:22088.01891231537
batch reward last col mean 5.528149813471828e-06 first col mean 4.0751729102339596e-05 all mean 0.00013493350706994534
0.0002283906942466274 0.00022839067969471216
rl training, epoch1, iter0, batch508/1133, batch loss:0.00022839067969471216, Training time:22104.625658273697
batch reward last col mean 0.00032557325903326273 first col mean 6.361316627589986e-05 all mean 0.0001310689258389175
0.0001247615582542494 0.00012476154370233417
rl training, epoch1, iter0, batch509/1133, batch loss:0.00012476154370233417, Training time:22121.361865520477
batch reward last col mean 9.086284990189597e-05 first col mean 7.275699317688122e-05 all mean 0.0002815847110468894
0.0006755634094588459 0.0006755634094588459
rl training, epoch1, iter0, batch510/1133, batch loss:0.0006755634094588459, Training time:22138.266827106476
batch reward last col mean 0.000402822537580505 first col mean 3.870853834087029e-05 all mean 0.000352640199707821
0.0003865119069814682 0.0003865119069814682
rl training, epoch1, iter0, batch511/1133, batch loss:0.0003865119069814682, Training time:22155.089176893234
batch reward last col mean 1.104540569940582e-05 first col mean 0.00036660535261034966 all mean 0.0002651573158800602
0.00045706777018494904 0.0004570677992887795
rl training, epoch1, iter0, batch512/1133, batch loss:0.0004570677992887795, Training time:22171.796250343323
batch reward last col mean 3.597660906962119e-05 first col mean 0.0018144154455512762 all mean 0.00019546892144717276
0.00029196107061579823 0.00029196107061579823
rl training, epoch1, iter0, batch513/1133, batch loss:0.00029196107061579823, Training time:22188.34727692604
batch reward last col mean 0.00010981481318594888 first col mean 6.711114110657945e-06 all mean 0.0002377938653808087
0.000563754525501281 0.000563754525501281
rl training, epoch1, iter0, batch514/1133, batch loss:0.000563754525501281, Training time:22205.55325627327
batch reward last col mean 8.51050135679543e-05 first col mean 9.975699504138902e-05 all mean 0.00033102877205237746
0.0005958041292615235 0.0005958040710538626
rl training, epoch1, iter0, batch515/1133, batch loss:0.0005958040710538626, Training time:22222.154866695404
batch reward last col mean 5.703619899577461e-05 first col mean 1.639715083001647e-05 all mean 0.00026348698884248734
0.00024283159291371703 0.0002428316220175475
rl training, epoch1, iter0, batch516/1133, batch loss:0.0002428316220175475, Training time:22238.76571202278
batch reward last col mean 5.0460703278076835e-06 first col mean 2.30182267841883e-05 all mean 0.00018121460743714124
0.00028411063249222934 0.00028411063249222934
rl training, epoch1, iter0, batch517/1133, batch loss:0.00028411063249222934, Training time:22255.387140989304
batch reward last col mean 0.00010250852938042954 first col mean 1.2284849617572036e-05 all mean 0.00022865412756800652
0.0004166258149780333 0.0004166258149780333
rl training, epoch1, iter0, batch518/1133, batch loss:0.0004166258149780333, Training time:22272.34326696396
batch reward last col mean 0.00010564511467237025 first col mean 0.00033079288550652564 all mean 0.00037125073140487075
0.0005164726171642542 0.0005164726171642542
rl training, epoch1, iter0, batch519/1133, batch loss:0.0005164726171642542, Training time:22289.335083961487
batch reward last col mean 0.0001404692739015445 first col mean 2.2762058506486937e-05 all mean 0.00018314566113986075
0.0005529886693693697 0.0005529886111617088
rl training, epoch1, iter0, batch520/1133, batch loss:0.0005529886111617088, Training time:22305.897224664688
batch reward last col mean 0.0010665541049093008 first col mean 0.0003933284606318921 all mean 0.0004620797699317336
0.0005620706360787153 0.0005620706360787153
rl training, epoch1, iter0, batch521/1133, batch loss:0.0005620706360787153, Training time:22322.761862516403
batch reward last col mean 0.0008395772892981768 first col mean 2.303458131791558e-05 all mean 0.0008367146365344524
0.0008503677090629935 0.0008503677090629935
rl training, epoch1, iter0, batch522/1133, batch loss:0.0008503677090629935, Training time:22339.429407596588
batch reward last col mean 8.419571713602636e-06 first col mean 0.0008177865529432893 all mean 0.00038309249794110656
0.0004952948656864464 0.0004952948074787855
rl training, epoch1, iter0, batch523/1133, batch loss:0.0004952948074787855, Training time:22356.02980852127
batch reward last col mean 0.00208485615439713 first col mean 0.0008518514805473387 all mean 0.0003741046821232885
0.00039708352414891124 0.00039708352414891124
rl training, epoch1, iter0, batch524/1133, batch loss:0.00039708352414891124, Training time:22372.740753889084
batch reward last col mean 0.0005808899295516312 first col mean 0.0010135422926396132 all mean 0.00020573929941747338
0.00023568062169943005 0.00023568062169943005
rl training, epoch1, iter0, batch525/1133, batch loss:0.00023568062169943005, Training time:22389.79712677002
batch reward last col mean 2.1676143660442904e-05 first col mean 7.419870235025883e-05 all mean 0.0002734045556280762
0.0004731061344500631 0.0004731061344500631
rl training, epoch1, iter0, batch526/1133, batch loss:0.0004731061344500631, Training time:22406.567494630814
batch reward last col mean 2.536855754442513e-05 first col mean 0.0010558824287727475 all mean 0.0002074037620332092
0.00037648738361895084 0.00037648738361895084
rl training, epoch1, iter0, batch527/1133, batch loss:0.00037648738361895084, Training time:22422.860530138016
batch reward last col mean 0.001352538587525487 first col mean 0.0001630076440051198 all mean 0.00020184206368867308
0.0001785886997822672 0.00017858868523035198
rl training, epoch1, iter0, batch528/1133, batch loss:0.00017858868523035198, Training time:22439.504075050354
batch reward last col mean 5.740162123402115e-06 first col mean 1.2424490705598146e-05 all mean 0.00016493865405209363
0.0003998290922027081 0.0003998290922027081
rl training, epoch1, iter0, batch529/1133, batch loss:0.0003998290922027081, Training time:22456.155259609222
batch reward last col mean 9.523639891995117e-05 first col mean 8.154617717082147e-06 all mean 0.0002623908221721649
0.0003812478680629283 0.0003812478680629283
rl training, epoch1, iter0, batch530/1133, batch loss:0.0003812478680629283, Training time:22472.892587423325
batch reward last col mean 0.0024090444203466177 first col mean 0.0013468615943565965 all mean 0.00045703095383942127
0.0009129220270551741 0.0009129220270551741
rl training, epoch1, iter0, batch531/1133, batch loss:0.0009129220270551741, Training time:22490.576464653015
batch reward last col mean 3.8803314964752644e-05 first col mean 5.255486939859111e-06 all mean 0.0004666289605665952
0.0005338808987289667 0.0005338808405213058
rl training, epoch1, iter0, batch532/1133, batch loss:0.0005338808405213058, Training time:22508.948101758957
batch reward last col mean 0.00038353269337676466 first col mean 6.640786523348652e-06 all mean 0.00024963472969830036
0.00035840514465235174 0.00035840514465235174
rl training, epoch1, iter0, batch533/1133, batch loss:0.00035840514465235174, Training time:22527.8250644207
batch reward last col mean 5.257925295154564e-05 first col mean 1.016694659483619e-05 all mean 0.00016166467685252428
0.00017580363783054054 0.00017580363783054054
rl training, epoch1, iter0, batch534/1133, batch loss:0.00017580363783054054, Training time:22546.37734222412
batch reward last col mean 7.821244071237743e-05 first col mean 2.8300302801653743e-05 all mean 0.0003763602871913463
0.00056521559599787 0.00056521559599787
rl training, epoch1, iter0, batch535/1133, batch loss:0.00056521559599787, Training time:22564.203513860703
batch reward last col mean 0.007193563040345907 first col mean 0.00011816164624178782 all mean 0.005668892525136471
0.0008990239002741873 0.0008990240166895092
rl training, epoch1, iter0, batch536/1133, batch loss:0.0008990240166895092, Training time:22580.69823884964
batch reward last col mean 3.4600202525325585e-06 first col mean 1.3432618288788944e-05 all mean 0.00021336933423299342
0.00030518011772073805 0.00030518011772073805
rl training, epoch1, iter0, batch537/1133, batch loss:0.00030518011772073805, Training time:22597.38468647003
batch reward last col mean 0.00013603366096504033 first col mean 1.9818216969724745e-05 all mean 0.0002754964225459844
0.00024116452550515532 0.00024116452550515532
rl training, epoch1, iter0, batch538/1133, batch loss:0.00024116452550515532, Training time:22613.919288635254
batch reward last col mean 2.133573252649512e-05 first col mean 0.0001470956631237641 all mean 0.0003151569690089673
0.0005593023379333317 0.0005593022797256708
rl training, epoch1, iter0, batch539/1133, batch loss:0.0005593022797256708, Training time:22630.655165195465
batch reward last col mean 0.0013019527541473508 first col mean 0.00021795459906570613 all mean 0.00019973258895333856
0.0005068995524197817 0.0005068995524197817
rl training, epoch1, iter0, batch540/1133, batch loss:0.0005068995524197817, Training time:22647.444066524506
batch reward last col mean 5.248143133940175e-05 first col mean 2.4190272597479634e-05 all mean 0.00032483527320437133
0.0003454385732766241 0.0003454385732766241
rl training, epoch1, iter0, batch541/1133, batch loss:0.0003454385732766241, Training time:22664.353215694427
batch reward last col mean 4.0687809814698994e-05 first col mean 4.059624916408211e-05 all mean 0.00013517742627300322
0.0002369774883845821 0.0002369774883845821
rl training, epoch1, iter0, batch542/1133, batch loss:0.0002369774883845821, Training time:22681.031106710434
batch reward last col mean 4.441764758666977e-05 first col mean 4.607751907315105e-05 all mean 0.0003200128849130124
0.0003065886558033526 0.0003065886558033526
rl training, epoch1, iter0, batch543/1133, batch loss:0.0003065886558033526, Training time:22697.787935256958
batch reward last col mean 0.007043117191642523 first col mean 0.00026485318085178733 all mean 0.006323880050331354
0.000689379230607301 0.0006893791723996401
rl training, epoch1, iter0, batch544/1133, batch loss:0.0006893791723996401, Training time:22714.401983499527
batch reward last col mean 6.0706275689881295e-05 first col mean 8.463587437290698e-05 all mean 0.0002103220613207668
0.00037130972486920655 0.00037130972486920655
rl training, epoch1, iter0, batch545/1133, batch loss:0.00037130972486920655, Training time:22731.21920132637
batch reward last col mean 0.0013075426686555147 first col mean 1.0052983270725235e-05 all mean 0.00028713676147162914
0.0004471039865165949 0.0004471040447242558
rl training, epoch1, iter0, batch546/1133, batch loss:0.0004471040447242558, Training time:22747.54169678688
batch reward last col mean 0.0009972810512408614 first col mean 0.0001366908836644143 all mean 0.0005851350724697113
0.0007194167701527476 0.0007194167701527476
rl training, epoch1, iter0, batch547/1133, batch loss:0.0007194167701527476, Training time:22766.04576253891
batch reward last col mean 0.00021591434779111296 first col mean 0.0003697369829751551 all mean 0.00036547728814184666
0.0004195900692138821 0.0004195900692138821
rl training, epoch1, iter0, batch548/1133, batch loss:0.0004195900692138821, Training time:22784.64990210533
batch reward last col mean 0.007176797837018967 first col mean 2.668468550837133e-05 all mean 0.00045972655061632395
0.0006695372285321355 0.0006695372285321355
rl training, epoch1, iter0, batch549/1133, batch loss:0.0006695372285321355, Training time:22803.349105358124
batch reward last col mean 0.00037609937135130167 first col mean 1.886220707092434e-05 all mean 0.00035893579479306936
0.000498131092172116 0.000498131092172116
rl training, epoch1, iter0, batch550/1133, batch loss:0.000498131092172116, Training time:22820.519474506378
batch reward last col mean 2.856563514797017e-05 first col mean 4.408306995173916e-05 all mean 0.00018756950157694519
0.0001933200255734846 0.0001933200255734846
rl training, epoch1, iter0, batch551/1133, batch loss:0.0001933200255734846, Training time:22837.88921904564
batch reward last col mean 0.010870774276554585 first col mean 4.802479816135019e-05 all mean 0.0007257599500007927
0.0015454035019502044 0.0015454036183655262
rl training, epoch1, iter0, batch552/1133, batch loss:0.0015454036183655262, Training time:22854.363793611526
batch reward last col mean 1.2602265996974893e-05 first col mean 9.933148248819634e-05 all mean 0.0001742945023579523
0.00010960840154439211 0.00010960838699247688
rl training, epoch1, iter0, batch553/1133, batch loss:0.00010960838699247688, Training time:22871.61484360695
batch reward last col mean 3.889887739205733e-05 first col mean 1.2912256352137774e-05 all mean 0.0002545043535064906
0.0005925255245529115 0.0005925255827605724
rl training, epoch1, iter0, batch554/1133, batch loss:0.0005925255827605724, Training time:22888.289650917053
batch reward last col mean 0.0029943494591861963 first col mean 6.961803592275828e-05 all mean 0.0028353435918688774
0.0011999451089650393 0.0011999451089650393
rl training, epoch1, iter0, batch555/1133, batch loss:0.0011999451089650393, Training time:22905.507792949677
batch reward last col mean 0.00010381287575000897 first col mean 0.00011332579015288502 all mean 0.00025184082915075123
0.0004028921539429575 0.0004028921539429575
rl training, epoch1, iter0, batch556/1133, batch loss:0.0004028921539429575, Training time:22922.18024110794
batch reward last col mean 8.086436537269037e-06 first col mean 2.7624568247119896e-05 all mean 0.0004094222094863653
0.0006652831216342747 0.0006652831216342747
rl training, epoch1, iter0, batch557/1133, batch loss:0.0006652831216342747, Training time:22938.64546895027
batch reward last col mean 0.000503541377838701 first col mean 1.9631415852927603e-05 all mean 0.00034953837166540325
0.0006451993831433356 0.0006451993249356747
rl training, epoch1, iter0, batch558/1133, batch loss:0.0006451993249356747, Training time:22955.168729305267
batch reward last col mean 2.8873548217234202e-05 first col mean 0.00019352597882971168 all mean 0.0003573493449948728
0.0004732016532216221 0.0004732016532216221
rl training, epoch1, iter0, batch559/1133, batch loss:0.0004732016532216221, Training time:22972.946554899216
batch reward last col mean 4.705185710918158e-05 first col mean 5.039154348196462e-05 all mean 0.00039263887447305024
0.0004892632714472711 0.0004892632714472711
rl training, epoch1, iter0, batch560/1133, batch loss:0.0004892632714472711, Training time:22990.554646492004
batch reward last col mean 0.0009086781647056341 first col mean 0.0021850005723536015 all mean 0.000250016717473045
0.00031627382850274444 0.00031627382850274444
rl training, epoch1, iter0, batch561/1133, batch loss:0.00031627382850274444, Training time:23009.297624111176
batch reward last col mean 1.880507988971658e-05 first col mean 0.0003948862722609192 all mean 0.00021796004148200154
0.0003139659238513559 0.0003139659238513559
rl training, epoch1, iter0, batch562/1133, batch loss:0.0003139659238513559, Training time:23027.60041642189
batch reward last col mean 0.001330964150838554 first col mean 5.447776857181452e-06 all mean 0.0004217738751322031
0.0005444569396786392 0.0005444569396786392
rl training, epoch1, iter0, batch563/1133, batch loss:0.0005444569396786392, Training time:23046.07416820526
batch reward last col mean 6.437499541789293e-05 first col mean 9.67231608228758e-05 all mean 0.00029195629758760333
0.0004873606376349926 0.0004873606376349926
rl training, epoch1, iter0, batch564/1133, batch loss:0.0004873606376349926, Training time:23063.866460323334
batch reward last col mean 5.632293687085621e-05 first col mean 8.167398482328281e-05 all mean 0.00037351265200413764
0.0004837102023884654 0.0004837102023884654
rl training, epoch1, iter0, batch565/1133, batch loss:0.0004837102023884654, Training time:23080.179656982422
batch reward last col mean 6.912667231517844e-06 first col mean 8.647968570585363e-06 all mean 0.00019933383737225085
0.00028592674061656 0.0002859267115127295
rl training, epoch1, iter0, batch566/1133, batch loss:0.0002859267115127295, Training time:23096.762625455856
batch reward last col mean 2.9928512958576903e-05 first col mean 1.3000881153857335e-05 all mean 0.00026651498046703637
0.0004278548585716635 0.0004278548585716635
rl training, epoch1, iter0, batch567/1133, batch loss:0.0004278548585716635, Training time:23113.56329536438
batch reward last col mean 2.6517343940213323e-05 first col mean 0.0003605562378652394 all mean 0.00021342285617720336
0.00024932349333539605 0.00024932349333539605
rl training, epoch1, iter0, batch568/1133, batch loss:0.00024932349333539605, Training time:23130.191836833954
batch reward last col mean 0.00017150293570011854 first col mean 0.0021128524094820023 all mean 0.001201665960252285
0.0011902920668944716 0.0011902920668944716
rl training, epoch1, iter0, batch569/1133, batch loss:0.0011902920668944716, Training time:23146.621195554733
batch reward last col mean 0.0010760144796222448 first col mean 0.0018104638438671827 all mean 0.00047007971443235874
0.0007830593385733664 0.0007830591639503837
rl training, epoch1, iter0, batch570/1133, batch loss:0.0007830591639503837, Training time:23163.770688295364
batch reward last col mean 0.0002239985769847408 first col mean 5.9495778259588405e-06 all mean 0.0008403088431805372
0.001242825179360807 0.0012428252957761288
rl training, epoch1, iter0, batch571/1133, batch loss:0.0012428252957761288, Training time:23180.447833538055
batch reward last col mean 0.005356214474886656 first col mean 3.559082324500196e-05 all mean 0.0002774084568955004
0.000476902408991009 0.000476902408991009
rl training, epoch1, iter0, batch572/1133, batch loss:0.000476902408991009, Training time:23197.035984516144
batch reward last col mean 5.372662053559907e-05 first col mean 0.0002957889810204506 all mean 0.0002814038598444313
0.00020820871577598155 0.00020820870122406632
rl training, epoch1, iter0, batch573/1133, batch loss:0.00020820870122406632, Training time:23214.138147592545
batch reward last col mean 4.331679519964382e-05 first col mean 2.1661293430952355e-05 all mean 0.0002731778076849878
0.0005175496335141361 0.0005175496335141361
rl training, epoch1, iter0, batch574/1133, batch loss:0.0005175496335141361, Training time:23231.75412940979
batch reward last col mean 0.0002426162245683372 first col mean 1.4527642633765936e-05 all mean 0.00017254291742574424
0.0002207539655501023 0.0002207539655501023
rl training, epoch1, iter0, batch575/1133, batch loss:0.0002207539655501023, Training time:23249.433113098145
batch reward last col mean 1.753631659084931e-05 first col mean 7.445299706887454e-05 all mean 0.00032070052111521363
0.0007136196363717318 0.0007136196363717318
rl training, epoch1, iter0, batch576/1133, batch loss:0.0007136196363717318, Training time:23268.68044948578
batch reward last col mean 0.0003311054897494614 first col mean 0.00046484393533319235 all mean 0.0003636655455920845
0.0006213002488948405 0.0006213002488948405
rl training, epoch1, iter0, batch577/1133, batch loss:0.0006213002488948405, Training time:23287.395851373672
batch reward last col mean 0.00012887651973869652 first col mean 0.001605476951226592 all mean 0.0004353726399131119
0.0003988234093412757 0.0003988234093412757
rl training, epoch1, iter0, batch578/1133, batch loss:0.0003988234093412757, Training time:23305.06559252739
batch reward last col mean 0.00670976284891367 first col mean 4.0884238842409104e-05 all mean 0.0010157340439036489
0.001265879487618804 0.001265879487618804
rl training, epoch1, iter0, batch579/1133, batch loss:0.001265879487618804, Training time:23321.391695022583
batch reward last col mean 0.003159804968163371 first col mean 0.0017906187567859888 all mean 0.0019561066292226315
0.0005212677060626447 0.0005212677060626447
rl training, epoch1, iter0, batch580/1133, batch loss:0.0005212677060626447, Training time:23337.893100500107
batch reward last col mean 1.854230504250154e-05 first col mean 0.00027838125242851675 all mean 0.0002665305510163307
0.0002448883024044335 0.0002448883024044335
rl training, epoch1, iter0, batch581/1133, batch loss:0.0002448883024044335, Training time:23354.305814504623
batch reward last col mean 0.00033770949812605977 first col mean 0.0007787586655467749 all mean 0.0003374986117705703
0.0003137427265755832 0.00031374269747175276
rl training, epoch1, iter0, batch582/1133, batch loss:0.00031374269747175276, Training time:23370.86877799034
batch reward last col mean 0.0011086310259997845 first col mean 0.00012242408411111683 all mean 0.0005586089100688696
0.0011003977851942182 0.0011003977851942182
rl training, epoch1, iter0, batch583/1133, batch loss:0.0011003977851942182, Training time:23387.99151110649
batch reward last col mean 3.6614124837797135e-05 first col mean 0.0009885464096441865 all mean 0.00024630120606161654
0.00024861193378455937 0.00024861193378455937
rl training, epoch1, iter0, batch584/1133, batch loss:0.00024861193378455937, Training time:23404.800043582916
batch reward last col mean 5.516833334695548e-05 first col mean 7.015897426754236e-05 all mean 0.00044938045903109014
0.0006099420716054738 0.0006099421298131347
rl training, epoch1, iter0, batch585/1133, batch loss:0.0006099421298131347, Training time:23421.29567360878
batch reward last col mean 0.0001348825462628156 first col mean 0.0011359029449522495 all mean 0.00024411070626229048
0.0004915951285511255 0.0004915951285511255
rl training, epoch1, iter0, batch586/1133, batch loss:0.0004915951285511255, Training time:23438.799334049225
batch reward last col mean 0.0003913859836757183 first col mean 3.453142198850401e-05 all mean 0.0009968845406547189
0.0012709923321381211 0.0012709925649687648
rl training, epoch1, iter0, batch587/1133, batch loss:0.0012709925649687648, Training time:23455.270493745804
batch reward last col mean 0.00013966589176561683 first col mean 6.230187136679888e-05 all mean 0.0003755155485123396
0.0004134480841457844 0.00041344802593812346
rl training, epoch1, iter0, batch588/1133, batch loss:0.00041344802593812346, Training time:23472.93832206726
batch reward last col mean 0.00018931744853034616 first col mean 8.580318535678089e-06 all mean 0.0002879649691749364
0.0004577093350235373 0.0004577093350235373
rl training, epoch1, iter0, batch589/1133, batch loss:0.0004577093350235373, Training time:23491.409259080887
batch reward last col mean 1.1840742445201613e-05 first col mean 0.0013513707090169191 all mean 0.0002936005184892565
0.00040165233076550066 0.0004016523016616702
rl training, epoch1, iter0, batch590/1133, batch loss:0.0004016523016616702, Training time:23510.395532608032
batch reward last col mean 2.675970972632058e-05 first col mean 0.00013272093201521784 all mean 0.0004456251044757664
0.0009852625662460923 0.0009852624498307705
rl training, epoch1, iter0, batch591/1133, batch loss:0.0009852624498307705, Training time:23528.937386274338
batch reward last col mean 0.005335917230695486 first col mean 0.00011310982517898083 all mean 0.0021434249356389046
0.0009723654366098344 0.0009723654366098344
rl training, epoch1, iter0, batch592/1133, batch loss:0.0009723654366098344, Training time:23545.590397834778
batch reward last col mean 0.0001937449851538986 first col mean 4.987301508663222e-05 all mean 0.0004881285422015935
0.0005800447543151677 0.0005800447543151677
rl training, epoch1, iter0, batch593/1133, batch loss:0.0005800447543151677, Training time:23564.24250102043
batch reward last col mean 8.560339483665302e-05 first col mean 9.127737575909123e-05 all mean 0.0002973883820232004
0.00042444176506251097 0.0004244418232701719
rl training, epoch1, iter0, batch594/1133, batch loss:0.0004244418232701719, Training time:23580.888207912445
batch reward last col mean 0.0010614822385832667 first col mean 0.0005303698708303273 all mean 0.0005822094972245395
0.0007549282745458186 0.0007549282163381577
rl training, epoch1, iter0, batch595/1133, batch loss:0.0007549282163381577, Training time:23597.364148378372
batch reward last col mean 0.00012269994476810098 first col mean 0.002074853517115116 all mean 0.00033491410431452096
0.0004048972041346133 0.0004048972041346133
rl training, epoch1, iter0, batch596/1133, batch loss:0.0004048972041346133, Training time:23614.100964546204
batch reward last col mean 7.322196324821562e-05 first col mean 0.0007811920368112624 all mean 0.00013730493083130568
0.00019112549489364028 0.00019112549489364028
rl training, epoch1, iter0, batch597/1133, batch loss:0.00019112549489364028, Training time:23630.613543510437
batch reward last col mean 0.0008187186322174966 first col mean 0.0002450731990393251 all mean 0.0008720960468053818
0.0006473310058936477 0.0006473310058936477
rl training, epoch1, iter0, batch598/1133, batch loss:0.0006473310058936477, Training time:23647.25213742256
batch reward last col mean 2.058618701994419e-05 first col mean 9.515426063444465e-05 all mean 0.0009097377769649029
0.0009793322533369064 0.0009793322533369064
rl training, epoch1, iter0, batch599/1133, batch loss:0.0009793322533369064, Training time:23663.977630138397
batch reward last col mean 9.358080205856822e-06 first col mean 5.3322321036830544e-05 all mean 0.0002236307627754286
0.00023807901015970856 0.00023807899560779333
rl training, epoch1, iter0, batch600/1133, batch loss:0.00023807899560779333, Training time:23680.327571630478
batch reward last col mean 0.00021938211284577847 first col mean 0.00012227056140545756 all mean 0.00032423646189272404
0.00026070946478284895 0.00026070946478284895
rl training, epoch1, iter0, batch601/1133, batch loss:0.00026070946478284895, Training time:23696.916093349457
batch reward last col mean 2.240620960947126e-05 first col mean 0.0008117271354421973 all mean 0.00018517587159294635
0.00028432547696866095 0.0002843255060724914
rl training, epoch1, iter0, batch602/1133, batch loss:0.0002843255060724914, Training time:23714.333790540695
batch reward last col mean 0.003975023981183767 first col mean 0.0005280555924400687 all mean 0.0035648338962346315
0.0007435216102749109 0.0007435216102749109
rl training, epoch1, iter0, batch603/1133, batch loss:0.0007435216102749109, Training time:23732.27452135086
batch reward last col mean 0.010617613792419434 first col mean 1.2510970918810926e-05 all mean 0.0010467745596542954
0.001644713687710464 0.0016447138041257858
rl training, epoch1, iter0, batch604/1133, batch loss:0.0016447138041257858, Training time:23750.647751569748
batch reward last col mean 0.001970796613022685 first col mean 3.466041380306706e-05 all mean 0.0004975256742909551
0.0005279658362269402 0.0005279657780192792
rl training, epoch1, iter0, batch605/1133, batch loss:0.0005279657780192792, Training time:23768.464457035065
batch reward last col mean 0.00033622377668507397 first col mean 4.047897891723551e-05 all mean 0.0002799672947730869
0.00035556918010115623 0.0003555692092049867
rl training, epoch1, iter0, batch606/1133, batch loss:0.0003555692092049867, Training time:23786.566265821457
batch reward last col mean 0.00015165247896220535 first col mean 6.8133367676637135e-06 all mean 0.0006878181593492627
0.0013290134957060218 0.0013290134957060218
rl training, epoch1, iter0, batch607/1133, batch loss:0.0013290134957060218, Training time:23805.655595064163
batch reward last col mean 0.0015171152772381902 first col mean 3.185505192959681e-05 all mean 0.00022712573991157115
0.00035332501283846796 0.0003533250419422984
rl training, epoch1, iter0, batch608/1133, batch loss:0.0003533250419422984, Training time:23822.09658074379
batch reward last col mean 3.8908350688870996e-05 first col mean 9.285472333431244e-05 all mean 0.0005772303557023406
0.0009016215335577726 0.0009016215335577726
rl training, epoch1, iter0, batch609/1133, batch loss:0.0009016215335577726, Training time:23838.563106536865
batch reward last col mean 1.7139353076345287e-05 first col mean 5.674683052347973e-05 all mean 0.0006139432662166655
0.0006600380293093622 0.0006600380293093622
rl training, epoch1, iter0, batch610/1133, batch loss:0.0006600380293093622, Training time:23855.13181090355
batch reward last col mean 0.00012338132364675403 first col mean 1.4563299373548944e-05 all mean 0.0004551929887384176
0.0005984738818369806 0.0005984738818369806
rl training, epoch1, iter0, batch611/1133, batch loss:0.0005984738818369806, Training time:23871.98701262474
batch reward last col mean 1.2932138815813232e-05 first col mean 6.0038655647076666e-05 all mean 0.0003901888558175415
0.0006534780259244144 0.0006534780259244144
rl training, epoch1, iter0, batch612/1133, batch loss:0.0006534780259244144, Training time:23888.561678886414
batch reward last col mean 0.006596880033612251 first col mean 0.0007074293680489063 all mean 0.0006378022953867912
0.0008702463819645345 0.0008702463819645345
rl training, epoch1, iter0, batch613/1133, batch loss:0.0008702463819645345, Training time:23905.31458210945
batch reward last col mean 7.474557787645608e-05 first col mean 0.00011512675700942054 all mean 0.00047883563092909753
0.000638624420389533 0.000638624420389533
rl training, epoch1, iter0, batch614/1133, batch loss:0.000638624420389533, Training time:23921.51433134079
batch reward last col mean 0.0004886587266810238 first col mean 0.0008203662582673132 all mean 0.0004236460372339934
0.0006120163016021252 0.0006120163016021252
rl training, epoch1, iter0, batch615/1133, batch loss:0.0006120163016021252, Training time:23938.487950086594
batch reward last col mean 0.0008672946714796126 first col mean 5.187395436223596e-05 all mean 0.00032954069320112467
0.0006658638012595475 0.0006658638012595475
rl training, epoch1, iter0, batch616/1133, batch loss:0.0006658638012595475, Training time:23954.98250579834
batch reward last col mean 0.001875094254501164 first col mean 0.0005491720512509346 all mean 0.0006624388042837381
0.0010355501435697079 0.0010355501435697079
rl training, epoch1, iter0, batch617/1133, batch loss:0.0010355501435697079, Training time:23971.503363370895
batch reward last col mean 4.515750697464682e-05 first col mean 5.204774788580835e-05 all mean 0.00024717155611142516
0.0005424906848929822 0.0005424906266853213
rl training, epoch1, iter0, batch618/1133, batch loss:0.0005424906266853213, Training time:23988.8566699028
batch reward last col mean 1.3675907212018501e-05 first col mean 0.0003593928995542228 all mean 0.000290716125164181
0.0003249665896873921 0.00032496656058356166
rl training, epoch1, iter0, batch619/1133, batch loss:0.00032496656058356166, Training time:24006.952713489532
batch reward last col mean 0.0010687581961974502 first col mean 0.00016939331544563174 all mean 0.0005915588117204607
0.0011341440258547664 0.0011341440258547664
rl training, epoch1, iter0, batch620/1133, batch loss:0.0011341440258547664, Training time:24026.442826986313
batch reward last col mean 0.0037406368646770716 first col mean 0.0041248430497944355 all mean 0.0005834241746924818
0.0008041425026021898 0.0008041425026021898
rl training, epoch1, iter0, batch621/1133, batch loss:0.0008041425026021898, Training time:24044.703832387924
batch reward last col mean 0.0004765645135194063 first col mean 0.00024210613628383726 all mean 0.0006337591912597418
0.0011199796572327614 0.0011199796572327614
rl training, epoch1, iter0, batch622/1133, batch loss:0.0011199796572327614, Training time:24063.46360015869
batch reward last col mean 0.00011816604092018679 first col mean 0.00012562843039631844 all mean 0.0005324034136720002
0.0008967996691353619 0.0008967996691353619
rl training, epoch1, iter0, batch623/1133, batch loss:0.0008967996691353619, Training time:24081.542907476425
batch reward last col mean 4.8409317969344556e-05 first col mean 0.00017235125415027142 all mean 0.0002524231094866991
0.000389400462154299 0.000389400462154299
rl training, epoch1, iter0, batch624/1133, batch loss:0.000389400462154299, Training time:24097.921021461487
batch reward last col mean 0.00126418296713382 first col mean 0.0009954929118975997 all mean 0.0005255065043456852
0.0008643465116620064 0.0008643465116620064
rl training, epoch1, iter0, batch625/1133, batch loss:0.0008643465116620064, Training time:24114.381755828857
batch reward last col mean 0.0019266566960141063 first col mean 0.0008546423050574958 all mean 0.0006926028290763497
0.0009917988209053874 0.0009917988209053874
rl training, epoch1, iter0, batch626/1133, batch loss:0.0009917988209053874, Training time:24131.344762563705
batch reward last col mean 0.00012565357610583305 first col mean 0.0003347417223267257 all mean 0.0005579808494076133
0.0012564585776999593 0.0012564585776999593
rl training, epoch1, iter0, batch627/1133, batch loss:0.0012564585776999593, Training time:24148.096179008484
batch reward last col mean 0.00011795321188401431 first col mean 0.00034757715184241533 all mean 0.00046872204984538257
0.0009032478556036949 0.000903247797396034
rl training, epoch1, iter0, batch628/1133, batch loss:0.000903247797396034, Training time:24164.593698978424
batch reward last col mean 4.708937194664031e-05 first col mean 6.696950003970414e-05 all mean 0.0004328021313995123
0.0008345877868123353 0.0008345876703970134
rl training, epoch1, iter0, batch629/1133, batch loss:0.0008345876703970134, Training time:24181.078547239304
batch reward last col mean 8.745487320993561e-06 first col mean 4.728468047687784e-05 all mean 0.0007816528086550534
0.0012716210912913084 0.0012716209748759866
rl training, epoch1, iter0, batch630/1133, batch loss:0.0012716209748759866, Training time:24198.022797107697
batch reward last col mean 0.001693553989753127 first col mean 6.14475502516143e-05 all mean 0.00030889143818058074
0.0007702188449911773 0.0007702187285758555
rl training, epoch1, iter0, batch631/1133, batch loss:0.0007702187285758555, Training time:24215.18808245659
batch reward last col mean 3.35855147568509e-05 first col mean 3.455636033322662e-05 all mean 0.0004172310000285506
0.000774688262026757 0.000774688262026757
rl training, epoch1, iter0, batch632/1133, batch loss:0.000774688262026757, Training time:24231.989073753357
batch reward last col mean 0.007357743103057146 first col mean 0.0005645919591188431 all mean 0.0008366320980712771
0.0018891289364546537 0.001889128820039332
rl training, epoch1, iter0, batch633/1133, batch loss:0.001889128820039332, Training time:24248.776272296906
batch reward last col mean 0.0007451876881532371 first col mean 2.773126652755309e-05 all mean 0.0003739095409400761
0.0005401495727710426 0.0005401495727710426
rl training, epoch1, iter0, batch634/1133, batch loss:0.0005401495727710426, Training time:24266.054280281067
batch reward last col mean 1.623925709282048e-05 first col mean 0.0004715067916549742 all mean 0.0003623949596658349
0.0005519218975678086 0.0005519218975678086
rl training, epoch1, iter0, batch635/1133, batch loss:0.0005519218975678086, Training time:24282.444335460663
batch reward last col mean 0.003917948808521032 first col mean 4.733975220005959e-05 all mean 0.003236992284655571
0.0011141541181132197 0.0011141541181132197
rl training, epoch1, iter0, batch636/1133, batch loss:0.0011141541181132197, Training time:24299.309550762177
batch reward last col mean 0.0016222383128479123 first col mean 7.907011604402214e-05 all mean 0.0013273177901282907
0.000743635231629014 0.000743635231629014
rl training, epoch1, iter0, batch637/1133, batch loss:0.000743635231629014, Training time:24315.947016239166
batch reward last col mean 0.00010478857439011335 first col mean 0.00021269232092890888 all mean 0.00029554986394941807
0.0003761810949072242 0.0003761810949072242
rl training, epoch1, iter0, batch638/1133, batch loss:0.0003761810949072242, Training time:24332.515162229538
batch reward last col mean 0.006425235420465469 first col mean 0.0011567596811801195 all mean 0.003424560884013772
0.0009903499158099294 0.0009903500322252512
rl training, epoch1, iter0, batch639/1133, batch loss:0.0009903500322252512, Training time:24350.121725082397
batch reward last col mean 2.288082214363385e-05 first col mean 0.001984728965908289 all mean 0.00026776132290251553
0.00016157950449269265 0.00016157950449269265
rl training, epoch1, iter0, batch640/1133, batch loss:0.00016157950449269265, Training time:24368.344306707382
batch reward last col mean 0.0035101198591291904 first col mean 0.00027456824318505824 all mean 0.0005427707219496369
0.001388068892993033 0.001388068776577711
rl training, epoch1, iter0, batch641/1133, batch loss:0.001388068776577711, Training time:24386.110756874084
batch reward last col mean 0.00020581699209287763 first col mean 0.00020240488811396062 all mean 0.00037148271803744137
0.00034808769123628736 0.00034808763302862644
rl training, epoch1, iter0, batch642/1133, batch loss:0.00034808763302862644, Training time:24404.21420931816
batch reward last col mean 0.0005036252550780773 first col mean 8.644044282846153e-05 all mean 0.00026221119333058596
0.0004894051817245781 0.0004894051817245781
rl training, epoch1, iter0, batch643/1133, batch loss:0.0004894051817245781, Training time:24422.658373594284
batch reward last col mean 0.009463741444051266 first col mean 0.0003818683326244354 all mean 0.0018398788524791598
0.002526393160223961 0.002526393160223961
rl training, epoch1, iter0, batch644/1133, batch loss:0.002526393160223961, Training time:24440.017294168472
batch reward last col mean 0.0003785813751164824 first col mean 2.0279288946767338e-05 all mean 0.0005691886181011796
0.0009174058213829994 0.0009174058213829994
rl training, epoch1, iter0, batch645/1133, batch loss:0.0009174058213829994, Training time:24456.667212486267
batch reward last col mean 0.0005270167021080852 first col mean 0.00038761558244004846 all mean 0.0009565713116899133
0.0007947629201225936 0.0007947629201225936
rl training, epoch1, iter0, batch646/1133, batch loss:0.0007947629201225936, Training time:24473.407042980194
batch reward last col mean 0.001161684631370008 first col mean 0.0019020764157176018 all mean 0.0005281714256852865
0.0009548274101689458 0.0009548275265842676
rl training, epoch1, iter0, batch647/1133, batch loss:0.0009548275265842676, Training time:24490.38440179825
batch reward last col mean 0.0015664733946323395 first col mean 8.629315561847761e-05 all mean 0.0003211481962352991
0.00043203181121498346 0.00043203181121498346
rl training, epoch1, iter0, batch648/1133, batch loss:0.00043203181121498346, Training time:24507.08028936386
batch reward last col mean 0.00010000877955462784 first col mean 9.06393597688293e-06 all mean 0.0005326699465513229
0.000731942243874073 0.000731942243874073
rl training, epoch1, iter0, batch649/1133, batch loss:0.000731942243874073, Training time:24524.53427052498
batch reward last col mean 0.0006685021799057722 first col mean 8.590760990045965e-05 all mean 0.0004126876883674413
0.0004700617282651365 0.0004700617282651365
rl training, epoch1, iter0, batch650/1133, batch loss:0.0004700617282651365, Training time:24541.050704717636
batch reward last col mean 0.00010067812399938703 first col mean 3.455139813013375e-05 all mean 0.0005195808480493724
0.0009703949908725917 0.0009703949908725917
rl training, epoch1, iter0, batch651/1133, batch loss:0.0009703949908725917, Training time:24557.979580640793
batch reward last col mean 0.0006349709583446383 first col mean 0.002728672930970788 all mean 0.0003864949685521424
0.0006471784436143935 0.0006471784436143935
rl training, epoch1, iter0, batch652/1133, batch loss:0.0006471784436143935, Training time:24574.972556591034
batch reward last col mean 0.00247942958958447 first col mean 0.0001137655126512982 all mean 0.0007381159230135381
0.0009411977371200919 0.0009411977371200919
rl training, epoch1, iter0, batch653/1133, batch loss:0.0009411977371200919, Training time:24591.922258138657
batch reward last col mean 0.0001703228772385046 first col mean 0.0014819760108366609 all mean 0.0006121683400124311
0.0008687502122484148 0.0008687502122484148
rl training, epoch1, iter0, batch654/1133, batch loss:0.0008687502122484148, Training time:24608.445235967636
batch reward last col mean 0.0019247401505708694 first col mean 0.00019640897517092526 all mean 0.0004707448824774474
0.0005876323557458818 0.0005876323557458818
rl training, epoch1, iter0, batch655/1133, batch loss:0.0005876323557458818, Training time:24626.02331829071
batch reward last col mean 2.114598100888543e-05 first col mean 0.0013524878304451704 all mean 0.0004571708559524268
0.0004547509306576103 0.00045475090155377984
rl training, epoch1, iter0, batch656/1133, batch loss:0.00045475090155377984, Training time:24644.805108308792
batch reward last col mean 0.002902213716879487 first col mean 6.835641397628933e-05 all mean 0.0010275386739522219
0.0017177971312776208 0.0017177971312776208
rl training, epoch1, iter0, batch657/1133, batch loss:0.0017177971312776208, Training time:24662.955564260483
batch reward last col mean 4.1532617615303025e-05 first col mean 0.000197697983821854 all mean 0.0003349408507347107
0.00034365535248070955 0.00034365538158454
rl training, epoch1, iter0, batch658/1133, batch loss:0.00034365538158454, Training time:24679.679080724716
batch reward last col mean 2.8840775485150516e-05 first col mean 2.887485607061535e-05 all mean 0.0009219769854098558
0.0014769912231713533 0.0014769912231713533
rl training, epoch1, iter0, batch659/1133, batch loss:0.0014769912231713533, Training time:24698.610911369324
batch reward last col mean 3.388423647265881e-05 first col mean 0.00010858129826374352 all mean 0.0014416256453841925
0.0019293848890811205 0.0019293848890811205
rl training, epoch1, iter0, batch660/1133, batch loss:0.0019293848890811205, Training time:24715.745527744293
batch reward last col mean 0.0002814006293192506 first col mean 0.0001253050722880289 all mean 0.001028483733534813
0.0013910632114857435 0.0013910630950704217
rl training, epoch1, iter0, batch661/1133, batch loss:0.0013910630950704217, Training time:24732.238748788834
batch reward last col mean 0.004702437203377485 first col mean 1.2003880328848027e-05 all mean 0.0009451744263060391
0.0011035598581656814 0.0011035598581656814
rl training, epoch1, iter0, batch662/1133, batch loss:0.0011035598581656814, Training time:24749.040810108185
batch reward last col mean 0.0007679599802941084 first col mean 0.0020247232168912888 all mean 0.0008841598173603415
0.0013835184508934617 0.0013835184508934617
rl training, epoch1, iter0, batch663/1133, batch loss:0.0013835184508934617, Training time:24765.86877799034
batch reward last col mean 0.00037807170883752406 first col mean 0.0007563565741293132 all mean 0.0005403243703767657
0.0008692648261785507 0.0008692648261785507
rl training, epoch1, iter0, batch664/1133, batch loss:0.0008692648261785507, Training time:24782.571962833405
batch reward last col mean 0.00015440651623066515 first col mean 0.0011324407532811165 all mean 0.0004797097062692046
0.000671564310323447 0.000671564310323447
rl training, epoch1, iter0, batch665/1133, batch loss:0.000671564310323447, Training time:24799.05825972557
batch reward last col mean 0.0006390684866346419 first col mean 0.001322407741099596 all mean 0.0006981759797781706
0.0008689475944265723 0.0008689475944265723
rl training, epoch1, iter0, batch666/1133, batch loss:0.0008689475944265723, Training time:24815.867314338684
batch reward last col mean 0.004932711366564035 first col mean 5.394423351390287e-05 all mean 0.0011662322795018554
0.001914961845614016 0.001914961845614016
rl training, epoch1, iter0, batch667/1133, batch loss:0.001914961845614016, Training time:24832.368447303772
batch reward last col mean 0.0005122144939377904 first col mean 4.395767973619513e-05 all mean 0.0004238590190652758
0.000867451133672148 0.0008674512500874698
rl training, epoch1, iter0, batch668/1133, batch loss:0.0008674512500874698, Training time:24848.767775535583
batch reward last col mean 0.0004991518217138946 first col mean 0.000550857512280345 all mean 0.0006644152454100549
0.0008937421371228993 0.0008937421371228993
rl training, epoch1, iter0, batch669/1133, batch loss:0.0008937421371228993, Training time:24865.55423951149
batch reward last col mean 7.263461156981066e-05 first col mean 9.09013906493783e-05 all mean 0.000572170945815742
0.0007576809730380774 0.0007576809730380774
rl training, epoch1, iter0, batch670/1133, batch loss:0.0007576809730380774, Training time:24884.394676446915
batch reward last col mean 0.0003272275789640844 first col mean 0.0002353085292270407 all mean 0.000575729354750365
0.0009394552325829864 0.0009394551743753254
rl training, epoch1, iter0, batch671/1133, batch loss:0.0009394551743753254, Training time:24902.230607271194
batch reward last col mean 0.0009015806135721505 first col mean 4.754961628350429e-05 all mean 0.0009726413991302252
0.0014119987608864903 0.0014119987608864903
rl training, epoch1, iter0, batch672/1133, batch loss:0.0014119987608864903, Training time:24919.737502098083
batch reward last col mean 0.0001254085509572178 first col mean 0.0002439972449792549 all mean 0.0004384424246381968
0.0004973272443749011 0.0004973272443749011
rl training, epoch1, iter0, batch673/1133, batch loss:0.0004973272443749011, Training time:24938.13448023796
batch reward last col mean 0.00014904537238180637 first col mean 0.001984029309824109 all mean 0.0008474971982650459
0.001090959063731134 0.0010909591801464558
rl training, epoch1, iter0, batch674/1133, batch loss:0.0010909591801464558, Training time:24956.64771270752
batch reward last col mean 5.073216379969381e-05 first col mean 2.5178836949635297e-05 all mean 0.000268119212705642
0.0004922292428091168 0.0004922292428091168
rl training, epoch1, iter0, batch675/1133, batch loss:0.0004922292428091168, Training time:24973.346661806107
batch reward last col mean 0.0013406837824732065 first col mean 0.00024514549295417964 all mean 0.0016495040617883205
0.0012191978748887777 0.0012191978748887777
rl training, epoch1, iter0, batch676/1133, batch loss:0.0012191978748887777, Training time:24989.90124797821
batch reward last col mean 5.6743319873930886e-05 first col mean 0.00019220280228182673 all mean 0.00044369683018885553
0.0006535642314702272 0.0006535641732625663
rl training, epoch1, iter0, batch677/1133, batch loss:0.0006535641732625663, Training time:25006.309903383255
batch reward last col mean 0.00021331218886189163 first col mean 0.0002094846568070352 all mean 0.0006410432979464531
0.0010058381594717503 0.0010058381594717503
rl training, epoch1, iter0, batch678/1133, batch loss:0.0010058381594717503, Training time:25022.87665772438
batch reward last col mean 0.008003177121281624 first col mean 0.0021082963794469833 all mean 0.0021336020436137915
0.0032088106963783503 0.0032088106963783503
rl training, epoch1, iter0, batch679/1133, batch loss:0.0032088106963783503, Training time:25039.305926561356
batch reward last col mean 0.00015811411140020937 first col mean 0.0009620964410714805 all mean 0.0005377815687097609
0.0006206096732057631 0.0006206096149981022
rl training, epoch1, iter0, batch680/1133, batch loss:0.0006206096149981022, Training time:25055.741314411163
batch reward last col mean 0.0006957498262636364 first col mean 0.00020895351190119982 all mean 0.000947939173784107
0.0013705894816666842 0.0013705894816666842
rl training, epoch1, iter0, batch681/1133, batch loss:0.0013705894816666842, Training time:25072.125151634216
batch reward last col mean 0.00020068464800715446 first col mean 0.00021739878866355866 all mean 0.0005548979970626533
0.0011082079727202654 0.0011082079727202654
rl training, epoch1, iter0, batch682/1133, batch loss:0.0011082079727202654, Training time:25089.75813961029
batch reward last col mean 0.0005813544848933816 first col mean 0.00015325291315093637 all mean 0.0008856070344336331
0.001201936393044889 0.001201936393044889
rl training, epoch1, iter0, batch683/1133, batch loss:0.001201936393044889, Training time:25107.51814198494
batch reward last col mean 0.00023736277944408357 first col mean 0.000133938345243223 all mean 0.0009442316950298846
0.001150099327787757 0.001150099211372435
rl training, epoch1, iter0, batch684/1133, batch loss:0.001150099211372435, Training time:25124.57920241356
batch reward last col mean 4.219992479193024e-05 first col mean 0.00019995677575934678 all mean 0.0007892615394666791
0.0008931239717639983 0.0008931239717639983
rl training, epoch1, iter0, batch685/1133, batch loss:0.0008931239717639983, Training time:25142.485722064972
batch reward last col mean 0.012422997504472733 first col mean 0.0001803621998988092 all mean 0.0017371021676808596
0.002997266361489892 0.002997266361489892
rl training, epoch1, iter0, batch686/1133, batch loss:0.002997266361489892, Training time:25159.630454301834
batch reward last col mean 0.0033980689477175474 first col mean 0.0003929397207684815 all mean 0.0027215457521378994
0.00400658929720521 0.00400658929720521
rl training, epoch1, iter0, batch687/1133, batch loss:0.00400658929720521, Training time:25176.69843363762
batch reward last col mean 0.0005068688769824803 first col mean 0.0004519248614087701 all mean 0.0011377492919564247
0.0014990333002060652 0.0014990333002060652
rl training, epoch1, iter0, batch688/1133, batch loss:0.0014990333002060652, Training time:25193.281686782837
batch reward last col mean 0.006584325805306435 first col mean 9.213649173034355e-05 all mean 0.0010872017592191696
0.0016906345263123512 0.0016906345263123512
rl training, epoch1, iter0, batch689/1133, batch loss:0.0016906345263123512, Training time:25209.853915691376
batch reward last col mean 0.0037810420617461205 first col mean 0.0009476306149736047 all mean 0.0006691356538794935
0.0009413948282599449 0.0009413948282599449
rl training, epoch1, iter0, batch690/1133, batch loss:0.0009413948282599449, Training time:25226.447870016098
batch reward last col mean 0.0030685975216329098 first col mean 0.0008068664465099573 all mean 0.0022404638584703207
0.003049650462344289 0.003049650462344289
rl training, epoch1, iter0, batch691/1133, batch loss:0.003049650462344289, Training time:25243.077310323715
batch reward last col mean 0.00044229754712432623 first col mean 0.00010454863513587043 all mean 0.0008684133063070476
0.0015978279989212751 0.0015978279989212751
rl training, epoch1, iter0, batch692/1133, batch loss:0.0015978279989212751, Training time:25259.894967556
batch reward last col mean 0.007883966900408268 first col mean 0.0006650667055509984 all mean 0.0009490573429502547
0.0014902094844728708 0.0014902094844728708
rl training, epoch1, iter0, batch693/1133, batch loss:0.0014902094844728708, Training time:25276.62041950226
batch reward last col mean 0.0016555008478462696 first col mean 0.002328988164663315 all mean 0.0016103023663163185
0.002355388831347227 0.002355388831347227
rl training, epoch1, iter0, batch694/1133, batch loss:0.002355388831347227, Training time:25293.207139015198
batch reward last col mean 2.199503614974674e-05 first col mean 0.0016193304909393191 all mean 0.0005410797311924398
0.0006734788184985518 0.0006734788184985518
rl training, epoch1, iter0, batch695/1133, batch loss:0.0006734788184985518, Training time:25310.94765138626
batch reward last col mean 0.0018590344116091728 first col mean 4.014981823274866e-05 all mean 0.0012282023672014475
0.0018742626998573542 0.0018742625834420323
rl training, epoch1, iter0, batch696/1133, batch loss:0.0018742625834420323, Training time:25328.131737709045
batch reward last col mean 0.00027313909959048033 first col mean 0.0025046896189451218 all mean 0.0006600710330531001
0.0007634992362000048 0.0007634992362000048
rl training, epoch1, iter0, batch697/1133, batch loss:0.0007634992362000048, Training time:25346.578273296356
batch reward last col mean 0.0003950354875996709 first col mean 0.0006176559254527092 all mean 0.0006470268708653748
0.0009294234914705157 0.0009294234332628548
rl training, epoch1, iter0, batch698/1133, batch loss:0.0009294234332628548, Training time:25363.735912322998
batch reward last col mean 0.016620783135294914 first col mean 7.626428850926459e-05 all mean 0.002817608416080475
0.0056607830338180065 0.0056607830338180065
rl training, epoch1, iter0, batch699/1133, batch loss:0.0056607830338180065, Training time:25382.615927934647
batch reward last col mean 0.0026065288111567497 first col mean 0.0006458874559029937 all mean 0.0011006424902006984
0.0012938971631228924 0.0012938971631228924
rl training, epoch1, iter0, batch700/1133, batch loss:0.0012938971631228924, Training time:25400.147491693497
batch reward last col mean 0.0013389915693551302 first col mean 0.00045182128087617457 all mean 0.0008483190322294831
0.0013512758305296302 0.0013512758305296302
rl training, epoch1, iter0, batch701/1133, batch loss:0.0013512758305296302, Training time:25417.117165327072
batch reward last col mean 0.0002365006657782942 first col mean 7.938228372950107e-05 all mean 0.0006725921994075179
0.000973678776063025 0.0009736788342706859
rl training, epoch1, iter0, batch702/1133, batch loss:0.0009736788342706859, Training time:25434.057029485703
batch reward last col mean 0.009914230555295944 first col mean 0.004520063288509846 all mean 0.0030407255981117487
0.0046127247624099255 0.0046127247624099255
rl training, epoch1, iter0, batch703/1133, batch loss:0.0046127247624099255, Training time:25450.793574810028
batch reward last col mean 0.0005531143397092819 first col mean 0.00025819448637776077 all mean 0.0008517185924574733
0.0012269809376448393 0.0012269809376448393
rl training, epoch1, iter0, batch704/1133, batch loss:0.0012269809376448393, Training time:25467.405409812927
batch reward last col mean 0.0002235132415080443 first col mean 0.000504107098095119 all mean 0.0010963579406961799
0.0018155834404751658 0.0018155834404751658
rl training, epoch1, iter0, batch705/1133, batch loss:0.0018155834404751658, Training time:25484.06657743454
batch reward last col mean 0.0004980790545232594 first col mean 0.00023067696020007133 all mean 0.0014677932485938072
0.002962997416034341 0.002962997416034341
rl training, epoch1, iter0, batch706/1133, batch loss:0.002962997416034341, Training time:25500.70124387741
batch reward last col mean 9.390634659212083e-05 first col mean 0.00036642083432525396 all mean 0.0009661506628617644
0.0013601878890767694 0.0013601878890767694
rl training, epoch1, iter0, batch707/1133, batch loss:0.0013601878890767694, Training time:25517.221409082413
batch reward last col mean 0.0003200820938218385 first col mean 0.0030072068329900503 all mean 0.0012566184159368277
0.0018972059478983283 0.0018972059478983283
rl training, epoch1, iter0, batch708/1133, batch loss:0.0018972059478983283, Training time:25533.537113904953
batch reward last col mean 0.009382948279380798 first col mean 0.001721684937365353 all mean 0.0011706484947353601
0.0013491433346644044 0.0013491433346644044
rl training, epoch1, iter0, batch709/1133, batch loss:0.0013491433346644044, Training time:25551.928753376007
batch reward last col mean 0.00045622052857652307 first col mean 0.002368328860029578 all mean 0.0014889657031744719
0.0023494225461035967 0.0023494225461035967
rl training, epoch1, iter0, batch710/1133, batch loss:0.0023494225461035967, Training time:25569.38364291191
batch reward last col mean 0.00016786088235676289 first col mean 0.000343830295605585 all mean 0.001212487812153995
0.0017799596535041928 0.0017799596535041928
rl training, epoch1, iter0, batch711/1133, batch loss:0.0017799596535041928, Training time:25587.283398628235
batch reward last col mean 0.00033866078592836857 first col mean 0.0009762420668266714 all mean 0.0009559609461575747
0.0013805401977151632 0.001380540314130485
rl training, epoch1, iter0, batch712/1133, batch loss:0.001380540314130485, Training time:25605.496374607086
batch reward last col mean 0.008136936463415623 first col mean 0.0012198155745863914 all mean 0.0023479280062019825
0.004259028006345034 0.004259028006345034
rl training, epoch1, iter0, batch713/1133, batch loss:0.004259028006345034, Training time:25622.724091768265
batch reward last col mean 0.001316011301241815 first col mean 0.002442834200337529 all mean 0.0016751684015616775
0.002698424505069852 0.002698424505069852
rl training, epoch1, iter0, batch714/1133, batch loss:0.002698424505069852, Training time:25639.316224575043
batch reward last col mean 0.00038469230639748275 first col mean 0.00012261363735888153 all mean 0.0015026319306343794
0.0020374981686472893 0.0020374981686472893
rl training, epoch1, iter0, batch715/1133, batch loss:0.0020374981686472893, Training time:25655.922247171402
batch reward last col mean 0.0009115246357396245 first col mean 0.0006303332629613578 all mean 0.0022845729254186153
0.003861477831378579 0.0038614782970398664
rl training, epoch1, iter0, batch716/1133, batch loss:0.0038614782970398664, Training time:25672.585520744324
batch reward last col mean 0.012208813801407814 first col mean 0.0006685867556370795 all mean 0.004886225331574678
0.007447218056768179 0.007447218522429466
rl training, epoch1, iter0, batch717/1133, batch loss:0.007447218522429466, Training time:25689.13681578636
batch reward last col mean 0.0001912142033688724 first col mean 0.00018775668286252767 all mean 0.0015599062899127603
0.002378842793405056 0.002378842793405056
rl training, epoch1, iter0, batch718/1133, batch loss:0.002378842793405056, Training time:25706.050418376923
batch reward last col mean 0.0016758450074121356 first col mean 0.0019315407844260335 all mean 0.0013836391735821962
0.000997709110379219 0.000997709110379219
rl training, epoch1, iter0, batch719/1133, batch loss:0.000997709110379219, Training time:25722.701018810272
batch reward last col mean 0.0009929738007485867 first col mean 0.0006429564673453569 all mean 0.0013463743962347507
0.0018907199846580625 0.0018907199846580625
rl training, epoch1, iter0, batch720/1133, batch loss:0.0018907199846580625, Training time:25739.52659010887
batch reward last col mean 0.0005643012700602412 first col mean 0.0021661047358065844 all mean 0.0013029153924435377
0.0018315254710614681 0.0018315254710614681
rl training, epoch1, iter0, batch721/1133, batch loss:0.0018315254710614681, Training time:25756.64759993553
batch reward last col mean 0.00014961734996177256 first col mean 0.00017528848547954112 all mean 0.0011505644069984555
0.0018632595892995596 0.0018632595892995596
rl training, epoch1, iter0, batch722/1133, batch loss:0.0018632595892995596, Training time:25773.479976654053
batch reward last col mean 0.0004565975395962596 first col mean 0.00013342020974960178 all mean 0.0013554614270105958
0.0019384120823815465 0.0019384123152121902
rl training, epoch1, iter0, batch723/1133, batch loss:0.0019384123152121902, Training time:25789.81707072258
batch reward last col mean 0.0009299181401729584 first col mean 0.0032333359122276306 all mean 0.002915572375059128
0.005568810738623142 0.005568810738623142
rl training, epoch1, iter0, batch724/1133, batch loss:0.005568810738623142, Training time:25806.983363628387
batch reward last col mean 0.0035238643176853657 first col mean 0.00010000777547247708 all mean 0.0023485999554395676
0.0034656296484172344 0.0034656296484172344
rl training, epoch1, iter0, batch725/1133, batch loss:0.0034656296484172344, Training time:25825.9390103817
batch reward last col mean 0.002710866741836071 first col mean 0.0016826544888317585 all mean 0.001367551158182323
0.002426375634968281 0.002426375402137637
rl training, epoch1, iter0, batch726/1133, batch loss:0.002426375402137637, Training time:25844.0733191967
batch reward last col mean 0.002484254539012909 first col mean 0.0015504943439736962 all mean 0.0017213169485330582
0.0031699826940894127 0.0031699826940894127
rl training, epoch1, iter0, batch727/1133, batch loss:0.0031699826940894127, Training time:25862.899874448776
batch reward last col mean 0.003704944159835577 first col mean 0.0012866889592260122 all mean 0.0023920258972793818
0.003761233063414693 0.003761233063414693
rl training, epoch1, iter0, batch728/1133, batch loss:0.003761233063414693, Training time:25880.79429078102
batch reward last col mean 0.007761883083730936 first col mean 0.0012974400306120515 all mean 0.0015335474163293839
0.0025755837559700012 0.002575583988800645
rl training, epoch1, iter0, batch729/1133, batch loss:0.002575583988800645, Training time:25900.702313184738
batch reward last col mean 0.002230876823887229 first col mean 0.0028724665753543377 all mean 0.0020615030080080032
0.003375289961695671 0.003375289961695671
rl training, epoch1, iter0, batch730/1133, batch loss:0.003375289961695671, Training time:25918.198465824127
batch reward last col mean 0.006586713716387749 first col mean 0.0018407017923891544 all mean 0.003324528457596898
0.005217182449996471 0.005217182449996471
rl training, epoch1, iter0, batch731/1133, batch loss:0.005217182449996471, Training time:25934.731048822403
batch reward last col mean 0.0023777105379849672 first col mean 0.00019805070769507438 all mean 0.002578340470790863
0.004373717587441206 0.004373717587441206
rl training, epoch1, iter0, batch732/1133, batch loss:0.004373717587441206, Training time:25951.564584732056
batch reward last col mean 0.01393226720392704 first col mean 0.0026205945760011673 all mean 0.008802168071269989
0.0051945229060947895 0.0051945229060947895
rl training, epoch1, iter0, batch733/1133, batch loss:0.0051945229060947895, Training time:25968.090269565582
batch reward last col mean 0.0009422998409718275 first col mean 0.0035264857579022646 all mean 0.0013885365333408117
0.002604977460578084 0.0026049769949167967
rl training, epoch1, iter0, batch734/1133, batch loss:0.0026049769949167967, Training time:25984.835325717926
batch reward last col mean 0.004424684215337038 first col mean 0.004191770683974028 all mean 0.0013739995192736387
0.0021754922345280647 0.0021754922345280647
rl training, epoch1, iter0, batch735/1133, batch loss:0.0021754922345280647, Training time:26001.340213775635
batch reward last col mean 0.006945502944290638 first col mean 0.001939466455951333 all mean 0.002216172404587269
0.0036003522109240294 0.003600352443754673
rl training, epoch1, iter0, batch736/1133, batch loss:0.003600352443754673, Training time:26017.93326807022
batch reward last col mean 0.006993712857365608 first col mean 0.0016037881141528487 all mean 0.0028302008286118507
0.0047530848532915115 0.0047530848532915115
rl training, epoch1, iter0, batch737/1133, batch loss:0.0047530848532915115, Training time:26034.332579135895
batch reward last col mean 0.0001104775074054487 first col mean 0.0027146427892148495 all mean 0.002123745856806636
0.0035043524112552404 0.0035043524112552404
rl training, epoch1, iter0, batch738/1133, batch loss:0.0035043524112552404, Training time:26051.378040075302
batch reward last col mean 0.0031379731371998787 first col mean 0.0007192328339442611 all mean 0.0021630532573908567
0.002981986152008176 0.0029819856863468885
rl training, epoch1, iter0, batch739/1133, batch loss:0.0029819856863468885, Training time:26067.883776664734
batch reward last col mean 0.001249882159754634 first col mean 0.0009048331412486732 all mean 0.002434052061289549
0.0042486670427024364 0.0042486670427024364
rl training, epoch1, iter0, batch740/1133, batch loss:0.0042486670427024364, Training time:26084.539948940277
batch reward last col mean 0.0019093987066298723 first col mean 0.0017675841227173805 all mean 0.0021475614048540592
0.0030609809327870607 0.0030609809327870607
rl training, epoch1, iter0, batch741/1133, batch loss:0.0030609809327870607, Training time:26101.1174223423
batch reward last col mean 0.001584862358868122 first col mean 0.003774189855903387 all mean 0.0019700280390679836
0.003041638294234872 0.0030416385270655155
rl training, epoch1, iter0, batch742/1133, batch loss:0.0030416385270655155, Training time:26117.62665247917
batch reward last col mean 0.006978889461606741 first col mean 0.0008278472232632339 all mean 0.002917049452662468
0.004774314351379871 0.004774313885718584
rl training, epoch1, iter0, batch743/1133, batch loss:0.004774313885718584, Training time:26134.401871204376
batch reward last col mean 0.00043847213964909315 first col mean 0.002214664127677679 all mean 0.0025567677803337574
0.0034692822955548763 0.0034692822955548763
rl training, epoch1, iter0, batch744/1133, batch loss:0.0034692822955548763, Training time:26151.866413593292
batch reward last col mean 0.013259612023830414 first col mean 0.0019349561771377921 all mean 0.005388085730373859
0.007663557771593332 0.007663557771593332
rl training, epoch1, iter0, batch745/1133, batch loss:0.007663557771593332, Training time:26170.562725782394
batch reward last col mean 0.003891566302627325 first col mean 0.0014232965186238289 all mean 0.0031811101362109184
0.0052314079366624355 0.005231407471001148
rl training, epoch1, iter0, batch746/1133, batch loss:0.005231407471001148, Training time:26190.12184381485
batch reward last col mean 0.02770942449569702 first col mean 0.002610534429550171 all mean 0.004951647948473692
0.009361790493130684 0.009361790493130684
rl training, epoch1, iter0, batch747/1133, batch loss:0.009361790493130684, Training time:26208.035921812057
batch reward last col mean 0.0017746144440025091 first col mean 0.003859580960124731 all mean 0.002348950132727623
0.003297625109553337 0.003297625109553337
rl training, epoch1, iter0, batch748/1133, batch loss:0.003297625109553337, Training time:26226.19031882286
batch reward last col mean 0.011980747804045677 first col mean 0.0012521407334133983 all mean 0.0058601368218660355
0.010099180974066257 0.010099180042743683
rl training, epoch1, iter0, batch749/1133, batch loss:0.010099180042743683, Training time:26242.970096826553
batch reward last col mean 0.005686837248504162 first col mean 0.003590263659134507 all mean 0.005197620019316673
0.007500617764890194 0.007500617764890194
rl training, epoch1, iter0, batch750/1133, batch loss:0.007500617764890194, Training time:26259.514373779297
batch reward last col mean 0.005913024302572012 first col mean 0.0020513066556304693 all mean 0.008711766451597214
0.01268314104527235 0.01268314104527235
rl training, epoch1, iter0, batch751/1133, batch loss:0.01268314104527235, Training time:26275.968452692032
batch reward last col mean 0.009674415923655033 first col mean 0.007532705552875996 all mean 0.004814154002815485
0.007777179125696421 0.007777179125696421
rl training, epoch1, iter0, batch752/1133, batch loss:0.007777179125696421, Training time:26292.445580482483
batch reward last col mean 0.010480969212949276 first col mean 0.0014291189145296812 all mean 0.004021209664642811
0.006580938585102558 0.006580938585102558
rl training, epoch1, iter0, batch753/1133, batch loss:0.006580938585102558, Training time:26309.400249004364
batch reward last col mean 0.0081694470718503 first col mean 0.005646216217428446 all mean 0.006131100468337536
0.009600457735359669 0.009600457735359669
rl training, epoch1, iter0, batch754/1133, batch loss:0.009600457735359669, Training time:26325.942737579346
batch reward last col mean 0.004615400917828083 first col mean 0.008564099669456482 all mean 0.006419253069907427
0.009522255510091782 0.009522255510091782
rl training, epoch1, iter0, batch755/1133, batch loss:0.009522255510091782, Training time:26342.753171920776
batch reward last col mean 0.004266913048923016 first col mean 0.002359529724344611 all mean 0.003984864801168442
0.006407590117305517 0.00640758965164423
rl training, epoch1, iter0, batch756/1133, batch loss:0.00640758965164423, Training time:26359.67845392227
batch reward last col mean 0.009080103598535061 first col mean 0.006058188155293465 all mean 0.006290755700320005
0.010947945527732372 0.010947945527732372
rl training, epoch1, iter0, batch757/1133, batch loss:0.010947945527732372, Training time:26376.195249080658
batch reward last col mean 0.010517224669456482 first col mean 0.00436212494969368 all mean 0.005832445342093706
0.009059736505150795 0.009059736505150795
rl training, epoch1, iter0, batch758/1133, batch loss:0.009059736505150795, Training time:26392.643631219864
batch reward last col mean 0.010666444897651672 first col mean 0.004242304712533951 all mean 0.00700182281434536
0.010698528029024601 0.010698528029024601
rl training, epoch1, iter0, batch759/1133, batch loss:0.010698528029024601, Training time:26410.02230167389
batch reward last col mean 0.004179554525762796 first col mean 0.008074570447206497 all mean 0.006942017935216427
0.010947075672447681 0.010947075672447681
rl training, epoch1, iter0, batch760/1133, batch loss:0.010947075672447681, Training time:26429.211492061615
batch reward last col mean 0.002948916982859373 first col mean 0.003472879994660616 all mean 0.005038481671363115
0.007988515309989452 0.007988515309989452
rl training, epoch1, iter0, batch761/1133, batch loss:0.007988515309989452, Training time:26445.962095737457
batch reward last col mean 0.007321844343096018 first col mean 0.0054248315282166 all mean 0.007424996234476566
0.01185758039355278 0.01185758039355278
rl training, epoch1, iter0, batch762/1133, batch loss:0.01185758039355278, Training time:26463.054121494293
batch reward last col mean 0.01067972183227539 first col mean 0.005275816656649113 all mean 0.006805987097322941
0.012407895177602768 0.012407895177602768
rl training, epoch1, iter0, batch763/1133, batch loss:0.012407895177602768, Training time:26480.432346343994
batch reward last col mean 0.009830138646066189 first col mean 0.0033527330961078405 all mean 0.006489420309662819
0.008969663642346859 0.008969663642346859
rl training, epoch1, iter0, batch764/1133, batch loss:0.008969663642346859, Training time:26498.262585639954
batch reward last col mean 0.009809192270040512 first col mean 0.008706394582986832 all mean 0.009081561118364334
0.013702289201319218 0.013702288269996643
rl training, epoch1, iter0, batch765/1133, batch loss:0.013702288269996643, Training time:26515.6464138031
batch reward last col mean 0.0013576803030446172 first col mean 0.0059167565777897835 all mean 0.007421888876706362
0.011144223622977734 0.011144223622977734
rl training, epoch1, iter0, batch766/1133, batch loss:0.011144223622977734, Training time:26532.705748796463
batch reward last col mean 0.03024628385901451 first col mean 0.009036142379045486 all mean 0.008877944201231003
0.014112312346696854 0.014112312346696854
rl training, epoch1, iter0, batch767/1133, batch loss:0.014112312346696854, Training time:26549.512108564377
batch reward last col mean 0.01305803470313549 first col mean 0.007091956213116646 all mean 0.010948999784886837
0.01601286232471466 0.01601286232471466
rl training, epoch1, iter0, batch768/1133, batch loss:0.01601286232471466, Training time:26566.860419750214
batch reward last col mean 0.01428006961941719 first col mean 0.010039071552455425 all mean 0.010197239927947521
0.016005277633666992 0.016005277633666992
rl training, epoch1, iter0, batch769/1133, batch loss:0.016005277633666992, Training time:26583.41608953476
batch reward last col mean 0.018886854872107506 first col mean 0.007658707909286022 all mean 0.012418900616466999
0.02095699869096279 0.02095699869096279
rl training, epoch1, iter0, batch770/1133, batch loss:0.02095699869096279, Training time:26600.154160499573
batch reward last col mean 0.02931605651974678 first col mean 0.0051740845665335655 all mean 0.01377398893237114
0.02066853642463684 0.020668532699346542
rl training, epoch1, iter0, batch771/1133, batch loss:0.020668532699346542, Training time:26616.551360607147
batch reward last col mean 0.01035760436207056 first col mean 0.012275617569684982 all mean 0.010488677769899368
0.01635099947452545 0.016350997611880302
rl training, epoch1, iter0, batch772/1133, batch loss:0.016350997611880302, Training time:26633.22427868843
batch reward last col mean 0.015227412804961205 first col mean 0.006687514018267393 all mean 0.01312495768070221
0.020836878567934036 0.020836878567934036
rl training, epoch1, iter0, batch773/1133, batch loss:0.020836878567934036, Training time:26649.982109069824
batch reward last col mean 0.019112633541226387 first col mean 0.010037768632173538 all mean 0.015086567960679531
0.023395240306854248 0.023395240306854248
rl training, epoch1, iter0, batch774/1133, batch loss:0.023395240306854248, Training time:26668.498651981354
batch reward last col mean 0.01744433119893074 first col mean 0.00807688757777214 all mean 0.015074791386723518
0.022751430049538612 0.022751430049538612
rl training, epoch1, iter0, batch775/1133, batch loss:0.022751430049538612, Training time:26688.206071138382
batch reward last col mean 0.015125289559364319 first col mean 0.013420764356851578 all mean 0.013561800122261047
0.021578330546617508 0.021578330546617508
rl training, epoch1, iter0, batch776/1133, batch loss:0.021578330546617508, Training time:26706.613990306854
batch reward last col mean 0.04416565224528313 first col mean 0.026270899921655655 all mean 0.023507127538323402
0.03264240548014641 0.03264240548014641
rl training, epoch1, iter0, batch777/1133, batch loss:0.03264240548014641, Training time:26724.250173330307
batch reward last col mean 0.01143022533506155 first col mean 0.010472471825778484 all mean 0.020496860146522522
0.031432606279850006 0.03143260255455971
rl training, epoch1, iter0, batch778/1133, batch loss:0.03143260255455971, Training time:26742.53148841858
batch reward last col mean 0.04939071834087372 first col mean 0.021592702716588974 all mean 0.02359459549188614
0.03951575979590416 0.03951575979590416
rl training, epoch1, iter0, batch779/1133, batch loss:0.03951575979590416, Training time:26759.871603488922
batch reward last col mean 0.025525517761707306 first col mean 0.018684333190321922 all mean 0.02697247639298439
0.04150092601776123 0.04150092601776123
rl training, epoch1, iter0, batch780/1133, batch loss:0.04150092601776123, Training time:26776.854650735855
batch reward last col mean 0.042162492871284485 first col mean 0.021553799510002136 all mean 0.030840151011943817
0.05152247101068497 0.05152246356010437
rl training, epoch1, iter0, batch781/1133, batch loss:0.05152246356010437, Training time:26793.429084300995
batch reward last col mean 0.030524540692567825 first col mean 0.01975852996110916 all mean 0.03142677992582321
0.05062176659703255 0.050621770322322845
rl training, epoch1, iter0, batch782/1133, batch loss:0.050621770322322845, Training time:26810.01654934883
batch reward last col mean 0.029154110699892044 first col mean 0.033589497208595276 all mean 0.03744928911328316
0.05942637473344803 0.05942637473344803
rl training, epoch1, iter0, batch783/1133, batch loss:0.05942637473344803, Training time:26826.78558945656
batch reward last col mean 0.028534218668937683 first col mean 0.03729365020990372 all mean 0.03637009859085083
0.05773911252617836 0.05773911252617836
rl training, epoch1, iter0, batch784/1133, batch loss:0.05773911252617836, Training time:26843.243559122086
batch reward last col mean 0.05201038718223572 first col mean 0.0409204326570034 all mean 0.03665643185377121
0.06175130605697632 0.06175130605697632
rl training, epoch1, iter0, batch785/1133, batch loss:0.06175130605697632, Training time:26859.76612472534
batch reward last col mean 0.038136083632707596 first col mean 0.03512609377503395 all mean 0.039219826459884644
0.0662250965833664 0.06622510403394699
rl training, epoch1, iter0, batch786/1133, batch loss:0.06622510403394699, Training time:26876.5857257843
batch reward last col mean 0.0333375409245491 first col mean 0.04708871990442276 all mean 0.04861481860280037
0.07801726460456848 0.07801726460456848
rl training, epoch1, iter0, batch787/1133, batch loss:0.07801726460456848, Training time:26893.418303012848
batch reward last col mean 0.07894270867109299 first col mean 0.06167981028556824 all mean 0.059242576360702515
0.08870027959346771 0.08870027959346771
rl training, epoch1, iter0, batch788/1133, batch loss:0.08870027959346771, Training time:26910.4501144886
batch reward last col mean 0.07951495796442032 first col mean 0.05744074285030365 all mean 0.06961457431316376
0.11929976940155029 0.11929976940155029
rl training, epoch1, iter0, batch789/1133, batch loss:0.11929976940155029, Training time:26929.206907987595
batch reward last col mean 0.09802190959453583 first col mean 0.07803086191415787 all mean 0.07758991420269012
0.11565648019313812 0.11565648019313812
rl training, epoch1, iter0, batch790/1133, batch loss:0.11565648019313812, Training time:26948.568794965744
batch reward last col mean 0.11027190089225769 first col mean 0.07477216422557831 all mean 0.08314373344182968
0.13836748898029327 0.13836748898029327
rl training, epoch1, iter0, batch791/1133, batch loss:0.13836748898029327, Training time:26966.694212913513
batch reward last col mean 0.10197360813617706 first col mean 0.08685307204723358 all mean 0.08973467350006104
0.14902710914611816 0.14902712404727936
rl training, epoch1, iter0, batch792/1133, batch loss:0.14902712404727936, Training time:26985.016261577606
batch reward last col mean 0.09088336676359177 first col mean 0.08894971758127213 all mean 0.09062106162309647
0.15028780698776245 0.15028780698776245
rl training, epoch1, iter0, batch793/1133, batch loss:0.15028780698776245, Training time:27004.036354780197
batch reward last col mean 0.12000467628240585 first col mean 0.0855744257569313 all mean 0.11805054545402527
0.19512854516506195 0.19512854516506195
rl training, epoch1, iter0, batch794/1133, batch loss:0.19512854516506195, Training time:27021.851124048233
batch reward last col mean 0.15382345020771027 first col mean 0.13483691215515137 all mean 0.13263610005378723
0.22093282639980316 0.22093282639980316
rl training, epoch1, iter0, batch795/1133, batch loss:0.22093282639980316, Training time:27038.48556947708
batch reward last col mean 0.11918400973081589 first col mean 0.1184537410736084 all mean 0.12858128547668457
0.2103608101606369 0.2103608101606369
rl training, epoch1, iter0, batch796/1133, batch loss:0.2103608101606369, Training time:27055.136824846268
batch reward last col mean 0.1747494786977768 first col mean 0.15682271122932434 all mean 0.1829862743616104
0.3006241023540497 0.3006241023540497
rl training, epoch1, iter0, batch797/1133, batch loss:0.3006241023540497, Training time:27071.675163269043
batch reward last col mean 0.21349042654037476 first col mean 0.1383146047592163 all mean 0.1686323881149292
0.2873045802116394 0.2873045802116394
rl training, epoch1, iter0, batch798/1133, batch loss:0.2873045802116394, Training time:27088.264997959137
batch reward last col mean 0.21347086131572723 first col mean 0.1892796754837036 all mean 0.20444099605083466
0.33466824889183044 0.33466824889183044
rl training, epoch1, iter0, batch799/1133, batch loss:0.33466824889183044, Training time:27104.95419692993
batch reward last col mean 0.21526896953582764 first col mean 0.18641744554042816 all mean 0.21073053777217865
0.35019201040267944 0.35019204020500183
rl training, epoch1, iter0, batch800/1133, batch loss:0.35019204020500183, Training time:27121.447274684906
batch reward last col mean 0.21828767657279968 first col mean 0.20974485576152802 all mean 0.2051595002412796
0.3573676347732544 0.3573676347732544
rl training, epoch1, iter0, batch801/1133, batch loss:0.3573676347732544, Training time:27137.971202135086
batch reward last col mean 0.23298169672489166 first col mean 0.23055033385753632 all mean 0.24926503002643585
0.42760005593299866 0.42760005593299866
rl training, epoch1, iter0, batch802/1133, batch loss:0.42760005593299866, Training time:27154.585646629333
batch reward last col mean 0.3208755552768707 first col mean 0.25476908683776855 all mean 0.256409615278244
0.43783605098724365 0.43783605098724365
rl training, epoch1, iter0, batch803/1133, batch loss:0.43783605098724365, Training time:27171.16806435585
batch reward last col mean 0.2511593699455261 first col mean 0.2465210109949112 all mean 0.24639645218849182
0.43336525559425354 0.43336525559425354
rl training, epoch1, iter0, batch804/1133, batch loss:0.43336525559425354, Training time:27188.24485397339
batch reward last col mean 0.23067651689052582 first col mean 0.2453421801328659 all mean 0.24507951736450195
0.42751452326774597 0.42751452326774597
rl training, epoch1, iter0, batch805/1133, batch loss:0.42751452326774597, Training time:27205.156270742416
batch reward last col mean 0.25852376222610474 first col mean 0.25908780097961426 all mean 0.27521175146102905
0.47469255328178406 0.47469255328178406
rl training, epoch1, iter0, batch806/1133, batch loss:0.47469255328178406, Training time:27222.795731306076
batch reward last col mean 0.30337297916412354 first col mean 0.2526291608810425 all mean 0.26805514097213745
0.46784070134162903 0.46784070134162903
rl training, epoch1, iter0, batch807/1133, batch loss:0.46784070134162903, Training time:27240.285147428513
batch reward last col mean 0.2668295204639435 first col mean 0.2852722704410553 all mean 0.27888354659080505
0.49689775705337524 0.49689775705337524
rl training, epoch1, iter0, batch808/1133, batch loss:0.49689775705337524, Training time:27258.506806373596
batch reward last col mean 0.35513734817504883 first col mean 0.3075791597366333 all mean 0.3255878686904907
0.5817376971244812 0.5817376971244812
rl training, epoch1, iter0, batch809/1133, batch loss:0.5817376971244812, Training time:27276.98175239563
batch reward last col mean 0.32970812916755676 first col mean 0.3311194181442261 all mean 0.3083933889865875
0.5424147844314575 0.5424147844314575
rl training, epoch1, iter0, batch810/1133, batch loss:0.5424147844314575, Training time:27296.28938269615
batch reward last col mean 0.3142164647579193 first col mean 0.3336236774921417 all mean 0.3027783930301666
0.5605807304382324 0.5605807304382324
rl training, epoch1, iter0, batch811/1133, batch loss:0.5605807304382324, Training time:27312.90883207321
batch reward last col mean 0.2992294430732727 first col mean 0.3279889225959778 all mean 0.33419474959373474
0.6054317951202393 0.6054317355155945
rl training, epoch1, iter0, batch812/1133, batch loss:0.6054317355155945, Training time:27329.688230276108
batch reward last col mean 0.28645676374435425 first col mean 0.3558236360549927 all mean 0.33747154474258423
0.5943053364753723 0.5943053364753723
rl training, epoch1, iter0, batch813/1133, batch loss:0.5943053364753723, Training time:27346.633556365967
batch reward last col mean 0.32046806812286377 first col mean 0.3352993428707123 all mean 0.33357638120651245
0.5846221446990967 0.5846221446990967
rl training, epoch1, iter0, batch814/1133, batch loss:0.5846221446990967, Training time:27363.03006029129
batch reward last col mean 0.3296624720096588 first col mean 0.3114505708217621 all mean 0.3334260880947113
0.5950844287872314 0.5950844287872314
rl training, epoch1, iter0, batch815/1133, batch loss:0.5950844287872314, Training time:27379.63845705986
batch reward last col mean 0.34285688400268555 first col mean 0.3584586977958679 all mean 0.3465307652950287
0.6445518136024475 0.6445518136024475
rl training, epoch1, iter0, batch816/1133, batch loss:0.6445518136024475, Training time:27396.301859378815
batch reward last col mean 0.41465097665786743 first col mean 0.37637412548065186 all mean 0.38109979033470154
0.6967854499816895 0.6967854499816895
rl training, epoch1, iter0, batch817/1133, batch loss:0.6967854499816895, Training time:27412.802523851395
batch reward last col mean 0.33009085059165955 first col mean 0.37048935890197754 all mean 0.3335808515548706
0.6208723187446594 0.6208723187446594
rl training, epoch1, iter0, batch818/1133, batch loss:0.6208723187446594, Training time:27429.474225521088
batch reward last col mean 0.40474507212638855 first col mean 0.3621928095817566 all mean 0.3605925440788269
0.6731359362602234 0.6731359362602234
rl training, epoch1, iter0, batch819/1133, batch loss:0.6731359362602234, Training time:27446.530932426453
batch reward last col mean 0.38768431544303894 first col mean 0.3924662172794342 all mean 0.3934154808521271
0.7524646520614624 0.752464771270752
rl training, epoch1, iter0, batch820/1133, batch loss:0.752464771270752, Training time:27463.042379140854
batch reward last col mean 0.4148862957954407 first col mean 0.43619847297668457 all mean 0.40340688824653625
0.7983732223510742 0.798373281955719
rl training, epoch1, iter0, batch821/1133, batch loss:0.798373281955719, Training time:27479.9586622715
batch reward last col mean 0.4054373502731323 first col mean 0.4305824339389801 all mean 0.43157219886779785
0.8506281971931458 0.8506281971931458
rl training, epoch1, iter0, batch822/1133, batch loss:0.8506281971931458, Training time:27497.332973718643
batch reward last col mean 0.42609626054763794 first col mean 0.4528876543045044 all mean 0.44451627135276794
0.8538497686386108 0.8538497686386108
rl training, epoch1, iter0, batch823/1133, batch loss:0.8538497686386108, Training time:27513.775506973267
batch reward last col mean 0.406184583902359 first col mean 0.4298866391181946 all mean 0.4295521676540375
0.8798461556434631 0.8798461556434631
rl training, epoch1, iter0, batch824/1133, batch loss:0.8798461556434631, Training time:27530.354749441147
batch reward last col mean 0.43350768089294434 first col mean 0.4393981397151947 all mean 0.42979586124420166
0.8800430297851562 0.8800430297851562
rl training, epoch1, iter0, batch825/1133, batch loss:0.8800430297851562, Training time:27548.667958498
batch reward last col mean 0.46781861782073975 first col mean 0.4897057116031647 all mean 0.45191293954849243
0.9549487233161926 0.9549486041069031
rl training, epoch1, iter0, batch826/1133, batch loss:0.9549486041069031, Training time:27565.490822553635
batch reward last col mean 0.5031770467758179 first col mean 0.5006060600280762 all mean 0.46564939618110657
0.9761461615562439 0.9761461615562439
rl training, epoch1, iter0, batch827/1133, batch loss:0.9761461615562439, Training time:27583.852691173553
batch reward last col mean 0.4706033766269684 first col mean 0.43544626235961914 all mean 0.45523783564567566
0.9758702516555786 0.9758702516555786
rl training, epoch1, iter0, batch828/1133, batch loss:0.9758702516555786, Training time:27601.19492459297
batch reward last col mean 0.44224947690963745 first col mean 0.44835346937179565 all mean 0.4636559784412384
1.0170413255691528 1.0170413255691528
rl training, epoch1, iter0, batch829/1133, batch loss:1.0170413255691528, Training time:27619.18978023529
batch reward last col mean 0.45792752504348755 first col mean 0.4746459722518921 all mean 0.45714789628982544
1.0128321647644043 1.0128321647644043
rl training, epoch1, iter0, batch830/1133, batch loss:1.0128321647644043, Training time:27635.97908782959
batch reward last col mean 0.4634980857372284 first col mean 0.48937875032424927 all mean 0.47714895009994507
1.1018344163894653 1.1018344163894653
rl training, epoch1, iter0, batch831/1133, batch loss:1.1018344163894653, Training time:27653.029364824295
batch reward last col mean 0.42983150482177734 first col mean 0.5199586153030396 all mean 0.5038313269615173
1.1403617858886719 1.1403617858886719
rl training, epoch1, iter0, batch832/1133, batch loss:1.1403617858886719, Training time:27670.06229186058
batch reward last col mean 0.4913761019706726 first col mean 0.48137274384498596 all mean 0.47651833295822144
1.0793612003326416 1.0793612003326416
rl training, epoch1, iter0, batch833/1133, batch loss:1.0793612003326416, Training time:27686.840656757355
batch reward last col mean 0.5098903775215149 first col mean 0.5168405175209045 all mean 0.5112322568893433
1.1889832019805908 1.1889832019805908
rl training, epoch1, iter0, batch834/1133, batch loss:1.1889832019805908, Training time:27703.671397924423
batch reward last col mean 0.4410266876220703 first col mean 0.5035409927368164 all mean 0.491091251373291
1.1661089658737183 1.1661089658737183
rl training, epoch1, iter0, batch835/1133, batch loss:1.1661089658737183, Training time:27720.463054418564
batch reward last col mean 0.541077733039856 first col mean 0.5169863700866699 all mean 0.5226650834083557
1.2232675552368164 1.2232675552368164
rl training, epoch1, iter0, batch836/1133, batch loss:1.2232675552368164, Training time:27737.44829583168
batch reward last col mean 0.4802224040031433 first col mean 0.5241908431053162 all mean 0.49856752157211304
1.2580528259277344 1.2580528259277344
rl training, epoch1, iter0, batch837/1133, batch loss:1.2580528259277344, Training time:27754.285588264465
batch reward last col mean 0.43996667861938477 first col mean 0.4822591543197632 all mean 0.4985775351524353
1.2550299167633057 1.2550299167633057
rl training, epoch1, iter0, batch838/1133, batch loss:1.2550299167633057, Training time:27770.80333662033
batch reward last col mean 0.4910261929035187 first col mean 0.5021936893463135 all mean 0.49615806341171265
1.2593607902526855 1.2593607902526855
rl training, epoch1, iter0, batch839/1133, batch loss:1.2593607902526855, Training time:27787.362871408463
batch reward last col mean 0.45632338523864746 first col mean 0.5243453979492188 all mean 0.5172740817070007
1.3677445650100708 1.3677445650100708
rl training, epoch1, iter0, batch840/1133, batch loss:1.3677445650100708, Training time:27804.345378160477
batch reward last col mean 0.49749869108200073 first col mean 0.5057593584060669 all mean 0.4792773723602295
1.3027822971343994 1.3027822971343994
rl training, epoch1, iter0, batch841/1133, batch loss:1.3027822971343994, Training time:27821.234959363937
batch reward last col mean 0.4643040597438812 first col mean 0.5252690315246582 all mean 0.4979105591773987
1.3780595064163208 1.3780595064163208
rl training, epoch1, iter0, batch842/1133, batch loss:1.3780595064163208, Training time:27838.66659092903
batch reward last col mean 0.5348690748214722 first col mean 0.5264276266098022 all mean 0.5263844728469849
1.4814153909683228 1.4814153909683228
rl training, epoch1, iter0, batch843/1133, batch loss:1.4814153909683228, Training time:27856.607194423676
batch reward last col mean 0.47405126690864563 first col mean 0.5463005900382996 all mean 0.5105404257774353
1.4310369491577148 1.4310369491577148
rl training, epoch1, iter0, batch844/1133, batch loss:1.4310369491577148, Training time:27874.461503505707
batch reward last col mean 0.5042952299118042 first col mean 0.531268835067749 all mean 0.5416536927223206
1.5076195001602173 1.5076195001602173
rl training, epoch1, iter0, batch845/1133, batch loss:1.5076195001602173, Training time:27893.847942113876
batch reward last col mean 0.5042119026184082 first col mean 0.53150475025177 all mean 0.549047589302063
1.5313326120376587 1.5313326120376587
rl training, epoch1, iter0, batch846/1133, batch loss:1.5313326120376587, Training time:27911.408276319504
batch reward last col mean 0.5541307926177979 first col mean 0.5619428753852844 all mean 0.5605601668357849
1.5533355474472046 1.5533355474472046
rl training, epoch1, iter0, batch847/1133, batch loss:1.5533355474472046, Training time:27928.044816970825
batch reward last col mean 0.5304186344146729 first col mean 0.5731624364852905 all mean 0.5803910493850708
1.6602617502212524 1.6602617502212524
rl training, epoch1, iter0, batch848/1133, batch loss:1.6602617502212524, Training time:27944.517753124237
batch reward last col mean 0.5676213502883911 first col mean 0.5688486695289612 all mean 0.5898616909980774
1.6816047430038452 1.6816049814224243
rl training, epoch1, iter0, batch849/1133, batch loss:1.6816049814224243, Training time:27960.886986017227
batch reward last col mean 0.5826345086097717 first col mean 0.6434024572372437 all mean 0.6103368997573853
1.7481063604354858 1.748106598854065
rl training, epoch1, iter0, batch850/1133, batch loss:1.748106598854065, Training time:27977.827288866043
batch reward last col mean 0.5650331974029541 first col mean 0.5695428848266602 all mean 0.582251250743866
1.6570385694503784 1.6570385694503784
rl training, epoch1, iter0, batch851/1133, batch loss:1.6570385694503784, Training time:27994.68109178543
batch reward last col mean 0.5682022571563721 first col mean 0.5442531108856201 all mean 0.5671157240867615
1.647752046585083 1.647752046585083
rl training, epoch1, iter0, batch852/1133, batch loss:1.647752046585083, Training time:28011.366949796677
batch reward last col mean 0.5392555594444275 first col mean 0.5912891626358032 all mean 0.5698567032814026
1.6731973886489868 1.6731973886489868
rl training, epoch1, iter0, batch853/1133, batch loss:1.6731973886489868, Training time:28027.979709625244
batch reward last col mean 0.6198422908782959 first col mean 0.586959958076477 all mean 0.5728185772895813
1.65282142162323 1.65282142162323
rl training, epoch1, iter0, batch854/1133, batch loss:1.65282142162323, Training time:28045.23673582077
batch reward last col mean 0.5683021545410156 first col mean 0.5913200378417969 all mean 0.5648943781852722
1.6199688911437988 1.6199688911437988
rl training, epoch1, iter0, batch855/1133, batch loss:1.6199688911437988, Training time:28062.3903632164
batch reward last col mean 0.5805942416191101 first col mean 0.5644963383674622 all mean 0.5676110982894897
1.64066481590271 1.64066481590271
rl training, epoch1, iter0, batch856/1133, batch loss:1.64066481590271, Training time:28079.004452466965
batch reward last col mean 0.6169610619544983 first col mean 0.5826987624168396 all mean 0.5913918614387512
1.6995209455490112 1.6995209455490112
rl training, epoch1, iter0, batch857/1133, batch loss:1.6995209455490112, Training time:28095.316213846207
batch reward last col mean 0.5925858020782471 first col mean 0.6250665783882141 all mean 0.6260421276092529
1.8036465644836426 1.8036465644836426
rl training, epoch1, iter0, batch858/1133, batch loss:1.8036465644836426, Training time:28112.90456533432
batch reward last col mean 0.5874015688896179 first col mean 0.5974489450454712 all mean 0.5873189568519592
1.7040488719940186 1.7040488719940186
rl training, epoch1, iter0, batch859/1133, batch loss:1.7040488719940186, Training time:28131.131319999695
batch reward last col mean 0.6194654107093811 first col mean 0.6173932552337646 all mean 0.6219727396965027
1.7995227575302124 1.7995227575302124
rl training, epoch1, iter0, batch860/1133, batch loss:1.7995227575302124, Training time:28150.18167757988
batch reward last col mean 0.6252413392066956 first col mean 0.6074100732803345 all mean 0.616801381111145
1.784275770187378 1.784275770187378
rl training, epoch1, iter0, batch861/1133, batch loss:1.784275770187378, Training time:28167.45699119568
batch reward last col mean 0.5610460638999939 first col mean 0.6183189749717712 all mean 0.596670389175415
1.7732380628585815 1.7732380628585815
rl training, epoch1, iter0, batch862/1133, batch loss:1.7732380628585815, Training time:28184.37456679344
batch reward last col mean 0.6188711524009705 first col mean 0.6241790056228638 all mean 0.6328425407409668
1.8619836568832397 1.8619836568832397
rl training, epoch1, iter0, batch863/1133, batch loss:1.8619836568832397, Training time:28200.87309384346
batch reward last col mean 0.6070046424865723 first col mean 0.6345851421356201 all mean 0.6175304651260376
1.8700833320617676 1.8700830936431885
rl training, epoch1, iter0, batch864/1133, batch loss:1.8700830936431885, Training time:28217.890908956528
batch reward last col mean 0.5540714859962463 first col mean 0.6204807162284851 all mean 0.5847194194793701
1.7764707803726196 1.7764707803726196
rl training, epoch1, iter0, batch865/1133, batch loss:1.7764707803726196, Training time:28234.57666158676
batch reward last col mean 0.5363185405731201 first col mean 0.5912209749221802 all mean 0.5802523493766785
1.8390135765075684 1.8390135765075684
rl training, epoch1, iter0, batch866/1133, batch loss:1.8390135765075684, Training time:28252.62810444832
batch reward last col mean 0.5864455103874207 first col mean 0.6365819573402405 all mean 0.6408889293670654
1.9866832494735718 1.9866832494735718
rl training, epoch1, iter0, batch867/1133, batch loss:1.9866832494735718, Training time:28272.295763254166
batch reward last col mean 0.51856529712677 first col mean 0.5679268836975098 all mean 0.6011934876441956
1.9212020635604858 1.9212020635604858
rl training, epoch1, iter0, batch868/1133, batch loss:1.9212020635604858, Training time:28290.927079200745
batch reward last col mean 0.5905630588531494 first col mean 0.6119266748428345 all mean 0.5767670273780823
1.9195303916931152 1.9195303916931152
rl training, epoch1, iter0, batch869/1133, batch loss:1.9195303916931152, Training time:28310.200811862946
batch reward last col mean 0.5565102100372314 first col mean 0.6058602333068848 all mean 0.5764647126197815
1.8777081966400146 1.8777081966400146
rl training, epoch1, iter0, batch870/1133, batch loss:1.8777081966400146, Training time:28328.09401702881
batch reward last col mean 0.5145780444145203 first col mean 0.5567073822021484 all mean 0.53441321849823
1.8141504526138306 1.8141504526138306
rl training, epoch1, iter0, batch871/1133, batch loss:1.8141504526138306, Training time:28344.7572555542
batch reward last col mean 0.60050368309021 first col mean 0.5946165323257446 all mean 0.6079570651054382
2.030794382095337 2.030794382095337
rl training, epoch1, iter0, batch872/1133, batch loss:2.030794382095337, Training time:28361.502820968628
batch reward last col mean 0.6454486846923828 first col mean 0.6041175723075867 all mean 0.6107917428016663
2.059028387069702 2.059028387069702
rl training, epoch1, iter0, batch873/1133, batch loss:2.059028387069702, Training time:28378.920878887177
batch reward last col mean 0.6049858331680298 first col mean 0.6471148729324341 all mean 0.6480002403259277
2.135129690170288 2.135129690170288
rl training, epoch1, iter0, batch874/1133, batch loss:2.135129690170288, Training time:28395.59698820114
batch reward last col mean 0.6071171760559082 first col mean 0.6472901105880737 all mean 0.6539787650108337
2.1228909492492676 2.1228909492492676
rl training, epoch1, iter0, batch875/1133, batch loss:2.1228909492492676, Training time:28412.156173229218
batch reward last col mean 0.6112498641014099 first col mean 0.6598992347717285 all mean 0.6451773047447205
2.125675678253174 2.125675678253174
rl training, epoch1, iter0, batch876/1133, batch loss:2.125675678253174, Training time:28428.864041805267
batch reward last col mean 0.6676465272903442 first col mean 0.7030348181724548 all mean 0.7050151824951172
2.2480645179748535 2.2480645179748535
rl training, epoch1, iter0, batch877/1133, batch loss:2.2480645179748535, Training time:28445.64897966385
batch reward last col mean 0.6716309785842896 first col mean 0.7229477167129517 all mean 0.7011205554008484
2.2118988037109375 2.2118988037109375
rl training, epoch1, iter0, batch878/1133, batch loss:2.2118988037109375, Training time:28462.248176574707
batch reward last col mean 0.6490591168403625 first col mean 0.7535712718963623 all mean 0.720451831817627
2.271803140640259 2.271803140640259
rl training, epoch1, iter0, batch879/1133, batch loss:2.271803140640259, Training time:28479.34504532814
batch reward last col mean 0.6871822476387024 first col mean 0.7329791784286499 all mean 0.7248278260231018
2.237379550933838 2.237379550933838
rl training, epoch1, iter0, batch880/1133, batch loss:2.237379550933838, Training time:28496.17995762825
batch reward last col mean 0.8000149726867676 first col mean 0.7383611798286438 all mean 0.7578331232070923
2.23818039894104 2.23818039894104
rl training, epoch1, iter0, batch881/1133, batch loss:2.23818039894104, Training time:28513.170850276947
batch reward last col mean 0.7199217081069946 first col mean 0.8032535314559937 all mean 0.774201512336731
2.235344648361206 2.235344648361206
rl training, epoch1, iter0, batch882/1133, batch loss:2.235344648361206, Training time:28531.45352458954
batch reward last col mean 0.7316194772720337 first col mean 0.7915704846382141 all mean 0.7908824682235718
2.255284547805786 2.255284547805786
rl training, epoch1, iter0, batch883/1133, batch loss:2.255284547805786, Training time:28549.536655664444
batch reward last col mean 0.7548923492431641 first col mean 0.8616880774497986 all mean 0.816930890083313
2.1967451572418213 2.1967451572418213
rl training, epoch1, iter0, batch884/1133, batch loss:2.1967451572418213, Training time:28567.48236298561
batch reward last col mean 0.8564924001693726 first col mean 0.8427387475967407 all mean 0.8443098068237305
2.2095870971679688 2.2095870971679688
rl training, epoch1, iter0, batch885/1133, batch loss:2.2095870971679688, Training time:28584.571496009827
batch reward last col mean 0.884425163269043 first col mean 0.8677129745483398 all mean 0.882762610912323
2.1910200119018555 2.1910202503204346
rl training, epoch1, iter0, batch886/1133, batch loss:2.1910202503204346, Training time:28603.730687379837
batch reward last col mean 0.9128786325454712 first col mean 0.8965272903442383 all mean 0.8929033875465393
2.134235382080078 2.134235382080078
rl training, epoch1, iter0, batch887/1133, batch loss:2.134235382080078, Training time:28620.23147916794
batch reward last col mean 0.8560475707054138 first col mean 0.9051773548126221 all mean 0.8993508815765381
2.0817151069641113 2.0817148685455322
rl training, epoch1, iter0, batch888/1133, batch loss:2.0817148685455322, Training time:28636.643456697464
batch reward last col mean 0.8871517181396484 first col mean 0.9033434391021729 all mean 0.8839903473854065
2.0187110900878906 2.0187110900878906
rl training, epoch1, iter0, batch889/1133, batch loss:2.0187110900878906, Training time:28653.294689893723
batch reward last col mean 0.9161239862442017 first col mean 0.9231552481651306 all mean 0.9106177091598511
1.9898030757904053 1.9898030757904053
rl training, epoch1, iter0, batch890/1133, batch loss:1.9898030757904053, Training time:28669.812064409256
batch reward last col mean 0.8922322392463684 first col mean 0.9007191061973572 all mean 0.9056662917137146
1.9646964073181152 1.9646964073181152
rl training, epoch1, iter0, batch891/1133, batch loss:1.9646964073181152, Training time:28686.345393180847
batch reward last col mean 0.9071977734565735 first col mean 0.9132311344146729 all mean 0.9118637442588806
1.9583359956741333 1.9583359956741333
rl training, epoch1, iter0, batch892/1133, batch loss:1.9583359956741333, Training time:28702.795461177826
batch reward last col mean 0.9180583953857422 first col mean 0.9250972867012024 all mean 0.9361201524734497
1.9319485425949097 1.9319485425949097
rl training, epoch1, iter0, batch893/1133, batch loss:1.9319485425949097, Training time:28719.32128095627
batch reward last col mean 0.8955652713775635 first col mean 0.9337604641914368 all mean 0.9211770296096802
1.8607428073883057 1.8607428073883057
rl training, epoch1, iter0, batch894/1133, batch loss:1.8607428073883057, Training time:28735.843131303787
batch reward last col mean 0.9387509226799011 first col mean 0.9365870952606201 all mean 0.9488338828086853
1.7241742610931396 1.72417414188385
rl training, epoch1, iter0, batch895/1133, batch loss:1.72417414188385, Training time:28752.40569281578
batch reward last col mean 0.953581690788269 first col mean 0.9465158581733704 all mean 0.9528146386146545
1.7032430171966553 1.7032430171966553
rl training, epoch1, iter0, batch896/1133, batch loss:1.7032430171966553, Training time:28769.56314444542
RL early break
rl training, epoch 1, iter 0, loss:0.15717757692981343, Training time:28769.568205595016 
rl epoch 1, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4586884606389587 Time: 135.89326739311218 s
loss of true 0.18904422228171144 loss of gen 0.009508204838519435 loss of other 0.2601360324819532 first score 0.9525904655456543
cur_epoch: 1
D Training Loss: 0.4352223647977016 Time: 136.3052613735199 s
loss of true 0.18041370384927777 loss of gen 0.0005736256043294016 loss of other 0.25423503536911846 first score 0.00022749105119146407
cur_epoch: 2
D Training Loss: 0.42786849134281896 Time: 136.86751079559326 s
loss of true 0.17624462439965485 loss of gen 0.0004826097692533732 loss of other 0.25114125676209803 first score 8.35588070913218e-06
cur_epoch: 3
D Training Loss: 0.4166644898959208 Time: 136.94158554077148 s
loss of true 0.17059407993454062 loss of gen 0.00048127777164754806 loss of other 0.2455891318362788 first score 2.612534217405482e-06
cur_epoch: 4
D Training Loss: 0.41186695851694666 Time: 137.36490559577942 s
loss of true 0.16876339202209162 loss of gen 0.0004737661184943683 loss of other 0.24262980022529324 first score 4.35569205592401e-07
rl epoch 2, begin RL for generator...
batch reward last col mean 3.0916548894310836e-06 first col mean 5.806437002320308e-07 all mean 4.844606519327499e-05
0.00015418441034853458 0.00015418441034853458
rl training, epoch2, iter0, batch0/1133, batch loss:0.00015418441034853458, Training time:29471.89125442505
batch reward last col mean 5.803073690913152e-06 first col mean 3.322690463392064e-05 all mean 2.481431329215411e-05
4.797107612830587e-05 4.797107612830587e-05
rl training, epoch2, iter0, batch1/1133, batch loss:4.797107612830587e-05, Training time:29488.536450386047
batch reward last col mean 2.711657089093933e-06 first col mean 2.084737570839934e-05 all mean 2.2819487639935687e-05
5.840415906277485e-05 5.8404166338732466e-05
rl training, epoch2, iter0, batch2/1133, batch loss:5.8404166338732466e-05, Training time:29506.647751569748
batch reward last col mean 1.0593981869533309e-06 first col mean 3.460404332145117e-05 all mean 4.5331304136198014e-05
8.374911703867838e-05 8.374911703867838e-05
rl training, epoch2, iter0, batch3/1133, batch loss:8.374911703867838e-05, Training time:29524.37554216385
batch reward last col mean 0.0006671322043985128 first col mean 1.5218676708173007e-05 all mean 0.0005722815403714776
6.57726195640862e-05 6.57726195640862e-05
rl training, epoch2, iter0, batch4/1133, batch loss:6.57726195640862e-05, Training time:29541.82928419113
batch reward last col mean 4.624768479288832e-08 first col mean 1.0499073255232361e-07 all mean 2.2894946596352383e-06
4.727886789623881e-06 4.727886789623881e-06
rl training, epoch2, iter0, batch5/1133, batch loss:4.727886789623881e-06, Training time:29558.3997130394
batch reward last col mean 0.00012154736032243818 first col mean 6.36428885627538e-05 all mean 0.00013236010272521526
3.601090793381445e-05 3.601090793381445e-05
rl training, epoch2, iter0, batch6/1133, batch loss:3.601090793381445e-05, Training time:29574.966960191727
batch reward last col mean 6.586794825125253e-07 first col mean 5.5711048219109216e-08 all mean 1.7304550055996515e-05
2.228728772024624e-05 2.2287289539235644e-05
rl training, epoch2, iter0, batch7/1133, batch loss:2.2287289539235644e-05, Training time:29591.54094004631
batch reward last col mean 3.9021102793412865e-08 first col mean 0.00034052826231345534 all mean 2.654269883350935e-05
3.148253745166585e-05 3.148253745166585e-05
rl training, epoch2, iter0, batch8/1133, batch loss:3.148253745166585e-05, Training time:29607.89980196953
batch reward last col mean 5.2970470676427794e-08 first col mean 4.544000375972246e-07 all mean 3.443425839577685e-06
1.1012396498699673e-05 1.1012396498699673e-05
rl training, epoch2, iter0, batch9/1133, batch loss:1.1012396498699673e-05, Training time:29625.00213289261
batch reward last col mean 1.6594865925867452e-08 first col mean 1.5924397303024307e-05 all mean 2.2546084437635727e-05
9.399289410794154e-05 9.399289410794154e-05
rl training, epoch2, iter0, batch10/1133, batch loss:9.399289410794154e-05, Training time:29642.04768538475
batch reward last col mean 3.0365178815827676e-08 first col mean 8.760418523934277e-08 all mean 3.692545215017162e-05
0.0002165400655940175 0.00021654003649018705
rl training, epoch2, iter0, batch11/1133, batch loss:0.00021654003649018705, Training time:29658.844454050064
batch reward last col mean 0.0015281040687114 first col mean 0.000252526777330786 all mean 0.0013779711443930864
0.00010970007861033082 0.00010970007861033082
rl training, epoch2, iter0, batch12/1133, batch loss:0.00010970007861033082, Training time:29675.658577680588
batch reward last col mean 8.023798159229045e-07 first col mean 0.0002398803480900824 all mean 3.998846750619123e-06
1.2354304317341303e-06 1.2354299769867794e-06
rl training, epoch2, iter0, batch13/1133, batch loss:1.2354299769867794e-06, Training time:29692.237608909607
batch reward last col mean 1.5953260401602165e-07 first col mean 1.4170088888931787e-06 all mean 2.2333751985570416e-05
2.6100618924829178e-05 2.610062074381858e-05
rl training, epoch2, iter0, batch14/1133, batch loss:2.610062074381858e-05, Training time:29709.04039001465
batch reward last col mean 2.436228783153638e-07 first col mean 4.361722312751226e-05 all mean 4.830818852497032e-06
1.2413339618433383e-06 1.2413330523486366e-06
rl training, epoch2, iter0, batch15/1133, batch loss:1.2413330523486366e-06, Training time:29725.60779953003
batch reward last col mean 5.092859737487743e-06 first col mean 2.737264594543376e-06 all mean 2.2153159079607576e-05
3.682090391521342e-05 3.6820911191171035e-05
rl training, epoch2, iter0, batch16/1133, batch loss:3.6820911191171035e-05, Training time:29742.209980726242
batch reward last col mean 4.515083219303051e-06 first col mean 8.64544854266569e-05 all mean 1.639296351640951e-05
8.57603590702638e-05 8.57603590702638e-05
rl training, epoch2, iter0, batch17/1133, batch loss:8.57603590702638e-05, Training time:29758.890008687973
batch reward last col mean 5.170105396246072e-06 first col mean 7.327635671572352e-07 all mean 1.3688981198356487e-05
5.313178917276673e-05 5.313178917276673e-05
rl training, epoch2, iter0, batch18/1133, batch loss:5.313178917276673e-05, Training time:29775.371621608734
batch reward last col mean 1.6427149773790006e-07 first col mean 2.1510438728000736e-06 all mean 2.141589720849879e-05
7.266698230523616e-05 7.266698230523616e-05
rl training, epoch2, iter0, batch19/1133, batch loss:7.266698230523616e-05, Training time:29792.567247629166
batch reward last col mean 0.0002421894168946892 first col mean 3.6828073461947497e-06 all mean 2.493367537681479e-05
2.800163383653853e-05 2.800163383653853e-05
rl training, epoch2, iter0, batch20/1133, batch loss:2.800163383653853e-05, Training time:29810.632086992264
batch reward last col mean 6.829254051154976e-09 first col mean 7.717097183501664e-09 all mean 4.7476434701820835e-05
0.00015129137318581343 0.00015129137318581343
rl training, epoch2, iter0, batch21/1133, batch loss:0.00015129137318581343, Training time:29829.033420562744
batch reward last col mean 7.643806020496413e-05 first col mean 2.1420632378976734e-07 all mean 7.445149822160602e-05
2.8122638468630612e-05 2.812263664964121e-05
rl training, epoch2, iter0, batch22/1133, batch loss:2.812263664964121e-05, Training time:29847.30334544182
batch reward last col mean 0.001124673173762858 first col mean 7.310147339012474e-05 all mean 0.0008692699484527111
0.00010943409142782912 0.00010943407687591389
rl training, epoch2, iter0, batch23/1133, batch loss:0.00010943407687591389, Training time:29864.76347708702
batch reward last col mean 4.929324504132637e-08 first col mean 1.7665980678316373e-08 all mean 2.246458643639926e-05
3.3754928153939545e-05 3.375493179191835e-05
rl training, epoch2, iter0, batch24/1133, batch loss:3.375493179191835e-05, Training time:29882.08543920517
batch reward last col mean 8.66173309077567e-07 first col mean 4.4983994484937284e-07 all mean 1.0983630090777297e-05
2.2965217794990167e-05 2.296521961397957e-05
rl training, epoch2, iter0, batch25/1133, batch loss:2.296521961397957e-05, Training time:29899.6305038929
batch reward last col mean 1.0268752248521196e-07 first col mean 4.509664904617239e-06 all mean 6.626142749155406e-06
1.3656272130901925e-05 1.3656271221407223e-05
rl training, epoch2, iter0, batch26/1133, batch loss:1.3656271221407223e-05, Training time:29916.362838983536
batch reward last col mean 2.895329309637873e-08 first col mean 2.0140706169513578e-07 all mean 9.808590220927726e-06
2.0826169929932803e-05 2.0826166291953996e-05
rl training, epoch2, iter0, batch27/1133, batch loss:2.0826166291953996e-05, Training time:29932.954874038696
batch reward last col mean 2.1973907138317372e-08 first col mean 9.367931852466427e-06 all mean 1.664356932451483e-05
0.00012413554941304028 0.00012413554941304028
rl training, epoch2, iter0, batch28/1133, batch loss:0.00012413554941304028, Training time:29950.358399152756
batch reward last col mean 7.462967914761975e-05 first col mean 3.6264691516407765e-07 all mean 8.443769183941185e-05
8.08750992291607e-05 8.087511378107592e-05
rl training, epoch2, iter0, batch29/1133, batch loss:8.087511378107592e-05, Training time:29966.94558262825
batch reward last col mean 5.493336985296082e-08 first col mean 1.837630776435617e-07 all mean 1.1548864904398215e-06
1.9971657820860855e-06 1.9971657820860855e-06
rl training, epoch2, iter0, batch30/1133, batch loss:1.9971657820860855e-06, Training time:29983.547693014145
batch reward last col mean 4.364392509614845e-07 first col mean 0.0008143351878970861 all mean 9.311257599620149e-06
6.6279826569370925e-06 6.627981747442391e-06
rl training, epoch2, iter0, batch31/1133, batch loss:6.627981747442391e-06, Training time:30000.223405361176
batch reward last col mean 4.350249867002276e-07 first col mean 1.2600998161360621e-05 all mean 3.475634457572596e-06
1.4000524970469996e-06 1.4000528381075128e-06
rl training, epoch2, iter0, batch32/1133, batch loss:1.4000528381075128e-06, Training time:30017.26040315628
batch reward last col mean 2.0013221728731878e-05 first col mean 4.198002727662242e-07 all mean 2.6388968763058074e-05
2.2012574845575728e-05 2.201257666456513e-05
rl training, epoch2, iter0, batch33/1133, batch loss:2.201257666456513e-05, Training time:30034.061697244644
batch reward last col mean 6.39397039776668e-05 first col mean 2.1664059204340447e-06 all mean 9.05164415598847e-05
8.608568168710917e-05 8.608567441115156e-05
rl training, epoch2, iter0, batch34/1133, batch loss:8.608567441115156e-05, Training time:30050.765715122223
batch reward last col mean 1.160418560175458e-05 first col mean 1.1791907127189916e-05 all mean 1.5555380741716363e-05
1.1582998013182078e-05 1.1582998013182078e-05
rl training, epoch2, iter0, batch35/1133, batch loss:1.1582998013182078e-05, Training time:30067.39757990837
batch reward last col mean 3.365986955827793e-08 first col mean 1.4853249012958258e-06 all mean 3.917947469744831e-05
0.00014589539205189794 0.00014589539205189794
rl training, epoch2, iter0, batch36/1133, batch loss:0.00014589539205189794, Training time:30086.40674352646
batch reward last col mean 2.5247854864574037e-05 first col mean 8.683604733050743e-07 all mean 2.6859272111323662e-05
5.077645710116485e-06 5.077645255369134e-06
rl training, epoch2, iter0, batch37/1133, batch loss:5.077645255369134e-06, Training time:30103.51615047455
batch reward last col mean 3.8753356079723744e-08 first col mean 8.090580195130315e-06 all mean 1.5491930753341876e-05
4.4994587369728833e-05 4.4994583731750026e-05
rl training, epoch2, iter0, batch38/1133, batch loss:4.4994583731750026e-05, Training time:30123.398156404495
batch reward last col mean 9.3753904195637e-08 first col mean 1.0325332766569773e-07 all mean 6.238562946236925e-06
8.075316486610973e-07 8.075315349742596e-07
rl training, epoch2, iter0, batch39/1133, batch loss:8.075315349742596e-07, Training time:30141.561077833176
batch reward last col mean 1.359456405225501e-07 first col mean 2.4947274468445357e-08 all mean 5.521480034076376e-06
8.960482773545664e-06 8.960483683040366e-06
rl training, epoch2, iter0, batch40/1133, batch loss:8.960483683040366e-06, Training time:30159.47117948532
batch reward last col mean 1.2723417341931054e-07 first col mean 0.000942180457059294 all mean 4.1566967411199585e-05
7.617397932335734e-05 7.617397204739973e-05
rl training, epoch2, iter0, batch41/1133, batch loss:7.617397204739973e-05, Training time:30176.233789920807
batch reward last col mean 1.3102852847168833e-07 first col mean 9.995478649216238e-07 all mean 3.3811120374593884e-05
1.6846286598592997e-05 1.68462884175824e-05
rl training, epoch2, iter0, batch42/1133, batch loss:1.68462884175824e-05, Training time:30192.806395292282
batch reward last col mean 8.497773151816546e-09 first col mean 4.545309906234252e-08 all mean 1.4406573427550029e-05
5.8698293287307024e-05 5.8698293287307024e-05
rl training, epoch2, iter0, batch43/1133, batch loss:5.8698293287307024e-05, Training time:30209.63819551468
batch reward last col mean 2.727117873746465e-07 first col mean 3.986144747614162e-06 all mean 2.999664729941287e-06
4.8984420573106036e-06 4.898442966805305e-06
rl training, epoch2, iter0, batch44/1133, batch loss:4.898442966805305e-06, Training time:30226.21265912056
batch reward last col mean 6.278174282670079e-07 first col mean 0.0005174109828658402 all mean 4.10218199249357e-05
0.0001750766532495618 0.0001750766532495618
rl training, epoch2, iter0, batch45/1133, batch loss:0.0001750766532495618, Training time:30243.599834680557
batch reward last col mean 7.585719004055136e-07 first col mean 0.001464997767470777 all mean 1.912628795253113e-05
1.2151671398896724e-05 1.215166412293911e-05
rl training, epoch2, iter0, batch46/1133, batch loss:1.215166412293911e-05, Training time:30260.02235841751
batch reward last col mean 0.0006453082896769047 first col mean 1.0200382121183793e-06 all mean 0.0005898888339288533
5.816021439386532e-05 5.816021439386532e-05
rl training, epoch2, iter0, batch47/1133, batch loss:5.816021439386532e-05, Training time:30276.514456272125
batch reward last col mean 6.891597195135546e-07 first col mean 5.904096838094119e-07 all mean 3.1821703032619553e-06
9.156331543636043e-06 9.156331543636043e-06
rl training, epoch2, iter0, batch48/1133, batch loss:9.156331543636043e-06, Training time:30293.23299384117
batch reward last col mean 2.2477827599232114e-08 first col mean 2.1923309759586118e-05 all mean 1.0780298680401756e-06
2.6639738734957064e-06 2.6639738734957064e-06
rl training, epoch2, iter0, batch49/1133, batch loss:2.6639738734957064e-06, Training time:30309.838571548462
batch reward last col mean 4.682377152676054e-08 first col mean 8.232221659909555e-08 all mean 1.2127738955314271e-05
2.823771683324594e-05 2.8237715014256537e-05
rl training, epoch2, iter0, batch50/1133, batch loss:2.8237715014256537e-05, Training time:30326.358358860016
batch reward last col mean 1.5869474623286806e-07 first col mean 1.433925547189574e-07 all mean 2.0881185264443047e-05
0.0001019841292873025 0.0001019841292873025
rl training, epoch2, iter0, batch51/1133, batch loss:0.0001019841292873025, Training time:30343.74379634857
batch reward last col mean 4.415927890022431e-08 first col mean 6.316140206763521e-05 all mean 2.6132996936212294e-05
9.47080334299244e-05 9.470802615396678e-05
rl training, epoch2, iter0, batch52/1133, batch loss:9.470802615396678e-05, Training time:30362.36251592636
batch reward last col mean 3.6905323241853694e-08 first col mean 7.013635894281833e-08 all mean 3.666496468213154e-06
2.218952658950002e-06 2.2189515220816247e-06
rl training, epoch2, iter0, batch53/1133, batch loss:2.2189515220816247e-06, Training time:30380.150594472885
batch reward last col mean 3.196274178662861e-07 first col mean 3.027886350537301e-07 all mean 4.139227257837774e-06
3.6086180443817284e-06 3.608617817008053e-06
rl training, epoch2, iter0, batch54/1133, batch loss:3.608617817008053e-06, Training time:30399.51112294197
batch reward last col mean 1.2228498214028605e-08 first col mean 6.928123497118577e-08 all mean 8.20253660549497e-07
1.7449428924010135e-06 1.7449428924010135e-06
rl training, epoch2, iter0, batch55/1133, batch loss:1.7449428924010135e-06, Training time:30417.738877296448
batch reward last col mean 2.4513132856895936e-08 first col mean 1.9008898561878596e-06 all mean 7.215409368654946e-06
1.6442694686702453e-05 1.6442694686702453e-05
rl training, epoch2, iter0, batch56/1133, batch loss:1.6442694686702453e-05, Training time:30436.083391189575
batch reward last col mean 3.100327035099326e-07 first col mean 0.0013086349936202168 all mean 3.10473442368675e-05
2.3281761968974024e-05 2.3281761968974024e-05
rl training, epoch2, iter0, batch57/1133, batch loss:2.3281761968974024e-05, Training time:30454.626972436905
batch reward last col mean 1.3479028382334945e-07 first col mean 2.9810485102643725e-07 all mean 2.750986141109024e-06
1.55196958075976e-05 1.55196958075976e-05
rl training, epoch2, iter0, batch58/1133, batch loss:1.55196958075976e-05, Training time:30471.149060487747
batch reward last col mean 3.872366505675018e-05 first col mean 2.961034442705568e-05 all mean 4.210619954392314e-05
3.743301203940064e-05 3.7433015677379444e-05
rl training, epoch2, iter0, batch59/1133, batch loss:3.7433015677379444e-05, Training time:30487.70944595337
batch reward last col mean 1.446976138907985e-08 first col mean 0.0008449970046058297 all mean 1.083079678210197e-05
7.118280791473808e-06 7.118283065210562e-06
rl training, epoch2, iter0, batch60/1133, batch loss:7.118283065210562e-06, Training time:30504.294137716293
batch reward last col mean 1.6672604630230126e-08 first col mean 0.0001975664490601048 all mean 7.945793186081573e-06
3.309786188765429e-05 3.309785824967548e-05
rl training, epoch2, iter0, batch61/1133, batch loss:3.309785824967548e-05, Training time:30520.96325778961
batch reward last col mean 1.9530974171289017e-08 first col mean 2.7862660090249847e-07 all mean 1.625133336347062e-05
4.222448114887811e-05 4.222448114887811e-05
rl training, epoch2, iter0, batch62/1133, batch loss:4.222448114887811e-05, Training time:30537.421269655228
batch reward last col mean 1.0387499749242579e-08 first col mean 2.662251858964737e-07 all mean 2.245139330625534e-05
0.00014080207620281726 0.00014080207620281726
rl training, epoch2, iter0, batch63/1133, batch loss:0.00014080207620281726, Training time:30554.75364780426
batch reward last col mean 8.72987993005836e-09 first col mean 0.0005198921426199377 all mean 1.0403807209513616e-05
1.9729843188542873e-05 1.972984136955347e-05
rl training, epoch2, iter0, batch64/1133, batch loss:1.972984136955347e-05, Training time:30571.738005399704
batch reward last col mean 4.458067337509419e-08 first col mean 0.0009688814170658588 all mean 1.2988959497306496e-05
7.409713361994363e-06 7.409718364215223e-06
rl training, epoch2, iter0, batch65/1133, batch loss:7.409718364215223e-06, Training time:30588.600482702255
batch reward last col mean 7.080654427227273e-07 first col mean 3.362749794177944e-07 all mean 1.9915260054403916e-06
6.566753199876985e-06 6.566753199876985e-06
rl training, epoch2, iter0, batch66/1133, batch loss:6.566753199876985e-06, Training time:30605.070561885834
batch reward last col mean 5.476071578414121e-07 first col mean 6.390185092186584e-08 all mean 2.365029104112182e-06
6.161059218356968e-07 6.161062060527911e-07
rl training, epoch2, iter0, batch67/1133, batch loss:6.161062060527911e-07, Training time:30621.829128026962
batch reward last col mean 7.891861741882167e-07 first col mean 4.155013044737643e-08 all mean 4.3202385313634295e-06
1.5682244338677265e-06 1.5682237517467001e-06
rl training, epoch2, iter0, batch68/1133, batch loss:1.5682237517467001e-06, Training time:30638.523174762726
batch reward last col mean 5.427099677035585e-05 first col mean 5.884601705474779e-06 all mean 7.685767923248932e-05
0.00012223594239912927 0.00012223594239912927
rl training, epoch2, iter0, batch69/1133, batch loss:0.00012223594239912927, Training time:30655.694052696228
batch reward last col mean 3.3463697945990134e-06 first col mean 1.625832169338537e-06 all mean 3.440301725277095e-06
8.91668696567649e-06 8.91668696567649e-06
rl training, epoch2, iter0, batch70/1133, batch loss:8.91668696567649e-06, Training time:30672.20495915413
batch reward last col mean 4.008426549262367e-05 first col mean 8.371913651217255e-08 all mean 1.76173634827137e-05
3.813026341958903e-05 3.813026341958903e-05
rl training, epoch2, iter0, batch71/1133, batch loss:3.813026341958903e-05, Training time:30688.725328683853
batch reward last col mean 3.1836538028073846e-07 first col mean 1.2182143294126035e-08 all mean 9.21358514460735e-06
1.7325995713690645e-06 1.7325994576822268e-06
rl training, epoch2, iter0, batch72/1133, batch loss:1.7325994576822268e-06, Training time:30705.35028409958
batch reward last col mean 5.16649288329063e-06 first col mean 1.9021720731871028e-07 all mean 1.9568877178244293e-05
9.295999188907444e-05 9.295999916503206e-05
rl training, epoch2, iter0, batch73/1133, batch loss:9.295999916503206e-05, Training time:30721.96858716011
batch reward last col mean 1.579074933033553e-07 first col mean 5.685307087333058e-07 all mean 1.8840908069250872e-06
1.2959385458088946e-06 1.2959390005562454e-06
rl training, epoch2, iter0, batch74/1133, batch loss:1.2959390005562454e-06, Training time:30739.986986637115
batch reward last col mean 5.285516024855497e-09 first col mean 1.3260620107757859e-05 all mean 1.0397768164693844e-05
3.14062817778904e-05 3.14062817778904e-05
rl training, epoch2, iter0, batch75/1133, batch loss:3.14062817778904e-05, Training time:30758.94352388382
batch reward last col mean 4.08010282626492e-06 first col mean 3.303878202132182e-07 all mean 4.166999588051112e-06
1.4648145224782638e-05 1.4648145224782638e-05
rl training, epoch2, iter0, batch76/1133, batch loss:1.4648145224782638e-05, Training time:30777.387370347977
batch reward last col mean 5.625942662845773e-07 first col mean 5.858304348294041e-07 all mean 1.4272131920733955e-05
2.8203477995702997e-05 2.82034798146924e-05
rl training, epoch2, iter0, batch77/1133, batch loss:2.82034798146924e-05, Training time:30795.561842918396
batch reward last col mean 0.003361338982358575 first col mean 6.253022775126738e-07 all mean 0.002585173351690173
0.0002747000544331968 0.0002747000544331968
rl training, epoch2, iter0, batch78/1133, batch loss:0.0002747000544331968, Training time:30814.13519835472
batch reward last col mean 1.4462071540322086e-08 first col mean 1.1757134643630707e-07 all mean 1.3258492799650412e-05
1.943993629538454e-05 1.9439934476395138e-05
rl training, epoch2, iter0, batch79/1133, batch loss:1.9439934476395138e-05, Training time:30832.246032238007
batch reward last col mean 0.0016135622281581163 first col mean 1.749574153109279e-06 all mean 0.001490900875069201
8.021404210012406e-05 8.021405665203929e-05
rl training, epoch2, iter0, batch80/1133, batch loss:8.021405665203929e-05, Training time:30848.77108693123
batch reward last col mean 3.403593495932e-07 first col mean 1.6968066120170988e-05 all mean 1.0106671652465593e-05
4.6778654905210715e-06 4.677862762036966e-06
rl training, epoch2, iter0, batch81/1133, batch loss:4.677862762036966e-06, Training time:30865.926351308823
batch reward last col mean 2.8896803172528962e-08 first col mean 7.656078651052667e-07 all mean 2.0178100385237485e-05
0.0001740460575092584 0.00017404602840542793
rl training, epoch2, iter0, batch82/1133, batch loss:0.00017404602840542793, Training time:30882.52012681961
batch reward last col mean 2.5233073301933473e-06 first col mean 5.1375437237766164e-08 all mean 6.518925147247501e-06
1.846226405177731e-05 1.846226405177731e-05
rl training, epoch2, iter0, batch83/1133, batch loss:1.846226405177731e-05, Training time:30899.03165960312
batch reward last col mean 5.7663946790853515e-06 first col mean 8.028530373849208e-08 all mean 6.248108547879383e-06
6.186150585563155e-06 6.186150585563155e-06
rl training, epoch2, iter0, batch84/1133, batch loss:6.186150585563155e-06, Training time:30915.94738316536
batch reward last col mean 8.998245704106012e-09 first col mean 4.3581550812632486e-08 all mean 5.301355940900976e-07
1.208946628139529e-06 1.208946628139529e-06
rl training, epoch2, iter0, batch85/1133, batch loss:1.208946628139529e-06, Training time:30932.31587958336
batch reward last col mean 2.0172699066733912e-08 first col mean 3.6117771884391914e-08 all mean 1.3004046195419505e-05
5.646086356136948e-05 5.6460867199348286e-05
rl training, epoch2, iter0, batch86/1133, batch loss:5.6460867199348286e-05, Training time:30948.911900281906
batch reward last col mean 0.00013357990246731788 first col mean 2.0486535504460335e-05 all mean 0.0001281930017285049
3.534943607519381e-05 3.534943607519381e-05
rl training, epoch2, iter0, batch87/1133, batch loss:3.534943607519381e-05, Training time:30965.634808778763
batch reward last col mean 1.2976067409908865e-05 first col mean 1.5609931125482035e-08 all mean 1.261405850527808e-05
4.108466782781761e-06 4.108466782781761e-06
rl training, epoch2, iter0, batch88/1133, batch loss:4.108466782781761e-06, Training time:30982.331846237183
batch reward last col mean 1.1046474668319206e-07 first col mean 3.744636245528454e-08 all mean 1.1487278243293986e-05
5.493271237355657e-05 5.493271237355657e-05
rl training, epoch2, iter0, batch89/1133, batch loss:5.493271237355657e-05, Training time:30998.983283042908
batch reward last col mean 3.6159985029371455e-05 first col mean 1.8376365318317767e-08 all mean 3.1612249586032704e-05
3.9074886444723234e-05 3.9074886444723234e-05
rl training, epoch2, iter0, batch90/1133, batch loss:3.9074886444723234e-05, Training time:31016.080878019333
batch reward last col mean 1.7024041198965278e-06 first col mean 3.885912519763224e-06 all mean 2.0876716462225886e-06
9.373502507514786e-06 9.373502507514786e-06
rl training, epoch2, iter0, batch91/1133, batch loss:9.373502507514786e-06, Training time:31034.08284664154
batch reward last col mean 8.703215144123533e-07 first col mean 0.00031182653037831187 all mean 4.929130682285177e-06
8.00833549874369e-06 8.00833549874369e-06
rl training, epoch2, iter0, batch92/1133, batch loss:8.00833549874369e-06, Training time:31052.51210832596
batch reward last col mean 1.568876371038641e-07 first col mean 1.6109530065477884e-07 all mean 8.014208106033038e-06
9.243603017239366e-06 9.243603926734067e-06
rl training, epoch2, iter0, batch93/1133, batch loss:9.243603926734067e-06, Training time:31072.079960346222
batch reward last col mean 3.7823816967375024e-08 first col mean 1.23551626529661e-05 all mean 5.671730377798667e-06
1.887696953417617e-06 1.8876976355386432e-06
rl training, epoch2, iter0, batch94/1133, batch loss:1.8876976355386432e-06, Training time:31090.899511814117
batch reward last col mean 2.34271393395602e-08 first col mean 8.092770542589278e-08 all mean 4.792626350536011e-05
0.00015024461026769131 0.00015024461026769131
rl training, epoch2, iter0, batch95/1133, batch loss:0.00015024461026769131, Training time:31107.9137301445
batch reward last col mean 5.309948960530164e-07 first col mean 3.3967844501603395e-05 all mean 1.2696888916252647e-05
2.4457680410705507e-05 2.4457685867673717e-05
rl training, epoch2, iter0, batch96/1133, batch loss:2.4457685867673717e-05, Training time:31124.41545033455
batch reward last col mean 1.065678247869073e-07 first col mean 1.5091047316673212e-05 all mean 2.1950721929897554e-05
1.0542178642936051e-05 1.0542178642936051e-05
rl training, epoch2, iter0, batch97/1133, batch loss:1.0542178642936051e-05, Training time:31141.30410671234
batch reward last col mean 1.7467911675339565e-05 first col mean 0.00011870497110066935 all mean 2.4696477339603007e-05
3.238879071432166e-05 3.238878707634285e-05
rl training, epoch2, iter0, batch98/1133, batch loss:3.238878707634285e-05, Training time:31158.1700527668
batch reward last col mean 7.461300128852599e-07 first col mean 8.751448149268981e-06 all mean 4.101106696907664e-06
9.08270067156991e-06 9.08270067156991e-06
rl training, epoch2, iter0, batch99/1133, batch loss:9.08270067156991e-06, Training time:31174.747777938843
batch reward last col mean 2.0940555600645894e-07 first col mean 7.908893167041242e-05 all mean 8.307974894705694e-06
3.4384367609163746e-05 3.438436397118494e-05
rl training, epoch2, iter0, batch100/1133, batch loss:3.438436397118494e-05, Training time:31191.37913966179
batch reward last col mean 1.5855857071755963e-08 first col mean 0.0016816835850477219 all mean 2.2836600692244247e-05
3.275366179877892e-05 3.275365452282131e-05
rl training, epoch2, iter0, batch101/1133, batch loss:3.275365452282131e-05, Training time:31207.95116329193
batch reward last col mean 0.0001165938374469988 first col mean 3.063982489948103e-07 all mean 0.00011645041377050802
6.338215462164953e-05 6.338215462164953e-05
rl training, epoch2, iter0, batch102/1133, batch loss:6.338215462164953e-05, Training time:31224.547011375427
batch reward last col mean 7.052282313679825e-09 first col mean 6.611759317820542e-08 all mean 4.472023192647612e-06
7.080879186105449e-06 7.0808796408528e-06
rl training, epoch2, iter0, batch103/1133, batch loss:7.0808796408528e-06, Training time:31241.055822134018
batch reward last col mean 1.474369781817586e-08 first col mean 1.2821065098478357e-08 all mean 3.5851173834089423e-06
7.466170700354269e-06 7.466170700354269e-06
rl training, epoch2, iter0, batch104/1133, batch loss:7.466170700354269e-06, Training time:31258.43993449211
batch reward last col mean 7.205198215842756e-09 first col mean 0.00010259677947033197 all mean 2.3210881408886053e-05
0.00010324456525268033 0.0001032445507007651
rl training, epoch2, iter0, batch105/1133, batch loss:0.0001032445507007651, Training time:31276.05630159378
batch reward last col mean 1.7802893381713147e-08 first col mean 3.349412338593538e-07 all mean 2.4011612822505413e-06
5.8443224588700105e-06 5.8443224588700105e-06
rl training, epoch2, iter0, batch106/1133, batch loss:5.8443224588700105e-06, Training time:31295.284405708313
batch reward last col mean 2.329566228809199e-08 first col mean 6.6304632895253235e-09 all mean 1.2441043963917764e-06
1.013606720334792e-06 1.013606720334792e-06
rl training, epoch2, iter0, batch107/1133, batch loss:1.013606720334792e-06, Training time:31314.336416482925
batch reward last col mean 2.0300761605085427e-07 first col mean 2.8715435362869357e-08 all mean 1.2874870662926696e-06
9.709063306218013e-06 9.709062396723311e-06
rl training, epoch2, iter0, batch108/1133, batch loss:9.709062396723311e-06, Training time:31333.032711029053
batch reward last col mean 5.258068647151504e-09 first col mean 9.84614132448769e-08 all mean 4.7113817345234565e-06
8.379836799576879e-06 8.379834980587475e-06
rl training, epoch2, iter0, batch109/1133, batch loss:8.379834980587475e-06, Training time:31350.22750353813
batch reward last col mean 1.7515978925075615e-06 first col mean 2.1500271429886197e-07 all mean 3.2016855584515724e-06
3.68703967978945e-06 3.6870399071631255e-06
rl training, epoch2, iter0, batch110/1133, batch loss:3.6870399071631255e-06, Training time:31366.86852645874
batch reward last col mean 0.0016998174833133817 first col mean 0.001881949370726943 all mean 0.001626108423806727
0.00032607384491711855 0.00032607384491711855
rl training, epoch2, iter0, batch111/1133, batch loss:0.00032607384491711855, Training time:31383.37738609314
batch reward last col mean 4.194301794768762e-08 first col mean 0.00016162137035280466 all mean 2.9445468499034178e-06
3.2178679703065427e-06 3.217868652427569e-06
rl training, epoch2, iter0, batch112/1133, batch loss:3.217868652427569e-06, Training time:31400.251128196716
batch reward last col mean 6.965755119381356e-07 first col mean 1.450705099159677e-06 all mean 3.510367378112278e-06
1.6606818462605588e-05 1.660681482462678e-05
rl training, epoch2, iter0, batch113/1133, batch loss:1.660681482462678e-05, Training time:31417.037461042404
batch reward last col mean 0.0012587131932377815 first col mean 6.722369789713412e-07 all mean 0.0011854702606797218
0.00010532655142014846 0.00010532655142014846
rl training, epoch2, iter0, batch114/1133, batch loss:0.00010532655142014846, Training time:31434.438869953156
batch reward last col mean 5.0144244596594945e-06 first col mean 4.322062920891767e-07 all mean 6.515631866932381e-06
5.596620667347452e-06 5.596620212600101e-06
rl training, epoch2, iter0, batch115/1133, batch loss:5.596620212600101e-06, Training time:31450.969767332077
batch reward last col mean 1.3385938473220449e-05 first col mean 2.533212750677194e-08 all mean 1.7575213860254735e-05
1.0509467756492086e-05 1.0509468665986788e-05
rl training, epoch2, iter0, batch116/1133, batch loss:1.0509468665986788e-05, Training time:31467.702658891678
batch reward last col mean 1.2843246395277674e-06 first col mean 1.1684643475007306e-08 all mean 1.866502861957997e-05
0.00011811898002633825 0.00011811898002633825
rl training, epoch2, iter0, batch117/1133, batch loss:0.00011811898002633825, Training time:31484.164311408997
batch reward last col mean 9.867184189715772e-07 first col mean 5.046896330895834e-05 all mean 9.09063146536937e-06
1.104865350498585e-05 1.1048656233469956e-05
rl training, epoch2, iter0, batch118/1133, batch loss:1.1048656233469956e-05, Training time:31500.778975248337
batch reward last col mean 4.529496422378543e-08 first col mean 1.993658571564083e-08 all mean 6.776537702535279e-06
2.277418161611422e-06 2.2774199806008255e-06
rl training, epoch2, iter0, batch119/1133, batch loss:2.2774199806008255e-06, Training time:31517.231891155243
batch reward last col mean 8.868827450214667e-08 first col mean 2.4693536033737473e-06 all mean 5.058404894953128e-06
2.3724664060864598e-05 2.3724664060864598e-05
rl training, epoch2, iter0, batch120/1133, batch loss:2.3724664060864598e-05, Training time:31535.175849437714
batch reward last col mean 4.384714429761516e-06 first col mean 1.0312558060832089e-06 all mean 2.6254749172949232e-05
2.4088127247523516e-05 2.4088127247523516e-05
rl training, epoch2, iter0, batch121/1133, batch loss:2.4088127247523516e-05, Training time:31552.491996526718
batch reward last col mean 4.8932583013083786e-05 first col mean 9.444480383535847e-06 all mean 2.193152340623783e-06
8.98893631529063e-06 8.988935405795928e-06
rl training, epoch2, iter0, batch122/1133, batch loss:8.988935405795928e-06, Training time:31570.325038194656
batch reward last col mean 0.002455988200381398 first col mean 0.0016154570039361715 all mean 0.002328818431124091
0.0002172901586163789 0.0002172901586163789
rl training, epoch2, iter0, batch123/1133, batch loss:0.0002172901586163789, Training time:31586.77257823944
batch reward last col mean 9.280522306198691e-08 first col mean 1.6564670659136027e-05 all mean 2.445643985993229e-06
2.4545647647755686e-06 2.4545647647755686e-06
rl training, epoch2, iter0, batch124/1133, batch loss:2.4545647647755686e-06, Training time:31604.661606311798
batch reward last col mean 4.98155685590973e-08 first col mean 1.9908095794107794e-07 all mean 4.178842937108129e-05
0.00012863741721957922 0.000128637402667664
rl training, epoch2, iter0, batch125/1133, batch loss:0.000128637402667664, Training time:31621.401505708694
batch reward last col mean 1.2396914428336459e-07 first col mean 5.38800213689683e-06 all mean 2.2627289126830874e-06
6.1549544625449926e-06 6.1549544625449926e-06
rl training, epoch2, iter0, batch126/1133, batch loss:6.1549544625449926e-06, Training time:31637.928189516068
batch reward last col mean 3.332077938011935e-07 first col mean 3.158781680667744e-08 all mean 6.9626953518309165e-06
4.7908648411976174e-05 4.7908648411976174e-05
rl training, epoch2, iter0, batch127/1133, batch loss:4.7908648411976174e-05, Training time:31654.58746933937
batch reward last col mean 2.4075140103718695e-08 first col mean 1.0083110737468814e-06 all mean 1.5258191524480935e-05
3.8387115637306124e-05 3.838711199932732e-05
rl training, epoch2, iter0, batch128/1133, batch loss:3.838711199932732e-05, Training time:31671.58060669899
batch reward last col mean 1.0393058857971482e-08 first col mean 6.1972468756721355e-06 all mean 5.825097105116583e-06
1.4361379498950555e-06 1.4361394278239459e-06
rl training, epoch2, iter0, batch129/1133, batch loss:1.4361394278239459e-06, Training time:31689.194308280945
batch reward last col mean 9.369276199322485e-08 first col mean 1.5676272369091748e-07 all mean 1.571983921166975e-05
1.408755542797735e-05 1.4087551789998543e-05
rl training, epoch2, iter0, batch130/1133, batch loss:1.4087551789998543e-05, Training time:31708.383064746857
batch reward last col mean 1.5795072272339894e-07 first col mean 1.4447020468821847e-08 all mean 2.2498077669297345e-05
8.303349750349298e-05 8.303349750349298e-05
rl training, epoch2, iter0, batch131/1133, batch loss:8.303349750349298e-05, Training time:31726.983404159546
batch reward last col mean 1.8777554089410842e-07 first col mean 0.000121050383313559 all mean 1.6284478988382034e-05
3.622332224040292e-05 3.6223318602424115e-05
rl training, epoch2, iter0, batch132/1133, batch loss:3.6223318602424115e-05, Training time:31745.032256364822
batch reward last col mean 6.172744804189279e-08 first col mean 4.059134823819477e-07 all mean 3.0788648928137263e-06
1.0155543350265361e-05 1.015554244077066e-05
rl training, epoch2, iter0, batch133/1133, batch loss:1.015554244077066e-05, Training time:31761.96056175232
batch reward last col mean 3.6353821286638777e-08 first col mean 1.4573419093721895e-06 all mean 2.5915946935128886e-06
9.126124496106058e-06 9.12612540560076e-06
rl training, epoch2, iter0, batch134/1133, batch loss:9.12612540560076e-06, Training time:31778.44634127617
batch reward last col mean 2.0661548205680447e-07 first col mean 5.803897806799796e-07 all mean 9.340070391772315e-06
2.4164237402146682e-05 2.4164237402146682e-05
rl training, epoch2, iter0, batch135/1133, batch loss:2.4164237402146682e-05, Training time:31795.20657801628
batch reward last col mean 2.9349548640311696e-06 first col mean 8.448982407571748e-05 all mean 5.295098162605427e-06
2.477566340530757e-06 2.477566340530757e-06
rl training, epoch2, iter0, batch136/1133, batch loss:2.477566340530757e-06, Training time:31811.80758547783
batch reward last col mean 0.00010040005145128816 first col mean 1.9767437606788008e-06 all mean 0.00010136258788406849
2.212068284279667e-05 2.2120681023807265e-05
rl training, epoch2, iter0, batch137/1133, batch loss:2.2120681023807265e-05, Training time:31828.286989927292
batch reward last col mean 4.347450328623381e-07 first col mean 1.719856186355173e-07 all mean 3.4934600989799947e-05
0.00012976607831660658 0.00012976607831660658
rl training, epoch2, iter0, batch138/1133, batch loss:0.00012976607831660658, Training time:31844.998937368393
batch reward last col mean 2.1706451747149913e-08 first col mean 3.1872430099610938e-06 all mean 2.1157116862013936e-05
0.00012038189015584067 0.00012038189015584067
rl training, epoch2, iter0, batch139/1133, batch loss:0.00012038189015584067, Training time:31861.74091887474
batch reward last col mean 1.757659795487143e-08 first col mean 4.222001592779634e-08 all mean 6.576699433935573e-06
1.2222722943988629e-05 1.2222726581967436e-05
rl training, epoch2, iter0, batch140/1133, batch loss:1.2222726581967436e-05, Training time:31878.553698778152
batch reward last col mean 4.895311533914537e-08 first col mean 0.001711032004095614 all mean 1.762497595336754e-05
3.039728653675411e-06 3.0397211503441213e-06
rl training, epoch2, iter0, batch141/1133, batch loss:3.0397211503441213e-06, Training time:31895.102744579315
batch reward last col mean 1.0250861492977492e-07 first col mean 3.293254735581286e-07 all mean 2.581153057690244e-05
1.2313877959968522e-05 1.2313867046032101e-05
rl training, epoch2, iter0, batch142/1133, batch loss:1.2313867046032101e-05, Training time:31911.855872154236
batch reward last col mean 5.7904196992808465e-09 first col mean 4.8595136803442074e-08 all mean 6.705921350658173e-06
2.2436790459323674e-05 2.2436790459323674e-05
rl training, epoch2, iter0, batch143/1133, batch loss:2.2436790459323674e-05, Training time:31928.58355665207
batch reward last col mean 5.189353373680206e-07 first col mean 1.0897972060774919e-05 all mean 2.0562108602462104e-06
6.4660921452741604e-06 6.466092600021511e-06
rl training, epoch2, iter0, batch144/1133, batch loss:6.466092600021511e-06, Training time:31945.66793704033
batch reward last col mean 9.608132955918336e-08 first col mean 1.8026858583652938e-07 all mean 2.6379149858257733e-05
5.559833880397491e-05 5.559833880397491e-05
rl training, epoch2, iter0, batch145/1133, batch loss:5.559833880397491e-05, Training time:31962.083253860474
batch reward last col mean 4.331998752604704e-06 first col mean 0.0002713222347665578 all mean 4.9853297241497785e-06
5.899251846130937e-06 5.8992513913835865e-06
rl training, epoch2, iter0, batch146/1133, batch loss:5.8992513913835865e-06, Training time:31979.50923037529
batch reward last col mean 2.8443864721339196e-06 first col mean 2.996605132921104e-07 all mean 5.533451712835813e-06
1.1206419003428891e-05 1.120641809393419e-05
rl training, epoch2, iter0, batch147/1133, batch loss:1.120641809393419e-05, Training time:31997.10639309883
batch reward last col mean 5.752841616413207e-07 first col mean 2.7968827254198914e-08 all mean 3.3100573091360275e-06
3.551850795702194e-06 3.551850795702194e-06
rl training, epoch2, iter0, batch148/1133, batch loss:3.551850795702194e-06, Training time:32015.756212949753
batch reward last col mean 2.6294415533811843e-08 first col mean 5.353329584067978e-07 all mean 8.512462045473512e-06
9.045387741934974e-06 9.045386832440272e-06
rl training, epoch2, iter0, batch149/1133, batch loss:9.045386832440272e-06, Training time:32034.522804498672
batch reward last col mean 0.003850206732749939 first col mean 1.6689175197370787e-07 all mean 0.0036185767967253923
0.0002378731151111424 0.0002378731151111424
rl training, epoch2, iter0, batch150/1133, batch loss:0.0002378731151111424, Training time:32051.768724679947
batch reward last col mean 1.416664385800459e-08 first col mean 1.449683736609586e-06 all mean 1.8153968994738534e-06
7.136387466744054e-06 7.136387466744054e-06
rl training, epoch2, iter0, batch151/1133, batch loss:7.136387466744054e-06, Training time:32068.5323035717
batch reward last col mean 4.4856378167423827e-07 first col mean 9.18135754091054e-08 all mean 2.5974553864216432e-05
8.211547537939623e-06 8.211544809455518e-06
rl training, epoch2, iter0, batch152/1133, batch loss:8.211544809455518e-06, Training time:32085.035705566406
batch reward last col mean 1.5021116723801242e-06 first col mean 1.2575367691169959e-05 all mean 1.767464891599957e-05
4.071549847139977e-05 4.071549847139977e-05
rl training, epoch2, iter0, batch153/1133, batch loss:4.071549847139977e-05, Training time:32102.000324964523
batch reward last col mean 4.984352042214368e-09 first col mean 1.6887079254956916e-05 all mean 1.1582008482946549e-05
2.3659047656110488e-05 2.365904947509989e-05
rl training, epoch2, iter0, batch154/1133, batch loss:2.365904947509989e-05, Training time:32118.622869729996
batch reward last col mean 8.765424581724801e-07 first col mean 0.0008778990595601499 all mean 1.4196343727235217e-05
2.2537766199093312e-05 2.2537768018082716e-05
rl training, epoch2, iter0, batch155/1133, batch loss:2.2537768018082716e-05, Training time:32135.707919359207
batch reward last col mean 0.00035815659794025123 first col mean 1.8817121372194379e-06 all mean 0.0003158292092848569
9.267785935662687e-05 9.267785935662687e-05
rl training, epoch2, iter0, batch156/1133, batch loss:9.267785935662687e-05, Training time:32152.352048158646
batch reward last col mean 1.4215345345292008e-07 first col mean 4.573580625333307e-08 all mean 2.772954940155614e-05
3.896403359249234e-05 3.896403359249234e-05
rl training, epoch2, iter0, batch157/1133, batch loss:3.896403359249234e-05, Training time:32168.843106746674
batch reward last col mean 2.7737630716728745e-06 first col mean 5.2161199164402205e-06 all mean 8.104853804979939e-06
5.0334681873209774e-05 5.0334681873209774e-05
rl training, epoch2, iter0, batch158/1133, batch loss:5.0334681873209774e-05, Training time:32185.54889678955
batch reward last col mean 2.1067393390694633e-05 first col mean 0.00024607108207419515 all mean 2.5454697606619447e-05
8.649149094708264e-05 8.649149094708264e-05
rl training, epoch2, iter0, batch159/1133, batch loss:8.649149094708264e-05, Training time:32202.247722625732
batch reward last col mean 9.162776137827677e-08 first col mean 4.553207588742225e-08 all mean 9.338511517853476e-06
3.245439438614994e-05 3.245439438614994e-05
rl training, epoch2, iter0, batch160/1133, batch loss:3.245439438614994e-05, Training time:32219.479161977768
batch reward last col mean 3.126117235296988e-06 first col mean 1.854586173521966e-08 all mean 7.44622639103909e-06
1.0419859790999908e-05 1.0419859790999908e-05
rl training, epoch2, iter0, batch161/1133, batch loss:1.0419859790999908e-05, Training time:32236.56213569641
batch reward last col mean 9.543391854549554e-09 first col mean 2.9316154837033537e-08 all mean 6.5398457991250325e-06
6.422194473998388e-06 6.422195838240441e-06
rl training, epoch2, iter0, batch162/1133, batch loss:6.422195838240441e-06, Training time:32254.55252289772
batch reward last col mean 6.050315732863965e-07 first col mean 4.627365228770941e-07 all mean 1.6687052266206592e-05
2.790811595332343e-05 2.7908117772312835e-05
rl training, epoch2, iter0, batch163/1133, batch loss:2.7908117772312835e-05, Training time:32274.392184734344
batch reward last col mean 2.7902019610337447e-06 first col mean 6.549688578161295e-07 all mean 2.0116895029786974e-05
3.1172679882729426e-05 3.117267624475062e-05
rl training, epoch2, iter0, batch164/1133, batch loss:3.117267624475062e-05, Training time:32292.402944803238
batch reward last col mean 4.0758457942047244e-08 first col mean 6.48361435651168e-08 all mean 2.178973772970494e-06
5.60070839128457e-06 5.60070839128457e-06
rl training, epoch2, iter0, batch165/1133, batch loss:5.60070839128457e-06, Training time:32310.52054309845
batch reward last col mean 3.584376173648707e-08 first col mean 2.208887082133515e-07 all mean 3.4816032439266564e-06
7.149156772356946e-06 7.149155862862244e-06
rl training, epoch2, iter0, batch166/1133, batch loss:7.149155862862244e-06, Training time:32327.819291114807
batch reward last col mean 1.7129163097706623e-05 first col mean 1.6639331079204567e-05 all mean 1.7438451322959736e-05
3.387705874047242e-06 3.3877056466735667e-06
rl training, epoch2, iter0, batch167/1133, batch loss:3.3877056466735667e-06, Training time:32344.370184659958
batch reward last col mean 3.403653181521804e-07 first col mean 1.5633511907253705e-07 all mean 3.288502193754539e-05
0.00015444682503584772 0.0001544468104839325
rl training, epoch2, iter0, batch168/1133, batch loss:0.0001544468104839325, Training time:32361.154052972794
batch reward last col mean 4.328674549469724e-06 first col mean 2.9367827210080577e-06 all mean 2.529761695768684e-05
8.128891204250976e-05 8.128891931846738e-05
rl training, epoch2, iter0, batch169/1133, batch loss:8.128891931846738e-05, Training time:32377.65910744667
batch reward last col mean 3.463506459411292e-08 first col mean 1.1042026017094031e-05 all mean 1.2858502486778889e-05
9.84461948974058e-05 9.84461948974058e-05
rl training, epoch2, iter0, batch170/1133, batch loss:9.84461948974058e-05, Training time:32394.634199142456
batch reward last col mean 3.868640305881854e-07 first col mean 0.0005559680867008865 all mean 2.1688423657906242e-05
1.6849902749527246e-05 1.6849900930537842e-05
rl training, epoch2, iter0, batch171/1133, batch loss:1.6849900930537842e-05, Training time:32411.208935260773
batch reward last col mean 1.0765296565296012e-07 first col mean 4.378526625714585e-07 all mean 2.463346390868537e-05
7.414986612275243e-05 7.414985884679481e-05
rl training, epoch2, iter0, batch172/1133, batch loss:7.414985884679481e-05, Training time:32427.816331148148
batch reward last col mean 1.3634937090500898e-07 first col mean 2.077902117036956e-08 all mean 6.248660611163359e-06
2.082971332129091e-05 2.0829711502301507e-05
rl training, epoch2, iter0, batch173/1133, batch loss:2.0829711502301507e-05, Training time:32444.408887386322
batch reward last col mean 1.4764013656076713e-07 first col mean 4.551998063107021e-05 all mean 1.8311569874640554e-05
7.174581696745008e-05 7.174581696745008e-05
rl training, epoch2, iter0, batch174/1133, batch loss:7.174581696745008e-05, Training time:32460.991527557373
batch reward last col mean 5.79413530488182e-08 first col mean 6.467993898695568e-06 all mean 6.74372222420061e-06
2.7550384402275085e-05 2.7550384402275085e-05
rl training, epoch2, iter0, batch175/1133, batch loss:2.7550384402275085e-05, Training time:32477.50287914276
batch reward last col mean 1.604366843821481e-05 first col mean 1.4227225619833916e-07 all mean 1.4784164704906289e-05
6.400126949301921e-06 6.400125130312517e-06
rl training, epoch2, iter0, batch176/1133, batch loss:6.400125130312517e-06, Training time:32494.205473423004
batch reward last col mean 7.263426232384518e-05 first col mean 8.493636727280318e-08 all mean 8.799758506938815e-05
0.00011082489072578028 0.00011082490527769551
rl training, epoch2, iter0, batch177/1133, batch loss:0.00011082490527769551, Training time:32512.051951408386
batch reward last col mean 3.07707836100235e-07 first col mean 2.0878429651816077e-08 all mean 1.7655536794336513e-05
6.510350067401305e-05 6.510350067401305e-05
rl training, epoch2, iter0, batch178/1133, batch loss:6.510350067401305e-05, Training time:32531.623873233795
batch reward last col mean 5.8875855302176205e-08 first col mean 2.1898593331570737e-05 all mean 1.0656619451765437e-05
1.131233261730813e-06 1.1312366723359446e-06
rl training, epoch2, iter0, batch179/1133, batch loss:1.1312366723359446e-06, Training time:32549.273331165314
batch reward last col mean 2.757503125394578e-06 first col mean 8.452369911537971e-06 all mean 1.1793005796789657e-05
2.8667661808867706e-06 2.8667654987657443e-06
rl training, epoch2, iter0, batch180/1133, batch loss:2.8667654987657443e-06, Training time:32567.93276119232
batch reward last col mean 1.849352671001725e-08 first col mean 5.994443199597299e-07 all mean 1.2056094647050486e-06
5.29535498117184e-07 5.295357254908595e-07
rl training, epoch2, iter0, batch181/1133, batch loss:5.295357254908595e-07, Training time:32587.346648931503
batch reward last col mean 0.0006917309947311878 first col mean 2.435128898525818e-08 all mean 0.0006205753888934851
4.519510912359692e-05 4.5195105485618114e-05
rl training, epoch2, iter0, batch182/1133, batch loss:4.5195105485618114e-05, Training time:32604.663076400757
batch reward last col mean 1.1185555592874152e-08 first col mean 0.0011722692288458347 all mean 1.2951055396115407e-05
7.354327863140497e-06 7.35432922738255e-06
rl training, epoch2, iter0, batch183/1133, batch loss:7.35432922738255e-06, Training time:32622.13141489029
batch reward last col mean 1.6462932350691517e-08 first col mean 3.8040170124986616e-08 all mean 4.725077360490104e-06
1.0313250641047489e-05 1.0313249731552787e-05
rl training, epoch2, iter0, batch184/1133, batch loss:1.0313249731552787e-05, Training time:32639.830911636353
batch reward last col mean 1.1313762371401026e-08 first col mean 4.5931622594252985e-07 all mean 7.7884214988444e-07
1.2877115977971698e-06 1.287711938857683e-06
rl training, epoch2, iter0, batch185/1133, batch loss:1.287711938857683e-06, Training time:32657.291969537735
batch reward last col mean 3.945212370126683e-07 first col mean 2.6411672848780654e-08 all mean 2.1023412045906298e-05
0.00016224822320509702 0.0001622482086531818
rl training, epoch2, iter0, batch186/1133, batch loss:0.0001622482086531818, Training time:32674.510874271393
batch reward last col mean 5.410169023889466e-08 first col mean 9.78274238150334e-06 all mean 1.3296869383339072e-06
2.892315933422651e-06 2.892316388170002e-06
rl training, epoch2, iter0, batch187/1133, batch loss:2.892316388170002e-06, Training time:32692.909705877304
batch reward last col mean 3.6213193652656628e-06 first col mean 1.271876755026824e-07 all mean 5.7685697356646415e-06
1.5291849194909446e-05 1.5291847375920042e-05
rl training, epoch2, iter0, batch188/1133, batch loss:1.5291847375920042e-05, Training time:32711.15963077545
batch reward last col mean 1.964633078443967e-08 first col mean 1.0090409432450542e-06 all mean 4.358414571470348e-06
1.822570811782498e-05 1.822570811782498e-05
rl training, epoch2, iter0, batch189/1133, batch loss:1.822570811782498e-05, Training time:32729.293104171753
batch reward last col mean 1.4620206911786227e-07 first col mean 2.3046032637807912e-08 all mean 3.260311859776266e-05
2.8174032195238397e-05 2.8174043109174818e-05
rl training, epoch2, iter0, batch190/1133, batch loss:2.8174043109174818e-05, Training time:32747.278226614
batch reward last col mean 3.699348383179313e-08 first col mean 2.341049912502058e-05 all mean 1.7907505025505088e-05
1.749933471728582e-05 1.749932926031761e-05
rl training, epoch2, iter0, batch191/1133, batch loss:1.749932926031761e-05, Training time:32765.05733680725
batch reward last col mean 5.150396873432328e-07 first col mean 2.5191759789322532e-08 all mean 2.0853887690464035e-05
6.787759775761515e-05 6.787759775761515e-05
rl training, epoch2, iter0, batch192/1133, batch loss:6.787759775761515e-05, Training time:32783.07369828224
batch reward last col mean 2.1996017949277302e-06 first col mean 8.183622668411772e-09 all mean 5.273875558486907e-06
1.6431987432952155e-06 1.6431990843557287e-06
rl training, epoch2, iter0, batch193/1133, batch loss:1.6431990843557287e-06, Training time:32799.910276412964
batch reward last col mean 8.345745072801947e-08 first col mean 0.0003726352588273585 all mean 2.986137224070262e-05
0.00010025524534285069 0.00010025525989476591
rl training, epoch2, iter0, batch194/1133, batch loss:0.00010025525989476591, Training time:32816.24941253662
batch reward last col mean 6.981366595937288e-09 first col mean 3.2818973068060586e-06 all mean 8.543638614355586e-06
1.989759402931668e-05 1.989759402931668e-05
rl training, epoch2, iter0, batch195/1133, batch loss:1.989759402931668e-05, Training time:32832.96296739578
batch reward last col mean 1.0780640380403383e-08 first col mean 3.078452692761857e-08 all mean 2.019677140197018e-06
2.9754128263448365e-06 2.975413053718512e-06
rl training, epoch2, iter0, batch196/1133, batch loss:2.975413053718512e-06, Training time:32849.91126036644
batch reward last col mean 1.399951088387752e-08 first col mean 7.759417712804861e-06 all mean 1.394156879541697e-05
0.00010723006562329829 0.00010723006562329829
rl training, epoch2, iter0, batch197/1133, batch loss:0.00010723006562329829, Training time:32867.4563126564
batch reward last col mean 3.550657012851843e-08 first col mean 6.059661927793059e-07 all mean 3.089108213316649e-05
3.8167145248735324e-05 3.8167145248735324e-05
rl training, epoch2, iter0, batch198/1133, batch loss:3.8167145248735324e-05, Training time:32885.333168268204
batch reward last col mean 3.3660169265203876e-06 first col mean 0.000159873379743658 all mean 2.2877551600686274e-05
7.701006688876078e-05 7.701006688876078e-05
rl training, epoch2, iter0, batch199/1133, batch loss:7.701006688876078e-05, Training time:32903.606138944626
batch reward last col mean 8.194545486617244e-09 first col mean 6.897879245570948e-08 all mean 1.071247061190661e-05
6.502474570879713e-05 6.502474570879713e-05
rl training, epoch2, iter0, batch200/1133, batch loss:6.502474570879713e-05, Training time:32920.959349393845
batch reward last col mean 5.383924062130063e-08 first col mean 9.252493669009709e-07 all mean 1.4461052160186227e-05
1.6138847058755346e-05 1.6138847058755346e-05
rl training, epoch2, iter0, batch201/1133, batch loss:1.6138847058755346e-05, Training time:32940.02244114876
batch reward last col mean 1.2546633065824153e-08 first col mean 4.943825047121209e-07 all mean 1.3132447747921105e-05
6.583324193343287e-06 6.5833273765747435e-06
rl training, epoch2, iter0, batch202/1133, batch loss:6.5833273765747435e-06, Training time:32958.209624290466
batch reward last col mean 1.622684493440829e-07 first col mean 1.5694478861405514e-05 all mean 3.43225292454008e-06
1.1353503396094311e-05 1.1353503396094311e-05
rl training, epoch2, iter0, batch203/1133, batch loss:1.1353503396094311e-05, Training time:32976.68851065636
batch reward last col mean 2.5424348848446243e-08 first col mean 2.483768213323856e-08 all mean 9.310640052717645e-06
3.496521821944043e-05 3.496521821944043e-05
rl training, epoch2, iter0, batch204/1133, batch loss:3.496521821944043e-05, Training time:32994.6812376976
batch reward last col mean 5.604520993074402e-06 first col mean 5.22646530498605e-07 all mean 5.542407507164171e-06
1.009574816634995e-06 1.0095747029481572e-06
rl training, epoch2, iter0, batch205/1133, batch loss:1.0095747029481572e-06, Training time:33012.79732513428
batch reward last col mean 6.354703714350762e-07 first col mean 1.0685705120749844e-07 all mean 1.2461886399250943e-05
5.423279799288139e-05 5.423279799288139e-05
rl training, epoch2, iter0, batch206/1133, batch loss:5.423279799288139e-05, Training time:33030.22976112366
batch reward last col mean 5.484228182695006e-09 first col mean 7.345575170347729e-08 all mean 5.250903427622688e-07
3.6026719385517936e-07 3.6026716543346993e-07
rl training, epoch2, iter0, batch207/1133, batch loss:3.6026716543346993e-07, Training time:33048.66365790367
batch reward last col mean 6.501832558569731e-06 first col mean 6.687662244075909e-05 all mean 6.990504516579676e-06
1.1098312825197354e-05 1.1098313734692056e-05
rl training, epoch2, iter0, batch208/1133, batch loss:1.1098313734692056e-05, Training time:33067.1653676033
batch reward last col mean 1.423882622475503e-05 first col mean 1.8787399369557534e-07 all mean 2.2017366063664667e-05
5.092255014460534e-05 5.092255014460534e-05
rl training, epoch2, iter0, batch209/1133, batch loss:5.092255014460534e-05, Training time:33084.720236063
batch reward last col mean 7.775592791858799e-08 first col mean 2.2110758436610922e-05 all mean 1.708325157778745e-06
1.629133066671784e-06 1.629133521419135e-06
rl training, epoch2, iter0, batch210/1133, batch loss:1.629133521419135e-06, Training time:33101.74587106705
batch reward last col mean 1.376850946144259e-06 first col mean 5.874562702956609e-07 all mean 5.751206117565744e-06
2.411832429061178e-05 2.411832429061178e-05
rl training, epoch2, iter0, batch211/1133, batch loss:2.411832429061178e-05, Training time:33120.089752197266
batch reward last col mean 0.00019297280232422054 first col mean 4.671406713896431e-06 all mean 0.00014053173072170466
2.601232881715987e-05 2.601232881715987e-05
rl training, epoch2, iter0, batch212/1133, batch loss:2.601232881715987e-05, Training time:33138.22395610809
batch reward last col mean 3.404372910154052e-05 first col mean 1.9673096929295752e-08 all mean 3.324234057799913e-05
4.0202203308581375e-06 4.020220785605488e-06
rl training, epoch2, iter0, batch213/1133, batch loss:4.020220785605488e-06, Training time:33156.19748330116
batch reward last col mean 1.718107967008109e-08 first col mean 2.4543916765651375e-07 all mean 2.1488138372660615e-05
5.328169936547056e-05 5.3281703003449365e-05
rl training, epoch2, iter0, batch214/1133, batch loss:5.3281703003449365e-05, Training time:33173.56945371628
batch reward last col mean 3.241469315184986e-08 first col mean 4.355737019068329e-06 all mean 4.64798831671942e-05
0.00013069227861706167 0.00013069227861706167
rl training, epoch2, iter0, batch215/1133, batch loss:0.00013069227861706167, Training time:33192.07101368904
batch reward last col mean 5.4638952917684946e-08 first col mean 1.1768226926278658e-07 all mean 3.929387457901612e-05
0.00015725585399195552 0.00015725585399195552
rl training, epoch2, iter0, batch216/1133, batch loss:0.00015725585399195552, Training time:33209.86255478859
batch reward last col mean 4.801454167591146e-08 first col mean 1.2765554835425519e-08 all mean 2.959353423648281e-06
1.3013242096349131e-05 1.3013242096349131e-05
rl training, epoch2, iter0, batch217/1133, batch loss:1.3013242096349131e-05, Training time:33227.49318623543
batch reward last col mean 3.1731678973301314e-06 first col mean 9.094856068259105e-07 all mean 8.884951057552826e-06
1.1209833246539347e-05 1.1209834156034049e-05
rl training, epoch2, iter0, batch218/1133, batch loss:1.1209834156034049e-05, Training time:33245.70732688904
batch reward last col mean 7.627736664517215e-08 first col mean 5.036413313064259e-07 all mean 7.648473911103792e-06
1.8933176761493087e-05 1.8933174942503683e-05
rl training, epoch2, iter0, batch219/1133, batch loss:1.8933174942503683e-05, Training time:33263.5465490818
batch reward last col mean 1.4813433146798616e-08 first col mean 1.2997044507301325e-07 all mean 6.494144145108294e-06
3.406033283681609e-05 3.406033283681609e-05
rl training, epoch2, iter0, batch220/1133, batch loss:3.406033283681609e-05, Training time:33279.9635989666
batch reward last col mean 0.00010409800597699359 first col mean 6.8067223764956e-05 all mean 1.5721923773526214e-05
3.103398921666667e-05 3.1033992854645476e-05
rl training, epoch2, iter0, batch221/1133, batch loss:3.1033992854645476e-05, Training time:33296.295016765594
batch reward last col mean 2.2241945174528155e-08 first col mean 1.0040950293443984e-08 all mean 3.226932312827557e-05
0.0001806040818337351 0.0001806040818337351
rl training, epoch2, iter0, batch222/1133, batch loss:0.0001806040818337351, Training time:33314.45208096504
batch reward last col mean 6.974540944781893e-09 first col mean 5.849157673765149e-07 all mean 1.3394061170401983e-05
1.7614667740417644e-05 1.7614667740417644e-05
rl training, epoch2, iter0, batch223/1133, batch loss:1.7614667740417644e-05, Training time:33331.56350159645
batch reward last col mean 9.558700639900053e-07 first col mean 2.113837993533707e-08 all mean 2.682245394680649e-06
5.419783065008232e-06 5.419783065008232e-06
rl training, epoch2, iter0, batch224/1133, batch loss:5.419783065008232e-06, Training time:33349.812728881836
batch reward last col mean 2.072741835945635e-07 first col mean 6.656261575699318e-06 all mean 8.837870154820848e-06
2.7660185878630728e-05 2.7660189516609535e-05
rl training, epoch2, iter0, batch225/1133, batch loss:2.7660189516609535e-05, Training time:33368.86334896088
batch reward last col mean 1.737152643954687e-07 first col mean 0.00017708510858938098 all mean 1.881163552752696e-05
0.00012555124703794718 0.0001255512615898624
rl training, epoch2, iter0, batch226/1133, batch loss:0.0001255512615898624, Training time:33385.52659368515
batch reward last col mean 0.000792700273450464 first col mean 6.48380648726743e-07 all mean 0.0007351745734922588
0.00013307819608598948 0.00013307819608598948
rl training, epoch2, iter0, batch227/1133, batch loss:0.00013307819608598948, Training time:33402.14487338066
batch reward last col mean 4.670991074817721e-06 first col mean 1.236172124663426e-06 all mean 2.229754682048224e-05
2.1710806322516873e-05 2.171080996049568e-05
rl training, epoch2, iter0, batch228/1133, batch loss:2.171080996049568e-05, Training time:33418.80466389656
batch reward last col mean 1.0895830655499594e-06 first col mean 3.2585587632638635e-06 all mean 2.46526651608292e-05
3.363576252013445e-05 3.363576979609206e-05
rl training, epoch2, iter0, batch229/1133, batch loss:3.363576979609206e-05, Training time:33435.48268699646
batch reward last col mean 0.001062797848135233 first col mean 2.635645387272234e-06 all mean 0.0009580269688740373
8.690850518178195e-05 8.690850518178195e-05
rl training, epoch2, iter0, batch230/1133, batch loss:8.690850518178195e-05, Training time:33452.079763412476
batch reward last col mean 1.66649165578292e-08 first col mean 2.126790377587895e-06 all mean 1.3563272887040512e-06
5.937604896644189e-07 5.937604896644189e-07
rl training, epoch2, iter0, batch231/1133, batch loss:5.937604896644189e-07, Training time:33468.8744122982
batch reward last col mean 3.5840574952317183e-08 first col mean 7.354412082349882e-05 all mean 2.2004473066772334e-05
0.00010575864143902436 0.00010575864871498197
rl training, epoch2, iter0, batch232/1133, batch loss:0.00010575864871498197, Training time:33485.872310876846
batch reward last col mean 4.360422565241606e-07 first col mean 1.4995594938227441e-05 all mean 1.7456415662309155e-05
1.0186472536588553e-05 1.0186467989115044e-05
rl training, epoch2, iter0, batch233/1133, batch loss:1.0186467989115044e-05, Training time:33502.564007520676
batch reward last col mean 1.0847021947313351e-08 first col mean 7.916182198641764e-08 all mean 1.6736848920118064e-05
5.7770597777562216e-05 5.7770597777562216e-05
rl training, epoch2, iter0, batch234/1133, batch loss:5.7770597777562216e-05, Training time:33519.33991646767
batch reward last col mean 1.2347738831408606e-08 first col mean 7.88625402492471e-06 all mean 5.35879235030734e-06
3.04701261484297e-05 3.04701261484297e-05
rl training, epoch2, iter0, batch235/1133, batch loss:3.04701261484297e-05, Training time:33535.95322608948
batch reward last col mean 1.115623859959669e-07 first col mean 0.0012345751747488976 all mean 1.6262118151644245e-05
1.52694592543412e-05 1.5269457435351796e-05
rl training, epoch2, iter0, batch236/1133, batch loss:1.5269457435351796e-05, Training time:33552.76959514618
batch reward last col mean 7.824220382701697e-09 first col mean 3.315971298434306e-06 all mean 1.1216760867682751e-05
2.857834260794334e-06 2.857832214431255e-06
rl training, epoch2, iter0, batch237/1133, batch loss:2.857832214431255e-06, Training time:33570.553048849106
batch reward last col mean 2.73799365402283e-08 first col mean 9.234554454451427e-09 all mean 8.995766620500945e-06
1.4144598026177846e-05 1.4144598026177846e-05
rl training, epoch2, iter0, batch238/1133, batch loss:1.4144598026177846e-05, Training time:33588.16661930084
batch reward last col mean 6.349808927552658e-07 first col mean 0.0009733593906275928 all mean 4.364863343653269e-05
6.134780414868146e-05 6.134780414868146e-05
rl training, epoch2, iter0, batch239/1133, batch loss:6.134780414868146e-05, Training time:33605.16313481331
batch reward last col mean 1.1783181541602517e-08 first col mean 4.660616781393401e-08 all mean 5.8020259530167095e-06
5.610672815237194e-06 5.610674634226598e-06
rl training, epoch2, iter0, batch240/1133, batch loss:5.610674634226598e-06, Training time:33622.87436032295
batch reward last col mean 5.481520304329024e-08 first col mean 1.199885080183094e-08 all mean 3.6139460917183897e-06
1.6925152976909885e-06 1.6925156387515017e-06
rl training, epoch2, iter0, batch241/1133, batch loss:1.6925156387515017e-06, Training time:33642.20146250725
batch reward last col mean 3.38491616957981e-08 first col mean 0.00031102122738957405 all mean 5.5365858315781225e-06
3.073684638366103e-06 3.0736848657397786e-06
rl training, epoch2, iter0, batch242/1133, batch loss:3.0736848657397786e-06, Training time:33658.866260290146
batch reward last col mean 2.2172411263454705e-05 first col mean 3.0397831096706796e-07 all mean 1.778097953319957e-06
4.410241217556177e-06 4.410240762808826e-06
rl training, epoch2, iter0, batch243/1133, batch loss:4.410240762808826e-06, Training time:33675.99706697464
batch reward last col mean 3.329208084323909e-06 first col mean 5.0530420736549786e-08 all mean 1.1572476978471968e-05
3.931467290385626e-05 3.931467290385626e-05
rl training, epoch2, iter0, batch244/1133, batch loss:3.931467290385626e-05, Training time:33692.56381416321
batch reward last col mean 1.0884890322415686e-08 first col mean 7.07792496541515e-05 all mean 1.4067795746086631e-05
8.03790899226442e-05 8.037908264668658e-05
rl training, epoch2, iter0, batch245/1133, batch loss:8.037908264668658e-05, Training time:33709.141595840454
batch reward last col mean 0.0007609906606376171 first col mean 1.2966632993993699e-06 all mean 0.0002022059343289584
7.886831735959277e-05 7.886831735959277e-05
rl training, epoch2, iter0, batch246/1133, batch loss:7.886831735959277e-05, Training time:33725.83609366417
batch reward last col mean 1.31253983681745e-07 first col mean 8.17937598185381e-06 all mean 2.607562691991916e-06
4.269559667591238e-06 4.26956057708594e-06
rl training, epoch2, iter0, batch247/1133, batch loss:4.26956057708594e-06, Training time:33743.00859975815
batch reward last col mean 7.157109212130308e-05 first col mean 4.842347152589355e-06 all mean 8.545802847947925e-05
6.853311788290739e-05 6.853311060694978e-05
rl training, epoch2, iter0, batch248/1133, batch loss:6.853311060694978e-05, Training time:33759.67641377449
batch reward last col mean 2.6907418515520476e-08 first col mean 2.5695911176626396e-08 all mean 1.639370748307556e-05
1.0232361091766506e-05 1.0232356544292998e-05
rl training, epoch2, iter0, batch249/1133, batch loss:1.0232356544292998e-05, Training time:33776.19119167328
batch reward last col mean 5.638286282305671e-08 first col mean 1.2079314615220937e-07 all mean 4.279221229808172e-06
9.753188351169229e-06 9.753187441674527e-06
rl training, epoch2, iter0, batch250/1133, batch loss:9.753187441674527e-06, Training time:33792.61693406105
batch reward last col mean 7.184819878602866e-06 first col mean 3.969742579101876e-08 all mean 1.0793378351081628e-06
1.964595867320895e-06 1.964595867320895e-06
rl training, epoch2, iter0, batch251/1133, batch loss:1.964595867320895e-06, Training time:33809.04988503456
batch reward last col mean 2.5826507155102263e-08 first col mean 1.9467041312282163e-08 all mean 2.049574732154724e-06
9.718348337628413e-06 9.718348337628413e-06
rl training, epoch2, iter0, batch252/1133, batch loss:9.718348337628413e-06, Training time:33825.70826458931
batch reward last col mean 8.990309652290307e-08 first col mean 1.3318222045199946e-06 all mean 7.390353857772425e-06
9.842392501013819e-06 9.842392501013819e-06
rl training, epoch2, iter0, batch253/1133, batch loss:9.842392501013819e-06, Training time:33842.58859562874
batch reward last col mean 2.4972978280857205e-06 first col mean 1.7402043113179388e-06 all mean 1.6290296116494574e-05
2.6556572265690193e-05 2.6556574084679596e-05
rl training, epoch2, iter0, batch254/1133, batch loss:2.6556574084679596e-05, Training time:33859.30904221535
batch reward last col mean 1.9521650074239005e-08 first col mean 8.696766826687963e-07 all mean 1.457357257095282e-06
1.7662440541243996e-06 1.7662441678112373e-06
rl training, epoch2, iter0, batch255/1133, batch loss:1.7662441678112373e-06, Training time:33877.341457128525
batch reward last col mean 1.9467599088329735e-08 first col mean 2.1180650833230175e-07 all mean 1.5932331734802574e-05
3.213312083971687e-05 3.213311720173806e-05
rl training, epoch2, iter0, batch256/1133, batch loss:3.213311720173806e-05, Training time:33894.683782339096
batch reward last col mean 5.310278083925368e-07 first col mean 6.197374023031443e-05 all mean 6.184985068102833e-06
3.977698725066148e-05 3.977698725066148e-05
rl training, epoch2, iter0, batch257/1133, batch loss:3.977698725066148e-05, Training time:33913.286110162735
batch reward last col mean 4.455701940742074e-08 first col mean 2.4861351448635105e-06 all mean 1.0813932931341697e-05
1.557996620249469e-05 1.5579964383505285e-05
rl training, epoch2, iter0, batch258/1133, batch loss:1.5579964383505285e-05, Training time:33930.58690261841
batch reward last col mean 3.0326127671287395e-05 first col mean 2.044228786246549e-08 all mean 3.4706386941252276e-05
1.8750155504676513e-05 1.8750155504676513e-05
rl training, epoch2, iter0, batch259/1133, batch loss:1.8750155504676513e-05, Training time:33950.28334403038
batch reward last col mean 2.180286537623033e-05 first col mean 3.9673042806498415e-07 all mean 4.666153472498991e-06
1.4150855349726044e-06 1.415085648659442e-06
rl training, epoch2, iter0, batch260/1133, batch loss:1.415085648659442e-06, Training time:33966.72367620468
batch reward last col mean 1.7185801226560216e-08 first col mean 6.775400834158063e-05 all mean 5.491663614520803e-06
3.121521331195254e-06 3.1215206490742275e-06
rl training, epoch2, iter0, batch261/1133, batch loss:3.1215206490742275e-06, Training time:33983.21827697754
batch reward last col mean 2.0936235500812472e-07 first col mean 5.738270374422427e-07 all mean 1.3979090908833314e-05
3.258146170992404e-05 3.2581458071945235e-05
rl training, epoch2, iter0, batch262/1133, batch loss:3.2581458071945235e-05, Training time:33999.807579517365
batch reward last col mean 1.1699683000188088e-06 first col mean 0.00015374942449852824 all mean 1.633949068491347e-05
9.029102511703968e-05 9.029101784108207e-05
rl training, epoch2, iter0, batch263/1133, batch loss:9.029101784108207e-05, Training time:34017.067187309265
batch reward last col mean 1.4205315146398334e-08 first col mean 0.00020634187967516482 all mean 1.9475848603178747e-05
1.3153619875083677e-05 1.3153615327610169e-05
rl training, epoch2, iter0, batch264/1133, batch loss:1.3153615327610169e-05, Training time:34033.5471534729
batch reward last col mean 1.278711533814203e-05 first col mean 1.6325750493706437e-06 all mean 1.658546352700796e-05
3.945922071579844e-05 3.9459224353777245e-05
rl training, epoch2, iter0, batch265/1133, batch loss:3.9459224353777245e-05, Training time:34050.072425842285
batch reward last col mean 1.292562927801555e-07 first col mean 2.69561951427022e-07 all mean 6.29816986474907e-06
1.6573937955399742e-06 1.6573952734688646e-06
rl training, epoch2, iter0, batch266/1133, batch loss:1.6573952734688646e-06, Training time:34066.61366844177
batch reward last col mean 5.061395313532557e-06 first col mean 1.8027603232440015e-07 all mean 3.6461767649598187e-06
6.664624834229471e-06 6.66462437948212e-06
rl training, epoch2, iter0, batch267/1133, batch loss:6.66462437948212e-06, Training time:34083.69225406647
batch reward last col mean 8.06690092503004e-09 first col mean 3.995584120275453e-05 all mean 1.591909494891297e-05
4.117500429856591e-05 4.117500429856591e-05
rl training, epoch2, iter0, batch268/1133, batch loss:4.117500429856591e-05, Training time:34100.52154803276
batch reward last col mean 2.5673958958805088e-08 first col mean 2.5931063518669362e-08 all mean 4.95469976158347e-06
2.8625114282476716e-05 2.8625112463487312e-05
rl training, epoch2, iter0, batch269/1133, batch loss:2.8625112463487312e-05, Training time:34117.4108877182
batch reward last col mean 1.581739184075559e-08 first col mean 9.259275975637138e-05 all mean 2.4393323201366e-06
2.1445036963996245e-06 2.1445036963996245e-06
rl training, epoch2, iter0, batch270/1133, batch loss:2.1445036963996245e-06, Training time:34134.94372200966
batch reward last col mean 6.743548874510452e-05 first col mean 8.14780196378706e-06 all mean 7.123590330593288e-05
1.4775901945540681e-05 1.4775901945540681e-05
rl training, epoch2, iter0, batch271/1133, batch loss:1.4775901945540681e-05, Training time:34152.90016889572
batch reward last col mean 2.4954212562988687e-07 first col mean 9.19532249099575e-05 all mean 4.7830388211878017e-05
0.00018852205539587885 0.00018852204084396362
rl training, epoch2, iter0, batch272/1133, batch loss:0.00018852204084396362, Training time:34171.39996409416
batch reward last col mean 1.6756996501499088e-07 first col mean 2.84204872968985e-07 all mean 1.3908063010603655e-05
2.988884261867497e-06 2.9888840344938217e-06
rl training, epoch2, iter0, batch273/1133, batch loss:2.9888840344938217e-06, Training time:34190.19916892052
batch reward last col mean 6.221362980340928e-09 first col mean 3.124301528600881e-08 all mean 2.312520518898964e-05
9.96839880826883e-05 9.96839880826883e-05
rl training, epoch2, iter0, batch274/1133, batch loss:9.96839880826883e-05, Training time:34209.1454076767
batch reward last col mean 0.0031276163645088673 first col mean 3.902612661477178e-05 all mean 0.002760203555226326
0.0002795636828523129 0.0002795636828523129
rl training, epoch2, iter0, batch275/1133, batch loss:0.0002795636828523129, Training time:34227.804716825485
batch reward last col mean 1.9538742179747715e-08 first col mean 1.6601553909367794e-07 all mean 2.7574653358897194e-05
7.1532886067871e-05 7.1532886067871e-05
rl training, epoch2, iter0, batch276/1133, batch loss:7.1532886067871e-05, Training time:34244.3176548481
batch reward last col mean 1.7428997125534806e-06 first col mean 6.834862453786172e-09 all mean 4.941849965689471e-06
2.0346580640762113e-05 2.0346580640762113e-05
rl training, epoch2, iter0, batch277/1133, batch loss:2.0346580640762113e-05, Training time:34261.17385149002
batch reward last col mean 1.0697664976078158e-07 first col mean 0.00013370558735914528 all mean 2.1204199583735317e-05
3.094328712904826e-05 3.094329440500587e-05
rl training, epoch2, iter0, batch278/1133, batch loss:3.094329440500587e-05, Training time:34278.44143271446
batch reward last col mean 3.568559225897161e-09 first col mean 0.0007299628923647106 all mean 9.216275429935195e-06
5.731377768825041e-06 5.731375040340936e-06
rl training, epoch2, iter0, batch279/1133, batch loss:5.731375040340936e-06, Training time:34295.001737356186
batch reward last col mean 1.1548419109885799e-08 first col mean 9.575644799042493e-05 all mean 2.861947905330453e-06
7.6225032898946665e-06 7.622503744642017e-06
rl training, epoch2, iter0, batch280/1133, batch loss:7.622503744642017e-06, Training time:34311.478541851044
batch reward last col mean 2.340308674320113e-05 first col mean 5.5717810027999803e-05 all mean 2.2853355403640307e-05
1.9792009879893158e-06 1.979201215362991e-06
rl training, epoch2, iter0, batch281/1133, batch loss:1.979201215362991e-06, Training time:34328.88515043259
batch reward last col mean 9.832790581754125e-09 first col mean 0.0016506245592609048 all mean 2.624106673465576e-05
2.0179326384095475e-05 2.0179320927127264e-05
rl training, epoch2, iter0, batch282/1133, batch loss:2.0179320927127264e-05, Training time:34345.66378903389
batch reward last col mean 7.157477375585586e-05 first col mean 8.017379116154189e-08 all mean 4.990616798750125e-05
2.7528838472790085e-05 2.7528838472790085e-05
rl training, epoch2, iter0, batch283/1133, batch loss:2.7528838472790085e-05, Training time:34362.2632021904
batch reward last col mean 1.1630941116891336e-05 first col mean 6.22205647005103e-08 all mean 1.5600940969306976e-05
5.288134616421303e-06 5.288134161673952e-06
rl training, epoch2, iter0, batch284/1133, batch loss:5.288134161673952e-06, Training time:34379.11836671829
batch reward last col mean 5.052271490058047e-07 first col mean 5.746637299353097e-08 all mean 5.947476893197745e-06
1.9777480702032335e-05 1.9777484340011142e-05
rl training, epoch2, iter0, batch285/1133, batch loss:1.9777484340011142e-05, Training time:34395.72608208656
batch reward last col mean 2.2963460821756598e-07 first col mean 3.676735650515184e-05 all mean 1.9905231965822168e-05
0.00012483808677643538 0.00012483808677643538
rl training, epoch2, iter0, batch286/1133, batch loss:0.00012483808677643538, Training time:34412.23669052124
batch reward last col mean 2.9367804472713033e-06 first col mean 3.2352397738577565e-07 all mean 7.070645096973749e-06
5.028688974562101e-05 5.028689338359982e-05
rl training, epoch2, iter0, batch287/1133, batch loss:5.028689338359982e-05, Training time:34429.833786726
batch reward last col mean 6.457699055317789e-05 first col mean 8.404948204088214e-08 all mean 8.393669850192964e-05
8.81089799804613e-05 8.810897270450369e-05
rl training, epoch2, iter0, batch288/1133, batch loss:8.810897270450369e-05, Training time:34448.26250743866
batch reward last col mean 2.2215694173155498e-08 first col mean 8.05014011007188e-08 all mean 2.2149955839267932e-05
1.7569751435075887e-05 1.7569755073054694e-05
rl training, epoch2, iter0, batch289/1133, batch loss:1.7569755073054694e-05, Training time:34466.89114046097
batch reward last col mean 0.001061632763594389 first col mean 1.9377523585717427e-08 all mean 0.0006915959529578686
0.00011494142381707206 0.00011494142381707206
rl training, epoch2, iter0, batch290/1133, batch loss:0.00011494142381707206, Training time:34483.80814766884
batch reward last col mean 6.262252050248662e-09 first col mean 2.770102724980461e-08 all mean 2.9569573598564602e-06
6.080365892557893e-06 6.080366347305244e-06
rl training, epoch2, iter0, batch291/1133, batch loss:6.080366347305244e-06, Training time:34500.864679813385
batch reward last col mean 5.8596530294607874e-08 first col mean 4.821583570446819e-05 all mean 2.0823165414185496e-06
1.481857680118992e-06 1.4818575664321543e-06
rl training, epoch2, iter0, batch292/1133, batch loss:1.4818575664321543e-06, Training time:34517.31434631348
batch reward last col mean 1.0455016052901556e-07 first col mean 3.2683296012692153e-05 all mean 1.5178758985712193e-05
4.639627877622843e-05 4.639627513824962e-05
rl training, epoch2, iter0, batch293/1133, batch loss:4.639627513824962e-05, Training time:34533.78317117691
batch reward last col mean 1.2580003705409126e-08 first col mean 8.731233265280025e-07 all mean 8.669973794894759e-06
3.808348628808744e-05 3.808348628808744e-05
rl training, epoch2, iter0, batch294/1133, batch loss:3.808348628808744e-05, Training time:34550.88949561119
batch reward last col mean 6.117551265560905e-08 first col mean 6.822418072260916e-06 all mean 5.557382792176213e-06
3.1973897876014234e-06 3.1973902423487743e-06
rl training, epoch2, iter0, batch295/1133, batch loss:3.1973902423487743e-06, Training time:34567.41769719124
batch reward last col mean 4.4365368268017846e-08 first col mean 2.890661221499613e-07 all mean 3.77592800759885e-06
1.282820085179992e-05 1.2828199032810517e-05
rl training, epoch2, iter0, batch296/1133, batch loss:1.2828199032810517e-05, Training time:34583.92333006859
batch reward last col mean 4.974401335289258e-09 first col mean 3.4078420867444947e-06 all mean 6.1736313909932505e-06
2.08819310500985e-05 2.08819310500985e-05
rl training, epoch2, iter0, batch297/1133, batch loss:2.08819310500985e-05, Training time:34600.41675066948
batch reward last col mean 7.814779223735968e-08 first col mean 7.231950149844124e-08 all mean 2.9203965823398903e-07
6.166737307466974e-07 6.166737307466974e-07
rl training, epoch2, iter0, batch298/1133, batch loss:6.166737307466974e-07, Training time:34617.196242809296
batch reward last col mean 7.380860438388481e-07 first col mean 4.3873637878277805e-06 all mean 3.5392192785366205e-06
1.109165964408021e-06 1.1091664191553718e-06
rl training, epoch2, iter0, batch299/1133, batch loss:1.1091664191553718e-06, Training time:34633.787851810455
batch reward last col mean 1.2483450717581945e-08 first col mean 1.5460392077670804e-08 all mean 3.314783725727466e-06
5.880577646166785e-06 5.8805781009141356e-06
rl training, epoch2, iter0, batch300/1133, batch loss:5.8805781009141356e-06, Training time:34650.294492959976
batch reward last col mean 4.467756298254244e-08 first col mean 4.664645132379519e-07 all mean 8.314147635246627e-06
3.597741306293756e-05 3.597740942495875e-05
rl training, epoch2, iter0, batch301/1133, batch loss:3.597740942495875e-05, Training time:34666.75145864487
batch reward last col mean 1.3337077575670264e-07 first col mean 2.422256329737138e-06 all mean 2.0364766896818765e-05
9.858771227300167e-05 9.858769772108644e-05
rl training, epoch2, iter0, batch302/1133, batch loss:9.858769772108644e-05, Training time:34683.25495672226
batch reward last col mean 2.251072004355592e-07 first col mean 1.146438535215566e-06 all mean 3.5867446968040895e-06
1.5548026567557827e-05 1.5548026567557827e-05
rl training, epoch2, iter0, batch303/1133, batch loss:1.5548026567557827e-05, Training time:34701.79871082306
batch reward last col mean 3.7012068965225353e-09 first col mean 1.3879275684303138e-05 all mean 9.37399181566434e-06
2.8384745746734552e-05 2.8384747565723956e-05
rl training, epoch2, iter0, batch304/1133, batch loss:2.8384747565723956e-05, Training time:34721.269874334335
batch reward last col mean 6.366353773046285e-07 first col mean 1.7321389123026165e-07 all mean 2.4790399038465694e-05
0.00013823818881064653 0.00013823818881064653
rl training, epoch2, iter0, batch305/1133, batch loss:0.00013823818881064653, Training time:34739.73482131958
batch reward last col mean 7.3709375101316255e-06 first col mean 4.416256160766352e-08 all mean 1.35839791255421e-05
5.2835643145954236e-05 5.2835643145954236e-05
rl training, epoch2, iter0, batch306/1133, batch loss:5.2835643145954236e-05, Training time:34756.55152249336
batch reward last col mean 0.000112026376882568 first col mean 1.673336669227865e-06 all mean 0.00011030035966541618
1.4184048268361948e-05 1.4184045539877843e-05
rl training, epoch2, iter0, batch307/1133, batch loss:1.4184045539877843e-05, Training time:34775.597445726395
batch reward last col mean 8.886043360689655e-06 first col mean 3.506650614326645e-07 all mean 2.9217682822491042e-05
0.00011414606706239283 0.00011414607433835045
rl training, epoch2, iter0, batch308/1133, batch loss:0.00011414607433835045, Training time:34792.79795360565
batch reward last col mean 2.30536514322921e-08 first col mean 1.221619822899811e-05 all mean 8.190473636204842e-06
6.223753644007957e-06 6.223752279765904e-06
rl training, epoch2, iter0, batch309/1133, batch loss:6.223752279765904e-06, Training time:34809.308160066605
batch reward last col mean 2.5794224711717106e-07 first col mean 8.450278255622834e-05 all mean 3.314835703349672e-05
2.3957400117069483e-05 2.3957387384143658e-05
rl training, epoch2, iter0, batch310/1133, batch loss:2.3957387384143658e-05, Training time:34825.707567453384
batch reward last col mean 1.5479168169463264e-08 first col mean 0.00014294857101049274 all mean 3.1640243832953274e-05
4.9398495320929214e-05 4.939850259688683e-05
rl training, epoch2, iter0, batch311/1133, batch loss:4.939850259688683e-05, Training time:34844.17157578468
batch reward last col mean 1.7051682732471818e-07 first col mean 4.564060773759593e-08 all mean 1.0072963050333783e-05
4.860394255956635e-06 4.8603919822198804e-06
rl training, epoch2, iter0, batch312/1133, batch loss:4.8603919822198804e-06, Training time:34862.73315739632
batch reward last col mean 5.036096695221204e-07 first col mean 4.891101639259432e-07 all mean 3.78496952180285e-06
6.36622280580923e-06 6.366222351061879e-06
rl training, epoch2, iter0, batch313/1133, batch loss:6.366222351061879e-06, Training time:34881.41521859169
batch reward last col mean 1.6080205966773065e-07 first col mean 1.8929246436982794e-07 all mean 1.2977097867405973e-06
1.5627905440851464e-06 1.5627909988324973e-06
rl training, epoch2, iter0, batch314/1133, batch loss:1.5627909988324973e-06, Training time:34900.79772686958
batch reward last col mean 8.815772645220932e-08 first col mean 1.9354491342937763e-08 all mean 3.1402591957885306e-06
3.662468998300028e-06 3.662468543552677e-06
rl training, epoch2, iter0, batch315/1133, batch loss:3.662468543552677e-06, Training time:34919.32052445412
batch reward last col mean 5.042215533990202e-08 first col mean 1.4758987276763946e-07 all mean 2.0841929654125124e-05
2.525380659790244e-05 2.5253808416891843e-05
rl training, epoch2, iter0, batch316/1133, batch loss:2.5253808416891843e-05, Training time:34936.8596739769
batch reward last col mean 6.78047911151225e-07 first col mean 1.467560650780797e-07 all mean 1.348242221865803e-05
6.188650149852037e-05 6.188650149852037e-05
rl training, epoch2, iter0, batch317/1133, batch loss:6.188650149852037e-05, Training time:34953.55178689957
batch reward last col mean 1.9627896108431742e-07 first col mean 1.2600751688296441e-05 all mean 6.629451490880456e-06
4.872169029113138e-06 4.8721672101237345e-06
rl training, epoch2, iter0, batch318/1133, batch loss:4.8721672101237345e-06, Training time:34970.33221387863
batch reward last col mean 1.7559566245495262e-08 first col mean 9.311845872161939e-08 all mean 6.0567081163753755e-06
3.204550739610568e-05 3.204550375812687e-05
rl training, epoch2, iter0, batch319/1133, batch loss:3.204550375812687e-05, Training time:34986.95189380646
batch reward last col mean 2.858546288564412e-08 first col mean 4.8534026575453026e-08 all mean 2.9091268061165465e-06
5.972449343971675e-06 5.972449343971675e-06
rl training, epoch2, iter0, batch320/1133, batch loss:5.972449343971675e-06, Training time:35003.64329242706
batch reward last col mean 6.0831091104773805e-05 first col mean 1.4889013755237102e-07 all mean 4.9313021008856595e-05
2.3530757971457206e-05 2.3530757971457206e-05
rl training, epoch2, iter0, batch321/1133, batch loss:2.3530757971457206e-05, Training time:35020.17213535309
batch reward last col mean 1.7505476535006892e-07 first col mean 1.7982375766223413e-07 all mean 5.8418872868060134e-06
5.9122485254192725e-06 5.912249889661325e-06
rl training, epoch2, iter0, batch322/1133, batch loss:5.912249889661325e-06, Training time:35036.55885863304
batch reward last col mean 4.90651871132286e-07 first col mean 6.345710426103324e-05 all mean 1.1520422958710697e-05
1.4770878351555439e-06 1.4770855614187894e-06
rl training, epoch2, iter0, batch323/1133, batch loss:1.4770855614187894e-06, Training time:35052.998503685
batch reward last col mean 2.4835060230543604e-06 first col mean 6.527530331368325e-06 all mean 2.9095879199303454e-06
2.6738553060567938e-06 2.6738550786831183e-06
rl training, epoch2, iter0, batch324/1133, batch loss:2.6738550786831183e-06, Training time:35069.58892035484
batch reward last col mean 4.023648259021684e-08 first col mean 6.311774541245541e-06 all mean 1.0380098501627799e-05
2.3578128093504347e-05 2.3578128093504347e-05
rl training, epoch2, iter0, batch325/1133, batch loss:2.3578128093504347e-05, Training time:35086.31590509415
batch reward last col mean 7.251482969650169e-08 first col mean 0.00022975116735324264 all mean 2.5149389330181293e-05
8.913582132663578e-05 8.913582132663578e-05
rl training, epoch2, iter0, batch326/1133, batch loss:8.913582132663578e-05, Training time:35102.653893232346
batch reward last col mean 1.1820286260899593e-07 first col mean 2.3374325337499613e-06 all mean 2.663960913196206e-05
0.00013748287165071815 0.00013748287165071815
rl training, epoch2, iter0, batch327/1133, batch loss:0.00013748287165071815, Training time:35119.568214178085
batch reward last col mean 7.485866149181675e-08 first col mean 1.0672026462543727e-07 all mean 2.129700078512542e-05
1.9433211491559632e-05 1.9433216948527843e-05
rl training, epoch2, iter0, batch328/1133, batch loss:1.9433216948527843e-05, Training time:35137.878796339035
batch reward last col mean 0.00029659588471986353 first col mean 4.942535269947257e-07 all mean 0.00025646708672866225
9.369546751258895e-05 9.369547478854656e-05
rl training, epoch2, iter0, batch329/1133, batch loss:9.369547478854656e-05, Training time:35157.244463443756
batch reward last col mean 1.2002891480733524e-06 first col mean 2.1432978769553301e-07 all mean 3.162767370668007e-06
2.0119487089687027e-06 2.011948254221352e-06
rl training, epoch2, iter0, batch330/1133, batch loss:2.011948254221352e-06, Training time:35175.34170150757
batch reward last col mean 5.041733075472621e-08 first col mean 7.098750938894227e-05 all mean 8.191715096472763e-06
1.8518443539505824e-05 1.8518443539505824e-05
rl training, epoch2, iter0, batch331/1133, batch loss:1.8518443539505824e-05, Training time:35192.28977704048
batch reward last col mean 6.164812020870158e-07 first col mean 5.357926511351252e-07 all mean 7.2981824814633e-06
8.925741894927341e-06 8.925741894927341e-06
rl training, epoch2, iter0, batch332/1133, batch loss:8.925741894927341e-06, Training time:35209.00133395195
batch reward last col mean 2.9439586768376103e-08 first col mean 7.818741210030566e-08 all mean 8.244983291660901e-06
9.887723535939585e-06 9.88772626442369e-06
rl training, epoch2, iter0, batch333/1133, batch loss:9.88772626442369e-06, Training time:35225.89411497116
batch reward last col mean 1.7538811789563624e-06 first col mean 2.7038666416956403e-07 all mean 2.1681223643099656e-06
2.6745342438516673e-06 2.6745344712253427e-06
rl training, epoch2, iter0, batch334/1133, batch loss:2.6745344712253427e-06, Training time:35242.822671175
batch reward last col mean 1.2335071630786842e-08 first col mean 3.1786980798642617e-06 all mean 2.5439881937927566e-05
7.146232383092865e-05 7.146231655497104e-05
rl training, epoch2, iter0, batch335/1133, batch loss:7.146231655497104e-05, Training time:35259.30454850197
batch reward last col mean 1.9724689082067925e-06 first col mean 5.327204348759551e-07 all mean 2.5873127924569417e-06
5.467300525197061e-06 5.467299615702359e-06
rl training, epoch2, iter0, batch336/1133, batch loss:5.467299615702359e-06, Training time:35275.975976228714
batch reward last col mean 7.3068008532573e-07 first col mean 3.5242363082943484e-05 all mean 6.563091119460296e-06
5.016906925447984e-06 5.016905561205931e-06
rl training, epoch2, iter0, batch337/1133, batch loss:5.016905561205931e-06, Training time:35292.46214842796
batch reward last col mean 6.293291221481923e-08 first col mean 0.00029210993670858443 all mean 7.721069778199308e-06
1.8990737089552567e-06 1.8990759826920112e-06
rl training, epoch2, iter0, batch338/1133, batch loss:1.8990759826920112e-06, Training time:35308.78072619438
batch reward last col mean 2.5623487331927208e-08 first col mean 4.664465436121645e-08 all mean 8.479983648612688e-07
7.852339649616624e-07 7.852340786485001e-07
rl training, epoch2, iter0, batch339/1133, batch loss:7.852340786485001e-07, Training time:35325.4641020298
batch reward last col mean 3.8419674552869765e-08 first col mean 2.646677330631064e-07 all mean 5.28233113072929e-06
2.5812554667936638e-05 2.5812552848947234e-05
rl training, epoch2, iter0, batch340/1133, batch loss:2.5812552848947234e-05, Training time:35342.247267484665
batch reward last col mean 1.7034574284480186e-07 first col mean 6.163010368709365e-08 all mean 2.6947514015773777e-06
5.455884092953056e-06 5.455884092953056e-06
rl training, epoch2, iter0, batch341/1133, batch loss:5.455884092953056e-06, Training time:35359.608184576035
batch reward last col mean 4.956518750987016e-09 first col mean 3.190726420143619e-05 all mean 1.388522741763154e-05
6.761903932783753e-05 6.761903932783753e-05
rl training, epoch2, iter0, batch342/1133, batch loss:6.761903932783753e-05, Training time:35378.055183172226
batch reward last col mean 3.017736105448421e-08 first col mean 0.00010887744429055601 all mean 9.216865691996645e-06
3.358197136549279e-05 3.358197136549279e-05
rl training, epoch2, iter0, batch343/1133, batch loss:3.358197136549279e-05, Training time:35396.404249191284
batch reward last col mean 3.300751316714923e-08 first col mean 2.7907506137125893e-06 all mean 2.908103124354966e-05
0.00017673976253718138 0.00017673973343335092
rl training, epoch2, iter0, batch344/1133, batch loss:0.00017673973343335092, Training time:35415.03945708275
batch reward last col mean 2.51258910566321e-07 first col mean 1.5152133414630953e-07 all mean 3.5571663374867057e-06
1.0395418939879164e-05 1.0395419849373866e-05
rl training, epoch2, iter0, batch345/1133, batch loss:1.0395419849373866e-05, Training time:35432.56786632538
batch reward last col mean 1.1361620266825412e-07 first col mean 1.2182701070173607e-08 all mean 3.610161911637988e-06
4.381170583656058e-06 4.381170583656058e-06
rl training, epoch2, iter0, batch346/1133, batch loss:4.381170583656058e-06, Training time:35450.295075416565
batch reward last col mean 1.3232960327513865e-07 first col mean 0.0001497400808148086 all mean 6.232420219021151e-06
1.7969159671338275e-05 1.796916149032768e-05
rl training, epoch2, iter0, batch347/1133, batch loss:1.796916149032768e-05, Training time:35466.950320482254
batch reward last col mean 3.101887635637013e-09 first col mean 1.0769011993261302e-07 all mean 7.443703907483723e-06
3.6002784327138215e-05 3.6002784327138215e-05
rl training, epoch2, iter0, batch348/1133, batch loss:3.6002784327138215e-05, Training time:35483.39924073219
batch reward last col mean 3.4002251680931295e-08 first col mean 5.864513923370396e-07 all mean 1.1650107808236498e-05
6.479427975136787e-05 6.479427975136787e-05
rl training, epoch2, iter0, batch349/1133, batch loss:6.479427975136787e-05, Training time:35500.182126283646
batch reward last col mean 2.280559783685021e-06 first col mean 2.468446780312661e-07 all mean 1.1158253073517699e-05
8.379478094866499e-05 8.379478094866499e-05
rl training, epoch2, iter0, batch350/1133, batch loss:8.379478094866499e-05, Training time:35516.84565138817
batch reward last col mean 0.002867746166884899 first col mean 3.7906623617800506e-08 all mean 0.0028242249973118305
0.00028731164638884366 0.00028731164638884366
rl training, epoch2, iter0, batch351/1133, batch loss:0.00028731164638884366, Training time:35533.35332465172
batch reward last col mean 1.0967397656713729e-08 first col mean 2.3603578824804572e-07 all mean 3.2255195492325583e-07
3.6801546343667724e-07 3.680154350149678e-07
rl training, epoch2, iter0, batch352/1133, batch loss:3.680154350149678e-07, Training time:35549.64669299126
batch reward last col mean 6.392945550715012e-08 first col mean 1.1369237427061307e-06 all mean 1.8627619056132971e-06
2.789284963000682e-06 2.789284963000682e-06
rl training, epoch2, iter0, batch353/1133, batch loss:2.789284963000682e-06, Training time:35565.973433971405
batch reward last col mean 2.515409036618621e-08 first col mean 9.31481292099079e-09 all mean 7.49789478504681e-06
3.55778138327878e-05 3.557781019480899e-05
rl training, epoch2, iter0, batch354/1133, batch loss:3.557781019480899e-05, Training time:35582.37041544914
batch reward last col mean 5.860335505758485e-08 first col mean 8.761958270042669e-06 all mean 1.712273297016509e-05
3.6801109672524035e-05 3.680111694848165e-05
rl training, epoch2, iter0, batch355/1133, batch loss:3.680111694848165e-05, Training time:35598.77736496925
batch reward last col mean 4.0628233932693547e-07 first col mean 7.212499622255564e-05 all mean 3.187656147929374e-06
2.2231984075915534e-06 2.223198180217878e-06
rl training, epoch2, iter0, batch356/1133, batch loss:2.223198180217878e-06, Training time:35615.833698272705
batch reward last col mean 8.142995966409217e-07 first col mean 2.4234664053324195e-08 all mean 4.1664861782919616e-05
0.00017046104767359793 0.00017046104767359793
rl training, epoch2, iter0, batch357/1133, batch loss:0.00017046104767359793, Training time:35632.49175143242
batch reward last col mean 2.731098902586382e-08 first col mean 0.0014032096369192004 all mean 2.3747254090267234e-05
0.00014434134936891496 0.00014434133481699973
rl training, epoch2, iter0, batch358/1133, batch loss:0.00014434133481699973, Training time:35650.745958805084
batch reward last col mean 4.13286397815682e-05 first col mean 2.003953341045417e-06 all mean 3.508991721901111e-05
1.869735751824919e-05 1.869735751824919e-05
rl training, epoch2, iter0, batch359/1133, batch loss:1.869735751824919e-05, Training time:35669.24332737923
batch reward last col mean 9.445521982343053e-07 first col mean 8.383580279769376e-05 all mean 1.441897802578751e-05
3.214048410882242e-05 3.214048047084361e-05
rl training, epoch2, iter0, batch360/1133, batch loss:3.214048047084361e-05, Training time:35687.14340019226
batch reward last col mean 1.2582183899212396e-06 first col mean 3.488862830636208e-06 all mean 2.2155493297759676e-06
1.0242614735034294e-05 1.0242614735034294e-05
rl training, epoch2, iter0, batch361/1133, batch loss:1.0242614735034294e-05, Training time:35705.04672598839
batch reward last col mean 8.531583972626322e-08 first col mean 2.25710877543861e-07 all mean 5.5344548854918685e-06
2.5068404283956625e-05 2.506840246496722e-05
rl training, epoch2, iter0, batch362/1133, batch loss:2.506840246496722e-05, Training time:35723.082788705826
batch reward last col mean 2.309466111682923e-07 first col mean 3.4924878491437994e-06 all mean 7.146520601963857e-06
1.8811755580827594e-05 1.8811757399816997e-05
rl training, epoch2, iter0, batch363/1133, batch loss:1.8811757399816997e-05, Training time:35742.05545806885
batch reward last col mean 1.9185935684618016e-07 first col mean 1.2913315003970638e-05 all mean 1.2279633665457368e-05
7.05375787219964e-05 7.05375787219964e-05
rl training, epoch2, iter0, batch364/1133, batch loss:7.05375787219964e-05, Training time:35758.6833589077
batch reward last col mean 4.6137276399349503e-07 first col mean 8.18280823295936e-05 all mean 1.0167589607590344e-05
3.3408439776394516e-05 3.3408439776394516e-05
rl training, epoch2, iter0, batch365/1133, batch loss:3.3408439776394516e-05, Training time:35775.22343277931
batch reward last col mean 5.24670042523212e-07 first col mean 3.841178397578915e-07 all mean 1.1254675882810261e-05
2.447201040922664e-05 2.4472015866194852e-05
rl training, epoch2, iter0, batch366/1133, batch loss:2.4472015866194852e-05, Training time:35791.87208890915
batch reward last col mean 6.178657585564906e-09 first col mean 1.2992437348202657e-07 all mean 1.8564554693512036e-06
5.351202162273694e-06 5.351202162273694e-06
rl training, epoch2, iter0, batch367/1133, batch loss:5.351202162273694e-06, Training time:35808.19857597351
batch reward last col mean 5.973862471364555e-07 first col mean 0.000545155955478549 all mean 9.105067874770612e-06
4.998223084839992e-05 4.998223448637873e-05
rl training, epoch2, iter0, batch368/1133, batch loss:4.998223448637873e-05, Training time:35824.85770058632
batch reward last col mean 2.8692360501736403e-05 first col mean 2.2931610033083416e-07 all mean 3.2298368751071393e-05
1.943258939718362e-05 1.943258939718362e-05
rl training, epoch2, iter0, batch369/1133, batch loss:1.943258939718362e-05, Training time:35841.469408512115
batch reward last col mean 3.2996293697351575e-08 first col mean 5.49916194358957e-07 all mean 2.3989073270058725e-06
1.1522464774316177e-05 1.1522464774316177e-05
rl training, epoch2, iter0, batch370/1133, batch loss:1.1522464774316177e-05, Training time:35858.25491666794
batch reward last col mean 9.742831252879114e-08 first col mean 1.1035204806830734e-05 all mean 9.552265510137659e-06
7.738124259049073e-05 7.738124259049073e-05
rl training, epoch2, iter0, batch371/1133, batch loss:7.738124259049073e-05, Training time:35874.941343307495
batch reward last col mean 4.211544002430401e-09 first col mean 1.4599358166833554e-07 all mean 1.3623519407701679e-05
6.275514169828966e-05 6.275514169828966e-05
rl training, epoch2, iter0, batch372/1133, batch loss:6.275514169828966e-05, Training time:35892.05539369583
batch reward last col mean 1.8489663489162922e-07 first col mean 2.836689532159653e-07 all mean 2.1814605588588165e-06
3.4767354009090923e-06 3.4767349461617414e-06
rl training, epoch2, iter0, batch373/1133, batch loss:3.4767349461617414e-06, Training time:35909.034271001816
batch reward last col mean 4.4124612941232044e-06 first col mean 0.000554981583263725 all mean 1.2045918992953375e-05
1.761897510732524e-05 1.7618976926314645e-05
rl training, epoch2, iter0, batch374/1133, batch loss:1.7618976926314645e-05, Training time:35926.27456188202
batch reward last col mean 2.1908617142685216e-08 first col mean 7.034266502614628e-08 all mean 1.347113084193552e-06
2.7718137971532997e-06 2.7718135697796242e-06
rl training, epoch2, iter0, batch375/1133, batch loss:2.7718135697796242e-06, Training time:35943.06968522072
batch reward last col mean 2.465987769539879e-08 first col mean 1.6090519920908264e-06 all mean 4.046435788040981e-05
8.758250623941422e-05 8.75824989634566e-05
rl training, epoch2, iter0, batch376/1133, batch loss:8.75824989634566e-05, Training time:35960.05528187752
batch reward last col mean 6.524133766561135e-08 first col mean 3.234019095543772e-05 all mean 1.813674543882371e-06
3.7455345136550022e-06 3.7455342862813268e-06
rl training, epoch2, iter0, batch377/1133, batch loss:3.7455342862813268e-06, Training time:35979.25086688995
batch reward last col mean 5.212437770296674e-08 first col mean 8.383030092318222e-08 all mean 9.304031323154049e-07
1.7530369404994417e-06 1.7530371678731171e-06
rl training, epoch2, iter0, batch378/1133, batch loss:1.7530371678731171e-06, Training time:35997.60419178009
batch reward last col mean 2.4347844629346582e-08 first col mean 3.633761878063524e-07 all mean 1.4765049627385451e-06
1.747171268107195e-06 1.747171609167708e-06
rl training, epoch2, iter0, batch379/1133, batch loss:1.747171609167708e-06, Training time:36016.39137530327
batch reward last col mean 2.8756076630997995e-07 first col mean 1.9229333702242002e-05 all mean 1.0200900760537479e-05
7.531292067142203e-05 7.531292067142203e-05
rl training, epoch2, iter0, batch380/1133, batch loss:7.531292067142203e-05, Training time:36033.95892357826
batch reward last col mean 1.0855838894485714e-08 first col mean 6.674034835896236e-08 all mean 2.0860561562585644e-06
4.172197350271745e-06 4.1721978050190955e-06
rl training, epoch2, iter0, batch381/1133, batch loss:4.1721978050190955e-06, Training time:36050.38672566414
batch reward last col mean 6.132422925020364e-08 first col mean 4.341197268331598e-07 all mean 2.160331314371433e-05
0.00011436322529334575 0.00011436322529334575
rl training, epoch2, iter0, batch382/1133, batch loss:0.00011436322529334575, Training time:36067.38416552544
batch reward last col mean 8.396990125447701e-08 first col mean 6.283743658741514e-08 all mean 1.0138671314052772e-05
2.7983167456113733e-05 2.7983167456113733e-05
rl training, epoch2, iter0, batch383/1133, batch loss:2.7983167456113733e-05, Training time:36084.00030040741
batch reward last col mean 4.468907732757543e-08 first col mean 4.4107281382821384e-08 all mean 5.686810709448764e-06
2.7116677301819436e-05 2.711667912080884e-05
rl training, epoch2, iter0, batch384/1133, batch loss:2.711667912080884e-05, Training time:36100.78761935234
batch reward last col mean 1.0719837518990971e-05 first col mean 9.96857352220104e-07 all mean 1.4751920389244333e-05
5.3754843975184485e-05 5.3754843975184485e-05
rl training, epoch2, iter0, batch385/1133, batch loss:5.3754843975184485e-05, Training time:36117.76323509216
batch reward last col mean 0.0020898045040667057 first col mean 0.001603697775863111 all mean 0.0019660801626741886
0.00018705535330809653 0.00018705535330809653
rl training, epoch2, iter0, batch386/1133, batch loss:0.00018705535330809653, Training time:36134.399159908295
batch reward last col mean 3.7705276554333977e-06 first col mean 1.2473143442548462e-06 all mean 1.0464086699357722e-05
1.2598643479577731e-05 1.2598644389072433e-05
rl training, epoch2, iter0, batch387/1133, batch loss:1.2598644389072433e-05, Training time:36150.99713587761
batch reward last col mean 5.799090274649643e-08 first col mean 2.3822527509764768e-05 all mean 3.4418112591083627e-06
8.02147769718431e-06 8.02147769718431e-06
rl training, epoch2, iter0, batch388/1133, batch loss:8.02147769718431e-06, Training time:36167.60519647598
batch reward last col mean 1.3238815199656528e-07 first col mean 5.901998534341146e-08 all mean 1.4908141565683763e-05
5.509415132110007e-05 5.509415132110007e-05
rl training, epoch2, iter0, batch389/1133, batch loss:5.509415132110007e-05, Training time:36184.3917863369
batch reward last col mean 2.8702093146648622e-08 first col mean 1.8232020011055283e-05 all mean 4.682877261075191e-06
4.630754119716585e-06 4.630753210221883e-06
rl training, epoch2, iter0, batch390/1133, batch loss:4.630753210221883e-06, Training time:36202.96359395981
batch reward last col mean 1.2154891010141e-05 first col mean 5.524219432118116e-06 all mean 2.704814323806204e-05
0.00013369249063543975 0.0001336925197392702
rl training, epoch2, iter0, batch391/1133, batch loss:0.0001336925197392702, Training time:36221.49209737778
batch reward last col mean 5.049315632277285e-08 first col mean 4.2634437136257475e-07 all mean 1.997032086364925e-05
1.7512551494291984e-05 1.7512551494291984e-05
rl training, epoch2, iter0, batch392/1133, batch loss:1.7512551494291984e-05, Training time:36238.19541668892
batch reward last col mean 1.679438099699837e-08 first col mean 0.00026871150475926697 all mean 2.5778479539440013e-05
7.35482681193389e-05 7.354826084338129e-05
rl training, epoch2, iter0, batch393/1133, batch loss:7.354826084338129e-05, Training time:36254.712288856506
batch reward last col mean 3.5961721778221545e-07 first col mean 0.0012736025964841247 all mean 1.5948635336826555e-05
5.884642177989008e-06 5.8846439969784115e-06
rl training, epoch2, iter0, batch394/1133, batch loss:5.8846439969784115e-06, Training time:36271.170780181885
batch reward last col mean 1.2496302659315006e-08 first col mean 4.4176636038173456e-07 all mean 2.9462066777341533e-06
4.745701971842209e-06 4.745701971842209e-06
rl training, epoch2, iter0, batch395/1133, batch loss:4.745701971842209e-06, Training time:36288.14925289154
batch reward last col mean 1.3222371819665568e-07 first col mean 0.0016104737296700478 all mean 2.7816873625852168e-05
0.00011557497055036947 0.00011557497055036947
rl training, epoch2, iter0, batch396/1133, batch loss:0.00011557497055036947, Training time:36304.65780830383
batch reward last col mean 1.6644414699840127e-06 first col mean 0.0005082779680378735 all mean 5.782157677458599e-05
5.1037073717452586e-05 5.103706644149497e-05
rl training, epoch2, iter0, batch397/1133, batch loss:5.103706644149497e-05, Training time:36321.503895998
batch reward last col mean 2.425501008929132e-07 first col mean 3.2040300084190676e-06 all mean 7.663825272175018e-06
5.746267925132997e-05 5.746267925132997e-05
rl training, epoch2, iter0, batch398/1133, batch loss:5.746267925132997e-05, Training time:36338.11374807358
batch reward last col mean 5.306013918016106e-05 first col mean 5.129154345695497e-08 all mean 5.613910252577625e-05
9.338642485090531e-06 9.33864157559583e-06
rl training, epoch2, iter0, batch399/1133, batch loss:9.33864157559583e-06, Training time:36355.068605184555
batch reward last col mean 1.4729307622474153e-06 first col mean 5.728551968786633e-06 all mean 1.7394655742464238e-06
3.430797505643568e-06 3.430797505643568e-06
rl training, epoch2, iter0, batch400/1133, batch loss:3.430797505643568e-06, Training time:36371.612443208694
batch reward last col mean 1.72136900289388e-08 first col mean 1.2069397143932292e-06 all mean 9.921761829900788e-07
6.647360919487255e-07 6.647362056355632e-07
rl training, epoch2, iter0, batch401/1133, batch loss:6.647362056355632e-07, Training time:36388.4151365757
batch reward last col mean 2.7540349378796236e-07 first col mean 7.370710477516695e-07 all mean 9.682615200290456e-06
5.2901679737260565e-05 5.2901679737260565e-05
rl training, epoch2, iter0, batch402/1133, batch loss:5.2901679737260565e-05, Training time:36405.868624687195
batch reward last col mean 4.1508815229462925e-07 first col mean 2.1953107420813467e-07 all mean 3.393636870896444e-05
0.0001767710637068376 0.00017677104915492237
rl training, epoch2, iter0, batch403/1133, batch loss:0.00017677104915492237, Training time:36422.31755113602
batch reward last col mean 8.515024063626697e-08 first col mean 5.743697784055257e-07 all mean 3.7314737255655928e-06
1.889933082566131e-05 1.889933082566131e-05
rl training, epoch2, iter0, batch404/1133, batch loss:1.889933082566131e-05, Training time:36439.07768249512
batch reward last col mean 7.2627059921615e-09 first col mean 6.334375513006307e-08 all mean 9.864558023764403e-07
3.0862454423186136e-06 3.0862454423186136e-06
rl training, epoch2, iter0, batch405/1133, batch loss:3.0862454423186136e-06, Training time:36457.75372385979
batch reward last col mean 2.0956576918251812e-07 first col mean 3.2124840799951926e-05 all mean 5.388139925344149e-06
3.0435516237048432e-05 3.043551441805903e-05
rl training, epoch2, iter0, batch406/1133, batch loss:3.043551441805903e-05, Training time:36474.622816085815
batch reward last col mean 2.323096452983009e-07 first col mean 0.0005523760337382555 all mean 3.085258140345104e-05
0.00017237903375644237 0.00017237903375644237
rl training, epoch2, iter0, batch407/1133, batch loss:0.00017237903375644237, Training time:36491.95012450218
batch reward last col mean 1.244925783794315e-06 first col mean 1.5496540299864137e-06 all mean 2.0676388885476626e-05
3.8024001696612686e-05 3.8024001696612686e-05
rl training, epoch2, iter0, batch408/1133, batch loss:3.8024001696612686e-05, Training time:36509.09939169884
batch reward last col mean 1.1698904245349695e-06 first col mean 9.583708049376582e-09 all mean 2.2899082523508696e-06
5.0989565352210775e-06 5.0989565352210775e-06
rl training, epoch2, iter0, batch409/1133, batch loss:5.0989565352210775e-06, Training time:36526.502496004105
batch reward last col mean 2.9279473778842657e-07 first col mean 0.001694281934760511 all mean 3.5808345273835585e-05
5.672638144460507e-05 5.672638144460507e-05
rl training, epoch2, iter0, batch410/1133, batch loss:5.672638144460507e-05, Training time:36544.49078965187
batch reward last col mean 2.004780341735568e-08 first col mean 0.0005916679510846734 all mean 2.4388626115978695e-05
0.00011992458166787401 0.00011992458166787401
rl training, epoch2, iter0, batch411/1133, batch loss:0.00011992458166787401, Training time:36561.377749443054
batch reward last col mean 4.180745349913195e-07 first col mean 0.0006108692614361644 all mean 1.4871285202389117e-05
7.501438813051209e-05 7.50143954064697e-05
rl training, epoch2, iter0, batch412/1133, batch loss:7.50143954064697e-05, Training time:36577.93763637543
batch reward last col mean 2.3892537726055707e-08 first col mean 2.8391093920276944e-08 all mean 1.46169359140913e-05
7.754655962344259e-05 7.75465668994002e-05
rl training, epoch2, iter0, batch413/1133, batch loss:7.75465668994002e-05, Training time:36594.47603392601
batch reward last col mean 3.880278427459416e-07 first col mean 2.662301312739146e-07 all mean 5.447441708383849e-06
1.739155050017871e-05 1.739155050017871e-05
rl training, epoch2, iter0, batch414/1133, batch loss:1.739155050017871e-05, Training time:36611.30538606644
batch reward last col mean 0.0012850853381678462 first col mean 0.0001013361252262257 all mean 0.0012355110375210643
0.00010132096213055775 0.00010132096213055775
rl training, epoch2, iter0, batch415/1133, batch loss:0.00010132096213055775, Training time:36627.803371191025
batch reward last col mean 2.745879896792758e-07 first col mean 6.314844114285734e-08 all mean 2.5644783363532042e-06
9.88185183814494e-06 9.88185183814494e-06
rl training, epoch2, iter0, batch416/1133, batch loss:9.88185183814494e-06, Training time:36644.254989147186
batch reward last col mean 3.573318707594808e-08 first col mean 1.982442299208742e-08 all mean 6.650019486187375e-07
5.384940777730662e-07 5.384940777730662e-07
rl training, epoch2, iter0, batch417/1133, batch loss:5.384940777730662e-07, Training time:36660.87559771538
batch reward last col mean 3.1372329090118e-07 first col mean 4.356694262241945e-06 all mean 3.056144487345591e-05
0.00012416210665833205 0.00012416210665833205
rl training, epoch2, iter0, batch418/1133, batch loss:0.00012416210665833205, Training time:36677.56584596634
batch reward last col mean 4.7192145302688004e-07 first col mean 7.016486591737703e-08 all mean 1.0002982890000567e-05
5.183636676520109e-05 5.183636676520109e-05
rl training, epoch2, iter0, batch419/1133, batch loss:5.183636676520109e-05, Training time:36694.00364255905
batch reward last col mean 6.012529070176242e-07 first col mean 0.0004676486714743078 all mean 4.6844368625897914e-05
4.640764746000059e-05 4.6407654735958204e-05
rl training, epoch2, iter0, batch420/1133, batch loss:4.6407654735958204e-05, Training time:36711.08221626282
batch reward last col mean 1.3358741668412222e-08 first col mean 0.00044314871774986386 all mean 1.3464394214679487e-05
2.0941371985827573e-05 2.0941371985827573e-05
rl training, epoch2, iter0, batch421/1133, batch loss:2.0941371985827573e-05, Training time:36728.15844511986
batch reward last col mean 2.346747862702614e-07 first col mean 7.228287302041281e-08 all mean 1.366179458273109e-05
8.58436687849462e-05 8.58436687849462e-05
rl training, epoch2, iter0, batch422/1133, batch loss:8.58436687849462e-05, Training time:36746.79701590538
batch reward last col mean 1.2805469395971159e-07 first col mean 1.5408124909299659e-07 all mean 1.6004878489184193e-05
6.9127490860410035e-06 6.912748176546302e-06
rl training, epoch2, iter0, batch423/1133, batch loss:6.912748176546302e-06, Training time:36765.51190042496
batch reward last col mean 6.0832835515611805e-06 first col mean 1.1155289314501715e-07 all mean 1.9991884983028285e-05
5.832239367009606e-06 5.83223618377815e-06
rl training, epoch2, iter0, batch424/1133, batch loss:5.83223618377815e-06, Training time:36784.068674087524
batch reward last col mean 8.025727584026754e-05 first col mean 2.662053475432913e-07 all mean 7.639329851372167e-05
1.4176230251905508e-05 1.4176230251905508e-05
rl training, epoch2, iter0, batch425/1133, batch loss:1.4176230251905508e-05, Training time:36802.132796525955
batch reward last col mean 2.764273290267738e-07 first col mean 2.421453757506242e-07 all mean 2.8172733436804265e-05
7.315031689358875e-05 7.315032416954637e-05
rl training, epoch2, iter0, batch426/1133, batch loss:7.315032416954637e-05, Training time:36818.6154794693
batch reward last col mean 9.547239642415661e-06 first col mean 5.9422600315883756e-06 all mean 3.1308078177971765e-05
4.115619958611205e-05 4.1156195948133245e-05
rl training, epoch2, iter0, batch427/1133, batch loss:4.1156195948133245e-05, Training time:36835.666689157486
batch reward last col mean 1.2083908984550362e-08 first col mean 9.063246011464798e-07 all mean 2.1254609237075783e-06
3.2897064556891564e-06 3.2897055461944547e-06
rl training, epoch2, iter0, batch428/1133, batch loss:3.2897055461944547e-06, Training time:36852.287224531174
batch reward last col mean 7.37774783488021e-08 first col mean 4.148822796423701e-08 all mean 2.123025524269906e-06
4.547102435026318e-06 4.547102435026318e-06
rl training, epoch2, iter0, batch429/1133, batch loss:4.547102435026318e-06, Training time:36868.90765428543
batch reward last col mean 7.89155421898613e-07 first col mean 1.3813499890602543e-06 all mean 1.815800897020381e-05
0.00010733074304880574 0.00010733074304880574
rl training, epoch2, iter0, batch430/1133, batch loss:0.00010733074304880574, Training time:36885.510234594345
batch reward last col mean 1.7447263189751538e-07 first col mean 1.427497977601888e-07 all mean 2.7307980872137705e-06
9.569914254825562e-06 9.569914254825562e-06
rl training, epoch2, iter0, batch431/1133, batch loss:9.569914254825562e-06, Training time:36902.129765987396
batch reward last col mean 0.0007090589497238398 first col mean 1.1883496853215547e-07 all mean 0.0006460492732003331
6.247241253731772e-05 6.247241253731772e-05
rl training, epoch2, iter0, batch432/1133, batch loss:6.247241253731772e-05, Training time:36918.77385663986
batch reward last col mean 6.678981208096957e-07 first col mean 1.9872409211529884e-06 all mean 6.476736871263711e-06
3.652198938652873e-05 3.652198574854992e-05
rl training, epoch2, iter0, batch433/1133, batch loss:3.652198574854992e-05, Training time:36935.30148744583
batch reward last col mean 1.9908910076082975e-08 first col mean 0.001002935809083283 all mean 2.8138958441559225e-05
7.547511631855741e-05 7.54751090425998e-05
rl training, epoch2, iter0, batch434/1133, batch loss:7.54751090425998e-05, Training time:36952.15277957916
batch reward last col mean 5.995826768412371e-08 first col mean 4.545453435866875e-08 all mean 1.0542335985519458e-05
8.42162535263924e-06 8.421628081123345e-06
rl training, epoch2, iter0, batch435/1133, batch loss:8.421628081123345e-06, Training time:36969.570385694504
batch reward last col mean 6.335093871712161e-07 first col mean 3.41630652656022e-08 all mean 1.521625199529808e-05
4.733226160169579e-05 4.733226160169579e-05
rl training, epoch2, iter0, batch436/1133, batch loss:4.733226160169579e-05, Training time:36987.948546648026
batch reward last col mean 3.391785696749139e-08 first col mean 1.6676024188200245e-06 all mean 2.351149305468425e-05
9.088757360586897e-05 9.088757360586897e-05
rl training, epoch2, iter0, batch437/1133, batch loss:9.088757360586897e-05, Training time:37005.96664619446
batch reward last col mean 5.511448186723555e-09 first col mean 1.6204528208163538e-07 all mean 3.043245305889286e-05
0.00013200868852436543 0.00013200868852436543
rl training, epoch2, iter0, batch438/1133, batch loss:0.00013200868852436543, Training time:37025.032173871994
batch reward last col mean 3.589122599123584e-08 first col mean 1.1500393384267227e-06 all mean 5.553821392823011e-05
0.00020270909590180963 0.00020270909590180963
rl training, epoch2, iter0, batch439/1133, batch loss:0.00020270909590180963, Training time:37044.14709830284
batch reward last col mean 2.517094088716476e-08 first col mean 1.1853461501232232e-06 all mean 2.1712100988224847e-06
1.1343790902174078e-06 1.134379431277921e-06
rl training, epoch2, iter0, batch440/1133, batch loss:1.134379431277921e-06, Training time:37062.12655735016
batch reward last col mean 8.299596032657064e-08 first col mean 2.1321159948684e-08 all mean 4.9106142796517815e-06
3.921381903637666e-06 3.921381448890315e-06
rl training, epoch2, iter0, batch441/1133, batch loss:3.921381448890315e-06, Training time:37078.72269964218
batch reward last col mean 0.0001488702546339482 first col mean 0.0004449955595191568 all mean 0.00015318072109948844
3.123546048300341e-05 3.12354568450246e-05
rl training, epoch2, iter0, batch442/1133, batch loss:3.12354568450246e-05, Training time:37095.198162317276
batch reward last col mean 1.0086778701179355e-07 first col mean 5.572313739321544e-07 all mean 4.7306552914960776e-06
1.770940980350133e-05 1.770940980350133e-05
rl training, epoch2, iter0, batch443/1133, batch loss:1.770940980350133e-05, Training time:37111.887890815735
batch reward last col mean 4.7628154753454055e-09 first col mean 1.3728929992851135e-08 all mean 3.394904706510715e-05
0.00015067953791003674 0.00015067953791003674
rl training, epoch2, iter0, batch444/1133, batch loss:0.00015067953791003674, Training time:37128.41046285629
batch reward last col mean 8.906798143470951e-08 first col mean 1.3692518223251682e-05 all mean 7.893691531535296e-07
5.589997726929141e-07 5.589997726929141e-07
rl training, epoch2, iter0, batch445/1133, batch loss:5.589997726929141e-07, Training time:37145.095776319504
batch reward last col mean 1.0934937932916e-07 first col mean 4.0893519326345995e-07 all mean 1.8608820028021e-05
5.8032048400491476e-05 5.803205567644909e-05
rl training, epoch2, iter0, batch446/1133, batch loss:5.803205567644909e-05, Training time:37161.550768852234
batch reward last col mean 2.8038946766173467e-05 first col mean 1.5653711670893244e-05 all mean 2.9503687983378768e-05
1.1237350008741487e-05 1.1237350008741487e-05
rl training, epoch2, iter0, batch447/1133, batch loss:1.1237350008741487e-05, Training time:37178.35386824608
batch reward last col mean 1.0426872449897928e-06 first col mean 4.291287325486337e-08 all mean 2.4283549464598764e-06
1.3988570572109893e-05 1.3988570572109893e-05
rl training, epoch2, iter0, batch448/1133, batch loss:1.3988570572109893e-05, Training time:37195.01355791092
batch reward last col mean 6.51241505167377e-09 first col mean 3.057386493310332e-05 all mean 3.3284028177149594e-05
7.390968676190823e-05 7.390968676190823e-05
rl training, epoch2, iter0, batch449/1133, batch loss:7.390968676190823e-05, Training time:37211.85327291489
batch reward last col mean 3.6311058693172527e-07 first col mean 7.937572377159086e-08 all mean 2.7556228815228678e-05
0.00016111796139739454 0.00016111796139739454
rl training, epoch2, iter0, batch450/1133, batch loss:0.00016111796139739454, Training time:37229.37051773071
batch reward last col mean 0.0005451604956761003 first col mean 3.831334470305592e-05 all mean 0.0005288799875415862
6.135578587418422e-05 6.135578587418422e-05
rl training, epoch2, iter0, batch451/1133, batch loss:6.135578587418422e-05, Training time:37247.3223490715
batch reward last col mean 4.518101661687979e-07 first col mean 2.51744268098264e-07 all mean 7.07172284819535e-06
4.287782940082252e-05 4.287782940082252e-05
rl training, epoch2, iter0, batch452/1133, batch loss:4.287782940082252e-05, Training time:37264.112107753754
batch reward last col mean 2.2843501312763692e-07 first col mean 2.376182095531476e-07 all mean 2.506311284378171e-05
6.5524538513273e-05 6.5524538513273e-05
rl training, epoch2, iter0, batch453/1133, batch loss:6.5524538513273e-05, Training time:37281.55607008934
batch reward last col mean 5.413759396333262e-08 first col mean 2.4752819172135787e-07 all mean 2.3857651285652537e-06
1.8047870753434836e-06 1.804787302717159e-06
rl training, epoch2, iter0, batch454/1133, batch loss:1.804787302717159e-06, Training time:37298.99107146263
batch reward last col mean 1.1814018563427453e-07 first col mean 1.0573988220130559e-05 all mean 8.708100722287782e-06
8.579999303037766e-06 8.579998393543065e-06
rl training, epoch2, iter0, batch455/1133, batch loss:8.579998393543065e-06, Training time:37317.48519015312
batch reward last col mean 0.000292641983833164 first col mean 1.0355673794038012e-06 all mean 0.00026815987075679004
4.1055085603147745e-05 4.105508924112655e-05
rl training, epoch2, iter0, batch456/1133, batch loss:4.105508924112655e-05, Training time:37334.3087887764
batch reward last col mean 5.425225140243128e-07 first col mean 2.2450063141832288e-08 all mean 1.7684607882983983e-05
1.8281780285178684e-05 1.828178392315749e-05
rl training, epoch2, iter0, batch457/1133, batch loss:1.828178392315749e-05, Training time:37351.284888505936
batch reward last col mean 1.4475666887392435e-07 first col mean 8.156061994668562e-06 all mean 5.720392437069677e-06
2.0130913981120102e-05 2.0130913981120102e-05
rl training, epoch2, iter0, batch458/1133, batch loss:2.0130913981120102e-05, Training time:37367.79378628731
batch reward last col mean 1.1798491783565623e-07 first col mean 0.00013919177581556141 all mean 4.967214863427216e-06
2.9647271730937064e-06 2.9647271730937064e-06
rl training, epoch2, iter0, batch459/1133, batch loss:2.9647271730937064e-06, Training time:37384.375205516815
batch reward last col mean 0.006302461959421635 first col mean 0.001004847465083003 all mean 0.005954495631158352
0.0004997773794457316 0.0004997774376533926
rl training, epoch2, iter0, batch460/1133, batch loss:0.0004997774376533926, Training time:37401.12768530846
batch reward last col mean 2.1534872303163866e-06 first col mean 0.00027115741977468133 all mean 5.223544121690793e-06
2.2686047032038914e-06 2.2686053853249177e-06
rl training, epoch2, iter0, batch461/1133, batch loss:2.2686053853249177e-06, Training time:37417.71567797661
batch reward last col mean 1.6386898948894668e-08 first col mean 6.603262381332797e-09 all mean 3.4753668387565995e-06
1.84117798198713e-05 1.84117798198713e-05
rl training, epoch2, iter0, batch462/1133, batch loss:1.84117798198713e-05, Training time:37434.18181562424
batch reward last col mean 1.4591556407594908e-07 first col mean 0.0003124265349470079 all mean 3.939684575016145e-06
9.881605365080759e-07 9.881607638817513e-07
rl training, epoch2, iter0, batch463/1133, batch loss:9.881607638817513e-07, Training time:37450.82977795601
batch reward last col mean 5.5332350257231155e-08 first col mean 1.4876058230584022e-05 all mean 4.4484680984169245e-05
0.00015660170174669474 0.00015660168719477952
rl training, epoch2, iter0, batch464/1133, batch loss:0.00015660168719477952, Training time:37467.80648350716
batch reward last col mean 8.60352500353656e-09 first col mean 1.3685939848073758e-07 all mean 4.855327915720409e-06
2.0228404537192546e-05 2.0228404537192546e-05
rl training, epoch2, iter0, batch465/1133, batch loss:2.0228404537192546e-05, Training time:37484.522045612335
batch reward last col mean 2.672319396879175e-07 first col mean 2.6009649900515797e-07 all mean 7.088950042088982e-06
8.084326509560924e-06 8.084326509560924e-06
rl training, epoch2, iter0, batch466/1133, batch loss:8.084326509560924e-06, Training time:37502.12704706192
batch reward last col mean 7.663516932154835e-09 first col mean 0.0002756980247795582 all mean 3.787906962315901e-06
4.520307356870035e-06 4.520306902122684e-06
rl training, epoch2, iter0, batch467/1133, batch loss:4.520306902122684e-06, Training time:37519.94945549965
batch reward last col mean 1.688854354142677e-05 first col mean 1.734835279876279e-07 all mean 3.2530246244277805e-05
4.3273797928122804e-05 4.3273794290143996e-05
rl training, epoch2, iter0, batch468/1133, batch loss:4.3273794290143996e-05, Training time:37538.003823041916
batch reward last col mean 8.232462391788431e-07 first col mean 3.732247222387741e-08 all mean 1.7669610315351747e-05
3.80788987968117e-05 3.807890243479051e-05
rl training, epoch2, iter0, batch469/1133, batch loss:3.807890243479051e-05, Training time:37555.61049056053
batch reward last col mean 1.5154402177586235e-08 first col mean 0.0017838027561083436 all mean 2.1073967218399048e-05
4.160051048529567e-06 4.160047865298111e-06
rl training, epoch2, iter0, batch470/1133, batch loss:4.160047865298111e-06, Training time:37573.59983873367
batch reward last col mean 2.7801242197256215e-08 first col mean 2.337652347250696e-07 all mean 4.5053566282149404e-06
3.99723967348109e-06 3.9972378544916864e-06
rl training, epoch2, iter0, batch471/1133, batch loss:3.9972378544916864e-06, Training time:37591.22909975052
batch reward last col mean 2.97101276913736e-08 first col mean 0.00019856284779962152 all mean 6.577737167390296e-06
1.3413304259302095e-05 1.3413302440312691e-05
rl training, epoch2, iter0, batch472/1133, batch loss:1.3413302440312691e-05, Training time:37607.70259428024
batch reward last col mean 7.55713571720662e-08 first col mean 2.294798377988627e-06 all mean 7.3642804636619985e-06
9.71737699728692e-06 9.717376087792218e-06
rl training, epoch2, iter0, batch473/1133, batch loss:9.717376087792218e-06, Training time:37624.15810537338
batch reward last col mean 1.6072441155756678e-07 first col mean 1.2585529418629449e-07 all mean 6.968980414967518e-06
4.447684113983996e-05 4.447684113983996e-05
rl training, epoch2, iter0, batch474/1133, batch loss:4.447684113983996e-05, Training time:37641.03450298309
batch reward last col mean 6.199379640747793e-07 first col mean 1.11900590127334e-07 all mean 1.0254984772473108e-05
6.519990711240098e-05 6.519990711240098e-05
rl training, epoch2, iter0, batch475/1133, batch loss:6.519990711240098e-05, Training time:37657.88398504257
batch reward last col mean 1.1790248208853882e-06 first col mean 8.962852007243782e-07 all mean 1.4764687875867821e-05
7.077384361764416e-05 7.077385089360178e-05
rl training, epoch2, iter0, batch476/1133, batch loss:7.077385089360178e-05, Training time:37674.59560799599
batch reward last col mean 7.994040061021224e-07 first col mean 2.3017120838630944e-05 all mean 1.4385939721250907e-05
2.8251755793462507e-05 2.82517521554837e-05
rl training, epoch2, iter0, batch477/1133, batch loss:2.82517521554837e-05, Training time:37691.66507267952
batch reward last col mean 4.049861956900713e-08 first col mean 4.175342738221843e-08 all mean 2.9027057735220296e-06
9.565395885147154e-06 9.565395885147154e-06
rl training, epoch2, iter0, batch478/1133, batch loss:9.565395885147154e-06, Training time:37708.16021704674
batch reward last col mean 2.488758070740005e-07 first col mean 7.476266432604461e-07 all mean 1.692774094408378e-05
0.00011306760279694572 0.00011306761007290334
rl training, epoch2, iter0, batch479/1133, batch loss:0.00011306761007290334, Training time:37724.854639053345
batch reward last col mean 4.1152785001941083e-07 first col mean 2.414693085484032e-07 all mean 2.7918865725951036e-06
3.1852987376623787e-06 3.1852987376623787e-06
rl training, epoch2, iter0, batch480/1133, batch loss:3.1852987376623787e-06, Training time:37741.937771081924
batch reward last col mean 1.3138819809910274e-08 first col mean 2.218120158659076e-07 all mean 1.0598042763376725e-06
2.0548059183056466e-06 2.0548059183056466e-06
rl training, epoch2, iter0, batch481/1133, batch loss:2.0548059183056466e-06, Training time:37758.5195915699
batch reward last col mean 1.415444206287475e-08 first col mean 3.4762077660843715e-08 all mean 1.2615471860044636e-05
1.0400745850347448e-05 1.0400742212368641e-05
rl training, epoch2, iter0, batch482/1133, batch loss:1.0400742212368641e-05, Training time:37775.77488207817
batch reward last col mean 3.3595577406231314e-05 first col mean 5.437335062197235e-07 all mean 5.894761852687225e-05
3.904035111190751e-05 3.90403438359499e-05
rl training, epoch2, iter0, batch483/1133, batch loss:3.90403438359499e-05, Training time:37794.405071020126
batch reward last col mean 3.6512656720333325e-07 first col mean 1.1454833526158836e-07 all mean 2.2027204977348447e-05
7.171690231189132e-05 7.171690231189132e-05
rl training, epoch2, iter0, batch484/1133, batch loss:7.171690231189132e-05, Training time:37813.51665401459
batch reward last col mean 1.5540887687848226e-08 first col mean 2.766228988093644e-07 all mean 8.55460311868228e-05
0.00018969793745782226 0.00018969793745782226
rl training, epoch2, iter0, batch485/1133, batch loss:0.00018969793745782226, Training time:37832.026012182236
batch reward last col mean 2.9098647047476334e-08 first col mean 1.8468698499418679e-06 all mean 4.004699439974502e-05
4.592237382894382e-05 4.5922377466922626e-05
rl training, epoch2, iter0, batch486/1133, batch loss:4.5922377466922626e-05, Training time:37850.59834456444
batch reward last col mean 0.0001241842983290553 first col mean 1.5914763935143128e-05 all mean 8.704255742486566e-05
4.8915673687588423e-05 4.891568096354604e-05
rl training, epoch2, iter0, batch487/1133, batch loss:4.891568096354604e-05, Training time:37867.383128881454
batch reward last col mean 2.8321673894993182e-08 first col mean 3.0153521493048174e-06 all mean 3.6247754451324e-06
1.3677165952685755e-05 1.3677165952685755e-05
rl training, epoch2, iter0, batch488/1133, batch loss:1.3677165952685755e-05, Training time:37884.06179189682
batch reward last col mean 4.435970524241384e-08 first col mean 5.315938622629801e-08 all mean 1.8608161553856917e-05
0.00014447676949203014 0.00014447676949203014
rl training, epoch2, iter0, batch489/1133, batch loss:0.00014447676949203014, Training time:37900.508178949356
batch reward last col mean 3.855329566704313e-07 first col mean 3.5313775015310966e-08 all mean 8.49361367727397e-06
1.6477995814057067e-05 1.647799763304647e-05
rl training, epoch2, iter0, batch490/1133, batch loss:1.647799763304647e-05, Training time:37918.64329075813
batch reward last col mean 9.078797302208841e-05 first col mean 0.0011006321292370558 all mean 0.00010095407924382016
3.712878606165759e-05 3.7128782423678786e-05
rl training, epoch2, iter0, batch491/1133, batch loss:3.7128782423678786e-05, Training time:37937.6557135582
batch reward last col mean 6.270487347137532e-07 first col mean 1.044881301481837e-07 all mean 1.3134961136529455e-06
3.543039838405093e-06 3.5430393836577423e-06
rl training, epoch2, iter0, batch492/1133, batch loss:3.5430393836577423e-06, Training time:37955.91711616516
batch reward last col mean 6.038391120455344e-08 first col mean 1.9868986782967113e-05 all mean 2.413099900877569e-05
0.00013464481162372977 0.00013464481162372977
rl training, epoch2, iter0, batch493/1133, batch loss:0.00013464481162372977, Training time:37973.58179187775
batch reward last col mean 3.4439219689375022e-06 first col mean 5.3687287504544656e-08 all mean 2.4310480512212962e-05
0.00013812402903568 0.00013812404358759522
rl training, epoch2, iter0, batch494/1133, batch loss:0.00013812404358759522, Training time:37991.752128362656
batch reward last col mean 9.362415909208721e-08 first col mean 9.185157523461385e-08 all mean 4.135980816499796e-06
5.261995283944998e-06 5.261995283944998e-06
rl training, epoch2, iter0, batch495/1133, batch loss:5.261995283944998e-06, Training time:38008.8857729435
batch reward last col mean 4.245485030196505e-08 first col mean 3.154637084890055e-08 all mean 1.1914706192328595e-05
7.444881339324638e-05 7.444881339324638e-05
rl training, epoch2, iter0, batch496/1133, batch loss:7.444881339324638e-05, Training time:38025.55872130394
batch reward last col mean 4.428251543231454e-08 first col mean 1.57718045556976e-06 all mean 9.122974915953819e-06
1.796813558030408e-05 1.796813558030408e-05
rl training, epoch2, iter0, batch497/1133, batch loss:1.796813558030408e-05, Training time:38042.07190775871
batch reward last col mean 0.006122629623860121 first col mean 1.999549539277723e-07 all mean 0.005233669653534889
0.0007151365280151367 0.0007151365280151367
rl training, epoch2, iter0, batch498/1133, batch loss:0.0007151365280151367, Training time:38058.598299741745
batch reward last col mean 5.283583845994144e-07 first col mean 2.021881982727791e-06 all mean 2.6752171834232286e-05
0.0001454185985494405 0.0001454185985494405
rl training, epoch2, iter0, batch499/1133, batch loss:0.0001454185985494405, Training time:38075.699431180954
batch reward last col mean 4.5208545884634077e-07 first col mean 3.603706204557966e-07 all mean 2.0494615000643535e-06
6.052512162568746e-06 6.052512162568746e-06
rl training, epoch2, iter0, batch500/1133, batch loss:6.052512162568746e-06, Training time:38092.22502350807
batch reward last col mean 1.9700777897924127e-08 first col mean 2.7362907530914526e-06 all mean 1.7798267435864545e-05
2.1639238184434362e-05 2.1639234546455555e-05
rl training, epoch2, iter0, batch501/1133, batch loss:2.1639234546455555e-05, Training time:38109.18620276451
batch reward last col mean 9.004620551422704e-07 first col mean 2.1435612040932028e-07 all mean 5.738776849284477e-07
8.716817774256924e-07 8.716817774256924e-07
rl training, epoch2, iter0, batch502/1133, batch loss:8.716817774256924e-07, Training time:38125.92200899124
batch reward last col mean 2.4342092785900604e-08 first col mean 3.5315760982257416e-08 all mean 4.31296439273865e-06
5.247860372037394e-06 5.247859917290043e-06
rl training, epoch2, iter0, batch503/1133, batch loss:5.247859917290043e-06, Training time:38142.74307870865
batch reward last col mean 7.35099803250705e-08 first col mean 1.3667554412677418e-06 all mean 1.271353175980039e-05
1.690872522885911e-05 1.6908723409869708e-05
rl training, epoch2, iter0, batch504/1133, batch loss:1.6908723409869708e-05, Training time:38159.10618686676
batch reward last col mean 8.785089278262603e-08 first col mean 1.7099655451602302e-06 all mean 8.851858183334116e-06
6.9540114964183886e-06 6.954013315407792e-06
rl training, epoch2, iter0, batch505/1133, batch loss:6.954013315407792e-06, Training time:38177.68218111992
batch reward last col mean 4.510648977884557e-06 first col mean 1.053123355632124e-06 all mean 2.4542364371882286e-06
8.651219104649499e-06 8.651219104649499e-06
rl training, epoch2, iter0, batch506/1133, batch loss:8.651219104649499e-06, Training time:38196.04963994026
batch reward last col mean 5.8382500611742216e-08 first col mean 3.6851229197054636e-06 all mean 2.8860811198683223e-06
5.21321589985746e-06 5.213215445110109e-06
rl training, epoch2, iter0, batch507/1133, batch loss:5.213215445110109e-06, Training time:38213.338151454926
batch reward last col mean 4.804261379831587e-07 first col mean 2.6441543354849273e-07 all mean 3.2252396522380877e-06
1.0558736903476529e-05 1.0558736903476529e-05
rl training, epoch2, iter0, batch508/1133, batch loss:1.0558736903476529e-05, Training time:38230.06905603409
batch reward last col mean 1.564390549901873e-05 first col mean 1.5952586807088665e-07 all mean 4.941537190461531e-05
0.00016043297364376485 0.00016043298819568008
rl training, epoch2, iter0, batch509/1133, batch loss:0.00016043298819568008, Training time:38247.16462922096
batch reward last col mean 4.4114975139564194e-07 first col mean 3.6344041291158646e-05 all mean 4.1504372347844765e-05
0.00013608558219857514 0.00013608559675049037
rl training, epoch2, iter0, batch510/1133, batch loss:0.00013608559675049037, Training time:38263.69380450249
batch reward last col mean 1.763737600413151e-05 first col mean 1.1432994142523967e-06 all mean 1.31488604893093e-05
3.64912466466194e-06 3.6491248920356156e-06
rl training, epoch2, iter0, batch511/1133, batch loss:3.6491248920356156e-06, Training time:38280.263795375824
batch reward last col mean 3.2719153608695706e-08 first col mean 4.225430672022412e-08 all mean 9.411037353856955e-06
3.983337228419259e-05 3.98333759221714e-05
rl training, epoch2, iter0, batch512/1133, batch loss:3.98333759221714e-05, Training time:38296.785145282745
batch reward last col mean 4.602528349550994e-07 first col mean 4.440012446593755e-07 all mean 5.340448296919931e-06
7.134033694455866e-06 7.134033239708515e-06
rl training, epoch2, iter0, batch513/1133, batch loss:7.134033239708515e-06, Training time:38313.801508426666
batch reward last col mean 0.00025305754388682544 first col mean 0.0008954147924669087 all mean 0.0002453248598612845
7.122631359379739e-05 7.1226320869755e-05
rl training, epoch2, iter0, batch514/1133, batch loss:7.1226320869755e-05, Training time:38330.274458646774
batch reward last col mean 6.2594640581892236e-09 first col mean 3.7229440295050154e-06 all mean 1.1901351172127761e-05
4.7953315515769646e-05 4.795331915374845e-05
rl training, epoch2, iter0, batch515/1133, batch loss:4.795331915374845e-05, Training time:38347.14808177948
batch reward last col mean 4.808318720961324e-08 first col mean 8.339695341419429e-05 all mean 4.552193786366843e-06
6.8862855187035166e-06 6.886284154461464e-06
rl training, epoch2, iter0, batch516/1133, batch loss:6.886284154461464e-06, Training time:38363.66756820679
batch reward last col mean 1.496648494025976e-08 first col mean 8.944687579059973e-06 all mean 5.166140454093693e-06
2.867017246899195e-05 2.867017246899195e-05
rl training, epoch2, iter0, batch517/1133, batch loss:2.867017246899195e-05, Training time:38380.26185154915
batch reward last col mean 4.784439511240635e-07 first col mean 2.404771112196613e-05 all mean 7.19514309821534e-06
3.469421426416375e-05 3.4694217902142555e-05
rl training, epoch2, iter0, batch518/1133, batch loss:3.4694217902142555e-05, Training time:38397.06576347351
batch reward last col mean 0.0008325594826601446 first col mean 1.354142966647487e-07 all mean 0.0006836906541138887
6.149497494334355e-05 6.149497494334355e-05
rl training, epoch2, iter0, batch519/1133, batch loss:6.149497494334355e-05, Training time:38413.88198566437
batch reward last col mean 4.0569901216258586e-08 first col mean 5.6900724302977324e-05 all mean 1.8893342712544836e-06
4.327411716076313e-06 4.327411716076313e-06
rl training, epoch2, iter0, batch520/1133, batch loss:4.327411716076313e-06, Training time:38431.28337216377
batch reward last col mean 0.0003367405151948333 first col mean 1.2215899687362253e-06 all mean 0.00030610364046879113
6.740020762663335e-05 6.740020762663335e-05
rl training, epoch2, iter0, batch521/1133, batch loss:6.740020762663335e-05, Training time:38447.90843963623
batch reward last col mean 5.016221393816522e-07 first col mean 3.384447779808397e-07 all mean 3.2283496693708e-05
9.936553396983072e-05 9.936554124578834e-05
rl training, epoch2, iter0, batch522/1133, batch loss:9.936554124578834e-05, Training time:38465.08083462715
batch reward last col mean 6.892334702968128e-09 first col mean 6.229014957170875e-07 all mean 1.5250299838953651e-05
6.289209977694554e-06 6.289205884968396e-06
rl training, epoch2, iter0, batch523/1133, batch loss:6.289205884968396e-06, Training time:38482.94263339043
batch reward last col mean 7.189915152139292e-08 first col mean 0.0001391660189256072 all mean 1.2616887033800595e-05
1.9873597921105102e-05 1.9873597921105102e-05
rl training, epoch2, iter0, batch524/1133, batch loss:1.9873597921105102e-05, Training time:38500.5663087368
batch reward last col mean 3.630928517850407e-07 first col mean 7.852771091165778e-07 all mean 1.6234051145147532e-05
2.8024613129673526e-05 2.802461494866293e-05
rl training, epoch2, iter0, batch525/1133, batch loss:2.802461494866293e-05, Training time:38517.20724129677
batch reward last col mean 9.772495104698464e-05 first col mean 1.0965391794570678e-07 all mean 0.00010726755863288417
1.9766615878324956e-05 1.9766615878324956e-05
rl training, epoch2, iter0, batch526/1133, batch loss:1.9766615878324956e-05, Training time:38534.342380046844
batch reward last col mean 5.154703330845223e-08 first col mean 0.00038226498872973025 all mean 1.6941654394031502e-05
2.2011670807842165e-05 2.2011667169863358e-05
rl training, epoch2, iter0, batch527/1133, batch loss:2.2011667169863358e-05, Training time:38551.626814603806
batch reward last col mean 4.709229273203164e-08 first col mean 1.7941903934115544e-05 all mean 2.3863971364335157e-05
3.814966476056725e-05 3.814966112258844e-05
rl training, epoch2, iter0, batch528/1133, batch loss:3.814966112258844e-05, Training time:38568.3026971817
batch reward last col mean 5.808840697341111e-08 first col mean 4.4883464056511e-07 all mean 1.877081194834318e-05
6.293160549830645e-05 6.293159822234884e-05
rl training, epoch2, iter0, batch529/1133, batch loss:6.293159822234884e-05, Training time:38584.931597709656
batch reward last col mean 5.916477618939098e-08 first col mean 4.230273020766617e-07 all mean 3.764871507883072e-06
1.1472550795588177e-05 1.147255261457758e-05
rl training, epoch2, iter0, batch530/1133, batch loss:1.147255261457758e-05, Training time:38602.356189489365
batch reward last col mean 0.00022717466345056891 first col mean 5.184403562452644e-05 all mean 6.943809421500191e-05
3.6021061532665044e-05 3.602105789468624e-05
rl training, epoch2, iter0, batch531/1133, batch loss:3.602105789468624e-05, Training time:38619.09946656227
batch reward last col mean 5.257806279246324e-08 first col mean 2.973957577978581e-07 all mean 1.6147689166245982e-05
4.135345807299018e-05 4.135346534894779e-05
rl training, epoch2, iter0, batch532/1133, batch loss:4.135346534894779e-05, Training time:38635.67853140831
batch reward last col mean 2.835789416621992e-07 first col mean 0.00030877627432346344 all mean 1.9211103790439665e-05
3.861288496409543e-05 3.8612877688137814e-05
rl training, epoch2, iter0, batch533/1133, batch loss:3.8612877688137814e-05, Training time:38652.755059719086
batch reward last col mean 0.0003326288715470582 first col mean 1.1417250789236277e-06 all mean 0.00027271805447526276
2.0111447156523354e-05 2.0111447156523354e-05
rl training, epoch2, iter0, batch534/1133, batch loss:2.0111447156523354e-05, Training time:38671.172842502594
batch reward last col mean 1.6967827320968354e-07 first col mean 4.479423296288587e-06 all mean 1.4119420484348666e-05
9.05361957848072e-06 9.053622306964826e-06
rl training, epoch2, iter0, batch535/1133, batch loss:9.053622306964826e-06, Training time:38690.49887800217
batch reward last col mean 9.260370603669799e-08 first col mean 0.0001211040944326669 all mean 2.7814974146167515e-06
3.1264596600522054e-06 3.12645943267853e-06
rl training, epoch2, iter0, batch536/1133, batch loss:3.12645943267853e-06, Training time:38708.67736196518
batch reward last col mean 1.1829531842977303e-07 first col mean 8.695163705851883e-05 all mean 2.0652527382480912e-05
7.470068521797657e-05 7.470068521797657e-05
rl training, epoch2, iter0, batch537/1133, batch loss:7.470068521797657e-05, Training time:38727.50505542755
batch reward last col mean 0.0004508449346758425 first col mean 1.6202724850700179e-07 all mean 0.0004263213195372373
7.296081457752734e-05 7.296081457752734e-05
rl training, epoch2, iter0, batch538/1133, batch loss:7.296081457752734e-05, Training time:38745.16415429115
batch reward last col mean 9.0464752133812e-08 first col mean 4.7597484808648005e-05 all mean 3.999999080406269e-06
8.095226803561673e-06 8.095226803561673e-06
rl training, epoch2, iter0, batch539/1133, batch loss:8.095226803561673e-06, Training time:38761.80309510231
batch reward last col mean 9.41936129095211e-09 first col mean 6.107930516918714e-07 all mean 9.277427466258814e-07
3.391546670172829e-06 3.3915468975465046e-06
rl training, epoch2, iter0, batch540/1133, batch loss:3.3915468975465046e-06, Training time:38779.196447849274
batch reward last col mean 6.961069942690301e-09 first col mean 1.4146463399811182e-05 all mean 1.578526644152589e-05
5.93231015955098e-05 5.93231015955098e-05
rl training, epoch2, iter0, batch541/1133, batch loss:5.93231015955098e-05, Training time:38795.93161416054
batch reward last col mean 4.182335760560818e-05 first col mean 6.596764734467797e-08 all mean 5.148736818227917e-05
2.413224683550652e-05 2.4132243197527714e-05
rl training, epoch2, iter0, batch542/1133, batch loss:2.4132243197527714e-05, Training time:38812.732009887695
batch reward last col mean 6.6602505732760164e-09 first col mean 6.904728070367128e-05 all mean 4.539006113191135e-06
1.2794899703294504e-05 1.2794899703294504e-05
rl training, epoch2, iter0, batch543/1133, batch loss:1.2794899703294504e-05, Training time:38829.27381515503
batch reward last col mean 4.711971257620462e-08 first col mean 1.3954818314232398e-05 all mean 1.6726937246858142e-05
8.632473327452317e-05 8.632472599856555e-05
rl training, epoch2, iter0, batch544/1133, batch loss:8.632472599856555e-05, Training time:38845.99267625809
batch reward last col mean 1.1396036114774688e-08 first col mean 0.00011975597590208054 all mean 2.0547689928207546e-05
7.4103095357713755e-06 7.41030680728727e-06
rl training, epoch2, iter0, batch545/1133, batch loss:7.41030680728727e-06, Training time:38862.59614825249
batch reward last col mean 3.921933284800616e-07 first col mean 0.0005321979406289756 all mean 9.312490874435753e-06
1.704837086435873e-05 1.7048369045369327e-05
rl training, epoch2, iter0, batch546/1133, batch loss:1.7048369045369327e-05, Training time:38879.36491537094
batch reward last col mean 2.8693028397697162e-08 first col mean 5.69679650652688e-05 all mean 1.057994450093247e-05
1.8881015421357006e-05 1.888101724034641e-05
rl training, epoch2, iter0, batch547/1133, batch loss:1.888101724034641e-05, Training time:38895.785383462906
batch reward last col mean 5.1543544543619646e-08 first col mean 6.779382033528236e-07 all mean 2.052083118542214e-06
2.3092284209269565e-06 2.3092284209269565e-06
rl training, epoch2, iter0, batch548/1133, batch loss:2.3092284209269565e-06, Training time:38912.64577293396
batch reward last col mean 1.0243336134863057e-07 first col mean 1.6637925170925882e-07 all mean 1.2151676855864935e-06
9.783245786820771e-07 9.783244649952394e-07
rl training, epoch2, iter0, batch549/1133, batch loss:9.783244649952394e-07, Training time:38929.2013232708
batch reward last col mean 1.0518895088296176e-08 first col mean 6.215656611630038e-08 all mean 2.1018218831159174e-05
3.2484965686307987e-06 3.2484924759046407e-06
rl training, epoch2, iter0, batch550/1133, batch loss:3.2484924759046407e-06, Training time:38945.77064990997
batch reward last col mean 2.013635196362884e-07 first col mean 1.533927502350707e-06 all mean 1.4842788004898466e-05
0.00010749962530098855 0.00010749962530098855
rl training, epoch2, iter0, batch551/1133, batch loss:0.00010749962530098855, Training time:38963.94623494148
batch reward last col mean 1.7741075453159283e-07 first col mean 8.48431866984356e-08 all mean 3.701466994243674e-06
1.4374305692399503e-06 1.4374305692399503e-06
rl training, epoch2, iter0, batch552/1133, batch loss:1.4374305692399503e-06, Training time:38982.55522274971
batch reward last col mean 7.546709639427718e-07 first col mean 0.00010911039862548932 all mean 5.429537850432098e-06
3.2572638701822143e-06 3.257264324929565e-06
rl training, epoch2, iter0, batch553/1133, batch loss:3.257264324929565e-06, Training time:39000.783544540405
batch reward last col mean 3.8133407542773057e-07 first col mean 5.745976523030549e-06 all mean 1.2097217449991149e-06
1.273938437407196e-06 1.273938437407196e-06
rl training, epoch2, iter0, batch554/1133, batch loss:1.273938437407196e-06, Training time:39016.91479563713
batch reward last col mean 3.0900618952500736e-08 first col mean 4.9416090774911936e-08 all mean 3.432199491726351e-06
4.3592463043751195e-06 4.3592463043751195e-06
rl training, epoch2, iter0, batch555/1133, batch loss:4.3592463043751195e-06, Training time:39035.42000603676
batch reward last col mean 2.5477745566604426e-06 first col mean 1.0665197578418883e-06 all mean 2.2930328213988105e-06
5.168499228602741e-06 5.168499228602741e-06
rl training, epoch2, iter0, batch556/1133, batch loss:5.168499228602741e-06, Training time:39054.0386633873
batch reward last col mean 1.1961777090618853e-05 first col mean 2.0746694644913077e-05 all mean 4.205721052130684e-05
0.00013971149746794254 0.00013971151201985776
rl training, epoch2, iter0, batch557/1133, batch loss:0.00013971151201985776, Training time:39070.80818271637
batch reward last col mean 4.708594403268762e-08 first col mean 0.002267510164529085 all mean 3.813730290858075e-05
3.4678629162954167e-05 3.467863643891178e-05
rl training, epoch2, iter0, batch558/1133, batch loss:3.467863643891178e-05, Training time:39087.29865217209
batch reward last col mean 5.3465154081777655e-08 first col mean 2.580856971690082e-06 all mean 2.9278326110215858e-06
1.435663398297038e-05 1.435663398297038e-05
rl training, epoch2, iter0, batch559/1133, batch loss:1.435663398297038e-05, Training time:39104.01554608345
batch reward last col mean 9.93359717540443e-05 first col mean 1.3334869208847522e-07 all mean 9.186899842461571e-05
1.0531460247875657e-05 1.0531460247875657e-05
rl training, epoch2, iter0, batch560/1133, batch loss:1.0531460247875657e-05, Training time:39120.57654309273
batch reward last col mean 3.411739953662618e-06 first col mean 5.794588986418603e-08 all mean 7.0870883064344525e-06
3.912051397492178e-05 3.912051397492178e-05
rl training, epoch2, iter0, batch561/1133, batch loss:3.912051397492178e-05, Training time:39137.10182929039
batch reward last col mean 1.4456959185338292e-08 first col mean 9.634778734834981e-07 all mean 1.2907343261758797e-05
5.1922273996751755e-05 5.1922273996751755e-05
rl training, epoch2, iter0, batch562/1133, batch loss:5.1922273996751755e-05, Training time:39153.62600898743
batch reward last col mean 6.77522535852404e-08 first col mean 3.9231835557984596e-08 all mean 1.3024598047195468e-05
3.887897401000373e-05 3.887897401000373e-05
rl training, epoch2, iter0, batch563/1133, batch loss:3.887897401000373e-05, Training time:39170.32712173462
batch reward last col mean 3.4352840572182686e-08 first col mean 7.526882086494879e-07 all mean 7.2139046096708626e-06
3.073845073231496e-05 3.073845073231496e-05
rl training, epoch2, iter0, batch564/1133, batch loss:3.073845073231496e-05, Training time:39187.01564669609
batch reward last col mean 6.469460913649527e-06 first col mean 2.342800826227176e-06 all mean 2.1294940779625904e-06
1.220065996676567e-06 1.2200661103634047e-06
rl training, epoch2, iter0, batch565/1133, batch loss:1.2200661103634047e-06, Training time:39203.49476933479
batch reward last col mean 3.228168665714293e-08 first col mean 3.857269064155844e-07 all mean 1.814479946915526e-05
3.286392893642187e-05 3.286392893642187e-05
rl training, epoch2, iter0, batch566/1133, batch loss:3.286392893642187e-05, Training time:39220.135929346085
batch reward last col mean 1.887476202000471e-07 first col mean 0.00036684388760477304 all mean 1.1843959327961784e-05
5.6484300330339465e-06 5.648429578286596e-06
rl training, epoch2, iter0, batch567/1133, batch loss:5.648429578286596e-06, Training time:39236.691329956055
batch reward last col mean 4.6254515773114235e-09 first col mean 1.4112055396253709e-05 all mean 2.2730220734956674e-05
7.108572026481852e-05 7.108572754077613e-05
rl training, epoch2, iter0, batch568/1133, batch loss:7.108572754077613e-05, Training time:39253.21520614624
batch reward last col mean 8.425723763139104e-07 first col mean 2.5494719224639084e-08 all mean 2.6563133360468782e-05
5.048400635132566e-05 5.0484002713346854e-05
rl training, epoch2, iter0, batch569/1133, batch loss:5.0484002713346854e-05, Training time:39269.75384902954
batch reward last col mean 1.038979959844255e-07 first col mean 2.359051443079352e-08 all mean 1.476615943829529e-05
6.148603279143572e-05 6.148603279143572e-05
rl training, epoch2, iter0, batch570/1133, batch loss:6.148603279143572e-05, Training time:39286.48889541626
batch reward last col mean 5.951749315613597e-08 first col mean 4.6055566826908034e-07 all mean 3.2591374292678665e-06
1.2132941265008412e-05 1.2132941265008412e-05
rl training, epoch2, iter0, batch571/1133, batch loss:1.2132941265008412e-05, Training time:39302.93882536888
batch reward last col mean 6.8864456359563064e-09 first col mean 1.3458318790071644e-05 all mean 6.898300398461288e-06
3.0194472856237553e-05 3.0194474675226957e-05
rl training, epoch2, iter0, batch572/1133, batch loss:3.0194474675226957e-05, Training time:39321.53148150444
batch reward last col mean 2.77720175745344e-07 first col mean 7.926182377104851e-08 all mean 4.471668944461271e-06
1.7824790120357648e-05 1.7824790120357648e-05
rl training, epoch2, iter0, batch573/1133, batch loss:1.7824790120357648e-05, Training time:39339.083174705505
batch reward last col mean 8.353954399353825e-06 first col mean 4.367581823316868e-06 all mean 2.9756092772004195e-05
4.9300437240162864e-05 4.930043360218406e-05
rl training, epoch2, iter0, batch574/1133, batch loss:4.930043360218406e-05, Training time:39356.3302898407
batch reward last col mean 8.02467911853455e-06 first col mean 0.0001437632308807224 all mean 1.5122439435799606e-05
2.8294953153817914e-05 2.8294953153817914e-05
rl training, epoch2, iter0, batch575/1133, batch loss:2.8294953153817914e-05, Training time:39375.26270866394
batch reward last col mean 1.065101969288662e-06 first col mean 7.860565887085613e-08 all mean 2.5003705559356604e-06
6.424290859285975e-06 6.424290859285975e-06
rl training, epoch2, iter0, batch576/1133, batch loss:6.424290859285975e-06, Training time:39392.814940452576
batch reward last col mean 5.222717663855292e-05 first col mean 3.361193279260988e-08 all mean 7.883946091169491e-05
9.092038817470893e-05 9.092038817470893e-05
rl training, epoch2, iter0, batch577/1133, batch loss:9.092038817470893e-05, Training time:39409.43908905983
batch reward last col mean 1.5003500948296278e-06 first col mean 1.201110535475891e-07 all mean 1.28532246890245e-06
4.1667945538392814e-07 4.1667945538392814e-07
rl training, epoch2, iter0, batch578/1133, batch loss:4.1667945538392814e-07, Training time:39426.04348397255
batch reward last col mean 2.9547148727715467e-08 first col mean 1.180689423563308e-06 all mean 1.7353992006974295e-05
5.430187229649164e-05 5.430186865851283e-05
rl training, epoch2, iter0, batch579/1133, batch loss:5.430186865851283e-05, Training time:39442.49726200104
batch reward last col mean 8.100738568828092e-08 first col mean 3.2113609904627083e-07 all mean 3.686367108457489e-06
1.5352354239439592e-05 1.5352352420450188e-05
rl training, epoch2, iter0, batch580/1133, batch loss:1.5352352420450188e-05, Training time:39459.17241692543
batch reward last col mean 1.0798395067013189e-08 first col mean 8.263388053819654e-07 all mean 2.4003908038139343e-05
0.00018372252816334367 0.00018372251361142844
rl training, epoch2, iter0, batch581/1133, batch loss:0.00018372251361142844, Training time:39476.00374293327
batch reward last col mean 2.1343309981602943e-06 first col mean 4.485540102905361e-06 all mean 1.1354242133165826e-06
2.0079226032976294e-06 2.0079226032976294e-06
rl training, epoch2, iter0, batch582/1133, batch loss:2.0079226032976294e-06, Training time:39492.81818270683
batch reward last col mean 8.983065526990686e-07 first col mean 2.6980606193660606e-08 all mean 2.2923773940419778e-05
0.00010415229917271063 0.00010415231372462586
rl training, epoch2, iter0, batch583/1133, batch loss:0.00010415231372462586, Training time:39510.162244558334
batch reward last col mean 1.0154948313356726e-06 first col mean 0.0008199666626751423 all mean 1.923517629620619e-05
1.9455850633676164e-05 1.945585427165497e-05
rl training, epoch2, iter0, batch584/1133, batch loss:1.945585427165497e-05, Training time:39526.69117808342
batch reward last col mean 0.00012697884812951088 first col mean 1.804316070774803e-06 all mean 0.00011357751645846292
3.678002394735813e-05 3.678002394735813e-05
rl training, epoch2, iter0, batch585/1133, batch loss:3.678002394735813e-05, Training time:39543.89296555519
batch reward last col mean 1.1788191756068045e-08 first col mean 0.001670983387157321 all mean 1.8001528587774374e-05
0.00013809828669764102 0.00013809828669764102
rl training, epoch2, iter0, batch586/1133, batch loss:0.00013809828669764102, Training time:39560.686052799225
batch reward last col mean 2.1607525923172943e-05 first col mean 1.9139572486892575e-06 all mean 6.627608399867313e-06
1.8134174752049148e-05 1.813417657103855e-05
rl training, epoch2, iter0, batch587/1133, batch loss:1.813417657103855e-05, Training time:39578.36307501793
batch reward last col mean 6.444762590263053e-08 first col mean 2.1856735088476853e-07 all mean 2.9826145691913553e-05
0.0001993261685129255 0.0001993261685129255
rl training, epoch2, iter0, batch588/1133, batch loss:0.0001993261685129255, Training time:39595.52383041382
batch reward last col mean 3.34846319560711e-08 first col mean 4.119439367400446e-08 all mean 5.848365276506229e-07
1.3896165000915062e-06 1.3896166137783439e-06
rl training, epoch2, iter0, batch589/1133, batch loss:1.3896166137783439e-06, Training time:39611.96151280403
batch reward last col mean 2.8811482479795814e-06 first col mean 2.8718432076857425e-05 all mean 2.554450838943012e-05
2.1980931705911644e-05 2.1980926248943433e-05
rl training, epoch2, iter0, batch590/1133, batch loss:2.1980926248943433e-05, Training time:39629.4870736599
batch reward last col mean 1.1249422726677949e-07 first col mean 4.458252078620717e-07 all mean 2.9016903226875e-06
1.36030621433747e-05 1.36030621433747e-05
rl training, epoch2, iter0, batch591/1133, batch loss:1.36030621433747e-05, Training time:39647.518832445145
batch reward last col mean 0.0001491216680733487 first col mean 1.268168580281781e-05 all mean 0.00018650139099918306
0.00031952044810168445 0.00031952044810168445
rl training, epoch2, iter0, batch592/1133, batch loss:0.00031952044810168445, Training time:39664.04120826721
batch reward last col mean 2.4947457433199816e-08 first col mean 0.00015284575056284666 all mean 1.1695170542225242e-05
5.313157816999592e-05 5.313157816999592e-05
rl training, epoch2, iter0, batch593/1133, batch loss:5.313157816999592e-05, Training time:39680.93503284454
batch reward last col mean 4.4396692828740925e-06 first col mean 9.61954447120661e-06 all mean 4.246679964126088e-06
1.5634837836842053e-05 1.5634839655831456e-05
rl training, epoch2, iter0, batch594/1133, batch loss:1.5634839655831456e-05, Training time:39697.64881443977
batch reward last col mean 6.362744642274265e-08 first col mean 2.924875843746122e-05 all mean 7.472906418115599e-06
9.184522241412196e-06 9.184522241412196e-06
rl training, epoch2, iter0, batch595/1133, batch loss:9.184522241412196e-06, Training time:39714.11242508888
batch reward last col mean 6.245547723437994e-08 first col mean 3.006706350561217e-08 all mean 6.376929832185851e-06
3.586652019293979e-05 3.586652019293979e-05
rl training, epoch2, iter0, batch596/1133, batch loss:3.586652019293979e-05, Training time:39731.06641936302
batch reward last col mean 4.7572189032507595e-06 first col mean 7.365535566350445e-05 all mean 1.2264278666407336e-05
1.7037753423210233e-05 1.7037755242199637e-05
rl training, epoch2, iter0, batch597/1133, batch loss:1.7037755242199637e-05, Training time:39747.806723594666
batch reward last col mean 1.360063794919597e-08 first col mean 2.168010723835323e-05 all mean 1.5381207049358636e-05
2.448689701850526e-05 2.448689701850526e-05
rl training, epoch2, iter0, batch598/1133, batch loss:2.448689701850526e-05, Training time:39764.51025032997
batch reward last col mean 6.954390983082703e-07 first col mean 9.30473834159784e-06 all mean 9.854850759438705e-06
6.614644371438771e-05 6.61464364384301e-05
rl training, epoch2, iter0, batch599/1133, batch loss:6.61464364384301e-05, Training time:39781.19830965996
batch reward last col mean 1.093420394226996e-07 first col mean 1.4391508784683538e-07 all mean 7.587073923787102e-06
1.554254959046375e-05 1.5542545952484943e-05
rl training, epoch2, iter0, batch600/1133, batch loss:1.5542545952484943e-05, Training time:39798.05641198158
batch reward last col mean 3.584699754810572e-07 first col mean 9.334531227978005e-07 all mean 3.739961357496213e-06
2.2043359422241338e-05 2.204335578426253e-05
rl training, epoch2, iter0, batch601/1133, batch loss:2.204335578426253e-05, Training time:39814.84595990181
batch reward last col mean 2.4553118649350836e-08 first col mean 4.923196684103459e-05 all mean 1.1164438546984456e-05
1.6347003111150116e-05 1.6347001292160712e-05
rl training, epoch2, iter0, batch602/1133, batch loss:1.6347001292160712e-05, Training time:39832.05318522453
batch reward last col mean 1.1810927389888093e-05 first col mean 2.6893233098235214e-06 all mean 2.330201823497191e-05
6.811235653003678e-05 6.811235653003678e-05
rl training, epoch2, iter0, batch603/1133, batch loss:6.811235653003678e-05, Training time:39851.31434464455
batch reward last col mean 2.4069313653285462e-08 first col mean 1.749729381117504e-05 all mean 1.8498425333746127e-06
3.710657210831414e-06 3.7106574382050894e-06
rl training, epoch2, iter0, batch604/1133, batch loss:3.7106574382050894e-06, Training time:39869.4024040699
batch reward last col mean 9.36496871872805e-06 first col mean 8.143788932102325e-08 all mean 1.2189149856567383e-05
6.229537393664941e-05 6.229537393664941e-05
rl training, epoch2, iter0, batch605/1133, batch loss:6.229537393664941e-05, Training time:39888.4141972065
batch reward last col mean 4.345572435227041e-08 first col mean 7.624308864251361e-07 all mean 4.50468451163033e-06
7.678462679905351e-06 7.67846177041065e-06
rl training, epoch2, iter0, batch606/1133, batch loss:7.67846177041065e-06, Training time:39908.0016207695
batch reward last col mean 3.433103046290853e-08 first col mean 1.508828404439555e-06 all mean 1.615840483282227e-05
2.5349301722599193e-05 2.5349305360578e-05
rl training, epoch2, iter0, batch607/1133, batch loss:2.5349305360578e-05, Training time:39925.08075261116
batch reward last col mean 7.597931173108918e-09 first col mean 3.437365592162678e-08 all mean 2.320048224646598e-06
3.2298303267452866e-06 3.229830554118962e-06
rl training, epoch2, iter0, batch608/1133, batch loss:3.229830554118962e-06, Training time:39941.643971681595
batch reward last col mean 8.868967427133612e-08 first col mean 0.0011656630085781217 all mean 1.6862990378285758e-05
7.575363724754425e-06 7.575364179501776e-06
rl training, epoch2, iter0, batch609/1133, batch loss:7.575364179501776e-06, Training time:39958.274518728256
batch reward last col mean 1.6361850541102285e-08 first col mean 3.0975442655289953e-07 all mean 2.054880496871192e-05
9.007887274492532e-05 9.007887274492532e-05
rl training, epoch2, iter0, batch610/1133, batch loss:9.007887274492532e-05, Training time:39974.95562291145
batch reward last col mean 5.1404544620936576e-08 first col mean 0.00011932537017855793 all mean 5.250647518550977e-05
0.00014023699623066932 0.00014023699623066932
rl training, epoch2, iter0, batch611/1133, batch loss:0.00014023699623066932, Training time:39991.40138602257
batch reward last col mean 2.3051451591982186e-07 first col mean 0.0006602627108804882 all mean 3.834065864793956e-05
5.071404666523449e-05 5.07140503032133e-05
rl training, epoch2, iter0, batch612/1133, batch loss:5.07140503032133e-05, Training time:40008.109320640564
batch reward last col mean 1.966450042800716e-07 first col mean 3.3035681212822965e-07 all mean 4.944832653563935e-06
1.42122889883467e-05 1.4212290807336103e-05
rl training, epoch2, iter0, batch613/1133, batch loss:1.4212290807336103e-05, Training time:40024.58270263672
batch reward last col mean 1.0375041270549445e-08 first col mean 3.825018168868155e-08 all mean 9.197794383908331e-07
1.51739016018837e-06 1.51739016018837e-06
rl training, epoch2, iter0, batch614/1133, batch loss:1.51739016018837e-06, Training time:40041.25277590752
batch reward last col mean 7.3535225055820774e-06 first col mean 0.001664872164838016 all mean 2.2505957531393506e-05
2.2107124095782638e-05 2.2107124095782638e-05
rl training, epoch2, iter0, batch615/1133, batch loss:2.2107124095782638e-05, Training time:40057.66372036934
batch reward last col mean 9.788508492647452e-08 first col mean 1.6284916171116492e-07 all mean 2.582456909294706e-05
0.00013215398939792067 0.00013215398939792067
rl training, epoch2, iter0, batch616/1133, batch loss:0.00013215398939792067, Training time:40074.550404548645
batch reward last col mean 1.8714094039751217e-05 first col mean 1.4291946399680455e-06 all mean 2.182020034524612e-05
2.254336686746683e-05 2.254336686746683e-05
rl training, epoch2, iter0, batch617/1133, batch loss:2.254336686746683e-05, Training time:40091.14351820946
batch reward last col mean 1.0685171503155289e-07 first col mean 0.0008864299161359668 all mean 4.000477201770991e-05
0.00014442014798987657 0.0001444201625417918
rl training, epoch2, iter0, batch618/1133, batch loss:0.0001444201625417918, Training time:40109.129124403
batch reward last col mean 1.1505784414111986e-06 first col mean 2.333235329388117e-07 all mean 3.9463743632950354e-06
4.1746129681996536e-06 4.1746129681996536e-06
rl training, epoch2, iter0, batch619/1133, batch loss:4.1746129681996536e-06, Training time:40128.27299308777
batch reward last col mean 1.6829635569592938e-06 first col mean 1.8381753079665941e-06 all mean 2.018826535277185e-06
7.143453331082128e-06 7.143453331082128e-06
rl training, epoch2, iter0, batch620/1133, batch loss:7.143453331082128e-06, Training time:40148.23301434517
batch reward last col mean 1.5349290833910345e-06 first col mean 9.665510560807888e-07 all mean 1.744466135278344e-05
4.7753474063938484e-05 4.7753474063938484e-05
rl training, epoch2, iter0, batch621/1133, batch loss:4.7753474063938484e-05, Training time:40167.17983198166
batch reward last col mean 8.662143358151297e-08 first col mean 0.001559370313771069 all mean 2.2189047740539536e-05
5.7492710766382515e-05 5.7492699852446094e-05
rl training, epoch2, iter0, batch622/1133, batch loss:5.7492699852446094e-05, Training time:40185.91918325424
batch reward last col mean 1.5915694575596717e-06 first col mean 6.729448159603635e-06 all mean 6.965688612581289e-07
7.690599659326836e-07 7.690599090892647e-07
rl training, epoch2, iter0, batch623/1133, batch loss:7.690599090892647e-07, Training time:40202.45106625557
batch reward last col mean 2.038418097072281e-05 first col mean 2.3347231490333797e-06 all mean 2.3481377866119146e-05
1.2035016879963223e-05 1.203501506097382e-05
rl training, epoch2, iter0, batch624/1133, batch loss:1.203501506097382e-05, Training time:40219.08620047569
batch reward last col mean 5.885583131970407e-09 first col mean 0.000982015742920339 all mean 6.329004099825397e-05
0.00014568779442925006 0.00014568777987733483
rl training, epoch2, iter0, batch625/1133, batch loss:0.00014568777987733483, Training time:40236.0726480484
batch reward last col mean 2.786467057092068e-08 first col mean 2.8205226954014506e-06 all mean 3.41138957082876e-06
9.020155630423687e-06 9.020154720928986e-06
rl training, epoch2, iter0, batch626/1133, batch loss:9.020154720928986e-06, Training time:40252.62596035004
batch reward last col mean 2.7729628371275794e-08 first col mean 6.841112281108508e-06 all mean 1.6876489098649472e-05
5.0523540267022327e-05 5.0523540267022327e-05
rl training, epoch2, iter0, batch627/1133, batch loss:5.0523540267022327e-05, Training time:40269.22804379463
batch reward last col mean 3.3025411738663024e-08 first col mean 0.000448434439022094 all mean 1.3808989024255425e-05
5.653241532854736e-05 5.6532408052589744e-05
rl training, epoch2, iter0, batch628/1133, batch loss:5.6532408052589744e-05, Training time:40285.783836603165
batch reward last col mean 9.430390690567947e-08 first col mean 0.0003206360852345824 all mean 2.0139632397331297e-05
0.00012357570813037455 0.00012357570813037455
rl training, epoch2, iter0, batch629/1133, batch loss:0.00012357570813037455, Training time:40302.330713272095
batch reward last col mean 1.8283915892425284e-07 first col mean 2.732487658363425e-08 all mean 1.6824444173835218e-05
0.00012188139226054773 0.00012188138498459011
rl training, epoch2, iter0, batch630/1133, batch loss:0.00012188138498459011, Training time:40319.06932973862
batch reward last col mean 1.3399805709468637e-07 first col mean 0.0007405828218907118 all mean 4.344485205365345e-05
0.00011802771041402593 0.00011802770313806832
rl training, epoch2, iter0, batch631/1133, batch loss:0.00011802770313806832, Training time:40335.608583688736
batch reward last col mean 2.543262134224733e-08 first col mean 9.499618869313053e-08 all mean 2.5161753001157194e-05
9.584992949385196e-05 9.584992949385196e-05
rl training, epoch2, iter0, batch632/1133, batch loss:9.584992949385196e-05, Training time:40352.16856646538
batch reward last col mean 9.351422704639845e-06 first col mean 4.486913383061619e-07 all mean 4.322431323089404e-06
2.1805532014695928e-05 2.1805532014695928e-05
rl training, epoch2, iter0, batch633/1133, batch loss:2.1805532014695928e-05, Training time:40369.862651348114
batch reward last col mean 1.2865248777416127e-07 first col mean 4.7330655661426135e-07 all mean 1.0330608347430825e-05
2.415928611299023e-05 2.4159287931979634e-05
rl training, epoch2, iter0, batch634/1133, batch loss:2.4159287931979634e-05, Training time:40389.01778769493
batch reward last col mean 2.9383247834857684e-08 first col mean 5.797635367343901e-06 all mean 3.3692183933453634e-05
3.5795474104816094e-05 3.57954777427949e-05
rl training, epoch2, iter0, batch635/1133, batch loss:3.57954777427949e-05, Training time:40406.97129225731
batch reward last col mean 4.6168631229193124e-07 first col mean 5.307093715600786e-07 all mean 1.4289897080743685e-05
3.8981892430456355e-05 3.8981892430456355e-05
rl training, epoch2, iter0, batch636/1133, batch loss:3.8981892430456355e-05, Training time:40425.55981993675
batch reward last col mean 1.4314105456492143e-08 first col mean 2.1909028191657853e-07 all mean 3.9324718272837345e-06
2.0780382328666747e-05 2.078038414765615e-05
rl training, epoch2, iter0, batch637/1133, batch loss:2.078038414765615e-05, Training time:40445.121091127396
batch reward last col mean 2.2250046072258556e-07 first col mean 6.017859504936496e-06 all mean 7.2171892497863155e-06
1.4369338714459445e-05 1.436934144294355e-05
rl training, epoch2, iter0, batch638/1133, batch loss:1.436934144294355e-05, Training time:40461.9081659317
batch reward last col mean 3.85634564281645e-07 first col mean 7.394159524665156e-07 all mean 4.097010787518229e-06
2.2513417206937447e-05 2.2513417206937447e-05
rl training, epoch2, iter0, batch639/1133, batch loss:2.2513417206937447e-05, Training time:40478.54273056984
batch reward last col mean 8.49635835038498e-05 first col mean 1.0057866717261277e-07 all mean 8.473131310893223e-05
8.696918484929483e-06 8.696920303918887e-06
rl training, epoch2, iter0, batch640/1133, batch loss:8.696920303918887e-06, Training time:40495.21368122101
batch reward last col mean 1.6283015824569702e-08 first col mean 8.817437446850818e-09 all mean 4.064221229782561e-06
6.178558578540105e-06 6.178559942782158e-06
rl training, epoch2, iter0, batch641/1133, batch loss:6.178559942782158e-06, Training time:40511.74661040306
batch reward last col mean 2.9020457148476453e-08 first col mean 6.485162430180935e-06 all mean 1.36744702103897e-05
0.00011365905811544508 0.00011365905811544508
rl training, epoch2, iter0, batch642/1133, batch loss:0.00011365905811544508, Training time:40528.39452815056
batch reward last col mean 4.1984801413263995e-08 first col mean 1.2726493991976895e-07 all mean 1.7987715182243846e-05
9.808651520870626e-05 9.808651520870626e-05
rl training, epoch2, iter0, batch643/1133, batch loss:9.808651520870626e-05, Training time:40544.94103765488
batch reward last col mean 1.3913274088395156e-08 first col mean 8.437305950792506e-06 all mean 1.3427477369987173e-06
8.831655122776283e-07 8.831655122776283e-07
rl training, epoch2, iter0, batch644/1133, batch loss:8.831655122776283e-07, Training time:40561.627675533295
batch reward last col mean 3.527680192405569e-08 first col mean 1.868983723340989e-08 all mean 2.9899038054281846e-05
3.929040758521296e-05 3.929040758521296e-05
rl training, epoch2, iter0, batch645/1133, batch loss:3.929040758521296e-05, Training time:40578.54761695862
batch reward last col mean 3.892240840741579e-08 first col mean 0.00010096992627950385 all mean 1.6969643183983862e-05
4.072918090969324e-05 4.0729177271714434e-05
rl training, epoch2, iter0, batch646/1133, batch loss:4.0729177271714434e-05, Training time:40595.19329047203
batch reward last col mean 1.861109240053338e-07 first col mean 2.90425958837659e-07 all mean 2.3330254407483153e-05
0.0001218296165461652 0.00012182960927020758
rl training, epoch2, iter0, batch647/1133, batch loss:0.00012182960927020758, Training time:40611.94663929939
batch reward last col mean 2.702516965769064e-08 first col mean 2.5398944103471877e-07 all mean 1.4665383787360042e-05
7.270245532708941e-06 7.270238711498678e-06
rl training, epoch2, iter0, batch648/1133, batch loss:7.270238711498678e-06, Training time:40629.34704089165
batch reward last col mean 5.169465211452007e-08 first col mean 5.0389587613608455e-08 all mean 2.7924630558118224e-05
0.00014630559599027038 0.00014630559599027038
rl training, epoch2, iter0, batch649/1133, batch loss:0.00014630559599027038, Training time:40646.548073768616
batch reward last col mean 3.2695609775146295e-08 first col mean 0.00010626817675074562 all mean 9.594058610673528e-06
1.4970408301451243e-05 1.4970409210945945e-05
rl training, epoch2, iter0, batch650/1133, batch loss:1.4970409210945945e-05, Training time:40663.34114575386
batch reward last col mean 4.099375018995488e-06 first col mean 1.0356211532780435e-05 all mean 4.064715994900325e-06
8.729846285859821e-07 8.729844580557256e-07
rl training, epoch2, iter0, batch651/1133, batch loss:8.729844580557256e-07, Training time:40680.28752756119
batch reward last col mean 1.6303219751989673e-07 first col mean 8.890754543244839e-05 all mean 7.771370292175561e-06
4.925599114358192e-06 4.925596840621438e-06
rl training, epoch2, iter0, batch652/1133, batch loss:4.925596840621438e-06, Training time:40699.065522909164
batch reward last col mean 4.884366688884256e-09 first col mean 4.4294597500993405e-07 all mean 2.1228099285508506e-05
0.00010742397716967389 0.0001074239844456315
rl training, epoch2, iter0, batch653/1133, batch loss:0.0001074239844456315, Training time:40715.58926200867
batch reward last col mean 1.8029255443252623e-05 first col mean 1.6724695228731434e-07 all mean 4.67050849692896e-05
0.00010106259287567809 0.00010106258559972048
rl training, epoch2, iter0, batch654/1133, batch loss:0.00010106258559972048, Training time:40731.971740961075
batch reward last col mean 4.447634438520254e-08 first col mean 0.0007463626097887754 all mean 1.3427392332232557e-05
2.2077631001593545e-05 2.207762918260414e-05
rl training, epoch2, iter0, batch655/1133, batch loss:2.207762918260414e-05, Training time:40748.54875445366
batch reward last col mean 5.373825473498073e-08 first col mean 1.4294371908363246e-07 all mean 1.4382394510903396e-05
5.703808710677549e-06 5.7038091654249e-06
rl training, epoch2, iter0, batch656/1133, batch loss:5.7038091654249e-06, Training time:40765.05265188217
batch reward last col mean 1.5814940468317218e-07 first col mean 1.0344154361519031e-05 all mean 3.389314997548354e-06
7.4167460297758225e-06 7.4167460297758225e-06
rl training, epoch2, iter0, batch657/1133, batch loss:7.4167460297758225e-06, Training time:40781.64734339714
batch reward last col mean 1.8010397297985037e-06 first col mean 3.9739166624030986e-08 all mean 3.559475590009242e-05
0.00018301716772839427 0.00018301716772839427
rl training, epoch2, iter0, batch658/1133, batch loss:0.00018301716772839427, Training time:40798.140599012375
batch reward last col mean 1.4402360193344066e-07 first col mean 2.3478509802998815e-08 all mean 1.4376753824763e-05
0.00010682813444873318 0.00010682813444873318
rl training, epoch2, iter0, batch659/1133, batch loss:0.00010682813444873318, Training time:40814.70401382446
batch reward last col mean 1.4435377337917998e-08 first col mean 3.1409729928100205e-08 all mean 2.4480968932039104e-05
3.210484283044934e-05 3.2104839192470536e-05
rl training, epoch2, iter0, batch660/1133, batch loss:3.2104839192470536e-05, Training time:40831.22813177109
batch reward last col mean 2.9316854011085525e-07 first col mean 1.3113969998812536e-07 all mean 1.3967358427180443e-05
7.296059629879892e-05 7.296059629879892e-05
rl training, epoch2, iter0, batch661/1133, batch loss:7.296059629879892e-05, Training time:40848.01069879532
batch reward last col mean 1.5613269965797372e-07 first col mean 2.0516232325462624e-05 all mean 6.339813580780174e-07
1.215782049257541e-06 1.215782049257541e-06
rl training, epoch2, iter0, batch662/1133, batch loss:1.215782049257541e-06, Training time:40864.91291356087
batch reward last col mean 5.161496829941825e-08 first col mean 6.854144157841802e-05 all mean 1.5853784134378657e-05
0.00014100126281846315 0.00014100126281846315
rl training, epoch2, iter0, batch663/1133, batch loss:0.00014100126281846315, Training time:40881.71848869324
batch reward last col mean 4.566310884968061e-09 first col mean 2.5282792748271277e-08 all mean 4.6864231990184635e-05
0.00020125943410675973 0.00020125944865867496
rl training, epoch2, iter0, batch664/1133, batch loss:0.00020125944865867496, Training time:40898.2968788147
batch reward last col mean 3.2549883144383784e-07 first col mean 8.510247653248371e-07 all mean 1.6598590946159675e-06
4.452382654562825e-06 4.452382654562825e-06
rl training, epoch2, iter0, batch665/1133, batch loss:4.452382654562825e-06, Training time:40914.82593989372
batch reward last col mean 3.714452390113365e-08 first col mean 0.0006283536786213517 all mean 1.3860351828043349e-05
3.4212258469779044e-05 3.4212258469779044e-05
rl training, epoch2, iter0, batch666/1133, batch loss:3.4212258469779044e-05, Training time:40931.53102970123
batch reward last col mean 1.0749382539643193e-07 first col mean 2.8277800083742477e-06 all mean 6.787076927139424e-06
5.874899670743616e-06 5.874897851754213e-06
rl training, epoch2, iter0, batch667/1133, batch loss:5.874897851754213e-06, Training time:40949.67583274841
batch reward last col mean 7.4497918944871344e-09 first col mean 6.274226649338743e-08 all mean 1.256665746041108e-05
3.208734415238723e-05 3.208734779036604e-05
rl training, epoch2, iter0, batch668/1133, batch loss:3.208734779036604e-05, Training time:40966.931529045105
batch reward last col mean 2.124405540371299e-08 first col mean 2.0589970972650917e-07 all mean 1.0719688816607231e-06
7.485352284675173e-07 7.485351716240984e-07
rl training, epoch2, iter0, batch669/1133, batch loss:7.485351716240984e-07, Training time:40985.65150332451
batch reward last col mean 2.654649506439455e-05 first col mean 8.080175575742032e-06 all mean 3.721693065017462e-05
5.589666398009285e-05 5.5896660342114046e-05
rl training, epoch2, iter0, batch670/1133, batch loss:5.5896660342114046e-05, Training time:41003.66686940193
batch reward last col mean 2.2589265427086502e-05 first col mean 9.35978334837273e-08 all mean 2.0153769582975656e-05
7.191505574155599e-06 7.191506483650301e-06
rl training, epoch2, iter0, batch671/1133, batch loss:7.191506483650301e-06, Training time:41021.5182261467
batch reward last col mean 3.1260718458270276e-08 first col mean 2.330407551198732e-05 all mean 6.927658887434518e-06
2.192928150179796e-06 2.192926558564068e-06
rl training, epoch2, iter0, batch672/1133, batch loss:2.192926558564068e-06, Training time:41038.3292632103
batch reward last col mean 7.477555641344225e-07 first col mean 2.999516084400966e-07 all mean 1.9025817891815677e-05
5.59613763471134e-05 5.59613763471134e-05
rl training, epoch2, iter0, batch673/1133, batch loss:5.59613763471134e-05, Training time:41055.27714109421
batch reward last col mean 6.598990864858933e-08 first col mean 1.286435349356907e-06 all mean 1.5209283446893096e-05
6.820601265644655e-05 6.820601265644655e-05
rl training, epoch2, iter0, batch674/1133, batch loss:6.820601265644655e-05, Training time:41072.19530892372
batch reward last col mean 1.4581150509229701e-08 first col mean 2.991711198774283e-07 all mean 2.4340726668015122e-05
8.603997412137687e-05 8.603997412137687e-05
rl training, epoch2, iter0, batch675/1133, batch loss:8.603997412137687e-05, Training time:41088.75546646118
batch reward last col mean 2.0525654065295384e-08 first col mean 8.428608921917657e-09 all mean 1.7289428342337487e-06
6.61926060274709e-06 6.619260147999739e-06
rl training, epoch2, iter0, batch676/1133, batch loss:6.619260147999739e-06, Training time:41108.33452653885
batch reward last col mean 5.26688017998822e-06 first col mean 1.1745362371584633e-06 all mean 4.3116746383020654e-05
5.895931462873705e-05 5.895931099075824e-05
rl training, epoch2, iter0, batch677/1133, batch loss:5.895931099075824e-05, Training time:41126.38902306557
batch reward last col mean 2.8099857445340604e-06 first col mean 8.681944905220007e-07 all mean 2.3259344743564725e-05
1.4256220310926437e-05 1.4256215763452929e-05
rl training, epoch2, iter0, batch678/1133, batch loss:1.4256215763452929e-05, Training time:41145.82882761955
batch reward last col mean 2.0499724087130744e-06 first col mean 3.7999921431719486e-08 all mean 2.0774964468728285e-06
2.8122469757363433e-06 2.8122472031100187e-06
rl training, epoch2, iter0, batch679/1133, batch loss:2.8122472031100187e-06, Training time:41163.343008995056
batch reward last col mean 7.691735959269863e-08 first col mean 2.20841030795782e-07 all mean 1.1376042493793648e-05
2.6034995244117454e-06 2.6034958864329383e-06
rl training, epoch2, iter0, batch680/1133, batch loss:2.6034958864329383e-06, Training time:41181.91364336014
batch reward last col mean 1.670119900154532e-07 first col mean 0.00016549094289075583 all mean 4.831118985748617e-06
1.985079052246874e-06 1.985079506994225e-06
rl training, epoch2, iter0, batch681/1133, batch loss:1.985079506994225e-06, Training time:41198.880551338196
batch reward last col mean 2.6431905553181423e-08 first col mean 3.196347824996337e-05 all mean 1.7708478480926715e-05
7.960902439663187e-05 7.960900984471664e-05
rl training, epoch2, iter0, batch682/1133, batch loss:7.960900984471664e-05, Training time:41215.69407892227
batch reward last col mean 6.145609354746284e-09 first col mean 5.893975796311679e-08 all mean 1.0556692586760619e-06
3.1430497529072454e-06 3.1430492981598945e-06
rl training, epoch2, iter0, batch683/1133, batch loss:3.1430492981598945e-06, Training time:41232.687794446945
batch reward last col mean 1.25467884970476e-08 first col mean 6.171228505991166e-08 all mean 2.9261620511533692e-05
6.702089012833312e-05 6.702089012833312e-05
rl training, epoch2, iter0, batch684/1133, batch loss:6.702089012833312e-05, Training time:41249.40070915222
batch reward last col mean 2.405021959361875e-08 first col mean 1.2124684367620375e-08 all mean 1.8620929040480405e-05
1.631662053114269e-05 1.63166259881109e-05
rl training, epoch2, iter0, batch685/1133, batch loss:1.63166259881109e-05, Training time:41266.044711112976
batch reward last col mean 1.8829624082172813e-07 first col mean 1.902542862808332e-05 all mean 3.1721897357783746e-06
7.906324754003435e-06 7.906323844508734e-06
rl training, epoch2, iter0, batch686/1133, batch loss:7.906323844508734e-06, Training time:41282.55205655098
batch reward last col mean 4.58115367862888e-09 first col mean 0.0003666645206976682 all mean 4.401679234433686e-06
5.3345092965173535e-06 5.3345092965173535e-06
rl training, epoch2, iter0, batch687/1133, batch loss:5.3345092965173535e-06, Training time:41299.0229780674
batch reward last col mean 4.951312462253554e-07 first col mean 2.9335693398024887e-05 all mean 1.1036755495297257e-05
4.387960507301614e-05 4.387960507301614e-05
rl training, epoch2, iter0, batch688/1133, batch loss:4.387960507301614e-05, Training time:41316.1663043499
batch reward last col mean 0.004298111889511347 first col mean 5.946958026470384e-06 all mean 0.003781368024647236
0.0002910572220571339 0.0002910572220571339
rl training, epoch2, iter0, batch689/1133, batch loss:0.0002910572220571339, Training time:41333.512649059296
batch reward last col mean 4.874100909546542e-07 first col mean 1.6699272009645938e-07 all mean 3.363562427693978e-05
9.280257654609159e-05 9.280256927013397e-05
rl training, epoch2, iter0, batch690/1133, batch loss:9.280256927013397e-05, Training time:41350.287313222885
batch reward last col mean 2.0762590224876476e-07 first col mean 1.27072979694276e-07 all mean 8.030658023017168e-07
2.7627829695120454e-06 2.7627834242593963e-06
rl training, epoch2, iter0, batch691/1133, batch loss:2.7627834242593963e-06, Training time:41367.174760341644
batch reward last col mean 3.3266678656218573e-07 first col mean 6.488543391469648e-08 all mean 4.474974502954865e-06
1.7724307781463722e-06 1.7724297549648327e-06
rl training, epoch2, iter0, batch692/1133, batch loss:1.7724297549648327e-06, Training time:41384.25175523758
batch reward last col mean 1.800183468958494e-07 first col mean 1.5008835134722176e-06 all mean 2.1476000711118104e-06
3.1057568321557483e-06 3.1057568321557483e-06
rl training, epoch2, iter0, batch693/1133, batch loss:3.1057568321557483e-06, Training time:41401.3792321682
batch reward last col mean 7.0699899268333866e-09 first col mean 0.0003181066131219268 all mean 7.234333224914735e-06
7.709753845119849e-06 7.709753845119849e-06
rl training, epoch2, iter0, batch694/1133, batch loss:7.709753845119849e-06, Training time:41419.35494041443
batch reward last col mean 3.0301173126190406e-08 first col mean 1.5134643035707995e-05 all mean 9.320167919213418e-06
2.4451466742902994e-05 2.4451463104924187e-05
rl training, epoch2, iter0, batch695/1133, batch loss:2.4451463104924187e-05, Training time:41437.76019692421
batch reward last col mean 1.0759205792965076e-07 first col mean 1.091043699830152e-07 all mean 1.932569284690544e-05
9.196085738949478e-05 9.196085738949478e-05
rl training, epoch2, iter0, batch696/1133, batch loss:9.196085738949478e-05, Training time:41455.312395095825
batch reward last col mean 1.1933490640103628e-08 first col mean 5.514500145409329e-08 all mean 2.0570059859892353e-06
3.0789497031946667e-06 3.0789497031946667e-06
rl training, epoch2, iter0, batch697/1133, batch loss:3.0789497031946667e-06, Training time:41472.38722395897
batch reward last col mean 3.68246304560671e-08 first col mean 8.831230502437393e-08 all mean 1.3601311366073787e-05
1.4214069778972771e-05 1.4214067050488666e-05
rl training, epoch2, iter0, batch698/1133, batch loss:1.4214067050488666e-05, Training time:41488.95179915428
batch reward last col mean 1.0984091147747677e-07 first col mean 9.71914886349623e-08 all mean 3.954562089347746e-06
6.9814482230867725e-06 6.981447313592071e-06
rl training, epoch2, iter0, batch699/1133, batch loss:6.981447313592071e-06, Training time:41505.431767463684
batch reward last col mean 5.98399253703974e-07 first col mean 1.0311068621149388e-07 all mean 1.4288342754298355e-05
1.0214492249360774e-05 1.0214492249360774e-05
rl training, epoch2, iter0, batch700/1133, batch loss:1.0214492249360774e-05, Training time:41522.107340574265
batch reward last col mean 1.678502314916841e-08 first col mean 0.0001971543679246679 all mean 1.95080410776427e-05
0.00012127527588745579 0.0001212752831634134
rl training, epoch2, iter0, batch701/1133, batch loss:0.0001212752831634134, Training time:41538.87279033661
batch reward last col mean 5.448874276225979e-07 first col mean 6.0896123613929376e-05 all mean 3.232256494811736e-05
6.002059672027826e-05 6.002060035825707e-05
rl training, epoch2, iter0, batch702/1133, batch loss:6.002060035825707e-05, Training time:41555.78103899956
batch reward last col mean 2.657686195561837e-07 first col mean 2.808757812999829e-07 all mean 2.1317924620234407e-05
5.3333878895500675e-05 5.3333878895500675e-05
rl training, epoch2, iter0, batch703/1133, batch loss:5.3333878895500675e-05, Training time:41572.46566605568
batch reward last col mean 0.00028113892767578363 first col mean 2.3503896954935044e-05 all mean 0.00027751445304602385
2.5309711418231018e-05 2.5309711418231018e-05
rl training, epoch2, iter0, batch704/1133, batch loss:2.5309711418231018e-05, Training time:41589.021852493286
batch reward last col mean 2.3465423382162953e-08 first col mean 2.5546636805984235e-08 all mean 3.4809036151273176e-05
5.547127148020081e-05 5.5471256928285584e-05
rl training, epoch2, iter0, batch705/1133, batch loss:5.5471256928285584e-05, Training time:41605.69923329353
batch reward last col mean 1.4616969565395266e-05 first col mean 9.084463954422972e-07 all mean 1.8506592823541723e-05
2.701759513001889e-05 2.701759513001889e-05
rl training, epoch2, iter0, batch706/1133, batch loss:2.701759513001889e-05, Training time:41622.272107839584
batch reward last col mean 8.557402179576457e-05 first col mean 1.0984128095969936e-07 all mean 7.556103082606569e-05
1.1741818525479175e-05 1.1741819434973877e-05
rl training, epoch2, iter0, batch707/1133, batch loss:1.1741819434973877e-05, Training time:41639.00251317024
batch reward last col mean 1.7746092595416485e-08 first col mean 1.2743072147713974e-05 all mean 1.906564534692734e-06
2.212784465882578e-06 2.2127846932562534e-06
rl training, epoch2, iter0, batch708/1133, batch loss:2.2127846932562534e-06, Training time:41655.92177391052
batch reward last col mean 3.408104731761341e-08 first col mean 1.7159409253508784e-05 all mean 3.418507731112186e-06
1.2874819731223397e-05 1.2874819731223397e-05
rl training, epoch2, iter0, batch709/1133, batch loss:1.2874819731223397e-05, Training time:41673.52118873596
batch reward last col mean 4.048769142173114e-08 first col mean 7.693437709122009e-08 all mean 1.662537943047937e-05
4.046201866003685e-05 4.046201502205804e-05
rl training, epoch2, iter0, batch710/1133, batch loss:4.046201502205804e-05, Training time:41690.701213121414
batch reward last col mean 1.2761297796259896e-07 first col mean 1.5484954474231927e-07 all mean 1.3921546269557439e-05
5.645311375701567e-06 5.645306828228058e-06
rl training, epoch2, iter0, batch711/1133, batch loss:5.645306828228058e-06, Training time:41708.97323513031
batch reward last col mean 1.0795323746037866e-08 first col mean 1.865183367044665e-05 all mean 7.595935130666476e-06
1.2484844774007797e-05 1.2484844774007797e-05
rl training, epoch2, iter0, batch712/1133, batch loss:1.2484844774007797e-05, Training time:41726.29713821411
batch reward last col mean 6.7843983764248605e-09 first col mean 5.220341563472175e-07 all mean 4.6526665755664e-06
1.1719555914169177e-05 1.1719555914169177e-05
rl training, epoch2, iter0, batch713/1133, batch loss:1.1719555914169177e-05, Training time:41743.364204883575
batch reward last col mean 8.380641247640597e-07 first col mean 3.728590672835708e-05 all mean 2.9532311600632966e-05
0.00011308647663099691 0.00011308646207908168
rl training, epoch2, iter0, batch714/1133, batch loss:0.00011308646207908168, Training time:41759.96542453766
batch reward last col mean 2.0868887986580376e-06 first col mean 5.843363624080666e-07 all mean 1.1773572623496875e-05
7.813161209924147e-05 7.813161209924147e-05
rl training, epoch2, iter0, batch715/1133, batch loss:7.813161209924147e-05, Training time:41776.901290655136
batch reward last col mean 3.2124098936492373e-08 first col mean 1.6595494116700138e-06 all mean 1.4069722965359688e-05
6.002502050250769e-05 6.002502050250769e-05
rl training, epoch2, iter0, batch716/1133, batch loss:6.002502050250769e-05, Training time:41793.739527225494
batch reward last col mean 3.5636870165944856e-07 first col mean 0.002472692634910345 all mean 3.260732046328485e-05
2.4917368136812e-05 2.4917368136812e-05
rl training, epoch2, iter0, batch717/1133, batch loss:2.4917368136812e-05, Training time:41810.52620792389
batch reward last col mean 2.0117457211199508e-07 first col mean 0.00016560356016270816 all mean 2.9653629098902456e-06
3.5003504308406264e-06 3.500350658214302e-06
rl training, epoch2, iter0, batch718/1133, batch loss:3.500350658214302e-06, Training time:41827.007924079895
batch reward last col mean 2.655750108715438e-07 first col mean 6.421503258025041e-07 all mean 3.787494961215998e-06
9.997299457609188e-06 9.997301276598591e-06
rl training, epoch2, iter0, batch719/1133, batch loss:9.997301276598591e-06, Training time:41843.46977472305
batch reward last col mean 5.246130285740946e-07 first col mean 4.931805008823176e-08 all mean 2.6224519388051704e-05
0.00010053819278255105 0.00010053819278255105
rl training, epoch2, iter0, batch720/1133, batch loss:0.00010053819278255105, Training time:41860.06999516487
batch reward last col mean 0.005265465937554836 first col mean 3.2280718187394086e-07 all mean 0.005218993406742811
0.0005113610532134771 0.0005113610532134771
rl training, epoch2, iter0, batch721/1133, batch loss:0.0005113610532134771, Training time:41877.40103292465
batch reward last col mean 5.267717284596074e-08 first col mean 0.0006198679329827428 all mean 1.7179763744934462e-05
1.8566137441666797e-05 1.85661392606562e-05
rl training, epoch2, iter0, batch722/1133, batch loss:1.85661392606562e-05, Training time:41893.96082496643
batch reward last col mean 4.335293795065809e-07 first col mean 0.002843852387741208 all mean 5.398019129643217e-05
0.00010000001930166036 0.00010000001930166036
rl training, epoch2, iter0, batch723/1133, batch loss:0.00010000001930166036, Training time:41911.09159088135
batch reward last col mean 8.721207755968408e-09 first col mean 5.163316018297337e-06 all mean 1.3625431165564805e-06
1.9064407297264552e-06 1.9064405023527797e-06
rl training, epoch2, iter0, batch724/1133, batch loss:1.9064405023527797e-06, Training time:41927.91093802452
batch reward last col mean 1.0351678625397653e-08 first col mean 1.2140564649598673e-05 all mean 7.0490900725417305e-06
2.228287121397443e-05 2.228287121397443e-05
rl training, epoch2, iter0, batch725/1133, batch loss:2.228287121397443e-05, Training time:41946.292341947556
batch reward last col mean 0.003775965655222535 first col mean 0.0002344535751035437 all mean 0.0034960219636559486
0.00032224616734310985 0.0003222461382392794
rl training, epoch2, iter0, batch726/1133, batch loss:0.0003222461382392794, Training time:41964.80689430237
batch reward last col mean 1.5530325981671922e-05 first col mean 1.9913564131002204e-08 all mean 4.856980740441941e-05
0.00012015762331429869 0.00012015760876238346
rl training, epoch2, iter0, batch727/1133, batch loss:0.00012015760876238346, Training time:41982.688244342804
batch reward last col mean 3.163708939268872e-08 first col mean 0.001213557436130941 all mean 3.64181432814803e-05
0.000119337099022232 0.000119337099022232
rl training, epoch2, iter0, batch728/1133, batch loss:0.000119337099022232, Training time:42001.08098912239
batch reward last col mean 1.9881774449004297e-08 first col mean 2.5941875492208055e-07 all mean 6.014358405082021e-06
2.8318709155428223e-06 2.8318709155428223e-06
rl training, epoch2, iter0, batch729/1133, batch loss:2.8318709155428223e-06, Training time:42020.08458828926
batch reward last col mean 7.306269367290952e-08 first col mean 1.5299475535357487e-06 all mean 7.895500857557636e-06
4.3850312067661434e-05 4.385031570564024e-05
rl training, epoch2, iter0, batch730/1133, batch loss:4.385031570564024e-05, Training time:42037.42412662506
batch reward last col mean 4.694938525062753e-06 first col mean 0.00032749364618211985 all mean 2.2902811906533316e-05
8.239870658144355e-05 8.239870658144355e-05
rl training, epoch2, iter0, batch731/1133, batch loss:8.239870658144355e-05, Training time:42054.21413183212
batch reward last col mean 2.1460325072553132e-08 first col mean 0.0008640768937766552 all mean 2.55537324846955e-05
2.12111681321403e-05 2.1211169951129705e-05
rl training, epoch2, iter0, batch732/1133, batch loss:2.1211169951129705e-05, Training time:42070.65591430664
batch reward last col mean 4.954968630954681e-07 first col mean 1.969599452422699e-07 all mean 3.388824097783072e-06
1.7517291780677624e-05 1.7517291780677624e-05
rl training, epoch2, iter0, batch733/1133, batch loss:1.7517291780677624e-05, Training time:42087.68873119354
batch reward last col mean 7.333923690566735e-09 first col mean 1.6057572793215513e-05 all mean 5.046257228968898e-06
8.152210284606554e-06 8.152210284606554e-06
rl training, epoch2, iter0, batch734/1133, batch loss:8.152210284606554e-06, Training time:42104.55514097214
batch reward last col mean 1.6967831584224768e-07 first col mean 3.0767565476708114e-05 all mean 7.768448085698765e-06
1.5229798918880988e-05 1.522979982837569e-05
rl training, epoch2, iter0, batch735/1133, batch loss:1.522979982837569e-05, Training time:42121.23179388046
batch reward last col mean 6.945004770386731e-06 first col mean 6.708136623956307e-08 all mean 5.298155429045437e-06
9.551918083161581e-07 9.551919220029959e-07
rl training, epoch2, iter0, batch736/1133, batch loss:9.551919220029959e-07, Training time:42138.39780330658
batch reward last col mean 2.1143875983398175e-06 first col mean 3.910923283001466e-07 all mean 1.0970097719109617e-06
5.982226866763085e-06 5.982226866763085e-06
rl training, epoch2, iter0, batch737/1133, batch loss:5.982226866763085e-06, Training time:42154.81485581398
batch reward last col mean 1.3985804514504707e-07 first col mean 0.0007195844664238393 all mean 1.0503103112569079e-05
2.0977184249204583e-05 2.0977184249204583e-05
rl training, epoch2, iter0, batch738/1133, batch loss:2.0977184249204583e-05, Training time:42171.239827394485
batch reward last col mean 5.308330628395197e-07 first col mean 1.2499144759203773e-06 all mean 2.906356894527562e-05
0.00013144483091309667 0.00013144481636118144
rl training, epoch2, iter0, batch739/1133, batch loss:0.00013144481636118144, Training time:42188.235954761505
batch reward last col mean 8.778527238462175e-09 first col mean 0.0004241732822265476 all mean 1.8344284399063326e-05
8.242173862527125e-06 8.242173862527125e-06
rl training, epoch2, iter0, batch740/1133, batch loss:8.242173862527125e-06, Training time:42206.452728033066
batch reward last col mean 1.539954581630809e-07 first col mean 0.0005229102680459619 all mean 2.4654749722685665e-05
7.635680958628654e-05 7.635680231032893e-05
rl training, epoch2, iter0, batch741/1133, batch loss:7.635680231032893e-05, Training time:42225.08225393295
batch reward last col mean 7.763101450564136e-08 first col mean 3.11984571510493e-08 all mean 1.0220064723398536e-06
8.719279094293597e-07 8.719277388991031e-07
rl training, epoch2, iter0, batch742/1133, batch loss:8.719277388991031e-07, Training time:42244.72042155266
batch reward last col mean 6.343265113173402e-08 first col mean 1.2925984265166335e-05 all mean 1.8923705283668824e-05
1.4876777640893124e-06 1.4876854947942775e-06
rl training, epoch2, iter0, batch743/1133, batch loss:1.4876854947942775e-06, Training time:42263.54352736473
batch reward last col mean 8.124137025333766e-07 first col mean 0.00013422431948129088 all mean 8.097984391497448e-06
1.2603286450030282e-05 1.260329008800909e-05
rl training, epoch2, iter0, batch744/1133, batch loss:1.260329008800909e-05, Training time:42281.363248586655
batch reward last col mean 0.00011437918874435127 first col mean 1.0241550398859545e-06 all mean 6.92936810082756e-05
1.755640005285386e-05 1.755640005285386e-05
rl training, epoch2, iter0, batch745/1133, batch loss:1.755640005285386e-05, Training time:42297.93538784981
batch reward last col mean 3.4018507903965656e-06 first col mean 1.5876770120826222e-08 all mean 4.380784048407804e-06
8.194882639145362e-07 8.194886049750494e-07
rl training, epoch2, iter0, batch746/1133, batch loss:8.194886049750494e-07, Training time:42314.71617126465
batch reward last col mean 4.877782430412481e-06 first col mean 1.9499728296068497e-05 all mean 8.259991773229558e-06
5.216561930865282e-06 5.216561930865282e-06
rl training, epoch2, iter0, batch747/1133, batch loss:5.216561930865282e-06, Training time:42331.557705163956
batch reward last col mean 2.535836785000356e-08 first col mean 5.1178528082118646e-08 all mean 6.2443732531392016e-06
2.8788224881282076e-05 2.8788224881282076e-05
rl training, epoch2, iter0, batch748/1133, batch loss:2.8788224881282076e-05, Training time:42348.24642467499
batch reward last col mean 1.5248876650275633e-07 first col mean 7.44306234423675e-08 all mean 6.60531759422156e-06
9.26744905882515e-06 9.267448149330448e-06
rl training, epoch2, iter0, batch749/1133, batch loss:9.267448149330448e-06, Training time:42364.73577785492
batch reward last col mean 2.679417354656266e-09 first col mean 1.0973421638027503e-07 all mean 9.395618008056772e-07
2.2640206225332804e-06 2.264020849906956e-06
rl training, epoch2, iter0, batch750/1133, batch loss:2.264020849906956e-06, Training time:42381.4941008091
batch reward last col mean 2.603010500479286e-07 first col mean 4.2210243123008695e-07 all mean 1.9768327547353692e-05
3.548657332430594e-05 3.548658060026355e-05
rl training, epoch2, iter0, batch751/1133, batch loss:3.548658060026355e-05, Training time:42397.981541633606
batch reward last col mean 5.903326609768555e-07 first col mean 2.773896881080873e-07 all mean 1.6992395103443414e-05
1.270724055757455e-06 1.2707225778285647e-06
rl training, epoch2, iter0, batch752/1133, batch loss:1.2707225778285647e-06, Training time:42414.62354159355
batch reward last col mean 0.0002509749901946634 first col mean 4.321189408074133e-06 all mean 0.00024353044864255935
3.958926390623674e-05 3.958926390623674e-05
rl training, epoch2, iter0, batch753/1133, batch loss:3.958926390623674e-05, Training time:42431.08135223389
batch reward last col mean 7.652621292209005e-08 first col mean 2.140482813217659e-08 all mean 2.5266381271649152e-05
7.225888839457184e-05 7.225890294648707e-05
rl training, epoch2, iter0, batch754/1133, batch loss:7.225890294648707e-05, Training time:42447.46148467064
batch reward last col mean 8.406554563578084e-09 first col mean 1.4475089926690998e-07 all mean 9.558987585478462e-06
2.67054965661373e-05 2.6705498385126702e-05
rl training, epoch2, iter0, batch755/1133, batch loss:2.6705498385126702e-05, Training time:42463.80679392815
batch reward last col mean 8.657257666300211e-08 first col mean 0.0003878332208842039 all mean 8.22656602395e-06
2.3177404727903195e-05 2.3177406546892598e-05
rl training, epoch2, iter0, batch756/1133, batch loss:2.3177406546892598e-05, Training time:42480.37473344803
batch reward last col mean 5.468148156495545e-09 first col mean 8.392662857659161e-05 all mean 4.562581125355791e-06
4.678633558796719e-06 4.678633558796719e-06
rl training, epoch2, iter0, batch757/1133, batch loss:4.678633558796719e-06, Training time:42497.07485580444
batch reward last col mean 1.0351828727550583e-08 first col mean 1.1723353964043781e-05 all mean 3.8031348594813608e-06
7.960966286191251e-06 7.960966286191251e-06
rl training, epoch2, iter0, batch758/1133, batch loss:7.960966286191251e-06, Training time:42513.964403152466
batch reward last col mean 8.461990574915035e-08 first col mean 1.5183609036739654e-07 all mean 2.1613503122352995e-05
9.489272633800283e-05 9.489274088991806e-05
rl training, epoch2, iter0, batch759/1133, batch loss:9.489274088991806e-05, Training time:42530.856343746185
batch reward last col mean 7.371443011550127e-09 first col mean 4.723970778286457e-05 all mean 2.9675302357645705e-05
4.477195761865005e-05 4.477195398067124e-05
rl training, epoch2, iter0, batch760/1133, batch loss:4.477195398067124e-05, Training time:42547.439183712006
batch reward last col mean 9.313494047091808e-07 first col mean 0.00017502185073681176 all mean 2.7567801225814037e-05
8.969142072601244e-05 8.969142072601244e-05
rl training, epoch2, iter0, batch761/1133, batch loss:8.969142072601244e-05, Training time:42566.51801800728
batch reward last col mean 6.029377885852227e-09 first col mean 6.226926052477211e-05 all mean 1.048465674102772e-05
2.4938837668742053e-05 2.493884130672086e-05
rl training, epoch2, iter0, batch762/1133, batch loss:2.493884130672086e-05, Training time:42584.615913152695
batch reward last col mean 3.483921489078057e-07 first col mean 1.2009134309209912e-07 all mean 1.3320439393282868e-05
9.325402061222121e-05 9.325403516413644e-05
rl training, epoch2, iter0, batch763/1133, batch loss:9.325403516413644e-05, Training time:42601.025069475174
batch reward last col mean 2.604942750394912e-08 first col mean 9.102588592213579e-06 all mean 1.473654947403702e-06
4.4189337131683715e-06 4.418933258421021e-06
rl training, epoch2, iter0, batch764/1133, batch loss:4.418933258421021e-06, Training time:42617.462550640106
batch reward last col mean 1.4761447175715148e-07 first col mean 0.0005831806338392198 all mean 2.5055933292605914e-05
0.00012578355381265283 0.00012578355381265283
rl training, epoch2, iter0, batch765/1133, batch loss:0.00012578355381265283, Training time:42633.80514502525
batch reward last col mean 6.181434031304889e-09 first col mean 1.974463614828892e-08 all mean 4.585433089232538e-06
2.7605872674030252e-05 2.7605872674030252e-05
rl training, epoch2, iter0, batch766/1133, batch loss:2.7605872674030252e-05, Training time:42650.51587820053
batch reward last col mean 9.879923368316668e-08 first col mean 2.9377023480492426e-08 all mean 4.7446676035178825e-05
0.00016561248048674315 0.00016561248048674315
rl training, epoch2, iter0, batch767/1133, batch loss:0.00016561248048674315, Training time:42667.198050022125
batch reward last col mean 4.3532529048206925e-07 first col mean 2.76146442956815e-06 all mean 1.784818323358195e-06
4.763538527186029e-06 4.763538527186029e-06
rl training, epoch2, iter0, batch768/1133, batch loss:4.763538527186029e-06, Training time:42683.64471197128
batch reward last col mean 6.569580932591634e-07 first col mean 1.2327544027357362e-05 all mean 1.4799395103182178e-05
1.2072051504219417e-05 1.2072051504219417e-05
rl training, epoch2, iter0, batch769/1133, batch loss:1.2072051504219417e-05, Training time:42700.13735079765
batch reward last col mean 8.440956378308329e-08 first col mean 0.0006882848683744669 all mean 3.1629733712179586e-05
4.392776099848561e-05 4.392776099848561e-05
rl training, epoch2, iter0, batch770/1133, batch loss:4.392776099848561e-05, Training time:42716.95518088341
batch reward last col mean 9.624007368813636e-09 first col mean 0.0013897152384743094 all mean 4.6242384996730834e-05
9.976056753657758e-05 9.976056753657758e-05
rl training, epoch2, iter0, batch771/1133, batch loss:9.976056753657758e-05, Training time:42733.722296237946
batch reward last col mean 8.906948778530932e-07 first col mean 2.1335114070097916e-05 all mean 6.100078280724119e-06
8.033180165512022e-06 8.033180165512022e-06
rl training, epoch2, iter0, batch772/1133, batch loss:8.033180165512022e-06, Training time:42750.35454368591
batch reward last col mean 1.154652693458047e-07 first col mean 0.00015046681801322848 all mean 2.3441984012606554e-05
1.890468774945475e-05 1.8904685930465348e-05
rl training, epoch2, iter0, batch773/1133, batch loss:1.8904685930465348e-05, Training time:42768.29375553131
batch reward last col mean 4.12713916375651e-07 first col mean 3.935865970561281e-05 all mean 1.255533607036341e-05
5.1970095228170976e-05 5.197009886614978e-05
rl training, epoch2, iter0, batch774/1133, batch loss:5.197009886614978e-05, Training time:42784.84082818031
batch reward last col mean 1.9514308391421764e-08 first col mean 1.8139025996788405e-06 all mean 9.213037628796883e-06
6.424753337341826e-06 6.424753337341826e-06
rl training, epoch2, iter0, batch775/1133, batch loss:6.424753337341826e-06, Training time:42801.98746228218
batch reward last col mean 5.727907819164102e-07 first col mean 0.00017204700270667672 all mean 5.482886990648694e-06
1.177495505544357e-05 1.1774955964938272e-05
rl training, epoch2, iter0, batch776/1133, batch loss:1.1774955964938272e-05, Training time:42820.87554335594
batch reward last col mean 3.998890861112159e-06 first col mean 1.0741160849647713e-06 all mean 5.6662163842702284e-05
0.00025901454500854015 0.0002590145159047097
rl training, epoch2, iter0, batch777/1133, batch loss:0.0002590145159047097, Training time:42838.2530977726
batch reward last col mean 9.430594218429178e-05 first col mean 8.111350325634703e-05 all mean 0.00013411267718765885
0.00015140172035899013 0.00015140172035899013
rl training, epoch2, iter0, batch778/1133, batch loss:0.00015140172035899013, Training time:42855.72504281998
batch reward last col mean 1.5431847089075745e-07 first col mean 1.795445996322087e-07 all mean 4.341575277067022e-06
2.238116940134205e-05 2.238116940134205e-05
rl training, epoch2, iter0, batch779/1133, batch loss:2.238116940134205e-05, Training time:42873.95280909538
batch reward last col mean 3.3688181702018483e-06 first col mean 3.977632800911124e-08 all mean 6.120522812125273e-06
1.5207287106022704e-05 1.5207287106022704e-05
rl training, epoch2, iter0, batch780/1133, batch loss:1.5207287106022704e-05, Training time:42891.660633563995
batch reward last col mean 9.44252676049473e-08 first col mean 0.001524601480923593 all mean 2.0627223420888186e-05
2.1388448658399284e-05 2.138845229637809e-05
rl training, epoch2, iter0, batch781/1133, batch loss:2.138845229637809e-05, Training time:42908.3251721859
batch reward last col mean 2.891285788564346e-08 first col mean 4.1442302745053894e-07 all mean 1.016757232719101e-05
6.462682358687744e-05 6.462682358687744e-05
rl training, epoch2, iter0, batch782/1133, batch loss:6.462682358687744e-05, Training time:42925.08004808426
batch reward last col mean 6.296585343079641e-05 first col mean 7.334412543968938e-08 all mean 5.6004428188316524e-05
9.770573342393618e-06 9.770573342393618e-06
rl training, epoch2, iter0, batch783/1133, batch loss:9.770573342393618e-06, Training time:42942.34738564491
batch reward last col mean 8.302561695927579e-07 first col mean 5.384582436818164e-06 all mean 6.746368399035418e-06
1.9884686480509117e-05 1.9884686480509117e-05
rl training, epoch2, iter0, batch784/1133, batch loss:1.9884686480509117e-05, Training time:42958.827001810074
batch reward last col mean 6.468602009590541e-07 first col mean 8.246941263223562e-08 all mean 7.402160008496139e-06
2.2655362045043148e-05 2.2655362045043148e-05
rl training, epoch2, iter0, batch785/1133, batch loss:2.2655362045043148e-05, Training time:42975.274607658386
batch reward last col mean 5.497666279552504e-06 first col mean 1.3284216038300656e-05 all mean 7.518865004385589e-06
7.525994078605436e-06 7.525994533352787e-06
rl training, epoch2, iter0, batch786/1133, batch loss:7.525994533352787e-06, Training time:42991.97339773178
batch reward last col mean 6.607626801269362e-08 first col mean 7.917263428680599e-05 all mean 4.137576524954056e-06
2.6466580038686516e-06 2.6466575491213007e-06
rl training, epoch2, iter0, batch787/1133, batch loss:2.6466575491213007e-06, Training time:43008.47180533409
batch reward last col mean 1.2611436659426545e-06 first col mean 8.487175051641316e-08 all mean 1.5730864106444642e-05
1.6366491763619706e-05 1.6366489944630302e-05
rl training, epoch2, iter0, batch788/1133, batch loss:1.6366489944630302e-05, Training time:43024.967269420624
batch reward last col mean 1.4360449718253676e-08 first col mean 2.2588334104511887e-05 all mean 2.1655507225659676e-05
9.832929208641872e-05 9.832929208641872e-05
rl training, epoch2, iter0, batch789/1133, batch loss:9.832929208641872e-05, Training time:43042.59527993202
batch reward last col mean 3.26577469422773e-06 first col mean 1.7051317513505637e-07 all mean 1.4563132026523817e-05
4.083691237610765e-05 4.083691237610765e-05
rl training, epoch2, iter0, batch790/1133, batch loss:4.083691237610765e-05, Training time:43059.302204847336
batch reward last col mean 5.071758641861379e-05 first col mean 4.137451105634682e-05 all mean 5.1452912884997204e-05
9.367043276142795e-06 9.367041457153391e-06
rl training, epoch2, iter0, batch791/1133, batch loss:9.367041457153391e-06, Training time:43077.48980689049
batch reward last col mean 5.73608019749372e-07 first col mean 1.0441027370688971e-05 all mean 2.2522470317198895e-05
0.00016502545622643083 0.00016502545622643083
rl training, epoch2, iter0, batch792/1133, batch loss:0.00016502545622643083, Training time:43094.440155506134
batch reward last col mean 6.760601536370814e-05 first col mean 7.263064617291093e-06 all mean 7.111230661394075e-05
2.637629586388357e-05 2.637629586388357e-05
rl training, epoch2, iter0, batch793/1133, batch loss:2.637629586388357e-05, Training time:43112.14019751549
batch reward last col mean 8.073698865018741e-08 first col mean 1.5366146044470952e-07 all mean 3.1823144581721863e-06
8.836416782287415e-06 8.836416782287415e-06
rl training, epoch2, iter0, batch794/1133, batch loss:8.836416782287415e-06, Training time:43130.63505220413
batch reward last col mean 6.66513386704537e-08 first col mean 0.0012415414676070213 all mean 1.5085465747688431e-05
1.6949903510976583e-05 1.6949905329965986e-05
rl training, epoch2, iter0, batch795/1133, batch loss:1.6949905329965986e-05, Training time:43147.390998363495
batch reward last col mean 0.00018298925715498626 first col mean 8.304231187139521e-07 all mean 0.00018229337001685053
5.671810140484013e-05 5.671810140484013e-05
rl training, epoch2, iter0, batch796/1133, batch loss:5.671810140484013e-05, Training time:43163.89039731026
batch reward last col mean 3.274503512784577e-07 first col mean 8.728735338081606e-06 all mean 1.434057776350528e-05
1.1350642125762533e-05 1.1350643944751937e-05
rl training, epoch2, iter0, batch797/1133, batch loss:1.1350643944751937e-05, Training time:43180.511776685715
batch reward last col mean 4.902361538938749e-08 first col mean 5.960302473795309e-08 all mean 3.145142909488641e-05
0.00011106587044196203 0.00011106587044196203
rl training, epoch2, iter0, batch798/1133, batch loss:0.00011106587044196203, Training time:43197.07191538811
batch reward last col mean 2.1136891348305653e-07 first col mean 3.203861342626624e-05 all mean 8.255905754595005e-07
1.0859022268050467e-06 1.085902113118209e-06
rl training, epoch2, iter0, batch799/1133, batch loss:1.085902113118209e-06, Training time:43213.58067059517
batch reward last col mean 1.205321780162194e-07 first col mean 1.4996842878645111e-07 all mean 2.399466666247463e-06
2.3946026885823812e-06 2.394602006461355e-06
rl training, epoch2, iter0, batch800/1133, batch loss:2.394602006461355e-06, Training time:43230.44693279266
batch reward last col mean 2.290659040227183e-06 first col mean 5.366280220187036e-07 all mean 2.6306017844035523e-06
1.5148051488722558e-06 1.5148051488722558e-06
rl training, epoch2, iter0, batch801/1133, batch loss:1.5148051488722558e-06, Training time:43246.72051548958
batch reward last col mean 5.390789148407293e-09 first col mean 3.0331405014294432e-06 all mean 1.1776735846069641e-05
1.5367930245702155e-05 1.536793206469156e-05
rl training, epoch2, iter0, batch802/1133, batch loss:1.536793206469156e-05, Training time:43263.44782042503
batch reward last col mean 3.139387416695172e-08 first col mean 0.0004541930684354156 all mean 4.6919660235289484e-05
0.0002264778158860281 0.0002264778158860281
rl training, epoch2, iter0, batch803/1133, batch loss:0.0002264778158860281, Training time:43279.76527237892
batch reward last col mean 9.529523836704357e-09 first col mean 4.887866452918388e-06 all mean 8.201031960197724e-07
2.0020063402625965e-06 2.0020063402625965e-06
rl training, epoch2, iter0, batch804/1133, batch loss:2.0020063402625965e-06, Training time:43296.58223032951
batch reward last col mean 1.8803879342499386e-08 first col mean 2.3556604844543472e-07 all mean 9.156827218248509e-06
1.5803016140125692e-05 1.5803017959115095e-05
rl training, epoch2, iter0, batch805/1133, batch loss:1.5803017959115095e-05, Training time:43313.513609170914
batch reward last col mean 3.269642334657874e-09 first col mean 0.00016762215818744153 all mean 3.1941741326591e-05
0.00012264253746252507 0.0001226425520144403
rl training, epoch2, iter0, batch806/1133, batch loss:0.0001226425520144403, Training time:43329.920359134674
batch reward last col mean 2.0813402443309315e-05 first col mean 1.6434225472039543e-05 all mean 2.336313991690986e-05
1.4264649507822469e-05 1.4264648598327767e-05
rl training, epoch2, iter0, batch807/1133, batch loss:1.4264648598327767e-05, Training time:43346.40538740158
batch reward last col mean 1.8993963749380782e-05 first col mean 0.0017218929715454578 all mean 4.284523311071098e-05
2.4887456675060093e-05 2.4887462132028304e-05
rl training, epoch2, iter0, batch808/1133, batch loss:2.4887462132028304e-05, Training time:43363.077768564224
batch reward last col mean 3.1500540842444025e-08 first col mean 1.0472025735452917e-07 all mean 3.296129989394103e-06
6.674411451967899e-06 6.674410087725846e-06
rl training, epoch2, iter0, batch809/1133, batch loss:6.674410087725846e-06, Training time:43379.399713754654
batch reward last col mean 7.5032607128378e-05 first col mean 7.950896360853221e-06 all mean 0.00010323472815798596
0.00012890480866190046 0.00012890480866190046
rl training, epoch2, iter0, batch810/1133, batch loss:0.00012890480866190046, Training time:43397.77344965935
batch reward last col mean 1.2175253516488738e-07 first col mean 1.9609096852946095e-06 all mean 1.5910374713712372e-05
6.851328635093523e-06 6.85133227307233e-06
rl training, epoch2, iter0, batch811/1133, batch loss:6.85133227307233e-06, Training time:43414.981260061264
batch reward last col mean 3.375710093678208e-07 first col mean 1.6422157500528556e-07 all mean 7.23625953469309e-06
4.5648004743270576e-05 4.564801201922819e-05
rl training, epoch2, iter0, batch812/1133, batch loss:4.564801201922819e-05, Training time:43433.88156461716
batch reward last col mean 3.841569650830934e-06 first col mean 0.00018684803217183799 all mean 8.351419637619983e-06
6.486976417363621e-06 6.486977326858323e-06
rl training, epoch2, iter0, batch813/1133, batch loss:6.486977326858323e-06, Training time:43450.46135044098
batch reward last col mean 2.9380046839833085e-07 first col mean 7.520539213601296e-08 all mean 2.8551457944558933e-06
9.938526090991218e-06 9.938526090991218e-06
rl training, epoch2, iter0, batch814/1133, batch loss:9.938526090991218e-06, Training time:43466.883373975754
batch reward last col mean 9.459973249192899e-09 first col mean 0.00012207678810227662 all mean 1.7655911506153643e-05
9.091933316085488e-05 9.091933316085488e-05
rl training, epoch2, iter0, batch815/1133, batch loss:9.091933316085488e-05, Training time:43483.32347035408
batch reward last col mean 1.283927009154695e-08 first col mean 9.399411169397354e-07 all mean 4.022220309707336e-06
7.87088447395945e-06 7.870883564464748e-06
rl training, epoch2, iter0, batch816/1133, batch loss:7.870883564464748e-06, Training time:43499.83233976364
batch reward last col mean 1.3214041416631517e-08 first col mean 1.6601923107373295e-06 all mean 1.161069030786166e-05
1.388494001730578e-05 1.3884936379326973e-05
rl training, epoch2, iter0, batch817/1133, batch loss:1.3884936379326973e-05, Training time:43516.410111904144
batch reward last col mean 5.859372322447598e-06 first col mean 1.467068102556368e-07 all mean 1.8977194486069493e-05
4.781887400895357e-05 4.781887764693238e-05
rl training, epoch2, iter0, batch818/1133, batch loss:4.781887764693238e-05, Training time:43533.04170393944
batch reward last col mean 2.493103146150588e-08 first col mean 2.1532092375764478e-07 all mean 2.0955181753379293e-05
8.530542982043698e-05 8.530542982043698e-05
rl training, epoch2, iter0, batch819/1133, batch loss:8.530542982043698e-05, Training time:43549.66608452797
batch reward last col mean 0.0037534034345299006 first col mean 5.34614227944985e-05 all mean 0.0032451904844492674
0.00021460170682985336 0.00021460170682985336
rl training, epoch2, iter0, batch820/1133, batch loss:0.00021460170682985336, Training time:43566.41711497307
batch reward last col mean 6.420976461640748e-08 first col mean 2.0915893401252106e-05 all mean 2.3120221158023924e-05
6.135041621746495e-05 6.135041621746495e-05
rl training, epoch2, iter0, batch821/1133, batch loss:6.135041621746495e-05, Training time:43582.83580207825
batch reward last col mean 2.5096371700783493e-06 first col mean 1.056706878443947e-05 all mean 1.0049802767753135e-05
1.8104550463249325e-06 1.8104576611222e-06
rl training, epoch2, iter0, batch822/1133, batch loss:1.8104576611222e-06, Training time:43599.25635313988
batch reward last col mean 1.624997167937181e-07 first col mean 2.1143026174286206e-07 all mean 2.2537855329574086e-05
0.0001486293476773426 0.0001486293476773426
rl training, epoch2, iter0, batch823/1133, batch loss:0.0001486293476773426, Training time:43616.10375189781
batch reward last col mean 4.820253352022519e-08 first col mean 2.0248185350624226e-08 all mean 3.084262789343484e-05
6.689054862363264e-05 6.689054862363264e-05
rl training, epoch2, iter0, batch824/1133, batch loss:6.689054862363264e-05, Training time:43632.609441280365
batch reward last col mean 3.8693670489919896e-08 first col mean 0.000647792243398726 all mean 2.103937731590122e-05
5.086477904114872e-05 5.086477904114872e-05
rl training, epoch2, iter0, batch825/1133, batch loss:5.086477904114872e-05, Training time:43649.23778963089
batch reward last col mean 5.106933258502977e-06 first col mean 2.9448607165249996e-05 all mean 1.2500468073994853e-05
2.779588248813525e-05 2.7795886126114056e-05
rl training, epoch2, iter0, batch826/1133, batch loss:2.7795886126114056e-05, Training time:43666.06022310257
batch reward last col mean 7.318286776580862e-08 first col mean 0.0006215194007381797 all mean 4.630038165487349e-05
0.00018539118173066527 0.00018539118173066527
rl training, epoch2, iter0, batch827/1133, batch loss:0.00018539118173066527, Training time:43684.29554128647
batch reward last col mean 4.73469242479041e-07 first col mean 2.0510903198101005e-07 all mean 6.230184226296842e-05
0.00029961884138174355 0.000299618870485574
rl training, epoch2, iter0, batch828/1133, batch loss:0.000299618870485574, Training time:43701.52804970741
batch reward last col mean 1.4701920569848426e-08 first col mean 2.042073174379766e-05 all mean 5.129115834279219e-06
1.638252433622256e-05 1.638252433622256e-05
rl training, epoch2, iter0, batch829/1133, batch loss:1.638252433622256e-05, Training time:43718.585611343384
batch reward last col mean 2.1590018661754584e-07 first col mean 1.987977640283134e-07 all mean 3.5682719499163795e-06
1.8682887457543984e-05 1.868288563855458e-05
rl training, epoch2, iter0, batch830/1133, batch loss:1.868288563855458e-05, Training time:43736.571902275085
batch reward last col mean 4.1647535198308105e-08 first col mean 0.001136217382736504 all mean 3.129672404611483e-05
8.885868737706915e-05 8.885868737706915e-05
rl training, epoch2, iter0, batch831/1133, batch loss:8.885868737706915e-05, Training time:43755.979425907135
batch reward last col mean 9.017701074753859e-08 first col mean 7.597201943099208e-07 all mean 2.3032627723296173e-05
4.782556788995862e-05 4.782557880389504e-05
rl training, epoch2, iter0, batch832/1133, batch loss:4.782557880389504e-05, Training time:43773.02006173134
batch reward last col mean 1.2883344879810465e-07 first col mean 9.589656713160366e-08 all mean 7.482846285711275e-06
4.7271976654883474e-05 4.7271976654883474e-05
rl training, epoch2, iter0, batch833/1133, batch loss:4.7271976654883474e-05, Training time:43789.7026848793
batch reward last col mean 1.8410931446055656e-08 first col mean 5.6545730330981314e-05 all mean 2.370386937400326e-05
1.9321711079101078e-05 1.932170198415406e-05
rl training, epoch2, iter0, batch834/1133, batch loss:1.932170198415406e-05, Training time:43806.5397901535
batch reward last col mean 8.437043561571045e-07 first col mean 2.2991208936673502e-07 all mean 8.880699169822037e-06
4.155531314609107e-06 4.155529950367054e-06
rl training, epoch2, iter0, batch835/1133, batch loss:4.155529950367054e-06, Training time:43823.2037730217
batch reward last col mean 4.653707037505228e-06 first col mean 5.477277227328159e-06 all mean 6.857210337329889e-06
1.3641132454722538e-06 1.364113586532767e-06
rl training, epoch2, iter0, batch836/1133, batch loss:1.364113586532767e-06, Training time:43839.69718384743
batch reward last col mean 1.1432935309585446e-07 first col mean 1.3719492926611565e-05 all mean 3.1229878914018627e-06
4.188847015029751e-06 4.1888465602824e-06
rl training, epoch2, iter0, batch837/1133, batch loss:4.1888465602824e-06, Training time:43856.442274570465
batch reward last col mean 5.97601683693938e-08 first col mean 2.8270469556446187e-06 all mean 1.7960186596610583e-05
0.00011837205238407478 0.00011837205966003239
rl training, epoch2, iter0, batch838/1133, batch loss:0.00011837205966003239, Training time:43873.249967336655
batch reward last col mean 2.448430677759461e-05 first col mean 1.1375952453818172e-05 all mean 2.6200583306490444e-05
6.425600986403879e-06 6.42560144115123e-06
rl training, epoch2, iter0, batch839/1133, batch loss:6.42560144115123e-06, Training time:43889.85362243652
batch reward last col mean 3.070965703955153e-08 first col mean 4.278995402273722e-05 all mean 1.146270278695738e-06
8.955407224675582e-07 8.955407224675582e-07
rl training, epoch2, iter0, batch840/1133, batch loss:8.955407224675582e-07, Training time:43906.44213962555
batch reward last col mean 9.025443432619795e-06 first col mean 8.118572480952935e-08 all mean 1.0211678272753488e-05
6.566047431988409e-06 6.5660487962304614e-06
rl training, epoch2, iter0, batch841/1133, batch loss:6.5660487962304614e-06, Training time:43923.08804035187
batch reward last col mean 2.0403144063152467e-08 first col mean 0.0016890414990484715 all mean 3.574839502107352e-05
3.5287182981846854e-05 3.528717570588924e-05
rl training, epoch2, iter0, batch842/1133, batch loss:3.528717570588924e-05, Training time:43939.82154202461
batch reward last col mean 1.8234709386888426e-07 first col mean 2.5440820650146634e-07 all mean 1.3350544350032578e-06
4.021356289740652e-06 4.021356289740652e-06
rl training, epoch2, iter0, batch843/1133, batch loss:4.021356289740652e-06, Training time:43956.25507211685
batch reward last col mean 4.147963750256167e-09 first col mean 1.5511862727635162e-07 all mean 1.7903539628605358e-05
9.547114132146817e-06 9.547116860630922e-06
rl training, epoch2, iter0, batch844/1133, batch loss:9.547116860630922e-06, Training time:43974.83867263794
batch reward last col mean 7.585138916965661e-08 first col mean 4.810500740859425e-06 all mean 1.2093164514226373e-05
2.888657718358445e-06 2.888658173105796e-06
rl training, epoch2, iter0, batch845/1133, batch loss:2.888658173105796e-06, Training time:43993.01438331604
batch reward last col mean 1.7074511049486318e-07 first col mean 0.0008309013792313635 all mean 9.217726073984522e-06
2.054025389952585e-05 2.054024844255764e-05
rl training, epoch2, iter0, batch846/1133, batch loss:2.054024844255764e-05, Training time:44011.88802194595
batch reward last col mean 5.0996227685118356e-08 first col mean 4.3867291310561995e-07 all mean 5.501196028490085e-06
1.4585575627279468e-06 1.458559495404188e-06
rl training, epoch2, iter0, batch847/1133, batch loss:1.458559495404188e-06, Training time:44029.77450466156
batch reward last col mean 5.131953173531656e-08 first col mean 1.41405536169259e-07 all mean 1.2672181583184283e-05
3.984680733992718e-05 3.984681097790599e-05
rl training, epoch2, iter0, batch848/1133, batch loss:3.984681097790599e-05, Training time:44048.83173274994
batch reward last col mean 1.0718862313296995e-06 first col mean 3.69876670447411e-06 all mean 3.721029861480929e-05
0.00018837251991499215 0.0001883725490188226
rl training, epoch2, iter0, batch849/1133, batch loss:0.0001883725490188226, Training time:44066.07929563522
batch reward last col mean 4.83264420836349e-06 first col mean 1.9008680851584359e-07 all mean 1.712893572403118e-05
1.4237187315302435e-05 1.4237188224797137e-05
rl training, epoch2, iter0, batch850/1133, batch loss:1.4237188224797137e-05, Training time:44082.83042550087
batch reward last col mean 1.4278636228937103e-07 first col mean 1.6802786717562412e-07 all mean 6.143942300695926e-06
9.084908015211113e-06 9.084908015211113e-06
rl training, epoch2, iter0, batch851/1133, batch loss:9.084908015211113e-06, Training time:44099.79433083534
batch reward last col mean 2.538497057003042e-08 first col mean 7.22385991025476e-08 all mean 1.3355427199712722e-06
1.3481146652338794e-06 1.3481145515470416e-06
rl training, epoch2, iter0, batch852/1133, batch loss:1.3481145515470416e-06, Training time:44116.67565560341
batch reward last col mean 6.39083950204622e-08 first col mean 2.9716106837440748e-06 all mean 5.7841220950649586e-06
3.905381163349375e-05 3.905381163349375e-05
rl training, epoch2, iter0, batch853/1133, batch loss:3.905381163349375e-05, Training time:44133.49770236015
batch reward last col mean 2.4857570224412484e-08 first col mean 0.0007896866882219911 all mean 6.425274477805942e-05
7.594011549372226e-05 7.594011549372226e-05
rl training, epoch2, iter0, batch854/1133, batch loss:7.594011549372226e-05, Training time:44149.87480092049
batch reward last col mean 1.5052083313094045e-07 first col mean 1.5570483924420842e-07 all mean 2.175022245864966e-06
3.942678631574381e-06 3.942678631574381e-06
rl training, epoch2, iter0, batch855/1133, batch loss:3.942678631574381e-06, Training time:44166.59962892532
batch reward last col mean 1.5881582271504158e-07 first col mean 1.7322303392575122e-05 all mean 1.9423887351877056e-05
3.110296165687032e-05 3.110296165687032e-05
rl training, epoch2, iter0, batch856/1133, batch loss:3.110296165687032e-05, Training time:44183.28714585304
batch reward last col mean 7.021844439236702e-09 first col mean 2.642790946083551e-07 all mean 8.970409908215515e-06
1.2984235581825487e-05 1.2984237400814891e-05
rl training, epoch2, iter0, batch857/1133, batch loss:1.2984237400814891e-05, Training time:44200.076394319534
batch reward last col mean 5.380002789934224e-07 first col mean 2.7641915949061513e-05 all mean 1.671256177360192e-05
7.571872265543789e-05 7.571872265543789e-05
rl training, epoch2, iter0, batch858/1133, batch loss:7.571872265543789e-05, Training time:44216.651656627655
batch reward last col mean 2.4622293040010845e-06 first col mean 6.622967418934422e-08 all mean 4.1753783079911955e-06
2.1409270630101673e-05 2.1409270630101673e-05
rl training, epoch2, iter0, batch859/1133, batch loss:2.1409270630101673e-05, Training time:44234.549437999725
batch reward last col mean 1.8861868511521607e-07 first col mean 0.0009519067825749516 all mean 1.8084474504576065e-05
1.2180549674667418e-05 1.2180547855678014e-05
rl training, epoch2, iter0, batch860/1133, batch loss:1.2180547855678014e-05, Training time:44251.23928666115
batch reward last col mean 0.0006579619366675615 first col mean 0.0010019897017627954 all mean 0.0006684390245936811
0.00018283702956978232 0.00018283704412169755
rl training, epoch2, iter0, batch861/1133, batch loss:0.00018283704412169755, Training time:44268.39872837067
batch reward last col mean 0.0021531626116484404 first col mean 1.7087415471905842e-05 all mean 0.0017906860448420048
0.00026771644479595125 0.00026771644479595125
rl training, epoch2, iter0, batch862/1133, batch loss:0.00026771644479595125, Training time:44286.48158144951
batch reward last col mean 1.414935013599461e-08 first col mean 4.335768608143553e-05 all mean 3.8626159948762506e-05
8.975007222034037e-05 8.975007949629799e-05
rl training, epoch2, iter0, batch863/1133, batch loss:8.975007949629799e-05, Training time:44304.32641983032
batch reward last col mean 0.001168586895801127 first col mean 1.882052629298414e-07 all mean 0.00109245372004807
9.796956874197349e-05 9.796954691410065e-05
rl training, epoch2, iter0, batch864/1133, batch loss:9.796954691410065e-05, Training time:44321.130546331406
batch reward last col mean 7.779018318387898e-09 first col mean 3.5450170798867475e-06 all mean 4.492350490181707e-05
0.00021820388792548329 0.00021820387337356806
rl training, epoch2, iter0, batch865/1133, batch loss:0.00021820387337356806, Training time:44337.852565050125
batch reward last col mean 1.0712555109648747e-07 first col mean 2.580773461602348e-08 all mean 1.7594868040760048e-05
7.837453495085356e-07 7.837396083232306e-07
rl training, epoch2, iter0, batch866/1133, batch loss:7.837396083232306e-07, Training time:44354.346229314804
batch reward last col mean 7.631184928413859e-08 first col mean 2.124768252542708e-05 all mean 2.9954067031212617e-06
1.273843281524023e-05 1.2738433724734932e-05
rl training, epoch2, iter0, batch867/1133, batch loss:1.2738433724734932e-05, Training time:44370.85044169426
batch reward last col mean 2.745791221059335e-07 first col mean 0.0011973626678809524 all mean 4.588075171341188e-05
0.00011355249444022775 0.00011355249444022775
rl training, epoch2, iter0, batch868/1133, batch loss:0.00011355249444022775, Training time:44389.92296743393
batch reward last col mean 0.0008046965231187642 first col mean 1.2579434951476287e-06 all mean 0.0007817670120857656
9.156460873782635e-05 9.156460873782635e-05
rl training, epoch2, iter0, batch869/1133, batch loss:9.156460873782635e-05, Training time:44409.32780146599
batch reward last col mean 5.802423430623094e-08 first col mean 0.0005948715261183679 all mean 1.230057478096569e-05
1.4730600923940074e-05 1.4730600014445372e-05
rl training, epoch2, iter0, batch870/1133, batch loss:1.4730600014445372e-05, Training time:44428.25612449646
batch reward last col mean 7.553706637963842e-08 first col mean 3.212941237507039e-07 all mean 1.325568064203253e-06
1.035225182022259e-06 1.035225182022259e-06
rl training, epoch2, iter0, batch871/1133, batch loss:1.035225182022259e-06, Training time:44445.72491168976
batch reward last col mean 1.3403442267190258e-07 first col mean 3.9804717744118534e-08 all mean 1.551928107801359e-05
5.931136547587812e-05 5.931136547587812e-05
rl training, epoch2, iter0, batch872/1133, batch loss:5.931136547587812e-05, Training time:44463.44765138626
batch reward last col mean 2.5902892275553313e-07 first col mean 3.493166786938673e-06 all mean 1.1344014637870714e-05
7.261987047968432e-05 7.261987047968432e-05
rl training, epoch2, iter0, batch873/1133, batch loss:7.261987047968432e-05, Training time:44480.18569588661
batch reward last col mean 0.002490284387022257 first col mean 3.49746164829412e-06 all mean 0.002266401657834649
0.0001532193273305893 0.00015321931277867407
rl training, epoch2, iter0, batch874/1133, batch loss:0.00015321931277867407, Training time:44497.14167332649
batch reward last col mean 1.242272062995653e-08 first col mean 9.90118132904172e-05 all mean 7.799504601280205e-06
5.7743091019801795e-06 5.7743091019801795e-06
rl training, epoch2, iter0, batch875/1133, batch loss:5.7743091019801795e-06, Training time:44513.74531888962
batch reward last col mean 1.1327620619283607e-08 first col mean 5.907454578846227e-06 all mean 9.16784210858168e-06
3.836672840407118e-05 3.836672840407118e-05
rl training, epoch2, iter0, batch876/1133, batch loss:3.836672840407118e-05, Training time:44530.23371052742
batch reward last col mean 3.481088469925453e-06 first col mean 9.613526344764978e-06 all mean 3.582977660698816e-05
9.121196490013972e-05 9.121196490013972e-05
rl training, epoch2, iter0, batch877/1133, batch loss:9.121196490013972e-05, Training time:44546.78943347931
batch reward last col mean 0.0001005937738227658 first col mean 1.2279039651730272e-07 all mean 9.900164150167257e-05
1.4250284948502667e-05 1.4250284948502667e-05
rl training, epoch2, iter0, batch878/1133, batch loss:1.4250284948502667e-05, Training time:44563.32409596443
batch reward last col mean 2.9582626126511968e-08 first col mean 3.954231033276301e-06 all mean 9.354538974548632e-07
5.792574938823236e-06 5.792574938823236e-06
rl training, epoch2, iter0, batch879/1133, batch loss:5.792574938823236e-06, Training time:44580.00450372696
batch reward last col mean 2.639786771396757e-06 first col mean 1.3722400581173133e-05 all mean 9.043055797519628e-06
1.6709378542145714e-05 1.6709378542145714e-05
rl training, epoch2, iter0, batch880/1133, batch loss:1.6709378542145714e-05, Training time:44596.864248514175
batch reward last col mean 5.944223602227794e-08 first col mean 3.556160379503126e-07 all mean 1.761797466315329e-05
5.956299719400704e-05 5.956299719400704e-05
rl training, epoch2, iter0, batch881/1133, batch loss:5.956299719400704e-05, Training time:44613.47173285484
batch reward last col mean 0.0019339878344908357 first col mean 6.625102287216578e-06 all mean 0.0014279602328315377
0.0001832827547332272 0.0001832827547332272
rl training, epoch2, iter0, batch882/1133, batch loss:0.0001832827547332272, Training time:44632.67773270607
batch reward last col mean 5.729406993282282e-08 first col mean 9.495515769231133e-07 all mean 2.8045481030858355e-06
5.216895260673482e-06 5.21689435117878e-06
rl training, epoch2, iter0, batch883/1133, batch loss:5.21689435117878e-06, Training time:44651.27344107628
batch reward last col mean 3.020828387434449e-08 first col mean 3.161776703564101e-06 all mean 1.0133055184269324e-05
2.2431984689319506e-05 2.24319810513407e-05
rl training, epoch2, iter0, batch884/1133, batch loss:2.24319810513407e-05, Training time:44669.41934490204
batch reward last col mean 7.065935836436665e-09 first col mean 1.6024825526983477e-05 all mean 1.1577645636862144e-05
4.5865439460612833e-05 4.5865439460612833e-05
rl training, epoch2, iter0, batch885/1133, batch loss:4.5865439460612833e-05, Training time:44688.04206991196
batch reward last col mean 3.154469396804416e-08 first col mean 4.845568923883548e-07 all mean 4.051099949720083e-06
2.5991308575612493e-05 2.5991308575612493e-05
rl training, epoch2, iter0, batch886/1133, batch loss:2.5991308575612493e-05, Training time:44705.72546315193
batch reward last col mean 2.0836193215245657e-08 first col mean 7.941884661022414e-08 all mean 1.1259642633376643e-05
6.287552241701633e-05 6.287552241701633e-05
rl training, epoch2, iter0, batch887/1133, batch loss:6.287552241701633e-05, Training time:44722.22999572754
batch reward last col mean 7.416618785782703e-08 first col mean 2.0089831309633155e-07 all mean 1.1391014140826883e-06
3.953313807869563e-06 3.953313807869563e-06
rl training, epoch2, iter0, batch888/1133, batch loss:3.953313807869563e-06, Training time:44738.86738348007
batch reward last col mean 9.924015387241525e-09 first col mean 1.84718359719227e-07 all mean 5.488488568516914e-06
1.196601351693971e-05 1.196601351693971e-05
rl training, epoch2, iter0, batch889/1133, batch loss:1.196601351693971e-05, Training time:44755.41044521332
batch reward last col mean 2.8495687729446217e-06 first col mean 8.614696525910404e-06 all mean 1.042523217620328e-05
1.2772876289091073e-05 1.2772873560606968e-05
rl training, epoch2, iter0, batch890/1133, batch loss:1.2772873560606968e-05, Training time:44771.875178813934
batch reward last col mean 0.0021856268867850304 first col mean 0.00014500001270789653 all mean 0.0018735311459749937
0.0001544620026834309 0.0001544620026834309
rl training, epoch2, iter0, batch891/1133, batch loss:0.0001544620026834309, Training time:44788.57768988609
batch reward last col mean 2.140507831427385e-06 first col mean 2.1064917746116407e-05 all mean 4.9185450734512415e-06
1.1614682989602443e-05 1.161468117061304e-05
rl training, epoch2, iter0, batch892/1133, batch loss:1.161468117061304e-05, Training time:44805.03822350502
batch reward last col mean 5.046237561145972e-07 first col mean 0.00034495239378884435 all mean 8.941081432567444e-06
8.197109309548978e-06 8.19711021904368e-06
rl training, epoch2, iter0, batch893/1133, batch loss:8.19711021904368e-06, Training time:44821.66524887085
batch reward last col mean 1.8850061067610113e-08 first col mean 2.704391555141683e-08 all mean 7.308224212465575e-06
3.292880137450993e-05 3.292880137450993e-05
rl training, epoch2, iter0, batch894/1133, batch loss:3.292880137450993e-05, Training time:44839.16353607178
batch reward last col mean 2.23297771384523e-08 first col mean 2.335483486604062e-07 all mean 8.486987098876853e-06
3.5767414374276996e-05 3.57674180122558e-05
rl training, epoch2, iter0, batch895/1133, batch loss:3.57674180122558e-05, Training time:44855.677372694016
batch reward last col mean 8.629597687104251e-06 first col mean 7.599413947900757e-06 all mean 3.6489858757704496e-05
2.0378898625494912e-05 2.0378891349537298e-05
rl training, epoch2, iter0, batch896/1133, batch loss:2.0378891349537298e-05, Training time:44872.486691236496
batch reward last col mean 6.45716937697216e-08 first col mean 7.969968578436237e-07 all mean 3.2917636417550966e-05
0.0002945232845377177 0.00029452325543388724
rl training, epoch2, iter0, batch897/1133, batch loss:0.00029452325543388724, Training time:44889.18513393402
batch reward last col mean 4.790184675584896e-07 first col mean 0.00015125208301469684 all mean 5.6539133765909355e-06
1.3006523658987135e-05 1.3006523658987135e-05
rl training, epoch2, iter0, batch898/1133, batch loss:1.3006523658987135e-05, Training time:44905.87240934372
batch reward last col mean 3.592679931330167e-08 first col mean 0.00019218551460653543 all mean 9.836150638875552e-06
2.445612699375488e-05 2.445612699375488e-05
rl training, epoch2, iter0, batch899/1133, batch loss:2.445612699375488e-05, Training time:44922.221247673035
batch reward last col mean 3.089697031555261e-08 first col mean 6.962243332964135e-07 all mean 1.1177725127708982e-06
1.795391654013656e-06 1.7953915403268184e-06
rl training, epoch2, iter0, batch900/1133, batch loss:1.7953915403268184e-06, Training time:44940.203719615936
batch reward last col mean 3.5532544018224144e-08 first col mean 1.1426591299823485e-06 all mean 3.0875360153004294e-06
9.307470463681966e-06 9.307470463681966e-06
rl training, epoch2, iter0, batch901/1133, batch loss:9.307470463681966e-06, Training time:44958.313438892365
batch reward last col mean 0.0001464708911953494 first col mean 2.7748313868869445e-07 all mean 0.00014820878277532756
4.512349551077932e-05 4.512349551077932e-05
rl training, epoch2, iter0, batch902/1133, batch loss:4.512349551077932e-05, Training time:44977.048253536224
batch reward last col mean 8.090748337963305e-07 first col mean 0.00020159684936515987 all mean 6.548758847202407e-06
1.7802294678403996e-05 1.7802292859414592e-05
rl training, epoch2, iter0, batch903/1133, batch loss:1.7802292859414592e-05, Training time:44996.61526656151
batch reward last col mean 5.130192221258767e-05 first col mean 2.1500883917724423e-07 all mean 5.385117037803866e-05
6.429498898796737e-05 6.429498898796737e-05
rl training, epoch2, iter0, batch904/1133, batch loss:6.429498898796737e-05, Training time:45014.7879486084
batch reward last col mean 1.2809496183763258e-06 first col mean 1.6183115292278671e-07 all mean 5.480888285092078e-05
0.0001726185146253556 0.00017261850007344037
rl training, epoch2, iter0, batch905/1133, batch loss:0.00017261850007344037, Training time:45032.39578270912
batch reward last col mean 5.727171270564213e-08 first col mean 1.587857582308061e-06 all mean 2.0469749870244414e-05
5.236337165115401e-05 5.236337165115401e-05
rl training, epoch2, iter0, batch906/1133, batch loss:5.236337165115401e-05, Training time:45049.794267416
batch reward last col mean 4.746438264646713e-08 first col mean 6.1293048929655924e-06 all mean 1.1653760338958818e-06
2.1132909751031548e-06 2.1132907477294793e-06
rl training, epoch2, iter0, batch907/1133, batch loss:2.1132907477294793e-06, Training time:45066.60139942169
batch reward last col mean 1.7773279736843506e-08 first col mean 1.4349311072692217e-07 all mean 5.42301359018893e-06
2.037188460235484e-05 2.0371880964376032e-05
rl training, epoch2, iter0, batch908/1133, batch loss:2.0371880964376032e-05, Training time:45083.144423246384
batch reward last col mean 0.0001335420529358089 first col mean 0.00019480349146761 all mean 0.0001288197818212211
2.0783209038199857e-05 2.078320540022105e-05
rl training, epoch2, iter0, batch909/1133, batch loss:2.078320540022105e-05, Training time:45099.603580236435
batch reward last col mean 1.3735882475884864e-07 first col mean 1.4911743164702784e-06 all mean 2.8250096875126474e-06
8.6099234977155e-06 8.609924407210201e-06
rl training, epoch2, iter0, batch910/1133, batch loss:8.609924407210201e-06, Training time:45116.122247457504
batch reward last col mean 1.1797725392170832e-06 first col mean 8.735142182558775e-05 all mean 2.285614755237475e-06
7.248002589221869e-07 7.248000315485115e-07
rl training, epoch2, iter0, batch911/1133, batch loss:7.248000315485115e-07, Training time:45132.700380802155
batch reward last col mean 1.5150945387176762e-07 first col mean 2.436198087707453e-08 all mean 1.6866024452610873e-05
2.8867305445601232e-05 2.8867305445601232e-05
rl training, epoch2, iter0, batch912/1133, batch loss:2.8867305445601232e-05, Training time:45149.13217830658
batch reward last col mean 1.7734770381139242e-06 first col mean 4.066175733896671e-07 all mean 7.222437034215545e-06
2.3356038582278416e-05 2.3356038582278416e-05
rl training, epoch2, iter0, batch913/1133, batch loss:2.3356038582278416e-05, Training time:45165.721031188965
batch reward last col mean 2.3561003814620562e-08 first col mean 1.5789782992214896e-07 all mean 1.2689192772086244e-05
5.4549942433368415e-05 5.4549942433368415e-05
rl training, epoch2, iter0, batch914/1133, batch loss:5.4549942433368415e-05, Training time:45182.655856609344
batch reward last col mean 2.527765673221438e-06 first col mean 1.0961046115198769e-07 all mean 1.947668715729378e-05
2.364293504797388e-05 2.364293504797388e-05
rl training, epoch2, iter0, batch915/1133, batch loss:2.364293504797388e-05, Training time:45199.413701057434
batch reward last col mean 0.0003774986835196614 first col mean 5.8813116083911154e-06 all mean 0.00032713753171265125
3.267185820732266e-05 3.267185820732266e-05
rl training, epoch2, iter0, batch916/1133, batch loss:3.267185820732266e-05, Training time:45216.01254606247
batch reward last col mean 1.7887517245185336e-08 first col mean 1.6115700418595225e-07 all mean 1.131012959376676e-05
2.038088859990239e-05 2.038088859990239e-05
rl training, epoch2, iter0, batch917/1133, batch loss:2.038088859990239e-05, Training time:45232.54163432121
batch reward last col mean 1.046335107446339e-08 first col mean 1.9907616660930216e-05 all mean 4.113866452826187e-06
3.5985815429739887e-06 3.5985813156003132e-06
rl training, epoch2, iter0, batch918/1133, batch loss:3.5985813156003132e-06, Training time:45248.9431245327
batch reward last col mean 8.508771998094744e-07 first col mean 4.991259174857987e-07 all mean 6.802034931752132e-06
9.134962965617888e-06 9.134962965617888e-06
rl training, epoch2, iter0, batch919/1133, batch loss:9.134962965617888e-06, Training time:45266.08701324463
batch reward last col mean 3.641292778411298e-08 first col mean 8.497802809870336e-06 all mean 1.3683375073014759e-06
7.854789146222174e-06 7.854789146222174e-06
rl training, epoch2, iter0, batch920/1133, batch loss:7.854789146222174e-06, Training time:45282.66393494606
batch reward last col mean 5.1697948947548866e-05 first col mean 1.0649758905856288e-06 all mean 3.0305925974971615e-05
0.0002296240272698924 0.00022962405637372285
rl training, epoch2, iter0, batch921/1133, batch loss:0.00022962405637372285, Training time:45301.21763396263
batch reward last col mean 4.61879912094787e-09 first col mean 1.65300298249349e-06 all mean 4.062095285917167e-06
3.3971696211665403e-06 3.397170530661242e-06
rl training, epoch2, iter0, batch922/1133, batch loss:3.397170530661242e-06, Training time:45318.934589385986
batch reward last col mean 3.892876421218716e-08 first col mean 2.6746346293293755e-07 all mean 1.6618329027551226e-05
7.680447743041441e-05 7.680447743041441e-05
rl training, epoch2, iter0, batch923/1133, batch loss:7.680447743041441e-05, Training time:45336.75535750389
batch reward last col mean 2.4061046133283526e-07 first col mean 9.035263701662188e-07 all mean 2.9473487757059047e-06
1.710767173790373e-05 1.7107669918914326e-05
rl training, epoch2, iter0, batch924/1133, batch loss:1.7107669918914326e-05, Training time:45354.2958920002
batch reward last col mean 8.575088031648193e-06 first col mean 4.8793408495839685e-05 all mean 1.0443004612170625e-05
9.881562618829776e-06 9.881562618829776e-06
rl training, epoch2, iter0, batch925/1133, batch loss:9.881562618829776e-06, Training time:45370.83158159256
batch reward last col mean 9.28760286456054e-08 first col mean 7.45089928386733e-05 all mean 1.9077342585660517e-06
1.00269562608446e-06 1.00269562608446e-06
rl training, epoch2, iter0, batch926/1133, batch loss:1.00269562608446e-06, Training time:45387.34549117088
batch reward last col mean 1.2152655770591991e-08 first col mean 0.0005206909845583141 all mean 1.579034505994059e-05
1.7272386685363017e-05 1.7272386685363017e-05
rl training, epoch2, iter0, batch927/1133, batch loss:1.7272386685363017e-05, Training time:45403.81334376335
batch reward last col mean 4.4356454509397736e-07 first col mean 1.889133159238554e-06 all mean 2.9300535970833153e-06
1.6641988622723147e-05 1.6641986803733744e-05
rl training, epoch2, iter0, batch928/1133, batch loss:1.6641986803733744e-05, Training time:45420.9720594883
batch reward last col mean 4.900963176623918e-05 first col mean 0.0012612729333341122 all mean 7.196137448772788e-05
0.00013877633318770677 0.00013877633318770677
rl training, epoch2, iter0, batch929/1133, batch loss:0.00013877633318770677, Training time:45437.58959817886
batch reward last col mean 2.4015929739107378e-05 first col mean 3.84922493879003e-08 all mean 2.5637978978920728e-05
4.364691903901985e-06 4.364691903901985e-06
rl training, epoch2, iter0, batch930/1133, batch loss:4.364691903901985e-06, Training time:45454.19084358215
batch reward last col mean 3.1790766570338747e-06 first col mean 6.160112775432935e-08 all mean 2.3740520191495307e-05
0.00013548672723118216 0.0001354866981273517
rl training, epoch2, iter0, batch931/1133, batch loss:0.0001354866981273517, Training time:45470.72478246689
batch reward last col mean 2.251352384519123e-07 first col mean 0.0002166562480852008 all mean 8.656408681417815e-06
1.3622608094010502e-05 1.3622608094010502e-05
rl training, epoch2, iter0, batch932/1133, batch loss:1.3622608094010502e-05, Training time:45487.401901721954
batch reward last col mean 3.729412867414794e-08 first col mean 8.864930691743211e-07 all mean 2.019528255914338e-05
3.495543933240697e-05 3.495544660836458e-05
rl training, epoch2, iter0, batch933/1133, batch loss:3.495544660836458e-05, Training time:45503.9688770771
batch reward last col mean 7.51706963342258e-09 first col mean 0.001038788235746324 all mean 2.7068354029324837e-05
0.00012953153054695576 0.00012953153054695576
rl training, epoch2, iter0, batch934/1133, batch loss:0.00012953153054695576, Training time:45522.02537918091
batch reward last col mean 0.00024894438683986664 first col mean 4.869598910772766e-07 all mean 9.699893780634739e-06
3.321699841762893e-05 3.321699841762893e-05
rl training, epoch2, iter0, batch935/1133, batch loss:3.321699841762893e-05, Training time:45540.798636198044
batch reward last col mean 9.991217098104244e-08 first col mean 2.5761237338883802e-06 all mean 1.7825259419623762e-05
2.1155906324565876e-06 2.1155935883143684e-06
rl training, epoch2, iter0, batch936/1133, batch loss:2.1155935883143684e-06, Training time:45559.320115566254
batch reward last col mean 8.786400940152816e-07 first col mean 9.475988008489367e-06 all mean 1.868163417384494e-05
6.305635906755924e-05 6.305635179160163e-05
rl training, epoch2, iter0, batch937/1133, batch loss:6.305635179160163e-05, Training time:45577.19830060005
batch reward last col mean 2.2577514755539596e-06 first col mean 0.00014601773000322282 all mean 2.1449059204314835e-05
3.83658152713906e-05 3.836581890936941e-05
rl training, epoch2, iter0, batch938/1133, batch loss:3.836581890936941e-05, Training time:45595.063333034515
batch reward last col mean 1.0956928697680723e-08 first col mean 6.247376404644456e-06 all mean 6.64119079374359e-06
1.2409055671014357e-05 1.2409054761519656e-05
rl training, epoch2, iter0, batch939/1133, batch loss:1.2409054761519656e-05, Training time:45612.04038119316
batch reward last col mean 1.1205985472884095e-08 first col mean 7.301038749574218e-06 all mean 8.24361268314533e-06
8.757107025303412e-06 8.757108844292816e-06
rl training, epoch2, iter0, batch940/1133, batch loss:8.757108844292816e-06, Training time:45628.682510614395
batch reward last col mean 3.4027786455226305e-07 first col mean 1.1803894267359283e-05 all mean 1.939091998792719e-05
6.545793439727277e-05 6.545793439727277e-05
rl training, epoch2, iter0, batch941/1133, batch loss:6.545793439727277e-05, Training time:45645.11313152313
batch reward last col mean 1.698236573588474e-08 first col mean 1.2728001763662178e-07 all mean 4.227341833029641e-06
4.25164171247161e-06 4.25164171247161e-06
rl training, epoch2, iter0, batch942/1133, batch loss:4.25164171247161e-06, Training time:45661.69385910034
batch reward last col mean 1.3576442370322184e-07 first col mean 4.660761260311119e-05 all mean 5.244408021098934e-05
0.00012026100739603862 0.00012026100739603862
rl training, epoch2, iter0, batch943/1133, batch loss:0.00012026100739603862, Training time:45678.221440553665
batch reward last col mean 2.1232646929547627e-07 first col mean 2.4376561214012327e-08 all mean 3.253253817092627e-05
2.356694676564075e-05 2.356694130867254e-05
rl training, epoch2, iter0, batch944/1133, batch loss:2.356694130867254e-05, Training time:45694.84854698181
batch reward last col mean 1.2185129349973067e-08 first col mean 3.1576782077991083e-08 all mean 1.4582359654013999e-05
0.00010263758304063231 0.00010263758304063231
rl training, epoch2, iter0, batch945/1133, batch loss:0.00010263758304063231, Training time:45711.49662685394
batch reward last col mean 6.471911007110975e-08 first col mean 7.153187198127853e-07 all mean 3.2749067031545565e-06
5.1002662075916305e-06 5.100267117086332e-06
rl training, epoch2, iter0, batch946/1133, batch loss:5.100267117086332e-06, Training time:45727.97887945175
batch reward last col mean 4.832710374103044e-07 first col mean 3.9599486626684666e-05 all mean 6.570216100953985e-06
1.3567594578489661e-05 1.3567594578489661e-05
rl training, epoch2, iter0, batch947/1133, batch loss:1.3567594578489661e-05, Training time:45744.498834848404
batch reward last col mean 9.515107376500964e-05 first col mean 3.423467092034116e-07 all mean 0.00011722755152732134
7.454845035681501e-05 7.454845035681501e-05
rl training, epoch2, iter0, batch948/1133, batch loss:7.454845035681501e-05, Training time:45761.583674669266
batch reward last col mean 2.613715466281974e-08 first col mean 6.500111453533464e-07 all mean 2.8058966563548893e-05
7.493094017263502e-05 7.493094017263502e-05
rl training, epoch2, iter0, batch949/1133, batch loss:7.493094017263502e-05, Training time:45778.22912359238
batch reward last col mean 1.0184898201259784e-05 first col mean 0.00042089339694939554 all mean 5.898720701225102e-05
0.00019996616174466908 0.00019996614719275385
rl training, epoch2, iter0, batch950/1133, batch loss:0.00019996614719275385, Training time:45794.863893032074
batch reward last col mean 1.0963093188820494e-07 first col mean 0.0011815449688583612 all mean 4.192180131212808e-05
0.00016798927390482277 0.00016798927390482277
rl training, epoch2, iter0, batch951/1133, batch loss:0.00016798927390482277, Training time:45811.627531051636
batch reward last col mean 1.373981012875447e-05 first col mean 3.812077409293124e-07 all mean 5.7059064602071885e-06
3.0189294193405658e-05 3.018929601239506e-05
rl training, epoch2, iter0, batch952/1133, batch loss:3.018929601239506e-05, Training time:45830.8507938385
batch reward last col mean 8.402815001318231e-05 first col mean 6.634539317929011e-07 all mean 6.876475526951253e-05
2.635598684719298e-05 2.6355985028203577e-05
rl training, epoch2, iter0, batch953/1133, batch loss:2.6355985028203577e-05, Training time:45848.88502550125
batch reward last col mean 2.3519554304129997e-07 first col mean 8.594511768933444e-07 all mean 1.0072170880448539e-05
3.622891381382942e-05 3.622891745180823e-05
rl training, epoch2, iter0, batch954/1133, batch loss:3.622891745180823e-05, Training time:45866.38108563423
batch reward last col mean 3.83471984832795e-07 first col mean 1.3079577911412343e-05 all mean 1.1357318498994573e-06
3.4351751310168765e-06 3.4351744488958502e-06
rl training, epoch2, iter0, batch955/1133, batch loss:3.4351744488958502e-06, Training time:45884.78166937828
batch reward last col mean 3.996649979853828e-07 first col mean 5.969295671093278e-07 all mean 1.5587942471029237e-05
1.8886454199673608e-05 1.8886454199673608e-05
rl training, epoch2, iter0, batch956/1133, batch loss:1.8886454199673608e-05, Training time:45904.734853982925
batch reward last col mean 2.628825939154922e-07 first col mean 2.746978134382516e-05 all mean 3.501746505207848e-06
1.1625512343016453e-05 1.1625511433521751e-05
rl training, epoch2, iter0, batch957/1133, batch loss:1.1625511433521751e-05, Training time:45921.37822365761
batch reward last col mean 4.3807508518511895e-06 first col mean 1.9123763195239007e-05 all mean 2.4869195840437897e-06
3.13095074488956e-06 3.1309509722632356e-06
rl training, epoch2, iter0, batch958/1133, batch loss:3.1309509722632356e-06, Training time:45938.18883776665
batch reward last col mean 0.004490753635764122 first col mean 9.927096016326686e-07 all mean 0.0031327256001532078
0.00036120391450822353 0.00036120391450822353
rl training, epoch2, iter0, batch959/1133, batch loss:0.00036120391450822353, Training time:45954.683057785034
batch reward last col mean 1.2865090326386053e-08 first col mean 2.6585007617541123e-06 all mean 4.087403431185521e-05
0.00010916946484940127 0.00010916946484940127
rl training, epoch2, iter0, batch960/1133, batch loss:0.00010916946484940127, Training time:45971.57937455177
batch reward last col mean 8.30778645877217e-08 first col mean 2.7498694521455036e-07 all mean 8.24808648758335e-06
2.2351849111146294e-05 2.23518527491251e-05
rl training, epoch2, iter0, batch961/1133, batch loss:2.23518527491251e-05, Training time:45988.4672665596
batch reward last col mean 6.717307599046762e-08 first col mean 0.00015723351680207998 all mean 1.4935519175196532e-05
1.2871442777395714e-05 1.2871446415374521e-05
rl training, epoch2, iter0, batch962/1133, batch loss:1.2871446415374521e-05, Training time:46005.25759959221
batch reward last col mean 2.3967359084053896e-05 first col mean 1.0259578857585439e-06 all mean 3.075618587899953e-05
1.864375917648431e-05 1.8643757357494906e-05
rl training, epoch2, iter0, batch963/1133, batch loss:1.8643757357494906e-05, Training time:46021.86613821983
batch reward last col mean 4.1508047843308304e-07 first col mean 2.3866272513828335e-08 all mean 1.5006775356596336e-05
7.02327597537078e-05 7.02327597537078e-05
rl training, epoch2, iter0, batch964/1133, batch loss:7.02327597537078e-05, Training time:46038.55569386482
batch reward last col mean 1.2998172849165712e-07 first col mean 2.1610328531096457e-06 all mean 7.4227259574399795e-06
9.725584277475718e-06 9.725583367981017e-06
rl training, epoch2, iter0, batch965/1133, batch loss:9.725583367981017e-06, Training time:46055.32194566727
batch reward last col mean 2.1289871199314803e-08 first col mean 4.551419863219053e-08 all mean 1.66121080837911e-05
6.5869367972482e-05 6.586936069652438e-05
rl training, epoch2, iter0, batch966/1133, batch loss:6.586936069652438e-05, Training time:46071.85358572006
batch reward last col mean 8.4400795685724e-08 first col mean 7.605191967741121e-06 all mean 2.3400582449539797e-06
1.8272492070536828e-06 1.8272493207405205e-06
rl training, epoch2, iter0, batch967/1133, batch loss:1.8272493207405205e-06, Training time:46088.33266186714
batch reward last col mean 3.963993435718294e-07 first col mean 4.0642554210990056e-08 all mean 3.7046499983262038e-06
5.382988547353307e-06 5.382987637858605e-06
rl training, epoch2, iter0, batch968/1133, batch loss:5.382987637858605e-06, Training time:46104.862906217575
batch reward last col mean 4.126727759512505e-08 first col mean 3.0723683153155434e-07 all mean 1.231829901371384e-05
2.1159639800316654e-05 2.115963798132725e-05
rl training, epoch2, iter0, batch969/1133, batch loss:2.115963798132725e-05, Training time:46122.38279461861
batch reward last col mean 6.6922232200283815e-09 first col mean 4.360634591193957e-07 all mean 2.846421693902812e-06
3.902685875800671e-06 3.902686785295373e-06
rl training, epoch2, iter0, batch970/1133, batch loss:3.902686785295373e-06, Training time:46140.70188164711
batch reward last col mean 7.661818557380684e-08 first col mean 1.5823637795620016e-06 all mean 2.5356073820148595e-05
9.381239215144888e-05 9.381238487549126e-05
rl training, epoch2, iter0, batch971/1133, batch loss:9.381238487549126e-05, Training time:46159.32273077965
batch reward last col mean 1.9344469137649867e-08 first col mean 0.0011319195618852973 all mean 2.213539664808195e-05
0.0001458848564652726 0.0001458848564652726
rl training, epoch2, iter0, batch972/1133, batch loss:0.0001458848564652726, Training time:46177.11266565323
batch reward last col mean 0.00010137780191143975 first col mean 3.984651993960142e-05 all mean 0.00011249702220084146
0.0001404948707204312 0.00014049488527234644
rl training, epoch2, iter0, batch973/1133, batch loss:0.00014049488527234644, Training time:46194.27844166756
batch reward last col mean 7.091706066830739e-08 first col mean 3.507466317387298e-07 all mean 9.078886250790674e-06
3.9884191210148856e-05 3.988419484812766e-05
rl training, epoch2, iter0, batch974/1133, batch loss:3.988419484812766e-05, Training time:46211.63663625717
batch reward last col mean 8.923702807805967e-07 first col mean 1.6700460037100129e-06 all mean 3.781926352530718e-06
3.4860288451454835e-06 3.48602952726651e-06
rl training, epoch2, iter0, batch975/1133, batch loss:3.48602952726651e-06, Training time:46228.20020699501
batch reward last col mean 6.745885457348777e-06 first col mean 6.775971996830776e-07 all mean 2.241730544483289e-05
0.00012050473014824092 0.00012050473014824092
rl training, epoch2, iter0, batch976/1133, batch loss:0.00012050473014824092, Training time:46244.81343984604
batch reward last col mean 2.9341131835280976e-07 first col mean 6.666064678029215e-08 all mean 4.390775939100422e-05
0.00038511573802679777 0.00038511567981913686
rl training, epoch2, iter0, batch977/1133, batch loss:0.00038511567981913686, Training time:46262.017522096634
batch reward last col mean 8.514201255138687e-08 first col mean 3.852857162200962e-07 all mean 1.3033993127464782e-05
2.3332775526796468e-05 2.333277188881766e-05
rl training, epoch2, iter0, batch978/1133, batch loss:2.333277188881766e-05, Training time:46279.015818595886
batch reward last col mean 5.54520283913007e-07 first col mean 0.00016910210251808167 all mean 2.1136847863090225e-05
6.758269591955468e-05 6.758269591955468e-05
rl training, epoch2, iter0, batch979/1133, batch loss:6.758269591955468e-05, Training time:46295.62765932083
batch reward last col mean 1.1120438614398154e-07 first col mean 0.0004830712277907878 all mean 2.373465758864768e-05
7.960800576256588e-05 7.96080130385235e-05
rl training, epoch2, iter0, batch980/1133, batch loss:7.96080130385235e-05, Training time:46312.203456401825
batch reward last col mean 0.00013581440725829452 first col mean 3.541003223972439e-08 all mean 0.0001375026913592592
1.4455316886596847e-05 1.4455320524575654e-05
rl training, epoch2, iter0, batch981/1133, batch loss:1.4455320524575654e-05, Training time:46328.78853535652
batch reward last col mean 5.98138782947899e-08 first col mean 1.6277662950869853e-07 all mean 3.4225674880872248e-06
3.3403166526113637e-06 3.3403166526113637e-06
rl training, epoch2, iter0, batch982/1133, batch loss:3.3403166526113637e-06, Training time:46345.30182027817
batch reward last col mean 1.4745945797756121e-08 first col mean 0.0026569601614028215 all mean 3.002258927153889e-05
9.236600453732535e-05 9.236600453732535e-05
rl training, epoch2, iter0, batch983/1133, batch loss:9.236600453732535e-05, Training time:46361.777747154236
batch reward last col mean 4.304210676764342e-07 first col mean 4.2943406697304454e-07 all mean 5.528958354261704e-06
6.0857146308990195e-06 6.085715540393721e-06
rl training, epoch2, iter0, batch984/1133, batch loss:6.085715540393721e-06, Training time:46378.64806890488
batch reward last col mean 1.0684962035156786e-06 first col mean 3.5806879168376327e-05 all mean 5.727092229790287e-06
3.460699190327432e-06 3.4606998724484583e-06
rl training, epoch2, iter0, batch985/1133, batch loss:3.4606998724484583e-06, Training time:46395.1335875988
batch reward last col mean 2.0513613208095194e-07 first col mean 2.0135752492933534e-05 all mean 5.2473496907623485e-06
6.659834980382584e-06 6.659835435129935e-06
rl training, epoch2, iter0, batch986/1133, batch loss:6.659835435129935e-06, Training time:46411.629719018936
batch reward last col mean 0.0002037641970673576 first col mean 0.000523462425917387 all mean 1.1183939932379872e-05
1.7133303117589094e-05 1.7133303117589094e-05
rl training, epoch2, iter0, batch987/1133, batch loss:1.7133303117589094e-05, Training time:46428.168325185776
batch reward last col mean 2.508155012037605e-05 first col mean 1.2875007996626664e-05 all mean 4.49410654255189e-05
0.00013241868873592466 0.00013241868873592466
rl training, epoch2, iter0, batch988/1133, batch loss:0.00013241868873592466, Training time:46447.363706588745
batch reward last col mean 4.842910072966333e-08 first col mean 2.8670554456766695e-05 all mean 7.67650726629654e-06
4.7184312279568985e-05 4.718431591754779e-05
rl training, epoch2, iter0, batch989/1133, batch loss:4.718431591754779e-05, Training time:46465.03664469719
batch reward last col mean 6.346810096147237e-06 first col mean 1.4275139619712718e-05 all mean 2.410705928923562e-05
0.00010616762301651761 0.00010616760118864477
rl training, epoch2, iter0, batch990/1133, batch loss:0.00010616760118864477, Training time:46482.978578329086
batch reward last col mean 4.894674248134834e-07 first col mean 7.122227998479502e-07 all mean 3.3572010579518974e-05
0.00022581500525120646 0.00022581500525120646
rl training, epoch2, iter0, batch991/1133, batch loss:0.00022581500525120646, Training time:46499.77270960808
batch reward last col mean 3.2328433263728584e-09 first col mean 3.493680083010986e-07 all mean 1.533632166683674e-05
3.536460280884057e-05 3.536460280884057e-05
rl training, epoch2, iter0, batch992/1133, batch loss:3.536460280884057e-05, Training time:46517.712530851364
batch reward last col mean 0.0038531403988599777 first col mean 5.675000807059405e-07 all mean 0.003620262024924159
0.0003512482508085668 0.0003512482508085668
rl training, epoch2, iter0, batch993/1133, batch loss:0.0003512482508085668, Training time:46534.82994580269
batch reward last col mean 1.3206970095325232e-07 first col mean 1.667113735948078e-07 all mean 3.278841631981777e-06
2.7614255486696493e-06 2.7614255486696493e-06
rl training, epoch2, iter0, batch994/1133, batch loss:2.7614255486696493e-06, Training time:46551.39366698265
batch reward last col mean 3.510050916588625e-08 first col mean 8.193134272005409e-05 all mean 2.3991965463210363e-06
5.500220140675083e-06 5.500219231180381e-06
rl training, epoch2, iter0, batch995/1133, batch loss:5.500219231180381e-06, Training time:46568.49062085152
batch reward last col mean 2.992258885115007e-08 first col mean 1.1538610067418631e-07 all mean 1.5681428067182424e-06
1.5303776308428496e-06 1.5303776308428496e-06
rl training, epoch2, iter0, batch996/1133, batch loss:1.5303776308428496e-06, Training time:46585.41318511963
batch reward last col mean 5.286808573146118e-07 first col mean 8.658844308229163e-06 all mean 1.2213040463393554e-05
2.098064032907132e-05 2.098064032907132e-05
rl training, epoch2, iter0, batch997/1133, batch loss:2.098064032907132e-05, Training time:46602.346759319305
batch reward last col mean 6.460595614043996e-08 first col mean 1.3689067600353155e-05 all mean 7.469443517038599e-06
9.628037332731765e-06 9.628037332731765e-06
rl training, epoch2, iter0, batch998/1133, batch loss:9.628037332731765e-06, Training time:46618.990770578384
batch reward last col mean 2.1278512463140942e-07 first col mean 2.7975143893854693e-05 all mean 4.4307812459010165e-06
1.296386653848458e-05 1.2963868357473984e-05
rl training, epoch2, iter0, batch999/1133, batch loss:1.2963868357473984e-05, Training time:46635.56432771683
batch reward last col mean 6.783555761558091e-08 first col mean 2.2339266081417009e-07 all mean 4.145770162722329e-06
1.8963166439789347e-05 1.8963166439789347e-05
rl training, epoch2, iter0, batch1000/1133, batch loss:1.8963166439789347e-05, Training time:46652.1425037384
batch reward last col mean 1.0038263553724391e-06 first col mean 6.566733645740896e-07 all mean 4.854464805248426e-06
1.2887258890259545e-05 1.2887258890259545e-05
rl training, epoch2, iter0, batch1001/1133, batch loss:1.2887258890259545e-05, Training time:46668.88712120056
batch reward last col mean 2.980468707391992e-06 first col mean 0.0013918388867750764 all mean 2.6819712729775347e-05
5.9868449170608073e-05 5.9868445532629266e-05
rl training, epoch2, iter0, batch1002/1133, batch loss:5.9868445532629266e-05, Training time:46687.053653001785
batch reward last col mean 3.121520421700552e-06 first col mean 1.0559886050032219e-06 all mean 3.5761659091804177e-06
1.1997261935903225e-05 1.1997261935903225e-05
rl training, epoch2, iter0, batch1003/1133, batch loss:1.1997261935903225e-05, Training time:46704.78605890274
batch reward last col mean 1.4642567691680597e-07 first col mean 3.765037206449051e-07 all mean 1.2101772881578654e-05
4.7109522711252794e-05 4.7109522711252794e-05
rl training, epoch2, iter0, batch1004/1133, batch loss:4.7109522711252794e-05, Training time:46723.18154168129
batch reward last col mean 2.2689296201860998e-06 first col mean 7.100068533105741e-09 all mean 3.4958263768203324e-06
8.285968760901596e-06 8.285969670396298e-06
rl training, epoch2, iter0, batch1005/1133, batch loss:8.285969670396298e-06, Training time:46741.17552828789
batch reward last col mean 2.785038304864429e-05 first col mean 1.4756793689230108e-06 all mean 4.5730401325272396e-05
2.395661431364715e-05 2.3956607037689537e-05
rl training, epoch2, iter0, batch1006/1133, batch loss:2.3956607037689537e-05, Training time:46759.61898612976
batch reward last col mean 6.901027660433101e-08 first col mean 1.6487657603647676e-06 all mean 9.52121990849264e-06
8.831851118884515e-06 8.831849299895111e-06
rl training, epoch2, iter0, batch1007/1133, batch loss:8.831849299895111e-06, Training time:46778.06762909889
batch reward last col mean 2.5281796212084373e-08 first col mean 3.61077327397652e-05 all mean 9.880099241854623e-06
1.5087087376741692e-05 1.5087088286236394e-05
rl training, epoch2, iter0, batch1008/1133, batch loss:1.5087088286236394e-05, Training time:46795.03426480293
batch reward last col mean 4.551896193305538e-09 first col mean 9.072647117136512e-06 all mean 4.006388280686224e-06
2.165586238334072e-06 2.1655851014656946e-06
rl training, epoch2, iter0, batch1009/1133, batch loss:2.1655851014656946e-06, Training time:46811.643139600754
batch reward last col mean 3.627777545034405e-08 first col mean 1.3581288271780068e-07 all mean 2.0691019017249346e-05
5.675799184245989e-05 5.675798820448108e-05
rl training, epoch2, iter0, batch1010/1133, batch loss:5.675798820448108e-05, Training time:46828.368894815445
batch reward last col mean 4.1640717540758487e-07 first col mean 9.381915333506186e-08 all mean 1.7031710513037979e-06
3.656013404906844e-06 3.656013404906844e-06
rl training, epoch2, iter0, batch1011/1133, batch loss:3.656013404906844e-06, Training time:46845.00829052925
batch reward last col mean 9.398942347615957e-05 first col mean 4.472687123779906e-06 all mean 9.860756836133078e-05
3.2116924558067694e-05 3.2116924558067694e-05
rl training, epoch2, iter0, batch1012/1133, batch loss:3.2116924558067694e-05, Training time:46862.337993860245
batch reward last col mean 7.859456445657997e-07 first col mean 3.4875132115530505e-08 all mean 1.032051477523055e-05
8.753525617066771e-05 8.753524161875248e-05
rl training, epoch2, iter0, batch1013/1133, batch loss:8.753524161875248e-05, Training time:46879.22482395172
batch reward last col mean 6.323483603409841e-08 first col mean 0.0005978309200145304 all mean 3.087789082201198e-05
0.0001312795066041872 0.0001312795066041872
rl training, epoch2, iter0, batch1014/1133, batch loss:0.0001312795066041872, Training time:46896.42716741562
batch reward last col mean 8.480183169012889e-05 first col mean 1.2240519708939246e-07 all mean 9.007383050629869e-05
5.6666904129087925e-05 5.6666904129087925e-05
rl training, epoch2, iter0, batch1015/1133, batch loss:5.6666904129087925e-05, Training time:46913.557515621185
batch reward last col mean 2.949918211925251e-07 first col mean 7.07922254150617e-08 all mean 1.3062825928500388e-05
6.022907837177627e-05 6.022907837177627e-05
rl training, epoch2, iter0, batch1016/1133, batch loss:6.022907837177627e-05, Training time:46930.32246828079
batch reward last col mean 3.5696210431979125e-08 first col mean 6.712227929028813e-08 all mean 3.222895884391619e-06
1.9000081010744907e-05 1.900008282973431e-05
rl training, epoch2, iter0, batch1017/1133, batch loss:1.900008282973431e-05, Training time:46946.910284519196
batch reward last col mean 1.6447588677692693e-06 first col mean 1.01082141554798e-05 all mean 3.554526483640075e-05
4.349225855548866e-05 4.349225855548866e-05
rl training, epoch2, iter0, batch1018/1133, batch loss:4.349225855548866e-05, Training time:46963.53653383255
batch reward last col mean 1.7248146022552646e-08 first col mean 0.0005750391283072531 all mean 2.416783172520809e-05
7.440851186402142e-05 7.44085045880638e-05
rl training, epoch2, iter0, batch1019/1133, batch loss:7.44085045880638e-05, Training time:46980.38759827614
batch reward last col mean 3.5923150676353544e-08 first col mean 1.762594692422681e-08 all mean 3.6088599699724e-06
2.1125566490809433e-05 2.1125566490809433e-05
rl training, epoch2, iter0, batch1020/1133, batch loss:2.1125566490809433e-05, Training time:46998.50279259682
batch reward last col mean 3.6868389230448884e-08 first col mean 1.2833156688429881e-05 all mean 1.700418215477839e-05
2.7935720936511643e-05 2.793571911752224e-05
rl training, epoch2, iter0, batch1021/1133, batch loss:2.793571911752224e-05, Training time:47015.91111564636
batch reward last col mean 1.9187798017128443e-08 first col mean 0.00010637352534104139 all mean 9.910027074511163e-06
2.5763376470422372e-05 2.5763376470422372e-05
rl training, epoch2, iter0, batch1022/1133, batch loss:2.5763376470422372e-05, Training time:47033.08046603203
batch reward last col mean 2.7612870212578855e-08 first col mean 4.0884810204033784e-08 all mean 1.2953347322763875e-05
7.536500925198197e-05 7.536500925198197e-05
rl training, epoch2, iter0, batch1023/1133, batch loss:7.536500925198197e-05, Training time:47051.20129990578
batch reward last col mean 1.8314684879783272e-08 first col mean 4.850877303397283e-06 all mean 3.5465118344291113e-06
3.805244432442123e-06 3.8052446598157985e-06
rl training, epoch2, iter0, batch1024/1133, batch loss:3.8052446598157985e-06, Training time:47070.2717397213
batch reward last col mean 4.2498891161812935e-07 first col mean 6.860863095425884e-07 all mean 6.069438768463442e-06
2.05911164812278e-05 2.0591114662238397e-05
rl training, epoch2, iter0, batch1025/1133, batch loss:2.0591114662238397e-05, Training time:47087.1614921093
batch reward last col mean 5.123784831084777e-06 first col mean 4.6247106411101413e-07 all mean 7.676459063077345e-06
2.2814390831626952e-05 2.2814392650616355e-05
rl training, epoch2, iter0, batch1026/1133, batch loss:2.2814392650616355e-05, Training time:47103.65150499344
batch reward last col mean 8.448938046967669e-07 first col mean 5.62504965273547e-07 all mean 6.20547234575497e-06
1.6762160157668404e-05 1.6762158338679e-05
rl training, epoch2, iter0, batch1027/1133, batch loss:1.6762158338679e-05, Training time:47120.07630395889
batch reward last col mean 1.7784637975637452e-06 first col mean 1.6267898672595038e-07 all mean 1.5000930034148041e-05
3.813416697084904e-05 3.813416697084904e-05
rl training, epoch2, iter0, batch1028/1133, batch loss:3.813416697084904e-05, Training time:47137.70493888855
batch reward last col mean 1.560357486596331e-05 first col mean 3.6985079532314558e-06 all mean 2.402624159003608e-05
1.7059966921806335e-05 1.7059970559785143e-05
rl training, epoch2, iter0, batch1029/1133, batch loss:1.7059970559785143e-05, Training time:47155.37585878372
batch reward last col mean 7.566336535091978e-07 first col mean 4.221127625214649e-08 all mean 2.100709025398828e-05
4.605036519933492e-05 4.605036519933492e-05
rl training, epoch2, iter0, batch1030/1133, batch loss:4.605036519933492e-05, Training time:47172.07409405708
batch reward last col mean 4.0331187278752623e-07 first col mean 2.848073599182044e-08 all mean 2.2726126189809293e-05
0.00013084358943160623 0.000130843574879691
rl training, epoch2, iter0, batch1031/1133, batch loss:0.000130843574879691, Training time:47188.84613585472
batch reward last col mean 1.3125095676969067e-07 first col mean 7.940012203278002e-09 all mean 3.3573745895409957e-05
7.450686098309234e-05 7.450685370713472e-05
rl training, epoch2, iter0, batch1032/1133, batch loss:7.450685370713472e-05, Training time:47205.29028582573
batch reward last col mean 1.4867160302856064e-07 first col mean 5.613302960227884e-07 all mean 9.718342880660202e-06
7.988293509697542e-05 7.988293509697542e-05
rl training, epoch2, iter0, batch1033/1133, batch loss:7.988293509697542e-05, Training time:47221.729976177216
batch reward last col mean 1.2236048974045843e-07 first col mean 9.087016792364011e-07 all mean 1.5281424566637725e-05
8.073048229562119e-05 8.073047501966357e-05
rl training, epoch2, iter0, batch1034/1133, batch loss:8.073047501966357e-05, Training time:47238.334985494614
batch reward last col mean 6.696357672808517e-07 first col mean 1.8445507521391846e-07 all mean 4.63983678855584e-06
1.9521601188898785e-06 1.952159891516203e-06
rl training, epoch2, iter0, batch1035/1133, batch loss:1.952159891516203e-06, Training time:47254.954488515854
batch reward last col mean 1.3397880138654727e-07 first col mean 9.33206251829688e-07 all mean 2.490509723429568e-05
3.502578329062089e-05 3.5025779652642086e-05
rl training, epoch2, iter0, batch1036/1133, batch loss:3.5025779652642086e-05, Training time:47272.00902533531
batch reward last col mean 2.834530334894225e-07 first col mean 9.344953610934681e-08 all mean 3.415811988816131e-06
1.4313821338873822e-05 1.4313821338873822e-05
rl training, epoch2, iter0, batch1037/1133, batch loss:1.4313821338873822e-05, Training time:47289.57950234413
batch reward last col mean 7.798957923910166e-09 first col mean 0.0014761704951524734 all mean 2.2053936845622957e-05
4.650966729968786e-05 4.650967093766667e-05
rl training, epoch2, iter0, batch1038/1133, batch loss:4.650967093766667e-05, Training time:47306.798793554306
batch reward last col mean 5.079051135226109e-08 first col mean 4.070820068591274e-06 all mean 1.979875605684356e-06
2.307976956217317e-06 2.307976956217317e-06
rl training, epoch2, iter0, batch1039/1133, batch loss:2.307976956217317e-06, Training time:47324.30557060242
batch reward last col mean 6.459939072556153e-07 first col mean 1.2114534229112905e-06 all mean 5.173551016923739e-06
9.636351933295373e-06 9.636352842790075e-06
rl training, epoch2, iter0, batch1040/1133, batch loss:9.636352842790075e-06, Training time:47341.530272483826
batch reward last col mean 8.16814491599871e-08 first col mean 1.8199501937488094e-05 all mean 4.531810191110708e-06
8.275581421912648e-06 8.275583240902051e-06
rl training, epoch2, iter0, batch1041/1133, batch loss:8.275583240902051e-06, Training time:47358.790080070496
batch reward last col mean 3.312332239602256e-07 first col mean 9.057055194716668e-08 all mean 3.2988693874358432e-06
4.855568931816379e-06 4.855568931816379e-06
rl training, epoch2, iter0, batch1042/1133, batch loss:4.855568931816379e-06, Training time:47375.19527554512
batch reward last col mean 8.804562412478845e-07 first col mean 7.429799779856694e-07 all mean 2.3387952751363628e-05
6.900129665154964e-05 6.900128937559202e-05
rl training, epoch2, iter0, batch1043/1133, batch loss:6.900128937559202e-05, Training time:47391.75879430771
batch reward last col mean 5.104164301883429e-06 first col mean 1.2170947911727126e-06 all mean 2.054832293651998e-05
3.9849881432019174e-05 3.9849881432019174e-05
rl training, epoch2, iter0, batch1044/1133, batch loss:3.9849881432019174e-05, Training time:47408.6706700325
batch reward last col mean 1.736332144730568e-08 first col mean 1.1779038544545983e-07 all mean 9.920991033141036e-06
4.072257434017956e-05 4.072257797815837e-05
rl training, epoch2, iter0, batch1045/1133, batch loss:4.072257797815837e-05, Training time:47425.28317642212
batch reward last col mean 7.019911762995434e-09 first col mean 4.244457159074955e-05 all mean 1.4565724995918572e-05
3.3339427318423986e-05 3.3339430956402794e-05
rl training, epoch2, iter0, batch1046/1133, batch loss:3.3339430956402794e-05, Training time:47442.12804245949
batch reward last col mean 1.0484831136636785e-07 first col mean 2.8432855287974235e-06 all mean 4.647106834454462e-06
6.4936084527289495e-06 6.4936089074763e-06
rl training, epoch2, iter0, batch1047/1133, batch loss:6.4936089074763e-06, Training time:47458.61034822464
batch reward last col mean 8.669557871598954e-08 first col mean 1.796036741552598e-08 all mean 2.1078822101117112e-05
0.00015372266352642328 0.00015372266352642328
rl training, epoch2, iter0, batch1048/1133, batch loss:0.00015372266352642328, Training time:47475.08639836311
batch reward last col mean 1.3454782177291236e-08 first col mean 0.0004380259779281914 all mean 6.488884991995292e-06
7.21865853847703e-06 7.21865853847703e-06
rl training, epoch2, iter0, batch1049/1133, batch loss:7.21865853847703e-06, Training time:47491.70207643509
batch reward last col mean 8.891648576536682e-06 first col mean 0.00025529100093990564 all mean 3.6281449865782633e-05
0.00011855476623168215 0.00011855478078359738
rl training, epoch2, iter0, batch1050/1133, batch loss:0.00011855478078359738, Training time:47508.18489217758
batch reward last col mean 3.57130396366756e-08 first col mean 8.359034109162167e-05 all mean 2.7876965305040358e-06
8.744741535338107e-06 8.744740625843406e-06
rl training, epoch2, iter0, batch1051/1133, batch loss:8.744740625843406e-06, Training time:47525.71273732185
batch reward last col mean 6.547959969793737e-07 first col mean 7.819338634362794e-07 all mean 1.5543373592663556e-05
9.809312177821994e-05 9.809312177821994e-05
rl training, epoch2, iter0, batch1052/1133, batch loss:9.809312177821994e-05, Training time:47543.83578848839
batch reward last col mean 3.9591107281466975e-08 first col mean 1.561883073009085e-05 all mean 1.039708422467811e-05
5.027359293308109e-06 5.0273615670448635e-06
rl training, epoch2, iter0, batch1053/1133, batch loss:5.0273615670448635e-06, Training time:47562.22602343559
batch reward last col mean 0.0022369245998561382 first col mean 0.0009163619251921773 all mean 0.0021877193357795477
0.0002959641278721392 0.0002959641278721392
rl training, epoch2, iter0, batch1054/1133, batch loss:0.0002959641278721392, Training time:47581.34223937988
batch reward last col mean 1.063990318073138e-08 first col mean 1.3916710486228112e-05 all mean 1.7374545677739661e-06
1.8452122958478867e-06 1.8452116137268604e-06
rl training, epoch2, iter0, batch1055/1133, batch loss:1.8452116137268604e-06, Training time:47599.73651218414
batch reward last col mean 1.2763844097207766e-06 first col mean 1.8622358766151592e-06 all mean 2.0510491594905034e-05
9.153674909612164e-05 9.153674182016402e-05
rl training, epoch2, iter0, batch1056/1133, batch loss:9.153674182016402e-05, Training time:47618.36035513878
batch reward last col mean 3.996706077202816e-09 first col mean 5.809392433775429e-08 all mean 1.8551563698565587e-05
6.19790589553304e-05 6.19790589553304e-05
rl training, epoch2, iter0, batch1057/1133, batch loss:6.19790589553304e-05, Training time:47635.59416794777
batch reward last col mean 2.4346968885424758e-08 first col mean 3.1272384148905985e-06 all mean 4.852616712014424e-06
1.9155704649165273e-05 1.9155704649165273e-05
rl training, epoch2, iter0, batch1058/1133, batch loss:1.9155704649165273e-05, Training time:47652.03689742088
batch reward last col mean 1.001229410491078e-08 first col mean 1.9990685018456134e-07 all mean 1.526764754089527e-05
1.6701313143130392e-05 1.6701313143130392e-05
rl training, epoch2, iter0, batch1059/1133, batch loss:1.6701313143130392e-05, Training time:47668.74364042282
batch reward last col mean 4.982496903949141e-08 first col mean 0.0008576753316447139 all mean 2.723436409723945e-05
5.908361708861776e-05 5.908362800255418e-05
rl training, epoch2, iter0, batch1060/1133, batch loss:5.908362800255418e-05, Training time:47686.318490982056
batch reward last col mean 2.3554415307103227e-08 first col mean 6.991524969635066e-06 all mean 7.530004040745553e-06
2.348914131289348e-05 2.348914131289348e-05
rl training, epoch2, iter0, batch1061/1133, batch loss:2.348914131289348e-05, Training time:47705.25213885307
batch reward last col mean 2.924420527961047e-07 first col mean 6.019250236022344e-07 all mean 2.861568282241933e-05
7.693373481743038e-05 7.693373481743038e-05
rl training, epoch2, iter0, batch1062/1133, batch loss:7.693373481743038e-05, Training time:47724.29559135437
batch reward last col mean 3.652377927210182e-06 first col mean 3.923954068341118e-07 all mean 1.9899756807717495e-05
0.00019581263768486679 0.00019581266678869724
rl training, epoch2, iter0, batch1063/1133, batch loss:0.00019581266678869724, Training time:47744.74857592583
batch reward last col mean 1.2766905754801883e-08 first col mean 1.7533504603761685e-07 all mean 4.333495780883823e-06
1.1946058293688111e-05 1.1946058293688111e-05
rl training, epoch2, iter0, batch1064/1133, batch loss:1.1946058293688111e-05, Training time:47761.525934934616
batch reward last col mean 2.8747017211117054e-08 first col mean 2.771235267573502e-05 all mean 2.115465576935094e-05
1.723549939924851e-05 1.7235506675206125e-05
rl training, epoch2, iter0, batch1065/1133, batch loss:1.7235506675206125e-05, Training time:47778.06992340088
batch reward last col mean 5.81681796063549e-08 first col mean 9.666623412840636e-08 all mean 2.5050294425454922e-05
0.00010159929661313072 0.00010159929661313072
rl training, epoch2, iter0, batch1066/1133, batch loss:0.00010159929661313072, Training time:47794.56835579872
batch reward last col mean 2.1679575183952693e-06 first col mean 0.00013687727914657444 all mean 1.2649516975216102e-05
7.055373316688929e-06 7.055371952446876e-06
rl training, epoch2, iter0, batch1067/1133, batch loss:7.055371952446876e-06, Training time:47811.36558651924
batch reward last col mean 2.421714384581719e-08 first col mean 2.0231568669260014e-06 all mean 2.171504638681654e-05
4.009192707599141e-05 4.0091930713970214e-05
rl training, epoch2, iter0, batch1068/1133, batch loss:4.0091930713970214e-05, Training time:47827.92687535286
batch reward last col mean 9.382179477768204e-09 first col mean 0.0002337414480280131 all mean 1.904673445096705e-05
3.098481829511002e-05 3.098481465713121e-05
rl training, epoch2, iter0, batch1069/1133, batch loss:3.098481465713121e-05, Training time:47844.730199575424
batch reward last col mean 0.000288247101707384 first col mean 1.7840956161307986e-06 all mean 0.0002645096101332456
2.2007265215506777e-05 2.2007265215506777e-05
rl training, epoch2, iter0, batch1070/1133, batch loss:2.2007265215506777e-05, Training time:47861.56543755531
batch reward last col mean 8.611480240006131e-08 first col mean 4.832363993045874e-05 all mean 9.475008482695557e-06
3.0291448638308793e-05 3.0291450457298197e-05
rl training, epoch2, iter0, batch1071/1133, batch loss:3.0291450457298197e-05, Training time:47878.28016757965
batch reward last col mean 3.928697367427958e-08 first col mean 3.11123955043513e-07 all mean 1.9213090126868337e-05
3.182666114298627e-05 3.182666841894388e-05
rl training, epoch2, iter0, batch1072/1133, batch loss:3.182666841894388e-05, Training time:47895.117404699326
batch reward last col mean 1.2170762175855998e-08 first col mean 4.071139301231597e-06 all mean 1.8796183212543838e-05
3.265136547270231e-05 3.265136547270231e-05
rl training, epoch2, iter0, batch1073/1133, batch loss:3.265136547270231e-05, Training time:47911.87295603752
batch reward last col mean 2.633076867653017e-08 first col mean 1.0257888334308518e-06 all mean 3.23858366755303e-05
2.944918378489092e-05 2.944918378489092e-05
rl training, epoch2, iter0, batch1074/1133, batch loss:2.944918378489092e-05, Training time:47928.8746740818
batch reward last col mean 1.5412101816991708e-08 first col mean 0.00025973792071454227 all mean 9.034855793288443e-06
1.444132180949964e-06 1.4441320672631264e-06
rl training, epoch2, iter0, batch1075/1133, batch loss:1.4441320672631264e-06, Training time:47946.75882911682
batch reward last col mean 1.0985107934402549e-07 first col mean 0.0015872811200097203 all mean 7.991784514160827e-05
0.00025299546541646123 0.00025299543631263077
rl training, epoch2, iter0, batch1076/1133, batch loss:0.00025299543631263077, Training time:47965.05286693573
batch reward last col mean 2.9196435491485317e-08 first col mean 1.1092332385942427e-07 all mean 1.2351847544778138e-05
1.2009602869511582e-05 1.2009606507490389e-05
rl training, epoch2, iter0, batch1077/1133, batch loss:1.2009606507490389e-05, Training time:47984.69918036461
batch reward last col mean 1.2779241842508782e-07 first col mean 1.7929197326793656e-07 all mean 1.4110796655586455e-06
2.202420091634849e-06 2.202420091634849e-06
rl training, epoch2, iter0, batch1078/1133, batch loss:2.202420091634849e-06, Training time:48002.21944975853
batch reward last col mean 4.446274814995377e-08 first col mean 8.671984687680379e-06 all mean 5.101919668959454e-06
2.504236181266606e-05 2.504236181266606e-05
rl training, epoch2, iter0, batch1079/1133, batch loss:2.504236181266606e-05, Training time:48020.3640267849
batch reward last col mean 1.268723650582615e-07 first col mean 8.636287702756817e-07 all mean 3.009217607541359e-06
2.016977759922156e-06 2.0169775325484807e-06
rl training, epoch2, iter0, batch1080/1133, batch loss:2.0169775325484807e-06, Training time:48038.045000076294
batch reward last col mean 6.73755835123302e-07 first col mean 2.4201369797083316e-06 all mean 2.5725294108269736e-06
1.5360920997409266e-06 1.536092327114602e-06
rl training, epoch2, iter0, batch1081/1133, batch loss:1.536092327114602e-06, Training time:48054.606248140335
batch reward last col mean 0.0038888067938387394 first col mean 9.642556619837706e-08 all mean 0.0034747845493257046
0.000225781841436401 0.00022578185598831624
rl training, epoch2, iter0, batch1082/1133, batch loss:0.00022578185598831624, Training time:48071.24196720123
batch reward last col mean 3.625159905595865e-08 first col mean 1.1678481115495742e-07 all mean 3.088499624936958e-06
2.6206138500128873e-05 2.6206138500128873e-05
rl training, epoch2, iter0, batch1083/1133, batch loss:2.6206138500128873e-05, Training time:48087.83409047127
batch reward last col mean 8.079138069660985e-07 first col mean 4.191689185972791e-06 all mean 3.7448091916303383e-06
4.44160696133622e-06 4.4416078708309215e-06
rl training, epoch2, iter0, batch1084/1133, batch loss:4.4416078708309215e-06, Training time:48104.68395829201
batch reward last col mean 2.5473948284115977e-08 first col mean 2.5153030946967192e-05 all mean 7.589474535052432e-06
6.629900781263132e-06 6.629903054999886e-06
rl training, epoch2, iter0, batch1085/1133, batch loss:6.629903054999886e-06, Training time:48121.57500886917
batch reward last col mean 5.806744525216345e-07 first col mean 5.188389332033694e-05 all mean 3.157353148708353e-06
5.392353159550112e-06 5.39235225005541e-06
rl training, epoch2, iter0, batch1086/1133, batch loss:5.39235225005541e-06, Training time:48138.083008527756
batch reward last col mean 0.0013879897305741906 first col mean 8.386164154217113e-06 all mean 0.0013376489514485002
0.00014531439228449017 0.00014531439228449017
rl training, epoch2, iter0, batch1087/1133, batch loss:0.00014531439228449017, Training time:48154.6373796463
batch reward last col mean 7.449786920687984e-08 first col mean 6.560303972946713e-06 all mean 1.57996726102283e-06
2.5255076252506115e-06 2.5255071705032606e-06
rl training, epoch2, iter0, batch1088/1133, batch loss:2.5255071705032606e-06, Training time:48171.3051609993
batch reward last col mean 1.3988679370413593e-07 first col mean 0.0009325562277808785 all mean 5.163716559763998e-05
0.00024497570120729506 0.00024497570120729506
rl training, epoch2, iter0, batch1089/1133, batch loss:0.00024497570120729506, Training time:48188.18550944328
batch reward last col mean 2.518067958590109e-06 first col mean 4.120368402027452e-08 all mean 3.102979462710209e-05
9.870220674201846e-05 9.870220674201846e-05
rl training, epoch2, iter0, batch1090/1133, batch loss:9.870220674201846e-05, Training time:48204.655928611755
batch reward last col mean 8.79956996158171e-09 first col mean 1.9676663214340806e-06 all mean 7.045461643429007e-06
2.2522701328853145e-05 2.252270314784255e-05
rl training, epoch2, iter0, batch1091/1133, batch loss:2.252270314784255e-05, Training time:48221.68583321571
batch reward last col mean 8.443093065579887e-06 first col mean 8.321072527905926e-06 all mean 1.6310112187056802e-05
6.63143873680383e-06 6.631436463067075e-06
rl training, epoch2, iter0, batch1092/1133, batch loss:6.631436463067075e-06, Training time:48238.48655962944
batch reward last col mean 2.40874584278572e-07 first col mean 5.457967290567467e-06 all mean 1.8354456187807955e-05
4.306220216676593e-05 4.306220216676593e-05
rl training, epoch2, iter0, batch1093/1133, batch loss:4.306220216676593e-05, Training time:48254.947926044464
batch reward last col mean 5.7739843128956636e-08 first col mean 1.0946652764687315e-05 all mean 3.3539687137817964e-05
5.906692967982963e-05 5.906692967982963e-05
rl training, epoch2, iter0, batch1094/1133, batch loss:5.906692967982963e-05, Training time:48273.470010757446
batch reward last col mean 2.2998021904641064e-06 first col mean 6.244453834369779e-05 all mean 4.130015895498218e-06
6.359168310154928e-06 6.359168310154928e-06
rl training, epoch2, iter0, batch1095/1133, batch loss:6.359168310154928e-06, Training time:48290.62030315399
batch reward last col mean 6.655643147723822e-09 first col mean 2.958066858127495e-08 all mean 5.902744305785745e-06
3.3482469007140025e-05 3.348246536916122e-05
rl training, epoch2, iter0, batch1096/1133, batch loss:3.348246536916122e-05, Training time:48308.08311033249
batch reward last col mean 1.926280646102896e-08 first col mean 0.0008405267144553363 all mean 1.802418591978494e-05
5.802139639854431e-05 5.8021392760565504e-05
rl training, epoch2, iter0, batch1097/1133, batch loss:5.8021392760565504e-05, Training time:48326.53006196022
batch reward last col mean 7.144058145058807e-08 first col mean 1.637663729070482e-07 all mean 3.524341809679754e-05
0.00013096406473778188 0.00013096405018586665
rl training, epoch2, iter0, batch1098/1133, batch loss:0.00013096405018586665, Training time:48344.87078881264
batch reward last col mean 1.1438970659582992e-06 first col mean 1.3108021335028752e-07 all mean 6.956164270377485e-06
1.7011396266752854e-05 1.7011396266752854e-05
rl training, epoch2, iter0, batch1099/1133, batch loss:1.7011396266752854e-05, Training time:48361.51932430267
batch reward last col mean 1.1172448211027586e-07 first col mean 2.322672116861213e-07 all mean 5.009498181607341e-06
1.8140230167773552e-05 1.8140231986762956e-05
rl training, epoch2, iter0, batch1100/1133, batch loss:1.8140231986762956e-05, Training time:48378.22980546951
batch reward last col mean 1.442294887965545e-06 first col mean 0.00013153525651432574 all mean 4.4356875150697306e-05
0.0002502628485672176 0.0002502628485672176
rl training, epoch2, iter0, batch1101/1133, batch loss:0.0002502628485672176, Training time:48395.40019488335
batch reward last col mean 0.003321896307170391 first col mean 1.8421278014102427e-07 all mean 0.002924690255895257
0.0002222021867055446 0.0002222021867055446
rl training, epoch2, iter0, batch1102/1133, batch loss:0.0002222021867055446, Training time:48411.960011959076
batch reward last col mean 9.497203734554205e-08 first col mean 3.107818429270992e-07 all mean 9.15541204449255e-06
5.681656148226466e-06 5.681655693479115e-06
rl training, epoch2, iter0, batch1103/1133, batch loss:5.681655693479115e-06, Training time:48428.77861714363
batch reward last col mean 3.936498274015321e-07 first col mean 3.425913348564791e-07 all mean 2.233473969681654e-05
8.331458957400173e-06 8.331451681442559e-06
rl training, epoch2, iter0, batch1104/1133, batch loss:8.331451681442559e-06, Training time:48445.2716217041
batch reward last col mean 2.1634180313867546e-07 first col mean 9.426539327250794e-05 all mean 1.1273861673544161e-05
3.611958845795016e-06 3.611959982663393e-06
rl training, epoch2, iter0, batch1105/1133, batch loss:3.611959982663393e-06, Training time:48461.78217744827
batch reward last col mean 2.792674536067352e-08 first col mean 2.8621705894238403e-08 all mean 2.083194885926787e-06
2.806518750730902e-06 2.8065185233572265e-06
rl training, epoch2, iter0, batch1106/1133, batch loss:2.8065185233572265e-06, Training time:48478.30256438255
batch reward last col mean 7.755866135994438e-06 first col mean 9.522398613626137e-06 all mean 3.050806662940886e-05
6.543244671775028e-05 6.54324539937079e-05
rl training, epoch2, iter0, batch1107/1133, batch loss:6.54324539937079e-05, Training time:48494.86438345909
batch reward last col mean 6.776428307375681e-08 first col mean 2.172667450395238e-07 all mean 3.442243905737996e-05
1.6006581063265912e-05 1.600658470124472e-05
rl training, epoch2, iter0, batch1108/1133, batch loss:1.600658470124472e-05, Training time:48511.308671951294
batch reward last col mean 0.00657540513202548 first col mean 4.867540701525286e-05 all mean 0.006125421263277531
0.0006992932176217437 0.0006992932176217437
rl training, epoch2, iter0, batch1109/1133, batch loss:0.0006992932176217437, Training time:48528.80527257919
batch reward last col mean 1.2692824213900167e-07 first col mean 1.964211264748883e-07 all mean 8.72608052304713e-06
1.1021551472367719e-05 1.1021549653378315e-05
rl training, epoch2, iter0, batch1110/1133, batch loss:1.1021549653378315e-05, Training time:48547.59074091911
batch reward last col mean 0.0022493537981063128 first col mean 3.98391202907078e-05 all mean 0.002002609893679619
0.00012989724928047508 0.00012989724928047508
rl training, epoch2, iter0, batch1111/1133, batch loss:0.00012989724928047508, Training time:48564.52504014969
batch reward last col mean 2.458033065977361e-07 first col mean 0.0011324045481160283 all mean 1.5932317182887346e-05
7.499585535697406e-06 7.499580988223897e-06
rl training, epoch2, iter0, batch1112/1133, batch loss:7.499580988223897e-06, Training time:48583.760862350464
batch reward last col mean 5.506500500018774e-08 first col mean 1.585798486303247e-06 all mean 2.2205369532457553e-05
0.00010595979256322607 0.00010595979256322607
rl training, epoch2, iter0, batch1113/1133, batch loss:0.00010595979256322607, Training time:48603.538945674896
batch reward last col mean 0.00038931038579903543 first col mean 5.128702105139382e-05 all mean 0.00038856244646012783
4.754415203933604e-05 4.754415567731485e-05
rl training, epoch2, iter0, batch1114/1133, batch loss:4.754415567731485e-05, Training time:48621.353320121765
batch reward last col mean 3.415802711970173e-05 first col mean 2.9186119718360715e-05 all mean 5.6463257351424545e-05
0.0001505500840721652 0.00015055009862408042
rl training, epoch2, iter0, batch1115/1133, batch loss:0.00015055009862408042, Training time:48638.0607779026
batch reward last col mean 1.1042510905667768e-08 first col mean 7.657179594389163e-06 all mean 4.079034624737687e-06
3.0774469905736623e-06 3.077447900068364e-06
rl training, epoch2, iter0, batch1116/1133, batch loss:3.077447900068364e-06, Training time:48654.71305799484
batch reward last col mean 6.45236432319507e-05 first col mean 3.890902462444501e-06 all mean 7.052576256683096e-05
3.552637645043433e-05 3.552637645043433e-05
rl training, epoch2, iter0, batch1117/1133, batch loss:3.552637645043433e-05, Training time:48671.16641449928
batch reward last col mean 2.427511390123982e-05 first col mean 7.189070743152115e-07 all mean 1.7696904251351953e-05
2.382819729973562e-05 2.3828195480746217e-05
rl training, epoch2, iter0, batch1118/1133, batch loss:2.3828195480746217e-05, Training time:48687.687811374664
batch reward last col mean 6.4571841207339276e-09 first col mean 3.0942231887820526e-07 all mean 6.065847173886141e-06
1.1800170796050224e-05 1.180017352453433e-05
rl training, epoch2, iter0, batch1119/1133, batch loss:1.180017352453433e-05, Training time:48704.48235273361
batch reward last col mean 0.0005372414016164839 first col mean 5.607176717603579e-05 all mean 0.0004984649131074548
3.226752596674487e-05 3.226752596674487e-05
rl training, epoch2, iter0, batch1120/1133, batch loss:3.226752596674487e-05, Training time:48721.2296936512
batch reward last col mean 0.0001449474220862612 first col mean 8.786706473529193e-08 all mean 0.00014156381075736135
9.348211460746825e-05 9.348211460746825e-05
rl training, epoch2, iter0, batch1121/1133, batch loss:9.348211460746825e-05, Training time:48737.77859401703
batch reward last col mean 3.678927100736473e-07 first col mean 7.624353770552261e-08 all mean 1.4416450540011283e-05
5.651244646287523e-05 5.651244646287523e-05
rl training, epoch2, iter0, batch1122/1133, batch loss:5.651244646287523e-05, Training time:48754.2823176384
batch reward last col mean 5.4395757615566254e-05 first col mean 1.2102506843802985e-05 all mean 4.904018351226114e-05
5.840083758812398e-05 5.8400841226102784e-05
rl training, epoch2, iter0, batch1123/1133, batch loss:5.8400841226102784e-05, Training time:48770.84070301056
batch reward last col mean 0.0010771818924695253 first col mean 5.613113899016753e-06 all mean 0.0010205996222794056
0.0001095102124963887 0.0001095102124963887
rl training, epoch2, iter0, batch1124/1133, batch loss:0.0001095102124963887, Training time:48788.95190739632
batch reward last col mean 2.4564199563315015e-08 first col mean 4.91534847242292e-05 all mean 8.414112016907893e-06
2.0660807422245853e-05 2.0660807422245853e-05
rl training, epoch2, iter0, batch1125/1133, batch loss:2.0660807422245853e-05, Training time:48808.03488326073
batch reward last col mean 7.792501577341682e-08 first col mean 0.00040160753997042775 all mean 2.6657533453544602e-05
0.00013697361282538623 0.00013697362737730145
rl training, epoch2, iter0, batch1126/1133, batch loss:0.00013697362737730145, Training time:48826.187772750854
batch reward last col mean 1.5611196602094424e-07 first col mean 5.853268703504e-06 all mean 1.7463453332311474e-05
4.997475116397254e-05 4.997475116397254e-05
rl training, epoch2, iter0, batch1127/1133, batch loss:4.997475116397254e-05, Training time:48843.50947880745
batch reward last col mean 1.0107342518494988e-07 first col mean 1.2251481606995185e-08 all mean 3.884092075168155e-05
0.0001599101087776944 0.0001599101087776944
rl training, epoch2, iter0, batch1128/1133, batch loss:0.0001599101087776944, Training time:48861.4288289547
batch reward last col mean 5.287327553560317e-08 first col mean 2.0322646321346838e-07 all mean 1.2425287422956899e-05
6.114369898568839e-05 6.114369898568839e-05
rl training, epoch2, iter0, batch1129/1133, batch loss:6.114369898568839e-05, Training time:48878.11447381973
batch reward last col mean 0.0006562969647347927 first col mean 7.440887202392332e-06 all mean 0.00040585678652860224
8.963751315604895e-05 8.963752043200657e-05
rl training, epoch2, iter0, batch1130/1133, batch loss:8.963752043200657e-05, Training time:48894.757180929184
batch reward last col mean 1.8353807362814223e-08 first col mean 0.0011822261149063706 all mean 1.2839567716582678e-05
2.520047701182193e-06 2.520048610676895e-06
rl training, epoch2, iter0, batch1131/1133, batch loss:2.520048610676895e-06, Training time:48911.95200252533
batch reward last col mean 9.800354305866676e-09 first col mean 2.1599223742896356e-08 all mean 1.950882506207563e-05
0.00014613017265219241 0.00014613017265219241
rl training, epoch2, iter0, batch1132/1133, batch loss:0.00014613017265219241, Training time:48928.205783843994
rl training, epoch 2, iter 0, loss:4.812660799262512e-05, Training time:48928.20603990555 
rl epoch 2, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4099106359881631 Time: 138.32306790351868 s
loss of true 0.16777942242842275 loss of gen 0.00022247530048292283 loss of other 0.2419087377500976 first score 7.912109190044703e-09
cur_epoch: 1
D Training Loss: 0.4049627662152183 Time: 135.93517565727234 s
loss of true 0.16421807735553381 loss of gen 0.0002932831191252449 loss of other 0.24045140548080654 first score 5.934712135058362e-07
cur_epoch: 2
D Training Loss: 0.3937294517511408 Time: 137.6566755771637 s
loss of true 0.15917553694134567 loss of gen 0.00022091988175279435 loss of other 0.23433299459326298 first score 0.0008178403368219733
cur_epoch: 3
D Training Loss: 0.3865588214264859 Time: 135.53718781471252 s
loss of true 0.15602027746501057 loss of gen 0.00022174740934894128 loss of other 0.2303167962899065 first score 7.317858035094105e-07
cur_epoch: 4
D Training Loss: 0.383550558393757 Time: 139.9678819179535 s
loss of true 0.15462288030958343 loss of gen 0.00023691352496623948 loss of other 0.22869076412779404 first score 2.0409970602486283e-07
rl epoch 3, begin RL for generator...
batch reward last col mean 1.553905576656689e-06 first col mean 1.1431109214754542e-06 all mean 1.2682107808359433e-05
1.2911206795251928e-05 1.2911208614241332e-05
rl training, epoch3, iter0, batch0/1133, batch loss:1.2911208614241332e-05, Training time:49632.61843204498
batch reward last col mean 1.4612758604926057e-05 first col mean 0.0004976670606993139 all mean 2.0753999706357718e-05
3.0520375730702654e-05 3.0520375730702654e-05
rl training, epoch3, iter0, batch1/1133, batch loss:3.0520375730702654e-05, Training time:49650.83993768692
batch reward last col mean 0.007303645834326744 first col mean 1.1324937077006325e-07 all mean 0.00665705744177103
0.0007326089544221759 0.0007326089544221759
rl training, epoch3, iter0, batch2/1133, batch loss:0.0007326089544221759, Training time:49670.56033706665
batch reward last col mean 1.2029107665512129e-06 first col mean 0.0008222644100897014 all mean 3.712158286361955e-05
0.00012596126180142164 0.00012596126180142164
rl training, epoch3, iter0, batch3/1133, batch loss:0.00012596126180142164, Training time:49687.79456830025
batch reward last col mean 1.0960900453937938e-07 first col mean 5.089170372230001e-06 all mean 1.9032084310310893e-05
7.202408596640453e-05 7.20240714144893e-05
rl training, epoch3, iter0, batch4/1133, batch loss:7.20240714144893e-05, Training time:49706.666066884995
batch reward last col mean 1.063542913470883e-05 first col mean 1.830027713367599e-06 all mean 1.800868267309852e-05
3.112194826826453e-05 3.1121944630285725e-05
rl training, epoch3, iter0, batch5/1133, batch loss:3.1121944630285725e-05, Training time:49725.81092238426
batch reward last col mean 2.4219511374212743e-07 first col mean 0.00010064680827781558 all mean 1.2867899386037607e-05
1.2081706699973438e-05 1.208170760946814e-05
rl training, epoch3, iter0, batch6/1133, batch loss:1.208170760946814e-05, Training time:49742.75545835495
batch reward last col mean 8.719699735593167e-07 first col mean 2.8032724003423937e-05 all mean 3.4065785712300567e-06
7.175481187005062e-06 7.17548027751036e-06
rl training, epoch3, iter0, batch7/1133, batch loss:7.17548027751036e-06, Training time:49759.372338056564
batch reward last col mean 6.589647455257364e-06 first col mean 4.4379671635397244e-06 all mean 3.372290302650072e-05
0.00013738144480157644 0.00013738145935349166
rl training, epoch3, iter0, batch8/1133, batch loss:0.00013738145935349166, Training time:49775.86632180214
batch reward last col mean 2.262203906866489e-06 first col mean 2.7240119493399106e-07 all mean 2.6933621484204195e-05
4.8038568820629735e-06 4.8038609747891314e-06
rl training, epoch3, iter0, batch9/1133, batch loss:4.8038609747891314e-06, Training time:49792.809970617294
batch reward last col mean 6.709497483825544e-06 first col mean 0.00038661554572172463 all mean 4.00314420403447e-05
0.00013855153520125896 0.00013855153520125896
rl training, epoch3, iter0, batch10/1133, batch loss:0.00013855153520125896, Training time:49809.3703083992
batch reward last col mean 8.720943696971517e-06 first col mean 0.0006657158955931664 all mean 1.5214807717711665e-05
3.8416208553826436e-05 3.8416208553826436e-05
rl training, epoch3, iter0, batch11/1133, batch loss:3.8416208553826436e-05, Training time:49825.80548763275
batch reward last col mean 0.005645095370709896 first col mean 9.002177102956921e-05 all mean 0.005498766433447599
0.00043404210009612143 0.00043404210009612143
rl training, epoch3, iter0, batch12/1133, batch loss:0.00043404210009612143, Training time:49842.421149492264
batch reward last col mean 1.1869274629816573e-07 first col mean 1.2002038829450612e-07 all mean 1.0787506653286982e-05
4.723274105344899e-05 4.723274105344899e-05
rl training, epoch3, iter0, batch13/1133, batch loss:4.723274105344899e-05, Training time:49859.22709226608
batch reward last col mean 4.04429201239509e-08 first col mean 1.2164819054305553e-06 all mean 7.296747753571253e-06
7.819092388672289e-06 7.819091479177587e-06
rl training, epoch3, iter0, batch14/1133, batch loss:7.819091479177587e-06, Training time:49875.919781684875
batch reward last col mean 8.541823603991361e-07 first col mean 4.853273821936455e-06 all mean 1.1058038580813445e-05
6.0778704209951684e-05 6.077870057197288e-05
rl training, epoch3, iter0, batch15/1133, batch loss:6.077870057197288e-05, Training time:49893.26922798157
batch reward last col mean 3.0750263249501586e-05 first col mean 2.1755290902092383e-07 all mean 1.4084930626268033e-05
3.467184433247894e-05 3.4671840694500133e-05
rl training, epoch3, iter0, batch16/1133, batch loss:3.4671840694500133e-05, Training time:49910.07531905174
batch reward last col mean 6.344707230709901e-07 first col mean 6.757652499800315e-07 all mean 2.399289314780617e-06
4.596909093379509e-06 4.596909093379509e-06
rl training, epoch3, iter0, batch17/1133, batch loss:4.596909093379509e-06, Training time:49926.7772231102
batch reward last col mean 0.00013106640835758299 first col mean 4.09301890158531e-07 all mean 0.00012326108117122203
1.1228597941226326e-05 1.1228597941226326e-05
rl training, epoch3, iter0, batch18/1133, batch loss:1.1228597941226326e-05, Training time:49944.73953938484
batch reward last col mean 7.921199198790418e-07 first col mean 8.27827607281506e-05 all mean 3.3883101423271e-05
1.5062044440128375e-05 1.506204716861248e-05
rl training, epoch3, iter0, batch19/1133, batch loss:1.506204716861248e-05, Training time:49961.847712278366
batch reward last col mean 1.3281311339596868e-07 first col mean 9.217037018061092e-07 all mean 1.947283817571588e-05
1.6914113075472414e-05 1.691411125648301e-05
rl training, epoch3, iter0, batch20/1133, batch loss:1.691411125648301e-05, Training time:49979.13440299034
batch reward last col mean 1.935948432674195e-07 first col mean 3.413569857002585e-06 all mean 5.429598786577117e-06
8.249126040027477e-06 8.249125130532775e-06
rl training, epoch3, iter0, batch21/1133, batch loss:8.249125130532775e-06, Training time:49998.08442592621
batch reward last col mean 2.6358387117397797e-07 first col mean 2.4528267772438994e-07 all mean 6.604708232771372e-06
1.5122155673452653e-05 1.5122155673452653e-05
rl training, epoch3, iter0, batch22/1133, batch loss:1.5122155673452653e-05, Training time:50015.198360443115
batch reward last col mean 2.3592742763867136e-06 first col mean 0.0011132941581308842 all mean 2.0178260456304997e-05
1.7411823137081228e-05 1.741181949910242e-05
rl training, epoch3, iter0, batch23/1133, batch loss:1.741181949910242e-05, Training time:50031.83048415184
batch reward last col mean 4.829535100725479e-07 first col mean 6.043075700290501e-06 all mean 1.4539742551278323e-05
3.7310801417334005e-05 3.731080869329162e-05
rl training, epoch3, iter0, batch24/1133, batch loss:3.731080869329162e-05, Training time:50048.79810285568
batch reward last col mean 9.864537986459254e-08 first col mean 9.451746763033952e-08 all mean 1.1442878530942835e-05
4.893348432233324e-06 4.893345249001868e-06
rl training, epoch3, iter0, batch25/1133, batch loss:4.893345249001868e-06, Training time:50065.35389518738
batch reward last col mean 3.762625738090719e-06 first col mean 6.576517080247868e-06 all mean 1.0761451449070591e-05
1.5788529708515853e-05 1.5788535165484063e-05
rl training, epoch3, iter0, batch26/1133, batch loss:1.5788535165484063e-05, Training time:50082.2636153698
batch reward last col mean 1.0051007848232985e-06 first col mean 0.0019425754435360432 all mean 6.974780262680724e-05
0.00013888839748688042 0.00013888841203879565
rl training, epoch3, iter0, batch27/1133, batch loss:0.00013888841203879565, Training time:50098.78795170784
batch reward last col mean 3.443599894126237e-07 first col mean 2.945666608411557e-07 all mean 2.8501010092440993e-05
2.8119540729676373e-05 2.8119540729676373e-05
rl training, epoch3, iter0, batch28/1133, batch loss:2.8119540729676373e-05, Training time:50115.514927625656
batch reward last col mean 1.4503597185466788e-06 first col mean 1.7696116628940217e-05 all mean 4.733561581815593e-05
0.0002482488634996116 0.0002482488634996116
rl training, epoch3, iter0, batch29/1133, batch loss:0.0002482488634996116, Training time:50131.96927690506
batch reward last col mean 0.0005416187341324985 first col mean 1.8336965013077133e-07 all mean 0.00013419984315987676
0.00016349813085980713 0.00016349813085980713
rl training, epoch3, iter0, batch30/1133, batch loss:0.00016349813085980713, Training time:50148.71495389938
batch reward last col mean 2.0902604092043475e-07 first col mean 3.2815962640597718e-06 all mean 1.2367326235107612e-05
2.4375158318434842e-05 2.437516195641365e-05
rl training, epoch3, iter0, batch31/1133, batch loss:2.437516195641365e-05, Training time:50165.299543857574
batch reward last col mean 5.456857365970791e-07 first col mean 8.442106263828464e-06 all mean 4.5302305807126686e-05
0.0001446770766051486 0.00014467706205323339
rl training, epoch3, iter0, batch32/1133, batch loss:0.00014467706205323339, Training time:50181.84585928917
batch reward last col mean 2.3102032287170005e-07 first col mean 2.1172368178667966e-06 all mean 9.236257938027848e-06
1.5805968359927647e-05 1.5805966540938243e-05
rl training, epoch3, iter0, batch33/1133, batch loss:1.5805966540938243e-05, Training time:50199.67959904671
batch reward last col mean 0.0003472213284112513 first col mean 1.5123177945497446e-06 all mean 0.0003114183200523257
3.857384581351653e-05 3.8573849451495335e-05
rl training, epoch3, iter0, batch34/1133, batch loss:3.8573849451495335e-05, Training time:50217.77730727196
batch reward last col mean 0.00012721068924292922 first col mean 4.436373330918286e-07 all mean 7.792061660438776e-05
2.2646931029157713e-05 2.264692921016831e-05
rl training, epoch3, iter0, batch35/1133, batch loss:2.264692921016831e-05, Training time:50235.196432352066
batch reward last col mean 3.8295209492389404e-07 first col mean 1.2208126918267226e-06 all mean 1.3145910088496748e-05
4.160351454629563e-05 4.160351454629563e-05
rl training, epoch3, iter0, batch36/1133, batch loss:4.160351454629563e-05, Training time:50254.178679943085
batch reward last col mean 4.899749228570727e-08 first col mean 0.00012433687516022474 all mean 2.601536107249558e-05
6.335702346405014e-05 6.335702346405014e-05
rl training, epoch3, iter0, batch37/1133, batch loss:6.335702346405014e-05, Training time:50271.86780309677
batch reward last col mean 8.36170528373259e-08 first col mean 4.515131513471715e-05 all mean 1.1260211067565251e-05
9.586830856278539e-06 9.586828127794433e-06
rl training, epoch3, iter0, batch38/1133, batch loss:9.586828127794433e-06, Training time:50288.390537023544
batch reward last col mean 1.9622430045274086e-06 first col mean 0.00023362347565125674 all mean 1.2878645975433756e-05
4.360517777968198e-05 4.360517777968198e-05
rl training, epoch3, iter0, batch39/1133, batch loss:4.360517777968198e-05, Training time:50304.83788180351
batch reward last col mean 1.1662758936381579e-07 first col mean 3.4178941632490023e-07 all mean 4.447985247679753e-06
6.202995791682042e-06 6.202996246429393e-06
rl training, epoch3, iter0, batch40/1133, batch loss:6.202996246429393e-06, Training time:50321.3921353817
batch reward last col mean 7.64319884183351e-06 first col mean 6.135385177685748e-08 all mean 1.0217520866717678e-05
1.1079321666329633e-05 1.1079323485319037e-05
rl training, epoch3, iter0, batch41/1133, batch loss:1.1079323485319037e-05, Training time:50337.90495753288
batch reward last col mean 1.4704680779686896e-06 first col mean 4.396221265778877e-05 all mean 1.5105863894859795e-05
3.0896357202436775e-05 3.0896357202436775e-05
rl training, epoch3, iter0, batch42/1133, batch loss:3.0896357202436775e-05, Training time:50354.61069583893
batch reward last col mean 7.321640964619291e-07 first col mean 9.697960479115864e-08 all mean 9.037328709382564e-06
2.512310675228946e-05 2.512310675228946e-05
rl training, epoch3, iter0, batch43/1133, batch loss:2.512310675228946e-05, Training time:50371.406036138535
batch reward last col mean 2.7166503059561364e-05 first col mean 8.305649998874287e-07 all mean 5.0246904720552266e-05
0.00011338208423694596 0.00011338208423694596
rl training, epoch3, iter0, batch44/1133, batch loss:0.00011338208423694596, Training time:50387.98459982872
batch reward last col mean 1.7372491356582032e-06 first col mean 0.00042185408528894186 all mean 1.6425747162429616e-05
4.5990927901584655e-05 4.5990927901584655e-05
rl training, epoch3, iter0, batch45/1133, batch loss:4.5990927901584655e-05, Training time:50404.38832068443
batch reward last col mean 2.075479642371647e-06 first col mean 2.084313791783643e-06 all mean 9.287823559134267e-06
1.1842374988191295e-05 1.1842375897685997e-05
rl training, epoch3, iter0, batch46/1133, batch loss:1.1842375897685997e-05, Training time:50420.74811244011
batch reward last col mean 4.3405967176113336e-07 first col mean 1.4802227497057174e-06 all mean 6.000660505378619e-06
2.0948971723555587e-05 2.0948971723555587e-05
rl training, epoch3, iter0, batch47/1133, batch loss:2.0948971723555587e-05, Training time:50437.5911386013
batch reward last col mean 1.2943774891027715e-05 first col mean 2.3400919246796548e-07 all mean 3.933948391932063e-05
0.00014273398846853524 0.00014273398846853524
rl training, epoch3, iter0, batch48/1133, batch loss:0.00014273398846853524, Training time:50454.059765815735
batch reward last col mean 4.2114808707083284e-07 first col mean 0.0006042375462129712 all mean 1.6765059626777656e-05
2.8340773496893235e-05 2.8340778953861445e-05
rl training, epoch3, iter0, batch49/1133, batch loss:2.8340778953861445e-05, Training time:50471.098140478134
batch reward last col mean 4.923756932839751e-06 first col mean 9.200683052768e-06 all mean 7.445286428264808e-06
7.53570702727302e-06 7.53570702727302e-06
rl training, epoch3, iter0, batch50/1133, batch loss:7.53570702727302e-06, Training time:50489.46648526192
batch reward last col mean 4.391761478927947e-07 first col mean 9.602866157365497e-06 all mean 5.266396783554228e-06
2.6029897526314016e-06 2.602988388389349e-06
rl training, epoch3, iter0, batch51/1133, batch loss:2.602988388389349e-06, Training time:50508.271480321884
batch reward last col mean 6.998369030952745e-07 first col mean 6.092477633501403e-08 all mean 5.448828687804053e-06
2.3189879357232712e-05 2.3189879357232712e-05
rl training, epoch3, iter0, batch52/1133, batch loss:2.3189879357232712e-05, Training time:50526.236729860306
batch reward last col mean 6.961921371839708e-06 first col mean 4.064970653416822e-06 all mean 2.1533087419811636e-05
4.595001882989891e-05 4.595001882989891e-05
rl training, epoch3, iter0, batch53/1133, batch loss:4.595001882989891e-05, Training time:50544.084700107574
batch reward last col mean 0.0010031756246462464 first col mean 2.037937974819215e-06 all mean 0.0009097911533899605
0.0001684680173639208 0.00016846803191583604
rl training, epoch3, iter0, batch54/1133, batch loss:0.00016846803191583604, Training time:50562.211621046066
batch reward last col mean 2.907204816438025e-06 first col mean 0.0017706481739878654 all mean 2.962991493404843e-05
9.18031728360802e-05 9.18031728360802e-05
rl training, epoch3, iter0, batch55/1133, batch loss:9.18031728360802e-05, Training time:50578.79327964783
batch reward last col mean 6.955323783586209e-07 first col mean 9.904346370603889e-05 all mean 1.3143976502760779e-05
1.856002927524969e-05 1.8560031094239093e-05
rl training, epoch3, iter0, batch56/1133, batch loss:1.8560031094239093e-05, Training time:50595.66454029083
batch reward last col mean 0.00020494611817412078 first col mean 7.521325642301235e-07 all mean 3.111794649157673e-05
8.717109449207783e-05 8.717109449207783e-05
rl training, epoch3, iter0, batch57/1133, batch loss:8.717109449207783e-05, Training time:50612.52030682564
batch reward last col mean 3.562564643289079e-08 first col mean 1.5824249203433283e-05 all mean 3.576489689294249e-05
7.492545410059392e-05 7.492544682463631e-05
rl training, epoch3, iter0, batch58/1133, batch loss:7.492544682463631e-05, Training time:50629.139372587204
batch reward last col mean 2.3051547941577155e-06 first col mean 3.8087498523964314e-06 all mean 7.201457265182398e-06
1.8403388821752742e-05 1.8403388821752742e-05
rl training, epoch3, iter0, batch59/1133, batch loss:1.8403388821752742e-05, Training time:50645.72048616409
batch reward last col mean 1.1555187029443914e-07 first col mean 6.265883257583482e-06 all mean 2.4929609935497865e-05
2.4660357667016797e-06 2.4660334929649252e-06
rl training, epoch3, iter0, batch60/1133, batch loss:2.4660334929649252e-06, Training time:50662.08176469803
batch reward last col mean 0.0001171651019831188 first col mean 1.7925833617482567e-06 all mean 0.00011693309352267534
1.6222269550780766e-05 1.622227136977017e-05
rl training, epoch3, iter0, batch61/1133, batch loss:1.622227136977017e-05, Training time:50678.86336350441
batch reward last col mean 1.4405497950065183e-07 first col mean 1.8499619045542204e-06 all mean 2.261411827930715e-05
7.281478610821068e-05 7.281478610821068e-05
rl training, epoch3, iter0, batch62/1133, batch loss:7.281478610821068e-05, Training time:50695.44749546051
batch reward last col mean 5.468963081511902e-06 first col mean 7.229283482956816e-07 all mean 1.9141736629535444e-05
1.558423537062481e-05 1.5584237189614214e-05
rl training, epoch3, iter0, batch63/1133, batch loss:1.5584237189614214e-05, Training time:50712.28357672691
batch reward last col mean 3.0590450478484854e-05 first col mean 3.7021001730863645e-07 all mean 1.8790717149386182e-05
4.7631459892727435e-05 4.7631459892727435e-05
rl training, epoch3, iter0, batch64/1133, batch loss:4.7631459892727435e-05, Training time:50729.03346180916
batch reward last col mean 5.633792170556262e-07 first col mean 0.0010681949788704515 all mean 3.879064024658874e-05
5.391221202444285e-05 5.391219747252762e-05
rl training, epoch3, iter0, batch65/1133, batch loss:5.391219747252762e-05, Training time:50745.5657389164
batch reward last col mean 5.1801670508666575e-08 first col mean 1.1264400200161617e-05 all mean 2.7401196348364465e-05
0.00011391886800993234 0.00011391886800993234
rl training, epoch3, iter0, batch66/1133, batch loss:0.00011391886800993234, Training time:50762.14653611183
batch reward last col mean 2.623011710056744e-07 first col mean 0.00020592300279531628 all mean 1.9783601601375267e-05
0.00012767808220814914 0.00012767808220814914
rl training, epoch3, iter0, batch67/1133, batch loss:0.00012767808220814914, Training time:50778.698075056076
batch reward last col mean 9.88072059726619e-08 first col mean 9.347140439786017e-05 all mean 2.9817383619956672e-05
6.527724326588213e-05 6.527725781779736e-05
rl training, epoch3, iter0, batch68/1133, batch loss:6.527725781779736e-05, Training time:50795.542023181915
batch reward last col mean 1.6370912589991349e-06 first col mean 0.0005052895285189152 all mean 6.080660023144446e-05
0.00032015913166105747 0.0003201591898687184
rl training, epoch3, iter0, batch69/1133, batch loss:0.0003201591898687184, Training time:50813.68786621094
batch reward last col mean 1.5307288094845717e-06 first col mean 0.0007979777292348444 all mean 2.285978371219244e-05
4.1007726395037025e-05 4.1007726395037025e-05
rl training, epoch3, iter0, batch70/1133, batch loss:4.1007726395037025e-05, Training time:50832.08241343498
batch reward last col mean 1.7703378034639172e-05 first col mean 3.807708344538696e-05 all mean 2.2011938199284486e-05
2.18674358620774e-05 2.18674358620774e-05
rl training, epoch3, iter0, batch71/1133, batch loss:2.18674358620774e-05, Training time:50850.51790976524
batch reward last col mean 6.637358751504507e-08 first col mean 7.286870840061965e-08 all mean 2.062590283458121e-05
6.927688809810206e-05 6.927688809810206e-05
rl training, epoch3, iter0, batch72/1133, batch loss:6.927688809810206e-05, Training time:50869.3549118042
batch reward last col mean 1.7457294632095e-07 first col mean 9.72753423411632e-06 all mean 2.1470523279276676e-05
0.0001810444809962064 0.0001810444809962064
rl training, epoch3, iter0, batch73/1133, batch loss:0.0001810444809962064, Training time:50886.40973734856
batch reward last col mean 4.32556760188163e-07 first col mean 0.0012265050318092108 all mean 5.241797771304846e-05
0.0003470845113042742 0.0003470845113042742
rl training, epoch3, iter0, batch74/1133, batch loss:0.0003470845113042742, Training time:50904.74677824974
batch reward last col mean 8.9836168626789e-05 first col mean 0.00021642677893396467 all mean 0.00016463980136904866
0.000515790656208992 0.000515790656208992
rl training, epoch3, iter0, batch75/1133, batch loss:0.000515790656208992, Training time:50922.0678153038
batch reward last col mean 1.1440766201076258e-07 first col mean 9.181860150420107e-06 all mean 2.197918001911603e-05
6.898021092638373e-05 6.898021820234135e-05
rl training, epoch3, iter0, batch76/1133, batch loss:6.898021820234135e-05, Training time:50938.605187892914
batch reward last col mean 2.4966262571979314e-05 first col mean 1.360405462946801e-06 all mean 1.551284731249325e-05
7.40414034225978e-05 7.40414034225978e-05
rl training, epoch3, iter0, batch77/1133, batch loss:7.40414034225978e-05, Training time:50955.339773893356
batch reward last col mean 0.00016859671450220048 first col mean 4.145343609707197e-06 all mean 0.000163891731062904
4.305724723963067e-05 4.305724360165186e-05
rl training, epoch3, iter0, batch78/1133, batch loss:4.305724360165186e-05, Training time:50972.50234222412
batch reward last col mean 9.499638053966919e-08 first col mean 1.7024096905515762e-06 all mean 1.2397686077747494e-05
2.224650415882934e-05 2.2246502339839935e-05
rl training, epoch3, iter0, batch79/1133, batch loss:2.2246502339839935e-05, Training time:50989.903920173645
batch reward last col mean 2.9342859875214344e-07 first col mean 2.2727492705598706e-06 all mean 2.5460063625359908e-05
1.678418084338773e-05 1.6784184481366538e-05
rl training, epoch3, iter0, batch80/1133, batch loss:1.6784184481366538e-05, Training time:51007.35609126091
batch reward last col mean 2.3605402077464532e-08 first col mean 4.6415718202297285e-07 all mean 2.2547164917341433e-05
0.0001053311352734454 0.0001053311352734454
rl training, epoch3, iter0, batch81/1133, batch loss:0.0001053311352734454, Training time:51026.239468574524
batch reward last col mean 3.98416489133524e-07 first col mean 1.847016392275691e-06 all mean 2.5721545171109028e-05
1.8325412384001538e-05 1.8325416021980345e-05
rl training, epoch3, iter0, batch82/1133, batch loss:1.8325416021980345e-05, Training time:51045.04858613014
batch reward last col mean 2.5299357275798684e-07 first col mean 9.577097443980165e-06 all mean 2.1504389223991893e-05
5.24293354828842e-05 5.24293354828842e-05
rl training, epoch3, iter0, batch83/1133, batch loss:5.24293354828842e-05, Training time:51063.23920440674
batch reward last col mean 1.1665164265650674e-06 first col mean 0.0005335229798220098 all mean 3.46062624885235e-05
0.00011526131856953725 0.00011526131129357964
rl training, epoch3, iter0, batch84/1133, batch loss:0.00011526131129357964, Training time:51080.04227423668
batch reward last col mean 0.006420476827770472 first col mean 5.926926291976997e-07 all mean 0.006160542834550142
0.0004783508775290102 0.0004783508775290102
rl training, epoch3, iter0, batch85/1133, batch loss:0.0004783508775290102, Training time:51097.30347943306
batch reward last col mean 0.00044712377712130547 first col mean 3.8568719901377335e-05 all mean 0.00041267930646426976
2.440859316266142e-05 2.440859316266142e-05
rl training, epoch3, iter0, batch86/1133, batch loss:2.440859316266142e-05, Training time:51114.184953927994
batch reward last col mean 2.968633907585172e-07 first col mean 0.0012104060733690858 all mean 3.858600393868983e-05
0.00016522181977052242 0.00016522181977052242
rl training, epoch3, iter0, batch87/1133, batch loss:0.00016522181977052242, Training time:51130.95922780037
batch reward last col mean 1.0562467878116877e-07 first col mean 2.467509830239578e-06 all mean 5.186331691220403e-05
0.00013316913100425154 0.0001331691164523363
rl training, epoch3, iter0, batch88/1133, batch loss:0.0001331691164523363, Training time:51148.42396211624
batch reward last col mean 5.980241013503473e-08 first col mean 1.07543764897855e-05 all mean 4.014514706796035e-05
0.00015297922072932124 0.00015297922072932124
rl training, epoch3, iter0, batch89/1133, batch loss:0.00015297922072932124, Training time:51164.93316721916
batch reward last col mean 9.631942702981178e-06 first col mean 0.00042783928802236915 all mean 3.108469536527991e-05
5.570687790168449e-05 5.570687790168449e-05
rl training, epoch3, iter0, batch90/1133, batch loss:5.570687790168449e-05, Training time:51181.70705676079
batch reward last col mean 1.2843072909163311e-05 first col mean 1.465135852640742e-07 all mean 2.113899427058641e-06
2.958777940875734e-06 2.958778395623085e-06
rl training, epoch3, iter0, batch91/1133, batch loss:2.958778395623085e-06, Training time:51198.16882419586
batch reward last col mean 0.00026311076362617314 first col mean 2.6581452402751893e-05 all mean 0.00024545093765482306
2.273489189974498e-05 2.273489189974498e-05
rl training, epoch3, iter0, batch92/1133, batch loss:2.273489189974498e-05, Training time:51214.691722631454
batch reward last col mean 9.915520422509871e-07 first col mean 0.0003422361332923174 all mean 2.409822991467081e-05
3.7175454053794965e-05 3.717544677783735e-05
rl training, epoch3, iter0, batch93/1133, batch loss:3.717544677783735e-05, Training time:51231.151527643204
batch reward last col mean 1.7312322597717866e-05 first col mean 6.7493838287191465e-06 all mean 2.183934884669725e-05
5.8634057495510206e-05 5.8634057495510206e-05
rl training, epoch3, iter0, batch94/1133, batch loss:5.8634057495510206e-05, Training time:51249.49326467514
batch reward last col mean 0.00011313943832647055 first col mean 3.880635631503537e-05 all mean 7.657679088879377e-05
3.748496965272352e-05 3.748496965272352e-05
rl training, epoch3, iter0, batch95/1133, batch loss:3.748496965272352e-05, Training time:51267.00133705139
batch reward last col mean 0.0012890346115455031 first col mean 8.13257138361223e-05 all mean 0.0011865674750879407
0.0001603739510755986 0.00016037392197176814
rl training, epoch3, iter0, batch96/1133, batch loss:0.00016037392197176814, Training time:51285.33779168129
batch reward last col mean 9.989051932279835e-07 first col mean 1.8543386204328272e-07 all mean 1.929591417137999e-05
0.0001431447162758559 0.0001431447162758559
rl training, epoch3, iter0, batch97/1133, batch loss:0.0001431447162758559, Training time:51303.99017524719
batch reward last col mean 5.812857040154995e-08 first col mean 1.7394324459019117e-05 all mean 2.1458266928675584e-05
4.3112067942274734e-05 4.311207521823235e-05
rl training, epoch3, iter0, batch98/1133, batch loss:4.311207521823235e-05, Training time:51322.247389793396
batch reward last col mean 2.3790744307916611e-07 first col mean 1.7511139276393806e-06 all mean 2.1229572666925378e-05
9.929440420819446e-05 9.929440420819446e-05
rl training, epoch3, iter0, batch99/1133, batch loss:9.929440420819446e-05, Training time:51339.53162908554
batch reward last col mean 1.583498345780754e-07 first col mean 0.00016129335563164204 all mean 2.1849300537724048e-05
5.95287092437502e-05 5.952871288172901e-05
rl training, epoch3, iter0, batch100/1133, batch loss:5.952871288172901e-05, Training time:51356.28463053703
batch reward last col mean 3.990850018453784e-05 first col mean 2.7020153083867626e-06 all mean 4.1458049963694066e-05
8.459728996967897e-05 8.459728996967897e-05
rl training, epoch3, iter0, batch101/1133, batch loss:8.459728996967897e-05, Training time:51373.119222164154
batch reward last col mean 1.73853067053642e-07 first col mean 0.0010719988495111465 all mean 1.8191767594544217e-05
1.0744087376224343e-05 1.074408555723494e-05
rl training, epoch3, iter0, batch102/1133, batch loss:1.074408555723494e-05, Training time:51389.63497424126
batch reward last col mean 2.2800865906447143e-07 first col mean 1.5042793393149623e-06 all mean 2.9994680517120287e-05
1.1514784091559704e-05 1.1514789548527915e-05
rl training, epoch3, iter0, batch103/1133, batch loss:1.1514789548527915e-05, Training time:51406.209206819534
batch reward last col mean 1.610484190450734e-07 first col mean 3.4362687983957585e-07 all mean 2.1607102098641917e-05
5.6633482017787173e-05 5.6633482017787173e-05
rl training, epoch3, iter0, batch104/1133, batch loss:5.6633482017787173e-05, Training time:51422.898236989975
batch reward last col mean 1.7389037338944036e-06 first col mean 0.0002940584672614932 all mean 3.208733323845081e-05
5.735494050895795e-05 5.735494050895795e-05
rl training, epoch3, iter0, batch105/1133, batch loss:5.735494050895795e-05, Training time:51439.536272764206
batch reward last col mean 7.738598242212902e-07 first col mean 0.00015067565254867077 all mean 2.260651672258973e-05
0.00013897463213652372 0.00013897463213652372
rl training, epoch3, iter0, batch106/1133, batch loss:0.00013897463213652372, Training time:51456.1347990036
batch reward last col mean 0.001941678230650723 first col mean 2.26665875402432e-07 all mean 0.0017374970484524965
7.281707803485915e-05 7.281708531081676e-05
rl training, epoch3, iter0, batch107/1133, batch loss:7.281708531081676e-05, Training time:51473.09287548065
batch reward last col mean 7.830094546079636e-06 first col mean 1.4145741715765325e-06 all mean 1.8695009202929214e-05
6.001064684824087e-05 6.001064684824087e-05
rl training, epoch3, iter0, batch108/1133, batch loss:6.001064684824087e-05, Training time:51489.5863609314
batch reward last col mean 1.825467188609764e-05 first col mean 6.781698402846814e-07 all mean 4.0448911022394896e-05
8.494734356645495e-05 8.494734356645495e-05
rl training, epoch3, iter0, batch109/1133, batch loss:8.494734356645495e-05, Training time:51507.50006866455
batch reward last col mean 1.785671770448971e-07 first col mean 1.550776573822077e-06 all mean 2.1340583771234378e-05
2.123197918990627e-05 2.1231975551927462e-05
rl training, epoch3, iter0, batch110/1133, batch loss:2.1231975551927462e-05, Training time:51524.64558172226
batch reward last col mean 2.0286016422232933e-07 first col mean 1.2757411127495288e-07 all mean 4.1154384234687313e-05
0.00010745011240942404 0.00010745011240942404
rl training, epoch3, iter0, batch111/1133, batch loss:0.00010745011240942404, Training time:51542.06456160545
batch reward last col mean 1.3159060472389683e-06 first col mean 3.084285481236293e-06 all mean 1.958392203960102e-05
5.0411061238264665e-05 5.0411061238264665e-05
rl training, epoch3, iter0, batch112/1133, batch loss:5.0411061238264665e-05, Training time:51559.52651023865
batch reward last col mean 1.7192242012242787e-05 first col mean 0.0006566072115674615 all mean 3.5041015507886186e-05
0.00010282819130225107 0.00010282819130225107
rl training, epoch3, iter0, batch113/1133, batch loss:0.00010282819130225107, Training time:51578.544932127
batch reward last col mean 6.524312084366102e-06 first col mean 9.577506716595963e-05 all mean 6.529777692776406e-06
1.7516400475869887e-05 1.7516400475869887e-05
rl training, epoch3, iter0, batch114/1133, batch loss:1.7516400475869887e-05, Training time:51595.165301561356
batch reward last col mean 1.2224329282162216e-07 first col mean 2.1820664187544025e-05 all mean 1.113231701310724e-05
1.7828138879849575e-05 1.7828138879849575e-05
rl training, epoch3, iter0, batch115/1133, batch loss:1.7828138879849575e-05, Training time:51611.67885637283
batch reward last col mean 1.2224563761265017e-05 first col mean 3.508196471102565e-07 all mean 2.0605210011126474e-05
2.049796785286162e-05 2.049796785286162e-05
rl training, epoch3, iter0, batch116/1133, batch loss:2.049796785286162e-05, Training time:51628.712168216705
batch reward last col mean 7.182893568824511e-07 first col mean 0.0015500144800171256 all mean 4.989176522940397e-05
8.663364860694855e-05 8.66336704348214e-05
rl training, epoch3, iter0, batch117/1133, batch loss:8.66336704348214e-05, Training time:51645.746507167816
batch reward last col mean 2.5991719212470343e-06 first col mean 2.585392394394148e-06 all mean 4.423984864843078e-05
0.00023114764189813286 0.0002311476564500481
rl training, epoch3, iter0, batch118/1133, batch loss:0.0002311476564500481, Training time:51662.334787368774
batch reward last col mean 2.168217861253652e-06 first col mean 1.6971915783869918e-07 all mean 1.1488201380416285e-05
1.714229438221082e-05 1.714229438221082e-05
rl training, epoch3, iter0, batch119/1133, batch loss:1.714229438221082e-05, Training time:51679.19847416878
batch reward last col mean 3.849246786558069e-05 first col mean 1.670545134402346e-05 all mean 1.7834472600952722e-05
6.422221485991031e-05 6.42222075839527e-05
rl training, epoch3, iter0, batch120/1133, batch loss:6.42222075839527e-05, Training time:51696.06332421303
batch reward last col mean 0.00011441799870226532 first col mean 1.2763135600835085e-05 all mean 0.00012439070269465446
8.60369618749246e-05 8.603697642683983e-05
rl training, epoch3, iter0, batch121/1133, batch loss:8.603697642683983e-05, Training time:51712.73773622513
batch reward last col mean 6.267714525165502e-07 first col mean 0.0009940428426489234 all mean 1.7313092030235566e-05
1.2150326256232802e-05 1.215031988976989e-05
rl training, epoch3, iter0, batch122/1133, batch loss:1.215031988976989e-05, Training time:51729.276354789734
batch reward last col mean 7.973638389557891e-07 first col mean 2.981783381983405e-06 all mean 5.511057679541409e-06
5.26897792951786e-06 5.26897792951786e-06
rl training, epoch3, iter0, batch123/1133, batch loss:5.26897792951786e-06, Training time:51746.201741695404
batch reward last col mean 2.555782430135878e-07 first col mean 1.913110963869258e-06 all mean 3.853774251183495e-05
0.00016077622422017157 0.00016077622422017157
rl training, epoch3, iter0, batch124/1133, batch loss:0.00016077622422017157, Training time:51764.95919275284
batch reward last col mean 6.7520173615776e-05 first col mean 0.00012500509910751134 all mean 0.00012600382615346462
0.00038634627708233893 0.00038634627708233893
rl training, epoch3, iter0, batch125/1133, batch loss:0.00038634627708233893, Training time:51783.3329679966
batch reward last col mean 0.0011679757153615355 first col mean 4.9883407626793996e-08 all mean 0.0011053307680413127
7.726040348643437e-05 7.726040348643437e-05
rl training, epoch3, iter0, batch126/1133, batch loss:7.726040348643437e-05, Training time:51802.18208646774
batch reward last col mean 2.391962198089459e-06 first col mean 2.937251792900497e-06 all mean 8.22126185084926e-06
3.0299399440991692e-05 3.0299399440991692e-05
rl training, epoch3, iter0, batch127/1133, batch loss:3.0299399440991692e-05, Training time:51820.06249856949
batch reward last col mean 7.600195658596931e-06 first col mean 0.0001672888029133901 all mean 1.4675525562779512e-05
8.894529855751898e-06 8.894528036762495e-06
rl training, epoch3, iter0, batch128/1133, batch loss:8.894528036762495e-06, Training time:51839.60219454765
batch reward last col mean 2.737135901043075e-06 first col mean 5.69395581351273e-07 all mean 1.9188337319064885e-05
1.690838507784065e-05 1.6908377801883034e-05
rl training, epoch3, iter0, batch129/1133, batch loss:1.6908377801883034e-05, Training time:51856.84811615944
batch reward last col mean 2.1004526118417743e-08 first col mean 6.193999070092104e-06 all mean 2.040582876361441e-05
4.2845000280067325e-05 4.284499664208852e-05
rl training, epoch3, iter0, batch130/1133, batch loss:4.284499664208852e-05, Training time:51873.44778800011
batch reward last col mean 1.9231120518270473e-07 first col mean 0.0014701306354254484 all mean 2.5809624276007526e-05
8.273615821963176e-05 8.273616549558938e-05
rl training, epoch3, iter0, batch131/1133, batch loss:8.273616549558938e-05, Training time:51891.00560927391
batch reward last col mean 8.15728708403185e-05 first col mean 3.1644520959162037e-07 all mean 9.95936497929506e-05
5.5635911849094555e-05 5.563590821111575e-05
rl training, epoch3, iter0, batch132/1133, batch loss:5.563590821111575e-05, Training time:51907.82233119011
batch reward last col mean 0.0008354636956937611 first col mean 3.885873411491048e-06 all mean 0.0007796175195835531
0.00011768804688472301 0.00011768804688472301
rl training, epoch3, iter0, batch133/1133, batch loss:0.00011768804688472301, Training time:51924.995453596115
batch reward last col mean 8.812575913452747e-08 first col mean 0.0017696968279778957 all mean 2.8466487492551096e-05
7.496999023715034e-05 7.496998296119273e-05
rl training, epoch3, iter0, batch134/1133, batch loss:7.496998296119273e-05, Training time:51941.541601896286
batch reward last col mean 0.0003750709001906216 first col mean 0.0007231803028844297 all mean 0.00034526773379184306
3.489855953375809e-05 3.4898563171736896e-05
rl training, epoch3, iter0, batch135/1133, batch loss:3.4898563171736896e-05, Training time:51958.25249028206
batch reward last col mean 8.130511730541912e-08 first col mean 1.1753299077099655e-05 all mean 2.2061338313505985e-05
0.00010139524965779856 0.00010139524965779856
rl training, epoch3, iter0, batch136/1133, batch loss:0.00010139524965779856, Training time:51974.89360809326
batch reward last col mean 6.334243494166003e-07 first col mean 1.3840956114563596e-07 all mean 4.4936492486158386e-05
6.315540667856112e-05 6.315539212664589e-05
rl training, epoch3, iter0, batch137/1133, batch loss:6.315539212664589e-05, Training time:51991.465723752975
batch reward last col mean 7.509686383855296e-07 first col mean 0.0010177354561164975 all mean 1.365448406431824e-05
1.0943691449938342e-05 1.0943695087917149e-05
rl training, epoch3, iter0, batch138/1133, batch loss:1.0943695087917149e-05, Training time:52007.95899295807
batch reward last col mean 1.2079600310244132e-05 first col mean 3.1528093131782953e-06 all mean 3.894359906553291e-05
8.718234312254936e-05 8.718235039850697e-05
rl training, epoch3, iter0, batch139/1133, batch loss:8.718235039850697e-05, Training time:52025.08173561096
batch reward last col mean 7.57960776809341e-07 first col mean 6.304875910245755e-08 all mean 1.4916428881406318e-05
2.6723757400759496e-05 2.6723761038738303e-05
rl training, epoch3, iter0, batch140/1133, batch loss:2.6723761038738303e-05, Training time:52042.59619998932
batch reward last col mean 1.63397388064368e-07 first col mean 0.00012071544188074768 all mean 9.300043529947288e-06
6.55710164210177e-06 6.557103461091174e-06
rl training, epoch3, iter0, batch141/1133, batch loss:6.557103461091174e-06, Training time:52059.700543403625
batch reward last col mean 1.176412865788734e-06 first col mean 2.714840775297489e-05 all mean 1.2660692846111488e-05
1.192130639537936e-05 1.1921303666895255e-05
rl training, epoch3, iter0, batch142/1133, batch loss:1.1921303666895255e-05, Training time:52078.746587753296
batch reward last col mean 0.007527966517955065 first col mean 2.1585365175269544e-06 all mean 0.006400535348802805
0.0004585467977449298 0.0004585467977449298
rl training, epoch3, iter0, batch143/1133, batch loss:0.0004585467977449298, Training time:52096.05682373047
batch reward last col mean 7.650784255019971e-07 first col mean 2.2306455775833456e-06 all mean 6.638563718297519e-06
2.261838744743727e-05 2.261838744743727e-05
rl training, epoch3, iter0, batch144/1133, batch loss:2.261838744743727e-05, Training time:52115.4777302742
batch reward last col mean 2.714700258366065e-06 first col mean 5.730684051741264e-07 all mean 3.646156983450055e-05
8.204751793527976e-05 8.204750338336453e-05
rl training, epoch3, iter0, batch145/1133, batch loss:8.204750338336453e-05, Training time:52133.435029029846
batch reward last col mean 7.329745130846277e-06 first col mean 6.0956994275329635e-05 all mean 2.1740981537732296e-05
8.219452138291672e-05 8.219452865887433e-05
rl training, epoch3, iter0, batch146/1133, batch loss:8.219452865887433e-05, Training time:52149.99222826958
batch reward last col mean 1.9378857629703816e-08 first col mean 0.000337360572302714 all mean 2.7030362616642378e-05
5.0682105211308226e-05 5.0682105211308226e-05
rl training, epoch3, iter0, batch147/1133, batch loss:5.0682105211308226e-05, Training time:52166.60125088692
batch reward last col mean 1.2259215509402566e-07 first col mean 8.139149031194393e-06 all mean 1.3776644664176274e-05
5.1622071623569354e-05 5.1622071623569354e-05
rl training, epoch3, iter0, batch148/1133, batch loss:5.1622071623569354e-05, Training time:52183.136976242065
batch reward last col mean 9.59708131631487e-07 first col mean 8.60668660607189e-05 all mean 1.1675925634335726e-05
1.3228845091362018e-05 1.3228842362877913e-05
rl training, epoch3, iter0, batch149/1133, batch loss:1.3228842362877913e-05, Training time:52200.09564113617
batch reward last col mean 0.0003536004514899105 first col mean 7.131260190362809e-06 all mean 0.00029039205401204526
2.621551902848296e-05 2.6215520847472362e-05
rl training, epoch3, iter0, batch150/1133, batch loss:2.6215520847472362e-05, Training time:52216.73498916626
batch reward last col mean 1.5276259546226356e-07 first col mean 0.0005043857381679118 all mean 2.7004936782759614e-05
4.655196607927792e-05 4.6551969717256725e-05
rl training, epoch3, iter0, batch151/1133, batch loss:4.6551969717256725e-05, Training time:52233.43501138687
batch reward last col mean 1.3105798757351295e-07 first col mean 1.5009099740836973e-07 all mean 3.2480045774718747e-05
4.85684176965151e-05 4.856841405853629e-05
rl training, epoch3, iter0, batch152/1133, batch loss:4.856841405853629e-05, Training time:52250.324571847916
batch reward last col mean 3.329417950226343e-07 first col mean 1.2403315849951468e-06 all mean 1.9124012396787293e-05
9.396338282385841e-05 9.39633755479008e-05
rl training, epoch3, iter0, batch153/1133, batch loss:9.39633755479008e-05, Training time:52267.48788380623
batch reward last col mean 1.1366139005986042e-05 first col mean 2.5420249585295096e-06 all mean 1.868917388492264e-05
2.2985515897744335e-05 2.298551771673374e-05
rl training, epoch3, iter0, batch154/1133, batch loss:2.298551771673374e-05, Training time:52284.26714539528
batch reward last col mean 4.5529965575497044e-08 first col mean 3.8565144677704666e-07 all mean 1.1596989679674152e-05
2.3856013285694644e-05 2.3856015104684047e-05
rl training, epoch3, iter0, batch155/1133, batch loss:2.3856015104684047e-05, Training time:52300.93612957001
batch reward last col mean 1.10556047729915e-05 first col mean 5.58731926503242e-06 all mean 1.9493703803163953e-05
2.7307791242492385e-05 2.730778942350298e-05
rl training, epoch3, iter0, batch156/1133, batch loss:2.730778942350298e-05, Training time:52317.54794192314
batch reward last col mean 8.525579460183508e-07 first col mean 0.00020145493908785284 all mean 2.129679523932282e-05
6.626284448429942e-05 6.626284448429942e-05
rl training, epoch3, iter0, batch157/1133, batch loss:6.626284448429942e-05, Training time:52334.198191165924
batch reward last col mean 1.6996709746308625e-06 first col mean 4.0101892295751895e-07 all mean 1.9070294001721777e-05
3.851884321193211e-05 3.8518846849910915e-05
rl training, epoch3, iter0, batch158/1133, batch loss:3.8518846849910915e-05, Training time:52351.06767988205
batch reward last col mean 4.886824740424345e-07 first col mean 7.148251461330801e-05 all mean 7.618499239470111e-06
5.030911779613234e-06 5.030912234360585e-06
rl training, epoch3, iter0, batch159/1133, batch loss:5.030912234360585e-06, Training time:52368.73360991478
batch reward last col mean 9.47324494404711e-08 first col mean 4.939725113217719e-05 all mean 1.0547275451244786e-05
1.2597201930475421e-05 1.2597201930475421e-05
rl training, epoch3, iter0, batch160/1133, batch loss:1.2597201930475421e-05, Training time:52386.644912958145
batch reward last col mean 4.338736289355438e-06 first col mean 4.5075771026859e-07 all mean 2.1747971914010122e-05
7.772776734782383e-05 7.772777462378144e-05
rl training, epoch3, iter0, batch161/1133, batch loss:7.772777462378144e-05, Training time:52404.645273685455
batch reward last col mean 1.29038113527713e-07 first col mean 3.525596912368201e-05 all mean 3.189888593624346e-05
3.737247971002944e-05 3.737246879609302e-05
rl training, epoch3, iter0, batch162/1133, batch loss:3.737246879609302e-05, Training time:52421.83297753334
batch reward last col mean 2.0224000252255792e-07 first col mean 6.968271577534324e-07 all mean 5.046239493822213e-06
4.754938345286064e-06 4.754939254780766e-06
rl training, epoch3, iter0, batch163/1133, batch loss:4.754939254780766e-06, Training time:52439.54432106018
batch reward last col mean 4.035460108298139e-07 first col mean 2.8744409519276815e-07 all mean 4.621872358256951e-05
0.00016107152623590082 0.00016107154078781605
rl training, epoch3, iter0, batch164/1133, batch loss:0.00016107154078781605, Training time:52456.222450494766
batch reward last col mean 7.569430238163477e-08 first col mean 1.1545680536073633e-06 all mean 5.124383733345894e-06
2.890181895054411e-05 2.890181895054411e-05
rl training, epoch3, iter0, batch165/1133, batch loss:2.890181895054411e-05, Training time:52472.88237500191
batch reward last col mean 0.0003710724995471537 first col mean 2.2393216568161733e-05 all mean 1.5628651453880593e-05
1.8827349776984192e-05 1.882734795799479e-05
rl training, epoch3, iter0, batch166/1133, batch loss:1.882734795799479e-05, Training time:52489.390182733536
batch reward last col mean 1.6485159903822932e-06 first col mean 2.438259230075346e-07 all mean 6.017401028657332e-05
0.00034304571454413235 0.0003430457436479628
rl training, epoch3, iter0, batch167/1133, batch loss:0.0003430457436479628, Training time:52506.145491838455
batch reward last col mean 1.3260799391900946e-07 first col mean 1.850067263831079e-07 all mean 1.4632919373980258e-05
9.105736535275355e-05 9.105736535275355e-05
rl training, epoch3, iter0, batch168/1133, batch loss:9.105736535275355e-05, Training time:52522.96407389641
batch reward last col mean 5.512246161742951e-07 first col mean 3.288624384367722e-06 all mean 3.641867806436494e-05
0.00019797369895968586 0.00019797369895968586
rl training, epoch3, iter0, batch169/1133, batch loss:0.00019797369895968586, Training time:52540.110923051834
batch reward last col mean 8.975541732070269e-08 first col mean 6.4233231569232885e-06 all mean 1.920252361742314e-05
0.0001834876456996426 0.0001834876456996426
rl training, epoch3, iter0, batch170/1133, batch loss:0.0001834876456996426, Training time:52556.90607070923
batch reward last col mean 2.5621790200602845e-07 first col mean 4.950542461301666e-06 all mean 3.647099219961092e-05
0.0001690175267867744 0.0001690175267867744
rl training, epoch3, iter0, batch171/1133, batch loss:0.0001690175267867744, Training time:52573.77513408661
batch reward last col mean 3.787651803577319e-05 first col mean 0.0005953653599135578 all mean 4.2299718188587576e-05
4.4813277781941e-05 4.4813277781941e-05
rl training, epoch3, iter0, batch172/1133, batch loss:4.4813277781941e-05, Training time:52590.56171250343
batch reward last col mean 2.8093685955354886e-07 first col mean 0.0010426784865558147 all mean 1.8674008970265277e-05
7.59423437557416e-06 7.594231647090055e-06
rl training, epoch3, iter0, batch173/1133, batch loss:7.594231647090055e-06, Training time:52607.65252137184
batch reward last col mean 1.8757422139970004e-06 first col mean 7.037313594082661e-07 all mean 2.7996517019346356e-05
1.7715732610668056e-05 1.771572897268925e-05
rl training, epoch3, iter0, batch174/1133, batch loss:1.771572897268925e-05, Training time:52624.43624162674
batch reward last col mean 5.497126949194353e-07 first col mean 2.1067451143608196e-06 all mean 2.6800567866303027e-05
6.122492050053552e-05 6.122492777649313e-05
rl training, epoch3, iter0, batch175/1133, batch loss:6.122492777649313e-05, Training time:52641.12872171402
batch reward last col mean 5.905213765799999e-05 first col mean 1.8084903103954275e-06 all mean 2.5518223992548883e-05
0.00012851229985244572 0.0001285122853005305
rl training, epoch3, iter0, batch176/1133, batch loss:0.0001285122853005305, Training time:52659.04332327843
batch reward last col mean 1.2313739716773853e-06 first col mean 0.00048157403944060206 all mean 2.11609967664117e-05
8.603554306318983e-05 8.603554306318983e-05
rl training, epoch3, iter0, batch177/1133, batch loss:8.603554306318983e-05, Training time:52677.40363883972
batch reward last col mean 1.2371388891097013e-07 first col mean 1.463244672095243e-07 all mean 1.5916481061140075e-05
3.061817915295251e-05 3.06181755149737e-05
rl training, epoch3, iter0, batch178/1133, batch loss:3.06181755149737e-05, Training time:52696.68684053421
batch reward last col mean 1.0242430903417699e-07 first col mean 4.930594172947167e-07 all mean 2.5087021640501916e-05
3.8414647860918194e-05 3.841464422293939e-05
rl training, epoch3, iter0, batch179/1133, batch loss:3.841464422293939e-05, Training time:52714.23043370247
batch reward last col mean 4.2537568134548565e-08 first col mean 9.921193850459531e-05 all mean 1.0779947842820548e-05
3.125798320979811e-05 3.125798320979811e-05
rl training, epoch3, iter0, batch180/1133, batch loss:3.125798320979811e-05, Training time:52733.23517584801
batch reward last col mean 1.72305431078712e-06 first col mean 0.0003901202871929854 all mean 2.139177013305016e-05
8.101804996840656e-05 8.101804996840656e-05
rl training, epoch3, iter0, batch181/1133, batch loss:8.101804996840656e-05, Training time:52750.741740226746
batch reward last col mean 8.320814231410623e-06 first col mean 2.3883803805802017e-06 all mean 5.560164208873175e-05
0.0001849028340075165 0.00018490284855943173
rl training, epoch3, iter0, batch182/1133, batch loss:0.00018490284855943173, Training time:52767.508159160614
batch reward last col mean 8.78680793903186e-07 first col mean 0.0001488783600507304 all mean 2.054030483122915e-05
4.8588859499432147e-05 4.8588859499432147e-05
rl training, epoch3, iter0, batch183/1133, batch loss:4.8588859499432147e-05, Training time:52784.45521426201
batch reward last col mean 2.047856497711109e-07 first col mean 1.0306225703970995e-06 all mean 1.0732002920121886e-05
6.078248406993225e-05 6.078248406993225e-05
rl training, epoch3, iter0, batch184/1133, batch loss:6.078248406993225e-05, Training time:52801.44589138031
batch reward last col mean 0.0012673179153352976 first col mean 8.473800789943198e-07 all mean 0.001083717099390924
0.00013244777801446617 0.00013244777801446617
rl training, epoch3, iter0, batch185/1133, batch loss:0.00013244777801446617, Training time:52817.90350866318
batch reward last col mean 2.3187614317521366e-07 first col mean 4.832052127312636e-07 all mean 3.1922972993925214e-05
2.1710287910536863e-05 2.171028609154746e-05
rl training, epoch3, iter0, batch186/1133, batch loss:2.171028609154746e-05, Training time:52835.16063499451
batch reward last col mean 0.0018562887562438846 first col mean 3.1777054232406954e-07 all mean 0.001793498988263309
0.0001820722100092098 0.00018207219545729458
rl training, epoch3, iter0, batch187/1133, batch loss:0.00018207219545729458, Training time:52853.49002790451
batch reward last col mean 2.007703869821853e-07 first col mean 0.00023578846594318748 all mean 1.326128767686896e-05
1.743497523420956e-05 1.7434977053198963e-05
rl training, epoch3, iter0, batch188/1133, batch loss:1.7434977053198963e-05, Training time:52871.80185055733
batch reward last col mean 4.483669613364327e-08 first col mean 7.58265457534435e-07 all mean 8.097030331555288e-06
3.46854426425125e-06 3.4685451737459516e-06
rl training, epoch3, iter0, batch189/1133, batch loss:3.4685451737459516e-06, Training time:52890.49591612816
batch reward last col mean 4.7719908025101176e-08 first col mean 4.757256465381943e-05 all mean 3.05386092804838e-05
0.00014805319369770586 0.00014805319369770586
rl training, epoch3, iter0, batch190/1133, batch loss:0.00014805319369770586, Training time:52908.81762385368
batch reward last col mean 2.6588245418679435e-06 first col mean 0.001477524172514677 all mean 5.5195479944813997e-05
0.00021096091950312257 0.00021096091950312257
rl training, epoch3, iter0, batch191/1133, batch loss:0.00021096091950312257, Training time:52927.76566028595
batch reward last col mean 3.408080431199778e-07 first col mean 8.797713235253468e-06 all mean 3.986680439993506e-06
5.915546353207901e-06 5.915546353207901e-06
rl training, epoch3, iter0, batch192/1133, batch loss:5.915546353207901e-06, Training time:52945.36899423599
batch reward last col mean 1.807263743103249e-07 first col mean 1.133620230575616e-06 all mean 4.478618848224869e-06
1.5607178283971734e-05 1.5607178283971734e-05
rl training, epoch3, iter0, batch193/1133, batch loss:1.5607178283971734e-05, Training time:52961.689259290695
batch reward last col mean 1.5912790729544213e-07 first col mean 0.000336368364514783 all mean 6.551713886437938e-05
0.00014051176549401134 0.00014051173639018089
rl training, epoch3, iter0, batch194/1133, batch loss:0.00014051173639018089, Training time:52979.0808801651
batch reward last col mean 4.292649828130379e-05 first col mean 1.2930709090142045e-06 all mean 5.9506874094950035e-05
0.00011885036656167358 0.00011885035928571597
rl training, epoch3, iter0, batch195/1133, batch loss:0.00011885035928571597, Training time:52997.87782430649
batch reward last col mean 0.0013620498357340693 first col mean 5.031223736295942e-06 all mean 3.5591448977356777e-05
0.00013758643763139844 0.00013758643763139844
rl training, epoch3, iter0, batch196/1133, batch loss:0.00013758643763139844, Training time:53015.1535217762
batch reward last col mean 1.1608058230194729e-06 first col mean 9.56291569309542e-06 all mean 1.1859273399750236e-05
3.660484071588144e-05 3.660483707790263e-05
rl training, epoch3, iter0, batch197/1133, batch loss:3.660483707790263e-05, Training time:53033.31318116188
batch reward last col mean 1.2786486536242592e-07 first col mean 3.2596400956208527e-07 all mean 1.5355468349298462e-05
1.4758360521227587e-05 1.4758360521227587e-05
rl training, epoch3, iter0, batch198/1133, batch loss:1.4758360521227587e-05, Training time:53051.18539905548
batch reward last col mean 3.5255891361885006e-07 first col mean 2.1475707399076782e-06 all mean 4.1656367102405056e-05
0.0001958749198820442 0.00019587490533012897
rl training, epoch3, iter0, batch199/1133, batch loss:0.00019587490533012897, Training time:53069.108360767365
batch reward last col mean 0.00019696296658366919 first col mean 5.5831792451499496e-06 all mean 0.0002129531785612926
0.0001036165704135783 0.00010361658496549353
rl training, epoch3, iter0, batch200/1133, batch loss:0.00010361658496549353, Training time:53087.47723817825
batch reward last col mean 2.9902545861659746e-07 first col mean 2.885675712605007e-05 all mean 2.1147552615730092e-05
2.7022952053812332e-05 2.7022953872801736e-05
rl training, epoch3, iter0, batch201/1133, batch loss:2.7022953872801736e-05, Training time:53104.96163868904
batch reward last col mean 3.0406064865928784e-07 first col mean 3.766263318993879e-07 all mean 2.577461964392569e-05
0.00010623712296364829 0.0001062371302396059
rl training, epoch3, iter0, batch202/1133, batch loss:0.0001062371302396059, Training time:53124.0720000267
batch reward last col mean 0.00013063267397228628 first col mean 6.628280857512436e-07 all mean 0.00015087408246472478
0.00014003893011249602 0.00014003893011249602
rl training, epoch3, iter0, batch203/1133, batch loss:0.00014003893011249602, Training time:53142.585344552994
batch reward last col mean 1.464153911001631e-06 first col mean 1.0884647053899243e-05 all mean 3.410561112104915e-05
8.968135080067441e-05 8.968135080067441e-05
rl training, epoch3, iter0, batch204/1133, batch loss:8.968135080067441e-05, Training time:53160.20918774605
batch reward last col mean 1.4828403891442576e-06 first col mean 9.723665243654978e-06 all mean 2.2010823158780113e-05
4.7964913392206654e-05 4.7964913392206654e-05
rl training, epoch3, iter0, batch205/1133, batch loss:4.7964913392206654e-05, Training time:53177.086277246475
batch reward last col mean 0.0004022887733299285 first col mean 6.12165365510009e-07 all mean 0.0004061841173097491
0.00015976239228621125 0.00015976239228621125
rl training, epoch3, iter0, batch206/1133, batch loss:0.00015976239228621125, Training time:53194.944440603256
batch reward last col mean 0.000203711970243603 first col mean 3.9193506381707266e-05 all mean 1.3276634490466677e-05
3.880268559441902e-05 3.880268559441902e-05
rl training, epoch3, iter0, batch207/1133, batch loss:3.880268559441902e-05, Training time:53212.759395837784
batch reward last col mean 1.9834012618957786e-06 first col mean 3.301745164208114e-05 all mean 1.8771701434161514e-05
3.6950990761397406e-05 3.69509871234186e-05
rl training, epoch3, iter0, batch208/1133, batch loss:3.69509871234186e-05, Training time:53230.5791823864
batch reward last col mean 1.0177582225878723e-06 first col mean 1.9153170796926133e-05 all mean 1.0483895493962336e-05
2.2205838831723668e-05 2.2205837012734264e-05
rl training, epoch3, iter0, batch209/1133, batch loss:2.2205837012734264e-05, Training time:53247.78985643387
batch reward last col mean 7.495908960208908e-08 first col mean 1.238509099721341e-07 all mean 4.945557975588599e-06
1.0712386938394047e-05 1.0712388757383451e-05
rl training, epoch3, iter0, batch210/1133, batch loss:1.0712388757383451e-05, Training time:53265.01012992859
batch reward last col mean 7.386299927247819e-08 first col mean 9.761599358171225e-06 all mean 2.5469229512964375e-05
5.006584615330212e-05 5.0065849791280925e-05
rl training, epoch3, iter0, batch211/1133, batch loss:5.0065849791280925e-05, Training time:53282.309557914734
batch reward last col mean 3.410374847589992e-05 first col mean 6.768425373593345e-05 all mean 5.298559335642494e-05
5.540047641261481e-05 5.540047641261481e-05
rl training, epoch3, iter0, batch212/1133, batch loss:5.540047641261481e-05, Training time:53299.61134624481
batch reward last col mean 0.00017034310440067202 first col mean 9.002477600006387e-05 all mean 9.768203744897619e-05
0.0001818183809518814 0.0001818183809518814
rl training, epoch3, iter0, batch213/1133, batch loss:0.0001818183809518814, Training time:53317.69343519211
batch reward last col mean 3.6583221572072944e-06 first col mean 5.096722816233523e-05 all mean 8.725879524718039e-06
7.72105067881057e-06 7.721049769315869e-06
rl training, epoch3, iter0, batch214/1133, batch loss:7.721049769315869e-06, Training time:53336.55234289169
batch reward last col mean 5.315091584634501e-07 first col mean 7.414866558974609e-05 all mean 9.781266271602362e-06
2.3280414097825997e-05 2.3280414097825997e-05
rl training, epoch3, iter0, batch215/1133, batch loss:2.3280414097825997e-05, Training time:53355.26512956619
batch reward last col mean 4.862004516326124e-06 first col mean 1.6198035268644162e-07 all mean 2.90188781946199e-05
2.324163870071061e-05 2.3241645976668224e-05
rl training, epoch3, iter0, batch216/1133, batch loss:2.3241645976668224e-05, Training time:53373.24472475052
batch reward last col mean 3.6920365431569735e-08 first col mean 3.3933232771232724e-05 all mean 3.9297842704399955e-06
1.1336190254951362e-05 1.1336191164446063e-05
rl training, epoch3, iter0, batch217/1133, batch loss:1.1336191164446063e-05, Training time:53390.97807884216
batch reward last col mean 5.296535618981579e-07 first col mean 0.0002704060752876103 all mean 1.1111931598861702e-05
4.780336439580424e-06 4.780336894327775e-06
rl training, epoch3, iter0, batch218/1133, batch loss:4.780336894327775e-06, Training time:53408.34407401085
batch reward last col mean 9.073958722183306e-07 first col mean 1.9212000552215613e-05 all mean 1.3931802641309332e-05
5.483492714120075e-05 5.4834923503221944e-05
rl training, epoch3, iter0, batch219/1133, batch loss:5.4834923503221944e-05, Training time:53426.119097709656
batch reward last col mean 8.346391950908583e-07 first col mean 0.0007740342407487333 all mean 2.0702616893686354e-05
3.257064236095175e-05 3.2570638722972944e-05
rl training, epoch3, iter0, batch220/1133, batch loss:3.2570638722972944e-05, Training time:53443.395025253296
batch reward last col mean 3.569142847936746e-07 first col mean 1.3957828741695266e-06 all mean 4.606545189744793e-05
0.00014855201879981905 0.00014855201879981905
rl training, epoch3, iter0, batch221/1133, batch loss:0.00014855201879981905, Training time:53461.44695711136
batch reward last col mean 1.2520634129487007e-07 first col mean 7.144002438508323e-07 all mean 1.950023761310149e-05
4.974059720552759e-06 4.9740547183318995e-06
rl training, epoch3, iter0, batch222/1133, batch loss:4.9740547183318995e-06, Training time:53479.00859975815
batch reward last col mean 8.163416168827098e-06 first col mean 2.6923839868686628e-06 all mean 4.2502029828028753e-05
0.00010026841482613236 0.00010026841482613236
rl training, epoch3, iter0, batch223/1133, batch loss:0.00010026841482613236, Training time:53497.88859820366
batch reward last col mean 0.007144229020923376 first col mean 0.0009884661994874477 all mean 0.0066727628000080585
0.0004262739385012537 0.0004262739385012537
rl training, epoch3, iter0, batch224/1133, batch loss:0.0004262739385012537, Training time:53515.68865799904
batch reward last col mean 5.115718886372633e-05 first col mean 0.0002418713556835428 all mean 3.486881541903131e-05
6.476871931226924e-05 6.476871203631163e-05
rl training, epoch3, iter0, batch225/1133, batch loss:6.476871203631163e-05, Training time:53534.73738837242
batch reward last col mean 4.6110367293294985e-06 first col mean 0.00030222683562897146 all mean 3.20736835419666e-05
6.53088281978853e-05 6.530883547384292e-05
rl training, epoch3, iter0, batch226/1133, batch loss:6.530883547384292e-05, Training time:53552.26667690277
batch reward last col mean 9.97163283500413e-07 first col mean 2.9844886739738286e-07 all mean 3.062497853534296e-05
0.00010351795936003327 0.00010351795936003327
rl training, epoch3, iter0, batch227/1133, batch loss:0.00010351795936003327, Training time:53570.86163473129
batch reward last col mean 7.471662115676736e-07 first col mean 3.353345050527423e-07 all mean 4.64601325802505e-05
8.727994281798601e-05 8.727994281798601e-05
rl training, epoch3, iter0, batch228/1133, batch loss:8.727994281798601e-05, Training time:53590.48456835747
batch reward last col mean 3.425580814564455e-07 first col mean 7.01819226378575e-05 all mean 1.2995776160096284e-05
4.0856444684322923e-05 4.0856444684322923e-05
rl training, epoch3, iter0, batch229/1133, batch loss:4.0856444684322923e-05, Training time:53607.82600545883
batch reward last col mean 1.2045519781622716e-07 first col mean 0.00035737847792916 all mean 3.715854836627841e-05
8.051181794144213e-05 8.051181794144213e-05
rl training, epoch3, iter0, batch230/1133, batch loss:8.051181794144213e-05, Training time:53624.27726984024
batch reward last col mean 7.664614713576157e-06 first col mean 1.8346286196901929e-06 all mean 4.204740253044292e-05
4.5992666855454445e-05 4.599265957949683e-05
rl training, epoch3, iter0, batch231/1133, batch loss:4.599265957949683e-05, Training time:53640.81445431709
batch reward last col mean 4.362072303365494e-08 first col mean 0.001342384028248489 all mean 2.95051413559122e-05
0.00010313900565961376 0.00010313898383174092
rl training, epoch3, iter0, batch232/1133, batch loss:0.00010313898383174092, Training time:53657.780215501785
batch reward last col mean 5.098290216665191e-07 first col mean 0.00013245690206531435 all mean 2.9185504899942316e-05
9.048323408933356e-05 9.048322681337595e-05
rl training, epoch3, iter0, batch233/1133, batch loss:9.048322681337595e-05, Training time:53674.484479904175
batch reward last col mean 9.472686457456803e-08 first col mean 1.6810305680792226e-07 all mean 4.350077870185487e-05
0.0001424665388185531 0.0001424665388185531
rl training, epoch3, iter0, batch234/1133, batch loss:0.0001424665388185531, Training time:53691.12012553215
batch reward last col mean 7.9852354247123e-05 first col mean 1.1163866702190717e-06 all mean 8.371926378458738e-05
3.358317553647794e-05 3.358317553647794e-05
rl training, epoch3, iter0, batch235/1133, batch loss:3.358317553647794e-05, Training time:53707.70594096184
batch reward last col mean 1.3094188489048975e-07 first col mean 2.2849901142762974e-05 all mean 3.765746077988297e-05
0.00012237898772582412 0.00012237898772582412
rl training, epoch3, iter0, batch236/1133, batch loss:0.00012237898772582412, Training time:53724.220219135284
batch reward last col mean 1.204464261661542e-08 first col mean 1.913112299689601e-07 all mean 3.209501301171258e-05
6.68876527925022e-05 6.68876527925022e-05
rl training, epoch3, iter0, batch237/1133, batch loss:6.68876527925022e-05, Training time:53741.15100002289
batch reward last col mean 6.2477272877004e-05 first col mean 1.0744488463387825e-05 all mean 0.00010169611050514504
0.0002003536792472005 0.00020035369379911572
rl training, epoch3, iter0, batch238/1133, batch loss:0.00020035369379911572, Training time:53757.94569396973
batch reward last col mean 3.655212026387744e-07 first col mean 1.176005298475502e-06 all mean 1.0544904398557264e-05
1.0535746696405113e-05 1.0535743967921007e-05
rl training, epoch3, iter0, batch239/1133, batch loss:1.0535743967921007e-05, Training time:53774.716024398804
batch reward last col mean 0.0001570331078255549 first col mean 1.7776988897821866e-05 all mean 3.0147095458232798e-05
3.1009076337795705e-05 3.1009076337795705e-05
rl training, epoch3, iter0, batch240/1133, batch loss:3.1009076337795705e-05, Training time:53793.44591832161
batch reward last col mean 0.0006325315916910768 first col mean 3.3248497857130133e-06 all mean 0.0005570921930484474
5.524916196009144e-05 5.524916196009144e-05
rl training, epoch3, iter0, batch241/1133, batch loss:5.524916196009144e-05, Training time:53812.97724556923
batch reward last col mean 4.0305593529410544e-07 first col mean 2.157457402063301e-06 all mean 7.326939339691307e-06
1.4809641470492352e-05 1.4809639651502948e-05
rl training, epoch3, iter0, batch242/1133, batch loss:1.4809639651502948e-05, Training time:53829.454107284546
batch reward last col mean 8.800167847766716e-07 first col mean 2.4996800220833393e-06 all mean 1.2878082998213358e-05
1.3895027223043144e-05 1.389503086102195e-05
rl training, epoch3, iter0, batch243/1133, batch loss:1.389503086102195e-05, Training time:53847.59030032158
batch reward last col mean 1.2975132221981767e-06 first col mean 1.27376988530159e-05 all mean 2.20605761569459e-05
1.636763226997573e-05 1.6367635907954536e-05
rl training, epoch3, iter0, batch244/1133, batch loss:1.6367635907954536e-05, Training time:53864.891302108765
batch reward last col mean 2.055091317743063e-05 first col mean 2.093527109536808e-05 all mean 4.2708124965429306e-05
0.0002236405707662925 0.00022364058531820774
rl training, epoch3, iter0, batch245/1133, batch loss:0.00022364058531820774, Training time:53882.29030251503
batch reward last col mean 1.9751143554458395e-05 first col mean 0.0012369205942377448 all mean 4.1562387195881456e-05
3.2220010325545445e-05 3.222001760150306e-05
rl training, epoch3, iter0, batch246/1133, batch loss:3.222001760150306e-05, Training time:53898.9015724659
batch reward last col mean 3.432752748722123e-07 first col mean 1.2955684724147432e-05 all mean 1.5338408047682606e-05
5.200268788030371e-05 5.200268788030371e-05
rl training, epoch3, iter0, batch247/1133, batch loss:5.200268788030371e-05, Training time:53915.892095804214
batch reward last col mean 2.3766797596636025e-07 first col mean 3.7317004171200097e-06 all mean 6.115441465226468e-06
1.2413158401614055e-05 1.2413157492119353e-05
rl training, epoch3, iter0, batch248/1133, batch loss:1.2413157492119353e-05, Training time:53932.56782460213
batch reward last col mean 5.934139721830434e-07 first col mean 2.411009518255014e-05 all mean 2.1385372747317888e-05
3.6839835956925526e-05 3.6839835956925526e-05
rl training, epoch3, iter0, batch249/1133, batch loss:3.6839835956925526e-05, Training time:53949.27822113037
batch reward last col mean 0.0034497722517699003 first col mean 4.123918643017532e-06 all mean 0.0031353593803942204
0.00020175008103251457 0.00020175008103251457
rl training, epoch3, iter0, batch250/1133, batch loss:0.00020175008103251457, Training time:53966.19580793381
batch reward last col mean 2.090323505399283e-05 first col mean 0.0001808565721148625 all mean 2.326456888113171e-05
6.102078623371199e-05 6.102078623371199e-05
rl training, epoch3, iter0, batch251/1133, batch loss:6.102078623371199e-05, Training time:53982.626057863235
batch reward last col mean 1.5334121883370244e-07 first col mean 3.64501538570039e-05 all mean 2.0074023268534802e-05
3.843720332952216e-05 3.843720332952216e-05
rl training, epoch3, iter0, batch252/1133, batch loss:3.843720332952216e-05, Training time:53999.103635549545
batch reward last col mean 1.537830307540844e-08 first col mean 3.080094757024199e-05 all mean 7.661778909096029e-06
1.970222183445003e-05 1.9702220015460625e-05
rl training, epoch3, iter0, batch253/1133, batch loss:1.9702220015460625e-05, Training time:54015.642426490784
batch reward last col mean 8.948408503783867e-05 first col mean 2.5494533474557102e-05 all mean 9.759389649843797e-05
2.427426807116717e-05 2.427426807116717e-05
rl training, epoch3, iter0, batch254/1133, batch loss:2.427426807116717e-05, Training time:54032.328966617584
batch reward last col mean 8.546805929654511e-08 first col mean 0.00284233083948493 all mean 4.7920719225658104e-05
0.00012753860210068524 0.00012753860210068524
rl training, epoch3, iter0, batch255/1133, batch loss:0.00012753860210068524, Training time:54048.78355073929
batch reward last col mean 3.4119653719244525e-05 first col mean 0.0002718646137509495 all mean 2.746527570707258e-05
5.090723425382748e-05 5.0907230615848675e-05
rl training, epoch3, iter0, batch256/1133, batch loss:5.0907230615848675e-05, Training time:54065.598237752914
batch reward last col mean 4.902259388472885e-05 first col mean 0.0013261389685794711 all mean 9.258583304472268e-05
4.2034091165987775e-05 4.203408752800897e-05
rl training, epoch3, iter0, batch257/1133, batch loss:4.203408752800897e-05, Training time:54085.10967206955
batch reward last col mean 1.8353229052081588e-06 first col mean 3.068164232900017e-06 all mean 2.533405859139748e-05
8.170974069798831e-06 8.170977707777638e-06
rl training, epoch3, iter0, batch258/1133, batch loss:8.170977707777638e-06, Training time:54102.193222761154
batch reward last col mean 8.01027454144787e-07 first col mean 8.246525794675108e-06 all mean 3.3949745557038113e-05
6.064432091079652e-05 6.064432091079652e-05
rl training, epoch3, iter0, batch259/1133, batch loss:6.064432091079652e-05, Training time:54119.34910988808
batch reward last col mean 0.0012860673014074564 first col mean 3.969063254771754e-05 all mean 0.001132903853431344
9.02639512787573e-05 9.026395855471492e-05
rl training, epoch3, iter0, batch260/1133, batch loss:9.026395855471492e-05, Training time:54136.97110366821
batch reward last col mean 9.850035667113843e-07 first col mean 4.0503524360246956e-05 all mean 1.160944430012023e-05
1.7257323634112254e-05 1.7257325453101657e-05
rl training, epoch3, iter0, batch261/1133, batch loss:1.7257325453101657e-05, Training time:54154.75908064842
batch reward last col mean 0.00046851197839714587 first col mean 0.00036426165024749935 all mean 0.0004418808384798467
8.803499804344028e-05 8.803499804344028e-05
rl training, epoch3, iter0, batch262/1133, batch loss:8.803499804344028e-05, Training time:54172.39602780342
batch reward last col mean 1.6994595171127003e-06 first col mean 1.166824063147942e-06 all mean 2.468195089022629e-05
9.825231973081827e-05 9.825231973081827e-05
rl training, epoch3, iter0, batch263/1133, batch loss:9.825231973081827e-05, Training time:54189.14736890793
batch reward last col mean 0.00023242257884703577 first col mean 1.7538832253194414e-05 all mean 8.213510227506049e-06
2.6457268177182414e-05 2.645726635819301e-05
rl training, epoch3, iter0, batch264/1133, batch loss:2.645726635819301e-05, Training time:54206.18580007553
batch reward last col mean 5.487434009410208e-07 first col mean 4.3650241423165426e-05 all mean 3.835583265754394e-05
3.683780596475117e-05 3.683780232677236e-05
rl training, epoch3, iter0, batch265/1133, batch loss:3.683780232677236e-05, Training time:54223.71036815643
batch reward last col mean 4.793777463873994e-08 first col mean 1.4861038835078944e-06 all mean 2.2603486286243424e-05
2.524269621062558e-05 2.5242701667593792e-05
rl training, epoch3, iter0, batch266/1133, batch loss:2.5242701667593792e-05, Training time:54241.13477373123
batch reward last col mean 1.861739207242863e-07 first col mean 3.9377468965540174e-06 all mean 1.0086408110510092e-05
7.746256596874446e-05 7.746256596874446e-05
rl training, epoch3, iter0, batch267/1133, batch loss:7.746256596874446e-05, Training time:54258.65499448776
batch reward last col mean 3.994615838109894e-07 first col mean 1.0899645985773532e-06 all mean 2.6048519430332817e-05
3.828277112916112e-05 3.828276749118231e-05
rl training, epoch3, iter0, batch268/1133, batch loss:3.828276749118231e-05, Training time:54276.51071214676
batch reward last col mean 2.4235785076598404e-06 first col mean 1.851578417699784e-05 all mean 5.193316246732138e-05
0.00015506570343859494 0.00015506571799051017
rl training, epoch3, iter0, batch269/1133, batch loss:0.00015506571799051017, Training time:54294.04591059685
batch reward last col mean 9.515755436950712e-07 first col mean 5.118622084410163e-06 all mean 6.400751772162039e-06
1.4047490367374849e-05 1.404749127686955e-05
rl training, epoch3, iter0, batch270/1133, batch loss:1.404749127686955e-05, Training time:54311.44344997406
batch reward last col mean 3.3262165288761025e-07 first col mean 1.8247317257191753e-06 all mean 1.9320817955303937e-05
1.8062959497910924e-05 1.8062961316900328e-05
rl training, epoch3, iter0, batch271/1133, batch loss:1.8062961316900328e-05, Training time:54327.8871512413
batch reward last col mean 1.7420617268726346e-06 first col mean 5.22696427651681e-06 all mean 3.32819799950812e-05
0.00017270157695747912 0.00017270157695747912
rl training, epoch3, iter0, batch272/1133, batch loss:0.00017270157695747912, Training time:54344.50659918785
batch reward last col mean 1.2082080047548516e-07 first col mean 1.31824867821706e-06 all mean 5.043413693783805e-05
0.00031844162731431425 0.00031844162731431425
rl training, epoch3, iter0, batch273/1133, batch loss:0.00031844162731431425, Training time:54361.15533399582
batch reward last col mean 1.3991137848279322e-06 first col mean 0.0017000328516587615 all mean 2.588636925793253e-05
1.9587849237723276e-05 1.958785105671268e-05
rl training, epoch3, iter0, batch274/1133, batch loss:1.958785105671268e-05, Training time:54377.91557049751
batch reward last col mean 5.059055183664896e-07 first col mean 5.626819074677769e-06 all mean 1.3233484423835762e-05
2.0668723664130084e-05 2.0668723664130084e-05
rl training, epoch3, iter0, batch275/1133, batch loss:2.0668723664130084e-05, Training time:54395.001287937164
batch reward last col mean 2.5807819383771857e-06 first col mean 0.0010619050590321422 all mean 2.7700418286258355e-05
3.482144165900536e-05 3.4821434383047745e-05
rl training, epoch3, iter0, batch276/1133, batch loss:3.4821434383047745e-05, Training time:54412.15274596214
batch reward last col mean 2.2707065454596886e-06 first col mean 1.2997854810237186e-06 all mean 1.7077727534342557e-05
7.67532765166834e-05 7.67532765166834e-05
rl training, epoch3, iter0, batch277/1133, batch loss:7.67532765166834e-05, Training time:54429.175329208374
batch reward last col mean 0.0005513067590072751 first col mean 8.524432814738248e-06 all mean 0.0004961577360518277
0.00016513782611582428 0.00016513779701199383
rl training, epoch3, iter0, batch278/1133, batch loss:0.00016513779701199383, Training time:54445.682394981384
batch reward last col mean 1.903120079305154e-07 first col mean 8.346805407200009e-05 all mean 1.6846310245455243e-05
1.849454019975383e-05 1.8494542018743232e-05
rl training, epoch3, iter0, batch279/1133, batch loss:1.8494542018743232e-05, Training time:54462.22314500809
batch reward last col mean 1.5717999701791996e-07 first col mean 0.00038491442683152854 all mean 3.796205419348553e-05
2.980082354042679e-05 2.980081808345858e-05
rl training, epoch3, iter0, batch280/1133, batch loss:2.980081808345858e-05, Training time:54478.89300465584
batch reward last col mean 3.664824177462833e-08 first col mean 7.589132565044565e-06 all mean 2.74462545348797e-05
6.374652002705261e-05 6.374652002705261e-05
rl training, epoch3, iter0, batch281/1133, batch loss:6.374652002705261e-05, Training time:54495.422244787216
batch reward last col mean 2.9751738566119457e-06 first col mean 9.514686638567582e-08 all mean 1.2241409422131255e-05
3.7081084883539006e-05 3.7081084883539006e-05
rl training, epoch3, iter0, batch282/1133, batch loss:3.7081084883539006e-05, Training time:54511.977236270905
batch reward last col mean 2.5678887141111773e-06 first col mean 7.851609211684263e-07 all mean 7.288516371772857e-06
8.869827070157044e-06 8.869827979651745e-06
rl training, epoch3, iter0, batch283/1133, batch loss:8.869827979651745e-06, Training time:54528.97911572456
batch reward last col mean 9.600226036354798e-08 first col mean 0.0006419135024771094 all mean 5.7846467825584114e-05
0.00013054849114269018 0.00013054846203885972
rl training, epoch3, iter0, batch284/1133, batch loss:0.00013054846203885972, Training time:54546.07806158066
batch reward last col mean 0.006185523699969053 first col mean 3.035003101103939e-05 all mean 0.005109814461320639
0.00040848832577466965 0.00040848832577466965
rl training, epoch3, iter0, batch285/1133, batch loss:0.00040848832577466965, Training time:54563.07367229462
batch reward last col mean 1.0992554280164768e-06 first col mean 1.387538304697955e-06 all mean 1.6316440451191738e-05
3.664942050818354e-05 3.664942050818354e-05
rl training, epoch3, iter0, batch286/1133, batch loss:3.664942050818354e-05, Training time:54580.92269563675
batch reward last col mean 2.488096470187884e-06 first col mean 3.3011488085321616e-06 all mean 2.8097205358790234e-05
9.113471605814993e-06 9.113473424804397e-06
rl training, epoch3, iter0, batch287/1133, batch loss:9.113473424804397e-06, Training time:54597.53286457062
batch reward last col mean 7.102054041752126e-06 first col mean 9.865225365501828e-06 all mean 1.3364387086767238e-05
1.3079968994134106e-05 1.3079967175144702e-05
rl training, epoch3, iter0, batch288/1133, batch loss:1.3079967175144702e-05, Training time:54613.979796886444
batch reward last col mean 1.5233341343900975e-07 first col mean 3.09754852878541e-07 all mean 8.097616955637932e-06
1.623345997359138e-05 1.6233458154601976e-05
rl training, epoch3, iter0, batch289/1133, batch loss:1.6233458154601976e-05, Training time:54630.85144305229
batch reward last col mean 7.231330414469994e-07 first col mean 1.5083454627529136e-06 all mean 3.310038664494641e-05
4.154154157731682e-05 4.154154157731682e-05
rl training, epoch3, iter0, batch290/1133, batch loss:4.154154157731682e-05, Training time:54647.38046121597
batch reward last col mean 1.304010623925933e-07 first col mean 8.683762644068338e-06 all mean 1.8512160750105977e-05
2.822921669576317e-05 2.8229220333741978e-05
rl training, epoch3, iter0, batch291/1133, batch loss:2.8229220333741978e-05, Training time:54664.1762547493
batch reward last col mean 8.631345593812512e-08 first col mean 4.432044443092309e-05 all mean 5.057960152043961e-05
0.00011219921725569293 0.0001121992027037777
rl training, epoch3, iter0, batch292/1133, batch loss:0.0001121992027037777, Training time:54680.68381810188
batch reward last col mean 1.4390464002644876e-06 first col mean 4.829976205655839e-06 all mean 4.194169014226645e-05
0.00010435782314743847 0.00010435781587148085
rl training, epoch3, iter0, batch293/1133, batch loss:0.00010435781587148085, Training time:54697.291373729706
batch reward last col mean 0.002191705396398902 first col mean 0.0005029492895118892 all mean 0.001960773952305317
0.00016115348262246698 0.00016115352627821267
rl training, epoch3, iter0, batch294/1133, batch loss:0.00016115352627821267, Training time:54713.85939049721
batch reward last col mean 8.053995770751499e-06 first col mean 0.0003722921246662736 all mean 2.2569223801838234e-05
5.424954724730924e-05 5.424954724730924e-05
rl training, epoch3, iter0, batch295/1133, batch loss:5.424954724730924e-05, Training time:54730.40884447098
batch reward last col mean 6.871980986034032e-06 first col mean 1.123329411711893e-06 all mean 3.1006085919216275e-05
0.0001507722627138719 0.00015077227726578712
rl training, epoch3, iter0, batch296/1133, batch loss:0.00015077227726578712, Training time:54747.08962106705
batch reward last col mean 1.0078365875187956e-07 first col mean 1.5309258571960527e-07 all mean 2.4013774236664176e-05
5.7964163715951145e-05 5.796416735392995e-05
rl training, epoch3, iter0, batch297/1133, batch loss:5.796416735392995e-05, Training time:54763.60458302498
batch reward last col mean 7.89823207014706e-06 first col mean 2.2272342903306708e-06 all mean 1.2512941793829668e-05
1.2711770978057757e-05 1.2711770978057757e-05
rl training, epoch3, iter0, batch298/1133, batch loss:1.2711770978057757e-05, Training time:54781.149741888046
batch reward last col mean 9.28156623558607e-06 first col mean 1.7797461623558775e-05 all mean 1.2650498319999315e-05
3.530278991092928e-05 3.530278627295047e-05
rl training, epoch3, iter0, batch299/1133, batch loss:3.530278627295047e-05, Training time:54797.83240032196
batch reward last col mean 3.3635128602327313e-06 first col mean 2.0292861790949246e-06 all mean 1.6955598766799085e-05
6.0289301472948864e-05 6.0289301472948864e-05
rl training, epoch3, iter0, batch300/1133, batch loss:6.0289301472948864e-05, Training time:54814.66943335533
batch reward last col mean 2.0837345005020325e-07 first col mean 0.0007766220951452851 all mean 2.2963104129303247e-05
3.8312784454319626e-05 3.8312784454319626e-05
rl training, epoch3, iter0, batch301/1133, batch loss:3.8312784454319626e-05, Training time:54834.06291913986
batch reward last col mean 3.2554464723943966e-07 first col mean 9.471852536080405e-06 all mean 1.0955692232528236e-05
5.0910919526359066e-05 5.0910919526359066e-05
rl training, epoch3, iter0, batch302/1133, batch loss:5.0910919526359066e-05, Training time:54852.339302778244
batch reward last col mean 5.028815621699323e-07 first col mean 4.228037653319916e-07 all mean 3.230109723517671e-05
0.0001333790278295055 0.0001333790278295055
rl training, epoch3, iter0, batch303/1133, batch loss:0.0001333790278295055, Training time:54870.287153959274
batch reward last col mean 4.4799236320614e-07 first col mean 0.0026041611563414335 all mean 4.9177833716385067e-05
5.07134354847949e-05 5.071345003671013e-05
rl training, epoch3, iter0, batch304/1133, batch loss:5.071345003671013e-05, Training time:54887.26536846161
batch reward last col mean 6.336183560051722e-07 first col mean 1.1206409453734523e-06 all mean 1.4439432561630383e-05
3.223226303816773e-05 3.223226667614654e-05
rl training, epoch3, iter0, batch305/1133, batch loss:3.223226667614654e-05, Training time:54905.19929289818
batch reward last col mean 8.573244514309408e-08 first col mean 6.616294285777258e-07 all mean 2.9647544579347596e-05
0.0001256711402675137 0.0001256711402675137
rl training, epoch3, iter0, batch306/1133, batch loss:0.0001256711402675137, Training time:54921.82414698601
batch reward last col mean 2.723854049690999e-05 first col mean 6.544822213072621e-07 all mean 2.9590926715172827e-05
4.594720667228103e-05 4.5947210310259834e-05
rl training, epoch3, iter0, batch307/1133, batch loss:4.5947210310259834e-05, Training time:54939.00378918648
batch reward last col mean 2.855717639249633e-06 first col mean 3.6122696656093467e-07 all mean 1.9962337319157086e-05
8.531894854968414e-05 8.531896310159937e-05
rl training, epoch3, iter0, batch308/1133, batch loss:8.531896310159937e-05, Training time:54955.80660867691
batch reward last col mean 8.06694970378885e-06 first col mean 0.0013741287402808666 all mean 3.001003096869681e-05
9.528779628453776e-06 9.528774171485566e-06
rl training, epoch3, iter0, batch309/1133, batch loss:9.528774171485566e-06, Training time:54972.68636965752
batch reward last col mean 9.942094038706273e-06 first col mean 0.0015469653299078345 all mean 4.642982457880862e-05
2.2014013666193932e-05 2.2014013666193932e-05
rl training, epoch3, iter0, batch310/1133, batch loss:2.2014013666193932e-05, Training time:54989.395951747894
batch reward last col mean 3.863987876684405e-05 first col mean 1.3582612155005336e-05 all mean 4.454724694369361e-05
5.974778832751326e-05 5.974778832751326e-05
rl training, epoch3, iter0, batch311/1133, batch loss:5.974778832751326e-05, Training time:55006.21601462364
batch reward last col mean 2.8750673664035276e-07 first col mean 0.0011883830884471536 all mean 5.683909694198519e-05
0.00023869250435382128 0.00023869250435382128
rl training, epoch3, iter0, batch312/1133, batch loss:0.00023869250435382128, Training time:55023.02355623245
batch reward last col mean 4.7487478127550276e-07 first col mean 5.9988597058691084e-05 all mean 2.353980380576104e-05
6.477379065472633e-05 6.477378337876871e-05
rl training, epoch3, iter0, batch313/1133, batch loss:6.477378337876871e-05, Training time:55040.16430187225
batch reward last col mean 0.00569527130573988 first col mean 0.0008300439803861082 all mean 0.005215367767959833
0.00041847440297715366 0.00041847440297715366
rl training, epoch3, iter0, batch314/1133, batch loss:0.00041847440297715366, Training time:55057.060425043106
batch reward last col mean 3.228821014999994e-07 first col mean 1.0569475307420362e-05 all mean 2.3834736566641368e-05
3.6634752177633345e-05 3.663474853965454e-05
rl training, epoch3, iter0, batch315/1133, batch loss:3.663474853965454e-05, Training time:55075.748629808426
batch reward last col mean 5.903078999835998e-06 first col mean 0.00033870237530209124 all mean 1.862051067291759e-05
0.00016445870278403163 0.00016445871733594686
rl training, epoch3, iter0, batch316/1133, batch loss:0.00016445871733594686, Training time:55094.045424222946
batch reward last col mean 1.519392469617742e-07 first col mean 0.0016320847207680345 all mean 5.0254773668712005e-05
3.974427454522811e-05 3.9744267269270495e-05
rl training, epoch3, iter0, batch317/1133, batch loss:3.9744267269270495e-05, Training time:55112.39868211746
batch reward last col mean 1.3816345926898066e-05 first col mean 2.566585180829861e-06 all mean 3.4340013371547684e-05
8.810181316221133e-05 8.810181316221133e-05
rl training, epoch3, iter0, batch318/1133, batch loss:8.810181316221133e-05, Training time:55131.080847501755
batch reward last col mean 6.017656346557487e-07 first col mean 1.8293518223799765e-05 all mean 3.542867489159107e-06
3.642573119577719e-06 3.6425728922040435e-06
rl training, epoch3, iter0, batch319/1133, batch loss:3.6425728922040435e-06, Training time:55149.35770010948
batch reward last col mean 1.147363093423337e-07 first col mean 1.4562961951014586e-05 all mean 2.9899880246375687e-05
0.0001766372297424823 0.0001766372297424823
rl training, epoch3, iter0, batch320/1133, batch loss:0.0001766372297424823, Training time:55166.80580282211
batch reward last col mean 6.211717845872045e-05 first col mean 6.126322114141658e-05 all mean 8.336277824128047e-05
5.589607826550491e-05 5.5896074627526104e-05
rl training, epoch3, iter0, batch321/1133, batch loss:5.5896074627526104e-05, Training time:55183.42778491974
batch reward last col mean 5.038762651565776e-07 first col mean 2.3677646368014393e-06 all mean 2.80889289570041e-05
0.00012030797370243818 0.0001203079882543534
rl training, epoch3, iter0, batch322/1133, batch loss:0.0001203079882543534, Training time:55200.08801603317
batch reward last col mean 2.301353134726014e-07 first col mean 1.2781338227796368e-05 all mean 3.3109333799075102e-06
5.4201791499508545e-06 5.420178695203504e-06
rl training, epoch3, iter0, batch323/1133, batch loss:5.420178695203504e-06, Training time:55217.11951351166
batch reward last col mean 1.3719353773922194e-05 first col mean 1.0997839581250446e-06 all mean 3.3681099012028426e-05
3.9563397876918316e-05 3.956339423893951e-05
rl training, epoch3, iter0, batch324/1133, batch loss:3.956339423893951e-05, Training time:55233.84848046303
batch reward last col mean 2.240657750007813e-06 first col mean 4.652978873309621e-07 all mean 3.3411466574762017e-05
0.000212822065805085 0.00021282209490891546
rl training, epoch3, iter0, batch325/1133, batch loss:0.00021282209490891546, Training time:55251.369556427
batch reward last col mean 2.2033955815459194e-07 first col mean 1.228404755693191e-07 all mean 1.6233427231782116e-05
5.951004823145922e-06 5.951005277893273e-06
rl training, epoch3, iter0, batch326/1133, batch loss:5.951005277893273e-06, Training time:55268.599806308746
batch reward last col mean 2.118553652508126e-07 first col mean 0.0001311780360992998 all mean 3.585430022212677e-05
3.497803845675662e-05 3.497805300867185e-05
rl training, epoch3, iter0, batch327/1133, batch loss:3.497805300867185e-05, Training time:55285.21004533768
batch reward last col mean 5.3962394304107875e-05 first col mean 1.6897216710276552e-06 all mean 8.427541615674272e-05
0.0003347182064317167 0.0003347182064317167
rl training, epoch3, iter0, batch328/1133, batch loss:0.0003347182064317167, Training time:55301.87622332573
batch reward last col mean 6.304085218289401e-06 first col mean 2.6976562139680027e-07 all mean 4.096297197975218e-05
8.042118133744225e-05 8.042118133744225e-05
rl training, epoch3, iter0, batch329/1133, batch loss:8.042118133744225e-05, Training time:55318.512151002884
batch reward last col mean 2.3465317156023957e-07 first col mean 1.4824659956502728e-05 all mean 2.6263498511980288e-05
5.134398179507116e-06 5.1343877203180455e-06
rl training, epoch3, iter0, batch330/1133, batch loss:5.1343877203180455e-06, Training time:55335.38859653473
batch reward last col mean 1.129334236793511e-06 first col mean 0.0008828114368952811 all mean 1.708750642137602e-05
2.883848901547026e-05 2.8838487196480855e-05
rl training, epoch3, iter0, batch331/1133, batch loss:2.8838487196480855e-05, Training time:55352.59416794777
batch reward last col mean 0.00015250449359882623 first col mean 6.851242505945265e-05 all mean 0.00016153123578988016
6.24970271019265e-05 6.249701255001128e-05
rl training, epoch3, iter0, batch332/1133, batch loss:6.249701255001128e-05, Training time:55369.0083489418
batch reward last col mean 2.9600334528367966e-05 first col mean 6.241823575692251e-05 all mean 1.117957344831666e-05
1.6475316442665644e-05 1.647531462367624e-05
rl training, epoch3, iter0, batch333/1133, batch loss:1.647531462367624e-05, Training time:55387.5700032711
batch reward last col mean 4.876092702943424e-07 first col mean 5.013817485632899e-07 all mean 1.7310198018094525e-05
2.8349357307888567e-05 2.834935912687797e-05
rl training, epoch3, iter0, batch334/1133, batch loss:2.834935912687797e-05, Training time:55405.03899693489
batch reward last col mean 6.51988472100129e-08 first col mean 4.675295713241212e-05 all mean 9.741538633534219e-06
5.2219013014109805e-05 5.2219013014109805e-05
rl training, epoch3, iter0, batch335/1133, batch loss:5.2219013014109805e-05, Training time:55424.48670363426
batch reward last col mean 2.4918622330005746e-06 first col mean 2.632085056575306e-07 all mean 3.53206523868721e-05
4.5736032916465774e-05 4.573602927848697e-05
rl training, epoch3, iter0, batch336/1133, batch loss:4.573602927848697e-05, Training time:55441.981917619705
batch reward last col mean 7.97316488387878e-07 first col mean 0.00012938311556354165 all mean 4.2333682358730584e-05
0.00010141716484213248 0.00010141715029021725
rl training, epoch3, iter0, batch337/1133, batch loss:0.00010141715029021725, Training time:55458.7062356472
batch reward last col mean 0.003142179921269417 first col mean 5.596388064077473e-07 all mean 0.0027113081887364388
0.00027268705889582634 0.0002726870297919959
rl training, epoch3, iter0, batch338/1133, batch loss:0.0002726870297919959, Training time:55475.59266734123
batch reward last col mean 7.145140261854976e-05 first col mean 2.1966724261801573e-07 all mean 7.861872290959582e-05
2.9616441679536365e-05 2.9616438041557558e-05
rl training, epoch3, iter0, batch339/1133, batch loss:2.9616438041557558e-05, Training time:55492.21331810951
batch reward last col mean 6.531870440085186e-07 first col mean 0.0006713601178489625 all mean 2.9683191314688884e-05
4.8909365432336926e-05 4.8909365432336926e-05
rl training, epoch3, iter0, batch340/1133, batch loss:4.8909365432336926e-05, Training time:55508.864995718
batch reward last col mean 0.0008171380613930523 first col mean 0.0003882903838530183 all mean 0.0006417336408048868
0.00010370987001806498 0.0001037098845699802
rl training, epoch3, iter0, batch341/1133, batch loss:0.0001037098845699802, Training time:55525.69816493988
batch reward last col mean 3.262337259002379e-06 first col mean 1.4749219872101094e-06 all mean 3.7500736652873456e-05
0.00016821913595777005 0.00016821913595777005
rl training, epoch3, iter0, batch342/1133, batch loss:0.00016821913595777005, Training time:55542.45523929596
batch reward last col mean 8.091149084066274e-08 first col mean 7.947455014800653e-05 all mean 1.35450427478645e-05
2.8102835130994208e-05 2.8102833312004805e-05
rl training, epoch3, iter0, batch343/1133, batch loss:2.8102833312004805e-05, Training time:55559.28935241699
batch reward last col mean 5.083387009108264e-07 first col mean 4.1756649693525105e-07 all mean 1.2633980986720417e-05
2.1887002731091343e-05 2.1887002731091343e-05
rl training, epoch3, iter0, batch344/1133, batch loss:2.1887002731091343e-05, Training time:55575.877784490585
batch reward last col mean 1.079503590517561e-06 first col mean 9.184731425193604e-06 all mean 3.468133945716545e-05
0.00011526333400979638 0.00011526334856171161
rl training, epoch3, iter0, batch345/1133, batch loss:0.00011526334856171161, Training time:55593.384591817856
batch reward last col mean 0.0001112596073653549 first col mean 8.617527782917023e-06 all mean 0.00012010079808533192
2.0242487153154798e-05 2.0242485334165394e-05
rl training, epoch3, iter0, batch346/1133, batch loss:2.0242485334165394e-05, Training time:55611.76323413849
batch reward last col mean 2.765126616566249e-08 first col mean 0.00010685057350201532 all mean 1.3357172065298073e-05
4.1233826777897775e-05 4.1233826777897775e-05
rl training, epoch3, iter0, batch347/1133, batch loss:4.1233826777897775e-05, Training time:55629.87061023712
batch reward last col mean 1.217922971363805e-07 first col mean 0.0013702790020033717 all mean 2.8043768907082267e-05
2.179156945203431e-05 2.1791573090013117e-05
rl training, epoch3, iter0, batch348/1133, batch loss:2.1791573090013117e-05, Training time:55648.71465563774
batch reward last col mean 0.007456708699464798 first col mean 4.843701049139781e-07 all mean 0.006103380583226681
0.0005051092011854053 0.0005051092593930662
rl training, epoch3, iter0, batch349/1133, batch loss:0.0005051092593930662, Training time:55667.25259804726
batch reward last col mean 5.273759597912431e-07 first col mean 4.566897132463055e-06 all mean 4.860480476054363e-05
0.00013569259317591786 0.00013569259317591786
rl training, epoch3, iter0, batch350/1133, batch loss:0.00013569259317591786, Training time:55685.02399396896
batch reward last col mean 1.884291805254179e-06 first col mean 0.0002675323630683124 all mean 4.5973967644385993e-05
0.00018647835531737655 0.00018647835531737655
rl training, epoch3, iter0, batch351/1133, batch loss:0.00018647835531737655, Training time:55701.66341519356
batch reward last col mean 1.407689325105821e-07 first col mean 1.1535597650436102e-06 all mean 3.257735079387203e-05
9.036729898070917e-05 9.036729898070917e-05
rl training, epoch3, iter0, batch352/1133, batch loss:9.036729898070917e-05, Training time:55718.3823120594
batch reward last col mean 7.896965712461679e-07 first col mean 0.00040567078394815326 all mean 9.125184442382306e-05
0.00020879815565422177 0.00020879815565422177
rl training, epoch3, iter0, batch353/1133, batch loss:0.00020879815565422177, Training time:55735.0501139164
batch reward last col mean 8.583261035255418e-08 first col mean 4.0840882320480887e-07 all mean 4.527175860857824e-06
5.851961759617552e-06 5.85196085012285e-06
rl training, epoch3, iter0, batch354/1133, batch loss:5.85196085012285e-06, Training time:55751.900141716
batch reward last col mean 0.0005643719341605902 first col mean 9.427205327483534e-07 all mean 0.0005253861309029162
4.569154043565504e-05 4.569154043565504e-05
rl training, epoch3, iter0, batch355/1133, batch loss:4.569154043565504e-05, Training time:55768.882899045944
batch reward last col mean 4.578215140327302e-08 first col mean 6.1336581893556286e-06 all mean 1.0816399480972905e-05
2.126672916347161e-05 2.1266732801450416e-05
rl training, epoch3, iter0, batch356/1133, batch loss:2.1266732801450416e-05, Training time:55785.56195187569
batch reward last col mean 1.135413367592264e-05 first col mean 9.627530744182877e-06 all mean 5.259869431029074e-05
0.00011427279241615906 0.00011427279241615906
rl training, epoch3, iter0, batch357/1133, batch loss:0.00011427279241615906, Training time:55802.3349840641
batch reward last col mean 1.4857785402000445e-07 first col mean 1.7608284906600602e-05 all mean 1.113608232117258e-05
2.21252648771042e-05 2.2125263058114797e-05
rl training, epoch3, iter0, batch358/1133, batch loss:2.2125263058114797e-05, Training time:55818.83990049362
batch reward last col mean 4.985113264410757e-07 first col mean 5.408749075286323e-07 all mean 3.026056037924718e-05
7.009301043581218e-05 7.009300315985456e-05
rl training, epoch3, iter0, batch359/1133, batch loss:7.009300315985456e-05, Training time:55836.40324163437
batch reward last col mean 2.0285126467456394e-08 first col mean 2.675299401744269e-05 all mean 1.9592178432503715e-05
0.00011884135165018961 0.00011884135165018961
rl training, epoch3, iter0, batch360/1133, batch loss:0.00011884135165018961, Training time:55854.6657640934
batch reward last col mean 2.0583336208801484e-06 first col mean 1.9860226529999636e-05 all mean 3.286145511083305e-05
0.00017947702144738287 0.0001794769923435524
rl training, epoch3, iter0, batch361/1133, batch loss:0.0001794769923435524, Training time:55872.38219213486
batch reward last col mean 2.935573775175726e-07 first col mean 0.0014748189132660627 all mean 4.1656967368908226e-05
5.0244467274751514e-05 5.0244467274751514e-05
rl training, epoch3, iter0, batch362/1133, batch loss:5.0244467274751514e-05, Training time:55892.34129881859
batch reward last col mean 1.0184109669353347e-05 first col mean 1.5339018943905103e-07 all mean 5.3022227803012356e-05
0.00017601187573745847 0.00017601187573745847
rl training, epoch3, iter0, batch363/1133, batch loss:0.00017601187573745847, Training time:55911.54735374451
batch reward last col mean 5.7290731092507485e-06 first col mean 9.66626544141036e-07 all mean 1.815249015635345e-05
2.4987137294374406e-05 2.4987137294374406e-05
rl training, epoch3, iter0, batch364/1133, batch loss:2.4987137294374406e-05, Training time:55928.50156021118
batch reward last col mean 0.00026176730170845985 first col mean 3.7698487176385242e-06 all mean 0.00025405679480172694
5.16075779160019e-05 5.16075779160019e-05
rl training, epoch3, iter0, batch365/1133, batch loss:5.16075779160019e-05, Training time:55945.34699010849
batch reward last col mean 2.7298318627799745e-07 first col mean 7.885878261504331e-08 all mean 6.352708169288235e-06
1.982911089726258e-05 1.982911089726258e-05
rl training, epoch3, iter0, batch366/1133, batch loss:1.982911089726258e-05, Training time:55961.73920893669
batch reward last col mean 4.938373194818269e-07 first col mean 7.6149290180183016e-06 all mean 1.8178632672061212e-05
1.6203468476305716e-05 1.6203466657316312e-05
rl training, epoch3, iter0, batch367/1133, batch loss:1.6203466657316312e-05, Training time:55978.15547323227
batch reward last col mean 6.720930514347856e-07 first col mean 1.3875193189960555e-06 all mean 2.1818697859998792e-05
9.87370585789904e-05 9.87370585789904e-05
rl training, epoch3, iter0, batch368/1133, batch loss:9.87370585789904e-05, Training time:55994.672045469284
batch reward last col mean 0.002005444373935461 first col mean 1.4100006637818296e-06 all mean 0.001635778695344925
0.0001587469014339149 0.00015874688688199967
rl training, epoch3, iter0, batch369/1133, batch loss:0.00015874688688199967, Training time:56011.395916461945
batch reward last col mean 6.727206880441372e-08 first col mean 3.1433653475687606e-06 all mean 1.9582497770898044e-05
1.7081445548683405e-05 1.7081441910704598e-05
rl training, epoch3, iter0, batch370/1133, batch loss:1.7081441910704598e-05, Training time:56027.88442969322
batch reward last col mean 1.2633000551431905e-05 first col mean 0.0023549573961645365 all mean 3.976680454798043e-05
2.495404078217689e-05 2.495403532520868e-05
rl training, epoch3, iter0, batch371/1133, batch loss:2.495403532520868e-05, Training time:56044.48437857628
batch reward last col mean 9.088026854442433e-05 first col mean 2.77374533652619e-06 all mean 1.020216859615175e-05
4.134482151130214e-05 4.134482514928095e-05
rl training, epoch3, iter0, batch372/1133, batch loss:4.134482514928095e-05, Training time:56061.01043057442
batch reward last col mean 4.7395326419064077e-07 first col mean 2.415883500361815e-06 all mean 2.660352038219571e-05
3.223435487598181e-05 3.223435487598181e-05
rl training, epoch3, iter0, batch373/1133, batch loss:3.223435487598181e-05, Training time:56077.70018029213
batch reward last col mean 6.343235554595594e-07 first col mean 0.00038090674206614494 all mean 7.858790922909975e-05
0.0003319754032418132 0.00033197543234564364
rl training, epoch3, iter0, batch374/1133, batch loss:0.00033197543234564364, Training time:56094.24790906906
batch reward last col mean 2.122381488334213e-07 first col mean 2.3955683445819886e-06 all mean 4.07600928156171e-05
0.00010306535114068538 0.00010306535114068538
rl training, epoch3, iter0, batch375/1133, batch loss:0.00010306535114068538, Training time:56111.05006480217
batch reward last col mean 1.4268802317474183e-07 first col mean 0.000201458198716864 all mean 7.967882265802473e-05
0.00029669280047528446 0.000296692771371454
rl training, epoch3, iter0, batch376/1133, batch loss:0.000296692771371454, Training time:56128.60276055336
batch reward last col mean 0.000512358732521534 first col mean 3.5635392237054475e-07 all mean 9.75753428065218e-05
0.00012208332191221416 0.00012208332191221416
rl training, epoch3, iter0, batch377/1133, batch loss:0.00012208332191221416, Training time:56147.33456683159
batch reward last col mean 5.966806497781363e-07 first col mean 5.1099807024002075e-05 all mean 2.45364208240062e-05
0.00011659654410323128 0.00011659654410323128
rl training, epoch3, iter0, batch378/1133, batch loss:0.00011659654410323128, Training time:56164.73558855057
batch reward last col mean 6.571289304702077e-06 first col mean 2.1924108750681626e-07 all mean 1.5032373084977735e-05
1.2590914593602065e-05 1.259091186511796e-05
rl training, epoch3, iter0, batch379/1133, batch loss:1.259091186511796e-05, Training time:56182.86616373062
batch reward last col mean 5.139127168263258e-08 first col mean 1.5706558770034462e-05 all mean 6.943377229617909e-06
1.6637141015962698e-05 1.6637141015962698e-05
rl training, epoch3, iter0, batch380/1133, batch loss:1.6637141015962698e-05, Training time:56200.39707827568
batch reward last col mean 5.527342850086825e-08 first col mean 0.0009877753909677267 all mean 1.3509019481716678e-05
2.225891876150854e-05 2.2258916942519136e-05
rl training, epoch3, iter0, batch381/1133, batch loss:2.2258916942519136e-05, Training time:56218.234892606735
batch reward last col mean 1.0246161764371209e-05 first col mean 2.688080712687224e-06 all mean 2.7166184736415744e-05
6.718507938785478e-05 6.718507938785478e-05
rl training, epoch3, iter0, batch382/1133, batch loss:6.718507938785478e-05, Training time:56235.18008565903
batch reward last col mean 6.51081427349709e-05 first col mean 2.764945520539186e-06 all mean 7.473114965250716e-05
0.0001529838627902791 0.0001529838627902791
rl training, epoch3, iter0, batch383/1133, batch loss:0.0001529838627902791, Training time:56251.55735707283
batch reward last col mean 2.804805205869343e-07 first col mean 3.0310845886560855e-06 all mean 4.230300419294508e-06
1.6986061382340267e-05 1.6986061382340267e-05
rl training, epoch3, iter0, batch384/1133, batch loss:1.6986061382340267e-05, Training time:56268.39308452606
batch reward last col mean 9.142082490143366e-06 first col mean 4.453610472410219e-06 all mean 2.703080463106744e-05
6.371884956024587e-05 6.371885683620349e-05
rl training, epoch3, iter0, batch385/1133, batch loss:6.371885683620349e-05, Training time:56285.201982975006
batch reward last col mean 0.0026423593517392874 first col mean 1.8654498035175493e-07 all mean 0.00236709788441658
0.00021835853112861514 0.00021835853112861514
rl training, epoch3, iter0, batch386/1133, batch loss:0.00021835853112861514, Training time:56302.04812002182
batch reward last col mean 1.9754736513277749e-07 first col mean 2.783738466405339e-07 all mean 2.0471063180593774e-05
0.00013547677372116596 0.00013547677372116596
rl training, epoch3, iter0, batch387/1133, batch loss:0.00013547677372116596, Training time:56319.21822333336
batch reward last col mean 0.0008465650025755167 first col mean 8.6204399849521e-06 all mean 0.000812613929156214
0.0002072748902719468 0.00020727486116811633
rl training, epoch3, iter0, batch388/1133, batch loss:0.00020727486116811633, Training time:56336.18649435043
batch reward last col mean 1.9012004770502244e-07 first col mean 2.1654213924193755e-06 all mean 4.757344504469074e-05
0.00015654914022888988 0.0001565491547808051
rl training, epoch3, iter0, batch389/1133, batch loss:0.0001565491547808051, Training time:56353.08829212189
batch reward last col mean 1.1650047781586181e-05 first col mean 6.12028543400811e-07 all mean 2.0609992134268396e-05
3.308037776150741e-05 3.308037776150741e-05
rl training, epoch3, iter0, batch390/1133, batch loss:3.308037776150741e-05, Training time:56370.20971989632
batch reward last col mean 7.144620894905529e-07 first col mean 2.692707425921981e-07 all mean 3.3337353670503944e-05
3.910510349669494e-05 3.910509985871613e-05
rl training, epoch3, iter0, batch391/1133, batch loss:3.910509985871613e-05, Training time:56386.730488061905
batch reward last col mean 1.1681947853503516e-07 first col mean 5.503374995896593e-05 all mean 8.99977112567285e-06
8.951869858719874e-06 8.951869858719874e-06
rl training, epoch3, iter0, batch392/1133, batch loss:8.951869858719874e-06, Training time:56403.919674396515
batch reward last col mean 2.8866949719486e-07 first col mean 0.000922387873288244 all mean 2.476789813954383e-05
3.328419188619591e-05 3.328419188619591e-05
rl training, epoch3, iter0, batch393/1133, batch loss:3.328419188619591e-05, Training time:56422.431460142136
batch reward last col mean 3.9324354474956635e-06 first col mean 6.002640589031216e-07 all mean 5.092045830679126e-05
0.0001579883974045515 0.0001579883974045515
rl training, epoch3, iter0, batch394/1133, batch loss:0.0001579883974045515, Training time:56441.47917032242
batch reward last col mean 0.0064576249569654465 first col mean 0.000157749600475654 all mean 0.005970544181764126
0.0005142928566783667 0.0005142929148860276
rl training, epoch3, iter0, batch395/1133, batch loss:0.0005142929148860276, Training time:56460.353011608124
batch reward last col mean 5.0041693612001836e-05 first col mean 0.0015945822233334184 all mean 3.156892489641905e-05
4.972423266735859e-05 4.972422539140098e-05
rl training, epoch3, iter0, batch396/1133, batch loss:4.972422539140098e-05, Training time:56479.20279669762
batch reward last col mean 5.762433943345968e-07 first col mean 4.4660620915237814e-05 all mean 7.589876986457966e-06
1.2226556464156602e-05 1.2226556464156602e-05
rl training, epoch3, iter0, batch397/1133, batch loss:1.2226556464156602e-05, Training time:56496.957979917526
batch reward last col mean 2.3191569198388606e-07 first col mean 2.2141587407986663e-07 all mean 1.3039847544860095e-05
4.98817753395997e-05 4.9881778977578506e-05
rl training, epoch3, iter0, batch398/1133, batch loss:4.9881778977578506e-05, Training time:56513.69080162048
batch reward last col mean 6.992723911025678e-08 first col mean 4.801916657015681e-05 all mean 1.2816901289625093e-05
4.06132749048993e-05 4.06132749048993e-05
rl training, epoch3, iter0, batch399/1133, batch loss:4.06132749048993e-05, Training time:56530.31798243523
batch reward last col mean 2.5766104272406665e-07 first col mean 3.1116550758270023e-07 all mean 2.4247579858638346e-05
4.39197538071312e-05 4.39197538071312e-05
rl training, epoch3, iter0, batch400/1133, batch loss:4.39197538071312e-05, Training time:56547.11942052841
batch reward last col mean 7.02603770719179e-08 first col mean 0.001181822270154953 all mean 6.976796430535614e-05
0.00014288457168731838 0.00014288457168731838
rl training, epoch3, iter0, batch401/1133, batch loss:0.00014288457168731838, Training time:56564.01171898842
batch reward last col mean 0.0027568386867642403 first col mean 0.0001506609405623749 all mean 0.0009552794508635998
0.0002575899998191744 0.00025759002892300487
rl training, epoch3, iter0, batch402/1133, batch loss:0.00025759002892300487, Training time:56580.75813150406
batch reward last col mean 0.0042719594202935696 first col mean 6.791357236579643e-07 all mean 0.003993488382548094
0.00023220438743010163 0.0002322043728781864
rl training, epoch3, iter0, batch403/1133, batch loss:0.0002322043728781864, Training time:56597.390696525574
batch reward last col mean 3.587862096310346e-08 first col mean 1.3060416677035391e-06 all mean 2.6395067834528163e-05
4.835822983295657e-05 4.835822983295657e-05
rl training, epoch3, iter0, batch404/1133, batch loss:4.835822983295657e-05, Training time:56614.06041765213
batch reward last col mean 2.9465729767252924e-07 first col mean 4.905907644570107e-06 all mean 3.868712519761175e-05
8.195713598979637e-05 8.19571505417116e-05
rl training, epoch3, iter0, batch405/1133, batch loss:8.19571505417116e-05, Training time:56630.6176712513
batch reward last col mean 4.270897591140965e-08 first col mean 3.028007995453663e-07 all mean 1.0642107554303948e-05
3.670894875540398e-05 3.670894875540398e-05
rl training, epoch3, iter0, batch406/1133, batch loss:3.670894875540398e-05, Training time:56647.82342672348
batch reward last col mean 0.0009362136479467154 first col mean 3.04219565805397e-06 all mean 0.00010051173012470827
0.00015730931772850454 0.0001573093031765893
rl training, epoch3, iter0, batch407/1133, batch loss:0.0001573093031765893, Training time:56664.316821336746
batch reward last col mean 1.5207852811727207e-05 first col mean 0.0001627191377338022 all mean 2.5321503926534206e-05
3.6552632082020864e-05 3.6552632082020864e-05
rl training, epoch3, iter0, batch408/1133, batch loss:3.6552632082020864e-05, Training time:56681.98938322067
batch reward last col mean 4.7423611704289215e-08 first col mean 1.5095075468707364e-05 all mean 3.232852031942457e-05
0.00011545229790499434 0.00011545229790499434
rl training, epoch3, iter0, batch409/1133, batch loss:0.00011545229790499434, Training time:56700.14665722847
batch reward last col mean 1.0509464942742852e-07 first col mean 8.09066023066407e-06 all mean 4.042068394483067e-05
0.00018675487081054598 0.00018675485625863075
rl training, epoch3, iter0, batch410/1133, batch loss:0.00018675485625863075, Training time:56719.73003458977
batch reward last col mean 1.038881265458258e-07 first col mean 3.431301229284145e-05 all mean 2.34128692682134e-05
6.435044633690268e-05 6.43504608888179e-05
rl training, epoch3, iter0, batch411/1133, batch loss:6.43504608888179e-05, Training time:56737.67112469673
batch reward last col mean 7.87314434091968e-07 first col mean 0.00033865042496472597 all mean 1.0526513506192714e-05
1.8521297533879988e-05 1.8521297533879988e-05
rl training, epoch3, iter0, batch412/1133, batch loss:1.8521297533879988e-05, Training time:56756.788242816925
batch reward last col mean 1.8193309188063722e-06 first col mean 1.2639621900234488e-06 all mean 6.167291576275602e-05
0.00030045161838643253 0.000300451647490263
rl training, epoch3, iter0, batch413/1133, batch loss:0.000300451647490263, Training time:56773.8912858963
batch reward last col mean 1.4046051546756644e-05 first col mean 3.0078886993578635e-05 all mean 2.763311204034835e-05
3.890097650582902e-05 3.890097650582902e-05
rl training, epoch3, iter0, batch414/1133, batch loss:3.890097650582902e-05, Training time:56790.44530081749
batch reward last col mean 1.9339977370691486e-06 first col mean 7.669173669455631e-07 all mean 6.305515398707939e-06
9.746417163114529e-06 9.746417163114529e-06
rl training, epoch3, iter0, batch415/1133, batch loss:9.746417163114529e-06, Training time:56807.316291093826
batch reward last col mean 1.2868210319538775e-07 first col mean 1.4191800801199861e-05 all mean 3.6067580367671326e-05
4.8321842768928036e-05 4.8321842768928036e-05
rl training, epoch3, iter0, batch416/1133, batch loss:4.8321842768928036e-05, Training time:56823.9670021534
batch reward last col mean 0.0028324455488473177 first col mean 6.530073619614996e-07 all mean 0.0026043280959129333
0.0004796207358594984 0.0004796207358594984
rl training, epoch3, iter0, batch417/1133, batch loss:0.0004796207358594984, Training time:56840.870675325394
batch reward last col mean 1.7980673305828532e-07 first col mean 3.812814156844979e-06 all mean 1.6186953871510923e-05
2.1076300981803797e-05 2.1076304619782604e-05
rl training, epoch3, iter0, batch418/1133, batch loss:2.1076304619782604e-05, Training time:56857.442835092545
batch reward last col mean 2.5074725726881297e-06 first col mean 0.0017834441969171166 all mean 6.071091047488153e-05
7.154577906476334e-05 7.154579361667857e-05
rl training, epoch3, iter0, batch419/1133, batch loss:7.154579361667857e-05, Training time:56873.894013643265
batch reward last col mean 2.1005398593842983e-06 first col mean 2.54777060035849e-05 all mean 6.190340354805812e-05
0.00021651489078067243 0.00021651490533258766
rl training, epoch3, iter0, batch420/1133, batch loss:0.00021651490533258766, Training time:56890.474105358124
batch reward last col mean 6.428780352507601e-07 first col mean 5.9143071666767355e-06 all mean 3.322512566228397e-05
0.00011311580601613969 0.00011311580601613969
rl training, epoch3, iter0, batch421/1133, batch loss:0.00011311580601613969, Training time:56906.98805975914
batch reward last col mean 1.6646472431602888e-05 first col mean 1.139015057560755e-05 all mean 5.099990085000172e-05
9.134606807492673e-05 9.13460535230115e-05
rl training, epoch3, iter0, batch422/1133, batch loss:9.13460535230115e-05, Training time:56923.662904024124
batch reward last col mean 3.7375104966486106e-06 first col mean 0.0011775679886341095 all mean 2.8122423827880993e-05
5.112385770189576e-05 5.112385406391695e-05
rl training, epoch3, iter0, batch423/1133, batch loss:5.112385406391695e-05, Training time:56940.32097053528
batch reward last col mean 6.73486283631064e-06 first col mean 0.00014947786985430866 all mean 3.988324533565901e-05
0.00015462965529877692 0.00015462965529877692
rl training, epoch3, iter0, batch424/1133, batch loss:0.00015462965529877692, Training time:56956.711886405945
batch reward last col mean 8.5938253846507e-08 first col mean 0.00020686724747065455 all mean 7.80640675657196e-06
1.1458656445029192e-05 1.1458656445029192e-05
rl training, epoch3, iter0, batch425/1133, batch loss:1.1458656445029192e-05, Training time:56975.47803759575
batch reward last col mean 0.000450294726761058 first col mean 2.299942025274504e-06 all mean 0.0004665211890824139
5.230671740719117e-05 5.230671740719117e-05
rl training, epoch3, iter0, batch426/1133, batch loss:5.230671740719117e-05, Training time:56994.290546655655
batch reward last col mean 4.351408733782591e-06 first col mean 0.00030802737455815077 all mean 1.629283906368073e-05
2.138653326255735e-05 2.138653326255735e-05
rl training, epoch3, iter0, batch427/1133, batch loss:2.138653326255735e-05, Training time:57013.42364239693
batch reward last col mean 4.6211494009185117e-07 first col mean 4.675064246839611e-06 all mean 1.7487698642071337e-05
5.808103742310777e-05 5.808103014715016e-05
rl training, epoch3, iter0, batch428/1133, batch loss:5.808103014715016e-05, Training time:57032.35575938225
batch reward last col mean 1.0474687428541074e-07 first col mean 0.00018620371702127159 all mean 2.5520035705994815e-05
9.491468517808244e-05 9.491468517808244e-05
rl training, epoch3, iter0, batch429/1133, batch loss:9.491468517808244e-05, Training time:57049.70886874199
batch reward last col mean 5.811309051750868e-07 first col mean 6.988230779825244e-06 all mean 1.5519381122430786e-05
6.119286990724504e-05 6.119286990724504e-05
rl training, epoch3, iter0, batch430/1133, batch loss:6.119286990724504e-05, Training time:57066.59760975838
batch reward last col mean 5.3246378229232505e-05 first col mean 1.2468285603972618e-07 all mean 8.803534728940576e-05
0.0002150165819330141 0.00021501656738109887
rl training, epoch3, iter0, batch431/1133, batch loss:0.00021501656738109887, Training time:57083.240273952484
batch reward last col mean 0.00011393905151635408 first col mean 2.368893547100015e-05 all mean 0.00014251402171794325
6.997353193582967e-05 6.997353921178728e-05
rl training, epoch3, iter0, batch432/1133, batch loss:6.997353921178728e-05, Training time:57099.8214404583
batch reward last col mean 1.2769574823323637e-05 first col mean 5.13203531227191e-07 all mean 6.705545820295811e-05
4.153596455580555e-05 4.153596091782674e-05
rl training, epoch3, iter0, batch433/1133, batch loss:4.153596091782674e-05, Training time:57116.66756916046
batch reward last col mean 3.7521112972171977e-06 first col mean 3.7258467955325614e-07 all mean 1.2914612852910068e-05
1.95499524124898e-05 1.9549950593500398e-05
rl training, epoch3, iter0, batch434/1133, batch loss:1.9549950593500398e-05, Training time:57133.293643713
batch reward last col mean 0.0005217313300818205 first col mean 8.33515059639467e-06 all mean 0.0005741522181779146
0.00024612294510006905 0.00024612294510006905
rl training, epoch3, iter0, batch435/1133, batch loss:0.00024612294510006905, Training time:57149.87712430954
batch reward last col mean 1.0045987153262104e-07 first col mean 2.3367974790744483e-05 all mean 3.759134779102169e-05
6.922440661583096e-05 6.922441389178857e-05
rl training, epoch3, iter0, batch436/1133, batch loss:6.922441389178857e-05, Training time:57166.79788684845
batch reward last col mean 0.0020166924223303795 first col mean 9.981018820326426e-07 all mean 0.00041068726568482816
0.00018043332966044545 0.00018043331510853022
rl training, epoch3, iter0, batch437/1133, batch loss:0.00018043331510853022, Training time:57183.44401717186
batch reward last col mean 0.0013848354574292898 first col mean 0.00011037504737032577 all mean 0.0012724390253424644
0.00012204761878820136 0.00012204761878820136
rl training, epoch3, iter0, batch438/1133, batch loss:0.00012204761878820136, Training time:57199.90977549553
batch reward last col mean 3.095798462027233e-08 first col mean 6.798220056225546e-06 all mean 1.6840884200064465e-05
4.608472954714671e-05 4.6084733185125515e-05
rl training, epoch3, iter0, batch439/1133, batch loss:4.6084733185125515e-05, Training time:57216.74511551857
batch reward last col mean 2.1955197837542073e-07 first col mean 0.001723101595416665 all mean 4.6585242671426386e-05
0.00015863483713474125 0.00015863483713474125
rl training, epoch3, iter0, batch440/1133, batch loss:0.00015863483713474125, Training time:57234.23821115494
batch reward last col mean 7.088098209351301e-05 first col mean 5.5657801567576826e-06 all mean 0.00013681803829967976
0.0001901874493341893 0.0001901874493341893
rl training, epoch3, iter0, batch441/1133, batch loss:0.0001901874493341893, Training time:57251.51527929306
batch reward last col mean 2.884771220124094e-06 first col mean 2.54832457358134e-06 all mean 2.1128398657310754e-05
0.00010524232493480667 0.00010524231038289145
rl training, epoch3, iter0, batch442/1133, batch loss:0.00010524231038289145, Training time:57271.180902957916
batch reward last col mean 1.0740551488197525e-06 first col mean 2.950489943032153e-06 all mean 2.577589293650817e-05
0.0001270740176551044 0.00012707400310318917
rl training, epoch3, iter0, batch443/1133, batch loss:0.00012707400310318917, Training time:57288.40422105789
batch reward last col mean 1.974426777451299e-05 first col mean 0.0006569168181158602 all mean 2.598570608824957e-05
2.568586751294788e-05 2.5685871150926687e-05
rl training, epoch3, iter0, batch444/1133, batch loss:2.5685871150926687e-05, Training time:57305.3825879097
batch reward last col mean 0.004606707952916622 first col mean 0.00041069075814448297 all mean 0.004275974817574024
0.0006088604568503797 0.0006088604568503797
rl training, epoch3, iter0, batch445/1133, batch loss:0.0006088604568503797, Training time:57322.97530555725
batch reward last col mean 4.0491144659426936e-07 first col mean 0.001069720950908959 all mean 3.137762178084813e-05
0.00013604573905467987 0.0001360457536065951
rl training, epoch3, iter0, batch446/1133, batch loss:0.0001360457536065951, Training time:57339.481982946396
batch reward last col mean 9.339965458821098e-07 first col mean 0.00033904044539667666 all mean 4.871035707765259e-05
0.00012032021913910285 0.00012032019731123
rl training, epoch3, iter0, batch447/1133, batch loss:0.00012032019731123, Training time:57356.245020866394
batch reward last col mean 0.0002876014623325318 first col mean 6.6587235778570175e-06 all mean 0.00029852380976080894
0.00011398456990718842 0.00011398459173506126
rl training, epoch3, iter0, batch448/1133, batch loss:0.00011398459173506126, Training time:57372.71047258377
batch reward last col mean 4.1938626793580625e-08 first col mean 0.001166564761660993 all mean 3.624886448960751e-05
8.862185495672747e-05 8.862185495672747e-05
rl training, epoch3, iter0, batch449/1133, batch loss:8.862185495672747e-05, Training time:57389.286803007126
batch reward last col mean 6.17731188867765e-07 first col mean 0.00016424436762463301 all mean 2.352806768612936e-05
8.522964344592765e-05 8.522964344592765e-05
rl training, epoch3, iter0, batch450/1133, batch loss:8.522964344592765e-05, Training time:57405.744240283966
batch reward last col mean 1.847231760621071e-05 first col mean 8.390063158003613e-05 all mean 2.4914877940318547e-05
7.363248732872307e-05 7.363248732872307e-05
rl training, epoch3, iter0, batch451/1133, batch loss:7.363248732872307e-05, Training time:57423.00163149834
batch reward last col mean 1.8934410945803393e-06 first col mean 0.0011006394634023309 all mean 3.346717858221382e-05
1.5270288713509217e-05 1.527028507553041e-05
rl training, epoch3, iter0, batch452/1133, batch loss:1.527028507553041e-05, Training time:57440.13936042786
batch reward last col mean 5.739481821365189e-06 first col mean 0.0006619589985348284 all mean 2.3071437681210227e-05
3.8186455640243366e-05 3.8186455640243366e-05
rl training, epoch3, iter0, batch453/1133, batch loss:3.8186455640243366e-05, Training time:57457.838129282
batch reward last col mean 1.4153272331896005e-06 first col mean 8.435638392256806e-07 all mean 2.383600440225564e-05
2.8104204830015078e-05 2.8104199373046868e-05
rl training, epoch3, iter0, batch454/1133, batch loss:2.8104199373046868e-05, Training time:57476.138617515564
batch reward last col mean 1.5116183931240812e-05 first col mean 3.9304752135649323e-05 all mean 4.02678779209964e-05
0.0001244133454747498 0.0001244133454747498
rl training, epoch3, iter0, batch455/1133, batch loss:0.0001244133454747498, Training time:57494.21868848801
batch reward last col mean 3.1097752071218565e-05 first col mean 0.0011299399193376303 all mean 1.9814491679426283e-05
1.5265915862983093e-05 1.5265921319951303e-05
rl training, epoch3, iter0, batch456/1133, batch loss:1.5265921319951303e-05, Training time:57510.721890449524
batch reward last col mean 0.00621411669999361 first col mean 0.0005692403065040708 all mean 0.0030506697949022055
0.0004644538857974112 0.0004644538857974112
rl training, epoch3, iter0, batch457/1133, batch loss:0.0004644538857974112, Training time:57527.344284534454
batch reward last col mean 8.557054570701439e-06 first col mean 0.00012148898531449959 all mean 1.5781575712026097e-05
2.7576530555961654e-05 2.7576530555961654e-05
rl training, epoch3, iter0, batch458/1133, batch loss:2.7576530555961654e-05, Training time:57543.97421526909
batch reward last col mean 0.006523209158331156 first col mean 0.0001225278538186103 all mean 0.006027986295521259
0.0005027480656281114 0.0005027480074204504
rl training, epoch3, iter0, batch459/1133, batch loss:0.0005027480074204504, Training time:57560.563152074814
batch reward last col mean 2.2968029043113347e-06 first col mean 2.638917248987127e-05 all mean 1.4387210285349283e-05
2.9086624635965563e-05 2.908662281697616e-05
rl training, epoch3, iter0, batch460/1133, batch loss:2.908662281697616e-05, Training time:57577.11011958122
batch reward last col mean 3.636040855781175e-05 first col mean 5.906159458390903e-06 all mean 4.2639177991077304e-05
9.42796905292198e-05 9.427970508113503e-05
rl training, epoch3, iter0, batch461/1133, batch loss:9.427970508113503e-05, Training time:57594.02983498573
batch reward last col mean 3.272407047916204e-05 first col mean 9.482890163781121e-06 all mean 3.425684917601757e-05
7.791521056788042e-06 7.791521056788042e-06
rl training, epoch3, iter0, batch462/1133, batch loss:7.791521056788042e-06, Training time:57610.61203670502
batch reward last col mean 1.465636927378e-07 first col mean 2.939941396107315e-06 all mean 1.5841656932025217e-05
1.646741475269664e-05 1.6467412933707237e-05
rl training, epoch3, iter0, batch463/1133, batch loss:1.6467412933707237e-05, Training time:57627.19107508659
batch reward last col mean 0.0012984198983758688 first col mean 6.141709309304133e-05 all mean 0.001213438343256712
0.00011237021681154147 0.00011237021681154147
rl training, epoch3, iter0, batch464/1133, batch loss:0.00011237021681154147, Training time:57643.87770962715
batch reward last col mean 1.5400621578010032e-07 first col mean 0.0002121894940501079 all mean 1.6665448129060678e-05
5.05122916365508e-05 5.05122916365508e-05
rl training, epoch3, iter0, batch465/1133, batch loss:5.05122916365508e-05, Training time:57660.9139213562
batch reward last col mean 1.2207419786136597e-05 first col mean 0.00010122721141669899 all mean 1.820444958866574e-05
1.5311086826841347e-05 1.5311086826841347e-05
rl training, epoch3, iter0, batch466/1133, batch loss:1.5311086826841347e-05, Training time:57677.650790691376
batch reward last col mean 6.435770046664402e-05 first col mean 8.239496764872456e-07 all mean 9.567993402015418e-05
4.029288902529515e-05 4.029289630125277e-05
rl training, epoch3, iter0, batch467/1133, batch loss:4.029289630125277e-05, Training time:57694.8380253315
batch reward last col mean 1.0656742688297527e-07 first col mean 0.0001176186342490837 all mean 5.606256308965385e-05
0.00024718561326153576 0.00024718561326153576
rl training, epoch3, iter0, batch468/1133, batch loss:0.00024718561326153576, Training time:57711.6314637661
batch reward last col mean 4.4994258985298075e-08 first col mean 6.19580750935711e-05 all mean 6.135243165772408e-05
5.331714783096686e-05 5.3317129641072825e-05
rl training, epoch3, iter0, batch469/1133, batch loss:5.3317129641072825e-05, Training time:57728.17901110649
batch reward last col mean 1.0944288675318603e-07 first col mean 2.2153906684252433e-05 all mean 1.6288075130432844e-05
4.775097841047682e-05 4.775097841047682e-05
rl training, epoch3, iter0, batch470/1133, batch loss:4.775097841047682e-05, Training time:57746.05895495415
batch reward last col mean 4.2869146454904694e-07 first col mean 0.00020039512310177088 all mean 5.307189348968677e-05
0.0002079796977341175 0.0002079796977341175
rl training, epoch3, iter0, batch471/1133, batch loss:0.0002079796977341175, Training time:57765.414746046066
batch reward last col mean 1.1481669162094477e-06 first col mean 0.00024568522348999977 all mean 2.7670885174302384e-05
7.853560236981139e-05 7.8535609645769e-05
rl training, epoch3, iter0, batch472/1133, batch loss:7.8535609645769e-05, Training time:57783.8027408123
batch reward last col mean 7.062450890771288e-07 first col mean 0.002284188522025943 all mean 9.00868108146824e-05
0.00029299547895789146 0.00029299547895789146
rl training, epoch3, iter0, batch473/1133, batch loss:0.00029299547895789146, Training time:57803.02646231651
batch reward last col mean 1.8583828875762265e-07 first col mean 4.045254172524437e-06 all mean 3.763512722798623e-05
9.775769285624847e-05 9.775769285624847e-05
rl training, epoch3, iter0, batch474/1133, batch loss:9.775769285624847e-05, Training time:57821.95265197754
batch reward last col mean 3.848801668482338e-07 first col mean 0.00019156136841047555 all mean 8.852201426634565e-05
0.00038963957922533154 0.000389639608329162
rl training, epoch3, iter0, batch475/1133, batch loss:0.000389639608329162, Training time:57840.353068351746
batch reward last col mean 1.600196810613852e-07 first col mean 0.00011316686141071841 all mean 1.3121525626047514e-05
2.5437951990170404e-05 2.5437951990170404e-05
rl training, epoch3, iter0, batch476/1133, batch loss:2.5437951990170404e-05, Training time:57856.96610355377
batch reward last col mean 9.670409326645313e-07 first col mean 1.2970284615221317e-06 all mean 4.566451389109716e-05
0.00010296053369529545 0.00010296054097125307
rl training, epoch3, iter0, batch477/1133, batch loss:0.00010296054097125307, Training time:57874.15538287163
batch reward last col mean 4.016274033347145e-06 first col mean 4.098559293197468e-05 all mean 1.969881122931838e-05
0.0001230508933076635 0.0001230508933076635
rl training, epoch3, iter0, batch478/1133, batch loss:0.0001230508933076635, Training time:57891.6323530674
batch reward last col mean 1.225078847255645e-07 first col mean 8.462094456263003e-07 all mean 3.029409344890155e-05
1.8995615391759202e-05 1.8995617210748605e-05
rl training, epoch3, iter0, batch479/1133, batch loss:1.8995617210748605e-05, Training time:57908.86078119278
batch reward last col mean 5.232659987086663e-06 first col mean 0.00040971668204292655 all mean 5.502967906068079e-05
0.00021257848129607737 0.00021257848129607737
rl training, epoch3, iter0, batch480/1133, batch loss:0.00021257848129607737, Training time:57925.44674420357
batch reward last col mean 3.0299113973342173e-07 first col mean 1.2093858458683826e-05 all mean 2.7716514523490332e-05
4.2856569052673876e-05 4.2856558138737455e-05
rl training, epoch3, iter0, batch481/1133, batch loss:4.2856558138737455e-05, Training time:57942.186141490936
batch reward last col mean 2.0066730940015987e-05 first col mean 0.0001824265200411901 all mean 8.66693244461203e-06
1.4444464795815293e-05 1.4444464795815293e-05
rl training, epoch3, iter0, batch482/1133, batch loss:1.4444464795815293e-05, Training time:57958.798434734344
batch reward last col mean 1.9761871953960508e-05 first col mean 9.454792598262429e-05 all mean 2.8328360713203438e-05
3.520404061418958e-05 3.520404061418958e-05
rl training, epoch3, iter0, batch483/1133, batch loss:3.520404061418958e-05, Training time:57975.65248131752
batch reward last col mean 6.2487233662977815e-06 first col mean 3.87709733331576e-05 all mean 1.5545967471553013e-05
3.270863453508355e-05 3.270863453508355e-05
rl training, epoch3, iter0, batch484/1133, batch loss:3.270863453508355e-05, Training time:57992.13450860977
batch reward last col mean 3.592205359836953e-07 first col mean 1.330593590864737e-06 all mean 7.238508260343224e-05
0.0001385946961818263 0.0001385946961818263
rl training, epoch3, iter0, batch485/1133, batch loss:0.0001385946961818263, Training time:58008.94562339783
batch reward last col mean 3.332753237828001e-07 first col mean 0.0018138696905225515 all mean 3.921951793017797e-05
4.694140807259828e-05 4.694139352068305e-05
rl training, epoch3, iter0, batch486/1133, batch loss:4.694139352068305e-05, Training time:58025.53593707085
batch reward last col mean 3.088881044277514e-07 first col mean 2.6529978640610352e-05 all mean 1.8070932128466666e-05
1.3470533303916454e-05 1.3470535122905858e-05
rl training, epoch3, iter0, batch487/1133, batch loss:1.3470535122905858e-05, Training time:58042.02268123627
batch reward last col mean 4.5658097747036663e-08 first col mean 2.288575302600293e-07 all mean 9.356588634545915e-06
1.9551564037101343e-05 1.9551564037101343e-05
rl training, epoch3, iter0, batch488/1133, batch loss:1.9551564037101343e-05, Training time:58060.06905698776
batch reward last col mean 4.896267000731314e-07 first col mean 0.00014888262376189232 all mean 6.977526936680079e-05
0.0002497868554200977 0.00024978682631626725
rl training, epoch3, iter0, batch489/1133, batch loss:0.00024978682631626725, Training time:58077.283227443695
batch reward last col mean 2.8906251259286364e-07 first col mean 1.0913034032000724e-07 all mean 5.150228025740944e-05
0.00019947686814703047 0.00019947686814703047
rl training, epoch3, iter0, batch490/1133, batch loss:0.00019947686814703047, Training time:58094.74446105957
batch reward last col mean 8.44794703880325e-06 first col mean 8.392557356273755e-05 all mean 4.76085624541156e-05
0.00010828956874320284 0.00010828955419128761
rl training, epoch3, iter0, batch491/1133, batch loss:0.00010828955419128761, Training time:58112.264031648636
batch reward last col mean 1.966261322650098e-07 first col mean 5.048658294981578e-06 all mean 4.074714161106385e-05
5.35374456376303e-05 5.3537449275609106e-05
rl training, epoch3, iter0, batch492/1133, batch loss:5.3537449275609106e-05, Training time:58131.854531526566
batch reward last col mean 4.2926441778945446e-07 first col mean 2.495720536899171e-07 all mean 2.0089182726223953e-05
4.4447780965128914e-05 4.4447780965128914e-05
rl training, epoch3, iter0, batch493/1133, batch loss:4.4447780965128914e-05, Training time:58149.649112939835
batch reward last col mean 6.391743227140978e-05 first col mean 0.001164251589216292 all mean 0.00010952231241390109
5.565878745983355e-05 5.565878382185474e-05
rl training, epoch3, iter0, batch494/1133, batch loss:5.565878382185474e-05, Training time:58166.22851347923
batch reward last col mean 1.1431525308580603e-06 first col mean 2.6876088668359444e-05 all mean 4.0031096432358027e-05
0.00013927198597230017 0.00013927198597230017
rl training, epoch3, iter0, batch495/1133, batch loss:0.00013927198597230017, Training time:58182.81313228607
batch reward last col mean 3.0046300025787787e-07 first col mean 3.457426282693632e-05 all mean 7.099898357409984e-05
0.00023701762256678194 0.00023701762256678194
rl training, epoch3, iter0, batch496/1133, batch loss:0.00023701762256678194, Training time:58199.42253565788
batch reward last col mean 1.1250983334321063e-05 first col mean 4.182971315458417e-05 all mean 3.0218439860618673e-05
4.709623317467049e-05 4.709623317467049e-05
rl training, epoch3, iter0, batch497/1133, batch loss:4.709623317467049e-05, Training time:58216.8207013607
batch reward last col mean 3.030061748177104e-07 first col mean 0.0006152499699965119 all mean 6.674337782897055e-05
0.00012258281640242785 0.00012258280185051262
rl training, epoch3, iter0, batch498/1133, batch loss:0.00012258280185051262, Training time:58233.647512197495
batch reward last col mean 3.618065966293216e-05 first col mean 3.180546627845615e-05 all mean 5.313552901498042e-05
2.2643116608378477e-05 2.264311842736788e-05
rl training, epoch3, iter0, batch499/1133, batch loss:2.264311842736788e-05, Training time:58250.17502474785
batch reward last col mean 6.95870880917937e-08 first col mean 7.091487645993766e-07 all mean 5.3786992793902755e-05
7.168967567849904e-05 7.168967567849904e-05
rl training, epoch3, iter0, batch500/1133, batch loss:7.168967567849904e-05, Training time:58266.758831739426
batch reward last col mean 0.007464342750608921 first col mean 4.2848827433772385e-05 all mean 0.0064306058920919895
0.00040032697143033147 0.00040032691322267056
rl training, epoch3, iter0, batch501/1133, batch loss:0.00040032691322267056, Training time:58283.53307080269
batch reward last col mean 5.853255788679235e-05 first col mean 1.8825138567990507e-06 all mean 7.921431824797764e-05
0.00011519304825924337 0.00011519305553520098
rl training, epoch3, iter0, batch502/1133, batch loss:0.00011519305553520098, Training time:58300.403790950775
batch reward last col mean 5.357313511922257e-06 first col mean 8.04034607426729e-06 all mean 2.419480006210506e-05
2.3165617676568218e-05 2.3165612219600007e-05
rl training, epoch3, iter0, batch503/1133, batch loss:2.3165612219600007e-05, Training time:58317.021394729614
batch reward last col mean 1.4831987300567562e-06 first col mean 0.0009605100494809449 all mean 5.2429328206926584e-05
0.00014859088696539402 0.0001485908724134788
rl training, epoch3, iter0, batch504/1133, batch loss:0.0001485908724134788, Training time:58333.7886402607
batch reward last col mean 0.00010903739166678861 first col mean 9.522939308226341e-07 all mean 9.905899059958756e-05
1.6627680452074856e-05 1.662768227106426e-05
rl training, epoch3, iter0, batch505/1133, batch loss:1.662768227106426e-05, Training time:58350.42079925537
batch reward last col mean 7.505284571607262e-08 first col mean 0.0002705587830860168 all mean 4.035607344121672e-05
0.0002423336118226871 0.00024233362637460232
rl training, epoch3, iter0, batch506/1133, batch loss:0.00024233362637460232, Training time:58366.89842057228
batch reward last col mean 6.971577590775269e-07 first col mean 4.0811621147440746e-05 all mean 2.226640390290413e-05
5.504316504811868e-05 5.5043172324076295e-05
rl training, epoch3, iter0, batch507/1133, batch loss:5.5043172324076295e-05, Training time:58384.41344118118
batch reward last col mean 6.616916152779595e-07 first col mean 2.6428917408338748e-05 all mean 2.572627090557944e-05
2.0579365809680894e-05 2.0579365809680894e-05
rl training, epoch3, iter0, batch508/1133, batch loss:2.0579365809680894e-05, Training time:58402.82500767708
batch reward last col mean 0.00011614331015152857 first col mean 1.4396058759302832e-05 all mean 0.00012411040370352566
0.0001604100689291954 0.0001604100689291954
rl training, epoch3, iter0, batch509/1133, batch loss:0.0001604100689291954, Training time:58420.29794049263
batch reward last col mean 0.00014656312123406678 first col mean 0.0005399202927947044 all mean 0.00016007658268790692
0.00013528691488318145 0.00013528691488318145
rl training, epoch3, iter0, batch510/1133, batch loss:0.00013528691488318145, Training time:58437.94992351532
batch reward last col mean 1.1328894288453739e-05 first col mean 9.7052088676719e-06 all mean 1.186902227345854e-05
6.139983270259108e-06 6.139983270259108e-06
rl training, epoch3, iter0, batch511/1133, batch loss:6.139983270259108e-06, Training time:58456.589603185654
batch reward last col mean 2.175831781414672e-08 first col mean 2.2711308247380657e-06 all mean 1.050899300025776e-05
6.275570922298357e-05 6.275570922298357e-05
rl training, epoch3, iter0, batch512/1133, batch loss:6.275570922298357e-05, Training time:58476.05263018608
batch reward last col mean 2.909313707277761e-06 first col mean 7.554787771368865e-06 all mean 8.707066626811866e-06
8.996755241241772e-06 8.99675433174707e-06
rl training, epoch3, iter0, batch513/1133, batch loss:8.99675433174707e-06, Training time:58493.36712408066
batch reward last col mean 1.6387975847464986e-06 first col mean 7.97227670545908e-08 all mean 3.0768020224059e-05
0.0001666115567786619 0.0001666115567786619
rl training, epoch3, iter0, batch514/1133, batch loss:0.0001666115567786619, Training time:58510.59715151787
batch reward last col mean 3.524848580127582e-05 first col mean 1.693418425929849e-06 all mean 6.173371366458014e-05
0.00011141322465846315 0.00011141321738250554
rl training, epoch3, iter0, batch515/1133, batch loss:0.00011141321738250554, Training time:58527.14610624313
batch reward last col mean 4.286160219635349e-06 first col mean 7.784123226883821e-06 all mean 2.892301017709542e-05
4.980264566256665e-05 4.980265293852426e-05
rl training, epoch3, iter0, batch516/1133, batch loss:4.980265293852426e-05, Training time:58543.69071936607
batch reward last col mean 4.514463944360614e-05 first col mean 4.822610435439856e-07 all mean 9.794578363653272e-05
0.0002174114342778921 0.0002174114342778921
rl training, epoch3, iter0, batch517/1133, batch loss:0.0002174114342778921, Training time:58560.42981505394
batch reward last col mean 6.044202223165485e-07 first col mean 2.7656433303491212e-05 all mean 1.9661851183627732e-05
2.4554890842409804e-05 2.45548890234204e-05
rl training, epoch3, iter0, batch518/1133, batch loss:2.45548890234204e-05, Training time:58576.87783622742
batch reward last col mean 1.4404041337456874e-07 first col mean 3.107038719463162e-05 all mean 2.7021807909477502e-05
7.801187166478485e-05 7.801187166478485e-05
rl training, epoch3, iter0, batch519/1133, batch loss:7.801187166478485e-05, Training time:58593.89940237999
batch reward last col mean 2.33239939007035e-06 first col mean 1.6116081269501592e-07 all mean 2.969001798192039e-05
7.28110535419546e-05 7.28110535419546e-05
rl training, epoch3, iter0, batch520/1133, batch loss:7.28110535419546e-05, Training time:58610.393115758896
batch reward last col mean 1.405050261382712e-05 first col mean 3.0084950140008004e-06 all mean 1.2865762982983142e-05
3.6937119148205966e-05 3.693712278618477e-05
rl training, epoch3, iter0, batch521/1133, batch loss:3.693712278618477e-05, Training time:58627.12052512169
batch reward last col mean 4.529746365733445e-05 first col mean 0.001538202865049243 all mean 7.490943244192749e-05
8.185355545720086e-05 8.185355545720086e-05
rl training, epoch3, iter0, batch522/1133, batch loss:8.185355545720086e-05, Training time:58644.145109415054
batch reward last col mean 8.059816991590196e-07 first col mean 0.001428497489541769 all mean 4.601488035405055e-05
0.00015833241923246533 0.0001583324046805501
rl training, epoch3, iter0, batch523/1133, batch loss:0.0001583324046805501, Training time:58660.78985667229
batch reward last col mean 1.4888864825479686e-06 first col mean 9.306019137511612e-07 all mean 2.651899376360234e-05
7.083123637130484e-05 7.083124364726245e-05
rl training, epoch3, iter0, batch524/1133, batch loss:7.083124364726245e-05, Training time:58677.68745613098
batch reward last col mean 0.0004911150317639112 first col mean 0.0001253461086889729 all mean 0.000475688255392015
0.0001395499421050772 0.00013954997120890766
rl training, epoch3, iter0, batch525/1133, batch loss:0.00013954997120890766, Training time:58694.307801008224
batch reward last col mean 2.716978144690074e-07 first col mean 0.00012817470997106284 all mean 2.7564465199247934e-05
0.00011478110536700115 0.0001147810835391283
rl training, epoch3, iter0, batch526/1133, batch loss:0.0001147810835391283, Training time:58711.14795708656
batch reward last col mean 3.940884198527783e-06 first col mean 3.8449916246463545e-06 all mean 1.982480716833379e-05
5.9269303164910525e-05 5.9269303164910525e-05
rl training, epoch3, iter0, batch527/1133, batch loss:5.9269303164910525e-05, Training time:58728.09231877327
batch reward last col mean 0.0003369921469129622 first col mean 0.001456060679629445 all mean 0.0003840423305518925
0.00022350269136950374 0.00022350269136950374
rl training, epoch3, iter0, batch528/1133, batch loss:0.00022350269136950374, Training time:58745.999477386475
batch reward last col mean 2.0097665753837646e-08 first col mean 3.831417780020274e-05 all mean 3.703715992742218e-05
9.72759080468677e-05 9.72759080468677e-05
rl training, epoch3, iter0, batch529/1133, batch loss:9.72759080468677e-05, Training time:58764.51598405838
batch reward last col mean 3.3372211305504607e-07 first col mean 0.0013200136600062251 all mean 4.079969949088991e-05
7.664306031074375e-05 7.664306758670136e-05
rl training, epoch3, iter0, batch530/1133, batch loss:7.664306758670136e-05, Training time:58782.377521276474
batch reward last col mean 3.26323288390995e-06 first col mean 0.0005544379819184542 all mean 2.5170982553390786e-05
1.0413938070996664e-05 1.041394079948077e-05
rl training, epoch3, iter0, batch531/1133, batch loss:1.041394079948077e-05, Training time:58799.42277646065
batch reward last col mean 4.173187306832915e-08 first col mean 0.0007490729331038892 all mean 4.168394661974162e-05
8.940914267441258e-05 8.940914267441258e-05
rl training, epoch3, iter0, batch532/1133, batch loss:8.940914267441258e-05, Training time:58818.164167165756
batch reward last col mean 2.5868878310575383e-06 first col mean 0.0005375504842959344 all mean 4.661081766244024e-05
0.00014451981405727565 0.00014451981405727565
rl training, epoch3, iter0, batch533/1133, batch loss:0.00014451981405727565, Training time:58835.62540769577
batch reward last col mean 1.2047927384628565e-06 first col mean 7.485334936063737e-05 all mean 5.621321906801313e-05
4.964455365552567e-05 4.964456456946209e-05
rl training, epoch3, iter0, batch534/1133, batch loss:4.964456456946209e-05, Training time:58852.37535190582
batch reward last col mean 1.4442231076827738e-05 first col mean 5.259167210169835e-06 all mean 1.5258118764904793e-05
4.638621612684801e-05 4.638621612684801e-05
rl training, epoch3, iter0, batch535/1133, batch loss:4.638621612684801e-05, Training time:58869.06624889374
batch reward last col mean 1.9831787767543574e-07 first col mean 0.00015500147128477693 all mean 2.6234371034661308e-05
0.00015112916298676282 0.00015112916298676282
rl training, epoch3, iter0, batch536/1133, batch loss:0.00015112916298676282, Training time:58885.82810091972
batch reward last col mean 1.7929903606273e-07 first col mean 0.0028161248192191124 all mean 5.210308518144302e-05
5.255005817161873e-05 5.2550065447576344e-05
rl training, epoch3, iter0, batch537/1133, batch loss:5.2550065447576344e-05, Training time:58902.44698405266
batch reward last col mean 6.681172521894041e-07 first col mean 4.515329419518821e-05 all mean 1.587486985954456e-05
1.4506295883620623e-05 1.450629406463122e-05
rl training, epoch3, iter0, batch538/1133, batch loss:1.450629406463122e-05, Training time:58918.95484042168
batch reward last col mean 2.696119736356195e-07 first col mean 0.0010655297664925456 all mean 5.12108308612369e-05
0.0002057364908978343 0.0002057364908978343
rl training, epoch3, iter0, batch539/1133, batch loss:0.0002057364908978343, Training time:58935.40591073036
batch reward last col mean 1.3052308531769086e-05 first col mean 1.2788538015229278e-06 all mean 2.760164898063522e-05
0.00014110644406173378 0.000141106458613649
rl training, epoch3, iter0, batch540/1133, batch loss:0.000141106458613649, Training time:58952.024542570114
batch reward last col mean 1.07535811366688e-07 first col mean 5.738413619837957e-07 all mean 7.516898040194064e-05
0.0003915706474799663 0.0003915706474799663
rl training, epoch3, iter0, batch541/1133, batch loss:0.0003915706474799663, Training time:58968.5688188076
batch reward last col mean 8.366153633687645e-05 first col mean 1.5119776435312815e-06 all mean 5.507785681402311e-05
0.00012288024299778044 0.00012288025754969567
rl training, epoch3, iter0, batch542/1133, batch loss:0.00012288025754969567, Training time:58985.69236969948
batch reward last col mean 0.0027198081370443106 first col mean 3.777810343308374e-05 all mean 6.0638391005340964e-05
0.00010860166366910562 0.00010860163456527516
rl training, epoch3, iter0, batch543/1133, batch loss:0.00010860163456527516, Training time:59002.70995903015
batch reward last col mean 5.116656893733307e-07 first col mean 0.0002932713832706213 all mean 4.474681190913543e-05
8.294159488286823e-05 8.294159488286823e-05
rl training, epoch3, iter0, batch544/1133, batch loss:8.294159488286823e-05, Training time:59019.18229556084
batch reward last col mean 2.203398935307632e-06 first col mean 6.493764317383466e-07 all mean 3.220674625481479e-05
0.0001236926909768954 0.0001236926909768954
rl training, epoch3, iter0, batch545/1133, batch loss:0.0001236926909768954, Training time:59035.640928030014
batch reward last col mean 3.0429276876020595e-07 first col mean 0.001899079536087811 all mean 3.479077713564038e-05
0.00010337404091842473 0.00010337403364246711
rl training, epoch3, iter0, batch546/1133, batch loss:0.00010337403364246711, Training time:59052.01734018326
batch reward last col mean 4.649726179195568e-06 first col mean 7.474744779756293e-05 all mean 4.57740061392542e-05
0.00018751346215140074 0.00018751346215140074
rl training, epoch3, iter0, batch547/1133, batch loss:0.00018751346215140074, Training time:59068.51248764992
batch reward last col mean 7.081482635840075e-07 first col mean 9.304991181124933e-06 all mean 8.626494673080742e-05
0.00040998210897669196 0.00040998210897669196
rl training, epoch3, iter0, batch548/1133, batch loss:0.00040998210897669196, Training time:59084.942323207855
batch reward last col mean 1.0620326520438539e-06 first col mean 1.0897527317865752e-05 all mean 1.6395679267589003e-05
2.8397709684213623e-05 2.839771332219243e-05
rl training, epoch3, iter0, batch549/1133, batch loss:2.839771332219243e-05, Training time:59101.54191160202
batch reward last col mean 5.011969150814366e-08 first col mean 1.9121641798847122e-06 all mean 2.819903238560073e-05
4.880392225459218e-05 4.880392225459218e-05
rl training, epoch3, iter0, batch550/1133, batch loss:4.880392225459218e-05, Training time:59118.102409124374
batch reward last col mean 1.0438633779585871e-07 first col mean 3.934430060326122e-05 all mean 1.570403946971055e-05
4.222470670356415e-05 4.2224703065585345e-05
rl training, epoch3, iter0, batch551/1133, batch loss:4.2224703065585345e-05, Training time:59134.51348233223
batch reward last col mean 0.0015446533216163516 first col mean 0.00010276478860760108 all mean 0.0013366787461563945
0.0002971359936054796 0.0002971359936054796
rl training, epoch3, iter0, batch552/1133, batch loss:0.0002971359936054796, Training time:59150.990240097046
batch reward last col mean 5.1023302916064495e-08 first col mean 3.749994721147232e-05 all mean 2.0830557332374156e-05
4.259608977008611e-05 4.259609340806492e-05
rl training, epoch3, iter0, batch553/1133, batch loss:4.259609340806492e-05, Training time:59167.671154260635
batch reward last col mean 5.788578619103646e-06 first col mean 4.210221959510818e-05 all mean 5.159354259376414e-05
0.00025910025578923523 0.00025910025578923523
rl training, epoch3, iter0, batch554/1133, batch loss:0.00025910025578923523, Training time:59184.27896308899
batch reward last col mean 5.958160727459472e-06 first col mean 0.0020603497978299856 all mean 6.830341590102762e-05
0.00017522719281259924 0.00017522719281259924
rl training, epoch3, iter0, batch555/1133, batch loss:0.00017522719281259924, Training time:59200.99019241333
batch reward last col mean 0.007215544581413269 first col mean 2.0341765775810927e-05 all mean 0.006429183762520552
0.00039395588100887835 0.00039395588100887835
rl training, epoch3, iter0, batch556/1133, batch loss:0.00039395588100887835, Training time:59217.61467170715
batch reward last col mean 0.00037133527803234756 first col mean 2.2215201170183718e-05 all mean 0.00036819203523918986
0.0001490692375227809 0.00014906922297086567
rl training, epoch3, iter0, batch557/1133, batch loss:0.00014906922297086567, Training time:59234.012172698975
batch reward last col mean 2.295619560754858e-05 first col mean 3.137004387099296e-05 all mean 0.0001092160091502592
0.00025814370019361377 0.00025814370019361377
rl training, epoch3, iter0, batch558/1133, batch loss:0.00025814370019361377, Training time:59250.47212100029
batch reward last col mean 1.7058970115613192e-05 first col mean 4.754215115099214e-05 all mean 2.060543374682311e-05
8.456795330857858e-05 8.456795330857858e-05
rl training, epoch3, iter0, batch559/1133, batch loss:8.456795330857858e-05, Training time:59266.935727119446
batch reward last col mean 2.0664887415478006e-05 first col mean 0.0008410558220930398 all mean 6.298847438301891e-05
8.325414819410071e-05 8.325414819410071e-05
rl training, epoch3, iter0, batch560/1133, batch loss:8.325414819410071e-05, Training time:59283.49889230728
batch reward last col mean 1.9328701910126256e-06 first col mean 3.0331653988469043e-07 all mean 1.671250538493041e-05
1.9974428141722456e-05 1.9974426322733052e-05
rl training, epoch3, iter0, batch561/1133, batch loss:1.9974426322733052e-05, Training time:59299.95995593071
batch reward last col mean 3.3792300655477447e-06 first col mean 9.870133908407297e-06 all mean 2.36382256844081e-05
4.740771328215487e-05 4.7407709644176066e-05
rl training, epoch3, iter0, batch562/1133, batch loss:4.7407709644176066e-05, Training time:59316.36681056023
batch reward last col mean 0.0001292901288252324 first col mean 1.3103262062941212e-05 all mean 9.200667409459129e-05
3.837201074929908e-05 3.837201802525669e-05
rl training, epoch3, iter0, batch563/1133, batch loss:3.837201802525669e-05, Training time:59332.84952378273
batch reward last col mean 4.287020783522166e-05 first col mean 0.0002227274962933734 all mean 6.630309508182108e-05
5.75243539060466e-05 5.752436481998302e-05
rl training, epoch3, iter0, batch564/1133, batch loss:5.752436481998302e-05, Training time:59349.30218434334
batch reward last col mean 6.483923016276094e-07 first col mean 9.603903663446545e-07 all mean 4.587354851537384e-05
0.00014614505926147103 0.00014614505926147103
rl training, epoch3, iter0, batch565/1133, batch loss:0.00014614505926147103, Training time:59365.69538784027
batch reward last col mean 0.0008056429214775562 first col mean 2.9048985084045853e-07 all mean 0.00018386986630503088
8.270254329545423e-05 8.270255784736946e-05
rl training, epoch3, iter0, batch566/1133, batch loss:8.270255784736946e-05, Training time:59382.12543082237
batch reward last col mean 1.017136355585535e-06 first col mean 1.1504587746458128e-05 all mean 2.7721758669940755e-05
7.499795174226165e-05 7.499794446630403e-05
rl training, epoch3, iter0, batch567/1133, batch loss:7.499794446630403e-05, Training time:59398.663519620895
batch reward last col mean 9.331338901574782e-07 first col mean 1.6844252286318806e-06 all mean 4.1632112697698176e-05
0.0002584467001724988 0.0002584467001724988
rl training, epoch3, iter0, batch568/1133, batch loss:0.0002584467001724988, Training time:59415.40470433235
batch reward last col mean 7.076065958244726e-05 first col mean 7.0219180088315625e-06 all mean 8.756330498727039e-05
9.215890167979524e-05 9.215890167979524e-05
rl training, epoch3, iter0, batch569/1133, batch loss:9.215890167979524e-05, Training time:59432.221575021744
batch reward last col mean 7.762292807456106e-05 first col mean 0.00043637785711325705 all mean 0.00011070368782384321
0.00011367347178747877 0.00011367345723556355
rl training, epoch3, iter0, batch570/1133, batch loss:0.00011367345723556355, Training time:59448.95229935646
batch reward last col mean 0.00036812032340094447 first col mean 2.3041097847453784e-06 all mean 8.207151404349133e-05
0.00018394888320472091 0.00018394888320472091
rl training, epoch3, iter0, batch571/1133, batch loss:0.00018394888320472091, Training time:59465.64027905464
batch reward last col mean 5.3934098104946315e-05 first col mean 0.00034720482653938234 all mean 6.436010880861431e-05
7.34182249289006e-05 7.34182249289006e-05
rl training, epoch3, iter0, batch572/1133, batch loss:7.34182249289006e-05, Training time:59482.212517261505
batch reward last col mean 2.8544359338411596e-06 first col mean 2.589569521660451e-05 all mean 1.7322714484180324e-05
3.5386914532864466e-05 3.538691089488566e-05
rl training, epoch3, iter0, batch573/1133, batch loss:3.538691089488566e-05, Training time:59498.86572813988
batch reward last col mean 2.738651164690964e-05 first col mean 8.723994142201263e-06 all mean 4.3216103222221136e-05
6.454427057178691e-05 6.454427057178691e-05
rl training, epoch3, iter0, batch574/1133, batch loss:6.454427057178691e-05, Training time:59515.437843322754
batch reward last col mean 7.14546040399e-05 first col mean 6.616873724851757e-05 all mean 4.760502997669391e-05
5.848016371601261e-05 5.8480170991970226e-05
rl training, epoch3, iter0, batch575/1133, batch loss:5.8480170991970226e-05, Training time:59531.94083213806
batch reward last col mean 1.5632813301635906e-06 first col mean 0.0001375765714328736 all mean 5.241377220954746e-05
0.00011929203174076974 0.00011929203174076974
rl training, epoch3, iter0, batch576/1133, batch loss:0.00011929203174076974, Training time:59548.506752967834
batch reward last col mean 0.0003633050073403865 first col mean 0.0008492498891428113 all mean 0.0003499625308904797
9.002924343803898e-05 9.002922888612375e-05
rl training, epoch3, iter0, batch577/1133, batch loss:9.002922888612375e-05, Training time:59564.936561346054
batch reward last col mean 6.558244081134035e-08 first col mean 0.0001589349703863263 all mean 4.173230627202429e-05
0.00023512625193689018 0.00023512625193689018
rl training, epoch3, iter0, batch578/1133, batch loss:0.00023512625193689018, Training time:59581.14541602135
batch reward last col mean 8.866110761118762e-07 first col mean 1.658426845096983e-05 all mean 3.94165217585396e-05
0.00015718647046014667 0.0001571864850120619
rl training, epoch3, iter0, batch579/1133, batch loss:0.0001571864850120619, Training time:59597.545563697815
batch reward last col mean 2.3118154786061496e-06 first col mean 0.0003332899941597134 all mean 3.5778411984210834e-05
5.92634423810523e-05 5.92634423810523e-05
rl training, epoch3, iter0, batch580/1133, batch loss:5.92634423810523e-05, Training time:59613.90428328514
batch reward last col mean 5.720911303797038e-06 first col mean 1.5945865925459657e-06 all mean 2.0856847186223604e-05
3.843916056212038e-05 3.843916056212038e-05
rl training, epoch3, iter0, batch581/1133, batch loss:3.843916056212038e-05, Training time:59630.42675232887
batch reward last col mean 0.00029532183543778956 first col mean 0.0004358783771749586 all mean 0.0003396608808543533
0.00014506866864394397 0.00014506866864394397
rl training, epoch3, iter0, batch582/1133, batch loss:0.00014506866864394397, Training time:59646.991983652115
batch reward last col mean 1.1254026048845844e-06 first col mean 0.0005439429660327733 all mean 9.830574708757922e-05
0.00019833032274618745 0.00019833032274618745
rl training, epoch3, iter0, batch583/1133, batch loss:0.00019833032274618745, Training time:59663.652796030045
batch reward last col mean 2.1582587805824005e-07 first col mean 0.0017968419706448913 all mean 6.19620259385556e-05
0.00024368871527258307 0.0002436887298244983
rl training, epoch3, iter0, batch584/1133, batch loss:0.0002436887298244983, Training time:59680.359882354736
batch reward last col mean 2.284706170030404e-05 first col mean 0.0017473059706389904 all mean 5.532673094421625e-05
7.413146522594616e-05 7.413145794998854e-05
rl training, epoch3, iter0, batch585/1133, batch loss:7.413145794998854e-05, Training time:59697.111317157745
batch reward last col mean 3.5582559121394297e-07 first col mean 4.0656410419614986e-05 all mean 1.4348256627272349e-05
1.3737923836742993e-05 1.3737922927248292e-05
rl training, epoch3, iter0, batch586/1133, batch loss:1.3737922927248292e-05, Training time:59713.888468027115
batch reward last col mean 8.493175118928775e-05 first col mean 1.6989799860311905e-06 all mean 0.00012040109868394211
0.00013265974121168256 0.00013265972665976733
rl training, epoch3, iter0, batch587/1133, batch loss:0.00013265972665976733, Training time:59730.5806453228
batch reward last col mean 0.0003381806891411543 first col mean 1.4749727597518358e-05 all mean 0.00031835242407396436
0.00020212733943480998 0.00020212733943480998
rl training, epoch3, iter0, batch588/1133, batch loss:0.00020212733943480998, Training time:59747.34634923935
batch reward last col mean 0.005155779886990786 first col mean 1.9875687939929776e-05 all mean 0.004826115444302559
0.00019873719429597259 0.00019873722339980304
rl training, epoch3, iter0, batch589/1133, batch loss:0.00019873722339980304, Training time:59764.18621993065
batch reward last col mean 0.000144830861245282 first col mean 5.405360752774868e-06 all mean 0.00016011575644370168
0.0001542679819976911 0.0001542679819976911
rl training, epoch3, iter0, batch590/1133, batch loss:0.0001542679819976911, Training time:59780.94932770729
batch reward last col mean 1.2798466741514858e-05 first col mean 0.002223037648946047 all mean 0.00012202496873214841
0.00030269843409769237 0.00030269843409769237
rl training, epoch3, iter0, batch591/1133, batch loss:0.00030269843409769237, Training time:59798.05736994743
batch reward last col mean 7.345525227719918e-05 first col mean 3.0755516490899026e-05 all mean 0.00011139363050460815
0.0003036001871805638 0.0003036001871805638
rl training, epoch3, iter0, batch592/1133, batch loss:0.0003036001871805638, Training time:59814.77301073074
batch reward last col mean 2.4289151951961685e-06 first col mean 3.217702032998204e-05 all mean 5.0705846661003307e-05
0.0001327834906987846 0.0001327834906987846
rl training, epoch3, iter0, batch593/1133, batch loss:0.0001327834906987846, Training time:59831.546844244
batch reward last col mean 7.738378826616099e-07 first col mean 0.00023475647321902215 all mean 4.4755113776773214e-05
0.00017958012176677585 0.00017958012176677585
rl training, epoch3, iter0, batch594/1133, batch loss:0.00017958012176677585, Training time:59848.56208014488
batch reward last col mean 2.264913518956746e-06 first col mean 0.0008351232390850782 all mean 5.526791210286319e-05
0.00018044747412204742 0.00018044747412204742
rl training, epoch3, iter0, batch595/1133, batch loss:0.00018044747412204742, Training time:59865.78290748596
batch reward last col mean 2.6741440706246067e-06 first col mean 9.946257341653109e-05 all mean 4.713591988547705e-05
0.0001985810959013179 0.00019858111045323312
rl training, epoch3, iter0, batch596/1133, batch loss:0.00019858111045323312, Training time:59882.168699502945
batch reward last col mean 4.5712004066444933e-05 first col mean 0.0009718310902826488 all mean 7.880241173552349e-05
4.5437980588758364e-05 4.5437966036843136e-05
rl training, epoch3, iter0, batch597/1133, batch loss:4.5437966036843136e-05, Training time:59898.49025774002
batch reward last col mean 2.093561590754689e-07 first col mean 4.475188325159252e-05 all mean 1.670142955845222e-05
4.466142854653299e-05 4.466142490855418e-05
rl training, epoch3, iter0, batch598/1133, batch loss:4.466142490855418e-05, Training time:59914.89041137695
batch reward last col mean 0.00034082497586496174 first col mean 0.00021316255151759833 all mean 0.00012214781600050628
0.00016653581405989826 0.00016653581405989826
rl training, epoch3, iter0, batch599/1133, batch loss:0.00016653581405989826, Training time:59931.290266275406
batch reward last col mean 1.0664170986274257e-06 first col mean 1.015911311696982e-05 all mean 6.206702528288588e-05
0.0004055842582602054 0.0004055842582602054
rl training, epoch3, iter0, batch600/1133, batch loss:0.0004055842582602054, Training time:59947.78656744957
batch reward last col mean 9.349893304033685e-08 first col mean 4.994871005692403e-07 all mean 3.3979991712840274e-05
0.000170332525158301 0.000170332525158301
rl training, epoch3, iter0, batch601/1133, batch loss:0.000170332525158301, Training time:59964.257989406586
batch reward last col mean 2.1702275262214243e-05 first col mean 0.002678325865417719 all mean 0.00013249012408778071
0.00011346712562954053 0.00011346711835358292
rl training, epoch3, iter0, batch602/1133, batch loss:0.00011346711835358292, Training time:59980.80164933205
batch reward last col mean 1.809982677514199e-05 first col mean 2.2446179173130076e-06 all mean 0.00013415649300441146
0.00042947413749061525 0.00042947419569827616
rl training, epoch3, iter0, batch603/1133, batch loss:0.00042947419569827616, Training time:59997.417999982834
batch reward last col mean 3.6910555536451284e-06 first col mean 2.541546564316377e-05 all mean 2.702338679227978e-05
0.0001532902824692428 0.0001532902824692428
rl training, epoch3, iter0, batch604/1133, batch loss:0.0001532902824692428, Training time:60013.907269239426
batch reward last col mean 0.00020936498185619712 first col mean 0.000636460492387414 all mean 0.00021231776918284595
2.5232411644537933e-05 2.523240982554853e-05
rl training, epoch3, iter0, batch605/1133, batch loss:2.523240982554853e-05, Training time:60030.465163469315
batch reward last col mean 3.7436453226291633e-07 first col mean 9.07050198293291e-05 all mean 4.479648487176746e-05
0.00010251735511701554 0.00010251735511701554
rl training, epoch3, iter0, batch606/1133, batch loss:0.00010251735511701554, Training time:60047.02358198166
batch reward last col mean 9.082939504878595e-05 first col mean 5.282550432639255e-07 all mean 0.0001354380656266585
0.00022556020121555775 0.00022556018666364253
rl training, epoch3, iter0, batch607/1133, batch loss:0.00022556018666364253, Training time:60063.594947338104
batch reward last col mean 4.135507879254874e-06 first col mean 1.5824469301151112e-05 all mean 5.130916542839259e-05
0.00021290061704348773 0.00021290061704348773
rl training, epoch3, iter0, batch608/1133, batch loss:0.00021290061704348773, Training time:60080.18772768974
batch reward last col mean 0.0008466026047244668 first col mean 0.002655928023159504 all mean 0.0008833981701172888
0.0003403274167794734 0.0003403274167794734
rl training, epoch3, iter0, batch609/1133, batch loss:0.0003403274167794734, Training time:60096.75177717209
batch reward last col mean 2.0424520243977895e-06 first col mean 2.3211709958559368e-06 all mean 7.434021244989708e-05
0.0003502028703223914 0.0003502028703223914
rl training, epoch3, iter0, batch610/1133, batch loss:0.0003502028703223914, Training time:60113.227882385254
batch reward last col mean 1.3598371424450306e-06 first col mean 6.45133332000114e-05 all mean 5.940322807873599e-05
0.00012737508222926408 0.00012737508222926408
rl training, epoch3, iter0, batch611/1133, batch loss:0.00012737508222926408, Training time:60129.6732840538
batch reward last col mean 7.956295178246364e-08 first col mean 0.00024138347362168133 all mean 5.121609865454957e-05
0.00014182794257067144 0.0001418279280187562
rl training, epoch3, iter0, batch612/1133, batch loss:0.0001418279280187562, Training time:60146.06386899948
batch reward last col mean 3.169220690324437e-06 first col mean 0.002029294613748789 all mean 5.119167690281756e-05
0.0001811029069358483 0.0001811029069358483
rl training, epoch3, iter0, batch613/1133, batch loss:0.0001811029069358483, Training time:60162.51062583923
batch reward last col mean 8.667925612826366e-06 first col mean 7.773469405947253e-05 all mean 6.576199666596949e-05
0.00011362111399648711 0.00011362109944457188
rl training, epoch3, iter0, batch614/1133, batch loss:0.00011362109944457188, Training time:60179.03418588638
batch reward last col mean 2.2241865735850297e-06 first col mean 0.00036429145256988704 all mean 9.663971286499873e-05
0.0003658379428088665 0.0003658379428088665
rl training, epoch3, iter0, batch615/1133, batch loss:0.0003658379428088665, Training time:60195.448615550995
batch reward last col mean 1.6194753982290422e-07 first col mean 0.00024500006111338735 all mean 4.075672768522054e-05
0.00016227358719334006 0.00016227358719334006
rl training, epoch3, iter0, batch616/1133, batch loss:0.00016227358719334006, Training time:60211.79700756073
batch reward last col mean 1.3290540664456785e-05 first col mean 0.001198610640130937 all mean 3.566896702977829e-05
5.9390789829194546e-05 5.9390789829194546e-05
rl training, epoch3, iter0, batch617/1133, batch loss:5.9390789829194546e-05, Training time:60228.091374874115
batch reward last col mean 0.0008376743062399328 first col mean 0.0012804672587662935 all mean 0.0008109007030725479
0.00020548557222355157 0.00020548555767163634
rl training, epoch3, iter0, batch618/1133, batch loss:0.00020548555767163634, Training time:60244.39157295227
batch reward last col mean 1.08134088350198e-06 first col mean 2.07877974389703e-06 all mean 8.03900184109807e-05
0.00035478154313750565 0.00035478154313750565
rl training, epoch3, iter0, batch619/1133, batch loss:0.00035478154313750565, Training time:60260.638974905014
batch reward last col mean 5.7180699513992295e-05 first col mean 0.002803199924528599 all mean 7.626410661032423e-05
0.00011394583998480812 0.00011394583998480812
rl training, epoch3, iter0, batch620/1133, batch loss:0.00011394583998480812, Training time:60277.192528009415
batch reward last col mean 2.4599983134976355e-06 first col mean 1.0309699973731767e-05 all mean 2.3742524717818014e-05
0.00010449271212564781 0.0001044927048496902
rl training, epoch3, iter0, batch621/1133, batch loss:0.0001044927048496902, Training time:60293.754214286804
batch reward last col mean 0.007275586016476154 first col mean 0.00031271844636648893 all mean 0.006806062534451485
0.0005770006100647151 0.0005770006100647151
rl training, epoch3, iter0, batch622/1133, batch loss:0.0005770006100647151, Training time:60310.56293010712
batch reward last col mean 4.207832716929261e-06 first col mean 4.772550892084837e-05 all mean 2.0561217752401717e-05
3.88317130273208e-05 3.88317130273208e-05
rl training, epoch3, iter0, batch623/1133, batch loss:3.88317130273208e-05, Training time:60327.02820801735
batch reward last col mean 1.1374831956345588e-06 first col mean 2.826302261382807e-05 all mean 6.375688826665282e-05
0.0003504876221995801 0.0003504876221995801
rl training, epoch3, iter0, batch624/1133, batch loss:0.0003504876221995801, Training time:60343.44813847542
batch reward last col mean 0.0009395865490660071 first col mean 9.781456174096093e-05 all mean 0.0008365869871340692
0.00010074341844301671 0.00010074343299493194
rl training, epoch3, iter0, batch625/1133, batch loss:0.00010074343299493194, Training time:60359.99405503273
batch reward last col mean 3.0797903036727803e-06 first col mean 0.0011002251412719488 all mean 5.725136725232005e-05
0.00029656337574124336 0.00029656337574124336
rl training, epoch3, iter0, batch626/1133, batch loss:0.00029656337574124336, Training time:60376.33188915253
batch reward last col mean 1.7274469428230077e-06 first col mean 9.624671292840503e-06 all mean 6.226323603186756e-05
0.00012216961476951838 0.00012216960021760315
rl training, epoch3, iter0, batch627/1133, batch loss:0.00012216960021760315, Training time:60392.4523935318
batch reward last col mean 1.5437532852047298e-07 first col mean 0.001464757602661848 all mean 9.258406498702243e-05
0.00020608151680789888 0.00020608150225598365
rl training, epoch3, iter0, batch628/1133, batch loss:0.00020608150225598365, Training time:60408.87219238281
batch reward last col mean 5.3068761189933866e-05 first col mean 2.409226362942718e-05 all mean 7.443963113473728e-05
0.000127892242744565 0.000127892242744565
rl training, epoch3, iter0, batch629/1133, batch loss:0.000127892242744565, Training time:60425.09372925758
batch reward last col mean 2.013757693930529e-07 first col mean 1.813643757486716e-05 all mean 0.00012198532931506634
0.00028097620815970004 0.00028097620815970004
rl training, epoch3, iter0, batch630/1133, batch loss:0.00028097620815970004, Training time:60441.30369877815
batch reward last col mean 3.4292941109015374e-06 first col mean 3.4085504012182355e-05 all mean 2.1887397451791912e-05
6.355383084155619e-05 6.355383084155619e-05
rl training, epoch3, iter0, batch631/1133, batch loss:6.355383084155619e-05, Training time:60457.44709897041
batch reward last col mean 3.7699450672334933e-07 first col mean 2.3630158466403373e-05 all mean 3.1027841032482684e-05
8.189748041331768e-05 8.189749496523291e-05
rl training, epoch3, iter0, batch632/1133, batch loss:8.189749496523291e-05, Training time:60473.55885100365
batch reward last col mean 1.56708708232145e-07 first col mean 3.492306132102385e-05 all mean 2.0082252376596443e-05
4.296158658689819e-05 4.296159386285581e-05
rl training, epoch3, iter0, batch633/1133, batch loss:4.296159386285581e-05, Training time:60489.7590816021
batch reward last col mean 4.4505789276172436e-08 first col mean 6.569087418029085e-06 all mean 3.026542253792286e-05
7.415324216708541e-05 7.415324216708541e-05
rl training, epoch3, iter0, batch634/1133, batch loss:7.415324216708541e-05, Training time:60505.85411763191
batch reward last col mean 4.410714993241527e-08 first col mean 0.0008081717533059418 all mean 1.8202435967396013e-05
4.1361257899552584e-05 4.136126153753139e-05
rl training, epoch3, iter0, batch635/1133, batch loss:4.136126153753139e-05, Training time:60521.94282579422
batch reward last col mean 6.661167049060168e-07 first col mean 6.109901278250618e-06 all mean 2.6117819288629107e-05
4.1371928091393784e-05 4.1371924453414977e-05
rl training, epoch3, iter0, batch636/1133, batch loss:4.1371924453414977e-05, Training time:60538.05328083038
batch reward last col mean 1.4253018321142008e-07 first col mean 0.00026032852474600077 all mean 6.666272383881733e-05
0.0002517459215596318 0.0002517459215596318
rl training, epoch3, iter0, batch637/1133, batch loss:0.0002517459215596318, Training time:60554.15343165398
batch reward last col mean 3.911973180947825e-06 first col mean 0.0014348459662869573 all mean 7.353878027061e-05
8.715924195712432e-05 8.715924195712432e-05
rl training, epoch3, iter0, batch638/1133, batch loss:8.715924195712432e-05, Training time:60570.27274274826
batch reward last col mean 1.1613590231718263e-06 first col mean 1.0290148111380404e-06 all mean 2.187609425163828e-05
5.4466418077936396e-05 5.446641443995759e-05
rl training, epoch3, iter0, batch639/1133, batch loss:5.446641443995759e-05, Training time:60586.37967586517
batch reward last col mean 1.1796528553986718e-07 first col mean 6.8128001657896675e-06 all mean 8.178110147127882e-05
0.0004010322445537895 0.0004010322445537895
rl training, epoch3, iter0, batch640/1133, batch loss:0.0004010322445537895, Training time:60602.62857866287
batch reward last col mean 7.967143034193214e-08 first col mean 8.866914868121967e-05 all mean 3.4128686820622534e-05
0.00011748214456019923 0.00011748214456019923
rl training, epoch3, iter0, batch641/1133, batch loss:0.00011748214456019923, Training time:60618.91511583328
batch reward last col mean 1.2183508601992799e-07 first col mean 0.0006649868446402252 all mean 2.7092606615042314e-05
5.895578215131536e-05 5.895578215131536e-05
rl training, epoch3, iter0, batch642/1133, batch loss:5.895578215131536e-05, Training time:60635.040006399155
batch reward last col mean 8.551059522687865e-07 first col mean 2.569896423665341e-06 all mean 1.2680952750088181e-05
4.3095216824440286e-05 4.3095216824440286e-05
rl training, epoch3, iter0, batch643/1133, batch loss:4.3095216824440286e-05, Training time:60651.22311282158
batch reward last col mean 6.217424015630968e-07 first col mean 0.0003485797205939889 all mean 5.434986451291479e-05
0.00027561397291719913 0.00027561397291719913
rl training, epoch3, iter0, batch644/1133, batch loss:0.00027561397291719913, Training time:60667.306344270706
batch reward last col mean 0.0002809440775308758 first col mean 0.0024242608342319727 all mean 0.0003049406222999096
9.808608592720702e-05 9.808610047912225e-05
rl training, epoch3, iter0, batch645/1133, batch loss:9.808610047912225e-05, Training time:60683.460463523865
batch reward last col mean 5.118809349369258e-05 first col mean 8.523096767021343e-06 all mean 6.85163468006067e-05
0.00016599107766523957 0.0001659910922171548
rl training, epoch3, iter0, batch646/1133, batch loss:0.0001659910922171548, Training time:60699.86636710167
batch reward last col mean 0.0017359163612127304 first col mean 6.129578832769766e-05 all mean 0.0015962623292580247
0.00022592631285078824 0.00022592631285078824
rl training, epoch3, iter0, batch647/1133, batch loss:0.00022592631285078824, Training time:60716.02041888237
batch reward last col mean 2.0167108516488952e-07 first col mean 3.4992531254829373e-06 all mean 4.522591189015657e-05
0.00011750314297387376 0.00011750314297387376
rl training, epoch3, iter0, batch648/1133, batch loss:0.00011750314297387376, Training time:60732.15876984596
batch reward last col mean 2.85836049442878e-05 first col mean 2.482197669451125e-05 all mean 4.587375951814465e-05
5.884942947886884e-05 5.884942947886884e-05
rl training, epoch3, iter0, batch649/1133, batch loss:5.884942947886884e-05, Training time:60748.26716256142
batch reward last col mean 6.112285433346187e-08 first col mean 0.00018364290008321404 all mean 3.645600736490451e-05
4.809687379747629e-05 4.809688471141271e-05
rl training, epoch3, iter0, batch650/1133, batch loss:4.809688471141271e-05, Training time:60764.26850628853
batch reward last col mean 0.00014290596300270408 first col mean 4.7484678361797705e-05 all mean 0.00016524753300473094
0.00016503392544109374 0.00016503392544109374
rl training, epoch3, iter0, batch651/1133, batch loss:0.00016503392544109374, Training time:60780.41729450226
batch reward last col mean 0.00028999801725149155 first col mean 0.001361483009532094 all mean 0.00032270519295707345
0.0002627932117320597 0.0002627932408358902
rl training, epoch3, iter0, batch652/1133, batch loss:0.0002627932408358902, Training time:60796.648443460464
batch reward last col mean 3.235453505112673e-07 first col mean 1.344996803709364e-06 all mean 1.7060989193851128e-05
8.269812678918242e-05 8.269812678918242e-05
rl training, epoch3, iter0, batch653/1133, batch loss:8.269812678918242e-05, Training time:60812.775161743164
batch reward last col mean 8.251824397120799e-07 first col mean 5.338727987691527e-06 all mean 6.917757127666846e-05
0.0001675069215707481 0.00016750689246691763
rl training, epoch3, iter0, batch654/1133, batch loss:0.00016750689246691763, Training time:60828.93200802803
batch reward last col mean 1.379201989948342e-06 first col mean 7.648284736205824e-06 all mean 4.143673140788451e-05
8.328898547915742e-05 8.328899275511503e-05
rl training, epoch3, iter0, batch655/1133, batch loss:8.328899275511503e-05, Training time:60845.35578727722
batch reward last col mean 1.902796839203802e-06 first col mean 0.0011162770679220557 all mean 5.0108494178857654e-05
0.00018053952953778207 0.00018053952953778207
rl training, epoch3, iter0, batch656/1133, batch loss:0.00018053952953778207, Training time:60861.45127391815
batch reward last col mean 2.5000026653287932e-05 first col mean 0.00023782772768754512 all mean 6.49602006888017e-05
7.109780563041568e-05 7.109781290637329e-05
rl training, epoch3, iter0, batch657/1133, batch loss:7.109781290637329e-05, Training time:60877.541758298874
batch reward last col mean 5.217627403908409e-06 first col mean 3.8240246794885024e-05 all mean 4.3201231164857745e-05
0.00010159509110962972 0.00010159509110962972
rl training, epoch3, iter0, batch658/1133, batch loss:0.00010159509110962972, Training time:60893.878667116165
batch reward last col mean 1.8229997067464865e-07 first col mean 2.1570314856944606e-05 all mean 4.3165568058611825e-05
8.672472176840529e-05 8.672472176840529e-05
rl training, epoch3, iter0, batch659/1133, batch loss:8.672472176840529e-05, Training time:60909.81177902222
batch reward last col mean 2.891499946144904e-07 first col mean 0.00046600395580753684 all mean 2.0298351955716498e-05
5.744018199038692e-05 5.7440185628365725e-05
rl training, epoch3, iter0, batch660/1133, batch loss:5.7440185628365725e-05, Training time:60925.74395823479
batch reward last col mean 3.6423962512799335e-08 first col mean 9.85812675935449e-06 all mean 8.424695261055604e-05
0.00030308644636534154 0.00030308644636534154
rl training, epoch3, iter0, batch661/1133, batch loss:0.00030308644636534154, Training time:60941.67336797714
batch reward last col mean 1.0309925528417807e-05 first col mean 0.0003767544694710523 all mean 5.0859209295595065e-05
0.00016747554764151573 0.00016747554764151573
rl training, epoch3, iter0, batch662/1133, batch loss:0.00016747554764151573, Training time:60957.92157244682
batch reward last col mean 6.235839009605115e-07 first col mean 0.0003414607490412891 all mean 0.00010103012027684599
0.0002594908874016255 0.0002594908874016255
rl training, epoch3, iter0, batch663/1133, batch loss:0.0002594908874016255, Training time:60974.05030155182
batch reward last col mean 4.237719508637383e-07 first col mean 0.00012840869021601975 all mean 2.297855644428637e-05
1.7901384126162156e-05 1.790138048818335e-05
rl training, epoch3, iter0, batch664/1133, batch loss:1.790138048818335e-05, Training time:60990.23400950432
batch reward last col mean 0.0027371218893676996 first col mean 2.683327329577878e-05 all mean 0.0025650961324572563
0.0007859827019274235 0.0007859827019274235
rl training, epoch3, iter0, batch665/1133, batch loss:0.0007859827019274235, Training time:61006.48156762123
batch reward last col mean 8.914341015042737e-05 first col mean 0.0016472248826175928 all mean 0.0001325057673966512
9.496115671936423e-05 9.496114944340661e-05
rl training, epoch3, iter0, batch666/1133, batch loss:9.496114944340661e-05, Training time:61022.806527137756
batch reward last col mean 5.2927083743270487e-05 first col mean 9.00274358173192e-07 all mean 5.8680354413809255e-05
3.211439980077557e-05 3.211439980077557e-05
rl training, epoch3, iter0, batch667/1133, batch loss:3.211439980077557e-05, Training time:61039.14533448219
batch reward last col mean 1.1410995284677483e-05 first col mean 0.0015594731085002422 all mean 7.941853255033493e-05
0.0001748305803630501 0.00017483060946688056
rl training, epoch3, iter0, batch668/1133, batch loss:0.00017483060946688056, Training time:61055.4557993412
batch reward last col mean 6.773784377855918e-08 first col mean 5.6018849136307836e-05 all mean 5.455131031339988e-05
0.00020648665667977184 0.00020648665667977184
rl training, epoch3, iter0, batch669/1133, batch loss:0.00020648665667977184, Training time:61071.81395769119
batch reward last col mean 4.508364952471311e-07 first col mean 0.0006348409806378186 all mean 1.5747133147669956e-05
6.033464160282165e-05 6.033463796484284e-05
rl training, epoch3, iter0, batch670/1133, batch loss:6.033463796484284e-05, Training time:61088.08908843994
batch reward last col mean 1.9066013692281558e-06 first col mean 0.0004683291190303862 all mean 3.985297735198401e-05
9.340927499579266e-05 9.340928227175027e-05
rl training, epoch3, iter0, batch671/1133, batch loss:9.340928227175027e-05, Training time:61104.38831567764
batch reward last col mean 0.0003542493504937738 first col mean 2.6052853172586765e-06 all mean 0.00039540682337246835
0.00037072840495966375 0.00037072840495966375
rl training, epoch3, iter0, batch672/1133, batch loss:0.00037072840495966375, Training time:61120.58639860153
batch reward last col mean 9.334241468650362e-08 first col mean 4.493535016081296e-05 all mean 2.788959682220593e-05
5.23520793649368e-05 5.23520793649368e-05
rl training, epoch3, iter0, batch673/1133, batch loss:5.23520793649368e-05, Training time:61136.7461502552
batch reward last col mean 1.3021377753830166e-06 first col mean 0.00023810385027900338 all mean 6.693864997942e-05
0.0002690151159185916 0.0002690151159185916
rl training, epoch3, iter0, batch674/1133, batch loss:0.0002690151159185916, Training time:61153.01542234421
batch reward last col mean 0.0004509227001108229 first col mean 0.00018433720106258988 all mean 0.00040252768667414784
3.2197207474382594e-05 3.2197207474382594e-05
rl training, epoch3, iter0, batch675/1133, batch loss:3.2197207474382594e-05, Training time:61169.26211357117
batch reward last col mean 6.292745524660859e-08 first col mean 0.00025782166630961 all mean 4.5845798013033345e-05
0.00014298454334493726 0.00014298454334493726
rl training, epoch3, iter0, batch676/1133, batch loss:0.00014298454334493726, Training time:61185.52709364891
batch reward last col mean 3.0716364562977105e-05 first col mean 1.6167931562449667e-06 all mean 4.5210792450234294e-05
2.08331966859987e-05 2.08331966859987e-05
rl training, epoch3, iter0, batch677/1133, batch loss:2.08331966859987e-05, Training time:61201.72190451622
batch reward last col mean 0.000547023955732584 first col mean 0.0008127835462801158 all mean 0.0006277425563894212
0.0004887485993094742 0.0004887485993094742
rl training, epoch3, iter0, batch678/1133, batch loss:0.0004887485993094742, Training time:61217.910803318024
batch reward last col mean 5.381282335292781e-07 first col mean 0.0006113794515840709 all mean 4.915994213661179e-05
7.881245983298868e-05 7.881245255703107e-05
rl training, epoch3, iter0, batch679/1133, batch loss:7.881245255703107e-05, Training time:61234.108459472656
batch reward last col mean 2.333892189199105e-05 first col mean 9.164427319774404e-05 all mean 6.036453851265833e-05
0.00010798269067890942 0.00010798270523082465
rl training, epoch3, iter0, batch680/1133, batch loss:0.00010798270523082465, Training time:61250.34252548218
batch reward last col mean 2.18998047785135e-06 first col mean 8.830836122797336e-06 all mean 4.264625022187829e-05
0.00016734063683543354 0.00016734062228351831
rl training, epoch3, iter0, batch681/1133, batch loss:0.00016734062228351831, Training time:61266.55631017685
batch reward last col mean 1.0063010336125444e-07 first col mean 3.783603915508138e-06 all mean 5.5861197324702516e-05
9.584511280991137e-05 9.584511280991137e-05
rl training, epoch3, iter0, batch682/1133, batch loss:9.584511280991137e-05, Training time:61282.76581287384
batch reward last col mean 9.942818905983586e-07 first col mean 9.882778613246046e-06 all mean 5.4481391998706385e-05
0.00027115788543596864 0.00027115788543596864
rl training, epoch3, iter0, batch683/1133, batch loss:0.00027115788543596864, Training time:61299.05666446686
batch reward last col mean 1.8933884575744742e-06 first col mean 0.0016999158542603254 all mean 4.414266732055694e-05
5.26467920280993e-05 5.2646784752141684e-05
rl training, epoch3, iter0, batch684/1133, batch loss:5.2646784752141684e-05, Training time:61315.30475091934
batch reward last col mean 0.0003965801151935011 first col mean 6.4855898926907685e-06 all mean 5.7035555073525757e-05
8.010593592189252e-05 8.010593592189252e-05
rl training, epoch3, iter0, batch685/1133, batch loss:8.010593592189252e-05, Training time:61331.53642010689
batch reward last col mean 3.571437991922721e-05 first col mean 3.2222854429164727e-07 all mean 4.022216307930648e-05
1.2610120393219404e-05 1.2610120393219404e-05
rl training, epoch3, iter0, batch686/1133, batch loss:1.2610120393219404e-05, Training time:61347.785950899124
batch reward last col mean 3.076380744460039e-05 first col mean 0.0003523541090544313 all mean 5.74008263356518e-05
0.00013617130753118545 0.00013617130753118545
rl training, epoch3, iter0, batch687/1133, batch loss:0.00013617130753118545, Training time:61364.42884373665
batch reward last col mean 0.00014134429511614144 first col mean 4.526290467765648e-06 all mean 0.0001633111241972074
7.511092553613707e-05 7.511091826017946e-05
rl training, epoch3, iter0, batch688/1133, batch loss:7.511091826017946e-05, Training time:61380.634355306625
batch reward last col mean 0.0010055390885099769 first col mean 2.1055966499261558e-05 all mean 0.0009757467778399587
0.0004314535763114691 0.0004314535763114691
rl training, epoch3, iter0, batch689/1133, batch loss:0.0004314535763114691, Training time:61396.76281261444
batch reward last col mean 3.197174009983428e-05 first col mean 2.7071357635577442e-06 all mean 6.722968100802973e-05
0.00012050354416714981 0.00012050354416714981
rl training, epoch3, iter0, batch690/1133, batch loss:0.00012050354416714981, Training time:61412.84988617897
batch reward last col mean 4.171178079559468e-05 first col mean 0.0022662749979645014 all mean 0.00015207892283797264
0.0003125779330730438 0.0003125779330730438
rl training, epoch3, iter0, batch691/1133, batch loss:0.0003125779330730438, Training time:61428.97508454323
batch reward last col mean 0.0003989671531599015 first col mean 1.8960557781610987e-06 all mean 0.0003632541047409177
0.00010798477160278708 0.00010798476432682946
rl training, epoch3, iter0, batch692/1133, batch loss:0.00010798476432682946, Training time:61445.09660077095
batch reward last col mean 0.00018646095122676343 first col mean 0.001590679050423205 all mean 7.527472189394757e-05
0.00026765523944050074 0.00026765523944050074
rl training, epoch3, iter0, batch693/1133, batch loss:0.00026765523944050074, Training time:61461.20683884621
batch reward last col mean 6.1951000134286005e-06 first col mean 6.275045052461792e-06 all mean 2.3757171220495366e-05
3.913854743586853e-05 3.9138543797889724e-05
rl training, epoch3, iter0, batch694/1133, batch loss:3.9138543797889724e-05, Training time:61477.14867734909
batch reward last col mean 5.466562470246572e-06 first col mean 3.676220501347416e-07 all mean 5.9177098592044786e-05
0.00019798801804427058 0.00019798801804427058
rl training, epoch3, iter0, batch695/1133, batch loss:0.00019798801804427058, Training time:61493.0708963871
batch reward last col mean 0.00015562452608719468 first col mean 0.0001293487148359418 all mean 0.00018276234914083034
0.0002134047244908288 0.0002134047244908288
rl training, epoch3, iter0, batch696/1133, batch loss:0.0002134047244908288, Training time:61509.74061012268
batch reward last col mean 1.6445638948425767e-06 first col mean 0.00011868236470036209 all mean 5.066539233666845e-05
0.00011562634608708322 0.00011562636063899845
rl training, epoch3, iter0, batch697/1133, batch loss:0.00011562636063899845, Training time:61525.91005682945
batch reward last col mean 7.612103217979893e-06 first col mean 4.8601919843349606e-05 all mean 6.265518459258601e-05
0.00027801436954177916 0.00027801436954177916
rl training, epoch3, iter0, batch698/1133, batch loss:0.00027801436954177916, Training time:61542.050143003464
batch reward last col mean 2.4262395527330227e-05 first col mean 8.356881835425156e-07 all mean 2.235775718872901e-05
3.518069934216328e-05 3.518069934216328e-05
rl training, epoch3, iter0, batch699/1133, batch loss:3.518069934216328e-05, Training time:61558.17994642258
batch reward last col mean 0.007022743579000235 first col mean 0.0016900754999369383 all mean 0.006403298117220402
0.0006059322040528059 0.0006059322040528059
rl training, epoch3, iter0, batch700/1133, batch loss:0.0006059322040528059, Training time:61574.61152386665
batch reward last col mean 1.9721796888916288e-06 first col mean 0.00010239932453259826 all mean 2.8315258532529697e-05
0.00012165650696260855 0.00012165650696260855
rl training, epoch3, iter0, batch701/1133, batch loss:0.00012165650696260855, Training time:61591.10245203972
batch reward last col mean 3.0349981898325495e-05 first col mean 3.4934041650558356e-06 all mean 7.999293302418664e-05
9.234946628566831e-05 9.234948083758354e-05
rl training, epoch3, iter0, batch702/1133, batch loss:9.234948083758354e-05, Training time:61607.66657614708
batch reward last col mean 1.3476092419750785e-07 first col mean 5.013543614040827e-06 all mean 3.647051562438719e-05
0.0001526887499494478 0.0001526887499494478
rl training, epoch3, iter0, batch703/1133, batch loss:0.0001526887499494478, Training time:61624.04351258278
batch reward last col mean 4.1053490349440835e-06 first col mean 0.0017782336799427867 all mean 6.265161209739745e-05
0.00014446600107476115 0.00014446600107476115
rl training, epoch3, iter0, batch704/1133, batch loss:0.00014446600107476115, Training time:61640.426996946335
batch reward last col mean 0.0006065125926397741 first col mean 0.0003498622972983867 all mean 0.0006066836067475379
0.00011574766540434211 0.00011574767268029973
rl training, epoch3, iter0, batch705/1133, batch loss:0.00011574767268029973, Training time:61656.62832856178
batch reward last col mean 0.0019383933395147324 first col mean 1.1533124052220955e-05 all mean 0.001818294869735837
0.00020076018699910492 0.00020076018699910492
rl training, epoch3, iter0, batch706/1133, batch loss:0.00020076018699910492, Training time:61672.79630899429
batch reward last col mean 5.80338962663518e-07 first col mean 6.067579670343548e-05 all mean 9.260785736842081e-05
0.00022969624842517078 0.00022969624842517078
rl training, epoch3, iter0, batch707/1133, batch loss:0.00022969624842517078, Training time:61688.97533130646
batch reward last col mean 7.075644248288881e-08 first col mean 2.2615286070504226e-06 all mean 4.513393287197687e-05
0.00015961479221004993 0.00015961479221004993
rl training, epoch3, iter0, batch708/1133, batch loss:0.00015961479221004993, Training time:61705.10936355591
batch reward last col mean 0.00014712830306962132 first col mean 4.81209372082958e-06 all mean 0.0001801240723580122
0.0002950474445242435 0.0002950474445242435
rl training, epoch3, iter0, batch709/1133, batch loss:0.0002950474445242435, Training time:61721.22619700432
batch reward last col mean 0.0007731139194220304 first col mean 0.0017809320706874132 all mean 0.0007071052677929401
0.00022242992417886853 0.0002224299096269533
rl training, epoch3, iter0, batch710/1133, batch loss:0.0002224299096269533, Training time:61737.38573527336
batch reward last col mean 0.00342327612452209 first col mean 0.0005318254698067904 all mean 0.0033157402649521828
0.0004559834487736225 0.0004559834487736225
rl training, epoch3, iter0, batch711/1133, batch loss:0.0004559834487736225, Training time:61753.46614098549
batch reward last col mean 4.5662250158784445e-06 first col mean 0.0015054307878017426 all mean 7.437006570398808e-05
0.00021442949946504086 0.00021442949946504086
rl training, epoch3, iter0, batch712/1133, batch loss:0.00021442949946504086, Training time:61769.57022476196
batch reward last col mean 1.7261172615690157e-06 first col mean 0.00013994831533636898 all mean 3.3812520996434614e-05
3.8575748476432636e-05 3.8575748476432636e-05
rl training, epoch3, iter0, batch713/1133, batch loss:3.8575748476432636e-05, Training time:61785.64705991745
batch reward last col mean 1.1289010615200823e-07 first col mean 9.545893408358097e-05 all mean 8.359186176676303e-05
0.00020389119163155556 0.00020389119163155556
rl training, epoch3, iter0, batch714/1133, batch loss:0.00020389119163155556, Training time:61801.72384953499
batch reward last col mean 1.6245607525888772e-07 first col mean 9.164316907117609e-06 all mean 4.1927414713427424e-05
9.699651855044067e-05 9.69965331023559e-05
rl training, epoch3, iter0, batch715/1133, batch loss:9.69965331023559e-05, Training time:61817.812027454376
batch reward last col mean 4.346903097030008e-06 first col mean 0.0009199075284413993 all mean 3.98436350224074e-05
8.480835822410882e-05 8.480835822410882e-05
rl training, epoch3, iter0, batch716/1133, batch loss:8.480835822410882e-05, Training time:61833.79803609848
batch reward last col mean 1.6466072338516824e-05 first col mean 0.00038213105290196836 all mean 6.948503869352862e-05
0.00024454330559819937 0.00024454330559819937
rl training, epoch3, iter0, batch717/1133, batch loss:0.00024454330559819937, Training time:61849.75211811066
batch reward last col mean 3.719935557455756e-05 first col mean 0.0004014544247183949 all mean 4.398281089379452e-05
2.434375710436143e-05 2.434375710436143e-05
rl training, epoch3, iter0, batch718/1133, batch loss:2.434375710436143e-05, Training time:61866.1039121151
batch reward last col mean 5.757905455539003e-05 first col mean 0.00010511581058381125 all mean 9.941363532561809e-05
0.00022372693638317287 0.00022372693638317287
rl training, epoch3, iter0, batch719/1133, batch loss:0.00022372693638317287, Training time:61882.42300367355
batch reward last col mean 6.176086753839627e-05 first col mean 5.036356014898047e-05 all mean 0.000117803159810137
9.118146408582106e-05 9.11814859136939e-05
rl training, epoch3, iter0, batch720/1133, batch loss:9.11814859136939e-05, Training time:61899.10492372513
batch reward last col mean 2.5906885639415123e-05 first col mean 9.59576300374465e-06 all mean 6.313770427368581e-05
0.00013893000141251832 0.00013893000141251832
rl training, epoch3, iter0, batch721/1133, batch loss:0.00013893000141251832, Training time:61915.663449048996
batch reward last col mean 1.5467551293113502e-06 first col mean 3.7633035390172154e-06 all mean 6.167755054775625e-05
0.00011743576760636643 0.00011743576033040881
rl training, epoch3, iter0, batch722/1133, batch loss:0.00011743576033040881, Training time:61932.334219932556
batch reward last col mean 3.670180888093455e-07 first col mean 0.0005342332297004759 all mean 2.8721367925754748e-05
6.424036109820008e-05 6.424036109820008e-05
rl training, epoch3, iter0, batch723/1133, batch loss:6.424036109820008e-05, Training time:61948.83396816254
batch reward last col mean 3.2105731406772975e-06 first col mean 2.877125780287315e-06 all mean 2.2373766114469618e-05
8.066353620961308e-05 8.066355076152831e-05
rl training, epoch3, iter0, batch724/1133, batch loss:8.066355076152831e-05, Training time:61965.105999708176
batch reward last col mean 2.0461179701669607e-06 first col mean 0.001197956153191626 all mean 4.8937323299469426e-05
0.00012214721937198192 0.00012214721937198192
rl training, epoch3, iter0, batch725/1133, batch loss:0.00012214721937198192, Training time:61981.65647792816
batch reward last col mean 1.346762701359694e-07 first col mean 4.72946658192086e-06 all mean 5.2834104280918837e-05
0.00010853620187845081 0.00010853620915440843
rl training, epoch3, iter0, batch726/1133, batch loss:0.00010853620915440843, Training time:61998.863961458206
batch reward last col mean 4.081562110513914e-06 first col mean 6.221403964445926e-06 all mean 3.0554208933608606e-05
0.0001187120724353008 0.0001187120724353008
rl training, epoch3, iter0, batch727/1133, batch loss:0.0001187120724353008, Training time:62016.43518471718
batch reward last col mean 2.9635978648911987e-07 first col mean 0.0003903553879354149 all mean 7.905055826995522e-05
0.0001705519389361143 0.00017055192438419908
rl training, epoch3, iter0, batch728/1133, batch loss:0.00017055192438419908, Training time:62032.51575636864
batch reward last col mean 4.834192282032745e-07 first col mean 6.25422717348556e-06 all mean 4.6889548684703186e-05
0.0002556434483267367 0.00025564347743056715
rl training, epoch3, iter0, batch729/1133, batch loss:0.00025564347743056715, Training time:62048.57957601547
batch reward last col mean 6.623377703363076e-05 first col mean 0.00192132662050426 all mean 0.0001029525010380894
0.0001243880542460829 0.0001243880542460829
rl training, epoch3, iter0, batch730/1133, batch loss:0.0001243880542460829, Training time:62064.62147021294
batch reward last col mean 5.2061001042602584e-05 first col mean 0.0019538868218660355 all mean 0.00012894932297058403
0.00024442787980660796 0.0002444278507027775
rl training, epoch3, iter0, batch731/1133, batch loss:0.0002444278507027775, Training time:62080.70759987831
batch reward last col mean 1.9080674974247813e-05 first col mean 8.870498277246952e-05 all mean 6.547340308316052e-05
0.00020091272017452866 0.00020091272017452866
rl training, epoch3, iter0, batch732/1133, batch loss:0.00020091272017452866, Training time:62096.686470746994
batch reward last col mean 3.0996529858384747e-06 first col mean 3.227929994409351e-07 all mean 1.3006975677853916e-05
1.876978058135137e-05 1.876978058135137e-05
rl training, epoch3, iter0, batch733/1133, batch loss:1.876978058135137e-05, Training time:62112.67165231705
batch reward last col mean 1.1325553714414127e-05 first col mean 9.366244921693578e-05 all mean 5.058476745034568e-05
0.00017975963419303298 0.00017975963419303298
rl training, epoch3, iter0, batch734/1133, batch loss:0.00017975963419303298, Training time:62128.690032720566
batch reward last col mean 4.945022737956606e-05 first col mean 0.0006440554861910641 all mean 7.838923920644447e-05
0.00013446972297970206 0.00013446972297970206
rl training, epoch3, iter0, batch735/1133, batch loss:0.00013446972297970206, Training time:62144.73518204689
batch reward last col mean 0.006461903918534517 first col mean 2.625145498313941e-06 all mean 0.005854220129549503
0.00044480993528850377 0.00044480993528850377
rl training, epoch3, iter0, batch736/1133, batch loss:0.00044480993528850377, Training time:62160.90007138252
batch reward last col mean 1.2545438039524015e-05 first col mean 0.0006142578786239028 all mean 6.502879114123061e-05
0.00033121637534350157 0.00033121637534350157
rl training, epoch3, iter0, batch737/1133, batch loss:0.00033121637534350157, Training time:62177.032317876816
batch reward last col mean 0.0008910814649425447 first col mean 6.338406819850206e-05 all mean 0.0008188800420612097
0.00010389667295385152 0.00010389666567789391
rl training, epoch3, iter0, batch738/1133, batch loss:0.00010389666567789391, Training time:62193.22860407829
batch reward last col mean 1.0828294989551068e-06 first col mean 0.0003282993275206536 all mean 3.952265251427889e-05
6.877449050080031e-05 6.877449777675793e-05
rl training, epoch3, iter0, batch739/1133, batch loss:6.877449777675793e-05, Training time:62209.32114195824
batch reward last col mean 1.7224432440343662e-06 first col mean 0.003064148360863328 all mean 9.3932292656973e-05
0.0001923169766087085 0.00019231700571253896
rl training, epoch3, iter0, batch740/1133, batch loss:0.00019231700571253896, Training time:62225.38725709915
batch reward last col mean 7.598636784678092e-06 first col mean 3.233877578168176e-06 all mean 4.974160037818365e-05
9.962508192984387e-05 9.962508192984387e-05
rl training, epoch3, iter0, batch741/1133, batch loss:9.962508192984387e-05, Training time:62241.71292376518
batch reward last col mean 4.9755628424463794e-05 first col mean 0.0003234314208384603 all mean 7.460525375790894e-05
0.00016280548879876733 0.00016280550335068256
rl training, epoch3, iter0, batch742/1133, batch loss:0.00016280550335068256, Training time:62258.194752693176
batch reward last col mean 0.002759238937869668 first col mean 2.9878892746637575e-05 all mean 0.00235243933275342
0.0003064255288336426 0.0003064255288336426
rl training, epoch3, iter0, batch743/1133, batch loss:0.0003064255288336426, Training time:62274.641380786896
batch reward last col mean 4.170823558524717e-06 first col mean 0.0003739147214218974 all mean 4.652183997677639e-05
8.502275159116834e-05 8.502273703925312e-05
rl training, epoch3, iter0, batch744/1133, batch loss:8.502273703925312e-05, Training time:62291.296872615814
batch reward last col mean 3.0320185828713875e-07 first col mean 7.941430521896109e-05 all mean 3.0446517484961078e-05
0.00012941888417117298 0.00012941888417117298
rl training, epoch3, iter0, batch745/1133, batch loss:0.00012941888417117298, Training time:62307.87116742134
batch reward last col mean 0.0012026596814393997 first col mean 5.391672675614245e-05 all mean 0.0011444289702922106
0.00034892227267846465 0.00034892227267846465
rl training, epoch3, iter0, batch746/1133, batch loss:0.00034892227267846465, Training time:62324.47277903557
batch reward last col mean 3.287922027084278e-06 first col mean 7.787721187924035e-06 all mean 9.929545922204852e-05
0.00032826949609443545 0.00032826943788677454
rl training, epoch3, iter0, batch747/1133, batch loss:0.00032826943788677454, Training time:62340.896721601486
batch reward last col mean 3.443343302933499e-05 first col mean 4.5574533942271955e-06 all mean 2.8361628210404888e-05
2.9495908165699802e-05 2.94959063467104e-05
rl training, epoch3, iter0, batch748/1133, batch loss:2.94959063467104e-05, Training time:62357.31722021103
batch reward last col mean 0.00026499645900912583 first col mean 9.027288615470752e-05 all mean 0.00017194201063830405
0.0007445461233146489 0.0007445461233146489
rl training, epoch3, iter0, batch749/1133, batch loss:0.0007445461233146489, Training time:62373.782997608185
batch reward last col mean 0.00013478331675287336 first col mean 0.0001412452693330124 all mean 0.00015925434126984328
0.00012835727829951793 0.00012835727829951793
rl training, epoch3, iter0, batch750/1133, batch loss:0.00012835727829951793, Training time:62390.30374765396
batch reward last col mean 2.5031637051142752e-05 first col mean 0.000753089552745223 all mean 8.715373405721039e-05
0.0003419396234676242 0.0003419396234676242
rl training, epoch3, iter0, batch751/1133, batch loss:0.0003419396234676242, Training time:62406.740025281906
batch reward last col mean 0.004775147419422865 first col mean 0.00024734518956393003 all mean 0.0035190109629184008
0.0003312791232019663 0.0003312791232019663
rl training, epoch3, iter0, batch752/1133, batch loss:0.0003312791232019663, Training time:62423.388964891434
batch reward last col mean 2.5426234060432762e-05 first col mean 0.0007206595619209111 all mean 0.00010531925363466144
0.00013080026837997139 0.00013080026837997139
rl training, epoch3, iter0, batch753/1133, batch loss:0.00013080026837997139, Training time:62439.9844148159
batch reward last col mean 8.508438440912869e-06 first col mean 0.0010676543461158872 all mean 0.00010800972813740373
0.00024332113389391452 0.00024332113389391452
rl training, epoch3, iter0, batch754/1133, batch loss:0.00024332113389391452, Training time:62456.675733327866
batch reward last col mean 1.290429736400256e-06 first col mean 0.0008917026570998132 all mean 3.685386764118448e-05
6.666930858045816e-05 6.666930858045816e-05
rl training, epoch3, iter0, batch755/1133, batch loss:6.666930858045816e-05, Training time:62473.39730334282
batch reward last col mean 1.0036865205620416e-07 first col mean 2.8639785796258366e-06 all mean 2.6978437745128758e-05
6.888055213494226e-05 6.888055213494226e-05
rl training, epoch3, iter0, batch756/1133, batch loss:6.888055213494226e-05, Training time:62490.239881038666
batch reward last col mean 2.8185281735204626e-06 first col mean 0.0031287723686546087 all mean 0.00011652849207166582
0.0005328002735041082 0.0005328002735041082
rl training, epoch3, iter0, batch757/1133, batch loss:0.0005328002735041082, Training time:62507.13799571991
batch reward last col mean 0.000999891897663474 first col mean 0.00018120389722753316 all mean 0.0008023450500331819
0.00012004758173134178 0.00012004758173134178
rl training, epoch3, iter0, batch758/1133, batch loss:0.00012004758173134178, Training time:62523.670493125916
batch reward last col mean 0.00119505962356925 first col mean 9.687190322438255e-05 all mean 0.0011677421862259507
0.00024372691405005753 0.00024372691405005753
rl training, epoch3, iter0, batch759/1133, batch loss:0.00024372691405005753, Training time:62540.639631032944
batch reward last col mean 1.9391423847991973e-05 first col mean 0.0005140046705491841 all mean 0.00010275695967720821
0.0004166209255345166 0.0004166209255345166
rl training, epoch3, iter0, batch760/1133, batch loss:0.0004166209255345166, Training time:62557.91992378235
batch reward last col mean 0.0020240871235728264 first col mean 0.0001687417970970273 all mean 0.0018201256170868874
0.0005250100512057543 0.0005250100512057543
rl training, epoch3, iter0, batch761/1133, batch loss:0.0005250100512057543, Training time:62574.40185403824
batch reward last col mean 9.380519259138964e-06 first col mean 3.965001451433636e-05 all mean 2.4501667212462053e-05
3.920005474356003e-05 3.920005474356003e-05
rl training, epoch3, iter0, batch762/1133, batch loss:3.920005474356003e-05, Training time:62590.95635962486
batch reward last col mean 3.1919574894345715e-07 first col mean 1.0960797226289287e-05 all mean 6.963864871067926e-05
0.00023442717792931944 0.00023442714882548898
rl training, epoch3, iter0, batch763/1133, batch loss:0.00023442714882548898, Training time:62607.439094781876
batch reward last col mean 0.004720701836049557 first col mean 0.00010895389277720824 all mean 0.004459969233721495
0.00047702918527647853 0.00047702918527647853
rl training, epoch3, iter0, batch764/1133, batch loss:0.00047702918527647853, Training time:62624.16871833801
batch reward last col mean 9.821945212706851e-08 first col mean 0.0028038625605404377 all mean 0.0001395811268594116
0.0004392371920403093 0.00043923722114413977
rl training, epoch3, iter0, batch765/1133, batch loss:0.00043923722114413977, Training time:62640.54776072502
batch reward last col mean 0.00012415590754244477 first col mean 1.6107949704746716e-05 all mean 0.00016301330470014364
0.0002112238435074687 0.00021122387261129916
rl training, epoch3, iter0, batch766/1133, batch loss:0.00021122387261129916, Training time:62656.83764028549
batch reward last col mean 0.00021399765682872385 first col mean 0.0002228389639640227 all mean 0.0002642114704940468
0.00032752816332504153 0.00032752816332504153
rl training, epoch3, iter0, batch767/1133, batch loss:0.00032752816332504153, Training time:62673.10260081291
batch reward last col mean 3.1958015824784525e-06 first col mean 7.74538548853343e-08 all mean 8.29978016554378e-05
0.0003062874311581254 0.0003062874311581254
rl training, epoch3, iter0, batch768/1133, batch loss:0.0003062874311581254, Training time:62689.41271686554
batch reward last col mean 8.660272783345135e-07 first col mean 5.1571255426097196e-06 all mean 0.00011336775060044602
0.0005017383373342454 0.0005017383373342454
rl training, epoch3, iter0, batch769/1133, batch loss:0.0005017383373342454, Training time:62705.749475479126
batch reward last col mean 4.125539999222383e-05 first col mean 2.1714937247452326e-05 all mean 9.772624616743997e-05
0.0001708420313661918 0.0001708420313661918
rl training, epoch3, iter0, batch770/1133, batch loss:0.0001708420313661918, Training time:62722.21085476875
batch reward last col mean 6.590372504433617e-05 first col mean 3.873892637784593e-05 all mean 0.0001244310406036675
0.000144549339893274 0.000144549339893274
rl training, epoch3, iter0, batch771/1133, batch loss:0.000144549339893274, Training time:62738.80180096626
batch reward last col mean 7.622417342645349e-06 first col mean 0.00029219346470199525 all mean 8.861810056259856e-05
0.00040103570790961385 0.00040103570790961385
rl training, epoch3, iter0, batch772/1133, batch loss:0.00040103570790961385, Training time:62755.399826049805
batch reward last col mean 6.394498655026837e-07 first col mean 0.00037657908978872 all mean 6.926109199412167e-05
0.00029337391606532037 0.00029337391606532037
rl training, epoch3, iter0, batch773/1133, batch loss:0.00029337391606532037, Training time:62771.99799823761
batch reward last col mean 5.120089099364122e-07 first col mean 4.527251803665422e-05 all mean 7.188532617874444e-05
0.00033807088038884103 0.0003380708221811801
rl training, epoch3, iter0, batch774/1133, batch loss:0.0003380708221811801, Training time:62788.82105302811
batch reward last col mean 1.2276215784368105e-05 first col mean 0.0019397408468648791 all mean 0.00011104533768957481
0.0003062850737478584 0.0003062850737478584
rl training, epoch3, iter0, batch775/1133, batch loss:0.0003062850737478584, Training time:62806.61326980591
batch reward last col mean 1.4252254914026707e-06 first col mean 3.3029130008799257e-07 all mean 5.456508733914234e-05
0.00022480102779809386 0.00022480101324617863
rl training, epoch3, iter0, batch776/1133, batch loss:0.00022480101324617863, Training time:62823.34421181679
batch reward last col mean 3.4569357154623503e-08 first col mean 1.4207264030119404e-05 all mean 4.4591633923118934e-05
0.0001649128389544785 0.0001649128389544785
rl training, epoch3, iter0, batch777/1133, batch loss:0.0001649128389544785, Training time:62839.708114147186
batch reward last col mean 0.0034649032168090343 first col mean 0.00275651877745986 all mean 0.002940455451607704
0.00027057083207182586 0.00027057083207182586
rl training, epoch3, iter0, batch778/1133, batch loss:0.00027057083207182586, Training time:62856.081560373306
batch reward last col mean 8.290518849207729e-08 first col mean 0.001103491522371769 all mean 0.0001826312654884532
0.0007482104701921344 0.0007482104701921344
rl training, epoch3, iter0, batch779/1133, batch loss:0.0007482104701921344, Training time:62872.54014825821
batch reward last col mean 6.695650426991051e-06 first col mean 0.0012692211894318461 all mean 6.66733249090612e-05
0.00024830468464642763 0.00024830468464642763
rl training, epoch3, iter0, batch780/1133, batch loss:0.00024830468464642763, Training time:62888.94794154167
batch reward last col mean 1.215693430367537e-07 first col mean 9.954885899787769e-05 all mean 0.00011194781109225005
0.00044498281204141676 0.0004449828702490777
rl training, epoch3, iter0, batch781/1133, batch loss:0.0004449828702490777, Training time:62905.372081279755
batch reward last col mean 0.0018348522717133164 first col mean 1.906302713905461e-05 all mean 0.0017509883036836982
0.00025578265194781125 0.0002557826810516417
rl training, epoch3, iter0, batch782/1133, batch loss:0.0002557826810516417, Training time:62921.88394403458
batch reward last col mean 2.5505314624751918e-05 first col mean 5.131270427227719e-06 all mean 5.9525500546442345e-05
0.00017417578783351928 0.0001741758023854345
rl training, epoch3, iter0, batch783/1133, batch loss:0.0001741758023854345, Training time:62938.29347229004
batch reward last col mean 1.3035263464189484e-06 first col mean 0.0007982429815456271 all mean 0.000219519977690652
0.0005360288778319955 0.0005360288196243346
rl training, epoch3, iter0, batch784/1133, batch loss:0.0005360288196243346, Training time:62954.766556978226
batch reward last col mean 0.0009640882490202785 first col mean 0.00014389237912837416 all mean 0.0008492299821227789
9.864901949185878e-05 9.864901949185878e-05
rl training, epoch3, iter0, batch785/1133, batch loss:9.864901949185878e-05, Training time:62971.33819389343
batch reward last col mean 1.6032080907280033e-07 first col mean 6.704541738145053e-05 all mean 4.916844773106277e-05
0.0001802679616957903 0.0001802679616957903
rl training, epoch3, iter0, batch786/1133, batch loss:0.0001802679616957903, Training time:62987.746034383774
batch reward last col mean 1.2973902130397619e-06 first col mean 0.0031629602890461683 all mean 0.00010830238898051903
0.00023465495905838907 0.0002346549299545586
rl training, epoch3, iter0, batch787/1133, batch loss:0.0002346549299545586, Training time:63004.286148786545
batch reward last col mean 2.6980324037140235e-06 first col mean 3.5204823234380456e-06 all mean 7.19234740245156e-05
0.00025590459699742496 0.00025590459699742496
rl training, epoch3, iter0, batch788/1133, batch loss:0.00025590459699742496, Training time:63020.80603337288
batch reward last col mean 0.00030598710873164237 first col mean 0.0011011158348992467 all mean 0.00034964559017680585
0.0003350194019731134 0.0003350194019731134
rl training, epoch3, iter0, batch789/1133, batch loss:0.0003350194019731134, Training time:63037.365936517715
batch reward last col mean 0.0005161454901099205 first col mean 0.00013414498243946582 all mean 0.0004233015060890466
0.00012674109893850982 0.00012674109893850982
rl training, epoch3, iter0, batch790/1133, batch loss:0.00012674109893850982, Training time:63053.898481845856
batch reward last col mean 3.060028393520042e-05 first col mean 3.4059346944559366e-05 all mean 4.211071063764393e-05
5.6244574807351455e-05 5.6244574807351455e-05
rl training, epoch3, iter0, batch791/1133, batch loss:5.6244574807351455e-05, Training time:63070.39721465111
batch reward last col mean 4.92532080897945e-07 first col mean 0.0001107946372940205 all mean 4.191510015516542e-05
0.00019376999989617616 0.0001937699707923457
rl training, epoch3, iter0, batch792/1133, batch loss:0.0001937699707923457, Training time:63086.8912961483
batch reward last col mean 6.164636033645365e-06 first col mean 2.7880281777470373e-05 all mean 8.657474245410413e-05
0.0002493435167707503 0.0002493435167707503
rl training, epoch3, iter0, batch793/1133, batch loss:0.0002493435167707503, Training time:63103.46916389465
batch reward last col mean 0.005324600264430046 first col mean 2.3241447706823237e-05 all mean 0.004820759408175945
0.00043811206705868244 0.00043811212526634336
rl training, epoch3, iter0, batch794/1133, batch loss:0.00043811212526634336, Training time:63120.083220243454
batch reward last col mean 0.0002865404530894011 first col mean 3.3444404834881425e-05 all mean 0.00029671177617274225
0.00017546344315633178 0.00017546344315633178
rl training, epoch3, iter0, batch795/1133, batch loss:0.00017546344315633178, Training time:63136.66130757332
batch reward last col mean 0.0008346134563907981 first col mean 5.948980742687127e-06 all mean 0.0008214476401917636
0.00021443315199576318 0.00021443315199576318
rl training, epoch3, iter0, batch796/1133, batch loss:0.00021443315199576318, Training time:63153.07928967476
batch reward last col mean 1.2997088560950942e-07 first col mean 8.405617336393334e-06 all mean 3.582746649044566e-05
7.936979091027752e-05 7.936979091027752e-05
rl training, epoch3, iter0, batch797/1133, batch loss:7.936979091027752e-05, Training time:63169.54991412163
batch reward last col mean 0.00015264449757523835 first col mean 1.8847895262297243e-06 all mean 0.0001528321299701929
9.159404726233333e-05 9.159404726233333e-05
rl training, epoch3, iter0, batch798/1133, batch loss:9.159404726233333e-05, Training time:63186.08352637291
batch reward last col mean 1.5418463590322062e-06 first col mean 0.001749156042933464 all mean 0.00010959851351799443
0.00048295053420588374 0.00048295053420588374
rl training, epoch3, iter0, batch799/1133, batch loss:0.00048295053420588374, Training time:63202.54402709007
batch reward last col mean 5.385447110484165e-08 first col mean 0.0021451169159263372 all mean 0.0001469387934776023
0.00039134922553785145 0.000391349196434021
rl training, epoch3, iter0, batch800/1133, batch loss:0.000391349196434021, Training time:63219.06569671631
batch reward last col mean 3.5347125049156602e-06 first col mean 0.00022487813839688897 all mean 3.364741132827476e-05
7.220201223390177e-05 7.220201223390177e-05
rl training, epoch3, iter0, batch801/1133, batch loss:7.220201223390177e-05, Training time:63235.38014316559
batch reward last col mean 1.5869900380494073e-06 first col mean 2.3527947632828727e-05 all mean 4.5762652007397264e-05
0.0001338108122581616 0.0001338108122581616
rl training, epoch3, iter0, batch802/1133, batch loss:0.0001338108122581616, Training time:63251.841354846954
batch reward last col mean 1.1681336786750762e-07 first col mean 0.0004885070375166833 all mean 0.00012155882723163813
0.0003892487729899585 0.000389248802093789
rl training, epoch3, iter0, batch803/1133, batch loss:0.000389248802093789, Training time:63268.066130399704
batch reward last col mean 1.1870652087964118e-05 first col mean 0.00010071479482576251 all mean 5.838622382725589e-05
0.00016191021131817251 0.00016191021131817251
rl training, epoch3, iter0, batch804/1133, batch loss:0.00016191021131817251, Training time:63284.546431303024
batch reward last col mean 0.0015642524231225252 first col mean 0.001628507161512971 all mean 0.0014764934312552214
9.790845797397196e-05 9.790845797397196e-05
rl training, epoch3, iter0, batch805/1133, batch loss:9.790845797397196e-05, Training time:63301.03061199188
batch reward last col mean 0.0007349144434556365 first col mean 6.30720314802602e-05 all mean 0.000715838628821075
0.0003058014262933284 0.0003058014262933284
rl training, epoch3, iter0, batch806/1133, batch loss:0.0003058014262933284, Training time:63317.56302142143
batch reward last col mean 2.5328043193439953e-05 first col mean 0.0005632442189380527 all mean 0.00010797268623718992
0.00024457668769173324 0.0002445766585879028
rl training, epoch3, iter0, batch807/1133, batch loss:0.0002445766585879028, Training time:63334.10191607475
batch reward last col mean 9.085212695936207e-06 first col mean 0.0017310603288933635 all mean 0.00012214136950206012
0.0002642875479068607 0.0002642875479068607
rl training, epoch3, iter0, batch808/1133, batch loss:0.0002642875479068607, Training time:63350.61355423927
batch reward last col mean 1.0360735359427053e-05 first col mean 0.0003470323281362653 all mean 6.192764703882858e-05
8.180514123523608e-05 8.180512668332085e-05
rl training, epoch3, iter0, batch809/1133, batch loss:8.180512668332085e-05, Training time:63367.473321676254
batch reward last col mean 0.001154331723228097 first col mean 0.00026625546161085367 all mean 0.0011315550655126572
0.0005045862053520977 0.0005045862053520977
rl training, epoch3, iter0, batch810/1133, batch loss:0.0005045862053520977, Training time:63383.96751785278
batch reward last col mean 0.004264181479811668 first col mean 1.0950742762361187e-05 all mean 0.0038895730394870043
0.00043995174928568304 0.00043995174928568304
rl training, epoch3, iter0, batch811/1133, batch loss:0.00043995174928568304, Training time:63400.3773932457
batch reward last col mean 1.3295358485265751e-06 first col mean 0.00015847651229705662 all mean 6.22493025730364e-05
8.046263246797025e-05 8.046263246797025e-05
rl training, epoch3, iter0, batch812/1133, batch loss:8.046263246797025e-05, Training time:63416.94256281853
batch reward last col mean 5.7203274081985e-06 first col mean 2.972752736241091e-05 all mean 6.325310823740438e-05
0.00032306284992955625 0.00032306284992955625
rl training, epoch3, iter0, batch813/1133, batch loss:0.00032306284992955625, Training time:63433.50622868538
batch reward last col mean 5.381034134188667e-05 first col mean 1.7383889598932e-06 all mean 6.73770991852507e-05
0.00014673091936856508 0.00014673091936856508
rl training, epoch3, iter0, batch814/1133, batch loss:0.00014673091936856508, Training time:63449.85955405235
batch reward last col mean 0.00024166949151549488 first col mean 0.0001071965743904002 all mean 0.00026727389195002615
0.00020959292305633426 0.00020959292305633426
rl training, epoch3, iter0, batch815/1133, batch loss:0.00020959292305633426, Training time:63466.32271814346
batch reward last col mean 0.0005332714645192027 first col mean 6.673939060419798e-05 all mean 0.000604550470598042
0.00028068971005268395 0.0002806897391565144
rl training, epoch3, iter0, batch816/1133, batch loss:0.0002806897391565144, Training time:63482.70336937904
batch reward last col mean 8.398345380555838e-05 first col mean 7.771950913593173e-05 all mean 0.00011074819485656917
4.65815573988948e-05 4.658157195081003e-05
rl training, epoch3, iter0, batch817/1133, batch loss:4.658157195081003e-05, Training time:63498.97364282608
batch reward last col mean 1.813342862533318e-07 first col mean 0.0023696860298514366 all mean 6.199987547006458e-05
0.0002043410495389253 0.00020434106409084052
rl training, epoch3, iter0, batch818/1133, batch loss:0.00020434106409084052, Training time:63515.18883705139
batch reward last col mean 6.8905756052117795e-06 first col mean 0.00029551138868555427 all mean 4.910563075100072e-05
0.00020886251877527684 0.00020886253332719207
rl training, epoch3, iter0, batch819/1133, batch loss:0.00020886253332719207, Training time:63531.51752281189
batch reward last col mean 3.5203991046728333e-06 first col mean 5.615025315819366e-07 all mean 5.331151987775229e-05
0.0002102955913869664 0.00021029560593888164
rl training, epoch3, iter0, batch820/1133, batch loss:0.00021029560593888164, Training time:63548.01265382767
batch reward last col mean 0.00037247478030622005 first col mean 1.16775536298519e-05 all mean 0.0004003090725746006
0.0004236459790263325 0.0004236459790263325
rl training, epoch3, iter0, batch821/1133, batch loss:0.0004236459790263325, Training time:63564.54648900032
batch reward last col mean 3.8656744436593726e-05 first col mean 0.00012995787255931646 all mean 0.00011623580212472007
0.0004022513167001307 0.0004022513167001307
rl training, epoch3, iter0, batch822/1133, batch loss:0.0004022513167001307, Training time:63580.96057891846
batch reward last col mean 3.730281605385244e-05 first col mean 0.0011393296299502254 all mean 3.301700417068787e-05
7.257475226651877e-05 7.257475226651877e-05
rl training, epoch3, iter0, batch823/1133, batch loss:7.257475226651877e-05, Training time:63597.40180659294
batch reward last col mean 0.003663173411041498 first col mean 0.0003508347144816071 all mean 0.0034228863660246134
0.000556289975065738 0.000556289916858077
rl training, epoch3, iter0, batch824/1133, batch loss:0.000556289916858077, Training time:63613.8132545948
batch reward last col mean 2.8371235316626553e-07 first col mean 3.9531150832772255e-05 all mean 5.6562577810836956e-05
6.375730299623683e-05 6.375731754815206e-05
rl training, epoch3, iter0, batch825/1133, batch loss:6.375731754815206e-05, Training time:63630.23009634018
batch reward last col mean 0.0002737830800469965 first col mean 7.401914626825601e-05 all mean 0.0002898465027101338
0.000160599869559519 0.000160599869559519
rl training, epoch3, iter0, batch826/1133, batch loss:0.000160599869559519, Training time:63646.81043124199
batch reward last col mean 4.559541412163526e-05 first col mean 4.809010079043219e-06 all mean 0.00012538519513327628
0.0003269811859354377 0.0003269811859354377
rl training, epoch3, iter0, batch827/1133, batch loss:0.0003269811859354377, Training time:63663.35580968857
batch reward last col mean 1.3325167458333453e-07 first col mean 0.001218030578456819 all mean 5.449977470561862e-05
0.0001355254789814353 0.0001355254789814353
rl training, epoch3, iter0, batch828/1133, batch loss:0.0001355254789814353, Training time:63679.968697309494
batch reward last col mean 0.0006343707209452987 first col mean 0.00039933560765348375 all mean 0.000615702650975436
0.000397301628254354 0.000397301628254354
rl training, epoch3, iter0, batch829/1133, batch loss:0.000397301628254354, Training time:63696.66367292404
batch reward last col mean 2.360782673349604e-06 first col mean 0.0015569223323836923 all mean 8.427423017565161e-05
0.00026090641040354967 0.00026090643950738013
rl training, epoch3, iter0, batch830/1133, batch loss:0.00026090643950738013, Training time:63713.24824690819
batch reward last col mean 9.935402545124816e-08 first col mean 6.033996214682702e-06 all mean 4.759828880196437e-05
8.310362318297848e-05 8.310364501085132e-05
rl training, epoch3, iter0, batch831/1133, batch loss:8.310364501085132e-05, Training time:63729.91917037964
batch reward last col mean 2.5652215640548093e-07 first col mean 3.0555649573216215e-05 all mean 6.790368934161961e-05
0.0002349500427953899 0.0002349499991396442
rl training, epoch3, iter0, batch832/1133, batch loss:0.0002349499991396442, Training time:63746.5630671978
batch reward last col mean 0.0033982032909989357 first col mean 5.6876680901041254e-05 all mean 0.0015773895429447293
0.0003447086492087692 0.0003447086492087692
rl training, epoch3, iter0, batch833/1133, batch loss:0.0003447086492087692, Training time:63763.0911192894
batch reward last col mean 2.8624201604543487e-06 first col mean 4.855920906265965e-06 all mean 3.709045995492488e-05
5.462751505547203e-05 5.462752596940845e-05
rl training, epoch3, iter0, batch834/1133, batch loss:5.462752596940845e-05, Training time:63779.675666093826
batch reward last col mean 0.005730604752898216 first col mean 0.00020065931312274188 all mean 0.003455407451838255
0.0008596094558015466 0.0008596093393862247
rl training, epoch3, iter0, batch835/1133, batch loss:0.0008596093393862247, Training time:63796.23812460899
batch reward last col mean 6.390026101144031e-05 first col mean 0.00021722802193835378 all mean 9.691414015833288e-05
0.0001619587856112048 0.0001619587856112048
rl training, epoch3, iter0, batch836/1133, batch loss:0.0001619587856112048, Training time:63812.79692316055
batch reward last col mean 1.3626738564198604e-06 first col mean 0.00011685625941026956 all mean 9.157985914498568e-05
0.00019107316620647907 0.00019107316620647907
rl training, epoch3, iter0, batch837/1133, batch loss:0.00019107316620647907, Training time:63829.27733659744
batch reward last col mean 1.3526945394914947e-06 first col mean 0.0012562618358060718 all mean 8.8702559878584e-05
0.00018095166888087988 0.00018095166888087988
rl training, epoch3, iter0, batch838/1133, batch loss:0.00018095166888087988, Training time:63845.85402035713
batch reward last col mean 3.403215487196576e-06 first col mean 0.00010024722723755985 all mean 3.7175090255914256e-05
0.0001740299485391006 0.0001740299485391006
rl training, epoch3, iter0, batch839/1133, batch loss:0.0001740299485391006, Training time:63862.68058228493
batch reward last col mean 9.463049354963005e-05 first col mean 5.562966634897748e-06 all mean 0.00014709746756125242
0.00023056392092257738 0.00023056392092257738
rl training, epoch3, iter0, batch840/1133, batch loss:0.00023056392092257738, Training time:63879.20611143112
batch reward last col mean 0.006584290415048599 first col mean 0.0019489024998620152 all mean 0.006208896636962891
0.000566505070310086 0.000566505070310086
rl training, epoch3, iter0, batch841/1133, batch loss:0.000566505070310086, Training time:63895.679478406906
batch reward last col mean 3.429962362133665e-06 first col mean 5.703547867597081e-05 all mean 7.350514351855963e-05
0.0003001900913659483 0.0003001900913659483
rl training, epoch3, iter0, batch842/1133, batch loss:0.0003001900913659483, Training time:63912.14471101761
batch reward last col mean 0.007139601744711399 first col mean 7.07069702912122e-05 all mean 0.006227262318134308
0.00042568647768348455 0.00042568647768348455
rl training, epoch3, iter0, batch843/1133, batch loss:0.00042568647768348455, Training time:63928.633120298386
batch reward last col mean 0.0008767503313720226 first col mean 3.7536901800194755e-05 all mean 0.0008195615373551846
0.0002944498264696449 0.00029444985557347536
rl training, epoch3, iter0, batch844/1133, batch loss:0.00029444985557347536, Training time:63945.085112810135
batch reward last col mean 0.00039500038838014007 first col mean 2.851433055184316e-05 all mean 0.00039461450069211423
0.00019659729150589556 0.00019659729150589556
rl training, epoch3, iter0, batch845/1133, batch loss:0.00019659729150589556, Training time:63961.49898171425
batch reward last col mean 8.376862581371824e-08 first col mean 0.0012861911673098803 all mean 0.00020586585742421448
0.0007124950643628836 0.0007124950643628836
rl training, epoch3, iter0, batch846/1133, batch loss:0.0007124950643628836, Training time:63977.9109749794
batch reward last col mean 0.004563021939247847 first col mean 5.378469722927548e-05 all mean 0.004060088656842709
0.0005625473568215966 0.0005625472986139357
rl training, epoch3, iter0, batch847/1133, batch loss:0.0005625472986139357, Training time:63994.62377119064
batch reward last col mean 4.935834567731945e-06 first col mean 0.0006954794516786933 all mean 9.252953896066174e-05
0.0002974887902382761 0.0002974887902382761
rl training, epoch3, iter0, batch848/1133, batch loss:0.0002974887902382761, Training time:64011.21337008476
batch reward last col mean 0.00017044214473571628 first col mean 0.0014697667211294174 all mean 0.0002522308495827019
0.0003172226424794644 0.0003172226424794644
rl training, epoch3, iter0, batch849/1133, batch loss:0.0003172226424794644, Training time:64027.964992284775
batch reward last col mean 0.0001455071324016899 first col mean 8.393309690291062e-05 all mean 0.000201903996639885
0.0003725131100509316 0.0003725131100509316
rl training, epoch3, iter0, batch850/1133, batch loss:0.0003725131100509316, Training time:64044.65308237076
batch reward last col mean 5.8136010920861736e-05 first col mean 0.0019600908271968365 all mean 0.00010547271085670218
0.00016234318900387734 0.00016234318900387734
rl training, epoch3, iter0, batch851/1133, batch loss:0.00016234318900387734, Training time:64061.380323171616
batch reward last col mean 2.5393836722287233e-07 first col mean 5.8702546084532514e-05 all mean 9.794162906473503e-05
0.00020465128181967884 0.00020465126726776361
rl training, epoch3, iter0, batch852/1133, batch loss:0.00020465126726776361, Training time:64077.854102134705
batch reward last col mean 1.5225825791276293e-06 first col mean 0.0018233670853078365 all mean 0.00010509486310184002
0.00033791785244829953 0.00033791785244829953
rl training, epoch3, iter0, batch853/1133, batch loss:0.00033791785244829953, Training time:64094.67111873627
batch reward last col mean 1.5567544323857874e-05 first col mean 1.0162482794839889e-05 all mean 8.504703146172687e-05
0.00034219390363432467 0.00034219390363432467
rl training, epoch3, iter0, batch854/1133, batch loss:0.00034219390363432467, Training time:64111.187608003616
batch reward last col mean 1.1864922271342948e-06 first col mean 7.253611693158746e-05 all mean 4.1281997255282477e-05
0.0001225645828526467 0.00012256459740456194
rl training, epoch3, iter0, batch855/1133, batch loss:0.00012256459740456194, Training time:64127.787091732025
batch reward last col mean 2.4361150281038135e-05 first col mean 0.00013402845070231706 all mean 0.00010017710155807436
0.0002809680299833417 0.0002809680299833417
rl training, epoch3, iter0, batch856/1133, batch loss:0.0002809680299833417, Training time:64144.557859659195
batch reward last col mean 6.671060873486567e-06 first col mean 5.793213495053351e-05 all mean 0.00010190706234425306
0.00041976768989115953 0.00041976768989115953
rl training, epoch3, iter0, batch857/1133, batch loss:0.00041976768989115953, Training time:64161.00810837746
batch reward last col mean 0.0002745999663602561 first col mean 0.00040787970647215843 all mean 0.00032016661134548485
0.00038042457890696824 0.0003804245498031378
rl training, epoch3, iter0, batch858/1133, batch loss:0.0003804245498031378, Training time:64177.49949979782
batch reward last col mean 2.9168841138016433e-05 first col mean 4.645033914130181e-05 all mean 0.0001327860081801191
0.0004793524567503482 0.0004793524567503482
rl training, epoch3, iter0, batch859/1133, batch loss:0.0004793524567503482, Training time:64193.8073952198
batch reward last col mean 4.788628575624898e-05 first col mean 0.0004474489251151681 all mean 0.0002087385655613616
0.0007455582963302732 0.0007455582381226122
rl training, epoch3, iter0, batch860/1133, batch loss:0.0007455582381226122, Training time:64210.20574045181
batch reward last col mean 2.375381882302463e-06 first col mean 0.002810294972732663 all mean 8.272767445305362e-05
0.00018692357116378844 0.00018692357116378844
rl training, epoch3, iter0, batch861/1133, batch loss:0.00018692357116378844, Training time:64226.65011692047
batch reward last col mean 0.0016763528110459447 first col mean 0.001164799788966775 all mean 0.0016501698410138488
0.00023650181537959725 0.00023650181537959725
rl training, epoch3, iter0, batch862/1133, batch loss:0.00023650181537959725, Training time:64243.06591153145
batch reward last col mean 3.968393230024958e-06 first col mean 0.000732169602997601 all mean 9.162594506051391e-05
0.0003390129713807255 0.0003390129713807255
rl training, epoch3, iter0, batch863/1133, batch loss:0.0003390129713807255, Training time:64259.68595337868
batch reward last col mean 0.00013859978935215622 first col mean 0.00020465250418055803 all mean 0.00016701844288036227
0.00019848636293318123 0.00019848636293318123
rl training, epoch3, iter0, batch864/1133, batch loss:0.00019848636293318123, Training time:64276.06440734863
batch reward last col mean 0.0002714750589802861 first col mean 0.00011956108210142702 all mean 0.0003124903596471995
0.0002571660152170807 0.0002571660152170807
rl training, epoch3, iter0, batch865/1133, batch loss:0.0002571660152170807, Training time:64292.30931353569
batch reward last col mean 1.0443906830914784e-05 first col mean 0.0030587203800678253 all mean 0.00010530569852562621
0.0002937650424428284 0.0002937650424428284
rl training, epoch3, iter0, batch866/1133, batch loss:0.0002937650424428284, Training time:64308.599789857864
batch reward last col mean 3.33807042807166e-06 first col mean 0.0012228813720867038 all mean 8.335912571055815e-05
0.00019138125935569406 0.00019138130301143974
rl training, epoch3, iter0, batch867/1133, batch loss:0.00019138130301143974, Training time:64325.28467822075
batch reward last col mean 8.171548984137189e-07 first col mean 0.0003671411832328886 all mean 0.00011223091860301793
0.0003413754457142204 0.0003413754457142204
rl training, epoch3, iter0, batch868/1133, batch loss:0.0003413754457142204, Training time:64341.881776571274
batch reward last col mean 1.710336050564365e-07 first col mean 1.8511318558012135e-05 all mean 5.283877908368595e-05
0.0002079786208923906 0.0002079786208923906
rl training, epoch3, iter0, batch869/1133, batch loss:0.0002079786208923906, Training time:64358.46366214752
batch reward last col mean 0.003730270080268383 first col mean 0.0021982535254210234 all mean 0.0034805964678525925
0.0008597475243732333 0.0008597475243732333
rl training, epoch3, iter0, batch870/1133, batch loss:0.0008597475243732333, Training time:64375.06743502617
batch reward last col mean 6.690045211144025e-07 first col mean 0.00011097560491180047 all mean 6.137570744613186e-05
0.00021262132213450968 0.00021262135123834014
rl training, epoch3, iter0, batch871/1133, batch loss:0.00021262135123834014, Training time:64391.63883757591
batch reward last col mean 0.00015420377894770354 first col mean 2.137561750714667e-06 all mean 0.00028643698897212744
0.000453182467026636 0.00045318249613046646
rl training, epoch3, iter0, batch872/1133, batch loss:0.00045318249613046646, Training time:64408.15400362015
batch reward last col mean 0.00020867188868578523 first col mean 0.0006827802280895412 all mean 0.00022716114472132176
0.0001817514857975766 0.00018175151490140706
rl training, epoch3, iter0, batch873/1133, batch loss:0.00018175151490140706, Training time:64424.99090766907
batch reward last col mean 0.00010034382285084575 first col mean 0.00349171319976449 all mean 0.00022397792781703174
0.0004173015768174082 0.00041730154771357775
rl training, epoch3, iter0, batch874/1133, batch loss:0.00041730154771357775, Training time:64441.42387342453
batch reward last col mean 7.428971002809703e-05 first col mean 0.002339922823011875 all mean 0.0001555710769025609
0.00023001182125881314 0.00023001182125881314
rl training, epoch3, iter0, batch875/1133, batch loss:0.00023001182125881314, Training time:64457.7792224884
batch reward last col mean 0.00021966107306070626 first col mean 0.0014952912461012602 all mean 0.00030326578416861594
0.0002981287252623588 0.00029812869615852833
rl training, epoch3, iter0, batch876/1133, batch loss:0.00029812869615852833, Training time:64474.07893705368
batch reward last col mean 0.00041075548506341875 first col mean 0.00013181593385525048 all mean 0.00047652734792791307
0.00022118235938251019 0.00022118235938251019
rl training, epoch3, iter0, batch877/1133, batch loss:0.00022118235938251019, Training time:64490.303449869156
batch reward last col mean 0.0005759149207733572 first col mean 0.0015128805534914136 all mean 0.0006207576370798051
0.00029554570210166276 0.00029554570210166276
rl training, epoch3, iter0, batch878/1133, batch loss:0.00029554570210166276, Training time:64506.59564971924
batch reward last col mean 0.001981444424018264 first col mean 0.00047372974222525954 all mean 0.0019115660106763244
0.000269192096311599 0.000269192096311599
rl training, epoch3, iter0, batch879/1133, batch loss:0.000269192096311599, Training time:64522.829443216324
batch reward last col mean 2.416713414277183e-06 first col mean 0.00014661259774584323 all mean 0.00019385978521313518
0.0007398865418508649 0.0007398864254355431
rl training, epoch3, iter0, batch880/1133, batch loss:0.0007398864254355431, Training time:64539.133274793625
batch reward last col mean 0.0002535908133722842 first col mean 0.0005115728126838803 all mean 0.0003164366935379803
0.0002962909056805074 0.0002962909056805074
rl training, epoch3, iter0, batch881/1133, batch loss:0.0002962909056805074, Training time:64555.39246511459
batch reward last col mean 5.601852421932563e-07 first col mean 0.0007636161171831191 all mean 5.953388608759269e-05
0.00014817394549027085 0.00014817394549027085
rl training, epoch3, iter0, batch882/1133, batch loss:0.00014817394549027085, Training time:64571.67793345451
batch reward last col mean 4.723178062704392e-05 first col mean 0.001227573142386973 all mean 0.00011233532131882384
0.00020073320774827152 0.0002007331931963563
rl training, epoch3, iter0, batch883/1133, batch loss:0.0002007331931963563, Training time:64587.97313594818
batch reward last col mean 0.0005162354209460318 first col mean 0.0006288430304266512 all mean 0.0005720895132981241
0.00020432185556273907 0.00020432185556273907
rl training, epoch3, iter0, batch884/1133, batch loss:0.00020432185556273907, Training time:64604.26082897186
batch reward last col mean 0.0004943181411363184 first col mean 4.332168828113936e-05 all mean 0.0005699900793842971
0.0004422222846187651 0.0004422222846187651
rl training, epoch3, iter0, batch885/1133, batch loss:0.0004422222846187651, Training time:64620.519877672195
batch reward last col mean 4.858412694375147e-07 first col mean 0.0005208255024626851 all mean 0.0001723578170640394
0.000580841617193073 0.000580841617193073
rl training, epoch3, iter0, batch886/1133, batch loss:0.000580841617193073, Training time:64636.9731862545
batch reward last col mean 5.928542918809399e-07 first col mean 0.0032079298980534077 all mean 0.0001588765881024301
0.0004070629656780511 0.0004070629656780511
rl training, epoch3, iter0, batch887/1133, batch loss:0.0004070629656780511, Training time:64653.365449905396
batch reward last col mean 5.6830594985513017e-05 first col mean 0.0016704709269106388 all mean 0.00011315780284348875
0.0002907030575443059 0.00029070302844047546
rl training, epoch3, iter0, batch888/1133, batch loss:0.00029070302844047546, Training time:64669.79654479027
batch reward last col mean 0.0004534338950179517 first col mean 0.002009173622354865 all mean 0.00048144639004021883
7.905624806880951e-05 7.905624806880951e-05
rl training, epoch3, iter0, batch889/1133, batch loss:7.905624806880951e-05, Training time:64686.28545832634
batch reward last col mean 0.0037488918751478195 first col mean 0.0018394277431070805 all mean 0.0037788983900099993
0.0007215238292701542 0.0007215238292701542
rl training, epoch3, iter0, batch890/1133, batch loss:0.0007215238292701542, Training time:64702.80035376549
batch reward last col mean 0.0008054624195210636 first col mean 0.0007666762103326619 all mean 0.000737807888071984
0.0002233512932434678 0.0002233513368992135
rl training, epoch3, iter0, batch891/1133, batch loss:0.0002233513368992135, Training time:64719.187443733215
batch reward last col mean 8.976592653198168e-06 first col mean 0.001065928372554481 all mean 0.00026696629356592894
0.0007687386241741478 0.0007687385659664869
rl training, epoch3, iter0, batch892/1133, batch loss:0.0007687385659664869, Training time:64735.61819934845
batch reward last col mean 2.5547069526510313e-06 first col mean 0.0024648464750498533 all mean 0.0003107071097474545
0.0008219463052228093 0.0008219463634304702
rl training, epoch3, iter0, batch893/1133, batch loss:0.0008219463634304702, Training time:64752.01353430748
batch reward last col mean 9.520596358925104e-05 first col mean 0.0012621082132682204 all mean 0.00023807155957911164
0.0005978015251457691 0.000597801641561091
rl training, epoch3, iter0, batch894/1133, batch loss:0.000597801641561091, Training time:64768.389177799225
batch reward last col mean 0.006568327080458403 first col mean 0.0001612245396245271 all mean 0.006270997226238251
0.0005793004529550672 0.0005793004529550672
rl training, epoch3, iter0, batch895/1133, batch loss:0.0005793004529550672, Training time:64784.757091999054
batch reward last col mean 9.341375516669359e-06 first col mean 0.0017248643562197685 all mean 0.00020595150999724865
0.0006850965437479317 0.0006850965437479317
rl training, epoch3, iter0, batch896/1133, batch loss:0.0006850965437479317, Training time:64801.05063581467
batch reward last col mean 1.0457478083480964e-06 first col mean 0.0002757394395302981 all mean 8.350375719601288e-05
0.00023418549972120672 0.00023418551427312195
rl training, epoch3, iter0, batch897/1133, batch loss:0.00023418551427312195, Training time:64817.339072704315
batch reward last col mean 5.31130499439314e-05 first col mean 8.980598067864776e-05 all mean 0.00015532640099991113
0.000607475929427892 0.0006074758130125701
rl training, epoch3, iter0, batch898/1133, batch loss:0.0006074758130125701, Training time:64833.921362400055
batch reward last col mean 1.7747084712027572e-05 first col mean 0.00021636464225593954 all mean 0.00013020657934248447
0.0002877225342672318 0.0002877225342672318
rl training, epoch3, iter0, batch899/1133, batch loss:0.0002877225342672318, Training time:64850.37175822258
batch reward last col mean 1.273103748644644e-06 first col mean 0.00018895749235525727 all mean 0.00010833892156369984
0.0003991520788986236 0.0003991520788986236
rl training, epoch3, iter0, batch900/1133, batch loss:0.0003991520788986236, Training time:64866.62629413605
batch reward last col mean 0.0002211202954640612 first col mean 0.0013271465431898832 all mean 0.00035905002732761204
0.0006149571854621172 0.0006149571854621172
rl training, epoch3, iter0, batch901/1133, batch loss:0.0006149571854621172, Training time:64882.95861196518
batch reward last col mean 0.0006478377617895603 first col mean 1.4644027942267712e-05 all mean 0.0006752731860615313
0.00043582450598478317 0.00043582450598478317
rl training, epoch3, iter0, batch902/1133, batch loss:0.00043582450598478317, Training time:64899.37628746033
batch reward last col mean 0.005624767392873764 first col mean 4.184135468676686e-05 all mean 0.00502955075353384
0.0005379198119044304 0.0005379198119044304
rl training, epoch3, iter0, batch903/1133, batch loss:0.0005379198119044304, Training time:64915.663466215134
batch reward last col mean 2.3533590137958527e-05 first col mean 7.146284769987687e-05 all mean 0.00016459205653518438
0.0005281376652419567 0.0005281376652419567
rl training, epoch3, iter0, batch904/1133, batch loss:0.0005281376652419567, Training time:64932.05924320221
batch reward last col mean 1.0797391951200552e-05 first col mean 4.2312916775699705e-05 all mean 0.0001060850263456814
0.00033292509033344686 0.0003329251485411078
rl training, epoch3, iter0, batch905/1133, batch loss:0.0003329251485411078, Training time:64948.36506867409
batch reward last col mean 3.845776882371865e-05 first col mean 0.00025329479831270874 all mean 5.2149087423458695e-05
0.00014821301738265902 0.00014821298827882856
rl training, epoch3, iter0, batch906/1133, batch loss:0.00014821298827882856, Training time:64965.01614236832
batch reward last col mean 0.001954948529601097 first col mean 0.00010836873116204515 all mean 0.0020225748885422945
0.0006871918449178338 0.000687191728502512
rl training, epoch3, iter0, batch907/1133, batch loss:0.000687191728502512, Training time:64981.87517786026
batch reward last col mean 0.0003035449481103569 first col mean 0.0007379903108812869 all mean 0.00031763833248987794
9.65953731792979e-05 9.659538045525551e-05
rl training, epoch3, iter0, batch908/1133, batch loss:9.659538045525551e-05, Training time:64998.34912109375
batch reward last col mean 0.005242513492703438 first col mean 0.00032202116562984884 all mean 0.004968778230249882
0.000837645900901407 0.000837645900901407
rl training, epoch3, iter0, batch909/1133, batch loss:0.000837645900901407, Training time:65014.828575611115
batch reward last col mean 0.009436508640646935 first col mean 5.4796608310425654e-05 all mean 0.008400149643421173
0.00048312018043361604 0.00048312018043361604
rl training, epoch3, iter0, batch910/1133, batch loss:0.00048312018043361604, Training time:65031.40379977226
batch reward last col mean 0.0009190626442432404 first col mean 1.3788683645543642e-05 all mean 0.0009248196729458869
0.0002992852823808789 0.0002992853114847094
rl training, epoch3, iter0, batch911/1133, batch loss:0.0002992853114847094, Training time:65047.87576985359
batch reward last col mean 2.2231990442378446e-05 first col mean 0.000496935099363327 all mean 0.0001288109051529318
0.00045665857032872736 0.00045665857032872736
rl training, epoch3, iter0, batch912/1133, batch loss:0.00045665857032872736, Training time:65065.48277544975
batch reward last col mean 4.961084050592035e-05 first col mean 0.002441762713715434 all mean 0.000176425208337605
0.0006312974728643894 0.0006312975310720503
rl training, epoch3, iter0, batch913/1133, batch loss:0.0006312975310720503, Training time:65082.104932785034
batch reward last col mean 0.0004012317513115704 first col mean 0.00025861590984277427 all mean 0.0004902323707938194
0.00035733182448893785 0.0003573318535927683
rl training, epoch3, iter0, batch914/1133, batch loss:0.0003573318535927683, Training time:65098.51570343971
batch reward last col mean 4.990258821635507e-05 first col mean 0.0012191362911835313 all mean 0.00011980434646829963
0.00026950350729748607 0.0002695034781936556
rl training, epoch3, iter0, batch915/1133, batch loss:0.0002695034781936556, Training time:65114.97500181198
batch reward last col mean 4.87444776808843e-05 first col mean 0.0009261580999009311 all mean 0.0002752463042270392
0.0010418726596981287 0.0010418725432828069
rl training, epoch3, iter0, batch916/1133, batch loss:0.0010418725432828069, Training time:65131.37463593483
batch reward last col mean 0.00024853184004314244 first col mean 0.00030822906410321593 all mean 0.00026565120788291097
0.00019119416538160294 0.0001911941944854334
rl training, epoch3, iter0, batch917/1133, batch loss:0.0001911941944854334, Training time:65147.81893610954
batch reward last col mean 2.8327003747108392e-05 first col mean 0.0035358655732125044 all mean 0.00019169176812283695
0.00043867164640687406 0.000438671704614535
rl training, epoch3, iter0, batch918/1133, batch loss:0.000438671704614535, Training time:65164.133051395416
batch reward last col mean 0.000865254900418222 first col mean 0.0007825973443686962 all mean 0.0008749720873311162
0.00041724121547304094 0.0004172411863692105
rl training, epoch3, iter0, batch919/1133, batch loss:0.0004172411863692105, Training time:65180.46684193611
batch reward last col mean 1.240431970472855e-06 first col mean 0.001290425076149404 all mean 0.00013641282566823065
0.00041069468716159463 0.00041069468716159463
rl training, epoch3, iter0, batch920/1133, batch loss:0.00041069468716159463, Training time:65196.828236579895
batch reward last col mean 1.0394879609521013e-05 first col mean 0.001244811457581818 all mean 0.00015249759599100798
0.0004374638956505805 0.0004374638956505805
rl training, epoch3, iter0, batch921/1133, batch loss:0.0004374638956505805, Training time:65213.49500322342
batch reward last col mean 0.00035254188696853817 first col mean 0.0007084343815222383 all mean 0.00042657775338739157
0.0005015288479626179 0.0005015288479626179
rl training, epoch3, iter0, batch922/1133, batch loss:0.0005015288479626179, Training time:65230.08363652229
batch reward last col mean 0.0026166217867285013 first col mean 0.001840614015236497 all mean 0.0026129174511879683
0.0007024187943898141 0.0007024187943898141
rl training, epoch3, iter0, batch923/1133, batch loss:0.0007024187943898141, Training time:65246.68531894684
batch reward last col mean 1.4874802218400873e-05 first col mean 8.910844917409122e-05 all mean 6.645430403295904e-05
0.00026489319861866534 0.00026489319861866534
rl training, epoch3, iter0, batch924/1133, batch loss:0.00026489319861866534, Training time:65263.236725091934
batch reward last col mean 5.255619271338219e-06 first col mean 0.003978329710662365 all mean 0.00024544313782826066
0.000779953901655972 0.000779953901655972
rl training, epoch3, iter0, batch925/1133, batch loss:0.000779953901655972, Training time:65279.892912864685
batch reward last col mean 0.000190569378901273 first col mean 0.0021231609862297773 all mean 0.0002821811940521002
0.0003250886220484972 0.0003250886220484972
rl training, epoch3, iter0, batch926/1133, batch loss:0.0003250886220484972, Training time:65296.48083972931
batch reward last col mean 0.00440962053835392 first col mean 0.0004811051767319441 all mean 0.0038213205989450216
0.0006397782708518207 0.0006397782708518207
rl training, epoch3, iter0, batch927/1133, batch loss:0.0006397782708518207, Training time:65313.071288108826
batch reward last col mean 2.8438262233976275e-05 first col mean 0.00017006054986268282 all mean 0.00010471096902620047
0.00028505700174719095 0.00028505700174719095
rl training, epoch3, iter0, batch928/1133, batch loss:0.00028505700174719095, Training time:65329.60353088379
batch reward last col mean 1.450031231797766e-05 first col mean 0.001946259057149291 all mean 0.00010443916835356504
0.00016257567040156573 0.0001625756558496505
rl training, epoch3, iter0, batch929/1133, batch loss:0.0001625756558496505, Training time:65346.0794403553
batch reward last col mean 0.0007823847117833793 first col mean 0.0019077731994912028 all mean 0.0008982990402728319
0.00040524371434003115 0.00040524371434003115
rl training, epoch3, iter0, batch930/1133, batch loss:0.00040524371434003115, Training time:65362.76463007927
batch reward last col mean 0.00444673839956522 first col mean 0.0002503613359294832 all mean 0.00400704937055707
0.0003774695214815438 0.0003774695214815438
rl training, epoch3, iter0, batch931/1133, batch loss:0.0003774695214815438, Training time:65379.2691860199
batch reward last col mean 7.922153031358903e-07 first col mean 0.001577093149535358 all mean 0.00021143752383068204
0.0005579428398050368 0.0005579428398050368
rl training, epoch3, iter0, batch932/1133, batch loss:0.0005579428398050368, Training time:65395.682765483856
batch reward last col mean 5.106127355247736e-05 first col mean 0.0018105923663824797 all mean 0.0001641000562813133
0.00024371895415242761 0.00024371895415242761
rl training, epoch3, iter0, batch933/1133, batch loss:0.00024371895415242761, Training time:65412.16463494301
batch reward last col mean 1.1847668247355614e-05 first col mean 0.0005930218612775207 all mean 0.00010104368993779644
0.00029827223625034094 0.0002982722071465105
rl training, epoch3, iter0, batch934/1133, batch loss:0.0002982722071465105, Training time:65428.56763267517
batch reward last col mean 9.2220363967499e-07 first col mean 0.00017917869263328612 all mean 0.00013175286585465074
0.0006183080258779228 0.0006183080258779228
rl training, epoch3, iter0, batch935/1133, batch loss:0.0006183080258779228, Training time:65445.04194355011
batch reward last col mean 0.003500456688925624 first col mean 0.00019776940462179482 all mean 0.0027837783563882113
0.0006712204776704311 0.0006712204776704311
rl training, epoch3, iter0, batch936/1133, batch loss:0.0006712204776704311, Training time:65461.55270957947
batch reward last col mean 6.665254477411509e-05 first col mean 0.0001625069126021117 all mean 0.000165645033121109
0.00045118312118574977 0.00045118312118574977
rl training, epoch3, iter0, batch937/1133, batch loss:0.00045118312118574977, Training time:65477.88482809067
batch reward last col mean 0.00023123275605030358 first col mean 0.0016981454100459814 all mean 0.0003177973267156631
0.0003552858834154904 0.0003552858834154904
rl training, epoch3, iter0, batch938/1133, batch loss:0.0003552858834154904, Training time:65494.41651844978
batch reward last col mean 5.926520429966331e-07 first col mean 0.00012232200242578983 all mean 8.455782517557964e-05
0.0003143070498481393 0.00031430702074430883
rl training, epoch3, iter0, batch939/1133, batch loss:0.00031430702074430883, Training time:65510.86151885986
batch reward last col mean 4.6018403736525215e-06 first col mean 0.0014973845100030303 all mean 0.0001157904916908592
0.00033328350400552154 0.00033328350400552154
rl training, epoch3, iter0, batch940/1133, batch loss:0.00033328350400552154, Training time:65527.36388754845
batch reward last col mean 0.0007962301024235785 first col mean 0.0018840656848624349 all mean 0.0008424632833339274
0.00047271233052015305 0.00047271227231249213
rl training, epoch3, iter0, batch941/1133, batch loss:0.00047271227231249213, Training time:65543.77116656303
batch reward last col mean 1.4670924429083243e-05 first col mean 0.0021504408214241266 all mean 0.00024319125805050135
0.000669613596983254 0.000669613596983254
rl training, epoch3, iter0, batch942/1133, batch loss:0.000669613596983254, Training time:65560.36584663391
batch reward last col mean 0.00042715948075056076 first col mean 0.0011182200396433473 all mean 0.0005042415577918291
0.0003296959330327809 0.0003296959912404418
rl training, epoch3, iter0, batch943/1133, batch loss:0.0003296959912404418, Training time:65576.76571321487
batch reward last col mean 0.0004163402190897614 first col mean 0.0016585646662861109 all mean 0.0005050278850831091
0.0006614125450141728 0.0006614126032218337
rl training, epoch3, iter0, batch944/1133, batch loss:0.0006614126032218337, Training time:65593.92508387566
batch reward last col mean 0.009489049203693867 first col mean 0.0007500158972106874 all mean 0.007186895236372948
0.0011116198729723692 0.0011116198729723692
rl training, epoch3, iter0, batch945/1133, batch loss:0.0011116198729723692, Training time:65610.5963652134
batch reward last col mean 0.0004876698076259345 first col mean 0.00013486076204571873 all mean 0.0005315230810083449
0.00037029723171144724 0.00037029723171144724
rl training, epoch3, iter0, batch946/1133, batch loss:0.00037029723171144724, Training time:65627.20857834816
batch reward last col mean 0.00023478726507164538 first col mean 0.0020262193866074085 all mean 0.000453383254352957
0.0007255611126311123 0.0007255611126311123
rl training, epoch3, iter0, batch947/1133, batch loss:0.0007255611126311123, Training time:65643.53817486763
batch reward last col mean 1.024822449835483e-05 first col mean 0.0021304634865373373 all mean 0.00021897083206567913
0.0006969533278606832 0.0006969532696530223
rl training, epoch3, iter0, batch948/1133, batch loss:0.0006969532696530223, Training time:65660.3334684372
batch reward last col mean 0.0076056052930653095 first col mean 0.0025624518748372793 all mean 0.006781649775803089
0.00043258245568722486 0.0004325824265833944
rl training, epoch3, iter0, batch949/1133, batch loss:0.0004325824265833944, Training time:65677.04909014702
batch reward last col mean 0.00046783636207692325 first col mean 0.000634628813713789 all mean 0.0005887240986339748
0.0006315195932984352 0.0006315195932984352
rl training, epoch3, iter0, batch950/1133, batch loss:0.0006315195932984352, Training time:65693.45894122124
batch reward last col mean 1.327600512013305e-05 first col mean 0.002842923626303673 all mean 0.0003130781988147646
0.0007521834340877831 0.0007521834340877831
rl training, epoch3, iter0, batch951/1133, batch loss:0.0007521834340877831, Training time:65709.92418909073
batch reward last col mean 1.594781133462675e-05 first col mean 0.001990276388823986 all mean 0.00015440306742675602
0.00034449671511538327 0.0003444967442192137
rl training, epoch3, iter0, batch952/1133, batch loss:0.0003444967442192137, Training time:65726.41117358208
batch reward last col mean 7.957216439535841e-06 first col mean 0.001310277613811195 all mean 0.00013330901856534183
0.0004181940166745335 0.00041819404577836394
rl training, epoch3, iter0, batch953/1133, batch loss:0.00041819404577836394, Training time:65742.9219110012
batch reward last col mean 2.4333792680408806e-05 first col mean 0.001603814191184938 all mean 0.00010867416858673096
0.0002958616241812706 0.0002958616241812706
rl training, epoch3, iter0, batch954/1133, batch loss:0.0002958616241812706, Training time:65759.4243683815
batch reward last col mean 0.0003265524283051491 first col mean 0.0005016319919377565 all mean 0.0005472530610859394
0.0007642759592272341 0.0007642759592272341
rl training, epoch3, iter0, batch955/1133, batch loss:0.0007642759592272341, Training time:65776.0189371109
batch reward last col mean 4.138762960792519e-05 first col mean 0.002043610205873847 all mean 0.00028016563737764955
0.0009059484582394361 0.0009059484582394361
rl training, epoch3, iter0, batch956/1133, batch loss:0.0009059484582394361, Training time:65792.69126224518
batch reward last col mean 0.0023250579833984375 first col mean 0.0010240416740998626 all mean 0.0021692560985684395
0.0006113748531788588 0.0006113747949711978
rl training, epoch3, iter0, batch957/1133, batch loss:0.0006113747949711978, Training time:65809.21361207962
batch reward last col mean 0.0033588248770684004 first col mean 0.004033251665532589 all mean 0.003177344100549817
0.0008818063070066273 0.0008818063070066273
rl training, epoch3, iter0, batch958/1133, batch loss:0.0008818063070066273, Training time:65825.69354224205
batch reward last col mean 0.0001766990462783724 first col mean 3.224774991394952e-05 all mean 0.00021695090981666
0.00041997339576482773 0.00041997339576482773
rl training, epoch3, iter0, batch959/1133, batch loss:0.00041997339576482773, Training time:65842.34774303436
batch reward last col mean 0.0011194866383448243 first col mean 0.002736353315412998 all mean 0.001047148834913969
0.000630423950497061 0.000630423950497061
rl training, epoch3, iter0, batch960/1133, batch loss:0.000630423950497061, Training time:65858.94885897636
batch reward last col mean 0.0013039375189691782 first col mean 0.0019215383799746633 all mean 0.0013397180009633303
0.0005349834100343287 0.0005349834100343287
rl training, epoch3, iter0, batch961/1133, batch loss:0.0005349834100343287, Training time:65875.57788991928
batch reward last col mean 0.0005479898536577821 first col mean 0.0009632757864892483 all mean 0.0005743851070292294
0.0006032268865965307 0.0006032268865965307
rl training, epoch3, iter0, batch962/1133, batch loss:0.0006032268865965307, Training time:65892.30398511887
batch reward last col mean 2.614619461382972e-06 first col mean 0.0007353031542152166 all mean 7.331262168008834e-05
0.0002876890648622066 0.0002876890648622066
rl training, epoch3, iter0, batch963/1133, batch loss:0.0002876890648622066, Training time:65908.90032863617
batch reward last col mean 4.5128406782168895e-05 first col mean 0.00017894917982630432 all mean 0.00012780136603396386
0.0004071395378559828 0.0004071395378559828
rl training, epoch3, iter0, batch964/1133, batch loss:0.0004071395378559828, Training time:65925.34431695938
batch reward last col mean 0.00027212745044380426 first col mean 0.004515412729233503 all mean 0.0004073652089573443
0.000580640509724617 0.0005806405679322779
rl training, epoch3, iter0, batch965/1133, batch loss:0.0005806405679322779, Training time:65941.66750216484
batch reward last col mean 0.00010873835708480328 first col mean 0.0016516909236088395 all mean 0.00021456149988807738
0.0003797965182457119 0.0003797965182457119
rl training, epoch3, iter0, batch966/1133, batch loss:0.0003797965182457119, Training time:65957.98904252052
batch reward last col mean 0.0011860503582283854 first col mean 0.003400825895369053 all mean 0.0010431987466290593
0.0003960315079893917 0.0003960315079893917
rl training, epoch3, iter0, batch967/1133, batch loss:0.0003960315079893917, Training time:65974.45087718964
batch reward last col mean 0.01244933158159256 first col mean 0.00011785930837504566 all mean 0.011147896759212017
0.0011118219699710608 0.0011118219699710608
rl training, epoch3, iter0, batch968/1133, batch loss:0.0011118219699710608, Training time:65991.04034638405
batch reward last col mean 0.0002080418635159731 first col mean 0.0016456320881843567 all mean 0.000326315697748214
0.00043035982525907457 0.00043035982525907457
rl training, epoch3, iter0, batch969/1133, batch loss:0.00043035982525907457, Training time:66007.8131699562
batch reward last col mean 0.0011317949974909425 first col mean 0.0028254203498363495 all mean 0.0011639894219115376
0.0008027323638089001 0.0008027322473935783
rl training, epoch3, iter0, batch970/1133, batch loss:0.0008027322473935783, Training time:66024.28964161873
batch reward last col mean 0.0006229275022633374 first col mean 0.0025805120822042227 all mean 0.0003234620380681008
0.0009359659161418676 0.0009359659161418676
rl training, epoch3, iter0, batch971/1133, batch loss:0.0009359659161418676, Training time:66040.76666212082
batch reward last col mean 1.3652376082973205e-06 first col mean 3.618503615143709e-05 all mean 0.00016894846339710057
0.0005465193535201252 0.0005465193535201252
rl training, epoch3, iter0, batch972/1133, batch loss:0.0005465193535201252, Training time:66057.32901096344
batch reward last col mean 0.0007922687800601125 first col mean 0.0022881159093230963 all mean 0.000958181219175458
0.0009646203252486885 0.0009646203252486885
rl training, epoch3, iter0, batch973/1133, batch loss:0.0009646203252486885, Training time:66073.65058779716
batch reward last col mean 6.294918875937583e-06 first col mean 0.0030168467201292515 all mean 0.00023739946482237428
0.0005506897578015924 0.0005506896995939314
rl training, epoch3, iter0, batch974/1133, batch loss:0.0005506896995939314, Training time:66090.39458537102
batch reward last col mean 3.1453269912162796e-05 first col mean 0.0005261677433736622 all mean 0.00015113425615709275
0.0004750893567688763 0.0004750892985612154
rl training, epoch3, iter0, batch975/1133, batch loss:0.0004750892985612154, Training time:66107.04196000099
batch reward last col mean 0.0003715419734362513 first col mean 0.002390538575127721 all mean 0.0004909101990051568
0.0009387253667227924 0.0009387253085151315
rl training, epoch3, iter0, batch976/1133, batch loss:0.0009387253085151315, Training time:66123.60096144676
batch reward last col mean 0.00012609951954800636 first col mean 0.0015405886806547642 all mean 0.00033198308665305376
0.0007186213042587042 0.0007186212460510433
rl training, epoch3, iter0, batch977/1133, batch loss:0.0007186212460510433, Training time:66140.22720074654
batch reward last col mean 0.0031067035160958767 first col mean 7.287670450750738e-05 all mean 0.002880200045183301
0.0008529676124453545 0.0008529676124453545
rl training, epoch3, iter0, batch978/1133, batch loss:0.0008529676124453545, Training time:66156.76180624962
batch reward last col mean 0.0006272150785662234 first col mean 0.00047638954129070044 all mean 0.0006768073071725667
0.0005296937888488173 0.0005296937306411564
rl training, epoch3, iter0, batch979/1133, batch loss:0.0005296937306411564, Training time:66173.32656407356
batch reward last col mean 0.00011707297380780801 first col mean 4.6648303396068513e-05 all mean 0.00025781927979551256
0.000574702222365886 0.000574702222365886
rl training, epoch3, iter0, batch980/1133, batch loss:0.000574702222365886, Training time:66189.85485339165
batch reward last col mean 8.817907655611634e-06 first col mean 0.0004107482673134655 all mean 0.0002197418361902237
0.0006340240361168981 0.0006340239779092371
rl training, epoch3, iter0, batch981/1133, batch loss:0.0006340239779092371, Training time:66206.31420779228
batch reward last col mean 1.5011402865638956e-05 first col mean 0.0013177762739360332 all mean 0.00023643250460736454
0.000782703747972846 0.000782703747972846
rl training, epoch3, iter0, batch982/1133, batch loss:0.000782703747972846, Training time:66222.90522408485
batch reward last col mean 0.0019311571959406137 first col mean 0.0017895493656396866 all mean 0.0019066842505708337
0.0006076653953641653 0.0006076653953641653
rl training, epoch3, iter0, batch983/1133, batch loss:0.0006076653953641653, Training time:66239.99727511406
batch reward last col mean 0.0006865866016596556 first col mean 0.0019743205048143864 all mean 0.0007166999275796115
0.0005503293359652162 0.0005503293359652162
rl training, epoch3, iter0, batch984/1133, batch loss:0.0005503293359652162, Training time:66257.90894412994
batch reward last col mean 0.0042450702749192715 first col mean 6.407598266378045e-05 all mean 0.004012607038021088
0.0007089493446983397 0.0007089493446983397
rl training, epoch3, iter0, batch985/1133, batch loss:0.0007089493446983397, Training time:66274.49277830124
batch reward last col mean 0.0068194679915905 first col mean 4.7838821046752855e-05 all mean 0.005754988640546799
0.001466421759687364 0.001466421759687364
rl training, epoch3, iter0, batch986/1133, batch loss:0.001466421759687364, Training time:66291.00662136078
batch reward last col mean 0.00169431883841753 first col mean 0.0022073835134506226 all mean 0.001612723572179675
0.001227319473400712 0.001227319473400712
rl training, epoch3, iter0, batch987/1133, batch loss:0.001227319473400712, Training time:66307.61824727058
batch reward last col mean 2.000331187446136e-05 first col mean 0.0016067909309640527 all mean 7.364403427345678e-05
0.00017091259360313416 0.00017091259360313416
rl training, epoch3, iter0, batch988/1133, batch loss:0.00017091259360313416, Training time:66324.25307703018
batch reward last col mean 0.0033572891261428595 first col mean 0.002710221102461219 all mean 0.00331902620382607
0.0012432148214429617 0.0012432148214429617
rl training, epoch3, iter0, batch989/1133, batch loss:0.0012432148214429617, Training time:66340.87887907028
batch reward last col mean 0.0019765538163483143 first col mean 0.0001064930111169815 all mean 0.0019299481064081192
0.0008817738271318376 0.0008817738271318376
rl training, epoch3, iter0, batch990/1133, batch loss:0.0008817738271318376, Training time:66357.46969628334
batch reward last col mean 3.259940058342181e-06 first col mean 0.0015869897324591875 all mean 0.00016979312931653112
0.0003921829629689455 0.0003921829629689455
rl training, epoch3, iter0, batch991/1133, batch loss:0.0003921829629689455, Training time:66374.20962309837
batch reward last col mean 0.00028531093266792595 first col mean 0.001451827585697174 all mean 0.0003399336419533938
0.0004599106905516237 0.0004599106905516237
rl training, epoch3, iter0, batch992/1133, batch loss:0.0004599106905516237, Training time:66390.7618997097
batch reward last col mean 0.0008937703678384423 first col mean 0.0028499108739197254 all mean 0.001111017307266593
0.0007576712523587048 0.0007576712523587048
rl training, epoch3, iter0, batch993/1133, batch loss:0.0007576712523587048, Training time:66407.36512947083
batch reward last col mean 0.003730833064764738 first col mean 0.003182639367878437 all mean 0.003074026433750987
0.002402090234681964 0.0024020904675126076
rl training, epoch3, iter0, batch994/1133, batch loss:0.0024020904675126076, Training time:66423.93329453468
batch reward last col mean 0.007336429785937071 first col mean 0.0036431264597922564 all mean 0.006523264106363058
0.0012554636923596263 0.0012554636923596263
rl training, epoch3, iter0, batch995/1133, batch loss:0.0012554636923596263, Training time:66440.41716122627
batch reward last col mean 0.0001190583934658207 first col mean 0.002235716674476862 all mean 0.0004129913286305964
0.0013170870952308178 0.0013170870952308178
rl training, epoch3, iter0, batch996/1133, batch loss:0.0013170870952308178, Training time:66456.98287796974
batch reward last col mean 0.0006497205467894673 first col mean 0.0017462692921981215 all mean 0.0008074382203631103
0.0010607211152091622 0.0010607211152091622
rl training, epoch3, iter0, batch997/1133, batch loss:0.0010607211152091622, Training time:66473.54776024818
batch reward last col mean 1.747723331391171e-06 first col mean 0.0012822865974158049 all mean 0.0004375764401629567
0.0017359323101118207 0.0017359321936964989
rl training, epoch3, iter0, batch998/1133, batch loss:0.0017359321936964989, Training time:66490.1185760498
batch reward last col mean 0.0005374430911615491 first col mean 0.00021065612963866442 all mean 0.0007030804408714175
0.0007535092299804091 0.0007535092881880701
rl training, epoch3, iter0, batch999/1133, batch loss:0.0007535092881880701, Training time:66506.65564537048
batch reward last col mean 2.164353099942673e-05 first col mean 0.003376043401658535 all mean 0.0004058673803228885
0.0013770281802862883 0.0013770281802862883
rl training, epoch3, iter0, batch1000/1133, batch loss:0.0013770281802862883, Training time:66523.28417277336
batch reward last col mean 0.0031218111980706453 first col mean 0.0003784002037718892 all mean 0.003022674936801195
0.0009420954156666994 0.0009420954156666994
rl training, epoch3, iter0, batch1001/1133, batch loss:0.0009420954156666994, Training time:66539.85660672188
batch reward last col mean 6.886734627187252e-05 first col mean 0.0022517056204378605 all mean 0.0004416523443069309
0.0015333323972299695 0.0015333323972299695
rl training, epoch3, iter0, batch1002/1133, batch loss:0.0015333323972299695, Training time:66556.32740998268
batch reward last col mean 0.0018748326692730188 first col mean 0.007983441464602947 all mean 0.002136906376108527
0.001447917427867651 0.001447917427867651
rl training, epoch3, iter0, batch1003/1133, batch loss:0.001447917427867651, Training time:66572.9064078331
batch reward last col mean 0.0085500068962574 first col mean 0.0035923116374760866 all mean 0.00841958075761795
0.002279008971527219 0.002279008971527219
rl training, epoch3, iter0, batch1004/1133, batch loss:0.002279008971527219, Training time:66589.45746612549
batch reward last col mean 0.006286285817623138 first col mean 0.0017846089322119951 all mean 0.005138265900313854
0.0015494576655328274 0.0015494576655328274
rl training, epoch3, iter0, batch1005/1133, batch loss:0.0015494576655328274, Training time:66606.08867263794
batch reward last col mean 0.0032231344375759363 first col mean 0.003032112028449774 all mean 0.003125675953924656
0.001178186503238976 0.0011781863868236542
rl training, epoch3, iter0, batch1006/1133, batch loss:0.0011781863868236542, Training time:66622.84574246407
batch reward last col mean 0.001342118252068758 first col mean 0.0028508654795587063 all mean 0.0015817862004041672
0.0016559483483433723 0.0016559483483433723
rl training, epoch3, iter0, batch1007/1133, batch loss:0.0016559483483433723, Training time:66639.70344781876
batch reward last col mean 0.00025850950623862445 first col mean 0.00023625617905054241 all mean 0.0004971091402694583
0.0009986109798774123 0.0009986108634620905
rl training, epoch3, iter0, batch1008/1133, batch loss:0.0009986108634620905, Training time:66656.3955309391
batch reward last col mean 0.0077481577172875404 first col mean 0.00029887555865570903 all mean 0.007183204870671034
0.0017749484395608306 0.0017749480903148651
rl training, epoch3, iter0, batch1009/1133, batch loss:0.0017749480903148651, Training time:66673.20748400688
batch reward last col mean 0.002217146335169673 first col mean 0.003462980967015028 all mean 0.0024164244532585144
0.0019481659401208162 0.0019481659401208162
rl training, epoch3, iter0, batch1010/1133, batch loss:0.0019481659401208162, Training time:66689.8286857605
batch reward last col mean 0.004686098080128431 first col mean 0.0017432153690606356 all mean 0.004275583662092686
0.0015187368262559175 0.0015187368262559175
rl training, epoch3, iter0, batch1011/1133, batch loss:0.0015187368262559175, Training time:66706.62033939362
batch reward last col mean 0.0009210911812260747 first col mean 0.0006239803042262793 all mean 0.0011515604564920068
0.0017468067817389965 0.0017468067817389965
rl training, epoch3, iter0, batch1012/1133, batch loss:0.0017468067817389965, Training time:66723.20565414429
batch reward last col mean 0.005415948573499918 first col mean 0.0016267742030322552 all mean 0.005137248430401087
0.0011008704314008355 0.0011008704314008355
rl training, epoch3, iter0, batch1013/1133, batch loss:0.0011008704314008355, Training time:66739.70308160782
batch reward last col mean 0.005016565788537264 first col mean 0.0049921730533242226 all mean 0.004829620476812124
0.0016262338031083345 0.0016262338031083345
rl training, epoch3, iter0, batch1014/1133, batch loss:0.0016262338031083345, Training time:66756.26914548874
batch reward last col mean 0.000773524516262114 first col mean 0.0025487621314823627 all mean 0.0009425439056940377
0.0008345180540345609 0.0008345180540345609
rl training, epoch3, iter0, batch1015/1133, batch loss:0.0008345180540345609, Training time:66772.79679942131
batch reward last col mean 0.003929931670427322 first col mean 0.0020535290241241455 all mean 0.0038699700962752104
0.001092988532036543 0.001092988532036543
rl training, epoch3, iter0, batch1016/1133, batch loss:0.001092988532036543, Training time:66789.42803001404
batch reward last col mean 0.019177047535777092 first col mean 0.007183373905718327 all mean 0.017187118530273438
0.0022748508490622044 0.002274851081892848
rl training, epoch3, iter0, batch1017/1133, batch loss:0.002274851081892848, Training time:66806.14833807945
batch reward last col mean 0.0002744010416790843 first col mean 0.0013464862713590264 all mean 0.0005994506645947695
0.0012133189011365175 0.0012133187847211957
rl training, epoch3, iter0, batch1018/1133, batch loss:0.0012133187847211957, Training time:66822.79453539848
batch reward last col mean 0.00014904193812981248 first col mean 0.007541677448898554 all mean 0.0005364791140891612
0.0014592134393751621 0.0014592134393751621
rl training, epoch3, iter0, batch1019/1133, batch loss:0.0014592134393751621, Training time:66839.58793520927
batch reward last col mean 0.004468666389584541 first col mean 0.0031983130611479282 all mean 0.004558926448225975
0.002619681181386113 0.002619681181386113
rl training, epoch3, iter0, batch1020/1133, batch loss:0.002619681181386113, Training time:66856.32205057144
batch reward last col mean 0.0017004472902044654 first col mean 0.003601682838052511 all mean 0.0017676173010841012
0.0007095495238900185 0.0007095495238900185
rl training, epoch3, iter0, batch1021/1133, batch loss:0.0007095495238900185, Training time:66873.387332201
batch reward last col mean 0.0010623122798278928 first col mean 0.0013345996849238873 all mean 0.0012477808631956577
0.001262063393369317 0.001262063393369317
rl training, epoch3, iter0, batch1022/1133, batch loss:0.001262063393369317, Training time:66890.54387998581
batch reward last col mean 0.0012035374529659748 first col mean 0.0017723165219649673 all mean 0.0014501456171274185
0.002093648072332144 0.002093648072332144
rl training, epoch3, iter0, batch1023/1133, batch loss:0.002093648072332144, Training time:66908.19660329819
batch reward last col mean 1.645166594244074e-05 first col mean 0.0003189171548001468 all mean 0.00014427681162487715
0.000716142647434026 0.0007161427638493478
rl training, epoch3, iter0, batch1024/1133, batch loss:0.0007161427638493478, Training time:66925.07073354721
batch reward last col mean 0.0005825757398270071 first col mean 0.0011611644877120852 all mean 0.0007960940711200237
0.001089943340048194 0.001089943340048194
rl training, epoch3, iter0, batch1025/1133, batch loss:0.001089943340048194, Training time:66942.4788107872
batch reward last col mean 0.011165397241711617 first col mean 0.003259763354435563 all mean 0.010931860655546188
0.0022204939741641283 0.0022204939741641283
rl training, epoch3, iter0, batch1026/1133, batch loss:0.0022204939741641283, Training time:66959.82211232185
batch reward last col mean 0.0025021813344210386 first col mean 0.0011472984915599227 all mean 0.0027859872207045555
0.0021130561362951994 0.0021130561362951994
rl training, epoch3, iter0, batch1027/1133, batch loss:0.0021130561362951994, Training time:66976.47648859024
batch reward last col mean 0.00045521926949732006 first col mean 0.0033266714308410883 all mean 0.0012840956915169954
0.003329838626086712 0.003329838626086712
rl training, epoch3, iter0, batch1028/1133, batch loss:0.003329838626086712, Training time:66993.11160182953
batch reward last col mean 0.005808973219245672 first col mean 0.003786821383982897 all mean 0.0054224091582000256
0.0022103488445281982 0.0022103488445281982
rl training, epoch3, iter0, batch1029/1133, batch loss:0.0022103488445281982, Training time:67009.65363025665
batch reward last col mean 0.0028251605108380318 first col mean 0.002924577798694372 all mean 0.0026878397911787033
0.0017519001848995686 0.001751899952068925
rl training, epoch3, iter0, batch1030/1133, batch loss:0.001751899952068925, Training time:67026.11195516586
batch reward last col mean 0.0009578398312442005 first col mean 0.002653899835422635 all mean 0.0018498996505513787
0.003963447641581297 0.003963447641581297
rl training, epoch3, iter0, batch1031/1133, batch loss:0.003963447641581297, Training time:67042.55004835129
batch reward last col mean 5.219616286922246e-05 first col mean 0.0039388262666761875 all mean 0.0005426955176517367
0.0019862097688019276 0.0019862100016325712
rl training, epoch3, iter0, batch1032/1133, batch loss:0.0019862100016325712, Training time:67058.92776608467
batch reward last col mean 0.0001679980050539598 first col mean 0.00266360305249691 all mean 0.0008107243338599801
0.0029032984748482704 0.0029032984748482704
rl training, epoch3, iter0, batch1033/1133, batch loss:0.0029032984748482704, Training time:67075.45143699646
batch reward last col mean 0.007152973674237728 first col mean 0.0040732785128057 all mean 0.007200371008366346
0.005020264536142349 0.005020264536142349
rl training, epoch3, iter0, batch1034/1133, batch loss:0.005020264536142349, Training time:67092.11007428169
batch reward last col mean 0.008362303487956524 first col mean 0.006245240103453398 all mean 0.007609216962009668
0.006303321570158005 0.00630332063883543
rl training, epoch3, iter0, batch1035/1133, batch loss:0.00630332063883543, Training time:67108.66597104073
batch reward last col mean 0.00817197747528553 first col mean 0.012167449109256268 all mean 0.00890435092151165
0.005905799567699432 0.005905799567699432
rl training, epoch3, iter0, batch1036/1133, batch loss:0.005905799567699432, Training time:67125.35119390488
batch reward last col mean 0.006870286539196968 first col mean 0.000967642932664603 all mean 0.006409907713532448
0.001984334783628583 0.001984334783628583
rl training, epoch3, iter0, batch1037/1133, batch loss:0.001984334783628583, Training time:67142.0095872879
batch reward last col mean 4.767912832903676e-05 first col mean 0.002404422266408801 all mean 0.00043003124301321805
0.0014908644370734692 0.0014908644370734692
rl training, epoch3, iter0, batch1038/1133, batch loss:0.0014908644370734692, Training time:67158.63237595558
batch reward last col mean 0.004835023079067469 first col mean 0.001931232400238514 all mean 0.0037559668999165297
0.0025388405192643404 0.002538840752094984
rl training, epoch3, iter0, batch1039/1133, batch loss:0.002538840752094984, Training time:67175.23779129982
batch reward last col mean 0.007478416431695223 first col mean 0.004649576731026173 all mean 0.007322148885577917
0.00230908440425992 0.0023090846370905638
rl training, epoch3, iter0, batch1040/1133, batch loss:0.0023090846370905638, Training time:67191.77089047432
batch reward last col mean 0.009287671186029911 first col mean 0.005155946593731642 all mean 0.008818311616778374
0.0028303489089012146 0.0028303491417318583
rl training, epoch3, iter0, batch1041/1133, batch loss:0.0028303491417318583, Training time:67208.22434926033
batch reward last col mean 0.00629269378259778 first col mean 0.004988165572285652 all mean 0.0060548377223312855
0.0027924326714128256 0.0027924326714128256
rl training, epoch3, iter0, batch1042/1133, batch loss:0.0027924326714128256, Training time:67224.62046980858
batch reward last col mean 0.007099262438714504 first col mean 0.0048418911173939705 all mean 0.0069868420250713825
0.0060136932879686356 0.0060136932879686356
rl training, epoch3, iter0, batch1043/1133, batch loss:0.0060136932879686356, Training time:67241.12718248367
batch reward last col mean 0.00010833118722075596 first col mean 0.0068750642240047455 all mean 0.0006254167528823018
0.002177037065848708 0.002177037065848708
rl training, epoch3, iter0, batch1044/1133, batch loss:0.002177037065848708, Training time:67257.6474161148
batch reward last col mean 0.009602095000445843 first col mean 0.007132873870432377 all mean 0.009359728544950485
0.004202194977551699 0.004202194977551699
rl training, epoch3, iter0, batch1045/1133, batch loss:0.004202194977551699, Training time:67274.11024594307
batch reward last col mean 0.009811812080442905 first col mean 0.0070739611983299255 all mean 0.0073554334230721
0.0032861169893294573 0.00328611652366817
rl training, epoch3, iter0, batch1046/1133, batch loss:0.00328611652366817, Training time:67290.49920463562
batch reward last col mean 0.017276383936405182 first col mean 0.004895019344985485 all mean 0.016857901588082314
0.006278619170188904 0.006278619635850191
rl training, epoch3, iter0, batch1047/1133, batch loss:0.006278619635850191, Training time:67307.05112147331
batch reward last col mean 0.008948350325226784 first col mean 0.004057686310261488 all mean 0.008807060308754444
0.0061400411650538445 0.0061400411650538445
rl training, epoch3, iter0, batch1048/1133, batch loss:0.0061400411650538445, Training time:67323.60643982887
batch reward last col mean 0.019100431352853775 first col mean 0.01786869391798973 all mean 0.019021881744265556
0.006968891713768244 0.006968891713768244
rl training, epoch3, iter0, batch1049/1133, batch loss:0.006968891713768244, Training time:67340.15239906311
batch reward last col mean 0.007593624759465456 first col mean 0.008887879550457 all mean 0.007207261398434639
0.005303896963596344 0.005303896963596344
rl training, epoch3, iter0, batch1050/1133, batch loss:0.005303896963596344, Training time:67356.49345588684
batch reward last col mean 0.008104553446173668 first col mean 0.009284344501793385 all mean 0.007969972677528858
0.005072005558758974 0.005072005558758974
rl training, epoch3, iter0, batch1051/1133, batch loss:0.005072005558758974, Training time:67373.15533971786
batch reward last col mean 0.0089537613093853 first col mean 0.007627133745700121 all mean 0.00918052438646555
0.007825959473848343 0.007825959473848343
rl training, epoch3, iter0, batch1052/1133, batch loss:0.007825959473848343, Training time:67389.95011734962
batch reward last col mean 0.007389476057142019 first col mean 0.00554752629250288 all mean 0.007526705972850323
0.0060026515275239944 0.0060026515275239944
rl training, epoch3, iter0, batch1053/1133, batch loss:0.0060026515275239944, Training time:67406.70150375366
batch reward last col mean 0.005006168503314257 first col mean 0.015584501437842846 all mean 0.00698066595941782
0.01032810378819704 0.01032810378819704
rl training, epoch3, iter0, batch1054/1133, batch loss:0.01032810378819704, Training time:67423.39365005493
batch reward last col mean 0.0006612638244405389 first col mean 0.006334113422781229 all mean 0.001283524907194078
0.0034239254891872406 0.0034239250235259533
rl training, epoch3, iter0, batch1055/1133, batch loss:0.0034239250235259533, Training time:67440.31947255135
batch reward last col mean 0.004938493017107248 first col mean 0.0035759196616709232 all mean 0.005037104710936546
0.0033153926488012075 0.0033153926488012075
rl training, epoch3, iter0, batch1056/1133, batch loss:0.0033153926488012075, Training time:67457.03834939003
batch reward last col mean 0.021135134622454643 first col mean 0.0171577800065279 all mean 0.020828239619731903
0.008079789578914642 0.008079789578914642
rl training, epoch3, iter0, batch1057/1133, batch loss:0.008079789578914642, Training time:67473.70150542259
batch reward last col mean 0.008734305389225483 first col mean 0.013730145059525967 all mean 0.008931336924433708
0.007691054604947567 0.007691054604947567
rl training, epoch3, iter0, batch1058/1133, batch loss:0.007691054604947567, Training time:67490.50309538841
batch reward last col mean 0.01074580941349268 first col mean 0.014599893242120743 all mean 0.010883651673793793
0.008403632789850235 0.008403632789850235
rl training, epoch3, iter0, batch1059/1133, batch loss:0.008403632789850235, Training time:67507.68733286858
batch reward last col mean 0.017976105213165283 first col mean 0.011302407830953598 all mean 0.017086435109376907
0.01281812321394682 0.01281812135130167
rl training, epoch3, iter0, batch1060/1133, batch loss:0.01281812135130167, Training time:67524.16995716095
batch reward last col mean 0.008730447851121426 first col mean 0.015825126320123672 all mean 0.009446671232581139
0.009349853731691837 0.009349854663014412
rl training, epoch3, iter0, batch1061/1133, batch loss:0.009349854663014412, Training time:67540.60429048538
batch reward last col mean 0.008738360367715359 first col mean 0.020994242280721664 all mean 0.00968350563198328
0.012495690025389194 0.012495690025389194
rl training, epoch3, iter0, batch1062/1133, batch loss:0.012495690025389194, Training time:67557.04307246208
batch reward last col mean 0.015415877103805542 first col mean 0.024892989546060562 all mean 0.016440996900200844
0.013583156280219555 0.013583156280219555
rl training, epoch3, iter0, batch1063/1133, batch loss:0.013583156280219555, Training time:67574.06719636917
batch reward last col mean 0.008940242230892181 first col mean 0.013510704040527344 all mean 0.011543093249201775
0.01961902529001236 0.01961902529001236
rl training, epoch3, iter0, batch1064/1133, batch loss:0.01961902529001236, Training time:67591.49836421013
batch reward last col mean 0.010945085436105728 first col mean 0.01030874066054821 all mean 0.009986377321183681
0.015120655298233032 0.015120655298233032
rl training, epoch3, iter0, batch1065/1133, batch loss:0.015120655298233032, Training time:67608.13280129433
batch reward last col mean 0.005430096760392189 first col mean 0.015504802577197552 all mean 0.007021408062428236
0.011322848498821259 0.011322848498821259
rl training, epoch3, iter0, batch1066/1133, batch loss:0.011322848498821259, Training time:67624.76713085175
batch reward last col mean 0.020601527765393257 first col mean 0.026652544736862183 all mean 0.02140887640416622
0.029461300000548363 0.029461296275258064
rl training, epoch3, iter0, batch1067/1133, batch loss:0.029461296275258064, Training time:67641.53207945824
batch reward last col mean 0.0226228479295969 first col mean 0.013337320648133755 all mean 0.021898169070482254
0.014781209640204906 0.014781209640204906
rl training, epoch3, iter0, batch1068/1133, batch loss:0.014781209640204906, Training time:67658.35217905045
batch reward last col mean 0.006522634066641331 first col mean 0.00820733793079853 all mean 0.006951187737286091
0.008482866920530796 0.00848286785185337
rl training, epoch3, iter0, batch1069/1133, batch loss:0.00848286785185337, Training time:67675.14329695702
batch reward last col mean 0.02057235687971115 first col mean 0.01989474892616272 all mean 0.02117767743766308
0.021634219214320183 0.021634219214320183
rl training, epoch3, iter0, batch1070/1133, batch loss:0.021634219214320183, Training time:67691.68406200409
batch reward last col mean 0.009051818400621414 first col mean 0.011275378987193108 all mean 0.009887869469821453
0.010338868014514446 0.010338868014514446
rl training, epoch3, iter0, batch1071/1133, batch loss:0.010338868014514446, Training time:67708.8566493988
batch reward last col mean 0.02300955168902874 first col mean 0.03046402707695961 all mean 0.02320323884487152
0.02649233676493168 0.02649233676493168
rl training, epoch3, iter0, batch1072/1133, batch loss:0.02649233676493168, Training time:67725.92976737022
batch reward last col mean 0.005314311943948269 first col mean 0.007180740125477314 all mean 0.005833909846842289
0.0074419379234313965 0.007441938854753971
rl training, epoch3, iter0, batch1073/1133, batch loss:0.007441938854753971, Training time:67742.59824824333
batch reward last col mean 0.01074260100722313 first col mean 0.017380163073539734 all mean 0.012464289553463459
0.020702337846159935 0.020702337846159935
rl training, epoch3, iter0, batch1074/1133, batch loss:0.020702337846159935, Training time:67759.32614207268
batch reward last col mean 0.0322037935256958 first col mean 0.02664441615343094 all mean 0.029022909700870514
0.040943484753370285 0.040943484753370285
rl training, epoch3, iter0, batch1075/1133, batch loss:0.040943484753370285, Training time:67776.15869402885
batch reward last col mean 0.02471083775162697 first col mean 0.01911040022969246 all mean 0.02587185986340046
0.03657333552837372 0.03657333552837372
rl training, epoch3, iter0, batch1076/1133, batch loss:0.03657333552837372, Training time:67793.0255947113
batch reward last col mean 0.028207944706082344 first col mean 0.024465782567858696 all mean 0.026989594101905823
0.039578892290592194 0.039578892290592194
rl training, epoch3, iter0, batch1077/1133, batch loss:0.039578892290592194, Training time:67809.72787427902
batch reward last col mean 0.01563301309943199 first col mean 0.017597105354070663 all mean 0.016642967239022255
0.03192707896232605 0.03192707896232605
rl training, epoch3, iter0, batch1078/1133, batch loss:0.03192707896232605, Training time:67826.36360669136
batch reward last col mean 0.02580849826335907 first col mean 0.027303436771035194 all mean 0.024792244657874107
0.058865711092948914 0.058865711092948914
rl training, epoch3, iter0, batch1079/1133, batch loss:0.058865711092948914, Training time:67843.20147657394
batch reward last col mean 0.01881023868918419 first col mean 0.02828323096036911 all mean 0.021507902070879936
0.08198182284832001 0.08198182284832001
rl training, epoch3, iter0, batch1080/1133, batch loss:0.08198182284832001, Training time:67860.03904652596
batch reward last col mean 0.023236893117427826 first col mean 0.023256268352270126 all mean 0.02428118884563446
0.028498634696006775 0.028498634696006775
rl training, epoch3, iter0, batch1081/1133, batch loss:0.028498634696006775, Training time:67876.887611866
batch reward last col mean 0.03558726608753204 first col mean 0.03972519934177399 all mean 0.03610403463244438
0.0477461963891983 0.0477461963891983
rl training, epoch3, iter0, batch1082/1133, batch loss:0.0477461963891983, Training time:67893.78344941139
batch reward last col mean 0.0167287178337574 first col mean 0.024881679564714432 all mean 0.018143992871046066
0.027990637347102165 0.027990637347102165
rl training, epoch3, iter0, batch1083/1133, batch loss:0.027990637347102165, Training time:67910.83853626251
batch reward last col mean 0.02794049121439457 first col mean 0.018839381635189056 all mean 0.024870477616786957
0.030589716508984566 0.030589720234274864
rl training, epoch3, iter0, batch1084/1133, batch loss:0.030589720234274864, Training time:67927.9403719902
batch reward last col mean 0.03243933618068695 first col mean 0.030163198709487915 all mean 0.0318962000310421
0.06404894590377808 0.06404894590377808
rl training, epoch3, iter0, batch1085/1133, batch loss:0.06404894590377808, Training time:67944.92491984367
batch reward last col mean 0.020590893924236298 first col mean 0.020862720906734467 all mean 0.02036474272608757
0.03009931929409504 0.03009931556880474
rl training, epoch3, iter0, batch1086/1133, batch loss:0.03009931556880474, Training time:67962.11840295792
batch reward last col mean 0.014598499983549118 first col mean 0.017745085060596466 all mean 0.015163482166826725
0.029378678649663925 0.029378678649663925
rl training, epoch3, iter0, batch1087/1133, batch loss:0.029378678649663925, Training time:67979.39395332336
batch reward last col mean 0.048540517687797546 first col mean 0.04588507115840912 all mean 0.04856328293681145
0.08118186146020889 0.08118186146020889
rl training, epoch3, iter0, batch1088/1133, batch loss:0.08118186146020889, Training time:67996.50572776794
batch reward last col mean 0.032123226672410965 first col mean 0.023988597095012665 all mean 0.03172042593359947
0.04304138198494911 0.04304138198494911
rl training, epoch3, iter0, batch1089/1133, batch loss:0.04304138198494911, Training time:68013.3280389309
batch reward last col mean 0.014046105556190014 first col mean 0.017764488235116005 all mean 0.01507496926933527
0.046618878841400146 0.046618878841400146
rl training, epoch3, iter0, batch1090/1133, batch loss:0.046618878841400146, Training time:68030.20549154282
batch reward last col mean 0.031066350638866425 first col mean 0.027845051139593124 all mean 0.03126739710569382
0.038912635296583176 0.038912639021873474
rl training, epoch3, iter0, batch1091/1133, batch loss:0.038912639021873474, Training time:68047.0815012455
batch reward last col mean 0.03544929623603821 first col mean 0.026891879737377167 all mean 0.03437601402401924
0.06448744982481003 0.06448744982481003
rl training, epoch3, iter0, batch1092/1133, batch loss:0.06448744982481003, Training time:68064.08786892891
batch reward last col mean 0.042995698750019073 first col mean 0.04260121285915375 all mean 0.04129793122410774
0.08239759504795074 0.08239759504795074
rl training, epoch3, iter0, batch1093/1133, batch loss:0.08239759504795074, Training time:68080.97884273529
batch reward last col mean 0.02751821093261242 first col mean 0.01817919872701168 all mean 0.026945803314447403
0.028664443641901016 0.028664443641901016
rl training, epoch3, iter0, batch1094/1133, batch loss:0.028664443641901016, Training time:68098.03445744514
batch reward last col mean 0.02940291352570057 first col mean 0.029304958879947662 all mean 0.02985101006925106
0.052891459316015244 0.052891459316015244
rl training, epoch3, iter0, batch1095/1133, batch loss:0.052891459316015244, Training time:68115.04113149643
batch reward last col mean 0.019612209871411324 first col mean 0.016473958268761635 all mean 0.01679358072578907
0.02663673274219036 0.026636729016900063
rl training, epoch3, iter0, batch1096/1133, batch loss:0.026636729016900063, Training time:68131.9958190918
batch reward last col mean 0.030233856290578842 first col mean 0.03887108340859413 all mean 0.031353019177913666
0.05391257256269455 0.05391257256269455
rl training, epoch3, iter0, batch1097/1133, batch loss:0.05391257256269455, Training time:68148.91759037971
batch reward last col mean 0.023365072906017303 first col mean 0.03287799283862114 all mean 0.023136412724852562
0.05236917361617088 0.05236917734146118
rl training, epoch3, iter0, batch1098/1133, batch loss:0.05236917734146118, Training time:68165.98666667938
batch reward last col mean 0.01975828781723976 first col mean 0.025193069130182266 all mean 0.020093262195587158
0.029774773865938187 0.029774772003293037
rl training, epoch3, iter0, batch1099/1133, batch loss:0.029774772003293037, Training time:68182.83959841728
batch reward last col mean 0.06750640273094177 first col mean 0.055193521082401276 all mean 0.0641944408416748
0.08105756342411041 0.08105756342411041
rl training, epoch3, iter0, batch1100/1133, batch loss:0.08105756342411041, Training time:68199.70557546616
batch reward last col mean 0.03908802196383476 first col mean 0.03855761140584946 all mean 0.03896881267428398
0.04229920357465744 0.04229920357465744
rl training, epoch3, iter0, batch1101/1133, batch loss:0.04229920357465744, Training time:68216.42957830429
batch reward last col mean 0.023930903524160385 first col mean 0.02458672784268856 all mean 0.024480164051055908
0.0509960800409317 0.0509960800409317
rl training, epoch3, iter0, batch1102/1133, batch loss:0.0509960800409317, Training time:68233.3409178257
batch reward last col mean 0.02940644696354866 first col mean 0.034497037529945374 all mean 0.02979852631688118
0.0606953464448452 0.0606953464448452
rl training, epoch3, iter0, batch1103/1133, batch loss:0.0606953464448452, Training time:68250.14522957802
batch reward last col mean 0.03827662765979767 first col mean 0.03600320592522621 all mean 0.03764791786670685
0.0597493052482605 0.0597493052482605
rl training, epoch3, iter0, batch1104/1133, batch loss:0.0597493052482605, Training time:68267.09456253052
batch reward last col mean 0.053498271852731705 first col mean 0.042125847190618515 all mean 0.05139382183551788
0.07511768490076065 0.07511768490076065
rl training, epoch3, iter0, batch1105/1133, batch loss:0.07511768490076065, Training time:68284.01090145111
batch reward last col mean 0.0674746111035347 first col mean 0.04312983900308609 all mean 0.06627576053142548
0.07173348218202591 0.07173348218202591
rl training, epoch3, iter0, batch1106/1133, batch loss:0.07173348218202591, Training time:68301.43878149986
batch reward last col mean 0.04738612473011017 first col mean 0.040583595633506775 all mean 0.045925382524728775
0.08443275094032288 0.08443275094032288
rl training, epoch3, iter0, batch1107/1133, batch loss:0.08443275094032288, Training time:68318.27763056755
batch reward last col mean 0.046985238790512085 first col mean 0.04091256856918335 all mean 0.04682563990354538
0.08071282505989075 0.08071282505989075
rl training, epoch3, iter0, batch1108/1133, batch loss:0.08071282505989075, Training time:68335.3136446476
batch reward last col mean 0.042880814522504807 first col mean 0.03478134423494339 all mean 0.042718496173620224
0.06099775806069374 0.06099775806069374
rl training, epoch3, iter0, batch1109/1133, batch loss:0.06099775806069374, Training time:68352.41392421722
batch reward last col mean 0.036445312201976776 first col mean 0.02916620299220085 all mean 0.03538829833269119
0.055711135268211365 0.055711135268211365
rl training, epoch3, iter0, batch1110/1133, batch loss:0.055711135268211365, Training time:68369.48927736282
batch reward last col mean 0.030162163078784943 first col mean 0.03981727361679077 all mean 0.031088802963495255
0.05968189612030983 0.05968189612030983
rl training, epoch3, iter0, batch1111/1133, batch loss:0.05968189612030983, Training time:68386.54884386063
batch reward last col mean 0.06238464266061783 first col mean 0.05148489400744438 all mean 0.06293504685163498
0.0831107348203659 0.0831107348203659
rl training, epoch3, iter0, batch1112/1133, batch loss:0.0831107348203659, Training time:68403.57973766327
batch reward last col mean 0.0808430090546608 first col mean 0.06976903229951859 all mean 0.07846128940582275
0.14167189598083496 0.14167189598083496
rl training, epoch3, iter0, batch1113/1133, batch loss:0.14167189598083496, Training time:68420.55229640007
batch reward last col mean 0.10378694534301758 first col mean 0.08148149400949478 all mean 0.09936995804309845
0.19123849272727966 0.19123849272727966
rl training, epoch3, iter0, batch1114/1133, batch loss:0.19123849272727966, Training time:68437.51016116142
batch reward last col mean 0.055946361273527145 first col mean 0.06440941989421844 all mean 0.05818270519375801
0.09433034807443619 0.09433034807443619
rl training, epoch3, iter0, batch1115/1133, batch loss:0.09433034807443619, Training time:68454.4522485733
batch reward last col mean 0.08175940066576004 first col mean 0.07034763693809509 all mean 0.07909736037254333
0.10250414162874222 0.10250414907932281
rl training, epoch3, iter0, batch1116/1133, batch loss:0.10250414907932281, Training time:68471.45551633835
batch reward last col mean 0.09067649394273758 first col mean 0.07904792577028275 all mean 0.09030428528785706
0.13464026153087616 0.13464026153087616
rl training, epoch3, iter0, batch1117/1133, batch loss:0.13464026153087616, Training time:68488.32369923592
batch reward last col mean 0.0676402822136879 first col mean 0.09479119628667831 all mean 0.07021345943212509
0.13086970150470734 0.13086970150470734
rl training, epoch3, iter0, batch1118/1133, batch loss:0.13086970150470734, Training time:68505.22395086288
batch reward last col mean 0.08312319219112396 first col mean 0.09337170422077179 all mean 0.0835912898182869
0.13405323028564453 0.13405323028564453
rl training, epoch3, iter0, batch1119/1133, batch loss:0.13405323028564453, Training time:68522.27595067024
batch reward last col mean 0.10070934891700745 first col mean 0.09622973948717117 all mean 0.10478740930557251
0.20245595276355743 0.20245595276355743
rl training, epoch3, iter0, batch1120/1133, batch loss:0.20245595276355743, Training time:68539.49845862389
batch reward last col mean 0.1283884346485138 first col mean 0.11171365529298782 all mean 0.1287560760974884
0.21758238971233368 0.21758238971233368
rl training, epoch3, iter0, batch1121/1133, batch loss:0.21758238971233368, Training time:68556.60686683655
batch reward last col mean 0.15026116371154785 first col mean 0.1331300586462021 all mean 0.14499133825302124
0.22342745959758759 0.22342745959758759
rl training, epoch3, iter0, batch1122/1133, batch loss:0.22342745959758759, Training time:68573.7552409172
batch reward last col mean 0.12305557727813721 first col mean 0.13152453303337097 all mean 0.12603531777858734
0.17280922830104828 0.17280922830104828
rl training, epoch3, iter0, batch1123/1133, batch loss:0.17280922830104828, Training time:68591.00241541862
batch reward last col mean 0.1746014952659607 first col mean 0.1645713746547699 all mean 0.17659568786621094
0.30909761786460876 0.30909761786460876
rl training, epoch3, iter0, batch1124/1133, batch loss:0.30909761786460876, Training time:68608.2229089737
batch reward last col mean 0.13301914930343628 first col mean 0.1351703703403473 all mean 0.13598373532295227
0.28225862979888916 0.28225862979888916
rl training, epoch3, iter0, batch1125/1133, batch loss:0.28225862979888916, Training time:68625.42118048668
batch reward last col mean 0.16571953892707825 first col mean 0.17590638995170593 all mean 0.16714295744895935
0.32036638259887695 0.32036641240119934
rl training, epoch3, iter0, batch1126/1133, batch loss:0.32036641240119934, Training time:68642.60409832001
batch reward last col mean 0.219826802611351 first col mean 0.18835923075675964 all mean 0.20605602860450745
0.4110000431537628 0.4110001027584076
rl training, epoch3, iter0, batch1127/1133, batch loss:0.4110001027584076, Training time:68659.7315940857
batch reward last col mean 0.20141273736953735 first col mean 0.1763983964920044 all mean 0.20570971071720123
0.5346746444702148 0.5346746444702148
rl training, epoch3, iter0, batch1128/1133, batch loss:0.5346746444702148, Training time:68676.85469603539
batch reward last col mean 0.2378368079662323 first col mean 0.2596963346004486 all mean 0.24057678878307343
0.731533408164978 0.731533408164978
rl training, epoch3, iter0, batch1129/1133, batch loss:0.731533408164978, Training time:68692.15853357315
batch reward last col mean 0.26631397008895874 first col mean 0.27629008889198303 all mean 0.2665468156337738
0.7724676728248596 0.7724676728248596
rl training, epoch3, iter0, batch1130/1133, batch loss:0.7724676728248596, Training time:68702.63708400726
batch reward last col mean 0.2881123125553131 first col mean 0.24240264296531677 all mean 0.2858542501926422
0.8131824731826782 0.8131824731826782
rl training, epoch3, iter0, batch1131/1133, batch loss:0.8131824731826782, Training time:68712.18747401237
batch reward last col mean 0.253972589969635 first col mean 0.22021004557609558 all mean 0.247237890958786
0.8480258584022522 0.8480258584022522
rl training, epoch3, iter0, batch1132/1133, batch loss:0.8480258584022522, Training time:68716.27200436592
rl training, epoch 3, iter 0, loss:0.008294346243449855, Training time:68716.27215313911 
rl epoch 3, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47737782680662144 Time: 101.31382632255554 s
loss of true 0.20638692098861233 loss of gen 0.050217925428288734 loss of other 0.22077297955251646 first score 0.26986926794052124
cur_epoch: 1
D Training Loss: 0.42739327061207866 Time: 105.03577041625977 s
loss of true 0.17895646528764206 loss of gen 0.021280731746597285 loss of other 0.2271560740057915 first score 0.009247725829482079
cur_epoch: 2
D Training Loss: 0.4121807300718296 Time: 100.431161403656 s
loss of true 0.1709781784140106 loss of gen 0.01773116299459203 loss of other 0.22347138835230657 first score 0.010788287036120892
cur_epoch: 3
D Training Loss: 0.38784304238849265 Time: 101.21584963798523 s
loss of true 0.15901880613335023 loss of gen 0.0147280101552881 loss of other 0.21409622617296065 first score 0.02264290861785412
cur_epoch: 4
D Training Loss: 0.3917221497852825 Time: 102.77264523506165 s
loss of true 0.15956972620966997 loss of gen 0.013216519016222388 loss of other 0.2189359040922647 first score 0.012826959602534771
rl epoch 4, begin RL for generator...
batch reward last col mean 0.0010568671859800816 first col mean 0.009759856387972832 all mean 0.0019401340978220105
0.013873952440917492 0.013873952440917492
rl training, epoch4, iter0, batch0/1133, batch loss:0.013873952440917492, Training time:69230.93843340874
batch reward last col mean 0.005292594898492098 first col mean 0.004589691758155823 all mean 0.005567281506955624
0.02118549682199955 0.02118549682199955
rl training, epoch4, iter0, batch1/1133, batch loss:0.02118549682199955, Training time:69233.67301654816
batch reward last col mean 0.011942198500037193 first col mean 0.006217639893293381 all mean 0.010889713652431965
0.023913180455565453 0.023913180455565453
rl training, epoch4, iter0, batch2/1133, batch loss:0.023913180455565453, Training time:69235.67663669586
batch reward last col mean 0.011100728996098042 first col mean 0.008183063939213753 all mean 0.01125855091959238
0.03337908536195755 0.03337908536195755
rl training, epoch4, iter0, batch3/1133, batch loss:0.03337908536195755, Training time:69237.82890319824
batch reward last col mean 0.0019612391479313374 first col mean 0.010645018890500069 all mean 0.003654713509604335
0.029216429218649864 0.029216429218649864
rl training, epoch4, iter0, batch4/1133, batch loss:0.029216429218649864, Training time:69239.26404762268
batch reward last col mean 0.007945843040943146 first col mean 0.008480330929160118 all mean 0.008038559928536415
0.025475407019257545 0.025475407019257545
rl training, epoch4, iter0, batch5/1133, batch loss:0.025475407019257545, Training time:69240.65190052986
batch reward last col mean 0.001836987677961588 first col mean 0.011219360865652561 all mean 0.00461577670648694
0.03286295756697655 0.03286295756697655
rl training, epoch4, iter0, batch6/1133, batch loss:0.03286295756697655, Training time:69241.70606970787
batch reward last col mean 0.012589586898684502 first col mean 0.008077793754637241 all mean 0.012442860752344131
0.03480466827750206 0.03480466827750206
rl training, epoch4, iter0, batch7/1133, batch loss:0.03480466827750206, Training time:69243.11725878716
batch reward last col mean 0.002719445154070854 first col mean 0.01390824094414711 all mean 0.005890147294849157
0.049199122935533524 0.049199122935533524
rl training, epoch4, iter0, batch8/1133, batch loss:0.049199122935533524, Training time:69244.11067605019
batch reward last col mean 0.0031799476128071547 first col mean 0.014867562800645828 all mean 0.004720385652035475
0.03826519101858139 0.03826519101858139
rl training, epoch4, iter0, batch9/1133, batch loss:0.03826519101858139, Training time:69245.47691583633
batch reward last col mean 0.01669527404010296 first col mean 0.008466514758765697 all mean 0.015048625878989697
0.04101629555225372 0.04101629555225372
rl training, epoch4, iter0, batch10/1133, batch loss:0.04101629555225372, Training time:69246.84504771233
batch reward last col mean 0.010098584927618504 first col mean 0.007053459994494915 all mean 0.010605217888951302
0.03176533058285713 0.03176533058285713
rl training, epoch4, iter0, batch11/1133, batch loss:0.03176533058285713, Training time:69247.66595959663
batch reward last col mean 0.004993367474526167 first col mean 0.010295988991856575 all mean 0.008739151991903782
0.04320588707923889 0.04320588707923889
rl training, epoch4, iter0, batch12/1133, batch loss:0.04320588707923889, Training time:69248.34750938416
batch reward last col mean 0.007960854098200798 first col mean 0.013017871417105198 all mean 0.010561954230070114
0.07312504202127457 0.07312503457069397
rl training, epoch4, iter0, batch13/1133, batch loss:0.07312503457069397, Training time:69249.21332335472
batch reward last col mean 0.012833574786782265 first col mean 0.016288381069898605 all mean 0.012970954179763794
0.05774334445595741 0.05774334445595741
rl training, epoch4, iter0, batch14/1133, batch loss:0.05774334445595741, Training time:69250.0904288292
batch reward last col mean 0.01749167963862419 first col mean 0.017061615362763405 all mean 0.01568756438791752
0.06606663018465042 0.06606663018465042
rl training, epoch4, iter0, batch15/1133, batch loss:0.06606663018465042, Training time:69251.06222629547
batch reward last col mean 0.01686142198741436 first col mean 0.020269222557544708 all mean 0.016941063106060028
0.08347859233617783 0.08347859233617783
rl training, epoch4, iter0, batch16/1133, batch loss:0.08347859233617783, Training time:69252.16737294197
batch reward last col mean 0.03117753379046917 first col mean 0.020531143993139267 all mean 0.027446061372756958
0.08640608191490173 0.08640608191490173
rl training, epoch4, iter0, batch17/1133, batch loss:0.08640608191490173, Training time:69252.99917840958
batch reward last col mean 0.010937273502349854 first col mean 0.01832595095038414 all mean 0.01735825277864933
0.11980685591697693 0.11980685591697693
rl training, epoch4, iter0, batch18/1133, batch loss:0.11980685591697693, Training time:69253.7685315609
batch reward last col mean 0.010956228710711002 first col mean 0.02635677345097065 all mean 0.01590438187122345
0.0893922969698906 0.0893922969698906
rl training, epoch4, iter0, batch19/1133, batch loss:0.0893922969698906, Training time:69254.49766469002
batch reward last col mean 0.03537272289395332 first col mean 0.04543263092637062 all mean 0.037591006606817245
0.16661666333675385 0.16661666333675385
rl training, epoch4, iter0, batch20/1133, batch loss:0.16661666333675385, Training time:69255.49828886986
batch reward last col mean 0.03015516698360443 first col mean 0.03893442079424858 all mean 0.03168227896094322
0.13554149866104126 0.13554149866104126
rl training, epoch4, iter0, batch21/1133, batch loss:0.13554149866104126, Training time:69256.16036510468
batch reward last col mean 0.03256051242351532 first col mean 0.03570950776338577 all mean 0.03379220515489578
0.18076975643634796 0.18076975643634796
rl training, epoch4, iter0, batch22/1133, batch loss:0.18076975643634796, Training time:69256.95811152458
batch reward last col mean 0.0333167128264904 first col mean 0.050025440752506256 all mean 0.041444964706897736
0.20272161066532135 0.20272161066532135
rl training, epoch4, iter0, batch23/1133, batch loss:0.20272161066532135, Training time:69257.63170146942
batch reward last col mean 0.04803737625479698 first col mean 0.051374927163124084 all mean 0.051702115684747696
0.24076887965202332 0.24076887965202332
rl training, epoch4, iter0, batch24/1133, batch loss:0.24076887965202332, Training time:69258.58451986313
batch reward last col mean 0.07097944617271423 first col mean 0.0606064647436142 all mean 0.06348948180675507
0.26192960143089294 0.26192960143089294
rl training, epoch4, iter0, batch25/1133, batch loss:0.26192960143089294, Training time:69259.37969493866
batch reward last col mean 0.050389714539051056 first col mean 0.04983455315232277 all mean 0.05467358976602554
0.25858044624328613 0.25858041644096375
rl training, epoch4, iter0, batch26/1133, batch loss:0.25858041644096375, Training time:69260.1350634098
batch reward last col mean 0.06172699108719826 first col mean 0.06497760862112045 all mean 0.06697004288434982
0.2797740697860718 0.27977409958839417
rl training, epoch4, iter0, batch27/1133, batch loss:0.27977409958839417, Training time:69260.69082021713
batch reward last col mean 0.1162416934967041 first col mean 0.08307129144668579 all mean 0.1072651743888855
0.36615657806396484 0.36615657806396484
rl training, epoch4, iter0, batch28/1133, batch loss:0.36615657806396484, Training time:69261.26774430275
batch reward last col mean 0.10500483959913254 first col mean 0.07402024418115616 all mean 0.09315326809883118
0.3129650056362152 0.3129650056362152
rl training, epoch4, iter0, batch29/1133, batch loss:0.3129650056362152, Training time:69261.83042120934
batch reward last col mean 0.1103278174996376 first col mean 0.11424984037876129 all mean 0.1057434231042862
0.36879003047943115 0.36879003047943115
rl training, epoch4, iter0, batch30/1133, batch loss:0.36879003047943115, Training time:69262.31161808968
batch reward last col mean 0.11282306909561157 first col mean 0.11707107722759247 all mean 0.11481984704732895
0.4175628125667572 0.4175628125667572
rl training, epoch4, iter0, batch31/1133, batch loss:0.4175628125667572, Training time:69262.8879749775
batch reward last col mean 0.11262795329093933 first col mean 0.12963858246803284 all mean 0.11700063943862915
0.3959851861000061 0.3959851562976837
rl training, epoch4, iter0, batch32/1133, batch loss:0.3959851562976837, Training time:69263.40517091751
batch reward last col mean 0.10989871621131897 first col mean 0.10554204136133194 all mean 0.11364950984716415
0.4570358991622925 0.4570358991622925
rl training, epoch4, iter0, batch33/1133, batch loss:0.4570358991622925, Training time:69264.26638388634
batch reward last col mean 0.13861426711082458 first col mean 0.1295481026172638 all mean 0.13472577929496765
0.3927040696144104 0.392704039812088
rl training, epoch4, iter0, batch34/1133, batch loss:0.392704039812088, Training time:69264.85766196251
batch reward last col mean 0.18220707774162292 first col mean 0.13637413084506989 all mean 0.18091900646686554
0.529388964176178 0.529388964176178
rl training, epoch4, iter0, batch35/1133, batch loss:0.529388964176178, Training time:69265.60355949402
batch reward last col mean 0.13579733669757843 first col mean 0.1467834711074829 all mean 0.1429206281900406
0.5144172310829163 0.5144172310829163
rl training, epoch4, iter0, batch36/1133, batch loss:0.5144172310829163, Training time:69266.23270225525
batch reward last col mean 0.16080273687839508 first col mean 0.1632901132106781 all mean 0.1672387570142746
0.4832337498664856 0.4832337498664856
rl training, epoch4, iter0, batch37/1133, batch loss:0.4832337498664856, Training time:69266.70916557312
batch reward last col mean 0.2097705602645874 first col mean 0.1845499575138092 all mean 0.20522993803024292
0.5667809247970581 0.5667809844017029
rl training, epoch4, iter0, batch38/1133, batch loss:0.5667809844017029, Training time:69267.4515748024
batch reward last col mean 0.19650831818580627 first col mean 0.20282571017742157 all mean 0.19605624675750732
0.5010956525802612 0.5010956525802612
rl training, epoch4, iter0, batch39/1133, batch loss:0.5010956525802612, Training time:69268.26111912727
batch reward last col mean 0.17466245591640472 first col mean 0.18822190165519714 all mean 0.17554831504821777
0.49531304836273193 0.49531304836273193
rl training, epoch4, iter0, batch40/1133, batch loss:0.49531304836273193, Training time:69269.10971951485
batch reward last col mean 0.15859802067279816 first col mean 0.19925299286842346 all mean 0.1707763820886612
0.4829707145690918 0.4829707145690918
rl training, epoch4, iter0, batch41/1133, batch loss:0.4829707145690918, Training time:69270.03972506523
batch reward last col mean 0.21798427402973175 first col mean 0.22814823687076569 all mean 0.2121451050043106
0.5310171246528625 0.5310171246528625
rl training, epoch4, iter0, batch42/1133, batch loss:0.5310171246528625, Training time:69271.06007122993
batch reward last col mean 0.16654187440872192 first col mean 0.20518778264522552 all mean 0.1686849445104599
0.40099483728408813 0.40099483728408813
rl training, epoch4, iter0, batch43/1133, batch loss:0.40099483728408813, Training time:69272.02799105644
batch reward last col mean 0.23629549145698547 first col mean 0.2168309986591339 all mean 0.22962124645709991
0.5543872117996216 0.5543872117996216
rl training, epoch4, iter0, batch44/1133, batch loss:0.5543872117996216, Training time:69272.79919600487
batch reward last col mean 0.1783902794122696 first col mean 0.2065475434064865 all mean 0.18899540603160858
0.5451247096061707 0.5451247096061707
rl training, epoch4, iter0, batch45/1133, batch loss:0.5451247096061707, Training time:69273.9300839901
batch reward last col mean 0.18527597188949585 first col mean 0.19438476860523224 all mean 0.17700397968292236
0.460814505815506 0.460814505815506
rl training, epoch4, iter0, batch46/1133, batch loss:0.460814505815506, Training time:69274.68200731277
batch reward last col mean 0.19415004551410675 first col mean 0.20999036729335785 all mean 0.1960858702659607
0.4513853192329407 0.45138534903526306
rl training, epoch4, iter0, batch47/1133, batch loss:0.45138534903526306, Training time:69275.7247710228
batch reward last col mean 0.20544403791427612 first col mean 0.19841335713863373 all mean 0.20649148523807526
0.4859997630119324 0.4859997630119324
rl training, epoch4, iter0, batch48/1133, batch loss:0.4859997630119324, Training time:69276.6547601223
batch reward last col mean 0.2592553198337555 first col mean 0.23842982947826385 all mean 0.2501388490200043
0.4957495927810669 0.4957495927810669
rl training, epoch4, iter0, batch49/1133, batch loss:0.4957495927810669, Training time:69277.54266786575
batch reward last col mean 0.23978149890899658 first col mean 0.21160241961479187 all mean 0.2274455577135086
0.49004849791526794 0.49004849791526794
rl training, epoch4, iter0, batch50/1133, batch loss:0.49004849791526794, Training time:69278.48233294487
batch reward last col mean 0.22063270211219788 first col mean 0.22591572999954224 all mean 0.23110271990299225
0.5218275189399719 0.5218275785446167
rl training, epoch4, iter0, batch51/1133, batch loss:0.5218275785446167, Training time:69279.34256410599
batch reward last col mean 0.23555779457092285 first col mean 0.23622724413871765 all mean 0.2369278520345688
0.48396381735801697 0.48396381735801697
rl training, epoch4, iter0, batch52/1133, batch loss:0.48396381735801697, Training time:69280.09107112885
batch reward last col mean 0.22404131293296814 first col mean 0.21090486645698547 all mean 0.2222173810005188
0.4800582230091095 0.4800582230091095
rl training, epoch4, iter0, batch53/1133, batch loss:0.4800582230091095, Training time:69281.22705507278
batch reward last col mean 0.3035702705383301 first col mean 0.24120089411735535 all mean 0.2917296290397644
0.5394378900527954 0.5394378900527954
rl training, epoch4, iter0, batch54/1133, batch loss:0.5394378900527954, Training time:69282.27419924736
batch reward last col mean 0.23297692835330963 first col mean 0.25393474102020264 all mean 0.2379990667104721
0.4960917830467224 0.4960918128490448
rl training, epoch4, iter0, batch55/1133, batch loss:0.4960918128490448, Training time:69283.57126784325
batch reward last col mean 0.24817992746829987 first col mean 0.2288329154253006 all mean 0.24446482956409454
0.4341839849948883 0.4341839849948883
rl training, epoch4, iter0, batch56/1133, batch loss:0.4341839849948883, Training time:69284.3586947918
batch reward last col mean 0.19354848563671112 first col mean 0.2385430932044983 all mean 0.2040511965751648
0.38672471046447754 0.3867247700691223
rl training, epoch4, iter0, batch57/1133, batch loss:0.3867247700691223, Training time:69285.2331969738
batch reward last col mean 0.23880623281002045 first col mean 0.23184676468372345 all mean 0.23362673819065094
0.4797660708427429 0.4797660708427429
rl training, epoch4, iter0, batch58/1133, batch loss:0.4797660708427429, Training time:69286.04424095154
batch reward last col mean 0.25734880566596985 first col mean 0.26071029901504517 all mean 0.2508741617202759
0.515170156955719 0.515170156955719
rl training, epoch4, iter0, batch59/1133, batch loss:0.515170156955719, Training time:69286.86834216118
batch reward last col mean 0.22372058033943176 first col mean 0.2861090898513794 all mean 0.23452848196029663
0.48934873938560486 0.48934876918792725
rl training, epoch4, iter0, batch60/1133, batch loss:0.48934876918792725, Training time:69287.99573993683
batch reward last col mean 0.269634485244751 first col mean 0.2758329510688782 all mean 0.26658526062965393
0.4829705059528351 0.4829705059528351
rl training, epoch4, iter0, batch61/1133, batch loss:0.4829705059528351, Training time:69288.95323085785
batch reward last col mean 0.30352291464805603 first col mean 0.291776567697525 all mean 0.31072402000427246
0.6017652153968811 0.6017651557922363
rl training, epoch4, iter0, batch62/1133, batch loss:0.6017651557922363, Training time:69290.13846302032
batch reward last col mean 0.2532094419002533 first col mean 0.26732102036476135 all mean 0.2691248059272766
0.5418898463249207 0.5418898463249207
rl training, epoch4, iter0, batch63/1133, batch loss:0.5418898463249207, Training time:69291.63552546501
batch reward last col mean 0.26817864179611206 first col mean 0.2836061716079712 all mean 0.27406781911849976
0.5236493349075317 0.5236493349075317
rl training, epoch4, iter0, batch64/1133, batch loss:0.5236493349075317, Training time:69293.8453719616
batch reward last col mean 0.2579537332057953 first col mean 0.26906031370162964 all mean 0.25731509923934937
0.4718227684497833 0.4718227684497833
rl training, epoch4, iter0, batch65/1133, batch loss:0.4718227684497833, Training time:69295.56266069412
batch reward last col mean 0.24973739683628082 first col mean 0.2527232766151428 all mean 0.24682050943374634
0.44825950264930725 0.44825950264930725
rl training, epoch4, iter0, batch66/1133, batch loss:0.44825950264930725, Training time:69297.90664720535
batch reward last col mean 0.3187342584133148 first col mean 0.30574706196784973 all mean 0.31431812047958374
0.5788494944572449 0.5788494944572449
rl training, epoch4, iter0, batch67/1133, batch loss:0.5788494944572449, Training time:69300.38923597336
batch reward last col mean 0.30415815114974976 first col mean 0.2970643937587738 all mean 0.29505959153175354
0.5754274725914001 0.5754274725914001
rl training, epoch4, iter0, batch68/1133, batch loss:0.5754274725914001, Training time:69302.51881051064
batch reward last col mean 0.22113507986068726 first col mean 0.29201462864875793 all mean 0.2336910218000412
0.4789081811904907 0.4789082109928131
rl training, epoch4, iter0, batch69/1133, batch loss:0.4789082109928131, Training time:69305.40072822571
batch reward last col mean 0.24428977072238922 first col mean 0.2561201751232147 all mean 0.24876698851585388
0.49869295954704285 0.49869292974472046
rl training, epoch4, iter0, batch70/1133, batch loss:0.49869292974472046, Training time:69308.54637289047
batch reward last col mean 0.29924625158309937 first col mean 0.28297746181488037 all mean 0.3023618161678314
0.48383355140686035 0.48383355140686035
rl training, epoch4, iter0, batch71/1133, batch loss:0.48383355140686035, Training time:69310.69295811653
batch reward last col mean 0.29315510392189026 first col mean 0.28248560428619385 all mean 0.28958192467689514
0.5461549162864685 0.5461549162864685
rl training, epoch4, iter0, batch72/1133, batch loss:0.5461549162864685, Training time:69312.84544420242
batch reward last col mean 0.24020230770111084 first col mean 0.2566291391849518 all mean 0.24878042936325073
0.4770020842552185 0.47700199484825134
rl training, epoch4, iter0, batch73/1133, batch loss:0.47700199484825134, Training time:69314.78207945824
batch reward last col mean 0.2713242769241333 first col mean 0.283985435962677 all mean 0.2739124000072479
0.49223214387893677 0.49223214387893677
rl training, epoch4, iter0, batch74/1133, batch loss:0.49223214387893677, Training time:69316.76261973381
batch reward last col mean 0.24692344665527344 first col mean 0.25489580631256104 all mean 0.2527220845222473
0.47975218296051025 0.47975218296051025
rl training, epoch4, iter0, batch75/1133, batch loss:0.47975218296051025, Training time:69318.82947444916
batch reward last col mean 0.2632671296596527 first col mean 0.26702743768692017 all mean 0.26550382375717163
0.4127884805202484 0.412788450717926
rl training, epoch4, iter0, batch76/1133, batch loss:0.412788450717926, Training time:69321.55943393707
batch reward last col mean 0.2549368739128113 first col mean 0.27862775325775146 all mean 0.25455495715141296
0.4423409402370453 0.4423409402370453
rl training, epoch4, iter0, batch77/1133, batch loss:0.4423409402370453, Training time:69324.97717738152
batch reward last col mean 0.27412480115890503 first col mean 0.29971441626548767 all mean 0.2745926082134247
0.5242363810539246 0.5242363810539246
rl training, epoch4, iter0, batch78/1133, batch loss:0.5242363810539246, Training time:69327.19476890564
batch reward last col mean 0.33067095279693604 first col mean 0.2812253534793854 all mean 0.32725512981414795
0.48121047019958496 0.48121047019958496
rl training, epoch4, iter0, batch79/1133, batch loss:0.48121047019958496, Training time:69330.64047408104
batch reward last col mean 0.3249378204345703 first col mean 0.3126096725463867 all mean 0.31891682744026184
0.5009549260139465 0.5009549260139465
rl training, epoch4, iter0, batch80/1133, batch loss:0.5009549260139465, Training time:69332.50646924973
batch reward last col mean 0.3106778860092163 first col mean 0.3283468186855316 all mean 0.3155936598777771
0.4704524576663971 0.4704524576663971
rl training, epoch4, iter0, batch81/1133, batch loss:0.4704524576663971, Training time:69334.14019203186
batch reward last col mean 0.31171804666519165 first col mean 0.32198673486709595 all mean 0.3144598603248596
0.5750218629837036 0.5750218629837036
rl training, epoch4, iter0, batch82/1133, batch loss:0.5750218629837036, Training time:69335.86911892891
batch reward last col mean 0.306632936000824 first col mean 0.3500080108642578 all mean 0.316496342420578
0.4815397560596466 0.481539785861969
rl training, epoch4, iter0, batch83/1133, batch loss:0.481539785861969, Training time:69337.20009994507
batch reward last col mean 0.3006325364112854 first col mean 0.34507912397384644 all mean 0.30554232001304626
0.4913112223148346 0.4913112223148346
rl training, epoch4, iter0, batch84/1133, batch loss:0.4913112223148346, Training time:69339.18031597137
batch reward last col mean 0.3146546483039856 first col mean 0.3575032651424408 all mean 0.31968823075294495
0.41475778818130493 0.41475778818130493
rl training, epoch4, iter0, batch85/1133, batch loss:0.41475778818130493, Training time:69340.31818318367
batch reward last col mean 0.3009730875492096 first col mean 0.3258063793182373 all mean 0.3073275089263916
0.4305917024612427 0.4305917024612427
rl training, epoch4, iter0, batch86/1133, batch loss:0.4305917024612427, Training time:69341.64394211769
batch reward last col mean 0.32663196325302124 first col mean 0.3657585382461548 all mean 0.33351171016693115
0.4558468163013458 0.4558468163013458
rl training, epoch4, iter0, batch87/1133, batch loss:0.4558468163013458, Training time:69342.58559632301
batch reward last col mean 0.3142772316932678 first col mean 0.35387110710144043 all mean 0.3194100856781006
0.418794721364975 0.418794721364975
rl training, epoch4, iter0, batch88/1133, batch loss:0.418794721364975, Training time:69343.59041786194
batch reward last col mean 0.34662139415740967 first col mean 0.337226539850235 all mean 0.34647101163864136
0.41405636072158813 0.41405633091926575
rl training, epoch4, iter0, batch89/1133, batch loss:0.41405633091926575, Training time:69344.34629583359
batch reward last col mean 0.36436980962753296 first col mean 0.3612866997718811 all mean 0.3640725016593933
0.4380616545677185 0.4380616545677185
rl training, epoch4, iter0, batch90/1133, batch loss:0.4380616545677185, Training time:69345.37812256813
batch reward last col mean 0.30969423055648804 first col mean 0.3461513817310333 all mean 0.3169756531715393
0.3991180658340454 0.3991180658340454
rl training, epoch4, iter0, batch91/1133, batch loss:0.3991180658340454, Training time:69346.24014210701
batch reward last col mean 0.3433949649333954 first col mean 0.36805275082588196 all mean 0.35998186469078064
0.4120958149433136 0.4120958149433136
rl training, epoch4, iter0, batch92/1133, batch loss:0.4120958149433136, Training time:69347.15522313118
batch reward last col mean 0.29158005118370056 first col mean 0.33234336972236633 all mean 0.30058449506759644
0.2908499836921692 0.2908499836921692
rl training, epoch4, iter0, batch93/1133, batch loss:0.2908499836921692, Training time:69348.02158474922
batch reward last col mean 0.3183099329471588 first col mean 0.35358142852783203 all mean 0.32410377264022827
0.3656451106071472 0.3656451106071472
rl training, epoch4, iter0, batch94/1133, batch loss:0.3656451106071472, Training time:69348.92118406296
batch reward last col mean 0.35820502042770386 first col mean 0.37181609869003296 all mean 0.3655058741569519
0.3667186498641968 0.3667186498641968
rl training, epoch4, iter0, batch95/1133, batch loss:0.3667186498641968, Training time:69349.7565279007
batch reward last col mean 0.28790387511253357 first col mean 0.33466798067092896 all mean 0.3002414405345917
0.3356667459011078 0.3356667459011078
rl training, epoch4, iter0, batch96/1133, batch loss:0.3356667459011078, Training time:69350.68178129196
batch reward last col mean 0.41500967741012573 first col mean 0.3835272192955017 all mean 0.4086649715900421
0.4256487190723419 0.42564868927001953
rl training, epoch4, iter0, batch97/1133, batch loss:0.42564868927001953, Training time:69351.64819145203
batch reward last col mean 0.40070831775665283 first col mean 0.3773071765899658 all mean 0.3851407468318939
0.4047849774360657 0.4047849774360657
rl training, epoch4, iter0, batch98/1133, batch loss:0.4047849774360657, Training time:69352.4426779747
batch reward last col mean 0.3545182943344116 first col mean 0.3693709373474121 all mean 0.3580409288406372
0.40172868967056274 0.40172868967056274
rl training, epoch4, iter0, batch99/1133, batch loss:0.40172868967056274, Training time:69353.38584399223
batch reward last col mean 0.4650280177593231 first col mean 0.4718078374862671 all mean 0.46404558420181274
0.4444882869720459 0.4444882869720459
rl training, epoch4, iter0, batch100/1133, batch loss:0.4444882869720459, Training time:69354.22745370865
batch reward last col mean 0.40910428762435913 first col mean 0.4063900113105774 all mean 0.4079786539077759
0.4017151892185211 0.4017151892185211
rl training, epoch4, iter0, batch101/1133, batch loss:0.4017151892185211, Training time:69354.85554409027
batch reward last col mean 0.3830525279045105 first col mean 0.4015791416168213 all mean 0.37897205352783203
0.3859809637069702 0.3859809637069702
rl training, epoch4, iter0, batch102/1133, batch loss:0.3859809637069702, Training time:69356.10979151726
batch reward last col mean 0.38372424244880676 first col mean 0.3910694420337677 all mean 0.3821505308151245
0.37005823850631714 0.37005823850631714
rl training, epoch4, iter0, batch103/1133, batch loss:0.37005823850631714, Training time:69357.043561697
batch reward last col mean 0.4127924144268036 first col mean 0.40470758080482483 all mean 0.41822564601898193
0.4163880944252014 0.4163880944252014
rl training, epoch4, iter0, batch104/1133, batch loss:0.4163880944252014, Training time:69357.70258188248
batch reward last col mean 0.3911900520324707 first col mean 0.40486079454421997 all mean 0.3910699486732483
0.40338730812072754 0.40338727831840515
rl training, epoch4, iter0, batch105/1133, batch loss:0.40338727831840515, Training time:69359.39853191376
batch reward last col mean 0.4074636697769165 first col mean 0.4063875377178192 all mean 0.4043985605239868
0.35698261857032776 0.35698261857032776
rl training, epoch4, iter0, batch106/1133, batch loss:0.35698261857032776, Training time:69360.48760199547
batch reward last col mean 0.3661138117313385 first col mean 0.3557009994983673 all mean 0.3641546666622162
0.3131535053253174 0.313153475522995
rl training, epoch4, iter0, batch107/1133, batch loss:0.313153475522995, Training time:69361.3567802906
batch reward last col mean 0.3542454242706299 first col mean 0.3740313947200775 all mean 0.3611088991165161
0.383262574672699 0.383262574672699
rl training, epoch4, iter0, batch108/1133, batch loss:0.383262574672699, Training time:69362.03591561317
batch reward last col mean 0.3984747529029846 first col mean 0.3857007324695587 all mean 0.39560383558273315
0.3687365651130676 0.36873650550842285
rl training, epoch4, iter0, batch109/1133, batch loss:0.36873650550842285, Training time:69363.00532698631
batch reward last col mean 0.40531280636787415 first col mean 0.4188488721847534 all mean 0.40596485137939453
0.29405349493026733 0.29405349493026733
rl training, epoch4, iter0, batch110/1133, batch loss:0.29405349493026733, Training time:69363.80173373222
batch reward last col mean 0.3594191074371338 first col mean 0.3932338356971741 all mean 0.3673489987850189
0.2999681532382965 0.2999681532382965
rl training, epoch4, iter0, batch111/1133, batch loss:0.2999681532382965, Training time:69364.53660941124
batch reward last col mean 0.4540305733680725 first col mean 0.4389808475971222 all mean 0.45401981472969055
0.38112783432006836 0.38112783432006836
rl training, epoch4, iter0, batch112/1133, batch loss:0.38112783432006836, Training time:69365.67857670784
batch reward last col mean 0.4107496738433838 first col mean 0.4150943160057068 all mean 0.4123290479183197
0.3622404634952545 0.3622404634952545
rl training, epoch4, iter0, batch113/1133, batch loss:0.3622404634952545, Training time:69366.82270860672
batch reward last col mean 0.403730183839798 first col mean 0.4035058617591858 all mean 0.40380534529685974
0.3358685076236725 0.3358685076236725
rl training, epoch4, iter0, batch114/1133, batch loss:0.3358685076236725, Training time:69368.08432722092
batch reward last col mean 0.3920400142669678 first col mean 0.4002104103565216 all mean 0.39216113090515137
0.3381061851978302 0.3381061851978302
rl training, epoch4, iter0, batch115/1133, batch loss:0.3381061851978302, Training time:69369.26446008682
batch reward last col mean 0.41864556074142456 first col mean 0.4283522069454193 all mean 0.4130229651927948
0.39723390340805054 0.39723390340805054
rl training, epoch4, iter0, batch116/1133, batch loss:0.39723390340805054, Training time:69370.26144957542
batch reward last col mean 0.411418616771698 first col mean 0.44212019443511963 all mean 0.4194663465023041
0.34133803844451904 0.34133803844451904
rl training, epoch4, iter0, batch117/1133, batch loss:0.34133803844451904, Training time:69371.0993745327
batch reward last col mean 0.4418864846229553 first col mean 0.449846476316452 all mean 0.44151854515075684
0.2701798975467682 0.2701798975467682
rl training, epoch4, iter0, batch118/1133, batch loss:0.2701798975467682, Training time:69372.33679938316
batch reward last col mean 0.3673854470252991 first col mean 0.39466702938079834 all mean 0.37170925736427307
0.3060230314731598 0.3060230314731598
rl training, epoch4, iter0, batch119/1133, batch loss:0.3060230314731598, Training time:69373.20969390869
batch reward last col mean 0.371066153049469 first col mean 0.37785908579826355 all mean 0.3724154531955719
0.2826184034347534 0.2826184034347534
rl training, epoch4, iter0, batch120/1133, batch loss:0.2826184034347534, Training time:69374.07337260246
batch reward last col mean 0.40573716163635254 first col mean 0.3905332684516907 all mean 0.40491703152656555
0.2890532612800598 0.2890532612800598
rl training, epoch4, iter0, batch121/1133, batch loss:0.2890532612800598, Training time:69375.0022842884
batch reward last col mean 0.4042673707008362 first col mean 0.41331326961517334 all mean 0.40869003534317017
0.32163840532302856 0.32163843512535095
rl training, epoch4, iter0, batch122/1133, batch loss:0.32163843512535095, Training time:69375.92736625671
batch reward last col mean 0.34268829226493835 first col mean 0.35677266120910645 all mean 0.3525989055633545
0.23320893943309784 0.23320892453193665
rl training, epoch4, iter0, batch123/1133, batch loss:0.23320892453193665, Training time:69376.70613121986
batch reward last col mean 0.471466600894928 first col mean 0.4666881561279297 all mean 0.4729680120944977
0.26624688506126404 0.26624688506126404
rl training, epoch4, iter0, batch124/1133, batch loss:0.26624688506126404, Training time:69377.67898440361
batch reward last col mean 0.4620088040828705 first col mean 0.4704427123069763 all mean 0.4612128734588623
0.34059277176856995 0.34059277176856995
rl training, epoch4, iter0, batch125/1133, batch loss:0.34059277176856995, Training time:69378.48924636841
batch reward last col mean 0.431959331035614 first col mean 0.4585358500480652 all mean 0.43911653757095337
0.3312477767467499 0.3312477767467499
rl training, epoch4, iter0, batch126/1133, batch loss:0.3312477767467499, Training time:69379.44006991386
batch reward last col mean 0.46652448177337646 first col mean 0.44237884879112244 all mean 0.45889759063720703
0.3594311773777008 0.3594311773777008
rl training, epoch4, iter0, batch127/1133, batch loss:0.3594311773777008, Training time:69380.54602646828
batch reward last col mean 0.4239285886287689 first col mean 0.434363454580307 all mean 0.43152546882629395
0.28865376114845276 0.28865379095077515
rl training, epoch4, iter0, batch128/1133, batch loss:0.28865379095077515, Training time:69381.14912748337
batch reward last col mean 0.3882793188095093 first col mean 0.39439332485198975 all mean 0.38959482312202454
0.3165208697319031 0.3165208399295807
rl training, epoch4, iter0, batch129/1133, batch loss:0.3165208399295807, Training time:69382.02737426758
batch reward last col mean 0.36000770330429077 first col mean 0.3579976558685303 all mean 0.3626328110694885
0.2964349389076233 0.2964349687099457
rl training, epoch4, iter0, batch130/1133, batch loss:0.2964349687099457, Training time:69383.18620848656
batch reward last col mean 0.419490784406662 first col mean 0.43326255679130554 all mean 0.4187116026878357
0.228554829955101 0.228554829955101
rl training, epoch4, iter0, batch131/1133, batch loss:0.228554829955101, Training time:69384.40312671661
batch reward last col mean 0.35145190358161926 first col mean 0.3820931911468506 all mean 0.3570965528488159
0.1997024565935135 0.1997024565935135
rl training, epoch4, iter0, batch132/1133, batch loss:0.1997024565935135, Training time:69385.23975110054
batch reward last col mean 0.4404259920120239 first col mean 0.42645734548568726 all mean 0.43603235483169556
0.33216455578804016 0.33216455578804016
rl training, epoch4, iter0, batch133/1133, batch loss:0.33216455578804016, Training time:69386.25668144226
batch reward last col mean 0.4281490445137024 first col mean 0.43201059103012085 all mean 0.430808961391449
0.2755897045135498 0.2755897045135498
rl training, epoch4, iter0, batch134/1133, batch loss:0.2755897045135498, Training time:69387.32523012161
batch reward last col mean 0.4375573992729187 first col mean 0.43226879835128784 all mean 0.4389205574989319
0.3387352526187897 0.3387352526187897
rl training, epoch4, iter0, batch135/1133, batch loss:0.3387352526187897, Training time:69388.11890554428
batch reward last col mean 0.36810287833213806 first col mean 0.3839801549911499 all mean 0.3704072833061218
0.30593764781951904 0.30593764781951904
rl training, epoch4, iter0, batch136/1133, batch loss:0.30593764781951904, Training time:69389.06641674042
batch reward last col mean 0.43456828594207764 first col mean 0.4498542547225952 all mean 0.43272101879119873
0.29140326380729675 0.29140326380729675
rl training, epoch4, iter0, batch137/1133, batch loss:0.29140326380729675, Training time:69390.2688961029
batch reward last col mean 0.47789466381073 first col mean 0.46645012497901917 all mean 0.4749428629875183
0.3124202787876129 0.3124202787876129
rl training, epoch4, iter0, batch138/1133, batch loss:0.3124202787876129, Training time:69390.89528942108
batch reward last col mean 0.428674578666687 first col mean 0.4458247125148773 all mean 0.43164530396461487
0.3487696349620819 0.3487696349620819
rl training, epoch4, iter0, batch139/1133, batch loss:0.3487696349620819, Training time:69391.90489172935
batch reward last col mean 0.41274482011795044 first col mean 0.4181305170059204 all mean 0.41549786925315857
0.3037385940551758 0.3037385940551758
rl training, epoch4, iter0, batch140/1133, batch loss:0.3037385940551758, Training time:69392.66979765892
batch reward last col mean 0.4023173451423645 first col mean 0.4293244779109955 all mean 0.4026472866535187
0.29595494270324707 0.29595494270324707
rl training, epoch4, iter0, batch141/1133, batch loss:0.29595494270324707, Training time:69393.36942911148
batch reward last col mean 0.39492425322532654 first col mean 0.4402446448802948 all mean 0.4003330171108246
0.29935744404792786 0.29935741424560547
rl training, epoch4, iter0, batch142/1133, batch loss:0.29935741424560547, Training time:69394.14286828041
batch reward last col mean 0.4021628499031067 first col mean 0.4076739251613617 all mean 0.4015679955482483
0.2421356439590454 0.2421356588602066
rl training, epoch4, iter0, batch143/1133, batch loss:0.2421356588602066, Training time:69394.64396595955
batch reward last col mean 0.42754659056663513 first col mean 0.41683870553970337 all mean 0.42949429154396057
0.29203855991363525 0.29203855991363525
rl training, epoch4, iter0, batch144/1133, batch loss:0.29203855991363525, Training time:69395.33602380753
batch reward last col mean 0.433057963848114 first col mean 0.44289594888687134 all mean 0.43213391304016113
0.2474878877401352 0.2474878877401352
rl training, epoch4, iter0, batch145/1133, batch loss:0.2474878877401352, Training time:69396.11719608307
batch reward last col mean 0.44414451718330383 first col mean 0.4731287360191345 all mean 0.4540848135948181
0.3535173833370209 0.3535173535346985
rl training, epoch4, iter0, batch146/1133, batch loss:0.3535173535346985, Training time:69396.66172814369
batch reward last col mean 0.45869511365890503 first col mean 0.47348397970199585 all mean 0.4633510708808899
0.2880600690841675 0.2880600392818451
rl training, epoch4, iter0, batch147/1133, batch loss:0.2880600392818451, Training time:69397.19296598434
batch reward last col mean 0.46787911653518677 first col mean 0.4573228359222412 all mean 0.4624124765396118
0.31253379583358765 0.31253379583358765
rl training, epoch4, iter0, batch148/1133, batch loss:0.31253379583358765, Training time:69397.89016461372
batch reward last col mean 0.44021299481391907 first col mean 0.40953725576400757 all mean 0.4332009255886078
0.29539555311203003 0.29539555311203003
rl training, epoch4, iter0, batch149/1133, batch loss:0.29539555311203003, Training time:69398.40518832207
batch reward last col mean 0.40455520153045654 first col mean 0.4276607930660248 all mean 0.4059814214706421
0.31581488251686096 0.31581488251686096
rl training, epoch4, iter0, batch150/1133, batch loss:0.31581488251686096, Training time:69398.94206237793
batch reward last col mean 0.399513840675354 first col mean 0.4552082419395447 all mean 0.40939900279045105
0.29031428694725037 0.29031428694725037
rl training, epoch4, iter0, batch151/1133, batch loss:0.29031428694725037, Training time:69399.68186593056
batch reward last col mean 0.4458240866661072 first col mean 0.44571584463119507 all mean 0.44065243005752563
0.32377079129219055 0.32377079129219055
rl training, epoch4, iter0, batch152/1133, batch loss:0.32377079129219055, Training time:69400.35686969757
batch reward last col mean 0.4746786952018738 first col mean 0.4582284390926361 all mean 0.46701565384864807
0.3280447721481323 0.3280448317527771
rl training, epoch4, iter0, batch153/1133, batch loss:0.3280448317527771, Training time:69400.82845878601
batch reward last col mean 0.3838122487068176 first col mean 0.4121541380882263 all mean 0.3857314884662628
0.2508493661880493 0.2508493661880493
rl training, epoch4, iter0, batch154/1133, batch loss:0.2508493661880493, Training time:69401.45335793495
batch reward last col mean 0.4508025050163269 first col mean 0.44727468490600586 all mean 0.4513707160949707
0.3162732720375061 0.3162733018398285
rl training, epoch4, iter0, batch155/1133, batch loss:0.3162733018398285, Training time:69402.06194591522
batch reward last col mean 0.4823712408542633 first col mean 0.47150877118110657 all mean 0.4803832471370697
0.35906368494033813 0.35906368494033813
rl training, epoch4, iter0, batch156/1133, batch loss:0.35906368494033813, Training time:69402.94241595268
batch reward last col mean 0.40961959958076477 first col mean 0.4295751452445984 all mean 0.41446855664253235
0.30242371559143066 0.30242371559143066
rl training, epoch4, iter0, batch157/1133, batch loss:0.30242371559143066, Training time:69403.82865786552
batch reward last col mean 0.45154324173927307 first col mean 0.4663029611110687 all mean 0.4536544680595398
0.35944733023643494 0.35944733023643494
rl training, epoch4, iter0, batch158/1133, batch loss:0.35944733023643494, Training time:69404.8201777935
batch reward last col mean 0.44344356656074524 first col mean 0.44660913944244385 all mean 0.4417039752006531
0.331933856010437 0.331933856010437
rl training, epoch4, iter0, batch159/1133, batch loss:0.331933856010437, Training time:69405.72100615501
batch reward last col mean 0.4833727478981018 first col mean 0.46886512637138367 all mean 0.48071232438087463
0.329516738653183 0.32951676845550537
rl training, epoch4, iter0, batch160/1133, batch loss:0.32951676845550537, Training time:69406.66397809982
batch reward last col mean 0.41540244221687317 first col mean 0.46532708406448364 all mean 0.42324626445770264
0.3254060447216034 0.3254060447216034
rl training, epoch4, iter0, batch161/1133, batch loss:0.3254060447216034, Training time:69407.74205684662
batch reward last col mean 0.46096980571746826 first col mean 0.4710099697113037 all mean 0.45970335602760315
0.3567788898944855 0.3567788898944855
rl training, epoch4, iter0, batch162/1133, batch loss:0.3567788898944855, Training time:69408.70128750801
batch reward last col mean 0.4373323917388916 first col mean 0.4781760573387146 all mean 0.446617990732193
0.34490376710891724 0.34490376710891724
rl training, epoch4, iter0, batch163/1133, batch loss:0.34490376710891724, Training time:69409.79272985458
batch reward last col mean 0.42664915323257446 first col mean 0.4496261775493622 all mean 0.43000924587249756
0.3475925028324127 0.3475925028324127
rl training, epoch4, iter0, batch164/1133, batch loss:0.3475925028324127, Training time:69410.81297707558
batch reward last col mean 0.4509884715080261 first col mean 0.4993053376674652 all mean 0.4611309766769409
0.3365221321582794 0.3365221321582794
rl training, epoch4, iter0, batch165/1133, batch loss:0.3365221321582794, Training time:69411.5882306099
batch reward last col mean 0.47082483768463135 first col mean 0.46923938393592834 all mean 0.4721209704875946
0.3844395875930786 0.3844395875930786
rl training, epoch4, iter0, batch166/1133, batch loss:0.3844395875930786, Training time:69412.80196070671
batch reward last col mean 0.4377481937408447 first col mean 0.4539948105812073 all mean 0.44244346022605896
0.3527921736240387 0.3527921438217163
rl training, epoch4, iter0, batch167/1133, batch loss:0.3527921438217163, Training time:69414.26699447632
batch reward last col mean 0.4398818016052246 first col mean 0.4749961495399475 all mean 0.4500618577003479
0.33723336458206177 0.33723336458206177
rl training, epoch4, iter0, batch168/1133, batch loss:0.33723336458206177, Training time:69415.65666341782
batch reward last col mean 0.5359758734703064 first col mean 0.5065219402313232 all mean 0.5311668515205383
0.415835440158844 0.415835440158844
rl training, epoch4, iter0, batch169/1133, batch loss:0.415835440158844, Training time:69417.81854915619
batch reward last col mean 0.5093556046485901 first col mean 0.5106997489929199 all mean 0.5107828378677368
0.38595640659332275 0.38595640659332275
rl training, epoch4, iter0, batch170/1133, batch loss:0.38595640659332275, Training time:69421.41002011299
batch reward last col mean 0.40754178166389465 first col mean 0.43409109115600586 all mean 0.4155479073524475
0.30129456520080566 0.30129456520080566
rl training, epoch4, iter0, batch171/1133, batch loss:0.30129456520080566, Training time:69423.26628255844
batch reward last col mean 0.4631672501564026 first col mean 0.4616177976131439 all mean 0.4675058424472809
0.3963112533092499 0.3963111937046051
rl training, epoch4, iter0, batch172/1133, batch loss:0.3963111937046051, Training time:69424.89089131355
batch reward last col mean 0.46496251225471497 first col mean 0.47735533118247986 all mean 0.4705456793308258
0.2752847373485565 0.27528470754623413
rl training, epoch4, iter0, batch173/1133, batch loss:0.27528470754623413, Training time:69426.62317442894
batch reward last col mean 0.5082935690879822 first col mean 0.48673149943351746 all mean 0.5026261806488037
0.3204091489315033 0.3204091787338257
rl training, epoch4, iter0, batch174/1133, batch loss:0.3204091787338257, Training time:69428.2358045578
batch reward last col mean 0.4873499870300293 first col mean 0.4805508255958557 all mean 0.4838663339614868
0.2787795066833496 0.2787795066833496
rl training, epoch4, iter0, batch175/1133, batch loss:0.2787795066833496, Training time:69429.51722121239
batch reward last col mean 0.4584789276123047 first col mean 0.5115277171134949 all mean 0.4700114130973816
0.2937223017215729 0.2937223017215729
rl training, epoch4, iter0, batch176/1133, batch loss:0.2937223017215729, Training time:69430.71140909195
batch reward last col mean 0.49480366706848145 first col mean 0.5086901783943176 all mean 0.496940553188324
0.30714964866638184 0.30714964866638184
rl training, epoch4, iter0, batch177/1133, batch loss:0.30714964866638184, Training time:69432.14331269264
batch reward last col mean 0.5197911262512207 first col mean 0.5019497275352478 all mean 0.5152583718299866
0.31682780385017395 0.31682777404785156
rl training, epoch4, iter0, batch178/1133, batch loss:0.31682777404785156, Training time:69433.10821986198
batch reward last col mean 0.47447580099105835 first col mean 0.5106173753738403 all mean 0.479193776845932
0.2826845943927765 0.2826845943927765
rl training, epoch4, iter0, batch179/1133, batch loss:0.2826845943927765, Training time:69433.9319319725
batch reward last col mean 0.4671574831008911 first col mean 0.4595189690589905 all mean 0.4639439582824707
0.2758288085460663 0.27582883834838867
rl training, epoch4, iter0, batch180/1133, batch loss:0.27582883834838867, Training time:69434.70953559875
batch reward last col mean 0.49964168667793274 first col mean 0.4826687276363373 all mean 0.497520387172699
0.3172595202922821 0.3172595202922821
rl training, epoch4, iter0, batch181/1133, batch loss:0.3172595202922821, Training time:69435.45536327362
batch reward last col mean 0.5109128952026367 first col mean 0.5112015604972839 all mean 0.5081802606582642
0.2893063724040985 0.2893063426017761
rl training, epoch4, iter0, batch182/1133, batch loss:0.2893063426017761, Training time:69436.00982785225
batch reward last col mean 0.4640238881111145 first col mean 0.48683446645736694 all mean 0.47013822197914124
0.2872523367404938 0.2872523367404938
rl training, epoch4, iter0, batch183/1133, batch loss:0.2872523367404938, Training time:69436.824280262
batch reward last col mean 0.5151922106742859 first col mean 0.5398528575897217 all mean 0.5193092823028564
0.28488674759864807 0.28488674759864807
rl training, epoch4, iter0, batch184/1133, batch loss:0.28488674759864807, Training time:69437.68263864517
batch reward last col mean 0.515002429485321 first col mean 0.5399768352508545 all mean 0.51930171251297
0.2484765648841858 0.2484765648841858
rl training, epoch4, iter0, batch185/1133, batch loss:0.2484765648841858, Training time:69438.34430742264
batch reward last col mean 0.5640575289726257 first col mean 0.5678104758262634 all mean 0.5654440522193909
0.27822351455688477 0.27822351455688477
rl training, epoch4, iter0, batch186/1133, batch loss:0.27822351455688477, Training time:69438.92177319527
batch reward last col mean 0.44408124685287476 first col mean 0.5073094367980957 all mean 0.4543747901916504
0.2596418261528015 0.2596418261528015
rl training, epoch4, iter0, batch187/1133, batch loss:0.2596418261528015, Training time:69439.61672449112
batch reward last col mean 0.5137351751327515 first col mean 0.5356298685073853 all mean 0.5155537724494934
0.28750932216644287 0.28750932216644287
rl training, epoch4, iter0, batch188/1133, batch loss:0.28750932216644287, Training time:69440.36235642433
batch reward last col mean 0.4732424020767212 first col mean 0.47323334217071533 all mean 0.4749651551246643
0.24969258904457092 0.24969258904457092
rl training, epoch4, iter0, batch189/1133, batch loss:0.24969258904457092, Training time:69441.18838620186
batch reward last col mean 0.4918197989463806 first col mean 0.526227593421936 all mean 0.4893304407596588
0.2503865361213684 0.2503865361213684
rl training, epoch4, iter0, batch190/1133, batch loss:0.2503865361213684, Training time:69441.99545478821
batch reward last col mean 0.48235267400741577 first col mean 0.48156222701072693 all mean 0.47997432947158813
0.24082998931407928 0.2408299744129181
rl training, epoch4, iter0, batch191/1133, batch loss:0.2408299744129181, Training time:69442.62270522118
batch reward last col mean 0.4735972583293915 first col mean 0.4915948510169983 all mean 0.47344380617141724
0.29479172825813293 0.29479172825813293
rl training, epoch4, iter0, batch192/1133, batch loss:0.29479172825813293, Training time:69443.26886343956
batch reward last col mean 0.48311159014701843 first col mean 0.5075675845146179 all mean 0.485800564289093
0.2545126974582672 0.2545126974582672
rl training, epoch4, iter0, batch193/1133, batch loss:0.2545126974582672, Training time:69443.9072842598
batch reward last col mean 0.4164910912513733 first col mean 0.47287240624427795 all mean 0.42673221230506897
0.24983717501163483 0.24983717501163483
rl training, epoch4, iter0, batch194/1133, batch loss:0.24983717501163483, Training time:69444.46939730644
batch reward last col mean 0.4395809471607208 first col mean 0.4474710524082184 all mean 0.4422623813152313
0.23199985921382904 0.23199984431266785
rl training, epoch4, iter0, batch195/1133, batch loss:0.23199984431266785, Training time:69445.11539816856
batch reward last col mean 0.5029187202453613 first col mean 0.47820228338241577 all mean 0.5023560523986816
0.27273091673851013 0.27273091673851013
rl training, epoch4, iter0, batch196/1133, batch loss:0.27273091673851013, Training time:69445.77685523033
batch reward last col mean 0.4843423068523407 first col mean 0.4969554543495178 all mean 0.4892098903656006
0.2829606533050537 0.2829606533050537
rl training, epoch4, iter0, batch197/1133, batch loss:0.2829606533050537, Training time:69446.35818910599
batch reward last col mean 0.515912652015686 first col mean 0.5164577960968018 all mean 0.5119777917861938
0.26444733142852783 0.26444730162620544
rl training, epoch4, iter0, batch198/1133, batch loss:0.26444730162620544, Training time:69447.15182375908
batch reward last col mean 0.5236912369728088 first col mean 0.5127407312393188 all mean 0.5205082297325134
0.2446146160364151 0.2446146011352539
rl training, epoch4, iter0, batch199/1133, batch loss:0.2446146011352539, Training time:69447.77504563332
batch reward last col mean 0.42486703395843506 first col mean 0.46004387736320496 all mean 0.4366244375705719
0.24165883660316467 0.24165883660316467
rl training, epoch4, iter0, batch200/1133, batch loss:0.24165883660316467, Training time:69448.53255343437
batch reward last col mean 0.5157241821289062 first col mean 0.5119400024414062 all mean 0.5154713988304138
0.25912484526634216 0.25912490487098694
rl training, epoch4, iter0, batch201/1133, batch loss:0.25912490487098694, Training time:69449.4213449955
batch reward last col mean 0.4506150484085083 first col mean 0.46662041544914246 all mean 0.4597877860069275
0.24646110832691193 0.24646110832691193
rl training, epoch4, iter0, batch202/1133, batch loss:0.24646110832691193, Training time:69450.18268871307
batch reward last col mean 0.4892844557762146 first col mean 0.45695334672927856 all mean 0.48913657665252686
0.3181501030921936 0.3181501030921936
rl training, epoch4, iter0, batch203/1133, batch loss:0.3181501030921936, Training time:69451.1142745018
batch reward last col mean 0.5021878480911255 first col mean 0.509331226348877 all mean 0.5060795545578003
0.26227304339408875 0.26227304339408875
rl training, epoch4, iter0, batch204/1133, batch loss:0.26227304339408875, Training time:69451.85045027733
batch reward last col mean 0.49562978744506836 first col mean 0.5093801021575928 all mean 0.5008485913276672
0.20848506689071655 0.20848506689071655
rl training, epoch4, iter0, batch205/1133, batch loss:0.20848506689071655, Training time:69452.356518507
batch reward last col mean 0.4762428104877472 first col mean 0.47058436274528503 all mean 0.4730338454246521
0.27705490589141846 0.27705487608909607
rl training, epoch4, iter0, batch206/1133, batch loss:0.27705487608909607, Training time:69453.10321831703
batch reward last col mean 0.4506743252277374 first col mean 0.48463520407676697 all mean 0.45174440741539
0.2212526798248291 0.2212526649236679
rl training, epoch4, iter0, batch207/1133, batch loss:0.2212526649236679, Training time:69453.76832914352
batch reward last col mean 0.4578606188297272 first col mean 0.46673980355262756 all mean 0.461160808801651
0.23902754485607147 0.23902755975723267
rl training, epoch4, iter0, batch208/1133, batch loss:0.23902755975723267, Training time:69454.41822075844
batch reward last col mean 0.49986732006073 first col mean 0.46338415145874023 all mean 0.4933410882949829
0.2592181861400604 0.2592181861400604
rl training, epoch4, iter0, batch209/1133, batch loss:0.2592181861400604, Training time:69455.11369776726
batch reward last col mean 0.5146164894104004 first col mean 0.5022104978561401 all mean 0.5119704008102417
0.26509422063827515 0.26509422063827515
rl training, epoch4, iter0, batch210/1133, batch loss:0.26509422063827515, Training time:69455.8589527607
batch reward last col mean 0.44184598326683044 first col mean 0.4760648310184479 all mean 0.44696441292762756
0.27295157313346863 0.27295157313346863
rl training, epoch4, iter0, batch211/1133, batch loss:0.27295157313346863, Training time:69456.52652025223
batch reward last col mean 0.45692020654678345 first col mean 0.48270082473754883 all mean 0.464949369430542
0.24364808201789856 0.24364806711673737
rl training, epoch4, iter0, batch212/1133, batch loss:0.24364806711673737, Training time:69457.27911663055
batch reward last col mean 0.5044677257537842 first col mean 0.47524797916412354 all mean 0.5021840333938599
0.32209253311157227 0.32209253311157227
rl training, epoch4, iter0, batch213/1133, batch loss:0.32209253311157227, Training time:69458.55638074875
batch reward last col mean 0.48771122097969055 first col mean 0.49756231904029846 all mean 0.48753437399864197
0.23900729417800903 0.23900730907917023
rl training, epoch4, iter0, batch214/1133, batch loss:0.23900730907917023, Training time:69459.68779802322
batch reward last col mean 0.46925118565559387 first col mean 0.4661409258842468 all mean 0.46273767948150635
0.2266867756843567 0.2266867607831955
rl training, epoch4, iter0, batch215/1133, batch loss:0.2266867607831955, Training time:69460.4118244648
batch reward last col mean 0.4765963852405548 first col mean 0.500084638595581 all mean 0.47445622086524963
0.22226384282112122 0.2222638577222824
rl training, epoch4, iter0, batch216/1133, batch loss:0.2222638577222824, Training time:69461.31730294228
batch reward last col mean 0.42867499589920044 first col mean 0.4541669487953186 all mean 0.4282323718070984
0.19526658952236176 0.19526661932468414
rl training, epoch4, iter0, batch217/1133, batch loss:0.19526661932468414, Training time:69462.1161043644
batch reward last col mean 0.48684945702552795 first col mean 0.48468342423439026 all mean 0.48596906661987305
0.3144250512123108 0.3144250214099884
rl training, epoch4, iter0, batch218/1133, batch loss:0.3144250214099884, Training time:69463.76162052155
batch reward last col mean 0.46085813641548157 first col mean 0.48282307386398315 all mean 0.465977281332016
0.24260085821151733 0.24260085821151733
rl training, epoch4, iter0, batch219/1133, batch loss:0.24260085821151733, Training time:69465.02006101608
batch reward last col mean 0.450433611869812 first col mean 0.4673624634742737 all mean 0.45360854268074036
0.23288553953170776 0.23288553953170776
rl training, epoch4, iter0, batch220/1133, batch loss:0.23288553953170776, Training time:69466.58106589317
batch reward last col mean 0.4625420570373535 first col mean 0.49145546555519104 all mean 0.47077199816703796
0.24620184302330017 0.24620184302330017
rl training, epoch4, iter0, batch221/1133, batch loss:0.24620184302330017, Training time:69467.4816596508
batch reward last col mean 0.5131499171257019 first col mean 0.49481910467147827 all mean 0.5113526582717896
0.2501361668109894 0.2501361668109894
rl training, epoch4, iter0, batch222/1133, batch loss:0.2501361668109894, Training time:69468.35044002533
batch reward last col mean 0.49244391918182373 first col mean 0.4896359443664551 all mean 0.49036523699760437
0.18646864593029022 0.18646864593029022
rl training, epoch4, iter0, batch223/1133, batch loss:0.18646864593029022, Training time:69469.30214548111
batch reward last col mean 0.4412039816379547 first col mean 0.4575002193450928 all mean 0.44443175196647644
0.22830632328987122 0.22830632328987122
rl training, epoch4, iter0, batch224/1133, batch loss:0.22830632328987122, Training time:69470.15807199478
batch reward last col mean 0.48437055945396423 first col mean 0.5006828904151917 all mean 0.482516884803772
0.23971524834632874 0.23971526324748993
rl training, epoch4, iter0, batch225/1133, batch loss:0.23971526324748993, Training time:69471.4950978756
batch reward last col mean 0.4762299954891205 first col mean 0.48932790756225586 all mean 0.4801798462867737
0.2525451183319092 0.2525450885295868
rl training, epoch4, iter0, batch226/1133, batch loss:0.2525450885295868, Training time:69472.40527391434
batch reward last col mean 0.5179944038391113 first col mean 0.5283398628234863 all mean 0.5225996971130371
0.2024989128112793 0.2024989128112793
rl training, epoch4, iter0, batch227/1133, batch loss:0.2024989128112793, Training time:69473.36213874817
batch reward last col mean 0.47321271896362305 first col mean 0.4730871915817261 all mean 0.46749651432037354
0.20950062572956085 0.20950062572956085
rl training, epoch4, iter0, batch228/1133, batch loss:0.20950062572956085, Training time:69474.28893733025
batch reward last col mean 0.49527591466903687 first col mean 0.5277045369148254 all mean 0.5048401355743408
0.2574242353439331 0.2574242651462555
rl training, epoch4, iter0, batch229/1133, batch loss:0.2574242651462555, Training time:69475.21592187881
batch reward last col mean 0.4950883388519287 first col mean 0.4880691170692444 all mean 0.49475356936454773
0.21264873445034027 0.21264873445034027
rl training, epoch4, iter0, batch230/1133, batch loss:0.21264873445034027, Training time:69476.34892010689
batch reward last col mean 0.4393652379512787 first col mean 0.47985702753067017 all mean 0.44755226373672485
0.2007635533809662 0.20076356828212738
rl training, epoch4, iter0, batch231/1133, batch loss:0.20076356828212738, Training time:69477.32288384438
batch reward last col mean 0.5409165620803833 first col mean 0.5324463248252869 all mean 0.5387448668479919
0.25127825140953064 0.25127822160720825
rl training, epoch4, iter0, batch232/1133, batch loss:0.25127822160720825, Training time:69478.11925840378
batch reward last col mean 0.45038169622421265 first col mean 0.44582149386405945 all mean 0.45111265778541565
0.17090122401714325 0.17090122401714325
rl training, epoch4, iter0, batch233/1133, batch loss:0.17090122401714325, Training time:69479.02979874611
batch reward last col mean 0.4599493741989136 first col mean 0.4621429741382599 all mean 0.45978909730911255
0.24110427498817444 0.24110427498817444
rl training, epoch4, iter0, batch234/1133, batch loss:0.24110427498817444, Training time:69479.8953306675
batch reward last col mean 0.5086784362792969 first col mean 0.49353528022766113 all mean 0.5088561177253723
0.2465774416923523 0.2465774416923523
rl training, epoch4, iter0, batch235/1133, batch loss:0.2465774416923523, Training time:69481.3352804184
batch reward last col mean 0.5232529640197754 first col mean 0.506759762763977 all mean 0.5172615647315979
0.30605456233024597 0.30605456233024597
rl training, epoch4, iter0, batch236/1133, batch loss:0.30605456233024597, Training time:69482.13469648361
batch reward last col mean 0.5191576480865479 first col mean 0.5007928609848022 all mean 0.5150811076164246
0.28420397639274597 0.28420397639274597
rl training, epoch4, iter0, batch237/1133, batch loss:0.28420397639274597, Training time:69483.11394548416
batch reward last col mean 0.4943198561668396 first col mean 0.48658251762390137 all mean 0.4922158718109131
0.2861417829990387 0.2861417829990387
rl training, epoch4, iter0, batch238/1133, batch loss:0.2861417829990387, Training time:69484.24947524071
batch reward last col mean 0.4952601194381714 first col mean 0.496049702167511 all mean 0.4975438117980957
0.21180517971515656 0.21180516481399536
rl training, epoch4, iter0, batch239/1133, batch loss:0.21180516481399536, Training time:69485.12974786758
batch reward last col mean 0.49794918298721313 first col mean 0.4986693859100342 all mean 0.495601087808609
0.22621659934520721 0.22621659934520721
rl training, epoch4, iter0, batch240/1133, batch loss:0.22621659934520721, Training time:69486.07238698006
batch reward last col mean 0.5069368481636047 first col mean 0.543488621711731 all mean 0.5138636827468872
0.2544795572757721 0.2544795572757721
rl training, epoch4, iter0, batch241/1133, batch loss:0.2544795572757721, Training time:69487.28203892708
batch reward last col mean 0.5156477093696594 first col mean 0.535287618637085 all mean 0.5170371532440186
0.2296040654182434 0.2296040654182434
rl training, epoch4, iter0, batch242/1133, batch loss:0.2296040654182434, Training time:69488.2707183361
batch reward last col mean 0.4877850115299225 first col mean 0.4842398762702942 all mean 0.4898468554019928
0.20789872109889984 0.20789873600006104
rl training, epoch4, iter0, batch243/1133, batch loss:0.20789873600006104, Training time:69489.21917676926
batch reward last col mean 0.5738523602485657 first col mean 0.5372067093849182 all mean 0.5682647824287415
0.24100112915039062 0.24100112915039062
rl training, epoch4, iter0, batch244/1133, batch loss:0.24100112915039062, Training time:69490.42368793488
batch reward last col mean 0.5214235782623291 first col mean 0.5367647409439087 all mean 0.5234469175338745
0.2529822885990143 0.2529822885990143
rl training, epoch4, iter0, batch245/1133, batch loss:0.2529822885990143, Training time:69492.80904912949
batch reward last col mean 0.5619783997535706 first col mean 0.5584238171577454 all mean 0.559612512588501
0.29056304693222046 0.29056307673454285
rl training, epoch4, iter0, batch246/1133, batch loss:0.29056307673454285, Training time:69494.03049135208
batch reward last col mean 0.535097062587738 first col mean 0.5172162055969238 all mean 0.5366270542144775
0.23115737736225128 0.23115737736225128
rl training, epoch4, iter0, batch247/1133, batch loss:0.23115737736225128, Training time:69494.99402117729
batch reward last col mean 0.4791114330291748 first col mean 0.495636522769928 all mean 0.4838029742240906
0.2793674170970917 0.2793674170970917
rl training, epoch4, iter0, batch248/1133, batch loss:0.2793674170970917, Training time:69496.33593273163
batch reward last col mean 0.5258716940879822 first col mean 0.5222009420394897 all mean 0.5237824320793152
0.23587432503700256 0.23587429523468018
rl training, epoch4, iter0, batch249/1133, batch loss:0.23587429523468018, Training time:69497.45791530609
batch reward last col mean 0.5004689693450928 first col mean 0.5314862728118896 all mean 0.5023457407951355
0.2094980925321579 0.2094980925321579
rl training, epoch4, iter0, batch250/1133, batch loss:0.2094980925321579, Training time:69498.7384569645
batch reward last col mean 0.5245444178581238 first col mean 0.5227094292640686 all mean 0.5224266648292542
0.2788172960281372 0.2788172960281372
rl training, epoch4, iter0, batch251/1133, batch loss:0.2788172960281372, Training time:69500.07711291313
batch reward last col mean 0.4417820870876312 first col mean 0.4652025103569031 all mean 0.4484884738922119
0.20478855073451996 0.20478856563568115
rl training, epoch4, iter0, batch252/1133, batch loss:0.20478856563568115, Training time:69501.07488846779
batch reward last col mean 0.5395591855049133 first col mean 0.5382729172706604 all mean 0.5411150455474854
0.2432660013437271 0.2432660162448883
rl training, epoch4, iter0, batch253/1133, batch loss:0.2432660162448883, Training time:69502.74003076553
batch reward last col mean 0.5271272659301758 first col mean 0.5478326678276062 all mean 0.5257517099380493
0.22771678864955902 0.22771677374839783
rl training, epoch4, iter0, batch254/1133, batch loss:0.22771677374839783, Training time:69504.09438204765
batch reward last col mean 0.52325439453125 first col mean 0.5335637927055359 all mean 0.5268760323524475
0.24215878546237946 0.24215878546237946
rl training, epoch4, iter0, batch255/1133, batch loss:0.24215878546237946, Training time:69505.29949045181
batch reward last col mean 0.4812527298927307 first col mean 0.4995306432247162 all mean 0.48311641812324524
0.2377733290195465 0.2377733290195465
rl training, epoch4, iter0, batch256/1133, batch loss:0.2377733290195465, Training time:69506.99862289429
batch reward last col mean 0.5614954233169556 first col mean 0.5644215941429138 all mean 0.5595762133598328
0.3123045861721039 0.3123045861721039
rl training, epoch4, iter0, batch257/1133, batch loss:0.3123045861721039, Training time:69508.74673724174
batch reward last col mean 0.5019575357437134 first col mean 0.48381945490837097 all mean 0.5014475584030151
0.26799431443214417 0.26799431443214417
rl training, epoch4, iter0, batch258/1133, batch loss:0.26799431443214417, Training time:69510.74250388145
batch reward last col mean 0.5252746939659119 first col mean 0.5105725526809692 all mean 0.5190539956092834
0.26061996817588806 0.26061996817588806
rl training, epoch4, iter0, batch259/1133, batch loss:0.26061996817588806, Training time:69512.06843090057
batch reward last col mean 0.4760076701641083 first col mean 0.4896681308746338 all mean 0.4812917709350586
0.20841661095619202 0.2084166556596756
rl training, epoch4, iter0, batch260/1133, batch loss:0.2084166556596756, Training time:69513.36649537086
batch reward last col mean 0.5306899547576904 first col mean 0.5297268629074097 all mean 0.5311111807823181
0.24501670897006989 0.24501670897006989
rl training, epoch4, iter0, batch261/1133, batch loss:0.24501670897006989, Training time:69515.10749983788
batch reward last col mean 0.47268936038017273 first col mean 0.4849693179130554 all mean 0.47429972887039185
0.19093772768974304 0.19093771278858185
rl training, epoch4, iter0, batch262/1133, batch loss:0.19093771278858185, Training time:69516.71044659615
batch reward last col mean 0.5032737851142883 first col mean 0.5280152559280396 all mean 0.5116742253303528
0.20654980838298798 0.20654982328414917
rl training, epoch4, iter0, batch263/1133, batch loss:0.20654982328414917, Training time:69517.80628705025
batch reward last col mean 0.5261434316635132 first col mean 0.5192565321922302 all mean 0.5189502835273743
0.22135519981384277 0.22135517001152039
rl training, epoch4, iter0, batch264/1133, batch loss:0.22135517001152039, Training time:69518.76516890526
batch reward last col mean 0.505041241645813 first col mean 0.5227096080780029 all mean 0.5068427324295044
0.2010517120361328 0.2010517120361328
rl training, epoch4, iter0, batch265/1133, batch loss:0.2010517120361328, Training time:69519.96070456505
batch reward last col mean 0.5057347416877747 first col mean 0.5033987164497375 all mean 0.5092160701751709
0.25724396109580994 0.25724396109580994
rl training, epoch4, iter0, batch266/1133, batch loss:0.25724396109580994, Training time:69520.75392007828
batch reward last col mean 0.5334014892578125 first col mean 0.5245282053947449 all mean 0.5361222624778748
0.23342770338058472 0.2334277331829071
rl training, epoch4, iter0, batch267/1133, batch loss:0.2334277331829071, Training time:69521.55468249321
batch reward last col mean 0.5262839794158936 first col mean 0.5452566146850586 all mean 0.5288362503051758
0.19348806142807007 0.19348806142807007
rl training, epoch4, iter0, batch268/1133, batch loss:0.19348806142807007, Training time:69522.64591288567
batch reward last col mean 0.4812660217285156 first col mean 0.5044412612915039 all mean 0.4839192032814026
0.13449512422084808 0.1344951093196869
rl training, epoch4, iter0, batch269/1133, batch loss:0.1344951093196869, Training time:69523.6110136509
batch reward last col mean 0.5283000469207764 first col mean 0.541576087474823 all mean 0.530752956867218
0.2595992088317871 0.2595992386341095
rl training, epoch4, iter0, batch270/1133, batch loss:0.2595992386341095, Training time:69524.4744336605
batch reward last col mean 0.489492267370224 first col mean 0.4804525077342987 all mean 0.4875807464122772
0.19400127232074738 0.19400128722190857
rl training, epoch4, iter0, batch271/1133, batch loss:0.19400128722190857, Training time:69525.36331701279
batch reward last col mean 0.4684067368507385 first col mean 0.5023497343063354 all mean 0.47364145517349243
0.20943838357925415 0.20943838357925415
rl training, epoch4, iter0, batch272/1133, batch loss:0.20943838357925415, Training time:69526.05528306961
batch reward last col mean 0.4875035881996155 first col mean 0.49395960569381714 all mean 0.4896881878376007
0.18308623135089874 0.18308623135089874
rl training, epoch4, iter0, batch273/1133, batch loss:0.18308623135089874, Training time:69527.00726771355
batch reward last col mean 0.4892956018447876 first col mean 0.48556584119796753 all mean 0.4904944896697998
0.1747073382139206 0.1747073382139206
rl training, epoch4, iter0, batch274/1133, batch loss:0.1747073382139206, Training time:69527.56384205818
batch reward last col mean 0.526642918586731 first col mean 0.5310545563697815 all mean 0.5319876670837402
0.21687859296798706 0.21687856316566467
rl training, epoch4, iter0, batch275/1133, batch loss:0.21687856316566467, Training time:69528.23561310768
batch reward last col mean 0.5218549370765686 first col mean 0.5507386922836304 all mean 0.5252034068107605
0.26127195358276367 0.26127198338508606
rl training, epoch4, iter0, batch276/1133, batch loss:0.26127198338508606, Training time:69529.35750627518
batch reward last col mean 0.53574538230896 first col mean 0.5482556223869324 all mean 0.5385956764221191
0.2591284215450287 0.2591284215450287
rl training, epoch4, iter0, batch277/1133, batch loss:0.2591284215450287, Training time:69530.25703454018
batch reward last col mean 0.504892885684967 first col mean 0.5054598450660706 all mean 0.5048827528953552
0.21187648177146912 0.21187648177146912
rl training, epoch4, iter0, batch278/1133, batch loss:0.21187648177146912, Training time:69531.71177196503
batch reward last col mean 0.5329393148422241 first col mean 0.5406062602996826 all mean 0.5355188846588135
0.21847926080226898 0.21847926080226898
rl training, epoch4, iter0, batch279/1133, batch loss:0.21847926080226898, Training time:69532.4070584774
batch reward last col mean 0.47987011075019836 first col mean 0.504063069820404 all mean 0.4836675226688385
0.19449307024478912 0.19449308514595032
rl training, epoch4, iter0, batch280/1133, batch loss:0.19449308514595032, Training time:69532.98839521408
batch reward last col mean 0.4854164719581604 first col mean 0.5107997059822083 all mean 0.48850151896476746
0.17030145227909088 0.1703014373779297
rl training, epoch4, iter0, batch281/1133, batch loss:0.1703014373779297, Training time:69533.93450474739
batch reward last col mean 0.47916173934936523 first col mean 0.48873233795166016 all mean 0.4782765209674835
0.23337024450302124 0.23337024450302124
rl training, epoch4, iter0, batch282/1133, batch loss:0.23337024450302124, Training time:69534.94565081596
batch reward last col mean 0.49227288365364075 first col mean 0.49909210205078125 all mean 0.4956548511981964
0.23051442205905914 0.23051440715789795
rl training, epoch4, iter0, batch283/1133, batch loss:0.23051440715789795, Training time:69536.10525918007
batch reward last col mean 0.5324782729148865 first col mean 0.5417887568473816 all mean 0.5401921272277832
0.2114754170179367 0.2114754170179367
rl training, epoch4, iter0, batch284/1133, batch loss:0.2114754170179367, Training time:69536.90852546692
batch reward last col mean 0.521866500377655 first col mean 0.5075721144676208 all mean 0.5216576457023621
0.21709899604320526 0.21709899604320526
rl training, epoch4, iter0, batch285/1133, batch loss:0.21709899604320526, Training time:69538.03662323952
batch reward last col mean 0.509063720703125 first col mean 0.5276451110839844 all mean 0.5117408037185669
0.2242969423532486 0.2242969423532486
rl training, epoch4, iter0, batch286/1133, batch loss:0.2242969423532486, Training time:69539.48268532753
batch reward last col mean 0.4742294251918793 first col mean 0.49867862462997437 all mean 0.48529478907585144
0.1940270960330963 0.1940271109342575
rl training, epoch4, iter0, batch287/1133, batch loss:0.1940271109342575, Training time:69540.2444691658
batch reward last col mean 0.5048778653144836 first col mean 0.5115706920623779 all mean 0.5044865608215332
0.18135181069374084 0.18135176599025726
rl training, epoch4, iter0, batch288/1133, batch loss:0.18135176599025726, Training time:69541.04699277878
batch reward last col mean 0.4947260320186615 first col mean 0.5082888007164001 all mean 0.496084064245224
0.21734057366847992 0.21734057366847992
rl training, epoch4, iter0, batch289/1133, batch loss:0.21734057366847992, Training time:69542.08101987839
batch reward last col mean 0.497641921043396 first col mean 0.5059782862663269 all mean 0.49794256687164307
0.1865331530570984 0.1865331530570984
rl training, epoch4, iter0, batch290/1133, batch loss:0.1865331530570984, Training time:69543.15791583061
batch reward last col mean 0.5563478469848633 first col mean 0.5236828327178955 all mean 0.5516394376754761
0.2579360008239746 0.2579360008239746
rl training, epoch4, iter0, batch291/1133, batch loss:0.2579360008239746, Training time:69544.02242565155
batch reward last col mean 0.524793267250061 first col mean 0.5048140287399292 all mean 0.519680917263031
0.21657799184322357 0.21657800674438477
rl training, epoch4, iter0, batch292/1133, batch loss:0.21657800674438477, Training time:69544.84443283081
batch reward last col mean 0.5055378079414368 first col mean 0.5100466012954712 all mean 0.5049567818641663
0.17756058275699615 0.17756058275699615
rl training, epoch4, iter0, batch293/1133, batch loss:0.17756058275699615, Training time:69546.4319152832
batch reward last col mean 0.5295287370681763 first col mean 0.5389725565910339 all mean 0.5269423723220825
0.16553956270217896 0.16553959250450134
rl training, epoch4, iter0, batch294/1133, batch loss:0.16553959250450134, Training time:69547.18002414703
batch reward last col mean 0.4996865391731262 first col mean 0.4990238845348358 all mean 0.5003036260604858
0.2285132259130478 0.2285132259130478
rl training, epoch4, iter0, batch295/1133, batch loss:0.2285132259130478, Training time:69548.16568827629
batch reward last col mean 0.5182627439498901 first col mean 0.5259671807289124 all mean 0.5175721049308777
0.22333639860153198 0.2233363837003708
rl training, epoch4, iter0, batch296/1133, batch loss:0.2233363837003708, Training time:69549.46499824524
batch reward last col mean 0.5293347239494324 first col mean 0.516779899597168 all mean 0.5317397117614746
0.22586864233016968 0.22586865723133087
rl training, epoch4, iter0, batch297/1133, batch loss:0.22586865723133087, Training time:69552.56795501709
batch reward last col mean 0.48862481117248535 first col mean 0.492841511964798 all mean 0.4895480275154114
0.18741320073604584 0.18741317093372345
rl training, epoch4, iter0, batch298/1133, batch loss:0.18741317093372345, Training time:69553.53294610977
batch reward last col mean 0.5481269359588623 first col mean 0.548590898513794 all mean 0.5469117760658264
0.21430477499961853 0.21430476009845734
rl training, epoch4, iter0, batch299/1133, batch loss:0.21430476009845734, Training time:69554.75358629227
batch reward last col mean 0.527319610118866 first col mean 0.5246146321296692 all mean 0.5283426642417908
0.13164332509040833 0.1316433548927307
rl training, epoch4, iter0, batch300/1133, batch loss:0.1316433548927307, Training time:69555.44589352608
batch reward last col mean 0.4928922653198242 first col mean 0.5327197909355164 all mean 0.5001439452171326
0.19763405621051788 0.19763405621051788
rl training, epoch4, iter0, batch301/1133, batch loss:0.19763405621051788, Training time:69556.34379696846
batch reward last col mean 0.5017730593681335 first col mean 0.5218286514282227 all mean 0.5060057044029236
0.17240804433822632 0.17240804433822632
rl training, epoch4, iter0, batch302/1133, batch loss:0.17240804433822632, Training time:69557.09904623032
batch reward last col mean 0.5785592198371887 first col mean 0.5774042010307312 all mean 0.5771340727806091
0.17481869459152222 0.1748187243938446
rl training, epoch4, iter0, batch303/1133, batch loss:0.1748187243938446, Training time:69557.64770412445
batch reward last col mean 0.5375082492828369 first col mean 0.5557057857513428 all mean 0.5398608446121216
0.17233796417713165 0.17233794927597046
rl training, epoch4, iter0, batch304/1133, batch loss:0.17233794927597046, Training time:69558.23309659958
batch reward last col mean 0.5207611322402954 first col mean 0.5411980152130127 all mean 0.5275188088417053
0.18253058195114136 0.18253058195114136
rl training, epoch4, iter0, batch305/1133, batch loss:0.18253058195114136, Training time:69558.82967305183
batch reward last col mean 0.5356907844543457 first col mean 0.5410656929016113 all mean 0.5360510945320129
0.17188505828380585 0.17188505828380585
rl training, epoch4, iter0, batch306/1133, batch loss:0.17188505828380585, Training time:69559.49959611893
batch reward last col mean 0.5360926389694214 first col mean 0.5606675148010254 all mean 0.5379404425621033
0.1984778493642807 0.1984778493642807
rl training, epoch4, iter0, batch307/1133, batch loss:0.1984778493642807, Training time:69560.20380449295
batch reward last col mean 0.594097375869751 first col mean 0.5919463634490967 all mean 0.5915853381156921
0.1955576241016388 0.1955576241016388
rl training, epoch4, iter0, batch308/1133, batch loss:0.1955576241016388, Training time:69560.8060760498
batch reward last col mean 0.5106903314590454 first col mean 0.5216134190559387 all mean 0.5091975331306458
0.1967805176973343 0.1967805027961731
rl training, epoch4, iter0, batch309/1133, batch loss:0.1967805027961731, Training time:69561.32718515396
batch reward last col mean 0.549822211265564 first col mean 0.5690938234329224 all mean 0.5526816248893738
0.19466546177864075 0.19466546177864075
rl training, epoch4, iter0, batch310/1133, batch loss:0.19466546177864075, Training time:69561.96983361244
batch reward last col mean 0.5471975803375244 first col mean 0.5580626130104065 all mean 0.5494826436042786
0.1624375283718109 0.16243749856948853
rl training, epoch4, iter0, batch311/1133, batch loss:0.16243749856948853, Training time:69562.49953460693
batch reward last col mean 0.5057790875434875 first col mean 0.5306529998779297 all mean 0.5134262442588806
0.2065672129392624 0.2065672129392624
rl training, epoch4, iter0, batch312/1133, batch loss:0.2065672129392624, Training time:69563.2883541584
batch reward last col mean 0.5247688293457031 first col mean 0.5265339016914368 all mean 0.5223820805549622
0.16542670130729675 0.16542674601078033
rl training, epoch4, iter0, batch313/1133, batch loss:0.16542674601078033, Training time:69563.99624419212
batch reward last col mean 0.5486435890197754 first col mean 0.5522150993347168 all mean 0.5529963374137878
0.18723486363887787 0.18723484873771667
rl training, epoch4, iter0, batch314/1133, batch loss:0.18723484873771667, Training time:69564.63741827011
batch reward last col mean 0.5087466239929199 first col mean 0.4980267882347107 all mean 0.5117961764335632
0.1815042942762375 0.1815042942762375
rl training, epoch4, iter0, batch315/1133, batch loss:0.1815042942762375, Training time:69565.4123404026
batch reward last col mean 0.5445149540901184 first col mean 0.5435305833816528 all mean 0.5448142886161804
0.19460399448871613 0.19460399448871613
rl training, epoch4, iter0, batch316/1133, batch loss:0.19460399448871613, Training time:69566.14936494827
batch reward last col mean 0.5072371363639832 first col mean 0.5415182113647461 all mean 0.5178149938583374
0.1897900551557541 0.1897900551557541
rl training, epoch4, iter0, batch317/1133, batch loss:0.1897900551557541, Training time:69566.84373021126
batch reward last col mean 0.5000787973403931 first col mean 0.48315858840942383 all mean 0.492794394493103
0.1605687141418457 0.1605687141418457
rl training, epoch4, iter0, batch318/1133, batch loss:0.1605687141418457, Training time:69567.44243574142
batch reward last col mean 0.5234242677688599 first col mean 0.5649245977401733 all mean 0.5288069248199463
0.18660472333431244 0.18660472333431244
rl training, epoch4, iter0, batch319/1133, batch loss:0.18660472333431244, Training time:69568.52888679504
batch reward last col mean 0.5494425296783447 first col mean 0.5602889060974121 all mean 0.5514045357704163
0.18032830953598022 0.18032830953598022
rl training, epoch4, iter0, batch320/1133, batch loss:0.18032830953598022, Training time:69569.46316480637
batch reward last col mean 0.49630916118621826 first col mean 0.5171980261802673 all mean 0.503634512424469
0.139961376786232 0.13996140658855438
rl training, epoch4, iter0, batch321/1133, batch loss:0.13996140658855438, Training time:69570.15955638885
batch reward last col mean 0.5376493334770203 first col mean 0.5315995812416077 all mean 0.5367306470870972
0.17409196496009827 0.17409195005893707
rl training, epoch4, iter0, batch322/1133, batch loss:0.17409195005893707, Training time:69571.01387119293
batch reward last col mean 0.5729778409004211 first col mean 0.5660951733589172 all mean 0.5678263306617737
0.20662477612495422 0.20662477612495422
rl training, epoch4, iter0, batch323/1133, batch loss:0.20662477612495422, Training time:69571.90242242813
batch reward last col mean 0.5162819623947144 first col mean 0.5527099967002869 all mean 0.5215145349502563
0.18148750066757202 0.18148748576641083
rl training, epoch4, iter0, batch324/1133, batch loss:0.18148748576641083, Training time:69572.90967178345
batch reward last col mean 0.5483812093734741 first col mean 0.5392231345176697 all mean 0.5500186085700989
0.20908212661743164 0.20908212661743164
rl training, epoch4, iter0, batch325/1133, batch loss:0.20908212661743164, Training time:69573.96658802032
batch reward last col mean 0.4913177490234375 first col mean 0.47774165868759155 all mean 0.491191029548645
0.1438390612602234 0.14383907616138458
rl training, epoch4, iter0, batch326/1133, batch loss:0.14383907616138458, Training time:69575.71222543716
batch reward last col mean 0.536574125289917 first col mean 0.5276951789855957 all mean 0.5340346097946167
0.11703246831893921 0.1170324757695198
rl training, epoch4, iter0, batch327/1133, batch loss:0.1170324757695198, Training time:69576.43367147446
batch reward last col mean 0.5628628134727478 first col mean 0.5780626535415649 all mean 0.5629400610923767
0.18105880916118622 0.18105879426002502
rl training, epoch4, iter0, batch328/1133, batch loss:0.18105879426002502, Training time:69577.85086512566
batch reward last col mean 0.4873964786529541 first col mean 0.503922700881958 all mean 0.48874521255493164
0.19420921802520752 0.19420918822288513
rl training, epoch4, iter0, batch329/1133, batch loss:0.19420918822288513, Training time:69579.57435202599
batch reward last col mean 0.5249024629592896 first col mean 0.5384668707847595 all mean 0.5244359374046326
0.1904689520597458 0.19046898186206818
rl training, epoch4, iter0, batch330/1133, batch loss:0.19046898186206818, Training time:69581.2341105938
batch reward last col mean 0.47397854924201965 first col mean 0.4825862944126129 all mean 0.4714321494102478
0.15699337422847748 0.15699337422847748
rl training, epoch4, iter0, batch331/1133, batch loss:0.15699337422847748, Training time:69582.38438081741
batch reward last col mean 0.5226424932479858 first col mean 0.5043845176696777 all mean 0.5250775218009949
0.19516335427761078 0.19516333937644958
rl training, epoch4, iter0, batch332/1133, batch loss:0.19516333937644958, Training time:69583.68097615242
batch reward last col mean 0.5099818110466003 first col mean 0.5433331727981567 all mean 0.5207964777946472
0.19377483427524567 0.19377481937408447
rl training, epoch4, iter0, batch333/1133, batch loss:0.19377481937408447, Training time:69585.16216135025
batch reward last col mean 0.5509679913520813 first col mean 0.543422281742096 all mean 0.5489462614059448
0.20960178971290588 0.2096017599105835
rl training, epoch4, iter0, batch334/1133, batch loss:0.2096017599105835, Training time:69586.77455735207
batch reward last col mean 0.5223441123962402 first col mean 0.5537760853767395 all mean 0.5291969776153564
0.20027080178260803 0.20027078688144684
rl training, epoch4, iter0, batch335/1133, batch loss:0.20027078688144684, Training time:69588.32191061974
batch reward last col mean 0.5229806900024414 first col mean 0.5549221038818359 all mean 0.5247621536254883
0.19743052124977112 0.19743052124977112
rl training, epoch4, iter0, batch336/1133, batch loss:0.19743052124977112, Training time:69589.64330863953
batch reward last col mean 0.5622178316116333 first col mean 0.5575748085975647 all mean 0.5600380301475525
0.19989846646785736 0.19989849627017975
rl training, epoch4, iter0, batch337/1133, batch loss:0.19989849627017975, Training time:69591.57232141495
batch reward last col mean 0.5760619044303894 first col mean 0.5731565952301025 all mean 0.5751999020576477
0.17956030368804932 0.17956030368804932
rl training, epoch4, iter0, batch338/1133, batch loss:0.17956030368804932, Training time:69594.0322637558
batch reward last col mean 0.5643059015274048 first col mean 0.5566835999488831 all mean 0.5583943724632263
0.17889074981212616 0.17889076471328735
rl training, epoch4, iter0, batch339/1133, batch loss:0.17889076471328735, Training time:69595.40937161446
batch reward last col mean 0.47848790884017944 first col mean 0.4816717505455017 all mean 0.4787772297859192
0.15806885063648224 0.15806885063648224
rl training, epoch4, iter0, batch340/1133, batch loss:0.15806885063648224, Training time:69597.06010723114
batch reward last col mean 0.5469297170639038 first col mean 0.5664963722229004 all mean 0.5479353666305542
0.19568593800067902 0.1956859529018402
rl training, epoch4, iter0, batch341/1133, batch loss:0.1956859529018402, Training time:69598.87853908539
batch reward last col mean 0.5158842206001282 first col mean 0.5344204306602478 all mean 0.5184946656227112
0.16217531263828278 0.16217531263828278
rl training, epoch4, iter0, batch342/1133, batch loss:0.16217531263828278, Training time:69600.86719465256
batch reward last col mean 0.514033854007721 first col mean 0.4994282126426697 all mean 0.5107556581497192
0.12609660625457764 0.12609660625457764
rl training, epoch4, iter0, batch343/1133, batch loss:0.12609660625457764, Training time:69601.5760281086
batch reward last col mean 0.4856286346912384 first col mean 0.5088691115379333 all mean 0.4905231297016144
0.13449250161647797 0.13449251651763916
rl training, epoch4, iter0, batch344/1133, batch loss:0.13449251651763916, Training time:69602.5293803215
batch reward last col mean 0.5742735862731934 first col mean 0.5488965511322021 all mean 0.5693832635879517
0.16677284240722656 0.16677284240722656
rl training, epoch4, iter0, batch345/1133, batch loss:0.16677284240722656, Training time:69603.56763863564
batch reward last col mean 0.5565258264541626 first col mean 0.5700030326843262 all mean 0.5555717349052429
0.14722749590873718 0.147227481007576
rl training, epoch4, iter0, batch346/1133, batch loss:0.147227481007576, Training time:69604.17930078506
batch reward last col mean 0.5413892865180969 first col mean 0.5588130354881287 all mean 0.5478830337524414
0.1421918272972107 0.1421918272972107
rl training, epoch4, iter0, batch347/1133, batch loss:0.1421918272972107, Training time:69604.76271080971
batch reward last col mean 0.54908686876297 first col mean 0.5687662959098816 all mean 0.5545121431350708
0.15386806428432465 0.15386806428432465
rl training, epoch4, iter0, batch348/1133, batch loss:0.15386806428432465, Training time:69605.30620765686
batch reward last col mean 0.5483991503715515 first col mean 0.5671728253364563 all mean 0.5493472814559937
0.11148273944854736 0.11148273944854736
rl training, epoch4, iter0, batch349/1133, batch loss:0.11148273944854736, Training time:69605.78209972382
batch reward last col mean 0.5503062605857849 first col mean 0.5696715116500854 all mean 0.5522053837776184
0.15582886338233948 0.15582886338233948
rl training, epoch4, iter0, batch350/1133, batch loss:0.15582886338233948, Training time:69606.33988142014
batch reward last col mean 0.5578269958496094 first col mean 0.5620739459991455 all mean 0.5589364171028137
0.13948726654052734 0.13948726654052734
rl training, epoch4, iter0, batch351/1133, batch loss:0.13948726654052734, Training time:69606.87145709991
batch reward last col mean 0.584250271320343 first col mean 0.5689175724983215 all mean 0.5794461369514465
0.1407449096441269 0.1407449096441269
rl training, epoch4, iter0, batch352/1133, batch loss:0.1407449096441269, Training time:69607.37657737732
batch reward last col mean 0.5207973718643188 first col mean 0.5506274700164795 all mean 0.527523934841156
0.11613265424966812 0.11613263934850693
rl training, epoch4, iter0, batch353/1133, batch loss:0.11613263934850693, Training time:69607.8602514267
batch reward last col mean 0.552070140838623 first col mean 0.5870862603187561 all mean 0.5592787861824036
0.11538703739643097 0.11538703739643097
rl training, epoch4, iter0, batch354/1133, batch loss:0.11538703739643097, Training time:69608.29938864708
batch reward last col mean 0.5561659932136536 first col mean 0.5636700391769409 all mean 0.5592581629753113
0.11901511996984482 0.11901511996984482
rl training, epoch4, iter0, batch355/1133, batch loss:0.11901511996984482, Training time:69608.75677204132
batch reward last col mean 0.4788162112236023 first col mean 0.5269438028335571 all mean 0.48957550525665283
0.1301497370004654 0.1301497370004654
rl training, epoch4, iter0, batch356/1133, batch loss:0.1301497370004654, Training time:69609.20661735535
batch reward last col mean 0.5441693067550659 first col mean 0.5782544612884521 all mean 0.5494598746299744
0.09866004437208176 0.09866004437208176
rl training, epoch4, iter0, batch357/1133, batch loss:0.09866004437208176, Training time:69609.54493188858
batch reward last col mean 0.5315170884132385 first col mean 0.5361295938491821 all mean 0.5306356549263
0.08032217621803284 0.08032217621803284
rl training, epoch4, iter0, batch358/1133, batch loss:0.08032217621803284, Training time:69610.10605120659
batch reward last col mean 0.5648044347763062 first col mean 0.5645816922187805 all mean 0.5614005327224731
0.10928522050380707 0.10928520560264587
rl training, epoch4, iter0, batch359/1133, batch loss:0.10928520560264587, Training time:69610.60627698898
batch reward last col mean 0.5075972676277161 first col mean 0.5235338807106018 all mean 0.5094659328460693
0.11139434576034546 0.11139434576034546
rl training, epoch4, iter0, batch360/1133, batch loss:0.11139434576034546, Training time:69610.9498872757
batch reward last col mean 0.477154403924942 first col mean 0.5000228881835938 all mean 0.4808592200279236
0.08176734298467636 0.08176735043525696
rl training, epoch4, iter0, batch361/1133, batch loss:0.08176735043525696, Training time:69611.34257388115
batch reward last col mean 0.5151258111000061 first col mean 0.5136183500289917 all mean 0.5129368305206299
0.1176338642835617 0.1176338717341423
rl training, epoch4, iter0, batch362/1133, batch loss:0.1176338717341423, Training time:69611.75937604904
batch reward last col mean 0.5717692375183105 first col mean 0.5677348971366882 all mean 0.5696443915367126
0.09788929671049118 0.09788928180932999
rl training, epoch4, iter0, batch363/1133, batch loss:0.09788928180932999, Training time:69612.133923769
batch reward last col mean 0.5645990371704102 first col mean 0.5633066296577454 all mean 0.5663496851921082
0.10468555986881256 0.10468555986881256
rl training, epoch4, iter0, batch364/1133, batch loss:0.10468555986881256, Training time:69612.55938076973
batch reward last col mean 0.5498213768005371 first col mean 0.5452480316162109 all mean 0.5499696731567383
0.08879252523183823 0.08879252523183823
rl training, epoch4, iter0, batch365/1133, batch loss:0.08879252523183823, Training time:69613.02443480492
batch reward last col mean 0.5545874834060669 first col mean 0.5667674541473389 all mean 0.5571316480636597
0.161493182182312 0.1614931970834732
rl training, epoch4, iter0, batch366/1133, batch loss:0.1614931970834732, Training time:69613.4462814331
batch reward last col mean 0.5173007845878601 first col mean 0.5372366905212402 all mean 0.518166720867157
0.11985334008932114 0.11985334753990173
rl training, epoch4, iter0, batch367/1133, batch loss:0.11985334753990173, Training time:69613.88837456703
batch reward last col mean 0.5434581637382507 first col mean 0.5521202683448792 all mean 0.5435347557067871
0.0905098170042038 0.0905098244547844
rl training, epoch4, iter0, batch368/1133, batch loss:0.0905098244547844, Training time:69614.29943823814
batch reward last col mean 0.5539003610610962 first col mean 0.5717519521713257 all mean 0.5576621294021606
0.10755733400583267 0.10755736380815506
rl training, epoch4, iter0, batch369/1133, batch loss:0.10755736380815506, Training time:69614.7858543396
batch reward last col mean 0.551572859287262 first col mean 0.5847280025482178 all mean 0.5559059381484985
0.12229098379611969 0.1222909688949585
rl training, epoch4, iter0, batch370/1133, batch loss:0.1222909688949585, Training time:69615.15833997726
batch reward last col mean 0.5909401178359985 first col mean 0.5853971242904663 all mean 0.5870232582092285
0.1243748664855957 0.1243748664855957
rl training, epoch4, iter0, batch371/1133, batch loss:0.1243748664855957, Training time:69615.48737430573
batch reward last col mean 0.6268136501312256 first col mean 0.6137675046920776 all mean 0.6247292757034302
0.1499270647764206 0.1499270647764206
rl training, epoch4, iter0, batch372/1133, batch loss:0.1499270647764206, Training time:69615.99244999886
batch reward last col mean 0.6311938166618347 first col mean 0.627373993396759 all mean 0.6306145787239075
0.14423905313014984 0.14423905313014984
rl training, epoch4, iter0, batch373/1133, batch loss:0.14423905313014984, Training time:69616.44188904762
batch reward last col mean 0.5482746362686157 first col mean 0.5481303930282593 all mean 0.5491328239440918
0.09227524697780609 0.09227526187896729
rl training, epoch4, iter0, batch374/1133, batch loss:0.09227526187896729, Training time:69616.83848929405
batch reward last col mean 0.5970094799995422 first col mean 0.6020915508270264 all mean 0.5937968492507935
0.1273612529039383 0.1273612380027771
rl training, epoch4, iter0, batch375/1133, batch loss:0.1273612380027771, Training time:69617.25723648071
batch reward last col mean 0.6365320682525635 first col mean 0.6119334697723389 all mean 0.6290224194526672
0.10604365915060043 0.10604365915060043
rl training, epoch4, iter0, batch376/1133, batch loss:0.10604365915060043, Training time:69617.61195206642
batch reward last col mean 0.5662360191345215 first col mean 0.5717722177505493 all mean 0.5692600011825562
0.11027013510465622 0.11027013510465622
rl training, epoch4, iter0, batch377/1133, batch loss:0.11027013510465622, Training time:69617.98260521889
batch reward last col mean 0.5495632290840149 first col mean 0.536401093006134 all mean 0.5459436178207397
0.1344119757413864 0.1344119757413864
rl training, epoch4, iter0, batch378/1133, batch loss:0.1344119757413864, Training time:69618.38690948486
batch reward last col mean 0.5818148851394653 first col mean 0.5724710822105408 all mean 0.5805411338806152
0.1350882202386856 0.1350882202386856
rl training, epoch4, iter0, batch379/1133, batch loss:0.1350882202386856, Training time:69618.89553117752
batch reward last col mean 0.5596098303794861 first col mean 0.53672194480896 all mean 0.5599538087844849
0.1451597958803177 0.1451597958803177
rl training, epoch4, iter0, batch380/1133, batch loss:0.1451597958803177, Training time:69619.59987401962
batch reward last col mean 0.5393509864807129 first col mean 0.5607025623321533 all mean 0.5445351004600525
0.12534186244010925 0.12534189224243164
rl training, epoch4, iter0, batch381/1133, batch loss:0.12534189224243164, Training time:69620.13959956169
batch reward last col mean 0.5416699647903442 first col mean 0.5510731935501099 all mean 0.5425313115119934
0.10827720910310745 0.10827720165252686
rl training, epoch4, iter0, batch382/1133, batch loss:0.10827720165252686, Training time:69620.5245976448
batch reward last col mean 0.5432522892951965 first col mean 0.5728306770324707 all mean 0.550555944442749
0.15571054816246033 0.15571053326129913
rl training, epoch4, iter0, batch383/1133, batch loss:0.15571053326129913, Training time:69620.92190480232
batch reward last col mean 0.5472869873046875 first col mean 0.5670377612113953 all mean 0.5490245819091797
0.12922276556491852 0.12922275066375732
rl training, epoch4, iter0, batch384/1133, batch loss:0.12922275066375732, Training time:69621.31503582001
batch reward last col mean 0.5621676445007324 first col mean 0.5708954334259033 all mean 0.5669142007827759
0.08995751291513443 0.08995750546455383
rl training, epoch4, iter0, batch385/1133, batch loss:0.08995750546455383, Training time:69621.74498319626
batch reward last col mean 0.562303900718689 first col mean 0.5907078385353088 all mean 0.5703915953636169
0.1497316062450409 0.14973163604736328
rl training, epoch4, iter0, batch386/1133, batch loss:0.14973163604736328, Training time:69622.23008823395
batch reward last col mean 0.4935210347175598 first col mean 0.5068943500518799 all mean 0.49684274196624756
0.13971517980098724 0.13971516489982605
rl training, epoch4, iter0, batch387/1133, batch loss:0.13971516489982605, Training time:69622.69993376732
batch reward last col mean 0.585913360118866 first col mean 0.616162896156311 all mean 0.5926994681358337
0.12097916752099991 0.12097916752099991
rl training, epoch4, iter0, batch388/1133, batch loss:0.12097916752099991, Training time:69623.13376688957
batch reward last col mean 0.5423803329467773 first col mean 0.5431948304176331 all mean 0.5435882806777954
0.10554789751768112 0.10554789751768112
rl training, epoch4, iter0, batch389/1133, batch loss:0.10554789751768112, Training time:69623.66025352478
batch reward last col mean 0.5528333187103271 first col mean 0.5377812385559082 all mean 0.5516778826713562
0.1349475234746933 0.1349475383758545
rl training, epoch4, iter0, batch390/1133, batch loss:0.1349475383758545, Training time:69624.18581914902
batch reward last col mean 0.6176416277885437 first col mean 0.6302474737167358 all mean 0.6218951344490051
0.15328340232372284 0.15328340232372284
rl training, epoch4, iter0, batch391/1133, batch loss:0.15328340232372284, Training time:69624.6525990963
batch reward last col mean 0.5458915829658508 first col mean 0.544487476348877 all mean 0.5485338568687439
0.11570879817008972 0.11570881307125092
rl training, epoch4, iter0, batch392/1133, batch loss:0.11570881307125092, Training time:69625.12173104286
batch reward last col mean 0.5517040491104126 first col mean 0.5625495910644531 all mean 0.5506368279457092
0.15632303059101105 0.15632303059101105
rl training, epoch4, iter0, batch393/1133, batch loss:0.15632303059101105, Training time:69625.63668584824
batch reward last col mean 0.5605459213256836 first col mean 0.5395991802215576 all mean 0.5556887984275818
0.15098926424980164 0.15098924934864044
rl training, epoch4, iter0, batch394/1133, batch loss:0.15098924934864044, Training time:69626.10863566399
batch reward last col mean 0.5070666074752808 first col mean 0.5203811526298523 all mean 0.5114604830741882
0.11977030336856842 0.11977030336856842
rl training, epoch4, iter0, batch395/1133, batch loss:0.11977030336856842, Training time:69626.5470752716
batch reward last col mean 0.5565236806869507 first col mean 0.551763653755188 all mean 0.5545465350151062
0.1434362828731537 0.1434362679719925
rl training, epoch4, iter0, batch396/1133, batch loss:0.1434362679719925, Training time:69627.05291128159
batch reward last col mean 0.5767449140548706 first col mean 0.5848937630653381 all mean 0.5760611295700073
0.13380911946296692 0.13380911946296692
rl training, epoch4, iter0, batch397/1133, batch loss:0.13380911946296692, Training time:69627.59662413597
batch reward last col mean 0.5552530288696289 first col mean 0.5532147288322449 all mean 0.5555958151817322
0.11432266980409622 0.11432268470525742
rl training, epoch4, iter0, batch398/1133, batch loss:0.11432268470525742, Training time:69628.39646697044
batch reward last col mean 0.5506213903427124 first col mean 0.5544010996818542 all mean 0.5530139803886414
0.15465599298477173 0.15465597808361053
rl training, epoch4, iter0, batch399/1133, batch loss:0.15465597808361053, Training time:69628.91739940643
batch reward last col mean 0.5198228359222412 first col mean 0.5535036325454712 all mean 0.5309343338012695
0.11236932128667831 0.11236932128667831
rl training, epoch4, iter0, batch400/1133, batch loss:0.11236932128667831, Training time:69629.43754076958
batch reward last col mean 0.5150734782218933 first col mean 0.5278476476669312 all mean 0.5182217955589294
0.10955747216939926 0.10955746471881866
rl training, epoch4, iter0, batch401/1133, batch loss:0.10955746471881866, Training time:69629.91696500778
batch reward last col mean 0.5426572561264038 first col mean 0.5755034685134888 all mean 0.5480495691299438
0.1308605819940567 0.1308605819940567
rl training, epoch4, iter0, batch402/1133, batch loss:0.1308605819940567, Training time:69630.32332515717
batch reward last col mean 0.5057006478309631 first col mean 0.5347134470939636 all mean 0.5128700137138367
0.12418913841247559 0.12418913841247559
rl training, epoch4, iter0, batch403/1133, batch loss:0.12418913841247559, Training time:69630.75809431076
batch reward last col mean 0.5453839898109436 first col mean 0.5633441209793091 all mean 0.5476119518280029
0.1471669226884842 0.147166907787323
rl training, epoch4, iter0, batch404/1133, batch loss:0.147166907787323, Training time:69631.41431593895
batch reward last col mean 0.571452260017395 first col mean 0.5674077868461609 all mean 0.5701993107795715
0.1654861718416214 0.1654861718416214
rl training, epoch4, iter0, batch405/1133, batch loss:0.1654861718416214, Training time:69632.36294770241
batch reward last col mean 0.5520808696746826 first col mean 0.560162365436554 all mean 0.5527603030204773
0.11102844774723053 0.11102846264839172
rl training, epoch4, iter0, batch406/1133, batch loss:0.11102846264839172, Training time:69632.8762831688
batch reward last col mean 0.5229744911193848 first col mean 0.5473714470863342 all mean 0.5296672582626343
0.1284041851758957 0.12840420007705688
rl training, epoch4, iter0, batch407/1133, batch loss:0.12840420007705688, Training time:69633.35144209862
batch reward last col mean 0.569221019744873 first col mean 0.5803014039993286 all mean 0.5707324147224426
0.11755063384771347 0.11755062639713287
rl training, epoch4, iter0, batch408/1133, batch loss:0.11755062639713287, Training time:69633.95459604263
batch reward last col mean 0.5172407031059265 first col mean 0.5165435671806335 all mean 0.5196418166160583
0.11501205712556839 0.11501205712556839
rl training, epoch4, iter0, batch409/1133, batch loss:0.11501205712556839, Training time:69634.69933629036
batch reward last col mean 0.5123611688613892 first col mean 0.5072487592697144 all mean 0.5112811326980591
0.1328151375055313 0.1328151375055313
rl training, epoch4, iter0, batch410/1133, batch loss:0.1328151375055313, Training time:69635.55758476257
batch reward last col mean 0.5210195183753967 first col mean 0.5227919220924377 all mean 0.5237212777137756
0.11999210715293884 0.11999210715293884
rl training, epoch4, iter0, batch411/1133, batch loss:0.11999210715293884, Training time:69636.00962495804
batch reward last col mean 0.5318590998649597 first col mean 0.5348690748214722 all mean 0.5349738001823425
0.11422842741012573 0.11422841995954514
rl training, epoch4, iter0, batch412/1133, batch loss:0.11422841995954514, Training time:69636.48015856743
batch reward last col mean 0.5176272392272949 first col mean 0.5483238697052002 all mean 0.5213973522186279
0.10380841046571732 0.10380840301513672
rl training, epoch4, iter0, batch413/1133, batch loss:0.10380840301513672, Training time:69637.00391221046
batch reward last col mean 0.5497126579284668 first col mean 0.5568015575408936 all mean 0.5512821078300476
0.15960271656513214 0.15960270166397095
rl training, epoch4, iter0, batch414/1133, batch loss:0.15960270166397095, Training time:69637.75583267212
batch reward last col mean 0.5130933523178101 first col mean 0.5145765542984009 all mean 0.5145388841629028
0.1243518739938736 0.1243518739938736
rl training, epoch4, iter0, batch415/1133, batch loss:0.1243518739938736, Training time:69638.40779733658
batch reward last col mean 0.5296655893325806 first col mean 0.5419151782989502 all mean 0.5349235534667969
0.15049242973327637 0.15049242973327637
rl training, epoch4, iter0, batch416/1133, batch loss:0.15049242973327637, Training time:69639.42491722107
batch reward last col mean 0.5235347151756287 first col mean 0.5338602662086487 all mean 0.5238298177719116
0.13093596696853638 0.13093596696853638
rl training, epoch4, iter0, batch417/1133, batch loss:0.13093596696853638, Training time:69640.21383452415
batch reward last col mean 0.522502601146698 first col mean 0.5160684585571289 all mean 0.5207635164260864
0.11913777887821198 0.11913777887821198
rl training, epoch4, iter0, batch418/1133, batch loss:0.11913777887821198, Training time:69640.908015728
batch reward last col mean 0.5167982578277588 first col mean 0.5409635901451111 all mean 0.5163314342498779
0.1303795427083969 0.13037952780723572
rl training, epoch4, iter0, batch419/1133, batch loss:0.13037952780723572, Training time:69642.90288352966
batch reward last col mean 0.5315839052200317 first col mean 0.5332970023155212 all mean 0.5295522809028625
0.148575559258461 0.1485755443572998
rl training, epoch4, iter0, batch420/1133, batch loss:0.1485755443572998, Training time:69644.21214580536
batch reward last col mean 0.5051994323730469 first col mean 0.5109765529632568 all mean 0.5049876570701599
0.14072167873382568 0.1407216489315033
rl training, epoch4, iter0, batch421/1133, batch loss:0.1407216489315033, Training time:69645.46126747131
batch reward last col mean 0.5339346528053284 first col mean 0.5429584980010986 all mean 0.5336244702339172
0.15258954465389252 0.15258954465389252
rl training, epoch4, iter0, batch422/1133, batch loss:0.15258954465389252, Training time:69646.58326983452
batch reward last col mean 0.5385257601737976 first col mean 0.5593509078025818 all mean 0.5433640480041504
0.19071759283542633 0.19071759283542633
rl training, epoch4, iter0, batch423/1133, batch loss:0.19071759283542633, Training time:69647.97422337532
batch reward last col mean 0.562269926071167 first col mean 0.5679782629013062 all mean 0.564167320728302
0.1895584911108017 0.1895584911108017
rl training, epoch4, iter0, batch424/1133, batch loss:0.1895584911108017, Training time:69652.77591180801
batch reward last col mean 0.5275779366493225 first col mean 0.5330262184143066 all mean 0.5316809415817261
0.16171225905418396 0.16171224415302277
rl training, epoch4, iter0, batch425/1133, batch loss:0.16171224415302277, Training time:69656.34114575386
batch reward last col mean 0.5337933301925659 first col mean 0.5627912878990173 all mean 0.535496711730957
0.16021177172660828 0.16021177172660828
rl training, epoch4, iter0, batch426/1133, batch loss:0.16021177172660828, Training time:69660.1705083847
batch reward last col mean 0.4816630482673645 first col mean 0.4621294140815735 all mean 0.47734564542770386
0.1699690818786621 0.16996906697750092
rl training, epoch4, iter0, batch427/1133, batch loss:0.16996906697750092, Training time:69663.89897561073
batch reward last col mean 0.5346462726593018 first col mean 0.5258408188819885 all mean 0.5335322022438049
0.1674230545759201 0.1674230545759201
rl training, epoch4, iter0, batch428/1133, batch loss:0.1674230545759201, Training time:69667.28367233276
batch reward last col mean 0.5154179930686951 first col mean 0.5130912065505981 all mean 0.5171656608581543
0.16824303567409515 0.16824302077293396
rl training, epoch4, iter0, batch429/1133, batch loss:0.16824302077293396, Training time:69670.75142908096
batch reward last col mean 0.5723795294761658 first col mean 0.56316077709198 all mean 0.5711023211479187
0.19784320890903473 0.19784320890903473
rl training, epoch4, iter0, batch430/1133, batch loss:0.19784320890903473, Training time:69673.65478229523
batch reward last col mean 0.5641950368881226 first col mean 0.5592228174209595 all mean 0.5646055936813354
0.20939543843269348 0.20939543843269348
rl training, epoch4, iter0, batch431/1133, batch loss:0.20939543843269348, Training time:69675.97429156303
batch reward last col mean 0.5429979562759399 first col mean 0.5456880927085876 all mean 0.5439732074737549
0.19614943861961365 0.19614942371845245
rl training, epoch4, iter0, batch432/1133, batch loss:0.19614942371845245, Training time:69678.05527877808
batch reward last col mean 0.5765680074691772 first col mean 0.5588515996932983 all mean 0.5678796172142029
0.20529332756996155 0.20529332756996155
rl training, epoch4, iter0, batch433/1133, batch loss:0.20529332756996155, Training time:69679.79656672478
batch reward last col mean 0.5311620235443115 first col mean 0.5335112810134888 all mean 0.5301993489265442
0.2043278068304062 0.2043278068304062
rl training, epoch4, iter0, batch434/1133, batch loss:0.2043278068304062, Training time:69683.12626552582
batch reward last col mean 0.5754325985908508 first col mean 0.5456259846687317 all mean 0.5684472322463989
0.2010975331068039 0.2010975480079651
rl training, epoch4, iter0, batch435/1133, batch loss:0.2010975480079651, Training time:69685.4297554493
batch reward last col mean 0.48941487073898315 first col mean 0.5087897777557373 all mean 0.49685999751091003
0.1816050112247467 0.1816050112247467
rl training, epoch4, iter0, batch436/1133, batch loss:0.1816050112247467, Training time:69686.45759701729
batch reward last col mean 0.5293121337890625 first col mean 0.5304318070411682 all mean 0.5298964381217957
0.1636832058429718 0.1636832058429718
rl training, epoch4, iter0, batch437/1133, batch loss:0.1636832058429718, Training time:69688.12434267998
batch reward last col mean 0.4900225102901459 first col mean 0.4704131484031677 all mean 0.4820552170276642
0.2044077217578888 0.2044077217578888
rl training, epoch4, iter0, batch438/1133, batch loss:0.2044077217578888, Training time:69690.27056765556
batch reward last col mean 0.5255265235900879 first col mean 0.546334981918335 all mean 0.5303274393081665
0.18501952290534973 0.18501952290534973
rl training, epoch4, iter0, batch439/1133, batch loss:0.18501952290534973, Training time:69692.18097090721
batch reward last col mean 0.6056123971939087 first col mean 0.6128648519515991 all mean 0.6071010231971741
0.18579545617103577 0.18579545617103577
rl training, epoch4, iter0, batch440/1133, batch loss:0.18579545617103577, Training time:69694.85523962975
batch reward last col mean 0.5595152378082275 first col mean 0.551605761051178 all mean 0.5585324764251709
0.16979438066482544 0.16979438066482544
rl training, epoch4, iter0, batch441/1133, batch loss:0.16979438066482544, Training time:69696.07637953758
batch reward last col mean 0.561919629573822 first col mean 0.5735071897506714 all mean 0.5637427568435669
0.20916175842285156 0.20916175842285156
rl training, epoch4, iter0, batch442/1133, batch loss:0.20916175842285156, Training time:69697.31444501877
batch reward last col mean 0.55633544921875 first col mean 0.5723276734352112 all mean 0.5620097517967224
0.19346904754638672 0.1934690624475479
rl training, epoch4, iter0, batch443/1133, batch loss:0.1934690624475479, Training time:69698.9276483059
batch reward last col mean 0.5302385091781616 first col mean 0.5336373448371887 all mean 0.5298910737037659
0.18293766677379608 0.1829376518726349
rl training, epoch4, iter0, batch444/1133, batch loss:0.1829376518726349, Training time:69700.00967144966
batch reward last col mean 0.5850017666816711 first col mean 0.5915307998657227 all mean 0.5842795372009277
0.2307009994983673 0.2307010143995285
rl training, epoch4, iter0, batch445/1133, batch loss:0.2307010143995285, Training time:69701.07130861282
batch reward last col mean 0.5399515628814697 first col mean 0.5396143198013306 all mean 0.5430446267127991
0.17355592548847198 0.17355592548847198
rl training, epoch4, iter0, batch446/1133, batch loss:0.17355592548847198, Training time:69701.95152521133
batch reward last col mean 0.5769814848899841 first col mean 0.5939478874206543 all mean 0.5789629817008972
0.18036720156669617 0.18036720156669617
rl training, epoch4, iter0, batch447/1133, batch loss:0.18036720156669617, Training time:69703.62588238716
batch reward last col mean 0.5539875030517578 first col mean 0.5463036298751831 all mean 0.5511842370033264
0.15852580964565277 0.15852580964565277
rl training, epoch4, iter0, batch448/1133, batch loss:0.15852580964565277, Training time:69705.02431368828
batch reward last col mean 0.577228307723999 first col mean 0.6045769453048706 all mean 0.584382176399231
0.23241841793060303 0.23241843283176422
rl training, epoch4, iter0, batch449/1133, batch loss:0.23241843283176422, Training time:69706.41185736656
batch reward last col mean 0.553554356098175 first col mean 0.5770875215530396 all mean 0.5550869107246399
0.18205711245536804 0.18205711245536804
rl training, epoch4, iter0, batch450/1133, batch loss:0.18205711245536804, Training time:69707.46665334702
batch reward last col mean 0.5377466678619385 first col mean 0.5462230443954468 all mean 0.5364425182342529
0.16746512055397034 0.16746510565280914
rl training, epoch4, iter0, batch451/1133, batch loss:0.16746510565280914, Training time:69709.0297806263
batch reward last col mean 0.5440714955329895 first col mean 0.5461639761924744 all mean 0.5429801940917969
0.16811244189739227 0.16811242699623108
rl training, epoch4, iter0, batch452/1133, batch loss:0.16811242699623108, Training time:69710.35849070549
batch reward last col mean 0.5510413646697998 first col mean 0.5331690907478333 all mean 0.5512333512306213
0.18792706727981567 0.18792706727981567
rl training, epoch4, iter0, batch453/1133, batch loss:0.18792706727981567, Training time:69713.46333575249
batch reward last col mean 0.5852640867233276 first col mean 0.571033775806427 all mean 0.5802555680274963
0.1987353265285492 0.1987352967262268
rl training, epoch4, iter0, batch454/1133, batch loss:0.1987352967262268, Training time:69715.03177762032
batch reward last col mean 0.5396340489387512 first col mean 0.5464149713516235 all mean 0.5402177572250366
0.1721310168504715 0.1721310168504715
rl training, epoch4, iter0, batch455/1133, batch loss:0.1721310168504715, Training time:69716.09143996239
batch reward last col mean 0.5813542008399963 first col mean 0.5786065459251404 all mean 0.5790662169456482
0.1810026317834854 0.1810026317834854
rl training, epoch4, iter0, batch456/1133, batch loss:0.1810026317834854, Training time:69716.918643713
batch reward last col mean 0.5532442331314087 first col mean 0.5511917471885681 all mean 0.5523130893707275
0.20843131840229034 0.20843131840229034
rl training, epoch4, iter0, batch457/1133, batch loss:0.20843131840229034, Training time:69718.43949174881
batch reward last col mean 0.5466655492782593 first col mean 0.5470610857009888 all mean 0.548132061958313
0.16836433112621307 0.16836431622505188
rl training, epoch4, iter0, batch458/1133, batch loss:0.16836431622505188, Training time:69721.33464622498
batch reward last col mean 0.5880651473999023 first col mean 0.5880270004272461 all mean 0.589755654335022
0.1869126260280609 0.1869126260280609
rl training, epoch4, iter0, batch459/1133, batch loss:0.1869126260280609, Training time:69723.25769662857
batch reward last col mean 0.6295939683914185 first col mean 0.63553786277771 all mean 0.629047155380249
0.21915210783481598 0.21915210783481598
rl training, epoch4, iter0, batch460/1133, batch loss:0.21915210783481598, Training time:69724.20205640793
batch reward last col mean 0.559390664100647 first col mean 0.5710046887397766 all mean 0.5620622634887695
0.23100920021533966 0.23100920021533966
rl training, epoch4, iter0, batch461/1133, batch loss:0.23100920021533966, Training time:69725.41893005371
batch reward last col mean 0.5384975075721741 first col mean 0.5487662553787231 all mean 0.5394679307937622
0.21258637309074402 0.21258635818958282
rl training, epoch4, iter0, batch462/1133, batch loss:0.21258635818958282, Training time:69726.48224973679
batch reward last col mean 0.5654706954956055 first col mean 0.5425424575805664 all mean 0.5618066787719727
0.2086832970380783 0.2086832970380783
rl training, epoch4, iter0, batch463/1133, batch loss:0.2086832970380783, Training time:69727.4306461811
batch reward last col mean 0.581333339214325 first col mean 0.6006030440330505 all mean 0.5869786739349365
0.19828642904758453 0.19828642904758453
rl training, epoch4, iter0, batch464/1133, batch loss:0.19828642904758453, Training time:69728.49204969406
batch reward last col mean 0.600402295589447 first col mean 0.5906762480735779 all mean 0.5979299545288086
0.1533980667591095 0.1533980518579483
rl training, epoch4, iter0, batch465/1133, batch loss:0.1533980518579483, Training time:69729.1566169262
batch reward last col mean 0.5571656823158264 first col mean 0.578223466873169 all mean 0.5618088245391846
0.1631736159324646 0.1631736159324646
rl training, epoch4, iter0, batch466/1133, batch loss:0.1631736159324646, Training time:69730.03047132492
batch reward last col mean 0.5403636693954468 first col mean 0.5504364371299744 all mean 0.5429272651672363
0.18971484899520874 0.18971483409404755
rl training, epoch4, iter0, batch467/1133, batch loss:0.18971483409404755, Training time:69731.21654438972
batch reward last col mean 0.5449754595756531 first col mean 0.5603435039520264 all mean 0.545071005821228
0.1340208500623703 0.1340208500623703
rl training, epoch4, iter0, batch468/1133, batch loss:0.1340208500623703, Training time:69732.20764422417
batch reward last col mean 0.5045020580291748 first col mean 0.5286747217178345 all mean 0.5099135637283325
0.14351221919059753 0.14351221919059753
rl training, epoch4, iter0, batch469/1133, batch loss:0.14351221919059753, Training time:69732.90949368477
batch reward last col mean 0.5786265134811401 first col mean 0.6110832691192627 all mean 0.5840417742729187
0.15003903210163116 0.15003903210163116
rl training, epoch4, iter0, batch470/1133, batch loss:0.15003903210163116, Training time:69733.58178329468
batch reward last col mean 0.49032866954803467 first col mean 0.525797963142395 all mean 0.49794039130210876
0.15627770125865936 0.15627770125865936
rl training, epoch4, iter0, batch471/1133, batch loss:0.15627770125865936, Training time:69734.2913851738
batch reward last col mean 0.5503412485122681 first col mean 0.5417624711990356 all mean 0.5481619834899902
0.13847500085830688 0.13847500085830688
rl training, epoch4, iter0, batch472/1133, batch loss:0.13847500085830688, Training time:69734.88702511787
batch reward last col mean 0.5059189200401306 first col mean 0.5439693331718445 all mean 0.513630211353302
0.1470201462507248 0.1470201462507248
rl training, epoch4, iter0, batch473/1133, batch loss:0.1470201462507248, Training time:69735.4934618473
batch reward last col mean 0.5662208795547485 first col mean 0.5908203721046448 all mean 0.5730984807014465
0.14345593750476837 0.14345593750476837
rl training, epoch4, iter0, batch474/1133, batch loss:0.14345593750476837, Training time:69736.16756105423
batch reward last col mean 0.5434132814407349 first col mean 0.5435512065887451 all mean 0.5447425246238708
0.13960133492946625 0.13960133492946625
rl training, epoch4, iter0, batch475/1133, batch loss:0.13960133492946625, Training time:69736.90474534035
batch reward last col mean 0.6002105474472046 first col mean 0.6098838448524475 all mean 0.600735068321228
0.15779952704906464 0.15779951214790344
rl training, epoch4, iter0, batch476/1133, batch loss:0.15779951214790344, Training time:69737.5527150631
batch reward last col mean 0.5844238996505737 first col mean 0.571479856967926 all mean 0.5832499265670776
0.14660775661468506 0.14660775661468506
rl training, epoch4, iter0, batch477/1133, batch loss:0.14660775661468506, Training time:69738.07529520988
batch reward last col mean 0.5838554501533508 first col mean 0.595000147819519 all mean 0.5851061344146729
0.11963744461536407 0.11963745206594467
rl training, epoch4, iter0, batch478/1133, batch loss:0.11963745206594467, Training time:69738.59107732773
batch reward last col mean 0.537301778793335 first col mean 0.5212177038192749 all mean 0.5345340371131897
0.11649907380342484 0.11649908125400543
rl training, epoch4, iter0, batch479/1133, batch loss:0.11649908125400543, Training time:69739.2819468975
batch reward last col mean 0.5295374989509583 first col mean 0.5465999245643616 all mean 0.5292747020721436
0.12799663841724396 0.12799660861492157
rl training, epoch4, iter0, batch480/1133, batch loss:0.12799660861492157, Training time:69739.81549048424
batch reward last col mean 0.5220632553100586 first col mean 0.5313845872879028 all mean 0.5254812836647034
0.11347709596157074 0.11347709596157074
rl training, epoch4, iter0, batch481/1133, batch loss:0.11347709596157074, Training time:69740.40232086182
batch reward last col mean 0.5586517453193665 first col mean 0.5812795162200928 all mean 0.5618581771850586
0.14049339294433594 0.14049336314201355
rl training, epoch4, iter0, batch482/1133, batch loss:0.14049336314201355, Training time:69740.90619659424
batch reward last col mean 0.5613278150558472 first col mean 0.5777093172073364 all mean 0.5615849494934082
0.14159758388996124 0.14159758388996124
rl training, epoch4, iter0, batch483/1133, batch loss:0.14159758388996124, Training time:69741.41879916191
batch reward last col mean 0.5780336856842041 first col mean 0.5633641481399536 all mean 0.5747159123420715
0.122876837849617 0.122876837849617
rl training, epoch4, iter0, batch484/1133, batch loss:0.122876837849617, Training time:69741.99716901779
batch reward last col mean 0.5316826701164246 first col mean 0.5391402840614319 all mean 0.5296314358711243
0.110324926674366 0.110324926674366
rl training, epoch4, iter0, batch485/1133, batch loss:0.110324926674366, Training time:69742.50093579292
batch reward last col mean 0.6422508955001831 first col mean 0.6478865742683411 all mean 0.646147608757019
0.17497581243515015 0.17497581243515015
rl training, epoch4, iter0, batch486/1133, batch loss:0.17497581243515015, Training time:69743.00560736656
batch reward last col mean 0.6064415574073792 first col mean 0.600891649723053 all mean 0.6090380549430847
0.13575755059719086 0.13575755059719086
rl training, epoch4, iter0, batch487/1133, batch loss:0.13575755059719086, Training time:69743.43652796745
batch reward last col mean 0.5545444488525391 first col mean 0.5829532742500305 all mean 0.5575301051139832
0.10840827971696854 0.10840827971696854
rl training, epoch4, iter0, batch488/1133, batch loss:0.10840827971696854, Training time:69743.910094738
batch reward last col mean 0.5722948908805847 first col mean 0.5773742198944092 all mean 0.5740799903869629
0.10469184815883636 0.10469184815883636
rl training, epoch4, iter0, batch489/1133, batch loss:0.10469184815883636, Training time:69744.37332296371
batch reward last col mean 0.47119569778442383 first col mean 0.47849419713020325 all mean 0.4708343744277954
0.09472648054361343 0.09472648799419403
rl training, epoch4, iter0, batch490/1133, batch loss:0.09472648799419403, Training time:69744.98879885674
batch reward last col mean 0.5940524339675903 first col mean 0.569506049156189 all mean 0.586988627910614
0.1559760421514511 0.15597601234912872
rl training, epoch4, iter0, batch491/1133, batch loss:0.15597601234912872, Training time:69745.44968390465
batch reward last col mean 0.5970101952552795 first col mean 0.6186807155609131 all mean 0.5996647477149963
0.12568360567092896 0.12568360567092896
rl training, epoch4, iter0, batch492/1133, batch loss:0.12568360567092896, Training time:69745.99358582497
batch reward last col mean 0.5559343099594116 first col mean 0.5758156180381775 all mean 0.5619741678237915
0.1309499591588974 0.1309499442577362
rl training, epoch4, iter0, batch493/1133, batch loss:0.1309499442577362, Training time:69746.4698548317
batch reward last col mean 0.5934156179428101 first col mean 0.5859743356704712 all mean 0.5921604633331299
0.14257465302944183 0.14257465302944183
rl training, epoch4, iter0, batch494/1133, batch loss:0.14257465302944183, Training time:69746.98188376427
batch reward last col mean 0.5905799269676208 first col mean 0.5798182487487793 all mean 0.586792528629303
0.12508617341518402 0.12508617341518402
rl training, epoch4, iter0, batch495/1133, batch loss:0.12508617341518402, Training time:69747.43263292313
batch reward last col mean 0.5935277938842773 first col mean 0.6013079881668091 all mean 0.5920811295509338
0.1345958262681961 0.1345958411693573
rl training, epoch4, iter0, batch496/1133, batch loss:0.1345958411693573, Training time:69747.95399904251
batch reward last col mean 0.5515426397323608 first col mean 0.5415782928466797 all mean 0.5489138960838318
0.11581588536500931 0.11581588536500931
rl training, epoch4, iter0, batch497/1133, batch loss:0.11581588536500931, Training time:69748.49876904488
batch reward last col mean 0.5461276173591614 first col mean 0.5623526573181152 all mean 0.5456246137619019
0.13330918550491333 0.13330921530723572
rl training, epoch4, iter0, batch498/1133, batch loss:0.13330921530723572, Training time:69749.06342124939
batch reward last col mean 0.6080353260040283 first col mean 0.6194010972976685 all mean 0.6099461913108826
0.1556975245475769 0.1556975245475769
rl training, epoch4, iter0, batch499/1133, batch loss:0.1556975245475769, Training time:69749.80191612244
batch reward last col mean 0.5151920914649963 first col mean 0.534485399723053 all mean 0.5213470458984375
0.14836545288562775 0.14836545288562775
rl training, epoch4, iter0, batch500/1133, batch loss:0.14836545288562775, Training time:69750.34654092789
batch reward last col mean 0.5746215581893921 first col mean 0.5980185270309448 all mean 0.5788402557373047
0.11673418432474136 0.11673418432474136
rl training, epoch4, iter0, batch501/1133, batch loss:0.11673418432474136, Training time:69750.8531703949
batch reward last col mean 0.5590737462043762 first col mean 0.5834097862243652 all mean 0.5607262253761292
0.1457650512456894 0.1457650512456894
rl training, epoch4, iter0, batch502/1133, batch loss:0.1457650512456894, Training time:69751.61286401749
batch reward last col mean 0.572344958782196 first col mean 0.5884238481521606 all mean 0.5759532451629639
0.16801604628562927 0.16801604628562927
rl training, epoch4, iter0, batch503/1133, batch loss:0.16801604628562927, Training time:69752.57389211655
batch reward last col mean 0.5343854427337646 first col mean 0.5333521366119385 all mean 0.5376920700073242
0.10529246181249619 0.10529246181249619
rl training, epoch4, iter0, batch504/1133, batch loss:0.10529246181249619, Training time:69753.31657242775
batch reward last col mean 0.505240797996521 first col mean 0.5435762405395508 all mean 0.5119925737380981
0.13491211831569672 0.13491211831569672
rl training, epoch4, iter0, batch505/1133, batch loss:0.13491211831569672, Training time:69753.95907473564
batch reward last col mean 0.5510700941085815 first col mean 0.5796877145767212 all mean 0.5547855496406555
0.13733914494514465 0.13733915984630585
rl training, epoch4, iter0, batch506/1133, batch loss:0.13733915984630585, Training time:69754.67234492302
batch reward last col mean 0.5567060708999634 first col mean 0.5565996170043945 all mean 0.5561010241508484
0.13686901330947876 0.13686901330947876
rl training, epoch4, iter0, batch507/1133, batch loss:0.13686901330947876, Training time:69755.58823227882
batch reward last col mean 0.5288763046264648 first col mean 0.5441985130310059 all mean 0.5327767729759216
0.14734818041324615 0.14734816551208496
rl training, epoch4, iter0, batch508/1133, batch loss:0.14734816551208496, Training time:69756.47366642952
batch reward last col mean 0.5578135251998901 first col mean 0.548549234867096 all mean 0.5560582280158997
0.15247243642807007 0.15247242152690887
rl training, epoch4, iter0, batch509/1133, batch loss:0.15247242152690887, Training time:69757.14198064804
batch reward last col mean 0.4689231514930725 first col mean 0.4963049590587616 all mean 0.47463560104370117
0.13883833587169647 0.13883835077285767
rl training, epoch4, iter0, batch510/1133, batch loss:0.13883835077285767, Training time:69757.97560930252
batch reward last col mean 0.5779244899749756 first col mean 0.5661253929138184 all mean 0.575950026512146
0.16264358162879944 0.16264356672763824
rl training, epoch4, iter0, batch511/1133, batch loss:0.16264356672763824, Training time:69758.77784514427
batch reward last col mean 0.5615193843841553 first col mean 0.5651512145996094 all mean 0.5644769072532654
0.20048047602176666 0.20048049092292786
rl training, epoch4, iter0, batch512/1133, batch loss:0.20048049092292786, Training time:69759.57406449318
batch reward last col mean 0.5777996778488159 first col mean 0.564627468585968 all mean 0.5748425722122192
0.17495512962341309 0.17495512962341309
rl training, epoch4, iter0, batch513/1133, batch loss:0.17495512962341309, Training time:69760.48407459259
batch reward last col mean 0.5852705240249634 first col mean 0.5895117521286011 all mean 0.5856139659881592
0.19850614666938782 0.19850614666938782
rl training, epoch4, iter0, batch514/1133, batch loss:0.19850614666938782, Training time:69761.78798532486
batch reward last col mean 0.5716641545295715 first col mean 0.5913490056991577 all mean 0.5736299753189087
0.16056858003139496 0.16056855022907257
rl training, epoch4, iter0, batch515/1133, batch loss:0.16056855022907257, Training time:69762.6741847992
batch reward last col mean 0.5604039430618286 first col mean 0.5771348476409912 all mean 0.5661672353744507
0.160371333360672 0.1603713184595108
rl training, epoch4, iter0, batch516/1133, batch loss:0.1603713184595108, Training time:69763.44524216652
batch reward last col mean 0.5679153800010681 first col mean 0.5704600214958191 all mean 0.5664452314376831
0.13441920280456543 0.13441917300224304
rl training, epoch4, iter0, batch517/1133, batch loss:0.13441917300224304, Training time:69764.56169438362
batch reward last col mean 0.5395284295082092 first col mean 0.5440337061882019 all mean 0.5366259217262268
0.16155311465263367 0.16155309975147247
rl training, epoch4, iter0, batch518/1133, batch loss:0.16155309975147247, Training time:69765.79042935371
batch reward last col mean 0.5958462953567505 first col mean 0.6058093905448914 all mean 0.6006252765655518
0.15440812706947327 0.15440812706947327
rl training, epoch4, iter0, batch519/1133, batch loss:0.15440812706947327, Training time:69767.35408115387
batch reward last col mean 0.5329550504684448 first col mean 0.5399335622787476 all mean 0.5367655754089355
0.12244933098554611 0.12244933843612671
rl training, epoch4, iter0, batch520/1133, batch loss:0.12244933843612671, Training time:69768.64942598343
batch reward last col mean 0.5425445437431335 first col mean 0.5487620830535889 all mean 0.5416712760925293
0.19384101033210754 0.19384104013442993
rl training, epoch4, iter0, batch521/1133, batch loss:0.19384104013442993, Training time:69769.94560956955
batch reward last col mean 0.5746773481369019 first col mean 0.5829121470451355 all mean 0.5721060037612915
0.15615446865558624 0.15615446865558624
rl training, epoch4, iter0, batch522/1133, batch loss:0.15615446865558624, Training time:69770.8410191536
batch reward last col mean 0.5528828501701355 first col mean 0.5587040185928345 all mean 0.5522283315658569
0.14865902066230774 0.14865902066230774
rl training, epoch4, iter0, batch523/1133, batch loss:0.14865902066230774, Training time:69772.04430651665
batch reward last col mean 0.5880018472671509 first col mean 0.5754826068878174 all mean 0.5875915288925171
0.16216081380844116 0.16216079890727997
rl training, epoch4, iter0, batch524/1133, batch loss:0.16216079890727997, Training time:69773.04758381844
batch reward last col mean 0.5509970188140869 first col mean 0.57060307264328 all mean 0.5529921650886536
0.16318589448928833 0.16318587958812714
rl training, epoch4, iter0, batch525/1133, batch loss:0.16318587958812714, Training time:69774.00091743469
batch reward last col mean 0.5587375164031982 first col mean 0.5622124075889587 all mean 0.5622107982635498
0.18067820370197296 0.18067820370197296
rl training, epoch4, iter0, batch526/1133, batch loss:0.18067820370197296, Training time:69775.36705732346
batch reward last col mean 0.5576881170272827 first col mean 0.5742499828338623 all mean 0.559393584728241
0.15800224244594574 0.15800224244594574
rl training, epoch4, iter0, batch527/1133, batch loss:0.15800224244594574, Training time:69776.8052611351
batch reward last col mean 0.5744585990905762 first col mean 0.5911036729812622 all mean 0.5769249200820923
0.16380546987056732 0.16380546987056732
rl training, epoch4, iter0, batch528/1133, batch loss:0.16380546987056732, Training time:69779.06158018112
batch reward last col mean 0.5704547762870789 first col mean 0.5803501009941101 all mean 0.5714430212974548
0.14091742038726807 0.14091742038726807
rl training, epoch4, iter0, batch529/1133, batch loss:0.14091742038726807, Training time:69780.33951449394
batch reward last col mean 0.5255210995674133 first col mean 0.5426163673400879 all mean 0.5282667279243469
0.15604622662067413 0.15604619681835175
rl training, epoch4, iter0, batch530/1133, batch loss:0.15604619681835175, Training time:69781.46893405914
batch reward last col mean 0.5631279945373535 first col mean 0.5755410194396973 all mean 0.561860203742981
0.19660067558288574 0.19660067558288574
rl training, epoch4, iter0, batch531/1133, batch loss:0.19660067558288574, Training time:69783.02723264694
batch reward last col mean 0.5598008632659912 first col mean 0.5511711835861206 all mean 0.5554377436637878
0.14180509746074677 0.14180511236190796
rl training, epoch4, iter0, batch532/1133, batch loss:0.14180511236190796, Training time:69784.3100092411
batch reward last col mean 0.5386277437210083 first col mean 0.5333654880523682 all mean 0.5389705896377563
0.1255740076303482 0.1255740225315094
rl training, epoch4, iter0, batch533/1133, batch loss:0.1255740225315094, Training time:69786.19620609283
batch reward last col mean 0.5152508616447449 first col mean 0.530610978603363 all mean 0.5205471515655518
0.17796507477760315 0.17796507477760315
rl training, epoch4, iter0, batch534/1133, batch loss:0.17796507477760315, Training time:69787.2513949871
batch reward last col mean 0.578004002571106 first col mean 0.5878251791000366 all mean 0.5797973275184631
0.1418852061033249 0.1418852061033249
rl training, epoch4, iter0, batch535/1133, batch loss:0.1418852061033249, Training time:69788.30387663841
batch reward last col mean 0.5776848196983337 first col mean 0.5731449127197266 all mean 0.5775355100631714
0.1168627068400383 0.1168627068400383
rl training, epoch4, iter0, batch536/1133, batch loss:0.1168627068400383, Training time:69789.45346045494
batch reward last col mean 0.5883631110191345 first col mean 0.6125151515007019 all mean 0.5927094221115112
0.15019862353801727 0.15019862353801727
rl training, epoch4, iter0, batch537/1133, batch loss:0.15019862353801727, Training time:69790.64444899559
batch reward last col mean 0.5718955397605896 first col mean 0.5770969390869141 all mean 0.5761456489562988
0.18544988334178925 0.18544986844062805
rl training, epoch4, iter0, batch538/1133, batch loss:0.18544986844062805, Training time:69792.08465337753
batch reward last col mean 0.5560588240623474 first col mean 0.528156578540802 all mean 0.5506806969642639
0.1444139927625656 0.1444140076637268
rl training, epoch4, iter0, batch539/1133, batch loss:0.1444140076637268, Training time:69793.24003434181
batch reward last col mean 0.544492244720459 first col mean 0.5590915083885193 all mean 0.5471905469894409
0.16679657995700836 0.16679657995700836
rl training, epoch4, iter0, batch540/1133, batch loss:0.16679657995700836, Training time:69794.48192930222
batch reward last col mean 0.58957839012146 first col mean 0.5826559662818909 all mean 0.5873231291770935
0.1366046816110611 0.1366046816110611
rl training, epoch4, iter0, batch541/1133, batch loss:0.1366046816110611, Training time:69796.30406951904
batch reward last col mean 0.6044926047325134 first col mean 0.6182160377502441 all mean 0.6062859296798706
0.13947930932044983 0.13947929441928864
rl training, epoch4, iter0, batch542/1133, batch loss:0.13947929441928864, Training time:69797.47719311714
batch reward last col mean 0.5004764795303345 first col mean 0.502255380153656 all mean 0.499435156583786
0.09759059548377991 0.0975906029343605
rl training, epoch4, iter0, batch543/1133, batch loss:0.0975906029343605, Training time:69798.35428190231
batch reward last col mean 0.5663567185401917 first col mean 0.5668268799781799 all mean 0.5645224452018738
0.19596649706363678 0.19596649706363678
rl training, epoch4, iter0, batch544/1133, batch loss:0.19596649706363678, Training time:69799.42027759552
batch reward last col mean 0.5636874437332153 first col mean 0.5545885562896729 all mean 0.5626214146614075
0.09600207209587097 0.09600207954645157
rl training, epoch4, iter0, batch545/1133, batch loss:0.09600207954645157, Training time:69800.20343828201
batch reward last col mean 0.5582424998283386 first col mean 0.5657039284706116 all mean 0.5602153539657593
0.137266606092453 0.1372665911912918
rl training, epoch4, iter0, batch546/1133, batch loss:0.1372665911912918, Training time:69801.01886367798
batch reward last col mean 0.562564492225647 first col mean 0.5821588039398193 all mean 0.566041886806488
0.12813155353069305 0.12813155353069305
rl training, epoch4, iter0, batch547/1133, batch loss:0.12813155353069305, Training time:69801.7411942482
batch reward last col mean 0.57216876745224 first col mean 0.5747169852256775 all mean 0.5734456181526184
0.11015242338180542 0.11015242338180542
rl training, epoch4, iter0, batch548/1133, batch loss:0.11015242338180542, Training time:69802.37984967232
batch reward last col mean 0.5477908849716187 first col mean 0.5495457649230957 all mean 0.5487960577011108
0.13338284194469452 0.13338284194469452
rl training, epoch4, iter0, batch549/1133, batch loss:0.13338284194469452, Training time:69803.04184865952
batch reward last col mean 0.5643333792686462 first col mean 0.5874587893486023 all mean 0.5660532116889954
0.12408244609832764 0.12408245354890823
rl training, epoch4, iter0, batch550/1133, batch loss:0.12408245354890823, Training time:69803.64074063301
batch reward last col mean 0.5348072648048401 first col mean 0.5525142550468445 all mean 0.5385675430297852
0.09820310026407242 0.09820310026407242
rl training, epoch4, iter0, batch551/1133, batch loss:0.09820310026407242, Training time:69804.33012485504
batch reward last col mean 0.5367656946182251 first col mean 0.5469294190406799 all mean 0.5378074049949646
0.09484639018774033 0.09484639763832092
rl training, epoch4, iter0, batch552/1133, batch loss:0.09484639763832092, Training time:69804.89404058456
batch reward last col mean 0.6036564111709595 first col mean 0.5992588996887207 all mean 0.6021983027458191
0.13332203030586243 0.13332203030586243
rl training, epoch4, iter0, batch553/1133, batch loss:0.13332203030586243, Training time:69805.54402542114
batch reward last col mean 0.5703254342079163 first col mean 0.5632609724998474 all mean 0.5680167078971863
0.09361501783132553 0.09361502528190613
rl training, epoch4, iter0, batch554/1133, batch loss:0.09361502528190613, Training time:69806.05395555496
batch reward last col mean 0.5702189207077026 first col mean 0.5679477453231812 all mean 0.5722178220748901
0.10782181471586227 0.10782181471586227
rl training, epoch4, iter0, batch555/1133, batch loss:0.10782181471586227, Training time:69806.66724944115
batch reward last col mean 0.5187554955482483 first col mean 0.5418609380722046 all mean 0.5227754712104797
0.08671896159648895 0.08671896904706955
rl training, epoch4, iter0, batch556/1133, batch loss:0.08671896904706955, Training time:69807.17022132874
batch reward last col mean 0.5409143567085266 first col mean 0.5553415417671204 all mean 0.5426597595214844
0.0885852575302124 0.0885852724313736
rl training, epoch4, iter0, batch557/1133, batch loss:0.0885852724313736, Training time:69807.6775867939
batch reward last col mean 0.5556493997573853 first col mean 0.5671337842941284 all mean 0.5562429428100586
0.11018367111682892 0.11018367856740952
rl training, epoch4, iter0, batch558/1133, batch loss:0.11018367856740952, Training time:69808.14985179901
batch reward last col mean 0.589016318321228 first col mean 0.5888105630874634 all mean 0.5882688760757446
0.1114075630903244 0.11140754818916321
rl training, epoch4, iter0, batch559/1133, batch loss:0.11140754818916321, Training time:69808.74090480804
batch reward last col mean 0.5934842228889465 first col mean 0.5785307884216309 all mean 0.5916343927383423
0.12732408940792084 0.12732407450675964
rl training, epoch4, iter0, batch560/1133, batch loss:0.12732407450675964, Training time:69809.28957915306
batch reward last col mean 0.5698615312576294 first col mean 0.5489726066589355 all mean 0.5650441646575928
0.10039012879133224 0.10039013624191284
rl training, epoch4, iter0, batch561/1133, batch loss:0.10039013624191284, Training time:69809.87926864624
batch reward last col mean 0.554202675819397 first col mean 0.5472870469093323 all mean 0.5510486364364624
0.10372745990753174 0.10372745245695114
rl training, epoch4, iter0, batch562/1133, batch loss:0.10372745245695114, Training time:69810.36956238747
batch reward last col mean 0.5377214550971985 first col mean 0.5416632294654846 all mean 0.5373631715774536
0.07790789008140564 0.07790789008140564
rl training, epoch4, iter0, batch563/1133, batch loss:0.07790789008140564, Training time:69810.81782197952
batch reward last col mean 0.519602358341217 first col mean 0.5364047288894653 all mean 0.52149897813797
0.07449541985988617 0.07449542731046677
rl training, epoch4, iter0, batch564/1133, batch loss:0.07449542731046677, Training time:69811.42517352104
batch reward last col mean 0.5332571268081665 first col mean 0.5361911058425903 all mean 0.5364755988121033
0.10546287149190903 0.10546287149190903
rl training, epoch4, iter0, batch565/1133, batch loss:0.10546287149190903, Training time:69811.84978437424
batch reward last col mean 0.5418055057525635 first col mean 0.5646985769271851 all mean 0.5460255146026611
0.1095612645149231 0.1095612645149231
rl training, epoch4, iter0, batch566/1133, batch loss:0.1095612645149231, Training time:69812.4305319786
batch reward last col mean 0.5248381495475769 first col mean 0.5340940952301025 all mean 0.5257672071456909
0.07952235639095306 0.07952234894037247
rl training, epoch4, iter0, batch567/1133, batch loss:0.07952234894037247, Training time:69812.9448094368
batch reward last col mean 0.5204584002494812 first col mean 0.5424785017967224 all mean 0.5239211320877075
0.07397525757551193 0.07397525757551193
rl training, epoch4, iter0, batch568/1133, batch loss:0.07397525757551193, Training time:69813.4124519825
batch reward last col mean 0.5975610613822937 first col mean 0.6051672101020813 all mean 0.5974947214126587
0.1363564133644104 0.1363564282655716
rl training, epoch4, iter0, batch569/1133, batch loss:0.1363564282655716, Training time:69813.9303946495
batch reward last col mean 0.5063730478286743 first col mean 0.52894127368927 all mean 0.5103708505630493
0.07551803439855576 0.07551803439855576
rl training, epoch4, iter0, batch570/1133, batch loss:0.07551803439855576, Training time:69814.40914821625
batch reward last col mean 0.5192185640335083 first col mean 0.5200737714767456 all mean 0.5180977582931519
0.09032843261957169 0.09032844752073288
rl training, epoch4, iter0, batch571/1133, batch loss:0.09032844752073288, Training time:69814.98140072823
batch reward last col mean 0.5621010661125183 first col mean 0.5628207921981812 all mean 0.5634693503379822
0.08098410069942474 0.08098410069942474
rl training, epoch4, iter0, batch572/1133, batch loss:0.08098410069942474, Training time:69815.54137849808
batch reward last col mean 0.57313072681427 first col mean 0.5751301050186157 all mean 0.575728178024292
0.10899540781974792 0.10899539291858673
rl training, epoch4, iter0, batch573/1133, batch loss:0.10899539291858673, Training time:69816.0490539074
batch reward last col mean 0.5729607343673706 first col mean 0.58470618724823 all mean 0.5762549638748169
0.12849877774715424 0.12849880754947662
rl training, epoch4, iter0, batch574/1133, batch loss:0.12849880754947662, Training time:69816.53460717201
batch reward last col mean 0.568605899810791 first col mean 0.5536495447158813 all mean 0.5665507316589355
0.09560436755418777 0.09560440480709076
rl training, epoch4, iter0, batch575/1133, batch loss:0.09560440480709076, Training time:69817.09434080124
batch reward last col mean 0.5109102725982666 first col mean 0.5185102820396423 all mean 0.5132736563682556
0.07688924670219421 0.07688923925161362
rl training, epoch4, iter0, batch576/1133, batch loss:0.07688923925161362, Training time:69817.5644466877
batch reward last col mean 0.5791671276092529 first col mean 0.5817397832870483 all mean 0.5797712206840515
0.10104570537805557 0.10104568302631378
rl training, epoch4, iter0, batch577/1133, batch loss:0.10104568302631378, Training time:69817.96111607552
batch reward last col mean 0.5587409138679504 first col mean 0.567765474319458 all mean 0.5597267150878906
0.1065916121006012 0.1065916046500206
rl training, epoch4, iter0, batch578/1133, batch loss:0.1065916046500206, Training time:69818.44090032578
batch reward last col mean 0.5731622576713562 first col mean 0.5584729909896851 all mean 0.5675236582756042
0.11121810227632523 0.11121807992458344
rl training, epoch4, iter0, batch579/1133, batch loss:0.11121807992458344, Training time:69818.93970704079
batch reward last col mean 0.6095462441444397 first col mean 0.6056912541389465 all mean 0.6065639853477478
0.10026592761278152 0.10026594996452332
rl training, epoch4, iter0, batch580/1133, batch loss:0.10026594996452332, Training time:69819.50739097595
batch reward last col mean 0.5895937085151672 first col mean 0.6019367575645447 all mean 0.5943173170089722
0.10344872623682022 0.10344874113798141
rl training, epoch4, iter0, batch581/1133, batch loss:0.10344874113798141, Training time:69820.16756558418
batch reward last col mean 0.5539093017578125 first col mean 0.5449514389038086 all mean 0.5539745092391968
0.07178636640310287 0.07178636640310287
rl training, epoch4, iter0, batch582/1133, batch loss:0.07178636640310287, Training time:69820.6300535202
batch reward last col mean 0.6368101239204407 first col mean 0.6452919244766235 all mean 0.6375204920768738
0.10079729557037354 0.10079729557037354
rl training, epoch4, iter0, batch583/1133, batch loss:0.10079729557037354, Training time:69821.09809470177
batch reward last col mean 0.5638574361801147 first col mean 0.5880045890808105 all mean 0.5695734620094299
0.09140181541442871 0.09140181541442871
rl training, epoch4, iter0, batch584/1133, batch loss:0.09140181541442871, Training time:69821.51701402664
batch reward last col mean 0.5381201505661011 first col mean 0.5279723405838013 all mean 0.5369921922683716
0.08187280595302582 0.08187280595302582
rl training, epoch4, iter0, batch585/1133, batch loss:0.08187280595302582, Training time:69822.05783629417
batch reward last col mean 0.539989173412323 first col mean 0.5461405515670776 all mean 0.544575572013855
0.08655727654695511 0.08655727654695511
rl training, epoch4, iter0, batch586/1133, batch loss:0.08655727654695511, Training time:69822.5601952076
batch reward last col mean 0.6049070358276367 first col mean 0.61236572265625 all mean 0.602846622467041
0.10156134516000748 0.10156133025884628
rl training, epoch4, iter0, batch587/1133, batch loss:0.10156133025884628, Training time:69823.13233923912
batch reward last col mean 0.5089410543441772 first col mean 0.5365913510322571 all mean 0.512533962726593
0.08135344833135605 0.08135344833135605
rl training, epoch4, iter0, batch588/1133, batch loss:0.08135344833135605, Training time:69823.70535898209
batch reward last col mean 0.5726014971733093 first col mean 0.591748833656311 all mean 0.5780413746833801
0.12278406322002411 0.1227840706706047
rl training, epoch4, iter0, batch589/1133, batch loss:0.1227840706706047, Training time:69824.36784744263
batch reward last col mean 0.5775498747825623 first col mean 0.5922964215278625 all mean 0.5832382440567017
0.1251288652420044 0.1251288652420044
rl training, epoch4, iter0, batch590/1133, batch loss:0.1251288652420044, Training time:69824.82566547394
batch reward last col mean 0.583654522895813 first col mean 0.6111610531806946 all mean 0.5905611515045166
0.07556181401014328 0.0755617767572403
rl training, epoch4, iter0, batch591/1133, batch loss:0.0755617767572403, Training time:69825.31794500351
batch reward last col mean 0.5824767351150513 first col mean 0.5914382934570312 all mean 0.5818958282470703
0.09792503714561462 0.09792503714561462
rl training, epoch4, iter0, batch592/1133, batch loss:0.09792503714561462, Training time:69825.78973579407
batch reward last col mean 0.5544929504394531 first col mean 0.5682539939880371 all mean 0.5618365406990051
0.08023775368928909 0.08023776113986969
rl training, epoch4, iter0, batch593/1133, batch loss:0.08023776113986969, Training time:69826.24430203438
batch reward last col mean 0.5376492738723755 first col mean 0.5596325397491455 all mean 0.5408751964569092
0.09059039503335953 0.09059040248394012
rl training, epoch4, iter0, batch594/1133, batch loss:0.09059040248394012, Training time:69826.79719758034
batch reward last col mean 0.5486796498298645 first col mean 0.5860974788665771 all mean 0.5554805397987366
0.09965753555297852 0.09965754300355911
rl training, epoch4, iter0, batch595/1133, batch loss:0.09965754300355911, Training time:69827.2613363266
batch reward last col mean 0.5188604593276978 first col mean 0.5361129641532898 all mean 0.5201643109321594
0.08124832808971405 0.08124832808971405
rl training, epoch4, iter0, batch596/1133, batch loss:0.08124832808971405, Training time:69827.87882399559
batch reward last col mean 0.5866255164146423 first col mean 0.6113156080245972 all mean 0.5909134149551392
0.08755053579807281 0.08755052834749222
rl training, epoch4, iter0, batch597/1133, batch loss:0.08755052834749222, Training time:69828.46790075302
batch reward last col mean 0.5401343703269958 first col mean 0.5539950728416443 all mean 0.5435266494750977
0.07483614981174469 0.07483614981174469
rl training, epoch4, iter0, batch598/1133, batch loss:0.07483614981174469, Training time:69828.9410469532
batch reward last col mean 0.5527303814888 first col mean 0.5714086294174194 all mean 0.5552868843078613
0.09673943370580673 0.09673944860696793
rl training, epoch4, iter0, batch599/1133, batch loss:0.09673944860696793, Training time:69829.45350694656
batch reward last col mean 0.5628328323364258 first col mean 0.5834434032440186 all mean 0.5679133534431458
0.08810342103242874 0.08810342103242874
rl training, epoch4, iter0, batch600/1133, batch loss:0.08810342103242874, Training time:69830.00950455666
batch reward last col mean 0.5407646894454956 first col mean 0.5408106446266174 all mean 0.5385907888412476
0.09618964046239853 0.09618964046239853
rl training, epoch4, iter0, batch601/1133, batch loss:0.09618964046239853, Training time:69830.50190854073
batch reward last col mean 0.5994501113891602 first col mean 0.5827295780181885 all mean 0.5939423441886902
0.10031437128782272 0.10031437128782272
rl training, epoch4, iter0, batch602/1133, batch loss:0.10031437128782272, Training time:69830.91923546791
batch reward last col mean 0.5924118757247925 first col mean 0.576227068901062 all mean 0.5889949202537537
0.10471053421497345 0.10471052676439285
rl training, epoch4, iter0, batch603/1133, batch loss:0.10471052676439285, Training time:69831.45325636864
batch reward last col mean 0.6057021021842957 first col mean 0.6050556898117065 all mean 0.6085070371627808
0.10535155236721039 0.10535155981779099
rl training, epoch4, iter0, batch604/1133, batch loss:0.10535155981779099, Training time:69831.96718358994
batch reward last col mean 0.5677333474159241 first col mean 0.5892894268035889 all mean 0.5723523497581482
0.09967663884162903 0.09967663884162903
rl training, epoch4, iter0, batch605/1133, batch loss:0.09967663884162903, Training time:69832.4738805294
batch reward last col mean 0.5837423205375671 first col mean 0.5971711277961731 all mean 0.5839041471481323
0.0753701850771904 0.075370192527771
rl training, epoch4, iter0, batch606/1133, batch loss:0.075370192527771, Training time:69833.02225589752
batch reward last col mean 0.5795911550521851 first col mean 0.5935328602790833 all mean 0.5822006464004517
0.0789937898516655 0.0789937898516655
rl training, epoch4, iter0, batch607/1133, batch loss:0.0789937898516655, Training time:69833.62745857239
batch reward last col mean 0.5394193530082703 first col mean 0.5636783838272095 all mean 0.5442529320716858
0.13158829510211945 0.13158828020095825
rl training, epoch4, iter0, batch608/1133, batch loss:0.13158828020095825, Training time:69834.26989936829
batch reward last col mean 0.5884308218955994 first col mean 0.5849450826644897 all mean 0.5891266465187073
0.07846385985612869 0.07846386730670929
rl training, epoch4, iter0, batch609/1133, batch loss:0.07846386730670929, Training time:69834.86893248558
batch reward last col mean 0.5745891332626343 first col mean 0.5990429520606995 all mean 0.5805935859680176
0.10935323685407639 0.10935323685407639
rl training, epoch4, iter0, batch610/1133, batch loss:0.10935323685407639, Training time:69835.43195533752
batch reward last col mean 0.5789638757705688 first col mean 0.5724782943725586 all mean 0.5763186812400818
0.08439311385154724 0.08439311385154724
rl training, epoch4, iter0, batch611/1133, batch loss:0.08439311385154724, Training time:69835.88411283493
batch reward last col mean 0.6008660197257996 first col mean 0.6049162149429321 all mean 0.5985507965087891
0.10389392822980881 0.10389392077922821
rl training, epoch4, iter0, batch612/1133, batch loss:0.10389392077922821, Training time:69836.53882479668
batch reward last col mean 0.5972312688827515 first col mean 0.607848048210144 all mean 0.5983704924583435
0.12824806571006775 0.12824806571006775
rl training, epoch4, iter0, batch613/1133, batch loss:0.12824806571006775, Training time:69837.10678648949
batch reward last col mean 0.6154484748840332 first col mean 0.6225614547729492 all mean 0.6167312264442444
0.12831400334835052 0.12831400334835052
rl training, epoch4, iter0, batch614/1133, batch loss:0.12831400334835052, Training time:69837.56152319908
batch reward last col mean 0.5638750195503235 first col mean 0.5622609853744507 all mean 0.5632745623588562
0.11335232853889465 0.11335232853889465
rl training, epoch4, iter0, batch615/1133, batch loss:0.11335232853889465, Training time:69838.44818854332
batch reward last col mean 0.5814105272293091 first col mean 0.5925825238227844 all mean 0.5844805240631104
0.1073639988899231 0.1073639839887619
rl training, epoch4, iter0, batch616/1133, batch loss:0.1073639839887619, Training time:69839.00573658943
batch reward last col mean 0.5242993235588074 first col mean 0.5393363237380981 all mean 0.5270124673843384
0.1005282998085022 0.10052831470966339
rl training, epoch4, iter0, batch617/1133, batch loss:0.10052831470966339, Training time:69839.67934346199
batch reward last col mean 0.6254585385322571 first col mean 0.6118631362915039 all mean 0.6221069693565369
0.10313627868890762 0.10313630104064941
rl training, epoch4, iter0, batch618/1133, batch loss:0.10313630104064941, Training time:69840.20296192169
batch reward last col mean 0.525264322757721 first col mean 0.5418647527694702 all mean 0.5296196937561035
0.10666989535093307 0.10666990280151367
rl training, epoch4, iter0, batch619/1133, batch loss:0.10666990280151367, Training time:69840.67749929428
batch reward last col mean 0.6131218075752258 first col mean 0.6045533418655396 all mean 0.6132333874702454
0.10000301152467728 0.10000299662351608
rl training, epoch4, iter0, batch620/1133, batch loss:0.10000299662351608, Training time:69841.28078985214
batch reward last col mean 0.5817521810531616 first col mean 0.6063050627708435 all mean 0.5875904560089111
0.11609723418951035 0.11609722673892975
rl training, epoch4, iter0, batch621/1133, batch loss:0.11609722673892975, Training time:69841.89765620232
batch reward last col mean 0.5891579985618591 first col mean 0.57051682472229 all mean 0.5871927738189697
0.12419881671667099 0.12419882416725159
rl training, epoch4, iter0, batch622/1133, batch loss:0.12419882416725159, Training time:69842.35765695572
batch reward last col mean 0.576129138469696 first col mean 0.5841377973556519 all mean 0.5780544281005859
0.14188005030155182 0.14188005030155182
rl training, epoch4, iter0, batch623/1133, batch loss:0.14188005030155182, Training time:69843.18756055832
batch reward last col mean 0.5880494713783264 first col mean 0.576405942440033 all mean 0.5853166580200195
0.12051239609718323 0.12051239609718323
rl training, epoch4, iter0, batch624/1133, batch loss:0.12051239609718323, Training time:69843.69026350975
batch reward last col mean 0.5947182774543762 first col mean 0.5769259333610535 all mean 0.5896662473678589
0.11015384644269943 0.11015385389328003
rl training, epoch4, iter0, batch625/1133, batch loss:0.11015385389328003, Training time:69844.34171462059
batch reward last col mean 0.5793986916542053 first col mean 0.5901103019714355 all mean 0.5816320776939392
0.12735895812511444 0.12735894322395325
rl training, epoch4, iter0, batch626/1133, batch loss:0.12735894322395325, Training time:69844.94388365746
batch reward last col mean 0.5768430233001709 first col mean 0.5822630524635315 all mean 0.5796870589256287
0.13499858975410461 0.13499858975410461
rl training, epoch4, iter0, batch627/1133, batch loss:0.13499858975410461, Training time:69845.50968003273
batch reward last col mean 0.5357484221458435 first col mean 0.5584138631820679 all mean 0.542235255241394
0.13221760094165802 0.13221758604049683
rl training, epoch4, iter0, batch628/1133, batch loss:0.13221758604049683, Training time:69846.20984721184
batch reward last col mean 0.5589702129364014 first col mean 0.5604573488235474 all mean 0.5611822605133057
0.11614951491355896 0.11614951491355896
rl training, epoch4, iter0, batch629/1133, batch loss:0.11614951491355896, Training time:69846.75173664093
batch reward last col mean 0.6102737188339233 first col mean 0.6170967221260071 all mean 0.6089526414871216
0.14221210777759552 0.14221210777759552
rl training, epoch4, iter0, batch630/1133, batch loss:0.14221210777759552, Training time:69847.35535740852
batch reward last col mean 0.5359513759613037 first col mean 0.5300101041793823 all mean 0.5330401659011841
0.1268434226512909 0.1268434226512909
rl training, epoch4, iter0, batch631/1133, batch loss:0.1268434226512909, Training time:69847.89922451973
batch reward last col mean 0.6230202317237854 first col mean 0.6130569577217102 all mean 0.6214665770530701
0.11759199947118759 0.11759199947118759
rl training, epoch4, iter0, batch632/1133, batch loss:0.11759199947118759, Training time:69848.7766199112
batch reward last col mean 0.5881553292274475 first col mean 0.5919051170349121 all mean 0.5898760557174683
0.1166178360581398 0.1166178435087204
rl training, epoch4, iter0, batch633/1133, batch loss:0.1166178435087204, Training time:69849.36019945145
batch reward last col mean 0.5337445735931396 first col mean 0.5433778166770935 all mean 0.5370005369186401
0.10409117490053177 0.10409115999937057
rl training, epoch4, iter0, batch634/1133, batch loss:0.10409115999937057, Training time:69850.05141592026
batch reward last col mean 0.577401340007782 first col mean 0.5661906003952026 all mean 0.5747579336166382
0.1310446709394455 0.1310446411371231
rl training, epoch4, iter0, batch635/1133, batch loss:0.1310446411371231, Training time:69850.63280773163
batch reward last col mean 0.5776042938232422 first col mean 0.6091341972351074 all mean 0.5835757255554199
0.09609917551279068 0.09609919041395187
rl training, epoch4, iter0, batch636/1133, batch loss:0.09609919041395187, Training time:69851.3908905983
batch reward last col mean 0.5693885684013367 first col mean 0.5977628231048584 all mean 0.5766182541847229
0.1285446733236313 0.1285446733236313
rl training, epoch4, iter0, batch637/1133, batch loss:0.1285446733236313, Training time:69852.1486287117
batch reward last col mean 0.5588210225105286 first col mean 0.5390974879264832 all mean 0.5556100606918335
0.1234571635723114 0.12345713376998901
rl training, epoch4, iter0, batch638/1133, batch loss:0.12345713376998901, Training time:69852.88178920746
batch reward last col mean 0.5860368013381958 first col mean 0.569277286529541 all mean 0.5845418572425842
0.14774319529533386 0.14774322509765625
rl training, epoch4, iter0, batch639/1133, batch loss:0.14774322509765625, Training time:69853.68666267395
batch reward last col mean 0.5805845856666565 first col mean 0.5992285013198853 all mean 0.5848307609558105
0.14802388846874237 0.14802388846874237
rl training, epoch4, iter0, batch640/1133, batch loss:0.14802388846874237, Training time:69854.58287334442
batch reward last col mean 0.5561003088951111 first col mean 0.5732033252716064 all mean 0.5585634112358093
0.11532004922628403 0.11532004922628403
rl training, epoch4, iter0, batch641/1133, batch loss:0.11532004922628403, Training time:69855.39527702332
batch reward last col mean 0.5621542930603027 first col mean 0.5636299848556519 all mean 0.5599798560142517
0.13010992109775543 0.13010992109775543
rl training, epoch4, iter0, batch642/1133, batch loss:0.13010992109775543, Training time:69856.16693854332
batch reward last col mean 0.5393898487091064 first col mean 0.557288408279419 all mean 0.5477044582366943
0.12657447159290314 0.12657445669174194
rl training, epoch4, iter0, batch643/1133, batch loss:0.12657445669174194, Training time:69856.7218503952
batch reward last col mean 0.51426762342453 first col mean 0.5316920280456543 all mean 0.5199189186096191
0.13457852602005005 0.13457852602005005
rl training, epoch4, iter0, batch644/1133, batch loss:0.13457852602005005, Training time:69857.47485780716
batch reward last col mean 0.5895107388496399 first col mean 0.5798069834709167 all mean 0.5898284316062927
0.15867741405963898 0.15867741405963898
rl training, epoch4, iter0, batch645/1133, batch loss:0.15867741405963898, Training time:69858.59436011314
batch reward last col mean 0.620655357837677 first col mean 0.6325204372406006 all mean 0.6252858638763428
0.1677469164133072 0.1677469164133072
rl training, epoch4, iter0, batch646/1133, batch loss:0.1677469164133072, Training time:69859.56782889366
batch reward last col mean 0.52953040599823 first col mean 0.5504434108734131 all mean 0.5328363180160522
0.1495000422000885 0.1495000272989273
rl training, epoch4, iter0, batch647/1133, batch loss:0.1495000272989273, Training time:69860.33115935326
batch reward last col mean 0.5690156817436218 first col mean 0.5589919686317444 all mean 0.5663903951644897
0.13761453330516815 0.13761453330516815
rl training, epoch4, iter0, batch648/1133, batch loss:0.13761453330516815, Training time:69861.01317000389
batch reward last col mean 0.5580613613128662 first col mean 0.5655163526535034 all mean 0.5607683658599854
0.13868571817874908 0.13868573307991028
rl training, epoch4, iter0, batch649/1133, batch loss:0.13868573307991028, Training time:69861.75239014626
batch reward last col mean 0.553379476070404 first col mean 0.5684611201286316 all mean 0.5573851466178894
0.16872164607048035 0.16872164607048035
rl training, epoch4, iter0, batch650/1133, batch loss:0.16872164607048035, Training time:69862.65715551376
batch reward last col mean 0.5663619637489319 first col mean 0.5684271454811096 all mean 0.5659010410308838
0.11874186247587204 0.11874186247587204
rl training, epoch4, iter0, batch651/1133, batch loss:0.11874186247587204, Training time:69863.25501871109
batch reward last col mean 0.6102533340454102 first col mean 0.6291553378105164 all mean 0.6147175431251526
0.12380054593086243 0.12380053848028183
rl training, epoch4, iter0, batch652/1133, batch loss:0.12380053848028183, Training time:69864.00155091286
batch reward last col mean 0.5802403092384338 first col mean 0.5667306184768677 all mean 0.5769695043563843
0.1549776792526245 0.15497766435146332
rl training, epoch4, iter0, batch653/1133, batch loss:0.15497766435146332, Training time:69864.8310008049
batch reward last col mean 0.5572094917297363 first col mean 0.5621021389961243 all mean 0.557925283908844
0.17273379862308502 0.17273379862308502
rl training, epoch4, iter0, batch654/1133, batch loss:0.17273379862308502, Training time:69865.72481799126
batch reward last col mean 0.5705286860466003 first col mean 0.5684791207313538 all mean 0.5743772387504578
0.14615875482559204 0.14615875482559204
rl training, epoch4, iter0, batch655/1133, batch loss:0.14615875482559204, Training time:69866.5118765831
batch reward last col mean 0.5689341425895691 first col mean 0.5913910865783691 all mean 0.5720036625862122
0.12788629531860352 0.12788629531860352
rl training, epoch4, iter0, batch656/1133, batch loss:0.12788629531860352, Training time:69867.26882576942
batch reward last col mean 0.5603309273719788 first col mean 0.5739865303039551 all mean 0.5623875856399536
0.1304176300764084 0.1304176300764084
rl training, epoch4, iter0, batch657/1133, batch loss:0.1304176300764084, Training time:69867.94873976707
batch reward last col mean 0.5904958248138428 first col mean 0.5765102505683899 all mean 0.5888408422470093
0.13993029296398163 0.13993027806282043
rl training, epoch4, iter0, batch658/1133, batch loss:0.13993027806282043, Training time:69868.83108234406
batch reward last col mean 0.6214128732681274 first col mean 0.6175286769866943 all mean 0.6197152733802795
0.1492602825164795 0.1492602825164795
rl training, epoch4, iter0, batch659/1133, batch loss:0.1492602825164795, Training time:69869.99921822548
batch reward last col mean 0.5528159737586975 first col mean 0.5233453512191772 all mean 0.5515199899673462
0.13730472326278687 0.13730469346046448
rl training, epoch4, iter0, batch660/1133, batch loss:0.13730469346046448, Training time:69870.87644124031
batch reward last col mean 0.5760589241981506 first col mean 0.5949097871780396 all mean 0.5805865526199341
0.1769315004348755 0.1769314855337143
rl training, epoch4, iter0, batch661/1133, batch loss:0.1769314855337143, Training time:69871.57396030426
batch reward last col mean 0.5917521715164185 first col mean 0.5717148184776306 all mean 0.5858988761901855
0.17230671644210815 0.17230673134326935
rl training, epoch4, iter0, batch662/1133, batch loss:0.17230673134326935, Training time:69872.52944755554
batch reward last col mean 0.5680097937583923 first col mean 0.5646260380744934 all mean 0.5673007965087891
0.15502691268920898 0.15502691268920898
rl training, epoch4, iter0, batch663/1133, batch loss:0.15502691268920898, Training time:69873.3283958435
batch reward last col mean 0.6116499304771423 first col mean 0.6099960207939148 all mean 0.6114633679389954
0.17776261270046234 0.17776264250278473
rl training, epoch4, iter0, batch664/1133, batch loss:0.17776264250278473, Training time:69874.4794049263
batch reward last col mean 0.541503369808197 first col mean 0.5405877828598022 all mean 0.541046679019928
0.180815190076828 0.1808151751756668
rl training, epoch4, iter0, batch665/1133, batch loss:0.1808151751756668, Training time:69875.33220362663
batch reward last col mean 0.5689153075218201 first col mean 0.5846044421195984 all mean 0.5711773633956909
0.1556064337491989 0.1556064486503601
rl training, epoch4, iter0, batch666/1133, batch loss:0.1556064486503601, Training time:69876.45802760124
batch reward last col mean 0.585064172744751 first col mean 0.5834499597549438 all mean 0.5835357308387756
0.1724877804517746 0.1724877655506134
rl training, epoch4, iter0, batch667/1133, batch loss:0.1724877655506134, Training time:69877.63830447197
batch reward last col mean 0.6017495393753052 first col mean 0.5981233716011047 all mean 0.6016039252281189
0.1518998146057129 0.1518998146057129
rl training, epoch4, iter0, batch668/1133, batch loss:0.1518998146057129, Training time:69878.68665027618
batch reward last col mean 0.6127089262008667 first col mean 0.5835973620414734 all mean 0.608605146408081
0.2066875398159027 0.20668751001358032
rl training, epoch4, iter0, batch669/1133, batch loss:0.20668751001358032, Training time:69879.7868206501
batch reward last col mean 0.5986841320991516 first col mean 0.5981726050376892 all mean 0.598522424697876
0.1568055897951126 0.15680557489395142
rl training, epoch4, iter0, batch670/1133, batch loss:0.15680557489395142, Training time:69880.73692131042
batch reward last col mean 0.5589007139205933 first col mean 0.5696161985397339 all mean 0.5598053932189941
0.14172719419002533 0.14172717928886414
rl training, epoch4, iter0, batch671/1133, batch loss:0.14172717928886414, Training time:69881.75621724129
batch reward last col mean 0.5796176791191101 first col mean 0.5908291935920715 all mean 0.5836080312728882
0.13690689206123352 0.13690689206123352
rl training, epoch4, iter0, batch672/1133, batch loss:0.13690689206123352, Training time:69882.83692288399
batch reward last col mean 0.6119277477264404 first col mean 0.5948891639709473 all mean 0.6098949313163757
0.173813134431839 0.173813134431839
rl training, epoch4, iter0, batch673/1133, batch loss:0.173813134431839, Training time:69883.64821219444
batch reward last col mean 0.5625514388084412 first col mean 0.5876458883285522 all mean 0.5677427649497986
0.13963989913463593 0.13963989913463593
rl training, epoch4, iter0, batch674/1133, batch loss:0.13963989913463593, Training time:69884.46987628937
batch reward last col mean 0.5543616414070129 first col mean 0.5588076710700989 all mean 0.5532655715942383
0.1279412806034088 0.1279412806034088
rl training, epoch4, iter0, batch675/1133, batch loss:0.1279412806034088, Training time:69885.68622946739
batch reward last col mean 0.5851178169250488 first col mean 0.583095133304596 all mean 0.5876943469047546
0.18890921771526337 0.18890924751758575
rl training, epoch4, iter0, batch676/1133, batch loss:0.18890924751758575, Training time:69886.69012904167
batch reward last col mean 0.5913400650024414 first col mean 0.5938445329666138 all mean 0.5902135372161865
0.16093610227108002 0.16093610227108002
rl training, epoch4, iter0, batch677/1133, batch loss:0.16093610227108002, Training time:69887.6657409668
batch reward last col mean 0.6499310731887817 first col mean 0.6539202332496643 all mean 0.6486129760742188
0.18824878334999084 0.18824876844882965
rl training, epoch4, iter0, batch678/1133, batch loss:0.18824876844882965, Training time:69888.91418886185
batch reward last col mean 0.6215548515319824 first col mean 0.6029693484306335 all mean 0.6200125813484192
0.18209584057331085 0.18209582567214966
rl training, epoch4, iter0, batch679/1133, batch loss:0.18209582567214966, Training time:69889.82267856598
batch reward last col mean 0.5838050246238708 first col mean 0.5912330150604248 all mean 0.5829038619995117
0.12744837999343872 0.12744835019111633
rl training, epoch4, iter0, batch680/1133, batch loss:0.12744835019111633, Training time:69890.61621236801
batch reward last col mean 0.6346246600151062 first col mean 0.6357238292694092 all mean 0.6310927271842957
0.17145292460918427 0.17145292460918427
rl training, epoch4, iter0, batch681/1133, batch loss:0.17145292460918427, Training time:69891.49283504486
batch reward last col mean 0.5849454402923584 first col mean 0.5871634483337402 all mean 0.581755518913269
0.1251518875360489 0.1251518726348877
rl training, epoch4, iter0, batch682/1133, batch loss:0.1251518726348877, Training time:69892.23099350929
batch reward last col mean 0.5881035327911377 first col mean 0.5936189293861389 all mean 0.5871754884719849
0.1620117723941803 0.1620117574930191
rl training, epoch4, iter0, batch683/1133, batch loss:0.1620117574930191, Training time:69892.90213871002
batch reward last col mean 0.5959433913230896 first col mean 0.6046764850616455 all mean 0.5982235074043274
0.1369827538728714 0.1369827538728714
rl training, epoch4, iter0, batch684/1133, batch loss:0.1369827538728714, Training time:69893.44411230087
batch reward last col mean 0.5854411125183105 first col mean 0.5742567181587219 all mean 0.5839008092880249
0.16694259643554688 0.16694259643554688
rl training, epoch4, iter0, batch685/1133, batch loss:0.16694259643554688, Training time:69894.51817178726
batch reward last col mean 0.6368312835693359 first col mean 0.6438384056091309 all mean 0.6385884881019592
0.14494265615940094 0.14494265615940094
rl training, epoch4, iter0, batch686/1133, batch loss:0.14494265615940094, Training time:69895.25187754631
batch reward last col mean 0.5917002558708191 first col mean 0.5965248346328735 all mean 0.5916891098022461
0.1429721713066101 0.1429721713066101
rl training, epoch4, iter0, batch687/1133, batch loss:0.1429721713066101, Training time:69895.74167847633
batch reward last col mean 0.5854017734527588 first col mean 0.6046000719070435 all mean 0.591092586517334
0.13573992252349854 0.13573992252349854
rl training, epoch4, iter0, batch688/1133, batch loss:0.13573992252349854, Training time:69896.5046722889
batch reward last col mean 0.6251096725463867 first col mean 0.6258068084716797 all mean 0.6235703825950623
0.13994130492210388 0.13994131982326508
rl training, epoch4, iter0, batch689/1133, batch loss:0.13994131982326508, Training time:69897.10179662704
batch reward last col mean 0.6138995289802551 first col mean 0.6200487017631531 all mean 0.6156317591667175
0.15238484740257263 0.15238486230373383
rl training, epoch4, iter0, batch690/1133, batch loss:0.15238486230373383, Training time:69897.71294021606
batch reward last col mean 0.5790460705757141 first col mean 0.5723211169242859 all mean 0.5803702473640442
0.13384512066841125 0.13384513556957245
rl training, epoch4, iter0, batch691/1133, batch loss:0.13384513556957245, Training time:69898.31335639954
batch reward last col mean 0.6346161961555481 first col mean 0.6218814849853516 all mean 0.6334415078163147
0.1741541475057602 0.1741541624069214
rl training, epoch4, iter0, batch692/1133, batch loss:0.1741541624069214, Training time:69899.16926169395
batch reward last col mean 0.5940645933151245 first col mean 0.6126805543899536 all mean 0.5941665768623352
0.17387624084949493 0.17387624084949493
rl training, epoch4, iter0, batch693/1133, batch loss:0.17387624084949493, Training time:69899.99282193184
batch reward last col mean 0.5750086307525635 first col mean 0.5922806859016418 all mean 0.5774837136268616
0.17194993793964386 0.17194993793964386
rl training, epoch4, iter0, batch694/1133, batch loss:0.17194993793964386, Training time:69900.62950444221
batch reward last col mean 0.5694716572761536 first col mean 0.5862163305282593 all mean 0.5745553374290466
0.17581790685653687 0.17581790685653687
rl training, epoch4, iter0, batch695/1133, batch loss:0.17581790685653687, Training time:69901.20988702774
batch reward last col mean 0.6245918869972229 first col mean 0.6239600777626038 all mean 0.6239807605743408
0.19622255861759186 0.19622254371643066
rl training, epoch4, iter0, batch696/1133, batch loss:0.19622254371643066, Training time:69901.95998215675
batch reward last col mean 0.6066715717315674 first col mean 0.6077834367752075 all mean 0.6078125238418579
0.1965082436800003 0.1965082436800003
rl training, epoch4, iter0, batch697/1133, batch loss:0.1965082436800003, Training time:69902.60897016525
batch reward last col mean 0.5975644588470459 first col mean 0.5895612835884094 all mean 0.595669686794281
0.161664679646492 0.1616646945476532
rl training, epoch4, iter0, batch698/1133, batch loss:0.1616646945476532, Training time:69903.48364877701
batch reward last col mean 0.5532500147819519 first col mean 0.5504283308982849 all mean 0.5501433610916138
0.12693482637405396 0.12693482637405396
rl training, epoch4, iter0, batch699/1133, batch loss:0.12693482637405396, Training time:69904.2912364006
batch reward last col mean 0.544297993183136 first col mean 0.5507579445838928 all mean 0.5439209342002869
0.111426442861557 0.11142642796039581
rl training, epoch4, iter0, batch700/1133, batch loss:0.11142642796039581, Training time:69904.97034096718
batch reward last col mean 0.6054385304450989 first col mean 0.5887542366981506 all mean 0.6003770232200623
0.18424607813358307 0.18424607813358307
rl training, epoch4, iter0, batch701/1133, batch loss:0.18424607813358307, Training time:69905.89775109291
batch reward last col mean 0.610084593296051 first col mean 0.61067134141922 all mean 0.6098405122756958
0.16004866361618042 0.16004866361618042
rl training, epoch4, iter0, batch702/1133, batch loss:0.16004866361618042, Training time:69906.60425448418
batch reward last col mean 0.6097749471664429 first col mean 0.6188866496086121 all mean 0.6106534004211426
0.1453324407339096 0.1453324407339096
rl training, epoch4, iter0, batch703/1133, batch loss:0.1453324407339096, Training time:69907.37501049042
batch reward last col mean 0.5947762727737427 first col mean 0.5826215744018555 all mean 0.5925102233886719
0.1488092690706253 0.1488092839717865
rl training, epoch4, iter0, batch704/1133, batch loss:0.1488092839717865, Training time:69908.04184532166
batch reward last col mean 0.6291565895080566 first col mean 0.6472378969192505 all mean 0.6298162341117859
0.19521482288837433 0.19521480798721313
rl training, epoch4, iter0, batch705/1133, batch loss:0.19521480798721313, Training time:69909.00230050087
batch reward last col mean 0.6175205111503601 first col mean 0.6280434131622314 all mean 0.6181803941726685
0.16421809792518616 0.16421811282634735
rl training, epoch4, iter0, batch706/1133, batch loss:0.16421811282634735, Training time:69909.93838500977
batch reward last col mean 0.5269402265548706 first col mean 0.5388302206993103 all mean 0.5276020765304565
0.11776802688837051 0.11776801198720932
rl training, epoch4, iter0, batch707/1133, batch loss:0.11776801198720932, Training time:69910.60648226738
batch reward last col mean 0.6484811902046204 first col mean 0.6388918161392212 all mean 0.6484670042991638
0.18328538537025452 0.18328538537025452
rl training, epoch4, iter0, batch708/1133, batch loss:0.18328538537025452, Training time:69911.2954530716
batch reward last col mean 0.5765717029571533 first col mean 0.6038711667060852 all mean 0.5797392725944519
0.1642024964094162 0.1642024964094162
rl training, epoch4, iter0, batch709/1133, batch loss:0.1642024964094162, Training time:69911.90347504616
batch reward last col mean 0.5327444672584534 first col mean 0.5510505437850952 all mean 0.536865770816803
0.1272684782743454 0.1272684782743454
rl training, epoch4, iter0, batch710/1133, batch loss:0.1272684782743454, Training time:69912.44404220581
batch reward last col mean 0.6327946186065674 first col mean 0.6408553123474121 all mean 0.6353588104248047
0.18642905354499817 0.18642903864383698
rl training, epoch4, iter0, batch711/1133, batch loss:0.18642903864383698, Training time:69913.05276322365
batch reward last col mean 0.57437664270401 first col mean 0.5880517959594727 all mean 0.5796569585800171
0.1493207961320877 0.1493207961320877
rl training, epoch4, iter0, batch712/1133, batch loss:0.1493207961320877, Training time:69913.81968426704
batch reward last col mean 0.6120436787605286 first col mean 0.6024913191795349 all mean 0.605949878692627
0.1360129863023758 0.1360129863023758
rl training, epoch4, iter0, batch713/1133, batch loss:0.1360129863023758, Training time:69914.35734176636
batch reward last col mean 0.5683075189590454 first col mean 0.5783787965774536 all mean 0.5694026350975037
0.1678076833486557 0.1678076982498169
rl training, epoch4, iter0, batch714/1133, batch loss:0.1678076982498169, Training time:69914.9874458313
batch reward last col mean 0.5563896298408508 first col mean 0.5603788495063782 all mean 0.5598952174186707
0.15227510035037994 0.15227508544921875
rl training, epoch4, iter0, batch715/1133, batch loss:0.15227508544921875, Training time:69915.63291144371
batch reward last col mean 0.6329654455184937 first col mean 0.6235035061836243 all mean 0.6344411969184875
0.12765848636627197 0.12765850126743317
rl training, epoch4, iter0, batch716/1133, batch loss:0.12765850126743317, Training time:69916.23262429237
batch reward last col mean 0.612695038318634 first col mean 0.6175600290298462 all mean 0.6109029650688171
0.16324666142463684 0.16324664652347565
rl training, epoch4, iter0, batch717/1133, batch loss:0.16324664652347565, Training time:69916.85686850548
batch reward last col mean 0.5967391729354858 first col mean 0.6062780618667603 all mean 0.596921980381012
0.13415347039699554 0.13415347039699554
rl training, epoch4, iter0, batch718/1133, batch loss:0.13415347039699554, Training time:69917.45130300522
batch reward last col mean 0.5580399036407471 first col mean 0.5928647518157959 all mean 0.5659844875335693
0.1247270405292511 0.1247270479798317
rl training, epoch4, iter0, batch719/1133, batch loss:0.1247270479798317, Training time:69918.12560081482
batch reward last col mean 0.6107273697853088 first col mean 0.6004308462142944 all mean 0.6110288500785828
0.15918047726154327 0.15918047726154327
rl training, epoch4, iter0, batch720/1133, batch loss:0.15918047726154327, Training time:69918.9508368969
batch reward last col mean 0.6052552461624146 first col mean 0.6028724312782288 all mean 0.6055783033370972
0.10810696333646774 0.10810694843530655
rl training, epoch4, iter0, batch721/1133, batch loss:0.10810694843530655, Training time:69919.53841090202
batch reward last col mean 0.6373223662376404 first col mean 0.6400810480117798 all mean 0.6367776989936829
0.1454584300518036 0.1454584002494812
rl training, epoch4, iter0, batch722/1133, batch loss:0.1454584002494812, Training time:69920.05276632309
batch reward last col mean 0.6029044389724731 first col mean 0.6051685810089111 all mean 0.6060752272605896
0.17140735685825348 0.17140735685825348
rl training, epoch4, iter0, batch723/1133, batch loss:0.17140735685825348, Training time:69920.6477136612
batch reward last col mean 0.6201899647712708 first col mean 0.6282867193222046 all mean 0.6187378168106079
0.1552644520998001 0.15526443719863892
rl training, epoch4, iter0, batch724/1133, batch loss:0.15526443719863892, Training time:69921.30685663223
batch reward last col mean 0.6260848045349121 first col mean 0.6347290277481079 all mean 0.6281706690788269
0.1338014453649521 0.13380146026611328
rl training, epoch4, iter0, batch725/1133, batch loss:0.13380146026611328, Training time:69921.83564090729
batch reward last col mean 0.6214625239372253 first col mean 0.6198610663414001 all mean 0.6216859221458435
0.11668884754180908 0.11668884009122849
rl training, epoch4, iter0, batch726/1133, batch loss:0.11668884009122849, Training time:69922.28118419647
batch reward last col mean 0.6158503293991089 first col mean 0.6080193519592285 all mean 0.6148001551628113
0.09621471911668777 0.09621469676494598
rl training, epoch4, iter0, batch727/1133, batch loss:0.09621469676494598, Training time:69922.80644321442
batch reward last col mean 0.6242563724517822 first col mean 0.6292526721954346 all mean 0.6258842349052429
0.14785176515579224 0.14785176515579224
rl training, epoch4, iter0, batch728/1133, batch loss:0.14785176515579224, Training time:69923.39171910286
batch reward last col mean 0.5677131414413452 first col mean 0.584985613822937 all mean 0.5719090700149536
0.0855918824672699 0.0855918824672699
rl training, epoch4, iter0, batch729/1133, batch loss:0.0855918824672699, Training time:69923.84544730186
batch reward last col mean 0.5912221670150757 first col mean 0.5867998600006104 all mean 0.5908301472663879
0.11398699134588242 0.11398697644472122
rl training, epoch4, iter0, batch730/1133, batch loss:0.11398697644472122, Training time:69924.32282185555
batch reward last col mean 0.5999667644500732 first col mean 0.5841946601867676 all mean 0.5948577523231506
0.16233612596988678 0.16233612596988678
rl training, epoch4, iter0, batch731/1133, batch loss:0.16233612596988678, Training time:69924.8026919365
batch reward last col mean 0.574286162853241 first col mean 0.5972229242324829 all mean 0.5783966779708862
0.12198564410209656 0.12198564410209656
rl training, epoch4, iter0, batch732/1133, batch loss:0.12198564410209656, Training time:69925.28103375435
batch reward last col mean 0.6038708090782166 first col mean 0.5995665788650513 all mean 0.6035284996032715
0.1177065372467041 0.1177065372467041
rl training, epoch4, iter0, batch733/1133, batch loss:0.1177065372467041, Training time:69925.88801455498
batch reward last col mean 0.6625404357910156 first col mean 0.6562584638595581 all mean 0.661732017993927
0.13204501569271088 0.13204504549503326
rl training, epoch4, iter0, batch734/1133, batch loss:0.13204504549503326, Training time:69926.46116995811
batch reward last col mean 0.6080518364906311 first col mean 0.6082522869110107 all mean 0.6067968606948853
0.1148870661854744 0.11488708108663559
rl training, epoch4, iter0, batch735/1133, batch loss:0.11488708108663559, Training time:69927.07216000557
batch reward last col mean 0.5951011180877686 first col mean 0.5993660688400269 all mean 0.5955381989479065
0.11725529283285141 0.11725527793169022
rl training, epoch4, iter0, batch736/1133, batch loss:0.11725527793169022, Training time:69927.54471468925
batch reward last col mean 0.5576308965682983 first col mean 0.5868070125579834 all mean 0.5656586289405823
0.09322409331798553 0.09322409331798553
rl training, epoch4, iter0, batch737/1133, batch loss:0.09322409331798553, Training time:69928.1533613205
batch reward last col mean 0.6189857721328735 first col mean 0.6215312480926514 all mean 0.6192871332168579
0.13225769996643066 0.13225771486759186
rl training, epoch4, iter0, batch738/1133, batch loss:0.13225771486759186, Training time:69928.8900501728
batch reward last col mean 0.6268270611763 first col mean 0.6224445104598999 all mean 0.6285847425460815
0.1338123381137848 0.1338123381137848
rl training, epoch4, iter0, batch739/1133, batch loss:0.1338123381137848, Training time:69929.36664915085
batch reward last col mean 0.6229242086410522 first col mean 0.6140168309211731 all mean 0.6231086254119873
0.12823276221752167 0.12823274731636047
rl training, epoch4, iter0, batch740/1133, batch loss:0.12823274731636047, Training time:69929.90335798264
batch reward last col mean 0.5930567979812622 first col mean 0.6109168529510498 all mean 0.5972076654434204
0.09490702301263809 0.09490703046321869
rl training, epoch4, iter0, batch741/1133, batch loss:0.09490703046321869, Training time:69930.41281795502
batch reward last col mean 0.5713294744491577 first col mean 0.5894595384597778 all mean 0.5749666094779968
0.12394694238901138 0.12394694238901138
rl training, epoch4, iter0, batch742/1133, batch loss:0.12394694238901138, Training time:69931.09622645378
batch reward last col mean 0.5753875970840454 first col mean 0.5735318660736084 all mean 0.5753428936004639
0.11830940842628479 0.11830940842628479
rl training, epoch4, iter0, batch743/1133, batch loss:0.11830940842628479, Training time:69931.61628890038
batch reward last col mean 0.5807386636734009 first col mean 0.5890012383460999 all mean 0.583573043346405
0.10656416416168213 0.10656414926052094
rl training, epoch4, iter0, batch744/1133, batch loss:0.10656414926052094, Training time:69932.16402125359
batch reward last col mean 0.6354501843452454 first col mean 0.6408373117446899 all mean 0.6381795406341553
0.14303550124168396 0.14303548634052277
rl training, epoch4, iter0, batch745/1133, batch loss:0.14303548634052277, Training time:69932.7934987545
batch reward last col mean 0.6195485591888428 first col mean 0.6396474838256836 all mean 0.6216157674789429
0.11617834866046906 0.11617834866046906
rl training, epoch4, iter0, batch746/1133, batch loss:0.11617834866046906, Training time:69933.26275110245
batch reward last col mean 0.6435040235519409 first col mean 0.6537413001060486 all mean 0.643687903881073
0.15046647191047668 0.15046648681163788
rl training, epoch4, iter0, batch747/1133, batch loss:0.15046648681163788, Training time:69933.91131091118
batch reward last col mean 0.5804030895233154 first col mean 0.5683491230010986 all mean 0.5765316486358643
0.10903460532426834 0.10903460532426834
rl training, epoch4, iter0, batch748/1133, batch loss:0.10903460532426834, Training time:69934.52427077293
batch reward last col mean 0.5819800496101379 first col mean 0.6201754212379456 all mean 0.5882154107093811
0.13189150393009186 0.13189151883125305
rl training, epoch4, iter0, batch749/1133, batch loss:0.13189151883125305, Training time:69935.12172746658
batch reward last col mean 0.5758047103881836 first col mean 0.5959756374359131 all mean 0.5801384449005127
0.100919708609581 0.1009196937084198
rl training, epoch4, iter0, batch750/1133, batch loss:0.1009196937084198, Training time:69935.73548150063
batch reward last col mean 0.5657891631126404 first col mean 0.5919508934020996 all mean 0.5712752342224121
0.12226063758134842 0.12226062268018723
rl training, epoch4, iter0, batch751/1133, batch loss:0.12226062268018723, Training time:69936.32761740685
batch reward last col mean 0.6037072539329529 first col mean 0.6369996666908264 all mean 0.6102010607719421
0.11570427566766739 0.1157042607665062
rl training, epoch4, iter0, batch752/1133, batch loss:0.1157042607665062, Training time:69936.97235512733
batch reward last col mean 0.6377097368240356 first col mean 0.6161673665046692 all mean 0.6321867108345032
0.12464356422424316 0.12464355677366257
rl training, epoch4, iter0, batch753/1133, batch loss:0.12464355677366257, Training time:69937.51866006851
batch reward last col mean 0.6278085708618164 first col mean 0.6390200853347778 all mean 0.6282438635826111
0.12457678467035294 0.12457678467035294
rl training, epoch4, iter0, batch754/1133, batch loss:0.12457678467035294, Training time:69938.10753726959
batch reward last col mean 0.5817872285842896 first col mean 0.586537778377533 all mean 0.5827814340591431
0.11231005936861038 0.11231004446744919
rl training, epoch4, iter0, batch755/1133, batch loss:0.11231004446744919, Training time:69938.63313436508
batch reward last col mean 0.5654159188270569 first col mean 0.5801606178283691 all mean 0.5648496150970459
0.1258460134267807 0.1258460134267807
rl training, epoch4, iter0, batch756/1133, batch loss:0.1258460134267807, Training time:69939.19513511658
batch reward last col mean 0.6385903358459473 first col mean 0.6635700464248657 all mean 0.6426932215690613
0.12899334728717804 0.12899333238601685
rl training, epoch4, iter0, batch757/1133, batch loss:0.12899333238601685, Training time:69940.0308368206
batch reward last col mean 0.5884274244308472 first col mean 0.5895482897758484 all mean 0.5855280160903931
0.13439548015594482 0.13439546525478363
rl training, epoch4, iter0, batch758/1133, batch loss:0.13439546525478363, Training time:69940.59676456451
batch reward last col mean 0.6412767767906189 first col mean 0.637365996837616 all mean 0.6425220966339111
0.1125546395778656 0.1125546395778656
rl training, epoch4, iter0, batch759/1133, batch loss:0.1125546395778656, Training time:69941.16767597198
batch reward last col mean 0.6415780782699585 first col mean 0.6551850438117981 all mean 0.6439287662506104
0.15432098507881165 0.15432099997997284
rl training, epoch4, iter0, batch760/1133, batch loss:0.15432099997997284, Training time:69941.78852963448
batch reward last col mean 0.6410682201385498 first col mean 0.6536112427711487 all mean 0.6450733542442322
0.14303620159626007 0.14303620159626007
rl training, epoch4, iter0, batch761/1133, batch loss:0.14303620159626007, Training time:69942.31668663025
batch reward last col mean 0.5901897549629211 first col mean 0.5998997688293457 all mean 0.5936750769615173
0.1399773359298706 0.1399773210287094
rl training, epoch4, iter0, batch762/1133, batch loss:0.1399773210287094, Training time:69943.2856760025
batch reward last col mean 0.5824185013771057 first col mean 0.6097858548164368 all mean 0.5903996229171753
0.1322723627090454 0.1322723627090454
rl training, epoch4, iter0, batch763/1133, batch loss:0.1322723627090454, Training time:69943.92411327362
batch reward last col mean 0.6066051721572876 first col mean 0.6145899295806885 all mean 0.6089183688163757
0.11425085365772247 0.11425084620714188
rl training, epoch4, iter0, batch764/1133, batch loss:0.11425084620714188, Training time:69944.3795940876
batch reward last col mean 0.5949422121047974 first col mean 0.5874923467636108 all mean 0.5910881161689758
0.12022774666547775 0.12022774666547775
rl training, epoch4, iter0, batch765/1133, batch loss:0.12022774666547775, Training time:69944.8827984333
batch reward last col mean 0.6118063926696777 first col mean 0.6025023460388184 all mean 0.6140803098678589
0.13546398282051086 0.13546398282051086
rl training, epoch4, iter0, batch766/1133, batch loss:0.13546398282051086, Training time:69945.50447583199
batch reward last col mean 0.6507081985473633 first col mean 0.6605343818664551 all mean 0.6527191996574402
0.10601124167442322 0.10601121932268143
rl training, epoch4, iter0, batch767/1133, batch loss:0.10601121932268143, Training time:69946.069211483
batch reward last col mean 0.6239851713180542 first col mean 0.6173931360244751 all mean 0.6210124492645264
0.08923230320215225 0.08923228830099106
rl training, epoch4, iter0, batch768/1133, batch loss:0.08923228830099106, Training time:69946.63592767715
batch reward last col mean 0.5824937224388123 first col mean 0.5932344198226929 all mean 0.5838656425476074
0.11914750188589096 0.11914747953414917
rl training, epoch4, iter0, batch769/1133, batch loss:0.11914747953414917, Training time:69947.23660087585
batch reward last col mean 0.5962018370628357 first col mean 0.5996657609939575 all mean 0.5943241119384766
0.11681188642978668 0.11681188642978668
rl training, epoch4, iter0, batch770/1133, batch loss:0.11681188642978668, Training time:69947.63434481621
batch reward last col mean 0.6216223239898682 first col mean 0.6096690893173218 all mean 0.6193196177482605
0.13666194677352905 0.13666194677352905
rl training, epoch4, iter0, batch771/1133, batch loss:0.13666194677352905, Training time:69948.14968681335
batch reward last col mean 0.5997257828712463 first col mean 0.5920031070709229 all mean 0.6016925573348999
0.10369105637073517 0.10369104146957397
rl training, epoch4, iter0, batch772/1133, batch loss:0.10369104146957397, Training time:69948.63035988808
batch reward last col mean 0.6126381158828735 first col mean 0.6286973357200623 all mean 0.6167246103286743
0.09510250389575958 0.09510251134634018
rl training, epoch4, iter0, batch773/1133, batch loss:0.09510251134634018, Training time:69949.15442228317
batch reward last col mean 0.6015464067459106 first col mean 0.6206417679786682 all mean 0.6070505380630493
0.09870918095111847 0.09870916604995728
rl training, epoch4, iter0, batch774/1133, batch loss:0.09870916604995728, Training time:69949.71849632263
batch reward last col mean 0.6052759885787964 first col mean 0.6235665678977966 all mean 0.6065059900283813
0.10452771186828613 0.10452771186828613
rl training, epoch4, iter0, batch775/1133, batch loss:0.10452771186828613, Training time:69950.45974469185
batch reward last col mean 0.6374251246452332 first col mean 0.6359802484512329 all mean 0.6360499262809753
0.10224277526140213 0.10224279761314392
rl training, epoch4, iter0, batch776/1133, batch loss:0.10224279761314392, Training time:69951.02030611038
batch reward last col mean 0.5958947539329529 first col mean 0.5715581774711609 all mean 0.5920596122741699
0.13106675446033478 0.13106675446033478
rl training, epoch4, iter0, batch777/1133, batch loss:0.13106675446033478, Training time:69951.62242269516
batch reward last col mean 0.5881110429763794 first col mean 0.6080517768859863 all mean 0.5928086638450623
0.1288764327764511 0.1288764327764511
rl training, epoch4, iter0, batch778/1133, batch loss:0.1288764327764511, Training time:69952.27716827393
batch reward last col mean 0.6040382385253906 first col mean 0.6139724254608154 all mean 0.602733314037323
0.1043420135974884 0.1043420135974884
rl training, epoch4, iter0, batch779/1133, batch loss:0.1043420135974884, Training time:69952.82976341248
batch reward last col mean 0.6061049699783325 first col mean 0.62464439868927 all mean 0.6094875335693359
0.09566542506217957 0.09566542506217957
rl training, epoch4, iter0, batch780/1133, batch loss:0.09566542506217957, Training time:69953.41117691994
batch reward last col mean 0.646752119064331 first col mean 0.6280584335327148 all mean 0.6458020806312561
0.1247297078371048 0.1247297078371048
rl training, epoch4, iter0, batch781/1133, batch loss:0.1247297078371048, Training time:69953.88420677185
batch reward last col mean 0.607933759689331 first col mean 0.6106242537498474 all mean 0.6064802408218384
0.11065706610679626 0.11065708100795746
rl training, epoch4, iter0, batch782/1133, batch loss:0.11065708100795746, Training time:69954.61659359932
batch reward last col mean 0.5803025960922241 first col mean 0.6005138754844666 all mean 0.5847944617271423
0.12107589095830917 0.12107588350772858
rl training, epoch4, iter0, batch783/1133, batch loss:0.12107588350772858, Training time:69955.16348266602
batch reward last col mean 0.6192622780799866 first col mean 0.6269022822380066 all mean 0.6218043565750122
0.10198315978050232 0.10198316723108292
rl training, epoch4, iter0, batch784/1133, batch loss:0.10198316723108292, Training time:69955.86592364311
batch reward last col mean 0.5236110687255859 first col mean 0.5461517572402954 all mean 0.5276172161102295
0.09736896306276321 0.09736893326044083
rl training, epoch4, iter0, batch785/1133, batch loss:0.09736893326044083, Training time:69956.70362067223
batch reward last col mean 0.5905999541282654 first col mean 0.6176509857177734 all mean 0.5956851840019226
0.11780821532011032 0.11780820041894913
rl training, epoch4, iter0, batch786/1133, batch loss:0.11780820041894913, Training time:69957.47910618782
batch reward last col mean 0.6406629085540771 first col mean 0.6355265378952026 all mean 0.6420764923095703
0.09613928943872452 0.09613928943872452
rl training, epoch4, iter0, batch787/1133, batch loss:0.09613928943872452, Training time:69957.96957349777
batch reward last col mean 0.6117137670516968 first col mean 0.6058062314987183 all mean 0.6120920777320862
0.12200953811407089 0.1220095306634903
rl training, epoch4, iter0, batch788/1133, batch loss:0.1220095306634903, Training time:69958.72753429413
batch reward last col mean 0.588929295539856 first col mean 0.6013771295547485 all mean 0.5895714163780212
0.13870704174041748 0.13870705664157867
rl training, epoch4, iter0, batch789/1133, batch loss:0.13870705664157867, Training time:69959.8542599678
batch reward last col mean 0.6118625402450562 first col mean 0.605762243270874 all mean 0.6117210388183594
0.10308396816253662 0.10308397561311722
rl training, epoch4, iter0, batch790/1133, batch loss:0.10308397561311722, Training time:69960.56842160225
batch reward last col mean 0.6077785491943359 first col mean 0.6009436845779419 all mean 0.606909453868866
0.09835180640220642 0.09835180640220642
rl training, epoch4, iter0, batch791/1133, batch loss:0.09835180640220642, Training time:69961.12855434418
batch reward last col mean 0.6408354043960571 first col mean 0.6346504092216492 all mean 0.6392497420310974
0.10274350643157959 0.10274350643157959
rl training, epoch4, iter0, batch792/1133, batch loss:0.10274350643157959, Training time:69961.67757630348
batch reward last col mean 0.6596722602844238 first col mean 0.6400680541992188 all mean 0.6586664915084839
0.10631296783685684 0.10631294548511505
rl training, epoch4, iter0, batch793/1133, batch loss:0.10631294548511505, Training time:69962.2021305561
batch reward last col mean 0.6176875829696655 first col mean 0.6301923990249634 all mean 0.6195914149284363
0.10524061322212219 0.10524061322212219
rl training, epoch4, iter0, batch794/1133, batch loss:0.10524061322212219, Training time:69962.68473052979
batch reward last col mean 0.5753039121627808 first col mean 0.587162971496582 all mean 0.5753340125083923
0.11787401139736176 0.11787400394678116
rl training, epoch4, iter0, batch795/1133, batch loss:0.11787400394678116, Training time:69963.325953722
batch reward last col mean 0.5956451892852783 first col mean 0.6133560538291931 all mean 0.5951563715934753
0.0947260931134224 0.09472610801458359
rl training, epoch4, iter0, batch796/1133, batch loss:0.09472610801458359, Training time:69963.77815151215
batch reward last col mean 0.6206996440887451 first col mean 0.6149911880493164 all mean 0.6211459040641785
0.09622659534215927 0.09622659534215927
rl training, epoch4, iter0, batch797/1133, batch loss:0.09622659534215927, Training time:69964.28705143929
batch reward last col mean 0.5931559801101685 first col mean 0.5979293584823608 all mean 0.5971238613128662
0.11365160346031189 0.1136515811085701
rl training, epoch4, iter0, batch798/1133, batch loss:0.1136515811085701, Training time:69964.73657822609
batch reward last col mean 0.6339874267578125 first col mean 0.6242681741714478 all mean 0.6317169070243835
0.10563603043556213 0.10563601553440094
rl training, epoch4, iter0, batch799/1133, batch loss:0.10563601553440094, Training time:69965.32915353775
batch reward last col mean 0.6188094615936279 first col mean 0.6185356378555298 all mean 0.6159230470657349
0.1175457090139389 0.1175457090139389
rl training, epoch4, iter0, batch800/1133, batch loss:0.1175457090139389, Training time:69965.86232042313
batch reward last col mean 0.5899692177772522 first col mean 0.5916795134544373 all mean 0.5873612761497498
0.10070496797561646 0.10070494562387466
rl training, epoch4, iter0, batch801/1133, batch loss:0.10070494562387466, Training time:69966.28589510918
batch reward last col mean 0.5822077989578247 first col mean 0.6023225784301758 all mean 0.5880069136619568
0.12378592789173126 0.12378592789173126
rl training, epoch4, iter0, batch802/1133, batch loss:0.12378592789173126, Training time:69966.87639784813
batch reward last col mean 0.6296882629394531 first col mean 0.6309149265289307 all mean 0.6285593509674072
0.13031740486621857 0.13031741976737976
rl training, epoch4, iter0, batch803/1133, batch loss:0.13031741976737976, Training time:69967.48833823204
batch reward last col mean 0.6022077202796936 first col mean 0.612909197807312 all mean 0.6019954681396484
0.10757565498352051 0.10757564008235931
rl training, epoch4, iter0, batch804/1133, batch loss:0.10757564008235931, Training time:69968.05904006958
batch reward last col mean 0.5893203020095825 first col mean 0.6028965711593628 all mean 0.5902782082557678
0.0806160420179367 0.08061603456735611
rl training, epoch4, iter0, batch805/1133, batch loss:0.08061603456735611, Training time:69968.68232989311
batch reward last col mean 0.6029056906700134 first col mean 0.6168692708015442 all mean 0.6035643815994263
0.10980036854743958 0.10980039089918137
rl training, epoch4, iter0, batch806/1133, batch loss:0.10980039089918137, Training time:69969.26188993454
batch reward last col mean 0.5825912356376648 first col mean 0.604396402835846 all mean 0.5888375639915466
0.12312953919172287 0.12312953174114227
rl training, epoch4, iter0, batch807/1133, batch loss:0.12312953174114227, Training time:69969.78773522377
batch reward last col mean 0.659614086151123 first col mean 0.6498916149139404 all mean 0.658320426940918
0.1142934039235115 0.1142934039235115
rl training, epoch4, iter0, batch808/1133, batch loss:0.1142934039235115, Training time:69970.26212191582
batch reward last col mean 0.5594271421432495 first col mean 0.5479240417480469 all mean 0.5564427375793457
0.07925821840763092 0.07925820350646973
rl training, epoch4, iter0, batch809/1133, batch loss:0.07925820350646973, Training time:69970.73105239868
batch reward last col mean 0.5981846451759338 first col mean 0.5940185189247131 all mean 0.5969364643096924
0.12438059598207474 0.12438057363033295
rl training, epoch4, iter0, batch810/1133, batch loss:0.12438057363033295, Training time:69971.43925738335
batch reward last col mean 0.6061547994613647 first col mean 0.62123703956604 all mean 0.6080657839775085
0.10029880702495575 0.10029880702495575
rl training, epoch4, iter0, batch811/1133, batch loss:0.10029880702495575, Training time:69971.88685536385
batch reward last col mean 0.565155029296875 first col mean 0.5902180671691895 all mean 0.5689378380775452
0.10860579460859299 0.10860579460859299
rl training, epoch4, iter0, batch812/1133, batch loss:0.10860579460859299, Training time:69972.6557059288
batch reward last col mean 0.5919961929321289 first col mean 0.6024243235588074 all mean 0.5951582789421082
0.09907595068216324 0.09907594323158264
rl training, epoch4, iter0, batch813/1133, batch loss:0.09907594323158264, Training time:69973.24452352524
batch reward last col mean 0.5580618977546692 first col mean 0.5689321756362915 all mean 0.5600028038024902
0.06929414719343185 0.06929416209459305
rl training, epoch4, iter0, batch814/1133, batch loss:0.06929416209459305, Training time:69973.75304174423
batch reward last col mean 0.5947381854057312 first col mean 0.5797099471092224 all mean 0.594498336315155
0.1065589115023613 0.1065589040517807
rl training, epoch4, iter0, batch815/1133, batch loss:0.1065589040517807, Training time:69974.38885951042
batch reward last col mean 0.5982804298400879 first col mean 0.5972838401794434 all mean 0.5979336500167847
0.13105982542037964 0.13105982542037964
rl training, epoch4, iter0, batch816/1133, batch loss:0.13105982542037964, Training time:69974.93201708794
batch reward last col mean 0.6403800845146179 first col mean 0.6362583637237549 all mean 0.6395721435546875
0.08111700415611267 0.08111698925495148
rl training, epoch4, iter0, batch817/1133, batch loss:0.08111698925495148, Training time:69975.40571117401
batch reward last col mean 0.6227902770042419 first col mean 0.6097705364227295 all mean 0.6222882866859436
0.09900826215744019 0.09900826960802078
rl training, epoch4, iter0, batch818/1133, batch loss:0.09900826960802078, Training time:69976.13503456116
batch reward last col mean 0.5795832872390747 first col mean 0.6041023135185242 all mean 0.5828404426574707
0.11159933358430862 0.11159933358430862
rl training, epoch4, iter0, batch819/1133, batch loss:0.11159933358430862, Training time:69976.81460046768
batch reward last col mean 0.5843496322631836 first col mean 0.579041063785553 all mean 0.5833127498626709
0.1367480307817459 0.13674800097942352
rl training, epoch4, iter0, batch820/1133, batch loss:0.13674800097942352, Training time:69977.62316346169
batch reward last col mean 0.6014360189437866 first col mean 0.6051019430160522 all mean 0.6050689220428467
0.12977361679077148 0.12977361679077148
rl training, epoch4, iter0, batch821/1133, batch loss:0.12977361679077148, Training time:69978.34830093384
batch reward last col mean 0.5428035259246826 first col mean 0.5583133101463318 all mean 0.5432297587394714
0.11543554812669754 0.11543554812669754
rl training, epoch4, iter0, batch822/1133, batch loss:0.11543554812669754, Training time:69978.8351097107
batch reward last col mean 0.6154852509498596 first col mean 0.6230478286743164 all mean 0.6176349520683289
0.108491450548172 0.108491450548172
rl training, epoch4, iter0, batch823/1133, batch loss:0.108491450548172, Training time:69979.3970272541
batch reward last col mean 0.544427752494812 first col mean 0.5328494310379028 all mean 0.542457640171051
0.11085646599531174 0.11085645109415054
rl training, epoch4, iter0, batch824/1133, batch loss:0.11085645109415054, Training time:69979.93611598015
batch reward last col mean 0.6052153706550598 first col mean 0.5997933745384216 all mean 0.6061574816703796
0.13140065968036652 0.13140064477920532
rl training, epoch4, iter0, batch825/1133, batch loss:0.13140064477920532, Training time:69980.43905115128
batch reward last col mean 0.621618390083313 first col mean 0.6233714818954468 all mean 0.6215528249740601
0.1221911758184433 0.1221911832690239
rl training, epoch4, iter0, batch826/1133, batch loss:0.1221911832690239, Training time:69981.19353294373
batch reward last col mean 0.5465731620788574 first col mean 0.5537341833114624 all mean 0.5488885641098022
0.12092996388673782 0.12092996388673782
rl training, epoch4, iter0, batch827/1133, batch loss:0.12092996388673782, Training time:69981.813164711
batch reward last col mean 0.5944166779518127 first col mean 0.6086490750312805 all mean 0.5985727906227112
0.16499607264995575 0.16499608755111694
rl training, epoch4, iter0, batch828/1133, batch loss:0.16499608755111694, Training time:69982.50302171707
batch reward last col mean 0.5490410327911377 first col mean 0.5584971308708191 all mean 0.5491539239883423
0.11378864198923111 0.11378864198923111
rl training, epoch4, iter0, batch829/1133, batch loss:0.11378864198923111, Training time:69983.18753027916
batch reward last col mean 0.5885159373283386 first col mean 0.6149627566337585 all mean 0.5993141531944275
0.11118338257074356 0.11118337512016296
rl training, epoch4, iter0, batch830/1133, batch loss:0.11118337512016296, Training time:69983.74641275406
batch reward last col mean 0.5951056480407715 first col mean 0.5959475040435791 all mean 0.5999326705932617
0.11360865086317062 0.11360864341259003
rl training, epoch4, iter0, batch831/1133, batch loss:0.11360864341259003, Training time:69984.39262080193
batch reward last col mean 0.6492624878883362 first col mean 0.6518617868423462 all mean 0.6450766324996948
0.12131761759519577 0.12131761759519577
rl training, epoch4, iter0, batch832/1133, batch loss:0.12131761759519577, Training time:69985.04438781738
batch reward last col mean 0.6428577303886414 first col mean 0.6402949094772339 all mean 0.6397758722305298
0.15571531653404236 0.15571530163288116
rl training, epoch4, iter0, batch833/1133, batch loss:0.15571530163288116, Training time:69985.57943201065
batch reward last col mean 0.5955480337142944 first col mean 0.6018533706665039 all mean 0.6001979112625122
0.12794645130634308 0.12794648110866547
rl training, epoch4, iter0, batch834/1133, batch loss:0.12794648110866547, Training time:69986.34684634209
batch reward last col mean 0.6241966485977173 first col mean 0.6154688596725464 all mean 0.6236090660095215
0.13276533782482147 0.13276533782482147
rl training, epoch4, iter0, batch835/1133, batch loss:0.13276533782482147, Training time:69987.11729621887
batch reward last col mean 0.6526175737380981 first col mean 0.6242049336433411 all mean 0.6475367546081543
0.157017782330513 0.157017782330513
rl training, epoch4, iter0, batch836/1133, batch loss:0.157017782330513, Training time:69987.8435459137
batch reward last col mean 0.5653760433197021 first col mean 0.580302357673645 all mean 0.5659600496292114
0.13110190629959106 0.13110190629959106
rl training, epoch4, iter0, batch837/1133, batch loss:0.13110190629959106, Training time:69988.51083087921
batch reward last col mean 0.6421436667442322 first col mean 0.6217790842056274 all mean 0.6381357908248901
0.14033947885036469 0.14033947885036469
rl training, epoch4, iter0, batch838/1133, batch loss:0.14033947885036469, Training time:69989.08571434021
batch reward last col mean 0.5777159929275513 first col mean 0.5969334244728088 all mean 0.5797505974769592
0.1122034415602684 0.1122034341096878
rl training, epoch4, iter0, batch839/1133, batch loss:0.1122034341096878, Training time:69989.5822994709
batch reward last col mean 0.6299582719802856 first col mean 0.6631737351417542 all mean 0.6328699588775635
0.14667589962482452 0.14667588472366333
rl training, epoch4, iter0, batch840/1133, batch loss:0.14667588472366333, Training time:69990.29510903358
batch reward last col mean 0.590279221534729 first col mean 0.593203067779541 all mean 0.5913111567497253
0.10564371198415756 0.10564369708299637
rl training, epoch4, iter0, batch841/1133, batch loss:0.10564369708299637, Training time:69990.85288596153
batch reward last col mean 0.6387423872947693 first col mean 0.637978196144104 all mean 0.6368250846862793
0.13290567696094513 0.13290566205978394
rl training, epoch4, iter0, batch842/1133, batch loss:0.13290566205978394, Training time:69991.43199038506
batch reward last col mean 0.6272146105766296 first col mean 0.6148124933242798 all mean 0.6272799968719482
0.11329078674316406 0.11329076439142227
rl training, epoch4, iter0, batch843/1133, batch loss:0.11329076439142227, Training time:69991.98611235619
batch reward last col mean 0.62516850233078 first col mean 0.6365601420402527 all mean 0.6255422234535217
0.11656232178211212 0.11656231433153152
rl training, epoch4, iter0, batch844/1133, batch loss:0.11656231433153152, Training time:69992.61724162102
batch reward last col mean 0.5743350982666016 first col mean 0.5900822877883911 all mean 0.5749068856239319
0.1460094153881073 0.1460094004869461
rl training, epoch4, iter0, batch845/1133, batch loss:0.1460094004869461, Training time:69993.18496656418
batch reward last col mean 0.6001061201095581 first col mean 0.5946155786514282 all mean 0.6009203791618347
0.127890482544899 0.127890482544899
rl training, epoch4, iter0, batch846/1133, batch loss:0.127890482544899, Training time:69993.73664164543
batch reward last col mean 0.5536594390869141 first col mean 0.5731385946273804 all mean 0.5581779479980469
0.1318366378545761 0.13183660805225372
rl training, epoch4, iter0, batch847/1133, batch loss:0.13183660805225372, Training time:69994.50067305565
batch reward last col mean 0.5847784876823425 first col mean 0.6045670509338379 all mean 0.5880898833274841
0.1059415340423584 0.1059415340423584
rl training, epoch4, iter0, batch848/1133, batch loss:0.1059415340423584, Training time:69995.23036956787
batch reward last col mean 0.5654730796813965 first col mean 0.5832746028900146 all mean 0.5670654773712158
0.10832525789737701 0.10832525044679642
rl training, epoch4, iter0, batch849/1133, batch loss:0.10832525044679642, Training time:69995.83995699883
batch reward last col mean 0.6157479286193848 first col mean 0.6136500239372253 all mean 0.6136228442192078
0.12438920885324478 0.1243891790509224
rl training, epoch4, iter0, batch850/1133, batch loss:0.1243891790509224, Training time:69996.61853766441
batch reward last col mean 0.6017940044403076 first col mean 0.6108943223953247 all mean 0.6008093953132629
0.10052213072776794 0.10052211582660675
rl training, epoch4, iter0, batch851/1133, batch loss:0.10052211582660675, Training time:69997.14995455742
batch reward last col mean 0.585556149482727 first col mean 0.5956830382347107 all mean 0.584848940372467
0.1506795585155487 0.1506795436143875
rl training, epoch4, iter0, batch852/1133, batch loss:0.1506795436143875, Training time:69997.8078391552
batch reward last col mean 0.5332272052764893 first col mean 0.5537227392196655 all mean 0.5376644730567932
0.14134545624256134 0.14134545624256134
rl training, epoch4, iter0, batch853/1133, batch loss:0.14134545624256134, Training time:69998.49031925201
batch reward last col mean 0.5812692046165466 first col mean 0.5904964804649353 all mean 0.588212251663208
0.157965749502182 0.1579657346010208
rl training, epoch4, iter0, batch854/1133, batch loss:0.1579657346010208, Training time:69999.14326548576
batch reward last col mean 0.6059227585792542 first col mean 0.6208227872848511 all mean 0.6092081069946289
0.15867269039154053 0.15867267549037933
rl training, epoch4, iter0, batch855/1133, batch loss:0.15867267549037933, Training time:69999.90267276764
batch reward last col mean 0.6276851892471313 first col mean 0.6188602447509766 all mean 0.6269755959510803
0.11741968244314194 0.11741967499256134
rl training, epoch4, iter0, batch856/1133, batch loss:0.11741967499256134, Training time:70000.88137292862
batch reward last col mean 0.5745502710342407 first col mean 0.6148048639297485 all mean 0.5809571146965027
0.10999473184347153 0.10999474674463272
rl training, epoch4, iter0, batch857/1133, batch loss:0.10999474674463272, Training time:70001.75264191628
batch reward last col mean 0.6089665293693542 first col mean 0.6330323219299316 all mean 0.6128208041191101
0.12303632497787476 0.12303632497787476
rl training, epoch4, iter0, batch858/1133, batch loss:0.12303632497787476, Training time:70002.75977921486
batch reward last col mean 0.6027388572692871 first col mean 0.6047371029853821 all mean 0.6024250984191895
0.12547814846038818 0.12547816336154938
rl training, epoch4, iter0, batch859/1133, batch loss:0.12547816336154938, Training time:70003.69071865082
batch reward last col mean 0.6184360980987549 first col mean 0.6108957529067993 all mean 0.6170632243156433
0.1147536113858223 0.11475362628698349
rl training, epoch4, iter0, batch860/1133, batch loss:0.11475362628698349, Training time:70004.51351952553
batch reward last col mean 0.6144748330116272 first col mean 0.6086021065711975 all mean 0.6117956638336182
0.10679890960454941 0.10679890960454941
rl training, epoch4, iter0, batch861/1133, batch loss:0.10679890960454941, Training time:70005.28619885445
batch reward last col mean 0.535306990146637 first col mean 0.5456287264823914 all mean 0.538054883480072
0.1288185864686966 0.1288185715675354
rl training, epoch4, iter0, batch862/1133, batch loss:0.1288185715675354, Training time:70006.32549381256
batch reward last col mean 0.6044374704360962 first col mean 0.6071570515632629 all mean 0.6056550741195679
0.14704638719558716 0.14704637229442596
rl training, epoch4, iter0, batch863/1133, batch loss:0.14704637229442596, Training time:70007.31399941444
batch reward last col mean 0.5654816627502441 first col mean 0.5767244100570679 all mean 0.5669304728507996
0.11259917169809341 0.11259918659925461
rl training, epoch4, iter0, batch864/1133, batch loss:0.11259918659925461, Training time:70008.37594246864
batch reward last col mean 0.5889629125595093 first col mean 0.5845165848731995 all mean 0.5893031358718872
0.13295535743236542 0.13295535743236542
rl training, epoch4, iter0, batch865/1133, batch loss:0.13295535743236542, Training time:70009.16755533218
batch reward last col mean 0.6303963661193848 first col mean 0.6476613283157349 all mean 0.6329517364501953
0.14961618185043335 0.14961616694927216
rl training, epoch4, iter0, batch866/1133, batch loss:0.14961616694927216, Training time:70010.2516720295
batch reward last col mean 0.5663677453994751 first col mean 0.5837278366088867 all mean 0.5701997876167297
0.13238316774368286 0.13238315284252167
rl training, epoch4, iter0, batch867/1133, batch loss:0.13238315284252167, Training time:70011.11273407936
batch reward last col mean 0.574196994304657 first col mean 0.5709465146064758 all mean 0.5768696665763855
0.12287170439958572 0.12287168949842453
rl training, epoch4, iter0, batch868/1133, batch loss:0.12287168949842453, Training time:70012.25260925293
batch reward last col mean 0.5898345708847046 first col mean 0.5722160339355469 all mean 0.58719402551651
0.15520267188549042 0.15520267188549042
rl training, epoch4, iter0, batch869/1133, batch loss:0.15520267188549042, Training time:70013.0210826397
batch reward last col mean 0.5873649716377258 first col mean 0.5916432738304138 all mean 0.5866643786430359
0.13855138421058655 0.13855136930942535
rl training, epoch4, iter0, batch870/1133, batch loss:0.13855136930942535, Training time:70014.2852306366
batch reward last col mean 0.5872295498847961 first col mean 0.597088098526001 all mean 0.5909251570701599
0.12088772654533386 0.12088770419359207
rl training, epoch4, iter0, batch871/1133, batch loss:0.12088770419359207, Training time:70015.40810370445
batch reward last col mean 0.5895728468894958 first col mean 0.597612738609314 all mean 0.5904805064201355
0.137028306722641 0.137028306722641
rl training, epoch4, iter0, batch872/1133, batch loss:0.137028306722641, Training time:70016.2294754982
batch reward last col mean 0.5871787071228027 first col mean 0.5840176343917847 all mean 0.5891708731651306
0.1336878538131714 0.13368786871433258
rl training, epoch4, iter0, batch873/1133, batch loss:0.13368786871433258, Training time:70017.38069295883
batch reward last col mean 0.6132482290267944 first col mean 0.6113173961639404 all mean 0.6129741072654724
0.1491270214319229 0.1491270214319229
rl training, epoch4, iter0, batch874/1133, batch loss:0.1491270214319229, Training time:70019.0356786251
batch reward last col mean 0.6011242866516113 first col mean 0.6098480820655823 all mean 0.6028600335121155
0.14851108193397522 0.14851106703281403
rl training, epoch4, iter0, batch875/1133, batch loss:0.14851106703281403, Training time:70020.19600224495
batch reward last col mean 0.5843097567558289 first col mean 0.5800212621688843 all mean 0.5823060274124146
0.13774937391281128 0.13774935901165009
rl training, epoch4, iter0, batch876/1133, batch loss:0.13774935901165009, Training time:70021.14502453804
batch reward last col mean 0.6244125366210938 first col mean 0.6323421001434326 all mean 0.6276717782020569
0.15990178287029266 0.15990176796913147
rl training, epoch4, iter0, batch877/1133, batch loss:0.15990176796913147, Training time:70022.15827155113
batch reward last col mean 0.6363471150398254 first col mean 0.6357758045196533 all mean 0.6381412148475647
0.17644226551055908 0.17644226551055908
rl training, epoch4, iter0, batch878/1133, batch loss:0.17644226551055908, Training time:70023.66216850281
batch reward last col mean 0.5967721939086914 first col mean 0.5989822149276733 all mean 0.5984053611755371
0.144995778799057 0.144995778799057
rl training, epoch4, iter0, batch879/1133, batch loss:0.144995778799057, Training time:70024.89685702324
batch reward last col mean 0.5849011540412903 first col mean 0.6231045722961426 all mean 0.5912062525749207
0.13708119094371796 0.13708119094371796
rl training, epoch4, iter0, batch880/1133, batch loss:0.13708119094371796, Training time:70026.53477048874
batch reward last col mean 0.6128397583961487 first col mean 0.6124433279037476 all mean 0.6121800541877747
0.14080724120140076 0.14080724120140076
rl training, epoch4, iter0, batch881/1133, batch loss:0.14080724120140076, Training time:70027.96917843819
batch reward last col mean 0.5988052487373352 first col mean 0.591068685054779 all mean 0.60094153881073
0.1539161503314972 0.153916135430336
rl training, epoch4, iter0, batch882/1133, batch loss:0.153916135430336, Training time:70029.19563484192
batch reward last col mean 0.591042160987854 first col mean 0.6222507357597351 all mean 0.5939590334892273
0.13583773374557495 0.13583773374557495
rl training, epoch4, iter0, batch883/1133, batch loss:0.13583773374557495, Training time:70030.24260616302
batch reward last col mean 0.6542543172836304 first col mean 0.6433432102203369 all mean 0.6501293778419495
0.14409583806991577 0.14409582316875458
rl training, epoch4, iter0, batch884/1133, batch loss:0.14409582316875458, Training time:70031.42712259293
batch reward last col mean 0.6476118564605713 first col mean 0.629860520362854 all mean 0.6483220458030701
0.15873606503009796 0.15873606503009796
rl training, epoch4, iter0, batch885/1133, batch loss:0.15873606503009796, Training time:70032.53620910645
batch reward last col mean 0.6129361391067505 first col mean 0.6286098957061768 all mean 0.6148506999015808
0.18643561005592346 0.18643561005592346
rl training, epoch4, iter0, batch886/1133, batch loss:0.18643561005592346, Training time:70034.4133605957
batch reward last col mean 0.6519274711608887 first col mean 0.6278859376907349 all mean 0.6471366286277771
0.15253199636936188 0.15253199636936188
rl training, epoch4, iter0, batch887/1133, batch loss:0.15253199636936188, Training time:70035.71832489967
batch reward last col mean 0.5559713840484619 first col mean 0.5927761197090149 all mean 0.5606001019477844
0.13013342022895813 0.13013342022895813
rl training, epoch4, iter0, batch888/1133, batch loss:0.13013342022895813, Training time:70037.18960928917
batch reward last col mean 0.5799456238746643 first col mean 0.5803443193435669 all mean 0.5798296928405762
0.13792181015014648 0.13792181015014648
rl training, epoch4, iter0, batch889/1133, batch loss:0.13792181015014648, Training time:70039.05864858627
batch reward last col mean 0.6534950137138367 first col mean 0.659735918045044 all mean 0.656347393989563
0.15191315114498138 0.15191315114498138
rl training, epoch4, iter0, batch890/1133, batch loss:0.15191315114498138, Training time:70040.87446427345
batch reward last col mean 0.5899970531463623 first col mean 0.6146377325057983 all mean 0.5939978361129761
0.12162487208843231 0.12162487208843231
rl training, epoch4, iter0, batch891/1133, batch loss:0.12162487208843231, Training time:70042.57717013359
batch reward last col mean 0.6159140467643738 first col mean 0.6323749423027039 all mean 0.6216279864311218
0.14040134847164154 0.14040133357048035
rl training, epoch4, iter0, batch892/1133, batch loss:0.14040133357048035, Training time:70044.20029520988
batch reward last col mean 0.5943606495857239 first col mean 0.6136239171028137 all mean 0.5975527763366699
0.1506664901971817 0.1506664901971817
rl training, epoch4, iter0, batch893/1133, batch loss:0.1506664901971817, Training time:70045.69676494598
batch reward last col mean 0.5991808772087097 first col mean 0.602777898311615 all mean 0.6032898426055908
0.11548502743244171 0.11548501998186111
rl training, epoch4, iter0, batch894/1133, batch loss:0.11548501998186111, Training time:70047.258092165
batch reward last col mean 0.6088317632675171 first col mean 0.6189870834350586 all mean 0.6097003817558289
0.11260239034891129 0.11260239034891129
rl training, epoch4, iter0, batch895/1133, batch loss:0.11260239034891129, Training time:70048.8496723175
batch reward last col mean 0.5868822336196899 first col mean 0.6136268973350525 all mean 0.5886792540550232
0.12263965606689453 0.12263966351747513
rl training, epoch4, iter0, batch896/1133, batch loss:0.12263966351747513, Training time:70050.48935580254
batch reward last col mean 0.6317508220672607 first col mean 0.6356515884399414 all mean 0.6332468390464783
0.11831887066364288 0.11831887066364288
rl training, epoch4, iter0, batch897/1133, batch loss:0.11831887066364288, Training time:70052.06529211998
batch reward last col mean 0.6588929891586304 first col mean 0.6644729971885681 all mean 0.657742977142334
0.11890508234500885 0.11890508234500885
rl training, epoch4, iter0, batch898/1133, batch loss:0.11890508234500885, Training time:70053.40559911728
batch reward last col mean 0.5776140093803406 first col mean 0.596638560295105 all mean 0.5807890295982361
0.09097373485565186 0.09097374230623245
rl training, epoch4, iter0, batch899/1133, batch loss:0.09097374230623245, Training time:70054.7575712204
batch reward last col mean 0.5925672054290771 first col mean 0.6039733290672302 all mean 0.5960057377815247
0.13488160073757172 0.13488158583641052
rl training, epoch4, iter0, batch900/1133, batch loss:0.13488158583641052, Training time:70056.41285204887
batch reward last col mean 0.6075157523155212 first col mean 0.606605052947998 all mean 0.6094357967376709
0.10599119961261749 0.10599119961261749
rl training, epoch4, iter0, batch901/1133, batch loss:0.10599119961261749, Training time:70058.21122431755
batch reward last col mean 0.6063928604125977 first col mean 0.5940485000610352 all mean 0.6054432392120361
0.11803168803453445 0.11803167313337326
rl training, epoch4, iter0, batch902/1133, batch loss:0.11803167313337326, Training time:70059.31119918823
batch reward last col mean 0.6124556064605713 first col mean 0.5989901423454285 all mean 0.6107513308525085
0.10807956010103226 0.10807954519987106
rl training, epoch4, iter0, batch903/1133, batch loss:0.10807954519987106, Training time:70060.34508085251
batch reward last col mean 0.6371059417724609 first col mean 0.6295545697212219 all mean 0.6356856822967529
0.1391473114490509 0.1391473114490509
rl training, epoch4, iter0, batch904/1133, batch loss:0.1391473114490509, Training time:70062.1101307869
batch reward last col mean 0.5676515102386475 first col mean 0.5742257833480835 all mean 0.5702151656150818
0.09609013050794601 0.09609011560678482
rl training, epoch4, iter0, batch905/1133, batch loss:0.09609011560678482, Training time:70063.41494035721
batch reward last col mean 0.6125203967094421 first col mean 0.6187165975570679 all mean 0.6127651929855347
0.11437507718801498 0.11437506228685379
rl training, epoch4, iter0, batch906/1133, batch loss:0.11437506228685379, Training time:70064.93668985367
batch reward last col mean 0.5843511819839478 first col mean 0.6041107177734375 all mean 0.588307797908783
0.09868303686380386 0.09868302941322327
rl training, epoch4, iter0, batch907/1133, batch loss:0.09868302941322327, Training time:70065.84243535995
batch reward last col mean 0.5408041477203369 first col mean 0.5772933959960938 all mean 0.5449565649032593
0.12342613190412521 0.12342611700296402
rl training, epoch4, iter0, batch908/1133, batch loss:0.12342611700296402, Training time:70067.33615756035
batch reward last col mean 0.6375361680984497 first col mean 0.6314731240272522 all mean 0.6374428272247314
0.1464991271495819 0.1464991271495819
rl training, epoch4, iter0, batch909/1133, batch loss:0.1464991271495819, Training time:70068.54615616798
batch reward last col mean 0.5744384527206421 first col mean 0.6148159503936768 all mean 0.5788795351982117
0.12492688000202179 0.12492689490318298
rl training, epoch4, iter0, batch910/1133, batch loss:0.12492689490318298, Training time:70069.79372429848
batch reward last col mean 0.5654004812240601 first col mean 0.5849480628967285 all mean 0.5671033263206482
0.09185509383678436 0.09185509383678436
rl training, epoch4, iter0, batch911/1133, batch loss:0.09185509383678436, Training time:70070.91052246094
batch reward last col mean 0.5715739130973816 first col mean 0.5961701273918152 all mean 0.5779571533203125
0.11655877530574799 0.11655876785516739
rl training, epoch4, iter0, batch912/1133, batch loss:0.11655876785516739, Training time:70072.06560921669
batch reward last col mean 0.5893939733505249 first col mean 0.5953730344772339 all mean 0.5910711288452148
0.1099843829870224 0.1099843978881836
rl training, epoch4, iter0, batch913/1133, batch loss:0.1099843978881836, Training time:70073.19454264641
batch reward last col mean 0.5810308456420898 first col mean 0.6266413927078247 all mean 0.5854399800300598
0.08596082776784897 0.08596082776784897
rl training, epoch4, iter0, batch914/1133, batch loss:0.08596082776784897, Training time:70075.28100085258
batch reward last col mean 0.5871361494064331 first col mean 0.5954830646514893 all mean 0.5908594727516174
0.1021745428442955 0.1021745428442955
rl training, epoch4, iter0, batch915/1133, batch loss:0.1021745428442955, Training time:70076.22281074524
batch reward last col mean 0.5577625036239624 first col mean 0.575158417224884 all mean 0.5604750514030457
0.12982691824436188 0.12982691824436188
rl training, epoch4, iter0, batch916/1133, batch loss:0.12982691824436188, Training time:70078.06597948074
batch reward last col mean 0.5999957919120789 first col mean 0.6011594533920288 all mean 0.5969657897949219
0.12170451134443283 0.12170449644327164
rl training, epoch4, iter0, batch917/1133, batch loss:0.12170449644327164, Training time:70079.4908618927
batch reward last col mean 0.5821537375450134 first col mean 0.5773208737373352 all mean 0.5826801657676697
0.11738366633653641 0.11738366633653641
rl training, epoch4, iter0, batch918/1133, batch loss:0.11738366633653641, Training time:70081.01847362518
batch reward last col mean 0.5706925988197327 first col mean 0.5910140872001648 all mean 0.5726152062416077
0.12329186499118805 0.12329186499118805
rl training, epoch4, iter0, batch919/1133, batch loss:0.12329186499118805, Training time:70082.68874979019
batch reward last col mean 0.5666723847389221 first col mean 0.5494011044502258 all mean 0.5642446875572205
0.09033209085464478 0.09033209085464478
rl training, epoch4, iter0, batch920/1133, batch loss:0.09033209085464478, Training time:70083.94673800468
batch reward last col mean 0.5627765655517578 first col mean 0.5765630602836609 all mean 0.5663319826126099
0.09192197024822235 0.09192197024822235
rl training, epoch4, iter0, batch921/1133, batch loss:0.09192197024822235, Training time:70085.55541110039
batch reward last col mean 0.5746771693229675 first col mean 0.5758014917373657 all mean 0.5761041045188904
0.12359970808029175 0.12359970062971115
rl training, epoch4, iter0, batch922/1133, batch loss:0.12359970062971115, Training time:70086.67976212502
batch reward last col mean 0.5575045943260193 first col mean 0.5778435468673706 all mean 0.5647426247596741
0.11115293204784393 0.11115293204784393
rl training, epoch4, iter0, batch923/1133, batch loss:0.11115293204784393, Training time:70087.58532977104
batch reward last col mean 0.6308025121688843 first col mean 0.622226893901825 all mean 0.6299293041229248
0.13303902745246887 0.13303905725479126
rl training, epoch4, iter0, batch924/1133, batch loss:0.13303905725479126, Training time:70089.8310520649
batch reward last col mean 0.5570537447929382 first col mean 0.5807164907455444 all mean 0.5569931268692017
0.09440285712480545 0.09440287947654724
rl training, epoch4, iter0, batch925/1133, batch loss:0.09440287947654724, Training time:70090.71307992935
batch reward last col mean 0.5905653834342957 first col mean 0.6124041676521301 all mean 0.5949360132217407
0.10499192774295807 0.10499192774295807
rl training, epoch4, iter0, batch926/1133, batch loss:0.10499192774295807, Training time:70091.62699699402
batch reward last col mean 0.6027423143386841 first col mean 0.6299762725830078 all mean 0.6064262390136719
0.11567360162734985 0.11567356437444687
rl training, epoch4, iter0, batch927/1133, batch loss:0.11567356437444687, Training time:70092.54564738274
batch reward last col mean 0.5564188957214355 first col mean 0.5919535160064697 all mean 0.5620503425598145
0.10280857235193253 0.10280858725309372
rl training, epoch4, iter0, batch928/1133, batch loss:0.10280858725309372, Training time:70093.39477825165
batch reward last col mean 0.5386232137680054 first col mean 0.5630545616149902 all mean 0.5392377376556396
0.11772562563419342 0.11772563308477402
rl training, epoch4, iter0, batch929/1133, batch loss:0.11772563308477402, Training time:70094.89915394783
batch reward last col mean 0.5837924480438232 first col mean 0.5846545100212097 all mean 0.5842466354370117
0.11264420300722122 0.11264419555664062
rl training, epoch4, iter0, batch930/1133, batch loss:0.11264419555664062, Training time:70095.68013334274
batch reward last col mean 0.6046147346496582 first col mean 0.6040773987770081 all mean 0.6050630211830139
0.09563697874546051 0.09563698619604111
rl training, epoch4, iter0, batch931/1133, batch loss:0.09563698619604111, Training time:70096.68442559242
batch reward last col mean 0.580706000328064 first col mean 0.589995801448822 all mean 0.5836578011512756
0.12101591378450394 0.12101589143276215
rl training, epoch4, iter0, batch932/1133, batch loss:0.12101589143276215, Training time:70097.34706115723
batch reward last col mean 0.5980125069618225 first col mean 0.6063908338546753 all mean 0.5993450284004211
0.11805087327957153 0.11805087327957153
rl training, epoch4, iter0, batch933/1133, batch loss:0.11805087327957153, Training time:70098.26300406456
batch reward last col mean 0.5611870288848877 first col mean 0.5653153657913208 all mean 0.560981035232544
0.07693611085414886 0.07693610340356827
rl training, epoch4, iter0, batch934/1133, batch loss:0.07693610340356827, Training time:70099.44794559479
batch reward last col mean 0.5751875638961792 first col mean 0.6011389493942261 all mean 0.579312264919281
0.1285620480775833 0.1285620480775833
rl training, epoch4, iter0, batch935/1133, batch loss:0.1285620480775833, Training time:70100.45256996155
batch reward last col mean 0.5824200510978699 first col mean 0.5901778340339661 all mean 0.582956075668335
0.10435023903846741 0.10435022413730621
rl training, epoch4, iter0, batch936/1133, batch loss:0.10435022413730621, Training time:70101.10984134674
batch reward last col mean 0.5970725417137146 first col mean 0.5887004733085632 all mean 0.5955100655555725
0.12107957154512405 0.12107957899570465
rl training, epoch4, iter0, batch937/1133, batch loss:0.12107957899570465, Training time:70102.43916869164
batch reward last col mean 0.5853083729743958 first col mean 0.6163551211357117 all mean 0.5893476605415344
0.1133652776479721 0.1133652776479721
rl training, epoch4, iter0, batch938/1133, batch loss:0.1133652776479721, Training time:70103.2677514553
batch reward last col mean 0.602907121181488 first col mean 0.5953033566474915 all mean 0.6025227904319763
0.11463692039251328 0.11463689804077148
rl training, epoch4, iter0, batch939/1133, batch loss:0.11463689804077148, Training time:70104.07687568665
batch reward last col mean 0.6095482707023621 first col mean 0.6181814074516296 all mean 0.6114068031311035
0.09273027628660202 0.09273029118776321
rl training, epoch4, iter0, batch940/1133, batch loss:0.09273029118776321, Training time:70104.71874904633
batch reward last col mean 0.6215704083442688 first col mean 0.6513540148735046 all mean 0.6271416544914246
0.11487263441085815 0.11487263441085815
rl training, epoch4, iter0, batch941/1133, batch loss:0.11487263441085815, Training time:70105.43110132217
batch reward last col mean 0.6151221394538879 first col mean 0.6042578816413879 all mean 0.614819347858429
0.10141998529434204 0.10141998529434204
rl training, epoch4, iter0, batch942/1133, batch loss:0.10141998529434204, Training time:70106.41019797325
batch reward last col mean 0.5620537996292114 first col mean 0.5944843292236328 all mean 0.567854106426239
0.10430458933115005 0.10430458933115005
rl training, epoch4, iter0, batch943/1133, batch loss:0.10430458933115005, Training time:70107.0434076786
batch reward last col mean 0.6118584275245667 first col mean 0.6342685222625732 all mean 0.613369882106781
0.1011127308011055 0.1011127308011055
rl training, epoch4, iter0, batch944/1133, batch loss:0.1011127308011055, Training time:70107.87142276764
batch reward last col mean 0.5736923813819885 first col mean 0.5881171226501465 all mean 0.5730510950088501
0.0916731059551239 0.0916731134057045
rl training, epoch4, iter0, batch945/1133, batch loss:0.0916731134057045, Training time:70108.72247862816
batch reward last col mean 0.579104483127594 first col mean 0.5788112878799438 all mean 0.5790372490882874
0.08166450262069702 0.08166451007127762
rl training, epoch4, iter0, batch946/1133, batch loss:0.08166451007127762, Training time:70109.22778868675
batch reward last col mean 0.5584101676940918 first col mean 0.587177574634552 all mean 0.5640811920166016
0.09180713444948196 0.09180712699890137
rl training, epoch4, iter0, batch947/1133, batch loss:0.09180712699890137, Training time:70109.8317785263
batch reward last col mean 0.5709548592567444 first col mean 0.5706589818000793 all mean 0.5715574026107788
0.10854807496070862 0.10854808241128922
rl training, epoch4, iter0, batch948/1133, batch loss:0.10854808241128922, Training time:70110.44888114929
batch reward last col mean 0.5841911435127258 first col mean 0.6048995852470398 all mean 0.5842443704605103
0.08660420030355453 0.08660420030355453
rl training, epoch4, iter0, batch949/1133, batch loss:0.08660420030355453, Training time:70111.27025389671
batch reward last col mean 0.6017339825630188 first col mean 0.5991587042808533 all mean 0.6013060212135315
0.09916261583566666 0.09916259348392487
rl training, epoch4, iter0, batch950/1133, batch loss:0.09916259348392487, Training time:70111.92257452011
batch reward last col mean 0.5371502041816711 first col mean 0.5341736078262329 all mean 0.5376143455505371
0.0744856595993042 0.0744856595993042
rl training, epoch4, iter0, batch951/1133, batch loss:0.0744856595993042, Training time:70112.41392683983
batch reward last col mean 0.5696175694465637 first col mean 0.5689679384231567 all mean 0.5684217810630798
0.08364113420248032 0.08364111930131912
rl training, epoch4, iter0, batch952/1133, batch loss:0.08364111930131912, Training time:70113.04673600197
batch reward last col mean 0.6103626489639282 first col mean 0.6337302923202515 all mean 0.6144084930419922
0.1210094764828682 0.121009461581707
rl training, epoch4, iter0, batch953/1133, batch loss:0.121009461581707, Training time:70113.87151765823
batch reward last col mean 0.6240134239196777 first col mean 0.6221405267715454 all mean 0.6222778558731079
0.07238247990608215 0.07238246500492096
rl training, epoch4, iter0, batch954/1133, batch loss:0.07238246500492096, Training time:70114.2829515934
batch reward last col mean 0.5572139024734497 first col mean 0.5635299682617188 all mean 0.5593650937080383
0.09029798209667206 0.09029798209667206
rl training, epoch4, iter0, batch955/1133, batch loss:0.09029798209667206, Training time:70114.88352179527
batch reward last col mean 0.6017600297927856 first col mean 0.5981488823890686 all mean 0.5993330478668213
0.07987574487924576 0.07987573742866516
rl training, epoch4, iter0, batch956/1133, batch loss:0.07987573742866516, Training time:70115.34947752953
batch reward last col mean 0.5552867650985718 first col mean 0.5446714758872986 all mean 0.5532363057136536
0.08717674762010574 0.08717674762010574
rl training, epoch4, iter0, batch957/1133, batch loss:0.08717674762010574, Training time:70115.8048992157
batch reward last col mean 0.5784571170806885 first col mean 0.5951716303825378 all mean 0.5819586515426636
0.09169381856918335 0.09169381856918335
rl training, epoch4, iter0, batch958/1133, batch loss:0.09169381856918335, Training time:70116.44152832031
batch reward last col mean 0.5448930263519287 first col mean 0.5446970462799072 all mean 0.5467249751091003
0.0925857350230217 0.0925857424736023
rl training, epoch4, iter0, batch959/1133, batch loss:0.0925857424736023, Training time:70116.866492033
batch reward last col mean 0.6045088768005371 first col mean 0.6018674969673157 all mean 0.6067190170288086
0.09653719514608383 0.09653719514608383
rl training, epoch4, iter0, batch960/1133, batch loss:0.09653719514608383, Training time:70117.42264127731
batch reward last col mean 0.5564450025558472 first col mean 0.5872206091880798 all mean 0.5638110637664795
0.08424875140190125 0.08424875885248184
rl training, epoch4, iter0, batch961/1133, batch loss:0.08424875885248184, Training time:70117.83634138107
batch reward last col mean 0.4869791567325592 first col mean 0.49981024861335754 all mean 0.48854103684425354
0.08429808914661407 0.08429808914661407
rl training, epoch4, iter0, batch962/1133, batch loss:0.08429808914661407, Training time:70118.40048384666
batch reward last col mean 0.608025074005127 first col mean 0.6063880920410156 all mean 0.6068449020385742
0.10052979737520218 0.10052980482578278
rl training, epoch4, iter0, batch963/1133, batch loss:0.10052980482578278, Training time:70119.19785237312
batch reward last col mean 0.597254753112793 first col mean 0.6068534851074219 all mean 0.5997123718261719
0.08927164226770401 0.08927163481712341
rl training, epoch4, iter0, batch964/1133, batch loss:0.08927163481712341, Training time:70119.94424510002
batch reward last col mean 0.616655707359314 first col mean 0.593906044960022 all mean 0.6134563088417053
0.1075514405965805 0.10755143314599991
rl training, epoch4, iter0, batch965/1133, batch loss:0.10755143314599991, Training time:70120.53232693672
batch reward last col mean 0.5424810647964478 first col mean 0.5511499643325806 all mean 0.5429368019104004
0.07383298873901367 0.07383299618959427
rl training, epoch4, iter0, batch966/1133, batch loss:0.07383299618959427, Training time:70121.13821458817
batch reward last col mean 0.5770978927612305 first col mean 0.591063380241394 all mean 0.5801308751106262
0.12492590397596359 0.12492591887712479
rl training, epoch4, iter0, batch967/1133, batch loss:0.12492591887712479, Training time:70121.64888858795
batch reward last col mean 0.6284915208816528 first col mean 0.6466021537780762 all mean 0.631671667098999
0.08305773138999939 0.08305774629116058
rl training, epoch4, iter0, batch968/1133, batch loss:0.08305774629116058, Training time:70122.16654086113
batch reward last col mean 0.6266034841537476 first col mean 0.6146666407585144 all mean 0.6238348484039307
0.10705534368753433 0.10705535113811493
rl training, epoch4, iter0, batch969/1133, batch loss:0.10705535113811493, Training time:70122.57473230362
batch reward last col mean 0.5612441897392273 first col mean 0.5629949569702148 all mean 0.560301661491394
0.08789118379354477 0.08789116889238358
rl training, epoch4, iter0, batch970/1133, batch loss:0.08789116889238358, Training time:70122.99170827866
batch reward last col mean 0.5799329876899719 first col mean 0.6110936403274536 all mean 0.5812228322029114
0.08640529960393906 0.08640530705451965
rl training, epoch4, iter0, batch971/1133, batch loss:0.08640530705451965, Training time:70123.70853424072
batch reward last col mean 0.5508676767349243 first col mean 0.5592146515846252 all mean 0.5569251775741577
0.1063653975725174 0.1063653975725174
rl training, epoch4, iter0, batch972/1133, batch loss:0.1063653975725174, Training time:70124.20343399048
batch reward last col mean 0.6129944920539856 first col mean 0.6218849420547485 all mean 0.6165335774421692
0.10445000231266022 0.10445000231266022
rl training, epoch4, iter0, batch973/1133, batch loss:0.10445000231266022, Training time:70124.7555270195
batch reward last col mean 0.6115809082984924 first col mean 0.6271535754203796 all mean 0.6152560710906982
0.07052130997180939 0.07052132487297058
rl training, epoch4, iter0, batch974/1133, batch loss:0.07052132487297058, Training time:70125.15654182434
batch reward last col mean 0.5827564597129822 first col mean 0.5887019634246826 all mean 0.58445805311203
0.08721798658370972 0.08721798658370972
rl training, epoch4, iter0, batch975/1133, batch loss:0.08721798658370972, Training time:70125.73931860924
batch reward last col mean 0.6054136753082275 first col mean 0.6167178750038147 all mean 0.6076710820198059
0.07403790205717087 0.07403790205717087
rl training, epoch4, iter0, batch976/1133, batch loss:0.07403790205717087, Training time:70126.19582772255
batch reward last col mean 0.6162033081054688 first col mean 0.6274933815002441 all mean 0.6194045543670654
0.10262802988290787 0.10262803733348846
rl training, epoch4, iter0, batch977/1133, batch loss:0.10262803733348846, Training time:70126.81665563583
batch reward last col mean 0.6135801076889038 first col mean 0.5971343517303467 all mean 0.6120092272758484
0.11319184303283691 0.11319184303283691
rl training, epoch4, iter0, batch978/1133, batch loss:0.11319184303283691, Training time:70127.52843594551
batch reward last col mean 0.5810181498527527 first col mean 0.5796586275100708 all mean 0.5809711813926697
0.08280648291110992 0.08280649781227112
rl training, epoch4, iter0, batch979/1133, batch loss:0.08280649781227112, Training time:70128.04404759407
batch reward last col mean 0.5943083763122559 first col mean 0.6252294778823853 all mean 0.597632884979248
0.07173514366149902 0.07173513621091843
rl training, epoch4, iter0, batch980/1133, batch loss:0.07173513621091843, Training time:70128.61930561066
batch reward last col mean 0.5889631509780884 first col mean 0.6087226867675781 all mean 0.5898407101631165
0.08287790417671204 0.08287792652845383
rl training, epoch4, iter0, batch981/1133, batch loss:0.08287792652845383, Training time:70129.06004881859
batch reward last col mean 0.5768294930458069 first col mean 0.5900053977966309 all mean 0.5781513452529907
0.0829969123005867 0.0829969272017479
rl training, epoch4, iter0, batch982/1133, batch loss:0.0829969272017479, Training time:70129.55786943436
batch reward last col mean 0.6437423229217529 first col mean 0.6487979888916016 all mean 0.6454354524612427
0.11629067361354828 0.11629068851470947
rl training, epoch4, iter0, batch983/1133, batch loss:0.11629068851470947, Training time:70130.10815882683
batch reward last col mean 0.5262971520423889 first col mean 0.5303424596786499 all mean 0.5296059846878052
0.08134254813194275 0.08134255558252335
rl training, epoch4, iter0, batch984/1133, batch loss:0.08134255558252335, Training time:70130.51830601692
batch reward last col mean 0.6044730544090271 first col mean 0.6157470345497131 all mean 0.6036525964736938
0.08375068753957748 0.08375067263841629
rl training, epoch4, iter0, batch985/1133, batch loss:0.08375067263841629, Training time:70131.22907066345
batch reward last col mean 0.5906513333320618 first col mean 0.6081259846687317 all mean 0.5923126935958862
0.0684841126203537 0.0684841051697731
rl training, epoch4, iter0, batch986/1133, batch loss:0.0684841051697731, Training time:70131.6483745575
batch reward last col mean 0.6313449740409851 first col mean 0.6438069343566895 all mean 0.6328359842300415
0.08349177241325378 0.08349177986383438
rl training, epoch4, iter0, batch987/1133, batch loss:0.08349177986383438, Training time:70132.04468894005
batch reward last col mean 0.6036571860313416 first col mean 0.5937330722808838 all mean 0.6058348417282104
0.07958711683750153 0.07958711683750153
rl training, epoch4, iter0, batch988/1133, batch loss:0.07958711683750153, Training time:70132.58793377876
batch reward last col mean 0.5652972459793091 first col mean 0.5683029294013977 all mean 0.5632014870643616
0.09143534302711487 0.09143534302711487
rl training, epoch4, iter0, batch989/1133, batch loss:0.09143534302711487, Training time:70133.11726260185
batch reward last col mean 0.5897679924964905 first col mean 0.6284962296485901 all mean 0.5925247669219971
0.08759821206331253 0.08759819716215134
rl training, epoch4, iter0, batch990/1133, batch loss:0.08759819716215134, Training time:70133.7412121296
batch reward last col mean 0.5890329480171204 first col mean 0.5893130302429199 all mean 0.5874625444412231
0.07773338258266449 0.0777333676815033
rl training, epoch4, iter0, batch991/1133, batch loss:0.0777333676815033, Training time:70134.22855615616
batch reward last col mean 0.5839521288871765 first col mean 0.5725927948951721 all mean 0.5837321281433105
0.09017559885978699 0.09017559885978699
rl training, epoch4, iter0, batch992/1133, batch loss:0.09017559885978699, Training time:70134.73512172699
batch reward last col mean 0.5960965752601624 first col mean 0.5911608338356018 all mean 0.5946535468101501
0.08304750174283981 0.08304750919342041
rl training, epoch4, iter0, batch993/1133, batch loss:0.08304750919342041, Training time:70135.17409873009
batch reward last col mean 0.5618089437484741 first col mean 0.5791445970535278 all mean 0.563500702381134
0.09559750556945801 0.09559749066829681
rl training, epoch4, iter0, batch994/1133, batch loss:0.09559749066829681, Training time:70135.56790828705
batch reward last col mean 0.6216862201690674 first col mean 0.6588175296783447 all mean 0.6258381605148315
0.07304728776216507 0.07304729521274567
rl training, epoch4, iter0, batch995/1133, batch loss:0.07304729521274567, Training time:70135.94732689857
batch reward last col mean 0.6020783185958862 first col mean 0.6237156987190247 all mean 0.6011766195297241
0.08573266863822937 0.08573266863822937
rl training, epoch4, iter0, batch996/1133, batch loss:0.08573266863822937, Training time:70136.37761950493
batch reward last col mean 0.6250517964363098 first col mean 0.6175671815872192 all mean 0.6239264607429504
0.07499571144580841 0.07499570399522781
rl training, epoch4, iter0, batch997/1133, batch loss:0.07499570399522781, Training time:70136.81209135056
batch reward last col mean 0.6503899097442627 first col mean 0.6505590677261353 all mean 0.6491971015930176
0.09631026536226273 0.09631026536226273
rl training, epoch4, iter0, batch998/1133, batch loss:0.09631026536226273, Training time:70137.2457485199
batch reward last col mean 0.5714257955551147 first col mean 0.5744414329528809 all mean 0.5728498697280884
0.0933568999171257 0.0933568999171257
rl training, epoch4, iter0, batch999/1133, batch loss:0.0933568999171257, Training time:70137.63475441933
batch reward last col mean 0.6074091792106628 first col mean 0.6129260659217834 all mean 0.6082188487052917
0.07079318165779114 0.07079316675662994
rl training, epoch4, iter0, batch1000/1133, batch loss:0.07079316675662994, Training time:70138.09105372429
batch reward last col mean 0.6367603540420532 first col mean 0.6377014517784119 all mean 0.6375434398651123
0.06400533020496368 0.06400533765554428
rl training, epoch4, iter0, batch1001/1133, batch loss:0.06400533765554428, Training time:70138.7642660141
batch reward last col mean 0.6096662282943726 first col mean 0.6176890730857849 all mean 0.6132608652114868
0.08220667392015457 0.08220666646957397
rl training, epoch4, iter0, batch1002/1133, batch loss:0.08220666646957397, Training time:70139.16223096848
batch reward last col mean 0.5474352836608887 first col mean 0.5695936679840088 all mean 0.5493425130844116
0.08853261172771454 0.08853261172771454
rl training, epoch4, iter0, batch1003/1133, batch loss:0.08853261172771454, Training time:70139.61834168434
batch reward last col mean 0.5862829685211182 first col mean 0.6115225553512573 all mean 0.589155912399292
0.05646565929055214 0.05646565556526184
rl training, epoch4, iter0, batch1004/1133, batch loss:0.05646565556526184, Training time:70140.1073038578
batch reward last col mean 0.6193906664848328 first col mean 0.6360808610916138 all mean 0.6186312437057495
0.09167032688856125 0.09167033433914185
rl training, epoch4, iter0, batch1005/1133, batch loss:0.09167033433914185, Training time:70140.74181389809
batch reward last col mean 0.565453052520752 first col mean 0.5971648693084717 all mean 0.5726373195648193
0.07458975166082382 0.07458975166082382
rl training, epoch4, iter0, batch1006/1133, batch loss:0.07458975166082382, Training time:70141.20378041267
batch reward last col mean 0.6049156188964844 first col mean 0.6067522764205933 all mean 0.6035659313201904
0.07058752328157425 0.07058753073215485
rl training, epoch4, iter0, batch1007/1133, batch loss:0.07058753073215485, Training time:70141.63132572174
batch reward last col mean 0.5811276435852051 first col mean 0.5966067314147949 all mean 0.5810177326202393
0.06888525933027267 0.06888525933027267
rl training, epoch4, iter0, batch1008/1133, batch loss:0.06888525933027267, Training time:70142.16753077507
batch reward last col mean 0.5899531841278076 first col mean 0.5997538566589355 all mean 0.5896576046943665
0.0834495946764946 0.0834495946764946
rl training, epoch4, iter0, batch1009/1133, batch loss:0.0834495946764946, Training time:70142.82796931267
batch reward last col mean 0.625985860824585 first col mean 0.6149917840957642 all mean 0.6226851940155029
0.08335202187299728 0.08335202187299728
rl training, epoch4, iter0, batch1010/1133, batch loss:0.08335202187299728, Training time:70143.22515273094
batch reward last col mean 0.5379157066345215 first col mean 0.5376278162002563 all mean 0.536980926990509
0.06768479198217392 0.06768479198217392
rl training, epoch4, iter0, batch1011/1133, batch loss:0.06768479198217392, Training time:70143.57702374458
batch reward last col mean 0.5812140703201294 first col mean 0.5704278945922852 all mean 0.5801939368247986
0.05964895710349083 0.05964893475174904
rl training, epoch4, iter0, batch1012/1133, batch loss:0.05964893475174904, Training time:70144.13269972801
batch reward last col mean 0.594525158405304 first col mean 0.6152662634849548 all mean 0.5996479988098145
0.06728225946426392 0.06728224456310272
rl training, epoch4, iter0, batch1013/1133, batch loss:0.06728224456310272, Training time:70144.62952184677
batch reward last col mean 0.5614437460899353 first col mean 0.5659559369087219 all mean 0.5631808638572693
0.062089644372463226 0.06208963692188263
rl training, epoch4, iter0, batch1014/1133, batch loss:0.06208963692188263, Training time:70145.08839654922
batch reward last col mean 0.5795494318008423 first col mean 0.5975522398948669 all mean 0.5826748609542847
0.08771810680627823 0.08771810680627823
rl training, epoch4, iter0, batch1015/1133, batch loss:0.08771810680627823, Training time:70145.7200140953
batch reward last col mean 0.5558292269706726 first col mean 0.5816412568092346 all mean 0.5609343647956848
0.06481748074293137 0.06481749564409256
rl training, epoch4, iter0, batch1016/1133, batch loss:0.06481749564409256, Training time:70146.1982319355
batch reward last col mean 0.5383695363998413 first col mean 0.541574239730835 all mean 0.5392466187477112
0.08070729672908783 0.08070727437734604
rl training, epoch4, iter0, batch1017/1133, batch loss:0.08070727437734604, Training time:70146.73420357704
batch reward last col mean 0.6074671745300293 first col mean 0.6127951145172119 all mean 0.6090655326843262
0.06255484372377396 0.06255484372377396
rl training, epoch4, iter0, batch1018/1133, batch loss:0.06255484372377396, Training time:70147.15309357643
batch reward last col mean 0.5725400447845459 first col mean 0.5814522504806519 all mean 0.577983021736145
0.07281474024057388 0.07281474024057388
rl training, epoch4, iter0, batch1019/1133, batch loss:0.07281474024057388, Training time:70147.53345036507
batch reward last col mean 0.6327381134033203 first col mean 0.6295731067657471 all mean 0.6328450441360474
0.07548301666975021 0.07548300176858902
rl training, epoch4, iter0, batch1020/1133, batch loss:0.07548300176858902, Training time:70147.9354660511
batch reward last col mean 0.5971357822418213 first col mean 0.5787827968597412 all mean 0.5950371026992798
0.07276622951030731 0.07276621460914612
rl training, epoch4, iter0, batch1021/1133, batch loss:0.07276621460914612, Training time:70148.40876197815
batch reward last col mean 0.5419546365737915 first col mean 0.5694865584373474 all mean 0.5470043420791626
0.08803220838308334 0.08803220838308334
rl training, epoch4, iter0, batch1022/1133, batch loss:0.08803220838308334, Training time:70148.8165576458
batch reward last col mean 0.5810133218765259 first col mean 0.5725456476211548 all mean 0.5783312916755676
0.09517709165811539 0.09517709165811539
rl training, epoch4, iter0, batch1023/1133, batch loss:0.09517709165811539, Training time:70149.27453923225
batch reward last col mean 0.589716911315918 first col mean 0.6017400026321411 all mean 0.5924417972564697
0.07341820746660233 0.07341820001602173
rl training, epoch4, iter0, batch1024/1133, batch loss:0.07341820001602173, Training time:70149.65464186668
batch reward last col mean 0.5911117792129517 first col mean 0.5932151079177856 all mean 0.595797598361969
0.06597243249416351 0.06597243249416351
rl training, epoch4, iter0, batch1025/1133, batch loss:0.06597243249416351, Training time:70149.99327039719
batch reward last col mean 0.5491420030593872 first col mean 0.5549265742301941 all mean 0.5506926774978638
0.050120171159505844 0.050120167434215546
rl training, epoch4, iter0, batch1026/1133, batch loss:0.050120167434215546, Training time:70150.37960672379
batch reward last col mean 0.606529951095581 first col mean 0.6111040711402893 all mean 0.6076775789260864
0.07919362187385559 0.07919362932443619
rl training, epoch4, iter0, batch1027/1133, batch loss:0.07919362932443619, Training time:70150.76085329056
batch reward last col mean 0.5220404863357544 first col mean 0.5495510101318359 all mean 0.5267173647880554
0.05419032648205757 0.05419032275676727
rl training, epoch4, iter0, batch1028/1133, batch loss:0.05419032275676727, Training time:70151.14328885078
batch reward last col mean 0.6140483617782593 first col mean 0.6006673574447632 all mean 0.6091644167900085
0.06939119845628738 0.06939120590686798
rl training, epoch4, iter0, batch1029/1133, batch loss:0.06939120590686798, Training time:70151.53237509727
batch reward last col mean 0.5986263751983643 first col mean 0.6110633611679077 all mean 0.5996590852737427
0.059202831238508224 0.05920282378792763
rl training, epoch4, iter0, batch1030/1133, batch loss:0.05920282378792763, Training time:70151.90968751907
batch reward last col mean 0.5516873598098755 first col mean 0.568034291267395 all mean 0.5543729662895203
0.057215023785829544 0.057215023785829544
rl training, epoch4, iter0, batch1031/1133, batch loss:0.057215023785829544, Training time:70152.32184791565
batch reward last col mean 0.5524324178695679 first col mean 0.5641118884086609 all mean 0.553968071937561
0.06880766153335571 0.0688076764345169
rl training, epoch4, iter0, batch1032/1133, batch loss:0.0688076764345169, Training time:70152.70841383934
batch reward last col mean 0.6335917115211487 first col mean 0.6361039280891418 all mean 0.6324277520179749
0.09297982603311539 0.0929798111319542
rl training, epoch4, iter0, batch1033/1133, batch loss:0.0929798111319542, Training time:70153.09898900986
batch reward last col mean 0.6217808723449707 first col mean 0.6148523092269897 all mean 0.6209216713905334
0.07070313394069672 0.07070313394069672
rl training, epoch4, iter0, batch1034/1133, batch loss:0.07070313394069672, Training time:70153.53121519089
batch reward last col mean 0.5795966386795044 first col mean 0.5614254474639893 all mean 0.5783424377441406
0.06763076037168503 0.06763075292110443
rl training, epoch4, iter0, batch1035/1133, batch loss:0.06763075292110443, Training time:70153.90515589714
batch reward last col mean 0.5534329414367676 first col mean 0.5614954233169556 all mean 0.551263689994812
0.06687034666538239 0.06687035411596298
rl training, epoch4, iter0, batch1036/1133, batch loss:0.06687035411596298, Training time:70154.28472495079
batch reward last col mean 0.6168868541717529 first col mean 0.6220264434814453 all mean 0.6175698637962341
0.05680696293711662 0.056806959211826324
rl training, epoch4, iter0, batch1037/1133, batch loss:0.056806959211826324, Training time:70154.66267299652
batch reward last col mean 0.6309405565261841 first col mean 0.613544762134552 all mean 0.6285400390625
0.05187634751200676 0.05187634751200676
rl training, epoch4, iter0, batch1038/1133, batch loss:0.05187634751200676, Training time:70155.11522269249
batch reward last col mean 0.5856198668479919 first col mean 0.5727092027664185 all mean 0.5837488770484924
0.06163303926587105 0.06163305044174194
rl training, epoch4, iter0, batch1039/1133, batch loss:0.06163305044174194, Training time:70155.6956524849
batch reward last col mean 0.6192511320114136 first col mean 0.6071484684944153 all mean 0.6163814663887024
0.05999138206243515 0.059991393238306046
rl training, epoch4, iter0, batch1040/1133, batch loss:0.059991393238306046, Training time:70156.11219906807
batch reward last col mean 0.6226727366447449 first col mean 0.6486583352088928 all mean 0.6257760524749756
0.06372573971748352 0.06372573971748352
rl training, epoch4, iter0, batch1041/1133, batch loss:0.06372573971748352, Training time:70156.47942948341
batch reward last col mean 0.569031834602356 first col mean 0.5715956687927246 all mean 0.5686277747154236
0.05691101774573326 0.056911010295152664
rl training, epoch4, iter0, batch1042/1133, batch loss:0.056911010295152664, Training time:70156.84350562096
batch reward last col mean 0.619942307472229 first col mean 0.620989203453064 all mean 0.6202805042266846
0.06469617038965225 0.06469617038965225
rl training, epoch4, iter0, batch1043/1133, batch loss:0.06469617038965225, Training time:70157.21576619148
batch reward last col mean 0.6124354600906372 first col mean 0.6075741052627563 all mean 0.610831618309021
0.07580467313528061 0.07580466568470001
rl training, epoch4, iter0, batch1044/1133, batch loss:0.07580466568470001, Training time:70157.58349084854
batch reward last col mean 0.5637115836143494 first col mean 0.5822339057922363 all mean 0.566043496131897
0.09201991558074951 0.09201991558074951
rl training, epoch4, iter0, batch1045/1133, batch loss:0.09201991558074951, Training time:70158.08233356476
batch reward last col mean 0.5896034836769104 first col mean 0.572613537311554 all mean 0.5863977074623108
0.06655729562044144 0.06655729562044144
rl training, epoch4, iter0, batch1046/1133, batch loss:0.06655729562044144, Training time:70158.45949554443
batch reward last col mean 0.549567461013794 first col mean 0.5910276174545288 all mean 0.5562187433242798
0.07057005167007446 0.07057004421949387
rl training, epoch4, iter0, batch1047/1133, batch loss:0.07057004421949387, Training time:70158.88565254211
batch reward last col mean 0.6164121627807617 first col mean 0.6041485071182251 all mean 0.6125022768974304
0.08777379244565964 0.08777380734682083
rl training, epoch4, iter0, batch1048/1133, batch loss:0.08777380734682083, Training time:70159.25975680351
batch reward last col mean 0.5740108489990234 first col mean 0.5729635953903198 all mean 0.5735088586807251
0.056655921041965485 0.05665592849254608
rl training, epoch4, iter0, batch1049/1133, batch loss:0.05665592849254608, Training time:70159.62917613983
batch reward last col mean 0.6219348907470703 first col mean 0.6213462352752686 all mean 0.6205348372459412
0.07889145612716675 0.07889143377542496
rl training, epoch4, iter0, batch1050/1133, batch loss:0.07889143377542496, Training time:70160.00475549698
batch reward last col mean 0.6137505769729614 first col mean 0.634411096572876 all mean 0.6194887161254883
0.08777505904436111 0.08777507394552231
rl training, epoch4, iter0, batch1051/1133, batch loss:0.08777507394552231, Training time:70160.3806784153
batch reward last col mean 0.5429706573486328 first col mean 0.5509200692176819 all mean 0.5482557415962219
0.07553961873054504 0.07553961873054504
rl training, epoch4, iter0, batch1052/1133, batch loss:0.07553961873054504, Training time:70160.70913767815
batch reward last col mean 0.5811062455177307 first col mean 0.5843371152877808 all mean 0.5832330584526062
0.062048640102148056 0.062048621475696564
rl training, epoch4, iter0, batch1053/1133, batch loss:0.062048621475696564, Training time:70161.14059519768
batch reward last col mean 0.560009241104126 first col mean 0.5715640783309937 all mean 0.5618176460266113
0.06346334517002106 0.06346334517002106
rl training, epoch4, iter0, batch1054/1133, batch loss:0.06346334517002106, Training time:70161.52275943756
batch reward last col mean 0.5534894466400146 first col mean 0.5362173914909363 all mean 0.5491869449615479
0.10845324397087097 0.10845325142145157
rl training, epoch4, iter0, batch1055/1133, batch loss:0.10845325142145157, Training time:70161.9129486084
batch reward last col mean 0.5719730257987976 first col mean 0.5824846029281616 all mean 0.5759925246238708
0.0557895302772522 0.055789534002542496
rl training, epoch4, iter0, batch1056/1133, batch loss:0.055789534002542496, Training time:70162.29083848
batch reward last col mean 0.5905979871749878 first col mean 0.5867490172386169 all mean 0.5887032747268677
0.05934721603989601 0.05934722349047661
rl training, epoch4, iter0, batch1057/1133, batch loss:0.05934722349047661, Training time:70162.60999631882
batch reward last col mean 0.5581015348434448 first col mean 0.5783441662788391 all mean 0.5607175230979919
0.05789479240775108 0.05789479240775108
rl training, epoch4, iter0, batch1058/1133, batch loss:0.05789479240775108, Training time:70163.04948925972
batch reward last col mean 0.6038783192634583 first col mean 0.5987696647644043 all mean 0.6035272479057312
0.08511915057897568 0.08511914312839508
rl training, epoch4, iter0, batch1059/1133, batch loss:0.08511914312839508, Training time:70163.54113459587
batch reward last col mean 0.6085357666015625 first col mean 0.6250971555709839 all mean 0.6144589185714722
0.07782494276762009 0.07782493531703949
rl training, epoch4, iter0, batch1060/1133, batch loss:0.07782493531703949, Training time:70163.92336201668
batch reward last col mean 0.612106204032898 first col mean 0.608138918876648 all mean 0.6122338771820068
0.07716192305088043 0.07716192305088043
rl training, epoch4, iter0, batch1061/1133, batch loss:0.07716192305088043, Training time:70164.29642701149
batch reward last col mean 0.5760380625724792 first col mean 0.5787396430969238 all mean 0.5768328905105591
0.08690164238214493 0.08690162748098373
rl training, epoch4, iter0, batch1062/1133, batch loss:0.08690162748098373, Training time:70164.67174172401
batch reward last col mean 0.6174157857894897 first col mean 0.631100594997406 all mean 0.6191065311431885
0.06219479814171791 0.06219480559229851
rl training, epoch4, iter0, batch1063/1133, batch loss:0.06219480559229851, Training time:70165.04594159126
batch reward last col mean 0.5548166036605835 first col mean 0.5691155195236206 all mean 0.5567571520805359
0.06534010171890259 0.06534010171890259
rl training, epoch4, iter0, batch1064/1133, batch loss:0.06534010171890259, Training time:70165.49096107483
batch reward last col mean 0.599038302898407 first col mean 0.6020785570144653 all mean 0.5978439450263977
0.1140611544251442 0.1140611320734024
rl training, epoch4, iter0, batch1065/1133, batch loss:0.1140611320734024, Training time:70166.05272054672
batch reward last col mean 0.5861464738845825 first col mean 0.59717857837677 all mean 0.5870853662490845
0.07686761021614075 0.07686760276556015
rl training, epoch4, iter0, batch1066/1133, batch loss:0.07686760276556015, Training time:70166.56583976746
batch reward last col mean 0.5953482389450073 first col mean 0.6155499815940857 all mean 0.5996823310852051
0.06181420758366585 0.06181419640779495
rl training, epoch4, iter0, batch1067/1133, batch loss:0.06181419640779495, Training time:70166.94588518143
batch reward last col mean 0.514538049697876 first col mean 0.5265336632728577 all mean 0.5162649154663086
0.06530749052762985 0.06530749797821045
rl training, epoch4, iter0, batch1068/1133, batch loss:0.06530749797821045, Training time:70167.34946608543
batch reward last col mean 0.5819552540779114 first col mean 0.5704179406166077 all mean 0.5808990597724915
0.04966198280453682 0.049661971628665924
rl training, epoch4, iter0, batch1069/1133, batch loss:0.049661971628665924, Training time:70167.73551678658
batch reward last col mean 0.5998040437698364 first col mean 0.6068428754806519 all mean 0.6037470102310181
0.06478053331375122 0.06478052586317062
rl training, epoch4, iter0, batch1070/1133, batch loss:0.06478052586317062, Training time:70168.06751322746
batch reward last col mean 0.5947802066802979 first col mean 0.5748001337051392 all mean 0.5924142599105835
0.05302184820175171 0.05302184075117111
rl training, epoch4, iter0, batch1071/1133, batch loss:0.05302184075117111, Training time:70168.57960629463
batch reward last col mean 0.5450081825256348 first col mean 0.5417121648788452 all mean 0.5423561334609985
0.06542473286390305 0.06542474776506424
rl training, epoch4, iter0, batch1072/1133, batch loss:0.06542474776506424, Training time:70168.94653630257
batch reward last col mean 0.5418550968170166 first col mean 0.5486345291137695 all mean 0.5436642169952393
0.04992831498384476 0.04992830753326416
rl training, epoch4, iter0, batch1073/1133, batch loss:0.04992830753326416, Training time:70169.30400466919
batch reward last col mean 0.5842748880386353 first col mean 0.5961149334907532 all mean 0.5866459012031555
0.0946599468588829 0.09465993940830231
rl training, epoch4, iter0, batch1074/1133, batch loss:0.09465993940830231, Training time:70169.79998111725
batch reward last col mean 0.5618984699249268 first col mean 0.5614628791809082 all mean 0.5641403198242188
0.05087248980998993 0.05087248980998993
rl training, epoch4, iter0, batch1075/1133, batch loss:0.05087248980998993, Training time:70170.2596783638
batch reward last col mean 0.5583098530769348 first col mean 0.5605109930038452 all mean 0.5573165416717529
0.06623674184083939 0.06623674929141998
rl training, epoch4, iter0, batch1076/1133, batch loss:0.06623674929141998, Training time:70170.62865257263
batch reward last col mean 0.5565567016601562 first col mean 0.565571129322052 all mean 0.5581598281860352
0.06775037199258804 0.06775035709142685
rl training, epoch4, iter0, batch1077/1133, batch loss:0.06775035709142685, Training time:70171.23007750511
batch reward last col mean 0.5611437559127808 first col mean 0.5555909872055054 all mean 0.5601651668548584
0.09342899918556213 0.09342899918556213
rl training, epoch4, iter0, batch1078/1133, batch loss:0.09342899918556213, Training time:70171.68650007248
batch reward last col mean 0.5673116445541382 first col mean 0.5772284269332886 all mean 0.5688315629959106
0.06549490243196487 0.06549489498138428
rl training, epoch4, iter0, batch1079/1133, batch loss:0.06549489498138428, Training time:70172.12647604942
batch reward last col mean 0.556333065032959 first col mean 0.5456627607345581 all mean 0.5531734228134155
0.06843794137239456 0.06843794137239456
rl training, epoch4, iter0, batch1080/1133, batch loss:0.06843794137239456, Training time:70172.52781581879
batch reward last col mean 0.5643398761749268 first col mean 0.581512987613678 all mean 0.5655040144920349
0.04957807436585426 0.04957807809114456
rl training, epoch4, iter0, batch1081/1133, batch loss:0.04957807809114456, Training time:70173.04918766022
batch reward last col mean 0.5644116401672363 first col mean 0.5931881070137024 all mean 0.5656421184539795
0.09451387077569962 0.09451387077569962
rl training, epoch4, iter0, batch1082/1133, batch loss:0.09451387077569962, Training time:70173.4852950573
batch reward last col mean 0.5728706121444702 first col mean 0.5916303396224976 all mean 0.5760629177093506
0.05789671093225479 0.05789671093225479
rl training, epoch4, iter0, batch1083/1133, batch loss:0.05789671093225479, Training time:70173.92744064331
batch reward last col mean 0.6361185312271118 first col mean 0.6274080872535706 all mean 0.6353633999824524
0.05903242155909538 0.05903243646025658
rl training, epoch4, iter0, batch1084/1133, batch loss:0.05903243646025658, Training time:70174.59160065651
batch reward last col mean 0.6213720440864563 first col mean 0.6158105134963989 all mean 0.6189041137695312
0.07296978682279587 0.07296980172395706
rl training, epoch4, iter0, batch1085/1133, batch loss:0.07296980172395706, Training time:70174.99674916267
batch reward last col mean 0.6003768444061279 first col mean 0.6045584678649902 all mean 0.6019573211669922
0.06303990632295609 0.06303990632295609
rl training, epoch4, iter0, batch1086/1133, batch loss:0.06303990632295609, Training time:70175.3720908165
batch reward last col mean 0.5998799204826355 first col mean 0.5977421998977661 all mean 0.5992624759674072
0.09618076682090759 0.09618076682090759
rl training, epoch4, iter0, batch1087/1133, batch loss:0.09618076682090759, Training time:70175.83723115921
batch reward last col mean 0.5989969372749329 first col mean 0.5984968543052673 all mean 0.5997391939163208
0.08242107182741165 0.08242107927799225
rl training, epoch4, iter0, batch1088/1133, batch loss:0.08242107927799225, Training time:70176.30368566513
batch reward last col mean 0.5593177080154419 first col mean 0.5685339570045471 all mean 0.5605844855308533
0.0745602548122406 0.0745602697134018
rl training, epoch4, iter0, batch1089/1133, batch loss:0.0745602697134018, Training time:70176.6219394207
batch reward last col mean 0.6302534341812134 first col mean 0.615397036075592 all mean 0.6294684410095215
0.08317691832780838 0.08317693322896957
rl training, epoch4, iter0, batch1090/1133, batch loss:0.08317693322896957, Training time:70177.03605031967
batch reward last col mean 0.6055636405944824 first col mean 0.6042022705078125 all mean 0.6051738262176514
0.06963318586349487 0.06963317841291428
rl training, epoch4, iter0, batch1091/1133, batch loss:0.06963317841291428, Training time:70177.44375491142
batch reward last col mean 0.5753531455993652 first col mean 0.5763484835624695 all mean 0.578359842300415
0.06867481023073196 0.06867479532957077
rl training, epoch4, iter0, batch1092/1133, batch loss:0.06867479532957077, Training time:70177.82971906662
batch reward last col mean 0.6219472289085388 first col mean 0.6103624105453491 all mean 0.6200308203697205
0.061213668435811996 0.06121367961168289
rl training, epoch4, iter0, batch1093/1133, batch loss:0.06121367961168289, Training time:70178.21695327759
batch reward last col mean 0.6291935443878174 first col mean 0.637769341468811 all mean 0.6299845576286316
0.07374017685651779 0.07374019920825958
rl training, epoch4, iter0, batch1094/1133, batch loss:0.07374019920825958, Training time:70178.58704209328
batch reward last col mean 0.6183983683586121 first col mean 0.6216504573822021 all mean 0.6203833818435669
0.07168153673410416 0.07168154418468475
rl training, epoch4, iter0, batch1095/1133, batch loss:0.07168154418468475, Training time:70178.95802903175
batch reward last col mean 0.6132563352584839 first col mean 0.6164827346801758 all mean 0.6145343780517578
0.0691627487540245 0.06916274130344391
rl training, epoch4, iter0, batch1096/1133, batch loss:0.06916274130344391, Training time:70179.33993625641
batch reward last col mean 0.5905382037162781 first col mean 0.6035475730895996 all mean 0.5944581627845764
0.06567708402872086 0.06567706167697906
rl training, epoch4, iter0, batch1097/1133, batch loss:0.06567706167697906, Training time:70179.71560168266
batch reward last col mean 0.5714191198348999 first col mean 0.5822758078575134 all mean 0.5734673738479614
0.049267470836639404 0.049267467111349106
rl training, epoch4, iter0, batch1098/1133, batch loss:0.049267467111349106, Training time:70180.09161877632
batch reward last col mean 0.6439725160598755 first col mean 0.6220225095748901 all mean 0.6393635272979736
0.05934423953294754 0.05934423208236694
rl training, epoch4, iter0, batch1099/1133, batch loss:0.05934423208236694, Training time:70180.54417347908
batch reward last col mean 0.5911307334899902 first col mean 0.6104193925857544 all mean 0.5932761430740356
0.06151021271944046 0.06151019036769867
rl training, epoch4, iter0, batch1100/1133, batch loss:0.06151019036769867, Training time:70180.92207360268
batch reward last col mean 0.5905171632766724 first col mean 0.5850914716720581 all mean 0.5889337062835693
0.05518735945224762 0.055187348276376724
rl training, epoch4, iter0, batch1101/1133, batch loss:0.055187348276376724, Training time:70181.37703895569
batch reward last col mean 0.5742934942245483 first col mean 0.5906013250350952 all mean 0.577774703502655
0.05484142526984215 0.05484142526984215
rl training, epoch4, iter0, batch1102/1133, batch loss:0.05484142526984215, Training time:70181.75173974037
batch reward last col mean 0.6207582950592041 first col mean 0.6431481242179871 all mean 0.6236873865127563
0.12202169001102448 0.12202166765928268
rl training, epoch4, iter0, batch1103/1133, batch loss:0.12202166765928268, Training time:70182.12775564194
batch reward last col mean 0.5907225012779236 first col mean 0.6294640302658081 all mean 0.5955893993377686
0.06630873680114746 0.06630874425172806
rl training, epoch4, iter0, batch1104/1133, batch loss:0.06630874425172806, Training time:70182.56606173515
batch reward last col mean 0.6039532423019409 first col mean 0.6072405576705933 all mean 0.6059614419937134
0.07481187582015991 0.07481187582015991
rl training, epoch4, iter0, batch1105/1133, batch loss:0.07481187582015991, Training time:70183.07611203194
batch reward last col mean 0.6128281354904175 first col mean 0.6107732653617859 all mean 0.6131302714347839
0.10747745633125305 0.10747744888067245
rl training, epoch4, iter0, batch1106/1133, batch loss:0.10747744888067245, Training time:70183.45901942253
batch reward last col mean 0.6094405055046082 first col mean 0.6238537430763245 all mean 0.6123157143592834
0.05026225000619888 0.05026225000619888
rl training, epoch4, iter0, batch1107/1133, batch loss:0.05026225000619888, Training time:70183.76410722733
batch reward last col mean 0.6025415658950806 first col mean 0.6033424139022827 all mean 0.6040344834327698
0.08401036262512207 0.08401036262512207
rl training, epoch4, iter0, batch1108/1133, batch loss:0.08401036262512207, Training time:70184.1315214634
batch reward last col mean 0.6468843221664429 first col mean 0.6574124693870544 all mean 0.6471147537231445
0.08092551678419113 0.08092552423477173
rl training, epoch4, iter0, batch1109/1133, batch loss:0.08092552423477173, Training time:70184.49838089943
batch reward last col mean 0.597712516784668 first col mean 0.6175409555435181 all mean 0.6023952960968018
0.07201598584651947 0.07201600074768066
rl training, epoch4, iter0, batch1110/1133, batch loss:0.07201600074768066, Training time:70184.87590169907
batch reward last col mean 0.6318628787994385 first col mean 0.6121293306350708 all mean 0.6294192671775818
0.07203513383865356 0.07203514873981476
rl training, epoch4, iter0, batch1111/1133, batch loss:0.07203514873981476, Training time:70185.20347499847
batch reward last col mean 0.5814714431762695 first col mean 0.586460530757904 all mean 0.5855051875114441
0.06107287481427193 0.061072882264852524
rl training, epoch4, iter0, batch1112/1133, batch loss:0.061072882264852524, Training time:70185.55851626396
batch reward last col mean 0.6370386481285095 first col mean 0.647759199142456 all mean 0.6377418637275696
0.05041254684329033 0.05041255056858063
rl training, epoch4, iter0, batch1113/1133, batch loss:0.05041255056858063, Training time:70186.07382917404
batch reward last col mean 0.6223219037055969 first col mean 0.6351792216300964 all mean 0.6258829236030579
0.07292769104242325 0.07292769849300385
rl training, epoch4, iter0, batch1114/1133, batch loss:0.07292769849300385, Training time:70186.40839481354
batch reward last col mean 0.6191264986991882 first col mean 0.6271607875823975 all mean 0.6207364797592163
0.06859617680311203 0.06859617680311203
rl training, epoch4, iter0, batch1115/1133, batch loss:0.06859617680311203, Training time:70186.77406787872
batch reward last col mean 0.6256694793701172 first col mean 0.6173393726348877 all mean 0.6236771941184998
0.07406018674373627 0.07406017929315567
rl training, epoch4, iter0, batch1116/1133, batch loss:0.07406017929315567, Training time:70187.14209580421
batch reward last col mean 0.6173038482666016 first col mean 0.6275980472564697 all mean 0.6187700629234314
0.062334056943655014 0.062334056943655014
rl training, epoch4, iter0, batch1117/1133, batch loss:0.062334056943655014, Training time:70187.50791501999
batch reward last col mean 0.5928027629852295 first col mean 0.5735493898391724 all mean 0.587722897529602
0.04935101419687271 0.04935101419687271
rl training, epoch4, iter0, batch1118/1133, batch loss:0.04935101419687271, Training time:70187.88703584671
batch reward last col mean 0.6144084930419922 first col mean 0.607176661491394 all mean 0.6140998601913452
0.051638126373291016 0.05163811892271042
rl training, epoch4, iter0, batch1119/1133, batch loss:0.05163811892271042, Training time:70188.2659649849
batch reward last col mean 0.6013026237487793 first col mean 0.5879002213478088 all mean 0.598792552947998
0.04931419715285301 0.04931420832872391
rl training, epoch4, iter0, batch1120/1133, batch loss:0.04931420832872391, Training time:70188.63111066818
batch reward last col mean 0.625208854675293 first col mean 0.6426836252212524 all mean 0.6269294619560242
0.0859975591301918 0.0859975814819336
rl training, epoch4, iter0, batch1121/1133, batch loss:0.0859975814819336, Training time:70189.02929973602
batch reward last col mean 0.5882618427276611 first col mean 0.6045433878898621 all mean 0.5902572274208069
0.06174615025520325 0.06174615025520325
rl training, epoch4, iter0, batch1122/1133, batch loss:0.06174615025520325, Training time:70189.29881668091
batch reward last col mean 0.6210195422172546 first col mean 0.6127371191978455 all mean 0.6183648109436035
0.07091674208641052 0.07091675698757172
rl training, epoch4, iter0, batch1123/1133, batch loss:0.07091675698757172, Training time:70189.74334836006
batch reward last col mean 0.5986380577087402 first col mean 0.6201773881912231 all mean 0.60138338804245
0.058315739035606384 0.05831573158502579
rl training, epoch4, iter0, batch1124/1133, batch loss:0.05831573158502579, Training time:70190.16815376282
batch reward last col mean 0.5994923710823059 first col mean 0.5853692293167114 all mean 0.5970126986503601
0.08490432798862457 0.08490431308746338
rl training, epoch4, iter0, batch1125/1133, batch loss:0.08490431308746338, Training time:70190.55849504471
batch reward last col mean 0.626345157623291 first col mean 0.6385898590087891 all mean 0.6280940771102905
0.0664055123925209 0.0664055198431015
rl training, epoch4, iter0, batch1126/1133, batch loss:0.0664055198431015, Training time:70190.95484018326
batch reward last col mean 0.5680522918701172 first col mean 0.5745534300804138 all mean 0.5707373023033142
0.07472359389066696 0.07472357898950577
rl training, epoch4, iter0, batch1127/1133, batch loss:0.07472357898950577, Training time:70191.33460235596
batch reward last col mean 0.6344767808914185 first col mean 0.6324700117111206 all mean 0.6346930861473083
0.07279796153306961 0.07279795408248901
rl training, epoch4, iter0, batch1128/1133, batch loss:0.07279795408248901, Training time:70191.7028169632
batch reward last col mean 0.5536932945251465 first col mean 0.5540810823440552 all mean 0.5518862009048462
0.07607392221689224 0.07607389986515045
rl training, epoch4, iter0, batch1129/1133, batch loss:0.07607389986515045, Training time:70192.0706949234
batch reward last col mean 0.6078558564186096 first col mean 0.607576847076416 all mean 0.608086109161377
0.05687560513615608 0.05687559396028519
rl training, epoch4, iter0, batch1130/1133, batch loss:0.05687559396028519, Training time:70192.4382982254
batch reward last col mean 0.5959922075271606 first col mean 0.591126024723053 all mean 0.594963788986206
0.06668474525213242 0.06668474525213242
rl training, epoch4, iter0, batch1131/1133, batch loss:0.06668474525213242, Training time:70192.84226799011
batch reward last col mean 0.6085279583930969 first col mean 0.5939162373542786 all mean 0.6047238111495972
0.05237000435590744 0.052369993180036545
rl training, epoch4, iter0, batch1132/1133, batch loss:0.052369993180036545, Training time:70193.15652728081
rl training, epoch 4, iter 0, loss:0.16952117195390723, Training time:70193.15669798851 
rl epoch 4, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.3699392800376358 Time: 81.272878408432 s
loss of true 0.14925711979433592 loss of gen 0.0046989870457420915 loss of other 0.21598317342607298 first score 0.6040520071983337
cur_epoch: 1
D Training Loss: 0.35448523714073127 Time: 83.72466516494751 s
loss of true 0.14071705139719692 loss of gen 0.000509845525115354 loss of other 0.2132583401590875 first score 0.00034179916838184
cur_epoch: 2
D Training Loss: 0.3538363876852017 Time: 81.27772092819214 s
loss of true 0.14035526465785683 loss of gen 0.000496826565598965 loss of other 0.21298429658611792 first score 0.00021642624051310122
cur_epoch: 3
D Training Loss: 0.3480536233426613 Time: 81.72891545295715 s
loss of true 0.13804821489216054 loss of gen 0.0004479716895386666 loss of other 0.2095574364526442 first score 0.0013424220960587263
cur_epoch: 4
D Training Loss: 0.34839881267415035 Time: 81.9421546459198 s
loss of true 0.13790928789423507 loss of gen 0.00032198332038492564 loss of other 0.21016754137988333 first score 4.170541069470346e-05
rl epoch 5, begin RL for generator...
batch reward last col mean 0.00038159912219271064 first col mean 0.0002320137427886948 all mean 0.0003008475759997964
0.00017033630865626037 0.00017033630865626037
rl training, epoch5, iter0, batch0/1133, batch loss:0.00017033630865626037, Training time:70603.56381940842
batch reward last col mean 5.991780199110508e-05 first col mean 0.0002255396539112553 all mean 9.297301585320383e-05
6.264686089707538e-05 6.264684634516016e-05
rl training, epoch5, iter0, batch1/1133, batch loss:6.264684634516016e-05, Training time:70603.95897960663
batch reward last col mean 0.0010237892856821418 first col mean 0.00011796915350714698 all mean 0.0005342669319361448
0.001242870232090354 0.0012428701156750321
rl training, epoch5, iter0, batch2/1133, batch loss:0.0012428701156750321, Training time:70604.41806459427
batch reward last col mean 0.006650516763329506 first col mean 0.00011591924703679979 all mean 0.002147088758647442
0.003628799691796303 0.00362880015745759
rl training, epoch5, iter0, batch3/1133, batch loss:0.00362880015745759, Training time:70604.81192040443
batch reward last col mean 7.285500032594427e-05 first col mean 0.00020379263150971383 all mean 0.00016976191545836627
7.437358726747334e-05 7.43736163713038e-05
rl training, epoch5, iter0, batch4/1133, batch loss:7.43736163713038e-05, Training time:70605.28153920174
batch reward last col mean 8.399116632062942e-05 first col mean 0.0001240623532794416 all mean 9.128811507252976e-05
1.5868234186200425e-05 1.5868237824179232e-05
rl training, epoch5, iter0, batch5/1133, batch loss:1.5868237824179232e-05, Training time:70605.713960886
batch reward last col mean 0.0005955219967290759 first col mean 0.0002431972825434059 all mean 0.0009362146956846118
0.004103560000658035 0.004103560000658035
rl training, epoch5, iter0, batch6/1133, batch loss:0.004103560000658035, Training time:70606.27765130997
batch reward last col mean 0.0004638441314455122 first col mean 0.0012553372653201222 all mean 0.00033786913263611495
0.00020819425117224455 0.00020819436758756638
rl training, epoch5, iter0, batch7/1133, batch loss:0.00020819436758756638, Training time:70606.70009589195
batch reward last col mean 0.00015527252980973572 first col mean 0.0004352879768703133 all mean 0.00016915949527174234
0.00010121191735379398 0.00010121188824996352
rl training, epoch5, iter0, batch8/1133, batch loss:0.00010121188824996352, Training time:70607.1197412014
batch reward last col mean 7.746137271169573e-05 first col mean 0.00020305285579524934 all mean 9.158870670944452e-05
8.402700041187927e-05 8.40270149637945e-05
rl training, epoch5, iter0, batch9/1133, batch loss:8.40270149637945e-05, Training time:70607.53099966049
batch reward last col mean 8.621130837127566e-05 first col mean 9.717963985167444e-05 all mean 8.885113493306562e-05
2.521626083762385e-05 2.5216268113581464e-05
rl training, epoch5, iter0, batch10/1133, batch loss:2.5216268113581464e-05, Training time:70607.92930793762
batch reward last col mean 0.000559953332412988 first col mean 0.00010000565816881135 all mean 0.0003337800153531134
0.0005112990038469434 0.0005112990038469434
rl training, epoch5, iter0, batch11/1133, batch loss:0.0005112990038469434, Training time:70608.26121544838
batch reward last col mean 7.857047603465617e-05 first col mean 6.388206384144723e-05 all mean 0.00039030067273415625
3.697979627759196e-05 3.697998545248993e-05
rl training, epoch5, iter0, batch12/1133, batch loss:3.697998545248993e-05, Training time:70608.67661833763
batch reward last col mean 0.0024262689985334873 first col mean 0.0002697568270377815 all mean 0.002275921171531081
0.0028416013810783625 0.002841601148247719
rl training, epoch5, iter0, batch13/1133, batch loss:0.002841601148247719, Training time:70609.15719532967
batch reward last col mean 0.0003114714636467397 first col mean 0.00015722094394732267 all mean 0.0004032942233607173
0.00024202877830248326 0.00024202876375056803
rl training, epoch5, iter0, batch14/1133, batch loss:0.00024202876375056803, Training time:70609.63304281235
batch reward last col mean 8.05851086624898e-05 first col mean 0.0005082488642074168 all mean 0.00017794209998100996
0.0005198060534894466 0.0005198061699047685
rl training, epoch5, iter0, batch15/1133, batch loss:0.0005198061699047685, Training time:70610.02012372017
batch reward last col mean 0.0001884231751319021 first col mean 9.074651461560279e-05 all mean 0.00018398318206891418
0.0001643504510866478 0.00016435048019047827
rl training, epoch5, iter0, batch16/1133, batch loss:0.00016435048019047827, Training time:70610.46772646904
batch reward last col mean 0.00011879206431331113 first col mean 0.00015391568013001233 all mean 0.00012426284956745803
0.0002782914962153882 0.0002782914962153882
rl training, epoch5, iter0, batch17/1133, batch loss:0.0002782914962153882, Training time:70610.87059950829
batch reward last col mean 0.00020973585196770728 first col mean 0.00015823860303498805 all mean 0.00029063105466775596
0.00032819859916344285 0.00032819859916344285
rl training, epoch5, iter0, batch18/1133, batch loss:0.00032819859916344285, Training time:70611.32858347893
batch reward last col mean 5.638327274937183e-05 first col mean 0.00010701981227612123 all mean 6.40802172711119e-05
7.730709330644459e-05 7.730708603048697e-05
rl training, epoch5, iter0, batch19/1133, batch loss:7.730708603048697e-05, Training time:70611.70334601402
batch reward last col mean 0.00019980607612524182 first col mean 0.0014612078666687012 all mean 0.00033573713153600693
0.0003315498470328748 0.0003315498470328748
rl training, epoch5, iter0, batch20/1133, batch loss:0.0003315498470328748, Training time:70612.09563708305
batch reward last col mean 8.030181197682396e-05 first col mean 0.00015082527534104884 all mean 9.24493870115839e-05
8.579905261285603e-05 8.579905261285603e-05
rl training, epoch5, iter0, batch21/1133, batch loss:8.579905261285603e-05, Training time:70612.47467041016
batch reward last col mean 5.939586117165163e-05 first col mean 0.00014519762771669775 all mean 9.939695883076638e-05
0.00021515176922548562 0.0002151517546735704
rl training, epoch5, iter0, batch22/1133, batch loss:0.0002151517546735704, Training time:70612.85070538521
batch reward last col mean 0.00015247058763634413 first col mean 0.0004970566369593143 all mean 0.00024237652542069554
0.0002511052298359573 0.00025110525893978775
rl training, epoch5, iter0, batch23/1133, batch loss:0.00025110525893978775, Training time:70613.23111867905
batch reward last col mean 0.00018626084784045815 first col mean 0.0001859780022641644 all mean 0.00017823881353251636
7.65904042054899e-05 7.659041875740513e-05
rl training, epoch5, iter0, batch24/1133, batch loss:7.659041875740513e-05, Training time:70613.65744757652
batch reward last col mean 0.00023874688486102968 first col mean 7.234346412587911e-05 all mean 0.00022501542116515338
0.0007386457291431725 0.0007386457291431725
rl training, epoch5, iter0, batch25/1133, batch loss:0.0007386457291431725, Training time:70614.07436275482
batch reward last col mean 0.00014506408479064703 first col mean 0.00014623202150687575 all mean 0.00014428138092625886
3.7064175558043644e-05 3.7064161006128415e-05
rl training, epoch5, iter0, batch26/1133, batch loss:3.7064161006128415e-05, Training time:70614.53041028976
batch reward last col mean 6.598355685127899e-05 first col mean 8.031827019294724e-05 all mean 0.0001889215491246432
0.002986371284350753 0.002986371284350753
rl training, epoch5, iter0, batch27/1133, batch loss:0.002986371284350753, Training time:70614.91540789604
batch reward last col mean 0.00016746713663451374 first col mean 0.00035381686757318676 all mean 0.00020238419529050589
0.0010851898696273565 0.0010851897532120347
rl training, epoch5, iter0, batch28/1133, batch loss:0.0010851897532120347, Training time:70615.33937215805
batch reward last col mean 7.283707964234054e-05 first col mean 6.380502600222826e-05 all mean 8.659131708554924e-05
7.040509808575734e-05 7.040510536171496e-05
rl training, epoch5, iter0, batch29/1133, batch loss:7.040510536171496e-05, Training time:70615.76666855812
batch reward last col mean 0.00027431276976130903 first col mean 0.000481443596072495 all mean 0.00028107219259254634
0.00011111873027402908 0.00011111873027402908
rl training, epoch5, iter0, batch30/1133, batch loss:0.00011111873027402908, Training time:70616.29044985771
batch reward last col mean 9.685180702945217e-05 first col mean 0.00019767633057199419 all mean 0.00015255407197400928
4.5723911171080545e-05 4.572391480905935e-05
rl training, epoch5, iter0, batch31/1133, batch loss:4.572391480905935e-05, Training time:70616.67119002342
batch reward last col mean 0.002109881956130266 first col mean 0.0001011281565297395 all mean 0.0013844065833836794
0.0009569277754053473 0.0009569277754053473
rl training, epoch5, iter0, batch32/1133, batch loss:0.0009569277754053473, Training time:70617.08801293373
batch reward last col mean 0.0019702145364135504 first col mean 0.000631640141364187 all mean 0.0012089178198948503
0.0006350018666125834 0.0006350019830279052
rl training, epoch5, iter0, batch33/1133, batch loss:0.0006350019830279052, Training time:70617.50455355644
batch reward last col mean 0.00020001528901048005 first col mean 0.00014591761282645166 all mean 0.00021385778381954879
8.67671551532112e-05 8.676716242916882e-05
rl training, epoch5, iter0, batch34/1133, batch loss:8.676716242916882e-05, Training time:70617.9224767685
batch reward last col mean 6.977956218179315e-05 first col mean 9.516578575130552e-05 all mean 0.00010575297346804291
0.0006512110703624785 0.0006512110703624785
rl training, epoch5, iter0, batch35/1133, batch loss:0.0006512110703624785, Training time:70618.60627174377
batch reward last col mean 0.00012739050725940615 first col mean 7.542328967247158e-05 all mean 0.0005019493401050568
0.001495758187957108 0.0014957580715417862
rl training, epoch5, iter0, batch36/1133, batch loss:0.0014957580715417862, Training time:70618.99542927742
batch reward last col mean 7.837455632397905e-05 first col mean 0.0003259853401686996 all mean 0.0001452525466447696
1.7639245925238356e-05 1.7639231373323128e-05
rl training, epoch5, iter0, batch37/1133, batch loss:1.7639231373323128e-05, Training time:70619.37853384018
batch reward last col mean 8.722493657842278e-05 first col mean 0.00023207235790323466 all mean 0.00013436470180749893
0.0010479137999936938 0.0010479137999936938
rl training, epoch5, iter0, batch38/1133, batch loss:0.0010479137999936938, Training time:70619.75913476944
batch reward last col mean 0.0003800059203058481 first col mean 0.00039433425990864635 all mean 0.0003066303033847362
0.00038494684849865735 0.0003849468193948269
rl training, epoch5, iter0, batch39/1133, batch loss:0.0003849468193948269, Training time:70620.19837117195
batch reward last col mean 0.0003546725201886147 first col mean 0.00017403543461114168 all mean 0.0003502622712403536
0.000632533454336226 0.000632533454336226
rl training, epoch5, iter0, batch40/1133, batch loss:0.000632533454336226, Training time:70620.65133571625
batch reward last col mean 0.0004045048845000565 first col mean 0.0001783564075594768 all mean 0.00034220749512314796
0.0002427626313874498 0.00024276261683553457
rl training, epoch5, iter0, batch41/1133, batch loss:0.00024276261683553457, Training time:70621.191239357
batch reward last col mean 0.0008436940261162817 first col mean 0.00012847111793234944 all mean 0.0005069575854577124
0.0005617410643026233 0.0005617410060949624
rl training, epoch5, iter0, batch42/1133, batch loss:0.0005617410060949624, Training time:70621.6963057518
batch reward last col mean 9.628449333831668e-05 first col mean 0.0004435956652741879 all mean 0.00012764013081323355
4.034983066958375e-05 4.034983794554137e-05
rl training, epoch5, iter0, batch43/1133, batch loss:4.034983794554137e-05, Training time:70622.11585974693
batch reward last col mean 9.621615026844665e-05 first col mean 7.397901936201379e-05 all mean 0.00024696707259863615
0.00023916921054478735 0.00023916931240819395
rl training, epoch5, iter0, batch44/1133, batch loss:0.00023916931240819395, Training time:70622.5874402523
batch reward last col mean 0.0004781861789524555 first col mean 9.083754412131384e-05 all mean 0.00031912693521007895
0.0003252402530051768 0.0003252403694204986
rl training, epoch5, iter0, batch45/1133, batch loss:0.0003252403694204986, Training time:70623.06179952621
batch reward last col mean 4.6655943151563406e-05 first col mean 7.780420855851844e-05 all mean 5.228611553320661e-05
2.099980520142708e-05 2.0999801563448273e-05
rl training, epoch5, iter0, batch46/1133, batch loss:2.0999801563448273e-05, Training time:70623.55622029305
batch reward last col mean 0.00011994203669019043 first col mean 0.0007555790361948311 all mean 0.00016336618864443153
0.00010404169734101743 0.00010404166823718697
rl training, epoch5, iter0, batch47/1133, batch loss:0.00010404166823718697, Training time:70624.01350784302
batch reward last col mean 0.001429594587534666 first col mean 0.00014829458086751401 all mean 0.0013418837916105986
0.00198727915994823 0.001987278927117586
rl training, epoch5, iter0, batch48/1133, batch loss:0.001987278927117586, Training time:70624.54340672493
batch reward last col mean 0.00017210067017003894 first col mean 9.976900764741004e-05 all mean 0.0001563169207656756
6.130670954007655e-05 6.130672409199178e-05
rl training, epoch5, iter0, batch49/1133, batch loss:6.130672409199178e-05, Training time:70624.92014217377
batch reward last col mean 9.928841609507799e-05 first col mean 0.0001390450488543138 all mean 0.00010732592636486515
3.791967174038291e-05 3.79196681024041e-05
rl training, epoch5, iter0, batch50/1133, batch loss:3.79196681024041e-05, Training time:70625.41024923325
batch reward last col mean 0.0005113753140904009 first col mean 0.00015125126810744405 all mean 0.0004888911498710513
0.0005391760496422648 0.0005391761078499258
rl training, epoch5, iter0, batch51/1133, batch loss:0.0005391761078499258, Training time:70625.93329143524
batch reward last col mean 9.697234054328874e-05 first col mean 7.006086525507271e-05 all mean 0.00010001740156440064
6.728699372615665e-05 6.728697189828381e-05
rl training, epoch5, iter0, batch52/1133, batch loss:6.728697189828381e-05, Training time:70626.50643396378
batch reward last col mean 0.0003966609947383404 first col mean 0.00031332013895735145 all mean 0.00039100213325582445
0.000538469641469419 0.000538469641469419
rl training, epoch5, iter0, batch53/1133, batch loss:0.000538469641469419, Training time:70626.97868180275
batch reward last col mean 0.0001974734477698803 first col mean 0.0001475615135859698 all mean 0.00017033831682056189
0.00018697945051826537 0.0001869794214144349
rl training, epoch5, iter0, batch54/1133, batch loss:0.0001869794214144349, Training time:70627.39547228813
batch reward last col mean 0.00011430545418988913 first col mean 0.00015071828966028988 all mean 0.00012177198368590325
0.00012189327389933169 0.00012189325934741646
rl training, epoch5, iter0, batch55/1133, batch loss:0.00012189325934741646, Training time:70627.78789329529
batch reward last col mean 0.00026809476548805833 first col mean 7.454937440343201e-05 all mean 0.0003799143014475703
0.0003148860123474151 0.00031488604145124555
rl training, epoch5, iter0, batch56/1133, batch loss:0.00031488604145124555, Training time:70628.19962716103
batch reward last col mean 5.807576235383749e-05 first col mean 0.00021142263722140342 all mean 7.379780436167493e-05
1.495275955676334e-05 1.4952746823837515e-05
rl training, epoch5, iter0, batch57/1133, batch loss:1.4952746823837515e-05, Training time:70628.58329963684
batch reward last col mean 0.00038552843034267426 first col mean 0.0001413951104041189 all mean 0.00038924458203837276
0.0004772197862621397 0.0004772196989506483
rl training, epoch5, iter0, batch58/1133, batch loss:0.0004772196989506483, Training time:70628.95465040207
batch reward last col mean 9.262793173547834e-05 first col mean 0.0004029441624879837 all mean 0.00017643238243181258
0.0002649393572937697 0.0002649393863976002
rl training, epoch5, iter0, batch59/1133, batch loss:0.0002649393863976002, Training time:70629.2653734684
batch reward last col mean 9.664244862506166e-05 first col mean 0.00018313180771656334 all mean 0.00011940889817196876
2.9114255085005425e-05 2.9114235076121986e-05
rl training, epoch5, iter0, batch60/1133, batch loss:2.9114235076121986e-05, Training time:70629.77433681488
batch reward last col mean 0.0004083926905877888 first col mean 9.701406816020608e-05 all mean 0.0004413342976476997
0.0013163890689611435 0.0013163890689611435
rl training, epoch5, iter0, batch61/1133, batch loss:0.0013163890689611435, Training time:70630.16417384148
batch reward last col mean 0.00021855399245396256 first col mean 0.00013967420090921223 all mean 0.00018020319112110883
4.256455576978624e-05 4.256456668372266e-05
rl training, epoch5, iter0, batch62/1133, batch loss:4.256456668372266e-05, Training time:70630.5760884285
batch reward last col mean 0.0002883395936805755 first col mean 6.451787339756265e-05 all mean 0.0002878930536098778
0.0005154031096026301 0.0005154031096026301
rl training, epoch5, iter0, batch63/1133, batch loss:0.0005154031096026301, Training time:70630.95297718048
batch reward last col mean 5.0437778554623947e-05 first col mean 0.0005248197121545672 all mean 0.00010939541971310973
3.1421997846337035e-05 3.142202695016749e-05
rl training, epoch5, iter0, batch64/1133, batch loss:3.142202695016749e-05, Training time:70631.43521475792
batch reward last col mean 8.837741188472137e-05 first col mean 0.00019528530538082123 all mean 0.0002066882880171761
1.1679669114528224e-05 1.167962091130903e-05
rl training, epoch5, iter0, batch65/1133, batch loss:1.167962091130903e-05, Training time:70631.82302594185
batch reward last col mean 0.000220817732042633 first col mean 0.0004380489990580827 all mean 0.0002131839719368145
0.00014525432197842747 0.0001452543365303427
rl training, epoch5, iter0, batch66/1133, batch loss:0.0001452543365303427, Training time:70632.20426106453
batch reward last col mean 9.667986159911379e-05 first col mean 0.0004341239109635353 all mean 0.00012438905832823366
0.00016861900803633034 0.00016861899348441511
rl training, epoch5, iter0, batch67/1133, batch loss:0.00016861899348441511, Training time:70632.66271328926
batch reward last col mean 0.0015316612552851439 first col mean 0.0003087235090788454 all mean 0.0009226234978996217
0.0017292231786996126 0.0017292230622842908
rl training, epoch5, iter0, batch68/1133, batch loss:0.0017292230622842908, Training time:70633.11531639099
batch reward last col mean 0.00014906049182172865 first col mean 0.00016572611639276147 all mean 0.00018015006207861006
9.386851888848469e-05 9.386851888848469e-05
rl training, epoch5, iter0, batch69/1133, batch loss:9.386851888848469e-05, Training time:70633.47738432884
batch reward last col mean 0.0003380115667823702 first col mean 9.254840551875532e-05 all mean 0.00033024634467437863
0.0003377405519131571 0.0003377405519131571
rl training, epoch5, iter0, batch70/1133, batch loss:0.0003377405519131571, Training time:70633.85182976723
batch reward last col mean 0.0004375628777779639 first col mean 0.0003911864187102765 all mean 0.00045823215623386204
0.0006562901544384658 0.0006562901544384658
rl training, epoch5, iter0, batch71/1133, batch loss:0.0006562901544384658, Training time:70634.33838129044
batch reward last col mean 0.0008165303152054548 first col mean 0.00017283885972574353 all mean 0.0007122638635337353
0.0008717709570191801 0.0008717709570191801
rl training, epoch5, iter0, batch72/1133, batch loss:0.0008717709570191801, Training time:70634.70381450653
batch reward last col mean 0.0003767846501432359 first col mean 6.142970232758671e-05 all mean 0.0002942267747130245
0.0004216500383336097 0.0004216499801259488
rl training, epoch5, iter0, batch73/1133, batch loss:0.0004216499801259488, Training time:70635.20499253273
batch reward last col mean 0.00017373445734847337 first col mean 0.00020387314725667238 all mean 0.00016623179544694722
0.00010818697774084285 0.00010818699229275808
rl training, epoch5, iter0, batch74/1133, batch loss:0.00010818699229275808, Training time:70635.65974116325
batch reward last col mean 0.0013305948814377189 first col mean 0.00013469105761032552 all mean 0.0010861805640161037
0.0011107074096798897 0.0011107075260952115
rl training, epoch5, iter0, batch75/1133, batch loss:0.0011107075260952115, Training time:70636.16577529907
batch reward last col mean 0.00029421685030683875 first col mean 0.0006250679143704474 all mean 0.0003195214958395809
0.00035307250800542533 0.0003530724789015949
rl training, epoch5, iter0, batch76/1133, batch loss:0.0003530724789015949, Training time:70636.55080389977
batch reward last col mean 7.004709186730906e-05 first col mean 0.0001322870230069384 all mean 9.519197919871658e-05
5.060174225945957e-05 5.060174225945957e-05
rl training, epoch5, iter0, batch77/1133, batch loss:5.060174225945957e-05, Training time:70636.92723321915
batch reward last col mean 6.753185152774677e-05 first col mean 0.00039899139665067196 all mean 0.00011105316661996767
3.176293830620125e-05 3.176289101247676e-05
rl training, epoch5, iter0, batch78/1133, batch loss:3.176289101247676e-05, Training time:70637.3282213211
batch reward last col mean 9.305045387009159e-05 first col mean 8.594442624598742e-05 all mean 0.00022577149502467364
2.0930277969455346e-05 2.0930430764565244e-05
rl training, epoch5, iter0, batch79/1133, batch loss:2.0930430764565244e-05, Training time:70637.69509482384
batch reward last col mean 8.609849464846775e-05 first col mean 0.00015723309479653835 all mean 9.778394451132044e-05
1.3380077689362224e-05 1.3380081327341031e-05
rl training, epoch5, iter0, batch80/1133, batch loss:1.3380081327341031e-05, Training time:70638.07431483269
batch reward last col mean 0.0004341542371548712 first col mean 0.0005789154674857855 all mean 0.0005729817203246057
0.0004381963808555156 0.0004381963808555156
rl training, epoch5, iter0, batch81/1133, batch loss:0.0004381963808555156, Training time:70638.50536847115
batch reward last col mean 0.0010391700780019164 first col mean 0.0005135838291607797 all mean 0.000611583876889199
0.00058371527120471 0.0005837153294123709
rl training, epoch5, iter0, batch82/1133, batch loss:0.0005837153294123709, Training time:70638.91684651375
batch reward last col mean 0.0010040344204753637 first col mean 0.0006211489671841264 all mean 0.0010463622165843844
0.0006523478659801185 0.0006523478659801185
rl training, epoch5, iter0, batch83/1133, batch loss:0.0006523478659801185, Training time:70639.47647857666
batch reward last col mean 0.00012922286987304688 first col mean 0.0006127753877080977 all mean 0.00018014304805547
0.0004569987650029361 0.0004569987650029361
rl training, epoch5, iter0, batch84/1133, batch loss:0.0004569987650029361, Training time:70639.8809337616
batch reward last col mean 0.0019197764340788126 first col mean 0.00029656931292265654 all mean 0.0015178029425442219
0.0015797707019373775 0.0015797702362760901
rl training, epoch5, iter0, batch85/1133, batch loss:0.0015797702362760901, Training time:70640.25514221191
batch reward last col mean 0.0002615868579596281 first col mean 0.0003713221522048116 all mean 0.00028111645951867104
3.98900629079435e-05 3.989006654592231e-05
rl training, epoch5, iter0, batch86/1133, batch loss:3.989006654592231e-05, Training time:70640.69290828705
batch reward last col mean 0.0006409742636606097 first col mean 7.958009518915787e-05 all mean 0.000568767951335758
0.0007660547271370888 0.0007660547271370888
rl training, epoch5, iter0, batch87/1133, batch loss:0.0007660547271370888, Training time:70641.05391550064
batch reward last col mean 0.00015258781786542386 first col mean 0.0002109388733515516 all mean 0.00018309186270926148
0.00012728504952974617 0.00012728503497783095
rl training, epoch5, iter0, batch88/1133, batch loss:0.00012728503497783095, Training time:70641.46076655388
batch reward last col mean 0.00016933903680182993 first col mean 0.0004996605566702783 all mean 0.00017436439520679414
0.00011123668809887022 0.00011123670265078545
rl training, epoch5, iter0, batch89/1133, batch loss:0.00011123670265078545, Training time:70641.82309794426
batch reward last col mean 7.828464731574059e-05 first col mean 0.00014881475362926722 all mean 0.00013513193698599935
0.00028130790451541543 0.000281307875411585
rl training, epoch5, iter0, batch90/1133, batch loss:0.000281307875411585, Training time:70642.23579525948
batch reward last col mean 0.0028215579222887754 first col mean 9.26128268474713e-05 all mean 0.0024808302987366915
0.0009486469207331538 0.0009486469207331538
rl training, epoch5, iter0, batch91/1133, batch loss:0.0009486469207331538, Training time:70642.6316781044
batch reward last col mean 0.0007138825603760779 first col mean 0.00031483531347475946 all mean 0.0006777998059988022
0.0008386842673644423 0.0008386843255721033
rl training, epoch5, iter0, batch92/1133, batch loss:0.0008386843255721033, Training time:70643.0037176609
batch reward last col mean 0.000870322750415653 first col mean 0.0001806811342248693 all mean 0.0008828322752378881
0.0015131955733522773 0.0015131955733522773
rl training, epoch5, iter0, batch93/1133, batch loss:0.0015131955733522773, Training time:70643.50619459152
batch reward last col mean 0.00046665495028719306 first col mean 9.195030725095421e-05 all mean 0.000340317958034575
0.0004968731664121151 0.0004968731664121151
rl training, epoch5, iter0, batch94/1133, batch loss:0.0004968731664121151, Training time:70643.91314935684
batch reward last col mean 0.0005615174886770546 first col mean 0.0001356635766569525 all mean 0.0003164100053254515
0.0004217248933855444 0.0004217249224893749
rl training, epoch5, iter0, batch95/1133, batch loss:0.0004217249224893749, Training time:70644.25370240211
batch reward last col mean 0.0004984688712283969 first col mean 0.00011568027548491955 all mean 0.0007545326370745897
0.0028101415373384953 0.002810141071677208
rl training, epoch5, iter0, batch96/1133, batch loss:0.002810141071677208, Training time:70644.63181471825
batch reward last col mean 0.002637172117829323 first col mean 0.00028778554406017065 all mean 0.0015329349553212523
0.0011697662994265556 0.0011697664158418775
rl training, epoch5, iter0, batch97/1133, batch loss:0.0011697664158418775, Training time:70645.08674669266
batch reward last col mean 0.0006347012822516263 first col mean 0.00011613804963417351 all mean 0.000598392856772989
0.0004169331514276564 0.0004169332387391478
rl training, epoch5, iter0, batch98/1133, batch loss:0.0004169332387391478, Training time:70645.50285077095
batch reward last col mean 0.001285951933823526 first col mean 0.00028880659374408424 all mean 0.0011310370173305273
0.0006012258236296475 0.0006012261146679521
rl training, epoch5, iter0, batch99/1133, batch loss:0.0006012261146679521, Training time:70645.8867418766
batch reward last col mean 0.0001161969848908484 first col mean 0.0003360327973496169 all mean 0.00011425597040215507
0.00012226052058394998 0.00012226052058394998
rl training, epoch5, iter0, batch100/1133, batch loss:0.00012226052058394998, Training time:70646.4453086853
batch reward last col mean 0.00016197538934648037 first col mean 0.00018855078087653965 all mean 0.0001492881856393069
7.912488945294172e-05 7.912488945294172e-05
rl training, epoch5, iter0, batch101/1133, batch loss:7.912488945294172e-05, Training time:70646.82561540604
batch reward last col mean 0.00011616932897595689 first col mean 0.00010302948794560507 all mean 0.00015576359874103218
6.105944339651614e-05 6.105945794843137e-05
rl training, epoch5, iter0, batch102/1133, batch loss:6.105945794843137e-05, Training time:70647.19777750969
batch reward last col mean 0.00017804188246373087 first col mean 0.00021704984828829765 all mean 0.0001732835080474615
0.00022141150839161128 0.00022141150839161128
rl training, epoch5, iter0, batch103/1133, batch loss:0.00022141150839161128, Training time:70647.75168657303
batch reward last col mean 0.00023321043408941478 first col mean 0.00019103585509583354 all mean 0.00021746166748926044
0.0001644356088945642 0.0001644356088945642
rl training, epoch5, iter0, batch104/1133, batch loss:0.0001644356088945642, Training time:70648.28684401512
batch reward last col mean 0.00026556383818387985 first col mean 0.0002731073764152825 all mean 0.0002741689095273614
0.00016275672533083707 0.00016275671077892184
rl training, epoch5, iter0, batch105/1133, batch loss:0.00016275671077892184, Training time:70648.79032897949
batch reward last col mean 0.00013026403030380607 first col mean 0.0003138722386211157 all mean 0.0002339763450436294
0.0009274106123484671 0.0009274105541408062
rl training, epoch5, iter0, batch106/1133, batch loss:0.0009274105541408062, Training time:70649.17787146568
batch reward last col mean 0.00028974772430956364 first col mean 0.00012533128028735518 all mean 0.0003579410840757191
0.001049985527060926 0.0010499852942302823
rl training, epoch5, iter0, batch107/1133, batch loss:0.0010499852942302823, Training time:70649.59381484985
batch reward last col mean 0.0001345966593362391 first col mean 0.0014338818145915866 all mean 0.000269537849817425
0.0007133347098715603 0.0007133347680792212
rl training, epoch5, iter0, batch108/1133, batch loss:0.0007133347680792212, Training time:70649.96636581421
batch reward last col mean 0.0003783768624998629 first col mean 0.0002411610767012462 all mean 0.0003513947012834251
0.00028938843752257526 0.00028938837931491435
rl training, epoch5, iter0, batch109/1133, batch loss:0.00028938837931491435, Training time:70650.33376288414
batch reward last col mean 0.0006853710510767996 first col mean 0.0001383390772389248 all mean 0.0005874061607755721
0.0033861277624964714 0.0033861277624964714
rl training, epoch5, iter0, batch110/1133, batch loss:0.0033861277624964714, Training time:70650.69828391075
batch reward last col mean 7.234721124405041e-05 first col mean 0.001630885642953217 all mean 0.00022009070380590856
0.00025077874306589365 0.0002507787721697241
rl training, epoch5, iter0, batch111/1133, batch loss:0.0002507787721697241, Training time:70651.07011938095
batch reward last col mean 0.00015844980953261256 first col mean 0.0002753135922830552 all mean 0.00018042053852695972
0.00011454829655122012 0.00011454828199930489
rl training, epoch5, iter0, batch112/1133, batch loss:0.00011454828199930489, Training time:70651.40828180313
batch reward last col mean 0.0008608813514001667 first col mean 6.0344053053995594e-05 all mean 0.0006145850638858974
0.0006662550149485469 0.0006662550149485469
rl training, epoch5, iter0, batch113/1133, batch loss:0.0006662550149485469, Training time:70651.9395506382
batch reward last col mean 0.0002273903228342533 first col mean 0.00029271148378029466 all mean 0.00019365554908290505
0.00020777835743501782 0.00020777835743501782
rl training, epoch5, iter0, batch114/1133, batch loss:0.00020777835743501782, Training time:70652.26484537125
batch reward last col mean 0.002755555557087064 first col mean 0.00023174725356511772 all mean 0.001696685329079628
0.0035979007370769978 0.0035979002714157104
rl training, epoch5, iter0, batch115/1133, batch loss:0.0035979002714157104, Training time:70652.75114893913
batch reward last col mean 0.000242045265622437 first col mean 0.00023345398949459195 all mean 0.0004587068106047809
0.0023159408010542393 0.0023159408010542393
rl training, epoch5, iter0, batch116/1133, batch loss:0.0023159408010542393, Training time:70653.29375648499
batch reward last col mean 0.0014097895473241806 first col mean 0.0001873884757515043 all mean 0.0011507095769047737
0.0011179134016856551 0.0011179132852703333
rl training, epoch5, iter0, batch117/1133, batch loss:0.0011179132852703333, Training time:70653.70303487778
batch reward last col mean 0.00013414864952210337 first col mean 0.0009523965418338776 all mean 0.0003357806126587093
9.067526843864471e-05 9.067522478289902e-05
rl training, epoch5, iter0, batch118/1133, batch loss:9.067522478289902e-05, Training time:70654.0818927288
batch reward last col mean 0.00013896272866986692 first col mean 0.00016170569870155305 all mean 0.0001452032447559759
4.919202547171153e-05 4.919201819575392e-05
rl training, epoch5, iter0, batch119/1133, batch loss:4.919201819575392e-05, Training time:70654.5620341301
batch reward last col mean 0.001101887901313603 first col mean 0.00013433759158942848 all mean 0.0010281284339725971
0.0006701497477479279 0.0006701495731249452
rl training, epoch5, iter0, batch120/1133, batch loss:0.0006701495731249452, Training time:70655.03338551521
batch reward last col mean 0.00011370350694051012 first col mean 0.0004928832640871406 all mean 0.00018289015861228108
5.115862950333394e-05 5.115857857163064e-05
rl training, epoch5, iter0, batch121/1133, batch loss:5.115857857163064e-05, Training time:70655.41808438301
batch reward last col mean 0.0006331781623885036 first col mean 0.001500245532952249 all mean 0.000532869657035917
0.0005720094195567071 0.000572009535972029
rl training, epoch5, iter0, batch122/1133, batch loss:0.000572009535972029, Training time:70655.81260299683
batch reward last col mean 0.0008536461973562837 first col mean 0.0005937593523412943 all mean 0.0007138738292269409
0.0007380187162198126 0.0007380185998044908
rl training, epoch5, iter0, batch123/1133, batch loss:0.0007380185998044908, Training time:70656.20351672173
batch reward last col mean 0.00026960906689055264 first col mean 0.0013566979905590415 all mean 0.00041466252878308296
0.000639297824818641 0.000639297824818641
rl training, epoch5, iter0, batch124/1133, batch loss:0.000639297824818641, Training time:70656.55014514923
batch reward last col mean 0.0011676419526338577 first col mean 0.00021098038996569812 all mean 0.0008619363070465624
0.007481932174414396 0.007481932174414396
rl training, epoch5, iter0, batch125/1133, batch loss:0.007481932174414396, Training time:70656.99346590042
batch reward last col mean 9.767559822648764e-05 first col mean 8.924487337935716e-05 all mean 9.806333400774747e-05
3.625600947998464e-05 3.625600220402703e-05
rl training, epoch5, iter0, batch126/1133, batch loss:3.625600220402703e-05, Training time:70657.43772649765
batch reward last col mean 0.0003796919190790504 first col mean 0.00018205586820840836 all mean 0.0003299795789644122
0.00025540534988977015 0.00025540534988977015
rl training, epoch5, iter0, batch127/1133, batch loss:0.00025540534988977015, Training time:70657.8141348362
batch reward last col mean 0.0002321369684068486 first col mean 0.00014065703726373613 all mean 0.00018310529412701726
0.00018319500668440014 0.0001831949921324849
rl training, epoch5, iter0, batch128/1133, batch loss:0.0001831949921324849, Training time:70658.4319987297
batch reward last col mean 0.00014177408593241125 first col mean 0.0003635657485574484 all mean 0.00016172109462786466
7.736135739833117e-05 7.736134284641594e-05
rl training, epoch5, iter0, batch129/1133, batch loss:7.736134284641594e-05, Training time:70658.86867880821
batch reward last col mean 9.541808685753495e-05 first col mean 0.0003211299772374332 all mean 0.00019051163690164685
0.0001610737235751003 0.000161073767230846
rl training, epoch5, iter0, batch130/1133, batch loss:0.000161073767230846, Training time:70659.46576523781
batch reward last col mean 0.00038921801024116576 first col mean 0.0002127384941559285 all mean 0.0004357513098511845
0.00014420248044189066 0.00014420232037082314
rl training, epoch5, iter0, batch131/1133, batch loss:0.00014420232037082314, Training time:70659.90150237083
batch reward last col mean 9.08019719645381e-05 first col mean 9.786659211385995e-05 all mean 9.021699952427298e-05
3.2598669349681586e-05 3.2598669349681586e-05
rl training, epoch5, iter0, batch132/1133, batch loss:3.2598669349681586e-05, Training time:70660.36636042595
batch reward last col mean 0.00041507824789732695 first col mean 0.00027076088008470833 all mean 0.00033282299409620464
0.0003048939979635179 0.00030489391065202653
rl training, epoch5, iter0, batch133/1133, batch loss:0.00030489391065202653, Training time:70661.02559661865
batch reward last col mean 0.0028598885983228683 first col mean 0.0006315040518529713 all mean 0.0018650413258001208
0.001854944508522749 0.0018549441592767835
rl training, epoch5, iter0, batch134/1133, batch loss:0.0018549441592767835, Training time:70661.46905064583
batch reward last col mean 0.0006275771302171052 first col mean 0.00021922463201917708 all mean 0.0005732321296818554
0.000862510350998491 0.000862510409206152
rl training, epoch5, iter0, batch135/1133, batch loss:0.000862510409206152, Training time:70662.16776299477
batch reward last col mean 0.0015457780100405216 first col mean 0.0002462955890223384 all mean 0.0014942213892936707
0.0024635400623083115 0.0024635400623083115
rl training, epoch5, iter0, batch136/1133, batch loss:0.0024635400623083115, Training time:70662.64131689072
batch reward last col mean 0.00045531586511060596 first col mean 8.729326509637758e-05 all mean 0.0004502211813814938
0.00048079591942951083 0.0004807958612218499
rl training, epoch5, iter0, batch137/1133, batch loss:0.0004807958612218499, Training time:70663.0507569313
batch reward last col mean 0.0005737966857850552 first col mean 0.00015437947877217084 all mean 0.0005133165395818651
0.0002018449013121426 0.00020184487220831215
rl training, epoch5, iter0, batch138/1133, batch loss:0.00020184487220831215, Training time:70663.4224524498
batch reward last col mean 0.0004408183158375323 first col mean 0.00030108558712527156 all mean 0.0004171738401055336
0.00011170560901518911 0.00011170563811901957
rl training, epoch5, iter0, batch139/1133, batch loss:0.00011170563811901957, Training time:70663.8035235405
batch reward last col mean 0.0005252719856798649 first col mean 0.0002645190979819745 all mean 0.0005864804261364043
0.0015724117401987314 0.0015724116237834096
rl training, epoch5, iter0, batch140/1133, batch loss:0.0015724116237834096, Training time:70664.18298768997
batch reward last col mean 0.0003258921205997467 first col mean 0.0009545255452394485 all mean 0.0004395031719468534
0.000400810589781031 0.000400810589781031
rl training, epoch5, iter0, batch141/1133, batch loss:0.000400810589781031, Training time:70664.54807639122
batch reward last col mean 0.0005638435832224786 first col mean 0.0001576398644829169 all mean 0.0005360128125175834
0.00033022838761098683 0.0003302284167148173
rl training, epoch5, iter0, batch142/1133, batch loss:0.0003302284167148173, Training time:70665.01269245148
batch reward last col mean 0.0007344962796196342 first col mean 0.0001957510394277051 all mean 0.0006901094457134604
0.000580227526370436 0.000580227468162775
rl training, epoch5, iter0, batch143/1133, batch loss:0.000580227468162775, Training time:70665.42725586891
batch reward last col mean 0.0018391639459878206 first col mean 0.0012688379501923919 all mean 0.0012535989517346025
0.0017177049303427339 0.0017177049303427339
rl training, epoch5, iter0, batch144/1133, batch loss:0.0017177049303427339, Training time:70665.83615899086
batch reward last col mean 0.00014120519335847348 first col mean 0.003338930429890752 all mean 0.0005109984776936471
0.007187189068645239 0.007187189068645239
rl training, epoch5, iter0, batch145/1133, batch loss:0.007187189068645239, Training time:70666.1701323986
batch reward last col mean 0.00633928831666708 first col mean 0.0002208867808803916 all mean 0.0033618872985243797
0.0029923911206424236 0.0029923913534730673
rl training, epoch5, iter0, batch146/1133, batch loss:0.0029923913534730673, Training time:70666.54241323471
batch reward last col mean 0.00020835727627854794 first col mean 0.000550320721231401 all mean 0.00019346742192283273
0.00010911903518717736 0.00010911904246313497
rl training, epoch5, iter0, batch147/1133, batch loss:0.00010911904246313497, Training time:70666.92667937279
batch reward last col mean 0.00043691392056643963 first col mean 8.935003279475495e-05 all mean 0.000412867171689868
0.0002808558929245919 0.0002808559511322528
rl training, epoch5, iter0, batch148/1133, batch loss:0.0002808559511322528, Training time:70667.43443632126
batch reward last col mean 0.0014233794063329697 first col mean 8.28045594971627e-05 all mean 0.0013669239124283195
0.0015557577135041356 0.0015557575970888138
rl training, epoch5, iter0, batch149/1133, batch loss:0.0015557575970888138, Training time:70667.81201910973
batch reward last col mean 0.0002846050774678588 first col mean 0.00017549292533658445 all mean 0.00032662361627444625
0.00019020872423425317 0.00019020870968233794
rl training, epoch5, iter0, batch150/1133, batch loss:0.00019020870968233794, Training time:70668.33336806297
batch reward last col mean 0.0001568424195284024 first col mean 0.00020575031521730125 all mean 0.00017442267562728375
0.00038694776594638824 0.00038694776594638824
rl training, epoch5, iter0, batch151/1133, batch loss:0.00038694776594638824, Training time:70669.06762456894
batch reward last col mean 0.0005125787574797869 first col mean 0.00045469228643924 all mean 0.0005925972945988178
0.0014120654668658972 0.0014120653504505754
rl training, epoch5, iter0, batch152/1133, batch loss:0.0014120653504505754, Training time:70669.48663067818
batch reward last col mean 0.009435204789042473 first col mean 0.0005115643725730479 all mean 0.006989091169089079
0.009384295903146267 0.009384295903146267
rl training, epoch5, iter0, batch153/1133, batch loss:0.009384295903146267, Training time:70669.90245771408
batch reward last col mean 0.0003972328850068152 first col mean 0.0001230499765370041 all mean 0.0002716099552344531
0.0003336891531944275 0.0003336891531944275
rl training, epoch5, iter0, batch154/1133, batch loss:0.0003336891531944275, Training time:70670.36046886444
batch reward last col mean 7.996463682502508e-05 first col mean 0.0004255470703355968 all mean 0.00011017359793186188
0.00034146569669246674 0.00034146569669246674
rl training, epoch5, iter0, batch155/1133, batch loss:0.00034146569669246674, Training time:70670.7833750248
batch reward last col mean 0.00024590533575974405 first col mean 0.00010228252358501777 all mean 0.00030078578856773674
0.0005267868982627988 0.000526786781847477
rl training, epoch5, iter0, batch156/1133, batch loss:0.000526786781847477, Training time:70671.16740322113
batch reward last col mean 0.00021670202841050923 first col mean 0.0011717312736436725 all mean 0.00026161508867517114
0.00029506790451705456 0.0002950678754132241
rl training, epoch5, iter0, batch157/1133, batch loss:0.0002950678754132241, Training time:70671.61685204506
batch reward last col mean 0.00227759568952024 first col mean 0.00021112864487804472 all mean 0.0020164870657026768
0.001068959361873567 0.001068959361873567
rl training, epoch5, iter0, batch158/1133, batch loss:0.001068959361873567, Training time:70671.99201107025
batch reward last col mean 0.0001362963521387428 first col mean 0.00029175751842558384 all mean 0.0002093338844133541
0.00019597164646256715 0.0001959717192221433
rl training, epoch5, iter0, batch159/1133, batch loss:0.0001959717192221433, Training time:70672.4369263649
batch reward last col mean 9.514411067357287e-05 first col mean 0.0005019515519961715 all mean 0.00013889302499592304
0.00017298723105341196 0.00017298721650149673
rl training, epoch5, iter0, batch160/1133, batch loss:0.00017298721650149673, Training time:70672.85446357727
batch reward last col mean 0.0022853899281471968 first col mean 0.0013921810314059258 all mean 0.001934607862494886
0.005992308259010315 0.005992308724671602
rl training, epoch5, iter0, batch161/1133, batch loss:0.005992308724671602, Training time:70673.2064409256
batch reward last col mean 0.0001919180213008076 first col mean 9.036863775691018e-05 all mean 0.0002229235542472452
0.0003522918850649148 0.00035229194327257574
rl training, epoch5, iter0, batch162/1133, batch loss:0.00035229194327257574, Training time:70673.5876865387
batch reward last col mean 0.002405719831585884 first col mean 0.00024219683837145567 all mean 0.0021883605513721704
0.0024631505366414785 0.0024631505366414785
rl training, epoch5, iter0, batch163/1133, batch loss:0.0024631505366414785, Training time:70674.04269480705
batch reward last col mean 0.00011345204256940633 first col mean 0.000488268822664395 all mean 0.0001844941289164126
0.00012507244537118822 0.00012507247447501868
rl training, epoch5, iter0, batch164/1133, batch loss:0.00012507247447501868, Training time:70674.4236524105
batch reward last col mean 0.0004271133802831173 first col mean 0.0017860999796539545 all mean 0.0006247724522836506
0.0004306361952330917 0.00043063622433692217
rl training, epoch5, iter0, batch165/1133, batch loss:0.00043063622433692217, Training time:70674.93580627441
batch reward last col mean 0.0009162007481791079 first col mean 0.00141796818934381 all mean 0.0007542792009189725
0.001385394367389381 0.0013853944838047028
rl training, epoch5, iter0, batch166/1133, batch loss:0.0013853944838047028, Training time:70675.31099629402
batch reward last col mean 0.0006724148988723755 first col mean 0.00021919695427641273 all mean 0.00046853971434757113
0.00035147316521033645 0.00035147316521033645
rl training, epoch5, iter0, batch167/1133, batch loss:0.00035147316521033645, Training time:70675.76570129395
batch reward last col mean 0.0033091376535594463 first col mean 0.00030882173450663686 all mean 0.002450816798955202
0.0023308817762881517 0.002330882241949439
rl training, epoch5, iter0, batch168/1133, batch loss:0.002330882241949439, Training time:70676.21573281288
batch reward last col mean 0.006034579128026962 first col mean 0.00026392185827717185 all mean 0.003736162558197975
0.0073663718067109585 0.0073663718067109585
rl training, epoch5, iter0, batch169/1133, batch loss:0.0073663718067109585, Training time:70676.63069152832
batch reward last col mean 0.0023182397708296776 first col mean 0.0008262348710559309 all mean 0.0021266499534249306
0.0018382045673206449 0.0018382043344900012
rl training, epoch5, iter0, batch170/1133, batch loss:0.0018382043344900012, Training time:70677.04374694824
batch reward last col mean 0.0003548020904418081 first col mean 0.00012534661800600588 all mean 0.0002754602173808962
0.00014103262219578028 0.00014103260764386505
rl training, epoch5, iter0, batch171/1133, batch loss:0.00014103260764386505, Training time:70677.45218682289
batch reward last col mean 0.0005587571067735553 first col mean 0.0003224161919206381 all mean 0.0005207049543969333
0.00026957489899359643 0.00026957481168210506
rl training, epoch5, iter0, batch172/1133, batch loss:0.00026957481168210506, Training time:70677.83162045479
batch reward last col mean 0.0001106096024159342 first col mean 0.00015074637485668063 all mean 0.00025981623912230134
0.0017580047715455294 0.0017580046551302075
rl training, epoch5, iter0, batch173/1133, batch loss:0.0017580046551302075, Training time:70678.2313117981
batch reward last col mean 0.00028085627127438784 first col mean 0.00035237250267528 all mean 0.0002397236239630729
0.00011915931099792942 0.00011915928917005658
rl training, epoch5, iter0, batch174/1133, batch loss:0.00011915928917005658, Training time:70678.59768843651
batch reward last col mean 0.00015575691941194236 first col mean 0.0002729364496190101 all mean 0.00015611822891514748
0.00010264010779792443 0.00010264010779792443
rl training, epoch5, iter0, batch175/1133, batch loss:0.00010264010779792443, Training time:70678.9707288742
batch reward last col mean 0.0009883688762784004 first col mean 0.00030255282763391733 all mean 0.0007944709504954517
0.0007620706455782056 0.0007620706455782056
rl training, epoch5, iter0, batch176/1133, batch loss:0.0007620706455782056, Training time:70679.43345475197
batch reward last col mean 0.00011033052578568459 first col mean 0.0009427801705896854 all mean 0.0002955690724775195
0.00038135223439894617 0.00038135232171043754
rl training, epoch5, iter0, batch177/1133, batch loss:0.00038135232171043754, Training time:70679.81479072571
batch reward last col mean 0.00469339219853282 first col mean 0.0007032150169834495 all mean 0.004231246188282967
0.003060103626921773 0.003060104325413704
rl training, epoch5, iter0, batch178/1133, batch loss:0.003060104325413704, Training time:70680.36796879768
batch reward last col mean 0.00042797732749022543 first col mean 0.0009133231942541897 all mean 0.00044358207378536463
0.0007238460821099579 0.0007238461403176188
rl training, epoch5, iter0, batch179/1133, batch loss:0.0007238461403176188, Training time:70680.73587727547
batch reward last col mean 4.868831820203923e-05 first col mean 0.0017813791055232286 all mean 0.00031652936013415456
5.6191322073573247e-05 5.619130388367921e-05
rl training, epoch5, iter0, batch180/1133, batch loss:5.619130388367921e-05, Training time:70681.11372923851
batch reward last col mean 0.0004243061994202435 first col mean 0.0006331371259875596 all mean 0.00046085024951025844
0.00013431423576548696 0.00013431423576548696
rl training, epoch5, iter0, batch181/1133, batch loss:0.00013431423576548696, Training time:70681.48912477493
batch reward last col mean 0.00018126069335266948 first col mean 9.228121780324727e-05 all mean 0.00029726832872256637
0.0004498098569456488 0.0004498098569456488
rl training, epoch5, iter0, batch182/1133, batch loss:0.0004498098569456488, Training time:70682.0335867405
batch reward last col mean 0.0027606061194092035 first col mean 0.0002609745424706489 all mean 0.002662473591044545
0.0027090052608400583 0.002709005493670702
rl training, epoch5, iter0, batch183/1133, batch loss:0.002709005493670702, Training time:70682.52192950249
batch reward last col mean 0.0005878850934095681 first col mean 0.00021614908473566175 all mean 0.0007760563748888671
0.0006290548481047153 0.0006290548481047153
rl training, epoch5, iter0, batch184/1133, batch loss:0.0006290548481047153, Training time:70682.93210983276
batch reward last col mean 0.00055719941155985 first col mean 0.00016980679356493056 all mean 0.00046468619257211685
0.0004524101095739752 0.00045241002226248384
rl training, epoch5, iter0, batch185/1133, batch loss:0.00045241002226248384, Training time:70683.31522154808
batch reward last col mean 0.00020237627904862165 first col mean 0.0006927750073373318 all mean 0.0002878444502130151
0.00030293824966065586 0.0003029382205568254
rl training, epoch5, iter0, batch186/1133, batch loss:0.0003029382205568254, Training time:70683.66263961792
batch reward last col mean 0.001530020497739315 first col mean 0.001646040240302682 all mean 0.0015612479764968157
0.0011788089759647846 0.0011788090923801064
rl training, epoch5, iter0, batch187/1133, batch loss:0.0011788090923801064, Training time:70684.04341030121
batch reward last col mean 0.0002406167914159596 first col mean 0.0006337250233627856 all mean 0.00034527070238254964
0.00014431015006266534 0.00014431009185500443
rl training, epoch5, iter0, batch188/1133, batch loss:0.00014431009185500443, Training time:70684.40803742409
batch reward last col mean 0.0003576987364795059 first col mean 0.0003884101752191782 all mean 0.00032656118855811656
0.00018119491869583726 0.00018119494779966772
rl training, epoch5, iter0, batch189/1133, batch loss:0.00018119494779966772, Training time:70684.97503852844
batch reward last col mean 0.0015889792703092098 first col mean 0.0003985149087384343 all mean 0.0009152771672233939
0.0008184375474229455 0.0008184376056306064
rl training, epoch5, iter0, batch190/1133, batch loss:0.0008184376056306064, Training time:70685.35238957405
batch reward last col mean 0.0038197608664631844 first col mean 0.00022859350428916514 all mean 0.0034223790280520916
0.006171821616590023 0.006171821616590023
rl training, epoch5, iter0, batch191/1133, batch loss:0.006171821616590023, Training time:70685.83105015755
batch reward last col mean 0.0038943064864724874 first col mean 0.0022468918468803167 all mean 0.003635881934314966
0.006284531205892563 0.0062845307402312756
rl training, epoch5, iter0, batch192/1133, batch loss:0.0062845307402312756, Training time:70686.41592264175
batch reward last col mean 0.0012528013903647661 first col mean 0.0008235443383455276 all mean 0.0012193747097626328
0.0011680473107844591 0.001168047427199781
rl training, epoch5, iter0, batch193/1133, batch loss:0.001168047427199781, Training time:70686.7816169262
batch reward last col mean 0.004317600280046463 first col mean 0.002037234138697386 all mean 0.0040611159056425095
0.003644198877736926 0.003644198877736926
rl training, epoch5, iter0, batch194/1133, batch loss:0.003644198877736926, Training time:70687.1657025814
batch reward last col mean 0.0026128964964300394 first col mean 0.0015527758514508605 all mean 0.0024759836960583925
0.002125327941030264 0.0021253274753689766
rl training, epoch5, iter0, batch195/1133, batch loss:0.0021253274753689766, Training time:70687.54823160172
batch reward last col mean 0.006732705049216747 first col mean 0.0007519859354943037 all mean 0.006035305093973875
0.004463528748601675 0.004463529214262962
rl training, epoch5, iter0, batch196/1133, batch loss:0.004463529214262962, Training time:70688.01248812675
batch reward last col mean 0.0008684234344400465 first col mean 0.000444401812274009 all mean 0.0008479346288368106
0.0007015317678451538 0.0007015318260528147
rl training, epoch5, iter0, batch197/1133, batch loss:0.0007015318260528147, Training time:70688.44869923592
batch reward last col mean 0.00033585081109777093 first col mean 0.001302556716836989 all mean 0.00042280787602066994
0.0003265385457780212 0.0003265385457780212
rl training, epoch5, iter0, batch198/1133, batch loss:0.0003265385457780212, Training time:70688.98595166206
batch reward last col mean 9.985030919779092e-05 first col mean 0.0015744682168588042 all mean 0.0002600821608211845
0.00014805266982875764 0.00014805268438067287
rl training, epoch5, iter0, batch199/1133, batch loss:0.00014805268438067287, Training time:70689.33113145828
batch reward last col mean 0.00039790268056094646 first col mean 0.001189271337352693 all mean 0.0007247942849062383
0.0012469383655115962 0.001246938481926918
rl training, epoch5, iter0, batch200/1133, batch loss:0.001246938481926918, Training time:70689.86199259758
batch reward last col mean 0.002084268955513835 first col mean 0.0013241227716207504 all mean 0.001722379238344729
0.003346814075484872 0.003346814075484872
rl training, epoch5, iter0, batch201/1133, batch loss:0.003346814075484872, Training time:70690.39404582977
batch reward last col mean 0.00040019958396442235 first col mean 0.002373257651925087 all mean 0.0005673008854500949
0.00025428298977203667 0.0002542831061873585
rl training, epoch5, iter0, batch202/1133, batch loss:0.0002542831061873585, Training time:70690.78301215172
batch reward last col mean 0.006714389193803072 first col mean 0.00089957972522825 all mean 0.005676579661667347
0.00414416566491127 0.004144165199249983
rl training, epoch5, iter0, batch203/1133, batch loss:0.004144165199249983, Training time:70691.24072003365
batch reward last col mean 0.0024420947302132845 first col mean 0.0012169419787824154 all mean 0.0027073193341493607
0.004849147517234087 0.004849147517234087
rl training, epoch5, iter0, batch204/1133, batch loss:0.004849147517234087, Training time:70691.55322647095
batch reward last col mean 0.003383075585588813 first col mean 0.00036401234683580697 all mean 0.0024349484592676163
0.0024587654042989016 0.0024587654042989016
rl training, epoch5, iter0, batch205/1133, batch loss:0.0024587654042989016, Training time:70692.0211174488
batch reward last col mean 0.0007560835219919682 first col mean 0.002262038178741932 all mean 0.0011176371481269598
0.0019435120048001409 0.0019435117719694972
rl training, epoch5, iter0, batch206/1133, batch loss:0.0019435117719694972, Training time:70692.45992040634
batch reward last col mean 0.006337385158985853 first col mean 0.0008293745340779424 all mean 0.005271620117127895
0.004637289792299271 0.004637290257960558
rl training, epoch5, iter0, batch207/1133, batch loss:0.004637290257960558, Training time:70692.84302139282
batch reward last col mean 0.00464723352342844 first col mean 0.0017030674498528242 all mean 0.0037039737217128277
0.006724310573190451 0.006724311038851738
rl training, epoch5, iter0, batch208/1133, batch loss:0.006724311038851738, Training time:70693.371311903
batch reward last col mean 0.0010653400095179677 first col mean 0.0028167329728603363 all mean 0.001201090170070529
0.0015511178644374013 0.0015511177480220795
rl training, epoch5, iter0, batch209/1133, batch loss:0.0015511177480220795, Training time:70693.75002741814
batch reward last col mean 0.000956377072725445 first col mean 0.0006182938814163208 all mean 0.001073453458957374
0.000861880776938051 0.0008618806605227292
rl training, epoch5, iter0, batch210/1133, batch loss:0.0008618806605227292, Training time:70694.21886563301
batch reward last col mean 0.00298253633081913 first col mean 0.0018637876491993666 all mean 0.002767218742519617
0.0024427510797977448 0.0024427510797977448
rl training, epoch5, iter0, batch211/1133, batch loss:0.0024427510797977448, Training time:70694.68003678322
batch reward last col mean 0.0003464557812549174 first col mean 0.0007786932401359081 all mean 0.0004312839882913977
0.000205262636882253 0.00020526266598608345
rl training, epoch5, iter0, batch212/1133, batch loss:0.00020526266598608345, Training time:70695.22223329544
batch reward last col mean 0.00170551473274827 first col mean 0.0005653855623677373 all mean 0.0016486913664266467
0.001290848245844245 0.001290848245844245
rl training, epoch5, iter0, batch213/1133, batch loss:0.001290848245844245, Training time:70695.63995909691
batch reward last col mean 0.002256982494145632 first col mean 0.0010581411188468337 all mean 0.0020905942656099796
0.0014913445338606834 0.0014913445338606834
rl training, epoch5, iter0, batch214/1133, batch loss:0.0014913445338606834, Training time:70696.01086688042
batch reward last col mean 0.0014683982590213418 first col mean 0.0005498795653693378 all mean 0.0014564886223524809
0.0012632817961275578 0.0012632817961275578
rl training, epoch5, iter0, batch215/1133, batch loss:0.0012632817961275578, Training time:70696.41237401962
batch reward last col mean 0.000289460935164243 first col mean 0.003404417308047414 all mean 0.0004985296982340515
0.000579710234887898 0.0005797100020572543
rl training, epoch5, iter0, batch216/1133, batch loss:0.0005797100020572543, Training time:70696.9972000122
batch reward last col mean 0.004211765248328447 first col mean 0.0007902397774159908 all mean 0.0033757842611521482
0.002537341322749853 0.002537341322749853
rl training, epoch5, iter0, batch217/1133, batch loss:0.002537341322749853, Training time:70697.48541140556
batch reward last col mean 0.007531790062785149 first col mean 0.0015775146894156933 all mean 0.006183966062963009
0.009865681640803814 0.009865681640803814
rl training, epoch5, iter0, batch218/1133, batch loss:0.009865681640803814, Training time:70697.91279411316
batch reward last col mean 0.003169506788253784 first col mean 0.004073590971529484 all mean 0.0032728458754718304
0.0019344236934557557 0.001934423460625112
rl training, epoch5, iter0, batch219/1133, batch loss:0.001934423460625112, Training time:70698.30143284798
batch reward last col mean 0.005067092832177877 first col mean 0.002180914394557476 all mean 0.0051099820993840694
0.005006858147680759 0.005006857216358185
rl training, epoch5, iter0, batch220/1133, batch loss:0.005006857216358185, Training time:70698.7862560749
batch reward last col mean 0.0030012447386980057 first col mean 0.004303520079702139 all mean 0.003123649163171649
0.002272011013701558 0.0022720114793628454
rl training, epoch5, iter0, batch221/1133, batch loss:0.0022720114793628454, Training time:70699.16616654396
batch reward last col mean 0.009119001217186451 first col mean 0.003255693707615137 all mean 0.008150635287165642
0.003310919739305973 0.003310919739305973
rl training, epoch5, iter0, batch222/1133, batch loss:0.003310919739305973, Training time:70699.66606903076
batch reward last col mean 0.0005413220496848226 first col mean 0.0014053035993129015 all mean 0.0005860041710548103
0.00021955605188850313 0.0002195560373365879
rl training, epoch5, iter0, batch223/1133, batch loss:0.0002195560373365879, Training time:70700.16102933884
batch reward last col mean 0.009206472896039486 first col mean 0.001992633566260338 all mean 0.00898560881614685
0.005298302508890629 0.005298302508890629
rl training, epoch5, iter0, batch224/1133, batch loss:0.005298302508890629, Training time:70700.62660646439
batch reward last col mean 0.0021759304217994213 first col mean 0.006676889955997467 all mean 0.002594246994704008
0.0016132666496559978 0.0016132663004100323
rl training, epoch5, iter0, batch225/1133, batch loss:0.0016132663004100323, Training time:70701.07803106308
batch reward last col mean 0.0055510844103991985 first col mean 0.001659332774579525 all mean 0.005730367265641689
0.010628863237798214 0.010628863237798214
rl training, epoch5, iter0, batch226/1133, batch loss:0.010628863237798214, Training time:70701.48766827583
batch reward last col mean 0.007113935425877571 first col mean 0.005408674944192171 all mean 0.00711571192368865
0.007704897318035364 0.007704897318035364
rl training, epoch5, iter0, batch227/1133, batch loss:0.007704897318035364, Training time:70701.88477635384
batch reward last col mean 0.0072000231593847275 first col mean 0.005150003358721733 all mean 0.005766181740909815
0.006915588863193989 0.006915588863193989
rl training, epoch5, iter0, batch228/1133, batch loss:0.006915588863193989, Training time:70702.19609165192
batch reward last col mean 0.009030217304825783 first col mean 0.0020389663986861706 all mean 0.008012201637029648
0.004642344079911709 0.004642344545572996
rl training, epoch5, iter0, batch229/1133, batch loss:0.004642344545572996, Training time:70702.57085943222
batch reward last col mean 0.003765552071854472 first col mean 0.00465887226164341 all mean 0.0038168472237885
0.0027252708096057177 0.0027252710424363613
rl training, epoch5, iter0, batch230/1133, batch loss:0.0027252710424363613, Training time:70703.01094818115
batch reward last col mean 0.003117889864370227 first col mean 0.003942910116165876 all mean 0.003209219314157963
0.0029142843559384346 0.0029142845887690783
rl training, epoch5, iter0, batch231/1133, batch loss:0.0029142845887690783, Training time:70703.52524256706
batch reward last col mean 0.004045340232551098 first col mean 0.005211537703871727 all mean 0.004262007772922516
0.003202395746484399 0.003202395746484399
rl training, epoch5, iter0, batch232/1133, batch loss:0.003202395746484399, Training time:70703.91217660904
batch reward last col mean 0.003539971075952053 first col mean 0.003814955474808812 all mean 0.0035335691645741463
0.002617359161376953 0.0026173596270382404
rl training, epoch5, iter0, batch233/1133, batch loss:0.0026173596270382404, Training time:70704.39676713943
batch reward last col mean 0.002703741192817688 first col mean 0.004639205057173967 all mean 0.0030108399223536253
0.0029252932872623205 0.002925293520092964
rl training, epoch5, iter0, batch234/1133, batch loss:0.002925293520092964, Training time:70704.8008992672
batch reward last col mean 0.001487410394474864 first col mean 0.002102904487401247 all mean 0.001599285751581192
0.0009251857409253716 0.0009251856827177107
rl training, epoch5, iter0, batch235/1133, batch loss:0.0009251856827177107, Training time:70705.2108476162
batch reward last col mean 0.02060086280107498 first col mean 0.006773598026484251 all mean 0.01844780519604683
0.020906558260321617 0.020906556397676468
rl training, epoch5, iter0, batch236/1133, batch loss:0.020906556397676468, Training time:70705.6595275402
batch reward last col mean 0.003964629955589771 first col mean 0.007003204431384802 all mean 0.0043126181699335575
0.004527965094894171 0.004527965094894171
rl training, epoch5, iter0, batch237/1133, batch loss:0.004527965094894171, Training time:70706.0258307457
batch reward last col mean 0.009514158591628075 first col mean 0.0125450249761343 all mean 0.009954258799552917
0.005406285636126995 0.005406285636126995
rl training, epoch5, iter0, batch238/1133, batch loss:0.005406285636126995, Training time:70706.46474647522
batch reward last col mean 0.011417506262660027 first col mean 0.005515248514711857 all mean 0.010789447464048862
0.0076834638603031635 0.0076834638603031635
rl training, epoch5, iter0, batch239/1133, batch loss:0.0076834638603031635, Training time:70706.80573558807
batch reward last col mean 0.00501228217035532 first col mean 0.008136961609125137 all mean 0.005305465776473284
0.0039044320583343506 0.003904431825503707
rl training, epoch5, iter0, batch240/1133, batch loss:0.003904431825503707, Training time:70707.20802807808
batch reward last col mean 0.003252148861065507 first col mean 0.007308441214263439 all mean 0.003452976932749152
0.0025944591034203768 0.0025944591034203768
rl training, epoch5, iter0, batch241/1133, batch loss:0.0025944591034203768, Training time:70707.60894465446
batch reward last col mean 0.011708837002515793 first col mean 0.00499925808981061 all mean 0.010376567021012306
0.008246892131865025 0.0082468930631876
rl training, epoch5, iter0, batch242/1133, batch loss:0.0082468930631876, Training time:70707.97897744179
batch reward last col mean 0.0197389367967844 first col mean 0.01787484809756279 all mean 0.019114047288894653
0.023593919351696968 0.02359391748905182
rl training, epoch5, iter0, batch243/1133, batch loss:0.02359391748905182, Training time:70708.25297498703
batch reward last col mean 0.007242470048367977 first col mean 0.012482314370572567 all mean 0.00811911839991808
0.006794563960283995 0.006794564425945282
rl training, epoch5, iter0, batch244/1133, batch loss:0.006794564425945282, Training time:70708.75175237656
batch reward last col mean 0.00732747046276927 first col mean 0.007140418980270624 all mean 0.007078745402395725
0.0050978646613657475 0.005097865127027035
rl training, epoch5, iter0, batch245/1133, batch loss:0.005097865127027035, Training time:70709.30802679062
batch reward last col mean 0.006191877648234367 first col mean 0.01083639357239008 all mean 0.006929510738700628
0.00475048553198576 0.004750485066324472
rl training, epoch5, iter0, batch246/1133, batch loss:0.004750485066324472, Training time:70709.76654219627
batch reward last col mean 0.01416628435254097 first col mean 0.011652469635009766 all mean 0.012771150097250938
0.013085315003991127 0.013085312210023403
rl training, epoch5, iter0, batch247/1133, batch loss:0.013085312210023403, Training time:70710.26383924484
batch reward last col mean 0.007732849568128586 first col mean 0.013243621215224266 all mean 0.008179491385817528
0.007960145361721516 0.007960145361721516
rl training, epoch5, iter0, batch248/1133, batch loss:0.007960145361721516, Training time:70710.63225364685
batch reward last col mean 0.020665248855948448 first col mean 0.014979982748627663 all mean 0.02034721150994301
0.021709701046347618 0.021709701046347618
rl training, epoch5, iter0, batch249/1133, batch loss:0.021709701046347618, Training time:70711.14698839188
batch reward last col mean 0.008965732529759407 first col mean 0.016316790133714676 all mean 0.009839532896876335
0.009535694494843483 0.009535694494843483
rl training, epoch5, iter0, batch250/1133, batch loss:0.009535694494843483, Training time:70711.54151391983
batch reward last col mean 0.012023499235510826 first col mean 0.007632127497345209 all mean 0.012157986871898174
0.006028992123901844 0.006028991192579269
rl training, epoch5, iter0, batch251/1133, batch loss:0.006028991192579269, Training time:70712.00313925743
batch reward last col mean 0.01949600875377655 first col mean 0.015648523345589638 all mean 0.019066965207457542
0.012192526832222939 0.012192526832222939
rl training, epoch5, iter0, batch252/1133, batch loss:0.012192526832222939, Training time:70712.61461997032
batch reward last col mean 0.00628655543550849 first col mean 0.010696373879909515 all mean 0.006870403420180082
0.005402659066021442 0.005402658600360155
rl training, epoch5, iter0, batch253/1133, batch loss:0.005402658600360155, Training time:70713.17478752136
batch reward last col mean 0.010858280584216118 first col mean 0.01605996862053871 all mean 0.011577554978430271
0.007925357669591904 0.007925358600914478
rl training, epoch5, iter0, batch254/1133, batch loss:0.007925358600914478, Training time:70713.53816628456
batch reward last col mean 0.008995365351438522 first col mean 0.010292356833815575 all mean 0.008815419860184193
0.008725772611796856 0.008725771680474281
rl training, epoch5, iter0, batch255/1133, batch loss:0.008725771680474281, Training time:70713.95378422737
batch reward last col mean 0.018874110653996468 first col mean 0.0208902470767498 all mean 0.019307995215058327
0.020236559212207794 0.020236559212207794
rl training, epoch5, iter0, batch256/1133, batch loss:0.020236559212207794, Training time:70714.29444026947
batch reward last col mean 0.00730470335111022 first col mean 0.019878976047039032 all mean 0.008628006093204021
0.004990473855286837 0.004990474320948124
rl training, epoch5, iter0, batch257/1133, batch loss:0.004990474320948124, Training time:70714.77118039131
batch reward last col mean 0.00824439525604248 first col mean 0.013211200013756752 all mean 0.008958753198385239
0.007431722711771727 0.007431722711771727
rl training, epoch5, iter0, batch258/1133, batch loss:0.007431722711771727, Training time:70715.23916864395
batch reward last col mean 0.015109527856111526 first col mean 0.019107723608613014 all mean 0.01518042292445898
0.008503257296979427 0.008503255434334278
rl training, epoch5, iter0, batch259/1133, batch loss:0.008503255434334278, Training time:70715.7048406601
batch reward last col mean 0.017568891867995262 first col mean 0.018864979967474937 all mean 0.017319966107606888
0.011465782299637794 0.011465782299637794
rl training, epoch5, iter0, batch260/1133, batch loss:0.011465782299637794, Training time:70716.12313222885
batch reward last col mean 0.019688455387949944 first col mean 0.01760067604482174 all mean 0.01975506916642189
0.011957314796745777 0.011957313865423203
rl training, epoch5, iter0, batch261/1133, batch loss:0.011957313865423203, Training time:70716.45829582214
batch reward last col mean 0.034887224435806274 first col mean 0.023937268182635307 all mean 0.03436965495347977
0.03359540179371834 0.033595405519008636
rl training, epoch5, iter0, batch262/1133, batch loss:0.033595405519008636, Training time:70716.90918803215
batch reward last col mean 0.0294781681150198 first col mean 0.02497362717986107 all mean 0.028909428045153618
0.03143668547272682 0.03143668919801712
rl training, epoch5, iter0, batch263/1133, batch loss:0.03143668919801712, Training time:70717.25811982155
batch reward last col mean 0.019341640174388885 first col mean 0.022545374929904938 all mean 0.020448263734579086
0.02055322751402855 0.02055322751402855
rl training, epoch5, iter0, batch264/1133, batch loss:0.02055322751402855, Training time:70717.70588827133
batch reward last col mean 0.02942769229412079 first col mean 0.01731136254966259 all mean 0.026926830410957336
0.020124120637774467 0.020124120637774467
rl training, epoch5, iter0, batch265/1133, batch loss:0.020124120637774467, Training time:70718.23498702049
batch reward last col mean 0.026040654629468918 first col mean 0.026533138006925583 all mean 0.026269853115081787
0.015543709509074688 0.015543709509074688
rl training, epoch5, iter0, batch266/1133, batch loss:0.015543709509074688, Training time:70718.67847156525
batch reward last col mean 0.01603185012936592 first col mean 0.015653476119041443 all mean 0.01581220142543316
0.01252793986350298 0.01252793986350298
rl training, epoch5, iter0, batch267/1133, batch loss:0.01252793986350298, Training time:70719.09827542305
batch reward last col mean 0.03452532738447189 first col mean 0.026464957743883133 all mean 0.0332939438521862
0.02345089428126812 0.02345089428126812
rl training, epoch5, iter0, batch268/1133, batch loss:0.02345089428126812, Training time:70719.40899538994
batch reward last col mean 0.05237344279885292 first col mean 0.036226145923137665 all mean 0.05009624361991882
0.05096040293574333 0.05096040293574333
rl training, epoch5, iter0, batch269/1133, batch loss:0.05096040293574333, Training time:70719.8012509346
batch reward last col mean 0.02398008108139038 first col mean 0.029417766258120537 all mean 0.02499469742178917
0.02205614559352398 0.022056149318814278
rl training, epoch5, iter0, batch270/1133, batch loss:0.022056149318814278, Training time:70720.17399311066
batch reward last col mean 0.037879131734371185 first col mean 0.03522887080907822 all mean 0.037762708961963654
0.015887320041656494 0.015887320041656494
rl training, epoch5, iter0, batch271/1133, batch loss:0.015887320041656494, Training time:70720.54007339478
batch reward last col mean 0.05179864168167114 first col mean 0.03280574083328247 all mean 0.047182485461235046
0.026041338220238686 0.026041332632303238
rl training, epoch5, iter0, batch272/1133, batch loss:0.026041332632303238, Training time:70720.87794208527
batch reward last col mean 0.02145828679203987 first col mean 0.04359015077352524 all mean 0.025226593017578125
0.025038590654730797 0.025038592517375946
rl training, epoch5, iter0, batch273/1133, batch loss:0.025038592517375946, Training time:70721.24703407288
batch reward last col mean 0.04506999999284744 first col mean 0.039688386023044586 all mean 0.04426009580492973
0.036019403487443924 0.036019399762153625
rl training, epoch5, iter0, batch274/1133, batch loss:0.036019399762153625, Training time:70721.62106609344
batch reward last col mean 0.042845431715250015 first col mean 0.03778085485100746 all mean 0.04165073111653328
0.028903396800160408 0.028903396800160408
rl training, epoch5, iter0, batch275/1133, batch loss:0.028903396800160408, Training time:70722.09455680847
batch reward last col mean 0.023704057559370995 first col mean 0.030368836596608162 all mean 0.02473035454750061
0.014791463501751423 0.014791463501751423
rl training, epoch5, iter0, batch276/1133, batch loss:0.014791463501751423, Training time:70722.46520519257
batch reward last col mean 0.03875480964779854 first col mean 0.046175215393304825 all mean 0.03947707638144493
0.04958595335483551 0.04958594962954521
rl training, epoch5, iter0, batch277/1133, batch loss:0.04958594962954521, Training time:70722.89640974998
batch reward last col mean 0.04704712703824043 first col mean 0.03900689631700516 all mean 0.046551499515771866
0.050940077751874924 0.050940077751874924
rl training, epoch5, iter0, batch278/1133, batch loss:0.050940077751874924, Training time:70723.22936964035
batch reward last col mean 0.038745954632759094 first col mean 0.05173822492361069 all mean 0.04091866686940193
0.036395616829395294 0.036395616829395294
rl training, epoch5, iter0, batch279/1133, batch loss:0.036395616829395294, Training time:70723.6035027504
batch reward last col mean 0.05698992311954498 first col mean 0.04350957274436951 all mean 0.05537036806344986
0.032795485109090805 0.032795485109090805
rl training, epoch5, iter0, batch280/1133, batch loss:0.032795485109090805, Training time:70724.03579330444
batch reward last col mean 0.03665026277303696 first col mean 0.048779260367155075 all mean 0.037037767469882965
0.02629275992512703 0.02629275992512703
rl training, epoch5, iter0, batch281/1133, batch loss:0.02629275992512703, Training time:70724.46031737328
batch reward last col mean 0.04486575350165367 first col mean 0.04733379930257797 all mean 0.045654669404029846
0.04171009361743927 0.04171009361743927
rl training, epoch5, iter0, batch282/1133, batch loss:0.04171009361743927, Training time:70724.75607991219
batch reward last col mean 0.052764929831027985 first col mean 0.06792899966239929 all mean 0.053990744054317474
0.033287711441516876 0.033287711441516876
rl training, epoch5, iter0, batch283/1133, batch loss:0.033287711441516876, Training time:70725.13014650345
batch reward last col mean 0.04980810731649399 first col mean 0.06190809607505798 all mean 0.05043993145227432
0.03924425691366196 0.03924425691366196
rl training, epoch5, iter0, batch284/1133, batch loss:0.03924425691366196, Training time:70725.41821289062
batch reward last col mean 0.035297222435474396 first col mean 0.049625761806964874 all mean 0.03721320629119873
0.02732057496905327 0.02732057124376297
rl training, epoch5, iter0, batch285/1133, batch loss:0.02732057124376297, Training time:70725.8014948368
batch reward last col mean 0.06632393598556519 first col mean 0.06914946436882019 all mean 0.06796234846115112
0.06239046901464462 0.062390465289354324
rl training, epoch5, iter0, batch286/1133, batch loss:0.062390465289354324, Training time:70726.13287377357
batch reward last col mean 0.04984875023365021 first col mean 0.07516049593687057 all mean 0.0525696724653244
0.04688173159956932 0.046881724148988724
rl training, epoch5, iter0, batch287/1133, batch loss:0.046881724148988724, Training time:70726.55061340332
batch reward last col mean 0.05634931102395058 first col mean 0.06943869590759277 all mean 0.05807632580399513
0.05890462175011635 0.05890462175011635
rl training, epoch5, iter0, batch288/1133, batch loss:0.05890462175011635, Training time:70727.0661535263
batch reward last col mean 0.04930434376001358 first col mean 0.057908594608306885 all mean 0.04952067881822586
0.03278646990656853 0.03278646990656853
rl training, epoch5, iter0, batch289/1133, batch loss:0.03278646990656853, Training time:70727.44353199005
batch reward last col mean 0.07260069996118546 first col mean 0.07992472499608994 all mean 0.07362667471170425
0.06851770728826523 0.06851770728826523
rl training, epoch5, iter0, batch290/1133, batch loss:0.06851770728826523, Training time:70727.92194414139
batch reward last col mean 0.06127481907606125 first col mean 0.07031621038913727 all mean 0.06303887069225311
0.06197365000844002 0.06197365000844002
rl training, epoch5, iter0, batch291/1133, batch loss:0.06197365000844002, Training time:70728.25523924828
batch reward last col mean 0.07627886533737183 first col mean 0.07203830778598785 all mean 0.07755310088396072
0.06629235297441483 0.06629233807325363
rl training, epoch5, iter0, batch292/1133, batch loss:0.06629233807325363, Training time:70728.66272091866
batch reward last col mean 0.09249526262283325 first col mean 0.07649701833724976 all mean 0.08897309750318527
0.10172116011381149 0.10172116011381149
rl training, epoch5, iter0, batch293/1133, batch loss:0.10172116011381149, Training time:70728.99692392349
batch reward last col mean 0.08526705205440521 first col mean 0.08289776742458344 all mean 0.08356747776269913
0.06530064344406128 0.06530064344406128
rl training, epoch5, iter0, batch294/1133, batch loss:0.06530064344406128, Training time:70729.30117702484
batch reward last col mean 0.1250111609697342 first col mean 0.09475967288017273 all mean 0.12237627804279327
0.12159433215856552 0.12159433215856552
rl training, epoch5, iter0, batch295/1133, batch loss:0.12159433215856552, Training time:70729.66184687614
batch reward last col mean 0.0851917415857315 first col mean 0.09063930809497833 all mean 0.08459530025720596
0.0738053023815155 0.0738053023815155
rl training, epoch5, iter0, batch296/1133, batch loss:0.0738053023815155, Training time:70730.13526558876
batch reward last col mean 0.09664534032344818 first col mean 0.11400794982910156 all mean 0.0939730629324913
0.1304578334093094 0.1304578334093094
rl training, epoch5, iter0, batch297/1133, batch loss:0.1304578334093094, Training time:70730.48359799385
batch reward last col mean 0.1406404674053192 first col mean 0.11803770065307617 all mean 0.1395990252494812
0.15283729135990143 0.15283729135990143
rl training, epoch5, iter0, batch298/1133, batch loss:0.15283729135990143, Training time:70730.84994602203
batch reward last col mean 0.10852386057376862 first col mean 0.10861014574766159 all mean 0.10921530425548553
0.11669504642486572 0.11669504642486572
rl training, epoch5, iter0, batch299/1133, batch loss:0.11669504642486572, Training time:70731.30627846718
batch reward last col mean 0.11519366502761841 first col mean 0.12763306498527527 all mean 0.12030297517776489
0.12942972779273987 0.12942972779273987
rl training, epoch5, iter0, batch300/1133, batch loss:0.12942972779273987, Training time:70731.73573756218
batch reward last col mean 0.13185767829418182 first col mean 0.1240449994802475 all mean 0.133677676320076
0.17735709249973297 0.17735707759857178
rl training, epoch5, iter0, batch301/1133, batch loss:0.17735707759857178, Training time:70732.18809223175
batch reward last col mean 0.14439575374126434 first col mean 0.16943323612213135 all mean 0.14730189740657806
0.1959293931722641 0.1959293931722641
rl training, epoch5, iter0, batch302/1133, batch loss:0.1959293931722641, Training time:70732.6123316288
batch reward last col mean 0.13007909059524536 first col mean 0.15669909119606018 all mean 0.1376846581697464
0.16689923405647278 0.16689923405647278
rl training, epoch5, iter0, batch303/1133, batch loss:0.16689923405647278, Training time:70733.3679471016
batch reward last col mean 0.194697767496109 first col mean 0.20371732115745544 all mean 0.19050748646259308
0.18971052765846252 0.18971054255962372
rl training, epoch5, iter0, batch304/1133, batch loss:0.18971054255962372, Training time:70734.26531124115
batch reward last col mean 0.17902536690235138 first col mean 0.17840032279491425 all mean 0.17881472408771515
0.19899676740169525 0.19899673759937286
rl training, epoch5, iter0, batch305/1133, batch loss:0.19899673759937286, Training time:70734.92887926102
batch reward last col mean 0.2026354968547821 first col mean 0.20730730891227722 all mean 0.1956743597984314
0.2316971719264984 0.2316971719264984
rl training, epoch5, iter0, batch306/1133, batch loss:0.2316971719264984, Training time:70735.57696032524
batch reward last col mean 0.19309179484844208 first col mean 0.19820156693458557 all mean 0.1971426010131836
0.2265545278787613 0.2265545278787613
rl training, epoch5, iter0, batch307/1133, batch loss:0.2265545278787613, Training time:70736.51036500931
batch reward last col mean 0.18415912985801697 first col mean 0.19301281869411469 all mean 0.18544839322566986
0.2435712069272995 0.2435712069272995
rl training, epoch5, iter0, batch308/1133, batch loss:0.2435712069272995, Training time:70737.48067879677
batch reward last col mean 0.21822461485862732 first col mean 0.22035837173461914 all mean 0.2166982740163803
0.22790054976940155 0.22790051996707916
rl training, epoch5, iter0, batch309/1133, batch loss:0.22790051996707916, Training time:70738.80458641052
batch reward last col mean 0.20611903071403503 first col mean 0.2123718410730362 all mean 0.20801009237766266
0.2480534464120865 0.24805346131324768
rl training, epoch5, iter0, batch310/1133, batch loss:0.24805346131324768, Training time:70740.53832221031
batch reward last col mean 0.2143515646457672 first col mean 0.19770045578479767 all mean 0.21013054251670837
0.21796150505542755 0.21796151995658875
rl training, epoch5, iter0, batch311/1133, batch loss:0.21796151995658875, Training time:70742.24843025208
batch reward last col mean 0.22924499213695526 first col mean 0.23358555138111115 all mean 0.23519636690616608
0.2504969835281372 0.2504969835281372
rl training, epoch5, iter0, batch312/1133, batch loss:0.2504969835281372, Training time:70744.11965465546
batch reward last col mean 0.2608102858066559 first col mean 0.2554534673690796 all mean 0.2593529224395752
0.2779596745967865 0.2779596447944641
rl training, epoch5, iter0, batch313/1133, batch loss:0.2779596447944641, Training time:70747.69780492783
batch reward last col mean 0.2887800633907318 first col mean 0.25170376896858215 all mean 0.28287744522094727
0.2973724901676178 0.2973724901676178
rl training, epoch5, iter0, batch314/1133, batch loss:0.2973724901676178, Training time:70750.09004878998
batch reward last col mean 0.23323486745357513 first col mean 0.25661501288414 all mean 0.23418444395065308
0.25708290934562683 0.25708290934562683
rl training, epoch5, iter0, batch315/1133, batch loss:0.25708290934562683, Training time:70754.19177985191
batch reward last col mean 0.3095798194408417 first col mean 0.3044630289077759 all mean 0.3039749264717102
0.30139490962028503 0.30139487981796265
rl training, epoch5, iter0, batch316/1133, batch loss:0.30139487981796265, Training time:70756.34764957428
batch reward last col mean 0.19654518365859985 first col mean 0.2637261152267456 all mean 0.21056830883026123
0.22792768478393555 0.22792768478393555
rl training, epoch5, iter0, batch317/1133, batch loss:0.22792768478393555, Training time:70757.9240899086
batch reward last col mean 0.25627538561820984 first col mean 0.2703820466995239 all mean 0.2641746401786804
0.24229806661605835 0.24229806661605835
rl training, epoch5, iter0, batch318/1133, batch loss:0.24229806661605835, Training time:70759.33420443535
batch reward last col mean 0.24240759015083313 first col mean 0.26721251010894775 all mean 0.24262124300003052
0.21249830722808838 0.21249830722808838
rl training, epoch5, iter0, batch319/1133, batch loss:0.21249830722808838, Training time:70760.8782055378
batch reward last col mean 0.30625155568122864 first col mean 0.29442813992500305 all mean 0.3047780692577362
0.2718462347984314 0.2718462347984314
rl training, epoch5, iter0, batch320/1133, batch loss:0.2718462347984314, Training time:70762.41464686394
batch reward last col mean 0.2575314939022064 first col mean 0.265016108751297 all mean 0.26128992438316345
0.24542082846164703 0.24542082846164703
rl training, epoch5, iter0, batch321/1133, batch loss:0.24542082846164703, Training time:70763.54208779335
batch reward last col mean 0.2527732253074646 first col mean 0.2810709774494171 all mean 0.2677792012691498
0.24837957322597504 0.24837957322597504
rl training, epoch5, iter0, batch322/1133, batch loss:0.24837957322597504, Training time:70764.58255386353
batch reward last col mean 0.2657226324081421 first col mean 0.28566646575927734 all mean 0.2792212665081024
0.23516307771205902 0.23516307771205902
rl training, epoch5, iter0, batch323/1133, batch loss:0.23516307771205902, Training time:70765.65246939659
batch reward last col mean 0.26409950852394104 first col mean 0.3025408685207367 all mean 0.2784607708454132
0.23729278147220612 0.23729278147220612
rl training, epoch5, iter0, batch324/1133, batch loss:0.23729278147220612, Training time:70766.90152025223
batch reward last col mean 0.25894397497177124 first col mean 0.3142281770706177 all mean 0.2707500159740448
0.22166374325752258 0.22166375815868378
rl training, epoch5, iter0, batch325/1133, batch loss:0.22166375815868378, Training time:70767.88455367088
batch reward last col mean 0.3161408603191376 first col mean 0.2985612750053406 all mean 0.3116166591644287
0.24936436116695404 0.24936436116695404
rl training, epoch5, iter0, batch326/1133, batch loss:0.24936436116695404, Training time:70768.92600417137
batch reward last col mean 0.2549647092819214 first col mean 0.27095597982406616 all mean 0.2601417303085327
0.20012694597244263 0.20012694597244263
rl training, epoch5, iter0, batch327/1133, batch loss:0.20012694597244263, Training time:70770.02026343346
batch reward last col mean 0.31316548585891724 first col mean 0.3221222758293152 all mean 0.3175310790538788
0.25475984811782837 0.25475984811782837
rl training, epoch5, iter0, batch328/1133, batch loss:0.25475984811782837, Training time:70770.94489860535
batch reward last col mean 0.32106244564056396 first col mean 0.29316800832748413 all mean 0.3149757981300354
0.23682232201099396 0.23682230710983276
rl training, epoch5, iter0, batch329/1133, batch loss:0.23682230710983276, Training time:70771.99633717537
batch reward last col mean 0.23103344440460205 first col mean 0.28274720907211304 all mean 0.24965062737464905
0.19246797263622284 0.19246797263622284
rl training, epoch5, iter0, batch330/1133, batch loss:0.19246797263622284, Training time:70772.88424515724
batch reward last col mean 0.2911016047000885 first col mean 0.3432198762893677 all mean 0.2988584637641907
0.23393481969833374 0.23393480479717255
rl training, epoch5, iter0, batch331/1133, batch loss:0.23393480479717255, Training time:70773.8288435936
batch reward last col mean 0.3319565951824188 first col mean 0.3327500820159912 all mean 0.33364537358283997
0.2482568919658661 0.2482568770647049
rl training, epoch5, iter0, batch332/1133, batch loss:0.2482568770647049, Training time:70774.4926662445
batch reward last col mean 0.33146482706069946 first col mean 0.3257906436920166 all mean 0.3311695456504822
0.19702407717704773 0.19702404737472534
rl training, epoch5, iter0, batch333/1133, batch loss:0.19702404737472534, Training time:70775.27350902557
batch reward last col mean 0.3254379630088806 first col mean 0.327780157327652 all mean 0.32751521468162537
0.22721056640148163 0.22721056640148163
rl training, epoch5, iter0, batch334/1133, batch loss:0.22721056640148163, Training time:70775.82300591469
batch reward last col mean 0.2849087417125702 first col mean 0.2977446913719177 all mean 0.29123571515083313
0.21612128615379333 0.21612128615379333
rl training, epoch5, iter0, batch335/1133, batch loss:0.21612128615379333, Training time:70776.5450618267
batch reward last col mean 0.38512328267097473 first col mean 0.38899171352386475 all mean 0.38440364599227905
0.22701554000377655 0.22701552510261536
rl training, epoch5, iter0, batch336/1133, batch loss:0.22701552510261536, Training time:70777.19279575348
batch reward last col mean 0.3354921042919159 first col mean 0.3469281494617462 all mean 0.3360634446144104
0.20602865517139435 0.20602864027023315
rl training, epoch5, iter0, batch337/1133, batch loss:0.20602864027023315, Training time:70778.1647734642
batch reward last col mean 0.31416016817092896 first col mean 0.34819555282592773 all mean 0.3189213275909424
0.2098281979560852 0.209828183054924
rl training, epoch5, iter0, batch338/1133, batch loss:0.209828183054924, Training time:70779.15449333191
batch reward last col mean 0.33800432085990906 first col mean 0.38201189041137695 all mean 0.341723769903183
0.18425627052783966 0.18425627052783966
rl training, epoch5, iter0, batch339/1133, batch loss:0.18425627052783966, Training time:70780.06786394119
batch reward last col mean 0.3587554395198822 first col mean 0.38994961977005005 all mean 0.3658093810081482
0.19509904086589813 0.19509905576705933
rl training, epoch5, iter0, batch340/1133, batch loss:0.19509905576705933, Training time:70781.22732496262
batch reward last col mean 0.3946145474910736 first col mean 0.409108966588974 all mean 0.3927285671234131
0.21815140545368195 0.21815140545368195
rl training, epoch5, iter0, batch341/1133, batch loss:0.21815140545368195, Training time:70782.26998138428
batch reward last col mean 0.42135196924209595 first col mean 0.4126010835170746 all mean 0.4155505895614624
0.22781451046466827 0.22781451046466827
rl training, epoch5, iter0, batch342/1133, batch loss:0.22781451046466827, Training time:70783.54610943794
batch reward last col mean 0.40625685453414917 first col mean 0.41079750657081604 all mean 0.41224053502082825
0.1830546259880066 0.1830546259880066
rl training, epoch5, iter0, batch343/1133, batch loss:0.1830546259880066, Training time:70785.82014513016
batch reward last col mean 0.4283451735973358 first col mean 0.41583001613616943 all mean 0.42061954736709595
0.16871589422225952 0.16871587932109833
rl training, epoch5, iter0, batch344/1133, batch loss:0.16871587932109833, Training time:70793.36853456497
batch reward last col mean 0.38100549578666687 first col mean 0.4006628096103668 all mean 0.3831440508365631
0.15460212528705597 0.15460212528705597
rl training, epoch5, iter0, batch345/1133, batch loss:0.15460212528705597, Training time:70807.62831711769
batch reward last col mean 0.39963698387145996 first col mean 0.38561272621154785 all mean 0.40268513560295105
0.13269272446632385 0.13269270956516266
rl training, epoch5, iter0, batch346/1133, batch loss:0.13269270956516266, Training time:70824.81147456169
batch reward last col mean 0.35194504261016846 first col mean 0.3444835841655731 all mean 0.3545228838920593
0.1170329600572586 0.11703294515609741
rl training, epoch5, iter0, batch347/1133, batch loss:0.11703294515609741, Training time:70840.12400746346
batch reward last col mean 0.3538281321525574 first col mean 0.3790135979652405 all mean 0.35539257526397705
0.1076124981045723 0.1076124981045723
rl training, epoch5, iter0, batch348/1133, batch loss:0.1076124981045723, Training time:70857.50100827217
batch reward last col mean 0.36187559366226196 first col mean 0.40013328194618225 all mean 0.3734486997127533
0.10926155000925064 0.10926155000925064
rl training, epoch5, iter0, batch349/1133, batch loss:0.10926155000925064, Training time:70874.84705519676
batch reward last col mean 0.37244099378585815 first col mean 0.3980954885482788 all mean 0.3834121823310852
0.08669451624155045 0.08669451624155045
rl training, epoch5, iter0, batch350/1133, batch loss:0.08669451624155045, Training time:70892.1759660244
batch reward last col mean 0.4314611852169037 first col mean 0.42499488592147827 all mean 0.4398498833179474
0.1118726059794426 0.1118726059794426
rl training, epoch5, iter0, batch351/1133, batch loss:0.1118726059794426, Training time:70909.65448188782
batch reward last col mean 0.3438795804977417 first col mean 0.36409690976142883 all mean 0.3552337884902954
0.0877949669957161 0.0877949669957161
rl training, epoch5, iter0, batch352/1133, batch loss:0.0877949669957161, Training time:70927.29744648933
batch reward last col mean 0.35299164056777954 first col mean 0.370423287153244 all mean 0.3680975139141083
0.09484419971704483 0.09484419971704483
rl training, epoch5, iter0, batch353/1133, batch loss:0.09484419971704483, Training time:70944.706761837
batch reward last col mean 0.3926044702529907 first col mean 0.3990704119205475 all mean 0.3790234625339508
0.09209226816892624 0.09209226816892624
rl training, epoch5, iter0, batch354/1133, batch loss:0.09209226816892624, Training time:70962.04691243172
batch reward last col mean 0.3699757158756256 first col mean 0.37703490257263184 all mean 0.37287431955337524
0.09461095929145813 0.09461096674203873
rl training, epoch5, iter0, batch355/1133, batch loss:0.09461096674203873, Training time:70979.50696492195
batch reward last col mean 0.377160906791687 first col mean 0.4112788438796997 all mean 0.38609081506729126
0.08958840370178223 0.08958839625120163
rl training, epoch5, iter0, batch356/1133, batch loss:0.08958839625120163, Training time:70996.91938018799
batch reward last col mean 0.336240291595459 first col mean 0.40556278824806213 all mean 0.3533598482608795
0.06954628229141235 0.06954628229141235
rl training, epoch5, iter0, batch357/1133, batch loss:0.06954628229141235, Training time:71014.40198802948
batch reward last col mean 0.3686298131942749 first col mean 0.37935003638267517 all mean 0.3690343499183655
0.07740413397550583 0.07740412652492523
rl training, epoch5, iter0, batch358/1133, batch loss:0.07740412652492523, Training time:71031.92687916756
batch reward last col mean 0.36686253547668457 first col mean 0.442211776971817 all mean 0.3905301094055176
0.07437087595462799 0.07437087595462799
rl training, epoch5, iter0, batch359/1133, batch loss:0.07437087595462799, Training time:71049.3296957016
batch reward last col mean 0.4334677457809448 first col mean 0.5257848501205444 all mean 0.44452837109565735
0.0696626678109169 0.0696626678109169
rl training, epoch5, iter0, batch360/1133, batch loss:0.0696626678109169, Training time:71067.01576304436
batch reward last col mean 0.4612773060798645 first col mean 0.5827321410179138 all mean 0.496137797832489
0.06328187882900238 0.06328187882900238
rl training, epoch5, iter0, batch361/1133, batch loss:0.06328187882900238, Training time:71084.66832566261
batch reward last col mean 0.497590035200119 first col mean 0.6135401129722595 all mean 0.5320018529891968
0.06905333697795868 0.06905333697795868
rl training, epoch5, iter0, batch362/1133, batch loss:0.06905333697795868, Training time:71101.7138478756
batch reward last col mean 0.49587613344192505 first col mean 0.5989797115325928 all mean 0.5524431467056274
0.0568164698779583 0.056816466152668
rl training, epoch5, iter0, batch363/1133, batch loss:0.056816466152668, Training time:71118.73088240623
batch reward last col mean 0.5234545469284058 first col mean 0.620106041431427 all mean 0.5492446422576904
0.0628032386302948 0.0628032311797142
rl training, epoch5, iter0, batch364/1133, batch loss:0.0628032311797142, Training time:71136.11626911163
batch reward last col mean 0.5141078233718872 first col mean 0.6294887661933899 all mean 0.5621170401573181
0.04663710668683052 0.04663710296154022
rl training, epoch5, iter0, batch365/1133, batch loss:0.04663710296154022, Training time:71153.56453442574
batch reward last col mean 0.5873501300811768 first col mean 0.6263158321380615 all mean 0.5851989984512329
0.036598023027181625 0.036598026752471924
rl training, epoch5, iter0, batch366/1133, batch loss:0.036598026752471924, Training time:71170.10135769844
batch reward last col mean 0.6094973683357239 first col mean 0.6308138370513916 all mean 0.6154168844223022
0.030940720811486244 0.030940713360905647
rl training, epoch5, iter0, batch367/1133, batch loss:0.030940713360905647, Training time:71186.54635214806
batch reward last col mean 0.6130289435386658 first col mean 0.630644679069519 all mean 0.61531662940979
0.04854804277420044 0.048548031598329544
rl training, epoch5, iter0, batch368/1133, batch loss:0.048548031598329544, Training time:71203.01259803772
batch reward last col mean 0.6340639591217041 first col mean 0.6348133087158203 all mean 0.6475443243980408
0.0374412015080452 0.0374411977827549
rl training, epoch5, iter0, batch369/1133, batch loss:0.0374411977827549, Training time:71219.48478889465
batch reward last col mean 0.6101984977722168 first col mean 0.6197026968002319 all mean 0.6134530901908875
0.024161357432603836 0.024161355569958687
rl training, epoch5, iter0, batch370/1133, batch loss:0.024161355569958687, Training time:71236.02387928963
batch reward last col mean 0.6181796789169312 first col mean 0.6279154419898987 all mean 0.6154751777648926
0.024739040061831474 0.024739030748605728
rl training, epoch5, iter0, batch371/1133, batch loss:0.024739030748605728, Training time:71252.32722640038
batch reward last col mean 0.6443548798561096 first col mean 0.6534038782119751 all mean 0.6438146829605103
0.025726158171892166 0.025726154446601868
rl training, epoch5, iter0, batch372/1133, batch loss:0.025726154446601868, Training time:71268.9963388443
batch reward last col mean 0.6199017763137817 first col mean 0.6399048566818237 all mean 0.6340802907943726
0.02086634561419487 0.020866338163614273
rl training, epoch5, iter0, batch373/1133, batch loss:0.020866338163614273, Training time:71285.61617541313
batch reward last col mean 0.5818873047828674 first col mean 0.599396824836731 all mean 0.5943238139152527
0.018627364188432693 0.018627360463142395
rl training, epoch5, iter0, batch374/1133, batch loss:0.018627360463142395, Training time:71302.06134414673
batch reward last col mean 0.6325448751449585 first col mean 0.6336462497711182 all mean 0.6301527619361877
0.014493300579488277 0.014493298716843128
rl training, epoch5, iter0, batch375/1133, batch loss:0.014493298716843128, Training time:71318.59242653847
batch reward last col mean 0.6088370084762573 first col mean 0.6190681457519531 all mean 0.6131946444511414
0.019612552598118782 0.019612543284893036
rl training, epoch5, iter0, batch376/1133, batch loss:0.019612543284893036, Training time:71334.97621440887
batch reward last col mean 0.647310733795166 first col mean 0.6597679257392883 all mean 0.6550850868225098
0.007617830764502287 0.007617820054292679
rl training, epoch5, iter0, batch377/1133, batch loss:0.007617820054292679, Training time:71351.2986137867
batch reward last col mean 0.6614126563072205 first col mean 0.6663132905960083 all mean 0.6556746959686279
0.010712004266679287 0.010711999610066414
rl training, epoch5, iter0, batch378/1133, batch loss:0.010711999610066414, Training time:71367.72972249985
batch reward last col mean 0.600513219833374 first col mean 0.5961350798606873 all mean 0.601327121257782
0.010036990977823734 0.010036985389888287
rl training, epoch5, iter0, batch379/1133, batch loss:0.010036985389888287, Training time:71384.00712251663
batch reward last col mean 0.6201986074447632 first col mean 0.6302037239074707 all mean 0.6298117637634277
0.005321570206433535 0.0053215608932077885
rl training, epoch5, iter0, batch380/1133, batch loss:0.0053215608932077885, Training time:71400.09754419327
batch reward last col mean 0.6640474200248718 first col mean 0.6657307147979736 all mean 0.665550172328949
0.010734928771853447 0.01073492132127285
rl training, epoch5, iter0, batch381/1133, batch loss:0.01073492132127285, Training time:71416.29149699211
batch reward last col mean 0.5992761850357056 first col mean 0.6079689264297485 all mean 0.6019473075866699
0.004848015960305929 0.004848004784435034
rl training, epoch5, iter0, batch382/1133, batch loss:0.004848004784435034, Training time:71432.3700594902
batch reward last col mean 0.6167011857032776 first col mean 0.6465641260147095 all mean 0.6303567886352539
0.007243713364005089 0.007243704982101917
rl training, epoch5, iter0, batch383/1133, batch loss:0.007243704982101917, Training time:71448.72950696945
batch reward last col mean 0.6684856414794922 first col mean 0.6688475012779236 all mean 0.6669801473617554
0.004125031642615795 0.0041250200010836124
rl training, epoch5, iter0, batch384/1133, batch loss:0.0041250200010836124, Training time:71464.96658539772
batch reward last col mean 0.6038164496421814 first col mean 0.5896598696708679 all mean 0.6001655459403992
0.008149477653205395 0.00814946461468935
rl training, epoch5, iter0, batch385/1133, batch loss:0.00814946461468935, Training time:71481.15502762794
batch reward last col mean 0.6251943111419678 first col mean 0.6353371739387512 all mean 0.6280109286308289
0.008555489592254162 0.008555472828447819
rl training, epoch5, iter0, batch386/1133, batch loss:0.008555472828447819, Training time:71497.2646214962
batch reward last col mean 0.654434084892273 first col mean 0.6661108732223511 all mean 0.661346435546875
0.007441364228725433 0.007441349793225527
rl training, epoch5, iter0, batch387/1133, batch loss:0.007441349793225527, Training time:71513.48811984062
batch reward last col mean 0.6045808792114258 first col mean 0.6181264519691467 all mean 0.6115842461585999
0.0009952306281775236 0.0009952132822945714
rl training, epoch5, iter0, batch388/1133, batch loss:0.0009952132822945714, Training time:71529.75977635384
batch reward last col mean 0.5980356335639954 first col mean 0.6050450205802917 all mean 0.6008630394935608
0.003395595820620656 0.0033955788239836693
rl training, epoch5, iter0, batch389/1133, batch loss:0.0033955788239836693, Training time:71546.02273225784
batch reward last col mean 0.6528685092926025 first col mean 0.6506076455116272 all mean 0.6530346870422363
0.01065511628985405 0.010655106976628304
rl training, epoch5, iter0, batch390/1133, batch loss:0.010655106976628304, Training time:71562.32219266891
batch reward last col mean 0.6690991520881653 first col mean 0.6566610336303711 all mean 0.6626866459846497
0.00739576481282711 0.007395748980343342
rl training, epoch5, iter0, batch391/1133, batch loss:0.007395748980343342, Training time:71578.77551603317
batch reward last col mean 0.6606669425964355 first col mean 0.667724609375 all mean 0.6650782823562622
0.004550899378955364 0.00455088634043932
rl training, epoch5, iter0, batch392/1133, batch loss:0.00455088634043932, Training time:71595.05632805824
batch reward last col mean 0.6176856756210327 first col mean 0.614331066608429 all mean 0.6173179745674133
0.007091817911714315 0.00709180161356926
rl training, epoch5, iter0, batch393/1133, batch loss:0.00709180161356926, Training time:71611.54307103157
batch reward last col mean 0.6625983715057373 first col mean 0.6776273250579834 all mean 0.668859601020813
0.003347031306475401 0.003347015706822276
rl training, epoch5, iter0, batch394/1133, batch loss:0.003347015706822276, Training time:71627.86148071289
batch reward last col mean 0.6880049705505371 first col mean 0.683713972568512 all mean 0.6860367059707642
0.005878360476344824 0.0058783418498933315
rl training, epoch5, iter0, batch395/1133, batch loss:0.0058783418498933315, Training time:71644.02715730667
batch reward last col mean 0.6388869881629944 first col mean 0.6415706276893616 all mean 0.637299120426178
0.0025369012728333473 0.0025368849746882915
rl training, epoch5, iter0, batch396/1133, batch loss:0.0025368849746882915, Training time:71660.28809833527
batch reward last col mean 0.653367817401886 first col mean 0.6513828039169312 all mean 0.6498550772666931
0.007674012333154678 0.007673995569348335
rl training, epoch5, iter0, batch397/1133, batch loss:0.007673995569348335, Training time:71676.71177625656
batch reward last col mean 0.6525411009788513 first col mean 0.6569076180458069 all mean 0.6533069610595703
0.0036348968278616667 0.0036348728463053703
rl training, epoch5, iter0, batch398/1133, batch loss:0.0036348728463053703, Training time:71692.88579106331
batch reward last col mean 0.6445826292037964 first col mean 0.645906925201416 all mean 0.6426655054092407
0.0062842718325555325 0.006284249015152454
rl training, epoch5, iter0, batch399/1133, batch loss:0.006284249015152454, Training time:71709.26319003105
batch reward last col mean 0.6249362230300903 first col mean 0.6426163911819458 all mean 0.6286152601242065
0.00506964698433876 0.00506962975487113
rl training, epoch5, iter0, batch400/1133, batch loss:0.00506962975487113, Training time:71725.61559605598
batch reward last col mean 0.6098346710205078 first col mean 0.62591552734375 all mean 0.6140673756599426
0.004098070785403252 0.004098049830645323
rl training, epoch5, iter0, batch401/1133, batch loss:0.004098049830645323, Training time:71741.7033958435
batch reward last col mean 0.6212579607963562 first col mean 0.6176505088806152 all mean 0.6205034852027893
0.005157328676432371 0.0051573109813034534
rl training, epoch5, iter0, batch402/1133, batch loss:0.0051573109813034534, Training time:71757.61237096786
batch reward last col mean 0.6228214502334595 first col mean 0.6223750114440918 all mean 0.6224902272224426
0.0044198473915457726 0.0044198306277394295
rl training, epoch5, iter0, batch403/1133, batch loss:0.0044198306277394295, Training time:71773.55753135681
batch reward last col mean 0.6055904626846313 first col mean 0.6006155014038086 all mean 0.6066999435424805
0.008194307796657085 0.008194285444915295
rl training, epoch5, iter0, batch404/1133, batch loss:0.008194285444915295, Training time:71789.4738099575
batch reward last col mean 0.6618710160255432 first col mean 0.6625352501869202 all mean 0.6627210378646851
0.0024513150565326214 0.0024512994568794966
rl training, epoch5, iter0, batch405/1133, batch loss:0.0024512994568794966, Training time:71805.42505550385
batch reward last col mean 0.6426333785057068 first col mean 0.6508951187133789 all mean 0.6488183736801147
0.005223231855779886 0.0052232141606509686
rl training, epoch5, iter0, batch406/1133, batch loss:0.0052232141606509686, Training time:71821.32663726807
batch reward last col mean 0.5719315409660339 first col mean 0.5849770307540894 all mean 0.5799160003662109
0.004182429984211922 0.004182411823421717
rl training, epoch5, iter0, batch407/1133, batch loss:0.004182411823421717, Training time:71837.27620220184
batch reward last col mean 0.6116195917129517 first col mean 0.6166983246803284 all mean 0.6142933964729309
0.004023610148578882 0.004023589659482241
rl training, epoch5, iter0, batch408/1133, batch loss:0.004023589659482241, Training time:71853.32069897652
batch reward last col mean 0.5757594108581543 first col mean 0.587533712387085 all mean 0.5789273381233215
0.0030907292384654284 0.00309071596711874
rl training, epoch5, iter0, batch409/1133, batch loss:0.00309071596711874, Training time:71869.37693572044
batch reward last col mean 0.6023380160331726 first col mean 0.5948286056518555 all mean 0.5958432555198669
0.004113916307687759 0.004113892558962107
rl training, epoch5, iter0, batch410/1133, batch loss:0.004113892558962107, Training time:71885.35391139984
batch reward last col mean 0.6408520340919495 first col mean 0.6354678273200989 all mean 0.6397892236709595
0.00164327141828835 0.0016432502306997776
rl training, epoch5, iter0, batch411/1133, batch loss:0.0016432502306997776, Training time:71901.35591673851
batch reward last col mean 0.6838263869285583 first col mean 0.6818770170211792 all mean 0.6816672682762146
0.004123589489609003 0.004123563878238201
rl training, epoch5, iter0, batch412/1133, batch loss:0.004123563878238201, Training time:71917.36701273918
batch reward last col mean 0.6341337561607361 first col mean 0.6417559385299683 all mean 0.6382824182510376
0.002079997444525361 0.002079979283735156
rl training, epoch5, iter0, batch413/1133, batch loss:0.002079979283735156, Training time:71933.31897521019
batch reward last col mean 0.6346622705459595 first col mean 0.6389428377151489 all mean 0.6363169550895691
0.005385504104197025 0.005385486409068108
rl training, epoch5, iter0, batch414/1133, batch loss:0.005385486409068108, Training time:71949.38794279099
batch reward last col mean 0.6286298036575317 first col mean 0.6314113140106201 all mean 0.6321548819541931
0.001910060760565102 0.0019100410863757133
rl training, epoch5, iter0, batch415/1133, batch loss:0.0019100410863757133, Training time:71965.33614039421
batch reward last col mean 0.6127765774726868 first col mean 0.6196847558021545 all mean 0.6137282848358154
0.0029583151917904615 0.0029582902789115906
rl training, epoch5, iter0, batch416/1133, batch loss:0.0029582902789115906, Training time:71981.23665738106
batch reward last col mean 0.6276964545249939 first col mean 0.6376392841339111 all mean 0.634012758731842
0.006969431880861521 0.006969412323087454
rl training, epoch5, iter0, batch417/1133, batch loss:0.006969412323087454, Training time:71997.17321038246
batch reward last col mean 0.6328232288360596 first col mean 0.6376028060913086 all mean 0.6361750364303589
0.004781939089298248 0.004781925119459629
rl training, epoch5, iter0, batch418/1133, batch loss:0.004781925119459629, Training time:72013.0773665905
batch reward last col mean 0.6219446063041687 first col mean 0.6337267756462097 all mean 0.6268345713615417
0.0030562113970518112 0.0030561950989067554
rl training, epoch5, iter0, batch419/1133, batch loss:0.0030561950989067554, Training time:72029.05763101578
batch reward last col mean 0.6420843005180359 first col mean 0.6385987997055054 all mean 0.6410150527954102
0.0033764110412448645 0.0033763907849788666
rl training, epoch5, iter0, batch420/1133, batch loss:0.0033763907849788666, Training time:72045.11706590652
batch reward last col mean 0.6417535543441772 first col mean 0.6413500308990479 all mean 0.6401370167732239
0.002223696792498231 0.0022236742079257965
rl training, epoch5, iter0, batch421/1133, batch loss:0.0022236742079257965, Training time:72061.05350470543
batch reward last col mean 0.6585415005683899 first col mean 0.6597069501876831 all mean 0.6566336750984192
0.003635900793597102 0.003635877976194024
rl training, epoch5, iter0, batch422/1133, batch loss:0.003635877976194024, Training time:72077.00786757469
batch reward last col mean 0.6706838607788086 first col mean 0.6634247303009033 all mean 0.6683697700500488
0.00773579441010952 0.00773577718064189
rl training, epoch5, iter0, batch423/1133, batch loss:0.00773577718064189, Training time:72092.95346879959
batch reward last col mean 0.6497063636779785 first col mean 0.6536321640014648 all mean 0.6498568654060364
0.0017726704245433211 0.0017726505175232887
rl training, epoch5, iter0, batch424/1133, batch loss:0.0017726505175232887, Training time:72108.85210752487
batch reward last col mean 0.6317259073257446 first col mean 0.6363275051116943 all mean 0.6330415606498718
0.004609264433383942 0.00460925092920661
rl training, epoch5, iter0, batch425/1133, batch loss:0.00460925092920661, Training time:72125.16856741905
batch reward last col mean 0.6196820735931396 first col mean 0.6194474697113037 all mean 0.6195255517959595
0.002811167389154434 0.0028111408464610577
rl training, epoch5, iter0, batch426/1133, batch loss:0.0028111408464610577, Training time:72141.18267297745
batch reward last col mean 0.633278489112854 first col mean 0.6461338996887207 all mean 0.6368868947029114
0.0018380506662651896 0.001838026917539537
rl training, epoch5, iter0, batch427/1133, batch loss:0.001838026917539537, Training time:72157.24746108055
batch reward last col mean 0.613635778427124 first col mean 0.6128500699996948 all mean 0.6124839186668396
0.004411014262586832 0.004410992842167616
rl training, epoch5, iter0, batch428/1133, batch loss:0.004410992842167616, Training time:72173.60664963722
batch reward last col mean 0.5994058847427368 first col mean 0.6057725548744202 all mean 0.6042944192886353
0.005833622068166733 0.005833600647747517
rl training, epoch5, iter0, batch429/1133, batch loss:0.005833600647747517, Training time:72189.80484032631
batch reward last col mean 0.6533026099205017 first col mean 0.6506760120391846 all mean 0.6502025723457336
0.0023059288505464792 0.0023059083614498377
rl training, epoch5, iter0, batch430/1133, batch loss:0.0023059083614498377, Training time:72205.9828927517
batch reward last col mean 0.5990626215934753 first col mean 0.6117859482765198 all mean 0.6074317097663879
0.001745350076816976 0.0017453284235671163
rl training, epoch5, iter0, batch431/1133, batch loss:0.0017453284235671163, Training time:72222.04573392868
batch reward last col mean 0.645560085773468 first col mean 0.6528507471084595 all mean 0.6504979729652405
0.0033973734825849533 0.003397352760657668
rl training, epoch5, iter0, batch432/1133, batch loss:0.003397352760657668, Training time:72238.10529708862
batch reward last col mean 0.6544599533081055 first col mean 0.651191234588623 all mean 0.6541538238525391
0.0029661443550139666 0.0029661257285624743
rl training, epoch5, iter0, batch433/1133, batch loss:0.0029661257285624743, Training time:72254.06613731384
batch reward last col mean 0.6626650094985962 first col mean 0.667219340801239 all mean 0.6639864444732666
0.0032622399739921093 0.003262214595451951
rl training, epoch5, iter0, batch434/1133, batch loss:0.003262214595451951, Training time:72270.03975439072
batch reward last col mean 0.6325082778930664 first col mean 0.6272334456443787 all mean 0.6311834454536438
0.0025668595917522907 0.0025668388698250055
rl training, epoch5, iter0, batch435/1133, batch loss:0.0025668388698250055, Training time:72286.09544825554
batch reward last col mean 0.6676726341247559 first col mean 0.6772105693817139 all mean 0.6739060878753662
0.0017136308597400784 0.0017136073438450694
rl training, epoch5, iter0, batch436/1133, batch loss:0.0017136073438450694, Training time:72302.09644079208
batch reward last col mean 0.6639568209648132 first col mean 0.6690064668655396 all mean 0.6704020500183105
0.002870194846764207 0.002870163880288601
rl training, epoch5, iter0, batch437/1133, batch loss:0.002870163880288601, Training time:72318.12682557106
batch reward last col mean 0.6086441278457642 first col mean 0.6034446358680725 all mean 0.6050301790237427
0.004597458988428116 0.004597438499331474
rl training, epoch5, iter0, batch438/1133, batch loss:0.004597438499331474, Training time:72334.10266947746
batch reward last col mean 0.6524597406387329 first col mean 0.654118537902832 all mean 0.6508668065071106
0.0041066319681704044 0.004106608219444752
rl training, epoch5, iter0, batch439/1133, batch loss:0.004106608219444752, Training time:72350.25086379051
batch reward last col mean 0.6252803206443787 first col mean 0.6273022294044495 all mean 0.626129686832428
0.001132665784098208 0.0011326418025419116
rl training, epoch5, iter0, batch440/1133, batch loss:0.0011326418025419116, Training time:72366.26820230484
batch reward last col mean 0.7048580646514893 first col mean 0.7165448665618896 all mean 0.7080038189888
0.004529712721705437 0.004529684782028198
rl training, epoch5, iter0, batch441/1133, batch loss:0.004529684782028198, Training time:72382.26123976707
batch reward last col mean 0.6795076131820679 first col mean 0.6798449754714966 all mean 0.6793602705001831
0.0029681480955332518 0.002968129701912403
rl training, epoch5, iter0, batch442/1133, batch loss:0.002968129701912403, Training time:72398.29815888405
batch reward last col mean 0.6543514132499695 first col mean 0.6553373336791992 all mean 0.6578356623649597
0.004730953834950924 0.004730932414531708
rl training, epoch5, iter0, batch443/1133, batch loss:0.004730932414531708, Training time:72414.28404521942
batch reward last col mean 0.6409481167793274 first col mean 0.6305556893348694 all mean 0.636451244354248
0.004927733447402716 0.0049277180805802345
rl training, epoch5, iter0, batch444/1133, batch loss:0.0049277180805802345, Training time:72430.30867671967
batch reward last col mean 0.6451169848442078 first col mean 0.6418994069099426 all mean 0.6423148512840271
0.0068151517771184444 0.006815125234425068
rl training, epoch5, iter0, batch445/1133, batch loss:0.006815125234425068, Training time:72446.44330048561
batch reward last col mean 0.6412948369979858 first col mean 0.645656943321228 all mean 0.6431388258934021
0.0028551837895065546 0.0028551623690873384
rl training, epoch5, iter0, batch446/1133, batch loss:0.0028551623690873384, Training time:72462.60757398605
batch reward last col mean 0.6432945132255554 first col mean 0.6471846699714661 all mean 0.6457123160362244
0.0022115714382380247 0.002211549784988165
rl training, epoch5, iter0, batch447/1133, batch loss:0.002211549784988165, Training time:72478.71547102928
batch reward last col mean 0.6399855613708496 first col mean 0.6382495760917664 all mean 0.6392664313316345
0.004648101050406694 0.004648074507713318
rl training, epoch5, iter0, batch448/1133, batch loss:0.004648074507713318, Training time:72494.8895816803
batch reward last col mean 0.6483415961265564 first col mean 0.6492897272109985 all mean 0.648505449295044
0.0015828729374334216 0.001582855125889182
rl training, epoch5, iter0, batch449/1133, batch loss:0.001582855125889182, Training time:72511.06741404533
batch reward last col mean 0.6460924744606018 first col mean 0.6621196866035461 all mean 0.6518286466598511
0.007456577382981777 0.007456551771610975
rl training, epoch5, iter0, batch450/1133, batch loss:0.007456551771610975, Training time:72527.07254648209
batch reward last col mean 0.6712279915809631 first col mean 0.6772216558456421 all mean 0.6741264462471008
0.0015441131545230746 0.0015440881252288818
rl training, epoch5, iter0, batch451/1133, batch loss:0.0015440881252288818, Training time:72543.05135273933
batch reward last col mean 0.6798096299171448 first col mean 0.6874905228614807 all mean 0.6869259476661682
0.0026415924075990915 0.0026415707543492317
rl training, epoch5, iter0, batch452/1133, batch loss:0.0026415707543492317, Training time:72558.90636372566
batch reward last col mean 0.5650270581245422 first col mean 0.5710539221763611 all mean 0.5680379271507263
0.004152760375291109 0.004152736160904169
rl training, epoch5, iter0, batch453/1133, batch loss:0.004152736160904169, Training time:72574.84822750092
batch reward last col mean 0.6286778450012207 first col mean 0.6212819814682007 all mean 0.6261560320854187
0.0035354676656425 0.003535447409376502
rl training, epoch5, iter0, batch454/1133, batch loss:0.003535447409376502, Training time:72590.85856795311
batch reward last col mean 0.6197779178619385 first col mean 0.6310200095176697 all mean 0.6219363212585449
0.0052955071441829205 0.005295488052070141
rl training, epoch5, iter0, batch455/1133, batch loss:0.005295488052070141, Training time:72607.0876557827
batch reward last col mean 0.6551696062088013 first col mean 0.6577835083007812 all mean 0.6574103832244873
0.00143680430483073 0.0014367880066856742
rl training, epoch5, iter0, batch456/1133, batch loss:0.0014367880066856742, Training time:72623.03636217117
batch reward last col mean 0.6240242719650269 first col mean 0.6218346953392029 all mean 0.6244057416915894
0.0019904589280486107 0.001990439835935831
rl training, epoch5, iter0, batch457/1133, batch loss:0.001990439835935831, Training time:72639.18511390686
batch reward last col mean 0.6635510921478271 first col mean 0.6515686511993408 all mean 0.6568374633789062
0.0038729412481188774 0.00387291656807065
rl training, epoch5, iter0, batch458/1133, batch loss:0.00387291656807065, Training time:72655.20531201363
batch reward last col mean 0.6365340352058411 first col mean 0.6364226341247559 all mean 0.636023759841919
0.0020380564965307713 0.0020380259957164526
rl training, epoch5, iter0, batch459/1133, batch loss:0.0020380259957164526, Training time:72671.33133482933
batch reward last col mean 0.7161344885826111 first col mean 0.7217922210693359 all mean 0.716086208820343
0.006257148925215006 0.006257123313844204
rl training, epoch5, iter0, batch460/1133, batch loss:0.006257123313844204, Training time:72687.32464122772
batch reward last col mean 0.6528630256652832 first col mean 0.6637033224105835 all mean 0.6558233499526978
0.00498784938827157 0.004987830296158791
rl training, epoch5, iter0, batch461/1133, batch loss:0.004987830296158791, Training time:72703.21762490273
batch reward last col mean 0.6331115961074829 first col mean 0.6385360956192017 all mean 0.6367922425270081
0.004708857275545597 0.004708839580416679
rl training, epoch5, iter0, batch462/1133, batch loss:0.004708839580416679, Training time:72719.23651194572
batch reward last col mean 0.6240537166595459 first col mean 0.6345115900039673 all mean 0.6267515420913696
0.003120862413197756 0.003120840759947896
rl training, epoch5, iter0, batch463/1133, batch loss:0.003120840759947896, Training time:72735.8173391819
batch reward last col mean 0.6382516622543335 first col mean 0.6371831893920898 all mean 0.6397588849067688
0.002774059073999524 0.0027740399818867445
rl training, epoch5, iter0, batch464/1133, batch loss:0.0027740399818867445, Training time:72752.10246920586
batch reward last col mean 0.6855577826499939 first col mean 0.6838799715042114 all mean 0.685201108455658
0.004308770410716534 0.004308743868023157
rl training, epoch5, iter0, batch465/1133, batch loss:0.004308743868023157, Training time:72768.07923793793
batch reward last col mean 0.6272007822990417 first col mean 0.628385066986084 all mean 0.6274111866950989
0.0020513064227998257 0.0020512882620096207
rl training, epoch5, iter0, batch466/1133, batch loss:0.0020512882620096207, Training time:72784.1799890995
batch reward last col mean 0.6245814561843872 first col mean 0.6298530101776123 all mean 0.6254095435142517
0.004118083510547876 0.004118063487112522
rl training, epoch5, iter0, batch467/1133, batch loss:0.004118063487112522, Training time:72800.25768375397
batch reward last col mean 0.6410225629806519 first col mean 0.6417202949523926 all mean 0.637697160243988
0.005944916512817144 0.005944892764091492
rl training, epoch5, iter0, batch468/1133, batch loss:0.005944892764091492, Training time:72816.16431546211
batch reward last col mean 0.6858626008033752 first col mean 0.6846864223480225 all mean 0.6868805289268494
0.004111769609153271 0.004111750982701778
rl training, epoch5, iter0, batch469/1133, batch loss:0.004111750982701778, Training time:72832.08064842224
batch reward last col mean 0.6401487588882446 first col mean 0.6424745917320251 all mean 0.6428869962692261
0.0037403700407594442 0.003740347223356366
rl training, epoch5, iter0, batch470/1133, batch loss:0.003740347223356366, Training time:72848.34771466255
batch reward last col mean 0.6583671569824219 first col mean 0.6470653414726257 all mean 0.6560903191566467
0.005132422316819429 0.005132395774126053
rl training, epoch5, iter0, batch471/1133, batch loss:0.005132395774126053, Training time:72864.4012722969
batch reward last col mean 0.6450309753417969 first col mean 0.6450435519218445 all mean 0.6447161436080933
0.0003244834078941494 0.00032445817487314343
rl training, epoch5, iter0, batch472/1133, batch loss:0.00032445817487314343, Training time:72880.45759797096
batch reward last col mean 0.6484503746032715 first col mean 0.6444066762924194 all mean 0.6473553776741028
0.001980286557227373 0.001980268396437168
rl training, epoch5, iter0, batch473/1133, batch loss:0.001980268396437168, Training time:72896.63987708092
batch reward last col mean 0.6265119314193726 first col mean 0.6337207555770874 all mean 0.6301490664482117
0.004479542374610901 0.004479524679481983
rl training, epoch5, iter0, batch474/1133, batch loss:0.004479524679481983, Training time:72912.81251430511
batch reward last col mean 0.5900689363479614 first col mean 0.5875221490859985 all mean 0.5849353075027466
0.005114267114549875 0.005114245694130659
rl training, epoch5, iter0, batch475/1133, batch loss:0.005114245694130659, Training time:72929.04783511162
batch reward last col mean 0.6537164449691772 first col mean 0.6519405841827393 all mean 0.6515886187553406
0.0017014459008350968 0.0017014212207868695
rl training, epoch5, iter0, batch476/1133, batch loss:0.0017014212207868695, Training time:72945.31542444229
batch reward last col mean 0.6948883533477783 first col mean 0.692583441734314 all mean 0.6931412816047668
0.004382448736578226 0.004382426850497723
rl training, epoch5, iter0, batch477/1133, batch loss:0.004382426850497723, Training time:72961.59656405449
batch reward last col mean 0.6726247668266296 first col mean 0.6738636493682861 all mean 0.673836886882782
0.006093891803175211 0.006093872245401144
rl training, epoch5, iter0, batch478/1133, batch loss:0.006093872245401144, Training time:72977.8798224926
batch reward last col mean 0.6509618759155273 first col mean 0.6459447741508484 all mean 0.6493538022041321
0.0038111242465674877 0.0038111035246402025
rl training, epoch5, iter0, batch479/1133, batch loss:0.0038111035246402025, Training time:72994.09253573418
batch reward last col mean 0.619079053401947 first col mean 0.634292721748352 all mean 0.6221504211425781
0.003201011335477233 0.003200987121090293
rl training, epoch5, iter0, batch480/1133, batch loss:0.003200987121090293, Training time:73010.09948945045
batch reward last col mean 0.6159642934799194 first col mean 0.6166394948959351 all mean 0.6165273785591125
0.0016715135425329208 0.0016714975936338305
rl training, epoch5, iter0, batch481/1133, batch loss:0.0016714975936338305, Training time:73026.36686635017
batch reward last col mean 0.681221604347229 first col mean 0.6848230957984924 all mean 0.6829663515090942
0.008492407388985157 0.008492384105920792
rl training, epoch5, iter0, batch482/1133, batch loss:0.008492384105920792, Training time:73042.24054265022
batch reward last col mean 0.6170918941497803 first col mean 0.6119970083236694 all mean 0.6161729097366333
0.0033552180975675583 0.003355196909978986
rl training, epoch5, iter0, batch483/1133, batch loss:0.003355196909978986, Training time:73059.01507592201
batch reward last col mean 0.6388659477233887 first col mean 0.6370629668235779 all mean 0.638757586479187
0.0003480555897112936 0.00034803448943421245
rl training, epoch5, iter0, batch484/1133, batch loss:0.00034803448943421245, Training time:73075.35336923599
batch reward last col mean 0.6327618360519409 first col mean 0.6405474543571472 all mean 0.6310310959815979
0.0038099295925348997 0.003809902351349592
rl training, epoch5, iter0, batch485/1133, batch loss:0.003809902351349592, Training time:73091.79952025414
batch reward last col mean 0.6817128658294678 first col mean 0.6796416640281677 all mean 0.6809890270233154
0.0045929248444736 0.00459290063008666
rl training, epoch5, iter0, batch486/1133, batch loss:0.00459290063008666, Training time:73108.1259689331
batch reward last col mean 0.6467503309249878 first col mean 0.6534637212753296 all mean 0.6490339040756226
0.003085126867517829 0.0030851059127599
rl training, epoch5, iter0, batch487/1133, batch loss:0.0030851059127599, Training time:73124.48944067955
batch reward last col mean 0.632184624671936 first col mean 0.6231337189674377 all mean 0.6309213638305664
0.004964736290276051 0.004964714869856834
rl training, epoch5, iter0, batch488/1133, batch loss:0.004964714869856834, Training time:73140.92192721367
batch reward last col mean 0.5823367238044739 first col mean 0.5694544911384583 all mean 0.5804427862167358
0.004406061954796314 0.004406041000038385
rl training, epoch5, iter0, batch489/1133, batch loss:0.004406041000038385, Training time:73157.26825356483
batch reward last col mean 0.6658586263656616 first col mean 0.6698010563850403 all mean 0.6652479767799377
0.002842248184606433 0.0028422323521226645
rl training, epoch5, iter0, batch490/1133, batch loss:0.0028422323521226645, Training time:73173.61549091339
batch reward last col mean 0.6631454825401306 first col mean 0.6556556224822998 all mean 0.6566787362098694
0.0036487916950136423 0.003648767014965415
rl training, epoch5, iter0, batch491/1133, batch loss:0.003648767014965415, Training time:73189.9650645256
batch reward last col mean 0.6581156253814697 first col mean 0.6522315740585327 all mean 0.6527978181838989
0.0036033825017511845 0.0036033529322594404
rl training, epoch5, iter0, batch492/1133, batch loss:0.0036033529322594404, Training time:73206.33901262283
batch reward last col mean 0.5966690182685852 first col mean 0.5979735851287842 all mean 0.5960204601287842
0.001269815256819129 0.001269795699045062
rl training, epoch5, iter0, batch493/1133, batch loss:0.001269795699045062, Training time:73222.73718738556
batch reward last col mean 0.629837155342102 first col mean 0.6287935972213745 all mean 0.6258502006530762
0.0018383427523076534 0.001838325522840023
rl training, epoch5, iter0, batch494/1133, batch loss:0.001838325522840023, Training time:73239.11612391472
batch reward last col mean 0.6176714301109314 first col mean 0.6161694526672363 all mean 0.6165708303451538
0.0025233696214854717 0.0025233535561710596
rl training, epoch5, iter0, batch495/1133, batch loss:0.0025233535561710596, Training time:73255.53169822693
batch reward last col mean 0.6103020906448364 first col mean 0.6058276891708374 all mean 0.608891487121582
0.0006189653649926186 0.0006189457490108907
rl training, epoch5, iter0, batch496/1133, batch loss:0.0006189457490108907, Training time:73272.16383957863
batch reward last col mean 0.6540671586990356 first col mean 0.6479310393333435 all mean 0.6509144902229309
0.004589003510773182 0.0045889816246926785
rl training, epoch5, iter0, batch497/1133, batch loss:0.0045889816246926785, Training time:73288.58336615562
batch reward last col mean 0.6794074773788452 first col mean 0.6799663305282593 all mean 0.6791529655456543
0.0033487367909401655 0.0033487153705209494
rl training, epoch5, iter0, batch498/1133, batch loss:0.0033487153705209494, Training time:73304.95323324203
batch reward last col mean 0.633789598941803 first col mean 0.6388430595397949 all mean 0.6347958445549011
0.0008799348142929375 0.0008799168281257153
rl training, epoch5, iter0, batch499/1133, batch loss:0.0008799168281257153, Training time:73321.65803837776
batch reward last col mean 0.6486785411834717 first col mean 0.6629198789596558 all mean 0.6524609923362732
0.0016076616011559963 0.0016076426254585385
rl training, epoch5, iter0, batch500/1133, batch loss:0.0016076426254585385, Training time:73338.47499203682
batch reward last col mean 0.6791977882385254 first col mean 0.6782736778259277 all mean 0.6788265109062195
0.004137787967920303 0.004137761890888214
rl training, epoch5, iter0, batch501/1133, batch loss:0.004137761890888214, Training time:73355.15263843536
batch reward last col mean 0.6573109030723572 first col mean 0.6552015542984009 all mean 0.6567433476448059
0.0019570598378777504 0.001957037253305316
rl training, epoch5, iter0, batch502/1133, batch loss:0.001957037253305316, Training time:73371.79878544807
batch reward last col mean 0.6325358152389526 first col mean 0.6371043920516968 all mean 0.6356164216995239
0.0018804476130753756 0.0018804242135956883
rl training, epoch5, iter0, batch503/1133, batch loss:0.0018804242135956883, Training time:73388.51074194908
batch reward last col mean 0.7092171907424927 first col mean 0.713053822517395 all mean 0.7094328999519348
0.0012743029510602355 0.0012742799008265138
rl training, epoch5, iter0, batch504/1133, batch loss:0.0012742799008265138, Training time:73405.17230033875
batch reward last col mean 0.6705238819122314 first col mean 0.6733246445655823 all mean 0.6708543300628662
0.003192839678376913 0.003192823613062501
rl training, epoch5, iter0, batch505/1133, batch loss:0.003192823613062501, Training time:73421.64875912666
batch reward last col mean 0.6523228883743286 first col mean 0.6521161794662476 all mean 0.6520140171051025
0.0021820180118083954 0.0021819965913891792
rl training, epoch5, iter0, batch506/1133, batch loss:0.0021819965913891792, Training time:73438.30335021019
batch reward last col mean 0.6145585775375366 first col mean 0.6151117086410522 all mean 0.6148407459259033
0.001609202940016985 0.0016091803554445505
rl training, epoch5, iter0, batch507/1133, batch loss:0.0016091803554445505, Training time:73454.92962574959
batch reward last col mean 0.6257122755050659 first col mean 0.6159460544586182 all mean 0.6183913350105286
0.00365850911475718 0.0036584928166121244
rl training, epoch5, iter0, batch508/1133, batch loss:0.0036584928166121244, Training time:73471.60757923126
batch reward last col mean 0.7086760997772217 first col mean 0.7034993171691895 all mean 0.7055732011795044
0.003039422444999218 0.0030393931083381176
rl training, epoch5, iter0, batch509/1133, batch loss:0.0030393931083381176, Training time:73488.18940806389
batch reward last col mean 0.6490827202796936 first col mean 0.6531675457954407 all mean 0.6500778794288635
0.0029858185444027185 0.0029857938643544912
rl training, epoch5, iter0, batch510/1133, batch loss:0.0029857938643544912, Training time:73504.79976606369
batch reward last col mean 0.6002267003059387 first col mean 0.5909090042114258 all mean 0.5914419293403625
0.00942277628928423 0.009422755800187588
rl training, epoch5, iter0, batch511/1133, batch loss:0.009422755800187588, Training time:73521.28088283539
batch reward last col mean 0.6471974849700928 first col mean 0.6528865098953247 all mean 0.6483029723167419
0.0024399214889854193 0.0024398937821388245
rl training, epoch5, iter0, batch512/1133, batch loss:0.0024398937821388245, Training time:73537.9931268692
batch reward last col mean 0.6212700605392456 first col mean 0.6175156831741333 all mean 0.6203004717826843
0.0020537711679935455 0.0020537436939775944
rl training, epoch5, iter0, batch513/1133, batch loss:0.0020537436939775944, Training time:73554.69448137283
batch reward last col mean 0.672768771648407 first col mean 0.673172116279602 all mean 0.672951877117157
0.0010746805928647518 0.0010746571933850646
rl training, epoch5, iter0, batch514/1133, batch loss:0.0010746571933850646, Training time:73571.32816886902
batch reward last col mean 0.6712691783905029 first col mean 0.663162350654602 all mean 0.6673681735992432
0.002296868711709976 0.002296845195814967
rl training, epoch5, iter0, batch515/1133, batch loss:0.002296845195814967, Training time:73587.85936760902
batch reward last col mean 0.632935643196106 first col mean 0.6345968246459961 all mean 0.6358939409255981
0.0009714983752928674 0.0009714766056276858
rl training, epoch5, iter0, batch516/1133, batch loss:0.0009714766056276858, Training time:73604.34461688995
batch reward last col mean 0.6993395090103149 first col mean 0.6931325197219849 all mean 0.6961953639984131
0.0046484521590173244 0.004648429341614246
rl training, epoch5, iter0, batch517/1133, batch loss:0.004648429341614246, Training time:73620.9811038971
batch reward last col mean 0.632989764213562 first col mean 0.6492840051651001 all mean 0.6437995433807373
0.002569569507613778 0.00256954412907362
rl training, epoch5, iter0, batch518/1133, batch loss:0.00256954412907362, Training time:73637.41102409363
batch reward last col mean 0.6453979015350342 first col mean 0.6589120626449585 all mean 0.6483327150344849
0.001056390581652522 0.0010563666000962257
rl training, epoch5, iter0, batch519/1133, batch loss:0.0010563666000962257, Training time:73653.56198430061
batch reward last col mean 0.6533491611480713 first col mean 0.6476755142211914 all mean 0.6506789922714233
0.0014492541085928679 0.0014492246555164456
rl training, epoch5, iter0, batch520/1133, batch loss:0.0014492246555164456, Training time:73669.70952606201
batch reward last col mean 0.672720193862915 first col mean 0.6735759973526001 all mean 0.6726995706558228
0.003341285977512598 0.0033412582706660032
rl training, epoch5, iter0, batch521/1133, batch loss:0.0033412582706660032, Training time:73686.0213162899
batch reward last col mean 0.5955251455307007 first col mean 0.5935525894165039 all mean 0.5908353924751282
0.003430257784202695 0.003430236829444766
rl training, epoch5, iter0, batch522/1133, batch loss:0.003430236829444766, Training time:73702.32220554352
batch reward last col mean 0.6331242918968201 first col mean 0.6336004137992859 all mean 0.6335921883583069
0.0035392888821661472 0.003539269557222724
rl training, epoch5, iter0, batch523/1133, batch loss:0.003539269557222724, Training time:73718.53598690033
batch reward last col mean 0.6605462431907654 first col mean 0.6532860994338989 all mean 0.6573022603988647
0.0038264375180006027 0.003826417028903961
rl training, epoch5, iter0, batch524/1133, batch loss:0.003826417028903961, Training time:73734.74512314796
batch reward last col mean 0.6654569506645203 first col mean 0.6580510139465332 all mean 0.6604340672492981
0.008628630079329014 0.00862860307097435
rl training, epoch5, iter0, batch525/1133, batch loss:0.00862860307097435, Training time:73751.05220484734
batch reward last col mean 0.6076350212097168 first col mean 0.6121695041656494 all mean 0.6071984767913818
0.004968799185007811 0.004968774970620871
rl training, epoch5, iter0, batch526/1133, batch loss:0.004968774970620871, Training time:73767.46384692192
batch reward last col mean 0.6187899112701416 first col mean 0.6178145408630371 all mean 0.6147373914718628
0.000979841104708612 0.0009798223618417978
rl training, epoch5, iter0, batch527/1133, batch loss:0.0009798223618417978, Training time:73783.81367588043
batch reward last col mean 0.6609222888946533 first col mean 0.6686795949935913 all mean 0.6649637222290039
0.0033517784904688597 0.003351758699864149
rl training, epoch5, iter0, batch528/1133, batch loss:0.003351758699864149, Training time:73799.91693973541
batch reward last col mean 0.5703706741333008 first col mean 0.5815579891204834 all mean 0.5731154680252075
0.007265310734510422 0.0072652921080589294
rl training, epoch5, iter0, batch529/1133, batch loss:0.0072652921080589294, Training time:73816.43071055412
batch reward last col mean 0.6457045078277588 first col mean 0.6428614854812622 all mean 0.64239901304245
0.0023478707298636436 0.00234784628264606
rl training, epoch5, iter0, batch530/1133, batch loss:0.00234784628264606, Training time:73832.85799717903
batch reward last col mean 0.6166751384735107 first col mean 0.6159746646881104 all mean 0.6163898706436157
0.0038970280438661575 0.003897002898156643
rl training, epoch5, iter0, batch531/1133, batch loss:0.003897002898156643, Training time:73849.26494574547
batch reward last col mean 0.6760997772216797 first col mean 0.674063503742218 all mean 0.6760609745979309
0.0012740707024931908 0.0012740569654852152
rl training, epoch5, iter0, batch532/1133, batch loss:0.0012740569654852152, Training time:73865.68643569946
batch reward last col mean 0.6512371301651001 first col mean 0.6465424299240112 all mean 0.6476648449897766
0.0068620056845247746 0.006861979141831398
rl training, epoch5, iter0, batch533/1133, batch loss:0.006861979141831398, Training time:73882.0705037117
batch reward last col mean 0.6323745846748352 first col mean 0.631370484828949 all mean 0.6295843124389648
0.003609862644225359 0.003609840525314212
rl training, epoch5, iter0, batch534/1133, batch loss:0.003609840525314212, Training time:73898.45304965973
batch reward last col mean 0.6309410333633423 first col mean 0.6404812335968018 all mean 0.6354371905326843
0.002557623665779829 0.0025576078332960606
rl training, epoch5, iter0, batch535/1133, batch loss:0.0025576078332960606, Training time:73914.92208623886
batch reward last col mean 0.5895262360572815 first col mean 0.5991100072860718 all mean 0.5952300429344177
0.003388941055163741 0.0033889201004058123
rl training, epoch5, iter0, batch536/1133, batch loss:0.0033889201004058123, Training time:73931.1960504055
batch reward last col mean 0.66982102394104 first col mean 0.6754249930381775 all mean 0.6716471910476685
0.0016322651645168662 0.0016322422306984663
rl training, epoch5, iter0, batch537/1133, batch loss:0.0016322422306984663, Training time:73947.6342086792
batch reward last col mean 0.6608020663261414 first col mean 0.6639482975006104 all mean 0.6619238257408142
0.00444058096036315 0.004440560936927795
rl training, epoch5, iter0, batch538/1133, batch loss:0.004440560936927795, Training time:73964.01264595985
batch reward last col mean 0.5915299654006958 first col mean 0.5846980214118958 all mean 0.5902013182640076
0.004831858444958925 0.0048318421468138695
rl training, epoch5, iter0, batch539/1133, batch loss:0.0048318421468138695, Training time:73980.41872525215
batch reward last col mean 0.6396901607513428 first col mean 0.6408714652061462 all mean 0.6452335119247437
0.0037547615356743336 0.0037547419779002666
rl training, epoch5, iter0, batch540/1133, batch loss:0.0037547419779002666, Training time:73996.75145697594
batch reward last col mean 0.5999032258987427 first col mean 0.6062042117118835 all mean 0.602699339389801
0.002582455286756158 0.002582440385594964
rl training, epoch5, iter0, batch541/1133, batch loss:0.002582440385594964, Training time:74013.18387460709
batch reward last col mean 0.6178001165390015 first col mean 0.6289077401161194 all mean 0.6250333786010742
0.004495833069086075 0.004495816305279732
rl training, epoch5, iter0, batch542/1133, batch loss:0.004495816305279732, Training time:74029.47617435455
batch reward last col mean 0.7164266109466553 first col mean 0.712371289730072 all mean 0.7106382846832275
0.003321226453408599 0.003321195486932993
rl training, epoch5, iter0, batch543/1133, batch loss:0.003321195486932993, Training time:74045.81583619118
batch reward last col mean 0.6058787703514099 first col mean 0.6128270030021667 all mean 0.6081559062004089
0.004941646941006184 0.004941626451909542
rl training, epoch5, iter0, batch544/1133, batch loss:0.004941626451909542, Training time:74062.16828846931
batch reward last col mean 0.592231810092926 first col mean 0.5857715606689453 all mean 0.5913805961608887
0.004913927521556616 0.004913907963782549
rl training, epoch5, iter0, batch545/1133, batch loss:0.004913907963782549, Training time:74078.50947546959
batch reward last col mean 0.6635839939117432 first col mean 0.6658916473388672 all mean 0.6612322926521301
0.0036965771578252316 0.0036965536419302225
rl training, epoch5, iter0, batch546/1133, batch loss:0.0036965536419302225, Training time:74095.00973272324
batch reward last col mean 0.6420942544937134 first col mean 0.6371347308158875 all mean 0.6389809846878052
0.0032127564772963524 0.0032127348240464926
rl training, epoch5, iter0, batch547/1133, batch loss:0.0032127348240464926, Training time:74111.4595541954
batch reward last col mean 0.6724188923835754 first col mean 0.6787732243537903 all mean 0.674138605594635
0.0045050266198813915 0.004505000077188015
rl training, epoch5, iter0, batch548/1133, batch loss:0.004505000077188015, Training time:74128.79190969467
batch reward last col mean 0.6312696933746338 first col mean 0.6235309839248657 all mean 0.6271893382072449
0.007003880105912685 0.007003860082477331
rl training, epoch5, iter0, batch549/1133, batch loss:0.007003860082477331, Training time:74145.07465553284
batch reward last col mean 0.6481856107711792 first col mean 0.6498403549194336 all mean 0.6490153074264526
0.0008685290231369436 0.0008685054490342736
rl training, epoch5, iter0, batch550/1133, batch loss:0.0008685054490342736, Training time:74161.41537666321
batch reward last col mean 0.6436638236045837 first col mean 0.6460390686988831 all mean 0.6448742151260376
0.00129371986258775 0.0012936986749991775
rl training, epoch5, iter0, batch551/1133, batch loss:0.0012936986749991775, Training time:74177.98684930801
batch reward last col mean 0.672603964805603 first col mean 0.6714190244674683 all mean 0.6731804013252258
0.0013611813774332404 0.0013611598405987024
rl training, epoch5, iter0, batch552/1133, batch loss:0.0013611598405987024, Training time:74194.4029288292
batch reward last col mean 0.6643804311752319 first col mean 0.6544876098632812 all mean 0.6606787443161011
0.0022170706652104855 0.002217045985162258
rl training, epoch5, iter0, batch553/1133, batch loss:0.002217045985162258, Training time:74211.01070022583
batch reward last col mean 0.6083066463470459 first col mean 0.6054278612136841 all mean 0.6096275448799133
0.0028727869503200054 0.002872766461223364
rl training, epoch5, iter0, batch554/1133, batch loss:0.002872766461223364, Training time:74227.46909832954
batch reward last col mean 0.6401033997535706 first col mean 0.629263162612915 all mean 0.6356962323188782
0.004132235422730446 0.0041322228498756886
rl training, epoch5, iter0, batch555/1133, batch loss:0.0041322228498756886, Training time:74244.35342383385
batch reward last col mean 0.6693012714385986 first col mean 0.670728325843811 all mean 0.6722080707550049
0.002614794997498393 0.0026147733442485332
rl training, epoch5, iter0, batch556/1133, batch loss:0.0026147733442485332, Training time:74261.16988396645
batch reward last col mean 0.6434609889984131 first col mean 0.661492109298706 all mean 0.6489518284797668
0.004513564519584179 0.004513544961810112
rl training, epoch5, iter0, batch557/1133, batch loss:0.004513544961810112, Training time:74277.76998853683
batch reward last col mean 0.6977967619895935 first col mean 0.6924726366996765 all mean 0.6930643916130066
0.005475182551890612 0.005475157406181097
rl training, epoch5, iter0, batch558/1133, batch loss:0.005475157406181097, Training time:74294.4706337452
batch reward last col mean 0.6707690358161926 first col mean 0.6621556878089905 all mean 0.6642113924026489
0.0024875227827578783 0.0024875039234757423
rl training, epoch5, iter0, batch559/1133, batch loss:0.0024875039234757423, Training time:74310.99592208862
batch reward last col mean 0.6025015115737915 first col mean 0.6148867011070251 all mean 0.6049021482467651
0.00743437185883522 0.007434355095028877
rl training, epoch5, iter0, batch560/1133, batch loss:0.007434355095028877, Training time:74327.55512809753
batch reward last col mean 0.6206541061401367 first col mean 0.6273029446601868 all mean 0.6208397150039673
0.003429871052503586 0.0034298556856811047
rl training, epoch5, iter0, batch561/1133, batch loss:0.0034298556856811047, Training time:74344.06803536415
batch reward last col mean 0.6769130229949951 first col mean 0.6743080019950867 all mean 0.6717531085014343
0.0050201211124658585 0.00502009829506278
rl training, epoch5, iter0, batch562/1133, batch loss:0.00502009829506278, Training time:74360.56060028076
batch reward last col mean 0.6357399225234985 first col mean 0.6344025731086731 all mean 0.6311551332473755
0.002843999769538641 0.0028439736925065517
rl training, epoch5, iter0, batch563/1133, batch loss:0.0028439736925065517, Training time:74377.5968773365
batch reward last col mean 0.6348774433135986 first col mean 0.6476298570632935 all mean 0.6390812993049622
0.005551549140363932 0.005551531910896301
rl training, epoch5, iter0, batch564/1133, batch loss:0.005551531910896301, Training time:74394.77607870102
batch reward last col mean 0.6190091371536255 first col mean 0.6084925532341003 all mean 0.6119614243507385
0.0028392381500452757 0.002839221153408289
rl training, epoch5, iter0, batch565/1133, batch loss:0.002839221153408289, Training time:74411.05118060112
batch reward last col mean 0.6984411478042603 first col mean 0.6816114783287048 all mean 0.6905243396759033
0.005818301811814308 0.0058182887732982635
rl training, epoch5, iter0, batch566/1133, batch loss:0.0058182887732982635, Training time:74427.24516749382
batch reward last col mean 0.6878454089164734 first col mean 0.683672308921814 all mean 0.6862654089927673
0.003780124243348837 0.003780100028961897
rl training, epoch5, iter0, batch567/1133, batch loss:0.003780100028961897, Training time:74443.48700475693
batch reward last col mean 0.6015464067459106 first col mean 0.6100698709487915 all mean 0.6056705713272095
0.00536973774433136 0.005369714926928282
rl training, epoch5, iter0, batch568/1133, batch loss:0.005369714926928282, Training time:74459.76751232147
batch reward last col mean 0.6607151627540588 first col mean 0.6586998701095581 all mean 0.661889910697937
0.00510860700160265 0.005108584184199572
rl training, epoch5, iter0, batch569/1133, batch loss:0.005108584184199572, Training time:74476.08223462105
batch reward last col mean 0.6667846441268921 first col mean 0.6758195757865906 all mean 0.6685687899589539
0.0041533405892550945 0.004153325222432613
rl training, epoch5, iter0, batch570/1133, batch loss:0.004153325222432613, Training time:74492.43118882179
batch reward last col mean 0.6584351062774658 first col mean 0.6464272737503052 all mean 0.6468444466590881
0.0038919460494071245 0.0038919285871088505
rl training, epoch5, iter0, batch571/1133, batch loss:0.0038919285871088505, Training time:74508.69660520554
batch reward last col mean 0.6518439650535583 first col mean 0.6548339128494263 all mean 0.6544017791748047
0.0016968896379694343 0.0016968726413324475
rl training, epoch5, iter0, batch572/1133, batch loss:0.0016968726413324475, Training time:74525.08928728104
batch reward last col mean 0.7244203090667725 first col mean 0.7112361192703247 all mean 0.7153056263923645
0.005584986414760351 0.00558497104793787
rl training, epoch5, iter0, batch573/1133, batch loss:0.00558497104793787, Training time:74541.74567484856
batch reward last col mean 0.6869437098503113 first col mean 0.6751686334609985 all mean 0.680476725101471
0.008213628083467484 0.00821361318230629
rl training, epoch5, iter0, batch574/1133, batch loss:0.00821361318230629, Training time:74558.14446663857
batch reward last col mean 0.681260883808136 first col mean 0.6574715375900269 all mean 0.6708465814590454
0.00493669742718339 0.004936675541102886
rl training, epoch5, iter0, batch575/1133, batch loss:0.004936675541102886, Training time:74574.54286551476
batch reward last col mean 0.6359198689460754 first col mean 0.6376774311065674 all mean 0.6370160579681396
0.004164344631135464 0.004164330195635557
rl training, epoch5, iter0, batch576/1133, batch loss:0.004164330195635557, Training time:74590.95881319046
batch reward last col mean 0.6543072462081909 first col mean 0.6335952281951904 all mean 0.6494521498680115
0.003373759565874934 0.0033737400081008673
rl training, epoch5, iter0, batch577/1133, batch loss:0.0033737400081008673, Training time:74607.22021126747
batch reward last col mean 0.6708412766456604 first col mean 0.6690241098403931 all mean 0.6748318076133728
0.0036103290040045977 0.0036103087477385998
rl training, epoch5, iter0, batch578/1133, batch loss:0.0036103087477385998, Training time:74623.38222193718
batch reward last col mean 0.5705615282058716 first col mean 0.5637363791465759 all mean 0.5644344687461853
0.004188333172351122 0.004188323859125376
rl training, epoch5, iter0, batch579/1133, batch loss:0.004188323859125376, Training time:74639.80362272263
batch reward last col mean 0.6815726161003113 first col mean 0.6828160285949707 all mean 0.6805284023284912
0.006468312814831734 0.006468299776315689
rl training, epoch5, iter0, batch580/1133, batch loss:0.006468299776315689, Training time:74656.30913090706
batch reward last col mean 0.6710608601570129 first col mean 0.6600552201271057 all mean 0.6640406250953674
0.005935520865023136 0.0059355031698942184
rl training, epoch5, iter0, batch581/1133, batch loss:0.0059355031698942184, Training time:74672.83161568642
batch reward last col mean 0.6916497945785522 first col mean 0.6877793073654175 all mean 0.6933074593544006
0.013238894753158092 0.01323887798935175
rl training, epoch5, iter0, batch582/1133, batch loss:0.01323887798935175, Training time:74689.42460227013
batch reward last col mean 0.7194300889968872 first col mean 0.693252682685852 all mean 0.7050747275352478
0.007443701848387718 0.007443686947226524
rl training, epoch5, iter0, batch583/1133, batch loss:0.007443686947226524, Training time:74706.0128724575
batch reward last col mean 0.5925631523132324 first col mean 0.5836926698684692 all mean 0.5907235741615295
0.004260758403688669 0.0042607481591403484
rl training, epoch5, iter0, batch584/1133, batch loss:0.0042607481591403484, Training time:74722.3393163681
batch reward last col mean 0.6511209011077881 first col mean 0.6498066782951355 all mean 0.6466691493988037
0.003265095641836524 0.0032650812063366175
rl training, epoch5, iter0, batch585/1133, batch loss:0.0032650812063366175, Training time:74739.26425218582
batch reward last col mean 0.6649730205535889 first col mean 0.6534693241119385 all mean 0.6589186191558838
0.010660413652658463 0.010660405270755291
rl training, epoch5, iter0, batch586/1133, batch loss:0.010660405270755291, Training time:74755.57406067848
batch reward last col mean 0.6552379131317139 first col mean 0.6381195783615112 all mean 0.6559311151504517
0.007401431445032358 0.007401418872177601
rl training, epoch5, iter0, batch587/1133, batch loss:0.007401418872177601, Training time:74771.91025924683
batch reward last col mean 0.6872286796569824 first col mean 0.6726799011230469 all mean 0.6791486144065857
0.009605471044778824 0.009605459868907928
rl training, epoch5, iter0, batch588/1133, batch loss:0.009605459868907928, Training time:74788.31935310364
batch reward last col mean 0.6554561853408813 first col mean 0.6284104585647583 all mean 0.639595627784729
0.012675631791353226 0.012675619684159756
rl training, epoch5, iter0, batch589/1133, batch loss:0.012675619684159756, Training time:74804.88453149796
batch reward last col mean 0.727954626083374 first col mean 0.7067608833312988 all mean 0.7205369472503662
0.005828189197927713 0.005828177090734243
rl training, epoch5, iter0, batch590/1133, batch loss:0.005828177090734243, Training time:74821.28674030304
batch reward last col mean 0.6890289187431335 first col mean 0.6721924543380737 all mean 0.6815391778945923
0.010125808417797089 0.010125798173248768
rl training, epoch5, iter0, batch591/1133, batch loss:0.010125798173248768, Training time:74837.5761911869
batch reward last col mean 0.6896587014198303 first col mean 0.6670732498168945 all mean 0.6783760786056519
0.008082953281700611 0.008082943968474865
rl training, epoch5, iter0, batch592/1133, batch loss:0.008082943968474865, Training time:74853.93718767166
batch reward last col mean 0.6961451768875122 first col mean 0.666289210319519 all mean 0.6769073009490967
0.009476897306740284 0.009476888924837112
rl training, epoch5, iter0, batch593/1133, batch loss:0.009476888924837112, Training time:74870.42824244499
batch reward last col mean 0.6008118987083435 first col mean 0.579597532749176 all mean 0.5953114032745361
0.007765099406242371 0.007765093352645636
rl training, epoch5, iter0, batch594/1133, batch loss:0.007765093352645636, Training time:74886.76264071465
batch reward last col mean 0.6907622218132019 first col mean 0.6689713597297668 all mean 0.6855184435844421
0.008210471831262112 0.008210457861423492
rl training, epoch5, iter0, batch595/1133, batch loss:0.008210457861423492, Training time:74903.39047431946
batch reward last col mean 0.6709694862365723 first col mean 0.664143443107605 all mean 0.6538745760917664
0.015405717305839062 0.015405705198645592
rl training, epoch5, iter0, batch596/1133, batch loss:0.015405705198645592, Training time:74920.28788614273
batch reward last col mean 0.6950475573539734 first col mean 0.6658813953399658 all mean 0.6813074946403503
0.010543140582740307 0.010543132200837135
rl training, epoch5, iter0, batch597/1133, batch loss:0.010543132200837135, Training time:74937.06994247437
batch reward last col mean 0.6460397243499756 first col mean 0.6153017282485962 all mean 0.6242826581001282
0.013450614176690578 0.01345060858875513
rl training, epoch5, iter0, batch598/1133, batch loss:0.01345060858875513, Training time:74954.01144337654
batch reward last col mean 0.7259089946746826 first col mean 0.7058627009391785 all mean 0.715730607509613
0.013990722596645355 0.013990715146064758
rl training, epoch5, iter0, batch599/1133, batch loss:0.013990715146064758, Training time:74970.68463945389
batch reward last col mean 0.7575385570526123 first col mean 0.693778932094574 all mean 0.7313397526741028
0.02207636833190918 0.022076357156038284
rl training, epoch5, iter0, batch600/1133, batch loss:0.022076357156038284, Training time:74987.4823114872
batch reward last col mean 0.6599893569946289 first col mean 0.6567789316177368 all mean 0.6514211297035217
0.018279224634170532 0.018279213458299637
rl training, epoch5, iter0, batch601/1133, batch loss:0.018279213458299637, Training time:75004.0321905613
batch reward last col mean 0.7199477553367615 first col mean 0.6642950773239136 all mean 0.6947131752967834
0.02132805436849594 0.021328052505850792
rl training, epoch5, iter0, batch602/1133, batch loss:0.021328052505850792, Training time:75020.53093624115
batch reward last col mean 0.7748518586158752 first col mean 0.6867044568061829 all mean 0.7289154529571533
0.021471448242664337 0.021471437066793442
rl training, epoch5, iter0, batch603/1133, batch loss:0.021471437066793442, Training time:75037.01790904999
batch reward last col mean 0.6983752846717834 first col mean 0.6249253749847412 all mean 0.6644001007080078
0.027114417403936386 0.027114415541291237
rl training, epoch5, iter0, batch604/1133, batch loss:0.027114415541291237, Training time:75053.53895664215
batch reward last col mean 0.7253756523132324 first col mean 0.7011343240737915 all mean 0.7170502543449402
0.022378170862793922 0.022378165274858475
rl training, epoch5, iter0, batch605/1133, batch loss:0.022378165274858475, Training time:75070.55632519722
batch reward last col mean 0.7616358995437622 first col mean 0.7201129198074341 all mean 0.7345556616783142
0.03160395845770836 0.03160396218299866
rl training, epoch5, iter0, batch606/1133, batch loss:0.03160396218299866, Training time:75087.18802547455
batch reward last col mean 0.8455002307891846 first col mean 0.7700241804122925 all mean 0.8123602271080017
0.05465461313724518 0.05465460196137428
rl training, epoch5, iter0, batch607/1133, batch loss:0.05465460196137428, Training time:75103.96993803978
batch reward last col mean 0.8196052312850952 first col mean 0.7370409965515137 all mean 0.7882882952690125
0.04378888010978699 0.04378886893391609
rl training, epoch5, iter0, batch608/1133, batch loss:0.04378886893391609, Training time:75120.6379635334
batch reward last col mean 0.8129282593727112 first col mean 0.7326695322990417 all mean 0.7805972099304199
0.06399324536323547 0.06399323791265488
rl training, epoch5, iter0, batch609/1133, batch loss:0.06399323791265488, Training time:75137.32828640938
batch reward last col mean 0.8463184833526611 first col mean 0.769760012626648 all mean 0.8104168176651001
0.06390102207660675 0.06390102207660675
rl training, epoch5, iter0, batch610/1133, batch loss:0.06390102207660675, Training time:75154.07880926132
batch reward last col mean 0.902658224105835 first col mean 0.7908082008361816 all mean 0.8594562411308289
0.08737791329622269 0.08737791329622269
rl training, epoch5, iter0, batch611/1133, batch loss:0.08737791329622269, Training time:75170.82199835777
batch reward last col mean 0.8923113346099854 first col mean 0.8552230596542358 all mean 0.8769426345825195
0.12501710653305054 0.12501710653305054
rl training, epoch5, iter0, batch612/1133, batch loss:0.12501710653305054, Training time:75187.78142905235
batch reward last col mean 0.8810375332832336 first col mean 0.8770332336425781 all mean 0.8772904872894287
0.135835662484169 0.1358356773853302
rl training, epoch5, iter0, batch613/1133, batch loss:0.1358356773853302, Training time:75204.77070260048
batch reward last col mean 0.9230498671531677 first col mean 0.9017819762229919 all mean 0.8988974690437317
0.15351910889148712 0.15351910889148712
rl training, epoch5, iter0, batch614/1133, batch loss:0.15351910889148712, Training time:75221.69948863983
batch reward last col mean 0.8720585107803345 first col mean 0.9044177532196045 all mean 0.892362654209137
0.1640113890171051 0.1640113741159439
rl training, epoch5, iter0, batch615/1133, batch loss:0.1640113741159439, Training time:75238.66553974152
batch reward last col mean 0.9003899097442627 first col mean 0.9099181890487671 all mean 0.9188648462295532
0.18554341793060303 0.18554341793060303
rl training, epoch5, iter0, batch616/1133, batch loss:0.18554341793060303, Training time:75255.46929097176
batch reward last col mean 0.8557683825492859 first col mean 0.9117032289505005 all mean 0.8808758854866028
0.18083646893501282 0.18083645403385162
rl training, epoch5, iter0, batch617/1133, batch loss:0.18083645403385162, Training time:75272.50730872154
batch reward last col mean 0.9097851514816284 first col mean 0.9436813592910767 all mean 0.9200005531311035
0.18757635354995728 0.18757635354995728
rl training, epoch5, iter0, batch618/1133, batch loss:0.18757635354995728, Training time:75289.34953784943
batch reward last col mean 0.8889123201370239 first col mean 0.9294167160987854 all mean 0.9199815392494202
0.20121650397777557 0.20121648907661438
rl training, epoch5, iter0, batch619/1133, batch loss:0.20121648907661438, Training time:75306.0950024128
batch reward last col mean 0.8845332860946655 first col mean 0.9524597525596619 all mean 0.9107232093811035
0.1898842751979828 0.1898842751979828
rl training, epoch5, iter0, batch620/1133, batch loss:0.1898842751979828, Training time:75323.0517115593
batch reward last col mean 0.9074180126190186 first col mean 0.9407263994216919 all mean 0.9262603521347046
0.1759541630744934 0.1759541630744934
rl training, epoch5, iter0, batch621/1133, batch loss:0.1759541630744934, Training time:75339.68603920937
batch reward last col mean 0.9277398586273193 first col mean 0.9494298100471497 all mean 0.9377840757369995
0.17078059911727905 0.17078059911727905
rl training, epoch5, iter0, batch622/1133, batch loss:0.17078059911727905, Training time:75356.41942453384
batch reward last col mean 0.9213992357254028 first col mean 0.9174154996871948 all mean 0.9246391654014587
0.16741204261779785 0.16741204261779785
rl training, epoch5, iter0, batch623/1133, batch loss:0.16741204261779785, Training time:75373.25948548317
batch reward last col mean 0.9489173889160156 first col mean 0.937578022480011 all mean 0.9512098431587219
0.15722061693668365 0.15722061693668365
rl training, epoch5, iter0, batch624/1133, batch loss:0.15722061693668365, Training time:75390.00159811974
RL early break
rl training, epoch 5, iter 0, loss:0.029294436744360428, Training time:75390.00637030602 
rl epoch 5, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.35488842681563226 Time: 139.67016744613647 s
loss of true 0.13777865812064058 loss of gen 0.005651577655838278 loss of other 0.2114581904930555 first score 0.9570593237876892
cur_epoch: 1
D Training Loss: 0.34081313775528455 Time: 138.73434591293335 s
loss of true 0.1343998365229142 loss of gen 0.00020515109748920672 loss of other 0.2062081493180827 first score 6.976629833843617e-07
cur_epoch: 2
D Training Loss: 0.33368896430609823 Time: 143.32610368728638 s
loss of true 0.1303859322289924 loss of gen 0.00010707013284557698 loss of other 0.20319596157201286 first score 7.341700438701082e-07
cur_epoch: 3
D Training Loss: 0.3271013296160778 Time: 142.63607001304626 s
loss of true 0.12812503312845094 loss of gen 9.297262158163149e-05 loss of other 0.19888332343453974 first score 2.5751262455742108e-06
cur_epoch: 4
D Training Loss: 0.3292163439614522 Time: 140.903461933136 s
loss of true 0.12867224757663992 loss of gen 0.0001344558549302493 loss of other 0.2004096404454504 first score 3.5659800801113306e-07
rl epoch 6, begin RL for generator...
batch reward last col mean 0.0004899520426988602 first col mean 1.150770731328521e-05 all mean 0.00026355261798016727
0.00016737192345317453 0.00016737192345317453
rl training, epoch6, iter0, batch0/1133, batch loss:0.00016737192345317453, Training time:76111.38477087021
batch reward last col mean 8.561373397242278e-05 first col mean 7.655904710190953e-07 all mean 2.648615736688953e-05
0.00019612576579675078 0.00019612576579675078
rl training, epoch6, iter0, batch1/1133, batch loss:0.00019612576579675078, Training time:76127.46057200432
batch reward last col mean 4.320549123804085e-05 first col mean 1.1974699418715318e-06 all mean 7.718868437223136e-05
3.3761371014406905e-05 3.3761371014406905e-05
rl training, epoch6, iter0, batch2/1133, batch loss:3.3761371014406905e-05, Training time:76143.57170176506
batch reward last col mean 0.00020503811538219452 first col mean 1.5635545423720032e-05 all mean 0.0002548883785493672
0.00029089595773257315 0.0002908959868364036
rl training, epoch6, iter0, batch3/1133, batch loss:0.0002908959868364036, Training time:76159.69744157791
batch reward last col mean 6.881420267745852e-05 first col mean 6.706894737362745e-07 all mean 6.746419239789248e-05
5.239569873083383e-06 5.239567599346628e-06
rl training, epoch6, iter0, batch4/1133, batch loss:5.239567599346628e-06, Training time:76175.98490023613
batch reward last col mean 3.194469536538236e-05 first col mean 5.860376859345706e-07 all mean 1.0300966096110642e-05
2.5518841084704036e-06 2.551881834733649e-06
rl training, epoch6, iter0, batch5/1133, batch loss:2.551881834733649e-06, Training time:76192.05708861351
batch reward last col mean 6.850036697869655e-06 first col mean 1.8248456399305724e-06 all mean 4.811176950170193e-06
6.600339474971406e-07 6.600332653761143e-07
rl training, epoch6, iter0, batch6/1133, batch loss:6.600332653761143e-07, Training time:76208.38676428795
batch reward last col mean 2.2746532977180323e-06 first col mean 1.085487156160525e-06 all mean 1.0364480658608954e-05
1.6054605112003628e-06 1.6054640354923322e-06
rl training, epoch6, iter0, batch7/1133, batch loss:1.6054640354923322e-06, Training time:76225.06130766869
batch reward last col mean 2.675480118341511e-06 first col mean 1.1758253322113887e-06 all mean 9.254727956431452e-06
9.736153515405022e-06 9.736155334394425e-06
rl training, epoch6, iter0, batch8/1133, batch loss:9.736155334394425e-06, Training time:76241.34598565102
batch reward last col mean 6.769255946892372e-07 first col mean 4.978635388397379e-07 all mean 8.857868465383945e-07
5.838844430172685e-08 5.8388401669162704e-08
rl training, epoch6, iter0, batch9/1133, batch loss:5.8388401669162704e-08, Training time:76257.61704206467
batch reward last col mean 4.100352271052543e-06 first col mean 5.569509085034952e-07 all mean 1.302309556194814e-05
1.1274040616626735e-06 1.127403038481134e-06
rl training, epoch6, iter0, batch10/1133, batch loss:1.127403038481134e-06, Training time:76273.89743590355
batch reward last col mean 3.35799231834244e-05 first col mean 7.333077292059897e-07 all mean 0.00015049910871312022
5.618131035589613e-05 5.618128489004448e-05
rl training, epoch6, iter0, batch11/1133, batch loss:5.618128489004448e-05, Training time:76290.15623521805
batch reward last col mean 4.727020836980955e-07 first col mean 2.5278495741076767e-06 all mean 6.6920561039296445e-06
1.5346208783739712e-06 1.534623038423888e-06
rl training, epoch6, iter0, batch12/1133, batch loss:1.534623038423888e-06, Training time:76306.44293189049
batch reward last col mean 4.9662962737784255e-06 first col mean 4.6216305804591684e-07 all mean 5.647531907015946e-06
2.3108866287202545e-07 2.3108603386390314e-07
rl training, epoch6, iter0, batch13/1133, batch loss:2.3108603386390314e-07, Training time:76322.50789165497
batch reward last col mean 0.00012779395910911262 first col mean 8.608837447354745e-07 all mean 5.102568138681818e-06
7.57659245209652e-06 7.576591542601818e-06
rl training, epoch6, iter0, batch14/1133, batch loss:7.576591542601818e-06, Training time:76339.02387976646
batch reward last col mean 2.4582700461905915e-06 first col mean 8.65546837758302e-07 all mean 9.814760232984554e-06
9.629720807424746e-07 9.62969465945207e-07
rl training, epoch6, iter0, batch15/1133, batch loss:9.62969465945207e-07, Training time:76354.89211082458
batch reward last col mean 1.2900512729174807e-06 first col mean 2.720316274462675e-07 all mean 2.118206612067297e-05
0.00011798895866377279 0.00011798894411185756
rl training, epoch6, iter0, batch16/1133, batch loss:0.00011798894411185756, Training time:76370.99227714539
batch reward last col mean 0.0001966077252291143 first col mean 1.4245888451114297e-06 all mean 4.466141945158597e-06
2.55151553574251e-06 2.551516445237212e-06
rl training, epoch6, iter0, batch17/1133, batch loss:2.551516445237212e-06, Training time:76386.99174809456
batch reward last col mean 1.0371383041274385e-06 first col mean 7.358538027801842e-07 all mean 1.4330714293464553e-05
2.3347665774053894e-06 2.334766804779065e-06
rl training, epoch6, iter0, batch18/1133, batch loss:2.334766804779065e-06, Training time:76402.89198255539
batch reward last col mean 8.994754239211034e-07 first col mean 2.955334639409557e-05 all mean 5.158980911801336e-06
5.584816449299979e-07 5.584809628089715e-07
rl training, epoch6, iter0, batch19/1133, batch loss:5.584809628089715e-07, Training time:76418.87981963158
batch reward last col mean 1.48258129684109e-06 first col mean 9.553472182233236e-07 all mean 1.635686021472793e-05
3.7004062960477313e-06 3.7004053865530295e-06
rl training, epoch6, iter0, batch20/1133, batch loss:3.7004053865530295e-06, Training time:76435.01205921173
batch reward last col mean 5.729391432396369e-07 first col mean 6.041967708370066e-07 all mean 9.494968935541692e-07
3.9089318448759514e-08 3.908927226348169e-08
rl training, epoch6, iter0, batch21/1133, batch loss:3.908927226348169e-08, Training time:76451.26023054123
batch reward last col mean 6.486463826149702e-05 first col mean 1.8191269191447645e-05 all mean 0.0003018055285792798
7.413962885038927e-05 7.413961429847404e-05
rl training, epoch6, iter0, batch22/1133, batch loss:7.413961429847404e-05, Training time:76467.40546941757
batch reward last col mean 1.954855179064907e-06 first col mean 6.423069294214656e-07 all mean 2.1714613467338495e-06
4.705605078925146e-07 4.7056067842277116e-07
rl training, epoch6, iter0, batch23/1133, batch loss:4.7056067842277116e-07, Training time:76483.6986811161
batch reward last col mean 2.2845018975203857e-05 first col mean 2.641082573973108e-06 all mean 1.6701582353562117e-05
7.805313543940429e-06 7.805313543940429e-06
rl training, epoch6, iter0, batch24/1133, batch loss:7.805313543940429e-06, Training time:76499.80157852173
batch reward last col mean 4.943551630276488e-07 first col mean 5.356949372981035e-07 all mean 7.178495707194088e-06
1.3215275430411566e-05 1.321527724940097e-05
rl training, epoch6, iter0, batch25/1133, batch loss:1.321527724940097e-05, Training time:76515.94857215881
batch reward last col mean 0.0015836340608075261 first col mean 5.665849585057003e-07 all mean 0.0009532164549455047
7.345055928453803e-05 7.345056656049564e-05
rl training, epoch6, iter0, batch26/1133, batch loss:7.345056656049564e-05, Training time:76532.27909564972
batch reward last col mean 1.0177882359130308e-06 first col mean 1.0824026048794622e-06 all mean 5.656729626934975e-06
2.436041199871397e-07 2.436046884213283e-07
rl training, epoch6, iter0, batch27/1133, batch loss:2.436046884213283e-07, Training time:76548.50473666191
batch reward last col mean 4.88688783661928e-07 first col mean 6.467571438406594e-07 all mean 4.122818609175738e-06
2.830666403497162e-07 2.8306715194048593e-07
rl training, epoch6, iter0, batch28/1133, batch loss:2.8306715194048593e-07, Training time:76564.6864361763
batch reward last col mean 7.5633447522704955e-06 first col mean 4.510099643084686e-06 all mean 2.0338437025202438e-05
9.812417829380138e-07 9.812471262193867e-07
rl training, epoch6, iter0, batch29/1133, batch loss:9.812471262193867e-07, Training time:76580.88635849953
batch reward last col mean 2.353109812247567e-05 first col mean 1.757143536451622e-06 all mean 2.058294921880588e-05
1.1938753232243471e-05 1.1938755051232874e-05
rl training, epoch6, iter0, batch30/1133, batch loss:1.1938755051232874e-05, Training time:76597.00392985344
batch reward last col mean 0.00025556838954798877 first col mean 2.6416932996653486e-06 all mean 9.398514521308243e-06
8.912822522688657e-06 8.91282434167806e-06
rl training, epoch6, iter0, batch31/1133, batch loss:8.91282434167806e-06, Training time:76612.98933362961
batch reward last col mean 1.2278919712116476e-06 first col mean 2.4146279429260176e-06 all mean 2.9881514365115436e-06
9.578151605182939e-08 9.578234028140287e-08
rl training, epoch6, iter0, batch32/1133, batch loss:9.578234028140287e-08, Training time:76628.92377567291
batch reward last col mean 5.498465270648012e-06 first col mean 5.349775733520801e-07 all mean 5.700071142200613e-06
1.0750818546512164e-06 1.0750815135907033e-06
rl training, epoch6, iter0, batch33/1133, batch loss:1.0750815135907033e-06, Training time:76644.94869160652
batch reward last col mean 0.0001344149641226977 first col mean 1.0743119673861656e-06 all mean 3.0720053473487496e-05
8.696795703144744e-06 8.696805707586464e-06
rl training, epoch6, iter0, batch34/1133, batch loss:8.696805707586464e-06, Training time:76660.89701771736
batch reward last col mean 3.8112810329948843e-07 first col mean 4.4933284470971557e-07 all mean 1.7866103689812007e-06
7.128307544235213e-08 7.128258516786445e-08
rl training, epoch6, iter0, batch35/1133, batch loss:7.128258516786445e-08, Training time:76676.75890493393
batch reward last col mean 1.6148979966601473e-06 first col mean 0.0007929409039206803 all mean 9.80523236648878e-06
1.3891197170323721e-07 1.3891006744870538e-07
rl training, epoch6, iter0, batch36/1133, batch loss:1.3891006744870538e-07, Training time:76692.56922721863
batch reward last col mean 1.212390088767279e-05 first col mean 1.2595520502145519e-06 all mean 0.0003877047565765679
0.00020021744421683252 0.00020021740056108683
rl training, epoch6, iter0, batch37/1133, batch loss:0.00020021740056108683, Training time:76708.35303020477
batch reward last col mean 1.6669321212248178e-06 first col mean 7.73037413637212e-07 all mean 7.819682650733739e-06
7.830057597857376e-07 7.830025197108625e-07
rl training, epoch6, iter0, batch38/1133, batch loss:7.830025197108625e-07, Training time:76724.27514457703
batch reward last col mean 4.529843863565475e-05 first col mean 5.284106737235561e-05 all mean 2.6760471882880665e-05
2.8473177735577337e-05 2.8473172278609127e-05
rl training, epoch6, iter0, batch39/1133, batch loss:2.8473172278609127e-05, Training time:76740.22694325447
batch reward last col mean 7.710981435593567e-07 first col mean 6.4019468482001685e-06 all mean 7.916046342870686e-07
5.797894431225359e-08 5.797891944325784e-08
rl training, epoch6, iter0, batch40/1133, batch loss:5.797891944325784e-08, Training time:76756.41670584679
batch reward last col mean 8.685053671797505e-07 first col mean 8.013273031792778e-07 all mean 3.657179604488192e-06
8.857308131382524e-08 8.85724347199357e-08
rl training, epoch6, iter0, batch41/1133, batch loss:8.85724347199357e-08, Training time:76772.70425152779
batch reward last col mean 2.4184769245039206e-06 first col mean 7.127478966140188e-06 all mean 9.849663001659792e-06
7.564905786239251e-07 7.564900101897365e-07
rl training, epoch6, iter0, batch42/1133, batch loss:7.564900101897365e-07, Training time:76789.10178494453
batch reward last col mean 0.0001385030773235485 first col mean 5.370317239794531e-07 all mean 3.201390427420847e-05
1.0679729712137487e-05 1.0679728802642785e-05
rl training, epoch6, iter0, batch43/1133, batch loss:1.0679728802642785e-05, Training time:76805.30408477783
batch reward last col mean 0.0001861469354480505 first col mean 7.861861490709998e-07 all mean 0.000246187875745818
0.00011289431859040633 0.00011289431859040633
rl training, epoch6, iter0, batch44/1133, batch loss:0.00011289431859040633, Training time:76821.50957870483
batch reward last col mean 5.957516009402752e-07 first col mean 1.403706164637697e-06 all mean 1.6074734503490617e-06
6.897338522549035e-08 6.89732928549347e-08
rl training, epoch6, iter0, batch45/1133, batch loss:6.89732928549347e-08, Training time:76837.67090892792
batch reward last col mean 3.0871076887706295e-05 first col mean 6.396105618478032e-07 all mean 9.279753430746496e-05
2.8750633646268398e-05 2.8750628189300187e-05
rl training, epoch6, iter0, batch46/1133, batch loss:2.8750628189300187e-05, Training time:76854.00713181496
batch reward last col mean 1.2497881698436686e-06 first col mean 6.227066364772327e-07 all mean 8.098323291960696e-07
7.135655977208444e-08 7.13564816123835e-08
rl training, epoch6, iter0, batch47/1133, batch loss:7.13564816123835e-08, Training time:76870.33884167671
batch reward last col mean 1.3119586128595984e-06 first col mean 5.467814116855152e-05 all mean 2.1752969132649014e-06
2.527598326196312e-07 2.527596620893746e-07
rl training, epoch6, iter0, batch48/1133, batch loss:2.527596620893746e-07, Training time:76886.52868556976
batch reward last col mean 3.0401829462789465e-06 first col mean 7.13303052179981e-07 all mean 4.55437248092494e-06
4.1365885294908367e-07 4.136588813707931e-07
rl training, epoch6, iter0, batch49/1133, batch loss:4.136588813707931e-07, Training time:76902.45817399025
batch reward last col mean 0.00016664924623910338 first col mean 4.947925731357827e-07 all mean 0.0001931490405695513
0.00011057063238695264 0.00011057062511099502
rl training, epoch6, iter0, batch50/1133, batch loss:0.00011057062511099502, Training time:76918.27349114418
batch reward last col mean 4.551733945845626e-05 first col mean 5.681809511770552e-07 all mean 1.1813187484221999e-05
6.8933391048631165e-06 6.8933391048631165e-06
rl training, epoch6, iter0, batch51/1133, batch loss:6.8933391048631165e-06, Training time:76934.02879977226
batch reward last col mean 2.539690513003734e-06 first col mean 1.2546006473712623e-06 all mean 2.5899580577970482e-05
2.0055583718203707e-06 2.005577016461757e-06
rl training, epoch6, iter0, batch52/1133, batch loss:2.005577016461757e-06, Training time:76949.76908612251
batch reward last col mean 1.430977226846153e-05 first col mean 2.884761670429725e-06 all mean 1.1636525414360221e-05
2.243374638055684e-06 2.243373501187307e-06
rl training, epoch6, iter0, batch53/1133, batch loss:2.243373501187307e-06, Training time:76965.71584773064
batch reward last col mean 5.6999265325430315e-06 first col mean 1.0804386647578212e-06 all mean 1.1416669622121844e-05
1.7733862023305846e-06 1.7733900676830672e-06
rl training, epoch6, iter0, batch54/1133, batch loss:1.7733900676830672e-06, Training time:76981.5958867073
batch reward last col mean 0.0005958692636340857 first col mean 1.3185402849558159e-06 all mean 0.0003907512000296265
3.7550413253484294e-05 3.7550398701569065e-05
rl training, epoch6, iter0, batch55/1133, batch loss:3.7550398701569065e-05, Training time:76997.4118282795
batch reward last col mean 1.0330777513445355e-06 first col mean 1.3167519682610873e-05 all mean 8.291189260489773e-06
2.5599117634556023e-06 2.559909034971497e-06
rl training, epoch6, iter0, batch56/1133, batch loss:2.559909034971497e-06, Training time:77013.47468996048
batch reward last col mean 2.384470008109929e-06 first col mean 1.1867081184391282e-06 all mean 1.8736422134679742e-05
1.1700109098455869e-05 1.1700111826939974e-05
rl training, epoch6, iter0, batch57/1133, batch loss:1.1700111826939974e-05, Training time:77029.5400826931
batch reward last col mean 1.8348647472521407e-06 first col mean 1.5629312883902458e-06 all mean 1.415000224369578e-05
3.077749397562002e-06 3.077747351198923e-06
rl training, epoch6, iter0, batch58/1133, batch loss:3.077747351198923e-06, Training time:77045.7224471569
batch reward last col mean 2.681282467165147e-06 first col mean 4.471778993320186e-06 all mean 2.4452272100461414e-06
1.3328863701644877e-07 1.3328933334832982e-07
rl training, epoch6, iter0, batch59/1133, batch loss:1.3328933334832982e-07, Training time:77061.85627532005
batch reward last col mean 1.4175408068695106e-05 first col mean 0.000494966225232929 all mean 0.0004181352269370109
0.0002268462849315256 0.0002268462849315256
rl training, epoch6, iter0, batch60/1133, batch loss:0.0002268462849315256, Training time:77077.94815015793
batch reward last col mean 4.454173563317454e-07 first col mean 5.366657660488272e-07 all mean 9.165694336843444e-07
1.1334324767631188e-07 1.1334329030887602e-07
rl training, epoch6, iter0, batch61/1133, batch loss:1.1334329030887602e-07, Training time:77094.03312373161
batch reward last col mean 7.228334197861841e-07 first col mean 8.526034207534394e-07 all mean 1.4267586720961845e-06
1.0412634310341673e-07 1.0412639284140823e-07
rl training, epoch6, iter0, batch62/1133, batch loss:1.0412639284140823e-07, Training time:77110.13930773735
batch reward last col mean 1.2491918823798187e-06 first col mean 2.4860191842890345e-06 all mean 1.1483371963549871e-05
1.8257169642765803e-07 1.8256996270338277e-07
rl training, epoch6, iter0, batch63/1133, batch loss:1.8256996270338277e-07, Training time:77126.29714083672
batch reward last col mean 1.0437072432978312e-06 first col mean 2.0973911887267604e-06 all mean 5.029983640270075e-06
2.4174102009055787e-07 2.4174073587346356e-07
rl training, epoch6, iter0, batch64/1133, batch loss:2.4174073587346356e-07, Training time:77142.54713892937
batch reward last col mean 5.485297833729419e-07 first col mean 5.18882870892412e-07 all mean 2.7781700282503152e-06
2.430826953059295e-07 2.430825816190918e-07
rl training, epoch6, iter0, batch65/1133, batch loss:2.430825816190918e-07, Training time:77158.58920764923
batch reward last col mean 4.98249391966965e-07 first col mean 7.004283588685212e-07 all mean 1.2269867966097081e-06
5.1957673719016384e-08 5.195748542519141e-08
rl training, epoch6, iter0, batch66/1133, batch loss:5.195748542519141e-08, Training time:77174.72075152397
batch reward last col mean 5.8414743762114085e-06 first col mean 1.0086901056638453e-06 all mean 6.6780812630895525e-06
4.704653747467091e-06 4.704653747467091e-06
rl training, epoch6, iter0, batch67/1133, batch loss:4.704653747467091e-06, Training time:77190.85547494888
batch reward last col mean 1.4843155895505333e-06 first col mean 5.693803473150183e-07 all mean 2.3058421447785804e-06
2.8586765665750136e-07 2.858677135009202e-07
rl training, epoch6, iter0, batch68/1133, batch loss:2.858677135009202e-07, Training time:77206.92230677605
batch reward last col mean 3.424195938350749e-06 first col mean 0.001199064776301384 all mean 2.4933975510066375e-05
1.4079038237468922e-06 1.4079041648074053e-06
rl training, epoch6, iter0, batch69/1133, batch loss:1.4079041648074053e-06, Training time:77222.98566889763
batch reward last col mean 0.00015346880536526442 first col mean 5.817566375299066e-07 all mean 3.8479731301777065e-05
2.3817652618163265e-05 2.3817652618163265e-05
rl training, epoch6, iter0, batch70/1133, batch loss:2.3817652618163265e-05, Training time:77238.95267057419
batch reward last col mean 3.287613310476445e-07 first col mean 6.846141786809312e-07 all mean 3.583325451472774e-06
1.862852627709799e-07 1.8628456643909885e-07
rl training, epoch6, iter0, batch71/1133, batch loss:1.8628456643909885e-07, Training time:77255.53479146957
batch reward last col mean 8.135282769217156e-06 first col mean 9.124486837208678e-07 all mean 2.5015544906636933e-06
4.362817094261118e-07 4.3628085677482886e-07
rl training, epoch6, iter0, batch72/1133, batch loss:4.3628085677482886e-07, Training time:77271.55901789665
batch reward last col mean 6.765301804989576e-05 first col mean 5.099399800201354e-07 all mean 0.00010760523582575843
3.133566860924475e-05 3.133566497126594e-05
rl training, epoch6, iter0, batch73/1133, batch loss:3.133566497126594e-05, Training time:77287.57588553429
batch reward last col mean 1.1975535016972572e-06 first col mean 4.502681463236513e-07 all mean 1.1377870805517887e-06
3.669144916784717e-07 3.6691426430479623e-07
rl training, epoch6, iter0, batch74/1133, batch loss:3.6691426430479623e-07, Training time:77303.64032626152
batch reward last col mean 6.160065595395281e-07 first col mean 6.692679335174034e-07 all mean 9.827209623836097e-07
4.0879086782297236e-08 4.0879093887724594e-08
rl training, epoch6, iter0, batch75/1133, batch loss:4.0879093887724594e-08, Training time:77319.49017333984
batch reward last col mean 1.2200375749671366e-06 first col mean 9.004460252981517e-07 all mean 1.8734532432063133e-06
2.999775006173877e-07 2.9997755746080657e-07
rl training, epoch6, iter0, batch76/1133, batch loss:2.9997755746080657e-07, Training time:77335.28835630417
batch reward last col mean 6.501106213363528e-07 first col mean 7.500840979446366e-07 all mean 2.5105027816607617e-06
8.696286357690042e-08 8.696395070728613e-08
rl training, epoch6, iter0, batch77/1133, batch loss:8.696395070728613e-08, Training time:77351.31390857697
batch reward last col mean 9.852751645667013e-07 first col mean 4.518923617524706e-07 all mean 2.4673709049238823e-06
2.035039443626374e-07 2.0350360330212425e-07
rl training, epoch6, iter0, batch78/1133, batch loss:2.0350360330212425e-07, Training time:77367.44257187843
batch reward last col mean 1.4477919876298984e-06 first col mean 6.393805733750924e-07 all mean 2.073511723210686e-06
1.071155253384859e-07 1.0711576692301605e-07
rl training, epoch6, iter0, batch79/1133, batch loss:1.0711576692301605e-07, Training time:77383.43711280823
batch reward last col mean 8.019285360205686e-07 first col mean 7.819543839104881e-07 all mean 5.856308234797325e-06
1.2443493346836476e-07 1.2443531716144207e-07
rl training, epoch6, iter0, batch80/1133, batch loss:1.2443531716144207e-07, Training time:77399.39670944214
batch reward last col mean 9.18737271149439e-07 first col mean 8.733501317692571e-07 all mean 1.694467982815695e-06
2.5200989739460056e-07 2.520100110814383e-07
rl training, epoch6, iter0, batch81/1133, batch loss:2.520100110814383e-07, Training time:77415.57267260551
batch reward last col mean 3.695132591019501e-07 first col mean 4.139769316680031e-06 all mean 1.6136324347826303e-06
1.5824049626189662e-07 1.5824032573164004e-07
rl training, epoch6, iter0, batch82/1133, batch loss:1.5824032573164004e-07, Training time:77431.6042046547
batch reward last col mean 8.310394719046599e-07 first col mean 0.00016389197844546288 all mean 3.236760448999121e-06
3.884347847815661e-07 3.8843563743284903e-07
rl training, epoch6, iter0, batch83/1133, batch loss:3.8843563743284903e-07, Training time:77447.59179258347
batch reward last col mean 7.780307896609884e-06 first col mean 8.679131724420586e-07 all mean 3.9170708987512626e-06
9.919660897139693e-07 9.91965748653456e-07
rl training, epoch6, iter0, batch84/1133, batch loss:9.91965748653456e-07, Training time:77463.62727236748
batch reward last col mean 1.3979714594825055e-06 first col mean 0.00016077687905635685 all mean 2.8699159884126857e-06
2.0930106359173806e-07 2.093004383141306e-07
rl training, epoch6, iter0, batch85/1133, batch loss:2.093004383141306e-07, Training time:77479.61233448982
batch reward last col mean 5.168228085494775e-07 first col mean 8.73817384672293e-07 all mean 1.6260495613096282e-05
2.8602655675058486e-06 2.8602660222531995e-06
rl training, epoch6, iter0, batch86/1133, batch loss:2.8602660222531995e-06, Training time:77495.62939405441
batch reward last col mean 5.229845214671514e-07 first col mean 5.906623528062482e-07 all mean 6.840133210062049e-06
3.7056861401651986e-07 3.705646349771996e-07
rl training, epoch6, iter0, batch87/1133, batch loss:3.705646349771996e-07, Training time:77511.68388795853
batch reward last col mean 1.7522577309136977e-06 first col mean 1.8077840877595008e-06 all mean 4.52528593086754e-06
1.8051636629934364e-07 1.8051701999866054e-07
rl training, epoch6, iter0, batch88/1133, batch loss:1.8051701999866054e-07, Training time:77527.7014169693
batch reward last col mean 3.9542635931866243e-05 first col mean 4.82577377169946e-07 all mean 1.0076702892547473e-05
1.4668065659861895e-06 1.466805997552001e-06
rl training, epoch6, iter0, batch89/1133, batch loss:1.466805997552001e-06, Training time:77543.69813013077
batch reward last col mean 4.556639396469109e-06 first col mean 8.069550858635921e-07 all mean 1.7971653505810536e-05
1.4472229850071017e-06 1.4472163911705138e-06
rl training, epoch6, iter0, batch90/1133, batch loss:1.4472163911705138e-06, Training time:77559.77722787857
batch reward last col mean 6.867386673548026e-06 first col mean 1.8508929997551604e-06 all mean 2.562093868618831e-05
9.365950245410204e-05 9.365950973005965e-05
rl training, epoch6, iter0, batch91/1133, batch loss:9.365950973005965e-05, Training time:77575.88789510727
batch reward last col mean 1.1642902791209053e-05 first col mean 2.9497837203962263e-06 all mean 3.1075724109541625e-05
5.321276148606557e-06 5.321274784364505e-06
rl training, epoch6, iter0, batch92/1133, batch loss:5.321274784364505e-06, Training time:77592.00627660751
batch reward last col mean 8.178595862773363e-07 first col mean 3.655945874925237e-07 all mean 2.257115511383745e-06
2.4914857021940406e-06 2.4914852474466898e-06
rl training, epoch6, iter0, batch93/1133, batch loss:2.4914852474466898e-06, Training time:77608.02194476128
batch reward last col mean 0.00031816845876164734 first col mean 1.9408075786486734e-06 all mean 1.2649673408304807e-05
1.1098553841293324e-05 1.1098555660282727e-05
rl training, epoch6, iter0, batch94/1133, batch loss:1.1098555660282727e-05, Training time:77624.03664183617
batch reward last col mean 4.4184031366967247e-07 first col mean 1.3144574495527195e-06 all mean 2.0059881080669584e-06
2.435102430808911e-07 2.4351129468414e-07
rl training, epoch6, iter0, batch95/1133, batch loss:2.4351129468414e-07, Training time:77640.2378885746
batch reward last col mean 7.386962579403189e-07 first col mean 1.1323071475999313e-06 all mean 2.3994684852368664e-06
3.299620914276602e-07 3.299625461750111e-07
rl training, epoch6, iter0, batch96/1133, batch loss:3.299625461750111e-07, Training time:77656.45369958878
batch reward last col mean 8.03848888608627e-06 first col mean 9.07062485566712e-07 all mean 1.2344347851467319e-05
2.028745620918926e-05 2.0287454390199855e-05
rl training, epoch6, iter0, batch97/1133, batch loss:2.0287454390199855e-05, Training time:77672.89567613602
batch reward last col mean 4.5157634076531394e-07 first col mean 7.629598144376359e-07 all mean 1.0425574146211147e-05
1.622845076099111e-07 1.622806848899927e-07
rl training, epoch6, iter0, batch98/1133, batch loss:1.622806848899927e-07, Training time:77689.11886906624
batch reward last col mean 5.63125695407507e-07 first col mean 1.6637244470985024e-06 all mean 1.1388284292479511e-05
9.341400186713145e-08 9.34114794404195e-08
rl training, epoch6, iter0, batch99/1133, batch loss:9.34114794404195e-08, Training time:77705.10152888298
batch reward last col mean 0.002742161275818944 first col mean 7.56246981836739e-06 all mean 0.0025226983707398176
0.0002748082624748349 0.000274808204267174
rl training, epoch6, iter0, batch100/1133, batch loss:0.000274808204267174, Training time:77721.06517100334
batch reward last col mean 5.405063348007388e-06 first col mean 8.455189117739792e-07 all mean 2.9754119168501347e-06
5.989971896269708e-07 5.989969622532954e-07
rl training, epoch6, iter0, batch101/1133, batch loss:5.989969622532954e-07, Training time:77736.98065781593
batch reward last col mean 1.6004469216568395e-06 first col mean 2.200889866799116e-06 all mean 1.2992336451134179e-05
1.5938134310999885e-05 1.5938130673021078e-05
rl training, epoch6, iter0, batch102/1133, batch loss:1.5938130673021078e-05, Training time:77752.91612887383
batch reward last col mean 6.685992411803454e-05 first col mean 2.496085926395608e-06 all mean 0.0008725078660063446
0.00045851815957576036 0.0004585181886795908
rl training, epoch6, iter0, batch103/1133, batch loss:0.0004585181886795908, Training time:77768.80171895027
batch reward last col mean 9.63969227996131e-07 first col mean 1.3754136034549447e-06 all mean 5.947455520072253e-06
1.2256259651621804e-06 1.225627784151584e-06
rl training, epoch6, iter0, batch104/1133, batch loss:1.225627784151584e-06, Training time:77784.75513005257
batch reward last col mean 8.054647651078994e-07 first col mean 7.397428589683841e-07 all mean 2.401127858320251e-05
1.39081885208725e-06 1.3908120308769867e-06
rl training, epoch6, iter0, batch105/1133, batch loss:1.3908120308769867e-06, Training time:77800.72613501549
batch reward last col mean 1.4546964166584075e-06 first col mean 4.3186622633584193e-07 all mean 1.768246988831379e-06
1.5259507790688076e-07 1.5259506369602605e-07
rl training, epoch6, iter0, batch106/1133, batch loss:1.5259506369602605e-07, Training time:77816.6726744175
batch reward last col mean 3.2847499824129045e-05 first col mean 7.845991785870865e-05 all mean 5.6832021073205397e-05
2.2234853531699628e-05 2.223484443675261e-05
rl training, epoch6, iter0, batch107/1133, batch loss:2.223484443675261e-05, Training time:77832.4812734127
batch reward last col mean 1.2478075177568826e-06 first col mean 9.1821578962481e-07 all mean 7.107948931661667e-06
2.235735507838399e-07 2.2357464501965296e-07
rl training, epoch6, iter0, batch108/1133, batch loss:2.2357464501965296e-07, Training time:77848.51918148994
batch reward last col mean 5.020022513235745e-07 first col mean 9.581656286172802e-07 all mean 1.4504302043860662e-06
5.961371840612628e-08 5.961343418903198e-08
rl training, epoch6, iter0, batch109/1133, batch loss:5.961343418903198e-08, Training time:77864.45124840736
batch reward last col mean 5.51857226582797e-07 first col mean 4.29751395358835e-07 all mean 6.96080405759858e-07
4.6269384768038435e-08 4.6269356346329005e-08
rl training, epoch6, iter0, batch110/1133, batch loss:4.6269356346329005e-08, Training time:77880.49041032791
batch reward last col mean 4.2937795114994515e-06 first col mean 2.1990756522427546e-06 all mean 1.3584412045020144e-05
1.325865810031246e-06 1.3258646731628687e-06
rl training, epoch6, iter0, batch111/1133, batch loss:1.3258646731628687e-06, Training time:77896.65143680573
batch reward last col mean 2.0435277292563114e-06 first col mean 3.9983478927752e-06 all mean 8.581409929320216e-06
1.7599081729713362e-06 1.7599082866581739e-06
rl training, epoch6, iter0, batch112/1133, batch loss:1.7599082866581739e-06, Training time:77913.03028798103
batch reward last col mean 1.9111173514829716e-06 first col mean 1.0845265023817774e-06 all mean 3.768357828448643e-06
1.3749261142947944e-06 1.3749260006079567e-06
rl training, epoch6, iter0, batch113/1133, batch loss:1.3749260006079567e-06, Training time:77929.04041981697
batch reward last col mean 7.290079224731016e-07 first col mean 9.28170493352809e-07 all mean 2.6747743504529353e-06
1.305139818441603e-07 1.3051489133886207e-07
rl training, epoch6, iter0, batch114/1133, batch loss:1.3051489133886207e-07, Training time:77945.17233896255
batch reward last col mean 5.258846726974298e-07 first col mean 4.031926437164657e-06 all mean 1.997223534999648e-06
1.1286547874078678e-07 1.1286569900903487e-07
rl training, epoch6, iter0, batch115/1133, batch loss:1.1286569900903487e-07, Training time:77961.52587771416
batch reward last col mean 5.419657827587798e-05 first col mean 1.0647559065546375e-06 all mean 4.482349322643131e-05
0.0002961722493637353 0.0002961722493637353
rl training, epoch6, iter0, batch116/1133, batch loss:0.0002961722493637353, Training time:77977.74383068085
batch reward last col mean 1.7535414826852502e-06 first col mean 1.5370123946922831e-06 all mean 5.122336006024852e-06
7.119908218555793e-07 7.119915608200245e-07
rl training, epoch6, iter0, batch117/1133, batch loss:7.119915608200245e-07, Training time:77993.6493692398
batch reward last col mean 9.80328536570596e-07 first col mean 6.725884418301575e-07 all mean 1.424295874130621e-06
2.249320942837585e-07 2.249321937597415e-07
rl training, epoch6, iter0, batch118/1133, batch loss:2.249321937597415e-07, Training time:78009.55455803871
batch reward last col mean 6.430889243347337e-07 first col mean 1.1692492307702196e-06 all mean 3.3742858249752317e-06
1.0974950015452123e-07 1.0975075781516352e-07
rl training, epoch6, iter0, batch119/1133, batch loss:1.0975075781516352e-07, Training time:78025.75351715088
batch reward last col mean 1.7125605609180639e-06 first col mean 1.0659045983629767e-06 all mean 2.992356712638866e-06
2.2980685798756895e-07 2.2980604796885018e-07
rl training, epoch6, iter0, batch120/1133, batch loss:2.2980604796885018e-07, Training time:78041.77348065376
batch reward last col mean 1.366423657600535e-05 first col mean 9.894699815049535e-07 all mean 4.078072015545331e-05
1.3406103789748158e-05 1.340610469924286e-05
rl training, epoch6, iter0, batch121/1133, batch loss:1.340610469924286e-05, Training time:78057.84917211533
batch reward last col mean 9.714784937386867e-06 first col mean 1.3199899058236042e-06 all mean 4.524231826508185e-06
2.3881998458819e-06 2.3882003006292507e-06
rl training, epoch6, iter0, batch122/1133, batch loss:2.3882003006292507e-06, Training time:78073.93318891525
batch reward last col mean 7.476859991584206e-06 first col mean 1.0494030675545218e-06 all mean 5.095518190501025e-06
7.340186698456819e-07 7.340196361838025e-07
rl training, epoch6, iter0, batch123/1133, batch loss:7.340196361838025e-07, Training time:78090.00998067856
batch reward last col mean 1.0595284720693599e-06 first col mean 1.0612449159452808e-06 all mean 2.7681683150149183e-06
6.027960353094386e-07 6.027958079357632e-07
rl training, epoch6, iter0, batch124/1133, batch loss:6.027958079357632e-07, Training time:78106.01880693436
batch reward last col mean 9.220957508659922e-07 first col mean 1.3597266388387652e-06 all mean 8.934404831961729e-06
1.2585664990183432e-06 1.2585664990183432e-06
rl training, epoch6, iter0, batch125/1133, batch loss:1.2585664990183432e-06, Training time:78121.99908399582
batch reward last col mean 9.047075195667276e-07 first col mean 1.2358823369140737e-06 all mean 6.278709406615235e-06
4.889492188908662e-08 4.889119153972388e-08
rl training, epoch6, iter0, batch126/1133, batch loss:4.889119153972388e-08, Training time:78137.98100352287
batch reward last col mean 9.375211220685742e-07 first col mean 8.630263437225949e-07 all mean 1.5849934698053403e-06
2.1682501483155647e-06 2.1682501483155647e-06
rl training, epoch6, iter0, batch127/1133, batch loss:2.1682501483155647e-06, Training time:78153.95930886269
batch reward last col mean 1.228853534485097e-06 first col mean 8.406483971157286e-07 all mean 5.283617156237597e-06
1.5112254914129153e-07 1.5112472340206295e-07
rl training, epoch6, iter0, batch128/1133, batch loss:1.5112472340206295e-07, Training time:78169.98365783691
batch reward last col mean 2.941571210612892e-06 first col mean 9.371317446493777e-07 all mean 4.176069978711894e-06
5.726021186092112e-07 5.726022322960489e-07
rl training, epoch6, iter0, batch129/1133, batch loss:5.726022322960489e-07, Training time:78186.24149012566
batch reward last col mean 1.64134530677984e-06 first col mean 1.0138489869859768e-06 all mean 5.172575129108736e-06
3.097562739640125e-06 3.097562284892774e-06
rl training, epoch6, iter0, batch130/1133, batch loss:3.097562284892774e-06, Training time:78202.54261612892
batch reward last col mean 6.727629511260602e-07 first col mean 6.578644047294802e-07 all mean 2.007438752116286e-06
1.5028565769625857e-07 1.5028527400318126e-07
rl training, epoch6, iter0, batch131/1133, batch loss:1.5028527400318126e-07, Training time:78218.81080412865
batch reward last col mean 6.971579750825185e-06 first col mean 8.961459343481692e-07 all mean 2.4333439796464518e-06
6.729064239152649e-07 6.729068218191969e-07
rl training, epoch6, iter0, batch132/1133, batch loss:6.729068218191969e-07, Training time:78234.9962322712
batch reward last col mean 0.0002135368704330176 first col mean 3.152427962049842e-05 all mean 0.0002142237644875422
2.815596599248238e-05 2.815596599248238e-05
rl training, epoch6, iter0, batch133/1133, batch loss:2.815596599248238e-05, Training time:78251.53318929672
batch reward last col mean 4.27084046350501e-07 first col mean 7.935118446766865e-07 all mean 7.373501830443274e-06
1.301324118685443e-06 1.3013251418669824e-06
rl training, epoch6, iter0, batch134/1133, batch loss:1.3013251418669824e-06, Training time:78267.68829345703
batch reward last col mean 9.470631994190626e-07 first col mean 7.862037136874278e-07 all mean 2.2961298782320227e-06
8.51246966249164e-08 8.512453320008717e-08
rl training, epoch6, iter0, batch135/1133, batch loss:8.512453320008717e-08, Training time:78284.48576498032
batch reward last col mean 4.6588982513640076e-05 first col mean 6.038567335053813e-07 all mean 0.00014758553879801184
3.026306876563467e-05 3.0263076041592285e-05
rl training, epoch6, iter0, batch136/1133, batch loss:3.0263076041592285e-05, Training time:78300.81241202354
batch reward last col mean 1.432422664038313e-06 first col mean 1.0480333685336518e-06 all mean 1.758155917741533e-06
2.9779357646475546e-07 2.977935196213366e-07
rl training, epoch6, iter0, batch137/1133, batch loss:2.977935196213366e-07, Training time:78316.86978006363
batch reward last col mean 6.254578579500958e-07 first col mean 1.246886426997662e-06 all mean 3.834405106317718e-06
5.784298764410778e-07 5.784301606581721e-07
rl training, epoch6, iter0, batch138/1133, batch loss:5.784301606581721e-07, Training time:78332.88894581795
batch reward last col mean 2.307363899944903e-07 first col mean 6.19058425854746e-07 all mean 4.045358764415141e-06
3.0306227927212603e-07 3.0306304665828065e-07
rl training, epoch6, iter0, batch139/1133, batch loss:3.0306304665828065e-07, Training time:78348.902769804
batch reward last col mean 0.00022621045354753733 first col mean 7.947115818751627e-07 all mean 1.0124990694748703e-05
5.522284482140094e-06 5.522279934666585e-06
rl training, epoch6, iter0, batch140/1133, batch loss:5.522279934666585e-06, Training time:78364.94623208046
batch reward last col mean 1.8993601997863152e-06 first col mean 8.762617085267266e-07 all mean 2.6776647246151697e-06
1.195653140939612e-07 1.1956514356370462e-07
rl training, epoch6, iter0, batch141/1133, batch loss:1.1956514356370462e-07, Training time:78380.96093249321
batch reward last col mean 1.466407411498949e-06 first col mean 4.563168204185786e-06 all mean 7.482273758796509e-06
9.885901164352617e-08 9.885416574206829e-08
rl training, epoch6, iter0, batch142/1133, batch loss:9.885416574206829e-08, Training time:78396.9615240097
batch reward last col mean 1.1806284874182893e-06 first col mean 1.0837140962394187e-06 all mean 3.3822464047261747e-06
3.4553909245005343e-07 3.455393198237289e-07
rl training, epoch6, iter0, batch143/1133, batch loss:3.455393198237289e-07, Training time:78412.95973873138
batch reward last col mean 4.751707820105366e-06 first col mean 3.236688280594535e-05 all mean 3.974306309828535e-06
7.041977596600191e-07 7.041980438771134e-07
rl training, epoch6, iter0, batch144/1133, batch loss:7.041980438771134e-07, Training time:78429.04856419563
batch reward last col mean 1.4189311514201108e-05 first col mean 3.5111218039673986e-06 all mean 5.673832492902875e-05
0.00021201772324275225 0.0002120177523465827
rl training, epoch6, iter0, batch145/1133, batch loss:0.0002120177523465827, Training time:78445.8437948227
batch reward last col mean 3.192061194567941e-05 first col mean 6.75017702178593e-07 all mean 7.573952643724624e-06
3.0547612368536647e-06 3.0547641927114455e-06
rl training, epoch6, iter0, batch146/1133, batch loss:3.0547641927114455e-06, Training time:78461.85197281837
batch reward last col mean 2.475514975230908e-06 first col mean 7.4147402528979e-07 all mean 5.493689513969002e-06
1.7266706890950445e-06 1.7266694385398296e-06
rl training, epoch6, iter0, batch147/1133, batch loss:1.7266694385398296e-06, Training time:78477.91750192642
batch reward last col mean 1.4068590417082305e-06 first col mean 4.6087134819572384e-07 all mean 4.46272679255344e-06
1.7453511702569813e-07 1.745363107374942e-07
rl training, epoch6, iter0, batch148/1133, batch loss:1.745363107374942e-07, Training time:78494.01267886162
batch reward last col mean 9.238806524081156e-05 first col mean 5.526945869860356e-07 all mean 0.00017066803411580622
0.00020211050286889076 0.00020211053197272122
rl training, epoch6, iter0, batch149/1133, batch loss:0.00020211053197272122, Training time:78510.07752490044
batch reward last col mean 4.3624353907034674e-07 first col mean 1.2187697393528651e-06 all mean 1.3675403351953719e-06
5.4518466185982106e-08 5.451837381542646e-08
rl training, epoch6, iter0, batch150/1133, batch loss:5.451837381542646e-08, Training time:78526.24925971031
batch reward last col mean 1.5821575516383746e-06 first col mean 1.0951355307042832e-06 all mean 1.3553409416999784e-06
7.218396831376594e-07 7.218396831376594e-07
rl training, epoch6, iter0, batch151/1133, batch loss:7.218396831376594e-07, Training time:78542.54620170593
batch reward last col mean 5.921012416365556e-06 first col mean 1.2117253618271207e-06 all mean 0.0001902573712868616
0.00011096060916315764 0.00011096060188720003
rl training, epoch6, iter0, batch152/1133, batch loss:0.00011096060188720003, Training time:78558.74518632889
batch reward last col mean 2.331551968381973e-06 first col mean 1.9116614566883072e-05 all mean 1.6004341887310147e-05
3.891296273650369e-06 3.891295818903018e-06
rl training, epoch6, iter0, batch153/1133, batch loss:3.891295818903018e-06, Training time:78574.82256364822
batch reward last col mean 2.9918178370280657e-06 first col mean 1.7327566865787958e-06 all mean 1.0023021559391054e-06
2.330242239168001e-07 2.3302425233850954e-07
rl training, epoch6, iter0, batch154/1133, batch loss:2.3302425233850954e-07, Training time:78590.90310931206
batch reward last col mean 1.2206970723127597e-06 first col mean 1.1838910722872242e-06 all mean 1.1735138514268328e-06
1.005675684950802e-07 1.0056753296794341e-07
rl training, epoch6, iter0, batch155/1133, batch loss:1.0056753296794341e-07, Training time:78606.8916194439
batch reward last col mean 1.798218931980955e-06 first col mean 1.42997282637225e-06 all mean 3.191900532328873e-06
1.5004121678430238e-07 1.5004182785105513e-07
rl training, epoch6, iter0, batch156/1133, batch loss:1.5004182785105513e-07, Training time:78622.90158510208
batch reward last col mean 6.0135589592391625e-06 first col mean 1.7310680959781166e-06 all mean 4.986836756870616e-06
1.1276200666543446e-06 1.1276197255938314e-06
rl training, epoch6, iter0, batch157/1133, batch loss:1.1276197255938314e-06, Training time:78638.96885848045
batch reward last col mean 1.672438656896702e-06 first col mean 2.7187141313333996e-05 all mean 5.465633876156062e-06
5.199005954636959e-07 5.199000270295073e-07
rl training, epoch6, iter0, batch158/1133, batch loss:5.199000270295073e-07, Training time:78655.06805706024
batch reward last col mean 8.566544806853926e-07 first col mean 1.222089963448525e-06 all mean 1.9707806586666266e-06
1.8398354484361334e-07 1.839835022110492e-07
rl training, epoch6, iter0, batch159/1133, batch loss:1.839835022110492e-07, Training time:78671.51000761986
batch reward last col mean 8.682324732944835e-06 first col mean 1.4331848205983988e-06 all mean 5.4165825531526934e-06
2.2057024580135476e-06 2.2057017758925213e-06
rl training, epoch6, iter0, batch160/1133, batch loss:2.2057017758925213e-06, Training time:78687.53730201721
batch reward last col mean 0.00012640771456062794 first col mean 1.0275082331645535e-06 all mean 2.0928313460899517e-05
1.4198398275766522e-05 1.4198409189702943e-05
rl training, epoch6, iter0, batch161/1133, batch loss:1.4198409189702943e-05, Training time:78703.51895236969
batch reward last col mean 4.881633799413976e-07 first col mean 6.334588533718488e-07 all mean 1.3420469713310013e-06
1.6398414004470396e-07 1.6398396951444738e-07
rl training, epoch6, iter0, batch162/1133, batch loss:1.6398396951444738e-07, Training time:78719.57895517349
batch reward last col mean 2.82331302514649e-06 first col mean 8.976197932497598e-06 all mean 1.8602588170324452e-05
4.321864537359943e-07 4.321860842537717e-07
rl training, epoch6, iter0, batch163/1133, batch loss:4.321860842537717e-07, Training time:78735.54359102249
batch reward last col mean 1.8820508103090106e-06 first col mean 7.681171155127231e-06 all mean 1.646102987251652e-06
1.192886145418015e-07 1.1928894139145996e-07
rl training, epoch6, iter0, batch164/1133, batch loss:1.1928894139145996e-07, Training time:78751.70771217346
batch reward last col mean 8.075246569205774e-07 first col mean 1.3941631777925068e-06 all mean 1.0748412933025975e-05
3.643581294454634e-07 3.6435477568375063e-07
rl training, epoch6, iter0, batch165/1133, batch loss:3.6435477568375063e-07, Training time:78767.70938682556
batch reward last col mean 6.707243755954551e-07 first col mean 0.0002625016786623746 all mean 4.109369456273271e-06
1.4870909126329934e-07 1.4870819597945228e-07
rl training, epoch6, iter0, batch166/1133, batch loss:1.4870819597945228e-07, Training time:78784.12788128853
batch reward last col mean 1.1054041806346504e-06 first col mean 7.696834245507489e-07 all mean 8.838616849971004e-06
5.135065066497191e-07 5.135075298312586e-07
rl training, epoch6, iter0, batch167/1133, batch loss:5.135075298312586e-07, Training time:78800.3833603859
batch reward last col mean 2.0339532511570724e-06 first col mean 1.4129512919680565e-06 all mean 7.298917353182333e-06
1.6148992187936528e-07 1.6148995030107471e-07
rl training, epoch6, iter0, batch168/1133, batch loss:1.6148995030107471e-07, Training time:78816.68590188026
batch reward last col mean 2.882543412852101e-06 first col mean 5.160174509910576e-07 all mean 4.3998919863952324e-05
2.8753771402989514e-05 2.8753765946021304e-05
rl training, epoch6, iter0, batch169/1133, batch loss:2.8753765946021304e-05, Training time:78832.94913005829
batch reward last col mean 5.064793526798894e-07 first col mean 5.564200478147541e-07 all mean 3.4431889162078733e-06
9.192826269099896e-07 9.192825700665708e-07
rl training, epoch6, iter0, batch170/1133, batch loss:9.192825700665708e-07, Training time:78849.24107956886
batch reward last col mean 4.996389293410175e-07 first col mean 5.881879587832373e-07 all mean 1.3254106306703761e-05
5.001895260647871e-06 5.001898443879327e-06
rl training, epoch6, iter0, batch171/1133, batch loss:5.001898443879327e-06, Training time:78865.3522093296
batch reward last col mean 5.744559530285187e-07 first col mean 1.052375637300429e-06 all mean 1.934288229676895e-05
2.7815476641990244e-05 2.781548391794786e-05
rl training, epoch6, iter0, batch172/1133, batch loss:2.781548391794786e-05, Training time:78881.41855216026
batch reward last col mean 1.7550904885865748e-05 first col mean 4.0433829440189584e-07 all mean 0.0005840479279868305
0.0005247250664979219 0.0005247250664979219
rl training, epoch6, iter0, batch173/1133, batch loss:0.0005247250664979219, Training time:78897.53443694115
batch reward last col mean 2.4390169528487604e-06 first col mean 1.1803373354268842e-06 all mean 3.133761765639065e-06
7.524743068643147e-07 7.524743637077336e-07
rl training, epoch6, iter0, batch174/1133, batch loss:7.524743637077336e-07, Training time:78913.57182145119
batch reward last col mean 3.3282776712439954e-06 first col mean 8.743080002204806e-07 all mean 3.9894512156024575e-06
4.256556621839991e-06 4.256555712345289e-06
rl training, epoch6, iter0, batch175/1133, batch loss:4.256555712345289e-06, Training time:78929.57415699959
batch reward last col mean 7.377796009677695e-07 first col mean 9.349081437903806e-07 all mean 6.553704679390648e-06
1.6533502389393107e-07 1.653336454410237e-07
rl training, epoch6, iter0, batch176/1133, batch loss:1.653336454410237e-07, Training time:78946.07601881027
batch reward last col mean 4.838839231524616e-07 first col mean 5.658982900058618e-07 all mean 1.1574476047826465e-05
7.708227656166855e-08 7.707616589414101e-08
rl training, epoch6, iter0, batch177/1133, batch loss:7.707616589414101e-08, Training time:78962.60635948181
batch reward last col mean 1.4330636304293876e-06 first col mean 7.255775358316896e-07 all mean 3.240993237341172e-06
1.1271459499084813e-07 1.1271334443563319e-07
rl training, epoch6, iter0, batch178/1133, batch loss:1.1271334443563319e-07, Training time:78978.78689098358
batch reward last col mean 3.6124882285548665e-07 first col mean 5.418871182882867e-07 all mean 1.2213766922286595e-06
6.087940818133575e-08 6.087928028364331e-08
rl training, epoch6, iter0, batch179/1133, batch loss:6.087928028364331e-08, Training time:78994.64491319656
batch reward last col mean 4.181814574621967e-07 first col mean 2.3697832148172893e-05 all mean 9.235923243977595e-06
6.792831186430703e-08 6.793204931909713e-08
rl training, epoch6, iter0, batch180/1133, batch loss:6.793204931909713e-08, Training time:79010.74590706825
batch reward last col mean 7.562198334198911e-07 first col mean 1.3451474387693452e-06 all mean 5.940603386989096e-06
1.1364528290869202e-05 1.1364524652890395e-05
rl training, epoch6, iter0, batch181/1133, batch loss:1.1364524652890395e-05, Training time:79026.77755784988
batch reward last col mean 1.4426730103878072e-06 first col mean 6.435192858589289e-07 all mean 8.1953248809441e-06
1.986886218219297e-06 1.9868873550876742e-06
rl training, epoch6, iter0, batch182/1133, batch loss:1.9868873550876742e-06, Training time:79042.7583386898
batch reward last col mean 6.234418833628297e-06 first col mean 2.842445974238217e-05 all mean 2.5974759410019033e-06
3.5789531693808385e-07 3.5789494745586126e-07
rl training, epoch6, iter0, batch183/1133, batch loss:3.5789494745586126e-07, Training time:79058.88558030128
batch reward last col mean 1.0901453606493305e-06 first col mean 1.093912942451425e-06 all mean 9.002252227219287e-06
2.403731741651427e-05 2.403731741651427e-05
rl training, epoch6, iter0, batch184/1133, batch loss:2.403731741651427e-05, Training time:79075.33467149734
batch reward last col mean 6.157929419714492e-07 first col mean 6.430350367736537e-07 all mean 2.5886363346216967e-06
5.048013349551184e-07 5.048005391472543e-07
rl training, epoch6, iter0, batch185/1133, batch loss:5.048005391472543e-07, Training time:79091.61237215996
batch reward last col mean 9.084271823667223e-07 first col mean 0.0014791021822020411 all mean 1.6297539332299493e-05
1.267568308094269e-07 1.2675073435275408e-07
rl training, epoch6, iter0, batch186/1133, batch loss:1.2675073435275408e-07, Training time:79108.00640130043
batch reward last col mean 1.5972651681295247e-06 first col mean 6.145614293018298e-07 all mean 7.930476385809015e-06
1.09973029793764e-07 1.09967466244143e-07
rl training, epoch6, iter0, batch187/1133, batch loss:1.09967466244143e-07, Training time:79124.29398822784
batch reward last col mean 1.597552568455285e-06 first col mean 9.376694833918009e-07 all mean 1.4101166925684083e-05
2.0070799564564368e-06 2.0070804112037877e-06
rl training, epoch6, iter0, batch188/1133, batch loss:2.0070804112037877e-06, Training time:79140.49520730972
batch reward last col mean 1.1451111276983283e-06 first col mean 6.386190420926141e-07 all mean 1.8154250938096084e-06
6.807370596106921e-07 6.80737514358043e-07
rl training, epoch6, iter0, batch189/1133, batch loss:6.80737514358043e-07, Training time:79156.75322580338
batch reward last col mean 5.037875325797359e-07 first col mean 4.359167178336065e-06 all mean 4.6085533540463075e-06
8.872688539440787e-08 8.872530798953449e-08
rl training, epoch6, iter0, batch190/1133, batch loss:8.872530798953449e-08, Training time:79172.74157071114
batch reward last col mean 6.545550377268228e-07 first col mean 7.904672202130314e-06 all mean 2.039126593444962e-05
5.465167305374052e-07 5.46518037936039e-07
rl training, epoch6, iter0, batch191/1133, batch loss:5.46518037936039e-07, Training time:79188.75221157074
batch reward last col mean 1.1619400765994214e-06 first col mean 9.938220273397746e-07 all mean 1.7527737554701162e-06
9.208574169861095e-08 9.208596907228639e-08
rl training, epoch6, iter0, batch192/1133, batch loss:9.208596907228639e-08, Training time:79205.17922282219
batch reward last col mean 9.194054655381478e-06 first col mean 5.963669877928623e-07 all mean 1.2168779903731775e-05
6.141299309092574e-07 6.141295898487442e-07
rl training, epoch6, iter0, batch193/1133, batch loss:6.141295898487442e-07, Training time:79221.57464265823
batch reward last col mean 4.159979653195478e-06 first col mean 3.9214128264575265e-06 all mean 1.3268691873236094e-05
4.613512282958254e-05 4.6135119191603735e-05
rl training, epoch6, iter0, batch194/1133, batch loss:4.6135119191603735e-05, Training time:79237.71495461464
batch reward last col mean 1.0668359209375922e-06 first col mean 7.154798709052557e-07 all mean 6.944728283997392e-06
2.9614906793540285e-07 2.961472489459993e-07
rl training, epoch6, iter0, batch195/1133, batch loss:2.961472489459993e-07, Training time:79253.76206111908
batch reward last col mean 2.2199008071766e-06 first col mean 5.882045002181258e-07 all mean 2.0450124793569557e-06
5.397416202868044e-07 5.39741790817061e-07
rl training, epoch6, iter0, batch196/1133, batch loss:5.39741790817061e-07, Training time:79269.83455467224
batch reward last col mean 1.3337130440049805e-06 first col mean 9.828318979998585e-06 all mean 9.435718311578967e-06
2.559614245001285e-07 2.559578717864497e-07
rl training, epoch6, iter0, batch197/1133, batch loss:2.559578717864497e-07, Training time:79285.9070930481
batch reward last col mean 9.223380175171769e-07 first col mean 1.8715857095230604e-06 all mean 2.7773294277722016e-06
2.552662010657514e-07 2.5526597369207593e-07
rl training, epoch6, iter0, batch198/1133, batch loss:2.5526597369207593e-07, Training time:79302.06364297867
batch reward last col mean 7.830041113265906e-07 first col mean 1.4018852425579098e-06 all mean 1.0718003977672197e-05
1.993736162830828e-07 1.9937057516017376e-07
rl training, epoch6, iter0, batch199/1133, batch loss:1.9937057516017376e-07, Training time:79318.2233479023
batch reward last col mean 2.4221058083639946e-06 first col mean 9.59917656473408e-07 all mean 1.671578866080381e-05
8.712811450095614e-07 8.712759154150262e-07
rl training, epoch6, iter0, batch200/1133, batch loss:8.712759154150262e-07, Training time:79334.27912020683
batch reward last col mean 6.159452823339961e-07 first col mean 8.212579132305109e-07 all mean 1.3053047041466925e-05
2.799729372782167e-07 2.799635012706858e-07
rl training, epoch6, iter0, batch201/1133, batch loss:2.799635012706858e-07, Training time:79350.45594906807
batch reward last col mean 0.00032792790443636477 first col mean 8.611532393842936e-07 all mean 4.287778210709803e-05
2.0338051399448887e-05 2.0338055037427694e-05
rl training, epoch6, iter0, batch202/1133, batch loss:2.0338055037427694e-05, Training time:79366.80906939507
batch reward last col mean 1.8603952867124463e-06 first col mean 1.2327243439358426e-06 all mean 4.716029252449516e-06
1.281470645153604e-07 1.2814906824587524e-07
rl training, epoch6, iter0, batch203/1133, batch loss:1.2814906824587524e-07, Training time:79383.10336947441
batch reward last col mean 5.035846697865054e-05 first col mean 6.19842523974512e-07 all mean 5.532665818464011e-05
4.271823127055541e-05 4.271822399459779e-05
rl training, epoch6, iter0, batch204/1133, batch loss:4.271822399459779e-05, Training time:79399.39225888252
batch reward last col mean 1.302241344092181e-05 first col mean 9.802907925404725e-07 all mean 3.526436921674758e-05
0.00010381118772784248 0.00010381118772784248
rl training, epoch6, iter0, batch205/1133, batch loss:0.00010381118772784248, Training time:79415.73461604118
batch reward last col mean 8.250469818449346e-07 first col mean 5.317941713656182e-07 all mean 1.2308401892369147e-05
4.596132328060776e-07 4.596067810780369e-07
rl training, epoch6, iter0, batch206/1133, batch loss:4.596067810780369e-07, Training time:79432.01554393768
batch reward last col mean 1.7014685909089167e-06 first col mean 4.4769720375370525e-07 all mean 5.928603059146553e-06
1.026485847432923e-06 1.0264860748065985e-06
rl training, epoch6, iter0, batch207/1133, batch loss:1.0264860748065985e-06, Training time:79448.17668199539
batch reward last col mean 1.4251411357690813e-06 first col mean 2.0004042653454235e-06 all mean 1.6038599142120802e-06
1.300515464208729e-07 1.3005161747514649e-07
rl training, epoch6, iter0, batch208/1133, batch loss:1.3005161747514649e-07, Training time:79464.32206463814
batch reward last col mean 1.5457651443284703e-06 first col mean 1.4484286339211394e-06 all mean 1.97392455447698e-06
1.8283017766407283e-07 1.828301492423634e-07
rl training, epoch6, iter0, batch209/1133, batch loss:1.828301492423634e-07, Training time:79480.52392816544
batch reward last col mean 2.303835572092794e-06 first col mean 1.1076943337684497e-05 all mean 6.281031801336212e-06
1.318331754873725e-07 1.3183041858155775e-07
rl training, epoch6, iter0, batch210/1133, batch loss:1.3183041858155775e-07, Training time:79496.54579734802
batch reward last col mean 4.788192313753825e-07 first col mean 6.992695489316247e-07 all mean 1.3376653669183725e-06
3.227545519735031e-08 3.2275089267841395e-08
rl training, epoch6, iter0, batch211/1133, batch loss:3.2275089267841395e-08, Training time:79512.65508651733
batch reward last col mean 5.769754238826863e-07 first col mean 7.898230478531332e-07 all mean 1.2209976375743281e-05
2.2749442507574713e-07 2.2749210870642855e-07
rl training, epoch6, iter0, batch212/1133, batch loss:2.2749210870642855e-07, Training time:79528.67394542694
batch reward last col mean 7.379616135949618e-07 first col mean 7.942733191157458e-07 all mean 1.3077129779048846e-06
7.229164822319945e-08 7.22916055906353e-08
rl training, epoch6, iter0, batch213/1133, batch loss:7.22916055906353e-08, Training time:79544.87534570694
batch reward last col mean 1.5174882719293237e-06 first col mean 4.156351678830106e-06 all mean 5.2547711675288156e-06
1.2639782198675675e-07 1.2639509350265143e-07
rl training, epoch6, iter0, batch214/1133, batch loss:1.2639509350265143e-07, Training time:79561.0201086998
batch reward last col mean 0.0003834864473901689 first col mean 4.386306784454064e-07 all mean 0.00014249894593376666
0.00010970983566949144 0.00010970982839353383
rl training, epoch6, iter0, batch215/1133, batch loss:0.00010970982839353383, Training time:79577.14502573013
batch reward last col mean 9.632638466428034e-06 first col mean 0.0014947328018024564 all mean 4.104903564439155e-05
1.0796228707476985e-05 1.0796235073939897e-05
rl training, epoch6, iter0, batch216/1133, batch loss:1.0796235073939897e-05, Training time:79593.3332939148
batch reward last col mean 2.041705374722369e-05 first col mean 5.604754278465407e-06 all mean 6.414113613573136e-06
3.5601394756668014e-06 3.560138793545775e-06
rl training, epoch6, iter0, batch217/1133, batch loss:3.560138793545775e-06, Training time:79609.3850672245
batch reward last col mean 0.0007734740502201021 first col mean 5.98123165218567e-07 all mean 0.0009061529999598861
0.0004145580460317433 0.0004145580460317433
rl training, epoch6, iter0, batch218/1133, batch loss:0.0004145580460317433, Training time:79625.4777302742
batch reward last col mean 1.1239727655265597e-06 first col mean 1.1223730780329788e-06 all mean 1.5621973943780176e-05
1.4979309526097495e-06 1.497935613770096e-06
rl training, epoch6, iter0, batch219/1133, batch loss:1.497935613770096e-06, Training time:79641.45915985107
batch reward last col mean 3.707097846472607e-07 first col mean 7.582412422380003e-07 all mean 6.095136541262036e-06
1.6177955330931582e-07 1.6178218231743813e-07
rl training, epoch6, iter0, batch220/1133, batch loss:1.6178218231743813e-07, Training time:79658.04985523224
batch reward last col mean 1.3075804190521012e-06 first col mean 1.4247050330595812e-06 all mean 3.992643996753031e-06
4.757114879794244e-07 4.7571151640113385e-07
rl training, epoch6, iter0, batch221/1133, batch loss:4.7571151640113385e-07, Training time:79674.23847293854
batch reward last col mean 1.2493266012825188e-06 first col mean 6.162375143503596e-07 all mean 1.2767730368068442e-05
4.399522367748432e-05 4.3995227315463126e-05
rl training, epoch6, iter0, batch222/1133, batch loss:4.3995227315463126e-05, Training time:79690.51084399223
batch reward last col mean 5.487636008183472e-05 first col mean 8.339057444572973e-07 all mean 0.00013812797260470688
8.12682046671398e-05 8.12682046671398e-05
rl training, epoch6, iter0, batch223/1133, batch loss:8.12682046671398e-05, Training time:79706.99011015892
batch reward last col mean 0.0037947294767946005 first col mean 8.138692919601453e-07 all mean 0.002017695689573884
0.0008058029343374074 0.0008058028761297464
rl training, epoch6, iter0, batch224/1133, batch loss:0.0008058028761297464, Training time:79723.3413579464
batch reward last col mean 5.274230716167949e-06 first col mean 7.555718752882967e-07 all mean 2.212507934018504e-05
4.4453019654611126e-05 4.445302329258993e-05
rl training, epoch6, iter0, batch225/1133, batch loss:4.445302329258993e-05, Training time:79739.42020154
batch reward last col mean 7.373803896371101e-07 first col mean 5.629912607219012e-07 all mean 1.8456792076904094e-06
3.358656215368683e-07 3.35865934175672e-07
rl training, epoch6, iter0, batch226/1133, batch loss:3.35865934175672e-07, Training time:79755.57735705376
batch reward last col mean 9.65818799159024e-07 first col mean 7.679477107558341e-07 all mean 8.286459888040554e-06
2.7232375941821374e-05 2.7232372303842567e-05
rl training, epoch6, iter0, batch227/1133, batch loss:2.7232372303842567e-05, Training time:79771.71308541298
batch reward last col mean 1.4581627283405396e-06 first col mean 1.081041546058259e-06 all mean 2.7997762117593084e-06
7.395437933155335e-07 7.395437933155335e-07
rl training, epoch6, iter0, batch228/1133, batch loss:7.395437933155335e-07, Training time:79787.83545613289
batch reward last col mean 2.3133902686822694e-06 first col mean 7.719996801824891e-07 all mean 2.7233982109464705e-06
4.080914948190184e-07 4.0809123902363353e-07
rl training, epoch6, iter0, batch229/1133, batch loss:4.0809123902363353e-07, Training time:79804.0394103527
batch reward last col mean 7.825978173059411e-06 first col mean 4.7203897679537477e-07 all mean 1.0369850542701897e-06
3.017711946995405e-07 3.0177116627783107e-07
rl training, epoch6, iter0, batch230/1133, batch loss:3.0177116627783107e-07, Training time:79820.15100288391
batch reward last col mean 7.494683814002201e-06 first col mean 0.0008943023858591914 all mean 2.5081128114834428e-05
3.1768015560373897e-06 3.176808377247653e-06
rl training, epoch6, iter0, batch231/1133, batch loss:3.176808377247653e-06, Training time:79836.40089869499
batch reward last col mean 1.7531085632072063e-06 first col mean 1.3068301996099763e-06 all mean 4.793740572495153e-06
3.992121037299512e-06 3.992121492046863e-06
rl training, epoch6, iter0, batch232/1133, batch loss:3.992121492046863e-06, Training time:79852.43387508392
batch reward last col mean 2.3822726689104456e-06 first col mean 6.51264599582646e-07 all mean 1.8343530427955557e-06
2.3544271243736148e-07 2.3544271243736148e-07
rl training, epoch6, iter0, batch233/1133, batch loss:2.3544271243736148e-07, Training time:79868.39362955093
batch reward last col mean 1.633982606108475e-06 first col mean 0.0001129247757489793 all mean 3.5270122680230998e-06
9.790710464585572e-08 9.79075451823519e-08
rl training, epoch6, iter0, batch234/1133, batch loss:9.79075451823519e-08, Training time:79884.35821342468
batch reward last col mean 1.893874923553085e-06 first col mean 8.720847972654155e-07 all mean 1.4156315046420787e-05
3.1108761504583526e-06 3.1108700113691157e-06
rl training, epoch6, iter0, batch235/1133, batch loss:3.1108700113691157e-06, Training time:79900.23385620117
batch reward last col mean 1.9413584595895372e-05 first col mean 9.622054676583502e-06 all mean 1.0340600056224503e-05
1.2639352462429088e-06 1.26393717891915e-06
rl training, epoch6, iter0, batch236/1133, batch loss:1.26393717891915e-06, Training time:79916.06666707993
batch reward last col mean 0.0021910755895078182 first col mean 0.0009092715918086469 all mean 0.0017259186133742332
0.00038921122904866934 0.00038921122904866934
rl training, epoch6, iter0, batch237/1133, batch loss:0.00038921122904866934, Training time:79932.06940865517
batch reward last col mean 4.5096319922777184e-07 first col mean 6.628192750213202e-07 all mean 1.3205607274358044e-06
9.961457436702403e-08 9.961476621356269e-08
rl training, epoch6, iter0, batch238/1133, batch loss:9.961476621356269e-08, Training time:79948.26517486572
batch reward last col mean 1.050338596542133e-06 first col mean 1.4684483176097274e-06 all mean 4.918564172839979e-06
5.0434268814569805e-06 5.043427336204331e-06
rl training, epoch6, iter0, batch239/1133, batch loss:5.043427336204331e-06, Training time:79964.22379922867
batch reward last col mean 3.465697318461025e-06 first col mean 1.2212142337375553e-06 all mean 3.6746558180311695e-05
2.2236072254600003e-06 2.2235997221287107e-06
rl training, epoch6, iter0, batch240/1133, batch loss:2.2235997221287107e-06, Training time:79980.12697958946
batch reward last col mean 1.0875483894778881e-05 first col mean 1.3903384115110384e-06 all mean 4.805437583854655e-06
1.345746227343625e-06 1.345747023151489e-06
rl training, epoch6, iter0, batch241/1133, batch loss:1.345747023151489e-06, Training time:79996.08164215088
batch reward last col mean 0.0004643478023353964 first col mean 4.887852469437348e-07 all mean 0.00046368318726308644
3.567362000467256e-05 3.567362000467256e-05
rl training, epoch6, iter0, batch242/1133, batch loss:3.567362000467256e-05, Training time:80012.21087574959
batch reward last col mean 4.6495904825860634e-05 first col mean 6.931452958269801e-07 all mean 5.865930870641023e-05
1.668589720793534e-05 1.6685895388945937e-05
rl training, epoch6, iter0, batch243/1133, batch loss:1.6685895388945937e-05, Training time:80028.21055960655
batch reward last col mean 8.872958687788923e-07 first col mean 9.363189974465058e-07 all mean 3.830169589491561e-06
3.1191794391816074e-07 3.119180860267079e-07
rl training, epoch6, iter0, batch244/1133, batch loss:3.119180860267079e-07, Training time:80044.25871753693
batch reward last col mean 1.5310879462049343e-06 first col mean 8.15584655811108e-07 all mean 1.9591275304264855e-06
2.1343714706745232e-07 2.1343720391087118e-07
rl training, epoch6, iter0, batch245/1133, batch loss:2.1343720391087118e-07, Training time:80060.41462898254
batch reward last col mean 5.796948698844062e-07 first col mean 6.189802661538124e-07 all mean 5.240258815319976e-06
4.300824230085709e-08 4.301066880429971e-08
rl training, epoch6, iter0, batch246/1133, batch loss:4.301066880429971e-08, Training time:80076.7518131733
batch reward last col mean 2.598476953608042e-07 first col mean 8.029061291381367e-07 all mean 1.5988043742254376e-05
6.002493790902008e-08 6.001408792144503e-08
rl training, epoch6, iter0, batch247/1133, batch loss:6.001408792144503e-08, Training time:80093.05139255524
batch reward last col mean 1.7468701116740704e-06 first col mean 1.0992138186338707e-06 all mean 4.546342097455636e-06
1.6304717576076655e-07 1.6304895211760595e-07
rl training, epoch6, iter0, batch248/1133, batch loss:1.6304895211760595e-07, Training time:80109.34122490883
batch reward last col mean 0.0011266606161370873 first col mean 5.851210289620212e-07 all mean 0.001027109450660646
0.00010530905274208635 0.00010530905274208635
rl training, epoch6, iter0, batch249/1133, batch loss:0.00010530905274208635, Training time:80125.6419107914
batch reward last col mean 4.796425855602138e-06 first col mean 7.151182899178821e-07 all mean 2.197707772211288e-06
3.179554823873332e-07 3.1795536870049546e-07
rl training, epoch6, iter0, batch250/1133, batch loss:3.1795536870049546e-07, Training time:80142.03315782547
batch reward last col mean 2.2822441678727046e-06 first col mean 3.543641651049256e-05 all mean 8.999865713121835e-06
2.0559209588100202e-06 2.055920731436345e-06
rl training, epoch6, iter0, batch251/1133, batch loss:2.055920731436345e-06, Training time:80158.04910850525
batch reward last col mean 5.04075387652847e-06 first col mean 1.1743957202270394e-06 all mean 4.076175173395313e-06
3.9564474718645215e-06 3.9564474718645215e-06
rl training, epoch6, iter0, batch252/1133, batch loss:3.9564474718645215e-06, Training time:80174.0834145546
batch reward last col mean 2.4708582714083605e-05 first col mean 7.402961728075752e-07 all mean 1.466145840822719e-05
6.995663625275483e-06 6.995663625275483e-06
rl training, epoch6, iter0, batch253/1133, batch loss:6.995663625275483e-06, Training time:80190.13446831703
batch reward last col mean 3.921870302292518e-06 first col mean 9.367786901748332e-07 all mean 5.189227067603497e-06
4.79471225389716e-07 4.794715096068103e-07
rl training, epoch6, iter0, batch254/1133, batch loss:4.794715096068103e-07, Training time:80206.18218541145
batch reward last col mean 0.0005435043131001294 first col mean 4.6927755192882614e-07 all mean 0.0013151522725820541
0.0002584280155133456 0.0002584280737210065
rl training, epoch6, iter0, batch255/1133, batch loss:0.0002584280737210065, Training time:80222.25706410408
batch reward last col mean 3.3551430078659905e-06 first col mean 1.8317095964448527e-06 all mean 5.1875504141207784e-06
3.8501934795931447e-07 3.850195753329899e-07
rl training, epoch6, iter0, batch256/1133, batch loss:3.850195753329899e-07, Training time:80238.4466035366
batch reward last col mean 9.434893968318647e-07 first col mean 1.5695570709794993e-06 all mean 2.7691291961673414e-06
1.8958411374114803e-07 1.8958397163260088e-07
rl training, epoch6, iter0, batch257/1133, batch loss:1.8958397163260088e-07, Training time:80254.4948990345
batch reward last col mean 1.1717199868144235e-06 first col mean 2.8528429538710043e-06 all mean 1.0443651262903586e-05
2.462390693835914e-05 2.462390693835914e-05
rl training, epoch6, iter0, batch258/1133, batch loss:2.462390693835914e-05, Training time:80270.61988019943
batch reward last col mean 1.1754643765016226e-06 first col mean 1.3234431435193983e-06 all mean 1.1528336472110823e-06
1.2166276519565145e-07 1.216627225630873e-07
rl training, epoch6, iter0, batch259/1133, batch loss:1.216627225630873e-07, Training time:80286.68871498108
batch reward last col mean 8.704742867848836e-06 first col mean 3.0379205782082863e-06 all mean 5.263705133984331e-06
1.160325496130099e-06 1.160325496130099e-06
rl training, epoch6, iter0, batch260/1133, batch loss:1.160325496130099e-06, Training time:80302.78193545341
batch reward last col mean 2.162482815037947e-06 first col mean 6.015054623276228e-07 all mean 1.0722059187173727e-06
1.564462053238458e-07 1.5644614848042693e-07
rl training, epoch6, iter0, batch261/1133, batch loss:1.5644614848042693e-07, Training time:80318.9243695736
batch reward last col mean 5.177313596504973e-06 first col mean 6.535074135172181e-07 all mean 1.8659689885680564e-05
1.0959375913444092e-06 1.0959399787680013e-06
rl training, epoch6, iter0, batch262/1133, batch loss:1.0959399787680013e-06, Training time:80335.16463398933
batch reward last col mean 3.114870560239069e-05 first col mean 6.474105020970455e-07 all mean 7.335484497161815e-06
2.3190543743112357e-06 2.319049826837727e-06
rl training, epoch6, iter0, batch263/1133, batch loss:2.319049826837727e-06, Training time:80351.39304661751
batch reward last col mean 5.293724143484724e-07 first col mean 0.0006095001590438187 all mean 8.516494744981173e-06
4.829996100852441e-07 4.829981321563537e-07
rl training, epoch6, iter0, batch264/1133, batch loss:4.829981321563537e-07, Training time:80367.61953806877
batch reward last col mean 7.509481747547397e-07 first col mean 1.1899010132765397e-06 all mean 3.3552496461197734e-05
1.5132976614040672e-06 1.513292431809532e-06
rl training, epoch6, iter0, batch265/1133, batch loss:1.513292431809532e-06, Training time:80384.08084988594
batch reward last col mean 0.0011319349287077785 first col mean 9.70889232121408e-07 all mean 0.00012029975187033415
6.782084528822452e-05 6.782083073630929e-05
rl training, epoch6, iter0, batch266/1133, batch loss:6.782083073630929e-05, Training time:80400.35643839836
batch reward last col mean 0.0005167412455193698 first col mean 1.3036183190706652e-06 all mean 0.0006622899090871215
0.00033691080170683563 0.00033691080170683563
rl training, epoch6, iter0, batch267/1133, batch loss:0.00033691080170683563, Training time:80416.59208083153
batch reward last col mean 9.682316158432513e-05 first col mean 1.1374977475497872e-06 all mean 3.104986535618082e-05
1.578136652824469e-05 1.578136652824469e-05
rl training, epoch6, iter0, batch268/1133, batch loss:1.578136652824469e-05, Training time:80432.84704637527
batch reward last col mean 1.1142847142764367e-06 first col mean 8.917810419006855e-07 all mean 8.793185770628043e-06
4.107603672309779e-06 4.107600943825673e-06
rl training, epoch6, iter0, batch269/1133, batch loss:4.107600943825673e-06, Training time:80448.97912478447
batch reward last col mean 0.0002623795880936086 first col mean 9.590628451405792e-07 all mean 0.0003821519494522363
0.00019569887081161141 0.00019569885625969619
rl training, epoch6, iter0, batch270/1133, batch loss:0.00019569885625969619, Training time:80464.94840836525
batch reward last col mean 5.62656452984811e-07 first col mean 8.805166658021335e-07 all mean 1.0116573321283795e-05
3.0279971952040796e-07 3.0280577334451664e-07
rl training, epoch6, iter0, batch271/1133, batch loss:3.0280577334451664e-07, Training time:80481.06254124641
batch reward last col mean 2.5728870241437107e-05 first col mean 9.424798577128968e-07 all mean 1.7183634554385208e-05
5.839317509526154e-06 5.839318419020856e-06
rl training, epoch6, iter0, batch272/1133, batch loss:5.839318419020856e-06, Training time:80497.09203648567
batch reward last col mean 4.5436627260642126e-07 first col mean 1.9275396425655345e-06 all mean 2.0492589101195335e-05
8.833398368324197e-08 8.833138309682909e-08
rl training, epoch6, iter0, batch273/1133, batch loss:8.833138309682909e-08, Training time:80513.06768274307
batch reward last col mean 4.956184511684114e-06 first col mean 1.6381536624976434e-06 all mean 2.4896758077375125e-06
3.4343401011938113e-07 3.4343383958912455e-07
rl training, epoch6, iter0, batch274/1133, batch loss:3.4343383958912455e-07, Training time:80529.03532671928
batch reward last col mean 2.195382876379881e-06 first col mean 1.3170624697522726e-05 all mean 5.512042207556078e-06
2.919667281275906e-07 2.919658754763077e-07
rl training, epoch6, iter0, batch275/1133, batch loss:2.919658754763077e-07, Training time:80545.06189894676
batch reward last col mean 5.771591418124444e-07 first col mean 4.247501408372045e-07 all mean 1.2121702184231253e-06
6.419764986276277e-08 6.419779907673728e-08
rl training, epoch6, iter0, batch276/1133, batch loss:6.419779907673728e-08, Training time:80561.5170185566
batch reward last col mean 1.9727824565052288e-06 first col mean 9.359682735521346e-07 all mean 1.0601233043416869e-05
4.8476949814357795e-06 4.847696800425183e-06
rl training, epoch6, iter0, batch277/1133, batch loss:4.847696800425183e-06, Training time:80577.5681939125
batch reward last col mean 1.4423897027882049e-06 first col mean 8.730170293347328e-07 all mean 1.734546572151885e-06
4.104875870325486e-07 4.104874733457109e-07
rl training, epoch6, iter0, batch278/1133, batch loss:4.104874733457109e-07, Training time:80593.60881495476
batch reward last col mean 2.935809243354015e-05 first col mean 8.822398740448989e-07 all mean 1.6604062693659216e-05
5.785033863503486e-06 5.785032954008784e-06
rl training, epoch6, iter0, batch279/1133, batch loss:5.785032954008784e-06, Training time:80609.73496961594
batch reward last col mean 8.33474189221306e-07 first col mean 4.992824869987089e-06 all mean 4.806873675988754e-06
1.501112478763389e-06 1.501112819823902e-06
rl training, epoch6, iter0, batch280/1133, batch loss:1.501112819823902e-06, Training time:80625.81914663315
batch reward last col mean 2.531404788896907e-06 first col mean 1.2345797131274594e-06 all mean 1.7263711924897507e-05
1.1124110415039468e-06 1.1124125194328371e-06
rl training, epoch6, iter0, batch281/1133, batch loss:1.1124125194328371e-06, Training time:80641.9342148304
batch reward last col mean 6.910460115250316e-07 first col mean 7.748115535832767e-07 all mean 1.1197170351806562e-05
3.913705768354703e-06 3.913701220881194e-06
rl training, epoch6, iter0, batch282/1133, batch loss:3.913701220881194e-06, Training time:80658.26660943031
batch reward last col mean 0.00014106729940976948 first col mean 2.8516899419628317e-06 all mean 0.00013800586748402566
1.5027242625365034e-05 1.5027243534859736e-05
rl training, epoch6, iter0, batch283/1133, batch loss:1.5027243534859736e-05, Training time:80674.55942392349
batch reward last col mean 4.6649751311633736e-05 first col mean 5.298694532029913e-07 all mean 6.03614462306723e-05
3.695968189276755e-05 3.695967825478874e-05
rl training, epoch6, iter0, batch284/1133, batch loss:3.695967825478874e-05, Training time:80691.01506447792
batch reward last col mean 1.940428319358034e-06 first col mean 1.4837065691608586e-06 all mean 3.793799578488688e-06
5.949294177298725e-07 5.949290766693593e-07
rl training, epoch6, iter0, batch285/1133, batch loss:5.949290766693593e-07, Training time:80707.2917804718
batch reward last col mean 8.391433766519185e-06 first col mean 6.685551170448889e-07 all mean 0.0001516707707196474
0.00010575258056633174 0.00010575258784228936
rl training, epoch6, iter0, batch286/1133, batch loss:0.00010575258784228936, Training time:80723.77305269241
batch reward last col mean 1.4103617331784335e-06 first col mean 1.9243802853452507e-06 all mean 1.0215973816229962e-05
2.8822128683714254e-07 2.88223560573897e-07
rl training, epoch6, iter0, batch287/1133, batch loss:2.88223560573897e-07, Training time:80740.97829055786
batch reward last col mean 0.0030191433615982533 first col mean 5.842903760822082e-07 all mean 0.0014068873133510351
0.0006593163125216961 0.0006593163125216961
rl training, epoch6, iter0, batch288/1133, batch loss:0.0006593163125216961, Training time:80758.05651926994
batch reward last col mean 5.274550858302973e-07 first col mean 9.863634886642103e-07 all mean 9.652206244936679e-06
1.0001855343944044e-07 1.0002394645880486e-07
rl training, epoch6, iter0, batch289/1133, batch loss:1.0002394645880486e-07, Training time:80774.97942018509
batch reward last col mean 3.7109764434717363e-06 first col mean 4.2503015151851287e-07 all mean 1.9605224679253297e-06
8.717400419300247e-07 8.717398145563493e-07
rl training, epoch6, iter0, batch290/1133, batch loss:8.717398145563493e-07, Training time:80792.0985622406
batch reward last col mean 1.1912211448361631e-05 first col mean 6.539041237374477e-07 all mean 3.2699794246582314e-05
1.8840690245269798e-05 1.884068115032278e-05
rl training, epoch6, iter0, batch291/1133, batch loss:1.884068115032278e-05, Training time:80809.9317855835
batch reward last col mean 3.1341901376436e-06 first col mean 1.0554440450505354e-06 all mean 9.028255590237677e-06
2.576675228738168e-07 2.5766496491996804e-07
rl training, epoch6, iter0, batch292/1133, batch loss:2.5766496491996804e-07, Training time:80826.63760995865
batch reward last col mean 1.2403802429616917e-06 first col mean 1.2374149491733988e-06 all mean 2.9129480481060455e-06
4.4962467882214696e-07 4.496241672313772e-07
rl training, epoch6, iter0, batch293/1133, batch loss:4.496241672313772e-07, Training time:80844.14062166214
batch reward last col mean 8.540720841665461e-07 first col mean 2.5264351279474795e-05 all mean 3.1374488571600523e-06
3.9240893556780065e-07 3.924087081941252e-07
rl training, epoch6, iter0, batch294/1133, batch loss:3.924087081941252e-07, Training time:80861.50920343399
batch reward last col mean 3.768019723793259e-06 first col mean 4.979112304681621e-07 all mean 1.4288605143519817e-06
7.076752126522479e-07 7.076752694956667e-07
rl training, epoch6, iter0, batch295/1133, batch loss:7.076752694956667e-07, Training time:80878.24268889427
batch reward last col mean 5.902539896851522e-07 first col mean 1.4251990023694816e-06 all mean 1.8939126675832085e-06
1.1848158010252519e-07 1.1848153036453368e-07
rl training, epoch6, iter0, batch296/1133, batch loss:1.1848153036453368e-07, Training time:80894.42208194733
batch reward last col mean 1.7375100469507743e-06 first col mean 1.2707749874607543e-06 all mean 1.7597492387722014e-06
4.036822929265327e-07 4.0368217923969496e-07
rl training, epoch6, iter0, batch297/1133, batch loss:4.0368217923969496e-07, Training time:80910.39994549751
batch reward last col mean 5.919941372667381e-07 first col mean 5.458999794427655e-07 all mean 1.0931426004390232e-06
1.9321493027746328e-07 1.9321493027746328e-07
rl training, epoch6, iter0, batch298/1133, batch loss:1.9321493027746328e-07, Training time:80927.4992351532
batch reward last col mean 1.7989016214414733e-06 first col mean 5.44416536740755e-07 all mean 5.175405476620654e-06
5.761714874097379e-07 5.761699526374287e-07
rl training, epoch6, iter0, batch299/1133, batch loss:5.761699526374287e-07, Training time:80944.89272379875
batch reward last col mean 0.005822570528835058 first col mean 8.034050438254781e-07 all mean 0.0009842514991760254
0.0006537262815982103 0.0006537261069752276
rl training, epoch6, iter0, batch300/1133, batch loss:0.0006537261069752276, Training time:80962.32737183571
batch reward last col mean 0.0008089221664704382 first col mean 2.1590085452771746e-06 all mean 9.140864858636633e-05
4.2348168790340424e-05 4.2348168790340424e-05
rl training, epoch6, iter0, batch301/1133, batch loss:4.2348168790340424e-05, Training time:80979.31699419022
batch reward last col mean 0.00042594916885718703 first col mean 1.0131245744560147e-06 all mean 0.00010524940444156528
0.00011906361032743007 0.00011906361032743007
rl training, epoch6, iter0, batch302/1133, batch loss:0.00011906361032743007, Training time:80995.80363607407
batch reward last col mean 9.941468306351453e-07 first col mean 4.177479240752291e-06 all mean 2.2460778836830286e-06
9.35966909310082e-07 9.35966909310082e-07
rl training, epoch6, iter0, batch303/1133, batch loss:9.35966909310082e-07, Training time:81013.58491873741
batch reward last col mean 3.506356733851135e-07 first col mean 4.430405624589184e-06 all mean 1.6424244677182287e-05
5.038253902966972e-07 5.038241397414822e-07
rl training, epoch6, iter0, batch304/1133, batch loss:5.038241397414822e-07, Training time:81032.61787295341
batch reward last col mean 1.2787560308424872e-06 first col mean 1.5961021517796325e-06 all mean 1.6113344827317633e-05
2.6312645218240505e-07 2.631271343034314e-07
rl training, epoch6, iter0, batch305/1133, batch loss:2.631271343034314e-07, Training time:81050.02275156975
batch reward last col mean 1.3649001857629628e-06 first col mean 1.0262472187605454e-06 all mean 6.197123184392694e-06
2.3071288524079137e-07 2.3071363841609127e-07
rl training, epoch6, iter0, batch306/1133, batch loss:2.3071363841609127e-07, Training time:81066.67021775246
batch reward last col mean 2.013652419918799e-06 first col mean 1.2506438906711992e-06 all mean 4.902894943370484e-06
6.356808057716989e-07 6.356804078677669e-07
rl training, epoch6, iter0, batch307/1133, batch loss:6.356804078677669e-07, Training time:81083.3116285801
batch reward last col mean 4.600564352585934e-06 first col mean 6.817577968831756e-07 all mean 8.416584023507312e-05
1.2934782716911286e-05 1.2934782716911286e-05
rl training, epoch6, iter0, batch308/1133, batch loss:1.2934782716911286e-05, Training time:81100.66537570953
batch reward last col mean 2.090774387397687e-06 first col mean 5.346581929188687e-06 all mean 2.255403160233982e-05
2.00980721842825e-07 2.009774533462405e-07
rl training, epoch6, iter0, batch309/1133, batch loss:2.009774533462405e-07, Training time:81118.46127080917
batch reward last col mean 0.0001903282682178542 first col mean 1.0013384326157393e-06 all mean 3.494820703053847e-05
3.228899367968552e-05 3.2288997317664325e-05
rl training, epoch6, iter0, batch310/1133, batch loss:3.2288997317664325e-05, Training time:81135.64787912369
batch reward last col mean 1.0501036058485624e-06 first col mean 1.0897291531364317e-06 all mean 5.467554728966206e-06
2.3683412564423634e-07 2.3683385563799675e-07
rl training, epoch6, iter0, batch311/1133, batch loss:2.3683385563799675e-07, Training time:81151.99000120163
batch reward last col mean 6.192168484631111e-07 first col mean 2.385333937127143e-05 all mean 6.359172857628437e-06
1.023556635004752e-07 1.0235955727466717e-07
rl training, epoch6, iter0, batch312/1133, batch loss:1.0235955727466717e-07, Training time:81168.31821703911
batch reward last col mean 6.053932679606078e-07 first col mean 1.0048377134808106e-06 all mean 2.234011617474607e-06
8.514498262002235e-08 8.514432892070545e-08
rl training, epoch6, iter0, batch313/1133, batch loss:8.514432892070545e-08, Training time:81184.76666283607
batch reward last col mean 3.6208723486197414e-07 first col mean 3.2450535059069807e-07 all mean 1.6325129763572477e-06
4.677865561575345e-08 4.6779081941394907e-08
rl training, epoch6, iter0, batch314/1133, batch loss:4.6779081941394907e-08, Training time:81201.06602907181
batch reward last col mean 4.391658148961142e-05 first col mean 6.868148716421274e-07 all mean 2.7712749215424992e-06
3.7924066873529227e-06 3.7924064599792473e-06
rl training, epoch6, iter0, batch315/1133, batch loss:3.7924064599792473e-06, Training time:81217.52456450462
batch reward last col mean 1.8090405546900001e-06 first col mean 1.5399918993352912e-06 all mean 1.5740062735858373e-05
2.5531076630613825e-07 2.5530050606903387e-07
rl training, epoch6, iter0, batch316/1133, batch loss:2.5530050606903387e-07, Training time:81234.99907946587
batch reward last col mean 7.55698101784219e-06 first col mean 3.830450623354409e-06 all mean 2.0747924281749874e-05
1.0294214916939382e-05 1.0294216735928785e-05
rl training, epoch6, iter0, batch317/1133, batch loss:1.0294216735928785e-05, Training time:81253.10185337067
batch reward last col mean 4.377192510673922e-07 first col mean 8.771710326982429e-07 all mean 7.424010163958883e-06
3.1425730639966787e-07 3.142542652767588e-07
rl training, epoch6, iter0, batch318/1133, batch loss:3.142542652767588e-07, Training time:81271.04105782509
batch reward last col mean 7.636797363375081e-07 first col mean 6.337050990623538e-07 all mean 1.5002644886408234e-06
1.1913260067331066e-07 1.1913274278185781e-07
rl training, epoch6, iter0, batch319/1133, batch loss:1.1913274278185781e-07, Training time:81288.15030908585
batch reward last col mean 4.983003236702643e-07 first col mean 6.687604354738141e-07 all mean 3.2348355034628185e-06
4.309786163503304e-06 4.309786163503304e-06
rl training, epoch6, iter0, batch320/1133, batch loss:4.309786163503304e-06, Training time:81304.15264773369
batch reward last col mean 1.7603217202122323e-05 first col mean 3.6333970001578564e-06 all mean 5.002809757570503e-06
9.943553322955268e-07 9.943541954271495e-07
rl training, epoch6, iter0, batch321/1133, batch loss:9.943541954271495e-07, Training time:81320.20965480804
batch reward last col mean 2.1805257347295992e-05 first col mean 7.383159186247212e-07 all mean 2.7015072191716172e-05
8.205777703551576e-06 8.205777703551576e-06
rl training, epoch6, iter0, batch322/1133, batch loss:8.205777703551576e-06, Training time:81336.43897271156
batch reward last col mean 1.203786268888507e-06 first col mean 1.30325781810825e-06 all mean 1.9719986084965058e-05
2.121021367429421e-07 2.1210657052961324e-07
rl training, epoch6, iter0, batch323/1133, batch loss:2.1210657052961324e-07, Training time:81353.24830341339
batch reward last col mean 1.4504966202366631e-05 first col mean 1.2283475371077657e-05 all mean 0.002523699076846242
0.0019612584728747606 0.001961258240044117
rl training, epoch6, iter0, batch324/1133, batch loss:0.001961258240044117, Training time:81370.9913175106
batch reward last col mean 6.385376991602243e-07 first col mean 5.0523831305326894e-05 all mean 1.5464553143829107e-05
4.4631255491367483e-07 4.463118727926485e-07
rl training, epoch6, iter0, batch325/1133, batch loss:4.463118727926485e-07, Training time:81388.70741462708
batch reward last col mean 1.8832564592230483e-06 first col mean 4.824121788260527e-06 all mean 9.577903256285936e-06
7.578725558232691e-07 7.578713052680541e-07
rl training, epoch6, iter0, batch326/1133, batch loss:7.578713052680541e-07, Training time:81408.21233510971
batch reward last col mean 1.0642910410751938e-06 first col mean 1.0436192496854346e-06 all mean 5.397443601395935e-06
4.046917183586629e-06 4.046918093081331e-06
rl training, epoch6, iter0, batch327/1133, batch loss:4.046918093081331e-06, Training time:81426.16610503197
batch reward last col mean 1.96150244846649e-06 first col mean 1.3189361425247625e-06 all mean 2.554196271375986e-06
4.6233918737925705e-07 4.6233935790951364e-07
rl training, epoch6, iter0, batch328/1133, batch loss:4.6233935790951364e-07, Training time:81442.63310456276
batch reward last col mean 0.0002820863446686417 first col mean 0.00030161571339704096 all mean 0.0003157056635245681
4.0214705222751945e-05 4.021470158477314e-05
rl training, epoch6, iter0, batch329/1133, batch loss:4.021470158477314e-05, Training time:81458.97105813026
batch reward last col mean 2.2319736672216095e-05 first col mean 6.300564336925163e-07 all mean 1.2800304830307141e-05
2.5430556434002938e-06 2.5430576897633728e-06
rl training, epoch6, iter0, batch330/1133, batch loss:2.5430576897633728e-06, Training time:81475.37120056152
batch reward last col mean 4.2312632331231725e-07 first col mean 4.0168544046537136e-07 all mean 8.45320028020069e-06
2.0717411644000094e-06 2.0717418465210358e-06
rl training, epoch6, iter0, batch331/1133, batch loss:2.0717418465210358e-06, Training time:81491.51956915855
batch reward last col mean 7.242107358251815e-07 first col mean 4.409668690641411e-06 all mean 3.89189199268003e-06
2.562634563219035e-06 2.5626343358453596e-06
rl training, epoch6, iter0, batch332/1133, batch loss:2.5626343358453596e-06, Training time:81507.77611708641
batch reward last col mean 5.665125399900717e-07 first col mean 1.2321245321800234e-06 all mean 2.9952645945741097e-06
2.953028115371126e-07 2.9530249889830884e-07
rl training, epoch6, iter0, batch333/1133, batch loss:2.9530249889830884e-07, Training time:81524.66076827049
batch reward last col mean 2.259714847241412e-06 first col mean 9.034765184878779e-07 all mean 1.4199962606653571e-05
6.551502792717656e-06 6.551502792717656e-06
rl training, epoch6, iter0, batch334/1133, batch loss:6.551502792717656e-06, Training time:81541.26699376106
batch reward last col mean 1.0439001698614447e-06 first col mean 9.053128451341763e-06 all mean 1.34782003442524e-05
1.1707338671840262e-06 1.1707397788995877e-06
rl training, epoch6, iter0, batch335/1133, batch loss:1.1707397788995877e-06, Training time:81558.47248029709
batch reward last col mean 8.031593097257428e-06 first col mean 5.348626359591435e-07 all mean 4.9592549657972995e-06
1.785969516276964e-06 1.7859689478427754e-06
rl training, epoch6, iter0, batch336/1133, batch loss:1.7859689478427754e-06, Training time:81575.51358413696
batch reward last col mean 1.3627499129142961e-06 first col mean 1.87990622180223e-06 all mean 9.308428161602933e-06
6.017748432896042e-07 6.017758096277248e-07
rl training, epoch6, iter0, batch337/1133, batch loss:6.017758096277248e-07, Training time:81593.20957684517
batch reward last col mean 5.79812592604867e-07 first col mean 8.036025747060194e-07 all mean 4.960317710356321e-06
2.712410491767514e-07 2.712393438741856e-07
rl training, epoch6, iter0, batch338/1133, batch loss:2.712393438741856e-07, Training time:81609.46694087982
batch reward last col mean 3.676627216009365e-07 first col mean 7.113717401807662e-07 all mean 9.169805707642809e-06
1.65340765079236e-07 1.6533822133624199e-07
rl training, epoch6, iter0, batch339/1133, batch loss:1.6533822133624199e-07, Training time:81626.99813771248
batch reward last col mean 4.321434516896261e-07 first col mean 1.93080518329225e-06 all mean 4.007235475000925e-06
7.295730597434158e-08 7.295855652955652e-08
rl training, epoch6, iter0, batch340/1133, batch loss:7.295855652955652e-08, Training time:81645.54990625381
batch reward last col mean 1.208601133839693e-06 first col mean 1.5213795450108591e-06 all mean 3.909283805114683e-06
4.444220394361764e-06 4.444220394361764e-06
rl training, epoch6, iter0, batch341/1133, batch loss:4.444220394361764e-06, Training time:81663.28855228424
batch reward last col mean 1.1884008017659653e-06 first col mean 9.487685019848868e-07 all mean 2.254246965094353e-06
1.163668912340654e-07 1.1636729624342479e-07
rl training, epoch6, iter0, batch342/1133, batch loss:1.1636729624342479e-07, Training time:81681.73664164543
batch reward last col mean 5.579763069363253e-07 first col mean 9.782219194676145e-07 all mean 2.5442129754083e-06
1.6493471832745854e-07 1.6493456200805667e-07
rl training, epoch6, iter0, batch343/1133, batch loss:1.6493456200805667e-07, Training time:81698.52840709686
batch reward last col mean 1.3365236100071343e-06 first col mean 1.212167444464285e-05 all mean 2.08274514079676e-06
1.8341422958201292e-07 1.834135474609866e-07
rl training, epoch6, iter0, batch344/1133, batch loss:1.834135474609866e-07, Training time:81714.92673873901
batch reward last col mean 7.045558731988422e-07 first col mean 4.2564056457194965e-06 all mean 3.540076704666717e-06
9.3154454816613e-07 9.315438092016848e-07
rl training, epoch6, iter0, batch345/1133, batch loss:9.315438092016848e-07, Training time:81731.17864465714
batch reward last col mean 1.1152126262459205e-06 first col mean 8.860759521667205e-07 all mean 1.5024581898614997e-06
1.8737341633823235e-07 1.8737340212737763e-07
rl training, epoch6, iter0, batch346/1133, batch loss:1.8737340212737763e-07, Training time:81747.26600074768
batch reward last col mean 4.842565977014601e-05 first col mean 4.4496778173197526e-07 all mean 3.22036758007016e-05
9.451238838664722e-06 9.451240657654125e-06
rl training, epoch6, iter0, batch347/1133, batch loss:9.451240657654125e-06, Training time:81764.02771258354
batch reward last col mean 4.5512382484957925e-07 first col mean 7.135254236345645e-07 all mean 1.320140654570423e-06
3.41836681627683e-07 3.4183662478426413e-07
rl training, epoch6, iter0, batch348/1133, batch loss:3.4183662478426413e-07, Training time:81780.05874323845
batch reward last col mean 3.8562743043257797e-07 first col mean 7.683625540266803e-07 all mean 8.967269309323456e-07
4.1990393384594427e-08 4.1990396937308105e-08
rl training, epoch6, iter0, batch349/1133, batch loss:4.1990396937308105e-08, Training time:81796.08943271637
batch reward last col mean 2.3796619643690065e-06 first col mean 1.195988261315506e-06 all mean 2.394386137893889e-05
4.877797891822411e-06 4.877805167780025e-06
rl training, epoch6, iter0, batch350/1133, batch loss:4.877805167780025e-06, Training time:81812.15932750702
batch reward last col mean 1.8837763491319492e-05 first col mean 1.3127720421834965e-06 all mean 5.140298981132219e-06
2.21855157178652e-06 2.21855157178652e-06
rl training, epoch6, iter0, batch351/1133, batch loss:2.21855157178652e-06, Training time:81830.56519293785
batch reward last col mean 1.5200075722532347e-06 first col mean 1.8271994122187607e-05 all mean 5.275324838294182e-06
1.4739890730197658e-07 1.473994046818916e-07
rl training, epoch6, iter0, batch352/1133, batch loss:1.473994046818916e-07, Training time:81848.03550767899
batch reward last col mean 7.9001511039678e-06 first col mean 6.294931154116057e-07 all mean 3.259463846916333e-05
7.966549674165435e-06 7.966544217197224e-06
rl training, epoch6, iter0, batch353/1133, batch loss:7.966544217197224e-06, Training time:81866.05294585228
batch reward last col mean 0.000692593224812299 first col mean 5.87802560403361e-07 all mean 0.00018754927441477776
0.00021161374752409756 0.00021161374752409756
rl training, epoch6, iter0, batch354/1133, batch loss:0.00021161374752409756, Training time:81884.71159887314
batch reward last col mean 1.039425001181371e-06 first col mean 1.4872011888655834e-06 all mean 1.5930232848404557e-06
8.33242665976286e-08 8.332413869993616e-08
rl training, epoch6, iter0, batch355/1133, batch loss:8.332413869993616e-08, Training time:81902.61277246475
batch reward last col mean 0.0016966728726401925 first col mean 8.39271592667501e-07 all mean 0.0004440190677996725
0.00012133856216678396 0.00012133856216678396
rl training, epoch6, iter0, batch356/1133, batch loss:0.00012133856216678396, Training time:81919.97106218338
batch reward last col mean 2.6982746703652083e-07 first col mean 1.53014957504638e-06 all mean 1.5532181123489863e-06
1.7413273667443718e-07 1.741328361504202e-07
rl training, epoch6, iter0, batch357/1133, batch loss:1.741328361504202e-07, Training time:81937.69331669807
batch reward last col mean 5.860298642801354e-06 first col mean 0.0002676478761713952 all mean 7.473473033314804e-06
2.620989289425779e-05 2.620989289425779e-05
rl training, epoch6, iter0, batch358/1133, batch loss:2.620989289425779e-05, Training time:81955.02870106697
batch reward last col mean 8.998196676657244e-07 first col mean 7.110828619261156e-07 all mean 2.7695436983776744e-06
7.732904094837068e-08 7.732997886478188e-08
rl training, epoch6, iter0, batch359/1133, batch loss:7.732997886478188e-08, Training time:81973.63190197945
batch reward last col mean 1.2529583273135358e-06 first col mean 9.173753596769529e-07 all mean 3.0453384169959463e-06
1.1661303744858742e-07 1.1661317245170721e-07
rl training, epoch6, iter0, batch360/1133, batch loss:1.1661317245170721e-07, Training time:81990.95244407654
batch reward last col mean 3.384744786671945e-07 first col mean 5.06118510656961e-07 all mean 7.086556479407591e-07
2.7466795060604454e-08 2.7466825258670724e-08
rl training, epoch6, iter0, batch361/1133, batch loss:2.7466825258670724e-08, Training time:82007.03562569618
batch reward last col mean 8.183616955648176e-06 first col mean 7.569710760435555e-07 all mean 2.802037852234207e-05
3.1161512197286356e-06 3.116156449323171e-06
rl training, epoch6, iter0, batch362/1133, batch loss:3.116156449323171e-06, Training time:82023.07829213142
batch reward last col mean 4.989645094610751e-05 first col mean 7.609139629494166e-07 all mean 1.3680586562259123e-05
8.97516292752698e-06 8.975164746516384e-06
rl training, epoch6, iter0, batch363/1133, batch loss:8.975164746516384e-06, Training time:82039.5423476696
batch reward last col mean 2.651004251674749e-06 first col mean 8.052207704167813e-06 all mean 3.112421109108254e-05
1.1655436537694186e-05 1.165543380921008e-05
rl training, epoch6, iter0, batch364/1133, batch loss:1.165543380921008e-05, Training time:82055.67850351334
batch reward last col mean 0.0027647376991808414 first col mean 1.2318411108935834e-06 all mean 0.0025955787859857082
0.00015948260261211544 0.00015948261716403067
rl training, epoch6, iter0, batch365/1133, batch loss:0.00015948261716403067, Training time:82071.95259070396
batch reward last col mean 1.3548831248044735e-06 first col mean 1.1517460052345996e-06 all mean 3.3735614124452695e-06
1.4642881751569803e-07 1.4642746748450008e-07
rl training, epoch6, iter0, batch366/1133, batch loss:1.4642746748450008e-07, Training time:82088.09067177773
batch reward last col mean 5.454668325910461e-07 first col mean 5.216417093834025e-07 all mean 1.5654273965992616e-06
6.732168600365185e-08 6.732181390134429e-08
rl training, epoch6, iter0, batch367/1133, batch loss:6.732181390134429e-08, Training time:82104.2829554081
batch reward last col mean 4.292307039577281e-06 first col mean 6.035658088876517e-07 all mean 2.4806686269585043e-06
3.9643128957322915e-07 3.9643117588639143e-07
rl training, epoch6, iter0, batch368/1133, batch loss:3.9643117588639143e-07, Training time:82120.21588468552
batch reward last col mean 1.3209241842560004e-05 first col mean 8.711328973731725e-07 all mean 8.008408258319832e-06
2.4778212264209287e-06 2.4778221359156305e-06
rl training, epoch6, iter0, batch369/1133, batch loss:2.4778221359156305e-06, Training time:82138.37286543846
batch reward last col mean 0.0009389077313244343 first col mean 8.885393754098914e-07 all mean 0.000919040699955076
4.9521309847477823e-05 4.9521309847477823e-05
rl training, epoch6, iter0, batch370/1133, batch loss:4.9521309847477823e-05, Training time:82155.30958938599
batch reward last col mean 6.842952871011221e-07 first col mean 5.870131190022221e-07 all mean 8.13383303466253e-06
8.995493772090413e-07 8.995505709208373e-07
rl training, epoch6, iter0, batch371/1133, batch loss:8.995505709208373e-07, Training time:82172.12480354309
batch reward last col mean 2.5409393856534734e-05 first col mean 8.499026193931059e-07 all mean 2.2283484213403426e-05
8.723121936782263e-06 8.723121027287561e-06
rl training, epoch6, iter0, batch372/1133, batch loss:8.723121027287561e-06, Training time:82188.83849525452
batch reward last col mean 7.83728864917066e-07 first col mean 1.1864134421557537e-06 all mean 2.13120210901252e-06
2.1916403625255043e-07 2.1916449099990132e-07
rl training, epoch6, iter0, batch373/1133, batch loss:2.1916449099990132e-07, Training time:82206.24161601067
batch reward last col mean 8.331940080097411e-07 first col mean 6.974191819608677e-07 all mean 2.8513175038824556e-06
2.3538181892490684e-07 2.3538116522558994e-07
rl training, epoch6, iter0, batch374/1133, batch loss:2.3538116522558994e-07, Training time:82224.86178064346
batch reward last col mean 3.371671846252866e-05 first col mean 8.485021112392133e-07 all mean 2.8714883228531107e-05
8.705376785655972e-06 8.705377695150673e-06
rl training, epoch6, iter0, batch375/1133, batch loss:8.705377695150673e-06, Training time:82242.76149392128
batch reward last col mean 0.0068360064178705215 first col mean 1.0664499541235273e-06 all mean 0.006578102242201567
0.0014249267987906933 0.0014249267987906933
rl training, epoch6, iter0, batch376/1133, batch loss:0.0014249267987906933, Training time:82260.55975818634
batch reward last col mean 1.9370500012882985e-05 first col mean 8.95877747097984e-07 all mean 2.519162262615282e-05
0.00010508058767300099 0.00010508058767300099
rl training, epoch6, iter0, batch377/1133, batch loss:0.00010508058767300099, Training time:82277.32207727432
batch reward last col mean 2.1055959678051295e-06 first col mean 5.641766165354056e-07 all mean 1.7486713659309316e-06
1.2537280724700395e-07 1.2537307725324354e-07
rl training, epoch6, iter0, batch378/1133, batch loss:1.2537307725324354e-07, Training time:82293.44814801216
batch reward last col mean 4.6333707359735854e-07 first col mean 1.349366129943519e-06 all mean 5.663815954903839e-06
1.0574949982355974e-07 1.0574735398449775e-07
rl training, epoch6, iter0, batch379/1133, batch loss:1.0574735398449775e-07, Training time:82309.49596309662
batch reward last col mean 1.8642001577973133e-06 first col mean 1.8309678125660866e-05 all mean 1.7525813746033236e-05
7.611116075167956e-07 7.611073442603811e-07
rl training, epoch6, iter0, batch380/1133, batch loss:7.611073442603811e-07, Training time:82325.53632497787
batch reward last col mean 3.54821931978222e-05 first col mean 5.164995400264161e-07 all mean 0.000917439756449312
8.679207530803978e-05 8.679203892825171e-05
rl training, epoch6, iter0, batch381/1133, batch loss:8.679203892825171e-05, Training time:82341.69965338707
batch reward last col mean 2.0656077595049283e-06 first col mean 1.3559615581471007e-06 all mean 0.00022729749616701156
0.0001587762380950153 0.0001587762380950153
rl training, epoch6, iter0, batch382/1133, batch loss:0.0001587762380950153, Training time:82358.0794312954
batch reward last col mean 1.0004281421061023e-06 first col mean 4.316500508139143e-07 all mean 1.9000603060703725e-05
0.00011108895705547184 0.00011108896433142945
rl training, epoch6, iter0, batch383/1133, batch loss:0.00011108896433142945, Training time:82374.30898070335
batch reward last col mean 1.8194558606410283e-06 first col mean 6.154999141472217e-07 all mean 3.409220516914502e-05
7.627015747857513e-06 7.627026207046583e-06
rl training, epoch6, iter0, batch384/1133, batch loss:7.627026207046583e-06, Training time:82390.25759363174
batch reward last col mean 1.1121779834866174e-06 first col mean 7.179093017839477e-07 all mean 1.8866276150220074e-06
2.094231774663058e-07 2.0942312062288693e-07
rl training, epoch6, iter0, batch385/1133, batch loss:2.0942312062288693e-07, Training time:82406.62167477608
batch reward last col mean 1.2050725217704894e-06 first col mean 2.588213192211697e-06 all mean 6.695623142149998e-06
5.148166906110418e-07 5.148177137925813e-07
rl training, epoch6, iter0, batch386/1133, batch loss:5.148177137925813e-07, Training time:82422.69932985306
batch reward last col mean 4.900193744106218e-07 first col mean 7.058198434606311e-07 all mean 4.36904974776553e-06
1.0053648225039069e-07 1.005358782890653e-07
rl training, epoch6, iter0, batch387/1133, batch loss:1.005358782890653e-07, Training time:82438.73999428749
batch reward last col mean 9.073372893908527e-06 first col mean 3.943910371617676e-07 all mean 1.712036282697227e-05
3.865729922836181e-06 3.865735834551742e-06
rl training, epoch6, iter0, batch388/1133, batch loss:3.865735834551742e-06, Training time:82454.86430311203
batch reward last col mean 4.242181148583768e-06 first col mean 1.1624631497397786e-06 all mean 5.853145012224559e-06
3.2332710020455124e-07 3.233258212276269e-07
rl training, epoch6, iter0, batch389/1133, batch loss:3.233258212276269e-07, Training time:82471.87593483925
batch reward last col mean 1.9834187696687877e-06 first col mean 2.433779627608601e-06 all mean 2.663775194378104e-05
1.9005575495611993e-06 1.9005544800165808e-06
rl training, epoch6, iter0, batch390/1133, batch loss:1.9005544800165808e-06, Training time:82488.06527137756
batch reward last col mean 2.5788078801269876e-06 first col mean 0.0003174122830387205 all mean 5.7220318012696225e-06
1.9666058506118134e-06 1.9666033495013835e-06
rl training, epoch6, iter0, batch391/1133, batch loss:1.9666033495013835e-06, Training time:82505.10173749924
batch reward last col mean 9.415749104846327e-07 first col mean 9.409873200638685e-07 all mean 1.1152042134199291e-05
2.1940812189313874e-07 2.1941552574844536e-07
rl training, epoch6, iter0, batch392/1133, batch loss:2.1941552574844536e-07, Training time:82521.48277497292
batch reward last col mean 1.4950355762266554e-05 first col mean 1.4847503280179808e-06 all mean 6.109451987867942e-06
1.8441934344082256e-06 1.8441942302160896e-06
rl training, epoch6, iter0, batch393/1133, batch loss:1.8441942302160896e-06, Training time:82540.18292307854
batch reward last col mean 7.965445547597483e-07 first col mean 1.0704497981350869e-06 all mean 7.968948921188712e-06
2.8113052508160763e-07 2.81133850421611e-07
rl training, epoch6, iter0, batch394/1133, batch loss:2.81133850421611e-07, Training time:82556.47221302986
batch reward last col mean 3.9932740037329495e-05 first col mean 1.8010359781328589e-06 all mean 5.013283953303471e-05
7.801909305271693e-06 7.801905667292885e-06
rl training, epoch6, iter0, batch395/1133, batch loss:7.801905667292885e-06, Training time:82574.37303733826
batch reward last col mean 0.0038996178191155195 first col mean 7.521709903812734e-07 all mean 0.0006287582218647003
0.00034435553243383765 0.0003443555615376681
rl training, epoch6, iter0, batch396/1133, batch loss:0.0003443555615376681, Training time:82592.23304200172
batch reward last col mean 6.404838472917618e-07 first col mean 2.3163831428973936e-05 all mean 9.459149623580743e-06
5.710684831683466e-07 5.710656409974035e-07
rl training, epoch6, iter0, batch397/1133, batch loss:5.710656409974035e-07, Training time:82609.47492432594
batch reward last col mean 6.768957064196002e-06 first col mean 6.002135251037544e-07 all mean 2.147294071619399e-05
1.4121561662250315e-06 1.412162077940593e-06
rl training, epoch6, iter0, batch398/1133, batch loss:1.412162077940593e-06, Training time:82626.64726662636
batch reward last col mean 6.000291250529699e-07 first col mean 6.870320703455945e-07 all mean 2.6562697712506633e-06
7.680281299826675e-08 7.680269931142902e-08
rl training, epoch6, iter0, batch399/1133, batch loss:7.680269931142902e-08, Training time:82642.56097626686
batch reward last col mean 0.0004844338109251112 first col mean 1.1287154393357923e-06 all mean 0.00020941537513863295
0.00024023535661399364 0.00024023535661399364
rl training, epoch6, iter0, batch400/1133, batch loss:0.00024023535661399364, Training time:82658.52164936066
batch reward last col mean 2.131097971869167e-06 first col mean 6.589006602553127e-07 all mean 1.4784092854824848e-05
1.0896212643274339e-06 1.0896262665482936e-06
rl training, epoch6, iter0, batch401/1133, batch loss:1.0896262665482936e-06, Training time:82674.6122572422
batch reward last col mean 4.016062121081632e-06 first col mean 7.675763527004165e-07 all mean 1.571447319292929e-05
3.1308688903664006e-06 3.1308684356190497e-06
rl training, epoch6, iter0, batch402/1133, batch loss:3.1308684356190497e-06, Training time:82690.7213845253
batch reward last col mean 4.1432508623984177e-07 first col mean 0.0011595560936257243 all mean 1.4484382518276107e-05
1.7115510786425148e-07 1.711457713327036e-07
rl training, epoch6, iter0, batch403/1133, batch loss:1.711457713327036e-07, Training time:82707.09704351425
batch reward last col mean 0.0006897544953972101 first col mean 0.0009260160732083023 all mean 0.0005635966081172228
0.00011632849054876715 0.00011632849054876715
rl training, epoch6, iter0, batch404/1133, batch loss:0.00011632849054876715, Training time:82723.4568490982
batch reward last col mean 1.0495567721591215e-06 first col mean 2.1215118977124803e-06 all mean 2.6753064048534725e-06
9.434091907678521e-08 9.43405353837079e-08
rl training, epoch6, iter0, batch405/1133, batch loss:9.43405353837079e-08, Training time:82739.77431344986
batch reward last col mean 3.0729272566532018e-06 first col mean 9.262150797439972e-07 all mean 3.5334214771864936e-06
2.9174270821386017e-07 2.9174250926189416e-07
rl training, epoch6, iter0, batch406/1133, batch loss:2.9174250926189416e-07, Training time:82757.2949666977
batch reward last col mean 8.082665203801298e-07 first col mean 4.877643959844136e-07 all mean 1.7735250366968103e-05
1.4410337826120667e-05 1.441033964511007e-05
rl training, epoch6, iter0, batch407/1133, batch loss:1.441033964511007e-05, Training time:82773.85194516182
batch reward last col mean 8.15559396869503e-05 first col mean 7.104879387043184e-07 all mean 2.072831011901144e-05
2.90213392872829e-06 2.902127789639053e-06
rl training, epoch6, iter0, batch408/1133, batch loss:2.902127789639053e-06, Training time:82791.06793498993
batch reward last col mean 1.8532082322053611e-06 first col mean 8.652580731904891e-07 all mean 5.1470698963385075e-05
8.439592784270644e-05 8.439593511866406e-05
rl training, epoch6, iter0, batch409/1133, batch loss:8.439593511866406e-05, Training time:82809.40356492996
batch reward last col mean 0.0003393534279894084 first col mean 3.3988883387792157e-06 all mean 0.0002721811179071665
0.0002683932543732226 0.0002683932543732226
rl training, epoch6, iter0, batch410/1133, batch loss:0.0002683932543732226, Training time:82827.70381689072
batch reward last col mean 7.576928169328312e-07 first col mean 1.0247936188534368e-06 all mean 3.0172020615282236e-06
9.71509166447504e-08 9.715193272086253e-08
rl training, epoch6, iter0, batch411/1133, batch loss:9.715193272086253e-08, Training time:82845.86101984978
batch reward last col mean 1.7027255125867669e-06 first col mean 0.0004538117500487715 all mean 5.058200258645229e-05
0.0003217141784261912 0.00032171414932236075
rl training, epoch6, iter0, batch412/1133, batch loss:0.00032171414932236075, Training time:82863.14181613922
batch reward last col mean 0.0030441847629845142 first col mean 8.859840363584226e-07 all mean 0.003342529060319066
0.00038419628981500864 0.00038419628981500864
rl training, epoch6, iter0, batch413/1133, batch loss:0.00038419628981500864, Training time:82881.04387807846
batch reward last col mean 1.239593984792009e-06 first col mean 2.9245102268760093e-06 all mean 5.116987267683726e-06
3.3287116707469977e-07 3.328715934003412e-07
rl training, epoch6, iter0, batch414/1133, batch loss:3.328715934003412e-07, Training time:82898.2223045826
batch reward last col mean 4.111784801352769e-05 first col mean 9.333289199275896e-07 all mean 9.264548680221196e-06
3.100932372035459e-05 3.100932372035459e-05
rl training, epoch6, iter0, batch415/1133, batch loss:3.100932372035459e-05, Training time:82915.76568627357
batch reward last col mean 1.4761708371224813e-06 first col mean 7.789819846948376e-07 all mean 6.910104275448248e-06
1.3734037338508642e-06 1.3734050980929169e-06
rl training, epoch6, iter0, batch416/1133, batch loss:1.3734050980929169e-06, Training time:82932.22220873833
batch reward last col mean 1.6112201137730153e-06 first col mean 2.568719537521247e-06 all mean 1.3893281902710441e-05
0.0001271274668397382 0.0001271274668397382
rl training, epoch6, iter0, batch417/1133, batch loss:0.0001271274668397382, Training time:82948.22122383118
batch reward last col mean 1.2299220770728425e-06 first col mean 1.4158318890622468e-06 all mean 7.81743074185215e-06
3.7733218505309196e-07 3.773317587274505e-07
rl training, epoch6, iter0, batch418/1133, batch loss:3.773317587274505e-07, Training time:82964.21424150467
batch reward last col mean 9.668663096817909e-07 first col mean 1.5754440028104e-06 all mean 2.3526214135927148e-05
3.306542566861026e-06 3.306548705950263e-06
rl training, epoch6, iter0, batch419/1133, batch loss:3.306548705950263e-06, Training time:82980.52782988548
batch reward last col mean 2.5312870093330275e-06 first col mean 5.646201088893577e-07 all mean 4.76646846436779e-06
1.3691853837372037e-06 1.369185270050366e-06
rl training, epoch6, iter0, batch420/1133, batch loss:1.369185270050366e-06, Training time:82996.63230752945
batch reward last col mean 5.3996188853489e-07 first col mean 9.609370863472577e-07 all mean 2.9590714802907314e-06
6.675629293795282e-08 6.675757902030455e-08
rl training, epoch6, iter0, batch421/1133, batch loss:6.675757902030455e-08, Training time:83013.04091000557
batch reward last col mean 1.0597993878036505e-06 first col mean 1.1750807971111499e-05 all mean 1.3335828953131568e-05
2.663993257101538e-07 2.664058058599039e-07
rl training, epoch6, iter0, batch422/1133, batch loss:2.664058058599039e-07, Training time:83030.63148021698
batch reward last col mean 1.2690982202911982e-06 first col mean 0.0015099641168490052 all mean 2.3555554435006343e-05
4.045713467348833e-06 4.0457257455273066e-06
rl training, epoch6, iter0, batch423/1133, batch loss:4.0457257455273066e-06, Training time:83049.56632256508
batch reward last col mean 7.93291917489114e-07 first col mean 6.885424568281451e-07 all mean 1.9206702290830435e-06
4.06321731816206e-07 4.06321731816206e-07
rl training, epoch6, iter0, batch424/1133, batch loss:4.06321731816206e-07, Training time:83066.3449010849
batch reward last col mean 2.3428021904692287e-06 first col mean 3.6058197565580485e-06 all mean 1.0622226909617893e-05
3.2337729294340534e-07 3.2337317179553793e-07
rl training, epoch6, iter0, batch425/1133, batch loss:3.2337317179553793e-07, Training time:83084.28180575371
batch reward last col mean 1.0001134796766564e-05 first col mean 1.5044956853671465e-06 all mean 1.0277356523147319e-05
8.035466635192279e-06 8.035466635192279e-06
rl training, epoch6, iter0, batch426/1133, batch loss:8.035466635192279e-06, Training time:83103.16588711739
batch reward last col mean 4.681725386035396e-06 first col mean 9.473833983975055e-07 all mean 1.0878376997425221e-05
6.047258011676604e-06 6.047258011676604e-06
rl training, epoch6, iter0, batch427/1133, batch loss:6.047258011676604e-06, Training time:83121.72751879692
batch reward last col mean 1.5301625353458803e-06 first col mean 1.7295085399382515e-06 all mean 2.8492286219261587e-06
1.4667377001842397e-07 1.4667367054244096e-07
rl training, epoch6, iter0, batch428/1133, batch loss:1.4667367054244096e-07, Training time:83140.84699082375
batch reward last col mean 0.0005296879098750651 first col mean 7.288568303920329e-05 all mean 2.514829975552857e-05
1.4011331586516462e-05 1.4011329767527059e-05
rl training, epoch6, iter0, batch429/1133, batch loss:1.4011329767527059e-05, Training time:83159.8125424385
batch reward last col mean 6.273246526689036e-06 first col mean 4.575620096147759e-06 all mean 1.0564654076006263e-05
4.101951617485611e-06 4.101952072232962e-06
rl training, epoch6, iter0, batch430/1133, batch loss:4.101952072232962e-06, Training time:83176.61185097694
batch reward last col mean 1.4383183952304535e-05 first col mean 2.834355655068066e-05 all mean 4.171586169832153e-06
1.0667980632206309e-06 1.0667979495337931e-06
rl training, epoch6, iter0, batch431/1133, batch loss:1.0667979495337931e-06, Training time:83193.77847671509
batch reward last col mean 9.451085816181148e-07 first col mean 7.630090408383694e-07 all mean 2.815131847455632e-05
3.816710886894725e-06 3.816712251136778e-06
rl training, epoch6, iter0, batch432/1133, batch loss:3.816712251136778e-06, Training time:83210.888256073
batch reward last col mean 0.0014281481271609664 first col mean 0.0008233008556999266 all mean 0.0014031664468348026
5.904776116949506e-05 5.904775389353745e-05
rl training, epoch6, iter0, batch433/1133, batch loss:5.904775389353745e-05, Training time:83227.06025862694
batch reward last col mean 1.4996193158367532e-06 first col mean 4.463641118945816e-07 all mean 3.137374733341858e-06
1.273925818168209e-06 1.2739272960970993e-06
rl training, epoch6, iter0, batch434/1133, batch loss:1.2739272960970993e-06, Training time:83243.05113625526
batch reward last col mean 5.907680247219105e-07 first col mean 9.09901530121715e-07 all mean 1.4777707519897376e-06
5.912480460779079e-08 5.912510303573981e-08
rl training, epoch6, iter0, batch435/1133, batch loss:5.912510303573981e-08, Training time:83258.97429585457
batch reward last col mean 2.087486564050778e-06 first col mean 5.489600880537182e-07 all mean 4.327495389588876e-06
3.0183427952579223e-06 3.0183427952579223e-06
rl training, epoch6, iter0, batch436/1133, batch loss:3.0183427952579223e-06, Training time:83275.10185694695
batch reward last col mean 9.51318634179188e-06 first col mean 6.301843313849531e-07 all mean 2.2677370452584e-06
1.074905981113261e-06 1.0749057537395856e-06
rl training, epoch6, iter0, batch437/1133, batch loss:1.0749057537395856e-06, Training time:83291.13244962692
batch reward last col mean 5.900100177314016e-07 first col mean 0.00011501173139549792 all mean 2.893461896746885e-06
1.0797338489965114e-07 1.0797344884849736e-07
rl training, epoch6, iter0, batch438/1133, batch loss:1.0797344884849736e-07, Training time:83308.87292551994
batch reward last col mean 0.0003097261651419103 first col mean 6.903930511725775e-07 all mean 0.00038163919816724956
0.0003165841626469046 0.00031658413354307413
rl training, epoch6, iter0, batch439/1133, batch loss:0.00031658413354307413, Training time:83325.37413263321
batch reward last col mean 5.321722710505128e-05 first col mean 1.0863259376492351e-06 all mean 9.97854585875757e-05
6.20321006863378e-05 6.20321006863378e-05
rl training, epoch6, iter0, batch440/1133, batch loss:6.20321006863378e-05, Training time:83341.70731067657
batch reward last col mean 6.977190309953585e-07 first col mean 1.222402374878584e-06 all mean 6.68053189656348e-06
8.930010153562762e-06 8.930011063057464e-06
rl training, epoch6, iter0, batch441/1133, batch loss:8.930011063057464e-06, Training time:83359.3663008213
batch reward last col mean 6.977325028856285e-06 first col mean 1.3964788649900584e-06 all mean 9.994116226152983e-06
2.4342924007214606e-05 2.4342927645193413e-05
rl training, epoch6, iter0, batch442/1133, batch loss:2.4342927645193413e-05, Training time:83375.74207687378
batch reward last col mean 8.717591981621808e-07 first col mean 1.8187873820352252e-06 all mean 6.503911208710633e-06
3.2300701491294603e-07 3.2301076657859085e-07
rl training, epoch6, iter0, batch443/1133, batch loss:3.2301076657859085e-07, Training time:83392.215924263
batch reward last col mean 1.1660042218863964e-05 first col mean 4.3386307879700325e-06 all mean 2.8660551834036596e-06
1.186949134535098e-06 1.1869492482219357e-06
rl training, epoch6, iter0, batch444/1133, batch loss:1.1869492482219357e-06, Training time:83408.5993077755
batch reward last col mean 2.3170023268903606e-06 first col mean 5.6003063946263865e-06 all mean 3.1545423553325236e-06
7.29372061414324e-07 7.293722887879994e-07
rl training, epoch6, iter0, batch445/1133, batch loss:7.293722887879994e-07, Training time:83424.74942970276
batch reward last col mean 0.005027268081903458 first col mean 8.323982183355838e-05 all mean 0.0020580305717885494
0.00021185667719691992 0.00021185667719691992
rl training, epoch6, iter0, batch446/1133, batch loss:0.00021185667719691992, Training time:83441.37462449074
batch reward last col mean 0.0048866067081689835 first col mean 5.607757884718012e-07 all mean 0.0009737066575326025
0.0005613012472167611 0.0005613012472167611
rl training, epoch6, iter0, batch447/1133, batch loss:0.0005613012472167611, Training time:83457.73286700249
batch reward last col mean 1.1597492175496882e-06 first col mean 2.0859095002379036e-06 all mean 7.505221674364293e-06
1.3539022347686114e-06 1.3539025758291245e-06
rl training, epoch6, iter0, batch448/1133, batch loss:1.3539025758291245e-06, Training time:83475.78305697441
batch reward last col mean 7.840195394237526e-06 first col mean 9.375403351441491e-07 all mean 1.0337275853089523e-05
2.14956207855721e-06 2.1495598048204556e-06
rl training, epoch6, iter0, batch449/1133, batch loss:2.1495598048204556e-06, Training time:83494.83839249611
batch reward last col mean 6.202188274073706e-07 first col mean 1.4311480072137783e-06 all mean 2.997958517880761e-06
1.9530359907093953e-07 1.953040538182904e-07
rl training, epoch6, iter0, batch450/1133, batch loss:1.953040538182904e-07, Training time:83510.95233082771
batch reward last col mean 9.716661679703975e-07 first col mean 4.7483860043939785e-07 all mean 1.0531008456382551e-06
6.600496504916009e-08 6.600488688945916e-08
rl training, epoch6, iter0, batch451/1133, batch loss:6.600488688945916e-08, Training time:83527.1755490303
batch reward last col mean 2.6429197532706894e-06 first col mean 7.894820441833872e-07 all mean 2.7127745852340013e-05
8.849674486555159e-06 8.849682672007475e-06
rl training, epoch6, iter0, batch452/1133, batch loss:8.849682672007475e-06, Training time:83543.42002654076
batch reward last col mean 8.947054993768688e-06 first col mean 5.923050707679067e-07 all mean 2.9820525924151298e-06
8.005126233001647e-07 8.005124527699081e-07
rl training, epoch6, iter0, batch453/1133, batch loss:8.005124527699081e-07, Training time:83560.95204663277
batch reward last col mean 3.304045776530984e-06 first col mean 3.0345663617481478e-05 all mean 1.643491123104468e-05
1.0602025213302113e-06 1.0602110478430404e-06
rl training, epoch6, iter0, batch454/1133, batch loss:1.0602110478430404e-06, Training time:83577.50531411171
batch reward last col mean 3.071252876907238e-06 first col mean 1.2287248409847962e-06 all mean 4.6859429858159274e-05
2.9441425795084797e-05 2.9441436709021218e-05
rl training, epoch6, iter0, batch455/1133, batch loss:2.9441436709021218e-05, Training time:83594.02524709702
batch reward last col mean 1.6402642359025776e-05 first col mean 3.353992042320897e-06 all mean 0.0001448209659429267
0.00020912184845656157 0.00020912184845656157
rl training, epoch6, iter0, batch456/1133, batch loss:0.00020912184845656157, Training time:83611.61819195747
batch reward last col mean 5.979519528409583e-07 first col mean 2.9685434128623456e-06 all mean 7.342287972278427e-06
2.556896845362644e-07 2.556916740559245e-07
rl training, epoch6, iter0, batch457/1133, batch loss:2.556916740559245e-07, Training time:83628.7404499054
batch reward last col mean 1.2700171282631345e-05 first col mean 1.565224238220253e-06 all mean 2.4864035367500037e-05
1.183083782052563e-06 1.1830675248347688e-06
rl training, epoch6, iter0, batch458/1133, batch loss:1.1830675248347688e-06, Training time:83646.40139436722
batch reward last col mean 5.0827387894969434e-05 first col mean 1.5465070646314416e-06 all mean 0.0001557512441650033
0.0009047610801644623 0.0009047610801644623
rl training, epoch6, iter0, batch459/1133, batch loss:0.0009047610801644623, Training time:83664.60101175308
batch reward last col mean 8.398235877393745e-06 first col mean 1.179874288936844e-06 all mean 3.6577857827069238e-06
9.462068192078732e-06 9.462068192078732e-06
rl training, epoch6, iter0, batch460/1133, batch loss:9.462068192078732e-06, Training time:83682.75101828575
batch reward last col mean 1.2761479410983156e-05 first col mean 7.3165409730791e-07 all mean 2.6010899091488682e-05
7.310389719350496e-06 7.310388355108444e-06
rl training, epoch6, iter0, batch461/1133, batch loss:7.310388355108444e-06, Training time:83700.33996915817
batch reward last col mean 0.0006283566472120583 first col mean 1.1429116284489282e-06 all mean 0.00019248150056228042
0.00015329955203924328 0.00015329952293541282
rl training, epoch6, iter0, batch462/1133, batch loss:0.00015329952293541282, Training time:83717.14412164688
batch reward last col mean 3.1535323614662047e-06 first col mean 9.046332706930116e-06 all mean 4.523854386206949e-06
3.401640697120456e-06 3.4016409244941315e-06
rl training, epoch6, iter0, batch463/1133, batch loss:3.4016409244941315e-06, Training time:83733.5856115818
batch reward last col mean 4.150214954279363e-05 first col mean 1.4725662822456798e-06 all mean 8.774692105362192e-05
8.734824223211035e-05 8.734822768019512e-05
rl training, epoch6, iter0, batch464/1133, batch loss:8.734822768019512e-05, Training time:83752.24341011047
batch reward last col mean 1.917909003168461e-06 first col mean 1.0386763733549742e-06 all mean 1.4160425052978098e-05
1.4408466086024418e-05 1.4408470633497927e-05
rl training, epoch6, iter0, batch465/1133, batch loss:1.4408470633497927e-05, Training time:83770.01519680023
batch reward last col mean 0.0014541404088959098 first col mean 2.5319391170341987e-06 all mean 0.0012983095366507769
2.4832943381625228e-05 2.4832943381625228e-05
rl training, epoch6, iter0, batch466/1133, batch loss:2.4832943381625228e-05, Training time:83787.60780668259
batch reward last col mean 1.6978256098809652e-06 first col mean 1.0620283319440205e-06 all mean 3.588427034628694e-06
2.8126279971729673e-07 2.812614638969535e-07
rl training, epoch6, iter0, batch467/1133, batch loss:2.812614638969535e-07, Training time:83804.06230139732
batch reward last col mean 5.07716094944044e-07 first col mean 9.767642040969804e-06 all mean 2.115550387316034e-06
3.307498275262333e-07 3.3074923067033524e-07
rl training, epoch6, iter0, batch468/1133, batch loss:3.3074923067033524e-07, Training time:83820.21160387993
batch reward last col mean 0.0008932958007790148 first col mean 0.00013907489483244717 all mean 0.000841057684738189
4.245613672537729e-05 4.245613672537729e-05
rl training, epoch6, iter0, batch469/1133, batch loss:4.245613672537729e-05, Training time:83836.23472523689
batch reward last col mean 1.1751508282031864e-05 first col mean 8.305870551339467e-07 all mean 2.883102069972665e-06
3.362150948760245e-07 3.3621520856286224e-07
rl training, epoch6, iter0, batch470/1133, batch loss:3.3621520856286224e-07, Training time:83852.239985466
batch reward last col mean 1.0329654287488665e-06 first col mean 5.587763780567911e-07 all mean 4.643008196580922e-06
2.1503674929590488e-07 2.150368487718879e-07
rl training, epoch6, iter0, batch471/1133, batch loss:2.150368487718879e-07, Training time:83868.19306564331
batch reward last col mean 6.255296466406435e-05 first col mean 2.0925494936818723e-06 all mean 0.0005850894958712161
0.0005820787628181279 0.0005820788210257888
rl training, epoch6, iter0, batch472/1133, batch loss:0.0005820788210257888, Training time:83884.17158937454
batch reward last col mean 7.156995707191527e-07 first col mean 5.517122190212831e-06 all mean 4.1576186049496755e-06
1.0490720114830765e-06 1.0490728072909405e-06
rl training, epoch6, iter0, batch473/1133, batch loss:1.0490728072909405e-06, Training time:83900.54858660698
batch reward last col mean 5.941147378507594e-07 first col mean 5.341390760804643e-07 all mean 8.14370832813438e-06
4.2625256924111454e-07 4.2625396190487663e-07
rl training, epoch6, iter0, batch474/1133, batch loss:4.2625396190487663e-07, Training time:83918.92349147797
batch reward last col mean 7.413724233629182e-05 first col mean 2.102820872096345e-06 all mean 8.887745207175612e-05
1.739625986374449e-05 1.7396267139702104e-05
rl training, epoch6, iter0, batch475/1133, batch loss:1.7396267139702104e-05, Training time:83935.8497812748
batch reward last col mean 0.00031937635503709316 first col mean 3.2991408716043225e-06 all mean 0.0002927995810750872
9.718321962282062e-05 9.718321962282062e-05
rl training, epoch6, iter0, batch476/1133, batch loss:9.718321962282062e-05, Training time:83952.61270904541
batch reward last col mean 3.883352292177733e-06 first col mean 0.0001355269196210429 all mean 8.999553756439127e-06
2.656668812051066e-06 2.6566694941720925e-06
rl training, epoch6, iter0, batch477/1133, batch loss:2.6566694941720925e-06, Training time:83970.49398779869
batch reward last col mean 6.217412646947196e-07 first col mean 1.0018802640843205e-05 all mean 2.8251688490854576e-05
1.0951105195999844e-06 1.0951210924758925e-06
rl training, epoch6, iter0, batch478/1133, batch loss:1.0951210924758925e-06, Training time:83988.18048167229
batch reward last col mean 1.806839463824872e-05 first col mean 5.619011744784075e-07 all mean 1.947330565599259e-05
1.665337322265259e-06 1.6653407328703906e-06
rl training, epoch6, iter0, batch479/1133, batch loss:1.6653407328703906e-06, Training time:84004.83192372322
batch reward last col mean 2.140486685675569e-06 first col mean 5.832088390889112e-06 all mean 6.973133622523164e-06
1.189363047160441e-06 1.1893639566551428e-06
rl training, epoch6, iter0, batch480/1133, batch loss:1.1893639566551428e-06, Training time:84021.01054167747
batch reward last col mean 2.2331587388180196e-06 first col mean 1.0819385352078825e-06 all mean 1.8837292827811325e-06
1.5509461093188293e-07 1.5509479567299422e-07
rl training, epoch6, iter0, batch481/1133, batch loss:1.5509479567299422e-07, Training time:84038.0048623085
batch reward last col mean 3.3975422866205918e-06 first col mean 6.462637429649476e-07 all mean 2.766227044048719e-05
1.0117850251845084e-05 1.011784297588747e-05
rl training, epoch6, iter0, batch482/1133, batch loss:1.011784297588747e-05, Training time:84055.63669347763
batch reward last col mean 1.341485130978981e-05 first col mean 6.965986358409282e-06 all mean 4.730061846203171e-06
1.5657560652471147e-06 1.5657566336813034e-06
rl training, epoch6, iter0, batch483/1133, batch loss:1.5657566336813034e-06, Training time:84073.44402742386
batch reward last col mean 6.913133802299853e-06 first col mean 1.4335325886349892e-06 all mean 6.404471150744939e-06
3.1611743906978518e-06 3.1611746180715272e-06
rl training, epoch6, iter0, batch484/1133, batch loss:3.1611746180715272e-06, Training time:84091.24844050407
batch reward last col mean 0.003976825624704361 first col mean 1.7642425518715754e-05 all mean 0.0008752877474762499
0.00016083782247733325 0.00016083780792541802
rl training, epoch6, iter0, batch485/1133, batch loss:0.00016083780792541802, Training time:84107.35495591164
batch reward last col mean 6.162507816043217e-06 first col mean 2.1094258499942953e-06 all mean 1.274667101824889e-05
5.654785582009936e-06 5.65478785574669e-06
rl training, epoch6, iter0, batch486/1133, batch loss:5.65478785574669e-06, Training time:84123.33538770676
batch reward last col mean 5.186579414839798e-07 first col mean 4.5659294301003683e-07 all mean 1.059900205291342e-05
6.332112434392911e-08 6.332930979624507e-08
rl training, epoch6, iter0, batch487/1133, batch loss:6.332930979624507e-08, Training time:84139.30620026588
batch reward last col mean 3.210848262824584e-07 first col mean 0.0003556650481186807 all mean 1.6830268577905372e-05
3.6048379570274847e-06 3.6048363654117566e-06
rl training, epoch6, iter0, batch488/1133, batch loss:3.6048363654117566e-06, Training time:84155.40396809578
batch reward last col mean 5.273065653454978e-06 first col mean 1.434645923836797e-06 all mean 2.2866728613735177e-05
2.7001099169865483e-06 2.7001099169865483e-06
rl training, epoch6, iter0, batch489/1133, batch loss:2.7001099169865483e-06, Training time:84171.58590650558
batch reward last col mean 4.1872132783282723e-07 first col mean 1.363395995213068e-06 all mean 4.517685738392174e-06
1.9179426544724265e-06 1.917942427098751e-06
rl training, epoch6, iter0, batch490/1133, batch loss:1.917942427098751e-06, Training time:84187.57910442352
batch reward last col mean 1.1904386383321253e-06 first col mean 6.887590302540048e-07 all mean 3.534168627084e-06
9.561379101796774e-07 9.561377964928397e-07
rl training, epoch6, iter0, batch491/1133, batch loss:9.561377964928397e-07, Training time:84204.04857850075
batch reward last col mean 2.9189871497692366e-07 first col mean 6.43725911686488e-07 all mean 3.185855575793539e-06
1.5593171553973662e-07 1.559307776233254e-07
rl training, epoch6, iter0, batch492/1133, batch loss:1.559307776233254e-07, Training time:84221.18864274025
batch reward last col mean 1.6098891819638084e-06 first col mean 8.108863198685867e-07 all mean 5.5810523917898536e-06
1.9633715453437617e-07 1.9633640135907626e-07
rl training, epoch6, iter0, batch493/1133, batch loss:1.9633640135907626e-07, Training time:84238.96712589264
batch reward last col mean 0.00022430886747315526 first col mean 8.558256377000362e-05 all mean 0.00022965657990425825
7.923754310468212e-05 7.923754310468212e-05
rl training, epoch6, iter0, batch494/1133, batch loss:7.923754310468212e-05, Training time:84255.15783309937
batch reward last col mean 4.860308990828344e-07 first col mean 6.560699148394633e-07 all mean 1.3500938621291425e-05
1.2479349607019685e-06 1.2479346196414554e-06
rl training, epoch6, iter0, batch495/1133, batch loss:1.2479346196414554e-06, Training time:84270.97618484497
batch reward last col mean 3.747703158296645e-05 first col mean 1.7139897181550623e-06 all mean 6.101506733102724e-05
0.00012324179988354445 0.00012324179988354445
rl training, epoch6, iter0, batch496/1133, batch loss:0.00012324179988354445, Training time:84288.03058099747
batch reward last col mean 4.853296218243486e-07 first col mean 3.10789687318902e-07 all mean 2.421397539364989e-06
1.898825701118767e-07 1.8988261274444085e-07
rl training, epoch6, iter0, batch497/1133, batch loss:1.8988261274444085e-07, Training time:84305.55720233917
batch reward last col mean 1.9815365703834686e-06 first col mean 1.2971809155715164e-06 all mean 9.941992175299674e-06
1.1071833796449937e-06 1.1071846302002086e-06
rl training, epoch6, iter0, batch498/1133, batch loss:1.1071846302002086e-06, Training time:84323.25252699852
batch reward last col mean 8.494694156979676e-06 first col mean 8.794763743935619e-07 all mean 1.7192183804581873e-05
1.2957236776856007e-06 1.2957244734934648e-06
rl training, epoch6, iter0, batch499/1133, batch loss:1.2957244734934648e-06, Training time:84342.08627271652
batch reward last col mean 2.1179678242333466e-06 first col mean 6.605107500945451e-07 all mean 9.820398190640844e-06
1.5886187156866072e-06 1.5886180335655808e-06
rl training, epoch6, iter0, batch500/1133, batch loss:1.5886180335655808e-06, Training time:84358.41180205345
batch reward last col mean 1.1080350077463663e-06 first col mean 5.94339496728935e-07 all mean 5.326907739799935e-06
2.895620525578124e-07 2.8956199571439356e-07
rl training, epoch6, iter0, batch501/1133, batch loss:2.8956199571439356e-07, Training time:84375.630235672
batch reward last col mean 2.036968453467125e-06 first col mean 9.96600533653691e-07 all mean 9.936508831742685e-06
1.582913682796061e-06 1.5829122048671707e-06
rl training, epoch6, iter0, batch502/1133, batch loss:1.5829122048671707e-06, Training time:84394.15491485596
batch reward last col mean 1.7798349745135056e-06 first col mean 1.4906343039911008e-06 all mean 2.6797422378876945e-06
4.6560296595998807e-07 4.656029943816975e-07
rl training, epoch6, iter0, batch503/1133, batch loss:4.656029943816975e-07, Training time:84412.4811091423
batch reward last col mean 1.305249838878808e-06 first col mean 6.413522442016983e-07 all mean 2.229306346634985e-06
1.2020491624298302e-07 1.2020495887554716e-07
rl training, epoch6, iter0, batch504/1133, batch loss:1.2020495887554716e-07, Training time:84428.3523736
batch reward last col mean 8.372589377358963e-07 first col mean 3.055468368984293e-06 all mean 3.387830020074034e-06
2.0234344901837176e-06 2.0234340354363667e-06
rl training, epoch6, iter0, batch505/1133, batch loss:2.0234340354363667e-06, Training time:84445.45242500305
batch reward last col mean 0.0003795157535932958 first col mean 1.4677561921416782e-06 all mean 0.0003533105191309005
9.171631245408207e-05 9.171631245408207e-05
rl training, epoch6, iter0, batch506/1133, batch loss:9.171631245408207e-05, Training time:84462.72365164757
batch reward last col mean 1.5785410596436122e-06 first col mean 2.940361582659534e-06 all mean 5.0728858695947565e-06
2.33769057444988e-07 2.3376973956601432e-07
rl training, epoch6, iter0, batch507/1133, batch loss:2.3376973956601432e-07, Training time:84480.12253594398
batch reward last col mean 4.6501634187734453e-07 first col mean 8.363848564840737e-07 all mean 2.3477766717405757e-06
3.5682310794982186e-07 3.56822852154437e-07
rl training, epoch6, iter0, batch508/1133, batch loss:3.56822852154437e-07, Training time:84497.1002202034
batch reward last col mean 3.848871710943058e-05 first col mean 2.1952168935968075e-06 all mean 5.212294854572974e-05
3.4040247555822134e-05 3.404025119380094e-05
rl training, epoch6, iter0, batch509/1133, batch loss:3.404025119380094e-05, Training time:84514.35105967522
batch reward last col mean 8.358178092748858e-06 first col mean 2.6319276003050618e-06 all mean 8.168078784365207e-05
5.228081499808468e-05 5.2280822274042293e-05
rl training, epoch6, iter0, batch510/1133, batch loss:5.2280822274042293e-05, Training time:84531.30057501793
batch reward last col mean 5.021817628403369e-07 first col mean 9.595667506800964e-06 all mean 2.0584971935022622e-05
3.3479261674074223e-07 3.347901440520218e-07
rl training, epoch6, iter0, batch511/1133, batch loss:3.347901440520218e-07, Training time:84550.37410140038
batch reward last col mean 2.9259938401082763e-06 first col mean 6.715625886499765e-07 all mean 2.4769967694737716e-06
4.387807621242246e-06 4.387807621242246e-06
rl training, epoch6, iter0, batch512/1133, batch loss:4.387807621242246e-06, Training time:84567.77229595184
batch reward last col mean 8.716561410437862e-07 first col mean 1.234727278642822e-06 all mean 6.094944637879962e-06
9.77689182946051e-07 9.776923661775072e-07
rl training, epoch6, iter0, batch513/1133, batch loss:9.776923661775072e-07, Training time:84585.13235354424
batch reward last col mean 1.1890713722095825e-05 first col mean 2.063560714304913e-06 all mean 2.4273502276628278e-05
9.031884928845102e-07 9.03178374755953e-07
rl training, epoch6, iter0, batch514/1133, batch loss:9.03178374755953e-07, Training time:84601.22179985046
batch reward last col mean 1.054952917911578e-06 first col mean 1.1174333849339746e-05 all mean 1.0653600838850252e-05
2.7261927471045055e-07 2.726202410485712e-07
rl training, epoch6, iter0, batch515/1133, batch loss:2.726202410485712e-07, Training time:84617.2917664051
batch reward last col mean 2.0851919089182047e-06 first col mean 1.047806222231884e-06 all mean 1.8575559579403489e-06
1.3394300140134874e-06 1.339430127700325e-06
rl training, epoch6, iter0, batch516/1133, batch loss:1.339430127700325e-06, Training time:84633.48464679718
batch reward last col mean 7.970562592163333e-07 first col mean 1.2898963177576661e-06 all mean 8.899328349798452e-06
6.827547593957206e-08 6.827109899631978e-08
rl training, epoch6, iter0, batch517/1133, batch loss:6.827109899631978e-08, Training time:84649.48938035965
batch reward last col mean 0.0002264352369820699 first col mean 2.3966695152921602e-06 all mean 0.0002336178149562329
6.455667517002439e-06 6.455663879023632e-06
rl training, epoch6, iter0, batch518/1133, batch loss:6.455663879023632e-06, Training time:84666.74851727486
batch reward last col mean 8.74126999406144e-06 first col mean 1.3808014500682475e-06 all mean 1.5202914482870256e-06
5.425667382041865e-07 5.4256656767393e-07
rl training, epoch6, iter0, batch519/1133, batch loss:5.4256656767393e-07, Training time:84684.49949359894
batch reward last col mean 5.172055352886673e-06 first col mean 3.598693638195982e-06 all mean 2.922969542851206e-05
1.289674173676758e-06 1.2896809948870214e-06
rl training, epoch6, iter0, batch520/1133, batch loss:1.2896809948870214e-06, Training time:84701.90710425377
batch reward last col mean 8.180990107575781e-07 first col mean 1.7609025917408871e-06 all mean 3.2808877676870907e-06
7.687603442718682e-08 7.687692971103388e-08
rl training, epoch6, iter0, batch521/1133, batch loss:7.687692971103388e-08, Training time:84718.5806441307
batch reward last col mean 4.2536698856565636e-06 first col mean 1.0864050636882894e-06 all mean 7.030263532215031e-06
1.1401182291592704e-06 1.1401206165828626e-06
rl training, epoch6, iter0, batch522/1133, batch loss:1.1401206165828626e-06, Training time:84736.20061993599
batch reward last col mean 3.271708919783123e-05 first col mean 4.834623723581899e-07 all mean 3.83890001103282e-05
2.0305655198171735e-05 2.030565337918233e-05
rl training, epoch6, iter0, batch523/1133, batch loss:2.030565337918233e-05, Training time:84753.1265335083
batch reward last col mean 1.0769958862510975e-05 first col mean 1.4560951058228966e-06 all mean 6.832059443695471e-05
2.0040726667502895e-05 2.0040721210534684e-05
rl training, epoch6, iter0, batch524/1133, batch loss:2.0040721210534684e-05, Training time:84769.64281725883
batch reward last col mean 9.352362440040451e-07 first col mean 7.254823231050977e-07 all mean 2.575440248619998e-06
3.18307570523757e-07 3.183078547408513e-07
rl training, epoch6, iter0, batch525/1133, batch loss:3.183078547408513e-07, Training time:84788.4085278511
batch reward last col mean 2.8002302769891685e-06 first col mean 8.603108767601952e-07 all mean 1.3668897736351937e-05
9.075957677850965e-06 9.075956768356264e-06
rl training, epoch6, iter0, batch526/1133, batch loss:9.075956768356264e-06, Training time:84807.168415308
batch reward last col mean 5.260390025796369e-07 first col mean 1.6685607988620177e-06 all mean 1.639082984183915e-05
3.795942404849484e-07 3.796005216827325e-07
rl training, epoch6, iter0, batch527/1133, batch loss:3.796005216827325e-07, Training time:84825.10907936096
batch reward last col mean 6.8392473622225225e-06 first col mean 1.8148987237509573e-06 all mean 6.809212663938524e-06
2.1640973955072695e-06 2.1640973955072695e-06
rl training, epoch6, iter0, batch528/1133, batch loss:2.1640973955072695e-06, Training time:84843.79720520973
batch reward last col mean 9.23913739825366e-06 first col mean 2.3199095267045777e-06 all mean 2.1667088731192052e-05
1.0439257493999321e-05 1.0439259312988725e-05
rl training, epoch6, iter0, batch529/1133, batch loss:1.0439259312988725e-05, Training time:84861.95074176788
batch reward last col mean 1.7472254967287881e-06 first col mean 1.407124273100635e-06 all mean 1.7743541320669465e-05
8.04514229457709e-07 8.045076356211212e-07
rl training, epoch6, iter0, batch530/1133, batch loss:8.045076356211212e-07, Training time:84879.51657414436
batch reward last col mean 6.919755833223462e-06 first col mean 1.2170269201305928e-06 all mean 4.754165274789557e-05
9.990091712097637e-06 9.990080798161216e-06
rl training, epoch6, iter0, batch531/1133, batch loss:9.990080798161216e-06, Training time:84896.25912737846
batch reward last col mean 0.00018305223784409463 first col mean 0.002877506660297513 all mean 0.0002524276787880808
0.00021391583140939474 0.0002139158168574795
rl training, epoch6, iter0, batch532/1133, batch loss:0.0002139158168574795, Training time:84912.9926378727
batch reward last col mean 8.699887985130772e-06 first col mean 1.4491492038359866e-05 all mean 1.9781273294938728e-05
8.526795681973454e-06 8.526797500962857e-06
rl training, epoch6, iter0, batch533/1133, batch loss:8.526797500962857e-06, Training time:84929.74827218056
batch reward last col mean 1.7709021449263673e-06 first col mean 1.3075782590021845e-06 all mean 3.226931585231796e-05
1.16609714950755e-06 1.1661003327390063e-06
rl training, epoch6, iter0, batch534/1133, batch loss:1.1661003327390063e-06, Training time:84946.89484262466
batch reward last col mean 6.321747605397832e-07 first col mean 4.892015681434714e-07 all mean 3.0337710086314473e-06
3.604424136938178e-07 3.6044244211552723e-07
rl training, epoch6, iter0, batch535/1133, batch loss:3.6044244211552723e-07, Training time:84963.74325084686
batch reward last col mean 1.395939534631907e-06 first col mean 1.3218503909229185e-06 all mean 1.733727549435571e-05
1.9437938192368165e-07 1.943877379062542e-07
rl training, epoch6, iter0, batch536/1133, batch loss:1.943877379062542e-07, Training time:84981.38472342491
batch reward last col mean 9.294804499404563e-07 first col mean 7.332214977395779e-07 all mean 7.202828328445321e-06
3.4668255466385745e-07 3.466816735908651e-07
rl training, epoch6, iter0, batch537/1133, batch loss:3.466816735908651e-07, Training time:84997.65152573586
batch reward last col mean 3.7880247418797808e-06 first col mean 6.434942747546302e-07 all mean 2.14645842788741e-06
8.555485351280367e-07 8.55548421441199e-07
rl training, epoch6, iter0, batch538/1133, batch loss:8.55548421441199e-07, Training time:85014.00327157974
batch reward last col mean 2.750940382156841e-07 first col mean 9.679984032118227e-07 all mean 1.6348651115549728e-05
5.01340127812e-06 5.013401732867351e-06
rl training, epoch6, iter0, batch539/1133, batch loss:5.013401732867351e-06, Training time:85030.3122909069
batch reward last col mean 1.5380825288957567e-06 first col mean 7.844264473533258e-07 all mean 1.1791764336521737e-05
8.101768798951525e-06 8.101766979962122e-06
rl training, epoch6, iter0, batch540/1133, batch loss:8.101766979962122e-06, Training time:85046.57861804962
batch reward last col mean 1.7954523627849994e-06 first col mean 2.008824139920762e-06 all mean 8.044692549447063e-06
7.162545898609096e-07 7.162518613768043e-07
rl training, epoch6, iter0, batch541/1133, batch loss:7.162518613768043e-07, Training time:85062.81555747986
batch reward last col mean 4.4726365899805387e-07 first col mean 3.7151189644646365e-06 all mean 1.2371435786917573e-06
1.651924037560093e-07 1.65192219014898e-07
rl training, epoch6, iter0, batch542/1133, batch loss:1.65192219014898e-07, Training time:85079.9375603199
batch reward last col mean 0.0002226864016847685 first col mean 9.873274393612519e-07 all mean 5.698527729691705e-06
7.578154509246815e-06 7.578154054499464e-06
rl training, epoch6, iter0, batch543/1133, batch loss:7.578154054499464e-06, Training time:85096.44933319092
batch reward last col mean 0.0017066833097487688 first col mean 4.651405106415041e-06 all mean 0.0016726215835660696
0.00012407428584992886 0.0001240742567460984
rl training, epoch6, iter0, batch544/1133, batch loss:0.0001240742567460984, Training time:85112.91882514954
batch reward last col mean 8.489343599649146e-06 first col mean 1.0184492111875443e-06 all mean 4.213823558529839e-05
6.65811458020471e-05 6.658113852608949e-05
rl training, epoch6, iter0, batch545/1133, batch loss:6.658113852608949e-05, Training time:85129.77707958221
batch reward last col mean 1.4639297660323791e-05 first col mean 1.9569990854506614e-06 all mean 1.4321267371997237e-05
1.9291878743388224e-06 1.9291883290861733e-06
rl training, epoch6, iter0, batch546/1133, batch loss:1.9291883290861733e-06, Training time:85146.97519612312
batch reward last col mean 5.461101318360306e-05 first col mean 8.102339847937401e-07 all mean 0.00029728744993917644
0.0002734035952016711 0.0002734035952016711
rl training, epoch6, iter0, batch547/1133, batch loss:0.0002734035952016711, Training time:85163.42423939705
batch reward last col mean 1.1164991065015784e-06 first col mean 7.031429959170055e-06 all mean 4.49709705208079e-06
1.8795036567098578e-06 1.8795036567098578e-06
rl training, epoch6, iter0, batch548/1133, batch loss:1.8795036567098578e-06, Training time:85179.75098538399
batch reward last col mean 2.4903616576921195e-05 first col mean 8.224770340348186e-07 all mean 3.9693768485449255e-05
2.5451161491218954e-05 2.545115967222955e-05
rl training, epoch6, iter0, batch549/1133, batch loss:2.545115967222955e-05, Training time:85196.13950133324
batch reward last col mean 0.0003247280546929687 first col mean 0.0003681268135551363 all mean 0.0003300618554931134
3.446759365033358e-05 3.446759365033358e-05
rl training, epoch6, iter0, batch550/1133, batch loss:3.446759365033358e-05, Training time:85212.56824398041
batch reward last col mean 1.798095581762027e-06 first col mean 0.0005970036727376282 all mean 3.5872490116162226e-05
1.6302950825775042e-05 1.6302958101732656e-05
rl training, epoch6, iter0, batch551/1133, batch loss:1.6302958101732656e-05, Training time:85228.97184205055
batch reward last col mean 0.0008277237066067755 first col mean 1.9188728401786648e-06 all mean 0.0006328160525299609
0.0003267119755037129 0.00032671200460754335
rl training, epoch6, iter0, batch552/1133, batch loss:0.00032671200460754335, Training time:85245.57443475723
batch reward last col mean 1.7032953110174276e-06 first col mean 5.241736857897195e-07 all mean 2.129921631421894e-05
1.7140100680990145e-06 1.7140179124908173e-06
rl training, epoch6, iter0, batch553/1133, batch loss:1.7140179124908173e-06, Training time:85262.12623548508
batch reward last col mean 7.69742182455957e-05 first col mean 7.159035249060253e-06 all mean 3.545265644788742e-05
1.204751151817618e-05 1.2047504242218565e-05
rl training, epoch6, iter0, batch554/1133, batch loss:1.2047504242218565e-05, Training time:85278.72785258293
batch reward last col mean 1.0473120255483082e-06 first col mean 1.438292019884102e-05 all mean 1.8295787640454364e-06
6.789604611867617e-08 6.789587558841959e-08
rl training, epoch6, iter0, batch555/1133, batch loss:6.789587558841959e-08, Training time:85295.11313772202
batch reward last col mean 0.00012618752953130752 first col mean 8.784602982814249e-07 all mean 0.00012949838128406554
2.3046002752380446e-05 2.3046000933391042e-05
rl training, epoch6, iter0, batch556/1133, batch loss:2.3046000933391042e-05, Training time:85311.66226863861
batch reward last col mean 5.96717836742755e-06 first col mean 5.514458507605013e-07 all mean 8.27343319542706e-05
0.00029208039632067084 0.0002920804254245013
rl training, epoch6, iter0, batch557/1133, batch loss:0.0002920804254245013, Training time:85328.07194137573
batch reward last col mean 0.0016805825289338827 first col mean 2.866105660359608e-06 all mean 0.0011457136133685708
0.00032155695953406394 0.00032155707594938576
rl training, epoch6, iter0, batch558/1133, batch loss:0.00032155707594938576, Training time:85344.42713427544
batch reward last col mean 3.5032226151088253e-06 first col mean 0.0002537522232159972 all mean 2.809516627166886e-05
2.3872403289715294e-06 2.387242602708284e-06
rl training, epoch6, iter0, batch559/1133, batch loss:2.387242602708284e-06, Training time:85360.84869337082
batch reward last col mean 8.844414765007969e-07 first col mean 1.0178929414905724e-06 all mean 1.7419659343431704e-05
1.4042362636246253e-05 1.404236081725685e-05
rl training, epoch6, iter0, batch560/1133, batch loss:1.404236081725685e-05, Training time:85377.20143270493
batch reward last col mean 4.856711939282832e-07 first col mean 1.2982680345885456e-05 all mean 4.277475454728119e-06
1.187242233413599e-07 1.1872462835071929e-07
rl training, epoch6, iter0, batch561/1133, batch loss:1.1872462835071929e-07, Training time:85393.66463327408
batch reward last col mean 3.735213613254018e-05 first col mean 5.955538426860585e-07 all mean 1.1475354767753743e-05
4.313295903557446e-06 4.313294539315393e-06
rl training, epoch6, iter0, batch562/1133, batch loss:4.313294539315393e-06, Training time:85410.16869044304
batch reward last col mean 7.297281285900681e-07 first col mean 1.4472964267042698e-06 all mean 5.1557640290411655e-06
3.0146264862196404e-07 3.014623359831603e-07
rl training, epoch6, iter0, batch563/1133, batch loss:3.014623359831603e-07, Training time:85426.71942162514
batch reward last col mean 0.0004590089665725827 first col mean 1.5284804248949513e-06 all mean 0.0005595360998995602
0.0002438463707221672 0.0002438463707221672
rl training, epoch6, iter0, batch564/1133, batch loss:0.0002438463707221672, Training time:85443.12911725044
batch reward last col mean 1.5951765135469032e-06 first col mean 1.4197349628375378e-05 all mean 1.6827873423608253e-06
2.453764125220914e-07 2.453763272569631e-07
rl training, epoch6, iter0, batch565/1133, batch loss:2.453763272569631e-07, Training time:85459.78706407547
batch reward last col mean 0.002116073854267597 first col mean 1.0104145076184068e-05 all mean 0.0013959113275632262
0.0008105382439680398 0.0008105382439680398
rl training, epoch6, iter0, batch566/1133, batch loss:0.0008105382439680398, Training time:85476.1980381012
batch reward last col mean 7.002036568337644e-07 first col mean 3.920170001947554e-07 all mean 5.50961658518645e-06
4.382090139642969e-07 4.38212452991138e-07
rl training, epoch6, iter0, batch567/1133, batch loss:4.38212452991138e-07, Training time:85492.6105234623
batch reward last col mean 1.0670617484720424e-05 first col mean 0.0007666985038667917 all mean 1.2190691450086888e-05
4.7244776624211227e-07 4.7245541168194904e-07
rl training, epoch6, iter0, batch568/1133, batch loss:4.7245541168194904e-07, Training time:85509.40004563332
batch reward last col mean 8.929032446758356e-06 first col mean 4.940857706969837e-06 all mean 4.40644689660985e-05
6.992897851887392e-06 6.992897851887392e-06
rl training, epoch6, iter0, batch569/1133, batch loss:6.992897851887392e-06, Training time:85526.23223590851
batch reward last col mean 9.838684491114691e-06 first col mean 1.552853518660413e-06 all mean 1.2804099242202938e-05
1.5242279687299742e-06 1.5242251265590312e-06
rl training, epoch6, iter0, batch570/1133, batch loss:1.5242251265590312e-06, Training time:85543.00295042992
batch reward last col mean 0.00033581300522200763 first col mean 2.13989733310882e-05 all mean 1.9033286662306637e-05
7.146369625843363e-06 7.146369171096012e-06
rl training, epoch6, iter0, batch571/1133, batch loss:7.146369171096012e-06, Training time:85559.77973914146
batch reward last col mean 9.201558555105294e-07 first col mean 1.4269504617914208e-06 all mean 4.8426481953356415e-06
1.8362831610829744e-07 1.8363081721872732e-07
rl training, epoch6, iter0, batch572/1133, batch loss:1.8363081721872732e-07, Training time:85576.32831382751
batch reward last col mean 7.449858821928501e-05 first col mean 7.602340019730036e-07 all mean 6.762910925317556e-05
4.647513196687214e-05 4.647513196687214e-05
rl training, epoch6, iter0, batch573/1133, batch loss:4.647513196687214e-05, Training time:85593.87038064003
batch reward last col mean 4.175136564299464e-05 first col mean 6.409213142433146e-07 all mean 0.0007297085248865187
0.00031743376166559756 0.00031743370345793664
rl training, epoch6, iter0, batch574/1133, batch loss:0.00031743370345793664, Training time:85611.37112903595
batch reward last col mean 6.831056680312031e-07 first col mean 6.004931378811307e-07 all mean 1.7446471929360996e-06
1.8673325996587664e-07 1.8673343049613322e-07
rl training, epoch6, iter0, batch575/1133, batch loss:1.8673343049613322e-07, Training time:85627.6664390564
batch reward last col mean 4.617431841325015e-06 first col mean 6.396423373189464e-07 all mean 7.4828538345173e-05
0.0003393085498828441 0.00033930857898667455
rl training, epoch6, iter0, batch576/1133, batch loss:0.00033930857898667455, Training time:85644.63112854958
batch reward last col mean 1.1040474419132806e-06 first col mean 9.847783530858578e-07 all mean 2.30578298214823e-05
4.315216131089983e-07 4.3152309103788866e-07
rl training, epoch6, iter0, batch577/1133, batch loss:4.3152309103788866e-07, Training time:85661.02572822571
batch reward last col mean 0.0001303319731960073 first col mean 9.390959689881129e-07 all mean 0.00010059668420581147
1.941602567967493e-05 1.9416023860685527e-05
rl training, epoch6, iter0, batch578/1133, batch loss:1.9416023860685527e-05, Training time:85677.49158549309
batch reward last col mean 2.2115222236607224e-05 first col mean 1.8328544229007093e-06 all mean 2.1618992832372896e-05
1.7053309875336709e-06 1.7053318970283726e-06
rl training, epoch6, iter0, batch579/1133, batch loss:1.7053318970283726e-06, Training time:85693.9213860035
batch reward last col mean 0.006325498688966036 first col mean 4.243721036800707e-07 all mean 0.005987514276057482
0.00036761199589818716 0.0003676119667943567
rl training, epoch6, iter0, batch580/1133, batch loss:0.0003676119667943567, Training time:85710.51920390129
batch reward last col mean 2.0329143808339722e-06 first col mean 8.44958265133755e-07 all mean 5.896644779568305e-06
1.394765831719269e-06 1.3947659454061068e-06
rl training, epoch6, iter0, batch581/1133, batch loss:1.3947659454061068e-06, Training time:85727.02517199516
batch reward last col mean 1.3351818779483438e-06 first col mean 9.222846983902855e-07 all mean 9.914736438076943e-06
7.276777864717587e-07 7.276813107637281e-07
rl training, epoch6, iter0, batch582/1133, batch loss:7.276813107637281e-07, Training time:85743.96746945381
batch reward last col mean 2.771788786049001e-06 first col mean 8.227253829318215e-07 all mean 1.2438213161658496e-05
1.526693495179643e-06 1.5266962236637482e-06
rl training, epoch6, iter0, batch583/1133, batch loss:1.5266962236637482e-06, Training time:85761.27444148064
batch reward last col mean 9.092872460314538e-06 first col mean 7.888505137998436e-07 all mean 5.7506858865963295e-06
5.576977173404885e-07 5.576976604970696e-07
rl training, epoch6, iter0, batch584/1133, batch loss:5.576976604970696e-07, Training time:85777.79502010345
batch reward last col mean 0.00031895129359327257 first col mean 0.0015182812931016088 all mean 0.0003980592009611428
0.00010818704322446138 0.00010818702867254615
rl training, epoch6, iter0, batch585/1133, batch loss:0.00010818702867254615, Training time:85794.68924307823
batch reward last col mean 9.208924166159704e-05 first col mean 4.831956061934761e-07 all mean 2.256662082800176e-05
5.698481345461914e-06 5.698487257177476e-06
rl training, epoch6, iter0, batch586/1133, batch loss:5.698487257177476e-06, Training time:85811.00813269615
batch reward last col mean 1.9203071133233607e-06 first col mean 1.4442337032960495e-06 all mean 5.6967942327901255e-06
9.189579941448756e-07 9.189572551804304e-07
rl training, epoch6, iter0, batch587/1133, batch loss:9.189572551804304e-07, Training time:85827.42419052124
batch reward last col mean 7.837902376195416e-05 first col mean 8.368962767235644e-07 all mean 3.946646029362455e-05
2.5915376681950875e-05 2.5915376681950875e-05
rl training, epoch6, iter0, batch588/1133, batch loss:2.5915376681950875e-05, Training time:85843.76246023178
batch reward last col mean 2.903914037233335e-06 first col mean 5.974480927761761e-07 all mean 1.920938302646391e-05
1.0764530998130795e-05 1.0764527360151988e-05
rl training, epoch6, iter0, batch589/1133, batch loss:1.0764527360151988e-05, Training time:85860.24800825119
batch reward last col mean 9.565120308252517e-06 first col mean 7.977257610036759e-07 all mean 5.781287109130062e-05
3.542303238646127e-05 3.542302147252485e-05
rl training, epoch6, iter0, batch590/1133, batch loss:3.542302147252485e-05, Training time:85876.84076476097
batch reward last col mean 1.2447018207240035e-06 first col mean 9.272701572626829e-05 all mean 2.2992144295130856e-05
1.2113098364352481e-06 1.2112989224988269e-06
rl training, epoch6, iter0, batch591/1133, batch loss:1.2112989224988269e-06, Training time:85894.37191843987
batch reward last col mean 2.4380854029004695e-06 first col mean 2.857628487618058e-06 all mean 3.029207800864242e-05
4.747660568682477e-06 4.7476542022195645e-06
rl training, epoch6, iter0, batch592/1133, batch loss:4.7476542022195645e-06, Training time:85911.03582000732
batch reward last col mean 1.8150471078115515e-05 first col mean 3.972435479226988e-06 all mean 4.115244792046724e-06
1.7162252561320201e-06 1.7162251424451824e-06
rl training, epoch6, iter0, batch593/1133, batch loss:1.7162251424451824e-06, Training time:85927.35467815399
batch reward last col mean 3.4230233723064885e-05 first col mean 7.893642077760887e-07 all mean 2.7843994757859036e-05
1.4576134162780363e-05 1.4576133253285661e-05
rl training, epoch6, iter0, batch594/1133, batch loss:1.4576133253285661e-05, Training time:85943.7185959816
batch reward last col mean 5.393541755438491e-07 first col mean 7.84488861427235e-07 all mean 1.115038458010531e-06
8.633843151528708e-08 8.633850967498802e-08
rl training, epoch6, iter0, batch595/1133, batch loss:8.633850967498802e-08, Training time:85960.04181742668
batch reward last col mean 0.005911614745855331 first col mean 1.0881741445700754e-06 all mean 0.00018892367370426655
0.0006453749374486506 0.0006453749374486506
rl training, epoch6, iter0, batch596/1133, batch loss:0.0006453749374486506, Training time:85976.90591430664
batch reward last col mean 4.6300656322273426e-06 first col mean 1.2793980204151012e-06 all mean 4.229187652526889e-06
3.251107614232751e-07 3.2511098879695055e-07
rl training, epoch6, iter0, batch597/1133, batch loss:3.2511098879695055e-07, Training time:85993.3710873127
batch reward last col mean 2.5407168777746847e-06 first col mean 4.2578179204610933e-07 all mean 3.470385490800254e-05
4.580245877150446e-05 4.580245877150446e-05
rl training, epoch6, iter0, batch598/1133, batch loss:4.580245877150446e-05, Training time:86010.25012612343
batch reward last col mean 0.0038436115719377995 first col mean 0.0003867604536935687 all mean 0.003364941105246544
0.0003587101527955383 0.00035871012369170785
rl training, epoch6, iter0, batch599/1133, batch loss:0.00035871012369170785, Training time:86027.16462516785
batch reward last col mean 0.0003077676519751549 first col mean 0.0002998064737766981 all mean 0.0005666755605489016
0.00025122222723439336 0.00025122222723439336
rl training, epoch6, iter0, batch600/1133, batch loss:0.00025122222723439336, Training time:86044.87315535545
batch reward last col mean 0.0013197424123063684 first col mean 4.88370733364718e-06 all mean 0.001581448595970869
0.0002755917375907302 0.00027559176669456065
rl training, epoch6, iter0, batch601/1133, batch loss:0.00027559176669456065, Training time:86062.3717315197
batch reward last col mean 0.00015877200348768383 first col mean 1.5715644394731498e-06 all mean 1.347306533716619e-05
3.7339775644795736e-06 3.733976654984872e-06
rl training, epoch6, iter0, batch602/1133, batch loss:3.733976654984872e-06, Training time:86078.92535352707
batch reward last col mean 9.10397716324951e-07 first col mean 2.155069068976445e-06 all mean 1.4273120541474782e-05
1.5652256024623057e-06 1.5652190086257178e-06
rl training, epoch6, iter0, batch603/1133, batch loss:1.5652190086257178e-06, Training time:86095.52010822296
batch reward last col mean 4.366126631794032e-06 first col mean 5.759530381510558e-07 all mean 8.853970939526334e-05
4.657256431528367e-05 4.657255340134725e-05
rl training, epoch6, iter0, batch604/1133, batch loss:4.657255340134725e-05, Training time:86112.27852678299
batch reward last col mean 7.31519321561791e-07 first col mean 2.4777240469120443e-05 all mean 2.6486179649509722e-06
5.320308105183358e-07 5.320303557709849e-07
rl training, epoch6, iter0, batch605/1133, batch loss:5.320303557709849e-07, Training time:86128.73859381676
batch reward last col mean 2.359078962399508e-06 first col mean 1.0685440656743594e-06 all mean 2.542552465456538e-06
4.640639303943317e-07 4.640641293462977e-07
rl training, epoch6, iter0, batch606/1133, batch loss:4.640641293462977e-07, Training time:86145.28455066681
batch reward last col mean 3.78400500267162e-06 first col mean 3.453992860613653e-07 all mean 9.446721378481016e-06
3.1636930089007365e-06 3.1636934636480873e-06
rl training, epoch6, iter0, batch607/1133, batch loss:3.1636934636480873e-06, Training time:86161.98701524734
batch reward last col mean 1.9511901427904377e-06 first col mean 6.174149120852235e-07 all mean 2.6219968276564032e-05
9.655061603552895e-07 9.654952464188682e-07
rl training, epoch6, iter0, batch608/1133, batch loss:9.654952464188682e-07, Training time:86178.61685967445
batch reward last col mean 0.0002969189081341028 first col mean 8.114509546430781e-05 all mean 0.00014012280735187232
0.0001429789117537439 0.0001429789117537439
rl training, epoch6, iter0, batch609/1133, batch loss:0.0001429789117537439, Training time:86195.04233837128
batch reward last col mean 5.438599828266888e-07 first col mean 1.6827352737891488e-06 all mean 5.437083018478006e-06
1.7671075056568952e-06 1.7671061414148426e-06
rl training, epoch6, iter0, batch610/1133, batch loss:1.7671061414148426e-06, Training time:86211.92874360085
batch reward last col mean 6.765567377442494e-07 first col mean 5.80579921916069e-07 all mean 1.4426119378185831e-05
2.987824530009675e-07 2.9878006557737535e-07
rl training, epoch6, iter0, batch611/1133, batch loss:2.9878006557737535e-07, Training time:86228.75236463547
batch reward last col mean 0.0013564680702984333 first col mean 0.00016009951650630683 all mean 0.0012653854209929705
0.00014509231550619006 0.00014509230095427483
rl training, epoch6, iter0, batch612/1133, batch loss:0.00014509230095427483, Training time:86246.09181904793
batch reward last col mean 7.027218202892982e-07 first col mean 1.0336935929444735e-06 all mean 1.3106991900713183e-05
3.214870787360269e-07 3.2147752904165827e-07
rl training, epoch6, iter0, batch613/1133, batch loss:3.2147752904165827e-07, Training time:86262.83361697197
batch reward last col mean 7.151388672355097e-07 first col mean 5.280101049720543e-07 all mean 2.6811151201400207e-06
1.5168893696682062e-07 1.5168842537605087e-07
rl training, epoch6, iter0, batch614/1133, batch loss:1.5168842537605087e-07, Training time:86279.58479809761
batch reward last col mean 2.9044815619272413e-06 first col mean 1.1518388873810181e-06 all mean 1.456140944355866e-05
8.051318900470505e-07 8.051349027482502e-07
rl training, epoch6, iter0, batch615/1133, batch loss:8.051349027482502e-07, Training time:86296.47553348541
batch reward last col mean 4.516371973295463e-06 first col mean 1.6110727756313281e-06 all mean 3.228750574635342e-05
2.3521624825662002e-05 2.3521621187683195e-05
rl training, epoch6, iter0, batch616/1133, batch loss:2.3521621187683195e-05, Training time:86313.43408298492
batch reward last col mean 0.00029888568678870797 first col mean 1.0817171869348385e-06 all mean 3.218481651856564e-05
6.997320269874763e-06 6.9973252720956225e-06
rl training, epoch6, iter0, batch617/1133, batch loss:6.9973252720956225e-06, Training time:86330.53094506264
batch reward last col mean 3.174668745486997e-05 first col mean 6.409778166016622e-07 all mean 2.6694891857914627e-05
7.839988029445522e-06 7.839989848434925e-06
rl training, epoch6, iter0, batch618/1133, batch loss:7.839989848434925e-06, Training time:86347.41175818443
batch reward last col mean 1.2889397567050764e-06 first col mean 1.8101993646268966e-06 all mean 1.3133346328686457e-05
1.1534930308698677e-06 1.1534907571331132e-06
rl training, epoch6, iter0, batch619/1133, batch loss:1.1534907571331132e-06, Training time:86364.10838484764
batch reward last col mean 3.1993704396882094e-07 first col mean 3.3926778542081593e-06 all mean 1.8654811810847605e-06
2.7043165573559236e-06 2.7043165573559236e-06
rl training, epoch6, iter0, batch620/1133, batch loss:2.7043165573559236e-06, Training time:86380.8066329956
batch reward last col mean 6.346794179989956e-06 first col mean 8.335703114425996e-07 all mean 2.5207220915035577e-06
2.504441454220796e-07 2.5044437279575504e-07
rl training, epoch6, iter0, batch621/1133, batch loss:2.5044437279575504e-07, Training time:86397.65268087387
batch reward last col mean 1.1411134437366854e-06 first col mean 4.147646905039437e-05 all mean 8.804873687040526e-06
1.7793593087844783e-07 1.779326197492992e-07
rl training, epoch6, iter0, batch622/1133, batch loss:1.779326197492992e-07, Training time:86414.3805937767
batch reward last col mean 1.4997074231359875e-06 first col mean 7.637249268555024e-07 all mean 4.114054718229454e-06
5.653715788866975e-07 5.653708967656712e-07
rl training, epoch6, iter0, batch623/1133, batch loss:5.653708967656712e-07, Training time:86431.03593420982
batch reward last col mean 4.796148459718097e-06 first col mean 2.1099631339893676e-06 all mean 4.82972536701709e-05
2.4352186756004812e-06 2.4352086711587617e-06
rl training, epoch6, iter0, batch624/1133, batch loss:2.4352086711587617e-06, Training time:86447.77631664276
batch reward last col mean 8.50731566970353e-07 first col mean 2.147513669115142e-06 all mean 2.246665417260374e-06
1.0363899605181359e-07 1.0363908131694188e-07
rl training, epoch6, iter0, batch625/1133, batch loss:1.0363908131694188e-07, Training time:86464.44855046272
batch reward last col mean 2.228476432719617e-06 first col mean 1.0558524081716314e-06 all mean 2.627601134008728e-05
4.6210845994210104e-07 4.6212241500143136e-07
rl training, epoch6, iter0, batch626/1133, batch loss:4.6212241500143136e-07, Training time:86481.2846763134
batch reward last col mean 7.292910595424473e-07 first col mean 1.3608319022750948e-06 all mean 2.2623048607783858e-06
8.825727491057478e-07 8.825727491057478e-07
rl training, epoch6, iter0, batch627/1133, batch loss:8.825727491057478e-07, Training time:86498.67699027061
batch reward last col mean 1.9597042410168797e-05 first col mean 2.735754378591082e-06 all mean 4.0360224375035614e-05
2.3620284991920926e-05 2.3620284991920926e-05
rl training, epoch6, iter0, batch628/1133, batch loss:2.3620284991920926e-05, Training time:86516.25066542625
batch reward last col mean 9.82604092314432e-07 first col mean 7.364189968939172e-07 all mean 1.0224042853224091e-05
7.479573582713783e-07 7.479591772607819e-07
rl training, epoch6, iter0, batch629/1133, batch loss:7.479591772607819e-07, Training time:86532.87753796577
batch reward last col mean 0.0027797038201242685 first col mean 1.3187982403906062e-06 all mean 0.0026817750185728073
0.00035023275995627046 0.00035023275995627046
rl training, epoch6, iter0, batch630/1133, batch loss:0.00035023275995627046, Training time:86549.67284703255
batch reward last col mean 8.004842015907343e-07 first col mean 4.8261099436786026e-06 all mean 1.4860982446407434e-05
2.053023536063847e-06 2.0530226265691454e-06
rl training, epoch6, iter0, batch631/1133, batch loss:2.0530226265691454e-06, Training time:86566.2898736
batch reward last col mean 7.349203315243358e-06 first col mean 9.922491699398961e-06 all mean 4.777107278641779e-06
3.718636207850068e-06 3.7186364352237433e-06
rl training, epoch6, iter0, batch632/1133, batch loss:3.7186364352237433e-06, Training time:86582.7585875988
batch reward last col mean 8.227943908423185e-07 first col mean 8.301801130983222e-07 all mean 1.4201645171851851e-05
4.22267390831621e-07 4.2227489416291064e-07
rl training, epoch6, iter0, batch633/1133, batch loss:4.2227489416291064e-07, Training time:86599.63518929482
batch reward last col mean 2.117730446116184e-06 first col mean 8.692351229910855e-07 all mean 2.1781631858175388e-06
3.3665841669971996e-07 3.366586440733954e-07
rl training, epoch6, iter0, batch634/1133, batch loss:3.366586440733954e-07, Training time:86616.34998202324
batch reward last col mean 3.834370090771699e-06 first col mean 1.5891874909357284e-06 all mean 1.6610409147688188e-05
1.1262169437031844e-06 1.126215011026943e-06
rl training, epoch6, iter0, batch635/1133, batch loss:1.126215011026943e-06, Training time:86632.94545912743
batch reward last col mean 1.1682656122502522e-06 first col mean 9.871529300653492e-07 all mean 3.2030400234361878e-06
1.5830885047307675e-07 1.583097315460691e-07
rl training, epoch6, iter0, batch636/1133, batch loss:1.583097315460691e-07, Training time:86649.63207125664
batch reward last col mean 1.8497867131372914e-06 first col mean 7.41572875995189e-07 all mean 2.517838765925262e-05
1.3615756415674696e-06 1.361567342428316e-06
rl training, epoch6, iter0, batch637/1133, batch loss:1.361567342428316e-06, Training time:86666.890645504
batch reward last col mean 9.535477829558658e-07 first col mean 7.936660608720558e-07 all mean 6.0379452406778e-06
2.4121965225276654e-07 2.4121527530951425e-07
rl training, epoch6, iter0, batch638/1133, batch loss:2.4121527530951425e-07, Training time:86683.688382864
batch reward last col mean 7.670004151805188e-07 first col mean 5.254129291643039e-07 all mean 3.185041805409128e-06
5.372773443923506e-07 5.372773443923506e-07
rl training, epoch6, iter0, batch639/1133, batch loss:5.372773443923506e-07, Training time:86700.38386631012
batch reward last col mean 2.3321132402998046e-07 first col mean 5.461936325446004e-07 all mean 1.220225567521993e-05
3.200310675310902e-05 3.200310675310902e-05
rl training, epoch6, iter0, batch640/1133, batch loss:3.200310675310902e-05, Training time:86717.05173873901
batch reward last col mean 1.3721448794967728e-06 first col mean 0.00014932309568393975 all mean 2.4871384084690362e-05
3.388962852568511e-07 3.3890566442096315e-07
rl training, epoch6, iter0, batch641/1133, batch loss:3.3890566442096315e-07, Training time:86733.8241250515
batch reward last col mean 1.1502149845910026e-06 first col mean 4.6674769691890106e-05 all mean 2.1730102162109688e-05
5.6411153082081e-07 5.641121560984175e-07
rl training, epoch6, iter0, batch642/1133, batch loss:5.641121560984175e-07, Training time:86750.67551994324
batch reward last col mean 2.9683556022064295e-06 first col mean 9.006483878692961e-07 all mean 4.961950253346004e-06
3.4010017202490417e-07 3.401004846637079e-07
rl training, epoch6, iter0, batch643/1133, batch loss:3.401004846637079e-07, Training time:86767.5098104477
batch reward last col mean 3.520994596328819e-06 first col mean 7.657795322302263e-07 all mean 0.00011017508222721517
0.0005102523136883974 0.0005102524301037192
rl training, epoch6, iter0, batch644/1133, batch loss:0.0005102524301037192, Training time:86784.22991275787
batch reward last col mean 1.2886586773674935e-05 first col mean 9.184263944916893e-06 all mean 1.2530505046015605e-05
5.6061339819279965e-06 5.606132617685944e-06
rl training, epoch6, iter0, batch645/1133, batch loss:5.606132617685944e-06, Training time:86800.95492959023
batch reward last col mean 5.933032412031025e-07 first col mean 6.231767315512116e-07 all mean 8.21217690827325e-06
1.1048298347304808e-06 1.1048313126593712e-06
rl training, epoch6, iter0, batch646/1133, batch loss:1.1048313126593712e-06, Training time:86817.88684487343
batch reward last col mean 0.00011956128582824022 first col mean 4.183607700269931e-07 all mean 0.00018513145914766937
0.00017550602206028998 0.00017550602206028998
rl training, epoch6, iter0, batch647/1133, batch loss:0.00017550602206028998, Training time:86834.87959170341
batch reward last col mean 7.989309551703627e-07 first col mean 2.793994553940138e-06 all mean 4.0581703615316655e-06
3.221393853891641e-07 3.221391295937792e-07
rl training, epoch6, iter0, batch648/1133, batch loss:3.221391295937792e-07, Training time:86851.87666463852
batch reward last col mean 2.881766704376787e-06 first col mean 7.553626346634701e-07 all mean 1.327307563769864e-05
1.0260197313982644e-06 1.0260184808430495e-06
rl training, epoch6, iter0, batch649/1133, batch loss:1.0260184808430495e-06, Training time:86868.79627919197
batch reward last col mean 3.1546783247904386e-06 first col mean 7.508094768127194e-07 all mean 1.3353192116483115e-05
3.7564581134574837e-07 3.756479145522462e-07
rl training, epoch6, iter0, batch650/1133, batch loss:3.756479145522462e-07, Training time:86885.73577713966
batch reward last col mean 9.509150800113275e-07 first col mean 0.000211053280509077 all mean 1.9768471247516572e-05
3.64101924787974e-06 3.6410217489901697e-06
rl training, epoch6, iter0, batch651/1133, batch loss:3.6410217489901697e-06, Training time:86902.72067928314
batch reward last col mean 9.717753709992394e-05 first col mean 2.0448133000172675e-06 all mean 0.00010498146730242297
8.827257988741621e-05 8.827257988741621e-05
rl training, epoch6, iter0, batch652/1133, batch loss:8.827257988741621e-05, Training time:86919.66074252129
batch reward last col mean 7.59773172376299e-07 first col mean 7.989820005604997e-06 all mean 1.5957382856868207e-05
3.174912990289158e-07 3.174950222728512e-07
rl training, epoch6, iter0, batch653/1133, batch loss:3.174950222728512e-07, Training time:86937.18006443977
batch reward last col mean 1.5100781638466287e-06 first col mean 1.5727150639577303e-06 all mean 2.7330399461789057e-05
6.058684903109679e-06 6.058691269572591e-06
rl training, epoch6, iter0, batch654/1133, batch loss:6.058691269572591e-06, Training time:86954.13628578186
batch reward last col mean 2.600927700768807e-06 first col mean 5.846638373441237e-07 all mean 4.405816525832051e-06
1.4280138884714688e-06 1.4280138884714688e-06
rl training, epoch6, iter0, batch655/1133, batch loss:1.4280138884714688e-06, Training time:86971.16634345055
batch reward last col mean 1.1963291399297304e-05 first col mean 6.472196218965109e-07 all mean 0.0006702506216242909
0.0006380851846188307 0.0006380851846188307
rl training, epoch6, iter0, batch656/1133, batch loss:0.0006380851846188307, Training time:86987.99537038803
batch reward last col mean 1.2433171150405542e-06 first col mean 4.4543105559569085e-07 all mean 1.6048956013037241e-06
1.0607598710521415e-07 1.0607598710521415e-07
rl training, epoch6, iter0, batch657/1133, batch loss:1.0607598710521415e-07, Training time:87004.7128264904
batch reward last col mean 6.935607643754338e-07 first col mean 6.214554559846874e-07 all mean 3.998998181486968e-06
1.1787759746084703e-07 1.1787703613208578e-07
rl training, epoch6, iter0, batch658/1133, batch loss:1.1787703613208578e-07, Training time:87021.535572052
batch reward last col mean 9.058394425665028e-07 first col mean 6.634782607761736e-07 all mean 2.5559588721080218e-06
2.784837818126107e-07 2.784838954994484e-07
rl training, epoch6, iter0, batch659/1133, batch loss:2.784838954994484e-07, Training time:87038.60533189774
batch reward last col mean 0.0008527682512067258 first col mean 6.132819407866918e-07 all mean 0.0008452141773886979
9.462043090024963e-05 9.462043090024963e-05
rl training, epoch6, iter0, batch660/1133, batch loss:9.462043090024963e-05, Training time:87055.58832168579
batch reward last col mean 4.489432285481598e-06 first col mean 1.234501041835756e-06 all mean 9.932728971762117e-06
2.0698296793852933e-05 2.0698296793852933e-05
rl training, epoch6, iter0, batch661/1133, batch loss:2.0698296793852933e-05, Training time:87072.62590742111
batch reward last col mean 7.076217798385187e-07 first col mean 8.478980362269795e-07 all mean 2.0279601358197397e-06
6.166478101476969e-07 6.16647753304278e-07
rl training, epoch6, iter0, batch662/1133, batch loss:6.16647753304278e-07, Training time:87089.52263069153
batch reward last col mean 4.854946746490896e-05 first col mean 9.168019232674851e-07 all mean 8.773789886618033e-05
6.356175435939804e-05 6.356175435939804e-05
rl training, epoch6, iter0, batch663/1133, batch loss:6.356175435939804e-05, Training time:87106.23043560982
batch reward last col mean 2.2821932361694053e-05 first col mean 0.00041691676597110927 all mean 2.4089476937660947e-05
1.4915846804797184e-05 1.4915843166818377e-05
rl training, epoch6, iter0, batch664/1133, batch loss:1.4915843166818377e-05, Training time:87123.09888410568
batch reward last col mean 8.253786290879361e-06 first col mean 1.9963536033174023e-06 all mean 3.3791380701586604e-05
3.8276602936093695e-06 3.827663476840826e-06
rl training, epoch6, iter0, batch665/1133, batch loss:3.827663476840826e-06, Training time:87139.82900476456
batch reward last col mean 3.8985967876215e-07 first col mean 1.585225163580617e-06 all mean 1.516458610240079e-06
5.956724180578021e-07 5.956725317446399e-07
rl training, epoch6, iter0, batch666/1133, batch loss:5.956725317446399e-07, Training time:87156.69582557678
batch reward last col mean 1.743153575262113e-06 first col mean 1.1529798484843923e-06 all mean 3.6525768791761948e-06
8.302257015202485e-07 8.302262131110183e-07
rl training, epoch6, iter0, batch667/1133, batch loss:8.302262131110183e-07, Training time:87173.61689019203
batch reward last col mean 6.0016627685399726e-05 first col mean 1.7964307517104317e-06 all mean 1.1260388419032097e-05
5.332633008947596e-06 5.332632099452894e-06
rl training, epoch6, iter0, batch668/1133, batch loss:5.332632099452894e-06, Training time:87190.48909902573
batch reward last col mean 1.031089936986973e-06 first col mean 7.498651939386036e-07 all mean 3.3879816783155547e-06
1.4297185657596856e-07 1.4297111761152337e-07
rl training, epoch6, iter0, batch669/1133, batch loss:1.4297111761152337e-07, Training time:87207.5358235836
batch reward last col mean 3.337396947244997e-06 first col mean 2.7109761049359804e-06 all mean 8.535918823326938e-06
4.7484909373451956e-06 4.7484909373451956e-06
rl training, epoch6, iter0, batch670/1133, batch loss:4.7484909373451956e-06, Training time:87224.74017429352
batch reward last col mean 3.755629450097331e-06 first col mean 1.6733965821913444e-06 all mean 9.155573934549466e-06
1.6826458022478619e-06 1.6826451201268355e-06
rl training, epoch6, iter0, batch671/1133, batch loss:1.6826451201268355e-06, Training time:87241.4246377945
batch reward last col mean 9.428722478332929e-07 first col mean 1.0307081765859039e-06 all mean 6.1731470850645564e-06
2.8092387083233916e-07 2.809273667025991e-07
rl training, epoch6, iter0, batch672/1133, batch loss:2.809273667025991e-07, Training time:87258.39604091644
batch reward last col mean 2.0915245841024444e-05 first col mean 9.456955467612715e-07 all mean 7.624782301718369e-05
4.890347190666944e-05 4.8903475544648245e-05
rl training, epoch6, iter0, batch673/1133, batch loss:4.8903475544648245e-05, Training time:87275.32163667679
batch reward last col mean 0.0004281288420315832 first col mean 1.1648265854091733e-06 all mean 0.0004718354030046612
0.00012252350279595703 0.00012252351734787226
rl training, epoch6, iter0, batch674/1133, batch loss:0.00012252351734787226, Training time:87292.23032450676
batch reward last col mean 2.685346316866344e-06 first col mean 1.2269109674889478e-06 all mean 5.918146143812919e-06
3.605871370382374e-07 3.605867675560148e-07
rl training, epoch6, iter0, batch675/1133, batch loss:3.605867675560148e-07, Training time:87309.06582283974
batch reward last col mean 2.6026209525298327e-05 first col mean 1.0663965213097981e-06 all mean 2.6179006454185583e-05
1.0188906571784173e-06 1.0188906571784173e-06
rl training, epoch6, iter0, batch676/1133, batch loss:1.0188906571784173e-06, Training time:87325.83972787857
batch reward last col mean 1.1365420959918993e-06 first col mean 6.895289175190555e-07 all mean 6.985965683270479e-06
9.622441154988337e-08 9.622291230471092e-08
rl training, epoch6, iter0, batch677/1133, batch loss:9.622291230471092e-08, Training time:87342.41432094574
batch reward last col mean 1.6377091469621519e-06 first col mean 1.0174088629355538e-06 all mean 5.246351520327153e-06
2.4610662876511924e-06 2.4610669697722187e-06
rl training, epoch6, iter0, batch678/1133, batch loss:2.4610669697722187e-06, Training time:87359.08758068085
batch reward last col mean 5.312851953931386e-07 first col mean 0.00031353591475635767 all mean 4.997342330170795e-06
2.1130107086264616e-07 2.113039130335892e-07
rl training, epoch6, iter0, batch679/1133, batch loss:2.113039130335892e-07, Training time:87375.94228029251
batch reward last col mean 1.1443629546192824e-06 first col mean 5.121480626257835e-07 all mean 4.080714006704511e-06
1.7653233896908205e-07 1.7653255213190278e-07
rl training, epoch6, iter0, batch680/1133, batch loss:1.7653255213190278e-07, Training time:87392.70813846588
batch reward last col mean 7.550516329501988e-06 first col mean 3.8864925500092795e-07 all mean 3.475332732705283e-06
1.4561771877197316e-06 1.4561771877197316e-06
rl training, epoch6, iter0, batch681/1133, batch loss:1.4561771877197316e-06, Training time:87409.49601197243
batch reward last col mean 1.0318774002371356e-05 first col mean 5.80976461606042e-07 all mean 2.5920404368662275e-05
3.005035250680521e-05 3.005035250680521e-05
rl training, epoch6, iter0, batch682/1133, batch loss:3.005035250680521e-05, Training time:87426.42959070206
batch reward last col mean 2.821326177127048e-07 first col mean 2.2162586901686154e-05 all mean 3.260331368437619e-06
6.577540290209072e-08 6.577386102435412e-08
rl training, epoch6, iter0, batch683/1133, batch loss:6.577386102435412e-08, Training time:87443.35134840012
batch reward last col mean 8.717837772564963e-06 first col mean 8.158575610650587e-07 all mean 4.6248838771134615e-05
6.327386017801473e-06 6.327378741843859e-06
rl training, epoch6, iter0, batch684/1133, batch loss:6.327378741843859e-06, Training time:87460.03312659264
batch reward last col mean 3.0831895401206566e-06 first col mean 1.0859728263312718e-06 all mean 1.9332897863932885e-05
4.718502168543637e-06 4.718501259048935e-06
rl training, epoch6, iter0, batch685/1133, batch loss:4.718501259048935e-06, Training time:87476.79350042343
batch reward last col mean 1.0555864946582005e-06 first col mean 4.89052240482124e-07 all mean 1.3720045899390243e-06
5.103966600472631e-07 5.10396716890682e-07
rl training, epoch6, iter0, batch686/1133, batch loss:5.10396716890682e-07, Training time:87493.60259246826
batch reward last col mean 3.2244386147795012e-06 first col mean 0.00024919098359532654 all mean 8.748722393647768e-06
1.3733856576436665e-05 1.3733855666941963e-05
rl training, epoch6, iter0, batch687/1133, batch loss:1.3733855666941963e-05, Training time:87509.98954296112
batch reward last col mean 2.1595681118924404e-06 first col mean 2.1109331100888085e-06 all mean 9.448697710467968e-06
1.980145043489756e-06 1.9801482267212123e-06
rl training, epoch6, iter0, batch688/1133, batch loss:1.9801482267212123e-06, Training time:87527.29416251183
batch reward last col mean 1.7541542547405697e-06 first col mean 2.3002494344837032e-06 all mean 6.963060059206327e-06
2.476990914601629e-07 2.4769997253315523e-07
rl training, epoch6, iter0, batch689/1133, batch loss:2.4769997253315523e-07, Training time:87544.53584384918
batch reward last col mean 5.363939635572024e-06 first col mean 7.406853228530963e-07 all mean 4.90542697662022e-06
5.885398763894045e-07 5.885408427275252e-07
rl training, epoch6, iter0, batch690/1133, batch loss:5.885408427275252e-07, Training time:87561.33201050758
batch reward last col mean 0.00034181991941295564 first col mean 1.2406776477291714e-06 all mean 0.00015244293899741024
4.476689355215058e-05 4.4766904466087e-05
rl training, epoch6, iter0, batch691/1133, batch loss:4.4766904466087e-05, Training time:87578.1161429882
batch reward last col mean 2.418979784124531e-05 first col mean 1.4807453680987237e-06 all mean 3.9612572436453775e-05
3.120612745988183e-05 3.120612745988183e-05
rl training, epoch6, iter0, batch692/1133, batch loss:3.120612745988183e-05, Training time:87595.02390122414
batch reward last col mean 1.8808282220561523e-06 first col mean 6.112045412010048e-07 all mean 3.011364015037543e-06
8.908845643418317e-07 8.908845643418317e-07
rl training, epoch6, iter0, batch693/1133, batch loss:8.908845643418317e-07, Training time:87611.86406803131
batch reward last col mean 0.0018210731213912368 first col mean 1.0117882993654348e-06 all mean 0.0006868339260108769
0.00043560320045799017 0.0004356031713541597
rl training, epoch6, iter0, batch694/1133, batch loss:0.0004356031713541597, Training time:87628.48187494278
batch reward last col mean 3.264059341745451e-05 first col mean 8.969345230980252e-07 all mean 4.038965926156379e-05
2.4092823878163472e-05 2.4092820240184665e-05
rl training, epoch6, iter0, batch695/1133, batch loss:2.4092820240184665e-05, Training time:87645.15991950035
batch reward last col mean 0.000501522736158222 first col mean 0.0009625813690945506 all mean 0.0005988138727843761
8.619397704023868e-05 8.619396248832345e-05
rl training, epoch6, iter0, batch696/1133, batch loss:8.619396248832345e-05, Training time:87662.0989458561
batch reward last col mean 2.5949234441213775e-06 first col mean 1.8436021491652355e-06 all mean 4.2794799810508266e-05
0.00014608757919631898 0.0001460875937482342
rl training, epoch6, iter0, batch697/1133, batch loss:0.0001460875937482342, Training time:87679.17883062363
batch reward last col mean 3.10471887132735e-06 first col mean 0.00031508805113844573 all mean 2.0629453501896933e-05
3.7899769722571364e-06 3.789981974477996e-06
rl training, epoch6, iter0, batch698/1133, batch loss:3.789981974477996e-06, Training time:87695.96130752563
batch reward last col mean 1.5401185464725131e-06 first col mean 1.1084483730883221e-06 all mean 4.798332884092815e-05
7.624757563462481e-05 7.624758291058242e-05
rl training, epoch6, iter0, batch699/1133, batch loss:7.624758291058242e-05, Training time:87712.93326115608
batch reward last col mean 6.841000868007541e-07 first col mean 6.05753768923023e-07 all mean 2.2346844161802437e-06
9.017775681741114e-08 9.017774260655642e-08
rl training, epoch6, iter0, batch700/1133, batch loss:9.017774260655642e-08, Training time:87729.66776251793
batch reward last col mean 7.680423550482374e-07 first col mean 3.991613084508572e-06 all mean 5.978605258860625e-06
1.4736529863057513e-07 1.473661228601486e-07
rl training, epoch6, iter0, batch701/1133, batch loss:1.473661228601486e-07, Training time:87746.89467549324
batch reward last col mean 9.046002560353372e-06 first col mean 1.2364889698801562e-06 all mean 5.4506133892573416e-05
2.001096981985029e-05 2.001096072490327e-05
rl training, epoch6, iter0, batch702/1133, batch loss:2.001096072490327e-05, Training time:87763.62941122055
batch reward last col mean 3.0362281904672273e-05 first col mean 0.0008725759689696133 all mean 2.8474474675022066e-05
2.298212166351732e-05 2.2982125301496126e-05
rl training, epoch6, iter0, batch703/1133, batch loss:2.2982125301496126e-05, Training time:87780.58619213104
batch reward last col mean 4.202756826998666e-06 first col mean 4.47521324531408e-06 all mean 5.280296591081424e-06
4.673476894367923e-07 4.6734766101508285e-07
rl training, epoch6, iter0, batch704/1133, batch loss:4.6734766101508285e-07, Training time:87797.69374966621
batch reward last col mean 1.2618737628145027e-06 first col mean 7.910963176982477e-06 all mean 7.78271169110667e-06
1.0747706937763724e-06 1.0747713758973987e-06
rl training, epoch6, iter0, batch705/1133, batch loss:1.0747713758973987e-06, Training time:87814.71591162682
batch reward last col mean 9.354476446787885e-07 first col mean 3.115731306024827e-05 all mean 1.3644602404383477e-05
1.529534188193793e-06 1.529538280919951e-06
rl training, epoch6, iter0, batch706/1133, batch loss:1.529538280919951e-06, Training time:87831.16099953651
batch reward last col mean 0.0010108427377417684 first col mean 2.106468855345156e-05 all mean 0.0006900212028995156
0.00034799313289113343 0.0003479931619949639
rl training, epoch6, iter0, batch707/1133, batch loss:0.0003479931619949639, Training time:87847.74501395226
batch reward last col mean 1.5398920822917717e-06 first col mean 1.269061954189965e-06 all mean 2.8932241548318416e-05
1.246063857252011e-05 1.24606331155519e-05
rl training, epoch6, iter0, batch708/1133, batch loss:1.24606331155519e-05, Training time:87864.53584432602
batch reward last col mean 4.348746927007596e-07 first col mean 0.0017799593042582273 all mean 3.228766581742093e-05
5.226375378697412e-06 5.226355369813973e-06
rl training, epoch6, iter0, batch709/1133, batch loss:5.226355369813973e-06, Training time:87881.32634615898
batch reward last col mean 1.782264189387206e-05 first col mean 0.00019400946621317416 all mean 3.107415250269696e-05
4.69609130959725e-06 4.696094947576057e-06
rl training, epoch6, iter0, batch710/1133, batch loss:4.696094947576057e-06, Training time:87898.87633395195
batch reward last col mean 7.076071710798715e-07 first col mean 7.799585546308663e-07 all mean 3.191543100911076e-06
7.004029498602904e-07 7.00402722486615e-07
rl training, epoch6, iter0, batch711/1133, batch loss:7.00402722486615e-07, Training time:87915.5899617672
batch reward last col mean 2.322209411431686e-06 first col mean 5.2469490583462175e-06 all mean 2.412009280305938e-06
2.3263498860615073e-06 2.3263501134351827e-06
rl training, epoch6, iter0, batch712/1133, batch loss:2.3263501134351827e-06, Training time:87932.36307549477
batch reward last col mean 0.0001269456697627902 first col mean 2.7638632673188113e-05 all mean 0.00015419685223605484
6.345842848531902e-05 6.345842848531902e-05
rl training, epoch6, iter0, batch713/1133, batch loss:6.345842848531902e-05, Training time:87949.33174467087
batch reward last col mean 7.891314453445375e-06 first col mean 1.2614933666554862e-06 all mean 1.2988010894332547e-05
6.324528658296913e-05 6.324528658296913e-05
rl training, epoch6, iter0, batch714/1133, batch loss:6.324528658296913e-05, Training time:87966.05313849449
batch reward last col mean 7.184051355579868e-06 first col mean 1.110950961447088e-06 all mean 4.8241785407299176e-05
3.0600742320530117e-05 3.060073868255131e-05
rl training, epoch6, iter0, batch715/1133, batch loss:3.060073868255131e-05, Training time:87983.68977952003
batch reward last col mean 0.0015172590501606464 first col mean 3.7659245322174684e-07 all mean 8.112839714158326e-05
6.982848572079092e-05 6.982850754866377e-05
rl training, epoch6, iter0, batch716/1133, batch loss:6.982850754866377e-05, Training time:88000.4881105423
batch reward last col mean 1.3382300494413357e-05 first col mean 1.8075323168886825e-05 all mean 5.0968286814168096e-05
1.3532327329812688e-06 1.3532525144910323e-06
rl training, epoch6, iter0, batch717/1133, batch loss:1.3532525144910323e-06, Training time:88017.61868190765
batch reward last col mean 2.6974207685270812e-06 first col mean 4.755318514071405e-05 all mean 3.4461647828720743e-06
9.806700518311118e-07 9.806698244574363e-07
rl training, epoch6, iter0, batch718/1133, batch loss:9.806698244574363e-07, Training time:88034.49529027939
batch reward last col mean 1.422392870153999e-06 first col mean 9.672066880739294e-07 all mean 1.5835705198696814e-05
3.315293781724904e-07 3.3152340961351e-07
rl training, epoch6, iter0, batch719/1133, batch loss:3.3152340961351e-07, Training time:88051.35512661934
batch reward last col mean 8.272596460301429e-06 first col mean 5.465391268444364e-07 all mean 3.110298348474316e-05
7.042889774311334e-05 7.042889774311334e-05
rl training, epoch6, iter0, batch720/1133, batch loss:7.042889774311334e-05, Training time:88068.15675759315
batch reward last col mean 1.0289619467584998e-06 first col mean 9.588771945345798e-07 all mean 4.28900284532574e-06
1.663461262069177e-07 1.6634508881452348e-07
rl training, epoch6, iter0, batch721/1133, batch loss:1.6634508881452348e-07, Training time:88085.33274912834
batch reward last col mean 2.387167296546977e-05 first col mean 0.0008996180258691311 all mean 4.209643884678371e-05
3.077552901231684e-05 3.077552901231684e-05
rl training, epoch6, iter0, batch722/1133, batch loss:3.077552901231684e-05, Training time:88102.38159799576
batch reward last col mean 4.103208993910812e-06 first col mean 9.478263223172689e-07 all mean 1.5119328054424841e-05
5.301916098687798e-05 5.301916098687798e-05
rl training, epoch6, iter0, batch723/1133, batch loss:5.301916098687798e-05, Training time:88119.37906336784
batch reward last col mean 4.2953497541020624e-06 first col mean 0.0007105403929017484 all mean 6.836072134319693e-05
4.003680805908516e-05 4.003680805908516e-05
rl training, epoch6, iter0, batch724/1133, batch loss:4.003680805908516e-05, Training time:88136.5439081192
batch reward last col mean 4.333279503043741e-05 first col mean 1.4781958270759787e-06 all mean 1.7770005797501653e-05
8.187000275938772e-06 8.186998456949368e-06
rl training, epoch6, iter0, batch725/1133, batch loss:8.186998456949368e-06, Training time:88153.65143203735
batch reward last col mean 2.7322899768478237e-05 first col mean 2.7738983590097632e-06 all mean 1.3548624338000081e-05
2.0395129922690103e-06 2.0395193587319227e-06
rl training, epoch6, iter0, batch726/1133, batch loss:2.0395193587319227e-06, Training time:88170.40575432777
batch reward last col mean 5.831412295265181e-07 first col mean 1.7551894416101277e-05 all mean 1.6008485545171425e-05
1.5853264301313175e-07 1.5852714341235696e-07
rl training, epoch6, iter0, batch727/1133, batch loss:1.5852714341235696e-07, Training time:88186.9558186531
batch reward last col mean 1.946616976056248e-06 first col mean 0.0007189750904217362 all mean 2.484425567672588e-05
2.0004921452709823e-07 2.0005541045975406e-07
rl training, epoch6, iter0, batch728/1133, batch loss:2.0005541045975406e-07, Training time:88203.64335107803
batch reward last col mean 2.8659812869591406e-06 first col mean 0.0008577470434829593 all mean 4.1700852307258174e-05
4.900021849607583e-06 4.900037765764864e-06
rl training, epoch6, iter0, batch729/1133, batch loss:4.900037765764864e-06, Training time:88220.59626460075
batch reward last col mean 0.0005529656773433089 first col mean 1.158244003818254e-06 all mean 0.0006712501053698361
0.00030773424077779055 0.00030773418257012963
rl training, epoch6, iter0, batch730/1133, batch loss:0.00030773418257012963, Training time:88237.20011043549
batch reward last col mean 5.885287100682035e-05 first col mean 2.7146777483721962e-06 all mean 9.79850665316917e-05
5.126161340740509e-05 5.126161340740509e-05
rl training, epoch6, iter0, batch731/1133, batch loss:5.126161340740509e-05, Training time:88254.04588341713
batch reward last col mean 2.1153489342395915e-06 first col mean 6.386497943822178e-07 all mean 1.4196632037055679e-05
2.5642697437433526e-05 2.564269925642293e-05
rl training, epoch6, iter0, batch732/1133, batch loss:2.564269925642293e-05, Training time:88270.6926510334
batch reward last col mean 1.6926312582654646e-06 first col mean 2.422545549052302e-06 all mean 2.7617512387223542e-05
6.257009204091446e-07 6.256876190491312e-07
rl training, epoch6, iter0, batch733/1133, batch loss:6.256876190491312e-07, Training time:88288.12155628204
batch reward last col mean 5.875295983059914e-07 first col mean 5.523671461560298e-06 all mean 2.9372149583650753e-06
4.0584447447145067e-07 4.058439628806809e-07
rl training, epoch6, iter0, batch734/1133, batch loss:4.058439628806809e-07, Training time:88304.72908759117
batch reward last col mean 5.4493262723553926e-05 first col mean 1.241834752363502e-06 all mean 7.738955901004374e-05
6.998901517363265e-05 6.998902244959027e-05
rl training, epoch6, iter0, batch735/1133, batch loss:6.998902244959027e-05, Training time:88321.44122314453
batch reward last col mean 2.090955058520194e-05 first col mean 6.49114497264236e-07 all mean 1.0557504538155627e-05
6.651567673543468e-06 6.651566764048766e-06
rl training, epoch6, iter0, batch736/1133, batch loss:6.651566764048766e-06, Training time:88338.15263795853
batch reward last col mean 1.73874673237151e-06 first col mean 8.304851917273481e-07 all mean 1.9983877791673876e-05
4.815969532501185e-06 4.815965894522378e-06
rl training, epoch6, iter0, batch737/1133, batch loss:4.815965894522378e-06, Training time:88354.85306668282
batch reward last col mean 2.735966290856595e-06 first col mean 1.3426461009657942e-06 all mean 3.4430551750119776e-05
5.85505913477391e-05 5.85505913477391e-05
rl training, epoch6, iter0, batch738/1133, batch loss:5.85505913477391e-05, Training time:88371.96457695961
batch reward last col mean 8.326775287059718e-07 first col mean 1.1004257203239831e-06 all mean 4.3997920329275075e-06
3.145446214602998e-07 3.145443372432055e-07
rl training, epoch6, iter0, batch739/1133, batch loss:3.145443372432055e-07, Training time:88388.59792113304
batch reward last col mean 0.004669904243201017 first col mean 9.842606232268736e-07 all mean 0.00423689279705286
0.0003603244258556515 0.00036032445495948195
rl training, epoch6, iter0, batch740/1133, batch loss:0.00036032445495948195, Training time:88405.39051151276
batch reward last col mean 2.186415713367751e-06 first col mean 1.0579581612546463e-05 all mean 1.4044191630091518e-05
1.3476401363732293e-06 1.3476408184942557e-06
rl training, epoch6, iter0, batch741/1133, batch loss:1.3476408184942557e-06, Training time:88421.99411320686
batch reward last col mean 1.6468624153276323e-06 first col mean 4.701747457147576e-06 all mean 1.3821251741319429e-05
2.2693316736877023e-07 2.2692741197261057e-07
rl training, epoch6, iter0, batch742/1133, batch loss:2.2692741197261057e-07, Training time:88439.33394646645
batch reward last col mean 0.001041028299368918 first col mean 4.878901904703525e-07 all mean 0.0010460675694048405
0.00022978708148002625 0.00022978708148002625
rl training, epoch6, iter0, batch743/1133, batch loss:0.00022978708148002625, Training time:88457.82345628738
batch reward last col mean 2.3603251975146122e-06 first col mean 7.176207645898103e-07 all mean 5.209920800552936e-06
1.5489276847802103e-05 1.5489276847802103e-05
rl training, epoch6, iter0, batch744/1133, batch loss:1.5489276847802103e-05, Training time:88474.51498746872
batch reward last col mean 7.423149099849979e-07 first col mean 1.0227447546640178e-06 all mean 1.6271327694994397e-05
1.9111801918825222e-07 1.9110586890747072e-07
rl training, epoch6, iter0, batch745/1133, batch loss:1.9110586890747072e-07, Training time:88491.15100336075
batch reward last col mean 0.00015404651639983058 first col mean 8.63446530274814e-07 all mean 0.00011390466534066945
6.66026389808394e-05 6.66026389808394e-05
rl training, epoch6, iter0, batch746/1133, batch loss:6.66026389808394e-05, Training time:88507.90278315544
batch reward last col mean 2.7646201488096267e-05 first col mean 8.122368626573007e-07 all mean 2.853837577276863e-05
2.502360302969464e-06 2.5023580292327097e-06
rl training, epoch6, iter0, batch747/1133, batch loss:2.5023580292327097e-06, Training time:88524.68453788757
batch reward last col mean 2.0104987470404012e-06 first col mean 1.2497596344474005e-06 all mean 4.167044153291499e-06
1.1547463145689107e-06 1.1547459735083976e-06
rl training, epoch6, iter0, batch748/1133, batch loss:1.1547459735083976e-06, Training time:88541.40691518784
batch reward last col mean 6.297987056314014e-07 first col mean 6.185939582792344e-07 all mean 9.171000101559912e-07
1.1642575969972313e-07 1.164256318020307e-07
rl training, epoch6, iter0, batch749/1133, batch loss:1.164256318020307e-07, Training time:88558.0494298935
batch reward last col mean 8.623059329693206e-06 first col mean 8.140544878187939e-07 all mean 1.731781776470598e-05
9.323812264483422e-06 9.32381135498872e-06
rl training, epoch6, iter0, batch750/1133, batch loss:9.32381135498872e-06, Training time:88574.83069038391
batch reward last col mean 1.2493084113884834e-06 first col mean 9.157964996120427e-06 all mean 4.519925823842641e-06
1.343898645700392e-07 1.3438862822567899e-07
rl training, epoch6, iter0, batch751/1133, batch loss:1.3438862822567899e-07, Training time:88591.47581076622
batch reward last col mean 2.929939000750892e-05 first col mean 1.1521236729095108e-06 all mean 7.511162402806804e-05
5.935271929047303e-06 5.9352591961214785e-06
rl training, epoch6, iter0, batch752/1133, batch loss:5.9352591961214785e-06, Training time:88608.39867043495
batch reward last col mean 5.693813704965578e-07 first col mean 6.359907729347469e-07 all mean 1.790863962014555e-06
9.467801476148452e-08 9.467787265293737e-08
rl training, epoch6, iter0, batch753/1133, batch loss:9.467787265293737e-08, Training time:88624.91208815575
batch reward last col mean 3.4778789995471016e-05 first col mean 8.97056338544644e-07 all mean 4.850252662436105e-05
0.0001167121808975935 0.00011671217362163588
rl training, epoch6, iter0, batch754/1133, batch loss:0.00011671217362163588, Training time:88641.7835226059
batch reward last col mean 7.605291898471478e-07 first col mean 3.373897357050737e-07 all mean 1.7825377653934993e-05
3.997116380105581e-07 3.9972283616407367e-07
rl training, epoch6, iter0, batch755/1133, batch loss:3.9972283616407367e-07, Training time:88658.6201262474
batch reward last col mean 0.00018518893921282142 first col mean 7.956864465086255e-06 all mean 5.107139077153988e-05
2.807736018439755e-05 2.807737109833397e-05
rl training, epoch6, iter0, batch756/1133, batch loss:2.807737109833397e-05, Training time:88675.41289281845
batch reward last col mean 2.2657688987237634e-06 first col mean 2.853455725926324e-06 all mean 4.305733455112204e-06
1.7377415133523755e-06 1.7377415133523755e-06
rl training, epoch6, iter0, batch757/1133, batch loss:1.7377415133523755e-06, Training time:88692.08093595505
batch reward last col mean 1.0825024219229817e-06 first col mean 2.2887579689268023e-06 all mean 1.7223229633600567e-06
1.6986739126423345e-07 1.6986727757739573e-07
rl training, epoch6, iter0, batch758/1133, batch loss:1.6986727757739573e-07, Training time:88708.84040617943
batch reward last col mean 2.9043956146779237e-06 first col mean 2.084187144646421e-06 all mean 9.8999917099718e-06
5.990836143610068e-06 5.990836143610068e-06
rl training, epoch6, iter0, batch759/1133, batch loss:5.990836143610068e-06, Training time:88725.41201019287
batch reward last col mean 1.9491226339596324e-06 first col mean 5.557430995395407e-07 all mean 3.929690137738362e-06
2.1255024762467656e-07 2.125499065641634e-07
rl training, epoch6, iter0, batch760/1133, batch loss:2.125499065641634e-07, Training time:88742.81122350693
batch reward last col mean 4.5324065922613954e-07 first col mean 5.412294399320672e-07 all mean 1.403826718160417e-05
1.8873618046200136e-06 1.8873682847697637e-06
rl training, epoch6, iter0, batch761/1133, batch loss:1.8873682847697637e-06, Training time:88759.25007104874
batch reward last col mean 2.8283791834837757e-05 first col mean 1.1541812909854343e-06 all mean 5.233849606156582e-06
6.492301963589853e-06 6.492301963589853e-06
rl training, epoch6, iter0, batch762/1133, batch loss:6.492301963589853e-06, Training time:88776.00072789192
batch reward last col mean 4.04538368456997e-05 first col mean 1.1991363635388552e-06 all mean 5.4374166211346164e-05
0.0001323260075878352 0.0001323260075878352
rl training, epoch6, iter0, batch763/1133, batch loss:0.0001323260075878352, Training time:88792.56364130974
batch reward last col mean 3.180530256940983e-07 first col mean 1.0597366326692281e-06 all mean 3.29131398757454e-06
1.3035723611665162e-07 1.3035827350904583e-07
rl training, epoch6, iter0, batch764/1133, batch loss:1.3035827350904583e-07, Training time:88809.26719594002
batch reward last col mean 0.00036732907756231725 first col mean 9.366937092636363e-07 all mean 0.0001264415477635339
0.00013410620158538222 0.000134106187033467
rl training, epoch6, iter0, batch765/1133, batch loss:0.000134106187033467, Training time:88826.01160788536
batch reward last col mean 4.444608748599421e-06 first col mean 2.133243287971709e-05 all mean 1.326003075519111e-05
2.7076509923062986e-06 2.707650082811597e-06
rl training, epoch6, iter0, batch766/1133, batch loss:2.707650082811597e-06, Training time:88842.79350399971
batch reward last col mean 8.044977448662394e-07 first col mean 6.328076551653794e-07 all mean 1.5503180748055456e-06
8.07187419127331e-08 8.071884849414346e-08
rl training, epoch6, iter0, batch767/1133, batch loss:8.071884849414346e-08, Training time:88859.71495842934
batch reward last col mean 5.132220053383207e-07 first col mean 1.5676030216127401e-06 all mean 3.642839510575868e-05
3.1765373478265246e-06 3.176544623784139e-06
rl training, epoch6, iter0, batch768/1133, batch loss:3.176544623784139e-06, Training time:88876.75375509262
batch reward last col mean 4.493719097808935e-05 first col mean 7.407280691040796e-07 all mean 4.5585224142996594e-05
4.717348474514438e-06 4.717351202998543e-06
rl training, epoch6, iter0, batch769/1133, batch loss:4.717351202998543e-06, Training time:88894.5359890461
batch reward last col mean 2.0047143607371254e-06 first col mean 6.3348097683046944e-06 all mean 2.8540020139189437e-05
1.1396162335586268e-05 1.1396164154575672e-05
rl training, epoch6, iter0, batch770/1133, batch loss:1.1396164154575672e-05, Training time:88911.36344146729
batch reward last col mean 1.3115471801938838e-06 first col mean 6.354601964631001e-07 all mean 1.8444267197992303e-06
7.245025557267581e-08 7.24501916238296e-08
rl training, epoch6, iter0, batch771/1133, batch loss:7.24501916238296e-08, Training time:88927.98142409325
batch reward last col mean 9.84752768999897e-05 first col mean 9.520393859929754e-07 all mean 0.000117662493721582
3.300124080851674e-05 3.300124080851674e-05
rl training, epoch6, iter0, batch772/1133, batch loss:3.300124080851674e-05, Training time:88944.77512979507
batch reward last col mean 0.00015269363939296454 first col mean 2.497349851182662e-05 all mean 2.125083665305283e-05
5.864791091880761e-06 5.864795184606919e-06
rl training, epoch6, iter0, batch773/1133, batch loss:5.864795184606919e-06, Training time:88961.29049539566
batch reward last col mean 3.178984684382158e-07 first col mean 1.0435671811137581e-06 all mean 5.5505402087874245e-06
1.8657662792520568e-07 1.8657939904187515e-07
rl training, epoch6, iter0, batch774/1133, batch loss:1.8657939904187515e-07, Training time:88977.92345118523
batch reward last col mean 5.644208158628317e-07 first col mean 1.5852765500312671e-06 all mean 0.0001501782680861652
0.00012856961984653026 0.00012856961984653026
rl training, epoch6, iter0, batch775/1133, batch loss:0.00012856961984653026, Training time:88994.80532884598
batch reward last col mean 0.0001311351516051218 first col mean 8.779278459769557e-07 all mean 3.9177306462079287e-05
3.4983564546564594e-05 3.4983564546564594e-05
rl training, epoch6, iter0, batch776/1133, batch loss:3.4983564546564594e-05, Training time:89011.7695324421
batch reward last col mean 3.5125864087603986e-05 first col mean 2.131994733645115e-06 all mean 2.7218782634008676e-05
8.565905773139093e-06 8.565905773139093e-06
rl training, epoch6, iter0, batch777/1133, batch loss:8.565905773139093e-06, Training time:89029.02911663055
batch reward last col mean 0.00038832792779430747 first col mean 7.623301598869148e-07 all mean 6.183586083352566e-05
3.9846527215559036e-05 3.984652357758023e-05
rl training, epoch6, iter0, batch778/1133, batch loss:3.984652357758023e-05, Training time:89046.41947865486
batch reward last col mean 3.085212028963724e-06 first col mean 9.772212479219888e-07 all mean 4.6343531721504405e-05
7.956041940815339e-07 7.956236345307843e-07
rl training, epoch6, iter0, batch779/1133, batch loss:7.956236345307843e-07, Training time:89063.1353263855
batch reward last col mean 1.6072320931925788e-06 first col mean 4.874378305430582e-07 all mean 4.647506557375891e-06
8.210175110434648e-06 8.210174200939946e-06
rl training, epoch6, iter0, batch780/1133, batch loss:8.210174200939946e-06, Training time:89079.90173077583
batch reward last col mean 1.105945443669043e-06 first col mean 8.259106607511058e-07 all mean 3.770185685425531e-06
1.8314494809601456e-07 1.8314500493943342e-07
rl training, epoch6, iter0, batch781/1133, batch loss:1.8314500493943342e-07, Training time:89096.92433619499
batch reward last col mean 6.350695684886887e-07 first col mean 1.0766792684080428e-06 all mean 4.543580871541053e-06
1.3280197208587197e-07 1.3280117627800792e-07
rl training, epoch6, iter0, batch782/1133, batch loss:1.3280117627800792e-07, Training time:89113.6144657135
batch reward last col mean 3.177279268129496e-06 first col mean 1.7225020201294683e-06 all mean 2.1731097149313428e-05
5.278676690068096e-05 5.2786759624723345e-05
rl training, epoch6, iter0, batch783/1133, batch loss:5.2786759624723345e-05, Training time:89130.65815472603
batch reward last col mean 1.9352708022779552e-06 first col mean 8.93511980848416e-07 all mean 1.644914118514862e-05
1.1458618018878042e-06 1.1458662356744753e-06
rl training, epoch6, iter0, batch784/1133, batch loss:1.1458662356744753e-06, Training time:89147.34383296967
batch reward last col mean 0.0006697706994600594 first col mean 3.1631273600396526e-07 all mean 0.00018397097301203758
0.00018257828196510673 0.00018257828196510673
rl training, epoch6, iter0, batch785/1133, batch loss:0.00018257828196510673, Training time:89163.9891037941
batch reward last col mean 6.197884658831754e-07 first col mean 5.71911141378223e-06 all mean 3.1383169698528945e-06
1.609107300737378e-07 1.6091095744741324e-07
rl training, epoch6, iter0, batch786/1133, batch loss:1.6091095744741324e-07, Training time:89180.94906592369
batch reward last col mean 2.2371114027919248e-06 first col mean 0.0005028932355344296 all mean 1.4826526239630766e-05
2.2925783014215995e-06 2.292577619300573e-06
rl training, epoch6, iter0, batch787/1133, batch loss:2.292577619300573e-06, Training time:89197.46346497536
batch reward last col mean 8.197618512895133e-07 first col mean 9.867849257716443e-07 all mean 1.998876905418001e-05
3.918336801689293e-07 3.9182478417387756e-07
rl training, epoch6, iter0, batch788/1133, batch loss:3.9182478417387756e-07, Training time:89214.34636735916
batch reward last col mean 4.724694008473307e-06 first col mean 8.563582014176063e-06 all mean 3.774508513743058e-05
2.1645679225912318e-05 2.1645677406922914e-05
rl training, epoch6, iter0, batch789/1133, batch loss:2.1645677406922914e-05, Training time:89230.97139048576
batch reward last col mean 6.664092779828934e-07 first col mean 4.0897117514759884e-07 all mean 2.6341504053561948e-05
2.6667748898034915e-07 2.6667842689676036e-07
rl training, epoch6, iter0, batch790/1133, batch loss:2.6667842689676036e-07, Training time:89247.48857355118
batch reward last col mean 0.0004725776088889688 first col mean 7.809805538272485e-06 all mean 0.0002567824849393219
7.956742047099397e-05 7.956742047099397e-05
rl training, epoch6, iter0, batch791/1133, batch loss:7.956742047099397e-05, Training time:89264.51393818855
batch reward last col mean 1.680524178482301e-06 first col mean 0.00010729124187491834 all mean 7.846238986530807e-06
6.515829227282666e-07 6.5158275219801e-07
rl training, epoch6, iter0, batch792/1133, batch loss:6.5158275219801e-07, Training time:89281.34344911575
batch reward last col mean 0.00015221600187942386 first col mean 2.068993353532278e-06 all mean 0.00015082779282238334
2.2979433197178878e-05 2.297943865414709e-05
rl training, epoch6, iter0, batch793/1133, batch loss:2.297943865414709e-05, Training time:89298.22672057152
batch reward last col mean 3.5668304008140694e-06 first col mean 1.0387163911218522e-06 all mean 2.153366403945256e-05
9.051431106854579e-07 9.051485108102497e-07
rl training, epoch6, iter0, batch794/1133, batch loss:9.051485108102497e-07, Training time:89314.81837701797
batch reward last col mean 0.00013376153947319835 first col mean 2.5918279789038934e-06 all mean 0.00012771318142767996
4.4293417886365205e-05 4.429341061040759e-05
rl training, epoch6, iter0, batch795/1133, batch loss:4.429341061040759e-05, Training time:89333.91591405869
batch reward last col mean 0.00014210095105227083 first col mean 2.5161564281006576e-06 all mean 6.258080247789621e-05
2.8235443096491508e-05 2.8235443096491508e-05
rl training, epoch6, iter0, batch796/1133, batch loss:2.8235443096491508e-05, Training time:89351.42634057999
batch reward last col mean 2.190542772950721e-06 first col mean 0.0005149946082383394 all mean 2.6731398975243792e-05
1.1418541134844418e-06 1.1418576377764111e-06
rl training, epoch6, iter0, batch797/1133, batch loss:1.1418576377764111e-06, Training time:89367.8783082962
batch reward last col mean 4.3004765757359564e-06 first col mean 8.116413710013148e-07 all mean 1.678909939073492e-05
9.193422556563746e-07 9.193426535603066e-07
rl training, epoch6, iter0, batch798/1133, batch loss:9.193426535603066e-07, Training time:89384.2938656807
batch reward last col mean 6.086417556616652e-07 first col mean 1.0016879059548955e-06 all mean 3.3227449875994353e-06
8.843035459449311e-08 8.843119303492131e-08
rl training, epoch6, iter0, batch799/1133, batch loss:8.843119303492131e-08, Training time:89400.6875193119
batch reward last col mean 3.934404958272353e-05 first col mean 6.086276584937877e-07 all mean 0.00023405849060509354
0.0005295323207974434 0.0005295323207974434
rl training, epoch6, iter0, batch800/1133, batch loss:0.0005295323207974434, Training time:89417.36237120628
batch reward last col mean 4.0983882172440644e-06 first col mean 1.3630500461658812e-06 all mean 1.4577853107766714e-05
1.0787950941448798e-06 1.0787999826789019e-06
rl training, epoch6, iter0, batch801/1133, batch loss:1.0787999826789019e-06, Training time:89434.110653162
batch reward last col mean 6.303546797425952e-06 first col mean 5.20382059221447e-07 all mean 7.683717740292195e-06
3.3413451205888123e-07 3.3413331834708515e-07
rl training, epoch6, iter0, batch802/1133, batch loss:3.3413331834708515e-07, Training time:89450.81978797913
batch reward last col mean 3.098765228060074e-05 first col mean 1.7551260498294141e-06 all mean 6.580404442502186e-05
2.9282460673130117e-05 2.928245703515131e-05
rl training, epoch6, iter0, batch803/1133, batch loss:2.928245703515131e-05, Training time:89467.4843325615
batch reward last col mean 1.6499023331562057e-05 first col mean 1.217203498526942e-05 all mean 6.748849409632385e-05
4.164047277299687e-05 4.164047641097568e-05
rl training, epoch6, iter0, batch804/1133, batch loss:4.164047641097568e-05, Training time:89484.55871891975
batch reward last col mean 0.00012800318654626608 first col mean 1.1983011063421145e-06 all mean 4.178405652055517e-05
2.0357183529995382e-05 2.0357183529995382e-05
rl training, epoch6, iter0, batch805/1133, batch loss:2.0357183529995382e-05, Training time:89503.16113114357
batch reward last col mean 1.4763035096621024e-06 first col mean 6.025302354828455e-07 all mean 2.0897102785966126e-06
1.584394908604736e-07 1.5843919243252458e-07
rl training, epoch6, iter0, batch806/1133, batch loss:1.5843919243252458e-07, Training time:89519.77717852592
batch reward last col mean 7.305432632165321e-07 first col mean 8.766728569753468e-07 all mean 1.429040185030317e-05
2.0280998569432995e-07 2.0280997148347524e-07
rl training, epoch6, iter0, batch807/1133, batch loss:2.0280997148347524e-07, Training time:89536.93802285194
batch reward last col mean 0.0007418975583277643 first col mean 7.729159960945253e-07 all mean 0.0007478242041543126
6.0754486185032874e-05 6.075448982301168e-05
rl training, epoch6, iter0, batch808/1133, batch loss:6.075448982301168e-05, Training time:89553.70715141296
batch reward last col mean 7.487381026294315e-07 first col mean 1.8566397557151504e-06 all mean 2.1387111246440327e-06
7.220159403686921e-08 7.220189246481823e-08
rl training, epoch6, iter0, batch809/1133, batch loss:7.220189246481823e-08, Training time:89570.48362326622
batch reward last col mean 7.867622571211541e-07 first col mean 3.388157097106159e-07 all mean 2.2276656181929866e-06
6.076334102544934e-08 6.076336944715877e-08
rl training, epoch6, iter0, batch810/1133, batch loss:6.076336944715877e-08, Training time:89587.33686685562
batch reward last col mean 8.948795766627882e-07 first col mean 1.4841421034361701e-06 all mean 8.634170626464766e-06
9.071152362594148e-07 9.071149520423205e-07
rl training, epoch6, iter0, batch811/1133, batch loss:9.071149520423205e-07, Training time:89604.10590267181
batch reward last col mean 8.260368304036092e-06 first col mean 9.627267445466714e-07 all mean 1.0024275070463773e-05
8.040755687943602e-07 8.040801731112879e-07
rl training, epoch6, iter0, batch812/1133, batch loss:8.040801731112879e-07, Training time:89620.86722064018
batch reward last col mean 4.9907966968021356e-06 first col mean 1.3090015045236214e-06 all mean 1.9955825337092392e-05
8.118013283819892e-06 8.11801237432519e-06
rl training, epoch6, iter0, batch813/1133, batch loss:8.11801237432519e-06, Training time:89638.08795309067
batch reward last col mean 0.00017181498697027564 first col mean 5.844605084348586e-07 all mean 0.0001644820295041427
1.6525216778973117e-05 1.6525214959983714e-05
rl training, epoch6, iter0, batch814/1133, batch loss:1.6525214959983714e-05, Training time:89655.37321519852
batch reward last col mean 1.4866702713334234e-06 first col mean 7.755718911539589e-07 all mean 6.125246272858931e-06
1.5117329610347952e-07 1.511696439138177e-07
rl training, epoch6, iter0, batch815/1133, batch loss:1.511696439138177e-07, Training time:89672.11816358566
batch reward last col mean 1.4424340406549163e-06 first col mean 3.544156061252579e-05 all mean 6.304383077804232e-06
3.2549503430345794e-06 3.2549494335398776e-06
rl training, epoch6, iter0, batch816/1133, batch loss:3.2549494335398776e-06, Training time:89688.88017392159
batch reward last col mean 3.2453385756525677e-06 first col mean 8.891428819879366e-07 all mean 1.6411891920142807e-05
1.5934569091768935e-05 1.5934569091768935e-05
rl training, epoch6, iter0, batch817/1133, batch loss:1.5934569091768935e-05, Training time:89705.3417634964
batch reward last col mean 1.022533979266882e-06 first col mean 1.409728156431811e-06 all mean 7.507907866965979e-06
1.027301777867251e-06 1.0273023463014397e-06
rl training, epoch6, iter0, batch818/1133, batch loss:1.0273023463014397e-06, Training time:89721.95309185982
batch reward last col mean 1.5015302778920159e-06 first col mean 2.395061073912075e-06 all mean 1.95796528714709e-05
1.4393556284630904e-06 1.4393605169971124e-06
rl training, epoch6, iter0, batch819/1133, batch loss:1.4393605169971124e-06, Training time:89739.0315630436
batch reward last col mean 7.24194342183182e-06 first col mean 7.207866019598441e-07 all mean 2.2489341517939465e-06
5.814069368170749e-07 5.814070505039126e-07
rl training, epoch6, iter0, batch820/1133, batch loss:5.814070505039126e-07, Training time:89755.82269835472
batch reward last col mean 5.9581416280707344e-06 first col mean 1.405383727615117e-06 all mean 2.7530952138477005e-05
1.4443134205066599e-05 1.4443136933550704e-05
rl training, epoch6, iter0, batch821/1133, batch loss:1.4443136933550704e-05, Training time:89772.3419623375
batch reward last col mean 0.0012456076219677925 first col mean 8.586175681557506e-07 all mean 0.0006548390374518931
0.0005380161455832422 0.0005380161455832422
rl training, epoch6, iter0, batch822/1133, batch loss:0.0005380161455832422, Training time:89789.87133288383
batch reward last col mean 9.344049090032058e-07 first col mean 6.361582200042903e-05 all mean 1.519171019026544e-05
4.699915905348462e-07 4.699916189565556e-07
rl training, epoch6, iter0, batch823/1133, batch loss:4.699916189565556e-07, Training time:89806.64067697525
batch reward last col mean 7.557064236607403e-07 first col mean 4.5707577100984054e-07 all mean 1.036132834997261e-05
2.275328085943329e-07 2.275330075462989e-07
rl training, epoch6, iter0, batch824/1133, batch loss:2.275330075462989e-07, Training time:89823.42681741714
batch reward last col mean 5.166485266272502e-07 first col mean 6.152607738840743e-07 all mean 1.8855005237128353e-06
1.3731255421589594e-07 1.373122273662375e-07
rl training, epoch6, iter0, batch825/1133, batch loss:1.373122273662375e-07, Training time:89840.15946388245
batch reward last col mean 1.3412557109404588e-06 first col mean 1.0642851293596323e-06 all mean 1.6739311831770465e-05
3.7981126865815895e-07 3.7980754541422357e-07
rl training, epoch6, iter0, batch826/1133, batch loss:3.7980754541422357e-07, Training time:89856.9137661457
batch reward last col mean 8.160928928191424e-07 first col mean 2.90450907414197e-06 all mean 3.7366942706285045e-05
1.0988485882990062e-05 1.0988491339958273e-05
rl training, epoch6, iter0, batch827/1133, batch loss:1.0988491339958273e-05, Training time:89873.80799865723
batch reward last col mean 0.004588134586811066 first col mean 3.960434241889743e-06 all mean 0.004388377070426941
0.001234558061696589 0.0012345579452812672
rl training, epoch6, iter0, batch828/1133, batch loss:0.0012345579452812672, Training time:89890.7866551876
batch reward last col mean 8.222301630667062e-07 first col mean 1.0406030241938424e-06 all mean 1.4687848306493834e-05
2.3812444851500914e-06 2.3812431209080387e-06
rl training, epoch6, iter0, batch829/1133, batch loss:2.3812431209080387e-06, Training time:89908.20485830307
batch reward last col mean 7.102222298271954e-06 first col mean 1.4550460036844015e-06 all mean 9.366552149003837e-06
4.073544062066503e-07 4.0735389461588056e-07
rl training, epoch6, iter0, batch830/1133, batch loss:4.0735389461588056e-07, Training time:89924.83678674698
batch reward last col mean 5.364185199141502e-06 first col mean 6.103471150709083e-07 all mean 2.093895545840496e-06
2.215025034502105e-07 2.2150247502850107e-07
rl training, epoch6, iter0, batch831/1133, batch loss:2.2150247502850107e-07, Training time:89942.80168485641
batch reward last col mean 1.3742044757236727e-05 first col mean 1.99402347789146e-06 all mean 2.2939191694604233e-05
1.7837055565905757e-05 1.7837059203884564e-05
rl training, epoch6, iter0, batch832/1133, batch loss:1.7837059203884564e-05, Training time:89960.08761239052
