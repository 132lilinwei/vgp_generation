loaded G
loaded D
Using device cuda:6
begin rl....
rl epoch 0, begin RL for generator...
rl epoch 0, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.3539625434673472 Time: 128.7743091583252 s
rl epoch 0, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6928356695206735 Time: 103.00102496147156 s
loss of true 0.3169922605485697 loss of gen 0.2445343586912959 loss of other 0.13130905049452715 first score 0.1822250485420227
rl epoch 1, begin RL for generator...
batch reward last col mean 0.12424559891223907 first col mean 0.13003551959991455 all mean 0.12934722006320953
0.4374845325946808 0.4374845325946808
rl training, epoch1, iter0, batch0/1133, batch loss:0.4374845325946808, Training time:233.9574704170227
batch reward last col mean 0.12072975188493729 first col mean 0.16035059094429016 all mean 0.1309376060962677
0.43768051266670227 0.43768051266670227
rl training, epoch1, iter0, batch1/1133, batch loss:0.43768051266670227, Training time:236.06381130218506
batch reward last col mean 0.10650832951068878 first col mean 0.13786065578460693 all mean 0.10745411366224289
0.40538889169692993 0.40538889169692993
rl training, epoch1, iter0, batch2/1133, batch loss:0.40538889169692993, Training time:238.85559010505676
batch reward last col mean 0.1258990466594696 first col mean 0.13303495943546295 all mean 0.12813608348369598
0.43553078174591064 0.43553078174591064
rl training, epoch1, iter0, batch3/1133, batch loss:0.43553078174591064, Training time:241.62532877922058
batch reward last col mean 0.16170504689216614 first col mean 0.16264331340789795 all mean 0.15514491498470306
0.5319281220436096 0.5319281220436096
rl training, epoch1, iter0, batch4/1133, batch loss:0.5319281220436096, Training time:244.48720383644104
batch reward last col mean 0.11471842229366302 first col mean 0.11779546737670898 all mean 0.12199629098176956
0.43801698088645935 0.43801698088645935
rl training, epoch1, iter0, batch5/1133, batch loss:0.43801698088645935, Training time:246.78042244911194
batch reward last col mean 0.1291901022195816 first col mean 0.13929001986980438 all mean 0.1345459520816803
0.5008204579353333 0.5008204579353333
rl training, epoch1, iter0, batch6/1133, batch loss:0.5008204579353333, Training time:248.87733149528503
batch reward last col mean 0.1194375604391098 first col mean 0.1339452713727951 all mean 0.12288924306631088
0.359645813703537 0.359645813703537
rl training, epoch1, iter0, batch7/1133, batch loss:0.359645813703537, Training time:252.07662558555603
batch reward last col mean 0.11441023647785187 first col mean 0.15235643088817596 all mean 0.11718744039535522
0.38036784529685974 0.38036784529685974
rl training, epoch1, iter0, batch8/1133, batch loss:0.38036784529685974, Training time:254.6732680797577
batch reward last col mean 0.11900756508111954 first col mean 0.14230044186115265 all mean 0.12756569683551788
0.47119519114494324 0.47119519114494324
rl training, epoch1, iter0, batch9/1133, batch loss:0.47119519114494324, Training time:257.7813847064972
batch reward last col mean 0.10603445768356323 first col mean 0.1309438943862915 all mean 0.11680690199136734
0.4520494043827057 0.4520494043827057
rl training, epoch1, iter0, batch10/1133, batch loss:0.4520494043827057, Training time:260.57345151901245
batch reward last col mean 0.12173666059970856 first col mean 0.13556978106498718 all mean 0.12396667897701263
0.425040602684021 0.425040602684021
rl training, epoch1, iter0, batch11/1133, batch loss:0.425040602684021, Training time:263.7143030166626
batch reward last col mean 0.13146767020225525 first col mean 0.1305760145187378 all mean 0.13177111744880676
0.4432108700275421 0.4432108700275421
rl training, epoch1, iter0, batch12/1133, batch loss:0.4432108700275421, Training time:266.9492464065552
batch reward last col mean 0.12626153230667114 first col mean 0.1582733392715454 all mean 0.12915554642677307
0.5009813904762268 0.5009813904762268
rl training, epoch1, iter0, batch13/1133, batch loss:0.5009813904762268, Training time:269.1490662097931
batch reward last col mean 0.1566280573606491 first col mean 0.15281958878040314 all mean 0.1584448665380478
0.5326236486434937 0.5326236486434937
rl training, epoch1, iter0, batch14/1133, batch loss:0.5326236486434937, Training time:271.44288635253906
batch reward last col mean 0.17092204093933105 first col mean 0.15717917680740356 all mean 0.16574563086032867
0.547964870929718 0.547964870929718
rl training, epoch1, iter0, batch15/1133, batch loss:0.547964870929718, Training time:274.903516292572
batch reward last col mean 0.14614009857177734 first col mean 0.15645645558834076 all mean 0.14327633380889893
0.479753702878952 0.479753702878952
rl training, epoch1, iter0, batch16/1133, batch loss:0.479753702878952, Training time:277.63473439216614
batch reward last col mean 0.1514083445072174 first col mean 0.14623293280601501 all mean 0.15310083329677582
0.4928809702396393 0.4928809404373169
rl training, epoch1, iter0, batch17/1133, batch loss:0.4928809404373169, Training time:280.46696400642395
batch reward last col mean 0.14596262574195862 first col mean 0.1346518099308014 all mean 0.13594329357147217
0.42928364872932434 0.42928364872932434
rl training, epoch1, iter0, batch18/1133, batch loss:0.42928364872932434, Training time:282.9640808105469
batch reward last col mean 0.16261060535907745 first col mean 0.14201773703098297 all mean 0.1531236469745636
0.4455956220626831 0.4455955922603607
rl training, epoch1, iter0, batch19/1133, batch loss:0.4455955922603607, Training time:284.94576144218445
batch reward last col mean 0.11389806866645813 first col mean 0.14569343626499176 all mean 0.12107368558645248
0.46415606141090393 0.46415606141090393
rl training, epoch1, iter0, batch20/1133, batch loss:0.46415606141090393, Training time:289.32946729660034
batch reward last col mean 0.1550092250108719 first col mean 0.15745113790035248 all mean 0.1485583335161209
0.468039870262146 0.468039870262146
rl training, epoch1, iter0, batch21/1133, batch loss:0.468039870262146, Training time:293.00944685935974
batch reward last col mean 0.133772611618042 first col mean 0.1507093757390976 all mean 0.140778049826622
0.5133882164955139 0.5133882164955139
rl training, epoch1, iter0, batch22/1133, batch loss:0.5133882164955139, Training time:295.5644721984863
batch reward last col mean 0.18162429332733154 first col mean 0.14292915165424347 all mean 0.1778886318206787
0.5260323882102966 0.5260323882102966
rl training, epoch1, iter0, batch23/1133, batch loss:0.5260323882102966, Training time:299.68854904174805
batch reward last col mean 0.13532039523124695 first col mean 0.16871517896652222 all mean 0.14147445559501648
0.4347383379936218 0.4347383379936218
rl training, epoch1, iter0, batch24/1133, batch loss:0.4347383379936218, Training time:302.3456451892853
batch reward last col mean 0.08587401360273361 first col mean 0.1530727595090866 all mean 0.10216518491506577
0.3920711874961853 0.3920711874961853
rl training, epoch1, iter0, batch25/1133, batch loss:0.3920711874961853, Training time:304.53461480140686
batch reward last col mean 0.18216240406036377 first col mean 0.1697033792734146 all mean 0.16919894516468048
0.5260991454124451 0.5260991454124451
rl training, epoch1, iter0, batch26/1133, batch loss:0.5260991454124451, Training time:306.6199572086334
batch reward last col mean 0.1564151644706726 first col mean 0.14211268723011017 all mean 0.15061314404010773
0.4690178334712982 0.4690178334712982
rl training, epoch1, iter0, batch27/1133, batch loss:0.4690178334712982, Training time:308.86958599090576
batch reward last col mean 0.1405443251132965 first col mean 0.1445581316947937 all mean 0.14486850798130035
0.49264466762542725 0.49264466762542725
rl training, epoch1, iter0, batch28/1133, batch loss:0.49264466762542725, Training time:311.6521158218384
batch reward last col mean 0.16101279854774475 first col mean 0.15041808784008026 all mean 0.15555134415626526
0.4786700904369354 0.4786700904369354
rl training, epoch1, iter0, batch29/1133, batch loss:0.4786700904369354, Training time:314.5021059513092
batch reward last col mean 0.1669943481683731 first col mean 0.14135956764221191 all mean 0.1610933244228363
0.5124683976173401 0.5124683976173401
rl training, epoch1, iter0, batch30/1133, batch loss:0.5124683976173401, Training time:317.38925886154175
batch reward last col mean 0.1533014178276062 first col mean 0.1486075222492218 all mean 0.1489637941122055
0.45141932368278503 0.45141932368278503
rl training, epoch1, iter0, batch31/1133, batch loss:0.45141932368278503, Training time:319.7082431316376
batch reward last col mean 0.13759982585906982 first col mean 0.15232208371162415 all mean 0.13792160153388977
0.5045599937438965 0.5045599937438965
rl training, epoch1, iter0, batch32/1133, batch loss:0.5045599937438965, Training time:322.1208915710449
batch reward last col mean 0.15135449171066284 first col mean 0.12624116241931915 all mean 0.14739082753658295
0.44207605719566345 0.4420759975910187
rl training, epoch1, iter0, batch33/1133, batch loss:0.4420759975910187, Training time:325.49197006225586
batch reward last col mean 0.129627525806427 first col mean 0.14012470841407776 all mean 0.13389046490192413
0.4550064206123352 0.4550064206123352
rl training, epoch1, iter0, batch34/1133, batch loss:0.4550064206123352, Training time:329.02081298828125
batch reward last col mean 0.12972880899906158 first col mean 0.16124829649925232 all mean 0.13375836610794067
0.4711945950984955 0.4711945950984955
rl training, epoch1, iter0, batch35/1133, batch loss:0.4711945950984955, Training time:331.2908344268799
batch reward last col mean 0.11716244369745255 first col mean 0.14480847120285034 all mean 0.1249915137887001
0.47044432163238525 0.47044432163238525
rl training, epoch1, iter0, batch36/1133, batch loss:0.47044432163238525, Training time:334.64737820625305
batch reward last col mean 0.15897443890571594 first col mean 0.14750105142593384 all mean 0.15396280586719513
0.5349043607711792 0.5349043607711792
rl training, epoch1, iter0, batch37/1133, batch loss:0.5349043607711792, Training time:337.3640534877777
batch reward last col mean 0.12556558847427368 first col mean 0.13089889287948608 all mean 0.12620002031326294
0.4404423236846924 0.44044229388237
rl training, epoch1, iter0, batch38/1133, batch loss:0.44044229388237, Training time:339.82022190093994
batch reward last col mean 0.10145263373851776 first col mean 0.13700957596302032 all mean 0.10880159586668015
0.42743661999702454 0.42743656039237976
rl training, epoch1, iter0, batch39/1133, batch loss:0.42743656039237976, Training time:342.9885182380676
batch reward last col mean 0.17464128136634827 first col mean 0.15064942836761475 all mean 0.1696470081806183
0.48884934186935425 0.48884934186935425
rl training, epoch1, iter0, batch40/1133, batch loss:0.48884934186935425, Training time:346.2445545196533
batch reward last col mean 0.14073045551776886 first col mean 0.16107694804668427 all mean 0.14479470252990723
0.5035997033119202 0.5035997033119202
rl training, epoch1, iter0, batch41/1133, batch loss:0.5035997033119202, Training time:349.14089465141296
batch reward last col mean 0.13793769478797913 first col mean 0.14251378178596497 all mean 0.13882122933864594
0.42634740471839905 0.42634740471839905
rl training, epoch1, iter0, batch42/1133, batch loss:0.42634740471839905, Training time:352.2915918827057
batch reward last col mean 0.11764335632324219 first col mean 0.12266214936971664 all mean 0.12190072983503342
0.41677168011665344 0.41677168011665344
rl training, epoch1, iter0, batch43/1133, batch loss:0.41677168011665344, Training time:354.7858591079712
batch reward last col mean 0.10234950482845306 first col mean 0.1729665994644165 all mean 0.12941975891590118
0.4800763428211212 0.4800763428211212
rl training, epoch1, iter0, batch44/1133, batch loss:0.4800763428211212, Training time:357.49419927597046
batch reward last col mean 0.10826525092124939 first col mean 0.13157011568546295 all mean 0.11639964580535889
0.44615405797958374 0.44615405797958374
rl training, epoch1, iter0, batch45/1133, batch loss:0.44615405797958374, Training time:361.69498586654663
batch reward last col mean 0.14382073283195496 first col mean 0.16298288106918335 all mean 0.14934688806533813
0.5123394131660461 0.5123394131660461
rl training, epoch1, iter0, batch46/1133, batch loss:0.5123394131660461, Training time:364.13022089004517
batch reward last col mean 0.1451813280582428 first col mean 0.15742480754852295 all mean 0.14766299724578857
0.4947759211063385 0.4947759211063385
rl training, epoch1, iter0, batch47/1133, batch loss:0.4947759211063385, Training time:366.63268780708313
batch reward last col mean 0.13326425850391388 first col mean 0.1441602110862732 all mean 0.1381155401468277
0.4722631871700287 0.4722632169723511
rl training, epoch1, iter0, batch48/1133, batch loss:0.4722632169723511, Training time:369.49994111061096
batch reward last col mean 0.09657296538352966 first col mean 0.12958842515945435 all mean 0.10887622833251953
0.40372660756111145 0.40372660756111145
rl training, epoch1, iter0, batch49/1133, batch loss:0.40372660756111145, Training time:371.7197482585907
batch reward last col mean 0.1658962368965149 first col mean 0.16889506578445435 all mean 0.1602097600698471
0.49891403317451477 0.49891403317451477
rl training, epoch1, iter0, batch50/1133, batch loss:0.49891403317451477, Training time:374.04642391204834
batch reward last col mean 0.14991329610347748 first col mean 0.1444038599729538 all mean 0.1521112322807312
0.46223437786102295 0.46223437786102295
rl training, epoch1, iter0, batch51/1133, batch loss:0.46223437786102295, Training time:376.2323200702667
batch reward last col mean 0.15460290014743805 first col mean 0.1373155415058136 all mean 0.15011067688465118
0.49835625290870667 0.49835625290870667
rl training, epoch1, iter0, batch52/1133, batch loss:0.49835625290870667, Training time:379.0649993419647
batch reward last col mean 0.1237972304224968 first col mean 0.13913831114768982 all mean 0.12689726054668427
0.4413391053676605 0.4413391053676605
rl training, epoch1, iter0, batch53/1133, batch loss:0.4413391053676605, Training time:382.06628227233887
batch reward last col mean 0.1375168263912201 first col mean 0.15255257487297058 all mean 0.1377280354499817
0.5292043089866638 0.5292043089866638
rl training, epoch1, iter0, batch54/1133, batch loss:0.5292043089866638, Training time:384.7267553806305
batch reward last col mean 0.11672336608171463 first col mean 0.14905939996242523 all mean 0.12568411231040955
0.4055918753147125 0.4055918753147125
rl training, epoch1, iter0, batch55/1133, batch loss:0.4055918753147125, Training time:386.9672107696533
batch reward last col mean 0.13113568723201752 first col mean 0.14966151118278503 all mean 0.13520927727222443
0.42317700386047363 0.42317700386047363
rl training, epoch1, iter0, batch56/1133, batch loss:0.42317700386047363, Training time:389.6765732765198
batch reward last col mean 0.11215482652187347 first col mean 0.16193515062332153 all mean 0.1201203390955925
0.4222020208835602 0.42220205068588257
rl training, epoch1, iter0, batch57/1133, batch loss:0.42220205068588257, Training time:392.26648116111755
batch reward last col mean 0.11542841792106628 first col mean 0.13601213693618774 all mean 0.1260872185230255
0.5255492925643921 0.5255492925643921
rl training, epoch1, iter0, batch58/1133, batch loss:0.5255492925643921, Training time:395.0002887248993
batch reward last col mean 0.15054310858249664 first col mean 0.15703722834587097 all mean 0.1448870450258255
0.4605686068534851 0.4605686068534851
rl training, epoch1, iter0, batch59/1133, batch loss:0.4605686068534851, Training time:398.471951007843
batch reward last col mean 0.11539342999458313 first col mean 0.1465049535036087 all mean 0.12608522176742554
0.46062761545181274 0.46062761545181274
rl training, epoch1, iter0, batch60/1133, batch loss:0.46062761545181274, Training time:401.02561354637146
batch reward last col mean 0.15335412323474884 first col mean 0.15364369750022888 all mean 0.15381772816181183
0.5439135432243347 0.5439135432243347
rl training, epoch1, iter0, batch61/1133, batch loss:0.5439135432243347, Training time:403.68145394325256
batch reward last col mean 0.10061310231685638 first col mean 0.14085377752780914 all mean 0.10623566806316376
0.4000207781791687 0.4000207781791687
rl training, epoch1, iter0, batch62/1133, batch loss:0.4000207781791687, Training time:406.3212254047394
batch reward last col mean 0.15002137422561646 first col mean 0.1470869779586792 all mean 0.14907142519950867
0.46418482065200806 0.46418482065200806
rl training, epoch1, iter0, batch63/1133, batch loss:0.46418482065200806, Training time:408.85107588768005
batch reward last col mean 0.12940125167369843 first col mean 0.12219172716140747 all mean 0.13703575730323792
0.45716801285743713 0.45716801285743713
rl training, epoch1, iter0, batch64/1133, batch loss:0.45716801285743713, Training time:410.87189173698425
batch reward last col mean 0.17225927114486694 first col mean 0.15364676713943481 all mean 0.16656044125556946
0.4841848611831665 0.4841848611831665
rl training, epoch1, iter0, batch65/1133, batch loss:0.4841848611831665, Training time:413.4884603023529
batch reward last col mean 0.15246520936489105 first col mean 0.14640450477600098 all mean 0.1480267345905304
0.4901878535747528 0.4901879131793976
rl training, epoch1, iter0, batch66/1133, batch loss:0.4901879131793976, Training time:416.2881968021393
batch reward last col mean 0.13866251707077026 first col mean 0.13139861822128296 all mean 0.14435802400112152
0.4837884306907654 0.4837884306907654
rl training, epoch1, iter0, batch67/1133, batch loss:0.4837884306907654, Training time:418.78749918937683
batch reward last col mean 0.16852955520153046 first col mean 0.14967340230941772 all mean 0.16838860511779785
0.5240978598594666 0.5240978598594666
rl training, epoch1, iter0, batch68/1133, batch loss:0.5240978598594666, Training time:421.51468992233276
batch reward last col mean 0.1687423288822174 first col mean 0.16490861773490906 all mean 0.16059380769729614
0.5651371479034424 0.5651371479034424
rl training, epoch1, iter0, batch69/1133, batch loss:0.5651371479034424, Training time:424.294885635376
batch reward last col mean 0.1517448127269745 first col mean 0.13566702604293823 all mean 0.1460963487625122
0.4329919219017029 0.4329918920993805
rl training, epoch1, iter0, batch70/1133, batch loss:0.4329918920993805, Training time:427.3730194568634
batch reward last col mean 0.17049187421798706 first col mean 0.13451872766017914 all mean 0.16517610847949982
0.5523852109909058 0.5523852109909058
rl training, epoch1, iter0, batch71/1133, batch loss:0.5523852109909058, Training time:429.7490656375885
batch reward last col mean 0.2028312087059021 first col mean 0.1551266610622406 all mean 0.1923813819885254
0.5245421528816223 0.5245420932769775
rl training, epoch1, iter0, batch72/1133, batch loss:0.5245420932769775, Training time:432.72006273269653
batch reward last col mean 0.12806527316570282 first col mean 0.14544028043746948 all mean 0.13099485635757446
0.46720781922340393 0.46720781922340393
rl training, epoch1, iter0, batch73/1133, batch loss:0.46720781922340393, Training time:435.49371886253357
batch reward last col mean 0.1556946337223053 first col mean 0.1604369580745697 all mean 0.15383301675319672
0.47172361612319946 0.47172367572784424
rl training, epoch1, iter0, batch74/1133, batch loss:0.47172367572784424, Training time:438.3178629875183
batch reward last col mean 0.16120752692222595 first col mean 0.14522257447242737 all mean 0.15567369759082794
0.49449387192726135 0.49449387192726135
rl training, epoch1, iter0, batch75/1133, batch loss:0.49449387192726135, Training time:440.7474830150604
batch reward last col mean 0.15021631121635437 first col mean 0.14107666909694672 all mean 0.14751441776752472
0.47518473863601685 0.47518473863601685
rl training, epoch1, iter0, batch76/1133, batch loss:0.47518473863601685, Training time:443.7627341747284
batch reward last col mean 0.14748744666576385 first col mean 0.14133918285369873 all mean 0.14801597595214844
0.47717052698135376 0.47717052698135376
rl training, epoch1, iter0, batch77/1133, batch loss:0.47717052698135376, Training time:445.92095136642456
batch reward last col mean 0.18616633117198944 first col mean 0.14627623558044434 all mean 0.17120960354804993
0.4942064583301544 0.4942064583301544
rl training, epoch1, iter0, batch78/1133, batch loss:0.4942064583301544, Training time:448.5533275604248
batch reward last col mean 0.15896522998809814 first col mean 0.1434137374162674 all mean 0.15258127450942993
0.4935493469238281 0.4935493767261505
rl training, epoch1, iter0, batch79/1133, batch loss:0.4935493767261505, Training time:451.41350841522217
batch reward last col mean 0.11322874575853348 first col mean 0.1460840106010437 all mean 0.1216786727309227
0.4177393913269043 0.4177393913269043
rl training, epoch1, iter0, batch80/1133, batch loss:0.4177393913269043, Training time:454.3778474330902
batch reward last col mean 0.12799786031246185 first col mean 0.14725467562675476 all mean 0.13447219133377075
0.4766215980052948 0.4766215980052948
rl training, epoch1, iter0, batch81/1133, batch loss:0.4766215980052948, Training time:456.83386421203613
batch reward last col mean 0.16466671228408813 first col mean 0.14746013283729553 all mean 0.1636473536491394
0.5280002355575562 0.5280002355575562
rl training, epoch1, iter0, batch82/1133, batch loss:0.5280002355575562, Training time:459.6647307872772
batch reward last col mean 0.14137974381446838 first col mean 0.14092351496219635 all mean 0.14042223989963531
0.45218008756637573 0.45218008756637573
rl training, epoch1, iter0, batch83/1133, batch loss:0.45218008756637573, Training time:462.28036165237427
batch reward last col mean 0.1462726593017578 first col mean 0.16189515590667725 all mean 0.15618017315864563
0.5109705924987793 0.5109706521034241
rl training, epoch1, iter0, batch84/1133, batch loss:0.5109706521034241, Training time:464.3081269264221
batch reward last col mean 0.1455199122428894 first col mean 0.13479188084602356 all mean 0.14416901767253876
0.4881754517555237 0.4881754219532013
rl training, epoch1, iter0, batch85/1133, batch loss:0.4881754219532013, Training time:466.50882029533386
batch reward last col mean 0.15211664140224457 first col mean 0.1720472276210785 all mean 0.15567530691623688
0.47490981221199036 0.47490981221199036
rl training, epoch1, iter0, batch86/1133, batch loss:0.47490981221199036, Training time:469.37069606781006
batch reward last col mean 0.11839719116687775 first col mean 0.1385374814271927 all mean 0.11915526539087296
0.384833961725235 0.384833961725235
rl training, epoch1, iter0, batch87/1133, batch loss:0.384833961725235, Training time:472.61586356163025
batch reward last col mean 0.12482604384422302 first col mean 0.16926154494285583 all mean 0.12838463485240936
0.47687748074531555 0.47687748074531555
rl training, epoch1, iter0, batch88/1133, batch loss:0.47687748074531555, Training time:474.6438386440277
batch reward last col mean 0.16049855947494507 first col mean 0.1639086902141571 all mean 0.1609441339969635
0.44611650705337524 0.44611650705337524
rl training, epoch1, iter0, batch89/1133, batch loss:0.44611650705337524, Training time:477.5573773384094
batch reward last col mean 0.12398706376552582 first col mean 0.14085407555103302 all mean 0.12574200332164764
0.4430111348628998 0.4430111348628998
rl training, epoch1, iter0, batch90/1133, batch loss:0.4430111348628998, Training time:480.74796295166016
batch reward last col mean 0.1661909967660904 first col mean 0.14509569108486176 all mean 0.16740496456623077
0.43391093611717224 0.43391093611717224
rl training, epoch1, iter0, batch91/1133, batch loss:0.43391093611717224, Training time:483.0997533798218
batch reward last col mean 0.16042330861091614 first col mean 0.12769797444343567 all mean 0.15769347548484802
0.5024805665016174 0.5024805068969727
rl training, epoch1, iter0, batch92/1133, batch loss:0.5024805068969727, Training time:486.24000573158264
batch reward last col mean 0.15347430109977722 first col mean 0.14016471803188324 all mean 0.15101589262485504
0.4711619019508362 0.4711619019508362
rl training, epoch1, iter0, batch93/1133, batch loss:0.4711619019508362, Training time:488.3439884185791
batch reward last col mean 0.13956642150878906 first col mean 0.16146986186504364 all mean 0.1422947496175766
0.47854629158973694 0.47854626178741455
rl training, epoch1, iter0, batch94/1133, batch loss:0.47854626178741455, Training time:490.8316354751587
batch reward last col mean 0.18532462418079376 first col mean 0.16228367388248444 all mean 0.17825499176979065
0.5085322856903076 0.5085322260856628
rl training, epoch1, iter0, batch95/1133, batch loss:0.5085322260856628, Training time:494.01777839660645
batch reward last col mean 0.17302708327770233 first col mean 0.1478227972984314 all mean 0.16686217486858368
0.4745389223098755 0.4745389223098755
rl training, epoch1, iter0, batch96/1133, batch loss:0.4745389223098755, Training time:497.37642216682434
batch reward last col mean 0.16386818885803223 first col mean 0.16162484884262085 all mean 0.16777852177619934
0.5235240459442139 0.5235240459442139
rl training, epoch1, iter0, batch97/1133, batch loss:0.5235240459442139, Training time:499.551310300827
batch reward last col mean 0.1275101751089096 first col mean 0.1504485011100769 all mean 0.12952838838100433
0.414935439825058 0.414935439825058
rl training, epoch1, iter0, batch98/1133, batch loss:0.414935439825058, Training time:502.7694101333618
batch reward last col mean 0.14215704798698425 first col mean 0.15278802812099457 all mean 0.1443767100572586
0.47292786836624146 0.47292786836624146
rl training, epoch1, iter0, batch99/1133, batch loss:0.47292786836624146, Training time:505.1967830657959
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6574669044468114 Time: 101.475506067276 s
loss of true 0.2998684260662109 loss of gen 0.22721830137988056 loss of other 0.13038017559346118 first score 0.13253048062324524
batch reward last col mean 0.12720482051372528 first col mean 0.1281304806470871 all mean 0.12953053414821625
0.40475183725357056 0.40475183725357056
rl training, epoch1, iter0, batch100/1133, batch loss:0.40475183725357056, Training time:608.9853746891022
batch reward last col mean 0.17356319725513458 first col mean 0.16736310720443726 all mean 0.17020411789417267
0.5070437788963318 0.5070437788963318
rl training, epoch1, iter0, batch101/1133, batch loss:0.5070437788963318, Training time:611.8838713169098
batch reward last col mean 0.14150695502758026 first col mean 0.14936310052871704 all mean 0.14562267065048218
0.47561362385749817 0.47561362385749817
rl training, epoch1, iter0, batch102/1133, batch loss:0.47561362385749817, Training time:614.1334435939789
batch reward last col mean 0.11643941700458527 first col mean 0.14888563752174377 all mean 0.13075228035449982
0.45517221093177795 0.45517221093177795
rl training, epoch1, iter0, batch103/1133, batch loss:0.45517221093177795, Training time:616.3462581634521
batch reward last col mean 0.15835392475128174 first col mean 0.1788119524717331 all mean 0.15710031986236572
0.508377194404602 0.508377194404602
rl training, epoch1, iter0, batch104/1133, batch loss:0.508377194404602, Training time:619.2543585300446
batch reward last col mean 0.13097357749938965 first col mean 0.135732963681221 all mean 0.1297551542520523
0.4929392635822296 0.4929392635822296
rl training, epoch1, iter0, batch105/1133, batch loss:0.4929392635822296, Training time:623.1731760501862
batch reward last col mean 0.15312214195728302 first col mean 0.14234532415866852 all mean 0.15308831632137299
0.45429155230522156 0.45429161190986633
rl training, epoch1, iter0, batch106/1133, batch loss:0.45429161190986633, Training time:625.0623817443848
batch reward last col mean 0.13190974295139313 first col mean 0.14274321496486664 all mean 0.13608241081237793
0.439687579870224 0.439687579870224
rl training, epoch1, iter0, batch107/1133, batch loss:0.439687579870224, Training time:627.9135947227478
batch reward last col mean 0.15001606941223145 first col mean 0.14176324009895325 all mean 0.14990495145320892
0.4435484707355499 0.4435484707355499
rl training, epoch1, iter0, batch108/1133, batch loss:0.4435484707355499, Training time:631.1690077781677
batch reward last col mean 0.13812431693077087 first col mean 0.14887575805187225 all mean 0.13967227935791016
0.4750862121582031 0.4750862121582031
rl training, epoch1, iter0, batch109/1133, batch loss:0.4750862121582031, Training time:634.1750633716583
batch reward last col mean 0.15294234454631805 first col mean 0.16081833839416504 all mean 0.1590549349784851
0.45581039786338806 0.45581039786338806
rl training, epoch1, iter0, batch110/1133, batch loss:0.45581039786338806, Training time:636.5366656780243
batch reward last col mean 0.15165799856185913 first col mean 0.1446027308702469 all mean 0.15243132412433624
0.4530782401561737 0.4530782103538513
rl training, epoch1, iter0, batch111/1133, batch loss:0.4530782103538513, Training time:639.0279312133789
batch reward last col mean 0.11641161888837814 first col mean 0.14376580715179443 all mean 0.12293072789907455
0.4112871289253235 0.4112871289253235
rl training, epoch1, iter0, batch112/1133, batch loss:0.4112871289253235, Training time:641.5408208370209
batch reward last col mean 0.16139961779117584 first col mean 0.1448909342288971 all mean 0.15983664989471436
0.5078598856925964 0.5078598856925964
rl training, epoch1, iter0, batch113/1133, batch loss:0.5078598856925964, Training time:644.5810654163361
batch reward last col mean 0.1765037178993225 first col mean 0.14140276610851288 all mean 0.16352227330207825
0.47933292388916016 0.47933289408683777
rl training, epoch1, iter0, batch114/1133, batch loss:0.47933289408683777, Training time:646.2857172489166
batch reward last col mean 0.16274546086788177 first col mean 0.14289501309394836 all mean 0.15515819191932678
0.48183414340019226 0.48183414340019226
rl training, epoch1, iter0, batch115/1133, batch loss:0.48183414340019226, Training time:649.0387451648712
batch reward last col mean 0.15106146037578583 first col mean 0.1350911557674408 all mean 0.1481628268957138
0.45897164940834045 0.45897161960601807
rl training, epoch1, iter0, batch116/1133, batch loss:0.45897161960601807, Training time:651.2090013027191
batch reward last col mean 0.16659507155418396 first col mean 0.1465960144996643 all mean 0.16243425011634827
0.5657541751861572 0.5657541751861572
rl training, epoch1, iter0, batch117/1133, batch loss:0.5657541751861572, Training time:653.5828912258148
batch reward last col mean 0.11590580642223358 first col mean 0.15195411443710327 all mean 0.12338602542877197
0.432003915309906 0.4320039451122284
rl training, epoch1, iter0, batch118/1133, batch loss:0.4320039451122284, Training time:656.6058869361877
batch reward last col mean 0.1372048705816269 first col mean 0.14734217524528503 all mean 0.14011071622371674
0.46093127131462097 0.46093127131462097
rl training, epoch1, iter0, batch119/1133, batch loss:0.46093127131462097, Training time:659.0229666233063
batch reward last col mean 0.11977119743824005 first col mean 0.1693895012140274 all mean 0.12678594887256622
0.4440356492996216 0.4440356492996216
rl training, epoch1, iter0, batch120/1133, batch loss:0.4440356492996216, Training time:661.3565707206726
batch reward last col mean 0.1038731038570404 first col mean 0.12599551677703857 all mean 0.11053505539894104
0.3796626627445221 0.3796626627445221
rl training, epoch1, iter0, batch121/1133, batch loss:0.3796626627445221, Training time:663.5150108337402
batch reward last col mean 0.14595462381839752 first col mean 0.1561337411403656 all mean 0.1446109265089035
0.460123747587204 0.460123747587204
rl training, epoch1, iter0, batch122/1133, batch loss:0.460123747587204, Training time:665.5761625766754
batch reward last col mean 0.12379974126815796 first col mean 0.13571062684059143 all mean 0.13365782797336578
0.46565157175064087 0.46565157175064087
rl training, epoch1, iter0, batch123/1133, batch loss:0.46565157175064087, Training time:667.8672959804535
batch reward last col mean 0.12201157212257385 first col mean 0.1323072761297226 all mean 0.12711480259895325
0.4016675055027008 0.4016675055027008
rl training, epoch1, iter0, batch124/1133, batch loss:0.4016675055027008, Training time:670.1839106082916
batch reward last col mean 0.13266323506832123 first col mean 0.1332423835992813 all mean 0.12765581905841827
0.40724456310272217 0.40724456310272217
rl training, epoch1, iter0, batch125/1133, batch loss:0.40724456310272217, Training time:673.0538380146027
batch reward last col mean 0.1344190388917923 first col mean 0.1318291574716568 all mean 0.14186708629131317
0.4897199869155884 0.4897199869155884
rl training, epoch1, iter0, batch126/1133, batch loss:0.4897199869155884, Training time:675.3964152336121
batch reward last col mean 0.15070419013500214 first col mean 0.1535976529121399 all mean 0.1521490067243576
0.44461771845817566 0.44461771845817566
rl training, epoch1, iter0, batch127/1133, batch loss:0.44461771845817566, Training time:679.1755366325378
batch reward last col mean 0.15947076678276062 first col mean 0.125069722533226 all mean 0.14935041964054108
0.4006343483924866 0.4006343483924866
rl training, epoch1, iter0, batch128/1133, batch loss:0.4006343483924866, Training time:681.6061081886292
batch reward last col mean 0.16546279191970825 first col mean 0.14295867085456848 all mean 0.15180620551109314
0.4568471312522888 0.4568471312522888
rl training, epoch1, iter0, batch129/1133, batch loss:0.4568471312522888, Training time:683.8225829601288
batch reward last col mean 0.13225188851356506 first col mean 0.15786898136138916 all mean 0.13394656777381897
0.42479321360588074 0.42479321360588074
rl training, epoch1, iter0, batch130/1133, batch loss:0.42479321360588074, Training time:686.3742563724518
batch reward last col mean 0.1397894322872162 first col mean 0.13204623758792877 all mean 0.14142119884490967
0.44600188732147217 0.44600188732147217
rl training, epoch1, iter0, batch131/1133, batch loss:0.44600188732147217, Training time:688.307293176651
batch reward last col mean 0.14623497426509857 first col mean 0.14738214015960693 all mean 0.14870785176753998
0.441446453332901 0.441446453332901
rl training, epoch1, iter0, batch132/1133, batch loss:0.441446453332901, Training time:690.3397853374481
batch reward last col mean 0.16062429547309875 first col mean 0.16342946887016296 all mean 0.1635705977678299
0.5083590149879456 0.5083590149879456
rl training, epoch1, iter0, batch133/1133, batch loss:0.5083590149879456, Training time:692.7632524967194
batch reward last col mean 0.1470600664615631 first col mean 0.14219491183757782 all mean 0.14332866668701172
0.4560718536376953 0.4560718536376953
rl training, epoch1, iter0, batch134/1133, batch loss:0.4560718536376953, Training time:694.8986749649048
batch reward last col mean 0.16236984729766846 first col mean 0.16658668220043182 all mean 0.1639183759689331
0.4619849920272827 0.4619849920272827
rl training, epoch1, iter0, batch135/1133, batch loss:0.4619849920272827, Training time:697.1466279029846
batch reward last col mean 0.15604262053966522 first col mean 0.16198983788490295 all mean 0.15066111087799072
0.4665544927120209 0.4665544927120209
rl training, epoch1, iter0, batch136/1133, batch loss:0.4665544927120209, Training time:699.3121931552887
batch reward last col mean 0.11663487553596497 first col mean 0.16167783737182617 all mean 0.12299885600805283
0.43952223658561707 0.43952223658561707
rl training, epoch1, iter0, batch137/1133, batch loss:0.43952223658561707, Training time:701.613130569458
batch reward last col mean 0.14055803418159485 first col mean 0.15289953351020813 all mean 0.14985664188861847
0.482230007648468 0.482230007648468
rl training, epoch1, iter0, batch138/1133, batch loss:0.482230007648468, Training time:703.5277118682861
batch reward last col mean 0.12133331596851349 first col mean 0.13821576535701752 all mean 0.1295236498117447
0.39760372042655945 0.39760372042655945
rl training, epoch1, iter0, batch139/1133, batch loss:0.39760372042655945, Training time:705.9977543354034
batch reward last col mean 0.12844318151474 first col mean 0.16381482779979706 all mean 0.13395090401172638
0.43713244795799255 0.43713244795799255
rl training, epoch1, iter0, batch140/1133, batch loss:0.43713244795799255, Training time:708.2164726257324
batch reward last col mean 0.12694784998893738 first col mean 0.14245520532131195 all mean 0.1297893226146698
0.3812696039676666 0.3812696039676666
rl training, epoch1, iter0, batch141/1133, batch loss:0.3812696039676666, Training time:710.005373954773
batch reward last col mean 0.14455804228782654 first col mean 0.13957640528678894 all mean 0.1488802433013916
0.4300942122936249 0.4300942122936249
rl training, epoch1, iter0, batch142/1133, batch loss:0.4300942122936249, Training time:711.735673904419
batch reward last col mean 0.10944829881191254 first col mean 0.13075286149978638 all mean 0.11792637407779694
0.43692269921302795 0.43692269921302795
rl training, epoch1, iter0, batch143/1133, batch loss:0.43692269921302795, Training time:713.6269960403442
batch reward last col mean 0.1436404287815094 first col mean 0.15626809000968933 all mean 0.14714530110359192
0.43822789192199707 0.43822789192199707
rl training, epoch1, iter0, batch144/1133, batch loss:0.43822789192199707, Training time:715.8458106517792
batch reward last col mean 0.1446780264377594 first col mean 0.169535294175148 all mean 0.14960965514183044
0.461257666349411 0.461257666349411
rl training, epoch1, iter0, batch145/1133, batch loss:0.461257666349411, Training time:717.8595962524414
batch reward last col mean 0.16943538188934326 first col mean 0.13034355640411377 all mean 0.1597452014684677
0.5184943675994873 0.5184943675994873
rl training, epoch1, iter0, batch146/1133, batch loss:0.5184943675994873, Training time:719.8791973590851
batch reward last col mean 0.12225092947483063 first col mean 0.15475431084632874 all mean 0.1313820332288742
0.4080950915813446 0.4080950915813446
rl training, epoch1, iter0, batch147/1133, batch loss:0.4080950915813446, Training time:722.0985097885132
batch reward last col mean 0.1452159881591797 first col mean 0.14782439172267914 all mean 0.14531832933425903
0.4619239568710327 0.4619239270687103
rl training, epoch1, iter0, batch148/1133, batch loss:0.4619239270687103, Training time:724.1124985218048
batch reward last col mean 0.11510880291461945 first col mean 0.1590435802936554 all mean 0.12070261687040329
0.3892601430416107 0.3892601430416107
rl training, epoch1, iter0, batch149/1133, batch loss:0.3892601430416107, Training time:726.679502248764
batch reward last col mean 0.13053551316261292 first col mean 0.1515411138534546 all mean 0.13517771661281586
0.48790428042411804 0.48790428042411804
rl training, epoch1, iter0, batch150/1133, batch loss:0.48790428042411804, Training time:729.7022407054901
batch reward last col mean 0.16852958500385284 first col mean 0.1607234627008438 all mean 0.16412323713302612
0.5569658279418945 0.5569657683372498
rl training, epoch1, iter0, batch151/1133, batch loss:0.5569657683372498, Training time:731.579879283905
batch reward last col mean 0.17275330424308777 first col mean 0.15570911765098572 all mean 0.16608068346977234
0.4653535783290863 0.4653535783290863
rl training, epoch1, iter0, batch152/1133, batch loss:0.4653535783290863, Training time:733.7985050678253
batch reward last col mean 0.133705735206604 first col mean 0.14353236556053162 all mean 0.13216693699359894
0.4279814064502716 0.4279814064502716
rl training, epoch1, iter0, batch153/1133, batch loss:0.4279814064502716, Training time:735.9946672916412
batch reward last col mean 0.1716603934764862 first col mean 0.16720321774482727 all mean 0.1683465987443924
0.48005688190460205 0.48005688190460205
rl training, epoch1, iter0, batch154/1133, batch loss:0.48005688190460205, Training time:738.3735897541046
batch reward last col mean 0.13405713438987732 first col mean 0.14229467511177063 all mean 0.1374513804912567
0.4821021854877472 0.4821021854877472
rl training, epoch1, iter0, batch155/1133, batch loss:0.4821021854877472, Training time:740.128576040268
batch reward last col mean 0.16788020730018616 first col mean 0.16113916039466858 all mean 0.1581006795167923
0.445749968290329 0.445749968290329
rl training, epoch1, iter0, batch156/1133, batch loss:0.445749968290329, Training time:742.3315467834473
batch reward last col mean 0.11385331302881241 first col mean 0.15894770622253418 all mean 0.12389861047267914
0.40288931131362915 0.40288931131362915
rl training, epoch1, iter0, batch157/1133, batch loss:0.40288931131362915, Training time:745.1083495616913
batch reward last col mean 0.13891726732254028 first col mean 0.13281725347042084 all mean 0.13695266842842102
0.4310007393360138 0.4310007691383362
rl training, epoch1, iter0, batch158/1133, batch loss:0.4310007691383362, Training time:747.4716985225677
batch reward last col mean 0.1653001606464386 first col mean 0.15156245231628418 all mean 0.15764416754245758
0.45587465167045593 0.45587465167045593
rl training, epoch1, iter0, batch159/1133, batch loss:0.45587465167045593, Training time:749.5190870761871
batch reward last col mean 0.1689961552619934 first col mean 0.1585748940706253 all mean 0.1673237830400467
0.4632802903652191 0.4632802903652191
rl training, epoch1, iter0, batch160/1133, batch loss:0.4632802903652191, Training time:752.9572412967682
batch reward last col mean 0.11990243941545486 first col mean 0.12346981465816498 all mean 0.12295892089605331
0.37498950958251953 0.37498950958251953
rl training, epoch1, iter0, batch161/1133, batch loss:0.37498950958251953, Training time:755.7558791637421
batch reward last col mean 0.15057162940502167 first col mean 0.14349518716335297 all mean 0.15560491383075714
0.49251657724380493 0.49251657724380493
rl training, epoch1, iter0, batch162/1133, batch loss:0.49251657724380493, Training time:757.8910927772522
batch reward last col mean 0.13829968869686127 first col mean 0.1571044921875 all mean 0.1472988873720169
0.4444772005081177 0.4444771707057953
rl training, epoch1, iter0, batch163/1133, batch loss:0.4444771707057953, Training time:760.1368088722229
batch reward last col mean 0.13665476441383362 first col mean 0.16108927130699158 all mean 0.1379045844078064
0.4439942240715027 0.4439942240715027
rl training, epoch1, iter0, batch164/1133, batch loss:0.4439942240715027, Training time:762.1565370559692
batch reward last col mean 0.1449929177761078 first col mean 0.16049611568450928 all mean 0.1417917013168335
0.44268953800201416 0.44268953800201416
rl training, epoch1, iter0, batch165/1133, batch loss:0.44268953800201416, Training time:764.1648306846619
batch reward last col mean 0.15944421291351318 first col mean 0.1612175852060318 all mean 0.15992626547813416
0.49615535140037537 0.49615538120269775
rl training, epoch1, iter0, batch166/1133, batch loss:0.49615538120269775, Training time:766.3203992843628
batch reward last col mean 0.16876481473445892 first col mean 0.16520756483078003 all mean 0.17201200127601624
0.5315256118774414 0.5315256118774414
rl training, epoch1, iter0, batch167/1133, batch loss:0.5315256118774414, Training time:768.3692514896393
batch reward last col mean 0.18532244861125946 first col mean 0.1607559621334076 all mean 0.1740528792142868
0.4897443652153015 0.4897443950176239
rl training, epoch1, iter0, batch168/1133, batch loss:0.4897443950176239, Training time:770.865963935852
batch reward last col mean 0.1161842942237854 first col mean 0.1552303433418274 all mean 0.12931035459041595
0.41367265582084656 0.41367265582084656
rl training, epoch1, iter0, batch169/1133, batch loss:0.41367265582084656, Training time:773.1502223014832
batch reward last col mean 0.15377488732337952 first col mean 0.16424116492271423 all mean 0.15967783331871033
0.5582581758499146 0.5582581758499146
rl training, epoch1, iter0, batch170/1133, batch loss:0.5582581758499146, Training time:775.2882282733917
batch reward last col mean 0.1490115523338318 first col mean 0.16269251704216003 all mean 0.14886020123958588
0.4587225317955017 0.4587225317955017
rl training, epoch1, iter0, batch171/1133, batch loss:0.4587225317955017, Training time:777.0186598300934
batch reward last col mean 0.16576574742794037 first col mean 0.15461252629756927 all mean 0.16331011056900024
0.47245338559150696 0.47245338559150696
rl training, epoch1, iter0, batch172/1133, batch loss:0.47245338559150696, Training time:779.4690048694611
batch reward last col mean 0.13890789449214935 first col mean 0.16583383083343506 all mean 0.1379397213459015
0.4200727045536041 0.4200727045536041
rl training, epoch1, iter0, batch173/1133, batch loss:0.4200727045536041, Training time:781.2034683227539
batch reward last col mean 0.15554384887218475 first col mean 0.14127333462238312 all mean 0.1571592092514038
0.4681631028652191 0.46816307306289673
rl training, epoch1, iter0, batch174/1133, batch loss:0.46816307306289673, Training time:783.564474105835
batch reward last col mean 0.13899929821491241 first col mean 0.13595938682556152 all mean 0.13584883511066437
0.37198537588119507 0.37198537588119507
rl training, epoch1, iter0, batch175/1133, batch loss:0.37198537588119507, Training time:785.3904092311859
batch reward last col mean 0.1725923717021942 first col mean 0.15624038875102997 all mean 0.16035433113574982
0.4690110683441162 0.4690110683441162
rl training, epoch1, iter0, batch176/1133, batch loss:0.4690110683441162, Training time:788.3842968940735
batch reward last col mean 0.15532073378562927 first col mean 0.18420523405075073 all mean 0.15259018540382385
0.4361637532711029 0.4361637532711029
rl training, epoch1, iter0, batch177/1133, batch loss:0.4361637532711029, Training time:790.4367294311523
batch reward last col mean 0.11282256245613098 first col mean 0.1451679915189743 all mean 0.1211533322930336
0.38965877890586853 0.38965877890586853
rl training, epoch1, iter0, batch178/1133, batch loss:0.38965877890586853, Training time:793.0062901973724
batch reward last col mean 0.1450367271900177 first col mean 0.15875256061553955 all mean 0.14794498682022095
0.45024633407592773 0.45024633407592773
rl training, epoch1, iter0, batch179/1133, batch loss:0.45024633407592773, Training time:795.3884468078613
batch reward last col mean 0.12535065412521362 first col mean 0.14802852272987366 all mean 0.12745018303394318
0.39438551664352417 0.39438554644584656
rl training, epoch1, iter0, batch180/1133, batch loss:0.39438554644584656, Training time:797.4101493358612
batch reward last col mean 0.15551094710826874 first col mean 0.14694355428218842 all mean 0.15130658447742462
0.41083720326423645 0.41083720326423645
rl training, epoch1, iter0, batch181/1133, batch loss:0.41083720326423645, Training time:799.645122051239
batch reward last col mean 0.13657701015472412 first col mean 0.1468450427055359 all mean 0.1391429603099823
0.4346630275249481 0.4346630275249481
rl training, epoch1, iter0, batch182/1133, batch loss:0.4346630275249481, Training time:801.7150363922119
batch reward last col mean 0.16185717284679413 first col mean 0.14957304298877716 all mean 0.16657912731170654
0.5168468952178955 0.5168468952178955
rl training, epoch1, iter0, batch183/1133, batch loss:0.5168468952178955, Training time:803.8024663925171
batch reward last col mean 0.16371171176433563 first col mean 0.1566518098115921 all mean 0.16336968541145325
0.4584713876247406 0.4584713876247406
rl training, epoch1, iter0, batch184/1133, batch loss:0.4584713876247406, Training time:805.9000775814056
batch reward last col mean 0.12907004356384277 first col mean 0.15168790519237518 all mean 0.1360229253768921
0.44375020265579224 0.44375020265579224
rl training, epoch1, iter0, batch185/1133, batch loss:0.44375020265579224, Training time:807.8489484786987
batch reward last col mean 0.10713498294353485 first col mean 0.14793068170547485 all mean 0.11473318934440613
0.4174172878265381 0.4174172878265381
rl training, epoch1, iter0, batch186/1133, batch loss:0.4174172878265381, Training time:810.2851779460907
batch reward last col mean 0.1440424770116806 first col mean 0.15620777010917664 all mean 0.15034154057502747
0.47691038250923157 0.47691038250923157
rl training, epoch1, iter0, batch187/1133, batch loss:0.47691038250923157, Training time:813.2690093517303
batch reward last col mean 0.20772336423397064 first col mean 0.15461327135562897 all mean 0.19240033626556396
0.5197285413742065 0.5197285413742065
rl training, epoch1, iter0, batch188/1133, batch loss:0.5197285413742065, Training time:815.3839194774628
batch reward last col mean 0.13392521440982819 first col mean 0.15806886553764343 all mean 0.13709111511707306
0.4295647442340851 0.4295647442340851
rl training, epoch1, iter0, batch189/1133, batch loss:0.4295647442340851, Training time:817.7482931613922
batch reward last col mean 0.18807931244373322 first col mean 0.1586003452539444 all mean 0.17894697189331055
0.48960286378860474 0.48960286378860474
rl training, epoch1, iter0, batch190/1133, batch loss:0.48960286378860474, Training time:820.4061906337738
batch reward last col mean 0.14601880311965942 first col mean 0.1511981189250946 all mean 0.1502259224653244
0.5319041013717651 0.5319039821624756
rl training, epoch1, iter0, batch191/1133, batch loss:0.5319039821624756, Training time:823.1475071907043
batch reward last col mean 0.14403963088989258 first col mean 0.1796739399433136 all mean 0.15488384664058685
0.4690294861793518 0.4690294861793518
rl training, epoch1, iter0, batch192/1133, batch loss:0.4690294861793518, Training time:825.6275250911713
batch reward last col mean 0.14771249890327454 first col mean 0.158140629529953 all mean 0.1450314223766327
0.459369033575058 0.459369033575058
rl training, epoch1, iter0, batch193/1133, batch loss:0.459369033575058, Training time:828.2042665481567
batch reward last col mean 0.1359844207763672 first col mean 0.1427323818206787 all mean 0.14113575220108032
0.449481338262558 0.4494813084602356
rl training, epoch1, iter0, batch194/1133, batch loss:0.4494813084602356, Training time:830.2898874282837
batch reward last col mean 0.15863347053527832 first col mean 0.1466030776500702 all mean 0.14902879297733307
0.43712133169174194 0.43712133169174194
rl training, epoch1, iter0, batch195/1133, batch loss:0.43712133169174194, Training time:832.406580209732
batch reward last col mean 0.15555959939956665 first col mean 0.15794415771961212 all mean 0.15776686370372772
0.48991259932518005 0.48991256952285767
rl training, epoch1, iter0, batch196/1133, batch loss:0.48991256952285767, Training time:834.1662518978119
batch reward last col mean 0.14733277261257172 first col mean 0.15638136863708496 all mean 0.15185078978538513
0.46507373452186584 0.46507370471954346
rl training, epoch1, iter0, batch197/1133, batch loss:0.46507370471954346, Training time:836.3051476478577
batch reward last col mean 0.15334048867225647 first col mean 0.15625926852226257 all mean 0.15510301291942596
0.47788605093955994 0.4778861105442047
rl training, epoch1, iter0, batch198/1133, batch loss:0.4778861105442047, Training time:838.3484556674957
batch reward last col mean 0.11971469968557358 first col mean 0.15612921118736267 all mean 0.1274760514497757
0.43398362398147583 0.43398362398147583
rl training, epoch1, iter0, batch199/1133, batch loss:0.43398362398147583, Training time:840.7473225593567
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.650375649661799 Time: 99.3644015789032 s
loss of true 0.29761907742387517 loss of gen 0.22218849753923156 loss of other 0.13056807587250396 first score 0.13867361843585968
batch reward last col mean 0.12650273740291595 first col mean 0.14404511451721191 all mean 0.13022693991661072
0.42810142040252686 0.42810142040252686
rl training, epoch1, iter0, batch200/1133, batch loss:0.42810142040252686, Training time:942.1303272247314
batch reward last col mean 0.11653915047645569 first col mean 0.12252228707075119 all mean 0.11803940683603287
0.3807240128517151 0.3807240128517151
rl training, epoch1, iter0, batch201/1133, batch loss:0.3807240128517151, Training time:944.4609401226044
batch reward last col mean 0.1296694576740265 first col mean 0.1424994170665741 all mean 0.13233590126037598
0.4209348261356354 0.420934796333313
rl training, epoch1, iter0, batch202/1133, batch loss:0.420934796333313, Training time:947.3162355422974
batch reward last col mean 0.10923820734024048 first col mean 0.12221276760101318 all mean 0.1150832548737526
0.37342727184295654 0.37342727184295654
rl training, epoch1, iter0, batch203/1133, batch loss:0.37342727184295654, Training time:949.7663359642029
batch reward last col mean 0.14812910556793213 first col mean 0.1240125447511673 all mean 0.14393411576747894
0.42730849981307983 0.42730849981307983
rl training, epoch1, iter0, batch204/1133, batch loss:0.42730849981307983, Training time:951.9269938468933
batch reward last col mean 0.1318727731704712 first col mean 0.11066068708896637 all mean 0.13109207153320312
0.42061737179756165 0.42061737179756165
rl training, epoch1, iter0, batch205/1133, batch loss:0.42061737179756165, Training time:954.7702894210815
batch reward last col mean 0.10599623620510101 first col mean 0.1119127944111824 all mean 0.10758376866579056
0.35524168610572815 0.35524168610572815
rl training, epoch1, iter0, batch206/1133, batch loss:0.35524168610572815, Training time:956.7144496440887
batch reward last col mean 0.14280810952186584 first col mean 0.12393023818731308 all mean 0.13818585872650146
0.44929584860801697 0.44929584860801697
rl training, epoch1, iter0, batch207/1133, batch loss:0.44929584860801697, Training time:958.9214217662811
batch reward last col mean 0.09213832020759583 first col mean 0.12042908370494843 all mean 0.09533125162124634
0.3602546751499176 0.3602546453475952
rl training, epoch1, iter0, batch208/1133, batch loss:0.3602546453475952, Training time:960.74347448349
batch reward last col mean 0.12679360806941986 first col mean 0.10664335638284683 all mean 0.12422380596399307
0.43000224232673645 0.43000224232673645
rl training, epoch1, iter0, batch209/1133, batch loss:0.43000224232673645, Training time:963.7000823020935
batch reward last col mean 0.13941529393196106 first col mean 0.12559789419174194 all mean 0.13313311338424683
0.39385440945625305 0.39385440945625305
rl training, epoch1, iter0, batch210/1133, batch loss:0.39385440945625305, Training time:966.5784785747528
batch reward last col mean 0.13954809308052063 first col mean 0.1280982494354248 all mean 0.12820829451084137
0.3524075150489807 0.3524075150489807
rl training, epoch1, iter0, batch211/1133, batch loss:0.3524075150489807, Training time:968.8714323043823
batch reward last col mean 0.1002066433429718 first col mean 0.1250394880771637 all mean 0.11177463084459305
0.3937112092971802 0.3937112092971802
rl training, epoch1, iter0, batch212/1133, batch loss:0.3937112092971802, Training time:971.0680794715881
batch reward last col mean 0.13565179705619812 first col mean 0.1254241168498993 all mean 0.1329551637172699
0.43069732189178467 0.43069732189178467
rl training, epoch1, iter0, batch213/1133, batch loss:0.43069732189178467, Training time:973.1994197368622
batch reward last col mean 0.08963731676340103 first col mean 0.10840044915676117 all mean 0.09599819779396057
0.3646915853023529 0.3646915853023529
rl training, epoch1, iter0, batch214/1133, batch loss:0.3646915853023529, Training time:975.250227689743
batch reward last col mean 0.1261914074420929 first col mean 0.14336027204990387 all mean 0.13495078682899475
0.3995828926563263 0.39958295226097107
rl training, epoch1, iter0, batch215/1133, batch loss:0.39958295226097107, Training time:977.0655148029327
batch reward last col mean 0.09880092740058899 first col mean 0.13775275647640228 all mean 0.1045982837677002
0.38940319418907166 0.38940319418907166
rl training, epoch1, iter0, batch216/1133, batch loss:0.38940319418907166, Training time:979.7159535884857
batch reward last col mean 0.09423350542783737 first col mean 0.13644255697727203 all mean 0.10136217623949051
0.3441635072231293 0.3441635072231293
rl training, epoch1, iter0, batch217/1133, batch loss:0.3441635072231293, Training time:982.1537938117981
batch reward last col mean 0.12507948279380798 first col mean 0.12969064712524414 all mean 0.12069173157215118
0.40384259819984436 0.40384259819984436
rl training, epoch1, iter0, batch218/1133, batch loss:0.40384259819984436, Training time:984.2294769287109
batch reward last col mean 0.10317828506231308 first col mean 0.11254903674125671 all mean 0.10435957461595535
0.3428787887096405 0.3428787887096405
rl training, epoch1, iter0, batch219/1133, batch loss:0.3428787887096405, Training time:986.5793309211731
batch reward last col mean 0.09965694695711136 first col mean 0.10678804665803909 all mean 0.10807698220014572
0.3842656910419464 0.3842656910419464
rl training, epoch1, iter0, batch220/1133, batch loss:0.3842656910419464, Training time:988.8788623809814
batch reward last col mean 0.1223006471991539 first col mean 0.1276124268770218 all mean 0.12712165713310242
0.42626985907554626 0.42626985907554626
rl training, epoch1, iter0, batch221/1133, batch loss:0.42626985907554626, Training time:991.0486738681793
batch reward last col mean 0.15320135653018951 first col mean 0.1329306960105896 all mean 0.14934204518795013
0.48925480246543884 0.48925480246543884
rl training, epoch1, iter0, batch222/1133, batch loss:0.48925480246543884, Training time:993.6415688991547
batch reward last col mean 0.13259722292423248 first col mean 0.13635750114917755 all mean 0.12937921285629272
0.38465774059295654 0.38465774059295654
rl training, epoch1, iter0, batch223/1133, batch loss:0.38465774059295654, Training time:996.451910495758
batch reward last col mean 0.14022590219974518 first col mean 0.12992757558822632 all mean 0.1307641714811325
0.3899863064289093 0.3899863064289093
rl training, epoch1, iter0, batch224/1133, batch loss:0.3899863064289093, Training time:998.7285289764404
batch reward last col mean 0.10308577120304108 first col mean 0.13782615959644318 all mean 0.10801377892494202
0.4213545620441437 0.4213545620441437
rl training, epoch1, iter0, batch225/1133, batch loss:0.4213545620441437, Training time:1000.8862512111664
batch reward last col mean 0.11705727875232697 first col mean 0.12750473618507385 all mean 0.12379459291696548
0.4056239128112793 0.4056239128112793
rl training, epoch1, iter0, batch226/1133, batch loss:0.4056239128112793, Training time:1002.8393499851227
batch reward last col mean 0.13248975574970245 first col mean 0.11915050446987152 all mean 0.13463850319385529
0.42045915126800537 0.42045915126800537
rl training, epoch1, iter0, batch227/1133, batch loss:0.42045915126800537, Training time:1005.0501592159271
batch reward last col mean 0.15910562872886658 first col mean 0.16639383137226105 all mean 0.15464060008525848
0.4803425371646881 0.4803425371646881
rl training, epoch1, iter0, batch228/1133, batch loss:0.4803425371646881, Training time:1006.764173746109
batch reward last col mean 0.11460666358470917 first col mean 0.1387237012386322 all mean 0.12092170119285583
0.3969684839248657 0.3969684839248657
rl training, epoch1, iter0, batch229/1133, batch loss:0.3969684839248657, Training time:1008.9327404499054
batch reward last col mean 0.12197990715503693 first col mean 0.11613143980503082 all mean 0.12704753875732422
0.400081992149353 0.400081992149353
rl training, epoch1, iter0, batch230/1133, batch loss:0.400081992149353, Training time:1010.8358314037323
batch reward last col mean 0.1327642947435379 first col mean 0.12416701018810272 all mean 0.13162192702293396
0.38513004779815674 0.38513001799583435
rl training, epoch1, iter0, batch231/1133, batch loss:0.38513001799583435, Training time:1013.0182166099548
batch reward last col mean 0.10840928554534912 first col mean 0.14113691449165344 all mean 0.11488128453493118
0.39577555656433105 0.39577552676200867
rl training, epoch1, iter0, batch232/1133, batch loss:0.39577552676200867, Training time:1015.6770513057709
batch reward last col mean 0.13255858421325684 first col mean 0.12036479264497757 all mean 0.13446149230003357
0.42406412959098816 0.42406412959098816
rl training, epoch1, iter0, batch233/1133, batch loss:0.42406412959098816, Training time:1017.564108133316
batch reward last col mean 0.12481889873743057 first col mean 0.13591542840003967 all mean 0.13046292960643768
0.41484472155570984 0.41484472155570984
rl training, epoch1, iter0, batch234/1133, batch loss:0.41484472155570984, Training time:1020.106388092041
batch reward last col mean 0.11821803450584412 first col mean 0.11780944466590881 all mean 0.11484459042549133
0.4223592281341553 0.4223592281341553
rl training, epoch1, iter0, batch235/1133, batch loss:0.4223592281341553, Training time:1022.6705729961395
batch reward last col mean 0.14503996074199677 first col mean 0.13121215999126434 all mean 0.13735279440879822
0.4154549837112427 0.4154549837112427
rl training, epoch1, iter0, batch236/1133, batch loss:0.4154549837112427, Training time:1024.4966950416565
batch reward last col mean 0.14364835619926453 first col mean 0.13392162322998047 all mean 0.1385798305273056
0.42998450994491577 0.42998450994491577
rl training, epoch1, iter0, batch237/1133, batch loss:0.42998450994491577, Training time:1026.6623487472534
batch reward last col mean 0.12831081449985504 first col mean 0.14102782309055328 all mean 0.12848299741744995
0.42214733362197876 0.42214733362197876
rl training, epoch1, iter0, batch238/1133, batch loss:0.42214733362197876, Training time:1029.6891503334045
batch reward last col mean 0.13312020897865295 first col mean 0.1227497011423111 all mean 0.13800986111164093
0.44307589530944824 0.44307583570480347
rl training, epoch1, iter0, batch239/1133, batch loss:0.44307583570480347, Training time:1032.1511979103088
batch reward last col mean 0.09906896948814392 first col mean 0.11897753924131393 all mean 0.10720178484916687
0.34404051303863525 0.34404051303863525
rl training, epoch1, iter0, batch240/1133, batch loss:0.34404051303863525, Training time:1034.3991303443909
batch reward last col mean 0.14728954434394836 first col mean 0.11697607487440109 all mean 0.14398795366287231
0.41334500908851624 0.41334500908851624
rl training, epoch1, iter0, batch241/1133, batch loss:0.41334500908851624, Training time:1036.5350835323334
batch reward last col mean 0.15507477521896362 first col mean 0.14234188199043274 all mean 0.1483915150165558
0.4402094781398773 0.4402094781398773
rl training, epoch1, iter0, batch242/1133, batch loss:0.4402094781398773, Training time:1038.6639137268066
batch reward last col mean 0.12238766252994537 first col mean 0.1292787343263626 all mean 0.12586139142513275
0.37698912620544434 0.37698912620544434
rl training, epoch1, iter0, batch243/1133, batch loss:0.37698912620544434, Training time:1040.6032872200012
batch reward last col mean 0.10681505501270294 first col mean 0.13263270258903503 all mean 0.11330493539571762
0.3885183334350586 0.3885183334350586
rl training, epoch1, iter0, batch244/1133, batch loss:0.3885183334350586, Training time:1042.1297109127045
batch reward last col mean 0.13089041411876678 first col mean 0.1217869371175766 all mean 0.1321686953306198
0.4227856397628784 0.42278560996055603
rl training, epoch1, iter0, batch245/1133, batch loss:0.42278560996055603, Training time:1044.1280221939087
batch reward last col mean 0.12707486748695374 first col mean 0.13076210021972656 all mean 0.1259307712316513
0.39541059732437134 0.39541059732437134
rl training, epoch1, iter0, batch246/1133, batch loss:0.39541059732437134, Training time:1046.9245505332947
batch reward last col mean 0.11487074196338654 first col mean 0.1314348578453064 all mean 0.12717077136039734
0.4276854693889618 0.4276854693889618
rl training, epoch1, iter0, batch247/1133, batch loss:0.4276854693889618, Training time:1048.9594597816467
batch reward last col mean 0.11636868119239807 first col mean 0.14263136684894562 all mean 0.12616071105003357
0.4108375310897827 0.4108375310897827
rl training, epoch1, iter0, batch248/1133, batch loss:0.4108375310897827, Training time:1050.741937160492
batch reward last col mean 0.10352456569671631 first col mean 0.14816761016845703 all mean 0.11494036018848419
0.424450546503067 0.424450546503067
rl training, epoch1, iter0, batch249/1133, batch loss:0.424450546503067, Training time:1052.7487077713013
batch reward last col mean 0.13945512473583221 first col mean 0.12663279473781586 all mean 0.13994865119457245
0.4385036528110504 0.4385036528110504
rl training, epoch1, iter0, batch250/1133, batch loss:0.4385036528110504, Training time:1054.8153457641602
batch reward last col mean 0.1119966134428978 first col mean 0.11473923176527023 all mean 0.1138877347111702
0.37016561627388 0.37016561627388
rl training, epoch1, iter0, batch251/1133, batch loss:0.37016561627388, Training time:1056.9882407188416
batch reward last col mean 0.12096378207206726 first col mean 0.11436176300048828 all mean 0.12095505744218826
0.42936164140701294 0.42936164140701294
rl training, epoch1, iter0, batch252/1133, batch loss:0.42936164140701294, Training time:1059.3145096302032
batch reward last col mean 0.09211666136980057 first col mean 0.1463274508714676 all mean 0.10457686334848404
0.4044360816478729 0.4044360816478729
rl training, epoch1, iter0, batch253/1133, batch loss:0.4044360816478729, Training time:1061.2770354747772
batch reward last col mean 0.13306370377540588 first col mean 0.11775006353855133 all mean 0.1345987617969513
0.3885124921798706 0.3885124623775482
rl training, epoch1, iter0, batch254/1133, batch loss:0.3885124623775482, Training time:1063.1552374362946
batch reward last col mean 0.1440707892179489 first col mean 0.13787411153316498 all mean 0.14356882870197296
0.4069613814353943 0.4069613814353943
rl training, epoch1, iter0, batch255/1133, batch loss:0.4069613814353943, Training time:1065.673807144165
batch reward last col mean 0.09382636845111847 first col mean 0.12777239084243774 all mean 0.10666925460100174
0.3834485411643982 0.3834485113620758
rl training, epoch1, iter0, batch256/1133, batch loss:0.3834485113620758, Training time:1068.7890541553497
batch reward last col mean 0.10818934440612793 first col mean 0.13721516728401184 all mean 0.11229854822158813
0.3932723104953766 0.3932723104953766
rl training, epoch1, iter0, batch257/1133, batch loss:0.3932723104953766, Training time:1071.8284003734589
batch reward last col mean 0.12324731051921844 first col mean 0.1524968147277832 all mean 0.13328304886817932
0.5409969091415405 0.5409969091415405
rl training, epoch1, iter0, batch258/1133, batch loss:0.5409969091415405, Training time:1073.6026122570038
batch reward last col mean 0.12246081233024597 first col mean 0.15717186033725739 all mean 0.12224402278661728
0.4316500425338745 0.4316500425338745
rl training, epoch1, iter0, batch259/1133, batch loss:0.4316500425338745, Training time:1075.8786690235138
batch reward last col mean 0.14896699786186218 first col mean 0.15137715637683868 all mean 0.14370833337306976
0.46477028727531433 0.46477028727531433
rl training, epoch1, iter0, batch260/1133, batch loss:0.46477028727531433, Training time:1077.7954235076904
batch reward last col mean 0.11612401157617569 first col mean 0.15680140256881714 all mean 0.12119706720113754
0.4122099280357361 0.4122099280357361
rl training, epoch1, iter0, batch261/1133, batch loss:0.4122099280357361, Training time:1079.6364316940308
batch reward last col mean 0.14577730000019073 first col mean 0.12505193054676056 all mean 0.14271560311317444
0.4266176223754883 0.4266176223754883
rl training, epoch1, iter0, batch262/1133, batch loss:0.4266176223754883, Training time:1083.255509853363
batch reward last col mean 0.12972526252269745 first col mean 0.14395703375339508 all mean 0.12719391286373138
0.4302394688129425 0.4302394688129425
rl training, epoch1, iter0, batch263/1133, batch loss:0.4302394688129425, Training time:1086.2530169487
batch reward last col mean 0.13714659214019775 first col mean 0.13821515440940857 all mean 0.13618618249893188
0.4116213023662567 0.4116213023662567
rl training, epoch1, iter0, batch264/1133, batch loss:0.4116213023662567, Training time:1088.2981340885162
batch reward last col mean 0.1382850557565689 first col mean 0.14770105481147766 all mean 0.13498786091804504
0.43569380044937134 0.43569380044937134
rl training, epoch1, iter0, batch265/1133, batch loss:0.43569380044937134, Training time:1090.3039181232452
batch reward last col mean 0.09691502153873444 first col mean 0.1421925276517868 all mean 0.10696936398744583
0.39710092544555664 0.39710092544555664
rl training, epoch1, iter0, batch266/1133, batch loss:0.39710092544555664, Training time:1092.0874316692352
batch reward last col mean 0.15066887438297272 first col mean 0.14589723944664001 all mean 0.1467115581035614
0.46246397495269775 0.46246397495269775
rl training, epoch1, iter0, batch267/1133, batch loss:0.46246397495269775, Training time:1093.7710094451904
batch reward last col mean 0.13621968030929565 first col mean 0.13298945128917694 all mean 0.13537760078907013
0.3856513500213623 0.3856513500213623
rl training, epoch1, iter0, batch268/1133, batch loss:0.3856513500213623, Training time:1096.0202736854553
batch reward last col mean 0.18148642778396606 first col mean 0.13521964848041534 all mean 0.1636732667684555
0.4224986135959625 0.4224986135959625
rl training, epoch1, iter0, batch269/1133, batch loss:0.4224986135959625, Training time:1097.9924054145813
batch reward last col mean 0.12202896177768707 first col mean 0.1520281732082367 all mean 0.1282716691493988
0.4123547077178955 0.4123547077178955
rl training, epoch1, iter0, batch270/1133, batch loss:0.4123547077178955, Training time:1101.1411621570587
batch reward last col mean 0.14427141845226288 first col mean 0.12738259136676788 all mean 0.1378573477268219
0.4280169606208801 0.42801690101623535
rl training, epoch1, iter0, batch271/1133, batch loss:0.42801690101623535, Training time:1103.3257851600647
batch reward last col mean 0.10623437911272049 first col mean 0.12970465421676636 all mean 0.11158838868141174
0.39781829714775085 0.39781829714775085
rl training, epoch1, iter0, batch272/1133, batch loss:0.39781829714775085, Training time:1105.8569509983063
batch reward last col mean 0.12076927721500397 first col mean 0.12246503680944443 all mean 0.12333051860332489
0.390876442193985 0.390876442193985
rl training, epoch1, iter0, batch273/1133, batch loss:0.390876442193985, Training time:1108.7155604362488
batch reward last col mean 0.11990971863269806 first col mean 0.13397233188152313 all mean 0.11911654472351074
0.3909843862056732 0.3909843862056732
rl training, epoch1, iter0, batch274/1133, batch loss:0.3909843862056732, Training time:1111.1042625904083
batch reward last col mean 0.16518567502498627 first col mean 0.15070293843746185 all mean 0.16159509122371674
0.4897030293941498 0.4897029995918274
rl training, epoch1, iter0, batch275/1133, batch loss:0.4897029995918274, Training time:1112.936398267746
batch reward last col mean 0.14104723930358887 first col mean 0.13434956967830658 all mean 0.1374211311340332
0.4287024736404419 0.42870253324508667
rl training, epoch1, iter0, batch276/1133, batch loss:0.42870253324508667, Training time:1116.1005795001984
batch reward last col mean 0.1123577207326889 first col mean 0.12383048236370087 all mean 0.10928475111722946
0.37585514783859253 0.37585511803627014
rl training, epoch1, iter0, batch277/1133, batch loss:0.37585511803627014, Training time:1119.7169454097748
batch reward last col mean 0.09947151690721512 first col mean 0.1310053914785385 all mean 0.11170446127653122
0.40438970923423767 0.40438970923423767
rl training, epoch1, iter0, batch278/1133, batch loss:0.40438970923423767, Training time:1122.071052789688
batch reward last col mean 0.10905088484287262 first col mean 0.13733820617198944 all mean 0.11317777633666992
0.3578222990036011 0.3578222990036011
rl training, epoch1, iter0, batch279/1133, batch loss:0.3578222990036011, Training time:1124.737048625946
batch reward last col mean 0.14809849858283997 first col mean 0.14712220430374146 all mean 0.14080722630023956
0.45137661695480347 0.45137661695480347
rl training, epoch1, iter0, batch280/1133, batch loss:0.45137661695480347, Training time:1126.9838037490845
batch reward last col mean 0.12771821022033691 first col mean 0.13578596711158752 all mean 0.12925592064857483
0.44089293479919434 0.44089293479919434
rl training, epoch1, iter0, batch281/1133, batch loss:0.44089293479919434, Training time:1129.5031430721283
batch reward last col mean 0.1294807344675064 first col mean 0.12589523196220398 all mean 0.12974347174167633
0.4604431986808777 0.4604431986808777
rl training, epoch1, iter0, batch282/1133, batch loss:0.4604431986808777, Training time:1131.7562704086304
batch reward last col mean 0.12054568529129028 first col mean 0.13452018797397614 all mean 0.12557433545589447
0.44905805587768555 0.44905805587768555
rl training, epoch1, iter0, batch283/1133, batch loss:0.44905805587768555, Training time:1134.3743460178375
batch reward last col mean 0.11472770571708679 first col mean 0.1337605118751526 all mean 0.12349116802215576
0.41476789116859436 0.41476789116859436
rl training, epoch1, iter0, batch284/1133, batch loss:0.41476789116859436, Training time:1136.58398771286
batch reward last col mean 0.1494075357913971 first col mean 0.12432785332202911 all mean 0.15264488756656647
0.4361152946949005 0.4361152946949005
rl training, epoch1, iter0, batch285/1133, batch loss:0.4361152946949005, Training time:1138.992442369461
batch reward last col mean 0.10420998930931091 first col mean 0.1321798413991928 all mean 0.11826030164957047
0.40835240483283997 0.40835240483283997
rl training, epoch1, iter0, batch286/1133, batch loss:0.40835240483283997, Training time:1141.1673810482025
batch reward last col mean 0.11643853038549423 first col mean 0.15775710344314575 all mean 0.12136650830507278
0.4103757441043854 0.4103757441043854
rl training, epoch1, iter0, batch287/1133, batch loss:0.4103757441043854, Training time:1143.0225863456726
batch reward last col mean 0.12733229994773865 first col mean 0.14152398705482483 all mean 0.13092301785945892
0.38720476627349854 0.38720476627349854
rl training, epoch1, iter0, batch288/1133, batch loss:0.38720476627349854, Training time:1145.1323280334473
batch reward last col mean 0.12865719199180603 first col mean 0.13883215188980103 all mean 0.1301073580980301
0.3801124095916748 0.3801123797893524
rl training, epoch1, iter0, batch289/1133, batch loss:0.3801123797893524, Training time:1147.77174782753
batch reward last col mean 0.1643654704093933 first col mean 0.13195113837718964 all mean 0.16462579369544983
0.5020431876182556 0.5020431876182556
rl training, epoch1, iter0, batch290/1133, batch loss:0.5020431876182556, Training time:1149.9478442668915
batch reward last col mean 0.15604734420776367 first col mean 0.13715846836566925 all mean 0.1448879837989807
0.4749471843242645 0.4749471843242645
rl training, epoch1, iter0, batch291/1133, batch loss:0.4749471843242645, Training time:1152.0275182724
batch reward last col mean 0.1624598652124405 first col mean 0.14811214804649353 all mean 0.15015128254890442
0.4224441349506378 0.4224441349506378
rl training, epoch1, iter0, batch292/1133, batch loss:0.4224441349506378, Training time:1153.8848087787628
batch reward last col mean 0.12372302263975143 first col mean 0.14368508756160736 all mean 0.13154412806034088
0.4129656255245209 0.4129656255245209
rl training, epoch1, iter0, batch293/1133, batch loss:0.4129656255245209, Training time:1155.772432088852
batch reward last col mean 0.13731062412261963 first col mean 0.15136662125587463 all mean 0.1310049295425415
0.40412425994873047 0.40412425994873047
rl training, epoch1, iter0, batch294/1133, batch loss:0.40412425994873047, Training time:1158.651762008667
batch reward last col mean 0.1235189437866211 first col mean 0.12561029195785522 all mean 0.1277250349521637
0.4071415066719055 0.4071415364742279
rl training, epoch1, iter0, batch295/1133, batch loss:0.4071415364742279, Training time:1160.5115883350372
batch reward last col mean 0.11749985069036484 first col mean 0.13413852453231812 all mean 0.12496013194322586
0.38995999097824097 0.38995999097824097
rl training, epoch1, iter0, batch296/1133, batch loss:0.38995999097824097, Training time:1162.8779320716858
batch reward last col mean 0.12949758768081665 first col mean 0.12746454775333405 all mean 0.1299711912870407
0.4333120584487915 0.4333120584487915
rl training, epoch1, iter0, batch297/1133, batch loss:0.4333120584487915, Training time:1165.2780182361603
batch reward last col mean 0.13000982999801636 first col mean 0.12093299627304077 all mean 0.1303156614303589
0.4008932411670685 0.4008932411670685
rl training, epoch1, iter0, batch298/1133, batch loss:0.4008932411670685, Training time:1167.1032342910767
batch reward last col mean 0.08121608197689056 first col mean 0.13232988119125366 all mean 0.08925838023424149
0.3851422965526581 0.3851422965526581
rl training, epoch1, iter0, batch299/1133, batch loss:0.3851422965526581, Training time:1169.046122789383
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6462034926620712 Time: 98.7265214920044 s
loss of true 0.29558380137527296 loss of gen 0.21966357626487804 loss of other 0.13095611547401861 first score 0.11540910601615906
batch reward last col mean 0.0951622948050499 first col mean 0.13535743951797485 all mean 0.0989074558019638
0.3259226381778717 0.3259226381778717
rl training, epoch1, iter0, batch300/1133, batch loss:0.3259226381778717, Training time:1270.2366437911987
batch reward last col mean 0.14164867997169495 first col mean 0.12812957167625427 all mean 0.14702622592449188
0.4599335193634033 0.4599335193634033
rl training, epoch1, iter0, batch301/1133, batch loss:0.4599335193634033, Training time:1272.1578152179718
batch reward last col mean 0.12636801600456238 first col mean 0.14011234045028687 all mean 0.1267748326063156
0.3455422520637512 0.34554222226142883
rl training, epoch1, iter0, batch302/1133, batch loss:0.34554222226142883, Training time:1274.3208332061768
batch reward last col mean 0.13648353517055511 first col mean 0.13995908200740814 all mean 0.13104213774204254
0.3579537868499756 0.3579537868499756
rl training, epoch1, iter0, batch303/1133, batch loss:0.3579537868499756, Training time:1277.7250618934631
batch reward last col mean 0.11867398023605347 first col mean 0.12600789964199066 all mean 0.12103598564863205
0.39154356718063354 0.39154356718063354
rl training, epoch1, iter0, batch304/1133, batch loss:0.39154356718063354, Training time:1280.0290694236755
batch reward last col mean 0.15702736377716064 first col mean 0.12221449613571167 all mean 0.15015119314193726
0.4495896100997925 0.4495896100997925
rl training, epoch1, iter0, batch305/1133, batch loss:0.4495896100997925, Training time:1282.3545966148376
batch reward last col mean 0.12808099389076233 first col mean 0.16033275425434113 all mean 0.13001976907253265
0.4234578013420105 0.4234578013420105
rl training, epoch1, iter0, batch306/1133, batch loss:0.4234578013420105, Training time:1284.732248544693
batch reward last col mean 0.16831696033477783 first col mean 0.11608659476041794 all mean 0.15878786146640778
0.42599016427993774 0.42599016427993774
rl training, epoch1, iter0, batch307/1133, batch loss:0.42599016427993774, Training time:1287.644211769104
batch reward last col mean 0.11622966825962067 first col mean 0.11832524836063385 all mean 0.12407288700342178
0.42165592312812805 0.42165592312812805
rl training, epoch1, iter0, batch308/1133, batch loss:0.42165592312812805, Training time:1290.2301647663116
batch reward last col mean 0.13160698115825653 first col mean 0.15115892887115479 all mean 0.13104131817817688
0.34530895948410034 0.34530895948410034
rl training, epoch1, iter0, batch309/1133, batch loss:0.34530895948410034, Training time:1292.341688156128
batch reward last col mean 0.1294747143983841 first col mean 0.13746917247772217 all mean 0.12769605219364166
0.3913019299507141 0.3913019299507141
rl training, epoch1, iter0, batch310/1133, batch loss:0.3913019299507141, Training time:1294.594407081604
batch reward last col mean 0.12033497542142868 first col mean 0.1434408277273178 all mean 0.12613411247730255
0.41161125898361206 0.41161125898361206
rl training, epoch1, iter0, batch311/1133, batch loss:0.41161125898361206, Training time:1297.3616750240326
batch reward last col mean 0.11052929610013962 first col mean 0.14366213977336884 all mean 0.11915986984968185
0.34986668825149536 0.349866658449173
rl training, epoch1, iter0, batch312/1133, batch loss:0.349866658449173, Training time:1299.4194874763489
batch reward last col mean 0.12310369312763214 first col mean 0.13409343361854553 all mean 0.12383762001991272
0.3710678815841675 0.37106791138648987
rl training, epoch1, iter0, batch313/1133, batch loss:0.37106791138648987, Training time:1302.5222609043121
batch reward last col mean 0.11430374532938004 first col mean 0.1323302835226059 all mean 0.11403057724237442
0.3609837293624878 0.3609836995601654
rl training, epoch1, iter0, batch314/1133, batch loss:0.3609836995601654, Training time:1304.5735311508179
batch reward last col mean 0.14418582618236542 first col mean 0.13409626483917236 all mean 0.14085659384727478
0.44088995456695557 0.44088995456695557
rl training, epoch1, iter0, batch315/1133, batch loss:0.44088995456695557, Training time:1306.407185792923
batch reward last col mean 0.15166811645030975 first col mean 0.12280682474374771 all mean 0.15319082140922546
0.41748008131980896 0.41748008131980896
rl training, epoch1, iter0, batch316/1133, batch loss:0.41748008131980896, Training time:1308.4072334766388
batch reward last col mean 0.1190614402294159 first col mean 0.14142441749572754 all mean 0.12286687642335892
0.38331300020217896 0.38331300020217896
rl training, epoch1, iter0, batch317/1133, batch loss:0.38331300020217896, Training time:1310.840170621872
batch reward last col mean 0.1312512457370758 first col mean 0.13453106582164764 all mean 0.128385990858078
0.3762533366680145 0.3762533366680145
rl training, epoch1, iter0, batch318/1133, batch loss:0.3762533366680145, Training time:1313.8187227249146
batch reward last col mean 0.1382494419813156 first col mean 0.13033810257911682 all mean 0.13310857117176056
0.41490352153778076 0.41490352153778076
rl training, epoch1, iter0, batch319/1133, batch loss:0.41490352153778076, Training time:1316.5001039505005
batch reward last col mean 0.10295480489730835 first col mean 0.1152934730052948 all mean 0.11278780549764633
0.35234108567237854 0.3523411154747009
rl training, epoch1, iter0, batch320/1133, batch loss:0.3523411154747009, Training time:1318.9760627746582
batch reward last col mean 0.11824703961610794 first col mean 0.1357094943523407 all mean 0.11731017380952835
0.37964391708374023 0.37964391708374023
rl training, epoch1, iter0, batch321/1133, batch loss:0.37964391708374023, Training time:1321.7609448432922
batch reward last col mean 0.140300452709198 first col mean 0.11367769539356232 all mean 0.1306409239768982
0.39264869689941406 0.39264869689941406
rl training, epoch1, iter0, batch322/1133, batch loss:0.39264869689941406, Training time:1324.5821068286896
batch reward last col mean 0.15504884719848633 first col mean 0.11543296277523041 all mean 0.14248719811439514
0.4077126681804657 0.4077126681804657
rl training, epoch1, iter0, batch323/1133, batch loss:0.4077126681804657, Training time:1326.7227420806885
batch reward last col mean 0.138036847114563 first col mean 0.14534549415111542 all mean 0.1348879188299179
0.373399943113327 0.373399943113327
rl training, epoch1, iter0, batch324/1133, batch loss:0.373399943113327, Training time:1329.7351417541504
batch reward last col mean 0.1281195878982544 first col mean 0.1256861686706543 all mean 0.13129399716854095
0.4056396484375 0.4056396484375
rl training, epoch1, iter0, batch325/1133, batch loss:0.4056396484375, Training time:1332.3640975952148
batch reward last col mean 0.11347509175539017 first col mean 0.13646860420703888 all mean 0.12105817347764969
0.37248873710632324 0.37248873710632324
rl training, epoch1, iter0, batch326/1133, batch loss:0.37248873710632324, Training time:1335.0013585090637
batch reward last col mean 0.15193220973014832 first col mean 0.14564356207847595 all mean 0.14614365994930267
0.4161135256290436 0.4161135256290436
rl training, epoch1, iter0, batch327/1133, batch loss:0.4161135256290436, Training time:1337.1068453788757
batch reward last col mean 0.16473601758480072 first col mean 0.1310887336730957 all mean 0.15647907555103302
0.4330119788646698 0.4330119788646698
rl training, epoch1, iter0, batch328/1133, batch loss:0.4330119788646698, Training time:1339.1179378032684
batch reward last col mean 0.12464083731174469 first col mean 0.12811750173568726 all mean 0.12737874686717987
0.365003377199173 0.3650033473968506
rl training, epoch1, iter0, batch329/1133, batch loss:0.3650033473968506, Training time:1341.23037815094
batch reward last col mean 0.10584741085767746 first col mean 0.14421676099300385 all mean 0.11121004819869995
0.34913307428359985 0.34913307428359985
rl training, epoch1, iter0, batch330/1133, batch loss:0.34913307428359985, Training time:1343.4297909736633
batch reward last col mean 0.08878499269485474 first col mean 0.13313521444797516 all mean 0.10123488306999207
0.35874125361442566 0.35874125361442566
rl training, epoch1, iter0, batch331/1133, batch loss:0.35874125361442566, Training time:1345.6850726604462
batch reward last col mean 0.11925974488258362 first col mean 0.15151934325695038 all mean 0.1275104582309723
0.42344093322753906 0.42344093322753906
rl training, epoch1, iter0, batch332/1133, batch loss:0.42344093322753906, Training time:1348.1781842708588
batch reward last col mean 0.1544196605682373 first col mean 0.15103021264076233 all mean 0.15331962704658508
0.4007493853569031 0.4007493853569031
rl training, epoch1, iter0, batch333/1133, batch loss:0.4007493853569031, Training time:1350.079449892044
batch reward last col mean 0.12195813655853271 first col mean 0.13067473471164703 all mean 0.13053064048290253
0.4300443232059479 0.4300442934036255
rl training, epoch1, iter0, batch334/1133, batch loss:0.4300442934036255, Training time:1352.0549886226654
batch reward last col mean 0.09762457758188248 first col mean 0.11463594436645508 all mean 0.1070777103304863
0.3958947956562042 0.3958948254585266
rl training, epoch1, iter0, batch335/1133, batch loss:0.3958948254585266, Training time:1354.6325693130493
batch reward last col mean 0.13902601599693298 first col mean 0.13371756672859192 all mean 0.13896027207374573
0.3906591534614563 0.3906591534614563
rl training, epoch1, iter0, batch336/1133, batch loss:0.3906591534614563, Training time:1356.997326374054
batch reward last col mean 0.12662161886692047 first col mean 0.16581633687019348 all mean 0.1357961744070053
0.44753319025039673 0.4475332200527191
rl training, epoch1, iter0, batch337/1133, batch loss:0.4475332200527191, Training time:1358.9576919078827
batch reward last col mean 0.14365920424461365 first col mean 0.1271880567073822 all mean 0.1405024528503418
0.408939391374588 0.408939391374588
rl training, epoch1, iter0, batch338/1133, batch loss:0.408939391374588, Training time:1361.1171107292175
batch reward last col mean 0.10593689233064651 first col mean 0.11835895478725433 all mean 0.11007508635520935
0.3384862244129181 0.3384862244129181
rl training, epoch1, iter0, batch339/1133, batch loss:0.3384862244129181, Training time:1363.3637292385101
batch reward last col mean 0.13184335827827454 first col mean 0.14234262704849243 all mean 0.1338973045349121
0.41255271434783936 0.41255271434783936
rl training, epoch1, iter0, batch340/1133, batch loss:0.41255271434783936, Training time:1365.793857574463
batch reward last col mean 0.1276019811630249 first col mean 0.14529506862163544 all mean 0.1308376044034958
0.37954145669937134 0.37954145669937134
rl training, epoch1, iter0, batch341/1133, batch loss:0.37954145669937134, Training time:1367.4085195064545
batch reward last col mean 0.11633190512657166 first col mean 0.13500738143920898 all mean 0.12597103416919708
0.37187087535858154 0.37187081575393677
rl training, epoch1, iter0, batch342/1133, batch loss:0.37187081575393677, Training time:1369.5753498077393
batch reward last col mean 0.12191072106361389 first col mean 0.12044259905815125 all mean 0.12305279076099396
0.3906599283218384 0.3906599283218384
rl training, epoch1, iter0, batch343/1133, batch loss:0.3906599283218384, Training time:1371.7087700366974
batch reward last col mean 0.1338537335395813 first col mean 0.13358786702156067 all mean 0.13999328017234802
0.4534720182418823 0.4534720182418823
rl training, epoch1, iter0, batch344/1133, batch loss:0.4534720182418823, Training time:1373.8474442958832
batch reward last col mean 0.11697849631309509 first col mean 0.13552992045879364 all mean 0.12397760897874832
0.4197803735733032 0.4197803735733032
rl training, epoch1, iter0, batch345/1133, batch loss:0.4197803735733032, Training time:1375.7839539051056
batch reward last col mean 0.11160510033369064 first col mean 0.14030995965003967 all mean 0.12355834990739822
0.36489084362983704 0.36489084362983704
rl training, epoch1, iter0, batch346/1133, batch loss:0.36489084362983704, Training time:1378.0820484161377
batch reward last col mean 0.170245960354805 first col mean 0.12363984435796738 all mean 0.16407938301563263
0.4305405020713806 0.4305405020713806
rl training, epoch1, iter0, batch347/1133, batch loss:0.4305405020713806, Training time:1379.8400671482086
batch reward last col mean 0.11666575074195862 first col mean 0.1409967839717865 all mean 0.12120525538921356
0.37669244408607483 0.37669244408607483
rl training, epoch1, iter0, batch348/1133, batch loss:0.37669244408607483, Training time:1381.9839084148407
batch reward last col mean 0.16807428002357483 first col mean 0.1485292762517929 all mean 0.1593896597623825
0.4391060471534729 0.4391060471534729
rl training, epoch1, iter0, batch349/1133, batch loss:0.4391060471534729, Training time:1383.9698400497437
batch reward last col mean 0.1546788364648819 first col mean 0.12724658846855164 all mean 0.14896851778030396
0.4378523826599121 0.4378523826599121
rl training, epoch1, iter0, batch350/1133, batch loss:0.4378523826599121, Training time:1385.8290512561798
batch reward last col mean 0.13684000074863434 first col mean 0.12985004484653473 all mean 0.13532915711402893
0.34948357939720154 0.34948357939720154
rl training, epoch1, iter0, batch351/1133, batch loss:0.34948357939720154, Training time:1388.1210370063782
batch reward last col mean 0.1412823349237442 first col mean 0.1477726399898529 all mean 0.1368008255958557
0.4040783643722534 0.4040783643722534
rl training, epoch1, iter0, batch352/1133, batch loss:0.4040783643722534, Training time:1389.9867568016052
batch reward last col mean 0.1232837587594986 first col mean 0.13246004283428192 all mean 0.12804117798805237
0.3805220127105713 0.3805220127105713
rl training, epoch1, iter0, batch353/1133, batch loss:0.3805220127105713, Training time:1391.737617969513
batch reward last col mean 0.18520621955394745 first col mean 0.13815855979919434 all mean 0.16441237926483154
0.4073033034801483 0.4073033034801483
rl training, epoch1, iter0, batch354/1133, batch loss:0.4073033034801483, Training time:1393.4119021892548
batch reward last col mean 0.11642816662788391 first col mean 0.11629164218902588 all mean 0.11995609849691391
0.3616683781147003 0.36166834831237793
rl training, epoch1, iter0, batch355/1133, batch loss:0.36166834831237793, Training time:1395.2606801986694
batch reward last col mean 0.1385095715522766 first col mean 0.1238345354795456 all mean 0.13970479369163513
0.4169310927391052 0.4169310927391052
rl training, epoch1, iter0, batch356/1133, batch loss:0.4169310927391052, Training time:1397.574711561203
batch reward last col mean 0.1100492924451828 first col mean 0.138868048787117 all mean 0.11671020090579987
0.3460902273654938 0.3460902273654938
rl training, epoch1, iter0, batch357/1133, batch loss:0.3460902273654938, Training time:1400.545221567154
batch reward last col mean 0.12955355644226074 first col mean 0.13757576048374176 all mean 0.1305864304304123
0.383121132850647 0.383121132850647
rl training, epoch1, iter0, batch358/1133, batch loss:0.383121132850647, Training time:1403.095772743225
batch reward last col mean 0.08696158230304718 first col mean 0.13166184723377228 all mean 0.09889605641365051
0.3155372142791748 0.3155372142791748
rl training, epoch1, iter0, batch359/1133, batch loss:0.3155372142791748, Training time:1404.8811440467834
batch reward last col mean 0.13924717903137207 first col mean 0.14302682876586914 all mean 0.14461687207221985
0.4258743226528168 0.4258743226528168
rl training, epoch1, iter0, batch360/1133, batch loss:0.4258743226528168, Training time:1406.6719522476196
batch reward last col mean 0.12034451961517334 first col mean 0.13156504929065704 all mean 0.12569530308246613
0.3725689649581909 0.3725689649581909
rl training, epoch1, iter0, batch361/1133, batch loss:0.3725689649581909, Training time:1408.6778984069824
batch reward last col mean 0.1095595508813858 first col mean 0.1369539201259613 all mean 0.11304380744695663
0.3732224404811859 0.3732224404811859
rl training, epoch1, iter0, batch362/1133, batch loss:0.3732224404811859, Training time:1411.1830615997314
batch reward last col mean 0.15366731584072113 first col mean 0.13709723949432373 all mean 0.13953693211078644
0.3902958035469055 0.3902958035469055
rl training, epoch1, iter0, batch363/1133, batch loss:0.3902958035469055, Training time:1413.2523860931396
batch reward last col mean 0.10768461227416992 first col mean 0.14690162241458893 all mean 0.11560048907995224
0.38739755749702454 0.3873974680900574
rl training, epoch1, iter0, batch364/1133, batch loss:0.3873974680900574, Training time:1415.5688724517822
batch reward last col mean 0.14062151312828064 first col mean 0.1265249103307724 all mean 0.13465768098831177
0.37946489453315735 0.37946489453315735
rl training, epoch1, iter0, batch365/1133, batch loss:0.37946489453315735, Training time:1417.607609987259
batch reward last col mean 0.15559984743595123 first col mean 0.13819225132465363 all mean 0.15658140182495117
0.4516672194004059 0.4516672194004059
rl training, epoch1, iter0, batch366/1133, batch loss:0.4516672194004059, Training time:1421.339911699295
batch reward last col mean 0.14768090844154358 first col mean 0.14959241449832916 all mean 0.1439962089061737
0.39528948068618774 0.39528948068618774
rl training, epoch1, iter0, batch367/1133, batch loss:0.39528948068618774, Training time:1423.2704243659973
batch reward last col mean 0.11896637082099915 first col mean 0.1565292775630951 all mean 0.12629453837871552
0.4238489270210266 0.42384886741638184
rl training, epoch1, iter0, batch368/1133, batch loss:0.42384886741638184, Training time:1425.7737469673157
batch reward last col mean 0.12344596534967422 first col mean 0.14068174362182617 all mean 0.12590309977531433
0.3400547206401825 0.3400547206401825
rl training, epoch1, iter0, batch369/1133, batch loss:0.3400547206401825, Training time:1427.818332195282
batch reward last col mean 0.1583242565393448 first col mean 0.15443269908428192 all mean 0.15524113178253174
0.43506860733032227 0.4350685775279999
rl training, epoch1, iter0, batch370/1133, batch loss:0.4350685775279999, Training time:1430.4812121391296
batch reward last col mean 0.12028472125530243 first col mean 0.13204513490200043 all mean 0.12773017585277557
0.40079358220100403 0.40079358220100403
rl training, epoch1, iter0, batch371/1133, batch loss:0.40079358220100403, Training time:1432.6833276748657
batch reward last col mean 0.1167767271399498 first col mean 0.13961951434612274 all mean 0.12043337523937225
0.3408657908439636 0.34086576104164124
rl training, epoch1, iter0, batch372/1133, batch loss:0.34086576104164124, Training time:1436.0501835346222
batch reward last col mean 0.10118888318538666 first col mean 0.11620480567216873 all mean 0.11142551898956299
0.38293853402137756 0.38293853402137756
rl training, epoch1, iter0, batch373/1133, batch loss:0.38293853402137756, Training time:1438.237543106079
batch reward last col mean 0.15426921844482422 first col mean 0.14706142246723175 all mean 0.15186567604541779
0.4215000867843628 0.4215000867843628
rl training, epoch1, iter0, batch374/1133, batch loss:0.4215000867843628, Training time:1439.9293222427368
batch reward last col mean 0.1641097068786621 first col mean 0.1426536738872528 all mean 0.15419423580169678
0.38384854793548584 0.38384854793548584
rl training, epoch1, iter0, batch375/1133, batch loss:0.38384854793548584, Training time:1443.525857925415
batch reward last col mean 0.12555193901062012 first col mean 0.13409510254859924 all mean 0.126705139875412
0.37846824526786804 0.37846824526786804
rl training, epoch1, iter0, batch376/1133, batch loss:0.37846824526786804, Training time:1445.7612459659576
batch reward last col mean 0.14852607250213623 first col mean 0.1325872540473938 all mean 0.14853735268115997
0.4511876702308655 0.4511876702308655
rl training, epoch1, iter0, batch377/1133, batch loss:0.4511876702308655, Training time:1447.6054289340973
batch reward last col mean 0.12633682787418365 first col mean 0.14541207253932953 all mean 0.12731590867042542
0.40558719635009766 0.40558719635009766
rl training, epoch1, iter0, batch378/1133, batch loss:0.40558719635009766, Training time:1449.5084822177887
batch reward last col mean 0.15205329656600952 first col mean 0.1266615390777588 all mean 0.15119080245494843
0.3910285234451294 0.3910285234451294
rl training, epoch1, iter0, batch379/1133, batch loss:0.3910285234451294, Training time:1452.2488510608673
batch reward last col mean 0.11701944470405579 first col mean 0.1454535722732544 all mean 0.11984305083751678
0.3767664432525635 0.3767664432525635
rl training, epoch1, iter0, batch380/1133, batch loss:0.3767664432525635, Training time:1455.3277027606964
batch reward last col mean 0.12942887842655182 first col mean 0.13140347599983215 all mean 0.1253831684589386
0.40455594658851624 0.40455594658851624
rl training, epoch1, iter0, batch381/1133, batch loss:0.40455594658851624, Training time:1457.4245445728302
batch reward last col mean 0.11440455913543701 first col mean 0.14821462333202362 all mean 0.12166841328144073
0.43276649713516235 0.43276649713516235
rl training, epoch1, iter0, batch382/1133, batch loss:0.43276649713516235, Training time:1459.2269282341003
batch reward last col mean 0.13264895975589752 first col mean 0.1383533775806427 all mean 0.1323135942220688
0.39467108249664307 0.39467108249664307
rl training, epoch1, iter0, batch383/1133, batch loss:0.39467108249664307, Training time:1460.815167427063
batch reward last col mean 0.12746912240982056 first col mean 0.13235092163085938 all mean 0.13374896347522736
0.40160179138183594 0.40160179138183594
rl training, epoch1, iter0, batch384/1133, batch loss:0.40160179138183594, Training time:1462.6643164157867
batch reward last col mean 0.139900803565979 first col mean 0.1468195617198944 all mean 0.14037074148654938
0.4199918210506439 0.41999173164367676
rl training, epoch1, iter0, batch385/1133, batch loss:0.41999173164367676, Training time:1465.5739333629608
batch reward last col mean 0.13076762855052948 first col mean 0.13800540566444397 all mean 0.12931284308433533
0.39637458324432373 0.39637458324432373
rl training, epoch1, iter0, batch386/1133, batch loss:0.39637458324432373, Training time:1467.5596888065338
batch reward last col mean 0.13448233902454376 first col mean 0.14994701743125916 all mean 0.13574354350566864
0.43383723497390747 0.43383723497390747
rl training, epoch1, iter0, batch387/1133, batch loss:0.43383723497390747, Training time:1470.1654295921326
batch reward last col mean 0.13904669880867004 first col mean 0.14743761718273163 all mean 0.1391991674900055
0.4174603521823883 0.4174603521823883
rl training, epoch1, iter0, batch388/1133, batch loss:0.4174603521823883, Training time:1472.2706518173218
batch reward last col mean 0.1307610124349594 first col mean 0.15003430843353271 all mean 0.13161292672157288
0.45544877648353577 0.45544877648353577
rl training, epoch1, iter0, batch389/1133, batch loss:0.45544877648353577, Training time:1474.6305763721466
batch reward last col mean 0.10868071764707565 first col mean 0.13250784575939178 all mean 0.11437083780765533
0.3670799434185028 0.3670799434185028
rl training, epoch1, iter0, batch390/1133, batch loss:0.3670799434185028, Training time:1477.0202069282532
batch reward last col mean 0.14081154763698578 first col mean 0.1425609141588211 all mean 0.13743019104003906
0.4882064759731293 0.4882064759731293
rl training, epoch1, iter0, batch391/1133, batch loss:0.4882064759731293, Training time:1479.7401657104492
batch reward last col mean 0.12679876387119293 first col mean 0.12869679927825928 all mean 0.12355049699544907
0.39407896995544434 0.39407896995544434
rl training, epoch1, iter0, batch392/1133, batch loss:0.39407896995544434, Training time:1482.5122866630554
batch reward last col mean 0.12427857518196106 first col mean 0.13422346115112305 all mean 0.12448164075613022
0.38750094175338745 0.38750094175338745
rl training, epoch1, iter0, batch393/1133, batch loss:0.38750094175338745, Training time:1484.9810180664062
batch reward last col mean 0.15821923315525055 first col mean 0.12745057046413422 all mean 0.14773060381412506
0.3811212480068207 0.3811212480068207
rl training, epoch1, iter0, batch394/1133, batch loss:0.3811212480068207, Training time:1487.4386074543
batch reward last col mean 0.0943327471613884 first col mean 0.1335250288248062 all mean 0.10364296287298203
0.3600454032421112 0.3600454032421112
rl training, epoch1, iter0, batch395/1133, batch loss:0.3600454032421112, Training time:1490.4177961349487
batch reward last col mean 0.11775532364845276 first col mean 0.15664468705654144 all mean 0.12155193090438843
0.3778846859931946 0.3778846859931946
rl training, epoch1, iter0, batch396/1133, batch loss:0.3778846859931946, Training time:1493.296467781067
batch reward last col mean 0.11540260165929794 first col mean 0.15555454790592194 all mean 0.12344096601009369
0.3645666241645813 0.3645666241645813
rl training, epoch1, iter0, batch397/1133, batch loss:0.3645666241645813, Training time:1496.3928973674774
batch reward last col mean 0.10824418067932129 first col mean 0.15166960656642914 all mean 0.1194700077176094
0.36694014072418213 0.3669402003288269
rl training, epoch1, iter0, batch398/1133, batch loss:0.3669402003288269, Training time:1499.020824432373
batch reward last col mean 0.1455349177122116 first col mean 0.1490810364484787 all mean 0.14315222203731537
0.35928526520729065 0.35928526520729065
rl training, epoch1, iter0, batch399/1133, batch loss:0.35928526520729065, Training time:1501.2070960998535
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6359956070373044 Time: 100.05224013328552 s
loss of true 0.2913427649876341 loss of gen 0.21283935982362423 loss of other 0.13181348188738326 first score 0.1349565088748932
batch reward last col mean 0.12523801624774933 first col mean 0.13840079307556152 all mean 0.12728454172611237
0.39172443747520447 0.3917244076728821
rl training, epoch1, iter0, batch400/1133, batch loss:0.3917244076728821, Training time:1603.4541370868683
batch reward last col mean 0.14673611521720886 first col mean 0.12374061346054077 all mean 0.14479894936084747
0.4010142385959625 0.4010142385959625
rl training, epoch1, iter0, batch401/1133, batch loss:0.4010142385959625, Training time:1605.7722160816193
batch reward last col mean 0.09685029089450836 first col mean 0.12745550274848938 all mean 0.11227399855852127
0.3728954792022705 0.3728954792022705
rl training, epoch1, iter0, batch402/1133, batch loss:0.3728954792022705, Training time:1608.213688135147
batch reward last col mean 0.11435580253601074 first col mean 0.12392963469028473 all mean 0.12013156712055206
0.37024518847465515 0.37024518847465515
rl training, epoch1, iter0, batch403/1133, batch loss:0.37024518847465515, Training time:1611.2594828605652
batch reward last col mean 0.1422809660434723 first col mean 0.1079874336719513 all mean 0.13366937637329102
0.3801726996898651 0.3801726996898651
rl training, epoch1, iter0, batch404/1133, batch loss:0.3801726996898651, Training time:1613.7408759593964
batch reward last col mean 0.12454824149608612 first col mean 0.13002508878707886 all mean 0.12859712541103363
0.4070308804512024 0.4070308804512024
rl training, epoch1, iter0, batch405/1133, batch loss:0.4070308804512024, Training time:1616.051940202713
batch reward last col mean 0.14164716005325317 first col mean 0.11652814596891403 all mean 0.13747167587280273
0.3817257881164551 0.3817257881164551
rl training, epoch1, iter0, batch406/1133, batch loss:0.3817257881164551, Training time:1618.1644563674927
batch reward last col mean 0.14804846048355103 first col mean 0.12110668420791626 all mean 0.14881932735443115
0.434884250164032 0.434884250164032
rl training, epoch1, iter0, batch407/1133, batch loss:0.434884250164032, Training time:1620.1418612003326
batch reward last col mean 0.17407990992069244 first col mean 0.13224950432777405 all mean 0.16651831567287445
0.4165216088294983 0.4165216088294983
rl training, epoch1, iter0, batch408/1133, batch loss:0.4165216088294983, Training time:1622.3386299610138
batch reward last col mean 0.10320597887039185 first col mean 0.13625693321228027 all mean 0.10835542529821396
0.34550824761390686 0.34550830721855164
rl training, epoch1, iter0, batch409/1133, batch loss:0.34550830721855164, Training time:1625.0325694084167
batch reward last col mean 0.11629731953144073 first col mean 0.13356007635593414 all mean 0.11370851844549179
0.36960238218307495 0.36960238218307495
rl training, epoch1, iter0, batch410/1133, batch loss:0.36960238218307495, Training time:1627.6718065738678
batch reward last col mean 0.12736335396766663 first col mean 0.1383754163980484 all mean 0.1320059895515442
0.38613075017929077 0.38613075017929077
rl training, epoch1, iter0, batch411/1133, batch loss:0.38613075017929077, Training time:1629.6625483036041
batch reward last col mean 0.14238165318965912 first col mean 0.1244104877114296 all mean 0.13540704548358917
0.3907099962234497 0.3907099962234497
rl training, epoch1, iter0, batch412/1133, batch loss:0.3907099962234497, Training time:1631.5686700344086
batch reward last col mean 0.13800513744354248 first col mean 0.1154557317495346 all mean 0.13279087841510773
0.3593464493751526 0.3593464493751526
rl training, epoch1, iter0, batch413/1133, batch loss:0.3593464493751526, Training time:1634.2936782836914
batch reward last col mean 0.14581871032714844 first col mean 0.14293885231018066 all mean 0.14777424931526184
0.4093002676963806 0.4093002676963806
rl training, epoch1, iter0, batch414/1133, batch loss:0.4093002676963806, Training time:1636.095059633255
batch reward last col mean 0.08957546949386597 first col mean 0.12250279635190964 all mean 0.09835317730903625
0.35325533151626587 0.35325533151626587
rl training, epoch1, iter0, batch415/1133, batch loss:0.35325533151626587, Training time:1638.191185951233
batch reward last col mean 0.11170226335525513 first col mean 0.13255225121974945 all mean 0.1174921989440918
0.34686970710754395 0.34686970710754395
rl training, epoch1, iter0, batch416/1133, batch loss:0.34686970710754395, Training time:1640.9608867168427
batch reward last col mean 0.1198800653219223 first col mean 0.12998098134994507 all mean 0.12542878091335297
0.34315577149391174 0.34315577149391174
rl training, epoch1, iter0, batch417/1133, batch loss:0.34315577149391174, Training time:1642.9737689495087
batch reward last col mean 0.08735868334770203 first col mean 0.12926754355430603 all mean 0.09544301778078079
0.31737232208251953 0.3173723518848419
rl training, epoch1, iter0, batch418/1133, batch loss:0.3173723518848419, Training time:1645.5931038856506
batch reward last col mean 0.1149304211139679 first col mean 0.14101579785346985 all mean 0.12327603995800018
0.4269694685935974 0.4269694685935974
rl training, epoch1, iter0, batch419/1133, batch loss:0.4269694685935974, Training time:1647.7032399177551
batch reward last col mean 0.1389358639717102 first col mean 0.12209045886993408 all mean 0.13645261526107788
0.4084852635860443 0.4084852635860443
rl training, epoch1, iter0, batch420/1133, batch loss:0.4084852635860443, Training time:1650.2745599746704
batch reward last col mean 0.15698890388011932 first col mean 0.11685968190431595 all mean 0.15387339890003204
0.4033840000629425 0.4033840000629425
rl training, epoch1, iter0, batch421/1133, batch loss:0.4033840000629425, Training time:1653.2001407146454
batch reward last col mean 0.12917421758174896 first col mean 0.12977778911590576 all mean 0.1297951340675354
0.3826649487018585 0.3826649487018585
rl training, epoch1, iter0, batch422/1133, batch loss:0.3826649487018585, Training time:1655.3007266521454
batch reward last col mean 0.10317561030387878 first col mean 0.12671272456645966 all mean 0.10969944298267365
0.35498517751693726 0.35498517751693726
rl training, epoch1, iter0, batch423/1133, batch loss:0.35498517751693726, Training time:1657.6288158893585
batch reward last col mean 0.13372838497161865 first col mean 0.12487170100212097 all mean 0.1308823674917221
0.3982901871204376 0.3982901871204376
rl training, epoch1, iter0, batch424/1133, batch loss:0.3982901871204376, Training time:1660.7950773239136
batch reward last col mean 0.14248140156269073 first col mean 0.13007324934005737 all mean 0.1405213624238968
0.4209766089916229 0.4209766089916229
rl training, epoch1, iter0, batch425/1133, batch loss:0.4209766089916229, Training time:1663.7767856121063
batch reward last col mean 0.17049574851989746 first col mean 0.1504139006137848 all mean 0.167585551738739
0.4482725262641907 0.4482725262641907
rl training, epoch1, iter0, batch426/1133, batch loss:0.4482725262641907, Training time:1666.369253873825
batch reward last col mean 0.13342994451522827 first col mean 0.11574335396289825 all mean 0.13567109405994415
0.3759528696537018 0.3759528696537018
rl training, epoch1, iter0, batch427/1133, batch loss:0.3759528696537018, Training time:1668.2462394237518
batch reward last col mean 0.1090233102440834 first col mean 0.1570061594247818 all mean 0.11557725816965103
0.3207986056804657 0.3207986056804657
rl training, epoch1, iter0, batch428/1133, batch loss:0.3207986056804657, Training time:1670.2379989624023
batch reward last col mean 0.13806244730949402 first col mean 0.12811152637004852 all mean 0.1364241987466812
0.400119423866272 0.400119423866272
rl training, epoch1, iter0, batch429/1133, batch loss:0.400119423866272, Training time:1672.426016330719
batch reward last col mean 0.11319731920957565 first col mean 0.13023383915424347 all mean 0.1155158132314682
0.3450829088687897 0.3450829088687897
rl training, epoch1, iter0, batch430/1133, batch loss:0.3450829088687897, Training time:1674.9884362220764
batch reward last col mean 0.15298953652381897 first col mean 0.12924721837043762 all mean 0.15334570407867432
0.4480002224445343 0.4480002522468567
rl training, epoch1, iter0, batch431/1133, batch loss:0.4480002522468567, Training time:1677.4236195087433
batch reward last col mean 0.12432849407196045 first col mean 0.13734540343284607 all mean 0.12639373540878296
0.35508352518081665 0.35508352518081665
rl training, epoch1, iter0, batch432/1133, batch loss:0.35508352518081665, Training time:1679.5422286987305
batch reward last col mean 0.13290411233901978 first col mean 0.12663748860359192 all mean 0.1329544186592102
0.40394845604896545 0.40394845604896545
rl training, epoch1, iter0, batch433/1133, batch loss:0.40394845604896545, Training time:1681.9392018318176
batch reward last col mean 0.19235974550247192 first col mean 0.14171859622001648 all mean 0.18348555266857147
0.41845664381980896 0.41845664381980896
rl training, epoch1, iter0, batch434/1133, batch loss:0.41845664381980896, Training time:1685.3413503170013
batch reward last col mean 0.12620466947555542 first col mean 0.14217357337474823 all mean 0.1294352412223816
0.42368558049201965 0.42368558049201965
rl training, epoch1, iter0, batch435/1133, batch loss:0.42368558049201965, Training time:1687.448647737503
batch reward last col mean 0.14313684403896332 first col mean 0.12959206104278564 all mean 0.14087657630443573
0.41972771286964417 0.41972771286964417
rl training, epoch1, iter0, batch436/1133, batch loss:0.41972771286964417, Training time:1689.6114509105682
batch reward last col mean 0.12244978547096252 first col mean 0.14034955203533173 all mean 0.1281375288963318
0.3962543308734894 0.3962543308734894
rl training, epoch1, iter0, batch437/1133, batch loss:0.3962543308734894, Training time:1691.9465882778168
batch reward last col mean 0.14149244129657745 first col mean 0.1421469897031784 all mean 0.14426173269748688
0.4442012906074524 0.4442012906074524
rl training, epoch1, iter0, batch438/1133, batch loss:0.4442012906074524, Training time:1694.1201848983765
batch reward last col mean 0.1314246654510498 first col mean 0.1549387276172638 all mean 0.13450917601585388
0.384907066822052 0.384907066822052
rl training, epoch1, iter0, batch439/1133, batch loss:0.384907066822052, Training time:1696.2656087875366
batch reward last col mean 0.13942426443099976 first col mean 0.1496330201625824 all mean 0.13809195160865784
0.43070754408836365 0.43070754408836365
rl training, epoch1, iter0, batch440/1133, batch loss:0.43070754408836365, Training time:1698.6646177768707
batch reward last col mean 0.1345933973789215 first col mean 0.14055995643138885 all mean 0.14227670431137085
0.42978864908218384 0.42978864908218384
rl training, epoch1, iter0, batch441/1133, batch loss:0.42978864908218384, Training time:1701.0486702919006
batch reward last col mean 0.14515450596809387 first col mean 0.12301641702651978 all mean 0.13911710679531097
0.4254896938800812 0.4254896938800812
rl training, epoch1, iter0, batch442/1133, batch loss:0.4254896938800812, Training time:1702.8930022716522
batch reward last col mean 0.09213878214359283 first col mean 0.1139432042837143 all mean 0.10287405550479889
0.34837886691093445 0.34837886691093445
rl training, epoch1, iter0, batch443/1133, batch loss:0.34837886691093445, Training time:1704.5655546188354
batch reward last col mean 0.10211645066738129 first col mean 0.13723702728748322 all mean 0.1088888868689537
0.3480052053928375 0.34800514578819275
rl training, epoch1, iter0, batch444/1133, batch loss:0.34800514578819275, Training time:1706.2812657356262
batch reward last col mean 0.14146646857261658 first col mean 0.11839085817337036 all mean 0.13955646753311157
0.3768959641456604 0.376895934343338
rl training, epoch1, iter0, batch445/1133, batch loss:0.376895934343338, Training time:1707.997043132782
batch reward last col mean 0.1388494372367859 first col mean 0.12995731830596924 all mean 0.139914870262146
0.3719320595264435 0.3719320595264435
rl training, epoch1, iter0, batch446/1133, batch loss:0.3719320595264435, Training time:1709.7320594787598
batch reward last col mean 0.14468997716903687 first col mean 0.1489170640707016 all mean 0.14098523557186127
0.4296925961971283 0.4296925961971283
rl training, epoch1, iter0, batch447/1133, batch loss:0.4296925961971283, Training time:1712.369282245636
batch reward last col mean 0.13910607993602753 first col mean 0.13198566436767578 all mean 0.13606643676757812
0.3947983384132385 0.3947983384132385
rl training, epoch1, iter0, batch448/1133, batch loss:0.3947983384132385, Training time:1714.35959982872
batch reward last col mean 0.12237118184566498 first col mean 0.1534232795238495 all mean 0.12399528175592422
0.36615777015686035 0.36615777015686035
rl training, epoch1, iter0, batch449/1133, batch loss:0.36615777015686035, Training time:1716.3208355903625
batch reward last col mean 0.1266566962003708 first col mean 0.1316530406475067 all mean 0.1302434206008911
0.4116530120372772 0.4116530120372772
rl training, epoch1, iter0, batch450/1133, batch loss:0.4116530120372772, Training time:1718.9071669578552
batch reward last col mean 0.15112148225307465 first col mean 0.13213703036308289 all mean 0.14742091298103333
0.3962689936161041 0.39626893401145935
rl training, epoch1, iter0, batch451/1133, batch loss:0.39626893401145935, Training time:1721.0706117153168
batch reward last col mean 0.16419200599193573 first col mean 0.13405470550060272 all mean 0.15745078027248383
0.41225218772888184 0.41225218772888184
rl training, epoch1, iter0, batch452/1133, batch loss:0.41225218772888184, Training time:1723.5974407196045
batch reward last col mean 0.11554586887359619 first col mean 0.13527528941631317 all mean 0.12231455743312836
0.3776012063026428 0.3776012063026428
rl training, epoch1, iter0, batch453/1133, batch loss:0.3776012063026428, Training time:1725.8432750701904
batch reward last col mean 0.1316322535276413 first col mean 0.14224347472190857 all mean 0.13438257575035095
0.4072369635105133 0.4072370231151581
rl training, epoch1, iter0, batch454/1133, batch loss:0.4072370231151581, Training time:1727.613156080246
batch reward last col mean 0.11432772874832153 first col mean 0.12930883467197418 all mean 0.1220616027712822
0.44727784395217896 0.44727784395217896
rl training, epoch1, iter0, batch455/1133, batch loss:0.44727784395217896, Training time:1730.4404737949371
batch reward last col mean 0.12369845807552338 first col mean 0.1345061957836151 all mean 0.12488328665494919
0.348789244890213 0.348789244890213
rl training, epoch1, iter0, batch456/1133, batch loss:0.348789244890213, Training time:1732.3506400585175
batch reward last col mean 0.1509273499250412 first col mean 0.1334816813468933 all mean 0.1526992917060852
0.44848471879959106 0.44848471879959106
rl training, epoch1, iter0, batch457/1133, batch loss:0.44848471879959106, Training time:1734.705349445343
batch reward last col mean 0.14643964171409607 first col mean 0.15987475216388702 all mean 0.14276520907878876
0.427377849817276 0.427377849817276
rl training, epoch1, iter0, batch458/1133, batch loss:0.427377849817276, Training time:1736.2447209358215
batch reward last col mean 0.13430467247962952 first col mean 0.15819764137268066 all mean 0.13593775033950806
0.3972489833831787 0.3972489535808563
rl training, epoch1, iter0, batch459/1133, batch loss:0.3972489535808563, Training time:1737.8974177837372
batch reward last col mean 0.14382940530776978 first col mean 0.12840141355991364 all mean 0.14240433275699615
0.3469292223453522 0.3469292223453522
rl training, epoch1, iter0, batch460/1133, batch loss:0.3469292223453522, Training time:1739.9368278980255
batch reward last col mean 0.15958654880523682 first col mean 0.13898396492004395 all mean 0.15569403767585754
0.4164057672023773 0.4164057672023773
rl training, epoch1, iter0, batch461/1133, batch loss:0.4164057672023773, Training time:1741.7993218898773
batch reward last col mean 0.11599892377853394 first col mean 0.13039962947368622 all mean 0.11959902942180634
0.3911076486110687 0.3911076486110687
rl training, epoch1, iter0, batch462/1133, batch loss:0.3911076486110687, Training time:1743.5923612117767
batch reward last col mean 0.1324949860572815 first col mean 0.13852961361408234 all mean 0.1342685967683792
0.4200272262096405 0.4200272262096405
rl training, epoch1, iter0, batch463/1133, batch loss:0.4200272262096405, Training time:1745.2583060264587
batch reward last col mean 0.15266938507556915 first col mean 0.11797992885112762 all mean 0.1470075249671936
0.3756495416164398 0.3756495416164398
rl training, epoch1, iter0, batch464/1133, batch loss:0.3756495416164398, Training time:1747.0290837287903
batch reward last col mean 0.1025090366601944 first col mean 0.15328644216060638 all mean 0.11770348250865936
0.3570478856563568 0.3570478856563568
rl training, epoch1, iter0, batch465/1133, batch loss:0.3570478856563568, Training time:1748.707317829132
batch reward last col mean 0.10593505203723907 first col mean 0.13229820132255554 all mean 0.11450862139463425
0.34421148896217346 0.34421148896217346
rl training, epoch1, iter0, batch466/1133, batch loss:0.34421148896217346, Training time:1750.5664649009705
batch reward last col mean 0.12090137600898743 first col mean 0.1509091854095459 all mean 0.12319857627153397
0.39741742610931396 0.39741742610931396
rl training, epoch1, iter0, batch467/1133, batch loss:0.39741742610931396, Training time:1752.6647107601166
batch reward last col mean 0.1826116293668747 first col mean 0.14356562495231628 all mean 0.16833098232746124
0.4115046560764313 0.4115046560764313
rl training, epoch1, iter0, batch468/1133, batch loss:0.4115046560764313, Training time:1754.7496483325958
batch reward last col mean 0.17879359424114227 first col mean 0.14274895191192627 all mean 0.16230550408363342
0.4949508011341095 0.4949508011341095
rl training, epoch1, iter0, batch469/1133, batch loss:0.4949508011341095, Training time:1756.3356928825378
batch reward last col mean 0.15967057645320892 first col mean 0.14725667238235474 all mean 0.15226320922374725
0.42332687973976135 0.42332687973976135
rl training, epoch1, iter0, batch470/1133, batch loss:0.42332687973976135, Training time:1758.1676943302155
batch reward last col mean 0.1494436264038086 first col mean 0.13511592149734497 all mean 0.1480545997619629
0.41721493005752563 0.41721493005752563
rl training, epoch1, iter0, batch471/1133, batch loss:0.41721493005752563, Training time:1760.2082912921906
batch reward last col mean 0.16298165917396545 first col mean 0.1489717960357666 all mean 0.14994871616363525
0.3969123959541321 0.3969123959541321
rl training, epoch1, iter0, batch472/1133, batch loss:0.3969123959541321, Training time:1761.8330342769623
batch reward last col mean 0.10959269106388092 first col mean 0.1329600214958191 all mean 0.11537676304578781
0.40442290902137756 0.4044228792190552
rl training, epoch1, iter0, batch473/1133, batch loss:0.4044228792190552, Training time:1763.3841216564178
batch reward last col mean 0.12144185602664948 first col mean 0.1419864296913147 all mean 0.12676382064819336
0.37123918533325195 0.37123918533325195
rl training, epoch1, iter0, batch474/1133, batch loss:0.37123918533325195, Training time:1765.2096855640411
batch reward last col mean 0.11767072975635529 first col mean 0.1286666989326477 all mean 0.12362417578697205
0.41304630041122437 0.41304630041122437
rl training, epoch1, iter0, batch475/1133, batch loss:0.41304630041122437, Training time:1766.9300928115845
batch reward last col mean 0.10698394477367401 first col mean 0.12001793086528778 all mean 0.11139394342899323
0.3494456112384796 0.3494456112384796
rl training, epoch1, iter0, batch476/1133, batch loss:0.3494456112384796, Training time:1768.674461364746
batch reward last col mean 0.1264401376247406 first col mean 0.1355990171432495 all mean 0.12986114621162415
0.36736947298049927 0.36736947298049927
rl training, epoch1, iter0, batch477/1133, batch loss:0.36736947298049927, Training time:1770.4693286418915
batch reward last col mean 0.10601160675287247 first col mean 0.1422092318534851 all mean 0.11930746585130692
0.42009255290031433 0.42009255290031433
rl training, epoch1, iter0, batch478/1133, batch loss:0.42009255290031433, Training time:1772.583057641983
batch reward last col mean 0.17442938685417175 first col mean 0.14573998749256134 all mean 0.16554202139377594
0.4983779191970825 0.4983779191970825
rl training, epoch1, iter0, batch479/1133, batch loss:0.4983779191970825, Training time:1774.3004202842712
batch reward last col mean 0.10460769385099411 first col mean 0.13286083936691284 all mean 0.11490180343389511
0.3428799510002136 0.3428799510002136
rl training, epoch1, iter0, batch480/1133, batch loss:0.3428799510002136, Training time:1776.3873748779297
batch reward last col mean 0.11784197390079498 first col mean 0.13911207020282745 all mean 0.1268487423658371
0.39093756675720215 0.39093756675720215
rl training, epoch1, iter0, batch481/1133, batch loss:0.39093756675720215, Training time:1778.1527268886566
batch reward last col mean 0.1331169456243515 first col mean 0.13543285429477692 all mean 0.13298505544662476
0.3501485288143158 0.3501485288143158
rl training, epoch1, iter0, batch482/1133, batch loss:0.3501485288143158, Training time:1779.970407485962
batch reward last col mean 0.13296139240264893 first col mean 0.14694534242153168 all mean 0.1397879421710968
0.3902813792228699 0.3902813792228699
rl training, epoch1, iter0, batch483/1133, batch loss:0.3902813792228699, Training time:1781.695722579956
batch reward last col mean 0.15191730856895447 first col mean 0.1361553966999054 all mean 0.15140871703624725
0.3971917927265167 0.3971917927265167
rl training, epoch1, iter0, batch484/1133, batch loss:0.3971917927265167, Training time:1783.4348301887512
batch reward last col mean 0.1672634482383728 first col mean 0.16077116131782532 all mean 0.16480755805969238
0.46441471576690674 0.46441471576690674
rl training, epoch1, iter0, batch485/1133, batch loss:0.46441471576690674, Training time:1786.267198085785
batch reward last col mean 0.12713585793972015 first col mean 0.13359405100345612 all mean 0.12428995966911316
0.37229257822036743 0.37229257822036743
rl training, epoch1, iter0, batch486/1133, batch loss:0.37229257822036743, Training time:1788.2497000694275
batch reward last col mean 0.13147900998592377 first col mean 0.1486644595861435 all mean 0.13485592603683472
0.36486658453941345 0.36486658453941345
rl training, epoch1, iter0, batch487/1133, batch loss:0.36486658453941345, Training time:1790.2824230194092
batch reward last col mean 0.16961778700351715 first col mean 0.14473223686218262 all mean 0.1531548649072647
0.41912418603897095 0.41912418603897095
rl training, epoch1, iter0, batch488/1133, batch loss:0.41912418603897095, Training time:1792.4120047092438
batch reward last col mean 0.10642354190349579 first col mean 0.1519898772239685 all mean 0.11578981578350067
0.3838306665420532 0.3838306665420532
rl training, epoch1, iter0, batch489/1133, batch loss:0.3838306665420532, Training time:1795.1893620491028
batch reward last col mean 0.12126782536506653 first col mean 0.13012297451496124 all mean 0.1280529797077179
0.3829718232154846 0.3829718232154846
rl training, epoch1, iter0, batch490/1133, batch loss:0.3829718232154846, Training time:1797.0816252231598
batch reward last col mean 0.15915881097316742 first col mean 0.14196842908859253 all mean 0.1523486077785492
0.4585382044315338 0.4585382044315338
rl training, epoch1, iter0, batch491/1133, batch loss:0.4585382044315338, Training time:1798.8898091316223
batch reward last col mean 0.15854305028915405 first col mean 0.1184316873550415 all mean 0.1606062799692154
0.42819759249687195 0.42819759249687195
rl training, epoch1, iter0, batch492/1133, batch loss:0.42819759249687195, Training time:1800.8481211662292
batch reward last col mean 0.1531423181295395 first col mean 0.12273738533258438 all mean 0.14576910436153412
0.39751240611076355 0.39751240611076355
rl training, epoch1, iter0, batch493/1133, batch loss:0.39751240611076355, Training time:1802.5016198158264
batch reward last col mean 0.17245495319366455 first col mean 0.14730650186538696 all mean 0.1643482893705368
0.4725445508956909 0.4725445508956909
rl training, epoch1, iter0, batch494/1133, batch loss:0.4725445508956909, Training time:1804.5806131362915
batch reward last col mean 0.12266753613948822 first col mean 0.13242420554161072 all mean 0.12730027735233307
0.38584408164024353 0.38584408164024353
rl training, epoch1, iter0, batch495/1133, batch loss:0.38584408164024353, Training time:1807.1953084468842
batch reward last col mean 0.13611683249473572 first col mean 0.1441882699728012 all mean 0.13507604598999023
0.4097472131252289 0.4097472131252289
rl training, epoch1, iter0, batch496/1133, batch loss:0.4097472131252289, Training time:1810.07617354393
batch reward last col mean 0.09494699537754059 first col mean 0.13201496005058289 all mean 0.10941456258296967
0.3709526062011719 0.3709526062011719
rl training, epoch1, iter0, batch497/1133, batch loss:0.3709526062011719, Training time:1812.0388615131378
batch reward last col mean 0.12265852093696594 first col mean 0.10949695110321045 all mean 0.12627941370010376
0.3683585226535797 0.3683585226535797
rl training, epoch1, iter0, batch498/1133, batch loss:0.3683585226535797, Training time:1814.0828766822815
batch reward last col mean 0.1246761903166771 first col mean 0.13791516423225403 all mean 0.12830528616905212
0.37969955801963806 0.37969955801963806
rl training, epoch1, iter0, batch499/1133, batch loss:0.37969955801963806, Training time:1816.176033258438
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6317452974058523 Time: 96.68962383270264 s
loss of true 0.2893579246875783 loss of gen 0.21015969369254697 loss of other 0.13222767891722345 first score 0.13868314027786255
batch reward last col mean 0.08641394972801208 first col mean 0.10832050442695618 all mean 0.09463946521282196
0.33893677592277527 0.33893677592277527
rl training, epoch1, iter0, batch500/1133, batch loss:0.33893677592277527, Training time:1914.628066778183
batch reward last col mean 0.13198041915893555 first col mean 0.12613289058208466 all mean 0.13097035884857178
0.39765509963035583 0.39765509963035583
rl training, epoch1, iter0, batch501/1133, batch loss:0.39765509963035583, Training time:1916.2677261829376
batch reward last col mean 0.09280333667993546 first col mean 0.09949632734060287 all mean 0.09829460829496384
0.3041872978210449 0.3041872978210449
rl training, epoch1, iter0, batch502/1133, batch loss:0.3041872978210449, Training time:1917.9751114845276
batch reward last col mean 0.15038152039051056 first col mean 0.11525987833738327 all mean 0.14607836306095123
0.3979930281639099 0.3979930281639099
rl training, epoch1, iter0, batch503/1133, batch loss:0.3979930281639099, Training time:1920.1411349773407
batch reward last col mean 0.1020166277885437 first col mean 0.13527365028858185 all mean 0.11309968680143356
0.3572499752044678 0.3572499752044678
rl training, epoch1, iter0, batch504/1133, batch loss:0.3572499752044678, Training time:1921.7277953624725
batch reward last col mean 0.10557371377944946 first col mean 0.11328694969415665 all mean 0.10669241845607758
0.33311182260513306 0.33311182260513306
rl training, epoch1, iter0, batch505/1133, batch loss:0.33311182260513306, Training time:1923.9286403656006
batch reward last col mean 0.12198852002620697 first col mean 0.11812406778335571 all mean 0.11880028992891312
0.3678657114505768 0.3678657114505768
rl training, epoch1, iter0, batch506/1133, batch loss:0.3678657114505768, Training time:1925.3092000484467
batch reward last col mean 0.16077002882957458 first col mean 0.12591016292572021 all mean 0.15304671227931976
0.38690251111984253 0.38690251111984253
rl training, epoch1, iter0, batch507/1133, batch loss:0.38690251111984253, Training time:1927.0195400714874
batch reward last col mean 0.1095862165093422 first col mean 0.12141922116279602 all mean 0.10852541029453278
0.3253047466278076 0.3253047466278076
rl training, epoch1, iter0, batch508/1133, batch loss:0.3253047466278076, Training time:1928.839674949646
batch reward last col mean 0.12199743092060089 first col mean 0.12179417908191681 all mean 0.11947841197252274
0.3728790581226349 0.3728790283203125
rl training, epoch1, iter0, batch509/1133, batch loss:0.3728790283203125, Training time:1930.4207339286804
batch reward last col mean 0.0728471577167511 first col mean 0.11860667169094086 all mean 0.07980070263147354
0.2619262933731079 0.2619263231754303
rl training, epoch1, iter0, batch510/1133, batch loss:0.2619263231754303, Training time:1932.090168952942
batch reward last col mean 0.08179698139429092 first col mean 0.10927695035934448 all mean 0.0891731008887291
0.302717387676239 0.302717387676239
rl training, epoch1, iter0, batch511/1133, batch loss:0.302717387676239, Training time:1933.600206375122
batch reward last col mean 0.14752940833568573 first col mean 0.09724132716655731 all mean 0.14666825532913208
0.396556556224823 0.3965566158294678
rl training, epoch1, iter0, batch512/1133, batch loss:0.3965566158294678, Training time:1935.0598952770233
batch reward last col mean 0.13272951543331146 first col mean 0.12143142521381378 all mean 0.12843304872512817
0.3464523255825043 0.3464523255825043
rl training, epoch1, iter0, batch513/1133, batch loss:0.3464523255825043, Training time:1936.9666681289673
batch reward last col mean 0.1007494404911995 first col mean 0.12223957479000092 all mean 0.11042729020118713
0.37493348121643066 0.37493348121643066
rl training, epoch1, iter0, batch514/1133, batch loss:0.37493348121643066, Training time:1938.664645433426
batch reward last col mean 0.09359391033649445 first col mean 0.1346048265695572 all mean 0.10716651380062103
0.35502952337265015 0.35502952337265015
rl training, epoch1, iter0, batch515/1133, batch loss:0.35502952337265015, Training time:1940.2922630310059
batch reward last col mean 0.14657336473464966 first col mean 0.1206730455160141 all mean 0.13529512286186218
0.40693792700767517 0.40693792700767517
rl training, epoch1, iter0, batch516/1133, batch loss:0.40693792700767517, Training time:1941.9809482097626
batch reward last col mean 0.12056949734687805 first col mean 0.12791520357131958 all mean 0.12153052538633347
0.4264897108078003 0.4264897108078003
rl training, epoch1, iter0, batch517/1133, batch loss:0.4264897108078003, Training time:1944.931602716446
batch reward last col mean 0.11600784212350845 first col mean 0.11870523542165756 all mean 0.12392192333936691
0.3503810167312622 0.3503810167312622
rl training, epoch1, iter0, batch518/1133, batch loss:0.3503810167312622, Training time:1946.9501016139984
batch reward last col mean 0.13485948741436005 first col mean 0.12290211021900177 all mean 0.1278565227985382
0.35759854316711426 0.35759851336479187
rl training, epoch1, iter0, batch519/1133, batch loss:0.35759851336479187, Training time:1949.3319873809814
batch reward last col mean 0.140301913022995 first col mean 0.12080541998147964 all mean 0.13439464569091797
0.42063674330711365 0.42063674330711365
rl training, epoch1, iter0, batch520/1133, batch loss:0.42063674330711365, Training time:1951.948169708252
batch reward last col mean 0.09233824908733368 first col mean 0.1325550079345703 all mean 0.09689375013113022
0.3380780816078186 0.3380780816078186
rl training, epoch1, iter0, batch521/1133, batch loss:0.3380780816078186, Training time:1953.8109772205353
batch reward last col mean 0.1170797199010849 first col mean 0.1276053488254547 all mean 0.11706195026636124
0.4093876779079437 0.4093876779079437
rl training, epoch1, iter0, batch522/1133, batch loss:0.4093876779079437, Training time:1955.6840138435364
batch reward last col mean 0.11535608768463135 first col mean 0.1261623054742813 all mean 0.11776665598154068
0.3719140887260437 0.3719141483306885
rl training, epoch1, iter0, batch523/1133, batch loss:0.3719141483306885, Training time:1957.642916917801
batch reward last col mean 0.1191110834479332 first col mean 0.1148826852440834 all mean 0.1194169670343399
0.37846335768699646 0.37846335768699646
rl training, epoch1, iter0, batch524/1133, batch loss:0.37846335768699646, Training time:1959.6038174629211
batch reward last col mean 0.13057032227516174 first col mean 0.13276506960391998 all mean 0.12805058062076569
0.35777556896209717 0.3577755391597748
rl training, epoch1, iter0, batch525/1133, batch loss:0.3577755391597748, Training time:1962.3151955604553
batch reward last col mean 0.11752606183290482 first col mean 0.12108214199542999 all mean 0.11894681304693222
0.3167545795440674 0.31675460934638977
rl training, epoch1, iter0, batch526/1133, batch loss:0.31675460934638977, Training time:1964.6823847293854
batch reward last col mean 0.14697055518627167 first col mean 0.13085000216960907 all mean 0.1406841278076172
0.4193268120288849 0.4193268120288849
rl training, epoch1, iter0, batch527/1133, batch loss:0.4193268120288849, Training time:1966.8435842990875
batch reward last col mean 0.12142904847860336 first col mean 0.14036524295806885 all mean 0.11965374648571014
0.3913988173007965 0.3913988173007965
rl training, epoch1, iter0, batch528/1133, batch loss:0.3913988173007965, Training time:1968.9415006637573
batch reward last col mean 0.10571125149726868 first col mean 0.09738804399967194 all mean 0.11053603887557983
0.3175818920135498 0.3175818920135498
rl training, epoch1, iter0, batch529/1133, batch loss:0.3175818920135498, Training time:1971.1499722003937
batch reward last col mean 0.13519881665706635 first col mean 0.11466535925865173 all mean 0.13417504727840424
0.3644478917121887 0.3644478917121887
rl training, epoch1, iter0, batch530/1133, batch loss:0.3644478917121887, Training time:1973.6370084285736
batch reward last col mean 0.1533997654914856 first col mean 0.11939284205436707 all mean 0.1449313908815384
0.37949877977371216 0.37949877977371216
rl training, epoch1, iter0, batch531/1133, batch loss:0.37949877977371216, Training time:1975.6152942180634
batch reward last col mean 0.08900906145572662 first col mean 0.11328127980232239 all mean 0.10332432389259338
0.3397772014141083 0.3397772014141083
rl training, epoch1, iter0, batch532/1133, batch loss:0.3397772014141083, Training time:1977.4051141738892
batch reward last col mean 0.13640367984771729 first col mean 0.1276942938566208 all mean 0.13050928711891174
0.3670124113559723 0.36701247096061707
rl training, epoch1, iter0, batch533/1133, batch loss:0.36701247096061707, Training time:1979.6866567134857
batch reward last col mean 0.12230287492275238 first col mean 0.11707374453544617 all mean 0.12099386751651764
0.37514811754226685 0.37514811754226685
rl training, epoch1, iter0, batch534/1133, batch loss:0.37514811754226685, Training time:1981.9847180843353
batch reward last col mean 0.11510097235441208 first col mean 0.12894012033939362 all mean 0.11717703938484192
0.3648737072944641 0.3648737072944641
rl training, epoch1, iter0, batch535/1133, batch loss:0.3648737072944641, Training time:1984.1373255252838
batch reward last col mean 0.08910705894231796 first col mean 0.1166490912437439 all mean 0.09920777380466461
0.3190249800682068 0.3190249800682068
rl training, epoch1, iter0, batch536/1133, batch loss:0.3190249800682068, Training time:1985.8964395523071
batch reward last col mean 0.12727689743041992 first col mean 0.1368567943572998 all mean 0.1269163191318512
0.38350850343704224 0.38350847363471985
rl training, epoch1, iter0, batch537/1133, batch loss:0.38350847363471985, Training time:1987.5854098796844
batch reward last col mean 0.13941462337970734 first col mean 0.11964040994644165 all mean 0.12905028462409973
0.42142030596733093 0.42142030596733093
rl training, epoch1, iter0, batch538/1133, batch loss:0.42142030596733093, Training time:1989.171611070633
batch reward last col mean 0.10775086283683777 first col mean 0.1388959437608719 all mean 0.11290305852890015
0.31163787841796875 0.31163784861564636
rl training, epoch1, iter0, batch539/1133, batch loss:0.31163784861564636, Training time:1990.8289034366608
batch reward last col mean 0.13154679536819458 first col mean 0.10580071806907654 all mean 0.12622901797294617
0.3773041367530823 0.3773041367530823
rl training, epoch1, iter0, batch540/1133, batch loss:0.3773041367530823, Training time:1992.8035407066345
batch reward last col mean 0.12026962637901306 first col mean 0.14349789917469025 all mean 0.11423619836568832
0.339267373085022 0.339267373085022
rl training, epoch1, iter0, batch541/1133, batch loss:0.339267373085022, Training time:1994.3693273067474
batch reward last col mean 0.12366941571235657 first col mean 0.1074758768081665 all mean 0.12219442427158356
0.36523404717445374 0.36523404717445374
rl training, epoch1, iter0, batch542/1133, batch loss:0.36523404717445374, Training time:1996.676996231079
batch reward last col mean 0.09462884068489075 first col mean 0.1109088808298111 all mean 0.09873663634061813
0.33934205770492554 0.33934205770492554
rl training, epoch1, iter0, batch543/1133, batch loss:0.33934205770492554, Training time:1998.4653434753418
batch reward last col mean 0.14703011512756348 first col mean 0.11765114963054657 all mean 0.1353176385164261
0.40372103452682495 0.40372103452682495
rl training, epoch1, iter0, batch544/1133, batch loss:0.40372103452682495, Training time:2000.413435459137
batch reward last col mean 0.1343512386083603 first col mean 0.13819226622581482 all mean 0.1327996402978897
0.36684003472328186 0.36684003472328186
rl training, epoch1, iter0, batch545/1133, batch loss:0.36684003472328186, Training time:2002.6359503269196
batch reward last col mean 0.07360158115625381 first col mean 0.12359234690666199 all mean 0.08854161202907562
0.34010717272758484 0.34010717272758484
rl training, epoch1, iter0, batch546/1133, batch loss:0.34010717272758484, Training time:2004.6526288986206
batch reward last col mean 0.12612272799015045 first col mean 0.1279817372560501 all mean 0.12619087100028992
0.3628121614456177 0.3628121614456177
rl training, epoch1, iter0, batch547/1133, batch loss:0.3628121614456177, Training time:2006.8850762844086
batch reward last col mean 0.11282391101121902 first col mean 0.13842210173606873 all mean 0.10823164880275726
0.35201817750930786 0.35201817750930786
rl training, epoch1, iter0, batch548/1133, batch loss:0.35201817750930786, Training time:2008.758023262024
batch reward last col mean 0.10788676887750626 first col mean 0.13533106446266174 all mean 0.1110767126083374
0.3474637269973755 0.3474637269973755
rl training, epoch1, iter0, batch549/1133, batch loss:0.3474637269973755, Training time:2010.5158705711365
batch reward last col mean 0.14262551069259644 first col mean 0.13060399889945984 all mean 0.1425779014825821
0.4228736460208893 0.4228736460208893
rl training, epoch1, iter0, batch550/1133, batch loss:0.4228736460208893, Training time:2012.505731344223
batch reward last col mean 0.1432235985994339 first col mean 0.13675609230995178 all mean 0.13581326603889465
0.39751601219177246 0.39751601219177246
rl training, epoch1, iter0, batch551/1133, batch loss:0.39751601219177246, Training time:2014.5012037754059
batch reward last col mean 0.11888331174850464 first col mean 0.11137016862630844 all mean 0.11927725374698639
0.33593985438346863 0.33593985438346863
rl training, epoch1, iter0, batch552/1133, batch loss:0.33593985438346863, Training time:2016.6761422157288
batch reward last col mean 0.14668434858322144 first col mean 0.11351287364959717 all mean 0.13532879948616028
0.35758334398269653 0.35758334398269653
rl training, epoch1, iter0, batch553/1133, batch loss:0.35758334398269653, Training time:2019.2492249011993
batch reward last col mean 0.12086213380098343 first col mean 0.12160220742225647 all mean 0.11520475894212723
0.37562862038612366 0.37562862038612366
rl training, epoch1, iter0, batch554/1133, batch loss:0.37562862038612366, Training time:2020.689335346222
batch reward last col mean 0.11473862081766129 first col mean 0.12010718137025833 all mean 0.11577773839235306
0.36353015899658203 0.36353015899658203
rl training, epoch1, iter0, batch555/1133, batch loss:0.36353015899658203, Training time:2022.419505596161
batch reward last col mean 0.08239316195249557 first col mean 0.13008424639701843 all mean 0.09981650859117508
0.3412168622016907 0.3412168622016907
rl training, epoch1, iter0, batch556/1133, batch loss:0.3412168622016907, Training time:2023.9616255760193
batch reward last col mean 0.11904013156890869 first col mean 0.12049296498298645 all mean 0.12045645713806152
0.36332857608795166 0.36332857608795166
rl training, epoch1, iter0, batch557/1133, batch loss:0.36332857608795166, Training time:2025.7174136638641
batch reward last col mean 0.1076921597123146 first col mean 0.12905146181583405 all mean 0.1123555526137352
0.3299654722213745 0.3299654722213745
rl training, epoch1, iter0, batch558/1133, batch loss:0.3299654722213745, Training time:2027.506893157959
batch reward last col mean 0.11393115669488907 first col mean 0.13509276509284973 all mean 0.12085144221782684
0.37123727798461914 0.37123727798461914
rl training, epoch1, iter0, batch559/1133, batch loss:0.37123727798461914, Training time:2029.37122964859
batch reward last col mean 0.12090875208377838 first col mean 0.12126629054546356 all mean 0.1235678493976593
0.3919234871864319 0.3919234871864319
rl training, epoch1, iter0, batch560/1133, batch loss:0.3919234871864319, Training time:2032.5605466365814
batch reward last col mean 0.11470187455415726 first col mean 0.126385897397995 all mean 0.11358056962490082
0.33600637316703796 0.3360063433647156
rl training, epoch1, iter0, batch561/1133, batch loss:0.3360063433647156, Training time:2034.976407289505
batch reward last col mean 0.09171704947948456 first col mean 0.11117815971374512 all mean 0.09858774393796921
0.3329836130142212 0.3329836130142212
rl training, epoch1, iter0, batch562/1133, batch loss:0.3329836130142212, Training time:2037.0706536769867
batch reward last col mean 0.13309422135353088 first col mean 0.10921993106603622 all mean 0.12536795437335968
0.3691175878047943 0.3691176176071167
rl training, epoch1, iter0, batch563/1133, batch loss:0.3691176176071167, Training time:2038.763968706131
batch reward last col mean 0.141078919172287 first col mean 0.13768739998340607 all mean 0.13947223126888275
0.4303523302078247 0.4303523004055023
rl training, epoch1, iter0, batch564/1133, batch loss:0.4303523004055023, Training time:2040.685558795929
batch reward last col mean 0.09761208295822144 first col mean 0.1170341819524765 all mean 0.10646039992570877
0.35882890224456787 0.3588288724422455
rl training, epoch1, iter0, batch565/1133, batch loss:0.3588288724422455, Training time:2042.8165793418884
batch reward last col mean 0.10608616471290588 first col mean 0.12007450312376022 all mean 0.109101302921772
0.35546278953552246 0.35546278953552246
rl training, epoch1, iter0, batch566/1133, batch loss:0.35546278953552246, Training time:2044.794685602188
batch reward last col mean 0.12513622641563416 first col mean 0.10918498784303665 all mean 0.12942321598529816
0.3617628216743469 0.3617628216743469
rl training, epoch1, iter0, batch567/1133, batch loss:0.3617628216743469, Training time:2046.4762878417969
batch reward last col mean 0.09697088599205017 first col mean 0.14978481829166412 all mean 0.10175037384033203
0.361764520406723 0.361764520406723
rl training, epoch1, iter0, batch568/1133, batch loss:0.361764520406723, Training time:2048.0178837776184
batch reward last col mean 0.13747136294841766 first col mean 0.1147410050034523 all mean 0.13241398334503174
0.4533398747444153 0.4533398449420929
rl training, epoch1, iter0, batch569/1133, batch loss:0.4533398449420929, Training time:2050.141087770462
batch reward last col mean 0.15601827204227448 first col mean 0.11573999375104904 all mean 0.1487656831741333
0.4192248284816742 0.4192248284816742
rl training, epoch1, iter0, batch570/1133, batch loss:0.4192248284816742, Training time:2052.4215466976166
batch reward last col mean 0.13635952770709991 first col mean 0.11164100468158722 all mean 0.12748098373413086
0.3858624994754791 0.3858624994754791
rl training, epoch1, iter0, batch571/1133, batch loss:0.3858624994754791, Training time:2054.277699947357
batch reward last col mean 0.11354253441095352 first col mean 0.11179453134536743 all mean 0.11551719903945923
0.3596009612083435 0.3596009612083435
rl training, epoch1, iter0, batch572/1133, batch loss:0.3596009612083435, Training time:2056.117550611496
batch reward last col mean 0.12294863164424896 first col mean 0.12397788465023041 all mean 0.12027829885482788
0.42549002170562744 0.42549002170562744
rl training, epoch1, iter0, batch573/1133, batch loss:0.42549002170562744, Training time:2057.7659957408905
batch reward last col mean 0.13647887110710144 first col mean 0.12441903352737427 all mean 0.14357708394527435
0.43653038144111633 0.43653038144111633
rl training, epoch1, iter0, batch574/1133, batch loss:0.43653038144111633, Training time:2059.9436490535736
batch reward last col mean 0.12582117319107056 first col mean 0.13294446468353271 all mean 0.12787558138370514
0.3823716342449188 0.3823716640472412
rl training, epoch1, iter0, batch575/1133, batch loss:0.3823716640472412, Training time:2061.873390674591
batch reward last col mean 0.14465594291687012 first col mean 0.13945543766021729 all mean 0.14317120611667633
0.41098254919052124 0.41098257899284363
rl training, epoch1, iter0, batch576/1133, batch loss:0.41098257899284363, Training time:2064.0520412921906
batch reward last col mean 0.1024884358048439 first col mean 0.12344831228256226 all mean 0.11204670369625092
0.346846342086792 0.346846342086792
rl training, epoch1, iter0, batch577/1133, batch loss:0.346846342086792, Training time:2065.9683046340942
batch reward last col mean 0.18955127894878387 first col mean 0.12209292501211166 all mean 0.163458913564682
0.40891286730766296 0.40891286730766296
rl training, epoch1, iter0, batch578/1133, batch loss:0.40891286730766296, Training time:2068.1475627422333
batch reward last col mean 0.13436006009578705 first col mean 0.12860023975372314 all mean 0.129797101020813
0.3635381758213043 0.36353814601898193
rl training, epoch1, iter0, batch579/1133, batch loss:0.36353814601898193, Training time:2070.2939052581787
batch reward last col mean 0.12685392796993256 first col mean 0.12200512737035751 all mean 0.12919658422470093
0.395826518535614 0.395826518535614
rl training, epoch1, iter0, batch580/1133, batch loss:0.395826518535614, Training time:2072.6741828918457
batch reward last col mean 0.1501370668411255 first col mean 0.13569720089435577 all mean 0.14785268902778625
0.4018149673938751 0.40181493759155273
rl training, epoch1, iter0, batch581/1133, batch loss:0.40181493759155273, Training time:2074.4606721401215
batch reward last col mean 0.11794167757034302 first col mean 0.14870497584342957 all mean 0.12499159574508667
0.3930148780345917 0.39301490783691406
rl training, epoch1, iter0, batch582/1133, batch loss:0.39301490783691406, Training time:2076.2234885692596
batch reward last col mean 0.1097475066781044 first col mean 0.1174779087305069 all mean 0.11523450165987015
0.38772138953208923 0.38772138953208923
rl training, epoch1, iter0, batch583/1133, batch loss:0.38772138953208923, Training time:2078.1059165000916
batch reward last col mean 0.11754534393548965 first col mean 0.1157606691122055 all mean 0.11847875267267227
0.39927276968955994 0.39927276968955994
rl training, epoch1, iter0, batch584/1133, batch loss:0.39927276968955994, Training time:2080.207965373993
batch reward last col mean 0.14082075655460358 first col mean 0.13064542412757874 all mean 0.13791613280773163
0.38862982392311096 0.38862982392311096
rl training, epoch1, iter0, batch585/1133, batch loss:0.38862982392311096, Training time:2082.5716733932495
batch reward last col mean 0.12733995914459229 first col mean 0.11062297224998474 all mean 0.13546958565711975
0.4191615581512451 0.4191615581512451
rl training, epoch1, iter0, batch586/1133, batch loss:0.4191615581512451, Training time:2084.5831220149994
batch reward last col mean 0.10221654176712036 first col mean 0.12057226151227951 all mean 0.10897651314735413
0.348111629486084 0.348111629486084
rl training, epoch1, iter0, batch587/1133, batch loss:0.348111629486084, Training time:2086.7340083122253
batch reward last col mean 0.11937432736158371 first col mean 0.13466373085975647 all mean 0.12128861993551254
0.36431798338890076 0.36431798338890076
rl training, epoch1, iter0, batch588/1133, batch loss:0.36431798338890076, Training time:2089.4852328300476
batch reward last col mean 0.09784628450870514 first col mean 0.12826751172542572 all mean 0.10273250937461853
0.3726193308830261 0.3726193308830261
rl training, epoch1, iter0, batch589/1133, batch loss:0.3726193308830261, Training time:2092.1086366176605
batch reward last col mean 0.14578768610954285 first col mean 0.14912737905979156 all mean 0.13989122211933136
0.4090178608894348 0.4090178608894348
rl training, epoch1, iter0, batch590/1133, batch loss:0.4090178608894348, Training time:2094.5381286144257
batch reward last col mean 0.08984056115150452 first col mean 0.12808109819889069 all mean 0.09008081257343292
0.3462165296077728 0.3462165296077728
rl training, epoch1, iter0, batch591/1133, batch loss:0.3462165296077728, Training time:2097.068612575531
batch reward last col mean 0.14013056457042694 first col mean 0.12500843405723572 all mean 0.13387125730514526
0.382580429315567 0.382580429315567
rl training, epoch1, iter0, batch592/1133, batch loss:0.382580429315567, Training time:2099.158554792404
batch reward last col mean 0.11729001998901367 first col mean 0.11389796435832977 all mean 0.12001652270555496
0.4104115068912506 0.4104114770889282
rl training, epoch1, iter0, batch593/1133, batch loss:0.4104114770889282, Training time:2101.190027475357
batch reward last col mean 0.12341862916946411 first col mean 0.1290392428636551 all mean 0.12107148766517639
0.4083408713340759 0.4083408713340759
rl training, epoch1, iter0, batch594/1133, batch loss:0.4083408713340759, Training time:2103.100927591324
batch reward last col mean 0.10997804254293442 first col mean 0.13341964781284332 all mean 0.11530256271362305
0.40356019139289856 0.40356016159057617
rl training, epoch1, iter0, batch595/1133, batch loss:0.40356016159057617, Training time:2105.0228168964386
batch reward last col mean 0.11790962517261505 first col mean 0.11546467244625092 all mean 0.11935935914516449
0.37260255217552185 0.37260255217552185
rl training, epoch1, iter0, batch596/1133, batch loss:0.37260255217552185, Training time:2107.9177610874176
batch reward last col mean 0.14871743321418762 first col mean 0.12333724647760391 all mean 0.13915371894836426
0.39087462425231934 0.39087462425231934
rl training, epoch1, iter0, batch597/1133, batch loss:0.39087462425231934, Training time:2109.5237510204315
batch reward last col mean 0.15901367366313934 first col mean 0.11937934160232544 all mean 0.1475842297077179
0.4159402847290039 0.4159402847290039
rl training, epoch1, iter0, batch598/1133, batch loss:0.4159402847290039, Training time:2111.8161056041718
batch reward last col mean 0.09801770001649857 first col mean 0.14633765816688538 all mean 0.10494423657655716
0.3768993616104126 0.3768993616104126
rl training, epoch1, iter0, batch599/1133, batch loss:0.3768993616104126, Training time:2114.1254181861877
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6211461941699274 Time: 98.30984663963318 s
loss of true 0.2830033232733305 loss of gen 0.20554543316811455 loss of other 0.13259743829730433 first score 0.1548539400100708
batch reward last col mean 0.08965782821178436 first col mean 0.11724330484867096 all mean 0.10163312405347824
0.35112425684928894 0.35112425684928894
rl training, epoch1, iter0, batch600/1133, batch loss:0.35112425684928894, Training time:2214.0879673957825
batch reward last col mean 0.11356925219297409 first col mean 0.10106337070465088 all mean 0.11068716645240784
0.31577733159065247 0.31577733159065247
rl training, epoch1, iter0, batch601/1133, batch loss:0.31577733159065247, Training time:2215.86381649971
batch reward last col mean 0.10914163291454315 first col mean 0.12328407913446426 all mean 0.11266738921403885
0.34604012966156006 0.34604012966156006
rl training, epoch1, iter0, batch602/1133, batch loss:0.34604012966156006, Training time:2217.447859287262
batch reward last col mean 0.1133512333035469 first col mean 0.12464238703250885 all mean 0.11413094401359558
0.3818986415863037 0.3818986117839813
rl training, epoch1, iter0, batch603/1133, batch loss:0.3818986117839813, Training time:2219.270015001297
batch reward last col mean 0.1419471800327301 first col mean 0.12680768966674805 all mean 0.13603413105010986
0.3658842146396637 0.3658842146396637
rl training, epoch1, iter0, batch604/1133, batch loss:0.3658842146396637, Training time:2221.8478264808655
batch reward last col mean 0.12846222519874573 first col mean 0.11347790062427521 all mean 0.12893259525299072
0.36445286870002747 0.36445286870002747
rl training, epoch1, iter0, batch605/1133, batch loss:0.36445286870002747, Training time:2223.7630887031555
batch reward last col mean 0.11616228520870209 first col mean 0.11953780055046082 all mean 0.11513690650463104
0.39534860849380493 0.39534860849380493
rl training, epoch1, iter0, batch606/1133, batch loss:0.39534860849380493, Training time:2225.4506158828735
batch reward last col mean 0.11681918054819107 first col mean 0.11135398596525192 all mean 0.11581803858280182
0.37028342485427856 0.3702833652496338
rl training, epoch1, iter0, batch607/1133, batch loss:0.3702833652496338, Training time:2227.208019256592
batch reward last col mean 0.1237865686416626 first col mean 0.12393081188201904 all mean 0.12447092682123184
0.35748961567878723 0.35748958587646484
rl training, epoch1, iter0, batch608/1133, batch loss:0.35748958587646484, Training time:2229.1597816944122
batch reward last col mean 0.12295471131801605 first col mean 0.13390880823135376 all mean 0.11916347593069077
0.37629902362823486 0.37629902362823486
rl training, epoch1, iter0, batch609/1133, batch loss:0.37629902362823486, Training time:2230.5712444782257
batch reward last col mean 0.14174893498420715 first col mean 0.13072527945041656 all mean 0.13391180336475372
0.37623724341392517 0.37623724341392517
rl training, epoch1, iter0, batch610/1133, batch loss:0.37623724341392517, Training time:2232.3723089694977
batch reward last col mean 0.1353929489850998 first col mean 0.13536565005779266 all mean 0.1286507397890091
0.4195577800273895 0.4195577800273895
rl training, epoch1, iter0, batch611/1133, batch loss:0.4195577800273895, Training time:2234.9094185829163
batch reward last col mean 0.1259661167860031 first col mean 0.11378078907728195 all mean 0.12237535417079926
0.39092257618904114 0.39092257618904114
rl training, epoch1, iter0, batch612/1133, batch loss:0.39092257618904114, Training time:2237.523823738098
batch reward last col mean 0.12760619819164276 first col mean 0.13929280638694763 all mean 0.12468333542346954
0.38320213556289673 0.38320210576057434
rl training, epoch1, iter0, batch613/1133, batch loss:0.38320210576057434, Training time:2239.272077322006
batch reward last col mean 0.13906867802143097 first col mean 0.12807421386241913 all mean 0.13350853323936462
0.42022818326950073 0.42022818326950073
rl training, epoch1, iter0, batch614/1133, batch loss:0.42022818326950073, Training time:2240.9807438850403
batch reward last col mean 0.12912505865097046 first col mean 0.124977245926857 all mean 0.12721094489097595
0.4253338873386383 0.4253338873386383
rl training, epoch1, iter0, batch615/1133, batch loss:0.4253338873386383, Training time:2242.768879175186
batch reward last col mean 0.15091325342655182 first col mean 0.12289448082447052 all mean 0.14373870193958282
0.4151769280433655 0.4151769280433655
rl training, epoch1, iter0, batch616/1133, batch loss:0.4151769280433655, Training time:2245.3240847587585
batch reward last col mean 0.11677578091621399 first col mean 0.13126476109027863 all mean 0.11961178481578827
0.35192105174064636 0.35192105174064636
rl training, epoch1, iter0, batch617/1133, batch loss:0.35192105174064636, Training time:2247.326962709427
batch reward last col mean 0.11001045256853104 first col mean 0.12498069554567337 all mean 0.11576060950756073
0.3622573912143707 0.3622573912143707
rl training, epoch1, iter0, batch618/1133, batch loss:0.3622573912143707, Training time:2248.8814039230347
batch reward last col mean 0.1284208446741104 first col mean 0.1265418827533722 all mean 0.1249072253704071
0.37338414788246155 0.37338414788246155
rl training, epoch1, iter0, batch619/1133, batch loss:0.37338414788246155, Training time:2250.6855034828186
batch reward last col mean 0.1407156139612198 first col mean 0.12670806050300598 all mean 0.13558249175548553
0.43610328435897827 0.43610328435897827
rl training, epoch1, iter0, batch620/1133, batch loss:0.43610328435897827, Training time:2252.8599395751953
batch reward last col mean 0.12043172866106033 first col mean 0.11232644319534302 all mean 0.12560155987739563
0.4131453335285187 0.4131453335285187
rl training, epoch1, iter0, batch621/1133, batch loss:0.4131453335285187, Training time:2254.627220392227
batch reward last col mean 0.15076524019241333 first col mean 0.13934625685214996 all mean 0.1491316258907318
0.36852511763572693 0.36852511763572693
rl training, epoch1, iter0, batch622/1133, batch loss:0.36852511763572693, Training time:2256.7170610427856
batch reward last col mean 0.13047628104686737 first col mean 0.14330236613750458 all mean 0.1361178457736969
0.40215250849723816 0.40215250849723816
rl training, epoch1, iter0, batch623/1133, batch loss:0.40215250849723816, Training time:2258.7908012866974
batch reward last col mean 0.1047414094209671 first col mean 0.13285285234451294 all mean 0.11221655458211899
0.39577704668045044 0.39577704668045044
rl training, epoch1, iter0, batch624/1133, batch loss:0.39577704668045044, Training time:2260.677979707718
batch reward last col mean 0.13630062341690063 first col mean 0.12990731000900269 all mean 0.1280282735824585
0.31525322794914246 0.31525322794914246
rl training, epoch1, iter0, batch625/1133, batch loss:0.31525322794914246, Training time:2262.54137468338
batch reward last col mean 0.0909423679113388 first col mean 0.15210175514221191 all mean 0.10056846588850021
0.3466990888118744 0.3466990888118744
rl training, epoch1, iter0, batch626/1133, batch loss:0.3466990888118744, Training time:2265.1647255420685
batch reward last col mean 0.15313076972961426 first col mean 0.14008145034313202 all mean 0.14516153931617737
0.4240071475505829 0.4240071475505829
rl training, epoch1, iter0, batch627/1133, batch loss:0.4240071475505829, Training time:2267.1538450717926
batch reward last col mean 0.10434727370738983 first col mean 0.14644594490528107 all mean 0.10806266963481903
0.3204839527606964 0.3204839527606964
rl training, epoch1, iter0, batch628/1133, batch loss:0.3204839527606964, Training time:2269.216089248657
batch reward last col mean 0.0869951844215393 first col mean 0.13661423325538635 all mean 0.09604568779468536
0.36268147826194763 0.36268147826194763
rl training, epoch1, iter0, batch629/1133, batch loss:0.36268147826194763, Training time:2271.2800736427307
batch reward last col mean 0.11301872134208679 first col mean 0.1379406750202179 all mean 0.1178300678730011
0.38263338804244995 0.38263338804244995
rl training, epoch1, iter0, batch630/1133, batch loss:0.38263338804244995, Training time:2273.690976381302
batch reward last col mean 0.10356797277927399 first col mean 0.11871639639139175 all mean 0.10784542560577393
0.3253324031829834 0.3253324031829834
rl training, epoch1, iter0, batch631/1133, batch loss:0.3253324031829834, Training time:2275.763855934143
batch reward last col mean 0.11969364434480667 first col mean 0.11818767338991165 all mean 0.12581747770309448
0.38231271505355835 0.38231271505355835
rl training, epoch1, iter0, batch632/1133, batch loss:0.38231271505355835, Training time:2277.751755475998
batch reward last col mean 0.11469577997922897 first col mean 0.1299712210893631 all mean 0.11683401465415955
0.361009806394577 0.361009806394577
rl training, epoch1, iter0, batch633/1133, batch loss:0.361009806394577, Training time:2280.0081441402435
batch reward last col mean 0.15229718387126923 first col mean 0.1224549412727356 all mean 0.1360298991203308
0.4254930019378662 0.4254930019378662
rl training, epoch1, iter0, batch634/1133, batch loss:0.4254930019378662, Training time:2281.7739391326904
batch reward last col mean 0.11952342092990875 first col mean 0.1523681879043579 all mean 0.1261254847049713
0.3708394765853882 0.3708394765853882
rl training, epoch1, iter0, batch635/1133, batch loss:0.3708394765853882, Training time:2283.3236689567566
batch reward last col mean 0.19183620810508728 first col mean 0.14695577323436737 all mean 0.17373864352703094
0.48948684334754944 0.48948684334754944
rl training, epoch1, iter0, batch636/1133, batch loss:0.48948684334754944, Training time:2285.161690235138
batch reward last col mean 0.14229042828083038 first col mean 0.1463642418384552 all mean 0.1438804417848587
0.4125622808933258 0.4125622808933258
rl training, epoch1, iter0, batch637/1133, batch loss:0.4125622808933258, Training time:2286.9843175411224
batch reward last col mean 0.1580425500869751 first col mean 0.14425380527973175 all mean 0.15239834785461426
0.4042680561542511 0.4042680561542511
rl training, epoch1, iter0, batch638/1133, batch loss:0.4042680561542511, Training time:2289.1810071468353
batch reward last col mean 0.12176211923360825 first col mean 0.11600390821695328 all mean 0.11966568231582642
0.3854392468929291 0.3854392468929291
rl training, epoch1, iter0, batch639/1133, batch loss:0.3854392468929291, Training time:2291.132072210312
batch reward last col mean 0.13595004379749298 first col mean 0.11428876221179962 all mean 0.12989789247512817
0.38566532731056213 0.38566532731056213
rl training, epoch1, iter0, batch640/1133, batch loss:0.38566532731056213, Training time:2292.9463975429535
batch reward last col mean 0.10182319581508636 first col mean 0.13875225186347961 all mean 0.1138700544834137
0.3705596327781677 0.3705596923828125
rl training, epoch1, iter0, batch641/1133, batch loss:0.3705596923828125, Training time:2294.6475393772125
batch reward last col mean 0.10653730481863022 first col mean 0.12936797738075256 all mean 0.1130586639046669
0.33893534541130066 0.33893534541130066
rl training, epoch1, iter0, batch642/1133, batch loss:0.33893534541130066, Training time:2296.814237833023
batch reward last col mean 0.10830645263195038 first col mean 0.1118006780743599 all mean 0.11681223660707474
0.38372132182121277 0.38372132182121277
rl training, epoch1, iter0, batch643/1133, batch loss:0.38372132182121277, Training time:2298.944808244705
batch reward last col mean 0.11596491932868958 first col mean 0.12515488266944885 all mean 0.11918459087610245
0.3482119143009186 0.3482119143009186
rl training, epoch1, iter0, batch644/1133, batch loss:0.3482119143009186, Training time:2301.901262283325
batch reward last col mean 0.11731261014938354 first col mean 0.1263280212879181 all mean 0.12791521847248077
0.3986767828464508 0.3986767828464508
rl training, epoch1, iter0, batch645/1133, batch loss:0.3986767828464508, Training time:2303.4145274162292
batch reward last col mean 0.10023269802331924 first col mean 0.13774049282073975 all mean 0.10986500978469849
0.35313525795936584 0.35313525795936584
rl training, epoch1, iter0, batch646/1133, batch loss:0.35313525795936584, Training time:2305.2524144649506
batch reward last col mean 0.15537385642528534 first col mean 0.1373569369316101 all mean 0.150774747133255
0.40668395161628723 0.40668395161628723
rl training, epoch1, iter0, batch647/1133, batch loss:0.40668395161628723, Training time:2307.628952026367
batch reward last col mean 0.10536102950572968 first col mean 0.12437544763088226 all mean 0.11129838973283768
0.39354899525642395 0.39354899525642395
rl training, epoch1, iter0, batch648/1133, batch loss:0.39354899525642395, Training time:2309.9236195087433
batch reward last col mean 0.11010172218084335 first col mean 0.12285687029361725 all mean 0.117935411632061
0.3592458665370941 0.3592458665370941
rl training, epoch1, iter0, batch649/1133, batch loss:0.3592458665370941, Training time:2311.5162320137024
batch reward last col mean 0.09089203178882599 first col mean 0.14241844415664673 all mean 0.10061793029308319
0.36911728978157043 0.36911728978157043
rl training, epoch1, iter0, batch650/1133, batch loss:0.36911728978157043, Training time:2313.621083498001
batch reward last col mean 0.16435152292251587 first col mean 0.14272046089172363 all mean 0.15308021008968353
0.49236586689949036 0.49236586689949036
rl training, epoch1, iter0, batch651/1133, batch loss:0.49236586689949036, Training time:2316.4519703388214
batch reward last col mean 0.17439594864845276 first col mean 0.13589060306549072 all mean 0.1607646942138672
0.42378881573677063 0.42378881573677063
rl training, epoch1, iter0, batch652/1133, batch loss:0.42378881573677063, Training time:2318.296809911728
batch reward last col mean 0.12756720185279846 first col mean 0.14297281205654144 all mean 0.12573710083961487
0.378370463848114 0.378370463848114
rl training, epoch1, iter0, batch653/1133, batch loss:0.378370463848114, Training time:2319.874951839447
batch reward last col mean 0.1186179369688034 first col mean 0.12436441332101822 all mean 0.12547925114631653
0.32970109581947327 0.32970109581947327
rl training, epoch1, iter0, batch654/1133, batch loss:0.32970109581947327, Training time:2321.593743801117
batch reward last col mean 0.1232224628329277 first col mean 0.11832144111394882 all mean 0.1260427087545395
0.36917221546173096 0.36917221546173096
rl training, epoch1, iter0, batch655/1133, batch loss:0.36917221546173096, Training time:2323.362782716751
batch reward last col mean 0.13838106393814087 first col mean 0.12446954846382141 all mean 0.13226774334907532
0.3432323634624481 0.3432323932647705
rl training, epoch1, iter0, batch656/1133, batch loss:0.3432323932647705, Training time:2325.1944284439087
batch reward last col mean 0.15486958622932434 first col mean 0.10597413778305054 all mean 0.13947349786758423
0.36956825852394104 0.36956825852394104
rl training, epoch1, iter0, batch657/1133, batch loss:0.36956825852394104, Training time:2326.928116083145
batch reward last col mean 0.11601382493972778 first col mean 0.13949964940547943 all mean 0.12062093615531921
0.37228748202323914 0.372287392616272
rl training, epoch1, iter0, batch658/1133, batch loss:0.372287392616272, Training time:2328.9956798553467
batch reward last col mean 0.14206846058368683 first col mean 0.13063499331474304 all mean 0.13726021349430084
0.3920605182647705 0.3920605182647705
rl training, epoch1, iter0, batch659/1133, batch loss:0.3920605182647705, Training time:2330.9125485420227
batch reward last col mean 0.14956198632717133 first col mean 0.1433563381433487 all mean 0.13963110744953156
0.36999714374542236 0.3699971139431
rl training, epoch1, iter0, batch660/1133, batch loss:0.3699971139431, Training time:2332.93555021286
batch reward last col mean 0.13259603083133698 first col mean 0.12299405038356781 all mean 0.13298247754573822
0.3764454424381256 0.3764454424381256
rl training, epoch1, iter0, batch661/1133, batch loss:0.3764454424381256, Training time:2334.6138458251953
batch reward last col mean 0.13160672783851624 first col mean 0.13059693574905396 all mean 0.13951505720615387
0.4231766164302826 0.4231766164302826
rl training, epoch1, iter0, batch662/1133, batch loss:0.4231766164302826, Training time:2336.181173324585
batch reward last col mean 0.14599359035491943 first col mean 0.13237927854061127 all mean 0.1405787467956543
0.43791845440864563 0.43791845440864563
rl training, epoch1, iter0, batch663/1133, batch loss:0.43791845440864563, Training time:2338.173153400421
batch reward last col mean 0.11321144551038742 first col mean 0.12043964862823486 all mean 0.11624003946781158
0.3549270033836365 0.3549270033836365
rl training, epoch1, iter0, batch664/1133, batch loss:0.3549270033836365, Training time:2340.4403960704803
batch reward last col mean 0.1528468132019043 first col mean 0.13721467554569244 all mean 0.14195212721824646
0.37764716148376465 0.37764716148376465
rl training, epoch1, iter0, batch665/1133, batch loss:0.37764716148376465, Training time:2342.7821066379547
batch reward last col mean 0.08235291391611099 first col mean 0.12628218531608582 all mean 0.09404610842466354
0.33378031849861145 0.33378031849861145
rl training, epoch1, iter0, batch666/1133, batch loss:0.33378031849861145, Training time:2344.8154752254486
batch reward last col mean 0.13161984086036682 first col mean 0.12355650961399078 all mean 0.12847261130809784
0.35024306178092957 0.35024306178092957
rl training, epoch1, iter0, batch667/1133, batch loss:0.35024306178092957, Training time:2346.423970222473
batch reward last col mean 0.12797515094280243 first col mean 0.13169610500335693 all mean 0.12816669046878815
0.3510548770427704 0.3510548770427704
rl training, epoch1, iter0, batch668/1133, batch loss:0.3510548770427704, Training time:2348.06000828743
batch reward last col mean 0.11277177184820175 first col mean 0.128517746925354 all mean 0.11513729393482208
0.389512836933136 0.389512836933136
rl training, epoch1, iter0, batch669/1133, batch loss:0.389512836933136, Training time:2349.6994013786316
batch reward last col mean 0.1315002739429474 first col mean 0.13528884947299957 all mean 0.13368168473243713
0.4204374849796295 0.4204375147819519
rl training, epoch1, iter0, batch670/1133, batch loss:0.4204375147819519, Training time:2351.2832934856415
batch reward last col mean 0.10614997148513794 first col mean 0.13178882002830505 all mean 0.11695073544979095
0.37367483973503113 0.37367483973503113
rl training, epoch1, iter0, batch671/1133, batch loss:0.37367483973503113, Training time:2353.1833403110504
batch reward last col mean 0.1193433627486229 first col mean 0.13909131288528442 all mean 0.1230284571647644
0.3557473421096802 0.3557473421096802
rl training, epoch1, iter0, batch672/1133, batch loss:0.3557473421096802, Training time:2355.0770156383514
batch reward last col mean 0.15138274431228638 first col mean 0.13439331948757172 all mean 0.14319410920143127
0.41203513741493225 0.412035197019577
rl training, epoch1, iter0, batch673/1133, batch loss:0.412035197019577, Training time:2356.3872232437134
batch reward last col mean 0.11369325965642929 first col mean 0.12922202050685883 all mean 0.12030749022960663
0.3802780508995056 0.3802780210971832
rl training, epoch1, iter0, batch674/1133, batch loss:0.3802780210971832, Training time:2357.9839794635773
batch reward last col mean 0.12625567615032196 first col mean 0.1478830873966217 all mean 0.1322021335363388
0.37722283601760864 0.37722283601760864
rl training, epoch1, iter0, batch675/1133, batch loss:0.37722283601760864, Training time:2359.769885778427
batch reward last col mean 0.12516649067401886 first col mean 0.1403324455022812 all mean 0.12533432245254517
0.38856977224349976 0.38856977224349976
rl training, epoch1, iter0, batch676/1133, batch loss:0.38856977224349976, Training time:2361.5786566734314
batch reward last col mean 0.14817804098129272 first col mean 0.12976022064685822 all mean 0.14306215941905975
0.400062620639801 0.4000626504421234
rl training, epoch1, iter0, batch677/1133, batch loss:0.4000626504421234, Training time:2363.2688376903534
batch reward last col mean 0.14272437989711761 first col mean 0.13570348918437958 all mean 0.13457709550857544
0.3314395844936371 0.3314395844936371
rl training, epoch1, iter0, batch678/1133, batch loss:0.3314395844936371, Training time:2365.288493156433
batch reward last col mean 0.13128291070461273 first col mean 0.12266506254673004 all mean 0.13330808281898499
0.34735530614852905 0.34735530614852905
rl training, epoch1, iter0, batch679/1133, batch loss:0.34735530614852905, Training time:2366.782368183136
batch reward last col mean 0.1544431895017624 first col mean 0.14121907949447632 all mean 0.1456722915172577
0.4026619791984558 0.4026619791984558
rl training, epoch1, iter0, batch680/1133, batch loss:0.4026619791984558, Training time:2368.340625524521
batch reward last col mean 0.14164721965789795 first col mean 0.13743150234222412 all mean 0.13473647832870483
0.3590688109397888 0.3590688109397888
rl training, epoch1, iter0, batch681/1133, batch loss:0.3590688109397888, Training time:2369.900651216507
batch reward last col mean 0.0928262323141098 first col mean 0.1473863571882248 all mean 0.10971710830926895
0.36421164870262146 0.36421164870262146
rl training, epoch1, iter0, batch682/1133, batch loss:0.36421164870262146, Training time:2371.4648468494415
batch reward last col mean 0.1078871414065361 first col mean 0.1359480768442154 all mean 0.1144653856754303
0.33780285716056824 0.33780285716056824
rl training, epoch1, iter0, batch683/1133, batch loss:0.33780285716056824, Training time:2373.4494569301605
batch reward last col mean 0.14024244248867035 first col mean 0.12534759938716888 all mean 0.13789817690849304
0.39672034978866577 0.39672034978866577
rl training, epoch1, iter0, batch684/1133, batch loss:0.39672034978866577, Training time:2375.440612077713
batch reward last col mean 0.145874485373497 first col mean 0.13456280529499054 all mean 0.1421523094177246
0.36781033873558044 0.36781030893325806
rl training, epoch1, iter0, batch685/1133, batch loss:0.36781030893325806, Training time:2378.288553237915
batch reward last col mean 0.09381306916475296 first col mean 0.1423228532075882 all mean 0.09685239940881729
0.32538309693336487 0.32538309693336487
rl training, epoch1, iter0, batch686/1133, batch loss:0.32538309693336487, Training time:2379.8924984931946
batch reward last col mean 0.10570426285266876 first col mean 0.1304052323102951 all mean 0.11263500154018402
0.35798266530036926 0.35798266530036926
rl training, epoch1, iter0, batch687/1133, batch loss:0.35798266530036926, Training time:2381.8107554912567
batch reward last col mean 0.1437998116016388 first col mean 0.14386986196041107 all mean 0.14102047681808472
0.4187696576118469 0.4187696576118469
rl training, epoch1, iter0, batch688/1133, batch loss:0.4187696576118469, Training time:2383.87481546402
batch reward last col mean 0.13887129724025726 first col mean 0.12827515602111816 all mean 0.13603639602661133
0.347914457321167 0.347914457321167
rl training, epoch1, iter0, batch689/1133, batch loss:0.347914457321167, Training time:2385.6489827632904
batch reward last col mean 0.12929925322532654 first col mean 0.12242336571216583 all mean 0.1307995468378067
0.37593138217926025 0.37593138217926025
rl training, epoch1, iter0, batch690/1133, batch loss:0.37593138217926025, Training time:2387.2740240097046
batch reward last col mean 0.13100114464759827 first col mean 0.12203031033277512 all mean 0.13440538942813873
0.3528619110584259 0.3528619110584259
rl training, epoch1, iter0, batch691/1133, batch loss:0.3528619110584259, Training time:2389.144213438034
batch reward last col mean 0.138698548078537 first col mean 0.15196332335472107 all mean 0.1382325142621994
0.4573458731174469 0.4573458731174469
rl training, epoch1, iter0, batch692/1133, batch loss:0.4573458731174469, Training time:2391.485235452652
batch reward last col mean 0.12113992869853973 first col mean 0.15673384070396423 all mean 0.1315321922302246
0.3463059365749359 0.3463059365749359
rl training, epoch1, iter0, batch693/1133, batch loss:0.3463059365749359, Training time:2393.2809631824493
batch reward last col mean 0.13886183500289917 first col mean 0.1416260004043579 all mean 0.13870076835155487
0.3549623489379883 0.3549622893333435
rl training, epoch1, iter0, batch694/1133, batch loss:0.3549622893333435, Training time:2395.396178483963
batch reward last col mean 0.12716488540172577 first col mean 0.152380108833313 all mean 0.12813925743103027
0.4080708622932434 0.4080708622932434
rl training, epoch1, iter0, batch695/1133, batch loss:0.4080708622932434, Training time:2397.1532068252563
batch reward last col mean 0.1443011313676834 first col mean 0.14345186948776245 all mean 0.14246465265750885
0.40248945355415344 0.40248945355415344
rl training, epoch1, iter0, batch696/1133, batch loss:0.40248945355415344, Training time:2398.922882080078
batch reward last col mean 0.10286366939544678 first col mean 0.14148208498954773 all mean 0.11824467033147812
0.3680679500102997 0.3680679500102997
rl training, epoch1, iter0, batch697/1133, batch loss:0.3680679500102997, Training time:2400.416300535202
batch reward last col mean 0.12911026179790497 first col mean 0.13992705941200256 all mean 0.13381865620613098
0.36406391859054565 0.36406391859054565
rl training, epoch1, iter0, batch698/1133, batch loss:0.36406391859054565, Training time:2402.6860024929047
batch reward last col mean 0.11657626926898956 first col mean 0.14736904203891754 all mean 0.12261682003736496
0.35965436697006226 0.35965436697006226
rl training, epoch1, iter0, batch699/1133, batch loss:0.35965436697006226, Training time:2404.1719286441803
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6073232990182403 Time: 97.7046856880188 s
loss of true 0.2775145522783209 loss of gen 0.1963645834656595 loss of other 0.13344416273174198 first score 0.09938208758831024
batch reward last col mean 0.11606084555387497 first col mean 0.11513346433639526 all mean 0.1132255271077156
0.3512945771217346 0.3512945771217346
rl training, epoch1, iter0, batch700/1133, batch loss:0.3512945771217346, Training time:2504.15016746521
batch reward last col mean 0.09495250880718231 first col mean 0.10788613557815552 all mean 0.10153104364871979
0.30427274107933044 0.30427274107933044
rl training, epoch1, iter0, batch701/1133, batch loss:0.30427274107933044, Training time:2506.115321159363
batch reward last col mean 0.08616679906845093 first col mean 0.10655870288610458 all mean 0.09037260711193085
0.3108425438404083 0.3108425438404083
rl training, epoch1, iter0, batch702/1133, batch loss:0.3108425438404083, Training time:2508.3418164253235
batch reward last col mean 0.11461793631315231 first col mean 0.10312426090240479 all mean 0.11504440009593964
0.3080403208732605 0.3080403208732605
rl training, epoch1, iter0, batch703/1133, batch loss:0.3080403208732605, Training time:2510.5709710121155
batch reward last col mean 0.09634421765804291 first col mean 0.11538650095462799 all mean 0.10402935743331909
0.30292484164237976 0.3029248118400574
rl training, epoch1, iter0, batch704/1133, batch loss:0.3029248118400574, Training time:2512.293079137802
batch reward last col mean 0.09746477007865906 first col mean 0.10657116025686264 all mean 0.10158753395080566
0.29378509521484375 0.29378509521484375
rl training, epoch1, iter0, batch705/1133, batch loss:0.29378509521484375, Training time:2514.4252274036407
batch reward last col mean 0.09726367890834808 first col mean 0.13005398213863373 all mean 0.10570894181728363
0.32095637917518616 0.32095637917518616
rl training, epoch1, iter0, batch706/1133, batch loss:0.32095637917518616, Training time:2515.87353515625
batch reward last col mean 0.10993773490190506 first col mean 0.12461090087890625 all mean 0.10825562477111816
0.32675668597221375 0.32675668597221375
rl training, epoch1, iter0, batch707/1133, batch loss:0.32675668597221375, Training time:2517.3373939990997
batch reward last col mean 0.09791789948940277 first col mean 0.11384761333465576 all mean 0.10096928477287292
0.3218994736671448 0.3218994736671448
rl training, epoch1, iter0, batch708/1133, batch loss:0.3218994736671448, Training time:2519.288186788559
batch reward last col mean 0.11397181451320648 first col mean 0.12963129580020905 all mean 0.11520251631736755
0.38601791858673096 0.38601788878440857
rl training, epoch1, iter0, batch709/1133, batch loss:0.38601788878440857, Training time:2521.0423169136047
batch reward last col mean 0.10013049095869064 first col mean 0.11824257671833038 all mean 0.1029873639345169
0.2933120131492615 0.2933120131492615
rl training, epoch1, iter0, batch710/1133, batch loss:0.2933120131492615, Training time:2522.946366071701
batch reward last col mean 0.14531651139259338 first col mean 0.1219780296087265 all mean 0.13743433356285095
0.38316071033477783 0.38316071033477783
rl training, epoch1, iter0, batch711/1133, batch loss:0.38316071033477783, Training time:2524.6499848365784
batch reward last col mean 0.07787863910198212 first col mean 0.12576794624328613 all mean 0.08678384870290756
0.2914031744003296 0.2914031744003296
rl training, epoch1, iter0, batch712/1133, batch loss:0.2914031744003296, Training time:2526.7406520843506
batch reward last col mean 0.09624665230512619 first col mean 0.1253594160079956 all mean 0.10998376458883286
0.3437250852584839 0.3437250852584839
rl training, epoch1, iter0, batch713/1133, batch loss:0.3437250852584839, Training time:2528.391891002655
batch reward last col mean 0.09734295308589935 first col mean 0.12232936918735504 all mean 0.099180668592453
0.3219698965549469 0.3219698965549469
rl training, epoch1, iter0, batch714/1133, batch loss:0.3219698965549469, Training time:2530.276146173477
batch reward last col mean 0.11268241703510284 first col mean 0.13394416868686676 all mean 0.11713650077581406
0.33726271986961365 0.33726271986961365
rl training, epoch1, iter0, batch715/1133, batch loss:0.33726271986961365, Training time:2532.191025495529
batch reward last col mean 0.13062544167041779 first col mean 0.11768515408039093 all mean 0.1287333071231842
0.4195830225944519 0.4195830225944519
rl training, epoch1, iter0, batch716/1133, batch loss:0.4195830225944519, Training time:2533.9911799430847
batch reward last col mean 0.12650489807128906 first col mean 0.13931648433208466 all mean 0.12377718836069107
0.3928601145744324 0.39286008477211
rl training, epoch1, iter0, batch717/1133, batch loss:0.39286008477211, Training time:2536.3200812339783
batch reward last col mean 0.13262353837490082 first col mean 0.11206559836864471 all mean 0.13041090965270996
0.3773573935031891 0.3773573935031891
rl training, epoch1, iter0, batch718/1133, batch loss:0.3773573935031891, Training time:2538.4008808135986
batch reward last col mean 0.12852099537849426 first col mean 0.12517884373664856 all mean 0.13120995461940765
0.36628246307373047 0.36628246307373047
rl training, epoch1, iter0, batch719/1133, batch loss:0.36628246307373047, Training time:2540.2768177986145
batch reward last col mean 0.11721882969141006 first col mean 0.14484673738479614 all mean 0.11910015344619751
0.33832576870918274 0.33832576870918274
rl training, epoch1, iter0, batch720/1133, batch loss:0.33832576870918274, Training time:2541.976090669632
batch reward last col mean 0.1511797457933426 first col mean 0.11885825544595718 all mean 0.14182719588279724
0.3871128261089325 0.3871128261089325
rl training, epoch1, iter0, batch721/1133, batch loss:0.3871128261089325, Training time:2544.1753849983215
batch reward last col mean 0.1054888442158699 first col mean 0.1264837682247162 all mean 0.11192361265420914
0.3157218396663666 0.3157218396663666
rl training, epoch1, iter0, batch722/1133, batch loss:0.3157218396663666, Training time:2545.8672592639923
batch reward last col mean 0.12482788413763046 first col mean 0.12695971131324768 all mean 0.12478448450565338
0.3376544415950775 0.3376544713973999
rl training, epoch1, iter0, batch723/1133, batch loss:0.3376544713973999, Training time:2547.847742319107
batch reward last col mean 0.13723938167095184 first col mean 0.1275862604379654 all mean 0.12230921536684036
0.3419117033481598 0.3419117033481598
rl training, epoch1, iter0, batch724/1133, batch loss:0.3419117033481598, Training time:2549.398657798767
batch reward last col mean 0.13366912305355072 first col mean 0.1227598786354065 all mean 0.1355980783700943
0.37120193243026733 0.37120193243026733
rl training, epoch1, iter0, batch725/1133, batch loss:0.37120193243026733, Training time:2551.091701030731
batch reward last col mean 0.0891924723982811 first col mean 0.13170649111270905 all mean 0.09683939814567566
0.3518446981906891 0.3518446981906891
rl training, epoch1, iter0, batch726/1133, batch loss:0.3518446981906891, Training time:2553.287176132202
batch reward last col mean 0.12728986144065857 first col mean 0.12429335713386536 all mean 0.1286475509405136
0.35908979177474976 0.35908979177474976
rl training, epoch1, iter0, batch727/1133, batch loss:0.35908979177474976, Training time:2555.2325558662415
batch reward last col mean 0.15360993146896362 first col mean 0.11616186797618866 all mean 0.1413625180721283
0.3767496645450592 0.3767496645450592
rl training, epoch1, iter0, batch728/1133, batch loss:0.3767496645450592, Training time:2556.77486205101
batch reward last col mean 0.13300758600234985 first col mean 0.129810631275177 all mean 0.1330447494983673
0.35451316833496094 0.35451316833496094
rl training, epoch1, iter0, batch729/1133, batch loss:0.35451316833496094, Training time:2558.5659618377686
batch reward last col mean 0.13865387439727783 first col mean 0.12573307752609253 all mean 0.13672217726707458
0.40262076258659363 0.40262076258659363
rl training, epoch1, iter0, batch730/1133, batch loss:0.40262076258659363, Training time:2560.9845640659332
batch reward last col mean 0.14332662522792816 first col mean 0.14177684485912323 all mean 0.13555005192756653
0.3652415871620178 0.3652416169643402
rl training, epoch1, iter0, batch731/1133, batch loss:0.3652416169643402, Training time:2562.5016107559204
batch reward last col mean 0.09820963442325592 first col mean 0.12976676225662231 all mean 0.10171378403902054
0.3525915741920471 0.3525915741920471
rl training, epoch1, iter0, batch732/1133, batch loss:0.3525915741920471, Training time:2564.21186375618
batch reward last col mean 0.11931147426366806 first col mean 0.11054054647684097 all mean 0.12014007568359375
0.38156643509864807 0.38156643509864807
rl training, epoch1, iter0, batch733/1133, batch loss:0.38156643509864807, Training time:2566.0510818958282
batch reward last col mean 0.1131753921508789 first col mean 0.10719882696866989 all mean 0.10930715501308441
0.3345225751399994 0.3345225751399994
rl training, epoch1, iter0, batch734/1133, batch loss:0.3345225751399994, Training time:2567.847974061966
batch reward last col mean 0.1083064153790474 first col mean 0.11403386294841766 all mean 0.10613700747489929
0.34511637687683105 0.34511637687683105
rl training, epoch1, iter0, batch735/1133, batch loss:0.34511637687683105, Training time:2569.3690757751465
batch reward last col mean 0.12363478541374207 first col mean 0.12395395338535309 all mean 0.1225942075252533
0.3693535327911377 0.3693535327911377
rl training, epoch1, iter0, batch736/1133, batch loss:0.3693535327911377, Training time:2571.3122684955597
batch reward last col mean 0.09679906070232391 first col mean 0.12324374914169312 all mean 0.10905048996210098
0.34718549251556396 0.3471854329109192
rl training, epoch1, iter0, batch737/1133, batch loss:0.3471854329109192, Training time:2572.9151544570923
batch reward last col mean 0.08378025144338608 first col mean 0.10759061574935913 all mean 0.0912797823548317
0.3207145035266876 0.3207145035266876
rl training, epoch1, iter0, batch738/1133, batch loss:0.3207145035266876, Training time:2575.3600339889526
batch reward last col mean 0.10290521383285522 first col mean 0.13802370429039001 all mean 0.10995900630950928
0.3698570728302002 0.3698570728302002
rl training, epoch1, iter0, batch739/1133, batch loss:0.3698570728302002, Training time:2577.30379986763
batch reward last col mean 0.12434056401252747 first col mean 0.11236255615949631 all mean 0.12240900099277496
0.3760325014591217 0.3760325014591217
rl training, epoch1, iter0, batch740/1133, batch loss:0.3760325014591217, Training time:2579.369432926178
batch reward last col mean 0.13283368945121765 first col mean 0.12673941254615784 all mean 0.1298118531703949
0.3929642140865326 0.3929642140865326
rl training, epoch1, iter0, batch741/1133, batch loss:0.3929642140865326, Training time:2581.404447078705
batch reward last col mean 0.10696068406105042 first col mean 0.14249922335147858 all mean 0.11110135167837143
0.3560393452644348 0.3560393452644348
rl training, epoch1, iter0, batch742/1133, batch loss:0.3560393452644348, Training time:2583.508958339691
batch reward last col mean 0.12543714046478271 first col mean 0.117759570479393 all mean 0.13151706755161285
0.4165319502353668 0.4165319502353668
rl training, epoch1, iter0, batch743/1133, batch loss:0.4165319502353668, Training time:2585.527616739273
batch reward last col mean 0.1301114708185196 first col mean 0.12758268415927887 all mean 0.12499682605266571
0.373464435338974 0.373464435338974
rl training, epoch1, iter0, batch744/1133, batch loss:0.373464435338974, Training time:2587.418119430542
batch reward last col mean 0.11744079738855362 first col mean 0.12641586363315582 all mean 0.1228925883769989
0.3820161521434784 0.3820161521434784
rl training, epoch1, iter0, batch745/1133, batch loss:0.3820161521434784, Training time:2589.2587916851044
batch reward last col mean 0.07909980416297913 first col mean 0.14499540627002716 all mean 0.10016658902168274
0.3493865430355072 0.3493865430355072
rl training, epoch1, iter0, batch746/1133, batch loss:0.3493865430355072, Training time:2590.840169429779
batch reward last col mean 0.09666989743709564 first col mean 0.1280325949192047 all mean 0.10454990714788437
0.33656954765319824 0.33656954765319824
rl training, epoch1, iter0, batch747/1133, batch loss:0.33656954765319824, Training time:2592.2550501823425
batch reward last col mean 0.12890800833702087 first col mean 0.13253262639045715 all mean 0.13179580867290497
0.40215033292770386 0.40215036273002625
rl training, epoch1, iter0, batch748/1133, batch loss:0.40215036273002625, Training time:2594.3321685791016
batch reward last col mean 0.110377736389637 first col mean 0.11931279301643372 all mean 0.11416647583246231
0.38492849469184875 0.38492849469184875
rl training, epoch1, iter0, batch749/1133, batch loss:0.38492849469184875, Training time:2596.221611738205
batch reward last col mean 0.1242005005478859 first col mean 0.11449521780014038 all mean 0.12450092285871506
0.38013970851898193 0.38013970851898193
rl training, epoch1, iter0, batch750/1133, batch loss:0.38013970851898193, Training time:2598.027851819992
batch reward last col mean 0.136435866355896 first col mean 0.1262923926115036 all mean 0.13896700739860535
0.43923816084861755 0.43923816084861755
rl training, epoch1, iter0, batch751/1133, batch loss:0.43923816084861755, Training time:2600.35044836998
batch reward last col mean 0.09826740622520447 first col mean 0.13067865371704102 all mean 0.11277465522289276
0.3931713104248047 0.39317137002944946
rl training, epoch1, iter0, batch752/1133, batch loss:0.39317137002944946, Training time:2601.872988462448
batch reward last col mean 0.16942013800144196 first col mean 0.1345108449459076 all mean 0.1523771733045578
0.42897650599479675 0.42897647619247437
rl training, epoch1, iter0, batch753/1133, batch loss:0.42897647619247437, Training time:2603.639037132263
batch reward last col mean 0.11030084639787674 first col mean 0.13382485508918762 all mean 0.11805397272109985
0.4558519423007965 0.4558519423007965
rl training, epoch1, iter0, batch754/1133, batch loss:0.4558519423007965, Training time:2605.419816970825
batch reward last col mean 0.14107684791088104 first col mean 0.10594872385263443 all mean 0.13540604710578918
0.43498319387435913 0.43498313426971436
rl training, epoch1, iter0, batch755/1133, batch loss:0.43498313426971436, Training time:2607.510120153427
batch reward last col mean 0.1307908147573471 first col mean 0.15797622501850128 all mean 0.13434436917304993
0.41364941000938416 0.41364941000938416
rl training, epoch1, iter0, batch756/1133, batch loss:0.41364941000938416, Training time:2609.2653062343597
batch reward last col mean 0.10831338912248611 first col mean 0.1551400125026703 all mean 0.11605816334486008
0.4124073386192322 0.41240736842155457
rl training, epoch1, iter0, batch757/1133, batch loss:0.41240736842155457, Training time:2611.0578248500824
batch reward last col mean 0.1516564041376114 first col mean 0.12574738264083862 all mean 0.14667008817195892
0.40080079436302185 0.40080079436302185
rl training, epoch1, iter0, batch758/1133, batch loss:0.40080079436302185, Training time:2614.1605520248413
batch reward last col mean 0.14508718252182007 first col mean 0.13486447930335999 all mean 0.13923470675945282
0.4130309820175171 0.4130309820175171
rl training, epoch1, iter0, batch759/1133, batch loss:0.4130309820175171, Training time:2616.06458568573
batch reward last col mean 0.11195474863052368 first col mean 0.14258208870887756 all mean 0.12081295251846313
0.42896950244903564 0.42896950244903564
rl training, epoch1, iter0, batch760/1133, batch loss:0.42896950244903564, Training time:2618.424842596054
batch reward last col mean 0.1495228409767151 first col mean 0.13689446449279785 all mean 0.1459590494632721
0.45690101385116577 0.45690101385116577
rl training, epoch1, iter0, batch761/1133, batch loss:0.45690101385116577, Training time:2620.3627619743347
batch reward last col mean 0.12660686671733856 first col mean 0.12330828607082367 all mean 0.1271752268075943
0.40261027216911316 0.40261027216911316
rl training, epoch1, iter0, batch762/1133, batch loss:0.40261027216911316, Training time:2622.3074131011963
batch reward last col mean 0.1044178307056427 first col mean 0.12117470055818558 all mean 0.1116388589143753
0.3731861710548401 0.3731861710548401
rl training, epoch1, iter0, batch763/1133, batch loss:0.3731861710548401, Training time:2623.991441965103
batch reward last col mean 0.17284119129180908 first col mean 0.14933346211910248 all mean 0.1600380539894104
0.46333596110343933 0.4633359909057617
rl training, epoch1, iter0, batch764/1133, batch loss:0.4633359909057617, Training time:2625.51483297348
batch reward last col mean 0.13655386865139008 first col mean 0.137857586145401 all mean 0.13176316022872925
0.429554283618927 0.429554283618927
rl training, epoch1, iter0, batch765/1133, batch loss:0.429554283618927, Training time:2627.4439947605133
batch reward last col mean 0.14639198780059814 first col mean 0.15325196087360382 all mean 0.14387665688991547
0.41238605976104736 0.412386029958725
rl training, epoch1, iter0, batch766/1133, batch loss:0.412386029958725, Training time:2629.4637718200684
batch reward last col mean 0.14408712089061737 first col mean 0.14908570051193237 all mean 0.14160089194774628
0.4376591444015503 0.4376591444015503
rl training, epoch1, iter0, batch767/1133, batch loss:0.4376591444015503, Training time:2631.24391579628
batch reward last col mean 0.15670570731163025 first col mean 0.13614259660243988 all mean 0.15454456210136414
0.508187472820282 0.508187472820282
rl training, epoch1, iter0, batch768/1133, batch loss:0.508187472820282, Training time:2632.999007463455
batch reward last col mean 0.15048590302467346 first col mean 0.14143355190753937 all mean 0.1464984267950058
0.41894203424453735 0.41894203424453735
rl training, epoch1, iter0, batch769/1133, batch loss:0.41894203424453735, Training time:2634.893363237381
batch reward last col mean 0.1226343959569931 first col mean 0.1271836757659912 all mean 0.12243424355983734
0.36685821413993835 0.36685821413993835
rl training, epoch1, iter0, batch770/1133, batch loss:0.36685821413993835, Training time:2637.277179479599
batch reward last col mean 0.1572173684835434 first col mean 0.12559054791927338 all mean 0.14794416725635529
0.4199531078338623 0.4199531078338623
rl training, epoch1, iter0, batch771/1133, batch loss:0.4199531078338623, Training time:2638.6314833164215
batch reward last col mean 0.14273793995380402 first col mean 0.13804735243320465 all mean 0.15053144097328186
0.4647897183895111 0.4647896885871887
rl training, epoch1, iter0, batch772/1133, batch loss:0.4647896885871887, Training time:2640.332243680954
batch reward last col mean 0.14200963079929352 first col mean 0.12785056233406067 all mean 0.14244675636291504
0.4356335699558258 0.4356335699558258
rl training, epoch1, iter0, batch773/1133, batch loss:0.4356335699558258, Training time:2642.4039919376373
batch reward last col mean 0.1321762204170227 first col mean 0.13508059084415436 all mean 0.13331688940525055
0.4363865852355957 0.4363865852355957
rl training, epoch1, iter0, batch774/1133, batch loss:0.4363865852355957, Training time:2643.8092608451843
batch reward last col mean 0.10315129905939102 first col mean 0.14003229141235352 all mean 0.11043849587440491
0.39848825335502625 0.39848825335502625
rl training, epoch1, iter0, batch775/1133, batch loss:0.39848825335502625, Training time:2645.6383335590363
batch reward last col mean 0.14125478267669678 first col mean 0.133400097489357 all mean 0.1382657289505005
0.432632714509964 0.432632714509964
rl training, epoch1, iter0, batch776/1133, batch loss:0.432632714509964, Training time:2646.9701902866364
batch reward last col mean 0.11314085870981216 first col mean 0.12433329969644547 all mean 0.12077440321445465
0.4092628061771393 0.4092627465724945
rl training, epoch1, iter0, batch777/1133, batch loss:0.4092627465724945, Training time:2649.241749048233
batch reward last col mean 0.12773644924163818 first col mean 0.1246923953294754 all mean 0.13366355001926422
0.47631925344467163 0.47631925344467163
rl training, epoch1, iter0, batch778/1133, batch loss:0.47631925344467163, Training time:2650.613336086273
batch reward last col mean 0.1534372717142105 first col mean 0.13851794600486755 all mean 0.14819924533367157
0.4456046521663666 0.4456046521663666
rl training, epoch1, iter0, batch779/1133, batch loss:0.4456046521663666, Training time:2652.514770269394
batch reward last col mean 0.12361815571784973 first col mean 0.11931496858596802 all mean 0.1275145560503006
0.4128054678440094 0.4128054678440094
rl training, epoch1, iter0, batch780/1133, batch loss:0.4128054678440094, Training time:2654.5435388088226
batch reward last col mean 0.10905403643846512 first col mean 0.12962345778942108 all mean 0.11691780388355255
0.40966394543647766 0.4096639156341553
rl training, epoch1, iter0, batch781/1133, batch loss:0.4096639156341553, Training time:2656.076689720154
batch reward last col mean 0.13374054431915283 first col mean 0.1469610631465912 all mean 0.14042837917804718
0.48594507575035095 0.48594507575035095
rl training, epoch1, iter0, batch782/1133, batch loss:0.48594507575035095, Training time:2658.1487662792206
batch reward last col mean 0.12846732139587402 first col mean 0.13465473055839539 all mean 0.12052544206380844
0.3714759051799774 0.3714759051799774
rl training, epoch1, iter0, batch783/1133, batch loss:0.3714759051799774, Training time:2660.0015218257904
batch reward last col mean 0.1514003872871399 first col mean 0.14264485239982605 all mean 0.1448737382888794
0.4326355755329132 0.4326355755329132
rl training, epoch1, iter0, batch784/1133, batch loss:0.4326355755329132, Training time:2662.0879192352295
batch reward last col mean 0.12446003407239914 first col mean 0.12481767684221268 all mean 0.12575286626815796
0.39175471663475037 0.39175474643707275
rl training, epoch1, iter0, batch785/1133, batch loss:0.39175474643707275, Training time:2663.733254671097
batch reward last col mean 0.13892799615859985 first col mean 0.13814155757427216 all mean 0.13859347999095917
0.5266562700271606 0.5266562700271606
rl training, epoch1, iter0, batch786/1133, batch loss:0.5266562700271606, Training time:2666.527016878128
batch reward last col mean 0.15733782947063446 first col mean 0.14183279871940613 all mean 0.15360184013843536
0.5194312930107117 0.5194312930107117
rl training, epoch1, iter0, batch787/1133, batch loss:0.5194312930107117, Training time:2668.1048069000244
batch reward last col mean 0.13822072744369507 first col mean 0.13215990364551544 all mean 0.13270585238933563
0.451004296541214 0.451004296541214
rl training, epoch1, iter0, batch788/1133, batch loss:0.451004296541214, Training time:2669.6171090602875
batch reward last col mean 0.1322835385799408 first col mean 0.140268936753273 all mean 0.13341209292411804
0.480111300945282 0.480111300945282
rl training, epoch1, iter0, batch789/1133, batch loss:0.480111300945282, Training time:2671.956514120102
batch reward last col mean 0.14079414308071136 first col mean 0.1473330855369568 all mean 0.13805124163627625
0.46891695261001587 0.46891701221466064
rl training, epoch1, iter0, batch790/1133, batch loss:0.46891701221466064, Training time:2674.3962774276733
batch reward last col mean 0.12210221588611603 first col mean 0.11697816848754883 all mean 0.1216869205236435
0.39211538434028625 0.39211538434028625
rl training, epoch1, iter0, batch791/1133, batch loss:0.39211538434028625, Training time:2676.4564135074615
batch reward last col mean 0.13611812889575958 first col mean 0.12794099748134613 all mean 0.13034844398498535
0.44200262427330017 0.44200262427330017
rl training, epoch1, iter0, batch792/1133, batch loss:0.44200262427330017, Training time:2678.3782482147217
batch reward last col mean 0.11004757881164551 first col mean 0.12597490847110748 all mean 0.11525648087263107
0.3698746860027313 0.3698746860027313
rl training, epoch1, iter0, batch793/1133, batch loss:0.3698746860027313, Training time:2680.1613552570343
batch reward last col mean 0.16211548447608948 first col mean 0.1307409405708313 all mean 0.1562667340040207
0.4552401602268219 0.4552401602268219
rl training, epoch1, iter0, batch794/1133, batch loss:0.4552401602268219, Training time:2683.031861782074
batch reward last col mean 0.1300225704908371 first col mean 0.1457522213459015 all mean 0.1313355416059494
0.4426736533641815 0.4426736831665039
rl training, epoch1, iter0, batch795/1133, batch loss:0.4426736831665039, Training time:2685.2250850200653
batch reward last col mean 0.12635698914527893 first col mean 0.13451294600963593 all mean 0.13036520779132843
0.4514816105365753 0.45148158073425293
rl training, epoch1, iter0, batch796/1133, batch loss:0.45148158073425293, Training time:2686.8993213176727
batch reward last col mean 0.13364575803279877 first col mean 0.15451408922672272 all mean 0.1356695145368576
0.4445332884788513 0.4445332884788513
rl training, epoch1, iter0, batch797/1133, batch loss:0.4445332884788513, Training time:2689.441418170929
batch reward last col mean 0.18065960705280304 first col mean 0.13713762164115906 all mean 0.17218434810638428
0.49276742339134216 0.49276742339134216
rl training, epoch1, iter0, batch798/1133, batch loss:0.49276742339134216, Training time:2691.3850450515747
batch reward last col mean 0.1747976839542389 first col mean 0.14178061485290527 all mean 0.1690445840358734
0.5154004096984863 0.5154004096984863
rl training, epoch1, iter0, batch799/1133, batch loss:0.5154004096984863, Training time:2693.368212223053
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5925309749062042 Time: 96.68245100975037 s
loss of true 0.268525785481309 loss of gen 0.19420451619592474 loss of other 0.12980067323225847 first score 0.11595267802476883
batch reward last col mean 0.10654257237911224 first col mean 0.11547066271305084 all mean 0.11094783991575241
0.347010999917984 0.347010999917984
rl training, epoch1, iter0, batch800/1133, batch loss:0.347010999917984, Training time:2791.3434858322144
batch reward last col mean 0.08464798331260681 first col mean 0.10744115710258484 all mean 0.08930683881044388
0.33717313408851624 0.33717313408851624
rl training, epoch1, iter0, batch801/1133, batch loss:0.33717313408851624, Training time:2793.120733976364
batch reward last col mean 0.10958659648895264 first col mean 0.12524767220020294 all mean 0.1122809648513794
0.3668433427810669 0.3668433427810669
rl training, epoch1, iter0, batch802/1133, batch loss:0.3668433427810669, Training time:2795.3162293434143
batch reward last col mean 0.1371052861213684 first col mean 0.10528212785720825 all mean 0.13041718304157257
0.402939110994339 0.402939110994339
rl training, epoch1, iter0, batch803/1133, batch loss:0.402939110994339, Training time:2796.9118366241455
batch reward last col mean 0.08894123882055283 first col mean 0.11205372214317322 all mean 0.09459424018859863
0.36266186833381653 0.36266180872917175
rl training, epoch1, iter0, batch804/1133, batch loss:0.36266180872917175, Training time:2798.9520778656006
batch reward last col mean 0.11069738119840622 first col mean 0.09566130489110947 all mean 0.1116330549120903
0.35850802063941956 0.35850802063941956
rl training, epoch1, iter0, batch805/1133, batch loss:0.35850802063941956, Training time:2800.823251724243
batch reward last col mean 0.08390074968338013 first col mean 0.10194964706897736 all mean 0.08635158091783524
0.29517635703086853 0.29517635703086853
rl training, epoch1, iter0, batch806/1133, batch loss:0.29517635703086853, Training time:2803.4590950012207
batch reward last col mean 0.06983410567045212 first col mean 0.10214737057685852 all mean 0.08139117062091827
0.37591803073883057 0.37591803073883057
rl training, epoch1, iter0, batch807/1133, batch loss:0.37591803073883057, Training time:2805.4767804145813
batch reward last col mean 0.10163114219903946 first col mean 0.10990409553050995 all mean 0.10756668448448181
0.38669005036354065 0.38669005036354065
rl training, epoch1, iter0, batch808/1133, batch loss:0.38669005036354065, Training time:2807.046365261078
batch reward last col mean 0.10570812970399857 first col mean 0.11959302425384521 all mean 0.10505039244890213
0.359173983335495 0.359173983335495
rl training, epoch1, iter0, batch809/1133, batch loss:0.359173983335495, Training time:2809.417179107666
batch reward last col mean 0.15623821318149567 first col mean 0.11589692533016205 all mean 0.14054468274116516
0.39164939522743225 0.39164939522743225
rl training, epoch1, iter0, batch810/1133, batch loss:0.39164939522743225, Training time:2811.700202703476
batch reward last col mean 0.09909889101982117 first col mean 0.1096535250544548 all mean 0.10604341328144073
0.332177072763443 0.332177072763443
rl training, epoch1, iter0, batch811/1133, batch loss:0.332177072763443, Training time:2813.468828678131
batch reward last col mean 0.13251100480556488 first col mean 0.11046072840690613 all mean 0.12658677995204926
0.36285635828971863 0.36285635828971863
rl training, epoch1, iter0, batch812/1133, batch loss:0.36285635828971863, Training time:2815.5119886398315
batch reward last col mean 0.12714877724647522 first col mean 0.12541846930980682 all mean 0.12810438871383667
0.37754788994789124 0.37754788994789124
rl training, epoch1, iter0, batch813/1133, batch loss:0.37754788994789124, Training time:2817.9562385082245
batch reward last col mean 0.10924816876649857 first col mean 0.11996050179004669 all mean 0.10893701761960983
0.37035518884658813 0.37035518884658813
rl training, epoch1, iter0, batch814/1133, batch loss:0.37035518884658813, Training time:2819.794001340866
batch reward last col mean 0.0993182510137558 first col mean 0.11480913311243057 all mean 0.10108543932437897
0.3115735352039337 0.3115735352039337
rl training, epoch1, iter0, batch815/1133, batch loss:0.3115735352039337, Training time:2821.627690553665
batch reward last col mean 0.17728272080421448 first col mean 0.10703085362911224 all mean 0.16661548614501953
0.3818034827709198 0.3818034827709198
rl training, epoch1, iter0, batch816/1133, batch loss:0.3818034827709198, Training time:2824.990042448044
batch reward last col mean 0.12262832373380661 first col mean 0.13179495930671692 all mean 0.12287178635597229
0.4009642004966736 0.4009642004966736
rl training, epoch1, iter0, batch817/1133, batch loss:0.4009642004966736, Training time:2826.753159046173
batch reward last col mean 0.10603603720664978 first col mean 0.11186333745718002 all mean 0.1071423664689064
0.35444262623786926 0.35444262623786926
rl training, epoch1, iter0, batch818/1133, batch loss:0.35444262623786926, Training time:2828.8369097709656
batch reward last col mean 0.10658766329288483 first col mean 0.11085166782140732 all mean 0.11282035708427429
0.3429141640663147 0.3429141640663147
rl training, epoch1, iter0, batch819/1133, batch loss:0.3429141640663147, Training time:2830.3434331417084
batch reward last col mean 0.16232264041900635 first col mean 0.12330125272274017 all mean 0.14589384198188782
0.3901112377643585 0.3901112377643585
rl training, epoch1, iter0, batch820/1133, batch loss:0.3901112377643585, Training time:2832.0355031490326
batch reward last col mean 0.13673840463161469 first col mean 0.11142335832118988 all mean 0.13164399564266205
0.3831218183040619 0.3831218183040619
rl training, epoch1, iter0, batch821/1133, batch loss:0.3831218183040619, Training time:2834.5348052978516
batch reward last col mean 0.11474376171827316 first col mean 0.10961486399173737 all mean 0.11291299760341644
0.3810814619064331 0.3810814619064331
rl training, epoch1, iter0, batch822/1133, batch loss:0.3810814619064331, Training time:2837.008402824402
batch reward last col mean 0.11075829714536667 first col mean 0.13993585109710693 all mean 0.11507700383663177
0.36852720379829407 0.36852720379829407
rl training, epoch1, iter0, batch823/1133, batch loss:0.36852720379829407, Training time:2838.8264253139496
batch reward last col mean 0.12993696331977844 first col mean 0.13165129721164703 all mean 0.12877529859542847
0.38981133699417114 0.38981133699417114
rl training, epoch1, iter0, batch824/1133, batch loss:0.38981133699417114, Training time:2840.88778924942
batch reward last col mean 0.10887744277715683 first col mean 0.12571391463279724 all mean 0.12022919207811356
0.3653500974178314 0.3653500974178314
rl training, epoch1, iter0, batch825/1133, batch loss:0.3653500974178314, Training time:2842.712749004364
batch reward last col mean 0.12302690744400024 first col mean 0.12100580334663391 all mean 0.12459338456392288
0.39142391085624695 0.39142388105392456
rl training, epoch1, iter0, batch826/1133, batch loss:0.39142388105392456, Training time:2844.4117572307587
batch reward last col mean 0.12473329901695251 first col mean 0.11122734844684601 all mean 0.11988373100757599
0.3631065785884857 0.3631065785884857
rl training, epoch1, iter0, batch827/1133, batch loss:0.3631065785884857, Training time:2846.3204350471497
batch reward last col mean 0.08313103765249252 first col mean 0.12739934027194977 all mean 0.09403154999017715
0.3285295367240906 0.3285295367240906
rl training, epoch1, iter0, batch828/1133, batch loss:0.3285295367240906, Training time:2848.748272895813
batch reward last col mean 0.13223667442798615 first col mean 0.1294546127319336 all mean 0.12384504079818726
0.35775917768478394 0.35775917768478394
rl training, epoch1, iter0, batch829/1133, batch loss:0.35775917768478394, Training time:2850.5203759670258
batch reward last col mean 0.11706003546714783 first col mean 0.13401229679584503 all mean 0.12956111133098602
0.37950006127357483 0.37950006127357483
rl training, epoch1, iter0, batch830/1133, batch loss:0.37950006127357483, Training time:2852.5558128356934
batch reward last col mean 0.09471172839403152 first col mean 0.13245786726474762 all mean 0.1039014384150505
0.3655261993408203 0.3655261993408203
rl training, epoch1, iter0, batch831/1133, batch loss:0.3655261993408203, Training time:2854.9684884548187
batch reward last col mean 0.09721609950065613 first col mean 0.11729159951210022 all mean 0.10725648701190948
0.34112852811813354 0.34112852811813354
rl training, epoch1, iter0, batch832/1133, batch loss:0.34112852811813354, Training time:2856.737024784088
batch reward last col mean 0.10590241849422455 first col mean 0.14265061914920807 all mean 0.11027234047651291
0.32065650820732117 0.32065650820732117
rl training, epoch1, iter0, batch833/1133, batch loss:0.32065650820732117, Training time:2858.94371509552
batch reward last col mean 0.14904087781906128 first col mean 0.13364435732364655 all mean 0.14554940164089203
0.37275761365890503 0.3727576434612274
rl training, epoch1, iter0, batch834/1133, batch loss:0.3727576434612274, Training time:2862.2771775722504
batch reward last col mean 0.12620070576667786 first col mean 0.12825359404087067 all mean 0.12172650545835495
0.33808979392051697 0.33808979392051697
rl training, epoch1, iter0, batch835/1133, batch loss:0.33808979392051697, Training time:2864.545171737671
batch reward last col mean 0.14114603400230408 first col mean 0.13116151094436646 all mean 0.1362154185771942
0.38966622948646545 0.38966622948646545
rl training, epoch1, iter0, batch836/1133, batch loss:0.38966622948646545, Training time:2866.5794298648834
batch reward last col mean 0.10712218284606934 first col mean 0.12032109498977661 all mean 0.11115045100450516
0.3602468967437744 0.3602468967437744
rl training, epoch1, iter0, batch837/1133, batch loss:0.3602468967437744, Training time:2868.3573467731476
batch reward last col mean 0.1123323142528534 first col mean 0.12147124111652374 all mean 0.11247655749320984
0.33645597100257874 0.33645597100257874
rl training, epoch1, iter0, batch838/1133, batch loss:0.33645597100257874, Training time:2869.9325573444366
batch reward last col mean 0.11059201508760452 first col mean 0.1212049350142479 all mean 0.11379742622375488
0.35447943210601807 0.35447943210601807
rl training, epoch1, iter0, batch839/1133, batch loss:0.35447943210601807, Training time:2872.348468065262
batch reward last col mean 0.12699013948440552 first col mean 0.139150470495224 all mean 0.13249383866786957
0.37616878747940063 0.37616878747940063
rl training, epoch1, iter0, batch840/1133, batch loss:0.37616878747940063, Training time:2874.219003677368
batch reward last col mean 0.13281255960464478 first col mean 0.11563439667224884 all mean 0.13240168988704681
0.37322303652763367 0.37322303652763367
rl training, epoch1, iter0, batch841/1133, batch loss:0.37322303652763367, Training time:2875.947635412216
batch reward last col mean 0.1560536026954651 first col mean 0.15107779204845428 all mean 0.15416444838047028
0.3939872682094574 0.3939872682094574
rl training, epoch1, iter0, batch842/1133, batch loss:0.3939872682094574, Training time:2877.848965406418
batch reward last col mean 0.17087718844413757 first col mean 0.14151470363140106 all mean 0.16060157120227814
0.3681628704071045 0.3681628704071045
rl training, epoch1, iter0, batch843/1133, batch loss:0.3681628704071045, Training time:2879.401168346405
batch reward last col mean 0.13723605871200562 first col mean 0.13760001957416534 all mean 0.13464894890785217
0.3691265285015106 0.3691265285015106
rl training, epoch1, iter0, batch844/1133, batch loss:0.3691265285015106, Training time:2881.2734382152557
batch reward last col mean 0.11569860577583313 first col mean 0.15981914103031158 all mean 0.12088765949010849
0.4145849943161011 0.4145849943161011
rl training, epoch1, iter0, batch845/1133, batch loss:0.4145849943161011, Training time:2883.257800579071
batch reward last col mean 0.12624336779117584 first col mean 0.1349458247423172 all mean 0.12987381219863892
0.40107229351997375 0.40107226371765137
rl training, epoch1, iter0, batch846/1133, batch loss:0.40107226371765137, Training time:2885.402687072754
batch reward last col mean 0.16356997191905975 first col mean 0.15154962241649628 all mean 0.1616649627685547
0.4369635283946991 0.4369635283946991
rl training, epoch1, iter0, batch847/1133, batch loss:0.4369635283946991, Training time:2887.9317977428436
batch reward last col mean 0.12652280926704407 first col mean 0.13684678077697754 all mean 0.13535496592521667
0.41402944922447205 0.41402944922447205
rl training, epoch1, iter0, batch848/1133, batch loss:0.41402944922447205, Training time:2889.9613568782806
batch reward last col mean 0.12223489582538605 first col mean 0.12735404074192047 all mean 0.1258290410041809
0.35581329464912415 0.35581329464912415
rl training, epoch1, iter0, batch849/1133, batch loss:0.35581329464912415, Training time:2891.8978180885315
batch reward last col mean 0.1161864846944809 first col mean 0.1437666267156601 all mean 0.1187124252319336
0.3272526264190674 0.3272526264190674
rl training, epoch1, iter0, batch850/1133, batch loss:0.3272526264190674, Training time:2893.4881389141083
batch reward last col mean 0.121006540954113 first col mean 0.15025070309638977 all mean 0.12839730083942413
0.35393738746643066 0.35393738746643066
rl training, epoch1, iter0, batch851/1133, batch loss:0.35393738746643066, Training time:2895.400157690048
batch reward last col mean 0.12499156594276428 first col mean 0.14079166948795319 all mean 0.12864084541797638
0.3653627038002014 0.3653627038002014
rl training, epoch1, iter0, batch852/1133, batch loss:0.3653627038002014, Training time:2897.1114954948425
batch reward last col mean 0.1490655094385147 first col mean 0.16714587807655334 all mean 0.14236021041870117
0.39419177174568176 0.39419177174568176
rl training, epoch1, iter0, batch853/1133, batch loss:0.39419177174568176, Training time:2899.2226736545563
batch reward last col mean 0.11986345797777176 first col mean 0.1228264793753624 all mean 0.12316275388002396
0.37762805819511414 0.37762805819511414
rl training, epoch1, iter0, batch854/1133, batch loss:0.37762805819511414, Training time:2901.0344610214233
batch reward last col mean 0.11284714937210083 first col mean 0.17381875216960907 all mean 0.12692345678806305
0.3612461984157562 0.3612461984157562
rl training, epoch1, iter0, batch855/1133, batch loss:0.3612461984157562, Training time:2902.717258453369
batch reward last col mean 0.1322234869003296 first col mean 0.13782507181167603 all mean 0.13279585540294647
0.38054516911506653 0.38054516911506653
rl training, epoch1, iter0, batch856/1133, batch loss:0.38054516911506653, Training time:2904.5014231204987
batch reward last col mean 0.09342657029628754 first col mean 0.1475585401058197 all mean 0.10413946956396103
0.3275350034236908 0.3275350034236908
rl training, epoch1, iter0, batch857/1133, batch loss:0.3275350034236908, Training time:2906.56352519989
batch reward last col mean 0.10855960100889206 first col mean 0.13064375519752502 all mean 0.12961676716804504
0.3710175156593323 0.3710175156593323
rl training, epoch1, iter0, batch858/1133, batch loss:0.3710175156593323, Training time:2907.9807817935944
batch reward last col mean 0.1321292370557785 first col mean 0.14967124164104462 all mean 0.13771119713783264
0.41183963418006897 0.41183963418006897
rl training, epoch1, iter0, batch859/1133, batch loss:0.41183963418006897, Training time:2909.9109098911285
batch reward last col mean 0.16059309244155884 first col mean 0.1522967517375946 all mean 0.15930812060832977
0.4389841854572296 0.4389841854572296
rl training, epoch1, iter0, batch860/1133, batch loss:0.4389841854572296, Training time:2911.5110483169556
batch reward last col mean 0.1320556253194809 first col mean 0.1418761909008026 all mean 0.13891646265983582
0.36209654808044434 0.36209654808044434
rl training, epoch1, iter0, batch861/1133, batch loss:0.36209654808044434, Training time:2912.9198632240295
batch reward last col mean 0.12697063386440277 first col mean 0.13642387092113495 all mean 0.13168884813785553
0.35722461342811584 0.35722461342811584
rl training, epoch1, iter0, batch862/1133, batch loss:0.35722461342811584, Training time:2914.486592531204
batch reward last col mean 0.14238016307353973 first col mean 0.14457151293754578 all mean 0.13610774278640747
0.368442565202713 0.368442565202713
rl training, epoch1, iter0, batch863/1133, batch loss:0.368442565202713, Training time:2916.1779973506927
batch reward last col mean 0.13609278202056885 first col mean 0.1545560508966446 all mean 0.13712984323501587
0.4474051594734192 0.4474051594734192
rl training, epoch1, iter0, batch864/1133, batch loss:0.4474051594734192, Training time:2918.975813627243
batch reward last col mean 0.17763647437095642 first col mean 0.14112797379493713 all mean 0.16268761456012726
0.37880098819732666 0.3788009583950043
rl training, epoch1, iter0, batch865/1133, batch loss:0.3788009583950043, Training time:2920.874869823456
batch reward last col mean 0.11973189562559128 first col mean 0.1581883579492569 all mean 0.1274534910917282
0.3707939088344574 0.3707939088344574
rl training, epoch1, iter0, batch866/1133, batch loss:0.3707939088344574, Training time:2922.609410047531
batch reward last col mean 0.11324366927146912 first col mean 0.14089363813400269 all mean 0.12130314856767654
0.37499338388442993 0.37499338388442993
rl training, epoch1, iter0, batch867/1133, batch loss:0.37499338388442993, Training time:2924.089021205902
batch reward last col mean 0.16231471300125122 first col mean 0.13671794533729553 all mean 0.15799933671951294
0.4039754569530487 0.4039754569530487
rl training, epoch1, iter0, batch868/1133, batch loss:0.4039754569530487, Training time:2925.8241641521454
batch reward last col mean 0.11614297330379486 first col mean 0.15368270874023438 all mean 0.11662585288286209
0.35826459527015686 0.35826459527015686
rl training, epoch1, iter0, batch869/1133, batch loss:0.35826459527015686, Training time:2927.7288661003113
batch reward last col mean 0.12022242695093155 first col mean 0.155498206615448 all mean 0.1230161264538765
0.35728636384010315 0.35728636384010315
rl training, epoch1, iter0, batch870/1133, batch loss:0.35728636384010315, Training time:2929.4917628765106
batch reward last col mean 0.1298324167728424 first col mean 0.14763307571411133 all mean 0.14134430885314941
0.4070536494255066 0.4070536494255066
rl training, epoch1, iter0, batch871/1133, batch loss:0.4070536494255066, Training time:2931.422547340393
batch reward last col mean 0.14251187443733215 first col mean 0.13371451199054718 all mean 0.14465482532978058
0.3906692564487457 0.3906692564487457
rl training, epoch1, iter0, batch872/1133, batch loss:0.3906692564487457, Training time:2933.265280485153
batch reward last col mean 0.11997101455926895 first col mean 0.15514644980430603 all mean 0.12937363982200623
0.3719756007194519 0.3719756007194519
rl training, epoch1, iter0, batch873/1133, batch loss:0.3719756007194519, Training time:2935.171429872513
batch reward last col mean 0.12606564164161682 first col mean 0.137393057346344 all mean 0.1365068554878235
0.379440575838089 0.379440575838089
rl training, epoch1, iter0, batch874/1133, batch loss:0.379440575838089, Training time:2936.6439661979675
batch reward last col mean 0.1307193636894226 first col mean 0.13046081364154816 all mean 0.13134413957595825
0.32682231068611145 0.32682231068611145
rl training, epoch1, iter0, batch875/1133, batch loss:0.32682231068611145, Training time:2938.483772754669
batch reward last col mean 0.10264433920383453 first col mean 0.14901480078697205 all mean 0.11367376148700714
0.3185889422893524 0.3185889422893524
rl training, epoch1, iter0, batch876/1133, batch loss:0.3185889422893524, Training time:2940.1318323612213
batch reward last col mean 0.10911194980144501 first col mean 0.14749892055988312 all mean 0.1144045814871788
0.3263626992702484 0.3263626992702484
rl training, epoch1, iter0, batch877/1133, batch loss:0.3263626992702484, Training time:2942.2897267341614
batch reward last col mean 0.13914518058300018 first col mean 0.15173926949501038 all mean 0.1407366394996643
0.38248082995414734 0.38248082995414734
rl training, epoch1, iter0, batch878/1133, batch loss:0.38248082995414734, Training time:2943.896823644638
batch reward last col mean 0.1470610797405243 first col mean 0.16647203266620636 all mean 0.15223564207553864
0.4206491708755493 0.4206491708755493
rl training, epoch1, iter0, batch879/1133, batch loss:0.4206491708755493, Training time:2945.7975680828094
batch reward last col mean 0.1472138911485672 first col mean 0.12713505327701569 all mean 0.14403825998306274
0.37307751178741455 0.37307754158973694
rl training, epoch1, iter0, batch880/1133, batch loss:0.37307754158973694, Training time:2947.4782631397247
batch reward last col mean 0.14798426628112793 first col mean 0.15422272682189941 all mean 0.1487654596567154
0.4198492467403412 0.4198492467403412
rl training, epoch1, iter0, batch881/1133, batch loss:0.4198492467403412, Training time:2949.767575263977
batch reward last col mean 0.1553565412759781 first col mean 0.1452130377292633 all mean 0.15012124180793762
0.4477033317089081 0.44770336151123047
rl training, epoch1, iter0, batch882/1133, batch loss:0.44770336151123047, Training time:2951.8198041915894
batch reward last col mean 0.15147905051708221 first col mean 0.15610864758491516 all mean 0.15296655893325806
0.3908650279045105 0.3908650577068329
rl training, epoch1, iter0, batch883/1133, batch loss:0.3908650577068329, Training time:2953.7693660259247
batch reward last col mean 0.1381322145462036 first col mean 0.15850642323493958 all mean 0.14653483033180237
0.39604732394218445 0.39604732394218445
rl training, epoch1, iter0, batch884/1133, batch loss:0.39604732394218445, Training time:2955.3596651554108
batch reward last col mean 0.14394143223762512 first col mean 0.1420007050037384 all mean 0.14605329930782318
0.32540202140808105 0.32540202140808105
rl training, epoch1, iter0, batch885/1133, batch loss:0.32540202140808105, Training time:2957.029529809952
batch reward last col mean 0.16199763119220734 first col mean 0.141095831990242 all mean 0.15733572840690613
0.37842899560928345 0.37842899560928345
rl training, epoch1, iter0, batch886/1133, batch loss:0.37842899560928345, Training time:2958.5922293663025
batch reward last col mean 0.14463740587234497 first col mean 0.14373886585235596 all mean 0.14765141904354095
0.3997930586338043 0.3997930586338043
rl training, epoch1, iter0, batch887/1133, batch loss:0.3997930586338043, Training time:2960.476403236389
batch reward last col mean 0.10090398788452148 first col mean 0.13910004496574402 all mean 0.11231021583080292
0.37927183508872986 0.3792717754840851
rl training, epoch1, iter0, batch888/1133, batch loss:0.3792717754840851, Training time:2962.488113641739
batch reward last col mean 0.10801680386066437 first col mean 0.1452094316482544 all mean 0.12260619550943375
0.3561300039291382 0.3561300039291382
rl training, epoch1, iter0, batch889/1133, batch loss:0.3561300039291382, Training time:2964.525854587555
batch reward last col mean 0.1524403691291809 first col mean 0.1547306776046753 all mean 0.14907224476337433
0.3392060697078705 0.3392060697078705
rl training, epoch1, iter0, batch890/1133, batch loss:0.3392060697078705, Training time:2966.4933857917786
batch reward last col mean 0.13795919716358185 first col mean 0.15058542788028717 all mean 0.1431269645690918
0.36589422821998596 0.36589422821998596
rl training, epoch1, iter0, batch891/1133, batch loss:0.36589422821998596, Training time:2968.084518432617
batch reward last col mean 0.12299792468547821 first col mean 0.14745385944843292 all mean 0.1266123503446579
0.36361101269721985 0.36361101269721985
rl training, epoch1, iter0, batch892/1133, batch loss:0.36361101269721985, Training time:2969.608864545822
batch reward last col mean 0.15547600388526917 first col mean 0.14172300696372986 all mean 0.149876669049263
0.361392617225647 0.361392617225647
rl training, epoch1, iter0, batch893/1133, batch loss:0.361392617225647, Training time:2971.342173099518
batch reward last col mean 0.1346036195755005 first col mean 0.15264415740966797 all mean 0.13996708393096924
0.35751956701278687 0.35751956701278687
rl training, epoch1, iter0, batch894/1133, batch loss:0.35751956701278687, Training time:2973.0274119377136
batch reward last col mean 0.125464528799057 first col mean 0.15771730244159698 all mean 0.12936849892139435
0.33029165863990784 0.33029159903526306
rl training, epoch1, iter0, batch895/1133, batch loss:0.33029159903526306, Training time:2974.805389404297
batch reward last col mean 0.14746196568012238 first col mean 0.14543257653713226 all mean 0.15043115615844727
0.4001515805721283 0.4001515805721283
rl training, epoch1, iter0, batch896/1133, batch loss:0.4001515805721283, Training time:2977.104148864746
batch reward last col mean 0.09221328794956207 first col mean 0.1500265896320343 all mean 0.10788048058748245
0.3385508954524994 0.3385508954524994
rl training, epoch1, iter0, batch897/1133, batch loss:0.3385508954524994, Training time:2978.736804485321
batch reward last col mean 0.1484677791595459 first col mean 0.13618144392967224 all mean 0.14981167018413544
0.40714189410209656 0.40714189410209656
rl training, epoch1, iter0, batch898/1133, batch loss:0.40714189410209656, Training time:2980.1353051662445
batch reward last col mean 0.12192770838737488 first col mean 0.14968104660511017 all mean 0.12464595586061478
0.35504475235939026 0.35504475235939026
rl training, epoch1, iter0, batch899/1133, batch loss:0.35504475235939026, Training time:2981.8637430667877
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5739007193434059 Time: 96.67046618461609 s
loss of true 0.2621728257594231 loss of gen 0.1737857944375629 loss of other 0.13794209917601188 first score 0.12951777875423431
batch reward last col mean 0.09139072149991989 first col mean 0.09356217086315155 all mean 0.09353386610746384
0.2274162322282791 0.2274162322282791
rl training, epoch1, iter0, batch900/1133, batch loss:0.2274162322282791, Training time:3080.5160326957703
batch reward last col mean 0.09231841564178467 first col mean 0.09733182936906815 all mean 0.09367270022630692
0.2562809884548187 0.2562809884548187
rl training, epoch1, iter0, batch901/1133, batch loss:0.2562809884548187, Training time:3082.540795326233
batch reward last col mean 0.10217072814702988 first col mean 0.0827968567609787 all mean 0.10479268431663513
0.266076922416687 0.266076922416687
rl training, epoch1, iter0, batch902/1133, batch loss:0.266076922416687, Training time:3084.474440097809
batch reward last col mean 0.08655595779418945 first col mean 0.08024707436561584 all mean 0.09319955855607986
0.2597414255142212 0.2597414255142212
rl training, epoch1, iter0, batch903/1133, batch loss:0.2597414255142212, Training time:3086.7071731090546
batch reward last col mean 0.10325906425714493 first col mean 0.0989803746342659 all mean 0.10209203511476517
0.27194344997406006 0.27194342017173767
rl training, epoch1, iter0, batch904/1133, batch loss:0.27194342017173767, Training time:3088.7618777751923
batch reward last col mean 0.0976841151714325 first col mean 0.1036282330751419 all mean 0.10097876936197281
0.28540903329849243 0.28540903329849243
rl training, epoch1, iter0, batch905/1133, batch loss:0.28540903329849243, Training time:3090.503557443619
batch reward last col mean 0.08588361740112305 first col mean 0.09287811070680618 all mean 0.08760581910610199
0.24068117141723633 0.24068117141723633
rl training, epoch1, iter0, batch906/1133, batch loss:0.24068117141723633, Training time:3092.4456071853638
batch reward last col mean 0.10138700157403946 first col mean 0.09311147779226303 all mean 0.1019216775894165
0.2729337215423584 0.2729337215423584
rl training, epoch1, iter0, batch907/1133, batch loss:0.2729337215423584, Training time:3094.522438764572
batch reward last col mean 0.0909229964017868 first col mean 0.08568758517503738 all mean 0.09555082023143768
0.2992132604122162 0.2992132604122162
rl training, epoch1, iter0, batch908/1133, batch loss:0.2992132604122162, Training time:3096.0867919921875
batch reward last col mean 0.10707469284534454 first col mean 0.09877155721187592 all mean 0.10805758833885193
0.24982622265815735 0.24982622265815735
rl training, epoch1, iter0, batch909/1133, batch loss:0.24982622265815735, Training time:3099.081015586853
batch reward last col mean 0.10111931711435318 first col mean 0.10438954085111618 all mean 0.09823182225227356
0.3356490135192871 0.3356490135192871
rl training, epoch1, iter0, batch910/1133, batch loss:0.3356490135192871, Training time:3101.05739402771
batch reward last col mean 0.12123755365610123 first col mean 0.09693440049886703 all mean 0.11394259333610535
0.28976818919181824 0.28976818919181824
rl training, epoch1, iter0, batch911/1133, batch loss:0.28976818919181824, Training time:3103.1029822826385
batch reward last col mean 0.08131004869937897 first col mean 0.0980304628610611 all mean 0.08764402568340302
0.27169644832611084 0.27169644832611084
rl training, epoch1, iter0, batch912/1133, batch loss:0.27169644832611084, Training time:3105.2409629821777
batch reward last col mean 0.08050841093063354 first col mean 0.0965929627418518 all mean 0.08585923165082932
0.2817751169204712 0.2817750871181488
rl training, epoch1, iter0, batch913/1133, batch loss:0.2817750871181488, Training time:3106.905017375946
batch reward last col mean 0.10538850724697113 first col mean 0.10883359611034393 all mean 0.10314077138900757
0.27084070444107056 0.27084070444107056
rl training, epoch1, iter0, batch914/1133, batch loss:0.27084070444107056, Training time:3109.188663482666
batch reward last col mean 0.0671539455652237 first col mean 0.09464138746261597 all mean 0.07629857212305069
0.257065087556839 0.257065087556839
rl training, epoch1, iter0, batch915/1133, batch loss:0.257065087556839, Training time:3111.411530971527
batch reward last col mean 0.15489935874938965 first col mean 0.10506049543619156 all mean 0.14103715121746063
0.3731994330883026 0.3731994330883026
rl training, epoch1, iter0, batch916/1133, batch loss:0.3731994330883026, Training time:3113.2724783420563
batch reward last col mean 0.09382714331150055 first col mean 0.11024630069732666 all mean 0.09726116806268692
0.29581889510154724 0.29581889510154724
rl training, epoch1, iter0, batch917/1133, batch loss:0.29581889510154724, Training time:3115.3945672512054
batch reward last col mean 0.11656773090362549 first col mean 0.11337311565876007 all mean 0.11137709021568298
0.34911981225013733 0.34911981225013733
rl training, epoch1, iter0, batch918/1133, batch loss:0.34911981225013733, Training time:3117.591732263565
batch reward last col mean 0.10388276726007462 first col mean 0.12194952368736267 all mean 0.10484980791807175
0.29920852184295654 0.29920852184295654
rl training, epoch1, iter0, batch919/1133, batch loss:0.29920852184295654, Training time:3120.508901119232
batch reward last col mean 0.12421108037233353 first col mean 0.11524376273155212 all mean 0.12247025221586227
0.29830095171928406 0.29830095171928406
rl training, epoch1, iter0, batch920/1133, batch loss:0.29830095171928406, Training time:3124.139813184738
batch reward last col mean 0.12245988100767136 first col mean 0.10674813389778137 all mean 0.11559414118528366
0.32778045535087585 0.32778045535087585
rl training, epoch1, iter0, batch921/1133, batch loss:0.32778045535087585, Training time:3126.502806663513
batch reward last col mean 0.11710325628519058 first col mean 0.11038373410701752 all mean 0.1164039745926857
0.34973663091659546 0.34973663091659546
rl training, epoch1, iter0, batch922/1133, batch loss:0.34973663091659546, Training time:3128.4683339595795
batch reward last col mean 0.07996684312820435 first col mean 0.09210705012083054 all mean 0.08663330972194672
0.2445339560508728 0.2445339560508728
rl training, epoch1, iter0, batch923/1133, batch loss:0.2445339560508728, Training time:3130.372262954712
batch reward last col mean 0.12059563398361206 first col mean 0.10899627953767776 all mean 0.11773045361042023
0.346702516078949 0.34670254588127136
rl training, epoch1, iter0, batch924/1133, batch loss:0.34670254588127136, Training time:3132.4822673797607
batch reward last col mean 0.08588303625583649 first col mean 0.12067195028066635 all mean 0.0893746092915535
0.2614287734031677 0.2614287734031677
rl training, epoch1, iter0, batch925/1133, batch loss:0.2614287734031677, Training time:3134.8508150577545
batch reward last col mean 0.11736899614334106 first col mean 0.10457579791545868 all mean 0.1123877763748169
0.3666035234928131 0.3666034936904907
rl training, epoch1, iter0, batch926/1133, batch loss:0.3666034936904907, Training time:3136.8924736976624
batch reward last col mean 0.11841577291488647 first col mean 0.09923578798770905 all mean 0.11737889051437378
0.3439735472202301 0.3439735472202301
rl training, epoch1, iter0, batch927/1133, batch loss:0.3439735472202301, Training time:3138.66997218132
batch reward last col mean 0.11081386357545853 first col mean 0.1088917925953865 all mean 0.11061922460794449
0.3125607669353485 0.3125607669353485
rl training, epoch1, iter0, batch928/1133, batch loss:0.3125607669353485, Training time:3141.055867910385
batch reward last col mean 0.13922671973705292 first col mean 0.11352365463972092 all mean 0.13263170421123505
0.355353444814682 0.355353444814682
rl training, epoch1, iter0, batch929/1133, batch loss:0.355353444814682, Training time:3143.108030796051
batch reward last col mean 0.12122951447963715 first col mean 0.12027693539857864 all mean 0.11886431276798248
0.3726637661457062 0.3726637661457062
rl training, epoch1, iter0, batch930/1133, batch loss:0.3726637661457062, Training time:3145.3167679309845
batch reward last col mean 0.11300907284021378 first col mean 0.11183622479438782 all mean 0.11165223270654678
0.314277321100235 0.3142773509025574
rl training, epoch1, iter0, batch931/1133, batch loss:0.3142773509025574, Training time:3147.197160959244
batch reward last col mean 0.09095041453838348 first col mean 0.14129400253295898 all mean 0.10012390464544296
0.3055976629257202 0.3055976331233978
rl training, epoch1, iter0, batch932/1133, batch loss:0.3055976331233978, Training time:3149.0281705856323
batch reward last col mean 0.08106042444705963 first col mean 0.10495885461568832 all mean 0.09490083903074265
0.2962721884250641 0.2962721884250641
rl training, epoch1, iter0, batch933/1133, batch loss:0.2962721884250641, Training time:3150.8012506961823
batch reward last col mean 0.1595272719860077 first col mean 0.11852432787418365 all mean 0.1520601361989975
0.33307740092277527 0.33307740092277527
rl training, epoch1, iter0, batch934/1133, batch loss:0.33307740092277527, Training time:3153.271717071533
batch reward last col mean 0.08798110485076904 first col mean 0.10725574195384979 all mean 0.09772051125764847
0.3223077058792114 0.3223077058792114
rl training, epoch1, iter0, batch935/1133, batch loss:0.3223077058792114, Training time:3155.664173603058
batch reward last col mean 0.1303664743900299 first col mean 0.10779354721307755 all mean 0.12697258591651917
0.3436617851257324 0.3436617851257324
rl training, epoch1, iter0, batch936/1133, batch loss:0.3436617851257324, Training time:3157.50523352623
batch reward last col mean 0.12612110376358032 first col mean 0.11383760720491409 all mean 0.11867711693048477
0.34597882628440857 0.34597882628440857
rl training, epoch1, iter0, batch937/1133, batch loss:0.34597882628440857, Training time:3159.7971642017365
batch reward last col mean 0.15298934280872345 first col mean 0.12529826164245605 all mean 0.14296171069145203
0.374525785446167 0.374525785446167
rl training, epoch1, iter0, batch938/1133, batch loss:0.374525785446167, Training time:3161.2726242542267
batch reward last col mean 0.12725014984607697 first col mean 0.13543792068958282 all mean 0.13324199616909027
0.3741967976093292 0.3741967976093292
rl training, epoch1, iter0, batch939/1133, batch loss:0.3741967976093292, Training time:3164.4648580551147
batch reward last col mean 0.12079910188913345 first col mean 0.12282347679138184 all mean 0.12255889177322388
0.3681924045085907 0.3681924343109131
rl training, epoch1, iter0, batch940/1133, batch loss:0.3681924343109131, Training time:3166.6457040309906
batch reward last col mean 0.1413460373878479 first col mean 0.1164548397064209 all mean 0.13479410111904144
0.3826097846031189 0.3826097846031189
rl training, epoch1, iter0, batch941/1133, batch loss:0.3826097846031189, Training time:3168.7937273979187
batch reward last col mean 0.11204294860363007 first col mean 0.13509634137153625 all mean 0.1166546568274498
0.3746306598186493 0.3746306598186493
rl training, epoch1, iter0, batch942/1133, batch loss:0.3746306598186493, Training time:3171.111249923706
batch reward last col mean 0.12920325994491577 first col mean 0.12070271372795105 all mean 0.12958091497421265
0.39562514424324036 0.39562514424324036
rl training, epoch1, iter0, batch943/1133, batch loss:0.39562514424324036, Training time:3173.0171508789062
batch reward last col mean 0.12410923838615417 first col mean 0.12062990665435791 all mean 0.12440988421440125
0.3841598331928253 0.3841598331928253
rl training, epoch1, iter0, batch944/1133, batch loss:0.3841598331928253, Training time:3174.7462871074677
batch reward last col mean 0.12348571419715881 first col mean 0.11943155527114868 all mean 0.13104704022407532
0.4086647033691406 0.4086647033691406
rl training, epoch1, iter0, batch945/1133, batch loss:0.4086647033691406, Training time:3177.026358127594
batch reward last col mean 0.14532899856567383 first col mean 0.12643153965473175 all mean 0.13042351603507996
0.35736802220344543 0.35736799240112305
rl training, epoch1, iter0, batch946/1133, batch loss:0.35736799240112305, Training time:3178.8991594314575
batch reward last col mean 0.09857932478189468 first col mean 0.133037269115448 all mean 0.10881250351667404
0.3624238967895508 0.3624238967895508
rl training, epoch1, iter0, batch947/1133, batch loss:0.3624238967895508, Training time:3180.563848733902
batch reward last col mean 0.127736896276474 first col mean 0.14426137506961823 all mean 0.12671680748462677
0.38866108655929565 0.38866108655929565
rl training, epoch1, iter0, batch948/1133, batch loss:0.38866108655929565, Training time:3182.535463809967
batch reward last col mean 0.13372348248958588 first col mean 0.12408307194709778 all mean 0.12891508638858795
0.4137762784957886 0.4137762784957886
rl training, epoch1, iter0, batch949/1133, batch loss:0.4137762784957886, Training time:3184.7254722118378
batch reward last col mean 0.1350933462381363 first col mean 0.11114002764225006 all mean 0.13434861600399017
0.3884020149707794 0.3884020149707794
rl training, epoch1, iter0, batch950/1133, batch loss:0.3884020149707794, Training time:3186.563234090805
batch reward last col mean 0.14570161700248718 first col mean 0.13847413659095764 all mean 0.13903020322322845
0.37853536009788513 0.37853536009788513
rl training, epoch1, iter0, batch951/1133, batch loss:0.37853536009788513, Training time:3189.0325062274933
batch reward last col mean 0.10301749408245087 first col mean 0.11914156377315521 all mean 0.10591866821050644
0.34608525037765503 0.34608525037765503
rl training, epoch1, iter0, batch952/1133, batch loss:0.34608525037765503, Training time:3191.1392850875854
batch reward last col mean 0.1393914818763733 first col mean 0.12280693650245667 all mean 0.1365700215101242
0.36541029810905457 0.36541029810905457
rl training, epoch1, iter0, batch953/1133, batch loss:0.36541029810905457, Training time:3192.9592649936676
batch reward last col mean 0.13623297214508057 first col mean 0.12279271334409714 all mean 0.13468104600906372
0.36319807171821594 0.36319810152053833
rl training, epoch1, iter0, batch954/1133, batch loss:0.36319810152053833, Training time:3195.3145434856415
batch reward last col mean 0.114204540848732 first col mean 0.12436967343091965 all mean 0.11667285859584808
0.36077991127967834 0.36077991127967834
rl training, epoch1, iter0, batch955/1133, batch loss:0.36077991127967834, Training time:3197.056238889694
batch reward last col mean 0.11732155829668045 first col mean 0.14063410460948944 all mean 0.1237398087978363
0.3734769821166992 0.3734770119190216
rl training, epoch1, iter0, batch956/1133, batch loss:0.3734770119190216, Training time:3198.8642354011536
batch reward last col mean 0.15758252143859863 first col mean 0.1760743111371994 all mean 0.15526120364665985
0.46438491344451904 0.46438491344451904
rl training, epoch1, iter0, batch957/1133, batch loss:0.46438491344451904, Training time:3200.9422528743744
batch reward last col mean 0.10983886569738388 first col mean 0.11612820625305176 all mean 0.11885469406843185
0.3969930410385132 0.3969929814338684
rl training, epoch1, iter0, batch958/1133, batch loss:0.3969929814338684, Training time:3203.249767780304
batch reward last col mean 0.1300177127122879 first col mean 0.12274784594774246 all mean 0.1259232759475708
0.38258102536201477 0.38258102536201477
rl training, epoch1, iter0, batch959/1133, batch loss:0.38258102536201477, Training time:3205.6951262950897
batch reward last col mean 0.15190079808235168 first col mean 0.14437128603458405 all mean 0.14091183245182037
0.4105284512042999 0.41052842140197754
rl training, epoch1, iter0, batch960/1133, batch loss:0.41052842140197754, Training time:3207.887864112854
batch reward last col mean 0.16325224936008453 first col mean 0.14632439613342285 all mean 0.1572951376438141
0.41667741537094116 0.41667741537094116
rl training, epoch1, iter0, batch961/1133, batch loss:0.41667741537094116, Training time:3209.865047454834
batch reward last col mean 0.12559323012828827 first col mean 0.11990399658679962 all mean 0.12714526057243347
0.3941381573677063 0.3941381573677063
rl training, epoch1, iter0, batch962/1133, batch loss:0.3941381573677063, Training time:3212.3247067928314
batch reward last col mean 0.15988171100616455 first col mean 0.1437772661447525 all mean 0.158254936337471
0.4944080710411072 0.4944080710411072
rl training, epoch1, iter0, batch963/1133, batch loss:0.4944080710411072, Training time:3214.3903546333313
batch reward last col mean 0.14652927219867706 first col mean 0.12610924243927002 all mean 0.14600084722042084
0.4786626696586609 0.4786626696586609
rl training, epoch1, iter0, batch964/1133, batch loss:0.4786626696586609, Training time:3216.7246074676514
batch reward last col mean 0.10768601298332214 first col mean 0.13953369855880737 all mean 0.11528322100639343
0.37972477078437805 0.37972477078437805
rl training, epoch1, iter0, batch965/1133, batch loss:0.37972477078437805, Training time:3218.449840068817
batch reward last col mean 0.12486911565065384 first col mean 0.14772053062915802 all mean 0.1336921900510788
0.4619017541408539 0.4619017243385315
rl training, epoch1, iter0, batch966/1133, batch loss:0.4619017243385315, Training time:3220.508342027664
batch reward last col mean 0.13160286843776703 first col mean 0.13784779608249664 all mean 0.1368464231491089
0.42063629627227783 0.42063629627227783
rl training, epoch1, iter0, batch967/1133, batch loss:0.42063629627227783, Training time:3222.6659002304077
batch reward last col mean 0.13138853013515472 first col mean 0.12795013189315796 all mean 0.13238921761512756
0.43047165870666504 0.43047159910202026
rl training, epoch1, iter0, batch968/1133, batch loss:0.43047159910202026, Training time:3224.976030111313
batch reward last col mean 0.14664071798324585 first col mean 0.13971370458602905 all mean 0.14182418584823608
0.4253425896167755 0.4253425896167755
rl training, epoch1, iter0, batch969/1133, batch loss:0.4253425896167755, Training time:3226.91703248024
batch reward last col mean 0.14757657051086426 first col mean 0.15021368861198425 all mean 0.147172212600708
0.4861808121204376 0.4861808121204376
rl training, epoch1, iter0, batch970/1133, batch loss:0.4861808121204376, Training time:3228.6325573921204
batch reward last col mean 0.1527395397424698 first col mean 0.13895371556282043 all mean 0.14871513843536377
0.4508885443210602 0.4508885443210602
rl training, epoch1, iter0, batch971/1133, batch loss:0.4508885443210602, Training time:3230.6554231643677
batch reward last col mean 0.12404953688383102 first col mean 0.1397559940814972 all mean 0.12888845801353455
0.4092487692832947 0.4092487692832947
rl training, epoch1, iter0, batch972/1133, batch loss:0.4092487692832947, Training time:3232.154352903366
batch reward last col mean 0.13627561926841736 first col mean 0.14635346829891205 all mean 0.1391422301530838
0.40375056862831116 0.40375059843063354
rl training, epoch1, iter0, batch973/1133, batch loss:0.40375059843063354, Training time:3233.7189824581146
batch reward last col mean 0.17511937022209167 first col mean 0.17839756608009338 all mean 0.17413224279880524
0.5204253792762756 0.5204253792762756
rl training, epoch1, iter0, batch974/1133, batch loss:0.5204253792762756, Training time:3235.864562511444
batch reward last col mean 0.1419498324394226 first col mean 0.14506979286670685 all mean 0.1441132128238678
0.4395589828491211 0.4395589828491211
rl training, epoch1, iter0, batch975/1133, batch loss:0.4395589828491211, Training time:3237.872188091278
batch reward last col mean 0.15308871865272522 first col mean 0.1307237148284912 all mean 0.14524154365062714
0.47176945209503174 0.47176945209503174
rl training, epoch1, iter0, batch976/1133, batch loss:0.47176945209503174, Training time:3239.398848056793
batch reward last col mean 0.14207395911216736 first col mean 0.1334371566772461 all mean 0.13727250695228577
0.4283243417739868 0.42832431197166443
rl training, epoch1, iter0, batch977/1133, batch loss:0.42832431197166443, Training time:3241.617294073105
batch reward last col mean 0.10951417684555054 first col mean 0.12333294004201889 all mean 0.12300265580415726
0.3864821195602417 0.3864821195602417
rl training, epoch1, iter0, batch978/1133, batch loss:0.3864821195602417, Training time:3243.717003583908
batch reward last col mean 0.13699696958065033 first col mean 0.14428716897964478 all mean 0.14046475291252136
0.4889459013938904 0.4889459013938904
rl training, epoch1, iter0, batch979/1133, batch loss:0.4889459013938904, Training time:3246.092764854431
batch reward last col mean 0.16346611082553864 first col mean 0.15455952286720276 all mean 0.1592199206352234
0.4772240221500397 0.4772239625453949
rl training, epoch1, iter0, batch980/1133, batch loss:0.4772239625453949, Training time:3247.9796435832977
batch reward last col mean 0.15451876819133759 first col mean 0.1509164571762085 all mean 0.15206877887248993
0.5077811479568481 0.5077811479568481
rl training, epoch1, iter0, batch981/1133, batch loss:0.5077811479568481, Training time:3250.039555311203
batch reward last col mean 0.11953473836183548 first col mean 0.14001303911209106 all mean 0.12609654664993286
0.4245528280735016 0.4245528280735016
rl training, epoch1, iter0, batch982/1133, batch loss:0.4245528280735016, Training time:3251.8110032081604
batch reward last col mean 0.16847407817840576 first col mean 0.15084096789360046 all mean 0.16342316567897797
0.49958720803260803 0.4995872378349304
rl training, epoch1, iter0, batch983/1133, batch loss:0.4995872378349304, Training time:3254.1958241462708
batch reward last col mean 0.18139663338661194 first col mean 0.14656510949134827 all mean 0.17639002203941345
0.5685749053955078 0.5685749053955078
rl training, epoch1, iter0, batch984/1133, batch loss:0.5685749053955078, Training time:3256.548723459244
batch reward last col mean 0.12085071206092834 first col mean 0.12535113096237183 all mean 0.12861983478069305
0.4473125636577606 0.4473125636577606
rl training, epoch1, iter0, batch985/1133, batch loss:0.4473125636577606, Training time:3258.5024218559265
batch reward last col mean 0.15374834835529327 first col mean 0.14048141241073608 all mean 0.15862520039081573
0.5064250826835632 0.5064250826835632
rl training, epoch1, iter0, batch986/1133, batch loss:0.5064250826835632, Training time:3260.349326610565
batch reward last col mean 0.18259494006633759 first col mean 0.15860404074192047 all mean 0.1720634251832962
0.5322588682174683 0.5322588682174683
rl training, epoch1, iter0, batch987/1133, batch loss:0.5322588682174683, Training time:3262.3322150707245
batch reward last col mean 0.14001214504241943 first col mean 0.145137757062912 all mean 0.13587968051433563
0.41077154874801636 0.41077154874801636
rl training, epoch1, iter0, batch988/1133, batch loss:0.41077154874801636, Training time:3264.028734922409
batch reward last col mean 0.12207116931676865 first col mean 0.16509318351745605 all mean 0.12557286024093628
0.4229438900947571 0.4229438900947571
rl training, epoch1, iter0, batch989/1133, batch loss:0.4229438900947571, Training time:3266.028396844864
batch reward last col mean 0.16274690628051758 first col mean 0.11922243237495422 all mean 0.16205477714538574
0.5396217703819275 0.5396217703819275
rl training, epoch1, iter0, batch990/1133, batch loss:0.5396217703819275, Training time:3268.6643702983856
batch reward last col mean 0.17003341019153595 first col mean 0.1365349143743515 all mean 0.16391967236995697
0.5246991515159607 0.5246991515159607
rl training, epoch1, iter0, batch991/1133, batch loss:0.5246991515159607, Training time:3270.3064844608307
batch reward last col mean 0.18903909623622894 first col mean 0.16047455370426178 all mean 0.1845286637544632
0.5792635679244995 0.5792635679244995
rl training, epoch1, iter0, batch992/1133, batch loss:0.5792635679244995, Training time:3272.283408641815
batch reward last col mean 0.11088267713785172 first col mean 0.149384006857872 all mean 0.11959899961948395
0.4160691797733307 0.4160691499710083
rl training, epoch1, iter0, batch993/1133, batch loss:0.4160691499710083, Training time:3274.066395521164
batch reward last col mean 0.16095024347305298 first col mean 0.1431751698255539 all mean 0.15528123080730438
0.44886085391044617 0.44886085391044617
rl training, epoch1, iter0, batch994/1133, batch loss:0.44886085391044617, Training time:3275.928354024887
batch reward last col mean 0.1551039218902588 first col mean 0.13604126870632172 all mean 0.15061204135417938
0.5239232182502747 0.5239231586456299
rl training, epoch1, iter0, batch995/1133, batch loss:0.5239231586456299, Training time:3277.5058307647705
batch reward last col mean 0.12936164438724518 first col mean 0.14097651839256287 all mean 0.13491789996623993
0.469978004693985 0.469978004693985
rl training, epoch1, iter0, batch996/1133, batch loss:0.469978004693985, Training time:3279.7202892303467
batch reward last col mean 0.14946499466896057 first col mean 0.1398327797651291 all mean 0.1518746316432953
0.4735215902328491 0.4735215902328491
rl training, epoch1, iter0, batch997/1133, batch loss:0.4735215902328491, Training time:3282.2884378433228
batch reward last col mean 0.14524051547050476 first col mean 0.1477583646774292 all mean 0.14911487698554993
0.5222357511520386 0.5222357511520386
rl training, epoch1, iter0, batch998/1133, batch loss:0.5222357511520386, Training time:3284.555233001709
batch reward last col mean 0.15922652184963226 first col mean 0.15086309611797333 all mean 0.1558697372674942
0.5389096140861511 0.5389096140861511
rl training, epoch1, iter0, batch999/1133, batch loss:0.5389096140861511, Training time:3287.008756160736
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5692307020275338 Time: 97.20962142944336 s
loss of true 0.25715346463412597 loss of gen 0.1725138220393542 loss of other 0.13956341513704643 first score 0.14800086617469788
batch reward last col mean 0.09463194012641907 first col mean 0.10009471327066422 all mean 0.0962444320321083
0.2893681526184082 0.2893681526184082
rl training, epoch1, iter0, batch1000/1133, batch loss:0.2893681526184082, Training time:3385.8282244205475
batch reward last col mean 0.08114147186279297 first col mean 0.10594941675662994 all mean 0.09484873712062836
0.3526592552661896 0.3526592552661896
rl training, epoch1, iter0, batch1001/1133, batch loss:0.3526592552661896, Training time:3387.5821096897125
batch reward last col mean 0.11374597251415253 first col mean 0.0911795049905777 all mean 0.10925839841365814
0.3562414348125458 0.3562414348125458
rl training, epoch1, iter0, batch1002/1133, batch loss:0.3562414348125458, Training time:3389.771866798401
batch reward last col mean 0.1100827157497406 first col mean 0.10053090751171112 all mean 0.10822013020515442
0.3226587176322937 0.3226587176322937
rl training, epoch1, iter0, batch1003/1133, batch loss:0.3226587176322937, Training time:3392.3271374702454
batch reward last col mean 0.11649095267057419 first col mean 0.1042492464184761 all mean 0.11271858960390091
0.3356805145740509 0.3356805145740509
rl training, epoch1, iter0, batch1004/1133, batch loss:0.3356805145740509, Training time:3394.3542556762695
batch reward last col mean 0.10862772166728973 first col mean 0.12851451337337494 all mean 0.10772283375263214
0.36392828822135925 0.36392828822135925
rl training, epoch1, iter0, batch1005/1133, batch loss:0.36392828822135925, Training time:3396.417629003525
batch reward last col mean 0.11084361374378204 first col mean 0.10400422662496567 all mean 0.10429362952709198
0.3148026764392853 0.3148026764392853
rl training, epoch1, iter0, batch1006/1133, batch loss:0.3148026764392853, Training time:3398.296443462372
batch reward last col mean 0.12111228704452515 first col mean 0.11918710172176361 all mean 0.11743366718292236
0.3443759083747864 0.3443758487701416
rl training, epoch1, iter0, batch1007/1133, batch loss:0.3443758487701416, Training time:3400.6256079673767
batch reward last col mean 0.13437750935554504 first col mean 0.1012345403432846 all mean 0.12131505459547043
0.365522563457489 0.3655225336551666
rl training, epoch1, iter0, batch1008/1133, batch loss:0.3655225336551666, Training time:3402.601338863373
batch reward last col mean 0.07904250919818878 first col mean 0.09063222259283066 all mean 0.08783148974180222
0.29956334829330444 0.29956334829330444
rl training, epoch1, iter0, batch1009/1133, batch loss:0.29956334829330444, Training time:3404.760179758072
batch reward last col mean 0.09538907557725906 first col mean 0.10882449150085449 all mean 0.09841059148311615
0.35179466009140015 0.35179463028907776
rl training, epoch1, iter0, batch1010/1133, batch loss:0.35179463028907776, Training time:3407.5617566108704
batch reward last col mean 0.08287177979946136 first col mean 0.10195742547512054 all mean 0.08277052640914917
0.30566632747650146 0.30566632747650146
rl training, epoch1, iter0, batch1011/1133, batch loss:0.30566632747650146, Training time:3409.4315259456635
batch reward last col mean 0.10047075152397156 first col mean 0.10508960485458374 all mean 0.10428456217050552
0.34090733528137207 0.34090733528137207
rl training, epoch1, iter0, batch1012/1133, batch loss:0.34090733528137207, Training time:3412.0068402290344
batch reward last col mean 0.08536862581968307 first col mean 0.10662274062633514 all mean 0.09155625104904175
0.28879180550575256 0.2887917757034302
rl training, epoch1, iter0, batch1013/1133, batch loss:0.2887917757034302, Training time:3414.58469581604
batch reward last col mean 0.08612694591283798 first col mean 0.10012531280517578 all mean 0.0947381928563118
0.33402350544929504 0.33402350544929504
rl training, epoch1, iter0, batch1014/1133, batch loss:0.33402350544929504, Training time:3416.5053033828735
batch reward last col mean 0.11625643074512482 first col mean 0.10102957487106323 all mean 0.11168697476387024
0.32123738527297974 0.3212374150753021
rl training, epoch1, iter0, batch1015/1133, batch loss:0.3212374150753021, Training time:3418.308153152466
batch reward last col mean 0.0721065029501915 first col mean 0.08130897581577301 all mean 0.08266439288854599
0.2833055853843689 0.2833055853843689
rl training, epoch1, iter0, batch1016/1133, batch loss:0.2833055853843689, Training time:3420.060812473297
batch reward last col mean 0.13399061560630798 first col mean 0.09109257906675339 all mean 0.1254015415906906
0.39398106932640076 0.39398106932640076
rl training, epoch1, iter0, batch1017/1133, batch loss:0.39398106932640076, Training time:3422.0604615211487
batch reward last col mean 0.11636339873075485 first col mean 0.11545167863368988 all mean 0.11478814482688904
0.3968152403831482 0.3968152403831482
rl training, epoch1, iter0, batch1018/1133, batch loss:0.3968152403831482, Training time:3423.8130960464478
batch reward last col mean 0.08921399712562561 first col mean 0.12462270259857178 all mean 0.09692880511283875
0.3515845537185669 0.3515845537185669
rl training, epoch1, iter0, batch1019/1133, batch loss:0.3515845537185669, Training time:3425.6860246658325
batch reward last col mean 0.09739530086517334 first col mean 0.1083909422159195 all mean 0.09989519417285919
0.3373810350894928 0.3373810350894928
rl training, epoch1, iter0, batch1020/1133, batch loss:0.3373810350894928, Training time:3427.476978302002
batch reward last col mean 0.12170391529798508 first col mean 0.1221989244222641 all mean 0.11779650300741196
0.3624408543109894 0.3624408543109894
rl training, epoch1, iter0, batch1021/1133, batch loss:0.3624408543109894, Training time:3429.512348175049
batch reward last col mean 0.09772051870822906 first col mean 0.12171024084091187 all mean 0.10180240869522095
0.3434419631958008 0.3434419631958008
rl training, epoch1, iter0, batch1022/1133, batch loss:0.3434419631958008, Training time:3431.6424794197083
batch reward last col mean 0.1242760419845581 first col mean 0.09493323415517807 all mean 0.11999965459108353
0.3660888671875 0.3660888671875
rl training, epoch1, iter0, batch1023/1133, batch loss:0.3660888671875, Training time:3433.5413076877594
batch reward last col mean 0.11769060045480728 first col mean 0.11002655327320099 all mean 0.11588586121797562
0.3314935266971588 0.3314935266971588
rl training, epoch1, iter0, batch1024/1133, batch loss:0.3314935266971588, Training time:3435.4079151153564
batch reward last col mean 0.0868803933262825 first col mean 0.11393795907497406 all mean 0.09268098324537277
0.31805065274238586 0.31805065274238586
rl training, epoch1, iter0, batch1025/1133, batch loss:0.31805065274238586, Training time:3437.439085483551
batch reward last col mean 0.11781992018222809 first col mean 0.12338162213563919 all mean 0.12168406695127487
0.3994463384151459 0.39944636821746826
rl training, epoch1, iter0, batch1026/1133, batch loss:0.39944636821746826, Training time:3439.975486755371
batch reward last col mean 0.12630754709243774 first col mean 0.12055456638336182 all mean 0.1225004568696022
0.4023660123348236 0.4023660123348236
rl training, epoch1, iter0, batch1027/1133, batch loss:0.4023660123348236, Training time:3441.9067783355713
batch reward last col mean 0.101796954870224 first col mean 0.11129029095172882 all mean 0.10267240554094315
0.3439271152019501 0.3439271152019501
rl training, epoch1, iter0, batch1028/1133, batch loss:0.3439271152019501, Training time:3443.8659961223602
batch reward last col mean 0.081300288438797 first col mean 0.11629791557788849 all mean 0.09173186123371124
0.32413220405578613 0.32413220405578613
rl training, epoch1, iter0, batch1029/1133, batch loss:0.32413220405578613, Training time:3445.8043551445007
batch reward last col mean 0.10277272760868073 first col mean 0.11261069029569626 all mean 0.10849764198064804
0.355930894613266 0.355930894613266
rl training, epoch1, iter0, batch1030/1133, batch loss:0.355930894613266, Training time:3447.412050962448
batch reward last col mean 0.10420522838830948 first col mean 0.12490040063858032 all mean 0.11109298467636108
0.3617510199546814 0.3617510199546814
rl training, epoch1, iter0, batch1031/1133, batch loss:0.3617510199546814, Training time:3449.5806436538696
batch reward last col mean 0.12416063249111176 first col mean 0.12311667948961258 all mean 0.1296786665916443
0.3832947909832001 0.3832947909832001
rl training, epoch1, iter0, batch1032/1133, batch loss:0.3832947909832001, Training time:3451.1853170394897
batch reward last col mean 0.12627120316028595 first col mean 0.13641716539859772 all mean 0.12863126397132874
0.37143075466156006 0.37143075466156006
rl training, epoch1, iter0, batch1033/1133, batch loss:0.37143075466156006, Training time:3453.1229066848755
batch reward last col mean 0.10461248457431793 first col mean 0.10511085391044617 all mean 0.10937900096178055
0.35265272855758667 0.35265272855758667
rl training, epoch1, iter0, batch1034/1133, batch loss:0.35265272855758667, Training time:3455.8358249664307
batch reward last col mean 0.10429681092500687 first col mean 0.1229303628206253 all mean 0.11342461407184601
0.3534572720527649 0.3534572720527649
rl training, epoch1, iter0, batch1035/1133, batch loss:0.3534572720527649, Training time:3457.963671684265
batch reward last col mean 0.15216493606567383 first col mean 0.12369722127914429 all mean 0.14715589582920074
0.38021376729011536 0.38021376729011536
rl training, epoch1, iter0, batch1036/1133, batch loss:0.38021376729011536, Training time:3460.5182962417603
batch reward last col mean 0.11546844244003296 first col mean 0.12333447486162186 all mean 0.11862747371196747
0.41690564155578613 0.41690564155578613
rl training, epoch1, iter0, batch1037/1133, batch loss:0.41690564155578613, Training time:3462.5749151706696
batch reward last col mean 0.14306500554084778 first col mean 0.11351331323385239 all mean 0.14001937210559845
0.37941351532936096 0.37941351532936096
rl training, epoch1, iter0, batch1038/1133, batch loss:0.37941351532936096, Training time:3464.6359729766846
batch reward last col mean 0.16667446494102478 first col mean 0.14067652821540833 all mean 0.16579924523830414
0.5175340175628662 0.5175340175628662
rl training, epoch1, iter0, batch1039/1133, batch loss:0.5175340175628662, Training time:3466.365898370743
batch reward last col mean 0.12482355535030365 first col mean 0.12999117374420166 all mean 0.12529109418392181
0.36204349994659424 0.36204349994659424
rl training, epoch1, iter0, batch1040/1133, batch loss:0.36204349994659424, Training time:3468.2293798923492
batch reward last col mean 0.13937504589557648 first col mean 0.14452022314071655 all mean 0.13566803932189941
0.3885500729084015 0.3885500729084015
rl training, epoch1, iter0, batch1041/1133, batch loss:0.3885500729084015, Training time:3470.204427242279
batch reward last col mean 0.11328380554914474 first col mean 0.12077097594738007 all mean 0.11561446636915207
0.3944604992866516 0.3944604992866516
rl training, epoch1, iter0, batch1042/1133, batch loss:0.3944604992866516, Training time:3472.6871135234833
batch reward last col mean 0.14589205384254456 first col mean 0.13457314670085907 all mean 0.14100709557533264
0.39541095495224 0.39541095495224
rl training, epoch1, iter0, batch1043/1133, batch loss:0.39541095495224, Training time:3474.7611000537872
batch reward last col mean 0.12285876274108887 first col mean 0.13409385085105896 all mean 0.12865108251571655
0.4147830307483673 0.4147830307483673
rl training, epoch1, iter0, batch1044/1133, batch loss:0.4147830307483673, Training time:3476.9219377040863
batch reward last col mean 0.12104900926351547 first col mean 0.14145979285240173 all mean 0.1247575655579567
0.3802129924297333 0.3802129924297333
rl training, epoch1, iter0, batch1045/1133, batch loss:0.3802129924297333, Training time:3478.9328982830048
batch reward last col mean 0.1751965582370758 first col mean 0.13313256204128265 all mean 0.16617095470428467
0.394482284784317 0.394482284784317
rl training, epoch1, iter0, batch1046/1133, batch loss:0.394482284784317, Training time:3481.18803858757
batch reward last col mean 0.1571625918149948 first col mean 0.1288209855556488 all mean 0.14523610472679138
0.43609002232551575 0.43608999252319336
rl training, epoch1, iter0, batch1047/1133, batch loss:0.43608999252319336, Training time:3483.0400297641754
batch reward last col mean 0.1563633680343628 first col mean 0.15249398350715637 all mean 0.15599572658538818
0.4511352479457855 0.4511352479457855
rl training, epoch1, iter0, batch1048/1133, batch loss:0.4511352479457855, Training time:3485.070740699768
batch reward last col mean 0.14574389159679413 first col mean 0.1434217095375061 all mean 0.1454942673444748
0.42227616906166077 0.42227616906166077
rl training, epoch1, iter0, batch1049/1133, batch loss:0.42227616906166077, Training time:3486.701085090637
batch reward last col mean 0.11692026257514954 first col mean 0.1360241323709488 all mean 0.12246926128864288
0.36322271823883057 0.36322271823883057
rl training, epoch1, iter0, batch1050/1133, batch loss:0.36322271823883057, Training time:3488.5573601722717
batch reward last col mean 0.14097732305526733 first col mean 0.16489002108573914 all mean 0.1448122262954712
0.3913790285587311 0.3913790285587311
rl training, epoch1, iter0, batch1051/1133, batch loss:0.3913790285587311, Training time:3490.6124670505524
batch reward last col mean 0.13166207075119019 first col mean 0.12067610025405884 all mean 0.13074292242527008
0.3459264636039734 0.3459264636039734
rl training, epoch1, iter0, batch1052/1133, batch loss:0.3459264636039734, Training time:3492.6647238731384
batch reward last col mean 0.14322179555892944 first col mean 0.1591314971446991 all mean 0.14778994023799896
0.4182395040988922 0.4182395040988922
rl training, epoch1, iter0, batch1053/1133, batch loss:0.4182395040988922, Training time:3494.748203754425
batch reward last col mean 0.10307291895151138 first col mean 0.11273320764303207 all mean 0.11122134327888489
0.3808921277523041 0.3808921277523041
rl training, epoch1, iter0, batch1054/1133, batch loss:0.3808921277523041, Training time:3497.293393135071
batch reward last col mean 0.12276190519332886 first col mean 0.1482161432504654 all mean 0.13412465155124664
0.41173845529556274 0.41173848509788513
rl training, epoch1, iter0, batch1055/1133, batch loss:0.41173848509788513, Training time:3499.2997941970825
batch reward last col mean 0.14865896105766296 first col mean 0.1671515256166458 all mean 0.14864782989025116
0.4182117283344269 0.4182117283344269
rl training, epoch1, iter0, batch1056/1133, batch loss:0.4182117283344269, Training time:3501.3386816978455
batch reward last col mean 0.13972918689250946 first col mean 0.1366521716117859 all mean 0.14222055673599243
0.4176468551158905 0.4176468551158905
rl training, epoch1, iter0, batch1057/1133, batch loss:0.4176468551158905, Training time:3503.2666552066803
batch reward last col mean 0.11363948881626129 first col mean 0.1332901418209076 all mean 0.127826988697052
0.43492579460144043 0.43492579460144043
rl training, epoch1, iter0, batch1058/1133, batch loss:0.43492579460144043, Training time:3505.149734735489
batch reward last col mean 0.12185817211866379 first col mean 0.13348570466041565 all mean 0.13152292370796204
0.43086448311805725 0.43086448311805725
rl training, epoch1, iter0, batch1059/1133, batch loss:0.43086448311805725, Training time:3507.0821404457092
batch reward last col mean 0.18052369356155396 first col mean 0.16270025074481964 all mean 0.17730697989463806
0.5138123035430908 0.5138123035430908
rl training, epoch1, iter0, batch1060/1133, batch loss:0.5138123035430908, Training time:3509.356138944626
batch reward last col mean 0.15733174979686737 first col mean 0.13491109013557434 all mean 0.14683251082897186
0.357785701751709 0.357785701751709
rl training, epoch1, iter0, batch1061/1133, batch loss:0.357785701751709, Training time:3511.088751554489
batch reward last col mean 0.15246590971946716 first col mean 0.16718102991580963 all mean 0.1524135172367096
0.4052065908908844 0.4052065908908844
rl training, epoch1, iter0, batch1062/1133, batch loss:0.4052065908908844, Training time:3512.9638016223907
batch reward last col mean 0.1400713324546814 first col mean 0.16696162521839142 all mean 0.14215846359729767
0.40606117248535156 0.40606117248535156
rl training, epoch1, iter0, batch1063/1133, batch loss:0.40606117248535156, Training time:3514.961631298065
batch reward last col mean 0.1573179066181183 first col mean 0.15226757526397705 all mean 0.15785947442054749
0.37823212146759033 0.37823212146759033
rl training, epoch1, iter0, batch1064/1133, batch loss:0.37823212146759033, Training time:3516.8285348415375
batch reward last col mean 0.12382762879133224 first col mean 0.13755573332309723 all mean 0.13261725008487701
0.4020741283893585 0.4020741283893585
rl training, epoch1, iter0, batch1065/1133, batch loss:0.4020741283893585, Training time:3518.985912322998
batch reward last col mean 0.1507684290409088 first col mean 0.14587803184986115 all mean 0.15092162787914276
0.4368407428264618 0.4368407428264618
rl training, epoch1, iter0, batch1066/1133, batch loss:0.4368407428264618, Training time:3520.936007499695
batch reward last col mean 0.1291113644838333 first col mean 0.15245628356933594 all mean 0.14222902059555054
0.43254563212394714 0.43254563212394714
rl training, epoch1, iter0, batch1067/1133, batch loss:0.43254563212394714, Training time:3523.2627449035645
batch reward last col mean 0.10723087191581726 first col mean 0.14762097597122192 all mean 0.11433178931474686
0.35531848669052124 0.35531848669052124
rl training, epoch1, iter0, batch1068/1133, batch loss:0.35531848669052124, Training time:3525.4716238975525
batch reward last col mean 0.14196845889091492 first col mean 0.15189853310585022 all mean 0.13707587122917175
0.3885324001312256 0.3885324001312256
rl training, epoch1, iter0, batch1069/1133, batch loss:0.3885324001312256, Training time:3527.4800987243652
batch reward last col mean 0.14891475439071655 first col mean 0.14694249629974365 all mean 0.14895202219486237
0.3930078446865082 0.3930078446865082
rl training, epoch1, iter0, batch1070/1133, batch loss:0.3930078446865082, Training time:3529.8067905902863
batch reward last col mean 0.17219559848308563 first col mean 0.1467936784029007 all mean 0.16737791895866394
0.42063984274864197 0.42063984274864197
rl training, epoch1, iter0, batch1071/1133, batch loss:0.42063984274864197, Training time:3531.7972831726074
batch reward last col mean 0.13303440809249878 first col mean 0.1750154197216034 all mean 0.13590800762176514
0.3605966866016388 0.3605966866016388
rl training, epoch1, iter0, batch1072/1133, batch loss:0.3605966866016388, Training time:3534.355282306671
batch reward last col mean 0.15967752039432526 first col mean 0.17321789264678955 all mean 0.16129730641841888
0.3975656032562256 0.3975655734539032
rl training, epoch1, iter0, batch1073/1133, batch loss:0.3975655734539032, Training time:3536.2941160202026
batch reward last col mean 0.144052192568779 first col mean 0.1865614503622055 all mean 0.15202757716178894
0.44689613580703735 0.44689616560935974
rl training, epoch1, iter0, batch1074/1133, batch loss:0.44689616560935974, Training time:3538.2542703151703
batch reward last col mean 0.13915959000587463 first col mean 0.1726808249950409 all mean 0.14979635179042816
0.39851129055023193 0.39851129055023193
rl training, epoch1, iter0, batch1075/1133, batch loss:0.39851129055023193, Training time:3540.156529188156
batch reward last col mean 0.1772046983242035 first col mean 0.18388833105564117 all mean 0.17897269129753113
0.506885826587677 0.5068857669830322
rl training, epoch1, iter0, batch1076/1133, batch loss:0.5068857669830322, Training time:3542.538992881775
batch reward last col mean 0.1552349328994751 first col mean 0.15295428037643433 all mean 0.14933903515338898
0.3972990810871124 0.3972990810871124
rl training, epoch1, iter0, batch1077/1133, batch loss:0.3972990810871124, Training time:3544.948558807373
batch reward last col mean 0.18138578534126282 first col mean 0.1609303057193756 all mean 0.17652712762355804
0.4847203493118286 0.4847203493118286
rl training, epoch1, iter0, batch1078/1133, batch loss:0.4847203493118286, Training time:3549.3880548477173
batch reward last col mean 0.1468779295682907 first col mean 0.16836762428283691 all mean 0.15107384324073792
0.387769877910614 0.387769877910614
rl training, epoch1, iter0, batch1079/1133, batch loss:0.387769877910614, Training time:3551.26832818985
batch reward last col mean 0.14555177092552185 first col mean 0.1737317591905594 all mean 0.15705174207687378
0.4502885639667511 0.4502885639667511
rl training, epoch1, iter0, batch1080/1133, batch loss:0.4502885639667511, Training time:3552.9669349193573
batch reward last col mean 0.17502783238887787 first col mean 0.18619883060455322 all mean 0.17510861158370972
0.3831441402435303 0.3831441402435303
rl training, epoch1, iter0, batch1081/1133, batch loss:0.3831441402435303, Training time:3555.7102065086365
batch reward last col mean 0.16602031886577606 first col mean 0.16923505067825317 all mean 0.1718687117099762
0.4818069338798523 0.4818069338798523
rl training, epoch1, iter0, batch1082/1133, batch loss:0.4818069338798523, Training time:3557.7771365642548
batch reward last col mean 0.18472307920455933 first col mean 0.15748924016952515 all mean 0.17684932053089142
0.40056556463241577 0.400565505027771
rl training, epoch1, iter0, batch1083/1133, batch loss:0.400565505027771, Training time:3561.8151848316193
batch reward last col mean 0.1486877053976059 first col mean 0.1695459932088852 all mean 0.16065692901611328
0.44448938965797424 0.44448938965797424
rl training, epoch1, iter0, batch1084/1133, batch loss:0.44448938965797424, Training time:3563.999928712845
batch reward last col mean 0.17861399054527283 first col mean 0.17395389080047607 all mean 0.17494243383407593
0.4072861969470978 0.4072861969470978
rl training, epoch1, iter0, batch1085/1133, batch loss:0.4072861969470978, Training time:3566.453890800476
batch reward last col mean 0.14069773256778717 first col mean 0.18514065444469452 all mean 0.15129365026950836
0.43800050020217896 0.43800050020217896
rl training, epoch1, iter0, batch1086/1133, batch loss:0.43800050020217896, Training time:3568.587296962738
batch reward last col mean 0.18129390478134155 first col mean 0.17337001860141754 all mean 0.1776917278766632
0.4406321942806244 0.4406321942806244
rl training, epoch1, iter0, batch1087/1133, batch loss:0.4406321942806244, Training time:3570.534907579422
batch reward last col mean 0.1837518811225891 first col mean 0.19808152318000793 all mean 0.17636853456497192
0.4531230926513672 0.4531230926513672
rl training, epoch1, iter0, batch1088/1133, batch loss:0.4531230926513672, Training time:3572.323659181595
batch reward last col mean 0.19624623656272888 first col mean 0.15953195095062256 all mean 0.17566412687301636
0.42991313338279724 0.42991313338279724
rl training, epoch1, iter0, batch1089/1133, batch loss:0.42991313338279724, Training time:3574.457197666168
batch reward last col mean 0.16845132410526276 first col mean 0.17795711755752563 all mean 0.16074290871620178
0.4037848114967346 0.4037848114967346
rl training, epoch1, iter0, batch1090/1133, batch loss:0.4037848114967346, Training time:3576.167155981064
batch reward last col mean 0.11972051858901978 first col mean 0.17159025371074677 all mean 0.13173559308052063
0.35796990990638733 0.35796988010406494
rl training, epoch1, iter0, batch1091/1133, batch loss:0.35796988010406494, Training time:3578.3094444274902
batch reward last col mean 0.16963180899620056 first col mean 0.170951247215271 all mean 0.1661076545715332
0.45610785484313965 0.45610785484313965
rl training, epoch1, iter0, batch1092/1133, batch loss:0.45610785484313965, Training time:3580.4567601680756
batch reward last col mean 0.16569329798221588 first col mean 0.17793519794940948 all mean 0.17204773426055908
0.4327477812767029 0.4327477812767029
rl training, epoch1, iter0, batch1093/1133, batch loss:0.4327477812767029, Training time:3582.6081132888794
batch reward last col mean 0.1586579531431198 first col mean 0.19234676659107208 all mean 0.158314511179924
0.39249569177627563 0.39249569177627563
rl training, epoch1, iter0, batch1094/1133, batch loss:0.39249569177627563, Training time:3584.3368394374847
batch reward last col mean 0.19008684158325195 first col mean 0.1662495732307434 all mean 0.18689505755901337
0.4349214732646942 0.4349214732646942
rl training, epoch1, iter0, batch1095/1133, batch loss:0.4349214732646942, Training time:3586.3736205101013
batch reward last col mean 0.12945502996444702 first col mean 0.17024606466293335 all mean 0.14114508032798767
0.40892142057418823 0.40892142057418823
rl training, epoch1, iter0, batch1096/1133, batch loss:0.40892142057418823, Training time:3589.31990647316
batch reward last col mean 0.15973174571990967 first col mean 0.16868655383586884 all mean 0.1612207144498825
0.40318599343299866 0.40318599343299866
rl training, epoch1, iter0, batch1097/1133, batch loss:0.40318599343299866, Training time:3591.2210586071014
batch reward last col mean 0.17301879823207855 first col mean 0.16362544894218445 all mean 0.17730861902236938
0.4697587490081787 0.4697587490081787
rl training, epoch1, iter0, batch1098/1133, batch loss:0.4697587490081787, Training time:3593.0367348194122
batch reward last col mean 0.17269307374954224 first col mean 0.16218486428260803 all mean 0.1737530678510666
0.44866809248924255 0.44866809248924255
rl training, epoch1, iter0, batch1099/1133, batch loss:0.44866809248924255, Training time:3595.4109449386597
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5673644557424278 Time: 99.10722804069519 s
loss of true 0.2595195562988914 loss of gen 0.1701243932030944 loss of other 0.13772050615495426 first score 0.16780757904052734
batch reward last col mean 0.10049286484718323 first col mean 0.10365913808345795 all mean 0.10492821782827377
0.299395889043808 0.299395889043808
rl training, epoch1, iter0, batch1100/1133, batch loss:0.299395889043808, Training time:3696.9707095623016
batch reward last col mean 0.136269211769104 first col mean 0.12390673160552979 all mean 0.12830166518688202
0.3183237910270691 0.3183237910270691
rl training, epoch1, iter0, batch1101/1133, batch loss:0.3183237910270691, Training time:3699.0507352352142
batch reward last col mean 0.11090686917304993 first col mean 0.10215260833501816 all mean 0.11313607543706894
0.29463106393814087 0.29463106393814087
rl training, epoch1, iter0, batch1102/1133, batch loss:0.29463106393814087, Training time:3700.968884706497
batch reward last col mean 0.1341000348329544 first col mean 0.12436632066965103 all mean 0.13256898522377014
0.33410122990608215 0.33410122990608215
rl training, epoch1, iter0, batch1103/1133, batch loss:0.33410122990608215, Training time:3702.6991670131683
batch reward last col mean 0.09929157793521881 first col mean 0.10955607146024704 all mean 0.10140446573495865
0.26845937967300415 0.26845937967300415
rl training, epoch1, iter0, batch1104/1133, batch loss:0.26845937967300415, Training time:3704.555892467499
batch reward last col mean 0.11716629564762115 first col mean 0.11175951361656189 all mean 0.11307838559150696
0.26615703105926514 0.26615703105926514
rl training, epoch1, iter0, batch1105/1133, batch loss:0.26615703105926514, Training time:3706.3646953105927
batch reward last col mean 0.13071134686470032 first col mean 0.10881307721138 all mean 0.11929066479206085
0.2991581857204437 0.2991581857204437
rl training, epoch1, iter0, batch1106/1133, batch loss:0.2991581857204437, Training time:3708.2320053577423
batch reward last col mean 0.09980586171150208 first col mean 0.12588214874267578 all mean 0.10774707794189453
0.31721919775009155 0.31721919775009155
rl training, epoch1, iter0, batch1107/1133, batch loss:0.31721919775009155, Training time:3710.161712884903
batch reward last col mean 0.11122766137123108 first col mean 0.10746446996927261 all mean 0.10733452439308167
0.32432618737220764 0.32432618737220764
rl training, epoch1, iter0, batch1108/1133, batch loss:0.32432618737220764, Training time:3712.389420032501
batch reward last col mean 0.1273135542869568 first col mean 0.10280464589595795 all mean 0.11838170140981674
0.3177133798599243 0.3177133798599243
rl training, epoch1, iter0, batch1109/1133, batch loss:0.3177133798599243, Training time:3714.501356601715
batch reward last col mean 0.1254226267337799 first col mean 0.1187589168548584 all mean 0.11991439014673233
0.3172890841960907 0.3172890841960907
rl training, epoch1, iter0, batch1110/1133, batch loss:0.3172890841960907, Training time:3716.409901857376
batch reward last col mean 0.12053589522838593 first col mean 0.11430489271879196 all mean 0.12370117008686066
0.3134186267852783 0.3134186267852783
rl training, epoch1, iter0, batch1111/1133, batch loss:0.3134186267852783, Training time:3718.5366218090057
batch reward last col mean 0.1303655207157135 first col mean 0.10699798911809921 all mean 0.12416097521781921
0.2877073287963867 0.2877073287963867
rl training, epoch1, iter0, batch1112/1133, batch loss:0.2877073287963867, Training time:3721.533278465271
batch reward last col mean 0.12473898380994797 first col mean 0.104354627430439 all mean 0.1198631227016449
0.33071351051330566 0.33071351051330566
rl training, epoch1, iter0, batch1113/1133, batch loss:0.33071351051330566, Training time:3723.3609759807587
batch reward last col mean 0.1510198563337326 first col mean 0.13853469491004944 all mean 0.14070935547351837
0.32592281699180603 0.32592281699180603
rl training, epoch1, iter0, batch1114/1133, batch loss:0.32592281699180603, Training time:3725.296546936035
batch reward last col mean 0.1147368997335434 first col mean 0.11042967438697815 all mean 0.10882558673620224
0.3124239146709442 0.3124239444732666
rl training, epoch1, iter0, batch1115/1133, batch loss:0.3124239444732666, Training time:3727.224881887436
batch reward last col mean 0.08019363880157471 first col mean 0.1197790876030922 all mean 0.09180060774087906
0.28613269329071045 0.28613266348838806
rl training, epoch1, iter0, batch1116/1133, batch loss:0.28613266348838806, Training time:3729.1780483722687
batch reward last col mean 0.12188027799129486 first col mean 0.12480495870113373 all mean 0.11961415410041809
0.2991306781768799 0.2991306781768799
rl training, epoch1, iter0, batch1117/1133, batch loss:0.2991306781768799, Training time:3731.036867380142
batch reward last col mean 0.10540883988142014 first col mean 0.10857024043798447 all mean 0.10785219073295593
0.305675208568573 0.305675208568573
rl training, epoch1, iter0, batch1118/1133, batch loss:0.305675208568573, Training time:3733.2346634864807
batch reward last col mean 0.1090812012553215 first col mean 0.11165241152048111 all mean 0.10855329036712646
0.3014954924583435 0.3014955222606659
rl training, epoch1, iter0, batch1119/1133, batch loss:0.3014955222606659, Training time:3735.003340482712
batch reward last col mean 0.097108393907547 first col mean 0.11578954756259918 all mean 0.09890485554933548
0.30523180961608887 0.30523183941841125
rl training, epoch1, iter0, batch1120/1133, batch loss:0.30523183941841125, Training time:3737.521219968796
batch reward last col mean 0.09834351390600204 first col mean 0.10619695484638214 all mean 0.10435660928487778
0.2748335301876068 0.2748335301876068
rl training, epoch1, iter0, batch1121/1133, batch loss:0.2748335301876068, Training time:3739.596831560135
batch reward last col mean 0.13918186724185944 first col mean 0.1153402104973793 all mean 0.1322212666273117
0.383018434047699 0.383018434047699
rl training, epoch1, iter0, batch1122/1133, batch loss:0.383018434047699, Training time:3741.64155459404
batch reward last col mean 0.07377748191356659 first col mean 0.10236784815788269 all mean 0.08905158936977386
0.2886906862258911 0.2886906862258911
rl training, epoch1, iter0, batch1123/1133, batch loss:0.2886906862258911, Training time:3743.6483986377716
batch reward last col mean 0.11749613285064697 first col mean 0.10981658101081848 all mean 0.11382469534873962
0.3356136679649353 0.3356136679649353
rl training, epoch1, iter0, batch1124/1133, batch loss:0.3356136679649353, Training time:3745.8289380073547
batch reward last col mean 0.15093107521533966 first col mean 0.13074301183223724 all mean 0.13853344321250916
0.35841822624206543 0.35841822624206543
rl training, epoch1, iter0, batch1125/1133, batch loss:0.35841822624206543, Training time:3748.1320004463196
batch reward last col mean 0.13903900980949402 first col mean 0.12074864655733109 all mean 0.1315966248512268
0.3343450427055359 0.3343450427055359
rl training, epoch1, iter0, batch1126/1133, batch loss:0.3343450427055359, Training time:3750.3039014339447
batch reward last col mean 0.09517475217580795 first col mean 0.11369167268276215 all mean 0.10011597722768784
0.2796868681907654 0.2796868681907654
rl training, epoch1, iter0, batch1127/1133, batch loss:0.2796868681907654, Training time:3752.262097597122
batch reward last col mean 0.09673048555850983 first col mean 0.1109226644039154 all mean 0.10223253071308136
0.3475470244884491 0.3475470244884491
rl training, epoch1, iter0, batch1128/1133, batch loss:0.3475470244884491, Training time:3755.4614882469177
batch reward last col mean 0.14937591552734375 first col mean 0.1148081123828888 all mean 0.14386360347270966
0.3485611379146576 0.3485611379146576
rl training, epoch1, iter0, batch1129/1133, batch loss:0.3485611379146576, Training time:3757.5226650238037
batch reward last col mean 0.10483399033546448 first col mean 0.11248157918453217 all mean 0.11186187714338303
0.36673325300216675 0.36673325300216675
rl training, epoch1, iter0, batch1130/1133, batch loss:0.36673325300216675, Training time:3760.0232553482056
batch reward last col mean 0.1527937352657318 first col mean 0.12639540433883667 all mean 0.1484983265399933
0.40098637342453003 0.40098631381988525
rl training, epoch1, iter0, batch1131/1133, batch loss:0.40098631381988525, Training time:3762.4942860603333
batch reward last col mean 0.11419958621263504 first col mean 0.13269710540771484 all mean 0.11598927527666092
0.3084913194179535 0.3084913194179535
rl training, epoch1, iter0, batch1132/1133, batch loss:0.3084913194179535, Training time:3764.499895811081
rl training, epoch 1, iter 0, loss:0.3992548463545536, Training time:3764.5001471042633 
rl epoch 1, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.2145392412857365 Time: 123.45463752746582 s
rl epoch 1, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.6025008368260653 Time: 100.31794166564941 s
loss of true 0.2698861013996001 loss of gen 0.20871571558613958 loss of other 0.12389902006062069 first score 0.12662532925605774
rl epoch 2, begin RL for generator...
batch reward last col mean 0.10447987169027328 first col mean 0.10606018453836441 all mean 0.10439690202474594
0.31821876764297485 0.31821876764297485
rl training, epoch2, iter0, batch0/1133, batch loss:0.31821876764297485, Training time:3991.0982835292816
batch reward last col mean 0.12704528868198395 first col mean 0.11848905682563782 all mean 0.12139257043600082
0.3511725068092346 0.3511725068092346
rl training, epoch2, iter0, batch1/1133, batch loss:0.3511725068092346, Training time:3993.662529706955
batch reward last col mean 0.14648959040641785 first col mean 0.109797902405262 all mean 0.14182059466838837
0.39330244064331055 0.39330244064331055
rl training, epoch2, iter0, batch2/1133, batch loss:0.39330244064331055, Training time:3995.6089293956757
batch reward last col mean 0.11402377486228943 first col mean 0.11139316111803055 all mean 0.11284054070711136
0.3443913161754608 0.3443912863731384
rl training, epoch2, iter0, batch3/1133, batch loss:0.3443912863731384, Training time:3998.308303117752
batch reward last col mean 0.10036467015743256 first col mean 0.11854521930217743 all mean 0.10669666528701782
0.35995984077453613 0.35995984077453613
rl training, epoch2, iter0, batch4/1133, batch loss:0.35995984077453613, Training time:4000.841579914093
batch reward last col mean 0.11825855076313019 first col mean 0.11713257431983948 all mean 0.12099834531545639
0.4025801122188568 0.4025801122188568
rl training, epoch2, iter0, batch5/1133, batch loss:0.4025801122188568, Training time:4003.203537940979
batch reward last col mean 0.10855977982282639 first col mean 0.12474535405635834 all mean 0.11269062012434006
0.3580090403556824 0.35800907015800476
rl training, epoch2, iter0, batch6/1133, batch loss:0.35800907015800476, Training time:4005.840805053711
batch reward last col mean 0.08856451511383057 first col mean 0.1310425102710724 all mean 0.0933721587061882
0.3040217459201813 0.3040217459201813
rl training, epoch2, iter0, batch7/1133, batch loss:0.3040217459201813, Training time:4009.157087087631
batch reward last col mean 0.12359242886304855 first col mean 0.13512186706066132 all mean 0.12233824282884598
0.3398878574371338 0.3398878574371338
rl training, epoch2, iter0, batch8/1133, batch loss:0.3398878574371338, Training time:4012.147562980652
batch reward last col mean 0.11261008679866791 first col mean 0.11147412657737732 all mean 0.11188260465860367
0.3614943027496338 0.3614943027496338
rl training, epoch2, iter0, batch9/1133, batch loss:0.3614943027496338, Training time:4014.2857632637024
batch reward last col mean 0.10049515962600708 first col mean 0.11603410542011261 all mean 0.1038551926612854
0.3328191637992859 0.3328191637992859
rl training, epoch2, iter0, batch10/1133, batch loss:0.3328191637992859, Training time:4019.903817176819
batch reward last col mean 0.08203495293855667 first col mean 0.14210909605026245 all mean 0.09121114760637283
0.3590567111968994 0.3590567111968994
rl training, epoch2, iter0, batch11/1133, batch loss:0.3590567111968994, Training time:4023.4090826511383
batch reward last col mean 0.1005541980266571 first col mean 0.09577471017837524 all mean 0.11204883456230164
0.36164817214012146 0.36164817214012146
rl training, epoch2, iter0, batch12/1133, batch loss:0.36164817214012146, Training time:4025.6332261562347
batch reward last col mean 0.10176905244588852 first col mean 0.10620959103107452 all mean 0.1059490218758583
0.3705786466598511 0.3705786466598511
rl training, epoch2, iter0, batch13/1133, batch loss:0.3705786466598511, Training time:4028.8017342090607
batch reward last col mean 0.10104438662528992 first col mean 0.11583544313907623 all mean 0.10507817566394806
0.4029347002506256 0.4029347002506256
rl training, epoch2, iter0, batch14/1133, batch loss:0.4029347002506256, Training time:4031.5286672115326
batch reward last col mean 0.0833633616566658 first col mean 0.13334038853645325 all mean 0.09153857082128525
0.35683000087738037 0.356829971075058
rl training, epoch2, iter0, batch15/1133, batch loss:0.356829971075058, Training time:4034.2335007190704
batch reward last col mean 0.10199317336082458 first col mean 0.12160149216651917 all mean 0.10992997139692307
0.40177199244499207 0.40177199244499207
rl training, epoch2, iter0, batch16/1133, batch loss:0.40177199244499207, Training time:4036.772844552994
batch reward last col mean 0.14106427133083344 first col mean 0.11839951574802399 all mean 0.1351696103811264
0.3964604437351227 0.3964604437351227
rl training, epoch2, iter0, batch17/1133, batch loss:0.3964604437351227, Training time:4039.334859609604
batch reward last col mean 0.09656549245119095 first col mean 0.10474222898483276 all mean 0.09576765447854996
0.33021748065948486 0.33021748065948486
rl training, epoch2, iter0, batch18/1133, batch loss:0.33021748065948486, Training time:4042.655347585678
batch reward last col mean 0.13361772894859314 first col mean 0.11777204275131226 all mean 0.12647074460983276
0.3556777238845825 0.3556777238845825
rl training, epoch2, iter0, batch19/1133, batch loss:0.3556777238845825, Training time:4045.6139600276947
batch reward last col mean 0.14043287932872772 first col mean 0.12336225807666779 all mean 0.13496217131614685
0.40938448905944824 0.40938448905944824
rl training, epoch2, iter0, batch20/1133, batch loss:0.40938448905944824, Training time:4047.9983716011047
batch reward last col mean 0.11366669088602066 first col mean 0.11731434613466263 all mean 0.11903361231088638
0.415497750043869 0.415497750043869
rl training, epoch2, iter0, batch21/1133, batch loss:0.415497750043869, Training time:4050.1091587543488
batch reward last col mean 0.09597490727901459 first col mean 0.11270128935575485 all mean 0.10043215751647949
0.35629671812057495 0.35629671812057495
rl training, epoch2, iter0, batch22/1133, batch loss:0.35629671812057495, Training time:4052.4417884349823
batch reward last col mean 0.12241734564304352 first col mean 0.11669516563415527 all mean 0.11987295001745224
0.35771411657333374 0.35771411657333374
rl training, epoch2, iter0, batch23/1133, batch loss:0.35771411657333374, Training time:4054.656520843506
batch reward last col mean 0.1316099613904953 first col mean 0.1166408360004425 all mean 0.1311553567647934
0.46630537509918213 0.46630537509918213
rl training, epoch2, iter0, batch24/1133, batch loss:0.46630537509918213, Training time:4057.060049057007
batch reward last col mean 0.11091163754463196 first col mean 0.12333066761493683 all mean 0.11294510215520859
0.36462095379829407 0.3646209239959717
rl training, epoch2, iter0, batch25/1133, batch loss:0.3646209239959717, Training time:4060.0159759521484
batch reward last col mean 0.10399304330348969 first col mean 0.11984598636627197 all mean 0.10289350897073746
0.29269275069236755 0.29269275069236755
rl training, epoch2, iter0, batch26/1133, batch loss:0.29269275069236755, Training time:4063.3692741394043
batch reward last col mean 0.10761624574661255 first col mean 0.12256896495819092 all mean 0.11841431260108948
0.3937782645225525 0.3937782645225525
rl training, epoch2, iter0, batch27/1133, batch loss:0.3937782645225525, Training time:4065.723270893097
batch reward last col mean 0.10772604495286942 first col mean 0.13021376729011536 all mean 0.11367141455411911
0.36661821603775024 0.36661818623542786
rl training, epoch2, iter0, batch28/1133, batch loss:0.36661818623542786, Training time:4069.135436296463
batch reward last col mean 0.12253864854574203 first col mean 0.12448137253522873 all mean 0.12481246888637543
0.3759898841381073 0.3759898841381073
rl training, epoch2, iter0, batch29/1133, batch loss:0.3759898841381073, Training time:4071.489423751831
batch reward last col mean 0.12913815677165985 first col mean 0.10990370064973831 all mean 0.12513868510723114
0.38744455575942993 0.38744455575942993
rl training, epoch2, iter0, batch30/1133, batch loss:0.38744455575942993, Training time:4073.657743692398
batch reward last col mean 0.1357424110174179 first col mean 0.11065943539142609 all mean 0.12889553606510162
0.3904741108417511 0.3904741108417511
rl training, epoch2, iter0, batch31/1133, batch loss:0.3904741108417511, Training time:4076.556569337845
batch reward last col mean 0.10603925585746765 first col mean 0.12259036302566528 all mean 0.1124987080693245
0.3729335069656372 0.3729335069656372
rl training, epoch2, iter0, batch32/1133, batch loss:0.3729335069656372, Training time:4078.5966427326202
batch reward last col mean 0.13405314087867737 first col mean 0.11712145060300827 all mean 0.1357567459344864
0.41502928733825684 0.41502928733825684
rl training, epoch2, iter0, batch33/1133, batch loss:0.41502928733825684, Training time:4081.097536802292
batch reward last col mean 0.10468333959579468 first col mean 0.11041617393493652 all mean 0.1119140237569809
0.358842670917511 0.358842670917511
rl training, epoch2, iter0, batch34/1133, batch loss:0.358842670917511, Training time:4083.541461467743
batch reward last col mean 0.10982469469308853 first col mean 0.12830036878585815 all mean 0.11630907654762268
0.3901643455028534 0.3901643753051758
rl training, epoch2, iter0, batch35/1133, batch loss:0.3901643753051758, Training time:4085.571690559387
batch reward last col mean 0.09693986177444458 first col mean 0.1311366856098175 all mean 0.10200724005699158
0.3504309058189392 0.3504309058189392
rl training, epoch2, iter0, batch36/1133, batch loss:0.3504309058189392, Training time:4088.4486968517303
batch reward last col mean 0.10632184147834778 first col mean 0.13002155721187592 all mean 0.11071228235960007
0.3330727517604828 0.3330727517604828
rl training, epoch2, iter0, batch37/1133, batch loss:0.3330727517604828, Training time:4091.4226710796356
batch reward last col mean 0.1253191977739334 first col mean 0.10595816373825073 all mean 0.12308065593242645
0.3903847336769104 0.3903847336769104
rl training, epoch2, iter0, batch38/1133, batch loss:0.3903847336769104, Training time:4094.6004700660706
batch reward last col mean 0.14955101907253265 first col mean 0.12287133932113647 all mean 0.14648564159870148
0.3889361619949341 0.3889361619949341
rl training, epoch2, iter0, batch39/1133, batch loss:0.3889361619949341, Training time:4098.423207521439
batch reward last col mean 0.09909649193286896 first col mean 0.12810751795768738 all mean 0.10413407534360886
0.3789360821247101 0.3789360523223877
rl training, epoch2, iter0, batch40/1133, batch loss:0.3789360523223877, Training time:4100.530093193054
batch reward last col mean 0.1247849315404892 first col mean 0.11369141936302185 all mean 0.11656545847654343
0.3594074845314026 0.359407514333725
rl training, epoch2, iter0, batch41/1133, batch loss:0.359407514333725, Training time:4102.2791521549225
batch reward last col mean 0.10451657325029373 first col mean 0.12407120317220688 all mean 0.10888052731752396
0.34744367003440857 0.34744367003440857
rl training, epoch2, iter0, batch42/1133, batch loss:0.34744367003440857, Training time:4104.856571674347
batch reward last col mean 0.118837371468544 first col mean 0.12912961840629578 all mean 0.12381739169359207
0.37450242042541504 0.37450242042541504
rl training, epoch2, iter0, batch43/1133, batch loss:0.37450242042541504, Training time:4107.183357477188
batch reward last col mean 0.11572764813899994 first col mean 0.13639643788337708 all mean 0.11803051084280014
0.4047931730747223 0.4047931730747223
rl training, epoch2, iter0, batch44/1133, batch loss:0.4047931730747223, Training time:4109.982185602188
batch reward last col mean 0.10374725610017776 first col mean 0.12430723756551743 all mean 0.10687819868326187
0.32190969586372375 0.32190969586372375
rl training, epoch2, iter0, batch45/1133, batch loss:0.32190969586372375, Training time:4112.384760379791
batch reward last col mean 0.10376119613647461 first col mean 0.1329091489315033 all mean 0.10751847922801971
0.3633493185043335 0.3633493185043335
rl training, epoch2, iter0, batch46/1133, batch loss:0.3633493185043335, Training time:4115.549601554871
batch reward last col mean 0.1285609006881714 first col mean 0.11782342940568924 all mean 0.13103613257408142
0.3621825873851776 0.3621825873851776
rl training, epoch2, iter0, batch47/1133, batch loss:0.3621825873851776, Training time:4118.1731905937195
batch reward last col mean 0.1179453432559967 first col mean 0.1152319386601448 all mean 0.11690162122249603
0.3620283305644989 0.3620283007621765
rl training, epoch2, iter0, batch48/1133, batch loss:0.3620283007621765, Training time:4120.739196300507
batch reward last col mean 0.08060436695814133 first col mean 0.14242622256278992 all mean 0.09034688770771027
0.39572203159332275 0.39572203159332275
rl training, epoch2, iter0, batch49/1133, batch loss:0.39572203159332275, Training time:4123.212026357651
batch reward last col mean 0.11366911977529526 first col mean 0.1068158969283104 all mean 0.11318019777536392
0.35648491978645325 0.35648491978645325
rl training, epoch2, iter0, batch50/1133, batch loss:0.35648491978645325, Training time:4124.940170764923
batch reward last col mean 0.10641595721244812 first col mean 0.12330496311187744 all mean 0.11008576303720474
0.36669647693634033 0.36669647693634033
rl training, epoch2, iter0, batch51/1133, batch loss:0.36669647693634033, Training time:4126.880748987198
batch reward last col mean 0.16966189444065094 first col mean 0.12247709929943085 all mean 0.1567883938550949
0.37486347556114197 0.37486347556114197
rl training, epoch2, iter0, batch52/1133, batch loss:0.37486347556114197, Training time:4128.739100694656
batch reward last col mean 0.12727698683738708 first col mean 0.12367624044418335 all mean 0.12441050261259079
0.3824671506881714 0.3824671506881714
rl training, epoch2, iter0, batch53/1133, batch loss:0.3824671506881714, Training time:4130.812031507492
batch reward last col mean 0.11297718435525894 first col mean 0.10821296274662018 all mean 0.11275731027126312
0.4074922204017639 0.4074922204017639
rl training, epoch2, iter0, batch54/1133, batch loss:0.4074922204017639, Training time:4133.489203929901
batch reward last col mean 0.10176272690296173 first col mean 0.1371961534023285 all mean 0.10680564492940903
0.3352436423301697 0.3352436423301697
rl training, epoch2, iter0, batch55/1133, batch loss:0.3352436423301697, Training time:4136.977494001389
batch reward last col mean 0.09852347522974014 first col mean 0.1259194314479828 all mean 0.10746435821056366
0.39838191866874695 0.39838191866874695
rl training, epoch2, iter0, batch56/1133, batch loss:0.39838191866874695, Training time:4139.636075258255
batch reward last col mean 0.13933110237121582 first col mean 0.12348181754350662 all mean 0.13273347914218903
0.40747103095054626 0.40747106075286865
rl training, epoch2, iter0, batch57/1133, batch loss:0.40747106075286865, Training time:4142.169487476349
batch reward last col mean 0.15997996926307678 first col mean 0.13821673393249512 all mean 0.1510893851518631
0.42268815636634827 0.42268815636634827
rl training, epoch2, iter0, batch58/1133, batch loss:0.42268815636634827, Training time:4144.543349266052
batch reward last col mean 0.1339631974697113 first col mean 0.11371825635433197 all mean 0.12750986218452454
0.36898237466812134 0.36898237466812134
rl training, epoch2, iter0, batch59/1133, batch loss:0.36898237466812134, Training time:4146.6270163059235
batch reward last col mean 0.11762140691280365 first col mean 0.1259295493364334 all mean 0.11929930746555328
0.3403889834880829 0.3403889834880829
rl training, epoch2, iter0, batch60/1133, batch loss:0.3403889834880829, Training time:4149.192983150482
batch reward last col mean 0.1305423378944397 first col mean 0.14013323187828064 all mean 0.12492997944355011
0.4161487817764282 0.4161487817764282
rl training, epoch2, iter0, batch61/1133, batch loss:0.4161487817764282, Training time:4151.428975582123
batch reward last col mean 0.1609502136707306 first col mean 0.14075250923633575 all mean 0.15816590189933777
0.45896416902542114 0.45896416902542114
rl training, epoch2, iter0, batch62/1133, batch loss:0.45896416902542114, Training time:4153.792495727539
batch reward last col mean 0.16007275879383087 first col mean 0.12267859280109406 all mean 0.15052081644535065
0.449640691280365 0.449640691280365
rl training, epoch2, iter0, batch63/1133, batch loss:0.449640691280365, Training time:4156.059651374817
batch reward last col mean 0.0947716236114502 first col mean 0.12653575837612152 all mean 0.10105063021183014
0.33294540643692017 0.33294540643692017
rl training, epoch2, iter0, batch64/1133, batch loss:0.33294540643692017, Training time:4158.612106561661
batch reward last col mean 0.11687380075454712 first col mean 0.12548911571502686 all mean 0.1135263592004776
0.35931721329689026 0.35931721329689026
rl training, epoch2, iter0, batch65/1133, batch loss:0.35931721329689026, Training time:4160.90661406517
batch reward last col mean 0.1328451931476593 first col mean 0.12420888245105743 all mean 0.12916339933872223
0.418796181678772 0.418796181678772
rl training, epoch2, iter0, batch66/1133, batch loss:0.418796181678772, Training time:4162.744293451309
batch reward last col mean 0.11279362440109253 first col mean 0.1077059879899025 all mean 0.11436726152896881
0.4011351466178894 0.4011351466178894
rl training, epoch2, iter0, batch67/1133, batch loss:0.4011351466178894, Training time:4164.807189941406
batch reward last col mean 0.11012155562639236 first col mean 0.10459206253290176 all mean 0.10857277363538742
0.3517518639564514 0.3517518639564514
rl training, epoch2, iter0, batch68/1133, batch loss:0.3517518639564514, Training time:4166.358424663544
batch reward last col mean 0.11343280971050262 first col mean 0.11359092593193054 all mean 0.12026809900999069
0.40624314546585083 0.40624314546585083
rl training, epoch2, iter0, batch69/1133, batch loss:0.40624314546585083, Training time:4168.559599637985
batch reward last col mean 0.1289529651403427 first col mean 0.13767021894454956 all mean 0.1299293339252472
0.4026486873626709 0.4026486873626709
rl training, epoch2, iter0, batch70/1133, batch loss:0.4026486873626709, Training time:4170.720731496811
batch reward last col mean 0.11093512177467346 first col mean 0.11517877131700516 all mean 0.11294206976890564
0.3682933747768402 0.3682933747768402
rl training, epoch2, iter0, batch71/1133, batch loss:0.3682933747768402, Training time:4172.637443304062
batch reward last col mean 0.09641194343566895 first col mean 0.13386863470077515 all mean 0.11022709310054779
0.3462582528591156 0.3462582528591156
rl training, epoch2, iter0, batch72/1133, batch loss:0.3462582528591156, Training time:4175.000892400742
batch reward last col mean 0.13340726494789124 first col mean 0.11969183385372162 all mean 0.13003471493721008
0.3662644326686859 0.3662644326686859
rl training, epoch2, iter0, batch73/1133, batch loss:0.3662644326686859, Training time:4179.086206674576
batch reward last col mean 0.11658141016960144 first col mean 0.10880905389785767 all mean 0.11951489001512527
0.4219152629375458 0.4219152629375458
rl training, epoch2, iter0, batch74/1133, batch loss:0.4219152629375458, Training time:4181.883884191513
batch reward last col mean 0.1337975114583969 first col mean 0.11395636945962906 all mean 0.13449245691299438
0.3707216680049896 0.3707216680049896
rl training, epoch2, iter0, batch75/1133, batch loss:0.3707216680049896, Training time:4184.670476198196
batch reward last col mean 0.11716341227293015 first col mean 0.1079484224319458 all mean 0.11888166517019272
0.38092413544654846 0.38092413544654846
rl training, epoch2, iter0, batch76/1133, batch loss:0.38092413544654846, Training time:4187.530351638794
batch reward last col mean 0.12182839959859848 first col mean 0.11533650755882263 all mean 0.1274816393852234
0.3789992928504944 0.3789992928504944
rl training, epoch2, iter0, batch77/1133, batch loss:0.3789992928504944, Training time:4189.674475431442
batch reward last col mean 0.11964303255081177 first col mean 0.12703558802604675 all mean 0.12719208002090454
0.42571455240249634 0.42571455240249634
rl training, epoch2, iter0, batch78/1133, batch loss:0.42571455240249634, Training time:4192.031128883362
batch reward last col mean 0.10129722207784653 first col mean 0.11984789371490479 all mean 0.10742262005805969
0.34386345744132996 0.34386345744132996
rl training, epoch2, iter0, batch79/1133, batch loss:0.34386345744132996, Training time:4194.267283678055
batch reward last col mean 0.13457715511322021 first col mean 0.1280534565448761 all mean 0.12503670156002045
0.4085230231285095 0.4085230231285095
rl training, epoch2, iter0, batch80/1133, batch loss:0.4085230231285095, Training time:4196.205078363419
batch reward last col mean 0.10521400719881058 first col mean 0.1294483244419098 all mean 0.11331754177808762
0.3747974634170532 0.3747974634170532
rl training, epoch2, iter0, batch81/1133, batch loss:0.3747974634170532, Training time:4198.16068816185
batch reward last col mean 0.1514626145362854 first col mean 0.1368028074502945 all mean 0.14638537168502808
0.375661164522171 0.375661164522171
rl training, epoch2, iter0, batch82/1133, batch loss:0.375661164522171, Training time:4200.392737627029
batch reward last col mean 0.1556873768568039 first col mean 0.12126104533672333 all mean 0.1543530821800232
0.425475537776947 0.425475537776947
rl training, epoch2, iter0, batch83/1133, batch loss:0.425475537776947, Training time:4203.021440267563
batch reward last col mean 0.1190742552280426 first col mean 0.13894668221473694 all mean 0.12342727184295654
0.41339126229286194 0.41339123249053955
rl training, epoch2, iter0, batch84/1133, batch loss:0.41339123249053955, Training time:4204.610117435455
batch reward last col mean 0.12210863083600998 first col mean 0.12084300071001053 all mean 0.1274116039276123
0.3850526213645935 0.3850526213645935
rl training, epoch2, iter0, batch85/1133, batch loss:0.3850526213645935, Training time:4206.387804269791
batch reward last col mean 0.10705871134996414 first col mean 0.13455089926719666 all mean 0.11335894465446472
0.3673314154148102 0.3673314154148102
rl training, epoch2, iter0, batch86/1133, batch loss:0.3673314154148102, Training time:4208.583944797516
batch reward last col mean 0.10411706566810608 first col mean 0.1236330047249794 all mean 0.10790512710809708
0.34580937027931213 0.34580937027931213
rl training, epoch2, iter0, batch87/1133, batch loss:0.34580937027931213, Training time:4210.700135231018
batch reward last col mean 0.1339055299758911 first col mean 0.13044407963752747 all mean 0.13272099196910858
0.4313424825668335 0.4313424825668335
rl training, epoch2, iter0, batch88/1133, batch loss:0.4313424825668335, Training time:4213.5216364860535
batch reward last col mean 0.17551812529563904 first col mean 0.12298668920993805 all mean 0.16083978116512299
0.429732084274292 0.429732084274292
rl training, epoch2, iter0, batch89/1133, batch loss:0.429732084274292, Training time:4215.789916753769
batch reward last col mean 0.1377655267715454 first col mean 0.13077440857887268 all mean 0.13360314071178436
0.4153520464897156 0.4153520464897156
rl training, epoch2, iter0, batch90/1133, batch loss:0.4153520464897156, Training time:4217.747087717056
batch reward last col mean 0.1359846293926239 first col mean 0.1327245533466339 all mean 0.1299525648355484
0.4122817814350128 0.4122817814350128
rl training, epoch2, iter0, batch91/1133, batch loss:0.4122817814350128, Training time:4220.061891555786
batch reward last col mean 0.15660955011844635 first col mean 0.12699852883815765 all mean 0.15325288474559784
0.3942256569862366 0.3942256569862366
rl training, epoch2, iter0, batch92/1133, batch loss:0.3942256569862366, Training time:4222.420614242554
batch reward last col mean 0.11349175125360489 first col mean 0.13508927822113037 all mean 0.11767470836639404
0.39601436257362366 0.39601442217826843
rl training, epoch2, iter0, batch93/1133, batch loss:0.39601442217826843, Training time:4224.0834946632385
batch reward last col mean 0.10593298077583313 first col mean 0.1399606317281723 all mean 0.1175149604678154
0.41497689485549927 0.41497689485549927
rl training, epoch2, iter0, batch94/1133, batch loss:0.41497689485549927, Training time:4226.16196846962
batch reward last col mean 0.16219237446784973 first col mean 0.09878867864608765 all mean 0.15247829258441925
0.4379379451274872 0.43793800473213196
rl training, epoch2, iter0, batch95/1133, batch loss:0.43793800473213196, Training time:4228.350462436676
batch reward last col mean 0.12825602293014526 first col mean 0.13648198544979095 all mean 0.122413270175457
0.37331393361091614 0.37331393361091614
rl training, epoch2, iter0, batch96/1133, batch loss:0.37331393361091614, Training time:4230.295397043228
batch reward last col mean 0.114153191447258 first col mean 0.11824169754981995 all mean 0.11958958953619003
0.34288692474365234 0.34288692474365234
rl training, epoch2, iter0, batch97/1133, batch loss:0.34288692474365234, Training time:4231.973241567612
batch reward last col mean 0.12017372995615005 first col mean 0.12452460080385208 all mean 0.12144146114587784
0.352076917886734 0.352076917886734
rl training, epoch2, iter0, batch98/1133, batch loss:0.352076917886734, Training time:4233.692015171051
batch reward last col mean 0.11985278129577637 first col mean 0.13145479559898376 all mean 0.12011083960533142
0.408084511756897 0.408084511756897
rl training, epoch2, iter0, batch99/1133, batch loss:0.408084511756897, Training time:4235.526907682419
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5861733629181652 Time: 98.63602232933044 s
loss of true 0.26220805143373577 loss of gen 0.20251341787514598 loss of other 0.12145189334953242 first score 0.12081827223300934
batch reward last col mean 0.0864650160074234 first col mean 0.10231199115514755 all mean 0.09685418009757996
0.3525432348251343 0.3525432348251343
rl training, epoch2, iter0, batch100/1133, batch loss:0.3525432348251343, Training time:4336.073695421219
batch reward last col mean 0.10707313567399979 first col mean 0.11483912169933319 all mean 0.10863754898309708
0.3736896216869354 0.3736896216869354
rl training, epoch2, iter0, batch101/1133, batch loss:0.3736896216869354, Training time:4337.876755475998
batch reward last col mean 0.1005696952342987 first col mean 0.11851644515991211 all mean 0.1081063449382782
0.3409671187400818 0.3409671187400818
rl training, epoch2, iter0, batch102/1133, batch loss:0.3409671187400818, Training time:4340.357417821884
batch reward last col mean 0.12271074950695038 first col mean 0.12134559452533722 all mean 0.11619017273187637
0.3468747138977051 0.3468746840953827
rl training, epoch2, iter0, batch103/1133, batch loss:0.3468746840953827, Training time:4342.258991718292
batch reward last col mean 0.12990179657936096 first col mean 0.11717517673969269 all mean 0.1302829533815384
0.36236563324928284 0.36236563324928284
rl training, epoch2, iter0, batch104/1133, batch loss:0.36236563324928284, Training time:4344.336751461029
batch reward last col mean 0.11572624742984772 first col mean 0.1172584593296051 all mean 0.11314123123884201
0.3329135477542877 0.3329135477542877
rl training, epoch2, iter0, batch105/1133, batch loss:0.3329135477542877, Training time:4345.965515375137
batch reward last col mean 0.0793851688504219 first col mean 0.12702703475952148 all mean 0.0901649221777916
0.3483849763870239 0.3483850359916687
rl training, epoch2, iter0, batch106/1133, batch loss:0.3483850359916687, Training time:4348.371674537659
batch reward last col mean 0.11342901736497879 first col mean 0.12372501194477081 all mean 0.11855564266443253
0.35696762800216675 0.35696762800216675
rl training, epoch2, iter0, batch107/1133, batch loss:0.35696762800216675, Training time:4350.520989656448
batch reward last col mean 0.12368583679199219 first col mean 0.09906728565692902 all mean 0.11761147528886795
0.4255469739437103 0.4255469739437103
rl training, epoch2, iter0, batch108/1133, batch loss:0.4255469739437103, Training time:4352.676074266434
batch reward last col mean 0.13148796558380127 first col mean 0.13402391970157623 all mean 0.12816976010799408
0.34782740473747253 0.34782740473747253
rl training, epoch2, iter0, batch109/1133, batch loss:0.34782740473747253, Training time:4354.27552986145
batch reward last col mean 0.1321490854024887 first col mean 0.1275542676448822 all mean 0.1310490220785141
0.36099281907081604 0.3609927296638489
rl training, epoch2, iter0, batch110/1133, batch loss:0.3609927296638489, Training time:4356.388282060623
batch reward last col mean 0.1425943672657013 first col mean 0.11978104710578918 all mean 0.13808757066726685
0.37264859676361084 0.37264859676361084
rl training, epoch2, iter0, batch111/1133, batch loss:0.37264859676361084, Training time:4358.572104215622
batch reward last col mean 0.11444529891014099 first col mean 0.11168499290943146 all mean 0.10635752230882645
0.3279881775379181 0.3279881775379181
rl training, epoch2, iter0, batch112/1133, batch loss:0.3279881775379181, Training time:4360.143512964249
batch reward last col mean 0.12124648690223694 first col mean 0.11774331331253052 all mean 0.11900180578231812
0.399709552526474 0.399709552526474
rl training, epoch2, iter0, batch113/1133, batch loss:0.399709552526474, Training time:4361.662797451019
batch reward last col mean 0.10305316001176834 first col mean 0.12229253351688385 all mean 0.10883574187755585
0.3685934543609619 0.3685934543609619
rl training, epoch2, iter0, batch114/1133, batch loss:0.3685934543609619, Training time:4363.065903663635
batch reward last col mean 0.14146137237548828 first col mean 0.1262357383966446 all mean 0.13486285507678986
0.38213154673576355 0.38213154673576355
rl training, epoch2, iter0, batch115/1133, batch loss:0.38213154673576355, Training time:4364.877897024155
batch reward last col mean 0.12002382427453995 first col mean 0.10994663834571838 all mean 0.12157326936721802
0.35521844029426575 0.35521844029426575
rl training, epoch2, iter0, batch116/1133, batch loss:0.35521844029426575, Training time:4366.624417304993
batch reward last col mean 0.1253116875886917 first col mean 0.09777919948101044 all mean 0.12698513269424438
0.36192798614501953 0.36192798614501953
rl training, epoch2, iter0, batch117/1133, batch loss:0.36192798614501953, Training time:4368.94592499733
batch reward last col mean 0.11712771654129028 first col mean 0.12518608570098877 all mean 0.12272308766841888
0.36353835463523865 0.36353835463523865
rl training, epoch2, iter0, batch118/1133, batch loss:0.36353835463523865, Training time:4370.685351848602
batch reward last col mean 0.14529544115066528 first col mean 0.11064767837524414 all mean 0.14116787910461426
0.3659737706184387 0.3659737706184387
rl training, epoch2, iter0, batch119/1133, batch loss:0.3659737706184387, Training time:4372.587505578995
batch reward last col mean 0.08562623709440231 first col mean 0.10778617113828659 all mean 0.09456881135702133
0.3372606039047241 0.3372606039047241
rl training, epoch2, iter0, batch120/1133, batch loss:0.3372606039047241, Training time:4374.417805433273
batch reward last col mean 0.1251790076494217 first col mean 0.11092272400856018 all mean 0.1224905401468277
0.38103699684143066 0.38103699684143066
rl training, epoch2, iter0, batch121/1133, batch loss:0.38103699684143066, Training time:4377.038293838501
batch reward last col mean 0.14475977420806885 first col mean 0.13146468997001648 all mean 0.14083538949489594
0.3776681125164032 0.3776680827140808
rl training, epoch2, iter0, batch122/1133, batch loss:0.3776680827140808, Training time:4379.171106338501
batch reward last col mean 0.12719260156154633 first col mean 0.13079160451889038 all mean 0.12338419258594513
0.34537917375564575 0.34537917375564575
rl training, epoch2, iter0, batch123/1133, batch loss:0.34537917375564575, Training time:4381.373012542725
batch reward last col mean 0.133563831448555 first col mean 0.12684130668640137 all mean 0.12815189361572266
0.38284218311309814 0.38284218311309814
rl training, epoch2, iter0, batch124/1133, batch loss:0.38284218311309814, Training time:4383.03292298317
batch reward last col mean 0.11270374804735184 first col mean 0.1377429962158203 all mean 0.11531350016593933
0.35180312395095825 0.35180312395095825
rl training, epoch2, iter0, batch125/1133, batch loss:0.35180312395095825, Training time:4385.315870523453
batch reward last col mean 0.12697607278823853 first col mean 0.12392989546060562 all mean 0.12486980110406876
0.3433528244495392 0.3433527946472168
rl training, epoch2, iter0, batch126/1133, batch loss:0.3433527946472168, Training time:4387.280690193176
batch reward last col mean 0.15968400239944458 first col mean 0.11024940758943558 all mean 0.1444113701581955
0.39033153653144836 0.39033153653144836
rl training, epoch2, iter0, batch127/1133, batch loss:0.39033153653144836, Training time:4389.247074127197
batch reward last col mean 0.08269492536783218 first col mean 0.139853373169899 all mean 0.09548886120319366
0.3356441557407379 0.3356441557407379
rl training, epoch2, iter0, batch128/1133, batch loss:0.3356441557407379, Training time:4390.918558597565
batch reward last col mean 0.08767097443342209 first col mean 0.13962224125862122 all mean 0.0965108722448349
0.32452821731567383 0.32452821731567383
rl training, epoch2, iter0, batch129/1133, batch loss:0.32452821731567383, Training time:4392.5907282829285
batch reward last col mean 0.10153715312480927 first col mean 0.1164492815732956 all mean 0.10605347901582718
0.36261969804763794 0.36261966824531555
rl training, epoch2, iter0, batch130/1133, batch loss:0.36261966824531555, Training time:4395.33553481102
batch reward last col mean 0.0832783505320549 first col mean 0.12600550055503845 all mean 0.09194918721914291
0.299650639295578 0.299650639295578
rl training, epoch2, iter0, batch131/1133, batch loss:0.299650639295578, Training time:4398.217737436295
batch reward last col mean 0.11577068269252777 first col mean 0.10643762350082397 all mean 0.11669669300317764
0.35977616906166077 0.35977616906166077
rl training, epoch2, iter0, batch132/1133, batch loss:0.35977616906166077, Training time:4400.789199352264
batch reward last col mean 0.10723762214183807 first col mean 0.1412375569343567 all mean 0.11822138726711273
0.37779632210731506 0.37779632210731506
rl training, epoch2, iter0, batch133/1133, batch loss:0.37779632210731506, Training time:4402.622786283493
batch reward last col mean 0.08359257876873016 first col mean 0.11469513922929764 all mean 0.09594210237264633
0.31361445784568787 0.31361445784568787
rl training, epoch2, iter0, batch134/1133, batch loss:0.31361445784568787, Training time:4404.741239309311
batch reward last col mean 0.11008928716182709 first col mean 0.14180932939052582 all mean 0.11190789937973022
0.3469594419002533 0.3469594419002533
rl training, epoch2, iter0, batch135/1133, batch loss:0.3469594419002533, Training time:4406.527771949768
batch reward last col mean 0.10496711730957031 first col mean 0.1288364976644516 all mean 0.1138455718755722
0.3771427273750305 0.3771427273750305
rl training, epoch2, iter0, batch136/1133, batch loss:0.3771427273750305, Training time:4408.211786746979
batch reward last col mean 0.14049211144447327 first col mean 0.12581530213356018 all mean 0.1392490416765213
0.37312576174736023 0.37312570214271545
rl training, epoch2, iter0, batch137/1133, batch loss:0.37312570214271545, Training time:4409.794140100479
batch reward last col mean 0.12207204103469849 first col mean 0.11652503907680511 all mean 0.12350825220346451
0.43267738819122314 0.43267738819122314
rl training, epoch2, iter0, batch138/1133, batch loss:0.43267738819122314, Training time:4411.844017505646
batch reward last col mean 0.09796683490276337 first col mean 0.12515701353549957 all mean 0.0972655788064003
0.33103811740875244 0.33103811740875244
rl training, epoch2, iter0, batch139/1133, batch loss:0.33103811740875244, Training time:4413.719142436981
batch reward last col mean 0.12575195729732513 first col mean 0.11388452351093292 all mean 0.12300153076648712
0.3918939232826233 0.3918938934803009
rl training, epoch2, iter0, batch140/1133, batch loss:0.3918938934803009, Training time:4415.650451898575
batch reward last col mean 0.100956030189991 first col mean 0.10980900377035141 all mean 0.10337875783443451
0.36101794242858887 0.36101794242858887
rl training, epoch2, iter0, batch141/1133, batch loss:0.36101794242858887, Training time:4418.205766916275
batch reward last col mean 0.11351226270198822 first col mean 0.11695145070552826 all mean 0.1145554929971695
0.3519028425216675 0.3519028425216675
rl training, epoch2, iter0, batch142/1133, batch loss:0.3519028425216675, Training time:4420.009407281876
batch reward last col mean 0.10029780119657516 first col mean 0.11443538963794708 all mean 0.10330855846405029
0.3321399986743927 0.3321399986743927
rl training, epoch2, iter0, batch143/1133, batch loss:0.3321399986743927, Training time:4422.407734870911
batch reward last col mean 0.1274392455816269 first col mean 0.12532606720924377 all mean 0.12854477763175964
0.3906419575214386 0.3906419575214386
rl training, epoch2, iter0, batch144/1133, batch loss:0.3906419575214386, Training time:4425.096562385559
batch reward last col mean 0.09549550712108612 first col mean 0.12485674023628235 all mean 0.1054665595293045
0.34775009751319885 0.34775009751319885
rl training, epoch2, iter0, batch145/1133, batch loss:0.34775009751319885, Training time:4427.49742436409
batch reward last col mean 0.11130815744400024 first col mean 0.12889060378074646 all mean 0.11972066760063171
0.369907945394516 0.36990800499916077
rl training, epoch2, iter0, batch146/1133, batch loss:0.36990800499916077, Training time:4429.366893053055
batch reward last col mean 0.11000664532184601 first col mean 0.12177684903144836 all mean 0.1189846470952034
0.3977417051792145 0.3977417051792145
rl training, epoch2, iter0, batch147/1133, batch loss:0.3977417051792145, Training time:4431.6417672634125
batch reward last col mean 0.12328808754682541 first col mean 0.130165234208107 all mean 0.12693750858306885
0.3765616714954376 0.3765616714954376
rl training, epoch2, iter0, batch148/1133, batch loss:0.3765616714954376, Training time:4433.837083101273
batch reward last col mean 0.129813089966774 first col mean 0.12388807535171509 all mean 0.12752163410186768
0.3773825466632843 0.37738245725631714
rl training, epoch2, iter0, batch149/1133, batch loss:0.37738245725631714, Training time:4435.860737323761
batch reward last col mean 0.12953856587409973 first col mean 0.12475374341011047 all mean 0.13179004192352295
0.39654040336608887 0.39654049277305603
rl training, epoch2, iter0, batch150/1133, batch loss:0.39654049277305603, Training time:4437.871512889862
batch reward last col mean 0.11103726923465729 first col mean 0.1419997215270996 all mean 0.10976903885602951
0.36351847648620605 0.36351847648620605
rl training, epoch2, iter0, batch151/1133, batch loss:0.36351847648620605, Training time:4439.364928245544
batch reward last col mean 0.1435176581144333 first col mean 0.1252158284187317 all mean 0.1443500816822052
0.4420029819011688 0.4420029819011688
rl training, epoch2, iter0, batch152/1133, batch loss:0.4420029819011688, Training time:4441.13593006134
batch reward last col mean 0.13102588057518005 first col mean 0.14443008601665497 all mean 0.13411805033683777
0.42231106758117676 0.42231109738349915
rl training, epoch2, iter0, batch153/1133, batch loss:0.42231109738349915, Training time:4443.96767783165
batch reward last col mean 0.1317514330148697 first col mean 0.13542330265045166 all mean 0.13277272880077362
0.3962291479110718 0.3962291479110718
rl training, epoch2, iter0, batch154/1133, batch loss:0.3962291479110718, Training time:4445.822842359543
batch reward last col mean 0.17102083563804626 first col mean 0.14069870114326477 all mean 0.15992991626262665
0.408637136220932 0.408637136220932
rl training, epoch2, iter0, batch155/1133, batch loss:0.408637136220932, Training time:4447.955355167389
batch reward last col mean 0.1545589566230774 first col mean 0.13384035229682922 all mean 0.14530092477798462
0.41760170459747314 0.41760170459747314
rl training, epoch2, iter0, batch156/1133, batch loss:0.41760170459747314, Training time:4449.705851078033
batch reward last col mean 0.09341153502464294 first col mean 0.12237672507762909 all mean 0.1039140522480011
0.3681347966194153 0.3681347966194153
rl training, epoch2, iter0, batch157/1133, batch loss:0.3681347966194153, Training time:4451.3684895038605
batch reward last col mean 0.16795071959495544 first col mean 0.11850428581237793 all mean 0.1585385650396347
0.38072195649147034 0.38072195649147034
rl training, epoch2, iter0, batch158/1133, batch loss:0.38072195649147034, Training time:4453.140164375305
batch reward last col mean 0.12985223531723022 first col mean 0.1283089518547058 all mean 0.12842175364494324
0.39479148387908936 0.39479148387908936
rl training, epoch2, iter0, batch159/1133, batch loss:0.39479148387908936, Training time:4455.408121347427
batch reward last col mean 0.09572787582874298 first col mean 0.12083351612091064 all mean 0.10464411973953247
0.3381045460700989 0.3381045460700989
rl training, epoch2, iter0, batch160/1133, batch loss:0.3381045460700989, Training time:4457.092551708221
batch reward last col mean 0.1378786861896515 first col mean 0.1297016739845276 all mean 0.13411740958690643
0.40722134709358215 0.40722134709358215
rl training, epoch2, iter0, batch161/1133, batch loss:0.40722134709358215, Training time:4459.004529953003
batch reward last col mean 0.11293312907218933 first col mean 0.1247229129076004 all mean 0.11498016864061356
0.3805616497993469 0.3805616497993469
rl training, epoch2, iter0, batch162/1133, batch loss:0.3805616497993469, Training time:4460.861159086227
batch reward last col mean 0.19855518639087677 first col mean 0.13492761552333832 all mean 0.17440997064113617
0.4359413683414459 0.4359413683414459
rl training, epoch2, iter0, batch163/1133, batch loss:0.4359413683414459, Training time:4462.551964044571
batch reward last col mean 0.1180405467748642 first col mean 0.11449921876192093 all mean 0.12155736982822418
0.35550183057785034 0.35550183057785034
rl training, epoch2, iter0, batch164/1133, batch loss:0.35550183057785034, Training time:4465.235791444778
batch reward last col mean 0.07999441027641296 first col mean 0.12359298020601273 all mean 0.09082362055778503
0.37580129504203796 0.3758012652397156
rl training, epoch2, iter0, batch165/1133, batch loss:0.3758012652397156, Training time:4467.626348257065
batch reward last col mean 0.13667672872543335 first col mean 0.1246236115694046 all mean 0.1308387815952301
0.39991915225982666 0.39991915225982666
rl training, epoch2, iter0, batch166/1133, batch loss:0.39991915225982666, Training time:4469.2559106349945
batch reward last col mean 0.0987495481967926 first col mean 0.14442874491214752 all mean 0.10779084265232086
0.32678326964378357 0.32678329944610596
rl training, epoch2, iter0, batch167/1133, batch loss:0.32678329944610596, Training time:4471.418329000473
batch reward last col mean 0.12870264053344727 first col mean 0.12399133294820786 all mean 0.12239132076501846
0.3504314720630646 0.3504314720630646
rl training, epoch2, iter0, batch168/1133, batch loss:0.3504314720630646, Training time:4473.3269810676575
batch reward last col mean 0.12677568197250366 first col mean 0.12580837309360504 all mean 0.1285521388053894
0.4088565707206726 0.4088565409183502
rl training, epoch2, iter0, batch169/1133, batch loss:0.4088565409183502, Training time:4475.32656621933
batch reward last col mean 0.11106950044631958 first col mean 0.12368033826351166 all mean 0.118653804063797
0.39819443225860596 0.39819443225860596
rl training, epoch2, iter0, batch170/1133, batch loss:0.39819443225860596, Training time:4477.583241939545
batch reward last col mean 0.09196437895298004 first col mean 0.11194983124732971 all mean 0.09933596104383469
0.351292222738266 0.351292222738266
rl training, epoch2, iter0, batch171/1133, batch loss:0.351292222738266, Training time:4479.975802659988
batch reward last col mean 0.09358388930559158 first col mean 0.13392646610736847 all mean 0.10418921709060669
0.3510817885398865 0.3510817885398865
rl training, epoch2, iter0, batch172/1133, batch loss:0.3510817885398865, Training time:4481.547380924225
batch reward last col mean 0.12487726658582687 first col mean 0.13585107028484344 all mean 0.12752215564250946
0.3525865972042084 0.3525865972042084
rl training, epoch2, iter0, batch173/1133, batch loss:0.3525865972042084, Training time:4483.569286108017
batch reward last col mean 0.1414119452238083 first col mean 0.11778921633958817 all mean 0.13507935404777527
0.3641888499259949 0.3641888499259949
rl training, epoch2, iter0, batch174/1133, batch loss:0.3641888499259949, Training time:4485.576449632645
batch reward last col mean 0.12337164580821991 first col mean 0.12931950390338898 all mean 0.128683403134346
0.3880031704902649 0.3880031704902649
rl training, epoch2, iter0, batch175/1133, batch loss:0.3880031704902649, Training time:4487.628121137619
batch reward last col mean 0.11455227434635162 first col mean 0.13028988242149353 all mean 0.11766177415847778
0.35563895106315613 0.35563895106315613
rl training, epoch2, iter0, batch176/1133, batch loss:0.35563895106315613, Training time:4489.577408790588
batch reward last col mean 0.12937164306640625 first col mean 0.12841378152370453 all mean 0.13241153955459595
0.37589728832244873 0.37589728832244873
rl training, epoch2, iter0, batch177/1133, batch loss:0.37589728832244873, Training time:4491.55099272728
batch reward last col mean 0.12400034815073013 first col mean 0.11699312180280685 all mean 0.12360326200723648
0.3799581825733185 0.3799581825733185
rl training, epoch2, iter0, batch178/1133, batch loss:0.3799581825733185, Training time:4494.032079458237
batch reward last col mean 0.08899717032909393 first col mean 0.13822825253009796 all mean 0.10235824435949326
0.37479737401008606 0.37479734420776367
rl training, epoch2, iter0, batch179/1133, batch loss:0.37479734420776367, Training time:4496.122677564621
batch reward last col mean 0.1295124590396881 first col mean 0.14571163058280945 all mean 0.12733283638954163
0.3416987955570221 0.3416987955570221
rl training, epoch2, iter0, batch180/1133, batch loss:0.3416987955570221, Training time:4498.53102183342
batch reward last col mean 0.14271730184555054 first col mean 0.13006336987018585 all mean 0.1409313678741455
0.42054325342178345 0.42054325342178345
rl training, epoch2, iter0, batch181/1133, batch loss:0.42054325342178345, Training time:4500.70134472847
batch reward last col mean 0.15415915846824646 first col mean 0.13218951225280762 all mean 0.15306870639324188
0.42981114983558655 0.42981114983558655
rl training, epoch2, iter0, batch182/1133, batch loss:0.42981114983558655, Training time:4503.093191862106
batch reward last col mean 0.13923171162605286 first col mean 0.13942277431488037 all mean 0.1385812759399414
0.37252286076545715 0.37252286076545715
rl training, epoch2, iter0, batch183/1133, batch loss:0.37252286076545715, Training time:4505.0167355537415
batch reward last col mean 0.10756109654903412 first col mean 0.15937095880508423 all mean 0.11683087795972824
0.35623636841773987 0.3562363088130951
rl training, epoch2, iter0, batch184/1133, batch loss:0.3562363088130951, Training time:4506.784543275833
batch reward last col mean 0.13687175512313843 first col mean 0.13644419610500336 all mean 0.13052092492580414
0.3511035144329071 0.3511035144329071
rl training, epoch2, iter0, batch185/1133, batch loss:0.3511035144329071, Training time:4508.604583024979
batch reward last col mean 0.10221643000841141 first col mean 0.11346757411956787 all mean 0.1105780377984047
0.3665674328804016 0.3665674328804016
rl training, epoch2, iter0, batch186/1133, batch loss:0.3665674328804016, Training time:4510.670726776123
batch reward last col mean 0.10672999918460846 first col mean 0.1200963482260704 all mean 0.11278099566698074
0.3348396420478821 0.3348396420478821
rl training, epoch2, iter0, batch187/1133, batch loss:0.3348396420478821, Training time:4512.378097772598
batch reward last col mean 0.10502303391695023 first col mean 0.13864727318286896 all mean 0.10865424573421478
0.3792189061641693 0.3792189359664917
rl training, epoch2, iter0, batch188/1133, batch loss:0.3792189359664917, Training time:4515.342241048813
batch reward last col mean 0.15897157788276672 first col mean 0.1405397206544876 all mean 0.15355432033538818
0.4619995057582855 0.4619995057582855
rl training, epoch2, iter0, batch189/1133, batch loss:0.4619995057582855, Training time:4517.591370582581
batch reward last col mean 0.1140986829996109 first col mean 0.11556603759527206 all mean 0.11658784747123718
0.3548654019832611 0.3548654019832611
rl training, epoch2, iter0, batch190/1133, batch loss:0.3548654019832611, Training time:4520.054364204407
batch reward last col mean 0.1687765121459961 first col mean 0.14123263955116272 all mean 0.1597088873386383
0.4133654534816742 0.4133654534816742
rl training, epoch2, iter0, batch191/1133, batch loss:0.4133654534816742, Training time:4522.225684404373
batch reward last col mean 0.14032363891601562 first col mean 0.14566227793693542 all mean 0.1414160430431366
0.38134387135505676 0.38134387135505676
rl training, epoch2, iter0, batch192/1133, batch loss:0.38134387135505676, Training time:4524.349863290787
batch reward last col mean 0.10859845578670502 first col mean 0.11967841535806656 all mean 0.11268189549446106
0.3599974513053894 0.3599974513053894
rl training, epoch2, iter0, batch193/1133, batch loss:0.3599974513053894, Training time:4526.485444784164
batch reward last col mean 0.14149720966815948 first col mean 0.12121285498142242 all mean 0.1356724202632904
0.39487797021865845 0.39487797021865845
rl training, epoch2, iter0, batch194/1133, batch loss:0.39487797021865845, Training time:4528.575953006744
batch reward last col mean 0.12968853116035461 first col mean 0.1501319706439972 all mean 0.14035379886627197
0.41464313864707947 0.41464313864707947
rl training, epoch2, iter0, batch195/1133, batch loss:0.41464313864707947, Training time:4530.396601200104
batch reward last col mean 0.11479353904724121 first col mean 0.11656563729047775 all mean 0.11129329353570938
0.3683139979839325 0.3683139979839325
rl training, epoch2, iter0, batch196/1133, batch loss:0.3683139979839325, Training time:4533.194638967514
batch reward last col mean 0.10785456746816635 first col mean 0.13504265248775482 all mean 0.11171084642410278
0.3344026803970337 0.3344026803970337
rl training, epoch2, iter0, batch197/1133, batch loss:0.3344026803970337, Training time:4535.0550746917725
batch reward last col mean 0.15708768367767334 first col mean 0.1312345713376999 all mean 0.15103955566883087
0.4265623092651367 0.4265623092651367
rl training, epoch2, iter0, batch198/1133, batch loss:0.4265623092651367, Training time:4537.1931681633
batch reward last col mean 0.13554894924163818 first col mean 0.13513335585594177 all mean 0.12510162591934204
0.3529699742794037 0.3529699742794037
rl training, epoch2, iter0, batch199/1133, batch loss:0.3529699742794037, Training time:4539.104310512543
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5823682458234486 Time: 99.9781539440155 s
loss of true 0.26041419259605425 loss of gen 0.19856215179597816 loss of other 0.12339190081327443 first score 0.12912367284297943
batch reward last col mean 0.10610663145780563 first col mean 0.13092073798179626 all mean 0.11139379441738129
0.34609654545783997 0.34609654545783997
rl training, epoch2, iter0, batch200/1133, batch loss:0.34609654545783997, Training time:4640.645607471466
batch reward last col mean 0.10023085027933121 first col mean 0.12542930245399475 all mean 0.10172085464000702
0.3163601756095886 0.3163601756095886
rl training, epoch2, iter0, batch201/1133, batch loss:0.3163601756095886, Training time:4642.399861812592
batch reward last col mean 0.11808996647596359 first col mean 0.12163428217172623 all mean 0.1208740845322609
0.3426205813884735 0.3426205813884735
rl training, epoch2, iter0, batch202/1133, batch loss:0.3426205813884735, Training time:4644.483035564423
batch reward last col mean 0.13066889345645905 first col mean 0.1334940791130066 all mean 0.12916794419288635
0.39552581310272217 0.39552581310272217
rl training, epoch2, iter0, batch203/1133, batch loss:0.39552581310272217, Training time:4646.32919883728
batch reward last col mean 0.12551674246788025 first col mean 0.12811627984046936 all mean 0.1251903623342514
0.35416287183761597 0.35416287183761597
rl training, epoch2, iter0, batch204/1133, batch loss:0.35416287183761597, Training time:4648.680916070938
batch reward last col mean 0.11438658088445663 first col mean 0.11371317505836487 all mean 0.11514155566692352
0.3856966197490692 0.3856966197490692
rl training, epoch2, iter0, batch205/1133, batch loss:0.3856966197490692, Training time:4651.935487747192
batch reward last col mean 0.11515939980745316 first col mean 0.1336786448955536 all mean 0.11143582314252853
0.3107314109802246 0.3107314109802246
rl training, epoch2, iter0, batch206/1133, batch loss:0.3107314109802246, Training time:4655.181132078171
batch reward last col mean 0.12936267256736755 first col mean 0.13870295882225037 all mean 0.12920904159545898
0.3465287387371063 0.3465287387371063
rl training, epoch2, iter0, batch207/1133, batch loss:0.3465287387371063, Training time:4656.936165809631
batch reward last col mean 0.12816214561462402 first col mean 0.12273314595222473 all mean 0.12479767948389053
0.3415994346141815 0.3415994346141815
rl training, epoch2, iter0, batch208/1133, batch loss:0.3415994346141815, Training time:4659.212960958481
batch reward last col mean 0.10132024437189102 first col mean 0.13345295190811157 all mean 0.110475555062294
0.339713990688324 0.339713990688324
rl training, epoch2, iter0, batch209/1133, batch loss:0.339713990688324, Training time:4661.078360795975
batch reward last col mean 0.13134624063968658 first col mean 0.1270613670349121 all mean 0.12739630043506622
0.35144302248954773 0.3514430522918701
rl training, epoch2, iter0, batch210/1133, batch loss:0.3514430522918701, Training time:4662.90865778923
batch reward last col mean 0.11348768323659897 first col mean 0.11355088651180267 all mean 0.1158992275595665
0.34091949462890625 0.34091949462890625
rl training, epoch2, iter0, batch211/1133, batch loss:0.34091949462890625, Training time:4665.141139745712
batch reward last col mean 0.1100929006934166 first col mean 0.11778368800878525 all mean 0.11111274361610413
0.3109256625175476 0.3109256625175476
rl training, epoch2, iter0, batch212/1133, batch loss:0.3109256625175476, Training time:4667.546037197113
batch reward last col mean 0.10162661224603653 first col mean 0.10187646001577377 all mean 0.10330800712108612
0.30558255314826965 0.30558255314826965
rl training, epoch2, iter0, batch213/1133, batch loss:0.30558255314826965, Training time:4669.778966665268
batch reward last col mean 0.09579137712717056 first col mean 0.12343168258666992 all mean 0.10229083150625229
0.29253143072128296 0.29253143072128296
rl training, epoch2, iter0, batch214/1133, batch loss:0.29253143072128296, Training time:4671.7726464271545
batch reward last col mean 0.11772958934307098 first col mean 0.10836492478847504 all mean 0.11584223806858063
0.35363519191741943 0.35363519191741943
rl training, epoch2, iter0, batch215/1133, batch loss:0.35363519191741943, Training time:4674.205176830292
batch reward last col mean 0.11464063078165054 first col mean 0.11222154647111893 all mean 0.10669437050819397
0.327951043844223 0.32795095443725586
rl training, epoch2, iter0, batch216/1133, batch loss:0.32795095443725586, Training time:4676.472712278366
batch reward last col mean 0.10198019444942474 first col mean 0.128336563706398 all mean 0.1109367161989212
0.3705962300300598 0.3705962002277374
rl training, epoch2, iter0, batch217/1133, batch loss:0.3705962002277374, Training time:4678.90838599205
batch reward last col mean 0.11720948666334152 first col mean 0.15244397521018982 all mean 0.1243724599480629
0.3677981495857239 0.3677981495857239
rl training, epoch2, iter0, batch218/1133, batch loss:0.3677981495857239, Training time:4681.267066717148
batch reward last col mean 0.1285858154296875 first col mean 0.10320061445236206 all mean 0.12486163526773453
0.34115472435951233 0.34115472435951233
rl training, epoch2, iter0, batch219/1133, batch loss:0.34115472435951233, Training time:4683.173273563385
batch reward last col mean 0.1149778664112091 first col mean 0.11837669461965561 all mean 0.11780822277069092
0.35673800110816956 0.35673800110816956
rl training, epoch2, iter0, batch220/1133, batch loss:0.35673800110816956, Training time:4685.045424938202
batch reward last col mean 0.08816581964492798 first col mean 0.12274551391601562 all mean 0.09448220580816269
0.3266700506210327 0.3266700506210327
rl training, epoch2, iter0, batch221/1133, batch loss:0.3266700506210327, Training time:4687.830418109894
batch reward last col mean 0.0880613625049591 first col mean 0.12983697652816772 all mean 0.09819276630878448
0.319108784198761 0.319108784198761
rl training, epoch2, iter0, batch222/1133, batch loss:0.319108784198761, Training time:4689.9617574214935
batch reward last col mean 0.08850409835577011 first col mean 0.12692321836948395 all mean 0.099215067923069
0.34246450662612915 0.34246447682380676
rl training, epoch2, iter0, batch223/1133, batch loss:0.34246447682380676, Training time:4692.059772014618
batch reward last col mean 0.10375571995973587 first col mean 0.11100068688392639 all mean 0.1120225042104721
0.31698670983314514 0.31698670983314514
rl training, epoch2, iter0, batch224/1133, batch loss:0.31698670983314514, Training time:4694.040582418442
batch reward last col mean 0.12776905298233032 first col mean 0.11368497461080551 all mean 0.12350456416606903
0.31576281785964966 0.31576281785964966
rl training, epoch2, iter0, batch225/1133, batch loss:0.31576281785964966, Training time:4696.8335247039795
batch reward last col mean 0.1117023378610611 first col mean 0.14803600311279297 all mean 0.11639851331710815
0.3257058560848236 0.3257058560848236
rl training, epoch2, iter0, batch226/1133, batch loss:0.3257058560848236, Training time:4698.973125219345
batch reward last col mean 0.11976208537817001 first col mean 0.12377088516950607 all mean 0.12646561861038208
0.3653141260147095 0.3653141260147095
rl training, epoch2, iter0, batch227/1133, batch loss:0.3653141260147095, Training time:4700.724279880524
batch reward last col mean 0.1656704694032669 first col mean 0.12728945910930634 all mean 0.15288741886615753
0.4080824553966522 0.4080824553966522
rl training, epoch2, iter0, batch228/1133, batch loss:0.4080824553966522, Training time:4702.599590778351
batch reward last col mean 0.12310533225536346 first col mean 0.11831836402416229 all mean 0.13090315461158752
0.37628141045570374 0.37628138065338135
rl training, epoch2, iter0, batch229/1133, batch loss:0.37628138065338135, Training time:4704.389608621597
batch reward last col mean 0.0996042862534523 first col mean 0.11429529637098312 all mean 0.10970579087734222
0.2966005802154541 0.2966005802154541
rl training, epoch2, iter0, batch230/1133, batch loss:0.2966005802154541, Training time:4706.235591411591
batch reward last col mean 0.12451724708080292 first col mean 0.11691337078809738 all mean 0.1285790503025055
0.3955935537815094 0.3955935537815094
rl training, epoch2, iter0, batch231/1133, batch loss:0.3955935537815094, Training time:4708.368641614914
batch reward last col mean 0.12461289763450623 first col mean 0.12283885478973389 all mean 0.12393863499164581
0.36492571234703064 0.36492571234703064
rl training, epoch2, iter0, batch232/1133, batch loss:0.36492571234703064, Training time:4711.177285909653
batch reward last col mean 0.14821968972682953 first col mean 0.13691920042037964 all mean 0.1435679942369461
0.37261244654655457 0.37261244654655457
rl training, epoch2, iter0, batch233/1133, batch loss:0.37261244654655457, Training time:4712.815213441849
batch reward last col mean 0.15120351314544678 first col mean 0.13857799768447876 all mean 0.14126603305339813
0.37412962317466736 0.37412962317466736
rl training, epoch2, iter0, batch234/1133, batch loss:0.37412962317466736, Training time:4714.6478090286255
batch reward last col mean 0.12928608059883118 first col mean 0.11487842351198196 all mean 0.12701541185379028
0.33981847763061523 0.33981847763061523
rl training, epoch2, iter0, batch235/1133, batch loss:0.33981847763061523, Training time:4716.31042098999
batch reward last col mean 0.10652299970388412 first col mean 0.1470501720905304 all mean 0.1158238872885704
0.333938866853714 0.333938866853714
rl training, epoch2, iter0, batch236/1133, batch loss:0.333938866853714, Training time:4718.205900669098
batch reward last col mean 0.1035427674651146 first col mean 0.11987782269716263 all mean 0.10709597170352936
0.3084077835083008 0.3084077537059784
rl training, epoch2, iter0, batch237/1133, batch loss:0.3084077537059784, Training time:4720.357731103897
batch reward last col mean 0.13599009811878204 first col mean 0.11408369243144989 all mean 0.13149070739746094
0.33323153853416443 0.33323153853416443
rl training, epoch2, iter0, batch238/1133, batch loss:0.33323153853416443, Training time:4722.121069431305
batch reward last col mean 0.12330981343984604 first col mean 0.13108380138874054 all mean 0.12764042615890503
0.3581524193286896 0.35815244913101196
rl training, epoch2, iter0, batch239/1133, batch loss:0.35815244913101196, Training time:4724.3658130168915
batch reward last col mean 0.10205131769180298 first col mean 0.12111986428499222 all mean 0.11034612357616425
0.35223817825317383 0.35223817825317383
rl training, epoch2, iter0, batch240/1133, batch loss:0.35223817825317383, Training time:4727.084689617157
batch reward last col mean 0.10083019733428955 first col mean 0.12941718101501465 all mean 0.10603751987218857
0.3357131779193878 0.33571314811706543
rl training, epoch2, iter0, batch241/1133, batch loss:0.33571314811706543, Training time:4728.876364707947
batch reward last col mean 0.11999571323394775 first col mean 0.13954414427280426 all mean 0.12039626389741898
0.3558860719203949 0.3558860719203949
rl training, epoch2, iter0, batch242/1133, batch loss:0.3558860719203949, Training time:4730.850729465485
batch reward last col mean 0.11020432412624359 first col mean 0.13265933096408844 all mean 0.11393234133720398
0.3356946110725403 0.3356946110725403
rl training, epoch2, iter0, batch243/1133, batch loss:0.3356946110725403, Training time:4732.753311872482
batch reward last col mean 0.12242709845304489 first col mean 0.12554587423801422 all mean 0.12526236474514008
0.3460293710231781 0.3460293710231781
rl training, epoch2, iter0, batch244/1133, batch loss:0.3460293710231781, Training time:4734.783895969391
batch reward last col mean 0.12871412932872772 first col mean 0.12263739854097366 all mean 0.1276821345090866
0.37761926651000977 0.37761926651000977
rl training, epoch2, iter0, batch245/1133, batch loss:0.37761926651000977, Training time:4736.360463380814
batch reward last col mean 0.10229149460792542 first col mean 0.125912606716156 all mean 0.10269885510206223
0.3466308116912842 0.3466308116912842
rl training, epoch2, iter0, batch246/1133, batch loss:0.3466308116912842, Training time:4738.39213848114
batch reward last col mean 0.09787567704916 first col mean 0.126692995429039 all mean 0.10099738091230392
0.31361573934555054 0.31361573934555054
rl training, epoch2, iter0, batch247/1133, batch loss:0.31361573934555054, Training time:4740.279294252396
batch reward last col mean 0.12460576742887497 first col mean 0.13863790035247803 all mean 0.12280738353729248
0.36594927310943604 0.36594927310943604
rl training, epoch2, iter0, batch248/1133, batch loss:0.36594927310943604, Training time:4742.6743721961975
batch reward last col mean 0.16204187273979187 first col mean 0.16088879108428955 all mean 0.15274110436439514
0.3625216484069824 0.3625216484069824
rl training, epoch2, iter0, batch249/1133, batch loss:0.3625216484069824, Training time:4744.3194489479065
batch reward last col mean 0.11161867529153824 first col mean 0.13624362647533417 all mean 0.12002944946289062
0.3253621757030487 0.3253621757030487
rl training, epoch2, iter0, batch250/1133, batch loss:0.3253621757030487, Training time:4745.900081396103
batch reward last col mean 0.10482527315616608 first col mean 0.11788428574800491 all mean 0.11112814396619797
0.31731680035591125 0.31731683015823364
rl training, epoch2, iter0, batch251/1133, batch loss:0.31731683015823364, Training time:4747.353187561035
batch reward last col mean 0.11800011992454529 first col mean 0.11937092244625092 all mean 0.11694317311048508
0.34281688928604126 0.34281688928604126
rl training, epoch2, iter0, batch252/1133, batch loss:0.34281688928604126, Training time:4749.370590209961
batch reward last col mean 0.12714532017707825 first col mean 0.1379767209291458 all mean 0.1316279023885727
0.3813903331756592 0.3813903331756592
rl training, epoch2, iter0, batch253/1133, batch loss:0.3813903331756592, Training time:4750.94876742363
batch reward last col mean 0.1395631581544876 first col mean 0.1233411505818367 all mean 0.13442781567573547
0.42239442467689514 0.42239442467689514
rl training, epoch2, iter0, batch254/1133, batch loss:0.42239442467689514, Training time:4753.246105670929
batch reward last col mean 0.12082627415657043 first col mean 0.13378693163394928 all mean 0.12232306599617004
0.3572022318840027 0.3572022318840027
rl training, epoch2, iter0, batch255/1133, batch loss:0.3572022318840027, Training time:4755.465183973312
batch reward last col mean 0.12996429204940796 first col mean 0.1397288590669632 all mean 0.12926119565963745
0.34578192234039307 0.34578192234039307
rl training, epoch2, iter0, batch256/1133, batch loss:0.34578192234039307, Training time:4757.1774315834045
batch reward last col mean 0.10289248079061508 first col mean 0.11280778050422668 all mean 0.10757674276828766
0.31845951080322266 0.31845951080322266
rl training, epoch2, iter0, batch257/1133, batch loss:0.31845951080322266, Training time:4759.020465373993
batch reward last col mean 0.1176242083311081 first col mean 0.13321605324745178 all mean 0.11843577027320862
0.34856700897216797 0.34856700897216797
rl training, epoch2, iter0, batch258/1133, batch loss:0.34856700897216797, Training time:4760.867086172104
batch reward last col mean 0.12970958650112152 first col mean 0.12720350921154022 all mean 0.13611473143100739
0.3973396420478821 0.3973396420478821
rl training, epoch2, iter0, batch259/1133, batch loss:0.3973396420478821, Training time:4762.786505222321
batch reward last col mean 0.13877429068088531 first col mean 0.14051254093647003 all mean 0.13622303307056427
0.37694674730300903 0.3769467771053314
rl training, epoch2, iter0, batch260/1133, batch loss:0.3769467771053314, Training time:4764.680109739304
batch reward last col mean 0.14091145992279053 first col mean 0.1265445500612259 all mean 0.1390063762664795
0.361167848110199 0.361167848110199
rl training, epoch2, iter0, batch261/1133, batch loss:0.361167848110199, Training time:4766.051495790482
batch reward last col mean 0.13304096460342407 first col mean 0.12240992486476898 all mean 0.13499610126018524
0.39532679319381714 0.39532679319381714
rl training, epoch2, iter0, batch262/1133, batch loss:0.39532679319381714, Training time:4767.852616548538
batch reward last col mean 0.10105732828378677 first col mean 0.11815037578344345 all mean 0.10552285611629486
0.3477793037891388 0.3477793037891388
rl training, epoch2, iter0, batch263/1133, batch loss:0.3477793037891388, Training time:4770.1997265815735
batch reward last col mean 0.13728104531764984 first col mean 0.1381235420703888 all mean 0.13588574528694153
0.3886139392852783 0.3886139392852783
rl training, epoch2, iter0, batch264/1133, batch loss:0.3886139392852783, Training time:4771.567620277405
batch reward last col mean 0.1256122887134552 first col mean 0.13904926180839539 all mean 0.12047082930803299
0.35294461250305176 0.35294461250305176
rl training, epoch2, iter0, batch265/1133, batch loss:0.35294461250305176, Training time:4773.2756016254425
batch reward last col mean 0.10785290598869324 first col mean 0.14099863171577454 all mean 0.10787999629974365
0.33258289098739624 0.33258286118507385
rl training, epoch2, iter0, batch266/1133, batch loss:0.33258286118507385, Training time:4774.81880068779
batch reward last col mean 0.11159022152423859 first col mean 0.13434261083602905 all mean 0.1061115562915802
0.3352981507778168 0.3352981507778168
rl training, epoch2, iter0, batch267/1133, batch loss:0.3352981507778168, Training time:4776.650106191635
batch reward last col mean 0.13215166330337524 first col mean 0.11465904861688614 all mean 0.12356482446193695
0.3603353500366211 0.3603353500366211
rl training, epoch2, iter0, batch268/1133, batch loss:0.3603353500366211, Training time:4778.515670061111
batch reward last col mean 0.15442489087581635 first col mean 0.13143634796142578 all mean 0.14436586201190948
0.4174688458442688 0.4174688458442688
rl training, epoch2, iter0, batch269/1133, batch loss:0.4174688458442688, Training time:4780.665463209152
batch reward last col mean 0.14712950587272644 first col mean 0.12562742829322815 all mean 0.14097796380519867
0.3544657230377197 0.3544657230377197
rl training, epoch2, iter0, batch270/1133, batch loss:0.3544657230377197, Training time:4782.199200391769
batch reward last col mean 0.078475721180439 first col mean 0.1231754869222641 all mean 0.09051728993654251
0.3000856041908264 0.30008557438850403
rl training, epoch2, iter0, batch271/1133, batch loss:0.30008557438850403, Training time:4784.664345026016
batch reward last col mean 0.14785225689411163 first col mean 0.12084126472473145 all mean 0.1379653513431549
0.3522752523422241 0.3522752523422241
rl training, epoch2, iter0, batch272/1133, batch loss:0.3522752523422241, Training time:4786.309896707535
batch reward last col mean 0.12726472318172455 first col mean 0.12407415360212326 all mean 0.12906867265701294
0.390516996383667 0.390516996383667
rl training, epoch2, iter0, batch273/1133, batch loss:0.390516996383667, Training time:4787.796394109726
batch reward last col mean 0.11460299789905548 first col mean 0.12717002630233765 all mean 0.11582893133163452
0.33717456459999084 0.33717456459999084
rl training, epoch2, iter0, batch274/1133, batch loss:0.33717456459999084, Training time:4789.42752289772
batch reward last col mean 0.1318492591381073 first col mean 0.1389656662940979 all mean 0.13295535743236542
0.33507946133613586 0.33507946133613586
rl training, epoch2, iter0, batch275/1133, batch loss:0.33507946133613586, Training time:4791.071427345276
batch reward last col mean 0.1295126974582672 first col mean 0.13720370829105377 all mean 0.12792152166366577
0.3812801241874695 0.3812801241874695
rl training, epoch2, iter0, batch276/1133, batch loss:0.3812801241874695, Training time:4792.867784976959
batch reward last col mean 0.14778006076812744 first col mean 0.11079961061477661 all mean 0.13837014138698578
0.3832201659679413 0.3832201659679413
rl training, epoch2, iter0, batch277/1133, batch loss:0.3832201659679413, Training time:4794.72456908226
batch reward last col mean 0.13891150057315826 first col mean 0.1417476236820221 all mean 0.133650004863739
0.3932328224182129 0.3932328224182129
rl training, epoch2, iter0, batch278/1133, batch loss:0.3932328224182129, Training time:4797.467496871948
batch reward last col mean 0.10013595968484879 first col mean 0.1274394541978836 all mean 0.110264353454113
0.37848758697509766 0.37848758697509766
rl training, epoch2, iter0, batch279/1133, batch loss:0.37848758697509766, Training time:4799.014518499374
batch reward last col mean 0.07786644250154495 first col mean 0.10946907103061676 all mean 0.09063596278429031
0.3331912159919739 0.3331912159919739
rl training, epoch2, iter0, batch280/1133, batch loss:0.3331912159919739, Training time:4800.701528549194
batch reward last col mean 0.14541518688201904 first col mean 0.13241684436798096 all mean 0.14168991148471832
0.4298767149448395 0.4298767149448395
rl training, epoch2, iter0, batch281/1133, batch loss:0.4298767149448395, Training time:4802.0950655937195
batch reward last col mean 0.10808108001947403 first col mean 0.1324528157711029 all mean 0.12246609479188919
0.3909599483013153 0.3909599184989929
rl training, epoch2, iter0, batch282/1133, batch loss:0.3909599184989929, Training time:4804.26296043396
batch reward last col mean 0.13737328350543976 first col mean 0.12275189161300659 all mean 0.13436497747898102
0.3563622832298279 0.3563622832298279
rl training, epoch2, iter0, batch283/1133, batch loss:0.3563622832298279, Training time:4806.05414223671
batch reward last col mean 0.09341373294591904 first col mean 0.11928457766771317 all mean 0.09576044231653214
0.31736037135124207 0.31736037135124207
rl training, epoch2, iter0, batch284/1133, batch loss:0.31736037135124207, Training time:4807.978593587875
batch reward last col mean 0.10727652162313461 first col mean 0.1346537470817566 all mean 0.11208225041627884
0.38433176279067993 0.3843317925930023
rl training, epoch2, iter0, batch285/1133, batch loss:0.3843317925930023, Training time:4809.587677717209
batch reward last col mean 0.1316467523574829 first col mean 0.13635417819023132 all mean 0.12337849289178848
0.3520817458629608 0.3520817458629608
rl training, epoch2, iter0, batch286/1133, batch loss:0.3520817458629608, Training time:4811.193420648575
batch reward last col mean 0.12209674715995789 first col mean 0.1389656662940979 all mean 0.12002700567245483
0.34522950649261475 0.34522950649261475
rl training, epoch2, iter0, batch287/1133, batch loss:0.34522950649261475, Training time:4813.304576873779
batch reward last col mean 0.1026349663734436 first col mean 0.13663902878761292 all mean 0.11047109961509705
0.349922776222229 0.349922776222229
rl training, epoch2, iter0, batch288/1133, batch loss:0.349922776222229, Training time:4815.947738647461
batch reward last col mean 0.09183492511510849 first col mean 0.13129860162734985 all mean 0.09725967794656754
0.3500804901123047 0.3500804901123047
rl training, epoch2, iter0, batch289/1133, batch loss:0.3500804901123047, Training time:4817.853545665741
batch reward last col mean 0.13402776420116425 first col mean 0.1183302029967308 all mean 0.12261718511581421
0.37583982944488525 0.37583982944488525
rl training, epoch2, iter0, batch290/1133, batch loss:0.37583982944488525, Training time:4819.347216844559
batch reward last col mean 0.13505789637565613 first col mean 0.10803686827421188 all mean 0.13962291181087494
0.36730673909187317 0.36730673909187317
rl training, epoch2, iter0, batch291/1133, batch loss:0.36730673909187317, Training time:4821.1477880477905
batch reward last col mean 0.11023333668708801 first col mean 0.1373259574174881 all mean 0.11683042347431183
0.3523353636264801 0.3523353636264801
rl training, epoch2, iter0, batch292/1133, batch loss:0.3523353636264801, Training time:4822.681382656097
batch reward last col mean 0.10906312614679337 first col mean 0.130991593003273 all mean 0.11679879575967789
0.3555355370044708 0.35553550720214844
rl training, epoch2, iter0, batch293/1133, batch loss:0.35553550720214844, Training time:4824.576398134232
batch reward last col mean 0.12654978036880493 first col mean 0.15726915001869202 all mean 0.13032075762748718
0.42342615127563477 0.42342615127563477
rl training, epoch2, iter0, batch294/1133, batch loss:0.42342615127563477, Training time:4826.284379482269
batch reward last col mean 0.1279170960187912 first col mean 0.1316012740135193 all mean 0.128532275557518
0.40690892934799194 0.40690892934799194
rl training, epoch2, iter0, batch295/1133, batch loss:0.40690892934799194, Training time:4828.084197759628
batch reward last col mean 0.1312149167060852 first col mean 0.13731351494789124 all mean 0.13640201091766357
0.3489692509174347 0.3489692509174347
rl training, epoch2, iter0, batch296/1133, batch loss:0.3489692509174347, Training time:4830.381380558014
batch reward last col mean 0.09494096040725708 first col mean 0.10788992792367935 all mean 0.0998368039727211
0.34161099791526794 0.34161093831062317
rl training, epoch2, iter0, batch297/1133, batch loss:0.34161093831062317, Training time:4832.497610807419
batch reward last col mean 0.14253193140029907 first col mean 0.11338411271572113 all mean 0.13773570954799652
0.40075528621673584 0.40075528621673584
rl training, epoch2, iter0, batch298/1133, batch loss:0.40075528621673584, Training time:4834.261106967926
batch reward last col mean 0.09192992746829987 first col mean 0.1453135907649994 all mean 0.09922876209020615
0.3228575885295868 0.3228575885295868
rl training, epoch2, iter0, batch299/1133, batch loss:0.3228575885295868, Training time:4836.655703544617
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5792734380433334 Time: 97.97591042518616 s
loss of true 0.2600136578398685 loss of gen 0.20028201927943032 loss of other 0.1189777610555541 first score 0.1442776471376419
batch reward last col mean 0.1350632905960083 first col mean 0.10566452145576477 all mean 0.12754952907562256
0.38192522525787354 0.38192519545555115
rl training, epoch2, iter0, batch300/1133, batch loss:0.38192519545555115, Training time:4936.356924295425
batch reward last col mean 0.1448340117931366 first col mean 0.12478798627853394 all mean 0.13744018971920013
0.4030366539955139 0.4030367434024811
rl training, epoch2, iter0, batch301/1133, batch loss:0.4030367434024811, Training time:4937.8659927845
batch reward last col mean 0.1159416139125824 first col mean 0.11813858151435852 all mean 0.11848507076501846
0.35169896483421326 0.35169896483421326
rl training, epoch2, iter0, batch302/1133, batch loss:0.35169896483421326, Training time:4939.768460273743
batch reward last col mean 0.12996649742126465 first col mean 0.11817231774330139 all mean 0.1341179460287094
0.36545273661613464 0.36545273661613464
rl training, epoch2, iter0, batch303/1133, batch loss:0.36545273661613464, Training time:4941.391543388367
batch reward last col mean 0.12568914890289307 first col mean 0.11088497191667557 all mean 0.12138555198907852
0.3846876323223114 0.3846876323223114
rl training, epoch2, iter0, batch304/1133, batch loss:0.3846876323223114, Training time:4943.656420946121
batch reward last col mean 0.15358689427375793 first col mean 0.11429331451654434 all mean 0.1420769989490509
0.36395496129989624 0.36395496129989624
rl training, epoch2, iter0, batch305/1133, batch loss:0.36395496129989624, Training time:4945.203805446625
batch reward last col mean 0.12326568365097046 first col mean 0.13432244956493378 all mean 0.12734419107437134
0.3884049654006958 0.3884049952030182
rl training, epoch2, iter0, batch306/1133, batch loss:0.3884049952030182, Training time:4946.9753448963165
batch reward last col mean 0.12942855060100555 first col mean 0.13072222471237183 all mean 0.12445903569459915
0.36806294322013855 0.36806294322013855
rl training, epoch2, iter0, batch307/1133, batch loss:0.36806294322013855, Training time:4949.318050861359
batch reward last col mean 0.12093372642993927 first col mean 0.13677795231342316 all mean 0.12176592648029327
0.38454949855804443 0.38454949855804443
rl training, epoch2, iter0, batch308/1133, batch loss:0.38454949855804443, Training time:4951.227200746536
batch reward last col mean 0.10824985802173615 first col mean 0.13681873679161072 all mean 0.11634786427021027
0.3387298882007599 0.3387298882007599
rl training, epoch2, iter0, batch309/1133, batch loss:0.3387298882007599, Training time:4952.871953487396
batch reward last col mean 0.09281647950410843 first col mean 0.12267795950174332 all mean 0.09357236325740814
0.2961697280406952 0.2961697280406952
rl training, epoch2, iter0, batch310/1133, batch loss:0.2961697280406952, Training time:4954.5581407547
batch reward last col mean 0.11343381553888321 first col mean 0.13058094680309296 all mean 0.11969161778688431
0.34231656789779663 0.34231656789779663
rl training, epoch2, iter0, batch311/1133, batch loss:0.34231656789779663, Training time:4956.613229751587
batch reward last col mean 0.15878993272781372 first col mean 0.12900282442569733 all mean 0.15181036293506622
0.3792862296104431 0.3792862594127655
rl training, epoch2, iter0, batch312/1133, batch loss:0.3792862594127655, Training time:4958.677284479141
batch reward last col mean 0.1434573531150818 first col mean 0.12283360213041306 all mean 0.1416984349489212
0.3822810649871826 0.3822810649871826
rl training, epoch2, iter0, batch313/1133, batch loss:0.3822810649871826, Training time:4960.511413574219
batch reward last col mean 0.11157221347093582 first col mean 0.12612807750701904 all mean 0.12018924951553345
0.360426127910614 0.360426127910614
rl training, epoch2, iter0, batch314/1133, batch loss:0.360426127910614, Training time:4962.191640853882
batch reward last col mean 0.09988804161548615 first col mean 0.10831054300069809 all mean 0.11078942567110062
0.3255905210971832 0.3255905210971832
rl training, epoch2, iter0, batch315/1133, batch loss:0.3255905210971832, Training time:4964.0560965538025
batch reward last col mean 0.12019819021224976 first col mean 0.139287531375885 all mean 0.11532539129257202
0.35832566022872925 0.35832566022872925
rl training, epoch2, iter0, batch316/1133, batch loss:0.35832566022872925, Training time:4965.93444442749
batch reward last col mean 0.13507959246635437 first col mean 0.12425458431243896 all mean 0.13059696555137634
0.40414246916770935 0.40414246916770935
rl training, epoch2, iter0, batch317/1133, batch loss:0.40414246916770935, Training time:4968.834707021713
batch reward last col mean 0.13172349333763123 first col mean 0.11934742331504822 all mean 0.12998589873313904
0.3834976553916931 0.3834976553916931
rl training, epoch2, iter0, batch318/1133, batch loss:0.3834976553916931, Training time:4970.933648586273
batch reward last col mean 0.13269203901290894 first col mean 0.14306066930294037 all mean 0.12717242538928986
0.3647157847881317 0.3647157847881317
rl training, epoch2, iter0, batch319/1133, batch loss:0.3647157847881317, Training time:4972.875821113586
batch reward last col mean 0.1046387255191803 first col mean 0.1511206030845642 all mean 0.11415848135948181
0.39487308263778687 0.39487308263778687
rl training, epoch2, iter0, batch320/1133, batch loss:0.39487308263778687, Training time:4975.391266822815
batch reward last col mean 0.13719694316387177 first col mean 0.1142013743519783 all mean 0.12985004484653473
0.3500308096408844 0.3500308096408844
rl training, epoch2, iter0, batch321/1133, batch loss:0.3500308096408844, Training time:4977.424980640411
batch reward last col mean 0.12465270608663559 first col mean 0.13627593219280243 all mean 0.1281137764453888
0.4021609425544739 0.4021609425544739
rl training, epoch2, iter0, batch322/1133, batch loss:0.4021609425544739, Training time:4979.113131284714
batch reward last col mean 0.12281057983636856 first col mean 0.1122034564614296 all mean 0.12495790421962738
0.3765888512134552 0.3765887916088104
rl training, epoch2, iter0, batch323/1133, batch loss:0.3765887916088104, Training time:4980.931444644928
batch reward last col mean 0.12076617777347565 first col mean 0.11866423487663269 all mean 0.11958353966474533
0.4297238886356354 0.4297238886356354
rl training, epoch2, iter0, batch324/1133, batch loss:0.4297238886356354, Training time:4983.126419782639
batch reward last col mean 0.13089053332805634 first col mean 0.12219700217247009 all mean 0.12109506130218506
0.320951908826828 0.3209518492221832
rl training, epoch2, iter0, batch325/1133, batch loss:0.3209518492221832, Training time:4984.941015005112
batch reward last col mean 0.15351463854312897 first col mean 0.11345100402832031 all mean 0.14085596799850464
0.4042072296142578 0.4042072296142578
rl training, epoch2, iter0, batch326/1133, batch loss:0.4042072296142578, Training time:4986.592437982559
batch reward last col mean 0.12244077771902084 first col mean 0.13271047174930573 all mean 0.12248756736516953
0.33612915873527527 0.33612915873527527
rl training, epoch2, iter0, batch327/1133, batch loss:0.33612915873527527, Training time:4988.505037784576
batch reward last col mean 0.1053663045167923 first col mean 0.11218447983264923 all mean 0.1097613275051117
0.33742082118988037 0.33742082118988037
rl training, epoch2, iter0, batch328/1133, batch loss:0.33742082118988037, Training time:4990.358978271484
batch reward last col mean 0.10478829592466354 first col mean 0.11338142305612564 all mean 0.11091099679470062
0.37496417760849 0.37496417760849
rl training, epoch2, iter0, batch329/1133, batch loss:0.37496417760849, Training time:4992.236471891403
batch reward last col mean 0.1353393942117691 first col mean 0.12311720103025436 all mean 0.1306038498878479
0.3408203125 0.3408203125
rl training, epoch2, iter0, batch330/1133, batch loss:0.3408203125, Training time:4994.223656177521
batch reward last col mean 0.1261337399482727 first col mean 0.12489353120326996 all mean 0.12589462101459503
0.3544310927391052 0.3544310927391052
rl training, epoch2, iter0, batch331/1133, batch loss:0.3544310927391052, Training time:4996.105829715729
batch reward last col mean 0.10678450018167496 first col mean 0.10394225269556046 all mean 0.11062425374984741
0.3832027316093445 0.3832027316093445
rl training, epoch2, iter0, batch332/1133, batch loss:0.3832027316093445, Training time:4998.243429899216
batch reward last col mean 0.14221489429473877 first col mean 0.14944249391555786 all mean 0.13300584256649017
0.4007459282875061 0.4007459282875061
rl training, epoch2, iter0, batch333/1133, batch loss:0.4007459282875061, Training time:5000.666316509247
batch reward last col mean 0.14982981979846954 first col mean 0.12982267141342163 all mean 0.14500057697296143
0.38154393434524536 0.38154393434524536
rl training, epoch2, iter0, batch334/1133, batch loss:0.38154393434524536, Training time:5002.90439748764
batch reward last col mean 0.11716468632221222 first col mean 0.11946579068899155 all mean 0.12094876915216446
0.357808381319046 0.3578084409236908
rl training, epoch2, iter0, batch335/1133, batch loss:0.3578084409236908, Training time:5004.842986822128
batch reward last col mean 0.10098204016685486 first col mean 0.1265253722667694 all mean 0.11020097136497498
0.36490219831466675 0.36490222811698914
rl training, epoch2, iter0, batch336/1133, batch loss:0.36490222811698914, Training time:5006.666929960251
batch reward last col mean 0.1019977256655693 first col mean 0.14770396053791046 all mean 0.10877484083175659
0.33518198132514954 0.33518198132514954
rl training, epoch2, iter0, batch337/1133, batch loss:0.33518198132514954, Training time:5008.958819150925
batch reward last col mean 0.10558414459228516 first col mean 0.11999555677175522 all mean 0.11263357102870941
0.37383708357810974 0.37383708357810974
rl training, epoch2, iter0, batch338/1133, batch loss:0.37383708357810974, Training time:5011.039687156677
batch reward last col mean 0.16146016120910645 first col mean 0.13714155554771423 all mean 0.14225465059280396
0.4046027958393097 0.4046027958393097
rl training, epoch2, iter0, batch339/1133, batch loss:0.4046027958393097, Training time:5012.900991201401
batch reward last col mean 0.10222149640321732 first col mean 0.10980553925037384 all mean 0.10735514760017395
0.32091328501701355 0.32091328501701355
rl training, epoch2, iter0, batch340/1133, batch loss:0.32091328501701355, Training time:5014.839532136917
batch reward last col mean 0.1021890938282013 first col mean 0.11024842411279678 all mean 0.11265649646520615
0.32851356267929077 0.32851356267929077
rl training, epoch2, iter0, batch341/1133, batch loss:0.32851356267929077, Training time:5016.79847407341
batch reward last col mean 0.13196584582328796 first col mean 0.12082690000534058 all mean 0.13027314841747284
0.4121064841747284 0.4121064841747284
rl training, epoch2, iter0, batch342/1133, batch loss:0.4121064841747284, Training time:5018.213206291199
batch reward last col mean 0.11681295186281204 first col mean 0.126418337225914 all mean 0.11620095372200012
0.38217803835868835 0.38217803835868835
rl training, epoch2, iter0, batch343/1133, batch loss:0.38217803835868835, Training time:5020.2980098724365
batch reward last col mean 0.1267213374376297 first col mean 0.1201598271727562 all mean 0.12694934010505676
0.3773574233055115 0.3773574233055115
rl training, epoch2, iter0, batch344/1133, batch loss:0.3773574233055115, Training time:5022.586452722549
batch reward last col mean 0.16612659394741058 first col mean 0.1251230388879776 all mean 0.15120592713356018
0.3903973698616028 0.3903973698616028
rl training, epoch2, iter0, batch345/1133, batch loss:0.3903973698616028, Training time:5024.319579124451
batch reward last col mean 0.14042837917804718 first col mean 0.13377726078033447 all mean 0.1405617892742157
0.4055520296096802 0.4055520296096802
rl training, epoch2, iter0, batch346/1133, batch loss:0.4055520296096802, Training time:5026.0846836566925
batch reward last col mean 0.10514462739229202 first col mean 0.12007717043161392 all mean 0.10999619215726852
0.36684450507164 0.36684450507164
rl training, epoch2, iter0, batch347/1133, batch loss:0.36684450507164, Training time:5028.237641334534
batch reward last col mean 0.14631281793117523 first col mean 0.10972338169813156 all mean 0.1424395591020584
0.45681890845298767 0.45681890845298767
rl training, epoch2, iter0, batch348/1133, batch loss:0.45681890845298767, Training time:5030.20899438858
batch reward last col mean 0.12308169156312943 first col mean 0.12975522875785828 all mean 0.11969920247793198
0.3664969801902771 0.3664969801902771
rl training, epoch2, iter0, batch349/1133, batch loss:0.3664969801902771, Training time:5032.753354310989
batch reward last col mean 0.10268989950418472 first col mean 0.13157440721988678 all mean 0.1093548908829689
0.3270373046398163 0.3270373046398163
rl training, epoch2, iter0, batch350/1133, batch loss:0.3270373046398163, Training time:5034.974849224091
batch reward last col mean 0.11637647449970245 first col mean 0.11597086489200592 all mean 0.11755699664354324
0.3668324947357178 0.3668324947357178
rl training, epoch2, iter0, batch351/1133, batch loss:0.3668324947357178, Training time:5036.824912548065
batch reward last col mean 0.1037742868065834 first col mean 0.12370280176401138 all mean 0.10830232501029968
0.3440515995025635 0.3440515995025635
rl training, epoch2, iter0, batch352/1133, batch loss:0.3440515995025635, Training time:5039.360848426819
batch reward last col mean 0.12918806076049805 first col mean 0.13735273480415344 all mean 0.12542986869812012
0.3890123665332794 0.3890123665332794
rl training, epoch2, iter0, batch353/1133, batch loss:0.3890123665332794, Training time:5041.227523803711
batch reward last col mean 0.11446496844291687 first col mean 0.1325625628232956 all mean 0.11775201559066772
0.3704090416431427 0.3704090416431427
rl training, epoch2, iter0, batch354/1133, batch loss:0.3704090416431427, Training time:5043.368820428848
batch reward last col mean 0.12385828047990799 first col mean 0.1498928815126419 all mean 0.12016206979751587
0.3787553608417511 0.3787553310394287
rl training, epoch2, iter0, batch355/1133, batch loss:0.3787553310394287, Training time:5045.613017320633
batch reward last col mean 0.1046416386961937 first col mean 0.13996712863445282 all mean 0.1107848584651947
0.3755771219730377 0.3755771219730377
rl training, epoch2, iter0, batch356/1133, batch loss:0.3755771219730377, Training time:5047.527400493622
batch reward last col mean 0.12141618132591248 first col mean 0.13122186064720154 all mean 0.12422771751880646
0.3524286150932312 0.3524286150932312
rl training, epoch2, iter0, batch357/1133, batch loss:0.3524286150932312, Training time:5049.5760016441345
batch reward last col mean 0.1590597927570343 first col mean 0.13465121388435364 all mean 0.14960601925849915
0.4064602553844452 0.4064602553844452
rl training, epoch2, iter0, batch358/1133, batch loss:0.4064602553844452, Training time:5051.755288600922
batch reward last col mean 0.15186923742294312 first col mean 0.12049075961112976 all mean 0.1482185572385788
0.3952445685863495 0.3952445685863495
rl training, epoch2, iter0, batch359/1133, batch loss:0.3952445685863495, Training time:5054.0923364162445
batch reward last col mean 0.143825963139534 first col mean 0.11018373817205429 all mean 0.13985614478588104
0.40809524059295654 0.40809524059295654
rl training, epoch2, iter0, batch360/1133, batch loss:0.40809524059295654, Training time:5056.2038197517395
batch reward last col mean 0.07697850465774536 first col mean 0.11698305606842041 all mean 0.08857768028974533
0.3162290155887604 0.3162290155887604
rl training, epoch2, iter0, batch361/1133, batch loss:0.3162290155887604, Training time:5058.846344232559
batch reward last col mean 0.12742987275123596 first col mean 0.1290208399295807 all mean 0.1240224838256836
0.35262203216552734 0.35262203216552734
rl training, epoch2, iter0, batch362/1133, batch loss:0.35262203216552734, Training time:5061.56902050972
batch reward last col mean 0.1218181625008583 first col mean 0.12942659854888916 all mean 0.11894422769546509
0.432804673910141 0.432804673910141
rl training, epoch2, iter0, batch363/1133, batch loss:0.432804673910141, Training time:5063.364746809006
batch reward last col mean 0.13140077888965607 first col mean 0.11892551183700562 all mean 0.12847070395946503
0.3900269865989685 0.3900269865989685
rl training, epoch2, iter0, batch364/1133, batch loss:0.3900269865989685, Training time:5065.476928472519
batch reward last col mean 0.08440738171339035 first col mean 0.12678590416908264 all mean 0.09650812298059464
0.34420445561408997 0.34420448541641235
rl training, epoch2, iter0, batch365/1133, batch loss:0.34420448541641235, Training time:5067.078373670578
batch reward last col mean 0.10375428199768066 first col mean 0.1335011124610901 all mean 0.1025867760181427
0.34250545501708984 0.34250545501708984
rl training, epoch2, iter0, batch366/1133, batch loss:0.34250545501708984, Training time:5069.441943407059
batch reward last col mean 0.09479150176048279 first col mean 0.1295299530029297 all mean 0.10421289503574371
0.389919638633728 0.389919638633728
rl training, epoch2, iter0, batch367/1133, batch loss:0.389919638633728, Training time:5071.804929494858
batch reward last col mean 0.13153889775276184 first col mean 0.14087417721748352 all mean 0.12579503655433655
0.37816116213798523 0.37816116213798523
rl training, epoch2, iter0, batch368/1133, batch loss:0.37816116213798523, Training time:5073.414029598236
batch reward last col mean 0.09788499027490616 first col mean 0.13094109296798706 all mean 0.11081960797309875
0.43293091654777527 0.43293091654777527
rl training, epoch2, iter0, batch369/1133, batch loss:0.43293091654777527, Training time:5075.5733461380005
batch reward last col mean 0.13006584346294403 first col mean 0.13493579626083374 all mean 0.1286538541316986
0.3953293263912201 0.3953293263912201
rl training, epoch2, iter0, batch370/1133, batch loss:0.3953293263912201, Training time:5077.237473487854
batch reward last col mean 0.09984596073627472 first col mean 0.13189855217933655 all mean 0.1123708039522171
0.3616383671760559 0.3616383671760559
rl training, epoch2, iter0, batch371/1133, batch loss:0.3616383671760559, Training time:5078.951855659485
batch reward last col mean 0.10749039053916931 first col mean 0.14532877504825592 all mean 0.11404303461313248
0.37249433994293213 0.37249433994293213
rl training, epoch2, iter0, batch372/1133, batch loss:0.37249433994293213, Training time:5081.221676826477
batch reward last col mean 0.10875066369771957 first col mean 0.13822242617607117 all mean 0.11391980946063995
0.31819915771484375 0.31819915771484375
rl training, epoch2, iter0, batch373/1133, batch loss:0.31819915771484375, Training time:5083.585203170776
batch reward last col mean 0.11916512995958328 first col mean 0.1363602727651596 all mean 0.1261509507894516
0.40224865078926086 0.40224865078926086
rl training, epoch2, iter0, batch374/1133, batch loss:0.40224865078926086, Training time:5085.759902238846
batch reward last col mean 0.1203090250492096 first col mean 0.12462858855724335 all mean 0.11525667458772659
0.35550758242607117 0.35550758242607117
rl training, epoch2, iter0, batch375/1133, batch loss:0.35550758242607117, Training time:5087.576946735382
batch reward last col mean 0.12287712097167969 first col mean 0.11441131681203842 all mean 0.12335735559463501
0.36667829751968384 0.36667829751968384
rl training, epoch2, iter0, batch376/1133, batch loss:0.36667829751968384, Training time:5089.897818803787
batch reward last col mean 0.13883176445960999 first col mean 0.14264416694641113 all mean 0.13471293449401855
0.38194119930267334 0.38194119930267334
rl training, epoch2, iter0, batch377/1133, batch loss:0.38194119930267334, Training time:5091.960244178772
batch reward last col mean 0.15127134323120117 first col mean 0.13502240180969238 all mean 0.1511807143688202
0.42288169264793396 0.42288169264793396
rl training, epoch2, iter0, batch378/1133, batch loss:0.42288169264793396, Training time:5093.987842321396
batch reward last col mean 0.1046551913022995 first col mean 0.13651332259178162 all mean 0.10784659534692764
0.306350439786911 0.306350439786911
rl training, epoch2, iter0, batch379/1133, batch loss:0.306350439786911, Training time:5096.468224287033
batch reward last col mean 0.10337188839912415 first col mean 0.14180593192577362 all mean 0.11308147013187408
0.4309491813182831 0.4309491813182831
rl training, epoch2, iter0, batch380/1133, batch loss:0.4309491813182831, Training time:5098.457426548004
batch reward last col mean 0.12275917828083038 first col mean 0.12486227601766586 all mean 0.12113481760025024
0.3964189291000366 0.3964189291000366
rl training, epoch2, iter0, batch381/1133, batch loss:0.3964189291000366, Training time:5100.343977928162
batch reward last col mean 0.13532085716724396 first col mean 0.12090729176998138 all mean 0.13411176204681396
0.36379051208496094 0.36379051208496094
rl training, epoch2, iter0, batch382/1133, batch loss:0.36379051208496094, Training time:5103.25968003273
batch reward last col mean 0.0998898297548294 first col mean 0.1447053849697113 all mean 0.1091865599155426
0.3232608139514923 0.3232608139514923
rl training, epoch2, iter0, batch383/1133, batch loss:0.3232608139514923, Training time:5105.233261585236
batch reward last col mean 0.12326545268297195 first col mean 0.13755716383457184 all mean 0.12567494809627533
0.3543402850627899 0.3543402850627899
rl training, epoch2, iter0, batch384/1133, batch loss:0.3543402850627899, Training time:5107.078065395355
batch reward last col mean 0.09684143960475922 first col mean 0.13754668831825256 all mean 0.11160444468259811
0.36603987216949463 0.36603987216949463
rl training, epoch2, iter0, batch385/1133, batch loss:0.36603987216949463, Training time:5109.22000169754
batch reward last col mean 0.107813760638237 first col mean 0.13381728529930115 all mean 0.11192741990089417
0.35526615381240845 0.3552662134170532
rl training, epoch2, iter0, batch386/1133, batch loss:0.3552662134170532, Training time:5111.649404525757
batch reward last col mean 0.13390053808689117 first col mean 0.12482307851314545 all mean 0.13182316720485687
0.3752098083496094 0.3752098083496094
rl training, epoch2, iter0, batch387/1133, batch loss:0.3752098083496094, Training time:5113.480702161789
batch reward last col mean 0.10048845410346985 first col mean 0.1269228458404541 all mean 0.11686497926712036
0.3968909978866577 0.3968909978866577
rl training, epoch2, iter0, batch388/1133, batch loss:0.3968909978866577, Training time:5115.427579641342
batch reward last col mean 0.13601528108119965 first col mean 0.13790327310562134 all mean 0.14302228391170502
0.35594314336776733 0.35594314336776733
rl training, epoch2, iter0, batch389/1133, batch loss:0.35594314336776733, Training time:5117.663703203201
batch reward last col mean 0.1198672503232956 first col mean 0.13695970177650452 all mean 0.12023337185382843
0.35749539732933044 0.35749539732933044
rl training, epoch2, iter0, batch390/1133, batch loss:0.35749539732933044, Training time:5120.168849468231
batch reward last col mean 0.11484956741333008 first col mean 0.1379275619983673 all mean 0.12573572993278503
0.3887561559677124 0.3887561559677124
rl training, epoch2, iter0, batch391/1133, batch loss:0.3887561559677124, Training time:5122.414226770401
batch reward last col mean 0.14912714064121246 first col mean 0.12542715668678284 all mean 0.14363260567188263
0.3977985382080078 0.3977985382080078
rl training, epoch2, iter0, batch392/1133, batch loss:0.3977985382080078, Training time:5124.415004253387
batch reward last col mean 0.12385466694831848 first col mean 0.12260077893733978 all mean 0.12297302484512329
0.3858601152896881 0.3858601152896881
rl training, epoch2, iter0, batch393/1133, batch loss:0.3858601152896881, Training time:5126.686686038971
batch reward last col mean 0.0998527780175209 first col mean 0.12606993317604065 all mean 0.10054845362901688
0.3562808930873871 0.3562808930873871
rl training, epoch2, iter0, batch394/1133, batch loss:0.3562808930873871, Training time:5129.476992368698
batch reward last col mean 0.11202433705329895 first col mean 0.1258547157049179 all mean 0.11965331435203552
0.36649537086486816 0.36649537086486816
rl training, epoch2, iter0, batch395/1133, batch loss:0.36649537086486816, Training time:5131.300442934036
batch reward last col mean 0.13409529626369476 first col mean 0.12792329490184784 all mean 0.1314634531736374
0.36462533473968506 0.36462533473968506
rl training, epoch2, iter0, batch396/1133, batch loss:0.36462533473968506, Training time:5133.515063285828
batch reward last col mean 0.11910037696361542 first col mean 0.1371484398841858 all mean 0.1171131581068039
0.3512164354324341 0.3512164354324341
rl training, epoch2, iter0, batch397/1133, batch loss:0.3512164354324341, Training time:5135.46401309967
batch reward last col mean 0.14121663570404053 first col mean 0.13649123907089233 all mean 0.13953815400600433
0.4139646589756012 0.4139646589756012
rl training, epoch2, iter0, batch398/1133, batch loss:0.4139646589756012, Training time:5137.4216294288635
batch reward last col mean 0.148646742105484 first col mean 0.12758757174015045 all mean 0.14489218592643738
0.37241268157958984 0.37241268157958984
rl training, epoch2, iter0, batch399/1133, batch loss:0.37241268157958984, Training time:5140.307951927185
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5815405050212056 Time: 99.64418697357178 s
loss of true 0.258845096823923 loss of gen 0.20085101284987614 loss of other 0.1218443951172473 first score 0.11336322128772736
batch reward last col mean 0.12662151455879211 first col mean 0.10636521875858307 all mean 0.12334287911653519
0.3689689040184021 0.3689689040184021
rl training, epoch2, iter0, batch400/1133, batch loss:0.3689689040184021, Training time:5241.816867589951
batch reward last col mean 0.11134710907936096 first col mean 0.12657487392425537 all mean 0.11384646594524384
0.3557664752006531 0.3557664752006531
rl training, epoch2, iter0, batch401/1133, batch loss:0.3557664752006531, Training time:5244.467530012131
batch reward last col mean 0.10343553870916367 first col mean 0.11190173774957657 all mean 0.10771956294775009
0.30258649587631226 0.30258649587631226
rl training, epoch2, iter0, batch402/1133, batch loss:0.30258649587631226, Training time:5246.519457817078
batch reward last col mean 0.12516263127326965 first col mean 0.12231607735157013 all mean 0.1292986422777176
0.36341920495033264 0.36341920495033264
rl training, epoch2, iter0, batch403/1133, batch loss:0.36341920495033264, Training time:5248.389825344086
batch reward last col mean 0.12337988615036011 first col mean 0.12966278195381165 all mean 0.12489799410104752
0.34154441952705383 0.3415444493293762
rl training, epoch2, iter0, batch404/1133, batch loss:0.3415444493293762, Training time:5250.758801937103
batch reward last col mean 0.09730386734008789 first col mean 0.13714148104190826 all mean 0.10896037518978119
0.3907189965248108 0.3907190263271332
rl training, epoch2, iter0, batch405/1133, batch loss:0.3907190263271332, Training time:5252.5384430885315
batch reward last col mean 0.1179647296667099 first col mean 0.12430521100759506 all mean 0.12113285064697266
0.3320687711238861 0.3320687711238861
rl training, epoch2, iter0, batch406/1133, batch loss:0.3320687711238861, Training time:5255.045111656189
batch reward last col mean 0.11263201385736465 first col mean 0.11317779868841171 all mean 0.11095518618822098
0.3613055646419525 0.3613055944442749
rl training, epoch2, iter0, batch407/1133, batch loss:0.3613055944442749, Training time:5257.344727754593
batch reward last col mean 0.10550275444984436 first col mean 0.12259185314178467 all mean 0.10332793742418289
0.29429301619529724 0.29429301619529724
rl training, epoch2, iter0, batch408/1133, batch loss:0.29429301619529724, Training time:5259.420308828354
batch reward last col mean 0.11181104183197021 first col mean 0.11229634284973145 all mean 0.11500360071659088
0.35317462682724 0.3531745672225952
rl training, epoch2, iter0, batch409/1133, batch loss:0.3531745672225952, Training time:5261.260718345642
batch reward last col mean 0.13884633779525757 first col mean 0.1319698840379715 all mean 0.13422232866287231
0.3514673411846161 0.3514673411846161
rl training, epoch2, iter0, batch410/1133, batch loss:0.3514673411846161, Training time:5263.104579210281
batch reward last col mean 0.14445318281650543 first col mean 0.10935154557228088 all mean 0.13999442756175995
0.3832002580165863 0.3832002580165863
rl training, epoch2, iter0, batch411/1133, batch loss:0.3832002580165863, Training time:5265.316968202591
batch reward last col mean 0.10633445531129837 first col mean 0.1193402037024498 all mean 0.10392945259809494
0.3299049437046051 0.3299049437046051
rl training, epoch2, iter0, batch412/1133, batch loss:0.3299049437046051, Training time:5267.631054639816
batch reward last col mean 0.11633910238742828 first col mean 0.11909481883049011 all mean 0.11580830067396164
0.3765821158885956 0.37658214569091797
rl training, epoch2, iter0, batch413/1133, batch loss:0.37658214569091797, Training time:5269.567232847214
batch reward last col mean 0.12896890938282013 first col mean 0.13841450214385986 all mean 0.12590958178043365
0.33418309688568115 0.33418309688568115
rl training, epoch2, iter0, batch414/1133, batch loss:0.33418309688568115, Training time:5271.979125499725
batch reward last col mean 0.1067664846777916 first col mean 0.12048119306564331 all mean 0.11310113221406937
0.34217870235443115 0.34217870235443115
rl training, epoch2, iter0, batch415/1133, batch loss:0.34217870235443115, Training time:5274.283961772919
batch reward last col mean 0.09118480980396271 first col mean 0.11638283729553223 all mean 0.09747534245252609
0.31240198016166687 0.31240198016166687
rl training, epoch2, iter0, batch416/1133, batch loss:0.31240198016166687, Training time:5277.229943037033
batch reward last col mean 0.09135223925113678 first col mean 0.127777099609375 all mean 0.09529459476470947
0.3436133861541748 0.3436133861541748
rl training, epoch2, iter0, batch417/1133, batch loss:0.3436133861541748, Training time:5280.168885946274
batch reward last col mean 0.13148169219493866 first col mean 0.1219341903924942 all mean 0.1359054297208786
0.3501606285572052 0.3501606285572052
rl training, epoch2, iter0, batch418/1133, batch loss:0.3501606285572052, Training time:5282.085067987442
batch reward last col mean 0.1002507284283638 first col mean 0.13947293162345886 all mean 0.11096043884754181
0.3445698618888855 0.3445698618888855
rl training, epoch2, iter0, batch419/1133, batch loss:0.3445698618888855, Training time:5284.313329219818
batch reward last col mean 0.14648054540157318 first col mean 0.12598636746406555 all mean 0.14235058426856995
0.384034126996994 0.384034126996994
rl training, epoch2, iter0, batch420/1133, batch loss:0.384034126996994, Training time:5285.971199989319
batch reward last col mean 0.1446048766374588 first col mean 0.11308714002370834 all mean 0.13378535211086273
0.3567795753479004 0.3567795753479004
rl training, epoch2, iter0, batch421/1133, batch loss:0.3567795753479004, Training time:5288.3058223724365
batch reward last col mean 0.08866691589355469 first col mean 0.12496832013130188 all mean 0.09968860447406769
0.37534815073013306 0.37534815073013306
rl training, epoch2, iter0, batch422/1133, batch loss:0.37534815073013306, Training time:5290.0723996162415
batch reward last col mean 0.1129642203450203 first col mean 0.11161377280950546 all mean 0.11929895728826523
0.3740377724170685 0.3740377724170685
rl training, epoch2, iter0, batch423/1133, batch loss:0.3740377724170685, Training time:5292.326559782028
batch reward last col mean 0.11893000453710556 first col mean 0.1411566436290741 all mean 0.11877504736185074
0.3664895296096802 0.36648955941200256
rl training, epoch2, iter0, batch424/1133, batch loss:0.36648955941200256, Training time:5294.258283615112
batch reward last col mean 0.15839964151382446 first col mean 0.13646285235881805 all mean 0.14897188544273376
0.3816450536251068 0.3816450536251068
rl training, epoch2, iter0, batch425/1133, batch loss:0.3816450536251068, Training time:5296.250067949295
batch reward last col mean 0.14264631271362305 first col mean 0.16184797883033752 all mean 0.14124418795108795
0.3854982852935791 0.3854982852935791
rl training, epoch2, iter0, batch426/1133, batch loss:0.3854982852935791, Training time:5300.0055067539215
batch reward last col mean 0.12691918015480042 first col mean 0.12845444679260254 all mean 0.1264745593070984
0.37902891635894775 0.37902888655662537
rl training, epoch2, iter0, batch427/1133, batch loss:0.37902888655662537, Training time:5302.266324996948
batch reward last col mean 0.10222116112709045 first col mean 0.1257603019475937 all mean 0.10054817795753479
0.3275233209133148 0.3275233209133148
rl training, epoch2, iter0, batch428/1133, batch loss:0.3275233209133148, Training time:5304.2286558151245
batch reward last col mean 0.12446361780166626 first col mean 0.12674590945243835 all mean 0.12001015245914459
0.322221577167511 0.322221577167511
rl training, epoch2, iter0, batch429/1133, batch loss:0.322221577167511, Training time:5306.66675901413
batch reward last col mean 0.13767144083976746 first col mean 0.12455921620130539 all mean 0.13737235963344574
0.33888059854507446 0.33888059854507446
rl training, epoch2, iter0, batch430/1133, batch loss:0.33888059854507446, Training time:5309.68591427803
batch reward last col mean 0.12782731652259827 first col mean 0.11138418316841125 all mean 0.1250409036874771
0.3608642816543579 0.3608642816543579
rl training, epoch2, iter0, batch431/1133, batch loss:0.3608642816543579, Training time:5313.029121637344
batch reward last col mean 0.10651371628046036 first col mean 0.13839580118656158 all mean 0.1113947257399559
0.35242921113967896 0.35242918133735657
rl training, epoch2, iter0, batch432/1133, batch loss:0.35242918133735657, Training time:5315.397186994553
batch reward last col mean 0.12525348365306854 first col mean 0.12853537499904633 all mean 0.1268320232629776
0.35436952114105225 0.35436952114105225
rl training, epoch2, iter0, batch433/1133, batch loss:0.35436952114105225, Training time:5317.342606306076
batch reward last col mean 0.11695535480976105 first col mean 0.13502445816993713 all mean 0.11946270614862442
0.3611754775047302 0.3611754775047302
rl training, epoch2, iter0, batch434/1133, batch loss:0.3611754775047302, Training time:5319.666009902954
batch reward last col mean 0.11756458878517151 first col mean 0.11317253857851028 all mean 0.11741673946380615
0.33910393714904785 0.33910390734672546
rl training, epoch2, iter0, batch435/1133, batch loss:0.33910390734672546, Training time:5321.742243051529
batch reward last col mean 0.10789555311203003 first col mean 0.13563823699951172 all mean 0.12190783023834229
0.3430434763431549 0.3430434763431549
rl training, epoch2, iter0, batch436/1133, batch loss:0.3430434763431549, Training time:5323.52447104454
batch reward last col mean 0.0821942687034607 first col mean 0.13421376049518585 all mean 0.0895669162273407
0.27398881316185 0.27398884296417236
rl training, epoch2, iter0, batch437/1133, batch loss:0.27398884296417236, Training time:5325.792088270187
batch reward last col mean 0.10895302146673203 first col mean 0.13016685843467712 all mean 0.11020730435848236
0.34545987844467163 0.34545987844467163
rl training, epoch2, iter0, batch438/1133, batch loss:0.34545987844467163, Training time:5328.490664720535
batch reward last col mean 0.14244696497917175 first col mean 0.12688004970550537 all mean 0.13162221014499664
0.3372102677822113 0.3372102677822113
rl training, epoch2, iter0, batch439/1133, batch loss:0.3372102677822113, Training time:5331.170849561691
batch reward last col mean 0.13784709572792053 first col mean 0.11974596977233887 all mean 0.13254059851169586
0.36216139793395996 0.36216139793395996
rl training, epoch2, iter0, batch440/1133, batch loss:0.36216139793395996, Training time:5333.8775227069855
batch reward last col mean 0.1390874683856964 first col mean 0.14145289361476898 all mean 0.1369512677192688
0.4096042811870575 0.4096042811870575
rl training, epoch2, iter0, batch441/1133, batch loss:0.4096042811870575, Training time:5336.55232167244
batch reward last col mean 0.13660603761672974 first col mean 0.13481275737285614 all mean 0.13778595626354218
0.37905025482177734 0.37905028462409973
rl training, epoch2, iter0, batch442/1133, batch loss:0.37905028462409973, Training time:5338.877880334854
batch reward last col mean 0.1227712482213974 first col mean 0.12488257884979248 all mean 0.12259447574615479
0.3363616466522217 0.3363616466522217
rl training, epoch2, iter0, batch443/1133, batch loss:0.3363616466522217, Training time:5341.275051355362
batch reward last col mean 0.1272766888141632 first col mean 0.12765294313430786 all mean 0.11648132652044296
0.34161636233329773 0.34161636233329773
rl training, epoch2, iter0, batch444/1133, batch loss:0.34161636233329773, Training time:5343.477382659912
batch reward last col mean 0.10595057904720306 first col mean 0.12800854444503784 all mean 0.11758004873991013
0.346915066242218 0.346915066242218
rl training, epoch2, iter0, batch445/1133, batch loss:0.346915066242218, Training time:5345.636197805405
batch reward last col mean 0.11342813819646835 first col mean 0.12448473274707794 all mean 0.11187063902616501
0.3048417568206787 0.3048417568206787
rl training, epoch2, iter0, batch446/1133, batch loss:0.3048417568206787, Training time:5347.860409021378
batch reward last col mean 0.12798631191253662 first col mean 0.12744608521461487 all mean 0.12569646537303925
0.3535381853580475 0.3535381853580475
rl training, epoch2, iter0, batch447/1133, batch loss:0.3535381853580475, Training time:5350.997056007385
batch reward last col mean 0.10772578418254852 first col mean 0.15283484756946564 all mean 0.1158595010638237
0.3783230185508728 0.3783230185508728
rl training, epoch2, iter0, batch448/1133, batch loss:0.3783230185508728, Training time:5353.809527397156
batch reward last col mean 0.11008694767951965 first col mean 0.12854711711406708 all mean 0.118084616959095
0.32893091440200806 0.32893091440200806
rl training, epoch2, iter0, batch449/1133, batch loss:0.32893091440200806, Training time:5355.668260812759
batch reward last col mean 0.11722320318222046 first col mean 0.14793044328689575 all mean 0.11970029026269913
0.36526381969451904 0.36526381969451904
rl training, epoch2, iter0, batch450/1133, batch loss:0.36526381969451904, Training time:5357.736378192902
batch reward last col mean 0.13593702018260956 first col mean 0.13863980770111084 all mean 0.13455730676651
0.38605111837387085 0.38605111837387085
rl training, epoch2, iter0, batch451/1133, batch loss:0.38605111837387085, Training time:5360.166986942291
batch reward last col mean 0.10685255378484726 first col mean 0.13186955451965332 all mean 0.11065608263015747
0.34572726488113403 0.3457273244857788
rl training, epoch2, iter0, batch452/1133, batch loss:0.3457273244857788, Training time:5362.435340642929
batch reward last col mean 0.137039914727211 first col mean 0.130998894572258 all mean 0.1286289393901825
0.35441839694976807 0.35441839694976807
rl training, epoch2, iter0, batch453/1133, batch loss:0.35441839694976807, Training time:5364.6175537109375
batch reward last col mean 0.10418776422739029 first col mean 0.11776973307132721 all mean 0.11265145987272263
0.33764320611953735 0.33764320611953735
rl training, epoch2, iter0, batch454/1133, batch loss:0.33764320611953735, Training time:5366.68532538414
batch reward last col mean 0.09914052486419678 first col mean 0.12896482646465302 all mean 0.10994646698236465
0.35830801725387573 0.35830801725387573
rl training, epoch2, iter0, batch455/1133, batch loss:0.35830801725387573, Training time:5368.774206399918
batch reward last col mean 0.12827333807945251 first col mean 0.16047821938991547 all mean 0.12555959820747375
0.3571225106716156 0.3571225106716156
rl training, epoch2, iter0, batch456/1133, batch loss:0.3571225106716156, Training time:5371.810986995697
batch reward last col mean 0.12210634350776672 first col mean 0.10399112850427628 all mean 0.12071250379085541
0.34427279233932495 0.34427279233932495
rl training, epoch2, iter0, batch457/1133, batch loss:0.34427279233932495, Training time:5374.371348619461
batch reward last col mean 0.1286756843328476 first col mean 0.1190880611538887 all mean 0.1289900541305542
0.3457346260547638 0.3457345962524414
rl training, epoch2, iter0, batch458/1133, batch loss:0.3457345962524414, Training time:5377.273397922516
batch reward last col mean 0.08709241449832916 first col mean 0.12220868468284607 all mean 0.09903760254383087
0.34100842475891113 0.34100842475891113
rl training, epoch2, iter0, batch459/1133, batch loss:0.34100842475891113, Training time:5379.728390693665
batch reward last col mean 0.13944905996322632 first col mean 0.13967782258987427 all mean 0.1399652063846588
0.344440221786499 0.34444019198417664
rl training, epoch2, iter0, batch460/1133, batch loss:0.34444019198417664, Training time:5381.777753829956
batch reward last col mean 0.11497007310390472 first col mean 0.1282384991645813 all mean 0.11799400299787521
0.3228936195373535 0.3228936195373535
rl training, epoch2, iter0, batch461/1133, batch loss:0.3228936195373535, Training time:5384.23411655426
batch reward last col mean 0.10336755216121674 first col mean 0.13101641833782196 all mean 0.11009448021650314
0.32701829075813293 0.32701829075813293
rl training, epoch2, iter0, batch462/1133, batch loss:0.32701829075813293, Training time:5386.027478218079
batch reward last col mean 0.11042148619890213 first col mean 0.13535362482070923 all mean 0.11794668436050415
0.32873427867889404 0.32873427867889404
rl training, epoch2, iter0, batch463/1133, batch loss:0.32873427867889404, Training time:5387.931793689728
batch reward last col mean 0.11718183755874634 first col mean 0.13509520888328552 all mean 0.12453969568014145
0.34216445684432983 0.34216445684432983
rl training, epoch2, iter0, batch464/1133, batch loss:0.34216445684432983, Training time:5390.159939050674
batch reward last col mean 0.11906816065311432 first col mean 0.13237617909908295 all mean 0.12087085843086243
0.3851878345012665 0.3851878345012665
rl training, epoch2, iter0, batch465/1133, batch loss:0.3851878345012665, Training time:5391.877453804016
batch reward last col mean 0.14164283871650696 first col mean 0.11679518222808838 all mean 0.1404201239347458
0.3701893091201782 0.3701893091201782
rl training, epoch2, iter0, batch466/1133, batch loss:0.3701893091201782, Training time:5394.186586141586
batch reward last col mean 0.12672939896583557 first col mean 0.1504284292459488 all mean 0.12910249829292297
0.38225606083869934 0.38225606083869934
rl training, epoch2, iter0, batch467/1133, batch loss:0.38225606083869934, Training time:5396.85718870163
batch reward last col mean 0.14587856829166412 first col mean 0.1226910650730133 all mean 0.1405448019504547
0.3903469443321228 0.3903469443321228
rl training, epoch2, iter0, batch468/1133, batch loss:0.3903469443321228, Training time:5399.184620380402
batch reward last col mean 0.11067181080579758 first col mean 0.11786922812461853 all mean 0.11274649947881699
0.32724863290786743 0.32724857330322266
rl training, epoch2, iter0, batch469/1133, batch loss:0.32724857330322266, Training time:5401.423114538193
batch reward last col mean 0.14070850610733032 first col mean 0.11350508779287338 all mean 0.1336366981267929
0.35982465744018555 0.35982465744018555
rl training, epoch2, iter0, batch470/1133, batch loss:0.35982465744018555, Training time:5403.216524839401
batch reward last col mean 0.13660670816898346 first col mean 0.1404000222682953 all mean 0.13571813702583313
0.4086386561393738 0.4086386561393738
rl training, epoch2, iter0, batch471/1133, batch loss:0.4086386561393738, Training time:5405.486644983292
batch reward last col mean 0.1263434886932373 first col mean 0.1300639808177948 all mean 0.12392936646938324
0.36487293243408203 0.36487293243408203
rl training, epoch2, iter0, batch472/1133, batch loss:0.36487293243408203, Training time:5408.582809448242
batch reward last col mean 0.1592038869857788 first col mean 0.12499559670686722 all mean 0.15485365688800812
0.38398414850234985 0.38398414850234985
rl training, epoch2, iter0, batch473/1133, batch loss:0.38398414850234985, Training time:5410.696433067322
batch reward last col mean 0.11644954234361649 first col mean 0.14304658770561218 all mean 0.11758360266685486
0.31294962763786316 0.31294962763786316
rl training, epoch2, iter0, batch474/1133, batch loss:0.31294962763786316, Training time:5413.056077003479
batch reward last col mean 0.1423856019973755 first col mean 0.13740386068820953 all mean 0.13988643884658813
0.3973872661590576 0.3973872661590576
rl training, epoch2, iter0, batch475/1133, batch loss:0.3973872661590576, Training time:5414.937426567078
batch reward last col mean 0.11045745015144348 first col mean 0.13153836131095886 all mean 0.11596744507551193
0.32706722617149353 0.32706722617149353
rl training, epoch2, iter0, batch476/1133, batch loss:0.32706722617149353, Training time:5417.753153562546
batch reward last col mean 0.11546506732702255 first col mean 0.13969892263412476 all mean 0.12167804688215256
0.338068425655365 0.338068425655365
rl training, epoch2, iter0, batch477/1133, batch loss:0.338068425655365, Training time:5420.037859678268
batch reward last col mean 0.17127715051174164 first col mean 0.12935955822467804 all mean 0.16404469311237335
0.4230556786060333 0.42305561900138855
rl training, epoch2, iter0, batch478/1133, batch loss:0.42305561900138855, Training time:5422.163474082947
batch reward last col mean 0.10050638765096664 first col mean 0.15134304761886597 all mean 0.11097848415374756
0.3344496786594391 0.3344496786594391
rl training, epoch2, iter0, batch479/1133, batch loss:0.3344496786594391, Training time:5424.135011911392
batch reward last col mean 0.10690478980541229 first col mean 0.12706151604652405 all mean 0.11800064146518707
0.35835692286491394 0.35835692286491394
rl training, epoch2, iter0, batch480/1133, batch loss:0.35835692286491394, Training time:5425.968671321869
batch reward last col mean 0.1213945746421814 first col mean 0.11648854613304138 all mean 0.12343825399875641
0.31385618448257446 0.31385618448257446
rl training, epoch2, iter0, batch481/1133, batch loss:0.31385618448257446, Training time:5428.572504281998
batch reward last col mean 0.15463405847549438 first col mean 0.12511976063251495 all mean 0.15070341527462006
0.37002214789390564 0.37002214789390564
rl training, epoch2, iter0, batch482/1133, batch loss:0.37002214789390564, Training time:5431.301836967468
batch reward last col mean 0.1292610913515091 first col mean 0.12646062672138214 all mean 0.13655126094818115
0.38371360301971436 0.38371360301971436
rl training, epoch2, iter0, batch483/1133, batch loss:0.38371360301971436, Training time:5433.045605659485
batch reward last col mean 0.11804114282131195 first col mean 0.12083466351032257 all mean 0.12448078393936157
0.35716524720191956 0.35716524720191956
rl training, epoch2, iter0, batch484/1133, batch loss:0.35716524720191956, Training time:5434.7987604141235
batch reward last col mean 0.13576170802116394 first col mean 0.12634123861789703 all mean 0.13193732500076294
0.3818022608757019 0.3818022608757019
rl training, epoch2, iter0, batch485/1133, batch loss:0.3818022608757019, Training time:5436.623513460159
batch reward last col mean 0.1146940067410469 first col mean 0.12946391105651855 all mean 0.1162547618150711
0.3395281136035919 0.3395281136035919
rl training, epoch2, iter0, batch486/1133, batch loss:0.3395281136035919, Training time:5438.71945309639
batch reward last col mean 0.13951407372951508 first col mean 0.1355190873146057 all mean 0.1412278115749359
0.35501307249069214 0.35501307249069214
rl training, epoch2, iter0, batch487/1133, batch loss:0.35501307249069214, Training time:5441.323693275452
batch reward last col mean 0.13002100586891174 first col mean 0.12434865534305573 all mean 0.13056999444961548
0.3462366461753845 0.3462366461753845
rl training, epoch2, iter0, batch488/1133, batch loss:0.3462366461753845, Training time:5444.1756937503815
batch reward last col mean 0.11548609286546707 first col mean 0.14341527223587036 all mean 0.1223629042506218
0.3421096205711365 0.3421096205711365
rl training, epoch2, iter0, batch489/1133, batch loss:0.3421096205711365, Training time:5446.861708164215
batch reward last col mean 0.1392885446548462 first col mean 0.1278441697359085 all mean 0.13682177662849426
0.3392718434333801 0.3392718434333801
rl training, epoch2, iter0, batch490/1133, batch loss:0.3392718434333801, Training time:5448.852809667587
batch reward last col mean 0.1454821676015854 first col mean 0.14819085597991943 all mean 0.1409893035888672
0.33235636353492737 0.332356333732605
rl training, epoch2, iter0, batch491/1133, batch loss:0.332356333732605, Training time:5450.658528804779
batch reward last col mean 0.11111898720264435 first col mean 0.13243907690048218 all mean 0.11965100467205048
0.3658602237701416 0.3658602237701416
rl training, epoch2, iter0, batch492/1133, batch loss:0.3658602237701416, Training time:5452.723592996597
batch reward last col mean 0.12530359625816345 first col mean 0.12750324606895447 all mean 0.13148880004882812
0.35255640745162964 0.35255640745162964
rl training, epoch2, iter0, batch493/1133, batch loss:0.35255640745162964, Training time:5454.3449103832245
batch reward last col mean 0.1293002963066101 first col mean 0.11960271000862122 all mean 0.12253879755735397
0.3401828706264496 0.3401828706264496
rl training, epoch2, iter0, batch494/1133, batch loss:0.3401828706264496, Training time:5456.1918432712555
batch reward last col mean 0.12363988161087036 first col mean 0.14585766196250916 all mean 0.12597452104091644
0.31706300377845764 0.31706300377845764
rl training, epoch2, iter0, batch495/1133, batch loss:0.31706300377845764, Training time:5459.167930603027
batch reward last col mean 0.11303330212831497 first col mean 0.1332607865333557 all mean 0.11741548776626587
0.3315413296222687 0.3315413296222687
rl training, epoch2, iter0, batch496/1133, batch loss:0.3315413296222687, Training time:5460.7193031311035
batch reward last col mean 0.10988816618919373 first col mean 0.13030323386192322 all mean 0.11397945135831833
0.31292787194252014 0.31292787194252014
rl training, epoch2, iter0, batch497/1133, batch loss:0.31292787194252014, Training time:5463.080924272537
batch reward last col mean 0.18245185911655426 first col mean 0.12129825353622437 all mean 0.16539327800273895
0.3914255201816559 0.3914255201816559
rl training, epoch2, iter0, batch498/1133, batch loss:0.3914255201816559, Training time:5464.6643307209015
batch reward last col mean 0.13578805327415466 first col mean 0.14909859001636505 all mean 0.13524720072746277
0.35585176944732666 0.35585176944732666
rl training, epoch2, iter0, batch499/1133, batch loss:0.35585176944732666, Training time:5466.929626941681
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5697254213419828 Time: 98.11352467536926 s
loss of true 0.2570203682120038 loss of gen 0.19512015756709536 loss of other 0.11758489433646413 first score 0.09780462831258774
batch reward last col mean 0.09804416447877884 first col mean 0.10652659833431244 all mean 0.10609900206327438
0.30116698145866394 0.30116698145866394
rl training, epoch2, iter0, batch500/1133, batch loss:0.30116698145866394, Training time:5566.50513625145
batch reward last col mean 0.10527211427688599 first col mean 0.12333378940820694 all mean 0.110318124294281
0.31169161200523376 0.31169161200523376
rl training, epoch2, iter0, batch501/1133, batch loss:0.31169161200523376, Training time:5568.1761302948
batch reward last col mean 0.13827694952487946 first col mean 0.14551866054534912 all mean 0.13415513932704926
0.33532577753067017 0.33532577753067017
rl training, epoch2, iter0, batch502/1133, batch loss:0.33532577753067017, Training time:5570.052810668945
batch reward last col mean 0.12226669490337372 first col mean 0.12174588441848755 all mean 0.11968047171831131
0.3315485119819641 0.3315485417842865
rl training, epoch2, iter0, batch503/1133, batch loss:0.3315485417842865, Training time:5572.379202842712
batch reward last col mean 0.09524044394493103 first col mean 0.1304318904876709 all mean 0.09862782806158066
0.2828229069709778 0.2828229069709778
rl training, epoch2, iter0, batch504/1133, batch loss:0.2828229069709778, Training time:5574.741199731827
batch reward last col mean 0.09322156012058258 first col mean 0.13817758858203888 all mean 0.10051725059747696
0.31850680708885193 0.31850677728652954
rl training, epoch2, iter0, batch505/1133, batch loss:0.31850677728652954, Training time:5577.259574651718
batch reward last col mean 0.12493417412042618 first col mean 0.1296163648366928 all mean 0.12462297081947327
0.3686200976371765 0.3686200976371765
rl training, epoch2, iter0, batch506/1133, batch loss:0.3686200976371765, Training time:5578.866084098816
batch reward last col mean 0.1262296587228775 first col mean 0.11500413715839386 all mean 0.12202093750238419
0.3353770077228546 0.3353770077228546
rl training, epoch2, iter0, batch507/1133, batch loss:0.3353770077228546, Training time:5581.412301301956
batch reward last col mean 0.11186262220144272 first col mean 0.13287360966205597 all mean 0.11499051004648209
0.3693598508834839 0.3693598508834839
rl training, epoch2, iter0, batch508/1133, batch loss:0.3693598508834839, Training time:5583.212535619736
batch reward last col mean 0.10984563082456589 first col mean 0.1132078468799591 all mean 0.11424094438552856
0.3036496937274933 0.3036497235298157
rl training, epoch2, iter0, batch509/1133, batch loss:0.3036497235298157, Training time:5585.057149648666
batch reward last col mean 0.09011128544807434 first col mean 0.10917991399765015 all mean 0.09064938127994537
0.2589539587497711 0.2589539587497711
rl training, epoch2, iter0, batch510/1133, batch loss:0.2589539587497711, Training time:5586.828997135162
batch reward last col mean 0.11346883326768875 first col mean 0.11018805205821991 all mean 0.11622712016105652
0.31967294216156006 0.31967291235923767
rl training, epoch2, iter0, batch511/1133, batch loss:0.31967291235923767, Training time:5588.275953769684
batch reward last col mean 0.11933335661888123 first col mean 0.11446025967597961 all mean 0.1167750284075737
0.30817851424217224 0.30817851424217224
rl training, epoch2, iter0, batch512/1133, batch loss:0.30817851424217224, Training time:5590.3924815654755
batch reward last col mean 0.10272884368896484 first col mean 0.11640290170907974 all mean 0.10966695845127106
0.32793498039245605 0.32793498039245605
rl training, epoch2, iter0, batch513/1133, batch loss:0.32793498039245605, Training time:5592.19723367691
batch reward last col mean 0.11732491850852966 first col mean 0.11206413805484772 all mean 0.1204446479678154
0.3615212142467499 0.3615212142467499
rl training, epoch2, iter0, batch514/1133, batch loss:0.3615212142467499, Training time:5593.960635900497
batch reward last col mean 0.10083010792732239 first col mean 0.13511048257350922 all mean 0.11113463342189789
0.34833917021751404 0.34833917021751404
rl training, epoch2, iter0, batch515/1133, batch loss:0.34833917021751404, Training time:5596.293419122696
batch reward last col mean 0.09481660276651382 first col mean 0.10573592782020569 all mean 0.0977388545870781
0.27209144830703735 0.27209144830703735
rl training, epoch2, iter0, batch516/1133, batch loss:0.27209144830703735, Training time:5598.142805814743
batch reward last col mean 0.1309974044561386 first col mean 0.11971785873174667 all mean 0.13603465259075165
0.3463144302368164 0.3463144302368164
rl training, epoch2, iter0, batch517/1133, batch loss:0.3463144302368164, Training time:5599.960783481598
batch reward last col mean 0.08955201506614685 first col mean 0.11870655417442322 all mean 0.10005006194114685
0.3709566295146942 0.3709566295146942
rl training, epoch2, iter0, batch518/1133, batch loss:0.3709566295146942, Training time:5602.405360460281
batch reward last col mean 0.14770027995109558 first col mean 0.12589213252067566 all mean 0.14103063941001892
0.342947393655777 0.342947393655777
rl training, epoch2, iter0, batch519/1133, batch loss:0.342947393655777, Training time:5604.082245588303
batch reward last col mean 0.1189802810549736 first col mean 0.11076129972934723 all mean 0.11840365082025528
0.33075422048568726 0.33075422048568726
rl training, epoch2, iter0, batch520/1133, batch loss:0.33075422048568726, Training time:5606.35812664032
batch reward last col mean 0.10348773002624512 first col mean 0.12447504699230194 all mean 0.10868405550718307
0.3000115156173706 0.3000115156173706
rl training, epoch2, iter0, batch521/1133, batch loss:0.3000115156173706, Training time:5608.29914689064
batch reward last col mean 0.15008313953876495 first col mean 0.12774106860160828 all mean 0.14124329388141632
0.3639831244945526 0.3639831244945526
rl training, epoch2, iter0, batch522/1133, batch loss:0.3639831244945526, Training time:5610.497914552689
batch reward last col mean 0.10664599388837814 first col mean 0.11165069043636322 all mean 0.11022044718265533
0.3397260904312134 0.3397260904312134
rl training, epoch2, iter0, batch523/1133, batch loss:0.3397260904312134, Training time:5612.216611146927
batch reward last col mean 0.08645554631948471 first col mean 0.11915723234415054 all mean 0.09133321791887283
0.2987893223762512 0.2987893223762512
rl training, epoch2, iter0, batch524/1133, batch loss:0.2987893223762512, Training time:5614.514620542526
batch reward last col mean 0.10257276892662048 first col mean 0.12866069376468658 all mean 0.11178338527679443
0.3210221529006958 0.3210221529006958
rl training, epoch2, iter0, batch525/1133, batch loss:0.3210221529006958, Training time:5616.849477052689
batch reward last col mean 0.10214190930128098 first col mean 0.1271304488182068 all mean 0.11171673983335495
0.3393666744232178 0.3393666744232178
rl training, epoch2, iter0, batch526/1133, batch loss:0.3393666744232178, Training time:5618.578358888626
batch reward last col mean 0.08574701845645905 first col mean 0.12007462978363037 all mean 0.10056763887405396
0.30055809020996094 0.30055809020996094
rl training, epoch2, iter0, batch527/1133, batch loss:0.30055809020996094, Training time:5620.228298664093
batch reward last col mean 0.1194329485297203 first col mean 0.11726880073547363 all mean 0.11859114468097687
0.3445376455783844 0.3445376455783844
rl training, epoch2, iter0, batch528/1133, batch loss:0.3445376455783844, Training time:5621.7635588645935
batch reward last col mean 0.1270284205675125 first col mean 0.1335395723581314 all mean 0.1208273246884346
0.3462112843990326 0.3462112843990326
rl training, epoch2, iter0, batch529/1133, batch loss:0.3462112843990326, Training time:5623.559317588806
batch reward last col mean 0.12966102361679077 first col mean 0.12587957084178925 all mean 0.1236078292131424
0.34551525115966797 0.34551528096199036
rl training, epoch2, iter0, batch530/1133, batch loss:0.34551528096199036, Training time:5625.29488325119
batch reward last col mean 0.1194019466638565 first col mean 0.13243089616298676 all mean 0.12128132581710815
0.3256149888038635 0.3256149888038635
rl training, epoch2, iter0, batch531/1133, batch loss:0.3256149888038635, Training time:5627.3004677295685
batch reward last col mean 0.132109597325325 first col mean 0.11613825708627701 all mean 0.12742429971694946
0.3368569314479828 0.3368569314479828
rl training, epoch2, iter0, batch532/1133, batch loss:0.3368569314479828, Training time:5629.429892063141
batch reward last col mean 0.12262602150440216 first col mean 0.13482257723808289 all mean 0.12118817120790482
0.3434469997882843 0.3434469997882843
rl training, epoch2, iter0, batch533/1133, batch loss:0.3434469997882843, Training time:5632.874855518341
batch reward last col mean 0.09411655366420746 first col mean 0.1345486044883728 all mean 0.09898760914802551
0.3328913152217865 0.3328913152217865
rl training, epoch2, iter0, batch534/1133, batch loss:0.3328913152217865, Training time:5635.074856996536
batch reward last col mean 0.09688457101583481 first col mean 0.11724191904067993 all mean 0.10877423733472824
0.39710733294487 0.39710733294487
rl training, epoch2, iter0, batch535/1133, batch loss:0.39710733294487, Training time:5636.569253444672
batch reward last col mean 0.13940726220607758 first col mean 0.11999739706516266 all mean 0.12610355019569397
0.3505299687385559 0.3505299687385559
rl training, epoch2, iter0, batch536/1133, batch loss:0.3505299687385559, Training time:5638.124016046524
batch reward last col mean 0.10594166070222855 first col mean 0.1115291565656662 all mean 0.10803958773612976
0.3127572536468506 0.3127572536468506
rl training, epoch2, iter0, batch537/1133, batch loss:0.3127572536468506, Training time:5640.00407576561
batch reward last col mean 0.12531140446662903 first col mean 0.13472597301006317 all mean 0.12223885953426361
0.39127951860427856 0.39127951860427856
rl training, epoch2, iter0, batch538/1133, batch loss:0.39127951860427856, Training time:5642.015821933746
batch reward last col mean 0.14973528683185577 first col mean 0.11860759556293488 all mean 0.14547820389270782
0.3975756764411926 0.3975756764411926
rl training, epoch2, iter0, batch539/1133, batch loss:0.3975756764411926, Training time:5644.630659341812
batch reward last col mean 0.1310558319091797 first col mean 0.11860837042331696 all mean 0.13641521334648132
0.3594203293323517 0.3594203591346741
rl training, epoch2, iter0, batch540/1133, batch loss:0.3594203591346741, Training time:5646.531071186066
batch reward last col mean 0.08409789949655533 first col mean 0.11942318081855774 all mean 0.09817688912153244
0.3104538321495056 0.3104538321495056
rl training, epoch2, iter0, batch541/1133, batch loss:0.3104538321495056, Training time:5648.613120555878
batch reward last col mean 0.12765902280807495 first col mean 0.14084362983703613 all mean 0.1286235898733139
0.3953167498111725 0.3953167498111725
rl training, epoch2, iter0, batch542/1133, batch loss:0.3953167498111725, Training time:5650.47115945816
batch reward last col mean 0.09887091815471649 first col mean 0.12773637473583221 all mean 0.1053495854139328
0.3884698748588562 0.3884698748588562
rl training, epoch2, iter0, batch543/1133, batch loss:0.3884698748588562, Training time:5652.628744363785
batch reward last col mean 0.12636521458625793 first col mean 0.13734200596809387 all mean 0.129242405295372
0.3362555205821991 0.3362555205821991
rl training, epoch2, iter0, batch544/1133, batch loss:0.3362555205821991, Training time:5654.520634651184
batch reward last col mean 0.1424509882926941 first col mean 0.10225977003574371 all mean 0.12960907816886902
0.33330637216567993 0.33330637216567993
rl training, epoch2, iter0, batch545/1133, batch loss:0.33330637216567993, Training time:5656.322741031647
batch reward last col mean 0.1274385154247284 first col mean 0.13055261969566345 all mean 0.12992405891418457
0.39530742168426514 0.39530742168426514
rl training, epoch2, iter0, batch546/1133, batch loss:0.39530742168426514, Training time:5658.48405122757
batch reward last col mean 0.11142396926879883 first col mean 0.11992590874433517 all mean 0.11575756222009659
0.36962389945983887 0.36962389945983887
rl training, epoch2, iter0, batch547/1133, batch loss:0.36962389945983887, Training time:5660.865014791489
batch reward last col mean 0.1233316957950592 first col mean 0.11931418627500534 all mean 0.12479818612337112
0.3328152894973755 0.3328152894973755
rl training, epoch2, iter0, batch548/1133, batch loss:0.3328152894973755, Training time:5663.082130432129
batch reward last col mean 0.10069555044174194 first col mean 0.12556388974189758 all mean 0.09710809588432312
0.32686668634414673 0.32686668634414673
rl training, epoch2, iter0, batch549/1133, batch loss:0.32686668634414673, Training time:5664.632974147797
batch reward last col mean 0.09228074550628662 first col mean 0.12697619199752808 all mean 0.10175402462482452
0.3390452265739441 0.3390452265739441
rl training, epoch2, iter0, batch550/1133, batch loss:0.3390452265739441, Training time:5666.299617052078
batch reward last col mean 0.11033886671066284 first col mean 0.14190471172332764 all mean 0.11878048628568649
0.38488492369651794 0.38488492369651794
rl training, epoch2, iter0, batch551/1133, batch loss:0.38488492369651794, Training time:5667.96160531044
batch reward last col mean 0.10185549408197403 first col mean 0.12468935549259186 all mean 0.10588233917951584
0.34385785460472107 0.3438578248023987
rl training, epoch2, iter0, batch552/1133, batch loss:0.3438578248023987, Training time:5669.880893468857
batch reward last col mean 0.12710082530975342 first col mean 0.09691434353590012 all mean 0.12635308504104614
0.34896281361579895 0.34896281361579895
rl training, epoch2, iter0, batch553/1133, batch loss:0.34896281361579895, Training time:5672.042968034744
batch reward last col mean 0.1227627545595169 first col mean 0.1581282764673233 all mean 0.12172939628362656
0.37336453795433044 0.37336453795433044
rl training, epoch2, iter0, batch554/1133, batch loss:0.37336453795433044, Training time:5673.9051332473755
batch reward last col mean 0.12456361204385757 first col mean 0.1500953733921051 all mean 0.13100385665893555
0.38884592056274414 0.38884592056274414
rl training, epoch2, iter0, batch555/1133, batch loss:0.38884592056274414, Training time:5675.5743844509125
batch reward last col mean 0.07764872908592224 first col mean 0.11867382377386093 all mean 0.0898810401558876
0.2983373999595642 0.2983373999595642
rl training, epoch2, iter0, batch556/1133, batch loss:0.2983373999595642, Training time:5677.286893606186
batch reward last col mean 0.07186064124107361 first col mean 0.12549865245819092 all mean 0.08929021656513214
0.30341628193855286 0.30341631174087524
rl training, epoch2, iter0, batch557/1133, batch loss:0.30341631174087524, Training time:5679.236391782761
batch reward last col mean 0.12277406454086304 first col mean 0.1244015172123909 all mean 0.12182602286338806
0.3483634889125824 0.3483634889125824
rl training, epoch2, iter0, batch558/1133, batch loss:0.3483634889125824, Training time:5681.08605837822
batch reward last col mean 0.15396296977996826 first col mean 0.13263219594955444 all mean 0.1508525311946869
0.388079434633255 0.388079434633255
rl training, epoch2, iter0, batch559/1133, batch loss:0.388079434633255, Training time:5683.4405336380005
batch reward last col mean 0.13636299967765808 first col mean 0.13131245970726013 all mean 0.13559003174304962
0.39603695273399353 0.39603695273399353
rl training, epoch2, iter0, batch560/1133, batch loss:0.39603695273399353, Training time:5685.262946367264
batch reward last col mean 0.09481333941221237 first col mean 0.11928494274616241 all mean 0.09497851878404617
0.2993902862071991 0.2993902862071991
rl training, epoch2, iter0, batch561/1133, batch loss:0.2993902862071991, Training time:5687.772439479828
batch reward last col mean 0.1399025022983551 first col mean 0.12660378217697144 all mean 0.13601630926132202
0.39501577615737915 0.39501577615737915
rl training, epoch2, iter0, batch562/1133, batch loss:0.39501577615737915, Training time:5689.520561218262
batch reward last col mean 0.14014819264411926 first col mean 0.1160673052072525 all mean 0.13467203080654144
0.3561560809612274 0.3561560809612274
rl training, epoch2, iter0, batch563/1133, batch loss:0.3561560809612274, Training time:5691.654286623001
batch reward last col mean 0.11424819380044937 first col mean 0.1306144893169403 all mean 0.12173128128051758
0.3924723267555237 0.3924722969532013
rl training, epoch2, iter0, batch564/1133, batch loss:0.3924722969532013, Training time:5693.549428224564
batch reward last col mean 0.1488761156797409 first col mean 0.1242942363023758 all mean 0.14894889295101166
0.4453809857368469 0.4453809857368469
rl training, epoch2, iter0, batch565/1133, batch loss:0.4453809857368469, Training time:5695.499425411224
batch reward last col mean 0.15480035543441772 first col mean 0.1045437902212143 all mean 0.14799551665782928
0.33932894468307495 0.33932894468307495
rl training, epoch2, iter0, batch566/1133, batch loss:0.33932894468307495, Training time:5697.843865633011
batch reward last col mean 0.1401938647031784 first col mean 0.12283733487129211 all mean 0.13708961009979248
0.36426374316215515 0.36426374316215515
rl training, epoch2, iter0, batch567/1133, batch loss:0.36426374316215515, Training time:5699.662333011627
batch reward last col mean 0.11613105237483978 first col mean 0.12957659363746643 all mean 0.1182093620300293
0.36603203415870667 0.36603203415870667
rl training, epoch2, iter0, batch568/1133, batch loss:0.36603203415870667, Training time:5701.2352867126465
batch reward last col mean 0.1584959328174591 first col mean 0.12906278669834137 all mean 0.1463082879781723
0.3695586323738098 0.3695586323738098
rl training, epoch2, iter0, batch569/1133, batch loss:0.3695586323738098, Training time:5703.087788581848
batch reward last col mean 0.09917797893285751 first col mean 0.12490497529506683 all mean 0.10815024375915527
0.34287333488464355 0.34287333488464355
rl training, epoch2, iter0, batch570/1133, batch loss:0.34287333488464355, Training time:5704.811774492264
batch reward last col mean 0.114851213991642 first col mean 0.132512629032135 all mean 0.12145824730396271
0.3626660704612732 0.3626660704612732
rl training, epoch2, iter0, batch571/1133, batch loss:0.3626660704612732, Training time:5706.698641777039
batch reward last col mean 0.1427689492702484 first col mean 0.13260138034820557 all mean 0.133998841047287
0.37434911727905273 0.37434911727905273
rl training, epoch2, iter0, batch572/1133, batch loss:0.37434911727905273, Training time:5708.377557277679
batch reward last col mean 0.16300907731056213 first col mean 0.1360395848751068 all mean 0.1556866466999054
0.4203944504261017 0.4203944504261017
rl training, epoch2, iter0, batch573/1133, batch loss:0.4203944504261017, Training time:5710.496312379837
batch reward last col mean 0.08475115150213242 first col mean 0.11992795765399933 all mean 0.09352126717567444
0.32848259806632996 0.32848259806632996
rl training, epoch2, iter0, batch574/1133, batch loss:0.32848259806632996, Training time:5712.713498353958
batch reward last col mean 0.11406682431697845 first col mean 0.14658471941947937 all mean 0.12485930323600769
0.36583471298217773 0.36583471298217773
rl training, epoch2, iter0, batch575/1133, batch loss:0.36583471298217773, Training time:5714.811192512512
batch reward last col mean 0.13545703887939453 first col mean 0.12069399654865265 all mean 0.13348309695720673
0.37257134914398193 0.37257134914398193
rl training, epoch2, iter0, batch576/1133, batch loss:0.37257134914398193, Training time:5717.268734693527
batch reward last col mean 0.15664252638816833 first col mean 0.10815554857254028 all mean 0.14991137385368347
0.41948843002319336 0.41948843002319336
rl training, epoch2, iter0, batch577/1133, batch loss:0.41948843002319336, Training time:5720.357964515686
batch reward last col mean 0.11922330409288406 first col mean 0.12593510746955872 all mean 0.12388979643583298
0.3548489809036255 0.3548489809036255
rl training, epoch2, iter0, batch578/1133, batch loss:0.3548489809036255, Training time:5722.272383451462
batch reward last col mean 0.14253994822502136 first col mean 0.14266225695610046 all mean 0.13974569737911224
0.35422036051750183 0.35422030091285706
rl training, epoch2, iter0, batch579/1133, batch loss:0.35422030091285706, Training time:5724.147515773773
batch reward last col mean 0.09563033282756805 first col mean 0.1291540414094925 all mean 0.09690624475479126
0.31122028827667236 0.31122028827667236
rl training, epoch2, iter0, batch580/1133, batch loss:0.31122028827667236, Training time:5725.864527463913
batch reward last col mean 0.11125732213258743 first col mean 0.10956049710512161 all mean 0.120613232254982
0.37453293800354004 0.37453290820121765
rl training, epoch2, iter0, batch581/1133, batch loss:0.37453290820121765, Training time:5727.882838010788
batch reward last col mean 0.0953538790345192 first col mean 0.13208234310150146 all mean 0.10446994006633759
0.31993868947029114 0.31993868947029114
rl training, epoch2, iter0, batch582/1133, batch loss:0.31993868947029114, Training time:5729.8596267700195
batch reward last col mean 0.12046607583761215 first col mean 0.11394667625427246 all mean 0.12922462821006775
0.3944450318813324 0.3944450318813324
rl training, epoch2, iter0, batch583/1133, batch loss:0.3944450318813324, Training time:5731.494736909866
batch reward last col mean 0.15942110121250153 first col mean 0.1214718297123909 all mean 0.14955079555511475
0.38713333010673523 0.38713333010673523
rl training, epoch2, iter0, batch584/1133, batch loss:0.38713333010673523, Training time:5733.282574176788
batch reward last col mean 0.11886975169181824 first col mean 0.12742917239665985 all mean 0.11869438737630844
0.31825414299964905 0.31825414299964905
rl training, epoch2, iter0, batch585/1133, batch loss:0.31825414299964905, Training time:5735.289090633392
batch reward last col mean 0.12394749373197556 first col mean 0.12646758556365967 all mean 0.12022712826728821
0.3492179214954376 0.3492179214954376
rl training, epoch2, iter0, batch586/1133, batch loss:0.3492179214954376, Training time:5737.956551790237
batch reward last col mean 0.12563176453113556 first col mean 0.12893050909042358 all mean 0.12466248869895935
0.37880298495292664 0.37880295515060425
rl training, epoch2, iter0, batch587/1133, batch loss:0.37880295515060425, Training time:5740.118164777756
batch reward last col mean 0.13754083216190338 first col mean 0.13152219355106354 all mean 0.1315254122018814
0.3663049638271332 0.3663049638271332
rl training, epoch2, iter0, batch588/1133, batch loss:0.3663049638271332, Training time:5742.883650302887
batch reward last col mean 0.13621392846107483 first col mean 0.11088297516107559 all mean 0.13321584463119507
0.3768855333328247 0.37688547372817993
rl training, epoch2, iter0, batch589/1133, batch loss:0.37688547372817993, Training time:5744.61704659462
batch reward last col mean 0.14324267208576202 first col mean 0.14450082182884216 all mean 0.1357768476009369
0.4026012122631073 0.4026011526584625
rl training, epoch2, iter0, batch590/1133, batch loss:0.4026011526584625, Training time:5746.210830926895
batch reward last col mean 0.1224205419421196 first col mean 0.1283482313156128 all mean 0.12353982031345367
0.37405264377593994 0.37405258417129517
rl training, epoch2, iter0, batch591/1133, batch loss:0.37405258417129517, Training time:5748.128827095032
batch reward last col mean 0.1338425874710083 first col mean 0.12296682596206665 all mean 0.13180939853191376
0.39457249641418457 0.39457249641418457
rl training, epoch2, iter0, batch592/1133, batch loss:0.39457249641418457, Training time:5750.679499387741
batch reward last col mean 0.10356172174215317 first col mean 0.1255791187286377 all mean 0.10985955595970154
0.3647787570953369 0.3647787570953369
rl training, epoch2, iter0, batch593/1133, batch loss:0.3647787570953369, Training time:5752.928864240646
batch reward last col mean 0.13406117260456085 first col mean 0.13719844818115234 all mean 0.13106925785541534
0.346331924200058 0.346331924200058
rl training, epoch2, iter0, batch594/1133, batch loss:0.346331924200058, Training time:5755.418019533157
batch reward last col mean 0.12031780183315277 first col mean 0.1259962022304535 all mean 0.12486924231052399
0.3766704201698303 0.3766704201698303
rl training, epoch2, iter0, batch595/1133, batch loss:0.3766704201698303, Training time:5757.085710287094
batch reward last col mean 0.13544461131095886 first col mean 0.1292135864496231 all mean 0.1349538415670395
0.3941018283367157 0.3941018283367157
rl training, epoch2, iter0, batch596/1133, batch loss:0.3941018283367157, Training time:5758.604443073273
batch reward last col mean 0.15877887606620789 first col mean 0.11778087913990021 all mean 0.15247030556201935
0.42325907945632935 0.42325907945632935
rl training, epoch2, iter0, batch597/1133, batch loss:0.42325907945632935, Training time:5761.079857826233
batch reward last col mean 0.10881095379590988 first col mean 0.12615066766738892 all mean 0.11461528390645981
0.34642234444618225 0.34642234444618225
rl training, epoch2, iter0, batch598/1133, batch loss:0.34642234444618225, Training time:5762.825816869736
batch reward last col mean 0.12257949262857437 first col mean 0.12157443165779114 all mean 0.12314294278621674
0.3479417860507965 0.3479417860507965
rl training, epoch2, iter0, batch599/1133, batch loss:0.3479417860507965, Training time:5764.449231386185
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5742173625217111 Time: 98.04886293411255 s
loss of true 0.2567394920949481 loss of gen 0.1988588795789237 loss of other 0.1186189906998798 first score 0.1384650468826294
batch reward last col mean 0.13715001940727234 first col mean 0.1340004801750183 all mean 0.13920606672763824
0.402179479598999 0.402179479598999
rl training, epoch2, iter0, batch600/1133, batch loss:0.402179479598999, Training time:5864.822383880615
batch reward last col mean 0.10505001246929169 first col mean 0.10700299590826035 all mean 0.1079736202955246
0.32757383584976196 0.32757383584976196
rl training, epoch2, iter0, batch601/1133, batch loss:0.32757383584976196, Training time:5866.914830446243
batch reward last col mean 0.11302204430103302 first col mean 0.12274935841560364 all mean 0.12334100902080536
0.35035499930381775 0.35035499930381775
rl training, epoch2, iter0, batch602/1133, batch loss:0.35035499930381775, Training time:5868.691824197769
batch reward last col mean 0.09458495676517487 first col mean 0.10388058423995972 all mean 0.09621550887823105
0.29754403233528137 0.29754403233528137
rl training, epoch2, iter0, batch603/1133, batch loss:0.29754403233528137, Training time:5870.896421432495
batch reward last col mean 0.12145661562681198 first col mean 0.1181240975856781 all mean 0.1222309097647667
0.33498048782348633 0.33498048782348633
rl training, epoch2, iter0, batch604/1133, batch loss:0.33498048782348633, Training time:5873.236034393311
batch reward last col mean 0.10761431604623795 first col mean 0.11174656450748444 all mean 0.10830377787351608
0.2908226251602173 0.2908226251602173
rl training, epoch2, iter0, batch605/1133, batch loss:0.2908226251602173, Training time:5875.279603004456
batch reward last col mean 0.1257823407649994 first col mean 0.11533363163471222 all mean 0.1225021481513977
0.3660808503627777 0.3660808503627777
rl training, epoch2, iter0, batch606/1133, batch loss:0.3660808503627777, Training time:5876.921473264694
batch reward last col mean 0.1099865734577179 first col mean 0.15075427293777466 all mean 0.11661814898252487
0.3329925835132599 0.3329925835132599
rl training, epoch2, iter0, batch607/1133, batch loss:0.3329925835132599, Training time:5878.376131057739
batch reward last col mean 0.10717225074768066 first col mean 0.10532105714082718 all mean 0.10858485102653503
0.2875564694404602 0.2875564694404602
rl training, epoch2, iter0, batch608/1133, batch loss:0.2875564694404602, Training time:5880.33301115036
batch reward last col mean 0.15717530250549316 first col mean 0.13016173243522644 all mean 0.1422373205423355
0.34322020411491394 0.34322020411491394
rl training, epoch2, iter0, batch609/1133, batch loss:0.34322020411491394, Training time:5881.90274810791
batch reward last col mean 0.11315511167049408 first col mean 0.13922294974327087 all mean 0.11688601225614548
0.2939488887786865 0.2939488887786865
rl training, epoch2, iter0, batch610/1133, batch loss:0.2939488887786865, Training time:5884.2977385520935
batch reward last col mean 0.10470223426818848 first col mean 0.1310988962650299 all mean 0.10917185992002487
0.3282393217086792 0.3282393217086792
rl training, epoch2, iter0, batch611/1133, batch loss:0.3282393217086792, Training time:5886.433408498764
batch reward last col mean 0.12487451732158661 first col mean 0.12259810417890549 all mean 0.12712743878364563
0.3313593566417694 0.3313593566417694
rl training, epoch2, iter0, batch612/1133, batch loss:0.3313593566417694, Training time:5888.3088183403015
batch reward last col mean 0.1332491636276245 first col mean 0.12093159556388855 all mean 0.13346366584300995
0.3611091077327728 0.3611091077327728
rl training, epoch2, iter0, batch613/1133, batch loss:0.3611091077327728, Training time:5890.238576889038
batch reward last col mean 0.12590569257736206 first col mean 0.11704904586076736 all mean 0.1301373690366745
0.3796588182449341 0.3796588182449341
rl training, epoch2, iter0, batch614/1133, batch loss:0.3796588182449341, Training time:5891.773149490356
batch reward last col mean 0.1090262234210968 first col mean 0.14071206748485565 all mean 0.11234481632709503
0.34413912892341614 0.34413912892341614
rl training, epoch2, iter0, batch615/1133, batch loss:0.34413912892341614, Training time:5893.47074341774
batch reward last col mean 0.12513059377670288 first col mean 0.1265699565410614 all mean 0.12828268110752106
0.37703123688697815 0.37703123688697815
rl training, epoch2, iter0, batch616/1133, batch loss:0.37703123688697815, Training time:5895.445014476776
batch reward last col mean 0.11536475270986557 first col mean 0.12302539497613907 all mean 0.11806025356054306
0.3477199375629425 0.3477199375629425
rl training, epoch2, iter0, batch617/1133, batch loss:0.3477199375629425, Training time:5897.129266738892
batch reward last col mean 0.09670423716306686 first col mean 0.12121565639972687 all mean 0.10823045670986176
0.38935455679893494 0.38935455679893494
rl training, epoch2, iter0, batch618/1133, batch loss:0.38935455679893494, Training time:5898.93384885788
batch reward last col mean 0.135993093252182 first col mean 0.12913483381271362 all mean 0.1333475410938263
0.3780760169029236 0.3780759871006012
rl training, epoch2, iter0, batch619/1133, batch loss:0.3780759871006012, Training time:5900.829760313034
batch reward last col mean 0.12652739882469177 first col mean 0.12168516218662262 all mean 0.11952754855155945
0.2972056269645691 0.2972056269645691
rl training, epoch2, iter0, batch620/1133, batch loss:0.2972056269645691, Training time:5902.4269824028015
batch reward last col mean 0.10846827924251556 first col mean 0.11652453243732452 all mean 0.11166631430387497
0.3602602481842041 0.3602602481842041
rl training, epoch2, iter0, batch621/1133, batch loss:0.3602602481842041, Training time:5903.99918794632
batch reward last col mean 0.15488603711128235 first col mean 0.12283007055521011 all mean 0.14855363965034485
0.3997254967689514 0.3997254967689514
rl training, epoch2, iter0, batch622/1133, batch loss:0.3997254967689514, Training time:5906.044333219528
batch reward last col mean 0.1490129828453064 first col mean 0.10804548859596252 all mean 0.14179089665412903
0.35950320959091187 0.35950320959091187
rl training, epoch2, iter0, batch623/1133, batch loss:0.35950320959091187, Training time:5907.639418125153
batch reward last col mean 0.1626659482717514 first col mean 0.10834330320358276 all mean 0.14946483075618744
0.38788270950317383 0.38788270950317383
rl training, epoch2, iter0, batch624/1133, batch loss:0.38788270950317383, Training time:5909.255934238434
batch reward last col mean 0.11668981611728668 first col mean 0.1240675300359726 all mean 0.12147661298513412
0.3615313172340393 0.3615313172340393
rl training, epoch2, iter0, batch625/1133, batch loss:0.3615313172340393, Training time:5910.827689409256
batch reward last col mean 0.10731329768896103 first col mean 0.11535853147506714 all mean 0.10926709324121475
0.3406237065792084 0.3406237065792084
rl training, epoch2, iter0, batch626/1133, batch loss:0.3406237065792084, Training time:5912.868318080902
batch reward last col mean 0.12341730296611786 first col mean 0.13104411959648132 all mean 0.12169011682271957
0.3321114182472229 0.3321114182472229
rl training, epoch2, iter0, batch627/1133, batch loss:0.3321114182472229, Training time:5914.986838579178
batch reward last col mean 0.1255359649658203 first col mean 0.11220037192106247 all mean 0.12884913384914398
0.32549849152565 0.32549846172332764
rl training, epoch2, iter0, batch628/1133, batch loss:0.32549846172332764, Training time:5916.487215042114
batch reward last col mean 0.11463064700365067 first col mean 0.12516579031944275 all mean 0.11436153203248978
0.3172411024570465 0.3172411024570465
rl training, epoch2, iter0, batch629/1133, batch loss:0.3172411024570465, Training time:5918.30027961731
batch reward last col mean 0.10693315416574478 first col mean 0.1136079877614975 all mean 0.10908166319131851
0.31797662377357483 0.31797662377357483
rl training, epoch2, iter0, batch630/1133, batch loss:0.31797662377357483, Training time:5919.976112127304
batch reward last col mean 0.11422640830278397 first col mean 0.11887341737747192 all mean 0.1186966598033905
0.35078686475753784 0.35078689455986023
rl training, epoch2, iter0, batch631/1133, batch loss:0.35078689455986023, Training time:5921.817809343338
batch reward last col mean 0.11114443838596344 first col mean 0.14394770562648773 all mean 0.11432027816772461
0.33018872141838074 0.33018872141838074
rl training, epoch2, iter0, batch632/1133, batch loss:0.33018872141838074, Training time:5923.609958410263
batch reward last col mean 0.1229906976222992 first col mean 0.13986286520957947 all mean 0.12305846810340881
0.35887590050697327 0.35887590050697327
rl training, epoch2, iter0, batch633/1133, batch loss:0.35887590050697327, Training time:5925.5700488090515
batch reward last col mean 0.13967148959636688 first col mean 0.11141075193881989 all mean 0.1351642906665802
0.338051974773407 0.338051974773407
rl training, epoch2, iter0, batch634/1133, batch loss:0.338051974773407, Training time:5928.087778806686
batch reward last col mean 0.15957114100456238 first col mean 0.1372183859348297 all mean 0.1451301872730255
0.3799012005329132 0.3799012005329132
rl training, epoch2, iter0, batch635/1133, batch loss:0.3799012005329132, Training time:5929.953234434128
batch reward last col mean 0.13773518800735474 first col mean 0.12043415009975433 all mean 0.13416893780231476
0.36602726578712463 0.36602726578712463
rl training, epoch2, iter0, batch636/1133, batch loss:0.36602726578712463, Training time:5932.132247209549
batch reward last col mean 0.12741298973560333 first col mean 0.11252130568027496 all mean 0.12765921652317047
0.3479955196380615 0.3479955196380615
rl training, epoch2, iter0, batch637/1133, batch loss:0.3479955196380615, Training time:5933.703150510788
batch reward last col mean 0.15888676047325134 first col mean 0.1372387707233429 all mean 0.1503768414258957
0.3744419813156128 0.3744419813156128
rl training, epoch2, iter0, batch638/1133, batch loss:0.3744419813156128, Training time:5935.531588315964
batch reward last col mean 0.1034676730632782 first col mean 0.10761987417936325 all mean 0.10576654225587845
0.3164091408252716 0.3164091408252716
rl training, epoch2, iter0, batch639/1133, batch loss:0.3164091408252716, Training time:5937.426785230637
batch reward last col mean 0.14023783802986145 first col mean 0.13886219263076782 all mean 0.12737257778644562
0.3637855350971222 0.3637855350971222
rl training, epoch2, iter0, batch640/1133, batch loss:0.3637855350971222, Training time:5939.079513311386
batch reward last col mean 0.14608675241470337 first col mean 0.15210485458374023 all mean 0.1382443755865097
0.34419187903404236 0.34419187903404236
rl training, epoch2, iter0, batch641/1133, batch loss:0.34419187903404236, Training time:5940.721416711807
batch reward last col mean 0.11707127094268799 first col mean 0.12466117739677429 all mean 0.11262910813093185
0.2983861565589905 0.2983861565589905
rl training, epoch2, iter0, batch642/1133, batch loss:0.2983861565589905, Training time:5942.432147979736
batch reward last col mean 0.07522991299629211 first col mean 0.11595258116722107 all mean 0.0883803516626358
0.2990645170211792 0.2990645468235016
rl training, epoch2, iter0, batch643/1133, batch loss:0.2990645468235016, Training time:5944.065009832382
batch reward last col mean 0.1339690387248993 first col mean 0.136421799659729 all mean 0.13253267109394073
0.39673879742622375 0.39673879742622375
rl training, epoch2, iter0, batch644/1133, batch loss:0.39673879742622375, Training time:5945.741540431976
batch reward last col mean 0.10551664233207703 first col mean 0.1336010843515396 all mean 0.1204456239938736
0.3361514210700989 0.3361514210700989
rl training, epoch2, iter0, batch645/1133, batch loss:0.3361514210700989, Training time:5947.257107496262
batch reward last col mean 0.0947326123714447 first col mean 0.1319696009159088 all mean 0.09865090250968933
0.3510814905166626 0.3510814905166626
rl training, epoch2, iter0, batch646/1133, batch loss:0.3510814905166626, Training time:5949.117313861847
batch reward last col mean 0.07847816497087479 first col mean 0.13538359105587006 all mean 0.09035037457942963
0.3347732722759247 0.3347732722759247
rl training, epoch2, iter0, batch647/1133, batch loss:0.3347732722759247, Training time:5951.276593208313
batch reward last col mean 0.1098208874464035 first col mean 0.13144651055335999 all mean 0.11564840376377106
0.3640401065349579 0.3640401065349579
rl training, epoch2, iter0, batch648/1133, batch loss:0.3640401065349579, Training time:5953.246492862701
batch reward last col mean 0.14506180584430695 first col mean 0.10657522082328796 all mean 0.13373614847660065
0.35691943764686584 0.35691943764686584
rl training, epoch2, iter0, batch649/1133, batch loss:0.35691943764686584, Training time:5955.077286243439
batch reward last col mean 0.12567351758480072 first col mean 0.15050940215587616 all mean 0.13228252530097961
0.372749000787735 0.372749000787735
rl training, epoch2, iter0, batch650/1133, batch loss:0.372749000787735, Training time:5957.03800868988
batch reward last col mean 0.12266550958156586 first col mean 0.1259765774011612 all mean 0.12541554868221283
0.34825608134269714 0.34825608134269714
rl training, epoch2, iter0, batch651/1133, batch loss:0.34825608134269714, Training time:5958.912122488022
batch reward last col mean 0.10465118288993835 first col mean 0.13844798505306244 all mean 0.11245124787092209
0.3773247003555298 0.3773247003555298
rl training, epoch2, iter0, batch652/1133, batch loss:0.3773247003555298, Training time:5960.575491666794
batch reward last col mean 0.09095504879951477 first col mean 0.12443406134843826 all mean 0.10323693603277206
0.3121490776538849 0.3121490776538849
rl training, epoch2, iter0, batch653/1133, batch loss:0.3121490776538849, Training time:5962.1879687309265
batch reward last col mean 0.11227871477603912 first col mean 0.12879401445388794 all mean 0.11750509589910507
0.33099544048309326 0.33099544048309326
rl training, epoch2, iter0, batch654/1133, batch loss:0.33099544048309326, Training time:5963.950075387955
batch reward last col mean 0.11694686859846115 first col mean 0.12002599239349365 all mean 0.120723195374012
0.33910906314849854 0.33910906314849854
rl training, epoch2, iter0, batch655/1133, batch loss:0.33910906314849854, Training time:5966.096867084503
batch reward last col mean 0.12476493418216705 first col mean 0.12843385338783264 all mean 0.13615283370018005
0.3830304443836212 0.3830304443836212
rl training, epoch2, iter0, batch656/1133, batch loss:0.3830304443836212, Training time:5967.793385267258
batch reward last col mean 0.12534260749816895 first col mean 0.1292203962802887 all mean 0.12704060971736908
0.35948774218559265 0.35948771238327026
rl training, epoch2, iter0, batch657/1133, batch loss:0.35948771238327026, Training time:5969.512272119522
batch reward last col mean 0.12146338820457458 first col mean 0.13540565967559814 all mean 0.12368687987327576
0.3097971975803375 0.3097971975803375
rl training, epoch2, iter0, batch658/1133, batch loss:0.3097971975803375, Training time:5971.796021699905
batch reward last col mean 0.1178419440984726 first col mean 0.1251794695854187 all mean 0.11748580634593964
0.36020156741142273 0.36020156741142273
rl training, epoch2, iter0, batch659/1133, batch loss:0.36020156741142273, Training time:5974.471550703049
batch reward last col mean 0.1319480538368225 first col mean 0.11704963445663452 all mean 0.13110029697418213
0.37721872329711914 0.37721872329711914
rl training, epoch2, iter0, batch660/1133, batch loss:0.37721872329711914, Training time:5976.014836072922
batch reward last col mean 0.1294822096824646 first col mean 0.12088929861783981 all mean 0.12790453433990479
0.34643661975860596 0.34643661975860596
rl training, epoch2, iter0, batch661/1133, batch loss:0.34643661975860596, Training time:5977.641545057297
batch reward last col mean 0.12553901970386505 first col mean 0.11004257202148438 all mean 0.12234727293252945
0.31785282492637634 0.31785282492637634
rl training, epoch2, iter0, batch662/1133, batch loss:0.31785282492637634, Training time:5980.285728216171
batch reward last col mean 0.1422564536333084 first col mean 0.1319044977426529 all mean 0.12874092161655426
0.3687876760959625 0.3687876760959625
rl training, epoch2, iter0, batch663/1133, batch loss:0.3687876760959625, Training time:5981.973649263382
batch reward last col mean 0.11139314621686935 first col mean 0.13265328109264374 all mean 0.12172280251979828
0.32228007912635803 0.32228007912635803
rl training, epoch2, iter0, batch664/1133, batch loss:0.32228007912635803, Training time:5983.397521495819
batch reward last col mean 0.1022900640964508 first col mean 0.15499165654182434 all mean 0.11309368163347244
0.3170892298221588 0.3170892298221588
rl training, epoch2, iter0, batch665/1133, batch loss:0.3170892298221588, Training time:5985.709604263306
batch reward last col mean 0.12953419983386993 first col mean 0.13660308718681335 all mean 0.12401242554187775
0.3848111629486084 0.384811133146286
rl training, epoch2, iter0, batch666/1133, batch loss:0.384811133146286, Training time:5987.076573133469
batch reward last col mean 0.10154270380735397 first col mean 0.13193446397781372 all mean 0.11899323761463165
0.40533447265625 0.40533447265625
rl training, epoch2, iter0, batch667/1133, batch loss:0.40533447265625, Training time:5988.638309001923
batch reward last col mean 0.12173923850059509 first col mean 0.1390674114227295 all mean 0.12700150907039642
0.35691866278648376 0.35691866278648376
rl training, epoch2, iter0, batch668/1133, batch loss:0.35691866278648376, Training time:5990.343543767929
batch reward last col mean 0.1135396733880043 first col mean 0.12979143857955933 all mean 0.11742882430553436
0.3641902506351471 0.3641902506351471
rl training, epoch2, iter0, batch669/1133, batch loss:0.3641902506351471, Training time:5992.16472196579
batch reward last col mean 0.1480303406715393 first col mean 0.12656071782112122 all mean 0.14190182089805603
0.402018278837204 0.402018278837204
rl training, epoch2, iter0, batch670/1133, batch loss:0.402018278837204, Training time:5993.7364773750305
batch reward last col mean 0.13646145164966583 first col mean 0.1409672647714615 all mean 0.13340164721012115
0.34792083501815796 0.34792083501815796
rl training, epoch2, iter0, batch671/1133, batch loss:0.34792083501815796, Training time:5995.299352645874
batch reward last col mean 0.12195217609405518 first col mean 0.12681153416633606 all mean 0.13149377703666687
0.3997643291950226 0.3997643291950226
rl training, epoch2, iter0, batch672/1133, batch loss:0.3997643291950226, Training time:5996.963970184326
batch reward last col mean 0.14271114766597748 first col mean 0.1367470771074295 all mean 0.13758085668087006
0.36073586344718933 0.36073586344718933
rl training, epoch2, iter0, batch673/1133, batch loss:0.36073586344718933, Training time:5998.697610616684
batch reward last col mean 0.14942622184753418 first col mean 0.13124437630176544 all mean 0.14122997224330902
0.34844866394996643 0.34844866394996643
rl training, epoch2, iter0, batch674/1133, batch loss:0.34844866394996643, Training time:6000.2565767765045
batch reward last col mean 0.09692731499671936 first col mean 0.13153940439224243 all mean 0.10085272789001465
0.3062305748462677 0.3062305748462677
rl training, epoch2, iter0, batch675/1133, batch loss:0.3062305748462677, Training time:6001.83737206459
batch reward last col mean 0.12397068738937378 first col mean 0.12978854775428772 all mean 0.12639503180980682
0.36742469668388367 0.36742469668388367
rl training, epoch2, iter0, batch676/1133, batch loss:0.36742469668388367, Training time:6003.347049713135
batch reward last col mean 0.1332499086856842 first col mean 0.13457149267196655 all mean 0.13296470046043396
0.3768852949142456 0.3768852949142456
rl training, epoch2, iter0, batch677/1133, batch loss:0.3768852949142456, Training time:6005.431745767593
batch reward last col mean 0.11754526197910309 first col mean 0.13384604454040527 all mean 0.12026229500770569
0.38287869095802307 0.38287869095802307
rl training, epoch2, iter0, batch678/1133, batch loss:0.38287869095802307, Training time:6007.520596265793
batch reward last col mean 0.10965872555971146 first col mean 0.11940301954746246 all mean 0.11344676464796066
0.367823988199234 0.367823988199234
rl training, epoch2, iter0, batch679/1133, batch loss:0.367823988199234, Training time:6009.2459580898285
batch reward last col mean 0.13791611790657043 first col mean 0.12685105204582214 all mean 0.1387377828359604
0.3678540587425232 0.3678540587425232
rl training, epoch2, iter0, batch680/1133, batch loss:0.3678540587425232, Training time:6011.083933830261
batch reward last col mean 0.11262202262878418 first col mean 0.13909518718719482 all mean 0.11882010847330093
0.34903109073638916 0.34903109073638916
rl training, epoch2, iter0, batch681/1133, batch loss:0.34903109073638916, Training time:6013.680727005005
batch reward last col mean 0.13558652997016907 first col mean 0.12225575745105743 all mean 0.13333161175251007
0.3560088574886322 0.3560088574886322
rl training, epoch2, iter0, batch682/1133, batch loss:0.3560088574886322, Training time:6015.743750572205
batch reward last col mean 0.10534251481294632 first col mean 0.13933932781219482 all mean 0.11072048544883728
0.36179304122924805 0.36179304122924805
rl training, epoch2, iter0, batch683/1133, batch loss:0.36179304122924805, Training time:6017.481191635132
batch reward last col mean 0.10399390012025833 first col mean 0.11809872090816498 all mean 0.11193328350782394
0.3235529661178589 0.3235529661178589
rl training, epoch2, iter0, batch684/1133, batch loss:0.3235529661178589, Training time:6019.155190229416
batch reward last col mean 0.14178913831710815 first col mean 0.11988507211208344 all mean 0.13494278490543365
0.3648220896720886 0.3648220896720886
rl training, epoch2, iter0, batch685/1133, batch loss:0.3648220896720886, Training time:6020.9127016067505
batch reward last col mean 0.12632377445697784 first col mean 0.1378743052482605 all mean 0.1266706883907318
0.34502971172332764 0.34502971172332764
rl training, epoch2, iter0, batch686/1133, batch loss:0.34502971172332764, Training time:6022.74188542366
batch reward last col mean 0.10887256264686584 first col mean 0.14329849183559418 all mean 0.1199730783700943
0.3925376534461975 0.3925376534461975
rl training, epoch2, iter0, batch687/1133, batch loss:0.3925376534461975, Training time:6024.757705688477
batch reward last col mean 0.10578278452157974 first col mean 0.12973980605602264 all mean 0.11735256016254425
0.33531439304351807 0.33531439304351807
rl training, epoch2, iter0, batch688/1133, batch loss:0.33531439304351807, Training time:6026.455039978027
batch reward last col mean 0.11652995645999908 first col mean 0.12518714368343353 all mean 0.12243731319904327
0.3665526211261749 0.3665526211261749
rl training, epoch2, iter0, batch689/1133, batch loss:0.3665526211261749, Training time:6028.089268922806
batch reward last col mean 0.10535959154367447 first col mean 0.1318938434123993 all mean 0.11010843515396118
0.33061882853507996 0.33061882853507996
rl training, epoch2, iter0, batch690/1133, batch loss:0.33061882853507996, Training time:6030.109803915024
batch reward last col mean 0.17013095319271088 first col mean 0.13907745480537415 all mean 0.16389720141887665
0.45262378454208374 0.45262378454208374
rl training, epoch2, iter0, batch691/1133, batch loss:0.45262378454208374, Training time:6032.012772798538
batch reward last col mean 0.11681489646434784 first col mean 0.13038301467895508 all mean 0.12545634806156158
0.3606451451778412 0.3606451451778412
rl training, epoch2, iter0, batch692/1133, batch loss:0.3606451451778412, Training time:6034.331403493881
batch reward last col mean 0.11499950289726257 first col mean 0.13966907560825348 all mean 0.12077228724956512
0.40341880917549133 0.40341880917549133
rl training, epoch2, iter0, batch693/1133, batch loss:0.40341880917549133, Training time:6036.211332082748
batch reward last col mean 0.1456962376832962 first col mean 0.13500799238681793 all mean 0.14699704945087433
0.39505594968795776 0.39505594968795776
rl training, epoch2, iter0, batch694/1133, batch loss:0.39505594968795776, Training time:6037.950494289398
batch reward last col mean 0.12388155609369278 first col mean 0.13069897890090942 all mean 0.12154407054185867
0.3292626738548279 0.3292626738548279
rl training, epoch2, iter0, batch695/1133, batch loss:0.3292626738548279, Training time:6039.49197936058
batch reward last col mean 0.08783607184886932 first col mean 0.12682688236236572 all mean 0.10326100140810013
0.3250312805175781 0.3250312805175781
rl training, epoch2, iter0, batch696/1133, batch loss:0.3250312805175781, Training time:6041.20133805275
batch reward last col mean 0.12804841995239258 first col mean 0.14899985492229462 all mean 0.1321914792060852
0.42264416813850403 0.42264416813850403
rl training, epoch2, iter0, batch697/1133, batch loss:0.42264416813850403, Training time:6043.059884786606
batch reward last col mean 0.11211051791906357 first col mean 0.11514930427074432 all mean 0.11554066091775894
0.3296617567539215 0.3296617567539215
rl training, epoch2, iter0, batch698/1133, batch loss:0.3296617567539215, Training time:6045.412747144699
batch reward last col mean 0.12047845125198364 first col mean 0.127079039812088 all mean 0.12294355034828186
0.3409424126148224 0.3409424126148224
rl training, epoch2, iter0, batch699/1133, batch loss:0.3409424126148224, Training time:6047.439527511597
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5767442728972287 Time: 98.3009991645813 s
loss of true 0.2580745972607479 loss of gen 0.19725006116457144 loss of other 0.12141961476125238 first score 0.1664876937866211
batch reward last col mean 0.1376204788684845 first col mean 0.10847604274749756 all mean 0.12976807355880737
0.3551165461540222 0.3551165461540222
rl training, epoch2, iter0, batch700/1133, batch loss:0.3551165461540222, Training time:6149.128853559494
batch reward last col mean 0.14886267483234406 first col mean 0.11297184228897095 all mean 0.14034070074558258
0.3949701488018036 0.3949701488018036
rl training, epoch2, iter0, batch701/1133, batch loss:0.3949701488018036, Training time:6151.363173723221
batch reward last col mean 0.12786082923412323 first col mean 0.11231330782175064 all mean 0.12146871536970139
0.35556578636169434 0.35556578636169434
rl training, epoch2, iter0, batch702/1133, batch loss:0.35556578636169434, Training time:6153.131939411163
batch reward last col mean 0.10579217970371246 first col mean 0.11527230590581894 all mean 0.10602135956287384
0.3800234794616699 0.3800234794616699
rl training, epoch2, iter0, batch703/1133, batch loss:0.3800234794616699, Training time:6155.414140462875
batch reward last col mean 0.16009965538978577 first col mean 0.10901626944541931 all mean 0.1554822474718094
0.4309993088245392 0.4309992790222168
rl training, epoch2, iter0, batch704/1133, batch loss:0.4309992790222168, Training time:6157.163850545883
batch reward last col mean 0.12148153781890869 first col mean 0.1252368688583374 all mean 0.120911605656147
0.39232149720191956 0.39232149720191956
rl training, epoch2, iter0, batch705/1133, batch loss:0.39232149720191956, Training time:6158.829591751099
batch reward last col mean 0.08357983082532883 first col mean 0.11276765912771225 all mean 0.09140071272850037
0.30281978845596313 0.30281978845596313
rl training, epoch2, iter0, batch706/1133, batch loss:0.30281978845596313, Training time:6160.40843629837
batch reward last col mean 0.09136496484279633 first col mean 0.10190978646278381 all mean 0.09938216954469681
0.32384055852890015 0.32384055852890015
rl training, epoch2, iter0, batch707/1133, batch loss:0.32384055852890015, Training time:6162.224010229111
batch reward last col mean 0.11284922063350677 first col mean 0.12872099876403809 all mean 0.11472591757774353
0.3487621247768402 0.3487621247768402
rl training, epoch2, iter0, batch708/1133, batch loss:0.3487621247768402, Training time:6164.148320198059
batch reward last col mean 0.09664272516965866 first col mean 0.11599557846784592 all mean 0.10415353626012802
0.3412381410598755 0.3412381410598755
rl training, epoch2, iter0, batch709/1133, batch loss:0.3412381410598755, Training time:6165.97326874733
batch reward last col mean 0.08751502633094788 first col mean 0.10773637890815735 all mean 0.09734149277210236
0.307344913482666 0.307344913482666
rl training, epoch2, iter0, batch710/1133, batch loss:0.307344913482666, Training time:6167.809604167938
batch reward last col mean 0.08601424098014832 first col mean 0.10086321830749512 all mean 0.09405737370252609
0.2960202395915985 0.2960202395915985
rl training, epoch2, iter0, batch711/1133, batch loss:0.2960202395915985, Training time:6170.217104434967
batch reward last col mean 0.10562369227409363 first col mean 0.12310871481895447 all mean 0.10962481051683426
0.31903189420700073 0.31903189420700073
rl training, epoch2, iter0, batch712/1133, batch loss:0.31903189420700073, Training time:6172.066511154175
batch reward last col mean 0.086717888712883 first col mean 0.11840683221817017 all mean 0.09405294805765152
0.31747227907180786 0.31747227907180786
rl training, epoch2, iter0, batch713/1133, batch loss:0.31747227907180786, Training time:6173.94083571434
batch reward last col mean 0.12132076919078827 first col mean 0.11405687034130096 all mean 0.11257098615169525
0.31843942403793335 0.31843945384025574
rl training, epoch2, iter0, batch714/1133, batch loss:0.31843945384025574, Training time:6175.585139989853
batch reward last col mean 0.1407901644706726 first col mean 0.1248319149017334 all mean 0.1312326192855835
0.35353681445121765 0.35353681445121765
rl training, epoch2, iter0, batch715/1133, batch loss:0.35353681445121765, Training time:6177.047487258911
batch reward last col mean 0.11276383697986603 first col mean 0.10566610097885132 all mean 0.11290553957223892
0.2936497926712036 0.2936497926712036
rl training, epoch2, iter0, batch716/1133, batch loss:0.2936497926712036, Training time:6178.682900905609
batch reward last col mean 0.10920990258455276 first col mean 0.11351564526557922 all mean 0.10872285813093185
0.3156531751155853 0.3156531751155853
rl training, epoch2, iter0, batch717/1133, batch loss:0.3156531751155853, Training time:6180.359505653381
batch reward last col mean 0.13850370049476624 first col mean 0.11917857825756073 all mean 0.12897291779518127
0.3359343409538269 0.3359343409538269
rl training, epoch2, iter0, batch718/1133, batch loss:0.3359343409538269, Training time:6182.1933352947235
batch reward last col mean 0.12925386428833008 first col mean 0.12943805754184723 all mean 0.1317910999059677
0.38735431432724 0.38735431432724
rl training, epoch2, iter0, batch719/1133, batch loss:0.38735431432724, Training time:6183.909696817398
batch reward last col mean 0.11636504530906677 first col mean 0.10649123787879944 all mean 0.11572626233100891
0.31094327569007874 0.31094327569007874
rl training, epoch2, iter0, batch720/1133, batch loss:0.31094327569007874, Training time:6185.890823364258
batch reward last col mean 0.10362739115953445 first col mean 0.11910323053598404 all mean 0.1121097281575203
0.3394944667816162 0.3394944667816162
rl training, epoch2, iter0, batch721/1133, batch loss:0.3394944667816162, Training time:6187.645225286484
batch reward last col mean 0.1171775758266449 first col mean 0.11135993897914886 all mean 0.11560560017824173
0.34958893060684204 0.34958893060684204
rl training, epoch2, iter0, batch722/1133, batch loss:0.34958893060684204, Training time:6189.652325630188
batch reward last col mean 0.10298635065555573 first col mean 0.10878371447324753 all mean 0.11080637574195862
0.34571313858032227 0.34571313858032227
rl training, epoch2, iter0, batch723/1133, batch loss:0.34571313858032227, Training time:6191.430076599121
batch reward last col mean 0.10207390785217285 first col mean 0.13113535940647125 all mean 0.10811199247837067
0.2983497381210327 0.2983497381210327
rl training, epoch2, iter0, batch724/1133, batch loss:0.2983497381210327, Training time:6193.192758560181
batch reward last col mean 0.15476109087467194 first col mean 0.11594665050506592 all mean 0.14182595908641815
0.37335216999053955 0.37335216999053955
rl training, epoch2, iter0, batch725/1133, batch loss:0.37335216999053955, Training time:6195.123338222504
batch reward last col mean 0.12245765328407288 first col mean 0.11773130297660828 all mean 0.12349285185337067
0.3205300569534302 0.3205300569534302
rl training, epoch2, iter0, batch726/1133, batch loss:0.3205300569534302, Training time:6196.98611831665
batch reward last col mean 0.083767831325531 first col mean 0.11070264875888824 all mean 0.09688472747802734
0.3196879029273987 0.3196879029273987
rl training, epoch2, iter0, batch727/1133, batch loss:0.3196879029273987, Training time:6198.867525100708
batch reward last col mean 0.10074347257614136 first col mean 0.12852340936660767 all mean 0.10540006309747696
0.3049243688583374 0.3049243688583374
rl training, epoch2, iter0, batch728/1133, batch loss:0.3049243688583374, Training time:6200.777999162674
batch reward last col mean 0.08158916980028152 first col mean 0.11231785267591476 all mean 0.09093081206083298
0.3369671404361725 0.3369671702384949
rl training, epoch2, iter0, batch729/1133, batch loss:0.3369671702384949, Training time:6202.864748477936
batch reward last col mean 0.12112986296415329 first col mean 0.10038885474205017 all mean 0.114710733294487
0.2869041860103607 0.2869041860103607
rl training, epoch2, iter0, batch730/1133, batch loss:0.2869041860103607, Training time:6204.842196702957
batch reward last col mean 0.13321831822395325 first col mean 0.1237628310918808 all mean 0.11952745914459229
0.3070233166217804 0.3070233166217804
rl training, epoch2, iter0, batch731/1133, batch loss:0.3070233166217804, Training time:6206.814576387405
batch reward last col mean 0.08495461940765381 first col mean 0.11378740519285202 all mean 0.08978588134050369
0.2579773962497711 0.2579773962497711
rl training, epoch2, iter0, batch732/1133, batch loss:0.2579773962497711, Training time:6208.747053384781
batch reward last col mean 0.09797398000955582 first col mean 0.11687850952148438 all mean 0.10561332106590271
0.342632532119751 0.342632532119751
rl training, epoch2, iter0, batch733/1133, batch loss:0.342632532119751, Training time:6210.625529527664
batch reward last col mean 0.1051093339920044 first col mean 0.11268424987792969 all mean 0.10895707458257675
0.30699801445007324 0.30699801445007324
rl training, epoch2, iter0, batch734/1133, batch loss:0.30699801445007324, Training time:6212.225002527237
batch reward last col mean 0.14355815947055817 first col mean 0.1278264820575714 all mean 0.14132919907569885
0.3700661063194275 0.3700661063194275
rl training, epoch2, iter0, batch735/1133, batch loss:0.3700661063194275, Training time:6214.056517362595
batch reward last col mean 0.150687575340271 first col mean 0.10108944028615952 all mean 0.13881121575832367
0.3474924564361572 0.3474924564361572
rl training, epoch2, iter0, batch736/1133, batch loss:0.3474924564361572, Training time:6216.084633350372
batch reward last col mean 0.15250755846500397 first col mean 0.1152808889746666 all mean 0.14115269482135773
0.36776062846183777 0.36776062846183777
rl training, epoch2, iter0, batch737/1133, batch loss:0.36776062846183777, Training time:6217.954599618912
batch reward last col mean 0.1269858330488205 first col mean 0.1265276074409485 all mean 0.1280124932527542
0.3450286388397217 0.3450286090373993
rl training, epoch2, iter0, batch738/1133, batch loss:0.3450286090373993, Training time:6219.912549495697
batch reward last col mean 0.11290940642356873 first col mean 0.12160301208496094 all mean 0.11596401780843735
0.3182711899280548 0.3182711899280548
rl training, epoch2, iter0, batch739/1133, batch loss:0.3182711899280548, Training time:6222.284947633743
batch reward last col mean 0.1373969167470932 first col mean 0.14165911078453064 all mean 0.13262784481048584
0.3355277180671692 0.3355277180671692
rl training, epoch2, iter0, batch740/1133, batch loss:0.3355277180671692, Training time:6224.147701025009
batch reward last col mean 0.110294409096241 first col mean 0.09808836877346039 all mean 0.11543586105108261
0.3340562582015991 0.3340562582015991
rl training, epoch2, iter0, batch741/1133, batch loss:0.3340562582015991, Training time:6225.968280553818
batch reward last col mean 0.09775286912918091 first col mean 0.12582187354564667 all mean 0.10785476118326187
0.295065313577652 0.295065313577652
rl training, epoch2, iter0, batch742/1133, batch loss:0.295065313577652, Training time:6227.808347702026
batch reward last col mean 0.11377935856580734 first col mean 0.11691199988126755 all mean 0.1159302219748497
0.3123411536216736 0.3123411536216736
rl training, epoch2, iter0, batch743/1133, batch loss:0.3123411536216736, Training time:6229.7753965854645
batch reward last col mean 0.11766447871923447 first col mean 0.11346293240785599 all mean 0.11188136041164398
0.31539252400398254 0.31539252400398254
rl training, epoch2, iter0, batch744/1133, batch loss:0.31539252400398254, Training time:6231.550991296768
batch reward last col mean 0.08421003818511963 first col mean 0.12289232015609741 all mean 0.10380937904119492
0.36510375142097473 0.36510375142097473
rl training, epoch2, iter0, batch745/1133, batch loss:0.36510375142097473, Training time:6233.267363548279
batch reward last col mean 0.16139771044254303 first col mean 0.11814577877521515 all mean 0.14100949466228485
0.3784492015838623 0.3784492015838623
rl training, epoch2, iter0, batch746/1133, batch loss:0.3784492015838623, Training time:6234.785122871399
batch reward last col mean 0.0995807945728302 first col mean 0.14106500148773193 all mean 0.10800837725400925
0.30951958894729614 0.30951955914497375
rl training, epoch2, iter0, batch747/1133, batch loss:0.30951955914497375, Training time:6236.44682431221
batch reward last col mean 0.1318875104188919 first col mean 0.1176847293972969 all mean 0.12348742038011551
0.33580029010772705 0.33580029010772705
rl training, epoch2, iter0, batch748/1133, batch loss:0.33580029010772705, Training time:6238.136289596558
batch reward last col mean 0.13401469588279724 first col mean 0.11859919130802155 all mean 0.12826910614967346
0.36270061135292053 0.36270061135292053
rl training, epoch2, iter0, batch749/1133, batch loss:0.36270061135292053, Training time:6240.065947771072
batch reward last col mean 0.10809699445962906 first col mean 0.09869107604026794 all mean 0.10553126782178879
0.2736901044845581 0.2736901044845581
rl training, epoch2, iter0, batch750/1133, batch loss:0.2736901044845581, Training time:6242.007148265839
batch reward last col mean 0.13005781173706055 first col mean 0.1339971274137497 all mean 0.12849733233451843
0.3692029118537903 0.3692029118537903
rl training, epoch2, iter0, batch751/1133, batch loss:0.3692029118537903, Training time:6243.721990346909
batch reward last col mean 0.13923689723014832 first col mean 0.132309228181839 all mean 0.12394382804632187
0.3769730031490326 0.3769730031490326
rl training, epoch2, iter0, batch752/1133, batch loss:0.3769730031490326, Training time:6245.2325484752655
batch reward last col mean 0.07963859289884567 first col mean 0.12906217575073242 all mean 0.09249943494796753
0.31214475631713867 0.3121447265148163
rl training, epoch2, iter0, batch753/1133, batch loss:0.3121447265148163, Training time:6247.047615766525
batch reward last col mean 0.11346171796321869 first col mean 0.11624972522258759 all mean 0.11272744834423065
0.34393125772476196 0.3439311981201172
rl training, epoch2, iter0, batch754/1133, batch loss:0.3439311981201172, Training time:6249.463676691055
batch reward last col mean 0.11740709096193314 first col mean 0.12187029421329498 all mean 0.11851141601800919
0.35020729899406433 0.35020729899406433
rl training, epoch2, iter0, batch755/1133, batch loss:0.35020729899406433, Training time:6251.263353586197
batch reward last col mean 0.13228367269039154 first col mean 0.1206078976392746 all mean 0.12418586760759354
0.3659362196922302 0.36593616008758545
rl training, epoch2, iter0, batch756/1133, batch loss:0.36593616008758545, Training time:6252.854796171188
batch reward last col mean 0.12635105848312378 first col mean 0.12679025530815125 all mean 0.1249864473938942
0.3338503837585449 0.3338503837585449
rl training, epoch2, iter0, batch757/1133, batch loss:0.3338503837585449, Training time:6254.783425569534
batch reward last col mean 0.13239078223705292 first col mean 0.14284513890743256 all mean 0.12329220771789551
0.3059631586074829 0.3059631586074829
rl training, epoch2, iter0, batch758/1133, batch loss:0.3059631586074829, Training time:6256.297700881958
batch reward last col mean 0.15626929700374603 first col mean 0.11327776312828064 all mean 0.14827942848205566
0.35665977001190186 0.35665977001190186
rl training, epoch2, iter0, batch759/1133, batch loss:0.35665977001190186, Training time:6258.292242527008
batch reward last col mean 0.09710878133773804 first col mean 0.129204660654068 all mean 0.10377748310565948
0.3680092394351959 0.3680092394351959
rl training, epoch2, iter0, batch760/1133, batch loss:0.3680092394351959, Training time:6260.020698308945
batch reward last col mean 0.14667493104934692 first col mean 0.12732376158237457 all mean 0.14410924911499023
0.35411596298217773 0.3541160225868225
rl training, epoch2, iter0, batch761/1133, batch loss:0.3541160225868225, Training time:6261.788382053375
batch reward last col mean 0.09101464599370956 first col mean 0.12414680421352386 all mean 0.10502443462610245
0.3159160614013672 0.3159160614013672
rl training, epoch2, iter0, batch762/1133, batch loss:0.3159160614013672, Training time:6263.659805774689
batch reward last col mean 0.16418233513832092 first col mean 0.12930627167224884 all mean 0.1541496068239212
0.40009820461273193 0.40009820461273193
rl training, epoch2, iter0, batch763/1133, batch loss:0.40009820461273193, Training time:6266.063119888306
batch reward last col mean 0.0963316261768341 first col mean 0.1316995471715927 all mean 0.10432740300893784
0.30614426732063293 0.30614426732063293
rl training, epoch2, iter0, batch764/1133, batch loss:0.30614426732063293, Training time:6268.064972639084
batch reward last col mean 0.09456539154052734 first col mean 0.13865581154823303 all mean 0.10499049723148346
0.3341927230358124 0.3341927230358124
rl training, epoch2, iter0, batch765/1133, batch loss:0.3341927230358124, Training time:6269.884353637695
batch reward last col mean 0.1437816619873047 first col mean 0.11391203850507736 all mean 0.13451486825942993
0.3616187274456024 0.3616187274456024
rl training, epoch2, iter0, batch766/1133, batch loss:0.3616187274456024, Training time:6271.684737443924
batch reward last col mean 0.13007472455501556 first col mean 0.1423983871936798 all mean 0.12831971049308777
0.36501696705818176 0.36501696705818176
rl training, epoch2, iter0, batch767/1133, batch loss:0.36501696705818176, Training time:6273.810858488083
batch reward last col mean 0.10378248244524002 first col mean 0.11859005689620972 all mean 0.10758502781391144
0.315841406583786 0.3158413767814636
rl training, epoch2, iter0, batch768/1133, batch loss:0.3158413767814636, Training time:6275.540219068527
batch reward last col mean 0.14108672738075256 first col mean 0.11037780344486237 all mean 0.13022302091121674
0.35290414094924927 0.35290414094924927
rl training, epoch2, iter0, batch769/1133, batch loss:0.35290414094924927, Training time:6277.27331662178
batch reward last col mean 0.12761574983596802 first col mean 0.13369031250476837 all mean 0.12999269366264343
0.4318668246269226 0.4318668246269226
rl training, epoch2, iter0, batch770/1133, batch loss:0.4318668246269226, Training time:6278.773620128632
batch reward last col mean 0.10608725249767303 first col mean 0.12424298375844955 all mean 0.11185652017593384
0.3301022946834564 0.3301022946834564
rl training, epoch2, iter0, batch771/1133, batch loss:0.3301022946834564, Training time:6280.440317630768
batch reward last col mean 0.10179953277111053 first col mean 0.11837258189916611 all mean 0.10929561406373978
0.36393481492996216 0.36393481492996216
rl training, epoch2, iter0, batch772/1133, batch loss:0.36393481492996216, Training time:6282.293805837631
batch reward last col mean 0.1358097642660141 first col mean 0.11772091686725616 all mean 0.13130788505077362
0.310261070728302 0.310261070728302
rl training, epoch2, iter0, batch773/1133, batch loss:0.310261070728302, Training time:6284.461784124374
batch reward last col mean 0.12162193655967712 first col mean 0.11226900666952133 all mean 0.118771992623806
0.3712342083454132 0.3712342083454132
rl training, epoch2, iter0, batch774/1133, batch loss:0.3712342083454132, Training time:6286.7219450473785
batch reward last col mean 0.1131538599729538 first col mean 0.12166640907526016 all mean 0.11281366646289825
0.32191264629364014 0.32191264629364014
rl training, epoch2, iter0, batch775/1133, batch loss:0.32191264629364014, Training time:6289.122184753418
batch reward last col mean 0.10981055349111557 first col mean 0.13004836440086365 all mean 0.10816960036754608
0.36878716945648193 0.36878716945648193
rl training, epoch2, iter0, batch776/1133, batch loss:0.36878716945648193, Training time:6291.01905465126
batch reward last col mean 0.13857895135879517 first col mean 0.12665589153766632 all mean 0.13613201677799225
0.393620103597641 0.393620103597641
rl training, epoch2, iter0, batch777/1133, batch loss:0.393620103597641, Training time:6292.917365074158
batch reward last col mean 0.12578339874744415 first col mean 0.10924611240625381 all mean 0.12461179494857788
0.361558735370636 0.361558735370636
rl training, epoch2, iter0, batch778/1133, batch loss:0.361558735370636, Training time:6295.2678916454315
batch reward last col mean 0.11895699799060822 first col mean 0.10547057539224625 all mean 0.11690395325422287
0.3606095612049103 0.3606095612049103
rl training, epoch2, iter0, batch779/1133, batch loss:0.3606095612049103, Training time:6297.184863567352
batch reward last col mean 0.12897121906280518 first col mean 0.1228695660829544 all mean 0.12988334894180298
0.32903775572776794 0.32903775572776794
rl training, epoch2, iter0, batch780/1133, batch loss:0.32903775572776794, Training time:6298.787218570709
batch reward last col mean 0.11409734189510345 first col mean 0.11958056688308716 all mean 0.11645548045635223
0.3320382535457611 0.3320382535457611
rl training, epoch2, iter0, batch781/1133, batch loss:0.3320382535457611, Training time:6300.628767251968
batch reward last col mean 0.1299785077571869 first col mean 0.09829909354448318 all mean 0.12572532892227173
0.34210675954818726 0.34210672974586487
rl training, epoch2, iter0, batch782/1133, batch loss:0.34210672974586487, Training time:6302.204609870911
batch reward last col mean 0.09605008363723755 first col mean 0.13131831586360931 all mean 0.10296168178319931
0.31977924704551697 0.31977924704551697
rl training, epoch2, iter0, batch783/1133, batch loss:0.31977924704551697, Training time:6304.017441987991
batch reward last col mean 0.10417889803647995 first col mean 0.1285329908132553 all mean 0.11805029958486557
0.41193753480911255 0.41193753480911255
rl training, epoch2, iter0, batch784/1133, batch loss:0.41193753480911255, Training time:6305.422337770462
batch reward last col mean 0.1232379749417305 first col mean 0.12180659174919128 all mean 0.1170300766825676
0.34422773122787476 0.34422773122787476
rl training, epoch2, iter0, batch785/1133, batch loss:0.34422773122787476, Training time:6307.1555552482605
batch reward last col mean 0.11618604511022568 first col mean 0.1155209019780159 all mean 0.11993826180696487
0.3175604045391083 0.3175604045391083
rl training, epoch2, iter0, batch786/1133, batch loss:0.3175604045391083, Training time:6308.979797363281
batch reward last col mean 0.11560526490211487 first col mean 0.1352127641439438 all mean 0.11538899689912796
0.3333966135978699 0.33339664340019226
rl training, epoch2, iter0, batch787/1133, batch loss:0.33339664340019226, Training time:6311.334492683411
batch reward last col mean 0.09179361909627914 first col mean 0.1164376437664032 all mean 0.10784795880317688
0.3611680865287781 0.3611680865287781
rl training, epoch2, iter0, batch788/1133, batch loss:0.3611680865287781, Training time:6312.709137916565
batch reward last col mean 0.1378505825996399 first col mean 0.1237182766199112 all mean 0.13477349281311035
0.35386738181114197 0.35386738181114197
rl training, epoch2, iter0, batch789/1133, batch loss:0.35386738181114197, Training time:6314.747795820236
batch reward last col mean 0.10668022930622101 first col mean 0.121943898499012 all mean 0.11338012665510178
0.3619484603404999 0.3619484603404999
rl training, epoch2, iter0, batch790/1133, batch loss:0.3619484603404999, Training time:6317.17000746727
batch reward last col mean 0.10831304639577866 first col mean 0.13416247069835663 all mean 0.11010083556175232
0.3155706822872162 0.3155706822872162
rl training, epoch2, iter0, batch791/1133, batch loss:0.3155706822872162, Training time:6319.417949914932
batch reward last col mean 0.09607133269309998 first col mean 0.12561509013175964 all mean 0.09859097003936768
0.302442342042923 0.302442342042923
rl training, epoch2, iter0, batch792/1133, batch loss:0.302442342042923, Training time:6321.281310558319
batch reward last col mean 0.12225624918937683 first col mean 0.12926791608333588 all mean 0.11982864886522293
0.3595958948135376 0.3595958948135376
rl training, epoch2, iter0, batch793/1133, batch loss:0.3595958948135376, Training time:6323.294357299805
batch reward last col mean 0.12504689395427704 first col mean 0.1318044662475586 all mean 0.12449242919683456
0.3295879364013672 0.3295879364013672
rl training, epoch2, iter0, batch794/1133, batch loss:0.3295879364013672, Training time:6325.103816270828
batch reward last col mean 0.1102759838104248 first col mean 0.1204451248049736 all mean 0.11156381666660309
0.28809037804603577 0.28809040784835815
rl training, epoch2, iter0, batch795/1133, batch loss:0.28809040784835815, Training time:6327.035457849503
batch reward last col mean 0.13537746667861938 first col mean 0.1362113058567047 all mean 0.1349049061536789
0.32776692509651184 0.32776686549186707
rl training, epoch2, iter0, batch796/1133, batch loss:0.32776686549186707, Training time:6328.960773229599
batch reward last col mean 0.1264088749885559 first col mean 0.1402408629655838 all mean 0.12824788689613342
0.35100945830345154 0.35100945830345154
rl training, epoch2, iter0, batch797/1133, batch loss:0.35100945830345154, Training time:6330.429399251938
batch reward last col mean 0.13040967285633087 first col mean 0.12170933187007904 all mean 0.12975747883319855
0.35013192892074585 0.35013192892074585
rl training, epoch2, iter0, batch798/1133, batch loss:0.35013192892074585, Training time:6331.799458503723
batch reward last col mean 0.1144128367304802 first col mean 0.11738377809524536 all mean 0.11862242221832275
0.35666874051094055 0.35666874051094055
rl training, epoch2, iter0, batch799/1133, batch loss:0.35666874051094055, Training time:6333.954560279846
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5748506663441132 Time: 99.23698043823242 s
loss of true 0.25709112085868907 loss of gen 0.19700073483683636 loss of other 0.12075881158237634 first score 0.13630211353302002
batch reward last col mean 0.07839865982532501 first col mean 0.1339005082845688 all mean 0.09419479966163635
0.2832508385181427 0.2832508385181427
rl training, epoch2, iter0, batch800/1133, batch loss:0.2832508385181427, Training time:6434.715202093124
batch reward last col mean 0.11641526222229004 first col mean 0.10665301978588104 all mean 0.11321204155683517
0.3069573938846588 0.3069573938846588
rl training, epoch2, iter0, batch801/1133, batch loss:0.3069573938846588, Training time:6436.260041236877
batch reward last col mean 0.09986592829227448 first col mean 0.12729498744010925 all mean 0.10572747886180878
0.34279197454452515 0.34279197454452515
rl training, epoch2, iter0, batch802/1133, batch loss:0.34279197454452515, Training time:6437.643917560577
batch reward last col mean 0.09937778115272522 first col mean 0.1066339761018753 all mean 0.10330542922019958
0.3117416799068451 0.3117416799068451
rl training, epoch2, iter0, batch803/1133, batch loss:0.3117416799068451, Training time:6439.494025707245
batch reward last col mean 0.1478986144065857 first col mean 0.11211401224136353 all mean 0.13802289962768555
0.35753148794174194 0.35753148794174194
rl training, epoch2, iter0, batch804/1133, batch loss:0.35753148794174194, Training time:6441.077446222305
batch reward last col mean 0.10845666378736496 first col mean 0.10934370756149292 all mean 0.10770679265260696
0.3158097565174103 0.3158097565174103
rl training, epoch2, iter0, batch805/1133, batch loss:0.3158097565174103, Training time:6442.708204746246
batch reward last col mean 0.13383305072784424 first col mean 0.10473303496837616 all mean 0.12327541410923004
0.3451235890388489 0.3451235890388489
rl training, epoch2, iter0, batch806/1133, batch loss:0.3451235890388489, Training time:6444.245938301086
batch reward last col mean 0.14997585117816925 first col mean 0.1035773977637291 all mean 0.13847151398658752
0.3673093318939209 0.3673093318939209
rl training, epoch2, iter0, batch807/1133, batch loss:0.3673093318939209, Training time:6445.731014966965
batch reward last col mean 0.13880042731761932 first col mean 0.120826855301857 all mean 0.1357325315475464
0.35383161902427673 0.35383161902427673
rl training, epoch2, iter0, batch808/1133, batch loss:0.35383161902427673, Training time:6447.453104734421
batch reward last col mean 0.11434552073478699 first col mean 0.1084698960185051 all mean 0.1169910803437233
0.3145993947982788 0.3145993649959564
rl training, epoch2, iter0, batch809/1133, batch loss:0.3145993649959564, Training time:6449.055603981018
batch reward last col mean 0.11998119950294495 first col mean 0.11985965073108673 all mean 0.117923304438591
0.31973811984062195 0.31973811984062195
rl training, epoch2, iter0, batch810/1133, batch loss:0.31973811984062195, Training time:6450.7605855464935
batch reward last col mean 0.10418815910816193 first col mean 0.12253247946500778 all mean 0.10872115939855576
0.34415099024772644 0.34415099024772644
rl training, epoch2, iter0, batch811/1133, batch loss:0.34415099024772644, Training time:6452.581206083298
batch reward last col mean 0.13047687709331512 first col mean 0.11668352782726288 all mean 0.12838971614837646
0.39172279834747314 0.39172276854515076
rl training, epoch2, iter0, batch812/1133, batch loss:0.39172276854515076, Training time:6454.104587316513
batch reward last col mean 0.11388678103685379 first col mean 0.1087496429681778 all mean 0.10985878854990005
0.3052159249782562 0.3052159249782562
rl training, epoch2, iter0, batch813/1133, batch loss:0.3052159249782562, Training time:6456.067521810532
batch reward last col mean 0.13091325759887695 first col mean 0.12406865507364273 all mean 0.1283591091632843
0.36543965339660645 0.36543965339660645
rl training, epoch2, iter0, batch814/1133, batch loss:0.36543965339660645, Training time:6457.876383304596
batch reward last col mean 0.09402233362197876 first col mean 0.11534557491540909 all mean 0.10031941533088684
0.3129430115222931 0.3129430115222931
rl training, epoch2, iter0, batch815/1133, batch loss:0.3129430115222931, Training time:6460.627131462097
batch reward last col mean 0.10786290466785431 first col mean 0.10522355139255524 all mean 0.1143675222992897
0.3182242810726166 0.3182242810726166
rl training, epoch2, iter0, batch816/1133, batch loss:0.3182242810726166, Training time:6462.283993721008
batch reward last col mean 0.13533470034599304 first col mean 0.10894301533699036 all mean 0.12663058936595917
0.3227001130580902 0.3227001130580902
rl training, epoch2, iter0, batch817/1133, batch loss:0.3227001130580902, Training time:6464.0894894599915
batch reward last col mean 0.1162322536110878 first col mean 0.12895801663398743 all mean 0.11406076699495316
0.30069077014923096 0.30069077014923096
rl training, epoch2, iter0, batch818/1133, batch loss:0.30069077014923096, Training time:6465.906208753586
batch reward last col mean 0.11564956605434418 first col mean 0.1036800965666771 all mean 0.11324338614940643
0.37765875458717346 0.37765875458717346
rl training, epoch2, iter0, batch819/1133, batch loss:0.37765875458717346, Training time:6467.577571392059
batch reward last col mean 0.09455149620771408 first col mean 0.1195020005106926 all mean 0.09969393908977509
0.3264835774898529 0.3264836072921753
rl training, epoch2, iter0, batch820/1133, batch loss:0.3264836072921753, Training time:6469.708824872971
batch reward last col mean 0.05933849513530731 first col mean 0.11996372044086456 all mean 0.08030430972576141
0.29522719979286194 0.29522716999053955
rl training, epoch2, iter0, batch821/1133, batch loss:0.29522716999053955, Training time:6471.039905786514
batch reward last col mean 0.08798767626285553 first col mean 0.10986761748790741 all mean 0.09590551257133484
0.2963941991329193 0.2963941991329193
rl training, epoch2, iter0, batch822/1133, batch loss:0.2963941991329193, Training time:6472.446508407593
batch reward last col mean 0.11249621212482452 first col mean 0.10515820980072021 all mean 0.11156456172466278
0.30151912569999695 0.30151912569999695
rl training, epoch2, iter0, batch823/1133, batch loss:0.30151912569999695, Training time:6475.195881843567
batch reward last col mean 0.14527972042560577 first col mean 0.1247611790895462 all mean 0.13826587796211243
0.38438817858695984 0.38438817858695984
rl training, epoch2, iter0, batch824/1133, batch loss:0.38438817858695984, Training time:6477.080260276794
batch reward last col mean 0.07997550070285797 first col mean 0.12402413785457611 all mean 0.08993705362081528
0.295552134513855 0.295552134513855
rl training, epoch2, iter0, batch825/1133, batch loss:0.295552134513855, Training time:6478.469133853912
batch reward last col mean 0.08752375096082687 first col mean 0.11410120874643326 all mean 0.09873474389314651
0.3014776110649109 0.3014776110649109
rl training, epoch2, iter0, batch826/1133, batch loss:0.3014776110649109, Training time:6480.178609609604
batch reward last col mean 0.10648811608552933 first col mean 0.11824280023574829 all mean 0.11198753863573074
0.31586888432502747 0.31586888432502747
rl training, epoch2, iter0, batch827/1133, batch loss:0.31586888432502747, Training time:6481.544156551361
batch reward last col mean 0.09539178758859634 first col mean 0.13719861209392548 all mean 0.10447093844413757
0.38103991746902466 0.38103994727134705
rl training, epoch2, iter0, batch828/1133, batch loss:0.38103994727134705, Training time:6483.423748731613
batch reward last col mean 0.12767863273620605 first col mean 0.11998601257801056 all mean 0.1206730455160141
0.33865320682525635 0.33865320682525635
rl training, epoch2, iter0, batch829/1133, batch loss:0.33865320682525635, Training time:6484.692529439926
batch reward last col mean 0.10816824436187744 first col mean 0.09420488774776459 all mean 0.11037395894527435
0.315211683511734 0.315211683511734
rl training, epoch2, iter0, batch830/1133, batch loss:0.315211683511734, Training time:6486.52180147171
batch reward last col mean 0.11328456550836563 first col mean 0.11029702425003052 all mean 0.11036811769008636
0.27488765120506287 0.27488765120506287
rl training, epoch2, iter0, batch831/1133, batch loss:0.27488765120506287, Training time:6488.5915286540985
batch reward last col mean 0.09213133156299591 first col mean 0.139842227101326 all mean 0.10191760957241058
0.3168764114379883 0.31687647104263306
rl training, epoch2, iter0, batch832/1133, batch loss:0.31687647104263306, Training time:6490.194086790085
batch reward last col mean 0.13764871656894684 first col mean 0.11176148056983948 all mean 0.13400153815746307
0.34221190214157104 0.34221190214157104
rl training, epoch2, iter0, batch833/1133, batch loss:0.34221190214157104, Training time:6492.63743019104
batch reward last col mean 0.1173996850848198 first col mean 0.12137515842914581 all mean 0.11283973604440689
0.31279686093330383 0.31279686093330383
rl training, epoch2, iter0, batch834/1133, batch loss:0.31279686093330383, Training time:6494.642472267151
batch reward last col mean 0.10611721873283386 first col mean 0.12502282857894897 all mean 0.1116160973906517
0.3607707917690277 0.3607707917690277
rl training, epoch2, iter0, batch835/1133, batch loss:0.3607707917690277, Training time:6496.153605699539
batch reward last col mean 0.12161155045032501 first col mean 0.12111428380012512 all mean 0.11410229653120041
0.34659522771835327 0.34659522771835327
rl training, epoch2, iter0, batch836/1133, batch loss:0.34659522771835327, Training time:6497.961043596268
batch reward last col mean 0.13549140095710754 first col mean 0.13978102803230286 all mean 0.12953975796699524
0.3620527982711792 0.3620527982711792
rl training, epoch2, iter0, batch837/1133, batch loss:0.3620527982711792, Training time:6499.544367313385
batch reward last col mean 0.15696214139461517 first col mean 0.10759736597537994 all mean 0.14265471696853638
0.35120290517807007 0.35120290517807007
rl training, epoch2, iter0, batch838/1133, batch loss:0.35120290517807007, Training time:6501.113683223724
batch reward last col mean 0.12398846447467804 first col mean 0.11543026566505432 all mean 0.12127546966075897
0.3407171070575714 0.3407171070575714
rl training, epoch2, iter0, batch839/1133, batch loss:0.3407171070575714, Training time:6502.7783443927765
batch reward last col mean 0.11515907943248749 first col mean 0.10212792456150055 all mean 0.11798708140850067
0.34838050603866577 0.348380446434021
rl training, epoch2, iter0, batch840/1133, batch loss:0.348380446434021, Training time:6504.120542526245
batch reward last col mean 0.14909091591835022 first col mean 0.13080894947052002 all mean 0.13486140966415405
0.3554355502128601 0.3554355502128601
rl training, epoch2, iter0, batch841/1133, batch loss:0.3554355502128601, Training time:6506.026482343674
batch reward last col mean 0.13508319854736328 first col mean 0.1345594972372055 all mean 0.13323193788528442
0.3396297097206116 0.3396297097206116
rl training, epoch2, iter0, batch842/1133, batch loss:0.3396297097206116, Training time:6507.757405281067
batch reward last col mean 0.07669185101985931 first col mean 0.11795768141746521 all mean 0.09123785048723221
0.31611526012420654 0.31611526012420654
rl training, epoch2, iter0, batch843/1133, batch loss:0.31611526012420654, Training time:6509.838001728058
batch reward last col mean 0.12076549232006073 first col mean 0.11699819564819336 all mean 0.1155342310667038
0.32171183824539185 0.32171180844306946
rl training, epoch2, iter0, batch844/1133, batch loss:0.32171180844306946, Training time:6511.38626909256
batch reward last col mean 0.11676786839962006 first col mean 0.12157288193702698 all mean 0.12204919010400772
0.33710700273513794 0.33710700273513794
rl training, epoch2, iter0, batch845/1133, batch loss:0.33710700273513794, Training time:6512.973966836929
batch reward last col mean 0.12040391564369202 first col mean 0.14637495577335358 all mean 0.1223563551902771
0.3396774232387543 0.3396774232387543
rl training, epoch2, iter0, batch846/1133, batch loss:0.3396774232387543, Training time:6514.506762504578
batch reward last col mean 0.12546521425247192 first col mean 0.13081477582454681 all mean 0.13162097334861755
0.3770946264266968 0.3770946264266968
rl training, epoch2, iter0, batch847/1133, batch loss:0.3770946264266968, Training time:6516.273780345917
batch reward last col mean 0.12938153743743896 first col mean 0.11399658769369125 all mean 0.12772008776664734
0.33763349056243896 0.33763349056243896
rl training, epoch2, iter0, batch848/1133, batch loss:0.33763349056243896, Training time:6518.101668357849
batch reward last col mean 0.13860957324504852 first col mean 0.13201507925987244 all mean 0.1349995732307434
0.3489736318588257 0.3489736318588257
rl training, epoch2, iter0, batch849/1133, batch loss:0.3489736318588257, Training time:6519.427852630615
batch reward last col mean 0.09603995829820633 first col mean 0.10009047389030457 all mean 0.10169850289821625
0.3135685920715332 0.3135685920715332
rl training, epoch2, iter0, batch850/1133, batch loss:0.3135685920715332, Training time:6521.227871656418
batch reward last col mean 0.12440508604049683 first col mean 0.13560988008975983 all mean 0.12451384216547012
0.3479800224304199 0.3479800224304199
rl training, epoch2, iter0, batch851/1133, batch loss:0.3479800224304199, Training time:6523.102705717087
batch reward last col mean 0.11936408281326294 first col mean 0.12369446456432343 all mean 0.11634484678506851
0.34993964433670044 0.34993964433670044
rl training, epoch2, iter0, batch852/1133, batch loss:0.34993964433670044, Training time:6525.100271224976
batch reward last col mean 0.11610717326402664 first col mean 0.13191922008991241 all mean 0.12158623337745667
0.34581229090690613 0.34581229090690613
rl training, epoch2, iter0, batch853/1133, batch loss:0.34581229090690613, Training time:6527.240780353546
batch reward last col mean 0.10075297206640244 first col mean 0.12629365921020508 all mean 0.10856379568576813
0.3721078932285309 0.3721078932285309
rl training, epoch2, iter0, batch854/1133, batch loss:0.3721078932285309, Training time:6529.269530296326
batch reward last col mean 0.10727246850728989 first col mean 0.11902774125337601 all mean 0.11282562464475632
0.3528003990650177 0.3528003990650177
rl training, epoch2, iter0, batch855/1133, batch loss:0.3528003990650177, Training time:6531.1232533454895
batch reward last col mean 0.10814297199249268 first col mean 0.11905911564826965 all mean 0.10636070370674133
0.31590989232063293 0.31590989232063293
rl training, epoch2, iter0, batch856/1133, batch loss:0.31590989232063293, Training time:6533.038805007935
batch reward last col mean 0.11385098099708557 first col mean 0.12364847213029861 all mean 0.11580806970596313
0.3771958351135254 0.3771958351135254
rl training, epoch2, iter0, batch857/1133, batch loss:0.3771958351135254, Training time:6535.246860742569
batch reward last col mean 0.10840022563934326 first col mean 0.12488073110580444 all mean 0.10952550917863846
0.3414028286933899 0.3414028286933899
rl training, epoch2, iter0, batch858/1133, batch loss:0.3414028286933899, Training time:6537.227964401245
batch reward last col mean 0.13779139518737793 first col mean 0.12831559777259827 all mean 0.13296125829219818
0.3654906451702118 0.3654906451702118
rl training, epoch2, iter0, batch859/1133, batch loss:0.3654906451702118, Training time:6539.054573297501
batch reward last col mean 0.14676755666732788 first col mean 0.1532163918018341 all mean 0.14487849175930023
0.40380480885505676 0.40380480885505676
rl training, epoch2, iter0, batch860/1133, batch loss:0.40380480885505676, Training time:6541.275608539581
batch reward last col mean 0.13219769299030304 first col mean 0.11184736341238022 all mean 0.12428456544876099
0.3494490683078766 0.3494490683078766
rl training, epoch2, iter0, batch861/1133, batch loss:0.3494490683078766, Training time:6543.227685451508
batch reward last col mean 0.09647868573665619 first col mean 0.151784747838974 all mean 0.1048772931098938
0.3206823766231537 0.3206823766231537
rl training, epoch2, iter0, batch862/1133, batch loss:0.3206823766231537, Training time:6545.369466543198
batch reward last col mean 0.11828308552503586 first col mean 0.1282624453306198 all mean 0.11791985481977463
0.3249288499355316 0.3249288499355316
rl training, epoch2, iter0, batch863/1133, batch loss:0.3249288499355316, Training time:6547.189930200577
batch reward last col mean 0.11761713027954102 first col mean 0.09194532781839371 all mean 0.11193101853132248
0.29277700185775757 0.2927769720554352
rl training, epoch2, iter0, batch864/1133, batch loss:0.2927769720554352, Training time:6548.992211103439
batch reward last col mean 0.10670754313468933 first col mean 0.1386573612689972 all mean 0.1104162335395813
0.3089218735694885 0.3089218735694885
rl training, epoch2, iter0, batch865/1133, batch loss:0.3089218735694885, Training time:6550.7603442668915
batch reward last col mean 0.11696062982082367 first col mean 0.0963376834988594 all mean 0.11905212700366974
0.3697129189968109 0.3697129189968109
rl training, epoch2, iter0, batch866/1133, batch loss:0.3697129189968109, Training time:6552.537552595139
batch reward last col mean 0.10893051326274872 first col mean 0.13792961835861206 all mean 0.1161227896809578
0.3510781526565552 0.3510781526565552
rl training, epoch2, iter0, batch867/1133, batch loss:0.3510781526565552, Training time:6555.0698273181915
batch reward last col mean 0.134428933262825 first col mean 0.13112570345401764 all mean 0.12877897918224335
0.3633551597595215 0.3633551597595215
rl training, epoch2, iter0, batch868/1133, batch loss:0.3633551597595215, Training time:6557.093582868576
batch reward last col mean 0.06243900954723358 first col mean 0.10984184592962265 all mean 0.07753293216228485
0.30686458945274353 0.30686458945274353
rl training, epoch2, iter0, batch869/1133, batch loss:0.30686458945274353, Training time:6559.360210180283
batch reward last col mean 0.12119551748037338 first col mean 0.13621853291988373 all mean 0.12712810933589935
0.34934595227241516 0.3493459224700928
rl training, epoch2, iter0, batch870/1133, batch loss:0.3493459224700928, Training time:6561.2970678806305
batch reward last col mean 0.11475804448127747 first col mean 0.12390756607055664 all mean 0.11905643343925476
0.3910193145275116 0.3910193145275116
rl training, epoch2, iter0, batch871/1133, batch loss:0.3910193145275116, Training time:6563.369460582733
batch reward last col mean 0.12412914633750916 first col mean 0.10791955888271332 all mean 0.12274020910263062
0.3371770679950714 0.3371770679950714
rl training, epoch2, iter0, batch872/1133, batch loss:0.3371770679950714, Training time:6566.276485681534
batch reward last col mean 0.11861535906791687 first col mean 0.1280193328857422 all mean 0.12113747000694275
0.3336808681488037 0.3336808681488037
rl training, epoch2, iter0, batch873/1133, batch loss:0.3336808681488037, Training time:6568.32058095932
batch reward last col mean 0.1248561441898346 first col mean 0.13761283457279205 all mean 0.12469489127397537
0.3400079607963562 0.3400079607963562
rl training, epoch2, iter0, batch874/1133, batch loss:0.3400079607963562, Training time:6570.184488534927
batch reward last col mean 0.12994688749313354 first col mean 0.13122348487377167 all mean 0.12691685557365417
0.36796900629997253 0.36796900629997253
rl training, epoch2, iter0, batch875/1133, batch loss:0.36796900629997253, Training time:6572.275959253311
batch reward last col mean 0.10766111314296722 first col mean 0.1214706301689148 all mean 0.11232073605060577
0.34143781661987305 0.34143781661987305
rl training, epoch2, iter0, batch876/1133, batch loss:0.34143781661987305, Training time:6574.7188448905945
batch reward last col mean 0.13211184740066528 first col mean 0.1450459361076355 all mean 0.131749227643013
0.35624316334724426 0.35624316334724426
rl training, epoch2, iter0, batch877/1133, batch loss:0.35624316334724426, Training time:6576.6552765369415
batch reward last col mean 0.15296760201454163 first col mean 0.11817090213298798 all mean 0.14244703948497772
0.3969956636428833 0.3969956636428833
rl training, epoch2, iter0, batch878/1133, batch loss:0.3969956636428833, Training time:6579.017184972763
batch reward last col mean 0.14381814002990723 first col mean 0.11591673642396927 all mean 0.143623948097229
0.4076639711856842 0.4076640009880066
rl training, epoch2, iter0, batch879/1133, batch loss:0.4076640009880066, Training time:6582.425129890442
batch reward last col mean 0.10426614433526993 first col mean 0.10811067372560501 all mean 0.10308436304330826
0.32427793741226196 0.32427793741226196
rl training, epoch2, iter0, batch880/1133, batch loss:0.32427793741226196, Training time:6586.052796363831
batch reward last col mean 0.11005140841007233 first col mean 0.1042284443974495 all mean 0.11222046613693237
0.32494258880615234 0.32494258880615234
rl training, epoch2, iter0, batch881/1133, batch loss:0.32494258880615234, Training time:6588.565519332886
batch reward last col mean 0.1602718085050583 first col mean 0.12960904836654663 all mean 0.14591911435127258
0.38363832235336304 0.38363832235336304
rl training, epoch2, iter0, batch882/1133, batch loss:0.38363832235336304, Training time:6590.502458572388
batch reward last col mean 0.11589038372039795 first col mean 0.11070524901151657 all mean 0.12006232142448425
0.3343867361545563 0.3343867361545563
rl training, epoch2, iter0, batch883/1133, batch loss:0.3343867361545563, Training time:6593.025025844574
batch reward last col mean 0.1105746328830719 first col mean 0.13519011437892914 all mean 0.1135384812951088
0.30086374282836914 0.30086374282836914
rl training, epoch2, iter0, batch884/1133, batch loss:0.30086374282836914, Training time:6595.128803253174
batch reward last col mean 0.14367057383060455 first col mean 0.13636815547943115 all mean 0.1377880573272705
0.3384745717048645 0.3384745717048645
rl training, epoch2, iter0, batch885/1133, batch loss:0.3384745717048645, Training time:6596.974990367889
batch reward last col mean 0.09774668514728546 first col mean 0.11612336337566376 all mean 0.10592755675315857
0.3334779143333435 0.3334779143333435
rl training, epoch2, iter0, batch886/1133, batch loss:0.3334779143333435, Training time:6599.134877920151
batch reward last col mean 0.10214035958051682 first col mean 0.13666246831417084 all mean 0.10886792838573456
0.34060946106910706 0.34060946106910706
rl training, epoch2, iter0, batch887/1133, batch loss:0.34060946106910706, Training time:6601.204783678055
batch reward last col mean 0.12848572432994843 first col mean 0.13188543915748596 all mean 0.1221982091665268
0.3509303033351898 0.3509303033351898
rl training, epoch2, iter0, batch888/1133, batch loss:0.3509303033351898, Training time:6602.785547733307
batch reward last col mean 0.08591649681329727 first col mean 0.11895286291837692 all mean 0.09488289803266525
0.3269948959350586 0.3269948959350586
rl training, epoch2, iter0, batch889/1133, batch loss:0.3269948959350586, Training time:6604.71023774147
batch reward last col mean 0.1070423573255539 first col mean 0.12029460072517395 all mean 0.11176441609859467
0.31931719183921814 0.31931719183921814
rl training, epoch2, iter0, batch890/1133, batch loss:0.31931719183921814, Training time:6607.307639360428
batch reward last col mean 0.1653359830379486 first col mean 0.12112250924110413 all mean 0.1533769965171814
0.39356309175491333 0.39356309175491333
rl training, epoch2, iter0, batch891/1133, batch loss:0.39356309175491333, Training time:6609.4668979644775
batch reward last col mean 0.09425845742225647 first col mean 0.11296495050191879 all mean 0.10229770839214325
0.3353511095046997 0.3353511095046997
rl training, epoch2, iter0, batch892/1133, batch loss:0.3353511095046997, Training time:6611.961254358292
batch reward last col mean 0.16022807359695435 first col mean 0.12816575169563293 all mean 0.15180443227291107
0.39308157563209534 0.39308157563209534
rl training, epoch2, iter0, batch893/1133, batch loss:0.39308157563209534, Training time:6614.427049398422
batch reward last col mean 0.1266367882490158 first col mean 0.12247364223003387 all mean 0.1275145560503006
0.37057679891586304 0.37057679891586304
rl training, epoch2, iter0, batch894/1133, batch loss:0.37057679891586304, Training time:6616.71750164032
batch reward last col mean 0.13827601075172424 first col mean 0.12058033794164658 all mean 0.12967562675476074
0.4064672291278839 0.4064672291278839
rl training, epoch2, iter0, batch895/1133, batch loss:0.4064672291278839, Training time:6618.556650876999
batch reward last col mean 0.1193971335887909 first col mean 0.12409929931163788 all mean 0.12317468225955963
0.3470618724822998 0.3470618724822998
rl training, epoch2, iter0, batch896/1133, batch loss:0.3470618724822998, Training time:6620.424854278564
batch reward last col mean 0.1776530146598816 first col mean 0.1353263556957245 all mean 0.164903923869133
0.4040319323539734 0.4040319323539734
rl training, epoch2, iter0, batch897/1133, batch loss:0.4040319323539734, Training time:6622.1790063381195
batch reward last col mean 0.12256082892417908 first col mean 0.12629646062850952 all mean 0.12507468461990356
0.36693328619003296 0.36693328619003296
rl training, epoch2, iter0, batch898/1133, batch loss:0.36693328619003296, Training time:6624.3481476306915
batch reward last col mean 0.11245644092559814 first col mean 0.12332624197006226 all mean 0.11498767137527466
0.33177489042282104 0.33177489042282104
rl training, epoch2, iter0, batch899/1133, batch loss:0.33177489042282104, Training time:6627.556967020035
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5591319211794019 Time: 99.6787416934967 s
loss of true 0.2515922894887133 loss of gen 0.1860180119445444 loss of other 0.12152161951927305 first score 0.14857225120067596
batch reward last col mean 0.08757015317678452 first col mean 0.12166035175323486 all mean 0.09750841557979584
0.28044137358665466 0.28044137358665466
rl training, epoch2, iter0, batch900/1133, batch loss:0.28044137358665466, Training time:6729.239861488342
batch reward last col mean 0.07872270047664642 first col mean 0.09922994673252106 all mean 0.08656906336545944
0.2541619837284088 0.2541619837284088
rl training, epoch2, iter0, batch901/1133, batch loss:0.2541619837284088, Training time:6731.282669305801
batch reward last col mean 0.12410566955804825 first col mean 0.09914682060480118 all mean 0.12011684477329254
0.33437594771385193 0.33437594771385193
rl training, epoch2, iter0, batch902/1133, batch loss:0.33437594771385193, Training time:6733.256907224655
batch reward last col mean 0.10818807780742645 first col mean 0.1052694320678711 all mean 0.11019566655158997
0.3006727993488312 0.3006727993488312
rl training, epoch2, iter0, batch903/1133, batch loss:0.3006727993488312, Training time:6735.664228439331
batch reward last col mean 0.1233503594994545 first col mean 0.1073850765824318 all mean 0.11756477504968643
0.29559698700904846 0.29559698700904846
rl training, epoch2, iter0, batch904/1133, batch loss:0.29559698700904846, Training time:6737.73087644577
batch reward last col mean 0.08871010690927505 first col mean 0.10669351369142532 all mean 0.09203676134347916
0.280055969953537 0.280055969953537
rl training, epoch2, iter0, batch905/1133, batch loss:0.280055969953537, Training time:6740.5270216465
batch reward last col mean 0.09832988679409027 first col mean 0.10982020199298859 all mean 0.09893498569726944
0.28608718514442444 0.28608718514442444
rl training, epoch2, iter0, batch906/1133, batch loss:0.28608718514442444, Training time:6742.84672999382
batch reward last col mean 0.14089685678482056 first col mean 0.12350234389305115 all mean 0.13889570534229279
0.33122149109840393 0.33122149109840393
rl training, epoch2, iter0, batch907/1133, batch loss:0.33122149109840393, Training time:6746.044766187668
batch reward last col mean 0.08248826861381531 first col mean 0.10350215435028076 all mean 0.08936864882707596
0.2806726396083832 0.2806726396083832
rl training, epoch2, iter0, batch908/1133, batch loss:0.2806726396083832, Training time:6748.235820531845
batch reward last col mean 0.12084317207336426 first col mean 0.10622843354940414 all mean 0.11633578687906265
0.3037610948085785 0.3037610948085785
rl training, epoch2, iter0, batch909/1133, batch loss:0.3037610948085785, Training time:6750.098914861679
batch reward last col mean 0.10019296407699585 first col mean 0.11668474227190018 all mean 0.10898210108280182
0.3186720013618469 0.3186720013618469
rl training, epoch2, iter0, batch910/1133, batch loss:0.3186720013618469, Training time:6751.97197842598
batch reward last col mean 0.10980066657066345 first col mean 0.11539813876152039 all mean 0.1109197810292244
0.3063676059246063 0.3063676059246063
rl training, epoch2, iter0, batch911/1133, batch loss:0.3063676059246063, Training time:6753.767375946045
batch reward last col mean 0.10609553754329681 first col mean 0.11611077934503555 all mean 0.10186607390642166
0.2910991311073303 0.29109910130500793
rl training, epoch2, iter0, batch912/1133, batch loss:0.29109910130500793, Training time:6755.529395103455
batch reward last col mean 0.1620524525642395 first col mean 0.11151599884033203 all mean 0.1410975307226181
0.3431459367275238 0.3431459367275238
rl training, epoch2, iter0, batch913/1133, batch loss:0.3431459367275238, Training time:6757.340580940247
batch reward last col mean 0.10113709419965744 first col mean 0.10532976686954498 all mean 0.10390815883874893
0.2997511029243469 0.2997511029243469
rl training, epoch2, iter0, batch914/1133, batch loss:0.2997511029243469, Training time:6759.432865619659
batch reward last col mean 0.13479670882225037 first col mean 0.1064547598361969 all mean 0.12192119657993317
0.3106854557991028 0.3106854557991028
rl training, epoch2, iter0, batch915/1133, batch loss:0.3106854557991028, Training time:6761.336737394333
batch reward last col mean 0.06753990054130554 first col mean 0.11294890940189362 all mean 0.08112874627113342
0.27147525548934937 0.27147525548934937
rl training, epoch2, iter0, batch916/1133, batch loss:0.27147525548934937, Training time:6763.0440883636475
batch reward last col mean 0.11895796656608582 first col mean 0.11951842904090881 all mean 0.12070386856794357
0.29348698258399963 0.29348698258399963
rl training, epoch2, iter0, batch917/1133, batch loss:0.29348698258399963, Training time:6765.288171291351
batch reward last col mean 0.1056443378329277 first col mean 0.11449003219604492 all mean 0.103011853992939
0.2834661602973938 0.2834661602973938
rl training, epoch2, iter0, batch918/1133, batch loss:0.2834661602973938, Training time:6767.297039270401
batch reward last col mean 0.12270200252532959 first col mean 0.11680132895708084 all mean 0.120292067527771
0.30693763494491577 0.30693763494491577
rl training, epoch2, iter0, batch919/1133, batch loss:0.30693763494491577, Training time:6769.441919565201
batch reward last col mean 0.11394583433866501 first col mean 0.11789904534816742 all mean 0.11965709924697876
0.3248157799243927 0.3248157501220703
rl training, epoch2, iter0, batch920/1133, batch loss:0.3248157501220703, Training time:6771.259290456772
batch reward last col mean 0.1256898045539856 first col mean 0.10705504566431046 all mean 0.12248696386814117
0.36109066009521484 0.36109066009521484
rl training, epoch2, iter0, batch921/1133, batch loss:0.36109066009521484, Training time:6773.179788827896
batch reward last col mean 0.10464618355035782 first col mean 0.11770391464233398 all mean 0.11074817925691605
0.3128049969673157 0.3128049969673157
rl training, epoch2, iter0, batch922/1133, batch loss:0.3128049969673157, Training time:6775.19025015831
batch reward last col mean 0.1094454675912857 first col mean 0.11262445151805878 all mean 0.11198224872350693
0.28270864486694336 0.28270864486694336
rl training, epoch2, iter0, batch923/1133, batch loss:0.28270864486694336, Training time:6777.033010005951
batch reward last col mean 0.10923044383525848 first col mean 0.1022806391119957 all mean 0.10951883345842361
0.30706971883773804 0.30706971883773804
rl training, epoch2, iter0, batch924/1133, batch loss:0.30706971883773804, Training time:6778.88462138176
batch reward last col mean 0.07300452142953873 first col mean 0.10953184962272644 all mean 0.08305937051773071
0.2746065855026245 0.2746065855026245
rl training, epoch2, iter0, batch925/1133, batch loss:0.2746065855026245, Training time:6780.43324804306
batch reward last col mean 0.12126226723194122 first col mean 0.11095766723155975 all mean 0.12143949419260025
0.30423131585121155 0.30423131585121155
rl training, epoch2, iter0, batch926/1133, batch loss:0.30423131585121155, Training time:6783.088637828827
batch reward last col mean 0.09638871997594833 first col mean 0.10289732366800308 all mean 0.10521582514047623
0.2936244010925293 0.2936244010925293
rl training, epoch2, iter0, batch927/1133, batch loss:0.2936244010925293, Training time:6784.897253513336
batch reward last col mean 0.1003185510635376 first col mean 0.12699663639068604 all mean 0.10189653933048248
0.298851877450943 0.2988518476486206
rl training, epoch2, iter0, batch928/1133, batch loss:0.2988518476486206, Training time:6787.428501367569
batch reward last col mean 0.0920632854104042 first col mean 0.115671306848526 all mean 0.09946548938751221
0.3100452423095703 0.3100452423095703
rl training, epoch2, iter0, batch929/1133, batch loss:0.3100452423095703, Training time:6789.400719642639
batch reward last col mean 0.12652847170829773 first col mean 0.10766326636075974 all mean 0.12017987668514252
0.30459287762641907 0.30459287762641907
rl training, epoch2, iter0, batch930/1133, batch loss:0.30459287762641907, Training time:6791.106517314911
batch reward last col mean 0.10421432554721832 first col mean 0.09308848530054092 all mean 0.10191019624471664
0.2789674699306488 0.2789674699306488
rl training, epoch2, iter0, batch931/1133, batch loss:0.2789674699306488, Training time:6792.878988981247
batch reward last col mean 0.10307279229164124 first col mean 0.12775957584381104 all mean 0.10829219222068787
0.3205305337905884 0.3205305337905884
rl training, epoch2, iter0, batch932/1133, batch loss:0.3205305337905884, Training time:6794.903613805771
batch reward last col mean 0.15609800815582275 first col mean 0.12678125500679016 all mean 0.14105452597141266
0.34516388177871704 0.34516388177871704
rl training, epoch2, iter0, batch933/1133, batch loss:0.34516388177871704, Training time:6796.536178827286
batch reward last col mean 0.09887327998876572 first col mean 0.10339179635047913 all mean 0.10651210695505142
0.3029128313064575 0.3029128313064575
rl training, epoch2, iter0, batch934/1133, batch loss:0.3029128313064575, Training time:6798.55172419548
batch reward last col mean 0.12585332989692688 first col mean 0.11536753177642822 all mean 0.12329965829849243
0.34330543875694275 0.34330546855926514
rl training, epoch2, iter0, batch935/1133, batch loss:0.34330546855926514, Training time:6800.663573503494
batch reward last col mean 0.10662482678890228 first col mean 0.11253201216459274 all mean 0.10892609506845474
0.3192236125469208 0.31922364234924316
rl training, epoch2, iter0, batch936/1133, batch loss:0.31922364234924316, Training time:6803.463927268982
batch reward last col mean 0.0818127766251564 first col mean 0.10686551034450531 all mean 0.09023050218820572
0.29521748423576355 0.29521748423576355
rl training, epoch2, iter0, batch937/1133, batch loss:0.29521748423576355, Training time:6805.282166957855
batch reward last col mean 0.10706581175327301 first col mean 0.1140429675579071 all mean 0.10891318321228027
0.28036028146743774 0.28036028146743774
rl training, epoch2, iter0, batch938/1133, batch loss:0.28036028146743774, Training time:6807.424705982208
batch reward last col mean 0.07456517219543457 first col mean 0.11302700638771057 all mean 0.08471006900072098
0.29298126697540283 0.29298126697540283
rl training, epoch2, iter0, batch939/1133, batch loss:0.29298126697540283, Training time:6809.568808794022
batch reward last col mean 0.10743602365255356 first col mean 0.12270594388246536 all mean 0.11001289635896683
0.3171050250530243 0.3171049952507019
rl training, epoch2, iter0, batch940/1133, batch loss:0.3171049952507019, Training time:6811.774074316025
batch reward last col mean 0.10680799186229706 first col mean 0.11979159712791443 all mean 0.10900338739156723
0.30641651153564453 0.30641651153564453
rl training, epoch2, iter0, batch941/1133, batch loss:0.30641651153564453, Training time:6813.8721425533295
batch reward last col mean 0.07707619667053223 first col mean 0.12068027257919312 all mean 0.09208324551582336
0.34742271900177 0.34742265939712524
rl training, epoch2, iter0, batch942/1133, batch loss:0.34742265939712524, Training time:6815.996599912643
batch reward last col mean 0.14548242092132568 first col mean 0.11512704193592072 all mean 0.13900691270828247
0.34692469239234924 0.34692469239234924
rl training, epoch2, iter0, batch943/1133, batch loss:0.34692469239234924, Training time:6817.651045799255
batch reward last col mean 0.12719549238681793 first col mean 0.10878022015094757 all mean 0.12344330549240112
0.37943553924560547 0.37943553924560547
rl training, epoch2, iter0, batch944/1133, batch loss:0.37943553924560547, Training time:6819.863265752792
batch reward last col mean 0.10688653588294983 first col mean 0.11856241524219513 all mean 0.11212892830371857
0.3453312814235687 0.3453312814235687
rl training, epoch2, iter0, batch945/1133, batch loss:0.3453312814235687, Training time:6821.9746260643005
batch reward last col mean 0.1469922810792923 first col mean 0.11819621175527573 all mean 0.13729432225227356
0.3362762928009033 0.3362762928009033
rl training, epoch2, iter0, batch946/1133, batch loss:0.3362762928009033, Training time:6823.877014875412
batch reward last col mean 0.11194577068090439 first col mean 0.14556172490119934 all mean 0.11329385638237
0.34013909101486206 0.34013909101486206
rl training, epoch2, iter0, batch947/1133, batch loss:0.34013909101486206, Training time:6826.268604040146
batch reward last col mean 0.15084955096244812 first col mean 0.1288217306137085 all mean 0.13750143349170685
0.379730224609375 0.379730224609375
rl training, epoch2, iter0, batch948/1133, batch loss:0.379730224609375, Training time:6827.890930175781
batch reward last col mean 0.1067674532532692 first col mean 0.12437892705202103 all mean 0.10904588550329208
0.2929246723651886 0.2929246723651886
rl training, epoch2, iter0, batch949/1133, batch loss:0.2929246723651886, Training time:6829.651388883591
batch reward last col mean 0.09942541271448135 first col mean 0.11819616705179214 all mean 0.0999985858798027
0.30275148153305054 0.30275148153305054
rl training, epoch2, iter0, batch950/1133, batch loss:0.30275148153305054, Training time:6831.082008123398
batch reward last col mean 0.1032881885766983 first col mean 0.10974600911140442 all mean 0.10062648355960846
0.2917376756668091 0.2917376458644867
rl training, epoch2, iter0, batch951/1133, batch loss:0.2917376458644867, Training time:6833.330500125885
batch reward last col mean 0.0847262442111969 first col mean 0.11207858473062515 all mean 0.09172192960977554
0.2814900279045105 0.2814900279045105
rl training, epoch2, iter0, batch952/1133, batch loss:0.2814900279045105, Training time:6835.126857280731
batch reward last col mean 0.0789891928434372 first col mean 0.12650805711746216 all mean 0.09059092402458191
0.2721497714519501 0.2721497714519501
rl training, epoch2, iter0, batch953/1133, batch loss:0.2721497714519501, Training time:6836.779957532883
batch reward last col mean 0.12766295671463013 first col mean 0.1296762228012085 all mean 0.12782475352287292
0.3404925465583801 0.3404926061630249
rl training, epoch2, iter0, batch954/1133, batch loss:0.3404926061630249, Training time:6839.035353422165
batch reward last col mean 0.11278010159730911 first col mean 0.12394708395004272 all mean 0.11381147801876068
0.3339522182941437 0.33395224809646606
rl training, epoch2, iter0, batch955/1133, batch loss:0.33395224809646606, Training time:6840.753463506699
batch reward last col mean 0.116807721555233 first col mean 0.11027608066797256 all mean 0.10725496709346771
0.31403467059135437 0.31403470039367676
rl training, epoch2, iter0, batch956/1133, batch loss:0.31403470039367676, Training time:6842.362730741501
batch reward last col mean 0.14079387485980988 first col mean 0.1218729317188263 all mean 0.13685686886310577
0.3260970413684845 0.3260970413684845
rl training, epoch2, iter0, batch957/1133, batch loss:0.3260970413684845, Training time:6844.107324123383
batch reward last col mean 0.11239559948444366 first col mean 0.118135005235672 all mean 0.1100282222032547
0.30149441957473755 0.30149441957473755
rl training, epoch2, iter0, batch958/1133, batch loss:0.30149441957473755, Training time:6846.624581336975
batch reward last col mean 0.09042657911777496 first col mean 0.11495880782604218 all mean 0.09396585822105408
0.27877941727638245 0.27877941727638245
rl training, epoch2, iter0, batch959/1133, batch loss:0.27877941727638245, Training time:6848.809426307678
batch reward last col mean 0.07188350707292557 first col mean 0.12397841364145279 all mean 0.0803239718079567
0.285704106092453 0.285704106092453
rl training, epoch2, iter0, batch960/1133, batch loss:0.285704106092453, Training time:6850.82568359375
batch reward last col mean 0.11861269176006317 first col mean 0.10910169780254364 all mean 0.11767855286598206
0.35994887351989746 0.35994887351989746
rl training, epoch2, iter0, batch961/1133, batch loss:0.35994887351989746, Training time:6852.359455347061
batch reward last col mean 0.08899552375078201 first col mean 0.11947441101074219 all mean 0.09680540859699249
0.3509662449359894 0.3509662449359894
rl training, epoch2, iter0, batch962/1133, batch loss:0.3509662449359894, Training time:6854.055478334427
batch reward last col mean 0.12016254663467407 first col mean 0.11267423629760742 all mean 0.11583257466554642
0.28954893350601196 0.28954896330833435
rl training, epoch2, iter0, batch963/1133, batch loss:0.28954896330833435, Training time:6855.76397895813
batch reward last col mean 0.1254505217075348 first col mean 0.11119647324085236 all mean 0.12359508872032166
0.32228076457977295 0.32228076457977295
rl training, epoch2, iter0, batch964/1133, batch loss:0.32228076457977295, Training time:6857.686703443527
batch reward last col mean 0.15808336436748505 first col mean 0.12697307765483856 all mean 0.14520873129367828
0.3713145852088928 0.3713145852088928
rl training, epoch2, iter0, batch965/1133, batch loss:0.3713145852088928, Training time:6859.419483184814
batch reward last col mean 0.10332927107810974 first col mean 0.1197897270321846 all mean 0.1117398664355278
0.3359817564487457 0.33598172664642334
rl training, epoch2, iter0, batch966/1133, batch loss:0.33598172664642334, Training time:6860.729778289795
batch reward last col mean 0.10335702449083328 first col mean 0.120742067694664 all mean 0.11240504682064056
0.3056879937648773 0.3056879937648773
rl training, epoch2, iter0, batch967/1133, batch loss:0.3056879937648773, Training time:6862.317069530487
batch reward last col mean 0.11397166550159454 first col mean 0.1066814512014389 all mean 0.1118035614490509
0.30955639481544495 0.30955642461776733
rl training, epoch2, iter0, batch968/1133, batch loss:0.30955642461776733, Training time:6864.129513025284
batch reward last col mean 0.13299697637557983 first col mean 0.12234123051166534 all mean 0.1299414187669754
0.3735172748565674 0.3735172748565674
rl training, epoch2, iter0, batch969/1133, batch loss:0.3735172748565674, Training time:6866.092571735382
batch reward last col mean 0.11080054193735123 first col mean 0.12544569373130798 all mean 0.11431512981653214
0.3233487606048584 0.3233487606048584
rl training, epoch2, iter0, batch970/1133, batch loss:0.3233487606048584, Training time:6867.866728305817
batch reward last col mean 0.13330815732479095 first col mean 0.1210319921374321 all mean 0.13080695271492004
0.3224990963935852 0.3224990665912628
rl training, epoch2, iter0, batch971/1133, batch loss:0.3224990665912628, Training time:6870.413179397583
batch reward last col mean 0.1465524286031723 first col mean 0.1458219736814499 all mean 0.14108380675315857
0.41173067688941956 0.41173064708709717
rl training, epoch2, iter0, batch972/1133, batch loss:0.41173064708709717, Training time:6872.832699298859
batch reward last col mean 0.11095321178436279 first col mean 0.13281531631946564 all mean 0.11016741394996643
0.3161834478378296 0.3161834478378296
rl training, epoch2, iter0, batch973/1133, batch loss:0.3161834478378296, Training time:6875.673120260239
batch reward last col mean 0.10658399760723114 first col mean 0.11011336743831635 all mean 0.11114397644996643
0.2672223746776581 0.26722240447998047
rl training, epoch2, iter0, batch974/1133, batch loss:0.26722240447998047, Training time:6877.436168432236
batch reward last col mean 0.09933394193649292 first col mean 0.11050236225128174 all mean 0.09920439124107361
0.2718861401081085 0.2718861401081085
rl training, epoch2, iter0, batch975/1133, batch loss:0.2718861401081085, Training time:6879.088521718979
batch reward last col mean 0.09862686693668365 first col mean 0.12437652796506882 all mean 0.09828724712133408
0.27107101678848267 0.27107101678848267
rl training, epoch2, iter0, batch976/1133, batch loss:0.27107101678848267, Training time:6881.057858467102
batch reward last col mean 0.0880378931760788 first col mean 0.10382750630378723 all mean 0.09869235008955002
0.31868988275527954 0.31868988275527954
rl training, epoch2, iter0, batch977/1133, batch loss:0.31868988275527954, Training time:6882.873091936111
batch reward last col mean 0.09862691164016724 first col mean 0.12029348313808441 all mean 0.10327757894992828
0.29551711678504944 0.29551711678504944
rl training, epoch2, iter0, batch978/1133, batch loss:0.29551711678504944, Training time:6884.8821849823
batch reward last col mean 0.12106603384017944 first col mean 0.12416745722293854 all mean 0.1184222400188446
0.3050074577331543 0.3050074279308319
rl training, epoch2, iter0, batch979/1133, batch loss:0.3050074279308319, Training time:6886.9356961250305
batch reward last col mean 0.12497089803218842 first col mean 0.13844449818134308 all mean 0.1316429227590561
0.3645954132080078 0.3645954132080078
rl training, epoch2, iter0, batch980/1133, batch loss:0.3645954132080078, Training time:6888.819336175919
batch reward last col mean 0.08136066794395447 first col mean 0.13059233129024506 all mean 0.10325320810079575
0.35546618700027466 0.35546618700027466
rl training, epoch2, iter0, batch981/1133, batch loss:0.35546618700027466, Training time:6890.761906385422
batch reward last col mean 0.12744329869747162 first col mean 0.1283339560031891 all mean 0.1276087462902069
0.3746996819972992 0.3746997117996216
rl training, epoch2, iter0, batch982/1133, batch loss:0.3746997117996216, Training time:6892.572229623795
batch reward last col mean 0.1172117292881012 first col mean 0.10509209334850311 all mean 0.11832626163959503
0.34548449516296387 0.34548449516296387
rl training, epoch2, iter0, batch983/1133, batch loss:0.34548449516296387, Training time:6894.247553348541
batch reward last col mean 0.09023450314998627 first col mean 0.11852779984474182 all mean 0.09638329595327377
0.27094870805740356 0.2709486782550812
rl training, epoch2, iter0, batch984/1133, batch loss:0.2709486782550812, Training time:6895.645315170288
batch reward last col mean 0.11359795182943344 first col mean 0.12000873684883118 all mean 0.11177635192871094
0.2997553050518036 0.2997553050518036
rl training, epoch2, iter0, batch985/1133, batch loss:0.2997553050518036, Training time:6897.382349729538
batch reward last col mean 0.11204901337623596 first col mean 0.13169291615486145 all mean 0.11491653323173523
0.3336440324783325 0.3336440324783325
rl training, epoch2, iter0, batch986/1133, batch loss:0.3336440324783325, Training time:6899.574136257172
batch reward last col mean 0.14073003828525543 first col mean 0.13645389676094055 all mean 0.13905596733093262
0.3519192934036255 0.3519192934036255
rl training, epoch2, iter0, batch987/1133, batch loss:0.3519192934036255, Training time:6901.816562652588
batch reward last col mean 0.09014692902565002 first col mean 0.10891695320606232 all mean 0.09885090589523315
0.2813393473625183 0.2813393473625183
rl training, epoch2, iter0, batch988/1133, batch loss:0.2813393473625183, Training time:6903.8439412117
batch reward last col mean 0.13141858577728271 first col mean 0.13390886783599854 all mean 0.1306334137916565
0.35494863986968994 0.35494863986968994
rl training, epoch2, iter0, batch989/1133, batch loss:0.35494863986968994, Training time:6905.372354507446
batch reward last col mean 0.11112416535615921 first col mean 0.12714001536369324 all mean 0.11404388397932053
0.37598809599876404 0.37598809599876404
rl training, epoch2, iter0, batch990/1133, batch loss:0.37598809599876404, Training time:6907.068937778473
batch reward last col mean 0.13734866678714752 first col mean 0.12891648709774017 all mean 0.13677196204662323
0.39606499671936035 0.39606499671936035
rl training, epoch2, iter0, batch991/1133, batch loss:0.39606499671936035, Training time:6908.868585586548
batch reward last col mean 0.1013871282339096 first col mean 0.14530891180038452 all mean 0.10526290535926819
0.2788334786891937 0.2788334786891937
rl training, epoch2, iter0, batch992/1133, batch loss:0.2788334786891937, Training time:6910.52116394043
batch reward last col mean 0.12892413139343262 first col mean 0.12088409066200256 all mean 0.12758763134479523
0.31990328431129456 0.31990328431129456
rl training, epoch2, iter0, batch993/1133, batch loss:0.31990328431129456, Training time:6912.960740327835
batch reward last col mean 0.09239531308412552 first col mean 0.11455323547124863 all mean 0.10394976288080215
0.33922162652015686 0.33922162652015686
rl training, epoch2, iter0, batch994/1133, batch loss:0.33922162652015686, Training time:6914.623161077499
batch reward last col mean 0.09466446936130524 first col mean 0.11103709042072296 all mean 0.10753648728132248
0.37692150473594666 0.37692150473594666
rl training, epoch2, iter0, batch995/1133, batch loss:0.37692150473594666, Training time:6916.488116264343
batch reward last col mean 0.13041366636753082 first col mean 0.13434059917926788 all mean 0.13054168224334717
0.3583381474018097 0.3583381474018097
rl training, epoch2, iter0, batch996/1133, batch loss:0.3583381474018097, Training time:6918.853964567184
batch reward last col mean 0.09790338575839996 first col mean 0.1187804639339447 all mean 0.09917635470628738
0.3044738173484802 0.3044738173484802
rl training, epoch2, iter0, batch997/1133, batch loss:0.3044738173484802, Training time:6920.706959486008
batch reward last col mean 0.13051889836788177 first col mean 0.13291355967521667 all mean 0.12477622181177139
0.3605351150035858 0.3605351150035858
rl training, epoch2, iter0, batch998/1133, batch loss:0.3605351150035858, Training time:6923.533705472946
batch reward last col mean 0.09438486397266388 first col mean 0.11961625516414642 all mean 0.09960143268108368
0.31665897369384766 0.31665897369384766
rl training, epoch2, iter0, batch999/1133, batch loss:0.31665897369384766, Training time:6925.69334602356
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5640647650185877 Time: 96.71677660942078 s
loss of true 0.2518160378811955 loss of gen 0.1952942027747368 loss of other 0.11695452505313288 first score 0.1371893286705017
batch reward last col mean 0.09155616909265518 first col mean 0.10330933332443237 all mean 0.09715316444635391
0.2818632423877716 0.2818632423877716
rl training, epoch2, iter0, batch1000/1133, batch loss:0.2818632423877716, Training time:7024.030978679657
batch reward last col mean 0.10984637588262558 first col mean 0.10952426493167877 all mean 0.1134779155254364
0.314567506313324 0.314567506313324
rl training, epoch2, iter0, batch1001/1133, batch loss:0.314567506313324, Training time:7026.5808045864105
batch reward last col mean 0.09638094156980515 first col mean 0.10315131396055222 all mean 0.10332365334033966
0.29305851459503174 0.29305851459503174
rl training, epoch2, iter0, batch1002/1133, batch loss:0.29305851459503174, Training time:7028.409710884094
batch reward last col mean 0.13857915997505188 first col mean 0.12292936444282532 all mean 0.1329728066921234
0.34860900044441223 0.348609060049057
rl training, epoch2, iter0, batch1003/1133, batch loss:0.348609060049057, Training time:7030.884909152985
batch reward last col mean 0.1455414742231369 first col mean 0.09556354582309723 all mean 0.12800201773643494
0.3414159417152405 0.3414159417152405
rl training, epoch2, iter0, batch1004/1133, batch loss:0.3414159417152405, Training time:7032.626565694809
batch reward last col mean 0.1524183750152588 first col mean 0.10241008549928665 all mean 0.1417578011751175
0.2861920893192291 0.2861920893192291
rl training, epoch2, iter0, batch1005/1133, batch loss:0.2861920893192291, Training time:7034.676059007645
batch reward last col mean 0.09960059821605682 first col mean 0.12175706773996353 all mean 0.10710497200489044
0.2899706959724426 0.2899706959724426
rl training, epoch2, iter0, batch1006/1133, batch loss:0.2899706959724426, Training time:7036.388391017914
batch reward last col mean 0.11722046136856079 first col mean 0.10152468830347061 all mean 0.11000964045524597
0.28905266523361206 0.28905266523361206
rl training, epoch2, iter0, batch1007/1133, batch loss:0.28905266523361206, Training time:7038.163541555405
batch reward last col mean 0.14933785796165466 first col mean 0.11184415221214294 all mean 0.13612377643585205
0.2950715720653534 0.2950715720653534
rl training, epoch2, iter0, batch1008/1133, batch loss:0.2950715720653534, Training time:7040.282577514648
batch reward last col mean 0.09090331196784973 first col mean 0.11858315020799637 all mean 0.09745422750711441
0.2668946087360382 0.2668946087360382
rl training, epoch2, iter0, batch1009/1133, batch loss:0.2668946087360382, Training time:7042.023837566376
batch reward last col mean 0.13294121623039246 first col mean 0.10889498889446259 all mean 0.12732064723968506
0.30427998304367065 0.30427998304367065
rl training, epoch2, iter0, batch1010/1133, batch loss:0.30427998304367065, Training time:7044.092287540436
batch reward last col mean 0.0961112529039383 first col mean 0.11867804825305939 all mean 0.10418294370174408
0.3190666735172272 0.3190666735172272
rl training, epoch2, iter0, batch1011/1133, batch loss:0.3190666735172272, Training time:7045.97375535965
batch reward last col mean 0.10251042991876602 first col mean 0.10738108307123184 all mean 0.09531737864017487
0.26609864830970764 0.26609864830970764
rl training, epoch2, iter0, batch1012/1133, batch loss:0.26609864830970764, Training time:7047.7076115608215
batch reward last col mean 0.101161889731884 first col mean 0.11672000586986542 all mean 0.10393156856298447
0.3286871314048767 0.3286871314048767
rl training, epoch2, iter0, batch1013/1133, batch loss:0.3286871314048767, Training time:7049.537954330444
batch reward last col mean 0.07402913272380829 first col mean 0.1012556403875351 all mean 0.08568879216909409
0.279025673866272 0.279025673866272
rl training, epoch2, iter0, batch1014/1133, batch loss:0.279025673866272, Training time:7051.706017255783
batch reward last col mean 0.08389261364936829 first col mean 0.11273742467164993 all mean 0.08756189793348312
0.27400097250938416 0.27400097250938416
rl training, epoch2, iter0, batch1015/1133, batch loss:0.27400097250938416, Training time:7053.72123837471
batch reward last col mean 0.09610724449157715 first col mean 0.11316654831171036 all mean 0.09814723581075668
0.2709745466709137 0.2709745168685913
rl training, epoch2, iter0, batch1016/1133, batch loss:0.2709745168685913, Training time:7055.855602264404
batch reward last col mean 0.10294538736343384 first col mean 0.13106751441955566 all mean 0.10835140943527222
0.33883118629455566 0.33883118629455566
rl training, epoch2, iter0, batch1017/1133, batch loss:0.33883118629455566, Training time:7057.872677326202
batch reward last col mean 0.11301926523447037 first col mean 0.09874673932790756 all mean 0.10750675946474075
0.3289896547794342 0.3289896547794342
rl training, epoch2, iter0, batch1018/1133, batch loss:0.3289896547794342, Training time:7059.507053375244
batch reward last col mean 0.08178772032260895 first col mean 0.10174030065536499 all mean 0.08920285850763321
0.2838176488876343 0.2838176488876343
rl training, epoch2, iter0, batch1019/1133, batch loss:0.2838176488876343, Training time:7061.339093446732
batch reward last col mean 0.05932273715734482 first col mean 0.09111163020133972 all mean 0.07105041295289993
0.23568375408649445 0.23568375408649445
rl training, epoch2, iter0, batch1020/1133, batch loss:0.23568375408649445, Training time:7063.131329298019
batch reward last col mean 0.08896773308515549 first col mean 0.1183016374707222 all mean 0.09215568751096725
0.2874825596809387 0.2874825596809387
rl training, epoch2, iter0, batch1021/1133, batch loss:0.2874825596809387, Training time:7064.919406890869
batch reward last col mean 0.13836920261383057 first col mean 0.11650701612234116 all mean 0.1294289231300354
0.36214205622673035 0.36214205622673035
rl training, epoch2, iter0, batch1022/1133, batch loss:0.36214205622673035, Training time:7066.8133289813995
batch reward last col mean 0.0839771181344986 first col mean 0.1119663342833519 all mean 0.09018877893686295
0.30104368925094604 0.30104368925094604
rl training, epoch2, iter0, batch1023/1133, batch loss:0.30104368925094604, Training time:7069.037093639374
batch reward last col mean 0.10082809627056122 first col mean 0.11455735564231873 all mean 0.10005379468202591
0.3192908763885498 0.3192908763885498
rl training, epoch2, iter0, batch1024/1133, batch loss:0.3192908763885498, Training time:7070.867615938187
batch reward last col mean 0.10369677096605301 first col mean 0.12507149577140808 all mean 0.10936101526021957
0.308359295129776 0.3083592653274536
rl training, epoch2, iter0, batch1025/1133, batch loss:0.3083592653274536, Training time:7072.935115098953
batch reward last col mean 0.09091121703386307 first col mean 0.12068472057580948 all mean 0.09598323702812195
0.27791088819503784 0.27791088819503784
rl training, epoch2, iter0, batch1026/1133, batch loss:0.27791088819503784, Training time:7074.578588008881
batch reward last col mean 0.1319425404071808 first col mean 0.1218041256070137 all mean 0.12763634324073792
0.34606823325157166 0.34606820344924927
rl training, epoch2, iter0, batch1027/1133, batch loss:0.34606820344924927, Training time:7076.368668556213
batch reward last col mean 0.1294907033443451 first col mean 0.11433359235525131 all mean 0.12520836293697357
0.33714017271995544 0.33714014291763306
rl training, epoch2, iter0, batch1028/1133, batch loss:0.33714014291763306, Training time:7077.963265657425
batch reward last col mean 0.09471745789051056 first col mean 0.10069586336612701 all mean 0.09942489862442017
0.2948657274246216 0.2948657274246216
rl training, epoch2, iter0, batch1029/1133, batch loss:0.2948657274246216, Training time:7080.649676561356
batch reward last col mean 0.11781983077526093 first col mean 0.1025356575846672 all mean 0.11888594180345535
0.3174711763858795 0.31747114658355713
rl training, epoch2, iter0, batch1030/1133, batch loss:0.31747114658355713, Training time:7082.6846652030945
batch reward last col mean 0.08993594348430634 first col mean 0.11248728632926941 all mean 0.09722568094730377
0.3139774203300476 0.3139774203300476
rl training, epoch2, iter0, batch1031/1133, batch loss:0.3139774203300476, Training time:7084.295950889587
batch reward last col mean 0.08877277374267578 first col mean 0.1093207597732544 all mean 0.09705155342817307
0.29911744594573975 0.29911744594573975
rl training, epoch2, iter0, batch1032/1133, batch loss:0.29911744594573975, Training time:7086.246438741684
batch reward last col mean 0.11759626865386963 first col mean 0.12379854172468185 all mean 0.11718901246786118
0.34871891140937805 0.34871891140937805
rl training, epoch2, iter0, batch1033/1133, batch loss:0.34871891140937805, Training time:7088.5760679244995
batch reward last col mean 0.10833851993083954 first col mean 0.12158648669719696 all mean 0.10972915589809418
0.30679619312286377 0.30679619312286377
rl training, epoch2, iter0, batch1034/1133, batch loss:0.30679619312286377, Training time:7090.622976779938
batch reward last col mean 0.11286284029483795 first col mean 0.11204305291175842 all mean 0.10235521197319031
0.3049512505531311 0.3049512505531311
rl training, epoch2, iter0, batch1035/1133, batch loss:0.3049512505531311, Training time:7092.457320690155
batch reward last col mean 0.10019920766353607 first col mean 0.1112787276506424 all mean 0.10429057478904724
0.3335237205028534 0.3335237205028534
rl training, epoch2, iter0, batch1036/1133, batch loss:0.3335237205028534, Training time:7094.668870210648
batch reward last col mean 0.09269401431083679 first col mean 0.10585509240627289 all mean 0.09472408890724182
0.26929357647895813 0.26929354667663574
rl training, epoch2, iter0, batch1037/1133, batch loss:0.26929354667663574, Training time:7096.8157839775085
batch reward last col mean 0.12778887152671814 first col mean 0.13103318214416504 all mean 0.12265206128358841
0.34426841139793396 0.34426841139793396
rl training, epoch2, iter0, batch1038/1133, batch loss:0.34426841139793396, Training time:7098.773148775101
batch reward last col mean 0.11667472869157791 first col mean 0.1201922744512558 all mean 0.12215013056993484
0.31691959500312805 0.31691959500312805
rl training, epoch2, iter0, batch1039/1133, batch loss:0.31691959500312805, Training time:7100.636978387833
batch reward last col mean 0.10933312773704529 first col mean 0.09918858110904694 all mean 0.1065053790807724
0.2959527373313904 0.2959527373313904
rl training, epoch2, iter0, batch1040/1133, batch loss:0.2959527373313904, Training time:7102.193231344223
batch reward last col mean 0.12860725820064545 first col mean 0.11046850681304932 all mean 0.11805345863103867
0.32391971349716187 0.32391971349716187
rl training, epoch2, iter0, batch1041/1133, batch loss:0.32391971349716187, Training time:7104.144852876663
batch reward last col mean 0.09948873519897461 first col mean 0.11469922214746475 all mean 0.10435949265956879
0.2946098744869232 0.2946098744869232
rl training, epoch2, iter0, batch1042/1133, batch loss:0.2946098744869232, Training time:7105.724342107773
batch reward last col mean 0.11900080740451813 first col mean 0.10797430574893951 all mean 0.11404358595609665
0.3277639150619507 0.3277639150619507
rl training, epoch2, iter0, batch1043/1133, batch loss:0.3277639150619507, Training time:7107.351692199707
batch reward last col mean 0.11856701970100403 first col mean 0.12445880472660065 all mean 0.12256889045238495
0.35761281847953796 0.3576127886772156
rl training, epoch2, iter0, batch1044/1133, batch loss:0.3576127886772156, Training time:7109.205350399017
batch reward last col mean 0.1131398156285286 first col mean 0.1228879913687706 all mean 0.11165214329957962
0.3208906948566437 0.3208906948566437
rl training, epoch2, iter0, batch1045/1133, batch loss:0.3208906948566437, Training time:7111.055558919907
batch reward last col mean 0.09922312200069427 first col mean 0.11014073342084885 all mean 0.10095638781785965
0.28780296444892883 0.28780296444892883
rl training, epoch2, iter0, batch1046/1133, batch loss:0.28780296444892883, Training time:7113.197616100311
batch reward last col mean 0.09457801282405853 first col mean 0.11116436123847961 all mean 0.09787403047084808
0.30894893407821655 0.30894893407821655
rl training, epoch2, iter0, batch1047/1133, batch loss:0.30894893407821655, Training time:7115.2690715789795
batch reward last col mean 0.1378515362739563 first col mean 0.10950344055891037 all mean 0.1299751251935959
0.3395887017250061 0.3395887315273285
rl training, epoch2, iter0, batch1048/1133, batch loss:0.3395887315273285, Training time:7116.835197210312
batch reward last col mean 0.07456054538488388 first col mean 0.11089251935482025 all mean 0.08762141317129135
0.27892255783081055 0.27892255783081055
rl training, epoch2, iter0, batch1049/1133, batch loss:0.27892255783081055, Training time:7118.88455748558
batch reward last col mean 0.13548040390014648 first col mean 0.11023423820734024 all mean 0.12518525123596191
0.3885546922683716 0.3885546922683716
rl training, epoch2, iter0, batch1050/1133, batch loss:0.3885546922683716, Training time:7120.702016592026
batch reward last col mean 0.0804157555103302 first col mean 0.12206803262233734 all mean 0.09564351290464401
0.31571581959724426 0.31571581959724426
rl training, epoch2, iter0, batch1051/1133, batch loss:0.31571581959724426, Training time:7122.30867934227
batch reward last col mean 0.11111116409301758 first col mean 0.10111209750175476 all mean 0.11330021917819977
0.3305882215499878 0.3305882215499878
rl training, epoch2, iter0, batch1052/1133, batch loss:0.3305882215499878, Training time:7124.176717996597
batch reward last col mean 0.12470106780529022 first col mean 0.12426984310150146 all mean 0.12339764088392258
0.3608039617538452 0.3608039617538452
rl training, epoch2, iter0, batch1053/1133, batch loss:0.3608039617538452, Training time:7126.156819105148
batch reward last col mean 0.06942904740571976 first col mean 0.1142117828130722 all mean 0.07918772846460342
0.2807363271713257 0.2807363271713257
rl training, epoch2, iter0, batch1054/1133, batch loss:0.2807363271713257, Training time:7127.831914424896
batch reward last col mean 0.09492335468530655 first col mean 0.13444876670837402 all mean 0.10129184275865555
0.31828323006629944 0.31828323006629944
rl training, epoch2, iter0, batch1055/1133, batch loss:0.31828323006629944, Training time:7129.8764979839325
batch reward last col mean 0.14208729565143585 first col mean 0.10723169147968292 all mean 0.1331806182861328
0.36008602380752563 0.36008602380752563
rl training, epoch2, iter0, batch1056/1133, batch loss:0.36008602380752563, Training time:7131.616805791855
batch reward last col mean 0.09795577079057693 first col mean 0.12316790223121643 all mean 0.10158514976501465
0.32450932264328003 0.32450932264328003
rl training, epoch2, iter0, batch1057/1133, batch loss:0.32450932264328003, Training time:7134.25249004364
batch reward last col mean 0.11544954031705856 first col mean 0.11675886064767838 all mean 0.11018595099449158
0.30574941635131836 0.30574941635131836
rl training, epoch2, iter0, batch1058/1133, batch loss:0.30574941635131836, Training time:7135.996599674225
batch reward last col mean 0.12310776114463806 first col mean 0.13860180974006653 all mean 0.1215817779302597
0.3568620979785919 0.3568620979785919
rl training, epoch2, iter0, batch1059/1133, batch loss:0.3568620979785919, Training time:7137.415769100189
batch reward last col mean 0.13742412626743317 first col mean 0.10413800179958344 all mean 0.12842899560928345
0.34368738532066345 0.34368738532066345
rl training, epoch2, iter0, batch1060/1133, batch loss:0.34368738532066345, Training time:7139.084795951843
batch reward last col mean 0.12086066603660583 first col mean 0.12071286141872406 all mean 0.12118218839168549
0.33463817834854126 0.33463817834854126
rl training, epoch2, iter0, batch1061/1133, batch loss:0.33463817834854126, Training time:7140.677572488785
batch reward last col mean 0.10221302509307861 first col mean 0.10551582276821136 all mean 0.11295745521783829
0.313402384519577 0.3134024143218994
rl training, epoch2, iter0, batch1062/1133, batch loss:0.3134024143218994, Training time:7142.358847141266
batch reward last col mean 0.10556052625179291 first col mean 0.13228671252727509 all mean 0.11264342069625854
0.35510069131851196 0.35510075092315674
rl training, epoch2, iter0, batch1063/1133, batch loss:0.35510075092315674, Training time:7143.877438545227
batch reward last col mean 0.14099088311195374 first col mean 0.09387035667896271 all mean 0.13363707065582275
0.34600532054901123 0.34600532054901123
rl training, epoch2, iter0, batch1064/1133, batch loss:0.34600532054901123, Training time:7145.305543661118
batch reward last col mean 0.11879316717386246 first col mean 0.1193191409111023 all mean 0.11889103800058365
0.30922287702560425 0.30922287702560425
rl training, epoch2, iter0, batch1065/1133, batch loss:0.30922287702560425, Training time:7146.788865566254
batch reward last col mean 0.12681573629379272 first col mean 0.12037581205368042 all mean 0.12266570329666138
0.3162940442562103 0.31629401445388794
rl training, epoch2, iter0, batch1066/1133, batch loss:0.31629401445388794, Training time:7148.607053995132
batch reward last col mean 0.10322999954223633 first col mean 0.1181316003203392 all mean 0.1048286184668541
0.33193790912628174 0.33193790912628174
rl training, epoch2, iter0, batch1067/1133, batch loss:0.33193790912628174, Training time:7150.209566116333
batch reward last col mean 0.0912269800901413 first col mean 0.09923403710126877 all mean 0.09350940585136414
0.3056269884109497 0.3056269884109497
rl training, epoch2, iter0, batch1068/1133, batch loss:0.3056269884109497, Training time:7151.890827894211
batch reward last col mean 0.08897237479686737 first col mean 0.12274699658155441 all mean 0.09950190782546997
0.31803879141807556 0.3180387616157532
rl training, epoch2, iter0, batch1069/1133, batch loss:0.3180387616157532, Training time:7153.566584348679
batch reward last col mean 0.11209782212972641 first col mean 0.11418671160936356 all mean 0.10778172314167023
0.3392513692378998 0.3392513692378998
rl training, epoch2, iter0, batch1070/1133, batch loss:0.3392513692378998, Training time:7155.043668270111
batch reward last col mean 0.11928194761276245 first col mean 0.1319517195224762 all mean 0.12240728735923767
0.35240864753723145 0.35240864753723145
rl training, epoch2, iter0, batch1071/1133, batch loss:0.35240864753723145, Training time:7156.5037977695465
batch reward last col mean 0.1195119246840477 first col mean 0.11682329326868057 all mean 0.11871324479579926
0.34990453720092773 0.34990447759628296
rl training, epoch2, iter0, batch1072/1133, batch loss:0.34990447759628296, Training time:7158.947536706924
batch reward last col mean 0.12372724711894989 first col mean 0.11891207844018936 all mean 0.1277870386838913
0.3566332459449768 0.3566332459449768
rl training, epoch2, iter0, batch1073/1133, batch loss:0.3566332459449768, Training time:7160.712899923325
batch reward last col mean 0.10458964109420776 first col mean 0.11040239036083221 all mean 0.10591799765825272
0.3413855731487274 0.3413855731487274
rl training, epoch2, iter0, batch1074/1133, batch loss:0.3413855731487274, Training time:7162.6069893836975
batch reward last col mean 0.12774880230426788 first col mean 0.1218402236700058 all mean 0.1181287169456482
0.34134742617607117 0.34134742617607117
rl training, epoch2, iter0, batch1075/1133, batch loss:0.34134742617607117, Training time:7164.1093118190765
batch reward last col mean 0.09530146420001984 first col mean 0.13490363955497742 all mean 0.10462018102407455
0.37885192036628723 0.37885192036628723
rl training, epoch2, iter0, batch1076/1133, batch loss:0.37885192036628723, Training time:7165.838009357452
batch reward last col mean 0.12793269753456116 first col mean 0.12350831180810928 all mean 0.12434599548578262
0.37364548444747925 0.37364548444747925
rl training, epoch2, iter0, batch1077/1133, batch loss:0.37364548444747925, Training time:7167.416447877884
batch reward last col mean 0.07665279507637024 first col mean 0.13792602717876434 all mean 0.08822479099035263
0.3285430669784546 0.3285430669784546
rl training, epoch2, iter0, batch1078/1133, batch loss:0.3285430669784546, Training time:7169.505905866623
batch reward last col mean 0.1010979488492012 first col mean 0.10029049217700958 all mean 0.108054518699646
0.3290708661079407 0.3290708661079407
rl training, epoch2, iter0, batch1079/1133, batch loss:0.3290708661079407, Training time:7171.386699914932
batch reward last col mean 0.11401514708995819 first col mean 0.11267676949501038 all mean 0.11642878502607346
0.36391735076904297 0.36391735076904297
rl training, epoch2, iter0, batch1080/1133, batch loss:0.36391735076904297, Training time:7173.032338857651
batch reward last col mean 0.11644107103347778 first col mean 0.12200959026813507 all mean 0.12251529097557068
0.3375835716724396 0.3375835716724396
rl training, epoch2, iter0, batch1081/1133, batch loss:0.3375835716724396, Training time:7174.998370170593
batch reward last col mean 0.08653534203767776 first col mean 0.11441555619239807 all mean 0.09674907475709915
0.30508947372436523 0.30508947372436523
rl training, epoch2, iter0, batch1082/1133, batch loss:0.30508947372436523, Training time:7176.920216321945
batch reward last col mean 0.12100494652986526 first col mean 0.11501458287239075 all mean 0.11851062625646591
0.4050160348415375 0.4050160348415375
rl training, epoch2, iter0, batch1083/1133, batch loss:0.4050160348415375, Training time:7178.3881046772
batch reward last col mean 0.11659755557775497 first col mean 0.11285270005464554 all mean 0.11495578289031982
0.34107649326324463 0.34107643365859985
rl training, epoch2, iter0, batch1084/1133, batch loss:0.34107643365859985, Training time:7179.985889911652
batch reward last col mean 0.14634668827056885 first col mean 0.11977525055408478 all mean 0.13544081151485443
0.3482827842235565 0.3482827842235565
rl training, epoch2, iter0, batch1085/1133, batch loss:0.3482827842235565, Training time:7181.742928743362
batch reward last col mean 0.10728804767131805 first col mean 0.10877880454063416 all mean 0.10543977469205856
0.2993153929710388 0.29931536316871643
rl training, epoch2, iter0, batch1086/1133, batch loss:0.29931536316871643, Training time:7183.368832826614
batch reward last col mean 0.08118273317813873 first col mean 0.11055120080709457 all mean 0.0872877910733223
0.2900817096233368 0.2900817096233368
rl training, epoch2, iter0, batch1087/1133, batch loss:0.2900817096233368, Training time:7185.140473365784
batch reward last col mean 0.10384416580200195 first col mean 0.11421088874340057 all mean 0.1078459694981575
0.29290908575057983 0.29290908575057983
rl training, epoch2, iter0, batch1088/1133, batch loss:0.29290908575057983, Training time:7186.7791204452515
batch reward last col mean 0.10075978934764862 first col mean 0.1171242892742157 all mean 0.11187665164470673
0.32367756962776184 0.32367756962776184
rl training, epoch2, iter0, batch1089/1133, batch loss:0.32367756962776184, Training time:7188.623395204544
batch reward last col mean 0.13383749127388 first col mean 0.10500315576791763 all mean 0.12530328333377838
0.3443247377872467 0.3443247377872467
rl training, epoch2, iter0, batch1090/1133, batch loss:0.3443247377872467, Training time:7190.438106536865
batch reward last col mean 0.10386443138122559 first col mean 0.1285514235496521 all mean 0.10610902309417725
0.2867349684238434 0.2867349684238434
rl training, epoch2, iter0, batch1091/1133, batch loss:0.2867349684238434, Training time:7192.365170717239
batch reward last col mean 0.11653314530849457 first col mean 0.10870225727558136 all mean 0.11376345902681351
0.3113565146923065 0.3113565146923065
rl training, epoch2, iter0, batch1092/1133, batch loss:0.3113565146923065, Training time:7194.784440994263
batch reward last col mean 0.11649201810359955 first col mean 0.1148885190486908 all mean 0.11106912046670914
0.3434394299983978 0.3434394299983978
rl training, epoch2, iter0, batch1093/1133, batch loss:0.3434394299983978, Training time:7196.823316574097
batch reward last col mean 0.11423640698194504 first col mean 0.1331331431865692 all mean 0.1193322166800499
0.3647460341453552 0.36474597454071045
rl training, epoch2, iter0, batch1094/1133, batch loss:0.36474597454071045, Training time:7198.810700416565
batch reward last col mean 0.13564927875995636 first col mean 0.1352568417787552 all mean 0.1294461339712143
0.3803836405277252 0.3803836405277252
rl training, epoch2, iter0, batch1095/1133, batch loss:0.3803836405277252, Training time:7200.707842350006
batch reward last col mean 0.08184296637773514 first col mean 0.1023922711610794 all mean 0.08992847055196762
0.31112539768218994 0.31112539768218994
rl training, epoch2, iter0, batch1096/1133, batch loss:0.31112539768218994, Training time:7202.586025953293
batch reward last col mean 0.11977589130401611 first col mean 0.10003479570150375 all mean 0.11987687647342682
0.34769001603126526 0.34768998622894287
rl training, epoch2, iter0, batch1097/1133, batch loss:0.34768998622894287, Training time:7204.906080961227
batch reward last col mean 0.10099928081035614 first col mean 0.12066841870546341 all mean 0.10583964735269547
0.32382798194885254 0.32382798194885254
rl training, epoch2, iter0, batch1098/1133, batch loss:0.32382798194885254, Training time:7206.978933095932
batch reward last col mean 0.12415362149477005 first col mean 0.10743383318185806 all mean 0.11520503461360931
0.3484748601913452 0.3484748601913452
rl training, epoch2, iter0, batch1099/1133, batch loss:0.3484748601913452, Training time:7209.006961107254
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.555146072017126 Time: 98.41066527366638 s
loss of true 0.24654152102945973 loss of gen 0.18977481885652886 loss of other 0.11882973245007215 first score 0.08442381024360657
batch reward last col mean 0.11471852660179138 first col mean 0.12396802753210068 all mean 0.1110890731215477
0.35441726446151733 0.35441726446151733
rl training, epoch2, iter0, batch1100/1133, batch loss:0.35441726446151733, Training time:7309.583455324173
batch reward last col mean 0.11519687622785568 first col mean 0.12074015289545059 all mean 0.11262936145067215
0.3219228684902191 0.3219228684902191
rl training, epoch2, iter0, batch1101/1133, batch loss:0.3219228684902191, Training time:7311.969032526016
batch reward last col mean 0.1264425814151764 first col mean 0.11923860013484955 all mean 0.11772856116294861
0.3430219888687134 0.3430219888687134
rl training, epoch2, iter0, batch1102/1133, batch loss:0.3430219888687134, Training time:7313.4963092803955
batch reward last col mean 0.12822440266609192 first col mean 0.09688833355903625 all mean 0.12292215973138809
0.35314756631851196 0.35314756631851196
rl training, epoch2, iter0, batch1103/1133, batch loss:0.35314756631851196, Training time:7315.442521572113
batch reward last col mean 0.09193634986877441 first col mean 0.11380419135093689 all mean 0.09735914319753647
0.32040339708328247 0.32040339708328247
rl training, epoch2, iter0, batch1104/1133, batch loss:0.32040339708328247, Training time:7316.91356086731
batch reward last col mean 0.10942868143320084 first col mean 0.10183160752058029 all mean 0.11095969378948212
0.2946508228778839 0.2946508228778839
rl training, epoch2, iter0, batch1105/1133, batch loss:0.2946508228778839, Training time:7319.0578763484955
batch reward last col mean 0.07605947554111481 first col mean 0.12219852209091187 all mean 0.08839614689350128
0.309261292219162 0.3092612624168396
rl training, epoch2, iter0, batch1106/1133, batch loss:0.3092612624168396, Training time:7320.932017803192
batch reward last col mean 0.10039404034614563 first col mean 0.11292578279972076 all mean 0.10216229408979416
0.31836989521980286 0.31836989521980286
rl training, epoch2, iter0, batch1107/1133, batch loss:0.31836989521980286, Training time:7322.807921409607
batch reward last col mean 0.11571233719587326 first col mean 0.09992522746324539 all mean 0.11254604905843735
0.32578346133232117 0.32578346133232117
rl training, epoch2, iter0, batch1108/1133, batch loss:0.32578346133232117, Training time:7324.362691402435
batch reward last col mean 0.11340764909982681 first col mean 0.10252290964126587 all mean 0.11074677854776382
0.3814936578273773 0.3814936578273773
rl training, epoch2, iter0, batch1109/1133, batch loss:0.3814936578273773, Training time:7326.008051633835
batch reward last col mean 0.10607551038265228 first col mean 0.11848984658718109 all mean 0.11231344938278198
0.31104743480682373 0.31104743480682373
rl training, epoch2, iter0, batch1110/1133, batch loss:0.31104743480682373, Training time:7327.691866397858
batch reward last col mean 0.10767676681280136 first col mean 0.10606934875249863 all mean 0.10628344118595123
0.336141973733902 0.336141973733902
rl training, epoch2, iter0, batch1111/1133, batch loss:0.336141973733902, Training time:7329.436585903168
batch reward last col mean 0.10653406381607056 first col mean 0.1199980229139328 all mean 0.10331405699253082
0.3197261691093445 0.3197261691093445
rl training, epoch2, iter0, batch1112/1133, batch loss:0.3197261691093445, Training time:7330.985976934433
batch reward last col mean 0.11207223683595657 first col mean 0.10880035161972046 all mean 0.10991638153791428
0.29380562901496887 0.29380562901496887
rl training, epoch2, iter0, batch1113/1133, batch loss:0.29380562901496887, Training time:7333.0967669487
batch reward last col mean 0.12074822187423706 first col mean 0.11534437537193298 all mean 0.11934389173984528
0.32665055990219116 0.32665055990219116
rl training, epoch2, iter0, batch1114/1133, batch loss:0.32665055990219116, Training time:7335.265303611755
batch reward last col mean 0.10737091302871704 first col mean 0.0998605415225029 all mean 0.11043605208396912
0.34351488947868347 0.3435148298740387
rl training, epoch2, iter0, batch1115/1133, batch loss:0.3435148298740387, Training time:7337.111304998398
batch reward last col mean 0.11357170343399048 first col mean 0.10321881622076035 all mean 0.11131208389997482
0.32310277223587036 0.32310277223587036
rl training, epoch2, iter0, batch1116/1133, batch loss:0.32310277223587036, Training time:7339.090660572052
batch reward last col mean 0.10538166761398315 first col mean 0.10860118269920349 all mean 0.10937043279409409
0.32247576117515564 0.32247576117515564
rl training, epoch2, iter0, batch1117/1133, batch loss:0.32247576117515564, Training time:7341.505073785782
batch reward last col mean 0.1109062060713768 first col mean 0.12325727939605713 all mean 0.11295009404420853
0.3641633689403534 0.3641633987426758
rl training, epoch2, iter0, batch1118/1133, batch loss:0.3641633987426758, Training time:7343.160152196884
batch reward last col mean 0.1317903697490692 first col mean 0.10654081404209137 all mean 0.13158759474754333
0.35375717282295227 0.35375717282295227
rl training, epoch2, iter0, batch1119/1133, batch loss:0.35375717282295227, Training time:7344.667256593704
batch reward last col mean 0.13814789056777954 first col mean 0.11739243566989899 all mean 0.132319837808609
0.38558781147003174 0.38558781147003174
rl training, epoch2, iter0, batch1120/1133, batch loss:0.38558781147003174, Training time:7346.576154470444
batch reward last col mean 0.10521902143955231 first col mean 0.13332286477088928 all mean 0.10905788838863373
0.3059127926826477 0.3059127926826477
rl training, epoch2, iter0, batch1121/1133, batch loss:0.3059127926826477, Training time:7348.477067708969
batch reward last col mean 0.11636937409639359 first col mean 0.1073351502418518 all mean 0.10853757709264755
0.2977396845817566 0.2977396845817566
rl training, epoch2, iter0, batch1122/1133, batch loss:0.2977396845817566, Training time:7350.017969608307
batch reward last col mean 0.13660365343093872 first col mean 0.13637293875217438 all mean 0.13189369440078735
0.3800261914730072 0.3800261616706848
rl training, epoch2, iter0, batch1123/1133, batch loss:0.3800261616706848, Training time:7351.696492671967
batch reward last col mean 0.10908687859773636 first col mean 0.09726087749004364 all mean 0.11122389137744904
0.3849800229072571 0.3849800229072571
rl training, epoch2, iter0, batch1124/1133, batch loss:0.3849800229072571, Training time:7353.513294935226
batch reward last col mean 0.12750019133090973 first col mean 0.1229560524225235 all mean 0.1275498867034912
0.3500150144100189 0.3500150144100189
rl training, epoch2, iter0, batch1125/1133, batch loss:0.3500150144100189, Training time:7355.172528505325
batch reward last col mean 0.11530525982379913 first col mean 0.11148975789546967 all mean 0.11217059195041656
0.3456376791000366 0.34563764929771423
rl training, epoch2, iter0, batch1126/1133, batch loss:0.34563764929771423, Training time:7356.63528418541
batch reward last col mean 0.11398184299468994 first col mean 0.10366149991750717 all mean 0.11376496404409409
0.33333227038383484 0.33333227038383484
rl training, epoch2, iter0, batch1127/1133, batch loss:0.33333227038383484, Training time:7358.6518034935
batch reward last col mean 0.10134044289588928 first col mean 0.13013483583927155 all mean 0.10270282626152039
0.31890758872032166 0.31890758872032166
rl training, epoch2, iter0, batch1128/1133, batch loss:0.31890758872032166, Training time:7360.08312869072
batch reward last col mean 0.10899175703525543 first col mean 0.11920008063316345 all mean 0.11088067293167114
0.33551332354545593 0.33551332354545593
rl training, epoch2, iter0, batch1129/1133, batch loss:0.33551332354545593, Training time:7361.413595914841
batch reward last col mean 0.1333598792552948 first col mean 0.12802156805992126 all mean 0.12977266311645508
0.33729636669158936 0.33729636669158936
rl training, epoch2, iter0, batch1130/1133, batch loss:0.33729636669158936, Training time:7362.898955821991
batch reward last col mean 0.08689969778060913 first col mean 0.10755456984043121 all mean 0.09418132901191711
0.287699431180954 0.28769946098327637
rl training, epoch2, iter0, batch1131/1133, batch loss:0.28769946098327637, Training time:7364.707144737244
batch reward last col mean 0.11088205128908157 first col mean 0.10677208751440048 all mean 0.10982003062963486
0.3334013819694519 0.3334013521671295
rl training, epoch2, iter0, batch1132/1133, batch loss:0.3334013521671295, Training time:7366.222732305527
rl training, epoch 2, iter 0, loss:0.3498524766076695, Training time:7366.222946166992 
rl epoch 2, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.140720728110762 Time: 126.80208945274353 s
rl epoch 2, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5501967910266196 Time: 100.11785006523132 s
loss of true 0.2411024429870725 loss of gen 0.19512886337653157 loss of other 0.11396548494907048 first score 0.1068028062582016
rl epoch 3, begin RL for generator...
batch reward last col mean 0.09704966098070145 first col mean 0.12215597927570343 all mean 0.10243675112724304
0.33912351727485657 0.33912351727485657
rl training, epoch3, iter0, batch0/1133, batch loss:0.33912351727485657, Training time:7595.784120798111
batch reward last col mean 0.0866282656788826 first col mean 0.1163681149482727 all mean 0.09876466542482376
0.3226848840713501 0.3226848840713501
rl training, epoch3, iter0, batch1/1133, batch loss:0.3226848840713501, Training time:7598.071531057358
batch reward last col mean 0.12727662920951843 first col mean 0.10911133885383606 all mean 0.12608370184898376
0.4215599000453949 0.4215598404407501
rl training, epoch3, iter0, batch2/1133, batch loss:0.4215598404407501, Training time:7601.464669704437
batch reward last col mean 0.10584563761949539 first col mean 0.1381646692752838 all mean 0.10797630250453949
0.34527042508125305 0.34527039527893066
rl training, epoch3, iter0, batch3/1133, batch loss:0.34527039527893066, Training time:7604.361832618713
batch reward last col mean 0.11056578159332275 first col mean 0.12035542726516724 all mean 0.1196100264787674
0.3697938024997711 0.3697938024997711
rl training, epoch3, iter0, batch4/1133, batch loss:0.3697938024997711, Training time:7606.514545917511
batch reward last col mean 0.09943124651908875 first col mean 0.12597039341926575 all mean 0.10320846736431122
0.33497148752212524 0.33497148752212524
rl training, epoch3, iter0, batch5/1133, batch loss:0.33497148752212524, Training time:7608.756880760193
batch reward last col mean 0.10500504821538925 first col mean 0.11824013292789459 all mean 0.10434688627719879
0.2926275432109833 0.2926275432109833
rl training, epoch3, iter0, batch6/1133, batch loss:0.2926275432109833, Training time:7611.056654930115
batch reward last col mean 0.11721447855234146 first col mean 0.12088246643543243 all mean 0.11651170253753662
0.34736013412475586 0.34736010432243347
rl training, epoch3, iter0, batch7/1133, batch loss:0.34736010432243347, Training time:7613.17578125
batch reward last col mean 0.09952053427696228 first col mean 0.11812939494848251 all mean 0.11077455431222916
0.35272878408432007 0.35272878408432007
rl training, epoch3, iter0, batch8/1133, batch loss:0.35272878408432007, Training time:7615.115808725357
batch reward last col mean 0.11455570161342621 first col mean 0.09647281467914581 all mean 0.11824465543031693
0.3692587912082672 0.3692587614059448
rl training, epoch3, iter0, batch9/1133, batch loss:0.3692587614059448, Training time:7617.291622161865
batch reward last col mean 0.13706442713737488 first col mean 0.13447849452495575 all mean 0.13672737777233124
0.3686365485191345 0.3686365485191345
rl training, epoch3, iter0, batch10/1133, batch loss:0.3686365485191345, Training time:7620.954365730286
batch reward last col mean 0.15514551103115082 first col mean 0.11574772000312805 all mean 0.14442266523838043
0.34473758935928345 0.34473758935928345
rl training, epoch3, iter0, batch11/1133, batch loss:0.34473758935928345, Training time:7623.475166559219
batch reward last col mean 0.11078276485204697 first col mean 0.11624760180711746 all mean 0.11615827679634094
0.3464014232158661 0.3464013934135437
rl training, epoch3, iter0, batch12/1133, batch loss:0.3464013934135437, Training time:7626.415591239929
batch reward last col mean 0.12972767651081085 first col mean 0.12221783399581909 all mean 0.12658953666687012
0.33533528447151184 0.33533525466918945
rl training, epoch3, iter0, batch13/1133, batch loss:0.33533525466918945, Training time:7630.441990852356
batch reward last col mean 0.10880708694458008 first col mean 0.11188836395740509 all mean 0.10806365311145782
0.3107306659221649 0.3107306957244873
rl training, epoch3, iter0, batch14/1133, batch loss:0.3107306957244873, Training time:7633.835111618042
batch reward last col mean 0.110793337225914 first col mean 0.140870600938797 all mean 0.11591054499149323
0.3676108419895172 0.3676108419895172
rl training, epoch3, iter0, batch15/1133, batch loss:0.3676108419895172, Training time:7636.224076271057
batch reward last col mean 0.10721409320831299 first col mean 0.11134686321020126 all mean 0.11157748848199844
0.3356606662273407 0.3356606662273407
rl training, epoch3, iter0, batch16/1133, batch loss:0.3356606662273407, Training time:7639.139760971069
batch reward last col mean 0.06498217582702637 first col mean 0.11245116591453552 all mean 0.07875779271125793
0.34942442178726196 0.34942442178726196
rl training, epoch3, iter0, batch17/1133, batch loss:0.34942442178726196, Training time:7643.166499614716
batch reward last col mean 0.14980928599834442 first col mean 0.130503311753273 all mean 0.14343887567520142
0.3541448712348938 0.3541448712348938
rl training, epoch3, iter0, batch18/1133, batch loss:0.3541448712348938, Training time:7645.641325235367
batch reward last col mean 0.10910897701978683 first col mean 0.12913790345191956 all mean 0.11232445389032364
0.3826964795589447 0.3826964795589447
rl training, epoch3, iter0, batch19/1133, batch loss:0.3826964795589447, Training time:7649.172390460968
batch reward last col mean 0.14489789307117462 first col mean 0.1320851892232895 all mean 0.1398354023694992
0.40550053119659424 0.40550053119659424
rl training, epoch3, iter0, batch20/1133, batch loss:0.40550053119659424, Training time:7651.944815158844
batch reward last col mean 0.0882081687450409 first col mean 0.09308752417564392 all mean 0.09686541557312012
0.3112325370311737 0.3112325370311737
rl training, epoch3, iter0, batch21/1133, batch loss:0.3112325370311737, Training time:7654.500849246979
batch reward last col mean 0.1017264574766159 first col mean 0.13691446185112 all mean 0.10801151394844055
0.3282512128353119 0.3282512128353119
rl training, epoch3, iter0, batch22/1133, batch loss:0.3282512128353119, Training time:7657.528944969177
batch reward last col mean 0.09190518409013748 first col mean 0.09971275925636292 all mean 0.10256379097700119
0.3222425878047943 0.3222425878047943
rl training, epoch3, iter0, batch23/1133, batch loss:0.3222425878047943, Training time:7659.823331832886
batch reward last col mean 0.11607437580823898 first col mean 0.11626112461090088 all mean 0.12179675698280334
0.36099857091903687 0.36099857091903687
rl training, epoch3, iter0, batch24/1133, batch loss:0.36099857091903687, Training time:7662.943560838699
batch reward last col mean 0.1470780223608017 first col mean 0.11671054363250732 all mean 0.1433648318052292
0.4023398160934448 0.4023398458957672
rl training, epoch3, iter0, batch25/1133, batch loss:0.4023398458957672, Training time:7666.659482717514
batch reward last col mean 0.12828369438648224 first col mean 0.12190887331962585 all mean 0.12710268795490265
0.3740043342113495 0.3740043342113495
rl training, epoch3, iter0, batch26/1133, batch loss:0.3740043342113495, Training time:7669.256694793701
batch reward last col mean 0.1231875866651535 first col mean 0.11521325260400772 all mean 0.12504270672798157
0.3031473755836487 0.3031473755836487
rl training, epoch3, iter0, batch27/1133, batch loss:0.3031473755836487, Training time:7671.592321634293
batch reward last col mean 0.10557104647159576 first col mean 0.12646591663360596 all mean 0.10605403035879135
0.3325381875038147 0.3325381875038147
rl training, epoch3, iter0, batch28/1133, batch loss:0.3325381875038147, Training time:7674.127116918564
batch reward last col mean 0.09480087459087372 first col mean 0.1170632541179657 all mean 0.10360599309206009
0.3080984652042389 0.3080984652042389
rl training, epoch3, iter0, batch29/1133, batch loss:0.3080984652042389, Training time:7676.935987949371
batch reward last col mean 0.14338263869285583 first col mean 0.11947843432426453 all mean 0.14513222873210907
0.38975319266319275 0.38975316286087036
rl training, epoch3, iter0, batch30/1133, batch loss:0.38975316286087036, Training time:7679.212105035782
batch reward last col mean 0.10137759149074554 first col mean 0.13940761983394623 all mean 0.1079457476735115
0.33169659972190857 0.33169659972190857
rl training, epoch3, iter0, batch31/1133, batch loss:0.33169659972190857, Training time:7682.459549665451
batch reward last col mean 0.12640772759914398 first col mean 0.11143931746482849 all mean 0.1191481351852417
0.35958969593048096 0.35958969593048096
rl training, epoch3, iter0, batch32/1133, batch loss:0.35958969593048096, Training time:7685.49395775795
batch reward last col mean 0.0924498438835144 first col mean 0.12833088636398315 all mean 0.10416395962238312
0.3742794692516327 0.3742794692516327
rl training, epoch3, iter0, batch33/1133, batch loss:0.3742794692516327, Training time:7687.679419517517
batch reward last col mean 0.09191576391458511 first col mean 0.11662972718477249 all mean 0.09634862840175629
0.3379501402378082 0.3379501402378082
rl training, epoch3, iter0, batch34/1133, batch loss:0.3379501402378082, Training time:7690.947663784027
batch reward last col mean 0.14625386893749237 first col mean 0.1224580630660057 all mean 0.13232888281345367
0.3220113217830658 0.3220113217830658
rl training, epoch3, iter0, batch35/1133, batch loss:0.3220113217830658, Training time:7693.180194377899
batch reward last col mean 0.12188462913036346 first col mean 0.13234102725982666 all mean 0.12002763897180557
0.3430769443511963 0.3430769443511963
rl training, epoch3, iter0, batch36/1133, batch loss:0.3430769443511963, Training time:7696.596121788025
batch reward last col mean 0.09414160251617432 first col mean 0.13858243823051453 all mean 0.10119027644395828
0.3520214855670929 0.3520214855670929
rl training, epoch3, iter0, batch37/1133, batch loss:0.3520214855670929, Training time:7699.461579799652
batch reward last col mean 0.12107021361589432 first col mean 0.1334470808506012 all mean 0.11228666454553604
0.32528823614120483 0.32528823614120483
rl training, epoch3, iter0, batch38/1133, batch loss:0.32528823614120483, Training time:7702.02695441246
batch reward last col mean 0.11944030970335007 first col mean 0.12237361818552017 all mean 0.12077203392982483
0.33913740515708923 0.33913740515708923
rl training, epoch3, iter0, batch39/1133, batch loss:0.33913740515708923, Training time:7704.850830554962
batch reward last col mean 0.11546343564987183 first col mean 0.11820272356271744 all mean 0.12305901199579239
0.3499388098716736 0.3499388098716736
rl training, epoch3, iter0, batch40/1133, batch loss:0.3499388098716736, Training time:7706.957222700119
batch reward last col mean 0.12965644896030426 first col mean 0.13269226253032684 all mean 0.1296905130147934
0.3629961907863617 0.3629961907863617
rl training, epoch3, iter0, batch41/1133, batch loss:0.3629961907863617, Training time:7709.6045117378235
batch reward last col mean 0.1104666143655777 first col mean 0.13633975386619568 all mean 0.11711549013853073
0.38680192828178406 0.38680189847946167
rl training, epoch3, iter0, batch42/1133, batch loss:0.38680189847946167, Training time:7712.369481086731
batch reward last col mean 0.1362675279378891 first col mean 0.13477712869644165 all mean 0.13076016306877136
0.3518216609954834 0.3518216609954834
rl training, epoch3, iter0, batch43/1133, batch loss:0.3518216609954834, Training time:7715.04013800621
batch reward last col mean 0.09178250283002853 first col mean 0.12712153792381287 all mean 0.10158742964267731
0.32607901096343994 0.32607901096343994
rl training, epoch3, iter0, batch44/1133, batch loss:0.32607901096343994, Training time:7717.473566293716
batch reward last col mean 0.1335025280714035 first col mean 0.11658351123332977 all mean 0.13223105669021606
0.3688524067401886 0.3688524067401886
rl training, epoch3, iter0, batch45/1133, batch loss:0.3688524067401886, Training time:7719.581538677216
batch reward last col mean 0.11592366546392441 first col mean 0.1221015602350235 all mean 0.11842459440231323
0.31794843077659607 0.31794843077659607
rl training, epoch3, iter0, batch46/1133, batch loss:0.31794843077659607, Training time:7721.8013389110565
batch reward last col mean 0.14977656304836273 first col mean 0.14006304740905762 all mean 0.14296995103359222
0.3559262752532959 0.3559262752532959
rl training, epoch3, iter0, batch47/1133, batch loss:0.3559262752532959, Training time:7724.2781302928925
batch reward last col mean 0.1044820249080658 first col mean 0.11933939158916473 all mean 0.10653653740882874
0.31233280897140503 0.31233280897140503
rl training, epoch3, iter0, batch48/1133, batch loss:0.31233280897140503, Training time:7726.308571577072
batch reward last col mean 0.12177031487226486 first col mean 0.1400710940361023 all mean 0.12320220470428467
0.3617580235004425 0.3617580235004425
rl training, epoch3, iter0, batch49/1133, batch loss:0.3617580235004425, Training time:7728.604811906815
batch reward last col mean 0.10705450177192688 first col mean 0.11970088630914688 all mean 0.11023274064064026
0.35856834053993225 0.35856831073760986
rl training, epoch3, iter0, batch50/1133, batch loss:0.35856831073760986, Training time:7731.486119747162
batch reward last col mean 0.11029595136642456 first col mean 0.10092419385910034 all mean 0.1175677552819252
0.3886224329471588 0.38862237334251404
rl training, epoch3, iter0, batch51/1133, batch loss:0.38862237334251404, Training time:7733.718768596649
batch reward last col mean 0.10619406402111053 first col mean 0.13028524816036224 all mean 0.10650473833084106
0.2792460322380066 0.2792460322380066
rl training, epoch3, iter0, batch52/1133, batch loss:0.2792460322380066, Training time:7736.321581602097
batch reward last col mean 0.10703885555267334 first col mean 0.12784482538700104 all mean 0.11144206672906876
0.35169628262519836 0.35169628262519836
rl training, epoch3, iter0, batch53/1133, batch loss:0.35169628262519836, Training time:7738.5689561367035
batch reward last col mean 0.11452893912792206 first col mean 0.13181334733963013 all mean 0.10962475836277008
0.33632519841194153 0.33632519841194153
rl training, epoch3, iter0, batch54/1133, batch loss:0.33632519841194153, Training time:7741.317927122116
batch reward last col mean 0.1283700317144394 first col mean 0.12355712801218033 all mean 0.129134401679039
0.36386430263519287 0.36386430263519287
rl training, epoch3, iter0, batch55/1133, batch loss:0.36386430263519287, Training time:7744.718046426773
batch reward last col mean 0.1135813444852829 first col mean 0.1385606974363327 all mean 0.11511409282684326
0.351704478263855 0.3517044484615326
rl training, epoch3, iter0, batch56/1133, batch loss:0.3517044484615326, Training time:7747.2277500629425
batch reward last col mean 0.1152200922369957 first col mean 0.1324004977941513 all mean 0.11680930852890015
0.3851282596588135 0.3851282596588135
rl training, epoch3, iter0, batch57/1133, batch loss:0.3851282596588135, Training time:7749.562022924423
batch reward last col mean 0.13364991545677185 first col mean 0.1301768571138382 all mean 0.1337573528289795
0.3471449315547943 0.3471449315547943
rl training, epoch3, iter0, batch58/1133, batch loss:0.3471449315547943, Training time:7752.497145414352
batch reward last col mean 0.15323802828788757 first col mean 0.12572306394577026 all mean 0.14212408661842346
0.39106857776641846 0.39106857776641846
rl training, epoch3, iter0, batch59/1133, batch loss:0.39106857776641846, Training time:7755.235315799713
batch reward last col mean 0.13222083449363708 first col mean 0.11718692630529404 all mean 0.12918826937675476
0.4011661410331726 0.4011661410331726
rl training, epoch3, iter0, batch60/1133, batch loss:0.4011661410331726, Training time:7757.511438131332
batch reward last col mean 0.10045018047094345 first col mean 0.11856941878795624 all mean 0.10604441165924072
0.2679916322231293 0.2679916322231293
rl training, epoch3, iter0, batch61/1133, batch loss:0.2679916322231293, Training time:7759.8920748233795
batch reward last col mean 0.12805400788784027 first col mean 0.11587969958782196 all mean 0.1357136368751526
0.4218635559082031 0.42186352610588074
rl training, epoch3, iter0, batch62/1133, batch loss:0.42186352610588074, Training time:7762.9492292404175
batch reward last col mean 0.13121479749679565 first col mean 0.11906623840332031 all mean 0.13124129176139832
0.3652091324329376 0.3652091324329376
rl training, epoch3, iter0, batch63/1133, batch loss:0.3652091324329376, Training time:7765.260920763016
batch reward last col mean 0.1267091929912567 first col mean 0.13910545408725739 all mean 0.13018091022968292
0.3738380968570709 0.37383806705474854
rl training, epoch3, iter0, batch64/1133, batch loss:0.37383806705474854, Training time:7767.860086917877
batch reward last col mean 0.11526215076446533 first col mean 0.13671225309371948 all mean 0.1181376725435257
0.33753377199172974 0.33753377199172974
rl training, epoch3, iter0, batch65/1133, batch loss:0.33753377199172974, Training time:7770.548358201981
batch reward last col mean 0.1535036265850067 first col mean 0.12071298062801361 all mean 0.14519858360290527
0.3928639590740204 0.3928639590740204
rl training, epoch3, iter0, batch66/1133, batch loss:0.3928639590740204, Training time:7772.980394363403
batch reward last col mean 0.09669674932956696 first col mean 0.10667914152145386 all mean 0.09937530010938644
0.2922327518463135 0.2922327518463135
rl training, epoch3, iter0, batch67/1133, batch loss:0.2922327518463135, Training time:7776.3829934597015
batch reward last col mean 0.14203128218650818 first col mean 0.12962551414966583 all mean 0.13681405782699585
0.3460730314254761 0.3460730314254761
rl training, epoch3, iter0, batch68/1133, batch loss:0.3460730314254761, Training time:7778.532765865326
batch reward last col mean 0.1384728103876114 first col mean 0.12946979701519012 all mean 0.1266425997018814
0.37488916516304016 0.37488916516304016
rl training, epoch3, iter0, batch69/1133, batch loss:0.37488916516304016, Training time:7780.661049365997
batch reward last col mean 0.11211209744215012 first col mean 0.1172143965959549 all mean 0.11600420624017715
0.34640875458717346 0.34640875458717346
rl training, epoch3, iter0, batch70/1133, batch loss:0.34640875458717346, Training time:7782.818743944168
batch reward last col mean 0.16442808508872986 first col mean 0.11748391389846802 all mean 0.14966818690299988
0.3940137028694153 0.3940137028694153
rl training, epoch3, iter0, batch71/1133, batch loss:0.3940137028694153, Training time:7785.105807065964
batch reward last col mean 0.12211495637893677 first col mean 0.1167735755443573 all mean 0.12089996784925461
0.3568873107433319 0.3568873703479767
rl training, epoch3, iter0, batch72/1133, batch loss:0.3568873703479767, Training time:7787.288574695587
batch reward last col mean 0.08834077417850494 first col mean 0.1297849416732788 all mean 0.09438114613294601
0.3059375584125519 0.3059375584125519
rl training, epoch3, iter0, batch73/1133, batch loss:0.3059375584125519, Training time:7790.072035551071
batch reward last col mean 0.11641661822795868 first col mean 0.11709423363208771 all mean 0.12781508266925812
0.3203745186328888 0.3203745186328888
rl training, epoch3, iter0, batch74/1133, batch loss:0.3203745186328888, Training time:7791.784289121628
batch reward last col mean 0.1271827220916748 first col mean 0.11352675408124924 all mean 0.1267746090888977
0.3878629207611084 0.3878629207611084
rl training, epoch3, iter0, batch75/1133, batch loss:0.3878629207611084, Training time:7794.304379463196
batch reward last col mean 0.08178134262561798 first col mean 0.12585963308811188 all mean 0.09122461080551147
0.36497172713279724 0.36497172713279724
rl training, epoch3, iter0, batch76/1133, batch loss:0.36497172713279724, Training time:7797.244580745697
batch reward last col mean 0.14367862045764923 first col mean 0.11621560156345367 all mean 0.13273286819458008
0.40306541323661804 0.40306541323661804
rl training, epoch3, iter0, batch77/1133, batch loss:0.40306541323661804, Training time:7799.733794927597
batch reward last col mean 0.11746248602867126 first col mean 0.1399134397506714 all mean 0.12526337802410126
0.3260948359966278 0.3260948359966278
rl training, epoch3, iter0, batch78/1133, batch loss:0.3260948359966278, Training time:7802.545231819153
batch reward last col mean 0.09094847738742828 first col mean 0.13243837654590607 all mean 0.10011869668960571
0.29634854197502136 0.29634857177734375
rl training, epoch3, iter0, batch79/1133, batch loss:0.29634857177734375, Training time:7805.133508205414
batch reward last col mean 0.09803652763366699 first col mean 0.1367870718240738 all mean 0.1085783988237381
0.36704757809638977 0.36704757809638977
rl training, epoch3, iter0, batch80/1133, batch loss:0.36704757809638977, Training time:7807.834894895554
batch reward last col mean 0.1176576241850853 first col mean 0.12518975138664246 all mean 0.1273486316204071
0.4351342022418976 0.4351342022418976
rl training, epoch3, iter0, batch81/1133, batch loss:0.4351342022418976, Training time:7810.807955980301
batch reward last col mean 0.13227024674415588 first col mean 0.12982864677906036 all mean 0.1313667893409729
0.34121930599212646 0.34121930599212646
rl training, epoch3, iter0, batch82/1133, batch loss:0.34121930599212646, Training time:7813.59922337532
batch reward last col mean 0.11958611756563187 first col mean 0.11627449095249176 all mean 0.12691724300384521
0.33297598361968994 0.33297598361968994
rl training, epoch3, iter0, batch83/1133, batch loss:0.33297598361968994, Training time:7815.84698009491
batch reward last col mean 0.12556686997413635 first col mean 0.12242306768894196 all mean 0.1312410682439804
0.37055155634880066 0.37055152654647827
rl training, epoch3, iter0, batch84/1133, batch loss:0.37055152654647827, Training time:7818.311171531677
batch reward last col mean 0.10482312738895416 first col mean 0.1153092235326767 all mean 0.10852976888418198
0.3258858919143677 0.3258858919143677
rl training, epoch3, iter0, batch85/1133, batch loss:0.3258858919143677, Training time:7822.936100721359
batch reward last col mean 0.13871930539608002 first col mean 0.1396496742963791 all mean 0.1395331472158432
0.40476617217063904 0.40476617217063904
rl training, epoch3, iter0, batch86/1133, batch loss:0.40476617217063904, Training time:7826.951069831848
batch reward last col mean 0.12825210392475128 first col mean 0.11609846353530884 all mean 0.12565858662128448
0.3319588601589203 0.3319588303565979
rl training, epoch3, iter0, batch87/1133, batch loss:0.3319588303565979, Training time:7829.321593284607
batch reward last col mean 0.1468663513660431 first col mean 0.12975937128067017 all mean 0.1438729166984558
0.3713676631450653 0.3713676631450653
rl training, epoch3, iter0, batch88/1133, batch loss:0.3713676631450653, Training time:7834.5000076293945
batch reward last col mean 0.14275403320789337 first col mean 0.11626996845006943 all mean 0.13548323512077332
0.4033185541629791 0.4033185541629791
rl training, epoch3, iter0, batch89/1133, batch loss:0.4033185541629791, Training time:7837.160987138748
batch reward last col mean 0.10266411304473877 first col mean 0.13099388778209686 all mean 0.11116869747638702
0.3947408199310303 0.3947408199310303
rl training, epoch3, iter0, batch90/1133, batch loss:0.3947408199310303, Training time:7839.563939332962
batch reward last col mean 0.12501129508018494 first col mean 0.1372116655111313 all mean 0.12321674078702927
0.33572253584861755 0.33572253584861755
rl training, epoch3, iter0, batch91/1133, batch loss:0.33572253584861755, Training time:7841.964787244797
batch reward last col mean 0.10348911583423615 first col mean 0.13959893584251404 all mean 0.11538258194923401
0.3548913598060608 0.3548913598060608
rl training, epoch3, iter0, batch92/1133, batch loss:0.3548913598060608, Training time:7843.788098335266
batch reward last col mean 0.16606181859970093 first col mean 0.1402026265859604 all mean 0.1570899784564972
0.40162307024002075 0.40162307024002075
rl training, epoch3, iter0, batch93/1133, batch loss:0.40162307024002075, Training time:7845.588614940643
batch reward last col mean 0.16009248793125153 first col mean 0.14107343554496765 all mean 0.14371000230312347
0.370116263628006 0.370116263628006
rl training, epoch3, iter0, batch94/1133, batch loss:0.370116263628006, Training time:7847.96383190155
batch reward last col mean 0.11224407702684402 first col mean 0.12109370529651642 all mean 0.12479441612958908
0.3583802580833435 0.3583802580833435
rl training, epoch3, iter0, batch95/1133, batch loss:0.3583802580833435, Training time:7850.049368619919
batch reward last col mean 0.13209669291973114 first col mean 0.11092352122068405 all mean 0.12865053117275238
0.35265374183654785 0.35265374183654785
rl training, epoch3, iter0, batch96/1133, batch loss:0.35265374183654785, Training time:7852.10107088089
batch reward last col mean 0.11272589862346649 first col mean 0.12780407071113586 all mean 0.11248869448900223
0.3319295346736908 0.3319295346736908
rl training, epoch3, iter0, batch97/1133, batch loss:0.3319295346736908, Training time:7854.049512147903
batch reward last col mean 0.1334315985441208 first col mean 0.11308220028877258 all mean 0.12464696913957596
0.32489192485809326 0.32489192485809326
rl training, epoch3, iter0, batch98/1133, batch loss:0.32489192485809326, Training time:7856.213527202606
batch reward last col mean 0.1175810694694519 first col mean 0.14701904356479645 all mean 0.1247234046459198
0.38755133748054504 0.38755133748054504
rl training, epoch3, iter0, batch99/1133, batch loss:0.38755133748054504, Training time:7858.678520441055
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5473567740325894 Time: 103.04947185516357 s
loss of true 0.24195109222278274 loss of gen 0.19174821615639978 loss of other 0.11365746564025492 first score 0.10611432790756226
batch reward last col mean 0.09879354387521744 first col mean 0.12881581485271454 all mean 0.10386545211076736
0.30582278966903687 0.30582278966903687
rl training, epoch3, iter0, batch100/1133, batch loss:0.30582278966903687, Training time:7964.977869749069
batch reward last col mean 0.10106610506772995 first col mean 0.11411865055561066 all mean 0.10791000723838806
0.32718756794929504 0.32718756794929504
rl training, epoch3, iter0, batch101/1133, batch loss:0.32718756794929504, Training time:7967.524844646454
batch reward last col mean 0.12287095934152603 first col mean 0.115028515458107 all mean 0.1281965672969818
0.3824959099292755 0.3824959099292755
rl training, epoch3, iter0, batch102/1133, batch loss:0.3824959099292755, Training time:7969.222781181335
batch reward last col mean 0.1620405614376068 first col mean 0.11475782096385956 all mean 0.15515747666358948
0.36412012577056885 0.36412012577056885
rl training, epoch3, iter0, batch103/1133, batch loss:0.36412012577056885, Training time:7971.150018692017
batch reward last col mean 0.13473661243915558 first col mean 0.13667090237140656 all mean 0.14261192083358765
0.42979809641838074 0.42979809641838074
rl training, epoch3, iter0, batch104/1133, batch loss:0.42979809641838074, Training time:7973.527125597
batch reward last col mean 0.12702850997447968 first col mean 0.11619026958942413 all mean 0.12675917148590088
0.36265140771865845 0.36265140771865845
rl training, epoch3, iter0, batch105/1133, batch loss:0.36265140771865845, Training time:7975.554898738861
batch reward last col mean 0.1349894106388092 first col mean 0.13107052445411682 all mean 0.13616855442523956
0.3831305503845215 0.3831305503845215
rl training, epoch3, iter0, batch106/1133, batch loss:0.3831305503845215, Training time:7977.605729818344
batch reward last col mean 0.12861470878124237 first col mean 0.13685467839241028 all mean 0.1276608258485794
0.3461511731147766 0.3461511433124542
rl training, epoch3, iter0, batch107/1133, batch loss:0.3461511433124542, Training time:7980.309800386429
batch reward last col mean 0.13865971565246582 first col mean 0.11635973304510117 all mean 0.1281569004058838
0.34253013134002686 0.34253013134002686
rl training, epoch3, iter0, batch108/1133, batch loss:0.34253013134002686, Training time:7982.679954528809
batch reward last col mean 0.07242463529109955 first col mean 0.1401931494474411 all mean 0.08403570204973221
0.29543599486351013 0.29543599486351013
rl training, epoch3, iter0, batch109/1133, batch loss:0.29543599486351013, Training time:7985.35279250145
batch reward last col mean 0.1036132350564003 first col mean 0.11610319465398788 all mean 0.10704933106899261
0.34403350949287415 0.3440335690975189
rl training, epoch3, iter0, batch110/1133, batch loss:0.3440335690975189, Training time:7987.548020601273
batch reward last col mean 0.15703320503234863 first col mean 0.1178261935710907 all mean 0.14174945652484894
0.34651491045951843 0.34651491045951843
rl training, epoch3, iter0, batch111/1133, batch loss:0.34651491045951843, Training time:7989.741479635239
batch reward last col mean 0.1368204653263092 first col mean 0.12291652709245682 all mean 0.13256072998046875
0.334605872631073 0.334605872631073
rl training, epoch3, iter0, batch112/1133, batch loss:0.334605872631073, Training time:7991.738532543182
batch reward last col mean 0.12087278068065643 first col mean 0.13687735795974731 all mean 0.1262584775686264
0.3480736315250397 0.3480736315250397
rl training, epoch3, iter0, batch113/1133, batch loss:0.3480736315250397, Training time:7993.687528371811
batch reward last col mean 0.14327523112297058 first col mean 0.11750718951225281 all mean 0.13842880725860596
0.34968602657318115 0.34968602657318115
rl training, epoch3, iter0, batch114/1133, batch loss:0.34968602657318115, Training time:7995.871972799301
batch reward last col mean 0.1597907841205597 first col mean 0.12185627222061157 all mean 0.15485763549804688
0.41996899247169495 0.41996899247169495
rl training, epoch3, iter0, batch115/1133, batch loss:0.41996899247169495, Training time:7998.536026954651
batch reward last col mean 0.08823463320732117 first col mean 0.11328268051147461 all mean 0.10015977919101715
0.3323691487312317 0.3323691487312317
rl training, epoch3, iter0, batch116/1133, batch loss:0.3323691487312317, Training time:8000.658488750458
batch reward last col mean 0.11253015697002411 first col mean 0.12057560682296753 all mean 0.11161250621080399
0.30076438188552856 0.3007643520832062
rl training, epoch3, iter0, batch117/1133, batch loss:0.3007643520832062, Training time:8003.470098257065
batch reward last col mean 0.11850504577159882 first col mean 0.12710115313529968 all mean 0.12219303101301193
0.3730946183204651 0.3730946183204651
rl training, epoch3, iter0, batch118/1133, batch loss:0.3730946183204651, Training time:8006.367922782898
batch reward last col mean 0.13416816294193268 first col mean 0.1462780237197876 all mean 0.1269342005252838
0.3630671203136444 0.3630671203136444
rl training, epoch3, iter0, batch119/1133, batch loss:0.3630671203136444, Training time:8007.960797548294
batch reward last col mean 0.12141114473342896 first col mean 0.11514592915773392 all mean 0.12341300398111343
0.34539908170700073 0.34539908170700073
rl training, epoch3, iter0, batch120/1133, batch loss:0.34539908170700073, Training time:8010.450773477554
batch reward last col mean 0.12197218090295792 first col mean 0.11010012030601501 all mean 0.12496720254421234
0.3687642216682434 0.3687642216682434
rl training, epoch3, iter0, batch121/1133, batch loss:0.3687642216682434, Training time:8013.2573325634
batch reward last col mean 0.13523346185684204 first col mean 0.12547652423381805 all mean 0.1382390260696411
0.4084283709526062 0.4084283709526062
rl training, epoch3, iter0, batch122/1133, batch loss:0.4084283709526062, Training time:8016.0711669921875
batch reward last col mean 0.11316201090812683 first col mean 0.14257723093032837 all mean 0.11480110883712769
0.3532264828681946 0.3532264828681946
rl training, epoch3, iter0, batch123/1133, batch loss:0.3532264828681946, Training time:8018.1686799526215
batch reward last col mean 0.12856647372245789 first col mean 0.13741731643676758 all mean 0.12568727135658264
0.34451279044151306 0.34451279044151306
rl training, epoch3, iter0, batch124/1133, batch loss:0.34451279044151306, Training time:8020.90998673439
batch reward last col mean 0.12075605988502502 first col mean 0.12974002957344055 all mean 0.12346256524324417
0.3871992230415344 0.3871992230415344
rl training, epoch3, iter0, batch125/1133, batch loss:0.3871992230415344, Training time:8023.2598423957825
batch reward last col mean 0.14593735337257385 first col mean 0.1354287564754486 all mean 0.14218313992023468
0.387976735830307 0.387976735830307
rl training, epoch3, iter0, batch126/1133, batch loss:0.387976735830307, Training time:8025.682998895645
batch reward last col mean 0.11055810004472733 first col mean 0.12887874245643616 all mean 0.11873048543930054
0.34538504481315613 0.34538504481315613
rl training, epoch3, iter0, batch127/1133, batch loss:0.34538504481315613, Training time:8027.467924356461
batch reward last col mean 0.16567476093769073 first col mean 0.13462606072425842 all mean 0.15264788269996643
0.3920672535896301 0.39206719398498535
rl training, epoch3, iter0, batch128/1133, batch loss:0.39206719398498535, Training time:8029.754830360413
batch reward last col mean 0.09688564389944077 first col mean 0.11190983653068542 all mean 0.10095199942588806
0.3276708126068115 0.3276708126068115
rl training, epoch3, iter0, batch129/1133, batch loss:0.3276708126068115, Training time:8032.124306201935
batch reward last col mean 0.09598199278116226 first col mean 0.1351427137851715 all mean 0.11200016736984253
0.3301897346973419 0.3301897346973419
rl training, epoch3, iter0, batch130/1133, batch loss:0.3301897346973419, Training time:8033.970773458481
batch reward last col mean 0.12429414689540863 first col mean 0.12773185968399048 all mean 0.12449254840612411
0.3308352530002594 0.3308352530002594
rl training, epoch3, iter0, batch131/1133, batch loss:0.3308352530002594, Training time:8035.669623851776
batch reward last col mean 0.1702379435300827 first col mean 0.13052213191986084 all mean 0.1588289588689804
0.39343881607055664 0.39343881607055664
rl training, epoch3, iter0, batch132/1133, batch loss:0.39343881607055664, Training time:8037.764595270157
batch reward last col mean 0.17279720306396484 first col mean 0.12371562421321869 all mean 0.1600744128227234
0.4205029010772705 0.4205029010772705
rl training, epoch3, iter0, batch133/1133, batch loss:0.4205029010772705, Training time:8039.7993767261505
batch reward last col mean 0.09575076401233673 first col mean 0.14310085773468018 all mean 0.1020144671201706
0.35191622376441956 0.35191622376441956
rl training, epoch3, iter0, batch134/1133, batch loss:0.35191622376441956, Training time:8042.065561294556
batch reward last col mean 0.08655322343111038 first col mean 0.14041385054588318 all mean 0.10040242969989777
0.36440908908843994 0.36440908908843994
rl training, epoch3, iter0, batch135/1133, batch loss:0.36440908908843994, Training time:8043.9987688064575
batch reward last col mean 0.12933672964572906 first col mean 0.1275584101676941 all mean 0.12058927118778229
0.3322111666202545 0.3322111666202545
rl training, epoch3, iter0, batch136/1133, batch loss:0.3322111666202545, Training time:8046.172452449799
batch reward last col mean 0.10962645709514618 first col mean 0.13315297663211823 all mean 0.1156257763504982
0.3869057595729828 0.386905699968338
rl training, epoch3, iter0, batch137/1133, batch loss:0.386905699968338, Training time:8048.3215074539185
batch reward last col mean 0.11163972318172455 first col mean 0.1303403079509735 all mean 0.11499553173780441
0.35871049761772156 0.35871049761772156
rl training, epoch3, iter0, batch138/1133, batch loss:0.35871049761772156, Training time:8050.352158784866
batch reward last col mean 0.07077232748270035 first col mean 0.13357886672019958 all mean 0.08708156645298004
0.3036360442638397 0.3036360442638397
rl training, epoch3, iter0, batch139/1133, batch loss:0.3036360442638397, Training time:8052.735443115234
batch reward last col mean 0.1431960165500641 first col mean 0.12575210630893707 all mean 0.13931681215763092
0.35732004046440125 0.35732004046440125
rl training, epoch3, iter0, batch140/1133, batch loss:0.35732004046440125, Training time:8054.812023639679
batch reward last col mean 0.16482338309288025 first col mean 0.135825976729393 all mean 0.15128479897975922
0.3885694146156311 0.3885694146156311
rl training, epoch3, iter0, batch141/1133, batch loss:0.3885694146156311, Training time:8056.875366926193
batch reward last col mean 0.11095771938562393 first col mean 0.10625362396240234 all mean 0.11374039202928543
0.35967305302619934 0.35967305302619934
rl training, epoch3, iter0, batch142/1133, batch loss:0.35967305302619934, Training time:8059.192838191986
batch reward last col mean 0.12470851838588715 first col mean 0.12980684638023376 all mean 0.12723451852798462
0.33563652634620667 0.33563652634620667
rl training, epoch3, iter0, batch143/1133, batch loss:0.33563652634620667, Training time:8061.296803236008
batch reward last col mean 0.13933993875980377 first col mean 0.1343786120414734 all mean 0.13307534158229828
0.33807212114334106 0.33807212114334106
rl training, epoch3, iter0, batch144/1133, batch loss:0.33807212114334106, Training time:8064.47718501091
batch reward last col mean 0.10538328438997269 first col mean 0.13211604952812195 all mean 0.11239030212163925
0.3319847881793976 0.3319847881793976
rl training, epoch3, iter0, batch145/1133, batch loss:0.3319847881793976, Training time:8066.332703590393
batch reward last col mean 0.15917648375034332 first col mean 0.12525621056556702 all mean 0.14653760194778442
0.41186144948005676 0.41186144948005676
rl training, epoch3, iter0, batch146/1133, batch loss:0.41186144948005676, Training time:8068.325752735138
batch reward last col mean 0.11588391661643982 first col mean 0.12222819775342941 all mean 0.11389926075935364
0.32241150736808777 0.32241150736808777
rl training, epoch3, iter0, batch147/1133, batch loss:0.32241150736808777, Training time:8070.484174966812
batch reward last col mean 0.12227305769920349 first col mean 0.13416540622711182 all mean 0.11906858533620834
0.3627890944480896 0.3627890944480896
rl training, epoch3, iter0, batch148/1133, batch loss:0.3627890944480896, Training time:8072.7167336940765
batch reward last col mean 0.11450019478797913 first col mean 0.1587185263633728 all mean 0.11449321359395981
0.3072158694267273 0.3072158694267273
rl training, epoch3, iter0, batch149/1133, batch loss:0.3072158694267273, Training time:8075.132275104523
batch reward last col mean 0.166764497756958 first col mean 0.12872350215911865 all mean 0.16093921661376953
0.4269099831581116 0.4269099831581116
rl training, epoch3, iter0, batch150/1133, batch loss:0.4269099831581116, Training time:8077.449920415878
batch reward last col mean 0.1449568122625351 first col mean 0.12237787246704102 all mean 0.13368751108646393
0.346475750207901 0.346475750207901
rl training, epoch3, iter0, batch151/1133, batch loss:0.346475750207901, Training time:8079.220599651337
batch reward last col mean 0.1365993767976761 first col mean 0.1314759999513626 all mean 0.13695213198661804
0.3574758768081665 0.3574758768081665
rl training, epoch3, iter0, batch152/1133, batch loss:0.3574758768081665, Training time:8081.13911318779
batch reward last col mean 0.12207235395908356 first col mean 0.15240265429019928 all mean 0.12194342166185379
0.312203049659729 0.312203049659729
rl training, epoch3, iter0, batch153/1133, batch loss:0.312203049659729, Training time:8083.784178733826
batch reward last col mean 0.12412093579769135 first col mean 0.12012853473424911 all mean 0.12140487134456635
0.3790770471096039 0.3790770471096039
rl training, epoch3, iter0, batch154/1133, batch loss:0.3790770471096039, Training time:8085.952991724014
batch reward last col mean 0.1524214744567871 first col mean 0.1236996054649353 all mean 0.142714262008667
0.369663804769516 0.3696637749671936
rl training, epoch3, iter0, batch155/1133, batch loss:0.3696637749671936, Training time:8087.968730926514
batch reward last col mean 0.1339305341243744 first col mean 0.14174844324588776 all mean 0.12932847440242767
0.34956154227256775 0.34956154227256775
rl training, epoch3, iter0, batch156/1133, batch loss:0.34956154227256775, Training time:8089.818411111832
batch reward last col mean 0.1310727894306183 first col mean 0.11692256480455399 all mean 0.13051453232765198
0.3673929274082184 0.3673929274082184
rl training, epoch3, iter0, batch157/1133, batch loss:0.3673929274082184, Training time:8092.1447167396545
batch reward last col mean 0.154817134141922 first col mean 0.12801870703697205 all mean 0.148311048746109
0.4132777452468872 0.413277804851532
rl training, epoch3, iter0, batch158/1133, batch loss:0.413277804851532, Training time:8094.059974908829
batch reward last col mean 0.13259397447109222 first col mean 0.13766169548034668 all mean 0.12746387720108032
0.3420362174510956 0.3420362174510956
rl training, epoch3, iter0, batch159/1133, batch loss:0.3420362174510956, Training time:8096.058804273605
batch reward last col mean 0.1314416378736496 first col mean 0.10006320476531982 all mean 0.1238284781575203
0.3464433252811432 0.3464433252811432
rl training, epoch3, iter0, batch160/1133, batch loss:0.3464433252811432, Training time:8097.8058450222015
batch reward last col mean 0.16150709986686707 first col mean 0.14163923263549805 all mean 0.1547916829586029
0.3730210065841675 0.3730210065841675
rl training, epoch3, iter0, batch161/1133, batch loss:0.3730210065841675, Training time:8100.355984210968
batch reward last col mean 0.1274651139974594 first col mean 0.13298143446445465 all mean 0.13436827063560486
0.41454488039016724 0.41454488039016724
rl training, epoch3, iter0, batch162/1133, batch loss:0.41454488039016724, Training time:8102.245019197464
batch reward last col mean 0.12191097438335419 first col mean 0.13659054040908813 all mean 0.1200990080833435
0.36603063344955444 0.36603063344955444
rl training, epoch3, iter0, batch163/1133, batch loss:0.36603063344955444, Training time:8104.331790685654
batch reward last col mean 0.09470571577548981 first col mean 0.12466387450695038 all mean 0.10605667531490326
0.35252153873443604 0.35252150893211365
rl training, epoch3, iter0, batch164/1133, batch loss:0.35252150893211365, Training time:8106.7381954193115
batch reward last col mean 0.12764491140842438 first col mean 0.1481189727783203 all mean 0.12816935777664185
0.3660332262516022 0.3660332262516022
rl training, epoch3, iter0, batch165/1133, batch loss:0.3660332262516022, Training time:8109.077546834946
batch reward last col mean 0.08816725760698318 first col mean 0.13689731061458588 all mean 0.09921899437904358
0.3273984491825104 0.3273984491825104
rl training, epoch3, iter0, batch166/1133, batch loss:0.3273984491825104, Training time:8111.070216417313
batch reward last col mean 0.12290026992559433 first col mean 0.12128423154354095 all mean 0.11779411137104034
0.33248448371887207 0.33248448371887207
rl training, epoch3, iter0, batch167/1133, batch loss:0.33248448371887207, Training time:8113.321074724197
batch reward last col mean 0.0911925658583641 first col mean 0.12192048877477646 all mean 0.10292378813028336
0.32950538396835327 0.32950538396835327
rl training, epoch3, iter0, batch168/1133, batch loss:0.32950538396835327, Training time:8115.644330263138
batch reward last col mean 0.12875798344612122 first col mean 0.11004900932312012 all mean 0.12959106266498566
0.36299121379852295 0.36299121379852295
rl training, epoch3, iter0, batch169/1133, batch loss:0.36299121379852295, Training time:8117.633605003357
batch reward last col mean 0.09180431813001633 first col mean 0.12398955225944519 all mean 0.0964968129992485
0.28093355894088745 0.28093355894088745
rl training, epoch3, iter0, batch170/1133, batch loss:0.28093355894088745, Training time:8119.6955308914185
batch reward last col mean 0.10682781785726547 first col mean 0.13236261904239655 all mean 0.11850026249885559
0.35177862644195557 0.35177862644195557
rl training, epoch3, iter0, batch171/1133, batch loss:0.35177862644195557, Training time:8121.81436753273
batch reward last col mean 0.12649285793304443 first col mean 0.13238300383090973 all mean 0.12678559124469757
0.3508833944797516 0.3508833944797516
rl training, epoch3, iter0, batch172/1133, batch loss:0.3508833944797516, Training time:8124.683646202087
batch reward last col mean 0.1288662850856781 first col mean 0.1403120458126068 all mean 0.12963873147964478
0.3638765811920166 0.363876610994339
rl training, epoch3, iter0, batch173/1133, batch loss:0.363876610994339, Training time:8126.545091867447
batch reward last col mean 0.1121964231133461 first col mean 0.12648865580558777 all mean 0.11637537181377411
0.3613809645175934 0.3613809049129486
rl training, epoch3, iter0, batch174/1133, batch loss:0.3613809049129486, Training time:8128.335509300232
batch reward last col mean 0.10242074728012085 first col mean 0.12764739990234375 all mean 0.10185972601175308
0.3264212906360626 0.3264212906360626
rl training, epoch3, iter0, batch175/1133, batch loss:0.3264212906360626, Training time:8130.872909069061
batch reward last col mean 0.1493450552225113 first col mean 0.125822976231575 all mean 0.1507207602262497
0.36867424845695496 0.36867424845695496
rl training, epoch3, iter0, batch176/1133, batch loss:0.36867424845695496, Training time:8133.267461061478
batch reward last col mean 0.1509203463792801 first col mean 0.12937772274017334 all mean 0.14486512541770935
0.3695955276489258 0.3695955276489258
rl training, epoch3, iter0, batch177/1133, batch loss:0.3695955276489258, Training time:8135.782864570618
batch reward last col mean 0.14984647929668427 first col mean 0.11385994404554367 all mean 0.1438266634941101
0.37699252367019653 0.37699252367019653
rl training, epoch3, iter0, batch178/1133, batch loss:0.37699252367019653, Training time:8138.18408203125
batch reward last col mean 0.10935333371162415 first col mean 0.1135474443435669 all mean 0.1158047765493393
0.3274692893028259 0.3274692893028259
rl training, epoch3, iter0, batch179/1133, batch loss:0.3274692893028259, Training time:8140.754480600357
batch reward last col mean 0.12996289134025574 first col mean 0.14003878831863403 all mean 0.1308692842721939
0.3670650124549866 0.3670650124549866
rl training, epoch3, iter0, batch180/1133, batch loss:0.3670650124549866, Training time:8142.843155384064
batch reward last col mean 0.11952407658100128 first col mean 0.12692801654338837 all mean 0.12578514218330383
0.3570236563682556 0.3570236563682556
rl training, epoch3, iter0, batch181/1133, batch loss:0.3570236563682556, Training time:8144.964369058609
batch reward last col mean 0.12782719731330872 first col mean 0.1335390955209732 all mean 0.12854178249835968
0.38281524181365967 0.38281524181365967
rl training, epoch3, iter0, batch182/1133, batch loss:0.38281524181365967, Training time:8147.007271766663
batch reward last col mean 0.14793522655963898 first col mean 0.15946722030639648 all mean 0.15196731686592102
0.3796790540218353 0.3796790540218353
rl training, epoch3, iter0, batch183/1133, batch loss:0.3796790540218353, Training time:8148.949362516403
batch reward last col mean 0.10415466874837875 first col mean 0.12157520651817322 all mean 0.1066502183675766
0.31166404485702515 0.31166407465934753
rl training, epoch3, iter0, batch184/1133, batch loss:0.31166407465934753, Training time:8150.955568313599
batch reward last col mean 0.12795111536979675 first col mean 0.14110027253627777 all mean 0.12614166736602783
0.33545371890068054 0.33545371890068054
rl training, epoch3, iter0, batch185/1133, batch loss:0.33545371890068054, Training time:8152.736669063568
batch reward last col mean 0.11224508285522461 first col mean 0.13960111141204834 all mean 0.11938554793596268
0.3724888563156128 0.3724888563156128
rl training, epoch3, iter0, batch186/1133, batch loss:0.3724888563156128, Training time:8154.80070567131
batch reward last col mean 0.15461137890815735 first col mean 0.13785937428474426 all mean 0.14855925738811493
0.3479054272174835 0.3479054272174835
rl training, epoch3, iter0, batch187/1133, batch loss:0.3479054272174835, Training time:8156.9449627399445
batch reward last col mean 0.12676316499710083 first col mean 0.13065817952156067 all mean 0.12810638546943665
0.3745803236961365 0.3745803236961365
rl training, epoch3, iter0, batch188/1133, batch loss:0.3745803236961365, Training time:8159.052010536194
batch reward last col mean 0.10959102213382721 first col mean 0.13375714421272278 all mean 0.11009544134140015
0.33105725049972534 0.33105725049972534
rl training, epoch3, iter0, batch189/1133, batch loss:0.33105725049972534, Training time:8161.803431034088
batch reward last col mean 0.10021467506885529 first col mean 0.12099301815032959 all mean 0.1098690927028656
0.3274635374546051 0.3274635076522827
rl training, epoch3, iter0, batch190/1133, batch loss:0.3274635076522827, Training time:8164.583502531052
batch reward last col mean 0.1245405375957489 first col mean 0.12811623513698578 all mean 0.12287286669015884
0.3338007628917694 0.3338007628917694
rl training, epoch3, iter0, batch191/1133, batch loss:0.3338007628917694, Training time:8167.332966566086
batch reward last col mean 0.11117488890886307 first col mean 0.1320256143808365 all mean 0.11291486024856567
0.3052448332309723 0.3052448332309723
rl training, epoch3, iter0, batch192/1133, batch loss:0.3052448332309723, Training time:8170.277275562286
batch reward last col mean 0.12789319455623627 first col mean 0.1324433535337448 all mean 0.1315258890390396
0.36200612783432007 0.36200612783432007
rl training, epoch3, iter0, batch193/1133, batch loss:0.36200612783432007, Training time:8172.513391494751
batch reward last col mean 0.14131112396717072 first col mean 0.13164182007312775 all mean 0.1338311731815338
0.36123156547546387 0.3612315356731415
rl training, epoch3, iter0, batch194/1133, batch loss:0.3612315356731415, Training time:8174.842128753662
batch reward last col mean 0.13576002418994904 first col mean 0.13947270810604095 all mean 0.13329066336154938
0.3567775785923004 0.3567775785923004
rl training, epoch3, iter0, batch195/1133, batch loss:0.3567775785923004, Training time:8177.044630527496
batch reward last col mean 0.12818382680416107 first col mean 0.1394966095685959 all mean 0.1357327252626419
0.3623616695404053 0.3623616397380829
rl training, epoch3, iter0, batch196/1133, batch loss:0.3623616397380829, Training time:8178.768742084503
batch reward last col mean 0.16377855837345123 first col mean 0.14432863891124725 all mean 0.1592167615890503
0.41442376375198364 0.41442376375198364
rl training, epoch3, iter0, batch197/1133, batch loss:0.41442376375198364, Training time:8180.932126522064
batch reward last col mean 0.11206584423780441 first col mean 0.13727352023124695 all mean 0.11519370228052139
0.3274707794189453 0.3274707794189453
rl training, epoch3, iter0, batch198/1133, batch loss:0.3274707794189453, Training time:8185.192675828934
batch reward last col mean 0.16463136672973633 first col mean 0.12911973893642426 all mean 0.1501425951719284
0.38502711057662964 0.38502711057662964
rl training, epoch3, iter0, batch199/1133, batch loss:0.38502711057662964, Training time:8187.091264486313
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5514233580807723 Time: 99.86372923851013 s
loss of true 0.24350778579659307 loss of gen 0.19380452072236354 loss of other 0.11411105221941317 first score 0.13905540108680725
batch reward last col mean 0.13572563230991364 first col mean 0.12384334206581116 all mean 0.13988341391086578
0.38097813725471497 0.38097813725471497
rl training, epoch3, iter0, batch200/1133, batch loss:0.38097813725471497, Training time:8288.787757873535
batch reward last col mean 0.12880803644657135 first col mean 0.12827062606811523 all mean 0.1229390799999237
0.3381125330924988 0.3381125330924988
rl training, epoch3, iter0, batch201/1133, batch loss:0.3381125330924988, Training time:8290.680171966553
batch reward last col mean 0.13046894967556 first col mean 0.12043827772140503 all mean 0.12803828716278076
0.3221929669380188 0.3221929669380188
rl training, epoch3, iter0, batch202/1133, batch loss:0.3221929669380188, Training time:8292.298430204391
batch reward last col mean 0.13641121983528137 first col mean 0.12378738820552826 all mean 0.13800203800201416
0.3474946916103363 0.3474946916103363
rl training, epoch3, iter0, batch203/1133, batch loss:0.3474946916103363, Training time:8294.041526556015
batch reward last col mean 0.1961812973022461 first col mean 0.12509214878082275 all mean 0.1753697395324707
0.40511882305145264 0.40511882305145264
rl training, epoch3, iter0, batch204/1133, batch loss:0.40511882305145264, Training time:8296.103524684906
batch reward last col mean 0.10436183214187622 first col mean 0.11603447794914246 all mean 0.10765508562326431
0.32562121748924255 0.32562121748924255
rl training, epoch3, iter0, batch205/1133, batch loss:0.32562121748924255, Training time:8297.699383020401
batch reward last col mean 0.13519877195358276 first col mean 0.12004689872264862 all mean 0.1222342923283577
0.3857928216457367 0.3857928216457367
rl training, epoch3, iter0, batch206/1133, batch loss:0.3857928216457367, Training time:8299.473004102707
batch reward last col mean 0.1617228090763092 first col mean 0.13294294476509094 all mean 0.14437545835971832
0.3694649338722229 0.3694649338722229
rl training, epoch3, iter0, batch207/1133, batch loss:0.3694649338722229, Training time:8301.706154823303
batch reward last col mean 0.10761797428131104 first col mean 0.14080806076526642 all mean 0.1114572063088417
0.3369518220424652 0.33695176243782043
rl training, epoch3, iter0, batch208/1133, batch loss:0.33695176243782043, Training time:8304.105491161346
batch reward last col mean 0.1399455964565277 first col mean 0.11673621088266373 all mean 0.13817718625068665
0.3523634672164917 0.3523634672164917
rl training, epoch3, iter0, batch209/1133, batch loss:0.3523634672164917, Training time:8305.774435043335
batch reward last col mean 0.13249571621418 first col mean 0.1240435242652893 all mean 0.12973658740520477
0.36088597774505615 0.36088597774505615
rl training, epoch3, iter0, batch210/1133, batch loss:0.36088597774505615, Training time:8307.52976155281
batch reward last col mean 0.12712356448173523 first col mean 0.13202106952667236 all mean 0.128596693277359
0.412941038608551 0.412941038608551
rl training, epoch3, iter0, batch211/1133, batch loss:0.412941038608551, Training time:8309.27647972107
batch reward last col mean 0.11099947243928909 first col mean 0.12962859869003296 all mean 0.11465165764093399
0.3139914274215698 0.3139914274215698
rl training, epoch3, iter0, batch212/1133, batch loss:0.3139914274215698, Training time:8310.89466381073
batch reward last col mean 0.15512344241142273 first col mean 0.1272302269935608 all mean 0.14698271453380585
0.3972407877445221 0.3972407877445221
rl training, epoch3, iter0, batch213/1133, batch loss:0.3972407877445221, Training time:8312.430778741837
batch reward last col mean 0.10966315120458603 first col mean 0.10440962016582489 all mean 0.10662923008203506
0.29524922370910645 0.29524922370910645
rl training, epoch3, iter0, batch214/1133, batch loss:0.29524922370910645, Training time:8314.156109571457
batch reward last col mean 0.11881314218044281 first col mean 0.1146039143204689 all mean 0.12097778916358948
0.33902764320373535 0.33902764320373535
rl training, epoch3, iter0, batch215/1133, batch loss:0.33902764320373535, Training time:8316.251735687256
batch reward last col mean 0.11623399704694748 first col mean 0.13665087521076202 all mean 0.11749688535928726
0.30479031801223755 0.30479031801223755
rl training, epoch3, iter0, batch216/1133, batch loss:0.30479031801223755, Training time:8317.933527946472
batch reward last col mean 0.12369145452976227 first col mean 0.10713569819927216 all mean 0.12098392099142075
0.3403514325618744 0.3403514325618744
rl training, epoch3, iter0, batch217/1133, batch loss:0.3403514325618744, Training time:8319.622771263123
batch reward last col mean 0.10712495446205139 first col mean 0.1296492964029312 all mean 0.11103439331054688
0.29690203070640564 0.29690203070640564
rl training, epoch3, iter0, batch218/1133, batch loss:0.29690203070640564, Training time:8322.022299051285
batch reward last col mean 0.09786994755268097 first col mean 0.11892294883728027 all mean 0.1042308583855629
0.354080468416214 0.354080468416214
rl training, epoch3, iter0, batch219/1133, batch loss:0.354080468416214, Training time:8324.194208621979
batch reward last col mean 0.13643617928028107 first col mean 0.12450844049453735 all mean 0.1273525208234787
0.3104236423969269 0.3104236423969269
rl training, epoch3, iter0, batch220/1133, batch loss:0.3104236423969269, Training time:8326.001506567001
batch reward last col mean 0.17271040380001068 first col mean 0.12647077441215515 all mean 0.15942606329917908
0.37562477588653564 0.37562477588653564
rl training, epoch3, iter0, batch221/1133, batch loss:0.37562477588653564, Training time:8328.196051120758
batch reward last col mean 0.13865119218826294 first col mean 0.13596102595329285 all mean 0.12981608510017395
0.3704479932785034 0.3704479932785034
rl training, epoch3, iter0, batch222/1133, batch loss:0.3704479932785034, Training time:8330.09201335907
batch reward last col mean 0.11215224862098694 first col mean 0.11600691825151443 all mean 0.11852376908063889
0.306429922580719 0.3064298927783966
rl training, epoch3, iter0, batch223/1133, batch loss:0.3064298927783966, Training time:8331.908651828766
batch reward last col mean 0.11742489039897919 first col mean 0.1391604095697403 all mean 0.12136723101139069
0.34772056341171265 0.34772056341171265
rl training, epoch3, iter0, batch224/1133, batch loss:0.34772056341171265, Training time:8334.114876508713
batch reward last col mean 0.12296058237552643 first col mean 0.10966113954782486 all mean 0.11697515845298767
0.31847500801086426 0.31847500801086426
rl training, epoch3, iter0, batch225/1133, batch loss:0.31847500801086426, Training time:8335.807393550873
batch reward last col mean 0.12103221565485 first col mean 0.12936753034591675 all mean 0.12086569517850876
0.35781732201576233 0.35781732201576233
rl training, epoch3, iter0, batch226/1133, batch loss:0.35781732201576233, Training time:8337.383270263672
batch reward last col mean 0.08860577642917633 first col mean 0.10744652152061462 all mean 0.09524670243263245
0.30225515365600586 0.30225512385368347
rl training, epoch3, iter0, batch227/1133, batch loss:0.30225512385368347, Training time:8339.57843542099
batch reward last col mean 0.13400577008724213 first col mean 0.13223949074745178 all mean 0.1337253302335739
0.4043482840061188 0.4043482840061188
rl training, epoch3, iter0, batch228/1133, batch loss:0.4043482840061188, Training time:8341.336868286133
batch reward last col mean 0.11037654429674149 first col mean 0.13122397661209106 all mean 0.1176517903804779
0.35393795371055603 0.35393792390823364
rl training, epoch3, iter0, batch229/1133, batch loss:0.35393792390823364, Training time:8343.800532102585
batch reward last col mean 0.13945060968399048 first col mean 0.14320716261863708 all mean 0.1414896845817566
0.39094746112823486 0.39094746112823486
rl training, epoch3, iter0, batch230/1133, batch loss:0.39094746112823486, Training time:8345.572005748749
batch reward last col mean 0.13265353441238403 first col mean 0.14324064552783966 all mean 0.13310228288173676
0.3299769163131714 0.3299769163131714
rl training, epoch3, iter0, batch231/1133, batch loss:0.3299769163131714, Training time:8347.863983631134
batch reward last col mean 0.12475308030843735 first col mean 0.11002403497695923 all mean 0.12135715782642365
0.35130229592323303 0.35130229592323303
rl training, epoch3, iter0, batch232/1133, batch loss:0.35130229592323303, Training time:8349.725314617157
batch reward last col mean 0.10524098575115204 first col mean 0.1217849999666214 all mean 0.1068871021270752
0.3121095597743988 0.3121095597743988
rl training, epoch3, iter0, batch233/1133, batch loss:0.3121095597743988, Training time:8353.458319664001
batch reward last col mean 0.09499835222959518 first col mean 0.13489483296871185 all mean 0.09941903501749039
0.29186925292015076 0.29186925292015076
rl training, epoch3, iter0, batch234/1133, batch loss:0.29186925292015076, Training time:8357.762281894684
batch reward last col mean 0.12856557965278625 first col mean 0.1259341984987259 all mean 0.12903667986392975
0.3355720639228821 0.3355720639228821
rl training, epoch3, iter0, batch235/1133, batch loss:0.3355720639228821, Training time:8359.899193763733
batch reward last col mean 0.1270904541015625 first col mean 0.13551414012908936 all mean 0.13025544583797455
0.33230477571487427 0.33230480551719666
rl training, epoch3, iter0, batch236/1133, batch loss:0.33230480551719666, Training time:8361.62583398819
batch reward last col mean 0.1305503249168396 first col mean 0.1236458420753479 all mean 0.12902981042861938
0.35331639647483826 0.35331639647483826
rl training, epoch3, iter0, batch237/1133, batch loss:0.35331639647483826, Training time:8363.365732908249
batch reward last col mean 0.10318928956985474 first col mean 0.1369001865386963 all mean 0.11392982304096222
0.3466629683971405 0.3466629981994629
rl training, epoch3, iter0, batch238/1133, batch loss:0.3466629981994629, Training time:8365.540088415146
batch reward last col mean 0.11232859641313553 first col mean 0.1307421326637268 all mean 0.1132601797580719
0.3444662392139435 0.3444662094116211
rl training, epoch3, iter0, batch239/1133, batch loss:0.3444662094116211, Training time:8367.736870765686
batch reward last col mean 0.1429019421339035 first col mean 0.10913221538066864 all mean 0.14005862176418304
0.35654085874557495 0.35654085874557495
rl training, epoch3, iter0, batch240/1133, batch loss:0.35654085874557495, Training time:8370.650331020355
batch reward last col mean 0.11294794827699661 first col mean 0.13762427866458893 all mean 0.1178627535700798
0.37545356154441833 0.37545356154441833
rl training, epoch3, iter0, batch241/1133, batch loss:0.37545356154441833, Training time:8372.711955070496
batch reward last col mean 0.10713912546634674 first col mean 0.14750170707702637 all mean 0.1126813292503357
0.3083619475364685 0.3083619475364685
rl training, epoch3, iter0, batch242/1133, batch loss:0.3083619475364685, Training time:8375.129479885101
batch reward last col mean 0.19020462036132812 first col mean 0.12677954137325287 all mean 0.17511850595474243
0.3862348794937134 0.3862348794937134
rl training, epoch3, iter0, batch243/1133, batch loss:0.3862348794937134, Training time:8377.695581674576
batch reward last col mean 0.12304085493087769 first col mean 0.1242496520280838 all mean 0.1212540939450264
0.3433174192905426 0.3433174192905426
rl training, epoch3, iter0, batch244/1133, batch loss:0.3433174192905426, Training time:8380.263438463211
batch reward last col mean 0.1274949610233307 first col mean 0.14765073359012604 all mean 0.133774071931839
0.3774107098579407 0.3774107098579407
rl training, epoch3, iter0, batch245/1133, batch loss:0.3774107098579407, Training time:8381.808079719543
batch reward last col mean 0.12527747452259064 first col mean 0.12339190393686295 all mean 0.1279769241809845
0.3562079966068268 0.3562079966068268
rl training, epoch3, iter0, batch246/1133, batch loss:0.3562079966068268, Training time:8383.463346719742
batch reward last col mean 0.09712840616703033 first col mean 0.1370469331741333 all mean 0.11054263263940811
0.35526782274246216 0.35526785254478455
rl training, epoch3, iter0, batch247/1133, batch loss:0.35526785254478455, Training time:8385.217594861984
batch reward last col mean 0.12104177474975586 first col mean 0.10608461499214172 all mean 0.1181086078286171
0.3060756325721741 0.3060756325721741
rl training, epoch3, iter0, batch248/1133, batch loss:0.3060756325721741, Training time:8388.057201385498
batch reward last col mean 0.1250559389591217 first col mean 0.12549333274364471 all mean 0.1182778999209404
0.3292723298072815 0.3292723298072815
rl training, epoch3, iter0, batch249/1133, batch loss:0.3292723298072815, Training time:8390.00598692894
batch reward last col mean 0.15090373158454895 first col mean 0.1278870403766632 all mean 0.13365237414836884
0.3695478141307831 0.3695478141307831
rl training, epoch3, iter0, batch250/1133, batch loss:0.3695478141307831, Training time:8392.635483264923
batch reward last col mean 0.09876781702041626 first col mean 0.1210671216249466 all mean 0.1063079833984375
0.30523398518562317 0.30523398518562317
rl training, epoch3, iter0, batch251/1133, batch loss:0.30523398518562317, Training time:8394.897636890411
batch reward last col mean 0.08099062740802765 first col mean 0.155822291970253 all mean 0.09404740482568741
0.3269522190093994 0.3269522190093994
rl training, epoch3, iter0, batch252/1133, batch loss:0.3269522190093994, Training time:8396.901442050934
batch reward last col mean 0.10415025055408478 first col mean 0.111919105052948 all mean 0.11119136214256287
0.35068222880363464 0.35068222880363464
rl training, epoch3, iter0, batch253/1133, batch loss:0.35068222880363464, Training time:8398.438916921616
batch reward last col mean 0.10120027512311935 first col mean 0.12857815623283386 all mean 0.11185411363840103
0.3114510476589203 0.3114510476589203
rl training, epoch3, iter0, batch254/1133, batch loss:0.3114510476589203, Training time:8400.665337562561
batch reward last col mean 0.10073791444301605 first col mean 0.126254603266716 all mean 0.10323342680931091
0.34093061089515686 0.3409305810928345
rl training, epoch3, iter0, batch255/1133, batch loss:0.3409305810928345, Training time:8402.732889175415
batch reward last col mean 0.10864824801683426 first col mean 0.1098516434431076 all mean 0.11161050200462341
0.33588382601737976 0.33588382601737976
rl training, epoch3, iter0, batch256/1133, batch loss:0.33588382601737976, Training time:8405.075353860855
batch reward last col mean 0.11076262593269348 first col mean 0.13507989048957825 all mean 0.12295690178871155
0.34164857864379883 0.34164857864379883
rl training, epoch3, iter0, batch257/1133, batch loss:0.34164857864379883, Training time:8406.773385763168
batch reward last col mean 0.1343037188053131 first col mean 0.131044402718544 all mean 0.12863950431346893
0.40288394689559937 0.40288394689559937
rl training, epoch3, iter0, batch258/1133, batch loss:0.40288394689559937, Training time:8409.377186775208
batch reward last col mean 0.13398420810699463 first col mean 0.12747088074684143 all mean 0.13513480126857758
0.4015578031539917 0.4015578031539917
rl training, epoch3, iter0, batch259/1133, batch loss:0.4015578031539917, Training time:8411.088568925858
batch reward last col mean 0.11195055395364761 first col mean 0.12491990625858307 all mean 0.11834472417831421
0.3567100763320923 0.3567100763320923
rl training, epoch3, iter0, batch260/1133, batch loss:0.3567100763320923, Training time:8413.402398347855
batch reward last col mean 0.12877820432186127 first col mean 0.11672212183475494 all mean 0.12391998618841171
0.3535269498825073 0.3535269498825073
rl training, epoch3, iter0, batch261/1133, batch loss:0.3535269498825073, Training time:8415.276521205902
batch reward last col mean 0.09233759343624115 first col mean 0.1478695422410965 all mean 0.10333987325429916
0.34110328555107117 0.34110328555107117
rl training, epoch3, iter0, batch262/1133, batch loss:0.34110328555107117, Training time:8417.97631907463
batch reward last col mean 0.16040094196796417 first col mean 0.1200447827577591 all mean 0.14870744943618774
0.3728357255458832 0.3728357255458832
rl training, epoch3, iter0, batch263/1133, batch loss:0.3728357255458832, Training time:8419.924037694931
batch reward last col mean 0.14383465051651 first col mean 0.12484348565340042 all mean 0.12799161672592163
0.35322248935699463 0.35322248935699463
rl training, epoch3, iter0, batch264/1133, batch loss:0.35322248935699463, Training time:8421.206738471985
batch reward last col mean 0.15455925464630127 first col mean 0.13164199888706207 all mean 0.14604273438453674
0.38202375173568726 0.38202375173568726
rl training, epoch3, iter0, batch265/1133, batch loss:0.38202375173568726, Training time:8422.92828631401
batch reward last col mean 0.1259002834558487 first col mean 0.1209498718380928 all mean 0.13050837814807892
0.40413087606430054 0.40413087606430054
rl training, epoch3, iter0, batch266/1133, batch loss:0.40413087606430054, Training time:8425.20878148079
batch reward last col mean 0.15401342511177063 first col mean 0.12569713592529297 all mean 0.1435931921005249
0.3678351044654846 0.3678351044654846
rl training, epoch3, iter0, batch267/1133, batch loss:0.3678351044654846, Training time:8427.244338989258
batch reward last col mean 0.10048143565654755 first col mean 0.12050574272871017 all mean 0.10606345534324646
0.3045901656150818 0.3045901358127594
rl training, epoch3, iter0, batch268/1133, batch loss:0.3045901358127594, Training time:8429.385694980621
batch reward last col mean 0.10265844315290451 first col mean 0.12177115678787231 all mean 0.11006233841180801
0.34910744428634644 0.34910744428634644
rl training, epoch3, iter0, batch269/1133, batch loss:0.34910744428634644, Training time:8431.669710636139
batch reward last col mean 0.08868011832237244 first col mean 0.13565769791603088 all mean 0.10108315944671631
0.3066890835762024 0.3066890835762024
rl training, epoch3, iter0, batch270/1133, batch loss:0.3066890835762024, Training time:8433.295167207718
batch reward last col mean 0.1436501443386078 first col mean 0.13975968956947327 all mean 0.13809023797512054
0.3764495849609375 0.3764495551586151
rl training, epoch3, iter0, batch271/1133, batch loss:0.3764495551586151, Training time:8434.89483499527
batch reward last col mean 0.11043502390384674 first col mean 0.1201949417591095 all mean 0.11251989006996155
0.3106614053249359 0.3106614053249359
rl training, epoch3, iter0, batch272/1133, batch loss:0.3106614053249359, Training time:8437.379366159439
batch reward last col mean 0.17493776977062225 first col mean 0.11937293410301208 all mean 0.164797842502594
0.43281805515289307 0.43281805515289307
rl training, epoch3, iter0, batch273/1133, batch loss:0.43281805515289307, Training time:8438.926191329956
batch reward last col mean 0.15143011510372162 first col mean 0.1283685564994812 all mean 0.14286114275455475
0.3684922754764557 0.3684922754764557
rl training, epoch3, iter0, batch274/1133, batch loss:0.3684922754764557, Training time:8440.612796545029
batch reward last col mean 0.10267283767461777 first col mean 0.1308521330356598 all mean 0.10902085155248642
0.35324162244796753 0.3532416522502899
rl training, epoch3, iter0, batch275/1133, batch loss:0.3532416522502899, Training time:8442.611393928528
batch reward last col mean 0.13974566757678986 first col mean 0.13765496015548706 all mean 0.127213716506958
0.37597987055778503 0.37597987055778503
rl training, epoch3, iter0, batch276/1133, batch loss:0.37597987055778503, Training time:8444.517429351807
batch reward last col mean 0.12417739629745483 first col mean 0.1236329972743988 all mean 0.1213981956243515
0.32617172598838806 0.32617172598838806
rl training, epoch3, iter0, batch277/1133, batch loss:0.32617172598838806, Training time:8447.078180074692
batch reward last col mean 0.09331302344799042 first col mean 0.1108158677816391 all mean 0.09900135546922684
0.32099446654319763 0.32099446654319763
rl training, epoch3, iter0, batch278/1133, batch loss:0.32099446654319763, Training time:8448.82248044014
batch reward last col mean 0.11754560470581055 first col mean 0.11994776129722595 all mean 0.11935225874185562
0.3421269357204437 0.3421269357204437
rl training, epoch3, iter0, batch279/1133, batch loss:0.3421269357204437, Training time:8450.71320438385
batch reward last col mean 0.14198815822601318 first col mean 0.15590393543243408 all mean 0.14431075751781464
0.3845222592353821 0.3845222592353821
rl training, epoch3, iter0, batch280/1133, batch loss:0.3845222592353821, Training time:8452.552149772644
batch reward last col mean 0.14000248908996582 first col mean 0.13467621803283691 all mean 0.13777562975883484
0.3745962083339691 0.3745962083339691
rl training, epoch3, iter0, batch281/1133, batch loss:0.3745962083339691, Training time:8455.009286880493
batch reward last col mean 0.13552522659301758 first col mean 0.12482823431491852 all mean 0.12601780891418457
0.35502108931541443 0.35502108931541443
rl training, epoch3, iter0, batch282/1133, batch loss:0.35502108931541443, Training time:8456.659744501114
batch reward last col mean 0.11257970333099365 first col mean 0.12762586772441864 all mean 0.11366799473762512
0.3321680426597595 0.3321680426597595
rl training, epoch3, iter0, batch283/1133, batch loss:0.3321680426597595, Training time:8458.42256617546
batch reward last col mean 0.14008930325508118 first col mean 0.11590864509344101 all mean 0.13656461238861084
0.39127016067504883 0.39127016067504883
rl training, epoch3, iter0, batch284/1133, batch loss:0.39127016067504883, Training time:8460.335420846939
batch reward last col mean 0.1294272243976593 first col mean 0.12689463794231415 all mean 0.1296113282442093
0.3634265661239624 0.3634265661239624
rl training, epoch3, iter0, batch285/1133, batch loss:0.3634265661239624, Training time:8462.182929992676
batch reward last col mean 0.12430606782436371 first col mean 0.12167304754257202 all mean 0.1264858841896057
0.3945842385292053 0.3945842385292053
rl training, epoch3, iter0, batch286/1133, batch loss:0.3945842385292053, Training time:8464.477742671967
batch reward last col mean 0.1027459055185318 first col mean 0.12018714845180511 all mean 0.11109574884176254
0.34618473052978516 0.34618473052978516
rl training, epoch3, iter0, batch287/1133, batch loss:0.34618473052978516, Training time:8466.386922359467
batch reward last col mean 0.11984355002641678 first col mean 0.12341919541358948 all mean 0.11742804199457169
0.3325240910053253 0.33252406120300293
rl training, epoch3, iter0, batch288/1133, batch loss:0.33252406120300293, Training time:8468.54523563385
batch reward last col mean 0.1082058697938919 first col mean 0.13353416323661804 all mean 0.11386194825172424
0.34163859486579895 0.34163859486579895
rl training, epoch3, iter0, batch289/1133, batch loss:0.34163859486579895, Training time:8470.673043727875
batch reward last col mean 0.10852047801017761 first col mean 0.13094662129878998 all mean 0.11509527266025543
0.38942909240722656 0.38942909240722656
rl training, epoch3, iter0, batch290/1133, batch loss:0.38942909240722656, Training time:8472.593426465988
batch reward last col mean 0.09865310043096542 first col mean 0.12004692852497101 all mean 0.10889071226119995
0.30114367604255676 0.3011436462402344
rl training, epoch3, iter0, batch291/1133, batch loss:0.3011436462402344, Training time:8474.828642368317
batch reward last col mean 0.12681844830513 first col mean 0.144192174077034 all mean 0.13276977837085724
0.33157971501350403 0.33157971501350403
rl training, epoch3, iter0, batch292/1133, batch loss:0.33157971501350403, Training time:8476.70841550827
batch reward last col mean 0.11847387999296188 first col mean 0.1410200297832489 all mean 0.12174700200557709
0.4081120491027832 0.4081120491027832
rl training, epoch3, iter0, batch293/1133, batch loss:0.4081120491027832, Training time:8478.743374109268
batch reward last col mean 0.1457672417163849 first col mean 0.1441085934638977 all mean 0.14141806960105896
0.39787915349006653 0.39787915349006653
rl training, epoch3, iter0, batch294/1133, batch loss:0.39787915349006653, Training time:8480.742756843567
batch reward last col mean 0.149014413356781 first col mean 0.14630496501922607 all mean 0.14394594728946686
0.37433019280433655 0.37433019280433655
rl training, epoch3, iter0, batch295/1133, batch loss:0.37433019280433655, Training time:8482.483575582504
batch reward last col mean 0.1143462210893631 first col mean 0.13448533415794373 all mean 0.11866118758916855
0.3087587356567383 0.3087587356567383
rl training, epoch3, iter0, batch296/1133, batch loss:0.3087587356567383, Training time:8484.543004989624
batch reward last col mean 0.11283469200134277 first col mean 0.11775971949100494 all mean 0.11430308222770691
0.37170302867889404 0.37170302867889404
rl training, epoch3, iter0, batch297/1133, batch loss:0.37170302867889404, Training time:8486.372597694397
batch reward last col mean 0.13259419798851013 first col mean 0.11188043653964996 all mean 0.12333336472511292
0.3882167637348175 0.3882167637348175
rl training, epoch3, iter0, batch298/1133, batch loss:0.3882167637348175, Training time:8488.380026102066
batch reward last col mean 0.09868835657835007 first col mean 0.13790693879127502 all mean 0.10378793627023697
0.33675166964530945 0.33675166964530945
rl training, epoch3, iter0, batch299/1133, batch loss:0.33675166964530945, Training time:8492.007172107697
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5507680108509333 Time: 97.83921432495117 s
loss of true 0.24419104208592704 loss of gen 0.1934731839009333 loss of other 0.11310378539179504 first score 0.12519700825214386
batch reward last col mean 0.12449076026678085 first col mean 0.1174226850271225 all mean 0.12749673426151276
0.382058709859848 0.38205868005752563
rl training, epoch3, iter0, batch300/1133, batch loss:0.38205868005752563, Training time:8592.057626724243
batch reward last col mean 0.1152801439166069 first col mean 0.13136644661426544 all mean 0.11384782195091248
0.30705147981643677 0.30705147981643677
rl training, epoch3, iter0, batch301/1133, batch loss:0.30705147981643677, Training time:8594.142293214798
batch reward last col mean 0.1090480238199234 first col mean 0.13090640306472778 all mean 0.1128850057721138
0.33261528611183167 0.33261528611183167
rl training, epoch3, iter0, batch302/1133, batch loss:0.33261528611183167, Training time:8596.085216522217
batch reward last col mean 0.1239812895655632 first col mean 0.10809458792209625 all mean 0.12167032063007355
0.3446590006351471 0.3446590006351471
rl training, epoch3, iter0, batch303/1133, batch loss:0.3446590006351471, Training time:8598.07087111473
batch reward last col mean 0.11022962629795074 first col mean 0.12607039511203766 all mean 0.11270909011363983
0.28251388669013977 0.28251388669013977
rl training, epoch3, iter0, batch304/1133, batch loss:0.28251388669013977, Training time:8600.35104060173
batch reward last col mean 0.10371965914964676 first col mean 0.1493808478116989 all mean 0.11011280864477158
0.3380032181739807 0.3380032181739807
rl training, epoch3, iter0, batch305/1133, batch loss:0.3380032181739807, Training time:8602.216180801392
batch reward last col mean 0.09743542224168777 first col mean 0.11531883478164673 all mean 0.10309493541717529
0.28025469183921814 0.28025469183921814
rl training, epoch3, iter0, batch306/1133, batch loss:0.28025469183921814, Training time:8603.983891963959
batch reward last col mean 0.13370010256767273 first col mean 0.12942367792129517 all mean 0.12770061194896698
0.31506040692329407 0.3150603473186493
rl training, epoch3, iter0, batch307/1133, batch loss:0.3150603473186493, Training time:8606.300002098083
batch reward last col mean 0.13130947947502136 first col mean 0.11819228529930115 all mean 0.1269707977771759
0.3702414631843567 0.3702414631843567
rl training, epoch3, iter0, batch308/1133, batch loss:0.3702414631843567, Training time:8608.112509965897
batch reward last col mean 0.16951283812522888 first col mean 0.12934443354606628 all mean 0.15671026706695557
0.3782804012298584 0.3782804012298584
rl training, epoch3, iter0, batch309/1133, batch loss:0.3782804012298584, Training time:8610.165288209915
batch reward last col mean 0.10673259943723679 first col mean 0.11521349102258682 all mean 0.10826778411865234
0.31334632635116577 0.3133462965488434
rl training, epoch3, iter0, batch310/1133, batch loss:0.3133462965488434, Training time:8611.874641418457
batch reward last col mean 0.09917382895946503 first col mean 0.10799141973257065 all mean 0.10386263579130173
0.30358728766441345 0.30358728766441345
rl training, epoch3, iter0, batch311/1133, batch loss:0.30358728766441345, Training time:8614.541557788849
batch reward last col mean 0.06983897089958191 first col mean 0.10369684547185898 all mean 0.08513011038303375
0.2781250774860382 0.2781250774860382
rl training, epoch3, iter0, batch312/1133, batch loss:0.2781250774860382, Training time:8616.512819766998
batch reward last col mean 0.10195563733577728 first col mean 0.10770586133003235 all mean 0.1033698171377182
0.36618784070014954 0.36618784070014954
rl training, epoch3, iter0, batch313/1133, batch loss:0.36618784070014954, Training time:8618.607558965683
batch reward last col mean 0.1319558471441269 first col mean 0.12395462393760681 all mean 0.12464606016874313
0.33655431866645813 0.33655431866645813
rl training, epoch3, iter0, batch314/1133, batch loss:0.33655431866645813, Training time:8620.817146062851
batch reward last col mean 0.10487280786037445 first col mean 0.13651788234710693 all mean 0.11165366321802139
0.3366149365901947 0.3366149365901947
rl training, epoch3, iter0, batch315/1133, batch loss:0.3366149365901947, Training time:8622.796742677689
batch reward last col mean 0.1388130933046341 first col mean 0.1163288801908493 all mean 0.1337997019290924
0.3322140872478485 0.3322140872478485
rl training, epoch3, iter0, batch316/1133, batch loss:0.3322140872478485, Training time:8624.733446359634
batch reward last col mean 0.12300921976566315 first col mean 0.12051156163215637 all mean 0.12178626656532288
0.3200770616531372 0.3200770318508148
rl training, epoch3, iter0, batch317/1133, batch loss:0.3200770318508148, Training time:8626.760175943375
batch reward last col mean 0.10324335098266602 first col mean 0.12103603780269623 all mean 0.11107222735881805
0.3190842568874359 0.3190842270851135
rl training, epoch3, iter0, batch318/1133, batch loss:0.3190842270851135, Training time:8628.910439252853
batch reward last col mean 0.12273430824279785 first col mean 0.13094359636306763 all mean 0.12228985130786896
0.35256484150886536 0.35256484150886536
rl training, epoch3, iter0, batch319/1133, batch loss:0.35256484150886536, Training time:8631.038701295853
batch reward last col mean 0.09606130421161652 first col mean 0.11940022557973862 all mean 0.09885526448488235
0.30390363931655884 0.30390363931655884
rl training, epoch3, iter0, batch320/1133, batch loss:0.30390363931655884, Training time:8632.939063072205
batch reward last col mean 0.12203007936477661 first col mean 0.11982257664203644 all mean 0.12243540585041046
0.35323792695999146 0.35323792695999146
rl training, epoch3, iter0, batch321/1133, batch loss:0.35323792695999146, Training time:8634.843887090683
batch reward last col mean 0.1455691158771515 first col mean 0.11049404740333557 all mean 0.1407238394021988
0.34654501080513 0.34654501080513
rl training, epoch3, iter0, batch322/1133, batch loss:0.34654501080513, Training time:8636.8652780056
batch reward last col mean 0.09286703169345856 first col mean 0.12760460376739502 all mean 0.09502054750919342
0.3139286935329437 0.31392866373062134
rl training, epoch3, iter0, batch323/1133, batch loss:0.31392866373062134, Training time:8639.047901391983
batch reward last col mean 0.12444499135017395 first col mean 0.11328332871198654 all mean 0.12745976448059082
0.38415205478668213 0.38415205478668213
rl training, epoch3, iter0, batch324/1133, batch loss:0.38415205478668213, Training time:8641.068486213684
batch reward last col mean 0.08502157777547836 first col mean 0.12054230272769928 all mean 0.09224169701337814
0.27748388051986694 0.27748388051986694
rl training, epoch3, iter0, batch325/1133, batch loss:0.27748388051986694, Training time:8642.650324106216
batch reward last col mean 0.10175910592079163 first col mean 0.12033890187740326 all mean 0.11261928826570511
0.3479020893573761 0.3479020893573761
rl training, epoch3, iter0, batch326/1133, batch loss:0.3479020893573761, Training time:8644.41667842865
batch reward last col mean 0.13387706875801086 first col mean 0.12465158104896545 all mean 0.12233234941959381
0.35444438457489014 0.35444438457489014
rl training, epoch3, iter0, batch327/1133, batch loss:0.35444438457489014, Training time:8646.02177810669
batch reward last col mean 0.127030149102211 first col mean 0.1241142749786377 all mean 0.12629477679729462
0.34366294741630554 0.34366294741630554
rl training, epoch3, iter0, batch328/1133, batch loss:0.34366294741630554, Training time:8647.809195756912
batch reward last col mean 0.1317308247089386 first col mean 0.12734277546405792 all mean 0.12245791405439377
0.37007513642311096 0.37007513642311096
rl training, epoch3, iter0, batch329/1133, batch loss:0.37007513642311096, Training time:8649.853914499283
batch reward last col mean 0.09173259139060974 first col mean 0.11397624015808105 all mean 0.09673602879047394
0.2905886769294739 0.29058870673179626
rl training, epoch3, iter0, batch330/1133, batch loss:0.29058870673179626, Training time:8651.663888454437
batch reward last col mean 0.10112537443637848 first col mean 0.1397421807050705 all mean 0.10359783470630646
0.3192548155784607 0.3192548155784607
rl training, epoch3, iter0, batch331/1133, batch loss:0.3192548155784607, Training time:8653.658161401749
batch reward last col mean 0.13363666832447052 first col mean 0.12128148972988129 all mean 0.1275390386581421
0.3898933231830597 0.3898933231830597
rl training, epoch3, iter0, batch332/1133, batch loss:0.3898933231830597, Training time:8655.816317796707
batch reward last col mean 0.11141227185726166 first col mean 0.1431770920753479 all mean 0.11908183246850967
0.3311864733695984 0.3311864733695984
rl training, epoch3, iter0, batch333/1133, batch loss:0.3311864733695984, Training time:8658.022225856781
batch reward last col mean 0.1437402069568634 first col mean 0.13651856780052185 all mean 0.13650086522102356
0.4191354811191559 0.41913554072380066
rl training, epoch3, iter0, batch334/1133, batch loss:0.41913554072380066, Training time:8659.804320335388
batch reward last col mean 0.13593710958957672 first col mean 0.12294755131006241 all mean 0.13316039741039276
0.39142873883247375 0.39142876863479614
rl training, epoch3, iter0, batch335/1133, batch loss:0.39142876863479614, Training time:8661.86747264862
batch reward last col mean 0.1065271720290184 first col mean 0.12417122721672058 all mean 0.10449754446744919
0.2990787625312805 0.29907873272895813
rl training, epoch3, iter0, batch336/1133, batch loss:0.29907873272895813, Training time:8663.68818116188
batch reward last col mean 0.08936673402786255 first col mean 0.12189844250679016 all mean 0.10089489817619324
0.3043152987957001 0.30431532859802246
rl training, epoch3, iter0, batch337/1133, batch loss:0.30431532859802246, Training time:8665.681188106537
batch reward last col mean 0.09789393097162247 first col mean 0.11602790653705597 all mean 0.1023457795381546
0.31670552492141724 0.31670552492141724
rl training, epoch3, iter0, batch338/1133, batch loss:0.31670552492141724, Training time:8667.391154289246
batch reward last col mean 0.1629943549633026 first col mean 0.10642175376415253 all mean 0.15053068101406097
0.38545703887939453 0.38545703887939453
rl training, epoch3, iter0, batch339/1133, batch loss:0.38545703887939453, Training time:8669.984358787537
batch reward last col mean 0.11720877885818481 first col mean 0.13608650863170624 all mean 0.11861974745988846
0.32091382145881653 0.32091382145881653
rl training, epoch3, iter0, batch340/1133, batch loss:0.32091382145881653, Training time:8672.19778418541
batch reward last col mean 0.08241661638021469 first col mean 0.11400091648101807 all mean 0.0935579389333725
0.30012598633766174 0.30012598633766174
rl training, epoch3, iter0, batch341/1133, batch loss:0.30012598633766174, Training time:8674.04897403717
batch reward last col mean 0.1435815840959549 first col mean 0.11569882929325104 all mean 0.13434714078903198
0.36287710070610046 0.36287710070610046
rl training, epoch3, iter0, batch342/1133, batch loss:0.36287710070610046, Training time:8676.304593801498
batch reward last col mean 0.13983303308486938 first col mean 0.10964721441268921 all mean 0.1310970038175583
0.3722163438796997 0.3722163140773773
rl training, epoch3, iter0, batch343/1133, batch loss:0.3722163140773773, Training time:8678.716248750687
batch reward last col mean 0.11993352323770523 first col mean 0.11128586530685425 all mean 0.12022744119167328
0.3464054465293884 0.3464054465293884
rl training, epoch3, iter0, batch344/1133, batch loss:0.3464054465293884, Training time:8681.11299109459
batch reward last col mean 0.10672174394130707 first col mean 0.12554265558719635 all mean 0.11366146057844162
0.3454126715660095 0.3454126715660095
rl training, epoch3, iter0, batch345/1133, batch loss:0.3454126715660095, Training time:8683.40873503685
batch reward last col mean 0.13830484449863434 first col mean 0.11383061856031418 all mean 0.13142314553260803
0.3259483277797699 0.3259483277797699
rl training, epoch3, iter0, batch346/1133, batch loss:0.3259483277797699, Training time:8685.269522190094
batch reward last col mean 0.11349201202392578 first col mean 0.09594091773033142 all mean 0.11674341559410095
0.32561084628105164 0.32561084628105164
rl training, epoch3, iter0, batch347/1133, batch loss:0.32561084628105164, Training time:8686.951585531235
batch reward last col mean 0.08349230885505676 first col mean 0.12081272155046463 all mean 0.09158596396446228
0.3028467893600464 0.3028467893600464
rl training, epoch3, iter0, batch348/1133, batch loss:0.3028467893600464, Training time:8689.898131370544
batch reward last col mean 0.1240757554769516 first col mean 0.12395698577165604 all mean 0.12195879220962524
0.3964736759662628 0.3964736759662628
rl training, epoch3, iter0, batch349/1133, batch loss:0.3964736759662628, Training time:8691.871219396591
batch reward last col mean 0.12173931300640106 first col mean 0.1351618766784668 all mean 0.13216541707515717
0.36678510904312134 0.36678510904312134
rl training, epoch3, iter0, batch350/1133, batch loss:0.36678510904312134, Training time:8693.628033161163
batch reward last col mean 0.1371113359928131 first col mean 0.13009324669837952 all mean 0.1340181678533554
0.3799087107181549 0.3799087107181549
rl training, epoch3, iter0, batch351/1133, batch loss:0.3799087107181549, Training time:8695.857575178146
batch reward last col mean 0.0838007926940918 first col mean 0.12169390916824341 all mean 0.09620451927185059
0.30932414531707764 0.3093241751194
rl training, epoch3, iter0, batch352/1133, batch loss:0.3093241751194, Training time:8697.69242978096
batch reward last col mean 0.1543426811695099 first col mean 0.12074518948793411 all mean 0.14319664239883423
0.36261221766471863 0.36261221766471863
rl training, epoch3, iter0, batch353/1133, batch loss:0.36261221766471863, Training time:8699.43948173523
batch reward last col mean 0.12533964216709137 first col mean 0.12425938993692398 all mean 0.11793763935565948
0.3216340243816376 0.3216340243816376
rl training, epoch3, iter0, batch354/1133, batch loss:0.3216340243816376, Training time:8701.361340999603
batch reward last col mean 0.0896935760974884 first col mean 0.12748466432094574 all mean 0.10499995201826096
0.34967198967933655 0.34967198967933655
rl training, epoch3, iter0, batch355/1133, batch loss:0.34967198967933655, Training time:8703.118834972382
batch reward last col mean 0.0997360348701477 first col mean 0.10469309985637665 all mean 0.112057626247406
0.3594612181186676 0.3594612181186676
rl training, epoch3, iter0, batch356/1133, batch loss:0.3594612181186676, Training time:8704.941737890244
batch reward last col mean 0.12220688164234161 first col mean 0.13092927634716034 all mean 0.1257501095533371
0.3409078121185303 0.3409078121185303
rl training, epoch3, iter0, batch357/1133, batch loss:0.3409078121185303, Training time:8706.778550386429
batch reward last col mean 0.1189601793885231 first col mean 0.11919163167476654 all mean 0.12055834382772446
0.30387309193611145 0.30387309193611145
rl training, epoch3, iter0, batch358/1133, batch loss:0.30387309193611145, Training time:8708.88549399376
batch reward last col mean 0.10027621686458588 first col mean 0.1199410930275917 all mean 0.10632556676864624
0.29807376861572266 0.29807376861572266
rl training, epoch3, iter0, batch359/1133, batch loss:0.29807376861572266, Training time:8711.724217414856
batch reward last col mean 0.10988004505634308 first col mean 0.11196521669626236 all mean 0.11364836245775223
0.30763131380081177 0.30763131380081177
rl training, epoch3, iter0, batch360/1133, batch loss:0.30763131380081177, Training time:8714.128756046295
batch reward last col mean 0.11654183268547058 first col mean 0.10115572065114975 all mean 0.11927556246519089
0.31513527035713196 0.31513530015945435
rl training, epoch3, iter0, batch361/1133, batch loss:0.31513530015945435, Training time:8715.948780059814
batch reward last col mean 0.09558127820491791 first col mean 0.11218012869358063 all mean 0.10076405853033066
0.36286798119544983 0.36286798119544983
rl training, epoch3, iter0, batch362/1133, batch loss:0.36286798119544983, Training time:8718.164361476898
batch reward last col mean 0.10972237586975098 first col mean 0.1360386610031128 all mean 0.10884501785039902
0.31684452295303345 0.31684452295303345
rl training, epoch3, iter0, batch363/1133, batch loss:0.31684452295303345, Training time:8721.264800548553
batch reward last col mean 0.11568649113178253 first col mean 0.1277419477701187 all mean 0.12153754383325577
0.33189570903778076 0.33189570903778076
rl training, epoch3, iter0, batch364/1133, batch loss:0.33189570903778076, Training time:8723.47355556488
batch reward last col mean 0.1218666136264801 first col mean 0.10453750193119049 all mean 0.11941814422607422
0.3217816948890686 0.3217816948890686
rl training, epoch3, iter0, batch365/1133, batch loss:0.3217816948890686, Training time:8725.754212141037
batch reward last col mean 0.09398999810218811 first col mean 0.13368818163871765 all mean 0.10143914818763733
0.3058101534843445 0.3058101534843445
rl training, epoch3, iter0, batch366/1133, batch loss:0.3058101534843445, Training time:8727.815078020096
batch reward last col mean 0.09739391505718231 first col mean 0.13351212441921234 all mean 0.10219936072826385
0.31951904296875 0.31951904296875
rl training, epoch3, iter0, batch367/1133, batch loss:0.31951904296875, Training time:8729.993908643723
batch reward last col mean 0.12195176631212234 first col mean 0.13003575801849365 all mean 0.12317083775997162
0.3188439607620239 0.3188439607620239
rl training, epoch3, iter0, batch368/1133, batch loss:0.3188439607620239, Training time:8732.10442495346
batch reward last col mean 0.10531719774007797 first col mean 0.13480162620544434 all mean 0.10811059176921844
0.34129810333251953 0.34129810333251953
rl training, epoch3, iter0, batch369/1133, batch loss:0.34129810333251953, Training time:8734.483648061752
batch reward last col mean 0.12575209140777588 first col mean 0.11489572376012802 all mean 0.12873299419879913
0.3437323272228241 0.3437322974205017
rl training, epoch3, iter0, batch370/1133, batch loss:0.3437322974205017, Training time:8736.349169969559
batch reward last col mean 0.1488320231437683 first col mean 0.12087298184633255 all mean 0.14496609568595886
0.3921557068824768 0.3921556770801544
rl training, epoch3, iter0, batch371/1133, batch loss:0.3921556770801544, Training time:8739.061433792114
batch reward last col mean 0.09438780695199966 first col mean 0.12755431234836578 all mean 0.10231313854455948
0.34332507848739624 0.34332507848739624
rl training, epoch3, iter0, batch372/1133, batch loss:0.34332507848739624, Training time:8741.049399137497
batch reward last col mean 0.09887756407260895 first col mean 0.11896244436502457 all mean 0.10821367055177689
0.3190593123435974 0.3190593123435974
rl training, epoch3, iter0, batch373/1133, batch loss:0.3190593123435974, Training time:8743.12705373764
batch reward last col mean 0.11533869802951813 first col mean 0.12462379783391953 all mean 0.11494260281324387
0.3121945559978485 0.3121945559978485
rl training, epoch3, iter0, batch374/1133, batch loss:0.3121945559978485, Training time:8745.667671918869
batch reward last col mean 0.1448735147714615 first col mean 0.11183960735797882 all mean 0.1416850984096527
0.3904331624507904 0.390433132648468
rl training, epoch3, iter0, batch375/1133, batch loss:0.390433132648468, Training time:8747.711623191833
batch reward last col mean 0.09097827225923538 first col mean 0.13853685557842255 all mean 0.0965489000082016
0.3280520439147949 0.32805201411247253
rl training, epoch3, iter0, batch376/1133, batch loss:0.32805201411247253, Training time:8750.159805297852
batch reward last col mean 0.10911602526903152 first col mean 0.13528066873550415 all mean 0.11161870509386063
0.3283499777317047 0.3283499777317047
rl training, epoch3, iter0, batch377/1133, batch loss:0.3283499777317047, Training time:8752.8285779953
batch reward last col mean 0.11474896967411041 first col mean 0.11879001557826996 all mean 0.11411775648593903
0.30174535512924194 0.30174535512924194
rl training, epoch3, iter0, batch378/1133, batch loss:0.30174535512924194, Training time:8754.636511564255
batch reward last col mean 0.11944616585969925 first col mean 0.12818802893161774 all mean 0.11702714115381241
0.30326688289642334 0.30326688289642334
rl training, epoch3, iter0, batch379/1133, batch loss:0.30326688289642334, Training time:8756.47384762764
batch reward last col mean 0.1365945041179657 first col mean 0.11028369516134262 all mean 0.13649436831474304
0.383617639541626 0.383617639541626
rl training, epoch3, iter0, batch380/1133, batch loss:0.383617639541626, Training time:8759.127859592438
batch reward last col mean 0.11761192977428436 first col mean 0.11668424308300018 all mean 0.11545968800783157
0.3458920121192932 0.3458920121192932
rl training, epoch3, iter0, batch381/1133, batch loss:0.3458920121192932, Training time:8761.30435180664
batch reward last col mean 0.1277962476015091 first col mean 0.11308938264846802 all mean 0.1288229525089264
0.36139151453971863 0.36139148473739624
rl training, epoch3, iter0, batch382/1133, batch loss:0.36139148473739624, Training time:8764.125218391418
batch reward last col mean 0.13284501433372498 first col mean 0.13889527320861816 all mean 0.1295490860939026
0.3709383010864258 0.37093833088874817
rl training, epoch3, iter0, batch383/1133, batch loss:0.37093833088874817, Training time:8766.251102924347
batch reward last col mean 0.13451915979385376 first col mean 0.12255551666021347 all mean 0.12928573787212372
0.35608357191085815 0.35608357191085815
rl training, epoch3, iter0, batch384/1133, batch loss:0.35608357191085815, Training time:8768.44108915329
batch reward last col mean 0.11011582612991333 first col mean 0.1271195113658905 all mean 0.11649874597787857
0.32517850399017334 0.32517850399017334
rl training, epoch3, iter0, batch385/1133, batch loss:0.32517850399017334, Training time:8770.519563913345
batch reward last col mean 0.13971826434135437 first col mean 0.13813599944114685 all mean 0.13558535277843475
0.33101701736450195 0.33101701736450195
rl training, epoch3, iter0, batch386/1133, batch loss:0.33101701736450195, Training time:8772.63814496994
batch reward last col mean 0.09782922267913818 first col mean 0.11704062670469284 all mean 0.1054149642586708
0.3281610906124115 0.3281610906124115
rl training, epoch3, iter0, batch387/1133, batch loss:0.3281610906124115, Training time:8774.495888471603
batch reward last col mean 0.10297089070081711 first col mean 0.11744639277458191 all mean 0.10568338632583618
0.34267181158065796 0.34267178177833557
rl training, epoch3, iter0, batch388/1133, batch loss:0.34267178177833557, Training time:8776.770421743393
batch reward last col mean 0.09128250181674957 first col mean 0.1298702359199524 all mean 0.10042541474103928
0.3384955823421478 0.3384955823421478
rl training, epoch3, iter0, batch389/1133, batch loss:0.3384955823421478, Training time:8779.708738803864
batch reward last col mean 0.10784880071878433 first col mean 0.13369427621364594 all mean 0.11108752340078354
0.33651620149612427 0.33651620149612427
rl training, epoch3, iter0, batch390/1133, batch loss:0.33651620149612427, Training time:8781.852798700333
batch reward last col mean 0.1297856867313385 first col mean 0.11943912506103516 all mean 0.12474258989095688
0.3226536512374878 0.3226536512374878
rl training, epoch3, iter0, batch391/1133, batch loss:0.3226536512374878, Training time:8784.111901283264
batch reward last col mean 0.06629534065723419 first col mean 0.11484285444021225 all mean 0.08171405643224716
0.25602957606315613 0.25602957606315613
rl training, epoch3, iter0, batch392/1133, batch loss:0.25602957606315613, Training time:8786.123626947403
batch reward last col mean 0.11747036874294281 first col mean 0.11769919097423553 all mean 0.11881372332572937
0.35726580023765564 0.35726580023765564
rl training, epoch3, iter0, batch393/1133, batch loss:0.35726580023765564, Training time:8788.435584068298
batch reward last col mean 0.09709435701370239 first col mean 0.12086310982704163 all mean 0.10137331485748291
0.3101024627685547 0.3101024329662323
rl training, epoch3, iter0, batch394/1133, batch loss:0.3101024329662323, Training time:8790.507886171341
batch reward last col mean 0.1286652833223343 first col mean 0.12333594262599945 all mean 0.13460955023765564
0.39660942554473877 0.39660942554473877
rl training, epoch3, iter0, batch395/1133, batch loss:0.39660942554473877, Training time:8792.646911859512
batch reward last col mean 0.1208714097738266 first col mean 0.1298399567604065 all mean 0.12160782516002655
0.3055354952812195 0.30553552508354187
rl training, epoch3, iter0, batch396/1133, batch loss:0.30553552508354187, Training time:8794.942588806152
batch reward last col mean 0.12068577855825424 first col mean 0.14801539480686188 all mean 0.1251567006111145
0.33414220809936523 0.33414220809936523
rl training, epoch3, iter0, batch397/1133, batch loss:0.33414220809936523, Training time:8796.729371786118
batch reward last col mean 0.13062234222888947 first col mean 0.13159418106079102 all mean 0.12767548859119415
0.3403148353099823 0.3403148353099823
rl training, epoch3, iter0, batch398/1133, batch loss:0.3403148353099823, Training time:8799.46923160553
batch reward last col mean 0.13000613451004028 first col mean 0.11163261532783508 all mean 0.12423182278871536
0.33726680278778076 0.33726680278778076
rl training, epoch3, iter0, batch399/1133, batch loss:0.33726680278778076, Training time:8801.751339197159
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5481378288786704 Time: 100.88263130187988 s
loss of true 0.24262652824331152 loss of gen 0.19258085871074226 loss of other 0.11293044266441388 first score 0.14598380029201508
batch reward last col mean 0.1622607558965683 first col mean 0.1245884895324707 all mean 0.14427196979522705
0.3448258340358734 0.344825804233551
rl training, epoch3, iter0, batch400/1133, batch loss:0.344825804233551, Training time:8904.369086503983
batch reward last col mean 0.08283085376024246 first col mean 0.13067059218883514 all mean 0.09475549310445786
0.3246130645275116 0.3246130645275116
rl training, epoch3, iter0, batch401/1133, batch loss:0.3246130645275116, Training time:8906.842206001282
batch reward last col mean 0.12049306929111481 first col mean 0.09936042129993439 all mean 0.11506469547748566
0.2893785834312439 0.2893785834312439
rl training, epoch3, iter0, batch402/1133, batch loss:0.2893785834312439, Training time:8908.843079805374
batch reward last col mean 0.07633277028799057 first col mean 0.0986601784825325 all mean 0.08364611864089966
0.27962976694107056 0.27962976694107056
rl training, epoch3, iter0, batch403/1133, batch loss:0.27962976694107056, Training time:8910.819871902466
batch reward last col mean 0.12290394306182861 first col mean 0.10494059324264526 all mean 0.12030741572380066
0.3323756456375122 0.3323756456375122
rl training, epoch3, iter0, batch404/1133, batch loss:0.3323756456375122, Training time:8913.172964811325
batch reward last col mean 0.117306187748909 first col mean 0.11971110105514526 all mean 0.1183604821562767
0.3112306594848633 0.3112306594848633
rl training, epoch3, iter0, batch405/1133, batch loss:0.3112306594848633, Training time:8915.825731754303
batch reward last col mean 0.12116797268390656 first col mean 0.08427968621253967 all mean 0.11728853732347488
0.29712116718292236 0.29712116718292236
rl training, epoch3, iter0, batch406/1133, batch loss:0.29712116718292236, Training time:8918.46209859848
batch reward last col mean 0.09024520963430405 first col mean 0.11001228541135788 all mean 0.09903635829687119
0.2953656017780304 0.2953656017780304
rl training, epoch3, iter0, batch407/1133, batch loss:0.2953656017780304, Training time:8920.470120668411
batch reward last col mean 0.0793142169713974 first col mean 0.11438536643981934 all mean 0.08627261221408844
0.3022814095020294 0.30228137969970703
rl training, epoch3, iter0, batch408/1133, batch loss:0.30228137969970703, Training time:8923.245172023773
batch reward last col mean 0.10563313961029053 first col mean 0.1260562539100647 all mean 0.10866643488407135
0.2844901382923126 0.2844901382923126
rl training, epoch3, iter0, batch409/1133, batch loss:0.2844901382923126, Training time:8925.128693580627
batch reward last col mean 0.1413562148809433 first col mean 0.10372938215732574 all mean 0.13224057853221893
0.32811030745506287 0.32811030745506287
rl training, epoch3, iter0, batch410/1133, batch loss:0.32811030745506287, Training time:8927.549309015274
batch reward last col mean 0.10797370225191116 first col mean 0.10424987226724625 all mean 0.11147961020469666
0.2925637364387512 0.2925637364387512
rl training, epoch3, iter0, batch411/1133, batch loss:0.2925637364387512, Training time:8929.992443561554
batch reward last col mean 0.11453060805797577 first col mean 0.0997735783457756 all mean 0.1133170872926712
0.327131062746048 0.327131062746048
rl training, epoch3, iter0, batch412/1133, batch loss:0.327131062746048, Training time:8932.555076122284
batch reward last col mean 0.11594870686531067 first col mean 0.10556882619857788 all mean 0.1143706664443016
0.3184479773044586 0.3184479773044586
rl training, epoch3, iter0, batch413/1133, batch loss:0.3184479773044586, Training time:8934.66383934021
batch reward last col mean 0.13358746469020844 first col mean 0.11237713694572449 all mean 0.12610609829425812
0.3321014642715454 0.3321014642715454
rl training, epoch3, iter0, batch414/1133, batch loss:0.3321014642715454, Training time:8936.534775733948
batch reward last col mean 0.1180904358625412 first col mean 0.11172420531511307 all mean 0.11630477011203766
0.32898610830307007 0.32898610830307007
rl training, epoch3, iter0, batch415/1133, batch loss:0.32898610830307007, Training time:8938.64823794365
batch reward last col mean 0.09430065751075745 first col mean 0.11953896284103394 all mean 0.09900034219026566
0.27319419384002686 0.27319419384002686
rl training, epoch3, iter0, batch416/1133, batch loss:0.27319419384002686, Training time:8941.219427585602
batch reward last col mean 0.13876567780971527 first col mean 0.11280866712331772 all mean 0.12750442326068878
0.3233833312988281 0.3233833312988281
rl training, epoch3, iter0, batch417/1133, batch loss:0.3233833312988281, Training time:8943.431941986084
batch reward last col mean 0.14008861780166626 first col mean 0.1031401976943016 all mean 0.13092677295207977
0.3622669577598572 0.3622669577598572
rl training, epoch3, iter0, batch418/1133, batch loss:0.3622669577598572, Training time:8945.462064266205
batch reward last col mean 0.08781153708696365 first col mean 0.12152809649705887 all mean 0.09815109521150589
0.3193188011646271 0.3193188011646271
rl training, epoch3, iter0, batch419/1133, batch loss:0.3193188011646271, Training time:8947.525032043457
batch reward last col mean 0.11421800404787064 first col mean 0.11037657409906387 all mean 0.11229885369539261
0.29831942915916443 0.29831942915916443
rl training, epoch3, iter0, batch420/1133, batch loss:0.29831942915916443, Training time:8949.39456653595
batch reward last col mean 0.10698679089546204 first col mean 0.10931704938411713 all mean 0.10505817830562592
0.2854306697845459 0.2854306697845459
rl training, epoch3, iter0, batch421/1133, batch loss:0.2854306697845459, Training time:8951.428819656372
batch reward last col mean 0.14053259789943695 first col mean 0.11316585540771484 all mean 0.13662375509738922
0.3064577579498291 0.3064577579498291
rl training, epoch3, iter0, batch422/1133, batch loss:0.3064577579498291, Training time:8953.838177204132
batch reward last col mean 0.09598810970783234 first col mean 0.11936316639184952 all mean 0.10307525098323822
0.3141394853591919 0.3141394853591919
rl training, epoch3, iter0, batch423/1133, batch loss:0.3141394853591919, Training time:8955.55954003334
batch reward last col mean 0.09780921041965485 first col mean 0.12385743856430054 all mean 0.10122912377119064
0.3026551604270935 0.3026551604270935
rl training, epoch3, iter0, batch424/1133, batch loss:0.3026551604270935, Training time:8957.580655097961
batch reward last col mean 0.12995031476020813 first col mean 0.10712933540344238 all mean 0.11777685582637787
0.29053160548210144 0.29053160548210144
rl training, epoch3, iter0, batch425/1133, batch loss:0.29053160548210144, Training time:8959.86489725113
batch reward last col mean 0.07153842598199844 first col mean 0.11427918821573257 all mean 0.08418164402246475
0.28921064734458923 0.28921064734458923
rl training, epoch3, iter0, batch426/1133, batch loss:0.28921064734458923, Training time:8961.639337301254
batch reward last col mean 0.11143933236598969 first col mean 0.10831189155578613 all mean 0.11810804158449173
0.3267752230167389 0.3267752230167389
rl training, epoch3, iter0, batch427/1133, batch loss:0.3267752230167389, Training time:8963.505729913712
batch reward last col mean 0.08653229475021362 first col mean 0.11349935084581375 all mean 0.08831815421581268
0.2729746401309967 0.2729746401309967
rl training, epoch3, iter0, batch428/1133, batch loss:0.2729746401309967, Training time:8965.890171051025
batch reward last col mean 0.11928388476371765 first col mean 0.1139233410358429 all mean 0.11088523268699646
0.32653486728668213 0.32653486728668213
rl training, epoch3, iter0, batch429/1133, batch loss:0.32653486728668213, Training time:8968.005930662155
batch reward last col mean 0.11015263199806213 first col mean 0.11468957364559174 all mean 0.10770059376955032
0.299471378326416 0.299471378326416
rl training, epoch3, iter0, batch430/1133, batch loss:0.299471378326416, Training time:8970.58666586876
batch reward last col mean 0.12361866235733032 first col mean 0.1175442561507225 all mean 0.12035952508449554
0.3003541827201843 0.3003541827201843
rl training, epoch3, iter0, batch431/1133, batch loss:0.3003541827201843, Training time:8972.55674123764
batch reward last col mean 0.1206825003027916 first col mean 0.12836125493049622 all mean 0.1180431991815567
0.31131160259246826 0.31131160259246826
rl training, epoch3, iter0, batch432/1133, batch loss:0.31131160259246826, Training time:8974.98101758957
batch reward last col mean 0.13732662796974182 first col mean 0.1271669715642929 all mean 0.13089358806610107
0.34979891777038574 0.34979888796806335
rl training, epoch3, iter0, batch433/1133, batch loss:0.34979888796806335, Training time:8976.848629951477
batch reward last col mean 0.12358161062002182 first col mean 0.11586339771747589 all mean 0.1209012120962143
0.29442286491394043 0.29442286491394043
rl training, epoch3, iter0, batch434/1133, batch loss:0.29442286491394043, Training time:8978.506117105484
batch reward last col mean 0.08703511953353882 first col mean 0.10884574055671692 all mean 0.09502074122428894
0.30698710680007935 0.30698704719543457
rl training, epoch3, iter0, batch435/1133, batch loss:0.30698704719543457, Training time:8980.627269029617
batch reward last col mean 0.13430842757225037 first col mean 0.11706550419330597 all mean 0.13067838549613953
0.34657812118530273 0.34657812118530273
rl training, epoch3, iter0, batch436/1133, batch loss:0.34657812118530273, Training time:8982.408021211624
batch reward last col mean 0.12110870331525803 first col mean 0.108632892370224 all mean 0.12096523493528366
0.33177852630615234 0.33177852630615234
rl training, epoch3, iter0, batch437/1133, batch loss:0.33177852630615234, Training time:8984.601829767227
batch reward last col mean 0.05902007222175598 first col mean 0.12047679722309113 all mean 0.07720757275819778
0.29980072379112244 0.29980072379112244
rl training, epoch3, iter0, batch438/1133, batch loss:0.29980072379112244, Training time:8986.32107257843
batch reward last col mean 0.10818403959274292 first col mean 0.1178722083568573 all mean 0.11035031080245972
0.3321426808834076 0.3321426808834076
rl training, epoch3, iter0, batch439/1133, batch loss:0.3321426808834076, Training time:8988.553342819214
batch reward last col mean 0.09067012369632721 first col mean 0.1310596913099289 all mean 0.1018211767077446
0.29057615995407104 0.29057615995407104
rl training, epoch3, iter0, batch440/1133, batch loss:0.29057615995407104, Training time:8990.547754526138
batch reward last col mean 0.12416660785675049 first col mean 0.11210547387599945 all mean 0.11850894242525101
0.3540380001068115 0.3540380001068115
rl training, epoch3, iter0, batch441/1133, batch loss:0.3540380001068115, Training time:8992.94822025299
batch reward last col mean 0.11719752848148346 first col mean 0.10579518973827362 all mean 0.11130472272634506
0.2978785037994385 0.2978785037994385
rl training, epoch3, iter0, batch442/1133, batch loss:0.2978785037994385, Training time:8994.476702451706
batch reward last col mean 0.1088290810585022 first col mean 0.13111504912376404 all mean 0.112300343811512
0.33292219042778015 0.33292219042778015
rl training, epoch3, iter0, batch443/1133, batch loss:0.33292219042778015, Training time:8996.542917490005
batch reward last col mean 0.13363340497016907 first col mean 0.1039794385433197 all mean 0.12746360898017883
0.3519834280014038 0.3519834280014038
rl training, epoch3, iter0, batch444/1133, batch loss:0.3519834280014038, Training time:8998.49267077446
batch reward last col mean 0.10856065899133682 first col mean 0.13104373216629028 all mean 0.1169019266963005
0.3084537386894226 0.3084537386894226
rl training, epoch3, iter0, batch445/1133, batch loss:0.3084537386894226, Training time:9000.2926902771
batch reward last col mean 0.08772896975278854 first col mean 0.10659757256507874 all mean 0.09288476407527924
0.29401230812072754 0.29401230812072754
rl training, epoch3, iter0, batch446/1133, batch loss:0.29401230812072754, Training time:9002.512313842773
batch reward last col mean 0.10320823639631271 first col mean 0.11670190095901489 all mean 0.10634101182222366
0.28986939787864685 0.28986939787864685
rl training, epoch3, iter0, batch447/1133, batch loss:0.28986939787864685, Training time:9004.58429145813
batch reward last col mean 0.10039885342121124 first col mean 0.11044058948755264 all mean 0.10403783619403839
0.29236510396003723 0.29236510396003723
rl training, epoch3, iter0, batch448/1133, batch loss:0.29236510396003723, Training time:9007.542093992233
batch reward last col mean 0.11441859602928162 first col mean 0.11740882694721222 all mean 0.11547605693340302
0.33137795329093933 0.33137795329093933
rl training, epoch3, iter0, batch449/1133, batch loss:0.33137795329093933, Training time:9010.123720645905
batch reward last col mean 0.1013248935341835 first col mean 0.11270856112241745 all mean 0.10508468002080917
0.3041985034942627 0.3041985034942627
rl training, epoch3, iter0, batch450/1133, batch loss:0.3041985034942627, Training time:9012.730166435242
batch reward last col mean 0.1020110696554184 first col mean 0.11266157031059265 all mean 0.10893341153860092
0.3330232799053192 0.3330232799053192
rl training, epoch3, iter0, batch451/1133, batch loss:0.3330232799053192, Training time:9014.355117082596
batch reward last col mean 0.11404766887426376 first col mean 0.10132784396409988 all mean 0.10815759748220444
0.28153398633003235 0.28153398633003235
rl training, epoch3, iter0, batch452/1133, batch loss:0.28153398633003235, Training time:9016.93467926979
batch reward last col mean 0.08239108324050903 first col mean 0.12120401859283447 all mean 0.09295888990163803
0.32729676365852356 0.32729676365852356
rl training, epoch3, iter0, batch453/1133, batch loss:0.32729676365852356, Training time:9019.028540611267
batch reward last col mean 0.10578246414661407 first col mean 0.1262827068567276 all mean 0.11004150658845901
0.3379852771759033 0.3379852771759033
rl training, epoch3, iter0, batch454/1133, batch loss:0.3379852771759033, Training time:9020.803337812424
batch reward last col mean 0.1156272441148758 first col mean 0.12085891515016556 all mean 0.10805962979793549
0.3332553803920746 0.3332553803920746
rl training, epoch3, iter0, batch455/1133, batch loss:0.3332553803920746, Training time:9022.383426427841
batch reward last col mean 0.10636075586080551 first col mean 0.1035243570804596 all mean 0.10948923975229263
0.2885764241218567 0.2885764241218567
rl training, epoch3, iter0, batch456/1133, batch loss:0.2885764241218567, Training time:9024.903483867645
batch reward last col mean 0.09750740975141525 first col mean 0.11382187902927399 all mean 0.10412769764661789
0.3229231834411621 0.3229231834411621
rl training, epoch3, iter0, batch457/1133, batch loss:0.3229231834411621, Training time:9027.184203386307
batch reward last col mean 0.08519162237644196 first col mean 0.11555470526218414 all mean 0.08943988382816315
0.2838471829891205 0.2838471829891205
rl training, epoch3, iter0, batch458/1133, batch loss:0.2838471829891205, Training time:9029.433773040771
batch reward last col mean 0.11153779923915863 first col mean 0.11970128864049911 all mean 0.11492501199245453
0.2944127917289734 0.2944127917289734
rl training, epoch3, iter0, batch459/1133, batch loss:0.2944127917289734, Training time:9031.475739717484
batch reward last col mean 0.10092766582965851 first col mean 0.10892447829246521 all mean 0.10786739736795425
0.3231666386127472 0.3231666386127472
rl training, epoch3, iter0, batch460/1133, batch loss:0.3231666386127472, Training time:9033.36915230751
batch reward last col mean 0.08549421280622482 first col mean 0.12612497806549072 all mean 0.09605911374092102
0.3583548665046692 0.3583548665046692
rl training, epoch3, iter0, batch461/1133, batch loss:0.3583548665046692, Training time:9035.300107717514
batch reward last col mean 0.127564936876297 first col mean 0.12700219452381134 all mean 0.1235717386007309
0.34683936834335327 0.34683936834335327
rl training, epoch3, iter0, batch462/1133, batch loss:0.34683936834335327, Training time:9037.322985649109
batch reward last col mean 0.1259758174419403 first col mean 0.11758382618427277 all mean 0.125010684132576
0.32068556547164917 0.32068556547164917
rl training, epoch3, iter0, batch463/1133, batch loss:0.32068556547164917, Training time:9039.075936079025
batch reward last col mean 0.11617565155029297 first col mean 0.1283596158027649 all mean 0.11594691872596741
0.31587105989456177 0.31587105989456177
rl training, epoch3, iter0, batch464/1133, batch loss:0.31587105989456177, Training time:9042.309573888779
batch reward last col mean 0.1066860631108284 first col mean 0.09627408534288406 all mean 0.10445895791053772
0.30283206701278687 0.30283206701278687
rl training, epoch3, iter0, batch465/1133, batch loss:0.30283206701278687, Training time:9044.472774267197
batch reward last col mean 0.11181160062551498 first col mean 0.11957015097141266 all mean 0.11494243890047073
0.3571072220802307 0.3571072220802307
rl training, epoch3, iter0, batch466/1133, batch loss:0.3571072220802307, Training time:9046.56845831871
batch reward last col mean 0.094899982213974 first col mean 0.11219286918640137 all mean 0.10307875275611877
0.31006109714508057 0.31006109714508057
rl training, epoch3, iter0, batch467/1133, batch loss:0.31006109714508057, Training time:9048.506647825241
batch reward last col mean 0.0734102874994278 first col mean 0.11216436326503754 all mean 0.08889235556125641
0.2872784733772278 0.2872784733772278
rl training, epoch3, iter0, batch468/1133, batch loss:0.2872784733772278, Training time:9050.42573094368
batch reward last col mean 0.11599159240722656 first col mean 0.11982857435941696 all mean 0.11699843406677246
0.39386412501335144 0.39386412501335144
rl training, epoch3, iter0, batch469/1133, batch loss:0.39386412501335144, Training time:9052.363247156143
batch reward last col mean 0.10622922331094742 first col mean 0.11682158708572388 all mean 0.10878896713256836
0.36793485283851624 0.36793485283851624
rl training, epoch3, iter0, batch470/1133, batch loss:0.36793485283851624, Training time:9054.455882549286
batch reward last col mean 0.11348925530910492 first col mean 0.12076552212238312 all mean 0.11410583555698395
0.32823628187179565 0.32823631167411804
rl training, epoch3, iter0, batch471/1133, batch loss:0.32823631167411804, Training time:9056.570099830627
batch reward last col mean 0.10705564171075821 first col mean 0.1403355747461319 all mean 0.11527077108621597
0.29640811681747437 0.29640811681747437
rl training, epoch3, iter0, batch472/1133, batch loss:0.29640811681747437, Training time:9058.462799549103
batch reward last col mean 0.12218649685382843 first col mean 0.1275274008512497 all mean 0.1228547915816307
0.35614243149757385 0.35614243149757385
rl training, epoch3, iter0, batch473/1133, batch loss:0.35614243149757385, Training time:9060.886255264282
batch reward last col mean 0.0999089702963829 first col mean 0.12060186266899109 all mean 0.10905525088310242
0.3778032660484314 0.3778032660484314
rl training, epoch3, iter0, batch474/1133, batch loss:0.3778032660484314, Training time:9063.44644498825
batch reward last col mean 0.10820899903774261 first col mean 0.12317251414060593 all mean 0.10816865414381027
0.3299960196018219 0.3299960196018219
rl training, epoch3, iter0, batch475/1133, batch loss:0.3299960196018219, Training time:9065.258791923523
batch reward last col mean 0.11621159315109253 first col mean 0.12370938062667847 all mean 0.11947645992040634
0.36865729093551636 0.36865729093551636
rl training, epoch3, iter0, batch476/1133, batch loss:0.36865729093551636, Training time:9066.967164516449
batch reward last col mean 0.08618036657571793 first col mean 0.11640962958335876 all mean 0.10187682509422302
0.3157012462615967 0.31570130586624146
rl training, epoch3, iter0, batch477/1133, batch loss:0.31570130586624146, Training time:9068.787391662598
batch reward last col mean 0.11164627224206924 first col mean 0.11265404522418976 all mean 0.1149524375796318
0.3597511649131775 0.3597511649131775
rl training, epoch3, iter0, batch478/1133, batch loss:0.3597511649131775, Training time:9070.829967975616
batch reward last col mean 0.09741588681936264 first col mean 0.10535425692796707 all mean 0.1031232699751854
0.3092164695262909 0.3092164397239685
rl training, epoch3, iter0, batch479/1133, batch loss:0.3092164397239685, Training time:9072.790392160416
batch reward last col mean 0.10001464188098907 first col mean 0.10736654698848724 all mean 0.1086336001753807
0.29015207290649414 0.29015207290649414
rl training, epoch3, iter0, batch480/1133, batch loss:0.29015207290649414, Training time:9075.293761968613
batch reward last col mean 0.1295967996120453 first col mean 0.1222022995352745 all mean 0.12880393862724304
0.34630122780799866 0.34630122780799866
rl training, epoch3, iter0, batch481/1133, batch loss:0.34630122780799866, Training time:9077.75991988182
batch reward last col mean 0.08827927708625793 first col mean 0.11899829655885696 all mean 0.09299721568822861
0.31412777304649353 0.31412777304649353
rl training, epoch3, iter0, batch482/1133, batch loss:0.31412777304649353, Training time:9079.748283863068
batch reward last col mean 0.08254736661911011 first col mean 0.1026076152920723 all mean 0.09044753015041351
0.29132726788520813 0.29132726788520813
rl training, epoch3, iter0, batch483/1133, batch loss:0.29132726788520813, Training time:9081.667400836945
batch reward last col mean 0.1287248283624649 first col mean 0.13678601384162903 all mean 0.12612980604171753
0.3616980314254761 0.3616980314254761
rl training, epoch3, iter0, batch484/1133, batch loss:0.3616980314254761, Training time:9084.266041994095
batch reward last col mean 0.11403611302375793 first col mean 0.10460592061281204 all mean 0.11388721317052841
0.3352968990802765 0.3352968990802765
rl training, epoch3, iter0, batch485/1133, batch loss:0.3352968990802765, Training time:9086.202288866043
batch reward last col mean 0.11798704415559769 first col mean 0.13689103722572327 all mean 0.1186293438076973
0.3396803140640259 0.3396803140640259
rl training, epoch3, iter0, batch486/1133, batch loss:0.3396803140640259, Training time:9088.584656953812
batch reward last col mean 0.11776226758956909 first col mean 0.10704533755779266 all mean 0.11969994008541107
0.33023273944854736 0.33023273944854736
rl training, epoch3, iter0, batch487/1133, batch loss:0.33023273944854736, Training time:9091.643153429031
batch reward last col mean 0.12045903503894806 first col mean 0.1104707345366478 all mean 0.11980310082435608
0.3137405812740326 0.3137405812740326
rl training, epoch3, iter0, batch488/1133, batch loss:0.3137405812740326, Training time:9093.784520149231
batch reward last col mean 0.11003934592008591 first col mean 0.11755859851837158 all mean 0.11175616085529327
0.35156509280204773 0.35156509280204773
rl training, epoch3, iter0, batch489/1133, batch loss:0.35156509280204773, Training time:9095.954721927643
batch reward last col mean 0.12631474435329437 first col mean 0.12908904254436493 all mean 0.12276492267847061
0.33584362268447876 0.33584362268447876
rl training, epoch3, iter0, batch490/1133, batch loss:0.33584362268447876, Training time:9098.47867155075
batch reward last col mean 0.10014783591032028 first col mean 0.1086917594075203 all mean 0.10050055384635925
0.32142722606658936 0.32142722606658936
rl training, epoch3, iter0, batch491/1133, batch loss:0.32142722606658936, Training time:9101.136501073837
batch reward last col mean 0.0822204127907753 first col mean 0.13110311329364777 all mean 0.08883700519800186
0.247941792011261 0.247941792011261
rl training, epoch3, iter0, batch492/1133, batch loss:0.247941792011261, Training time:9103.550941228867
batch reward last col mean 0.1498049646615982 first col mean 0.11855708062648773 all mean 0.1419336050748825
0.3356500566005707 0.3356500566005707
rl training, epoch3, iter0, batch493/1133, batch loss:0.3356500566005707, Training time:9106.473004102707
batch reward last col mean 0.10254107415676117 first col mean 0.13219694793224335 all mean 0.10533726215362549
0.3385525643825531 0.3385525643825531
rl training, epoch3, iter0, batch494/1133, batch loss:0.3385525643825531, Training time:9109.918105125427
batch reward last col mean 0.0879325419664383 first col mean 0.1386769711971283 all mean 0.1045682281255722
0.31121447682380676 0.31121447682380676
rl training, epoch3, iter0, batch495/1133, batch loss:0.31121447682380676, Training time:9111.695749759674
batch reward last col mean 0.1432344764471054 first col mean 0.10094697028398514 all mean 0.13340958952903748
0.31193652749061584 0.31193652749061584
rl training, epoch3, iter0, batch496/1133, batch loss:0.31193652749061584, Training time:9113.974209070206
batch reward last col mean 0.1064736545085907 first col mean 0.10338667035102844 all mean 0.10794030874967575
0.30084288120269775 0.30084288120269775
rl training, epoch3, iter0, batch497/1133, batch loss:0.30084288120269775, Training time:9116.334919214249
batch reward last col mean 0.117833212018013 first col mean 0.12423096597194672 all mean 0.11302246898412704
0.33869442343711853 0.33869442343711853
rl training, epoch3, iter0, batch498/1133, batch loss:0.33869442343711853, Training time:9118.12344956398
batch reward last col mean 0.13957524299621582 first col mean 0.11214985698461533 all mean 0.13870510458946228
0.35795465111732483 0.35795465111732483
rl training, epoch3, iter0, batch499/1133, batch loss:0.35795465111732483, Training time:9121.17152094841
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5462588900396073 Time: 101.15018820762634 s
loss of true 0.24030871756394565 loss of gen 0.19369705615191996 loss of other 0.11225311623003403 first score 0.12162420898675919
batch reward last col mean 0.10898652672767639 first col mean 0.10415246337652206 all mean 0.11146765947341919
0.35185909271240234 0.35185909271240234
rl training, epoch3, iter0, batch500/1133, batch loss:0.35185909271240234, Training time:9224.12000632286
batch reward last col mean 0.09957689046859741 first col mean 0.09909626841545105 all mean 0.10210377722978592
0.28745847940444946 0.28745850920677185
rl training, epoch3, iter0, batch501/1133, batch loss:0.28745850920677185, Training time:9226.165807008743
batch reward last col mean 0.13007968664169312 first col mean 0.10375309735536575 all mean 0.1230066567659378
0.32725614309310913 0.32725614309310913
rl training, epoch3, iter0, batch502/1133, batch loss:0.32725614309310913, Training time:9228.043695926666
batch reward last col mean 0.11178469657897949 first col mean 0.11406148970127106 all mean 0.10802856087684631
0.3267694115638733 0.3267694115638733
rl training, epoch3, iter0, batch503/1133, batch loss:0.3267694115638733, Training time:9229.835692167282
batch reward last col mean 0.09820202738046646 first col mean 0.10257384181022644 all mean 0.10557064414024353
0.2788909375667572 0.2788909375667572
rl training, epoch3, iter0, batch504/1133, batch loss:0.2788909375667572, Training time:9232.065927028656
batch reward last col mean 0.0946589857339859 first col mean 0.10382121801376343 all mean 0.10021430253982544
0.3077634274959564 0.3077634274959564
rl training, epoch3, iter0, batch505/1133, batch loss:0.3077634274959564, Training time:9234.094512224197
batch reward last col mean 0.1278601437807083 first col mean 0.10926277935504913 all mean 0.1266515702009201
0.35164159536361694 0.35164159536361694
rl training, epoch3, iter0, batch506/1133, batch loss:0.35164159536361694, Training time:9236.705407857895
batch reward last col mean 0.12033012509346008 first col mean 0.12428325414657593 all mean 0.11889812350273132
0.32559794187545776 0.32559794187545776
rl training, epoch3, iter0, batch507/1133, batch loss:0.32559794187545776, Training time:9238.639201164246
batch reward last col mean 0.09165630489587784 first col mean 0.10618224740028381 all mean 0.10135449469089508
0.306270956993103 0.306270956993103
rl training, epoch3, iter0, batch508/1133, batch loss:0.306270956993103, Training time:9240.693922519684
batch reward last col mean 0.09651554375886917 first col mean 0.11387698352336884 all mean 0.10472045093774796
0.31400585174560547 0.31400585174560547
rl training, epoch3, iter0, batch509/1133, batch loss:0.31400585174560547, Training time:9243.103285312653
batch reward last col mean 0.0889207050204277 first col mean 0.12830211222171783 all mean 0.09305945783853531
0.3152255415916443 0.3152255415916443
rl training, epoch3, iter0, batch510/1133, batch loss:0.3152255415916443, Training time:9246.008856773376
batch reward last col mean 0.12217378616333008 first col mean 0.12228482961654663 all mean 0.12450646609067917
0.34564608335494995 0.34564608335494995
rl training, epoch3, iter0, batch511/1133, batch loss:0.34564608335494995, Training time:9248.090688228607
batch reward last col mean 0.09053933620452881 first col mean 0.11906648427248001 all mean 0.09928898513317108
0.3344275951385498 0.3344275951385498
rl training, epoch3, iter0, batch512/1133, batch loss:0.3344275951385498, Training time:9250.224080562592
batch reward last col mean 0.10910820215940475 first col mean 0.11167310178279877 all mean 0.10160104185342789
0.3020234704017639 0.3020234704017639
rl training, epoch3, iter0, batch513/1133, batch loss:0.3020234704017639, Training time:9251.821154594421
batch reward last col mean 0.12954196333885193 first col mean 0.1349930763244629 all mean 0.12726174294948578
0.3424663245677948 0.3424663245677948
rl training, epoch3, iter0, batch514/1133, batch loss:0.3424663245677948, Training time:9254.29260468483
batch reward last col mean 0.11785018444061279 first col mean 0.11568339169025421 all mean 0.11390691250562668
0.30824387073516846 0.30824387073516846
rl training, epoch3, iter0, batch515/1133, batch loss:0.30824387073516846, Training time:9256.293861865997
batch reward last col mean 0.09943300485610962 first col mean 0.1110810786485672 all mean 0.10000801831483841
0.31173598766326904 0.31173595786094666
rl training, epoch3, iter0, batch516/1133, batch loss:0.31173595786094666, Training time:9258.153735876083
batch reward last col mean 0.11180901527404785 first col mean 0.11939163506031036 all mean 0.10666551440954208
0.31084463000297546 0.3108446002006531
rl training, epoch3, iter0, batch517/1133, batch loss:0.3108446002006531, Training time:9260.063863992691
batch reward last col mean 0.11365167796611786 first col mean 0.12655122578144073 all mean 0.11491027474403381
0.34904366731643677 0.34904366731643677
rl training, epoch3, iter0, batch518/1133, batch loss:0.34904366731643677, Training time:9262.11114358902
batch reward last col mean 0.0981789231300354 first col mean 0.11715976148843765 all mean 0.10588902235031128
0.38877108693122864 0.38877108693122864
rl training, epoch3, iter0, batch519/1133, batch loss:0.38877108693122864, Training time:9264.011468172073
batch reward last col mean 0.09489529579877853 first col mean 0.12390787899494171 all mean 0.1030363142490387
0.35770153999328613 0.35770153999328613
rl training, epoch3, iter0, batch520/1133, batch loss:0.35770153999328613, Training time:9266.157191514969
batch reward last col mean 0.11826558411121368 first col mean 0.11533129215240479 all mean 0.11742450296878815
0.3429674208164215 0.3429674208164215
rl training, epoch3, iter0, batch521/1133, batch loss:0.3429674208164215, Training time:9268.746882677078
batch reward last col mean 0.09008540958166122 first col mean 0.1062927171587944 all mean 0.10077305883169174
0.30881133675575256 0.30881133675575256
rl training, epoch3, iter0, batch522/1133, batch loss:0.30881133675575256, Training time:9270.684200525284
batch reward last col mean 0.097307488322258 first col mean 0.12435396015644073 all mean 0.10748124122619629
0.31512850522994995 0.31512847542762756
rl training, epoch3, iter0, batch523/1133, batch loss:0.31512847542762756, Training time:9273.358257055283
batch reward last col mean 0.13093145191669464 first col mean 0.11242262274026871 all mean 0.1269593983888626
0.3720346987247467 0.3720346987247467
rl training, epoch3, iter0, batch524/1133, batch loss:0.3720346987247467, Training time:9275.457290172577
batch reward last col mean 0.12772056460380554 first col mean 0.11516847461462021 all mean 0.12907327711582184
0.3350902795791626 0.3350903391838074
rl training, epoch3, iter0, batch525/1133, batch loss:0.3350903391838074, Training time:9277.524631977081
batch reward last col mean 0.10846499353647232 first col mean 0.1253744214773178 all mean 0.11021167039871216
0.299672394990921 0.29967236518859863
rl training, epoch3, iter0, batch526/1133, batch loss:0.29967236518859863, Training time:9279.477858066559
batch reward last col mean 0.11711274087429047 first col mean 0.1122698113322258 all mean 0.11627145111560822
0.3059018850326538 0.3059018850326538
rl training, epoch3, iter0, batch527/1133, batch loss:0.3059018850326538, Training time:9281.934769153595
batch reward last col mean 0.10725577920675278 first col mean 0.11814050376415253 all mean 0.10874559730291367
0.34109750390052795 0.34109750390052795
rl training, epoch3, iter0, batch528/1133, batch loss:0.34109750390052795, Training time:9283.684958219528
batch reward last col mean 0.11068902909755707 first col mean 0.1307782232761383 all mean 0.11520993709564209
0.32165980339050293 0.3216598331928253
rl training, epoch3, iter0, batch529/1133, batch loss:0.3216598331928253, Training time:9285.880588293076
batch reward last col mean 0.11912210285663605 first col mean 0.11334532499313354 all mean 0.11886610090732574
0.35650965571403503 0.35650965571403503
rl training, epoch3, iter0, batch530/1133, batch loss:0.35650965571403503, Training time:9288.247646808624
batch reward last col mean 0.1315191090106964 first col mean 0.12039133161306381 all mean 0.1286761462688446
0.3384436368942261 0.3384436368942261
rl training, epoch3, iter0, batch531/1133, batch loss:0.3384436368942261, Training time:9290.12348484993
batch reward last col mean 0.12551026046276093 first col mean 0.10997644066810608 all mean 0.1265726387500763
0.39317044615745544 0.39317044615745544
rl training, epoch3, iter0, batch532/1133, batch loss:0.39317044615745544, Training time:9292.138441562653
batch reward last col mean 0.09989213943481445 first col mean 0.11802935600280762 all mean 0.10649501532316208
0.3001064956188202 0.3001064956188202
rl training, epoch3, iter0, batch533/1133, batch loss:0.3001064956188202, Training time:9293.847574710846
batch reward last col mean 0.10402843356132507 first col mean 0.1251508742570877 all mean 0.11193110048770905
0.3314431607723236 0.3314431607723236
rl training, epoch3, iter0, batch534/1133, batch loss:0.3314431607723236, Training time:9295.773842096329
batch reward last col mean 0.17688605189323425 first col mean 0.11670660972595215 all mean 0.16294030845165253
0.3357648551464081 0.3357648551464081
rl training, epoch3, iter0, batch535/1133, batch loss:0.3357648551464081, Training time:9298.019731760025
batch reward last col mean 0.10534608364105225 first col mean 0.12686321139335632 all mean 0.10840336233377457
0.32033541798591614 0.32033541798591614
rl training, epoch3, iter0, batch536/1133, batch loss:0.32033541798591614, Training time:9300.081901073456
batch reward last col mean 0.12382276356220245 first col mean 0.10901830345392227 all mean 0.12329045683145523
0.33208879828453064 0.33208879828453064
rl training, epoch3, iter0, batch537/1133, batch loss:0.33208879828453064, Training time:9302.127298116684
batch reward last col mean 0.1297779232263565 first col mean 0.1314133107662201 all mean 0.13162001967430115
0.3633340001106262 0.3633340001106262
rl training, epoch3, iter0, batch538/1133, batch loss:0.3633340001106262, Training time:9303.990605831146
batch reward last col mean 0.09495510160923004 first col mean 0.12484478950500488 all mean 0.10344287008047104
0.3141091465950012 0.3141091465950012
rl training, epoch3, iter0, batch539/1133, batch loss:0.3141091465950012, Training time:9305.980639457703
batch reward last col mean 0.1055004671216011 first col mean 0.10767068713903427 all mean 0.11005161702632904
0.28488871455192566 0.28488871455192566
rl training, epoch3, iter0, batch540/1133, batch loss:0.28488871455192566, Training time:9308.010833978653
batch reward last col mean 0.10295552760362625 first col mean 0.11073315143585205 all mean 0.10951147228479385
0.3227494955062866 0.3227494955062866
rl training, epoch3, iter0, batch541/1133, batch loss:0.3227494955062866, Training time:9309.910054206848
batch reward last col mean 0.08072848618030548 first col mean 0.13328084349632263 all mean 0.09135209023952484
0.26451432704925537 0.26451432704925537
rl training, epoch3, iter0, batch542/1133, batch loss:0.26451432704925537, Training time:9312.003832817078
batch reward last col mean 0.14815422892570496 first col mean 0.11317476630210876 all mean 0.13990595936775208
0.355459988117218 0.35545992851257324
rl training, epoch3, iter0, batch543/1133, batch loss:0.35545992851257324, Training time:9314.364264726639
batch reward last col mean 0.15141411125659943 first col mean 0.11660236865282059 all mean 0.13728252053260803
0.3625583052635193 0.3625583052635193
rl training, epoch3, iter0, batch544/1133, batch loss:0.3625583052635193, Training time:9316.988229990005
batch reward last col mean 0.08581558614969254 first col mean 0.12459646910429001 all mean 0.0955536887049675
0.32196044921875 0.3219604790210724
rl training, epoch3, iter0, batch545/1133, batch loss:0.3219604790210724, Training time:9318.912499427795
batch reward last col mean 0.115807443857193 first col mean 0.12062238156795502 all mean 0.1111561581492424
0.277726411819458 0.277726411819458
rl training, epoch3, iter0, batch546/1133, batch loss:0.277726411819458, Training time:9320.76834321022
batch reward last col mean 0.11938236653804779 first col mean 0.12267358601093292 all mean 0.12132491916418076
0.3262939751148224 0.3262939453125
rl training, epoch3, iter0, batch547/1133, batch loss:0.3262939453125, Training time:9322.512965202332
batch reward last col mean 0.1115056574344635 first col mean 0.1475859135389328 all mean 0.10956622660160065
0.3108256459236145 0.3108256459236145
rl training, epoch3, iter0, batch548/1133, batch loss:0.3108256459236145, Training time:9324.50477194786
batch reward last col mean 0.1433301866054535 first col mean 0.10932612419128418 all mean 0.13363385200500488
0.33667516708374023 0.33667516708374023
rl training, epoch3, iter0, batch549/1133, batch loss:0.33667516708374023, Training time:9326.553738117218
batch reward last col mean 0.15135341882705688 first col mean 0.1156356930732727 all mean 0.14270493388175964
0.33087825775146484 0.33087822794914246
rl training, epoch3, iter0, batch550/1133, batch loss:0.33087822794914246, Training time:9328.988288640976
batch reward last col mean 0.11150259524583817 first col mean 0.11713175475597382 all mean 0.11167752742767334
0.3105776906013489 0.3105776906013489
rl training, epoch3, iter0, batch551/1133, batch loss:0.3105776906013489, Training time:9330.733489751816
batch reward last col mean 0.15637093782424927 first col mean 0.11645336449146271 all mean 0.14838238060474396
0.3684219419956207 0.3684219419956207
rl training, epoch3, iter0, batch552/1133, batch loss:0.3684219419956207, Training time:9332.673426628113
batch reward last col mean 0.13132637739181519 first col mean 0.12777970731258392 all mean 0.12494560331106186
0.3191692531108856 0.3191692531108856
rl training, epoch3, iter0, batch553/1133, batch loss:0.3191692531108856, Training time:9334.47639298439
batch reward last col mean 0.1101057305932045 first col mean 0.12133225798606873 all mean 0.11331351846456528
0.32089558243751526 0.32089558243751526
rl training, epoch3, iter0, batch554/1133, batch loss:0.32089558243751526, Training time:9336.159015655518
batch reward last col mean 0.07333359867334366 first col mean 0.10487277805805206 all mean 0.08669255673885345
0.28110605478286743 0.2811060845851898
rl training, epoch3, iter0, batch555/1133, batch loss:0.2811060845851898, Training time:9338.137795209885
batch reward last col mean 0.11980685591697693 first col mean 0.11691868305206299 all mean 0.12190837413072586
0.32356563210487366 0.32356563210487366
rl training, epoch3, iter0, batch556/1133, batch loss:0.32356563210487366, Training time:9339.980774641037
batch reward last col mean 0.09377594292163849 first col mean 0.11659303307533264 all mean 0.10112954676151276
0.34012937545776367 0.34012940526008606
rl training, epoch3, iter0, batch557/1133, batch loss:0.34012940526008606, Training time:9341.63441824913
batch reward last col mean 0.130349263548851 first col mean 0.1384568214416504 all mean 0.1289856880903244
0.3665415942668915 0.3665415942668915
rl training, epoch3, iter0, batch558/1133, batch loss:0.3665415942668915, Training time:9343.575665712357
batch reward last col mean 0.1004912406206131 first col mean 0.11792118102312088 all mean 0.09909024834632874
0.30701518058776855 0.30701518058776855
rl training, epoch3, iter0, batch559/1133, batch loss:0.30701518058776855, Training time:9345.14456486702
batch reward last col mean 0.12612533569335938 first col mean 0.1235944852232933 all mean 0.1272292137145996
0.32964006066322327 0.32964006066322327
rl training, epoch3, iter0, batch560/1133, batch loss:0.32964006066322327, Training time:9346.826430559158
batch reward last col mean 0.11675629764795303 first col mean 0.11503475904464722 all mean 0.11686626076698303
0.3532724678516388 0.3532724678516388
rl training, epoch3, iter0, batch561/1133, batch loss:0.3532724678516388, Training time:9348.411529302597
batch reward last col mean 0.09894411265850067 first col mean 0.11007113754749298 all mean 0.09746968001127243
0.2874866724014282 0.2874866724014282
rl training, epoch3, iter0, batch562/1133, batch loss:0.2874866724014282, Training time:9349.804434537888
batch reward last col mean 0.11583354324102402 first col mean 0.1295611560344696 all mean 0.12495457381010056
0.3690864145755768 0.369086354970932
rl training, epoch3, iter0, batch563/1133, batch loss:0.369086354970932, Training time:9352.08881855011
batch reward last col mean 0.10880833864212036 first col mean 0.11811552196741104 all mean 0.112323097884655
0.33183562755584717 0.3318355977535248
rl training, epoch3, iter0, batch564/1133, batch loss:0.3318355977535248, Training time:9353.797564983368
batch reward last col mean 0.11972102522850037 first col mean 0.11498738080263138 all mean 0.11983653903007507
0.30308181047439575 0.30308181047439575
rl training, epoch3, iter0, batch565/1133, batch loss:0.30308181047439575, Training time:9355.792073249817
batch reward last col mean 0.10985361039638519 first col mean 0.11511580646038055 all mean 0.11584442108869553
0.3254883289337158 0.3254883289337158
rl training, epoch3, iter0, batch566/1133, batch loss:0.3254883289337158, Training time:9357.656638383865
batch reward last col mean 0.11626091599464417 first col mean 0.11741086840629578 all mean 0.12016473710536957
0.3082907795906067 0.3082907497882843
rl training, epoch3, iter0, batch567/1133, batch loss:0.3082907497882843, Training time:9359.377908706665
batch reward last col mean 0.1000511571764946 first col mean 0.11135929822921753 all mean 0.10527817159891129
0.3015177547931671 0.3015177547931671
rl training, epoch3, iter0, batch568/1133, batch loss:0.3015177547931671, Training time:9361.268736124039
batch reward last col mean 0.10521797835826874 first col mean 0.11124839633703232 all mean 0.10625500977039337
0.30927348136901855 0.30927348136901855
rl training, epoch3, iter0, batch569/1133, batch loss:0.30927348136901855, Training time:9363.120663881302
batch reward last col mean 0.09569155424833298 first col mean 0.11579733341932297 all mean 0.10062889754772186
0.28181540966033936 0.28181540966033936
rl training, epoch3, iter0, batch570/1133, batch loss:0.28181540966033936, Training time:9364.939036607742
batch reward last col mean 0.09990342706441879 first col mean 0.11795245110988617 all mean 0.10170896351337433
0.27864640951156616 0.27864640951156616
rl training, epoch3, iter0, batch571/1133, batch loss:0.27864640951156616, Training time:9366.707423686981
batch reward last col mean 0.0870596170425415 first col mean 0.11902490258216858 all mean 0.10115053504705429
0.3230561316013336 0.323056161403656
rl training, epoch3, iter0, batch572/1133, batch loss:0.323056161403656, Training time:9368.568404912949
batch reward last col mean 0.12772151827812195 first col mean 0.11672106385231018 all mean 0.1241147369146347
0.3581255376338959 0.3581255376338959
rl training, epoch3, iter0, batch573/1133, batch loss:0.3581255376338959, Training time:9371.039722919464
batch reward last col mean 0.08992034196853638 first col mean 0.12298502027988434 all mean 0.09688257426023483
0.3323349058628082 0.3323349058628082
rl training, epoch3, iter0, batch574/1133, batch loss:0.3323349058628082, Training time:9372.579960823059
batch reward last col mean 0.1065811738371849 first col mean 0.11211077868938446 all mean 0.11021241545677185
0.30003494024276733 0.30003494024276733
rl training, epoch3, iter0, batch575/1133, batch loss:0.30003494024276733, Training time:9374.532802581787
batch reward last col mean 0.14266729354858398 first col mean 0.11559551954269409 all mean 0.12984032928943634
0.3108556568622589 0.3108556568622589
rl training, epoch3, iter0, batch576/1133, batch loss:0.3108556568622589, Training time:9376.199153661728
batch reward last col mean 0.10583876073360443 first col mean 0.12348389625549316 all mean 0.11103065311908722
0.35597679018974304 0.35597679018974304
rl training, epoch3, iter0, batch577/1133, batch loss:0.35597679018974304, Training time:9378.008751630783
batch reward last col mean 0.10928208380937576 first col mean 0.1167636588215828 all mean 0.11129336804151535
0.32674509286880493 0.32674506306648254
rl training, epoch3, iter0, batch578/1133, batch loss:0.32674506306648254, Training time:9380.290983915329
batch reward last col mean 0.12696634232997894 first col mean 0.12210492789745331 all mean 0.12492824345827103
0.3031826913356781 0.3031826913356781
rl training, epoch3, iter0, batch579/1133, batch loss:0.3031826913356781, Training time:9382.247647285461
batch reward last col mean 0.14354059100151062 first col mean 0.12859845161437988 all mean 0.13680236041545868
0.3784709870815277 0.3784709572792053
rl training, epoch3, iter0, batch580/1133, batch loss:0.3784709572792053, Training time:9384.05182003975
batch reward last col mean 0.1274944245815277 first col mean 0.12708762288093567 all mean 0.13273842632770538
0.36646568775177 0.36646568775177
rl training, epoch3, iter0, batch581/1133, batch loss:0.36646568775177, Training time:9385.572241544724
batch reward last col mean 0.14138144254684448 first col mean 0.13751819729804993 all mean 0.13092108070850372
0.35234585404396057 0.3523458242416382
rl training, epoch3, iter0, batch582/1133, batch loss:0.3523458242416382, Training time:9387.906845092773
batch reward last col mean 0.08075177669525146 first col mean 0.10709928721189499 all mean 0.08858722448348999
0.29586419463157654 0.29586416482925415
rl training, epoch3, iter0, batch583/1133, batch loss:0.29586416482925415, Training time:9389.93703842163
batch reward last col mean 0.10629002004861832 first col mean 0.12607866525650024 all mean 0.11132334917783737
0.34159529209136963 0.34159529209136963
rl training, epoch3, iter0, batch584/1133, batch loss:0.34159529209136963, Training time:9391.590668678284
batch reward last col mean 0.10245601832866669 first col mean 0.14422273635864258 all mean 0.11348391324281693
0.35311636328697205 0.35311636328697205
rl training, epoch3, iter0, batch585/1133, batch loss:0.35311636328697205, Training time:9393.503109455109
batch reward last col mean 0.14325961470603943 first col mean 0.1196356937289238 all mean 0.13963140547275543
0.38491392135620117 0.38491392135620117
rl training, epoch3, iter0, batch586/1133, batch loss:0.38491392135620117, Training time:9395.625126123428
batch reward last col mean 0.09327912330627441 first col mean 0.13288885354995728 all mean 0.10156143456697464
0.31338995695114136 0.31338995695114136
rl training, epoch3, iter0, batch587/1133, batch loss:0.31338995695114136, Training time:9398.374869585037
batch reward last col mean 0.13806015253067017 first col mean 0.13267597556114197 all mean 0.1319456547498703
0.30899736285209656 0.30899736285209656
rl training, epoch3, iter0, batch588/1133, batch loss:0.30899736285209656, Training time:9400.459589719772
batch reward last col mean 0.14944255352020264 first col mean 0.12670446932315826 all mean 0.14545296132564545
0.3687411844730377 0.3687411844730377
rl training, epoch3, iter0, batch589/1133, batch loss:0.3687411844730377, Training time:9402.28899526596
batch reward last col mean 0.15024812519550323 first col mean 0.11541645973920822 all mean 0.14099252223968506
0.3577375113964081 0.3577375113964081
rl training, epoch3, iter0, batch590/1133, batch loss:0.3577375113964081, Training time:9404.76455116272
batch reward last col mean 0.09333591163158417 first col mean 0.126060351729393 all mean 0.10864099860191345
0.35663601756095886 0.35663601756095886
rl training, epoch3, iter0, batch591/1133, batch loss:0.35663601756095886, Training time:9406.779745340347
batch reward last col mean 0.11896875500679016 first col mean 0.11893002688884735 all mean 0.12494200468063354
0.3606967329978943 0.3606967031955719
rl training, epoch3, iter0, batch592/1133, batch loss:0.3606967031955719, Training time:9408.921443939209
batch reward last col mean 0.11999322474002838 first col mean 0.12107738852500916 all mean 0.12059237062931061
0.34513673186302185 0.34513673186302185
rl training, epoch3, iter0, batch593/1133, batch loss:0.34513673186302185, Training time:9410.530834436417
batch reward last col mean 0.12735746800899506 first col mean 0.14085231721401215 all mean 0.12978538870811462
0.38400906324386597 0.38400906324386597
rl training, epoch3, iter0, batch594/1133, batch loss:0.38400906324386597, Training time:9412.184199810028
batch reward last col mean 0.15585440397262573 first col mean 0.14358115196228027 all mean 0.15044613182544708
0.35834988951683044 0.35834988951683044
rl training, epoch3, iter0, batch595/1133, batch loss:0.35834988951683044, Training time:9413.957723379135
batch reward last col mean 0.13266393542289734 first col mean 0.10610279440879822 all mean 0.1313546895980835
0.33856311440467834 0.33856311440467834
rl training, epoch3, iter0, batch596/1133, batch loss:0.33856311440467834, Training time:9415.604717731476
batch reward last col mean 0.14927387237548828 first col mean 0.12493765354156494 all mean 0.1416613757610321
0.3604641258716583 0.36046409606933594
rl training, epoch3, iter0, batch597/1133, batch loss:0.36046409606933594, Training time:9417.315719604492
batch reward last col mean 0.099037304520607 first col mean 0.12607933580875397 all mean 0.10342200100421906
0.3245898187160492 0.3245898187160492
rl training, epoch3, iter0, batch598/1133, batch loss:0.3245898187160492, Training time:9418.911485433578
batch reward last col mean 0.0969976857304573 first col mean 0.11613718420267105 all mean 0.10574327409267426
0.30972251296043396 0.30972251296043396
rl training, epoch3, iter0, batch599/1133, batch loss:0.30972251296043396, Training time:9420.871967792511
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5429772289579986 Time: 97.46980595588684 s
loss of true 0.23948148178349316 loss of gen 0.1918243772538489 loss of other 0.11167137042700666 first score 0.12449558079242706
batch reward last col mean 0.14885272085666656 first col mean 0.1200052946805954 all mean 0.13709956407546997
0.3897276520729065 0.3897276520729065
rl training, epoch3, iter0, batch600/1133, batch loss:0.3897276520729065, Training time:9520.360074043274
batch reward last col mean 0.10944213718175888 first col mean 0.12915919721126556 all mean 0.1147269755601883
0.32752031087875366 0.32752031087875366
rl training, epoch3, iter0, batch601/1133, batch loss:0.32752031087875366, Training time:9523.384963274002
batch reward last col mean 0.09016364812850952 first col mean 0.11558038741350174 all mean 0.09524717181921005
0.30087295174598694 0.30087295174598694
rl training, epoch3, iter0, batch602/1133, batch loss:0.30087295174598694, Training time:9526.28676867485
batch reward last col mean 0.13049191236495972 first col mean 0.11906663328409195 all mean 0.12616312503814697
0.27936220169067383 0.27936220169067383
rl training, epoch3, iter0, batch603/1133, batch loss:0.27936220169067383, Training time:9527.994358539581
batch reward last col mean 0.08890575915575027 first col mean 0.13462984561920166 all mean 0.10341028869152069
0.3536994159221649 0.3536994159221649
rl training, epoch3, iter0, batch604/1133, batch loss:0.3536994159221649, Training time:9529.846934080124
batch reward last col mean 0.12162932008504868 first col mean 0.12396962940692902 all mean 0.11758124083280563
0.3204534649848938 0.3204534649848938
rl training, epoch3, iter0, batch605/1133, batch loss:0.3204534649848938, Training time:9531.92001748085
batch reward last col mean 0.09474247694015503 first col mean 0.12397526204586029 all mean 0.09764888137578964
0.33220672607421875 0.33220669627189636
rl training, epoch3, iter0, batch606/1133, batch loss:0.33220669627189636, Training time:9533.819527864456
batch reward last col mean 0.1135735958814621 first col mean 0.11145471036434174 all mean 0.11521359533071518
0.3099614083766937 0.3099614083766937
rl training, epoch3, iter0, batch607/1133, batch loss:0.3099614083766937, Training time:9535.595673084259
batch reward last col mean 0.11444342136383057 first col mean 0.11427926272153854 all mean 0.10995811969041824
0.2762216031551361 0.2762216031551361
rl training, epoch3, iter0, batch608/1133, batch loss:0.2762216031551361, Training time:9537.39241695404
batch reward last col mean 0.11269403994083405 first col mean 0.10630101710557938 all mean 0.10974589735269547
0.35801446437835693 0.35801446437835693
rl training, epoch3, iter0, batch609/1133, batch loss:0.35801446437835693, Training time:9538.991555929184
batch reward last col mean 0.11506868153810501 first col mean 0.12117066979408264 all mean 0.12392669916152954
0.40412822365760803 0.40412822365760803
rl training, epoch3, iter0, batch610/1133, batch loss:0.40412822365760803, Training time:9540.80678987503
batch reward last col mean 0.11052478849887848 first col mean 0.1174059808254242 all mean 0.11142578721046448
0.3340437412261963 0.3340437412261963
rl training, epoch3, iter0, batch611/1133, batch loss:0.3340437412261963, Training time:9542.873755693436
batch reward last col mean 0.13357199728488922 first col mean 0.10634870827198029 all mean 0.12920093536376953
0.35538822412490845 0.35538819432258606
rl training, epoch3, iter0, batch612/1133, batch loss:0.35538819432258606, Training time:9544.94834947586
batch reward last col mean 0.09450207650661469 first col mean 0.13340671360492706 all mean 0.10163659602403641
0.3004024624824524 0.3004024624824524
rl training, epoch3, iter0, batch613/1133, batch loss:0.3004024624824524, Training time:9546.881158351898
batch reward last col mean 0.09360751509666443 first col mean 0.13071642816066742 all mean 0.10364917665719986
0.3235640227794647 0.3235640227794647
rl training, epoch3, iter0, batch614/1133, batch loss:0.3235640227794647, Training time:9548.852223396301
batch reward last col mean 0.1010553389787674 first col mean 0.13975122570991516 all mean 0.11118201166391373
0.3349187672138214 0.3349187672138214
rl training, epoch3, iter0, batch615/1133, batch loss:0.3349187672138214, Training time:9550.929599761963
batch reward last col mean 0.12599487602710724 first col mean 0.12464991211891174 all mean 0.12545819580554962
0.3660341203212738 0.3660341203212738
rl training, epoch3, iter0, batch616/1133, batch loss:0.3660341203212738, Training time:9552.813469409943
batch reward last col mean 0.10714966058731079 first col mean 0.12321716547012329 all mean 0.10789923369884491
0.30419352650642395 0.30419352650642395
rl training, epoch3, iter0, batch617/1133, batch loss:0.30419352650642395, Training time:9555.076922655106
batch reward last col mean 0.11955870687961578 first col mean 0.1122017353773117 all mean 0.11588411033153534
0.2963787317276001 0.2963787317276001
rl training, epoch3, iter0, batch618/1133, batch loss:0.2963787317276001, Training time:9556.851459264755
batch reward last col mean 0.11790302395820618 first col mean 0.12130071222782135 all mean 0.11943681538105011
0.3258732259273529 0.3258732259273529
rl training, epoch3, iter0, batch619/1133, batch loss:0.3258732259273529, Training time:9558.751712083817
batch reward last col mean 0.10749339312314987 first col mean 0.12238045036792755 all mean 0.11237853765487671
0.34338733553886414 0.34338733553886414
rl training, epoch3, iter0, batch620/1133, batch loss:0.34338733553886414, Training time:9560.871004343033
batch reward last col mean 0.11299528181552887 first col mean 0.11302822828292847 all mean 0.1168617457151413
0.33681008219718933 0.33681008219718933
rl training, epoch3, iter0, batch621/1133, batch loss:0.33681008219718933, Training time:9563.181879758835
batch reward last col mean 0.13953456282615662 first col mean 0.140158012509346 all mean 0.13741575181484222
0.3498590290546417 0.3498590290546417
rl training, epoch3, iter0, batch622/1133, batch loss:0.3498590290546417, Training time:9565.768273353577
batch reward last col mean 0.11442168056964874 first col mean 0.10652414709329605 all mean 0.11534275859594345
0.3197745680809021 0.3197745680809021
rl training, epoch3, iter0, batch623/1133, batch loss:0.3197745680809021, Training time:9568.035932779312
batch reward last col mean 0.12498345971107483 first col mean 0.09795528650283813 all mean 0.11901232600212097
0.29235437512397766 0.2923543453216553
rl training, epoch3, iter0, batch624/1133, batch loss:0.2923543453216553, Training time:9570.298142910004
batch reward last col mean 0.10503460466861725 first col mean 0.11189170926809311 all mean 0.10498316586017609
0.30873677134513855 0.30873677134513855
rl training, epoch3, iter0, batch625/1133, batch loss:0.30873677134513855, Training time:9572.380519628525
batch reward last col mean 0.16954386234283447 first col mean 0.1311538964509964 all mean 0.15355131030082703
0.3617652356624603 0.3617652356624603
rl training, epoch3, iter0, batch626/1133, batch loss:0.3617652356624603, Training time:9574.699301242828
batch reward last col mean 0.1295778453350067 first col mean 0.11217670142650604 all mean 0.1290103942155838
0.3574616611003876 0.3574616611003876
rl training, epoch3, iter0, batch627/1133, batch loss:0.3574616611003876, Training time:9576.48790383339
batch reward last col mean 0.09627591073513031 first col mean 0.11844643205404282 all mean 0.10864906013011932
0.34663257002830505 0.34663257002830505
rl training, epoch3, iter0, batch628/1133, batch loss:0.34663257002830505, Training time:9578.277228355408
batch reward last col mean 0.10299080610275269 first col mean 0.10213042795658112 all mean 0.10542423278093338
0.3162845969200134 0.3162845969200134
rl training, epoch3, iter0, batch629/1133, batch loss:0.3162845969200134, Training time:9580.666600942612
batch reward last col mean 0.12272327393293381 first col mean 0.12166956067085266 all mean 0.12366724014282227
0.3562258780002594 0.3562258780002594
rl training, epoch3, iter0, batch630/1133, batch loss:0.3562258780002594, Training time:9582.885838270187
batch reward last col mean 0.14731265604496002 first col mean 0.12888379395008087 all mean 0.13948649168014526
0.3228282928466797 0.3228282928466797
rl training, epoch3, iter0, batch631/1133, batch loss:0.3228282928466797, Training time:9585.032257795334
batch reward last col mean 0.15133997797966003 first col mean 0.12337852269411087 all mean 0.14557787775993347
0.36316922307014465 0.36316922307014465
rl training, epoch3, iter0, batch632/1133, batch loss:0.36316922307014465, Training time:9586.817471027374
batch reward last col mean 0.12355437874794006 first col mean 0.11864203959703445 all mean 0.122273750603199
0.313466876745224 0.313466876745224
rl training, epoch3, iter0, batch633/1133, batch loss:0.313466876745224, Training time:9589.066556692123
batch reward last col mean 0.13799995183944702 first col mean 0.1229064017534256 all mean 0.12848849594593048
0.3333302438259125 0.3333302140235901
rl training, epoch3, iter0, batch634/1133, batch loss:0.3333302140235901, Training time:9591.127337217331
batch reward last col mean 0.13001000881195068 first col mean 0.1285996288061142 all mean 0.12790212035179138
0.3358306586742401 0.3358306586742401
rl training, epoch3, iter0, batch635/1133, batch loss:0.3358306586742401, Training time:9594.30336523056
batch reward last col mean 0.11567464470863342 first col mean 0.10956752300262451 all mean 0.11662530153989792
0.3487282395362854 0.3487282395362854
rl training, epoch3, iter0, batch636/1133, batch loss:0.3487282395362854, Training time:9596.587094545364
batch reward last col mean 0.11929772794246674 first col mean 0.11737401783466339 all mean 0.11476348340511322
0.3204837441444397 0.3204837441444397
rl training, epoch3, iter0, batch637/1133, batch loss:0.3204837441444397, Training time:9598.936563968658
batch reward last col mean 0.105136439204216 first col mean 0.12897688150405884 all mean 0.10706298798322678
0.3034575283527374 0.3034575283527374
rl training, epoch3, iter0, batch638/1133, batch loss:0.3034575283527374, Training time:9600.885502815247
batch reward last col mean 0.112544946372509 first col mean 0.1323995590209961 all mean 0.11024434119462967
0.3233538568019867 0.3233538568019867
rl training, epoch3, iter0, batch639/1133, batch loss:0.3233538568019867, Training time:9603.178479194641
batch reward last col mean 0.11167964339256287 first col mean 0.12849317491054535 all mean 0.11256428807973862
0.3481564521789551 0.3481564521789551
rl training, epoch3, iter0, batch640/1133, batch loss:0.3481564521789551, Training time:9604.663990020752
batch reward last col mean 0.10440416634082794 first col mean 0.1130097508430481 all mean 0.10084354132413864
0.26495593786239624 0.26495593786239624
rl training, epoch3, iter0, batch641/1133, batch loss:0.26495593786239624, Training time:9606.65151667595
batch reward last col mean 0.10933640599250793 first col mean 0.12379710376262665 all mean 0.1152251809835434
0.3348531723022461 0.3348531424999237
rl training, epoch3, iter0, batch642/1133, batch loss:0.3348531424999237, Training time:9608.581030368805
batch reward last col mean 0.1466754674911499 first col mean 0.11992623656988144 all mean 0.13778312504291534
0.35954320430755615 0.35954320430755615
rl training, epoch3, iter0, batch643/1133, batch loss:0.35954320430755615, Training time:9610.513290405273
batch reward last col mean 0.10628019273281097 first col mean 0.12386638671159744 all mean 0.10895445942878723
0.3456253111362457 0.3456253111362457
rl training, epoch3, iter0, batch644/1133, batch loss:0.3456253111362457, Training time:9612.866577148438
batch reward last col mean 0.07256974279880524 first col mean 0.10326936841011047 all mean 0.09180761873722076
0.30794557929039 0.30794557929039
rl training, epoch3, iter0, batch645/1133, batch loss:0.30794557929039, Training time:9614.553378582
batch reward last col mean 0.13307644426822662 first col mean 0.1129579246044159 all mean 0.13235728442668915
0.324892520904541 0.32489246129989624
rl training, epoch3, iter0, batch646/1133, batch loss:0.32489246129989624, Training time:9617.010855674744
batch reward last col mean 0.146969273686409 first col mean 0.12060175836086273 all mean 0.14231328666210175
0.3821915090084076 0.3821915090084076
rl training, epoch3, iter0, batch647/1133, batch loss:0.3821915090084076, Training time:9618.732690095901
batch reward last col mean 0.10793116688728333 first col mean 0.10605791211128235 all mean 0.10851006954908371
0.34753894805908203 0.34753894805908203
rl training, epoch3, iter0, batch648/1133, batch loss:0.34753894805908203, Training time:9620.688112974167
batch reward last col mean 0.08173730969429016 first col mean 0.113925039768219 all mean 0.08954381942749023
0.28717315196990967 0.28717315196990967
rl training, epoch3, iter0, batch649/1133, batch loss:0.28717315196990967, Training time:9622.412254810333
batch reward last col mean 0.12473802268505096 first col mean 0.10942548513412476 all mean 0.11904573440551758
0.34273561835289 0.3427355885505676
rl training, epoch3, iter0, batch650/1133, batch loss:0.3427355885505676, Training time:9623.867225170135
batch reward last col mean 0.14698757231235504 first col mean 0.13660219311714172 all mean 0.14223946630954742
0.3118099272251129 0.3118099272251129
rl training, epoch3, iter0, batch651/1133, batch loss:0.3118099272251129, Training time:9626.08424782753
batch reward last col mean 0.09946294128894806 first col mean 0.10722607374191284 all mean 0.10587283223867416
0.3357594609260559 0.3357594609260559
rl training, epoch3, iter0, batch652/1133, batch loss:0.3357594609260559, Training time:9628.676344633102
batch reward last col mean 0.14716945588588715 first col mean 0.1394803375005722 all mean 0.14247269928455353
0.3607296347618103 0.3607296347618103
rl training, epoch3, iter0, batch653/1133, batch loss:0.3607296347618103, Training time:9630.527847528458
batch reward last col mean 0.14800909161567688 first col mean 0.11972163617610931 all mean 0.14092838764190674
0.38634446263313293 0.38634443283081055
rl training, epoch3, iter0, batch654/1133, batch loss:0.38634443283081055, Training time:9631.938896417618
batch reward last col mean 0.11574278026819229 first col mean 0.12084745615720749 all mean 0.1132545992732048
0.3923954367637634 0.3923954367637634
rl training, epoch3, iter0, batch655/1133, batch loss:0.3923954367637634, Training time:9634.555338144302
batch reward last col mean 0.10320103913545609 first col mean 0.12424832582473755 all mean 0.10819530487060547
0.3222005367279053 0.3222005367279053
rl training, epoch3, iter0, batch656/1133, batch loss:0.3222005367279053, Training time:9636.281629562378
batch reward last col mean 0.16492488980293274 first col mean 0.12772107124328613 all mean 0.1529211401939392
0.41625022888183594 0.41625022888183594
rl training, epoch3, iter0, batch657/1133, batch loss:0.41625022888183594, Training time:9638.411887645721
batch reward last col mean 0.12529513239860535 first col mean 0.12942177057266235 all mean 0.12272175401449203
0.32463595271110535 0.32463595271110535
rl training, epoch3, iter0, batch658/1133, batch loss:0.32463595271110535, Training time:9639.980646133423
batch reward last col mean 0.09515649080276489 first col mean 0.11048031598329544 all mean 0.10088266432285309
0.3346939980983734 0.3346939980983734
rl training, epoch3, iter0, batch659/1133, batch loss:0.3346939980983734, Training time:9641.700950860977
batch reward last col mean 0.1100464016199112 first col mean 0.15016622841358185 all mean 0.11334753036499023
0.3208169639110565 0.3208169639110565
rl training, epoch3, iter0, batch660/1133, batch loss:0.3208169639110565, Training time:9643.83875131607
batch reward last col mean 0.09444966912269592 first col mean 0.12836574018001556 all mean 0.10557091236114502
0.30011793971061707 0.30011793971061707
rl training, epoch3, iter0, batch661/1133, batch loss:0.30011793971061707, Training time:9645.186922073364
batch reward last col mean 0.1536523699760437 first col mean 0.14404740929603577 all mean 0.14865480363368988
0.3576527237892151 0.3576527237892151
rl training, epoch3, iter0, batch662/1133, batch loss:0.3576527237892151, Training time:9647.335309028625
batch reward last col mean 0.13139203190803528 first col mean 0.11319729685783386 all mean 0.12697651982307434
0.3607447147369385 0.3607447147369385
rl training, epoch3, iter0, batch663/1133, batch loss:0.3607447147369385, Training time:9648.990514755249
batch reward last col mean 0.08879725635051727 first col mean 0.1160573735833168 all mean 0.10102914273738861
0.302924245595932 0.302924245595932
rl training, epoch3, iter0, batch664/1133, batch loss:0.302924245595932, Training time:9651.076236486435
batch reward last col mean 0.09474772959947586 first col mean 0.12905748188495636 all mean 0.1070164367556572
0.3407384157180786 0.3407384157180786
rl training, epoch3, iter0, batch665/1133, batch loss:0.3407384157180786, Training time:9653.11070728302
batch reward last col mean 0.12422196567058563 first col mean 0.12759414315223694 all mean 0.12474367767572403
0.3389863073825836 0.33898627758026123
rl training, epoch3, iter0, batch666/1133, batch loss:0.33898627758026123, Training time:9655.097100019455
batch reward last col mean 0.1391013115644455 first col mean 0.10268650949001312 all mean 0.12314268946647644
0.36661046743392944 0.36661046743392944
rl training, epoch3, iter0, batch667/1133, batch loss:0.36661046743392944, Training time:9656.808309316635
batch reward last col mean 0.10389512032270432 first col mean 0.12558521330356598 all mean 0.10749457031488419
0.33268848061561584 0.33268848061561584
rl training, epoch3, iter0, batch668/1133, batch loss:0.33268848061561584, Training time:9659.162093639374
batch reward last col mean 0.10606740415096283 first col mean 0.1276278793811798 all mean 0.10915038734674454
0.33861789107322693 0.33861789107322693
rl training, epoch3, iter0, batch669/1133, batch loss:0.33861789107322693, Training time:9661.406145095825
batch reward last col mean 0.14203521609306335 first col mean 0.11394841969013214 all mean 0.1371907889842987
0.3631846308708191 0.3631846308708191
rl training, epoch3, iter0, batch670/1133, batch loss:0.3631846308708191, Training time:9663.159764528275
batch reward last col mean 0.09745809435844421 first col mean 0.12038318812847137 all mean 0.10875717550516129
0.34253692626953125 0.34253692626953125
rl training, epoch3, iter0, batch671/1133, batch loss:0.34253692626953125, Training time:9664.797863721848
batch reward last col mean 0.13143093883991241 first col mean 0.11610744893550873 all mean 0.12996868789196014
0.354952871799469 0.3549528419971466
rl training, epoch3, iter0, batch672/1133, batch loss:0.3549528419971466, Training time:9666.382025718689
batch reward last col mean 0.08316326141357422 first col mean 0.12839074432849884 all mean 0.09292210638523102
0.29069846868515015 0.29069846868515015
rl training, epoch3, iter0, batch673/1133, batch loss:0.29069846868515015, Training time:9668.475482463837
batch reward last col mean 0.12634319067001343 first col mean 0.10926688462495804 all mean 0.12233355641365051
0.3279355764389038 0.3279355764389038
rl training, epoch3, iter0, batch674/1133, batch loss:0.3279355764389038, Training time:9670.427351474762
batch reward last col mean 0.11388105154037476 first col mean 0.12656903266906738 all mean 0.11584030091762543
0.3217437267303467 0.3217437267303467
rl training, epoch3, iter0, batch675/1133, batch loss:0.3217437267303467, Training time:9672.20148396492
batch reward last col mean 0.1241036057472229 first col mean 0.12442167103290558 all mean 0.12192229926586151
0.3210943341255188 0.3210943341255188
rl training, epoch3, iter0, batch676/1133, batch loss:0.3210943341255188, Training time:9673.846605539322
batch reward last col mean 0.10426265001296997 first col mean 0.12232691049575806 all mean 0.1068650409579277
0.3108533024787903 0.3108533024787903
rl training, epoch3, iter0, batch677/1133, batch loss:0.3108533024787903, Training time:9675.584575176239
batch reward last col mean 0.10599283874034882 first col mean 0.11737200617790222 all mean 0.10575619339942932
0.32882413268089294 0.32882413268089294
rl training, epoch3, iter0, batch678/1133, batch loss:0.32882413268089294, Training time:9677.388711690903
batch reward last col mean 0.09645149111747742 first col mean 0.1308656632900238 all mean 0.10340598970651627
0.31966572999954224 0.31966572999954224
rl training, epoch3, iter0, batch679/1133, batch loss:0.31966572999954224, Training time:9679.14455294609
batch reward last col mean 0.1226363331079483 first col mean 0.12381576001644135 all mean 0.11562741547822952
0.35825401544570923 0.35825401544570923
rl training, epoch3, iter0, batch680/1133, batch loss:0.35825401544570923, Training time:9681.146993875504
batch reward last col mean 0.10599784553050995 first col mean 0.09749499708414078 all mean 0.11099040508270264
0.3145619034767151 0.3145619332790375
rl training, epoch3, iter0, batch681/1133, batch loss:0.3145619332790375, Training time:9682.706265211105
batch reward last col mean 0.11256013065576553 first col mean 0.11504875123500824 all mean 0.11665958166122437
0.32236969470977783 0.32236969470977783
rl training, epoch3, iter0, batch682/1133, batch loss:0.32236969470977783, Training time:9684.29407453537
batch reward last col mean 0.09991058707237244 first col mean 0.11724796146154404 all mean 0.10358209162950516
0.2915026545524597 0.2915026545524597
rl training, epoch3, iter0, batch683/1133, batch loss:0.2915026545524597, Training time:9685.759701013565
batch reward last col mean 0.1172603964805603 first col mean 0.14353463053703308 all mean 0.12197379767894745
0.35477834939956665 0.35477834939956665
rl training, epoch3, iter0, batch684/1133, batch loss:0.35477834939956665, Training time:9687.173254728317
batch reward last col mean 0.11685813218355179 first col mean 0.12251558154821396 all mean 0.12498247623443604
0.3662984073162079 0.3662983775138855
rl training, epoch3, iter0, batch685/1133, batch loss:0.3662983775138855, Training time:9689.177533864975
batch reward last col mean 0.10062363743782043 first col mean 0.11808368563652039 all mean 0.10385945439338684
0.3166537880897522 0.3166537880897522
rl training, epoch3, iter0, batch686/1133, batch loss:0.3166537880897522, Training time:9691.503846645355
batch reward last col mean 0.13334009051322937 first col mean 0.11505267769098282 all mean 0.12633298337459564
0.3218812346458435 0.3218812346458435
rl training, epoch3, iter0, batch687/1133, batch loss:0.3218812346458435, Training time:9693.148254394531
batch reward last col mean 0.12728750705718994 first col mean 0.11468464136123657 all mean 0.1222774088382721
0.3303847312927246 0.3303847312927246
rl training, epoch3, iter0, batch688/1133, batch loss:0.3303847312927246, Training time:9694.783228635788
batch reward last col mean 0.1267659068107605 first col mean 0.11781999468803406 all mean 0.12554235756397247
0.3940575420856476 0.3940575420856476
rl training, epoch3, iter0, batch689/1133, batch loss:0.3940575420856476, Training time:9696.717570066452
batch reward last col mean 0.10153502970933914 first col mean 0.10247852653265 all mean 0.11052517592906952
0.3286832869052887 0.3286832869052887
rl training, epoch3, iter0, batch690/1133, batch loss:0.3286832869052887, Training time:9698.212534666061
batch reward last col mean 0.14369997382164001 first col mean 0.12352067232131958 all mean 0.1332583725452423
0.339641809463501 0.339641809463501
rl training, epoch3, iter0, batch691/1133, batch loss:0.339641809463501, Training time:9700.055494308472
batch reward last col mean 0.08283768594264984 first col mean 0.1318216621875763 all mean 0.09150159358978271
0.32930320501327515 0.32930320501327515
rl training, epoch3, iter0, batch692/1133, batch loss:0.32930320501327515, Training time:9701.940723896027
batch reward last col mean 0.09629863500595093 first col mean 0.13280630111694336 all mean 0.10367945581674576
0.3510982096195221 0.3510982096195221
rl training, epoch3, iter0, batch693/1133, batch loss:0.3510982096195221, Training time:9703.624289751053
batch reward last col mean 0.072670578956604 first col mean 0.12146682292222977 all mean 0.08616157621145248
0.3006395399570465 0.3006395399570465
rl training, epoch3, iter0, batch694/1133, batch loss:0.3006395399570465, Training time:9705.359068870544
batch reward last col mean 0.15823356807231903 first col mean 0.10051104426383972 all mean 0.14332111179828644
0.34059518575668335 0.34059518575668335
rl training, epoch3, iter0, batch695/1133, batch loss:0.34059518575668335, Training time:9707.036219835281
batch reward last col mean 0.12282431125640869 first col mean 0.12737354636192322 all mean 0.12762443721294403
0.3443410396575928 0.3443410396575928
rl training, epoch3, iter0, batch696/1133, batch loss:0.3443410396575928, Training time:9709.097831249237
batch reward last col mean 0.09837840497493744 first col mean 0.11083099991083145 all mean 0.11155872792005539
0.3223806619644165 0.3223806619644165
rl training, epoch3, iter0, batch697/1133, batch loss:0.3223806619644165, Training time:9710.81826877594
batch reward last col mean 0.15700004994869232 first col mean 0.12324943393468857 all mean 0.15077722072601318
0.37040483951568604 0.37040483951568604
rl training, epoch3, iter0, batch698/1133, batch loss:0.37040483951568604, Training time:9713.39388012886
batch reward last col mean 0.14060808718204498 first col mean 0.13440802693367004 all mean 0.13594120740890503
0.38906174898147583 0.38906174898147583
rl training, epoch3, iter0, batch699/1133, batch loss:0.38906174898147583, Training time:9715.243072509766
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5453233119669154 Time: 99.9260630607605 s
loss of true 0.2413981278465579 loss of gen 0.19158852491642875 loss of other 0.11233666026266086 first score 0.11389271169900894
batch reward last col mean 0.1252424716949463 first col mean 0.10071584582328796 all mean 0.12063891440629959
0.34818872809410095 0.34818872809410095
rl training, epoch3, iter0, batch700/1133, batch loss:0.34818872809410095, Training time:9816.595515012741
batch reward last col mean 0.12839260697364807 first col mean 0.11481642723083496 all mean 0.12519386410713196
0.32215654850006104 0.32215654850006104
rl training, epoch3, iter0, batch701/1133, batch loss:0.32215654850006104, Training time:9818.179665327072
batch reward last col mean 0.07857956737279892 first col mean 0.12166579067707062 all mean 0.09155555814504623
0.27099910378456116 0.27099910378456116
rl training, epoch3, iter0, batch702/1133, batch loss:0.27099910378456116, Training time:9820.15188407898
batch reward last col mean 0.13180935382843018 first col mean 0.12080531567335129 all mean 0.13279351592063904
0.35554906725883484 0.35554906725883484
rl training, epoch3, iter0, batch703/1133, batch loss:0.35554906725883484, Training time:9822.435475111008
batch reward last col mean 0.11724521219730377 first col mean 0.1185290515422821 all mean 0.12356778979301453
0.34751227498054504 0.34751221537590027
rl training, epoch3, iter0, batch704/1133, batch loss:0.34751221537590027, Training time:9824.303756713867
batch reward last col mean 0.13622814416885376 first col mean 0.12114883959293365 all mean 0.12283783406019211
0.30741435289382935 0.30741435289382935
rl training, epoch3, iter0, batch705/1133, batch loss:0.30741435289382935, Training time:9826.30453324318
batch reward last col mean 0.1215365007519722 first col mean 0.11713060736656189 all mean 0.12165458500385284
0.313086599111557 0.313086599111557
rl training, epoch3, iter0, batch706/1133, batch loss:0.313086599111557, Training time:9827.95240020752
batch reward last col mean 0.12814143300056458 first col mean 0.125327467918396 all mean 0.1201060339808464
0.3451439440250397 0.3451439440250397
rl training, epoch3, iter0, batch707/1133, batch loss:0.3451439440250397, Training time:9829.727331161499
batch reward last col mean 0.14265459775924683 first col mean 0.13608473539352417 all mean 0.13293293118476868
0.3301471769809723 0.3301471769809723
rl training, epoch3, iter0, batch708/1133, batch loss:0.3301471769809723, Training time:9831.24286532402
batch reward last col mean 0.12685757875442505 first col mean 0.12271136045455933 all mean 0.12331665307283401
0.3380002975463867 0.3380002975463867
rl training, epoch3, iter0, batch709/1133, batch loss:0.3380002975463867, Training time:9833.373923301697
batch reward last col mean 0.1104971393942833 first col mean 0.10333104431629181 all mean 0.11323241144418716
0.32765233516693115 0.32765233516693115
rl training, epoch3, iter0, batch710/1133, batch loss:0.32765233516693115, Training time:9835.021487951279
batch reward last col mean 0.11358995735645294 first col mean 0.1210876852273941 all mean 0.11657856404781342
0.3068191111087799 0.3068190813064575
rl training, epoch3, iter0, batch711/1133, batch loss:0.3068190813064575, Training time:9836.695717096329
batch reward last col mean 0.11824087053537369 first col mean 0.11795289069414139 all mean 0.12235774844884872
0.34281131625175476 0.34281131625175476
rl training, epoch3, iter0, batch712/1133, batch loss:0.34281131625175476, Training time:9838.888513803482
batch reward last col mean 0.08844302594661713 first col mean 0.11359129846096039 all mean 0.09302785247564316
0.2823126018047333 0.2823126018047333
rl training, epoch3, iter0, batch713/1133, batch loss:0.2823126018047333, Training time:9840.80330324173
batch reward last col mean 0.10167127847671509 first col mean 0.12021727859973907 all mean 0.10547912120819092
0.3194669485092163 0.3194669485092163
rl training, epoch3, iter0, batch714/1133, batch loss:0.3194669485092163, Training time:9842.724167346954
batch reward last col mean 0.11925944685935974 first col mean 0.1271558254957199 all mean 0.11802131682634354
0.30135074257850647 0.30135074257850647
rl training, epoch3, iter0, batch715/1133, batch loss:0.30135074257850647, Training time:9844.723868131638
batch reward last col mean 0.12434151768684387 first col mean 0.10695914924144745 all mean 0.12261633574962616
0.3648660480976105 0.3648660480976105
rl training, epoch3, iter0, batch716/1133, batch loss:0.3648660480976105, Training time:9846.271643400192
batch reward last col mean 0.10944140702486038 first col mean 0.12072701752185822 all mean 0.10362276434898376
0.30670613050460815 0.30670613050460815
rl training, epoch3, iter0, batch717/1133, batch loss:0.30670613050460815, Training time:9847.947279453278
batch reward last col mean 0.09493333101272583 first col mean 0.1132749617099762 all mean 0.1045197919011116
0.30554941296577454 0.30554941296577454
rl training, epoch3, iter0, batch718/1133, batch loss:0.30554941296577454, Training time:9849.553164243698
batch reward last col mean 0.12393277883529663 first col mean 0.12808047235012054 all mean 0.12524846196174622
0.3415882885456085 0.3415882885456085
rl training, epoch3, iter0, batch719/1133, batch loss:0.3415882885456085, Training time:9851.293702602386
batch reward last col mean 0.09282282739877701 first col mean 0.11162794381380081 all mean 0.09705546498298645
0.2943165898323059 0.2943165600299835
rl training, epoch3, iter0, batch720/1133, batch loss:0.2943165600299835, Training time:9852.90263915062
batch reward last col mean 0.11297281086444855 first col mean 0.12293635308742523 all mean 0.11789929866790771
0.3625088930130005 0.3625088930130005
rl training, epoch3, iter0, batch721/1133, batch loss:0.3625088930130005, Training time:9854.409182310104
batch reward last col mean 0.13012757897377014 first col mean 0.12026014924049377 all mean 0.1293802112340927
0.362958699464798 0.3629586696624756
rl training, epoch3, iter0, batch722/1133, batch loss:0.3629586696624756, Training time:9856.151205301285
batch reward last col mean 0.11267655342817307 first col mean 0.1128612607717514 all mean 0.11466571688652039
0.33746537566185 0.33746537566185
rl training, epoch3, iter0, batch723/1133, batch loss:0.33746537566185, Training time:9858.371034145355
batch reward last col mean 0.11286288499832153 first col mean 0.10664685070514679 all mean 0.11918710172176361
0.3588632345199585 0.3588631749153137
rl training, epoch3, iter0, batch724/1133, batch loss:0.3588631749153137, Training time:9859.945096969604
batch reward last col mean 0.12044195830821991 first col mean 0.10316160321235657 all mean 0.11414182186126709
0.34565889835357666 0.34565889835357666
rl training, epoch3, iter0, batch725/1133, batch loss:0.34565889835357666, Training time:9861.692368030548
batch reward last col mean 0.1158737912774086 first col mean 0.10249879211187363 all mean 0.11929909884929657
0.30356350541114807 0.30356350541114807
rl training, epoch3, iter0, batch726/1133, batch loss:0.30356350541114807, Training time:9863.96736907959
batch reward last col mean 0.13658158481121063 first col mean 0.11234402656555176 all mean 0.1362256109714508
0.3754505217075348 0.3754505217075348
rl training, epoch3, iter0, batch727/1133, batch loss:0.3754505217075348, Training time:9865.532595157623
batch reward last col mean 0.0955997183918953 first col mean 0.1318322718143463 all mean 0.09723711758852005
0.27156493067741394 0.27156493067741394
rl training, epoch3, iter0, batch728/1133, batch loss:0.27156493067741394, Training time:9867.279429912567
batch reward last col mean 0.08885955810546875 first col mean 0.12305676937103271 all mean 0.10131526738405228
0.34469759464263916 0.34469759464263916
rl training, epoch3, iter0, batch729/1133, batch loss:0.34469759464263916, Training time:9869.06377196312
batch reward last col mean 0.10158511996269226 first col mean 0.13019061088562012 all mean 0.10947640985250473
0.30026566982269287 0.30026566982269287
rl training, epoch3, iter0, batch730/1133, batch loss:0.30026566982269287, Training time:9871.41535449028
batch reward last col mean 0.16910423338413239 first col mean 0.12520691752433777 all mean 0.15473449230194092
0.38605791330337524 0.38605797290802
rl training, epoch3, iter0, batch731/1133, batch loss:0.38605797290802, Training time:9873.458444833755
batch reward last col mean 0.11903218924999237 first col mean 0.11318588256835938 all mean 0.1167948916554451
0.30435073375701904 0.30435070395469666
rl training, epoch3, iter0, batch732/1133, batch loss:0.30435070395469666, Training time:9874.87814617157
batch reward last col mean 0.10182908177375793 first col mean 0.10703033208847046 all mean 0.10750579833984375
0.3328598141670227 0.3328598141670227
rl training, epoch3, iter0, batch733/1133, batch loss:0.3328598141670227, Training time:9878.412530183792
batch reward last col mean 0.11027368903160095 first col mean 0.11569901555776596 all mean 0.11164170503616333
0.314822793006897 0.314822793006897
rl training, epoch3, iter0, batch734/1133, batch loss:0.314822793006897, Training time:9880.378714323044
batch reward last col mean 0.11547181755304337 first col mean 0.12318884581327438 all mean 0.12095165252685547
0.346164345741272 0.346164345741272
rl training, epoch3, iter0, batch735/1133, batch loss:0.346164345741272, Training time:9882.231501340866
batch reward last col mean 0.08933678269386292 first col mean 0.11319390684366226 all mean 0.09953305870294571
0.31425392627716064 0.31425392627716064
rl training, epoch3, iter0, batch736/1133, batch loss:0.31425392627716064, Training time:9884.168028116226
batch reward last col mean 0.12214909493923187 first col mean 0.12552911043167114 all mean 0.12804877758026123
0.36910736560821533 0.36910736560821533
rl training, epoch3, iter0, batch737/1133, batch loss:0.36910736560821533, Training time:9886.047688007355
batch reward last col mean 0.09016835689544678 first col mean 0.12264878302812576 all mean 0.09901757538318634
0.31070399284362793 0.31070399284362793
rl training, epoch3, iter0, batch738/1133, batch loss:0.31070399284362793, Training time:9887.912388086319
batch reward last col mean 0.132748082280159 first col mean 0.13433220982551575 all mean 0.12845222651958466
0.38492992520332336 0.38492992520332336
rl training, epoch3, iter0, batch739/1133, batch loss:0.38492992520332336, Training time:9889.829048633575
batch reward last col mean 0.11608006060123444 first col mean 0.12900525331497192 all mean 0.12592454254627228
0.346841037273407 0.3468409776687622
rl training, epoch3, iter0, batch740/1133, batch loss:0.3468409776687622, Training time:9891.623671293259
batch reward last col mean 0.11878731846809387 first col mean 0.11951574683189392 all mean 0.12102410942316055
0.334961861371994 0.334961861371994
rl training, epoch3, iter0, batch741/1133, batch loss:0.334961861371994, Training time:9894.059828519821
batch reward last col mean 0.09656717628240585 first col mean 0.12773555517196655 all mean 0.1077788770198822
0.35730844736099243 0.35730844736099243
rl training, epoch3, iter0, batch742/1133, batch loss:0.35730844736099243, Training time:9896.045415878296
batch reward last col mean 0.1315057873725891 first col mean 0.12703630328178406 all mean 0.12638121843338013
0.33605363965034485 0.33605363965034485
rl training, epoch3, iter0, batch743/1133, batch loss:0.33605363965034485, Training time:9897.767508983612
batch reward last col mean 0.09897752106189728 first col mean 0.1282052993774414 all mean 0.1026853397488594
0.306113600730896 0.3061136305332184
rl training, epoch3, iter0, batch744/1133, batch loss:0.3061136305332184, Training time:9899.580672979355
batch reward last col mean 0.12446193397045135 first col mean 0.13596095144748688 all mean 0.12365880608558655
0.30968987941741943 0.30968984961509705
rl training, epoch3, iter0, batch745/1133, batch loss:0.30968984961509705, Training time:9901.348939180374
batch reward last col mean 0.14471805095672607 first col mean 0.11780507862567902 all mean 0.13729877769947052
0.35986703634262085 0.35986703634262085
rl training, epoch3, iter0, batch746/1133, batch loss:0.35986703634262085, Training time:9903.917711496353
batch reward last col mean 0.18551045656204224 first col mean 0.14065715670585632 all mean 0.16449232399463654
0.3694218397140503 0.3694218397140503
rl training, epoch3, iter0, batch747/1133, batch loss:0.3694218397140503, Training time:9906.122086524963
batch reward last col mean 0.09741870313882828 first col mean 0.11900176107883453 all mean 0.11033548414707184
0.34534308314323425 0.34534308314323425
rl training, epoch3, iter0, batch748/1133, batch loss:0.34534308314323425, Training time:9907.984458446503
batch reward last col mean 0.09698434174060822 first col mean 0.1197996512055397 all mean 0.10218808799982071
0.2956305146217346 0.2956305146217346
rl training, epoch3, iter0, batch749/1133, batch loss:0.2956305146217346, Training time:9909.807464122772
batch reward last col mean 0.10246489942073822 first col mean 0.12933340668678284 all mean 0.10966900736093521
0.3249054253101349 0.3249054253101349
rl training, epoch3, iter0, batch750/1133, batch loss:0.3249054253101349, Training time:9911.623332977295
batch reward last col mean 0.08385145664215088 first col mean 0.12028275430202484 all mean 0.0953545868396759
0.3615444004535675 0.3615444600582123
rl training, epoch3, iter0, batch751/1133, batch loss:0.3615444600582123, Training time:9913.65307378769
batch reward last col mean 0.1502825766801834 first col mean 0.11676093935966492 all mean 0.14184172451496124
0.34331268072128296 0.34331268072128296
rl training, epoch3, iter0, batch752/1133, batch loss:0.34331268072128296, Training time:9915.373409986496
batch reward last col mean 0.12442854791879654 first col mean 0.11510252952575684 all mean 0.11737304925918579
0.3259845972061157 0.3259845972061157
rl training, epoch3, iter0, batch753/1133, batch loss:0.3259845972061157, Training time:9916.858276128769
batch reward last col mean 0.12042118608951569 first col mean 0.11505255848169327 all mean 0.11899696290493011
0.3243005871772766 0.3243005871772766
rl training, epoch3, iter0, batch754/1133, batch loss:0.3243005871772766, Training time:9918.825464963913
batch reward last col mean 0.0962265133857727 first col mean 0.12471957504749298 all mean 0.10224948823451996
0.3272578716278076 0.3272578716278076
rl training, epoch3, iter0, batch755/1133, batch loss:0.3272578716278076, Training time:9920.72106719017
batch reward last col mean 0.1249670535326004 first col mean 0.1311856508255005 all mean 0.12354244291782379
0.31659743189811707 0.31659743189811707
rl training, epoch3, iter0, batch756/1133, batch loss:0.31659743189811707, Training time:9923.016461372375
batch reward last col mean 0.1282978504896164 first col mean 0.12277466803789139 all mean 0.1283673793077469
0.3560512959957123 0.3560512959957123
rl training, epoch3, iter0, batch757/1133, batch loss:0.3560512959957123, Training time:9924.592528820038
batch reward last col mean 0.1047634482383728 first col mean 0.13733822107315063 all mean 0.11264432221651077
0.3502531349658966 0.3502531349658966
rl training, epoch3, iter0, batch758/1133, batch loss:0.3502531349658966, Training time:9926.355508804321
batch reward last col mean 0.08138449490070343 first col mean 0.135156512260437 all mean 0.08932626992464066
0.3131072521209717 0.3131072521209717
rl training, epoch3, iter0, batch759/1133, batch loss:0.3131072521209717, Training time:9928.524119377136
batch reward last col mean 0.13204392790794373 first col mean 0.10547467321157455 all mean 0.12282657623291016
0.3179449141025543 0.3179449141025543
rl training, epoch3, iter0, batch760/1133, batch loss:0.3179449141025543, Training time:9930.010559797287
batch reward last col mean 0.10389912873506546 first col mean 0.11871626228094101 all mean 0.11361511796712875
0.3391326665878296 0.3391326367855072
rl training, epoch3, iter0, batch761/1133, batch loss:0.3391326367855072, Training time:9932.42970776558
batch reward last col mean 0.09112600237131119 first col mean 0.11511780321598053 all mean 0.09929728507995605
0.33579257130622864 0.33579257130622864
rl training, epoch3, iter0, batch762/1133, batch loss:0.33579257130622864, Training time:9934.126615285873
batch reward last col mean 0.12581950426101685 first col mean 0.13527803122997284 all mean 0.12568019330501556
0.31284260749816895 0.31284257769584656
rl training, epoch3, iter0, batch763/1133, batch loss:0.31284257769584656, Training time:9935.651720046997
batch reward last col mean 0.14066293835639954 first col mean 0.11994186043739319 all mean 0.13812394440174103
0.3886060416698456 0.38860607147216797
rl training, epoch3, iter0, batch764/1133, batch loss:0.38860607147216797, Training time:9937.428590774536
batch reward last col mean 0.08540558815002441 first col mean 0.1409383863210678 all mean 0.10069559514522552
0.3070964217185974 0.3070964515209198
rl training, epoch3, iter0, batch765/1133, batch loss:0.3070964515209198, Training time:9939.284609556198
batch reward last col mean 0.08166233450174332 first col mean 0.1136147603392601 all mean 0.09091170877218246
0.2550731897354126 0.2550731897354126
rl training, epoch3, iter0, batch766/1133, batch loss:0.2550731897354126, Training time:9940.79405093193
batch reward last col mean 0.0931745395064354 first col mean 0.11654233932495117 all mean 0.10478352755308151
0.3565431237220764 0.3565431237220764
rl training, epoch3, iter0, batch767/1133, batch loss:0.3565431237220764, Training time:9942.662296772003
batch reward last col mean 0.15245887637138367 first col mean 0.11691389977931976 all mean 0.13693097233772278
0.35055655241012573 0.3505565822124481
rl training, epoch3, iter0, batch768/1133, batch loss:0.3505565822124481, Training time:9944.54878115654
batch reward last col mean 0.11354556679725647 first col mean 0.12196299433708191 all mean 0.11061619967222214
0.2718355357646942 0.2718355357646942
rl training, epoch3, iter0, batch769/1133, batch loss:0.2718355357646942, Training time:9946.66765165329
batch reward last col mean 0.12032824754714966 first col mean 0.1441844403743744 all mean 0.12015079706907272
0.3213866055011749 0.3213866055011749
rl training, epoch3, iter0, batch770/1133, batch loss:0.3213866055011749, Training time:9948.599841356277
batch reward last col mean 0.09768570959568024 first col mean 0.11672907322645187 all mean 0.10470845550298691
0.34507879614830017 0.34507879614830017
rl training, epoch3, iter0, batch771/1133, batch loss:0.34507879614830017, Training time:9950.351151943207
batch reward last col mean 0.07875663042068481 first col mean 0.12644173204898834 all mean 0.09355531632900238
0.28505754470825195 0.28505754470825195
rl training, epoch3, iter0, batch772/1133, batch loss:0.28505754470825195, Training time:9951.954936504364
batch reward last col mean 0.12812374532222748 first col mean 0.11553086340427399 all mean 0.12292461842298508
0.3597695231437683 0.3597695231437683
rl training, epoch3, iter0, batch773/1133, batch loss:0.3597695231437683, Training time:9953.415647983551
batch reward last col mean 0.11220338195562363 first col mean 0.11995045095682144 all mean 0.1185479387640953
0.30891305208206177 0.30891305208206177
rl training, epoch3, iter0, batch774/1133, batch loss:0.30891305208206177, Training time:9955.029851913452
batch reward last col mean 0.08375367522239685 first col mean 0.13070625066757202 all mean 0.09509832412004471
0.31750932335853577 0.31750932335853577
rl training, epoch3, iter0, batch775/1133, batch loss:0.31750932335853577, Training time:9956.507073402405
batch reward last col mean 0.08740448951721191 first col mean 0.11512306332588196 all mean 0.10067010670900345
0.35577741265296936 0.35577741265296936
rl training, epoch3, iter0, batch776/1133, batch loss:0.35577741265296936, Training time:9958.076734304428
batch reward last col mean 0.07974991202354431 first col mean 0.13316461443901062 all mean 0.0935916006565094
0.33520832657814026 0.33520832657814026
rl training, epoch3, iter0, batch777/1133, batch loss:0.33520832657814026, Training time:9959.817661523819
batch reward last col mean 0.11242745816707611 first col mean 0.11618079245090485 all mean 0.11559846252202988
0.3212849795818329 0.3212850093841553
rl training, epoch3, iter0, batch778/1133, batch loss:0.3212850093841553, Training time:9961.163676977158
batch reward last col mean 0.12277363240718842 first col mean 0.11952975392341614 all mean 0.12372279912233353
0.3499017059803009 0.3499016761779785
rl training, epoch3, iter0, batch779/1133, batch loss:0.3499016761779785, Training time:9962.924925088882
batch reward last col mean 0.0907868891954422 first col mean 0.11502446234226227 all mean 0.10167230665683746
0.2864918112754822 0.2864918112754822
rl training, epoch3, iter0, batch780/1133, batch loss:0.2864918112754822, Training time:9964.706225156784
batch reward last col mean 0.11082141101360321 first col mean 0.13397592306137085 all mean 0.11270543932914734
0.3367979824542999 0.3367979824542999
rl training, epoch3, iter0, batch781/1133, batch loss:0.3367979824542999, Training time:9966.569623231888
batch reward last col mean 0.16637040674686432 first col mean 0.1203356683254242 all mean 0.15875501930713654
0.3852945864200592 0.3852945864200592
rl training, epoch3, iter0, batch782/1133, batch loss:0.3852945864200592, Training time:9968.208064556122
batch reward last col mean 0.14908845722675323 first col mean 0.12835296988487244 all mean 0.14131851494312286
0.32073119282722473 0.3207312226295471
rl training, epoch3, iter0, batch783/1133, batch loss:0.3207312226295471, Training time:9969.860570192337
batch reward last col mean 0.10083145648241043 first col mean 0.13429704308509827 all mean 0.10761944204568863
0.3509620726108551 0.3509620726108551
rl training, epoch3, iter0, batch784/1133, batch loss:0.3509620726108551, Training time:9972.330525159836
batch reward last col mean 0.11465968191623688 first col mean 0.12525632977485657 all mean 0.11387621611356735
0.3522021174430847 0.35220205783843994
rl training, epoch3, iter0, batch785/1133, batch loss:0.35220205783843994, Training time:9974.56971859932
batch reward last col mean 0.10639993846416473 first col mean 0.11801700294017792 all mean 0.11547059565782547
0.3632037341594696 0.3632037341594696
rl training, epoch3, iter0, batch786/1133, batch loss:0.3632037341594696, Training time:9976.113934755325
batch reward last col mean 0.13470293581485748 first col mean 0.11582563817501068 all mean 0.12837256491184235
0.3122205138206482 0.3122205138206482
rl training, epoch3, iter0, batch787/1133, batch loss:0.3122205138206482, Training time:9978.07732963562
batch reward last col mean 0.09868083149194717 first col mean 0.12730267643928528 all mean 0.10405946522951126
0.31249725818634033 0.31249725818634033
rl training, epoch3, iter0, batch788/1133, batch loss:0.31249725818634033, Training time:9979.928534507751
batch reward last col mean 0.08997505903244019 first col mean 0.10477541387081146 all mean 0.10090518742799759
0.2992205321788788 0.2992205321788788
rl training, epoch3, iter0, batch789/1133, batch loss:0.2992205321788788, Training time:9981.607766389847
batch reward last col mean 0.10782447457313538 first col mean 0.11286914348602295 all mean 0.10786942392587662
0.29601752758026123 0.29601752758026123
rl training, epoch3, iter0, batch790/1133, batch loss:0.29601752758026123, Training time:9983.475957870483
batch reward last col mean 0.13382719457149506 first col mean 0.12895715236663818 all mean 0.13346026837825775
0.3168066143989563 0.3168066442012787
rl training, epoch3, iter0, batch791/1133, batch loss:0.3168066442012787, Training time:9985.623339176178
batch reward last col mean 0.09545017778873444 first col mean 0.13899767398834229 all mean 0.10233494639396667
0.30838632583618164 0.30838629603385925
rl training, epoch3, iter0, batch792/1133, batch loss:0.30838629603385925, Training time:9987.655839443207
batch reward last col mean 0.10610289871692657 first col mean 0.12464840710163116 all mean 0.11225742846727371
0.36822664737701416 0.36822664737701416
rl training, epoch3, iter0, batch793/1133, batch loss:0.36822664737701416, Training time:9989.745106458664
batch reward last col mean 0.09013479948043823 first col mean 0.1316860169172287 all mean 0.09317996352910995
0.28038910031318665 0.28038910031318665
rl training, epoch3, iter0, batch794/1133, batch loss:0.28038910031318665, Training time:9991.657184362411
batch reward last col mean 0.07676512002944946 first col mean 0.11433688551187515 all mean 0.08917903900146484
0.30874547362327576 0.30874547362327576
rl training, epoch3, iter0, batch795/1133, batch loss:0.30874547362327576, Training time:9993.296526193619
batch reward last col mean 0.14860159158706665 first col mean 0.11715896427631378 all mean 0.14232490956783295
0.38638436794281006 0.38638436794281006
rl training, epoch3, iter0, batch796/1133, batch loss:0.38638436794281006, Training time:9995.12344121933
batch reward last col mean 0.10271508991718292 first col mean 0.1202869862318039 all mean 0.10252934694290161
0.35076892375946045 0.35076892375946045
rl training, epoch3, iter0, batch797/1133, batch loss:0.35076892375946045, Training time:9997.820899963379
batch reward last col mean 0.09475279599428177 first col mean 0.1220930963754654 all mean 0.1031176745891571
0.30801311135292053 0.30801311135292053
rl training, epoch3, iter0, batch798/1133, batch loss:0.30801311135292053, Training time:9999.532948970795
batch reward last col mean 0.094988152384758 first col mean 0.13461890816688538 all mean 0.10108751803636551
0.3465048372745514 0.3465048372745514
rl training, epoch3, iter0, batch799/1133, batch loss:0.3465048372745514, Training time:10001.112552165985
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5391010262223334 Time: 99.84871792793274 s
loss of true 0.23915267532522028 loss of gen 0.1893856863557819 loss of other 0.1105626638081099 first score 0.13291287422180176
batch reward last col mean 0.08950421959161758 first col mean 0.09004514664411545 all mean 0.09021342545747757
0.2688424587249756 0.2688424289226532
rl training, epoch3, iter0, batch800/1133, batch loss:0.2688424289226532, Training time:10102.775459766388
batch reward last col mean 0.1143941730260849 first col mean 0.1153196394443512 all mean 0.11815773695707321
0.30707892775535583 0.30707889795303345
rl training, epoch3, iter0, batch801/1133, batch loss:0.30707889795303345, Training time:10104.241549253464
batch reward last col mean 0.11589216440916061 first col mean 0.10995998978614807 all mean 0.1107158213853836
0.2943821847438812 0.29438215494155884
rl training, epoch3, iter0, batch802/1133, batch loss:0.29438215494155884, Training time:10106.462233304977
batch reward last col mean 0.11879795044660568 first col mean 0.10502620041370392 all mean 0.1174776628613472
0.316588819026947 0.316588819026947
rl training, epoch3, iter0, batch803/1133, batch loss:0.316588819026947, Training time:10108.272914886475
batch reward last col mean 0.07323895394802094 first col mean 0.09365539252758026 all mean 0.07959752529859543
0.29030901193618774 0.29030904173851013
rl training, epoch3, iter0, batch804/1133, batch loss:0.29030904173851013, Training time:10110.075305461884
batch reward last col mean 0.08155030757188797 first col mean 0.09836016595363617 all mean 0.09412042051553726
0.33177420496940613 0.33177420496940613
rl training, epoch3, iter0, batch805/1133, batch loss:0.33177420496940613, Training time:10111.973390817642
batch reward last col mean 0.07289436459541321 first col mean 0.10195028781890869 all mean 0.08401697874069214
0.2730304002761841 0.2730303704738617
rl training, epoch3, iter0, batch806/1133, batch loss:0.2730303704738617, Training time:10113.569252967834
batch reward last col mean 0.126485675573349 first col mean 0.11008351296186447 all mean 0.11697140336036682
0.31147855520248413 0.31147855520248413
rl training, epoch3, iter0, batch807/1133, batch loss:0.31147855520248413, Training time:10115.230025291443
batch reward last col mean 0.10716279596090317 first col mean 0.09642289578914642 all mean 0.10963524132966995
0.3210631012916565 0.3210631012916565
rl training, epoch3, iter0, batch808/1133, batch loss:0.3210631012916565, Training time:10117.043511867523
batch reward last col mean 0.1335112452507019 first col mean 0.11237160116434097 all mean 0.12389538437128067
0.3147906959056854 0.3147906959056854
rl training, epoch3, iter0, batch809/1133, batch loss:0.3147906959056854, Training time:10118.925321340561
batch reward last col mean 0.09358496218919754 first col mean 0.10665833950042725 all mean 0.10049349069595337
0.2789560556411743 0.2789560556411743
rl training, epoch3, iter0, batch810/1133, batch loss:0.2789560556411743, Training time:10120.620008707047
batch reward last col mean 0.10958699136972427 first col mean 0.1290019452571869 all mean 0.11288689821958542
0.3242749869823456 0.3242749571800232
rl training, epoch3, iter0, batch811/1133, batch loss:0.3242749571800232, Training time:10122.535478115082
batch reward last col mean 0.1262514293193817 first col mean 0.13002687692642212 all mean 0.11997859925031662
0.34456509351730347 0.34456509351730347
rl training, epoch3, iter0, batch812/1133, batch loss:0.34456509351730347, Training time:10124.776484489441
batch reward last col mean 0.12397508323192596 first col mean 0.12011127918958664 all mean 0.12297587841749191
0.31305062770843506 0.31305062770843506
rl training, epoch3, iter0, batch813/1133, batch loss:0.31305062770843506, Training time:10126.924095153809
batch reward last col mean 0.08144744485616684 first col mean 0.09764321148395538 all mean 0.08502065390348434
0.29878145456314087 0.29878145456314087
rl training, epoch3, iter0, batch814/1133, batch loss:0.29878145456314087, Training time:10128.578477859497
batch reward last col mean 0.09858293831348419 first col mean 0.12717153131961823 all mean 0.10410675406455994
0.27395933866500854 0.27395933866500854
rl training, epoch3, iter0, batch815/1133, batch loss:0.27395933866500854, Training time:10130.457961797714
batch reward last col mean 0.10607333481311798 first col mean 0.09872301667928696 all mean 0.1036926656961441
0.32327961921691895 0.32327961921691895
rl training, epoch3, iter0, batch816/1133, batch loss:0.32327961921691895, Training time:10132.516989946365
batch reward last col mean 0.14252763986587524 first col mean 0.11601350456476212 all mean 0.13144148886203766
0.35662642121315 0.35662642121315
rl training, epoch3, iter0, batch817/1133, batch loss:0.35662642121315, Training time:10134.224467515945
batch reward last col mean 0.1204955205321312 first col mean 0.1350528448820114 all mean 0.1247604638338089
0.33360716700553894 0.33360716700553894
rl training, epoch3, iter0, batch818/1133, batch loss:0.33360716700553894, Training time:10136.114813566208
batch reward last col mean 0.07508869469165802 first col mean 0.10630598664283752 all mean 0.085125632584095
0.2864640951156616 0.2864640951156616
rl training, epoch3, iter0, batch819/1133, batch loss:0.2864640951156616, Training time:10138.086199760437
batch reward last col mean 0.1089688241481781 first col mean 0.11308404803276062 all mean 0.11001560837030411
0.32176244258880615 0.32176241278648376
rl training, epoch3, iter0, batch820/1133, batch loss:0.32176241278648376, Training time:10139.972559690475
batch reward last col mean 0.12194576859474182 first col mean 0.12592190504074097 all mean 0.11957699060440063
0.308826744556427 0.308826744556427
rl training, epoch3, iter0, batch821/1133, batch loss:0.308826744556427, Training time:10142.221768379211
batch reward last col mean 0.11192207038402557 first col mean 0.10972002148628235 all mean 0.10981689393520355
0.3370814919471741 0.3370814919471741
rl training, epoch3, iter0, batch822/1133, batch loss:0.3370814919471741, Training time:10144.476959228516
batch reward last col mean 0.0880984291434288 first col mean 0.1357862949371338 all mean 0.09059330821037292
0.25669190287590027 0.2566918730735779
rl training, epoch3, iter0, batch823/1133, batch loss:0.2566918730735779, Training time:10146.601594924927
batch reward last col mean 0.09801696240901947 first col mean 0.11794626712799072 all mean 0.10033170133829117
0.3113517165184021 0.3113517165184021
rl training, epoch3, iter0, batch824/1133, batch loss:0.3113517165184021, Training time:10148.898230075836
batch reward last col mean 0.14988312125205994 first col mean 0.11271499842405319 all mean 0.1359815150499344
0.32896748185157776 0.32896748185157776
rl training, epoch3, iter0, batch825/1133, batch loss:0.32896748185157776, Training time:10150.692018985748
batch reward last col mean 0.12614211440086365 first col mean 0.13774201273918152 all mean 0.11490008234977722
0.32379019260406494 0.32379019260406494
rl training, epoch3, iter0, batch826/1133, batch loss:0.32379019260406494, Training time:10152.52017211914
batch reward last col mean 0.10466496646404266 first col mean 0.11140179634094238 all mean 0.1067037358880043
0.3051002025604248 0.3051002025604248
rl training, epoch3, iter0, batch827/1133, batch loss:0.3051002025604248, Training time:10154.405203580856
batch reward last col mean 0.11102236062288284 first col mean 0.1355707198381424 all mean 0.10942970216274261
0.33499303460121155 0.33499306440353394
rl training, epoch3, iter0, batch828/1133, batch loss:0.33499306440353394, Training time:10157.32366156578
batch reward last col mean 0.11289668828248978 first col mean 0.13761532306671143 all mean 0.11367861926555634
0.32365894317626953 0.32365894317626953
rl training, epoch3, iter0, batch829/1133, batch loss:0.32365894317626953, Training time:10159.268526792526
batch reward last col mean 0.09291741251945496 first col mean 0.09527293592691422 all mean 0.10455892980098724
0.32577356696128845 0.32577356696128845
rl training, epoch3, iter0, batch830/1133, batch loss:0.32577356696128845, Training time:10161.713244915009
batch reward last col mean 0.12527352571487427 first col mean 0.1276906579732895 all mean 0.12410418689250946
0.33248552680015564 0.33248552680015564
rl training, epoch3, iter0, batch831/1133, batch loss:0.33248552680015564, Training time:10164.49699139595
batch reward last col mean 0.10291557013988495 first col mean 0.12396107614040375 all mean 0.10530322045087814
0.3168724477291107 0.3168724477291107
rl training, epoch3, iter0, batch832/1133, batch loss:0.3168724477291107, Training time:10166.397453308105
batch reward last col mean 0.0859585851430893 first col mean 0.11703532934188843 all mean 0.09276702255010605
0.27448323369026184 0.27448323369026184
rl training, epoch3, iter0, batch833/1133, batch loss:0.27448323369026184, Training time:10168.284567832947
batch reward last col mean 0.11469259858131409 first col mean 0.10550583153963089 all mean 0.11141793429851532
0.3014516532421112 0.3014516532421112
rl training, epoch3, iter0, batch834/1133, batch loss:0.3014516532421112, Training time:10170.35282254219
batch reward last col mean 0.0913376659154892 first col mean 0.1278148740530014 all mean 0.09553699940443039
0.2877468168735504 0.2877468168735504
rl training, epoch3, iter0, batch835/1133, batch loss:0.2877468168735504, Training time:10172.923963069916
batch reward last col mean 0.10207659006118774 first col mean 0.12743252515792847 all mean 0.10690392553806305
0.33525440096855164 0.33525440096855164
rl training, epoch3, iter0, batch836/1133, batch loss:0.33525440096855164, Training time:10174.671432495117
batch reward last col mean 0.11108297854661942 first col mean 0.11336777359247208 all mean 0.10897654294967651
0.27700310945510864 0.27700310945510864
rl training, epoch3, iter0, batch837/1133, batch loss:0.27700310945510864, Training time:10176.838530540466
batch reward last col mean 0.10223458707332611 first col mean 0.12302228808403015 all mean 0.10526187717914581
0.31482061743736267 0.31482061743736267
rl training, epoch3, iter0, batch838/1133, batch loss:0.31482061743736267, Training time:10178.671122550964
batch reward last col mean 0.08368007838726044 first col mean 0.10260195285081863 all mean 0.09192991256713867
0.2953329384326935 0.2953329384326935
rl training, epoch3, iter0, batch839/1133, batch loss:0.2953329384326935, Training time:10181.021245718002
batch reward last col mean 0.13093358278274536 first col mean 0.1057051569223404 all mean 0.12567557394504547
0.33896344900131226 0.33896344900131226
rl training, epoch3, iter0, batch840/1133, batch loss:0.33896344900131226, Training time:10183.344955921173
batch reward last col mean 0.10434085130691528 first col mean 0.12152162194252014 all mean 0.10735560208559036
0.3623230755329132 0.3623230755329132
rl training, epoch3, iter0, batch841/1133, batch loss:0.3623230755329132, Training time:10185.461379766464
batch reward last col mean 0.09341739118099213 first col mean 0.1267411857843399 all mean 0.1064063310623169
0.3328058421611786 0.3328058123588562
rl training, epoch3, iter0, batch842/1133, batch loss:0.3328058123588562, Training time:10187.239265203476
batch reward last col mean 0.11846363544464111 first col mean 0.120329350233078 all mean 0.11867981404066086
0.33179715275764465 0.33179715275764465
rl training, epoch3, iter0, batch843/1133, batch loss:0.33179715275764465, Training time:10189.265547037125
batch reward last col mean 0.08263160288333893 first col mean 0.13176727294921875 all mean 0.08628625422716141
0.2940899729728699 0.2940899729728699
rl training, epoch3, iter0, batch844/1133, batch loss:0.2940899729728699, Training time:10192.063112020493
batch reward last col mean 0.07747039943933487 first col mean 0.11501042544841766 all mean 0.08984382450580597
0.2865217924118042 0.2865217924118042
rl training, epoch3, iter0, batch845/1133, batch loss:0.2865217924118042, Training time:10193.971066236496
batch reward last col mean 0.09465022385120392 first col mean 0.12863658368587494 all mean 0.09660398215055466
0.2883220911026001 0.2883220911026001
rl training, epoch3, iter0, batch846/1133, batch loss:0.2883220911026001, Training time:10196.39666390419
batch reward last col mean 0.11326222866773605 first col mean 0.09973661601543427 all mean 0.107325978577137
0.31576773524284363 0.31576773524284363
rl training, epoch3, iter0, batch847/1133, batch loss:0.31576773524284363, Training time:10198.82645869255
batch reward last col mean 0.10146795213222504 first col mean 0.11540861427783966 all mean 0.10616730153560638
0.31085827946662903 0.31085824966430664
rl training, epoch3, iter0, batch848/1133, batch loss:0.31085824966430664, Training time:10201.251989126205
batch reward last col mean 0.11767274141311646 first col mean 0.1134461984038353 all mean 0.11492208391427994
0.31553274393081665 0.31553274393081665
rl training, epoch3, iter0, batch849/1133, batch loss:0.31553274393081665, Training time:10203.728048324585
batch reward last col mean 0.11230045557022095 first col mean 0.11234204471111298 all mean 0.11510059982538223
0.3604183495044708 0.3604183495044708
rl training, epoch3, iter0, batch850/1133, batch loss:0.3604183495044708, Training time:10206.113819122314
batch reward last col mean 0.113284170627594 first col mean 0.09582772850990295 all mean 0.11224593967199326
0.2847863435745239 0.2847863435745239
rl training, epoch3, iter0, batch851/1133, batch loss:0.2847863435745239, Training time:10208.440527677536
batch reward last col mean 0.12084927409887314 first col mean 0.10698077082633972 all mean 0.11943767219781876
0.32948267459869385 0.32948267459869385
rl training, epoch3, iter0, batch852/1133, batch loss:0.32948267459869385, Training time:10211.148042678833
batch reward last col mean 0.11731746792793274 first col mean 0.10539337992668152 all mean 0.11255281418561935
0.3244142234325409 0.3244142234325409
rl training, epoch3, iter0, batch853/1133, batch loss:0.3244142234325409, Training time:10212.866171836853
batch reward last col mean 0.11452233046293259 first col mean 0.11636614799499512 all mean 0.1125374585390091
0.30685797333717346 0.3068579435348511
rl training, epoch3, iter0, batch854/1133, batch loss:0.3068579435348511, Training time:10214.628868341446
batch reward last col mean 0.11638277769088745 first col mean 0.125242218375206 all mean 0.11614330857992172
0.34891706705093384 0.34891706705093384
rl training, epoch3, iter0, batch855/1133, batch loss:0.34891706705093384, Training time:10216.441328048706
batch reward last col mean 0.09100290387868881 first col mean 0.12289533019065857 all mean 0.09449539333581924
0.3085767924785614 0.3085767924785614
rl training, epoch3, iter0, batch856/1133, batch loss:0.3085767924785614, Training time:10218.514214754105
batch reward last col mean 0.12989355623722076 first col mean 0.13449779152870178 all mean 0.12683221697807312
0.3539993464946747 0.3539993464946747
rl training, epoch3, iter0, batch857/1133, batch loss:0.3539993464946747, Training time:10220.390076637268
batch reward last col mean 0.1135110855102539 first col mean 0.12488614022731781 all mean 0.11702477931976318
0.3289334177970886 0.3289334177970886
rl training, epoch3, iter0, batch858/1133, batch loss:0.3289334177970886, Training time:10222.356006383896
batch reward last col mean 0.10614807903766632 first col mean 0.12070275098085403 all mean 0.1107354462146759
0.3274562358856201 0.3274562358856201
rl training, epoch3, iter0, batch859/1133, batch loss:0.3274562358856201, Training time:10225.21304345131
batch reward last col mean 0.13174180686473846 first col mean 0.11582794785499573 all mean 0.12471402436494827
0.31454309821128845 0.31454309821128845
rl training, epoch3, iter0, batch860/1133, batch loss:0.31454309821128845, Training time:10227.02300953865
batch reward last col mean 0.10329899936914444 first col mean 0.10057923197746277 all mean 0.10747804492712021
0.3379652202129364 0.3379652202129364
rl training, epoch3, iter0, batch861/1133, batch loss:0.3379652202129364, Training time:10228.684881448746
batch reward last col mean 0.09085564315319061 first col mean 0.12188991159200668 all mean 0.09632616490125656
0.28416451811790466 0.28416451811790466
rl training, epoch3, iter0, batch862/1133, batch loss:0.28416451811790466, Training time:10230.653734445572
batch reward last col mean 0.13759306073188782 first col mean 0.11522992700338364 all mean 0.12611281871795654
0.33436116576194763 0.33436116576194763
rl training, epoch3, iter0, batch863/1133, batch loss:0.33436116576194763, Training time:10232.67611527443
batch reward last col mean 0.09572379291057587 first col mean 0.11628695577383041 all mean 0.10559934377670288
0.32730409502983093 0.32730409502983093
rl training, epoch3, iter0, batch864/1133, batch loss:0.32730409502983093, Training time:10234.669216871262
batch reward last col mean 0.107320137321949 first col mean 0.1161116287112236 all mean 0.11347861588001251
0.34622034430503845 0.34622034430503845
rl training, epoch3, iter0, batch865/1133, batch loss:0.34622034430503845, Training time:10236.622883319855
batch reward last col mean 0.1303202509880066 first col mean 0.14622089266777039 all mean 0.13053283095359802
0.3688846230506897 0.3688846528530121
rl training, epoch3, iter0, batch866/1133, batch loss:0.3688846528530121, Training time:10238.976369857788
batch reward last col mean 0.10042847692966461 first col mean 0.13058532774448395 all mean 0.10750986635684967
0.31866487860679626 0.31866487860679626
rl training, epoch3, iter0, batch867/1133, batch loss:0.31866487860679626, Training time:10241.300822496414
batch reward last col mean 0.12551099061965942 first col mean 0.13052457571029663 all mean 0.1265014410018921
0.3645576238632202 0.3645576238632202
rl training, epoch3, iter0, batch868/1133, batch loss:0.3645576238632202, Training time:10243.325935602188
batch reward last col mean 0.13441021740436554 first col mean 0.1285964846611023 all mean 0.13687987625598907
0.4007694721221924 0.4007694721221924
rl training, epoch3, iter0, batch869/1133, batch loss:0.4007694721221924, Training time:10245.338684082031
batch reward last col mean 0.06550350785255432 first col mean 0.12656086683273315 all mean 0.08127401024103165
0.2969100773334503 0.2969100773334503
rl training, epoch3, iter0, batch870/1133, batch loss:0.2969100773334503, Training time:10247.029627084732
batch reward last col mean 0.08466605842113495 first col mean 0.12645211815834045 all mean 0.09751147031784058
0.2868325710296631 0.2868325710296631
rl training, epoch3, iter0, batch871/1133, batch loss:0.2868325710296631, Training time:10248.846517801285
batch reward last col mean 0.11143050342798233 first col mean 0.12370911985635757 all mean 0.11789578199386597
0.34477534890174866 0.34477534890174866
rl training, epoch3, iter0, batch872/1133, batch loss:0.34477534890174866, Training time:10250.718443870544
batch reward last col mean 0.10155686736106873 first col mean 0.12822307646274567 all mean 0.10698341578245163
0.31865158677101135 0.31865158677101135
rl training, epoch3, iter0, batch873/1133, batch loss:0.31865158677101135, Training time:10252.862247228622
batch reward last col mean 0.11406469345092773 first col mean 0.12690365314483643 all mean 0.11130525916814804
0.299960732460022 0.299960732460022
rl training, epoch3, iter0, batch874/1133, batch loss:0.299960732460022, Training time:10254.988143205643
batch reward last col mean 0.10725235939025879 first col mean 0.1322052925825119 all mean 0.10699322819709778
0.3010382652282715 0.3010382652282715
rl training, epoch3, iter0, batch875/1133, batch loss:0.3010382652282715, Training time:10257.196615219116
batch reward last col mean 0.12682418525218964 first col mean 0.1224600076675415 all mean 0.12445728480815887
0.31506842374801636 0.31506842374801636
rl training, epoch3, iter0, batch876/1133, batch loss:0.31506842374801636, Training time:10259.813750267029
batch reward last col mean 0.08709312975406647 first col mean 0.12557348608970642 all mean 0.10136577486991882
0.3352062404155731 0.3352062404155731
rl training, epoch3, iter0, batch877/1133, batch loss:0.3352062404155731, Training time:10261.609179496765
batch reward last col mean 0.12459303438663483 first col mean 0.12884919345378876 all mean 0.12038776278495789
0.296522319316864 0.296522319316864
rl training, epoch3, iter0, batch878/1133, batch loss:0.296522319316864, Training time:10264.117018222809
batch reward last col mean 0.1131691187620163 first col mean 0.11948543787002563 all mean 0.11595680564641953
0.3400127589702606 0.3400127589702606
rl training, epoch3, iter0, batch879/1133, batch loss:0.3400127589702606, Training time:10265.964079618454
batch reward last col mean 0.11009562760591507 first col mean 0.13142116367816925 all mean 0.10931786149740219
0.312200129032135 0.312200129032135
rl training, epoch3, iter0, batch880/1133, batch loss:0.312200129032135, Training time:10267.877441883087
batch reward last col mean 0.09492479264736176 first col mean 0.13430742919445038 all mean 0.10322099924087524
0.3443581461906433 0.3443581759929657
rl training, epoch3, iter0, batch881/1133, batch loss:0.3443581759929657, Training time:10270.227301120758
batch reward last col mean 0.10610412061214447 first col mean 0.11698132008314133 all mean 0.11971191316843033
0.33563023805618286 0.33563026785850525
rl training, epoch3, iter0, batch882/1133, batch loss:0.33563026785850525, Training time:10272.541172504425
batch reward last col mean 0.1234302967786789 first col mean 0.12915289402008057 all mean 0.12630926072597504
0.36616572737693787 0.36616572737693787
rl training, epoch3, iter0, batch883/1133, batch loss:0.36616572737693787, Training time:10276.316653251648
batch reward last col mean 0.10223596543073654 first col mean 0.12398001551628113 all mean 0.10508646070957184
0.34472277760505676 0.34472277760505676
rl training, epoch3, iter0, batch884/1133, batch loss:0.34472277760505676, Training time:10278.457886457443
batch reward last col mean 0.12962467968463898 first col mean 0.11727404594421387 all mean 0.12361299246549606
0.3239092230796814 0.3239092230796814
rl training, epoch3, iter0, batch885/1133, batch loss:0.3239092230796814, Training time:10280.846124649048
batch reward last col mean 0.1110912561416626 first col mean 0.12065459787845612 all mean 0.115447998046875
0.35840389132499695 0.35840389132499695
rl training, epoch3, iter0, batch886/1133, batch loss:0.35840389132499695, Training time:10283.323806762695
batch reward last col mean 0.10618063807487488 first col mean 0.10774926841259003 all mean 0.11143508553504944
0.3139971196651459 0.3139971196651459
rl training, epoch3, iter0, batch887/1133, batch loss:0.3139971196651459, Training time:10285.372719287872
batch reward last col mean 0.10107222199440002 first col mean 0.10620405524969101 all mean 0.10324058681726456
0.3148474395275116 0.3148474395275116
rl training, epoch3, iter0, batch888/1133, batch loss:0.3148474395275116, Training time:10288.148753404617
batch reward last col mean 0.1308840811252594 first col mean 0.09960859268903732 all mean 0.12456371635198593
0.3481295108795166 0.3481295108795166
rl training, epoch3, iter0, batch889/1133, batch loss:0.3481295108795166, Training time:10290.456932544708
batch reward last col mean 0.1450451910495758 first col mean 0.1437716782093048 all mean 0.14366085827350616
0.3680926561355591 0.3680926561355591
rl training, epoch3, iter0, batch890/1133, batch loss:0.3680926561355591, Training time:10292.576033353806
batch reward last col mean 0.153229221701622 first col mean 0.1163216084241867 all mean 0.1442786604166031
0.3731791079044342 0.3731791079044342
rl training, epoch3, iter0, batch891/1133, batch loss:0.3731791079044342, Training time:10294.996022224426
batch reward last col mean 0.133143350481987 first col mean 0.1313648372888565 all mean 0.1325429379940033
0.4111258089542389 0.4111258089542389
rl training, epoch3, iter0, batch892/1133, batch loss:0.4111258089542389, Training time:10296.925190448761
batch reward last col mean 0.07920895516872406 first col mean 0.12787246704101562 all mean 0.09049299359321594
0.30945584177970886 0.30945584177970886
rl training, epoch3, iter0, batch893/1133, batch loss:0.30945584177970886, Training time:10299.14036154747
batch reward last col mean 0.13614949584007263 first col mean 0.1185881569981575 all mean 0.12829001247882843
0.34218207001686096 0.34218207001686096
rl training, epoch3, iter0, batch894/1133, batch loss:0.34218207001686096, Training time:10301.56043624878
batch reward last col mean 0.10708983242511749 first col mean 0.13106399774551392 all mean 0.11117656528949738
0.35965579748153687 0.35965579748153687
rl training, epoch3, iter0, batch895/1133, batch loss:0.35965579748153687, Training time:10303.816939592361
batch reward last col mean 0.12215680629014969 first col mean 0.12017952650785446 all mean 0.11792297661304474
0.3635115623474121 0.3635115623474121
rl training, epoch3, iter0, batch896/1133, batch loss:0.3635115623474121, Training time:10306.639335632324
batch reward last col mean 0.08888812363147736 first col mean 0.12157370150089264 all mean 0.09857746213674545
0.28529658913612366 0.28529658913612366
rl training, epoch3, iter0, batch897/1133, batch loss:0.28529658913612366, Training time:10308.843014001846
batch reward last col mean 0.1464270055294037 first col mean 0.1183350458741188 all mean 0.1411903202533722
0.35098516941070557 0.35098516941070557
rl training, epoch3, iter0, batch898/1133, batch loss:0.35098516941070557, Training time:10310.888582706451
batch reward last col mean 0.08998296409845352 first col mean 0.11465011537075043 all mean 0.09930713474750519
0.30577927827835083 0.30577927827835083
rl training, epoch3, iter0, batch899/1133, batch loss:0.30577927827835083, Training time:10312.968720912933
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5360765749126647 Time: 103.96033382415771 s
loss of true 0.2368525701648139 loss of gen 0.18853518914592446 loss of other 0.11068881559206234 first score 0.15984642505645752
batch reward last col mean 0.094965860247612 first col mean 0.11678419262170792 all mean 0.1051589697599411
0.3391611874103546 0.3391611874103546
rl training, epoch3, iter0, batch900/1133, batch loss:0.3391611874103546, Training time:10418.992179870605
batch reward last col mean 0.12944737076759338 first col mean 0.11562173068523407 all mean 0.12164255231618881
0.30185091495513916 0.30185097455978394
rl training, epoch3, iter0, batch901/1133, batch loss:0.30185097455978394, Training time:10420.604040145874
batch reward last col mean 0.09688422083854675 first col mean 0.10776159167289734 all mean 0.10501322150230408
0.30052995681762695 0.30052995681762695
rl training, epoch3, iter0, batch902/1133, batch loss:0.30052995681762695, Training time:10422.729408979416
batch reward last col mean 0.10357387363910675 first col mean 0.12277814000844955 all mean 0.10894380509853363
0.29293230175971985 0.29293230175971985
rl training, epoch3, iter0, batch903/1133, batch loss:0.29293230175971985, Training time:10424.934577703476
batch reward last col mean 0.10952208936214447 first col mean 0.13644665479660034 all mean 0.1132090762257576
0.31924381852149963 0.31924381852149963
rl training, epoch3, iter0, batch904/1133, batch loss:0.31924381852149963, Training time:10427.817047834396
batch reward last col mean 0.1234615221619606 first col mean 0.10869249701499939 all mean 0.12204782664775848
0.3417727053165436 0.3417727053165436
rl training, epoch3, iter0, batch905/1133, batch loss:0.3417727053165436, Training time:10430.63795375824
batch reward last col mean 0.12541358172893524 first col mean 0.11532960832118988 all mean 0.11951033771038055
0.3078146278858185 0.3078146278858185
rl training, epoch3, iter0, batch906/1133, batch loss:0.3078146278858185, Training time:10432.807356119156
batch reward last col mean 0.0987626165151596 first col mean 0.12680195271968842 all mean 0.10340404510498047
0.3110825717449188 0.3110825717449188
rl training, epoch3, iter0, batch907/1133, batch loss:0.3110825717449188, Training time:10435.066267490387
batch reward last col mean 0.10855002701282501 first col mean 0.10830457508563995 all mean 0.10600495338439941
0.3071289360523224 0.3071289658546448
rl training, epoch3, iter0, batch908/1133, batch loss:0.3071289658546448, Training time:10437.557370901108
batch reward last col mean 0.11653253436088562 first col mean 0.10856883972883224 all mean 0.10884649306535721
0.3200457990169525 0.3200457990169525
rl training, epoch3, iter0, batch909/1133, batch loss:0.3200457990169525, Training time:10439.295927524567
batch reward last col mean 0.07948923856019974 first col mean 0.11837001144886017 all mean 0.08373718708753586
0.2895320653915405 0.2895320653915405
rl training, epoch3, iter0, batch910/1133, batch loss:0.2895320653915405, Training time:10441.50222659111
batch reward last col mean 0.13824620842933655 first col mean 0.10328929871320724 all mean 0.1323477178812027
0.34889787435531616 0.3488978445529938
rl training, epoch3, iter0, batch911/1133, batch loss:0.3488978445529938, Training time:10443.832051992416
batch reward last col mean 0.13224506378173828 first col mean 0.11983902752399445 all mean 0.12894459068775177
0.3665914833545685 0.3665914833545685
rl training, epoch3, iter0, batch912/1133, batch loss:0.3665914833545685, Training time:10446.38687133789
batch reward last col mean 0.10058190673589706 first col mean 0.09748576581478119 all mean 0.10811688750982285
0.33959344029426575 0.33959338068962097
rl training, epoch3, iter0, batch913/1133, batch loss:0.33959338068962097, Training time:10448.820974111557
batch reward last col mean 0.12456159293651581 first col mean 0.12075404077768326 all mean 0.123699851334095
0.33996355533599854 0.33996355533599854
rl training, epoch3, iter0, batch914/1133, batch loss:0.33996355533599854, Training time:10451.265429019928
batch reward last col mean 0.15319910645484924 first col mean 0.12119957059621811 all mean 0.14684954285621643
0.33867529034614563 0.33867529034614563
rl training, epoch3, iter0, batch915/1133, batch loss:0.33867529034614563, Training time:10452.991354703903
batch reward last col mean 0.15667802095413208 first col mean 0.12892208993434906 all mean 0.14842119812965393
0.34277909994125366 0.34277909994125366
rl training, epoch3, iter0, batch916/1133, batch loss:0.34277909994125366, Training time:10455.053721904755
batch reward last col mean 0.11200679838657379 first col mean 0.13836659491062164 all mean 0.11510942131280899
0.3372364044189453 0.3372364342212677
rl training, epoch3, iter0, batch917/1133, batch loss:0.3372364342212677, Training time:10457.797246694565
batch reward last col mean 0.1056978851556778 first col mean 0.09548115730285645 all mean 0.10603542625904083
0.33884352445602417 0.33884352445602417
rl training, epoch3, iter0, batch918/1133, batch loss:0.33884352445602417, Training time:10460.479897022247
batch reward last col mean 0.13474354147911072 first col mean 0.11409132927656174 all mean 0.1323162168264389
0.3304649889469147 0.3304649889469147
rl training, epoch3, iter0, batch919/1133, batch loss:0.3304649889469147, Training time:10462.4650182724
batch reward last col mean 0.11486586928367615 first col mean 0.12748537957668304 all mean 0.11297047138214111
0.3159683346748352 0.3159683346748352
rl training, epoch3, iter0, batch920/1133, batch loss:0.3159683346748352, Training time:10465.2596347332
batch reward last col mean 0.08764439821243286 first col mean 0.10499530285596848 all mean 0.09958982467651367
0.3339601755142212 0.3339601755142212
rl training, epoch3, iter0, batch921/1133, batch loss:0.3339601755142212, Training time:10467.06919002533
batch reward last col mean 0.12091466784477234 first col mean 0.10007313638925552 all mean 0.11742676049470901
0.2920302748680115 0.2920302748680115
rl training, epoch3, iter0, batch922/1133, batch loss:0.2920302748680115, Training time:10469.214856147766
batch reward last col mean 0.1572524458169937 first col mean 0.11681875586509705 all mean 0.1540215015411377
0.3798215985298157 0.3798215985298157
rl training, epoch3, iter0, batch923/1133, batch loss:0.3798215985298157, Training time:10471.910772800446
batch reward last col mean 0.16556426882743835 first col mean 0.12473360449075699 all mean 0.149769589304924
0.38351720571517944 0.38351720571517944
rl training, epoch3, iter0, batch924/1133, batch loss:0.38351720571517944, Training time:10474.12298822403
batch reward last col mean 0.10502397269010544 first col mean 0.1354040950536728 all mean 0.11372268944978714
0.3470079004764557 0.3470079302787781
rl training, epoch3, iter0, batch925/1133, batch loss:0.3470079302787781, Training time:10476.411221265793
batch reward last col mean 0.1355055719614029 first col mean 0.13561928272247314 all mean 0.1300455778837204
0.31625279784202576 0.31625276803970337
rl training, epoch3, iter0, batch926/1133, batch loss:0.31625276803970337, Training time:10478.856089115143
batch reward last col mean 0.12271581590175629 first col mean 0.11730754375457764 all mean 0.1252732127904892
0.2976595163345337 0.2976595163345337
rl training, epoch3, iter0, batch927/1133, batch loss:0.2976595163345337, Training time:10480.952304124832
batch reward last col mean 0.10480423271656036 first col mean 0.11446856707334518 all mean 0.10612021386623383
0.3071688115596771 0.3071688115596771
rl training, epoch3, iter0, batch928/1133, batch loss:0.3071688115596771, Training time:10483.809444665909
batch reward last col mean 0.1250314861536026 first col mean 0.13049888610839844 all mean 0.12448999285697937
0.3037092983722687 0.30370932817459106
rl training, epoch3, iter0, batch929/1133, batch loss:0.30370932817459106, Training time:10486.180341243744
batch reward last col mean 0.07821167260408401 first col mean 0.11339698731899261 all mean 0.09176529943943024
0.31330764293670654 0.31330764293670654
rl training, epoch3, iter0, batch930/1133, batch loss:0.31330764293670654, Training time:10488.37624502182
batch reward last col mean 0.11796298623085022 first col mean 0.11949954926967621 all mean 0.12016472965478897
0.30313268303871155 0.30313268303871155
rl training, epoch3, iter0, batch931/1133, batch loss:0.30313268303871155, Training time:10490.231346130371
batch reward last col mean 0.13255727291107178 first col mean 0.11743621528148651 all mean 0.127370685338974
0.4133627712726593 0.4133627712726593
rl training, epoch3, iter0, batch932/1133, batch loss:0.4133627712726593, Training time:10492.58016371727
batch reward last col mean 0.11407221853733063 first col mean 0.11214283108711243 all mean 0.11687172949314117
0.336117148399353 0.336117148399353
rl training, epoch3, iter0, batch933/1133, batch loss:0.336117148399353, Training time:10495.222643136978
batch reward last col mean 0.11731813102960587 first col mean 0.126231849193573 all mean 0.12241581082344055
0.3567165434360504 0.3567165434360504
rl training, epoch3, iter0, batch934/1133, batch loss:0.3567165434360504, Training time:10497.332879781723
batch reward last col mean 0.1144329160451889 first col mean 0.13253769278526306 all mean 0.11804483830928802
0.3698605000972748 0.3698605000972748
rl training, epoch3, iter0, batch935/1133, batch loss:0.3698605000972748, Training time:10499.13146686554
batch reward last col mean 0.08788831532001495 first col mean 0.12402325123548508 all mean 0.09838562458753586
0.31018027663230896 0.31018027663230896
rl training, epoch3, iter0, batch936/1133, batch loss:0.31018027663230896, Training time:10501.243663311005
batch reward last col mean 0.13310858607292175 first col mean 0.11272302269935608 all mean 0.1295589655637741
0.37118756771087646 0.37118756771087646
rl training, epoch3, iter0, batch937/1133, batch loss:0.37118756771087646, Training time:10503.455476045609
batch reward last col mean 0.09825782477855682 first col mean 0.13857893645763397 all mean 0.10820579528808594
0.376130610704422 0.376130610704422
rl training, epoch3, iter0, batch938/1133, batch loss:0.376130610704422, Training time:10505.880011081696
batch reward last col mean 0.15868860483169556 first col mean 0.1299385130405426 all mean 0.15425845980644226
0.4107498526573181 0.4107498526573181
rl training, epoch3, iter0, batch939/1133, batch loss:0.4107498526573181, Training time:10508.140942573547
batch reward last col mean 0.11185652762651443 first col mean 0.12086337804794312 all mean 0.11704663932323456
0.3564789295196533 0.3564789295196533
rl training, epoch3, iter0, batch940/1133, batch loss:0.3564789295196533, Training time:10510.532829999924
batch reward last col mean 0.12289445102214813 first col mean 0.10221520811319351 all mean 0.1180073693394661
0.3727896511554718 0.3727896511554718
rl training, epoch3, iter0, batch941/1133, batch loss:0.3727896511554718, Training time:10512.816626548767
batch reward last col mean 0.11908453702926636 first col mean 0.11743806302547455 all mean 0.11952213943004608
0.3540854752063751 0.3540854752063751
rl training, epoch3, iter0, batch942/1133, batch loss:0.3540854752063751, Training time:10514.48356962204
batch reward last col mean 0.14662690460681915 first col mean 0.1512167900800705 all mean 0.14500978589057922
0.43728944659233093 0.43728944659233093
rl training, epoch3, iter0, batch943/1133, batch loss:0.43728944659233093, Training time:10516.486454963684
batch reward last col mean 0.14741745591163635 first col mean 0.12358064949512482 all mean 0.13710784912109375
0.4106913208961487 0.4106913208961487
rl training, epoch3, iter0, batch944/1133, batch loss:0.4106913208961487, Training time:10518.977232694626
batch reward last col mean 0.11388201266527176 first col mean 0.1409318447113037 all mean 0.11895421892404556
0.37528935074806213 0.37528935074806213
rl training, epoch3, iter0, batch945/1133, batch loss:0.37528935074806213, Training time:10520.805773496628
batch reward last col mean 0.07821290194988251 first col mean 0.10908599942922592 all mean 0.08488896489143372
0.2748980224132538 0.2748979926109314
rl training, epoch3, iter0, batch946/1133, batch loss:0.2748979926109314, Training time:10522.714643716812
batch reward last col mean 0.09189443290233612 first col mean 0.11841251701116562 all mean 0.10161945968866348
0.3436538875102997 0.3436538875102997
rl training, epoch3, iter0, batch947/1133, batch loss:0.3436538875102997, Training time:10524.584945678711
batch reward last col mean 0.15763133764266968 first col mean 0.16015687584877014 all mean 0.15668974816799164
0.40278705954551697 0.40278705954551697
rl training, epoch3, iter0, batch948/1133, batch loss:0.40278705954551697, Training time:10526.5554728508
batch reward last col mean 0.1193573921918869 first col mean 0.12963587045669556 all mean 0.12176713347434998
0.3591381907463074 0.3591381907463074
rl training, epoch3, iter0, batch949/1133, batch loss:0.3591381907463074, Training time:10528.44755101204
batch reward last col mean 0.1472259759902954 first col mean 0.13342569768428802 all mean 0.14444704353809357
0.44601237773895264 0.44601237773895264
rl training, epoch3, iter0, batch950/1133, batch loss:0.44601237773895264, Training time:10530.770925045013
batch reward last col mean 0.11404770612716675 first col mean 0.12845838069915771 all mean 0.11992774903774261
0.33809229731559753 0.33809229731559753
rl training, epoch3, iter0, batch951/1133, batch loss:0.33809229731559753, Training time:10532.768709421158
batch reward last col mean 0.10795384645462036 first col mean 0.12697167694568634 all mean 0.10982780903577805
0.3319539725780487 0.3319539725780487
rl training, epoch3, iter0, batch952/1133, batch loss:0.3319539725780487, Training time:10535.239853143692
batch reward last col mean 0.11942638456821442 first col mean 0.14651817083358765 all mean 0.12393367290496826
0.4040188491344452 0.4040188491344452
rl training, epoch3, iter0, batch953/1133, batch loss:0.4040188491344452, Training time:10537.13523721695
batch reward last col mean 0.11593112349510193 first col mean 0.11955705285072327 all mean 0.11386734247207642
0.3097637891769409 0.3097637891769409
rl training, epoch3, iter0, batch954/1133, batch loss:0.3097637891769409, Training time:10539.83823132515
batch reward last col mean 0.13694074749946594 first col mean 0.1109762191772461 all mean 0.130607470870018
0.35788923501968384 0.35788923501968384
rl training, epoch3, iter0, batch955/1133, batch loss:0.35788923501968384, Training time:10541.451897382736
batch reward last col mean 0.1483488380908966 first col mean 0.13449853658676147 all mean 0.13960346579551697
0.3930428624153137 0.3930428624153137
rl training, epoch3, iter0, batch956/1133, batch loss:0.3930428624153137, Training time:10542.971403121948
batch reward last col mean 0.1113421618938446 first col mean 0.11396914720535278 all mean 0.10846927016973495
0.33948540687561035 0.33948540687561035
rl training, epoch3, iter0, batch957/1133, batch loss:0.33948540687561035, Training time:10544.691861152649
batch reward last col mean 0.12380298972129822 first col mean 0.13219963014125824 all mean 0.12538567185401917
0.3748714029788971 0.3748714029788971
rl training, epoch3, iter0, batch958/1133, batch loss:0.3748714029788971, Training time:10546.644476652145
batch reward last col mean 0.14256896078586578 first col mean 0.12206865847110748 all mean 0.13796992599964142
0.3603270649909973 0.3603270649909973
rl training, epoch3, iter0, batch959/1133, batch loss:0.3603270649909973, Training time:10548.98844909668
batch reward last col mean 0.13174936175346375 first col mean 0.1273307055234909 all mean 0.13385193049907684
0.41651448607444763 0.41651448607444763
rl training, epoch3, iter0, batch960/1133, batch loss:0.41651448607444763, Training time:10550.884160757065
batch reward last col mean 0.1332552284002304 first col mean 0.1204865500330925 all mean 0.1363833248615265
0.3814181387424469 0.3814181387424469
rl training, epoch3, iter0, batch961/1133, batch loss:0.3814181387424469, Training time:10552.555456638336
batch reward last col mean 0.1472664177417755 first col mean 0.11551661044359207 all mean 0.13579538464546204
0.38356465101242065 0.38356465101242065
rl training, epoch3, iter0, batch962/1133, batch loss:0.38356465101242065, Training time:10554.246275424957
batch reward last col mean 0.12646228075027466 first col mean 0.11779208481311798 all mean 0.13016055524349213
0.3874457776546478 0.3874457776546478
rl training, epoch3, iter0, batch963/1133, batch loss:0.3874457776546478, Training time:10555.933539152145
batch reward last col mean 0.12751397490501404 first col mean 0.12530677020549774 all mean 0.12299342453479767
0.3690578043460846 0.3690578043460846
rl training, epoch3, iter0, batch964/1133, batch loss:0.3690578043460846, Training time:10557.718708276749
batch reward last col mean 0.13834668695926666 first col mean 0.12156502157449722 all mean 0.13450990617275238
0.3499908149242401 0.3499908149242401
rl training, epoch3, iter0, batch965/1133, batch loss:0.3499908149242401, Training time:10559.213227272034
batch reward last col mean 0.11544685065746307 first col mean 0.1176600232720375 all mean 0.11482381075620651
0.3108145594596863 0.3108145594596863
rl training, epoch3, iter0, batch966/1133, batch loss:0.3108145594596863, Training time:10560.976025819778
batch reward last col mean 0.09297020733356476 first col mean 0.12165781110525131 all mean 0.10128046572208405
0.3170170485973358 0.3170170485973358
rl training, epoch3, iter0, batch967/1133, batch loss:0.3170170485973358, Training time:10562.305057525635
batch reward last col mean 0.12022757530212402 first col mean 0.13723592460155487 all mean 0.12385006994009018
0.38570767641067505 0.38570767641067505
rl training, epoch3, iter0, batch968/1133, batch loss:0.38570767641067505, Training time:10563.936579942703
batch reward last col mean 0.08902712911367416 first col mean 0.130004420876503 all mean 0.10423053801059723
0.3621203601360321 0.3621203601360321
rl training, epoch3, iter0, batch969/1133, batch loss:0.3621203601360321, Training time:10565.441640138626
batch reward last col mean 0.13632579147815704 first col mean 0.13797146081924438 all mean 0.13624678552150726
0.39627546072006226 0.39627546072006226
rl training, epoch3, iter0, batch970/1133, batch loss:0.39627546072006226, Training time:10566.775257587433
batch reward last col mean 0.1413431018590927 first col mean 0.1407550573348999 all mean 0.13631649315357208
0.35648685693740845 0.35648685693740845
rl training, epoch3, iter0, batch971/1133, batch loss:0.35648685693740845, Training time:10568.62160205841
batch reward last col mean 0.12232242524623871 first col mean 0.12927624583244324 all mean 0.11916524171829224
0.33110371232032776 0.33110371232032776
rl training, epoch3, iter0, batch972/1133, batch loss:0.33110371232032776, Training time:10570.213025808334
batch reward last col mean 0.16665580868721008 first col mean 0.12470386922359467 all mean 0.15331678092479706
0.390189528465271 0.39018961787223816
rl training, epoch3, iter0, batch973/1133, batch loss:0.39018961787223816, Training time:10572.06290602684
batch reward last col mean 0.1346302181482315 first col mean 0.10620729625225067 all mean 0.13171204924583435
0.38328248262405396 0.38328248262405396
rl training, epoch3, iter0, batch974/1133, batch loss:0.38328248262405396, Training time:10573.767433643341
batch reward last col mean 0.1141168549656868 first col mean 0.108525350689888 all mean 0.11514425277709961
0.32375749945640564 0.32375749945640564
rl training, epoch3, iter0, batch975/1133, batch loss:0.32375749945640564, Training time:10575.80434846878
batch reward last col mean 0.09842851758003235 first col mean 0.12761962413787842 all mean 0.10416301339864731
0.3220446705818176 0.3220446705818176
rl training, epoch3, iter0, batch976/1133, batch loss:0.3220446705818176, Training time:10577.064285516739
batch reward last col mean 0.10715148597955704 first col mean 0.10957176238298416 all mean 0.11154793947935104
0.32900822162628174 0.32900822162628174
rl training, epoch3, iter0, batch977/1133, batch loss:0.32900822162628174, Training time:10578.419661283493
batch reward last col mean 0.09933729469776154 first col mean 0.1278916597366333 all mean 0.10264748334884644
0.28590667247772217 0.2859066426753998
rl training, epoch3, iter0, batch978/1133, batch loss:0.2859066426753998, Training time:10580.009375810623
batch reward last col mean 0.11657566577196121 first col mean 0.1205868124961853 all mean 0.12048623710870743
0.3557831645011902 0.3557831048965454
rl training, epoch3, iter0, batch979/1133, batch loss:0.3557831048965454, Training time:10581.536243200302
batch reward last col mean 0.10156605392694473 first col mean 0.1289035975933075 all mean 0.11034537851810455
0.36644989252090454 0.36644989252090454
rl training, epoch3, iter0, batch980/1133, batch loss:0.36644989252090454, Training time:10583.371767044067
batch reward last col mean 0.13815873861312866 first col mean 0.11069568991661072 all mean 0.13512437045574188
0.32425400614738464 0.32425400614738464
rl training, epoch3, iter0, batch981/1133, batch loss:0.32425400614738464, Training time:10584.977910757065
batch reward last col mean 0.08796990662813187 first col mean 0.13369220495224 all mean 0.1083134263753891
0.38675785064697266 0.3867577910423279
rl training, epoch3, iter0, batch982/1133, batch loss:0.3867577910423279, Training time:10586.443305969238
batch reward last col mean 0.10346636176109314 first col mean 0.1248178780078888 all mean 0.10537710785865784
0.34474483132362366 0.34474480152130127
rl training, epoch3, iter0, batch983/1133, batch loss:0.34474480152130127, Training time:10588.089082717896
batch reward last col mean 0.10629601776599884 first col mean 0.15078862011432648 all mean 0.11842945218086243
0.3813266456127167 0.3813266456127167
rl training, epoch3, iter0, batch984/1133, batch loss:0.3813266456127167, Training time:10589.974608659744
batch reward last col mean 0.09857805073261261 first col mean 0.13578906655311584 all mean 0.11137500405311584
0.3515944480895996 0.3515944480895996
rl training, epoch3, iter0, batch985/1133, batch loss:0.3515944480895996, Training time:10591.663532018661
batch reward last col mean 0.11847323179244995 first col mean 0.11889320611953735 all mean 0.12329123914241791
0.3215582072734833 0.3215582072734833
rl training, epoch3, iter0, batch986/1133, batch loss:0.3215582072734833, Training time:10593.12742805481
batch reward last col mean 0.1331312358379364 first col mean 0.10598671436309814 all mean 0.12766072154045105
0.3663415312767029 0.3663415312767029
rl training, epoch3, iter0, batch987/1133, batch loss:0.3663415312767029, Training time:10594.767062187195
batch reward last col mean 0.090777687728405 first col mean 0.11140399426221848 all mean 0.10154042392969131
0.3167102634906769 0.3167102634906769
rl training, epoch3, iter0, batch988/1133, batch loss:0.3167102634906769, Training time:10595.984018087387
batch reward last col mean 0.12832094728946686 first col mean 0.13998520374298096 all mean 0.13127683103084564
0.35329169034957886 0.35329169034957886
rl training, epoch3, iter0, batch989/1133, batch loss:0.35329169034957886, Training time:10597.615691900253
batch reward last col mean 0.13012290000915527 first col mean 0.11172465980052948 all mean 0.1338721066713333
0.37958115339279175 0.37958115339279175
rl training, epoch3, iter0, batch990/1133, batch loss:0.37958115339279175, Training time:10598.928674697876
batch reward last col mean 0.1321314126253128 first col mean 0.1256636530160904 all mean 0.12889140844345093
0.3571687936782837 0.3571687936782837
rl training, epoch3, iter0, batch991/1133, batch loss:0.3571687936782837, Training time:10601.197450399399
batch reward last col mean 0.09852010011672974 first col mean 0.13814768195152283 all mean 0.10933684557676315
0.32415568828582764 0.32415568828582764
rl training, epoch3, iter0, batch992/1133, batch loss:0.32415568828582764, Training time:10602.515534877777
batch reward last col mean 0.12817873060703278 first col mean 0.12844228744506836 all mean 0.12275107204914093
0.3983772099018097 0.3983772099018097
rl training, epoch3, iter0, batch993/1133, batch loss:0.3983772099018097, Training time:10604.004352807999
batch reward last col mean 0.160806804895401 first col mean 0.14176295697689056 all mean 0.14967294037342072
0.3590198755264282 0.3590198755264282
rl training, epoch3, iter0, batch994/1133, batch loss:0.3590198755264282, Training time:10605.368389368057
batch reward last col mean 0.099525585770607 first col mean 0.12420296669006348 all mean 0.10154259949922562
0.3063735067844391 0.3063735067844391
rl training, epoch3, iter0, batch995/1133, batch loss:0.3063735067844391, Training time:10607.362379789352
batch reward last col mean 0.10527544468641281 first col mean 0.1208144947886467 all mean 0.10474513471126556
0.33516979217529297 0.3351697623729706
rl training, epoch3, iter0, batch996/1133, batch loss:0.3351697623729706, Training time:10609.436104774475
batch reward last col mean 0.10493209958076477 first col mean 0.12724007666110992 all mean 0.11309592425823212
0.34999093413352966 0.34999093413352966
rl training, epoch3, iter0, batch997/1133, batch loss:0.34999093413352966, Training time:10610.840639829636
batch reward last col mean 0.07991065084934235 first col mean 0.13509653508663177 all mean 0.0896434411406517
0.30422139167785645 0.30422139167785645
rl training, epoch3, iter0, batch998/1133, batch loss:0.30422139167785645, Training time:10612.759423971176
batch reward last col mean 0.10615917295217514 first col mean 0.12782345712184906 all mean 0.10933928191661835
0.32980069518089294 0.32980069518089294
rl training, epoch3, iter0, batch999/1133, batch loss:0.32980069518089294, Training time:10614.15413069725
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5284321597741961 Time: 98.65713548660278 s
loss of true 0.23372505589438453 loss of gen 0.18131450048770298 loss of other 0.11339260426671338 first score 0.11449003219604492
batch reward last col mean 0.10892574489116669 first col mean 0.10647117346525192 all mean 0.11390537768602371
0.35884061455726624 0.35884055495262146
rl training, epoch3, iter0, batch1000/1133, batch loss:0.35884055495262146, Training time:10714.451387166977
batch reward last col mean 0.08818742632865906 first col mean 0.09676362574100494 all mean 0.09573804587125778
0.29687437415122986 0.29687437415122986
rl training, epoch3, iter0, batch1001/1133, batch loss:0.29687437415122986, Training time:10715.496802568436
batch reward last col mean 0.12422513961791992 first col mean 0.10969579219818115 all mean 0.12306548655033112
0.31999480724334717 0.31999480724334717
rl training, epoch3, iter0, batch1002/1133, batch loss:0.31999480724334717, Training time:10716.80515742302
batch reward last col mean 0.08658646047115326 first col mean 0.11500538885593414 all mean 0.09774548560380936
0.3158351182937622 0.3158351182937622
rl training, epoch3, iter0, batch1003/1133, batch loss:0.3158351182937622, Training time:10718.411960363388
batch reward last col mean 0.09407209604978561 first col mean 0.09648284316062927 all mean 0.09698566794395447
0.342113196849823 0.342113196849823
rl training, epoch3, iter0, batch1004/1133, batch loss:0.342113196849823, Training time:10719.991372823715
batch reward last col mean 0.0940203070640564 first col mean 0.11259575933218002 all mean 0.09460632503032684
0.3127647936344147 0.3127647936344147
rl training, epoch3, iter0, batch1005/1133, batch loss:0.3127647936344147, Training time:10721.716022968292
batch reward last col mean 0.09538203477859497 first col mean 0.09853295236825943 all mean 0.10151460021734238
0.3417339622974396 0.3417339622974396
rl training, epoch3, iter0, batch1006/1133, batch loss:0.3417339622974396, Training time:10723.328916549683
batch reward last col mean 0.13142596185207367 first col mean 0.10122422873973846 all mean 0.12404116243124008
0.29506736993789673 0.29506736993789673
rl training, epoch3, iter0, batch1007/1133, batch loss:0.29506736993789673, Training time:10724.686322689056
batch reward last col mean 0.08572772890329361 first col mean 0.1153344139456749 all mean 0.08718821406364441
0.27567723393440247 0.27567723393440247
rl training, epoch3, iter0, batch1008/1133, batch loss:0.27567723393440247, Training time:10726.800288677216
batch reward last col mean 0.1209656149148941 first col mean 0.11818720400333405 all mean 0.11876709759235382
0.3166152834892273 0.3166153132915497
rl training, epoch3, iter0, batch1009/1133, batch loss:0.3166153132915497, Training time:10728.491679668427
batch reward last col mean 0.12191958725452423 first col mean 0.11150336265563965 all mean 0.1162157878279686
0.3143034279346466 0.3143033981323242
rl training, epoch3, iter0, batch1010/1133, batch loss:0.3143033981323242, Training time:10729.843695878983
batch reward last col mean 0.13423548638820648 first col mean 0.10351784527301788 all mean 0.1286780685186386
0.3909596800804138 0.3909596800804138
rl training, epoch3, iter0, batch1011/1133, batch loss:0.3909596800804138, Training time:10731.044674396515
batch reward last col mean 0.11393766850233078 first col mean 0.09387283772230148 all mean 0.1084943637251854
0.3191119134426117 0.3191119134426117
rl training, epoch3, iter0, batch1012/1133, batch loss:0.3191119134426117, Training time:10732.417189359665
batch reward last col mean 0.08853016793727875 first col mean 0.10835158824920654 all mean 0.09133242070674896
0.2695874869823456 0.2695874869823456
rl training, epoch3, iter0, batch1013/1133, batch loss:0.2695874869823456, Training time:10734.228976011276
batch reward last col mean 0.13230258226394653 first col mean 0.10119115561246872 all mean 0.1256464272737503
0.3150273263454437 0.3150273263454437
rl training, epoch3, iter0, batch1014/1133, batch loss:0.3150273263454437, Training time:10735.97785115242
batch reward last col mean 0.10416299104690552 first col mean 0.10836006700992584 all mean 0.10207857191562653
0.281887412071228 0.281887412071228
rl training, epoch3, iter0, batch1015/1133, batch loss:0.281887412071228, Training time:10737.395403862
batch reward last col mean 0.0870421752333641 first col mean 0.11841151118278503 all mean 0.09395980834960938
0.2767779529094696 0.2767779529094696
rl training, epoch3, iter0, batch1016/1133, batch loss:0.2767779529094696, Training time:10738.719185590744
batch reward last col mean 0.12818953394889832 first col mean 0.11828580498695374 all mean 0.11862514913082123
0.2965013086795807 0.2965013086795807
rl training, epoch3, iter0, batch1017/1133, batch loss:0.2965013086795807, Training time:10740.360969781876
batch reward last col mean 0.0949549525976181 first col mean 0.10684918612241745 all mean 0.09346146136522293
0.3112850785255432 0.3112851083278656
rl training, epoch3, iter0, batch1018/1133, batch loss:0.3112851083278656, Training time:10741.68281507492
batch reward last col mean 0.13091333210468292 first col mean 0.11175285279750824 all mean 0.12373029440641403
0.32290777564048767 0.32290780544281006
rl training, epoch3, iter0, batch1019/1133, batch loss:0.32290780544281006, Training time:10743.201110124588
batch reward last col mean 0.13165946304798126 first col mean 0.09723614156246185 all mean 0.1175561249256134
0.33580467104911804 0.33580467104911804
rl training, epoch3, iter0, batch1020/1133, batch loss:0.33580467104911804, Training time:10744.961317539215
batch reward last col mean 0.10045953840017319 first col mean 0.09705304354429245 all mean 0.10596713423728943
0.3066856265068054 0.3066856265068054
rl training, epoch3, iter0, batch1021/1133, batch loss:0.3066856265068054, Training time:10746.239295482635
batch reward last col mean 0.07545334845781326 first col mean 0.10576781630516052 all mean 0.08587166666984558
0.3199034035205841 0.3199034035205841
rl training, epoch3, iter0, batch1022/1133, batch loss:0.3199034035205841, Training time:10748.012397527695
batch reward last col mean 0.1281309574842453 first col mean 0.10604577511548996 all mean 0.11824570596218109
0.3401019871234894 0.3401019871234894
rl training, epoch3, iter0, batch1023/1133, batch loss:0.3401019871234894, Training time:10749.457339048386
batch reward last col mean 0.1053815484046936 first col mean 0.10291771590709686 all mean 0.10682463645935059
0.2865464985370636 0.2865464985370636
rl training, epoch3, iter0, batch1024/1133, batch loss:0.2865464985370636, Training time:10750.774952888489
batch reward last col mean 0.1145000010728836 first col mean 0.11562280356884003 all mean 0.11370579153299332
0.30193477869033813 0.30193477869033813
rl training, epoch3, iter0, batch1025/1133, batch loss:0.30193477869033813, Training time:10752.469399929047
batch reward last col mean 0.1303408294916153 first col mean 0.10945999622344971 all mean 0.12524232268333435
0.318915456533432 0.3189154267311096
rl training, epoch3, iter0, batch1026/1133, batch loss:0.3189154267311096, Training time:10753.966081619263
batch reward last col mean 0.1401197910308838 first col mean 0.0983208492398262 all mean 0.13023236393928528
0.33499249815940857 0.33499255776405334
rl training, epoch3, iter0, batch1027/1133, batch loss:0.33499255776405334, Training time:10755.307887792587
batch reward last col mean 0.10382143408060074 first col mean 0.09524406492710114 all mean 0.10264981538057327
0.2993288040161133 0.2993288040161133
rl training, epoch3, iter0, batch1028/1133, batch loss:0.2993288040161133, Training time:10757.000384569168
batch reward last col mean 0.10982996225357056 first col mean 0.1089557334780693 all mean 0.11323165148496628
0.3260534703731537 0.3260534703731537
rl training, epoch3, iter0, batch1029/1133, batch loss:0.3260534703731537, Training time:10758.872864961624
batch reward last col mean 0.10254596918821335 first col mean 0.13070674240589142 all mean 0.11064984649419785
0.3230535387992859 0.3230535387992859
rl training, epoch3, iter0, batch1030/1133, batch loss:0.3230535387992859, Training time:10760.352412939072
batch reward last col mean 0.08945824205875397 first col mean 0.10179395973682404 all mean 0.1012217178940773
0.3034072518348694 0.3034072518348694
rl training, epoch3, iter0, batch1031/1133, batch loss:0.3034072518348694, Training time:10761.777356863022
batch reward last col mean 0.1138855591416359 first col mean 0.10936197638511658 all mean 0.11293003708124161
0.3664509057998657 0.3664509057998657
rl training, epoch3, iter0, batch1032/1133, batch loss:0.3664509057998657, Training time:10763.124832391739
batch reward last col mean 0.09706126153469086 first col mean 0.12528720498085022 all mean 0.10347378998994827
0.3097520172595978 0.3097520172595978
rl training, epoch3, iter0, batch1033/1133, batch loss:0.3097520172595978, Training time:10764.819332361221
batch reward last col mean 0.07731249183416367 first col mean 0.09884573519229889 all mean 0.08980703353881836
0.29605937004089355 0.29605937004089355
rl training, epoch3, iter0, batch1034/1133, batch loss:0.29605937004089355, Training time:10766.515419960022
batch reward last col mean 0.07902931421995163 first col mean 0.1004730612039566 all mean 0.0863918736577034
0.2718172073364258 0.2718171775341034
rl training, epoch3, iter0, batch1035/1133, batch loss:0.2718171775341034, Training time:10768.081286430359
batch reward last col mean 0.1288570761680603 first col mean 0.11790493130683899 all mean 0.12233492732048035
0.33727699518203735 0.33727699518203735
rl training, epoch3, iter0, batch1036/1133, batch loss:0.33727699518203735, Training time:10769.575107574463
batch reward last col mean 0.10186454653739929 first col mean 0.11387209594249725 all mean 0.11091293394565582
0.3566133975982666 0.3566133975982666
rl training, epoch3, iter0, batch1037/1133, batch loss:0.3566133975982666, Training time:10770.984548807144
batch reward last col mean 0.10567295551300049 first col mean 0.11663581430912018 all mean 0.10858749598264694
0.3328228294849396 0.3328228294849396
rl training, epoch3, iter0, batch1038/1133, batch loss:0.3328228294849396, Training time:10772.203286647797
batch reward last col mean 0.07533498108386993 first col mean 0.10209564864635468 all mean 0.08382376283407211
0.3059132397174835 0.3059132397174835
rl training, epoch3, iter0, batch1039/1133, batch loss:0.3059132397174835, Training time:10774.096199989319
batch reward last col mean 0.11431530117988586 first col mean 0.09889258444309235 all mean 0.11979445815086365
0.3248954713344574 0.3248954713344574
rl training, epoch3, iter0, batch1040/1133, batch loss:0.3248954713344574, Training time:10775.948571681976
batch reward last col mean 0.13194771111011505 first col mean 0.10323837399482727 all mean 0.12215431034564972
0.30425357818603516 0.30425357818603516
rl training, epoch3, iter0, batch1041/1133, batch loss:0.30425357818603516, Training time:10777.552834272385
batch reward last col mean 0.08817020803689957 first col mean 0.10386928915977478 all mean 0.09265893697738647
0.31088393926620483 0.31088393926620483
rl training, epoch3, iter0, batch1042/1133, batch loss:0.31088393926620483, Training time:10778.937901258469
batch reward last col mean 0.0838937908411026 first col mean 0.11746631562709808 all mean 0.09268399327993393
0.2929374575614929 0.2929374575614929
rl training, epoch3, iter0, batch1043/1133, batch loss:0.2929374575614929, Training time:10780.118333816528
batch reward last col mean 0.1095612496137619 first col mean 0.12466105073690414 all mean 0.1080537661910057
0.3090442717075348 0.3090443015098572
rl training, epoch3, iter0, batch1044/1133, batch loss:0.3090443015098572, Training time:10781.498594760895
batch reward last col mean 0.08239690214395523 first col mean 0.10387204587459564 all mean 0.09420516341924667
0.2773197591304779 0.2773197591304779
rl training, epoch3, iter0, batch1045/1133, batch loss:0.2773197591304779, Training time:10782.877623558044
batch reward last col mean 0.08530455082654953 first col mean 0.13026723265647888 all mean 0.08973002433776855
0.2736878991127014 0.2736878991127014
rl training, epoch3, iter0, batch1046/1133, batch loss:0.2736878991127014, Training time:10784.07730102539
batch reward last col mean 0.11631473898887634 first col mean 0.11465026438236237 all mean 0.11670233309268951
0.3159621059894562 0.3159620761871338
rl training, epoch3, iter0, batch1047/1133, batch loss:0.3159620761871338, Training time:10785.880215168
batch reward last col mean 0.09568465501070023 first col mean 0.1120707243680954 all mean 0.09935404360294342
0.2873629331588745 0.2873629033565521
rl training, epoch3, iter0, batch1048/1133, batch loss:0.2873629033565521, Training time:10787.28059387207
batch reward last col mean 0.09000572562217712 first col mean 0.11034578084945679 all mean 0.09733591973781586
0.30660536885261536 0.30660536885261536
rl training, epoch3, iter0, batch1049/1133, batch loss:0.30660536885261536, Training time:10788.818913459778
batch reward last col mean 0.08358578383922577 first col mean 0.1153726726770401 all mean 0.0966988354921341
0.3139917254447937 0.3139916956424713
rl training, epoch3, iter0, batch1050/1133, batch loss:0.3139916956424713, Training time:10790.404774904251
batch reward last col mean 0.07582415640354156 first col mean 0.11574141681194305 all mean 0.08818821609020233
0.30735957622528076 0.30735957622528076
rl training, epoch3, iter0, batch1051/1133, batch loss:0.30735957622528076, Training time:10791.777271986008
batch reward last col mean 0.13066470623016357 first col mean 0.13515979051589966 all mean 0.1309737265110016
0.37591418623924255 0.37591418623924255
rl training, epoch3, iter0, batch1052/1133, batch loss:0.37591418623924255, Training time:10793.143881559372
batch reward last col mean 0.07618483155965805 first col mean 0.10786493867635727 all mean 0.08879076689481735
0.2929445505142212 0.2929445505142212
rl training, epoch3, iter0, batch1053/1133, batch loss:0.2929445505142212, Training time:10794.630070209503
batch reward last col mean 0.11094934493303299 first col mean 0.11946969479322433 all mean 0.10580764710903168
0.32169848680496216 0.32169848680496216
rl training, epoch3, iter0, batch1054/1133, batch loss:0.32169848680496216, Training time:10796.008446216583
batch reward last col mean 0.0938909724354744 first col mean 0.10306579619646072 all mean 0.0970597118139267
0.2849593162536621 0.2849593162536621
rl training, epoch3, iter0, batch1055/1133, batch loss:0.2849593162536621, Training time:10797.449625730515
batch reward last col mean 0.10483556985855103 first col mean 0.13060550391674042 all mean 0.11338594555854797
0.3040972948074341 0.3040972948074341
rl training, epoch3, iter0, batch1056/1133, batch loss:0.3040972948074341, Training time:10798.815594434738
batch reward last col mean 0.1126258447766304 first col mean 0.11778689920902252 all mean 0.11547490954399109
0.3015229105949402 0.3015229105949402
rl training, epoch3, iter0, batch1057/1133, batch loss:0.3015229105949402, Training time:10800.07251405716
batch reward last col mean 0.1119585856795311 first col mean 0.10826966166496277 all mean 0.11188729852437973
0.3106807470321655 0.31068071722984314
rl training, epoch3, iter0, batch1058/1133, batch loss:0.31068071722984314, Training time:10801.808705091476
batch reward last col mean 0.11537768691778183 first col mean 0.10109134018421173 all mean 0.11152840405702591
0.33837997913360596 0.33837997913360596
rl training, epoch3, iter0, batch1059/1133, batch loss:0.33837997913360596, Training time:10803.401678323746
batch reward last col mean 0.09957011789083481 first col mean 0.10400145500898361 all mean 0.10475289821624756
0.29001033306121826 0.29001033306121826
rl training, epoch3, iter0, batch1060/1133, batch loss:0.29001033306121826, Training time:10805.547544240952
batch reward last col mean 0.12765337526798248 first col mean 0.11661922931671143 all mean 0.1276072859764099
0.33465754985809326 0.33465754985809326
rl training, epoch3, iter0, batch1061/1133, batch loss:0.33465754985809326, Training time:10807.45999121666
batch reward last col mean 0.10520583391189575 first col mean 0.11803717166185379 all mean 0.1176069900393486
0.33759623765945435 0.33759623765945435
rl training, epoch3, iter0, batch1062/1133, batch loss:0.33759623765945435, Training time:10808.988276958466
batch reward last col mean 0.09977491945028305 first col mean 0.11425592005252838 all mean 0.10120202600955963
0.255960077047348 0.255960077047348
rl training, epoch3, iter0, batch1063/1133, batch loss:0.255960077047348, Training time:10810.399916887283
batch reward last col mean 0.09536781907081604 first col mean 0.10541930794715881 all mean 0.10249513387680054
0.2736501395702362 0.2736501395702362
rl training, epoch3, iter0, batch1064/1133, batch loss:0.2736501395702362, Training time:10812.23798751831
batch reward last col mean 0.0864190012216568 first col mean 0.1323397159576416 all mean 0.0937691181898117
0.33020099997520447 0.33020099997520447
rl training, epoch3, iter0, batch1065/1133, batch loss:0.33020099997520447, Training time:10814.09110212326
batch reward last col mean 0.11465142667293549 first col mean 0.12091797590255737 all mean 0.11243675649166107
0.3206857144832611 0.3206857144832611
rl training, epoch3, iter0, batch1066/1133, batch loss:0.3206857144832611, Training time:10816.288983345032
batch reward last col mean 0.08972285687923431 first col mean 0.11673598736524582 all mean 0.09993712604045868
0.30438750982284546 0.30438748002052307
rl training, epoch3, iter0, batch1067/1133, batch loss:0.30438748002052307, Training time:10818.170957565308
batch reward last col mean 0.14229074120521545 first col mean 0.11162850260734558 all mean 0.1385924071073532
0.35542887449264526 0.35542887449264526
rl training, epoch3, iter0, batch1068/1133, batch loss:0.35542887449264526, Training time:10820.111579418182
batch reward last col mean 0.1362554132938385 first col mean 0.13980771601200104 all mean 0.13559511303901672
0.367276668548584 0.367276668548584
rl training, epoch3, iter0, batch1069/1133, batch loss:0.367276668548584, Training time:10822.13773727417
batch reward last col mean 0.11432206630706787 first col mean 0.11955799907445908 all mean 0.11444883793592453
0.27954617142677307 0.27954617142677307
rl training, epoch3, iter0, batch1070/1133, batch loss:0.27954617142677307, Training time:10823.891401290894
batch reward last col mean 0.10391728579998016 first col mean 0.13142381608486176 all mean 0.11058107763528824
0.29919013381004333 0.29919013381004333
rl training, epoch3, iter0, batch1071/1133, batch loss:0.29919013381004333, Training time:10825.799241542816
batch reward last col mean 0.16553926467895508 first col mean 0.1273581087589264 all mean 0.15108060836791992
0.3626563549041748 0.3626563251018524
rl training, epoch3, iter0, batch1072/1133, batch loss:0.3626563251018524, Training time:10827.597924232483
batch reward last col mean 0.1288634091615677 first col mean 0.12989084422588348 all mean 0.12708976864814758
0.32405298948287964 0.32405298948287964
rl training, epoch3, iter0, batch1073/1133, batch loss:0.32405298948287964, Training time:10829.314555168152
batch reward last col mean 0.14901402592658997 first col mean 0.13558423519134521 all mean 0.1414063572883606
0.35455191135406494 0.35455191135406494
rl training, epoch3, iter0, batch1074/1133, batch loss:0.35455191135406494, Training time:10830.91609621048
batch reward last col mean 0.1330241858959198 first col mean 0.1260182112455368 all mean 0.12714476883411407
0.35419762134552 0.35419759154319763
rl training, epoch3, iter0, batch1075/1133, batch loss:0.35419759154319763, Training time:10832.505980491638
batch reward last col mean 0.10384102165699005 first col mean 0.13351942598819733 all mean 0.10629229992628098
0.3469046354293823 0.3469046354293823
rl training, epoch3, iter0, batch1076/1133, batch loss:0.3469046354293823, Training time:10834.303748130798
batch reward last col mean 0.13795119524002075 first col mean 0.11665024608373642 all mean 0.13428843021392822
0.3051953613758087 0.3051953911781311
rl training, epoch3, iter0, batch1077/1133, batch loss:0.3051953911781311, Training time:10836.123111963272
batch reward last col mean 0.12030564248561859 first col mean 0.13124361634254456 all mean 0.11816242337226868
0.33956822752952576 0.33956822752952576
rl training, epoch3, iter0, batch1078/1133, batch loss:0.33956822752952576, Training time:10837.989457130432
batch reward last col mean 0.1374625265598297 first col mean 0.11930908262729645 all mean 0.12980429828166962
0.3338926136493683 0.3338926136493683
rl training, epoch3, iter0, batch1079/1133, batch loss:0.3338926136493683, Training time:10840.5589158535
batch reward last col mean 0.1284700185060501 first col mean 0.12089909613132477 all mean 0.12389173358678818
0.3467172384262085 0.3467172384262085
rl training, epoch3, iter0, batch1080/1133, batch loss:0.3467172384262085, Training time:10842.236100196838
batch reward last col mean 0.10645595192909241 first col mean 0.1155446395277977 all mean 0.11173219978809357
0.31865954399108887 0.31865960359573364
rl training, epoch3, iter0, batch1081/1133, batch loss:0.31865960359573364, Training time:10844.279874324799
batch reward last col mean 0.12500505149364471 first col mean 0.12759774923324585 all mean 0.12662623822689056
0.3427836298942566 0.3427836298942566
rl training, epoch3, iter0, batch1082/1133, batch loss:0.3427836298942566, Training time:10845.990888357162
batch reward last col mean 0.1275126338005066 first col mean 0.11463901400566101 all mean 0.1261230856180191
0.33840593695640564 0.33840590715408325
rl training, epoch3, iter0, batch1083/1133, batch loss:0.33840590715408325, Training time:10847.690931081772
batch reward last col mean 0.12375897914171219 first col mean 0.12518177926540375 all mean 0.1214049682021141
0.32485121488571167 0.3248511850833893
rl training, epoch3, iter0, batch1084/1133, batch loss:0.3248511850833893, Training time:10849.357154369354
batch reward last col mean 0.10050007700920105 first col mean 0.10522614419460297 all mean 0.10680600255727768
0.33300700783729553 0.33300697803497314
rl training, epoch3, iter0, batch1085/1133, batch loss:0.33300697803497314, Training time:10851.480865716934
batch reward last col mean 0.10703568905591965 first col mean 0.11988779902458191 all mean 0.1038706824183464
0.2540944218635559 0.2540944218635559
rl training, epoch3, iter0, batch1086/1133, batch loss:0.2540944218635559, Training time:10853.622745037079
batch reward last col mean 0.1094910129904747 first col mean 0.14365415275096893 all mean 0.11394248157739639
0.2825855016708374 0.2825855016708374
rl training, epoch3, iter0, batch1087/1133, batch loss:0.2825855016708374, Training time:10855.876827716827
batch reward last col mean 0.08095358312129974 first col mean 0.12706585228443146 all mean 0.09172336012125015
0.26704028248786926 0.26704028248786926
rl training, epoch3, iter0, batch1088/1133, batch loss:0.26704028248786926, Training time:10857.61507344246
batch reward last col mean 0.11744728684425354 first col mean 0.1277342587709427 all mean 0.11713781952857971
0.2845052480697632 0.2845052182674408
rl training, epoch3, iter0, batch1089/1133, batch loss:0.2845052182674408, Training time:10859.527922868729
batch reward last col mean 0.10230240970849991 first col mean 0.1344621628522873 all mean 0.11229219287633896
0.3422137200832367 0.3422137200832367
rl training, epoch3, iter0, batch1090/1133, batch loss:0.3422137200832367, Training time:10861.024084329605
batch reward last col mean 0.10479103028774261 first col mean 0.11498765647411346 all mean 0.1147046759724617
0.3210386633872986 0.3210386633872986
rl training, epoch3, iter0, batch1091/1133, batch loss:0.3210386633872986, Training time:10862.503601789474
batch reward last col mean 0.12273065745830536 first col mean 0.11825402826070786 all mean 0.12599517405033112
0.3320518732070923 0.3320518732070923
rl training, epoch3, iter0, batch1092/1133, batch loss:0.3320518732070923, Training time:10864.012599468231
batch reward last col mean 0.12876543402671814 first col mean 0.14233343303203583 all mean 0.1273612529039383
0.3541761040687561 0.3541761040687561
rl training, epoch3, iter0, batch1093/1133, batch loss:0.3541761040687561, Training time:10866.00473022461
batch reward last col mean 0.13247522711753845 first col mean 0.11984672397375107 all mean 0.13373401761054993
0.3810303509235382 0.3810303509235382
rl training, epoch3, iter0, batch1094/1133, batch loss:0.3810303509235382, Training time:10867.668765306473
batch reward last col mean 0.10653036087751389 first col mean 0.12862545251846313 all mean 0.10764169692993164
0.3149624466896057 0.3149624466896057
rl training, epoch3, iter0, batch1095/1133, batch loss:0.3149624466896057, Training time:10869.426871299744
batch reward last col mean 0.1286843866109848 first col mean 0.13552045822143555 all mean 0.12755213677883148
0.33468618988990784 0.33468618988990784
rl training, epoch3, iter0, batch1096/1133, batch loss:0.33468618988990784, Training time:10871.10823726654
batch reward last col mean 0.12506312131881714 first col mean 0.13473893702030182 all mean 0.12728816270828247
0.3223157525062561 0.3223157525062561
rl training, epoch3, iter0, batch1097/1133, batch loss:0.3223157525062561, Training time:10872.990395784378
batch reward last col mean 0.11153585463762283 first col mean 0.12382370233535767 all mean 0.12041868269443512
0.3005860447883606 0.3005860447883606
rl training, epoch3, iter0, batch1098/1133, batch loss:0.3005860447883606, Training time:10874.900578737259
batch reward last col mean 0.12430937588214874 first col mean 0.1367020606994629 all mean 0.1274842619895935
0.3335646390914917 0.3335646390914917
rl training, epoch3, iter0, batch1099/1133, batch loss:0.3335646390914917, Training time:10876.968147277832
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5252393571444559 Time: 104.11405873298645 s
loss of true 0.23242774712939443 loss of gen 0.18131345562432996 loss of other 0.11149815424277208 first score 0.1443595290184021
batch reward last col mean 0.09574148058891296 first col mean 0.09882739931344986 all mean 0.10107841342687607
0.291568785905838 0.2915688157081604
rl training, epoch3, iter0, batch1100/1133, batch loss:0.2915688157081604, Training time:10982.869767189026
batch reward last col mean 0.091072678565979 first col mean 0.10970533639192581 all mean 0.09750230610370636
0.24857617914676666 0.24857617914676666
rl training, epoch3, iter0, batch1101/1133, batch loss:0.24857617914676666, Training time:10984.552396059036
batch reward last col mean 0.07587084174156189 first col mean 0.10095500946044922 all mean 0.08773011714220047
0.2592584788799286 0.259258508682251
rl training, epoch3, iter0, batch1102/1133, batch loss:0.259258508682251, Training time:10986.167326927185
batch reward last col mean 0.11159496009349823 first col mean 0.10127782076597214 all mean 0.11343478411436081
0.3326874077320099 0.3326874077320099
rl training, epoch3, iter0, batch1103/1133, batch loss:0.3326874077320099, Training time:10988.319289445877
batch reward last col mean 0.06863754987716675 first col mean 0.10912370681762695 all mean 0.08037001639604568
0.3286152184009552 0.3286152184009552
rl training, epoch3, iter0, batch1104/1133, batch loss:0.3286152184009552, Training time:10990.37124824524
batch reward last col mean 0.07660040259361267 first col mean 0.09717772901058197 all mean 0.08476047962903976
0.24768629670143127 0.24768629670143127
rl training, epoch3, iter0, batch1105/1133, batch loss:0.24768629670143127, Training time:10992.50480890274
batch reward last col mean 0.11795922368764877 first col mean 0.11293623596429825 all mean 0.11469760537147522
0.2571868598461151 0.2571868598461151
rl training, epoch3, iter0, batch1106/1133, batch loss:0.2571868598461151, Training time:10994.245279550552
batch reward last col mean 0.09074410796165466 first col mean 0.1278323531150818 all mean 0.09819864481687546
0.270435094833374 0.270435094833374
rl training, epoch3, iter0, batch1107/1133, batch loss:0.270435094833374, Training time:10996.082471370697
batch reward last col mean 0.10383188724517822 first col mean 0.114188551902771 all mean 0.09872950613498688
0.29757529497146606 0.29757529497146606
rl training, epoch3, iter0, batch1108/1133, batch loss:0.29757529497146606, Training time:10997.832135677338
batch reward last col mean 0.11780841648578644 first col mean 0.09684829413890839 all mean 0.11511252075433731
0.2905207574367523 0.2905207574367523
rl training, epoch3, iter0, batch1109/1133, batch loss:0.2905207574367523, Training time:11000.379472732544
batch reward last col mean 0.11610507220029831 first col mean 0.09707038849592209 all mean 0.11695674806833267
0.2914445698261261 0.2914445698261261
rl training, epoch3, iter0, batch1110/1133, batch loss:0.2914445698261261, Training time:11002.545535326004
batch reward last col mean 0.0841817557811737 first col mean 0.08386335521936417 all mean 0.08649105578660965
0.23421387374401093 0.23421387374401093
rl training, epoch3, iter0, batch1111/1133, batch loss:0.23421387374401093, Training time:11004.552915334702
batch reward last col mean 0.0851932018995285 first col mean 0.09934283792972565 all mean 0.09021227806806564
0.2386384904384613 0.2386384755373001
rl training, epoch3, iter0, batch1112/1133, batch loss:0.2386384755373001, Training time:11006.483407735825
batch reward last col mean 0.12704938650131226 first col mean 0.08893214166164398 all mean 0.12495791167020798
0.31525084376335144 0.31525084376335144
rl training, epoch3, iter0, batch1113/1133, batch loss:0.31525084376335144, Training time:11009.345602035522
batch reward last col mean 0.10569153726100922 first col mean 0.09526784718036652 all mean 0.10284052044153214
0.26798513531684875 0.26798513531684875
rl training, epoch3, iter0, batch1114/1133, batch loss:0.26798513531684875, Training time:11012.045672655106
batch reward last col mean 0.10597724467515945 first col mean 0.09531933069229126 all mean 0.10785488784313202
0.2724461257457733 0.2724460959434509
rl training, epoch3, iter0, batch1115/1133, batch loss:0.2724460959434509, Training time:11014.168803930283
batch reward last col mean 0.0797952264547348 first col mean 0.09224899858236313 all mean 0.08735976368188858
0.25724127888679504 0.25724127888679504
rl training, epoch3, iter0, batch1116/1133, batch loss:0.25724127888679504, Training time:11016.050800323486
batch reward last col mean 0.1036791279911995 first col mean 0.12074354290962219 all mean 0.10473363846540451
0.2737811803817749 0.2737811803817749
rl training, epoch3, iter0, batch1117/1133, batch loss:0.2737811803817749, Training time:11018.521721363068
batch reward last col mean 0.11326023191213608 first col mean 0.09426853060722351 all mean 0.11184348165988922
0.28266292810440063 0.28266292810440063
rl training, epoch3, iter0, batch1118/1133, batch loss:0.28266292810440063, Training time:11020.216916322708
batch reward last col mean 0.09674602001905441 first col mean 0.11080625653266907 all mean 0.10351857542991638
0.2977927029132843 0.2977927029132843
rl training, epoch3, iter0, batch1119/1133, batch loss:0.2977927029132843, Training time:11021.799680709839
batch reward last col mean 0.12604478001594543 first col mean 0.11241479218006134 all mean 0.11768369376659393
0.28301358222961426 0.28301355242729187
rl training, epoch3, iter0, batch1120/1133, batch loss:0.28301355242729187, Training time:11023.464812994003
batch reward last col mean 0.11079146713018417 first col mean 0.12411992996931076 all mean 0.11356845498085022
0.28338178992271423 0.28338178992271423
rl training, epoch3, iter0, batch1121/1133, batch loss:0.28338178992271423, Training time:11025.105857133865
batch reward last col mean 0.11992622166872025 first col mean 0.11138623207807541 all mean 0.11852874606847763
0.3066166341304779 0.3066166341304779
rl training, epoch3, iter0, batch1122/1133, batch loss:0.3066166341304779, Training time:11027.97122168541
batch reward last col mean 0.08139234036207199 first col mean 0.11322525143623352 all mean 0.09396123141050339
0.2517034709453583 0.2517034709453583
rl training, epoch3, iter0, batch1123/1133, batch loss:0.2517034709453583, Training time:11029.641942501068
batch reward last col mean 0.08232622593641281 first col mean 0.10588047653436661 all mean 0.0894036665558815
0.2806994616985321 0.2806994616985321
rl training, epoch3, iter0, batch1124/1133, batch loss:0.2806994616985321, Training time:11031.301712036133
batch reward last col mean 0.13696640729904175 first col mean 0.11865273863077164 all mean 0.13343016803264618
0.32771557569503784 0.32771557569503784
rl training, epoch3, iter0, batch1125/1133, batch loss:0.32771557569503784, Training time:11033.328551769257
batch reward last col mean 0.09164168685674667 first col mean 0.10980094969272614 all mean 0.09671307355165482
0.26454153656959534 0.26454153656959534
rl training, epoch3, iter0, batch1126/1133, batch loss:0.26454153656959534, Training time:11034.867684602737
batch reward last col mean 0.15814730525016785 first col mean 0.11385717242956161 all mean 0.1426999866962433
0.3183240294456482 0.3183240294456482
rl training, epoch3, iter0, batch1127/1133, batch loss:0.3183240294456482, Training time:11036.540315151215
batch reward last col mean 0.08864828199148178 first col mean 0.11290790140628815 all mean 0.10000710934400558
0.2994811236858368 0.2994811236858368
rl training, epoch3, iter0, batch1128/1133, batch loss:0.2994811236858368, Training time:11038.23956155777
batch reward last col mean 0.11004358530044556 first col mean 0.10781461000442505 all mean 0.10829105228185654
0.29496240615844727 0.29496240615844727
rl training, epoch3, iter0, batch1129/1133, batch loss:0.29496240615844727, Training time:11040.114629983902
batch reward last col mean 0.11412068456411362 first col mean 0.12025021016597748 all mean 0.11520516872406006
0.3101511299610138 0.3101511299610138
rl training, epoch3, iter0, batch1130/1133, batch loss:0.3101511299610138, Training time:11042.061715841293
batch reward last col mean 0.13454902172088623 first col mean 0.11775831878185272 all mean 0.12908540666103363
0.3274986445903778 0.3274986445903778
rl training, epoch3, iter0, batch1131/1133, batch loss:0.3274986445903778, Training time:11043.894624233246
batch reward last col mean 0.1209743469953537 first col mean 0.11613810807466507 all mean 0.11517246812582016
0.331360399723053 0.331360399723053
rl training, epoch3, iter0, batch1132/1133, batch loss:0.331360399723053, Training time:11045.43189239502
rl training, epoch 3, iter 0, loss:0.33466329209223744, Training time:11045.43201804161 
rl epoch 3, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.0916955841397775 Time: 124.9375491142273 s
rl epoch 3, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5208796350596125 Time: 103.18164658546448 s
loss of true 0.2275479547712304 loss of gen 0.18576997611918286 loss of other 0.10756170363325727 first score 0.14524731040000916
rl epoch 4, begin RL for generator...
batch reward last col mean 0.13423867523670197 first col mean 0.11445904523134232 all mean 0.12525182962417603
0.2965679466724396 0.2965679466724396
rl training, epoch4, iter0, batch0/1133, batch loss:0.2965679466724396, Training time:11276.01831817627
batch reward last col mean 0.08915349841117859 first col mean 0.12381600588560104 all mean 0.09499288350343704
0.3235219419002533 0.3235219419002533
rl training, epoch4, iter0, batch1/1133, batch loss:0.3235219419002533, Training time:11278.212460517883
batch reward last col mean 0.10893140733242035 first col mean 0.09431549906730652 all mean 0.10752268135547638
0.3068517744541168 0.3068517744541168
rl training, epoch4, iter0, batch2/1133, batch loss:0.3068517744541168, Training time:11280.433130979538
batch reward last col mean 0.11755925416946411 first col mean 0.11519604176282883 all mean 0.1130700558423996
0.3108983635902405 0.31089839339256287
rl training, epoch4, iter0, batch3/1133, batch loss:0.31089839339256287, Training time:11283.468435764313
batch reward last col mean 0.14765813946723938 first col mean 0.12023532390594482 all mean 0.14082644879817963
0.37833884358406067 0.37833884358406067
rl training, epoch4, iter0, batch4/1133, batch loss:0.37833884358406067, Training time:11286.055205583572
batch reward last col mean 0.1148504689335823 first col mean 0.13342991471290588 all mean 0.1124478131532669
0.3977217376232147 0.3977217376232147
rl training, epoch4, iter0, batch5/1133, batch loss:0.3977217376232147, Training time:11289.368840932846
batch reward last col mean 0.0996803268790245 first col mean 0.10889539122581482 all mean 0.10434579104185104
0.29438990354537964 0.29438990354537964
rl training, epoch4, iter0, batch6/1133, batch loss:0.29438990354537964, Training time:11292.226506710052
batch reward last col mean 0.11005652695894241 first col mean 0.12069562822580338 all mean 0.1118609830737114
0.3183180093765259 0.3183180093765259
rl training, epoch4, iter0, batch7/1133, batch loss:0.3183180093765259, Training time:11294.838096618652
batch reward last col mean 0.10748342424631119 first col mean 0.10924391448497772 all mean 0.10781548917293549
0.3105996549129486 0.3105996549129486
rl training, epoch4, iter0, batch8/1133, batch loss:0.3105996549129486, Training time:11297.456715583801
batch reward last col mean 0.10705578327178955 first col mean 0.0982106551527977 all mean 0.11049944162368774
0.2987639605998993 0.2987639605998993
rl training, epoch4, iter0, batch9/1133, batch loss:0.2987639605998993, Training time:11299.519923448563
batch reward last col mean 0.10145291686058044 first col mean 0.12241104245185852 all mean 0.10192737728357315
0.31473374366760254 0.31473374366760254
rl training, epoch4, iter0, batch10/1133, batch loss:0.31473374366760254, Training time:11302.068357229233
batch reward last col mean 0.09895318001508713 first col mean 0.11137424409389496 all mean 0.10447706282138824
0.30443665385246277 0.30443665385246277
rl training, epoch4, iter0, batch11/1133, batch loss:0.30443665385246277, Training time:11304.171322107315
batch reward last col mean 0.11398395150899887 first col mean 0.12154719233512878 all mean 0.10947360098361969
0.3102477192878723 0.3102477192878723
rl training, epoch4, iter0, batch12/1133, batch loss:0.3102477192878723, Training time:11306.018169164658
batch reward last col mean 0.12041600048542023 first col mean 0.12250189483165741 all mean 0.11130372434854507
0.327604204416275 0.327604204416275
rl training, epoch4, iter0, batch13/1133, batch loss:0.327604204416275, Training time:11308.286111593246
batch reward last col mean 0.12274166941642761 first col mean 0.1385727822780609 all mean 0.11691996455192566
0.34413209557533264 0.34413209557533264
rl training, epoch4, iter0, batch14/1133, batch loss:0.34413209557533264, Training time:11310.651321649551
batch reward last col mean 0.09021927416324615 first col mean 0.10758763551712036 all mean 0.09995962679386139
0.32693180441856384 0.32693180441856384
rl training, epoch4, iter0, batch15/1133, batch loss:0.32693180441856384, Training time:11312.19533443451
batch reward last col mean 0.13424822688102722 first col mean 0.10722394287586212 all mean 0.1223137155175209
0.3452014625072479 0.3452014625072479
rl training, epoch4, iter0, batch16/1133, batch loss:0.3452014625072479, Training time:11314.229650974274
batch reward last col mean 0.0948595404624939 first col mean 0.11900656670331955 all mean 0.09976767748594284
0.3753838539123535 0.3753838539123535
rl training, epoch4, iter0, batch17/1133, batch loss:0.3753838539123535, Training time:11316.31658744812
batch reward last col mean 0.07824335992336273 first col mean 0.10291188210248947 all mean 0.08647470921278
0.29641053080558777 0.29641053080558777
rl training, epoch4, iter0, batch18/1133, batch loss:0.29641053080558777, Training time:11318.29236125946
batch reward last col mean 0.11433658003807068 first col mean 0.09263332188129425 all mean 0.11442232131958008
0.2988169491291046 0.2988169491291046
rl training, epoch4, iter0, batch19/1133, batch loss:0.2988169491291046, Training time:11320.997746229172
batch reward last col mean 0.09768880158662796 first col mean 0.11746348440647125 all mean 0.09753332287073135
0.309876412153244 0.309876412153244
rl training, epoch4, iter0, batch20/1133, batch loss:0.309876412153244, Training time:11323.680792808533
batch reward last col mean 0.11362820863723755 first col mean 0.08705832064151764 all mean 0.11147657781839371
0.33843833208084106 0.33843833208084106
rl training, epoch4, iter0, batch21/1133, batch loss:0.33843833208084106, Training time:11326.276308298111
batch reward last col mean 0.11810731887817383 first col mean 0.1407417207956314 all mean 0.11951547861099243
0.3553657829761505 0.3553657829761505
rl training, epoch4, iter0, batch22/1133, batch loss:0.3553657829761505, Training time:11330.26764702797
batch reward last col mean 0.08940983563661575 first col mean 0.10791848599910736 all mean 0.09646663069725037
0.2977713346481323 0.2977713346481323
rl training, epoch4, iter0, batch23/1133, batch loss:0.2977713346481323, Training time:11332.241167068481
batch reward last col mean 0.09920335561037064 first col mean 0.1266896277666092 all mean 0.10548673570156097
0.3397735357284546 0.3397735357284546
rl training, epoch4, iter0, batch24/1133, batch loss:0.3397735357284546, Training time:11334.660189628601
batch reward last col mean 0.10986336320638657 first col mean 0.13663332164287567 all mean 0.10882129520177841
0.3733738958835602 0.3733738958835602
rl training, epoch4, iter0, batch25/1133, batch loss:0.3733738958835602, Training time:11336.671860218048
batch reward last col mean 0.08571477234363556 first col mean 0.1153993010520935 all mean 0.0961172804236412
0.33152902126312256 0.33152899146080017
rl training, epoch4, iter0, batch26/1133, batch loss:0.33152899146080017, Training time:11338.655411481857
batch reward last col mean 0.11836229264736176 first col mean 0.11848535388708115 all mean 0.11659648269414902
0.3121163249015808 0.3121162950992584
rl training, epoch4, iter0, batch27/1133, batch loss:0.3121162950992584, Training time:11340.829729318619
batch reward last col mean 0.1184033453464508 first col mean 0.11671273410320282 all mean 0.11719435453414917
0.3417234718799591 0.3417234718799591
rl training, epoch4, iter0, batch28/1133, batch loss:0.3417234718799591, Training time:11343.76227903366
batch reward last col mean 0.10622836649417877 first col mean 0.09752140939235687 all mean 0.10626848042011261
0.2827903628349304 0.2827903628349304
rl training, epoch4, iter0, batch29/1133, batch loss:0.2827903628349304, Training time:11347.192286491394
batch reward last col mean 0.13348284363746643 first col mean 0.12386657297611237 all mean 0.13082191348075867
0.3897993564605713 0.3897993564605713
rl training, epoch4, iter0, batch30/1133, batch loss:0.3897993564605713, Training time:11349.643171548843
batch reward last col mean 0.13616035878658295 first col mean 0.10484384745359421 all mean 0.12546461820602417
0.3675408959388733 0.3675408959388733
rl training, epoch4, iter0, batch31/1133, batch loss:0.3675408959388733, Training time:11351.616961717606
batch reward last col mean 0.10673242807388306 first col mean 0.12018179893493652 all mean 0.11182218044996262
0.3354700803756714 0.3354700803756714
rl training, epoch4, iter0, batch32/1133, batch loss:0.3354700803756714, Training time:11354.235157728195
batch reward last col mean 0.07495245337486267 first col mean 0.11529192328453064 all mean 0.08577612787485123
0.3053651452064514 0.3053651452064514
rl training, epoch4, iter0, batch33/1133, batch loss:0.3053651452064514, Training time:11356.650705099106
batch reward last col mean 0.08240761607885361 first col mean 0.10548703372478485 all mean 0.0983884334564209
0.35250622034072876 0.35250622034072876
rl training, epoch4, iter0, batch34/1133, batch loss:0.35250622034072876, Training time:11358.702076911926
batch reward last col mean 0.11252211034297943 first col mean 0.10951940715312958 all mean 0.11672107130289078
0.31016314029693604 0.31016314029693604
rl training, epoch4, iter0, batch35/1133, batch loss:0.31016314029693604, Training time:11361.360762834549
batch reward last col mean 0.11118108034133911 first col mean 0.12165406346321106 all mean 0.11537428200244904
0.3559138774871826 0.3559138774871826
rl training, epoch4, iter0, batch36/1133, batch loss:0.3559138774871826, Training time:11363.643713712692
batch reward last col mean 0.08366800099611282 first col mean 0.10255573689937592 all mean 0.09046570956707001
0.26168909668922424 0.26168909668922424
rl training, epoch4, iter0, batch37/1133, batch loss:0.26168909668922424, Training time:11366.31536269188
batch reward last col mean 0.09898607432842255 first col mean 0.1283196061849594 all mean 0.10200538486242294
0.2980669140815735 0.2980669140815735
rl training, epoch4, iter0, batch38/1133, batch loss:0.2980669140815735, Training time:11368.920767307281
batch reward last col mean 0.10660990327596664 first col mean 0.12338270246982574 all mean 0.10680996626615524
0.3143095076084137 0.3143095076084137
rl training, epoch4, iter0, batch39/1133, batch loss:0.3143095076084137, Training time:11371.105986595154
batch reward last col mean 0.09724478423595428 first col mean 0.12335482239723206 all mean 0.10372686386108398
0.29893696308135986 0.29893696308135986
rl training, epoch4, iter0, batch40/1133, batch loss:0.29893696308135986, Training time:11373.012578487396
batch reward last col mean 0.07327088713645935 first col mean 0.12670204043388367 all mean 0.08380325138568878
0.271803081035614 0.271803081035614
rl training, epoch4, iter0, batch41/1133, batch loss:0.271803081035614, Training time:11375.12582206726
batch reward last col mean 0.1055430993437767 first col mean 0.09840422868728638 all mean 0.10586600005626678
0.3388424217700958 0.3388424217700958
rl training, epoch4, iter0, batch42/1133, batch loss:0.3388424217700958, Training time:11378.081393003464
batch reward last col mean 0.10624457895755768 first col mean 0.10707409679889679 all mean 0.10434183478355408
0.3091689646244049 0.3091689646244049
rl training, epoch4, iter0, batch43/1133, batch loss:0.3091689646244049, Training time:11381.22436952591
batch reward last col mean 0.13025012612342834 first col mean 0.10200311243534088 all mean 0.12788650393486023
0.32978522777557373 0.32978522777557373
rl training, epoch4, iter0, batch44/1133, batch loss:0.32978522777557373, Training time:11383.657962560654
batch reward last col mean 0.13013048470020294 first col mean 0.12692788243293762 all mean 0.1294187605381012
0.3671846389770508 0.3671846389770508
rl training, epoch4, iter0, batch45/1133, batch loss:0.3671846389770508, Training time:11386.33906173706
batch reward last col mean 0.09505778551101685 first col mean 0.1162840723991394 all mean 0.10055618733167648
0.31294524669647217 0.31294524669647217
rl training, epoch4, iter0, batch46/1133, batch loss:0.31294524669647217, Training time:11388.83288025856
batch reward last col mean 0.1042461022734642 first col mean 0.10542486608028412 all mean 0.09938408434391022
0.27904170751571655 0.27904170751571655
rl training, epoch4, iter0, batch47/1133, batch loss:0.27904170751571655, Training time:11391.380311012268
batch reward last col mean 0.10322530567646027 first col mean 0.1276278793811798 all mean 0.11014122515916824
0.3444620370864868 0.3444620370864868
rl training, epoch4, iter0, batch48/1133, batch loss:0.3444620370864868, Training time:11393.911052703857
batch reward last col mean 0.10987114161252975 first col mean 0.11280029267072678 all mean 0.10804960131645203
0.33190739154815674 0.33190739154815674
rl training, epoch4, iter0, batch49/1133, batch loss:0.33190739154815674, Training time:11396.112221240997
batch reward last col mean 0.08355402201414108 first col mean 0.1192997470498085 all mean 0.09599131345748901
0.3041585683822632 0.3041585683822632
rl training, epoch4, iter0, batch50/1133, batch loss:0.3041585683822632, Training time:11398.211434841156
batch reward last col mean 0.1063513234257698 first col mean 0.09606847912073135 all mean 0.10542286187410355
0.31923583149909973 0.31923583149909973
rl training, epoch4, iter0, batch51/1133, batch loss:0.31923583149909973, Training time:11400.428773641586
batch reward last col mean 0.11188383400440216 first col mean 0.10780607908964157 all mean 0.11238262057304382
0.36420002579689026 0.36420002579689026
rl training, epoch4, iter0, batch52/1133, batch loss:0.36420002579689026, Training time:11402.545751810074
batch reward last col mean 0.10665884613990784 first col mean 0.10474927723407745 all mean 0.10720380395650864
0.2503889501094818 0.2503889203071594
rl training, epoch4, iter0, batch53/1133, batch loss:0.2503889203071594, Training time:11404.772921085358
batch reward last col mean 0.09601826965808868 first col mean 0.1114126443862915 all mean 0.09606201201677322
0.29716622829437256 0.29716622829437256
rl training, epoch4, iter0, batch54/1133, batch loss:0.29716622829437256, Training time:11406.751697063446
batch reward last col mean 0.08844835311174393 first col mean 0.11780822277069092 all mean 0.0928361788392067
0.2849467396736145 0.2849467396736145
rl training, epoch4, iter0, batch55/1133, batch loss:0.2849467396736145, Training time:11409.204959869385
batch reward last col mean 0.12978151440620422 first col mean 0.1049528494477272 all mean 0.12549065053462982
0.31060582399368286 0.31060582399368286
rl training, epoch4, iter0, batch56/1133, batch loss:0.31060582399368286, Training time:11411.555547952652
batch reward last col mean 0.11681348085403442 first col mean 0.11269184201955795 all mean 0.1151219829916954
0.3417697548866272 0.3417697548866272
rl training, epoch4, iter0, batch57/1133, batch loss:0.3417697548866272, Training time:11414.236666679382
batch reward last col mean 0.10835277289152145 first col mean 0.1186843141913414 all mean 0.10380581766366959
0.2956068515777588 0.2956068217754364
rl training, epoch4, iter0, batch58/1133, batch loss:0.2956068217754364, Training time:11417.543627738953
batch reward last col mean 0.08289740234613419 first col mean 0.11661465466022491 all mean 0.08671244978904724
0.2847834825515747 0.2847834825515747
rl training, epoch4, iter0, batch59/1133, batch loss:0.2847834825515747, Training time:11420.556946277618
batch reward last col mean 0.13605880737304688 first col mean 0.11878669261932373 all mean 0.1269209086894989
0.32726526260375977 0.32726526260375977
rl training, epoch4, iter0, batch60/1133, batch loss:0.32726526260375977, Training time:11423.041327476501
batch reward last col mean 0.0719013661146164 first col mean 0.12316533178091049 all mean 0.08618313074111938
0.3171996772289276 0.3171996772289276
rl training, epoch4, iter0, batch61/1133, batch loss:0.3171996772289276, Training time:11425.383286714554
batch reward last col mean 0.1092270240187645 first col mean 0.11188115179538727 all mean 0.10650868713855743
0.27592673897743225 0.27592673897743225
rl training, epoch4, iter0, batch62/1133, batch loss:0.27592673897743225, Training time:11427.551431894302
batch reward last col mean 0.10388126969337463 first col mean 0.10706692188978195 all mean 0.11026906967163086
0.3245871365070343 0.3245871365070343
rl training, epoch4, iter0, batch63/1133, batch loss:0.3245871365070343, Training time:11429.740822315216
batch reward last col mean 0.1052856594324112 first col mean 0.1081855446100235 all mean 0.10479524731636047
0.2873368561267853 0.2873368561267853
rl training, epoch4, iter0, batch64/1133, batch loss:0.2873368561267853, Training time:11431.411893367767
batch reward last col mean 0.09796205908060074 first col mean 0.11189112812280655 all mean 0.10234781354665756
0.2986505627632141 0.2986505627632141
rl training, epoch4, iter0, batch65/1133, batch loss:0.2986505627632141, Training time:11433.666412115097
batch reward last col mean 0.08819252252578735 first col mean 0.11873378604650497 all mean 0.09827295690774918
0.3165692687034607 0.3165692687034607
rl training, epoch4, iter0, batch66/1133, batch loss:0.3165692687034607, Training time:11435.389295339584
batch reward last col mean 0.10915039479732513 first col mean 0.1318243145942688 all mean 0.11339195817708969
0.3423347771167755 0.3423347771167755
rl training, epoch4, iter0, batch67/1133, batch loss:0.3423347771167755, Training time:11437.203828334808
batch reward last col mean 0.08366203308105469 first col mean 0.12684711813926697 all mean 0.09661304205656052
0.3159881830215454 0.3159881830215454
rl training, epoch4, iter0, batch68/1133, batch loss:0.3159881830215454, Training time:11439.14742398262
batch reward last col mean 0.10260617733001709 first col mean 0.12073725461959839 all mean 0.10876424610614777
0.292085200548172 0.292085200548172
rl training, epoch4, iter0, batch69/1133, batch loss:0.292085200548172, Training time:11441.6410009861
batch reward last col mean 0.11883053928613663 first col mean 0.12076115608215332 all mean 0.11843609064817429
0.3102615773677826 0.3102615773677826
rl training, epoch4, iter0, batch70/1133, batch loss:0.3102615773677826, Training time:11443.792695045471
batch reward last col mean 0.1269550770521164 first col mean 0.09429492056369781 all mean 0.11983733624219894
0.305843323469162 0.305843323469162
rl training, epoch4, iter0, batch71/1133, batch loss:0.305843323469162, Training time:11446.591325759888
batch reward last col mean 0.1404738873243332 first col mean 0.10291077196598053 all mean 0.13732022047042847
0.39732304215431213 0.39732304215431213
rl training, epoch4, iter0, batch72/1133, batch loss:0.39732304215431213, Training time:11448.486634492874
batch reward last col mean 0.1014222800731659 first col mean 0.12906119227409363 all mean 0.10860041528940201
0.3443388342857361 0.3443388044834137
rl training, epoch4, iter0, batch73/1133, batch loss:0.3443388044834137, Training time:11450.24712896347
batch reward last col mean 0.08809572458267212 first col mean 0.12140823155641556 all mean 0.09627930074930191
0.28332120180130005 0.28332120180130005
rl training, epoch4, iter0, batch74/1133, batch loss:0.28332120180130005, Training time:11452.137593984604
batch reward last col mean 0.11112748831510544 first col mean 0.12005811929702759 all mean 0.11573649197816849
0.31347453594207764 0.31347453594207764
rl training, epoch4, iter0, batch75/1133, batch loss:0.31347453594207764, Training time:11454.128521680832
batch reward last col mean 0.12973415851593018 first col mean 0.10010991245508194 all mean 0.1262080818414688
0.3140757083892822 0.3140757083892822
rl training, epoch4, iter0, batch76/1133, batch loss:0.3140757083892822, Training time:11456.092654943466
batch reward last col mean 0.09245660901069641 first col mean 0.10788726061582565 all mean 0.09836802631616592
0.2892211079597473 0.2892211079597473
rl training, epoch4, iter0, batch77/1133, batch loss:0.2892211079597473, Training time:11458.110732793808
batch reward last col mean 0.14097589254379272 first col mean 0.10060086846351624 all mean 0.14048632979393005
0.38760700821876526 0.38760700821876526
rl training, epoch4, iter0, batch78/1133, batch loss:0.38760700821876526, Training time:11460.357866048813
batch reward last col mean 0.09808581322431564 first col mean 0.11130654811859131 all mean 0.10271575301885605
0.33739805221557617 0.33739805221557617
rl training, epoch4, iter0, batch79/1133, batch loss:0.33739805221557617, Training time:11462.358845949173
batch reward last col mean 0.10382644087076187 first col mean 0.11522100865840912 all mean 0.10855937004089355
0.34165531396865845 0.34165531396865845
rl training, epoch4, iter0, batch80/1133, batch loss:0.34165531396865845, Training time:11464.59241104126
batch reward last col mean 0.11130120605230331 first col mean 0.10029997676610947 all mean 0.10838116705417633
0.3180924654006958 0.3180924654006958
rl training, epoch4, iter0, batch81/1133, batch loss:0.3180924654006958, Training time:11466.4290933609
batch reward last col mean 0.12334705144166946 first col mean 0.13180725276470184 all mean 0.12289100885391235
0.36705365777015686 0.36705365777015686
rl training, epoch4, iter0, batch82/1133, batch loss:0.36705365777015686, Training time:11468.288631916046
batch reward last col mean 0.11451184004545212 first col mean 0.1250535398721695 all mean 0.11610785126686096
0.2900116741657257 0.2900116741657257
rl training, epoch4, iter0, batch83/1133, batch loss:0.2900116741657257, Training time:11470.032087087631
batch reward last col mean 0.14887991547584534 first col mean 0.12555426359176636 all mean 0.1376664936542511
0.3621639907360077 0.3621639907360077
rl training, epoch4, iter0, batch84/1133, batch loss:0.3621639907360077, Training time:11471.587360858917
batch reward last col mean 0.13012990355491638 first col mean 0.1067337691783905 all mean 0.1277443915605545
0.33387479186058044 0.33387479186058044
rl training, epoch4, iter0, batch85/1133, batch loss:0.33387479186058044, Training time:11473.27687716484
batch reward last col mean 0.12333215773105621 first col mean 0.10832872986793518 all mean 0.1182515025138855
0.3509148359298706 0.3509148359298706
rl training, epoch4, iter0, batch86/1133, batch loss:0.3509148359298706, Training time:11475.4408929348
batch reward last col mean 0.12866362929344177 first col mean 0.1092921793460846 all mean 0.12848547101020813
0.3290034234523773 0.3290034234523773
rl training, epoch4, iter0, batch87/1133, batch loss:0.3290034234523773, Training time:11477.168069124222
batch reward last col mean 0.1209234744310379 first col mean 0.10322309285402298 all mean 0.11747108399868011
0.3113129138946533 0.3113129138946533
rl training, epoch4, iter0, batch88/1133, batch loss:0.3113129138946533, Training time:11478.87646150589
batch reward last col mean 0.10456705838441849 first col mean 0.10704157501459122 all mean 0.10653520375490189
0.2989620566368103 0.2989620268344879
rl training, epoch4, iter0, batch89/1133, batch loss:0.2989620268344879, Training time:11480.95536351204
batch reward last col mean 0.12546944618225098 first col mean 0.11800865828990936 all mean 0.12055367231369019
0.33323991298675537 0.33323991298675537
rl training, epoch4, iter0, batch90/1133, batch loss:0.33323991298675537, Training time:11483.221685171127
batch reward last col mean 0.11634141206741333 first col mean 0.12618345022201538 all mean 0.11893349140882492
0.3427077531814575 0.3427077531814575
rl training, epoch4, iter0, batch91/1133, batch loss:0.3427077531814575, Training time:11484.736086845398
batch reward last col mean 0.10437653958797455 first col mean 0.11742760241031647 all mean 0.10572449862957001
0.31360602378845215 0.31360602378845215
rl training, epoch4, iter0, batch92/1133, batch loss:0.31360602378845215, Training time:11486.696672439575
batch reward last col mean 0.11341845244169235 first col mean 0.12358073890209198 all mean 0.1098773255944252
0.3197394907474518 0.319739431142807
rl training, epoch4, iter0, batch93/1133, batch loss:0.319739431142807, Training time:11488.595589399338
batch reward last col mean 0.13734981417655945 first col mean 0.09587462991476059 all mean 0.13252350687980652
0.32176095247268677 0.32176095247268677
rl training, epoch4, iter0, batch94/1133, batch loss:0.32176095247268677, Training time:11490.634380340576
batch reward last col mean 0.1073986291885376 first col mean 0.12676697969436646 all mean 0.11457137018442154
0.3907718062400818 0.3907718062400818
rl training, epoch4, iter0, batch95/1133, batch loss:0.3907718062400818, Training time:11492.388807535172
batch reward last col mean 0.11885624378919601 first col mean 0.10541421175003052 all mean 0.11895200610160828
0.26131898164749146 0.26131901144981384
rl training, epoch4, iter0, batch96/1133, batch loss:0.26131901144981384, Training time:11494.972725629807
batch reward last col mean 0.13079369068145752 first col mean 0.10048918426036835 all mean 0.12501296401023865
0.2939072251319885 0.2939072251319885
rl training, epoch4, iter0, batch97/1133, batch loss:0.2939072251319885, Training time:11496.920917749405
batch reward last col mean 0.11681479960680008 first col mean 0.12140261381864548 all mean 0.11735701560974121
0.3600737452507019 0.3600737452507019
rl training, epoch4, iter0, batch98/1133, batch loss:0.3600737452507019, Training time:11498.306549310684
batch reward last col mean 0.07772573828697205 first col mean 0.10329645127058029 all mean 0.08698872476816177
0.2901923358440399 0.2901923656463623
rl training, epoch4, iter0, batch99/1133, batch loss:0.2901923656463623, Training time:11500.281732320786
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5140656477460163 Time: 100.42976570129395 s
loss of true 0.2226745280036859 loss of gen 0.18305617891127096 loss of other 0.1083349405022606 first score 0.10782191157341003
batch reward last col mean 0.08552854508161545 first col mean 0.1307654082775116 all mean 0.09024077653884888
0.2934800386428833 0.2934800386428833
rl training, epoch4, iter0, batch100/1133, batch loss:0.2934800386428833, Training time:11602.789732933044
batch reward last col mean 0.11202651262283325 first col mean 0.1242506206035614 all mean 0.11082321405410767
0.31479379534721375 0.31479379534721375
rl training, epoch4, iter0, batch101/1133, batch loss:0.31479379534721375, Training time:11605.020030260086
batch reward last col mean 0.1131705790758133 first col mean 0.10417523980140686 all mean 0.11090239882469177
0.29938942193984985 0.29938942193984985
rl training, epoch4, iter0, batch102/1133, batch loss:0.29938942193984985, Training time:11607.457359075546
batch reward last col mean 0.1121847853064537 first col mean 0.11870718002319336 all mean 0.11074278503656387
0.2988184988498688 0.2988184988498688
rl training, epoch4, iter0, batch103/1133, batch loss:0.2988184988498688, Training time:11609.763912677765
batch reward last col mean 0.11112503707408905 first col mean 0.10767059773206711 all mean 0.11080344766378403
0.3287137448787689 0.3287137448787689
rl training, epoch4, iter0, batch104/1133, batch loss:0.3287137448787689, Training time:11611.617023944855
batch reward last col mean 0.10566616803407669 first col mean 0.11844856292009354 all mean 0.10585018247365952
0.3150932490825653 0.3150932490825653
rl training, epoch4, iter0, batch105/1133, batch loss:0.3150932490825653, Training time:11613.336229085922
batch reward last col mean 0.08983626961708069 first col mean 0.11904118955135345 all mean 0.09218878298997879
0.26154106855392456 0.26154106855392456
rl training, epoch4, iter0, batch106/1133, batch loss:0.26154106855392456, Training time:11615.625999689102
batch reward last col mean 0.10487343370914459 first col mean 0.11334502696990967 all mean 0.10573717206716537
0.32364892959594727 0.32364892959594727
rl training, epoch4, iter0, batch107/1133, batch loss:0.32364892959594727, Training time:11617.091681718826
batch reward last col mean 0.1165250614285469 first col mean 0.1243116706609726 all mean 0.12061327695846558
0.3499801456928253 0.3499801456928253
rl training, epoch4, iter0, batch108/1133, batch loss:0.3499801456928253, Training time:11618.73578953743
batch reward last col mean 0.12308205664157867 first col mean 0.11749652028083801 all mean 0.11757779121398926
0.34856531023979187 0.34856531023979187
rl training, epoch4, iter0, batch109/1133, batch loss:0.34856531023979187, Training time:11620.783755540848
batch reward last col mean 0.09117764979600906 first col mean 0.1111731231212616 all mean 0.09742387384176254
0.28049492835998535 0.28049492835998535
rl training, epoch4, iter0, batch110/1133, batch loss:0.28049492835998535, Training time:11622.525871276855
batch reward last col mean 0.11854997277259827 first col mean 0.10496040433645248 all mean 0.11917693167924881
0.351013720035553 0.351013720035553
rl training, epoch4, iter0, batch111/1133, batch loss:0.351013720035553, Training time:11625.015486955643
batch reward last col mean 0.12192932516336441 first col mean 0.11223770678043365 all mean 0.11595172435045242
0.31296995282173157 0.31296995282173157
rl training, epoch4, iter0, batch112/1133, batch loss:0.31296995282173157, Training time:11626.995636940002
batch reward last col mean 0.09739053249359131 first col mean 0.10649150609970093 all mean 0.09826923906803131
0.33226248621940613 0.33226248621940613
rl training, epoch4, iter0, batch113/1133, batch loss:0.33226248621940613, Training time:11629.192526817322
batch reward last col mean 0.12954558432102203 first col mean 0.12635791301727295 all mean 0.12174123525619507
0.31003305315971375 0.31003305315971375
rl training, epoch4, iter0, batch114/1133, batch loss:0.31003305315971375, Training time:11630.82446718216
batch reward last col mean 0.11161904036998749 first col mean 0.10623127222061157 all mean 0.11611561477184296
0.35477015376091003 0.35477015376091003
rl training, epoch4, iter0, batch115/1133, batch loss:0.35477015376091003, Training time:11633.307824611664
batch reward last col mean 0.13342252373695374 first col mean 0.1029437854886055 all mean 0.12787990272045135
0.33641594648361206 0.33641594648361206
rl training, epoch4, iter0, batch116/1133, batch loss:0.33641594648361206, Training time:11635.61423754692
batch reward last col mean 0.1270478516817093 first col mean 0.1212964877486229 all mean 0.12260761111974716
0.37693408131599426 0.37693408131599426
rl training, epoch4, iter0, batch117/1133, batch loss:0.37693408131599426, Training time:11637.67832159996
batch reward last col mean 0.11783450841903687 first col mean 0.08873525261878967 all mean 0.1207125261425972
0.3636607229709625 0.3636607229709625
rl training, epoch4, iter0, batch118/1133, batch loss:0.3636607229709625, Training time:11639.567838191986
batch reward last col mean 0.09732691198587418 first col mean 0.10824176669120789 all mean 0.1025552973151207
0.31922686100006104 0.31922686100006104
rl training, epoch4, iter0, batch119/1133, batch loss:0.31922686100006104, Training time:11642.592383861542
batch reward last col mean 0.11701879650354385 first col mean 0.11731146275997162 all mean 0.10874445736408234
0.2837633490562439 0.2837633788585663
rl training, epoch4, iter0, batch120/1133, batch loss:0.2837633788585663, Training time:11644.567913293839
batch reward last col mean 0.09887834638357162 first col mean 0.11579751968383789 all mean 0.0966610312461853
0.3390626311302185 0.3390626311302185
rl training, epoch4, iter0, batch121/1133, batch loss:0.3390626311302185, Training time:11646.568341970444
batch reward last col mean 0.08009691536426544 first col mean 0.12397772073745728 all mean 0.08736833184957504
0.29659831523895264 0.29659831523895264
rl training, epoch4, iter0, batch122/1133, batch loss:0.29659831523895264, Training time:11649.102486133575
batch reward last col mean 0.08336839079856873 first col mean 0.11579059064388275 all mean 0.09436270594596863
0.3276808261871338 0.3276807963848114
rl training, epoch4, iter0, batch123/1133, batch loss:0.3276807963848114, Training time:11651.47700047493
batch reward last col mean 0.12892787158489227 first col mean 0.10692394524812698 all mean 0.12909731268882751
0.34347912669181824 0.34347912669181824
rl training, epoch4, iter0, batch124/1133, batch loss:0.34347912669181824, Training time:11653.52792596817
batch reward last col mean 0.1303505003452301 first col mean 0.13090801239013672 all mean 0.12010201811790466
0.35563719272613525 0.35563719272613525
rl training, epoch4, iter0, batch125/1133, batch loss:0.35563719272613525, Training time:11655.15301322937
batch reward last col mean 0.11347123980522156 first col mean 0.123035728931427 all mean 0.11295486241579056
0.3835311532020569 0.3835311830043793
rl training, epoch4, iter0, batch126/1133, batch loss:0.3835311830043793, Training time:11657.249812841415
batch reward last col mean 0.06301946192979813 first col mean 0.09611900895833969 all mean 0.06909041851758957
0.25847509503364563 0.25847509503364563
rl training, epoch4, iter0, batch127/1133, batch loss:0.25847509503364563, Training time:11659.952178239822
batch reward last col mean 0.11214680224657059 first col mean 0.11887682974338531 all mean 0.11219418048858643
0.3315558433532715 0.3315558135509491
rl training, epoch4, iter0, batch128/1133, batch loss:0.3315558135509491, Training time:11661.590911865234
batch reward last col mean 0.10797211527824402 first col mean 0.10178667306900024 all mean 0.10957171767950058
0.3369992673397064 0.3369992673397064
rl training, epoch4, iter0, batch129/1133, batch loss:0.3369992673397064, Training time:11663.259489297867
batch reward last col mean 0.07722010463476181 first col mean 0.10784684121608734 all mean 0.08488225936889648
0.31069979071617126 0.31069979071617126
rl training, epoch4, iter0, batch130/1133, batch loss:0.31069979071617126, Training time:11665.624238729477
batch reward last col mean 0.13035622239112854 first col mean 0.11513783037662506 all mean 0.1257535219192505
0.36403441429138184 0.36403441429138184
rl training, epoch4, iter0, batch131/1133, batch loss:0.36403441429138184, Training time:11667.441579341888
batch reward last col mean 0.08958447724580765 first col mean 0.10870638489723206 all mean 0.09356922656297684
0.3052385747432709 0.3052385747432709
rl training, epoch4, iter0, batch132/1133, batch loss:0.3052385747432709, Training time:11671.76658153534
batch reward last col mean 0.11285525560379028 first col mean 0.11838860809803009 all mean 0.11378021538257599
0.30066752433776855 0.30066755414009094
rl training, epoch4, iter0, batch133/1133, batch loss:0.30066755414009094, Training time:11673.966978311539
batch reward last col mean 0.10537897795438766 first col mean 0.11345329880714417 all mean 0.10787717998027802
0.2967697083950043 0.2967697083950043
rl training, epoch4, iter0, batch134/1133, batch loss:0.2967697083950043, Training time:11675.865680217743
batch reward last col mean 0.1355464905500412 first col mean 0.12149495631456375 all mean 0.13118308782577515
0.35238194465637207 0.35238194465637207
rl training, epoch4, iter0, batch135/1133, batch loss:0.35238194465637207, Training time:11677.900052309036
batch reward last col mean 0.1414380967617035 first col mean 0.12494085729122162 all mean 0.13709889352321625
0.35086748003959656 0.35086748003959656
rl training, epoch4, iter0, batch136/1133, batch loss:0.35086748003959656, Training time:11679.764019727707
batch reward last col mean 0.10112525522708893 first col mean 0.10843107849359512 all mean 0.10339969396591187
0.31489914655685425 0.31489914655685425
rl training, epoch4, iter0, batch137/1133, batch loss:0.31489914655685425, Training time:11681.832602977753
batch reward last col mean 0.1029914915561676 first col mean 0.126875638961792 all mean 0.11076079308986664
0.31298893690109253 0.31298893690109253
rl training, epoch4, iter0, batch138/1133, batch loss:0.31298893690109253, Training time:11683.560780763626
batch reward last col mean 0.08834341168403625 first col mean 0.09622757136821747 all mean 0.09741522371768951
0.2786822021007538 0.2786821722984314
rl training, epoch4, iter0, batch139/1133, batch loss:0.2786821722984314, Training time:11685.45439505577
batch reward last col mean 0.11005689948797226 first col mean 0.12899886071681976 all mean 0.11321629583835602
0.305355042219162 0.305355042219162
rl training, epoch4, iter0, batch140/1133, batch loss:0.305355042219162, Training time:11687.760126829147
batch reward last col mean 0.09884731471538544 first col mean 0.11568073183298111 all mean 0.10666447132825851
0.32362109422683716 0.32362109422683716
rl training, epoch4, iter0, batch141/1133, batch loss:0.32362109422683716, Training time:11689.635514736176
batch reward last col mean 0.08926516771316528 first col mean 0.1112448126077652 all mean 0.09711450338363647
0.30204346776008606 0.30204346776008606
rl training, epoch4, iter0, batch142/1133, batch loss:0.30204346776008606, Training time:11691.36093711853
batch reward last col mean 0.07290976494550705 first col mean 0.0994306281208992 all mean 0.0814065933227539
0.304816871881485 0.304816871881485
rl training, epoch4, iter0, batch143/1133, batch loss:0.304816871881485, Training time:11693.441815376282
batch reward last col mean 0.07731054723262787 first col mean 0.12044599652290344 all mean 0.08667682856321335
0.2904936373233795 0.29049360752105713
rl training, epoch4, iter0, batch144/1133, batch loss:0.29049360752105713, Training time:11695.6979637146
batch reward last col mean 0.11342920362949371 first col mean 0.1041022539138794 all mean 0.11302787810564041
0.3358677327632904 0.3358677327632904
rl training, epoch4, iter0, batch145/1133, batch loss:0.3358677327632904, Training time:11698.206114768982
batch reward last col mean 0.10659657418727875 first col mean 0.12748298048973083 all mean 0.11500465124845505
0.2832881212234497 0.2832881212234497
rl training, epoch4, iter0, batch146/1133, batch loss:0.2832881212234497, Training time:11699.737527608871
batch reward last col mean 0.11566285789012909 first col mean 0.13105079531669617 all mean 0.12026403844356537
0.3263549208641052 0.3263549208641052
rl training, epoch4, iter0, batch147/1133, batch loss:0.3263549208641052, Training time:11702.497968912125
batch reward last col mean 0.10996417701244354 first col mean 0.11932380497455597 all mean 0.10760288685560226
0.28327035903930664 0.28327038884162903
rl training, epoch4, iter0, batch148/1133, batch loss:0.28327038884162903, Training time:11704.78331542015
batch reward last col mean 0.13509832322597504 first col mean 0.12281166017055511 all mean 0.1309335082769394
0.3564501702785492 0.3564501702785492
rl training, epoch4, iter0, batch149/1133, batch loss:0.3564501702785492, Training time:11706.298208475113
batch reward last col mean 0.13022832572460175 first col mean 0.12602980434894562 all mean 0.13198362290859222
0.3274257779121399 0.3274257779121399
rl training, epoch4, iter0, batch150/1133, batch loss:0.3274257779121399, Training time:11708.459693431854
batch reward last col mean 0.10677679628133774 first col mean 0.1084076464176178 all mean 0.10846619307994843
0.3353358805179596 0.3353358805179596
rl training, epoch4, iter0, batch151/1133, batch loss:0.3353358805179596, Training time:11710.64400434494
batch reward last col mean 0.09767867624759674 first col mean 0.11745436489582062 all mean 0.10221400856971741
0.28826001286506653 0.28826001286506653
rl training, epoch4, iter0, batch152/1133, batch loss:0.28826001286506653, Training time:11712.629943609238
batch reward last col mean 0.11899717152118683 first col mean 0.12492203712463379 all mean 0.11796658486127853
0.32586872577667236 0.32586872577667236
rl training, epoch4, iter0, batch153/1133, batch loss:0.32586872577667236, Training time:11714.399905443192
batch reward last col mean 0.0783599391579628 first col mean 0.12603871524333954 all mean 0.08787485957145691
0.2898145616054535 0.2898145616054535
rl training, epoch4, iter0, batch154/1133, batch loss:0.2898145616054535, Training time:11716.55768084526
batch reward last col mean 0.15672501921653748 first col mean 0.10087314993143082 all mean 0.14513349533081055
0.3574522137641907 0.3574522137641907
rl training, epoch4, iter0, batch155/1133, batch loss:0.3574522137641907, Training time:11718.728925704956
batch reward last col mean 0.13745687901973724 first col mean 0.11423557996749878 all mean 0.13189345598220825
0.36221712827682495 0.36221712827682495
rl training, epoch4, iter0, batch156/1133, batch loss:0.36221712827682495, Training time:11720.401040315628
batch reward last col mean 0.10559628903865814 first col mean 0.10721252858638763 all mean 0.1051025390625
0.30881381034851074 0.30881381034851074
rl training, epoch4, iter0, batch157/1133, batch loss:0.30881381034851074, Training time:11723.21172451973
batch reward last col mean 0.10040711611509323 first col mean 0.12386482954025269 all mean 0.10025236755609512
0.28376904129981995 0.28376907110214233
rl training, epoch4, iter0, batch158/1133, batch loss:0.28376907110214233, Training time:11725.391591787338
batch reward last col mean 0.11234240233898163 first col mean 0.10436341166496277 all mean 0.11451492458581924
0.33839523792266846 0.33839523792266846
rl training, epoch4, iter0, batch159/1133, batch loss:0.33839523792266846, Training time:11727.591980218887
batch reward last col mean 0.08622299134731293 first col mean 0.10790559649467468 all mean 0.09758857637643814
0.28967559337615967 0.28967559337615967
rl training, epoch4, iter0, batch160/1133, batch loss:0.28967559337615967, Training time:11729.288189172745
batch reward last col mean 0.08879102766513824 first col mean 0.09751025587320328 all mean 0.10146106034517288
0.31111910939216614 0.31111910939216614
rl training, epoch4, iter0, batch161/1133, batch loss:0.31111910939216614, Training time:11731.029807567596
batch reward last col mean 0.10041581094264984 first col mean 0.1292838752269745 all mean 0.10313484817743301
0.2839072346687317 0.2839072346687317
rl training, epoch4, iter0, batch162/1133, batch loss:0.2839072346687317, Training time:11733.420472860336
batch reward last col mean 0.08207179605960846 first col mean 0.10964567214250565 all mean 0.08667591214179993
0.2826560437679291 0.2826560437679291
rl training, epoch4, iter0, batch163/1133, batch loss:0.2826560437679291, Training time:11735.439308404922
batch reward last col mean 0.16730466485023499 first col mean 0.12175149470567703 all mean 0.15506890416145325
0.3797549903392792 0.3797549903392792
rl training, epoch4, iter0, batch164/1133, batch loss:0.3797549903392792, Training time:11737.000462532043
batch reward last col mean 0.14035920798778534 first col mean 0.12111538648605347 all mean 0.1350778490304947
0.3749390244483948 0.3749390244483948
rl training, epoch4, iter0, batch165/1133, batch loss:0.3749390244483948, Training time:11739.169508934021
batch reward last col mean 0.09098722040653229 first col mean 0.1286384016275406 all mean 0.09451627731323242
0.30827346444129944 0.30827346444129944
rl training, epoch4, iter0, batch166/1133, batch loss:0.30827346444129944, Training time:11741.160604953766
batch reward last col mean 0.1087646558880806 first col mean 0.10227370262145996 all mean 0.10896013677120209
0.3272501230239868 0.3272501230239868
rl training, epoch4, iter0, batch167/1133, batch loss:0.3272501230239868, Training time:11742.976056814194
batch reward last col mean 0.06466017663478851 first col mean 0.12168973684310913 all mean 0.07654847949743271
0.28869959712028503 0.28869959712028503
rl training, epoch4, iter0, batch168/1133, batch loss:0.28869959712028503, Training time:11744.84973192215
batch reward last col mean 0.13320454955101013 first col mean 0.11892382055521011 all mean 0.12570065259933472
0.3502388596534729 0.3502388596534729
rl training, epoch4, iter0, batch169/1133, batch loss:0.3502388596534729, Training time:11746.561671257019
batch reward last col mean 0.10687604546546936 first col mean 0.12177284061908722 all mean 0.11238951236009598
0.35162943601608276 0.35162943601608276
rl training, epoch4, iter0, batch170/1133, batch loss:0.35162943601608276, Training time:11748.253906011581
batch reward last col mean 0.10812452435493469 first col mean 0.12597745656967163 all mean 0.10763445496559143
0.3079191744327545 0.3079191744327545
rl training, epoch4, iter0, batch171/1133, batch loss:0.3079191744327545, Training time:11750.750771522522
batch reward last col mean 0.11451216787099838 first col mean 0.11422832310199738 all mean 0.11569295823574066
0.30934640765190125 0.30934640765190125
rl training, epoch4, iter0, batch172/1133, batch loss:0.30934640765190125, Training time:11752.628196716309
batch reward last col mean 0.06936058402061462 first col mean 0.11649978160858154 all mean 0.08793605864048004
0.35821107029914856 0.35821107029914856
rl training, epoch4, iter0, batch173/1133, batch loss:0.35821107029914856, Training time:11754.25706243515
batch reward last col mean 0.07794523984193802 first col mean 0.11631304025650024 all mean 0.0896325409412384
0.3040551543235779 0.3040551543235779
rl training, epoch4, iter0, batch174/1133, batch loss:0.3040551543235779, Training time:11756.04529428482
batch reward last col mean 0.1042272299528122 first col mean 0.09963321685791016 all mean 0.10371050238609314
0.2894124388694763 0.2894124388694763
rl training, epoch4, iter0, batch175/1133, batch loss:0.2894124388694763, Training time:11757.802258491516
batch reward last col mean 0.11890298128128052 first col mean 0.11114475131034851 all mean 0.12083916366100311
0.36137157678604126 0.36137157678604126
rl training, epoch4, iter0, batch176/1133, batch loss:0.36137157678604126, Training time:11759.334624767303
batch reward last col mean 0.14445219933986664 first col mean 0.11962956190109253 all mean 0.12649431824684143
0.33772122859954834 0.33772122859954834
rl training, epoch4, iter0, batch177/1133, batch loss:0.33772122859954834, Training time:11760.802499771118
batch reward last col mean 0.10924851894378662 first col mean 0.12953220307826996 all mean 0.11426565051078796
0.321972131729126 0.321972131729126
rl training, epoch4, iter0, batch178/1133, batch loss:0.321972131729126, Training time:11762.496510267258
batch reward last col mean 0.1372213363647461 first col mean 0.10678453743457794 all mean 0.13459010422229767
0.3418339490890503 0.3418339490890503
rl training, epoch4, iter0, batch179/1133, batch loss:0.3418339490890503, Training time:11764.592044115067
batch reward last col mean 0.09236829727888107 first col mean 0.12729762494564056 all mean 0.0996621623635292
0.3331012725830078 0.3331012725830078
rl training, epoch4, iter0, batch180/1133, batch loss:0.3331012725830078, Training time:11766.355814695358
batch reward last col mean 0.11367291212081909 first col mean 0.10879853367805481 all mean 0.11316397041082382
0.3272835314273834 0.3272835314273834
rl training, epoch4, iter0, batch181/1133, batch loss:0.3272835314273834, Training time:11767.961775302887
batch reward last col mean 0.11471713334321976 first col mean 0.12354300171136856 all mean 0.1191665306687355
0.3548571467399597 0.3548571467399597
rl training, epoch4, iter0, batch182/1133, batch loss:0.3548571467399597, Training time:11770.14953994751
batch reward last col mean 0.11245083063840866 first col mean 0.12346981465816498 all mean 0.11361821740865707
0.3311370313167572 0.3311370611190796
rl training, epoch4, iter0, batch183/1133, batch loss:0.3311370611190796, Training time:11772.03591299057
batch reward last col mean 0.11901090294122696 first col mean 0.11816909909248352 all mean 0.11996091902256012
0.3587806224822998 0.35878056287765503
rl training, epoch4, iter0, batch184/1133, batch loss:0.35878056287765503, Training time:11774.141022205353
batch reward last col mean 0.11986827850341797 first col mean 0.10966883599758148 all mean 0.1156802847981453
0.3146400451660156 0.3146401047706604
rl training, epoch4, iter0, batch185/1133, batch loss:0.3146401047706604, Training time:11776.168734073639
batch reward last col mean 0.1094900518655777 first col mean 0.11681509017944336 all mean 0.11052751541137695
0.30999061465263367 0.30999061465263367
rl training, epoch4, iter0, batch186/1133, batch loss:0.30999061465263367, Training time:11778.114172458649
batch reward last col mean 0.1549510806798935 first col mean 0.13113273680210114 all mean 0.1501804143190384
0.3467405438423157 0.3467405438423157
rl training, epoch4, iter0, batch187/1133, batch loss:0.3467405438423157, Training time:11779.506737232208
batch reward last col mean 0.0982527881860733 first col mean 0.12444677948951721 all mean 0.10432574152946472
0.3351873457431793 0.3351873457431793
rl training, epoch4, iter0, batch188/1133, batch loss:0.3351873457431793, Training time:11781.051110982895
batch reward last col mean 0.11214503645896912 first col mean 0.11511777341365814 all mean 0.1078699454665184
0.3157033324241638 0.3157033622264862
rl training, epoch4, iter0, batch189/1133, batch loss:0.3157033622264862, Training time:11782.79119181633
batch reward last col mean 0.126675084233284 first col mean 0.1262403130531311 all mean 0.13007423281669617
0.3906562328338623 0.3906562328338623
rl training, epoch4, iter0, batch190/1133, batch loss:0.3906562328338623, Training time:11784.326996088028
batch reward last col mean 0.13869163393974304 first col mean 0.1271880567073822 all mean 0.13229314982891083
0.315824955701828 0.3158249855041504
rl training, epoch4, iter0, batch191/1133, batch loss:0.3158249855041504, Training time:11786.290944099426
batch reward last col mean 0.09428544342517853 first col mean 0.12369818985462189 all mean 0.10480019450187683
0.32847005128860474 0.32847002148628235
rl training, epoch4, iter0, batch192/1133, batch loss:0.32847002148628235, Training time:11788.10087609291
batch reward last col mean 0.1273721307516098 first col mean 0.09244316816329956 all mean 0.123561330139637
0.31541866064071655 0.31541866064071655
rl training, epoch4, iter0, batch193/1133, batch loss:0.31541866064071655, Training time:11790.516578674316
batch reward last col mean 0.08926594257354736 first col mean 0.12134988605976105 all mean 0.0986555814743042
0.3401031792163849 0.3401032090187073
rl training, epoch4, iter0, batch194/1133, batch loss:0.3401032090187073, Training time:11792.733031272888
batch reward last col mean 0.09114550054073334 first col mean 0.12005232274532318 all mean 0.09800220280885696
0.30014291405677795 0.30014291405677795
rl training, epoch4, iter0, batch195/1133, batch loss:0.30014291405677795, Training time:11794.722037792206
batch reward last col mean 0.09537109732627869 first col mean 0.11321388930082321 all mean 0.10493169724941254
0.3277468979358673 0.3277468979358673
rl training, epoch4, iter0, batch196/1133, batch loss:0.3277468979358673, Training time:11796.576499938965
batch reward last col mean 0.10243305563926697 first col mean 0.09918498992919922 all mean 0.10623051971197128
0.28639498353004456 0.28639498353004456
rl training, epoch4, iter0, batch197/1133, batch loss:0.28639498353004456, Training time:11798.034798145294
batch reward last col mean 0.10844673216342926 first col mean 0.12602598965168 all mean 0.11531410366296768
0.3424341678619385 0.3424341678619385
rl training, epoch4, iter0, batch198/1133, batch loss:0.3424341678619385, Training time:11799.84560251236
batch reward last col mean 0.0784737691283226 first col mean 0.10202628374099731 all mean 0.09073355048894882
0.2752009630203247 0.2752009630203247
rl training, epoch4, iter0, batch199/1133, batch loss:0.2752009630203247, Training time:11801.889342784882
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5104504207910318 Time: 98.43784165382385 s
loss of true 0.22269056027217554 loss of gen 0.1812475390028659 loss of other 0.10651232104498601 first score 0.1006312370300293
batch reward last col mean 0.14093127846717834 first col mean 0.10180492699146271 all mean 0.13625960052013397
0.3567069470882416 0.3567069470882416
rl training, epoch4, iter0, batch200/1133, batch loss:0.3567069470882416, Training time:11902.80364203453
batch reward last col mean 0.10151183605194092 first col mean 0.11160072684288025 all mean 0.10804411768913269
0.307449609041214 0.307449609041214
rl training, epoch4, iter0, batch201/1133, batch loss:0.307449609041214, Training time:11904.435777664185
batch reward last col mean 0.11182768642902374 first col mean 0.11255265027284622 all mean 0.11026506870985031
0.3072895109653473 0.3072895109653473
rl training, epoch4, iter0, batch202/1133, batch loss:0.3072895109653473, Training time:11905.931592702866
batch reward last col mean 0.08429138362407684 first col mean 0.09884517639875412 all mean 0.08932574093341827
0.2688824534416199 0.2688824534416199
rl training, epoch4, iter0, batch203/1133, batch loss:0.2688824534416199, Training time:11907.714579582214
batch reward last col mean 0.11215655505657196 first col mean 0.10374290496110916 all mean 0.11466020345687866
0.3249906897544861 0.3249906897544861
rl training, epoch4, iter0, batch204/1133, batch loss:0.3249906897544861, Training time:11909.59575009346
batch reward last col mean 0.09876588732004166 first col mean 0.11191441118717194 all mean 0.10446881502866745
0.3194206953048706 0.3194206953048706
rl training, epoch4, iter0, batch205/1133, batch loss:0.3194206953048706, Training time:11911.258719682693
batch reward last col mean 0.09308646619319916 first col mean 0.10816405713558197 all mean 0.09424535185098648
0.28232067823410034 0.28232067823410034
rl training, epoch4, iter0, batch206/1133, batch loss:0.28232067823410034, Training time:11913.020998001099
batch reward last col mean 0.1233019009232521 first col mean 0.1155412569642067 all mean 0.12293267250061035
0.3720360994338989 0.3720360994338989
rl training, epoch4, iter0, batch207/1133, batch loss:0.3720360994338989, Training time:11915.866983652115
batch reward last col mean 0.129779651761055 first col mean 0.09504051506519318 all mean 0.12633106112480164
0.3577251136302948 0.3577251136302948
rl training, epoch4, iter0, batch208/1133, batch loss:0.3577251136302948, Training time:11917.405614614487
batch reward last col mean 0.12008616328239441 first col mean 0.12438680231571198 all mean 0.11888382583856583
0.34126412868499756 0.34126412868499756
rl training, epoch4, iter0, batch209/1133, batch loss:0.34126412868499756, Training time:11919.240537643433
batch reward last col mean 0.1113029420375824 first col mean 0.09250473976135254 all mean 0.11500591039657593
0.36061891913414 0.3606188893318176
rl training, epoch4, iter0, batch210/1133, batch loss:0.3606188893318176, Training time:11920.813582897186
batch reward last col mean 0.0957055389881134 first col mean 0.11528399586677551 all mean 0.1006002202630043
0.2748369872570038 0.2748369872570038
rl training, epoch4, iter0, batch211/1133, batch loss:0.2748369872570038, Training time:11922.528144359589
batch reward last col mean 0.09971340000629425 first col mean 0.10542729496955872 all mean 0.0989968329668045
0.3136554956436157 0.3136554956436157
rl training, epoch4, iter0, batch212/1133, batch loss:0.3136554956436157, Training time:11924.46678853035
batch reward last col mean 0.10812380909919739 first col mean 0.10176465660333633 all mean 0.10203488916158676
0.29616937041282654 0.29616934061050415
rl training, epoch4, iter0, batch213/1133, batch loss:0.29616934061050415, Training time:11926.760059595108
batch reward last col mean 0.09479917585849762 first col mean 0.11373551189899445 all mean 0.09880746155977249
0.27731385827064514 0.27731385827064514
rl training, epoch4, iter0, batch214/1133, batch loss:0.27731385827064514, Training time:11928.887622594833
batch reward last col mean 0.09562895447015762 first col mean 0.11200769990682602 all mean 0.10331594944000244
0.3018449544906616 0.3018449544906616
rl training, epoch4, iter0, batch215/1133, batch loss:0.3018449544906616, Training time:11930.361466646194
batch reward last col mean 0.10154353082180023 first col mean 0.128768652677536 all mean 0.10655282437801361
0.28331899642944336 0.28331899642944336
rl training, epoch4, iter0, batch216/1133, batch loss:0.28331899642944336, Training time:11932.373759508133
batch reward last col mean 0.11890184134244919 first col mean 0.10428459942340851 all mean 0.11521995067596436
0.34007716178894043 0.34007716178894043
rl training, epoch4, iter0, batch217/1133, batch loss:0.34007716178894043, Training time:11934.069206237793
batch reward last col mean 0.0969836488366127 first col mean 0.11086922883987427 all mean 0.10480319708585739
0.342570960521698 0.342570960521698
rl training, epoch4, iter0, batch218/1133, batch loss:0.342570960521698, Training time:11936.062164068222
batch reward last col mean 0.0919070839881897 first col mean 0.10981869697570801 all mean 0.09580491483211517
0.2699912488460541 0.2699912488460541
rl training, epoch4, iter0, batch219/1133, batch loss:0.2699912488460541, Training time:11938.144237041473
batch reward last col mean 0.1320890486240387 first col mean 0.11952666938304901 all mean 0.11989792436361313
0.28906023502349854 0.28906023502349854
rl training, epoch4, iter0, batch220/1133, batch loss:0.28906023502349854, Training time:11939.64576792717
batch reward last col mean 0.10156631469726562 first col mean 0.11431188881397247 all mean 0.10307087004184723
0.31381863355636597 0.31381863355636597
rl training, epoch4, iter0, batch221/1133, batch loss:0.31381863355636597, Training time:11941.31853055954
batch reward last col mean 0.09195494651794434 first col mean 0.11055849492549896 all mean 0.10265782475471497
0.31628793478012085 0.31628793478012085
rl training, epoch4, iter0, batch222/1133, batch loss:0.31628793478012085, Training time:11943.333778142929
batch reward last col mean 0.0876677930355072 first col mean 0.11425162106752396 all mean 0.09060607105493546
0.2771935760974884 0.2771935760974884
rl training, epoch4, iter0, batch223/1133, batch loss:0.2771935760974884, Training time:11945.036580562592
batch reward last col mean 0.08691763877868652 first col mean 0.09473606944084167 all mean 0.08924011886119843
0.2604012191295624 0.2604012191295624
rl training, epoch4, iter0, batch224/1133, batch loss:0.2604012191295624, Training time:11946.94777059555
batch reward last col mean 0.1211111843585968 first col mean 0.1135234534740448 all mean 0.11843948811292648
0.31267693638801575 0.31267693638801575
rl training, epoch4, iter0, batch225/1133, batch loss:0.31267693638801575, Training time:11948.818720340729
batch reward last col mean 0.10213402658700943 first col mean 0.1060749962925911 all mean 0.1056426540017128
0.3024093210697174 0.302409291267395
rl training, epoch4, iter0, batch226/1133, batch loss:0.302409291267395, Training time:11950.697082281113
batch reward last col mean 0.09909358620643616 first col mean 0.11126917600631714 all mean 0.10612959414720535
0.3290446400642395 0.3290446400642395
rl training, epoch4, iter0, batch227/1133, batch loss:0.3290446400642395, Training time:11952.612629413605
batch reward last col mean 0.1112758070230484 first col mean 0.11233320832252502 all mean 0.10625894367694855
0.3207874596118927 0.3207874596118927
rl training, epoch4, iter0, batch228/1133, batch loss:0.3207874596118927, Training time:11954.187954187393
batch reward last col mean 0.1378227174282074 first col mean 0.11416313052177429 all mean 0.13035021722316742
0.34427404403686523 0.34427404403686523
rl training, epoch4, iter0, batch229/1133, batch loss:0.34427404403686523, Training time:11955.943553447723
batch reward last col mean 0.12404555082321167 first col mean 0.10716786980628967 all mean 0.12177210301160812
0.35308876633644104 0.35308876633644104
rl training, epoch4, iter0, batch230/1133, batch loss:0.35308876633644104, Training time:11958.047570466995
batch reward last col mean 0.09625346213579178 first col mean 0.12263794243335724 all mean 0.10802942514419556
0.3382534384727478 0.3382534086704254
rl training, epoch4, iter0, batch231/1133, batch loss:0.3382534086704254, Training time:11960.096488237381
batch reward last col mean 0.0865497887134552 first col mean 0.10926084220409393 all mean 0.09269503504037857
0.28305402398109436 0.28305402398109436
rl training, epoch4, iter0, batch232/1133, batch loss:0.28305402398109436, Training time:11961.98103427887
batch reward last col mean 0.11755966395139694 first col mean 0.11143805086612701 all mean 0.11586806178092957
0.34296324849128723 0.34296324849128723
rl training, epoch4, iter0, batch233/1133, batch loss:0.34296324849128723, Training time:11963.884903907776
batch reward last col mean 0.10786230862140656 first col mean 0.12365764379501343 all mean 0.10682515054941177
0.33440837264060974 0.33440837264060974
rl training, epoch4, iter0, batch234/1133, batch loss:0.33440837264060974, Training time:11965.715859174728
batch reward last col mean 0.13714472949504852 first col mean 0.10648142546415329 all mean 0.1281585544347763
0.3024786114692688 0.3024786114692688
rl training, epoch4, iter0, batch235/1133, batch loss:0.3024786114692688, Training time:11967.251625299454
batch reward last col mean 0.11048806458711624 first col mean 0.09592510759830475 all mean 0.11049482226371765
0.32026609778404236 0.32026609778404236
rl training, epoch4, iter0, batch236/1133, batch loss:0.32026609778404236, Training time:11969.080998659134
batch reward last col mean 0.14051133394241333 first col mean 0.0988595113158226 all mean 0.13439375162124634
0.32752546668052673 0.32752546668052673
rl training, epoch4, iter0, batch237/1133, batch loss:0.32752546668052673, Training time:11971.656095981598
batch reward last col mean 0.12720385193824768 first col mean 0.11420847475528717 all mean 0.12281563878059387
0.3555217981338501 0.3555217981338501
rl training, epoch4, iter0, batch238/1133, batch loss:0.3555217981338501, Training time:11973.118851661682
batch reward last col mean 0.10706096142530441 first col mean 0.10931907594203949 all mean 0.10629083216190338
0.32442107796669006 0.32442107796669006
rl training, epoch4, iter0, batch239/1133, batch loss:0.32442107796669006, Training time:11974.842388153076
batch reward last col mean 0.1046816036105156 first col mean 0.11340276896953583 all mean 0.10502675920724869
0.28727564215660095 0.28727564215660095
rl training, epoch4, iter0, batch240/1133, batch loss:0.28727564215660095, Training time:11976.370314121246
batch reward last col mean 0.0988566130399704 first col mean 0.12583796679973602 all mean 0.10736097395420074
0.3023204803466797 0.3023204803466797
rl training, epoch4, iter0, batch241/1133, batch loss:0.3023204803466797, Training time:11977.990255832672
batch reward last col mean 0.11042051762342453 first col mean 0.11015784740447998 all mean 0.10697396844625473
0.26627030968666077 0.26627030968666077
rl training, epoch4, iter0, batch242/1133, batch loss:0.26627030968666077, Training time:11979.783733606339
batch reward last col mean 0.12809954583644867 first col mean 0.11617778241634369 all mean 0.12145674228668213
0.37731823325157166 0.37731823325157166
rl training, epoch4, iter0, batch243/1133, batch loss:0.37731823325157166, Training time:11981.2235455513
batch reward last col mean 0.12258264422416687 first col mean 0.12671130895614624 all mean 0.12238001823425293
0.33120977878570557 0.33120977878570557
rl training, epoch4, iter0, batch244/1133, batch loss:0.33120977878570557, Training time:11983.503499269485
batch reward last col mean 0.10531632602214813 first col mean 0.099488765001297 all mean 0.10585574060678482
0.3083602786064148 0.3083602488040924
rl training, epoch4, iter0, batch245/1133, batch loss:0.3083602488040924, Training time:11985.574477910995
batch reward last col mean 0.11335024982690811 first col mean 0.11219080537557602 all mean 0.1159597784280777
0.36229175329208374 0.36229175329208374
rl training, epoch4, iter0, batch246/1133, batch loss:0.36229175329208374, Training time:11987.145476341248
batch reward last col mean 0.12142302095890045 first col mean 0.1201513484120369 all mean 0.12153750658035278
0.34272509813308716 0.34272509813308716
rl training, epoch4, iter0, batch247/1133, batch loss:0.34272509813308716, Training time:11989.024491786957
batch reward last col mean 0.13213631510734558 first col mean 0.10904621332883835 all mean 0.12176327407360077
0.321117639541626 0.321117639541626
rl training, epoch4, iter0, batch248/1133, batch loss:0.321117639541626, Training time:11990.600244283676
batch reward last col mean 0.09752552211284637 first col mean 0.12579403817653656 all mean 0.10504899173974991
0.29921436309814453 0.29921436309814453
rl training, epoch4, iter0, batch249/1133, batch loss:0.29921436309814453, Training time:11992.604403972626
batch reward last col mean 0.10259205847978592 first col mean 0.11900152266025543 all mean 0.1039428636431694
0.3132621645927429 0.3132621645927429
rl training, epoch4, iter0, batch250/1133, batch loss:0.3132621645927429, Training time:11994.532651901245
batch reward last col mean 0.09706699848175049 first col mean 0.12494028359651566 all mean 0.10350672155618668
0.3076757490634918 0.3076757490634918
rl training, epoch4, iter0, batch251/1133, batch loss:0.3076757490634918, Training time:11996.327344179153
batch reward last col mean 0.12420684099197388 first col mean 0.10147935152053833 all mean 0.12329209595918655
0.3307834267616272 0.3307834267616272
rl training, epoch4, iter0, batch252/1133, batch loss:0.3307834267616272, Training time:11997.987812519073
batch reward last col mean 0.13313600420951843 first col mean 0.1160820797085762 all mean 0.12899918854236603
0.35474827885627747 0.35474827885627747
rl training, epoch4, iter0, batch253/1133, batch loss:0.35474827885627747, Training time:11999.703986406326
batch reward last col mean 0.11180105805397034 first col mean 0.11413657665252686 all mean 0.11432629823684692
0.32453233003616333 0.32453233003616333
rl training, epoch4, iter0, batch254/1133, batch loss:0.32453233003616333, Training time:12002.84958934784
batch reward last col mean 0.09619435667991638 first col mean 0.1213710680603981 all mean 0.10146588832139969
0.2828108072280884 0.2828108072280884
rl training, epoch4, iter0, batch255/1133, batch loss:0.2828108072280884, Training time:12004.386749982834
batch reward last col mean 0.09515268355607986 first col mean 0.11706095933914185 all mean 0.1016451045870781
0.30792203545570374 0.30792203545570374
rl training, epoch4, iter0, batch256/1133, batch loss:0.30792203545570374, Training time:12006.105807065964
batch reward last col mean 0.1112084835767746 first col mean 0.11732544004917145 all mean 0.1151266098022461
0.33069485425949097 0.33069485425949097
rl training, epoch4, iter0, batch257/1133, batch loss:0.33069485425949097, Training time:12007.919828414917
batch reward last col mean 0.11459420621395111 first col mean 0.10830370336771011 all mean 0.11426172405481339
0.30979523062705994 0.30979523062705994
rl training, epoch4, iter0, batch258/1133, batch loss:0.30979523062705994, Training time:12009.791527032852
batch reward last col mean 0.13027265667915344 first col mean 0.12261614203453064 all mean 0.12771353125572205
0.3422427773475647 0.3422427773475647
rl training, epoch4, iter0, batch259/1133, batch loss:0.3422427773475647, Training time:12012.0509557724
batch reward last col mean 0.09027578681707382 first col mean 0.14099183678627014 all mean 0.1007998138666153
0.3048916161060333 0.3048916161060333
rl training, epoch4, iter0, batch260/1133, batch loss:0.3048916161060333, Training time:12013.359367609024
batch reward last col mean 0.10613469034433365 first col mean 0.10903221368789673 all mean 0.11379209905862808
0.31918543577194214 0.31918543577194214
rl training, epoch4, iter0, batch261/1133, batch loss:0.31918543577194214, Training time:12015.06394314766
batch reward last col mean 0.12906888127326965 first col mean 0.1182192787528038 all mean 0.12164568901062012
0.31138187646865845 0.31138187646865845
rl training, epoch4, iter0, batch262/1133, batch loss:0.31138187646865845, Training time:12016.911339998245
batch reward last col mean 0.12367464601993561 first col mean 0.11753447353839874 all mean 0.12040529400110245
0.32478490471839905 0.32478490471839905
rl training, epoch4, iter0, batch263/1133, batch loss:0.32478490471839905, Training time:12018.596680164337
batch reward last col mean 0.13422247767448425 first col mean 0.12517407536506653 all mean 0.13820892572402954
0.3706439435482025 0.3706439435482025
rl training, epoch4, iter0, batch264/1133, batch loss:0.3706439435482025, Training time:12020.391652107239
batch reward last col mean 0.1448000967502594 first col mean 0.11181920766830444 all mean 0.13483497500419617
0.32958412170410156 0.32958412170410156
rl training, epoch4, iter0, batch265/1133, batch loss:0.32958412170410156, Training time:12022.168337583542
batch reward last col mean 0.12328598648309708 first col mean 0.12180034816265106 all mean 0.12187229841947556
0.33770978450775146 0.33770978450775146
rl training, epoch4, iter0, batch266/1133, batch loss:0.33770978450775146, Training time:12024.343785762787
batch reward last col mean 0.0963936448097229 first col mean 0.1267472207546234 all mean 0.10610296577215195
0.30986902117729187 0.3098689913749695
rl training, epoch4, iter0, batch267/1133, batch loss:0.3098689913749695, Training time:12026.248853683472
batch reward last col mean 0.11659356206655502 first col mean 0.11835756152868271 all mean 0.11592353880405426
0.31369566917419434 0.31369566917419434
rl training, epoch4, iter0, batch268/1133, batch loss:0.31369566917419434, Training time:12028.010432958603
batch reward last col mean 0.12084683030843735 first col mean 0.12153825908899307 all mean 0.12177837640047073
0.35354578495025635 0.35354578495025635
rl training, epoch4, iter0, batch269/1133, batch loss:0.35354578495025635, Training time:12030.161283493042
batch reward last col mean 0.12098854035139084 first col mean 0.11472280323505402 all mean 0.11692452430725098
0.32085177302360535 0.32085174322128296
rl training, epoch4, iter0, batch270/1133, batch loss:0.32085174322128296, Training time:12031.904695987701
batch reward last col mean 0.09375335276126862 first col mean 0.12499509751796722 all mean 0.0978873074054718
0.3092588782310486 0.30925890803337097
rl training, epoch4, iter0, batch271/1133, batch loss:0.30925890803337097, Training time:12033.45109295845
batch reward last col mean 0.08451676368713379 first col mean 0.10182704031467438 all mean 0.09070440381765366
0.29591405391693115 0.29591405391693115
rl training, epoch4, iter0, batch272/1133, batch loss:0.29591405391693115, Training time:12035.599680900574
batch reward last col mean 0.09129323810338974 first col mean 0.11618492007255554 all mean 0.09791561216115952
0.3054446280002594 0.3054446280002594
rl training, epoch4, iter0, batch273/1133, batch loss:0.3054446280002594, Training time:12037.46261882782
batch reward last col mean 0.13753147423267365 first col mean 0.11112499237060547 all mean 0.1377466768026352
0.3340737819671631 0.3340737819671631
rl training, epoch4, iter0, batch274/1133, batch loss:0.3340737819671631, Training time:12039.285531520844
batch reward last col mean 0.08632422238588333 first col mean 0.11444556713104248 all mean 0.08770174533128738
0.3029173016548157 0.3029172718524933
rl training, epoch4, iter0, batch275/1133, batch loss:0.3029172718524933, Training time:12041.308800935745
batch reward last col mean 0.0920332744717598 first col mean 0.12719160318374634 all mean 0.10019794851541519
0.33193811774253845 0.33193811774253845
rl training, epoch4, iter0, batch276/1133, batch loss:0.33193811774253845, Training time:12042.957818508148
batch reward last col mean 0.12161500751972198 first col mean 0.1300051212310791 all mean 0.11920168995857239
0.3435198962688446 0.3435198962688446
rl training, epoch4, iter0, batch277/1133, batch loss:0.3435198962688446, Training time:12045.080208301544
batch reward last col mean 0.09224840998649597 first col mean 0.12956278026103973 all mean 0.09797924011945724
0.3154833912849426 0.3154833912849426
rl training, epoch4, iter0, batch278/1133, batch loss:0.3154833912849426, Training time:12047.147123336792
batch reward last col mean 0.11663687974214554 first col mean 0.09252697229385376 all mean 0.10820925980806351
0.3031275272369385 0.3031275272369385
rl training, epoch4, iter0, batch279/1133, batch loss:0.3031275272369385, Training time:12049.100877046585
batch reward last col mean 0.09562362730503082 first col mean 0.11750002205371857 all mean 0.10162821412086487
0.31920096278190613 0.31920096278190613
rl training, epoch4, iter0, batch280/1133, batch loss:0.31920096278190613, Training time:12051.193877458572
batch reward last col mean 0.0878487154841423 first col mean 0.12198386341333389 all mean 0.09461767226457596
0.3181692063808441 0.3181692063808441
rl training, epoch4, iter0, batch281/1133, batch loss:0.3181692063808441, Training time:12054.168066263199
batch reward last col mean 0.11179342865943909 first col mean 0.125116229057312 all mean 0.11977999657392502
0.34580132365226746 0.34580132365226746
rl training, epoch4, iter0, batch282/1133, batch loss:0.34580132365226746, Training time:12055.903814792633
batch reward last col mean 0.11680178344249725 first col mean 0.11995804309844971 all mean 0.11795345693826675
0.319620281457901 0.319620281457901
rl training, epoch4, iter0, batch283/1133, batch loss:0.319620281457901, Training time:12057.83889746666
batch reward last col mean 0.11893892288208008 first col mean 0.11326505243778229 all mean 0.11904767900705338
0.32781916856765747 0.3278191387653351
rl training, epoch4, iter0, batch284/1133, batch loss:0.3278191387653351, Training time:12060.353818178177
batch reward last col mean 0.10292276740074158 first col mean 0.10773216933012009 all mean 0.10965895652770996
0.3027257025241852 0.3027257025241852
rl training, epoch4, iter0, batch285/1133, batch loss:0.3027257025241852, Training time:12062.9241604805
batch reward last col mean 0.11939719319343567 first col mean 0.10827644169330597 all mean 0.12067975103855133
0.37157484889030457 0.37157484889030457
rl training, epoch4, iter0, batch286/1133, batch loss:0.37157484889030457, Training time:12064.575481891632
batch reward last col mean 0.08288374543190002 first col mean 0.1064407080411911 all mean 0.09509334713220596
0.2878120541572571 0.28781208395957947
rl training, epoch4, iter0, batch287/1133, batch loss:0.28781208395957947, Training time:12066.229550361633
batch reward last col mean 0.11376631259918213 first col mean 0.10609838366508484 all mean 0.11258445680141449
0.3417637050151825 0.3417637050151825
rl training, epoch4, iter0, batch288/1133, batch loss:0.3417637050151825, Training time:12068.466211795807
batch reward last col mean 0.0893140584230423 first col mean 0.11797337979078293 all mean 0.0938270092010498
0.2886834442615509 0.2886834442615509
rl training, epoch4, iter0, batch289/1133, batch loss:0.2886834442615509, Training time:12070.908568620682
batch reward last col mean 0.0694352388381958 first col mean 0.13611389696598053 all mean 0.08668241649866104
0.3024894893169403 0.3024894893169403
rl training, epoch4, iter0, batch290/1133, batch loss:0.3024894893169403, Training time:12072.393161058426
batch reward last col mean 0.15256012976169586 first col mean 0.11446697264909744 all mean 0.14044275879859924
0.39629319310188293 0.39629319310188293
rl training, epoch4, iter0, batch291/1133, batch loss:0.39629319310188293, Training time:12074.649206876755
batch reward last col mean 0.07694646716117859 first col mean 0.11898870021104813 all mean 0.09332884848117828
0.311359167098999 0.311359167098999
rl training, epoch4, iter0, batch292/1133, batch loss:0.311359167098999, Training time:12076.237199544907
batch reward last col mean 0.14941120147705078 first col mean 0.11138904094696045 all mean 0.14343735575675964
0.39384925365448 0.3938492238521576
rl training, epoch4, iter0, batch293/1133, batch loss:0.3938492238521576, Training time:12078.106533765793
batch reward last col mean 0.12321074306964874 first col mean 0.10209105163812637 all mean 0.12486881017684937
0.3290812075138092 0.3290811777114868
rl training, epoch4, iter0, batch294/1133, batch loss:0.3290811777114868, Training time:12081.080362081528
batch reward last col mean 0.08820725977420807 first col mean 0.11180128902196884 all mean 0.09279496967792511
0.28297004103660583 0.28297004103660583
rl training, epoch4, iter0, batch295/1133, batch loss:0.28297004103660583, Training time:12082.707398176193
batch reward last col mean 0.07872848212718964 first col mean 0.1220354437828064 all mean 0.08794982731342316
0.2903904318809509 0.2903904318809509
rl training, epoch4, iter0, batch296/1133, batch loss:0.2903904318809509, Training time:12084.349978208542
batch reward last col mean 0.12064681202173233 first col mean 0.12128333002328873 all mean 0.11999395489692688
0.2925140857696533 0.2925140857696533
rl training, epoch4, iter0, batch297/1133, batch loss:0.2925140857696533, Training time:12085.996329545975
batch reward last col mean 0.12668414413928986 first col mean 0.10059773921966553 all mean 0.12269417941570282
0.31109321117401123 0.31109321117401123
rl training, epoch4, iter0, batch298/1133, batch loss:0.31109321117401123, Training time:12089.246460199356
batch reward last col mean 0.1465219110250473 first col mean 0.10596352815628052 all mean 0.13840092718601227
0.37175190448760986 0.37175190448760986
rl training, epoch4, iter0, batch299/1133, batch loss:0.37175190448760986, Training time:12091.119001626968
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.519681981703084 Time: 97.08146929740906 s
loss of true 0.22619441978876714 loss of gen 0.18675778399156662 loss of other 0.10672977845211631 first score 0.1278502643108368
batch reward last col mean 0.07465767115354538 first col mean 0.10041291266679764 all mean 0.08530318737030029
0.23999200761318207 0.23999200761318207
rl training, epoch4, iter0, batch300/1133, batch loss:0.23999200761318207, Training time:12189.842258691788
batch reward last col mean 0.12215294688940048 first col mean 0.11072517931461334 all mean 0.11651292443275452
0.31885838508605957 0.31885838508605957
rl training, epoch4, iter0, batch301/1133, batch loss:0.31885838508605957, Training time:12191.616642475128
batch reward last col mean 0.11215632408857346 first col mean 0.1116739809513092 all mean 0.1026030108332634
0.2857058048248291 0.2857058346271515
rl training, epoch4, iter0, batch302/1133, batch loss:0.2857058346271515, Training time:12193.438572645187
batch reward last col mean 0.08888794481754303 first col mean 0.12251915037631989 all mean 0.0950770229101181
0.3113407492637634 0.3113407492637634
rl training, epoch4, iter0, batch303/1133, batch loss:0.3113407492637634, Training time:12195.424376249313
batch reward last col mean 0.10020223259925842 first col mean 0.12101615965366364 all mean 0.10720083862543106
0.29015663266181946 0.29015663266181946
rl training, epoch4, iter0, batch304/1133, batch loss:0.29015663266181946, Training time:12197.116785287857
batch reward last col mean 0.08891595155000687 first col mean 0.11438821256160736 all mean 0.09529479593038559
0.28178367018699646 0.28178367018699646
rl training, epoch4, iter0, batch305/1133, batch loss:0.28178367018699646, Training time:12198.979060649872
batch reward last col mean 0.07875078171491623 first col mean 0.11602999269962311 all mean 0.08970967680215836
0.2809503972530365 0.2809503972530365
rl training, epoch4, iter0, batch306/1133, batch loss:0.2809503972530365, Training time:12200.76936173439
batch reward last col mean 0.09615559875965118 first col mean 0.10165373235940933 all mean 0.10329772531986237
0.33530157804489136 0.33530154824256897
rl training, epoch4, iter0, batch307/1133, batch loss:0.33530154824256897, Training time:12203.230262517929
batch reward last col mean 0.09614686667919159 first col mean 0.11367052048444748 all mean 0.09953392297029495
0.29504796862602234 0.29504796862602234
rl training, epoch4, iter0, batch308/1133, batch loss:0.29504796862602234, Training time:12205.009106397629
batch reward last col mean 0.11720946431159973 first col mean 0.1298176348209381 all mean 0.11745398491621017
0.332802414894104 0.332802414894104
rl training, epoch4, iter0, batch309/1133, batch loss:0.332802414894104, Training time:12206.800367355347
batch reward last col mean 0.12665703892707825 first col mean 0.10859126597642899 all mean 0.1283833533525467
0.35131675004959106 0.35131675004959106
rl training, epoch4, iter0, batch310/1133, batch loss:0.35131675004959106, Training time:12209.129440307617
batch reward last col mean 0.13201403617858887 first col mean 0.09309743344783783 all mean 0.126960888504982
0.36847811937332153 0.36847811937332153
rl training, epoch4, iter0, batch311/1133, batch loss:0.36847811937332153, Training time:12210.800986528397
batch reward last col mean 0.07119704782962799 first col mean 0.12292592227458954 all mean 0.08304151892662048
0.28308188915252686 0.28308185935020447
rl training, epoch4, iter0, batch312/1133, batch loss:0.28308185935020447, Training time:12212.797083377838
batch reward last col mean 0.1061621904373169 first col mean 0.10062247514724731 all mean 0.10883791744709015
0.25826042890548706 0.25826042890548706
rl training, epoch4, iter0, batch313/1133, batch loss:0.25826042890548706, Training time:12214.740307331085
batch reward last col mean 0.11893518269062042 first col mean 0.1101071834564209 all mean 0.11938448250293732
0.3159528076648712 0.3159528374671936
rl training, epoch4, iter0, batch314/1133, batch loss:0.3159528374671936, Training time:12216.719789028168
batch reward last col mean 0.10528647899627686 first col mean 0.11326388269662857 all mean 0.10489702969789505
0.32992011308670044 0.32992011308670044
rl training, epoch4, iter0, batch315/1133, batch loss:0.32992011308670044, Training time:12218.57067656517
batch reward last col mean 0.1410188227891922 first col mean 0.10634419322013855 all mean 0.13102936744689941
0.3801012635231018 0.3801013231277466
rl training, epoch4, iter0, batch316/1133, batch loss:0.3801013231277466, Training time:12220.407728910446
batch reward last col mean 0.09735776484012604 first col mean 0.0910128653049469 all mean 0.10197930783033371
0.3046763241291046 0.304676353931427
rl training, epoch4, iter0, batch317/1133, batch loss:0.304676353931427, Training time:12222.539284944534
batch reward last col mean 0.08571799099445343 first col mean 0.12877792119979858 all mean 0.09408868849277496
0.3055110275745392 0.3055110275745392
rl training, epoch4, iter0, batch318/1133, batch loss:0.3055110275745392, Training time:12224.778668403625
batch reward last col mean 0.12447322905063629 first col mean 0.11618831753730774 all mean 0.12506020069122314
0.3360104560852051 0.3360104560852051
rl training, epoch4, iter0, batch319/1133, batch loss:0.3360104560852051, Training time:12227.075617313385
batch reward last col mean 0.14105436205863953 first col mean 0.12199722975492477 all mean 0.13501717150211334
0.34486326575279236 0.34486323595046997
rl training, epoch4, iter0, batch320/1133, batch loss:0.34486323595046997, Training time:12229.030886888504
batch reward last col mean 0.0785871297121048 first col mean 0.11495201289653778 all mean 0.08649315685033798
0.30414336919784546 0.30414336919784546
rl training, epoch4, iter0, batch321/1133, batch loss:0.30414336919784546, Training time:12231.71822476387
batch reward last col mean 0.13797982037067413 first col mean 0.11575853824615479 all mean 0.12812091410160065
0.31414496898651123 0.3141449987888336
rl training, epoch4, iter0, batch322/1133, batch loss:0.3141449987888336, Training time:12233.635041475296
batch reward last col mean 0.10817817598581314 first col mean 0.10974860191345215 all mean 0.10621138662099838
0.2874957323074341 0.2874957323074341
rl training, epoch4, iter0, batch323/1133, batch loss:0.2874957323074341, Training time:12236.76832151413
batch reward last col mean 0.1299271285533905 first col mean 0.12762011587619781 all mean 0.12813115119934082
0.37356847524642944 0.37356847524642944
rl training, epoch4, iter0, batch324/1133, batch loss:0.37356847524642944, Training time:12238.714256048203
batch reward last col mean 0.10722129046916962 first col mean 0.10693930834531784 all mean 0.10953542590141296
0.31624090671539307 0.31624090671539307
rl training, epoch4, iter0, batch325/1133, batch loss:0.31624090671539307, Training time:12242.457611560822
batch reward last col mean 0.11082285642623901 first col mean 0.10104946792125702 all mean 0.10986071825027466
0.3264752924442291 0.3264752924442291
rl training, epoch4, iter0, batch326/1133, batch loss:0.3264752924442291, Training time:12244.237138032913
batch reward last col mean 0.09917794167995453 first col mean 0.11236805468797684 all mean 0.10253363847732544
0.3057018518447876 0.3057018518447876
rl training, epoch4, iter0, batch327/1133, batch loss:0.3057018518447876, Training time:12246.701891183853
batch reward last col mean 0.08142074942588806 first col mean 0.10581716895103455 all mean 0.08869288116693497
0.284437358379364 0.284437358379364
rl training, epoch4, iter0, batch328/1133, batch loss:0.284437358379364, Training time:12249.661886692047
batch reward last col mean 0.10509733110666275 first col mean 0.1144217699766159 all mean 0.10123586654663086
0.33288124203681946 0.33288127183914185
rl training, epoch4, iter0, batch329/1133, batch loss:0.33288127183914185, Training time:12251.946484327316
batch reward last col mean 0.10460933297872543 first col mean 0.1263958364725113 all mean 0.1118960976600647
0.3576638400554657 0.3576638400554657
rl training, epoch4, iter0, batch330/1133, batch loss:0.3576638400554657, Training time:12254.253490924835
batch reward last col mean 0.06496337056159973 first col mean 0.13771562278270721 all mean 0.08677088469266891
0.3173813819885254 0.3173813819885254
rl training, epoch4, iter0, batch331/1133, batch loss:0.3173813819885254, Training time:12256.436363697052
batch reward last col mean 0.08951938897371292 first col mean 0.11493346095085144 all mean 0.09498931467533112
0.2633659243583679 0.2633659243583679
rl training, epoch4, iter0, batch332/1133, batch loss:0.2633659243583679, Training time:12258.30130982399
batch reward last col mean 0.1295713186264038 first col mean 0.12766723334789276 all mean 0.12468266487121582
0.3546493351459503 0.3546493351459503
rl training, epoch4, iter0, batch333/1133, batch loss:0.3546493351459503, Training time:12260.511102676392
batch reward last col mean 0.09918853640556335 first col mean 0.10057671368122101 all mean 0.10610709339380264
0.3478466272354126 0.3478466272354126
rl training, epoch4, iter0, batch334/1133, batch loss:0.3478466272354126, Training time:12262.800026416779
batch reward last col mean 0.09456576406955719 first col mean 0.1172756478190422 all mean 0.09776944667100906
0.27759966254234314 0.27759966254234314
rl training, epoch4, iter0, batch335/1133, batch loss:0.27759966254234314, Training time:12265.399049758911
batch reward last col mean 0.08921729028224945 first col mean 0.11229225993156433 all mean 0.09126731753349304
0.26891323924064636 0.26891323924064636
rl training, epoch4, iter0, batch336/1133, batch loss:0.26891323924064636, Training time:12267.387097120285
batch reward last col mean 0.12354191392660141 first col mean 0.11018714308738708 all mean 0.11887361109256744
0.3126673996448517 0.3126673996448517
rl training, epoch4, iter0, batch337/1133, batch loss:0.3126673996448517, Training time:12269.853093624115
batch reward last col mean 0.13216255605220795 first col mean 0.12830810248851776 all mean 0.12290409952402115
0.34509432315826416 0.34509435296058655
rl training, epoch4, iter0, batch338/1133, batch loss:0.34509435296058655, Training time:12271.908376455307
batch reward last col mean 0.09994934499263763 first col mean 0.1184028685092926 all mean 0.10542027652263641
0.3231211304664612 0.3231211304664612
rl training, epoch4, iter0, batch339/1133, batch loss:0.3231211304664612, Training time:12273.904082536697
batch reward last col mean 0.12497436255216599 first col mean 0.11143430322408676 all mean 0.12159762531518936
0.3258835971355438 0.3258835971355438
rl training, epoch4, iter0, batch340/1133, batch loss:0.3258835971355438, Training time:12275.937830924988
batch reward last col mean 0.0856417790055275 first col mean 0.11363239586353302 all mean 0.09712471067905426
0.32797086238861084 0.32797080278396606
rl training, epoch4, iter0, batch341/1133, batch loss:0.32797080278396606, Training time:12278.021428585052
batch reward last col mean 0.10800747573375702 first col mean 0.11265216022729874 all mean 0.11299725621938705
0.3168843686580658 0.3168843686580658
rl training, epoch4, iter0, batch342/1133, batch loss:0.3168843686580658, Training time:12280.468911886215
batch reward last col mean 0.10127343237400055 first col mean 0.10408075153827667 all mean 0.10481160879135132
0.31563878059387207 0.31563878059387207
rl training, epoch4, iter0, batch343/1133, batch loss:0.31563878059387207, Training time:12284.195688009262
batch reward last col mean 0.09145054221153259 first col mean 0.10125397145748138 all mean 0.09978310018777847
0.2760559618473053 0.2760559320449829
rl training, epoch4, iter0, batch344/1133, batch loss:0.2760559320449829, Training time:12286.175296783447
batch reward last col mean 0.08726904541254044 first col mean 0.10987110435962677 all mean 0.09236766397953033
0.2697173058986664 0.2697173058986664
rl training, epoch4, iter0, batch345/1133, batch loss:0.2697173058986664, Training time:12288.392940759659
batch reward last col mean 0.13617052137851715 first col mean 0.11795599013566971 all mean 0.13288134336471558
0.32729849219322205 0.32729849219322205
rl training, epoch4, iter0, batch346/1133, batch loss:0.32729849219322205, Training time:12290.348381757736
batch reward last col mean 0.11644411087036133 first col mean 0.1304842084646225 all mean 0.1210172176361084
0.32195064425468445 0.32195064425468445
rl training, epoch4, iter0, batch347/1133, batch loss:0.32195064425468445, Training time:12292.293105840683
batch reward last col mean 0.09722200036048889 first col mean 0.11690182983875275 all mean 0.10566585510969162
0.3356216251850128 0.3356216251850128
rl training, epoch4, iter0, batch348/1133, batch loss:0.3356216251850128, Training time:12294.316910266876
batch reward last col mean 0.11803461611270905 first col mean 0.12271882593631744 all mean 0.11954095214605331
0.3336632549762726 0.3336632549762726
rl training, epoch4, iter0, batch349/1133, batch loss:0.3336632549762726, Training time:12296.236095190048
batch reward last col mean 0.0849744975566864 first col mean 0.13281099498271942 all mean 0.091731496155262
0.27780982851982117 0.27780982851982117
rl training, epoch4, iter0, batch350/1133, batch loss:0.27780982851982117, Training time:12298.809243917465
batch reward last col mean 0.13259784877300262 first col mean 0.11168993264436722 all mean 0.12543585896492004
0.32301387190818787 0.32301387190818787
rl training, epoch4, iter0, batch351/1133, batch loss:0.32301387190818787, Training time:12301.150574684143
batch reward last col mean 0.07301213592290878 first col mean 0.1050652489066124 all mean 0.08092528581619263
0.2882695496082306 0.2882695496082306
rl training, epoch4, iter0, batch352/1133, batch loss:0.2882695496082306, Training time:12303.743454694748
batch reward last col mean 0.11940136551856995 first col mean 0.10718899965286255 all mean 0.11564361304044724
0.31597551703453064 0.31597551703453064
rl training, epoch4, iter0, batch353/1133, batch loss:0.31597551703453064, Training time:12306.533745527267
batch reward last col mean 0.1005501076579094 first col mean 0.11739525198936462 all mean 0.10279902070760727
0.3018036186695099 0.3018036186695099
rl training, epoch4, iter0, batch354/1133, batch loss:0.3018036186695099, Training time:12309.230003118515
batch reward last col mean 0.11132866144180298 first col mean 0.13023123145103455 all mean 0.11159315705299377
0.32458561658859253 0.32458561658859253
rl training, epoch4, iter0, batch355/1133, batch loss:0.32458561658859253, Training time:12311.531243085861
batch reward last col mean 0.1308588981628418 first col mean 0.10707356035709381 all mean 0.12520386278629303
0.33678528666496277 0.33678528666496277
rl training, epoch4, iter0, batch356/1133, batch loss:0.33678528666496277, Training time:12313.505727529526
batch reward last col mean 0.12982961535453796 first col mean 0.11994624137878418 all mean 0.12777233123779297
0.36053577065467834 0.36053577065467834
rl training, epoch4, iter0, batch357/1133, batch loss:0.36053577065467834, Training time:12316.25201845169
batch reward last col mean 0.08643046021461487 first col mean 0.11908061802387238 all mean 0.09696787595748901
0.30376389622688293 0.30376389622688293
rl training, epoch4, iter0, batch358/1133, batch loss:0.30376389622688293, Training time:12318.432715177536
batch reward last col mean 0.09905935823917389 first col mean 0.10223472118377686 all mean 0.09805522114038467
0.30417925119400024 0.30417925119400024
rl training, epoch4, iter0, batch359/1133, batch loss:0.30417925119400024, Training time:12320.900659322739
batch reward last col mean 0.08753690123558044 first col mean 0.14596940577030182 all mean 0.09589595347642899
0.29386457800865173 0.29386457800865173
rl training, epoch4, iter0, batch360/1133, batch loss:0.29386457800865173, Training time:12323.179854869843
batch reward last col mean 0.12433373928070068 first col mean 0.12804949283599854 all mean 0.12581996619701385
0.3170447051525116 0.3170447051525116
rl training, epoch4, iter0, batch361/1133, batch loss:0.3170447051525116, Training time:12325.239065170288
batch reward last col mean 0.11579205840826035 first col mean 0.1104661375284195 all mean 0.11570347845554352
0.29255324602127075 0.29255324602127075
rl training, epoch4, iter0, batch362/1133, batch loss:0.29255324602127075, Training time:12327.742930650711
batch reward last col mean 0.09986589848995209 first col mean 0.09621352702379227 all mean 0.09919781237840652
0.32543525099754333 0.32543525099754333
rl training, epoch4, iter0, batch363/1133, batch loss:0.32543525099754333, Training time:12329.885643482208
batch reward last col mean 0.09355208277702332 first col mean 0.1027870625257492 all mean 0.09863168746232986
0.3310316801071167 0.3310316801071167
rl training, epoch4, iter0, batch364/1133, batch loss:0.3310316801071167, Training time:12332.297833442688
batch reward last col mean 0.13128365576267242 first col mean 0.1133301854133606 all mean 0.12939870357513428
0.34278857707977295 0.34278857707977295
rl training, epoch4, iter0, batch365/1133, batch loss:0.34278857707977295, Training time:12334.66976928711
batch reward last col mean 0.09892866760492325 first col mean 0.11610560119152069 all mean 0.10467822849750519
0.2971206307411194 0.2971206307411194
rl training, epoch4, iter0, batch366/1133, batch loss:0.2971206307411194, Training time:12337.052406549454
batch reward last col mean 0.11449766159057617 first col mean 0.10586623847484589 all mean 0.11394240707159042
0.30633842945098877 0.30633842945098877
rl training, epoch4, iter0, batch367/1133, batch loss:0.30633842945098877, Training time:12339.323320627213
batch reward last col mean 0.10855761170387268 first col mean 0.13074305653572083 all mean 0.10897704213857651
0.305163711309433 0.305163711309433
rl training, epoch4, iter0, batch368/1133, batch loss:0.305163711309433, Training time:12342.359491586685
batch reward last col mean 0.09641896188259125 first col mean 0.10688558965921402 all mean 0.10390177369117737
0.2654836177825928 0.2654836177825928
rl training, epoch4, iter0, batch369/1133, batch loss:0.2654836177825928, Training time:12344.492581367493
batch reward last col mean 0.09988108277320862 first col mean 0.09160614758729935 all mean 0.10682834684848785
0.28661587834358215 0.28661584854125977
rl training, epoch4, iter0, batch370/1133, batch loss:0.28661584854125977, Training time:12346.708161592484
batch reward last col mean 0.10280509293079376 first col mean 0.09931079298257828 all mean 0.10582654923200607
0.28308960795402527 0.28308960795402527
rl training, epoch4, iter0, batch371/1133, batch loss:0.28308960795402527, Training time:12348.59700012207
batch reward last col mean 0.11419498920440674 first col mean 0.1224505752325058 all mean 0.10945479571819305
0.3563210964202881 0.3563210964202881
rl training, epoch4, iter0, batch372/1133, batch loss:0.3563210964202881, Training time:12350.751278162003
batch reward last col mean 0.15545979142189026 first col mean 0.1144062951207161 all mean 0.15156732499599457
0.40238678455352783 0.40238678455352783
rl training, epoch4, iter0, batch373/1133, batch loss:0.40238678455352783, Training time:12353.32847905159
batch reward last col mean 0.13284693658351898 first col mean 0.11595777422189713 all mean 0.12643033266067505
0.3058891296386719 0.3058891296386719
rl training, epoch4, iter0, batch374/1133, batch loss:0.3058891296386719, Training time:12355.479327917099
batch reward last col mean 0.0890333503484726 first col mean 0.11603347957134247 all mean 0.0928683876991272
0.32124781608581543 0.32124781608581543
rl training, epoch4, iter0, batch375/1133, batch loss:0.32124781608581543, Training time:12357.677813768387
batch reward last col mean 0.11513852328062057 first col mean 0.1351431906223297 all mean 0.11648181080818176
0.35513314604759216 0.35513314604759216
rl training, epoch4, iter0, batch376/1133, batch loss:0.35513314604759216, Training time:12359.851814508438
batch reward last col mean 0.11718367040157318 first col mean 0.13685163855552673 all mean 0.11974537372589111
0.3393959403038025 0.3393959403038025
rl training, epoch4, iter0, batch377/1133, batch loss:0.3393959403038025, Training time:12361.92077422142
batch reward last col mean 0.08706288039684296 first col mean 0.11600743234157562 all mean 0.09276719391345978
0.2998881936073303 0.2998881936073303
rl training, epoch4, iter0, batch378/1133, batch loss:0.2998881936073303, Training time:12364.388163805008
batch reward last col mean 0.10005030781030655 first col mean 0.13288964331150055 all mean 0.10522002726793289
0.3116143047809601 0.3116142749786377
rl training, epoch4, iter0, batch379/1133, batch loss:0.3116142749786377, Training time:12367.296292066574
batch reward last col mean 0.10335837304592133 first col mean 0.1236644834280014 all mean 0.11545028537511826
0.37151873111724854 0.37151873111724854
rl training, epoch4, iter0, batch380/1133, batch loss:0.37151873111724854, Training time:12369.72148180008
batch reward last col mean 0.1278984397649765 first col mean 0.1299290657043457 all mean 0.12440251559019089
0.3546294569969177 0.35462942719459534
rl training, epoch4, iter0, batch381/1133, batch loss:0.35462942719459534, Training time:12371.820692777634
batch reward last col mean 0.0944025069475174 first col mean 0.13226228952407837 all mean 0.1072005182504654
0.3299925923347473 0.3299925923347473
rl training, epoch4, iter0, batch382/1133, batch loss:0.3299925923347473, Training time:12374.293637514114
batch reward last col mean 0.1039431095123291 first col mean 0.13068178296089172 all mean 0.10963289439678192
0.3498938977718353 0.3498938977718353
rl training, epoch4, iter0, batch383/1133, batch loss:0.3498938977718353, Training time:12376.654437065125
batch reward last col mean 0.13692614436149597 first col mean 0.1174691766500473 all mean 0.12954537570476532
0.3469913601875305 0.3469913601875305
rl training, epoch4, iter0, batch384/1133, batch loss:0.3469913601875305, Training time:12378.869515180588
batch reward last col mean 0.08651718497276306 first col mean 0.11558473110198975 all mean 0.09090373665094376
0.30957654118537903 0.30957654118537903
rl training, epoch4, iter0, batch385/1133, batch loss:0.30957654118537903, Training time:12381.219430923462
batch reward last col mean 0.11131751537322998 first col mean 0.11320938169956207 all mean 0.11340655386447906
0.3224954605102539 0.3224954605102539
rl training, epoch4, iter0, batch386/1133, batch loss:0.3224954605102539, Training time:12383.217101812363
batch reward last col mean 0.0787808746099472 first col mean 0.1297619640827179 all mean 0.0916573703289032
0.32680779695510864 0.32680779695510864
rl training, epoch4, iter0, batch387/1133, batch loss:0.32680779695510864, Training time:12385.503630399704
batch reward last col mean 0.11142958700656891 first col mean 0.12874732911586761 all mean 0.1106255054473877
0.2985715866088867 0.29857155680656433
rl training, epoch4, iter0, batch388/1133, batch loss:0.29857155680656433, Training time:12387.499620199203
batch reward last col mean 0.10068561136722565 first col mean 0.13157878816127777 all mean 0.10850191861391068
0.31193363666534424 0.31193360686302185
rl training, epoch4, iter0, batch389/1133, batch loss:0.31193360686302185, Training time:12389.404104948044
batch reward last col mean 0.10064389556646347 first col mean 0.12077412754297256 all mean 0.1050819605588913
0.30141937732696533 0.30141937732696533
rl training, epoch4, iter0, batch390/1133, batch loss:0.30141937732696533, Training time:12391.66717672348
batch reward last col mean 0.10838199406862259 first col mean 0.11680607497692108 all mean 0.11333511024713516
0.3455252945423126 0.3455252945423126
rl training, epoch4, iter0, batch391/1133, batch loss:0.3455252945423126, Training time:12394.530180454254
batch reward last col mean 0.12185006588697433 first col mean 0.13975799083709717 all mean 0.12145242840051651
0.3396860957145691 0.3396860957145691
rl training, epoch4, iter0, batch392/1133, batch loss:0.3396860957145691, Training time:12396.41837143898
batch reward last col mean 0.11225758492946625 first col mean 0.10668976604938507 all mean 0.11377967149019241
0.3519803285598755 0.3519802689552307
rl training, epoch4, iter0, batch393/1133, batch loss:0.3519802689552307, Training time:12398.830563783646
batch reward last col mean 0.1265077292919159 first col mean 0.12468187510967255 all mean 0.11918272078037262
0.29949331283569336 0.29949331283569336
rl training, epoch4, iter0, batch394/1133, batch loss:0.29949331283569336, Training time:12401.448395252228
batch reward last col mean 0.10376419126987457 first col mean 0.12200188636779785 all mean 0.11217421293258667
0.31697580218315125 0.31697580218315125
rl training, epoch4, iter0, batch395/1133, batch loss:0.31697580218315125, Training time:12403.357201337814
batch reward last col mean 0.15417179465293884 first col mean 0.13787725567817688 all mean 0.14914663136005402
0.3411083519458771 0.3411083519458771
rl training, epoch4, iter0, batch396/1133, batch loss:0.3411083519458771, Training time:12405.798342704773
batch reward last col mean 0.13194935023784637 first col mean 0.13153865933418274 all mean 0.12336520105600357
0.3042318820953369 0.3042318820953369
rl training, epoch4, iter0, batch397/1133, batch loss:0.3042318820953369, Training time:12407.855642557144
batch reward last col mean 0.12333320081233978 first col mean 0.11921191215515137 all mean 0.11683319509029388
0.3278249204158783 0.3278249204158783
rl training, epoch4, iter0, batch398/1133, batch loss:0.3278249204158783, Training time:12409.747198820114
batch reward last col mean 0.1033407524228096 first col mean 0.12332414090633392 all mean 0.11474943161010742
0.3773481547832489 0.3773481547832489
rl training, epoch4, iter0, batch399/1133, batch loss:0.3773481547832489, Training time:12411.956066608429
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5247031509718428 Time: 100.87307238578796 s
loss of true 0.2295649360474084 loss of gen 0.1892299364334908 loss of other 0.1059082782722924 first score 0.10598452389240265
batch reward last col mean 0.09916552156209946 first col mean 0.11227485537528992 all mean 0.09661924093961716
0.277445524930954 0.277445524930954
rl training, epoch4, iter0, batch400/1133, batch loss:0.277445524930954, Training time:12515.48679447174
batch reward last col mean 0.14572998881340027 first col mean 0.0979481190443039 all mean 0.14076103270053864
0.3482818007469177 0.3482818007469177
rl training, epoch4, iter0, batch401/1133, batch loss:0.3482818007469177, Training time:12518.282928228378
batch reward last col mean 0.09442374110221863 first col mean 0.12487000226974487 all mean 0.09731458872556686
0.30574217438697815 0.30574217438697815
rl training, epoch4, iter0, batch402/1133, batch loss:0.30574217438697815, Training time:12520.468997240067
batch reward last col mean 0.09391946345567703 first col mean 0.10663987696170807 all mean 0.0928846076130867
0.31298285722732544 0.31298285722732544
rl training, epoch4, iter0, batch403/1133, batch loss:0.31298285722732544, Training time:12522.558195114136
batch reward last col mean 0.10484649240970612 first col mean 0.10500124096870422 all mean 0.10861505568027496
0.3063387870788574 0.3063387870788574
rl training, epoch4, iter0, batch404/1133, batch loss:0.3063387870788574, Training time:12525.140661716461
batch reward last col mean 0.09985814988613129 first col mean 0.12331116944551468 all mean 0.1048068255186081
0.3458753228187561 0.3458753228187561
rl training, epoch4, iter0, batch405/1133, batch loss:0.3458753228187561, Training time:12527.14804148674
batch reward last col mean 0.08160512149333954 first col mean 0.1058005541563034 all mean 0.08894845843315125
0.2794860005378723 0.2794860005378723
rl training, epoch4, iter0, batch406/1133, batch loss:0.2794860005378723, Training time:12529.304739713669
batch reward last col mean 0.11214359104633331 first col mean 0.12582728266716003 all mean 0.10885035246610641
0.3146686255931854 0.3146686255931854
rl training, epoch4, iter0, batch407/1133, batch loss:0.3146686255931854, Training time:12531.484931707382
batch reward last col mean 0.14061015844345093 first col mean 0.10414980351924896 all mean 0.13640235364437103
0.29353415966033936 0.29353415966033936
rl training, epoch4, iter0, batch408/1133, batch loss:0.29353415966033936, Training time:12533.786923646927
batch reward last col mean 0.10007182508707047 first col mean 0.1341320276260376 all mean 0.10529402643442154
0.3060092329978943 0.3060092329978943
rl training, epoch4, iter0, batch409/1133, batch loss:0.3060092329978943, Training time:12536.708390712738
batch reward last col mean 0.07241283357143402 first col mean 0.09489580988883972 all mean 0.0781409740447998
0.2757440507411957 0.2757440507411957
rl training, epoch4, iter0, batch410/1133, batch loss:0.2757440507411957, Training time:12541.035533189774
batch reward last col mean 0.07927675545215607 first col mean 0.11001379042863846 all mean 0.09074490517377853
0.2535901367664337 0.2535901367664337
rl training, epoch4, iter0, batch411/1133, batch loss:0.2535901367664337, Training time:12543.21776175499
batch reward last col mean 0.10227493196725845 first col mean 0.11992846429347992 all mean 0.1033458560705185
0.29822346568107605 0.29822346568107605
rl training, epoch4, iter0, batch412/1133, batch loss:0.29822346568107605, Training time:12545.354640483856
batch reward last col mean 0.07802018523216248 first col mean 0.10146676003932953 all mean 0.08663244545459747
0.3028630316257477 0.3028630316257477
rl training, epoch4, iter0, batch413/1133, batch loss:0.3028630316257477, Training time:12547.713858366013
batch reward last col mean 0.0895596295595169 first col mean 0.10778948664665222 all mean 0.09522893279790878
0.2945979833602905 0.2945980131626129
rl training, epoch4, iter0, batch414/1133, batch loss:0.2945980131626129, Training time:12550.014605998993
batch reward last col mean 0.10868117213249207 first col mean 0.11152729392051697 all mean 0.10529357194900513
0.29646989703178406 0.29646989703178406
rl training, epoch4, iter0, batch415/1133, batch loss:0.29646989703178406, Training time:12553.002046585083
batch reward last col mean 0.08530662208795547 first col mean 0.10733068734407425 all mean 0.09379663318395615
0.28966400027275085 0.28966400027275085
rl training, epoch4, iter0, batch416/1133, batch loss:0.28966400027275085, Training time:12555.898991823196
batch reward last col mean 0.12965157628059387 first col mean 0.12482655048370361 all mean 0.1259852796792984
0.3429899215698242 0.3429899513721466
rl training, epoch4, iter0, batch417/1133, batch loss:0.3429899513721466, Training time:12558.413358211517
batch reward last col mean 0.08297307044267654 first col mean 0.1079031378030777 all mean 0.08776330947875977
0.3156650960445404 0.3156650960445404
rl training, epoch4, iter0, batch418/1133, batch loss:0.3156650960445404, Training time:12561.066720962524
batch reward last col mean 0.09744833409786224 first col mean 0.12357442080974579 all mean 0.10049734264612198
0.31226205825805664 0.31226205825805664
rl training, epoch4, iter0, batch419/1133, batch loss:0.31226205825805664, Training time:12563.013503074646
batch reward last col mean 0.11592648178339005 first col mean 0.11171061545610428 all mean 0.11603887379169464
0.29181787371635437 0.29181787371635437
rl training, epoch4, iter0, batch420/1133, batch loss:0.29181787371635437, Training time:12565.156954288483
batch reward last col mean 0.08881894499063492 first col mean 0.1185656413435936 all mean 0.0986880213022232
0.2934195399284363 0.2934195399284363
rl training, epoch4, iter0, batch421/1133, batch loss:0.2934195399284363, Training time:12567.501420974731
batch reward last col mean 0.07978424429893494 first col mean 0.09314216673374176 all mean 0.09350648522377014
0.31763938069343567 0.31763938069343567
rl training, epoch4, iter0, batch422/1133, batch loss:0.31763938069343567, Training time:12570.068850040436
batch reward last col mean 0.10453785955905914 first col mean 0.1195848286151886 all mean 0.10313717275857925
0.29414209723472595 0.29414209723472595
rl training, epoch4, iter0, batch423/1133, batch loss:0.29414209723472595, Training time:12572.360675096512
batch reward last col mean 0.10637396574020386 first col mean 0.11518675833940506 all mean 0.10400699824094772
0.28853103518486023 0.28853103518486023
rl training, epoch4, iter0, batch424/1133, batch loss:0.28853103518486023, Training time:12575.537880897522
batch reward last col mean 0.08355284482240677 first col mean 0.11856243014335632 all mean 0.09519346058368683
0.2761758267879486 0.2761757969856262
rl training, epoch4, iter0, batch425/1133, batch loss:0.2761757969856262, Training time:12577.30059337616
batch reward last col mean 0.13660450279712677 first col mean 0.128434419631958 all mean 0.13694871962070465
0.3664443790912628 0.3664444088935852
rl training, epoch4, iter0, batch426/1133, batch loss:0.3664444088935852, Training time:12580.085893392563
batch reward last col mean 0.10572606325149536 first col mean 0.10117754340171814 all mean 0.10378696024417877
0.28297358751296997 0.28297358751296997
rl training, epoch4, iter0, batch427/1133, batch loss:0.28297358751296997, Training time:12582.197910308838
batch reward last col mean 0.09267536550760269 first col mean 0.11506517231464386 all mean 0.09963340312242508
0.3298276960849762 0.3298277258872986
rl training, epoch4, iter0, batch428/1133, batch loss:0.3298277258872986, Training time:12584.880806207657
batch reward last col mean 0.11743006110191345 first col mean 0.11212904751300812 all mean 0.11737043410539627
0.2941737473011017 0.2941737473011017
rl training, epoch4, iter0, batch429/1133, batch loss:0.2941737473011017, Training time:12587.797981739044
batch reward last col mean 0.07473619282245636 first col mean 0.10006807744503021 all mean 0.08270053565502167
0.26504698395729065 0.26504698395729065
rl training, epoch4, iter0, batch430/1133, batch loss:0.26504698395729065, Training time:12590.499187469482
batch reward last col mean 0.11788313090801239 first col mean 0.13048653304576874 all mean 0.11062547564506531
0.3128628432750702 0.3128628432750702
rl training, epoch4, iter0, batch431/1133, batch loss:0.3128628432750702, Training time:12592.773693561554
batch reward last col mean 0.13398483395576477 first col mean 0.11103505641222 all mean 0.12729063630104065
0.2894679605960846 0.2894679605960846
rl training, epoch4, iter0, batch432/1133, batch loss:0.2894679605960846, Training time:12596.36516714096
batch reward last col mean 0.07120506465435028 first col mean 0.11220251023769379 all mean 0.08540227264165878
0.30343949794769287 0.30343949794769287
rl training, epoch4, iter0, batch433/1133, batch loss:0.30343949794769287, Training time:12598.669563770294
batch reward last col mean 0.10242864489555359 first col mean 0.1118379533290863 all mean 0.1042219027876854
0.2997298538684845 0.2997298836708069
rl training, epoch4, iter0, batch434/1133, batch loss:0.2997298836708069, Training time:12601.163452148438
batch reward last col mean 0.06463194638490677 first col mean 0.10062023997306824 all mean 0.07662422955036163
0.27186042070388794 0.27186042070388794
rl training, epoch4, iter0, batch435/1133, batch loss:0.27186042070388794, Training time:12603.895774841309
batch reward last col mean 0.13499967753887177 first col mean 0.12545782327651978 all mean 0.132489413022995
0.35426774621009827 0.35426774621009827
rl training, epoch4, iter0, batch436/1133, batch loss:0.35426774621009827, Training time:12606.789165258408
batch reward last col mean 0.13464947044849396 first col mean 0.10066632181406021 all mean 0.12417928874492645
0.30181458592414856 0.30181458592414856
rl training, epoch4, iter0, batch437/1133, batch loss:0.30181458592414856, Training time:12609.484382629395
batch reward last col mean 0.15640318393707275 first col mean 0.12422824651002884 all mean 0.14165228605270386
0.39658480882644653 0.39658480882644653
rl training, epoch4, iter0, batch438/1133, batch loss:0.39658480882644653, Training time:12612.881083011627
batch reward last col mean 0.1315358281135559 first col mean 0.10258983820676804 all mean 0.12437690794467926
0.32033729553222656 0.32033729553222656
rl training, epoch4, iter0, batch439/1133, batch loss:0.32033729553222656, Training time:12615.825446367264
batch reward last col mean 0.10683353990316391 first col mean 0.1037590503692627 all mean 0.10628309845924377
0.31324318051338196 0.31324318051338196
rl training, epoch4, iter0, batch440/1133, batch loss:0.31324318051338196, Training time:12618.835833072662
batch reward last col mean 0.07531166821718216 first col mean 0.10319855809211731 all mean 0.08602862060070038
0.29177841544151306 0.29177841544151306
rl training, epoch4, iter0, batch441/1133, batch loss:0.29177841544151306, Training time:12621.483278512955
batch reward last col mean 0.10191358625888824 first col mean 0.09894734621047974 all mean 0.10517337173223495
0.297002911567688 0.297002911567688
rl training, epoch4, iter0, batch442/1133, batch loss:0.297002911567688, Training time:12624.052778244019
batch reward last col mean 0.09144389629364014 first col mean 0.13461315631866455 all mean 0.10365147143602371
0.34520766139030457 0.34520766139030457
rl training, epoch4, iter0, batch443/1133, batch loss:0.34520766139030457, Training time:12627.016412973404
batch reward last col mean 0.14114362001419067 first col mean 0.08473200350999832 all mean 0.13430561125278473
0.315947949886322 0.315947949886322
rl training, epoch4, iter0, batch444/1133, batch loss:0.315947949886322, Training time:12629.546120643616
batch reward last col mean 0.11929646134376526 first col mean 0.11843330413103104 all mean 0.11959228664636612
0.3257595896720886 0.3257595896720886
rl training, epoch4, iter0, batch445/1133, batch loss:0.3257595896720886, Training time:12631.989407539368
batch reward last col mean 0.11003882437944412 first col mean 0.11038492619991302 all mean 0.1115204468369484
0.3299724757671356 0.329972505569458
rl training, epoch4, iter0, batch446/1133, batch loss:0.329972505569458, Training time:12634.39242863655
batch reward last col mean 0.14595511555671692 first col mean 0.10575289279222488 all mean 0.138273686170578
0.3666151762008667 0.3666151762008667
rl training, epoch4, iter0, batch447/1133, batch loss:0.3666151762008667, Training time:12636.352223396301
batch reward last col mean 0.09773942828178406 first col mean 0.09972149133682251 all mean 0.09559483826160431
0.3036341071128845 0.3036341071128845
rl training, epoch4, iter0, batch448/1133, batch loss:0.3036341071128845, Training time:12638.576798677444
batch reward last col mean 0.07802280783653259 first col mean 0.13205274939537048 all mean 0.08720759302377701
0.2729106545448303 0.27291062474250793
rl training, epoch4, iter0, batch449/1133, batch loss:0.27291062474250793, Training time:12641.170595407486
batch reward last col mean 0.12918899953365326 first col mean 0.0979449599981308 all mean 0.12246111035346985
0.3184307813644409 0.3184307813644409
rl training, epoch4, iter0, batch450/1133, batch loss:0.3184307813644409, Training time:12643.164923906326
batch reward last col mean 0.12854920327663422 first col mean 0.12372338771820068 all mean 0.11996594816446304
0.3240988850593567 0.3240988552570343
rl training, epoch4, iter0, batch451/1133, batch loss:0.3240988552570343, Training time:12645.088693618774
batch reward last col mean 0.1541910022497177 first col mean 0.12119300663471222 all mean 0.1417149007320404
0.3495835065841675 0.3495835065841675
rl training, epoch4, iter0, batch452/1133, batch loss:0.3495835065841675, Training time:12647.543067932129
batch reward last col mean 0.11674457788467407 first col mean 0.10403724014759064 all mean 0.10623907297849655
0.2845309376716614 0.2845309376716614
rl training, epoch4, iter0, batch453/1133, batch loss:0.2845309376716614, Training time:12649.81168103218
batch reward last col mean 0.11059903353452682 first col mean 0.09857630729675293 all mean 0.1109001412987709
0.257394015789032 0.257394015789032
rl training, epoch4, iter0, batch454/1133, batch loss:0.257394015789032, Training time:12651.87725520134
batch reward last col mean 0.11117900907993317 first col mean 0.1048334389925003 all mean 0.11251784861087799
0.311355322599411 0.311355322599411
rl training, epoch4, iter0, batch455/1133, batch loss:0.311355322599411, Training time:12654.615056037903
batch reward last col mean 0.1304538995027542 first col mean 0.10488486289978027 all mean 0.12841583788394928
0.3568630814552307 0.3568630814552307
rl training, epoch4, iter0, batch456/1133, batch loss:0.3568630814552307, Training time:12657.66176199913
batch reward last col mean 0.0974300280213356 first col mean 0.10616204887628555 all mean 0.09673718363046646
0.2886410653591156 0.2886410057544708
rl training, epoch4, iter0, batch457/1133, batch loss:0.2886410057544708, Training time:12659.861347198486
batch reward last col mean 0.11201216280460358 first col mean 0.12403867393732071 all mean 0.11539279669523239
0.3030937910079956 0.3030937910079956
rl training, epoch4, iter0, batch458/1133, batch loss:0.3030937910079956, Training time:12662.563778877258
batch reward last col mean 0.09442564845085144 first col mean 0.12432302534580231 all mean 0.10205516219139099
0.32941052317619324 0.32941052317619324
rl training, epoch4, iter0, batch459/1133, batch loss:0.32941052317619324, Training time:12664.729179382324
batch reward last col mean 0.10847509652376175 first col mean 0.12208160012960434 all mean 0.11178386956453323
0.33191215991973877 0.33191215991973877
rl training, epoch4, iter0, batch460/1133, batch loss:0.33191215991973877, Training time:12666.846149921417
batch reward last col mean 0.11972656846046448 first col mean 0.1226777583360672 all mean 0.11756635457277298
0.3173195421695709 0.3173195421695709
rl training, epoch4, iter0, batch461/1133, batch loss:0.3173195421695709, Training time:12668.467738866806
batch reward last col mean 0.08537784963846207 first col mean 0.11795300990343094 all mean 0.0931461751461029
0.3125508427619934 0.3125508427619934
rl training, epoch4, iter0, batch462/1133, batch loss:0.3125508427619934, Training time:12670.40752530098
batch reward last col mean 0.10294953733682632 first col mean 0.09017312526702881 all mean 0.10104294121265411
0.31031864881515503 0.31031864881515503
rl training, epoch4, iter0, batch463/1133, batch loss:0.31031864881515503, Training time:12672.367545843124
batch reward last col mean 0.11011000722646713 first col mean 0.1121205985546112 all mean 0.11287513375282288
0.3318362236022949 0.3318362236022949
rl training, epoch4, iter0, batch464/1133, batch loss:0.3318362236022949, Training time:12675.42571902275
batch reward last col mean 0.09723538905382156 first col mean 0.12225182354450226 all mean 0.1039060577750206
0.31314247846603394 0.31314244866371155
rl training, epoch4, iter0, batch465/1133, batch loss:0.31314244866371155, Training time:12677.391704082489
batch reward last col mean 0.10282670706510544 first col mean 0.12104868143796921 all mean 0.10417317599058151
0.27492308616638184 0.27492308616638184
rl training, epoch4, iter0, batch466/1133, batch loss:0.27492308616638184, Training time:12679.546183109283
batch reward last col mean 0.13837163150310516 first col mean 0.11992184817790985 all mean 0.13116376101970673
0.36408111453056335 0.36408114433288574
rl training, epoch4, iter0, batch467/1133, batch loss:0.36408114433288574, Training time:12681.377741336823
batch reward last col mean 0.10673703253269196 first col mean 0.12926268577575684 all mean 0.10785241425037384
0.3200565278530121 0.3200565278530121
rl training, epoch4, iter0, batch468/1133, batch loss:0.3200565278530121, Training time:12684.127778053284
batch reward last col mean 0.10352036356925964 first col mean 0.10528364032506943 all mean 0.10609797388315201
0.2970142066478729 0.2970142066478729
rl training, epoch4, iter0, batch469/1133, batch loss:0.2970142066478729, Training time:12686.197913646698
batch reward last col mean 0.0949491411447525 first col mean 0.12889665365219116 all mean 0.1014433205127716
0.3160119652748108 0.3160119652748108
rl training, epoch4, iter0, batch470/1133, batch loss:0.3160119652748108, Training time:12688.248377084732
batch reward last col mean 0.10792304575443268 first col mean 0.11070551723241806 all mean 0.1111743375658989
0.333048552274704 0.333048552274704
rl training, epoch4, iter0, batch471/1133, batch loss:0.333048552274704, Training time:12690.681324958801
batch reward last col mean 0.08636493235826492 first col mean 0.1243533045053482 all mean 0.09137697517871857
0.29654425382614136 0.29654425382614136
rl training, epoch4, iter0, batch472/1133, batch loss:0.29654425382614136, Training time:12692.621735334396
batch reward last col mean 0.11910457909107208 first col mean 0.11962693184614182 all mean 0.12367857247591019
0.3443835973739624 0.3443835973739624
rl training, epoch4, iter0, batch473/1133, batch loss:0.3443835973739624, Training time:12694.804502010345
batch reward last col mean 0.08330181986093521 first col mean 0.13445186614990234 all mean 0.09179604053497314
0.29316437244415283 0.29316437244415283
rl training, epoch4, iter0, batch474/1133, batch loss:0.29316437244415283, Training time:12697.427717208862
batch reward last col mean 0.111567422747612 first col mean 0.10609857738018036 all mean 0.11103034764528275
0.2969101369380951 0.2969101369380951
rl training, epoch4, iter0, batch475/1133, batch loss:0.2969101369380951, Training time:12699.108872175217
batch reward last col mean 0.10090441256761551 first col mean 0.10854193568229675 all mean 0.10819528251886368
0.269648939371109 0.269648939371109
rl training, epoch4, iter0, batch476/1133, batch loss:0.269648939371109, Training time:12700.99970817566
batch reward last col mean 0.13286246359348297 first col mean 0.1147015392780304 all mean 0.1296321451663971
0.3544466495513916 0.3544466495513916
rl training, epoch4, iter0, batch477/1133, batch loss:0.3544466495513916, Training time:12703.166846990585
batch reward last col mean 0.08985470980405807 first col mean 0.11649589985609055 all mean 0.09986602514982224
0.3288404643535614 0.3288404643535614
rl training, epoch4, iter0, batch478/1133, batch loss:0.3288404643535614, Training time:12705.839754581451
batch reward last col mean 0.1130828857421875 first col mean 0.1188243106007576 all mean 0.11626380681991577
0.369721919298172 0.369721919298172
rl training, epoch4, iter0, batch479/1133, batch loss:0.369721919298172, Training time:12707.618294477463
batch reward last col mean 0.11518970876932144 first col mean 0.14374278485774994 all mean 0.11382030695676804
0.3083834946155548 0.3083834648132324
rl training, epoch4, iter0, batch480/1133, batch loss:0.3083834648132324, Training time:12709.768761873245
batch reward last col mean 0.08925169706344604 first col mean 0.11496748775243759 all mean 0.09608270972967148
0.2754354774951935 0.2754354774951935
rl training, epoch4, iter0, batch481/1133, batch loss:0.2754354774951935, Training time:12712.324935436249
batch reward last col mean 0.1187526062130928 first col mean 0.10266710072755814 all mean 0.1171559989452362
0.3292091190814972 0.3292091190814972
rl training, epoch4, iter0, batch482/1133, batch loss:0.3292091190814972, Training time:12714.780221223831
batch reward last col mean 0.07851128280162811 first col mean 0.09974734485149384 all mean 0.08881720155477524
0.289646714925766 0.289646714925766
rl training, epoch4, iter0, batch483/1133, batch loss:0.289646714925766, Training time:12716.837465047836
batch reward last col mean 0.1371052861213684 first col mean 0.11822426319122314 all mean 0.1346818208694458
0.36836156249046326 0.36836156249046326
rl training, epoch4, iter0, batch484/1133, batch loss:0.36836156249046326, Training time:12718.550340175629
batch reward last col mean 0.12692293524742126 first col mean 0.09674978256225586 all mean 0.12561219930648804
0.33830106258392334 0.33830106258392334
rl training, epoch4, iter0, batch485/1133, batch loss:0.33830106258392334, Training time:12720.778038263321
batch reward last col mean 0.1300254911184311 first col mean 0.10424685478210449 all mean 0.12110983580350876
0.36317601799964905 0.36317601799964905
rl training, epoch4, iter0, batch486/1133, batch loss:0.36317601799964905, Training time:12723.017040729523
batch reward last col mean 0.11113200336694717 first col mean 0.11837794631719589 all mean 0.11218754947185516
0.3220057189464569 0.3220057189464569
rl training, epoch4, iter0, batch487/1133, batch loss:0.3220057189464569, Training time:12725.07167840004
batch reward last col mean 0.10123369097709656 first col mean 0.124235138297081 all mean 0.09949293732643127
0.29028433561325073 0.29028433561325073
rl training, epoch4, iter0, batch488/1133, batch loss:0.29028433561325073, Training time:12727.06839966774
batch reward last col mean 0.08218824118375778 first col mean 0.11534471809864044 all mean 0.08884762227535248
0.2819918096065521 0.28199177980422974
rl training, epoch4, iter0, batch489/1133, batch loss:0.28199177980422974, Training time:12729.020002365112
batch reward last col mean 0.11219305545091629 first col mean 0.11338283121585846 all mean 0.11018369346857071
0.3250085115432739 0.3250085115432739
rl training, epoch4, iter0, batch490/1133, batch loss:0.3250085115432739, Training time:12731.492285966873
batch reward last col mean 0.12761454284191132 first col mean 0.10671152919530869 all mean 0.1260441094636917
0.3463866710662842 0.3463866412639618
rl training, epoch4, iter0, batch491/1133, batch loss:0.3463866412639618, Training time:12733.45065498352
batch reward last col mean 0.12225732207298279 first col mean 0.1430656611919403 all mean 0.12446422129869461
0.31750863790512085 0.31750863790512085
rl training, epoch4, iter0, batch492/1133, batch loss:0.31750863790512085, Training time:12735.344710588455
batch reward last col mean 0.12080882489681244 first col mean 0.11735111474990845 all mean 0.12154418975114822
0.31708720326423645 0.31708720326423645
rl training, epoch4, iter0, batch493/1133, batch loss:0.31708720326423645, Training time:12737.483988046646
batch reward last col mean 0.12528999149799347 first col mean 0.11131665110588074 all mean 0.12059758603572845
0.30325818061828613 0.30325818061828613
rl training, epoch4, iter0, batch494/1133, batch loss:0.30325818061828613, Training time:12739.270015716553
batch reward last col mean 0.11637023091316223 first col mean 0.12473765015602112 all mean 0.11167363077402115
0.2624976634979248 0.2624976634979248
rl training, epoch4, iter0, batch495/1133, batch loss:0.2624976634979248, Training time:12741.102521419525
batch reward last col mean 0.08953848481178284 first col mean 0.09906475245952606 all mean 0.09380743652582169
0.2899312376976013 0.2899312376976013
rl training, epoch4, iter0, batch496/1133, batch loss:0.2899312376976013, Training time:12743.5397503376
batch reward last col mean 0.12604489922523499 first col mean 0.10602215677499771 all mean 0.1240045428276062
0.30815404653549194 0.30815401673316956
rl training, epoch4, iter0, batch497/1133, batch loss:0.30815401673316956, Training time:12746.252230882645
batch reward last col mean 0.08384610712528229 first col mean 0.11349011957645416 all mean 0.09100256115198135
0.2719956040382385 0.2719956040382385
rl training, epoch4, iter0, batch498/1133, batch loss:0.2719956040382385, Training time:12748.048354148865
batch reward last col mean 0.11077556014060974 first col mean 0.12871424853801727 all mean 0.11065594851970673
0.29620876908302307 0.29620876908302307
rl training, epoch4, iter0, batch499/1133, batch loss:0.29620876908302307, Training time:12750.188756465912
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5165251515549258 Time: 98.5802161693573 s
loss of true 0.22606564296733356 loss of gen 0.18573028228631192 loss of other 0.104729226667891 first score 0.15207892656326294
batch reward last col mean 0.13388760387897491 first col mean 0.1257990300655365 all mean 0.12680213153362274
0.3399432897567749 0.3399432897567749
rl training, epoch4, iter0, batch500/1133, batch loss:0.3399432897567749, Training time:12850.85637140274
batch reward last col mean 0.101308673620224 first col mean 0.1211412325501442 all mean 0.11073871701955795
0.3481830954551697 0.3481830954551697
rl training, epoch4, iter0, batch501/1133, batch loss:0.3481830954551697, Training time:12853.558678865433
batch reward last col mean 0.1327706277370453 first col mean 0.1291169375181198 all mean 0.13031241297721863
0.3464001417160034 0.3464001417160034
rl training, epoch4, iter0, batch502/1133, batch loss:0.3464001417160034, Training time:12856.177567958832
batch reward last col mean 0.11847425997257233 first col mean 0.1166967824101448 all mean 0.11782354861497879
0.3444361984729767 0.3444361984729767
rl training, epoch4, iter0, batch503/1133, batch loss:0.3444361984729767, Training time:12858.335676193237
batch reward last col mean 0.09822580218315125 first col mean 0.11887858808040619 all mean 0.10599219799041748
0.29353463649749756 0.29353463649749756
rl training, epoch4, iter0, batch504/1133, batch loss:0.29353463649749756, Training time:12860.809549331665
batch reward last col mean 0.11258070915937424 first col mean 0.11314690113067627 all mean 0.11366091668605804
0.30229607224464417 0.30229607224464417
rl training, epoch4, iter0, batch505/1133, batch loss:0.30229607224464417, Training time:12862.874541521072
batch reward last col mean 0.12471695244312286 first col mean 0.11339111626148224 all mean 0.12209489196538925
0.3150951862335205 0.3150951862335205
rl training, epoch4, iter0, batch506/1133, batch loss:0.3150951862335205, Training time:12864.908977270126
batch reward last col mean 0.10679125785827637 first col mean 0.12192533910274506 all mean 0.10938210785388947
0.30093660950660706 0.30093660950660706
rl training, epoch4, iter0, batch507/1133, batch loss:0.30093660950660706, Training time:12866.62864947319
batch reward last col mean 0.13548344373703003 first col mean 0.13329121470451355 all mean 0.13242119550704956
0.36533114314079285 0.36533108353614807
rl training, epoch4, iter0, batch508/1133, batch loss:0.36533108353614807, Training time:12868.689927816391
batch reward last col mean 0.12523195147514343 first col mean 0.0982723981142044 all mean 0.11887941509485245
0.28777509927749634 0.28777509927749634
rl training, epoch4, iter0, batch509/1133, batch loss:0.28777509927749634, Training time:12870.513188838959
batch reward last col mean 0.1330530345439911 first col mean 0.1251356303691864 all mean 0.12582772970199585
0.3558071255683899 0.3558071255683899
rl training, epoch4, iter0, batch510/1133, batch loss:0.3558071255683899, Training time:12872.929949760437
batch reward last col mean 0.09469375014305115 first col mean 0.13145335018634796 all mean 0.10253910720348358
0.2945750653743744 0.2945750653743744
rl training, epoch4, iter0, batch511/1133, batch loss:0.2945750653743744, Training time:12875.167666435242
batch reward last col mean 0.10880827903747559 first col mean 0.11674955487251282 all mean 0.1111193522810936
0.29782161116600037 0.29782161116600037
rl training, epoch4, iter0, batch512/1133, batch loss:0.29782161116600037, Training time:12877.608744621277
batch reward last col mean 0.11678031831979752 first col mean 0.12639515101909637 all mean 0.11502239853143692
0.2951579988002777 0.2951579988002777
rl training, epoch4, iter0, batch513/1133, batch loss:0.2951579988002777, Training time:12879.680275201797
batch reward last col mean 0.12101398408412933 first col mean 0.12381616234779358 all mean 0.11457480490207672
0.3205919563770294 0.3205919563770294
rl training, epoch4, iter0, batch514/1133, batch loss:0.3205919563770294, Training time:12881.845577478409
batch reward last col mean 0.1159694641828537 first col mean 0.12711483240127563 all mean 0.12215234339237213
0.37217530608177185 0.37217530608177185
rl training, epoch4, iter0, batch515/1133, batch loss:0.37217530608177185, Training time:12883.78552889824
batch reward last col mean 0.11526129394769669 first col mean 0.13393209874629974 all mean 0.12064546346664429
0.3575838804244995 0.3575838506221771
rl training, epoch4, iter0, batch516/1133, batch loss:0.3575838506221771, Training time:12885.60775756836
batch reward last col mean 0.12568145990371704 first col mean 0.12762778997421265 all mean 0.12393166124820709
0.3788248896598816 0.3788248896598816
rl training, epoch4, iter0, batch517/1133, batch loss:0.3788248896598816, Training time:12887.769139051437
batch reward last col mean 0.1681961566209793 first col mean 0.11820100247859955 all mean 0.14168231189250946
0.3386240303516388 0.3386240303516388
rl training, epoch4, iter0, batch518/1133, batch loss:0.3386240303516388, Training time:12889.397784233093
batch reward last col mean 0.09554967284202576 first col mean 0.122589111328125 all mean 0.10371465235948563
0.2809608578681946 0.2809608578681946
rl training, epoch4, iter0, batch519/1133, batch loss:0.2809608578681946, Training time:12891.561196804047
batch reward last col mean 0.0712280347943306 first col mean 0.12316398322582245 all mean 0.08387980610132217
0.2637350261211395 0.2637350261211395
rl training, epoch4, iter0, batch520/1133, batch loss:0.2637350261211395, Training time:12893.891253471375
batch reward last col mean 0.10725069046020508 first col mean 0.12928371131420135 all mean 0.10587531328201294
0.3003566563129425 0.3003566563129425
rl training, epoch4, iter0, batch521/1133, batch loss:0.3003566563129425, Training time:12895.623542070389
batch reward last col mean 0.1372687816619873 first col mean 0.13689911365509033 all mean 0.12697206437587738
0.351053386926651 0.351053386926651
rl training, epoch4, iter0, batch522/1133, batch loss:0.351053386926651, Training time:12897.70439004898
batch reward last col mean 0.07667423784732819 first col mean 0.13515150547027588 all mean 0.0869034081697464
0.25715816020965576 0.25715816020965576
rl training, epoch4, iter0, batch523/1133, batch loss:0.25715816020965576, Training time:12899.979986667633
batch reward last col mean 0.12147824466228485 first col mean 0.10450997203588486 all mean 0.11732912808656693
0.2964631915092468 0.2964632511138916
rl training, epoch4, iter0, batch524/1133, batch loss:0.2964632511138916, Training time:12902.43703198433
batch reward last col mean 0.07750402390956879 first col mean 0.10941066592931747 all mean 0.09135185927152634
0.30257242918014526 0.30257242918014526
rl training, epoch4, iter0, batch525/1133, batch loss:0.30257242918014526, Training time:12904.702748537064
batch reward last col mean 0.09414408355951309 first col mean 0.10974958539009094 all mean 0.10538825392723083
0.3072134256362915 0.3072134256362915
rl training, epoch4, iter0, batch526/1133, batch loss:0.3072134256362915, Training time:12906.636118650436
batch reward last col mean 0.10261300206184387 first col mean 0.12195439636707306 all mean 0.10506538301706314
0.3394031226634979 0.3394031226634979
rl training, epoch4, iter0, batch527/1133, batch loss:0.3394031226634979, Training time:12909.543633699417
batch reward last col mean 0.11836079508066177 first col mean 0.10214810818433762 all mean 0.1221158504486084
0.345785528421402 0.345785528421402
rl training, epoch4, iter0, batch528/1133, batch loss:0.345785528421402, Training time:12911.18314576149
batch reward last col mean 0.13933655619621277 first col mean 0.11700256913900375 all mean 0.1357489824295044
0.3597550690174103 0.3597550690174103
rl training, epoch4, iter0, batch529/1133, batch loss:0.3597550690174103, Training time:12912.991250514984
batch reward last col mean 0.16043630242347717 first col mean 0.124299556016922 all mean 0.1492599993944168
0.3215198218822479 0.3215198516845703
rl training, epoch4, iter0, batch530/1133, batch loss:0.3215198516845703, Training time:12914.640792369843
batch reward last col mean 0.10518709570169449 first col mean 0.119550421833992 all mean 0.10589433461427689
0.32303282618522644 0.32303279638290405
rl training, epoch4, iter0, batch531/1133, batch loss:0.32303279638290405, Training time:12916.758374452591
batch reward last col mean 0.09124062955379486 first col mean 0.12132222950458527 all mean 0.09937725216150284
0.2983952760696411 0.2983952760696411
rl training, epoch4, iter0, batch532/1133, batch loss:0.2983952760696411, Training time:12918.613282442093
batch reward last col mean 0.11617456376552582 first col mean 0.12241291999816895 all mean 0.11507999151945114
0.2959848642349243 0.2959848642349243
rl training, epoch4, iter0, batch533/1133, batch loss:0.2959848642349243, Training time:12920.327095985413
batch reward last col mean 0.11939799785614014 first col mean 0.1088838279247284 all mean 0.11837935447692871
0.30021175742149353 0.30021175742149353
rl training, epoch4, iter0, batch534/1133, batch loss:0.30021175742149353, Training time:12922.115031719208
batch reward last col mean 0.11760039627552032 first col mean 0.11404619365930557 all mean 0.11868410557508469
0.32418936491012573 0.32418936491012573
rl training, epoch4, iter0, batch535/1133, batch loss:0.32418936491012573, Training time:12924.465384244919
batch reward last col mean 0.11684456467628479 first col mean 0.10080212354660034 all mean 0.12351538240909576
0.3590940833091736 0.3590940833091736
rl training, epoch4, iter0, batch536/1133, batch loss:0.3590940833091736, Training time:12926.818835020065
batch reward last col mean 0.10139691084623337 first col mean 0.1263435333967209 all mean 0.11065283417701721
0.37241894006729126 0.37241894006729126
rl training, epoch4, iter0, batch537/1133, batch loss:0.37241894006729126, Training time:12928.565328359604
batch reward last col mean 0.12224282324314117 first col mean 0.13200926780700684 all mean 0.11514589190483093
0.3245479166507721 0.3245478868484497
rl training, epoch4, iter0, batch538/1133, batch loss:0.3245478868484497, Training time:12930.686042308807
batch reward last col mean 0.13930852711200714 first col mean 0.12752936780452728 all mean 0.12593387067317963
0.36575499176979065 0.36575502157211304
rl training, epoch4, iter0, batch539/1133, batch loss:0.36575502157211304, Training time:12932.498485803604
batch reward last col mean 0.11326126009225845 first col mean 0.10556589812040329 all mean 0.11579073965549469
0.30643507838249207 0.30643507838249207
rl training, epoch4, iter0, batch540/1133, batch loss:0.30643507838249207, Training time:12934.760956287384
batch reward last col mean 0.16897468268871307 first col mean 0.10127824544906616 all mean 0.1541294902563095
0.33059290051460266 0.33059290051460266
rl training, epoch4, iter0, batch541/1133, batch loss:0.33059290051460266, Training time:12936.828318119049
batch reward last col mean 0.1066652312874794 first col mean 0.1324218511581421 all mean 0.11043394356966019
0.32760244607925415 0.32760244607925415
rl training, epoch4, iter0, batch542/1133, batch loss:0.32760244607925415, Training time:12939.403778076172
batch reward last col mean 0.11500920355319977 first col mean 0.10725336521863937 all mean 0.11609666049480438
0.3163743019104004 0.3163743019104004
rl training, epoch4, iter0, batch543/1133, batch loss:0.3163743019104004, Training time:12941.785419225693
batch reward last col mean 0.13704320788383484 first col mean 0.10984440892934799 all mean 0.13362336158752441
0.34380435943603516 0.34380432963371277
rl training, epoch4, iter0, batch544/1133, batch loss:0.34380432963371277, Training time:12943.700133800507
batch reward last col mean 0.16849656403064728 first col mean 0.13253118097782135 all mean 0.15062546730041504
0.3990141749382019 0.3990141749382019
rl training, epoch4, iter0, batch545/1133, batch loss:0.3990141749382019, Training time:12945.449501991272
batch reward last col mean 0.09904845058917999 first col mean 0.10036585479974747 all mean 0.10189189016819
0.3157058656215668 0.3157058358192444
rl training, epoch4, iter0, batch546/1133, batch loss:0.3157058358192444, Training time:12947.39682340622
batch reward last col mean 0.13523495197296143 first col mean 0.11494271457195282 all mean 0.13410045206546783
0.3010091483592987 0.3010091483592987
rl training, epoch4, iter0, batch547/1133, batch loss:0.3010091483592987, Training time:12949.349465847015
batch reward last col mean 0.1080009937286377 first col mean 0.12917213141918182 all mean 0.1118692010641098
0.29630181193351746 0.29630181193351746
rl training, epoch4, iter0, batch548/1133, batch loss:0.29630181193351746, Training time:12951.072035312653
batch reward last col mean 0.1302383542060852 first col mean 0.13203811645507812 all mean 0.12457682192325592
0.3236662745475769 0.3236662745475769
rl training, epoch4, iter0, batch549/1133, batch loss:0.3236662745475769, Training time:12952.623399972916
batch reward last col mean 0.10091954469680786 first col mean 0.14355236291885376 all mean 0.10941831767559052
0.3011361062526703 0.3011361062526703
rl training, epoch4, iter0, batch550/1133, batch loss:0.3011361062526703, Training time:12954.80561375618
batch reward last col mean 0.13803859055042267 first col mean 0.10691133886575699 all mean 0.1353209763765335
0.3258673846721649 0.32586735486984253
rl training, epoch4, iter0, batch551/1133, batch loss:0.32586735486984253, Training time:12956.301390886307
batch reward last col mean 0.11786472052335739 first col mean 0.1173340454697609 all mean 0.11985038965940475
0.30869126319885254 0.30869123339653015
rl training, epoch4, iter0, batch552/1133, batch loss:0.30869123339653015, Training time:12958.199676513672
batch reward last col mean 0.15299108624458313 first col mean 0.15456004440784454 all mean 0.14352434873580933
0.3708588778972626 0.3708588778972626
rl training, epoch4, iter0, batch553/1133, batch loss:0.3708588778972626, Training time:12959.91992354393
batch reward last col mean 0.14186644554138184 first col mean 0.12291115522384644 all mean 0.13215553760528564
0.3424103558063507 0.3424103558063507
rl training, epoch4, iter0, batch554/1133, batch loss:0.3424103558063507, Training time:12962.028201341629
batch reward last col mean 0.10421533137559891 first col mean 0.11541860550642014 all mean 0.10609547048807144
0.3089349865913391 0.3089349865913391
rl training, epoch4, iter0, batch555/1133, batch loss:0.3089349865913391, Training time:12964.627471923828
batch reward last col mean 0.10849665850400925 first col mean 0.10654976963996887 all mean 0.10859747231006622
0.3383001983165741 0.3383001983165741
rl training, epoch4, iter0, batch556/1133, batch loss:0.3383001983165741, Training time:12967.213324069977
batch reward last col mean 0.11285682022571564 first col mean 0.1271056830883026 all mean 0.11519007384777069
0.32367539405822754 0.3236754238605499
rl training, epoch4, iter0, batch557/1133, batch loss:0.3236754238605499, Training time:12969.316348075867
batch reward last col mean 0.11032502353191376 first col mean 0.12484236061573029 all mean 0.11376628279685974
0.35810038447380066 0.35810038447380066
rl training, epoch4, iter0, batch558/1133, batch loss:0.35810038447380066, Training time:12971.264402151108
batch reward last col mean 0.13111625611782074 first col mean 0.09680553525686264 all mean 0.1308416873216629
0.3362336754798889 0.3362336754798889
rl training, epoch4, iter0, batch559/1133, batch loss:0.3362336754798889, Training time:12973.345163106918
batch reward last col mean 0.14333364367485046 first col mean 0.12978076934814453 all mean 0.1372847557067871
0.347978413105011 0.347978413105011
rl training, epoch4, iter0, batch560/1133, batch loss:0.347978413105011, Training time:12976.163604974747
batch reward last col mean 0.0891212522983551 first col mean 0.13475894927978516 all mean 0.10049660503864288
0.2945258915424347 0.2945258915424347
rl training, epoch4, iter0, batch561/1133, batch loss:0.2945258915424347, Training time:12977.797387599945
batch reward last col mean 0.09748905897140503 first col mean 0.1275215595960617 all mean 0.10613974183797836
0.30331024527549744 0.30331024527549744
rl training, epoch4, iter0, batch562/1133, batch loss:0.30331024527549744, Training time:12979.305048942566
batch reward last col mean 0.10662086308002472 first col mean 0.14258959889411926 all mean 0.1107834056019783
0.3539423942565918 0.3539423942565918
rl training, epoch4, iter0, batch563/1133, batch loss:0.3539423942565918, Training time:12981.083974599838
batch reward last col mean 0.08716575801372528 first col mean 0.12339816987514496 all mean 0.09593582153320312
0.35011354088783264 0.35011354088783264
rl training, epoch4, iter0, batch564/1133, batch loss:0.35011354088783264, Training time:12983.538001537323
batch reward last col mean 0.08737234026193619 first col mean 0.12223298847675323 all mean 0.09319106489419937
0.32089853286743164 0.32089853286743164
rl training, epoch4, iter0, batch565/1133, batch loss:0.32089853286743164, Training time:12985.803076982498
batch reward last col mean 0.11607794463634491 first col mean 0.12131384015083313 all mean 0.12048473954200745
0.32902616262435913 0.32902616262435913
rl training, epoch4, iter0, batch566/1133, batch loss:0.32902616262435913, Training time:12987.52882027626
batch reward last col mean 0.114704430103302 first col mean 0.13694895803928375 all mean 0.11498485505580902
0.30131855607032776 0.30131855607032776
rl training, epoch4, iter0, batch567/1133, batch loss:0.30131855607032776, Training time:12989.289045095444
batch reward last col mean 0.08192651718854904 first col mean 0.11942782253026962 all mean 0.08862420916557312
0.2575494647026062 0.2575494647026062
rl training, epoch4, iter0, batch568/1133, batch loss:0.2575494647026062, Training time:12991.448952913284
batch reward last col mean 0.0903729796409607 first col mean 0.1334439069032669 all mean 0.0943143293261528
0.28821465373039246 0.28821465373039246
rl training, epoch4, iter0, batch569/1133, batch loss:0.28821465373039246, Training time:12993.395941495895
batch reward last col mean 0.11018513143062592 first col mean 0.12193778902292252 all mean 0.1143612489104271
0.336981862783432 0.336981862783432
rl training, epoch4, iter0, batch570/1133, batch loss:0.336981862783432, Training time:12995.427506923676
batch reward last col mean 0.12130175530910492 first col mean 0.10130926221609116 all mean 0.11313056200742722
0.26968273520469666 0.26968273520469666
rl training, epoch4, iter0, batch571/1133, batch loss:0.26968273520469666, Training time:12997.32801246643
batch reward last col mean 0.10829535126686096 first col mean 0.12398318946361542 all mean 0.11732359230518341
0.31412166357040405 0.31412166357040405
rl training, epoch4, iter0, batch572/1133, batch loss:0.31412166357040405, Training time:12999.047721147537
batch reward last col mean 0.09796705842018127 first col mean 0.10587336122989655 all mean 0.10078249126672745
0.3172423541545868 0.3172423541545868
rl training, epoch4, iter0, batch573/1133, batch loss:0.3172423541545868, Training time:13000.837976694107
batch reward last col mean 0.1393987238407135 first col mean 0.10855892300605774 all mean 0.13291975855827332
0.3100893199443817 0.3100893199443817
rl training, epoch4, iter0, batch574/1133, batch loss:0.3100893199443817, Training time:13003.10377573967
batch reward last col mean 0.1213720291852951 first col mean 0.12450119107961655 all mean 0.11954088509082794
0.35209232568740845 0.35209232568740845
rl training, epoch4, iter0, batch575/1133, batch loss:0.35209232568740845, Training time:13005.115059137344
batch reward last col mean 0.14878936111927032 first col mean 0.1254422515630722 all mean 0.13714173436164856
0.37154752016067505 0.37154752016067505
rl training, epoch4, iter0, batch576/1133, batch loss:0.37154752016067505, Training time:13007.631403446198
batch reward last col mean 0.08833330869674683 first col mean 0.12301748991012573 all mean 0.09865748137235641
0.2948506474494934 0.2948506474494934
rl training, epoch4, iter0, batch577/1133, batch loss:0.2948506474494934, Training time:13009.57537651062
batch reward last col mean 0.10546877235174179 first col mean 0.12724751234054565 all mean 0.11130177974700928
0.32891717553138733 0.32891717553138733
rl training, epoch4, iter0, batch578/1133, batch loss:0.32891717553138733, Training time:13011.131927013397
batch reward last col mean 0.07916966080665588 first col mean 0.12740035355091095 all mean 0.09680373966693878
0.3500104546546936 0.3500104546546936
rl training, epoch4, iter0, batch579/1133, batch loss:0.3500104546546936, Training time:13012.733710765839
batch reward last col mean 0.12179681658744812 first col mean 0.12585392594337463 all mean 0.10589969903230667
0.304555743932724 0.3045557141304016
rl training, epoch4, iter0, batch580/1133, batch loss:0.3045557141304016, Training time:13014.558208465576
batch reward last col mean 0.11167027801275253 first col mean 0.11998189985752106 all mean 0.11339107900857925
0.32161444425582886 0.32161444425582886
rl training, epoch4, iter0, batch581/1133, batch loss:0.32161444425582886, Training time:13016.22715997696
batch reward last col mean 0.1365526020526886 first col mean 0.12206177413463593 all mean 0.12680600583553314
0.3398230969905853 0.3398231267929077
rl training, epoch4, iter0, batch582/1133, batch loss:0.3398231267929077, Training time:13017.87535071373
batch reward last col mean 0.1284484565258026 first col mean 0.13211636245250702 all mean 0.12957432866096497
0.33739688992500305 0.33739688992500305
rl training, epoch4, iter0, batch583/1133, batch loss:0.33739688992500305, Training time:13019.893107652664
batch reward last col mean 0.1170894131064415 first col mean 0.11849113553762436 all mean 0.1226099506020546
0.3423145115375519 0.3423145115375519
rl training, epoch4, iter0, batch584/1133, batch loss:0.3423145115375519, Training time:13022.04513335228
batch reward last col mean 0.10811819136142731 first col mean 0.11680448055267334 all mean 0.11471756547689438
0.33134523034095764 0.33134523034095764
rl training, epoch4, iter0, batch585/1133, batch loss:0.33134523034095764, Training time:13024.039868593216
batch reward last col mean 0.1144079640507698 first col mean 0.12214495241641998 all mean 0.11647376418113708
0.3603869378566742 0.3603869378566742
rl training, epoch4, iter0, batch586/1133, batch loss:0.3603869378566742, Training time:13026.944551944733
batch reward last col mean 0.1322183758020401 first col mean 0.12047223746776581 all mean 0.1337222307920456
0.33985140919685364 0.33985140919685364
rl training, epoch4, iter0, batch587/1133, batch loss:0.33985140919685364, Training time:13028.827713012695
batch reward last col mean 0.12637586891651154 first col mean 0.11741228401660919 all mean 0.12562412023544312
0.36874324083328247 0.3687432110309601
rl training, epoch4, iter0, batch588/1133, batch loss:0.3687432110309601, Training time:13030.79942393303
batch reward last col mean 0.0989665612578392 first col mean 0.11421464383602142 all mean 0.10238721966743469
0.29575976729393005 0.29575973749160767
rl training, epoch4, iter0, batch589/1133, batch loss:0.29575973749160767, Training time:13033.063177585602
batch reward last col mean 0.13704358041286469 first col mean 0.1151026040315628 all mean 0.12904495000839233
0.3154943585395813 0.3154943585395813
rl training, epoch4, iter0, batch590/1133, batch loss:0.3154943585395813, Training time:13034.508950710297
batch reward last col mean 0.12298138439655304 first col mean 0.12055201083421707 all mean 0.1232268288731575
0.3303160071372986 0.3303159475326538
rl training, epoch4, iter0, batch591/1133, batch loss:0.3303159475326538, Training time:13036.055680513382
batch reward last col mean 0.1718151867389679 first col mean 0.11549265682697296 all mean 0.15709124505519867
0.41158580780029297 0.41158580780029297
rl training, epoch4, iter0, batch592/1133, batch loss:0.41158580780029297, Training time:13037.694709300995
batch reward last col mean 0.07655682414770126 first col mean 0.12435007095336914 all mean 0.09349039196968079
0.3274562954902649 0.3274562656879425
rl training, epoch4, iter0, batch593/1133, batch loss:0.3274562656879425, Training time:13039.50361585617
batch reward last col mean 0.10165795683860779 first col mean 0.11900072544813156 all mean 0.10631967335939407
0.34897753596305847 0.34897753596305847
rl training, epoch4, iter0, batch594/1133, batch loss:0.34897753596305847, Training time:13042.067792654037
batch reward last col mean 0.09802472591400146 first col mean 0.12507691979408264 all mean 0.10818695276975632
0.3396819531917572 0.3396819531917572
rl training, epoch4, iter0, batch595/1133, batch loss:0.3396819531917572, Training time:13044.114228248596
batch reward last col mean 0.13880595564842224 first col mean 0.11997827887535095 all mean 0.13560721278190613
0.32881632447242737 0.32881632447242737
rl training, epoch4, iter0, batch596/1133, batch loss:0.32881632447242737, Training time:13045.973310470581
batch reward last col mean 0.09737948328256607 first col mean 0.08749473839998245 all mean 0.09980069100856781
0.3047701120376587 0.3047701120376587
rl training, epoch4, iter0, batch597/1133, batch loss:0.3047701120376587, Training time:13052.511546850204
batch reward last col mean 0.1254511922597885 first col mean 0.10512770712375641 all mean 0.1267985850572586
0.36887413263320923 0.36887413263320923
rl training, epoch4, iter0, batch598/1133, batch loss:0.36887413263320923, Training time:13054.404774188995
batch reward last col mean 0.09642419219017029 first col mean 0.13508577644824982 all mean 0.10446891188621521
0.3136472702026367 0.3136472702026367
rl training, epoch4, iter0, batch599/1133, batch loss:0.3136472702026367, Training time:13057.964344739914
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5161720145516762 Time: 97.95218920707703 s
loss of true 0.22648692642653398 loss of gen 0.18377510171518427 loss of other 0.10590998637214606 first score 0.10011735558509827
batch reward last col mean 0.11348067224025726 first col mean 0.10872992873191833 all mean 0.12141895294189453
0.38119733333587646 0.38119733333587646
rl training, epoch4, iter0, batch600/1133, batch loss:0.38119733333587646, Training time:13157.561241149902
batch reward last col mean 0.07261786609888077 first col mean 0.11139608174562454 all mean 0.08389169722795486
0.2823413014411926 0.2823413014411926
rl training, epoch4, iter0, batch601/1133, batch loss:0.2823413014411926, Training time:13159.591791391373
batch reward last col mean 0.12064918130636215 first col mean 0.11299961805343628 all mean 0.11814439296722412
0.3100340962409973 0.3100340962409973
rl training, epoch4, iter0, batch602/1133, batch loss:0.3100340962409973, Training time:13161.746865034103
batch reward last col mean 0.09369419515132904 first col mean 0.0996931716799736 all mean 0.09992536157369614
0.29463231563568115 0.29463231563568115
rl training, epoch4, iter0, batch603/1133, batch loss:0.29463231563568115, Training time:13164.082417488098
batch reward last col mean 0.08922546356916428 first col mean 0.11858625710010529 all mean 0.09845677763223648
0.28319641947746277 0.28319641947746277
rl training, epoch4, iter0, batch604/1133, batch loss:0.28319641947746277, Training time:13166.235740184784
batch reward last col mean 0.10072094947099686 first col mean 0.09801197052001953 all mean 0.10116921365261078
0.28885549306869507 0.28885552287101746
rl training, epoch4, iter0, batch605/1133, batch loss:0.28885552287101746, Training time:13168.733155488968
batch reward last col mean 0.12942226231098175 first col mean 0.10531909018754959 all mean 0.12390519678592682
0.2861241400241852 0.2861241400241852
rl training, epoch4, iter0, batch606/1133, batch loss:0.2861241400241852, Training time:13170.87156009674
batch reward last col mean 0.08171743154525757 first col mean 0.11530473828315735 all mean 0.09132314473390579
0.32199355959892273 0.32199355959892273
rl training, epoch4, iter0, batch607/1133, batch loss:0.32199355959892273, Training time:13172.998641729355
batch reward last col mean 0.09661352634429932 first col mean 0.11137337237596512 all mean 0.09922473132610321
0.3004406690597534 0.3004406690597534
rl training, epoch4, iter0, batch608/1133, batch loss:0.3004406690597534, Training time:13175.801939964294
batch reward last col mean 0.12728871405124664 first col mean 0.11031901836395264 all mean 0.12950173020362854
0.30504193902015686 0.30504193902015686
rl training, epoch4, iter0, batch609/1133, batch loss:0.30504193902015686, Training time:13177.791516542435
batch reward last col mean 0.11141346395015717 first col mean 0.09679488092660904 all mean 0.11403203755617142
0.2961963713169098 0.2961963713169098
rl training, epoch4, iter0, batch610/1133, batch loss:0.2961963713169098, Training time:13179.574889421463
batch reward last col mean 0.13026073575019836 first col mean 0.12156771123409271 all mean 0.12624987959861755
0.3028133511543274 0.3028133511543274
rl training, epoch4, iter0, batch611/1133, batch loss:0.3028133511543274, Training time:13181.389347076416
batch reward last col mean 0.10298200696706772 first col mean 0.09626951813697815 all mean 0.10385806858539581
0.28213822841644287 0.28213822841644287
rl training, epoch4, iter0, batch612/1133, batch loss:0.28213822841644287, Training time:13183.466309070587
batch reward last col mean 0.13217419385910034 first col mean 0.1300581395626068 all mean 0.1288524568080902
0.2940855026245117 0.2940855026245117
rl training, epoch4, iter0, batch613/1133, batch loss:0.2940855026245117, Training time:13185.58418226242
batch reward last col mean 0.16432243585586548 first col mean 0.1122329831123352 all mean 0.14813284575939178
0.330229789018631 0.330229789018631
rl training, epoch4, iter0, batch614/1133, batch loss:0.330229789018631, Training time:13187.62443780899
batch reward last col mean 0.13932804763317108 first col mean 0.12963876128196716 all mean 0.1310119926929474
0.354316771030426 0.354316771030426
rl training, epoch4, iter0, batch615/1133, batch loss:0.354316771030426, Training time:13189.133616924286
batch reward last col mean 0.09298249334096909 first col mean 0.11927948892116547 all mean 0.10406456142663956
0.2915458083152771 0.2915458083152771
rl training, epoch4, iter0, batch616/1133, batch loss:0.2915458083152771, Training time:13191.863537311554
batch reward last col mean 0.09358114004135132 first col mean 0.10752616822719574 all mean 0.09491048008203506
0.29228484630584717 0.29228484630584717
rl training, epoch4, iter0, batch617/1133, batch loss:0.29228484630584717, Training time:13194.089925050735
batch reward last col mean 0.129256933927536 first col mean 0.1065339595079422 all mean 0.12219542264938354
0.3124139606952667 0.3124140202999115
rl training, epoch4, iter0, batch618/1133, batch loss:0.3124140202999115, Training time:13196.183739900589
batch reward last col mean 0.12550555169582367 first col mean 0.1014937311410904 all mean 0.1247209683060646
0.3073994219303131 0.3073994219303131
rl training, epoch4, iter0, batch619/1133, batch loss:0.3073994219303131, Training time:13198.080165624619
batch reward last col mean 0.14241689443588257 first col mean 0.11988065391778946 all mean 0.13732272386550903
0.3099817633628845 0.3099817633628845
rl training, epoch4, iter0, batch620/1133, batch loss:0.3099817633628845, Training time:13200.257564783096
batch reward last col mean 0.11790785193443298 first col mean 0.11395439505577087 all mean 0.11698465049266815
0.3316119313240051 0.3316119313240051
rl training, epoch4, iter0, batch621/1133, batch loss:0.3316119313240051, Training time:13202.252695083618
batch reward last col mean 0.13490793108940125 first col mean 0.12126434594392776 all mean 0.1321297287940979
0.35955819487571716 0.35955819487571716
rl training, epoch4, iter0, batch622/1133, batch loss:0.35955819487571716, Training time:13204.421924114227
batch reward last col mean 0.10056052356958389 first col mean 0.11409131437540054 all mean 0.09703186899423599
0.2612772583961487 0.2612772583961487
rl training, epoch4, iter0, batch623/1133, batch loss:0.2612772583961487, Training time:13207.221467971802
batch reward last col mean 0.11268272250890732 first col mean 0.1240776777267456 all mean 0.11128729581832886
0.32853585481643677 0.3285358250141144
rl training, epoch4, iter0, batch624/1133, batch loss:0.3285358250141144, Training time:13209.433263540268
batch reward last col mean 0.07510663568973541 first col mean 0.11351435631513596 all mean 0.08852816373109818
0.2749735713005066 0.2749735713005066
rl training, epoch4, iter0, batch625/1133, batch loss:0.2749735713005066, Training time:13211.572900533676
batch reward last col mean 0.09871754050254822 first col mean 0.1231912299990654 all mean 0.10614737123250961
0.2938686013221741 0.2938686013221741
rl training, epoch4, iter0, batch626/1133, batch loss:0.2938686013221741, Training time:13213.700790405273
batch reward last col mean 0.09333556145429611 first col mean 0.11583724617958069 all mean 0.10619852691888809
0.29172512888908386 0.29172512888908386
rl training, epoch4, iter0, batch627/1133, batch loss:0.29172512888908386, Training time:13215.603699684143
batch reward last col mean 0.14526332914829254 first col mean 0.11328229308128357 all mean 0.14001694321632385
0.32667991518974304 0.3266799747943878
rl training, epoch4, iter0, batch628/1133, batch loss:0.3266799747943878, Training time:13217.711497068405
batch reward last col mean 0.11145821213722229 first col mean 0.11738022416830063 all mean 0.11147467792034149
0.33685314655303955 0.33685314655303955
rl training, epoch4, iter0, batch629/1133, batch loss:0.33685314655303955, Training time:13219.579892158508
batch reward last col mean 0.09174630045890808 first col mean 0.09970574080944061 all mean 0.09555710107088089
0.2526490092277527 0.2526490092277527
rl training, epoch4, iter0, batch630/1133, batch loss:0.2526490092277527, Training time:13221.925431728363
batch reward last col mean 0.10985444486141205 first col mean 0.11464016884565353 all mean 0.11254682391881943
0.33372676372528076 0.33372676372528076
rl training, epoch4, iter0, batch631/1133, batch loss:0.33372676372528076, Training time:13223.759783744812
batch reward last col mean 0.12593095004558563 first col mean 0.1303856521844864 all mean 0.12475679814815521
0.346106618642807 0.346106618642807
rl training, epoch4, iter0, batch632/1133, batch loss:0.346106618642807, Training time:13226.126547813416
batch reward last col mean 0.10952307283878326 first col mean 0.12259960919618607 all mean 0.11269636452198029
0.3017401695251465 0.3017401695251465
rl training, epoch4, iter0, batch633/1133, batch loss:0.3017401695251465, Training time:13228.717386245728
batch reward last col mean 0.1282351016998291 first col mean 0.11642453074455261 all mean 0.12439852952957153
0.311128169298172 0.311128169298172
rl training, epoch4, iter0, batch634/1133, batch loss:0.311128169298172, Training time:13230.724685668945
batch reward last col mean 0.09796267747879028 first col mean 0.12271474301815033 all mean 0.10770951956510544
0.29708346724510193 0.29708346724510193
rl training, epoch4, iter0, batch635/1133, batch loss:0.29708346724510193, Training time:13232.812444925308
batch reward last col mean 0.11346842348575592 first col mean 0.1050259917974472 all mean 0.11556846648454666
0.3107624650001526 0.3107624650001526
rl training, epoch4, iter0, batch636/1133, batch loss:0.3107624650001526, Training time:13235.175691604614
batch reward last col mean 0.13062527775764465 first col mean 0.12690502405166626 all mean 0.12159770727157593
0.3039890229701996 0.3039889931678772
rl training, epoch4, iter0, batch637/1133, batch loss:0.3039889931678772, Training time:13236.86827468872
batch reward last col mean 0.1249094009399414 first col mean 0.11068861931562424 all mean 0.11695204675197601
0.3722895681858063 0.3722895681858063
rl training, epoch4, iter0, batch638/1133, batch loss:0.3722895681858063, Training time:13238.870710372925
batch reward last col mean 0.10171791166067123 first col mean 0.12419980764389038 all mean 0.10585717111825943
0.3409431278705597 0.3409431278705597
rl training, epoch4, iter0, batch639/1133, batch loss:0.3409431278705597, Training time:13240.675095558167
batch reward last col mean 0.08299791812896729 first col mean 0.10658584535121918 all mean 0.0878034383058548
0.25726982951164246 0.25726982951164246
rl training, epoch4, iter0, batch640/1133, batch loss:0.25726982951164246, Training time:13243.032486915588
batch reward last col mean 0.10698151588439941 first col mean 0.11487660557031631 all mean 0.10431866347789764
0.2842813730239868 0.2842813730239868
rl training, epoch4, iter0, batch641/1133, batch loss:0.2842813730239868, Training time:13245.154122829437
batch reward last col mean 0.10486061125993729 first col mean 0.1073741763830185 all mean 0.11117465794086456
0.30411645770072937 0.30411645770072937
rl training, epoch4, iter0, batch642/1133, batch loss:0.30411645770072937, Training time:13246.957701206207
batch reward last col mean 0.11106999963521957 first col mean 0.11354724317789078 all mean 0.11247751861810684
0.3307674527168274 0.3307674527168274
rl training, epoch4, iter0, batch643/1133, batch loss:0.3307674527168274, Training time:13249.183493852615
batch reward last col mean 0.1300424486398697 first col mean 0.10495845973491669 all mean 0.12721532583236694
0.3268660008907318 0.3268660008907318
rl training, epoch4, iter0, batch644/1133, batch loss:0.3268660008907318, Training time:13251.311316490173
batch reward last col mean 0.09808684885501862 first col mean 0.09364692866802216 all mean 0.09747488051652908
0.24675899744033813 0.24675899744033813
rl training, epoch4, iter0, batch645/1133, batch loss:0.24675899744033813, Training time:13253.260850906372
batch reward last col mean 0.08465420454740524 first col mean 0.11105365306138992 all mean 0.09450744837522507
0.28318333625793457 0.28318333625793457
rl training, epoch4, iter0, batch646/1133, batch loss:0.28318333625793457, Training time:13255.145898342133
batch reward last col mean 0.1303020715713501 first col mean 0.11912035942077637 all mean 0.12738017737865448
0.3230333626270294 0.3230333626270294
rl training, epoch4, iter0, batch647/1133, batch loss:0.3230333626270294, Training time:13256.871591091156
batch reward last col mean 0.13800640404224396 first col mean 0.10888567566871643 all mean 0.1294603794813156
0.3098367750644684 0.30983680486679077
rl training, epoch4, iter0, batch648/1133, batch loss:0.30983680486679077, Training time:13258.275939702988
batch reward last col mean 0.1044887974858284 first col mean 0.11023586243391037 all mean 0.10261216014623642
0.3151683807373047 0.3151683807373047
rl training, epoch4, iter0, batch649/1133, batch loss:0.3151683807373047, Training time:13260.027605772018
batch reward last col mean 0.12000057101249695 first col mean 0.11505043506622314 all mean 0.11628608405590057
0.30465447902679443 0.30465447902679443
rl training, epoch4, iter0, batch650/1133, batch loss:0.30465447902679443, Training time:13261.611526727676
batch reward last col mean 0.14110952615737915 first col mean 0.1296006292104721 all mean 0.12813971936702728
0.35250601172447205 0.35250601172447205
rl training, epoch4, iter0, batch651/1133, batch loss:0.35250601172447205, Training time:13263.32262969017
batch reward last col mean 0.07813700288534164 first col mean 0.11668765544891357 all mean 0.09544580429792404
0.3186924159526825 0.3186924159526825
rl training, epoch4, iter0, batch652/1133, batch loss:0.3186924159526825, Training time:13265.012137889862
batch reward last col mean 0.12679517269134521 first col mean 0.12316375970840454 all mean 0.12148075550794601
0.3178706765174866 0.3178706765174866
rl training, epoch4, iter0, batch653/1133, batch loss:0.3178706765174866, Training time:13266.52728152275
batch reward last col mean 0.07386051118373871 first col mean 0.1215125173330307 all mean 0.09245018661022186
0.2678237855434418 0.2678237855434418
rl training, epoch4, iter0, batch654/1133, batch loss:0.2678237855434418, Training time:13267.925882101059
batch reward last col mean 0.14804010093212128 first col mean 0.11944299191236496 all mean 0.14618603885173798
0.37501078844070435 0.37501078844070435
rl training, epoch4, iter0, batch655/1133, batch loss:0.37501078844070435, Training time:13269.597075223923
batch reward last col mean 0.11129669845104218 first col mean 0.13501958549022675 all mean 0.11360906064510345
0.2973698079586029 0.2973698079586029
rl training, epoch4, iter0, batch656/1133, batch loss:0.2973698079586029, Training time:13270.979202985764
batch reward last col mean 0.1043243557214737 first col mean 0.12291692942380905 all mean 0.10534800589084625
0.2766372859477997 0.2766372859477997
rl training, epoch4, iter0, batch657/1133, batch loss:0.2766372859477997, Training time:13272.96878528595
batch reward last col mean 0.10115586221218109 first col mean 0.11170537769794464 all mean 0.11128376424312592
0.28833824396133423 0.28833824396133423
rl training, epoch4, iter0, batch658/1133, batch loss:0.28833824396133423, Training time:13274.615495443344
batch reward last col mean 0.1442515105009079 first col mean 0.12104925513267517 all mean 0.13297489285469055
0.3937690854072571 0.3937690854072571
rl training, epoch4, iter0, batch659/1133, batch loss:0.3937690854072571, Training time:13276.415498018265
batch reward last col mean 0.11830393970012665 first col mean 0.11505918204784393 all mean 0.11959368735551834
0.3103175461292267 0.3103175461292267
rl training, epoch4, iter0, batch660/1133, batch loss:0.3103175461292267, Training time:13278.124999761581
batch reward last col mean 0.1241595447063446 first col mean 0.11282797157764435 all mean 0.12065654247999191
0.34383517503738403 0.34383517503738403
rl training, epoch4, iter0, batch661/1133, batch loss:0.34383517503738403, Training time:13279.785065412521
batch reward last col mean 0.11450904607772827 first col mean 0.12149184197187424 all mean 0.11628029495477676
0.3262772262096405 0.3262772262096405
rl training, epoch4, iter0, batch662/1133, batch loss:0.3262772262096405, Training time:13281.564867019653
batch reward last col mean 0.06773243099451065 first col mean 0.10669240355491638 all mean 0.08238305151462555
0.2877390682697296 0.2877390682697296
rl training, epoch4, iter0, batch663/1133, batch loss:0.2877390682697296, Training time:13283.328357934952
batch reward last col mean 0.1034432053565979 first col mean 0.10638623684644699 all mean 0.1135590597987175
0.3358776271343231 0.33587756752967834
rl training, epoch4, iter0, batch664/1133, batch loss:0.33587756752967834, Training time:13285.25575709343
batch reward last col mean 0.1341976672410965 first col mean 0.1168612539768219 all mean 0.12372991442680359
0.34698286652565 0.34698286652565
rl training, epoch4, iter0, batch665/1133, batch loss:0.34698286652565, Training time:13287.106179237366
batch reward last col mean 0.11485794186592102 first col mean 0.12577655911445618 all mean 0.11959251016378403
0.2980472445487976 0.2980472147464752
rl training, epoch4, iter0, batch666/1133, batch loss:0.2980472147464752, Training time:13288.749067783356
batch reward last col mean 0.10156114399433136 first col mean 0.1273578554391861 all mean 0.09839111566543579
0.2798847258090973 0.2798847258090973
rl training, epoch4, iter0, batch667/1133, batch loss:0.2798847258090973, Training time:13290.224918603897
batch reward last col mean 0.11545971781015396 first col mean 0.12272126972675323 all mean 0.12239274382591248
0.34528836607933044 0.34528836607933044
rl training, epoch4, iter0, batch668/1133, batch loss:0.34528836607933044, Training time:13292.347713470459
batch reward last col mean 0.11737928539514542 first col mean 0.11622797697782516 all mean 0.11364039778709412
0.27901172637939453 0.27901172637939453
rl training, epoch4, iter0, batch669/1133, batch loss:0.27901172637939453, Training time:13294.387956857681
batch reward last col mean 0.139175146818161 first col mean 0.14229708909988403 all mean 0.13858012855052948
0.3600485920906067 0.3600485920906067
rl training, epoch4, iter0, batch670/1133, batch loss:0.3600485920906067, Training time:13295.85433602333
batch reward last col mean 0.11135970056056976 first col mean 0.10741404443979263 all mean 0.11068447679281235
0.3011367619037628 0.3011367619037628
rl training, epoch4, iter0, batch671/1133, batch loss:0.3011367619037628, Training time:13297.662122249603
batch reward last col mean 0.11415592581033707 first col mean 0.1299634873867035 all mean 0.11584952473640442
0.32678332924842834 0.32678329944610596
rl training, epoch4, iter0, batch672/1133, batch loss:0.32678329944610596, Training time:13299.397414684296
batch reward last col mean 0.09551391005516052 first col mean 0.11584419012069702 all mean 0.09971071034669876
0.26999813318252563 0.26999813318252563
rl training, epoch4, iter0, batch673/1133, batch loss:0.26999813318252563, Training time:13301.36757183075
batch reward last col mean 0.12107272446155548 first col mean 0.11196362972259521 all mean 0.12003536522388458
0.32623642683029175 0.32623642683029175
rl training, epoch4, iter0, batch674/1133, batch loss:0.32623642683029175, Training time:13303.36059474945
batch reward last col mean 0.14927995204925537 first col mean 0.10264936834573746 all mean 0.13679713010787964
0.30453306436538696 0.30453306436538696
rl training, epoch4, iter0, batch675/1133, batch loss:0.30453306436538696, Training time:13304.783431768417
batch reward last col mean 0.10832759737968445 first col mean 0.11627387255430222 all mean 0.10848093032836914
0.30291903018951416 0.30291903018951416
rl training, epoch4, iter0, batch676/1133, batch loss:0.30291903018951416, Training time:13306.418112039566
batch reward last col mean 0.08683932572603226 first col mean 0.12596683204174042 all mean 0.10005824267864227
0.31303173303604126 0.31303176283836365
rl training, epoch4, iter0, batch677/1133, batch loss:0.31303176283836365, Training time:13308.338557243347
batch reward last col mean 0.10532590746879578 first col mean 0.10787077248096466 all mean 0.10915765166282654
0.28806960582733154 0.28806960582733154
rl training, epoch4, iter0, batch678/1133, batch loss:0.28806960582733154, Training time:13310.020909070969
batch reward last col mean 0.08535776287317276 first col mean 0.11138193309307098 all mean 0.09391819685697556
0.30341044068336487 0.30341044068336487
rl training, epoch4, iter0, batch679/1133, batch loss:0.30341044068336487, Training time:13311.511429071426
batch reward last col mean 0.09187052398920059 first col mean 0.1191767156124115 all mean 0.09945479035377502
0.27695396542549133 0.27695396542549133
rl training, epoch4, iter0, batch680/1133, batch loss:0.27695396542549133, Training time:13313.341641664505
batch reward last col mean 0.12599971890449524 first col mean 0.1260821670293808 all mean 0.12115922570228577
0.3380213975906372 0.3380213975906372
rl training, epoch4, iter0, batch681/1133, batch loss:0.3380213975906372, Training time:13314.861123085022
batch reward last col mean 0.13632337749004364 first col mean 0.12511500716209412 all mean 0.1351650357246399
0.3655039370059967 0.3655039370059967
rl training, epoch4, iter0, batch682/1133, batch loss:0.3655039370059967, Training time:13316.171579837799
batch reward last col mean 0.07150793075561523 first col mean 0.12269914150238037 all mean 0.08540219068527222
0.2765079736709595 0.2765079736709595
rl training, epoch4, iter0, batch683/1133, batch loss:0.2765079736709595, Training time:13318.049241065979
batch reward last col mean 0.13907520473003387 first col mean 0.12108800560235977 all mean 0.13624519109725952
0.3550192713737488 0.3550192713737488
rl training, epoch4, iter0, batch684/1133, batch loss:0.3550192713737488, Training time:13319.751319408417
batch reward last col mean 0.09395556151866913 first col mean 0.1123017966747284 all mean 0.10071811079978943
0.3139306902885437 0.3139306902885437
rl training, epoch4, iter0, batch685/1133, batch loss:0.3139306902885437, Training time:13321.53729391098
batch reward last col mean 0.1395666003227234 first col mean 0.12200818955898285 all mean 0.13842123746871948
0.35437366366386414 0.35437366366386414
rl training, epoch4, iter0, batch686/1133, batch loss:0.35437366366386414, Training time:13323.910214424133
batch reward last col mean 0.10171224921941757 first col mean 0.11287540942430496 all mean 0.10489948093891144
0.29698485136032104 0.29698485136032104
rl training, epoch4, iter0, batch687/1133, batch loss:0.29698485136032104, Training time:13325.691722154617
batch reward last col mean 0.13428841531276703 first col mean 0.12079329788684845 all mean 0.1328679770231247
0.3291861414909363 0.3291861414909363
rl training, epoch4, iter0, batch688/1133, batch loss:0.3291861414909363, Training time:13327.57490682602
batch reward last col mean 0.08223484456539154 first col mean 0.11119551211595535 all mean 0.08892112225294113
0.2715094983577728 0.2715094983577728
rl training, epoch4, iter0, batch689/1133, batch loss:0.2715094983577728, Training time:13329.539177894592
batch reward last col mean 0.1201101690530777 first col mean 0.1301998347043991 all mean 0.11994016915559769
0.30537137389183044 0.30537140369415283
rl training, epoch4, iter0, batch690/1133, batch loss:0.30537140369415283, Training time:13331.76895737648
batch reward last col mean 0.11055141687393188 first col mean 0.1297924965620041 all mean 0.11519448459148407
0.3400247395038605 0.3400247395038605
rl training, epoch4, iter0, batch691/1133, batch loss:0.3400247395038605, Training time:13333.94811296463
batch reward last col mean 0.11522556841373444 first col mean 0.11486126482486725 all mean 0.12165268510580063
0.32040935754776 0.32040935754776
rl training, epoch4, iter0, batch692/1133, batch loss:0.32040935754776, Training time:13335.555244922638
batch reward last col mean 0.10702954977750778 first col mean 0.105970099568367 all mean 0.1095229834318161
0.29732516407966614 0.29732516407966614
rl training, epoch4, iter0, batch693/1133, batch loss:0.29732516407966614, Training time:13337.516874074936
batch reward last col mean 0.12859514355659485 first col mean 0.11440303176641464 all mean 0.12686076760292053
0.36685726046562195 0.36685726046562195
rl training, epoch4, iter0, batch694/1133, batch loss:0.36685726046562195, Training time:13339.450256824493
batch reward last col mean 0.11576448380947113 first col mean 0.13112151622772217 all mean 0.1184215322136879
0.3152583837509155 0.3152583837509155
rl training, epoch4, iter0, batch695/1133, batch loss:0.3152583837509155, Training time:13341.370728492737
batch reward last col mean 0.12085157632827759 first col mean 0.13300710916519165 all mean 0.12022294849157333
0.31745028495788574 0.31745028495788574
rl training, epoch4, iter0, batch696/1133, batch loss:0.31745028495788574, Training time:13342.96097445488
batch reward last col mean 0.1296919584274292 first col mean 0.10252144932746887 all mean 0.12182626128196716
0.2560020089149475 0.2560020089149475
rl training, epoch4, iter0, batch697/1133, batch loss:0.2560020089149475, Training time:13344.671441793442
batch reward last col mean 0.1122724860906601 first col mean 0.13823843002319336 all mean 0.11713229864835739
0.29947906732559204 0.29947903752326965
rl training, epoch4, iter0, batch698/1133, batch loss:0.29947903752326965, Training time:13346.226610898972
batch reward last col mean 0.10768111795186996 first col mean 0.11887091398239136 all mean 0.11547920852899551
0.3254067003726959 0.3254067003726959
rl training, epoch4, iter0, batch699/1133, batch loss:0.3254067003726959, Training time:13348.000193595886
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5204534301269612 Time: 97.34815740585327 s
loss of true 0.22900744312543944 loss of gen 0.18625415433510573 loss of other 0.1051918331924941 first score 0.13278910517692566
batch reward last col mean 0.09044915437698364 first col mean 0.0907493606209755 all mean 0.09377188980579376
0.26095107197761536 0.26095107197761536
rl training, epoch4, iter0, batch700/1133, batch loss:0.26095107197761536, Training time:13447.394535779953
batch reward last col mean 0.1302056610584259 first col mean 0.1237696036696434 all mean 0.1290837675333023
0.3228395879268646 0.322839617729187
rl training, epoch4, iter0, batch701/1133, batch loss:0.322839617729187, Training time:13449.406465291977
batch reward last col mean 0.12519869208335876 first col mean 0.11537464708089828 all mean 0.1189417913556099
0.2817819118499756 0.2817818820476532
rl training, epoch4, iter0, batch702/1133, batch loss:0.2817818820476532, Training time:13450.971688270569
batch reward last col mean 0.0861033946275711 first col mean 0.10846739262342453 all mean 0.08661268651485443
0.2603389322757721 0.2603389322757721
rl training, epoch4, iter0, batch703/1133, batch loss:0.2603389322757721, Training time:13453.375957012177
batch reward last col mean 0.09695156663656235 first col mean 0.10852640122175217 all mean 0.09804598242044449
0.273787260055542 0.273787260055542
rl training, epoch4, iter0, batch704/1133, batch loss:0.273787260055542, Training time:13455.335930347443
batch reward last col mean 0.09669924527406693 first col mean 0.11097484827041626 all mean 0.10294368118047714
0.33305659890174866 0.33305659890174866
rl training, epoch4, iter0, batch705/1133, batch loss:0.33305659890174866, Training time:13457.059158563614
batch reward last col mean 0.10690942406654358 first col mean 0.100526362657547 all mean 0.105362169444561
0.251892626285553 0.251892626285553
rl training, epoch4, iter0, batch706/1133, batch loss:0.251892626285553, Training time:13459.107954740524
batch reward last col mean 0.11824756860733032 first col mean 0.09199885278940201 all mean 0.11552955955266953
0.3082021176815033 0.3082021176815033
rl training, epoch4, iter0, batch707/1133, batch loss:0.3082021176815033, Training time:13461.50181221962
batch reward last col mean 0.0938325822353363 first col mean 0.10793795436620712 all mean 0.09571526199579239
0.2825610637664795 0.2825610637664795
rl training, epoch4, iter0, batch708/1133, batch loss:0.2825610637664795, Training time:13463.25609087944
batch reward last col mean 0.10820558667182922 first col mean 0.125309556722641 all mean 0.10735604166984558
0.30645447969436646 0.30645447969436646
rl training, epoch4, iter0, batch709/1133, batch loss:0.30645447969436646, Training time:13465.1008746624
batch reward last col mean 0.12350159138441086 first col mean 0.10529975593090057 all mean 0.12397832423448563
0.3273266851902008 0.3273266851902008
rl training, epoch4, iter0, batch710/1133, batch loss:0.3273266851902008, Training time:13467.131702661514
batch reward last col mean 0.08621789515018463 first col mean 0.10073249042034149 all mean 0.09217751026153564
0.26259681582450867 0.26259681582450867
rl training, epoch4, iter0, batch711/1133, batch loss:0.26259681582450867, Training time:13469.252273082733
batch reward last col mean 0.10889463871717453 first col mean 0.11808891594409943 all mean 0.11167969554662704
0.37734970450401306 0.37734973430633545
rl training, epoch4, iter0, batch712/1133, batch loss:0.37734973430633545, Training time:13471.081325531006
batch reward last col mean 0.13818898797035217 first col mean 0.11125156283378601 all mean 0.1353202909231186
0.32744377851486206 0.32744377851486206
rl training, epoch4, iter0, batch713/1133, batch loss:0.32744377851486206, Training time:13473.607832431793
batch reward last col mean 0.09655522555112839 first col mean 0.11526639759540558 all mean 0.09560300409793854
0.24678458273410797 0.24678458273410797
rl training, epoch4, iter0, batch714/1133, batch loss:0.24678458273410797, Training time:13475.843674182892
batch reward last col mean 0.12333013862371445 first col mean 0.10135658830404282 all mean 0.1207752376794815
0.317751407623291 0.317751407623291
rl training, epoch4, iter0, batch715/1133, batch loss:0.317751407623291, Training time:13477.405351161957
batch reward last col mean 0.1258113533258438 first col mean 0.12610268592834473 all mean 0.11711037158966064
0.34325969219207764 0.34325969219207764
rl training, epoch4, iter0, batch716/1133, batch loss:0.34325969219207764, Training time:13479.108862400055
batch reward last col mean 0.08832955360412598 first col mean 0.11021843552589417 all mean 0.09335936605930328
0.25138378143310547 0.25138378143310547
rl training, epoch4, iter0, batch717/1133, batch loss:0.25138378143310547, Training time:13481.037530899048
batch reward last col mean 0.12574179470539093 first col mean 0.12241090089082718 all mean 0.12519578635692596
0.34220314025878906 0.34220314025878906
rl training, epoch4, iter0, batch718/1133, batch loss:0.34220314025878906, Training time:13482.976859807968
batch reward last col mean 0.10881864279508591 first col mean 0.10273440182209015 all mean 0.10931509733200073
0.291689932346344 0.291689932346344
rl training, epoch4, iter0, batch719/1133, batch loss:0.291689932346344, Training time:13484.482796907425
batch reward last col mean 0.09833978116512299 first col mean 0.12720909714698792 all mean 0.09933962672948837
0.30690011382102966 0.30690011382102966
rl training, epoch4, iter0, batch720/1133, batch loss:0.30690011382102966, Training time:13486.954629182816
batch reward last col mean 0.09318491816520691 first col mean 0.1213880181312561 all mean 0.10510410368442535
0.26141589879989624 0.26141589879989624
rl training, epoch4, iter0, batch721/1133, batch loss:0.26141589879989624, Training time:13488.680073022842
batch reward last col mean 0.1313009411096573 first col mean 0.10302606970071793 all mean 0.12178383022546768
0.27723053097724915 0.27723053097724915
rl training, epoch4, iter0, batch722/1133, batch loss:0.27723053097724915, Training time:13490.386482477188
batch reward last col mean 0.09161127358675003 first col mean 0.12751956284046173 all mean 0.10060442984104156
0.28540360927581787 0.28540360927581787
rl training, epoch4, iter0, batch723/1133, batch loss:0.28540360927581787, Training time:13492.456219911575
batch reward last col mean 0.06276366859674454 first col mean 0.11677668988704681 all mean 0.07987761497497559
0.2859571576118469 0.2859571576118469
rl training, epoch4, iter0, batch724/1133, batch loss:0.2859571576118469, Training time:13494.392046451569
batch reward last col mean 0.09352447092533112 first col mean 0.10469598323106766 all mean 0.09599922597408295
0.2747388780117035 0.2747388780117035
rl training, epoch4, iter0, batch725/1133, batch loss:0.2747388780117035, Training time:13496.30563378334
batch reward last col mean 0.10087452828884125 first col mean 0.11550037562847137 all mean 0.10601716488599777
0.2963366210460663 0.2963366210460663
rl training, epoch4, iter0, batch726/1133, batch loss:0.2963366210460663, Training time:13498.389364242554
batch reward last col mean 0.12177842855453491 first col mean 0.12444886565208435 all mean 0.1213001012802124
0.30571669340133667 0.30571669340133667
rl training, epoch4, iter0, batch727/1133, batch loss:0.30571669340133667, Training time:13500.344853639603
batch reward last col mean 0.11700377613306046 first col mean 0.0911572277545929 all mean 0.11236126720905304
0.3276444971561432 0.3276444971561432
rl training, epoch4, iter0, batch728/1133, batch loss:0.3276444971561432, Training time:13502.549339294434
batch reward last col mean 0.1099969819188118 first col mean 0.09786062687635422 all mean 0.10794525593519211
0.27775371074676514 0.27775371074676514
rl training, epoch4, iter0, batch729/1133, batch loss:0.27775371074676514, Training time:13504.622419118881
batch reward last col mean 0.09440605342388153 first col mean 0.11001232266426086 all mean 0.10138466209173203
0.27722784876823425 0.27722784876823425
rl training, epoch4, iter0, batch730/1133, batch loss:0.27722784876823425, Training time:13506.9707903862
batch reward last col mean 0.12218856066465378 first col mean 0.11371243000030518 all mean 0.11893434822559357
0.3519122302532196 0.3519122302532196
rl training, epoch4, iter0, batch731/1133, batch loss:0.3519122302532196, Training time:13508.859702587128
batch reward last col mean 0.11653327941894531 first col mean 0.10865656286478043 all mean 0.11690723150968552
0.29782164096832275 0.29782167077064514
rl training, epoch4, iter0, batch732/1133, batch loss:0.29782167077064514, Training time:13510.835373878479
batch reward last col mean 0.10619084537029266 first col mean 0.12007691711187363 all mean 0.1031738668680191
0.31355059146881104 0.31355059146881104
rl training, epoch4, iter0, batch733/1133, batch loss:0.31355059146881104, Training time:13512.951846122742
batch reward last col mean 0.09850528836250305 first col mean 0.09600985050201416 all mean 0.0948031023144722
0.2690197229385376 0.2690196931362152
rl training, epoch4, iter0, batch734/1133, batch loss:0.2690196931362152, Training time:13514.916044473648
batch reward last col mean 0.12866123020648956 first col mean 0.11239352822303772 all mean 0.12435796111822128
0.30305373668670654 0.30305373668670654
rl training, epoch4, iter0, batch735/1133, batch loss:0.30305373668670654, Training time:13516.831367015839
batch reward last col mean 0.10474856942892075 first col mean 0.10245003551244736 all mean 0.10715784132480621
0.3009507358074188 0.3009507358074188
rl training, epoch4, iter0, batch736/1133, batch loss:0.3009507358074188, Training time:13518.63571858406
batch reward last col mean 0.14015886187553406 first col mean 0.13299064338207245 all mean 0.13499969244003296
0.34213632345199585 0.34213632345199585
rl training, epoch4, iter0, batch737/1133, batch loss:0.34213632345199585, Training time:13520.706411838531
batch reward last col mean 0.12485764920711517 first col mean 0.11697374284267426 all mean 0.11899662017822266
0.291437566280365 0.291437566280365
rl training, epoch4, iter0, batch738/1133, batch loss:0.291437566280365, Training time:13523.189578771591
batch reward last col mean 0.12258818745613098 first col mean 0.11819931864738464 all mean 0.12340176105499268
0.28742319345474243 0.28742319345474243
rl training, epoch4, iter0, batch739/1133, batch loss:0.28742319345474243, Training time:13525.861646652222
batch reward last col mean 0.10157466679811478 first col mean 0.12980449199676514 all mean 0.10673406720161438
0.33596232533454895 0.33596232533454895
rl training, epoch4, iter0, batch740/1133, batch loss:0.33596232533454895, Training time:13528.268255233765
batch reward last col mean 0.08365486562252045 first col mean 0.12484872341156006 all mean 0.09818243235349655
0.3119407296180725 0.3119407296180725
rl training, epoch4, iter0, batch741/1133, batch loss:0.3119407296180725, Training time:13530.245130300522
batch reward last col mean 0.09223268926143646 first col mean 0.12446586787700653 all mean 0.09292679280042648
0.24929215013980865 0.24929215013980865
rl training, epoch4, iter0, batch742/1133, batch loss:0.24929215013980865, Training time:13532.449178934097
batch reward last col mean 0.09704641997814178 first col mean 0.09761720150709152 all mean 0.10394349694252014
0.3448195159435272 0.3448195159435272
rl training, epoch4, iter0, batch743/1133, batch loss:0.3448195159435272, Training time:13534.39747786522
batch reward last col mean 0.10223695635795593 first col mean 0.10244540870189667 all mean 0.10334600508213043
0.3110024333000183 0.3110024034976959
rl training, epoch4, iter0, batch744/1133, batch loss:0.3110024034976959, Training time:13536.42505645752
batch reward last col mean 0.1027071624994278 first col mean 0.10101557523012161 all mean 0.1067141443490982
0.2745636999607086 0.274563729763031
rl training, epoch4, iter0, batch745/1133, batch loss:0.274563729763031, Training time:13538.401272296906
batch reward last col mean 0.11470483243465424 first col mean 0.11958970129489899 all mean 0.1104554682970047
0.3408917486667633 0.3408917486667633
rl training, epoch4, iter0, batch746/1133, batch loss:0.3408917486667633, Training time:13540.829183101654
batch reward last col mean 0.1150531992316246 first col mean 0.11831966042518616 all mean 0.12128318846225739
0.33570414781570435 0.33570414781570435
rl training, epoch4, iter0, batch747/1133, batch loss:0.33570414781570435, Training time:13542.584319353104
batch reward last col mean 0.09815652668476105 first col mean 0.11183154582977295 all mean 0.09987469017505646
0.32800400257110596 0.32800400257110596
rl training, epoch4, iter0, batch748/1133, batch loss:0.32800400257110596, Training time:13544.903482437134
batch reward last col mean 0.09257592260837555 first col mean 0.10747973620891571 all mean 0.0970243290066719
0.3057786822319031 0.3057786822319031
rl training, epoch4, iter0, batch749/1133, batch loss:0.3057786822319031, Training time:13547.738035917282
batch reward last col mean 0.15385888516902924 first col mean 0.12786483764648438 all mean 0.14136336743831635
0.3568804860115051 0.3568805158138275
rl training, epoch4, iter0, batch750/1133, batch loss:0.3568805158138275, Training time:13549.114249944687
batch reward last col mean 0.09530115127563477 first col mean 0.1090492531657219 all mean 0.10259248316287994
0.3465702533721924 0.3465702533721924
rl training, epoch4, iter0, batch751/1133, batch loss:0.3465702533721924, Training time:13551.25773024559
batch reward last col mean 0.097566157579422 first col mean 0.10882048308849335 all mean 0.10205880552530289
0.29264765977859497 0.29264765977859497
rl training, epoch4, iter0, batch752/1133, batch loss:0.29264765977859497, Training time:13553.365555286407
batch reward last col mean 0.12334051728248596 first col mean 0.1107158288359642 all mean 0.11571623384952545
0.2950456440448761 0.2950456142425537
rl training, epoch4, iter0, batch753/1133, batch loss:0.2950456142425537, Training time:13555.861118555069
batch reward last col mean 0.12520362436771393 first col mean 0.10641185939311981 all mean 0.12444166839122772
0.31609591841697693 0.31609591841697693
rl training, epoch4, iter0, batch754/1133, batch loss:0.31609591841697693, Training time:13558.569610357285
batch reward last col mean 0.09441377222537994 first col mean 0.12046873569488525 all mean 0.10436214506626129
0.3033188581466675 0.3033188581466675
rl training, epoch4, iter0, batch755/1133, batch loss:0.3033188581466675, Training time:13560.471120595932
batch reward last col mean 0.11583063006401062 first col mean 0.12925542891025543 all mean 0.11328400671482086
0.3263234496116638 0.3263234496116638
rl training, epoch4, iter0, batch756/1133, batch loss:0.3263234496116638, Training time:13562.404057264328
batch reward last col mean 0.08597546070814133 first col mean 0.11813446879386902 all mean 0.09421257674694061
0.2933988571166992 0.2933988571166992
rl training, epoch4, iter0, batch757/1133, batch loss:0.2933988571166992, Training time:13564.699548006058
batch reward last col mean 0.07442928850650787 first col mean 0.11956769227981567 all mean 0.08310871571302414
0.29569900035858154 0.29569900035858154
rl training, epoch4, iter0, batch758/1133, batch loss:0.29569900035858154, Training time:13566.912307739258
batch reward last col mean 0.15599775314331055 first col mean 0.11416201293468475 all mean 0.13641948997974396
0.34172651171684265 0.34172651171684265
rl training, epoch4, iter0, batch759/1133, batch loss:0.34172651171684265, Training time:13568.688159227371
batch reward last col mean 0.13540486991405487 first col mean 0.1172066181898117 all mean 0.13254927098751068
0.3486049175262451 0.3486049175262451
rl training, epoch4, iter0, batch760/1133, batch loss:0.3486049175262451, Training time:13570.714756727219
batch reward last col mean 0.11834289133548737 first col mean 0.096120186150074 all mean 0.11357565224170685
0.2801033854484558 0.2801033556461334
rl training, epoch4, iter0, batch761/1133, batch loss:0.2801033556461334, Training time:13573.433110952377
batch reward last col mean 0.09501062333583832 first col mean 0.10495395213365555 all mean 0.09356596320867538
0.29903391003608704 0.29903391003608704
rl training, epoch4, iter0, batch762/1133, batch loss:0.29903391003608704, Training time:13576.731265068054
batch reward last col mean 0.1133432388305664 first col mean 0.12192382663488388 all mean 0.11943133920431137
0.3358161747455597 0.3358161449432373
rl training, epoch4, iter0, batch763/1133, batch loss:0.3358161449432373, Training time:13579.449324846268
batch reward last col mean 0.07646843791007996 first col mean 0.10993210971355438 all mean 0.0869993194937706
0.2434079349040985 0.2434079349040985
rl training, epoch4, iter0, batch764/1133, batch loss:0.2434079349040985, Training time:13582.058452606201
batch reward last col mean 0.13011139631271362 first col mean 0.12711165845394135 all mean 0.12023522704839706
0.31535032391548157 0.31535032391548157
rl training, epoch4, iter0, batch765/1133, batch loss:0.31535032391548157, Training time:13584.344086885452
batch reward last col mean 0.14658965170383453 first col mean 0.11666595935821533 all mean 0.13613665103912354
0.3337976336479187 0.3337976336479187
rl training, epoch4, iter0, batch766/1133, batch loss:0.3337976336479187, Training time:13586.535913228989
batch reward last col mean 0.13029897212982178 first col mean 0.10666520893573761 all mean 0.1289856731891632
0.33923524618148804 0.33923524618148804
rl training, epoch4, iter0, batch767/1133, batch loss:0.33923524618148804, Training time:13589.773094892502
batch reward last col mean 0.10809584707021713 first col mean 0.11171899735927582 all mean 0.10804075002670288
0.3162657916545868 0.3162657916545868
rl training, epoch4, iter0, batch768/1133, batch loss:0.3162657916545868, Training time:13591.899691343307
batch reward last col mean 0.1293593943119049 first col mean 0.09872733056545258 all mean 0.1257687509059906
0.30991291999816895 0.30991291999816895
rl training, epoch4, iter0, batch769/1133, batch loss:0.30991291999816895, Training time:13594.513775348663
batch reward last col mean 0.11821432411670685 first col mean 0.12268561124801636 all mean 0.12086544185876846
0.30898433923721313 0.30898433923721313
rl training, epoch4, iter0, batch770/1133, batch loss:0.30898433923721313, Training time:13597.08054113388
batch reward last col mean 0.17539286613464355 first col mean 0.1064525693655014 all mean 0.1639925092458725
0.38337820768356323 0.38337820768356323
rl training, epoch4, iter0, batch771/1133, batch loss:0.38337820768356323, Training time:13600.068066358566
batch reward last col mean 0.09338133037090302 first col mean 0.11908875405788422 all mean 0.1008114442229271
0.30583441257476807 0.30583441257476807
rl training, epoch4, iter0, batch772/1133, batch loss:0.30583441257476807, Training time:13602.365928888321
batch reward last col mean 0.08281300216913223 first col mean 0.1215190589427948 all mean 0.09773948788642883
0.3245094120502472 0.3245094120502472
rl training, epoch4, iter0, batch773/1133, batch loss:0.3245094120502472, Training time:13604.693289995193
batch reward last col mean 0.09908311069011688 first col mean 0.10423043370246887 all mean 0.10718231648206711
0.2962603271007538 0.2962603271007538
rl training, epoch4, iter0, batch774/1133, batch loss:0.2962603271007538, Training time:13606.812091827393
batch reward last col mean 0.10662156343460083 first col mean 0.1164989024400711 all mean 0.1072399914264679
0.3076336085796356 0.30763357877731323
rl training, epoch4, iter0, batch775/1133, batch loss:0.30763357877731323, Training time:13609.507891178131
batch reward last col mean 0.09281252324581146 first col mean 0.11544948071241379 all mean 0.09754884988069534
0.2629881799221039 0.2629881799221039
rl training, epoch4, iter0, batch776/1133, batch loss:0.2629881799221039, Training time:13612.080374240875
batch reward last col mean 0.12189212441444397 first col mean 0.1295493096113205 all mean 0.11476273089647293
0.29110661149024963 0.29110661149024963
rl training, epoch4, iter0, batch777/1133, batch loss:0.29110661149024963, Training time:13614.351597309113
batch reward last col mean 0.10913129150867462 first col mean 0.10501471161842346 all mean 0.10485401004552841
0.31750479340553284 0.31750479340553284
rl training, epoch4, iter0, batch778/1133, batch loss:0.31750479340553284, Training time:13616.632393598557
batch reward last col mean 0.1232512816786766 first col mean 0.0812339186668396 all mean 0.11857706308364868
0.29789218306541443 0.29789218306541443
rl training, epoch4, iter0, batch779/1133, batch loss:0.29789218306541443, Training time:13619.778636932373
batch reward last col mean 0.09640123695135117 first col mean 0.12309896945953369 all mean 0.10136926919221878
0.26099687814712524 0.26099687814712524
rl training, epoch4, iter0, batch780/1133, batch loss:0.26099687814712524, Training time:13622.543640375137
batch reward last col mean 0.10398057848215103 first col mean 0.11846812069416046 all mean 0.1060185506939888
0.30951443314552307 0.30951443314552307
rl training, epoch4, iter0, batch781/1133, batch loss:0.30951443314552307, Training time:13625.777188539505
batch reward last col mean 0.1057916060090065 first col mean 0.10988271236419678 all mean 0.10873690247535706
0.33587244153022766 0.33587244153022766
rl training, epoch4, iter0, batch782/1133, batch loss:0.33587244153022766, Training time:13628.102223396301
batch reward last col mean 0.11202680319547653 first col mean 0.12971454858779907 all mean 0.11607642471790314
0.35011646151542664 0.35011646151542664
rl training, epoch4, iter0, batch783/1133, batch loss:0.35011646151542664, Training time:13630.60181427002
batch reward last col mean 0.1071830540895462 first col mean 0.10869879275560379 all mean 0.11475440859794617
0.31919899582862854 0.31919899582862854
rl training, epoch4, iter0, batch784/1133, batch loss:0.31919899582862854, Training time:13632.528052330017
batch reward last col mean 0.0959649458527565 first col mean 0.1088642030954361 all mean 0.10314925014972687
0.35648784041404724 0.35648784041404724
rl training, epoch4, iter0, batch785/1133, batch loss:0.35648784041404724, Training time:13636.796090126038
batch reward last col mean 0.10493597388267517 first col mean 0.11484212428331375 all mean 0.10301047563552856
0.27653393149375916 0.27653393149375916
rl training, epoch4, iter0, batch786/1133, batch loss:0.27653393149375916, Training time:13639.6402759552
batch reward last col mean 0.09527520090341568 first col mean 0.11648532003164291 all mean 0.10539299994707108
0.2930945158004761 0.2930945158004761
rl training, epoch4, iter0, batch787/1133, batch loss:0.2930945158004761, Training time:13641.952580213547
batch reward last col mean 0.10899420082569122 first col mean 0.10256467014551163 all mean 0.11179759353399277
0.2895933985710144 0.2895933985710144
rl training, epoch4, iter0, batch788/1133, batch loss:0.2895933985710144, Training time:13644.827086925507
batch reward last col mean 0.11444012820720673 first col mean 0.11343680322170258 all mean 0.1121329739689827
0.31288865208625793 0.31288859248161316
rl training, epoch4, iter0, batch789/1133, batch loss:0.31288859248161316, Training time:13647.472476243973
batch reward last col mean 0.11653578281402588 first col mean 0.10242168605327606 all mean 0.11383095383644104
0.30183616280555725 0.30183616280555725
rl training, epoch4, iter0, batch790/1133, batch loss:0.30183616280555725, Training time:13649.599980831146
batch reward last col mean 0.08004038035869598 first col mean 0.09388608485460281 all mean 0.08699673414230347
0.2771282196044922 0.2771282196044922
rl training, epoch4, iter0, batch791/1133, batch loss:0.2771282196044922, Training time:13652.363258600235
batch reward last col mean 0.10123558342456818 first col mean 0.14560635387897491 all mean 0.11082222312688828
0.313385933637619 0.313385933637619
rl training, epoch4, iter0, batch792/1133, batch loss:0.313385933637619, Training time:13655.812527179718
batch reward last col mean 0.1147627979516983 first col mean 0.11477742344141006 all mean 0.11767933517694473
0.35850876569747925 0.35850876569747925
rl training, epoch4, iter0, batch793/1133, batch loss:0.35850876569747925, Training time:13659.384208202362
batch reward last col mean 0.099006786942482 first col mean 0.12051185965538025 all mean 0.10060470551252365
0.317173033952713 0.317173033952713
rl training, epoch4, iter0, batch794/1133, batch loss:0.317173033952713, Training time:13663.648180246353
batch reward last col mean 0.11010165512561798 first col mean 0.11294624209403992 all mean 0.10834172368049622
0.30438271164894104 0.30438271164894104
rl training, epoch4, iter0, batch795/1133, batch loss:0.30438271164894104, Training time:13666.076770544052
batch reward last col mean 0.10344007611274719 first col mean 0.11505650728940964 all mean 0.11289377510547638
0.32944396138191223 0.32944396138191223
rl training, epoch4, iter0, batch796/1133, batch loss:0.32944396138191223, Training time:13668.759838581085
batch reward last col mean 0.12046584486961365 first col mean 0.11463010311126709 all mean 0.11737065762281418
0.3124542832374573 0.3124542832374573
rl training, epoch4, iter0, batch797/1133, batch loss:0.3124542832374573, Training time:13670.970914840698
batch reward last col mean 0.1272699534893036 first col mean 0.124228835105896 all mean 0.1250092089176178
0.32212385535240173 0.32212385535240173
rl training, epoch4, iter0, batch798/1133, batch loss:0.32212385535240173, Training time:13673.263632297516
batch reward last col mean 0.12310920655727386 first col mean 0.11170001327991486 all mean 0.12021639943122864
0.31286782026290894 0.31286782026290894
rl training, epoch4, iter0, batch799/1133, batch loss:0.31286782026290894, Training time:13675.827586174011
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5141636863127285 Time: 101.52651524543762 s
loss of true 0.2250162638848794 loss of gen 0.18346802583860278 loss of other 0.10567939601549246 first score 0.12220607697963715
batch reward last col mean 0.10884244740009308 first col mean 0.1112770140171051 all mean 0.10590958595275879
0.31745439767837524 0.31745439767837524
rl training, epoch4, iter0, batch800/1133, batch loss:0.31745439767837524, Training time:13779.77573466301
batch reward last col mean 0.12510627508163452 first col mean 0.09964247047901154 all mean 0.12053481489419937
0.31239521503448486 0.31239521503448486
rl training, epoch4, iter0, batch801/1133, batch loss:0.31239521503448486, Training time:13782.011980772018
batch reward last col mean 0.10510389506816864 first col mean 0.12511828541755676 all mean 0.10753994435071945
0.28452274203300476 0.28452274203300476
rl training, epoch4, iter0, batch802/1133, batch loss:0.28452274203300476, Training time:13785.075075387955
batch reward last col mean 0.0940331444144249 first col mean 0.11347905546426773 all mean 0.09977158904075623
0.3010290563106537 0.3010290563106537
rl training, epoch4, iter0, batch803/1133, batch loss:0.3010290563106537, Training time:13787.575845003128
batch reward last col mean 0.10374539345502853 first col mean 0.10314472764730453 all mean 0.10492055118083954
0.2715357542037964 0.2715357542037964
rl training, epoch4, iter0, batch804/1133, batch loss:0.2715357542037964, Training time:13790.247994422913
batch reward last col mean 0.09939560294151306 first col mean 0.10590439289808273 all mean 0.10095495730638504
0.30569979548454285 0.30569979548454285
rl training, epoch4, iter0, batch805/1133, batch loss:0.30569979548454285, Training time:13793.044924974442
batch reward last col mean 0.11905413866043091 first col mean 0.11577914655208588 all mean 0.11455897241830826
0.31713035702705383 0.31713035702705383
rl training, epoch4, iter0, batch806/1133, batch loss:0.31713035702705383, Training time:13795.676261663437
batch reward last col mean 0.1357610821723938 first col mean 0.12233147025108337 all mean 0.13343781232833862
0.3226264417171478 0.3226264417171478
rl training, epoch4, iter0, batch807/1133, batch loss:0.3226264417171478, Training time:13799.332388877869
batch reward last col mean 0.12077077478170395 first col mean 0.13144373893737793 all mean 0.11868666857481003
0.3045681416988373 0.3045681416988373
rl training, epoch4, iter0, batch808/1133, batch loss:0.3045681416988373, Training time:13802.781314849854
batch reward last col mean 0.1173894852399826 first col mean 0.11728763580322266 all mean 0.11151140183210373
0.31482499837875366 0.31482502818107605
rl training, epoch4, iter0, batch809/1133, batch loss:0.31482502818107605, Training time:13805.179857254028
batch reward last col mean 0.09094862639904022 first col mean 0.10723066329956055 all mean 0.09592977166175842
0.27894189953804016 0.27894189953804016
rl training, epoch4, iter0, batch810/1133, batch loss:0.27894189953804016, Training time:13807.686693191528
batch reward last col mean 0.11443124711513519 first col mean 0.11197678744792938 all mean 0.11078552156686783
0.26517337560653687 0.26517337560653687
rl training, epoch4, iter0, batch811/1133, batch loss:0.26517337560653687, Training time:13810.026407003403
batch reward last col mean 0.08017940819263458 first col mean 0.11680029332637787 all mean 0.09396308660507202
0.29135751724243164 0.29135751724243164
rl training, epoch4, iter0, batch812/1133, batch loss:0.29135751724243164, Training time:13812.29276227951
batch reward last col mean 0.09170879423618317 first col mean 0.10503210127353668 all mean 0.09443347156047821
0.28326812386512756 0.28326818346977234
rl training, epoch4, iter0, batch813/1133, batch loss:0.28326818346977234, Training time:13814.619012117386
batch reward last col mean 0.1242632120847702 first col mean 0.102206751704216 all mean 0.11855011433362961
0.2915549874305725 0.2915549874305725
rl training, epoch4, iter0, batch814/1133, batch loss:0.2915549874305725, Training time:13816.563670635223
batch reward last col mean 0.09749127179384232 first col mean 0.10694213211536407 all mean 0.09965488314628601
0.28463685512542725 0.28463682532310486
rl training, epoch4, iter0, batch815/1133, batch loss:0.28463682532310486, Training time:13818.804983139038
batch reward last col mean 0.10368450731039047 first col mean 0.10795778036117554 all mean 0.10095424950122833
0.2818388044834137 0.2818388044834137
rl training, epoch4, iter0, batch816/1133, batch loss:0.2818388044834137, Training time:13821.011101722717
batch reward last col mean 0.09930725395679474 first col mean 0.0933937281370163 all mean 0.10180964320898056
0.30857470631599426 0.30857470631599426
rl training, epoch4, iter0, batch817/1133, batch loss:0.30857470631599426, Training time:13823.173253536224
batch reward last col mean 0.17337587475776672 first col mean 0.12509530782699585 all mean 0.1649041473865509
0.3331442177295685 0.3331442177295685
rl training, epoch4, iter0, batch818/1133, batch loss:0.3331442177295685, Training time:13825.543833971024
batch reward last col mean 0.09261994063854218 first col mean 0.08773316442966461 all mean 0.09453669935464859
0.2709643244743347 0.27096429467201233
rl training, epoch4, iter0, batch819/1133, batch loss:0.27096429467201233, Training time:13827.624277591705
batch reward last col mean 0.09583494067192078 first col mean 0.09012050926685333 all mean 0.10502135008573532
0.30010926723480225 0.30010926723480225
rl training, epoch4, iter0, batch820/1133, batch loss:0.30010926723480225, Training time:13830.344278335571
batch reward last col mean 0.10035347938537598 first col mean 0.101828932762146 all mean 0.10317850857973099
0.3120630979537964 0.3120630979537964
rl training, epoch4, iter0, batch821/1133, batch loss:0.3120630979537964, Training time:13832.317121982574
batch reward last col mean 0.10370267927646637 first col mean 0.1047113686800003 all mean 0.10198293626308441
0.2954048216342926 0.2954048216342926
rl training, epoch4, iter0, batch822/1133, batch loss:0.2954048216342926, Training time:13835.227096319199
batch reward last col mean 0.1123180016875267 first col mean 0.10969430953264236 all mean 0.1144464984536171
0.26877447962760925 0.26877447962760925
rl training, epoch4, iter0, batch823/1133, batch loss:0.26877447962760925, Training time:13838.093835353851
batch reward last col mean 0.12577639520168304 first col mean 0.10679341107606888 all mean 0.11944398283958435
0.29160672426223755 0.29160669445991516
rl training, epoch4, iter0, batch824/1133, batch loss:0.29160669445991516, Training time:13840.344451189041
batch reward last col mean 0.14318814873695374 first col mean 0.11841295659542084 all mean 0.14090290665626526
0.3145173490047455 0.3145173490047455
rl training, epoch4, iter0, batch825/1133, batch loss:0.3145173490047455, Training time:13842.299632072449
batch reward last col mean 0.10293934494256973 first col mean 0.1011921688914299 all mean 0.10111726820468903
0.2641780376434326 0.2641780376434326
rl training, epoch4, iter0, batch826/1133, batch loss:0.2641780376434326, Training time:13844.60536122322
batch reward last col mean 0.09893176704645157 first col mean 0.11023537814617157 all mean 0.10644105821847916
0.3070780634880066 0.3070780634880066
rl training, epoch4, iter0, batch827/1133, batch loss:0.3070780634880066, Training time:13846.355870962143
batch reward last col mean 0.09059643000364304 first col mean 0.10467264801263809 all mean 0.0980754941701889
0.24983735382556915 0.24983735382556915
rl training, epoch4, iter0, batch828/1133, batch loss:0.24983735382556915, Training time:13848.281628131866
batch reward last col mean 0.12740984559059143 first col mean 0.11446493864059448 all mean 0.12637531757354736
0.33891531825065613 0.33891531825065613
rl training, epoch4, iter0, batch829/1133, batch loss:0.33891531825065613, Training time:13850.656089544296
batch reward last col mean 0.0857856348156929 first col mean 0.11265280842781067 all mean 0.0965057909488678
0.28471487760543823 0.28471487760543823
rl training, epoch4, iter0, batch830/1133, batch loss:0.28471487760543823, Training time:13852.792992830276
batch reward last col mean 0.10254022479057312 first col mean 0.12010161578655243 all mean 0.10370638966560364
0.28079351782798767 0.28079351782798767
rl training, epoch4, iter0, batch831/1133, batch loss:0.28079351782798767, Training time:13855.202643156052
batch reward last col mean 0.11939931660890579 first col mean 0.10889184474945068 all mean 0.11718485504388809
0.316012978553772 0.316012978553772
rl training, epoch4, iter0, batch832/1133, batch loss:0.316012978553772, Training time:13857.176301240921
batch reward last col mean 0.11824126541614532 first col mean 0.12103584408760071 all mean 0.11566072702407837
0.3182278871536255 0.3182278573513031
rl training, epoch4, iter0, batch833/1133, batch loss:0.3182278573513031, Training time:13859.049272537231
batch reward last col mean 0.08882313966751099 first col mean 0.11247825622558594 all mean 0.0941726565361023
0.2717989385128021 0.2717989385128021
rl training, epoch4, iter0, batch834/1133, batch loss:0.2717989385128021, Training time:13861.134551048279
batch reward last col mean 0.1134733036160469 first col mean 0.1297895908355713 all mean 0.11069401353597641
0.2505452036857605 0.2505452036857605
rl training, epoch4, iter0, batch835/1133, batch loss:0.2505452036857605, Training time:13863.333099365234
batch reward last col mean 0.0881616622209549 first col mean 0.10823192447423935 all mean 0.0917055755853653
0.24555550515651703 0.24555550515651703
rl training, epoch4, iter0, batch836/1133, batch loss:0.24555550515651703, Training time:13865.379930496216
batch reward last col mean 0.08285112679004669 first col mean 0.08978931605815887 all mean 0.09204985946416855
0.2766697108745575 0.2766697108745575
rl training, epoch4, iter0, batch837/1133, batch loss:0.2766697108745575, Training time:13867.472627162933
batch reward last col mean 0.14624905586242676 first col mean 0.11770296096801758 all mean 0.1390342265367508
0.33597078919410706 0.33597078919410706
rl training, epoch4, iter0, batch838/1133, batch loss:0.33597078919410706, Training time:13870.369045257568
batch reward last col mean 0.12643513083457947 first col mean 0.11335742473602295 all mean 0.1216113269329071
0.29278773069381714 0.29278773069381714
rl training, epoch4, iter0, batch839/1133, batch loss:0.29278773069381714, Training time:13872.301792621613
batch reward last col mean 0.11201201379299164 first col mean 0.1186583936214447 all mean 0.11438697576522827
0.29936403036117554 0.29936403036117554
rl training, epoch4, iter0, batch840/1133, batch loss:0.29936403036117554, Training time:13875.41287946701
batch reward last col mean 0.10518753528594971 first col mean 0.10700824111700058 all mean 0.10423441976308823
0.3034208416938782 0.3034208416938782
rl training, epoch4, iter0, batch841/1133, batch loss:0.3034208416938782, Training time:13877.662074804306
batch reward last col mean 0.1111757904291153 first col mean 0.12262272834777832 all mean 0.10972025990486145
0.2775524854660034 0.27755245566368103
rl training, epoch4, iter0, batch842/1133, batch loss:0.27755245566368103, Training time:13879.755653381348
batch reward last col mean 0.12367920577526093 first col mean 0.12053455412387848 all mean 0.11779764294624329
0.29994356632232666 0.29994356632232666
rl training, epoch4, iter0, batch843/1133, batch loss:0.29994356632232666, Training time:13881.261785507202
batch reward last col mean 0.09123485535383224 first col mean 0.11941079050302505 all mean 0.09895093739032745
0.3131311237812042 0.3131311237812042
rl training, epoch4, iter0, batch844/1133, batch loss:0.3131311237812042, Training time:13883.341014623642
batch reward last col mean 0.11320971697568893 first col mean 0.13013812899589539 all mean 0.11552617698907852
0.2768484354019165 0.2768484055995941
rl training, epoch4, iter0, batch845/1133, batch loss:0.2768484055995941, Training time:13885.807571411133
batch reward last col mean 0.14152878522872925 first col mean 0.11227752268314362 all mean 0.13512122631072998
0.3507675528526306 0.350767582654953
rl training, epoch4, iter0, batch846/1133, batch loss:0.350767582654953, Training time:13888.247730731964
batch reward last col mean 0.13677294552326202 first col mean 0.12189360707998276 all mean 0.13373160362243652
0.3329484760761261 0.3329484760761261
rl training, epoch4, iter0, batch847/1133, batch loss:0.3329484760761261, Training time:13889.996631383896
batch reward last col mean 0.0931464284658432 first col mean 0.09443028271198273 all mean 0.09869012981653214
0.3051932156085968 0.3051932156085968
rl training, epoch4, iter0, batch848/1133, batch loss:0.3051932156085968, Training time:13892.19337439537
batch reward last col mean 0.10191747546195984 first col mean 0.10102877020835876 all mean 0.10634799301624298
0.3002665638923645 0.3002665638923645
rl training, epoch4, iter0, batch849/1133, batch loss:0.3002665638923645, Training time:13893.932804346085
batch reward last col mean 0.08627231419086456 first col mean 0.12986207008361816 all mean 0.09272562712430954
0.31311100721359253 0.31311100721359253
rl training, epoch4, iter0, batch850/1133, batch loss:0.31311100721359253, Training time:13895.864842176437
batch reward last col mean 0.11504410207271576 first col mean 0.12124182283878326 all mean 0.11067177355289459
0.2872832715511322 0.2872832715511322
rl training, epoch4, iter0, batch851/1133, batch loss:0.2872832715511322, Training time:13897.984228134155
batch reward last col mean 0.11702128499746323 first col mean 0.1063266173005104 all mean 0.11732666939496994
0.27540791034698486 0.27540791034698486
rl training, epoch4, iter0, batch852/1133, batch loss:0.27540791034698486, Training time:13900.637042045593
batch reward last col mean 0.11353161931037903 first col mean 0.11246392130851746 all mean 0.11543700844049454
0.3176988363265991 0.31769880652427673
rl training, epoch4, iter0, batch853/1133, batch loss:0.31769880652427673, Training time:13903.133512735367
batch reward last col mean 0.1605791449546814 first col mean 0.10953433066606522 all mean 0.14507707953453064
0.3715822696685791 0.3715822696685791
rl training, epoch4, iter0, batch854/1133, batch loss:0.3715822696685791, Training time:13905.595727443695
batch reward last col mean 0.10914649069309235 first col mean 0.12511923909187317 all mean 0.10866028070449829
0.3000844120979309 0.3000844120979309
rl training, epoch4, iter0, batch855/1133, batch loss:0.3000844120979309, Training time:13908.169523239136
batch reward last col mean 0.12805035710334778 first col mean 0.094122976064682 all mean 0.12345055490732193
0.3325248062610626 0.3325248062610626
rl training, epoch4, iter0, batch856/1133, batch loss:0.3325248062610626, Training time:13911.342196464539
batch reward last col mean 0.07561033964157104 first col mean 0.11794020980596542 all mean 0.0873769149184227
0.2927255928516388 0.2927255928516388
rl training, epoch4, iter0, batch857/1133, batch loss:0.2927255928516388, Training time:13913.591482639313
batch reward last col mean 0.09776864945888519 first col mean 0.10169211030006409 all mean 0.10220803320407867
0.2695589065551758 0.2695589065551758
rl training, epoch4, iter0, batch858/1133, batch loss:0.2695589065551758, Training time:13915.725311040878
batch reward last col mean 0.11558318138122559 first col mean 0.108721062541008 all mean 0.11520256847143173
0.2796843945980072 0.2796843647956848
rl training, epoch4, iter0, batch859/1133, batch loss:0.2796843647956848, Training time:13917.686780929565
batch reward last col mean 0.10829361528158188 first col mean 0.12662766873836517 all mean 0.1076039969921112
0.2937982380390167 0.2937982380390167
rl training, epoch4, iter0, batch860/1133, batch loss:0.2937982380390167, Training time:13919.552675962448
batch reward last col mean 0.12577003240585327 first col mean 0.12628887593746185 all mean 0.12485089153051376
0.3188987076282501 0.3188987076282501
rl training, epoch4, iter0, batch861/1133, batch loss:0.3188987076282501, Training time:13921.726611375809
batch reward last col mean 0.15230372548103333 first col mean 0.118736132979393 all mean 0.14379474520683289
0.3606186509132385 0.3606186509132385
rl training, epoch4, iter0, batch862/1133, batch loss:0.3606186509132385, Training time:13923.829381465912
batch reward last col mean 0.11224722862243652 first col mean 0.09784336388111115 all mean 0.11190515756607056
0.32985761761665344 0.32985761761665344
rl training, epoch4, iter0, batch863/1133, batch loss:0.32985761761665344, Training time:13926.082354784012
batch reward last col mean 0.10389649868011475 first col mean 0.1112128272652626 all mean 0.10793904215097427
0.3066308796405792 0.3066308796405792
rl training, epoch4, iter0, batch864/1133, batch loss:0.3066308796405792, Training time:13927.369458675385
batch reward last col mean 0.09768194705247879 first col mean 0.1038353443145752 all mean 0.10575012862682343
0.3121943771839142 0.3121943771839142
rl training, epoch4, iter0, batch865/1133, batch loss:0.3121943771839142, Training time:13929.189761638641
batch reward last col mean 0.10383881628513336 first col mean 0.12099063396453857 all mean 0.10735703259706497
0.31008657813072205 0.31008657813072205
rl training, epoch4, iter0, batch866/1133, batch loss:0.31008657813072205, Training time:13931.14487528801
batch reward last col mean 0.09947676956653595 first col mean 0.10859745740890503 all mean 0.10036799311637878
0.2966597378253937 0.2966597378253937
rl training, epoch4, iter0, batch867/1133, batch loss:0.2966597378253937, Training time:13933.298164606094
batch reward last col mean 0.12133437395095825 first col mean 0.1246270090341568 all mean 0.12786948680877686
0.31916746497154236 0.31916746497154236
rl training, epoch4, iter0, batch868/1133, batch loss:0.31916746497154236, Training time:13935.258392810822
batch reward last col mean 0.10488645732402802 first col mean 0.11465536057949066 all mean 0.1083880141377449
0.2992726266384125 0.2992725968360901
rl training, epoch4, iter0, batch869/1133, batch loss:0.2992725968360901, Training time:13936.889330625534
batch reward last col mean 0.11513470113277435 first col mean 0.11288367956876755 all mean 0.11885329335927963
0.30060380697250366 0.3006037771701813
rl training, epoch4, iter0, batch870/1133, batch loss:0.3006037771701813, Training time:13938.567153930664
batch reward last col mean 0.0650324821472168 first col mean 0.1262652575969696 all mean 0.08192939311265945
0.2703932225704193 0.2703932225704193
rl training, epoch4, iter0, batch871/1133, batch loss:0.2703932225704193, Training time:13940.31181359291
batch reward last col mean 0.12068774551153183 first col mean 0.13128060102462769 all mean 0.11975240707397461
0.3161429762840271 0.3161429762840271
rl training, epoch4, iter0, batch872/1133, batch loss:0.3161429762840271, Training time:13942.214563846588
batch reward last col mean 0.14514006674289703 first col mean 0.12164688855409622 all mean 0.1367352455854416
0.3087840974330902 0.3087840974330902
rl training, epoch4, iter0, batch873/1133, batch loss:0.3087840974330902, Training time:13943.876045703888
batch reward last col mean 0.1094224750995636 first col mean 0.11166087538003922 all mean 0.10661153495311737
0.29579785466194153 0.29579785466194153
rl training, epoch4, iter0, batch874/1133, batch loss:0.29579785466194153, Training time:13945.679536104202
batch reward last col mean 0.10022693872451782 first col mean 0.1228855550289154 all mean 0.10247798264026642
0.26842010021209717 0.26842010021209717
rl training, epoch4, iter0, batch875/1133, batch loss:0.26842010021209717, Training time:13947.420428037643
batch reward last col mean 0.0917491763830185 first col mean 0.11036232113838196 all mean 0.09500187635421753
0.2666180431842804 0.2666180431842804
rl training, epoch4, iter0, batch876/1133, batch loss:0.2666180431842804, Training time:13949.17168879509
batch reward last col mean 0.12133404612541199 first col mean 0.11876644939184189 all mean 0.1250087469816208
0.3014730215072632 0.3014730215072632
rl training, epoch4, iter0, batch877/1133, batch loss:0.3014730215072632, Training time:13950.534409046173
batch reward last col mean 0.1335574984550476 first col mean 0.12063776701688766 all mean 0.1257593333721161
0.33850234746932983 0.33850231766700745
rl training, epoch4, iter0, batch878/1133, batch loss:0.33850231766700745, Training time:13952.09514284134
batch reward last col mean 0.11266963928937912 first col mean 0.10577815771102905 all mean 0.10940691083669662
0.3049543797969818 0.3049543797969818
rl training, epoch4, iter0, batch879/1133, batch loss:0.3049543797969818, Training time:13954.262491703033
batch reward last col mean 0.08800595998764038 first col mean 0.11834284663200378 all mean 0.09185086190700531
0.28485044836997986 0.28485044836997986
rl training, epoch4, iter0, batch880/1133, batch loss:0.28485044836997986, Training time:13956.168181180954
batch reward last col mean 0.14833638072013855 first col mean 0.11378409713506699 all mean 0.1389726847410202
0.35843250155448914 0.3584325313568115
rl training, epoch4, iter0, batch881/1133, batch loss:0.3584325313568115, Training time:13957.98318529129
batch reward last col mean 0.0978701189160347 first col mean 0.10921278595924377 all mean 0.10520800203084946
0.32079818844795227 0.32079818844795227
rl training, epoch4, iter0, batch882/1133, batch loss:0.32079818844795227, Training time:13959.812811613083
batch reward last col mean 0.09459047019481659 first col mean 0.11563186347484589 all mean 0.10084754973649979
0.2599504590034485 0.2599504292011261
rl training, epoch4, iter0, batch883/1133, batch loss:0.2599504292011261, Training time:13961.372698068619
batch reward last col mean 0.13320887088775635 first col mean 0.12339888513088226 all mean 0.1309913545846939
0.3472030460834503 0.3472030460834503
rl training, epoch4, iter0, batch884/1133, batch loss:0.3472030460834503, Training time:13964.115593910217
batch reward last col mean 0.11699321120977402 first col mean 0.10626653581857681 all mean 0.11941121518611908
0.3189764618873596 0.3189764618873596
rl training, epoch4, iter0, batch885/1133, batch loss:0.3189764618873596, Training time:13966.917637348175
batch reward last col mean 0.0884697362780571 first col mean 0.1086093857884407 all mean 0.09560489654541016
0.2965984642505646 0.2965984642505646
rl training, epoch4, iter0, batch886/1133, batch loss:0.2965984642505646, Training time:13968.803122758865
batch reward last col mean 0.10263404250144958 first col mean 0.12320105731487274 all mean 0.10426130890846252
0.2795848250389099 0.2795848250389099
rl training, epoch4, iter0, batch887/1133, batch loss:0.2795848250389099, Training time:13970.432909488678
batch reward last col mean 0.12465976923704147 first col mean 0.13782213628292084 all mean 0.12627610564231873
0.30569031834602356 0.30569031834602356
rl training, epoch4, iter0, batch888/1133, batch loss:0.30569031834602356, Training time:13971.95240855217
batch reward last col mean 0.10890301316976547 first col mean 0.129980206489563 all mean 0.11829676479101181
0.3332827389240265 0.3332827389240265
rl training, epoch4, iter0, batch889/1133, batch loss:0.3332827389240265, Training time:13973.638985157013
batch reward last col mean 0.0966125875711441 first col mean 0.1110786497592926 all mean 0.10306328535079956
0.29080432653427124 0.29080435633659363
rl training, epoch4, iter0, batch890/1133, batch loss:0.29080435633659363, Training time:13975.019595623016
batch reward last col mean 0.15013663470745087 first col mean 0.12636476755142212 all mean 0.13763076066970825
0.3591631352901459 0.3591631352901459
rl training, epoch4, iter0, batch891/1133, batch loss:0.3591631352901459, Training time:13976.638393163681
batch reward last col mean 0.11443162709474564 first col mean 0.13150179386138916 all mean 0.12466815859079361
0.3293384909629822 0.3293384611606598
rl training, epoch4, iter0, batch892/1133, batch loss:0.3293384611606598, Training time:13978.234729766846
batch reward last col mean 0.11052994430065155 first col mean 0.12887157499790192 all mean 0.10925431549549103
0.32380348443984985 0.32380348443984985
rl training, epoch4, iter0, batch893/1133, batch loss:0.32380348443984985, Training time:13980.23726439476
batch reward last col mean 0.12852279841899872 first col mean 0.13554830849170685 all mean 0.1251983493566513
0.2594737708568573 0.2594737708568573
rl training, epoch4, iter0, batch894/1133, batch loss:0.2594737708568573, Training time:13981.531492471695
batch reward last col mean 0.1521008461713791 first col mean 0.11373525112867355 all mean 0.13904517889022827
0.312818318605423 0.3128182888031006
rl training, epoch4, iter0, batch895/1133, batch loss:0.3128182888031006, Training time:13983.615336179733
batch reward last col mean 0.09611281007528305 first col mean 0.10444872826337814 all mean 0.09659887850284576
0.26802849769592285 0.26802849769592285
rl training, epoch4, iter0, batch896/1133, batch loss:0.26802849769592285, Training time:13985.145080566406
batch reward last col mean 0.13839714229106903 first col mean 0.11358954012393951 all mean 0.12932634353637695
0.2801417410373688 0.2801417410373688
rl training, epoch4, iter0, batch897/1133, batch loss:0.2801417410373688, Training time:13986.861282110214
batch reward last col mean 0.11999836564064026 first col mean 0.14549803733825684 all mean 0.1203514114022255
0.29804885387420654 0.29804885387420654
rl training, epoch4, iter0, batch898/1133, batch loss:0.29804885387420654, Training time:13988.417940855026
batch reward last col mean 0.09469962120056152 first col mean 0.12864099442958832 all mean 0.10256925970315933
0.27026841044425964 0.27026841044425964
rl training, epoch4, iter0, batch899/1133, batch loss:0.27026841044425964, Training time:13990.156736135483
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5109959176864018 Time: 96.92068099975586 s
loss of true 0.22449500749622522 loss of gen 0.18032031535234266 loss of other 0.10618059454684697 first score 0.12091389298439026
batch reward last col mean 0.0888601690530777 first col mean 0.09878356009721756 all mean 0.09503202140331268
0.27563267946243286 0.27563267946243286
rl training, epoch4, iter0, batch900/1133, batch loss:0.27563267946243286, Training time:14088.48158288002
batch reward last col mean 0.09620800614356995 first col mean 0.09945476800203323 all mean 0.10066420584917068
0.2797021269798279 0.2797021269798279
rl training, epoch4, iter0, batch901/1133, batch loss:0.2797021269798279, Training time:14089.934921264648
batch reward last col mean 0.05559607595205307 first col mean 0.10875575989484787 all mean 0.06991807371377945
0.21825571358203888 0.21825574338436127
rl training, epoch4, iter0, batch902/1133, batch loss:0.21825574338436127, Training time:14091.636074066162
batch reward last col mean 0.13708263635635376 first col mean 0.12231166660785675 all mean 0.13131970167160034
0.3178531527519226 0.3178531527519226
rl training, epoch4, iter0, batch903/1133, batch loss:0.3178531527519226, Training time:14092.911764860153
batch reward last col mean 0.08186031877994537 first col mean 0.09350959956645966 all mean 0.08487681299448013
0.24640803039073944 0.24640803039073944
rl training, epoch4, iter0, batch904/1133, batch loss:0.24640803039073944, Training time:14094.408685922623
batch reward last col mean 0.07687897980213165 first col mean 0.11108572781085968 all mean 0.08351621776819229
0.2724967300891876 0.2724967300891876
rl training, epoch4, iter0, batch905/1133, batch loss:0.2724967300891876, Training time:14095.85748243332
batch reward last col mean 0.09935081005096436 first col mean 0.11681713908910751 all mean 0.10176454484462738
0.30767834186553955 0.30767834186553955
rl training, epoch4, iter0, batch906/1133, batch loss:0.30767834186553955, Training time:14097.686256885529
batch reward last col mean 0.08867698907852173 first col mean 0.09638188779354095 all mean 0.09267017990350723
0.28758692741394043 0.28758692741394043
rl training, epoch4, iter0, batch907/1133, batch loss:0.28758692741394043, Training time:14099.280179023743
batch reward last col mean 0.09241580963134766 first col mean 0.11825013160705566 all mean 0.09541410952806473
0.3135514557361603 0.3135514557361603
rl training, epoch4, iter0, batch908/1133, batch loss:0.3135514557361603, Training time:14101.107347488403
batch reward last col mean 0.13516606390476227 first col mean 0.09618410468101501 all mean 0.12436974793672562
0.3350968360900879 0.33509689569473267
rl training, epoch4, iter0, batch909/1133, batch loss:0.33509689569473267, Training time:14102.530968666077
batch reward last col mean 0.10973796248435974 first col mean 0.11162005364894867 all mean 0.10898881405591965
0.26664793491363525 0.26664793491363525
rl training, epoch4, iter0, batch910/1133, batch loss:0.26664793491363525, Training time:14103.988996744156
batch reward last col mean 0.10389231890439987 first col mean 0.09834305197000504 all mean 0.10527878999710083
0.2836519181728363 0.2836519181728363
rl training, epoch4, iter0, batch911/1133, batch loss:0.2836519181728363, Training time:14105.378044843674
batch reward last col mean 0.09167942404747009 first col mean 0.0846807211637497 all mean 0.09589199721813202
0.24941818416118622 0.24941818416118622
rl training, epoch4, iter0, batch912/1133, batch loss:0.24941818416118622, Training time:14106.890691518784
batch reward last col mean 0.09146629273891449 first col mean 0.08821083605289459 all mean 0.094785176217556
0.27992597222328186 0.27992597222328186
rl training, epoch4, iter0, batch913/1133, batch loss:0.27992597222328186, Training time:14108.886188268661
batch reward last col mean 0.10706297308206558 first col mean 0.0998261347413063 all mean 0.10606774687767029
0.26173868775367737 0.26173868775367737
rl training, epoch4, iter0, batch914/1133, batch loss:0.26173868775367737, Training time:14111.031874656677
batch reward last col mean 0.1488635540008545 first col mean 0.0923294872045517 all mean 0.12879064679145813
0.2986711859703064 0.2986711859703064
rl training, epoch4, iter0, batch915/1133, batch loss:0.2986711859703064, Training time:14112.626960039139
batch reward last col mean 0.11221779882907867 first col mean 0.11778660118579865 all mean 0.11561369150876999
0.3197835385799408 0.3197835385799408
rl training, epoch4, iter0, batch916/1133, batch loss:0.3197835385799408, Training time:14114.70411157608
batch reward last col mean 0.09243079274892807 first col mean 0.10670175403356552 all mean 0.09283824265003204
0.28587454557418823 0.28587454557418823
rl training, epoch4, iter0, batch917/1133, batch loss:0.28587454557418823, Training time:14116.527497768402
batch reward last col mean 0.11323700845241547 first col mean 0.12658348679542542 all mean 0.11192407459020615
0.2743428945541382 0.2743428945541382
rl training, epoch4, iter0, batch918/1133, batch loss:0.2743428945541382, Training time:14118.685145378113
batch reward last col mean 0.09538722038269043 first col mean 0.1294950246810913 all mean 0.10209193080663681
0.2947746813297272 0.2947746813297272
rl training, epoch4, iter0, batch919/1133, batch loss:0.2947746813297272, Training time:14120.255951881409
batch reward last col mean 0.11476456373929977 first col mean 0.10540175437927246 all mean 0.10730981081724167
0.3127753734588623 0.3127753734588623
rl training, epoch4, iter0, batch920/1133, batch loss:0.3127753734588623, Training time:14122.357098579407
batch reward last col mean 0.1239536702632904 first col mean 0.11768543720245361 all mean 0.1175597757101059
0.32808050513267517 0.32808050513267517
rl training, epoch4, iter0, batch921/1133, batch loss:0.32808050513267517, Training time:14123.835551738739
batch reward last col mean 0.10159043967723846 first col mean 0.1039508506655693 all mean 0.10384847968816757
0.2923833131790161 0.2923833131790161
rl training, epoch4, iter0, batch922/1133, batch loss:0.2923833131790161, Training time:14125.556771755219
batch reward last col mean 0.08446253836154938 first col mean 0.11105851083993912 all mean 0.09188395738601685
0.2917817234992981 0.2917816936969757
rl training, epoch4, iter0, batch923/1133, batch loss:0.2917816936969757, Training time:14127.165947198868
batch reward last col mean 0.09821932762861252 first col mean 0.11950817704200745 all mean 0.10814929008483887
0.31285780668258667 0.31285780668258667
rl training, epoch4, iter0, batch924/1133, batch loss:0.31285780668258667, Training time:14128.540587186813
batch reward last col mean 0.13683968782424927 first col mean 0.1189909428358078 all mean 0.12822002172470093
0.3089348077774048 0.3089348077774048
rl training, epoch4, iter0, batch925/1133, batch loss:0.3089348077774048, Training time:14130.5144033432
batch reward last col mean 0.10316532105207443 first col mean 0.11035485565662384 all mean 0.10570172220468521
0.30604925751686096 0.30604928731918335
rl training, epoch4, iter0, batch926/1133, batch loss:0.30604928731918335, Training time:14132.324656009674
batch reward last col mean 0.08671706914901733 first col mean 0.10827270150184631 all mean 0.09287530928850174
0.2613692581653595 0.2613692581653595
rl training, epoch4, iter0, batch927/1133, batch loss:0.2613692581653595, Training time:14134.247968196869
batch reward last col mean 0.08099593222141266 first col mean 0.13030871748924255 all mean 0.09605982899665833
0.31755807995796204 0.31755807995796204
rl training, epoch4, iter0, batch928/1133, batch loss:0.31755807995796204, Training time:14136.21104335785
batch reward last col mean 0.1024857833981514 first col mean 0.12321778386831284 all mean 0.10678884387016296
0.3192644417285919 0.3192644417285919
rl training, epoch4, iter0, batch929/1133, batch loss:0.3192644417285919, Training time:14137.731320142746
batch reward last col mean 0.07093095034360886 first col mean 0.10435444116592407 all mean 0.08210344612598419
0.25794216990470886 0.25794216990470886
rl training, epoch4, iter0, batch930/1133, batch loss:0.25794216990470886, Training time:14139.231554746628
batch reward last col mean 0.11346578598022461 first col mean 0.12339020520448685 all mean 0.11306297779083252
0.3118327260017395 0.3118327558040619
rl training, epoch4, iter0, batch931/1133, batch loss:0.3118327558040619, Training time:14140.69217991829
batch reward last col mean 0.10976177453994751 first col mean 0.1073530837893486 all mean 0.11160074174404144
0.28551262617111206 0.2855125963687897
rl training, epoch4, iter0, batch932/1133, batch loss:0.2855125963687897, Training time:14142.008706331253
batch reward last col mean 0.09692956507205963 first col mean 0.1002112478017807 all mean 0.0993674024939537
0.2954445779323578 0.2954445779323578
rl training, epoch4, iter0, batch933/1133, batch loss:0.2954445779323578, Training time:14143.89003109932
batch reward last col mean 0.09124364703893661 first col mean 0.10037550330162048 all mean 0.0967816561460495
0.3066123127937317 0.3066123127937317
rl training, epoch4, iter0, batch934/1133, batch loss:0.3066123127937317, Training time:14145.555626630783
batch reward last col mean 0.08800551295280457 first col mean 0.1050565168261528 all mean 0.09100444614887238
0.26270443201065063 0.26270443201065063
rl training, epoch4, iter0, batch935/1133, batch loss:0.26270443201065063, Training time:14147.04532790184
batch reward last col mean 0.08896920084953308 first col mean 0.09523595869541168 all mean 0.09490539878606796
0.3010213077068329 0.3010213077068329
rl training, epoch4, iter0, batch936/1133, batch loss:0.3010213077068329, Training time:14148.829599142075
batch reward last col mean 0.08874920755624771 first col mean 0.10377548635005951 all mean 0.08723645657300949
0.28894469141960144 0.28894466161727905
rl training, epoch4, iter0, batch937/1133, batch loss:0.28894466161727905, Training time:14151.004853010178
batch reward last col mean 0.09898032993078232 first col mean 0.09141320735216141 all mean 0.09803719073534012
0.26845017075538635 0.26845017075538635
rl training, epoch4, iter0, batch938/1133, batch loss:0.26845017075538635, Training time:14152.673200130463
batch reward last col mean 0.12594613432884216 first col mean 0.13697710633277893 all mean 0.12598514556884766
0.3715219795703888 0.3715219795703888
rl training, epoch4, iter0, batch939/1133, batch loss:0.3715219795703888, Training time:14154.533147573471
batch reward last col mean 0.11649022251367569 first col mean 0.1025090292096138 all mean 0.1133139356970787
0.2715768814086914 0.2715768814086914
rl training, epoch4, iter0, batch940/1133, batch loss:0.2715768814086914, Training time:14156.122117757797
batch reward last col mean 0.12701945006847382 first col mean 0.10578013211488724 all mean 0.1265605390071869
0.35821959376335144 0.35821959376335144
rl training, epoch4, iter0, batch941/1133, batch loss:0.35821959376335144, Training time:14157.9424431324
batch reward last col mean 0.1053285226225853 first col mean 0.09667113423347473 all mean 0.10646563023328781
0.2723176181316376 0.2723176181316376
rl training, epoch4, iter0, batch942/1133, batch loss:0.2723176181316376, Training time:14159.72913479805
batch reward last col mean 0.09227368980646133 first col mean 0.10226365923881531 all mean 0.10106164216995239
0.29980430006980896 0.29980430006980896
rl training, epoch4, iter0, batch943/1133, batch loss:0.29980430006980896, Training time:14161.599814653397
batch reward last col mean 0.15119053423404694 first col mean 0.10511930286884308 all mean 0.13853336870670319
0.301484078168869 0.301484078168869
rl training, epoch4, iter0, batch944/1133, batch loss:0.301484078168869, Training time:14163.689731121063
batch reward last col mean 0.10201570391654968 first col mean 0.12964196503162384 all mean 0.10778467357158661
0.32998085021972656 0.32998085021972656
rl training, epoch4, iter0, batch945/1133, batch loss:0.32998085021972656, Training time:14165.144902229309
batch reward last col mean 0.11707065254449844 first col mean 0.12684108316898346 all mean 0.11839533597230911
0.28388747572898865 0.28388747572898865
rl training, epoch4, iter0, batch946/1133, batch loss:0.28388747572898865, Training time:14167.713206768036
batch reward last col mean 0.09671290218830109 first col mean 0.13035516440868378 all mean 0.10146612673997879
0.31116044521331787 0.31116047501564026
rl training, epoch4, iter0, batch947/1133, batch loss:0.31116047501564026, Training time:14169.742686748505
batch reward last col mean 0.09113593399524689 first col mean 0.09572380781173706 all mean 0.09336807578802109
0.25546470284461975 0.25546467304229736
rl training, epoch4, iter0, batch948/1133, batch loss:0.25546467304229736, Training time:14171.770901441574
batch reward last col mean 0.09916726499795914 first col mean 0.13407880067825317 all mean 0.10330267995595932
0.2740556299686432 0.2740556299686432
rl training, epoch4, iter0, batch949/1133, batch loss:0.2740556299686432, Training time:14173.583039283752
batch reward last col mean 0.07314876466989517 first col mean 0.10591761767864227 all mean 0.07906585186719894
0.2594716548919678 0.2594716548919678
rl training, epoch4, iter0, batch950/1133, batch loss:0.2594716548919678, Training time:14175.201113939285
batch reward last col mean 0.10226043313741684 first col mean 0.11245004832744598 all mean 0.10741423070430756
0.3315299451351166 0.3315299451351166
rl training, epoch4, iter0, batch951/1133, batch loss:0.3315299451351166, Training time:14177.061348199844
batch reward last col mean 0.13230739533901215 first col mean 0.08526068925857544 all mean 0.1340181529521942
0.32961106300354004 0.32961103320121765
rl training, epoch4, iter0, batch952/1133, batch loss:0.32961103320121765, Training time:14178.66808128357
batch reward last col mean 0.11541398614645004 first col mean 0.10194972157478333 all mean 0.11193463206291199
0.32669171690940857 0.32669177651405334
rl training, epoch4, iter0, batch953/1133, batch loss:0.32669177651405334, Training time:14180.423790693283
batch reward last col mean 0.12998473644256592 first col mean 0.116971954703331 all mean 0.12252305448055267
0.3172614872455597 0.3172614872455597
rl training, epoch4, iter0, batch954/1133, batch loss:0.3172614872455597, Training time:14181.951215028763
batch reward last col mean 0.11300789564847946 first col mean 0.1112474799156189 all mean 0.11279063671827316
0.3278622031211853 0.3278622031211853
rl training, epoch4, iter0, batch955/1133, batch loss:0.3278622031211853, Training time:14183.64765381813
batch reward last col mean 0.09399668872356415 first col mean 0.11833962053060532 all mean 0.09648491442203522
0.28860557079315186 0.28860557079315186
rl training, epoch4, iter0, batch956/1133, batch loss:0.28860557079315186, Training time:14185.740565299988
batch reward last col mean 0.14091730117797852 first col mean 0.12246575951576233 all mean 0.13923685252666473
0.3764098584651947 0.3764097988605499
rl training, epoch4, iter0, batch957/1133, batch loss:0.3764097988605499, Training time:14187.711804151535
batch reward last col mean 0.09426669031381607 first col mean 0.12616845965385437 all mean 0.10462828725576401
0.2891433835029602 0.2891433835029602
rl training, epoch4, iter0, batch958/1133, batch loss:0.2891433835029602, Training time:14189.218541145325
batch reward last col mean 0.11373648047447205 first col mean 0.1150001809000969 all mean 0.11284047365188599
0.332658976316452 0.332658976316452
rl training, epoch4, iter0, batch959/1133, batch loss:0.332658976316452, Training time:14190.93819642067
batch reward last col mean 0.1368723213672638 first col mean 0.13288596272468567 all mean 0.13247954845428467
0.3378189504146576 0.3378189504146576
rl training, epoch4, iter0, batch960/1133, batch loss:0.3378189504146576, Training time:14192.772227048874
batch reward last col mean 0.09784480929374695 first col mean 0.11300760507583618 all mean 0.10261546820402145
0.3184259831905365 0.3184260427951813
rl training, epoch4, iter0, batch961/1133, batch loss:0.3184260427951813, Training time:14194.602155208588
batch reward last col mean 0.12778596580028534 first col mean 0.12652090191841125 all mean 0.12123788893222809
0.3105030953884125 0.3105030953884125
rl training, epoch4, iter0, batch962/1133, batch loss:0.3105030953884125, Training time:14196.412104129791
batch reward last col mean 0.10906423628330231 first col mean 0.11455821990966797 all mean 0.1046723872423172
0.29132288694381714 0.29132288694381714
rl training, epoch4, iter0, batch963/1133, batch loss:0.29132288694381714, Training time:14197.923006296158
batch reward last col mean 0.08535252511501312 first col mean 0.12291769683361053 all mean 0.09243743866682053
0.29185542464256287 0.29185542464256287
rl training, epoch4, iter0, batch964/1133, batch loss:0.29185542464256287, Training time:14200.382656812668
batch reward last col mean 0.12253043055534363 first col mean 0.12252014130353928 all mean 0.11947130411863327
0.3415633738040924 0.3415633738040924
rl training, epoch4, iter0, batch965/1133, batch loss:0.3415633738040924, Training time:14202.231993198395
batch reward last col mean 0.09683637320995331 first col mean 0.10905180871486664 all mean 0.09760736674070358
0.27731046080589294 0.27731046080589294
rl training, epoch4, iter0, batch966/1133, batch loss:0.27731046080589294, Training time:14204.007675409317
batch reward last col mean 0.10153865814208984 first col mean 0.14369583129882812 all mean 0.10765524208545685
0.32748478651046753 0.32748475670814514
rl training, epoch4, iter0, batch967/1133, batch loss:0.32748475670814514, Training time:14205.655963897705
batch reward last col mean 0.11056318134069443 first col mean 0.13581012189388275 all mean 0.11843738704919815
0.34375178813934326 0.34375178813934326
rl training, epoch4, iter0, batch968/1133, batch loss:0.34375178813934326, Training time:14207.278373479843
batch reward last col mean 0.11252790689468384 first col mean 0.0968318060040474 all mean 0.1077401265501976
0.2870776057243347 0.2870776057243347
rl training, epoch4, iter0, batch969/1133, batch loss:0.2870776057243347, Training time:14208.894360542297
batch reward last col mean 0.09341923147439957 first col mean 0.11196577548980713 all mean 0.09911556541919708
0.26586076617240906 0.26586076617240906
rl training, epoch4, iter0, batch970/1133, batch loss:0.26586076617240906, Training time:14210.464253902435
batch reward last col mean 0.10543777048587799 first col mean 0.11197875440120697 all mean 0.10698816180229187
0.3121992349624634 0.3121992349624634
rl training, epoch4, iter0, batch971/1133, batch loss:0.3121992349624634, Training time:14212.587020397186
batch reward last col mean 0.10970488935709 first col mean 0.11810323596000671 all mean 0.11327477544546127
0.3090103566646576 0.3090103268623352
rl training, epoch4, iter0, batch972/1133, batch loss:0.3090103268623352, Training time:14214.249530553818
batch reward last col mean 0.11202799528837204 first col mean 0.12673133611679077 all mean 0.1142323911190033
0.35341525077819824 0.35341522097587585
rl training, epoch4, iter0, batch973/1133, batch loss:0.35341522097587585, Training time:14215.87812924385
batch reward last col mean 0.141379252076149 first col mean 0.12185120582580566 all mean 0.13230127096176147
0.3687919080257416 0.3687919080257416
rl training, epoch4, iter0, batch974/1133, batch loss:0.3687919080257416, Training time:14217.38098859787
batch reward last col mean 0.12646788358688354 first col mean 0.1125735491514206 all mean 0.11929377168416977
0.340956449508667 0.340956449508667
rl training, epoch4, iter0, batch975/1133, batch loss:0.340956449508667, Training time:14219.53684091568
batch reward last col mean 0.11940675973892212 first col mean 0.1286357045173645 all mean 0.12167399376630783
0.32055172324180603 0.32055169343948364
rl training, epoch4, iter0, batch976/1133, batch loss:0.32055169343948364, Training time:14221.312477827072
batch reward last col mean 0.09853087365627289 first col mean 0.10981900244951248 all mean 0.10691946744918823
0.34232383966445923 0.34232383966445923
rl training, epoch4, iter0, batch977/1133, batch loss:0.34232383966445923, Training time:14223.554014444351
batch reward last col mean 0.09592943638563156 first col mean 0.12123991549015045 all mean 0.09967848658561707
0.29490646719932556 0.29490646719932556
rl training, epoch4, iter0, batch978/1133, batch loss:0.29490646719932556, Training time:14225.57505273819
batch reward last col mean 0.11608362942934036 first col mean 0.1158163771033287 all mean 0.10752502083778381
0.29922375082969666 0.29922375082969666
rl training, epoch4, iter0, batch979/1133, batch loss:0.29922375082969666, Training time:14227.914681196213
batch reward last col mean 0.11073768883943558 first col mean 0.11545351892709732 all mean 0.11548580229282379
0.3116092085838318 0.3116091787815094
rl training, epoch4, iter0, batch980/1133, batch loss:0.3116091787815094, Training time:14230.353553056717
batch reward last col mean 0.12133453786373138 first col mean 0.10660427063703537 all mean 0.1186518520116806
0.3050878345966339 0.3050878345966339
rl training, epoch4, iter0, batch981/1133, batch loss:0.3050878345966339, Training time:14232.071571111679
batch reward last col mean 0.10818994045257568 first col mean 0.10194147378206253 all mean 0.10662133991718292
0.2709956467151642 0.2709956467151642
rl training, epoch4, iter0, batch982/1133, batch loss:0.2709956467151642, Training time:14233.788647890091
batch reward last col mean 0.12290184944868088 first col mean 0.10116620361804962 all mean 0.12000098079442978
0.32800349593162537 0.32800349593162537
rl training, epoch4, iter0, batch983/1133, batch loss:0.32800349593162537, Training time:14235.529835700989
batch reward last col mean 0.07953563332557678 first col mean 0.12313374876976013 all mean 0.09217081218957901
0.30171430110931396 0.30171430110931396
rl training, epoch4, iter0, batch984/1133, batch loss:0.30171430110931396, Training time:14237.20097708702
batch reward last col mean 0.15834005177021027 first col mean 0.11710526049137115 all mean 0.14195291697978973
0.37564653158187866 0.37564653158187866
rl training, epoch4, iter0, batch985/1133, batch loss:0.37564653158187866, Training time:14238.724395990372
batch reward last col mean 0.10758064687252045 first col mean 0.10991229861974716 all mean 0.11108364164829254
0.34578055143356323 0.34578055143356323
rl training, epoch4, iter0, batch986/1133, batch loss:0.34578055143356323, Training time:14240.859483480453
batch reward last col mean 0.13835561275482178 first col mean 0.10895635932683945 all mean 0.1249004527926445
0.34014415740966797 0.34014415740966797
rl training, epoch4, iter0, batch987/1133, batch loss:0.34014415740966797, Training time:14242.575755119324
batch reward last col mean 0.09992563724517822 first col mean 0.1338837444782257 all mean 0.10604310780763626
0.31006553769111633 0.31006553769111633
rl training, epoch4, iter0, batch988/1133, batch loss:0.31006553769111633, Training time:14245.479378461838
batch reward last col mean 0.11089633405208588 first col mean 0.1330261081457138 all mean 0.11383148282766342
0.35672441124916077 0.35672441124916077
rl training, epoch4, iter0, batch989/1133, batch loss:0.35672441124916077, Training time:14247.386395454407
batch reward last col mean 0.09588196873664856 first col mean 0.11259439587593079 all mean 0.09843172132968903
0.29887551069259644 0.29887551069259644
rl training, epoch4, iter0, batch990/1133, batch loss:0.29887551069259644, Training time:14249.259291410446
batch reward last col mean 0.1091376319527626 first col mean 0.1422460824251175 all mean 0.11609125137329102
0.3414445221424103 0.3414444625377655
rl training, epoch4, iter0, batch991/1133, batch loss:0.3414444625377655, Training time:14251.250922441483
batch reward last col mean 0.1144457459449768 first col mean 0.12787115573883057 all mean 0.1152348592877388
0.3424508273601532 0.3424507975578308
rl training, epoch4, iter0, batch992/1133, batch loss:0.3424507975578308, Training time:14253.3208091259
batch reward last col mean 0.12649761140346527 first col mean 0.09537605196237564 all mean 0.12153185904026031
0.3152734637260437 0.3152734339237213
rl training, epoch4, iter0, batch993/1133, batch loss:0.3152734339237213, Training time:14255.050463199615
batch reward last col mean 0.12436056137084961 first col mean 0.10922816395759583 all mean 0.1230178028345108
0.33412185311317444 0.33412185311317444
rl training, epoch4, iter0, batch994/1133, batch loss:0.33412185311317444, Training time:14257.335191726685
batch reward last col mean 0.09078984707593918 first col mean 0.12365522980690002 all mean 0.1013944074511528
0.3123718500137329 0.3123718500137329
rl training, epoch4, iter0, batch995/1133, batch loss:0.3123718500137329, Training time:14259.24076294899
batch reward last col mean 0.07152494043111801 first col mean 0.13578981161117554 all mean 0.0844324603676796
0.2871626615524292 0.2871626615524292
rl training, epoch4, iter0, batch996/1133, batch loss:0.2871626615524292, Training time:14261.163823366165
batch reward last col mean 0.14771445095539093 first col mean 0.13798843324184418 all mean 0.14393988251686096
0.37404751777648926 0.37404751777648926
rl training, epoch4, iter0, batch997/1133, batch loss:0.37404751777648926, Training time:14263.386152505875
batch reward last col mean 0.1135345995426178 first col mean 0.10455846786499023 all mean 0.1053197905421257
0.2881641983985901 0.2881641983985901
rl training, epoch4, iter0, batch998/1133, batch loss:0.2881641983985901, Training time:14265.42113852501
batch reward last col mean 0.10333090275526047 first col mean 0.13153451681137085 all mean 0.10948855429887772
0.3126693367958069 0.3126693367958069
rl training, epoch4, iter0, batch999/1133, batch loss:0.3126693367958069, Training time:14267.645742893219
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5152194115143378 Time: 100.67984294891357 s
loss of true 0.22556204060117227 loss of gen 0.185543029132609 loss of other 0.10411434111309494 first score 0.10577742010354996
batch reward last col mean 0.1167980208992958 first col mean 0.10245142877101898 all mean 0.11483054608106613
0.2817073166370392 0.28170737624168396
rl training, epoch4, iter0, batch1000/1133, batch loss:0.28170737624168396, Training time:14371.18712091446
batch reward last col mean 0.08654514700174332 first col mean 0.12055693566799164 all mean 0.09551798552274704
0.29474034905433655 0.29474034905433655
rl training, epoch4, iter0, batch1001/1133, batch loss:0.29474034905433655, Training time:14373.775974988937
batch reward last col mean 0.09464645385742188 first col mean 0.10708460211753845 all mean 0.10140193998813629
0.272489994764328 0.272489994764328
rl training, epoch4, iter0, batch1002/1133, batch loss:0.272489994764328, Training time:14376.261054754257
batch reward last col mean 0.10136612504720688 first col mean 0.1035894975066185 all mean 0.10644803196191788
0.31850242614746094 0.31850242614746094
rl training, epoch4, iter0, batch1003/1133, batch loss:0.31850242614746094, Training time:14378.846392393112
batch reward last col mean 0.08494214713573456 first col mean 0.11742185056209564 all mean 0.08995214849710464
0.26810985803604126 0.26810985803604126
rl training, epoch4, iter0, batch1004/1133, batch loss:0.26810985803604126, Training time:14381.10780262947
batch reward last col mean 0.08370152115821838 first col mean 0.09835286438465118 all mean 0.08974161744117737
0.2910977303981781 0.2910977303981781
rl training, epoch4, iter0, batch1005/1133, batch loss:0.2910977303981781, Training time:14383.596189975739
batch reward last col mean 0.13604235649108887 first col mean 0.1112862080335617 all mean 0.13037081062793732
0.2984273433685303 0.2984273433685303
rl training, epoch4, iter0, batch1006/1133, batch loss:0.2984273433685303, Training time:14386.589083194733
batch reward last col mean 0.13374468684196472 first col mean 0.12754806876182556 all mean 0.12944084405899048
0.30069124698638916 0.30069124698638916
rl training, epoch4, iter0, batch1007/1133, batch loss:0.30069124698638916, Training time:14389.376724243164
batch reward last col mean 0.08125173300504684 first col mean 0.09882523119449615 all mean 0.09045960754156113
0.30489835143089294 0.3048984110355377
rl training, epoch4, iter0, batch1008/1133, batch loss:0.3048984110355377, Training time:14391.420056343079
batch reward last col mean 0.13617755472660065 first col mean 0.10959801822900772 all mean 0.13138450682163239
0.2995437979698181 0.2995437979698181
rl training, epoch4, iter0, batch1009/1133, batch loss:0.2995437979698181, Training time:14393.876208543777
batch reward last col mean 0.11184057593345642 first col mean 0.1166878417134285 all mean 0.10860219597816467
0.2745915651321411 0.2745915651321411
rl training, epoch4, iter0, batch1010/1133, batch loss:0.2745915651321411, Training time:14395.83243393898
batch reward last col mean 0.11299869418144226 first col mean 0.10969595611095428 all mean 0.11830678582191467
0.3392399549484253 0.3392399549484253
rl training, epoch4, iter0, batch1011/1133, batch loss:0.3392399549484253, Training time:14398.03805232048
batch reward last col mean 0.13008007407188416 first col mean 0.10569508373737335 all mean 0.12452629953622818
0.3151502311229706 0.3151502311229706
rl training, epoch4, iter0, batch1012/1133, batch loss:0.3151502311229706, Training time:14400.751203775406
batch reward last col mean 0.14546042680740356 first col mean 0.11257683485746384 all mean 0.1390955001115799
0.33442527055740356 0.33442527055740356
rl training, epoch4, iter0, batch1013/1133, batch loss:0.33442527055740356, Training time:14403.959849834442
batch reward last col mean 0.07298405468463898 first col mean 0.12273116409778595 all mean 0.08171620219945908
0.2783423960208893 0.2783423960208893
rl training, epoch4, iter0, batch1014/1133, batch loss:0.2783423960208893, Training time:14406.399959802628
batch reward last col mean 0.09496993571519852 first col mean 0.13173635303974152 all mean 0.10141370445489883
0.3136184811592102 0.3136184811592102
rl training, epoch4, iter0, batch1015/1133, batch loss:0.3136184811592102, Training time:14409.222863435745
batch reward last col mean 0.08033113181591034 first col mean 0.11663684993982315 all mean 0.08770167827606201
0.28144150972366333 0.28144150972366333
rl training, epoch4, iter0, batch1016/1133, batch loss:0.28144150972366333, Training time:14412.27087187767
batch reward last col mean 0.11117097735404968 first col mean 0.1144699901342392 all mean 0.11412305384874344
0.3559991121292114 0.3559991121292114
rl training, epoch4, iter0, batch1017/1133, batch loss:0.3559991121292114, Training time:14414.876424312592
batch reward last col mean 0.09979882836341858 first col mean 0.10222206264734268 all mean 0.10545200854539871
0.3031975030899048 0.3031975030899048
rl training, epoch4, iter0, batch1018/1133, batch loss:0.3031975030899048, Training time:14417.300558328629
batch reward last col mean 0.07769372314214706 first col mean 0.11383131146430969 all mean 0.09258285164833069
0.32400333881378174 0.32400333881378174
rl training, epoch4, iter0, batch1019/1133, batch loss:0.32400333881378174, Training time:14419.399624586105
batch reward last col mean 0.09648262709379196 first col mean 0.1079384982585907 all mean 0.09842222929000854
0.29501256346702576 0.29501256346702576
rl training, epoch4, iter0, batch1020/1133, batch loss:0.29501256346702576, Training time:14420.92416524887
batch reward last col mean 0.11426488310098648 first col mean 0.12515142560005188 all mean 0.10944269597530365
0.3483543395996094 0.3483543395996094
rl training, epoch4, iter0, batch1021/1133, batch loss:0.3483543395996094, Training time:14423.448668003082
batch reward last col mean 0.10316861420869827 first col mean 0.11087372153997421 all mean 0.10599954426288605
0.29426148533821106 0.29426148533821106
rl training, epoch4, iter0, batch1022/1133, batch loss:0.29426148533821106, Training time:14425.377384662628
batch reward last col mean 0.09683677554130554 first col mean 0.10521378368139267 all mean 0.10634315013885498
0.3086230158805847 0.3086230158805847
rl training, epoch4, iter0, batch1023/1133, batch loss:0.3086230158805847, Training time:14426.97439956665
batch reward last col mean 0.1208105981349945 first col mean 0.11471176147460938 all mean 0.11897322535514832
0.31486791372299194 0.31486788392066956
rl training, epoch4, iter0, batch1024/1133, batch loss:0.31486788392066956, Training time:14430.189788341522
batch reward last col mean 0.11981679499149323 first col mean 0.11498299241065979 all mean 0.11966508626937866
0.3099159896373749 0.3099159896373749
rl training, epoch4, iter0, batch1025/1133, batch loss:0.3099159896373749, Training time:14431.70819568634
batch reward last col mean 0.08095037192106247 first col mean 0.12155856192111969 all mean 0.08657033741474152
0.2490629106760025 0.2490629106760025
rl training, epoch4, iter0, batch1026/1133, batch loss:0.2490629106760025, Training time:14433.427510499954
batch reward last col mean 0.12761551141738892 first col mean 0.1218516081571579 all mean 0.13045650720596313
0.32415515184402466 0.32415518164634705
rl training, epoch4, iter0, batch1027/1133, batch loss:0.32415518164634705, Training time:14435.960311889648
batch reward last col mean 0.0894962027668953 first col mean 0.1206664890050888 all mean 0.09591346979141235
0.28082403540611267 0.28082403540611267
rl training, epoch4, iter0, batch1028/1133, batch loss:0.28082403540611267, Training time:14439.38503575325
batch reward last col mean 0.09743655472993851 first col mean 0.14354676008224487 all mean 0.10207588225603104
0.310352623462677 0.310352623462677
rl training, epoch4, iter0, batch1029/1133, batch loss:0.310352623462677, Training time:14441.165805339813
batch reward last col mean 0.11439397931098938 first col mean 0.10762809216976166 all mean 0.11304936558008194
0.30203744769096375 0.30203744769096375
rl training, epoch4, iter0, batch1030/1133, batch loss:0.30203744769096375, Training time:14443.265183448792
batch reward last col mean 0.07854622602462769 first col mean 0.11931225657463074 all mean 0.08834069967269897
0.31595003604888916 0.31595003604888916
rl training, epoch4, iter0, batch1031/1133, batch loss:0.31595003604888916, Training time:14445.249300718307
batch reward last col mean 0.12992241978645325 first col mean 0.11357714235782623 all mean 0.12778176367282867
0.2920844256877899 0.2920844256877899
rl training, epoch4, iter0, batch1032/1133, batch loss:0.2920844256877899, Training time:14447.273333311081
batch reward last col mean 0.10815279185771942 first col mean 0.12171676754951477 all mean 0.10827958583831787
0.27041494846343994 0.27041494846343994
rl training, epoch4, iter0, batch1033/1133, batch loss:0.27041494846343994, Training time:14449.488797903061
batch reward last col mean 0.1321316957473755 first col mean 0.1112358421087265 all mean 0.12747545540332794
0.34829995036125183 0.34829995036125183
rl training, epoch4, iter0, batch1034/1133, batch loss:0.34829995036125183, Training time:14451.452637434006
batch reward last col mean 0.11134631186723709 first col mean 0.1322411745786667 all mean 0.11229274421930313
0.30478566884994507 0.30478566884994507
rl training, epoch4, iter0, batch1035/1133, batch loss:0.30478566884994507, Training time:14453.504402160645
batch reward last col mean 0.1221998929977417 first col mean 0.11007693409919739 all mean 0.12158069759607315
0.34269070625305176 0.34269070625305176
rl training, epoch4, iter0, batch1036/1133, batch loss:0.34269070625305176, Training time:14455.314546108246
batch reward last col mean 0.08649450540542603 first col mean 0.12217835336923599 all mean 0.09570034593343735
0.27837419509887695 0.27837419509887695
rl training, epoch4, iter0, batch1037/1133, batch loss:0.27837419509887695, Training time:14457.847110748291
batch reward last col mean 0.13518020510673523 first col mean 0.10180775821208954 all mean 0.1262756586074829
0.3041149079799652 0.3041149079799652
rl training, epoch4, iter0, batch1038/1133, batch loss:0.3041149079799652, Training time:14460.35541677475
batch reward last col mean 0.10159651935100555 first col mean 0.11310489475727081 all mean 0.10474280267953873
0.2842726409435272 0.2842726409435272
rl training, epoch4, iter0, batch1039/1133, batch loss:0.2842726409435272, Training time:14462.30502295494
batch reward last col mean 0.08186895400285721 first col mean 0.11900196224451065 all mean 0.09307099878787994
0.2883473038673401 0.2883473038673401
rl training, epoch4, iter0, batch1040/1133, batch loss:0.2883473038673401, Training time:14464.04573559761
batch reward last col mean 0.06912580877542496 first col mean 0.1279161423444748 all mean 0.08167714625597
0.2591685354709625 0.2591685354709625
rl training, epoch4, iter0, batch1041/1133, batch loss:0.2591685354709625, Training time:14465.818407773972
batch reward last col mean 0.13707081973552704 first col mean 0.12045030295848846 all mean 0.13845524191856384
0.3245028555393219 0.3245028555393219
rl training, epoch4, iter0, batch1042/1133, batch loss:0.3245028555393219, Training time:14467.660615682602
batch reward last col mean 0.08669259399175644 first col mean 0.12504860758781433 all mean 0.09626481682062149
0.2745978832244873 0.2745978832244873
rl training, epoch4, iter0, batch1043/1133, batch loss:0.2745978832244873, Training time:14469.669839143753
batch reward last col mean 0.10793203115463257 first col mean 0.127134770154953 all mean 0.10677125304937363
0.2946717441082001 0.29467177391052246
rl training, epoch4, iter0, batch1044/1133, batch loss:0.29467177391052246, Training time:14471.858440876007
batch reward last col mean 0.11841646581888199 first col mean 0.1085398942232132 all mean 0.1189575269818306
0.3115066587924957 0.3115066587924957
rl training, epoch4, iter0, batch1045/1133, batch loss:0.3115066587924957, Training time:14473.634214401245
batch reward last col mean 0.09243396669626236 first col mean 0.12256002426147461 all mean 0.1036238819360733
0.279742032289505 0.279742032289505
rl training, epoch4, iter0, batch1046/1133, batch loss:0.279742032289505, Training time:14475.680116176605
batch reward last col mean 0.1188654974102974 first col mean 0.12379567325115204 all mean 0.11924348026514053
0.3258320093154907 0.3258320093154907
rl training, epoch4, iter0, batch1047/1133, batch loss:0.3258320093154907, Training time:14477.453706979752
batch reward last col mean 0.10283535718917847 first col mean 0.12883839011192322 all mean 0.10709034651517868
0.29400834441185 0.29400834441185
rl training, epoch4, iter0, batch1048/1133, batch loss:0.29400834441185, Training time:14479.98975944519
batch reward last col mean 0.12168513238430023 first col mean 0.11712108552455902 all mean 0.12154264748096466
0.32158833742141724 0.32158833742141724
rl training, epoch4, iter0, batch1049/1133, batch loss:0.32158833742141724, Training time:14482.802681207657
batch reward last col mean 0.06426707655191422 first col mean 0.11562154442071915 all mean 0.08101795613765717
0.26678624749183655 0.26678624749183655
rl training, epoch4, iter0, batch1050/1133, batch loss:0.26678624749183655, Training time:14484.590131759644
batch reward last col mean 0.11888779699802399 first col mean 0.14869901537895203 all mean 0.11917369812726974
0.3309490978717804 0.3309490978717804
rl training, epoch4, iter0, batch1051/1133, batch loss:0.3309490978717804, Training time:14486.25855755806
batch reward last col mean 0.12246667593717575 first col mean 0.12157392501831055 all mean 0.12310253828763962
0.3261588215827942 0.3261588215827942
rl training, epoch4, iter0, batch1052/1133, batch loss:0.3261588215827942, Training time:14488.188117742538
batch reward last col mean 0.110934779047966 first col mean 0.10943219065666199 all mean 0.11473427712917328
0.31321561336517334 0.31321561336517334
rl training, epoch4, iter0, batch1053/1133, batch loss:0.31321561336517334, Training time:14489.96618938446
batch reward last col mean 0.12519852817058563 first col mean 0.12834285199642181 all mean 0.1266445368528366
0.3101317584514618 0.3101317584514618
rl training, epoch4, iter0, batch1054/1133, batch loss:0.3101317584514618, Training time:14492.003520965576
batch reward last col mean 0.12269562482833862 first col mean 0.12138344347476959 all mean 0.12867355346679688
0.3331635594367981 0.3331635594367981
rl training, epoch4, iter0, batch1055/1133, batch loss:0.3331635594367981, Training time:14493.711182832718
batch reward last col mean 0.15347006916999817 first col mean 0.10811305791139603 all mean 0.14209215342998505
0.33063170313835144 0.33063170313835144
rl training, epoch4, iter0, batch1056/1133, batch loss:0.33063170313835144, Training time:14495.563569784164
batch reward last col mean 0.08915729075670242 first col mean 0.11529888212680817 all mean 0.09909317642450333
0.2996065318584442 0.2996065318584442
rl training, epoch4, iter0, batch1057/1133, batch loss:0.2996065318584442, Training time:14497.62873339653
batch reward last col mean 0.15075305104255676 first col mean 0.12379102408885956 all mean 0.13936211168766022
0.36891016364097595 0.36891016364097595
rl training, epoch4, iter0, batch1058/1133, batch loss:0.36891016364097595, Training time:14500.241364479065
batch reward last col mean 0.12568111717700958 first col mean 0.11224978417158127 all mean 0.1256156712770462
0.3369724452495575 0.3369724452495575
rl training, epoch4, iter0, batch1059/1133, batch loss:0.3369724452495575, Training time:14502.453645706177
batch reward last col mean 0.13493874669075012 first col mean 0.12980586290359497 all mean 0.13207405805587769
0.3278607428073883 0.3278607428073883
rl training, epoch4, iter0, batch1060/1133, batch loss:0.3278607428073883, Training time:14505.301696777344
batch reward last col mean 0.09201942384243011 first col mean 0.1313258707523346 all mean 0.10578373819589615
0.30752596259117126 0.30752596259117126
rl training, epoch4, iter0, batch1061/1133, batch loss:0.30752596259117126, Training time:14507.095460176468
batch reward last col mean 0.12590563297271729 first col mean 0.1200316995382309 all mean 0.12109596282243729
0.3243405222892761 0.3243405222892761
rl training, epoch4, iter0, batch1062/1133, batch loss:0.3243405222892761, Training time:14508.763553857803
batch reward last col mean 0.10974033176898956 first col mean 0.11419571936130524 all mean 0.11316268891096115
0.3263896405696869 0.3263896405696869
rl training, epoch4, iter0, batch1063/1133, batch loss:0.3263896405696869, Training time:14510.924242973328
batch reward last col mean 0.10483087599277496 first col mean 0.13049423694610596 all mean 0.1086420789361
0.30679965019226074 0.30679965019226074
rl training, epoch4, iter0, batch1064/1133, batch loss:0.30679965019226074, Training time:14513.065698623657
batch reward last col mean 0.08809349685907364 first col mean 0.13251172006130219 all mean 0.10108126699924469
0.2861020863056183 0.2861020565032959
rl training, epoch4, iter0, batch1065/1133, batch loss:0.2861020565032959, Training time:14514.912146091461
batch reward last col mean 0.11604797095060349 first col mean 0.12264092266559601 all mean 0.1161307841539383
0.3198215365409851 0.3198215365409851
rl training, epoch4, iter0, batch1066/1133, batch loss:0.3198215365409851, Training time:14518.328551769257
batch reward last col mean 0.12493883818387985 first col mean 0.10955394804477692 all mean 0.12342889606952667
0.34234619140625 0.3423462212085724
rl training, epoch4, iter0, batch1067/1133, batch loss:0.3423462212085724, Training time:14520.181518316269
batch reward last col mean 0.12004172801971436 first col mean 0.114254891872406 all mean 0.11718059331178665
0.29931318759918213 0.29931318759918213
rl training, epoch4, iter0, batch1068/1133, batch loss:0.29931318759918213, Training time:14521.994961977005
batch reward last col mean 0.11034652590751648 first col mean 0.1074848622083664 all mean 0.11215813457965851
0.2801607549190521 0.2801607549190521
rl training, epoch4, iter0, batch1069/1133, batch loss:0.2801607549190521, Training time:14523.96006822586
batch reward last col mean 0.07892519235610962 first col mean 0.12810423970222473 all mean 0.09506729245185852
0.3222837746143341 0.3222837746143341
rl training, epoch4, iter0, batch1070/1133, batch loss:0.3222837746143341, Training time:14526.025491714478
batch reward last col mean 0.09812590479850769 first col mean 0.10795806348323822 all mean 0.10649571567773819
0.28206849098205566 0.2820684611797333
rl training, epoch4, iter0, batch1071/1133, batch loss:0.2820684611797333, Training time:14527.618667840958
batch reward last col mean 0.11811704188585281 first col mean 0.10868023335933685 all mean 0.11885060369968414
0.33217155933380127 0.33217155933380127
rl training, epoch4, iter0, batch1072/1133, batch loss:0.33217155933380127, Training time:14529.783872127533
batch reward last col mean 0.11414103209972382 first col mean 0.1273811310529709 all mean 0.11506734043359756
0.27218544483184814 0.27218541502952576
rl training, epoch4, iter0, batch1073/1133, batch loss:0.27218541502952576, Training time:14531.700232744217
batch reward last col mean 0.1115347146987915 first col mean 0.1184137612581253 all mean 0.11740349233150482
0.3067817687988281 0.3067817687988281
rl training, epoch4, iter0, batch1074/1133, batch loss:0.3067817687988281, Training time:14533.812590122223
batch reward last col mean 0.12134610861539841 first col mean 0.11725107580423355 all mean 0.12132450938224792
0.3400956094264984 0.3400956094264984
rl training, epoch4, iter0, batch1075/1133, batch loss:0.3400956094264984, Training time:14535.973926782608
batch reward last col mean 0.08779323846101761 first col mean 0.11750470846891403 all mean 0.09535188227891922
0.2789592742919922 0.2789592742919922
rl training, epoch4, iter0, batch1076/1133, batch loss:0.2789592742919922, Training time:14537.918258190155
batch reward last col mean 0.11400625109672546 first col mean 0.12481611967086792 all mean 0.1123831644654274
0.3196296989917755 0.3196296989917755
rl training, epoch4, iter0, batch1077/1133, batch loss:0.3196296989917755, Training time:14539.84812617302
batch reward last col mean 0.11665882170200348 first col mean 0.1077999547123909 all mean 0.12004508823156357
0.29565808176994324 0.29565808176994324
rl training, epoch4, iter0, batch1078/1133, batch loss:0.29565808176994324, Training time:14541.778144359589
batch reward last col mean 0.11130239069461823 first col mean 0.13087879121303558 all mean 0.11538218706846237
0.3159889876842499 0.3159889876842499
rl training, epoch4, iter0, batch1079/1133, batch loss:0.3159889876842499, Training time:14543.727683544159
batch reward last col mean 0.16039937734603882 first col mean 0.1374654769897461 all mean 0.1427033543586731
0.29655539989471436 0.29655539989471436
rl training, epoch4, iter0, batch1080/1133, batch loss:0.29655539989471436, Training time:14545.221474170685
batch reward last col mean 0.10609006136655807 first col mean 0.1356627196073532 all mean 0.11262889951467514
0.2837929129600525 0.2837929129600525
rl training, epoch4, iter0, batch1081/1133, batch loss:0.2837929129600525, Training time:14547.739264726639
batch reward last col mean 0.10978458821773529 first col mean 0.10400736331939697 all mean 0.11391129344701767
0.30049261450767517 0.30049261450767517
rl training, epoch4, iter0, batch1082/1133, batch loss:0.30049261450767517, Training time:14549.342230796814
batch reward last col mean 0.1196477860212326 first col mean 0.11315598338842392 all mean 0.12149660289287567
0.30324587225914 0.30324587225914
rl training, epoch4, iter0, batch1083/1133, batch loss:0.30324587225914, Training time:14551.225848436356
batch reward last col mean 0.11264621466398239 first col mean 0.12697961926460266 all mean 0.11505187302827835
0.3180677890777588 0.3180677890777588
rl training, epoch4, iter0, batch1084/1133, batch loss:0.3180677890777588, Training time:14554.443423986435
batch reward last col mean 0.09817499667406082 first col mean 0.12318167090415955 all mean 0.10722513496875763
0.29199403524398804 0.29199403524398804
rl training, epoch4, iter0, batch1085/1133, batch loss:0.29199403524398804, Training time:14556.533309221268
batch reward last col mean 0.09672563523054123 first col mean 0.10114476084709167 all mean 0.11055466532707214
0.29764166474342346 0.29764166474342346
rl training, epoch4, iter0, batch1086/1133, batch loss:0.29764166474342346, Training time:14558.191505670547
batch reward last col mean 0.11446242779493332 first col mean 0.12593071162700653 all mean 0.12065381556749344
0.3312970697879791 0.3312970697879791
rl training, epoch4, iter0, batch1087/1133, batch loss:0.3312970697879791, Training time:14559.930689573288
batch reward last col mean 0.15185903012752533 first col mean 0.1158563643693924 all mean 0.14693330228328705
0.32739102840423584 0.32739102840423584
rl training, epoch4, iter0, batch1088/1133, batch loss:0.32739102840423584, Training time:14562.29255437851
batch reward last col mean 0.1161286011338234 first col mean 0.1388445347547531 all mean 0.11447355151176453
0.314907044172287 0.314907044172287
rl training, epoch4, iter0, batch1089/1133, batch loss:0.314907044172287, Training time:14564.25582909584
batch reward last col mean 0.13441547751426697 first col mean 0.11234864592552185 all mean 0.1286514550447464
0.34018468856811523 0.34018468856811523
rl training, epoch4, iter0, batch1090/1133, batch loss:0.34018468856811523, Training time:14567.009868383408
batch reward last col mean 0.1194617822766304 first col mean 0.11762429773807526 all mean 0.11646952480077744
0.2921217083930969 0.2921217083930969
rl training, epoch4, iter0, batch1091/1133, batch loss:0.2921217083930969, Training time:14569.25753068924
batch reward last col mean 0.14769679307937622 first col mean 0.1138741672039032 all mean 0.13754048943519592
0.3336857557296753 0.3336857557296753
rl training, epoch4, iter0, batch1092/1133, batch loss:0.3336857557296753, Training time:14571.57632613182
batch reward last col mean 0.10518869757652283 first col mean 0.10342810302972794 all mean 0.10401468724012375
0.30895373225212097 0.30895373225212097
rl training, epoch4, iter0, batch1093/1133, batch loss:0.30895373225212097, Training time:14573.50648355484
batch reward last col mean 0.10596957802772522 first col mean 0.11363883316516876 all mean 0.11407678574323654
0.3066971004009247 0.3066971004009247
rl training, epoch4, iter0, batch1094/1133, batch loss:0.3066971004009247, Training time:14575.219939231873
batch reward last col mean 0.09258134663105011 first col mean 0.13031664490699768 all mean 0.10110966861248016
0.30712074041366577 0.30712074041366577
rl training, epoch4, iter0, batch1095/1133, batch loss:0.30712074041366577, Training time:14577.30119228363
batch reward last col mean 0.08251888304948807 first col mean 0.12031412869691849 all mean 0.09797586500644684
0.26612991094589233 0.26612991094589233
rl training, epoch4, iter0, batch1096/1133, batch loss:0.26612991094589233, Training time:14578.994417905807
batch reward last col mean 0.09896612167358398 first col mean 0.11688113212585449 all mean 0.09863664209842682
0.3036174476146698 0.3036174476146698
rl training, epoch4, iter0, batch1097/1133, batch loss:0.3036174476146698, Training time:14581.437196969986
batch reward last col mean 0.11317411810159683 first col mean 0.11192876100540161 all mean 0.11438627541065216
0.29325810074806213 0.29325810074806213
rl training, epoch4, iter0, batch1098/1133, batch loss:0.29325810074806213, Training time:14583.420399904251
batch reward last col mean 0.14347250759601593 first col mean 0.135445237159729 all mean 0.1331413984298706
0.34243226051330566 0.34243226051330566
rl training, epoch4, iter0, batch1099/1133, batch loss:0.34243226051330566, Training time:14585.284100532532
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5136654595569079 Time: 98.09665155410767 s
loss of true 0.2261970274525202 loss of gen 0.1820209303908609 loss of other 0.10544750193546593 first score 0.14551404118537903
batch reward last col mean 0.13664598762989044 first col mean 0.11120758950710297 all mean 0.12985926866531372
0.3198530673980713 0.3198530673980713
rl training, epoch4, iter0, batch1100/1133, batch loss:0.3198530673980713, Training time:14684.8580160141
batch reward last col mean 0.09946095198392868 first col mean 0.10797309875488281 all mean 0.10104461759328842
0.2774835526943207 0.2774835526943207
rl training, epoch4, iter0, batch1101/1133, batch loss:0.2774835526943207, Training time:14686.673308134079
batch reward last col mean 0.08401693403720856 first col mean 0.11124856770038605 all mean 0.09082017838954926
0.25322428345680237 0.25322425365448
rl training, epoch4, iter0, batch1102/1133, batch loss:0.25322425365448, Training time:14688.259233236313
batch reward last col mean 0.13347212970256805 first col mean 0.1103537455201149 all mean 0.12420184910297394
0.3100857138633728 0.3100857138633728
rl training, epoch4, iter0, batch1103/1133, batch loss:0.3100857138633728, Training time:14690.236706256866
batch reward last col mean 0.1338869035243988 first col mean 0.1129092276096344 all mean 0.12578971683979034
0.3147449791431427 0.3147449791431427
rl training, epoch4, iter0, batch1104/1133, batch loss:0.3147449791431427, Training time:14692.14065003395
batch reward last col mean 0.10592109709978104 first col mean 0.111726313829422 all mean 0.10872439295053482
0.291386216878891 0.291386216878891
rl training, epoch4, iter0, batch1105/1133, batch loss:0.291386216878891, Training time:14693.996239185333
batch reward last col mean 0.11689745634794235 first col mean 0.11891274154186249 all mean 0.10824654996395111
0.31979092955589294 0.31979092955589294
rl training, epoch4, iter0, batch1106/1133, batch loss:0.31979092955589294, Training time:14695.880012273788
batch reward last col mean 0.07545118033885956 first col mean 0.12817299365997314 all mean 0.08695080876350403
0.25934553146362305 0.25934553146362305
rl training, epoch4, iter0, batch1107/1133, batch loss:0.25934553146362305, Training time:14697.799184083939
batch reward last col mean 0.11675381660461426 first col mean 0.11053009331226349 all mean 0.1123628318309784
0.31767538189888 0.31767538189888
rl training, epoch4, iter0, batch1108/1133, batch loss:0.31767538189888, Training time:14699.532974004745
batch reward last col mean 0.09462837874889374 first col mean 0.12010850012302399 all mean 0.10132981836795807
0.34630832076072693 0.34630832076072693
rl training, epoch4, iter0, batch1109/1133, batch loss:0.34630832076072693, Training time:14701.367686271667
batch reward last col mean 0.11125165969133377 first col mean 0.1081586629152298 all mean 0.11330276727676392
0.3209931552410126 0.3209931552410126
rl training, epoch4, iter0, batch1110/1133, batch loss:0.3209931552410126, Training time:14702.9269490242
batch reward last col mean 0.11787457764148712 first col mean 0.1377267986536026 all mean 0.11947395652532578
0.3240918219089508 0.3240918219089508
rl training, epoch4, iter0, batch1111/1133, batch loss:0.3240918219089508, Training time:14704.916952133179
batch reward last col mean 0.09196407347917557 first col mean 0.10942412167787552 all mean 0.09762358665466309
0.30491286516189575 0.30491286516189575
rl training, epoch4, iter0, batch1112/1133, batch loss:0.30491286516189575, Training time:14706.53180384636
batch reward last col mean 0.09272129833698273 first col mean 0.10447268187999725 all mean 0.09673354774713516
0.2750232517719269 0.2750232517719269
rl training, epoch4, iter0, batch1113/1133, batch loss:0.2750232517719269, Training time:14708.445094585419
batch reward last col mean 0.10991914570331573 first col mean 0.12345298379659653 all mean 0.11281643807888031
0.3150710165500641 0.3150710165500641
rl training, epoch4, iter0, batch1114/1133, batch loss:0.3150710165500641, Training time:14710.673189640045
batch reward last col mean 0.0770135149359703 first col mean 0.1241878941655159 all mean 0.08479989320039749
0.28834623098373413 0.28834623098373413
rl training, epoch4, iter0, batch1115/1133, batch loss:0.28834623098373413, Training time:14712.821219205856
batch reward last col mean 0.09681114554405212 first col mean 0.10338519513607025 all mean 0.10080290585756302
0.2702808976173401 0.2702808976173401
rl training, epoch4, iter0, batch1116/1133, batch loss:0.2702808976173401, Training time:14714.928347587585
batch reward last col mean 0.10445868223905563 first col mean 0.13032233715057373 all mean 0.10753053426742554
0.29427799582481384 0.29427799582481384
rl training, epoch4, iter0, batch1117/1133, batch loss:0.29427799582481384, Training time:14716.687463283539
batch reward last col mean 0.11156834661960602 first col mean 0.1183222234249115 all mean 0.1128125712275505
0.28535670042037964 0.28535670042037964
rl training, epoch4, iter0, batch1118/1133, batch loss:0.28535670042037964, Training time:14718.663101911545
batch reward last col mean 0.0957229882478714 first col mean 0.1207711398601532 all mean 0.1039554551243782
0.3255259096622467 0.3255259096622467
rl training, epoch4, iter0, batch1119/1133, batch loss:0.3255259096622467, Training time:14720.662116289139
batch reward last col mean 0.1100543886423111 first col mean 0.11257082223892212 all mean 0.11193776875734329
0.33476948738098145 0.33476945757865906
rl training, epoch4, iter0, batch1120/1133, batch loss:0.33476945757865906, Training time:14722.740199804306
batch reward last col mean 0.13921824097633362 first col mean 0.12900830805301666 all mean 0.12936145067214966
0.3367053270339966 0.3367053270339966
rl training, epoch4, iter0, batch1121/1133, batch loss:0.3367053270339966, Training time:14724.43135356903
batch reward last col mean 0.12650668621063232 first col mean 0.13799771666526794 all mean 0.12795959413051605
0.35884982347488403 0.35884979367256165
rl training, epoch4, iter0, batch1122/1133, batch loss:0.35884979367256165, Training time:14726.120522499084
batch reward last col mean 0.10780086368322372 first col mean 0.12633256614208221 all mean 0.1072135791182518
0.2980864346027374 0.2980864346027374
rl training, epoch4, iter0, batch1123/1133, batch loss:0.2980864346027374, Training time:14728.075884580612
batch reward last col mean 0.12334568053483963 first col mean 0.11630655825138092 all mean 0.11719698458909988
0.3205597698688507 0.3205597698688507
rl training, epoch4, iter0, batch1124/1133, batch loss:0.3205597698688507, Training time:14729.62606883049
batch reward last col mean 0.11675659567117691 first col mean 0.11459248512983322 all mean 0.12010817229747772
0.30823034048080444 0.30823034048080444
rl training, epoch4, iter0, batch1125/1133, batch loss:0.30823034048080444, Training time:14731.349764347076
batch reward last col mean 0.11249375343322754 first col mean 0.1190657690167427 all mean 0.11234740167856216
0.31343987584114075 0.31343987584114075
rl training, epoch4, iter0, batch1126/1133, batch loss:0.31343987584114075, Training time:14733.187111139297
batch reward last col mean 0.10920368880033493 first col mean 0.12616732716560364 all mean 0.10890348255634308
0.26685357093811035 0.26685354113578796
rl training, epoch4, iter0, batch1127/1133, batch loss:0.26685354113578796, Training time:14735.944220542908
batch reward last col mean 0.12525860965251923 first col mean 0.11112429946660995 all mean 0.1252502053976059
0.3227608799934387 0.3227608799934387
rl training, epoch4, iter0, batch1128/1133, batch loss:0.3227608799934387, Training time:14737.988035440445
batch reward last col mean 0.08822673559188843 first col mean 0.11873243004083633 all mean 0.09722327440977097
0.2702030539512634 0.2702030539512634
rl training, epoch4, iter0, batch1129/1133, batch loss:0.2702030539512634, Training time:14739.800111293793
batch reward last col mean 0.12050305306911469 first col mean 0.10505776107311249 all mean 0.11651895195245743
0.3057263195514679 0.3057263195514679
rl training, epoch4, iter0, batch1130/1133, batch loss:0.3057263195514679, Training time:14741.573174476624
batch reward last col mean 0.09187465906143188 first col mean 0.1054653748869896 all mean 0.09394857287406921
0.27182888984680176 0.27182888984680176
rl training, epoch4, iter0, batch1131/1133, batch loss:0.27182888984680176, Training time:14743.954145669937
batch reward last col mean 0.11898643523454666 first col mean 0.10160648077726364 all mean 0.12082236260175705
0.3267921209335327 0.3267921209335327
rl training, epoch4, iter0, batch1132/1133, batch loss:0.3267921209335327, Training time:14746.041486501694
rl training, epoch 4, iter 0, loss:0.3135263848415225, Training time:14746.041743278503 
rl epoch 4, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.0536246621703427 Time: 127.60299372673035 s
rl epoch 4, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.49411198446841126 Time: 108.2034330368042 s
loss of true 0.21232026598407228 loss of gen 0.17632315231574286 loss of other 0.10546856566060199 first score 0.09150147438049316
rl epoch 5, begin RL for generator...
batch reward last col mean 0.08003553003072739 first col mean 0.1081780418753624 all mean 0.08199470490217209
0.2501339018344879 0.2501339018344879
rl training, epoch5, iter0, batch0/1133, batch loss:0.2501339018344879, Training time:14984.663509130478
batch reward last col mean 0.09928227961063385 first col mean 0.09773494303226471 all mean 0.10006552934646606
0.27295568585395813 0.27295568585395813
rl training, epoch5, iter0, batch1/1133, batch loss:0.27295568585395813, Training time:14987.803544044495
batch reward last col mean 0.0835728645324707 first col mean 0.10610073804855347 all mean 0.09255579113960266
0.2999129593372345 0.2999129593372345
rl training, epoch5, iter0, batch2/1133, batch loss:0.2999129593372345, Training time:14990.589091062546
batch reward last col mean 0.092713862657547 first col mean 0.08790533989667892 all mean 0.09156720340251923
0.26733770966529846 0.26733770966529846
rl training, epoch5, iter0, batch3/1133, batch loss:0.26733770966529846, Training time:14992.889112234116
batch reward last col mean 0.07125943154096603 first col mean 0.09866656363010406 all mean 0.07945766299962997
0.21668407320976257 0.21668407320976257
rl training, epoch5, iter0, batch4/1133, batch loss:0.21668407320976257, Training time:14995.290644407272
batch reward last col mean 0.0746103823184967 first col mean 0.11662809550762177 all mean 0.08753281086683273
0.2998485565185547 0.2998485565185547
rl training, epoch5, iter0, batch5/1133, batch loss:0.2998485565185547, Training time:14997.396275281906
batch reward last col mean 0.06424007564783096 first col mean 0.08251428604125977 all mean 0.06931757181882858
0.2377421110868454 0.2377420961856842
rl training, epoch5, iter0, batch6/1133, batch loss:0.2377420961856842, Training time:15000.228889226913
batch reward last col mean 0.10681937634944916 first col mean 0.0910477489233017 all mean 0.10520646721124649
0.2930866479873657 0.2930866479873657
rl training, epoch5, iter0, batch7/1133, batch loss:0.2930866479873657, Training time:15002.830996513367
batch reward last col mean 0.08381863683462143 first col mean 0.09047886729240417 all mean 0.08418110013008118
0.2694545388221741 0.2694545388221741
rl training, epoch5, iter0, batch8/1133, batch loss:0.2694545388221741, Training time:15005.395698547363
batch reward last col mean 0.09415493905544281 first col mean 0.09901610016822815 all mean 0.0956542119383812
0.26822009682655334 0.26822009682655334
rl training, epoch5, iter0, batch9/1133, batch loss:0.26822009682655334, Training time:15008.363963127136
batch reward last col mean 0.11357416212558746 first col mean 0.10037073493003845 all mean 0.11081790924072266
0.30582305788993835 0.30582305788993835
rl training, epoch5, iter0, batch10/1133, batch loss:0.30582305788993835, Training time:15011.314117908478
batch reward last col mean 0.09156287461519241 first col mean 0.11455024778842926 all mean 0.09342826902866364
0.29388561844825745 0.29388561844825745
rl training, epoch5, iter0, batch11/1133, batch loss:0.29388561844825745, Training time:15014.214435338974
batch reward last col mean 0.08146069198846817 first col mean 0.12156818807125092 all mean 0.08963382989168167
0.2647935748100281 0.2647935748100281
rl training, epoch5, iter0, batch12/1133, batch loss:0.2647935748100281, Training time:15016.88618350029
batch reward last col mean 0.10034739226102829 first col mean 0.10346537828445435 all mean 0.1080639585852623
0.30990082025527954 0.30990079045295715
rl training, epoch5, iter0, batch13/1133, batch loss:0.30990079045295715, Training time:15019.1324198246
batch reward last col mean 0.08078829199075699 first col mean 0.11421339958906174 all mean 0.08637998253107071
0.3085114359855652 0.3085114359855652
rl training, epoch5, iter0, batch14/1133, batch loss:0.3085114359855652, Training time:15022.110080957413
batch reward last col mean 0.09891617298126221 first col mean 0.08754918724298477 all mean 0.100804403424263
0.290804386138916 0.290804386138916
rl training, epoch5, iter0, batch15/1133, batch loss:0.290804386138916, Training time:15024.901319265366
batch reward last col mean 0.12662307918071747 first col mean 0.1130380630493164 all mean 0.11857157945632935
0.2925844192504883 0.2925844192504883
rl training, epoch5, iter0, batch16/1133, batch loss:0.2925844192504883, Training time:15026.955001115799
batch reward last col mean 0.11434955894947052 first col mean 0.10248739272356033 all mean 0.10889308154582977
0.2834489345550537 0.2834489345550537
rl training, epoch5, iter0, batch17/1133, batch loss:0.2834489345550537, Training time:15029.136733055115
batch reward last col mean 0.10088474303483963 first col mean 0.10621095448732376 all mean 0.09466255456209183
0.2452077716588974 0.2452077716588974
rl training, epoch5, iter0, batch18/1133, batch loss:0.2452077716588974, Training time:15032.06057190895
batch reward last col mean 0.10606104135513306 first col mean 0.10916631668806076 all mean 0.10759944468736649
0.32562556862831116 0.32562562823295593
rl training, epoch5, iter0, batch19/1133, batch loss:0.32562562823295593, Training time:15034.552037239075
batch reward last col mean 0.0733848288655281 first col mean 0.09809475392103195 all mean 0.08342127501964569
0.27401888370513916 0.27401888370513916
rl training, epoch5, iter0, batch20/1133, batch loss:0.27401888370513916, Training time:15037.123419046402
batch reward last col mean 0.11908961087465286 first col mean 0.0880853682756424 all mean 0.1043684259057045
0.2694849371910095 0.2694849669933319
rl training, epoch5, iter0, batch21/1133, batch loss:0.2694849669933319, Training time:15039.313708543777
batch reward last col mean 0.08052605390548706 first col mean 0.08171764016151428 all mean 0.07641039043664932
0.23894937336444855 0.23894937336444855
rl training, epoch5, iter0, batch22/1133, batch loss:0.23894937336444855, Training time:15041.346145629883
batch reward last col mean 0.11363743245601654 first col mean 0.10208958387374878 all mean 0.10916800051927567
0.27835458517074585 0.27835458517074585
rl training, epoch5, iter0, batch23/1133, batch loss:0.27835458517074585, Training time:15043.457434892654
batch reward last col mean 0.10770826041698456 first col mean 0.10130110383033752 all mean 0.10244327038526535
0.29962021112442017 0.29962021112442017
rl training, epoch5, iter0, batch24/1133, batch loss:0.29962021112442017, Training time:15045.828681230545
batch reward last col mean 0.09663164615631104 first col mean 0.09551411122083664 all mean 0.09575966745615005
0.2544742524623871 0.2544742524623871
rl training, epoch5, iter0, batch25/1133, batch loss:0.2544742524623871, Training time:15047.820423841476
batch reward last col mean 0.06857109069824219 first col mean 0.08871843665838242 all mean 0.07662536203861237
0.2466849684715271 0.2466849684715271
rl training, epoch5, iter0, batch26/1133, batch loss:0.2466849684715271, Training time:15050.347326040268
batch reward last col mean 0.1250724047422409 first col mean 0.0905541479587555 all mean 0.11578967422246933
0.2922893464565277 0.2922893464565277
rl training, epoch5, iter0, batch27/1133, batch loss:0.2922893464565277, Training time:15052.559918642044
batch reward last col mean 0.11492511630058289 first col mean 0.11070255190134048 all mean 0.1096968799829483
0.3131658732891083 0.3131658732891083
rl training, epoch5, iter0, batch28/1133, batch loss:0.3131658732891083, Training time:15054.982424259186
batch reward last col mean 0.09875419735908508 first col mean 0.10094334930181503 all mean 0.09614632278680801
0.23538118600845337 0.23538118600845337
rl training, epoch5, iter0, batch29/1133, batch loss:0.23538118600845337, Training time:15057.412422895432
batch reward last col mean 0.08617916703224182 first col mean 0.09350273758172989 all mean 0.09292087703943253
0.2877585291862488 0.2877585291862488
rl training, epoch5, iter0, batch30/1133, batch loss:0.2877585291862488, Training time:15060.015898227692
batch reward last col mean 0.10598821938037872 first col mean 0.11225185543298721 all mean 0.10299012064933777
0.28280848264694214 0.28280848264694214
rl training, epoch5, iter0, batch31/1133, batch loss:0.28280848264694214, Training time:15062.135255813599
batch reward last col mean 0.08402801305055618 first col mean 0.09198550134897232 all mean 0.0833645761013031
0.20111964643001556 0.20111961662769318
rl training, epoch5, iter0, batch32/1133, batch loss:0.20111961662769318, Training time:15064.930903673172
batch reward last col mean 0.09746977686882019 first col mean 0.10341724753379822 all mean 0.09194891899824142
0.24815386533737183 0.24815386533737183
rl training, epoch5, iter0, batch33/1133, batch loss:0.24815386533737183, Training time:15067.55967593193
batch reward last col mean 0.06664019823074341 first col mean 0.0970117449760437 all mean 0.07476600259542465
0.2412298023700714 0.2412298023700714
rl training, epoch5, iter0, batch34/1133, batch loss:0.2412298023700714, Training time:15070.033307313919
batch reward last col mean 0.12179705500602722 first col mean 0.10371872782707214 all mean 0.11137916892766953
0.26794400811195374 0.26794400811195374
rl training, epoch5, iter0, batch35/1133, batch loss:0.26794400811195374, Training time:15072.308411121368
batch reward last col mean 0.12880617380142212 first col mean 0.09404750168323517 all mean 0.12075264006853104
0.28755396604537964 0.28755393624305725
rl training, epoch5, iter0, batch36/1133, batch loss:0.28755393624305725, Training time:15075.094864606857
batch reward last col mean 0.10727736353874207 first col mean 0.10412196815013885 all mean 0.10561341047286987
0.28047850728034973 0.28047850728034973
rl training, epoch5, iter0, batch37/1133, batch loss:0.28047850728034973, Training time:15077.15225148201
batch reward last col mean 0.05766947194933891 first col mean 0.10264252126216888 all mean 0.06530986726284027
0.21914254128932953 0.21914254128932953
rl training, epoch5, iter0, batch38/1133, batch loss:0.21914254128932953, Training time:15079.486123800278
batch reward last col mean 0.1107497438788414 first col mean 0.10325072705745697 all mean 0.1058836430311203
0.30872833728790283 0.30872833728790283
rl training, epoch5, iter0, batch39/1133, batch loss:0.30872833728790283, Training time:15081.807756662369
batch reward last col mean 0.08039773255586624 first col mean 0.10292749106884003 all mean 0.0838833600282669
0.27913305163383484 0.27913305163383484
rl training, epoch5, iter0, batch40/1133, batch loss:0.27913305163383484, Training time:15084.09279036522
batch reward last col mean 0.10519332438707352 first col mean 0.11380790919065475 all mean 0.10728330910205841
0.31067079305648804 0.31067079305648804
rl training, epoch5, iter0, batch41/1133, batch loss:0.31067079305648804, Training time:15086.455583810806
batch reward last col mean 0.09446084499359131 first col mean 0.10473229736089706 all mean 0.09708113223314285
0.3136856257915497 0.3136856257915497
rl training, epoch5, iter0, batch42/1133, batch loss:0.3136856257915497, Training time:15088.58235859871
batch reward last col mean 0.07311667501926422 first col mean 0.11526967585086823 all mean 0.08219706267118454
0.23483537137508392 0.23483537137508392
rl training, epoch5, iter0, batch43/1133, batch loss:0.23483537137508392, Training time:15090.563708543777
batch reward last col mean 0.09918045997619629 first col mean 0.10669634491205215 all mean 0.0972367376089096
0.2867615520954132 0.2867615818977356
rl training, epoch5, iter0, batch44/1133, batch loss:0.2867615818977356, Training time:15092.44675540924
batch reward last col mean 0.10831482708454132 first col mean 0.11542710661888123 all mean 0.10283961892127991
0.2718676030635834 0.2718676030635834
rl training, epoch5, iter0, batch45/1133, batch loss:0.2718676030635834, Training time:15094.854594945908
batch reward last col mean 0.0984698235988617 first col mean 0.09809916466474533 all mean 0.09804105758666992
0.30071449279785156 0.30071449279785156
rl training, epoch5, iter0, batch46/1133, batch loss:0.30071449279785156, Training time:15097.028110027313
batch reward last col mean 0.09784308075904846 first col mean 0.09809347242116928 all mean 0.102128766477108
0.28284502029418945 0.28284505009651184
rl training, epoch5, iter0, batch47/1133, batch loss:0.28284505009651184, Training time:15099.348358869553
batch reward last col mean 0.10848517715930939 first col mean 0.1134411171078682 all mean 0.10854142904281616
0.2823368012905121 0.2823368012905121
rl training, epoch5, iter0, batch48/1133, batch loss:0.2823368012905121, Training time:15102.628070831299
batch reward last col mean 0.08033772557973862 first col mean 0.09287247806787491 all mean 0.09095868468284607
0.27168208360671997 0.27168208360671997
rl training, epoch5, iter0, batch49/1133, batch loss:0.27168208360671997, Training time:15104.57447052002
batch reward last col mean 0.14057132601737976 first col mean 0.11698931455612183 all mean 0.1296340376138687
0.33367133140563965 0.33367133140563965
rl training, epoch5, iter0, batch50/1133, batch loss:0.33367133140563965, Training time:15106.759722709656
batch reward last col mean 0.06447678059339523 first col mean 0.10596037656068802 all mean 0.07703126221895218
0.2488487809896469 0.2488487809896469
rl training, epoch5, iter0, batch51/1133, batch loss:0.2488487809896469, Training time:15108.636624574661
batch reward last col mean 0.06098292022943497 first col mean 0.09814915060997009 all mean 0.07250010967254639
0.23764510452747345 0.23764510452747345
rl training, epoch5, iter0, batch52/1133, batch loss:0.23764510452747345, Training time:15111.265555381775
batch reward last col mean 0.07389689236879349 first col mean 0.09584107249975204 all mean 0.08442267030477524
0.2647096812725067 0.2647096812725067
rl training, epoch5, iter0, batch53/1133, batch loss:0.2647096812725067, Training time:15113.696330308914
batch reward last col mean 0.11749853193759918 first col mean 0.09857762604951859 all mean 0.10996134579181671
0.28285399079322815 0.28285399079322815
rl training, epoch5, iter0, batch54/1133, batch loss:0.28285399079322815, Training time:15115.621390342712
batch reward last col mean 0.12164399027824402 first col mean 0.10264188051223755 all mean 0.11865539848804474
0.3161761164665222 0.3161761164665222
rl training, epoch5, iter0, batch55/1133, batch loss:0.3161761164665222, Training time:15117.547050476074
batch reward last col mean 0.09554042667150497 first col mean 0.10162658244371414 all mean 0.09722153097391129
0.2646949887275696 0.2646949887275696
rl training, epoch5, iter0, batch56/1133, batch loss:0.2646949887275696, Training time:15119.530081987381
batch reward last col mean 0.09376154094934464 first col mean 0.08662088215351105 all mean 0.09971097856760025
0.30314725637435913 0.30314725637435913
rl training, epoch5, iter0, batch57/1133, batch loss:0.30314725637435913, Training time:15121.968950510025
batch reward last col mean 0.0959864929318428 first col mean 0.0901111513376236 all mean 0.09802945703268051
0.28590211272239685 0.28590211272239685
rl training, epoch5, iter0, batch58/1133, batch loss:0.28590211272239685, Training time:15125.374786376953
batch reward last col mean 0.1027258038520813 first col mean 0.09570115804672241 all mean 0.10152263194322586
0.2426498830318451 0.2426498830318451
rl training, epoch5, iter0, batch59/1133, batch loss:0.2426498830318451, Training time:15127.356475830078
batch reward last col mean 0.09116128832101822 first col mean 0.10652900487184525 all mean 0.08999427407979965
0.26457586884498596 0.26457586884498596
rl training, epoch5, iter0, batch60/1133, batch loss:0.26457586884498596, Training time:15129.990008115768
batch reward last col mean 0.07682295888662338 first col mean 0.09813062846660614 all mean 0.0827808529138565
0.24974679946899414 0.24974679946899414
rl training, epoch5, iter0, batch61/1133, batch loss:0.24974679946899414, Training time:15132.18063735962
batch reward last col mean 0.13641482591629028 first col mean 0.11239702999591827 all mean 0.12558060884475708
0.3234550654888153 0.3234550654888153
rl training, epoch5, iter0, batch62/1133, batch loss:0.3234550654888153, Training time:15134.590474367142
batch reward last col mean 0.0818479061126709 first col mean 0.10321346670389175 all mean 0.08882585912942886
0.27557840943336487 0.27557840943336487
rl training, epoch5, iter0, batch63/1133, batch loss:0.27557840943336487, Training time:15136.668291091919
batch reward last col mean 0.07822290062904358 first col mean 0.12264294922351837 all mean 0.08398368209600449
0.2657864987850189 0.2657864987850189
rl training, epoch5, iter0, batch64/1133, batch loss:0.2657864987850189, Training time:15139.085197687149
batch reward last col mean 0.09930384159088135 first col mean 0.10769860446453094 all mean 0.10301127284765244
0.296024352312088 0.296024352312088
rl training, epoch5, iter0, batch65/1133, batch loss:0.296024352312088, Training time:15141.468202352524
batch reward last col mean 0.10375139117240906 first col mean 0.10184865444898605 all mean 0.10385854542255402
0.2779953181743622 0.2779953181743622
rl training, epoch5, iter0, batch66/1133, batch loss:0.2779953181743622, Training time:15144.37462759018
batch reward last col mean 0.06582792848348618 first col mean 0.11029806733131409 all mean 0.07324825972318649
0.2533964216709137 0.2533964216709137
rl training, epoch5, iter0, batch67/1133, batch loss:0.2533964216709137, Training time:15146.71346616745
batch reward last col mean 0.10629670321941376 first col mean 0.09562571346759796 all mean 0.10627433657646179
0.2539215683937073 0.2539215683937073
rl training, epoch5, iter0, batch68/1133, batch loss:0.2539215683937073, Training time:15148.850660800934
batch reward last col mean 0.09056232124567032 first col mean 0.09060626477003098 all mean 0.09669583290815353
0.2545214891433716 0.2545214891433716
rl training, epoch5, iter0, batch69/1133, batch loss:0.2545214891433716, Training time:15151.702862262726
batch reward last col mean 0.06795963644981384 first col mean 0.10344329476356506 all mean 0.07773032784461975
0.28866085410118103 0.2886608839035034
rl training, epoch5, iter0, batch70/1133, batch loss:0.2886608839035034, Training time:15154.35454750061
batch reward last col mean 0.07566695660352707 first col mean 0.09064769744873047 all mean 0.08375202119350433
0.22748132050037384 0.22748133540153503
rl training, epoch5, iter0, batch71/1133, batch loss:0.22748133540153503, Training time:15157.16288971901
batch reward last col mean 0.14462760090827942 first col mean 0.09396450221538544 all mean 0.1318838894367218
0.2935371994972229 0.2935371994972229
rl training, epoch5, iter0, batch72/1133, batch loss:0.2935371994972229, Training time:15160.080565929413
batch reward last col mean 0.10677865147590637 first col mean 0.09071909636259079 all mean 0.10883144289255142
0.2913160026073456 0.29131603240966797
rl training, epoch5, iter0, batch73/1133, batch loss:0.29131603240966797, Training time:15162.956785440445
batch reward last col mean 0.08168911933898926 first col mean 0.10849692672491074 all mean 0.08709797263145447
0.2601940631866455 0.2601940631866455
rl training, epoch5, iter0, batch74/1133, batch loss:0.2601940631866455, Training time:15165.66362118721
batch reward last col mean 0.1232643723487854 first col mean 0.09722750633955002 all mean 0.11782699078321457
0.3088667690753937 0.3088667690753937
rl training, epoch5, iter0, batch75/1133, batch loss:0.3088667690753937, Training time:15167.945463895798
batch reward last col mean 0.09242004156112671 first col mean 0.1141769289970398 all mean 0.09656504541635513
0.27366903424263 0.2736690044403076
rl training, epoch5, iter0, batch76/1133, batch loss:0.2736690044403076, Training time:15170.138804912567
batch reward last col mean 0.09827911853790283 first col mean 0.09602337330579758 all mean 0.09960076212882996
0.27252626419067383 0.27252626419067383
rl training, epoch5, iter0, batch77/1133, batch loss:0.27252626419067383, Training time:15172.16303396225
batch reward last col mean 0.09069503843784332 first col mean 0.09764523804187775 all mean 0.09771677851676941
0.3424113094806671 0.3424113094806671
rl training, epoch5, iter0, batch78/1133, batch loss:0.3424113094806671, Training time:15174.046543836594
batch reward last col mean 0.11717052757740021 first col mean 0.10565929114818573 all mean 0.11004841327667236
0.3095468282699585 0.3095468282699585
rl training, epoch5, iter0, batch79/1133, batch loss:0.3095468282699585, Training time:15176.071274757385
batch reward last col mean 0.08533614873886108 first col mean 0.11179172992706299 all mean 0.09160260111093521
0.26654478907585144 0.26654478907585144
rl training, epoch5, iter0, batch80/1133, batch loss:0.26654478907585144, Training time:15178.406615257263
batch reward last col mean 0.10472368448972702 first col mean 0.09917566180229187 all mean 0.09975225478410721
0.2885037958621979 0.2885037958621979
rl training, epoch5, iter0, batch81/1133, batch loss:0.2885037958621979, Training time:15180.412110328674
batch reward last col mean 0.07785943150520325 first col mean 0.12020822614431381 all mean 0.08594717085361481
0.29819315671920776 0.29819315671920776
rl training, epoch5, iter0, batch82/1133, batch loss:0.29819315671920776, Training time:15183.055498361588
batch reward last col mean 0.060566697269678116 first col mean 0.11045937240123749 all mean 0.0717984139919281
0.25113344192504883 0.25113344192504883
rl training, epoch5, iter0, batch83/1133, batch loss:0.25113344192504883, Training time:15186.317586898804
batch reward last col mean 0.10583104193210602 first col mean 0.10784608125686646 all mean 0.10306656360626221
0.3128926753997803 0.3128926753997803
rl training, epoch5, iter0, batch84/1133, batch loss:0.3128926753997803, Training time:15188.379751205444
batch reward last col mean 0.1035165786743164 first col mean 0.13872742652893066 all mean 0.10601672530174255
0.3218119144439697 0.3218119144439697
rl training, epoch5, iter0, batch85/1133, batch loss:0.3218119144439697, Training time:15190.526689052582
batch reward last col mean 0.08423952758312225 first col mean 0.09992799907922745 all mean 0.08610702306032181
0.2576412856578827 0.2576412856578827
rl training, epoch5, iter0, batch86/1133, batch loss:0.2576412856578827, Training time:15192.601478099823
batch reward last col mean 0.1128639355301857 first col mean 0.1158597320318222 all mean 0.10886599123477936
0.30665475130081177 0.30665475130081177
rl training, epoch5, iter0, batch87/1133, batch loss:0.30665475130081177, Training time:15194.961087942123
batch reward last col mean 0.11353671550750732 first col mean 0.11338586360216141 all mean 0.10948488116264343
0.305422306060791 0.305422306060791
rl training, epoch5, iter0, batch88/1133, batch loss:0.305422306060791, Training time:15197.734152317047
batch reward last col mean 0.10912153124809265 first col mean 0.09831979870796204 all mean 0.10221672803163528
0.27608370780944824 0.27608370780944824
rl training, epoch5, iter0, batch89/1133, batch loss:0.27608370780944824, Training time:15199.862037420273
batch reward last col mean 0.08163538575172424 first col mean 0.08047065883874893 all mean 0.08981521427631378
0.2894234359264374 0.2894234359264374
rl training, epoch5, iter0, batch90/1133, batch loss:0.2894234359264374, Training time:15202.540765285492
batch reward last col mean 0.10114842653274536 first col mean 0.10000959038734436 all mean 0.10318826138973236
0.30434757471084595 0.30434757471084595
rl training, epoch5, iter0, batch91/1133, batch loss:0.30434757471084595, Training time:15205.368093013763
batch reward last col mean 0.11253177374601364 first col mean 0.10961560159921646 all mean 0.10658849775791168
0.30602002143859863 0.30602002143859863
rl training, epoch5, iter0, batch92/1133, batch loss:0.30602002143859863, Training time:15207.541534900665
batch reward last col mean 0.09528768807649612 first col mean 0.1156604140996933 all mean 0.09874773770570755
0.2766193151473999 0.2766193151473999
rl training, epoch5, iter0, batch93/1133, batch loss:0.2766193151473999, Training time:15210.81699848175
batch reward last col mean 0.07773157954216003 first col mean 0.11650703847408295 all mean 0.08694326877593994
0.29016438126564026 0.29016438126564026
rl training, epoch5, iter0, batch94/1133, batch loss:0.29016438126564026, Training time:15212.972709417343
batch reward last col mean 0.11243639886379242 first col mean 0.09555164724588394 all mean 0.11056340485811234
0.3228137791156769 0.3228137791156769
rl training, epoch5, iter0, batch95/1133, batch loss:0.3228137791156769, Training time:15214.889085769653
batch reward last col mean 0.10440638661384583 first col mean 0.11470014601945877 all mean 0.10896971076726913
0.317364901304245 0.317364901304245
rl training, epoch5, iter0, batch96/1133, batch loss:0.317364901304245, Training time:15216.88815832138
batch reward last col mean 0.0898866280913353 first col mean 0.09318413585424423 all mean 0.09555927664041519
0.2613232433795929 0.2613232433795929
rl training, epoch5, iter0, batch97/1133, batch loss:0.2613232433795929, Training time:15219.455024242401
batch reward last col mean 0.09670911729335785 first col mean 0.1051928848028183 all mean 0.10073976963758469
0.2874235212802887 0.2874235212802887
rl training, epoch5, iter0, batch98/1133, batch loss:0.2874235212802887, Training time:15221.897277355194
batch reward last col mean 0.09830497950315475 first col mean 0.12125140428543091 all mean 0.1013571172952652
0.26999127864837646 0.26999127864837646
rl training, epoch5, iter0, batch99/1133, batch loss:0.26999127864837646, Training time:15224.012556552887
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4835991778156974 Time: 97.79550099372864 s
loss of true 0.2084815348551953 loss of gen 0.17284923133301397 loss of other 0.10226841294432729 first score 0.11753953993320465
batch reward last col mean 0.13527946174144745 first col mean 0.0929657518863678 all mean 0.12179430574178696
0.3078077733516693 0.3078077733516693
rl training, epoch5, iter0, batch100/1133, batch loss:0.3078077733516693, Training time:15324.075226545334
batch reward last col mean 0.09399864822626114 first col mean 0.08747325837612152 all mean 0.09410222619771957
0.2964004576206207 0.2964004576206207
rl training, epoch5, iter0, batch101/1133, batch loss:0.2964004576206207, Training time:15326.423025369644
batch reward last col mean 0.12271523475646973 first col mean 0.10693700611591339 all mean 0.11360172182321548
0.2810581922531128 0.2810581922531128
rl training, epoch5, iter0, batch102/1133, batch loss:0.2810581922531128, Training time:15328.486288309097
batch reward last col mean 0.11583346873521805 first col mean 0.11446153372526169 all mean 0.11213462054729462
0.3015080988407135 0.3015080988407135
rl training, epoch5, iter0, batch103/1133, batch loss:0.3015080988407135, Training time:15330.294725894928
batch reward last col mean 0.08355933427810669 first col mean 0.09386292099952698 all mean 0.0822579562664032
0.2715773582458496 0.2715773582458496
rl training, epoch5, iter0, batch104/1133, batch loss:0.2715773582458496, Training time:15332.506368160248
batch reward last col mean 0.06671297550201416 first col mean 0.10587601363658905 all mean 0.07803479582071304
0.264575719833374 0.264575719833374
rl training, epoch5, iter0, batch105/1133, batch loss:0.264575719833374, Training time:15334.469603776932
batch reward last col mean 0.10893139988183975 first col mean 0.0954190194606781 all mean 0.10490173101425171
0.2955120801925659 0.2955120801925659
rl training, epoch5, iter0, batch106/1133, batch loss:0.2955120801925659, Training time:15337.276245594025
batch reward last col mean 0.09101828187704086 first col mean 0.10678870975971222 all mean 0.0974045991897583
0.263419508934021 0.263419508934021
rl training, epoch5, iter0, batch107/1133, batch loss:0.263419508934021, Training time:15338.95412683487
batch reward last col mean 0.10044443607330322 first col mean 0.09341724216938019 all mean 0.09523633867502213
0.26323702931404114 0.26323702931404114
rl training, epoch5, iter0, batch108/1133, batch loss:0.26323702931404114, Training time:15341.183367013931
batch reward last col mean 0.11664998531341553 first col mean 0.09159278124570847 all mean 0.10944255441427231
0.2864135205745697 0.2864135205745697
rl training, epoch5, iter0, batch109/1133, batch loss:0.2864135205745697, Training time:15342.847838878632
batch reward last col mean 0.07328657060861588 first col mean 0.10542327165603638 all mean 0.08260456472635269
0.27068787813186646 0.27068787813186646
rl training, epoch5, iter0, batch110/1133, batch loss:0.27068787813186646, Training time:15344.588449954987
batch reward last col mean 0.09252583980560303 first col mean 0.10152015835046768 all mean 0.09397301822900772
0.270324170589447 0.270324170589447
rl training, epoch5, iter0, batch111/1133, batch loss:0.270324170589447, Training time:15346.735679626465
batch reward last col mean 0.10533330589532852 first col mean 0.09108709543943405 all mean 0.10379685461521149
0.2802327871322632 0.2802327871322632
rl training, epoch5, iter0, batch112/1133, batch loss:0.2802327871322632, Training time:15348.6956949234
batch reward last col mean 0.08986426889896393 first col mean 0.1062157154083252 all mean 0.09558825194835663
0.2801739275455475 0.2801739275455475
rl training, epoch5, iter0, batch113/1133, batch loss:0.2801739275455475, Training time:15350.817312955856
batch reward last col mean 0.06095702201128006 first col mean 0.11016958951950073 all mean 0.07621121406555176
0.26012375950813293 0.26012375950813293
rl training, epoch5, iter0, batch114/1133, batch loss:0.26012375950813293, Training time:15352.746794939041
batch reward last col mean 0.10543247312307358 first col mean 0.10960081964731216 all mean 0.10603442788124084
0.3048606514930725 0.3048606216907501
rl training, epoch5, iter0, batch115/1133, batch loss:0.3048606216907501, Training time:15355.969828605652
batch reward last col mean 0.14625906944274902 first col mean 0.06564667820930481 all mean 0.13467907905578613
0.3109162747859955 0.3109162747859955
rl training, epoch5, iter0, batch116/1133, batch loss:0.3109162747859955, Training time:15358.376723527908
batch reward last col mean 0.13469921052455902 first col mean 0.10930904746055603 all mean 0.13471415638923645
0.352041095495224 0.352041095495224
rl training, epoch5, iter0, batch117/1133, batch loss:0.352041095495224, Training time:15360.834312915802
batch reward last col mean 0.08849788457155228 first col mean 0.09538063406944275 all mean 0.09104615449905396
0.2560088336467743 0.2560088336467743
rl training, epoch5, iter0, batch118/1133, batch loss:0.2560088336467743, Training time:15363.743710279465
batch reward last col mean 0.07863862812519073 first col mean 0.09217269718647003 all mean 0.08334266394376755
0.26890066266059875 0.26890066266059875
rl training, epoch5, iter0, batch119/1133, batch loss:0.26890066266059875, Training time:15365.560016393661
batch reward last col mean 0.08809937536716461 first col mean 0.1179589331150055 all mean 0.09486528486013412
0.2530716061592102 0.2530716061592102
rl training, epoch5, iter0, batch120/1133, batch loss:0.2530716061592102, Training time:15367.29223036766
batch reward last col mean 0.05671549588441849 first col mean 0.09722360968589783 all mean 0.0681641697883606
0.2610003352165222 0.26100030541419983
rl training, epoch5, iter0, batch121/1133, batch loss:0.26100030541419983, Training time:15369.51755785942
batch reward last col mean 0.1060146614909172 first col mean 0.11432910710573196 all mean 0.10643503069877625
0.293478399515152 0.2934783697128296
rl training, epoch5, iter0, batch122/1133, batch loss:0.2934783697128296, Training time:15372.186366558075
batch reward last col mean 0.1175471618771553 first col mean 0.0968276634812355 all mean 0.10750390589237213
0.28478580713272095 0.28478577733039856
rl training, epoch5, iter0, batch123/1133, batch loss:0.28478577733039856, Training time:15373.910639047623
batch reward last col mean 0.07823848724365234 first col mean 0.0793493390083313 all mean 0.08699353039264679
0.2566976547241211 0.2566976547241211
rl training, epoch5, iter0, batch124/1133, batch loss:0.2566976547241211, Training time:15375.768042325974
batch reward last col mean 0.10781049728393555 first col mean 0.08814015239477158 all mean 0.10905919969081879
0.3155958652496338 0.3155958354473114
rl training, epoch5, iter0, batch125/1133, batch loss:0.3155958354473114, Training time:15378.026982069016
batch reward last col mean 0.101519376039505 first col mean 0.0958678275346756 all mean 0.10200143605470657
0.3091614842414856 0.3091614842414856
rl training, epoch5, iter0, batch126/1133, batch loss:0.3091614842414856, Training time:15380.014837503433
batch reward last col mean 0.07188734412193298 first col mean 0.09725584089756012 all mean 0.07513996958732605
0.22862717509269714 0.22862717509269714
rl training, epoch5, iter0, batch127/1133, batch loss:0.22862717509269714, Training time:15382.213547706604
batch reward last col mean 0.09670698642730713 first col mean 0.1086983010172844 all mean 0.10195007920265198
0.29545822739601135 0.29545822739601135
rl training, epoch5, iter0, batch128/1133, batch loss:0.29545822739601135, Training time:15383.945343494415
batch reward last col mean 0.11433082818984985 first col mean 0.09566441923379898 all mean 0.11483001708984375
0.2748751640319824 0.2748751640319824
rl training, epoch5, iter0, batch129/1133, batch loss:0.2748751640319824, Training time:15386.513263463974
batch reward last col mean 0.10704471915960312 first col mean 0.10173646360635757 all mean 0.11102000623941422
0.3035292327404022 0.3035292327404022
rl training, epoch5, iter0, batch130/1133, batch loss:0.3035292327404022, Training time:15388.702281475067
batch reward last col mean 0.08183024078607559 first col mean 0.10975220799446106 all mean 0.0902765765786171
0.29338133335113525 0.29338133335113525
rl training, epoch5, iter0, batch131/1133, batch loss:0.29338133335113525, Training time:15390.641640424728
batch reward last col mean 0.08857955783605576 first col mean 0.10461877286434174 all mean 0.08922812342643738
0.26443400979042053 0.26443400979042053
rl training, epoch5, iter0, batch132/1133, batch loss:0.26443400979042053, Training time:15392.80523633957
batch reward last col mean 0.0763108879327774 first col mean 0.08634636551141739 all mean 0.08499062806367874
0.30579662322998047 0.30579662322998047
rl training, epoch5, iter0, batch133/1133, batch loss:0.30579662322998047, Training time:15395.450020551682
batch reward last col mean 0.07251103222370148 first col mean 0.10329459607601166 all mean 0.08165767043828964
0.286641925573349 0.286641925573349
rl training, epoch5, iter0, batch134/1133, batch loss:0.286641925573349, Training time:15397.829926013947
batch reward last col mean 0.10909172892570496 first col mean 0.08997777849435806 all mean 0.10319393128156662
0.2787151634693146 0.27871519327163696
rl training, epoch5, iter0, batch135/1133, batch loss:0.27871519327163696, Training time:15399.598420619965
batch reward last col mean 0.09502729028463364 first col mean 0.12150223553180695 all mean 0.10534382611513138
0.3042661249637604 0.3042661249637604
rl training, epoch5, iter0, batch136/1133, batch loss:0.3042661249637604, Training time:15401.763522863388
batch reward last col mean 0.0688389465212822 first col mean 0.09778844565153122 all mean 0.07876092195510864
0.2829884886741638 0.2829884886741638
rl training, epoch5, iter0, batch137/1133, batch loss:0.2829884886741638, Training time:15403.76316666603
batch reward last col mean 0.10705320537090302 first col mean 0.11767157912254333 all mean 0.10364194959402084
0.28097304701805115 0.28097304701805115
rl training, epoch5, iter0, batch138/1133, batch loss:0.28097304701805115, Training time:15406.114714622498
batch reward last col mean 0.10401497781276703 first col mean 0.1193329244852066 all mean 0.1019943505525589
0.30243411660194397 0.30243411660194397
rl training, epoch5, iter0, batch139/1133, batch loss:0.30243411660194397, Training time:15407.90393280983
batch reward last col mean 0.10369201004505157 first col mean 0.11529526114463806 all mean 0.10276510566473007
0.25954845547676086 0.25954845547676086
rl training, epoch5, iter0, batch140/1133, batch loss:0.25954845547676086, Training time:15410.575659751892
batch reward last col mean 0.10164517909288406 first col mean 0.09103966504335403 all mean 0.09827253222465515
0.32185861468315125 0.32185861468315125
rl training, epoch5, iter0, batch141/1133, batch loss:0.32185861468315125, Training time:15412.275610208511
batch reward last col mean 0.12633472681045532 first col mean 0.09885609149932861 all mean 0.12365081906318665
0.3193438947200775 0.3193438947200775
rl training, epoch5, iter0, batch142/1133, batch loss:0.3193438947200775, Training time:15414.230489730835
batch reward last col mean 0.1283693015575409 first col mean 0.11504499614238739 all mean 0.1190371885895729
0.29932311177253723 0.2993231415748596
rl training, epoch5, iter0, batch143/1133, batch loss:0.2993231415748596, Training time:15417.40305685997
batch reward last col mean 0.0820709764957428 first col mean 0.1084136813879013 all mean 0.0851597711443901
0.2618109881877899 0.2618109881877899
rl training, epoch5, iter0, batch144/1133, batch loss:0.2618109881877899, Training time:15419.784080982208
batch reward last col mean 0.11419227719306946 first col mean 0.10818265378475189 all mean 0.11006440967321396
0.321373850107193 0.321373850107193
rl training, epoch5, iter0, batch145/1133, batch loss:0.321373850107193, Training time:15422.182787179947
batch reward last col mean 0.0769040435552597 first col mean 0.11563755571842194 all mean 0.08313068002462387
0.2809332013130188 0.2809332013130188
rl training, epoch5, iter0, batch146/1133, batch loss:0.2809332013130188, Training time:15424.73576593399
batch reward last col mean 0.09637037664651871 first col mean 0.1017247885465622 all mean 0.09926017373800278
0.2769799828529358 0.2769799828529358
rl training, epoch5, iter0, batch147/1133, batch loss:0.2769799828529358, Training time:15426.31968998909
batch reward last col mean 0.0901552215218544 first col mean 0.09289614111185074 all mean 0.09121129661798477
0.23991350829601288 0.23991350829601288
rl training, epoch5, iter0, batch148/1133, batch loss:0.23991350829601288, Training time:15428.060180902481
batch reward last col mean 0.0838712751865387 first col mean 0.09577387571334839 all mean 0.09456628561019897
0.29505184292793274 0.29505184292793274
rl training, epoch5, iter0, batch149/1133, batch loss:0.29505184292793274, Training time:15430.680433034897
batch reward last col mean 0.09834954142570496 first col mean 0.09240156412124634 all mean 0.1018364354968071
0.2850879430770874 0.2850879430770874
rl training, epoch5, iter0, batch150/1133, batch loss:0.2850879430770874, Training time:15432.72103023529
batch reward last col mean 0.08219534903764725 first col mean 0.10665157437324524 all mean 0.09268768876791
0.29068928956985474 0.29068928956985474
rl training, epoch5, iter0, batch151/1133, batch loss:0.29068928956985474, Training time:15435.096961975098
batch reward last col mean 0.07987234741449356 first col mean 0.11318661272525787 all mean 0.0887683853507042
0.28304779529571533 0.28304779529571533
rl training, epoch5, iter0, batch152/1133, batch loss:0.28304779529571533, Training time:15436.960804700851
batch reward last col mean 0.12328372150659561 first col mean 0.11030712723731995 all mean 0.12038253992795944
0.30407506227493286 0.30407506227493286
rl training, epoch5, iter0, batch153/1133, batch loss:0.30407506227493286, Training time:15438.927601099014
batch reward last col mean 0.11853818595409393 first col mean 0.11240462958812714 all mean 0.11641314625740051
0.3147391378879547 0.3147391676902771
rl training, epoch5, iter0, batch154/1133, batch loss:0.3147391676902771, Training time:15441.359410762787
batch reward last col mean 0.0831485390663147 first col mean 0.11121778190135956 all mean 0.0869775339961052
0.25072208046913147 0.25072208046913147
rl training, epoch5, iter0, batch155/1133, batch loss:0.25072208046913147, Training time:15443.376584768295
batch reward last col mean 0.13154727220535278 first col mean 0.1129908636212349 all mean 0.12390162795782089
0.3239225149154663 0.3239225149154663
rl training, epoch5, iter0, batch156/1133, batch loss:0.3239225149154663, Training time:15445.306129932404
batch reward last col mean 0.09497968852519989 first col mean 0.1114308163523674 all mean 0.09747358411550522
0.2710365653038025 0.2710365653038025
rl training, epoch5, iter0, batch157/1133, batch loss:0.2710365653038025, Training time:15447.66318321228
batch reward last col mean 0.12638382613658905 first col mean 0.11366821825504303 all mean 0.12495899200439453
0.31665346026420593 0.31665346026420593
rl training, epoch5, iter0, batch158/1133, batch loss:0.31665346026420593, Training time:15450.148969173431
batch reward last col mean 0.12373483926057816 first col mean 0.1030852347612381 all mean 0.11292508989572525
0.30334141850471497 0.30334141850471497
rl training, epoch5, iter0, batch159/1133, batch loss:0.30334141850471497, Training time:15452.228407382965
batch reward last col mean 0.1143450140953064 first col mean 0.09965213388204575 all mean 0.10599203407764435
0.294709175825119 0.294709175825119
rl training, epoch5, iter0, batch160/1133, batch loss:0.294709175825119, Training time:15454.905291557312
batch reward last col mean 0.0846870020031929 first col mean 0.10181595385074615 all mean 0.08775661140680313
0.24544616043567657 0.24544616043567657
rl training, epoch5, iter0, batch161/1133, batch loss:0.24544616043567657, Training time:15457.803013801575
batch reward last col mean 0.1088842898607254 first col mean 0.10052411258220673 all mean 0.10958978533744812
0.2842065691947937 0.2842065691947937
rl training, epoch5, iter0, batch162/1133, batch loss:0.2842065691947937, Training time:15460.149805545807
batch reward last col mean 0.08733890950679779 first col mean 0.11589276045560837 all mean 0.08833587914705276
0.2651306688785553 0.2651306688785553
rl training, epoch5, iter0, batch163/1133, batch loss:0.2651306688785553, Training time:15462.365569353104
batch reward last col mean 0.11619314551353455 first col mean 0.0950726568698883 all mean 0.11904267966747284
0.33136916160583496 0.33136916160583496
rl training, epoch5, iter0, batch164/1133, batch loss:0.33136916160583496, Training time:15464.766383171082
batch reward last col mean 0.11670386046171188 first col mean 0.10992011427879333 all mean 0.10636413842439651
0.28138941526412964 0.28138941526412964
rl training, epoch5, iter0, batch165/1133, batch loss:0.28138941526412964, Training time:15467.014913797379
batch reward last col mean 0.10408706963062286 first col mean 0.10559229552745819 all mean 0.10753270983695984
0.2938721776008606 0.2938721477985382
rl training, epoch5, iter0, batch166/1133, batch loss:0.2938721477985382, Training time:15469.999617099762
batch reward last col mean 0.11065548658370972 first col mean 0.09697884321212769 all mean 0.10660627484321594
0.2940760552883148 0.2940760850906372
rl training, epoch5, iter0, batch167/1133, batch loss:0.2940760850906372, Training time:15472.794672489166
batch reward last col mean 0.08789661526679993 first col mean 0.1263687163591385 all mean 0.09750867635011673
0.3001633286476135 0.3001633584499359
rl training, epoch5, iter0, batch168/1133, batch loss:0.3001633584499359, Training time:15475.156574249268
batch reward last col mean 0.10860178619623184 first col mean 0.08972567319869995 all mean 0.10468244552612305
0.27108120918273926 0.27108120918273926
rl training, epoch5, iter0, batch169/1133, batch loss:0.27108120918273926, Training time:15478.209042549133
batch reward last col mean 0.10205026715993881 first col mean 0.11993759870529175 all mean 0.10485934466123581
0.32360848784446716 0.32360848784446716
rl training, epoch5, iter0, batch170/1133, batch loss:0.32360848784446716, Training time:15480.779195308685
batch reward last col mean 0.07153769582509995 first col mean 0.11314193904399872 all mean 0.07939699292182922
0.2759222388267517 0.2759222388267517
rl training, epoch5, iter0, batch171/1133, batch loss:0.2759222388267517, Training time:15483.622386932373
batch reward last col mean 0.0950903594493866 first col mean 0.11147257685661316 all mean 0.09487675130367279
0.28574666380882263 0.28574666380882263
rl training, epoch5, iter0, batch172/1133, batch loss:0.28574666380882263, Training time:15486.037964344025
batch reward last col mean 0.10331277549266815 first col mean 0.09847655892372131 all mean 0.10835512727499008
0.27125585079193115 0.27125582098960876
rl training, epoch5, iter0, batch173/1133, batch loss:0.27125582098960876, Training time:15487.994990825653
batch reward last col mean 0.08382046222686768 first col mean 0.1253269463777542 all mean 0.08896157890558243
0.24111229181289673 0.24111229181289673
rl training, epoch5, iter0, batch174/1133, batch loss:0.24111229181289673, Training time:15489.91574215889
batch reward last col mean 0.09800370782613754 first col mean 0.09826481342315674 all mean 0.10107165575027466
0.258230984210968 0.258230984210968
rl training, epoch5, iter0, batch175/1133, batch loss:0.258230984210968, Training time:15492.329402685165
batch reward last col mean 0.09738946706056595 first col mean 0.09333615005016327 all mean 0.09795021265745163
0.2766822278499603 0.2766822278499603
rl training, epoch5, iter0, batch176/1133, batch loss:0.2766822278499603, Training time:15494.634380102158
batch reward last col mean 0.11919218301773071 first col mean 0.09837068617343903 all mean 0.11106635630130768
0.2735978364944458 0.2735978364944458
rl training, epoch5, iter0, batch177/1133, batch loss:0.2735978364944458, Training time:15497.456838607788
batch reward last col mean 0.1424122452735901 first col mean 0.1414889097213745 all mean 0.13762697577476501
0.3206406533718109 0.3206406533718109
rl training, epoch5, iter0, batch178/1133, batch loss:0.3206406533718109, Training time:15500.709944963455
batch reward last col mean 0.10803939402103424 first col mean 0.10436532646417618 all mean 0.10720504820346832
0.30485159158706665 0.30485159158706665
rl training, epoch5, iter0, batch179/1133, batch loss:0.30485159158706665, Training time:15503.123195648193
batch reward last col mean 0.10637274384498596 first col mean 0.11261098086833954 all mean 0.10474144667387009
0.33336660265922546 0.33336660265922546
rl training, epoch5, iter0, batch180/1133, batch loss:0.33336660265922546, Training time:15505.345755338669
batch reward last col mean 0.11597338318824768 first col mean 0.10008139163255692 all mean 0.11502540856599808
0.3216998875141144 0.3216998875141144
rl training, epoch5, iter0, batch181/1133, batch loss:0.3216998875141144, Training time:15507.471366882324
batch reward last col mean 0.09507675468921661 first col mean 0.10784561932086945 all mean 0.0956365317106247
0.2701440453529358 0.2701440453529358
rl training, epoch5, iter0, batch182/1133, batch loss:0.2701440453529358, Training time:15509.721264362335
batch reward last col mean 0.10139414668083191 first col mean 0.12066865712404251 all mean 0.10758194327354431
0.2984735667705536 0.298473596572876
rl training, epoch5, iter0, batch183/1133, batch loss:0.298473596572876, Training time:15511.544805765152
batch reward last col mean 0.10156846791505814 first col mean 0.09436248242855072 all mean 0.10182637721300125
0.28154924511909485 0.28154924511909485
rl training, epoch5, iter0, batch184/1133, batch loss:0.28154924511909485, Training time:15514.995288610458
batch reward last col mean 0.11579660326242447 first col mean 0.11962936818599701 all mean 0.11864574253559113
0.3086148202419281 0.3086147904396057
rl training, epoch5, iter0, batch185/1133, batch loss:0.3086147904396057, Training time:15517.457118988037
batch reward last col mean 0.12001465260982513 first col mean 0.1133035197854042 all mean 0.1193142682313919
0.34162718057632446 0.34162718057632446
rl training, epoch5, iter0, batch186/1133, batch loss:0.34162718057632446, Training time:15521.150835037231
batch reward last col mean 0.07190738618373871 first col mean 0.11226870119571686 all mean 0.08082771301269531
0.2773558795452118 0.2773558795452118
rl training, epoch5, iter0, batch187/1133, batch loss:0.2773558795452118, Training time:15523.32771897316
batch reward last col mean 0.08102945238351822 first col mean 0.12165520340204239 all mean 0.08900657296180725
0.2692607641220093 0.2692607641220093
rl training, epoch5, iter0, batch188/1133, batch loss:0.2692607641220093, Training time:15525.53073501587
batch reward last col mean 0.10427951067686081 first col mean 0.09360341727733612 all mean 0.09562021493911743
0.2680720388889313 0.2680720388889313
rl training, epoch5, iter0, batch189/1133, batch loss:0.2680720388889313, Training time:15528.047440052032
batch reward last col mean 0.10087650269269943 first col mean 0.10925465822219849 all mean 0.1011858657002449
0.29069167375564575 0.29069167375564575
rl training, epoch5, iter0, batch190/1133, batch loss:0.29069167375564575, Training time:15530.245826244354
batch reward last col mean 0.12688308954238892 first col mean 0.08876913040876389 all mean 0.1257561296224594
0.34771791100502014 0.34771791100502014
rl training, epoch5, iter0, batch191/1133, batch loss:0.34771791100502014, Training time:15532.507079839706
batch reward last col mean 0.08592446148395538 first col mean 0.09537117183208466 all mean 0.09151367098093033
0.2661687433719635 0.2661687433719635
rl training, epoch5, iter0, batch192/1133, batch loss:0.2661687433719635, Training time:15535.01209306717
batch reward last col mean 0.13801275193691254 first col mean 0.10212956368923187 all mean 0.12792783975601196
0.34425675868988037 0.34425675868988037
rl training, epoch5, iter0, batch193/1133, batch loss:0.34425675868988037, Training time:15537.20749425888
batch reward last col mean 0.08211593329906464 first col mean 0.10336446017026901 all mean 0.09190458804368973
0.27481743693351746 0.27481743693351746
rl training, epoch5, iter0, batch194/1133, batch loss:0.27481743693351746, Training time:15539.15085887909
batch reward last col mean 0.07958738505840302 first col mean 0.11900748312473297 all mean 0.09369147568941116
0.302912175655365 0.3029121458530426
rl training, epoch5, iter0, batch195/1133, batch loss:0.3029121458530426, Training time:15541.16536784172
batch reward last col mean 0.09136751294136047 first col mean 0.10987120121717453 all mean 0.0962999239563942
0.2519470155239105 0.2519470155239105
rl training, epoch5, iter0, batch196/1133, batch loss:0.2519470155239105, Training time:15543.283632516861
batch reward last col mean 0.1112762913107872 first col mean 0.11413955688476562 all mean 0.1131151095032692
0.28736647963523865 0.28736647963523865
rl training, epoch5, iter0, batch197/1133, batch loss:0.28736647963523865, Training time:15545.164182901382
batch reward last col mean 0.07465094327926636 first col mean 0.11248357594013214 all mean 0.08497409522533417
0.2557985782623291 0.2557985782623291
rl training, epoch5, iter0, batch198/1133, batch loss:0.2557985782623291, Training time:15547.501346826553
batch reward last col mean 0.06582500040531158 first col mean 0.10502549260854721 all mean 0.08301692456007004
0.264793336391449 0.264793336391449
rl training, epoch5, iter0, batch199/1133, batch loss:0.264793336391449, Training time:15549.433444976807
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.49370334112633674 Time: 99.77576088905334 s
loss of true 0.21304572526191254 loss of gen 0.1784075583871339 loss of other 0.1022500576104538 first score 0.13190262019634247
batch reward last col mean 0.08680626004934311 first col mean 0.10988955199718475 all mean 0.09033028781414032
0.22195573151111603 0.22195573151111603
rl training, epoch5, iter0, batch200/1133, batch loss:0.22195573151111603, Training time:15651.275804042816
batch reward last col mean 0.10604169964790344 first col mean 0.11397156119346619 all mean 0.10963527113199234
0.2918928265571594 0.2918928265571594
rl training, epoch5, iter0, batch201/1133, batch loss:0.2918928265571594, Training time:15652.991653442383
batch reward last col mean 0.10310350358486176 first col mean 0.11896108090877533 all mean 0.09655910730361938
0.2833974063396454 0.2833974063396454
rl training, epoch5, iter0, batch202/1133, batch loss:0.2833974063396454, Training time:15655.324877262115
batch reward last col mean 0.08719296753406525 first col mean 0.11389832198619843 all mean 0.09367220103740692
0.3085536062717438 0.3085536062717438
rl training, epoch5, iter0, batch203/1133, batch loss:0.3085536062717438, Training time:15657.570172786713
batch reward last col mean 0.12924528121948242 first col mean 0.11712328344583511 all mean 0.12825006246566772
0.34775811433792114 0.34775811433792114
rl training, epoch5, iter0, batch204/1133, batch loss:0.34775811433792114, Training time:15659.440604448318
batch reward last col mean 0.06227738410234451 first col mean 0.10334710776805878 all mean 0.06784947961568832
0.23479031026363373 0.23479031026363373
rl training, epoch5, iter0, batch205/1133, batch loss:0.23479031026363373, Training time:15661.810084819794
batch reward last col mean 0.08069698512554169 first col mean 0.09985200315713882 all mean 0.08577948808670044
0.28295546770095825 0.28295549750328064
rl training, epoch5, iter0, batch206/1133, batch loss:0.28295549750328064, Training time:15664.544832229614
batch reward last col mean 0.10497897863388062 first col mean 0.10455770790576935 all mean 0.10574500262737274
0.3105148673057556 0.3105148673057556
rl training, epoch5, iter0, batch207/1133, batch loss:0.3105148673057556, Training time:15666.78277683258
batch reward last col mean 0.08934306353330612 first col mean 0.10098608583211899 all mean 0.09221230447292328
0.2923177480697632 0.29231777787208557
rl training, epoch5, iter0, batch208/1133, batch loss:0.29231777787208557, Training time:15668.730735778809
batch reward last col mean 0.10617745667695999 first col mean 0.09836909919977188 all mean 0.10287797451019287
0.24154342710971832 0.24154342710971832
rl training, epoch5, iter0, batch209/1133, batch loss:0.24154342710971832, Training time:15671.062811136246
batch reward last col mean 0.10184845328330994 first col mean 0.10434882342815399 all mean 0.10219962149858475
0.2697082459926605 0.26970821619033813
rl training, epoch5, iter0, batch210/1133, batch loss:0.26970821619033813, Training time:15673.784964084625
batch reward last col mean 0.062153205275535583 first col mean 0.11777591705322266 all mean 0.0774335041642189
0.2512139678001404 0.251213937997818
rl training, epoch5, iter0, batch211/1133, batch loss:0.251213937997818, Training time:15676.295418739319
batch reward last col mean 0.09808312356472015 first col mean 0.0960802286863327 all mean 0.09803315997123718
0.29447034001350403 0.29447034001350403
rl training, epoch5, iter0, batch212/1133, batch loss:0.29447034001350403, Training time:15679.209260225296
batch reward last col mean 0.0769120305776596 first col mean 0.09370501339435577 all mean 0.08138084411621094
0.23441964387893677 0.23441965878009796
rl training, epoch5, iter0, batch213/1133, batch loss:0.23441965878009796, Training time:15681.68993473053
batch reward last col mean 0.09499792009592056 first col mean 0.1099957525730133 all mean 0.10062768310308456
0.26023271679878235 0.26023271679878235
rl training, epoch5, iter0, batch214/1133, batch loss:0.26023271679878235, Training time:15683.849278450012
batch reward last col mean 0.0702098160982132 first col mean 0.10191939026117325 all mean 0.07982116937637329
0.26292893290519714 0.26292893290519714
rl training, epoch5, iter0, batch215/1133, batch loss:0.26292893290519714, Training time:15687.01995921135
batch reward last col mean 0.08752551674842834 first col mean 0.0994100570678711 all mean 0.08550024032592773
0.27477186918258667 0.27477186918258667
rl training, epoch5, iter0, batch216/1133, batch loss:0.27477186918258667, Training time:15688.978583097458
batch reward last col mean 0.10301017761230469 first col mean 0.09190633893013 all mean 0.10444239526987076
0.26449933648109436 0.26449933648109436
rl training, epoch5, iter0, batch217/1133, batch loss:0.26449933648109436, Training time:15691.274105072021
batch reward last col mean 0.11946950107812881 first col mean 0.10278933495283127 all mean 0.10737583786249161
0.2829219698905945 0.2829219400882721
rl training, epoch5, iter0, batch218/1133, batch loss:0.2829219400882721, Training time:15693.3835709095
batch reward last col mean 0.13391900062561035 first col mean 0.09627893567085266 all mean 0.12480120360851288
0.2929368019104004 0.2929368019104004
rl training, epoch5, iter0, batch219/1133, batch loss:0.2929368019104004, Training time:15695.475184679031
batch reward last col mean 0.09695766866207123 first col mean 0.11598950624465942 all mean 0.09788644313812256
0.29277151823043823 0.29277151823043823
rl training, epoch5, iter0, batch220/1133, batch loss:0.29277151823043823, Training time:15697.944023370743
batch reward last col mean 0.10625038295984268 first col mean 0.1282525509595871 all mean 0.10097791999578476
0.2815505266189575 0.2815505266189575
rl training, epoch5, iter0, batch221/1133, batch loss:0.2815505266189575, Training time:15699.989196777344
batch reward last col mean 0.10746695846319199 first col mean 0.1110806092619896 all mean 0.10341273993253708
0.27959656715393066 0.27959656715393066
rl training, epoch5, iter0, batch222/1133, batch loss:0.27959656715393066, Training time:15703.080731391907
batch reward last col mean 0.07451601326465607 first col mean 0.10111862421035767 all mean 0.0829402357339859
0.24900378286838531 0.24900378286838531
rl training, epoch5, iter0, batch223/1133, batch loss:0.24900378286838531, Training time:15705.343815803528
batch reward last col mean 0.09030859172344208 first col mean 0.09964539855718613 all mean 0.09054289758205414
0.22680747509002686 0.22680747509002686
rl training, epoch5, iter0, batch224/1133, batch loss:0.22680747509002686, Training time:15708.311956644058
batch reward last col mean 0.07118869572877884 first col mean 0.11156712472438812 all mean 0.07684766501188278
0.2544272243976593 0.2544272243976593
rl training, epoch5, iter0, batch225/1133, batch loss:0.2544272243976593, Training time:15710.760121583939
batch reward last col mean 0.10690467059612274 first col mean 0.09899958223104477 all mean 0.1056995540857315
0.26208260655403137 0.26208260655403137
rl training, epoch5, iter0, batch226/1133, batch loss:0.26208260655403137, Training time:15712.637518405914
batch reward last col mean 0.12718647718429565 first col mean 0.12146590650081635 all mean 0.12203867733478546
0.32778239250183105 0.32778239250183105
rl training, epoch5, iter0, batch227/1133, batch loss:0.32778239250183105, Training time:15714.634798288345
batch reward last col mean 0.1061256006360054 first col mean 0.1171802282333374 all mean 0.10853321105241776
0.32444146275520325 0.32444143295288086
rl training, epoch5, iter0, batch228/1133, batch loss:0.32444143295288086, Training time:15716.469338178635
batch reward last col mean 0.1222427636384964 first col mean 0.11703945696353912 all mean 0.12071626633405685
0.3119305372238159 0.3119305670261383
rl training, epoch5, iter0, batch229/1133, batch loss:0.3119305670261383, Training time:15718.675946950912
batch reward last col mean 0.11270781606435776 first col mean 0.11361606419086456 all mean 0.11072403937578201
0.2844114899635315 0.2844114899635315
rl training, epoch5, iter0, batch230/1133, batch loss:0.2844114899635315, Training time:15721.153983831406
batch reward last col mean 0.1135132759809494 first col mean 0.11159680783748627 all mean 0.11599556356668472
0.3002132177352905 0.3002132475376129
rl training, epoch5, iter0, batch231/1133, batch loss:0.3002132475376129, Training time:15723.630267381668
batch reward last col mean 0.08820860087871552 first col mean 0.10770884156227112 all mean 0.09680165350437164
0.2801385819911957 0.2801385819911957
rl training, epoch5, iter0, batch232/1133, batch loss:0.2801385819911957, Training time:15725.468878507614
batch reward last col mean 0.0787276178598404 first col mean 0.089725561439991 all mean 0.08230575174093246
0.25071609020233154 0.25071609020233154
rl training, epoch5, iter0, batch233/1133, batch loss:0.25071609020233154, Training time:15727.830364704132
batch reward last col mean 0.09826710820198059 first col mean 0.09744250774383545 all mean 0.10183309018611908
0.26566267013549805 0.26566264033317566
rl training, epoch5, iter0, batch234/1133, batch loss:0.26566264033317566, Training time:15729.70776629448
batch reward last col mean 0.10117174685001373 first col mean 0.1178269162774086 all mean 0.10403646528720856
0.300497829914093 0.300497829914093
rl training, epoch5, iter0, batch235/1133, batch loss:0.300497829914093, Training time:15731.965919494629
batch reward last col mean 0.07778152078390121 first col mean 0.09963257610797882 all mean 0.08292456716299057
0.27320119738578796 0.27320119738578796
rl training, epoch5, iter0, batch236/1133, batch loss:0.27320119738578796, Training time:15734.969060659409
batch reward last col mean 0.09810791909694672 first col mean 0.11488071084022522 all mean 0.10104769468307495
0.2773420512676239 0.2773420512676239
rl training, epoch5, iter0, batch237/1133, batch loss:0.2773420512676239, Training time:15737.661504030228
batch reward last col mean 0.10363935679197311 first col mean 0.09584541618824005 all mean 0.10667667537927628
0.2966221272945404 0.296622097492218
rl training, epoch5, iter0, batch238/1133, batch loss:0.296622097492218, Training time:15739.819001436234
batch reward last col mean 0.09045124053955078 first col mean 0.09991294145584106 all mean 0.09751081466674805
0.26429036259651184 0.26429036259651184
rl training, epoch5, iter0, batch239/1133, batch loss:0.26429036259651184, Training time:15741.562402248383
batch reward last col mean 0.11871485412120819 first col mean 0.11775686591863632 all mean 0.11430984735488892
0.2885388135910034 0.2885388135910034
rl training, epoch5, iter0, batch240/1133, batch loss:0.2885388135910034, Training time:15743.619451761246
batch reward last col mean 0.1361737996339798 first col mean 0.10307174921035767 all mean 0.12607289850711823
0.31996235251426697 0.3199623227119446
rl training, epoch5, iter0, batch241/1133, batch loss:0.3199623227119446, Training time:15745.46761417389
batch reward last col mean 0.10473067313432693 first col mean 0.10084598511457443 all mean 0.10973848402500153
0.3213644027709961 0.3213644027709961
rl training, epoch5, iter0, batch242/1133, batch loss:0.3213644027709961, Training time:15747.601838827133
batch reward last col mean 0.12689509987831116 first col mean 0.12064995616674423 all mean 0.12410077452659607
0.3787231743335724 0.3787231743335724
rl training, epoch5, iter0, batch243/1133, batch loss:0.3787231743335724, Training time:15749.275315523148
batch reward last col mean 0.05777627229690552 first col mean 0.08993791788816452 all mean 0.06849399209022522
0.2657630443572998 0.2657630443572998
rl training, epoch5, iter0, batch244/1133, batch loss:0.2657630443572998, Training time:15751.728826284409
batch reward last col mean 0.07907795906066895 first col mean 0.10991036146879196 all mean 0.09236326813697815
0.27163219451904297 0.27163219451904297
rl training, epoch5, iter0, batch245/1133, batch loss:0.27163219451904297, Training time:15753.4432117939
batch reward last col mean 0.09466579556465149 first col mean 0.10217693448066711 all mean 0.10357746481895447
0.3071618974208832 0.3071618974208832
rl training, epoch5, iter0, batch246/1133, batch loss:0.3071618974208832, Training time:15754.952149629593
batch reward last col mean 0.07574661076068878 first col mean 0.10755079984664917 all mean 0.07957778126001358
0.23654460906982422 0.23654460906982422
rl training, epoch5, iter0, batch247/1133, batch loss:0.23654460906982422, Training time:15756.859509468079
batch reward last col mean 0.10183683782815933 first col mean 0.09077209234237671 all mean 0.10598254948854446
0.2907322347164154 0.2907322347164154
rl training, epoch5, iter0, batch248/1133, batch loss:0.2907322347164154, Training time:15758.683948278427
batch reward last col mean 0.12104443460702896 first col mean 0.12079431116580963 all mean 0.11892203241586685
0.31870055198669434 0.31870055198669434
rl training, epoch5, iter0, batch249/1133, batch loss:0.31870055198669434, Training time:15760.478924751282
batch reward last col mean 0.11779960989952087 first col mean 0.10631096363067627 all mean 0.11736483126878738
0.3121796250343323 0.3121796250343323
rl training, epoch5, iter0, batch250/1133, batch loss:0.3121796250343323, Training time:15763.00043797493
batch reward last col mean 0.12408740818500519 first col mean 0.0879601314663887 all mean 0.11078740656375885
0.3164655864238739 0.3164655864238739
rl training, epoch5, iter0, batch251/1133, batch loss:0.3164655864238739, Training time:15765.073033809662
batch reward last col mean 0.10694892704486847 first col mean 0.10684137046337128 all mean 0.10740964114665985
0.3192279040813446 0.3192279040813446
rl training, epoch5, iter0, batch252/1133, batch loss:0.3192279040813446, Training time:15767.23824596405
batch reward last col mean 0.12238587439060211 first col mean 0.10225214064121246 all mean 0.12086495757102966
0.3226010203361511 0.3226010203361511
rl training, epoch5, iter0, batch253/1133, batch loss:0.3226010203361511, Training time:15769.037923336029
batch reward last col mean 0.11025840044021606 first col mean 0.09535890072584152 all mean 0.10657192021608353
0.31056854128837585 0.31056854128837585
rl training, epoch5, iter0, batch254/1133, batch loss:0.31056854128837585, Training time:15771.068163871765
batch reward last col mean 0.09999029338359833 first col mean 0.09847208857536316 all mean 0.10339835286140442
0.25844472646713257 0.25844472646713257
rl training, epoch5, iter0, batch255/1133, batch loss:0.25844472646713257, Training time:15772.756268501282
batch reward last col mean 0.12573391199111938 first col mean 0.09803146868944168 all mean 0.11983348429203033
0.3308490216732025 0.3308490216732025
rl training, epoch5, iter0, batch256/1133, batch loss:0.3308490216732025, Training time:15775.154115915298
batch reward last col mean 0.06776685267686844 first col mean 0.10326482355594635 all mean 0.08512836694717407
0.2790933847427368 0.2790933847427368
rl training, epoch5, iter0, batch257/1133, batch loss:0.2790933847427368, Training time:15776.753201723099
batch reward last col mean 0.10000206530094147 first col mean 0.11275207251310349 all mean 0.09993661940097809
0.25123852491378784 0.25123852491378784
rl training, epoch5, iter0, batch258/1133, batch loss:0.25123852491378784, Training time:15778.956356287003
batch reward last col mean 0.10466249287128448 first col mean 0.10507634282112122 all mean 0.0990629568696022
0.2922199070453644 0.2922199070453644
rl training, epoch5, iter0, batch259/1133, batch loss:0.2922199070453644, Training time:15780.773072719574
batch reward last col mean 0.12959551811218262 first col mean 0.11162728071212769 all mean 0.11674884706735611
0.3125337064266205 0.3125337064266205
rl training, epoch5, iter0, batch260/1133, batch loss:0.3125337064266205, Training time:15782.643873929977
batch reward last col mean 0.07865729182958603 first col mean 0.12355421483516693 all mean 0.09002428501844406
0.2847329080104828 0.2847329080104828
rl training, epoch5, iter0, batch261/1133, batch loss:0.2847329080104828, Training time:15784.607753515244
batch reward last col mean 0.09867627918720245 first col mean 0.09922093152999878 all mean 0.10095732659101486
0.2865002155303955 0.2865002155303955
rl training, epoch5, iter0, batch262/1133, batch loss:0.2865002155303955, Training time:15786.77400302887
batch reward last col mean 0.07680759578943253 first col mean 0.11400792002677917 all mean 0.08963185548782349
0.27517467737197876 0.27517467737197876
rl training, epoch5, iter0, batch263/1133, batch loss:0.27517467737197876, Training time:15789.044872522354
batch reward last col mean 0.08550900965929031 first col mean 0.11243020743131638 all mean 0.0929219126701355
0.288312166929245 0.288312166929245
rl training, epoch5, iter0, batch264/1133, batch loss:0.288312166929245, Training time:15790.967077732086
batch reward last col mean 0.08111917972564697 first col mean 0.12880107760429382 all mean 0.087221659719944
0.26833465695381165 0.26833465695381165
rl training, epoch5, iter0, batch265/1133, batch loss:0.26833465695381165, Training time:15794.454575300217
batch reward last col mean 0.10708266496658325 first col mean 0.11106859892606735 all mean 0.10904382169246674
0.2767278552055359 0.2767278552055359
rl training, epoch5, iter0, batch266/1133, batch loss:0.2767278552055359, Training time:15796.807424545288
batch reward last col mean 0.08616666495800018 first col mean 0.10312923789024353 all mean 0.09216263890266418
0.2875083088874817 0.2875082790851593
rl training, epoch5, iter0, batch267/1133, batch loss:0.2875082790851593, Training time:15799.54579615593
batch reward last col mean 0.12706485390663147 first col mean 0.09912285953760147 all mean 0.11734320968389511
0.27736571431159973 0.27736571431159973
rl training, epoch5, iter0, batch268/1133, batch loss:0.27736571431159973, Training time:15801.493278503418
batch reward last col mean 0.14248214662075043 first col mean 0.10898195952177048 all mean 0.13476930558681488
0.3097854554653168 0.3097854554653168
rl training, epoch5, iter0, batch269/1133, batch loss:0.3097854554653168, Training time:15803.61994600296
batch reward last col mean 0.10433408617973328 first col mean 0.10561990737915039 all mean 0.10348615050315857
0.2887393832206726 0.2887393832206726
rl training, epoch5, iter0, batch270/1133, batch loss:0.2887393832206726, Training time:15805.449500083923
batch reward last col mean 0.07072523236274719 first col mean 0.10373406112194061 all mean 0.08179273456335068
0.2657274305820465 0.2657274007797241
rl training, epoch5, iter0, batch271/1133, batch loss:0.2657274007797241, Training time:15807.777115345001
batch reward last col mean 0.08852029591798782 first col mean 0.11175356805324554 all mean 0.09038716554641724
0.2650514841079712 0.2650514841079712
rl training, epoch5, iter0, batch272/1133, batch loss:0.2650514841079712, Training time:15809.741990089417
batch reward last col mean 0.09376678615808487 first col mean 0.11660797894001007 all mean 0.09948746114969254
0.3083818852901459 0.30838191509246826
rl training, epoch5, iter0, batch273/1133, batch loss:0.30838191509246826, Training time:15812.58559679985
batch reward last col mean 0.09517651796340942 first col mean 0.11113810539245605 all mean 0.09885818511247635
0.2767339050769806 0.2767339050769806
rl training, epoch5, iter0, batch274/1133, batch loss:0.2767339050769806, Training time:15814.559933185577
batch reward last col mean 0.09575194120407104 first col mean 0.10828392952680588 all mean 0.09199868887662888
0.31064727902412415 0.31064727902412415
rl training, epoch5, iter0, batch275/1133, batch loss:0.31064727902412415, Training time:15816.376626729965
batch reward last col mean 0.08475176990032196 first col mean 0.09412490576505661 all mean 0.09021127223968506
0.24899619817733765 0.24899619817733765
rl training, epoch5, iter0, batch276/1133, batch loss:0.24899619817733765, Training time:15817.99904203415
batch reward last col mean 0.08758451044559479 first col mean 0.09518475085496902 all mean 0.08902374655008316
0.24855288863182068 0.24855288863182068
rl training, epoch5, iter0, batch277/1133, batch loss:0.24855288863182068, Training time:15819.874010324478
batch reward last col mean 0.09403888881206512 first col mean 0.11575956642627716 all mean 0.09524672478437424
0.25190430879592896 0.25190430879592896
rl training, epoch5, iter0, batch278/1133, batch loss:0.25190430879592896, Training time:15821.876593112946
batch reward last col mean 0.08760149776935577 first col mean 0.1047423779964447 all mean 0.09269289672374725
0.2904159426689148 0.2904159426689148
rl training, epoch5, iter0, batch279/1133, batch loss:0.2904159426689148, Training time:15824.585448026657
batch reward last col mean 0.09530513733625412 first col mean 0.11636112630367279 all mean 0.0981164276599884
0.3122192621231079 0.3122192621231079
rl training, epoch5, iter0, batch280/1133, batch loss:0.3122192621231079, Training time:15826.35944533348
batch reward last col mean 0.08743079006671906 first col mean 0.11679130047559738 all mean 0.09420335292816162
0.24011658132076263 0.24011658132076263
rl training, epoch5, iter0, batch281/1133, batch loss:0.24011658132076263, Training time:15828.60915350914
batch reward last col mean 0.11499536037445068 first col mean 0.11543978750705719 all mean 0.11378307640552521
0.3048170804977417 0.3048170804977417
rl training, epoch5, iter0, batch282/1133, batch loss:0.3048170804977417, Training time:15830.792016267776
batch reward last col mean 0.07970308512449265 first col mean 0.1003391444683075 all mean 0.08839426189661026
0.24421745538711548 0.24421745538711548
rl training, epoch5, iter0, batch283/1133, batch loss:0.24421745538711548, Training time:15833.34075140953
batch reward last col mean 0.09487423300743103 first col mean 0.09481284022331238 all mean 0.09937679767608643
0.2895195186138153 0.2895195186138153
rl training, epoch5, iter0, batch284/1133, batch loss:0.2895195186138153, Training time:15835.013616800308
batch reward last col mean 0.09144318848848343 first col mean 0.1086309477686882 all mean 0.09913692623376846
0.2619600296020508 0.2619600296020508
rl training, epoch5, iter0, batch285/1133, batch loss:0.2619600296020508, Training time:15837.430819749832
batch reward last col mean 0.0843009427189827 first col mean 0.10286441445350647 all mean 0.09030254185199738
0.3057558834552765 0.3057558834552765
rl training, epoch5, iter0, batch286/1133, batch loss:0.3057558834552765, Training time:15839.5664935112
batch reward last col mean 0.1130506619811058 first col mean 0.11698544025421143 all mean 0.11565382778644562
0.2972431778907776 0.2972431778907776
rl training, epoch5, iter0, batch287/1133, batch loss:0.2972431778907776, Training time:15841.779262065887
batch reward last col mean 0.14518126845359802 first col mean 0.11986468732357025 all mean 0.13672977685928345
0.34574779868125916 0.34574779868125916
rl training, epoch5, iter0, batch288/1133, batch loss:0.34574779868125916, Training time:15843.634303808212
batch reward last col mean 0.13467997312545776 first col mean 0.10431782901287079 all mean 0.13176485896110535
0.3116878569126129 0.3116878569126129
rl training, epoch5, iter0, batch289/1133, batch loss:0.3116878569126129, Training time:15845.972868442535
batch reward last col mean 0.09595900774002075 first col mean 0.1041988804936409 all mean 0.1056157723069191
0.3080345392227173 0.3080345392227173
rl training, epoch5, iter0, batch290/1133, batch loss:0.3080345392227173, Training time:15847.481699466705
batch reward last col mean 0.11590085923671722 first col mean 0.09637468308210373 all mean 0.11483904719352722
0.2983235716819763 0.2983235716819763
rl training, epoch5, iter0, batch291/1133, batch loss:0.2983235716819763, Training time:15849.347615242004
batch reward last col mean 0.0965002179145813 first col mean 0.12324947118759155 all mean 0.09350396692752838
0.238650381565094 0.238650381565094
rl training, epoch5, iter0, batch292/1133, batch loss:0.238650381565094, Training time:15851.596380472183
batch reward last col mean 0.08755530416965485 first col mean 0.1102970540523529 all mean 0.08936335891485214
0.25762739777565 0.25762739777565
rl training, epoch5, iter0, batch293/1133, batch loss:0.25762739777565, Training time:15853.579360961914
batch reward last col mean 0.079103484749794 first col mean 0.10399049520492554 all mean 0.08904530107975006
0.2513870298862457 0.2513870298862457
rl training, epoch5, iter0, batch294/1133, batch loss:0.2513870298862457, Training time:15855.50894355774
batch reward last col mean 0.11219188570976257 first col mean 0.12367862462997437 all mean 0.11119039356708527
0.3118918240070343 0.3118917942047119
rl training, epoch5, iter0, batch295/1133, batch loss:0.3118917942047119, Training time:15857.432721614838
batch reward last col mean 0.11086991429328918 first col mean 0.1010570153594017 all mean 0.10603136569261551
0.2694856524467468 0.2694856524467468
rl training, epoch5, iter0, batch296/1133, batch loss:0.2694856524467468, Training time:15859.484979391098
batch reward last col mean 0.10233790427446365 first col mean 0.11609087139368057 all mean 0.10468165576457977
0.2822350859642029 0.2822350859642029
rl training, epoch5, iter0, batch297/1133, batch loss:0.2822350859642029, Training time:15861.215237140656
batch reward last col mean 0.09606952220201492 first col mean 0.10930981487035751 all mean 0.0932508260011673
0.2720317542552948 0.2720317542552948
rl training, epoch5, iter0, batch298/1133, batch loss:0.2720317542552948, Training time:15863.224623441696
batch reward last col mean 0.11173104494810104 first col mean 0.11869458109140396 all mean 0.10821138322353363
0.31787046790122986 0.31787046790122986
rl training, epoch5, iter0, batch299/1133, batch loss:0.31787046790122986, Training time:15865.07229590416
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4922521766686166 Time: 100.35290598869324 s
loss of true 0.21384071489666168 loss of gen 0.175064872539317 loss of other 0.10334658909454245 first score 0.11571494489908218
batch reward last col mean 0.14979055523872375 first col mean 0.1067114919424057 all mean 0.1408734917640686
0.3265807032585144 0.3265807032585144
rl training, epoch5, iter0, batch300/1133, batch loss:0.3265807032585144, Training time:15967.832510232925
batch reward last col mean 0.09077996015548706 first col mean 0.11141812056303024 all mean 0.09176791459321976
0.25257110595703125 0.25257110595703125
rl training, epoch5, iter0, batch301/1133, batch loss:0.25257110595703125, Training time:15970.306095123291
batch reward last col mean 0.09506021440029144 first col mean 0.12693408131599426 all mean 0.0958525538444519
0.26772111654281616 0.26772111654281616
rl training, epoch5, iter0, batch302/1133, batch loss:0.26772111654281616, Training time:15973.493056297302
batch reward last col mean 0.07866646349430084 first col mean 0.1189340353012085 all mean 0.08741997182369232
0.27146196365356445 0.27146199345588684
rl training, epoch5, iter0, batch303/1133, batch loss:0.27146199345588684, Training time:15975.49626994133
batch reward last col mean 0.08329887688159943 first col mean 0.1074661910533905 all mean 0.08980181813240051
0.28939762711524963 0.28939762711524963
rl training, epoch5, iter0, batch304/1133, batch loss:0.28939762711524963, Training time:15977.933179140091
batch reward last col mean 0.10140454769134521 first col mean 0.09281371533870697 all mean 0.10454607009887695
0.31191590428352356 0.31191590428352356
rl training, epoch5, iter0, batch305/1133, batch loss:0.31191590428352356, Training time:15979.351916313171
batch reward last col mean 0.08495945483446121 first col mean 0.10971743613481522 all mean 0.09847836196422577
0.29218193888664246 0.29218193888664246
rl training, epoch5, iter0, batch306/1133, batch loss:0.29218193888664246, Training time:15981.134987592697
batch reward last col mean 0.12279316037893295 first col mean 0.09793571382761002 all mean 0.12126731872558594
0.30419617891311646 0.30419614911079407
rl training, epoch5, iter0, batch307/1133, batch loss:0.30419614911079407, Training time:15982.868985414505
batch reward last col mean 0.08858672529459 first col mean 0.11685165017843246 all mean 0.095065638422966
0.2920624911785126 0.2920624911785126
rl training, epoch5, iter0, batch308/1133, batch loss:0.2920624911785126, Training time:15985.399696826935
batch reward last col mean 0.09408748149871826 first col mean 0.10841101408004761 all mean 0.0985121950507164
0.30102309584617615 0.30102309584617615
rl training, epoch5, iter0, batch309/1133, batch loss:0.30102309584617615, Training time:15987.278680562973
batch reward last col mean 0.10330561548471451 first col mean 0.11630724370479584 all mean 0.1070844754576683
0.26506826281547546 0.26506826281547546
rl training, epoch5, iter0, batch310/1133, batch loss:0.26506826281547546, Training time:15990.107026338577
batch reward last col mean 0.09758374094963074 first col mean 0.09976378083229065 all mean 0.09894794225692749
0.24911630153656006 0.24911630153656006
rl training, epoch5, iter0, batch311/1133, batch loss:0.24911630153656006, Training time:15991.84531712532
batch reward last col mean 0.08904817700386047 first col mean 0.11278331279754639 all mean 0.09953102469444275
0.29586559534072876 0.29586559534072876
rl training, epoch5, iter0, batch312/1133, batch loss:0.29586559534072876, Training time:15993.489082098007
batch reward last col mean 0.09070271998643875 first col mean 0.09844903647899628 all mean 0.09330306202173233
0.27265751361846924 0.27265751361846924
rl training, epoch5, iter0, batch313/1133, batch loss:0.27265751361846924, Training time:15995.52079463005
batch reward last col mean 0.10073947161436081 first col mean 0.10768620669841766 all mean 0.10281696915626526
0.3311425447463989 0.3311425447463989
rl training, epoch5, iter0, batch314/1133, batch loss:0.3311425447463989, Training time:15997.501346826553
batch reward last col mean 0.10491016507148743 first col mean 0.11344580352306366 all mean 0.10245738923549652
0.3173235356807709 0.3173235356807709
rl training, epoch5, iter0, batch315/1133, batch loss:0.3173235356807709, Training time:15999.574610948563
batch reward last col mean 0.10257254540920258 first col mean 0.11279359459877014 all mean 0.10053429752588272
0.27816617488861084 0.27816617488861084
rl training, epoch5, iter0, batch316/1133, batch loss:0.27816617488861084, Training time:16001.680809736252
batch reward last col mean 0.12470763921737671 first col mean 0.11337792873382568 all mean 0.11409225314855576
0.2578144669532776 0.2578144669532776
rl training, epoch5, iter0, batch317/1133, batch loss:0.2578144669532776, Training time:16003.715942382812
batch reward last col mean 0.08909641951322556 first col mean 0.11623561382293701 all mean 0.09220961481332779
0.24145297706127167 0.24145297706127167
rl training, epoch5, iter0, batch318/1133, batch loss:0.24145297706127167, Training time:16006.192494630814
batch reward last col mean 0.12477535009384155 first col mean 0.09547381848096848 all mean 0.11785457283258438
0.3310777544975281 0.3310777246952057
rl training, epoch5, iter0, batch319/1133, batch loss:0.3310777246952057, Training time:16008.19106388092
batch reward last col mean 0.1245146244764328 first col mean 0.1056680902838707 all mean 0.114267498254776
0.3400614559650421 0.3400614559650421
rl training, epoch5, iter0, batch320/1133, batch loss:0.3400614559650421, Training time:16010.26134634018
batch reward last col mean 0.10003451257944107 first col mean 0.11323954910039902 all mean 0.10414586216211319
0.29818129539489746 0.29818129539489746
rl training, epoch5, iter0, batch321/1133, batch loss:0.29818129539489746, Training time:16012.11302947998
batch reward last col mean 0.08213312923908234 first col mean 0.11726894974708557 all mean 0.08542973548173904
0.252601683139801 0.2526017129421234
rl training, epoch5, iter0, batch322/1133, batch loss:0.2526017129421234, Training time:16014.42730975151
batch reward last col mean 0.15178373456001282 first col mean 0.120325967669487 all mean 0.14354054629802704
0.34340640902519226 0.34340640902519226
rl training, epoch5, iter0, batch323/1133, batch loss:0.34340640902519226, Training time:16016.83410859108
batch reward last col mean 0.09075015783309937 first col mean 0.10917076468467712 all mean 0.09858307242393494
0.2911473512649536 0.2911473512649536
rl training, epoch5, iter0, batch324/1133, batch loss:0.2911473512649536, Training time:16018.746696710587
batch reward last col mean 0.1138499453663826 first col mean 0.11878447979688644 all mean 0.11566291749477386
0.3285543918609619 0.3285543918609619
rl training, epoch5, iter0, batch325/1133, batch loss:0.3285543918609619, Training time:16021.19123506546
batch reward last col mean 0.09788699448108673 first col mean 0.10851810872554779 all mean 0.10085291415452957
0.26331827044487 0.26331827044487
rl training, epoch5, iter0, batch326/1133, batch loss:0.26331827044487, Training time:16023.207971572876
batch reward last col mean 0.12159073352813721 first col mean 0.1175454631447792 all mean 0.11710699647665024
0.31776532530784607 0.31776532530784607
rl training, epoch5, iter0, batch327/1133, batch loss:0.31776532530784607, Training time:16025.812799215317
batch reward last col mean 0.11048078536987305 first col mean 0.11225590109825134 all mean 0.11465399712324142
0.3019181191921234 0.3019181191921234
rl training, epoch5, iter0, batch328/1133, batch loss:0.3019181191921234, Training time:16027.448768854141
batch reward last col mean 0.1161355972290039 first col mean 0.11204807460308075 all mean 0.11275815218687057
0.307801216840744 0.307801216840744
rl training, epoch5, iter0, batch329/1133, batch loss:0.307801216840744, Training time:16029.957329273224
batch reward last col mean 0.11755110323429108 first col mean 0.10859787464141846 all mean 0.11551303416490555
0.28326764702796936 0.283267617225647
rl training, epoch5, iter0, batch330/1133, batch loss:0.283267617225647, Training time:16031.779673337936
batch reward last col mean 0.10634534060955048 first col mean 0.11145403236150742 all mean 0.11289805918931961
0.2834842801094055 0.2834842801094055
rl training, epoch5, iter0, batch331/1133, batch loss:0.2834842801094055, Training time:16033.434551000595
batch reward last col mean 0.11464802920818329 first col mean 0.11651398241519928 all mean 0.11625821888446808
0.29088521003723145 0.29088521003723145
rl training, epoch5, iter0, batch332/1133, batch loss:0.29088521003723145, Training time:16035.283846378326
batch reward last col mean 0.10305555164813995 first col mean 0.11296188086271286 all mean 0.10467637330293655
0.28143322467803955 0.28143322467803955
rl training, epoch5, iter0, batch333/1133, batch loss:0.28143322467803955, Training time:16037.149203777313
batch reward last col mean 0.12128811329603195 first col mean 0.1053803563117981 all mean 0.1193157434463501
0.34029829502105713 0.34029829502105713
rl training, epoch5, iter0, batch334/1133, batch loss:0.34029829502105713, Training time:16039.100579023361
batch reward last col mean 0.10620870441198349 first col mean 0.1010250672698021 all mean 0.10564620792865753
0.2803220748901367 0.2803220748901367
rl training, epoch5, iter0, batch335/1133, batch loss:0.2803220748901367, Training time:16041.36576294899
batch reward last col mean 0.09768040478229523 first col mean 0.11159758269786835 all mean 0.09991119801998138
0.30204203724861145 0.30204203724861145
rl training, epoch5, iter0, batch336/1133, batch loss:0.30204203724861145, Training time:16043.16970705986
batch reward last col mean 0.13122344017028809 first col mean 0.11237754672765732 all mean 0.12546232342720032
0.32419466972351074 0.32419466972351074
rl training, epoch5, iter0, batch337/1133, batch loss:0.32419466972351074, Training time:16045.18224287033
batch reward last col mean 0.12365280091762543 first col mean 0.11288969218730927 all mean 0.11693748831748962
0.2909122407436371 0.2909122407436371
rl training, epoch5, iter0, batch338/1133, batch loss:0.2909122407436371, Training time:16047.052937746048
batch reward last col mean 0.10177618265151978 first col mean 0.10741719603538513 all mean 0.10507337003946304
0.28075844049453735 0.28075844049453735
rl training, epoch5, iter0, batch339/1133, batch loss:0.28075844049453735, Training time:16048.53631901741
batch reward last col mean 0.08321820199489594 first col mean 0.10134366154670715 all mean 0.09101887047290802
0.2919735610485077 0.2919735610485077
rl training, epoch5, iter0, batch340/1133, batch loss:0.2919735610485077, Training time:16050.46950507164
batch reward last col mean 0.08683976531028748 first col mean 0.11630846560001373 all mean 0.09384120255708694
0.27107924222946167 0.27107924222946167
rl training, epoch5, iter0, batch341/1133, batch loss:0.27107924222946167, Training time:16052.287528276443
batch reward last col mean 0.1326102912425995 first col mean 0.1013544350862503 all mean 0.12456249445676804
0.28972896933555603 0.28972893953323364
rl training, epoch5, iter0, batch342/1133, batch loss:0.28972893953323364, Training time:16054.216912031174
batch reward last col mean 0.1130104511976242 first col mean 0.12459754943847656 all mean 0.10777628421783447
0.2584976255893707 0.2584976255893707
rl training, epoch5, iter0, batch343/1133, batch loss:0.2584976255893707, Training time:16055.872524261475
batch reward last col mean 0.08709897100925446 first col mean 0.11699696630239487 all mean 0.09073148667812347
0.30279502272605896 0.30279502272605896
rl training, epoch5, iter0, batch344/1133, batch loss:0.30279502272605896, Training time:16057.372480869293
batch reward last col mean 0.10485067963600159 first col mean 0.10564976185560226 all mean 0.1044834554195404
0.28521716594696045 0.28521716594696045
rl training, epoch5, iter0, batch345/1133, batch loss:0.28521716594696045, Training time:16059.201749801636
batch reward last col mean 0.1114988923072815 first col mean 0.11553473770618439 all mean 0.11039282381534576
0.26651981472969055 0.26651981472969055
rl training, epoch5, iter0, batch346/1133, batch loss:0.26651981472969055, Training time:16061.12403512001
batch reward last col mean 0.11166029423475266 first col mean 0.11406521499156952 all mean 0.10706103593111038
0.2948342561721802 0.2948342561721802
rl training, epoch5, iter0, batch347/1133, batch loss:0.2948342561721802, Training time:16063.453788995743
batch reward last col mean 0.07685250043869019 first col mean 0.10317294299602509 all mean 0.09164901822805405
0.2987253665924072 0.2987253665924072
rl training, epoch5, iter0, batch348/1133, batch loss:0.2987253665924072, Training time:16065.142757892609
batch reward last col mean 0.12746188044548035 first col mean 0.10572952777147293 all mean 0.11973899602890015
0.2940148413181305 0.2940148413181305
rl training, epoch5, iter0, batch349/1133, batch loss:0.2940148413181305, Training time:16067.064533233643
batch reward last col mean 0.12653903663158417 first col mean 0.12557050585746765 all mean 0.12166330218315125
0.32556456327438354 0.32556456327438354
rl training, epoch5, iter0, batch350/1133, batch loss:0.32556456327438354, Training time:16068.453579902649
batch reward last col mean 0.07691358029842377 first col mean 0.11584770679473877 all mean 0.08608186990022659
0.267331600189209 0.267331600189209
rl training, epoch5, iter0, batch351/1133, batch loss:0.267331600189209, Training time:16070.556776285172
batch reward last col mean 0.1111682653427124 first col mean 0.10548601299524307 all mean 0.11181528121232986
0.32104071974754333 0.32104071974754333
rl training, epoch5, iter0, batch352/1133, batch loss:0.32104071974754333, Training time:16072.219110012054
batch reward last col mean 0.08109399676322937 first col mean 0.1281907558441162 all mean 0.08880576491355896
0.3024182617664337 0.3024182617664337
rl training, epoch5, iter0, batch353/1133, batch loss:0.3024182617664337, Training time:16074.918372154236
batch reward last col mean 0.13825872540473938 first col mean 0.12332412600517273 all mean 0.13188771903514862
0.30091848969459534 0.30091848969459534
rl training, epoch5, iter0, batch354/1133, batch loss:0.30091848969459534, Training time:16076.840209245682
batch reward last col mean 0.12730993330478668 first col mean 0.10849170386791229 all mean 0.11545224487781525
0.29874950647354126 0.29874950647354126
rl training, epoch5, iter0, batch355/1133, batch loss:0.29874950647354126, Training time:16078.572736263275
batch reward last col mean 0.12856937944889069 first col mean 0.10002020001411438 all mean 0.12852734327316284
0.33849260210990906 0.33849257230758667
rl training, epoch5, iter0, batch356/1133, batch loss:0.33849257230758667, Training time:16081.017542123795
batch reward last col mean 0.14792205393314362 first col mean 0.09484651684761047 all mean 0.13767202198505402
0.3427424728870392 0.3427424728870392
rl training, epoch5, iter0, batch357/1133, batch loss:0.3427424728870392, Training time:16082.82193517685
batch reward last col mean 0.12317520380020142 first col mean 0.11008971184492111 all mean 0.11514981836080551
0.28953102231025696 0.28953102231025696
rl training, epoch5, iter0, batch358/1133, batch loss:0.28953102231025696, Training time:16084.50647187233
batch reward last col mean 0.0991208627820015 first col mean 0.1054377481341362 all mean 0.10034149140119553
0.2679911255836487 0.2679911255836487
rl training, epoch5, iter0, batch359/1133, batch loss:0.2679911255836487, Training time:16086.114541769028
batch reward last col mean 0.08292809128761292 first col mean 0.11153388023376465 all mean 0.09927748888731003
0.26107096672058105 0.26107096672058105
rl training, epoch5, iter0, batch360/1133, batch loss:0.26107096672058105, Training time:16087.396076917648
batch reward last col mean 0.13071443140506744 first col mean 0.1026570200920105 all mean 0.1252790242433548
0.3084455132484436 0.3084455132484436
rl training, epoch5, iter0, batch361/1133, batch loss:0.3084455132484436, Training time:16089.04213309288
batch reward last col mean 0.09691769629716873 first col mean 0.13164517283439636 all mean 0.09989474713802338
0.2953272759914398 0.29532724618911743
rl training, epoch5, iter0, batch362/1133, batch loss:0.29532724618911743, Training time:16090.600747346878
batch reward last col mean 0.09696252644062042 first col mean 0.11249088495969772 all mean 0.10079026222229004
0.2857097387313843 0.2857097387313843
rl training, epoch5, iter0, batch363/1133, batch loss:0.2857097387313843, Training time:16092.34466958046
batch reward last col mean 0.13406138122081757 first col mean 0.09864716976881027 all mean 0.12653899192810059
0.30434930324554443 0.30434930324554443
rl training, epoch5, iter0, batch364/1133, batch loss:0.30434930324554443, Training time:16094.237706184387
batch reward last col mean 0.11627571284770966 first col mean 0.11898452043533325 all mean 0.1158105656504631
0.3352801203727722 0.3352801203727722
rl training, epoch5, iter0, batch365/1133, batch loss:0.3352801203727722, Training time:16096.47907614708
batch reward last col mean 0.07515881210565567 first col mean 0.10771842300891876 all mean 0.08225597441196442
0.2574099898338318 0.2574099898338318
rl training, epoch5, iter0, batch366/1133, batch loss:0.2574099898338318, Training time:16097.927481412888
batch reward last col mean 0.14182162284851074 first col mean 0.09644966572523117 all mean 0.1288052201271057
0.3223735988140106 0.3223735988140106
rl training, epoch5, iter0, batch367/1133, batch loss:0.3223735988140106, Training time:16099.443536996841
batch reward last col mean 0.10320386290550232 first col mean 0.10682889819145203 all mean 0.10028175264596939
0.30612248182296753 0.3061225116252899
rl training, epoch5, iter0, batch368/1133, batch loss:0.3061225116252899, Training time:16101.656355381012
batch reward last col mean 0.13188108801841736 first col mean 0.11528390645980835 all mean 0.12582014501094818
0.3407347798347473 0.3407347798347473
rl training, epoch5, iter0, batch369/1133, batch loss:0.3407347798347473, Training time:16103.374275684357
batch reward last col mean 0.1192031055688858 first col mean 0.09164516627788544 all mean 0.1133100688457489
0.3137495219707489 0.3137494921684265
rl training, epoch5, iter0, batch370/1133, batch loss:0.3137494921684265, Training time:16105.066349983215
batch reward last col mean 0.0797060877084732 first col mean 0.10780935734510422 all mean 0.08229934424161911
0.2671121656894684 0.2671121656894684
rl training, epoch5, iter0, batch371/1133, batch loss:0.2671121656894684, Training time:16106.725027799606
batch reward last col mean 0.12426158785820007 first col mean 0.12411579489707947 all mean 0.11906750500202179
0.3219091594219208 0.3219091594219208
rl training, epoch5, iter0, batch372/1133, batch loss:0.3219091594219208, Training time:16108.525207519531
batch reward last col mean 0.11641736328601837 first col mean 0.1271858513355255 all mean 0.11312447488307953
0.32178574800491333 0.32178574800491333
rl training, epoch5, iter0, batch373/1133, batch loss:0.32178574800491333, Training time:16110.051501274109
batch reward last col mean 0.07926103472709656 first col mean 0.10448839515447617 all mean 0.08588676154613495
0.277132511138916 0.277132511138916
rl training, epoch5, iter0, batch374/1133, batch loss:0.277132511138916, Training time:16112.91383099556
batch reward last col mean 0.09580476582050323 first col mean 0.11854095011949539 all mean 0.09797714650630951
0.2897123396396637 0.2897123396396637
rl training, epoch5, iter0, batch375/1133, batch loss:0.2897123396396637, Training time:16115.181834459305
batch reward last col mean 0.10630639642477036 first col mean 0.12138745188713074 all mean 0.10824219137430191
0.2751608192920685 0.2751608192920685
rl training, epoch5, iter0, batch376/1133, batch loss:0.2751608192920685, Training time:16117.79407787323
batch reward last col mean 0.0880608782172203 first col mean 0.09989504516124725 all mean 0.0885038822889328
0.24418841302394867 0.24418838322162628
rl training, epoch5, iter0, batch377/1133, batch loss:0.24418838322162628, Training time:16119.71318769455
batch reward last col mean 0.09543503820896149 first col mean 0.10234898328781128 all mean 0.10155415534973145
0.27611494064331055 0.27611494064331055
rl training, epoch5, iter0, batch378/1133, batch loss:0.27611494064331055, Training time:16121.39038491249
batch reward last col mean 0.11311904340982437 first col mean 0.10339056700468063 all mean 0.11371508985757828
0.29232484102249146 0.29232481122016907
rl training, epoch5, iter0, batch379/1133, batch loss:0.29232481122016907, Training time:16122.944416999817
batch reward last col mean 0.10876524448394775 first col mean 0.12568357586860657 all mean 0.10184905678033829
0.2663418650627136 0.2663418650627136
rl training, epoch5, iter0, batch380/1133, batch loss:0.2663418650627136, Training time:16124.686183691025
batch reward last col mean 0.10896222293376923 first col mean 0.10142835229635239 all mean 0.10552361607551575
0.29181423783302307 0.29181423783302307
rl training, epoch5, iter0, batch381/1133, batch loss:0.29181423783302307, Training time:16126.42975783348
batch reward last col mean 0.1295432597398758 first col mean 0.11427722871303558 all mean 0.11791327595710754
0.2853817045688629 0.2853817045688629
rl training, epoch5, iter0, batch382/1133, batch loss:0.2853817045688629, Training time:16128.513382673264
batch reward last col mean 0.135284885764122 first col mean 0.12606987357139587 all mean 0.13111957907676697
0.3244961202144623 0.3244961202144623
rl training, epoch5, iter0, batch383/1133, batch loss:0.3244961202144623, Training time:16130.047251224518
batch reward last col mean 0.11450540274381638 first col mean 0.10751494765281677 all mean 0.10437214374542236
0.30703112483024597 0.30703112483024597
rl training, epoch5, iter0, batch384/1133, batch loss:0.30703112483024597, Training time:16131.583932161331
batch reward last col mean 0.09408854693174362 first col mean 0.1081637367606163 all mean 0.09998728334903717
0.26401448249816895 0.26401448249816895
rl training, epoch5, iter0, batch385/1133, batch loss:0.26401448249816895, Training time:16133.447197675705
batch reward last col mean 0.1269216537475586 first col mean 0.11583369970321655 all mean 0.12760673463344574
0.3275659680366516 0.3275659680366516
rl training, epoch5, iter0, batch386/1133, batch loss:0.3275659680366516, Training time:16135.16154909134
batch reward last col mean 0.07953689247369766 first col mean 0.0850614383816719 all mean 0.08211290836334229
0.27501752972602844 0.27501749992370605
rl training, epoch5, iter0, batch387/1133, batch loss:0.27501749992370605, Training time:16137.362945318222
batch reward last col mean 0.10256496071815491 first col mean 0.11743856966495514 all mean 0.10823429375886917
0.27970635890960693 0.27970635890960693
rl training, epoch5, iter0, batch388/1133, batch loss:0.27970635890960693, Training time:16139.534410953522
batch reward last col mean 0.1069471538066864 first col mean 0.12700161337852478 all mean 0.1105085238814354
0.3418468236923218 0.3418468236923218
rl training, epoch5, iter0, batch389/1133, batch loss:0.3418468236923218, Training time:16141.30127120018
batch reward last col mean 0.09857051819562912 first col mean 0.11776754260063171 all mean 0.10068131238222122
0.27439460158348083 0.27439457178115845
rl training, epoch5, iter0, batch390/1133, batch loss:0.27439457178115845, Training time:16142.959654331207
batch reward last col mean 0.12124159932136536 first col mean 0.11391942203044891 all mean 0.11617913097143173
0.30711960792541504 0.30711960792541504
rl training, epoch5, iter0, batch391/1133, batch loss:0.30711960792541504, Training time:16144.276517868042
batch reward last col mean 0.08831115812063217 first col mean 0.13447877764701843 all mean 0.10225290060043335
0.31202003359794617 0.31202003359794617
rl training, epoch5, iter0, batch392/1133, batch loss:0.31202003359794617, Training time:16145.67247724533
batch reward last col mean 0.14657659828662872 first col mean 0.10239947587251663 all mean 0.13734883069992065
0.311008095741272 0.311008095741272
rl training, epoch5, iter0, batch393/1133, batch loss:0.311008095741272, Training time:16147.537526369095
batch reward last col mean 0.1252259612083435 first col mean 0.11677082628011703 all mean 0.12067806720733643
0.3088628947734833 0.3088628947734833
rl training, epoch5, iter0, batch394/1133, batch loss:0.3088628947734833, Training time:16148.975035429
batch reward last col mean 0.07950511574745178 first col mean 0.09697224199771881 all mean 0.08672016859054565
0.27650460600852966 0.27650460600852966
rl training, epoch5, iter0, batch395/1133, batch loss:0.27650460600852966, Training time:16150.861715555191
batch reward last col mean 0.10242215543985367 first col mean 0.10117374360561371 all mean 0.10360744595527649
0.24576133489608765 0.24576131999492645
rl training, epoch5, iter0, batch396/1133, batch loss:0.24576131999492645, Training time:16152.46075129509
batch reward last col mean 0.1123863011598587 first col mean 0.12387555837631226 all mean 0.11531946808099747
0.3487919569015503 0.3487919569015503
rl training, epoch5, iter0, batch397/1133, batch loss:0.3487919569015503, Training time:16154.751497507095
batch reward last col mean 0.11383303254842758 first col mean 0.1124638095498085 all mean 0.11224273592233658
0.3159727454185486 0.3159727454185486
rl training, epoch5, iter0, batch398/1133, batch loss:0.3159727454185486, Training time:16157.039325475693
batch reward last col mean 0.10313444584608078 first col mean 0.11492815613746643 all mean 0.10497517883777618
0.2840169370174408 0.2840169370174408
rl training, epoch5, iter0, batch399/1133, batch loss:0.2840169370174408, Training time:16159.045082569122
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.49385257121849563 Time: 98.95235800743103 s
loss of true 0.2147651329334079 loss of gen 0.1771571612362039 loss of other 0.1019302764981459 first score 0.12976059317588806
batch reward last col mean 0.09916439652442932 first col mean 0.10655256360769272 all mean 0.10093346983194351
0.26119372248649597 0.26119372248649597
rl training, epoch5, iter0, batch400/1133, batch loss:0.26119372248649597, Training time:16259.964685440063
batch reward last col mean 0.11958014965057373 first col mean 0.10712172836065292 all mean 0.11536862701177597
0.2871713638305664 0.287171334028244
rl training, epoch5, iter0, batch401/1133, batch loss:0.287171334028244, Training time:16261.754842042923
batch reward last col mean 0.10961660742759705 first col mean 0.11157295107841492 all mean 0.1049463301897049
0.29754725098609924 0.29754725098609924
rl training, epoch5, iter0, batch402/1133, batch loss:0.29754725098609924, Training time:16264.07544016838
batch reward last col mean 0.08934307843446732 first col mean 0.10780884325504303 all mean 0.09631400555372238
0.264952689409256 0.264952689409256
rl training, epoch5, iter0, batch403/1133, batch loss:0.264952689409256, Training time:16265.785812854767
batch reward last col mean 0.10215924680233002 first col mean 0.10943139344453812 all mean 0.1065988764166832
0.267788290977478 0.267788290977478
rl training, epoch5, iter0, batch404/1133, batch loss:0.267788290977478, Training time:16267.288039684296
batch reward last col mean 0.08178152143955231 first col mean 0.09211292862892151 all mean 0.08833931386470795
0.26820218563079834 0.26820218563079834
rl training, epoch5, iter0, batch405/1133, batch loss:0.26820218563079834, Training time:16269.138858556747
batch reward last col mean 0.09876295179128647 first col mean 0.10129707306623459 all mean 0.09884671866893768
0.28398820757865906 0.28398823738098145
rl training, epoch5, iter0, batch406/1133, batch loss:0.28398823738098145, Training time:16271.039655685425
batch reward last col mean 0.08606269955635071 first col mean 0.11470198631286621 all mean 0.09079307317733765
0.25204095244407654 0.25204095244407654
rl training, epoch5, iter0, batch407/1133, batch loss:0.25204095244407654, Training time:16273.3315346241
batch reward last col mean 0.12184113264083862 first col mean 0.11126655340194702 all mean 0.11370275914669037
0.320777952671051 0.320777952671051
rl training, epoch5, iter0, batch408/1133, batch loss:0.320777952671051, Training time:16274.807928323746
batch reward last col mean 0.09030550718307495 first col mean 0.11070257425308228 all mean 0.09454023092985153
0.23515290021896362 0.23515290021896362
rl training, epoch5, iter0, batch409/1133, batch loss:0.23515290021896362, Training time:16276.481821537018
batch reward last col mean 0.09254010021686554 first col mean 0.10198704153299332 all mean 0.09589304029941559
0.25678750872612 0.25678750872612
rl training, epoch5, iter0, batch410/1133, batch loss:0.25678750872612, Training time:16278.04862499237
batch reward last col mean 0.10650075227022171 first col mean 0.13157320022583008 all mean 0.11091341823339462
0.33860790729522705 0.33860790729522705
rl training, epoch5, iter0, batch411/1133, batch loss:0.33860790729522705, Training time:16279.740837574005
batch reward last col mean 0.06875146180391312 first col mean 0.09886813908815384 all mean 0.07767966389656067
0.2635331153869629 0.2635331153869629
rl training, epoch5, iter0, batch412/1133, batch loss:0.2635331153869629, Training time:16281.610600948334
batch reward last col mean 0.09121058136224747 first col mean 0.12329255044460297 all mean 0.09411083161830902
0.26408448815345764 0.26408448815345764
rl training, epoch5, iter0, batch413/1133, batch loss:0.26408448815345764, Training time:16283.131811618805
batch reward last col mean 0.11968055367469788 first col mean 0.11846897751092911 all mean 0.11579674482345581
0.3063391149044037 0.3063390851020813
rl training, epoch5, iter0, batch414/1133, batch loss:0.3063390851020813, Training time:16285.376702547073
batch reward last col mean 0.10486620664596558 first col mean 0.10395915806293488 all mean 0.10323940962553024
0.293635755777359 0.2936357259750366
rl training, epoch5, iter0, batch415/1133, batch loss:0.2936357259750366, Training time:16287.14236664772
batch reward last col mean 0.0819905549287796 first col mean 0.10287010669708252 all mean 0.09163802862167358
0.28942057490348816 0.28942057490348816
rl training, epoch5, iter0, batch416/1133, batch loss:0.28942057490348816, Training time:16288.657591342926
batch reward last col mean 0.09449666738510132 first col mean 0.11560438573360443 all mean 0.09703458845615387
0.2503744661808014 0.2503744661808014
rl training, epoch5, iter0, batch417/1133, batch loss:0.2503744661808014, Training time:16291.172636508942
batch reward last col mean 0.09469842910766602 first col mean 0.10334677249193192 all mean 0.10025371611118317
0.28009331226348877 0.28009331226348877
rl training, epoch5, iter0, batch418/1133, batch loss:0.28009331226348877, Training time:16292.738030433655
batch reward last col mean 0.09058885276317596 first col mean 0.09850151836872101 all mean 0.09240849316120148
0.2902924120426178 0.2902924120426178
rl training, epoch5, iter0, batch419/1133, batch loss:0.2902924120426178, Training time:16294.35215139389
batch reward last col mean 0.09381002187728882 first col mean 0.10582248866558075 all mean 0.09785477072000504
0.2797015905380249 0.2797015905380249
rl training, epoch5, iter0, batch420/1133, batch loss:0.2797015905380249, Training time:16295.959249019623
batch reward last col mean 0.12471997737884521 first col mean 0.10831547528505325 all mean 0.12184099853038788
0.3048085868358612 0.3048085868358612
rl training, epoch5, iter0, batch421/1133, batch loss:0.3048085868358612, Training time:16298.10873246193
batch reward last col mean 0.04436152055859566 first col mean 0.10575830191373825 all mean 0.0647071897983551
0.2559061646461487 0.2559061348438263
rl training, epoch5, iter0, batch422/1133, batch loss:0.2559061348438263, Training time:16299.828668355942
batch reward last col mean 0.10004657506942749 first col mean 0.11080802977085114 all mean 0.10668878257274628
0.27709144353866577 0.27709144353866577
rl training, epoch5, iter0, batch423/1133, batch loss:0.27709144353866577, Training time:16301.63811635971
batch reward last col mean 0.11210305988788605 first col mean 0.10254886746406555 all mean 0.11190714687108994
0.2674644887447357 0.26746445894241333
rl training, epoch5, iter0, batch424/1133, batch loss:0.26746445894241333, Training time:16303.632336854935
batch reward last col mean 0.0937105342745781 first col mean 0.08601392805576324 all mean 0.09736469388008118
0.3163624405860901 0.3163624405860901
rl training, epoch5, iter0, batch425/1133, batch loss:0.3163624405860901, Training time:16305.301458358765
batch reward last col mean 0.08492493629455566 first col mean 0.10654911398887634 all mean 0.08664646744728088
0.26793697476387024 0.26793697476387024
rl training, epoch5, iter0, batch426/1133, batch loss:0.26793697476387024, Training time:16307.160501241684
batch reward last col mean 0.10526751726865768 first col mean 0.10652938485145569 all mean 0.10288341343402863
0.2544402480125427 0.2544402480125427
rl training, epoch5, iter0, batch427/1133, batch loss:0.2544402480125427, Training time:16309.59178686142
batch reward last col mean 0.10659952461719513 first col mean 0.10518437623977661 all mean 0.1048159971833229
0.27567946910858154 0.27567946910858154
rl training, epoch5, iter0, batch428/1133, batch loss:0.27567946910858154, Training time:16311.602587223053
batch reward last col mean 0.08973045647144318 first col mean 0.1020529717206955 all mean 0.10043025016784668
0.32847318053245544 0.32847318053245544
rl training, epoch5, iter0, batch429/1133, batch loss:0.32847318053245544, Training time:16313.245375394821
batch reward last col mean 0.10839438438415527 first col mean 0.09632076323032379 all mean 0.10906621813774109
0.3054472804069519 0.3054472804069519
rl training, epoch5, iter0, batch430/1133, batch loss:0.3054472804069519, Training time:16315.097625017166
batch reward last col mean 0.12174025177955627 first col mean 0.11709322035312653 all mean 0.1129891648888588
0.28634485602378845 0.28634485602378845
rl training, epoch5, iter0, batch431/1133, batch loss:0.28634485602378845, Training time:16316.804458618164
batch reward last col mean 0.09791284054517746 first col mean 0.09636464715003967 all mean 0.10088379681110382
0.28300410509109497 0.28300410509109497
rl training, epoch5, iter0, batch432/1133, batch loss:0.28300410509109497, Training time:16318.824922561646
batch reward last col mean 0.11164437234401703 first col mean 0.10408725589513779 all mean 0.11221393942832947
0.30719423294067383 0.30719423294067383
rl training, epoch5, iter0, batch433/1133, batch loss:0.30719423294067383, Training time:16320.464114904404
batch reward last col mean 0.08637523651123047 first col mean 0.12518173456192017 all mean 0.09186465293169022
0.27082112431526184 0.27082112431526184
rl training, epoch5, iter0, batch434/1133, batch loss:0.27082112431526184, Training time:16322.065523147583
batch reward last col mean 0.11204302310943604 first col mean 0.10437991470098495 all mean 0.10761842131614685
0.31231337785720825 0.31231337785720825
rl training, epoch5, iter0, batch435/1133, batch loss:0.31231337785720825, Training time:16324.009271621704
batch reward last col mean 0.08216702938079834 first col mean 0.0998368039727211 all mean 0.0876825600862503
0.2712000012397766 0.2712000012397766
rl training, epoch5, iter0, batch436/1133, batch loss:0.2712000012397766, Training time:16325.588184595108
batch reward last col mean 0.10823006927967072 first col mean 0.12982869148254395 all mean 0.11200098693370819
0.3399650752544403 0.33996501564979553
rl training, epoch5, iter0, batch437/1133, batch loss:0.33996501564979553, Training time:16327.188548326492
batch reward last col mean 0.10994826257228851 first col mean 0.12036499381065369 all mean 0.11073718965053558
0.318307489156723 0.318307489156723
rl training, epoch5, iter0, batch438/1133, batch loss:0.318307489156723, Training time:16329.196034669876
batch reward last col mean 0.08864249289035797 first col mean 0.11049330979585648 all mean 0.09077471494674683
0.2660413384437561 0.2660413384437561
rl training, epoch5, iter0, batch439/1133, batch loss:0.2660413384437561, Training time:16330.93867301941
batch reward last col mean 0.09934733808040619 first col mean 0.09019391238689423 all mean 0.09215708076953888
0.2886117696762085 0.2886117696762085
rl training, epoch5, iter0, batch440/1133, batch loss:0.2886117696762085, Training time:16332.687932252884
batch reward last col mean 0.11196567118167877 first col mean 0.11319097131490707 all mean 0.11310624331235886
0.3122269809246063 0.3122269809246063
rl training, epoch5, iter0, batch441/1133, batch loss:0.3122269809246063, Training time:16334.352422475815
batch reward last col mean 0.08408786356449127 first col mean 0.10961751639842987 all mean 0.09188920259475708
0.2906954288482666 0.2906954288482666
rl training, epoch5, iter0, batch442/1133, batch loss:0.2906954288482666, Training time:16336.348178863525
batch reward last col mean 0.12648704648017883 first col mean 0.11765533685684204 all mean 0.11991888284683228
0.29722338914871216 0.29722338914871216
rl training, epoch5, iter0, batch443/1133, batch loss:0.29722338914871216, Training time:16338.737455368042
batch reward last col mean 0.09128360450267792 first col mean 0.10636124759912491 all mean 0.10038204491138458
0.3102051019668579 0.3102051019668579
rl training, epoch5, iter0, batch444/1133, batch loss:0.3102051019668579, Training time:16340.6614215374
batch reward last col mean 0.11520898342132568 first col mean 0.11271950602531433 all mean 0.11521017551422119
0.31515973806381226 0.31515973806381226
rl training, epoch5, iter0, batch445/1133, batch loss:0.31515973806381226, Training time:16343.809837818146
batch reward last col mean 0.09911093860864639 first col mean 0.10858102142810822 all mean 0.1024249941110611
0.2886536121368408 0.2886536121368408
rl training, epoch5, iter0, batch446/1133, batch loss:0.2886536121368408, Training time:16345.68361878395
batch reward last col mean 0.11925989389419556 first col mean 0.10333462059497833 all mean 0.11789184808731079
0.3298203647136688 0.32982033491134644
rl training, epoch5, iter0, batch447/1133, batch loss:0.32982033491134644, Training time:16347.110754013062
batch reward last col mean 0.12127290666103363 first col mean 0.10375617444515228 all mean 0.11938802152872086
0.315195769071579 0.315195769071579
rl training, epoch5, iter0, batch448/1133, batch loss:0.315195769071579, Training time:16349.234994888306
batch reward last col mean 0.11125901341438293 first col mean 0.10696031153202057 all mean 0.10915928333997726
0.2800873816013336 0.2800873816013336
rl training, epoch5, iter0, batch449/1133, batch loss:0.2800873816013336, Training time:16351.301144599915
batch reward last col mean 0.11717124283313751 first col mean 0.11692672967910767 all mean 0.11398249864578247
0.3213348984718323 0.3213348984718323
rl training, epoch5, iter0, batch450/1133, batch loss:0.3213348984718323, Training time:16353.036643743515
batch reward last col mean 0.10320035368204117 first col mean 0.08895407617092133 all mean 0.10457900911569595
0.33791810274124146 0.33791810274124146
rl training, epoch5, iter0, batch451/1133, batch loss:0.33791810274124146, Training time:16354.615074157715
batch reward last col mean 0.11783219128847122 first col mean 0.11101910471916199 all mean 0.11762838065624237
0.36683782935142517 0.36683782935142517
rl training, epoch5, iter0, batch452/1133, batch loss:0.36683782935142517, Training time:16356.29590845108
batch reward last col mean 0.1252041757106781 first col mean 0.12635213136672974 all mean 0.12568509578704834
0.3360609710216522 0.3360609710216522
rl training, epoch5, iter0, batch453/1133, batch loss:0.3360609710216522, Training time:16358.49855542183
batch reward last col mean 0.11157703399658203 first col mean 0.12280977517366409 all mean 0.11303207278251648
0.30119383335113525 0.30119386315345764
rl training, epoch5, iter0, batch454/1133, batch loss:0.30119386315345764, Training time:16361.0982568264
batch reward last col mean 0.09464474022388458 first col mean 0.08831910789012909 all mean 0.09971942752599716
0.28301170468330383 0.28301170468330383
rl training, epoch5, iter0, batch455/1133, batch loss:0.28301170468330383, Training time:16362.937784671783
batch reward last col mean 0.1200997531414032 first col mean 0.09959272295236588 all mean 0.11520488560199738
0.3041875660419464 0.3041875660419464
rl training, epoch5, iter0, batch456/1133, batch loss:0.3041875660419464, Training time:16364.518985033035
batch reward last col mean 0.11320719122886658 first col mean 0.09356657415628433 all mean 0.11351379752159119
0.3279504179954529 0.3279504179954529
rl training, epoch5, iter0, batch457/1133, batch loss:0.3279504179954529, Training time:16366.49812912941
batch reward last col mean 0.13922841846942902 first col mean 0.11496827006340027 all mean 0.1358419805765152
0.3131195902824402 0.3131195604801178
rl training, epoch5, iter0, batch458/1133, batch loss:0.3131195604801178, Training time:16368.989475488663
batch reward last col mean 0.09174912422895432 first col mean 0.11393208801746368 all mean 0.09145127981901169
0.2852347195148468 0.2852347195148468
rl training, epoch5, iter0, batch459/1133, batch loss:0.2852347195148468, Training time:16370.82434797287
batch reward last col mean 0.08074359595775604 first col mean 0.09657612442970276 all mean 0.09099237620830536
0.2921586036682129 0.2921585738658905
rl training, epoch5, iter0, batch460/1133, batch loss:0.2921585738658905, Training time:16372.704974889755
batch reward last col mean 0.08057226240634918 first col mean 0.10014106333255768 all mean 0.08887230604887009
0.28623491525650024 0.28623491525650024
rl training, epoch5, iter0, batch461/1133, batch loss:0.28623491525650024, Training time:16374.454394578934
batch reward last col mean 0.08665112406015396 first col mean 0.08206057548522949 all mean 0.09225188940763474
0.2903618812561035 0.2903619110584259
rl training, epoch5, iter0, batch462/1133, batch loss:0.2903619110584259, Training time:16376.300139427185
batch reward last col mean 0.11073355376720428 first col mean 0.10833951830863953 all mean 0.11616233736276627
0.30940356850624084 0.30940356850624084
rl training, epoch5, iter0, batch463/1133, batch loss:0.30940356850624084, Training time:16377.945046901703
batch reward last col mean 0.14167238771915436 first col mean 0.10802712291479111 all mean 0.127136692404747
0.3209091126918793 0.3209091126918793
rl training, epoch5, iter0, batch464/1133, batch loss:0.3209091126918793, Training time:16379.525501728058
batch reward last col mean 0.09523133188486099 first col mean 0.11153090000152588 all mean 0.1052422896027565
0.32076430320739746 0.32076430320739746
rl training, epoch5, iter0, batch465/1133, batch loss:0.32076430320739746, Training time:16381.395943403244
batch reward last col mean 0.10725817829370499 first col mean 0.12368722259998322 all mean 0.11421575397253036
0.3528803288936615 0.3528803288936615
rl training, epoch5, iter0, batch466/1133, batch loss:0.3528803288936615, Training time:16383.52078127861
batch reward last col mean 0.10662710666656494 first col mean 0.11339270323514938 all mean 0.10503829270601273
0.29836082458496094 0.29836082458496094
rl training, epoch5, iter0, batch467/1133, batch loss:0.29836082458496094, Training time:16385.409067869186
batch reward last col mean 0.11307615041732788 first col mean 0.11467696726322174 all mean 0.11227110028266907
0.30381739139556885 0.30381736159324646
rl training, epoch5, iter0, batch468/1133, batch loss:0.30381736159324646, Training time:16387.13919568062
batch reward last col mean 0.10267464071512222 first col mean 0.10843603312969208 all mean 0.1090206578373909
0.35812777280807495 0.35812777280807495
rl training, epoch5, iter0, batch469/1133, batch loss:0.35812777280807495, Training time:16388.940265893936
batch reward last col mean 0.1107955276966095 first col mean 0.11688342690467834 all mean 0.10896997153759003
0.31394046545028687 0.31394046545028687
rl training, epoch5, iter0, batch470/1133, batch loss:0.31394046545028687, Training time:16391.58173418045
batch reward last col mean 0.10478334873914719 first col mean 0.11688005924224854 all mean 0.10505333542823792
0.2959219217300415 0.2959219217300415
rl training, epoch5, iter0, batch471/1133, batch loss:0.2959219217300415, Training time:16393.31904411316
batch reward last col mean 0.061931051313877106 first col mean 0.12700530886650085 all mean 0.07813279330730438
0.27688026428222656 0.27688026428222656
rl training, epoch5, iter0, batch472/1133, batch loss:0.27688026428222656, Training time:16395.23603773117
batch reward last col mean 0.11604910343885422 first col mean 0.10394689440727234 all mean 0.1084829717874527
0.3078474700450897 0.3078474700450897
rl training, epoch5, iter0, batch473/1133, batch loss:0.3078474700450897, Training time:16397.59629011154
batch reward last col mean 0.09338598698377609 first col mean 0.12200053036212921 all mean 0.09288682043552399
0.27241969108581543 0.27241969108581543
rl training, epoch5, iter0, batch474/1133, batch loss:0.27241969108581543, Training time:16399.319988012314
batch reward last col mean 0.10665170848369598 first col mean 0.11312582343816757 all mean 0.10491473972797394
0.30431875586509705 0.30431875586509705
rl training, epoch5, iter0, batch475/1133, batch loss:0.30431875586509705, Training time:16401.04071879387
batch reward last col mean 0.0703677162528038 first col mean 0.10240183025598526 all mean 0.0804261714220047
0.2795429229736328 0.2795429229736328
rl training, epoch5, iter0, batch476/1133, batch loss:0.2795429229736328, Training time:16402.864969730377
batch reward last col mean 0.11192698776721954 first col mean 0.11074209958314896 all mean 0.10839557647705078
0.2897374927997589 0.2897375226020813
rl training, epoch5, iter0, batch477/1133, batch loss:0.2897375226020813, Training time:16405.415974855423
batch reward last col mean 0.08843053132295609 first col mean 0.11016716063022614 all mean 0.10105594247579575
0.30716198682785034 0.30716195702552795
rl training, epoch5, iter0, batch478/1133, batch loss:0.30716195702552795, Training time:16407.010355710983
batch reward last col mean 0.14844855666160583 first col mean 0.09606355428695679 all mean 0.13777506351470947
0.30724024772644043 0.3072402775287628
rl training, epoch5, iter0, batch479/1133, batch loss:0.3072402775287628, Training time:16409.89048910141
batch reward last col mean 0.09394757449626923 first col mean 0.11766299605369568 all mean 0.10511469841003418
0.3080675005912781 0.30806753039360046
rl training, epoch5, iter0, batch480/1133, batch loss:0.30806753039360046, Training time:16411.68668794632
batch reward last col mean 0.11549477279186249 first col mean 0.11413335055112839 all mean 0.11612369120121002
0.3779671788215637 0.3779671788215637
rl training, epoch5, iter0, batch481/1133, batch loss:0.3779671788215637, Training time:16413.348455429077
batch reward last col mean 0.10885032266378403 first col mean 0.11268174648284912 all mean 0.10900039970874786
0.2930259704589844 0.2930259704589844
rl training, epoch5, iter0, batch482/1133, batch loss:0.2930259704589844, Training time:16416.24781370163
batch reward last col mean 0.12307915091514587 first col mean 0.12031270563602448 all mean 0.12303802371025085
0.33469703793525696 0.33469703793525696
rl training, epoch5, iter0, batch483/1133, batch loss:0.33469703793525696, Training time:16417.71537899971
batch reward last col mean 0.10426673293113708 first col mean 0.08692649751901627 all mean 0.10673922300338745
0.35119152069091797 0.35119152069091797
rl training, epoch5, iter0, batch484/1133, batch loss:0.35119152069091797, Training time:16419.83875632286
batch reward last col mean 0.09509608894586563 first col mean 0.09503335505723953 all mean 0.09602046757936478
0.332874596118927 0.3328746259212494
rl training, epoch5, iter0, batch485/1133, batch loss:0.3328746259212494, Training time:16421.914541959763
batch reward last col mean 0.13033169507980347 first col mean 0.12079892307519913 all mean 0.12097947299480438
0.33364996314048767 0.33364996314048767
rl training, epoch5, iter0, batch486/1133, batch loss:0.33364996314048767, Training time:16423.548661470413
batch reward last col mean 0.07752472162246704 first col mean 0.11306771636009216 all mean 0.08311425149440765
0.25785768032073975 0.25785768032073975
rl training, epoch5, iter0, batch487/1133, batch loss:0.25785768032073975, Training time:16425.607925891876
batch reward last col mean 0.10722778737545013 first col mean 0.11249015480279922 all mean 0.10855833441019058
0.30745363235473633 0.30745363235473633
rl training, epoch5, iter0, batch488/1133, batch loss:0.30745363235473633, Training time:16427.38748073578
batch reward last col mean 0.1088816449046135 first col mean 0.1164693608880043 all mean 0.11553286761045456
0.3134692311286926 0.3134692311286926
rl training, epoch5, iter0, batch489/1133, batch loss:0.3134692311286926, Training time:16429.606642246246
batch reward last col mean 0.14505250751972198 first col mean 0.09948170930147171 all mean 0.13966962695121765
0.36474353075027466 0.36474353075027466
rl training, epoch5, iter0, batch490/1133, batch loss:0.36474353075027466, Training time:16431.453330278397
batch reward last col mean 0.09737151861190796 first col mean 0.09955821931362152 all mean 0.10107194632291794
0.2986278831958771 0.2986278831958771
rl training, epoch5, iter0, batch491/1133, batch loss:0.2986278831958771, Training time:16433.03635764122
batch reward last col mean 0.10275458544492722 first col mean 0.10562236607074738 all mean 0.10863659530878067
0.3101794719696045 0.3101794719696045
rl training, epoch5, iter0, batch492/1133, batch loss:0.3101794719696045, Training time:16435.08226132393
batch reward last col mean 0.08098698407411575 first col mean 0.1202431470155716 all mean 0.09045636653900146
0.2700510025024414 0.2700510025024414
rl training, epoch5, iter0, batch493/1133, batch loss:0.2700510025024414, Training time:16436.873797655106
batch reward last col mean 0.10383190959692001 first col mean 0.08971865475177765 all mean 0.1060653105378151
0.34071680903434753 0.34071680903434753
rl training, epoch5, iter0, batch494/1133, batch loss:0.34071680903434753, Training time:16439.133505821228
batch reward last col mean 0.11696696281433105 first col mean 0.12204150855541229 all mean 0.10860606282949448
0.33019599318504333 0.33019599318504333
rl training, epoch5, iter0, batch495/1133, batch loss:0.33019599318504333, Training time:16441.189611434937
batch reward last col mean 0.08714164048433304 first col mean 0.10076864808797836 all mean 0.09491623938083649
0.31358662247657776 0.31358662247657776
rl training, epoch5, iter0, batch496/1133, batch loss:0.31358662247657776, Training time:16442.98480129242
batch reward last col mean 0.09148214757442474 first col mean 0.10328973084688187 all mean 0.09673910588026047
0.29529085755348206 0.29529085755348206
rl training, epoch5, iter0, batch497/1133, batch loss:0.29529085755348206, Training time:16445.253116369247
batch reward last col mean 0.12006673961877823 first col mean 0.11517351865768433 all mean 0.11127838492393494
0.29583367705345154 0.29583364725112915
rl training, epoch5, iter0, batch498/1133, batch loss:0.29583364725112915, Training time:16447.717861413956
batch reward last col mean 0.09585747867822647 first col mean 0.1088784858584404 all mean 0.10433641821146011
0.3273598551750183 0.3273598551750183
rl training, epoch5, iter0, batch499/1133, batch loss:0.3273598551750183, Training time:16449.649079561234
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4918631513825793 Time: 97.88302969932556 s
loss of true 0.21354940225882332 loss of gen 0.17674791877998888 loss of other 0.10156583051145444 first score 0.12634561955928802
batch reward last col mean 0.13882839679718018 first col mean 0.1213734894990921 all mean 0.12902098894119263
0.3022506833076477 0.3022506833076477
rl training, epoch5, iter0, batch500/1133, batch loss:0.3022506833076477, Training time:16549.27134847641
batch reward last col mean 0.10821522772312164 first col mean 0.10785937309265137 all mean 0.10270566493272781
0.2956136167049408 0.2956136167049408
rl training, epoch5, iter0, batch501/1133, batch loss:0.2956136167049408, Training time:16551.34405398369
batch reward last col mean 0.06478673964738846 first col mean 0.10608810186386108 all mean 0.08176379650831223
0.3118763566017151 0.3118763566017151
rl training, epoch5, iter0, batch502/1133, batch loss:0.3118763566017151, Training time:16553.141070842743
batch reward last col mean 0.08811057358980179 first col mean 0.10172862559556961 all mean 0.08771665394306183
0.28482046723365784 0.28482046723365784
rl training, epoch5, iter0, batch503/1133, batch loss:0.28482046723365784, Training time:16554.9621591568
batch reward last col mean 0.06695237755775452 first col mean 0.12329080700874329 all mean 0.08389268070459366
0.30393505096435547 0.3039350211620331
rl training, epoch5, iter0, batch504/1133, batch loss:0.3039350211620331, Training time:16556.406154870987
batch reward last col mean 0.11188225448131561 first col mean 0.10575837641954422 all mean 0.10904138535261154
0.29951339960098267 0.29951339960098267
rl training, epoch5, iter0, batch505/1133, batch loss:0.29951339960098267, Training time:16558.122814655304
batch reward last col mean 0.10595232993364334 first col mean 0.10357540845870972 all mean 0.10322384536266327
0.3185005486011505 0.3185005486011505
rl training, epoch5, iter0, batch506/1133, batch loss:0.3185005486011505, Training time:16560.47438311577
batch reward last col mean 0.10006215423345566 first col mean 0.10140248388051987 all mean 0.10176548361778259
0.2861998975276947 0.2861998975276947
rl training, epoch5, iter0, batch507/1133, batch loss:0.2861998975276947, Training time:16562.35735321045
batch reward last col mean 0.10720130801200867 first col mean 0.09382716566324234 all mean 0.10673275589942932
0.3269844353199005 0.3269844353199005
rl training, epoch5, iter0, batch508/1133, batch loss:0.3269844353199005, Training time:16564.34064388275
batch reward last col mean 0.09846284985542297 first col mean 0.1014479249715805 all mean 0.09585724771022797
0.2796032130718231 0.2796032130718231
rl training, epoch5, iter0, batch509/1133, batch loss:0.2796032130718231, Training time:16566.249074220657
batch reward last col mean 0.10901202261447906 first col mean 0.11023348569869995 all mean 0.11049740761518478
0.3291870355606079 0.3291870355606079
rl training, epoch5, iter0, batch510/1133, batch loss:0.3291870355606079, Training time:16568.4615316391
batch reward last col mean 0.0954565480351448 first col mean 0.10228126496076584 all mean 0.0989508330821991
0.3180774748325348 0.3180774748325348
rl training, epoch5, iter0, batch511/1133, batch loss:0.3180774748325348, Training time:16570.46132540703
batch reward last col mean 0.0765882134437561 first col mean 0.10918352007865906 all mean 0.08313281834125519
0.27050042152404785 0.27050042152404785
rl training, epoch5, iter0, batch512/1133, batch loss:0.27050042152404785, Training time:16572.215705871582
batch reward last col mean 0.08378410339355469 first col mean 0.08861507475376129 all mean 0.0847567692399025
0.2597094476222992 0.2597094476222992
rl training, epoch5, iter0, batch513/1133, batch loss:0.2597094476222992, Training time:16574.107135295868
batch reward last col mean 0.0824047401547432 first col mean 0.11435602605342865 all mean 0.08547767996788025
0.2886127531528473 0.2886127531528473
rl training, epoch5, iter0, batch514/1133, batch loss:0.2886127531528473, Training time:16575.904656410217
batch reward last col mean 0.08857832849025726 first col mean 0.11970548331737518 all mean 0.09757045656442642
0.2934798002243042 0.2934798002243042
rl training, epoch5, iter0, batch515/1133, batch loss:0.2934798002243042, Training time:16577.676038742065
batch reward last col mean 0.07890601456165314 first col mean 0.09770151227712631 all mean 0.09161143004894257
0.28504401445388794 0.28504401445388794
rl training, epoch5, iter0, batch516/1133, batch loss:0.28504401445388794, Training time:16579.239604234695
batch reward last col mean 0.08399590849876404 first col mean 0.1000121682882309 all mean 0.08665390312671661
0.26691997051239014 0.26691997051239014
rl training, epoch5, iter0, batch517/1133, batch loss:0.26691997051239014, Training time:16581.14949941635
batch reward last col mean 0.08123575150966644 first col mean 0.12316287308931351 all mean 0.09062877297401428
0.3010699152946472 0.3010699152946472
rl training, epoch5, iter0, batch518/1133, batch loss:0.3010699152946472, Training time:16582.711760520935
batch reward last col mean 0.09828463941812515 first col mean 0.08611899614334106 all mean 0.09698806703090668
0.29445233941078186 0.29445233941078186
rl training, epoch5, iter0, batch519/1133, batch loss:0.29445233941078186, Training time:16584.357955932617
batch reward last col mean 0.08148591220378876 first col mean 0.10785198211669922 all mean 0.0989822968840599
0.34774744510650635 0.34774744510650635
rl training, epoch5, iter0, batch520/1133, batch loss:0.34774744510650635, Training time:16585.776544332504
batch reward last col mean 0.08075456321239471 first col mean 0.10728239268064499 all mean 0.08923129737377167
0.2891494035720825 0.2891494035720825
rl training, epoch5, iter0, batch521/1133, batch loss:0.2891494035720825, Training time:16587.967671871185
batch reward last col mean 0.10574185103178024 first col mean 0.11310527473688126 all mean 0.11001028120517731
0.3186516761779785 0.31865164637565613
rl training, epoch5, iter0, batch522/1133, batch loss:0.31865164637565613, Training time:16589.74022102356
batch reward last col mean 0.08834720402956009 first col mean 0.11757019907236099 all mean 0.08847292512655258
0.29679930210113525 0.29679933190345764
rl training, epoch5, iter0, batch523/1133, batch loss:0.29679933190345764, Training time:16591.889988183975
batch reward last col mean 0.09171542525291443 first col mean 0.10083163529634476 all mean 0.09278717637062073
0.29044535756111145 0.29044535756111145
rl training, epoch5, iter0, batch524/1133, batch loss:0.29044535756111145, Training time:16595.2822535038
batch reward last col mean 0.10329023003578186 first col mean 0.104286327958107 all mean 0.10765390843153
0.3230319619178772 0.3230319619178772
rl training, epoch5, iter0, batch525/1133, batch loss:0.3230319619178772, Training time:16597.166660547256
batch reward last col mean 0.0862579345703125 first col mean 0.10761155188083649 all mean 0.0933319702744484
0.26275232434272766 0.26275232434272766
rl training, epoch5, iter0, batch526/1133, batch loss:0.26275232434272766, Training time:16598.689689159393
batch reward last col mean 0.07881329208612442 first col mean 0.09226810932159424 all mean 0.09036468714475632
0.28880494832992554 0.28880494832992554
rl training, epoch5, iter0, batch527/1133, batch loss:0.28880494832992554, Training time:16600.494146585464
batch reward last col mean 0.12588909268379211 first col mean 0.09817182272672653 all mean 0.11594368517398834
0.3026060163974762 0.3026060163974762
rl training, epoch5, iter0, batch528/1133, batch loss:0.3026060163974762, Training time:16602.21148443222
batch reward last col mean 0.07723776251077652 first col mean 0.10715846717357635 all mean 0.08706127107143402
0.2771487534046173 0.2771487534046173
rl training, epoch5, iter0, batch529/1133, batch loss:0.2771487534046173, Training time:16604.05721306801
batch reward last col mean 0.08890285342931747 first col mean 0.09021890163421631 all mean 0.0938558578491211
0.29838836193084717 0.29838836193084717
rl training, epoch5, iter0, batch530/1133, batch loss:0.29838836193084717, Training time:16605.78402209282
batch reward last col mean 0.08515934646129608 first col mean 0.08826694637537003 all mean 0.09049540758132935
0.25320109724998474 0.25320109724998474
rl training, epoch5, iter0, batch531/1133, batch loss:0.25320109724998474, Training time:16607.414543628693
batch reward last col mean 0.09582650661468506 first col mean 0.11497530341148376 all mean 0.10305185616016388
0.27067485451698303 0.27067485451698303
rl training, epoch5, iter0, batch532/1133, batch loss:0.27067485451698303, Training time:16609.245467185974
batch reward last col mean 0.10203635692596436 first col mean 0.10131953656673431 all mean 0.10473547875881195
0.2960820198059082 0.2960820198059082
rl training, epoch5, iter0, batch533/1133, batch loss:0.2960820198059082, Training time:16611.27102994919
batch reward last col mean 0.09210823476314545 first col mean 0.1093636006116867 all mean 0.09713459759950638
0.28917190432548523 0.28917190432548523
rl training, epoch5, iter0, batch534/1133, batch loss:0.28917190432548523, Training time:16613.09193086624
batch reward last col mean 0.08006740361452103 first col mean 0.12066203355789185 all mean 0.09388969838619232
0.28377681970596313 0.28377678990364075
rl training, epoch5, iter0, batch535/1133, batch loss:0.28377678990364075, Training time:16614.62939429283
batch reward last col mean 0.12247832864522934 first col mean 0.1317552924156189 all mean 0.12134526669979095
0.327343225479126 0.327343225479126
rl training, epoch5, iter0, batch536/1133, batch loss:0.327343225479126, Training time:16617.11567568779
batch reward last col mean 0.11515223979949951 first col mean 0.11878614872694016 all mean 0.11034204810857773
0.26083409786224365 0.26083409786224365
rl training, epoch5, iter0, batch537/1133, batch loss:0.26083409786224365, Training time:16619.42874956131
batch reward last col mean 0.10042097419500351 first col mean 0.13063645362854004 all mean 0.10277727246284485
0.35194888710975647 0.3519488275051117
rl training, epoch5, iter0, batch538/1133, batch loss:0.3519488275051117, Training time:16620.963711738586
batch reward last col mean 0.08116451650857925 first col mean 0.09466571360826492 all mean 0.09076355397701263
0.3062590956687927 0.3062590956687927
rl training, epoch5, iter0, batch539/1133, batch loss:0.3062590956687927, Training time:16622.764534950256
batch reward last col mean 0.09910690784454346 first col mean 0.09732896089553833 all mean 0.09827635437250137
0.26801931858062744 0.26801931858062744
rl training, epoch5, iter0, batch540/1133, batch loss:0.26801931858062744, Training time:16624.33518075943
batch reward last col mean 0.09873034805059433 first col mean 0.11206431686878204 all mean 0.099779412150383
0.343341201543808 0.343341201543808
rl training, epoch5, iter0, batch541/1133, batch loss:0.343341201543808, Training time:16626.68998646736
batch reward last col mean 0.1147959977388382 first col mean 0.11031384021043777 all mean 0.1112741082906723
0.33214667439460754 0.33214667439460754
rl training, epoch5, iter0, batch542/1133, batch loss:0.33214667439460754, Training time:16628.40118265152
batch reward last col mean 0.13143247365951538 first col mean 0.1220804750919342 all mean 0.12958964705467224
0.3080276548862457 0.3080276548862457
rl training, epoch5, iter0, batch543/1133, batch loss:0.3080276548862457, Training time:16630.28753709793
batch reward last col mean 0.14306773245334625 first col mean 0.10440488159656525 all mean 0.12914632260799408
0.32107624411582947 0.32107624411582947
rl training, epoch5, iter0, batch544/1133, batch loss:0.32107624411582947, Training time:16632.246966600418
batch reward last col mean 0.1330508589744568 first col mean 0.11155690252780914 all mean 0.1296176165342331
0.32494091987609863 0.32494091987609863
rl training, epoch5, iter0, batch545/1133, batch loss:0.32494091987609863, Training time:16633.824677467346
batch reward last col mean 0.08586536347866058 first col mean 0.10813792049884796 all mean 0.09797041863203049
0.2886372208595276 0.2886372208595276
rl training, epoch5, iter0, batch546/1133, batch loss:0.2886372208595276, Training time:16635.287572860718
batch reward last col mean 0.10331717133522034 first col mean 0.11233483254909515 all mean 0.10529312491416931
0.3071138262748718 0.3071138262748718
rl training, epoch5, iter0, batch547/1133, batch loss:0.3071138262748718, Training time:16636.9845225811
batch reward last col mean 0.11718957126140594 first col mean 0.10736106336116791 all mean 0.1202116385102272
0.3453381657600403 0.3453381657600403
rl training, epoch5, iter0, batch548/1133, batch loss:0.3453381657600403, Training time:16638.27193713188
batch reward last col mean 0.09508182108402252 first col mean 0.10843983292579651 all mean 0.10710522532463074
0.3063546419143677 0.3063546419143677
rl training, epoch5, iter0, batch549/1133, batch loss:0.3063546419143677, Training time:16639.787202119827
batch reward last col mean 0.11325807869434357 first col mean 0.11003119498491287 all mean 0.11203964054584503
0.32930126786231995 0.32930126786231995
rl training, epoch5, iter0, batch550/1133, batch loss:0.32930126786231995, Training time:16641.41514468193
batch reward last col mean 0.10498729348182678 first col mean 0.12909983098506927 all mean 0.10575465112924576
0.2803996205329895 0.2803996205329895
rl training, epoch5, iter0, batch551/1133, batch loss:0.2803996205329895, Training time:16643.145128250122
batch reward last col mean 0.09701932966709137 first col mean 0.10689353197813034 all mean 0.1036643385887146
0.3103192150592804 0.3103192150592804
rl training, epoch5, iter0, batch552/1133, batch loss:0.3103192150592804, Training time:16644.763808250427
batch reward last col mean 0.10279718786478043 first col mean 0.12061147391796112 all mean 0.10186653584241867
0.3120957016944885 0.3120957016944885
rl training, epoch5, iter0, batch553/1133, batch loss:0.3120957016944885, Training time:16646.353347301483
batch reward last col mean 0.09720920026302338 first col mean 0.11523278802633286 all mean 0.11047908663749695
0.3398336172103882 0.3398336172103882
rl training, epoch5, iter0, batch554/1133, batch loss:0.3398336172103882, Training time:16647.912907123566
batch reward last col mean 0.1265888214111328 first col mean 0.11717343330383301 all mean 0.12099593132734299
0.33665481209754944 0.33665481209754944
rl training, epoch5, iter0, batch555/1133, batch loss:0.33665481209754944, Training time:16649.585002422333
batch reward last col mean 0.10581347346305847 first col mean 0.12027327716350555 all mean 0.1118466705083847
0.2571648359298706 0.2571648359298706
rl training, epoch5, iter0, batch556/1133, batch loss:0.2571648359298706, Training time:16651.08393216133
batch reward last col mean 0.08210698515176773 first col mean 0.1096755713224411 all mean 0.09107358753681183
0.26897990703582764 0.26897993683815
rl training, epoch5, iter0, batch557/1133, batch loss:0.26897993683815, Training time:16652.844608545303
batch reward last col mean 0.07533254474401474 first col mean 0.11350270360708237 all mean 0.08692143112421036
0.2621411979198456 0.2621411979198456
rl training, epoch5, iter0, batch558/1133, batch loss:0.2621411979198456, Training time:16654.557757616043
batch reward last col mean 0.1298316866159439 first col mean 0.11566757410764694 all mean 0.1266498565673828
0.3823271691799164 0.3823271691799164
rl training, epoch5, iter0, batch559/1133, batch loss:0.3823271691799164, Training time:16656.17376422882
batch reward last col mean 0.13260972499847412 first col mean 0.12038785219192505 all mean 0.12088825553655624
0.31689178943634033 0.31689178943634033
rl training, epoch5, iter0, batch560/1133, batch loss:0.31689178943634033, Training time:16657.87853384018
batch reward last col mean 0.10954540222883224 first col mean 0.11065312474966049 all mean 0.11066232621669769
0.29375848174095154 0.29375848174095154
rl training, epoch5, iter0, batch561/1133, batch loss:0.29375848174095154, Training time:16659.367735624313
batch reward last col mean 0.12413482367992401 first col mean 0.11261865496635437 all mean 0.12301555275917053
0.3195524513721466 0.3195524513721466
rl training, epoch5, iter0, batch562/1133, batch loss:0.3195524513721466, Training time:16661.13352870941
batch reward last col mean 0.11001777648925781 first col mean 0.09337298572063446 all mean 0.11247783899307251
0.3397223949432373 0.3397223949432373
rl training, epoch5, iter0, batch563/1133, batch loss:0.3397223949432373, Training time:16663.146826982498
batch reward last col mean 0.10840024054050446 first col mean 0.12074200809001923 all mean 0.10193798691034317
0.31229496002197266 0.31229496002197266
rl training, epoch5, iter0, batch564/1133, batch loss:0.31229496002197266, Training time:16664.78649353981
batch reward last col mean 0.10548751801252365 first col mean 0.1136557012796402 all mean 0.10901445895433426
0.3165261149406433 0.3165261149406433
rl training, epoch5, iter0, batch565/1133, batch loss:0.3165261149406433, Training time:16666.461299419403
batch reward last col mean 0.10198819637298584 first col mean 0.11100848019123077 all mean 0.1097344383597374
0.286516010761261 0.286516010761261
rl training, epoch5, iter0, batch566/1133, batch loss:0.286516010761261, Training time:16667.961359977722
batch reward last col mean 0.14507807791233063 first col mean 0.13587574660778046 all mean 0.12845510244369507
0.32406672835350037 0.32406672835350037
rl training, epoch5, iter0, batch567/1133, batch loss:0.32406672835350037, Training time:16669.39490365982
batch reward last col mean 0.12227818369865417 first col mean 0.11692826449871063 all mean 0.12552249431610107
0.3441265821456909 0.3441265821456909
rl training, epoch5, iter0, batch568/1133, batch loss:0.3441265821456909, Training time:16670.803547620773
batch reward last col mean 0.13910430669784546 first col mean 0.11610940098762512 all mean 0.13132236897945404
0.3863970935344696 0.3863970935344696
rl training, epoch5, iter0, batch569/1133, batch loss:0.3863970935344696, Training time:16672.279505491257
batch reward last col mean 0.08308781683444977 first col mean 0.11701178550720215 all mean 0.09221364557743073
0.3001832664012909 0.3001832664012909
rl training, epoch5, iter0, batch570/1133, batch loss:0.3001832664012909, Training time:16674.073166131973
batch reward last col mean 0.10320650041103363 first col mean 0.10974106192588806 all mean 0.11094165593385696
0.3256269097328186 0.3256269097328186
rl training, epoch5, iter0, batch571/1133, batch loss:0.3256269097328186, Training time:16676.166946411133
batch reward last col mean 0.10471691191196442 first col mean 0.10442979633808136 all mean 0.10883733630180359
0.3210967481136322 0.3210967481136322
rl training, epoch5, iter0, batch572/1133, batch loss:0.3210967481136322, Training time:16677.619436264038
batch reward last col mean 0.09174376726150513 first col mean 0.12012803554534912 all mean 0.09206043928861618
0.2749899923801422 0.2749899923801422
rl training, epoch5, iter0, batch573/1133, batch loss:0.2749899923801422, Training time:16679.15576672554
batch reward last col mean 0.09639013558626175 first col mean 0.1294485628604889 all mean 0.09994962066411972
0.32853490114212036 0.32853490114212036
rl training, epoch5, iter0, batch574/1133, batch loss:0.32853490114212036, Training time:16680.72489953041
batch reward last col mean 0.0905938446521759 first col mean 0.1270744651556015 all mean 0.09774766117334366
0.2923205494880676 0.2923205494880676
rl training, epoch5, iter0, batch575/1133, batch loss:0.2923205494880676, Training time:16682.284636497498
batch reward last col mean 0.11121708899736404 first col mean 0.11157167702913284 all mean 0.11251620203256607
0.35161101818084717 0.35161101818084717
rl training, epoch5, iter0, batch576/1133, batch loss:0.35161101818084717, Training time:16684.398326396942
batch reward last col mean 0.12826339900493622 first col mean 0.1243211179971695 all mean 0.12285217642784119
0.3888204097747803 0.3888204097747803
rl training, epoch5, iter0, batch577/1133, batch loss:0.3888204097747803, Training time:16686.12374162674
batch reward last col mean 0.10079982876777649 first col mean 0.11758069694042206 all mean 0.10358816385269165
0.3036101460456848 0.3036101460456848
rl training, epoch5, iter0, batch578/1133, batch loss:0.3036101460456848, Training time:16687.776561021805
batch reward last col mean 0.10467667877674103 first col mean 0.12395760416984558 all mean 0.10655571520328522
0.2920248508453369 0.2920248508453369
rl training, epoch5, iter0, batch579/1133, batch loss:0.2920248508453369, Training time:16689.70411658287
batch reward last col mean 0.11575745046138763 first col mean 0.13267606496810913 all mean 0.12245788425207138
0.3868175745010376 0.3868175148963928
rl training, epoch5, iter0, batch580/1133, batch loss:0.3868175148963928, Training time:16691.410037755966
batch reward last col mean 0.06865859776735306 first col mean 0.11695738881826401 all mean 0.081930972635746
0.29579293727874756 0.29579290747642517
rl training, epoch5, iter0, batch581/1133, batch loss:0.29579290747642517, Training time:16693.686923265457
batch reward last col mean 0.11565423011779785 first col mean 0.12494136393070221 all mean 0.12109506130218506
0.3127600848674774 0.3127600848674774
rl training, epoch5, iter0, batch582/1133, batch loss:0.3127600848674774, Training time:16695.58014035225
batch reward last col mean 0.1158609688282013 first col mean 0.11436718702316284 all mean 0.1105831116437912
0.3492222726345062 0.3492222726345062
rl training, epoch5, iter0, batch583/1133, batch loss:0.3492222726345062, Training time:16697.592835187912
batch reward last col mean 0.09401663392782211 first col mean 0.11685661971569061 all mean 0.1028059870004654
0.31559064984321594 0.31559064984321594
rl training, epoch5, iter0, batch584/1133, batch loss:0.31559064984321594, Training time:16699.016675710678
batch reward last col mean 0.12588262557983398 first col mean 0.09740407764911652 all mean 0.1181861013174057
0.29698240756988525 0.29698237776756287
rl training, epoch5, iter0, batch585/1133, batch loss:0.29698237776756287, Training time:16700.77474975586
batch reward last col mean 0.1083308607339859 first col mean 0.11758939176797867 all mean 0.1158134862780571
0.3231715261936188 0.3231715261936188
rl training, epoch5, iter0, batch586/1133, batch loss:0.3231715261936188, Training time:16702.610916137695
batch reward last col mean 0.13793720304965973 first col mean 0.1129555031657219 all mean 0.13131144642829895
0.3948056399822235 0.3948056399822235
rl training, epoch5, iter0, batch587/1133, batch loss:0.3948056399822235, Training time:16704.173882722855
batch reward last col mean 0.1205311045050621 first col mean 0.11579069495201111 all mean 0.11870542168617249
0.3274945914745331 0.3274945914745331
rl training, epoch5, iter0, batch588/1133, batch loss:0.3274945914745331, Training time:16705.869679927826
batch reward last col mean 0.08543545752763748 first col mean 0.10985089838504791 all mean 0.09328848123550415
0.2836618423461914 0.2836618423461914
rl training, epoch5, iter0, batch589/1133, batch loss:0.2836618423461914, Training time:16707.560478925705
batch reward last col mean 0.07921827584505081 first col mean 0.11989700794219971 all mean 0.08993494510650635
0.2794879674911499 0.2794879674911499
rl training, epoch5, iter0, batch590/1133, batch loss:0.2794879674911499, Training time:16709.086824178696
batch reward last col mean 0.09652256220579147 first col mean 0.1146233081817627 all mean 0.10366039723157883
0.33247438073158264 0.33247438073158264
rl training, epoch5, iter0, batch591/1133, batch loss:0.33247438073158264, Training time:16710.642312049866
batch reward last col mean 0.12601767480373383 first col mean 0.11301896721124649 all mean 0.12618157267570496
0.33242496848106384 0.33242496848106384
rl training, epoch5, iter0, batch592/1133, batch loss:0.33242496848106384, Training time:16712.327274799347
batch reward last col mean 0.09524603933095932 first col mean 0.1007046177983284 all mean 0.09505318105220795
0.291596919298172 0.291596919298172
rl training, epoch5, iter0, batch593/1133, batch loss:0.291596919298172, Training time:16714.45595550537
batch reward last col mean 0.09905839711427689 first col mean 0.11387725174427032 all mean 0.09877336770296097
0.2888469099998474 0.2888469099998474
rl training, epoch5, iter0, batch594/1133, batch loss:0.2888469099998474, Training time:16716.406955242157
batch reward last col mean 0.09763655811548233 first col mean 0.09619215130805969 all mean 0.10125556588172913
0.29900842905044556 0.29900845885276794
rl training, epoch5, iter0, batch595/1133, batch loss:0.29900845885276794, Training time:16717.942311048508
batch reward last col mean 0.09085328131914139 first col mean 0.10840153694152832 all mean 0.09843261539936066
0.28528323769569397 0.28528326749801636
rl training, epoch5, iter0, batch596/1133, batch loss:0.28528326749801636, Training time:16719.535800933838
batch reward last col mean 0.11112985759973526 first col mean 0.11309446394443512 all mean 0.11812902241945267
0.334885835647583 0.3348858058452606
rl training, epoch5, iter0, batch597/1133, batch loss:0.3348858058452606, Training time:16721.233960151672
batch reward last col mean 0.10747627913951874 first col mean 0.12588143348693848 all mean 0.11183974146842957
0.2969741225242615 0.2969741225242615
rl training, epoch5, iter0, batch598/1133, batch loss:0.2969741225242615, Training time:16722.734988212585
batch reward last col mean 0.07473580539226532 first col mean 0.11765982210636139 all mean 0.08948013931512833
0.32871437072753906 0.32871437072753906
rl training, epoch5, iter0, batch599/1133, batch loss:0.32871437072753906, Training time:16724.691567659378
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5046422286624942 Time: 93.86077642440796 s
loss of true 0.2204584638207546 loss of gen 0.18210919530172845 loss of other 0.1020745687467841 first score 0.12278541922569275
batch reward last col mean 0.07594827562570572 first col mean 0.09340248256921768 all mean 0.08428414911031723
0.25518175959587097 0.2551817297935486
rl training, epoch5, iter0, batch600/1133, batch loss:0.2551817297935486, Training time:16820.163338422775
batch reward last col mean 0.10413168370723724 first col mean 0.10298465937376022 all mean 0.10099023580551147
0.2839769124984741 0.2839769124984741
rl training, epoch5, iter0, batch601/1133, batch loss:0.2839769124984741, Training time:16821.739852905273
batch reward last col mean 0.07746678590774536 first col mean 0.11872145533561707 all mean 0.08160882443189621
0.2793239653110504 0.2793239653110504
rl training, epoch5, iter0, batch602/1133, batch loss:0.2793239653110504, Training time:16823.638605594635
batch reward last col mean 0.10914157330989838 first col mean 0.11322158575057983 all mean 0.10796300321817398
0.30704039335250854 0.30704039335250854
rl training, epoch5, iter0, batch603/1133, batch loss:0.30704039335250854, Training time:16825.860990285873
batch reward last col mean 0.07605347782373428 first col mean 0.11057844012975693 all mean 0.08392499387264252
0.26898515224456787 0.26898515224456787
rl training, epoch5, iter0, batch604/1133, batch loss:0.26898515224456787, Training time:16827.79902768135
batch reward last col mean 0.07686302065849304 first col mean 0.09721701592206955 all mean 0.08315202593803406
0.257064551115036 0.257064551115036
rl training, epoch5, iter0, batch605/1133, batch loss:0.257064551115036, Training time:16829.57632613182
batch reward last col mean 0.09638135135173798 first col mean 0.09551036357879639 all mean 0.10207288712263107
0.2735793888568878 0.27357935905456543
rl training, epoch5, iter0, batch606/1133, batch loss:0.27357935905456543, Training time:16830.94674897194
batch reward last col mean 0.10335630178451538 first col mean 0.08882959187030792 all mean 0.09830907732248306
0.2529526650905609 0.2529526650905609
rl training, epoch5, iter0, batch607/1133, batch loss:0.2529526650905609, Training time:16832.655444145203
batch reward last col mean 0.08414138853549957 first col mean 0.10775011777877808 all mean 0.08506467938423157
0.25957778096199036 0.25957778096199036
rl training, epoch5, iter0, batch608/1133, batch loss:0.25957778096199036, Training time:16834.707066059113
batch reward last col mean 0.07798244804143906 first col mean 0.11729249358177185 all mean 0.09066212177276611
0.2689240574836731 0.2689240574836731
rl training, epoch5, iter0, batch609/1133, batch loss:0.2689240574836731, Training time:16836.306475877762
batch reward last col mean 0.10755739361047745 first col mean 0.11899425089359283 all mean 0.10310933738946915
0.2579542100429535 0.2579542100429535
rl training, epoch5, iter0, batch610/1133, batch loss:0.2579542100429535, Training time:16838.547294855118
batch reward last col mean 0.12499275803565979 first col mean 0.10244464874267578 all mean 0.11913388222455978
0.295863538980484 0.295863538980484
rl training, epoch5, iter0, batch611/1133, batch loss:0.295863538980484, Training time:16840.4020755291
batch reward last col mean 0.07911847531795502 first col mean 0.0909125953912735 all mean 0.08318829536437988
0.27870145440101624 0.27870145440101624
rl training, epoch5, iter0, batch612/1133, batch loss:0.27870145440101624, Training time:16842.12486410141
batch reward last col mean 0.11150386929512024 first col mean 0.11445268988609314 all mean 0.11574363708496094
0.33205774426460266 0.33205774426460266
rl training, epoch5, iter0, batch613/1133, batch loss:0.33205774426460266, Training time:16844.097308158875
batch reward last col mean 0.10874567925930023 first col mean 0.12117062509059906 all mean 0.10320214182138443
0.3073430359363556 0.3073430359363556
rl training, epoch5, iter0, batch614/1133, batch loss:0.3073430359363556, Training time:16845.723996400833
batch reward last col mean 0.08001016825437546 first col mean 0.11781436204910278 all mean 0.08911338448524475
0.2539372146129608 0.2539372146129608
rl training, epoch5, iter0, batch615/1133, batch loss:0.2539372146129608, Training time:16847.902637004852
batch reward last col mean 0.11089491844177246 first col mean 0.10059646517038345 all mean 0.10945937037467957
0.26553335785865784 0.26553332805633545
rl training, epoch5, iter0, batch616/1133, batch loss:0.26553332805633545, Training time:16849.377957344055
batch reward last col mean 0.0908001959323883 first col mean 0.10401444882154465 all mean 0.0960245206952095
0.2654114067554474 0.2654114067554474
rl training, epoch5, iter0, batch617/1133, batch loss:0.2654114067554474, Training time:16851.23690199852
batch reward last col mean 0.08829665184020996 first col mean 0.08879400789737701 all mean 0.09201373904943466
0.2591336965560913 0.2591336965560913
rl training, epoch5, iter0, batch618/1133, batch loss:0.2591336965560913, Training time:16853.134082078934
batch reward last col mean 0.10105275362730026 first col mean 0.09915381669998169 all mean 0.10760392993688583
0.2563856840133667 0.2563856542110443
rl training, epoch5, iter0, batch619/1133, batch loss:0.2563856542110443, Training time:16854.720016241074
batch reward last col mean 0.0868426263332367 first col mean 0.10673555731773376 all mean 0.08879286795854568
0.25599533319473267 0.25599533319473267
rl training, epoch5, iter0, batch620/1133, batch loss:0.25599533319473267, Training time:16856.540244579315
batch reward last col mean 0.07348049432039261 first col mean 0.0945848673582077 all mean 0.08073469251394272
0.24126392602920532 0.24126392602920532
rl training, epoch5, iter0, batch621/1133, batch loss:0.24126392602920532, Training time:16858.367458105087
batch reward last col mean 0.13074791431427002 first col mean 0.11206451803445816 all mean 0.12189428508281708
0.2802887260913849 0.2802887260913849
rl training, epoch5, iter0, batch622/1133, batch loss:0.2802887260913849, Training time:16859.864647626877
batch reward last col mean 0.11395493149757385 first col mean 0.09725505113601685 all mean 0.10817842185497284
0.2812684178352356 0.2812684178352356
rl training, epoch5, iter0, batch623/1133, batch loss:0.2812684178352356, Training time:16862.02666759491
batch reward last col mean 0.12434320151805878 first col mean 0.09946783632040024 all mean 0.12101797014474869
0.32138344645500183 0.32138341665267944
rl training, epoch5, iter0, batch624/1133, batch loss:0.32138341665267944, Training time:16864.16760802269
batch reward last col mean 0.11362595856189728 first col mean 0.088628850877285 all mean 0.11432904750108719
0.2782801687717438 0.2782801687717438
rl training, epoch5, iter0, batch625/1133, batch loss:0.2782801687717438, Training time:16866.157590150833
batch reward last col mean 0.13909617066383362 first col mean 0.0861838236451149 all mean 0.13105803728103638
0.3134521543979645 0.3134521543979645
rl training, epoch5, iter0, batch626/1133, batch loss:0.3134521543979645, Training time:16868.35102415085
batch reward last col mean 0.09351576864719391 first col mean 0.1153733879327774 all mean 0.09372539818286896
0.2493041753768921 0.2493041753768921
rl training, epoch5, iter0, batch627/1133, batch loss:0.2493041753768921, Training time:16870.046904563904
batch reward last col mean 0.11596059799194336 first col mean 0.10300566256046295 all mean 0.11068753153085709
0.3414086401462555 0.3414086401462555
rl training, epoch5, iter0, batch628/1133, batch loss:0.3414086401462555, Training time:16871.592772483826
batch reward last col mean 0.1082809716463089 first col mean 0.09039118885993958 all mean 0.10164061933755875
0.2531445324420929 0.2531445324420929
rl training, epoch5, iter0, batch629/1133, batch loss:0.2531445324420929, Training time:16873.653508901596
batch reward last col mean 0.09774741530418396 first col mean 0.1021110862493515 all mean 0.10462336987257004
0.3050073981285095 0.3050074279308319
rl training, epoch5, iter0, batch630/1133, batch loss:0.3050074279308319, Training time:16875.296610593796
batch reward last col mean 0.09146330505609512 first col mean 0.09204165637493134 all mean 0.10024791210889816
0.27182719111442566 0.27182719111442566
rl training, epoch5, iter0, batch631/1133, batch loss:0.27182719111442566, Training time:16876.88243174553
batch reward last col mean 0.06700176000595093 first col mean 0.11136731505393982 all mean 0.0757606253027916
0.23079805076122284 0.23079805076122284
rl training, epoch5, iter0, batch632/1133, batch loss:0.23079805076122284, Training time:16878.923191070557
batch reward last col mean 0.09004522860050201 first col mean 0.10480745136737823 all mean 0.0911388099193573
0.26795029640197754 0.26795029640197754
rl training, epoch5, iter0, batch633/1133, batch loss:0.26795029640197754, Training time:16880.75793480873
batch reward last col mean 0.11104618012905121 first col mean 0.08678079396486282 all mean 0.11023422330617905
0.2739793360233307 0.2739793062210083
rl training, epoch5, iter0, batch634/1133, batch loss:0.2739793062210083, Training time:16882.696016550064
batch reward last col mean 0.09923599660396576 first col mean 0.10696958005428314 all mean 0.10010749846696854
0.319295197725296 0.319295197725296
rl training, epoch5, iter0, batch635/1133, batch loss:0.319295197725296, Training time:16883.968587636948
batch reward last col mean 0.12850475311279297 first col mean 0.10128984600305557 all mean 0.1280786097049713
0.3146023154258728 0.3146023154258728
rl training, epoch5, iter0, batch636/1133, batch loss:0.3146023154258728, Training time:16885.592742204666
batch reward last col mean 0.1471928060054779 first col mean 0.11137335747480392 all mean 0.13821454346179962
0.3533641993999481 0.3533641993999481
rl training, epoch5, iter0, batch637/1133, batch loss:0.3533641993999481, Training time:16887.438007116318
batch reward last col mean 0.09564881771802902 first col mean 0.10811937600374222 all mean 0.09462326765060425
0.2647402584552765 0.2647402584552765
rl training, epoch5, iter0, batch638/1133, batch loss:0.2647402584552765, Training time:16889.419986248016
batch reward last col mean 0.09819135069847107 first col mean 0.11025366932153702 all mean 0.0994955450296402
0.32206153869628906 0.3220615088939667
rl training, epoch5, iter0, batch639/1133, batch loss:0.3220615088939667, Training time:16891.49923157692
batch reward last col mean 0.1022462323307991 first col mean 0.09831532835960388 all mean 0.10696662962436676
0.2934781014919281 0.2934781014919281
rl training, epoch5, iter0, batch640/1133, batch loss:0.2934781014919281, Training time:16893.578290224075
batch reward last col mean 0.10194560885429382 first col mean 0.09630587697029114 all mean 0.09972620010375977
0.26473137736320496 0.26473137736320496
rl training, epoch5, iter0, batch641/1133, batch loss:0.26473137736320496, Training time:16895.129168510437
batch reward last col mean 0.09875259548425674 first col mean 0.10969939827919006 all mean 0.10689329355955124
0.30891430377960205 0.30891427397727966
rl training, epoch5, iter0, batch642/1133, batch loss:0.30891427397727966, Training time:16897.01580929756
batch reward last col mean 0.10652965307235718 first col mean 0.12316747009754181 all mean 0.11124701052904129
0.27953192591667175 0.27953192591667175
rl training, epoch5, iter0, batch643/1133, batch loss:0.27953192591667175, Training time:16899.214743852615
batch reward last col mean 0.07366493344306946 first col mean 0.10744743794202805 all mean 0.08691167831420898
0.25769445300102234 0.25769445300102234
rl training, epoch5, iter0, batch644/1133, batch loss:0.25769445300102234, Training time:16901.03346180916
batch reward last col mean 0.0937940776348114 first col mean 0.10934696346521378 all mean 0.09897133708000183
0.27533262968063354 0.27533262968063354
rl training, epoch5, iter0, batch645/1133, batch loss:0.27533262968063354, Training time:16902.608321666718
batch reward last col mean 0.11881129443645477 first col mean 0.11418741941452026 all mean 0.1135706752538681
0.30677416920661926 0.30677416920661926
rl training, epoch5, iter0, batch646/1133, batch loss:0.30677416920661926, Training time:16904.337141513824
batch reward last col mean 0.09013873338699341 first col mean 0.09411878138780594 all mean 0.08779881149530411
0.2318151593208313 0.2318151593208313
rl training, epoch5, iter0, batch647/1133, batch loss:0.2318151593208313, Training time:16906.113481760025
batch reward last col mean 0.07383237779140472 first col mean 0.09421364217996597 all mean 0.08449897170066833
0.22817842662334442 0.22817841172218323
rl training, epoch5, iter0, batch648/1133, batch loss:0.22817841172218323, Training time:16907.508192062378
batch reward last col mean 0.07113304734230042 first col mean 0.10844133794307709 all mean 0.08241531997919083
0.2796259820461273 0.2796259820461273
rl training, epoch5, iter0, batch649/1133, batch loss:0.2796259820461273, Training time:16909.292860984802
batch reward last col mean 0.08470740169286728 first col mean 0.11933679133653641 all mean 0.09492544084787369
0.29361337423324585 0.29361340403556824
rl training, epoch5, iter0, batch650/1133, batch loss:0.29361340403556824, Training time:16911.3763794899
batch reward last col mean 0.09518887847661972 first col mean 0.1130753830075264 all mean 0.09700407087802887
0.2826434373855591 0.2826434373855591
rl training, epoch5, iter0, batch651/1133, batch loss:0.2826434373855591, Training time:16913.202340364456
batch reward last col mean 0.08404102176427841 first col mean 0.09903097152709961 all mean 0.08556971698999405
0.28156909346580505 0.28156909346580505
rl training, epoch5, iter0, batch652/1133, batch loss:0.28156909346580505, Training time:16915.10510134697
batch reward last col mean 0.08877645432949066 first col mean 0.11777178943157196 all mean 0.09571599960327148
0.2947436571121216 0.2947436571121216
rl training, epoch5, iter0, batch653/1133, batch loss:0.2947436571121216, Training time:16917.12092423439
batch reward last col mean 0.1269402652978897 first col mean 0.11112985014915466 all mean 0.12298037111759186
0.27295705676078796 0.27295705676078796
rl training, epoch5, iter0, batch654/1133, batch loss:0.27295705676078796, Training time:16919.54018855095
batch reward last col mean 0.11142881214618683 first col mean 0.12499822676181793 all mean 0.11059411615133286
0.3190333843231201 0.3190333843231201
rl training, epoch5, iter0, batch655/1133, batch loss:0.3190333843231201, Training time:16921.62331700325
batch reward last col mean 0.11900989711284637 first col mean 0.11188903450965881 all mean 0.116683728992939
0.26650747656822205 0.26650750637054443
rl training, epoch5, iter0, batch656/1133, batch loss:0.26650750637054443, Training time:16923.60638475418
batch reward last col mean 0.09849675744771957 first col mean 0.11073615401983261 all mean 0.09877780824899673
0.28942060470581055 0.28942060470581055
rl training, epoch5, iter0, batch657/1133, batch loss:0.28942060470581055, Training time:16925.509794950485
batch reward last col mean 0.10220250487327576 first col mean 0.10475650429725647 all mean 0.10961982607841492
0.2820282578468323 0.2820282578468323
rl training, epoch5, iter0, batch658/1133, batch loss:0.2820282578468323, Training time:16926.98522567749
batch reward last col mean 0.08510696887969971 first col mean 0.09369654953479767 all mean 0.09022371470928192
0.24381566047668457 0.24381566047668457
rl training, epoch5, iter0, batch659/1133, batch loss:0.24381566047668457, Training time:16928.3503575325
batch reward last col mean 0.10611759126186371 first col mean 0.09808909893035889 all mean 0.10489536076784134
0.2800489366054535 0.2800489366054535
rl training, epoch5, iter0, batch660/1133, batch loss:0.2800489366054535, Training time:16930.438294410706
batch reward last col mean 0.14061984419822693 first col mean 0.10600873827934265 all mean 0.13035592436790466
0.35216405987739563 0.35216405987739563
rl training, epoch5, iter0, batch661/1133, batch loss:0.35216405987739563, Training time:16932.092765808105
batch reward last col mean 0.09647691249847412 first col mean 0.09638141840696335 all mean 0.10025841742753983
0.2990148067474365 0.2990148067474365
rl training, epoch5, iter0, batch662/1133, batch loss:0.2990148067474365, Training time:16934.12695980072
batch reward last col mean 0.10333867371082306 first col mean 0.10359853506088257 all mean 0.10437411069869995
0.30477291345596313 0.30477291345596313
rl training, epoch5, iter0, batch663/1133, batch loss:0.30477291345596313, Training time:16935.974226474762
batch reward last col mean 0.0870777815580368 first col mean 0.0980415940284729 all mean 0.08682867884635925
0.2420528084039688 0.2420528084039688
rl training, epoch5, iter0, batch664/1133, batch loss:0.2420528084039688, Training time:16937.730932950974
batch reward last col mean 0.11147807538509369 first col mean 0.10959699749946594 all mean 0.10874289274215698
0.30078595876693726 0.30078595876693726
rl training, epoch5, iter0, batch665/1133, batch loss:0.30078595876693726, Training time:16939.520855903625
batch reward last col mean 0.073013074696064 first col mean 0.11394552886486053 all mean 0.08189234137535095
0.2740240693092346 0.2740240693092346
rl training, epoch5, iter0, batch666/1133, batch loss:0.2740240693092346, Training time:16941.805425405502
batch reward last col mean 0.10315833240747452 first col mean 0.10282903909683228 all mean 0.10040754079818726
0.26320016384124756 0.26320016384124756
rl training, epoch5, iter0, batch667/1133, batch loss:0.26320016384124756, Training time:16944.825659751892
batch reward last col mean 0.09707311540842056 first col mean 0.10240575671195984 all mean 0.09645302593708038
0.2907784581184387 0.2907784581184387
rl training, epoch5, iter0, batch668/1133, batch loss:0.2907784581184387, Training time:16946.64923095703
batch reward last col mean 0.10921022295951843 first col mean 0.10914507508277893 all mean 0.11030422896146774
0.28339341282844543 0.28339341282844543
rl training, epoch5, iter0, batch669/1133, batch loss:0.28339341282844543, Training time:16948.77048921585
batch reward last col mean 0.106521837413311 first col mean 0.09164895862340927 all mean 0.1051146537065506
0.2810254395008087 0.2810254395008087
rl training, epoch5, iter0, batch670/1133, batch loss:0.2810254395008087, Training time:16951.15821170807
batch reward last col mean 0.1041809692978859 first col mean 0.11297652870416641 all mean 0.107259102165699
0.30155956745147705 0.30155956745147705
rl training, epoch5, iter0, batch671/1133, batch loss:0.30155956745147705, Training time:16953.440895318985
batch reward last col mean 0.11792612075805664 first col mean 0.11806550621986389 all mean 0.11844933778047562
0.29930394887924194 0.29930394887924194
rl training, epoch5, iter0, batch672/1133, batch loss:0.29930394887924194, Training time:16955.212716579437
batch reward last col mean 0.10646585375070572 first col mean 0.11659828573465347 all mean 0.10603101551532745
0.3247416615486145 0.3247416615486145
rl training, epoch5, iter0, batch673/1133, batch loss:0.3247416615486145, Training time:16957.104333400726
batch reward last col mean 0.11485831439495087 first col mean 0.10613158345222473 all mean 0.11446849256753922
0.32637715339660645 0.32637715339660645
rl training, epoch5, iter0, batch674/1133, batch loss:0.32637715339660645, Training time:16959.095376729965
batch reward last col mean 0.09712540358304977 first col mean 0.09859570860862732 all mean 0.09620144963264465
0.2958585321903229 0.2958585321903229
rl training, epoch5, iter0, batch675/1133, batch loss:0.2958585321903229, Training time:16960.882570266724
batch reward last col mean 0.09553605318069458 first col mean 0.10493778437376022 all mean 0.10084879398345947
0.30454301834106445 0.30454304814338684
rl training, epoch5, iter0, batch676/1133, batch loss:0.30454304814338684, Training time:16962.77041387558
batch reward last col mean 0.08773958683013916 first col mean 0.10772436112165451 all mean 0.0960649698972702
0.31037667393684387 0.31037667393684387
rl training, epoch5, iter0, batch677/1133, batch loss:0.31037667393684387, Training time:16964.610820055008
batch reward last col mean 0.10904200375080109 first col mean 0.12009499967098236 all mean 0.11437256634235382
0.3059074282646179 0.3059074282646179
rl training, epoch5, iter0, batch678/1133, batch loss:0.3059074282646179, Training time:16966.36083817482
batch reward last col mean 0.10971827059984207 first col mean 0.11545358598232269 all mean 0.10739929974079132
0.3264741897583008 0.3264741897583008
rl training, epoch5, iter0, batch679/1133, batch loss:0.3264741897583008, Training time:16968.027616024017
batch reward last col mean 0.09153120219707489 first col mean 0.12559017539024353 all mean 0.10137171298265457
0.2738904058933258 0.2738904058933258
rl training, epoch5, iter0, batch680/1133, batch loss:0.2738904058933258, Training time:16969.704337120056
batch reward last col mean 0.11180304735898972 first col mean 0.09399577230215073 all mean 0.11365552246570587
0.28887638449668884 0.28887638449668884
rl training, epoch5, iter0, batch681/1133, batch loss:0.28887638449668884, Training time:16971.386997938156
batch reward last col mean 0.12070918083190918 first col mean 0.10676021873950958 all mean 0.12232368439435959
0.3163236379623413 0.3163236379623413
rl training, epoch5, iter0, batch682/1133, batch loss:0.3163236379623413, Training time:16973.279855966568
batch reward last col mean 0.09313619136810303 first col mean 0.10389549285173416 all mean 0.10134519636631012
0.2970435619354248 0.2970435619354248
rl training, epoch5, iter0, batch683/1133, batch loss:0.2970435619354248, Training time:16974.774317502975
batch reward last col mean 0.1332808881998062 first col mean 0.10919864475727081 all mean 0.1311287134885788
0.38281866908073425 0.38281866908073425
rl training, epoch5, iter0, batch684/1133, batch loss:0.38281866908073425, Training time:16977.707589149475
batch reward last col mean 0.0689365565776825 first col mean 0.09638678282499313 all mean 0.07620591670274734
0.2517576515674591 0.2517576217651367
rl training, epoch5, iter0, batch685/1133, batch loss:0.2517576217651367, Training time:16979.705616235733
batch reward last col mean 0.07808681577444077 first col mean 0.10185336321592331 all mean 0.08881251513957977
0.2832041382789612 0.2832041382789612
rl training, epoch5, iter0, batch686/1133, batch loss:0.2832041382789612, Training time:16981.66665005684
batch reward last col mean 0.11334425210952759 first col mean 0.11404997855424881 all mean 0.11383546888828278
0.3196927309036255 0.3196927309036255
rl training, epoch5, iter0, batch687/1133, batch loss:0.3196927309036255, Training time:16983.408108234406
batch reward last col mean 0.11126101762056351 first col mean 0.12000413984060287 all mean 0.11364694684743881
0.32984659075737 0.32984659075737
rl training, epoch5, iter0, batch688/1133, batch loss:0.32984659075737, Training time:16985.58794617653
batch reward last col mean 0.10373485088348389 first col mean 0.11162987351417542 all mean 0.11148932576179504
0.3382006287574768 0.3382006287574768
rl training, epoch5, iter0, batch689/1133, batch loss:0.3382006287574768, Training time:16987.31024479866
batch reward last col mean 0.09353271126747131 first col mean 0.11817996203899384 all mean 0.09888360649347305
0.3504272699356079 0.3504272699356079
rl training, epoch5, iter0, batch690/1133, batch loss:0.3504272699356079, Training time:16989.787884235382
batch reward last col mean 0.07264705747365952 first col mean 0.10387519001960754 all mean 0.08943749219179153
0.31492847204208374 0.31492847204208374
rl training, epoch5, iter0, batch691/1133, batch loss:0.31492847204208374, Training time:16991.652961969376
batch reward last col mean 0.1322641372680664 first col mean 0.10432082414627075 all mean 0.13070373237133026
0.3746529519557953 0.3746528923511505
rl training, epoch5, iter0, batch692/1133, batch loss:0.3746528923511505, Training time:16993.152806520462
batch reward last col mean 0.08390243351459503 first col mean 0.09723968803882599 all mean 0.09161966294050217
0.2871076464653015 0.2871076464653015
rl training, epoch5, iter0, batch693/1133, batch loss:0.2871076464653015, Training time:16995.33468914032
batch reward last col mean 0.09420377761125565 first col mean 0.09792405366897583 all mean 0.09488695859909058
0.2788335680961609 0.2788335680961609
rl training, epoch5, iter0, batch694/1133, batch loss:0.2788335680961609, Training time:16997.159343242645
batch reward last col mean 0.11613190174102783 first col mean 0.13008591532707214 all mean 0.11369789391756058
0.3198103606700897 0.3198103606700897
rl training, epoch5, iter0, batch695/1133, batch loss:0.3198103606700897, Training time:16999.39771080017
batch reward last col mean 0.10511577129364014 first col mean 0.10554933547973633 all mean 0.10676946491003036
0.2924268841743469 0.2924268841743469
rl training, epoch5, iter0, batch696/1133, batch loss:0.2924268841743469, Training time:17001.605090379715
batch reward last col mean 0.14738333225250244 first col mean 0.09614939242601395 all mean 0.13451135158538818
0.34062790870666504 0.34062790870666504
rl training, epoch5, iter0, batch697/1133, batch loss:0.34062790870666504, Training time:17003.782397031784
batch reward last col mean 0.09977671504020691 first col mean 0.11337384581565857 all mean 0.10814036428928375
0.3187963664531708 0.3187963664531708
rl training, epoch5, iter0, batch698/1133, batch loss:0.3187963664531708, Training time:17005.801391124725
batch reward last col mean 0.14837822318077087 first col mean 0.11105169355869293 all mean 0.13157804310321808
0.3223147988319397 0.3223147988319397
rl training, epoch5, iter0, batch699/1133, batch loss:0.3223147988319397, Training time:17007.712933301926
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5025402179673406 Time: 95.01039934158325 s
loss of true 0.21820940398870056 loss of gen 0.18301467341021532 loss of other 0.10131613998645086 first score 0.13353095948696136
batch reward last col mean 0.12103946506977081 first col mean 0.11294315755367279 all mean 0.1153763011097908
0.3050447702407837 0.3050447702407837
rl training, epoch5, iter0, batch700/1133, batch loss:0.3050447702407837, Training time:17105.006216287613
batch reward last col mean 0.11797893047332764 first col mean 0.10016213357448578 all mean 0.1118130013346672
0.2909393012523651 0.2909393012523651
rl training, epoch5, iter0, batch701/1133, batch loss:0.2909393012523651, Training time:17106.752844810486
batch reward last col mean 0.10049095749855042 first col mean 0.11544082313776016 all mean 0.1016383022069931
0.290774941444397 0.2907749116420746
rl training, epoch5, iter0, batch702/1133, batch loss:0.2907749116420746, Training time:17108.88805913925
batch reward last col mean 0.11753730475902557 first col mean 0.10732772201299667 all mean 0.11656177788972855
0.294183611869812 0.294183611869812
rl training, epoch5, iter0, batch703/1133, batch loss:0.294183611869812, Training time:17110.87152981758
batch reward last col mean 0.09117167443037033 first col mean 0.11628976464271545 all mean 0.09590589255094528
0.24949945509433746 0.24949945509433746
rl training, epoch5, iter0, batch704/1133, batch loss:0.24949945509433746, Training time:17113.762336969376
batch reward last col mean 0.10096577554941177 first col mean 0.1028568297624588 all mean 0.10453005135059357
0.32374051213264465 0.32374051213264465
rl training, epoch5, iter0, batch705/1133, batch loss:0.32374051213264465, Training time:17115.76137280464
batch reward last col mean 0.119260773062706 first col mean 0.1028313934803009 all mean 0.11178027093410492
0.2907928228378296 0.290792852640152
rl training, epoch5, iter0, batch706/1133, batch loss:0.290792852640152, Training time:17117.873764276505
batch reward last col mean 0.10819324105978012 first col mean 0.11657495051622391 all mean 0.10373024642467499
0.3070741891860962 0.3070741891860962
rl training, epoch5, iter0, batch707/1133, batch loss:0.3070741891860962, Training time:17120.292726755142
batch reward last col mean 0.10044856369495392 first col mean 0.11778676509857178 all mean 0.10099492222070694
0.30310362577438354 0.30310362577438354
rl training, epoch5, iter0, batch708/1133, batch loss:0.30310362577438354, Training time:17123.40199828148
batch reward last col mean 0.10537204146385193 first col mean 0.11606147885322571 all mean 0.110242560505867
0.3460904061794281 0.3460904061794281
rl training, epoch5, iter0, batch709/1133, batch loss:0.3460904061794281, Training time:17125.61449074745
batch reward last col mean 0.09411486238241196 first col mean 0.10910192131996155 all mean 0.09689431637525558
0.287016898393631 0.287016898393631
rl training, epoch5, iter0, batch710/1133, batch loss:0.287016898393631, Training time:17127.7216360569
batch reward last col mean 0.10590923577547073 first col mean 0.10318340361118317 all mean 0.10486263781785965
0.2999369502067566 0.2999369502067566
rl training, epoch5, iter0, batch711/1133, batch loss:0.2999369502067566, Training time:17130.1726000309
batch reward last col mean 0.10881353169679642 first col mean 0.11702028661966324 all mean 0.11116940528154373
0.3056153953075409 0.3056153953075409
rl training, epoch5, iter0, batch712/1133, batch loss:0.3056153953075409, Training time:17132.472407102585
batch reward last col mean 0.10785262286663055 first col mean 0.1109260618686676 all mean 0.10885818302631378
0.31183695793151855 0.31183692812919617
rl training, epoch5, iter0, batch713/1133, batch loss:0.31183692812919617, Training time:17134.808626174927
batch reward last col mean 0.09997771680355072 first col mean 0.09938787668943405 all mean 0.09988056868314743
0.26728928089141846 0.26728928089141846
rl training, epoch5, iter0, batch714/1133, batch loss:0.26728928089141846, Training time:17137.36875653267
batch reward last col mean 0.10723865777254105 first col mean 0.10773579031229019 all mean 0.10655295848846436
0.3066052496433258 0.3066052496433258
rl training, epoch5, iter0, batch715/1133, batch loss:0.3066052496433258, Training time:17139.540237665176
batch reward last col mean 0.09573911130428314 first col mean 0.11089374125003815 all mean 0.10346854478120804
0.30494073033332825 0.30494073033332825
rl training, epoch5, iter0, batch716/1133, batch loss:0.30494073033332825, Training time:17141.355266809464
batch reward last col mean 0.10960308462381363 first col mean 0.11674380302429199 all mean 0.10639162361621857
0.27391138672828674 0.27391138672828674
rl training, epoch5, iter0, batch717/1133, batch loss:0.27391138672828674, Training time:17143.296523571014
batch reward last col mean 0.08654721826314926 first col mean 0.1119881123304367 all mean 0.0923030897974968
0.2993232309818268 0.2993232309818268
rl training, epoch5, iter0, batch718/1133, batch loss:0.2993232309818268, Training time:17145.443888425827
batch reward last col mean 0.13618256151676178 first col mean 0.11068009585142136 all mean 0.12720024585723877
0.2907025218009949 0.2907025218009949
rl training, epoch5, iter0, batch719/1133, batch loss:0.2907025218009949, Training time:17147.70606660843
batch reward last col mean 0.11867329478263855 first col mean 0.12496832013130188 all mean 0.11926647275686264
0.33523693680763245 0.33523693680763245
rl training, epoch5, iter0, batch720/1133, batch loss:0.33523693680763245, Training time:17150.23541688919
batch reward last col mean 0.1232716292142868 first col mean 0.0928606316447258 all mean 0.11909841001033783
0.2856070399284363 0.2856070399284363
rl training, epoch5, iter0, batch721/1133, batch loss:0.2856070399284363, Training time:17152.31881380081
batch reward last col mean 0.09281346946954727 first col mean 0.10232797265052795 all mean 0.09001043438911438
0.25146618485450745 0.25146618485450745
rl training, epoch5, iter0, batch722/1133, batch loss:0.25146618485450745, Training time:17154.055381536484
batch reward last col mean 0.14356102049350739 first col mean 0.10078985244035721 all mean 0.1309387981891632
0.3334245979785919 0.3334245979785919
rl training, epoch5, iter0, batch723/1133, batch loss:0.3334245979785919, Training time:17155.682726621628
batch reward last col mean 0.08950170129537582 first col mean 0.10580144822597504 all mean 0.09722031652927399
0.2967318892478943 0.2967318892478943
rl training, epoch5, iter0, batch724/1133, batch loss:0.2967318892478943, Training time:17157.5518887043
batch reward last col mean 0.06781282275915146 first col mean 0.11495263874530792 all mean 0.07823187112808228
0.24521145224571228 0.24521145224571228
rl training, epoch5, iter0, batch725/1133, batch loss:0.24521145224571228, Training time:17159.515075922012
batch reward last col mean 0.11014650762081146 first col mean 0.10519099235534668 all mean 0.10428334027528763
0.26513075828552246 0.26513075828552246
rl training, epoch5, iter0, batch726/1133, batch loss:0.26513075828552246, Training time:17161.33929681778
batch reward last col mean 0.10264075547456741 first col mean 0.10885880887508392 all mean 0.10641710460186005
0.3464035391807556 0.3464035391807556
rl training, epoch5, iter0, batch727/1133, batch loss:0.3464035391807556, Training time:17163.379119873047
batch reward last col mean 0.11010690033435822 first col mean 0.11474227905273438 all mean 0.10839425772428513
0.28061628341674805 0.28061628341674805
rl training, epoch5, iter0, batch728/1133, batch loss:0.28061628341674805, Training time:17165.821346759796
batch reward last col mean 0.11543400585651398 first col mean 0.10269831120967865 all mean 0.10596632212400436
0.305390328168869 0.305390328168869
rl training, epoch5, iter0, batch729/1133, batch loss:0.305390328168869, Training time:17167.454084396362
batch reward last col mean 0.10426037013530731 first col mean 0.0948094055056572 all mean 0.1041659489274025
0.2645886540412903 0.2645886540412903
rl training, epoch5, iter0, batch730/1133, batch loss:0.2645886540412903, Training time:17169.705520629883
batch reward last col mean 0.10902106761932373 first col mean 0.09952464699745178 all mean 0.10990574210882187
0.3541393578052521 0.3541393578052521
rl training, epoch5, iter0, batch731/1133, batch loss:0.3541393578052521, Training time:17171.92294692993
batch reward last col mean 0.11486545205116272 first col mean 0.11297955363988876 all mean 0.110183946788311
0.2787257134914398 0.2787257134914398
rl training, epoch5, iter0, batch732/1133, batch loss:0.2787257134914398, Training time:17174.11680150032
batch reward last col mean 0.11325516551733017 first col mean 0.09946483373641968 all mean 0.11257282644510269
0.32031694054603577 0.32031694054603577
rl training, epoch5, iter0, batch733/1133, batch loss:0.32031694054603577, Training time:17175.96245932579
batch reward last col mean 0.11423413455486298 first col mean 0.09958364814519882 all mean 0.10941923409700394
0.27913710474967957 0.27913710474967957
rl training, epoch5, iter0, batch734/1133, batch loss:0.27913710474967957, Training time:17177.958607912064
batch reward last col mean 0.10584776103496552 first col mean 0.09968283772468567 all mean 0.1034521535038948
0.29365232586860657 0.2936522662639618
rl training, epoch5, iter0, batch735/1133, batch loss:0.2936522662639618, Training time:17179.75859260559
batch reward last col mean 0.12075507640838623 first col mean 0.1149745061993599 all mean 0.11668401956558228
0.30181407928466797 0.3018140494823456
rl training, epoch5, iter0, batch736/1133, batch loss:0.3018140494823456, Training time:17181.72040081024
batch reward last col mean 0.09631706029176712 first col mean 0.10685360431671143 all mean 0.09878484159708023
0.2867536246776581 0.2867536246776581
rl training, epoch5, iter0, batch737/1133, batch loss:0.2867536246776581, Training time:17183.26745533943
batch reward last col mean 0.10658697783946991 first col mean 0.10061223804950714 all mean 0.10361940413713455
0.3009677231311798 0.3009677231311798
rl training, epoch5, iter0, batch738/1133, batch loss:0.3009677231311798, Training time:17185.19957280159
batch reward last col mean 0.10177477449178696 first col mean 0.12014438211917877 all mean 0.1069352775812149
0.30181828141212463 0.30181828141212463
rl training, epoch5, iter0, batch739/1133, batch loss:0.30181828141212463, Training time:17187.566475391388
batch reward last col mean 0.12422744929790497 first col mean 0.11227701604366302 all mean 0.11907725036144257
0.3415846526622772 0.3415846526622772
rl training, epoch5, iter0, batch740/1133, batch loss:0.3415846526622772, Training time:17189.862039089203
batch reward last col mean 0.10452166944742203 first col mean 0.10870171338319778 all mean 0.10435416549444199
0.2902167737483978 0.2902167737483978
rl training, epoch5, iter0, batch741/1133, batch loss:0.2902167737483978, Training time:17191.877815246582
batch reward last col mean 0.11261001229286194 first col mean 0.1073165163397789 all mean 0.10990320891141891
0.30124929547309875 0.30124926567077637
rl training, epoch5, iter0, batch742/1133, batch loss:0.30124926567077637, Training time:17193.415355205536
batch reward last col mean 0.12080077826976776 first col mean 0.0953654795885086 all mean 0.11443755030632019
0.27835962176322937 0.278359591960907
rl training, epoch5, iter0, batch743/1133, batch loss:0.278359591960907, Training time:17195.505036830902
batch reward last col mean 0.11250640451908112 first col mean 0.10755541920661926 all mean 0.11822963505983353
0.32973533868789673 0.32973530888557434
rl training, epoch5, iter0, batch744/1133, batch loss:0.32973530888557434, Training time:17197.431894540787
batch reward last col mean 0.09465043246746063 first col mean 0.11126205325126648 all mean 0.09864411503076553
0.31686657667160034 0.31686657667160034
rl training, epoch5, iter0, batch745/1133, batch loss:0.31686657667160034, Training time:17199.50367474556
batch reward last col mean 0.11810752749443054 first col mean 0.11932834982872009 all mean 0.11663803458213806
0.29136648774147034 0.29136648774147034
rl training, epoch5, iter0, batch746/1133, batch loss:0.29136648774147034, Training time:17202.030729055405
batch reward last col mean 0.11714065819978714 first col mean 0.09795354306697845 all mean 0.11249645054340363
0.3175298273563385 0.3175298273563385
rl training, epoch5, iter0, batch747/1133, batch loss:0.3175298273563385, Training time:17203.92919611931
batch reward last col mean 0.07456928491592407 first col mean 0.11184582859277725 all mean 0.08124648034572601
0.26046982407569885 0.26046982407569885
rl training, epoch5, iter0, batch748/1133, batch loss:0.26046982407569885, Training time:17206.172942638397
batch reward last col mean 0.09371669590473175 first col mean 0.12058272957801819 all mean 0.09995049238204956
0.3149518370628357 0.3149518370628357
rl training, epoch5, iter0, batch749/1133, batch loss:0.3149518370628357, Training time:17207.965315580368
batch reward last col mean 0.09556543081998825 first col mean 0.11209062486886978 all mean 0.10373188555240631
0.3109457492828369 0.3109457492828369
rl training, epoch5, iter0, batch750/1133, batch loss:0.3109457492828369, Training time:17210.366388082504
batch reward last col mean 0.08555716276168823 first col mean 0.10344545543193817 all mean 0.08931823819875717
0.27442580461502075 0.27442580461502075
rl training, epoch5, iter0, batch751/1133, batch loss:0.27442580461502075, Training time:17212.74868607521
batch reward last col mean 0.07823449373245239 first col mean 0.1114562451839447 all mean 0.08333505690097809
0.30399057269096375 0.30399054288864136
rl training, epoch5, iter0, batch752/1133, batch loss:0.30399054288864136, Training time:17214.99782848358
batch reward last col mean 0.11243122816085815 first col mean 0.10809816420078278 all mean 0.10341349989175797
0.2799284756183624 0.2799284756183624
rl training, epoch5, iter0, batch753/1133, batch loss:0.2799284756183624, Training time:17217.6960208416
batch reward last col mean 0.10617958754301071 first col mean 0.10131043195724487 all mean 0.10370976477861404
0.3623984158039093 0.3623984158039093
rl training, epoch5, iter0, batch754/1133, batch loss:0.3623984158039093, Training time:17220.910026073456
batch reward last col mean 0.10939298570156097 first col mean 0.13056814670562744 all mean 0.11150842905044556
0.3519035279750824 0.3519035279750824
rl training, epoch5, iter0, batch755/1133, batch loss:0.3519035279750824, Training time:17223.86066365242
batch reward last col mean 0.09878859668970108 first col mean 0.11570429801940918 all mean 0.10192891955375671
0.28607919812202454 0.28607919812202454
rl training, epoch5, iter0, batch756/1133, batch loss:0.28607919812202454, Training time:17225.983343839645
batch reward last col mean 0.0909794270992279 first col mean 0.10768519341945648 all mean 0.09175123274326324
0.24697810411453247 0.24697810411453247
rl training, epoch5, iter0, batch757/1133, batch loss:0.24697810411453247, Training time:17227.882385969162
batch reward last col mean 0.12821835279464722 first col mean 0.11094224452972412 all mean 0.12093598395586014
0.3098287284374237 0.3098286986351013
rl training, epoch5, iter0, batch758/1133, batch loss:0.3098286986351013, Training time:17230.28376674652
batch reward last col mean 0.0990985557436943 first col mean 0.10507075488567352 all mean 0.11104750633239746
0.3266630172729492 0.3266630172729492
rl training, epoch5, iter0, batch759/1133, batch loss:0.3266630172729492, Training time:17232.250132083893
batch reward last col mean 0.09737472236156464 first col mean 0.11864451318979263 all mean 0.10174208134412766
0.280529648065567 0.280529648065567
rl training, epoch5, iter0, batch760/1133, batch loss:0.280529648065567, Training time:17233.995659589767
batch reward last col mean 0.12261791527271271 first col mean 0.10869091749191284 all mean 0.11632907390594482
0.2837309241294861 0.2837309241294861
rl training, epoch5, iter0, batch761/1133, batch loss:0.2837309241294861, Training time:17236.383850574493
batch reward last col mean 0.1033502146601677 first col mean 0.11439210921525955 all mean 0.1089956983923912
0.33130425214767456 0.3313041925430298
rl training, epoch5, iter0, batch762/1133, batch loss:0.3313041925430298, Training time:17238.461946725845
batch reward last col mean 0.11657743155956268 first col mean 0.11912969499826431 all mean 0.11383769661188126
0.30552083253860474 0.30552083253860474
rl training, epoch5, iter0, batch763/1133, batch loss:0.30552083253860474, Training time:17240.609602689743
batch reward last col mean 0.07643517851829529 first col mean 0.11414767056703568 all mean 0.08204253762960434
0.25021472573280334 0.25021472573280334
rl training, epoch5, iter0, batch764/1133, batch loss:0.25021472573280334, Training time:17242.532773971558
batch reward last col mean 0.12470363080501556 first col mean 0.11221496015787125 all mean 0.12140119075775146
0.3199193477630615 0.3199193477630615
rl training, epoch5, iter0, batch765/1133, batch loss:0.3199193477630615, Training time:17244.63532114029
batch reward last col mean 0.10255414247512817 first col mean 0.11710596084594727 all mean 0.10572647303342819
0.34670448303222656 0.34670448303222656
rl training, epoch5, iter0, batch766/1133, batch loss:0.34670448303222656, Training time:17247.105150699615
batch reward last col mean 0.09753337502479553 first col mean 0.10873018205165863 all mean 0.10928598791360855
0.3307949900627136 0.3307949900627136
rl training, epoch5, iter0, batch767/1133, batch loss:0.3307949900627136, Training time:17249.112542390823
batch reward last col mean 0.1133592277765274 first col mean 0.12055628001689911 all mean 0.11350240558385849
0.2760981023311615 0.2760981023311615
rl training, epoch5, iter0, batch768/1133, batch loss:0.2760981023311615, Training time:17251.142884731293
batch reward last col mean 0.0986262634396553 first col mean 0.12975019216537476 all mean 0.10666345059871674
0.29335758090019226 0.29335758090019226
rl training, epoch5, iter0, batch769/1133, batch loss:0.29335758090019226, Training time:17252.828421115875
batch reward last col mean 0.11178458482027054 first col mean 0.09583587199449539 all mean 0.1078043133020401
0.29919713735580444 0.29919710755348206
rl training, epoch5, iter0, batch770/1133, batch loss:0.29919710755348206, Training time:17254.652796030045
batch reward last col mean 0.11089839041233063 first col mean 0.10221081972122192 all mean 0.10882928967475891
0.30437493324279785 0.30437493324279785
rl training, epoch5, iter0, batch771/1133, batch loss:0.30437493324279785, Training time:17256.52847480774
batch reward last col mean 0.09877107292413712 first col mean 0.11005404591560364 all mean 0.10208156704902649
0.29587194323539734 0.29587191343307495
rl training, epoch5, iter0, batch772/1133, batch loss:0.29587191343307495, Training time:17258.324947595596
batch reward last col mean 0.07784828543663025 first col mean 0.09999249130487442 all mean 0.08617017418146133
0.2363852709531784 0.2363852560520172
rl training, epoch5, iter0, batch773/1133, batch loss:0.2363852560520172, Training time:17260.172936439514
batch reward last col mean 0.06530240178108215 first col mean 0.12104618549346924 all mean 0.07669048756361008
0.2737897038459778 0.2737897038459778
rl training, epoch5, iter0, batch774/1133, batch loss:0.2737897038459778, Training time:17262.60843229294
batch reward last col mean 0.10194994509220123 first col mean 0.10874597728252411 all mean 0.10158064216375351
0.27191659808158875 0.27191659808158875
rl training, epoch5, iter0, batch775/1133, batch loss:0.27191659808158875, Training time:17265.281452417374
batch reward last col mean 0.1122979074716568 first col mean 0.11295944452285767 all mean 0.11162635684013367
0.3078092336654663 0.3078092336654663
rl training, epoch5, iter0, batch776/1133, batch loss:0.3078092336654663, Training time:17267.594570159912
batch reward last col mean 0.10464581102132797 first col mean 0.10452178120613098 all mean 0.10381301492452621
0.29337286949157715 0.29337286949157715
rl training, epoch5, iter0, batch777/1133, batch loss:0.29337286949157715, Training time:17269.524273633957
batch reward last col mean 0.09649292379617691 first col mean 0.10598722100257874 all mean 0.10747372359037399
0.32653409242630005 0.32653409242630005
rl training, epoch5, iter0, batch778/1133, batch loss:0.32653409242630005, Training time:17271.674797058105
batch reward last col mean 0.07751952111721039 first col mean 0.10167500376701355 all mean 0.08720745146274567
0.2563561201095581 0.2563561201095581
rl training, epoch5, iter0, batch779/1133, batch loss:0.2563561201095581, Training time:17273.39362668991
batch reward last col mean 0.08623338490724564 first col mean 0.12223881483078003 all mean 0.09674534201622009
0.3070155382156372 0.3070155382156372
rl training, epoch5, iter0, batch780/1133, batch loss:0.3070155382156372, Training time:17275.456165075302
batch reward last col mean 0.1273268759250641 first col mean 0.10335740447044373 all mean 0.11827234923839569
0.2945961654186249 0.2945961654186249
rl training, epoch5, iter0, batch781/1133, batch loss:0.2945961654186249, Training time:17277.674862861633
batch reward last col mean 0.1149943470954895 first col mean 0.09445556998252869 all mean 0.11653952300548553
0.33488160371780396 0.33488160371780396
rl training, epoch5, iter0, batch782/1133, batch loss:0.33488160371780396, Training time:17279.77848815918
batch reward last col mean 0.11780720949172974 first col mean 0.11478705704212189 all mean 0.11280365288257599
0.28381842374801636 0.28381842374801636
rl training, epoch5, iter0, batch783/1133, batch loss:0.28381842374801636, Training time:17281.97772336006
batch reward last col mean 0.09322173148393631 first col mean 0.11306814104318619 all mean 0.09807740151882172
0.33909276127815247 0.33909276127815247
rl training, epoch5, iter0, batch784/1133, batch loss:0.33909276127815247, Training time:17284.388452768326
batch reward last col mean 0.08640781790018082 first col mean 0.10354430228471756 all mean 0.0895257517695427
0.2601648271083832 0.2601648271083832
rl training, epoch5, iter0, batch785/1133, batch loss:0.2601648271083832, Training time:17286.212646484375
batch reward last col mean 0.11752481758594513 first col mean 0.140855073928833 all mean 0.11577063798904419
0.33634868264198303 0.33634865283966064
rl training, epoch5, iter0, batch786/1133, batch loss:0.33634865283966064, Training time:17288.023452997208
batch reward last col mean 0.08500883728265762 first col mean 0.12479522824287415 all mean 0.0901171863079071
0.2530173063278198 0.2530173063278198
rl training, epoch5, iter0, batch787/1133, batch loss:0.2530173063278198, Training time:17289.85521006584
batch reward last col mean 0.0996241644024849 first col mean 0.10886260867118835 all mean 0.10056851804256439
0.29821324348449707 0.29821324348449707
rl training, epoch5, iter0, batch788/1133, batch loss:0.29821324348449707, Training time:17292.19271683693
batch reward last col mean 0.10931721329689026 first col mean 0.10460589081048965 all mean 0.11136747151613235
0.28085675835609436 0.28085675835609436
rl training, epoch5, iter0, batch789/1133, batch loss:0.28085675835609436, Training time:17294.19563794136
batch reward last col mean 0.12824717164039612 first col mean 0.1026528999209404 all mean 0.12215109169483185
0.35890424251556396 0.35890424251556396
rl training, epoch5, iter0, batch790/1133, batch loss:0.35890424251556396, Training time:17296.33492708206
batch reward last col mean 0.07985079288482666 first col mean 0.11793502420186996 all mean 0.08533529192209244
0.24000519514083862 0.24000521004199982
rl training, epoch5, iter0, batch791/1133, batch loss:0.24000521004199982, Training time:17298.337970495224
batch reward last col mean 0.10770247876644135 first col mean 0.12059296667575836 all mean 0.10863374173641205
0.3094121813774109 0.30941224098205566
rl training, epoch5, iter0, batch792/1133, batch loss:0.30941224098205566, Training time:17301.060697078705
batch reward last col mean 0.10215865075588226 first col mean 0.1206245869398117 all mean 0.09869687259197235
0.23532867431640625 0.23532867431640625
rl training, epoch5, iter0, batch793/1133, batch loss:0.23532867431640625, Training time:17303.17750310898
batch reward last col mean 0.09579934179782867 first col mean 0.1069045439362526 all mean 0.09650886058807373
0.27430734038352966 0.27430734038352966
rl training, epoch5, iter0, batch794/1133, batch loss:0.27430734038352966, Training time:17305.024775266647
batch reward last col mean 0.12996543943881989 first col mean 0.1125134527683258 all mean 0.12513718008995056
0.3000512421131134 0.300051212310791
rl training, epoch5, iter0, batch795/1133, batch loss:0.300051212310791, Training time:17308.072808265686
batch reward last col mean 0.08963411301374435 first col mean 0.10286667943000793 all mean 0.09458086639642715
0.26245757937431335 0.26245757937431335
rl training, epoch5, iter0, batch796/1133, batch loss:0.26245757937431335, Training time:17310.18364048004
batch reward last col mean 0.08397277444601059 first col mean 0.12191404402256012 all mean 0.09268661588430405
0.2718481123447418 0.2718481123447418
rl training, epoch5, iter0, batch797/1133, batch loss:0.2718481123447418, Training time:17313.131836891174
batch reward last col mean 0.10094232857227325 first col mean 0.10856414586305618 all mean 0.09946189820766449
0.29071950912475586 0.29071947932243347
rl training, epoch5, iter0, batch798/1133, batch loss:0.29071947932243347, Training time:17315.216459035873
batch reward last col mean 0.10861659049987793 first col mean 0.11338406056165695 all mean 0.10753742605447769
0.3053165674209595 0.3053165674209595
rl training, epoch5, iter0, batch799/1133, batch loss:0.3053165674209595, Training time:17317.483085870743
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4972804040637357 Time: 96.24521851539612 s
loss of true 0.2159447241755365 loss of gen 0.1812292867243974 loss of other 0.10010639360439219 first score 0.12740442156791687
batch reward last col mean 0.10557309538125992 first col mean 0.1019124761223793 all mean 0.10442116856575012
0.2413628250360489 0.24136285483837128
rl training, epoch5, iter0, batch800/1133, batch loss:0.24136285483837128, Training time:17415.520824193954
batch reward last col mean 0.09652146697044373 first col mean 0.1065610945224762 all mean 0.10233139246702194
0.2543025314807892 0.2543025314807892
rl training, epoch5, iter0, batch801/1133, batch loss:0.2543025314807892, Training time:17417.866864442825
batch reward last col mean 0.05249432474374771 first col mean 0.10764381289482117 all mean 0.06907917559146881
0.20747412741184235 0.20747412741184235
rl training, epoch5, iter0, batch802/1133, batch loss:0.20747412741184235, Training time:17419.497079372406
batch reward last col mean 0.06332032382488251 first col mean 0.1199333593249321 all mean 0.07285880297422409
0.20798875391483307 0.20798875391483307
rl training, epoch5, iter0, batch803/1133, batch loss:0.20798875391483307, Training time:17421.860186338425
batch reward last col mean 0.10070060193538666 first col mean 0.09384018182754517 all mean 0.10245228558778763
0.2547072768211365 0.25470730662345886
rl training, epoch5, iter0, batch804/1133, batch loss:0.25470730662345886, Training time:17423.942269563675
batch reward last col mean 0.10801985114812851 first col mean 0.10198564827442169 all mean 0.10370601713657379
0.2753371000289917 0.2753371000289917
rl training, epoch5, iter0, batch805/1133, batch loss:0.2753371000289917, Training time:17425.698944091797
batch reward last col mean 0.08273809403181076 first col mean 0.09753070026636124 all mean 0.0903056189417839
0.258352667093277 0.2583526372909546
rl training, epoch5, iter0, batch806/1133, batch loss:0.2583526372909546, Training time:17427.628709316254
batch reward last col mean 0.06835737079381943 first col mean 0.11842044442892075 all mean 0.07790419459342957
0.24281930923461914 0.24281930923461914
rl training, epoch5, iter0, batch807/1133, batch loss:0.24281930923461914, Training time:17429.749490261078
batch reward last col mean 0.08989319950342178 first col mean 0.10518553107976913 all mean 0.09205253422260284
0.25932207703590393 0.25932207703590393
rl training, epoch5, iter0, batch808/1133, batch loss:0.25932207703590393, Training time:17432.11651992798
batch reward last col mean 0.11653243005275726 first col mean 0.10015036165714264 all mean 0.11138180643320084
0.2757776975631714 0.2757776975631714
rl training, epoch5, iter0, batch809/1133, batch loss:0.2757776975631714, Training time:17434.33978176117
batch reward last col mean 0.08468684554100037 first col mean 0.09875528514385223 all mean 0.0887942686676979
0.2962900996208191 0.2962900996208191
rl training, epoch5, iter0, batch810/1133, batch loss:0.2962900996208191, Training time:17436.74613261223
batch reward last col mean 0.07283969223499298 first col mean 0.11046133935451508 all mean 0.07845009118318558
0.2536764442920685 0.2536764442920685
rl training, epoch5, iter0, batch811/1133, batch loss:0.2536764442920685, Training time:17439.87649989128
batch reward last col mean 0.1386672705411911 first col mean 0.10424387454986572 all mean 0.13418860733509064
0.33719030022621155 0.33719030022621155
rl training, epoch5, iter0, batch812/1133, batch loss:0.33719030022621155, Training time:17442.338104486465
batch reward last col mean 0.10979648679494858 first col mean 0.10313643515110016 all mean 0.11056853830814362
0.2978825271129608 0.2978825271129608
rl training, epoch5, iter0, batch813/1133, batch loss:0.2978825271129608, Training time:17444.189495801926
batch reward last col mean 0.09231410920619965 first col mean 0.13328281044960022 all mean 0.09827578067779541
0.2574741244316101 0.2574741244316101
rl training, epoch5, iter0, batch814/1133, batch loss:0.2574741244316101, Training time:17446.458765029907
batch reward last col mean 0.08632151037454605 first col mean 0.09802934527397156 all mean 0.09217387437820435
0.27464759349823 0.27464759349823
rl training, epoch5, iter0, batch815/1133, batch loss:0.27464759349823, Training time:17448.38459587097
batch reward last col mean 0.09911732375621796 first col mean 0.10291354358196259 all mean 0.0996486097574234
0.2582935094833374 0.2582935094833374
rl training, epoch5, iter0, batch816/1133, batch loss:0.2582935094833374, Training time:17450.633712768555
batch reward last col mean 0.11438226699829102 first col mean 0.09750919044017792 all mean 0.10870581120252609
0.2749403119087219 0.2749403119087219
rl training, epoch5, iter0, batch817/1133, batch loss:0.2749403119087219, Training time:17452.62374806404
batch reward last col mean 0.10256586223840714 first col mean 0.1008741706609726 all mean 0.10107804089784622
0.2568993866443634 0.2568993866443634
rl training, epoch5, iter0, batch818/1133, batch loss:0.2568993866443634, Training time:17454.725106954575
batch reward last col mean 0.1091059148311615 first col mean 0.10740042477846146 all mean 0.10523509234189987
0.2920319437980652 0.2920319437980652
rl training, epoch5, iter0, batch819/1133, batch loss:0.2920319437980652, Training time:17456.624975919724
batch reward last col mean 0.10358725488185883 first col mean 0.10705979913473129 all mean 0.10609695315361023
0.2661551535129547 0.2661551535129547
rl training, epoch5, iter0, batch820/1133, batch loss:0.2661551535129547, Training time:17459.90996479988
batch reward last col mean 0.07480496168136597 first col mean 0.09620936214923859 all mean 0.07955819368362427
0.26550057530403137 0.26550057530403137
rl training, epoch5, iter0, batch821/1133, batch loss:0.26550057530403137, Training time:17462.095606565475
batch reward last col mean 0.09444356709718704 first col mean 0.09495169669389725 all mean 0.09884418547153473
0.25998759269714355 0.25998759269714355
rl training, epoch5, iter0, batch822/1133, batch loss:0.25998759269714355, Training time:17463.70379781723
batch reward last col mean 0.1022094190120697 first col mean 0.10185853391885757 all mean 0.10397573560476303
0.24343658983707428 0.24343658983707428
rl training, epoch5, iter0, batch823/1133, batch loss:0.24343658983707428, Training time:17466.400539636612
batch reward last col mean 0.10544706881046295 first col mean 0.10390797257423401 all mean 0.10234204679727554
0.31020310521125793 0.31020310521125793
rl training, epoch5, iter0, batch824/1133, batch loss:0.31020310521125793, Training time:17469.304374456406
batch reward last col mean 0.09467357397079468 first col mean 0.09942229092121124 all mean 0.09805794060230255
0.2583940625190735 0.2583940625190735
rl training, epoch5, iter0, batch825/1133, batch loss:0.2583940625190735, Training time:17471.29372191429
batch reward last col mean 0.10547362267971039 first col mean 0.09793255478143692 all mean 0.10594170540571213
0.28557440638542175 0.28557440638542175
rl training, epoch5, iter0, batch826/1133, batch loss:0.28557440638542175, Training time:17473.02798128128
batch reward last col mean 0.15709784626960754 first col mean 0.10681142657995224 all mean 0.13807633519172668
0.34449803829193115 0.34449803829193115
rl training, epoch5, iter0, batch827/1133, batch loss:0.34449803829193115, Training time:17475.16556572914
batch reward last col mean 0.11299813538789749 first col mean 0.134755939245224 all mean 0.10772926360368729
0.3117743730545044 0.3117743730545044
rl training, epoch5, iter0, batch828/1133, batch loss:0.3117743730545044, Training time:17477.39262652397
batch reward last col mean 0.10380901396274567 first col mean 0.12438797950744629 all mean 0.10546298325061798
0.3033401072025299 0.3033401072025299
rl training, epoch5, iter0, batch829/1133, batch loss:0.3033401072025299, Training time:17479.710472106934
batch reward last col mean 0.08755439519882202 first col mean 0.1022309884428978 all mean 0.08961458504199982
0.24574153125286102 0.2457415610551834
rl training, epoch5, iter0, batch830/1133, batch loss:0.2457415610551834, Training time:17482.278220891953
batch reward last col mean 0.09811420738697052 first col mean 0.1074957400560379 all mean 0.10489744693040848
0.26481327414512634 0.26481327414512634
rl training, epoch5, iter0, batch831/1133, batch loss:0.26481327414512634, Training time:17484.017000198364
batch reward last col mean 0.07255825400352478 first col mean 0.0956314280629158 all mean 0.08266434073448181
0.28268003463745117 0.28268003463745117
rl training, epoch5, iter0, batch832/1133, batch loss:0.28268003463745117, Training time:17486.67843580246
batch reward last col mean 0.1025148332118988 first col mean 0.12364749610424042 all mean 0.10253039002418518
0.2885770797729492 0.2885770797729492
rl training, epoch5, iter0, batch833/1133, batch loss:0.2885770797729492, Training time:17488.895310401917
batch reward last col mean 0.14349547028541565 first col mean 0.13022328913211823 all mean 0.13672709465026855
0.2773478329181671 0.2773478329181671
rl training, epoch5, iter0, batch834/1133, batch loss:0.2773478329181671, Training time:17491.321778059006
batch reward last col mean 0.10756771266460419 first col mean 0.10434344410896301 all mean 0.10757216066122055
0.2581802010536194 0.2581802010536194
rl training, epoch5, iter0, batch835/1133, batch loss:0.2581802010536194, Training time:17493.700713157654
batch reward last col mean 0.09085233509540558 first col mean 0.07540960609912872 all mean 0.09936877340078354
0.29405906796455383 0.29405906796455383
rl training, epoch5, iter0, batch836/1133, batch loss:0.29405906796455383, Training time:17495.580224752426
batch reward last col mean 0.07697278261184692 first col mean 0.11085760593414307 all mean 0.08932161331176758
0.24775640666484833 0.24775640666484833
rl training, epoch5, iter0, batch837/1133, batch loss:0.24775640666484833, Training time:17497.559776067734
batch reward last col mean 0.12006006389856339 first col mean 0.09788525849580765 all mean 0.11744668334722519
0.28263089060783386 0.28263089060783386
rl training, epoch5, iter0, batch838/1133, batch loss:0.28263089060783386, Training time:17499.50048327446
batch reward last col mean 0.09332746267318726 first col mean 0.10965064913034439 all mean 0.0989006981253624
0.24951305985450745 0.24951305985450745
rl training, epoch5, iter0, batch839/1133, batch loss:0.24951305985450745, Training time:17501.523310899734
batch reward last col mean 0.11204539984464645 first col mean 0.10367405414581299 all mean 0.11011632531881332
0.2572769522666931 0.2572769522666931
rl training, epoch5, iter0, batch840/1133, batch loss:0.2572769522666931, Training time:17503.630520105362
batch reward last col mean 0.08134113252162933 first col mean 0.09572778642177582 all mean 0.0861530750989914
0.2577011287212372 0.2577011287212372
rl training, epoch5, iter0, batch841/1133, batch loss:0.2577011287212372, Training time:17505.720090150833
batch reward last col mean 0.1250237673521042 first col mean 0.1061839684844017 all mean 0.11824966967105865
0.3271661698818207 0.3271661698818207
rl training, epoch5, iter0, batch842/1133, batch loss:0.3271661698818207, Training time:17508.752023220062
batch reward last col mean 0.08224008977413177 first col mean 0.1019277572631836 all mean 0.09005510807037354
0.2838513255119324 0.2838513255119324
rl training, epoch5, iter0, batch843/1133, batch loss:0.2838513255119324, Training time:17511.028240203857
batch reward last col mean 0.08567145466804504 first col mean 0.12027432024478912 all mean 0.08725479990243912
0.32543233036994934 0.32543233036994934
rl training, epoch5, iter0, batch844/1133, batch loss:0.32543233036994934, Training time:17513.683277130127
batch reward last col mean 0.10903240740299225 first col mean 0.121663898229599 all mean 0.11441997438669205
0.31525060534477234 0.31525060534477234
rl training, epoch5, iter0, batch845/1133, batch loss:0.31525060534477234, Training time:17515.306654453278
batch reward last col mean 0.122703418135643 first col mean 0.09117892384529114 all mean 0.11497228592634201
0.27339914441108704 0.27339914441108704
rl training, epoch5, iter0, batch846/1133, batch loss:0.27339914441108704, Training time:17517.07421374321
batch reward last col mean 0.08744598925113678 first col mean 0.10638856142759323 all mean 0.09154173731803894
0.2847093343734741 0.2847093343734741
rl training, epoch5, iter0, batch847/1133, batch loss:0.2847093343734741, Training time:17519.303557157516
batch reward last col mean 0.12270592153072357 first col mean 0.11424113810062408 all mean 0.11663739383220673
0.28464382886886597 0.28464382886886597
rl training, epoch5, iter0, batch848/1133, batch loss:0.28464382886886597, Training time:17520.978987455368
batch reward last col mean 0.08561192452907562 first col mean 0.08216417580842972 all mean 0.08951598405838013
0.23646172881126404 0.23646172881126404
rl training, epoch5, iter0, batch849/1133, batch loss:0.23646172881126404, Training time:17522.68100118637
batch reward last col mean 0.12924185395240784 first col mean 0.11666810512542725 all mean 0.121220164000988
0.286091685295105 0.286091685295105
rl training, epoch5, iter0, batch850/1133, batch loss:0.286091685295105, Training time:17525.069986343384
batch reward last col mean 0.08650229871273041 first col mean 0.11462242901325226 all mean 0.10007262974977493
0.26851290464401245 0.26851287484169006
rl training, epoch5, iter0, batch851/1133, batch loss:0.26851287484169006, Training time:17526.88579750061
batch reward last col mean 0.08956217765808105 first col mean 0.11558793485164642 all mean 0.0998975932598114
0.28913769125938416 0.28913769125938416
rl training, epoch5, iter0, batch852/1133, batch loss:0.28913769125938416, Training time:17529.073140144348
batch reward last col mean 0.12167207896709442 first col mean 0.10411213338375092 all mean 0.11741573363542557
0.30519697070121765 0.30519697070121765
rl training, epoch5, iter0, batch853/1133, batch loss:0.30519697070121765, Training time:17531.174501419067
batch reward last col mean 0.11093109846115112 first col mean 0.09510985016822815 all mean 0.1092822477221489
0.293637216091156 0.293637216091156
rl training, epoch5, iter0, batch854/1133, batch loss:0.293637216091156, Training time:17533.668741703033
batch reward last col mean 0.11365380883216858 first col mean 0.1135060042142868 all mean 0.11218582838773727
0.29067423939704895 0.29067423939704895
rl training, epoch5, iter0, batch855/1133, batch loss:0.29067423939704895, Training time:17535.364270448685
batch reward last col mean 0.09069492667913437 first col mean 0.11801185458898544 all mean 0.0951518639922142
0.2676152288913727 0.2676152288913727
rl training, epoch5, iter0, batch856/1133, batch loss:0.2676152288913727, Training time:17537.396499872208
batch reward last col mean 0.1257370263338089 first col mean 0.10048004984855652 all mean 0.11369524151086807
0.29006919264793396 0.2900691628456116
rl training, epoch5, iter0, batch857/1133, batch loss:0.2900691628456116, Training time:17539.37371778488
batch reward last col mean 0.1146019995212555 first col mean 0.10073700547218323 all mean 0.11345705389976501
0.29808104038238525 0.29808104038238525
rl training, epoch5, iter0, batch858/1133, batch loss:0.29808104038238525, Training time:17541.32340860367
batch reward last col mean 0.09058228135108948 first col mean 0.1071312353014946 all mean 0.09808918833732605
0.2614249885082245 0.2614249885082245
rl training, epoch5, iter0, batch859/1133, batch loss:0.2614249885082245, Training time:17543.435111761093
batch reward last col mean 0.0855952575802803 first col mean 0.09421512484550476 all mean 0.08875062316656113
0.24616555869579315 0.24616555869579315
rl training, epoch5, iter0, batch860/1133, batch loss:0.24616555869579315, Training time:17545.461082220078
batch reward last col mean 0.146693617105484 first col mean 0.10738329589366913 all mean 0.13776333630084991
0.31997987627983093 0.31997987627983093
rl training, epoch5, iter0, batch861/1133, batch loss:0.31997987627983093, Training time:17547.719791650772
batch reward last col mean 0.10792051255702972 first col mean 0.10112032294273376 all mean 0.10785922408103943
0.2677709758281708 0.2677709758281708
rl training, epoch5, iter0, batch862/1133, batch loss:0.2677709758281708, Training time:17549.349972248077
batch reward last col mean 0.11348520219326019 first col mean 0.11243411898612976 all mean 0.10783957690000534
0.31817537546157837 0.31817537546157837
rl training, epoch5, iter0, batch863/1133, batch loss:0.31817537546157837, Training time:17551.23740053177
batch reward last col mean 0.10152262449264526 first col mean 0.10088519752025604 all mean 0.10257235914468765
0.2685680091381073 0.2685680091381073
rl training, epoch5, iter0, batch864/1133, batch loss:0.2685680091381073, Training time:17552.883588790894
batch reward last col mean 0.08203881978988647 first col mean 0.10379593074321747 all mean 0.08582469820976257
0.26756057143211365 0.26756051182746887
rl training, epoch5, iter0, batch865/1133, batch loss:0.26756051182746887, Training time:17555.418981075287
batch reward last col mean 0.15094150602817535 first col mean 0.12399158626794815 all mean 0.14076144993305206
0.34759315848350525 0.34759315848350525
rl training, epoch5, iter0, batch866/1133, batch loss:0.34759315848350525, Training time:17557.81181383133
batch reward last col mean 0.07568977773189545 first col mean 0.09977196156978607 all mean 0.08385256677865982
0.2614043951034546 0.2614043653011322
rl training, epoch5, iter0, batch867/1133, batch loss:0.2614043653011322, Training time:17559.67068362236
batch reward last col mean 0.09319241344928741 first col mean 0.10762138664722443 all mean 0.09546087682247162
0.28042376041412354 0.28042373061180115
rl training, epoch5, iter0, batch868/1133, batch loss:0.28042373061180115, Training time:17561.797703266144
batch reward last col mean 0.11310242116451263 first col mean 0.1130686029791832 all mean 0.11345648020505905
0.2776293158531189 0.2776293456554413
rl training, epoch5, iter0, batch869/1133, batch loss:0.2776293456554413, Training time:17563.730309963226
batch reward last col mean 0.08048206567764282 first col mean 0.11468781530857086 all mean 0.09136182814836502
0.30458733439445496 0.30458733439445496
rl training, epoch5, iter0, batch870/1133, batch loss:0.30458733439445496, Training time:17566.186955690384
batch reward last col mean 0.10367514193058014 first col mean 0.12185925245285034 all mean 0.10914730280637741
0.3200763165950775 0.3200763165950775
rl training, epoch5, iter0, batch871/1133, batch loss:0.3200763165950775, Training time:17568.05416417122
batch reward last col mean 0.09890765696763992 first col mean 0.10225595533847809 all mean 0.09897883236408234
0.2981985807418823 0.2981985807418823
rl training, epoch5, iter0, batch872/1133, batch loss:0.2981985807418823, Training time:17570.215834379196
batch reward last col mean 0.12959778308868408 first col mean 0.10574276745319366 all mean 0.11914099752902985
0.31401246786117554 0.31401246786117554
rl training, epoch5, iter0, batch873/1133, batch loss:0.31401246786117554, Training time:17572.12903189659
batch reward last col mean 0.11106368899345398 first col mean 0.10759131610393524 all mean 0.11127915233373642
0.29680168628692627 0.29680168628692627
rl training, epoch5, iter0, batch874/1133, batch loss:0.29680168628692627, Training time:17574.668664693832
batch reward last col mean 0.09617168456315994 first col mean 0.1370757520198822 all mean 0.10089276731014252
0.2768464982509613 0.2768464982509613
rl training, epoch5, iter0, batch875/1133, batch loss:0.2768464982509613, Training time:17577.022119283676
batch reward last col mean 0.0992613434791565 first col mean 0.09601770341396332 all mean 0.10495664179325104
0.27603867650032043 0.27603864669799805
rl training, epoch5, iter0, batch876/1133, batch loss:0.27603864669799805, Training time:17578.67169237137
batch reward last col mean 0.12055548280477524 first col mean 0.11209193617105484 all mean 0.1188446655869484
0.31783661246299744 0.31783661246299744
rl training, epoch5, iter0, batch877/1133, batch loss:0.31783661246299744, Training time:17581.062581539154
batch reward last col mean 0.10387466847896576 first col mean 0.09627099335193634 all mean 0.0989854633808136
0.2933926582336426 0.2933926582336426
rl training, epoch5, iter0, batch878/1133, batch loss:0.2933926582336426, Training time:17583.40323615074
batch reward last col mean 0.14007939398288727 first col mean 0.11485739797353745 all mean 0.13288475573062897
0.2993321418762207 0.2993321418762207
rl training, epoch5, iter0, batch879/1133, batch loss:0.2993321418762207, Training time:17585.643171310425
batch reward last col mean 0.13185575604438782 first col mean 0.11473804712295532 all mean 0.1252828687429428
0.33682772517204285 0.33682772517204285
rl training, epoch5, iter0, batch880/1133, batch loss:0.33682772517204285, Training time:17587.422377347946
batch reward last col mean 0.07725920528173447 first col mean 0.10558590292930603 all mean 0.08709989488124847
0.26369500160217285 0.26369500160217285
rl training, epoch5, iter0, batch881/1133, batch loss:0.26369500160217285, Training time:17589.23109936714
batch reward last col mean 0.12185726314783096 first col mean 0.11811117827892303 all mean 0.12209615856409073
0.3431781828403473 0.3431781828403473
rl training, epoch5, iter0, batch882/1133, batch loss:0.3431781828403473, Training time:17590.9236536026
batch reward last col mean 0.1213417798280716 first col mean 0.10929632186889648 all mean 0.11930081993341446
0.27243879437446594 0.27243879437446594
rl training, epoch5, iter0, batch883/1133, batch loss:0.27243879437446594, Training time:17592.90327835083
batch reward last col mean 0.10072766244411469 first col mean 0.12790755927562714 all mean 0.11007356643676758
0.31934186816215515 0.31934186816215515
rl training, epoch5, iter0, batch884/1133, batch loss:0.31934186816215515, Training time:17595.083540201187
batch reward last col mean 0.16465605795383453 first col mean 0.12686873972415924 all mean 0.14715556800365448
0.3508475720882416 0.3508475720882416
rl training, epoch5, iter0, batch885/1133, batch loss:0.3508475720882416, Training time:17596.67706012726
batch reward last col mean 0.09037964046001434 first col mean 0.11006230115890503 all mean 0.09529948234558105
0.2612147629261017 0.2612147629261017
rl training, epoch5, iter0, batch886/1133, batch loss:0.2612147629261017, Training time:17599.136637687683
batch reward last col mean 0.09748685359954834 first col mean 0.11783440411090851 all mean 0.10427291691303253
0.29108768701553345 0.29108768701553345
rl training, epoch5, iter0, batch887/1133, batch loss:0.29108768701553345, Training time:17601.72019648552
batch reward last col mean 0.11109042167663574 first col mean 0.1017824038863182 all mean 0.10969424992799759
0.2930566072463989 0.29305657744407654
rl training, epoch5, iter0, batch888/1133, batch loss:0.29305657744407654, Training time:17603.641130447388
batch reward last col mean 0.07332576811313629 first col mean 0.09866040199995041 all mean 0.08263044059276581
0.273913711309433 0.273913711309433
rl training, epoch5, iter0, batch889/1133, batch loss:0.273913711309433, Training time:17605.8688249588
batch reward last col mean 0.0944032073020935 first col mean 0.10365582257509232 all mean 0.10033246874809265
0.3041577935218811 0.3041577637195587
rl training, epoch5, iter0, batch890/1133, batch loss:0.3041577637195587, Training time:17608.10675907135
batch reward last col mean 0.11874072998762131 first col mean 0.1097906231880188 all mean 0.11384186148643494
0.277715265750885 0.277715265750885
rl training, epoch5, iter0, batch891/1133, batch loss:0.277715265750885, Training time:17610.320368766785
batch reward last col mean 0.11856606602668762 first col mean 0.11592665314674377 all mean 0.1126706451177597
0.262803852558136 0.262803852558136
rl training, epoch5, iter0, batch892/1133, batch loss:0.262803852558136, Training time:17612.06304359436
batch reward last col mean 0.11545798182487488 first col mean 0.11920317262411118 all mean 0.12055286020040512
0.35947275161743164 0.35947275161743164
rl training, epoch5, iter0, batch893/1133, batch loss:0.35947275161743164, Training time:17614.067650794983
batch reward last col mean 0.12159387767314911 first col mean 0.11334247887134552 all mean 0.1199350506067276
0.33870944380760193 0.33870944380760193
rl training, epoch5, iter0, batch894/1133, batch loss:0.33870944380760193, Training time:17615.61647462845
batch reward last col mean 0.10428424924612045 first col mean 0.09682685881853104 all mean 0.10737482458353043
0.27004048228263855 0.27004048228263855
rl training, epoch5, iter0, batch895/1133, batch loss:0.27004048228263855, Training time:17617.81981754303
batch reward last col mean 0.10822427272796631 first col mean 0.1296526938676834 all mean 0.1170586347579956
0.31342145800590515 0.31342145800590515
rl training, epoch5, iter0, batch896/1133, batch loss:0.31342145800590515, Training time:17619.517934322357
batch reward last col mean 0.13838952779769897 first col mean 0.11964137852191925 all mean 0.12693481147289276
0.30800536274909973 0.30800536274909973
rl training, epoch5, iter0, batch897/1133, batch loss:0.30800536274909973, Training time:17621.409614801407
batch reward last col mean 0.11456143856048584 first col mean 0.10515983402729034 all mean 0.11941216140985489
0.2757795453071594 0.2757795453071594
rl training, epoch5, iter0, batch898/1133, batch loss:0.2757795453071594, Training time:17623.11252593994
batch reward last col mean 0.12111818790435791 first col mean 0.11532798409461975 all mean 0.12041308730840683
0.31480759382247925 0.31480759382247925
rl training, epoch5, iter0, batch899/1133, batch loss:0.31480759382247925, Training time:17624.5194606781
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.497280718027125 Time: 95.43898844718933 s
loss of true 0.21703597314044215 loss of gen 0.18018756934424365 loss of other 0.10005717604056935 first score 0.11208654940128326
batch reward last col mean 0.08891147375106812 first col mean 0.11757691949605942 all mean 0.09765444695949554
0.28704386949539185 0.28704383969306946
rl training, epoch5, iter0, batch900/1133, batch loss:0.28704383969306946, Training time:17721.702276468277
batch reward last col mean 0.09547227621078491 first col mean 0.09737242758274078 all mean 0.09705241769552231
0.2769390046596527 0.2769390046596527
rl training, epoch5, iter0, batch901/1133, batch loss:0.2769390046596527, Training time:17723.457964897156
batch reward last col mean 0.08025284111499786 first col mean 0.10342773795127869 all mean 0.08487987518310547
0.25480106472969055 0.25480106472969055
rl training, epoch5, iter0, batch902/1133, batch loss:0.25480106472969055, Training time:17725.803258895874
batch reward last col mean 0.08308228105306625 first col mean 0.11255066096782684 all mean 0.09293095022439957
0.26221582293510437 0.26221582293510437
rl training, epoch5, iter0, batch903/1133, batch loss:0.26221582293510437, Training time:17727.294514894485
batch reward last col mean 0.1215294897556305 first col mean 0.10447356849908829 all mean 0.11818449944257736
0.2779482305049896 0.2779482305049896
rl training, epoch5, iter0, batch904/1133, batch loss:0.2779482305049896, Training time:17729.27615404129
batch reward last col mean 0.07206814736127853 first col mean 0.11160451918840408 all mean 0.08798252791166306
0.2918725907802582 0.2918725907802582
rl training, epoch5, iter0, batch905/1133, batch loss:0.2918725907802582, Training time:17730.871281147003
batch reward last col mean 0.09894264489412308 first col mean 0.10069996863603592 all mean 0.10335923731327057
0.26672250032424927 0.26672250032424927
rl training, epoch5, iter0, batch906/1133, batch loss:0.26672250032424927, Training time:17732.906148195267
batch reward last col mean 0.11635331809520721 first col mean 0.10967188328504562 all mean 0.11307582259178162
0.31790268421173096 0.31790271401405334
rl training, epoch5, iter0, batch907/1133, batch loss:0.31790271401405334, Training time:17734.71599841118
batch reward last col mean 0.10729999840259552 first col mean 0.10343773663043976 all mean 0.10872648656368256
0.30006563663482666 0.30006563663482666
rl training, epoch5, iter0, batch908/1133, batch loss:0.30006563663482666, Training time:17736.565860271454
batch reward last col mean 0.12941759824752808 first col mean 0.10728579014539719 all mean 0.11906181275844574
0.2890969216823578 0.2890969514846802
rl training, epoch5, iter0, batch909/1133, batch loss:0.2890969514846802, Training time:17738.398223638535
batch reward last col mean 0.10929109156131744 first col mean 0.08891173452138901 all mean 0.10559369623661041
0.27531543374061584 0.27531543374061584
rl training, epoch5, iter0, batch910/1133, batch loss:0.27531543374061584, Training time:17740.289716005325
batch reward last col mean 0.0697089284658432 first col mean 0.1178237721323967 all mean 0.07635630667209625
0.26266923546791077 0.26266923546791077
rl training, epoch5, iter0, batch911/1133, batch loss:0.26266923546791077, Training time:17742.563742399216
batch reward last col mean 0.11769565939903259 first col mean 0.12084309011697769 all mean 0.11413917690515518
0.2783089876174927 0.27830901741981506
rl training, epoch5, iter0, batch912/1133, batch loss:0.27830901741981506, Training time:17744.198286771774
batch reward last col mean 0.12190253287553787 first col mean 0.09874171018600464 all mean 0.11892236024141312
0.3320567011833191 0.3320566713809967
rl training, epoch5, iter0, batch913/1133, batch loss:0.3320566713809967, Training time:17746.062271356583
batch reward last col mean 0.1102176234126091 first col mean 0.09446726739406586 all mean 0.11035425961017609
0.28754040598869324 0.28754040598869324
rl training, epoch5, iter0, batch914/1133, batch loss:0.28754040598869324, Training time:17748.426289319992
batch reward last col mean 0.09114252030849457 first col mean 0.10567653924226761 all mean 0.09377047419548035
0.3043689429759979 0.3043689429759979
rl training, epoch5, iter0, batch915/1133, batch loss:0.3043689429759979, Training time:17750.3097178936
batch reward last col mean 0.08295004069805145 first col mean 0.08596684783697128 all mean 0.09682448953390121
0.3192155063152313 0.3192155063152313
rl training, epoch5, iter0, batch916/1133, batch loss:0.3192155063152313, Training time:17752.008986473083
batch reward last col mean 0.10273197293281555 first col mean 0.11011236906051636 all mean 0.10824072360992432
0.3144921362400055 0.3144921362400055
rl training, epoch5, iter0, batch917/1133, batch loss:0.3144921362400055, Training time:17753.82650089264
batch reward last col mean 0.13363175094127655 first col mean 0.11536089330911636 all mean 0.1198987364768982
0.31838706135749817 0.31838706135749817
rl training, epoch5, iter0, batch918/1133, batch loss:0.31838706135749817, Training time:17755.52102994919
batch reward last col mean 0.1289915293455124 first col mean 0.1034114807844162 all mean 0.11908434331417084
0.2942318022251129 0.2942318022251129
rl training, epoch5, iter0, batch919/1133, batch loss:0.2942318022251129, Training time:17757.094514131546
batch reward last col mean 0.09521251916885376 first col mean 0.12351013720035553 all mean 0.09432801604270935
0.28785282373428345 0.28785279393196106
rl training, epoch5, iter0, batch920/1133, batch loss:0.28785279393196106, Training time:17758.90150165558
batch reward last col mean 0.09706727415323257 first col mean 0.09322167187929153 all mean 0.10566797852516174
0.30675169825553894 0.30675166845321655
rl training, epoch5, iter0, batch921/1133, batch loss:0.30675166845321655, Training time:17760.68822336197
batch reward last col mean 0.09750635176897049 first col mean 0.12420782446861267 all mean 0.09620588272809982
0.2913247346878052 0.2913247346878052
rl training, epoch5, iter0, batch922/1133, batch loss:0.2913247346878052, Training time:17762.543155431747
batch reward last col mean 0.12043756991624832 first col mean 0.12196968495845795 all mean 0.11982043087482452
0.3236439526081085 0.3236439526081085
rl training, epoch5, iter0, batch923/1133, batch loss:0.3236439526081085, Training time:17764.00184559822
batch reward last col mean 0.10363802313804626 first col mean 0.11723113059997559 all mean 0.10972156375646591
0.31501996517181396 0.31501996517181396
rl training, epoch5, iter0, batch924/1133, batch loss:0.31501996517181396, Training time:17765.82210946083
batch reward last col mean 0.11276949942111969 first col mean 0.10505132377147675 all mean 0.11157899349927902
0.29083555936813354 0.29083555936813354
rl training, epoch5, iter0, batch925/1133, batch loss:0.29083555936813354, Training time:17767.674072027206
batch reward last col mean 0.07675100117921829 first col mean 0.08560673147439957 all mean 0.0882556289434433
0.2799886465072632 0.2799886465072632
rl training, epoch5, iter0, batch926/1133, batch loss:0.2799886465072632, Training time:17769.450970172882
batch reward last col mean 0.11777941882610321 first col mean 0.10508577525615692 all mean 0.10900954902172089
0.29977643489837646 0.29977643489837646
rl training, epoch5, iter0, batch927/1133, batch loss:0.29977643489837646, Training time:17771.328553199768
batch reward last col mean 0.06443329155445099 first col mean 0.10120008140802383 all mean 0.07571714371442795
0.26812490820884705 0.26812490820884705
rl training, epoch5, iter0, batch928/1133, batch loss:0.26812490820884705, Training time:17773.074337244034
batch reward last col mean 0.08520057797431946 first col mean 0.10905278474092484 all mean 0.08218346536159515
0.29368144273757935 0.29368141293525696
rl training, epoch5, iter0, batch929/1133, batch loss:0.29368141293525696, Training time:17775.03385782242
batch reward last col mean 0.09487064182758331 first col mean 0.09850866347551346 all mean 0.0896620899438858
0.24232348799705505 0.24232348799705505
rl training, epoch5, iter0, batch930/1133, batch loss:0.24232348799705505, Training time:17777.46051979065
batch reward last col mean 0.11776947230100632 first col mean 0.10463276505470276 all mean 0.1082577109336853
0.2718392014503479 0.2718391716480255
rl training, epoch5, iter0, batch931/1133, batch loss:0.2718391716480255, Training time:17779.086724996567
batch reward last col mean 0.10514730215072632 first col mean 0.12971162796020508 all mean 0.1013634204864502
0.2908453047275543 0.2908453047275543
rl training, epoch5, iter0, batch932/1133, batch loss:0.2908453047275543, Training time:17780.645017147064
batch reward last col mean 0.12343398481607437 first col mean 0.10791635513305664 all mean 0.11759648472070694
0.3551301658153534 0.3551301062107086
rl training, epoch5, iter0, batch933/1133, batch loss:0.3551301062107086, Training time:17782.471410274506
batch reward last col mean 0.09585603326559067 first col mean 0.12349681556224823 all mean 0.09909520298242569
0.292088121175766 0.292088121175766
rl training, epoch5, iter0, batch934/1133, batch loss:0.292088121175766, Training time:17784.024567604065
batch reward last col mean 0.10444511473178864 first col mean 0.09815260767936707 all mean 0.10674363374710083
0.30110612511634827 0.30110612511634827
rl training, epoch5, iter0, batch935/1133, batch loss:0.30110612511634827, Training time:17785.864089250565
batch reward last col mean 0.09154585748910904 first col mean 0.10260745882987976 all mean 0.0955556184053421
0.25138071179389954 0.25138071179389954
rl training, epoch5, iter0, batch936/1133, batch loss:0.25138071179389954, Training time:17787.474873781204
batch reward last col mean 0.10442698001861572 first col mean 0.1197451651096344 all mean 0.10934409499168396
0.29381003975868225 0.29381003975868225
rl training, epoch5, iter0, batch937/1133, batch loss:0.29381003975868225, Training time:17789.269745349884
batch reward last col mean 0.08198529481887817 first col mean 0.12048687785863876 all mean 0.09252897650003433
0.3148873448371887 0.3148873746395111
rl training, epoch5, iter0, batch938/1133, batch loss:0.3148873746395111, Training time:17790.718879699707
batch reward last col mean 0.07254163175821304 first col mean 0.11134152114391327 all mean 0.08643054962158203
0.27345800399780273 0.27345800399780273
rl training, epoch5, iter0, batch939/1133, batch loss:0.27345800399780273, Training time:17792.18886590004
batch reward last col mean 0.0902329534292221 first col mean 0.10950086265802383 all mean 0.09410852938890457
0.2734717130661011 0.2734717130661011
rl training, epoch5, iter0, batch940/1133, batch loss:0.2734717130661011, Training time:17794.02237010002
batch reward last col mean 0.12496139854192734 first col mean 0.12329798936843872 all mean 0.12363750487565994
0.3344120383262634 0.3344120383262634
rl training, epoch5, iter0, batch941/1133, batch loss:0.3344120383262634, Training time:17796.126173734665
batch reward last col mean 0.09266388416290283 first col mean 0.09327270090579987 all mean 0.0966784656047821
0.27293670177459717 0.27293670177459717
rl training, epoch5, iter0, batch942/1133, batch loss:0.27293670177459717, Training time:17797.568665981293
batch reward last col mean 0.10150077939033508 first col mean 0.11713680624961853 all mean 0.10505163669586182
0.2929711639881134 0.292971134185791
rl training, epoch5, iter0, batch943/1133, batch loss:0.292971134185791, Training time:17799.429108142853
batch reward last col mean 0.09767454862594604 first col mean 0.10378412902355194 all mean 0.0933174267411232
0.2642439603805542 0.2642439603805542
rl training, epoch5, iter0, batch944/1133, batch loss:0.2642439603805542, Training time:17800.855694055557
batch reward last col mean 0.07213375717401505 first col mean 0.1050729751586914 all mean 0.07713853567838669
0.2743498682975769 0.2743498682975769
rl training, epoch5, iter0, batch945/1133, batch loss:0.2743498682975769, Training time:17803.15416574478
batch reward last col mean 0.09691457450389862 first col mean 0.10802001506090164 all mean 0.10011615604162216
0.3120321035385132 0.3120320439338684
rl training, epoch5, iter0, batch946/1133, batch loss:0.3120320439338684, Training time:17805.156224012375
batch reward last col mean 0.11161111295223236 first col mean 0.09798921644687653 all mean 0.1072007268667221
0.2796608805656433 0.2796608805656433
rl training, epoch5, iter0, batch947/1133, batch loss:0.2796608805656433, Training time:17807.551951646805
batch reward last col mean 0.11958923935890198 first col mean 0.10194195806980133 all mean 0.11651356518268585
0.29682496190071106 0.29682496190071106
rl training, epoch5, iter0, batch948/1133, batch loss:0.29682496190071106, Training time:17809.662543058395
batch reward last col mean 0.07461860030889511 first col mean 0.10998412221670151 all mean 0.0850687325000763
0.2849740982055664 0.2849740982055664
rl training, epoch5, iter0, batch949/1133, batch loss:0.2849740982055664, Training time:17811.717198371887
batch reward last col mean 0.09045799821615219 first col mean 0.09202609211206436 all mean 0.09511971473693848
0.27059510350227356 0.27059510350227356
rl training, epoch5, iter0, batch950/1133, batch loss:0.27059510350227356, Training time:17813.697703123093
batch reward last col mean 0.09883818030357361 first col mean 0.10232551395893097 all mean 0.10112223774194717
0.33238333463668823 0.33238333463668823
rl training, epoch5, iter0, batch951/1133, batch loss:0.33238333463668823, Training time:17815.630488872528
batch reward last col mean 0.15414637327194214 first col mean 0.10878019779920578 all mean 0.133214071393013
0.34540706872940063 0.34540706872940063
rl training, epoch5, iter0, batch952/1133, batch loss:0.34540706872940063, Training time:17817.556064367294
batch reward last col mean 0.12844470143318176 first col mean 0.12373277544975281 all mean 0.12589441239833832
0.33780860900878906 0.33780860900878906
rl training, epoch5, iter0, batch953/1133, batch loss:0.33780860900878906, Training time:17819.52407360077
batch reward last col mean 0.09931062161922455 first col mean 0.09685835242271423 all mean 0.10707804560661316
0.30355730652809143 0.30355730652809143
rl training, epoch5, iter0, batch954/1133, batch loss:0.30355730652809143, Training time:17821.52210998535
batch reward last col mean 0.08918626606464386 first col mean 0.11867140233516693 all mean 0.09408454596996307
0.3024235963821411 0.3024235665798187
rl training, epoch5, iter0, batch955/1133, batch loss:0.3024235665798187, Training time:17823.73953962326
batch reward last col mean 0.09441991150379181 first col mean 0.10795172303915024 all mean 0.09912697225809097
0.29683300852775574 0.29683300852775574
rl training, epoch5, iter0, batch956/1133, batch loss:0.29683300852775574, Training time:17825.3208963871
batch reward last col mean 0.11623109877109528 first col mean 0.1027769148349762 all mean 0.11166620999574661
0.3107510209083557 0.3107510209083557
rl training, epoch5, iter0, batch957/1133, batch loss:0.3107510209083557, Training time:17827.021639585495
batch reward last col mean 0.14013442397117615 first col mean 0.10080941766500473 all mean 0.13164874911308289
0.3026185929775238 0.3026185929775238
rl training, epoch5, iter0, batch958/1133, batch loss:0.3026185929775238, Training time:17828.932122945786
batch reward last col mean 0.10789037495851517 first col mean 0.10880035161972046 all mean 0.11017341911792755
0.3778964877128601 0.3778965473175049
rl training, epoch5, iter0, batch959/1133, batch loss:0.3778965473175049, Training time:17830.8156542778
batch reward last col mean 0.10427019000053406 first col mean 0.1208016574382782 all mean 0.10415462404489517
0.2753685414791107 0.2753685414791107
rl training, epoch5, iter0, batch960/1133, batch loss:0.2753685414791107, Training time:17832.68305850029
batch reward last col mean 0.1295267790555954 first col mean 0.11020823568105698 all mean 0.11822567880153656
0.31354159116744995 0.31354156136512756
rl training, epoch5, iter0, batch961/1133, batch loss:0.31354156136512756, Training time:17834.422379016876
batch reward last col mean 0.11042408645153046 first col mean 0.11647819727659225 all mean 0.11653023958206177
0.29527926445007324 0.29527926445007324
rl training, epoch5, iter0, batch962/1133, batch loss:0.29527926445007324, Training time:17836.067083597183
batch reward last col mean 0.11533652245998383 first col mean 0.1292894035577774 all mean 0.11400015652179718
0.31932416558265686 0.31932416558265686
rl training, epoch5, iter0, batch963/1133, batch loss:0.31932416558265686, Training time:17837.704758405685
batch reward last col mean 0.12851324677467346 first col mean 0.1190728098154068 all mean 0.11988407373428345
0.3347158133983612 0.3347158133983612
rl training, epoch5, iter0, batch964/1133, batch loss:0.3347158133983612, Training time:17839.882964611053
batch reward last col mean 0.11814641952514648 first col mean 0.11393658816814423 all mean 0.1144706979393959
0.3593709170818329 0.3593709170818329
rl training, epoch5, iter0, batch965/1133, batch loss:0.3593709170818329, Training time:17841.511125087738
batch reward last col mean 0.1160697489976883 first col mean 0.0903063416481018 all mean 0.11213430017232895
0.31557223200798035 0.31557223200798035
rl training, epoch5, iter0, batch966/1133, batch loss:0.31557223200798035, Training time:17843.60170340538
batch reward last col mean 0.0720030665397644 first col mean 0.09754294157028198 all mean 0.08361367136240005
0.2744459807872772 0.2744459807872772
rl training, epoch5, iter0, batch967/1133, batch loss:0.2744459807872772, Training time:17845.07314348221
batch reward last col mean 0.07408686727285385 first col mean 0.10086900740861893 all mean 0.08173835277557373
0.2746753692626953 0.2746753692626953
rl training, epoch5, iter0, batch968/1133, batch loss:0.2746753692626953, Training time:17846.895493745804
batch reward last col mean 0.088423952460289 first col mean 0.11948352307081223 all mean 0.09575583785772324
0.33328884840011597 0.33328884840011597
rl training, epoch5, iter0, batch969/1133, batch loss:0.33328884840011597, Training time:17848.775909900665
batch reward last col mean 0.10777825862169266 first col mean 0.10437990725040436 all mean 0.10531748831272125
0.30337467789649963 0.30337467789649963
rl training, epoch5, iter0, batch970/1133, batch loss:0.30337467789649963, Training time:17850.397974729538
batch reward last col mean 0.10925345122814178 first col mean 0.10814746469259262 all mean 0.11093106865882874
0.29848605394363403 0.29848605394363403
rl training, epoch5, iter0, batch971/1133, batch loss:0.29848605394363403, Training time:17852.05994796753
batch reward last col mean 0.08231842517852783 first col mean 0.1072167307138443 all mean 0.08923014253377914
0.29186639189720154 0.29186639189720154
rl training, epoch5, iter0, batch972/1133, batch loss:0.29186639189720154, Training time:17854.10217690468
batch reward last col mean 0.10708765685558319 first col mean 0.08679334074258804 all mean 0.1053929403424263
0.3006919026374817 0.3006919026374817
rl training, epoch5, iter0, batch973/1133, batch loss:0.3006919026374817, Training time:17856.27380824089
batch reward last col mean 0.09747681021690369 first col mean 0.11432081460952759 all mean 0.09858251363039017
0.3081382215023041 0.3081381916999817
rl training, epoch5, iter0, batch974/1133, batch loss:0.3081381916999817, Training time:17858.164214134216
batch reward last col mean 0.13200123608112335 first col mean 0.11062771081924438 all mean 0.11659596115350723
0.28159740567207336 0.28159740567207336
rl training, epoch5, iter0, batch975/1133, batch loss:0.28159740567207336, Training time:17860.144551992416
batch reward last col mean 0.091748908162117 first col mean 0.10230407863855362 all mean 0.09845157712697983
0.3123199939727783 0.3123199939727783
rl training, epoch5, iter0, batch976/1133, batch loss:0.3123199939727783, Training time:17861.60136270523
batch reward last col mean 0.10018932819366455 first col mean 0.11412350833415985 all mean 0.10767939686775208
0.3298376798629761 0.3298376798629761
rl training, epoch5, iter0, batch977/1133, batch loss:0.3298376798629761, Training time:17863.559450864792
batch reward last col mean 0.08139271289110184 first col mean 0.10412780940532684 all mean 0.09066994488239288
0.2577196955680847 0.25771966576576233
rl training, epoch5, iter0, batch978/1133, batch loss:0.25771966576576233, Training time:17865.402177095413
batch reward last col mean 0.12114918231964111 first col mean 0.1272030621767044 all mean 0.11921573430299759
0.32525843381881714 0.3252584636211395
rl training, epoch5, iter0, batch979/1133, batch loss:0.3252584636211395, Training time:17866.96942615509
batch reward last col mean 0.10386663675308228 first col mean 0.11833648383617401 all mean 0.10384178906679153
0.2852318286895752 0.2852318286895752
rl training, epoch5, iter0, batch980/1133, batch loss:0.2852318286895752, Training time:17869.149795532227
batch reward last col mean 0.13134464621543884 first col mean 0.11745040118694305 all mean 0.12481025606393814
0.3288792371749878 0.3288792371749878
rl training, epoch5, iter0, batch981/1133, batch loss:0.3288792371749878, Training time:17870.808469057083
batch reward last col mean 0.12949919700622559 first col mean 0.10025356709957123 all mean 0.12750108540058136
0.3102976381778717 0.3102976381778717
rl training, epoch5, iter0, batch982/1133, batch loss:0.3102976381778717, Training time:17872.44358062744
batch reward last col mean 0.12912899255752563 first col mean 0.10145589709281921 all mean 0.13028526306152344
0.33880966901779175 0.33880969882011414
rl training, epoch5, iter0, batch983/1133, batch loss:0.33880969882011414, Training time:17874.31852030754
batch reward last col mean 0.11187470704317093 first col mean 0.11653228849172592 all mean 0.1098480224609375
0.2803370952606201 0.2803370952606201
rl training, epoch5, iter0, batch984/1133, batch loss:0.2803370952606201, Training time:17875.874804019928
batch reward last col mean 0.0647181048989296 first col mean 0.11604130268096924 all mean 0.07339491695165634
0.2463417798280716 0.2463417500257492
rl training, epoch5, iter0, batch985/1133, batch loss:0.2463417500257492, Training time:17877.545820713043
batch reward last col mean 0.12050572782754898 first col mean 0.11935687065124512 all mean 0.11678465455770493
0.2983265817165375 0.2983265817165375
rl training, epoch5, iter0, batch986/1133, batch loss:0.2983265817165375, Training time:17879.182787895203
batch reward last col mean 0.09572601318359375 first col mean 0.10182377696037292 all mean 0.09758828580379486
0.30083388090133667 0.30083388090133667
rl training, epoch5, iter0, batch987/1133, batch loss:0.30083388090133667, Training time:17881.24830698967
batch reward last col mean 0.10840887576341629 first col mean 0.12244836986064911 all mean 0.11097332835197449
0.3355630338191986 0.3355630338191986
rl training, epoch5, iter0, batch988/1133, batch loss:0.3355630338191986, Training time:17883.43483018875
batch reward last col mean 0.09198896586894989 first col mean 0.12658356130123138 all mean 0.09865119308233261
0.2858923077583313 0.2858923077583313
rl training, epoch5, iter0, batch989/1133, batch loss:0.2858923077583313, Training time:17885.393877744675
batch reward last col mean 0.0975109338760376 first col mean 0.12342426180839539 all mean 0.10338233411312103
0.292493999004364 0.292493999004364
rl training, epoch5, iter0, batch990/1133, batch loss:0.292493999004364, Training time:17887.2379488945
batch reward last col mean 0.10179437696933746 first col mean 0.10882090777158737 all mean 0.09898857772350311
0.2832084000110626 0.2832084000110626
rl training, epoch5, iter0, batch991/1133, batch loss:0.2832084000110626, Training time:17889.170876979828
batch reward last col mean 0.16664373874664307 first col mean 0.1292601078748703 all mean 0.15456019341945648
0.37480443716049194 0.37480440735816956
rl training, epoch5, iter0, batch992/1133, batch loss:0.37480440735816956, Training time:17891.0608587265
batch reward last col mean 0.07392749935388565 first col mean 0.12468867003917694 all mean 0.08896048367023468
0.316746324300766 0.316746324300766
rl training, epoch5, iter0, batch993/1133, batch loss:0.316746324300766, Training time:17892.906750679016
batch reward last col mean 0.14262165129184723 first col mean 0.1009790375828743 all mean 0.13430990278720856
0.3117660880088806 0.3117660880088806
rl training, epoch5, iter0, batch994/1133, batch loss:0.3117660880088806, Training time:17895.050762176514
batch reward last col mean 0.08671849220991135 first col mean 0.13504226505756378 all mean 0.09464132785797119
0.28797900676727295 0.28797900676727295
rl training, epoch5, iter0, batch995/1133, batch loss:0.28797900676727295, Training time:17896.96160054207
batch reward last col mean 0.07675911486148834 first col mean 0.11286123096942902 all mean 0.08182132989168167
0.2545258402824402 0.2545258402824402
rl training, epoch5, iter0, batch996/1133, batch loss:0.2545258402824402, Training time:17898.955360651016
batch reward last col mean 0.11314107477664948 first col mean 0.10118710994720459 all mean 0.11340177804231644
0.31444019079208374 0.31444019079208374
rl training, epoch5, iter0, batch997/1133, batch loss:0.31444019079208374, Training time:17900.58287525177
batch reward last col mean 0.12721845507621765 first col mean 0.13445797562599182 all mean 0.12185803800821304
0.34565556049346924 0.34565556049346924
rl training, epoch5, iter0, batch998/1133, batch loss:0.34565556049346924, Training time:17902.409105539322
batch reward last col mean 0.08615603297948837 first col mean 0.10624323040246964 all mean 0.0961461290717125
0.26016297936439514 0.26016297936439514
rl training, epoch5, iter0, batch999/1133, batch loss:0.26016297936439514, Training time:17904.03137612343
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4946103453478346 Time: 96.9511616230011 s
loss of true 0.21558579992558824 loss of gen 0.178808662645841 loss of other 0.1002158823029351 first score 0.09178628027439117
batch reward last col mean 0.08856099098920822 first col mean 0.09478485584259033 all mean 0.08758792281150818
0.26434341073036194 0.26434341073036194
rl training, epoch5, iter0, batch1000/1133, batch loss:0.26434341073036194, Training time:18003.08567547798
batch reward last col mean 0.1125456839799881 first col mean 0.09610339999198914 all mean 0.10843993723392487
0.2615087628364563 0.2615087330341339
rl training, epoch5, iter0, batch1001/1133, batch loss:0.2615087330341339, Training time:18005.053438186646
batch reward last col mean 0.0895003229379654 first col mean 0.1067458838224411 all mean 0.09686170518398285
0.29370972514152527 0.29370972514152527
rl training, epoch5, iter0, batch1002/1133, batch loss:0.29370972514152527, Training time:18006.81272673607
batch reward last col mean 0.1070474237203598 first col mean 0.10567570477724075 all mean 0.10686526447534561
0.2653959095478058 0.2653959393501282
rl training, epoch5, iter0, batch1003/1133, batch loss:0.2653959393501282, Training time:18008.383788585663
batch reward last col mean 0.0972808301448822 first col mean 0.09059089422225952 all mean 0.10156014561653137
0.26390767097473145 0.26390767097473145
rl training, epoch5, iter0, batch1004/1133, batch loss:0.26390767097473145, Training time:18010.238860607147
batch reward last col mean 0.07353410124778748 first col mean 0.08414503186941147 all mean 0.07869654148817062
0.23236320912837982 0.23236320912837982
rl training, epoch5, iter0, batch1005/1133, batch loss:0.23236320912837982, Training time:18011.70297408104
batch reward last col mean 0.128925621509552 first col mean 0.11477616429328918 all mean 0.12275343388319016
0.2939821183681488 0.2939821481704712
rl training, epoch5, iter0, batch1006/1133, batch loss:0.2939821481704712, Training time:18013.657638072968
batch reward last col mean 0.11816679686307907 first col mean 0.11499026417732239 all mean 0.11796902120113373
0.3313235640525818 0.3313235938549042
rl training, epoch5, iter0, batch1007/1133, batch loss:0.3313235938549042, Training time:18015.594924926758
batch reward last col mean 0.07019829750061035 first col mean 0.10087673366069794 all mean 0.07264546304941177
0.21662478148937225 0.21662476658821106
rl training, epoch5, iter0, batch1008/1133, batch loss:0.21662476658821106, Training time:18017.365543842316
batch reward last col mean 0.11395250260829926 first col mean 0.11212968081235886 all mean 0.11213092505931854
0.2710888981819153 0.2710888981819153
rl training, epoch5, iter0, batch1009/1133, batch loss:0.2710888981819153, Training time:18019.416656255722
batch reward last col mean 0.06986372917890549 first col mean 0.10053929686546326 all mean 0.07499318569898605
0.24115365743637085 0.24115365743637085
rl training, epoch5, iter0, batch1010/1133, batch loss:0.24115365743637085, Training time:18021.391975164413
batch reward last col mean 0.09376537054777145 first col mean 0.10839821398258209 all mean 0.09819651395082474
0.27216896414756775 0.27216893434524536
rl training, epoch5, iter0, batch1011/1133, batch loss:0.27216893434524536, Training time:18023.326790332794
batch reward last col mean 0.10768109560012817 first col mean 0.10724182426929474 all mean 0.10936293005943298
0.3158825933933258 0.3158826231956482
rl training, epoch5, iter0, batch1012/1133, batch loss:0.3158826231956482, Training time:18025.21838569641
batch reward last col mean 0.11449825763702393 first col mean 0.10943728685379028 all mean 0.11262983828783035
0.2861393094062805 0.28613927960395813
rl training, epoch5, iter0, batch1013/1133, batch loss:0.28613927960395813, Training time:18027.073425531387
batch reward last col mean 0.11905521154403687 first col mean 0.10600172728300095 all mean 0.1167873963713646
0.28068068623542786 0.28068068623542786
rl training, epoch5, iter0, batch1014/1133, batch loss:0.28068068623542786, Training time:18029.227310180664
batch reward last col mean 0.0698026567697525 first col mean 0.0889151394367218 all mean 0.0762377455830574
0.2060203105211258 0.2060203105211258
rl training, epoch5, iter0, batch1015/1133, batch loss:0.2060203105211258, Training time:18030.87696814537
batch reward last col mean 0.09172339737415314 first col mean 0.09802565723657608 all mean 0.09341420233249664
0.22532998025417328 0.22532998025417328
rl training, epoch5, iter0, batch1016/1133, batch loss:0.22532998025417328, Training time:18032.376512765884
batch reward last col mean 0.0819738358259201 first col mean 0.10425524413585663 all mean 0.08952257037162781
0.2792518138885498 0.2792518138885498
rl training, epoch5, iter0, batch1017/1133, batch loss:0.2792518138885498, Training time:18034.132150411606
batch reward last col mean 0.09676642715930939 first col mean 0.11424937844276428 all mean 0.09570609778165817
0.24570460617542267 0.24570460617542267
rl training, epoch5, iter0, batch1018/1133, batch loss:0.24570460617542267, Training time:18035.48691725731
batch reward last col mean 0.10105544328689575 first col mean 0.09718532860279083 all mean 0.10166539996862411
0.27981624007225037 0.279816210269928
rl training, epoch5, iter0, batch1019/1133, batch loss:0.279816210269928, Training time:18037.427042484283
batch reward last col mean 0.12178803980350494 first col mean 0.09396912157535553 all mean 0.11870540678501129
0.3014540374279022 0.3014540374279022
rl training, epoch5, iter0, batch1020/1133, batch loss:0.3014540374279022, Training time:18039.61456799507
batch reward last col mean 0.09678591787815094 first col mean 0.10710273683071136 all mean 0.10045681148767471
0.2905287742614746 0.2905287742614746
rl training, epoch5, iter0, batch1021/1133, batch loss:0.2905287742614746, Training time:18041.481924295425
batch reward last col mean 0.1044505313038826 first col mean 0.10383260250091553 all mean 0.10490021109580994
0.28848201036453247 0.28848201036453247
rl training, epoch5, iter0, batch1022/1133, batch loss:0.28848201036453247, Training time:18043.476360559464
batch reward last col mean 0.08394093811511993 first col mean 0.12292599678039551 all mean 0.09026036411523819
0.24310985207557678 0.24310985207557678
rl training, epoch5, iter0, batch1023/1133, batch loss:0.24310985207557678, Training time:18045.40724158287
batch reward last col mean 0.10298755764961243 first col mean 0.10796548426151276 all mean 0.10302238166332245
0.2887035310268402 0.2887035310268402
rl training, epoch5, iter0, batch1024/1133, batch loss:0.2887035310268402, Training time:18046.980788230896
batch reward last col mean 0.12527424097061157 first col mean 0.11770884692668915 all mean 0.12191179394721985
0.2890594005584717 0.2890594005584717
rl training, epoch5, iter0, batch1025/1133, batch loss:0.2890594005584717, Training time:18048.38407921791
batch reward last col mean 0.10941699892282486 first col mean 0.10091917216777802 all mean 0.1100839227437973
0.26192474365234375 0.26192474365234375
rl training, epoch5, iter0, batch1026/1133, batch loss:0.26192474365234375, Training time:18050.31581759453
batch reward last col mean 0.08600789308547974 first col mean 0.12109462916851044 all mean 0.09131674468517303
0.271762490272522 0.271762490272522
rl training, epoch5, iter0, batch1027/1133, batch loss:0.271762490272522, Training time:18051.928422689438
batch reward last col mean 0.08362594991922379 first col mean 0.09995514154434204 all mean 0.08338478207588196
0.2554427981376648 0.2554427981376648
rl training, epoch5, iter0, batch1028/1133, batch loss:0.2554427981376648, Training time:18053.33562898636
batch reward last col mean 0.09616927057504654 first col mean 0.12007007002830505 all mean 0.09529276192188263
0.2481393963098526 0.2481393963098526
rl training, epoch5, iter0, batch1029/1133, batch loss:0.2481393963098526, Training time:18054.881610631943
batch reward last col mean 0.05810831859707832 first col mean 0.11219136416912079 all mean 0.07997198402881622
0.2901161015033722 0.2901161015033722
rl training, epoch5, iter0, batch1030/1133, batch loss:0.2901161015033722, Training time:18056.39885687828
batch reward last col mean 0.09597606956958771 first col mean 0.10710814595222473 all mean 0.10213714092969894
0.2801040709018707 0.2801040709018707
rl training, epoch5, iter0, batch1031/1133, batch loss:0.2801040709018707, Training time:18057.992141008377
batch reward last col mean 0.09850656986236572 first col mean 0.1151551604270935 all mean 0.10015986114740372
0.26978787779808044 0.26978787779808044
rl training, epoch5, iter0, batch1032/1133, batch loss:0.26978787779808044, Training time:18059.834690093994
batch reward last col mean 0.096316397190094 first col mean 0.10048944503068924 all mean 0.10096798837184906
0.27793005108833313 0.27793005108833313
rl training, epoch5, iter0, batch1033/1133, batch loss:0.27793005108833313, Training time:18062.006074666977
batch reward last col mean 0.08510102331638336 first col mean 0.10375623404979706 all mean 0.08901457488536835
0.24134966731071472 0.24134966731071472
rl training, epoch5, iter0, batch1034/1133, batch loss:0.24134966731071472, Training time:18063.957840442657
batch reward last col mean 0.09347409009933472 first col mean 0.09934535622596741 all mean 0.09421553462743759
0.2484656423330307 0.2484656423330307
rl training, epoch5, iter0, batch1035/1133, batch loss:0.2484656423330307, Training time:18065.774089336395
batch reward last col mean 0.08612124621868134 first col mean 0.10018935054540634 all mean 0.09644011408090591
0.25437214970588684 0.25437214970588684
rl training, epoch5, iter0, batch1036/1133, batch loss:0.25437214970588684, Training time:18067.33325433731
batch reward last col mean 0.09006184339523315 first col mean 0.09670838713645935 all mean 0.09070643782615662
0.2594020664691925 0.2594020366668701
rl training, epoch5, iter0, batch1037/1133, batch loss:0.2594020366668701, Training time:18069.1173620224
batch reward last col mean 0.10511186718940735 first col mean 0.11000615358352661 all mean 0.1002313643693924
0.24967415630817413 0.24967412650585175
rl training, epoch5, iter0, batch1038/1133, batch loss:0.24967412650585175, Training time:18071.4705221653
batch reward last col mean 0.0976644977927208 first col mean 0.10999802500009537 all mean 0.09615837037563324
0.25674059987068176 0.25674059987068176
rl training, epoch5, iter0, batch1039/1133, batch loss:0.25674059987068176, Training time:18073.804129362106
batch reward last col mean 0.13471651077270508 first col mean 0.08884814381599426 all mean 0.12911219894886017
0.3048185408115387 0.3048185408115387
rl training, epoch5, iter0, batch1040/1133, batch loss:0.3048185408115387, Training time:18075.52032852173
batch reward last col mean 0.09468832612037659 first col mean 0.08160258084535599 all mean 0.09241723269224167
0.23033683001995087 0.23033683001995087
rl training, epoch5, iter0, batch1041/1133, batch loss:0.23033683001995087, Training time:18077.429045200348
batch reward last col mean 0.13001355528831482 first col mean 0.12187644839286804 all mean 0.12291373312473297
0.26015427708625793 0.26015427708625793
rl training, epoch5, iter0, batch1042/1133, batch loss:0.26015427708625793, Training time:18078.858246326447
batch reward last col mean 0.13170233368873596 first col mean 0.11419707536697388 all mean 0.13097281754016876
0.35728272795677185 0.35728272795677185
rl training, epoch5, iter0, batch1043/1133, batch loss:0.35728272795677185, Training time:18080.331166744232
batch reward last col mean 0.10640165209770203 first col mean 0.10417096316814423 all mean 0.1026279628276825
0.2584836483001709 0.2584836483001709
rl training, epoch5, iter0, batch1044/1133, batch loss:0.2584836483001709, Training time:18081.82896566391
batch reward last col mean 0.07900052517652512 first col mean 0.09035177528858185 all mean 0.08835704624652863
0.2501632273197174 0.2501632273197174
rl training, epoch5, iter0, batch1045/1133, batch loss:0.2501632273197174, Training time:18083.5711145401
batch reward last col mean 0.10057096183300018 first col mean 0.09412233531475067 all mean 0.09665610641241074
0.2451315075159073 0.2451314926147461
rl training, epoch5, iter0, batch1046/1133, batch loss:0.2451314926147461, Training time:18085.572924375534
batch reward last col mean 0.11920139193534851 first col mean 0.11679473519325256 all mean 0.12081781774759293
0.29067301750183105 0.29067301750183105
rl training, epoch5, iter0, batch1047/1133, batch loss:0.29067301750183105, Training time:18087.16708445549
batch reward last col mean 0.09018830955028534 first col mean 0.09571139514446259 all mean 0.09175566583871841
0.2733097970485687 0.2733097970485687
rl training, epoch5, iter0, batch1048/1133, batch loss:0.2733097970485687, Training time:18089.338811397552
batch reward last col mean 0.09094759821891785 first col mean 0.08677725493907928 all mean 0.09045210480690002
0.22378993034362793 0.22378993034362793
rl training, epoch5, iter0, batch1049/1133, batch loss:0.22378993034362793, Training time:18090.89456653595
batch reward last col mean 0.08717287331819534 first col mean 0.1209401935338974 all mean 0.08985047042369843
0.24513448774814606 0.24513450264930725
rl training, epoch5, iter0, batch1050/1133, batch loss:0.24513450264930725, Training time:18092.57666039467
batch reward last col mean 0.13741502165794373 first col mean 0.1343579739332199 all mean 0.13436368107795715
0.29844754934310913 0.29844754934310913
rl training, epoch5, iter0, batch1051/1133, batch loss:0.29844754934310913, Training time:18094.331087350845
batch reward last col mean 0.09947438538074493 first col mean 0.1169423907995224 all mean 0.10765458643436432
0.2857249975204468 0.2857249975204468
rl training, epoch5, iter0, batch1052/1133, batch loss:0.2857249975204468, Training time:18095.874635219574
batch reward last col mean 0.0992162823677063 first col mean 0.10077127814292908 all mean 0.09960731118917465
0.26200562715530396 0.26200562715530396
rl training, epoch5, iter0, batch1053/1133, batch loss:0.26200562715530396, Training time:18097.507868289948
batch reward last col mean 0.08856924623250961 first col mean 0.08632509410381317 all mean 0.09001751244068146
0.2536062002182007 0.2536062002182007
rl training, epoch5, iter0, batch1054/1133, batch loss:0.2536062002182007, Training time:18098.701860427856
batch reward last col mean 0.1153678372502327 first col mean 0.10805879533290863 all mean 0.10922663658857346
0.30354586243629456 0.30354586243629456
rl training, epoch5, iter0, batch1055/1133, batch loss:0.30354586243629456, Training time:18100.165950536728
batch reward last col mean 0.10560104250907898 first col mean 0.11372296512126923 all mean 0.10924425721168518
0.300718754529953 0.3007187247276306
rl training, epoch5, iter0, batch1056/1133, batch loss:0.3007187247276306, Training time:18101.80992293358
batch reward last col mean 0.1253676414489746 first col mean 0.10887455195188522 all mean 0.11909854412078857
0.2993106245994568 0.2993106245994568
rl training, epoch5, iter0, batch1057/1133, batch loss:0.2993106245994568, Training time:18103.191091537476
batch reward last col mean 0.1506924331188202 first col mean 0.11104532331228256 all mean 0.1264413595199585
0.2988913059234619 0.2988913059234619
rl training, epoch5, iter0, batch1058/1133, batch loss:0.2988913059234619, Training time:18104.513788223267
batch reward last col mean 0.10098579525947571 first col mean 0.0990409106016159 all mean 0.0965321809053421
0.2649337947368622 0.2649337947368622
rl training, epoch5, iter0, batch1059/1133, batch loss:0.2649337947368622, Training time:18106.223054409027
batch reward last col mean 0.09201227128505707 first col mean 0.09954705834388733 all mean 0.0951438695192337
0.24464038014411926 0.24464038014411926
rl training, epoch5, iter0, batch1060/1133, batch loss:0.24464038014411926, Training time:18107.707603931427
batch reward last col mean 0.11135979741811752 first col mean 0.1023714691400528 all mean 0.10755065083503723
0.29033344984054565 0.29033344984054565
rl training, epoch5, iter0, batch1061/1133, batch loss:0.29033344984054565, Training time:18109.423570871353
batch reward last col mean 0.049957118928432465 first col mean 0.0898192897439003 all mean 0.06403475999832153
0.22787970304489136 0.22787970304489136
rl training, epoch5, iter0, batch1062/1133, batch loss:0.22787970304489136, Training time:18110.85602259636
batch reward last col mean 0.12820756435394287 first col mean 0.11560894548892975 all mean 0.12166416645050049
0.28123781085014343 0.28123781085014343
rl training, epoch5, iter0, batch1063/1133, batch loss:0.28123781085014343, Training time:18112.220110416412
batch reward last col mean 0.10098619014024734 first col mean 0.10434330999851227 all mean 0.10613580048084259
0.2982260286808014 0.2982260286808014
rl training, epoch5, iter0, batch1064/1133, batch loss:0.2982260286808014, Training time:18113.651765584946
batch reward last col mean 0.12814189493656158 first col mean 0.09599768370389938 all mean 0.12248336523771286
0.2818589210510254 0.2818589210510254
rl training, epoch5, iter0, batch1065/1133, batch loss:0.2818589210510254, Training time:18115.045774936676
batch reward last col mean 0.1287820041179657 first col mean 0.11529874801635742 all mean 0.12208981812000275
0.3089272677898407 0.3089272677898407
rl training, epoch5, iter0, batch1066/1133, batch loss:0.3089272677898407, Training time:18116.82339334488
batch reward last col mean 0.10089440643787384 first col mean 0.11241963505744934 all mean 0.10604877769947052
0.26110178232192993 0.26110178232192993
rl training, epoch5, iter0, batch1067/1133, batch loss:0.26110178232192993, Training time:18118.54620575905
batch reward last col mean 0.11072707176208496 first col mean 0.12351508438587189 all mean 0.11178195476531982
0.27319619059562683 0.27319616079330444
rl training, epoch5, iter0, batch1068/1133, batch loss:0.27319616079330444, Training time:18119.627893447876
batch reward last col mean 0.0811491385102272 first col mean 0.10256398469209671 all mean 0.09106200933456421
0.26948082447052 0.26948082447052
rl training, epoch5, iter0, batch1069/1133, batch loss:0.26948082447052, Training time:18121.048332214355
batch reward last col mean 0.07630332559347153 first col mean 0.09531685709953308 all mean 0.08275144547224045
0.25498712062835693 0.25498712062835693
rl training, epoch5, iter0, batch1070/1133, batch loss:0.25498712062835693, Training time:18122.508753061295
batch reward last col mean 0.1015610322356224 first col mean 0.1044030636548996 all mean 0.10014855861663818
0.25333085656166077 0.25333085656166077
rl training, epoch5, iter0, batch1071/1133, batch loss:0.25333085656166077, Training time:18124.313373088837
batch reward last col mean 0.08143449574708939 first col mean 0.11342082917690277 all mean 0.0867689922451973
0.24332867562770844 0.24332867562770844
rl training, epoch5, iter0, batch1072/1133, batch loss:0.24332867562770844, Training time:18126.009110450745
batch reward last col mean 0.12328501790761948 first col mean 0.1199309378862381 all mean 0.1224542185664177
0.30436721444129944 0.30436721444129944
rl training, epoch5, iter0, batch1073/1133, batch loss:0.30436721444129944, Training time:18127.369111299515
batch reward last col mean 0.09463528543710709 first col mean 0.09589290618896484 all mean 0.10289965569972992
0.2747184634208679 0.2747184634208679
rl training, epoch5, iter0, batch1074/1133, batch loss:0.2747184634208679, Training time:18128.57388162613
batch reward last col mean 0.11583897471427917 first col mean 0.11482002586126328 all mean 0.11171089112758636
0.2745080590248108 0.2745080888271332
rl training, epoch5, iter0, batch1075/1133, batch loss:0.2745080888271332, Training time:18130.095794677734
batch reward last col mean 0.11686727404594421 first col mean 0.0968974381685257 all mean 0.11444192379713058
0.2900667190551758 0.2900666892528534
rl training, epoch5, iter0, batch1076/1133, batch loss:0.2900666892528534, Training time:18131.526321411133
batch reward last col mean 0.09475540369749069 first col mean 0.11412297189235687 all mean 0.09972457587718964
0.2824033796787262 0.2824033796787262
rl training, epoch5, iter0, batch1077/1133, batch loss:0.2824033796787262, Training time:18133.456903219223
batch reward last col mean 0.09326197952032089 first col mean 0.09936561435461044 all mean 0.09755942225456238
0.26923367381095886 0.26923367381095886
rl training, epoch5, iter0, batch1078/1133, batch loss:0.26923367381095886, Training time:18135.377847909927
batch reward last col mean 0.1141573116183281 first col mean 0.09865347295999527 all mean 0.11581552028656006
0.31863468885421753 0.31863468885421753
rl training, epoch5, iter0, batch1079/1133, batch loss:0.31863468885421753, Training time:18136.737102985382
batch reward last col mean 0.08883126080036163 first col mean 0.12237685918807983 all mean 0.09372168034315109
0.2580660879611969 0.2580660879611969
rl training, epoch5, iter0, batch1080/1133, batch loss:0.2580660879611969, Training time:18138.268139600754
batch reward last col mean 0.06951785087585449 first col mean 0.1374083012342453 all mean 0.08363200724124908
0.24956151843070984 0.24956151843070984
rl training, epoch5, iter0, batch1081/1133, batch loss:0.24956151843070984, Training time:18139.667182445526
batch reward last col mean 0.10095623135566711 first col mean 0.09902096539735794 all mean 0.10212709754705429
0.29257673025131226 0.29257673025131226
rl training, epoch5, iter0, batch1082/1133, batch loss:0.29257673025131226, Training time:18141.34655189514
batch reward last col mean 0.14497454464435577 first col mean 0.12643370032310486 all mean 0.1399550586938858
0.2730276584625244 0.2730276584625244
rl training, epoch5, iter0, batch1083/1133, batch loss:0.2730276584625244, Training time:18143.534166812897
batch reward last col mean 0.11744150519371033 first col mean 0.10759157687425613 all mean 0.11892636865377426
0.2884770929813385 0.2884770929813385
rl training, epoch5, iter0, batch1084/1133, batch loss:0.2884770929813385, Training time:18145.219342947006
batch reward last col mean 0.10725858807563782 first col mean 0.1088206022977829 all mean 0.10597731173038483
0.31024208664894104 0.31024205684661865
rl training, epoch5, iter0, batch1085/1133, batch loss:0.31024205684661865, Training time:18146.32591509819
batch reward last col mean 0.12063930928707123 first col mean 0.12330378592014313 all mean 0.11674528568983078
0.3130255937576294 0.3130255937576294
rl training, epoch5, iter0, batch1086/1133, batch loss:0.3130255937576294, Training time:18147.801265478134
batch reward last col mean 0.09237299859523773 first col mean 0.1313409060239792 all mean 0.10077670216560364
0.27180957794189453 0.27180957794189453
rl training, epoch5, iter0, batch1087/1133, batch loss:0.27180957794189453, Training time:18149.24782204628
batch reward last col mean 0.09887820482254028 first col mean 0.10840318351984024 all mean 0.10175956040620804
0.2781391441822052 0.2781391441822052
rl training, epoch5, iter0, batch1088/1133, batch loss:0.2781391441822052, Training time:18151.50060915947
batch reward last col mean 0.10079256445169449 first col mean 0.11535423994064331 all mean 0.10256364941596985
0.2766094207763672 0.2766094207763672
rl training, epoch5, iter0, batch1089/1133, batch loss:0.2766094207763672, Training time:18153.39026594162
batch reward last col mean 0.11537288129329681 first col mean 0.10171733796596527 all mean 0.11404190957546234
0.27230679988861084 0.27230677008628845
rl training, epoch5, iter0, batch1090/1133, batch loss:0.27230677008628845, Training time:18155.271487236023
batch reward last col mean 0.0828244686126709 first col mean 0.10135971754789352 all mean 0.08671213686466217
0.23639585077762604 0.23639585077762604
rl training, epoch5, iter0, batch1091/1133, batch loss:0.23639585077762604, Training time:18156.742230176926
batch reward last col mean 0.10929425060749054 first col mean 0.11528407782316208 all mean 0.11311892420053482
0.2899414002895355 0.2899414002895355
rl training, epoch5, iter0, batch1092/1133, batch loss:0.2899414002895355, Training time:18158.394634008408
batch reward last col mean 0.10092923045158386 first col mean 0.10447783768177032 all mean 0.1030104011297226
0.2935468852519989 0.2935468852519989
rl training, epoch5, iter0, batch1093/1133, batch loss:0.2935468852519989, Training time:18159.901758670807
batch reward last col mean 0.120379239320755 first col mean 0.09684917330741882 all mean 0.11947217583656311
0.2909697890281677 0.2909697890281677
rl training, epoch5, iter0, batch1094/1133, batch loss:0.2909697890281677, Training time:18162.235001564026
batch reward last col mean 0.11553329229354858 first col mean 0.10830139368772507 all mean 0.11631657183170319
0.3184175491333008 0.3184175491333008
rl training, epoch5, iter0, batch1095/1133, batch loss:0.3184175491333008, Training time:18164.34760904312
batch reward last col mean 0.11146619915962219 first col mean 0.12026076018810272 all mean 0.11303896456956863
0.32688382267951965 0.32688382267951965
rl training, epoch5, iter0, batch1096/1133, batch loss:0.32688382267951965, Training time:18166.531653881073
batch reward last col mean 0.08357127755880356 first col mean 0.11921753734350204 all mean 0.09411696344614029
0.26487940549850464 0.26487940549850464
rl training, epoch5, iter0, batch1097/1133, batch loss:0.26487940549850464, Training time:18168.588814496994
batch reward last col mean 0.1652372181415558 first col mean 0.10860377550125122 all mean 0.13950853049755096
0.3100190758705139 0.3100190758705139
rl training, epoch5, iter0, batch1098/1133, batch loss:0.3100190758705139, Training time:18169.92104792595
batch reward last col mean 0.08986720442771912 first col mean 0.10613033920526505 all mean 0.09744273126125336
0.26339665055274963 0.26339665055274963
rl training, epoch5, iter0, batch1099/1133, batch loss:0.26339665055274963, Training time:18171.511545181274
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.49226646287085624 Time: 93.96909856796265 s
loss of true 0.21531026949160728 loss of gen 0.17602620323805923 loss of other 0.10092998940303645 first score 0.16163018345832825
batch reward last col mean 0.09874240309000015 first col mean 0.09663450717926025 all mean 0.10129944235086441
0.2846757173538208 0.2846757173538208
rl training, epoch5, iter0, batch1100/1133, batch loss:0.2846757173538208, Training time:18267.102349996567
batch reward last col mean 0.10195208340883255 first col mean 0.11574410647153854 all mean 0.11157787591218948
0.2913788855075836 0.2913788855075836
rl training, epoch5, iter0, batch1101/1133, batch loss:0.2913788855075836, Training time:18268.705498456955
batch reward last col mean 0.09616108238697052 first col mean 0.11902198195457458 all mean 0.09848568588495255
0.237394779920578 0.237394779920578
rl training, epoch5, iter0, batch1102/1133, batch loss:0.237394779920578, Training time:18270.26769065857
batch reward last col mean 0.0894533321261406 first col mean 0.10033057630062103 all mean 0.09530224651098251
0.25802090764045715 0.25802090764045715
rl training, epoch5, iter0, batch1103/1133, batch loss:0.25802090764045715, Training time:18271.6707072258
batch reward last col mean 0.09615659713745117 first col mean 0.10670004785060883 all mean 0.09306632727384567
0.2656490206718445 0.2656490206718445
rl training, epoch5, iter0, batch1104/1133, batch loss:0.2656490206718445, Training time:18273.446127414703
batch reward last col mean 0.07848943769931793 first col mean 0.10827162861824036 all mean 0.08380509912967682
0.25209057331085205 0.25209057331085205
rl training, epoch5, iter0, batch1105/1133, batch loss:0.25209057331085205, Training time:18274.839539527893
batch reward last col mean 0.08981355279684067 first col mean 0.11156178265810013 all mean 0.09024719148874283
0.2801032066345215 0.2801032066345215
rl training, epoch5, iter0, batch1106/1133, batch loss:0.2801032066345215, Training time:18276.347708940506
batch reward last col mean 0.10362682491540909 first col mean 0.10071027278900146 all mean 0.10729028284549713
0.31714075803756714 0.31714075803756714
rl training, epoch5, iter0, batch1107/1133, batch loss:0.31714075803756714, Training time:18278.327173948288
batch reward last col mean 0.09924348443746567 first col mean 0.0958135724067688 all mean 0.09815525263547897
0.2744750678539276 0.2744750678539276
rl training, epoch5, iter0, batch1108/1133, batch loss:0.2744750678539276, Training time:18280.307873487473
batch reward last col mean 0.11616934835910797 first col mean 0.08902917802333832 all mean 0.10611678659915924
0.26025378704071045 0.26025378704071045
rl training, epoch5, iter0, batch1109/1133, batch loss:0.26025378704071045, Training time:18281.82958650589
batch reward last col mean 0.09856397658586502 first col mean 0.10868381708860397 all mean 0.10298357903957367
0.29764947295188904 0.29764947295188904
rl training, epoch5, iter0, batch1110/1133, batch loss:0.29764947295188904, Training time:18283.559512853622
batch reward last col mean 0.0786161720752716 first col mean 0.11477451026439667 all mean 0.09520566463470459
0.29199355840682983 0.29199355840682983
rl training, epoch5, iter0, batch1111/1133, batch loss:0.29199355840682983, Training time:18284.975714206696
batch reward last col mean 0.09682848304510117 first col mean 0.104681596159935 all mean 0.10135513544082642
0.2610296607017517 0.2610296607017517
rl training, epoch5, iter0, batch1112/1133, batch loss:0.2610296607017517, Training time:18286.6557366848
batch reward last col mean 0.0937255322933197 first col mean 0.12139032036066055 all mean 0.1021648645401001
0.30172786116600037 0.30172786116600037
rl training, epoch5, iter0, batch1113/1133, batch loss:0.30172786116600037, Training time:18288.283034086227
batch reward last col mean 0.11050661653280258 first col mean 0.11327043920755386 all mean 0.11488107591867447
0.3451022803783417 0.3451022803783417
rl training, epoch5, iter0, batch1114/1133, batch loss:0.3451022803783417, Training time:18289.74940109253
batch reward last col mean 0.10395551472902298 first col mean 0.09900251775979996 all mean 0.10398081690073013
0.29174187779426575 0.29174187779426575
rl training, epoch5, iter0, batch1115/1133, batch loss:0.29174187779426575, Training time:18291.379411935806
batch reward last col mean 0.10125676542520523 first col mean 0.11290261894464493 all mean 0.10242835432291031
0.2536602020263672 0.2536602020263672
rl training, epoch5, iter0, batch1116/1133, batch loss:0.2536602020263672, Training time:18293.03854417801
batch reward last col mean 0.10167905688285828 first col mean 0.10656246542930603 all mean 0.10037586838006973
0.2744028866291046 0.2744028866291046
rl training, epoch5, iter0, batch1117/1133, batch loss:0.2744028866291046, Training time:18294.5623421669
batch reward last col mean 0.11129669845104218 first col mean 0.11922594159841537 all mean 0.1053205281496048
0.31643298268318176 0.31643298268318176
rl training, epoch5, iter0, batch1118/1133, batch loss:0.31643298268318176, Training time:18296.151758670807
batch reward last col mean 0.09839971363544464 first col mean 0.11384442448616028 all mean 0.10242974758148193
0.3004349172115326 0.3004349172115326
rl training, epoch5, iter0, batch1119/1133, batch loss:0.3004349172115326, Training time:18298.65296649933
batch reward last col mean 0.11191995441913605 first col mean 0.1040574461221695 all mean 0.1065291240811348
0.2668738067150116 0.2668737769126892
rl training, epoch5, iter0, batch1120/1133, batch loss:0.2668737769126892, Training time:18300.46689724922
batch reward last col mean 0.08672557771205902 first col mean 0.11543415486812592 all mean 0.09239869564771652
0.24838228523731232 0.24838228523731232
rl training, epoch5, iter0, batch1121/1133, batch loss:0.24838228523731232, Training time:18302.588004350662
batch reward last col mean 0.07667138427495956 first col mean 0.09676626324653625 all mean 0.08962707966566086
0.3135727643966675 0.3135727643966675
rl training, epoch5, iter0, batch1122/1133, batch loss:0.3135727643966675, Training time:18304.198583364487
batch reward last col mean 0.09846949577331543 first col mean 0.11413300037384033 all mean 0.1053752601146698
0.29760587215423584 0.2976059019565582
rl training, epoch5, iter0, batch1123/1133, batch loss:0.2976059019565582, Training time:18306.065457582474
batch reward last col mean 0.09082376956939697 first col mean 0.11644592881202698 all mean 0.0972573384642601
0.26907140016555786 0.26907140016555786
rl training, epoch5, iter0, batch1124/1133, batch loss:0.26907140016555786, Training time:18307.54394030571
batch reward last col mean 0.0886533185839653 first col mean 0.12027104198932648 all mean 0.10097448527812958
0.31703341007232666 0.31703343987464905
rl training, epoch5, iter0, batch1125/1133, batch loss:0.31703343987464905, Training time:18309.399482250214
batch reward last col mean 0.0923195481300354 first col mean 0.10869089514017105 all mean 0.0926932767033577
0.27345797419548035 0.27345797419548035
rl training, epoch5, iter0, batch1126/1133, batch loss:0.27345797419548035, Training time:18310.983221530914
batch reward last col mean 0.11784879863262177 first col mean 0.09686341881752014 all mean 0.10922206938266754
0.2819540798664093 0.2819540798664093
rl training, epoch5, iter0, batch1127/1133, batch loss:0.2819540798664093, Training time:18312.56602692604
batch reward last col mean 0.11331403255462646 first col mean 0.10038632154464722 all mean 0.11361826211214066
0.28704461455345154 0.28704461455345154
rl training, epoch5, iter0, batch1128/1133, batch loss:0.28704461455345154, Training time:18314.406542539597
batch reward last col mean 0.09181804209947586 first col mean 0.111139215528965 all mean 0.09394240379333496
0.2560955882072449 0.2560955882072449
rl training, epoch5, iter0, batch1129/1133, batch loss:0.2560955882072449, Training time:18316.327925920486
batch reward last col mean 0.11005976796150208 first col mean 0.1111828088760376 all mean 0.11134374886751175
0.28917431831359863 0.28917431831359863
rl training, epoch5, iter0, batch1130/1133, batch loss:0.28917431831359863, Training time:18318.09743618965
batch reward last col mean 0.10090915113687515 first col mean 0.11725286394357681 all mean 0.1057923212647438
0.30839860439300537 0.30839860439300537
rl training, epoch5, iter0, batch1131/1133, batch loss:0.30839860439300537, Training time:18319.949953317642
batch reward last col mean 0.10324371606111526 first col mean 0.11935370415449142 all mean 0.10683555901050568
0.3131842017173767 0.3131842017173767
rl training, epoch5, iter0, batch1132/1133, batch loss:0.3131842017173767, Training time:18322.29589509964
rl training, epoch 5, iter 0, loss:0.2905646867307013, Training time:18322.296107769012 
rl epoch 5, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 3.0226813673657436 Time: 127.60711598396301 s
rl epoch 5, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4699548196971469 Time: 98.35507035255432 s
loss of true 0.20158146031115398 loss of gen 0.16711824761484959 loss of other 0.101255111591948 first score 0.10532689094543457
rl epoch 6, begin RL for generator...
batch reward last col mean 0.11999770998954773 first col mean 0.10428346693515778 all mean 0.11036886274814606
0.28746452927589417 0.28746452927589417
rl training, epoch6, iter0, batch0/1133, batch loss:0.28746452927589417, Training time:18550.556571483612
batch reward last col mean 0.10125432908535004 first col mean 0.1136135682463646 all mean 0.09736502915620804
0.2837311029434204 0.283731073141098
rl training, epoch6, iter0, batch1/1133, batch loss:0.283731073141098, Training time:18552.908128738403
batch reward last col mean 0.08303619176149368 first col mean 0.09922352433204651 all mean 0.08566004782915115
0.22857429087162018 0.22857429087162018
rl training, epoch6, iter0, batch2/1133, batch loss:0.22857429087162018, Training time:18554.750802755356
batch reward last col mean 0.11485457420349121 first col mean 0.1266699731349945 all mean 0.11632686853408813
0.32409605383872986 0.32409605383872986
rl training, epoch6, iter0, batch3/1133, batch loss:0.32409605383872986, Training time:18557.514664888382
batch reward last col mean 0.09917297214269638 first col mean 0.1013883426785469 all mean 0.09596177935600281
0.2746568024158478 0.2746568024158478
rl training, epoch6, iter0, batch4/1133, batch loss:0.2746568024158478, Training time:18559.55147743225
batch reward last col mean 0.06950296461582184 first col mean 0.10274332761764526 all mean 0.07850093394517899
0.24963180720806122 0.24963180720806122
rl training, epoch6, iter0, batch5/1133, batch loss:0.24963180720806122, Training time:18562.124481916428
batch reward last col mean 0.13016217947006226 first col mean 0.09016609936952591 all mean 0.11692748963832855
0.27315011620521545 0.27315011620521545
rl training, epoch6, iter0, batch6/1133, batch loss:0.27315011620521545, Training time:18564.20213150978
batch reward last col mean 0.10471297800540924 first col mean 0.10062868893146515 all mean 0.10540490597486496
0.313900351524353 0.313900351524353
rl training, epoch6, iter0, batch7/1133, batch loss:0.313900351524353, Training time:18566.65535378456
batch reward last col mean 0.0735497772693634 first col mean 0.09031964093446732 all mean 0.08123568445444107
0.3098622262477875 0.3098622262477875
rl training, epoch6, iter0, batch8/1133, batch loss:0.3098622262477875, Training time:18568.8895111084
batch reward last col mean 0.1063191369175911 first col mean 0.09851378947496414 all mean 0.10398709774017334
0.282882422208786 0.282882422208786
rl training, epoch6, iter0, batch9/1133, batch loss:0.282882422208786, Training time:18570.944370269775
batch reward last col mean 0.07851129025220871 first col mean 0.10670212656259537 all mean 0.08274643868207932
0.2742519676685333 0.2742520272731781
rl training, epoch6, iter0, batch10/1133, batch loss:0.2742520272731781, Training time:18573.648850679398
batch reward last col mean 0.09836085140705109 first col mean 0.12094639241695404 all mean 0.09848392754793167
0.25582730770111084 0.25582730770111084
rl training, epoch6, iter0, batch11/1133, batch loss:0.25582730770111084, Training time:18576.62805700302
batch reward last col mean 0.07930874079465866 first col mean 0.10543264448642731 all mean 0.08192350715398788
0.25990045070648193 0.25990045070648193
rl training, epoch6, iter0, batch12/1133, batch loss:0.25990045070648193, Training time:18581.845934152603
batch reward last col mean 0.10667483508586884 first col mean 0.10248330980539322 all mean 0.10463577508926392
0.2599174976348877 0.2599174976348877
rl training, epoch6, iter0, batch13/1133, batch loss:0.2599174976348877, Training time:18584.280781507492
batch reward last col mean 0.12024906277656555 first col mean 0.10819244384765625 all mean 0.11504312604665756
0.2900450527667999 0.2900450527667999
rl training, epoch6, iter0, batch14/1133, batch loss:0.2900450527667999, Training time:18587.07164669037
batch reward last col mean 0.11348901689052582 first col mean 0.11164164543151855 all mean 0.10630565136671066
0.3087933361530304 0.308793306350708
rl training, epoch6, iter0, batch15/1133, batch loss:0.308793306350708, Training time:18588.934525728226
batch reward last col mean 0.12822026014328003 first col mean 0.09524132311344147 all mean 0.1201145127415657
0.31277164816856384 0.31277164816856384
rl training, epoch6, iter0, batch16/1133, batch loss:0.31277164816856384, Training time:18591.273923397064
batch reward last col mean 0.11035685241222382 first col mean 0.0912170559167862 all mean 0.11493872851133347
0.29822832345962524 0.29822832345962524
rl training, epoch6, iter0, batch17/1133, batch loss:0.29822832345962524, Training time:18593.901265382767
batch reward last col mean 0.09107723832130432 first col mean 0.0973515510559082 all mean 0.09953925758600235
0.2632507383823395 0.2632507383823395
rl training, epoch6, iter0, batch18/1133, batch loss:0.2632507383823395, Training time:18595.86668944359
batch reward last col mean 0.09528924524784088 first col mean 0.10057336091995239 all mean 0.09375397115945816
0.22391153872013092 0.22391153872013092
rl training, epoch6, iter0, batch19/1133, batch loss:0.22391153872013092, Training time:18597.809822797775
batch reward last col mean 0.10028479248285294 first col mean 0.1008920669555664 all mean 0.09740922600030899
0.2647635042667389 0.2647635042667389
rl training, epoch6, iter0, batch20/1133, batch loss:0.2647635042667389, Training time:18600.444174528122
batch reward last col mean 0.10923173278570175 first col mean 0.09841061383485794 all mean 0.1057911068201065
0.2828081250190735 0.2828081250190735
rl training, epoch6, iter0, batch21/1133, batch loss:0.2828081250190735, Training time:18602.85956263542
batch reward last col mean 0.10692821443080902 first col mean 0.09889563918113708 all mean 0.10370410233736038
0.24488870799541473 0.24488870799541473
rl training, epoch6, iter0, batch22/1133, batch loss:0.24488870799541473, Training time:18604.854072093964
batch reward last col mean 0.10976400226354599 first col mean 0.1060924306511879 all mean 0.11058016866445541
0.3163622319698334 0.3163622319698334
rl training, epoch6, iter0, batch23/1133, batch loss:0.3163622319698334, Training time:18607.17198228836
batch reward last col mean 0.08874183893203735 first col mean 0.09715775400400162 all mean 0.08883177489042282
0.2651805281639099 0.2651805281639099
rl training, epoch6, iter0, batch24/1133, batch loss:0.2651805281639099, Training time:18610.62936592102
batch reward last col mean 0.14308254420757294 first col mean 0.11629005521535873 all mean 0.12354686111211777
0.3120129108428955 0.3120129108428955
rl training, epoch6, iter0, batch25/1133, batch loss:0.3120129108428955, Training time:18612.938868284225
batch reward last col mean 0.08837327361106873 first col mean 0.10401161015033722 all mean 0.09289774298667908
0.2801234722137451 0.2801234722137451
rl training, epoch6, iter0, batch26/1133, batch loss:0.2801234722137451, Training time:18616.249582529068
batch reward last col mean 0.10405422002077103 first col mean 0.11798247694969177 all mean 0.10320504754781723
0.2989112436771393 0.2989112436771393
rl training, epoch6, iter0, batch27/1133, batch loss:0.2989112436771393, Training time:18619.1104118824
batch reward last col mean 0.10720687359571457 first col mean 0.11276129633188248 all mean 0.10948395729064941
0.2705846130847931 0.2705846130847931
rl training, epoch6, iter0, batch28/1133, batch loss:0.2705846130847931, Training time:18622.580235242844
batch reward last col mean 0.10639394074678421 first col mean 0.08841405808925629 all mean 0.11201997101306915
0.30993688106536865 0.30993688106536865
rl training, epoch6, iter0, batch29/1133, batch loss:0.30993688106536865, Training time:18624.65215420723
batch reward last col mean 0.09736429899930954 first col mean 0.10226728022098541 all mean 0.0955607146024704
0.26146531105041504 0.26146531105041504
rl training, epoch6, iter0, batch30/1133, batch loss:0.26146531105041504, Training time:18627.137355327606
batch reward last col mean 0.08553535491228104 first col mean 0.11360824853181839 all mean 0.0909581109881401
0.2891933023929596 0.2891933023929596
rl training, epoch6, iter0, batch31/1133, batch loss:0.2891933023929596, Training time:18629.728398561478
batch reward last col mean 0.0727454423904419 first col mean 0.10382705181837082 all mean 0.08015535771846771
0.23774224519729614 0.23774224519729614
rl training, epoch6, iter0, batch32/1133, batch loss:0.23774224519729614, Training time:18632.111509799957
batch reward last col mean 0.09337854385375977 first col mean 0.11448781192302704 all mean 0.09501095861196518
0.2373289167881012 0.23732887208461761
rl training, epoch6, iter0, batch33/1133, batch loss:0.23732887208461761, Training time:18634.588078975677
batch reward last col mean 0.08792861551046371 first col mean 0.10010936856269836 all mean 0.09030376374721527
0.26894015073776245 0.26894012093544006
rl training, epoch6, iter0, batch34/1133, batch loss:0.26894012093544006, Training time:18636.809335947037
batch reward last col mean 0.09154856950044632 first col mean 0.09757905453443527 all mean 0.09316814690828323
0.2919042110443115 0.2919042110443115
rl training, epoch6, iter0, batch35/1133, batch loss:0.2919042110443115, Training time:18639.47419333458
batch reward last col mean 0.1327221393585205 first col mean 0.10659409314393997 all mean 0.12594985961914062
0.2892821133136749 0.28928208351135254
rl training, epoch6, iter0, batch36/1133, batch loss:0.28928208351135254, Training time:18641.93695473671
batch reward last col mean 0.09550169110298157 first col mean 0.10949130356311798 all mean 0.09554344415664673
0.24342185258865356 0.24342185258865356
rl training, epoch6, iter0, batch37/1133, batch loss:0.24342185258865356, Training time:18644.2135014534
batch reward last col mean 0.05907783657312393 first col mean 0.11328351497650146 all mean 0.0693962350487709
0.24530483782291412 0.24530483782291412
rl training, epoch6, iter0, batch38/1133, batch loss:0.24530483782291412, Training time:18646.81504058838
batch reward last col mean 0.07523742318153381 first col mean 0.0970321074128151 all mean 0.08165841549634933
0.23396725952625275 0.23396725952625275
rl training, epoch6, iter0, batch39/1133, batch loss:0.23396725952625275, Training time:18648.959857463837
batch reward last col mean 0.0910484567284584 first col mean 0.1100752055644989 all mean 0.0949680358171463
0.2880685031414032 0.2880685031414032
rl training, epoch6, iter0, batch40/1133, batch loss:0.2880685031414032, Training time:18651.10958123207
batch reward last col mean 0.09786897897720337 first col mean 0.10653430223464966 all mean 0.09958058595657349
0.26005393266677856 0.26005393266677856
rl training, epoch6, iter0, batch41/1133, batch loss:0.26005393266677856, Training time:18653.595266342163
batch reward last col mean 0.11362969875335693 first col mean 0.11721735447645187 all mean 0.1118176281452179
0.32716408371925354 0.32716408371925354
rl training, epoch6, iter0, batch42/1133, batch loss:0.32716408371925354, Training time:18655.968489408493
batch reward last col mean 0.08761696517467499 first col mean 0.09789127856492996 all mean 0.0879305899143219
0.22675859928131104 0.22675859928131104
rl training, epoch6, iter0, batch43/1133, batch loss:0.22675859928131104, Training time:18658.29613494873
batch reward last col mean 0.09613247215747833 first col mean 0.09662483632564545 all mean 0.09848684817552567
0.28719139099121094 0.28719139099121094
rl training, epoch6, iter0, batch44/1133, batch loss:0.28719139099121094, Training time:18662.954783201218
batch reward last col mean 0.09850859642028809 first col mean 0.11298085749149323 all mean 0.1036108136177063
0.28433769941329956 0.28433769941329956
rl training, epoch6, iter0, batch45/1133, batch loss:0.28433769941329956, Training time:18664.738905906677
batch reward last col mean 0.10488409548997879 first col mean 0.0914125144481659 all mean 0.10097075253725052
0.27375882863998413 0.27375882863998413
rl training, epoch6, iter0, batch46/1133, batch loss:0.27375882863998413, Training time:18667.02072930336
batch reward last col mean 0.09403593093156815 first col mean 0.1005222499370575 all mean 0.09459981322288513
0.25016680359840393 0.25016680359840393
rl training, epoch6, iter0, batch47/1133, batch loss:0.25016680359840393, Training time:18669.00023341179
batch reward last col mean 0.09081607311964035 first col mean 0.09434331208467484 all mean 0.09452216327190399
0.27109870314598083 0.27109870314598083
rl training, epoch6, iter0, batch48/1133, batch loss:0.27109870314598083, Training time:18672.011589050293
batch reward last col mean 0.08230075240135193 first col mean 0.09671463817358017 all mean 0.08755609393119812
0.2746637463569641 0.2746637463569641
rl training, epoch6, iter0, batch49/1133, batch loss:0.2746637463569641, Training time:18674.05699467659
batch reward last col mean 0.061247389763593674 first col mean 0.10342996567487717 all mean 0.07690532505512238
0.25727972388267517 0.25727975368499756
rl training, epoch6, iter0, batch50/1133, batch loss:0.25727975368499756, Training time:18675.965048074722
batch reward last col mean 0.09607823938131332 first col mean 0.10386019200086594 all mean 0.10211959481239319
0.3126673400402069 0.3126673400402069
rl training, epoch6, iter0, batch51/1133, batch loss:0.3126673400402069, Training time:18678.001173496246
batch reward last col mean 0.10690851509571075 first col mean 0.10782530158758163 all mean 0.10686296224594116
0.3216094970703125 0.3216094970703125
rl training, epoch6, iter0, batch52/1133, batch loss:0.3216094970703125, Training time:18680.19894552231
batch reward last col mean 0.098995640873909 first col mean 0.10449770092964172 all mean 0.10034912079572678
0.3094744086265564 0.3094744086265564
rl training, epoch6, iter0, batch53/1133, batch loss:0.3094744086265564, Training time:18682.50838494301
batch reward last col mean 0.07008323073387146 first col mean 0.09039637446403503 all mean 0.08170052617788315
0.23693005740642548 0.23693005740642548
rl training, epoch6, iter0, batch54/1133, batch loss:0.23693005740642548, Training time:18684.743724107742
batch reward last col mean 0.09824644029140472 first col mean 0.10811509191989899 all mean 0.09543903172016144
0.29300040006637573 0.29300040006637573
rl training, epoch6, iter0, batch55/1133, batch loss:0.29300040006637573, Training time:18688.218666791916
batch reward last col mean 0.07457105070352554 first col mean 0.10953763127326965 all mean 0.08511317521333694
0.2765045762062073 0.27650460600852966
rl training, epoch6, iter0, batch56/1133, batch loss:0.27650460600852966, Training time:18690.660787820816
batch reward last col mean 0.0813046544790268 first col mean 0.10417290776968002 all mean 0.08292916417121887
0.23935267329216003 0.23935267329216003
rl training, epoch6, iter0, batch57/1133, batch loss:0.23935267329216003, Training time:18693.108328580856
batch reward last col mean 0.0780743882060051 first col mean 0.13126887381076813 all mean 0.08490737527608871
0.2604914605617523 0.2604914605617523
rl training, epoch6, iter0, batch58/1133, batch loss:0.2604914605617523, Training time:18696.220987558365
batch reward last col mean 0.09421904385089874 first col mean 0.10030502080917358 all mean 0.0969645082950592
0.26710355281829834 0.26710355281829834
rl training, epoch6, iter0, batch59/1133, batch loss:0.26710355281829834, Training time:18698.663976192474
batch reward last col mean 0.13430246710777283 first col mean 0.10191769897937775 all mean 0.13044172525405884
0.2994959354400635 0.2994959354400635
rl training, epoch6, iter0, batch60/1133, batch loss:0.2994959354400635, Training time:18702.15947651863
batch reward last col mean 0.09331831336021423 first col mean 0.10290740430355072 all mean 0.09473183006048203
0.25123152136802673 0.2512315511703491
rl training, epoch6, iter0, batch61/1133, batch loss:0.2512315511703491, Training time:18704.086621046066
batch reward last col mean 0.0885259360074997 first col mean 0.0982045978307724 all mean 0.09496641159057617
0.26453790068626404 0.26453790068626404
rl training, epoch6, iter0, batch62/1133, batch loss:0.26453790068626404, Training time:18706.251044273376
batch reward last col mean 0.08976304531097412 first col mean 0.09435932338237762 all mean 0.08887601643800735
0.2651563286781311 0.2651562988758087
rl training, epoch6, iter0, batch63/1133, batch loss:0.2651562988758087, Training time:18708.98570728302
batch reward last col mean 0.06973817944526672 first col mean 0.11341626942157745 all mean 0.08642421662807465
0.3061661124229431 0.3061661422252655
rl training, epoch6, iter0, batch64/1133, batch loss:0.3061661422252655, Training time:18710.58292365074
batch reward last col mean 0.07931976765394211 first col mean 0.1179046779870987 all mean 0.08262812346220016
0.2615182399749756 0.2615182399749756
rl training, epoch6, iter0, batch65/1133, batch loss:0.2615182399749756, Training time:18712.896107196808
batch reward last col mean 0.09386292845010757 first col mean 0.11636895686388016 all mean 0.09253734350204468
0.26377084851264954 0.26377084851264954
rl training, epoch6, iter0, batch66/1133, batch loss:0.26377084851264954, Training time:18714.603336572647
batch reward last col mean 0.09069862216711044 first col mean 0.10120763629674911 all mean 0.09417905658483505
0.267500638961792 0.267500638961792
rl training, epoch6, iter0, batch67/1133, batch loss:0.267500638961792, Training time:18716.899490356445
batch reward last col mean 0.1201290637254715 first col mean 0.10036275535821915 all mean 0.11641309410333633
0.27390775084495544 0.27390775084495544
rl training, epoch6, iter0, batch68/1133, batch loss:0.27390775084495544, Training time:18718.921140432358
batch reward last col mean 0.07248998433351517 first col mean 0.09015443921089172 all mean 0.07977975159883499
0.23251934349536896 0.23251934349536896
rl training, epoch6, iter0, batch69/1133, batch loss:0.23251934349536896, Training time:18721.30649137497
batch reward last col mean 0.09621687978506088 first col mean 0.0996040552854538 all mean 0.0950464978814125
0.25830745697021484 0.25830745697021484
rl training, epoch6, iter0, batch70/1133, batch loss:0.25830745697021484, Training time:18723.19871854782
batch reward last col mean 0.1000765934586525 first col mean 0.10008691251277924 all mean 0.10336335003376007
0.3081934154033661 0.3081934154033661
rl training, epoch6, iter0, batch71/1133, batch loss:0.3081934154033661, Training time:18725.546181678772
batch reward last col mean 0.11133329570293427 first col mean 0.12504813075065613 all mean 0.11208758503198624
0.2857801616191864 0.2857801616191864
rl training, epoch6, iter0, batch72/1133, batch loss:0.2857801616191864, Training time:18728.32739853859
batch reward last col mean 0.1501905918121338 first col mean 0.10999786108732224 all mean 0.13616886734962463
0.3444872200489044 0.3444872200489044
rl training, epoch6, iter0, batch73/1133, batch loss:0.3444872200489044, Training time:18730.646950244904
batch reward last col mean 0.09966020286083221 first col mean 0.1013823002576828 all mean 0.09879806637763977
0.27090978622436523 0.27090978622436523
rl training, epoch6, iter0, batch74/1133, batch loss:0.27090978622436523, Training time:18732.52950167656
batch reward last col mean 0.11646430194377899 first col mean 0.10389547049999237 all mean 0.1168908029794693
0.3003075122833252 0.3003075122833252
rl training, epoch6, iter0, batch75/1133, batch loss:0.3003075122833252, Training time:18734.716430664062
batch reward last col mean 0.10493204742670059 first col mean 0.11742573976516724 all mean 0.10680671781301498
0.2939664125442505 0.2939664125442505
rl training, epoch6, iter0, batch76/1133, batch loss:0.2939664125442505, Training time:18736.99337887764
batch reward last col mean 0.13732662796974182 first col mean 0.11562466621398926 all mean 0.12998870015144348
0.32363808155059814 0.32363808155059814
rl training, epoch6, iter0, batch77/1133, batch loss:0.32363808155059814, Training time:18738.948347091675
batch reward last col mean 0.09354513883590698 first col mean 0.11372344195842743 all mean 0.09958954155445099
0.25808030366897583 0.25808030366897583
rl training, epoch6, iter0, batch78/1133, batch loss:0.25808030366897583, Training time:18740.817800045013
batch reward last col mean 0.09783616662025452 first col mean 0.11208810657262802 all mean 0.10408993810415268
0.31832075119018555 0.31832072138786316
rl training, epoch6, iter0, batch79/1133, batch loss:0.31832072138786316, Training time:18742.828793764114
batch reward last col mean 0.10462093353271484 first col mean 0.10934267938137054 all mean 0.10786892473697662
0.29481935501098633 0.29481932520866394
rl training, epoch6, iter0, batch80/1133, batch loss:0.29481932520866394, Training time:18745.03369832039
batch reward last col mean 0.07851870357990265 first col mean 0.1007128432393074 all mean 0.08638709038496017
0.2334355264902115 0.2334355264902115
rl training, epoch6, iter0, batch81/1133, batch loss:0.2334355264902115, Training time:18746.875781297684
batch reward last col mean 0.09334680438041687 first col mean 0.10468627512454987 all mean 0.09895525872707367
0.2765963077545166 0.2765963077545166
rl training, epoch6, iter0, batch82/1133, batch loss:0.2765963077545166, Training time:18749.12947535515
batch reward last col mean 0.08153796195983887 first col mean 0.1075015738606453 all mean 0.08807943016290665
0.24221152067184448 0.24221152067184448
rl training, epoch6, iter0, batch83/1133, batch loss:0.24221152067184448, Training time:18751.67540383339
batch reward last col mean 0.09848348796367645 first col mean 0.09478750079870224 all mean 0.09210439771413803
0.24777090549468994 0.24777090549468994
rl training, epoch6, iter0, batch84/1133, batch loss:0.24777090549468994, Training time:18753.93026661873
batch reward last col mean 0.09655461460351944 first col mean 0.1037566214799881 all mean 0.09649311751127243
0.2855178117752075 0.2855178117752075
rl training, epoch6, iter0, batch85/1133, batch loss:0.2855178117752075, Training time:18756.644692897797
batch reward last col mean 0.10553360730409622 first col mean 0.12203992158174515 all mean 0.10239298641681671
0.2831956446170807 0.2831956744194031
rl training, epoch6, iter0, batch86/1133, batch loss:0.2831956744194031, Training time:18758.68976354599
batch reward last col mean 0.11571657657623291 first col mean 0.09325718879699707 all mean 0.11195021867752075
0.2780998945236206 0.2780998945236206
rl training, epoch6, iter0, batch87/1133, batch loss:0.2780998945236206, Training time:18760.604380607605
batch reward last col mean 0.1212150901556015 first col mean 0.11240312457084656 all mean 0.11933381110429764
0.275726854801178 0.2757268249988556
rl training, epoch6, iter0, batch88/1133, batch loss:0.2757268249988556, Training time:18762.758338689804
batch reward last col mean 0.10957296192646027 first col mean 0.10321027040481567 all mean 0.10698237270116806
0.2644352912902832 0.2644352912902832
rl training, epoch6, iter0, batch89/1133, batch loss:0.2644352912902832, Training time:18764.658038377762
batch reward last col mean 0.10543242841959 first col mean 0.13575762510299683 all mean 0.10844533145427704
0.2782486379146576 0.2782486379146576
rl training, epoch6, iter0, batch90/1133, batch loss:0.2782486379146576, Training time:18766.840801000595
batch reward last col mean 0.10267791152000427 first col mean 0.09324155002832413 all mean 0.10613793879747391
0.2805584669113159 0.2805584669113159
rl training, epoch6, iter0, batch91/1133, batch loss:0.2805584669113159, Training time:18769.226224422455
batch reward last col mean 0.08546888083219528 first col mean 0.11291377246379852 all mean 0.09318177402019501
0.2541244924068451 0.2541244328022003
rl training, epoch6, iter0, batch92/1133, batch loss:0.2541244328022003, Training time:18771.541163682938
batch reward last col mean 0.10533443838357925 first col mean 0.11409760266542435 all mean 0.10316117852926254
0.2642640173435211 0.2642640173435211
rl training, epoch6, iter0, batch93/1133, batch loss:0.2642640173435211, Training time:18773.508232355118
batch reward last col mean 0.13325896859169006 first col mean 0.09551071375608444 all mean 0.11895980685949326
0.29704564809799194 0.29704564809799194
rl training, epoch6, iter0, batch94/1133, batch loss:0.29704564809799194, Training time:18775.306574344635
batch reward last col mean 0.10478468239307404 first col mean 0.10471953451633453 all mean 0.10381905734539032
0.28355172276496887 0.28355172276496887
rl training, epoch6, iter0, batch95/1133, batch loss:0.28355172276496887, Training time:18777.276078939438
batch reward last col mean 0.107693150639534 first col mean 0.11547406017780304 all mean 0.11100791394710541
0.3338591754436493 0.3338591754436493
rl training, epoch6, iter0, batch96/1133, batch loss:0.3338591754436493, Training time:18780.292912006378
batch reward last col mean 0.07549811154603958 first col mean 0.10737965255975723 all mean 0.08027216792106628
0.24985291063785553 0.24985291063785553
rl training, epoch6, iter0, batch97/1133, batch loss:0.24985291063785553, Training time:18782.98174405098
batch reward last col mean 0.1288718581199646 first col mean 0.10980569571256638 all mean 0.12169760465621948
0.2814556062221527 0.2814556062221527
rl training, epoch6, iter0, batch98/1133, batch loss:0.2814556062221527, Training time:18785.389012813568
batch reward last col mean 0.08745063096284866 first col mean 0.09160156548023224 all mean 0.08983452618122101
0.2610214054584503 0.2610214054584503
rl training, epoch6, iter0, batch99/1133, batch loss:0.2610214054584503, Training time:18787.744261980057
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47271238128011034 Time: 96.0725257396698 s
loss of true 0.20393561044443212 loss of gen 0.16789711295690352 loss of other 0.10087965732803675 first score 0.09917312860488892
batch reward last col mean 0.10124930739402771 first col mean 0.12526658177375793 all mean 0.10338563472032547
0.2662656307220459 0.2662656307220459
rl training, epoch6, iter0, batch100/1133, batch loss:0.2662656307220459, Training time:18886.04670548439
batch reward last col mean 0.09211957454681396 first col mean 0.1109568402171135 all mean 0.0971013680100441
0.2879374623298645 0.2879374623298645
rl training, epoch6, iter0, batch101/1133, batch loss:0.2879374623298645, Training time:18887.897711992264
batch reward last col mean 0.09642535448074341 first col mean 0.08938877284526825 all mean 0.10053806006908417
0.2554296553134918 0.2554296553134918
rl training, epoch6, iter0, batch102/1133, batch loss:0.2554296553134918, Training time:18890.068336486816
batch reward last col mean 0.10664871335029602 first col mean 0.1122722327709198 all mean 0.10942404717206955
0.27535679936408997 0.2753567695617676
rl training, epoch6, iter0, batch103/1133, batch loss:0.2753567695617676, Training time:18892.19774413109
batch reward last col mean 0.09550386667251587 first col mean 0.11286354809999466 all mean 0.09642734378576279
0.24915020167827606 0.24915020167827606
rl training, epoch6, iter0, batch104/1133, batch loss:0.24915020167827606, Training time:18894.69354248047
batch reward last col mean 0.09336620569229126 first col mean 0.09399868547916412 all mean 0.09839919209480286
0.25015008449554443 0.25015008449554443
rl training, epoch6, iter0, batch105/1133, batch loss:0.25015008449554443, Training time:18896.917246341705
batch reward last col mean 0.10439722239971161 first col mean 0.10753466188907623 all mean 0.10365071147680283
0.27765634655952454 0.2776563763618469
rl training, epoch6, iter0, batch106/1133, batch loss:0.2776563763618469, Training time:18898.502387285233
batch reward last col mean 0.11497088521718979 first col mean 0.12678438425064087 all mean 0.11339246481657028
0.30464300513267517 0.30464300513267517
rl training, epoch6, iter0, batch107/1133, batch loss:0.30464300513267517, Training time:18900.09695124626
batch reward last col mean 0.10081346333026886 first col mean 0.10219350457191467 all mean 0.10175107419490814
0.2806350290775299 0.2806350290775299
rl training, epoch6, iter0, batch108/1133, batch loss:0.2806350290775299, Training time:18901.747644662857
batch reward last col mean 0.1307087242603302 first col mean 0.10937942564487457 all mean 0.12629923224449158
0.2773812711238861 0.2773812711238861
rl training, epoch6, iter0, batch109/1133, batch loss:0.2773812711238861, Training time:18903.894009828568
batch reward last col mean 0.11611516028642654 first col mean 0.11526991426944733 all mean 0.1175088882446289
0.3080958127975464 0.3080958127975464
rl training, epoch6, iter0, batch110/1133, batch loss:0.3080958127975464, Training time:18906.905427455902
batch reward last col mean 0.07229267805814743 first col mean 0.11370154470205307 all mean 0.07813037186861038
0.24485617876052856 0.24485619366168976
rl training, epoch6, iter0, batch111/1133, batch loss:0.24485619366168976, Training time:18908.994017362595
batch reward last col mean 0.10814568400382996 first col mean 0.10577084124088287 all mean 0.10592945665121078
0.29937824606895447 0.29937824606895447
rl training, epoch6, iter0, batch112/1133, batch loss:0.29937824606895447, Training time:18910.535204410553
batch reward last col mean 0.09721700847148895 first col mean 0.11382697522640228 all mean 0.0986034944653511
0.29078447818756104 0.29078447818756104
rl training, epoch6, iter0, batch113/1133, batch loss:0.29078447818756104, Training time:18912.407178401947
batch reward last col mean 0.08256474137306213 first col mean 0.1062810868024826 all mean 0.08654259145259857
0.2518776059150696 0.2518776059150696
rl training, epoch6, iter0, batch114/1133, batch loss:0.2518776059150696, Training time:18914.674944877625
batch reward last col mean 0.13665273785591125 first col mean 0.1251770555973053 all mean 0.13150730729103088
0.3124992847442627 0.3124993145465851
rl training, epoch6, iter0, batch115/1133, batch loss:0.3124993145465851, Training time:18917.388847112656
batch reward last col mean 0.09905139356851578 first col mean 0.11568054556846619 all mean 0.0984671488404274
0.272982120513916 0.272982120513916
rl training, epoch6, iter0, batch116/1133, batch loss:0.272982120513916, Training time:18919.139189481735
batch reward last col mean 0.06901056319475174 first col mean 0.09887678921222687 all mean 0.08293035626411438
0.2627944052219391 0.2627944052219391
rl training, epoch6, iter0, batch117/1133, batch loss:0.2627944052219391, Training time:18920.787692070007
batch reward last col mean 0.0885397270321846 first col mean 0.1119237095117569 all mean 0.09900086373090744
0.3091181814670563 0.3091181814670563
rl training, epoch6, iter0, batch118/1133, batch loss:0.3091181814670563, Training time:18922.68063879013
batch reward last col mean 0.15280447900295258 first col mean 0.10422865301370621 all mean 0.13346506655216217
0.29944342374801636 0.29944345355033875
rl training, epoch6, iter0, batch119/1133, batch loss:0.29944345355033875, Training time:18924.796521663666
batch reward last col mean 0.15564139187335968 first col mean 0.10873262584209442 all mean 0.13872109353542328
0.3042820990085602 0.3042820990085602
rl training, epoch6, iter0, batch120/1133, batch loss:0.3042820990085602, Training time:18926.81840610504
batch reward last col mean 0.11261594295501709 first col mean 0.09808070212602615 all mean 0.11105459928512573
0.2598003149032593 0.2598003149032593
rl training, epoch6, iter0, batch121/1133, batch loss:0.2598003149032593, Training time:18928.77637863159
batch reward last col mean 0.12881794571876526 first col mean 0.09405827522277832 all mean 0.11936334520578384
0.2859169840812683 0.2859169840812683
rl training, epoch6, iter0, batch122/1133, batch loss:0.2859169840812683, Training time:18930.25353550911
batch reward last col mean 0.07973823696374893 first col mean 0.08956608176231384 all mean 0.08575723320245743
0.20832416415214539 0.20832416415214539
rl training, epoch6, iter0, batch123/1133, batch loss:0.20832416415214539, Training time:18932.073130846024
batch reward last col mean 0.08682692795991898 first col mean 0.12163648754358292 all mean 0.08966923505067825
0.25480854511260986 0.25480854511260986
rl training, epoch6, iter0, batch124/1133, batch loss:0.25480854511260986, Training time:18934.055469751358
batch reward last col mean 0.12462015450000763 first col mean 0.11187820136547089 all mean 0.12457989901304245
0.32355526089668274 0.32355526089668274
rl training, epoch6, iter0, batch125/1133, batch loss:0.32355526089668274, Training time:18936.711668491364
batch reward last col mean 0.10613727569580078 first col mean 0.09836438298225403 all mean 0.10145625472068787
0.27153098583221436 0.27153098583221436
rl training, epoch6, iter0, batch126/1133, batch loss:0.27153098583221436, Training time:18938.389981269836
batch reward last col mean 0.08958538621664047 first col mean 0.11118045449256897 all mean 0.09436459094285965
0.293798565864563 0.293798565864563
rl training, epoch6, iter0, batch127/1133, batch loss:0.293798565864563, Training time:18940.64357161522
batch reward last col mean 0.08315332233905792 first col mean 0.09730736911296844 all mean 0.09080920368432999
0.26169124245643616 0.26169124245643616
rl training, epoch6, iter0, batch128/1133, batch loss:0.26169124245643616, Training time:18942.57296848297
batch reward last col mean 0.11659109592437744 first col mean 0.11528953909873962 all mean 0.11008826643228531
0.301789790391922 0.3017897605895996
rl training, epoch6, iter0, batch129/1133, batch loss:0.3017897605895996, Training time:18944.57450413704
batch reward last col mean 0.09110186994075775 first col mean 0.11124733835458755 all mean 0.09075985848903656
0.2665540277957916 0.2665540277957916
rl training, epoch6, iter0, batch130/1133, batch loss:0.2665540277957916, Training time:18947.08700609207
batch reward last col mean 0.1180814802646637 first col mean 0.09601448476314545 all mean 0.10983133316040039
0.3037862479686737 0.3037862479686737
rl training, epoch6, iter0, batch131/1133, batch loss:0.3037862479686737, Training time:18948.853489398956
batch reward last col mean 0.10280780494213104 first col mean 0.11500982940196991 all mean 0.10438056290149689
0.2848222255706787 0.2848222255706787
rl training, epoch6, iter0, batch132/1133, batch loss:0.2848222255706787, Training time:18950.576890707016
batch reward last col mean 0.11332110315561295 first col mean 0.11314801871776581 all mean 0.10801272094249725
0.28840652108192444 0.28840652108192444
rl training, epoch6, iter0, batch133/1133, batch loss:0.28840652108192444, Training time:18952.802635908127
batch reward last col mean 0.11386539041996002 first col mean 0.10930760949850082 all mean 0.10895922780036926
0.2857964336872101 0.2857964336872101
rl training, epoch6, iter0, batch134/1133, batch loss:0.2857964336872101, Training time:18954.476996421814
batch reward last col mean 0.11131200939416885 first col mean 0.09460127353668213 all mean 0.10698075592517853
0.2733168601989746 0.2733168601989746
rl training, epoch6, iter0, batch135/1133, batch loss:0.2733168601989746, Training time:18957.14976787567
batch reward last col mean 0.10727503895759583 first col mean 0.11475421488285065 all mean 0.10389523208141327
0.286235511302948 0.286235511302948
rl training, epoch6, iter0, batch136/1133, batch loss:0.286235511302948, Training time:18959.22342967987
batch reward last col mean 0.09757132083177567 first col mean 0.12304174900054932 all mean 0.10074224323034286
0.3130497932434082 0.3130497932434082
rl training, epoch6, iter0, batch137/1133, batch loss:0.3130497932434082, Training time:18961.148635864258
batch reward last col mean 0.10381542146205902 first col mean 0.12806330621242523 all mean 0.10007344186306
0.2776558995246887 0.2776558995246887
rl training, epoch6, iter0, batch138/1133, batch loss:0.2776558995246887, Training time:18962.740735054016
batch reward last col mean 0.09094060957431793 first col mean 0.09859830886125565 all mean 0.09604816138744354
0.244490846991539 0.244490846991539
rl training, epoch6, iter0, batch139/1133, batch loss:0.244490846991539, Training time:18964.35873222351
batch reward last col mean 0.08606356382369995 first col mean 0.11433126777410507 all mean 0.09773331135511398
0.30916827917099 0.30916827917099
rl training, epoch6, iter0, batch140/1133, batch loss:0.30916827917099, Training time:18966.297227859497
batch reward last col mean 0.10590385645627975 first col mean 0.12130635976791382 all mean 0.11010603606700897
0.27155813574790955 0.27155813574790955
rl training, epoch6, iter0, batch141/1133, batch loss:0.27155813574790955, Training time:18968.30947303772
batch reward last col mean 0.08212394267320633 first col mean 0.09885352849960327 all mean 0.09209839254617691
0.27497902512550354 0.27497902512550354
rl training, epoch6, iter0, batch142/1133, batch loss:0.27497902512550354, Training time:18969.85772204399
batch reward last col mean 0.0965331420302391 first col mean 0.10326182842254639 all mean 0.09808715432882309
0.321956992149353 0.321956992149353
rl training, epoch6, iter0, batch143/1133, batch loss:0.321956992149353, Training time:18971.618088245392
batch reward last col mean 0.11173603683710098 first col mean 0.09447658061981201 all mean 0.1122039407491684
0.2796519696712494 0.2796519696712494
rl training, epoch6, iter0, batch144/1133, batch loss:0.2796519696712494, Training time:18973.335733890533
batch reward last col mean 0.10003530234098434 first col mean 0.12431290745735168 all mean 0.10012883692979813
0.2853774428367615 0.2853774130344391
rl training, epoch6, iter0, batch145/1133, batch loss:0.2853774130344391, Training time:18975.15363073349
batch reward last col mean 0.12336153537034988 first col mean 0.08906237781047821 all mean 0.1193188801407814
0.2832730710506439 0.2832730710506439
rl training, epoch6, iter0, batch146/1133, batch loss:0.2832730710506439, Training time:18977.05938601494
batch reward last col mean 0.13726094365119934 first col mean 0.1180042177438736 all mean 0.12302464246749878
0.2884904146194458 0.2884904146194458
rl training, epoch6, iter0, batch147/1133, batch loss:0.2884904146194458, Training time:18978.536429166794
batch reward last col mean 0.0841660276055336 first col mean 0.10019998252391815 all mean 0.08765742182731628
0.2658342123031616 0.2658342123031616
rl training, epoch6, iter0, batch148/1133, batch loss:0.2658342123031616, Training time:18980.64227437973
batch reward last col mean 0.07341230660676956 first col mean 0.10399245470762253 all mean 0.080657958984375
0.25781574845314026 0.25781574845314026
rl training, epoch6, iter0, batch149/1133, batch loss:0.25781574845314026, Training time:18982.165632486343
batch reward last col mean 0.08035068213939667 first col mean 0.10700507462024689 all mean 0.08768166601657867
0.2930852770805359 0.2930852770805359
rl training, epoch6, iter0, batch150/1133, batch loss:0.2930852770805359, Training time:18984.482065200806
batch reward last col mean 0.1168530285358429 first col mean 0.0967937707901001 all mean 0.11086062341928482
0.290223628282547 0.290223628282547
rl training, epoch6, iter0, batch151/1133, batch loss:0.290223628282547, Training time:18986.567834854126
batch reward last col mean 0.10111398249864578 first col mean 0.10423064231872559 all mean 0.10267927497625351
0.28803861141204834 0.28803861141204834
rl training, epoch6, iter0, batch152/1133, batch loss:0.28803861141204834, Training time:18988.969396829605
batch reward last col mean 0.13596303761005402 first col mean 0.10973809659481049 all mean 0.12524236738681793
0.2787523567676544 0.2787523567676544
rl training, epoch6, iter0, batch153/1133, batch loss:0.2787523567676544, Training time:18991.033322572708
batch reward last col mean 0.10406190156936646 first col mean 0.10602467507123947 all mean 0.10302387177944183
0.29930517077445984 0.29930517077445984
rl training, epoch6, iter0, batch154/1133, batch loss:0.29930517077445984, Training time:18992.85297560692
batch reward last col mean 0.08636526763439178 first col mean 0.12120622396469116 all mean 0.09412748366594315
0.31268858909606934 0.31268858909606934
rl training, epoch6, iter0, batch155/1133, batch loss:0.31268858909606934, Training time:18994.515616178513
batch reward last col mean 0.09379462152719498 first col mean 0.1287902295589447 all mean 0.09097567200660706
0.2525888979434967 0.2525888979434967
rl training, epoch6, iter0, batch156/1133, batch loss:0.2525888979434967, Training time:18996.2411339283
batch reward last col mean 0.09630537778139114 first col mean 0.11305990070104599 all mean 0.09726762026548386
0.2527315020561218 0.2527315020561218
rl training, epoch6, iter0, batch157/1133, batch loss:0.2527315020561218, Training time:18998.21684718132
batch reward last col mean 0.09705754369497299 first col mean 0.10152940452098846 all mean 0.09696461260318756
0.2931963801383972 0.29319635033607483
rl training, epoch6, iter0, batch158/1133, batch loss:0.29319635033607483, Training time:18999.695189237595
batch reward last col mean 0.08591178804636002 first col mean 0.1046861931681633 all mean 0.09136974811553955
0.27251696586608887 0.27251696586608887
rl training, epoch6, iter0, batch159/1133, batch loss:0.27251696586608887, Training time:19001.708236932755
batch reward last col mean 0.11462128162384033 first col mean 0.10238797962665558 all mean 0.11296102404594421
0.27189818024635315 0.27189818024635315
rl training, epoch6, iter0, batch160/1133, batch loss:0.27189818024635315, Training time:19003.219133138657
batch reward last col mean 0.10229673981666565 first col mean 0.09322789311408997 all mean 0.10748479515314102
0.3325643241405487 0.3325643241405487
rl training, epoch6, iter0, batch161/1133, batch loss:0.3325643241405487, Training time:19005.286563634872
batch reward last col mean 0.10318634659051895 first col mean 0.11052793264389038 all mean 0.10179320722818375
0.24576039612293243 0.24576039612293243
rl training, epoch6, iter0, batch162/1133, batch loss:0.24576039612293243, Training time:19007.11765885353
batch reward last col mean 0.08557434380054474 first col mean 0.12138224393129349 all mean 0.09157746285200119
0.27488210797309875 0.27488210797309875
rl training, epoch6, iter0, batch163/1133, batch loss:0.27488210797309875, Training time:19009.180418014526
batch reward last col mean 0.10760058462619781 first col mean 0.13565285503864288 all mean 0.11538364738225937
0.32292917370796204 0.32292917370796204
rl training, epoch6, iter0, batch164/1133, batch loss:0.32292917370796204, Training time:19011.224407434464
batch reward last col mean 0.10569141805171967 first col mean 0.12473013997077942 all mean 0.10823880881071091
0.32191091775894165 0.32191088795661926
rl training, epoch6, iter0, batch165/1133, batch loss:0.32191088795661926, Training time:19013.44081902504
batch reward last col mean 0.11231811344623566 first col mean 0.09991488605737686 all mean 0.11113105714321136
0.29328641295433044 0.29328641295433044
rl training, epoch6, iter0, batch166/1133, batch loss:0.29328641295433044, Training time:19015.684589624405
batch reward last col mean 0.11837208271026611 first col mean 0.12066693603992462 all mean 0.1188231110572815
0.3205993175506592 0.3205993175506592
rl training, epoch6, iter0, batch167/1133, batch loss:0.3205993175506592, Training time:19017.51563501358
batch reward last col mean 0.13626305758953094 first col mean 0.10177431255578995 all mean 0.13142548501491547
0.32038331031799316 0.32038331031799316
rl training, epoch6, iter0, batch168/1133, batch loss:0.32038331031799316, Training time:19019.92573094368
batch reward last col mean 0.11077914386987686 first col mean 0.10617474466562271 all mean 0.11091092228889465
0.26805368065834045 0.26805368065834045
rl training, epoch6, iter0, batch169/1133, batch loss:0.26805368065834045, Training time:19021.958827733994
batch reward last col mean 0.09630471467971802 first col mean 0.11034955084323883 all mean 0.10546215623617172
0.34651219844818115 0.34651219844818115
rl training, epoch6, iter0, batch170/1133, batch loss:0.34651219844818115, Training time:19024.100942134857
batch reward last col mean 0.10304755717515945 first col mean 0.10911647975444794 all mean 0.10766559839248657
0.2638474106788635 0.26384738087654114
rl training, epoch6, iter0, batch171/1133, batch loss:0.26384738087654114, Training time:19026.037300348282
batch reward last col mean 0.10828825831413269 first col mean 0.12064175307750702 all mean 0.10741126537322998
0.2661973834037781 0.26619741320610046
rl training, epoch6, iter0, batch172/1133, batch loss:0.26619741320610046, Training time:19028.23994064331
batch reward last col mean 0.09710147231817245 first col mean 0.11173012107610703 all mean 0.09936375916004181
0.24813894927501678 0.2481389343738556
rl training, epoch6, iter0, batch173/1133, batch loss:0.2481389343738556, Training time:19030.191437244415
batch reward last col mean 0.11277581751346588 first col mean 0.10261892527341843 all mean 0.11061181873083115
0.27641183137893677 0.27641183137893677
rl training, epoch6, iter0, batch174/1133, batch loss:0.27641183137893677, Training time:19032.68600153923
batch reward last col mean 0.11021150648593903 first col mean 0.11638307571411133 all mean 0.10912838578224182
0.2831522524356842 0.2831522524356842
rl training, epoch6, iter0, batch175/1133, batch loss:0.2831522524356842, Training time:19034.46657395363
batch reward last col mean 0.11088833212852478 first col mean 0.1204165443778038 all mean 0.10388463735580444
0.2891140282154083 0.2891140282154083
rl training, epoch6, iter0, batch176/1133, batch loss:0.2891140282154083, Training time:19036.221865415573
batch reward last col mean 0.08444343507289886 first col mean 0.1242561787366867 all mean 0.09446651488542557
0.291695773601532 0.2916957437992096
rl training, epoch6, iter0, batch177/1133, batch loss:0.2916957437992096, Training time:19038.1451587677
batch reward last col mean 0.14410251379013062 first col mean 0.10955635458230972 all mean 0.13844288885593414
0.34263136982917786 0.34263136982917786
rl training, epoch6, iter0, batch178/1133, batch loss:0.34263136982917786, Training time:19039.705283164978
batch reward last col mean 0.12479515373706818 first col mean 0.10391070693731308 all mean 0.11995834112167358
0.27902981638908386 0.27902981638908386
rl training, epoch6, iter0, batch179/1133, batch loss:0.27902981638908386, Training time:19041.220558404922
batch reward last col mean 0.08076684176921844 first col mean 0.1093803197145462 all mean 0.08763373643159866
0.2574898302555084 0.2574898302555084
rl training, epoch6, iter0, batch180/1133, batch loss:0.2574898302555084, Training time:19043.121027231216
batch reward last col mean 0.09036214649677277 first col mean 0.08268782496452332 all mean 0.09593749046325684
0.2627280652523041 0.2627280652523041
rl training, epoch6, iter0, batch181/1133, batch loss:0.2627280652523041, Training time:19044.84679031372
batch reward last col mean 0.11805194616317749 first col mean 0.11976845562458038 all mean 0.11968769133090973
0.3044886291027069 0.3044886291027069
rl training, epoch6, iter0, batch182/1133, batch loss:0.3044886291027069, Training time:19046.924145698547
batch reward last col mean 0.15232083201408386 first col mean 0.11574122309684753 all mean 0.14162592589855194
0.314651757478714 0.314651757478714
rl training, epoch6, iter0, batch183/1133, batch loss:0.314651757478714, Training time:19049.08435869217
batch reward last col mean 0.08201073110103607 first col mean 0.11371296644210815 all mean 0.09002795070409775
0.2667939364910126 0.2667939364910126
rl training, epoch6, iter0, batch184/1133, batch loss:0.2667939364910126, Training time:19051.625308275223
batch reward last col mean 0.14166676998138428 first col mean 0.12131014466285706 all mean 0.1360168755054474
0.2798522710800171 0.2798522710800171
rl training, epoch6, iter0, batch185/1133, batch loss:0.2798522710800171, Training time:19053.836270332336
batch reward last col mean 0.09228044748306274 first col mean 0.12109730392694473 all mean 0.10139147937297821
0.31703731417655945 0.31703731417655945
rl training, epoch6, iter0, batch186/1133, batch loss:0.31703731417655945, Training time:19055.753297567368
batch reward last col mean 0.11671839654445648 first col mean 0.11074554920196533 all mean 0.11768001317977905
0.28727129101753235 0.28727129101753235
rl training, epoch6, iter0, batch187/1133, batch loss:0.28727129101753235, Training time:19057.523586034775
batch reward last col mean 0.09991998225450516 first col mean 0.10553732514381409 all mean 0.10631990432739258
0.2790681719779968 0.2790681719779968
rl training, epoch6, iter0, batch188/1133, batch loss:0.2790681719779968, Training time:19060.1652071476
batch reward last col mean 0.07652521878480911 first col mean 0.10451527684926987 all mean 0.08513177931308746
0.2576718330383301 0.2576718330383301
rl training, epoch6, iter0, batch189/1133, batch loss:0.2576718330383301, Training time:19062.121156215668
batch reward last col mean 0.11012862622737885 first col mean 0.11081342399120331 all mean 0.11060576140880585
0.3064152002334595 0.3064152002334595
rl training, epoch6, iter0, batch190/1133, batch loss:0.3064152002334595, Training time:19064.401883602142
batch reward last col mean 0.08249650150537491 first col mean 0.11522398144006729 all mean 0.08575043827295303
0.25596877932548523 0.25596877932548523
rl training, epoch6, iter0, batch191/1133, batch loss:0.25596877932548523, Training time:19065.969871997833
batch reward last col mean 0.07906167209148407 first col mean 0.11918430030345917 all mean 0.08635928481817245
0.26371169090270996 0.26371169090270996
rl training, epoch6, iter0, batch192/1133, batch loss:0.26371169090270996, Training time:19068.060190439224
batch reward last col mean 0.10775048285722733 first col mean 0.12483170628547668 all mean 0.10559266805648804
0.2859819233417511 0.2859818935394287
rl training, epoch6, iter0, batch193/1133, batch loss:0.2859818935394287, Training time:19070.14000415802
batch reward last col mean 0.07872476428747177 first col mean 0.09139284491539001 all mean 0.08764500916004181
0.25879088044166565 0.25879088044166565
rl training, epoch6, iter0, batch194/1133, batch loss:0.25879088044166565, Training time:19072.013079881668
batch reward last col mean 0.0688498318195343 first col mean 0.10736030340194702 all mean 0.07868793606758118
0.26857849955558777 0.26857849955558777
rl training, epoch6, iter0, batch195/1133, batch loss:0.26857849955558777, Training time:19074.064553022385
batch reward last col mean 0.10984162241220474 first col mean 0.11252601444721222 all mean 0.11031990498304367
0.28700271248817444 0.28700271248817444
rl training, epoch6, iter0, batch196/1133, batch loss:0.28700271248817444, Training time:19075.728816747665
batch reward last col mean 0.10429000109434128 first col mean 0.10920923203229904 all mean 0.10473798960447311
0.30455660820007324 0.30455660820007324
rl training, epoch6, iter0, batch197/1133, batch loss:0.30455660820007324, Training time:19077.775096416473
batch reward last col mean 0.11308541893959045 first col mean 0.09883991628885269 all mean 0.10522954910993576
0.27891209721565247 0.27891209721565247
rl training, epoch6, iter0, batch198/1133, batch loss:0.27891209721565247, Training time:19079.394138097763
batch reward last col mean 0.12330490350723267 first col mean 0.10083340108394623 all mean 0.11071198433637619
0.27676886320114136 0.27676883339881897
rl training, epoch6, iter0, batch199/1133, batch loss:0.27676883339881897, Training time:19081.053529262543
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4730811092249608 Time: 95.270024061203 s
loss of true 0.2045376611197826 loss of gen 0.16876200208767578 loss of other 0.09978144531222907 first score 0.1139194518327713
batch reward last col mean 0.11824822425842285 first col mean 0.10749952495098114 all mean 0.11127175390720367
0.2761152982711792 0.2761152982711792
rl training, epoch6, iter0, batch200/1133, batch loss:0.2761152982711792, Training time:19178.05876636505
batch reward last col mean 0.0845591276884079 first col mean 0.09267468750476837 all mean 0.08622512966394424
0.2642345130443573 0.2642345130443573
rl training, epoch6, iter0, batch201/1133, batch loss:0.2642345130443573, Training time:19179.747002601624
batch reward last col mean 0.13699112832546234 first col mean 0.10560333728790283 all mean 0.12102550268173218
0.2965991795063019 0.2965991795063019
rl training, epoch6, iter0, batch202/1133, batch loss:0.2965991795063019, Training time:19181.841011047363
batch reward last col mean 0.0833534300327301 first col mean 0.09269679337739944 all mean 0.08743773400783539
0.2619754374027252 0.2619754374027252
rl training, epoch6, iter0, batch203/1133, batch loss:0.2619754374027252, Training time:19183.56888651848
batch reward last col mean 0.08929996937513351 first col mean 0.10104057937860489 all mean 0.08871247619390488
0.24636898934841156 0.24636897444725037
rl training, epoch6, iter0, batch204/1133, batch loss:0.24636897444725037, Training time:19185.383427858353
batch reward last col mean 0.09675553441047668 first col mean 0.10925349593162537 all mean 0.09615585952997208
0.28871411085128784 0.28871411085128784
rl training, epoch6, iter0, batch205/1133, batch loss:0.28871411085128784, Training time:19187.32234930992
batch reward last col mean 0.10103191435337067 first col mean 0.09616246074438095 all mean 0.09621065855026245
0.26125892996788025 0.26125892996788025
rl training, epoch6, iter0, batch206/1133, batch loss:0.26125892996788025, Training time:19189.548278331757
batch reward last col mean 0.07876487076282501 first col mean 0.12211208790540695 all mean 0.0865231305360794
0.24062085151672363 0.24062083661556244
rl training, epoch6, iter0, batch207/1133, batch loss:0.24062083661556244, Training time:19191.241193532944
batch reward last col mean 0.11805425584316254 first col mean 0.1103188693523407 all mean 0.11305896937847137
0.27835288643836975 0.27835285663604736
rl training, epoch6, iter0, batch208/1133, batch loss:0.27835285663604736, Training time:19193.226009368896
batch reward last col mean 0.1257159411907196 first col mean 0.08609095215797424 all mean 0.12316709756851196
0.30228590965270996 0.30228590965270996
rl training, epoch6, iter0, batch209/1133, batch loss:0.30228590965270996, Training time:19195.019141197205
batch reward last col mean 0.07832464575767517 first col mean 0.1053059920668602 all mean 0.08308512717485428
0.22125278413295746 0.22125278413295746
rl training, epoch6, iter0, batch210/1133, batch loss:0.22125278413295746, Training time:19197.060883522034
batch reward last col mean 0.11487910151481628 first col mean 0.11758127808570862 all mean 0.11542440205812454
0.31359830498695374 0.31359830498695374
rl training, epoch6, iter0, batch211/1133, batch loss:0.31359830498695374, Training time:19198.67472600937
batch reward last col mean 0.08452397584915161 first col mean 0.10808789730072021 all mean 0.09294921904802322
0.28464189171791077 0.28464189171791077
rl training, epoch6, iter0, batch212/1133, batch loss:0.28464189171791077, Training time:19200.376541614532
batch reward last col mean 0.0857248604297638 first col mean 0.10754624754190445 all mean 0.09502407908439636
0.2637965977191925 0.2637965977191925
rl training, epoch6, iter0, batch213/1133, batch loss:0.2637965977191925, Training time:19202.18353819847
batch reward last col mean 0.12560096383094788 first col mean 0.11339262127876282 all mean 0.11918965727090836
0.2986941337585449 0.2986941337585449
rl training, epoch6, iter0, batch214/1133, batch loss:0.2986941337585449, Training time:19204.14031457901
batch reward last col mean 0.09077201783657074 first col mean 0.09686294943094254 all mean 0.10007332265377045
0.2931365370750427 0.2931365370750427
rl training, epoch6, iter0, batch215/1133, batch loss:0.2931365370750427, Training time:19205.95202589035
batch reward last col mean 0.08993899077177048 first col mean 0.10739483684301376 all mean 0.09765122085809708
0.25674596428871155 0.25674596428871155
rl training, epoch6, iter0, batch216/1133, batch loss:0.25674596428871155, Training time:19208.30115032196
batch reward last col mean 0.1162971630692482 first col mean 0.0950213074684143 all mean 0.11163318902254105
0.30617204308509827 0.30617204308509827
rl training, epoch6, iter0, batch217/1133, batch loss:0.30617204308509827, Training time:19210.01718521118
batch reward last col mean 0.09208975732326508 first col mean 0.09929127991199493 all mean 0.09582271426916122
0.2612326443195343 0.2612326443195343
rl training, epoch6, iter0, batch218/1133, batch loss:0.2612326443195343, Training time:19211.944559812546
batch reward last col mean 0.09665018320083618 first col mean 0.10589316487312317 all mean 0.10164389759302139
0.2982254922389984 0.2982254922389984
rl training, epoch6, iter0, batch219/1133, batch loss:0.2982254922389984, Training time:19213.742961406708
batch reward last col mean 0.09757311642169952 first col mean 0.1262073963880539 all mean 0.10291777551174164
0.30363112688064575 0.30363112688064575
rl training, epoch6, iter0, batch220/1133, batch loss:0.30363112688064575, Training time:19215.580524683
batch reward last col mean 0.10861827433109283 first col mean 0.09211806207895279 all mean 0.10678737610578537
0.26852262020111084 0.26852262020111084
rl training, epoch6, iter0, batch221/1133, batch loss:0.26852262020111084, Training time:19217.660628557205
batch reward last col mean 0.12413223087787628 first col mean 0.11095914244651794 all mean 0.12003527581691742
0.33682096004486084 0.33682096004486084
rl training, epoch6, iter0, batch222/1133, batch loss:0.33682096004486084, Training time:19219.35998773575
batch reward last col mean 0.08241716027259827 first col mean 0.11096719652414322 all mean 0.09122996777296066
0.2603599429130554 0.2603599727153778
rl training, epoch6, iter0, batch223/1133, batch loss:0.2603599727153778, Training time:19220.994308948517
batch reward last col mean 0.08670511096715927 first col mean 0.09679921716451645 all mean 0.092041015625
0.27065718173980713 0.27065718173980713
rl training, epoch6, iter0, batch224/1133, batch loss:0.27065718173980713, Training time:19222.97360944748
batch reward last col mean 0.11737614870071411 first col mean 0.08924471586942673 all mean 0.11315714567899704
0.30346134305000305 0.30346134305000305
rl training, epoch6, iter0, batch225/1133, batch loss:0.30346134305000305, Training time:19224.84288239479
batch reward last col mean 0.08239232003688812 first col mean 0.11360546201467514 all mean 0.09252871572971344
0.2545458972454071 0.2545458972454071
rl training, epoch6, iter0, batch226/1133, batch loss:0.2545458972454071, Training time:19226.569927930832
batch reward last col mean 0.07323051244020462 first col mean 0.09802904725074768 all mean 0.07985952496528625
0.23341013491153717 0.23341013491153717
rl training, epoch6, iter0, batch227/1133, batch loss:0.23341013491153717, Training time:19228.180396556854
batch reward last col mean 0.07269352674484253 first col mean 0.11644109338521957 all mean 0.08456175774335861
0.26549971103668213 0.26549971103668213
rl training, epoch6, iter0, batch228/1133, batch loss:0.26549971103668213, Training time:19229.791073560715
batch reward last col mean 0.09470155090093613 first col mean 0.11852645128965378 all mean 0.09409987926483154
0.29210102558135986 0.29210102558135986
rl training, epoch6, iter0, batch229/1133, batch loss:0.29210102558135986, Training time:19231.66372346878
batch reward last col mean 0.11207996308803558 first col mean 0.11452704668045044 all mean 0.1104748547077179
0.2763555943965912 0.2763555943965912
rl training, epoch6, iter0, batch230/1133, batch loss:0.2763555943965912, Training time:19233.651036024094
batch reward last col mean 0.11655482649803162 first col mean 0.11147046089172363 all mean 0.11495944857597351
0.3016637861728668 0.3016637861728668
rl training, epoch6, iter0, batch231/1133, batch loss:0.3016637861728668, Training time:19235.1010723114
batch reward last col mean 0.10788697004318237 first col mean 0.11346282064914703 all mean 0.1022735983133316
0.29725712537765503 0.29725712537765503
rl training, epoch6, iter0, batch232/1133, batch loss:0.29725712537765503, Training time:19236.71739268303
batch reward last col mean 0.10162904858589172 first col mean 0.1181432232260704 all mean 0.100857675075531
0.2917264401912689 0.2917264401912689
rl training, epoch6, iter0, batch233/1133, batch loss:0.2917264401912689, Training time:19238.828313589096
batch reward last col mean 0.10478362441062927 first col mean 0.09348433464765549 all mean 0.10682426393032074
0.2931412160396576 0.2931412160396576
rl training, epoch6, iter0, batch234/1133, batch loss:0.2931412160396576, Training time:19240.63207578659
batch reward last col mean 0.11681976914405823 first col mean 0.12211304903030396 all mean 0.11694476008415222
0.2962602376937866 0.2962602376937866
rl training, epoch6, iter0, batch235/1133, batch loss:0.2962602376937866, Training time:19242.729355335236
batch reward last col mean 0.081597700715065 first col mean 0.10528340935707092 all mean 0.08681206405162811
0.2948575019836426 0.29485753178596497
rl training, epoch6, iter0, batch236/1133, batch loss:0.29485753178596497, Training time:19245.13629412651
batch reward last col mean 0.09047164767980576 first col mean 0.09788965433835983 all mean 0.09490946680307388
0.25180381536483765 0.25180381536483765
rl training, epoch6, iter0, batch237/1133, batch loss:0.25180381536483765, Training time:19246.890720129013
batch reward last col mean 0.10392121970653534 first col mean 0.11405296623706818 all mean 0.10564176738262177
0.2706034779548645 0.2706034779548645
rl training, epoch6, iter0, batch238/1133, batch loss:0.2706034779548645, Training time:19249.26558971405
batch reward last col mean 0.13073556125164032 first col mean 0.10014843940734863 all mean 0.11372531950473785
0.28291112184524536 0.28291112184524536
rl training, epoch6, iter0, batch239/1133, batch loss:0.28291112184524536, Training time:19250.97321510315
batch reward last col mean 0.0954403504729271 first col mean 0.10962288081645966 all mean 0.10260069370269775
0.30567964911460876 0.30567964911460876
rl training, epoch6, iter0, batch240/1133, batch loss:0.30567964911460876, Training time:19252.86083674431
batch reward last col mean 0.07703398168087006 first col mean 0.08925139904022217 all mean 0.08392384648323059
0.2443329244852066 0.2443329244852066
rl training, epoch6, iter0, batch241/1133, batch loss:0.2443329244852066, Training time:19254.72190141678
batch reward last col mean 0.09258119016885757 first col mean 0.10967710614204407 all mean 0.09876545518636703
0.28201764822006226 0.28201764822006226
rl training, epoch6, iter0, batch242/1133, batch loss:0.28201764822006226, Training time:19256.46163225174
batch reward last col mean 0.101530060172081 first col mean 0.10557153820991516 all mean 0.10747165232896805
0.33408641815185547 0.33408641815185547
rl training, epoch6, iter0, batch243/1133, batch loss:0.33408641815185547, Training time:19258.358280181885
batch reward last col mean 0.09355118125677109 first col mean 0.09384061396121979 all mean 0.09957157075405121
0.2749890685081482 0.2749890685081482
rl training, epoch6, iter0, batch244/1133, batch loss:0.2749890685081482, Training time:19260.66796898842
batch reward last col mean 0.11846704035997391 first col mean 0.10131190717220306 all mean 0.10939052700996399
0.28439730405807495 0.28439730405807495
rl training, epoch6, iter0, batch245/1133, batch loss:0.28439730405807495, Training time:19262.333558797836
batch reward last col mean 0.09604427218437195 first col mean 0.11212997883558273 all mean 0.10357900708913803
0.2650502622127533 0.2650502622127533
rl training, epoch6, iter0, batch246/1133, batch loss:0.2650502622127533, Training time:19264.035876512527
batch reward last col mean 0.09155424684286118 first col mean 0.11338387429714203 all mean 0.09258631616830826
0.2840211093425751 0.2840211093425751
rl training, epoch6, iter0, batch247/1133, batch loss:0.2840211093425751, Training time:19265.888205766678
batch reward last col mean 0.09230346977710724 first col mean 0.1105041429400444 all mean 0.09174390882253647
0.2450800985097885 0.2450800985097885
rl training, epoch6, iter0, batch248/1133, batch loss:0.2450800985097885, Training time:19268.373027086258
batch reward last col mean 0.1282767653465271 first col mean 0.10886036604642868 all mean 0.1250542402267456
0.26448944211006165 0.26448941230773926
rl training, epoch6, iter0, batch249/1133, batch loss:0.26448941230773926, Training time:19270.12171316147
batch reward last col mean 0.07978707551956177 first col mean 0.12533771991729736 all mean 0.08915433287620544
0.2966820001602173 0.2966820299625397
rl training, epoch6, iter0, batch250/1133, batch loss:0.2966820299625397, Training time:19271.89851140976
batch reward last col mean 0.11428014934062958 first col mean 0.09739147871732712 all mean 0.11100941896438599
0.30454152822494507 0.30454152822494507
rl training, epoch6, iter0, batch251/1133, batch loss:0.30454152822494507, Training time:19273.751471042633
batch reward last col mean 0.12332817912101746 first col mean 0.09739693999290466 all mean 0.11585023254156113
0.3060475289821625 0.3060475289821625
rl training, epoch6, iter0, batch252/1133, batch loss:0.3060475289821625, Training time:19275.34784221649
batch reward last col mean 0.12168655544519424 first col mean 0.10833326727151871 all mean 0.12048830091953278
0.31193214654922485 0.31193214654922485
rl training, epoch6, iter0, batch253/1133, batch loss:0.31193214654922485, Training time:19277.1187415123
batch reward last col mean 0.08989039063453674 first col mean 0.10263101756572723 all mean 0.09391362965106964
0.27362748980522156 0.27362748980522156
rl training, epoch6, iter0, batch254/1133, batch loss:0.27362748980522156, Training time:19278.877227306366
batch reward last col mean 0.09352844208478928 first col mean 0.09731288254261017 all mean 0.09935068339109421
0.29330018162727356 0.29330018162727356
rl training, epoch6, iter0, batch255/1133, batch loss:0.29330018162727356, Training time:19281.640949964523
batch reward last col mean 0.12410261482000351 first col mean 0.10736103355884552 all mean 0.11945439875125885
0.31613433361053467 0.31613436341285706
rl training, epoch6, iter0, batch256/1133, batch loss:0.31613436341285706, Training time:19283.66474699974
batch reward last col mean 0.09841009974479675 first col mean 0.10188964009284973 all mean 0.10424192994832993
0.29292652010917664 0.29292652010917664
rl training, epoch6, iter0, batch257/1133, batch loss:0.29292652010917664, Training time:19285.58592057228
batch reward last col mean 0.09816280007362366 first col mean 0.09666155278682709 all mean 0.0954010859131813
0.2723854184150696 0.2723854184150696
rl training, epoch6, iter0, batch258/1133, batch loss:0.2723854184150696, Training time:19287.23587656021
batch reward last col mean 0.11238157004117966 first col mean 0.12028302252292633 all mean 0.11242013424634933
0.26109984517097473 0.26109984517097473
rl training, epoch6, iter0, batch259/1133, batch loss:0.26109984517097473, Training time:19289.00136899948
batch reward last col mean 0.10824011266231537 first col mean 0.09706564247608185 all mean 0.10790735483169556
0.32135578989982605 0.32135578989982605
rl training, epoch6, iter0, batch260/1133, batch loss:0.32135578989982605, Training time:19291.026221513748
batch reward last col mean 0.1389814168214798 first col mean 0.11204174160957336 all mean 0.12309062480926514
0.31442567706108093 0.31442567706108093
rl training, epoch6, iter0, batch261/1133, batch loss:0.31442567706108093, Training time:19292.540929317474
batch reward last col mean 0.11920738220214844 first col mean 0.11944948136806488 all mean 0.11896473914384842
0.2985050082206726 0.2985050082206726
rl training, epoch6, iter0, batch262/1133, batch loss:0.2985050082206726, Training time:19294.770545244217
batch reward last col mean 0.09390025585889816 first col mean 0.11183209717273712 all mean 0.09400757402181625
0.2593569755554199 0.2593569755554199
rl training, epoch6, iter0, batch263/1133, batch loss:0.2593569755554199, Training time:19296.611683130264
batch reward last col mean 0.11487939953804016 first col mean 0.11470988392829895 all mean 0.11451664566993713
0.3291168212890625 0.3291168212890625
rl training, epoch6, iter0, batch264/1133, batch loss:0.3291168212890625, Training time:19298.397085428238
batch reward last col mean 0.0948970690369606 first col mean 0.11598921567201614 all mean 0.09985221177339554
0.2913171350955963 0.2913171350955963
rl training, epoch6, iter0, batch265/1133, batch loss:0.2913171350955963, Training time:19300.17816233635
batch reward last col mean 0.09431517124176025 first col mean 0.11208284646272659 all mean 0.10166306048631668
0.2955251932144165 0.2955251932144165
rl training, epoch6, iter0, batch266/1133, batch loss:0.2955251932144165, Training time:19301.942692041397
batch reward last col mean 0.09033404290676117 first col mean 0.10372966527938843 all mean 0.09187884628772736
0.2763577997684479 0.2763577997684479
rl training, epoch6, iter0, batch267/1133, batch loss:0.2763577997684479, Training time:19303.56337618828
batch reward last col mean 0.1280827820301056 first col mean 0.10303808003664017 all mean 0.12027408182621002
0.32669228315353394 0.32669228315353394
rl training, epoch6, iter0, batch268/1133, batch loss:0.32669228315353394, Training time:19305.125395298004
batch reward last col mean 0.1004989892244339 first col mean 0.11216935515403748 all mean 0.10139261186122894
0.302470326423645 0.302470326423645
rl training, epoch6, iter0, batch269/1133, batch loss:0.302470326423645, Training time:19306.979280233383
batch reward last col mean 0.0799618661403656 first col mean 0.102945476770401 all mean 0.08792280405759811
0.2691315710544586 0.2691315710544586
rl training, epoch6, iter0, batch270/1133, batch loss:0.2691315710544586, Training time:19308.944145679474
batch reward last col mean 0.07521995157003403 first col mean 0.11430393904447556 all mean 0.08117196708917618
0.24090728163719177 0.24090728163719177
rl training, epoch6, iter0, batch271/1133, batch loss:0.24090728163719177, Training time:19310.74601626396
batch reward last col mean 0.1388939768075943 first col mean 0.1103094220161438 all mean 0.1285187155008316
0.3612949848175049 0.3612949848175049
rl training, epoch6, iter0, batch272/1133, batch loss:0.3612949848175049, Training time:19312.866493701935
batch reward last col mean 0.08291782438755035 first col mean 0.10609361529350281 all mean 0.08651847392320633
0.2903509736061096 0.2903509736061096
rl training, epoch6, iter0, batch273/1133, batch loss:0.2903509736061096, Training time:19315.145174980164
batch reward last col mean 0.10601947456598282 first col mean 0.10414942353963852 all mean 0.10316044092178345
0.3042849600315094 0.3042849898338318
rl training, epoch6, iter0, batch274/1133, batch loss:0.3042849898338318, Training time:19317.285880088806
batch reward last col mean 0.08665486425161362 first col mean 0.09995664656162262 all mean 0.09224143624305725
0.29873982071876526 0.29873982071876526
rl training, epoch6, iter0, batch275/1133, batch loss:0.29873982071876526, Training time:19319.146944761276
batch reward last col mean 0.13399089872837067 first col mean 0.10488054901361465 all mean 0.1279548704624176
0.3258269131183624 0.3258269131183624
rl training, epoch6, iter0, batch276/1133, batch loss:0.3258269131183624, Training time:19320.989862203598
batch reward last col mean 0.10028602182865143 first col mean 0.10911905765533447 all mean 0.09772651642560959
0.2770274579524994 0.2770274579524994
rl training, epoch6, iter0, batch277/1133, batch loss:0.2770274579524994, Training time:19323.47669363022
batch reward last col mean 0.09389558434486389 first col mean 0.10998085141181946 all mean 0.09283044934272766
0.25941839814186096 0.25941839814186096
rl training, epoch6, iter0, batch278/1133, batch loss:0.25941839814186096, Training time:19325.54332089424
batch reward last col mean 0.09129109978675842 first col mean 0.11204179376363754 all mean 0.10120011866092682
0.30725792050361633 0.30725789070129395
rl training, epoch6, iter0, batch279/1133, batch loss:0.30725789070129395, Training time:19327.58394885063
batch reward last col mean 0.11933271586894989 first col mean 0.1064484491944313 all mean 0.11525988578796387
0.29641908407211304 0.29641908407211304
rl training, epoch6, iter0, batch280/1133, batch loss:0.29641908407211304, Training time:19330.20573735237
batch reward last col mean 0.10361085832118988 first col mean 0.1284283846616745 all mean 0.1059608981013298
0.3165638744831085 0.3165638744831085
rl training, epoch6, iter0, batch281/1133, batch loss:0.3165638744831085, Training time:19332.31523990631
batch reward last col mean 0.10054337978363037 first col mean 0.09580541402101517 all mean 0.10440515726804733
0.30303269624710083 0.30303269624710083
rl training, epoch6, iter0, batch282/1133, batch loss:0.30303269624710083, Training time:19334.286203861237
batch reward last col mean 0.1160980612039566 first col mean 0.12094897031784058 all mean 0.1163887232542038
0.2908351719379425 0.2908351719379425
rl training, epoch6, iter0, batch283/1133, batch loss:0.2908351719379425, Training time:19336.370200157166
batch reward last col mean 0.11514724791049957 first col mean 0.12267417460680008 all mean 0.11761369556188583
0.2915881872177124 0.2915881872177124
rl training, epoch6, iter0, batch284/1133, batch loss:0.2915881872177124, Training time:19338.326343536377
batch reward last col mean 0.07979731261730194 first col mean 0.10941758006811142 all mean 0.087587870657444
0.25527650117874146 0.25527650117874146
rl training, epoch6, iter0, batch285/1133, batch loss:0.25527650117874146, Training time:19340.81292629242
batch reward last col mean 0.08570163697004318 first col mean 0.09881680458784103 all mean 0.09417607635259628
0.30521857738494873 0.30521857738494873
rl training, epoch6, iter0, batch286/1133, batch loss:0.30521857738494873, Training time:19342.559622764587
batch reward last col mean 0.11341077089309692 first col mean 0.1152186393737793 all mean 0.114414282143116
0.31496626138687134 0.31496626138687134
rl training, epoch6, iter0, batch287/1133, batch loss:0.31496626138687134, Training time:19345.384011507034
batch reward last col mean 0.13679230213165283 first col mean 0.11218962073326111 all mean 0.13231830298900604
0.3106372058391571 0.3106372058391571
rl training, epoch6, iter0, batch288/1133, batch loss:0.3106372058391571, Training time:19347.319348812103
batch reward last col mean 0.05661270022392273 first col mean 0.11306066811084747 all mean 0.07148482650518417
0.2484833002090454 0.2484833002090454
rl training, epoch6, iter0, batch289/1133, batch loss:0.2484833002090454, Training time:19349.358663082123
batch reward last col mean 0.06309748440980911 first col mean 0.10059446096420288 all mean 0.07594070583581924
0.23338794708251953 0.23338793218135834
rl training, epoch6, iter0, batch290/1133, batch loss:0.23338793218135834, Training time:19351.42051053047
batch reward last col mean 0.1107422411441803 first col mean 0.10157107561826706 all mean 0.11139065027236938
0.27115270495414734 0.27115270495414734
rl training, epoch6, iter0, batch291/1133, batch loss:0.27115270495414734, Training time:19353.556571483612
batch reward last col mean 0.09635835886001587 first col mean 0.1120118647813797 all mean 0.10416365414857864
0.3021203875541687 0.3021203875541687
rl training, epoch6, iter0, batch292/1133, batch loss:0.3021203875541687, Training time:19355.25120639801
batch reward last col mean 0.0882008746266365 first col mean 0.0884256437420845 all mean 0.09483751654624939
0.2696983814239502 0.2696984112262726
rl training, epoch6, iter0, batch293/1133, batch loss:0.2696984112262726, Training time:19357.13691687584
batch reward last col mean 0.11851688474416733 first col mean 0.10881747305393219 all mean 0.11618486046791077
0.2668876647949219 0.2668876647949219
rl training, epoch6, iter0, batch294/1133, batch loss:0.2668876647949219, Training time:19359.008319854736
batch reward last col mean 0.11079919338226318 first col mean 0.10087967664003372 all mean 0.10335300117731094
0.2994089424610138 0.2994089424610138
rl training, epoch6, iter0, batch295/1133, batch loss:0.2994089424610138, Training time:19360.654703378677
batch reward last col mean 0.09061574935913086 first col mean 0.1177501380443573 all mean 0.09740771353244781
0.280733197927475 0.280733197927475
rl training, epoch6, iter0, batch296/1133, batch loss:0.280733197927475, Training time:19362.454712867737
batch reward last col mean 0.09506434202194214 first col mean 0.1188727393746376 all mean 0.10139111429452896
0.27966150641441345 0.27966150641441345
rl training, epoch6, iter0, batch297/1133, batch loss:0.27966150641441345, Training time:19364.759214878082
batch reward last col mean 0.07716798782348633 first col mean 0.09805598109960556 all mean 0.08422239124774933
0.2504367232322693 0.2504367232322693
rl training, epoch6, iter0, batch298/1133, batch loss:0.2504367232322693, Training time:19367.011632680893
batch reward last col mean 0.07124551385641098 first col mean 0.13260672986507416 all mean 0.08550752699375153
0.2841578423976898 0.2841578423976898
rl training, epoch6, iter0, batch299/1133, batch loss:0.2841578423976898, Training time:19369.05814933777
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4840850935819816 Time: 96.5827386379242 s
loss of true 0.20936543540494798 loss of gen 0.1763796905369645 loss of other 0.09833996837986642 first score 0.10138608515262604
batch reward last col mean 0.09129064530134201 first col mean 0.10596306622028351 all mean 0.09209912270307541
0.201467365026474 0.201467365026474
rl training, epoch6, iter0, batch300/1133, batch loss:0.201467365026474, Training time:19467.635910749435
batch reward last col mean 0.09751204401254654 first col mean 0.11186740547418594 all mean 0.09263873100280762
0.24430327117443085 0.24430327117443085
rl training, epoch6, iter0, batch301/1133, batch loss:0.24430327117443085, Training time:19469.332895040512
batch reward last col mean 0.05740758776664734 first col mean 0.09026865661144257 all mean 0.07465798407793045
0.24802851676940918 0.24802850186824799
rl training, epoch6, iter0, batch302/1133, batch loss:0.24802850186824799, Training time:19471.042883634567
batch reward last col mean 0.09514569491147995 first col mean 0.11679405719041824 all mean 0.09499035775661469
0.272360235452652 0.27236026525497437
rl training, epoch6, iter0, batch303/1133, batch loss:0.27236026525497437, Training time:19473.104308843613
batch reward last col mean 0.09780489653348923 first col mean 0.10115993022918701 all mean 0.09445412456989288
0.2385379523038864 0.2385379523038864
rl training, epoch6, iter0, batch304/1133, batch loss:0.2385379523038864, Training time:19475.012665510178
batch reward last col mean 0.06651149690151215 first col mean 0.1128399521112442 all mean 0.07881084829568863
0.25982141494750977 0.25982144474983215
rl training, epoch6, iter0, batch305/1133, batch loss:0.25982144474983215, Training time:19477.194949388504
batch reward last col mean 0.09135744720697403 first col mean 0.09260392934083939 all mean 0.09704077988862991
0.2913484573364258 0.29134848713874817
rl training, epoch6, iter0, batch306/1133, batch loss:0.29134848713874817, Training time:19479.067855358124
batch reward last col mean 0.0890699177980423 first col mean 0.10185615718364716 all mean 0.09309868514537811
0.25454121828079224 0.25454121828079224
rl training, epoch6, iter0, batch307/1133, batch loss:0.25454121828079224, Training time:19481.942687273026
batch reward last col mean 0.10182761400938034 first col mean 0.08946069329977036 all mean 0.09931197762489319
0.2624102830886841 0.2624102830886841
rl training, epoch6, iter0, batch308/1133, batch loss:0.2624102830886841, Training time:19483.68697500229
batch reward last col mean 0.11456667631864548 first col mean 0.08692817389965057 all mean 0.1103011965751648
0.2700181305408478 0.2700181007385254
rl training, epoch6, iter0, batch309/1133, batch loss:0.2700181007385254, Training time:19485.672261476517
batch reward last col mean 0.08739020675420761 first col mean 0.07858356833457947 all mean 0.09189373254776001
0.23914307355880737 0.23914307355880737
rl training, epoch6, iter0, batch310/1133, batch loss:0.23914307355880737, Training time:19487.668843984604
batch reward last col mean 0.07804473489522934 first col mean 0.08782057464122772 all mean 0.08375564962625504
0.23958511650562286 0.23958511650562286
rl training, epoch6, iter0, batch311/1133, batch loss:0.23958511650562286, Training time:19489.436491250992
batch reward last col mean 0.07236484438180923 first col mean 0.0953773483633995 all mean 0.07947655022144318
0.2717733681201935 0.2717733681201935
rl training, epoch6, iter0, batch312/1133, batch loss:0.2717733681201935, Training time:19492.070420503616
batch reward last col mean 0.09143254160881042 first col mean 0.11355026811361313 all mean 0.09541875123977661
0.2657291293144226 0.2657291293144226
rl training, epoch6, iter0, batch313/1133, batch loss:0.2657291293144226, Training time:19494.69997215271
batch reward last col mean 0.12773002684116364 first col mean 0.08899406343698502 all mean 0.11903346329927444
0.27863579988479614 0.27863579988479614
rl training, epoch6, iter0, batch314/1133, batch loss:0.27863579988479614, Training time:19497.77894639969
batch reward last col mean 0.1190340667963028 first col mean 0.11130732297897339 all mean 0.11459014564752579
0.2953679859638214 0.295367956161499
rl training, epoch6, iter0, batch315/1133, batch loss:0.295367956161499, Training time:19501.45418858528
batch reward last col mean 0.09006904065608978 first col mean 0.1033831387758255 all mean 0.09219294041395187
0.22368641197681427 0.22368641197681427
rl training, epoch6, iter0, batch316/1133, batch loss:0.22368641197681427, Training time:19504.263729572296
batch reward last col mean 0.08923722803592682 first col mean 0.10157882422208786 all mean 0.09196775406599045
0.2386343777179718 0.238634392619133
rl training, epoch6, iter0, batch317/1133, batch loss:0.238634392619133, Training time:19506.531802415848
batch reward last col mean 0.0989174023270607 first col mean 0.08906253427267075 all mean 0.09660349786281586
0.2911713421344757 0.2911713421344757
rl training, epoch6, iter0, batch318/1133, batch loss:0.2911713421344757, Training time:19508.3464243412
batch reward last col mean 0.07482016086578369 first col mean 0.12558549642562866 all mean 0.08249665796756744
0.2509378492832184 0.2509378492832184
rl training, epoch6, iter0, batch319/1133, batch loss:0.2509378492832184, Training time:19510.49162387848
batch reward last col mean 0.0964185893535614 first col mean 0.0958031639456749 all mean 0.09512226283550262
0.24307402968406677 0.24307401478290558
rl training, epoch6, iter0, batch320/1133, batch loss:0.24307401478290558, Training time:19513.193574666977
batch reward last col mean 0.08504238724708557 first col mean 0.09724202007055283 all mean 0.08510685712099075
0.28124842047691345 0.28124842047691345
rl training, epoch6, iter0, batch321/1133, batch loss:0.28124842047691345, Training time:19515.11167693138
batch reward last col mean 0.08255666494369507 first col mean 0.12659858167171478 all mean 0.09100663661956787
0.25960636138916016 0.25960636138916016
rl training, epoch6, iter0, batch322/1133, batch loss:0.25960636138916016, Training time:19516.640274763107
batch reward last col mean 0.10590347647666931 first col mean 0.08115161210298538 all mean 0.0970703512430191
0.2406485229730606 0.2406485229730606
rl training, epoch6, iter0, batch323/1133, batch loss:0.2406485229730606, Training time:19518.334713697433
batch reward last col mean 0.10147051513195038 first col mean 0.12369011342525482 all mean 0.10409034788608551
0.26253029704093933 0.26253029704093933
rl training, epoch6, iter0, batch324/1133, batch loss:0.26253029704093933, Training time:19521.058037042618
batch reward last col mean 0.0826922357082367 first col mean 0.11227286607027054 all mean 0.09034673124551773
0.25417229533195496 0.25417229533195496
rl training, epoch6, iter0, batch325/1133, batch loss:0.25417229533195496, Training time:19523.292844057083
batch reward last col mean 0.10322055220603943 first col mean 0.10124078392982483 all mean 0.09970841556787491
0.2834571599960327 0.2834571599960327
rl training, epoch6, iter0, batch326/1133, batch loss:0.2834571599960327, Training time:19525.26417374611
batch reward last col mean 0.13092365860939026 first col mean 0.11390388011932373 all mean 0.1279708296060562
0.3187679350376129 0.3187679350376129
rl training, epoch6, iter0, batch327/1133, batch loss:0.3187679350376129, Training time:19527.54142665863
batch reward last col mean 0.10422391444444656 first col mean 0.08855556696653366 all mean 0.10263066738843918
0.28471076488494873 0.28471076488494873
rl training, epoch6, iter0, batch328/1133, batch loss:0.28471076488494873, Training time:19531.34251141548
batch reward last col mean 0.12674470245838165 first col mean 0.09404618293046951 all mean 0.123101606965065
0.3289889097213745 0.3289889097213745
rl training, epoch6, iter0, batch329/1133, batch loss:0.3289889097213745, Training time:19533.375751018524
batch reward last col mean 0.0999276340007782 first col mean 0.09492995589971542 all mean 0.10556799173355103
0.27849239110946655 0.27849239110946655
rl training, epoch6, iter0, batch330/1133, batch loss:0.27849239110946655, Training time:19535.421628713608
batch reward last col mean 0.11281542479991913 first col mean 0.10827632993459702 all mean 0.10640184581279755
0.3107176125049591 0.3107175827026367
rl training, epoch6, iter0, batch331/1133, batch loss:0.3107175827026367, Training time:19537.660616874695
batch reward last col mean 0.07283873111009598 first col mean 0.09234259277582169 all mean 0.08426912873983383
0.29771173000335693 0.2977117598056793
rl training, epoch6, iter0, batch332/1133, batch loss:0.2977117598056793, Training time:19539.91922903061
batch reward last col mean 0.0782618522644043 first col mean 0.09912052750587463 all mean 0.08745162934064865
0.2636204659938812 0.2636204659938812
rl training, epoch6, iter0, batch333/1133, batch loss:0.2636204659938812, Training time:19542.47634768486
batch reward last col mean 0.11523518711328506 first col mean 0.06999345868825912 all mean 0.10866929590702057
0.25965672731399536 0.259656697511673
rl training, epoch6, iter0, batch334/1133, batch loss:0.259656697511673, Training time:19545.03750014305
batch reward last col mean 0.10646580159664154 first col mean 0.09613119810819626 all mean 0.09843375533819199
0.24740062654018402 0.24740062654018402
rl training, epoch6, iter0, batch335/1133, batch loss:0.24740062654018402, Training time:19546.910133838654
batch reward last col mean 0.08487044274806976 first col mean 0.08701954782009125 all mean 0.08968399465084076
0.23953478038311005 0.23953476548194885
rl training, epoch6, iter0, batch336/1133, batch loss:0.23953476548194885, Training time:19548.99468278885
batch reward last col mean 0.09782123565673828 first col mean 0.09616577625274658 all mean 0.09601552784442902
0.26488009095191956 0.26488009095191956
rl training, epoch6, iter0, batch337/1133, batch loss:0.26488009095191956, Training time:19551.13711309433
batch reward last col mean 0.09379158169031143 first col mean 0.09780445694923401 all mean 0.09525221586227417
0.28606078028678894 0.28606078028678894
rl training, epoch6, iter0, batch338/1133, batch loss:0.28606078028678894, Training time:19552.94044804573
batch reward last col mean 0.0900309830904007 first col mean 0.10489548742771149 all mean 0.0937202051281929
0.25767165422439575 0.25767162442207336
rl training, epoch6, iter0, batch339/1133, batch loss:0.25767162442207336, Training time:19554.91610789299
batch reward last col mean 0.10237766802310944 first col mean 0.10650031268596649 all mean 0.10310354828834534
0.27428698539733887 0.27428698539733887
rl training, epoch6, iter0, batch340/1133, batch loss:0.27428698539733887, Training time:19556.67798423767
batch reward last col mean 0.10442400723695755 first col mean 0.10056069493293762 all mean 0.10418038070201874
0.2747805416584015 0.2747805416584015
rl training, epoch6, iter0, batch341/1133, batch loss:0.2747805416584015, Training time:19559.047018766403
batch reward last col mean 0.10913018882274628 first col mean 0.10445950925350189 all mean 0.10909531265497208
0.28535133600234985 0.28535133600234985
rl training, epoch6, iter0, batch342/1133, batch loss:0.28535133600234985, Training time:19561.100120544434
batch reward last col mean 0.07146776467561722 first col mean 0.0972147211432457 all mean 0.08049076795578003
0.26686370372772217 0.26686370372772217
rl training, epoch6, iter0, batch343/1133, batch loss:0.26686370372772217, Training time:19562.885966539383
batch reward last col mean 0.11241878569126129 first col mean 0.11398730427026749 all mean 0.11007224023342133
0.2711234986782074 0.2711234986782074
rl training, epoch6, iter0, batch344/1133, batch loss:0.2711234986782074, Training time:19564.916876077652
batch reward last col mean 0.08963323384523392 first col mean 0.1138751357793808 all mean 0.09708753228187561
0.27033495903015137 0.27033495903015137
rl training, epoch6, iter0, batch345/1133, batch loss:0.27033495903015137, Training time:19566.948664665222
batch reward last col mean 0.0856914073228836 first col mean 0.10578475892543793 all mean 0.09008023142814636
0.2815411686897278 0.2815411686897278
rl training, epoch6, iter0, batch346/1133, batch loss:0.2815411686897278, Training time:19569.034073352814
batch reward last col mean 0.1038452684879303 first col mean 0.09489864110946655 all mean 0.1051429808139801
0.3200182020664215 0.3200182020664215
rl training, epoch6, iter0, batch347/1133, batch loss:0.3200182020664215, Training time:19571.53011226654
batch reward last col mean 0.04751669615507126 first col mean 0.10894936323165894 all mean 0.06739677488803864
0.21106676757335663 0.21106675267219543
rl training, epoch6, iter0, batch348/1133, batch loss:0.21106675267219543, Training time:19573.233367204666
batch reward last col mean 0.10047521442174911 first col mean 0.11139443516731262 all mean 0.10480035841464996
0.2998298108577728 0.2998298108577728
rl training, epoch6, iter0, batch349/1133, batch loss:0.2998298108577728, Training time:19576.072814702988
batch reward last col mean 0.10681942105293274 first col mean 0.11325495690107346 all mean 0.10436469316482544
0.28361067175865173 0.28361067175865173
rl training, epoch6, iter0, batch350/1133, batch loss:0.28361067175865173, Training time:19577.844093561172
batch reward last col mean 0.1440836489200592 first col mean 0.10196593403816223 all mean 0.1334119588136673
0.2862470746040344 0.2862470746040344
rl training, epoch6, iter0, batch351/1133, batch loss:0.2862470746040344, Training time:19580.025010108948
batch reward last col mean 0.12032017111778259 first col mean 0.10186387598514557 all mean 0.10775907337665558
0.27832716703414917 0.27832716703414917
rl training, epoch6, iter0, batch352/1133, batch loss:0.27832716703414917, Training time:19581.828240394592
batch reward last col mean 0.14517414569854736 first col mean 0.11381690204143524 all mean 0.12576067447662354
0.27589529752731323 0.27589529752731323
rl training, epoch6, iter0, batch353/1133, batch loss:0.27589529752731323, Training time:19583.665551900864
batch reward last col mean 0.11981585621833801 first col mean 0.10523176938295364 all mean 0.11607664823532104
0.3045663833618164 0.3045663833618164
rl training, epoch6, iter0, batch354/1133, batch loss:0.3045663833618164, Training time:19585.475823402405
batch reward last col mean 0.12521645426750183 first col mean 0.09904421120882034 all mean 0.11067207157611847
0.3052557706832886 0.3052557706832886
rl training, epoch6, iter0, batch355/1133, batch loss:0.3052557706832886, Training time:19587.643833875656
batch reward last col mean 0.07496488094329834 first col mean 0.10371874272823334 all mean 0.08286630362272263
0.26006561517715454 0.26006561517715454
rl training, epoch6, iter0, batch356/1133, batch loss:0.26006561517715454, Training time:19589.945502519608
batch reward last col mean 0.0854044035077095 first col mean 0.11490926891565323 all mean 0.09438475221395493
0.28104081749916077 0.28104081749916077
rl training, epoch6, iter0, batch357/1133, batch loss:0.28104081749916077, Training time:19591.68023109436
batch reward last col mean 0.09353075176477432 first col mean 0.08088041096925735 all mean 0.09260311722755432
0.2636667490005493 0.2636667490005493
rl training, epoch6, iter0, batch358/1133, batch loss:0.2636667490005493, Training time:19593.770142793655
batch reward last col mean 0.1072017028927803 first col mean 0.1006593257188797 all mean 0.10915859788656235
0.28650540113449097 0.28650540113449097
rl training, epoch6, iter0, batch359/1133, batch loss:0.28650540113449097, Training time:19596.109565019608
batch reward last col mean 0.08658712357282639 first col mean 0.10585702210664749 all mean 0.0867714136838913
0.2385297268629074 0.2385297268629074
rl training, epoch6, iter0, batch360/1133, batch loss:0.2385297268629074, Training time:19598.31046152115
batch reward last col mean 0.0836198553442955 first col mean 0.12092141062021255 all mean 0.08968980610370636
0.2587096691131592 0.2587096691131592
rl training, epoch6, iter0, batch361/1133, batch loss:0.2587096691131592, Training time:19600.093631744385
batch reward last col mean 0.08362548053264618 first col mean 0.10559156537055969 all mean 0.0887724906206131
0.24726460874080658 0.24726460874080658
rl training, epoch6, iter0, batch362/1133, batch loss:0.24726460874080658, Training time:19602.60582613945
batch reward last col mean 0.1023607924580574 first col mean 0.08681493997573853 all mean 0.09744010120630264
0.2399042844772339 0.2399042844772339
rl training, epoch6, iter0, batch363/1133, batch loss:0.2399042844772339, Training time:19604.65889763832
batch reward last col mean 0.09658598899841309 first col mean 0.1060086116194725 all mean 0.09927399456501007
0.271305650472641 0.271305650472641
rl training, epoch6, iter0, batch364/1133, batch loss:0.271305650472641, Training time:19606.416234493256
batch reward last col mean 0.10708260536193848 first col mean 0.09212049096822739 all mean 0.09722422063350677
0.26069554686546326 0.26069554686546326
rl training, epoch6, iter0, batch365/1133, batch loss:0.26069554686546326, Training time:19608.189380645752
batch reward last col mean 0.15146425366401672 first col mean 0.08654195815324783 all mean 0.13435818254947662
0.31687361001968384 0.31687361001968384
rl training, epoch6, iter0, batch366/1133, batch loss:0.31687361001968384, Training time:19609.980063676834
batch reward last col mean 0.06405922025442123 first col mean 0.09694923460483551 all mean 0.07975482940673828
0.25580471754074097 0.25580471754074097
rl training, epoch6, iter0, batch367/1133, batch loss:0.25580471754074097, Training time:19611.76620531082
batch reward last col mean 0.11485706269741058 first col mean 0.10044924914836884 all mean 0.10678470879793167
0.28349554538726807 0.28349554538726807
rl training, epoch6, iter0, batch368/1133, batch loss:0.28349554538726807, Training time:19614.208191394806
batch reward last col mean 0.09733733534812927 first col mean 0.09981577098369598 all mean 0.10009023547172546
0.2635260224342346 0.2635260224342346
rl training, epoch6, iter0, batch369/1133, batch loss:0.2635260224342346, Training time:19616.48932480812
batch reward last col mean 0.11908095329999924 first col mean 0.09340614825487137 all mean 0.10910036414861679
0.2645053267478943 0.2645053267478943
rl training, epoch6, iter0, batch370/1133, batch loss:0.2645053267478943, Training time:19618.481335401535
batch reward last col mean 0.15065419673919678 first col mean 0.1104544997215271 all mean 0.1423591673374176
0.3051384389400482 0.3051384389400482
rl training, epoch6, iter0, batch371/1133, batch loss:0.3051384389400482, Training time:19620.338187217712
batch reward last col mean 0.14293962717056274 first col mean 0.09752858430147171 all mean 0.13185882568359375
0.330731064081192 0.330731064081192
rl training, epoch6, iter0, batch372/1133, batch loss:0.330731064081192, Training time:19622.251601696014
batch reward last col mean 0.09973479807376862 first col mean 0.11364990472793579 all mean 0.09944231063127518
0.265625536441803 0.265625536441803
rl training, epoch6, iter0, batch373/1133, batch loss:0.265625536441803, Training time:19624.57097196579
batch reward last col mean 0.10395004600286484 first col mean 0.09983915835618973 all mean 0.10686203092336655
0.26080945134162903 0.26080945134162903
rl training, epoch6, iter0, batch374/1133, batch loss:0.26080945134162903, Training time:19627.786066532135
batch reward last col mean 0.12112380564212799 first col mean 0.10741356760263443 all mean 0.11532533913850784
0.32429808378219604 0.32429808378219604
rl training, epoch6, iter0, batch375/1133, batch loss:0.32429808378219604, Training time:19630.176266670227
batch reward last col mean 0.11003121733665466 first col mean 0.10866378247737885 all mean 0.10954329371452332
0.26364725828170776 0.26364725828170776
rl training, epoch6, iter0, batch376/1133, batch loss:0.26364725828170776, Training time:19632.552171468735
batch reward last col mean 0.08815641701221466 first col mean 0.09448345005512238 all mean 0.09296303987503052
0.26395076513290405 0.26395076513290405
rl training, epoch6, iter0, batch377/1133, batch loss:0.26395076513290405, Training time:19634.633761405945
batch reward last col mean 0.1002613753080368 first col mean 0.09779076278209686 all mean 0.10378312319517136
0.2879604399204254 0.2879604399204254
rl training, epoch6, iter0, batch378/1133, batch loss:0.2879604399204254, Training time:19636.871431589127
batch reward last col mean 0.08448196202516556 first col mean 0.09823063015937805 all mean 0.0919904038310051
0.25865480303764343 0.25865480303764343
rl training, epoch6, iter0, batch379/1133, batch loss:0.25865480303764343, Training time:19638.441556692123
batch reward last col mean 0.12999603152275085 first col mean 0.09957738220691681 all mean 0.1215023323893547
0.29277902841567993 0.29277902841567993
rl training, epoch6, iter0, batch380/1133, batch loss:0.29277902841567993, Training time:19640.610992908478
batch reward last col mean 0.09482436627149582 first col mean 0.10621152073144913 all mean 0.09939265996217728
0.28285446763038635 0.28285446763038635
rl training, epoch6, iter0, batch381/1133, batch loss:0.28285446763038635, Training time:19642.90395474434
batch reward last col mean 0.10238029062747955 first col mean 0.12274205684661865 all mean 0.10483254492282867
0.27224797010421753 0.27224797010421753
rl training, epoch6, iter0, batch382/1133, batch loss:0.27224797010421753, Training time:19645.242191553116
batch reward last col mean 0.11084587126970291 first col mean 0.08304183185100555 all mean 0.10903716832399368
0.31917524337768555 0.31917524337768555
rl training, epoch6, iter0, batch383/1133, batch loss:0.31917524337768555, Training time:19647.472546339035
batch reward last col mean 0.10895092040300369 first col mean 0.12387093156576157 all mean 0.10854832082986832
0.29345324635505676 0.29345324635505676
rl training, epoch6, iter0, batch384/1133, batch loss:0.29345324635505676, Training time:19649.337422132492
batch reward last col mean 0.08931779116392136 first col mean 0.08959852159023285 all mean 0.0941256508231163
0.2707346975803375 0.2707346975803375
rl training, epoch6, iter0, batch385/1133, batch loss:0.2707346975803375, Training time:19651.08989739418
batch reward last col mean 0.10183583199977875 first col mean 0.11777088791131973 all mean 0.0998002141714096
0.23778313398361206 0.23778313398361206
rl training, epoch6, iter0, batch386/1133, batch loss:0.23778313398361206, Training time:19652.943261146545
batch reward last col mean 0.12175243347883224 first col mean 0.09392303228378296 all mean 0.11631841212511063
0.294650673866272 0.2946506440639496
rl training, epoch6, iter0, batch387/1133, batch loss:0.2946506440639496, Training time:19654.61332297325
batch reward last col mean 0.06278938800096512 first col mean 0.10545289516448975 all mean 0.07473089545965195
0.2466736137866974 0.2466736137866974
rl training, epoch6, iter0, batch388/1133, batch loss:0.2466736137866974, Training time:19656.29914355278
batch reward last col mean 0.13905955851078033 first col mean 0.13688430190086365 all mean 0.12703575193881989
0.32692497968673706 0.32692503929138184
rl training, epoch6, iter0, batch389/1133, batch loss:0.32692503929138184, Training time:19658.038426160812
batch reward last col mean 0.08308971673250198 first col mean 0.12297471612691879 all mean 0.08604376018047333
0.25675663352012634 0.25675663352012634
rl training, epoch6, iter0, batch390/1133, batch loss:0.25675663352012634, Training time:19660.246210813522
batch reward last col mean 0.12575538456439972 first col mean 0.10739505290985107 all mean 0.12070751190185547
0.27222883701324463 0.27222883701324463
rl training, epoch6, iter0, batch391/1133, batch loss:0.27222883701324463, Training time:19662.13649535179
batch reward last col mean 0.13008534908294678 first col mean 0.10411728173494339 all mean 0.11927714198827744
0.26348423957824707 0.26348423957824707
rl training, epoch6, iter0, batch392/1133, batch loss:0.26348423957824707, Training time:19664.20997619629
batch reward last col mean 0.09963163733482361 first col mean 0.1081337109208107 all mean 0.1024148017168045
0.29646557569503784 0.29646557569503784
rl training, epoch6, iter0, batch393/1133, batch loss:0.29646557569503784, Training time:19666.143847227097
batch reward last col mean 0.14070956408977509 first col mean 0.0974973812699318 all mean 0.13490886986255646
0.30538833141326904 0.30538833141326904
rl training, epoch6, iter0, batch394/1133, batch loss:0.30538833141326904, Training time:19668.373491048813
batch reward last col mean 0.11591189354658127 first col mean 0.11470836400985718 all mean 0.1153906062245369
0.28011301159858704 0.28011301159858704
rl training, epoch6, iter0, batch395/1133, batch loss:0.28011301159858704, Training time:19669.965461730957
batch reward last col mean 0.10188061743974686 first col mean 0.10137142241001129 all mean 0.10551635175943375
0.29785647988319397 0.29785647988319397
rl training, epoch6, iter0, batch396/1133, batch loss:0.29785647988319397, Training time:19672.182070732117
batch reward last col mean 0.05898824706673622 first col mean 0.10506358742713928 all mean 0.07455096393823624
0.23452532291412354 0.23452529311180115
rl training, epoch6, iter0, batch397/1133, batch loss:0.23452529311180115, Training time:19673.76729297638
batch reward last col mean 0.1056843027472496 first col mean 0.10783563554286957 all mean 0.10617813467979431
0.2683827877044678 0.2683827877044678
rl training, epoch6, iter0, batch398/1133, batch loss:0.2683827877044678, Training time:19676.218265533447
batch reward last col mean 0.10931434482336044 first col mean 0.114357128739357 all mean 0.11067406088113785
0.25334155559539795 0.25334155559539795
rl training, epoch6, iter0, batch399/1133, batch loss:0.25334155559539795, Training time:19678.54807639122
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.48346802421302154 Time: 95.14315056800842 s
loss of true 0.20945414278692412 loss of gen 0.17524765548933322 loss of other 0.09876622598444006 first score 0.11184202879667282
batch reward last col mean 0.10116513818502426 first col mean 0.10401047766208649 all mean 0.10028901696205139
0.29905828833580017 0.2990582585334778
rl training, epoch6, iter0, batch400/1133, batch loss:0.2990582585334778, Training time:19775.50714278221
batch reward last col mean 0.12323436141014099 first col mean 0.11318965256214142 all mean 0.1196805015206337
0.2950825095176697 0.2950825095176697
rl training, epoch6, iter0, batch401/1133, batch loss:0.2950825095176697, Training time:19777.26530981064
batch reward last col mean 0.10479097813367844 first col mean 0.09874232858419418 all mean 0.0962904542684555
0.25344476103782654 0.25344476103782654
rl training, epoch6, iter0, batch402/1133, batch loss:0.25344476103782654, Training time:19779.53377223015
batch reward last col mean 0.09198996424674988 first col mean 0.10528296232223511 all mean 0.09586722403764725
0.2997761368751526 0.2997761368751526
rl training, epoch6, iter0, batch403/1133, batch loss:0.2997761368751526, Training time:19780.853526830673
batch reward last col mean 0.09851015359163284 first col mean 0.08839650452136993 all mean 0.10241090506315231
0.2511550188064575 0.2511550188064575
rl training, epoch6, iter0, batch404/1133, batch loss:0.2511550188064575, Training time:19782.619380950928
batch reward last col mean 0.14080850780010223 first col mean 0.1042129322886467 all mean 0.1357569396495819
0.324521005153656 0.324521005153656
rl training, epoch6, iter0, batch405/1133, batch loss:0.324521005153656, Training time:19785.00542616844
batch reward last col mean 0.09195816516876221 first col mean 0.10345567762851715 all mean 0.09569724649190903
0.2899761497974396 0.2899761497974396
rl training, epoch6, iter0, batch406/1133, batch loss:0.2899761497974396, Training time:19787.55335998535
batch reward last col mean 0.08572360873222351 first col mean 0.10105035454034805 all mean 0.09263984113931656
0.26041048765182495 0.26041048765182495
rl training, epoch6, iter0, batch407/1133, batch loss:0.26041048765182495, Training time:19789.519273519516
batch reward last col mean 0.08352481573820114 first col mean 0.11848381906747818 all mean 0.09120003879070282
0.2681393027305603 0.2681393027305603
rl training, epoch6, iter0, batch408/1133, batch loss:0.2681393027305603, Training time:19791.018681764603
batch reward last col mean 0.06499002128839493 first col mean 0.09500639140605927 all mean 0.07053174078464508
0.2133447676897049 0.2133447676897049
rl training, epoch6, iter0, batch409/1133, batch loss:0.2133447676897049, Training time:19792.867165088654
batch reward last col mean 0.10698702931404114 first col mean 0.09853044152259827 all mean 0.10757558047771454
0.26925691962242126 0.26925691962242126
rl training, epoch6, iter0, batch410/1133, batch loss:0.26925691962242126, Training time:19794.418486118317
batch reward last col mean 0.08775115013122559 first col mean 0.10191889107227325 all mean 0.09272744506597519
0.28430357575416565 0.2843035161495209
rl training, epoch6, iter0, batch411/1133, batch loss:0.2843035161495209, Training time:19796.396548986435
batch reward last col mean 0.07801445573568344 first col mean 0.11610932648181915 all mean 0.08951504528522491
0.2857731282711029 0.2857730984687805
rl training, epoch6, iter0, batch412/1133, batch loss:0.2857730984687805, Training time:19797.914256095886
batch reward last col mean 0.15226030349731445 first col mean 0.10368852317333221 all mean 0.13795486092567444
0.3137633204460144 0.3137633204460144
rl training, epoch6, iter0, batch413/1133, batch loss:0.3137633204460144, Training time:19800.34322309494
batch reward last col mean 0.06839999556541443 first col mean 0.10722263157367706 all mean 0.07915504276752472
0.23661668598651886 0.23661668598651886
rl training, epoch6, iter0, batch414/1133, batch loss:0.23661668598651886, Training time:19802.02262878418
batch reward last col mean 0.08092539012432098 first col mean 0.11181233823299408 all mean 0.08443985134363174
0.27105575799942017 0.27105575799942017
rl training, epoch6, iter0, batch415/1133, batch loss:0.27105575799942017, Training time:19804.696128845215
batch reward last col mean 0.11884601414203644 first col mean 0.12448426336050034 all mean 0.11903400719165802
0.29353684186935425 0.29353684186935425
rl training, epoch6, iter0, batch416/1133, batch loss:0.29353684186935425, Training time:19806.53628873825
batch reward last col mean 0.08948390185832977 first col mean 0.10760755091905594 all mean 0.08985034376382828
0.29762810468673706 0.29762810468673706
rl training, epoch6, iter0, batch417/1133, batch loss:0.29762810468673706, Training time:19808.46359705925
batch reward last col mean 0.12589557468891144 first col mean 0.09798373281955719 all mean 0.12147777527570724
0.3086557984352112 0.3086557686328888
rl training, epoch6, iter0, batch418/1133, batch loss:0.3086557686328888, Training time:19810.843039274216
batch reward last col mean 0.08605898916721344 first col mean 0.09180024266242981 all mean 0.0881057009100914
0.29303762316703796 0.29303762316703796
rl training, epoch6, iter0, batch419/1133, batch loss:0.29303762316703796, Training time:19812.517566919327
batch reward last col mean 0.1005331501364708 first col mean 0.11263243854045868 all mean 0.10754624009132385
0.2577897906303406 0.2577897906303406
rl training, epoch6, iter0, batch420/1133, batch loss:0.2577897906303406, Training time:19814.3731405735
batch reward last col mean 0.1125079095363617 first col mean 0.0959802120923996 all mean 0.11266522854566574
0.28850144147872925 0.28850144147872925
rl training, epoch6, iter0, batch421/1133, batch loss:0.28850144147872925, Training time:19816.022481679916
batch reward last col mean 0.10723040997982025 first col mean 0.09805205464363098 all mean 0.10494683682918549
0.29186367988586426 0.29186370968818665
rl training, epoch6, iter0, batch422/1133, batch loss:0.29186370968818665, Training time:19817.739159584045
batch reward last col mean 0.08897799998521805 first col mean 0.10691618919372559 all mean 0.09160105139017105
0.2633510231971741 0.2633510231971741
rl training, epoch6, iter0, batch423/1133, batch loss:0.2633510231971741, Training time:19821.900289058685
batch reward last col mean 0.1028389111161232 first col mean 0.10016467422246933 all mean 0.10644467920064926
0.26844364404678345 0.26844361424446106
rl training, epoch6, iter0, batch424/1133, batch loss:0.26844361424446106, Training time:19823.50652241707
batch reward last col mean 0.10638558864593506 first col mean 0.124201700091362 all mean 0.10814851522445679
0.27061927318573 0.27061927318573
rl training, epoch6, iter0, batch425/1133, batch loss:0.27061927318573, Training time:19825.401234149933
batch reward last col mean 0.07312998175621033 first col mean 0.09904001653194427 all mean 0.08414117246866226
0.27042391896247864 0.27042391896247864
rl training, epoch6, iter0, batch426/1133, batch loss:0.27042391896247864, Training time:19827.11303305626
batch reward last col mean 0.12909430265426636 first col mean 0.10721127688884735 all mean 0.12258530408143997
0.28724205493927 0.28724205493927
rl training, epoch6, iter0, batch427/1133, batch loss:0.28724205493927, Training time:19829.095538139343
batch reward last col mean 0.09798268973827362 first col mean 0.12422949075698853 all mean 0.09989020228385925
0.2577551007270813 0.2577551007270813
rl training, epoch6, iter0, batch428/1133, batch loss:0.2577551007270813, Training time:19830.856237888336
batch reward last col mean 0.09550882875919342 first col mean 0.10389939695596695 all mean 0.10286927223205566
0.2963610291481018 0.2963610291481018
rl training, epoch6, iter0, batch429/1133, batch loss:0.2963610291481018, Training time:19832.693944454193
batch reward last col mean 0.08798794448375702 first col mean 0.10595659911632538 all mean 0.09608897566795349
0.267959326505661 0.267959326505661
rl training, epoch6, iter0, batch430/1133, batch loss:0.267959326505661, Training time:19834.342255830765
batch reward last col mean 0.12475734204053879 first col mean 0.10811173915863037 all mean 0.11968186497688293
0.29254862666130066 0.29254862666130066
rl training, epoch6, iter0, batch431/1133, batch loss:0.29254862666130066, Training time:19835.819153785706
batch reward last col mean 0.09671121835708618 first col mean 0.11502727121114731 all mean 0.09623150527477264
0.27036112546920776 0.27036112546920776
rl training, epoch6, iter0, batch432/1133, batch loss:0.27036112546920776, Training time:19838.24875164032
batch reward last col mean 0.10032720863819122 first col mean 0.12699700891971588 all mean 0.10595045238733292
0.29160553216934204 0.29160553216934204
rl training, epoch6, iter0, batch433/1133, batch loss:0.29160553216934204, Training time:19840.046415567398
batch reward last col mean 0.12506899237632751 first col mean 0.0976877436041832 all mean 0.1187332421541214
0.2898258566856384 0.2898258864879608
rl training, epoch6, iter0, batch434/1133, batch loss:0.2898258864879608, Training time:19841.93048119545
batch reward last col mean 0.08938250690698624 first col mean 0.12959058582782745 all mean 0.09820035845041275
0.29482781887054443 0.29482781887054443
rl training, epoch6, iter0, batch435/1133, batch loss:0.29482781887054443, Training time:19843.831180095673
batch reward last col mean 0.10324398428201675 first col mean 0.10120640695095062 all mean 0.10710585862398148
0.28863516449928284 0.28863516449928284
rl training, epoch6, iter0, batch436/1133, batch loss:0.28863516449928284, Training time:19845.739424705505
batch reward last col mean 0.12384729087352753 first col mean 0.10252020508050919 all mean 0.11351785063743591
0.2790876030921936 0.2790876030921936
rl training, epoch6, iter0, batch437/1133, batch loss:0.2790876030921936, Training time:19847.551224708557
batch reward last col mean 0.09794428944587708 first col mean 0.11150102317333221 all mean 0.09622932225465775
0.2857387661933899 0.2857387661933899
rl training, epoch6, iter0, batch438/1133, batch loss:0.2857387661933899, Training time:19849.848556756973
batch reward last col mean 0.0892971083521843 first col mean 0.11634261161088943 all mean 0.09238027036190033
0.27430474758148193 0.27430474758148193
rl training, epoch6, iter0, batch439/1133, batch loss:0.27430474758148193, Training time:19851.994745731354
batch reward last col mean 0.12901540100574493 first col mean 0.1012590080499649 all mean 0.12352126091718674
0.2885146141052246 0.2885146141052246
rl training, epoch6, iter0, batch440/1133, batch loss:0.2885146141052246, Training time:19853.743738651276
batch reward last col mean 0.10066991299390793 first col mean 0.10660457611083984 all mean 0.09694244712591171
0.257079541683197 0.257079541683197
rl training, epoch6, iter0, batch441/1133, batch loss:0.257079541683197, Training time:19855.356230020523
batch reward last col mean 0.10544280707836151 first col mean 0.11885005235671997 all mean 0.1029236912727356
0.2580643594264984 0.2580643594264984
rl training, epoch6, iter0, batch442/1133, batch loss:0.2580643594264984, Training time:19857.34888792038
batch reward last col mean 0.1097661554813385 first col mean 0.12122990190982819 all mean 0.10978351533412933
0.2897011935710907 0.2897011935710907
rl training, epoch6, iter0, batch443/1133, batch loss:0.2897011935710907, Training time:19859.035840272903
batch reward last col mean 0.07208932936191559 first col mean 0.09565672278404236 all mean 0.08535763621330261
0.2636564373970032 0.2636564075946808
rl training, epoch6, iter0, batch444/1133, batch loss:0.2636564075946808, Training time:19860.82972717285
batch reward last col mean 0.08584018796682358 first col mean 0.09387672692537308 all mean 0.09505170583724976
0.2925523817539215 0.2925523817539215
rl training, epoch6, iter0, batch445/1133, batch loss:0.2925523817539215, Training time:19862.77903318405
batch reward last col mean 0.10335937142372131 first col mean 0.10148442536592484 all mean 0.10639183223247528
0.2869472801685333 0.2869473099708557
rl training, epoch6, iter0, batch446/1133, batch loss:0.2869473099708557, Training time:19864.595041036606
batch reward last col mean 0.13185109198093414 first col mean 0.11659719794988632 all mean 0.1257210075855255
0.2706259489059448 0.2706259489059448
rl training, epoch6, iter0, batch447/1133, batch loss:0.2706259489059448, Training time:19866.923201322556
batch reward last col mean 0.12123126536607742 first col mean 0.09978576004505157 all mean 0.10864842683076859
0.2619350850582123 0.2619350850582123
rl training, epoch6, iter0, batch448/1133, batch loss:0.2619350850582123, Training time:19869.18411874771
batch reward last col mean 0.12871471047401428 first col mean 0.09457975625991821 all mean 0.12070046365261078
0.323368638753891 0.323368638753891
rl training, epoch6, iter0, batch449/1133, batch loss:0.323368638753891, Training time:19870.90766763687
batch reward last col mean 0.09312744438648224 first col mean 0.1089748740196228 all mean 0.09649914503097534
0.26932477951049805 0.26932474970817566
rl training, epoch6, iter0, batch450/1133, batch loss:0.26932474970817566, Training time:19872.388386249542
batch reward last col mean 0.11873328685760498 first col mean 0.10006709396839142 all mean 0.11300159245729446
0.2764071822166443 0.2764071822166443
rl training, epoch6, iter0, batch451/1133, batch loss:0.2764071822166443, Training time:19873.946901082993
batch reward last col mean 0.13559147715568542 first col mean 0.10781491547822952 all mean 0.12179150432348251
0.3075799345970154 0.3075799345970154
rl training, epoch6, iter0, batch452/1133, batch loss:0.3075799345970154, Training time:19875.397128105164
batch reward last col mean 0.10410880297422409 first col mean 0.11260133981704712 all mean 0.10622669011354446
0.283414751291275 0.28341472148895264
rl training, epoch6, iter0, batch453/1133, batch loss:0.28341472148895264, Training time:19877.05598425865
batch reward last col mean 0.09088708460330963 first col mean 0.12496265769004822 all mean 0.10664483904838562
0.3020881414413452 0.3020881414413452
rl training, epoch6, iter0, batch454/1133, batch loss:0.3020881414413452, Training time:19878.460067033768
batch reward last col mean 0.12643784284591675 first col mean 0.10646086186170578 all mean 0.12037614732980728
0.2783125936985016 0.2783125936985016
rl training, epoch6, iter0, batch455/1133, batch loss:0.2783125936985016, Training time:19880.38113951683
batch reward last col mean 0.09305870532989502 first col mean 0.11276670545339584 all mean 0.09484367817640305
0.2659648358821869 0.2659648358821869
rl training, epoch6, iter0, batch456/1133, batch loss:0.2659648358821869, Training time:19882.70022368431
batch reward last col mean 0.07635310292243958 first col mean 0.1007753312587738 all mean 0.0822082981467247
0.25512129068374634 0.2551213204860687
rl training, epoch6, iter0, batch457/1133, batch loss:0.2551213204860687, Training time:19884.532888412476
batch reward last col mean 0.08843138068914413 first col mean 0.10970024764537811 all mean 0.09308596700429916
0.2645218074321747 0.2645218074321747
rl training, epoch6, iter0, batch458/1133, batch loss:0.2645218074321747, Training time:19887.137323379517
batch reward last col mean 0.11504469066858292 first col mean 0.09136917442083359 all mean 0.11296557635068893
0.3311207890510559 0.3311207890510559
rl training, epoch6, iter0, batch459/1133, batch loss:0.3311207890510559, Training time:19889.28900051117
batch reward last col mean 0.10210579633712769 first col mean 0.09584393352270126 all mean 0.10400956124067307
0.27219927310943604 0.27219927310943604
rl training, epoch6, iter0, batch460/1133, batch loss:0.27219927310943604, Training time:19890.983203172684
batch reward last col mean 0.11304572224617004 first col mean 0.10347921401262283 all mean 0.10994307696819305
0.2725771963596344 0.2725771963596344
rl training, epoch6, iter0, batch461/1133, batch loss:0.2725771963596344, Training time:19893.747259140015
batch reward last col mean 0.11291618645191193 first col mean 0.09549175202846527 all mean 0.10466141253709793
0.27203890681266785 0.27203890681266785
rl training, epoch6, iter0, batch462/1133, batch loss:0.27203890681266785, Training time:19895.578926324844
batch reward last col mean 0.07654476165771484 first col mean 0.08069881051778793 all mean 0.0818789005279541
0.2632138729095459 0.2632138729095459
rl training, epoch6, iter0, batch463/1133, batch loss:0.2632138729095459, Training time:19897.258451223373
batch reward last col mean 0.0625820904970169 first col mean 0.10772787779569626 all mean 0.077234648168087
0.2450028955936432 0.2450028955936432
rl training, epoch6, iter0, batch464/1133, batch loss:0.2450028955936432, Training time:19898.88732433319
batch reward last col mean 0.1253405660390854 first col mean 0.10547713935375214 all mean 0.1152535080909729
0.2909713685512543 0.2909713685512543
rl training, epoch6, iter0, batch465/1133, batch loss:0.2909713685512543, Training time:19900.81970858574
batch reward last col mean 0.1128111481666565 first col mean 0.10676202178001404 all mean 0.1108359843492508
0.27736330032348633 0.27736330032348633
rl training, epoch6, iter0, batch466/1133, batch loss:0.27736330032348633, Training time:19903.353106975555
batch reward last col mean 0.10667960345745087 first col mean 0.11025242507457733 all mean 0.10910215973854065
0.34959498047828674 0.34959498047828674
rl training, epoch6, iter0, batch467/1133, batch loss:0.34959498047828674, Training time:19905.75462436676
batch reward last col mean 0.0929856225848198 first col mean 0.08567643165588379 all mean 0.0942152589559555
0.2561153769493103 0.2561153471469879
rl training, epoch6, iter0, batch468/1133, batch loss:0.2561153471469879, Training time:19907.49192714691
batch reward last col mean 0.12482400238513947 first col mean 0.10798715800046921 all mean 0.12854567170143127
0.3467242419719696 0.3467242419719696
rl training, epoch6, iter0, batch469/1133, batch loss:0.3467242419719696, Training time:19909.2204041481
batch reward last col mean 0.1019430160522461 first col mean 0.12896721065044403 all mean 0.10100894421339035
0.23625870048999786 0.23625870048999786
rl training, epoch6, iter0, batch470/1133, batch loss:0.23625870048999786, Training time:19911.042875766754
batch reward last col mean 0.0796043872833252 first col mean 0.09564158320426941 all mean 0.0852636843919754
0.2388148456811905 0.2388148307800293
rl training, epoch6, iter0, batch471/1133, batch loss:0.2388148307800293, Training time:19912.926454782486
batch reward last col mean 0.13502666354179382 first col mean 0.11779720336198807 all mean 0.13032186031341553
0.30190685391426086 0.30190685391426086
rl training, epoch6, iter0, batch472/1133, batch loss:0.30190685391426086, Training time:19914.50402379036
batch reward last col mean 0.11267414689064026 first col mean 0.1356024146080017 all mean 0.10297586023807526
0.2941896617412567 0.2941896617412567
rl training, epoch6, iter0, batch473/1133, batch loss:0.2941896617412567, Training time:19916.81527042389
batch reward last col mean 0.06695546954870224 first col mean 0.10928373038768768 all mean 0.07935313880443573
0.21196840703487396 0.21196840703487396
rl training, epoch6, iter0, batch474/1133, batch loss:0.21196840703487396, Training time:19919.035330057144
batch reward last col mean 0.12002940475940704 first col mean 0.1324605643749237 all mean 0.12033107131719589
0.31184121966362 0.31184121966362
rl training, epoch6, iter0, batch475/1133, batch loss:0.31184121966362, Training time:19920.96839737892
batch reward last col mean 0.08702676743268967 first col mean 0.11868727952241898 all mean 0.09249827265739441
0.246649369597435 0.246649369597435
rl training, epoch6, iter0, batch476/1133, batch loss:0.246649369597435, Training time:19922.75119328499
batch reward last col mean 0.09201785176992416 first col mean 0.12548615038394928 all mean 0.09905564785003662
0.294856458902359 0.294856458902359
rl training, epoch6, iter0, batch477/1133, batch loss:0.294856458902359, Training time:19924.658582687378
batch reward last col mean 0.11267590522766113 first col mean 0.1166045144200325 all mean 0.11158337444067001
0.3121747374534607 0.3121747374534607
rl training, epoch6, iter0, batch478/1133, batch loss:0.3121747374534607, Training time:19926.427175283432
batch reward last col mean 0.10104633122682571 first col mean 0.11387227475643158 all mean 0.10824885964393616
0.3186263144016266 0.3186263144016266
rl training, epoch6, iter0, batch479/1133, batch loss:0.3186263144016266, Training time:19927.974578857422
batch reward last col mean 0.13359802961349487 first col mean 0.10713629424571991 all mean 0.12909212708473206
0.32024988532066345 0.32024988532066345
rl training, epoch6, iter0, batch480/1133, batch loss:0.32024988532066345, Training time:19929.638946533203
batch reward last col mean 0.08710655570030212 first col mean 0.1306382715702057 all mean 0.09511422365903854
0.3017908036708832 0.3017908036708832
rl training, epoch6, iter0, batch481/1133, batch loss:0.3017908036708832, Training time:19931.152039527893
batch reward last col mean 0.09099757671356201 first col mean 0.10223895311355591 all mean 0.09705805033445358
0.26413536071777344 0.26413536071777344
rl training, epoch6, iter0, batch482/1133, batch loss:0.26413536071777344, Training time:19932.630484342575
batch reward last col mean 0.12828822433948517 first col mean 0.12046153098344803 all mean 0.12118227034807205
0.32050517201423645 0.32050517201423645
rl training, epoch6, iter0, batch483/1133, batch loss:0.32050517201423645, Training time:19934.50111889839
batch reward last col mean 0.09437483549118042 first col mean 0.11001966148614883 all mean 0.09774862974882126
0.31526806950569153 0.31526806950569153
rl training, epoch6, iter0, batch484/1133, batch loss:0.31526806950569153, Training time:19936.404072523117
batch reward last col mean 0.12423969060182571 first col mean 0.10699314624071121 all mean 0.12382127344608307
0.29215767979621887 0.29215767979621887
rl training, epoch6, iter0, batch485/1133, batch loss:0.29215767979621887, Training time:19938.47285103798
batch reward last col mean 0.12363933771848679 first col mean 0.08784079551696777 all mean 0.11112421005964279
0.30447930097579956 0.30447930097579956
rl training, epoch6, iter0, batch486/1133, batch loss:0.30447930097579956, Training time:19940.171604394913
batch reward last col mean 0.11351542174816132 first col mean 0.11802913248538971 all mean 0.11568866670131683
0.2846955358982086 0.2846955358982086
rl training, epoch6, iter0, batch487/1133, batch loss:0.2846955358982086, Training time:19942.47009253502
batch reward last col mean 0.1215316578745842 first col mean 0.09235942363739014 all mean 0.11609186977148056
0.2803344428539276 0.2803344428539276
rl training, epoch6, iter0, batch488/1133, batch loss:0.2803344428539276, Training time:19944.11634850502
batch reward last col mean 0.0741187185049057 first col mean 0.12277128547430038 all mean 0.08734999597072601
0.2998436391353607 0.2998436689376831
rl training, epoch6, iter0, batch489/1133, batch loss:0.2998436689376831, Training time:19946.011389017105
batch reward last col mean 0.10391754657030106 first col mean 0.1126328632235527 all mean 0.10176800936460495
0.28107643127441406 0.28107643127441406
rl training, epoch6, iter0, batch490/1133, batch loss:0.28107643127441406, Training time:19947.88978624344
batch reward last col mean 0.09588916599750519 first col mean 0.11407463252544403 all mean 0.09885266423225403
0.2842768132686615 0.2842768132686615
rl training, epoch6, iter0, batch491/1133, batch loss:0.2842768132686615, Training time:19949.919355630875
batch reward last col mean 0.1459706723690033 first col mean 0.11111754924058914 all mean 0.13819938898086548
0.2994333505630493 0.2994333505630493
rl training, epoch6, iter0, batch492/1133, batch loss:0.2994333505630493, Training time:19951.739471673965
batch reward last col mean 0.07944028079509735 first col mean 0.1051761656999588 all mean 0.08776173740625381
0.2714369297027588 0.2714369297027588
rl training, epoch6, iter0, batch493/1133, batch loss:0.2714369297027588, Training time:19953.5333275795
batch reward last col mean 0.1217167004942894 first col mean 0.09888216108083725 all mean 0.11646438390016556
0.28251704573631287 0.28251704573631287
rl training, epoch6, iter0, batch494/1133, batch loss:0.28251704573631287, Training time:19955.401114463806
batch reward last col mean 0.10357891023159027 first col mean 0.1156388372182846 all mean 0.09881678968667984
0.29085996747016907 0.29085996747016907
rl training, epoch6, iter0, batch495/1133, batch loss:0.29085996747016907, Training time:19957.133280038834
batch reward last col mean 0.09826569259166718 first col mean 0.1008673757314682 all mean 0.09798811376094818
0.2729978859424591 0.2729979157447815
rl training, epoch6, iter0, batch496/1133, batch loss:0.2729979157447815, Training time:19958.75751018524
batch reward last col mean 0.10927926003932953 first col mean 0.10886627435684204 all mean 0.10492217540740967
0.3225933015346527 0.3225933015346527
rl training, epoch6, iter0, batch497/1133, batch loss:0.3225933015346527, Training time:19960.46944618225
batch reward last col mean 0.10971718281507492 first col mean 0.09306339174509048 all mean 0.10963760316371918
0.2959088683128357 0.2959088683128357
rl training, epoch6, iter0, batch498/1133, batch loss:0.2959088683128357, Training time:19962.109303236008
batch reward last col mean 0.1220698207616806 first col mean 0.12221027910709381 all mean 0.1260872334241867
0.3371550738811493 0.3371550440788269
rl training, epoch6, iter0, batch499/1133, batch loss:0.3371550440788269, Training time:19964.19983315468
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4861819349025481 Time: 95.13258957862854 s
loss of true 0.21054733390052657 loss of gen 0.17636700303335687 loss of other 0.09926759815936792 first score 0.13782839477062225
batch reward last col mean 0.09255728125572205 first col mean 0.0957631766796112 all mean 0.09864307194948196
0.25171706080436707 0.25171706080436707
rl training, epoch6, iter0, batch500/1133, batch loss:0.25171706080436707, Training time:20060.815222263336
batch reward last col mean 0.07812181860208511 first col mean 0.10918598622083664 all mean 0.08410852402448654
0.25061312317848206 0.25061312317848206
rl training, epoch6, iter0, batch501/1133, batch loss:0.25061312317848206, Training time:20062.621785640717
batch reward last col mean 0.10563887655735016 first col mean 0.12767037749290466 all mean 0.10618702322244644
0.29962262511253357 0.29962262511253357
rl training, epoch6, iter0, batch502/1133, batch loss:0.29962262511253357, Training time:20064.78337931633
batch reward last col mean 0.09557010233402252 first col mean 0.10469481348991394 all mean 0.0935850739479065
0.2608882784843445 0.2608882784843445
rl training, epoch6, iter0, batch503/1133, batch loss:0.2608882784843445, Training time:20066.634661197662
batch reward last col mean 0.10279566794633865 first col mean 0.10788703709840775 all mean 0.1035318672657013
0.2577039897441864 0.2577039897441864
rl training, epoch6, iter0, batch504/1133, batch loss:0.2577039897441864, Training time:20069.488117933273
batch reward last col mean 0.08510984480381012 first col mean 0.10395704209804535 all mean 0.08984710276126862
0.25905412435531616 0.25905412435531616
rl training, epoch6, iter0, batch505/1133, batch loss:0.25905412435531616, Training time:20071.312732458115
batch reward last col mean 0.11722318828105927 first col mean 0.0829695612192154 all mean 0.11036688089370728
0.284166544675827 0.284166544675827
rl training, epoch6, iter0, batch506/1133, batch loss:0.284166544675827, Training time:20073.09760451317
batch reward last col mean 0.11929988861083984 first col mean 0.09993070363998413 all mean 0.11803923547267914
0.29589924216270447 0.2958991825580597
rl training, epoch6, iter0, batch507/1133, batch loss:0.2958991825580597, Training time:20074.99583721161
batch reward last col mean 0.14620456099510193 first col mean 0.09485089033842087 all mean 0.13580308854579926
0.26896220445632935 0.26896220445632935
rl training, epoch6, iter0, batch508/1133, batch loss:0.26896220445632935, Training time:20078.129469156265
batch reward last col mean 0.12922333180904388 first col mean 0.11432918906211853 all mean 0.12283682078123093
0.2948659360408783 0.2948659360408783
rl training, epoch6, iter0, batch509/1133, batch loss:0.2948659360408783, Training time:20079.899124860764
batch reward last col mean 0.12985239923000336 first col mean 0.10980702936649323 all mean 0.11837971955537796
0.2800702154636383 0.2800702154636383
rl training, epoch6, iter0, batch510/1133, batch loss:0.2800702154636383, Training time:20081.883945703506
batch reward last col mean 0.07844174653291702 first col mean 0.09543938934803009 all mean 0.08844353258609772
0.24957582354545593 0.24957582354545593
rl training, epoch6, iter0, batch511/1133, batch loss:0.24957582354545593, Training time:20083.44849920273
batch reward last col mean 0.09368439018726349 first col mean 0.09693849086761475 all mean 0.10042896866798401
0.27159345149993896 0.27159345149993896
rl training, epoch6, iter0, batch512/1133, batch loss:0.27159345149993896, Training time:20085.285561084747
batch reward last col mean 0.10002397000789642 first col mean 0.11163084208965302 all mean 0.09857752919197083
0.259573370218277 0.259573370218277
rl training, epoch6, iter0, batch513/1133, batch loss:0.259573370218277, Training time:20087.28654360771
batch reward last col mean 0.0806877464056015 first col mean 0.09109704941511154 all mean 0.08938462287187576
0.26595473289489746 0.26595473289489746
rl training, epoch6, iter0, batch514/1133, batch loss:0.26595473289489746, Training time:20088.96414232254
batch reward last col mean 0.14762873947620392 first col mean 0.1076066717505455 all mean 0.13843746483325958
0.3282625079154968 0.3282625377178192
rl training, epoch6, iter0, batch515/1133, batch loss:0.3282625377178192, Training time:20091.22643852234
batch reward last col mean 0.09443633258342743 first col mean 0.112874835729599 all mean 0.09740728884935379
0.2498588263988495 0.2498588114976883
rl training, epoch6, iter0, batch516/1133, batch loss:0.2498588114976883, Training time:20093.208691120148
batch reward last col mean 0.06803621351718903 first col mean 0.12480038404464722 all mean 0.08216982334852219
0.262735515832901 0.262735515832901
rl training, epoch6, iter0, batch517/1133, batch loss:0.262735515832901, Training time:20094.85481619835
batch reward last col mean 0.09164530038833618 first col mean 0.1142575740814209 all mean 0.09927140921354294
0.2956932485103607 0.2956932485103607
rl training, epoch6, iter0, batch518/1133, batch loss:0.2956932485103607, Training time:20096.466232776642
batch reward last col mean 0.09685055166482925 first col mean 0.10918048769235611 all mean 0.09774639457464218
0.29660287499427795 0.29660287499427795
rl training, epoch6, iter0, batch519/1133, batch loss:0.29660287499427795, Training time:20098.16229224205
batch reward last col mean 0.09350285679101944 first col mean 0.0982251763343811 all mean 0.10024481266736984
0.2540803551673889 0.2540803551673889
rl training, epoch6, iter0, batch520/1133, batch loss:0.2540803551673889, Training time:20099.764825820923
batch reward last col mean 0.11727367341518402 first col mean 0.1022312343120575 all mean 0.11431745439767838
0.3024885058403015 0.3024885058403015
rl training, epoch6, iter0, batch521/1133, batch loss:0.3024885058403015, Training time:20101.512741327286
batch reward last col mean 0.09522341936826706 first col mean 0.10479435324668884 all mean 0.10037415474653244
0.2817530333995819 0.2817530333995819
rl training, epoch6, iter0, batch522/1133, batch loss:0.2817530333995819, Training time:20103.338381052017
batch reward last col mean 0.11695465445518494 first col mean 0.09071901440620422 all mean 0.11815191060304642
0.29255303740501404 0.29255303740501404
rl training, epoch6, iter0, batch523/1133, batch loss:0.29255303740501404, Training time:20105.222036600113
batch reward last col mean 0.12430677562952042 first col mean 0.11463282257318497 all mean 0.1210787296295166
0.2951924800872803 0.2951924502849579
rl training, epoch6, iter0, batch524/1133, batch loss:0.2951924502849579, Training time:20107.350499868393
batch reward last col mean 0.10238417237997055 first col mean 0.10695797204971313 all mean 0.10846252739429474
0.2918536067008972 0.2918536067008972
rl training, epoch6, iter0, batch525/1133, batch loss:0.2918536067008972, Training time:20109.083000183105
batch reward last col mean 0.10731561481952667 first col mean 0.08846843987703323 all mean 0.10205661505460739
0.2386041134595871 0.2386040836572647
rl training, epoch6, iter0, batch526/1133, batch loss:0.2386040836572647, Training time:20110.79026579857
batch reward last col mean 0.1056598424911499 first col mean 0.10958883166313171 all mean 0.10532309859991074
0.2951972484588623 0.2951972186565399
rl training, epoch6, iter0, batch527/1133, batch loss:0.2951972186565399, Training time:20113.035188913345
batch reward last col mean 0.104680135846138 first col mean 0.09504673629999161 all mean 0.10394147038459778
0.30310142040252686 0.30310142040252686
rl training, epoch6, iter0, batch528/1133, batch loss:0.30310142040252686, Training time:20115.31110906601
batch reward last col mean 0.11409328132867813 first col mean 0.10071881115436554 all mean 0.10741832852363586
0.2700035572052002 0.2700035572052002
rl training, epoch6, iter0, batch529/1133, batch loss:0.2700035572052002, Training time:20117.280126571655
batch reward last col mean 0.08754720538854599 first col mean 0.09878678619861603 all mean 0.08792635053396225
0.21733921766281128 0.21733921766281128
rl training, epoch6, iter0, batch530/1133, batch loss:0.21733921766281128, Training time:20119.82700777054
batch reward last col mean 0.07438082993030548 first col mean 0.11546102166175842 all mean 0.08276662230491638
0.2730977535247803 0.2730977535247803
rl training, epoch6, iter0, batch531/1133, batch loss:0.2730977535247803, Training time:20121.959092140198
batch reward last col mean 0.12322841584682465 first col mean 0.11444069445133209 all mean 0.12563610076904297
0.3067724108695984 0.3067724108695984
rl training, epoch6, iter0, batch532/1133, batch loss:0.3067724108695984, Training time:20124.040616750717
batch reward last col mean 0.10179568827152252 first col mean 0.10220466554164886 all mean 0.10035307705402374
0.2525389492511749 0.2525389492511749
rl training, epoch6, iter0, batch533/1133, batch loss:0.2525389492511749, Training time:20126.04762816429
batch reward last col mean 0.1296459436416626 first col mean 0.10348847508430481 all mean 0.1239594891667366
0.3125341534614563 0.3125341534614563
rl training, epoch6, iter0, batch534/1133, batch loss:0.3125341534614563, Training time:20128.38068151474
batch reward last col mean 0.08841314911842346 first col mean 0.08516167104244232 all mean 0.09693460166454315
0.28124019503593445 0.28124019503593445
rl training, epoch6, iter0, batch535/1133, batch loss:0.28124019503593445, Training time:20130.43744969368
batch reward last col mean 0.08454358577728271 first col mean 0.09677432477474213 all mean 0.08797404170036316
0.26352375745773315 0.26352378726005554
rl training, epoch6, iter0, batch536/1133, batch loss:0.26352378726005554, Training time:20132.305352926254
batch reward last col mean 0.11796802282333374 first col mean 0.09889453649520874 all mean 0.11534678190946579
0.3084174692630768 0.3084174692630768
rl training, epoch6, iter0, batch537/1133, batch loss:0.3084174692630768, Training time:20134.641943216324
batch reward last col mean 0.07899209856987 first col mean 0.10458789020776749 all mean 0.08940740674734116
0.2845800817012787 0.2845801115036011
rl training, epoch6, iter0, batch538/1133, batch loss:0.2845801115036011, Training time:20136.391565799713
batch reward last col mean 0.08611376583576202 first col mean 0.11288721114397049 all mean 0.09255797415971756
0.2709077000617981 0.2709077000617981
rl training, epoch6, iter0, batch539/1133, batch loss:0.2709077000617981, Training time:20138.161569595337
batch reward last col mean 0.10113973915576935 first col mean 0.10796891897916794 all mean 0.10156766325235367
0.2768666446208954 0.2768666744232178
rl training, epoch6, iter0, batch540/1133, batch loss:0.2768666744232178, Training time:20140.036811828613
batch reward last col mean 0.10145188868045807 first col mean 0.1056995838880539 all mean 0.10725110024213791
0.32064998149871826 0.32064998149871826
rl training, epoch6, iter0, batch541/1133, batch loss:0.32064998149871826, Training time:20141.72209572792
batch reward last col mean 0.1284591555595398 first col mean 0.10492672026157379 all mean 0.11793985217809677
0.2932743728160858 0.2932743728160858
rl training, epoch6, iter0, batch542/1133, batch loss:0.2932743728160858, Training time:20143.545955181122
batch reward last col mean 0.11562469601631165 first col mean 0.08055183291435242 all mean 0.11125558614730835
0.2618558704853058 0.2618558704853058
rl training, epoch6, iter0, batch543/1133, batch loss:0.2618558704853058, Training time:20144.9583902359
batch reward last col mean 0.0849069207906723 first col mean 0.11168885231018066 all mean 0.09789497405290604
0.2901005148887634 0.2901005148887634
rl training, epoch6, iter0, batch544/1133, batch loss:0.2901005148887634, Training time:20146.739535808563
batch reward last col mean 0.06309883296489716 first col mean 0.10763286054134369 all mean 0.07821875810623169
0.25104331970214844 0.25104331970214844
rl training, epoch6, iter0, batch545/1133, batch loss:0.25104331970214844, Training time:20148.337188482285
batch reward last col mean 0.097157783806324 first col mean 0.09022589027881622 all mean 0.0983695238828659
0.27407363057136536 0.27407360076904297
rl training, epoch6, iter0, batch546/1133, batch loss:0.27407360076904297, Training time:20150.67624282837
batch reward last col mean 0.0881265178322792 first col mean 0.11326855421066284 all mean 0.09044836461544037
0.23826676607131958 0.23826676607131958
rl training, epoch6, iter0, batch547/1133, batch loss:0.23826676607131958, Training time:20152.539885759354
batch reward last col mean 0.09333138167858124 first col mean 0.0956365317106247 all mean 0.09747979044914246
0.28775498270988464 0.28775498270988464
rl training, epoch6, iter0, batch548/1133, batch loss:0.28775498270988464, Training time:20154.331968545914
batch reward last col mean 0.09303008019924164 first col mean 0.11115613579750061 all mean 0.09859440475702286
0.26499927043914795 0.26499927043914795
rl training, epoch6, iter0, batch549/1133, batch loss:0.26499927043914795, Training time:20156.336261749268
batch reward last col mean 0.11982037127017975 first col mean 0.09998035430908203 all mean 0.1091654971241951
0.3167627453804016 0.3167627453804016
rl training, epoch6, iter0, batch550/1133, batch loss:0.3167627453804016, Training time:20158.26399064064
batch reward last col mean 0.12741322815418243 first col mean 0.1089341938495636 all mean 0.11874683201313019
0.2997863292694092 0.2997863292694092
rl training, epoch6, iter0, batch551/1133, batch loss:0.2997863292694092, Training time:20159.71008682251
batch reward last col mean 0.10665372014045715 first col mean 0.10084356367588043 all mean 0.1061764657497406
0.2657046914100647 0.2657046914100647
rl training, epoch6, iter0, batch552/1133, batch loss:0.2657046914100647, Training time:20161.776913642883
batch reward last col mean 0.08601011335849762 first col mean 0.10573549568653107 all mean 0.08570486307144165
0.26877766847610474 0.26877766847610474
rl training, epoch6, iter0, batch553/1133, batch loss:0.26877766847610474, Training time:20164.009006500244
batch reward last col mean 0.13431492447853088 first col mean 0.1085243970155716 all mean 0.12605327367782593
0.3326210081577301 0.3326210081577301
rl training, epoch6, iter0, batch554/1133, batch loss:0.3326210081577301, Training time:20166.102647304535
batch reward last col mean 0.06439405679702759 first col mean 0.09605927020311356 all mean 0.07225797325372696
0.22141477465629578 0.22141477465629578
rl training, epoch6, iter0, batch555/1133, batch loss:0.22141477465629578, Training time:20168.332634210587
batch reward last col mean 0.1259191930294037 first col mean 0.10614624619483948 all mean 0.11622856557369232
0.28017422556877136 0.28017422556877136
rl training, epoch6, iter0, batch556/1133, batch loss:0.28017422556877136, Training time:20170.523398160934
batch reward last col mean 0.12191087007522583 first col mean 0.10903984308242798 all mean 0.11416475474834442
0.2663910984992981 0.2663910984992981
rl training, epoch6, iter0, batch557/1133, batch loss:0.2663910984992981, Training time:20172.510514736176
batch reward last col mean 0.08277510851621628 first col mean 0.10562163591384888 all mean 0.0867946520447731
0.24085067212581635 0.24085067212581635
rl training, epoch6, iter0, batch558/1133, batch loss:0.24085067212581635, Training time:20174.80650949478
batch reward last col mean 0.11509473621845245 first col mean 0.10837008059024811 all mean 0.1097337007522583
0.3043935298919678 0.3043935298919678
rl training, epoch6, iter0, batch559/1133, batch loss:0.3043935298919678, Training time:20176.646142959595
batch reward last col mean 0.08686839044094086 first col mean 0.09716334193944931 all mean 0.09134843200445175
0.27249711751937866 0.2724970877170563
rl training, epoch6, iter0, batch560/1133, batch loss:0.2724970877170563, Training time:20178.40651488304
batch reward last col mean 0.08455098420381546 first col mean 0.12206324934959412 all mean 0.09288473427295685
0.3139955997467041 0.3139955997467041
rl training, epoch6, iter0, batch561/1133, batch loss:0.3139955997467041, Training time:20180.252246141434
batch reward last col mean 0.09592685103416443 first col mean 0.11621848493814468 all mean 0.09979908168315887
0.3078007996082306 0.3078007996082306
rl training, epoch6, iter0, batch562/1133, batch loss:0.3078007996082306, Training time:20182.617369174957
batch reward last col mean 0.08292156457901001 first col mean 0.11946733295917511 all mean 0.0865088552236557
0.3230648934841156 0.3230648934841156
rl training, epoch6, iter0, batch563/1133, batch loss:0.3230648934841156, Training time:20185.301752090454
batch reward last col mean 0.08295746892690659 first col mean 0.1071142852306366 all mean 0.08957222104072571
0.27203771471977234 0.27203771471977234
rl training, epoch6, iter0, batch564/1133, batch loss:0.27203771471977234, Training time:20187.002143621445
batch reward last col mean 0.13655327260494232 first col mean 0.09911768138408661 all mean 0.11891446262598038
0.26781922578811646 0.26781922578811646
rl training, epoch6, iter0, batch565/1133, batch loss:0.26781922578811646, Training time:20188.519409418106
batch reward last col mean 0.10344796627759933 first col mean 0.11628008633852005 all mean 0.10733756422996521
0.29025959968566895 0.29025959968566895
rl training, epoch6, iter0, batch566/1133, batch loss:0.29025959968566895, Training time:20191.285999059677
batch reward last col mean 0.12837527692317963 first col mean 0.10233855247497559 all mean 0.1177259162068367
0.2926003336906433 0.2926003336906433
rl training, epoch6, iter0, batch567/1133, batch loss:0.2926003336906433, Training time:20192.879318237305
batch reward last col mean 0.1150805801153183 first col mean 0.10219451040029526 all mean 0.11189313977956772
0.2806371748447418 0.2806371748447418
rl training, epoch6, iter0, batch568/1133, batch loss:0.2806371748447418, Training time:20194.5842833519
batch reward last col mean 0.07730409502983093 first col mean 0.09846572577953339 all mean 0.08993231505155563
0.2472502887248993 0.2472502589225769
rl training, epoch6, iter0, batch569/1133, batch loss:0.2472502589225769, Training time:20196.25672698021
batch reward last col mean 0.10060545802116394 first col mean 0.11663605272769928 all mean 0.10307414084672928
0.27020540833473206 0.27020540833473206
rl training, epoch6, iter0, batch570/1133, batch loss:0.27020540833473206, Training time:20197.65293955803
batch reward last col mean 0.11214181780815125 first col mean 0.10849067568778992 all mean 0.10827182233333588
0.31042787432670593 0.31042787432670593
rl training, epoch6, iter0, batch571/1133, batch loss:0.31042787432670593, Training time:20199.323722600937
batch reward last col mean 0.11561929434537888 first col mean 0.09878545254468918 all mean 0.11248359829187393
0.2587619125843048 0.2587618827819824
rl training, epoch6, iter0, batch572/1133, batch loss:0.2587618827819824, Training time:20201.110801935196
batch reward last col mean 0.13054203987121582 first col mean 0.11231078207492828 all mean 0.12324853241443634
0.3326069414615631 0.33260688185691833
rl training, epoch6, iter0, batch573/1133, batch loss:0.33260688185691833, Training time:20202.766163110733
batch reward last col mean 0.08981864899396896 first col mean 0.11243510991334915 all mean 0.09254027158021927
0.2591480016708374 0.2591480314731598
rl training, epoch6, iter0, batch574/1133, batch loss:0.2591480314731598, Training time:20204.366386413574
batch reward last col mean 0.08808694779872894 first col mean 0.09320439398288727 all mean 0.09484238177537918
0.2919681668281555 0.2919681668281555
rl training, epoch6, iter0, batch575/1133, batch loss:0.2919681668281555, Training time:20206.047375440598
batch reward last col mean 0.11086418479681015 first col mean 0.09807608276605606 all mean 0.09725235402584076
0.33336344361305237 0.33336344361305237
rl training, epoch6, iter0, batch576/1133, batch loss:0.33336344361305237, Training time:20207.825483560562
batch reward last col mean 0.08644501119852066 first col mean 0.13201482594013214 all mean 0.0916837677359581
0.25934356451034546 0.25934356451034546
rl training, epoch6, iter0, batch577/1133, batch loss:0.25934356451034546, Training time:20209.576510190964
batch reward last col mean 0.11540139466524124 first col mean 0.11862404644489288 all mean 0.11669372767210007
0.3045647442340851 0.3045647442340851
rl training, epoch6, iter0, batch578/1133, batch loss:0.3045647442340851, Training time:20211.62318778038
batch reward last col mean 0.09418202936649323 first col mean 0.120480976998806 all mean 0.09834670275449753
0.24966514110565186 0.24966514110565186
rl training, epoch6, iter0, batch579/1133, batch loss:0.24966514110565186, Training time:20213.276701688766
batch reward last col mean 0.12193585932254791 first col mean 0.11225149035453796 all mean 0.11377506703138351
0.30902302265167236 0.30902302265167236
rl training, epoch6, iter0, batch580/1133, batch loss:0.30902302265167236, Training time:20215.064707756042
batch reward last col mean 0.08445976674556732 first col mean 0.09887470304965973 all mean 0.08642186224460602
0.2589893341064453 0.2589893341064453
rl training, epoch6, iter0, batch581/1133, batch loss:0.2589893341064453, Training time:20217.50991487503
batch reward last col mean 0.09422016888856888 first col mean 0.1001354306936264 all mean 0.09585707634687424
0.26774898171424866 0.26774898171424866
rl training, epoch6, iter0, batch582/1133, batch loss:0.26774898171424866, Training time:20220.080418348312
batch reward last col mean 0.08213429898023605 first col mean 0.11281350255012512 all mean 0.08741291612386703
0.2867060899734497 0.2867060899734497
rl training, epoch6, iter0, batch583/1133, batch loss:0.2867060899734497, Training time:20221.939888954163
batch reward last col mean 0.1231040358543396 first col mean 0.09852975606918335 all mean 0.11339616030454636
0.2860991358757019 0.2860991358757019
rl training, epoch6, iter0, batch584/1133, batch loss:0.2860991358757019, Training time:20224.14094567299
batch reward last col mean 0.10361175239086151 first col mean 0.09428293257951736 all mean 0.10916555672883987
0.3327797055244446 0.3327797055244446
rl training, epoch6, iter0, batch585/1133, batch loss:0.3327797055244446, Training time:20226.356036663055
batch reward last col mean 0.11510789394378662 first col mean 0.10830267518758774 all mean 0.11242517083883286
0.29041460156440735 0.29041463136672974
rl training, epoch6, iter0, batch586/1133, batch loss:0.29041463136672974, Training time:20229.244989156723
batch reward last col mean 0.09742727130651474 first col mean 0.0920971930027008 all mean 0.10013268142938614
0.30013516545295715 0.30013519525527954
rl training, epoch6, iter0, batch587/1133, batch loss:0.30013519525527954, Training time:20230.869713544846
batch reward last col mean 0.07954565435647964 first col mean 0.12804125249385834 all mean 0.09406387060880661
0.3149834871292114 0.3149834871292114
rl training, epoch6, iter0, batch588/1133, batch loss:0.3149834871292114, Training time:20232.652769088745
batch reward last col mean 0.1185828149318695 first col mean 0.10391074419021606 all mean 0.11222906410694122
0.3161933124065399 0.3161933124065399
rl training, epoch6, iter0, batch589/1133, batch loss:0.3161933124065399, Training time:20234.508946418762
batch reward last col mean 0.11932931840419769 first col mean 0.11543972790241241 all mean 0.11341667175292969
0.3209329843521118 0.3209329843521118
rl training, epoch6, iter0, batch590/1133, batch loss:0.3209329843521118, Training time:20236.122123003006
batch reward last col mean 0.10602036863565445 first col mean 0.10698619484901428 all mean 0.10155963897705078
0.2788923680782318 0.2788923978805542
rl training, epoch6, iter0, batch591/1133, batch loss:0.2788923978805542, Training time:20237.884259939194
batch reward last col mean 0.14169694483280182 first col mean 0.10779502242803574 all mean 0.13432292640209198
0.2842696011066437 0.2842696011066437
rl training, epoch6, iter0, batch592/1133, batch loss:0.2842696011066437, Training time:20241.08156967163
batch reward last col mean 0.08048654347658157 first col mean 0.12026475369930267 all mean 0.08617350459098816
0.25999683141708374 0.25999686121940613
rl training, epoch6, iter0, batch593/1133, batch loss:0.25999686121940613, Training time:20242.963590860367
batch reward last col mean 0.1049189493060112 first col mean 0.08904300630092621 all mean 0.1053801029920578
0.2662769854068756 0.2662769854068756
rl training, epoch6, iter0, batch594/1133, batch loss:0.2662769854068756, Training time:20244.800046682358
batch reward last col mean 0.08285759389400482 first col mean 0.11174803972244263 all mean 0.08813908696174622
0.25633782148361206 0.25633782148361206
rl training, epoch6, iter0, batch595/1133, batch loss:0.25633782148361206, Training time:20246.480478286743
batch reward last col mean 0.10562538355588913 first col mean 0.10229893028736115 all mean 0.10631049424409866
0.2631383538246155 0.2631383538246155
rl training, epoch6, iter0, batch596/1133, batch loss:0.2631383538246155, Training time:20248.209804296494
batch reward last col mean 0.12299352139234543 first col mean 0.11759617924690247 all mean 0.11981842666864395
0.295806348323822 0.295806348323822
rl training, epoch6, iter0, batch597/1133, batch loss:0.295806348323822, Training time:20249.959153175354
batch reward last col mean 0.11480475962162018 first col mean 0.10634716600179672 all mean 0.11370064318180084
0.27564293146133423 0.27564293146133423
rl training, epoch6, iter0, batch598/1133, batch loss:0.27564293146133423, Training time:20251.828636407852
batch reward last col mean 0.10318848490715027 first col mean 0.12483417242765427 all mean 0.10735910385847092
0.2871415317058563 0.2871415317058563
rl training, epoch6, iter0, batch599/1133, batch loss:0.2871415317058563, Training time:20254.19137120247
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.48285795160341555 Time: 95.79936909675598 s
loss of true 0.20901789272241852 loss of gen 0.17579676527184715 loss of other 0.0980432934677664 first score 0.08902755379676819
batch reward last col mean 0.10279881209135056 first col mean 0.10712672770023346 all mean 0.10341362655162811
0.27649104595184326 0.27649104595184326
rl training, epoch6, iter0, batch600/1133, batch loss:0.27649104595184326, Training time:20351.75441479683
batch reward last col mean 0.096119225025177 first col mean 0.09634460508823395 all mean 0.09473253041505814
0.28782516717910767 0.28782516717910767
rl training, epoch6, iter0, batch601/1133, batch loss:0.28782516717910767, Training time:20353.38153076172
batch reward last col mean 0.08887337893247604 first col mean 0.1059451624751091 all mean 0.09441453963518143
0.2517964839935303 0.2517964839935303
rl training, epoch6, iter0, batch602/1133, batch loss:0.2517964839935303, Training time:20355.783226251602
batch reward last col mean 0.10473594069480896 first col mean 0.11191962659358978 all mean 0.1019982248544693
0.26830407977104187 0.26830407977104187
rl training, epoch6, iter0, batch603/1133, batch loss:0.26830407977104187, Training time:20357.419376850128
batch reward last col mean 0.0921681672334671 first col mean 0.11156266927719116 all mean 0.10661940276622772
0.33791711926460266 0.33791711926460266
rl training, epoch6, iter0, batch604/1133, batch loss:0.33791711926460266, Training time:20359.290449142456
batch reward last col mean 0.10095381736755371 first col mean 0.11975604295730591 all mean 0.10466107726097107
0.2819371223449707 0.2819371223449707
rl training, epoch6, iter0, batch605/1133, batch loss:0.2819371223449707, Training time:20361.59726691246
batch reward last col mean 0.11451156437397003 first col mean 0.11401519924402237 all mean 0.11223314702510834
0.28883638978004456 0.28883635997772217
rl training, epoch6, iter0, batch606/1133, batch loss:0.28883635997772217, Training time:20363.804793596268
batch reward last col mean 0.08681870251893997 first col mean 0.1153871938586235 all mean 0.08999226242303848
0.2524101436138153 0.2524101436138153
rl training, epoch6, iter0, batch607/1133, batch loss:0.2524101436138153, Training time:20366.640493392944
batch reward last col mean 0.09573444724082947 first col mean 0.11107972264289856 all mean 0.09685827791690826
0.2673344910144806 0.2673344910144806
rl training, epoch6, iter0, batch608/1133, batch loss:0.2673344910144806, Training time:20368.63422703743
batch reward last col mean 0.12769021093845367 first col mean 0.1106942892074585 all mean 0.12463781982660294
0.30966895818710327 0.30966898798942566
rl training, epoch6, iter0, batch609/1133, batch loss:0.30966898798942566, Training time:20371.023651123047
batch reward last col mean 0.1577737033367157 first col mean 0.09934824705123901 all mean 0.13966773450374603
0.3023473024368286 0.3023473024368286
rl training, epoch6, iter0, batch610/1133, batch loss:0.3023473024368286, Training time:20372.95254778862
batch reward last col mean 0.0536331981420517 first col mean 0.09521444141864777 all mean 0.07068592309951782
0.21759812533855438 0.21759812533855438
rl training, epoch6, iter0, batch611/1133, batch loss:0.21759812533855438, Training time:20374.489414215088
batch reward last col mean 0.09903806447982788 first col mean 0.10798918455839157 all mean 0.10189049690961838
0.271384060382843 0.2713840901851654
rl training, epoch6, iter0, batch612/1133, batch loss:0.2713840901851654, Training time:20376.666330575943
batch reward last col mean 0.09663796424865723 first col mean 0.10274288803339005 all mean 0.09350090473890305
0.3064056932926178 0.3064056634902954
rl training, epoch6, iter0, batch613/1133, batch loss:0.3064056634902954, Training time:20378.719207763672
batch reward last col mean 0.07997959852218628 first col mean 0.10981309413909912 all mean 0.08785327523946762
0.25878527760505676 0.25878527760505676
rl training, epoch6, iter0, batch614/1133, batch loss:0.25878527760505676, Training time:20380.890531539917
batch reward last col mean 0.08115503191947937 first col mean 0.09877117723226547 all mean 0.08933505415916443
0.27713730931282043 0.27713730931282043
rl training, epoch6, iter0, batch615/1133, batch loss:0.27713730931282043, Training time:20382.580635786057
batch reward last col mean 0.09886737167835236 first col mean 0.10156349092721939 all mean 0.09879645705223083
0.3029128909111023 0.3029128909111023
rl training, epoch6, iter0, batch616/1133, batch loss:0.3029128909111023, Training time:20384.389058351517
batch reward last col mean 0.1382436752319336 first col mean 0.11344722658395767 all mean 0.12638907134532928
0.3098571002483368 0.3098570704460144
rl training, epoch6, iter0, batch617/1133, batch loss:0.3098570704460144, Training time:20386.12249302864
batch reward last col mean 0.10551507771015167 first col mean 0.09889940917491913 all mean 0.09763733297586441
0.2901652455329895 0.2901652455329895
rl training, epoch6, iter0, batch618/1133, batch loss:0.2901652455329895, Training time:20387.90985774994
batch reward last col mean 0.09185366332530975 first col mean 0.10411074757575989 all mean 0.09214972704648972
0.23802140355110168 0.23802140355110168
rl training, epoch6, iter0, batch619/1133, batch loss:0.23802140355110168, Training time:20389.78879380226
batch reward last col mean 0.07835036516189575 first col mean 0.10909850895404816 all mean 0.08433088660240173
0.2781723141670227 0.2781723141670227
rl training, epoch6, iter0, batch620/1133, batch loss:0.2781723141670227, Training time:20391.737763404846
batch reward last col mean 0.1313939094543457 first col mean 0.10729935765266418 all mean 0.12979628145694733
0.2789956331253052 0.2789956331253052
rl training, epoch6, iter0, batch621/1133, batch loss:0.2789956331253052, Training time:20393.971175909042
batch reward last col mean 0.09085026383399963 first col mean 0.10793352872133255 all mean 0.09753680974245071
0.2696402966976166 0.2696402966976166
rl training, epoch6, iter0, batch622/1133, batch loss:0.2696402966976166, Training time:20395.78097128868
batch reward last col mean 0.11437481641769409 first col mean 0.11652421206235886 all mean 0.11005870997905731
0.2827768921852112 0.2827768921852112
rl training, epoch6, iter0, batch623/1133, batch loss:0.2827768921852112, Training time:20397.506810426712
batch reward last col mean 0.10331451892852783 first col mean 0.10020031034946442 all mean 0.09823062270879745
0.27615487575531006 0.27615487575531006
rl training, epoch6, iter0, batch624/1133, batch loss:0.27615487575531006, Training time:20399.386011123657
batch reward last col mean 0.09891185909509659 first col mean 0.10458415746688843 all mean 0.09619344770908356
0.2550804913043976 0.2550804913043976
rl training, epoch6, iter0, batch625/1133, batch loss:0.2550804913043976, Training time:20401.230422735214
batch reward last col mean 0.11371557414531708 first col mean 0.11004726588726044 all mean 0.10768313705921173
0.2774210274219513 0.2774209976196289
rl training, epoch6, iter0, batch626/1133, batch loss:0.2774209976196289, Training time:20402.868664741516
batch reward last col mean 0.08969847857952118 first col mean 0.11659928411245346 all mean 0.0876229777932167
0.2919435203075409 0.2919434905052185
rl training, epoch6, iter0, batch627/1133, batch loss:0.2919434905052185, Training time:20404.737161159515
batch reward last col mean 0.09351778775453568 first col mean 0.0908321887254715 all mean 0.09872876852750778
0.29175281524658203 0.29175278544425964
rl training, epoch6, iter0, batch628/1133, batch loss:0.29175278544425964, Training time:20406.623917341232
batch reward last col mean 0.1139807254076004 first col mean 0.10129942744970322 all mean 0.11250656843185425
0.30245712399482727 0.30245712399482727
rl training, epoch6, iter0, batch629/1133, batch loss:0.30245712399482727, Training time:20408.266227960587
batch reward last col mean 0.11061026155948639 first col mean 0.09625813364982605 all mean 0.10075517743825912
0.2569131851196289 0.2569131851196289
rl training, epoch6, iter0, batch630/1133, batch loss:0.2569131851196289, Training time:20409.97851729393
batch reward last col mean 0.09430950880050659 first col mean 0.09588509798049927 all mean 0.09666185081005096
0.27745407819747925 0.27745407819747925
rl training, epoch6, iter0, batch631/1133, batch loss:0.27745407819747925, Training time:20411.87904548645
batch reward last col mean 0.0842263400554657 first col mean 0.10008140653371811 all mean 0.09265032410621643
0.2648638188838959 0.2648638188838959
rl training, epoch6, iter0, batch632/1133, batch loss:0.2648638188838959, Training time:20413.345111370087
batch reward last col mean 0.11839941143989563 first col mean 0.09559528529644012 all mean 0.11315666139125824
0.2743682861328125 0.2743682861328125
rl training, epoch6, iter0, batch633/1133, batch loss:0.2743682861328125, Training time:20415.441199064255
batch reward last col mean 0.1049254983663559 first col mean 0.09949356317520142 all mean 0.10411393642425537
0.30576279759407043 0.30576279759407043
rl training, epoch6, iter0, batch634/1133, batch loss:0.30576279759407043, Training time:20417.27734375
batch reward last col mean 0.11716114729642868 first col mean 0.1153591051697731 all mean 0.10940851271152496
0.27824729681015015 0.27824729681015015
rl training, epoch6, iter0, batch635/1133, batch loss:0.27824729681015015, Training time:20418.93864250183
batch reward last col mean 0.0728631243109703 first col mean 0.10136058926582336 all mean 0.07665801793336868
0.21907325088977814 0.21907325088977814
rl training, epoch6, iter0, batch636/1133, batch loss:0.21907325088977814, Training time:20420.65684556961
batch reward last col mean 0.10303275287151337 first col mean 0.10269350558519363 all mean 0.10929777473211288
0.3138163685798645 0.3138163685798645
rl training, epoch6, iter0, batch637/1133, batch loss:0.3138163685798645, Training time:20423.212512016296
batch reward last col mean 0.11705181002616882 first col mean 0.1122000515460968 all mean 0.11114044487476349
0.3167121112346649 0.3167121112346649
rl training, epoch6, iter0, batch638/1133, batch loss:0.3167121112346649, Training time:20424.97131419182
batch reward last col mean 0.08792528510093689 first col mean 0.11196450144052505 all mean 0.09663763642311096
0.30077889561653137 0.30077889561653137
rl training, epoch6, iter0, batch639/1133, batch loss:0.30077889561653137, Training time:20427.155289411545
batch reward last col mean 0.10916224122047424 first col mean 0.10860461741685867 all mean 0.10967524349689484
0.27040284872055054 0.27040284872055054
rl training, epoch6, iter0, batch640/1133, batch loss:0.27040284872055054, Training time:20429.684395313263
batch reward last col mean 0.1079733744263649 first col mean 0.10902702063322067 all mean 0.10460640490055084
0.319729745388031 0.319729745388031
rl training, epoch6, iter0, batch641/1133, batch loss:0.319729745388031, Training time:20431.871780633926
batch reward last col mean 0.07079235464334488 first col mean 0.09061173349618912 all mean 0.07469141483306885
0.23858866095542908 0.23858866095542908
rl training, epoch6, iter0, batch642/1133, batch loss:0.23858866095542908, Training time:20434.545804977417
batch reward last col mean 0.11165334284305573 first col mean 0.09985538572072983 all mean 0.11105448752641678
0.258277028799057 0.258277028799057
rl training, epoch6, iter0, batch643/1133, batch loss:0.258277028799057, Training time:20436.327799797058
batch reward last col mean 0.10499033331871033 first col mean 0.11611875891685486 all mean 0.10353904962539673
0.269301176071167 0.269301176071167
rl training, epoch6, iter0, batch644/1133, batch loss:0.269301176071167, Training time:20438.390340328217
batch reward last col mean 0.09817374497652054 first col mean 0.11820758879184723 all mean 0.10017488896846771
0.2838749587535858 0.2838749587535858
rl training, epoch6, iter0, batch645/1133, batch loss:0.2838749587535858, Training time:20440.326900720596
batch reward last col mean 0.08263268321752548 first col mean 0.11249998211860657 all mean 0.09197332710027695
0.26895520091056824 0.26895520091056824
rl training, epoch6, iter0, batch646/1133, batch loss:0.26895520091056824, Training time:20442.363578796387
batch reward last col mean 0.10241889208555222 first col mean 0.10528426617383957 all mean 0.10126467049121857
0.2509101629257202 0.2509101629257202
rl training, epoch6, iter0, batch647/1133, batch loss:0.2509101629257202, Training time:20444.123997449875
batch reward last col mean 0.0928698480129242 first col mean 0.10105838626623154 all mean 0.0894080325961113
0.24693360924720764 0.24693360924720764
rl training, epoch6, iter0, batch648/1133, batch loss:0.24693360924720764, Training time:20446.102017879486
batch reward last col mean 0.08679618686437607 first col mean 0.11489798873662949 all mean 0.08706967532634735
0.23398055136203766 0.23398055136203766
rl training, epoch6, iter0, batch649/1133, batch loss:0.23398055136203766, Training time:20449.036859750748
batch reward last col mean 0.1013941615819931 first col mean 0.11604973673820496 all mean 0.10101255774497986
0.2895705997943878 0.2895705997943878
rl training, epoch6, iter0, batch650/1133, batch loss:0.2895705997943878, Training time:20450.89993262291
batch reward last col mean 0.09889734536409378 first col mean 0.10015088319778442 all mean 0.09648400545120239
0.30283379554748535 0.30283379554748535
rl training, epoch6, iter0, batch651/1133, batch loss:0.30283379554748535, Training time:20453.158818006516
batch reward last col mean 0.11570893228054047 first col mean 0.11692708730697632 all mean 0.11019784212112427
0.3137676417827606 0.3137676417827606
rl training, epoch6, iter0, batch652/1133, batch loss:0.3137676417827606, Training time:20455.506029367447
batch reward last col mean 0.08020976185798645 first col mean 0.10427616536617279 all mean 0.08910812437534332
0.281216561794281 0.281216561794281
rl training, epoch6, iter0, batch653/1133, batch loss:0.281216561794281, Training time:20458.16184735298
batch reward last col mean 0.1006973385810852 first col mean 0.1237100213766098 all mean 0.10377054661512375
0.3013158142566681 0.3013158142566681
rl training, epoch6, iter0, batch654/1133, batch loss:0.3013158142566681, Training time:20460.20394396782
batch reward last col mean 0.1185702458024025 first col mean 0.09981809556484222 all mean 0.11814851313829422
0.3280792832374573 0.3280792832374573
rl training, epoch6, iter0, batch655/1133, batch loss:0.3280792832374573, Training time:20462.467839956284
batch reward last col mean 0.11346447467803955 first col mean 0.10354223847389221 all mean 0.11211034655570984
0.3157612979412079 0.3157612681388855
rl training, epoch6, iter0, batch656/1133, batch loss:0.3157612681388855, Training time:20464.30328798294
batch reward last col mean 0.13126680254936218 first col mean 0.10884641855955124 all mean 0.12851034104824066
0.31256768107414246 0.31256768107414246
rl training, epoch6, iter0, batch657/1133, batch loss:0.31256768107414246, Training time:20466.85943031311
batch reward last col mean 0.1339958906173706 first col mean 0.10563374310731888 all mean 0.12196426838636398
0.30921027064323425 0.30921027064323425
rl training, epoch6, iter0, batch658/1133, batch loss:0.30921027064323425, Training time:20468.65439224243
batch reward last col mean 0.09702657163143158 first col mean 0.10800822079181671 all mean 0.09452445060014725
0.2678377330303192 0.2678377330303192
rl training, epoch6, iter0, batch659/1133, batch loss:0.2678377330303192, Training time:20471.754506111145
batch reward last col mean 0.09608615934848785 first col mean 0.12447240948677063 all mean 0.10002078860998154
0.3182620704174042 0.3182620704174042
rl training, epoch6, iter0, batch660/1133, batch loss:0.3182620704174042, Training time:20474.134344100952
batch reward last col mean 0.12191435694694519 first col mean 0.11252617835998535 all mean 0.12181422114372253
0.2982417345046997 0.2982417345046997
rl training, epoch6, iter0, batch661/1133, batch loss:0.2982417345046997, Training time:20477.88586950302
batch reward last col mean 0.09587312489748001 first col mean 0.11095482110977173 all mean 0.0955900251865387
0.2950037121772766 0.2950037121772766
rl training, epoch6, iter0, batch662/1133, batch loss:0.2950037121772766, Training time:20479.893074274063
batch reward last col mean 0.12301379442214966 first col mean 0.11199602484703064 all mean 0.11588508635759354
0.31331661343574524 0.31331661343574524
rl training, epoch6, iter0, batch663/1133, batch loss:0.31331661343574524, Training time:20481.678805828094
batch reward last col mean 0.11142361164093018 first col mean 0.12064321339130402 all mean 0.11552365869283676
0.3143221139907837 0.3143221139907837
rl training, epoch6, iter0, batch664/1133, batch loss:0.3143221139907837, Training time:20483.916195631027
batch reward last col mean 0.10161308199167252 first col mean 0.1092594638466835 all mean 0.10621660202741623
0.26843708753585815 0.26843708753585815
rl training, epoch6, iter0, batch665/1133, batch loss:0.26843708753585815, Training time:20485.73644566536
batch reward last col mean 0.07714672386646271 first col mean 0.0943363681435585 all mean 0.08562532067298889
0.23949281871318817 0.23949281871318817
rl training, epoch6, iter0, batch666/1133, batch loss:0.23949281871318817, Training time:20487.389618635178
batch reward last col mean 0.1240444928407669 first col mean 0.12212559580802917 all mean 0.12021408975124359
0.32583796977996826 0.32583796977996826
rl training, epoch6, iter0, batch667/1133, batch loss:0.32583796977996826, Training time:20489.181978225708
batch reward last col mean 0.1390848606824875 first col mean 0.13229143619537354 all mean 0.13619431853294373
0.31825828552246094 0.3182583153247833
rl training, epoch6, iter0, batch668/1133, batch loss:0.3182583153247833, Training time:20491.364030122757
batch reward last col mean 0.08321348577737808 first col mean 0.10284212976694107 all mean 0.09399809688329697
0.2560058534145355 0.2560058534145355
rl training, epoch6, iter0, batch669/1133, batch loss:0.2560058534145355, Training time:20493.112817525864
batch reward last col mean 0.07295005768537521 first col mean 0.1075049340724945 all mean 0.08125121146440506
0.26067736744880676 0.26067736744880676
rl training, epoch6, iter0, batch670/1133, batch loss:0.26067736744880676, Training time:20495.39182806015
batch reward last col mean 0.08158254623413086 first col mean 0.10514181107282639 all mean 0.08945057541131973
0.25883275270462036 0.25883275270462036
rl training, epoch6, iter0, batch671/1133, batch loss:0.25883275270462036, Training time:20497.03926897049
batch reward last col mean 0.09504514932632446 first col mean 0.10642266273498535 all mean 0.09465888142585754
0.30031657218933105 0.30031660199165344
rl training, epoch6, iter0, batch672/1133, batch loss:0.30031660199165344, Training time:20498.791504859924
batch reward last col mean 0.07288538664579391 first col mean 0.10432778298854828 all mean 0.08392776548862457
0.25049784779548645 0.25049784779548645
rl training, epoch6, iter0, batch673/1133, batch loss:0.25049784779548645, Training time:20500.6767077446
batch reward last col mean 0.08776706457138062 first col mean 0.1218639612197876 all mean 0.09661043435335159
0.270376056432724 0.270376056432724
rl training, epoch6, iter0, batch674/1133, batch loss:0.270376056432724, Training time:20502.943513154984
batch reward last col mean 0.0918213278055191 first col mean 0.10628730803728104 all mean 0.09795652329921722
0.2913404703140259 0.2913404703140259
rl training, epoch6, iter0, batch675/1133, batch loss:0.2913404703140259, Training time:20504.607238054276
batch reward last col mean 0.09486643224954605 first col mean 0.10523080825805664 all mean 0.09223420172929764
0.2863679528236389 0.2863679528236389
rl training, epoch6, iter0, batch676/1133, batch loss:0.2863679528236389, Training time:20507.414623498917
batch reward last col mean 0.11847209185361862 first col mean 0.10400675237178802 all mean 0.11757536977529526
0.31035059690475464 0.31035059690475464
rl training, epoch6, iter0, batch677/1133, batch loss:0.31035059690475464, Training time:20510.222450971603
batch reward last col mean 0.1223355233669281 first col mean 0.09571285545825958 all mean 0.11523797363042831
0.3053308427333832 0.3053308129310608
rl training, epoch6, iter0, batch678/1133, batch loss:0.3053308129310608, Training time:20512.157680511475
batch reward last col mean 0.08958233147859573 first col mean 0.09902870655059814 all mean 0.09467524290084839
0.2604309618473053 0.2604309618473053
rl training, epoch6, iter0, batch679/1133, batch loss:0.2604309618473053, Training time:20514.197247505188
batch reward last col mean 0.10893705487251282 first col mean 0.08959737420082092 all mean 0.111005038022995
0.3146379888057709 0.3146379888057709
rl training, epoch6, iter0, batch680/1133, batch loss:0.3146379888057709, Training time:20515.70999097824
batch reward last col mean 0.08998729288578033 first col mean 0.10756149888038635 all mean 0.0913332849740982
0.27488940954208374 0.27488940954208374
rl training, epoch6, iter0, batch681/1133, batch loss:0.27488940954208374, Training time:20517.573229074478
batch reward last col mean 0.09332654625177383 first col mean 0.10356646031141281 all mean 0.09284553676843643
0.24551650881767273 0.24551650881767273
rl training, epoch6, iter0, batch682/1133, batch loss:0.24551650881767273, Training time:20519.385445594788
batch reward last col mean 0.11395788937807083 first col mean 0.1060003787279129 all mean 0.11139252781867981
0.27030760049819946 0.27030760049819946
rl training, epoch6, iter0, batch683/1133, batch loss:0.27030760049819946, Training time:20521.45581650734
batch reward last col mean 0.0757942870259285 first col mean 0.12180227041244507 all mean 0.08878432214260101
0.25470855832099915 0.25470855832099915
rl training, epoch6, iter0, batch684/1133, batch loss:0.25470855832099915, Training time:20523.12677550316
batch reward last col mean 0.13883674144744873 first col mean 0.11954860389232635 all mean 0.13067051768302917
0.33144962787628174 0.33144962787628174
rl training, epoch6, iter0, batch685/1133, batch loss:0.33144962787628174, Training time:20525.0142827034
batch reward last col mean 0.06569946557283401 first col mean 0.10988131165504456 all mean 0.08394041657447815
0.26448169350624084 0.26448169350624084
rl training, epoch6, iter0, batch686/1133, batch loss:0.26448169350624084, Training time:20526.718403816223
batch reward last col mean 0.08694721758365631 first col mean 0.0937720239162445 all mean 0.09424526244401932
0.2779357135295868 0.2779357135295868
rl training, epoch6, iter0, batch687/1133, batch loss:0.2779357135295868, Training time:20528.765342235565
batch reward last col mean 0.11839694529771805 first col mean 0.12229977548122406 all mean 0.11454696953296661
0.2996291220188141 0.2996291220188141
rl training, epoch6, iter0, batch688/1133, batch loss:0.2996291220188141, Training time:20530.600611448288
batch reward last col mean 0.10967038571834564 first col mean 0.12919826805591583 all mean 0.1099250316619873
0.27164986729621887 0.27164986729621887
rl training, epoch6, iter0, batch689/1133, batch loss:0.27164986729621887, Training time:20532.56481027603
batch reward last col mean 0.11736249923706055 first col mean 0.11957232654094696 all mean 0.11679936200380325
0.3045022785663605 0.30450230836868286
rl training, epoch6, iter0, batch690/1133, batch loss:0.30450230836868286, Training time:20534.75403881073
batch reward last col mean 0.08496126532554626 first col mean 0.11278192698955536 all mean 0.09242639690637589
0.29133614897727966 0.2913361191749573
rl training, epoch6, iter0, batch691/1133, batch loss:0.2913361191749573, Training time:20536.640297412872
batch reward last col mean 0.10183807462453842 first col mean 0.10418806970119476 all mean 0.10733772814273834
0.26601672172546387 0.26601672172546387
rl training, epoch6, iter0, batch692/1133, batch loss:0.26601672172546387, Training time:20538.765134572983
batch reward last col mean 0.10346777737140656 first col mean 0.10203519463539124 all mean 0.10608974099159241
0.30008816719055176 0.30008816719055176
rl training, epoch6, iter0, batch693/1133, batch loss:0.30008816719055176, Training time:20540.981798887253
batch reward last col mean 0.09613880515098572 first col mean 0.09856496751308441 all mean 0.09967533499002457
0.2764151990413666 0.2764151990413666
rl training, epoch6, iter0, batch694/1133, batch loss:0.2764151990413666, Training time:20543.474241256714
batch reward last col mean 0.09069705009460449 first col mean 0.10700961947441101 all mean 0.09939751029014587
0.27396783232688904 0.27396783232688904
rl training, epoch6, iter0, batch695/1133, batch loss:0.27396783232688904, Training time:20545.530230998993
batch reward last col mean 0.10628058016300201 first col mean 0.11221697181463242 all mean 0.10308972001075745
0.2733341455459595 0.2733341455459595
rl training, epoch6, iter0, batch696/1133, batch loss:0.2733341455459595, Training time:20547.414934396744
batch reward last col mean 0.09750112146139145 first col mean 0.10119961202144623 all mean 0.10034501552581787
0.27954021096229553 0.27954021096229553
rl training, epoch6, iter0, batch697/1133, batch loss:0.27954021096229553, Training time:20549.224553346634
batch reward last col mean 0.11202369630336761 first col mean 0.10078279674053192 all mean 0.11448538303375244
0.3212994933128357 0.3212994933128357
rl training, epoch6, iter0, batch698/1133, batch loss:0.3212994933128357, Training time:20551.055772066116
batch reward last col mean 0.08854570239782333 first col mean 0.10187505185604095 all mean 0.09495002776384354
0.25891876220703125 0.25891876220703125
rl training, epoch6, iter0, batch699/1133, batch loss:0.25891876220703125, Training time:20553.361683130264
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47837590432124966 Time: 96.05858039855957 s
loss of true 0.20727775525383896 loss of gen 0.17395463709481923 loss of other 0.09714351188710382 first score 0.12372435629367828
batch reward last col mean 0.10492165386676788 first col mean 0.10715731233358383 all mean 0.09913415461778641
0.2592543065547943 0.2592543065547943
rl training, epoch6, iter0, batch700/1133, batch loss:0.2592543065547943, Training time:20650.93931698799
batch reward last col mean 0.08476006239652634 first col mean 0.09434278309345245 all mean 0.09256157279014587
0.2656996250152588 0.2656996250152588
rl training, epoch6, iter0, batch701/1133, batch loss:0.2656996250152588, Training time:20652.805562973022
batch reward last col mean 0.08603173494338989 first col mean 0.10118845105171204 all mean 0.0923694297671318
0.2658095061779022 0.2658095061779022
rl training, epoch6, iter0, batch702/1133, batch loss:0.2658095061779022, Training time:20654.550912857056
batch reward last col mean 0.13333797454833984 first col mean 0.10653181374073029 all mean 0.12499884516000748
0.3011930286884308 0.3011930286884308
rl training, epoch6, iter0, batch703/1133, batch loss:0.3011930286884308, Training time:20656.544383764267
batch reward last col mean 0.11277542263269424 first col mean 0.11091014742851257 all mean 0.11184065788984299
0.29914698004722595 0.29914698004722595
rl training, epoch6, iter0, batch704/1133, batch loss:0.29914698004722595, Training time:20658.10013604164
batch reward last col mean 0.08874242007732391 first col mean 0.10339710861444473 all mean 0.09068359434604645
0.253206342458725 0.253206342458725
rl training, epoch6, iter0, batch705/1133, batch loss:0.253206342458725, Training time:20660.05974149704
batch reward last col mean 0.11057829856872559 first col mean 0.10320456326007843 all mean 0.10681282728910446
0.31429392099380493 0.31429392099380493
rl training, epoch6, iter0, batch706/1133, batch loss:0.31429392099380493, Training time:20661.785977840424
batch reward last col mean 0.09409025311470032 first col mean 0.10481591522693634 all mean 0.09766578674316406
0.26277193427085876 0.26277193427085876
rl training, epoch6, iter0, batch707/1133, batch loss:0.26277193427085876, Training time:20663.322369337082
batch reward last col mean 0.09330733865499496 first col mean 0.11269724369049072 all mean 0.0973203107714653
0.2688623070716858 0.2688623070716858
rl training, epoch6, iter0, batch708/1133, batch loss:0.2688623070716858, Training time:20665.36144924164
batch reward last col mean 0.11007340252399445 first col mean 0.10692436993122101 all mean 0.1122075691819191
0.2683156430721283 0.2683156430721283
rl training, epoch6, iter0, batch709/1133, batch loss:0.2683156430721283, Training time:20667.994925022125
batch reward last col mean 0.11738327145576477 first col mean 0.10319468379020691 all mean 0.11997800320386887
0.30958130955696106 0.30958130955696106
rl training, epoch6, iter0, batch710/1133, batch loss:0.30958130955696106, Training time:20669.934346675873
batch reward last col mean 0.08142820000648499 first col mean 0.1058746948838234 all mean 0.09327683597803116
0.316670298576355 0.316670298576355
rl training, epoch6, iter0, batch711/1133, batch loss:0.316670298576355, Training time:20672.076591014862
batch reward last col mean 0.13930173218250275 first col mean 0.10804075747728348 all mean 0.13013575971126556
0.3070182204246521 0.3070182204246521
rl training, epoch6, iter0, batch712/1133, batch loss:0.3070182204246521, Training time:20674.277807235718
batch reward last col mean 0.11954070627689362 first col mean 0.10027437657117844 all mean 0.11667889356613159
0.2941683232784271 0.2941683232784271
rl training, epoch6, iter0, batch713/1133, batch loss:0.2941683232784271, Training time:20675.863678455353
batch reward last col mean 0.0846656858921051 first col mean 0.1097007691860199 all mean 0.0920070931315422
0.25904446840286255 0.25904446840286255
rl training, epoch6, iter0, batch714/1133, batch loss:0.25904446840286255, Training time:20677.531182527542
batch reward last col mean 0.108877994120121 first col mean 0.09634684771299362 all mean 0.11002928018569946
0.30589205026626587 0.30589205026626587
rl training, epoch6, iter0, batch715/1133, batch loss:0.30589205026626587, Training time:20679.112105607986
batch reward last col mean 0.11301515996456146 first col mean 0.12003283202648163 all mean 0.11466597020626068
0.3317306637763977 0.3317306637763977
rl training, epoch6, iter0, batch716/1133, batch loss:0.3317306637763977, Training time:20680.860963344574
batch reward last col mean 0.07489874958992004 first col mean 0.10186401009559631 all mean 0.08404470980167389
0.26146140694618225 0.26146140694618225
rl training, epoch6, iter0, batch717/1133, batch loss:0.26146140694618225, Training time:20683.1489508152
batch reward last col mean 0.11443017423152924 first col mean 0.10085096210241318 all mean 0.11207669228315353
0.3209393322467804 0.3209392726421356
rl training, epoch6, iter0, batch718/1133, batch loss:0.3209392726421356, Training time:20685.293777942657
batch reward last col mean 0.10464074462652206 first col mean 0.10867956280708313 all mean 0.10151635855436325
0.27955931425094604 0.27955931425094604
rl training, epoch6, iter0, batch719/1133, batch loss:0.27955931425094604, Training time:20687.464307546616
batch reward last col mean 0.11870764195919037 first col mean 0.1039981096982956 all mean 0.11327003687620163
0.2801821827888489 0.2801821827888489
rl training, epoch6, iter0, batch720/1133, batch loss:0.2801821827888489, Training time:20689.508272647858
batch reward last col mean 0.11039352416992188 first col mean 0.12491268664598465 all mean 0.11574895679950714
0.29939794540405273 0.29939794540405273
rl training, epoch6, iter0, batch721/1133, batch loss:0.29939794540405273, Training time:20691.28200984001
batch reward last col mean 0.0963609516620636 first col mean 0.11300257593393326 all mean 0.09902593493461609
0.3077801465988159 0.3077801465988159
rl training, epoch6, iter0, batch722/1133, batch loss:0.3077801465988159, Training time:20692.961083173752
batch reward last col mean 0.10497742146253586 first col mean 0.10613508522510529 all mean 0.10389173030853271
0.2668403387069702 0.2668403089046478
rl training, epoch6, iter0, batch723/1133, batch loss:0.2668403089046478, Training time:20694.671491622925
batch reward last col mean 0.10886643826961517 first col mean 0.11175721883773804 all mean 0.10694461315870285
0.30565759539604187 0.3056575655937195
rl training, epoch6, iter0, batch724/1133, batch loss:0.3056575655937195, Training time:20696.716906785965
batch reward last col mean 0.07083983719348907 first col mean 0.11622421443462372 all mean 0.08681192249059677
0.3057609498500824 0.3057609498500824
rl training, epoch6, iter0, batch725/1133, batch loss:0.3057609498500824, Training time:20698.80408358574
batch reward last col mean 0.08768180012702942 first col mean 0.10714372992515564 all mean 0.09103786200284958
0.2761390805244446 0.2761390507221222
rl training, epoch6, iter0, batch726/1133, batch loss:0.2761390507221222, Training time:20701.73494076729
batch reward last col mean 0.11211207509040833 first col mean 0.08913367241621017 all mean 0.10912903398275375
0.28067734837532043 0.28067734837532043
rl training, epoch6, iter0, batch727/1133, batch loss:0.28067734837532043, Training time:20703.596551418304
batch reward last col mean 0.08720548450946808 first col mean 0.09598557651042938 all mean 0.09583195298910141
0.26518651843070984 0.26518651843070984
rl training, epoch6, iter0, batch728/1133, batch loss:0.26518651843070984, Training time:20705.25012588501
batch reward last col mean 0.08312481641769409 first col mean 0.10903021693229675 all mean 0.09090742468833923
0.259311705827713 0.259311705827713
rl training, epoch6, iter0, batch729/1133, batch loss:0.259311705827713, Training time:20707.13704752922
batch reward last col mean 0.1131787896156311 first col mean 0.09950321912765503 all mean 0.10715123265981674
0.2679412066936493 0.2679412066936493
rl training, epoch6, iter0, batch730/1133, batch loss:0.2679412066936493, Training time:20708.481831789017
batch reward last col mean 0.13423627614974976 first col mean 0.10056234896183014 all mean 0.12597233057022095
0.2867126762866974 0.2867126762866974
rl training, epoch6, iter0, batch731/1133, batch loss:0.2867126762866974, Training time:20710.553429841995
batch reward last col mean 0.11749047785997391 first col mean 0.11778154969215393 all mean 0.11485347896814346
0.2879731059074402 0.2879730761051178
rl training, epoch6, iter0, batch732/1133, batch loss:0.2879730761051178, Training time:20712.74555039406
batch reward last col mean 0.09448830038309097 first col mean 0.09902805089950562 all mean 0.09735645353794098
0.26372089982032776 0.26372089982032776
rl training, epoch6, iter0, batch733/1133, batch loss:0.26372089982032776, Training time:20714.384911060333
batch reward last col mean 0.10698746144771576 first col mean 0.10425019264221191 all mean 0.10778404027223587
0.29209643602371216 0.29209643602371216
rl training, epoch6, iter0, batch734/1133, batch loss:0.29209643602371216, Training time:20716.490569353104
batch reward last col mean 0.14011117815971375 first col mean 0.09860241413116455 all mean 0.1311592310667038
0.34682103991508484 0.34682103991508484
rl training, epoch6, iter0, batch735/1133, batch loss:0.34682103991508484, Training time:20718.431799650192
batch reward last col mean 0.11653336882591248 first col mean 0.12219087779521942 all mean 0.11092683672904968
0.2821715176105499 0.2821715176105499
rl training, epoch6, iter0, batch736/1133, batch loss:0.2821715176105499, Training time:20720.247315645218
batch reward last col mean 0.08463568240404129 first col mean 0.10415798425674438 all mean 0.09275470674037933
0.2690196633338928 0.2690196633338928
rl training, epoch6, iter0, batch737/1133, batch loss:0.2690196633338928, Training time:20722.406727075577
batch reward last col mean 0.10329701751470566 first col mean 0.12984316051006317 all mean 0.10784149169921875
0.2988136410713196 0.2988136410713196
rl training, epoch6, iter0, batch738/1133, batch loss:0.2988136410713196, Training time:20724.29282641411
batch reward last col mean 0.11627307534217834 first col mean 0.10226383060216904 all mean 0.11074098944664001
0.3119852542877197 0.3119852542877197
rl training, epoch6, iter0, batch739/1133, batch loss:0.3119852542877197, Training time:20726.258369207382
batch reward last col mean 0.09330877661705017 first col mean 0.10859710723161697 all mean 0.09983882308006287
0.2592383325099945 0.2592383325099945
rl training, epoch6, iter0, batch740/1133, batch loss:0.2592383325099945, Training time:20728.24121928215
batch reward last col mean 0.15766486525535583 first col mean 0.10576222836971283 all mean 0.14101123809814453
0.31184878945350647 0.31184878945350647
rl training, epoch6, iter0, batch741/1133, batch loss:0.31184878945350647, Training time:20730.56422185898
batch reward last col mean 0.08921872079372406 first col mean 0.11812269687652588 all mean 0.09206230938434601
0.2586170732975006 0.2586170732975006
rl training, epoch6, iter0, batch742/1133, batch loss:0.2586170732975006, Training time:20732.66269493103
batch reward last col mean 0.10302262008190155 first col mean 0.08932638168334961 all mean 0.0996098592877388
0.2579054832458496 0.2579054832458496
rl training, epoch6, iter0, batch743/1133, batch loss:0.2579054832458496, Training time:20734.67053461075
batch reward last col mean 0.1082601547241211 first col mean 0.12112999707460403 all mean 0.10828845947980881
0.24986864626407623 0.24986864626407623
rl training, epoch6, iter0, batch744/1133, batch loss:0.24986864626407623, Training time:20736.612986326218
batch reward last col mean 0.12139259278774261 first col mean 0.11494508385658264 all mean 0.11870475858449936
0.2783830165863037 0.2783830165863037
rl training, epoch6, iter0, batch745/1133, batch loss:0.2783830165863037, Training time:20739.188849449158
batch reward last col mean 0.11353576928377151 first col mean 0.12093961238861084 all mean 0.11025109142065048
0.31817764043807983 0.31817764043807983
rl training, epoch6, iter0, batch746/1133, batch loss:0.31817764043807983, Training time:20740.95000720024
batch reward last col mean 0.09128106385469437 first col mean 0.10723182559013367 all mean 0.0949413850903511
0.29754531383514404 0.29754534363746643
rl training, epoch6, iter0, batch747/1133, batch loss:0.29754534363746643, Training time:20743.224496364594
batch reward last col mean 0.09726931154727936 first col mean 0.11380929499864578 all mean 0.10022108256816864
0.25740402936935425 0.25740402936935425
rl training, epoch6, iter0, batch748/1133, batch loss:0.25740402936935425, Training time:20745.088732481003
batch reward last col mean 0.10035058110952377 first col mean 0.12205798923969269 all mean 0.09980379045009613
0.26674601435661316 0.26674604415893555
rl training, epoch6, iter0, batch749/1133, batch loss:0.26674604415893555, Training time:20746.824863672256
batch reward last col mean 0.10036282241344452 first col mean 0.10565679520368576 all mean 0.09747809916734695
0.27675661444664 0.27675661444664
rl training, epoch6, iter0, batch750/1133, batch loss:0.27675661444664, Training time:20749.22073841095
batch reward last col mean 0.09467382729053497 first col mean 0.10906808078289032 all mean 0.10243473201990128
0.30946364998817444 0.30946364998817444
rl training, epoch6, iter0, batch751/1133, batch loss:0.30946364998817444, Training time:20751.23559141159
batch reward last col mean 0.10540466010570526 first col mean 0.10620333254337311 all mean 0.10380357503890991
0.264662504196167 0.264662504196167
rl training, epoch6, iter0, batch752/1133, batch loss:0.264662504196167, Training time:20753.58577299118
batch reward last col mean 0.08478069305419922 first col mean 0.09811461716890335 all mean 0.09087210148572922
0.26036331057548523 0.26036331057548523
rl training, epoch6, iter0, batch753/1133, batch loss:0.26036331057548523, Training time:20755.52415037155
batch reward last col mean 0.09479238092899323 first col mean 0.09756962954998016 all mean 0.09796500951051712
0.2570975422859192 0.2570975422859192
rl training, epoch6, iter0, batch754/1133, batch loss:0.2570975422859192, Training time:20757.131509780884
batch reward last col mean 0.11401774734258652 first col mean 0.1214069277048111 all mean 0.11517167091369629
0.3197634816169739 0.3197634816169739
rl training, epoch6, iter0, batch755/1133, batch loss:0.3197634816169739, Training time:20758.882544755936
batch reward last col mean 0.08499252796173096 first col mean 0.10494007170200348 all mean 0.09069782495498657
0.2605004608631134 0.2605004608631134
rl training, epoch6, iter0, batch756/1133, batch loss:0.2605004608631134, Training time:20761.4168279171
batch reward last col mean 0.12001973390579224 first col mean 0.1274910420179367 all mean 0.11563530564308167
0.2794159948825836 0.2794159948825836
rl training, epoch6, iter0, batch757/1133, batch loss:0.2794159948825836, Training time:20763.02041244507
batch reward last col mean 0.11115986108779907 first col mean 0.1239677220582962 all mean 0.10939839482307434
0.3047322630882263 0.3047322630882263
rl training, epoch6, iter0, batch758/1133, batch loss:0.3047322630882263, Training time:20765.945158481598
batch reward last col mean 0.1261693388223648 first col mean 0.11027154326438904 all mean 0.12182218581438065
0.31905263662338257 0.31905263662338257
rl training, epoch6, iter0, batch759/1133, batch loss:0.31905263662338257, Training time:20767.80368232727
batch reward last col mean 0.11043377220630646 first col mean 0.08706124871969223 all mean 0.10984169691801071
0.27789735794067383 0.27789735794067383
rl training, epoch6, iter0, batch760/1133, batch loss:0.27789735794067383, Training time:20769.779635429382
batch reward last col mean 0.10897859185934067 first col mean 0.12726564705371857 all mean 0.1117386668920517
0.2764835059642792 0.2764835059642792
rl training, epoch6, iter0, batch761/1133, batch loss:0.2764835059642792, Training time:20771.43898844719
batch reward last col mean 0.1094195768237114 first col mean 0.10721244663000107 all mean 0.10749319940805435
0.2626628577709198 0.2626628577709198
rl training, epoch6, iter0, batch762/1133, batch loss:0.2626628577709198, Training time:20773.412199020386
batch reward last col mean 0.10489323735237122 first col mean 0.11050388962030411 all mean 0.10831227898597717
0.2882795035839081 0.2882795035839081
rl training, epoch6, iter0, batch763/1133, batch loss:0.2882795035839081, Training time:20775.28039932251
batch reward last col mean 0.1268729865550995 first col mean 0.11720778048038483 all mean 0.12073905020952225
0.29659125208854675 0.29659125208854675
rl training, epoch6, iter0, batch764/1133, batch loss:0.29659125208854675, Training time:20777.273035526276
batch reward last col mean 0.09011056274175644 first col mean 0.105427086353302 all mean 0.09848659485578537
0.2692474126815796 0.2692474126815796
rl training, epoch6, iter0, batch765/1133, batch loss:0.2692474126815796, Training time:20779.230014562607
batch reward last col mean 0.10648524761199951 first col mean 0.096934974193573 all mean 0.10374148935079575
0.3060373067855835 0.3060372769832611
rl training, epoch6, iter0, batch766/1133, batch loss:0.3060372769832611, Training time:20780.999989509583
batch reward last col mean 0.10593611001968384 first col mean 0.1316729635000229 all mean 0.10794303566217422
0.28571391105651855 0.28571391105651855
rl training, epoch6, iter0, batch767/1133, batch loss:0.28571391105651855, Training time:20783.277139425278
batch reward last col mean 0.09893075376749039 first col mean 0.12333638221025467 all mean 0.10079384595155716
0.2677030563354492 0.2677030861377716
rl training, epoch6, iter0, batch768/1133, batch loss:0.2677030861377716, Training time:20785.139636278152
batch reward last col mean 0.10124380886554718 first col mean 0.11126329004764557 all mean 0.10837889462709427
0.2697541415691376 0.2697541415691376
rl training, epoch6, iter0, batch769/1133, batch loss:0.2697541415691376, Training time:20786.972104787827
batch reward last col mean 0.08383682370185852 first col mean 0.09668867290019989 all mean 0.08847341686487198
0.24917472898960114 0.24917472898960114
rl training, epoch6, iter0, batch770/1133, batch loss:0.24917472898960114, Training time:20789.019977808
batch reward last col mean 0.11339317262172699 first col mean 0.10330834984779358 all mean 0.10796164721250534
0.29626062512397766 0.29626062512397766
rl training, epoch6, iter0, batch771/1133, batch loss:0.29626062512397766, Training time:20790.947517633438
batch reward last col mean 0.10483646392822266 first col mean 0.10161885619163513 all mean 0.10626646131277084
0.26191315054893494 0.26191315054893494
rl training, epoch6, iter0, batch772/1133, batch loss:0.26191315054893494, Training time:20792.89585161209
batch reward last col mean 0.11788889020681381 first col mean 0.112693190574646 all mean 0.11299348622560501
0.2542787790298462 0.2542787790298462
rl training, epoch6, iter0, batch773/1133, batch loss:0.2542787790298462, Training time:20794.69136071205
batch reward last col mean 0.06796049326658249 first col mean 0.10401918739080429 all mean 0.0828549936413765
0.2802788317203522 0.2802788317203522
rl training, epoch6, iter0, batch774/1133, batch loss:0.2802788317203522, Training time:20796.59908747673
batch reward last col mean 0.09482943266630173 first col mean 0.11602872610092163 all mean 0.09707210958003998
0.2652924358844757 0.2652924358844757
rl training, epoch6, iter0, batch775/1133, batch loss:0.2652924358844757, Training time:20798.616406917572
batch reward last col mean 0.10279226303100586 first col mean 0.12205938994884491 all mean 0.10963515192270279
0.3033570647239685 0.3033570647239685
rl training, epoch6, iter0, batch776/1133, batch loss:0.3033570647239685, Training time:20800.567031145096
batch reward last col mean 0.08457663655281067 first col mean 0.1368548721075058 all mean 0.09613693505525589
0.26029250025749207 0.26029250025749207
rl training, epoch6, iter0, batch777/1133, batch loss:0.26029250025749207, Training time:20802.384368419647
batch reward last col mean 0.0892578586935997 first col mean 0.11545087397098541 all mean 0.09366937726736069
0.27601122856140137 0.27601122856140137
rl training, epoch6, iter0, batch778/1133, batch loss:0.27601122856140137, Training time:20804.359923362732
batch reward last col mean 0.14127355813980103 first col mean 0.1500362604856491 all mean 0.13607360422611237
0.3126409351825714 0.3126409351825714
rl training, epoch6, iter0, batch779/1133, batch loss:0.3126409351825714, Training time:20806.049825906754
batch reward last col mean 0.12860070168972015 first col mean 0.10625334084033966 all mean 0.12571680545806885
0.300216406583786 0.300216406583786
rl training, epoch6, iter0, batch780/1133, batch loss:0.300216406583786, Training time:20807.634027957916
batch reward last col mean 0.11092144250869751 first col mean 0.12117423862218857 all mean 0.11011970788240433
0.3260539770126343 0.3260539770126343
rl training, epoch6, iter0, batch781/1133, batch loss:0.3260539770126343, Training time:20809.240924596786
batch reward last col mean 0.10895995795726776 first col mean 0.09630663692951202 all mean 0.11108648777008057
0.2891688346862793 0.2891688346862793
rl training, epoch6, iter0, batch782/1133, batch loss:0.2891688346862793, Training time:20811.507476568222
batch reward last col mean 0.12333972007036209 first col mean 0.11038772016763687 all mean 0.11963226646184921
0.30124330520629883 0.30124330520629883
rl training, epoch6, iter0, batch783/1133, batch loss:0.30124330520629883, Training time:20813.06221961975
batch reward last col mean 0.07705900818109512 first col mean 0.10371153801679611 all mean 0.09029849618673325
0.28364840149879456 0.28364840149879456
rl training, epoch6, iter0, batch784/1133, batch loss:0.28364840149879456, Training time:20814.615039110184
batch reward last col mean 0.11613404750823975 first col mean 0.1215033233165741 all mean 0.11236194521188736
0.29390519857406616 0.29390519857406616
rl training, epoch6, iter0, batch785/1133, batch loss:0.29390519857406616, Training time:20816.256606578827
batch reward last col mean 0.12161669880151749 first col mean 0.11418019235134125 all mean 0.1144213005900383
0.3030279576778412 0.3030279576778412
rl training, epoch6, iter0, batch786/1133, batch loss:0.3030279576778412, Training time:20818.413571357727
batch reward last col mean 0.10150977969169617 first col mean 0.09906091541051865 all mean 0.0996459573507309
0.23768837749958038 0.23768837749958038
rl training, epoch6, iter0, batch787/1133, batch loss:0.23768837749958038, Training time:20820.22997736931
batch reward last col mean 0.12920577824115753 first col mean 0.10746143758296967 all mean 0.13106052577495575
0.2935815155506134 0.2935815155506134
rl training, epoch6, iter0, batch788/1133, batch loss:0.2935815155506134, Training time:20821.947473526
batch reward last col mean 0.12707452476024628 first col mean 0.11282068490982056 all mean 0.12455382943153381
0.32464292645454407 0.32464292645454407
rl training, epoch6, iter0, batch789/1133, batch loss:0.32464292645454407, Training time:20823.902121782303
batch reward last col mean 0.09043443948030472 first col mean 0.09925641119480133 all mean 0.09305214136838913
0.2615412175655365 0.2615412175655365
rl training, epoch6, iter0, batch790/1133, batch loss:0.2615412175655365, Training time:20826.02617788315
batch reward last col mean 0.11504590511322021 first col mean 0.10616081953048706 all mean 0.11486808955669403
0.3155518174171448 0.3155518174171448
rl training, epoch6, iter0, batch791/1133, batch loss:0.3155518174171448, Training time:20827.890360832214
batch reward last col mean 0.07256635278463364 first col mean 0.1104404553771019 all mean 0.07686346769332886
0.25500747561454773 0.25500744581222534
rl training, epoch6, iter0, batch792/1133, batch loss:0.25500744581222534, Training time:20830.16191148758
batch reward last col mean 0.08650904893875122 first col mean 0.1185811460018158 all mean 0.09530290216207504
0.3279673755168915 0.3279673755168915
rl training, epoch6, iter0, batch793/1133, batch loss:0.3279673755168915, Training time:20832.287690877914
batch reward last col mean 0.14067049324512482 first col mean 0.11566006392240524 all mean 0.13637785613536835
0.33683663606643677 0.33683663606643677
rl training, epoch6, iter0, batch794/1133, batch loss:0.33683663606643677, Training time:20834.524343013763
batch reward last col mean 0.12358978390693665 first col mean 0.10190872102975845 all mean 0.11830571293830872
0.32137757539749146 0.32137757539749146
rl training, epoch6, iter0, batch795/1133, batch loss:0.32137757539749146, Training time:20836.060918807983
batch reward last col mean 0.08609730750322342 first col mean 0.12821555137634277 all mean 0.08876261860132217
0.26155632734298706 0.26155632734298706
rl training, epoch6, iter0, batch796/1133, batch loss:0.26155632734298706, Training time:20837.934374570847
batch reward last col mean 0.09930498152971268 first col mean 0.12809771299362183 all mean 0.09891479462385178
0.2653641104698181 0.2653641104698181
rl training, epoch6, iter0, batch797/1133, batch loss:0.2653641104698181, Training time:20840.51719737053
batch reward last col mean 0.08611580729484558 first col mean 0.09281091392040253 all mean 0.09460978955030441
0.2944619059562683 0.2944619059562683
rl training, epoch6, iter0, batch798/1133, batch loss:0.2944619059562683, Training time:20842.38876771927
batch reward last col mean 0.07935462146997452 first col mean 0.11243221163749695 all mean 0.08649128675460815
0.29178139567375183 0.29178139567375183
rl training, epoch6, iter0, batch799/1133, batch loss:0.29178139567375183, Training time:20845.13613009453
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4797841712161701 Time: 95.83233380317688 s
loss of true 0.2081340475752621 loss of gen 0.17451110511807771 loss of other 0.09713901947634682 first score 0.12908881902694702
batch reward last col mean 0.10096360743045807 first col mean 0.1113324910402298 all mean 0.10041899234056473
0.25699806213378906 0.25699806213378906
rl training, epoch6, iter0, batch800/1133, batch loss:0.25699806213378906, Training time:20942.606865644455
batch reward last col mean 0.0850396454334259 first col mean 0.10788862407207489 all mean 0.09076861292123795
0.2732529640197754 0.2732529640197754
rl training, epoch6, iter0, batch801/1133, batch loss:0.2732529640197754, Training time:20944.607573986053
batch reward last col mean 0.07653515785932541 first col mean 0.10600614547729492 all mean 0.08643971383571625
0.25253933668136597 0.25253933668136597
rl training, epoch6, iter0, batch802/1133, batch loss:0.25253933668136597, Training time:20946.268836021423
batch reward last col mean 0.13034075498580933 first col mean 0.10044152289628983 all mean 0.12123587727546692
0.27599668502807617 0.27599668502807617
rl training, epoch6, iter0, batch803/1133, batch loss:0.27599668502807617, Training time:20948.625171899796
batch reward last col mean 0.15576475858688354 first col mean 0.09772169589996338 all mean 0.13490766286849976
0.3027398884296417 0.3027398884296417
rl training, epoch6, iter0, batch804/1133, batch loss:0.3027398884296417, Training time:20950.51745033264
batch reward last col mean 0.09010986238718033 first col mean 0.08711548149585724 all mean 0.0862853080034256
0.23900388181209564 0.23900388181209564
rl training, epoch6, iter0, batch805/1133, batch loss:0.23900388181209564, Training time:20952.515465259552
batch reward last col mean 0.11510158330202103 first col mean 0.09165538847446442 all mean 0.11148257553577423
0.33623936772346497 0.33623936772346497
rl training, epoch6, iter0, batch806/1133, batch loss:0.33623936772346497, Training time:20954.296887397766
batch reward last col mean 0.11811220645904541 first col mean 0.10318991541862488 all mean 0.1107483059167862
0.30731937289237976 0.30731937289237976
rl training, epoch6, iter0, batch807/1133, batch loss:0.30731937289237976, Training time:20956.312284231186
batch reward last col mean 0.10431632399559021 first col mean 0.0998690128326416 all mean 0.10298104584217072
0.25898000597953796 0.25898000597953796
rl training, epoch6, iter0, batch808/1133, batch loss:0.25898000597953796, Training time:20958.288618803024
batch reward last col mean 0.10393058508634567 first col mean 0.09174047410488129 all mean 0.1050960123538971
0.28744059801101685 0.28744059801101685
rl training, epoch6, iter0, batch809/1133, batch loss:0.28744059801101685, Training time:20960.220019578934
batch reward last col mean 0.10561154782772064 first col mean 0.11589580029249191 all mean 0.09965020418167114
0.2691976726055145 0.2691976726055145
rl training, epoch6, iter0, batch810/1133, batch loss:0.2691976726055145, Training time:20962.069288492203
batch reward last col mean 0.08614702522754669 first col mean 0.0998130664229393 all mean 0.09234007447957993
0.25358423590660095 0.25358420610427856
rl training, epoch6, iter0, batch811/1133, batch loss:0.25358420610427856, Training time:20964.19647336006
batch reward last col mean 0.09166952967643738 first col mean 0.10353252291679382 all mean 0.09177694469690323
0.2193671017885208 0.2193671017885208
rl training, epoch6, iter0, batch812/1133, batch loss:0.2193671017885208, Training time:20966.27395439148
batch reward last col mean 0.11270488798618317 first col mean 0.12642115354537964 all mean 0.11113526672124863
0.29365795850753784 0.29365795850753784
rl training, epoch6, iter0, batch813/1133, batch loss:0.29365795850753784, Training time:20968.61781835556
batch reward last col mean 0.12477058172225952 first col mean 0.1101529523730278 all mean 0.12359236180782318
0.27933794260025024 0.27933797240257263
rl training, epoch6, iter0, batch814/1133, batch loss:0.27933797240257263, Training time:20971.464844465256
batch reward last col mean 0.10191023349761963 first col mean 0.10837047547101974 all mean 0.10320116579532623
0.26111435890197754 0.26111435890197754
rl training, epoch6, iter0, batch815/1133, batch loss:0.26111435890197754, Training time:20973.311329126358
batch reward last col mean 0.11410751938819885 first col mean 0.11100244522094727 all mean 0.10993489623069763
0.3330741822719574 0.3330741822719574
rl training, epoch6, iter0, batch816/1133, batch loss:0.3330741822719574, Training time:20975.121727228165
batch reward last col mean 0.1028936505317688 first col mean 0.08550674468278885 all mean 0.10207948833703995
0.254303514957428 0.254303514957428
rl training, epoch6, iter0, batch817/1133, batch loss:0.254303514957428, Training time:20977.060623645782
batch reward last col mean 0.0793275535106659 first col mean 0.09266830235719681 all mean 0.08366604149341583
0.24838434159755707 0.24838434159755707
rl training, epoch6, iter0, batch818/1133, batch loss:0.24838434159755707, Training time:20978.909840345383
batch reward last col mean 0.10170729458332062 first col mean 0.0864178016781807 all mean 0.09895338863134384
0.27902108430862427 0.27902108430862427
rl training, epoch6, iter0, batch819/1133, batch loss:0.27902108430862427, Training time:20981.550987005234
batch reward last col mean 0.08238419890403748 first col mean 0.08680135011672974 all mean 0.0850677490234375
0.2341984063386917 0.2341984063386917
rl training, epoch6, iter0, batch820/1133, batch loss:0.2341984063386917, Training time:20983.72751736641
batch reward last col mean 0.11005869507789612 first col mean 0.09926198422908783 all mean 0.10604853928089142
0.2506869435310364 0.2506869435310364
rl training, epoch6, iter0, batch821/1133, batch loss:0.2506869435310364, Training time:20986.62579536438
batch reward last col mean 0.09573302417993546 first col mean 0.11586694419384003 all mean 0.09795860946178436
0.26299574971199036 0.26299574971199036
rl training, epoch6, iter0, batch822/1133, batch loss:0.26299574971199036, Training time:20988.97507071495
batch reward last col mean 0.09184574335813522 first col mean 0.10720156133174896 all mean 0.09940527379512787
0.2747930884361267 0.2747930884361267
rl training, epoch6, iter0, batch823/1133, batch loss:0.2747930884361267, Training time:20991.04622912407
batch reward last col mean 0.06893017143011093 first col mean 0.09042804688215256 all mean 0.081714928150177
0.26564672589302063 0.26564672589302063
rl training, epoch6, iter0, batch824/1133, batch loss:0.26564672589302063, Training time:20992.934293031693
batch reward last col mean 0.08298508822917938 first col mean 0.10533018410205841 all mean 0.08774314075708389
0.24836081266403198 0.24836081266403198
rl training, epoch6, iter0, batch825/1133, batch loss:0.24836081266403198, Training time:20995.17072534561
batch reward last col mean 0.09113642573356628 first col mean 0.10176172852516174 all mean 0.09854622185230255
0.2673357129096985 0.2673357129096985
rl training, epoch6, iter0, batch826/1133, batch loss:0.2673357129096985, Training time:20997.364310503006
batch reward last col mean 0.15045195817947388 first col mean 0.1165541559457779 all mean 0.14060050249099731
0.35717350244522095 0.35717350244522095
rl training, epoch6, iter0, batch827/1133, batch loss:0.35717350244522095, Training time:20999.331349611282
batch reward last col mean 0.08788253366947174 first col mean 0.10342729836702347 all mean 0.09353896975517273
0.2758445739746094 0.2758445739746094
rl training, epoch6, iter0, batch828/1133, batch loss:0.2758445739746094, Training time:21001.344930410385
batch reward last col mean 0.10423318296670914 first col mean 0.10167231410741806 all mean 0.10370085388422012
0.32328230142593384 0.32328230142593384
rl training, epoch6, iter0, batch829/1133, batch loss:0.32328230142593384, Training time:21003.662615060806
batch reward last col mean 0.07638160139322281 first col mean 0.11869201064109802 all mean 0.09050379693508148
0.2946634292602539 0.2946634292602539
rl training, epoch6, iter0, batch830/1133, batch loss:0.2946634292602539, Training time:21005.555004119873
batch reward last col mean 0.10484044998884201 first col mean 0.09369948506355286 all mean 0.1011904776096344
0.2657351791858673 0.2657351791858673
rl training, epoch6, iter0, batch831/1133, batch loss:0.2657351791858673, Training time:21007.77091550827
batch reward last col mean 0.09501819312572479 first col mean 0.09669404476881027 all mean 0.09608858078718185
0.27265501022338867 0.27265501022338867
rl training, epoch6, iter0, batch832/1133, batch loss:0.27265501022338867, Training time:21009.741353988647
batch reward last col mean 0.08828365802764893 first col mean 0.11806747317314148 all mean 0.09575427323579788
0.2701565623283386 0.270156592130661
rl training, epoch6, iter0, batch833/1133, batch loss:0.270156592130661, Training time:21011.41381931305
batch reward last col mean 0.112657830119133 first col mean 0.10587014257907867 all mean 0.11078701913356781
0.2764197587966919 0.2764197885990143
rl training, epoch6, iter0, batch834/1133, batch loss:0.2764197885990143, Training time:21013.62743639946
batch reward last col mean 0.09743053466081619 first col mean 0.0998862236738205 all mean 0.09728202223777771
0.29740992188453674 0.29740992188453674
rl training, epoch6, iter0, batch835/1133, batch loss:0.29740992188453674, Training time:21015.047790050507
batch reward last col mean 0.11290673911571503 first col mean 0.10664453357458115 all mean 0.10610487312078476
0.28145551681518555 0.28145548701286316
rl training, epoch6, iter0, batch836/1133, batch loss:0.28145548701286316, Training time:21016.792036294937
batch reward last col mean 0.11039470881223679 first col mean 0.0965413749217987 all mean 0.11221708357334137
0.3047679662704468 0.3047679662704468
rl training, epoch6, iter0, batch837/1133, batch loss:0.3047679662704468, Training time:21019.044176101685
batch reward last col mean 0.12314571440219879 first col mean 0.1006861999630928 all mean 0.12021375447511673
0.2691369354724884 0.2691369354724884
rl training, epoch6, iter0, batch838/1133, batch loss:0.2691369354724884, Training time:21021.49803543091
batch reward last col mean 0.0874406099319458 first col mean 0.1042482852935791 all mean 0.09562376886606216
0.27532652020454407 0.27532655000686646
rl training, epoch6, iter0, batch839/1133, batch loss:0.27532655000686646, Training time:21024.127052545547
batch reward last col mean 0.12300601601600647 first col mean 0.12099349498748779 all mean 0.12276382744312286
0.3046042025089264 0.3046042025089264
rl training, epoch6, iter0, batch840/1133, batch loss:0.3046042025089264, Training time:21026.444802045822
batch reward last col mean 0.07061144709587097 first col mean 0.09453202784061432 all mean 0.07699432969093323
0.27429360151290894 0.27429360151290894
rl training, epoch6, iter0, batch841/1133, batch loss:0.27429360151290894, Training time:21028.510883808136
batch reward last col mean 0.08673347532749176 first col mean 0.08384303748607635 all mean 0.09027203172445297
0.2261061668395996 0.2261061668395996
rl training, epoch6, iter0, batch842/1133, batch loss:0.2261061668395996, Training time:21030.463001966476
batch reward last col mean 0.11813454329967499 first col mean 0.12592528760433197 all mean 0.11175086349248886
0.2857110798358917 0.2857110798358917
rl training, epoch6, iter0, batch843/1133, batch loss:0.2857110798358917, Training time:21032.398517370224
batch reward last col mean 0.10700790584087372 first col mean 0.1144978478550911 all mean 0.10584782809019089
0.27910664677619934 0.27910664677619934
rl training, epoch6, iter0, batch844/1133, batch loss:0.27910664677619934, Training time:21034.291447877884
batch reward last col mean 0.11809809505939484 first col mean 0.10490860044956207 all mean 0.11521048098802567
0.32765841484069824 0.32765841484069824
rl training, epoch6, iter0, batch845/1133, batch loss:0.32765841484069824, Training time:21036.268418073654
batch reward last col mean 0.06455546617507935 first col mean 0.09266964346170425 all mean 0.07893530279397964
0.23277242481708527 0.23277242481708527
rl training, epoch6, iter0, batch846/1133, batch loss:0.23277242481708527, Training time:21038.173852682114
batch reward last col mean 0.08697160333395004 first col mean 0.10318377614021301 all mean 0.09136315435171127
0.2778124511241913 0.2778124511241913
rl training, epoch6, iter0, batch847/1133, batch loss:0.2778124511241913, Training time:21040.203758239746
batch reward last col mean 0.10703669488430023 first col mean 0.09850337356328964 all mean 0.1019960269331932
0.29102903604507446 0.29102906584739685
rl training, epoch6, iter0, batch848/1133, batch loss:0.29102906584739685, Training time:21041.72494482994
batch reward last col mean 0.094286248087883 first col mean 0.106002077460289 all mean 0.09056445211172104
0.3081968128681183 0.3081968128681183
rl training, epoch6, iter0, batch849/1133, batch loss:0.3081968128681183, Training time:21043.555210351944
batch reward last col mean 0.09542630612850189 first col mean 0.11222527921199799 all mean 0.09411969780921936
0.29280221462249756 0.29280221462249756
rl training, epoch6, iter0, batch850/1133, batch loss:0.29280221462249756, Training time:21045.65966129303
batch reward last col mean 0.10875123739242554 first col mean 0.10500010848045349 all mean 0.10438448935747147
0.28066176176071167 0.28066176176071167
rl training, epoch6, iter0, batch851/1133, batch loss:0.28066176176071167, Training time:21047.683451890945
batch reward last col mean 0.11356668174266815 first col mean 0.10672459006309509 all mean 0.11068838834762573
0.2919153869152069 0.2919153869152069
rl training, epoch6, iter0, batch852/1133, batch loss:0.2919153869152069, Training time:21049.66956090927
batch reward last col mean 0.10607722401618958 first col mean 0.10171766579151154 all mean 0.1070094034075737
0.2986370027065277 0.2986370027065277
rl training, epoch6, iter0, batch853/1133, batch loss:0.2986370027065277, Training time:21051.893145799637
batch reward last col mean 0.079184889793396 first col mean 0.09207946062088013 all mean 0.08282385766506195
0.26852157711982727 0.26852157711982727
rl training, epoch6, iter0, batch854/1133, batch loss:0.26852157711982727, Training time:21054.496180534363
batch reward last col mean 0.11274358630180359 first col mean 0.11538001894950867 all mean 0.11179950088262558
0.3140951991081238 0.3140951991081238
rl training, epoch6, iter0, batch855/1133, batch loss:0.3140951991081238, Training time:21056.4606385231
batch reward last col mean 0.09811694175004959 first col mean 0.11209897696971893 all mean 0.10370634496212006
0.26556625962257385 0.26556625962257385
rl training, epoch6, iter0, batch856/1133, batch loss:0.26556625962257385, Training time:21058.269257068634
batch reward last col mean 0.10527694225311279 first col mean 0.0930810421705246 all mean 0.10995015501976013
0.3055558204650879 0.3055558204650879
rl training, epoch6, iter0, batch857/1133, batch loss:0.3055558204650879, Training time:21060.111058473587
batch reward last col mean 0.10911764204502106 first col mean 0.12984806299209595 all mean 0.10870761424303055
0.3055907189846039 0.3055907189846039
rl training, epoch6, iter0, batch858/1133, batch loss:0.3055907189846039, Training time:21061.922196388245
batch reward last col mean 0.08793975412845612 first col mean 0.12204131484031677 all mean 0.09187154471874237
0.2726399898529053 0.2726399898529053
rl training, epoch6, iter0, batch859/1133, batch loss:0.2726399898529053, Training time:21063.89441394806
batch reward last col mean 0.0609135702252388 first col mean 0.087812639772892 all mean 0.07285073399543762
0.27258944511413574 0.27258944511413574
rl training, epoch6, iter0, batch860/1133, batch loss:0.27258944511413574, Training time:21065.68207383156
batch reward last col mean 0.10781985521316528 first col mean 0.10628002882003784 all mean 0.1039581447839737
0.27642446756362915 0.27642443776130676
rl training, epoch6, iter0, batch861/1133, batch loss:0.27642443776130676, Training time:21067.987525224686
batch reward last col mean 0.12839150428771973 first col mean 0.10427211970090866 all mean 0.12550893425941467
0.2880713939666748 0.2880713939666748
rl training, epoch6, iter0, batch862/1133, batch loss:0.2880713939666748, Training time:21070.537714481354
batch reward last col mean 0.08471138775348663 first col mean 0.09932752698659897 all mean 0.08808503299951553
0.28625255823135376 0.28625255823135376
rl training, epoch6, iter0, batch863/1133, batch loss:0.28625255823135376, Training time:21073.055131673813
batch reward last col mean 0.12112858891487122 first col mean 0.11305032670497894 all mean 0.12151279300451279
0.29941636323928833 0.29941636323928833
rl training, epoch6, iter0, batch864/1133, batch loss:0.29941636323928833, Training time:21075.51850581169
batch reward last col mean 0.08622577041387558 first col mean 0.09811004251241684 all mean 0.08965229988098145
0.2671160101890564 0.2671160101890564
rl training, epoch6, iter0, batch865/1133, batch loss:0.2671160101890564, Training time:21077.096361398697
batch reward last col mean 0.10058678686618805 first col mean 0.11682119965553284 all mean 0.10515324771404266
0.28674909472465515 0.28674909472465515
rl training, epoch6, iter0, batch866/1133, batch loss:0.28674909472465515, Training time:21079.04042005539
batch reward last col mean 0.073221854865551 first col mean 0.11007476598024368 all mean 0.08051978051662445
0.2622855603694916 0.2622855603694916
rl training, epoch6, iter0, batch867/1133, batch loss:0.2622855603694916, Training time:21080.920407772064
batch reward last col mean 0.09151607751846313 first col mean 0.11747434735298157 all mean 0.09123183786869049
0.2690570056438446 0.2690570056438446
rl training, epoch6, iter0, batch868/1133, batch loss:0.2690570056438446, Training time:21083.304271697998
batch reward last col mean 0.1130485013127327 first col mean 0.11167877912521362 all mean 0.11841510236263275
0.3207058310508728 0.32070574164390564
rl training, epoch6, iter0, batch869/1133, batch loss:0.32070574164390564, Training time:21085.893002033234
batch reward last col mean 0.08832105994224548 first col mean 0.11623391509056091 all mean 0.10446446388959885
0.3155476152896881 0.3155476152896881
rl training, epoch6, iter0, batch870/1133, batch loss:0.3155476152896881, Training time:21087.239370584488
batch reward last col mean 0.06451442092657089 first col mean 0.08505909144878387 all mean 0.07034599035978317
0.24072836339473724 0.24072836339473724
rl training, epoch6, iter0, batch871/1133, batch loss:0.24072836339473724, Training time:21089.17823767662
batch reward last col mean 0.12405127286911011 first col mean 0.10092951357364655 all mean 0.11649364233016968
0.31534823775291443 0.31534823775291443
rl training, epoch6, iter0, batch872/1133, batch loss:0.31534823775291443, Training time:21091.34047627449
batch reward last col mean 0.10732703655958176 first col mean 0.10837353765964508 all mean 0.10033334791660309
0.2828630208969116 0.2828630208969116
rl training, epoch6, iter0, batch873/1133, batch loss:0.2828630208969116, Training time:21093.334183216095
batch reward last col mean 0.0909697413444519 first col mean 0.10893786698579788 all mean 0.09759301692247391
0.2917059659957886 0.2917059659957886
rl training, epoch6, iter0, batch874/1133, batch loss:0.2917059659957886, Training time:21095.342548131943
batch reward last col mean 0.11051253974437714 first col mean 0.13350239396095276 all mean 0.10907642543315887
0.2959615886211395 0.2959615886211395
rl training, epoch6, iter0, batch875/1133, batch loss:0.2959615886211395, Training time:21097.268132686615
batch reward last col mean 0.11452212184667587 first col mean 0.0982314944267273 all mean 0.1122698187828064
0.2638646960258484 0.2638646960258484
rl training, epoch6, iter0, batch876/1133, batch loss:0.2638646960258484, Training time:21099.71786570549
batch reward last col mean 0.11657840758562088 first col mean 0.10273583978414536 all mean 0.11424247175455093
0.27533382177352905 0.27533382177352905
rl training, epoch6, iter0, batch877/1133, batch loss:0.27533382177352905, Training time:21101.14269566536
batch reward last col mean 0.06490813195705414 first col mean 0.11132898926734924 all mean 0.07072179019451141
0.24163216352462769 0.2416321486234665
rl training, epoch6, iter0, batch878/1133, batch loss:0.2416321486234665, Training time:21103.22459793091
batch reward last col mean 0.07786208391189575 first col mean 0.1112707257270813 all mean 0.08499160408973694
0.25425398349761963 0.25425398349761963
rl training, epoch6, iter0, batch879/1133, batch loss:0.25425398349761963, Training time:21105.044487953186
batch reward last col mean 0.09060028940439224 first col mean 0.12623463571071625 all mean 0.10385444760322571
0.30637064576148987 0.30637064576148987
rl training, epoch6, iter0, batch880/1133, batch loss:0.30637064576148987, Training time:21106.605250597
batch reward last col mean 0.1219278872013092 first col mean 0.09812198579311371 all mean 0.11308983713388443
0.3213443458080292 0.3213443458080292
rl training, epoch6, iter0, batch881/1133, batch loss:0.3213443458080292, Training time:21108.23926615715
batch reward last col mean 0.11921493709087372 first col mean 0.08731454610824585 all mean 0.11008616536855698
0.2856195867061615 0.2856195867061615
rl training, epoch6, iter0, batch882/1133, batch loss:0.2856195867061615, Training time:21110.75063610077
batch reward last col mean 0.11457914113998413 first col mean 0.11764983832836151 all mean 0.11106494069099426
0.3123842775821686 0.3123842775821686
rl training, epoch6, iter0, batch883/1133, batch loss:0.3123842775821686, Training time:21112.844801187515
batch reward last col mean 0.11261210590600967 first col mean 0.10181695967912674 all mean 0.10798433423042297
0.27478721737861633 0.27478721737861633
rl training, epoch6, iter0, batch884/1133, batch loss:0.27478721737861633, Training time:21114.56271982193
batch reward last col mean 0.1039888933300972 first col mean 0.10539078712463379 all mean 0.1036883145570755
0.2657681703567505 0.2657681703567505
rl training, epoch6, iter0, batch885/1133, batch loss:0.2657681703567505, Training time:21117.1584045887
batch reward last col mean 0.07692182809114456 first col mean 0.09519584476947784 all mean 0.0812317356467247
0.2674875557422638 0.2674875855445862
rl training, epoch6, iter0, batch886/1133, batch loss:0.2674875855445862, Training time:21118.71972465515
batch reward last col mean 0.10089465230703354 first col mean 0.10285962373018265 all mean 0.096654012799263
0.2613176107406616 0.2613176107406616
rl training, epoch6, iter0, batch887/1133, batch loss:0.2613176107406616, Training time:21120.910539865494
batch reward last col mean 0.09792204201221466 first col mean 0.10307426750659943 all mean 0.09668053686618805
0.3176622986793518 0.3176622688770294
rl training, epoch6, iter0, batch888/1133, batch loss:0.3176622688770294, Training time:21122.726021766663
batch reward last col mean 0.07326774299144745 first col mean 0.12224629521369934 all mean 0.08080355077981949
0.2438364177942276 0.2438364028930664
rl training, epoch6, iter0, batch889/1133, batch loss:0.2438364028930664, Training time:21124.720518112183
batch reward last col mean 0.08523866534233093 first col mean 0.10823886096477509 all mean 0.09111493825912476
0.24473519623279572 0.24473519623279572
rl training, epoch6, iter0, batch890/1133, batch loss:0.24473519623279572, Training time:21126.841059207916
batch reward last col mean 0.11615578830242157 first col mean 0.10486095398664474 all mean 0.11608720570802689
0.33455023169517517 0.33455023169517517
rl training, epoch6, iter0, batch891/1133, batch loss:0.33455023169517517, Training time:21128.939541101456
batch reward last col mean 0.09635937958955765 first col mean 0.11100464314222336 all mean 0.10119748115539551
0.2864499092102051 0.2864499092102051
rl training, epoch6, iter0, batch892/1133, batch loss:0.2864499092102051, Training time:21131.08642101288
batch reward last col mean 0.08441489189863205 first col mean 0.11078736931085587 all mean 0.09067659080028534
0.2689308524131775 0.2689308524131775
rl training, epoch6, iter0, batch893/1133, batch loss:0.2689308524131775, Training time:21132.986740350723
batch reward last col mean 0.11391157656908035 first col mean 0.12018775939941406 all mean 0.11046919971704483
0.2981620728969574 0.2981620728969574
rl training, epoch6, iter0, batch894/1133, batch loss:0.2981620728969574, Training time:21134.8668115139
batch reward last col mean 0.10773219168186188 first col mean 0.11897842586040497 all mean 0.10917240381240845
0.27964577078819275 0.27964577078819275
rl training, epoch6, iter0, batch895/1133, batch loss:0.27964577078819275, Training time:21136.898329257965
batch reward last col mean 0.10291218757629395 first col mean 0.11943154782056808 all mean 0.09853917360305786
0.29639169573783875 0.29639169573783875
rl training, epoch6, iter0, batch896/1133, batch loss:0.29639169573783875, Training time:21138.589035749435
batch reward last col mean 0.06908145546913147 first col mean 0.10199528932571411 all mean 0.0796525701880455
0.29061079025268555 0.29061079025268555
rl training, epoch6, iter0, batch897/1133, batch loss:0.29061079025268555, Training time:21140.483294010162
batch reward last col mean 0.09722693264484406 first col mean 0.12024389952421188 all mean 0.10489800572395325
0.2842877209186554 0.2842877209186554
rl training, epoch6, iter0, batch898/1133, batch loss:0.2842877209186554, Training time:21142.391667842865
batch reward last col mean 0.08490695059299469 first col mean 0.11910399794578552 all mean 0.09630418568849564
0.296642005443573 0.296642005443573
rl training, epoch6, iter0, batch899/1133, batch loss:0.296642005443573, Training time:21144.3147752285
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4803353899996152 Time: 96.52010178565979 s
loss of true 0.20697835788775207 loss of gen 0.17672000474248012 loss of other 0.09663702835084743 first score 0.11642887443304062
batch reward last col mean 0.0802910178899765 first col mean 0.09594979882240295 all mean 0.08540370315313339
0.23180769383907318 0.23180769383907318
rl training, epoch6, iter0, batch900/1133, batch loss:0.23180769383907318, Training time:21242.751918554306
batch reward last col mean 0.09569314867258072 first col mean 0.09877003729343414 all mean 0.09864567220211029
0.2914141118526459 0.2914141118526459
rl training, epoch6, iter0, batch901/1133, batch loss:0.2914141118526459, Training time:21244.797036647797
batch reward last col mean 0.09484459459781647 first col mean 0.10474388301372528 all mean 0.09585113823413849
0.2690295875072479 0.2690295875072479
rl training, epoch6, iter0, batch902/1133, batch loss:0.2690295875072479, Training time:21246.616557359695
batch reward last col mean 0.0868304967880249 first col mean 0.10182277858257294 all mean 0.08901065587997437
0.27130746841430664 0.27130746841430664
rl training, epoch6, iter0, batch903/1133, batch loss:0.27130746841430664, Training time:21248.558395385742
batch reward last col mean 0.06840090453624725 first col mean 0.10647116601467133 all mean 0.08067736774682999
0.21856920421123505 0.21856920421123505
rl training, epoch6, iter0, batch904/1133, batch loss:0.21856920421123505, Training time:21250.97624373436
batch reward last col mean 0.08702775835990906 first col mean 0.09614202380180359 all mean 0.09657242149114609
0.29469749331474304 0.29469749331474304
rl training, epoch6, iter0, batch905/1133, batch loss:0.29469749331474304, Training time:21252.52102279663
batch reward last col mean 0.09961037337779999 first col mean 0.09580905735492706 all mean 0.10073735564947128
0.26990070939064026 0.26990070939064026
rl training, epoch6, iter0, batch906/1133, batch loss:0.26990070939064026, Training time:21254.59321784973
batch reward last col mean 0.07479426264762878 first col mean 0.09986826032400131 all mean 0.08375923335552216
0.2602885365486145 0.2602885365486145
rl training, epoch6, iter0, batch907/1133, batch loss:0.2602885365486145, Training time:21256.530121326447
batch reward last col mean 0.10906148701906204 first col mean 0.09724591672420502 all mean 0.10475935786962509
0.25803375244140625 0.25803375244140625
rl training, epoch6, iter0, batch908/1133, batch loss:0.25803375244140625, Training time:21258.297533988953
batch reward last col mean 0.07491306960582733 first col mean 0.08296802639961243 all mean 0.07892908155918121
0.2753293216228485 0.2753293216228485
rl training, epoch6, iter0, batch909/1133, batch loss:0.2753293216228485, Training time:21260.404718875885
batch reward last col mean 0.09482726454734802 first col mean 0.11817070841789246 all mean 0.09516120702028275
0.27327048778533936 0.27327048778533936
rl training, epoch6, iter0, batch910/1133, batch loss:0.27327048778533936, Training time:21262.40546274185
batch reward last col mean 0.11104732006788254 first col mean 0.1186082661151886 all mean 0.10822174698114395
0.277963787317276 0.277963787317276
rl training, epoch6, iter0, batch911/1133, batch loss:0.277963787317276, Training time:21265.0178232193
batch reward last col mean 0.08035384118556976 first col mean 0.08779676258563995 all mean 0.08367262780666351
0.2388116866350174 0.2388116866350174
rl training, epoch6, iter0, batch912/1133, batch loss:0.2388116866350174, Training time:21267.777359485626
batch reward last col mean 0.08998275548219681 first col mean 0.09425914287567139 all mean 0.09437131881713867
0.2404453605413437 0.2404453605413437
rl training, epoch6, iter0, batch913/1133, batch loss:0.2404453605413437, Training time:21269.920727729797
batch reward last col mean 0.10201621055603027 first col mean 0.08018971979618073 all mean 0.09681989997625351
0.25424110889434814 0.25424113869667053
rl training, epoch6, iter0, batch914/1133, batch loss:0.25424113869667053, Training time:21272.9166970253
batch reward last col mean 0.09975079447031021 first col mean 0.10202907025814056 all mean 0.10105729103088379
0.2738383412361145 0.2738383114337921
rl training, epoch6, iter0, batch915/1133, batch loss:0.2738383114337921, Training time:21276.058225631714
batch reward last col mean 0.10264033079147339 first col mean 0.1037856861948967 all mean 0.10218154639005661
0.25348424911499023 0.25348424911499023
rl training, epoch6, iter0, batch916/1133, batch loss:0.25348424911499023, Training time:21277.9673037529
batch reward last col mean 0.127424955368042 first col mean 0.10693880915641785 all mean 0.12242501229047775
0.3356683850288391 0.3356683850288391
rl training, epoch6, iter0, batch917/1133, batch loss:0.3356683850288391, Training time:21279.685933351517
batch reward last col mean 0.07349468022584915 first col mean 0.10346218943595886 all mean 0.08139671385288239
0.2441118210554123 0.2441118210554123
rl training, epoch6, iter0, batch918/1133, batch loss:0.2441118210554123, Training time:21281.803665161133
batch reward last col mean 0.09855920076370239 first col mean 0.10333801805973053 all mean 0.0989987701177597
0.266534686088562 0.266534686088562
rl training, epoch6, iter0, batch919/1133, batch loss:0.266534686088562, Training time:21283.766073465347
batch reward last col mean 0.11511039733886719 first col mean 0.09250560402870178 all mean 0.11157309263944626
0.2886507511138916 0.2886507511138916
rl training, epoch6, iter0, batch920/1133, batch loss:0.2886507511138916, Training time:21286.21376991272
batch reward last col mean 0.12328868359327316 first col mean 0.09080788493156433 all mean 0.11345060914754868
0.29042118787765503 0.29042118787765503
rl training, epoch6, iter0, batch921/1133, batch loss:0.29042118787765503, Training time:21288.22344684601
batch reward last col mean 0.09506139159202576 first col mean 0.11247766017913818 all mean 0.09489979594945908
0.23174816370010376 0.23174816370010376
rl training, epoch6, iter0, batch922/1133, batch loss:0.23174816370010376, Training time:21290.191351413727
batch reward last col mean 0.06917253881692886 first col mean 0.10548477619886398 all mean 0.07918546348810196
0.23694659769535065 0.23694659769535065
rl training, epoch6, iter0, batch923/1133, batch loss:0.23694659769535065, Training time:21292.102410316467
batch reward last col mean 0.08509613573551178 first col mean 0.09473998099565506 all mean 0.08737247437238693
0.2560126483440399 0.2560126483440399
rl training, epoch6, iter0, batch924/1133, batch loss:0.2560126483440399, Training time:21294.331565380096
batch reward last col mean 0.11790454387664795 first col mean 0.10545732825994492 all mean 0.10945075005292892
0.2708432972431183 0.2708432972431183
rl training, epoch6, iter0, batch925/1133, batch loss:0.2708432972431183, Training time:21296.720086812973
batch reward last col mean 0.11789946258068085 first col mean 0.10875653475522995 all mean 0.11450165510177612
0.29757407307624817 0.29757407307624817
rl training, epoch6, iter0, batch926/1133, batch loss:0.29757407307624817, Training time:21299.440854549408
batch reward last col mean 0.07307200133800507 first col mean 0.10869044810533524 all mean 0.07527920603752136
0.22889602184295654 0.22889600694179535
rl training, epoch6, iter0, batch927/1133, batch loss:0.22889600694179535, Training time:21301.95324897766
batch reward last col mean 0.11226406693458557 first col mean 0.11486876010894775 all mean 0.10988576710224152
0.258091002702713 0.258091002702713
rl training, epoch6, iter0, batch928/1133, batch loss:0.258091002702713, Training time:21303.955513954163
batch reward last col mean 0.13752810657024384 first col mean 0.11042778939008713 all mean 0.1207832545042038
0.3073993921279907 0.3073993921279907
rl training, epoch6, iter0, batch929/1133, batch loss:0.3073993921279907, Training time:21305.9620616436
batch reward last col mean 0.10486952215433121 first col mean 0.11380060017108917 all mean 0.10417678207159042
0.27230748534202576 0.27230748534202576
rl training, epoch6, iter0, batch930/1133, batch loss:0.27230748534202576, Training time:21308.000350236893
batch reward last col mean 0.0699465423822403 first col mean 0.08666784316301346 all mean 0.08064340054988861
0.23695598542690277 0.23695598542690277
rl training, epoch6, iter0, batch931/1133, batch loss:0.23695598542690277, Training time:21309.851702451706
batch reward last col mean 0.109702467918396 first col mean 0.1109030544757843 all mean 0.11077673733234406
0.26721587777137756 0.2672158479690552
rl training, epoch6, iter0, batch932/1133, batch loss:0.2672158479690552, Training time:21311.838136196136
batch reward last col mean 0.07821930199861526 first col mean 0.10468961298465729 all mean 0.09058529138565063
0.2806667983531952 0.2806667983531952
rl training, epoch6, iter0, batch933/1133, batch loss:0.2806667983531952, Training time:21313.469763040543
batch reward last col mean 0.08436937630176544 first col mean 0.10311362147331238 all mean 0.09305045008659363
0.2626994252204895 0.2626994252204895
rl training, epoch6, iter0, batch934/1133, batch loss:0.2626994252204895, Training time:21316.168332338333
batch reward last col mean 0.06203623116016388 first col mean 0.1086670383810997 all mean 0.0715830996632576
0.24251516163349152 0.24251516163349152
rl training, epoch6, iter0, batch935/1133, batch loss:0.24251516163349152, Training time:21318.312614917755
batch reward last col mean 0.13151781260967255 first col mean 0.11131305992603302 all mean 0.1298285722732544
0.3337121307849884 0.3337121307849884
rl training, epoch6, iter0, batch936/1133, batch loss:0.3337121307849884, Training time:21320.105382204056
batch reward last col mean 0.09239139407873154 first col mean 0.10685868561267853 all mean 0.09907351434230804
0.2703404724597931 0.2703404724597931
rl training, epoch6, iter0, batch937/1133, batch loss:0.2703404724597931, Training time:21322.11735391617
batch reward last col mean 0.09568111598491669 first col mean 0.1023484468460083 all mean 0.0863194689154625
0.2532719075679779 0.2532719075679779
rl training, epoch6, iter0, batch938/1133, batch loss:0.2532719075679779, Training time:21324.060303926468
batch reward last col mean 0.09481588006019592 first col mean 0.1349218338727951 all mean 0.10189738124608994
0.25020480155944824 0.25020480155944824
rl training, epoch6, iter0, batch939/1133, batch loss:0.25020480155944824, Training time:21325.66703057289
batch reward last col mean 0.10352841019630432 first col mean 0.11290682852268219 all mean 0.10581322014331818
0.2904701232910156 0.2904701232910156
rl training, epoch6, iter0, batch940/1133, batch loss:0.2904701232910156, Training time:21327.831008195877
batch reward last col mean 0.09376794099807739 first col mean 0.09608687460422516 all mean 0.10514938086271286
0.2980324625968933 0.2980324327945709
rl training, epoch6, iter0, batch941/1133, batch loss:0.2980324327945709, Training time:21329.60303258896
batch reward last col mean 0.11116857081651688 first col mean 0.1114402562379837 all mean 0.10961107164621353
0.27657821774482727 0.2765781879425049
rl training, epoch6, iter0, batch942/1133, batch loss:0.2765781879425049, Training time:21331.380222320557
batch reward last col mean 0.08012223243713379 first col mean 0.09411434084177017 all mean 0.08829966932535172
0.22940096259117126 0.22940096259117126
rl training, epoch6, iter0, batch943/1133, batch loss:0.22940096259117126, Training time:21333.453144311905
batch reward last col mean 0.11860259622335434 first col mean 0.11114296317100525 all mean 0.11207088828086853
0.31103602051734924 0.31103602051734924
rl training, epoch6, iter0, batch944/1133, batch loss:0.31103602051734924, Training time:21335.07024550438
batch reward last col mean 0.10324804484844208 first col mean 0.11268450319766998 all mean 0.11205790191888809
0.2824203670024872 0.2824203670024872
rl training, epoch6, iter0, batch945/1133, batch loss:0.2824203670024872, Training time:21337.10171532631
batch reward last col mean 0.12383685261011124 first col mean 0.10301831364631653 all mean 0.11628399789333344
0.26062238216400146 0.26062238216400146
rl training, epoch6, iter0, batch946/1133, batch loss:0.26062238216400146, Training time:21338.881126880646
batch reward last col mean 0.08187291771173477 first col mean 0.09205931425094604 all mean 0.09165778756141663
0.2751578688621521 0.2751578688621521
rl training, epoch6, iter0, batch947/1133, batch loss:0.2751578688621521, Training time:21340.814264059067
batch reward last col mean 0.09387315809726715 first col mean 0.09886279702186584 all mean 0.0975373387336731
0.27063482999801636 0.27063482999801636
rl training, epoch6, iter0, batch948/1133, batch loss:0.27063482999801636, Training time:21342.542156219482
batch reward last col mean 0.09442488849163055 first col mean 0.10773265361785889 all mean 0.09406033158302307
0.27278459072113037 0.27278459072113037
rl training, epoch6, iter0, batch949/1133, batch loss:0.27278459072113037, Training time:21344.500002861023
batch reward last col mean 0.1120760515332222 first col mean 0.11245425045490265 all mean 0.11180903017520905
0.25876742601394653 0.25876742601394653
rl training, epoch6, iter0, batch950/1133, batch loss:0.25876742601394653, Training time:21346.595376968384
batch reward last col mean 0.10114294290542603 first col mean 0.11045755445957184 all mean 0.10250282287597656
0.2551268935203552 0.2551268935203552
rl training, epoch6, iter0, batch951/1133, batch loss:0.2551268935203552, Training time:21348.61893105507
batch reward last col mean 0.10422206670045853 first col mean 0.10017058998346329 all mean 0.10523116588592529
0.26507076621055603 0.26507076621055603
rl training, epoch6, iter0, batch952/1133, batch loss:0.26507076621055603, Training time:21351.51578617096
batch reward last col mean 0.09274045377969742 first col mean 0.10576867312192917 all mean 0.09567729383707047
0.23085413873195648 0.23085413873195648
rl training, epoch6, iter0, batch953/1133, batch loss:0.23085413873195648, Training time:21353.075511455536
batch reward last col mean 0.13690176606178284 first col mean 0.10805957764387131 all mean 0.13386361300945282
0.29033011198043823 0.29033011198043823
rl training, epoch6, iter0, batch954/1133, batch loss:0.29033011198043823, Training time:21355.352739810944
batch reward last col mean 0.11154332756996155 first col mean 0.12550607323646545 all mean 0.11472755670547485
0.2909848392009735 0.2909848392009735
rl training, epoch6, iter0, batch955/1133, batch loss:0.2909848392009735, Training time:21357.383661031723
batch reward last col mean 0.07114511728286743 first col mean 0.11607670783996582 all mean 0.07736272364854813
0.2475704699754715 0.2475704699754715
rl training, epoch6, iter0, batch956/1133, batch loss:0.2475704699754715, Training time:21359.752976179123
batch reward last col mean 0.1091330349445343 first col mean 0.11750727146863937 all mean 0.11011102050542831
0.2845320403575897 0.2845320701599121
rl training, epoch6, iter0, batch957/1133, batch loss:0.2845320701599121, Training time:21361.69323015213
batch reward last col mean 0.11768729239702225 first col mean 0.10981089621782303 all mean 0.1118115559220314
0.29303768277168274 0.29303765296936035
rl training, epoch6, iter0, batch958/1133, batch loss:0.29303765296936035, Training time:21363.500351667404
batch reward last col mean 0.0915549248456955 first col mean 0.10978643596172333 all mean 0.09740675240755081
0.2579527199268341 0.2579527199268341
rl training, epoch6, iter0, batch959/1133, batch loss:0.2579527199268341, Training time:21365.210842370987
batch reward last col mean 0.10269484668970108 first col mean 0.11585056781768799 all mean 0.10749899595975876
0.2905033528804779 0.2905033528804779
rl training, epoch6, iter0, batch960/1133, batch loss:0.2905033528804779, Training time:21366.92186665535
batch reward last col mean 0.12339162826538086 first col mean 0.09250681847333908 all mean 0.11921428889036179
0.26641181111335754 0.26641181111335754
rl training, epoch6, iter0, batch961/1133, batch loss:0.26641181111335754, Training time:21369.99240422249
batch reward last col mean 0.0999852865934372 first col mean 0.1030883714556694 all mean 0.09776552021503448
0.2793945074081421 0.2793945074081421
rl training, epoch6, iter0, batch962/1133, batch loss:0.2793945074081421, Training time:21371.966831445694
batch reward last col mean 0.11460362374782562 first col mean 0.0974293202161789 all mean 0.10919743031263351
0.27145493030548096 0.27145493030548096
rl training, epoch6, iter0, batch963/1133, batch loss:0.27145493030548096, Training time:21374.000648736954
batch reward last col mean 0.08755725622177124 first col mean 0.09733469039201736 all mean 0.09478449821472168
0.2776773273944855 0.2776772975921631
rl training, epoch6, iter0, batch964/1133, batch loss:0.2776772975921631, Training time:21376.025865793228
batch reward last col mean 0.10284136980772018 first col mean 0.11017739772796631 all mean 0.10572699457406998
0.2983633577823639 0.2983633279800415
rl training, epoch6, iter0, batch965/1133, batch loss:0.2983633279800415, Training time:21377.920093774796
batch reward last col mean 0.1133122593164444 first col mean 0.11417984962463379 all mean 0.1150900200009346
0.31058380007743835 0.31058380007743835
rl training, epoch6, iter0, batch966/1133, batch loss:0.31058380007743835, Training time:21379.700657367706
batch reward last col mean 0.09973392635583878 first col mean 0.12162381410598755 all mean 0.09398972988128662
0.24157506227493286 0.24157506227493286
rl training, epoch6, iter0, batch967/1133, batch loss:0.24157506227493286, Training time:21381.695588111877
batch reward last col mean 0.09113393723964691 first col mean 0.11121409386396408 all mean 0.09306574612855911
0.2548283040523529 0.2548283338546753
rl training, epoch6, iter0, batch968/1133, batch loss:0.2548283338546753, Training time:21383.943543434143
batch reward last col mean 0.07440708577632904 first col mean 0.09848938882350922 all mean 0.08191869407892227
0.26843878626823425 0.26843878626823425
rl training, epoch6, iter0, batch969/1133, batch loss:0.26843878626823425, Training time:21385.616515159607
batch reward last col mean 0.13068586587905884 first col mean 0.09631902724504471 all mean 0.1212482824921608
0.30536964535713196 0.30536964535713196
rl training, epoch6, iter0, batch970/1133, batch loss:0.30536964535713196, Training time:21387.595594406128
batch reward last col mean 0.0665067583322525 first col mean 0.10786618292331696 all mean 0.0802110955119133
0.23999278247356415 0.23999278247356415
rl training, epoch6, iter0, batch971/1133, batch loss:0.23999278247356415, Training time:21389.773374080658
batch reward last col mean 0.05836303532123566 first col mean 0.10218282043933868 all mean 0.07177847623825073
0.24390192329883575 0.24390192329883575
rl training, epoch6, iter0, batch972/1133, batch loss:0.24390192329883575, Training time:21391.89180803299
batch reward last col mean 0.10745618492364883 first col mean 0.10110269486904144 all mean 0.09765101969242096
0.2591383159160614 0.2591383159160614
rl training, epoch6, iter0, batch973/1133, batch loss:0.2591383159160614, Training time:21393.58722424507
batch reward last col mean 0.11861458420753479 first col mean 0.09787885844707489 all mean 0.11189883202314377
0.30009976029396057 0.30009976029396057
rl training, epoch6, iter0, batch974/1133, batch loss:0.30009976029396057, Training time:21395.63242125511
batch reward last col mean 0.1440780907869339 first col mean 0.12275844067335129 all mean 0.1377713531255722
0.34007033705711365 0.34007033705711365
rl training, epoch6, iter0, batch975/1133, batch loss:0.34007033705711365, Training time:21397.279314756393
batch reward last col mean 0.07015204429626465 first col mean 0.10498487949371338 all mean 0.07517824321985245
0.2286309450864792 0.2286309450864792
rl training, epoch6, iter0, batch976/1133, batch loss:0.2286309450864792, Training time:21399.834669589996
batch reward last col mean 0.12936332821846008 first col mean 0.10760792344808578 all mean 0.11071266978979111
0.28113090991973877 0.28113090991973877
rl training, epoch6, iter0, batch977/1133, batch loss:0.28113090991973877, Training time:21401.518243312836
batch reward last col mean 0.05715164169669151 first col mean 0.09457558393478394 all mean 0.06611540913581848
0.2253372222185135 0.2253372222185135
rl training, epoch6, iter0, batch978/1133, batch loss:0.2253372222185135, Training time:21403.299273490906
batch reward last col mean 0.11318744719028473 first col mean 0.11407633125782013 all mean 0.11219653487205505
0.2627967894077301 0.2627967596054077
rl training, epoch6, iter0, batch979/1133, batch loss:0.2627967596054077, Training time:21404.892085790634
batch reward last col mean 0.12342754006385803 first col mean 0.10082754492759705 all mean 0.11972690373659134
0.2929094135761261 0.2929094135761261
rl training, epoch6, iter0, batch980/1133, batch loss:0.2929094135761261, Training time:21406.84594464302
batch reward last col mean 0.08583490550518036 first col mean 0.10969846695661545 all mean 0.09412601590156555
0.3051573634147644 0.3051573634147644
rl training, epoch6, iter0, batch981/1133, batch loss:0.3051573634147644, Training time:21408.807743787766
batch reward last col mean 0.12422563135623932 first col mean 0.09970049560070038 all mean 0.12178780138492584
0.2584938406944275 0.2584938406944275
rl training, epoch6, iter0, batch982/1133, batch loss:0.2584938406944275, Training time:21411.162012577057
batch reward last col mean 0.0913897231221199 first col mean 0.11461080610752106 all mean 0.09355124086141586
0.2570401132106781 0.2570401132106781
rl training, epoch6, iter0, batch983/1133, batch loss:0.2570401132106781, Training time:21412.84491300583
batch reward last col mean 0.0939999595284462 first col mean 0.10493839532136917 all mean 0.10139400511980057
0.28945180773735046 0.28945183753967285
rl training, epoch6, iter0, batch984/1133, batch loss:0.28945183753967285, Training time:21414.80858230591
batch reward last col mean 0.10720372200012207 first col mean 0.10371414572000504 all mean 0.10589700192213058
0.2784728705883026 0.2784728705883026
rl training, epoch6, iter0, batch985/1133, batch loss:0.2784728705883026, Training time:21417.6126871109
batch reward last col mean 0.10389016568660736 first col mean 0.10023444145917892 all mean 0.10153491795063019
0.29601719975471497 0.29601719975471497
rl training, epoch6, iter0, batch986/1133, batch loss:0.29601719975471497, Training time:21419.726238250732
batch reward last col mean 0.12215804308652878 first col mean 0.11627078056335449 all mean 0.12162833660840988
0.2865251302719116 0.2865251302719116
rl training, epoch6, iter0, batch987/1133, batch loss:0.2865251302719116, Training time:21422.097747564316
batch reward last col mean 0.10858820378780365 first col mean 0.10628432780504227 all mean 0.10947968810796738
0.2711033821105957 0.2711034119129181
rl training, epoch6, iter0, batch988/1133, batch loss:0.2711034119129181, Training time:21424.11447739601
batch reward last col mean 0.04531951621174812 first col mean 0.10430466383695602 all mean 0.06254629790782928
0.24629999697208405 0.24629999697208405
rl training, epoch6, iter0, batch989/1133, batch loss:0.24629999697208405, Training time:21426.22518515587
batch reward last col mean 0.10639189183712006 first col mean 0.09657537937164307 all mean 0.10911352187395096
0.291608065366745 0.291608065366745
rl training, epoch6, iter0, batch990/1133, batch loss:0.291608065366745, Training time:21428.308706760406
batch reward last col mean 0.08373880386352539 first col mean 0.10834310948848724 all mean 0.09012357890605927
0.2977537512779236 0.2977537512779236
rl training, epoch6, iter0, batch991/1133, batch loss:0.2977537512779236, Training time:21430.400322437286
batch reward last col mean 0.10121221840381622 first col mean 0.11508917808532715 all mean 0.10013247281312943
0.2769601345062256 0.2769601345062256
rl training, epoch6, iter0, batch992/1133, batch loss:0.2769601345062256, Training time:21432.96471619606
batch reward last col mean 0.09973315894603729 first col mean 0.09795425832271576 all mean 0.10203500092029572
0.2586369812488556 0.2586369812488556
rl training, epoch6, iter0, batch993/1133, batch loss:0.2586369812488556, Training time:21434.939893484116
batch reward last col mean 0.07091935724020004 first col mean 0.10851749032735825 all mean 0.08475032448768616
0.2666003406047821 0.2666003406047821
rl training, epoch6, iter0, batch994/1133, batch loss:0.2666003406047821, Training time:21437.034632205963
batch reward last col mean 0.12432783097028732 first col mean 0.1142941489815712 all mean 0.1236022487282753
0.2779428958892822 0.2779428958892822
rl training, epoch6, iter0, batch995/1133, batch loss:0.2779428958892822, Training time:21439.082272529602
batch reward last col mean 0.09640808403491974 first col mean 0.11271268129348755 all mean 0.09254874289035797
0.2655274569988251 0.2655274569988251
rl training, epoch6, iter0, batch996/1133, batch loss:0.2655274569988251, Training time:21440.905750989914
batch reward last col mean 0.07705491036176682 first col mean 0.11397545039653778 all mean 0.08522572368383408
0.27459123730659485 0.27459123730659485
rl training, epoch6, iter0, batch997/1133, batch loss:0.27459123730659485, Training time:21442.981223106384
batch reward last col mean 0.12077680230140686 first col mean 0.10864290595054626 all mean 0.12359675765037537
0.3579344153404236 0.3579344153404236
rl training, epoch6, iter0, batch998/1133, batch loss:0.3579344153404236, Training time:21444.743173599243
batch reward last col mean 0.09165599197149277 first col mean 0.10680248588323593 all mean 0.09904888272285461
0.27603477239608765 0.27603477239608765
rl training, epoch6, iter0, batch999/1133, batch loss:0.27603477239608765, Training time:21446.343619823456
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4817410069078023 Time: 94.71112132072449 s
loss of true 0.20910413544181167 loss of gen 0.17509691346196715 loss of other 0.09753995812896701 first score 0.11171001195907593
batch reward last col mean 0.12298153340816498 first col mean 0.10531884431838989 all mean 0.12049534171819687
0.31289926171302795 0.31289926171302795
rl training, epoch6, iter0, batch1000/1133, batch loss:0.31289926171302795, Training time:21542.836472272873
batch reward last col mean 0.11899502575397491 first col mean 0.12791354954242706 all mean 0.11590801179409027
0.2765425145626068 0.2765424847602844
rl training, epoch6, iter0, batch1001/1133, batch loss:0.2765424847602844, Training time:21544.825396299362
batch reward last col mean 0.10744857788085938 first col mean 0.10321903228759766 all mean 0.10930092632770538
0.2898044288158417 0.2898044288158417
rl training, epoch6, iter0, batch1002/1133, batch loss:0.2898044288158417, Training time:21546.614891052246
batch reward last col mean 0.11766325682401657 first col mean 0.11843952536582947 all mean 0.11378546059131622
0.292617529630661 0.292617529630661
rl training, epoch6, iter0, batch1003/1133, batch loss:0.292617529630661, Training time:21548.58654689789
batch reward last col mean 0.08578577637672424 first col mean 0.08854794502258301 all mean 0.08900942653417587
0.2254680097103119 0.2254680097103119
rl training, epoch6, iter0, batch1004/1133, batch loss:0.2254680097103119, Training time:21550.476858854294
batch reward last col mean 0.09953609108924866 first col mean 0.10772530734539032 all mean 0.10304069519042969
0.29777565598487854 0.29777565598487854
rl training, epoch6, iter0, batch1005/1133, batch loss:0.29777565598487854, Training time:21552.348189353943
batch reward last col mean 0.11747705191373825 first col mean 0.10730449855327606 all mean 0.11582792550325394
0.31004729866981506 0.31004729866981506
rl training, epoch6, iter0, batch1006/1133, batch loss:0.31004729866981506, Training time:21554.749443531036
batch reward last col mean 0.0981372743844986 first col mean 0.10726085305213928 all mean 0.09954223036766052
0.29015064239501953 0.29015064239501953
rl training, epoch6, iter0, batch1007/1133, batch loss:0.29015064239501953, Training time:21556.898871660233
batch reward last col mean 0.08585429936647415 first col mean 0.11640490591526031 all mean 0.09328997135162354
0.3050856292247772 0.3050856292247772
rl training, epoch6, iter0, batch1008/1133, batch loss:0.3050856292247772, Training time:21558.89279103279
batch reward last col mean 0.10164567828178406 first col mean 0.11857181042432785 all mean 0.10412920266389847
0.301089882850647 0.301089882850647
rl training, epoch6, iter0, batch1009/1133, batch loss:0.301089882850647, Training time:21560.711901903152
batch reward last col mean 0.10514278709888458 first col mean 0.11482059955596924 all mean 0.1056097224354744
0.25580403208732605 0.25580403208732605
rl training, epoch6, iter0, batch1010/1133, batch loss:0.25580403208732605, Training time:21562.709350824356
batch reward last col mean 0.0927237793803215 first col mean 0.08544451743364334 all mean 0.0942009836435318
0.2884921729564667 0.2884921729564667
rl training, epoch6, iter0, batch1011/1133, batch loss:0.2884921729564667, Training time:21564.85175013542
batch reward last col mean 0.1110629290342331 first col mean 0.10514210164546967 all mean 0.11099967360496521
0.26532140374183655 0.26532140374183655
rl training, epoch6, iter0, batch1012/1133, batch loss:0.26532140374183655, Training time:21567.004762649536
batch reward last col mean 0.07541520148515701 first col mean 0.12094239890575409 all mean 0.08600675314664841
0.26862895488739014 0.26862895488739014
rl training, epoch6, iter0, batch1013/1133, batch loss:0.26862895488739014, Training time:21568.681354761124
batch reward last col mean 0.11553338915109634 first col mean 0.11915794759988785 all mean 0.11244380474090576
0.27628177404403687 0.27628177404403687
rl training, epoch6, iter0, batch1014/1133, batch loss:0.27628177404403687, Training time:21570.555607795715
batch reward last col mean 0.12565600872039795 first col mean 0.1111035943031311 all mean 0.11824456602334976
0.29340502619743347 0.29340502619743347
rl training, epoch6, iter0, batch1015/1133, batch loss:0.29340502619743347, Training time:21572.44123983383
batch reward last col mean 0.08798101544380188 first col mean 0.10176140815019608 all mean 0.09206973761320114
0.2828252613544464 0.2828252613544464
rl training, epoch6, iter0, batch1016/1133, batch loss:0.2828252613544464, Training time:21573.967657327652
batch reward last col mean 0.13203588128089905 first col mean 0.09787684679031372 all mean 0.1269981563091278
0.3151077926158905 0.3151077926158905
rl training, epoch6, iter0, batch1017/1133, batch loss:0.3151077926158905, Training time:21575.700632333755
batch reward last col mean 0.1127738207578659 first col mean 0.11525213718414307 all mean 0.11165274679660797
0.29394784569740295 0.29394787549972534
rl training, epoch6, iter0, batch1018/1133, batch loss:0.29394787549972534, Training time:21577.94805932045
batch reward last col mean 0.12014250457286835 first col mean 0.1142183244228363 all mean 0.11201190203428268
0.25929751992225647 0.25929751992225647
rl training, epoch6, iter0, batch1019/1133, batch loss:0.25929751992225647, Training time:21579.906514406204
batch reward last col mean 0.11318860203027725 first col mean 0.1133875921368599 all mean 0.10638648271560669
0.26187124848365784 0.26187124848365784
rl training, epoch6, iter0, batch1020/1133, batch loss:0.26187124848365784, Training time:21582.62455701828
batch reward last col mean 0.10739283263683319 first col mean 0.1048465371131897 all mean 0.10742026567459106
0.2881147563457489 0.2881147563457489
rl training, epoch6, iter0, batch1021/1133, batch loss:0.2881147563457489, Training time:21584.832842588425
batch reward last col mean 0.12406007945537567 first col mean 0.0915469080209732 all mean 0.12218847125768661
0.28477776050567627 0.28477776050567627
rl training, epoch6, iter0, batch1022/1133, batch loss:0.28477776050567627, Training time:21587.5385055542
batch reward last col mean 0.07845193147659302 first col mean 0.11645173281431198 all mean 0.08526461571455002
0.24917367100715637 0.24917367100715637
rl training, epoch6, iter0, batch1023/1133, batch loss:0.24917367100715637, Training time:21588.947021007538
batch reward last col mean 0.10770972073078156 first col mean 0.1229151114821434 all mean 0.10917013883590698
0.29096099734306335 0.29096099734306335
rl training, epoch6, iter0, batch1024/1133, batch loss:0.29096099734306335, Training time:21590.74774837494
batch reward last col mean 0.08357444405555725 first col mean 0.10745203495025635 all mean 0.09800677001476288
0.2974049150943756 0.2974049150943756
rl training, epoch6, iter0, batch1025/1133, batch loss:0.2974049150943756, Training time:21592.1975209713
batch reward last col mean 0.10397108644247055 first col mean 0.10388290882110596 all mean 0.10351315885782242
0.31290382146835327 0.31290382146835327
rl training, epoch6, iter0, batch1026/1133, batch loss:0.31290382146835327, Training time:21594.07736635208
batch reward last col mean 0.10357315838336945 first col mean 0.1136903464794159 all mean 0.10475101321935654
0.2985741198062897 0.2985740900039673
rl training, epoch6, iter0, batch1027/1133, batch loss:0.2985740900039673, Training time:21596.1136200428
batch reward last col mean 0.09913946688175201 first col mean 0.1221921369433403 all mean 0.1032460629940033
0.2782166004180908 0.2782166004180908
rl training, epoch6, iter0, batch1028/1133, batch loss:0.2782166004180908, Training time:21598.134604215622
batch reward last col mean 0.10907875746488571 first col mean 0.10481840372085571 all mean 0.10881803929805756
0.2598402202129364 0.2598402202129364
rl training, epoch6, iter0, batch1029/1133, batch loss:0.2598402202129364, Training time:21599.7708029747
batch reward last col mean 0.09376710653305054 first col mean 0.0970509946346283 all mean 0.09751135110855103
0.2655733525753021 0.26557332277297974
rl training, epoch6, iter0, batch1030/1133, batch loss:0.26557332277297974, Training time:21602.52276778221
batch reward last col mean 0.10725034773349762 first col mean 0.1194903627038002 all mean 0.1069478690624237
0.2631566822528839 0.2631566822528839
rl training, epoch6, iter0, batch1031/1133, batch loss:0.2631566822528839, Training time:21604.758106708527
batch reward last col mean 0.09859278053045273 first col mean 0.1307324320077896 all mean 0.10073362290859222
0.25857535004615784 0.25857535004615784
rl training, epoch6, iter0, batch1032/1133, batch loss:0.25857535004615784, Training time:21607.04082775116
batch reward last col mean 0.10220885276794434 first col mean 0.11939706653356552 all mean 0.10305829346179962
0.264533132314682 0.264533132314682
rl training, epoch6, iter0, batch1033/1133, batch loss:0.264533132314682, Training time:21608.719177007675
batch reward last col mean 0.09754893183708191 first col mean 0.10915147513151169 all mean 0.10182972252368927
0.2823459804058075 0.2823459506034851
rl training, epoch6, iter0, batch1034/1133, batch loss:0.2823459506034851, Training time:21610.642810344696
batch reward last col mean 0.09265698492527008 first col mean 0.10770344734191895 all mean 0.09682519733905792
0.2794891893863678 0.2794891893863678
rl training, epoch6, iter0, batch1035/1133, batch loss:0.2794891893863678, Training time:21612.323629140854
batch reward last col mean 0.11895500123500824 first col mean 0.11462637782096863 all mean 0.11091362684965134
0.2813703119754791 0.2813703119754791
rl training, epoch6, iter0, batch1036/1133, batch loss:0.2813703119754791, Training time:21613.990016698837
batch reward last col mean 0.12502585351467133 first col mean 0.10275798290967941 all mean 0.12455558031797409
0.2935921847820282 0.2935922145843506
rl training, epoch6, iter0, batch1037/1133, batch loss:0.2935922145843506, Training time:21615.98409962654
batch reward last col mean 0.12513534724712372 first col mean 0.10393448173999786 all mean 0.11968386918306351
0.31095850467681885 0.31095850467681885
rl training, epoch6, iter0, batch1038/1133, batch loss:0.31095850467681885, Training time:21617.93668103218
batch reward last col mean 0.09347929060459137 first col mean 0.102145716547966 all mean 0.09824246913194656
0.2564869225025177 0.2564869225025177
rl training, epoch6, iter0, batch1039/1133, batch loss:0.2564869225025177, Training time:21620.001373052597
batch reward last col mean 0.07069490104913712 first col mean 0.11032219231128693 all mean 0.083690345287323
0.2739650309085846 0.2739650309085846
rl training, epoch6, iter0, batch1040/1133, batch loss:0.2739650309085846, Training time:21621.820918560028
batch reward last col mean 0.1087767481803894 first col mean 0.1021449938416481 all mean 0.10430948436260223
0.2614513039588928 0.2614513039588928
rl training, epoch6, iter0, batch1041/1133, batch loss:0.2614513039588928, Training time:21623.71612262726
batch reward last col mean 0.12913638353347778 first col mean 0.12043070048093796 all mean 0.11679170280694962
0.30470210313796997 0.3047020733356476
rl training, epoch6, iter0, batch1042/1133, batch loss:0.3047020733356476, Training time:21625.35161781311
batch reward last col mean 0.08283750712871552 first col mean 0.09301431477069855 all mean 0.09485238045454025
0.30427518486976624 0.30427518486976624
rl training, epoch6, iter0, batch1043/1133, batch loss:0.30427518486976624, Training time:21627.14761853218
batch reward last col mean 0.1029789075255394 first col mean 0.12104816734790802 all mean 0.10486078262329102
0.2639591097831726 0.2639590799808502
rl training, epoch6, iter0, batch1044/1133, batch loss:0.2639590799808502, Training time:21629.13387107849
batch reward last col mean 0.0644569844007492 first col mean 0.11480613797903061 all mean 0.0790429338812828
0.2402915209531784 0.2402915209531784
rl training, epoch6, iter0, batch1045/1133, batch loss:0.2402915209531784, Training time:21630.83834028244
batch reward last col mean 0.07769814133644104 first col mean 0.11682727932929993 all mean 0.0852920189499855
0.28819459676742554 0.28819459676742554
rl training, epoch6, iter0, batch1046/1133, batch loss:0.28819459676742554, Training time:21632.662328243256
batch reward last col mean 0.10426709055900574 first col mean 0.0857454314827919 all mean 0.10505972802639008
0.2716309428215027 0.2716309428215027
rl training, epoch6, iter0, batch1047/1133, batch loss:0.2716309428215027, Training time:21634.29320716858
batch reward last col mean 0.1062103733420372 first col mean 0.10243235528469086 all mean 0.10960596799850464
0.2774295508861542 0.2774295508861542
rl training, epoch6, iter0, batch1048/1133, batch loss:0.2774295508861542, Training time:21636.013909578323
batch reward last col mean 0.09437225013971329 first col mean 0.10988573729991913 all mean 0.09679155051708221
0.3025660216808319 0.3025660216808319
rl training, epoch6, iter0, batch1049/1133, batch loss:0.3025660216808319, Training time:21637.729365825653
batch reward last col mean 0.09385904669761658 first col mean 0.11615192890167236 all mean 0.09503405541181564
0.28037208318710327 0.28037208318710327
rl training, epoch6, iter0, batch1050/1133, batch loss:0.28037208318710327, Training time:21639.680931806564
batch reward last col mean 0.09899504482746124 first col mean 0.0904887318611145 all mean 0.10017502307891846
0.27872905135154724 0.27872905135154724
rl training, epoch6, iter0, batch1051/1133, batch loss:0.27872905135154724, Training time:21641.53825354576
batch reward last col mean 0.10655102133750916 first col mean 0.11790940910577774 all mean 0.10613925755023956
0.31127819418907166 0.31127816438674927
rl training, epoch6, iter0, batch1052/1133, batch loss:0.31127816438674927, Training time:21643.34726023674
batch reward last col mean 0.11436354368925095 first col mean 0.10395660996437073 all mean 0.11945535987615585
0.32633593678474426 0.32633593678474426
rl training, epoch6, iter0, batch1053/1133, batch loss:0.32633593678474426, Training time:21645.999308347702
batch reward last col mean 0.08317989110946655 first col mean 0.11259300261735916 all mean 0.09045825898647308
0.2727683186531067 0.2727683186531067
rl training, epoch6, iter0, batch1054/1133, batch loss:0.2727683186531067, Training time:21648.268771648407
batch reward last col mean 0.07647423446178436 first col mean 0.08816986531019211 all mean 0.08578624576330185
0.2715167999267578 0.2715167701244354
rl training, epoch6, iter0, batch1055/1133, batch loss:0.2715167701244354, Training time:21649.956236839294
batch reward last col mean 0.09356636554002762 first col mean 0.10407502949237823 all mean 0.09889394044876099
0.27075815200805664 0.27075815200805664
rl training, epoch6, iter0, batch1056/1133, batch loss:0.27075815200805664, Training time:21651.83667588234
batch reward last col mean 0.08214197307825089 first col mean 0.1177644357085228 all mean 0.09295157343149185
0.27705222368240356 0.27705222368240356
rl training, epoch6, iter0, batch1057/1133, batch loss:0.27705222368240356, Training time:21653.692535877228
batch reward last col mean 0.06598309427499771 first col mean 0.10449247807264328 all mean 0.07885114848613739
0.26810452342033386 0.26810452342033386
rl training, epoch6, iter0, batch1058/1133, batch loss:0.26810452342033386, Training time:21655.815060853958
batch reward last col mean 0.12147615849971771 first col mean 0.1039239764213562 all mean 0.11435026675462723
0.2734771966934204 0.2734771966934204
rl training, epoch6, iter0, batch1059/1133, batch loss:0.2734771966934204, Training time:21657.70482635498
batch reward last col mean 0.09825011342763901 first col mean 0.08803164958953857 all mean 0.10189569741487503
0.3037562072277069 0.3037562072277069
rl training, epoch6, iter0, batch1060/1133, batch loss:0.3037562072277069, Training time:21659.703022003174
batch reward last col mean 0.1083838939666748 first col mean 0.0938628762960434 all mean 0.11040812730789185
0.3141497075557709 0.3141496479511261
rl training, epoch6, iter0, batch1061/1133, batch loss:0.3141496479511261, Training time:21661.4821600914
batch reward last col mean 0.09043408930301666 first col mean 0.12614436447620392 all mean 0.09407316148281097
0.2676476836204529 0.2676476836204529
rl training, epoch6, iter0, batch1062/1133, batch loss:0.2676476836204529, Training time:21663.23969888687
batch reward last col mean 0.11136497557163239 first col mean 0.10108846426010132 all mean 0.10988835990428925
0.2728438973426819 0.2728438675403595
rl training, epoch6, iter0, batch1063/1133, batch loss:0.2728438675403595, Training time:21665.356995105743
batch reward last col mean 0.08851916342973709 first col mean 0.09225617349147797 all mean 0.09963132441043854
0.30432844161987305 0.30432844161987305
rl training, epoch6, iter0, batch1064/1133, batch loss:0.30432844161987305, Training time:21666.918446302414
batch reward last col mean 0.08987343311309814 first col mean 0.10355772078037262 all mean 0.09571155905723572
0.27153608202934265 0.27153608202934265
rl training, epoch6, iter0, batch1065/1133, batch loss:0.27153608202934265, Training time:21669.51167178154
batch reward last col mean 0.1260807365179062 first col mean 0.1000290960073471 all mean 0.1175733208656311
0.31321844458580017 0.31321844458580017
rl training, epoch6, iter0, batch1066/1133, batch loss:0.31321844458580017, Training time:21672.517642498016
batch reward last col mean 0.13494856655597687 first col mean 0.11529843509197235 all mean 0.12419627606868744
0.2712884843349457 0.2712884843349457
rl training, epoch6, iter0, batch1067/1133, batch loss:0.2712884843349457, Training time:21674.01981472969
batch reward last col mean 0.10008437931537628 first col mean 0.11344830691814423 all mean 0.11243505775928497
0.3086707890033722 0.3086707890033722
rl training, epoch6, iter0, batch1068/1133, batch loss:0.3086707890033722, Training time:21675.869036197662
batch reward last col mean 0.09898151457309723 first col mean 0.1078324243426323 all mean 0.10251738876104355
0.24802736937999725 0.24802736937999725
rl training, epoch6, iter0, batch1069/1133, batch loss:0.24802736937999725, Training time:21677.554107904434
batch reward last col mean 0.11032960563898087 first col mean 0.12619024515151978 all mean 0.1145663931965828
0.28237485885620117 0.28237485885620117
rl training, epoch6, iter0, batch1070/1133, batch loss:0.28237485885620117, Training time:21680.13428735733
batch reward last col mean 0.08953786641359329 first col mean 0.11003845185041428 all mean 0.09762679040431976
0.258676677942276 0.258676677942276
rl training, epoch6, iter0, batch1071/1133, batch loss:0.258676677942276, Training time:21682.020916461945
batch reward last col mean 0.10837714374065399 first col mean 0.09533697366714478 all mean 0.10899315774440765
0.2630215287208557 0.2630215287208557
rl training, epoch6, iter0, batch1072/1133, batch loss:0.2630215287208557, Training time:21683.804862737656
batch reward last col mean 0.10198456794023514 first col mean 0.11596411466598511 all mean 0.10153133422136307
0.28596216440200806 0.28596216440200806
rl training, epoch6, iter0, batch1073/1133, batch loss:0.28596216440200806, Training time:21685.761315584183
batch reward last col mean 0.11342601478099823 first col mean 0.12975963950157166 all mean 0.1023615300655365
0.24337805807590485 0.24337805807590485
rl training, epoch6, iter0, batch1074/1133, batch loss:0.24337805807590485, Training time:21687.962751865387
batch reward last col mean 0.14090925455093384 first col mean 0.09857486933469772 all mean 0.13051488995552063
0.2953261733055115 0.2953261733055115
rl training, epoch6, iter0, batch1075/1133, batch loss:0.2953261733055115, Training time:21689.65091252327
batch reward last col mean 0.1053040474653244 first col mean 0.12053251266479492 all mean 0.106196328997612
0.3314385414123535 0.3314385414123535
rl training, epoch6, iter0, batch1076/1133, batch loss:0.3314385414123535, Training time:21692.331934452057
batch reward last col mean 0.10792180895805359 first col mean 0.10359750688076019 all mean 0.10376967489719391
0.2473975419998169 0.2473975419998169
rl training, epoch6, iter0, batch1077/1133, batch loss:0.2473975419998169, Training time:21694.6138985157
batch reward last col mean 0.09776829928159714 first col mean 0.11622680723667145 all mean 0.0983353927731514
0.28935718536376953 0.28935715556144714
rl training, epoch6, iter0, batch1078/1133, batch loss:0.28935715556144714, Training time:21696.65292596817
batch reward last col mean 0.09420592337846756 first col mean 0.09621451050043106 all mean 0.09892489016056061
0.27571576833724976 0.27571576833724976
rl training, epoch6, iter0, batch1079/1133, batch loss:0.27571576833724976, Training time:21698.549163341522
batch reward last col mean 0.09439310431480408 first col mean 0.09454860538244247 all mean 0.10065726935863495
0.24042478203773499 0.2404247671365738
rl training, epoch6, iter0, batch1080/1133, batch loss:0.2404247671365738, Training time:21700.833300590515
batch reward last col mean 0.09453641623258591 first col mean 0.11095605045557022 all mean 0.10323610156774521
0.287241667509079 0.287241667509079
rl training, epoch6, iter0, batch1081/1133, batch loss:0.287241667509079, Training time:21703.149765253067
batch reward last col mean 0.09047971665859222 first col mean 0.11715774238109589 all mean 0.0940706878900528
0.28140607476234436 0.28140607476234436
rl training, epoch6, iter0, batch1082/1133, batch loss:0.28140607476234436, Training time:21705.52538394928
batch reward last col mean 0.09779936820268631 first col mean 0.11726940423250198 all mean 0.09382125735282898
0.28668463230133057 0.2866846024990082
rl training, epoch6, iter0, batch1083/1133, batch loss:0.2866846024990082, Training time:21707.36347055435
batch reward last col mean 0.10069607198238373 first col mean 0.10508839786052704 all mean 0.1055339127779007
0.27544501423835754 0.27544501423835754
rl training, epoch6, iter0, batch1084/1133, batch loss:0.27544501423835754, Training time:21709.07228565216
batch reward last col mean 0.10615042597055435 first col mean 0.10220558941364288 all mean 0.10366391390562057
0.2402617186307907 0.2402617186307907
rl training, epoch6, iter0, batch1085/1133, batch loss:0.2402617186307907, Training time:21710.622314453125
batch reward last col mean 0.12020634114742279 first col mean 0.12424535304307938 all mean 0.11844633519649506
0.31351161003112793 0.31351161003112793
rl training, epoch6, iter0, batch1086/1133, batch loss:0.31351161003112793, Training time:21712.51856136322
batch reward last col mean 0.07003936916589737 first col mean 0.12956880033016205 all mean 0.07871267199516296
0.2544180452823639 0.2544180452823639
rl training, epoch6, iter0, batch1087/1133, batch loss:0.2544180452823639, Training time:21714.664603710175
batch reward last col mean 0.12163437902927399 first col mean 0.10272818058729172 all mean 0.11682561039924622
0.3203740417957306 0.3203740417957306
rl training, epoch6, iter0, batch1088/1133, batch loss:0.3203740417957306, Training time:21716.811193704605
batch reward last col mean 0.09596633166074753 first col mean 0.1257030963897705 all mean 0.10321701318025589
0.26129797101020813 0.26129794120788574
rl training, epoch6, iter0, batch1089/1133, batch loss:0.26129794120788574, Training time:21718.52108860016
batch reward last col mean 0.0961715430021286 first col mean 0.11661668121814728 all mean 0.09817598015069962
0.2740866243839264 0.2740866243839264
rl training, epoch6, iter0, batch1090/1133, batch loss:0.2740866243839264, Training time:21720.540339946747
batch reward last col mean 0.12520478665828705 first col mean 0.10559850186109543 all mean 0.11774957180023193
0.2906074523925781 0.2906074523925781
rl training, epoch6, iter0, batch1091/1133, batch loss:0.2906074523925781, Training time:21722.59677219391
batch reward last col mean 0.1293237805366516 first col mean 0.10501578450202942 all mean 0.12188085913658142
0.28319886326789856 0.28319886326789856
rl training, epoch6, iter0, batch1092/1133, batch loss:0.28319886326789856, Training time:21725.608835697174
batch reward last col mean 0.09896935522556305 first col mean 0.10570023208856583 all mean 0.09990505874156952
0.27098599076271057 0.27098599076271057
rl training, epoch6, iter0, batch1093/1133, batch loss:0.27098599076271057, Training time:21729.141565561295
batch reward last col mean 0.12409473955631256 first col mean 0.10335864126682281 all mean 0.12140101194381714
0.3333790898323059 0.3333790600299835
rl training, epoch6, iter0, batch1094/1133, batch loss:0.3333790600299835, Training time:21730.945720911026
batch reward last col mean 0.09370922297239304 first col mean 0.10020752251148224 all mean 0.09395020455121994
0.24187028408050537 0.24187028408050537
rl training, epoch6, iter0, batch1095/1133, batch loss:0.24187028408050537, Training time:21733.312299489975
batch reward last col mean 0.0970265194773674 first col mean 0.12306202948093414 all mean 0.10300274193286896
0.2962425947189331 0.2962425947189331
rl training, epoch6, iter0, batch1096/1133, batch loss:0.2962425947189331, Training time:21735.071197986603
batch reward last col mean 0.09971623867750168 first col mean 0.12243686616420746 all mean 0.1032257229089737
0.2877894937992096 0.2877894639968872
rl training, epoch6, iter0, batch1097/1133, batch loss:0.2877894639968872, Training time:21737.512706041336
batch reward last col mean 0.10391134023666382 first col mean 0.10102567821741104 all mean 0.10446126759052277
0.26636144518852234 0.26636144518852234
rl training, epoch6, iter0, batch1098/1133, batch loss:0.26636144518852234, Training time:21739.562458992004
batch reward last col mean 0.1041933000087738 first col mean 0.11624914407730103 all mean 0.1041654646396637
0.28382378816604614 0.28382375836372375
rl training, epoch6, iter0, batch1099/1133, batch loss:0.28382375836372375, Training time:21741.41771531105
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.481518821072389 Time: 95.32750034332275 s
loss of true 0.2092728345586679 loss of gen 0.1730595660204395 loss of other 0.0991864209897678 first score 0.09874264895915985
batch reward last col mean 0.09283489733934402 first col mean 0.09274349361658096 all mean 0.09596148878335953
0.30540838837623596 0.30540838837623596
rl training, epoch6, iter0, batch1100/1133, batch loss:0.30540838837623596, Training time:21838.80869936943
batch reward last col mean 0.05494663491845131 first col mean 0.11033626645803452 all mean 0.06638237833976746
0.20911921560764313 0.20911921560764313
rl training, epoch6, iter0, batch1101/1133, batch loss:0.20911921560764313, Training time:21840.935898542404
batch reward last col mean 0.08885762095451355 first col mean 0.10238634049892426 all mean 0.09297902882099152
0.2528650760650635 0.2528650760650635
rl training, epoch6, iter0, batch1102/1133, batch loss:0.2528650760650635, Training time:21842.66071176529
batch reward last col mean 0.08404042571783066 first col mean 0.09448658674955368 all mean 0.08844328671693802
0.24083004891872406 0.24083004891872406
rl training, epoch6, iter0, batch1103/1133, batch loss:0.24083004891872406, Training time:21844.495639562607
batch reward last col mean 0.08881928026676178 first col mean 0.10683126747608185 all mean 0.09664125740528107
0.2683313488960266 0.2683313488960266
rl training, epoch6, iter0, batch1104/1133, batch loss:0.2683313488960266, Training time:21846.49508523941
batch reward last col mean 0.13433575630187988 first col mean 0.08313415944576263 all mean 0.11556405574083328
0.290144681930542 0.290144681930542
rl training, epoch6, iter0, batch1105/1133, batch loss:0.290144681930542, Training time:21848.54756784439
batch reward last col mean 0.08654852211475372 first col mean 0.1017395406961441 all mean 0.08763957023620605
0.22003096342086792 0.22003096342086792
rl training, epoch6, iter0, batch1106/1133, batch loss:0.22003096342086792, Training time:21850.94046473503
batch reward last col mean 0.13653527200222015 first col mean 0.0890900045633316 all mean 0.12565281987190247
0.3098717927932739 0.3098717927932739
rl training, epoch6, iter0, batch1107/1133, batch loss:0.3098717927932739, Training time:21853.151791095734
batch reward last col mean 0.08592107146978378 first col mean 0.08747558295726776 all mean 0.08741065114736557
0.24464558064937592 0.24464558064937592
rl training, epoch6, iter0, batch1108/1133, batch loss:0.24464558064937592, Training time:21855.543221473694
batch reward last col mean 0.07882896810770035 first col mean 0.10306605696678162 all mean 0.08721151947975159
0.26102203130722046 0.26102203130722046
rl training, epoch6, iter0, batch1109/1133, batch loss:0.26102203130722046, Training time:21857.281542539597
batch reward last col mean 0.09678943455219269 first col mean 0.10911121964454651 all mean 0.1013299897313118
0.2788751423358917 0.2788751423358917
rl training, epoch6, iter0, batch1110/1133, batch loss:0.2788751423358917, Training time:21859.34827685356
batch reward last col mean 0.08554819971323013 first col mean 0.08238299936056137 all mean 0.08826621621847153
0.22525474429130554 0.22525474429130554
rl training, epoch6, iter0, batch1111/1133, batch loss:0.22525474429130554, Training time:21861.343594789505
batch reward last col mean 0.10837145149707794 first col mean 0.10897309333086014 all mean 0.10150781273841858
0.28902560472488403 0.28902560472488403
rl training, epoch6, iter0, batch1112/1133, batch loss:0.28902560472488403, Training time:21863.66760802269
batch reward last col mean 0.09636389464139938 first col mean 0.10438058525323868 all mean 0.09769562631845474
0.29209914803504944 0.29209914803504944
rl training, epoch6, iter0, batch1113/1133, batch loss:0.29209914803504944, Training time:21865.468027591705
batch reward last col mean 0.08155183494091034 first col mean 0.09499050676822662 all mean 0.08955295383930206
0.269614040851593 0.26961401104927063
rl training, epoch6, iter0, batch1114/1133, batch loss:0.26961401104927063, Training time:21867.430722236633
batch reward last col mean 0.09090904146432877 first col mean 0.09708837419748306 all mean 0.09656425565481186
0.2546658515930176 0.2546658515930176
rl training, epoch6, iter0, batch1115/1133, batch loss:0.2546658515930176, Training time:21869.034857988358
batch reward last col mean 0.09330864250659943 first col mean 0.11097022891044617 all mean 0.0971251055598259
0.25346216559410095 0.25346216559410095
rl training, epoch6, iter0, batch1116/1133, batch loss:0.25346216559410095, Training time:21870.91122698784
batch reward last col mean 0.07556465268135071 first col mean 0.11442261934280396 all mean 0.09093707799911499
0.2636280357837677 0.2636280357837677
rl training, epoch6, iter0, batch1117/1133, batch loss:0.2636280357837677, Training time:21872.541640758514
batch reward last col mean 0.0848848819732666 first col mean 0.09338685870170593 all mean 0.09315060079097748
0.2170678675174713 0.2170678675174713
rl training, epoch6, iter0, batch1118/1133, batch loss:0.2170678675174713, Training time:21874.21560025215
batch reward last col mean 0.1292310655117035 first col mean 0.1029076799750328 all mean 0.11756173521280289
0.2808038294315338 0.2808038294315338
rl training, epoch6, iter0, batch1119/1133, batch loss:0.2808038294315338, Training time:21875.902450799942
batch reward last col mean 0.08279132843017578 first col mean 0.1025664210319519 all mean 0.08874895423650742
0.2597164809703827 0.2597164809703827
rl training, epoch6, iter0, batch1120/1133, batch loss:0.2597164809703827, Training time:21878.736649751663
batch reward last col mean 0.08444034308195114 first col mean 0.10520462691783905 all mean 0.0925149917602539
0.24126608669757843 0.24126608669757843
rl training, epoch6, iter0, batch1121/1133, batch loss:0.24126608669757843, Training time:21880.68384695053
batch reward last col mean 0.12569399178028107 first col mean 0.10906505584716797 all mean 0.11591731011867523
0.2558000981807709 0.2558000981807709
rl training, epoch6, iter0, batch1122/1133, batch loss:0.2558000981807709, Training time:21882.789331436157
batch reward last col mean 0.09843762218952179 first col mean 0.11237601935863495 all mean 0.1031455472111702
0.25367188453674316 0.25367188453674316
rl training, epoch6, iter0, batch1123/1133, batch loss:0.25367188453674316, Training time:21884.570393562317
batch reward last col mean 0.08286209404468536 first col mean 0.09725210815668106 all mean 0.08972134441137314
0.23479077219963074 0.23479077219963074
rl training, epoch6, iter0, batch1124/1133, batch loss:0.23479077219963074, Training time:21886.0782392025
batch reward last col mean 0.127280130982399 first col mean 0.10873863101005554 all mean 0.11771784722805023
0.26567426323890686 0.26567426323890686
rl training, epoch6, iter0, batch1125/1133, batch loss:0.26567426323890686, Training time:21887.93364548683
batch reward last col mean 0.10431249439716339 first col mean 0.09389159828424454 all mean 0.10021208226680756
0.24272455275058746 0.24272455275058746
rl training, epoch6, iter0, batch1126/1133, batch loss:0.24272455275058746, Training time:21889.666283130646
batch reward last col mean 0.09443864226341248 first col mean 0.12136844545602798 all mean 0.09785115718841553
0.2895461618900299 0.2895461618900299
rl training, epoch6, iter0, batch1127/1133, batch loss:0.2895461618900299, Training time:21891.452855587006
batch reward last col mean 0.08809036016464233 first col mean 0.10432121902704239 all mean 0.09288229048252106
0.234341099858284 0.234341099858284
rl training, epoch6, iter0, batch1128/1133, batch loss:0.234341099858284, Training time:21893.27059364319
batch reward last col mean 0.08415355533361435 first col mean 0.11041676253080368 all mean 0.08867106586694717
0.25825172662734985 0.25825172662734985
rl training, epoch6, iter0, batch1129/1133, batch loss:0.25825172662734985, Training time:21895.084208726883
batch reward last col mean 0.10649248212575912 first col mean 0.09041749686002731 all mean 0.10307376831769943
0.2734760046005249 0.2734760344028473
rl training, epoch6, iter0, batch1130/1133, batch loss:0.2734760344028473, Training time:21897.10476732254
batch reward last col mean 0.0932612419128418 first col mean 0.10528775304555893 all mean 0.09667890518903732
0.27140215039253235 0.27140215039253235
rl training, epoch6, iter0, batch1131/1133, batch loss:0.27140215039253235, Training time:21898.78107690811
batch reward last col mean 0.09429921954870224 first col mean 0.1096552386879921 all mean 0.09073801338672638
0.25939100980758667 0.2593909800052643
rl training, epoch6, iter0, batch1132/1133, batch loss:0.2593909800052643, Training time:21900.74894142151
rl training, epoch 6, iter 0, loss:0.279702378445143, Training time:21900.74916577339 
rl epoch 6, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.9963157296917236 Time: 132.2456920146942 s
rl epoch 6, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46069355625971586 Time: 96.1709794998169 s
loss of true 0.1973394937254324 loss of gen 0.16536897133184236 loss of other 0.09798509119422112 first score 0.08758687973022461
rl epoch 7, begin RL for generator...
batch reward last col mean 0.042470552027225494 first col mean 0.09600736945867538 all mean 0.056533873081207275
0.2286258190870285 0.2286258190870285
rl training, epoch7, iter0, batch0/1133, batch loss:0.2286258190870285, Training time:22131.396594762802
batch reward last col mean 0.10592745244503021 first col mean 0.10427072644233704 all mean 0.10764211416244507
0.2907731533050537 0.2907731533050537
rl training, epoch7, iter0, batch1/1133, batch loss:0.2907731533050537, Training time:22133.689416885376
batch reward last col mean 0.09003687649965286 first col mean 0.08980614691972733 all mean 0.08869954943656921
0.2515929341316223 0.2515929341316223
rl training, epoch7, iter0, batch2/1133, batch loss:0.2515929341316223, Training time:22136.202845811844
batch reward last col mean 0.10935728251934052 first col mean 0.09971734136343002 all mean 0.10485180467367172
0.31134068965911865 0.31134068965911865
rl training, epoch7, iter0, batch3/1133, batch loss:0.31134068965911865, Training time:22138.681934595108
batch reward last col mean 0.08026348799467087 first col mean 0.10631708800792694 all mean 0.08702975511550903
0.24784281849861145 0.24784278869628906
rl training, epoch7, iter0, batch4/1133, batch loss:0.24784278869628906, Training time:22140.64983344078
batch reward last col mean 0.09548914432525635 first col mean 0.10372138023376465 all mean 0.10224743187427521
0.29191794991493225 0.29191794991493225
rl training, epoch7, iter0, batch5/1133, batch loss:0.29191794991493225, Training time:22142.443076610565
batch reward last col mean 0.08198128640651703 first col mean 0.09334732592105865 all mean 0.08730193227529526
0.2281128466129303 0.2281128466129303
rl training, epoch7, iter0, batch6/1133, batch loss:0.2281128466129303, Training time:22144.464346408844
batch reward last col mean 0.07446612417697906 first col mean 0.10208253562450409 all mean 0.08107994496822357
0.2500729262828827 0.2500729262828827
rl training, epoch7, iter0, batch7/1133, batch loss:0.2500729262828827, Training time:22146.429040670395
batch reward last col mean 0.09134386479854584 first col mean 0.08373679220676422 all mean 0.09654399007558823
0.26938188076019287 0.26938188076019287
rl training, epoch7, iter0, batch8/1133, batch loss:0.26938188076019287, Training time:22148.67088651657
batch reward last col mean 0.0862504094839096 first col mean 0.08851732313632965 all mean 0.08821510523557663
0.2630833685398102 0.2630833685398102
rl training, epoch7, iter0, batch9/1133, batch loss:0.2630833685398102, Training time:22150.739395856857
batch reward last col mean 0.11922549456357956 first col mean 0.09535089135169983 all mean 0.109965980052948
0.27232682704925537 0.27232682704925537
rl training, epoch7, iter0, batch10/1133, batch loss:0.27232682704925537, Training time:22152.95679616928
batch reward last col mean 0.08880259841680527 first col mean 0.10937412828207016 all mean 0.09307456761598587
0.28178611397743225 0.28178611397743225
rl training, epoch7, iter0, batch11/1133, batch loss:0.28178611397743225, Training time:22155.441944122314
batch reward last col mean 0.08518903702497482 first col mean 0.11132892966270447 all mean 0.08634471148252487
0.25947487354278564 0.25947490334510803
rl training, epoch7, iter0, batch12/1133, batch loss:0.25947490334510803, Training time:22157.793406248093
batch reward last col mean 0.085105761885643 first col mean 0.09479503333568573 all mean 0.08867857605218887
0.24392403662204742 0.24392403662204742
rl training, epoch7, iter0, batch13/1133, batch loss:0.24392403662204742, Training time:22160.031413316727
batch reward last col mean 0.08916272222995758 first col mean 0.09376857429742813 all mean 0.09363504499197006
0.30237501859664917 0.30237501859664917
rl training, epoch7, iter0, batch14/1133, batch loss:0.30237501859664917, Training time:22162.714232444763
batch reward last col mean 0.0806971937417984 first col mean 0.11197499930858612 all mean 0.08679503202438354
0.23342305421829224 0.23342305421829224
rl training, epoch7, iter0, batch15/1133, batch loss:0.23342305421829224, Training time:22164.92691874504
batch reward last col mean 0.07925887405872345 first col mean 0.09884993731975555 all mean 0.08147767931222916
0.241624653339386 0.2416246384382248
rl training, epoch7, iter0, batch16/1133, batch loss:0.2416246384382248, Training time:22167.14817428589
batch reward last col mean 0.10134191811084747 first col mean 0.09449440240859985 all mean 0.10086558014154434
0.2683011591434479 0.2683011591434479
rl training, epoch7, iter0, batch17/1133, batch loss:0.2683011591434479, Training time:22169.459716320038
batch reward last col mean 0.08636870980262756 first col mean 0.10017970204353333 all mean 0.08914665132761002
0.2785983979701996 0.2785983979701996
rl training, epoch7, iter0, batch18/1133, batch loss:0.2785983979701996, Training time:22171.204685926437
batch reward last col mean 0.11775055527687073 first col mean 0.10106556862592697 all mean 0.1060643345117569
0.28226450085639954 0.28226450085639954
rl training, epoch7, iter0, batch19/1133, batch loss:0.28226450085639954, Training time:22173.491358280182
batch reward last col mean 0.07963403314352036 first col mean 0.09759295731782913 all mean 0.08693666011095047
0.27169668674468994 0.27169668674468994
rl training, epoch7, iter0, batch20/1133, batch loss:0.27169668674468994, Training time:22175.27619433403
batch reward last col mean 0.07997434586286545 first col mean 0.11368218809366226 all mean 0.08579903095960617
0.24846695363521576 0.24846695363521576
rl training, epoch7, iter0, batch21/1133, batch loss:0.24846695363521576, Training time:22178.00817513466
batch reward last col mean 0.09496905654668808 first col mean 0.08342082053422928 all mean 0.093348927795887
0.23483915627002716 0.23483914136886597
rl training, epoch7, iter0, batch22/1133, batch loss:0.23483914136886597, Training time:22181.341381311417
batch reward last col mean 0.08919540047645569 first col mean 0.09095856547355652 all mean 0.09147469699382782
0.26814281940460205 0.26814281940460205
rl training, epoch7, iter0, batch23/1133, batch loss:0.26814281940460205, Training time:22183.515827417374
batch reward last col mean 0.10973764210939407 first col mean 0.10987736284732819 all mean 0.11065655946731567
0.26276838779449463 0.26276838779449463
rl training, epoch7, iter0, batch24/1133, batch loss:0.26276838779449463, Training time:22185.446888446808
batch reward last col mean 0.09918960928916931 first col mean 0.09810309112071991 all mean 0.10158200562000275
0.27857130765914917 0.27857130765914917
rl training, epoch7, iter0, batch25/1133, batch loss:0.27857130765914917, Training time:22187.247171878815
batch reward last col mean 0.06354473531246185 first col mean 0.0948624536395073 all mean 0.06560272723436356
0.23140232264995575 0.23140230774879456
rl training, epoch7, iter0, batch26/1133, batch loss:0.23140230774879456, Training time:22189.43998527527
batch reward last col mean 0.1064627468585968 first col mean 0.10585974901914597 all mean 0.1048981323838234
0.23616351187229156 0.23616349697113037
rl training, epoch7, iter0, batch27/1133, batch loss:0.23616349697113037, Training time:22191.708153247833
batch reward last col mean 0.09861619025468826 first col mean 0.1213427484035492 all mean 0.10512107610702515
0.2716614007949829 0.2716614007949829
rl training, epoch7, iter0, batch28/1133, batch loss:0.2716614007949829, Training time:22193.797565937042
batch reward last col mean 0.06947486102581024 first col mean 0.103416308760643 all mean 0.07449666410684586
0.23884057998657227 0.23884059488773346
rl training, epoch7, iter0, batch29/1133, batch loss:0.23884059488773346, Training time:22195.909343004227
batch reward last col mean 0.07586846500635147 first col mean 0.09036605805158615 all mean 0.08201011270284653
0.2639065086841583 0.2639065086841583
rl training, epoch7, iter0, batch30/1133, batch loss:0.2639065086841583, Training time:22197.795249462128
batch reward last col mean 0.09220137447118759 first col mean 0.08451808989048004 all mean 0.09296894073486328
0.25490233302116394 0.25490233302116394
rl training, epoch7, iter0, batch31/1133, batch loss:0.25490233302116394, Training time:22200.534687519073
batch reward last col mean 0.1053173840045929 first col mean 0.10286375135183334 all mean 0.10355377197265625
0.29364725947380066 0.29364728927612305
rl training, epoch7, iter0, batch32/1133, batch loss:0.29364728927612305, Training time:22202.68470454216
batch reward last col mean 0.10057951509952545 first col mean 0.10224109143018723 all mean 0.09988369792699814
0.3080357611179352 0.3080357611179352
rl training, epoch7, iter0, batch33/1133, batch loss:0.3080357611179352, Training time:22204.912620544434
batch reward last col mean 0.1121007651090622 first col mean 0.10094599425792694 all mean 0.1053658202290535
0.28513678908348083 0.28513678908348083
rl training, epoch7, iter0, batch34/1133, batch loss:0.28513678908348083, Training time:22207.13272380829
batch reward last col mean 0.0982673168182373 first col mean 0.09445931762456894 all mean 0.09839577972888947
0.2687614858150482 0.2687614858150482
rl training, epoch7, iter0, batch35/1133, batch loss:0.2687614858150482, Training time:22209.421167373657
batch reward last col mean 0.09165804088115692 first col mean 0.09738580882549286 all mean 0.09359133988618851
0.2342037409543991 0.23420372605323792
rl training, epoch7, iter0, batch36/1133, batch loss:0.23420372605323792, Training time:22211.562388896942
batch reward last col mean 0.09081663936376572 first col mean 0.0984116643667221 all mean 0.08781453967094421
0.27100735902786255 0.27100735902786255
rl training, epoch7, iter0, batch37/1133, batch loss:0.27100735902786255, Training time:22213.195724725723
batch reward last col mean 0.06357074528932571 first col mean 0.08787272870540619 all mean 0.07139287143945694
0.24528393149375916 0.24528393149375916
rl training, epoch7, iter0, batch38/1133, batch loss:0.24528393149375916, Training time:22215.434985637665
batch reward last col mean 0.08624199032783508 first col mean 0.10130217671394348 all mean 0.09119945019483566
0.2572549283504486 0.2572549283504486
rl training, epoch7, iter0, batch39/1133, batch loss:0.2572549283504486, Training time:22217.111460208893
batch reward last col mean 0.05568958446383476 first col mean 0.10037574917078018 all mean 0.0697173997759819
0.24559961259365082 0.24559958279132843
rl training, epoch7, iter0, batch40/1133, batch loss:0.24559958279132843, Training time:22219.444563150406
batch reward last col mean 0.08770501613616943 first col mean 0.10425601899623871 all mean 0.08628873527050018
0.28682389855384827 0.28682389855384827
rl training, epoch7, iter0, batch41/1133, batch loss:0.28682389855384827, Training time:22222.413509845734
batch reward last col mean 0.09541118890047073 first col mean 0.09101735055446625 all mean 0.0929844081401825
0.3072238564491272 0.3072238564491272
rl training, epoch7, iter0, batch42/1133, batch loss:0.3072238564491272, Training time:22225.77355480194
batch reward last col mean 0.10435701161623001 first col mean 0.10460612177848816 all mean 0.1039159744977951
0.26612451672554016 0.2661244869232178
rl training, epoch7, iter0, batch43/1133, batch loss:0.2661244869232178, Training time:22228.215887784958
batch reward last col mean 0.07310415804386139 first col mean 0.10200950503349304 all mean 0.07879281044006348
0.22371070086956024 0.22371070086956024
rl training, epoch7, iter0, batch44/1133, batch loss:0.22371070086956024, Training time:22230.607080698013
batch reward last col mean 0.11033914983272552 first col mean 0.1135973334312439 all mean 0.1094207763671875
0.3008633255958557 0.3008633852005005
rl training, epoch7, iter0, batch45/1133, batch loss:0.3008633852005005, Training time:22233.313381671906
batch reward last col mean 0.08001922070980072 first col mean 0.10620023310184479 all mean 0.08737451583147049
0.25907281041145325 0.25907278060913086
rl training, epoch7, iter0, batch46/1133, batch loss:0.25907278060913086, Training time:22235.83354973793
batch reward last col mean 0.08163774013519287 first col mean 0.09301376342773438 all mean 0.09064209461212158
0.25988778471946716 0.25988781452178955
rl training, epoch7, iter0, batch47/1133, batch loss:0.25988781452178955, Training time:22238.015014648438
batch reward last col mean 0.0839548408985138 first col mean 0.10473944246768951 all mean 0.08668036758899689
0.2780323028564453 0.2780323028564453
rl training, epoch7, iter0, batch48/1133, batch loss:0.2780323028564453, Training time:22239.901214122772
batch reward last col mean 0.08161036670207977 first col mean 0.09961804747581482 all mean 0.08374066650867462
0.23756222426891327 0.23756222426891327
rl training, epoch7, iter0, batch49/1133, batch loss:0.23756222426891327, Training time:22242.26648736
batch reward last col mean 0.07050138711929321 first col mean 0.09912768751382828 all mean 0.08060768246650696
0.22299350798130035 0.22299350798130035
rl training, epoch7, iter0, batch50/1133, batch loss:0.22299350798130035, Training time:22244.08431506157
batch reward last col mean 0.10092262923717499 first col mean 0.10541218519210815 all mean 0.09875400364398956
0.23499025404453278 0.23499025404453278
rl training, epoch7, iter0, batch51/1133, batch loss:0.23499025404453278, Training time:22246.496335744858
batch reward last col mean 0.1193000078201294 first col mean 0.10882585495710373 all mean 0.1135006919503212
0.2592053711414337 0.2592053711414337
rl training, epoch7, iter0, batch52/1133, batch loss:0.2592053711414337, Training time:22249.121060848236
batch reward last col mean 0.08176547288894653 first col mean 0.08722185343503952 all mean 0.08549977838993073
0.2624313533306122 0.26243138313293457
rl training, epoch7, iter0, batch53/1133, batch loss:0.26243138313293457, Training time:22250.988119602203
batch reward last col mean 0.12043097615242004 first col mean 0.0983739122748375 all mean 0.11887606233358383
0.31284603476524353 0.31284603476524353
rl training, epoch7, iter0, batch54/1133, batch loss:0.31284603476524353, Training time:22252.989433526993
batch reward last col mean 0.1353309005498886 first col mean 0.09686977416276932 all mean 0.12378612160682678
0.31112369894981384 0.31112369894981384
rl training, epoch7, iter0, batch55/1133, batch loss:0.31112369894981384, Training time:22255.07187652588
batch reward last col mean 0.11233043670654297 first col mean 0.08338627964258194 all mean 0.10949480533599854
0.2672477960586548 0.2672477960586548
rl training, epoch7, iter0, batch56/1133, batch loss:0.2672477960586548, Training time:22257.045645475388
batch reward last col mean 0.08590628206729889 first col mean 0.10239376127719879 all mean 0.08889627456665039
0.23845840990543365 0.23845840990543365
rl training, epoch7, iter0, batch57/1133, batch loss:0.23845840990543365, Training time:22259.040389060974
batch reward last col mean 0.12945407629013062 first col mean 0.10190706700086594 all mean 0.12067174911499023
0.2782227396965027 0.2782227396965027
rl training, epoch7, iter0, batch58/1133, batch loss:0.2782227396965027, Training time:22260.81210708618
batch reward last col mean 0.11284728348255157 first col mean 0.09062114357948303 all mean 0.11452288180589676
0.30707481503486633 0.30707481503486633
rl training, epoch7, iter0, batch59/1133, batch loss:0.30707481503486633, Training time:22262.609154462814
batch reward last col mean 0.0876568928360939 first col mean 0.10456502437591553 all mean 0.09047901630401611
0.24122454226016998 0.24122454226016998
rl training, epoch7, iter0, batch60/1133, batch loss:0.24122454226016998, Training time:22264.85545349121
batch reward last col mean 0.08958640694618225 first col mean 0.0822688639163971 all mean 0.09297721832990646
0.276887446641922 0.276887446641922
rl training, epoch7, iter0, batch61/1133, batch loss:0.276887446641922, Training time:22267.206664562225
batch reward last col mean 0.10465016961097717 first col mean 0.09925097227096558 all mean 0.10273714363574982
0.2536468803882599 0.2536468803882599
rl training, epoch7, iter0, batch62/1133, batch loss:0.2536468803882599, Training time:22269.1547062397
batch reward last col mean 0.0936405211687088 first col mean 0.09363621473312378 all mean 0.09401954710483551
0.24673670530319214 0.24673670530319214
rl training, epoch7, iter0, batch63/1133, batch loss:0.24673670530319214, Training time:22271.046016454697
batch reward last col mean 0.09509110450744629 first col mean 0.11245882511138916 all mean 0.09794746339321136
0.2615267336368561 0.2615267336368561
rl training, epoch7, iter0, batch64/1133, batch loss:0.2615267336368561, Training time:22272.942249298096
batch reward last col mean 0.1454620361328125 first col mean 0.0985419750213623 all mean 0.12797847390174866
0.30751684308052063 0.30751681327819824
rl training, epoch7, iter0, batch65/1133, batch loss:0.30751681327819824, Training time:22274.626660585403
batch reward last col mean 0.10261714458465576 first col mean 0.10600988566875458 all mean 0.10168392211198807
0.28158292174339294 0.28158295154571533
rl training, epoch7, iter0, batch66/1133, batch loss:0.28158295154571533, Training time:22277.158535003662
batch reward last col mean 0.09271721541881561 first col mean 0.0941198393702507 all mean 0.09115491062402725
0.247993603348732 0.2479935884475708
rl training, epoch7, iter0, batch67/1133, batch loss:0.2479935884475708, Training time:22279.205322027206
batch reward last col mean 0.10395146161317825 first col mean 0.086131252348423 all mean 0.10611563920974731
0.2577459216117859 0.2577459216117859
rl training, epoch7, iter0, batch68/1133, batch loss:0.2577459216117859, Training time:22281.00225710869
batch reward last col mean 0.11388205736875534 first col mean 0.10123710334300995 all mean 0.10470333695411682
0.2483418732881546 0.2483418732881546
rl training, epoch7, iter0, batch69/1133, batch loss:0.2483418732881546, Training time:22283.450241804123
batch reward last col mean 0.09289900958538055 first col mean 0.10992933809757233 all mean 0.09397722035646439
0.28419768810272217 0.28419768810272217
rl training, epoch7, iter0, batch70/1133, batch loss:0.28419768810272217, Training time:22285.511850833893
batch reward last col mean 0.09973372519016266 first col mean 0.09561292827129364 all mean 0.09941403567790985
0.2576753795146942 0.2576754093170166
rl training, epoch7, iter0, batch71/1133, batch loss:0.2576754093170166, Training time:22287.628485679626
batch reward last col mean 0.0801791250705719 first col mean 0.09264883399009705 all mean 0.08576827496290207
0.2573482394218445 0.2573482394218445
rl training, epoch7, iter0, batch72/1133, batch loss:0.2573482394218445, Training time:22289.638669490814
batch reward last col mean 0.12480376660823822 first col mean 0.09618236869573593 all mean 0.11607511341571808
0.2953455448150635 0.2953455150127411
rl training, epoch7, iter0, batch73/1133, batch loss:0.2953455150127411, Training time:22291.459309101105
batch reward last col mean 0.06697140634059906 first col mean 0.11137626320123672 all mean 0.07922226190567017
0.23480156064033508 0.2348015308380127
rl training, epoch7, iter0, batch74/1133, batch loss:0.2348015308380127, Training time:22293.220731973648
batch reward last col mean 0.08568599820137024 first col mean 0.0965164303779602 all mean 0.09088953584432602
0.2516385614871979 0.2516385614871979
rl training, epoch7, iter0, batch75/1133, batch loss:0.2516385614871979, Training time:22295.076735258102
batch reward last col mean 0.08741571009159088 first col mean 0.10397250950336456 all mean 0.09025613218545914
0.2817757725715637 0.2817757725715637
rl training, epoch7, iter0, batch76/1133, batch loss:0.2817757725715637, Training time:22296.975173473358
batch reward last col mean 0.06553325802087784 first col mean 0.1285114735364914 all mean 0.08032256364822388
0.27205324172973633 0.27205321192741394
rl training, epoch7, iter0, batch77/1133, batch loss:0.27205321192741394, Training time:22299.261090040207
batch reward last col mean 0.11880481243133545 first col mean 0.10985161364078522 all mean 0.1152145117521286
0.3058856427669525 0.3058856427669525
rl training, epoch7, iter0, batch78/1133, batch loss:0.3058856427669525, Training time:22301.20151948929
batch reward last col mean 0.08539817482233047 first col mean 0.08881291002035141 all mean 0.08823394775390625
0.23463472723960876 0.23463472723960876
rl training, epoch7, iter0, batch79/1133, batch loss:0.23463472723960876, Training time:22303.23202753067
batch reward last col mean 0.08232292532920837 first col mean 0.11420576274394989 all mean 0.08979398012161255
0.24796025454998016 0.24796025454998016
rl training, epoch7, iter0, batch80/1133, batch loss:0.24796025454998016, Training time:22305.47213435173
batch reward last col mean 0.10690881311893463 first col mean 0.10788647830486298 all mean 0.1066816970705986
0.2818695306777954 0.2818695306777954
rl training, epoch7, iter0, batch81/1133, batch loss:0.2818695306777954, Training time:22307.068035840988
batch reward last col mean 0.07136139273643494 first col mean 0.09968352317810059 all mean 0.08003507554531097
0.2404893934726715 0.2404893934726715
rl training, epoch7, iter0, batch82/1133, batch loss:0.2404893934726715, Training time:22308.76378417015
batch reward last col mean 0.10252926498651505 first col mean 0.10464099049568176 all mean 0.09887969493865967
0.2303134948015213 0.2303134948015213
rl training, epoch7, iter0, batch83/1133, batch loss:0.2303134948015213, Training time:22310.44588780403
batch reward last col mean 0.0989362969994545 first col mean 0.10829916596412659 all mean 0.10102621465921402
0.2576914429664612 0.2576914429664612
rl training, epoch7, iter0, batch84/1133, batch loss:0.2576914429664612, Training time:22312.40179157257
batch reward last col mean 0.11810512840747833 first col mean 0.11116494983434677 all mean 0.11622756719589233
0.2668675482273102 0.2668675482273102
rl training, epoch7, iter0, batch85/1133, batch loss:0.2668675482273102, Training time:22314.66005897522
batch reward last col mean 0.10663693398237228 first col mean 0.11963926255702972 all mean 0.10730799287557602
0.31037312746047974 0.31037312746047974
rl training, epoch7, iter0, batch86/1133, batch loss:0.31037312746047974, Training time:22316.559409856796
batch reward last col mean 0.07908181846141815 first col mean 0.09425036609172821 all mean 0.08571035414934158
0.24522776901721954 0.24522776901721954
rl training, epoch7, iter0, batch87/1133, batch loss:0.24522776901721954, Training time:22318.832152843475
batch reward last col mean 0.08778160065412521 first col mean 0.0896543636918068 all mean 0.08537226915359497
0.25590112805366516 0.25590112805366516
rl training, epoch7, iter0, batch88/1133, batch loss:0.25590112805366516, Training time:22320.772456407547
batch reward last col mean 0.12317634373903275 first col mean 0.07893408834934235 all mean 0.11591336876153946
0.2865982949733734 0.2865982949733734
rl training, epoch7, iter0, batch89/1133, batch loss:0.2865982949733734, Training time:22322.679575920105
batch reward last col mean 0.12954971194267273 first col mean 0.10587810724973679 all mean 0.12133219838142395
0.2616685926914215 0.2616685628890991
rl training, epoch7, iter0, batch90/1133, batch loss:0.2616685628890991, Training time:22324.63161587715
batch reward last col mean 0.1187497079372406 first col mean 0.08679332584142685 all mean 0.12031615525484085
0.29115116596221924 0.29115113615989685
rl training, epoch7, iter0, batch91/1133, batch loss:0.29115113615989685, Training time:22326.422322273254
batch reward last col mean 0.0900169238448143 first col mean 0.10646729171276093 all mean 0.0943610891699791
0.2396562546491623 0.2396562546491623
rl training, epoch7, iter0, batch92/1133, batch loss:0.2396562546491623, Training time:22328.589293956757
batch reward last col mean 0.08202821761369705 first col mean 0.09643715620040894 all mean 0.0870729610323906
0.2691614329814911 0.2691614329814911
rl training, epoch7, iter0, batch93/1133, batch loss:0.2691614329814911, Training time:22330.70021057129
batch reward last col mean 0.10227681696414948 first col mean 0.08753852546215057 all mean 0.09371019899845123
0.22851289808750153 0.22851289808750153
rl training, epoch7, iter0, batch94/1133, batch loss:0.22851289808750153, Training time:22332.425184965134
batch reward last col mean 0.09604877233505249 first col mean 0.09700296819210052 all mean 0.09322106093168259
0.25560179352760315 0.25560179352760315
rl training, epoch7, iter0, batch95/1133, batch loss:0.25560179352760315, Training time:22334.309566020966
batch reward last col mean 0.10876251757144928 first col mean 0.10328125208616257 all mean 0.10829076170921326
0.2791239321231842 0.2791239321231842
rl training, epoch7, iter0, batch96/1133, batch loss:0.2791239321231842, Training time:22337.091836452484
batch reward last col mean 0.09605677425861359 first col mean 0.09473472833633423 all mean 0.09842190146446228
0.30268073081970215 0.30268073081970215
rl training, epoch7, iter0, batch97/1133, batch loss:0.30268073081970215, Training time:22339.016505479813
batch reward last col mean 0.09248237311840057 first col mean 0.0936080813407898 all mean 0.09042961895465851
0.26459676027297974 0.26459673047065735
rl training, epoch7, iter0, batch98/1133, batch loss:0.26459673047065735, Training time:22340.618005275726
batch reward last col mean 0.11205685138702393 first col mean 0.10302204638719559 all mean 0.1056578978896141
0.2782990634441376 0.2782990634441376
rl training, epoch7, iter0, batch99/1133, batch loss:0.2782990634441376, Training time:22342.636439323425
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46032566358216126 Time: 94.74976253509521 s
loss of true 0.19768017364726695 loss of gen 0.16590108372935233 loss of other 0.09674440671353611 first score 0.13770298659801483
batch reward last col mean 0.0647829920053482 first col mean 0.12128591537475586 all mean 0.07187040895223618
0.22532308101654053 0.22532308101654053
rl training, epoch7, iter0, batch100/1133, batch loss:0.22532308101654053, Training time:22439.146228790283
batch reward last col mean 0.06758930534124374 first col mean 0.0830918624997139 all mean 0.06875955313444138
0.20960655808448792 0.20960655808448792
rl training, epoch7, iter0, batch101/1133, batch loss:0.20960655808448792, Training time:22441.070477962494
batch reward last col mean 0.07365219295024872 first col mean 0.08677602559328079 all mean 0.07757630199193954
0.23699897527694702 0.23699897527694702
rl training, epoch7, iter0, batch102/1133, batch loss:0.23699897527694702, Training time:22443.089787006378
batch reward last col mean 0.08749768137931824 first col mean 0.10930444300174713 all mean 0.08781073242425919
0.24471193552017212 0.24471193552017212
rl training, epoch7, iter0, batch103/1133, batch loss:0.24471193552017212, Training time:22444.682947397232
batch reward last col mean 0.08097580820322037 first col mean 0.10877947509288788 all mean 0.0893695056438446
0.22638554871082306 0.22638554871082306
rl training, epoch7, iter0, batch104/1133, batch loss:0.22638554871082306, Training time:22446.120131254196
batch reward last col mean 0.09632956236600876 first col mean 0.09368613362312317 all mean 0.09644665569067001
0.2528834640979767 0.2528834640979767
rl training, epoch7, iter0, batch105/1133, batch loss:0.2528834640979767, Training time:22448.23616719246
batch reward last col mean 0.10007236152887344 first col mean 0.08980856835842133 all mean 0.0993775799870491
0.2851654589176178 0.2851654589176178
rl training, epoch7, iter0, batch106/1133, batch loss:0.2851654589176178, Training time:22450.87949037552
batch reward last col mean 0.09466440975666046 first col mean 0.07183192670345306 all mean 0.09065580368041992
0.24082441627979279 0.24082441627979279
rl training, epoch7, iter0, batch107/1133, batch loss:0.24082441627979279, Training time:22452.318851709366
batch reward last col mean 0.06318042427301407 first col mean 0.08580978959798813 all mean 0.07434424757957458
0.22311361134052277 0.22311361134052277
rl training, epoch7, iter0, batch108/1133, batch loss:0.22311361134052277, Training time:22454.13302731514
batch reward last col mean 0.08487864583730698 first col mean 0.08027306199073792 all mean 0.08996105194091797
0.2639840245246887 0.2639840245246887
rl training, epoch7, iter0, batch109/1133, batch loss:0.2639840245246887, Training time:22455.8247487545
batch reward last col mean 0.07820526510477066 first col mean 0.09460164606571198 all mean 0.08114057034254074
0.25864318013191223 0.25864318013191223
rl training, epoch7, iter0, batch110/1133, batch loss:0.25864318013191223, Training time:22457.603105783463
batch reward last col mean 0.07416205108165741 first col mean 0.08354628831148148 all mean 0.08185118436813354
0.2366521805524826 0.2366521805524826
rl training, epoch7, iter0, batch111/1133, batch loss:0.2366521805524826, Training time:22459.443875074387
batch reward last col mean 0.10147562623023987 first col mean 0.09460999816656113 all mean 0.0967678502202034
0.27356114983558655 0.27356117963790894
rl training, epoch7, iter0, batch112/1133, batch loss:0.27356117963790894, Training time:22461.316632270813
batch reward last col mean 0.082546167075634 first col mean 0.09333495050668716 all mean 0.08258996158838272
0.22037070989608765 0.22037070989608765
rl training, epoch7, iter0, batch113/1133, batch loss:0.22037070989608765, Training time:22462.86952328682
batch reward last col mean 0.10032625496387482 first col mean 0.10191711783409119 all mean 0.09993132203817368
0.27299389243125916 0.27299389243125916
rl training, epoch7, iter0, batch114/1133, batch loss:0.27299389243125916, Training time:22464.656309843063
batch reward last col mean 0.1072831079363823 first col mean 0.09622135758399963 all mean 0.09958948194980621
0.22777125239372253 0.22777125239372253
rl training, epoch7, iter0, batch115/1133, batch loss:0.22777125239372253, Training time:22466.523011922836
batch reward last col mean 0.09267054498195648 first col mean 0.11063544452190399 all mean 0.0916890799999237
0.21748362481594086 0.21748362481594086
rl training, epoch7, iter0, batch116/1133, batch loss:0.21748362481594086, Training time:22468.34259033203
batch reward last col mean 0.0619833841919899 first col mean 0.08240500092506409 all mean 0.07314609736204147
0.24913954734802246 0.24913954734802246
rl training, epoch7, iter0, batch117/1133, batch loss:0.24913954734802246, Training time:22469.933220386505
batch reward last col mean 0.07899191975593567 first col mean 0.09336356818675995 all mean 0.07874603569507599
0.2460777759552002 0.2460777312517166
rl training, epoch7, iter0, batch118/1133, batch loss:0.2460777312517166, Training time:22471.628075122833
batch reward last col mean 0.11735232919454575 first col mean 0.0970725417137146 all mean 0.10708789527416229
0.23689864575862885 0.23689864575862885
rl training, epoch7, iter0, batch119/1133, batch loss:0.23689864575862885, Training time:22473.369776010513
batch reward last col mean 0.07357290387153625 first col mean 0.10569168627262115 all mean 0.07897377014160156
0.2356058955192566 0.2356058955192566
rl training, epoch7, iter0, batch120/1133, batch loss:0.2356058955192566, Training time:22475.236317396164
batch reward last col mean 0.08858806639909744 first col mean 0.07959216088056564 all mean 0.09900680184364319
0.26260480284690857 0.26260480284690857
rl training, epoch7, iter0, batch121/1133, batch loss:0.26260480284690857, Training time:22476.872111797333
batch reward last col mean 0.08323855698108673 first col mean 0.09620297700166702 all mean 0.08585712313652039
0.23062549531459808 0.23062549531459808
rl training, epoch7, iter0, batch122/1133, batch loss:0.23062549531459808, Training time:22478.40180659294
batch reward last col mean 0.09925969690084457 first col mean 0.09456422924995422 all mean 0.09919625520706177
0.24989567697048187 0.24989566206932068
rl training, epoch7, iter0, batch123/1133, batch loss:0.24989566206932068, Training time:22480.892862319946
batch reward last col mean 0.07564782351255417 first col mean 0.09585148096084595 all mean 0.08226059377193451
0.281297504901886 0.281297504901886
rl training, epoch7, iter0, batch124/1133, batch loss:0.281297504901886, Training time:22482.529628515244
batch reward last col mean 0.08607169985771179 first col mean 0.09175292402505875 all mean 0.08688004314899445
0.23309281468391418 0.23309281468391418
rl training, epoch7, iter0, batch125/1133, batch loss:0.23309281468391418, Training time:22484.200587272644
batch reward last col mean 0.06495362520217896 first col mean 0.07881630957126617 all mean 0.07008046656847
0.22852417826652527 0.22852417826652527
rl training, epoch7, iter0, batch126/1133, batch loss:0.22852417826652527, Training time:22485.969225168228
batch reward last col mean 0.04022790864109993 first col mean 0.09201972931623459 all mean 0.05306626483798027
0.22832252085208893 0.22832252085208893
rl training, epoch7, iter0, batch127/1133, batch loss:0.22832252085208893, Training time:22488.32148861885
batch reward last col mean 0.0929180383682251 first col mean 0.09375231713056564 all mean 0.09463426470756531
0.23121869564056396 0.23121869564056396
rl training, epoch7, iter0, batch128/1133, batch loss:0.23121869564056396, Training time:22490.38893342018
batch reward last col mean 0.09894967824220657 first col mean 0.10413385182619095 all mean 0.09786432236433029
0.2645748555660248 0.2645748555660248
rl training, epoch7, iter0, batch129/1133, batch loss:0.2645748555660248, Training time:22491.995168685913
batch reward last col mean 0.07722605019807816 first col mean 0.10357622802257538 all mean 0.08425595611333847
0.28156784176826477 0.28156784176826477
rl training, epoch7, iter0, batch130/1133, batch loss:0.28156784176826477, Training time:22493.81158900261
batch reward last col mean 0.07608247548341751 first col mean 0.1007007360458374 all mean 0.08089689165353775
0.23990826308727264 0.23990826308727264
rl training, epoch7, iter0, batch131/1133, batch loss:0.23990826308727264, Training time:22495.415691137314
batch reward last col mean 0.07492464780807495 first col mean 0.10512964427471161 all mean 0.07692985236644745
0.23868446052074432 0.23868446052074432
rl training, epoch7, iter0, batch132/1133, batch loss:0.23868446052074432, Training time:22497.748829364777
batch reward last col mean 0.08730266988277435 first col mean 0.08864423632621765 all mean 0.08726580440998077
0.24898084998130798 0.24898084998130798
rl training, epoch7, iter0, batch133/1133, batch loss:0.24898084998130798, Training time:22499.72421336174
batch reward last col mean 0.07016246020793915 first col mean 0.08479470014572144 all mean 0.07463754713535309
0.21517471969127655 0.21517471969127655
rl training, epoch7, iter0, batch134/1133, batch loss:0.21517471969127655, Training time:22501.489292144775
batch reward last col mean 0.09179158508777618 first col mean 0.08046527951955795 all mean 0.0916636660695076
0.23952558636665344 0.23952558636665344
rl training, epoch7, iter0, batch135/1133, batch loss:0.23952558636665344, Training time:22502.8315243721
batch reward last col mean 0.10918192565441132 first col mean 0.10333851724863052 all mean 0.10617916285991669
0.2475074827671051 0.2475074827671051
rl training, epoch7, iter0, batch136/1133, batch loss:0.2475074827671051, Training time:22504.511666059494
batch reward last col mean 0.10660656541585922 first col mean 0.10018846392631531 all mean 0.10533569008111954
0.29831770062446594 0.29831767082214355
rl training, epoch7, iter0, batch137/1133, batch loss:0.29831767082214355, Training time:22506.144730329514
batch reward last col mean 0.07000291347503662 first col mean 0.09185899794101715 all mean 0.0673433169722557
0.21753588318824768 0.2175358682870865
rl training, epoch7, iter0, batch138/1133, batch loss:0.2175358682870865, Training time:22507.86198735237
batch reward last col mean 0.07489684224128723 first col mean 0.07447529584169388 all mean 0.07871019095182419
0.23923203349113464 0.23923203349113464
rl training, epoch7, iter0, batch139/1133, batch loss:0.23923203349113464, Training time:22509.71795296669
batch reward last col mean 0.07910285890102386 first col mean 0.08303562551736832 all mean 0.07945001870393753
0.2289348989725113 0.2289348989725113
rl training, epoch7, iter0, batch140/1133, batch loss:0.2289348989725113, Training time:22511.14383292198
batch reward last col mean 0.10870423167943954 first col mean 0.08792563527822495 all mean 0.10633505135774612
0.26394370198249817 0.26394370198249817
rl training, epoch7, iter0, batch141/1133, batch loss:0.26394370198249817, Training time:22513.084391355515
batch reward last col mean 0.07768906652927399 first col mean 0.09797793626785278 all mean 0.0834578275680542
0.2141764760017395 0.2141764760017395
rl training, epoch7, iter0, batch142/1133, batch loss:0.2141764760017395, Training time:22514.917324543
batch reward last col mean 0.07035432010889053 first col mean 0.09222782403230667 all mean 0.07883772999048233
0.22204923629760742 0.22204923629760742
rl training, epoch7, iter0, batch143/1133, batch loss:0.22204923629760742, Training time:22516.724092960358
batch reward last col mean 0.10999071598052979 first col mean 0.09499497711658478 all mean 0.1013936698436737
0.2781604826450348 0.2781604826450348
rl training, epoch7, iter0, batch144/1133, batch loss:0.2781604826450348, Training time:22518.65691924095
batch reward last col mean 0.09534704685211182 first col mean 0.08601447194814682 all mean 0.09394774585962296
0.2738206088542938 0.2738206088542938
rl training, epoch7, iter0, batch145/1133, batch loss:0.2738206088542938, Training time:22520.223578453064
batch reward last col mean 0.07816720008850098 first col mean 0.09667471051216125 all mean 0.08165943622589111
0.23004359006881714 0.23004359006881714
rl training, epoch7, iter0, batch146/1133, batch loss:0.23004359006881714, Training time:22521.90530180931
batch reward last col mean 0.06329980492591858 first col mean 0.10134143382310867 all mean 0.08092544972896576
0.2639849781990051 0.2639849781990051
rl training, epoch7, iter0, batch147/1133, batch loss:0.2639849781990051, Training time:22523.360745191574
batch reward last col mean 0.0862494632601738 first col mean 0.09993874281644821 all mean 0.08938019722700119
0.2639465928077698 0.2639465928077698
rl training, epoch7, iter0, batch148/1133, batch loss:0.2639465928077698, Training time:22524.922677755356
batch reward last col mean 0.12115025520324707 first col mean 0.10716812312602997 all mean 0.11470074206590652
0.31975722312927246 0.31975722312927246
rl training, epoch7, iter0, batch149/1133, batch loss:0.31975722312927246, Training time:22526.73000383377
batch reward last col mean 0.1093345433473587 first col mean 0.0841733068227768 all mean 0.1107398048043251
0.2537805140018463 0.2537805140018463
rl training, epoch7, iter0, batch150/1133, batch loss:0.2537805140018463, Training time:22528.57226204872
batch reward last col mean 0.09014133363962173 first col mean 0.09953239560127258 all mean 0.09535770863294601
0.2550772726535797 0.2550772726535797
rl training, epoch7, iter0, batch151/1133, batch loss:0.2550772726535797, Training time:22530.496817350388
batch reward last col mean 0.06349384039640427 first col mean 0.10583402216434479 all mean 0.06685655564069748
0.225184366106987 0.225184366106987
rl training, epoch7, iter0, batch152/1133, batch loss:0.225184366106987, Training time:22532.523668527603
batch reward last col mean 0.07058416306972504 first col mean 0.0972355306148529 all mean 0.07724831998348236
0.21353916823863983 0.21353916823863983
rl training, epoch7, iter0, batch153/1133, batch loss:0.21353916823863983, Training time:22535.07912492752
batch reward last col mean 0.08436606079339981 first col mean 0.09463702887296677 all mean 0.0900629460811615
0.29559969902038574 0.29559966921806335
rl training, epoch7, iter0, batch154/1133, batch loss:0.29559966921806335, Training time:22537.15967822075
batch reward last col mean 0.09522729367017746 first col mean 0.10816695541143417 all mean 0.09719634801149368
0.253348171710968 0.253348171710968
rl training, epoch7, iter0, batch155/1133, batch loss:0.253348171710968, Training time:22539.16473340988
batch reward last col mean 0.062468208372592926 first col mean 0.08719682693481445 all mean 0.06727615743875504
0.19653452932834625 0.19653451442718506
rl training, epoch7, iter0, batch156/1133, batch loss:0.19653451442718506, Training time:22541.50536799431
batch reward last col mean 0.08564776927232742 first col mean 0.09132145345211029 all mean 0.08682633936405182
0.23361864686012268 0.23361864686012268
rl training, epoch7, iter0, batch157/1133, batch loss:0.23361864686012268, Training time:22543.04727768898
batch reward last col mean 0.11256023496389389 first col mean 0.09585290402173996 all mean 0.11093397438526154
0.26849597692489624 0.26849597692489624
rl training, epoch7, iter0, batch158/1133, batch loss:0.26849597692489624, Training time:22545.27277445793
batch reward last col mean 0.09890761226415634 first col mean 0.0941108986735344 all mean 0.0943535789847374
0.23749253153800964 0.23749253153800964
rl training, epoch7, iter0, batch159/1133, batch loss:0.23749253153800964, Training time:22546.839707374573
batch reward last col mean 0.084651879966259 first col mean 0.1079944297671318 all mean 0.0854390561580658
0.24846221506595612 0.24846220016479492
rl training, epoch7, iter0, batch160/1133, batch loss:0.24846220016479492, Training time:22549.52199459076
batch reward last col mean 0.08418925106525421 first col mean 0.11169268190860748 all mean 0.0875689685344696
0.2914671301841736 0.2914671301841736
rl training, epoch7, iter0, batch161/1133, batch loss:0.2914671301841736, Training time:22551.437507390976
batch reward last col mean 0.09797723591327667 first col mean 0.11840733885765076 all mean 0.10086769610643387
0.27613964676856995 0.27613964676856995
rl training, epoch7, iter0, batch162/1133, batch loss:0.27613964676856995, Training time:22553.10201883316
batch reward last col mean 0.07553460448980331 first col mean 0.07817462831735611 all mean 0.0791531652212143
0.2667934000492096 0.2667933702468872
rl training, epoch7, iter0, batch163/1133, batch loss:0.2667933702468872, Training time:22555.86408519745
batch reward last col mean 0.1168680340051651 first col mean 0.10064659267663956 all mean 0.10498769581317902
0.28213146328926086 0.28213149309158325
rl training, epoch7, iter0, batch164/1133, batch loss:0.28213149309158325, Training time:22557.46838903427
batch reward last col mean 0.10004428774118423 first col mean 0.09125200659036636 all mean 0.1026153713464737
0.2761386036872864 0.2761386036872864
rl training, epoch7, iter0, batch165/1133, batch loss:0.2761386036872864, Training time:22559.297580242157
batch reward last col mean 0.10440316051244736 first col mean 0.09547041356563568 all mean 0.09777957946062088
0.2887991964817047 0.2887991666793823
rl training, epoch7, iter0, batch166/1133, batch loss:0.2887991666793823, Training time:22561.127289295197
batch reward last col mean 0.10498905181884766 first col mean 0.09844096004962921 all mean 0.09775324165821075
0.26530277729034424 0.26530277729034424
rl training, epoch7, iter0, batch167/1133, batch loss:0.26530277729034424, Training time:22562.973750591278
batch reward last col mean 0.09291710704565048 first col mean 0.0996050164103508 all mean 0.090804822742939
0.27501028776168823 0.27501028776168823
rl training, epoch7, iter0, batch168/1133, batch loss:0.27501028776168823, Training time:22564.861616373062
batch reward last col mean 0.08656527101993561 first col mean 0.0974942147731781 all mean 0.08823556452989578
0.24604342877864838 0.24604342877864838
rl training, epoch7, iter0, batch169/1133, batch loss:0.24604342877864838, Training time:22566.435624837875
batch reward last col mean 0.12567377090454102 first col mean 0.10624435544013977 all mean 0.1160305067896843
0.2512403428554535 0.2512403428554535
rl training, epoch7, iter0, batch170/1133, batch loss:0.2512403428554535, Training time:22568.481783866882
batch reward last col mean 0.11433111131191254 first col mean 0.0925602838397026 all mean 0.10739003121852875
0.27137160301208496 0.27137160301208496
rl training, epoch7, iter0, batch171/1133, batch loss:0.27137160301208496, Training time:22570.5771753788
batch reward last col mean 0.12688538432121277 first col mean 0.09452975541353226 all mean 0.11919638514518738
0.2933383584022522 0.2933383584022522
rl training, epoch7, iter0, batch172/1133, batch loss:0.2933383584022522, Training time:22572.237070322037
batch reward last col mean 0.11225263774394989 first col mean 0.09750982373952866 all mean 0.10151131451129913
0.28019288182258606 0.28019288182258606
rl training, epoch7, iter0, batch173/1133, batch loss:0.28019288182258606, Training time:22574.02831339836
batch reward last col mean 0.07636266201734543 first col mean 0.10358340293169022 all mean 0.08285903185606003
0.23090432584285736 0.23090432584285736
rl training, epoch7, iter0, batch174/1133, batch loss:0.23090432584285736, Training time:22576.702249526978
batch reward last col mean 0.09802155196666718 first col mean 0.09409952163696289 all mean 0.10001782327890396
0.285313218832016 0.285313218832016
rl training, epoch7, iter0, batch175/1133, batch loss:0.285313218832016, Training time:22578.28259754181
batch reward last col mean 0.1091337725520134 first col mean 0.08887280523777008 all mean 0.10306411236524582
0.23858651518821716 0.23858651518821716
rl training, epoch7, iter0, batch176/1133, batch loss:0.23858651518821716, Training time:22580.00009083748
batch reward last col mean 0.0954282358288765 first col mean 0.10200830549001694 all mean 0.09488578140735626
0.2867334187030792 0.2867334187030792
rl training, epoch7, iter0, batch177/1133, batch loss:0.2867334187030792, Training time:22581.628821372986
batch reward last col mean 0.0782821774482727 first col mean 0.10477519035339355 all mean 0.08266063779592514
0.23731841146945953 0.23731841146945953
rl training, epoch7, iter0, batch178/1133, batch loss:0.23731841146945953, Training time:22583.456189632416
batch reward last col mean 0.09575937688350677 first col mean 0.09680281579494476 all mean 0.09504809230566025
0.24498672783374786 0.24498672783374786
rl training, epoch7, iter0, batch179/1133, batch loss:0.24498672783374786, Training time:22585.244166851044
batch reward last col mean 0.09270228445529938 first col mean 0.10181427747011185 all mean 0.09529748558998108
0.2449558526277542 0.2449558526277542
rl training, epoch7, iter0, batch180/1133, batch loss:0.2449558526277542, Training time:22587.1990981102
batch reward last col mean 0.10234855115413666 first col mean 0.09672700613737106 all mean 0.09715215861797333
0.24651853740215302 0.24651853740215302
rl training, epoch7, iter0, batch181/1133, batch loss:0.24651853740215302, Training time:22589.087845802307
batch reward last col mean 0.13316771388053894 first col mean 0.07630445063114166 all mean 0.12265399843454361
0.27771100401878357 0.2777109742164612
rl training, epoch7, iter0, batch182/1133, batch loss:0.2777109742164612, Training time:22590.684242010117
batch reward last col mean 0.12138590961694717 first col mean 0.10346351563930511 all mean 0.11064527183771133
0.24985159933567047 0.24985159933567047
rl training, epoch7, iter0, batch183/1133, batch loss:0.24985159933567047, Training time:22592.83267235756
batch reward last col mean 0.11178430169820786 first col mean 0.09153426438570023 all mean 0.10808337479829788
0.280658096075058 0.280658096075058
rl training, epoch7, iter0, batch184/1133, batch loss:0.280658096075058, Training time:22594.5020301342
batch reward last col mean 0.11247880756855011 first col mean 0.11308635771274567 all mean 0.10362342745065689
0.2696581482887268 0.2696581482887268
rl training, epoch7, iter0, batch185/1133, batch loss:0.2696581482887268, Training time:22596.149943351746
batch reward last col mean 0.1016155481338501 first col mean 0.0910295695066452 all mean 0.10566283762454987
0.2735233008861542 0.2735233008861542
rl training, epoch7, iter0, batch186/1133, batch loss:0.2735233008861542, Training time:22597.479355812073
batch reward last col mean 0.057914577424526215 first col mean 0.10105618834495544 all mean 0.07144089788198471
0.23051388561725616 0.23051388561725616
rl training, epoch7, iter0, batch187/1133, batch loss:0.23051388561725616, Training time:22599.029129743576
batch reward last col mean 0.10042531043291092 first col mean 0.10355424135923386 all mean 0.1047174260020256
0.28293782472610474 0.28293779492378235
rl training, epoch7, iter0, batch188/1133, batch loss:0.28293779492378235, Training time:22600.784199237823
batch reward last col mean 0.09961036592721939 first col mean 0.09678298234939575 all mean 0.09888600558042526
0.2914062738418579 0.2914062738418579
rl training, epoch7, iter0, batch189/1133, batch loss:0.2914062738418579, Training time:22602.465383291245
batch reward last col mean 0.11940557509660721 first col mean 0.0836268961429596 all mean 0.11157917231321335
0.2880059480667114 0.28800591826438904
rl training, epoch7, iter0, batch190/1133, batch loss:0.28800591826438904, Training time:22603.839997529984
batch reward last col mean 0.10405272990465164 first col mean 0.11145266890525818 all mean 0.1034654825925827
0.2754814028739929 0.2754814326763153
rl training, epoch7, iter0, batch191/1133, batch loss:0.2754814326763153, Training time:22605.521624326706
batch reward last col mean 0.13086801767349243 first col mean 0.09047326445579529 all mean 0.11537977308034897
0.29705604910850525 0.29705604910850525
rl training, epoch7, iter0, batch192/1133, batch loss:0.29705604910850525, Training time:22606.89119720459
batch reward last col mean 0.12033100426197052 first col mean 0.10752613842487335 all mean 0.1151462197303772
0.29958418011665344 0.29958418011665344
rl training, epoch7, iter0, batch193/1133, batch loss:0.29958418011665344, Training time:22608.770053625107
batch reward last col mean 0.08197667449712753 first col mean 0.07866030931472778 all mean 0.08523185551166534
0.23003172874450684 0.23003172874450684
rl training, epoch7, iter0, batch194/1133, batch loss:0.23003172874450684, Training time:22610.78840327263
batch reward last col mean 0.0828203409910202 first col mean 0.1062670350074768 all mean 0.08749184757471085
0.2670302093029022 0.2670302093029022
rl training, epoch7, iter0, batch195/1133, batch loss:0.2670302093029022, Training time:22612.349451303482
batch reward last col mean 0.11532586812973022 first col mean 0.0922495573759079 all mean 0.1039913147687912
0.2537097632884979 0.2537097632884979
rl training, epoch7, iter0, batch196/1133, batch loss:0.2537097632884979, Training time:22614.308885097504
batch reward last col mean 0.11460715532302856 first col mean 0.11217781156301498 all mean 0.11627624183893204
0.3134045898914337 0.3134045898914337
rl training, epoch7, iter0, batch197/1133, batch loss:0.3134045898914337, Training time:22615.820538043976
batch reward last col mean 0.1062982976436615 first col mean 0.10224994271993637 all mean 0.0993652418255806
0.26650434732437134 0.26650434732437134
rl training, epoch7, iter0, batch198/1133, batch loss:0.26650434732437134, Training time:22617.427961349487
batch reward last col mean 0.06974233686923981 first col mean 0.09526282548904419 all mean 0.07913098484277725
0.2395031899213791 0.2395031899213791
rl training, epoch7, iter0, batch199/1133, batch loss:0.2395031899213791, Training time:22619.183931589127
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4628223413823457 Time: 94.00806283950806 s
loss of true 0.19940434559351136 loss of gen 0.16755815800887658 loss of other 0.09585983799532095 first score 0.1083524227142334
batch reward last col mean 0.09039676934480667 first col mean 0.12027321755886078 all mean 0.09599599987268448
0.30437177419662476 0.30437177419662476
rl training, epoch7, iter0, batch200/1133, batch loss:0.30437177419662476, Training time:22714.557909965515
batch reward last col mean 0.10736018419265747 first col mean 0.09107469767332077 all mean 0.10575234889984131
0.2440895438194275 0.2440895438194275
rl training, epoch7, iter0, batch201/1133, batch loss:0.2440895438194275, Training time:22716.07121706009
batch reward last col mean 0.1140832006931305 first col mean 0.11596132069826126 all mean 0.10650160908699036
0.26973050832748413 0.26973050832748413
rl training, epoch7, iter0, batch202/1133, batch loss:0.26973050832748413, Training time:22718.0879406929
batch reward last col mean 0.10800536721944809 first col mean 0.1027495414018631 all mean 0.10569655895233154
0.29619744420051575 0.29619744420051575
rl training, epoch7, iter0, batch203/1133, batch loss:0.29619744420051575, Training time:22720.39981150627
batch reward last col mean 0.062166977673769 first col mean 0.09949510544538498 all mean 0.07696694135665894
0.2784499228000641 0.2784499228000641
rl training, epoch7, iter0, batch204/1133, batch loss:0.2784499228000641, Training time:22721.960886716843
batch reward last col mean 0.07328919321298599 first col mean 0.10772573947906494 all mean 0.08209323137998581
0.27931448817253113 0.27931448817253113
rl training, epoch7, iter0, batch205/1133, batch loss:0.27931448817253113, Training time:22724.37507724762
batch reward last col mean 0.09365126490592957 first col mean 0.11807343363761902 all mean 0.09814076870679855
0.29753977060317993 0.29753977060317993
rl training, epoch7, iter0, batch206/1133, batch loss:0.29753977060317993, Training time:22726.168632030487
batch reward last col mean 0.08071689307689667 first col mean 0.10295633971691132 all mean 0.08694040775299072
0.2794411778450012 0.2794411778450012
rl training, epoch7, iter0, batch207/1133, batch loss:0.2794411778450012, Training time:22728.567716360092
batch reward last col mean 0.10687801986932755 first col mean 0.10580819100141525 all mean 0.10666041821241379
0.2748565077781677 0.2748565077781677
rl training, epoch7, iter0, batch208/1133, batch loss:0.2748565077781677, Training time:22730.718685626984
batch reward last col mean 0.05694902688264847 first col mean 0.09123394638299942 all mean 0.06914251297712326
0.22661447525024414 0.22661447525024414
rl training, epoch7, iter0, batch209/1133, batch loss:0.22661447525024414, Training time:22732.276544332504
batch reward last col mean 0.07952339202165604 first col mean 0.10820154845714569 all mean 0.08854997903108597
0.24956102669239044 0.24956101179122925
rl training, epoch7, iter0, batch210/1133, batch loss:0.24956101179122925, Training time:22733.931272745132
batch reward last col mean 0.07947033643722534 first col mean 0.08579564094543457 all mean 0.08173547685146332
0.2352192997932434 0.2352192997932434
rl training, epoch7, iter0, batch211/1133, batch loss:0.2352192997932434, Training time:22735.847940444946
batch reward last col mean 0.08690030127763748 first col mean 0.10853342711925507 all mean 0.09067484736442566
0.25162991881370544 0.25162991881370544
rl training, epoch7, iter0, batch212/1133, batch loss:0.25162991881370544, Training time:22737.85594367981
batch reward last col mean 0.1153218150138855 first col mean 0.09725528210401535 all mean 0.12009645998477936
0.326886922121048 0.326886922121048
rl training, epoch7, iter0, batch213/1133, batch loss:0.326886922121048, Training time:22739.904334306717
batch reward last col mean 0.10724164545536041 first col mean 0.08835458010435104 all mean 0.10965774953365326
0.2961995601654053 0.2961995601654053
rl training, epoch7, iter0, batch214/1133, batch loss:0.2961995601654053, Training time:22741.852493047714
batch reward last col mean 0.09953078627586365 first col mean 0.11641295254230499 all mean 0.10217522829771042
0.2889796495437622 0.2889796793460846
rl training, epoch7, iter0, batch215/1133, batch loss:0.2889796793460846, Training time:22743.72881603241
batch reward last col mean 0.1053907573223114 first col mean 0.12017448246479034 all mean 0.10356691479682922
0.296986848115921 0.29698681831359863
rl training, epoch7, iter0, batch216/1133, batch loss:0.29698681831359863, Training time:22745.15461063385
batch reward last col mean 0.0852743461728096 first col mean 0.0906343162059784 all mean 0.08977487683296204
0.2666739821434021 0.2666739821434021
rl training, epoch7, iter0, batch217/1133, batch loss:0.2666739821434021, Training time:22746.862517118454
batch reward last col mean 0.11573319137096405 first col mean 0.1028231829404831 all mean 0.10562768578529358
0.2797192931175232 0.2797192931175232
rl training, epoch7, iter0, batch218/1133, batch loss:0.2797192931175232, Training time:22748.653636217117
batch reward last col mean 0.1315760314464569 first col mean 0.11850383877754211 all mean 0.11674051731824875
0.28923824429512024 0.28923824429512024
rl training, epoch7, iter0, batch219/1133, batch loss:0.28923824429512024, Training time:22750.297214746475
batch reward last col mean 0.09299108386039734 first col mean 0.10360661149024963 all mean 0.09592781215906143
0.2893233299255371 0.2893233299255371
rl training, epoch7, iter0, batch220/1133, batch loss:0.2893233299255371, Training time:22752.555222034454
batch reward last col mean 0.10962563753128052 first col mean 0.09946978092193604 all mean 0.10340513288974762
0.25958409905433655 0.25958409905433655
rl training, epoch7, iter0, batch221/1133, batch loss:0.25958409905433655, Training time:22754.195130348206
batch reward last col mean 0.09591525048017502 first col mean 0.11750480532646179 all mean 0.10028187930583954
0.3082084059715271 0.3082084059715271
rl training, epoch7, iter0, batch222/1133, batch loss:0.3082084059715271, Training time:22756.26089477539
batch reward last col mean 0.07155990600585938 first col mean 0.11214987933635712 all mean 0.08187191933393478
0.27930861711502075 0.27930861711502075
rl training, epoch7, iter0, batch223/1133, batch loss:0.27930861711502075, Training time:22758.416173934937
batch reward last col mean 0.12761378288269043 first col mean 0.10140667855739594 all mean 0.11969070136547089
0.2816241681575775 0.2816241681575775
rl training, epoch7, iter0, batch224/1133, batch loss:0.2816241681575775, Training time:22760.705840587616
batch reward last col mean 0.13208889961242676 first col mean 0.10045529901981354 all mean 0.11823928356170654
0.3084242045879364 0.308424174785614
rl training, epoch7, iter0, batch225/1133, batch loss:0.308424174785614, Training time:22762.40261077881
batch reward last col mean 0.06762775778770447 first col mean 0.10098732262849808 all mean 0.07763910293579102
0.23880551755428314 0.23880551755428314
rl training, epoch7, iter0, batch226/1133, batch loss:0.23880551755428314, Training time:22763.936826705933
batch reward last col mean 0.09747792780399323 first col mean 0.11663572490215302 all mean 0.10078040510416031
0.2773434817790985 0.2773434817790985
rl training, epoch7, iter0, batch227/1133, batch loss:0.2773434817790985, Training time:22765.533080101013
batch reward last col mean 0.09142091870307922 first col mean 0.12293356657028198 all mean 0.09490244090557098
0.28293031454086304 0.28293028473854065
rl training, epoch7, iter0, batch228/1133, batch loss:0.28293028473854065, Training time:22767.5705909729
batch reward last col mean 0.09613531827926636 first col mean 0.09704635292291641 all mean 0.10138580203056335
0.26294076442718506 0.26294076442718506
rl training, epoch7, iter0, batch229/1133, batch loss:0.26294076442718506, Training time:22769.615835428238
batch reward last col mean 0.13162676990032196 first col mean 0.09282157570123672 all mean 0.12456753849983215
0.31201431155204773 0.31201431155204773
rl training, epoch7, iter0, batch230/1133, batch loss:0.31201431155204773, Training time:22771.750422477722
batch reward last col mean 0.10149645805358887 first col mean 0.10848046839237213 all mean 0.10221592336893082
0.2780269682407379 0.2780269682407379
rl training, epoch7, iter0, batch231/1133, batch loss:0.2780269682407379, Training time:22774.29109430313
batch reward last col mean 0.09830766916275024 first col mean 0.09974279999732971 all mean 0.09571947902441025
0.26999884843826294 0.26999884843826294
rl training, epoch7, iter0, batch232/1133, batch loss:0.26999884843826294, Training time:22775.709758996964
batch reward last col mean 0.07495543360710144 first col mean 0.09811383485794067 all mean 0.08335045725107193
0.2674380838871002 0.2674380838871002
rl training, epoch7, iter0, batch233/1133, batch loss:0.2674380838871002, Training time:22777.400181293488
batch reward last col mean 0.11640749871730804 first col mean 0.10170209407806396 all mean 0.1084345206618309
0.2709912955760956 0.2709912955760956
rl training, epoch7, iter0, batch234/1133, batch loss:0.2709912955760956, Training time:22779.98573946953
batch reward last col mean 0.09292856603860855 first col mean 0.11334383487701416 all mean 0.10010134428739548
0.28395527601242065 0.28395527601242065
rl training, epoch7, iter0, batch235/1133, batch loss:0.28395527601242065, Training time:22781.664510011673
batch reward last col mean 0.09273711591959 first col mean 0.10982318222522736 all mean 0.09363820403814316
0.2733401358127594 0.273340106010437
rl training, epoch7, iter0, batch236/1133, batch loss:0.273340106010437, Training time:22783.60772752762
batch reward last col mean 0.0799202173948288 first col mean 0.10100618749856949 all mean 0.08273984491825104
0.21928106248378754 0.21928104758262634
rl training, epoch7, iter0, batch237/1133, batch loss:0.21928104758262634, Training time:22785.364537000656
batch reward last col mean 0.1137901097536087 first col mean 0.12478366494178772 all mean 0.1138850599527359
0.31685954332351685 0.31685954332351685
rl training, epoch7, iter0, batch238/1133, batch loss:0.31685954332351685, Training time:22787.46368741989
batch reward last col mean 0.08981448411941528 first col mean 0.08713053166866302 all mean 0.09513141959905624
0.2766150236129761 0.2766150236129761
rl training, epoch7, iter0, batch239/1133, batch loss:0.2766150236129761, Training time:22789.165837049484
batch reward last col mean 0.06953628361225128 first col mean 0.11657470464706421 all mean 0.0831507071852684
0.2249775379896164 0.2249775379896164
rl training, epoch7, iter0, batch240/1133, batch loss:0.2249775379896164, Training time:22790.70454263687
batch reward last col mean 0.12926721572875977 first col mean 0.08873127400875092 all mean 0.12297974526882172
0.30804362893104553 0.30804362893104553
rl training, epoch7, iter0, batch241/1133, batch loss:0.30804362893104553, Training time:22792.04786658287
batch reward last col mean 0.11766695231199265 first col mean 0.0947209820151329 all mean 0.11523982137441635
0.2957603931427002 0.2957603931427002
rl training, epoch7, iter0, batch242/1133, batch loss:0.2957603931427002, Training time:22793.80532860756
batch reward last col mean 0.07664142549037933 first col mean 0.11003685742616653 all mean 0.08667289465665817
0.2850908041000366 0.2850908041000366
rl training, epoch7, iter0, batch243/1133, batch loss:0.2850908041000366, Training time:22795.46977710724
batch reward last col mean 0.09775187075138092 first col mean 0.09555108100175858 all mean 0.10060067474842072
0.2942706346511841 0.2942706346511841
rl training, epoch7, iter0, batch244/1133, batch loss:0.2942706346511841, Training time:22797.41287088394
batch reward last col mean 0.13043183088302612 first col mean 0.10604501515626907 all mean 0.12033738195896149
0.3383963406085968 0.3383963406085968
rl training, epoch7, iter0, batch245/1133, batch loss:0.3383963406085968, Training time:22798.721882104874
batch reward last col mean 0.08593225479125977 first col mean 0.11561036109924316 all mean 0.09050749242305756
0.2500646412372589 0.2500646412372589
rl training, epoch7, iter0, batch246/1133, batch loss:0.2500646412372589, Training time:22800.472567796707
batch reward last col mean 0.10183107107877731 first col mean 0.10886691510677338 all mean 0.10378237813711166
0.29782700538635254 0.29782700538635254
rl training, epoch7, iter0, batch247/1133, batch loss:0.29782700538635254, Training time:22802.11121582985
batch reward last col mean 0.08675382286310196 first col mean 0.11754666268825531 all mean 0.09392999112606049
0.29994845390319824 0.29994845390319824
rl training, epoch7, iter0, batch248/1133, batch loss:0.29994845390319824, Training time:22803.97384762764
batch reward last col mean 0.08280929177999496 first col mean 0.10414167493581772 all mean 0.086135633289814
0.2907126247882843 0.2907126247882843
rl training, epoch7, iter0, batch249/1133, batch loss:0.2907126247882843, Training time:22805.773760795593
batch reward last col mean 0.10022515058517456 first col mean 0.10176343470811844 all mean 0.09037017822265625
0.28494301438331604 0.28494298458099365
rl training, epoch7, iter0, batch250/1133, batch loss:0.28494298458099365, Training time:22807.299650669098
batch reward last col mean 0.11565545201301575 first col mean 0.0973922610282898 all mean 0.10703764855861664
0.3210318982601166 0.3210318982601166
rl training, epoch7, iter0, batch251/1133, batch loss:0.3210318982601166, Training time:22808.871104478836
batch reward last col mean 0.06946706026792526 first col mean 0.1056009978055954 all mean 0.08682572096586227
0.26418909430503845 0.26418909430503845
rl training, epoch7, iter0, batch252/1133, batch loss:0.26418909430503845, Training time:22810.18046116829
batch reward last col mean 0.10306094586849213 first col mean 0.13278569281101227 all mean 0.10823959112167358
0.3172169327735901 0.3172169327735901
rl training, epoch7, iter0, batch253/1133, batch loss:0.3172169327735901, Training time:22811.80114555359
batch reward last col mean 0.13554982841014862 first col mean 0.10803656280040741 all mean 0.12646035850048065
0.29062944650650024 0.29062944650650024
rl training, epoch7, iter0, batch254/1133, batch loss:0.29062944650650024, Training time:22813.564930915833
batch reward last col mean 0.11064145714044571 first col mean 0.09099039435386658 all mean 0.10510516911745071
0.3023526668548584 0.3023526668548584
rl training, epoch7, iter0, batch255/1133, batch loss:0.3023526668548584, Training time:22815.23703122139
batch reward last col mean 0.07540027797222137 first col mean 0.09751074761152267 all mean 0.07992158830165863
0.2564224600791931 0.25642240047454834
rl training, epoch7, iter0, batch256/1133, batch loss:0.25642240047454834, Training time:22816.978150606155
batch reward last col mean 0.1317012906074524 first col mean 0.09980840235948563 all mean 0.12242686003446579
0.28752386569976807 0.2875238060951233
rl training, epoch7, iter0, batch257/1133, batch loss:0.2875238060951233, Training time:22818.692967176437
batch reward last col mean 0.13318490982055664 first col mean 0.10844624042510986 all mean 0.11910278350114822
0.3335946798324585 0.3335946798324585
rl training, epoch7, iter0, batch258/1133, batch loss:0.3335946798324585, Training time:22820.743322134018
batch reward last col mean 0.07294297963380814 first col mean 0.09445542097091675 all mean 0.08491969108581543
0.2633751332759857 0.2633751332759857
rl training, epoch7, iter0, batch259/1133, batch loss:0.2633751332759857, Training time:22822.76091003418
batch reward last col mean 0.09474258869886398 first col mean 0.09662327915430069 all mean 0.09352967143058777
0.24908336997032166 0.24908336997032166
rl training, epoch7, iter0, batch260/1133, batch loss:0.24908336997032166, Training time:22824.904695272446
batch reward last col mean 0.08909276872873306 first col mean 0.11289676278829575 all mean 0.09055964648723602
0.2688142955303192 0.2688142955303192
rl training, epoch7, iter0, batch261/1133, batch loss:0.2688142955303192, Training time:22826.679963588715
batch reward last col mean 0.09565968066453934 first col mean 0.10257461667060852 all mean 0.10122333467006683
0.27737191319465637 0.277371883392334
rl training, epoch7, iter0, batch262/1133, batch loss:0.277371883392334, Training time:22828.428097963333
batch reward last col mean 0.11270077526569366 first col mean 0.10133614391088486 all mean 0.10925120860338211
0.30648887157440186 0.30648887157440186
rl training, epoch7, iter0, batch263/1133, batch loss:0.30648887157440186, Training time:22830.19481778145
batch reward last col mean 0.11791449040174484 first col mean 0.11973538249731064 all mean 0.10996313393115997
0.28939828276634216 0.28939828276634216
rl training, epoch7, iter0, batch264/1133, batch loss:0.28939828276634216, Training time:22831.87584543228
batch reward last col mean 0.07057566195726395 first col mean 0.10177770256996155 all mean 0.07919210940599442
0.24112547934055328 0.24112547934055328
rl training, epoch7, iter0, batch265/1133, batch loss:0.24112547934055328, Training time:22833.601092100143
batch reward last col mean 0.09682993590831757 first col mean 0.09842754900455475 all mean 0.09921721369028091
0.28698426485061646 0.28698426485061646
rl training, epoch7, iter0, batch266/1133, batch loss:0.28698426485061646, Training time:22835.6440680027
batch reward last col mean 0.130937859416008 first col mean 0.0983428955078125 all mean 0.11847938597202301
0.25976884365081787 0.25976884365081787
rl training, epoch7, iter0, batch267/1133, batch loss:0.25976884365081787, Training time:22837.463472366333
batch reward last col mean 0.10690172761678696 first col mean 0.09701897203922272 all mean 0.10489164292812347
0.274059921503067 0.274059921503067
rl training, epoch7, iter0, batch268/1133, batch loss:0.274059921503067, Training time:22839.32747244835
batch reward last col mean 0.10842978954315186 first col mean 0.10656978189945221 all mean 0.11632517725229263
0.3463987708091736 0.3463987410068512
rl training, epoch7, iter0, batch269/1133, batch loss:0.3463987410068512, Training time:22840.86768913269
batch reward last col mean 0.1294565051794052 first col mean 0.10299458354711533 all mean 0.12037274241447449
0.32035407423973083 0.32035407423973083
rl training, epoch7, iter0, batch270/1133, batch loss:0.32035407423973083, Training time:22842.60481095314
batch reward last col mean 0.09497860074043274 first col mean 0.10717369616031647 all mean 0.09814155846834183
0.28058281540870667 0.28058281540870667
rl training, epoch7, iter0, batch271/1133, batch loss:0.28058281540870667, Training time:22844.306579113007
batch reward last col mean 0.09936192631721497 first col mean 0.11520568281412125 all mean 0.10138282924890518
0.28351297974586487 0.28351297974586487
rl training, epoch7, iter0, batch272/1133, batch loss:0.28351297974586487, Training time:22845.86308979988
batch reward last col mean 0.07681328058242798 first col mean 0.12201286852359772 all mean 0.09094991534948349
0.28616011142730713 0.28616011142730713
rl training, epoch7, iter0, batch273/1133, batch loss:0.28616011142730713, Training time:22847.88810276985
batch reward last col mean 0.11643710732460022 first col mean 0.12042693048715591 all mean 0.11756587773561478
0.2934471070766449 0.2934471070766449
rl training, epoch7, iter0, batch274/1133, batch loss:0.2934471070766449, Training time:22850.101830244064
batch reward last col mean 0.09900704026222229 first col mean 0.0960991382598877 all mean 0.10142725706100464
0.26753318309783936 0.26753318309783936
rl training, epoch7, iter0, batch275/1133, batch loss:0.26753318309783936, Training time:22852.05253124237
batch reward last col mean 0.09374556690454483 first col mean 0.11188434064388275 all mean 0.09964852035045624
0.2764534056186676 0.2764534056186676
rl training, epoch7, iter0, batch276/1133, batch loss:0.2764534056186676, Training time:22853.72975540161
batch reward last col mean 0.06814795732498169 first col mean 0.120403952896595 all mean 0.07777727395296097
0.2408914715051651 0.2408914715051651
rl training, epoch7, iter0, batch277/1133, batch loss:0.2408914715051651, Training time:22855.5396733284
batch reward last col mean 0.09121181070804596 first col mean 0.1038142740726471 all mean 0.0926046073436737
0.264279305934906 0.264279305934906
rl training, epoch7, iter0, batch278/1133, batch loss:0.264279305934906, Training time:22857.33965396881
batch reward last col mean 0.13631640374660492 first col mean 0.09384295344352722 all mean 0.12938141822814941
0.31307217478752136 0.313072144985199
rl training, epoch7, iter0, batch279/1133, batch loss:0.313072144985199, Training time:22859.564267635345
batch reward last col mean 0.10088106244802475 first col mean 0.0965692400932312 all mean 0.09538836032152176
0.26978757977485657 0.26978757977485657
rl training, epoch7, iter0, batch280/1133, batch loss:0.26978757977485657, Training time:22861.748225927353
batch reward last col mean 0.09996164590120316 first col mean 0.10280716419219971 all mean 0.10774416476488113
0.2851814329624176 0.2851814329624176
rl training, epoch7, iter0, batch281/1133, batch loss:0.2851814329624176, Training time:22863.779445886612
batch reward last col mean 0.08839104324579239 first col mean 0.11812587082386017 all mean 0.09306712448596954
0.2850678563117981 0.2850678563117981
rl training, epoch7, iter0, batch282/1133, batch loss:0.2850678563117981, Training time:22865.582177639008
batch reward last col mean 0.05383690074086189 first col mean 0.09561699628829956 all mean 0.06998896598815918
0.25587841868400574 0.25587841868400574
rl training, epoch7, iter0, batch283/1133, batch loss:0.25587841868400574, Training time:22867.153734207153
batch reward last col mean 0.11166217923164368 first col mean 0.09765598177909851 all mean 0.10700593888759613
0.2896568477153778 0.2896568477153778
rl training, epoch7, iter0, batch284/1133, batch loss:0.2896568477153778, Training time:22869.346034049988
batch reward last col mean 0.0931137204170227 first col mean 0.12154510617256165 all mean 0.0934305265545845
0.24551399052143097 0.24551399052143097
rl training, epoch7, iter0, batch285/1133, batch loss:0.24551399052143097, Training time:22871.173463344574
batch reward last col mean 0.09195586293935776 first col mean 0.10395446419715881 all mean 0.09564193338155746
0.24935764074325562 0.24935764074325562
rl training, epoch7, iter0, batch286/1133, batch loss:0.24935764074325562, Training time:22872.959488868713
batch reward last col mean 0.10083720088005066 first col mean 0.10320492088794708 all mean 0.09608124196529388
0.32032737135887146 0.32032737135887146
rl training, epoch7, iter0, batch287/1133, batch loss:0.32032737135887146, Training time:22874.51763510704
batch reward last col mean 0.08671798557043076 first col mean 0.09760933369398117 all mean 0.09226352721452713
0.26425713300704956 0.26425713300704956
rl training, epoch7, iter0, batch288/1133, batch loss:0.26425713300704956, Training time:22876.506636857986
batch reward last col mean 0.11523588746786118 first col mean 0.10702678561210632 all mean 0.11011376231908798
0.3098652958869934 0.3098652958869934
rl training, epoch7, iter0, batch289/1133, batch loss:0.3098652958869934, Training time:22877.979454755783
batch reward last col mean 0.10960519313812256 first col mean 0.10335038602352142 all mean 0.11021771281957626
0.3218824863433838 0.3218824863433838
rl training, epoch7, iter0, batch290/1133, batch loss:0.3218824863433838, Training time:22879.50679898262
batch reward last col mean 0.12887200713157654 first col mean 0.09686467051506042 all mean 0.1200956478714943
0.2796737253665924 0.2796737253665924
rl training, epoch7, iter0, batch291/1133, batch loss:0.2796737253665924, Training time:22880.817218780518
batch reward last col mean 0.11564147472381592 first col mean 0.11323274672031403 all mean 0.11064463108778
0.32503992319107056 0.32503995299339294
rl training, epoch7, iter0, batch292/1133, batch loss:0.32503995299339294, Training time:22882.229682207108
batch reward last col mean 0.10136784613132477 first col mean 0.10609173774719238 all mean 0.10740526020526886
0.30323007702827454 0.30323007702827454
rl training, epoch7, iter0, batch293/1133, batch loss:0.30323007702827454, Training time:22884.313374757767
batch reward last col mean 0.12523148953914642 first col mean 0.10563009977340698 all mean 0.11842101067304611
0.2893085479736328 0.2893085479736328
rl training, epoch7, iter0, batch294/1133, batch loss:0.2893085479736328, Training time:22885.96359181404
batch reward last col mean 0.1218777447938919 first col mean 0.1160743460059166 all mean 0.11673089861869812
0.2901487946510315 0.2901487946510315
rl training, epoch7, iter0, batch295/1133, batch loss:0.2901487946510315, Training time:22887.465859651566
batch reward last col mean 0.09178037196397781 first col mean 0.10290879756212234 all mean 0.0956415981054306
0.2673761546611786 0.2673761546611786
rl training, epoch7, iter0, batch296/1133, batch loss:0.2673761546611786, Training time:22888.978847503662
batch reward last col mean 0.1299373060464859 first col mean 0.09617991745471954 all mean 0.11911783367395401
0.3174132704734802 0.3174132704734802
rl training, epoch7, iter0, batch297/1133, batch loss:0.3174132704734802, Training time:22890.759040117264
batch reward last col mean 0.0861709713935852 first col mean 0.10146857053041458 all mean 0.09017074853181839
0.2502155005931854 0.2502155005931854
rl training, epoch7, iter0, batch298/1133, batch loss:0.2502155005931854, Training time:22892.64067220688
batch reward last col mean 0.09552836418151855 first col mean 0.13400694727897644 all mean 0.09760499000549316
0.3015627861022949 0.3015627861022949
rl training, epoch7, iter0, batch299/1133, batch loss:0.3015627861022949, Training time:22894.045224428177
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4681684065475363 Time: 95.11729049682617 s
loss of true 0.20131049754339725 loss of gen 0.1710795967363722 loss of other 0.09577831171209689 first score 0.13417309522628784
batch reward last col mean 0.06331729143857956 first col mean 0.09122271835803986 all mean 0.08013150095939636
0.26315784454345703 0.26315784454345703
rl training, epoch7, iter0, batch300/1133, batch loss:0.26315784454345703, Training time:22990.568956375122
batch reward last col mean 0.0941816195845604 first col mean 0.10261920094490051 all mean 0.09702745079994202
0.25938647985458374 0.25938647985458374
rl training, epoch7, iter0, batch301/1133, batch loss:0.25938647985458374, Training time:22992.71511697769
batch reward last col mean 0.1291135847568512 first col mean 0.10646545141935349 all mean 0.12287390977144241
0.2548462748527527 0.2548462748527527
rl training, epoch7, iter0, batch302/1133, batch loss:0.2548462748527527, Training time:22994.308373451233
batch reward last col mean 0.1261289268732071 first col mean 0.09900297224521637 all mean 0.12060210108757019
0.33320921659469604 0.33320921659469604
rl training, epoch7, iter0, batch303/1133, batch loss:0.33320921659469604, Training time:22996.063782691956
batch reward last col mean 0.10610885918140411 first col mean 0.11020415276288986 all mean 0.10210642963647842
0.25594624876976013 0.25594621896743774
rl training, epoch7, iter0, batch304/1133, batch loss:0.25594621896743774, Training time:22997.57484483719
batch reward last col mean 0.09354528039693832 first col mean 0.10355871170759201 all mean 0.0959005281329155
0.3070735037326813 0.3070735037326813
rl training, epoch7, iter0, batch305/1133, batch loss:0.3070735037326813, Training time:22999.151347637177
batch reward last col mean 0.10293861478567123 first col mean 0.10512237250804901 all mean 0.10383255779743195
0.28584593534469604 0.28584593534469604
rl training, epoch7, iter0, batch306/1133, batch loss:0.28584593534469604, Training time:23000.753222703934
batch reward last col mean 0.13155989348888397 first col mean 0.11600290238857269 all mean 0.12246910482645035
0.2895565330982208 0.2895565330982208
rl training, epoch7, iter0, batch307/1133, batch loss:0.2895565330982208, Training time:23002.761502742767
batch reward last col mean 0.09593085944652557 first col mean 0.09453774243593216 all mean 0.10118135064840317
0.2817727029323578 0.2817727029323578
rl training, epoch7, iter0, batch308/1133, batch loss:0.2817727029323578, Training time:23004.54291510582
batch reward last col mean 0.06902486085891724 first col mean 0.09371709823608398 all mean 0.07478033751249313
0.22635410726070404 0.22635410726070404
rl training, epoch7, iter0, batch309/1133, batch loss:0.22635410726070404, Training time:23005.973108291626
batch reward last col mean 0.0723705142736435 first col mean 0.0812964141368866 all mean 0.08346273750066757
0.23375406861305237 0.23375406861305237
rl training, epoch7, iter0, batch310/1133, batch loss:0.23375406861305237, Training time:23007.761768102646
batch reward last col mean 0.0866638720035553 first col mean 0.0959426537156105 all mean 0.08425645530223846
0.2664901614189148 0.2664901614189148
rl training, epoch7, iter0, batch311/1133, batch loss:0.2664901614189148, Training time:23010.22336125374
batch reward last col mean 0.10131081193685532 first col mean 0.10374653339385986 all mean 0.10459744185209274
0.2822020649909973 0.2822020649909973
rl training, epoch7, iter0, batch312/1133, batch loss:0.2822020649909973, Training time:23012.100702047348
batch reward last col mean 0.09154757857322693 first col mean 0.11690419912338257 all mean 0.09739137440919876
0.27114737033843994 0.27114737033843994
rl training, epoch7, iter0, batch313/1133, batch loss:0.27114737033843994, Training time:23013.617141485214
batch reward last col mean 0.10162118822336197 first col mean 0.10798231512308121 all mean 0.10057846456766129
0.25866541266441345 0.25866541266441345
rl training, epoch7, iter0, batch314/1133, batch loss:0.25866541266441345, Training time:23015.341430187225
batch reward last col mean 0.08903272449970245 first col mean 0.10287249833345413 all mean 0.09547771513462067
0.2826659679412842 0.2826659679412842
rl training, epoch7, iter0, batch315/1133, batch loss:0.2826659679412842, Training time:23017.0535800457
batch reward last col mean 0.13266733288764954 first col mean 0.10600587725639343 all mean 0.12394679337739944
0.2702735364437103 0.2702735364437103
rl training, epoch7, iter0, batch316/1133, batch loss:0.2702735364437103, Training time:23018.751431703568
batch reward last col mean 0.11618197709321976 first col mean 0.10259798914194107 all mean 0.10925336182117462
0.2918543517589569 0.2918543517589569
rl training, epoch7, iter0, batch317/1133, batch loss:0.2918543517589569, Training time:23020.48414993286
batch reward last col mean 0.08613811433315277 first col mean 0.10400985926389694 all mean 0.09245176613330841
0.24700097739696503 0.24700097739696503
rl training, epoch7, iter0, batch318/1133, batch loss:0.24700097739696503, Training time:23022.17221546173
batch reward last col mean 0.10964305698871613 first col mean 0.10241788625717163 all mean 0.10870474576950073
0.27674272656440735 0.27674269676208496
rl training, epoch7, iter0, batch319/1133, batch loss:0.27674269676208496, Training time:23024.25342130661
batch reward last col mean 0.08269099146127701 first col mean 0.09303106367588043 all mean 0.08854859322309494
0.24219024181365967 0.24219024181365967
rl training, epoch7, iter0, batch320/1133, batch loss:0.24219024181365967, Training time:23026.035226345062
batch reward last col mean 0.05808219686150551 first col mean 0.11009212583303452 all mean 0.07090561091899872
0.24080972373485565 0.24080972373485565
rl training, epoch7, iter0, batch321/1133, batch loss:0.24080972373485565, Training time:23028.17315888405
batch reward last col mean 0.08052051067352295 first col mean 0.10615561157464981 all mean 0.086944580078125
0.28216877579689026 0.28216877579689026
rl training, epoch7, iter0, batch322/1133, batch loss:0.28216877579689026, Training time:23030.440089702606
batch reward last col mean 0.09429676085710526 first col mean 0.101047083735466 all mean 0.09591501206159592
0.2799083888530731 0.27990835905075073
rl training, epoch7, iter0, batch323/1133, batch loss:0.27990835905075073, Training time:23033.266891241074
batch reward last col mean 0.09378685802221298 first col mean 0.12030745297670364 all mean 0.09985784441232681
0.2656155526638031 0.2656155526638031
rl training, epoch7, iter0, batch324/1133, batch loss:0.2656155526638031, Training time:23034.85601592064
batch reward last col mean 0.11005495488643646 first col mean 0.1050458699464798 all mean 0.10828322172164917
0.2743529677391052 0.2743529677391052
rl training, epoch7, iter0, batch325/1133, batch loss:0.2743529677391052, Training time:23036.464703559875
batch reward last col mean 0.06967233866453171 first col mean 0.09886449575424194 all mean 0.08509467542171478
0.2739468812942505 0.2739468514919281
rl training, epoch7, iter0, batch326/1133, batch loss:0.2739468514919281, Training time:23038.29540371895
batch reward last col mean 0.10370499640703201 first col mean 0.124757781624794 all mean 0.10159584134817123
0.27091437578201294 0.27091437578201294
rl training, epoch7, iter0, batch327/1133, batch loss:0.27091437578201294, Training time:23039.863647460938
batch reward last col mean 0.10919759422540665 first col mean 0.1250089555978775 all mean 0.10835712403059006
0.28814998269081116 0.28815001249313354
rl training, epoch7, iter0, batch328/1133, batch loss:0.28815001249313354, Training time:23042.18082332611
batch reward last col mean 0.06767348945140839 first col mean 0.10024522244930267 all mean 0.07632006704807281
0.24585427343845367 0.24585427343845367
rl training, epoch7, iter0, batch329/1133, batch loss:0.24585427343845367, Training time:23043.93315386772
batch reward last col mean 0.10184134542942047 first col mean 0.11989088356494904 all mean 0.10247725248336792
0.2839081585407257 0.2839081585407257
rl training, epoch7, iter0, batch330/1133, batch loss:0.2839081585407257, Training time:23045.561209201813
batch reward last col mean 0.10734545439481735 first col mean 0.10022466629743576 all mean 0.10372527688741684
0.262159526348114 0.262159526348114
rl training, epoch7, iter0, batch331/1133, batch loss:0.262159526348114, Training time:23047.231984376907
batch reward last col mean 0.09934815764427185 first col mean 0.08788606524467468 all mean 0.10112541168928146
0.2915383279323578 0.2915383279323578
rl training, epoch7, iter0, batch332/1133, batch loss:0.2915383279323578, Training time:23048.651569843292
batch reward last col mean 0.06532418727874756 first col mean 0.0814075618982315 all mean 0.07176891714334488
0.2353314459323883 0.2353314459323883
rl training, epoch7, iter0, batch333/1133, batch loss:0.2353314459323883, Training time:23050.38347864151
batch reward last col mean 0.09211799502372742 first col mean 0.10770254582166672 all mean 0.09674733132123947
0.2875310480594635 0.2875310480594635
rl training, epoch7, iter0, batch334/1133, batch loss:0.2875310480594635, Training time:23052.49575161934
batch reward last col mean 0.12033736705780029 first col mean 0.08783809840679169 all mean 0.11401992291212082
0.2896650433540344 0.2896650433540344
rl training, epoch7, iter0, batch335/1133, batch loss:0.2896650433540344, Training time:23053.938314437866
batch reward last col mean 0.08863832801580429 first col mean 0.10278870910406113 all mean 0.09463920444250107
0.2811019718647003 0.2811019718647003
rl training, epoch7, iter0, batch336/1133, batch loss:0.2811019718647003, Training time:23055.400307416916
batch reward last col mean 0.08751179277896881 first col mean 0.0964115709066391 all mean 0.08531314879655838
0.2401484102010727 0.2401484102010727
rl training, epoch7, iter0, batch337/1133, batch loss:0.2401484102010727, Training time:23057.423584222794
batch reward last col mean 0.07355745136737823 first col mean 0.11599463224411011 all mean 0.0836106464266777
0.2668951153755188 0.2668951153755188
rl training, epoch7, iter0, batch338/1133, batch loss:0.2668951153755188, Training time:23058.964402914047
batch reward last col mean 0.08285979926586151 first col mean 0.09535761177539825 all mean 0.08727193623781204
0.2584933936595917 0.2584933936595917
rl training, epoch7, iter0, batch339/1133, batch loss:0.2584933936595917, Training time:23060.935157060623
batch reward last col mean 0.11740044504404068 first col mean 0.10509194433689117 all mean 0.11335428059101105
0.2864959239959717 0.2864959239959717
rl training, epoch7, iter0, batch340/1133, batch loss:0.2864959239959717, Training time:23062.83301115036
batch reward last col mean 0.10196509957313538 first col mean 0.10195977240800858 all mean 0.10350493341684341
0.25757309794425964 0.25757309794425964
rl training, epoch7, iter0, batch341/1133, batch loss:0.25757309794425964, Training time:23064.921410799026
batch reward last col mean 0.12607355415821075 first col mean 0.10186096280813217 all mean 0.11365582048892975
0.29782021045684814 0.29782021045684814
rl training, epoch7, iter0, batch342/1133, batch loss:0.29782021045684814, Training time:23066.663403511047
batch reward last col mean 0.0826164186000824 first col mean 0.11008739471435547 all mean 0.0943208858370781
0.3208029270172119 0.3208029270172119
rl training, epoch7, iter0, batch343/1133, batch loss:0.3208029270172119, Training time:23068.22931456566
batch reward last col mean 0.07550106942653656 first col mean 0.10039494931697845 all mean 0.08613310754299164
0.27301859855651855 0.27301859855651855
rl training, epoch7, iter0, batch344/1133, batch loss:0.27301859855651855, Training time:23070.065281391144
batch reward last col mean 0.09633631259202957 first col mean 0.09704417735338211 all mean 0.09640324860811234
0.2722785174846649 0.2722785174846649
rl training, epoch7, iter0, batch345/1133, batch loss:0.2722785174846649, Training time:23072.69665455818
batch reward last col mean 0.11307276785373688 first col mean 0.09060454368591309 all mean 0.10598210990428925
0.27854135632514954 0.27854135632514954
rl training, epoch7, iter0, batch346/1133, batch loss:0.27854135632514954, Training time:23074.696853876114
batch reward last col mean 0.10360267758369446 first col mean 0.10975885391235352 all mean 0.10114125907421112
0.2591712176799774 0.2591712176799774
rl training, epoch7, iter0, batch347/1133, batch loss:0.2591712176799774, Training time:23076.376398563385
batch reward last col mean 0.1360577940940857 first col mean 0.09075423330068588 all mean 0.12758095562458038
0.2949041724205017 0.2949041724205017
rl training, epoch7, iter0, batch348/1133, batch loss:0.2949041724205017, Training time:23078.22456240654
batch reward last col mean 0.0952281802892685 first col mean 0.09604280441999435 all mean 0.09395315498113632
0.265996515750885 0.265996515750885
rl training, epoch7, iter0, batch349/1133, batch loss:0.265996515750885, Training time:23079.76256299019
batch reward last col mean 0.11995941400527954 first col mean 0.11622162163257599 all mean 0.11472738534212112
0.3208206593990326 0.3208206593990326
rl training, epoch7, iter0, batch350/1133, batch loss:0.3208206593990326, Training time:23081.480308532715
batch reward last col mean 0.10802201181650162 first col mean 0.09585414081811905 all mean 0.10693352669477463
0.28447529673576355 0.28447529673576355
rl training, epoch7, iter0, batch351/1133, batch loss:0.28447529673576355, Training time:23083.52868938446
batch reward last col mean 0.0677599236369133 first col mean 0.09069155156612396 all mean 0.0737413689494133
0.2402603179216385 0.2402603030204773
rl training, epoch7, iter0, batch352/1133, batch loss:0.2402603030204773, Training time:23085.167888879776
batch reward last col mean 0.12323020398616791 first col mean 0.11657533049583435 all mean 0.1214049905538559
0.26816147565841675 0.26816147565841675
rl training, epoch7, iter0, batch353/1133, batch loss:0.26816147565841675, Training time:23086.567739248276
batch reward last col mean 0.14196369051933289 first col mean 0.1258171796798706 all mean 0.13460829854011536
0.3041533827781677 0.3041533827781677
rl training, epoch7, iter0, batch354/1133, batch loss:0.3041533827781677, Training time:23088.78391647339
batch reward last col mean 0.09126978367567062 first col mean 0.10253036022186279 all mean 0.09002001583576202
0.22847409546375275 0.22847409546375275
rl training, epoch7, iter0, batch355/1133, batch loss:0.22847409546375275, Training time:23090.68725681305
batch reward last col mean 0.13087265193462372 first col mean 0.1279226690530777 all mean 0.12580162286758423
0.3032958507537842 0.3032958507537842
rl training, epoch7, iter0, batch356/1133, batch loss:0.3032958507537842, Training time:23092.798851013184
batch reward last col mean 0.10392381995916367 first col mean 0.10525161027908325 all mean 0.10161508619785309
0.2903914451599121 0.2903914749622345
rl training, epoch7, iter0, batch357/1133, batch loss:0.2903914749622345, Training time:23094.4176030159
batch reward last col mean 0.08497852832078934 first col mean 0.09094372391700745 all mean 0.09119889885187149
0.2681027054786682 0.2681027054786682
rl training, epoch7, iter0, batch358/1133, batch loss:0.2681027054786682, Training time:23096.005618810654
batch reward last col mean 0.10490094125270844 first col mean 0.11703468859195709 all mean 0.10555122792720795
0.28145503997802734 0.28145503997802734
rl training, epoch7, iter0, batch359/1133, batch loss:0.28145503997802734, Training time:23097.83240056038
batch reward last col mean 0.09748675674200058 first col mean 0.10408934205770493 all mean 0.10272280126810074
0.27245470881462097 0.27245470881462097
rl training, epoch7, iter0, batch360/1133, batch loss:0.27245470881462097, Training time:23099.388493061066
batch reward last col mean 0.14028222858905792 first col mean 0.09880589693784714 all mean 0.13042213022708893
0.30338266491889954 0.30338263511657715
rl training, epoch7, iter0, batch361/1133, batch loss:0.30338263511657715, Training time:23101.352978229523
batch reward last col mean 0.1084945946931839 first col mean 0.12907083332538605 all mean 0.11065737158060074
0.334898442029953 0.334898442029953
rl training, epoch7, iter0, batch362/1133, batch loss:0.334898442029953, Training time:23103.09716320038
batch reward last col mean 0.09665452688932419 first col mean 0.1015271246433258 all mean 0.10277750343084335
0.2905106246471405 0.2905106246471405
rl training, epoch7, iter0, batch363/1133, batch loss:0.2905106246471405, Training time:23104.578244686127
batch reward last col mean 0.09670275449752808 first col mean 0.10668940097093582 all mean 0.0974162220954895
0.2799887955188751 0.2799887955188751
rl training, epoch7, iter0, batch364/1133, batch loss:0.2799887955188751, Training time:23107.156338214874
batch reward last col mean 0.07912185043096542 first col mean 0.09079962968826294 all mean 0.0882011204957962
0.23661617934703827 0.23661617934703827
rl training, epoch7, iter0, batch365/1133, batch loss:0.23661617934703827, Training time:23108.66539478302
batch reward last col mean 0.09362663328647614 first col mean 0.11613127589225769 all mean 0.09981997311115265
0.29311811923980713 0.29311811923980713
rl training, epoch7, iter0, batch366/1133, batch loss:0.29311811923980713, Training time:23110.32570028305
batch reward last col mean 0.08384022116661072 first col mean 0.11577711254358292 all mean 0.09062902629375458
0.2692165672779083 0.2692165672779083
rl training, epoch7, iter0, batch367/1133, batch loss:0.2692165672779083, Training time:23112.425277471542
batch reward last col mean 0.0883813425898552 first col mean 0.11644013226032257 all mean 0.09759927541017532
0.27615875005722046 0.2761586904525757
rl training, epoch7, iter0, batch368/1133, batch loss:0.2761586904525757, Training time:23114.010434389114
batch reward last col mean 0.07793830335140228 first col mean 0.09872680902481079 all mean 0.08798666298389435
0.26657792925834656 0.26657792925834656
rl training, epoch7, iter0, batch369/1133, batch loss:0.26657792925834656, Training time:23115.925013780594
batch reward last col mean 0.10556907951831818 first col mean 0.08936341106891632 all mean 0.09603987634181976
0.25124508142471313 0.25124508142471313
rl training, epoch7, iter0, batch370/1133, batch loss:0.25124508142471313, Training time:23117.454293251038
batch reward last col mean 0.06052640452980995 first col mean 0.1146836131811142 all mean 0.07372616231441498
0.26373061537742615 0.26373061537742615
rl training, epoch7, iter0, batch371/1133, batch loss:0.26373061537742615, Training time:23119.12664914131
batch reward last col mean 0.10486049205064774 first col mean 0.11726990342140198 all mean 0.10804492235183716
0.3095996677875519 0.3095996677875519
rl training, epoch7, iter0, batch372/1133, batch loss:0.3095996677875519, Training time:23120.553645133972
batch reward last col mean 0.09427313506603241 first col mean 0.11081589758396149 all mean 0.10149434208869934
0.2822279632091522 0.28222793340682983
rl training, epoch7, iter0, batch373/1133, batch loss:0.28222793340682983, Training time:23122.803632974625
batch reward last col mean 0.0910143032670021 first col mean 0.09084191918373108 all mean 0.09694062173366547
0.2880205810070038 0.2880205810070038
rl training, epoch7, iter0, batch374/1133, batch loss:0.2880205810070038, Training time:23124.766859054565
batch reward last col mean 0.11322934925556183 first col mean 0.10808071494102478 all mean 0.10726886242628098
0.2935152053833008 0.2935151755809784
rl training, epoch7, iter0, batch375/1133, batch loss:0.2935151755809784, Training time:23127.49611711502
batch reward last col mean 0.09383843839168549 first col mean 0.1139768660068512 all mean 0.10021240264177322
0.3043864071369171 0.3043864071369171
rl training, epoch7, iter0, batch376/1133, batch loss:0.3043864071369171, Training time:23129.446845054626
batch reward last col mean 0.11354272067546844 first col mean 0.09954001009464264 all mean 0.11143816262483597
0.2760077118873596 0.2760077118873596
rl training, epoch7, iter0, batch377/1133, batch loss:0.2760077118873596, Training time:23131.119745731354
batch reward last col mean 0.13450650870800018 first col mean 0.10087157040834427 all mean 0.1296103149652481
0.29740193486213684 0.29740193486213684
rl training, epoch7, iter0, batch378/1133, batch loss:0.29740193486213684, Training time:23132.77389025688
batch reward last col mean 0.09617442637681961 first col mean 0.10984303802251816 all mean 0.0961914137005806
0.25104162096977234 0.25104162096977234
rl training, epoch7, iter0, batch379/1133, batch loss:0.25104162096977234, Training time:23134.9597761631
batch reward last col mean 0.13233281672000885 first col mean 0.10342388600111008 all mean 0.11961188167333603
0.3021053075790405 0.3021053075790405
rl training, epoch7, iter0, batch380/1133, batch loss:0.3021053075790405, Training time:23136.697846889496
batch reward last col mean 0.10137967765331268 first col mean 0.11875257641077042 all mean 0.09748848527669907
0.2769688069820404 0.2769688069820404
rl training, epoch7, iter0, batch381/1133, batch loss:0.2769688069820404, Training time:23138.84471845627
batch reward last col mean 0.09902489930391312 first col mean 0.11106289178133011 all mean 0.10350432991981506
0.2845405042171478 0.2845405340194702
rl training, epoch7, iter0, batch382/1133, batch loss:0.2845405340194702, Training time:23140.703966379166
batch reward last col mean 0.09643329679965973 first col mean 0.10900253802537918 all mean 0.1045495942234993
0.2911248207092285 0.2911248207092285
rl training, epoch7, iter0, batch383/1133, batch loss:0.2911248207092285, Training time:23142.32540678978
batch reward last col mean 0.08846193552017212 first col mean 0.09708693623542786 all mean 0.09041690081357956
0.26118460297584534 0.26118460297584534
rl training, epoch7, iter0, batch384/1133, batch loss:0.26118460297584534, Training time:23144.08824324608
batch reward last col mean 0.07905427366495132 first col mean 0.11956840753555298 all mean 0.08799505233764648
0.2526426315307617 0.2526426315307617
rl training, epoch7, iter0, batch385/1133, batch loss:0.2526426315307617, Training time:23146.143869400024
batch reward last col mean 0.0976816937327385 first col mean 0.09842091053724289 all mean 0.10121909528970718
0.26835447549819946 0.26835447549819946
rl training, epoch7, iter0, batch386/1133, batch loss:0.26835447549819946, Training time:23148.527187108994
batch reward last col mean 0.1106685921549797 first col mean 0.09031696617603302 all mean 0.10682995617389679
0.2704121470451355 0.2704121470451355
rl training, epoch7, iter0, batch387/1133, batch loss:0.2704121470451355, Training time:23150.14094686508
batch reward last col mean 0.08071892708539963 first col mean 0.09280797839164734 all mean 0.0886625126004219
0.27565568685531616 0.27565568685531616
rl training, epoch7, iter0, batch388/1133, batch loss:0.27565568685531616, Training time:23152.597236156464
batch reward last col mean 0.11073563992977142 first col mean 0.12341826409101486 all mean 0.10950898379087448
0.2650719881057739 0.2650719881057739
rl training, epoch7, iter0, batch389/1133, batch loss:0.2650719881057739, Training time:23154.52374958992
batch reward last col mean 0.1260787397623062 first col mean 0.1189822107553482 all mean 0.12374831736087799
0.3344052731990814 0.3344053030014038
rl training, epoch7, iter0, batch390/1133, batch loss:0.3344053030014038, Training time:23156.592367887497
batch reward last col mean 0.07528919726610184 first col mean 0.11669951677322388 all mean 0.08687840402126312
0.26525387167930603 0.26525387167930603
rl training, epoch7, iter0, batch391/1133, batch loss:0.26525387167930603, Training time:23158.106477737427
batch reward last col mean 0.10610103607177734 first col mean 0.10812076181173325 all mean 0.10421586781740189
0.2713017761707306 0.2713017761707306
rl training, epoch7, iter0, batch392/1133, batch loss:0.2713017761707306, Training time:23160.270395994186
batch reward last col mean 0.10274557769298553 first col mean 0.0976981371641159 all mean 0.10345915704965591
0.2538989186286926 0.2538989186286926
rl training, epoch7, iter0, batch393/1133, batch loss:0.2538989186286926, Training time:23162.028504371643
batch reward last col mean 0.12978023290634155 first col mean 0.08625049889087677 all mean 0.11827763170003891
0.2633642256259918 0.2633642554283142
rl training, epoch7, iter0, batch394/1133, batch loss:0.2633642554283142, Training time:23164.36468553543
batch reward last col mean 0.11000625789165497 first col mean 0.11153049767017365 all mean 0.10946948826313019
0.31608647108078003 0.31608647108078003
rl training, epoch7, iter0, batch395/1133, batch loss:0.31608647108078003, Training time:23166.698434114456
batch reward last col mean 0.11414321511983871 first col mean 0.114969402551651 all mean 0.12001492083072662
0.2790064811706543 0.2790064811706543
rl training, epoch7, iter0, batch396/1133, batch loss:0.2790064811706543, Training time:23168.585189580917
batch reward last col mean 0.09515774995088577 first col mean 0.11743922531604767 all mean 0.09635515511035919
0.2753770053386688 0.2753770053386688
rl training, epoch7, iter0, batch397/1133, batch loss:0.2753770053386688, Training time:23170.651820898056
batch reward last col mean 0.1082252562046051 first col mean 0.10824566334486008 all mean 0.10736367851495743
0.27506574988365173 0.27506574988365173
rl training, epoch7, iter0, batch398/1133, batch loss:0.27506574988365173, Training time:23173.065355539322
batch reward last col mean 0.10918949544429779 first col mean 0.12525740265846252 all mean 0.10618291050195694
0.26377561688423157 0.26377561688423157
rl training, epoch7, iter0, batch399/1133, batch loss:0.26377561688423157, Training time:23174.896476507187
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.468368243021662 Time: 95.0307993888855 s
loss of true 0.20205220889829473 loss of gen 0.16986474159378345 loss of other 0.09645129318224942 first score 0.13173538446426392
batch reward last col mean 0.08369327336549759 first col mean 0.10830479860305786 all mean 0.09123791009187698
0.2446610927581787 0.24466107785701752
rl training, epoch7, iter0, batch400/1133, batch loss:0.24466107785701752, Training time:23271.92512702942
batch reward last col mean 0.08219178020954132 first col mean 0.10660573840141296 all mean 0.08971752226352692
0.26519468426704407 0.2651946544647217
rl training, epoch7, iter0, batch401/1133, batch loss:0.2651946544647217, Training time:23274.10026025772
batch reward last col mean 0.07282160967588425 first col mean 0.11701296269893646 all mean 0.07864800095558167
0.24690455198287964 0.24690455198287964
rl training, epoch7, iter0, batch402/1133, batch loss:0.24690455198287964, Training time:23277.17175078392
batch reward last col mean 0.08886393904685974 first col mean 0.1066766232252121 all mean 0.09446270018815994
0.2669528126716614 0.2669528126716614
rl training, epoch7, iter0, batch403/1133, batch loss:0.2669528126716614, Training time:23279.19504380226
batch reward last col mean 0.09316739439964294 first col mean 0.10428430885076523 all mean 0.10103549063205719
0.2655491530895233 0.2655491530895233
rl training, epoch7, iter0, batch404/1133, batch loss:0.2655491530895233, Training time:23280.92293214798
batch reward last col mean 0.09406408667564392 first col mean 0.11623115092515945 all mean 0.10048408806324005
0.29473036527633667 0.2947303354740143
rl training, epoch7, iter0, batch405/1133, batch loss:0.2947303354740143, Training time:23283.008450746536
batch reward last col mean 0.10204093158245087 first col mean 0.11092740297317505 all mean 0.10601356625556946
0.2955538034439087 0.2955537736415863
rl training, epoch7, iter0, batch406/1133, batch loss:0.2955537736415863, Training time:23284.839517354965
batch reward last col mean 0.11690577864646912 first col mean 0.11043640226125717 all mean 0.11865673959255219
0.2892898917198181 0.2892898917198181
rl training, epoch7, iter0, batch407/1133, batch loss:0.2892898917198181, Training time:23286.670007944107
batch reward last col mean 0.14397192001342773 first col mean 0.10551709681749344 all mean 0.13365505635738373
0.3062603175640106 0.306260347366333
rl training, epoch7, iter0, batch408/1133, batch loss:0.306260347366333, Training time:23288.42311477661
batch reward last col mean 0.08089892566204071 first col mean 0.11669094860553741 all mean 0.08881115168333054
0.2551054060459137 0.2551054060459137
rl training, epoch7, iter0, batch409/1133, batch loss:0.2551054060459137, Training time:23290.57772374153
batch reward last col mean 0.10050977766513824 first col mean 0.1241988092660904 all mean 0.10486532747745514
0.2854028642177582 0.2854028642177582
rl training, epoch7, iter0, batch410/1133, batch loss:0.2854028642177582, Training time:23292.34347486496
batch reward last col mean 0.10719893127679825 first col mean 0.10562943667173386 all mean 0.10506860911846161
0.26633867621421814 0.26633867621421814
rl training, epoch7, iter0, batch411/1133, batch loss:0.26633867621421814, Training time:23294.024364471436
batch reward last col mean 0.10805496573448181 first col mean 0.11939072608947754 all mean 0.10793961584568024
0.2893981635570526 0.2893981635570526
rl training, epoch7, iter0, batch412/1133, batch loss:0.2893981635570526, Training time:23295.66201066971
batch reward last col mean 0.13080069422721863 first col mean 0.13249070942401886 all mean 0.1161295622587204
0.27770644426345825 0.27770644426345825
rl training, epoch7, iter0, batch413/1133, batch loss:0.27770644426345825, Training time:23297.34726381302
batch reward last col mean 0.12485486268997192 first col mean 0.08976365625858307 all mean 0.11854783445596695
0.2796100676059723 0.2796100676059723
rl training, epoch7, iter0, batch414/1133, batch loss:0.2796100676059723, Training time:23299.13563799858
batch reward last col mean 0.1315353363752365 first col mean 0.10363662242889404 all mean 0.12689067423343658
0.3002690374851227 0.3002690374851227
rl training, epoch7, iter0, batch415/1133, batch loss:0.3002690374851227, Training time:23301.08355307579
batch reward last col mean 0.0787893533706665 first col mean 0.10252245515584946 all mean 0.0864332914352417
0.27047792077064514 0.27047792077064514
rl training, epoch7, iter0, batch416/1133, batch loss:0.27047792077064514, Training time:23303.08535051346
batch reward last col mean 0.08987229317426682 first col mean 0.10394169390201569 all mean 0.09626046568155289
0.2581457197666168 0.2581457197666168
rl training, epoch7, iter0, batch417/1133, batch loss:0.2581457197666168, Training time:23304.904691696167
batch reward last col mean 0.09028162062168121 first col mean 0.12681016325950623 all mean 0.10083449631929398
0.2732633352279663 0.2732633352279663
rl training, epoch7, iter0, batch418/1133, batch loss:0.2732633352279663, Training time:23306.75100684166
batch reward last col mean 0.11614605039358139 first col mean 0.11056257784366608 all mean 0.10600610822439194
0.2811311185359955 0.2811311185359955
rl training, epoch7, iter0, batch419/1133, batch loss:0.2811311185359955, Training time:23308.58971810341
batch reward last col mean 0.09425750374794006 first col mean 0.10036655515432358 all mean 0.09929854422807693
0.2909606397151947 0.2909606397151947
rl training, epoch7, iter0, batch420/1133, batch loss:0.2909606397151947, Training time:23310.517334461212
batch reward last col mean 0.10733222961425781 first col mean 0.09810072928667068 all mean 0.10159385204315186
0.2901407480239868 0.2901407480239868
rl training, epoch7, iter0, batch421/1133, batch loss:0.2901407480239868, Training time:23312.559469223022
batch reward last col mean 0.09277338534593582 first col mean 0.1119709312915802 all mean 0.09932037442922592
0.2842092216014862 0.2842091917991638
rl training, epoch7, iter0, batch422/1133, batch loss:0.2842091917991638, Training time:23314.12464404106
batch reward last col mean 0.1010081097483635 first col mean 0.10920362919569016 all mean 0.10963310301303864
0.3140961527824402 0.3140961527824402
rl training, epoch7, iter0, batch423/1133, batch loss:0.3140961527824402, Training time:23315.757130861282
batch reward last col mean 0.12041950225830078 first col mean 0.109535813331604 all mean 0.11931785941123962
0.28751683235168457 0.28751683235168457
rl training, epoch7, iter0, batch424/1133, batch loss:0.28751683235168457, Training time:23317.659379720688
batch reward last col mean 0.11927249282598495 first col mean 0.09925287961959839 all mean 0.11655449867248535
0.3001914620399475 0.3001914620399475
rl training, epoch7, iter0, batch425/1133, batch loss:0.3001914620399475, Training time:23319.537187576294
batch reward last col mean 0.06915176659822464 first col mean 0.11334150284528732 all mean 0.07488606125116348
0.22353942692279816 0.22353944182395935
rl training, epoch7, iter0, batch426/1133, batch loss:0.22353944182395935, Training time:23322.35260272026
batch reward last col mean 0.07933676987886429 first col mean 0.10656808316707611 all mean 0.08631134033203125
0.2938297688961029 0.2938297688961029
rl training, epoch7, iter0, batch427/1133, batch loss:0.2938297688961029, Training time:23324.05876493454
batch reward last col mean 0.11837291717529297 first col mean 0.09428627789020538 all mean 0.11837977916002274
0.2866111993789673 0.2866111993789673
rl training, epoch7, iter0, batch428/1133, batch loss:0.2866111993789673, Training time:23326.436547279358
batch reward last col mean 0.1361343115568161 first col mean 0.11408835649490356 all mean 0.12754014134407043
0.3087291419506073 0.3087291717529297
rl training, epoch7, iter0, batch429/1133, batch loss:0.3087291717529297, Training time:23328.079164505005
batch reward last col mean 0.11040321737527847 first col mean 0.09987825155258179 all mean 0.10960885882377625
0.3138304650783539 0.3138304650783539
rl training, epoch7, iter0, batch430/1133, batch loss:0.3138304650783539, Training time:23330.23306441307
batch reward last col mean 0.0893247127532959 first col mean 0.10590457916259766 all mean 0.09168405830860138
0.29124099016189575 0.29124099016189575
rl training, epoch7, iter0, batch431/1133, batch loss:0.29124099016189575, Training time:23332.583768606186
batch reward last col mean 0.11238890886306763 first col mean 0.09950313717126846 all mean 0.10305169969797134
0.26881468296051025 0.26881468296051025
rl training, epoch7, iter0, batch432/1133, batch loss:0.26881468296051025, Training time:23334.41846895218
batch reward last col mean 0.12516729533672333 first col mean 0.11143378168344498 all mean 0.12374390661716461
0.2784774899482727 0.2784774899482727
rl training, epoch7, iter0, batch433/1133, batch loss:0.2784774899482727, Training time:23337.454985380173
batch reward last col mean 0.13931557536125183 first col mean 0.10409233719110489 all mean 0.13292428851127625
0.3572070896625519 0.3572070896625519
rl training, epoch7, iter0, batch434/1133, batch loss:0.3572070896625519, Training time:23339.504006147385
batch reward last col mean 0.09661902487277985 first col mean 0.10794393718242645 all mean 0.09986775368452072
0.26083871722221375 0.26083871722221375
rl training, epoch7, iter0, batch435/1133, batch loss:0.26083871722221375, Training time:23341.267634391785
batch reward last col mean 0.07544417679309845 first col mean 0.12906071543693542 all mean 0.08775880932807922
0.2871015667915344 0.2871015965938568
rl training, epoch7, iter0, batch436/1133, batch loss:0.2871015965938568, Training time:23342.972167491913
batch reward last col mean 0.14074592292308807 first col mean 0.10650846362113953 all mean 0.13048294186592102
0.3030884265899658 0.3030884265899658
rl training, epoch7, iter0, batch437/1133, batch loss:0.3030884265899658, Training time:23345.223936080933
batch reward last col mean 0.10814092308282852 first col mean 0.11230745911598206 all mean 0.10865791887044907
0.28227460384368896 0.28227460384368896
rl training, epoch7, iter0, batch438/1133, batch loss:0.28227460384368896, Training time:23346.975014925003
batch reward last col mean 0.09824081510305405 first col mean 0.10019824653863907 all mean 0.10386382043361664
0.3068326413631439 0.3068326413631439
rl training, epoch7, iter0, batch439/1133, batch loss:0.3068326413631439, Training time:23349.03934955597
batch reward last col mean 0.10747617483139038 first col mean 0.11555909365415573 all mean 0.10281029343605042
0.2713141441345215 0.2713141441345215
rl training, epoch7, iter0, batch440/1133, batch loss:0.2713141441345215, Training time:23351.70118355751
batch reward last col mean 0.11621589958667755 first col mean 0.10929183661937714 all mean 0.1097530946135521
0.3093484938144684 0.3093484938144684
rl training, epoch7, iter0, batch441/1133, batch loss:0.3093484938144684, Training time:23353.679577112198
batch reward last col mean 0.11209586262702942 first col mean 0.1431083381175995 all mean 0.11290577799081802
0.32239124178886414 0.32239124178886414
rl training, epoch7, iter0, batch442/1133, batch loss:0.32239124178886414, Training time:23355.57302713394
batch reward last col mean 0.11184139549732208 first col mean 0.09348164498806 all mean 0.10241038352251053
0.28225278854370117 0.28225278854370117
rl training, epoch7, iter0, batch443/1133, batch loss:0.28225278854370117, Training time:23356.944244861603
batch reward last col mean 0.10368164628744125 first col mean 0.11750420182943344 all mean 0.10311807692050934
0.2762748599052429 0.2762748599052429
rl training, epoch7, iter0, batch444/1133, batch loss:0.2762748599052429, Training time:23358.56805086136
batch reward last col mean 0.10189444571733475 first col mean 0.10399017482995987 all mean 0.09831778705120087
0.2767254412174225 0.2767254114151001
rl training, epoch7, iter0, batch445/1133, batch loss:0.2767254114151001, Training time:23360.623423576355
batch reward last col mean 0.08073580265045166 first col mean 0.10871843248605728 all mean 0.08248621970415115
0.302749365568161 0.302749365568161
rl training, epoch7, iter0, batch446/1133, batch loss:0.302749365568161, Training time:23363.787333488464
batch reward last col mean 0.10433607548475266 first col mean 0.10330244898796082 all mean 0.10105607658624649
0.26667436957359314 0.26667436957359314
rl training, epoch7, iter0, batch447/1133, batch loss:0.26667436957359314, Training time:23365.807815790176
batch reward last col mean 0.08006678521633148 first col mean 0.10344980657100677 all mean 0.08758784830570221
0.2641688287258148 0.2641688287258148
rl training, epoch7, iter0, batch448/1133, batch loss:0.2641688287258148, Training time:23368.09925341606
batch reward last col mean 0.11190590262413025 first col mean 0.12062177062034607 all mean 0.11283601075410843
0.2695859372615814 0.26958590745925903
rl training, epoch7, iter0, batch449/1133, batch loss:0.26958590745925903, Training time:23369.674449920654
batch reward last col mean 0.09939184039831161 first col mean 0.11072344332933426 all mean 0.10317973047494888
0.2938046157360077 0.2938046157360077
rl training, epoch7, iter0, batch450/1133, batch loss:0.2938046157360077, Training time:23371.447251558304
batch reward last col mean 0.10085275024175644 first col mean 0.09750613570213318 all mean 0.09957903623580933
0.25671839714050293 0.25671839714050293
rl training, epoch7, iter0, batch451/1133, batch loss:0.25671839714050293, Training time:23373.18222784996
batch reward last col mean 0.1033397912979126 first col mean 0.10781829804182053 all mean 0.10417033731937408
0.30273619294166565 0.30273619294166565
rl training, epoch7, iter0, batch452/1133, batch loss:0.30273619294166565, Training time:23375.362097501755
batch reward last col mean 0.12324665486812592 first col mean 0.09967201203107834 all mean 0.11156519502401352
0.2940503656864166 0.2940503656864166
rl training, epoch7, iter0, batch453/1133, batch loss:0.2940503656864166, Training time:23377.276257753372
batch reward last col mean 0.10837128013372421 first col mean 0.11116810142993927 all mean 0.10814829915761948
0.30671581625938416 0.30671581625938416
rl training, epoch7, iter0, batch454/1133, batch loss:0.30671581625938416, Training time:23378.67680478096
batch reward last col mean 0.11068025231361389 first col mean 0.1219765841960907 all mean 0.11001218855381012
0.29405075311660767 0.29405075311660767
rl training, epoch7, iter0, batch455/1133, batch loss:0.29405075311660767, Training time:23380.125155448914
batch reward last col mean 0.14870640635490417 first col mean 0.10064835846424103 all mean 0.14106082916259766
0.3313159644603729 0.3313159644603729
rl training, epoch7, iter0, batch456/1133, batch loss:0.3313159644603729, Training time:23382.819037675858
batch reward last col mean 0.09188688546419144 first col mean 0.10899282246828079 all mean 0.09533748030662537
0.267422080039978 0.2674221098423004
rl training, epoch7, iter0, batch457/1133, batch loss:0.2674221098423004, Training time:23385.217500925064
batch reward last col mean 0.0832146406173706 first col mean 0.10790952295064926 all mean 0.09164442867040634
0.24534769356250763 0.24534769356250763
rl training, epoch7, iter0, batch458/1133, batch loss:0.24534769356250763, Training time:23386.776417016983
batch reward last col mean 0.09527874737977982 first col mean 0.09732919931411743 all mean 0.09511611610651016
0.26943182945251465 0.26943182945251465
rl training, epoch7, iter0, batch459/1133, batch loss:0.26943182945251465, Training time:23388.343114376068
batch reward last col mean 0.10817334055900574 first col mean 0.1187649741768837 all mean 0.10680371522903442
0.27174362540245056 0.27174362540245056
rl training, epoch7, iter0, batch460/1133, batch loss:0.27174362540245056, Training time:23390.39739727974
batch reward last col mean 0.1095140129327774 first col mean 0.10788924247026443 all mean 0.10728739202022552
0.2945360839366913 0.2945360839366913
rl training, epoch7, iter0, batch461/1133, batch loss:0.2945360839366913, Training time:23392.00363445282
batch reward last col mean 0.10027530789375305 first col mean 0.11057155579328537 all mean 0.10703331977128983
0.28835880756378174 0.28835880756378174
rl training, epoch7, iter0, batch462/1133, batch loss:0.28835880756378174, Training time:23393.750604629517
batch reward last col mean 0.10328146070241928 first col mean 0.11006605625152588 all mean 0.10106721520423889
0.286188006401062 0.286188006401062
rl training, epoch7, iter0, batch463/1133, batch loss:0.286188006401062, Training time:23395.507865190506
batch reward last col mean 0.11873751133680344 first col mean 0.1214742362499237 all mean 0.11807657033205032
0.3214431405067444 0.3214431405067444
rl training, epoch7, iter0, batch464/1133, batch loss:0.3214431405067444, Training time:23397.1642973423
batch reward last col mean 0.10425736010074615 first col mean 0.10790495574474335 all mean 0.11218421906232834
0.28545454144477844 0.28545454144477844
rl training, epoch7, iter0, batch465/1133, batch loss:0.28545454144477844, Training time:23398.97260570526
batch reward last col mean 0.10299641638994217 first col mean 0.09605728834867477 all mean 0.10180347412824631
0.23462547361850739 0.23462547361850739
rl training, epoch7, iter0, batch466/1133, batch loss:0.23462547361850739, Training time:23400.954437494278
batch reward last col mean 0.09087765216827393 first col mean 0.09810961782932281 all mean 0.09880386292934418
0.3027186989784241 0.3027186989784241
rl training, epoch7, iter0, batch467/1133, batch loss:0.3027186989784241, Training time:23403.323633670807
batch reward last col mean 0.1058586910367012 first col mean 0.11865659058094025 all mean 0.10734978318214417
0.3193339705467224 0.3193339705467224
rl training, epoch7, iter0, batch468/1133, batch loss:0.3193339705467224, Training time:23404.820093154907
batch reward last col mean 0.1720099002122879 first col mean 0.13453027606010437 all mean 0.16474246978759766
0.3776955008506775 0.3776955008506775
rl training, epoch7, iter0, batch469/1133, batch loss:0.3776955008506775, Training time:23407.105951070786
batch reward last col mean 0.14587721228599548 first col mean 0.10126093029975891 all mean 0.13619007170200348
0.3156798183917999 0.3156798183917999
rl training, epoch7, iter0, batch470/1133, batch loss:0.3156798183917999, Training time:23408.984666109085
batch reward last col mean 0.09725277125835419 first col mean 0.10023628175258636 all mean 0.10822832584381104
0.2579314708709717 0.2579314410686493
rl training, epoch7, iter0, batch471/1133, batch loss:0.2579314410686493, Training time:23411.271196126938
batch reward last col mean 0.059181444346904755 first col mean 0.11747658252716064 all mean 0.0756712406873703
0.2544063627719879 0.2544063627719879
rl training, epoch7, iter0, batch472/1133, batch loss:0.2544063627719879, Training time:23412.97603201866
batch reward last col mean 0.10221990197896957 first col mean 0.0987524539232254 all mean 0.10531112551689148
0.24983751773834229 0.24983751773834229
rl training, epoch7, iter0, batch473/1133, batch loss:0.24983751773834229, Training time:23414.818281412125
batch reward last col mean 0.09475632756948471 first col mean 0.11270482838153839 all mean 0.10425475984811783
0.30526167154312134 0.30526167154312134
rl training, epoch7, iter0, batch474/1133, batch loss:0.30526167154312134, Training time:23416.605043411255
batch reward last col mean 0.11533334851264954 first col mean 0.12021194398403168 all mean 0.11022656410932541
0.2762470245361328 0.2762470245361328
rl training, epoch7, iter0, batch475/1133, batch loss:0.2762470245361328, Training time:23418.017441034317
batch reward last col mean 0.07820378243923187 first col mean 0.11204136908054352 all mean 0.0869312733411789
0.2551596462726593 0.2551596462726593
rl training, epoch7, iter0, batch476/1133, batch loss:0.2551596462726593, Training time:23419.922459840775
batch reward last col mean 0.06769832223653793 first col mean 0.11046992987394333 all mean 0.0818217471241951
0.3069916069507599 0.3069916069507599
rl training, epoch7, iter0, batch477/1133, batch loss:0.3069916069507599, Training time:23421.65545630455
batch reward last col mean 0.11807109415531158 first col mean 0.1204213947057724 all mean 0.11540079861879349
0.33203235268592834 0.33203235268592834
rl training, epoch7, iter0, batch478/1133, batch loss:0.33203235268592834, Training time:23423.36616921425
batch reward last col mean 0.12597313523292542 first col mean 0.11793404817581177 all mean 0.11411766707897186
0.2810733914375305 0.2810733914375305
rl training, epoch7, iter0, batch479/1133, batch loss:0.2810733914375305, Training time:23424.83083128929
batch reward last col mean 0.09268854558467865 first col mean 0.11337520182132721 all mean 0.09910793602466583
0.2647707462310791 0.2647707462310791
rl training, epoch7, iter0, batch480/1133, batch loss:0.2647707462310791, Training time:23427.008169412613
batch reward last col mean 0.09044351428747177 first col mean 0.10261689126491547 all mean 0.09204131364822388
0.2687201499938965 0.2687201499938965
rl training, epoch7, iter0, batch481/1133, batch loss:0.2687201499938965, Training time:23428.61632156372
batch reward last col mean 0.0794675275683403 first col mean 0.10294030606746674 all mean 0.08922738581895828
0.2602418065071106 0.2602418065071106
rl training, epoch7, iter0, batch482/1133, batch loss:0.2602418065071106, Training time:23430.94520330429
batch reward last col mean 0.10041829198598862 first col mean 0.0994894951581955 all mean 0.10178551822900772
0.2841300070285797 0.2841300070285797
rl training, epoch7, iter0, batch483/1133, batch loss:0.2841300070285797, Training time:23432.825625181198
batch reward last col mean 0.11888498067855835 first col mean 0.10303732007741928 all mean 0.12048829346895218
0.3449891209602356 0.3449891209602356
rl training, epoch7, iter0, batch484/1133, batch loss:0.3449891209602356, Training time:23434.638189077377
batch reward last col mean 0.1462346911430359 first col mean 0.13030356168746948 all mean 0.13270598649978638
0.3210769593715668 0.3210769295692444
rl training, epoch7, iter0, batch485/1133, batch loss:0.3210769295692444, Training time:23436.134410619736
batch reward last col mean 0.0712035670876503 first col mean 0.10727950930595398 all mean 0.08176127076148987
0.2642069160938263 0.2642069160938263
rl training, epoch7, iter0, batch486/1133, batch loss:0.2642069160938263, Training time:23437.798086881638
batch reward last col mean 0.1155715212225914 first col mean 0.12018421292304993 all mean 0.1129155233502388
0.300637423992157 0.30063745379447937
rl training, epoch7, iter0, batch487/1133, batch loss:0.30063745379447937, Training time:23439.85368204117
batch reward last col mean 0.09581118077039719 first col mean 0.10591982305049896 all mean 0.09151323139667511
0.2730630338191986 0.2730630338191986
rl training, epoch7, iter0, batch488/1133, batch loss:0.2730630338191986, Training time:23441.548104286194
batch reward last col mean 0.09963766485452652 first col mean 0.1208040714263916 all mean 0.10445360094308853
0.27666032314300537 0.27666032314300537
rl training, epoch7, iter0, batch489/1133, batch loss:0.27666032314300537, Training time:23443.226073503494
batch reward last col mean 0.11553236842155457 first col mean 0.11139823496341705 all mean 0.1199149489402771
0.31669822335243225 0.31669819355010986
rl training, epoch7, iter0, batch490/1133, batch loss:0.31669819355010986, Training time:23444.775636672974
batch reward last col mean 0.09212099015712738 first col mean 0.13437031209468842 all mean 0.09876807779073715
0.30552470684051514 0.30552470684051514
rl training, epoch7, iter0, batch491/1133, batch loss:0.30552470684051514, Training time:23447.00538277626
batch reward last col mean 0.12055302411317825 first col mean 0.11095620691776276 all mean 0.11569023877382278
0.2948867976665497 0.2948867976665497
rl training, epoch7, iter0, batch492/1133, batch loss:0.2948867976665497, Training time:23448.987919330597
batch reward last col mean 0.06927287578582764 first col mean 0.1176917552947998 all mean 0.08341129869222641
0.27034199237823486 0.2703419625759125
rl training, epoch7, iter0, batch493/1133, batch loss:0.2703419625759125, Training time:23450.96234345436
batch reward last col mean 0.11400942504405975 first col mean 0.10931607335805893 all mean 0.11282287538051605
0.30034297704696655 0.30034297704696655
rl training, epoch7, iter0, batch494/1133, batch loss:0.30034297704696655, Training time:23453.060501098633
batch reward last col mean 0.15072932839393616 first col mean 0.1148734986782074 all mean 0.14204226434230804
0.3340144157409668 0.3340144157409668
rl training, epoch7, iter0, batch495/1133, batch loss:0.3340144157409668, Training time:23454.8938331604
batch reward last col mean 0.07137738913297653 first col mean 0.11277010291814804 all mean 0.08288710564374924
0.2720499038696289 0.2720499336719513
rl training, epoch7, iter0, batch496/1133, batch loss:0.2720499336719513, Training time:23457.00130558014
batch reward last col mean 0.10796298086643219 first col mean 0.09842000901699066 all mean 0.10278195887804031
0.28013238310813904 0.28013238310813904
rl training, epoch7, iter0, batch497/1133, batch loss:0.28013238310813904, Training time:23459.24334836006
batch reward last col mean 0.10507404059171677 first col mean 0.10230369865894318 all mean 0.10298329591751099
0.24222733080387115 0.24222733080387115
rl training, epoch7, iter0, batch498/1133, batch loss:0.24222733080387115, Training time:23460.923310041428
batch reward last col mean 0.11249826848506927 first col mean 0.11140431463718414 all mean 0.1178147941827774
0.3127487599849701 0.3127487301826477
rl training, epoch7, iter0, batch499/1133, batch loss:0.3127487301826477, Training time:23463.116208314896
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47234807212796764 Time: 94.83096766471863 s
loss of true 0.20402026720943434 loss of gen 0.17369522704740384 loss of other 0.09463257694556086 first score 0.11033887416124344
batch reward last col mean 0.11740466952323914 first col mean 0.0962975025177002 all mean 0.11639072000980377
0.29505929350852966 0.29505929350852966
rl training, epoch7, iter0, batch500/1133, batch loss:0.29505929350852966, Training time:23559.41212940216
batch reward last col mean 0.11683955043554306 first col mean 0.11304840445518494 all mean 0.11265044659376144
0.2613730728626251 0.2613730728626251
rl training, epoch7, iter0, batch501/1133, batch loss:0.2613730728626251, Training time:23560.910024166107
batch reward last col mean 0.09168048202991486 first col mean 0.09993059933185577 all mean 0.0924435630440712
0.26382744312286377 0.26382747292518616
rl training, epoch7, iter0, batch502/1133, batch loss:0.26382747292518616, Training time:23562.79421210289
batch reward last col mean 0.09936366975307465 first col mean 0.0876532569527626 all mean 0.09580768644809723
0.2398497313261032 0.2398497313261032
rl training, epoch7, iter0, batch503/1133, batch loss:0.2398497313261032, Training time:23564.38276696205
batch reward last col mean 0.0810764729976654 first col mean 0.11364651471376419 all mean 0.08362483978271484
0.271462619304657 0.2714625895023346
rl training, epoch7, iter0, batch504/1133, batch loss:0.2714625895023346, Training time:23566.487527370453
batch reward last col mean 0.11105190962553024 first col mean 0.0835760161280632 all mean 0.10672919452190399
0.2535344660282135 0.2535344660282135
rl training, epoch7, iter0, batch505/1133, batch loss:0.2535344660282135, Training time:23568.39180135727
batch reward last col mean 0.10395368188619614 first col mean 0.09871762990951538 all mean 0.10127992928028107
0.27095872163772583 0.27095872163772583
rl training, epoch7, iter0, batch506/1133, batch loss:0.27095872163772583, Training time:23570.058294296265
batch reward last col mean 0.1007431149482727 first col mean 0.09271132946014404 all mean 0.10008586198091507
0.26235219836235046 0.26235219836235046
rl training, epoch7, iter0, batch507/1133, batch loss:0.26235219836235046, Training time:23571.651888132095
batch reward last col mean 0.10782007873058319 first col mean 0.11083843559026718 all mean 0.10500947386026382
0.29493752121925354 0.29493752121925354
rl training, epoch7, iter0, batch508/1133, batch loss:0.29493752121925354, Training time:23573.61986708641
batch reward last col mean 0.11873702704906464 first col mean 0.10381962358951569 all mean 0.11422448605298996
0.26917019486427307 0.26917019486427307
rl training, epoch7, iter0, batch509/1133, batch loss:0.26917019486427307, Training time:23575.53670835495
batch reward last col mean 0.07680769264698029 first col mean 0.11008110642433167 all mean 0.07852279394865036
0.23000507056713104 0.23000507056713104
rl training, epoch7, iter0, batch510/1133, batch loss:0.23000507056713104, Training time:23577.828293323517
batch reward last col mean 0.09216166287660599 first col mean 0.10104092210531235 all mean 0.0920267403125763
0.2683235704898834 0.2683235704898834
rl training, epoch7, iter0, batch511/1133, batch loss:0.2683235704898834, Training time:23579.27165555954
batch reward last col mean 0.09850015491247177 first col mean 0.10677557438611984 all mean 0.10429713129997253
0.27735376358032227 0.27735376358032227
rl training, epoch7, iter0, batch512/1133, batch loss:0.27735376358032227, Training time:23581.027763843536
batch reward last col mean 0.06163286417722702 first col mean 0.1121496856212616 all mean 0.07444767653942108
0.2252376675605774 0.2252376675605774
rl training, epoch7, iter0, batch513/1133, batch loss:0.2252376675605774, Training time:23582.942492723465
batch reward last col mean 0.09236995875835419 first col mean 0.10685577243566513 all mean 0.09082932025194168
0.24681507050991058 0.24681507050991058
rl training, epoch7, iter0, batch514/1133, batch loss:0.24681507050991058, Training time:23585.06835460663
batch reward last col mean 0.10415735840797424 first col mean 0.10257425159215927 all mean 0.10093557089567184
0.2567584812641144 0.2567584812641144
rl training, epoch7, iter0, batch515/1133, batch loss:0.2567584812641144, Training time:23586.673016309738
batch reward last col mean 0.0855560302734375 first col mean 0.11683060973882675 all mean 0.09365995973348618
0.30254480242729187 0.30254480242729187
rl training, epoch7, iter0, batch516/1133, batch loss:0.30254480242729187, Training time:23588.186575889587
batch reward last col mean 0.10994921624660492 first col mean 0.10163604468107224 all mean 0.11244672536849976
0.30266791582107544 0.30266791582107544
rl training, epoch7, iter0, batch517/1133, batch loss:0.30266791582107544, Training time:23589.914969682693
batch reward last col mean 0.07854411005973816 first col mean 0.10707573592662811 all mean 0.0868896096944809
0.2537626028060913 0.2537626326084137
rl training, epoch7, iter0, batch518/1133, batch loss:0.2537626326084137, Training time:23592.624504566193
batch reward last col mean 0.0692051351070404 first col mean 0.11339270323514938 all mean 0.08018047362565994
0.23092173039913177 0.23092173039913177
rl training, epoch7, iter0, batch519/1133, batch loss:0.23092173039913177, Training time:23594.489907979965
batch reward last col mean 0.09156016260385513 first col mean 0.09738840162754059 all mean 0.09536963701248169
0.22050541639328003 0.22050537168979645
rl training, epoch7, iter0, batch520/1133, batch loss:0.22050537168979645, Training time:23596.207763910294
batch reward last col mean 0.07878147810697556 first col mean 0.10836672782897949 all mean 0.08679237216711044
0.2567370533943176 0.25673708319664
rl training, epoch7, iter0, batch521/1133, batch loss:0.25673708319664, Training time:23598.037531852722
batch reward last col mean 0.09938301146030426 first col mean 0.09381333738565445 all mean 0.10316643863916397
0.28732821345329285 0.28732821345329285
rl training, epoch7, iter0, batch522/1133, batch loss:0.28732821345329285, Training time:23600.21730351448
batch reward last col mean 0.07178881019353867 first col mean 0.09037899225950241 all mean 0.08149909973144531
0.25772732496261597 0.25772732496261597
rl training, epoch7, iter0, batch523/1133, batch loss:0.25772732496261597, Training time:23602.084188461304
batch reward last col mean 0.08969442546367645 first col mean 0.10120902955532074 all mean 0.09646592289209366
0.27578863501548767 0.27578863501548767
rl training, epoch7, iter0, batch524/1133, batch loss:0.27578863501548767, Training time:23604.086810827255
batch reward last col mean 0.11152198165655136 first col mean 0.10231431573629379 all mean 0.11124035716056824
0.2692279517650604 0.2692279517650604
rl training, epoch7, iter0, batch525/1133, batch loss:0.2692279517650604, Training time:23605.88824224472
batch reward last col mean 0.08266735076904297 first col mean 0.10770275443792343 all mean 0.09062564373016357
0.2774584889411926 0.2774584889411926
rl training, epoch7, iter0, batch526/1133, batch loss:0.2774584889411926, Training time:23607.34156537056
batch reward last col mean 0.10978648066520691 first col mean 0.09078900516033173 all mean 0.10150907933712006
0.2997889220714569 0.2997889220714569
rl training, epoch7, iter0, batch527/1133, batch loss:0.2997889220714569, Training time:23608.999657154083
batch reward last col mean 0.1306593120098114 first col mean 0.10778265446424484 all mean 0.12163392454385757
0.28283289074897766 0.28283289074897766
rl training, epoch7, iter0, batch528/1133, batch loss:0.28283289074897766, Training time:23610.899214029312
batch reward last col mean 0.08166107535362244 first col mean 0.08591208606958389 all mean 0.08865942060947418
0.25940006971359253 0.25940006971359253
rl training, epoch7, iter0, batch529/1133, batch loss:0.25940006971359253, Training time:23613.096530914307
batch reward last col mean 0.10230172425508499 first col mean 0.10196704417467117 all mean 0.10041096806526184
0.2465333193540573 0.2465333193540573
rl training, epoch7, iter0, batch530/1133, batch loss:0.2465333193540573, Training time:23614.991384506226
batch reward last col mean 0.12435285747051239 first col mean 0.09936841577291489 all mean 0.12041595578193665
0.2813474237918854 0.281347393989563
rl training, epoch7, iter0, batch531/1133, batch loss:0.281347393989563, Training time:23616.99955892563
batch reward last col mean 0.11024579405784607 first col mean 0.1086917370557785 all mean 0.10847984999418259
0.278759241104126 0.278759241104126
rl training, epoch7, iter0, batch532/1133, batch loss:0.278759241104126, Training time:23618.96880221367
batch reward last col mean 0.1100907027721405 first col mean 0.11257819086313248 all mean 0.10612485557794571
0.28466862440109253 0.28466862440109253
rl training, epoch7, iter0, batch533/1133, batch loss:0.28466862440109253, Training time:23620.77187514305
batch reward last col mean 0.10745474696159363 first col mean 0.12219546735286713 all mean 0.10437251627445221
0.24245402216911316 0.24245402216911316
rl training, epoch7, iter0, batch534/1133, batch loss:0.24245402216911316, Training time:23622.792756319046
batch reward last col mean 0.1112615168094635 first col mean 0.10722668468952179 all mean 0.10443049669265747
0.2761968672275543 0.2761968672275543
rl training, epoch7, iter0, batch535/1133, batch loss:0.2761968672275543, Training time:23624.37898874283
batch reward last col mean 0.10091816633939743 first col mean 0.1053791493177414 all mean 0.09900545328855515
0.2843128442764282 0.2843128740787506
rl training, epoch7, iter0, batch536/1133, batch loss:0.2843128740787506, Training time:23626.383882284164
batch reward last col mean 0.10853861272335052 first col mean 0.09621333330869675 all mean 0.10218240320682526
0.25391924381256104 0.25391924381256104
rl training, epoch7, iter0, batch537/1133, batch loss:0.25391924381256104, Training time:23628.372905254364
batch reward last col mean 0.13223369419574738 first col mean 0.09502074867486954 all mean 0.11650469154119492
0.2632795572280884 0.2632795572280884
rl training, epoch7, iter0, batch538/1133, batch loss:0.2632795572280884, Training time:23629.865094661713
batch reward last col mean 0.12367085367441177 first col mean 0.09084886312484741 all mean 0.11824711412191391
0.2789492905139923 0.2789492905139923
rl training, epoch7, iter0, batch539/1133, batch loss:0.2789492905139923, Training time:23631.92505788803
batch reward last col mean 0.11874900013208389 first col mean 0.09439850598573685 all mean 0.11666669696569443
0.2766226828098297 0.2766226828098297
rl training, epoch7, iter0, batch540/1133, batch loss:0.2766226828098297, Training time:23634.04457473755
batch reward last col mean 0.09461544454097748 first col mean 0.12755051255226135 all mean 0.10037171840667725
0.24435167014598846 0.24435167014598846
rl training, epoch7, iter0, batch541/1133, batch loss:0.24435167014598846, Training time:23635.607048034668
batch reward last col mean 0.07177150249481201 first col mean 0.10736677050590515 all mean 0.0828322023153305
0.27455952763557434 0.27455952763557434
rl training, epoch7, iter0, batch542/1133, batch loss:0.27455952763557434, Training time:23637.612611055374
batch reward last col mean 0.08750367164611816 first col mean 0.0940987691283226 all mean 0.09060905873775482
0.26332414150238037 0.26332414150238037
rl training, epoch7, iter0, batch543/1133, batch loss:0.26332414150238037, Training time:23639.454841852188
batch reward last col mean 0.05973462015390396 first col mean 0.10384446382522583 all mean 0.07146158069372177
0.24731086194515228 0.24731086194515228
rl training, epoch7, iter0, batch544/1133, batch loss:0.24731086194515228, Training time:23641.331577539444
batch reward last col mean 0.11595971882343292 first col mean 0.10962025821208954 all mean 0.11216378957033157
0.29254135489463806 0.29254135489463806
rl training, epoch7, iter0, batch545/1133, batch loss:0.29254135489463806, Training time:23643.573923826218
batch reward last col mean 0.11243278533220291 first col mean 0.08539789170026779 all mean 0.10538678616285324
0.24977874755859375 0.24977873265743256
rl training, epoch7, iter0, batch546/1133, batch loss:0.24977873265743256, Training time:23645.024161815643
batch reward last col mean 0.09096714854240417 first col mean 0.10399174690246582 all mean 0.09072362631559372
0.2636241018772125 0.2636241018772125
rl training, epoch7, iter0, batch547/1133, batch loss:0.2636241018772125, Training time:23646.856513261795
batch reward last col mean 0.1380617320537567 first col mean 0.09766130894422531 all mean 0.1259745955467224
0.2682400047779083 0.2682400047779083
rl training, epoch7, iter0, batch548/1133, batch loss:0.2682400047779083, Training time:23648.279134511948
batch reward last col mean 0.08651423454284668 first col mean 0.0989055186510086 all mean 0.08968575298786163
0.23900718986988068 0.23900718986988068
rl training, epoch7, iter0, batch549/1133, batch loss:0.23900718986988068, Training time:23650.354647874832
batch reward last col mean 0.060661688446998596 first col mean 0.11168726533651352 all mean 0.07603432238101959
0.24706166982650757 0.24706166982650757
rl training, epoch7, iter0, batch550/1133, batch loss:0.24706166982650757, Training time:23652.081540822983
batch reward last col mean 0.10001928359270096 first col mean 0.10465608537197113 all mean 0.10480072349309921
0.2757278084754944 0.2757278084754944
rl training, epoch7, iter0, batch551/1133, batch loss:0.2757278084754944, Training time:23654.107260465622
batch reward last col mean 0.08498578518629074 first col mean 0.10410341620445251 all mean 0.09034288674592972
0.24550871551036835 0.24550868570804596
rl training, epoch7, iter0, batch552/1133, batch loss:0.24550868570804596, Training time:23655.997250556946
batch reward last col mean 0.08911529183387756 first col mean 0.10076742619276047 all mean 0.09622190147638321
0.255048543214798 0.255048543214798
rl training, epoch7, iter0, batch553/1133, batch loss:0.255048543214798, Training time:23657.391085386276
batch reward last col mean 0.08299052715301514 first col mean 0.10147253423929214 all mean 0.0912509560585022
0.2507675290107727 0.2507675290107727
rl training, epoch7, iter0, batch554/1133, batch loss:0.2507675290107727, Training time:23659.381588935852
batch reward last col mean 0.09672601521015167 first col mean 0.10110768675804138 all mean 0.10077014565467834
0.24365125596523285 0.24365125596523285
rl training, epoch7, iter0, batch555/1133, batch loss:0.24365125596523285, Training time:23661.484400987625
batch reward last col mean 0.07934173941612244 first col mean 0.1064634919166565 all mean 0.0844673216342926
0.24170756340026855 0.24170753359794617
rl training, epoch7, iter0, batch556/1133, batch loss:0.24170753359794617, Training time:23663.13299679756
batch reward last col mean 0.0916568785905838 first col mean 0.10958530008792877 all mean 0.09707408398389816
0.2702100872993469 0.2702100872993469
rl training, epoch7, iter0, batch557/1133, batch loss:0.2702100872993469, Training time:23665.366265296936
batch reward last col mean 0.07926841080188751 first col mean 0.10243333876132965 all mean 0.08867258578538895
0.28426414728164673 0.28426414728164673
rl training, epoch7, iter0, batch558/1133, batch loss:0.28426414728164673, Training time:23667.088404417038
batch reward last col mean 0.11286231130361557 first col mean 0.1171608716249466 all mean 0.10550637543201447
0.28118985891342163 0.28118985891342163
rl training, epoch7, iter0, batch559/1133, batch loss:0.28118985891342163, Training time:23669.22939801216
batch reward last col mean 0.09488614648580551 first col mean 0.1051136702299118 all mean 0.0941167101264
0.2708243727684021 0.2708243727684021
rl training, epoch7, iter0, batch560/1133, batch loss:0.2708243727684021, Training time:23670.86255812645
batch reward last col mean 0.08742104470729828 first col mean 0.08258700370788574 all mean 0.09078215807676315
0.2730591297149658 0.2730591297149658
rl training, epoch7, iter0, batch561/1133, batch loss:0.2730591297149658, Training time:23672.21858024597
batch reward last col mean 0.09965771436691284 first col mean 0.10358675569295883 all mean 0.10048255324363708
0.27635493874549866 0.27635493874549866
rl training, epoch7, iter0, batch562/1133, batch loss:0.27635493874549866, Training time:23674.486412525177
batch reward last col mean 0.10484862327575684 first col mean 0.09240499138832092 all mean 0.10215133428573608
0.23996852338314056 0.23996852338314056
rl training, epoch7, iter0, batch563/1133, batch loss:0.23996852338314056, Training time:23676.41216135025
batch reward last col mean 0.13926102221012115 first col mean 0.1135929599404335 all mean 0.13052156567573547
0.2990091145038605 0.2990091145038605
rl training, epoch7, iter0, batch564/1133, batch loss:0.2990091145038605, Training time:23677.858040094376
batch reward last col mean 0.155872642993927 first col mean 0.08751024305820465 all mean 0.13866427540779114
0.2915175259113312 0.2915175259113312
rl training, epoch7, iter0, batch565/1133, batch loss:0.2915175259113312, Training time:23679.286999464035
batch reward last col mean 0.08794520795345306 first col mean 0.10066981613636017 all mean 0.08940036594867706
0.2545480728149414 0.2545480728149414
rl training, epoch7, iter0, batch566/1133, batch loss:0.2545480728149414, Training time:23681.421122074127
batch reward last col mean 0.10906101763248444 first col mean 0.11154181510210037 all mean 0.1098763644695282
0.31282684206962585 0.31282684206962585
rl training, epoch7, iter0, batch567/1133, batch loss:0.31282684206962585, Training time:23683.085086345673
batch reward last col mean 0.10763803124427795 first col mean 0.11596378684043884 all mean 0.10649783164262772
0.25089216232299805 0.25089213252067566
rl training, epoch7, iter0, batch568/1133, batch loss:0.25089213252067566, Training time:23684.972047567368
batch reward last col mean 0.11138541996479034 first col mean 0.09549129754304886 all mean 0.10716568678617477
0.2717169225215912 0.2717169225215912
rl training, epoch7, iter0, batch569/1133, batch loss:0.2717169225215912, Training time:23686.680874824524
batch reward last col mean 0.07431956380605698 first col mean 0.1001465916633606 all mean 0.08712980896234512
0.27449294924736023 0.27449294924736023
rl training, epoch7, iter0, batch570/1133, batch loss:0.27449294924736023, Training time:23688.53086400032
batch reward last col mean 0.10338135063648224 first col mean 0.1023290678858757 all mean 0.10213910788297653
0.2627725899219513 0.2627725899219513
rl training, epoch7, iter0, batch571/1133, batch loss:0.2627725899219513, Training time:23690.322246074677
batch reward last col mean 0.10276336222887039 first col mean 0.09886191040277481 all mean 0.1045583114027977
0.2824532985687256 0.282453328371048
rl training, epoch7, iter0, batch572/1133, batch loss:0.282453328371048, Training time:23692.296014547348
batch reward last col mean 0.08800956606864929 first col mean 0.09980796277523041 all mean 0.09632597863674164
0.2575758099555969 0.2575758099555969
rl training, epoch7, iter0, batch573/1133, batch loss:0.2575758099555969, Training time:23693.86329317093
batch reward last col mean 0.09098608046770096 first col mean 0.08481961488723755 all mean 0.0875529870390892
0.27030566334724426 0.27030566334724426
rl training, epoch7, iter0, batch574/1133, batch loss:0.27030566334724426, Training time:23696.528800964355
batch reward last col mean 0.09667865931987762 first col mean 0.09904123842716217 all mean 0.09423431754112244
0.25137677788734436 0.25137677788734436
rl training, epoch7, iter0, batch575/1133, batch loss:0.25137677788734436, Training time:23698.176958799362
batch reward last col mean 0.07680189609527588 first col mean 0.09901493787765503 all mean 0.08048742264509201
0.23093430697917938 0.23093430697917938
rl training, epoch7, iter0, batch576/1133, batch loss:0.23093430697917938, Training time:23700.085552453995
batch reward last col mean 0.08555684983730316 first col mean 0.10718385130167007 all mean 0.08841070532798767
0.2511598467826843 0.2511598467826843
rl training, epoch7, iter0, batch577/1133, batch loss:0.2511598467826843, Training time:23702.09351706505
batch reward last col mean 0.0751420333981514 first col mean 0.10710488259792328 all mean 0.07502024620771408
0.2538660168647766 0.2538660168647766
rl training, epoch7, iter0, batch578/1133, batch loss:0.2538660168647766, Training time:23704.452123641968
batch reward last col mean 0.08604025840759277 first col mean 0.09699195623397827 all mean 0.09189178794622421
0.2672695219516754 0.2672695219516754
rl training, epoch7, iter0, batch579/1133, batch loss:0.2672695219516754, Training time:23706.57587480545
batch reward last col mean 0.07839222252368927 first col mean 0.12088847160339355 all mean 0.08837293088436127
0.2627497613430023 0.2627497613430023
rl training, epoch7, iter0, batch580/1133, batch loss:0.2627497613430023, Training time:23708.409117937088
batch reward last col mean 0.10038842260837555 first col mean 0.1199645847082138 all mean 0.10225649923086166
0.25685834884643555 0.25685834884643555
rl training, epoch7, iter0, batch581/1133, batch loss:0.25685834884643555, Training time:23710.836911201477
batch reward last col mean 0.11001670360565186 first col mean 0.10410299152135849 all mean 0.1054505705833435
0.2952066659927368 0.2952066659927368
rl training, epoch7, iter0, batch582/1133, batch loss:0.2952066659927368, Training time:23713.072218179703
batch reward last col mean 0.10619957745075226 first col mean 0.11826540529727936 all mean 0.10213449597358704
0.2717168927192688 0.2717168927192688
rl training, epoch7, iter0, batch583/1133, batch loss:0.2717168927192688, Training time:23714.613116264343
batch reward last col mean 0.10663014650344849 first col mean 0.10327732563018799 all mean 0.10032497346401215
0.24784788489341736 0.24784788489341736
rl training, epoch7, iter0, batch584/1133, batch loss:0.24784788489341736, Training time:23716.39327645302
batch reward last col mean 0.10261012613773346 first col mean 0.1074536144733429 all mean 0.10398931056261063
0.25073689222335815 0.25073689222335815
rl training, epoch7, iter0, batch585/1133, batch loss:0.25073689222335815, Training time:23718.758030176163
batch reward last col mean 0.11665244400501251 first col mean 0.1186581626534462 all mean 0.11645068973302841
0.2910759747028351 0.2910759747028351
rl training, epoch7, iter0, batch586/1133, batch loss:0.2910759747028351, Training time:23720.654585838318
batch reward last col mean 0.10646389424800873 first col mean 0.09816975891590118 all mean 0.09950564801692963
0.2713582217693329 0.2713582217693329
rl training, epoch7, iter0, batch587/1133, batch loss:0.2713582217693329, Training time:23722.463817834854
batch reward last col mean 0.08834754675626755 first col mean 0.08979752659797668 all mean 0.09275531023740768
0.24244630336761475 0.24244630336761475
rl training, epoch7, iter0, batch588/1133, batch loss:0.24244630336761475, Training time:23724.210926771164
batch reward last col mean 0.13705846667289734 first col mean 0.12250934541225433 all mean 0.12716303765773773
0.29969322681427 0.2996932566165924
rl training, epoch7, iter0, batch589/1133, batch loss:0.2996932566165924, Training time:23725.91570019722
batch reward last col mean 0.13341306149959564 first col mean 0.090457484126091 all mean 0.12078114598989487
0.2881130278110504 0.2881130576133728
rl training, epoch7, iter0, batch590/1133, batch loss:0.2881130576133728, Training time:23727.784209489822
batch reward last col mean 0.07506353408098221 first col mean 0.1053219884634018 all mean 0.08144630491733551
0.2417459487915039 0.2417459487915039
rl training, epoch7, iter0, batch591/1133, batch loss:0.2417459487915039, Training time:23729.452201604843
batch reward last col mean 0.11171973496675491 first col mean 0.10755300521850586 all mean 0.1123209148645401
0.2874600887298584 0.2874600887298584
rl training, epoch7, iter0, batch592/1133, batch loss:0.2874600887298584, Training time:23732.4951171875
batch reward last col mean 0.0816284716129303 first col mean 0.10175955295562744 all mean 0.09265441447496414
0.29245084524154663 0.29245084524154663
rl training, epoch7, iter0, batch593/1133, batch loss:0.29245084524154663, Training time:23734.090066194534
batch reward last col mean 0.10597381740808487 first col mean 0.10520613938570023 all mean 0.10925928503274918
0.2576725482940674 0.257672518491745
rl training, epoch7, iter0, batch594/1133, batch loss:0.257672518491745, Training time:23735.899646043777
batch reward last col mean 0.10199017077684402 first col mean 0.12885257601737976 all mean 0.10263877362012863
0.2938380539417267 0.2938380539417267
rl training, epoch7, iter0, batch595/1133, batch loss:0.2938380539417267, Training time:23737.591824769974
batch reward last col mean 0.09928080439567566 first col mean 0.10669805854558945 all mean 0.10133872926235199
0.28984713554382324 0.28984713554382324
rl training, epoch7, iter0, batch596/1133, batch loss:0.28984713554382324, Training time:23739.87457227707
batch reward last col mean 0.09115958213806152 first col mean 0.10870327055454254 all mean 0.091429702937603
0.25742852687835693 0.25742852687835693
rl training, epoch7, iter0, batch597/1133, batch loss:0.25742852687835693, Training time:23741.5763463974
batch reward last col mean 0.08383466303348541 first col mean 0.1067393571138382 all mean 0.09062886238098145
0.23431232571601868 0.23431232571601868
rl training, epoch7, iter0, batch598/1133, batch loss:0.23431232571601868, Training time:23742.99592781067
batch reward last col mean 0.09295333921909332 first col mean 0.11878809332847595 all mean 0.09657815098762512
0.2986069321632385 0.2986069321632385
rl training, epoch7, iter0, batch599/1133, batch loss:0.2986069321632385, Training time:23744.70162153244
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47115954612065286 Time: 94.67810845375061 s
loss of true 0.20398915908237736 loss of gen 0.17198772049473643 loss of other 0.0951826655883786 first score 0.10118609666824341
batch reward last col mean 0.07597817480564117 first col mean 0.09322210401296616 all mean 0.08116554468870163
0.24543678760528564 0.24543678760528564
rl training, epoch7, iter0, batch600/1133, batch loss:0.24543678760528564, Training time:23841.334317684174
batch reward last col mean 0.09694205224514008 first col mean 0.10776945948600769 all mean 0.09265182167291641
0.23281008005142212 0.23281008005142212
rl training, epoch7, iter0, batch601/1133, batch loss:0.23281008005142212, Training time:23843.0289478302
batch reward last col mean 0.07601660490036011 first col mean 0.10714952647686005 all mean 0.08355459570884705
0.22244414687156677 0.22244414687156677
rl training, epoch7, iter0, batch602/1133, batch loss:0.22244414687156677, Training time:23844.49550294876
batch reward last col mean 0.10508684068918228 first col mean 0.09725248068571091 all mean 0.10146533697843552
0.2522037625312805 0.2522037625312805
rl training, epoch7, iter0, batch603/1133, batch loss:0.2522037625312805, Training time:23846.027483701706
batch reward last col mean 0.09195169806480408 first col mean 0.0852343961596489 all mean 0.09543493390083313
0.24762186408042908 0.24762186408042908
rl training, epoch7, iter0, batch604/1133, batch loss:0.24762186408042908, Training time:23847.553575754166
batch reward last col mean 0.12442426383495331 first col mean 0.11188995838165283 all mean 0.11626516282558441
0.28404924273490906 0.28404924273490906
rl training, epoch7, iter0, batch605/1133, batch loss:0.28404924273490906, Training time:23849.066870212555
batch reward last col mean 0.10877355933189392 first col mean 0.11278558522462845 all mean 0.1108725443482399
0.29065433144569397 0.29065433144569397
rl training, epoch7, iter0, batch606/1133, batch loss:0.29065433144569397, Training time:23850.61246919632
batch reward last col mean 0.10059019923210144 first col mean 0.10953988879919052 all mean 0.0988956093788147
0.27387312054634094 0.27387312054634094
rl training, epoch7, iter0, batch607/1133, batch loss:0.27387312054634094, Training time:23852.80009841919
batch reward last col mean 0.10421177744865417 first col mean 0.11167552322149277 all mean 0.10620614141225815
0.2666873037815094 0.2666873037815094
rl training, epoch7, iter0, batch608/1133, batch loss:0.2666873037815094, Training time:23854.22618985176
batch reward last col mean 0.10703969746828079 first col mean 0.12202218174934387 all mean 0.10954286903142929
0.2772444486618042 0.2772444486618042
rl training, epoch7, iter0, batch609/1133, batch loss:0.2772444486618042, Training time:23856.14469385147
batch reward last col mean 0.10225804150104523 first col mean 0.09315462410449982 all mean 0.09744833409786224
0.2842194736003876 0.28421950340270996
rl training, epoch7, iter0, batch610/1133, batch loss:0.28421950340270996, Training time:23858.126103639603
batch reward last col mean 0.09793543815612793 first col mean 0.10589464753866196 all mean 0.10106226801872253
0.27182385325431824 0.27182385325431824
rl training, epoch7, iter0, batch611/1133, batch loss:0.27182385325431824, Training time:23859.797894239426
batch reward last col mean 0.08149692416191101 first col mean 0.08283448219299316 all mean 0.0870564803481102
0.21633271872997284 0.21633271872997284
rl training, epoch7, iter0, batch612/1133, batch loss:0.21633271872997284, Training time:23861.29393386841
batch reward last col mean 0.0781870186328888 first col mean 0.09433843940496445 all mean 0.08664731681346893
0.2921160161495209 0.2921160161495209
rl training, epoch7, iter0, batch613/1133, batch loss:0.2921160161495209, Training time:23863.472107887268
batch reward last col mean 0.09898882359266281 first col mean 0.10378727316856384 all mean 0.09986171126365662
0.2654683291912079 0.2654683291912079
rl training, epoch7, iter0, batch614/1133, batch loss:0.2654683291912079, Training time:23865.248552799225
batch reward last col mean 0.10195813328027725 first col mean 0.09237723797559738 all mean 0.10381554067134857
0.26999950408935547 0.26999950408935547
rl training, epoch7, iter0, batch615/1133, batch loss:0.26999950408935547, Training time:23867.00638985634
batch reward last col mean 0.11901454627513885 first col mean 0.08661584556102753 all mean 0.11541618406772614
0.26943138241767883 0.26943138241767883
rl training, epoch7, iter0, batch616/1133, batch loss:0.26943138241767883, Training time:23868.533684015274
batch reward last col mean 0.07639230787754059 first col mean 0.10732142627239227 all mean 0.08792099356651306
0.24092984199523926 0.24092984199523926
rl training, epoch7, iter0, batch617/1133, batch loss:0.24092984199523926, Training time:23869.96695804596
batch reward last col mean 0.11956615746021271 first col mean 0.09967632591724396 all mean 0.11359823495149612
0.2922687530517578 0.2922687530517578
rl training, epoch7, iter0, batch618/1133, batch loss:0.2922687530517578, Training time:23871.67082953453
batch reward last col mean 0.10093066096305847 first col mean 0.10588061809539795 all mean 0.10079497843980789
0.26267093420028687 0.26267093420028687
rl training, epoch7, iter0, batch619/1133, batch loss:0.26267093420028687, Training time:23873.29380273819
batch reward last col mean 0.10577553510665894 first col mean 0.11482938379049301 all mean 0.10730340331792831
0.2915549874305725 0.2915549874305725
rl training, epoch7, iter0, batch620/1133, batch loss:0.2915549874305725, Training time:23875.266575813293
batch reward last col mean 0.1254858374595642 first col mean 0.10202521085739136 all mean 0.11632135510444641
0.27274441719055176 0.27274441719055176
rl training, epoch7, iter0, batch621/1133, batch loss:0.27274441719055176, Training time:23876.8815677166
batch reward last col mean 0.08053117245435715 first col mean 0.09146412461996078 all mean 0.09068183600902557
0.2528667151927948 0.2528667449951172
rl training, epoch7, iter0, batch622/1133, batch loss:0.2528667449951172, Training time:23878.353323221207
batch reward last col mean 0.1216578334569931 first col mean 0.1308530569076538 all mean 0.11761754751205444
0.31652042269706726 0.31652042269706726
rl training, epoch7, iter0, batch623/1133, batch loss:0.31652042269706726, Training time:23879.827825784683
batch reward last col mean 0.09125842899084091 first col mean 0.0918702632188797 all mean 0.09539097547531128
0.25841718912124634 0.25841718912124634
rl training, epoch7, iter0, batch624/1133, batch loss:0.25841718912124634, Training time:23881.42011809349
batch reward last col mean 0.11800019443035126 first col mean 0.0961497351527214 all mean 0.10484518855810165
0.267347127199173 0.267347127199173
rl training, epoch7, iter0, batch625/1133, batch loss:0.267347127199173, Training time:23883.24860048294
batch reward last col mean 0.07457026094198227 first col mean 0.0921797975897789 all mean 0.07994607090950012
0.21219894289970398 0.21219894289970398
rl training, epoch7, iter0, batch626/1133, batch loss:0.21219894289970398, Training time:23885.501344442368
batch reward last col mean 0.09398891776800156 first col mean 0.0892656147480011 all mean 0.09840014576911926
0.27292701601982117 0.27292701601982117
rl training, epoch7, iter0, batch627/1133, batch loss:0.27292701601982117, Training time:23887.00744175911
batch reward last col mean 0.07131893187761307 first col mean 0.10989109426736832 all mean 0.08873718231916428
0.26859769225120544 0.26859769225120544
rl training, epoch7, iter0, batch628/1133, batch loss:0.26859769225120544, Training time:23888.686102867126
batch reward last col mean 0.12276645004749298 first col mean 0.10199182480573654 all mean 0.11711804568767548
0.3193228542804718 0.3193228840827942
rl training, epoch7, iter0, batch629/1133, batch loss:0.3193228840827942, Training time:23890.424535036087
batch reward last col mean 0.1114317923784256 first col mean 0.10759638249874115 all mean 0.11022863537073135
0.2991030216217041 0.2991030216217041
rl training, epoch7, iter0, batch630/1133, batch loss:0.2991030216217041, Training time:23892.00678706169
batch reward last col mean 0.14999082684516907 first col mean 0.10172686725854874 all mean 0.1399712860584259
0.297092080116272 0.297092080116272
rl training, epoch7, iter0, batch631/1133, batch loss:0.297092080116272, Training time:23894.17337369919
batch reward last col mean 0.09786687791347504 first col mean 0.10387314110994339 all mean 0.09532687067985535
0.2737307846546173 0.2737307846546173
rl training, epoch7, iter0, batch632/1133, batch loss:0.2737307846546173, Training time:23896.008208990097
batch reward last col mean 0.09415403008460999 first col mean 0.08914757519960403 all mean 0.09951265901327133
0.2887859344482422 0.2887859344482422
rl training, epoch7, iter0, batch633/1133, batch loss:0.2887859344482422, Training time:23897.970247745514
batch reward last col mean 0.08591005206108093 first col mean 0.10021419078111649 all mean 0.0916806310415268
0.2643963694572449 0.26439639925956726
rl training, epoch7, iter0, batch634/1133, batch loss:0.26439639925956726, Training time:23899.925357103348
batch reward last col mean 0.08458591997623444 first col mean 0.10045236349105835 all mean 0.09265896677970886
0.27584293484687805 0.27584293484687805
rl training, epoch7, iter0, batch635/1133, batch loss:0.27584293484687805, Training time:23901.76697397232
batch reward last col mean 0.10674163699150085 first col mean 0.1003098413348198 all mean 0.10462737083435059
0.2635956108570099 0.2635956108570099
rl training, epoch7, iter0, batch636/1133, batch loss:0.2635956108570099, Training time:23903.69937825203
batch reward last col mean 0.0904601514339447 first col mean 0.1027774065732956 all mean 0.0942719355225563
0.26849454641342163 0.26849454641342163
rl training, epoch7, iter0, batch637/1133, batch loss:0.26849454641342163, Training time:23906.0208568573
batch reward last col mean 0.0754234567284584 first col mean 0.08894257992506027 all mean 0.07918000221252441
0.2488967478275299 0.2488967478275299
rl training, epoch7, iter0, batch638/1133, batch loss:0.2488967478275299, Training time:23907.62834763527
batch reward last col mean 0.07655363529920578 first col mean 0.1105082780122757 all mean 0.0847834050655365
0.2763189673423767 0.2763189673423767
rl training, epoch7, iter0, batch639/1133, batch loss:0.2763189673423767, Training time:23909.365915298462
batch reward last col mean 0.12814150750637054 first col mean 0.10003864020109177 all mean 0.11864370852708817
0.2765887677669525 0.2765887677669525
rl training, epoch7, iter0, batch640/1133, batch loss:0.2765887677669525, Training time:23911.016582250595
batch reward last col mean 0.07189726829528809 first col mean 0.10129746794700623 all mean 0.08393920212984085
0.24709582328796387 0.24709582328796387
rl training, epoch7, iter0, batch641/1133, batch loss:0.24709582328796387, Training time:23912.850107192993
batch reward last col mean 0.08089064806699753 first col mean 0.08997870981693268 all mean 0.08563842624425888
0.24682864546775818 0.24682864546775818
rl training, epoch7, iter0, batch642/1133, batch loss:0.24682864546775818, Training time:23914.501719474792
batch reward last col mean 0.08975864946842194 first col mean 0.10142336785793304 all mean 0.0943622961640358
0.30007606744766235 0.30007603764533997
rl training, epoch7, iter0, batch643/1133, batch loss:0.30007603764533997, Training time:23916.52822780609
batch reward last col mean 0.11233843117952347 first col mean 0.10295777022838593 all mean 0.11442320793867111
0.26562875509262085 0.26562875509262085
rl training, epoch7, iter0, batch644/1133, batch loss:0.26562875509262085, Training time:23918.249533891678
batch reward last col mean 0.10610084235668182 first col mean 0.11238747090101242 all mean 0.10179001837968826
0.266937255859375 0.266937255859375
rl training, epoch7, iter0, batch645/1133, batch loss:0.266937255859375, Training time:23919.851501703262
batch reward last col mean 0.11514609307050705 first col mean 0.0953020304441452 all mean 0.10824085772037506
0.2557757496833801 0.2557757496833801
rl training, epoch7, iter0, batch646/1133, batch loss:0.2557757496833801, Training time:23922.05048418045
batch reward last col mean 0.0919889360666275 first col mean 0.111168771982193 all mean 0.09783432632684708
0.27069175243377686 0.27069175243377686
rl training, epoch7, iter0, batch647/1133, batch loss:0.27069175243377686, Training time:23923.993567228317
batch reward last col mean 0.12655937671661377 first col mean 0.11575128138065338 all mean 0.12342008203268051
0.33273693919181824 0.33273687958717346
rl training, epoch7, iter0, batch648/1133, batch loss:0.33273687958717346, Training time:23925.61855006218
batch reward last col mean 0.10506606847047806 first col mean 0.11146612465381622 all mean 0.10677365958690643
0.26511695981025696 0.26511695981025696
rl training, epoch7, iter0, batch649/1133, batch loss:0.26511695981025696, Training time:23927.821171045303
batch reward last col mean 0.13067543506622314 first col mean 0.09978188574314117 all mean 0.12542374432086945
0.2985083758831024 0.29850834608078003
rl training, epoch7, iter0, batch650/1133, batch loss:0.29850834608078003, Training time:23929.655579566956
batch reward last col mean 0.10905183106660843 first col mean 0.11230627447366714 all mean 0.1110105961561203
0.26538336277008057 0.2653833329677582
rl training, epoch7, iter0, batch651/1133, batch loss:0.2653833329677582, Training time:23931.011848449707
batch reward last col mean 0.07600975036621094 first col mean 0.11130256950855255 all mean 0.08573119342327118
0.21500292420387268 0.21500292420387268
rl training, epoch7, iter0, batch652/1133, batch loss:0.21500292420387268, Training time:23932.78929257393
batch reward last col mean 0.11148133873939514 first col mean 0.10873975604772568 all mean 0.10868627578020096
0.3131205439567566 0.3131205439567566
rl training, epoch7, iter0, batch653/1133, batch loss:0.3131205439567566, Training time:23935.521637916565
batch reward last col mean 0.08510713279247284 first col mean 0.10140726715326309 all mean 0.09236923605203629
0.22674496471881866 0.22674494981765747
rl training, epoch7, iter0, batch654/1133, batch loss:0.22674494981765747, Training time:23937.368495941162
batch reward last col mean 0.12582609057426453 first col mean 0.10018274188041687 all mean 0.11940058320760727
0.31485068798065186 0.31485068798065186
rl training, epoch7, iter0, batch655/1133, batch loss:0.31485068798065186, Training time:23938.840757608414
batch reward last col mean 0.11180440336465836 first col mean 0.11433836817741394 all mean 0.11548043042421341
0.27202656865119934 0.27202656865119934
rl training, epoch7, iter0, batch656/1133, batch loss:0.27202656865119934, Training time:23940.371710538864
batch reward last col mean 0.10327517986297607 first col mean 0.1181693971157074 all mean 0.10138401389122009
0.27499252557754517 0.27499252557754517
rl training, epoch7, iter0, batch657/1133, batch loss:0.27499252557754517, Training time:23942.096544981003
batch reward last col mean 0.0786619782447815 first col mean 0.10876071453094482 all mean 0.0875774696469307
0.25860273838043213 0.25860273838043213
rl training, epoch7, iter0, batch658/1133, batch loss:0.25860273838043213, Training time:23943.64502954483
batch reward last col mean 0.07492226362228394 first col mean 0.10020431131124496 all mean 0.08331765234470367
0.2409718632698059 0.24097184836864471
rl training, epoch7, iter0, batch659/1133, batch loss:0.24097184836864471, Training time:23945.243294477463
batch reward last col mean 0.07617422938346863 first col mean 0.10133630037307739 all mean 0.08316482603549957
0.25813326239585876 0.25813326239585876
rl training, epoch7, iter0, batch660/1133, batch loss:0.25813326239585876, Training time:23946.815938472748
batch reward last col mean 0.10156021267175674 first col mean 0.10180269926786423 all mean 0.10428234934806824
0.26405835151672363 0.26405835151672363
rl training, epoch7, iter0, batch661/1133, batch loss:0.26405835151672363, Training time:23948.47606062889
batch reward last col mean 0.09362153708934784 first col mean 0.11075938493013382 all mean 0.09584128856658936
0.29854440689086914 0.29854440689086914
rl training, epoch7, iter0, batch662/1133, batch loss:0.29854440689086914, Training time:23950.707783460617
batch reward last col mean 0.1195068359375 first col mean 0.09684935212135315 all mean 0.11250986158847809
0.26945626735687256 0.26945626735687256
rl training, epoch7, iter0, batch663/1133, batch loss:0.26945626735687256, Training time:23952.443684577942
batch reward last col mean 0.11317872256040573 first col mean 0.10727377235889435 all mean 0.10999521613121033
0.27899280190467834 0.27899280190467834
rl training, epoch7, iter0, batch664/1133, batch loss:0.27899280190467834, Training time:23954.092847824097
batch reward last col mean 0.09425896406173706 first col mean 0.11575725674629211 all mean 0.09478791803121567
0.272256076335907 0.272256076335907
rl training, epoch7, iter0, batch665/1133, batch loss:0.272256076335907, Training time:23956.66411113739
batch reward last col mean 0.09427297115325928 first col mean 0.09199437499046326 all mean 0.10208618640899658
0.2968442738056183 0.2968442738056183
rl training, epoch7, iter0, batch666/1133, batch loss:0.2968442738056183, Training time:23958.1334836483
batch reward last col mean 0.08874557912349701 first col mean 0.09763605892658234 all mean 0.086500383913517
0.269157350063324 0.269157350063324
rl training, epoch7, iter0, batch667/1133, batch loss:0.269157350063324, Training time:23960.1394302845
batch reward last col mean 0.08952374011278152 first col mean 0.11020103096961975 all mean 0.0991743728518486
0.29612791538238525 0.29612791538238525
rl training, epoch7, iter0, batch668/1133, batch loss:0.29612791538238525, Training time:23961.793741226196
batch reward last col mean 0.11695258319377899 first col mean 0.09153509885072708 all mean 0.11355965584516525
0.2890368103981018 0.2890368103981018
rl training, epoch7, iter0, batch669/1133, batch loss:0.2890368103981018, Training time:23963.840215206146
batch reward last col mean 0.10225421190261841 first col mean 0.10557541251182556 all mean 0.10629525780677795
0.27794620394706726 0.27794620394706726
rl training, epoch7, iter0, batch670/1133, batch loss:0.27794620394706726, Training time:23965.884309530258
batch reward last col mean 0.1350654810667038 first col mean 0.10926813632249832 all mean 0.12966379523277283
0.3097689747810364 0.3097689747810364
rl training, epoch7, iter0, batch671/1133, batch loss:0.3097689747810364, Training time:23967.574719667435
batch reward last col mean 0.07328904420137405 first col mean 0.09859231859445572 all mean 0.08042103797197342
0.22740785777568817 0.22740785777568817
rl training, epoch7, iter0, batch672/1133, batch loss:0.22740785777568817, Training time:23969.705441713333
batch reward last col mean 0.08878326416015625 first col mean 0.111905038356781 all mean 0.09587271511554718
0.25850358605384827 0.25850358605384827
rl training, epoch7, iter0, batch673/1133, batch loss:0.25850358605384827, Training time:23971.763096809387
batch reward last col mean 0.08810845017433167 first col mean 0.13353997468948364 all mean 0.09411221742630005
0.2533014714717865 0.2533014714717865
rl training, epoch7, iter0, batch674/1133, batch loss:0.2533014714717865, Training time:23973.674098968506
batch reward last col mean 0.162884920835495 first col mean 0.10778917372226715 all mean 0.14418858289718628
0.2926150858402252 0.2926151156425476
rl training, epoch7, iter0, batch675/1133, batch loss:0.2926151156425476, Training time:23975.347328424454
batch reward last col mean 0.11295507848262787 first col mean 0.10143017768859863 all mean 0.11183362454175949
0.2697017192840576 0.2697017192840576
rl training, epoch7, iter0, batch676/1133, batch loss:0.2697017192840576, Training time:23976.940724611282
batch reward last col mean 0.1317131668329239 first col mean 0.09156738966703415 all mean 0.11793740093708038
0.32301783561706543 0.32301783561706543
rl training, epoch7, iter0, batch677/1133, batch loss:0.32301783561706543, Training time:23978.597613334656
batch reward last col mean 0.11611409485340118 first col mean 0.11439195275306702 all mean 0.10960925370454788
0.27919360995292664 0.27919360995292664
rl training, epoch7, iter0, batch678/1133, batch loss:0.27919360995292664, Training time:23980.20633292198
batch reward last col mean 0.11817091703414917 first col mean 0.10779726505279541 all mean 0.1142675057053566
0.28480979800224304 0.28480976819992065
rl training, epoch7, iter0, batch679/1133, batch loss:0.28480976819992065, Training time:23981.727558612823
batch reward last col mean 0.09833946824073792 first col mean 0.1028645932674408 all mean 0.09647990018129349
0.2653798758983612 0.2653798758983612
rl training, epoch7, iter0, batch680/1133, batch loss:0.2653798758983612, Training time:23983.3554251194
batch reward last col mean 0.09915712475776672 first col mean 0.0971975177526474 all mean 0.09746693074703217
0.2682783603668213 0.2682783603668213
rl training, epoch7, iter0, batch681/1133, batch loss:0.2682783603668213, Training time:23985.441491365433
batch reward last col mean 0.12493157386779785 first col mean 0.11722061783075333 all mean 0.11466550081968307
0.2844425141811371 0.2844425141811371
rl training, epoch7, iter0, batch682/1133, batch loss:0.2844425141811371, Training time:23987.315336942673
batch reward last col mean 0.10199873149394989 first col mean 0.09164341539144516 all mean 0.09806936234235764
0.22640563547611237 0.22640563547611237
rl training, epoch7, iter0, batch683/1133, batch loss:0.22640563547611237, Training time:23988.950399398804
batch reward last col mean 0.1271454393863678 first col mean 0.10302238166332245 all mean 0.11605954170227051
0.30754923820495605 0.30754926800727844
rl training, epoch7, iter0, batch684/1133, batch loss:0.30754926800727844, Training time:23991.063290834427
batch reward last col mean 0.10922020673751831 first col mean 0.10890474170446396 all mean 0.10936789959669113
0.3106834590435028 0.3106834590435028
rl training, epoch7, iter0, batch685/1133, batch loss:0.3106834590435028, Training time:23992.61188697815
batch reward last col mean 0.11333417147397995 first col mean 0.1133764386177063 all mean 0.11609936505556107
0.2655107080936432 0.2655107080936432
rl training, epoch7, iter0, batch686/1133, batch loss:0.2655107080936432, Training time:23994.56049990654
batch reward last col mean 0.11342333257198334 first col mean 0.09109412878751755 all mean 0.11130785942077637
0.3058106005191803 0.3058106005191803
rl training, epoch7, iter0, batch687/1133, batch loss:0.3058106005191803, Training time:23996.318831205368
batch reward last col mean 0.10569120198488235 first col mean 0.10049930214881897 all mean 0.10679484903812408
0.30752119421958923 0.30752119421958923
rl training, epoch7, iter0, batch688/1133, batch loss:0.30752119421958923, Training time:23998.267694473267
batch reward last col mean 0.08506304770708084 first col mean 0.10964209586381912 all mean 0.09233592450618744
0.27537456154823303 0.27537456154823303
rl training, epoch7, iter0, batch689/1133, batch loss:0.27537456154823303, Training time:23999.809350967407
batch reward last col mean 0.07993794232606888 first col mean 0.08407480269670486 all mean 0.08428239822387695
0.2292647808790207 0.2292647510766983
rl training, epoch7, iter0, batch690/1133, batch loss:0.2292647510766983, Training time:24001.535703659058
batch reward last col mean 0.1047186553478241 first col mean 0.11124861240386963 all mean 0.09616449475288391
0.23621730506420135 0.23621733486652374
rl training, epoch7, iter0, batch691/1133, batch loss:0.23621733486652374, Training time:24003.290781259537
batch reward last col mean 0.10064777731895447 first col mean 0.10867195576429367 all mean 0.10334362089633942
0.29969581961631775 0.29969584941864014
rl training, epoch7, iter0, batch692/1133, batch loss:0.29969584941864014, Training time:24005.049716472626
batch reward last col mean 0.09798426926136017 first col mean 0.11665631830692291 all mean 0.10660230368375778
0.33772456645965576 0.337724506855011
rl training, epoch7, iter0, batch693/1133, batch loss:0.337724506855011, Training time:24006.83935546875
batch reward last col mean 0.11583641171455383 first col mean 0.0999838262796402 all mean 0.1127043291926384
0.2701268494129181 0.2701268494129181
rl training, epoch7, iter0, batch694/1133, batch loss:0.2701268494129181, Training time:24008.439649820328
batch reward last col mean 0.10052023082971573 first col mean 0.098111592233181 all mean 0.09856490045785904
0.29079875349998474 0.29079875349998474
rl training, epoch7, iter0, batch695/1133, batch loss:0.29079875349998474, Training time:24010.188796043396
batch reward last col mean 0.1186177134513855 first col mean 0.1127210184931755 all mean 0.12004458159208298
0.3040730953216553 0.3040730953216553
rl training, epoch7, iter0, batch696/1133, batch loss:0.3040730953216553, Training time:24012.057175159454
batch reward last col mean 0.10289587825536728 first col mean 0.11593444645404816 all mean 0.10754941403865814
0.2690097689628601 0.2690097689628601
rl training, epoch7, iter0, batch697/1133, batch loss:0.2690097689628601, Training time:24014.10955953598
batch reward last col mean 0.1044773980975151 first col mean 0.11224919557571411 all mean 0.10455802083015442
0.27339106798171997 0.27339106798171997
rl training, epoch7, iter0, batch698/1133, batch loss:0.27339106798171997, Training time:24016.052851200104
batch reward last col mean 0.08876300603151321 first col mean 0.1098199337720871 all mean 0.09844760596752167
0.28486326336860657 0.28486326336860657
rl training, epoch7, iter0, batch699/1133, batch loss:0.28486326336860657, Training time:24018.01618051529
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47223363520819217 Time: 94.90723657608032 s
loss of true 0.20469382457888874 loss of gen 0.17189785177899164 loss of other 0.09564195897114534 first score 0.08454981446266174
batch reward last col mean 0.12913143634796143 first col mean 0.10104425251483917 all mean 0.12823337316513062
0.30189794301986694 0.30189794301986694
rl training, epoch7, iter0, batch700/1133, batch loss:0.30189794301986694, Training time:24115.152135133743
batch reward last col mean 0.09587214142084122 first col mean 0.11276520788669586 all mean 0.09629710018634796
0.2483876645565033 0.2483876645565033
rl training, epoch7, iter0, batch701/1133, batch loss:0.2483876645565033, Training time:24117.01966023445
batch reward last col mean 0.1175791472196579 first col mean 0.1092950701713562 all mean 0.11445361375808716
0.2805781960487366 0.2805781960487366
rl training, epoch7, iter0, batch702/1133, batch loss:0.2805781960487366, Training time:24118.763345003128
batch reward last col mean 0.09728199243545532 first col mean 0.12179916352033615 all mean 0.09770745038986206
0.30674558877944946 0.3067455589771271
rl training, epoch7, iter0, batch703/1133, batch loss:0.3067455589771271, Training time:24120.60211110115
batch reward last col mean 0.11645583063364029 first col mean 0.09530827403068542 all mean 0.10983690619468689
0.30011406540870667 0.30011406540870667
rl training, epoch7, iter0, batch704/1133, batch loss:0.30011406540870667, Training time:24122.315990447998
batch reward last col mean 0.1036742627620697 first col mean 0.10856890678405762 all mean 0.10222193598747253
0.28718772530555725 0.28718772530555725
rl training, epoch7, iter0, batch705/1133, batch loss:0.28718772530555725, Training time:24124.437398195267
batch reward last col mean 0.10285139083862305 first col mean 0.12143035233020782 all mean 0.11048636585474014
0.31640252470970154 0.31640252470970154
rl training, epoch7, iter0, batch706/1133, batch loss:0.31640252470970154, Training time:24126.165931224823
batch reward last col mean 0.11799809336662292 first col mean 0.09226619452238083 all mean 0.11737944185733795
0.2668032944202423 0.2668032646179199
rl training, epoch7, iter0, batch707/1133, batch loss:0.2668032646179199, Training time:24127.875413417816
batch reward last col mean 0.12572672963142395 first col mean 0.10770485550165176 all mean 0.12623509764671326
0.32085832953453064 0.32085832953453064
rl training, epoch7, iter0, batch708/1133, batch loss:0.32085832953453064, Training time:24130.029422283173
batch reward last col mean 0.07776554673910141 first col mean 0.10937803238630295 all mean 0.08498132973909378
0.25544795393943787 0.25544795393943787
rl training, epoch7, iter0, batch709/1133, batch loss:0.25544795393943787, Training time:24131.939163446426
batch reward last col mean 0.07981577515602112 first col mean 0.10205061733722687 all mean 0.08613001555204391
0.2709050178527832 0.2709050178527832
rl training, epoch7, iter0, batch710/1133, batch loss:0.2709050178527832, Training time:24133.975406885147
batch reward last col mean 0.12512759864330292 first col mean 0.10690398514270782 all mean 0.12328951060771942
0.3286382555961609 0.3286382555961609
rl training, epoch7, iter0, batch711/1133, batch loss:0.3286382555961609, Training time:24136.7355632782
batch reward last col mean 0.10974108427762985 first col mean 0.09981444478034973 all mean 0.10744614154100418
0.2628020942211151 0.2628020942211151
rl training, epoch7, iter0, batch712/1133, batch loss:0.2628020942211151, Training time:24138.37985253334
batch reward last col mean 0.09863536059856415 first col mean 0.10571620613336563 all mean 0.09930485486984253
0.2591691315174103 0.2591691315174103
rl training, epoch7, iter0, batch713/1133, batch loss:0.2591691315174103, Training time:24140.13895869255
batch reward last col mean 0.08682522177696228 first col mean 0.0864957720041275 all mean 0.08858739584684372
0.2884052097797394 0.2884052097797394
rl training, epoch7, iter0, batch714/1133, batch loss:0.2884052097797394, Training time:24141.685402154922
batch reward last col mean 0.09489206224679947 first col mean 0.09045799821615219 all mean 0.10053206235170364
0.2634115219116211 0.2634115219116211
rl training, epoch7, iter0, batch715/1133, batch loss:0.2634115219116211, Training time:24143.476316213608
batch reward last col mean 0.109954833984375 first col mean 0.12807612121105194 all mean 0.10964865237474442
0.29133760929107666 0.29133760929107666
rl training, epoch7, iter0, batch716/1133, batch loss:0.29133760929107666, Training time:24145.255736112595
batch reward last col mean 0.06883107125759125 first col mean 0.12092109769582748 all mean 0.08142226189374924
0.27573755383491516 0.27573755383491516
rl training, epoch7, iter0, batch717/1133, batch loss:0.27573755383491516, Training time:24147.8158493042
batch reward last col mean 0.10646107792854309 first col mean 0.09767968207597733 all mean 0.10818129032850266
0.3100689649581909 0.3100689649581909
rl training, epoch7, iter0, batch718/1133, batch loss:0.3100689649581909, Training time:24149.850904226303
batch reward last col mean 0.0889337882399559 first col mean 0.10826414078474045 all mean 0.09103947877883911
0.2734350562095642 0.2734350562095642
rl training, epoch7, iter0, batch719/1133, batch loss:0.2734350562095642, Training time:24151.72706770897
batch reward last col mean 0.08678266406059265 first col mean 0.10307842493057251 all mean 0.08886580914258957
0.28000882267951965 0.28000882267951965
rl training, epoch7, iter0, batch720/1133, batch loss:0.28000882267951965, Training time:24153.77854323387
batch reward last col mean 0.09604451060295105 first col mean 0.10950061678886414 all mean 0.09737546741962433
0.2758408784866333 0.2758408784866333
rl training, epoch7, iter0, batch721/1133, batch loss:0.2758408784866333, Training time:24155.76081776619
batch reward last col mean 0.10616610944271088 first col mean 0.11392495036125183 all mean 0.10539412498474121
0.23384660482406616 0.23384660482406616
rl training, epoch7, iter0, batch722/1133, batch loss:0.23384660482406616, Training time:24158.33262705803
batch reward last col mean 0.06708347797393799 first col mean 0.08341844379901886 all mean 0.07521894574165344
0.22924478352069855 0.22924478352069855
rl training, epoch7, iter0, batch723/1133, batch loss:0.22924478352069855, Training time:24160.375024080276
batch reward last col mean 0.07968004047870636 first col mean 0.134711354970932 all mean 0.08963214606046677
0.29086658358573914 0.29086658358573914
rl training, epoch7, iter0, batch724/1133, batch loss:0.29086658358573914, Training time:24161.9085085392
batch reward last col mean 0.09069400280714035 first col mean 0.10071173310279846 all mean 0.08607680350542068
0.2636477053165436 0.2636477053165436
rl training, epoch7, iter0, batch725/1133, batch loss:0.2636477053165436, Training time:24163.683970928192
batch reward last col mean 0.12187548726797104 first col mean 0.0960877314209938 all mean 0.11116088181734085
0.2761572003364563 0.2761572003364563
rl training, epoch7, iter0, batch726/1133, batch loss:0.2761572003364563, Training time:24165.328889131546
batch reward last col mean 0.1130126342177391 first col mean 0.11165282875299454 all mean 0.11167218536138535
0.27924901247024536 0.27924901247024536
rl training, epoch7, iter0, batch727/1133, batch loss:0.27924901247024536, Training time:24167.1524643898
batch reward last col mean 0.09084052592515945 first col mean 0.10967940837144852 all mean 0.09491869807243347
0.28696727752685547 0.28696727752685547
rl training, epoch7, iter0, batch728/1133, batch loss:0.28696727752685547, Training time:24169.191570997238
batch reward last col mean 0.10352064669132233 first col mean 0.1089324951171875 all mean 0.11080681532621384
0.3252594470977783 0.3252594470977783
rl training, epoch7, iter0, batch729/1133, batch loss:0.3252594470977783, Training time:24171.268890857697
batch reward last col mean 0.11278907209634781 first col mean 0.09930720925331116 all mean 0.11331307888031006
0.2889842092990875 0.28898417949676514
rl training, epoch7, iter0, batch730/1133, batch loss:0.28898417949676514, Training time:24172.796742916107
batch reward last col mean 0.1324368119239807 first col mean 0.12131674587726593 all mean 0.1261787712574005
0.26026058197021484 0.26026058197021484
rl training, epoch7, iter0, batch731/1133, batch loss:0.26026058197021484, Training time:24175.020990133286
batch reward last col mean 0.08314718306064606 first col mean 0.10623103380203247 all mean 0.09261062741279602
0.2708468735218048 0.2708468437194824
rl training, epoch7, iter0, batch732/1133, batch loss:0.2708468437194824, Training time:24176.71248316765
batch reward last col mean 0.1276499629020691 first col mean 0.10062376409769058 all mean 0.12132225930690765
0.2858729362487793 0.2858729362487793
rl training, epoch7, iter0, batch733/1133, batch loss:0.2858729362487793, Training time:24178.45659804344
batch reward last col mean 0.14648893475532532 first col mean 0.12060247361660004 all mean 0.13814237713813782
0.3033428192138672 0.3033428192138672
rl training, epoch7, iter0, batch734/1133, batch loss:0.3033428192138672, Training time:24180.07040166855
batch reward last col mean 0.10043437778949738 first col mean 0.10368441790342331 all mean 0.10575421899557114
0.31213900446891785 0.31213900446891785
rl training, epoch7, iter0, batch735/1133, batch loss:0.31213900446891785, Training time:24181.92884159088
batch reward last col mean 0.08981209993362427 first col mean 0.1097366064786911 all mean 0.09898125380277634
0.2656497061252594 0.265649676322937
rl training, epoch7, iter0, batch736/1133, batch loss:0.265649676322937, Training time:24183.696013450623
batch reward last col mean 0.12722215056419373 first col mean 0.11291908472776413 all mean 0.12150704860687256
0.3240797221660614 0.3240797221660614
rl training, epoch7, iter0, batch737/1133, batch loss:0.3240797221660614, Training time:24185.51791524887
batch reward last col mean 0.06645586341619492 first col mean 0.11369180679321289 all mean 0.08099748939275742
0.25003406405448914 0.25003406405448914
rl training, epoch7, iter0, batch738/1133, batch loss:0.25003406405448914, Training time:24187.32360267639
batch reward last col mean 0.07861106097698212 first col mean 0.11594830453395844 all mean 0.09393999725580215
0.3018060326576233 0.3018060326576233
rl training, epoch7, iter0, batch739/1133, batch loss:0.3018060326576233, Training time:24188.80695104599
batch reward last col mean 0.05814233049750328 first col mean 0.1074242889881134 all mean 0.0701909288764
0.21628452837467194 0.21628452837467194
rl training, epoch7, iter0, batch740/1133, batch loss:0.21628452837467194, Training time:24190.91042995453
batch reward last col mean 0.08744104206562042 first col mean 0.09104054421186447 all mean 0.08973003178834915
0.23127734661102295 0.23127734661102295
rl training, epoch7, iter0, batch741/1133, batch loss:0.23127734661102295, Training time:24193.22281217575
batch reward last col mean 0.12113885581493378 first col mean 0.11548419296741486 all mean 0.11343792825937271
0.24871376156806946 0.24871376156806946
rl training, epoch7, iter0, batch742/1133, batch loss:0.24871376156806946, Training time:24195.211466550827
batch reward last col mean 0.11281648278236389 first col mean 0.12186459451913834 all mean 0.1138664186000824
0.3179975152015686 0.3179975152015686
rl training, epoch7, iter0, batch743/1133, batch loss:0.3179975152015686, Training time:24197.13210463524
batch reward last col mean 0.10741046816110611 first col mean 0.11588065326213837 all mean 0.10491019487380981
0.29850122332572937 0.29850122332572937
rl training, epoch7, iter0, batch744/1133, batch loss:0.29850122332572937, Training time:24199.310072660446
batch reward last col mean 0.08882521837949753 first col mean 0.09547869861125946 all mean 0.09665843844413757
0.27242788672447205 0.27242791652679443
rl training, epoch7, iter0, batch745/1133, batch loss:0.27242791652679443, Training time:24201.127763032913
batch reward last col mean 0.14797525107860565 first col mean 0.11656191200017929 all mean 0.13638873398303986
0.33531439304351807 0.33531439304351807
rl training, epoch7, iter0, batch746/1133, batch loss:0.33531439304351807, Training time:24202.722098350525
batch reward last col mean 0.08388819545507431 first col mean 0.11145813763141632 all mean 0.08874385803937912
0.26163536310195923 0.2616353929042816
rl training, epoch7, iter0, batch747/1133, batch loss:0.2616353929042816, Training time:24205.331619501114
batch reward last col mean 0.1113128513097763 first col mean 0.1046110987663269 all mean 0.1086435467004776
0.2754058539867401 0.2754058539867401
rl training, epoch7, iter0, batch748/1133, batch loss:0.2754058539867401, Training time:24207.74645113945
batch reward last col mean 0.08933208882808685 first col mean 0.10602647811174393 all mean 0.09049040824174881
0.242344930768013 0.2423449158668518
rl training, epoch7, iter0, batch749/1133, batch loss:0.2423449158668518, Training time:24209.66570353508
batch reward last col mean 0.1069658100605011 first col mean 0.10929635912179947 all mean 0.10777324438095093
0.30694013833999634 0.30694010853767395
rl training, epoch7, iter0, batch750/1133, batch loss:0.30694010853767395, Training time:24211.098871469498
batch reward last col mean 0.09764434397220612 first col mean 0.11533769965171814 all mean 0.10461808741092682
0.32257336378097534 0.32257336378097534
rl training, epoch7, iter0, batch751/1133, batch loss:0.32257336378097534, Training time:24212.654265880585
batch reward last col mean 0.11678595095872879 first col mean 0.1314658522605896 all mean 0.10811598598957062
0.2985677719116211 0.2985677719116211
rl training, epoch7, iter0, batch752/1133, batch loss:0.2985677719116211, Training time:24214.984229326248
batch reward last col mean 0.09430161118507385 first col mean 0.10617460310459137 all mean 0.09777624905109406
0.28761282563209534 0.28761282563209534
rl training, epoch7, iter0, batch753/1133, batch loss:0.28761282563209534, Training time:24216.32483124733
batch reward last col mean 0.10143596678972244 first col mean 0.11168883740901947 all mean 0.10963727533817291
0.307620108127594 0.307620108127594
rl training, epoch7, iter0, batch754/1133, batch loss:0.307620108127594, Training time:24217.752906560898
batch reward last col mean 0.10346725583076477 first col mean 0.10005674511194229 all mean 0.10890670120716095
0.29605230689048767 0.29605230689048767
rl training, epoch7, iter0, batch755/1133, batch loss:0.29605230689048767, Training time:24219.299867630005
batch reward last col mean 0.09187008440494537 first col mean 0.09036581218242645 all mean 0.0979018583893776
0.27475571632385254 0.27475571632385254
rl training, epoch7, iter0, batch756/1133, batch loss:0.27475571632385254, Training time:24220.9296374321
batch reward last col mean 0.10668600350618362 first col mean 0.12023812532424927 all mean 0.1054103747010231
0.28802981972694397 0.2880297899246216
rl training, epoch7, iter0, batch757/1133, batch loss:0.2880297899246216, Training time:24222.791927814484
batch reward last col mean 0.09777946770191193 first col mean 0.09263981878757477 all mean 0.09937933087348938
0.24663637578487396 0.24663637578487396
rl training, epoch7, iter0, batch758/1133, batch loss:0.24663637578487396, Training time:24224.52985239029
batch reward last col mean 0.11606207489967346 first col mean 0.11610371619462967 all mean 0.11687374114990234
0.29494497179985046 0.29494497179985046
rl training, epoch7, iter0, batch759/1133, batch loss:0.29494497179985046, Training time:24225.92622423172
batch reward last col mean 0.07385407388210297 first col mean 0.10538866370916367 all mean 0.0807870402932167
0.2673802971839905 0.2673802971839905
rl training, epoch7, iter0, batch760/1133, batch loss:0.2673802971839905, Training time:24227.41955447197
batch reward last col mean 0.11118048429489136 first col mean 0.09510349482297897 all mean 0.10659082978963852
0.2921499013900757 0.2921499013900757
rl training, epoch7, iter0, batch761/1133, batch loss:0.2921499013900757, Training time:24228.885068416595
batch reward last col mean 0.07008740305900574 first col mean 0.10431993007659912 all mean 0.07828718423843384
0.29046276211738586 0.29046279191970825
rl training, epoch7, iter0, batch762/1133, batch loss:0.29046279191970825, Training time:24231.337775230408
batch reward last col mean 0.11358726769685745 first col mean 0.11510441452264786 all mean 0.113201804459095
0.2990865111351013 0.2990865111351013
rl training, epoch7, iter0, batch763/1133, batch loss:0.2990865111351013, Training time:24232.91328907013
batch reward last col mean 0.11079712957143784 first col mean 0.10678093880414963 all mean 0.11314485967159271
0.32954421639442444 0.32954421639442444
rl training, epoch7, iter0, batch764/1133, batch loss:0.32954421639442444, Training time:24234.702565193176
batch reward last col mean 0.08715786784887314 first col mean 0.12856005132198334 all mean 0.08933238685131073
0.2739134132862091 0.2739134132862091
rl training, epoch7, iter0, batch765/1133, batch loss:0.2739134132862091, Training time:24236.09156870842
batch reward last col mean 0.10016858577728271 first col mean 0.09431686997413635 all mean 0.1046844869852066
0.30941951274871826 0.30941951274871826
rl training, epoch7, iter0, batch766/1133, batch loss:0.30941951274871826, Training time:24237.59238553047
batch reward last col mean 0.11607266962528229 first col mean 0.10786004364490509 all mean 0.10949287563562393
0.3265041708946228 0.3265041708946228
rl training, epoch7, iter0, batch767/1133, batch loss:0.3265041708946228, Training time:24239.58502459526
batch reward last col mean 0.11317771673202515 first col mean 0.0963459461927414 all mean 0.10607566684484482
0.2674843966960907 0.2674843966960907
rl training, epoch7, iter0, batch768/1133, batch loss:0.2674843966960907, Training time:24241.26107430458
batch reward last col mean 0.09478931128978729 first col mean 0.10638650506734848 all mean 0.09852512180805206
0.305392861366272 0.3053928017616272
rl training, epoch7, iter0, batch769/1133, batch loss:0.3053928017616272, Training time:24243.37204837799
batch reward last col mean 0.11526468396186829 first col mean 0.11413128674030304 all mean 0.11760444194078445
0.3288173973560333 0.3288173973560333
rl training, epoch7, iter0, batch770/1133, batch loss:0.3288173973560333, Training time:24244.86044049263
batch reward last col mean 0.13092662394046783 first col mean 0.10485595464706421 all mean 0.12682974338531494
0.30246689915657043 0.30246686935424805
rl training, epoch7, iter0, batch771/1133, batch loss:0.30246686935424805, Training time:24246.6072845459
batch reward last col mean 0.1290234625339508 first col mean 0.09184206277132034 all mean 0.11778007447719574
0.30008649826049805 0.30008649826049805
rl training, epoch7, iter0, batch772/1133, batch loss:0.30008649826049805, Training time:24248.342099428177
batch reward last col mean 0.10454101115465164 first col mean 0.1148521825671196 all mean 0.10823889076709747
0.310646653175354 0.310646653175354
rl training, epoch7, iter0, batch773/1133, batch loss:0.310646653175354, Training time:24250.40059018135
batch reward last col mean 0.08671814203262329 first col mean 0.10053509473800659 all mean 0.09421832114458084
0.280304491519928 0.280304491519928
rl training, epoch7, iter0, batch774/1133, batch loss:0.280304491519928, Training time:24252.217993736267
batch reward last col mean 0.09662549197673798 first col mean 0.09531675279140472 all mean 0.10027729719877243
0.3091980814933777 0.3091980814933777
rl training, epoch7, iter0, batch775/1133, batch loss:0.3091980814933777, Training time:24254.135968208313
batch reward last col mean 0.11589863151311874 first col mean 0.10964325070381165 all mean 0.11152166873216629
0.26681196689605713 0.26681193709373474
rl training, epoch7, iter0, batch776/1133, batch loss:0.26681193709373474, Training time:24255.809294462204
batch reward last col mean 0.11452336609363556 first col mean 0.12066881358623505 all mean 0.1136508360505104
0.27305909991264343 0.27305909991264343
rl training, epoch7, iter0, batch777/1133, batch loss:0.27305909991264343, Training time:24257.341251850128
batch reward last col mean 0.10488751530647278 first col mean 0.11784032732248306 all mean 0.10268788784742355
0.2771807610988617 0.2771807610988617
rl training, epoch7, iter0, batch778/1133, batch loss:0.2771807610988617, Training time:24259.05295777321
batch reward last col mean 0.08226832747459412 first col mean 0.10173331946134567 all mean 0.08891385048627853
0.26284119486808777 0.26284119486808777
rl training, epoch7, iter0, batch779/1133, batch loss:0.26284119486808777, Training time:24260.727732658386
batch reward last col mean 0.08958179503679276 first col mean 0.11186631768941879 all mean 0.09509185701608658
0.23826953768730164 0.23826952278614044
rl training, epoch7, iter0, batch780/1133, batch loss:0.23826952278614044, Training time:24263.217749595642
batch reward last col mean 0.10941798239946365 first col mean 0.11917591094970703 all mean 0.1128477230668068
0.3210025131702423 0.3210025131702423
rl training, epoch7, iter0, batch781/1133, batch loss:0.3210025131702423, Training time:24265.278827905655
batch reward last col mean 0.09069564938545227 first col mean 0.12147402763366699 all mean 0.09945637732744217
0.2538381516933441 0.2538381516933441
rl training, epoch7, iter0, batch782/1133, batch loss:0.2538381516933441, Training time:24267.665769815445
batch reward last col mean 0.09528052806854248 first col mean 0.10267722606658936 all mean 0.10205259174108505
0.2819041609764099 0.2819041609764099
rl training, epoch7, iter0, batch783/1133, batch loss:0.2819041609764099, Training time:24269.572055101395
batch reward last col mean 0.09222079813480377 first col mean 0.1047712117433548 all mean 0.09376803040504456
0.28562289476394653 0.28562289476394653
rl training, epoch7, iter0, batch784/1133, batch loss:0.28562289476394653, Training time:24271.271834135056
batch reward last col mean 0.1022811233997345 first col mean 0.09468498826026917 all mean 0.10112246125936508
0.2616015672683716 0.2616015374660492
rl training, epoch7, iter0, batch785/1133, batch loss:0.2616015374660492, Training time:24273.225180387497
batch reward last col mean 0.10896390676498413 first col mean 0.1324194371700287 all mean 0.10636473447084427
0.27767667174339294 0.27767667174339294
rl training, epoch7, iter0, batch786/1133, batch loss:0.27767667174339294, Training time:24274.915545225143
batch reward last col mean 0.09294215589761734 first col mean 0.11263778805732727 all mean 0.09925701469182968
0.26329606771469116 0.26329606771469116
rl training, epoch7, iter0, batch787/1133, batch loss:0.26329606771469116, Training time:24276.913051366806
batch reward last col mean 0.12481149286031723 first col mean 0.12339866161346436 all mean 0.1199074238538742
0.2983643114566803 0.2983642816543579
rl training, epoch7, iter0, batch788/1133, batch loss:0.2983642816543579, Training time:24278.510405540466
batch reward last col mean 0.11290227621793747 first col mean 0.09613901376724243 all mean 0.11165907233953476
0.2671947777271271 0.2671947777271271
rl training, epoch7, iter0, batch789/1133, batch loss:0.2671947777271271, Training time:24279.89829969406
batch reward last col mean 0.09417691826820374 first col mean 0.10972824692726135 all mean 0.10227889567613602
0.31403687596321106 0.31403687596321106
rl training, epoch7, iter0, batch790/1133, batch loss:0.31403687596321106, Training time:24281.35393023491
batch reward last col mean 0.1404138058423996 first col mean 0.12496913224458694 all mean 0.13566431403160095
0.3226626217365265 0.3226626217365265
rl training, epoch7, iter0, batch791/1133, batch loss:0.3226626217365265, Training time:24283.22121310234
batch reward last col mean 0.1027228832244873 first col mean 0.11716783046722412 all mean 0.11051512509584427
0.30272457003593445 0.30272457003593445
rl training, epoch7, iter0, batch792/1133, batch loss:0.30272457003593445, Training time:24284.904210805893
batch reward last col mean 0.12726104259490967 first col mean 0.1161736473441124 all mean 0.11821386218070984
0.31399115920066833 0.31399115920066833
rl training, epoch7, iter0, batch793/1133, batch loss:0.31399115920066833, Training time:24287.113232135773
batch reward last col mean 0.09378562122583389 first col mean 0.10930927842855453 all mean 0.09830570220947266
0.2893643081188202 0.2893643081188202
rl training, epoch7, iter0, batch794/1133, batch loss:0.2893643081188202, Training time:24288.483737707138
batch reward last col mean 0.13271982967853546 first col mean 0.10314635187387466 all mean 0.12331872433423996
0.31329870223999023 0.31329870223999023
rl training, epoch7, iter0, batch795/1133, batch loss:0.31329870223999023, Training time:24290.17205095291
batch reward last col mean 0.1041955053806305 first col mean 0.113060362637043 all mean 0.10096627473831177
0.28567931056022644 0.28567934036254883
rl training, epoch7, iter0, batch796/1133, batch loss:0.28567934036254883, Training time:24291.71737718582
batch reward last col mean 0.13806094229221344 first col mean 0.10473012924194336 all mean 0.12768776714801788
0.29362156987190247 0.29362156987190247
rl training, epoch7, iter0, batch797/1133, batch loss:0.29362156987190247, Training time:24293.537847042084
batch reward last col mean 0.09312839806079865 first col mean 0.11149847507476807 all mean 0.09731842577457428
0.27939194440841675 0.27939194440841675
rl training, epoch7, iter0, batch798/1133, batch loss:0.27939194440841675, Training time:24295.367426156998
batch reward last col mean 0.1247202605009079 first col mean 0.10726785659790039 all mean 0.1204189881682396
0.29326945543289185 0.29326945543289185
rl training, epoch7, iter0, batch799/1133, batch loss:0.29326945543289185, Training time:24297.285973787308
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4754589893390726 Time: 97.34080529212952 s
loss of true 0.20572055734213957 loss of gen 0.17526391869622948 loss of other 0.09447451354565867 first score 0.1330346018075943
batch reward last col mean 0.08464502543210983 first col mean 0.09786015748977661 all mean 0.08246435225009918
0.24430009722709656 0.24430009722709656
rl training, epoch7, iter0, batch800/1133, batch loss:0.24430009722709656, Training time:24396.305314302444
batch reward last col mean 0.07647694647312164 first col mean 0.11764910817146301 all mean 0.08093433082103729
0.2711823880672455 0.2711823880672455
rl training, epoch7, iter0, batch801/1133, batch loss:0.2711823880672455, Training time:24398.444596529007
batch reward last col mean 0.08709335327148438 first col mean 0.10543064773082733 all mean 0.0882125198841095
0.26985976099967957 0.26985976099967957
rl training, epoch7, iter0, batch802/1133, batch loss:0.26985976099967957, Training time:24400.093585252762
batch reward last col mean 0.0673956573009491 first col mean 0.10595200955867767 all mean 0.08046408742666245
0.26883530616760254 0.26883530616760254
rl training, epoch7, iter0, batch803/1133, batch loss:0.26883530616760254, Training time:24402.264437675476
batch reward last col mean 0.058769114315509796 first col mean 0.11393940448760986 all mean 0.0662861168384552
0.2311181128025055 0.2311181128025055
rl training, epoch7, iter0, batch804/1133, batch loss:0.2311181128025055, Training time:24405.446895122528
batch reward last col mean 0.08853410184383392 first col mean 0.11343108862638474 all mean 0.097083181142807
0.2691294550895691 0.2691294252872467
rl training, epoch7, iter0, batch805/1133, batch loss:0.2691294252872467, Training time:24406.871770620346
batch reward last col mean 0.1011035144329071 first col mean 0.10007740557193756 all mean 0.0998142808675766
0.2483806014060974 0.2483806014060974
rl training, epoch7, iter0, batch806/1133, batch loss:0.2483806014060974, Training time:24409.024437189102
batch reward last col mean 0.11233018338680267 first col mean 0.08597686886787415 all mean 0.10178031772375107
0.28451329469680786 0.28451329469680786
rl training, epoch7, iter0, batch807/1133, batch loss:0.28451329469680786, Training time:24410.80068922043
batch reward last col mean 0.11232611536979675 first col mean 0.10043786466121674 all mean 0.10416101664304733
0.27264222502708435 0.27264219522476196
rl training, epoch7, iter0, batch808/1133, batch loss:0.27264219522476196, Training time:24412.937015533447
batch reward last col mean 0.10281025618314743 first col mean 0.0919005498290062 all mean 0.10588845610618591
0.28682273626327515 0.28682270646095276
rl training, epoch7, iter0, batch809/1133, batch loss:0.28682270646095276, Training time:24415.087824583054
batch reward last col mean 0.10494130849838257 first col mean 0.09250371158123016 all mean 0.09975685924291611
0.2580769956111908 0.2580769956111908
rl training, epoch7, iter0, batch810/1133, batch loss:0.2580769956111908, Training time:24417.174692869186
batch reward last col mean 0.10986834019422531 first col mean 0.09626471251249313 all mean 0.10398376733064651
0.2578361928462982 0.25783616304397583
rl training, epoch7, iter0, batch811/1133, batch loss:0.25783616304397583, Training time:24418.90351176262
batch reward last col mean 0.09502871334552765 first col mean 0.10607601702213287 all mean 0.09978216886520386
0.2805470824241638 0.2805470824241638
rl training, epoch7, iter0, batch812/1133, batch loss:0.2805470824241638, Training time:24420.418276786804
batch reward last col mean 0.07157139480113983 first col mean 0.09154929220676422 all mean 0.0759323313832283
0.23099569976329803 0.23099568486213684
rl training, epoch7, iter0, batch813/1133, batch loss:0.23099568486213684, Training time:24422.600712537766
batch reward last col mean 0.08173172175884247 first col mean 0.1178424209356308 all mean 0.08973610401153564
0.2524677515029907 0.2524677515029907
rl training, epoch7, iter0, batch814/1133, batch loss:0.2524677515029907, Training time:24424.42357158661
batch reward last col mean 0.09571235626935959 first col mean 0.09870307147502899 all mean 0.0951821506023407
0.2617799937725067 0.2617799937725067
rl training, epoch7, iter0, batch815/1133, batch loss:0.2617799937725067, Training time:24426.239386558533
batch reward last col mean 0.10899420082569122 first col mean 0.09123774617910385 all mean 0.10914573073387146
0.25011032819747925 0.25011032819747925
rl training, epoch7, iter0, batch816/1133, batch loss:0.25011032819747925, Training time:24427.840081214905
batch reward last col mean 0.09579196572303772 first col mean 0.10111525654792786 all mean 0.09886927902698517
0.27955278754234314 0.27955278754234314
rl training, epoch7, iter0, batch817/1133, batch loss:0.27955278754234314, Training time:24429.79610466957
batch reward last col mean 0.12002547085285187 first col mean 0.1189609244465828 all mean 0.1137276142835617
0.3055669665336609 0.3055669665336609
rl training, epoch7, iter0, batch818/1133, batch loss:0.3055669665336609, Training time:24432.292021274567
batch reward last col mean 0.1296328455209732 first col mean 0.09322457015514374 all mean 0.12587763369083405
0.291952908039093 0.291952908039093
rl training, epoch7, iter0, batch819/1133, batch loss:0.291952908039093, Training time:24433.928593158722
batch reward last col mean 0.11020864546298981 first col mean 0.119336798787117 all mean 0.10656268894672394
0.26800617575645447 0.26800617575645447
rl training, epoch7, iter0, batch820/1133, batch loss:0.26800617575645447, Training time:24435.81086230278
batch reward last col mean 0.1113307923078537 first col mean 0.11094291508197784 all mean 0.11159385740756989
0.2876386344432831 0.2876386344432831
rl training, epoch7, iter0, batch821/1133, batch loss:0.2876386344432831, Training time:24437.39455986023
batch reward last col mean 0.12591493129730225 first col mean 0.11220437288284302 all mean 0.11557400971651077
0.31286856532096863 0.31286856532096863
rl training, epoch7, iter0, batch822/1133, batch loss:0.31286856532096863, Training time:24439.178364515305
batch reward last col mean 0.13490808010101318 first col mean 0.09251687675714493 all mean 0.12335105985403061
0.2832341492176056 0.2832341492176056
rl training, epoch7, iter0, batch823/1133, batch loss:0.2832341492176056, Training time:24441.928554534912
batch reward last col mean 0.11104562133550644 first col mean 0.11095346510410309 all mean 0.11151915788650513
0.3117469549179077 0.3117469549179077
rl training, epoch7, iter0, batch824/1133, batch loss:0.3117469549179077, Training time:24443.551435232162
batch reward last col mean 0.09785489737987518 first col mean 0.08721990883350372 all mean 0.09137555211782455
0.265595406293869 0.265595406293869
rl training, epoch7, iter0, batch825/1133, batch loss:0.265595406293869, Training time:24445.95148587227
batch reward last col mean 0.11809401214122772 first col mean 0.08337318897247314 all mean 0.1130618304014206
0.24301204085350037 0.24301204085350037
rl training, epoch7, iter0, batch826/1133, batch loss:0.24301204085350037, Training time:24447.42382335663
batch reward last col mean 0.11892031878232956 first col mean 0.1286487877368927 all mean 0.11900757253170013
0.31011736392974854 0.31011736392974854
rl training, epoch7, iter0, batch827/1133, batch loss:0.31011736392974854, Training time:24449.27984380722
batch reward last col mean 0.09568104147911072 first col mean 0.11112228780984879 all mean 0.097712941467762
0.259698748588562 0.259698748588562
rl training, epoch7, iter0, batch828/1133, batch loss:0.259698748588562, Training time:24451.31706047058
batch reward last col mean 0.0929233506321907 first col mean 0.11013561487197876 all mean 0.0893762856721878
0.2551584243774414 0.2551584243774414
rl training, epoch7, iter0, batch829/1133, batch loss:0.2551584243774414, Training time:24453.7842297554
batch reward last col mean 0.09039320796728134 first col mean 0.11153073608875275 all mean 0.08996671438217163
0.253465473651886 0.253465473651886
rl training, epoch7, iter0, batch830/1133, batch loss:0.253465473651886, Training time:24455.75182032585
batch reward last col mean 0.10044607520103455 first col mean 0.0937543660402298 all mean 0.10209619253873825
0.29572299122810364 0.29572299122810364
rl training, epoch7, iter0, batch831/1133, batch loss:0.29572299122810364, Training time:24457.58788061142
batch reward last col mean 0.07593221217393875 first col mean 0.09371894598007202 all mean 0.08412401378154755
0.22749170660972595 0.22749169170856476
rl training, epoch7, iter0, batch832/1133, batch loss:0.22749169170856476, Training time:24459.075759410858
batch reward last col mean 0.09951291978359222 first col mean 0.096918985247612 all mean 0.09607954323291779
0.2395782470703125 0.2395782470703125
rl training, epoch7, iter0, batch833/1133, batch loss:0.2395782470703125, Training time:24461.472358226776
batch reward last col mean 0.08326010406017303 first col mean 0.1092408150434494 all mean 0.08924964815378189
0.22868217527866364 0.22868217527866364
rl training, epoch7, iter0, batch834/1133, batch loss:0.22868217527866364, Training time:24463.08820772171
batch reward last col mean 0.09475243836641312 first col mean 0.10571997612714767 all mean 0.09534122049808502
0.26603081822395325 0.26603081822395325
rl training, epoch7, iter0, batch835/1133, batch loss:0.26603081822395325, Training time:24464.71992969513
batch reward last col mean 0.0768386647105217 first col mean 0.08828794956207275 all mean 0.08700596541166306
0.26736918091773987 0.26736918091773987
rl training, epoch7, iter0, batch836/1133, batch loss:0.26736918091773987, Training time:24466.82352089882
batch reward last col mean 0.09803013503551483 first col mean 0.10485799610614777 all mean 0.0977429747581482
0.282539039850235 0.282539039850235
rl training, epoch7, iter0, batch837/1133, batch loss:0.282539039850235, Training time:24469.70527768135
batch reward last col mean 0.1061764657497406 first col mean 0.09786972403526306 all mean 0.10906321555376053
0.2712692320346832 0.27126920223236084
rl training, epoch7, iter0, batch838/1133, batch loss:0.27126920223236084, Training time:24471.443207263947
batch reward last col mean 0.09545333683490753 first col mean 0.10310147702693939 all mean 0.0987733006477356
0.2902563214302063 0.2902563214302063
rl training, epoch7, iter0, batch839/1133, batch loss:0.2902563214302063, Training time:24473.090743780136
batch reward last col mean 0.06785479187965393 first col mean 0.1123613640666008 all mean 0.0777752622961998
0.24813280999660492 0.24813279509544373
rl training, epoch7, iter0, batch840/1133, batch loss:0.24813279509544373, Training time:24474.820142507553
batch reward last col mean 0.10419618338346481 first col mean 0.08599929511547089 all mean 0.09865131974220276
0.26634758710861206 0.26634758710861206
rl training, epoch7, iter0, batch841/1133, batch loss:0.26634758710861206, Training time:24477.00014948845
batch reward last col mean 0.07519607245922089 first col mean 0.11491155624389648 all mean 0.08419959992170334
0.2691122889518738 0.2691122889518738
rl training, epoch7, iter0, batch842/1133, batch loss:0.2691122889518738, Training time:24479.63168144226
batch reward last col mean 0.11204022914171219 first col mean 0.10958236455917358 all mean 0.11326368898153305
0.2597695589065552 0.2597695589065552
rl training, epoch7, iter0, batch843/1133, batch loss:0.2597695589065552, Training time:24481.451629638672
batch reward last col mean 0.10313698649406433 first col mean 0.10769026726484299 all mean 0.10085059702396393
0.27489596605300903 0.27489596605300903
rl training, epoch7, iter0, batch844/1133, batch loss:0.27489596605300903, Training time:24483.2288107872
batch reward last col mean 0.11099747568368912 first col mean 0.11062295734882355 all mean 0.10776213556528091
0.27196890115737915 0.27196890115737915
rl training, epoch7, iter0, batch845/1133, batch loss:0.27196890115737915, Training time:24485.066185235977
batch reward last col mean 0.08654796332120895 first col mean 0.10440385341644287 all mean 0.09768801182508469
0.2675887644290924 0.2675887644290924
rl training, epoch7, iter0, batch846/1133, batch loss:0.2675887644290924, Training time:24486.561810016632
batch reward last col mean 0.0933798998594284 first col mean 0.10634803771972656 all mean 0.09552647918462753
0.29273635149002075 0.29273635149002075
rl training, epoch7, iter0, batch847/1133, batch loss:0.29273635149002075, Training time:24488.98091506958
batch reward last col mean 0.08567077666521072 first col mean 0.09964299947023392 all mean 0.09028652310371399
0.2620090842247009 0.2620090842247009
rl training, epoch7, iter0, batch848/1133, batch loss:0.2620090842247009, Training time:24490.865956783295
batch reward last col mean 0.11591872572898865 first col mean 0.10013599693775177 all mean 0.11252902448177338
0.3021939694881439 0.3021939694881439
rl training, epoch7, iter0, batch849/1133, batch loss:0.3021939694881439, Training time:24492.596581459045
batch reward last col mean 0.10953414440155029 first col mean 0.0930362120270729 all mean 0.10540148615837097
0.2740964889526367 0.2740964889526367
rl training, epoch7, iter0, batch850/1133, batch loss:0.2740964889526367, Training time:24494.310085058212
batch reward last col mean 0.12682870030403137 first col mean 0.08664603531360626 all mean 0.1208205446600914
0.31122657656669617 0.31122657656669617
rl training, epoch7, iter0, batch851/1133, batch loss:0.31122657656669617, Training time:24496.116913080215
batch reward last col mean 0.09688401222229004 first col mean 0.09747358411550522 all mean 0.09749449044466019
0.2612772583961487 0.2612772583961487
rl training, epoch7, iter0, batch852/1133, batch loss:0.2612772583961487, Training time:24497.926444530487
batch reward last col mean 0.10665997862815857 first col mean 0.10542286932468414 all mean 0.1097463071346283
0.2936130166053772 0.2936130166053772
rl training, epoch7, iter0, batch853/1133, batch loss:0.2936130166053772, Training time:24499.59930253029
batch reward last col mean 0.09997435659170151 first col mean 0.0945570319890976 all mean 0.10518387705087662
0.2758623957633972 0.2758623957633972
rl training, epoch7, iter0, batch854/1133, batch loss:0.2758623957633972, Training time:24501.462701559067
batch reward last col mean 0.10285043716430664 first col mean 0.09815622866153717 all mean 0.10334435850381851
0.2744978070259094 0.2744978070259094
rl training, epoch7, iter0, batch855/1133, batch loss:0.2744978070259094, Training time:24503.32293653488
batch reward last col mean 0.07447352260351181 first col mean 0.11455574631690979 all mean 0.0866457149386406
0.26999637484550476 0.26999637484550476
rl training, epoch7, iter0, batch856/1133, batch loss:0.26999637484550476, Training time:24505.08176636696
batch reward last col mean 0.1088876947760582 first col mean 0.10429666191339493 all mean 0.09962507337331772
0.2384762465953827 0.2384762465953827
rl training, epoch7, iter0, batch857/1133, batch loss:0.2384762465953827, Training time:24506.776688337326
batch reward last col mean 0.11290912330150604 first col mean 0.1282622516155243 all mean 0.1128380224108696
0.29707518219947815 0.29707518219947815
rl training, epoch7, iter0, batch858/1133, batch loss:0.29707518219947815, Training time:24508.796726465225
batch reward last col mean 0.11096049100160599 first col mean 0.11120665073394775 all mean 0.11203426867723465
0.28557339310646057 0.28557339310646057
rl training, epoch7, iter0, batch859/1133, batch loss:0.28557339310646057, Training time:24510.769021987915
batch reward last col mean 0.10739914327859879 first col mean 0.11626371741294861 all mean 0.10628915578126907
0.2899971604347229 0.2899971902370453
rl training, epoch7, iter0, batch860/1133, batch loss:0.2899971902370453, Training time:24512.574257850647
batch reward last col mean 0.10415217280387878 first col mean 0.09976095706224442 all mean 0.09799321740865707
0.2470390498638153 0.2470390349626541
rl training, epoch7, iter0, batch861/1133, batch loss:0.2470390349626541, Training time:24514.90421104431
batch reward last col mean 0.09594301879405975 first col mean 0.10279322415590286 all mean 0.10103783756494522
0.26227930188179016 0.26227930188179016
rl training, epoch7, iter0, batch862/1133, batch loss:0.26227930188179016, Training time:24516.98368024826
batch reward last col mean 0.09017089009284973 first col mean 0.11229413747787476 all mean 0.09406634420156479
0.2644820213317871 0.2644820213317871
rl training, epoch7, iter0, batch863/1133, batch loss:0.2644820213317871, Training time:24519.663801670074
batch reward last col mean 0.10767058283090591 first col mean 0.09630311280488968 all mean 0.11225248128175735
0.29644012451171875 0.29644012451171875
rl training, epoch7, iter0, batch864/1133, batch loss:0.29644012451171875, Training time:24521.543551445007
batch reward last col mean 0.07107968628406525 first col mean 0.10249733924865723 all mean 0.07644867151975632
0.22169575095176697 0.22169575095176697
rl training, epoch7, iter0, batch865/1133, batch loss:0.22169575095176697, Training time:24523.451725244522
batch reward last col mean 0.10268531739711761 first col mean 0.09538359940052032 all mean 0.10150200128555298
0.2669580280780792 0.2669580280780792
rl training, epoch7, iter0, batch866/1133, batch loss:0.2669580280780792, Training time:24525.887585163116
batch reward last col mean 0.1205257922410965 first col mean 0.10069144517183304 all mean 0.11272666603326797
0.24028651416301727 0.24028651416301727
rl training, epoch7, iter0, batch867/1133, batch loss:0.24028651416301727, Training time:24527.897216796875
batch reward last col mean 0.09494262933731079 first col mean 0.09627604484558105 all mean 0.09636344760656357
0.24348653852939606 0.24348653852939606
rl training, epoch7, iter0, batch868/1133, batch loss:0.24348653852939606, Training time:24530.371069431305
batch reward last col mean 0.09861589968204498 first col mean 0.10560745745897293 all mean 0.0961858257651329
0.2641613185405731 0.2641613185405731
rl training, epoch7, iter0, batch869/1133, batch loss:0.2641613185405731, Training time:24532.06854224205
batch reward last col mean 0.08714901655912399 first col mean 0.09778838604688644 all mean 0.09135597944259644
0.24579651653766632 0.24579651653766632
rl training, epoch7, iter0, batch870/1133, batch loss:0.24579651653766632, Training time:24534.210144996643
batch reward last col mean 0.10675234347581863 first col mean 0.09104651212692261 all mean 0.1021176278591156
0.28660812973976135 0.28660812973976135
rl training, epoch7, iter0, batch871/1133, batch loss:0.28660812973976135, Training time:24536.128807783127
batch reward last col mean 0.10638945549726486 first col mean 0.10118849575519562 all mean 0.1066160649061203
0.3050028681755066 0.3050028681755066
rl training, epoch7, iter0, batch872/1133, batch loss:0.3050028681755066, Training time:24538.883491516113
batch reward last col mean 0.11983522772789001 first col mean 0.103426992893219 all mean 0.11224780231714249
0.27719321846961975 0.27719321846961975
rl training, epoch7, iter0, batch873/1133, batch loss:0.27719321846961975, Training time:24540.483962535858
batch reward last col mean 0.10893059521913528 first col mean 0.11242099106311798 all mean 0.11108320206403732
0.317385196685791 0.317385196685791
rl training, epoch7, iter0, batch874/1133, batch loss:0.317385196685791, Training time:24541.88753414154
batch reward last col mean 0.14366662502288818 first col mean 0.11861377954483032 all mean 0.12108628451824188
0.26432108879089355 0.26432108879089355
rl training, epoch7, iter0, batch875/1133, batch loss:0.26432108879089355, Training time:24543.47162771225
batch reward last col mean 0.08587265014648438 first col mean 0.09170626103878021 all mean 0.09668595343828201
0.3003069758415222 0.3003069758415222
rl training, epoch7, iter0, batch876/1133, batch loss:0.3003069758415222, Training time:24545.193684101105
batch reward last col mean 0.08429701626300812 first col mean 0.08264917880296707 all mean 0.08660095185041428
0.23250339925289154 0.23250339925289154
rl training, epoch7, iter0, batch877/1133, batch loss:0.23250339925289154, Training time:24546.710594654083
batch reward last col mean 0.08347052335739136 first col mean 0.1007891446352005 all mean 0.08647999167442322
0.21802791953086853 0.21802791953086853
rl training, epoch7, iter0, batch878/1133, batch loss:0.21802791953086853, Training time:24548.45375418663
batch reward last col mean 0.12889160215854645 first col mean 0.11257989704608917 all mean 0.12414101511240005
0.32371440529823303 0.32371440529823303
rl training, epoch7, iter0, batch879/1133, batch loss:0.32371440529823303, Training time:24550.592778921127
batch reward last col mean 0.11231787502765656 first col mean 0.10196960717439651 all mean 0.10827374458312988
0.2819753587245941 0.2819753587245941
rl training, epoch7, iter0, batch880/1133, batch loss:0.2819753587245941, Training time:24552.637919425964
batch reward last col mean 0.10213357210159302 first col mean 0.1102709248661995 all mean 0.10480493307113647
0.2502579987049103 0.2502579987049103
rl training, epoch7, iter0, batch881/1133, batch loss:0.2502579987049103, Training time:24554.475850105286
batch reward last col mean 0.08393093943595886 first col mean 0.10402320325374603 all mean 0.08863664418458939
0.25709372758865356 0.25709372758865356
rl training, epoch7, iter0, batch882/1133, batch loss:0.25709372758865356, Training time:24556.367872714996
batch reward last col mean 0.08613288402557373 first col mean 0.09629736095666885 all mean 0.09168486297130585
0.2690022885799408 0.2690022885799408
rl training, epoch7, iter0, batch883/1133, batch loss:0.2690022885799408, Training time:24558.514009475708
batch reward last col mean 0.08418510854244232 first col mean 0.09870727360248566 all mean 0.08992891013622284
0.26095739006996155 0.26095739006996155
rl training, epoch7, iter0, batch884/1133, batch loss:0.26095739006996155, Training time:24560.397129774094
batch reward last col mean 0.07179562002420425 first col mean 0.10869868099689484 all mean 0.07940927147865295
0.2614348828792572 0.2614348828792572
rl training, epoch7, iter0, batch885/1133, batch loss:0.2614348828792572, Training time:24562.153603076935
batch reward last col mean 0.07987947762012482 first col mean 0.09382928162813187 all mean 0.08439717441797256
0.26937928795814514 0.26937928795814514
rl training, epoch7, iter0, batch886/1133, batch loss:0.26937928795814514, Training time:24564.266367912292
batch reward last col mean 0.09760741889476776 first col mean 0.11430709809064865 all mean 0.10024052858352661
0.29003021121025085 0.29003021121025085
rl training, epoch7, iter0, batch887/1133, batch loss:0.29003021121025085, Training time:24565.842876195908
batch reward last col mean 0.11508695781230927 first col mean 0.09479838609695435 all mean 0.10836759954690933
0.2958570718765259 0.2958570718765259
rl training, epoch7, iter0, batch888/1133, batch loss:0.2958570718765259, Training time:24567.583812475204
batch reward last col mean 0.11028110980987549 first col mean 0.09318315237760544 all mean 0.11666732281446457
0.28884178400039673 0.28884178400039673
rl training, epoch7, iter0, batch889/1133, batch loss:0.28884178400039673, Training time:24569.415722370148
batch reward last col mean 0.12313450872898102 first col mean 0.09892243891954422 all mean 0.11598677933216095
0.2738077640533447 0.2738077640533447
rl training, epoch7, iter0, batch890/1133, batch loss:0.2738077640533447, Training time:24571.40562438965
batch reward last col mean 0.11070667952299118 first col mean 0.09903905540704727 all mean 0.10523024201393127
0.30235883593559265 0.30235883593559265
rl training, epoch7, iter0, batch891/1133, batch loss:0.30235883593559265, Training time:24573.061419963837
batch reward last col mean 0.14332249760627747 first col mean 0.11833444982767105 all mean 0.1338266283273697
0.3116803765296936 0.3116803765296936
rl training, epoch7, iter0, batch892/1133, batch loss:0.3116803765296936, Training time:24576.089188575745
batch reward last col mean 0.08976112306118011 first col mean 0.11725859344005585 all mean 0.0931861624121666
0.25364646315574646 0.25364646315574646
rl training, epoch7, iter0, batch893/1133, batch loss:0.25364646315574646, Training time:24578.204023361206
batch reward last col mean 0.0963546633720398 first col mean 0.10645978897809982 all mean 0.10013426095247269
0.2821083664894104 0.2821083664894104
rl training, epoch7, iter0, batch894/1133, batch loss:0.2821083664894104, Training time:24580.016879558563
batch reward last col mean 0.08209270238876343 first col mean 0.11268831789493561 all mean 0.08818930387496948
0.2720670700073242 0.2720670700073242
rl training, epoch7, iter0, batch895/1133, batch loss:0.2720670700073242, Training time:24582.93867111206
batch reward last col mean 0.10215109586715698 first col mean 0.11698895692825317 all mean 0.10174340009689331
0.2578674554824829 0.2578674554824829
rl training, epoch7, iter0, batch896/1133, batch loss:0.2578674554824829, Training time:24584.854794979095
batch reward last col mean 0.10860247910022736 first col mean 0.09722378849983215 all mean 0.10656926035881042
0.2634926736354828 0.2634926736354828
rl training, epoch7, iter0, batch897/1133, batch loss:0.2634926736354828, Training time:24586.867958307266
batch reward last col mean 0.1218070387840271 first col mean 0.10521724075078964 all mean 0.12147869169712067
0.30108433961868286 0.30108433961868286
rl training, epoch7, iter0, batch898/1133, batch loss:0.30108433961868286, Training time:24588.678046941757
batch reward last col mean 0.0693746954202652 first col mean 0.09738573431968689 all mean 0.08170773833990097
0.2527172267436981 0.2527172267436981
rl training, epoch7, iter0, batch899/1133, batch loss:0.2527172267436981, Training time:24590.34959244728
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.47434434665585656 Time: 95.54678702354431 s
loss of true 0.20587434128439752 loss of gen 0.1755082179304781 loss of other 0.09296178689681894 first score 0.0910693034529686
batch reward last col mean 0.08176969736814499 first col mean 0.1002519428730011 all mean 0.0942283496260643
0.28476932644844055 0.28476932644844055
rl training, epoch7, iter0, batch900/1133, batch loss:0.28476932644844055, Training time:24687.629330158234
batch reward last col mean 0.10000201314687729 first col mean 0.10351283103227615 all mean 0.1011248379945755
0.25900501012802124 0.25900501012802124
rl training, epoch7, iter0, batch901/1133, batch loss:0.25900501012802124, Training time:24689.189386606216
batch reward last col mean 0.11938727647066116 first col mean 0.10018990188837051 all mean 0.10523661226034164
0.29382362961769104 0.29382362961769104
rl training, epoch7, iter0, batch902/1133, batch loss:0.29382362961769104, Training time:24691.61176085472
batch reward last col mean 0.12377375364303589 first col mean 0.12179414927959442 all mean 0.11626981198787689
0.31041833758354187 0.31041833758354187
rl training, epoch7, iter0, batch903/1133, batch loss:0.31041833758354187, Training time:24693.830730199814
batch reward last col mean 0.08910225331783295 first col mean 0.10846360772848129 all mean 0.09755098074674606
0.2906040549278259 0.2906040549278259
rl training, epoch7, iter0, batch904/1133, batch loss:0.2906040549278259, Training time:24695.689155340195
batch reward last col mean 0.08561283349990845 first col mean 0.12088683992624283 all mean 0.08888085931539536
0.2778110206127167 0.2778110206127167
rl training, epoch7, iter0, batch905/1133, batch loss:0.2778110206127167, Training time:24697.702502012253
batch reward last col mean 0.11982976645231247 first col mean 0.11831200867891312 all mean 0.11561455577611923
0.26621875166893005 0.26621872186660767
rl training, epoch7, iter0, batch906/1133, batch loss:0.26621872186660767, Training time:24699.794693231583
batch reward last col mean 0.08056458830833435 first col mean 0.10192563384771347 all mean 0.09020534157752991
0.26990649104118347 0.26990649104118347
rl training, epoch7, iter0, batch907/1133, batch loss:0.26990649104118347, Training time:24701.619582414627
batch reward last col mean 0.09661597013473511 first col mean 0.10324639081954956 all mean 0.09638376533985138
0.20957624912261963 0.20957624912261963
rl training, epoch7, iter0, batch908/1133, batch loss:0.20957624912261963, Training time:24703.575603723526
batch reward last col mean 0.07586784660816193 first col mean 0.11830271780490875 all mean 0.08911160379648209
0.28392741084098816 0.28392741084098816
rl training, epoch7, iter0, batch909/1133, batch loss:0.28392741084098816, Training time:24705.416041851044
batch reward last col mean 0.1091422513127327 first col mean 0.11055150628089905 all mean 0.11369223147630692
0.28918033838272095 0.28918033838272095
rl training, epoch7, iter0, batch910/1133, batch loss:0.28918033838272095, Training time:24707.11958360672
batch reward last col mean 0.08456175029277802 first col mean 0.11798267066478729 all mean 0.0910055935382843
0.2536569833755493 0.2536570131778717
rl training, epoch7, iter0, batch911/1133, batch loss:0.2536570131778717, Training time:24709.360713005066
batch reward last col mean 0.09127234667539597 first col mean 0.1253850907087326 all mean 0.10442205518484116
0.2598894238471985 0.2598894238471985
rl training, epoch7, iter0, batch912/1133, batch loss:0.2598894238471985, Training time:24711.181061029434
batch reward last col mean 0.08808775246143341 first col mean 0.12664981186389923 all mean 0.09707929939031601
0.30715206265449524 0.30715206265449524
rl training, epoch7, iter0, batch913/1133, batch loss:0.30715206265449524, Training time:24713.38965177536
batch reward last col mean 0.06108306348323822 first col mean 0.10431738197803497 all mean 0.07360503077507019
0.26433899998664856 0.26433899998664856
rl training, epoch7, iter0, batch914/1133, batch loss:0.26433899998664856, Training time:24715.313881397247
batch reward last col mean 0.15553070604801178 first col mean 0.12200120091438293 all mean 0.14430783689022064
0.30252915620803833 0.30252915620803833
rl training, epoch7, iter0, batch915/1133, batch loss:0.30252915620803833, Training time:24717.41606593132
batch reward last col mean 0.14142665266990662 first col mean 0.100883848965168 all mean 0.12650573253631592
0.34007781744003296 0.34007778763771057
rl training, epoch7, iter0, batch916/1133, batch loss:0.34007778763771057, Training time:24719.24795818329
batch reward last col mean 0.08279088884592056 first col mean 0.10940525680780411 all mean 0.09194532036781311
0.2563539743423462 0.2563539743423462
rl training, epoch7, iter0, batch917/1133, batch loss:0.2563539743423462, Training time:24721.028563022614
batch reward last col mean 0.08348915725946426 first col mean 0.11070528626441956 all mean 0.0850444808602333
0.2589186131954193 0.2589186131954193
rl training, epoch7, iter0, batch918/1133, batch loss:0.2589186131954193, Training time:24723.025028944016
batch reward last col mean 0.10701044648885727 first col mean 0.1038728654384613 all mean 0.10408647358417511
0.26806551218032837 0.26806551218032837
rl training, epoch7, iter0, batch919/1133, batch loss:0.26806551218032837, Training time:24726.02623939514
batch reward last col mean 0.1005723625421524 first col mean 0.10209804773330688 all mean 0.10237934440374374
0.2556702792644501 0.2556702792644501
rl training, epoch7, iter0, batch920/1133, batch loss:0.2556702792644501, Training time:24728.099682569504
batch reward last col mean 0.09765991568565369 first col mean 0.12535429000854492 all mean 0.1013995110988617
0.27955320477485657 0.27955320477485657
rl training, epoch7, iter0, batch921/1133, batch loss:0.27955320477485657, Training time:24730.74560046196
batch reward last col mean 0.09548141062259674 first col mean 0.11808709055185318 all mean 0.09555923193693161
0.2874487340450287 0.2874487340450287
rl training, epoch7, iter0, batch922/1133, batch loss:0.2874487340450287, Training time:24732.607869148254
batch reward last col mean 0.0973193570971489 first col mean 0.09763394296169281 all mean 0.10333698242902756
0.28696948289871216 0.28696948289871216
rl training, epoch7, iter0, batch923/1133, batch loss:0.28696948289871216, Training time:24734.559765338898
batch reward last col mean 0.09969040006399155 first col mean 0.1209665834903717 all mean 0.10846644639968872
0.2985522747039795 0.2985522747039795
rl training, epoch7, iter0, batch924/1133, batch loss:0.2985522747039795, Training time:24736.450514793396
batch reward last col mean 0.11312529444694519 first col mean 0.11521026492118835 all mean 0.10993196070194244
0.2744269073009491 0.2744269073009491
rl training, epoch7, iter0, batch925/1133, batch loss:0.2744269073009491, Training time:24738.549373149872
batch reward last col mean 0.08222198486328125 first col mean 0.10335943102836609 all mean 0.09498404711484909
0.27512335777282715 0.27512335777282715
rl training, epoch7, iter0, batch926/1133, batch loss:0.27512335777282715, Training time:24740.392163276672
batch reward last col mean 0.15510718524456024 first col mean 0.12159854173660278 all mean 0.13577499985694885
0.2979621887207031 0.2979621887207031
rl training, epoch7, iter0, batch927/1133, batch loss:0.2979621887207031, Training time:24742.103842020035
batch reward last col mean 0.1167898178100586 first col mean 0.09630091488361359 all mean 0.11784796416759491
0.2814154326915741 0.2814154028892517
rl training, epoch7, iter0, batch928/1133, batch loss:0.2814154028892517, Training time:24745.595943689346
batch reward last col mean 0.11187239736318588 first col mean 0.10859563946723938 all mean 0.11356865614652634
0.26892656087875366 0.2689265310764313
rl training, epoch7, iter0, batch929/1133, batch loss:0.2689265310764313, Training time:24747.66809463501
batch reward last col mean 0.11907441914081573 first col mean 0.11736050993204117 all mean 0.11509808152914047
0.25139811635017395 0.25139811635017395
rl training, epoch7, iter0, batch930/1133, batch loss:0.25139811635017395, Training time:24750.432512760162
batch reward last col mean 0.07110767066478729 first col mean 0.11659322679042816 all mean 0.08318223804235458
0.2821589410305023 0.2821589410305023
rl training, epoch7, iter0, batch931/1133, batch loss:0.2821589410305023, Training time:24752.701726913452
batch reward last col mean 0.11399182677268982 first col mean 0.10715650767087936 all mean 0.11288590729236603
0.28728950023651123 0.2872895300388336
rl training, epoch7, iter0, batch932/1133, batch loss:0.2872895300388336, Training time:24754.946070194244
batch reward last col mean 0.061177413910627365 first col mean 0.0897398516535759 all mean 0.08101207762956619
0.2810822129249573 0.2810822129249573
rl training, epoch7, iter0, batch933/1133, batch loss:0.2810822129249573, Training time:24756.92067217827
batch reward last col mean 0.12631332874298096 first col mean 0.1110297292470932 all mean 0.12242968380451202
0.30171871185302734 0.30171871185302734
rl training, epoch7, iter0, batch934/1133, batch loss:0.30171871185302734, Training time:24759.785772562027
batch reward last col mean 0.09676719456911087 first col mean 0.10091995447874069 all mean 0.09505121409893036
0.29194676876068115 0.29194676876068115
rl training, epoch7, iter0, batch935/1133, batch loss:0.29194676876068115, Training time:24762.13625574112
batch reward last col mean 0.10791197419166565 first col mean 0.10949130356311798 all mean 0.11205897480249405
0.31124383211135864 0.31124383211135864
rl training, epoch7, iter0, batch936/1133, batch loss:0.31124383211135864, Training time:24765.048352003098
batch reward last col mean 0.10906235128641129 first col mean 0.0999065712094307 all mean 0.10883094370365143
0.3084836006164551 0.3084836006164551
rl training, epoch7, iter0, batch937/1133, batch loss:0.3084836006164551, Training time:24767.6381483078
batch reward last col mean 0.06539035588502884 first col mean 0.11666612327098846 all mean 0.07478146255016327
0.24570171535015106 0.24570171535015106
rl training, epoch7, iter0, batch938/1133, batch loss:0.24570171535015106, Training time:24769.781720399857
batch reward last col mean 0.11480889469385147 first col mean 0.08997255563735962 all mean 0.11632997542619705
0.34584373235702515 0.34584373235702515
rl training, epoch7, iter0, batch939/1133, batch loss:0.34584373235702515, Training time:24772.019589662552
batch reward last col mean 0.09611708670854568 first col mean 0.10368458926677704 all mean 0.09576468169689178
0.2577305734157562 0.2577305734157562
rl training, epoch7, iter0, batch940/1133, batch loss:0.2577305734157562, Training time:24774.247735738754
batch reward last col mean 0.08418252319097519 first col mean 0.09489352256059647 all mean 0.09595897048711777
0.2847254276275635 0.2847254276275635
rl training, epoch7, iter0, batch941/1133, batch loss:0.2847254276275635, Training time:24776.329931259155
batch reward last col mean 0.11824571341276169 first col mean 0.12374672293663025 all mean 0.11597136408090591
0.30200091004371643 0.30200091004371643
rl training, epoch7, iter0, batch942/1133, batch loss:0.30200091004371643, Training time:24778.551901578903
batch reward last col mean 0.08169541507959366 first col mean 0.109818235039711 all mean 0.0931723341345787
0.29144078493118286 0.29144078493118286
rl training, epoch7, iter0, batch943/1133, batch loss:0.29144078493118286, Training time:24780.577193260193
batch reward last col mean 0.09396132826805115 first col mean 0.09838736057281494 all mean 0.09892576187849045
0.267320454120636 0.267320454120636
rl training, epoch7, iter0, batch944/1133, batch loss:0.267320454120636, Training time:24783.063344955444
batch reward last col mean 0.11151275038719177 first col mean 0.1161261722445488 all mean 0.11087553948163986
0.28171518445014954 0.28171518445014954
rl training, epoch7, iter0, batch945/1133, batch loss:0.28171518445014954, Training time:24785.268635988235
batch reward last col mean 0.1546984612941742 first col mean 0.10580853372812271 all mean 0.1468050181865692
0.33676812052726746 0.33676809072494507
rl training, epoch7, iter0, batch946/1133, batch loss:0.33676809072494507, Training time:24787.762424707413
batch reward last col mean 0.10237400233745575 first col mean 0.11258722841739655 all mean 0.0981118306517601
0.2582893669605255 0.2582893669605255
rl training, epoch7, iter0, batch947/1133, batch loss:0.2582893669605255, Training time:24790.143955230713
batch reward last col mean 0.10676778852939606 first col mean 0.12474723160266876 all mean 0.10679786652326584
0.285843163728714 0.285843163728714
rl training, epoch7, iter0, batch948/1133, batch loss:0.285843163728714, Training time:24792.06285047531
batch reward last col mean 0.10031352192163467 first col mean 0.10781823843717575 all mean 0.10208966583013535
0.22818753123283386 0.22818754613399506
rl training, epoch7, iter0, batch949/1133, batch loss:0.22818754613399506, Training time:24794.832289218903
batch reward last col mean 0.09592072665691376 first col mean 0.11612498760223389 all mean 0.09567313641309738
0.2763684093952179 0.2763684093952179
rl training, epoch7, iter0, batch950/1133, batch loss:0.2763684093952179, Training time:24796.722932577133
batch reward last col mean 0.06686997413635254 first col mean 0.09389781206846237 all mean 0.07569269835948944
0.2299506664276123 0.2299506664276123
rl training, epoch7, iter0, batch951/1133, batch loss:0.2299506664276123, Training time:24798.88639640808
batch reward last col mean 0.09353720396757126 first col mean 0.10101091861724854 all mean 0.09375547617673874
0.24811388552188873 0.24811387062072754
rl training, epoch7, iter0, batch952/1133, batch loss:0.24811387062072754, Training time:24800.84970808029
batch reward last col mean 0.0879896804690361 first col mean 0.11317439377307892 all mean 0.09045980870723724
0.2575185000896454 0.2575185000896454
rl training, epoch7, iter0, batch953/1133, batch loss:0.2575185000896454, Training time:24803.15950345993
batch reward last col mean 0.1243698000907898 first col mean 0.11573606729507446 all mean 0.12175586074590683
0.31469079852104187 0.31469079852104187
rl training, epoch7, iter0, batch954/1133, batch loss:0.31469079852104187, Training time:24805.199800491333
batch reward last col mean 0.12776583433151245 first col mean 0.1115913838148117 all mean 0.12480354309082031
0.3073665499687195 0.3073665499687195
rl training, epoch7, iter0, batch955/1133, batch loss:0.3073665499687195, Training time:24807.46466398239
batch reward last col mean 0.0815812200307846 first col mean 0.11076554656028748 all mean 0.0914110392332077
0.29914358258247375 0.29914358258247375
rl training, epoch7, iter0, batch956/1133, batch loss:0.29914358258247375, Training time:24809.69159770012
batch reward last col mean 0.09123294055461884 first col mean 0.12028840184211731 all mean 0.09724488109350204
0.274776428937912 0.274776428937912
rl training, epoch7, iter0, batch957/1133, batch loss:0.274776428937912, Training time:24812.77596449852
batch reward last col mean 0.1650533825159073 first col mean 0.0986783429980278 all mean 0.14528727531433105
0.32425233721733093 0.32425233721733093
rl training, epoch7, iter0, batch958/1133, batch loss:0.32425233721733093, Training time:24814.610837459564
batch reward last col mean 0.08632002025842667 first col mean 0.09650976210832596 all mean 0.09548820555210114
0.2627955675125122 0.2627955675125122
rl training, epoch7, iter0, batch959/1133, batch loss:0.2627955675125122, Training time:24816.61901450157
batch reward last col mean 0.10280048102140427 first col mean 0.10730426013469696 all mean 0.1044301763176918
0.2815544009208679 0.2815544009208679
rl training, epoch7, iter0, batch960/1133, batch loss:0.2815544009208679, Training time:24818.45955514908
batch reward last col mean 0.09490647912025452 first col mean 0.10266896337270737 all mean 0.09937567263841629
0.29696863889694214 0.29696863889694214
rl training, epoch7, iter0, batch961/1133, batch loss:0.29696863889694214, Training time:24820.7241897583
batch reward last col mean 0.11493238806724548 first col mean 0.10940192639827728 all mean 0.11008492112159729
0.31514012813568115 0.31514012813568115
rl training, epoch7, iter0, batch962/1133, batch loss:0.31514012813568115, Training time:24822.84205555916
batch reward last col mean 0.10397877544164658 first col mean 0.10298829525709152 all mean 0.1050422415137291
0.26645979285240173 0.2664598226547241
rl training, epoch7, iter0, batch963/1133, batch loss:0.2664598226547241, Training time:24825.20397424698
batch reward last col mean 0.08127336204051971 first col mean 0.12847842276096344 all mean 0.09172333776950836
0.2719939351081848 0.2719939351081848
rl training, epoch7, iter0, batch964/1133, batch loss:0.2719939351081848, Training time:24827.239669799805
batch reward last col mean 0.1051030158996582 first col mean 0.12410226464271545 all mean 0.11339453607797623
0.32392239570617676 0.32392239570617676
rl training, epoch7, iter0, batch965/1133, batch loss:0.32392239570617676, Training time:24829.676321983337
batch reward last col mean 0.10805727541446686 first col mean 0.11097712814807892 all mean 0.10608850419521332
0.3188128173351288 0.3188128173351288
rl training, epoch7, iter0, batch966/1133, batch loss:0.3188128173351288, Training time:24831.72001838684
batch reward last col mean 0.12980963289737701 first col mean 0.12706072628498077 all mean 0.11944685876369476
0.29552292823791504 0.29552292823791504
rl training, epoch7, iter0, batch967/1133, batch loss:0.29552292823791504, Training time:24833.73608827591
batch reward last col mean 0.09111683815717697 first col mean 0.10122016072273254 all mean 0.09257328510284424
0.23334456980228424 0.23334456980228424
rl training, epoch7, iter0, batch968/1133, batch loss:0.23334456980228424, Training time:24836.38764834404
batch reward last col mean 0.13596543669700623 first col mean 0.10999433696269989 all mean 0.1294580101966858
0.322935551404953 0.322935551404953
rl training, epoch7, iter0, batch969/1133, batch loss:0.322935551404953, Training time:24839.676236867905
batch reward last col mean 0.09606638550758362 first col mean 0.12713322043418884 all mean 0.09661364555358887
0.2634276747703552 0.2634276747703552
rl training, epoch7, iter0, batch970/1133, batch loss:0.2634276747703552, Training time:24841.717707633972
batch reward last col mean 0.10721448063850403 first col mean 0.10618826001882553 all mean 0.10374711453914642
0.3060462474822998 0.3060462176799774
rl training, epoch7, iter0, batch971/1133, batch loss:0.3060462176799774, Training time:24844.302351236343
batch reward last col mean 0.1152152344584465 first col mean 0.11635912954807281 all mean 0.1154095008969307
0.29404598474502563 0.29404598474502563
rl training, epoch7, iter0, batch972/1133, batch loss:0.29404598474502563, Training time:24846.36489057541
batch reward last col mean 0.07250747829675674 first col mean 0.1129462867975235 all mean 0.08464895933866501
0.24124421179294586 0.24124421179294586
rl training, epoch7, iter0, batch973/1133, batch loss:0.24124421179294586, Training time:24848.53869175911
batch reward last col mean 0.08496133983135223 first col mean 0.10230010002851486 all mean 0.092552550137043
0.2816736400127411 0.2816736400127411
rl training, epoch7, iter0, batch974/1133, batch loss:0.2816736400127411, Training time:24850.371420621872
batch reward last col mean 0.10709530860185623 first col mean 0.10578171908855438 all mean 0.11219470947980881
0.26860302686691284 0.26860302686691284
rl training, epoch7, iter0, batch975/1133, batch loss:0.26860302686691284, Training time:24852.46140575409
batch reward last col mean 0.08528062701225281 first col mean 0.10653857886791229 all mean 0.08916309475898743
0.24889904260635376 0.24889904260635376
rl training, epoch7, iter0, batch976/1133, batch loss:0.24889904260635376, Training time:24854.43868613243
batch reward last col mean 0.08896992355585098 first col mean 0.1080310195684433 all mean 0.09594335407018661
0.25079819560050964 0.25079819560050964
rl training, epoch7, iter0, batch977/1133, batch loss:0.25079819560050964, Training time:24856.619720697403
batch reward last col mean 0.11045971512794495 first col mean 0.12129831314086914 all mean 0.11110109835863113
0.29385560750961304 0.29385560750961304
rl training, epoch7, iter0, batch978/1133, batch loss:0.29385560750961304, Training time:24858.23462843895
batch reward last col mean 0.09700944274663925 first col mean 0.09582114219665527 all mean 0.09973365813493729
0.27346721291542053 0.27346721291542053
rl training, epoch7, iter0, batch979/1133, batch loss:0.27346721291542053, Training time:24860.415142774582
batch reward last col mean 0.09392227232456207 first col mean 0.12720158696174622 all mean 0.09594869613647461
0.2631341814994812 0.2631341814994812
rl training, epoch7, iter0, batch980/1133, batch loss:0.2631341814994812, Training time:24862.456080675125
batch reward last col mean 0.08833352476358414 first col mean 0.11135688424110413 all mean 0.09165965765714645
0.2711135745048523 0.2711135745048523
rl training, epoch7, iter0, batch981/1133, batch loss:0.2711135745048523, Training time:24864.504214286804
batch reward last col mean 0.0996289923787117 first col mean 0.113313227891922 all mean 0.09649775177240372
0.24836385250091553 0.24836385250091553
rl training, epoch7, iter0, batch982/1133, batch loss:0.24836385250091553, Training time:24866.373800754547
batch reward last col mean 0.10151462256908417 first col mean 0.12387942522764206 all mean 0.10354923456907272
0.27629566192626953 0.27629566192626953
rl training, epoch7, iter0, batch983/1133, batch loss:0.27629566192626953, Training time:24868.57173705101
batch reward last col mean 0.0962698832154274 first col mean 0.12226393073797226 all mean 0.10560190677642822
0.3145039677619934 0.3145039677619934
rl training, epoch7, iter0, batch984/1133, batch loss:0.3145039677619934, Training time:24870.624750614166
batch reward last col mean 0.0801413431763649 first col mean 0.12696295976638794 all mean 0.09052605926990509
0.306755006313324 0.306755006313324
rl training, epoch7, iter0, batch985/1133, batch loss:0.306755006313324, Training time:24872.39118695259
batch reward last col mean 0.1051645576953888 first col mean 0.13027524948120117 all mean 0.11470168828964233
0.30531007051467896 0.30531007051467896
rl training, epoch7, iter0, batch986/1133, batch loss:0.30531007051467896, Training time:24874.164323568344
batch reward last col mean 0.09650195389986038 first col mean 0.10433317720890045 all mean 0.1018625944852829
0.27916744351387024 0.27916744351387024
rl training, epoch7, iter0, batch987/1133, batch loss:0.27916744351387024, Training time:24876.40431857109
batch reward last col mean 0.08667208254337311 first col mean 0.1254005879163742 all mean 0.09254877269268036
0.27602431178092957 0.27602431178092957
rl training, epoch7, iter0, batch988/1133, batch loss:0.27602431178092957, Training time:24879.019494771957
batch reward last col mean 0.11897805333137512 first col mean 0.11288344860076904 all mean 0.11537227034568787
0.293678343296051 0.293678343296051
rl training, epoch7, iter0, batch989/1133, batch loss:0.293678343296051, Training time:24881.129787683487
batch reward last col mean 0.13787733018398285 first col mean 0.10354862362146378 all mean 0.13124680519104004
0.3387570381164551 0.3387570083141327
rl training, epoch7, iter0, batch990/1133, batch loss:0.3387570083141327, Training time:24882.933539152145
batch reward last col mean 0.1427360326051712 first col mean 0.09757201373577118 all mean 0.13429422676563263
0.2902463376522064 0.2902463674545288
rl training, epoch7, iter0, batch991/1133, batch loss:0.2902463674545288, Training time:24884.80516219139
batch reward last col mean 0.12787102162837982 first col mean 0.11279696226119995 all mean 0.1113840714097023
0.25396108627319336 0.25396108627319336
rl training, epoch7, iter0, batch992/1133, batch loss:0.25396108627319336, Training time:24886.468142271042
batch reward last col mean 0.08964066952466965 first col mean 0.10729151219129562 all mean 0.09129616618156433
0.3010360598564148 0.30103600025177
rl training, epoch7, iter0, batch993/1133, batch loss:0.30103600025177, Training time:24888.382170677185
batch reward last col mean 0.11042533069849014 first col mean 0.09159485995769501 all mean 0.11397276073694229
0.3186385929584503 0.3186385929584503
rl training, epoch7, iter0, batch994/1133, batch loss:0.3186385929584503, Training time:24891.069073200226
batch reward last col mean 0.11659989506006241 first col mean 0.11916553974151611 all mean 0.11518075317144394
0.28527510166168213 0.28527510166168213
rl training, epoch7, iter0, batch995/1133, batch loss:0.28527510166168213, Training time:24893.055705308914
batch reward last col mean 0.127868190407753 first col mean 0.0965857207775116 all mean 0.11856908351182938
0.29553619027137756 0.29553619027137756
rl training, epoch7, iter0, batch996/1133, batch loss:0.29553619027137756, Training time:24894.873192310333
batch reward last col mean 0.1199905127286911 first col mean 0.10988809168338776 all mean 0.11799558252096176
0.29682469367980957 0.29682469367980957
rl training, epoch7, iter0, batch997/1133, batch loss:0.29682469367980957, Training time:24897.247841596603
batch reward last col mean 0.12326851487159729 first col mean 0.11793555319309235 all mean 0.11553975939750671
0.3018685579299927 0.3018685579299927
rl training, epoch7, iter0, batch998/1133, batch loss:0.3018685579299927, Training time:24899.308163404465
batch reward last col mean 0.16016635298728943 first col mean 0.11562201380729675 all mean 0.14790354669094086
0.33897799253463745 0.33897799253463745
rl training, epoch7, iter0, batch999/1133, batch loss:0.33897799253463745, Training time:24901.59807419777
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46998903092197475 Time: 96.36091995239258 s
loss of true 0.2027442266627002 loss of gen 0.173112066730607 loss of other 0.09413273766676304 first score 0.10953822731971741
batch reward last col mean 0.10491786152124405 first col mean 0.10785016417503357 all mean 0.10212819278240204
0.2845599353313446 0.2845599353313446
rl training, epoch7, iter0, batch1000/1133, batch loss:0.2845599353313446, Training time:25000.109430789948
batch reward last col mean 0.1024441123008728 first col mean 0.09889902174472809 all mean 0.10593260824680328
0.2723575234413147 0.2723575234413147
rl training, epoch7, iter0, batch1001/1133, batch loss:0.2723575234413147, Training time:25002.85647034645
batch reward last col mean 0.07513177394866943 first col mean 0.11717858165502548 all mean 0.08625379204750061
0.2766871154308319 0.2766871154308319
rl training, epoch7, iter0, batch1002/1133, batch loss:0.2766871154308319, Training time:25004.786541223526
batch reward last col mean 0.10368014872074127 first col mean 0.11181861162185669 all mean 0.10671637952327728
0.3020224869251251 0.3020225167274475
rl training, epoch7, iter0, batch1003/1133, batch loss:0.3020225167274475, Training time:25006.52072763443
batch reward last col mean 0.09215395897626877 first col mean 0.10545278340578079 all mean 0.09628625214099884
0.2604464888572693 0.2604464888572693
rl training, epoch7, iter0, batch1004/1133, batch loss:0.2604464888572693, Training time:25008.628534317017
batch reward last col mean 0.10625787824392319 first col mean 0.10574272274971008 all mean 0.10465092957019806
0.28181520104408264 0.28181517124176025
rl training, epoch7, iter0, batch1005/1133, batch loss:0.28181517124176025, Training time:25010.887922763824
batch reward last col mean 0.11631965637207031 first col mean 0.10314329713582993 all mean 0.1157500296831131
0.3009216785430908 0.3009216785430908
rl training, epoch7, iter0, batch1006/1133, batch loss:0.3009216785430908, Training time:25012.860184907913
batch reward last col mean 0.08498532325029373 first col mean 0.1044694185256958 all mean 0.09302137792110443
0.2892899513244629 0.2892899513244629
rl training, epoch7, iter0, batch1007/1133, batch loss:0.2892899513244629, Training time:25014.74814391136
batch reward last col mean 0.1024259626865387 first col mean 0.12826722860336304 all mean 0.1068372055888176
0.27116647362709045 0.27116647362709045
rl training, epoch7, iter0, batch1008/1133, batch loss:0.27116647362709045, Training time:25016.62105989456
batch reward last col mean 0.10179702937602997 first col mean 0.09247682988643646 all mean 0.107572540640831
0.28124499320983887 0.28124499320983887
rl training, epoch7, iter0, batch1009/1133, batch loss:0.28124499320983887, Training time:25018.65362262726
batch reward last col mean 0.0879765972495079 first col mean 0.10586846619844437 all mean 0.09470345079898834
0.287546843290329 0.287546843290329
rl training, epoch7, iter0, batch1010/1133, batch loss:0.287546843290329, Training time:25020.59698987007
batch reward last col mean 0.07725473493337631 first col mean 0.11873862892389297 all mean 0.08504074066877365
0.29597416520118713 0.29597416520118713
rl training, epoch7, iter0, batch1011/1133, batch loss:0.29597416520118713, Training time:25023.824329137802
batch reward last col mean 0.10603192448616028 first col mean 0.10706601291894913 all mean 0.1026613637804985
0.27222371101379395 0.27222371101379395
rl training, epoch7, iter0, batch1012/1133, batch loss:0.27222371101379395, Training time:25025.880840301514
batch reward last col mean 0.12115047872066498 first col mean 0.10641279071569443 all mean 0.12189931422472
0.3046296238899231 0.3046296238899231
rl training, epoch7, iter0, batch1013/1133, batch loss:0.3046296238899231, Training time:25027.796436071396
batch reward last col mean 0.10674578696489334 first col mean 0.105218306183815 all mean 0.10486475378274918
0.2559893727302551 0.2559893727302551
rl training, epoch7, iter0, batch1014/1133, batch loss:0.2559893727302551, Training time:25029.509472608566
batch reward last col mean 0.06801038980484009 first col mean 0.11117127537727356 all mean 0.0820690244436264
0.2823207974433899 0.2823207974433899
rl training, epoch7, iter0, batch1015/1133, batch loss:0.2823207974433899, Training time:25032.178061008453
batch reward last col mean 0.08742982149124146 first col mean 0.10896500200033188 all mean 0.08712229132652283
0.22085723280906677 0.22085723280906677
rl training, epoch7, iter0, batch1016/1133, batch loss:0.22085723280906677, Training time:25034.202713012695
batch reward last col mean 0.10557244718074799 first col mean 0.11026894301176071 all mean 0.10824953764677048
0.3060327470302582 0.3060327470302582
rl training, epoch7, iter0, batch1017/1133, batch loss:0.3060327470302582, Training time:25035.998727560043
batch reward last col mean 0.09752184897661209 first col mean 0.11477074772119522 all mean 0.10136158764362335
0.2547813355922699 0.2547813355922699
rl training, epoch7, iter0, batch1018/1133, batch loss:0.2547813355922699, Training time:25037.78087067604
batch reward last col mean 0.08690677583217621 first col mean 0.12762251496315002 all mean 0.09846559166908264
0.2631668150424957 0.2631668150424957
rl training, epoch7, iter0, batch1019/1133, batch loss:0.2631668150424957, Training time:25039.942533254623
batch reward last col mean 0.10382382571697235 first col mean 0.13004285097122192 all mean 0.10467945784330368
0.28731968998908997 0.28731971979141235
rl training, epoch7, iter0, batch1020/1133, batch loss:0.28731971979141235, Training time:25042.135469913483
batch reward last col mean 0.09055012464523315 first col mean 0.11062774062156677 all mean 0.09820360690355301
0.2740117907524109 0.2740117907524109
rl training, epoch7, iter0, batch1021/1133, batch loss:0.2740117907524109, Training time:25043.984253644943
batch reward last col mean 0.1274527609348297 first col mean 0.10937029123306274 all mean 0.12099767476320267
0.29106661677360535 0.29106661677360535
rl training, epoch7, iter0, batch1022/1133, batch loss:0.29106661677360535, Training time:25045.97359609604
batch reward last col mean 0.10722197592258453 first col mean 0.11695583164691925 all mean 0.10709285736083984
0.2743057906627655 0.2743057906627655
rl training, epoch7, iter0, batch1023/1133, batch loss:0.2743057906627655, Training time:25047.994325637817
batch reward last col mean 0.13345825672149658 first col mean 0.12409414350986481 all mean 0.12471037358045578
0.3579253852367401 0.3579253852367401
rl training, epoch7, iter0, batch1024/1133, batch loss:0.3579253852367401, Training time:25050.198808908463
batch reward last col mean 0.13361772894859314 first col mean 0.10740721225738525 all mean 0.1282503455877304
0.291201651096344 0.291201651096344
rl training, epoch7, iter0, batch1025/1133, batch loss:0.291201651096344, Training time:25052.79074716568
batch reward last col mean 0.06124472990632057 first col mean 0.10089676827192307 all mean 0.06753746420145035
0.2471417784690857 0.2471417784690857
rl training, epoch7, iter0, batch1026/1133, batch loss:0.2471417784690857, Training time:25055.231904745102
batch reward last col mean 0.11076518893241882 first col mean 0.09444313496351242 all mean 0.10687282681465149
0.33842015266418457 0.33842015266418457
rl training, epoch7, iter0, batch1027/1133, batch loss:0.33842015266418457, Training time:25057.51534128189
batch reward last col mean 0.09336148947477341 first col mean 0.11451072245836258 all mean 0.09680164605379105
0.2589894235134125 0.2589894235134125
rl training, epoch7, iter0, batch1028/1133, batch loss:0.2589894235134125, Training time:25059.56526327133
batch reward last col mean 0.12446751445531845 first col mean 0.10939154028892517 all mean 0.11705610156059265
0.2794433534145355 0.2794433534145355
rl training, epoch7, iter0, batch1029/1133, batch loss:0.2794433534145355, Training time:25061.924328804016
batch reward last col mean 0.10591165721416473 first col mean 0.1077825129032135 all mean 0.1063741147518158
0.2685597538948059 0.2685597538948059
rl training, epoch7, iter0, batch1030/1133, batch loss:0.2685597538948059, Training time:25063.693467140198
batch reward last col mean 0.10777188092470169 first col mean 0.11477429419755936 all mean 0.10910718888044357
0.3022761940956116 0.3022761940956116
rl training, epoch7, iter0, batch1031/1133, batch loss:0.3022761940956116, Training time:25066.120227098465
batch reward last col mean 0.12562817335128784 first col mean 0.1040850281715393 all mean 0.12032084912061691
0.32357320189476013 0.32357317209243774
rl training, epoch7, iter0, batch1032/1133, batch loss:0.32357317209243774, Training time:25068.872612953186
batch reward last col mean 0.1065351590514183 first col mean 0.11442498862743378 all mean 0.10607760399580002
0.254312127828598 0.254312127828598
rl training, epoch7, iter0, batch1033/1133, batch loss:0.254312127828598, Training time:25071.05814909935
batch reward last col mean 0.09423020482063293 first col mean 0.11098817735910416 all mean 0.09803105890750885
0.3037751019001007 0.3037751019001007
rl training, epoch7, iter0, batch1034/1133, batch loss:0.3037751019001007, Training time:25073.28550505638
batch reward last col mean 0.12022530287504196 first col mean 0.10845824331045151 all mean 0.11829826980829239
0.3237253725528717 0.3237253725528717
rl training, epoch7, iter0, batch1035/1133, batch loss:0.3237253725528717, Training time:25075.660615444183
batch reward last col mean 0.11524989455938339 first col mean 0.12681549787521362 all mean 0.11204475164413452
0.2589587867259979 0.2589587867259979
rl training, epoch7, iter0, batch1036/1133, batch loss:0.2589587867259979, Training time:25077.919073343277
batch reward last col mean 0.1170729398727417 first col mean 0.09961902350187302 all mean 0.11547759175300598
0.2883969247341156 0.2883969247341156
rl training, epoch7, iter0, batch1037/1133, batch loss:0.2883969247341156, Training time:25080.318263053894
batch reward last col mean 0.08049418777227402 first col mean 0.11477082967758179 all mean 0.08862243592739105
0.26767805218696594 0.26767805218696594
rl training, epoch7, iter0, batch1038/1133, batch loss:0.26767805218696594, Training time:25082.299650669098
batch reward last col mean 0.10830314457416534 first col mean 0.0978415235877037 all mean 0.1035454198718071
0.2384129911661148 0.2384129911661148
rl training, epoch7, iter0, batch1039/1133, batch loss:0.2384129911661148, Training time:25084.197930574417
batch reward last col mean 0.11035965383052826 first col mean 0.09326979517936707 all mean 0.11455650627613068
0.3022424578666687 0.3022424578666687
rl training, epoch7, iter0, batch1040/1133, batch loss:0.3022424578666687, Training time:25086.13720536232
batch reward last col mean 0.08929753303527832 first col mean 0.10795919597148895 all mean 0.09271668642759323
0.25509101152420044 0.25509098172187805
rl training, epoch7, iter0, batch1041/1133, batch loss:0.25509098172187805, Training time:25088.591819047928
batch reward last col mean 0.1434124857187271 first col mean 0.11380654573440552 all mean 0.12269168347120285
0.2841346859931946 0.2841346561908722
rl training, epoch7, iter0, batch1042/1133, batch loss:0.2841346561908722, Training time:25090.93821287155
batch reward last col mean 0.08925611525774002 first col mean 0.0960782915353775 all mean 0.09344274550676346
0.2859291434288025 0.2859291732311249
rl training, epoch7, iter0, batch1043/1133, batch loss:0.2859291732311249, Training time:25093.162894248962
batch reward last col mean 0.09486045688390732 first col mean 0.11219644546508789 all mean 0.10242966562509537
0.27922433614730835 0.27922433614730835
rl training, epoch7, iter0, batch1044/1133, batch loss:0.27922433614730835, Training time:25095.0157289505
batch reward last col mean 0.11763455718755722 first col mean 0.09226860105991364 all mean 0.11332250386476517
0.2985195815563202 0.2985195815563202
rl training, epoch7, iter0, batch1045/1133, batch loss:0.2985195815563202, Training time:25097.156294107437
batch reward last col mean 0.11609813570976257 first col mean 0.1035400778055191 all mean 0.1147666946053505
0.30951210856437683 0.30951210856437683
rl training, epoch7, iter0, batch1046/1133, batch loss:0.30951210856437683, Training time:25099.206042289734
batch reward last col mean 0.09981159120798111 first col mean 0.10967324674129486 all mean 0.10467245429754257
0.31101223826408386 0.31101223826408386
rl training, epoch7, iter0, batch1047/1133, batch loss:0.31101223826408386, Training time:25102.38928413391
batch reward last col mean 0.10049266368150711 first col mean 0.12063777446746826 all mean 0.09914176911115646
0.2763298451900482 0.2763298451900482
rl training, epoch7, iter0, batch1048/1133, batch loss:0.2763298451900482, Training time:25104.39043569565
batch reward last col mean 0.14210689067840576 first col mean 0.11089878529310226 all mean 0.13072052597999573
0.2755720019340515 0.2755720019340515
rl training, epoch7, iter0, batch1049/1133, batch loss:0.2755720019340515, Training time:25106.216341733932
batch reward last col mean 0.12160826474428177 first col mean 0.125770702958107 all mean 0.11659307032823563
0.2862735688686371 0.2862735688686371
rl training, epoch7, iter0, batch1050/1133, batch loss:0.2862735688686371, Training time:25108.29952788353
batch reward last col mean 0.08185966312885284 first col mean 0.09632647037506104 all mean 0.0841132327914238
0.25341928005218506 0.25341928005218506
rl training, epoch7, iter0, batch1051/1133, batch loss:0.25341928005218506, Training time:25110.680810928345
batch reward last col mean 0.08371918648481369 first col mean 0.11580727994441986 all mean 0.09739487618207932
0.30724120140075684 0.30724120140075684
rl training, epoch7, iter0, batch1052/1133, batch loss:0.30724120140075684, Training time:25112.629518032074
batch reward last col mean 0.1014501303434372 first col mean 0.11051903665065765 all mean 0.10824932157993317
0.3171330690383911 0.3171330690383911
rl training, epoch7, iter0, batch1053/1133, batch loss:0.3171330690383911, Training time:25114.58381319046
batch reward last col mean 0.10118257254362106 first col mean 0.11635685712099075 all mean 0.10308025777339935
0.28055697679519653 0.28055697679519653
rl training, epoch7, iter0, batch1054/1133, batch loss:0.28055697679519653, Training time:25116.72467494011
batch reward last col mean 0.11433416604995728 first col mean 0.09517773985862732 all mean 0.10779932141304016
0.2404254674911499 0.2404254674911499
rl training, epoch7, iter0, batch1055/1133, batch loss:0.2404254674911499, Training time:25118.83935546875
batch reward last col mean 0.10794684290885925 first col mean 0.10122987627983093 all mean 0.10322348773479462
0.2634955048561096 0.2634955048561096
rl training, epoch7, iter0, batch1056/1133, batch loss:0.2634955048561096, Training time:25120.90156674385
batch reward last col mean 0.10181161761283875 first col mean 0.11364226788282394 all mean 0.1034381315112114
0.2909573018550873 0.2909573018550873
rl training, epoch7, iter0, batch1057/1133, batch loss:0.2909573018550873, Training time:25123.048404932022
batch reward last col mean 0.08867976814508438 first col mean 0.09442064166069031 all mean 0.09651347994804382
0.27290093898773193 0.27290093898773193
rl training, epoch7, iter0, batch1058/1133, batch loss:0.27290093898773193, Training time:25125.200414180756
batch reward last col mean 0.08739639818668365 first col mean 0.09530719369649887 all mean 0.09041968733072281
0.27007222175598145 0.27007222175598145
rl training, epoch7, iter0, batch1059/1133, batch loss:0.27007222175598145, Training time:25127.419536352158
batch reward last col mean 0.09198538959026337 first col mean 0.13097450137138367 all mean 0.10010673850774765
0.2913838326931 0.2913838326931
rl training, epoch7, iter0, batch1060/1133, batch loss:0.2913838326931, Training time:25128.89576292038
batch reward last col mean 0.09586945921182632 first col mean 0.13224665820598602 all mean 0.10038972645998001
0.24992947280406952 0.24992947280406952
rl training, epoch7, iter0, batch1061/1133, batch loss:0.24992947280406952, Training time:25131.14487671852
batch reward last col mean 0.0912325382232666 first col mean 0.12422657012939453 all mean 0.09199970215559006
0.2697661221027374 0.2697661221027374
rl training, epoch7, iter0, batch1062/1133, batch loss:0.2697661221027374, Training time:25133.409266233444
batch reward last col mean 0.15121561288833618 first col mean 0.12125638872385025 all mean 0.1373332440853119
0.32332900166511536 0.32332897186279297
rl training, epoch7, iter0, batch1063/1133, batch loss:0.32332897186279297, Training time:25135.431537151337
batch reward last col mean 0.10019316524267197 first col mean 0.11260712146759033 all mean 0.10419819504022598
0.30131667852401733 0.30131664872169495
rl training, epoch7, iter0, batch1064/1133, batch loss:0.30131664872169495, Training time:25137.27198076248
batch reward last col mean 0.09849674254655838 first col mean 0.12786290049552917 all mean 0.09557534754276276
0.2510402798652649 0.2510402798652649
rl training, epoch7, iter0, batch1065/1133, batch loss:0.2510402798652649, Training time:25139.13035941124
batch reward last col mean 0.10650478303432465 first col mean 0.11319144070148468 all mean 0.1092064306139946
0.2956455945968628 0.2956455945968628
rl training, epoch7, iter0, batch1066/1133, batch loss:0.2956455945968628, Training time:25141.095817565918
batch reward last col mean 0.11134349554777145 first col mean 0.09884423017501831 all mean 0.11302982270717621
0.31327420473098755 0.31327420473098755
rl training, epoch7, iter0, batch1067/1133, batch loss:0.31327420473098755, Training time:25143.047846078873
batch reward last col mean 0.08217982202768326 first col mean 0.11533201485872269 all mean 0.09365645796060562
0.28056278824806213 0.28056278824806213
rl training, epoch7, iter0, batch1068/1133, batch loss:0.28056278824806213, Training time:25145.044387817383
batch reward last col mean 0.09687045216560364 first col mean 0.11192553490400314 all mean 0.10116876661777496
0.2786366045475006 0.2786366045475006
rl training, epoch7, iter0, batch1069/1133, batch loss:0.2786366045475006, Training time:25147.437345027924
batch reward last col mean 0.09119734913110733 first col mean 0.10507969558238983 all mean 0.09916096925735474
0.2749534547328949 0.2749534547328949
rl training, epoch7, iter0, batch1070/1133, batch loss:0.2749534547328949, Training time:25149.643976926804
batch reward last col mean 0.1329393982887268 first col mean 0.09588826447725296 all mean 0.12292587757110596
0.3065677285194397 0.3065677285194397
rl training, epoch7, iter0, batch1071/1133, batch loss:0.3065677285194397, Training time:25151.83770775795
batch reward last col mean 0.10802784562110901 first col mean 0.10554775595664978 all mean 0.11254269629716873
0.2730174958705902 0.2730174958705902
rl training, epoch7, iter0, batch1072/1133, batch loss:0.2730174958705902, Training time:25153.993995428085
batch reward last col mean 0.06075088679790497 first col mean 0.1042376309633255 all mean 0.075741246342659
0.23110581934452057 0.23110581934452057
rl training, epoch7, iter0, batch1073/1133, batch loss:0.23110581934452057, Training time:25155.751954078674
batch reward last col mean 0.140703022480011 first col mean 0.10147219896316528 all mean 0.12692679464817047
0.26355963945388794 0.26355963945388794
rl training, epoch7, iter0, batch1074/1133, batch loss:0.26355963945388794, Training time:25157.576523065567
batch reward last col mean 0.10375044494867325 first col mean 0.10184171795845032 all mean 0.1075601875782013
0.3003131151199341 0.3003131151199341
rl training, epoch7, iter0, batch1075/1133, batch loss:0.3003131151199341, Training time:25159.392132520676
batch reward last col mean 0.10833917558193207 first col mean 0.11952781677246094 all mean 0.1110014095902443
0.26461663842201233 0.26461663842201233
rl training, epoch7, iter0, batch1076/1133, batch loss:0.26461663842201233, Training time:25161.588739156723
batch reward last col mean 0.13461706042289734 first col mean 0.10475066304206848 all mean 0.11908993124961853
0.30410510301589966 0.30410510301589966
rl training, epoch7, iter0, batch1077/1133, batch loss:0.30410510301589966, Training time:25163.438779592514
batch reward last col mean 0.10025355219841003 first col mean 0.1144665852189064 all mean 0.10616493970155716
0.2890147268772125 0.2890147268772125
rl training, epoch7, iter0, batch1078/1133, batch loss:0.2890147268772125, Training time:25165.301066875458
batch reward last col mean 0.06708496809005737 first col mean 0.1141296923160553 all mean 0.08048474043607712
0.26385727524757385 0.26385727524757385
rl training, epoch7, iter0, batch1079/1133, batch loss:0.26385727524757385, Training time:25167.380829811096
batch reward last col mean 0.11381065845489502 first col mean 0.11086952686309814 all mean 0.11613903939723969
0.2694827616214752 0.2694827616214752
rl training, epoch7, iter0, batch1080/1133, batch loss:0.2694827616214752, Training time:25169.429614305496
batch reward last col mean 0.09528671205043793 first col mean 0.0994262844324112 all mean 0.10048944503068924
0.26704540848731995 0.26704540848731995
rl training, epoch7, iter0, batch1081/1133, batch loss:0.26704540848731995, Training time:25171.3615026474
batch reward last col mean 0.10815990716218948 first col mean 0.10800067335367203 all mean 0.10863306373357773
0.3121907711029053 0.3121907711029053
rl training, epoch7, iter0, batch1082/1133, batch loss:0.3121907711029053, Training time:25173.245267629623
batch reward last col mean 0.10158532857894897 first col mean 0.0987769067287445 all mean 0.10151973366737366
0.3193293809890747 0.3193293809890747
rl training, epoch7, iter0, batch1083/1133, batch loss:0.3193293809890747, Training time:25175.08921432495
batch reward last col mean 0.11243072152137756 first col mean 0.10444524884223938 all mean 0.10872431099414825
0.2789963483810425 0.2789963483810425
rl training, epoch7, iter0, batch1084/1133, batch loss:0.2789963483810425, Training time:25177.792306423187
batch reward last col mean 0.1167043074965477 first col mean 0.1264762282371521 all mean 0.11938910186290741
0.2824026942253113 0.2824026942253113
rl training, epoch7, iter0, batch1085/1133, batch loss:0.2824026942253113, Training time:25179.37566280365
batch reward last col mean 0.1357041895389557 first col mean 0.1255049854516983 all mean 0.1277395486831665
0.3011823892593384 0.3011823892593384
rl training, epoch7, iter0, batch1086/1133, batch loss:0.3011823892593384, Training time:25181.11301636696
batch reward last col mean 0.09686586260795593 first col mean 0.11633315682411194 all mean 0.10096690058708191
0.27161073684692383 0.27161073684692383
rl training, epoch7, iter0, batch1087/1133, batch loss:0.27161073684692383, Training time:25182.911821603775
batch reward last col mean 0.11600019037723541 first col mean 0.11823564767837524 all mean 0.11352452635765076
0.2754683196544647 0.2754683196544647
rl training, epoch7, iter0, batch1088/1133, batch loss:0.2754683196544647, Training time:25184.996717214584
batch reward last col mean 0.10845702886581421 first col mean 0.10885416716337204 all mean 0.11099971830844879
0.28144949674606323 0.28144949674606323
rl training, epoch7, iter0, batch1089/1133, batch loss:0.28144949674606323, Training time:25186.747164964676
batch reward last col mean 0.10060589015483856 first col mean 0.09702745079994202 all mean 0.0997769758105278
0.26254430413246155 0.26254430413246155
rl training, epoch7, iter0, batch1090/1133, batch loss:0.26254430413246155, Training time:25188.499118328094
batch reward last col mean 0.11712402105331421 first col mean 0.10060650110244751 all mean 0.11733240634202957
0.305475115776062 0.30547505617141724
rl training, epoch7, iter0, batch1091/1133, batch loss:0.30547505617141724, Training time:25190.620529174805
batch reward last col mean 0.12734924256801605 first col mean 0.10512888431549072 all mean 0.12429209053516388
0.3088693916797638 0.3088693916797638
rl training, epoch7, iter0, batch1092/1133, batch loss:0.3088693916797638, Training time:25192.494341373444
batch reward last col mean 0.08587756752967834 first col mean 0.13155271112918854 all mean 0.0907769426703453
0.2322022020816803 0.2322022020816803
rl training, epoch7, iter0, batch1093/1133, batch loss:0.2322022020816803, Training time:25193.93705677986
batch reward last col mean 0.08899269253015518 first col mean 0.11957009136676788 all mean 0.10046380758285522
0.25479835271835327 0.25479835271835327
rl training, epoch7, iter0, batch1094/1133, batch loss:0.25479835271835327, Training time:25196.067531347275
batch reward last col mean 0.1139649897813797 first col mean 0.09577333927154541 all mean 0.1151011660695076
0.29535555839538574 0.29535555839538574
rl training, epoch7, iter0, batch1095/1133, batch loss:0.29535555839538574, Training time:25198.572346925735
batch reward last col mean 0.07267697900533676 first col mean 0.10467386990785599 all mean 0.077965147793293
0.2511563003063202 0.2511563003063202
rl training, epoch7, iter0, batch1096/1133, batch loss:0.2511563003063202, Training time:25200.66870355606
batch reward last col mean 0.09423303604125977 first col mean 0.11641900986433029 all mean 0.10025081783533096
0.30188459157943726 0.30188456177711487
rl training, epoch7, iter0, batch1097/1133, batch loss:0.30188456177711487, Training time:25202.610986948013
batch reward last col mean 0.0806032195687294 first col mean 0.115528404712677 all mean 0.08854088932275772
0.25843822956085205 0.25843825936317444
rl training, epoch7, iter0, batch1098/1133, batch loss:0.25843825936317444, Training time:25205.10632276535
batch reward last col mean 0.13030971586704254 first col mean 0.0921153873205185 all mean 0.12194821983575821
0.2914963960647583 0.2914964258670807
rl training, epoch7, iter0, batch1099/1133, batch loss:0.2914964258670807, Training time:25207.546287059784
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4709830487973903 Time: 96.80392050743103 s
loss of true 0.20341102822970628 loss of gen 0.17324252841568372 loss of other 0.09432949171962984 first score 0.09741482138633728
batch reward last col mean 0.09035538136959076 first col mean 0.11132773756980896 all mean 0.09553217142820358
0.25135838985443115 0.25135838985443115
rl training, epoch7, iter0, batch1100/1133, batch loss:0.25135838985443115, Training time:25306.329363822937
batch reward last col mean 0.10324491560459137 first col mean 0.09080741554498672 all mean 0.10723612457513809
0.2696358561515808 0.2696358561515808
rl training, epoch7, iter0, batch1101/1133, batch loss:0.2696358561515808, Training time:25308.196736097336
batch reward last col mean 0.10578299313783646 first col mean 0.09516559541225433 all mean 0.10632487386465073
0.29903194308280945 0.29903194308280945
rl training, epoch7, iter0, batch1102/1133, batch loss:0.29903194308280945, Training time:25310.12170314789
batch reward last col mean 0.10789504647254944 first col mean 0.08558458089828491 all mean 0.10403832793235779
0.27818813920021057 0.27818813920021057
rl training, epoch7, iter0, batch1103/1133, batch loss:0.27818813920021057, Training time:25311.949838399887
batch reward last col mean 0.0896490141749382 first col mean 0.12046578526496887 all mean 0.09410358220338821
0.24316705763339996 0.24316705763339996
rl training, epoch7, iter0, batch1104/1133, batch loss:0.24316705763339996, Training time:25314.450428009033
batch reward last col mean 0.13014283776283264 first col mean 0.11233444511890411 all mean 0.11826294660568237
0.25477102398872375 0.25477102398872375
rl training, epoch7, iter0, batch1105/1133, batch loss:0.25477102398872375, Training time:25316.15277314186
batch reward last col mean 0.09194394201040268 first col mean 0.10153161734342575 all mean 0.09719918668270111
0.2796623408794403 0.2796623110771179
rl training, epoch7, iter0, batch1106/1133, batch loss:0.2796623110771179, Training time:25318.217719078064
batch reward last col mean 0.08283933997154236 first col mean 0.09715943038463593 all mean 0.0895543247461319
0.25310879945755005 0.25310879945755005
rl training, epoch7, iter0, batch1107/1133, batch loss:0.25310879945755005, Training time:25320.239509105682
batch reward last col mean 0.08120287954807281 first col mean 0.10627342015504837 all mean 0.08811045438051224
0.24574889242649078 0.24574889242649078
rl training, epoch7, iter0, batch1108/1133, batch loss:0.24574889242649078, Training time:25322.292444467545
batch reward last col mean 0.10864295065402985 first col mean 0.11359085142612457 all mean 0.10469865798950195
0.26560789346694946 0.26560789346694946
rl training, epoch7, iter0, batch1109/1133, batch loss:0.26560789346694946, Training time:25324.492077589035
batch reward last col mean 0.10296902060508728 first col mean 0.09455110132694244 all mean 0.09886077791452408
0.2562180459499359 0.2562180459499359
rl training, epoch7, iter0, batch1110/1133, batch loss:0.2562180459499359, Training time:25326.337310791016
batch reward last col mean 0.08327394723892212 first col mean 0.11162721365690231 all mean 0.09155210107564926
0.2648230493068695 0.2648230195045471
rl training, epoch7, iter0, batch1111/1133, batch loss:0.2648230195045471, Training time:25328.030349254608
batch reward last col mean 0.09386562556028366 first col mean 0.12779441475868225 all mean 0.09712283313274384
0.24754738807678223 0.24754738807678223
rl training, epoch7, iter0, batch1112/1133, batch loss:0.24754738807678223, Training time:25330.071115732193
batch reward last col mean 0.0870567113161087 first col mean 0.09901737421751022 all mean 0.09061523526906967
0.2563498616218567 0.2563498616218567
rl training, epoch7, iter0, batch1113/1133, batch loss:0.2563498616218567, Training time:25332.12013745308
batch reward last col mean 0.08020322024822235 first col mean 0.10149303078651428 all mean 0.08010199666023254
0.20283232629299164 0.20283234119415283
rl training, epoch7, iter0, batch1114/1133, batch loss:0.20283234119415283, Training time:25333.968982219696
batch reward last col mean 0.12529779970645905 first col mean 0.11386798322200775 all mean 0.11831124126911163
0.2861846685409546 0.2861846387386322
rl training, epoch7, iter0, batch1115/1133, batch loss:0.2861846387386322, Training time:25335.971790075302
batch reward last col mean 0.08402983844280243 first col mean 0.09118020534515381 all mean 0.09066766500473022
0.2502996325492859 0.2502996325492859
rl training, epoch7, iter0, batch1116/1133, batch loss:0.2502996325492859, Training time:25337.56922507286
batch reward last col mean 0.0899871289730072 first col mean 0.10464157164096832 all mean 0.09160970896482468
0.252649188041687 0.252649188041687
rl training, epoch7, iter0, batch1117/1133, batch loss:0.252649188041687, Training time:25339.44403386116
batch reward last col mean 0.08447980880737305 first col mean 0.09901228547096252 all mean 0.09233760088682175
0.2636703550815582 0.2636703550815582
rl training, epoch7, iter0, batch1118/1133, batch loss:0.2636703550815582, Training time:25341.750311613083
batch reward last col mean 0.08349189162254333 first col mean 0.12101095169782639 all mean 0.08878814429044724
0.24124179780483246 0.24124179780483246
rl training, epoch7, iter0, batch1119/1133, batch loss:0.24124179780483246, Training time:25343.299847841263
batch reward last col mean 0.1022043526172638 first col mean 0.09893308579921722 all mean 0.10307396948337555
0.2701011300086975 0.2701011300086975
rl training, epoch7, iter0, batch1120/1133, batch loss:0.2701011300086975, Training time:25346.298434495926
batch reward last col mean 0.07917069643735886 first col mean 0.10236614942550659 all mean 0.08637343347072601
0.23884254693984985 0.23884254693984985
rl training, epoch7, iter0, batch1121/1133, batch loss:0.23884254693984985, Training time:25348.21746659279
batch reward last col mean 0.09932893514633179 first col mean 0.11270291358232498 all mean 0.09999778866767883
0.24600377678871155 0.24600377678871155
rl training, epoch7, iter0, batch1122/1133, batch loss:0.24600377678871155, Training time:25350.20803809166
batch reward last col mean 0.0916604995727539 first col mean 0.10529040545225143 all mean 0.09345515817403793
0.26995527744293213 0.26995527744293213
rl training, epoch7, iter0, batch1123/1133, batch loss:0.26995527744293213, Training time:25352.157622098923
batch reward last col mean 0.10082916915416718 first col mean 0.10205989331007004 all mean 0.10347576439380646
0.27602052688598633 0.27602052688598633
rl training, epoch7, iter0, batch1124/1133, batch loss:0.27602052688598633, Training time:25353.99755334854
batch reward last col mean 0.1312263458967209 first col mean 0.11132778227329254 all mean 0.12433016300201416
0.3063104748725891 0.3063104748725891
rl training, epoch7, iter0, batch1125/1133, batch loss:0.3063104748725891, Training time:25356.05139899254
batch reward last col mean 0.0928109660744667 first col mean 0.1070617213845253 all mean 0.09566494077444077
0.2722969651222229 0.2722969353199005
rl training, epoch7, iter0, batch1126/1133, batch loss:0.2722969353199005, Training time:25358.406893491745
batch reward last col mean 0.10822959244251251 first col mean 0.10008758306503296 all mean 0.10714886337518692
0.25714629888534546 0.25714629888534546
rl training, epoch7, iter0, batch1127/1133, batch loss:0.25714629888534546, Training time:25360.644618988037
batch reward last col mean 0.09407936036586761 first col mean 0.10945829004049301 all mean 0.09681281447410583
0.25158044695854187 0.25158044695854187
rl training, epoch7, iter0, batch1128/1133, batch loss:0.25158044695854187, Training time:25363.26580119133
batch reward last col mean 0.13883505761623383 first col mean 0.0915670245885849 all mean 0.13204753398895264
0.26520654559135437 0.26520654559135437
rl training, epoch7, iter0, batch1129/1133, batch loss:0.26520654559135437, Training time:25365.81638765335
batch reward last col mean 0.13903719186782837 first col mean 0.10254289209842682 all mean 0.12886177003383636
0.2734942138195038 0.2734942138195038
rl training, epoch7, iter0, batch1130/1133, batch loss:0.2734942138195038, Training time:25367.507376909256
batch reward last col mean 0.11376441270112991 first col mean 0.11235764622688293 all mean 0.11144771426916122
0.26835715770721436 0.26835715770721436
rl training, epoch7, iter0, batch1131/1133, batch loss:0.26835715770721436, Training time:25369.40068602562
batch reward last col mean 0.09309926629066467 first col mean 0.09765136241912842 all mean 0.096541628241539
0.2952546775341034 0.2952546775341034
rl training, epoch7, iter0, batch1132/1133, batch loss:0.2952546775341034, Training time:25371.04478573799
rl training, epoch 7, iter 0, loss:0.2747182254494552, Training time:25371.045001506805 
rl epoch 7, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.9736759485865942 Time: 131.69300436973572 s
rl epoch 7, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.44406755730207265 Time: 97.81884169578552 s
loss of true 0.18943662135241207 loss of gen 0.16027889892932387 loss of other 0.09435203750695892 first score 0.11993473023176193
rl epoch 8, begin RL for generator...
batch reward last col mean 0.10001412034034729 first col mean 0.09563173353672028 all mean 0.09440267086029053
0.28779688477516174 0.28779688477516174
rl training, epoch8, iter0, batch0/1133, batch loss:0.28779688477516174, Training time:25603.32449889183
batch reward last col mean 0.09778722375631332 first col mean 0.08047521859407425 all mean 0.09495823830366135
0.24399295449256897 0.24399295449256897
rl training, epoch8, iter0, batch1/1133, batch loss:0.24399295449256897, Training time:25605.267701387405
batch reward last col mean 0.08433803915977478 first col mean 0.07654386013746262 all mean 0.08024837076663971
0.2414449155330658 0.2414449155330658
rl training, epoch8, iter0, batch2/1133, batch loss:0.2414449155330658, Training time:25607.321058511734
batch reward last col mean 0.09122402966022491 first col mean 0.08370082825422287 all mean 0.09248077869415283
0.26575344800949097 0.26575344800949097
rl training, epoch8, iter0, batch3/1133, batch loss:0.26575344800949097, Training time:25609.286705732346
batch reward last col mean 0.12524384260177612 first col mean 0.09095587581396103 all mean 0.1192111000418663
0.2745261788368225 0.2745261788368225
rl training, epoch8, iter0, batch4/1133, batch loss:0.2745261788368225, Training time:25611.169378995895
batch reward last col mean 0.0841471329331398 first col mean 0.07498104870319366 all mean 0.08379001170396805
0.2611050605773926 0.2611050605773926
rl training, epoch8, iter0, batch5/1133, batch loss:0.2611050605773926, Training time:25612.77143931389
batch reward last col mean 0.09102430939674377 first col mean 0.08191625773906708 all mean 0.08732457458972931
0.22830399870872498 0.22830399870872498
rl training, epoch8, iter0, batch6/1133, batch loss:0.22830399870872498, Training time:25614.539332151413
batch reward last col mean 0.11132918298244476 first col mean 0.07880605757236481 all mean 0.09925281256437302
0.24200104176998138 0.24200104176998138
rl training, epoch8, iter0, batch7/1133, batch loss:0.24200104176998138, Training time:25616.717160463333
batch reward last col mean 0.07204015552997589 first col mean 0.09126877039670944 all mean 0.0799095556139946
0.27130889892578125 0.27130889892578125
rl training, epoch8, iter0, batch8/1133, batch loss:0.27130889892578125, Training time:25618.575694322586
batch reward last col mean 0.0523366816341877 first col mean 0.09099845588207245 all mean 0.0594058595597744
0.2157546579837799 0.2157546728849411
rl training, epoch8, iter0, batch9/1133, batch loss:0.2157546728849411, Training time:25620.83315229416
batch reward last col mean 0.10050798952579498 first col mean 0.09865690022706985 all mean 0.0973614901304245
0.23193813860416412 0.23193813860416412
rl training, epoch8, iter0, batch10/1133, batch loss:0.23193813860416412, Training time:25622.94241309166
batch reward last col mean 0.08210403472185135 first col mean 0.09373699128627777 all mean 0.0864388719201088
0.25487494468688965 0.25487494468688965
rl training, epoch8, iter0, batch11/1133, batch loss:0.25487494468688965, Training time:25625.063625335693
batch reward last col mean 0.06785893440246582 first col mean 0.0786658301949501 all mean 0.07362286746501923
0.2528390884399414 0.2528391182422638
rl training, epoch8, iter0, batch12/1133, batch loss:0.2528391182422638, Training time:25627.59796690941
batch reward last col mean 0.07237009704113007 first col mean 0.08053280413150787 all mean 0.07870243489742279
0.22732703387737274 0.22732706367969513
rl training, epoch8, iter0, batch13/1133, batch loss:0.22732706367969513, Training time:25629.210449934006
batch reward last col mean 0.06635326147079468 first col mean 0.08866435289382935 all mean 0.07002346962690353
0.22461660206317902 0.22461660206317902
rl training, epoch8, iter0, batch14/1133, batch loss:0.22461660206317902, Training time:25631.514917373657
batch reward last col mean 0.05886334925889969 first col mean 0.0881732925772667 all mean 0.06408034265041351
0.1907951533794403 0.1907951533794403
rl training, epoch8, iter0, batch15/1133, batch loss:0.1907951533794403, Training time:25633.592054367065
batch reward last col mean 0.08249732106924057 first col mean 0.07949718832969666 all mean 0.08424610644578934
0.243859201669693 0.243859201669693
rl training, epoch8, iter0, batch16/1133, batch loss:0.243859201669693, Training time:25636.084935188293
batch reward last col mean 0.05977439880371094 first col mean 0.08857785165309906 all mean 0.0674324780702591
0.2644425630569458 0.2644425630569458
rl training, epoch8, iter0, batch17/1133, batch loss:0.2644425630569458, Training time:25638.930054187775
batch reward last col mean 0.11845001578330994 first col mean 0.08222080767154694 all mean 0.10825320333242416
0.2708604037761688 0.2708604037761688
rl training, epoch8, iter0, batch18/1133, batch loss:0.2708604037761688, Training time:25641.01144003868
batch reward last col mean 0.0729110985994339 first col mean 0.0907079353928566 all mean 0.07681282609701157
0.20505881309509277 0.20505881309509277
rl training, epoch8, iter0, batch19/1133, batch loss:0.20505881309509277, Training time:25642.78378725052
batch reward last col mean 0.11169618368148804 first col mean 0.08687354624271393 all mean 0.10671085864305496
0.23564903438091278 0.2356490194797516
rl training, epoch8, iter0, batch20/1133, batch loss:0.2356490194797516, Training time:25645.047309160233
batch reward last col mean 0.07545743137598038 first col mean 0.08938444405794144 all mean 0.07517445832490921
0.1993047595024109 0.1993047595024109
rl training, epoch8, iter0, batch21/1133, batch loss:0.1993047595024109, Training time:25647.37671971321
batch reward last col mean 0.09602659940719604 first col mean 0.08035962283611298 all mean 0.09333552420139313
0.2468872219324112 0.2468872219324112
rl training, epoch8, iter0, batch22/1133, batch loss:0.2468872219324112, Training time:25650.61986231804
batch reward last col mean 0.10714761912822723 first col mean 0.08599308878183365 all mean 0.10356912761926651
0.26521068811416626 0.26521068811416626
rl training, epoch8, iter0, batch23/1133, batch loss:0.26521068811416626, Training time:25653.115099668503
batch reward last col mean 0.06607756018638611 first col mean 0.09129909425973892 all mean 0.07129578292369843
0.23657263815402985 0.23657263815402985
rl training, epoch8, iter0, batch24/1133, batch loss:0.23657263815402985, Training time:25655.336058855057
batch reward last col mean 0.0863267332315445 first col mean 0.08787253499031067 all mean 0.08722395449876785
0.22571256756782532 0.22571256756782532
rl training, epoch8, iter0, batch25/1133, batch loss:0.22571256756782532, Training time:25657.37163209915
batch reward last col mean 0.0756228119134903 first col mean 0.08345426619052887 all mean 0.08049992471933365
0.2360536754131317 0.23605366051197052
rl training, epoch8, iter0, batch26/1133, batch loss:0.23605366051197052, Training time:25659.296369314194
batch reward last col mean 0.1068415567278862 first col mean 0.07217275351285934 all mean 0.1036062091588974
0.26237916946411133 0.26237916946411133
rl training, epoch8, iter0, batch27/1133, batch loss:0.26237916946411133, Training time:25662.51394033432
batch reward last col mean 0.06936166435480118 first col mean 0.08516374975442886 all mean 0.0692272037267685
0.2348765730857849 0.2348766028881073
rl training, epoch8, iter0, batch28/1133, batch loss:0.2348766028881073, Training time:25664.49925661087
batch reward last col mean 0.08900865912437439 first col mean 0.09217654168605804 all mean 0.09221048653125763
0.27214130759239197 0.27214130759239197
rl training, epoch8, iter0, batch29/1133, batch loss:0.27214130759239197, Training time:25666.32798242569
batch reward last col mean 0.06837376952171326 first col mean 0.08382809907197952 all mean 0.07184723764657974
0.24162454903125763 0.24162454903125763
rl training, epoch8, iter0, batch30/1133, batch loss:0.24162454903125763, Training time:25668.497745990753
batch reward last col mean 0.09047234058380127 first col mean 0.10601245611906052 all mean 0.09332107752561569
0.2471136897802353 0.2471136897802353
rl training, epoch8, iter0, batch31/1133, batch loss:0.2471136897802353, Training time:25670.346925020218
batch reward last col mean 0.0836748480796814 first col mean 0.0872756764292717 all mean 0.08550947904586792
0.24979299306869507 0.24979299306869507
rl training, epoch8, iter0, batch32/1133, batch loss:0.24979299306869507, Training time:25672.35723400116
batch reward last col mean 0.10741423070430756 first col mean 0.0812453031539917 all mean 0.1025073230266571
0.2510364055633545 0.2510363757610321
rl training, epoch8, iter0, batch33/1133, batch loss:0.2510363757610321, Training time:25674.372483491898
batch reward last col mean 0.07214891910552979 first col mean 0.12402262538671494 all mean 0.07745692133903503
0.24649670720100403 0.24649670720100403
rl training, epoch8, iter0, batch34/1133, batch loss:0.24649670720100403, Training time:25676.980600357056
batch reward last col mean 0.05205599218606949 first col mean 0.09796042740345001 all mean 0.060744743794202805
0.21506989002227783 0.21506987512111664
rl training, epoch8, iter0, batch35/1133, batch loss:0.21506987512111664, Training time:25679.915169239044
batch reward last col mean 0.08886142075061798 first col mean 0.08376426994800568 all mean 0.08949550241231918
0.23214814066886902 0.23214814066886902
rl training, epoch8, iter0, batch36/1133, batch loss:0.23214814066886902, Training time:25681.955900669098
batch reward last col mean 0.09770984947681427 first col mean 0.09299951791763306 all mean 0.09396000951528549
0.22893474996089935 0.22893474996089935
rl training, epoch8, iter0, batch37/1133, batch loss:0.22893474996089935, Training time:25685.023377418518
batch reward last col mean 0.1036798357963562 first col mean 0.09580501914024353 all mean 0.09768864512443542
0.27610960602760315 0.27610957622528076
rl training, epoch8, iter0, batch38/1133, batch loss:0.27610957622528076, Training time:25686.96808075905
batch reward last col mean 0.10460951924324036 first col mean 0.08797875791788101 all mean 0.10298162698745728
0.26008352637290955 0.26008352637290955
rl training, epoch8, iter0, batch39/1133, batch loss:0.26008352637290955, Training time:25688.72415471077
batch reward last col mean 0.1036868765950203 first col mean 0.09388361871242523 all mean 0.10292040556669235
0.3043493926525116 0.3043493926525116
rl training, epoch8, iter0, batch40/1133, batch loss:0.3043493926525116, Training time:25690.96032357216
batch reward last col mean 0.07950188219547272 first col mean 0.08379810303449631 all mean 0.08000980317592621
0.2483150213956833 0.2483150213956833
rl training, epoch8, iter0, batch41/1133, batch loss:0.2483150213956833, Training time:25692.450174570084
batch reward last col mean 0.08323711901903152 first col mean 0.10083311796188354 all mean 0.09144024550914764
0.2678963243961334 0.26789629459381104
rl training, epoch8, iter0, batch42/1133, batch loss:0.26789629459381104, Training time:25694.379597902298
batch reward last col mean 0.08063845336437225 first col mean 0.09264185279607773 all mean 0.08372907340526581
0.25435173511505127 0.25435173511505127
rl training, epoch8, iter0, batch43/1133, batch loss:0.25435173511505127, Training time:25696.33032631874
batch reward last col mean 0.0737907737493515 first col mean 0.11174166947603226 all mean 0.07981796562671661
0.23076292872428894 0.23076291382312775
rl training, epoch8, iter0, batch44/1133, batch loss:0.23076291382312775, Training time:25698.627974510193
batch reward last col mean 0.09062430262565613 first col mean 0.07974521070718765 all mean 0.09205536544322968
0.26335376501083374 0.26335376501083374
rl training, epoch8, iter0, batch45/1133, batch loss:0.26335376501083374, Training time:25701.075892686844
batch reward last col mean 0.10198815166950226 first col mean 0.09081561863422394 all mean 0.10053512454032898
0.24016758799552917 0.24016758799552917
rl training, epoch8, iter0, batch46/1133, batch loss:0.24016758799552917, Training time:25703.004062891006
batch reward last col mean 0.07878526300191879 first col mean 0.09884566068649292 all mean 0.07947775721549988
0.23755206167697906 0.23755206167697906
rl training, epoch8, iter0, batch47/1133, batch loss:0.23755206167697906, Training time:25705.083519935608
batch reward last col mean 0.09799978137016296 first col mean 0.1024743914604187 all mean 0.09663957357406616
0.25994551181793213 0.25994551181793213
rl training, epoch8, iter0, batch48/1133, batch loss:0.25994551181793213, Training time:25707.01622223854
batch reward last col mean 0.06964405626058578 first col mean 0.08113263547420502 all mean 0.07545098662376404
0.24005134403705597 0.24005134403705597
rl training, epoch8, iter0, batch49/1133, batch loss:0.24005134403705597, Training time:25710.100451231003
batch reward last col mean 0.0647953599691391 first col mean 0.11884298920631409 all mean 0.0743454322218895
0.2366013526916504 0.2366013526916504
rl training, epoch8, iter0, batch50/1133, batch loss:0.2366013526916504, Training time:25712.43791294098
batch reward last col mean 0.08327431231737137 first col mean 0.08939032256603241 all mean 0.08458394557237625
0.2434348165988922 0.2434348165988922
rl training, epoch8, iter0, batch51/1133, batch loss:0.2434348165988922, Training time:25714.533159971237
batch reward last col mean 0.08850722014904022 first col mean 0.10320568829774857 all mean 0.0957576334476471
0.2536022961139679 0.2536022961139679
rl training, epoch8, iter0, batch52/1133, batch loss:0.2536022961139679, Training time:25716.605927705765
batch reward last col mean 0.12025131285190582 first col mean 0.09173133224248886 all mean 0.10322342813014984
0.24486829340457916 0.24486829340457916
rl training, epoch8, iter0, batch53/1133, batch loss:0.24486829340457916, Training time:25718.20443058014
batch reward last col mean 0.09464916586875916 first col mean 0.06887883692979813 all mean 0.09630629420280457
0.23578079044818878 0.2357807755470276
rl training, epoch8, iter0, batch54/1133, batch loss:0.2357807755470276, Training time:25720.482748031616
batch reward last col mean 0.10263793170452118 first col mean 0.09334097057580948 all mean 0.09645801782608032
0.25299975275993347 0.25299975275993347
rl training, epoch8, iter0, batch55/1133, batch loss:0.25299975275993347, Training time:25722.281158685684
batch reward last col mean 0.10105033218860626 first col mean 0.07347714155912399 all mean 0.09581980109214783
0.25173211097717285 0.25173211097717285
rl training, epoch8, iter0, batch56/1133, batch loss:0.25173211097717285, Training time:25725.36935400963
batch reward last col mean 0.08566749840974808 first col mean 0.09924642741680145 all mean 0.08535254001617432
0.21665248274803162 0.21665246784687042
rl training, epoch8, iter0, batch57/1133, batch loss:0.21665246784687042, Training time:25727.007917642593
batch reward last col mean 0.08561428636312485 first col mean 0.07993733137845993 all mean 0.08660586178302765
0.2789413630962372 0.2789413630962372
rl training, epoch8, iter0, batch58/1133, batch loss:0.2789413630962372, Training time:25730.084220647812
batch reward last col mean 0.107340969145298 first col mean 0.10054699331521988 all mean 0.10149122029542923
0.29250478744506836 0.29250478744506836
rl training, epoch8, iter0, batch59/1133, batch loss:0.29250478744506836, Training time:25732.060012817383
batch reward last col mean 0.07708638906478882 first col mean 0.07328882813453674 all mean 0.0808790773153305
0.2249322384595871 0.2249322384595871
rl training, epoch8, iter0, batch60/1133, batch loss:0.2249322384595871, Training time:25734.088099718094
batch reward last col mean 0.09940147399902344 first col mean 0.09732240438461304 all mean 0.10033096373081207
0.24620623886585236 0.24620623886585236
rl training, epoch8, iter0, batch61/1133, batch loss:0.24620623886585236, Training time:25735.896220445633
batch reward last col mean 0.08822044730186462 first col mean 0.10306694358587265 all mean 0.08913026750087738
0.24837671220302582 0.24837671220302582
rl training, epoch8, iter0, batch62/1133, batch loss:0.24837671220302582, Training time:25737.801043510437
batch reward last col mean 0.08912520110607147 first col mean 0.0845576673746109 all mean 0.0889493077993393
0.28401899337768555 0.28401899337768555
rl training, epoch8, iter0, batch63/1133, batch loss:0.28401899337768555, Training time:25739.89235973358
batch reward last col mean 0.10890556871891022 first col mean 0.09048476815223694 all mean 0.10746759921312332
0.2797599136829376 0.2797599136829376
rl training, epoch8, iter0, batch64/1133, batch loss:0.2797599136829376, Training time:25741.955409526825
batch reward last col mean 0.10547605901956558 first col mean 0.11197839677333832 all mean 0.10522465407848358
0.2761426270008087 0.2761426270008087
rl training, epoch8, iter0, batch65/1133, batch loss:0.2761426270008087, Training time:25743.929498910904
batch reward last col mean 0.09006847441196442 first col mean 0.08369439095258713 all mean 0.09112492203712463
0.2442052960395813 0.2442052811384201
rl training, epoch8, iter0, batch66/1133, batch loss:0.2442052811384201, Training time:25745.550009012222
batch reward last col mean 0.10437759757041931 first col mean 0.10205744206905365 all mean 0.10245833545923233
0.2618577182292938 0.2618577182292938
rl training, epoch8, iter0, batch67/1133, batch loss:0.2618577182292938, Training time:25747.876930475235
batch reward last col mean 0.10051341354846954 first col mean 0.079993337392807 all mean 0.09940246492624283
0.24807550013065338 0.24807550013065338
rl training, epoch8, iter0, batch68/1133, batch loss:0.24807550013065338, Training time:25749.78426837921
batch reward last col mean 0.0845019519329071 first col mean 0.09061980992555618 all mean 0.08172960579395294
0.23564665019512177 0.23564665019512177
rl training, epoch8, iter0, batch69/1133, batch loss:0.23564665019512177, Training time:25751.5838162899
batch reward last col mean 0.08488087356090546 first col mean 0.10402721166610718 all mean 0.08583200722932816
0.24512913823127747 0.24512913823127747
rl training, epoch8, iter0, batch70/1133, batch loss:0.24512913823127747, Training time:25753.43979024887
batch reward last col mean 0.06776422262191772 first col mean 0.09879159927368164 all mean 0.0773678570985794
0.2098701000213623 0.2098701000213623
rl training, epoch8, iter0, batch71/1133, batch loss:0.2098701000213623, Training time:25755.1898021698
batch reward last col mean 0.09981323778629303 first col mean 0.09810672700405121 all mean 0.09636297076940536
0.2310551255941391 0.2310551255941391
rl training, epoch8, iter0, batch72/1133, batch loss:0.2310551255941391, Training time:25756.76244020462
batch reward last col mean 0.09948435425758362 first col mean 0.07521877437829971 all mean 0.09559310227632523
0.24713890254497528 0.24713890254497528
rl training, epoch8, iter0, batch73/1133, batch loss:0.24713890254497528, Training time:25758.53861308098
batch reward last col mean 0.0811651200056076 first col mean 0.08409769088029861 all mean 0.08327534049749374
0.22705619037151337 0.22705619037151337
rl training, epoch8, iter0, batch74/1133, batch loss:0.22705619037151337, Training time:25760.52858376503
batch reward last col mean 0.07673278450965881 first col mean 0.09904135763645172 all mean 0.08445873111486435
0.2703818082809448 0.2703818082809448
rl training, epoch8, iter0, batch75/1133, batch loss:0.2703818082809448, Training time:25762.322704553604
batch reward last col mean 0.08255493640899658 first col mean 0.11371983587741852 all mean 0.08393509685993195
0.2324662208557129 0.2324662208557129
rl training, epoch8, iter0, batch76/1133, batch loss:0.2324662208557129, Training time:25764.191785812378
batch reward last col mean 0.11068346351385117 first col mean 0.09377489984035492 all mean 0.10841836780309677
0.2784321904182434 0.2784321904182434
rl training, epoch8, iter0, batch77/1133, batch loss:0.2784321904182434, Training time:25766.687485933304
batch reward last col mean 0.07782455533742905 first col mean 0.10195207595825195 all mean 0.08094590157270432
0.24589039385318756 0.24589040875434875
rl training, epoch8, iter0, batch78/1133, batch loss:0.24589040875434875, Training time:25768.722972154617
batch reward last col mean 0.06959665566682816 first col mean 0.10264363139867783 all mean 0.0749446228146553
0.24300825595855713 0.24300822615623474
rl training, epoch8, iter0, batch79/1133, batch loss:0.24300822615623474, Training time:25772.561317920685
batch reward last col mean 0.07303357124328613 first col mean 0.08407151699066162 all mean 0.07615349441766739
0.23111018538475037 0.23111018538475037
rl training, epoch8, iter0, batch80/1133, batch loss:0.23111018538475037, Training time:25776.153583288193
batch reward last col mean 0.09648948907852173 first col mean 0.0983065515756607 all mean 0.09976263344287872
0.2584407925605774 0.258440762758255
rl training, epoch8, iter0, batch81/1133, batch loss:0.258440762758255, Training time:25779.75056362152
batch reward last col mean 0.06766849756240845 first col mean 0.07870818674564362 all mean 0.07154672592878342
0.23145897686481476 0.23145897686481476
rl training, epoch8, iter0, batch82/1133, batch loss:0.23145897686481476, Training time:25782.92456650734
batch reward last col mean 0.06288351118564606 first col mean 0.09024996310472488 all mean 0.07024342566728592
0.23756945133209229 0.2375694364309311
rl training, epoch8, iter0, batch83/1133, batch loss:0.2375694364309311, Training time:25786.771555900574
batch reward last col mean 0.058369480073451996 first col mean 0.09647144377231598 all mean 0.06667065620422363
0.21017207205295563 0.21017207205295563
rl training, epoch8, iter0, batch84/1133, batch loss:0.21017207205295563, Training time:25790.815655231476
batch reward last col mean 0.06961217522621155 first col mean 0.07868748903274536 all mean 0.07691686600446701
0.2529326379299164 0.2529326379299164
rl training, epoch8, iter0, batch85/1133, batch loss:0.2529326379299164, Training time:25793.637897729874
batch reward last col mean 0.10808704793453217 first col mean 0.10775651037693024 all mean 0.10221733897924423
0.23888519406318665 0.23888519406318665
rl training, epoch8, iter0, batch86/1133, batch loss:0.23888519406318665, Training time:25796.487460136414
batch reward last col mean 0.0759621411561966 first col mean 0.09174242615699768 all mean 0.07898761332035065
0.2233760952949524 0.2233760952949524
rl training, epoch8, iter0, batch87/1133, batch loss:0.2233760952949524, Training time:25799.346303462982
batch reward last col mean 0.07334265112876892 first col mean 0.0847792997956276 all mean 0.07721491903066635
0.2364085465669632 0.2364085465669632
rl training, epoch8, iter0, batch88/1133, batch loss:0.2364085465669632, Training time:25803.400166988373
batch reward last col mean 0.08306220173835754 first col mean 0.08495333045721054 all mean 0.08553312718868256
0.24043485522270203 0.24043485522270203
rl training, epoch8, iter0, batch89/1133, batch loss:0.24043485522270203, Training time:25806.366935014725
batch reward last col mean 0.08755095303058624 first col mean 0.0956335961818695 all mean 0.08559615164995193
0.261279821395874 0.261279821395874
rl training, epoch8, iter0, batch90/1133, batch loss:0.261279821395874, Training time:25809.286316394806
batch reward last col mean 0.1154940202832222 first col mean 0.11886899173259735 all mean 0.1050707995891571
0.3016228973865509 0.3016228973865509
rl training, epoch8, iter0, batch91/1133, batch loss:0.3016228973865509, Training time:25812.416831970215
batch reward last col mean 0.09258349239826202 first col mean 0.09890952706336975 all mean 0.09508514404296875
0.31108376383781433 0.31108376383781433
rl training, epoch8, iter0, batch92/1133, batch loss:0.31108376383781433, Training time:25815.279071331024
batch reward last col mean 0.069247767329216 first col mean 0.10201980173587799 all mean 0.07585371285676956
0.1993563026189804 0.1993563026189804
rl training, epoch8, iter0, batch93/1133, batch loss:0.1993563026189804, Training time:25818.338923454285
batch reward last col mean 0.07267983257770538 first col mean 0.09376687556505203 all mean 0.07480212301015854
0.23212796449661255 0.23212796449661255
rl training, epoch8, iter0, batch94/1133, batch loss:0.23212796449661255, Training time:25823.571855068207
batch reward last col mean 0.08557340502738953 first col mean 0.07996536791324615 all mean 0.08709356933832169
0.24087366461753845 0.24087366461753845
rl training, epoch8, iter0, batch95/1133, batch loss:0.24087366461753845, Training time:25826.56280350685
batch reward last col mean 0.0933476984500885 first col mean 0.10468597710132599 all mean 0.09701145440340042
0.284621924161911 0.284621924161911
rl training, epoch8, iter0, batch96/1133, batch loss:0.284621924161911, Training time:25829.450803995132
batch reward last col mean 0.14332111179828644 first col mean 0.09746764600276947 all mean 0.12455501407384872
0.2984794080257416 0.2984793782234192
rl training, epoch8, iter0, batch97/1133, batch loss:0.2984793782234192, Training time:25832.23695588112
batch reward last col mean 0.12332411110401154 first col mean 0.07882329076528549 all mean 0.11166035383939743
0.26714053750038147 0.26714053750038147
rl training, epoch8, iter0, batch98/1133, batch loss:0.26714053750038147, Training time:25835.787140607834
batch reward last col mean 0.06923803687095642 first col mean 0.09764470160007477 all mean 0.07419758290052414
0.23814401030540466 0.23814401030540466
rl training, epoch8, iter0, batch99/1133, batch loss:0.23814401030540466, Training time:25838.625752687454
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.45182452263394396 Time: 243.95870733261108 s
loss of true 0.19332849413209116 loss of gen 0.1642852746482876 loss of other 0.09421075472323798 first score 0.06940240412950516
batch reward last col mean 0.12028373032808304 first col mean 0.09711771458387375 all mean 0.11809186637401581
0.2790902256965637 0.2790902256965637
rl training, epoch8, iter0, batch100/1133, batch loss:0.2790902256965637, Training time:26084.80488705635
batch reward last col mean 0.07895118743181229 first col mean 0.11046069860458374 all mean 0.0812026709318161
0.2213028371334076 0.2213028371334076
rl training, epoch8, iter0, batch101/1133, batch loss:0.2213028371334076, Training time:26086.793437719345
batch reward last col mean 0.08008468151092529 first col mean 0.0935869961977005 all mean 0.0836222842335701
0.2411322146654129 0.2411322146654129
rl training, epoch8, iter0, batch102/1133, batch loss:0.2411322146654129, Training time:26088.88530731201
batch reward last col mean 0.11696445941925049 first col mean 0.10807303339242935 all mean 0.11272403597831726
0.27920565009117126 0.27920565009117126
rl training, epoch8, iter0, batch103/1133, batch loss:0.27920565009117126, Training time:26091.86882543564
batch reward last col mean 0.0995212122797966 first col mean 0.10831502825021744 all mean 0.09859778732061386
0.28625378012657166 0.28625378012657166
rl training, epoch8, iter0, batch104/1133, batch loss:0.28625378012657166, Training time:26093.22316479683
batch reward last col mean 0.09445121884346008 first col mean 0.10225395113229752 all mean 0.09508202224969864
0.249781996011734 0.24978198111057281
rl training, epoch8, iter0, batch105/1133, batch loss:0.24978198111057281, Training time:26095.070103406906
batch reward last col mean 0.12243513762950897 first col mean 0.1038813591003418 all mean 0.11412173509597778
0.3241291046142578 0.3241291046142578
rl training, epoch8, iter0, batch106/1133, batch loss:0.3241291046142578, Training time:26096.729483127594
batch reward last col mean 0.11129356175661087 first col mean 0.1008501648902893 all mean 0.10367085039615631
0.2551538646221161 0.2551538646221161
rl training, epoch8, iter0, batch107/1133, batch loss:0.2551538646221161, Training time:26098.620109319687
batch reward last col mean 0.10118387639522552 first col mean 0.10867027193307877 all mean 0.09789230674505234
0.26452869176864624 0.26452869176864624
rl training, epoch8, iter0, batch108/1133, batch loss:0.26452869176864624, Training time:26100.318871974945
batch reward last col mean 0.10672805458307266 first col mean 0.12081390619277954 all mean 0.10825639963150024
0.27755382657051086 0.27755385637283325
rl training, epoch8, iter0, batch109/1133, batch loss:0.27755385637283325, Training time:26103.298191070557
batch reward last col mean 0.09492389857769012 first col mean 0.10670462250709534 all mean 0.0989297404885292
0.2467155158519745 0.2467155158519745
rl training, epoch8, iter0, batch110/1133, batch loss:0.2467155158519745, Training time:26105.225703001022
batch reward last col mean 0.0977393388748169 first col mean 0.11205965280532837 all mean 0.09773197770118713
0.2639288008213043 0.2639288008213043
rl training, epoch8, iter0, batch111/1133, batch loss:0.2639288008213043, Training time:26106.830134391785
batch reward last col mean 0.10325078666210175 first col mean 0.09416912496089935 all mean 0.1019262969493866
0.3008090853691101 0.3008090853691101
rl training, epoch8, iter0, batch112/1133, batch loss:0.3008090853691101, Training time:26108.816568613052
batch reward last col mean 0.09771940857172012 first col mean 0.09745293855667114 all mean 0.09925995022058487
0.2856600284576416 0.2856600284576416
rl training, epoch8, iter0, batch113/1133, batch loss:0.2856600284576416, Training time:26110.789543628693
batch reward last col mean 0.14655998349189758 first col mean 0.09549006074666977 all mean 0.1274326890707016
0.31379759311676025 0.31379759311676025
rl training, epoch8, iter0, batch114/1133, batch loss:0.31379759311676025, Training time:26112.351572990417
batch reward last col mean 0.08169601857662201 first col mean 0.10950252413749695 all mean 0.08566205203533173
0.2448136955499649 0.2448136955499649
rl training, epoch8, iter0, batch115/1133, batch loss:0.2448136955499649, Training time:26113.878494024277
batch reward last col mean 0.07459792494773865 first col mean 0.10501454770565033 all mean 0.08475876599550247
0.24241484701633453 0.24241484701633453
rl training, epoch8, iter0, batch116/1133, batch loss:0.24241484701633453, Training time:26115.872619390488
batch reward last col mean 0.0927453339099884 first col mean 0.09097915887832642 all mean 0.09099795669317245
0.2649131417274475 0.2649131417274475
rl training, epoch8, iter0, batch117/1133, batch loss:0.2649131417274475, Training time:26117.918888807297
batch reward last col mean 0.09225467592477798 first col mean 0.10469596832990646 all mean 0.0972226932644844
0.248538538813591 0.2485385239124298
rl training, epoch8, iter0, batch118/1133, batch loss:0.2485385239124298, Training time:26120.176417589188
batch reward last col mean 0.10987105220556259 first col mean 0.09361261129379272 all mean 0.10632462799549103
0.2714804410934448 0.2714804410934448
rl training, epoch8, iter0, batch119/1133, batch loss:0.2714804410934448, Training time:26122.094421625137
batch reward last col mean 0.0753195658326149 first col mean 0.09729278087615967 all mean 0.08222124725580215
0.2433367520570755 0.2433367520570755
rl training, epoch8, iter0, batch120/1133, batch loss:0.2433367520570755, Training time:26123.918751955032
batch reward last col mean 0.12636110186576843 first col mean 0.11319013684988022 all mean 0.12618322670459747
0.3008790910243988 0.3008790910243988
rl training, epoch8, iter0, batch121/1133, batch loss:0.3008790910243988, Training time:26125.74968314171
batch reward last col mean 0.1081048846244812 first col mean 0.0887489914894104 all mean 0.11119823157787323
0.3339047133922577 0.3339047133922577
rl training, epoch8, iter0, batch122/1133, batch loss:0.3339047133922577, Training time:26128.489423036575
batch reward last col mean 0.0893087238073349 first col mean 0.10258335620164871 all mean 0.09343240410089493
0.28245633840560913 0.28245633840560913
rl training, epoch8, iter0, batch123/1133, batch loss:0.28245633840560913, Training time:26130.88856458664
batch reward last col mean 0.09318297356367111 first col mean 0.10245134681463242 all mean 0.09756499528884888
0.27496474981307983 0.27496474981307983
rl training, epoch8, iter0, batch124/1133, batch loss:0.27496474981307983, Training time:26133.591819524765
batch reward last col mean 0.10019928216934204 first col mean 0.10230251401662827 all mean 0.09973389655351639
0.2728559970855713 0.2728559970855713
rl training, epoch8, iter0, batch125/1133, batch loss:0.2728559970855713, Training time:26135.497015476227
batch reward last col mean 0.09317600727081299 first col mean 0.10306811332702637 all mean 0.09235779196023941
0.25601062178611755 0.25601062178611755
rl training, epoch8, iter0, batch126/1133, batch loss:0.25601062178611755, Training time:26137.489700078964
batch reward last col mean 0.09363850206136703 first col mean 0.08403261005878448 all mean 0.09624974429607391
0.2460324764251709 0.24603243172168732
rl training, epoch8, iter0, batch127/1133, batch loss:0.24603243172168732, Training time:26139.41249370575
batch reward last col mean 0.06585369259119034 first col mean 0.10176682472229004 all mean 0.07377446442842484
0.25655803084373474 0.25655803084373474
rl training, epoch8, iter0, batch128/1133, batch loss:0.25655803084373474, Training time:26141.48508954048
batch reward last col mean 0.06398453563451767 first col mean 0.1019560843706131 all mean 0.07378680258989334
0.26126861572265625 0.26126861572265625
rl training, epoch8, iter0, batch129/1133, batch loss:0.26126861572265625, Training time:26143.344040632248
batch reward last col mean 0.10627354681491852 first col mean 0.10869664698839188 all mean 0.10006600618362427
0.26231321692466736 0.26231321692466736
rl training, epoch8, iter0, batch130/1133, batch loss:0.26231321692466736, Training time:26145.87680363655
batch reward last col mean 0.08136570453643799 first col mean 0.095331110060215 all mean 0.08626329898834229
0.24075424671173096 0.24075423181056976
rl training, epoch8, iter0, batch131/1133, batch loss:0.24075423181056976, Training time:26148.38307619095
batch reward last col mean 0.0730707123875618 first col mean 0.0907139852643013 all mean 0.07782138884067535
0.2285909652709961 0.2285909652709961
rl training, epoch8, iter0, batch132/1133, batch loss:0.2285909652709961, Training time:26150.66654419899
batch reward last col mean 0.06530462950468063 first col mean 0.09344339370727539 all mean 0.07739099860191345
0.2673729360103607 0.2673729360103607
rl training, epoch8, iter0, batch133/1133, batch loss:0.2673729360103607, Training time:26152.504239797592
batch reward last col mean 0.09585469961166382 first col mean 0.11514165997505188 all mean 0.10082390904426575
0.2913375198841095 0.2913375198841095
rl training, epoch8, iter0, batch134/1133, batch loss:0.2913375198841095, Training time:26154.246391057968
batch reward last col mean 0.1114056184887886 first col mean 0.09374454617500305 all mean 0.10773912072181702
0.290559858083725 0.290559858083725
rl training, epoch8, iter0, batch135/1133, batch loss:0.290559858083725, Training time:26156.593822956085
batch reward last col mean 0.083073690533638 first col mean 0.08908819407224655 all mean 0.08996324241161346
0.25111857056617737 0.25111857056617737
rl training, epoch8, iter0, batch136/1133, batch loss:0.25111857056617737, Training time:26158.88199853897
batch reward last col mean 0.10340825468301773 first col mean 0.09294427186250687 all mean 0.09906256198883057
0.24225831031799316 0.24225829541683197
rl training, epoch8, iter0, batch137/1133, batch loss:0.24225829541683197, Training time:26160.50727748871
batch reward last col mean 0.09413206577301025 first col mean 0.09778347611427307 all mean 0.09065442532300949
0.28313958644866943 0.2831396162509918
rl training, epoch8, iter0, batch138/1133, batch loss:0.2831396162509918, Training time:26162.367950439453
batch reward last col mean 0.07764236629009247 first col mean 0.09813196212053299 all mean 0.08835584670305252
0.2880897521972656 0.2880897521972656
rl training, epoch8, iter0, batch139/1133, batch loss:0.2880897521972656, Training time:26164.03920006752
batch reward last col mean 0.08359944820404053 first col mean 0.1071942001581192 all mean 0.08804287016391754
0.23153568804264069 0.23153568804264069
rl training, epoch8, iter0, batch140/1133, batch loss:0.23153568804264069, Training time:26165.78950405121
batch reward last col mean 0.09692081063985825 first col mean 0.1151510626077652 all mean 0.09612921625375748
0.2612839639186859 0.2612839639186859
rl training, epoch8, iter0, batch141/1133, batch loss:0.2612839639186859, Training time:26168.75244307518
batch reward last col mean 0.10301031917333603 first col mean 0.09740389883518219 all mean 0.10254577547311783
0.2632690966129303 0.2632690966129303
rl training, epoch8, iter0, batch142/1133, batch loss:0.2632690966129303, Training time:26171.215126991272
batch reward last col mean 0.07885147631168365 first col mean 0.10175051540136337 all mean 0.0789104774594307
0.2390359342098236 0.2390359342098236
rl training, epoch8, iter0, batch143/1133, batch loss:0.2390359342098236, Training time:26173.45897912979
batch reward last col mean 0.10892165452241898 first col mean 0.10489015281200409 all mean 0.1062563881278038
0.2851788401603699 0.2851788401603699
rl training, epoch8, iter0, batch144/1133, batch loss:0.2851788401603699, Training time:26176.191680192947
batch reward last col mean 0.07987206429243088 first col mean 0.09808776527643204 all mean 0.08211782574653625
0.232838436961174 0.23283840715885162
rl training, epoch8, iter0, batch145/1133, batch loss:0.23283840715885162, Training time:26177.804293632507
batch reward last col mean 0.08155906945466995 first col mean 0.08981314301490784 all mean 0.08579202741384506
0.26024681329727173 0.26024681329727173
rl training, epoch8, iter0, batch146/1133, batch loss:0.26024681329727173, Training time:26179.49830508232
batch reward last col mean 0.07363849878311157 first col mean 0.10938937962055206 all mean 0.08613276481628418
0.2839776277542114 0.2839776277542114
rl training, epoch8, iter0, batch147/1133, batch loss:0.2839776277542114, Training time:26181.644569158554
batch reward last col mean 0.10048884153366089 first col mean 0.10221223533153534 all mean 0.1017281711101532
0.27163878083229065 0.27163878083229065
rl training, epoch8, iter0, batch148/1133, batch loss:0.27163878083229065, Training time:26184.146326303482
batch reward last col mean 0.10783891379833221 first col mean 0.112720787525177 all mean 0.10699682682752609
0.2687866687774658 0.2687866687774658
rl training, epoch8, iter0, batch149/1133, batch loss:0.2687866687774658, Training time:26186.191320180893
batch reward last col mean 0.12441545724868774 first col mean 0.10522251576185226 all mean 0.11732202023267746
0.2944890558719635 0.2944890558719635
rl training, epoch8, iter0, batch150/1133, batch loss:0.2944890558719635, Training time:26187.890123844147
batch reward last col mean 0.09254687279462814 first col mean 0.09838929772377014 all mean 0.09671921283006668
0.2462330460548401 0.2462330460548401
rl training, epoch8, iter0, batch151/1133, batch loss:0.2462330460548401, Training time:26189.54168510437
batch reward last col mean 0.0801483541727066 first col mean 0.10592282563447952 all mean 0.08704061806201935
0.27013465762138367 0.27013465762138367
rl training, epoch8, iter0, batch152/1133, batch loss:0.27013465762138367, Training time:26191.477182388306
batch reward last col mean 0.075617715716362 first col mean 0.10289916396141052 all mean 0.0848316103219986
0.24215368926525116 0.24215370416641235
rl training, epoch8, iter0, batch153/1133, batch loss:0.24215370416641235, Training time:26193.482275247574
batch reward last col mean 0.09169188141822815 first col mean 0.1073993593454361 all mean 0.09101755172014236
0.256089985370636 0.256089985370636
rl training, epoch8, iter0, batch154/1133, batch loss:0.256089985370636, Training time:26195.19508910179
batch reward last col mean 0.11906580626964569 first col mean 0.1029738187789917 all mean 0.11586340516805649
0.29421836137771606 0.29421836137771606
rl training, epoch8, iter0, batch155/1133, batch loss:0.29421836137771606, Training time:26197.386785268784
batch reward last col mean 0.09264957904815674 first col mean 0.11176995187997818 all mean 0.09447198361158371
0.30466145277023315 0.30466145277023315
rl training, epoch8, iter0, batch156/1133, batch loss:0.30466145277023315, Training time:26199.954629421234
batch reward last col mean 0.11216847598552704 first col mean 0.10666011273860931 all mean 0.10133321583271027
0.2810654044151306 0.281065434217453
rl training, epoch8, iter0, batch157/1133, batch loss:0.281065434217453, Training time:26201.946887016296
batch reward last col mean 0.08814411610364914 first col mean 0.10960692912340164 all mean 0.09054300934076309
0.26967334747314453 0.26967334747314453
rl training, epoch8, iter0, batch158/1133, batch loss:0.26967334747314453, Training time:26203.58274269104
batch reward last col mean 0.09585410356521606 first col mean 0.10920555144548416 all mean 0.0925532877445221
0.25084537267684937 0.25084537267684937
rl training, epoch8, iter0, batch159/1133, batch loss:0.25084537267684937, Training time:26205.406594991684
batch reward last col mean 0.13099034130573273 first col mean 0.09385079145431519 all mean 0.12663932144641876
0.28655490279197693 0.28655490279197693
rl training, epoch8, iter0, batch160/1133, batch loss:0.28655490279197693, Training time:26207.483647823334
batch reward last col mean 0.10839088261127472 first col mean 0.10946724563837051 all mean 0.10627605020999908
0.2613030970096588 0.2613031268119812
rl training, epoch8, iter0, batch161/1133, batch loss:0.2613031268119812, Training time:26209.128957509995
batch reward last col mean 0.08936804533004761 first col mean 0.09122344106435776 all mean 0.08889492601156235
0.23763109743595123 0.23763109743595123
rl training, epoch8, iter0, batch162/1133, batch loss:0.23763109743595123, Training time:26211.557711839676
batch reward last col mean 0.08402549475431442 first col mean 0.09103348106145859 all mean 0.1009129211306572
0.30754727125167847 0.30754727125167847
rl training, epoch8, iter0, batch163/1133, batch loss:0.30754727125167847, Training time:26212.97863316536
batch reward last col mean 0.083140529692173 first col mean 0.10875625908374786 all mean 0.09148912131786346
0.24913319945335388 0.24913322925567627
rl training, epoch8, iter0, batch164/1133, batch loss:0.24913322925567627, Training time:26214.634103298187
batch reward last col mean 0.0722000002861023 first col mean 0.09595857560634613 all mean 0.07965255528688431
0.24049726128578186 0.24049726128578186
rl training, epoch8, iter0, batch165/1133, batch loss:0.24049726128578186, Training time:26216.195388793945
batch reward last col mean 0.10717083513736725 first col mean 0.10352931171655655 all mean 0.10586651414632797
0.27959194779396057 0.27959194779396057
rl training, epoch8, iter0, batch166/1133, batch loss:0.27959194779396057, Training time:26217.699788570404
batch reward last col mean 0.07690157741308212 first col mean 0.09932370483875275 all mean 0.0834035649895668
0.25441262125968933 0.25441262125968933
rl training, epoch8, iter0, batch167/1133, batch loss:0.25441262125968933, Training time:26219.987644195557
batch reward last col mean 0.0870145857334137 first col mean 0.11096645146608353 all mean 0.09176135808229446
0.27947017550468445 0.27947017550468445
rl training, epoch8, iter0, batch168/1133, batch loss:0.27947017550468445, Training time:26221.88052225113
batch reward last col mean 0.09600706398487091 first col mean 0.10914885997772217 all mean 0.10102414339780807
0.28806477785110474 0.28806477785110474
rl training, epoch8, iter0, batch169/1133, batch loss:0.28806477785110474, Training time:26224.24534034729
batch reward last col mean 0.09524644166231155 first col mean 0.09138539433479309 all mean 0.09987114369869232
0.2753615379333496 0.2753615379333496
rl training, epoch8, iter0, batch170/1133, batch loss:0.2753615379333496, Training time:26226.09187054634
batch reward last col mean 0.12084157764911652 first col mean 0.09652779996395111 all mean 0.11240077763795853
0.2562694847583771 0.2562694847583771
rl training, epoch8, iter0, batch171/1133, batch loss:0.2562694847583771, Training time:26227.757816791534
batch reward last col mean 0.10109873116016388 first col mean 0.11280779540538788 all mean 0.10186843574047089
0.25325635075569153 0.25325635075569153
rl training, epoch8, iter0, batch172/1133, batch loss:0.25325635075569153, Training time:26229.931703805923
batch reward last col mean 0.11111068725585938 first col mean 0.10465556383132935 all mean 0.11087443679571152
0.30717039108276367 0.30717039108276367
rl training, epoch8, iter0, batch173/1133, batch loss:0.30717039108276367, Training time:26231.774053812027
batch reward last col mean 0.09108622372150421 first col mean 0.08881737291812897 all mean 0.08938097953796387
0.24699755012989044 0.24699755012989044
rl training, epoch8, iter0, batch174/1133, batch loss:0.24699755012989044, Training time:26233.7837805748
batch reward last col mean 0.11978955566883087 first col mean 0.09541599452495575 all mean 0.1157475933432579
0.29617998003959656 0.29617998003959656
rl training, epoch8, iter0, batch175/1133, batch loss:0.29617998003959656, Training time:26235.57927250862
batch reward last col mean 0.10277889668941498 first col mean 0.08904283493757248 all mean 0.09991554170846939
0.25031962990760803 0.25031962990760803
rl training, epoch8, iter0, batch176/1133, batch loss:0.25031962990760803, Training time:26237.222720623016
batch reward last col mean 0.07780720293521881 first col mean 0.11776727437973022 all mean 0.08664608746767044
0.2782730758190155 0.2782730758190155
rl training, epoch8, iter0, batch177/1133, batch loss:0.2782730758190155, Training time:26239.04749727249
batch reward last col mean 0.11515134572982788 first col mean 0.11603280156850815 all mean 0.10937957465648651
0.2934207320213318 0.2934207022190094
rl training, epoch8, iter0, batch178/1133, batch loss:0.2934207022190094, Training time:26240.611201286316
batch reward last col mean 0.12053012102842331 first col mean 0.11064676940441132 all mean 0.11337728798389435
0.29575541615486145 0.29575544595718384
rl training, epoch8, iter0, batch179/1133, batch loss:0.29575544595718384, Training time:26242.93015575409
batch reward last col mean 0.06941384077072144 first col mean 0.10981898009777069 all mean 0.0792681872844696
0.24235430359840393 0.24235430359840393
rl training, epoch8, iter0, batch180/1133, batch loss:0.24235430359840393, Training time:26245.254826068878
batch reward last col mean 0.08281515538692474 first col mean 0.11707448959350586 all mean 0.09245362132787704
0.3019237816333771 0.3019237816333771
rl training, epoch8, iter0, batch181/1133, batch loss:0.3019237816333771, Training time:26247.07230782509
batch reward last col mean 0.09082798659801483 first col mean 0.1109815388917923 all mean 0.0874003991484642
0.2601774334907532 0.2601774334907532
rl training, epoch8, iter0, batch182/1133, batch loss:0.2601774334907532, Training time:26249.283973932266
batch reward last col mean 0.07980919629335403 first col mean 0.11631888151168823 all mean 0.0896662250161171
0.27665776014328003 0.27665776014328003
rl training, epoch8, iter0, batch183/1133, batch loss:0.27665776014328003, Training time:26250.90428853035
batch reward last col mean 0.09082411229610443 first col mean 0.09403408318758011 all mean 0.09181227535009384
0.28904226422309875 0.28904226422309875
rl training, epoch8, iter0, batch184/1133, batch loss:0.28904226422309875, Training time:26254.283299207687
batch reward last col mean 0.06577984243631363 first col mean 0.11336532235145569 all mean 0.07297033071517944
0.22716939449310303 0.22716939449310303
rl training, epoch8, iter0, batch185/1133, batch loss:0.22716939449310303, Training time:26256.817616462708
batch reward last col mean 0.12362165749073029 first col mean 0.10539619624614716 all mean 0.1219659075140953
0.26222267746925354 0.26222267746925354
rl training, epoch8, iter0, batch186/1133, batch loss:0.26222267746925354, Training time:26258.7786154747
batch reward last col mean 0.0662074163556099 first col mean 0.0965486541390419 all mean 0.07206971198320389
0.22963058948516846 0.22963058948516846
rl training, epoch8, iter0, batch187/1133, batch loss:0.22963058948516846, Training time:26260.872095823288
batch reward last col mean 0.11677029728889465 first col mean 0.12534785270690918 all mean 0.11607406288385391
0.2868134081363678 0.2868134081363678
rl training, epoch8, iter0, batch188/1133, batch loss:0.2868134081363678, Training time:26263.003311157227
batch reward last col mean 0.11471370607614517 first col mean 0.10219088941812515 all mean 0.11169206351041794
0.27708670496940613 0.27708670496940613
rl training, epoch8, iter0, batch189/1133, batch loss:0.27708670496940613, Training time:26264.625732421875
batch reward last col mean 0.10703939944505692 first col mean 0.09717528522014618 all mean 0.10282575339078903
0.24100831151008606 0.24100831151008606
rl training, epoch8, iter0, batch190/1133, batch loss:0.24100831151008606, Training time:26267.429541110992
batch reward last col mean 0.1161329597234726 first col mean 0.09076154232025146 all mean 0.1136913076043129
0.24853515625 0.24853515625
rl training, epoch8, iter0, batch191/1133, batch loss:0.24853515625, Training time:26269.674289941788
batch reward last col mean 0.1098131388425827 first col mean 0.10942848026752472 all mean 0.1060653105378151
0.304916650056839 0.304916650056839
rl training, epoch8, iter0, batch192/1133, batch loss:0.304916650056839, Training time:26271.495119333267
batch reward last col mean 0.10525970906019211 first col mean 0.10080979764461517 all mean 0.10049974918365479
0.26692700386047363 0.26692700386047363
rl training, epoch8, iter0, batch193/1133, batch loss:0.26692700386047363, Training time:26273.531844377518
batch reward last col mean 0.10773211717605591 first col mean 0.10168397426605225 all mean 0.10436015576124191
0.29478180408477783 0.29478180408477783
rl training, epoch8, iter0, batch194/1133, batch loss:0.29478180408477783, Training time:26275.262783288956
batch reward last col mean 0.07205688208341599 first col mean 0.07568265497684479 all mean 0.07108817249536514
0.2136370837688446 0.2136370837688446
rl training, epoch8, iter0, batch195/1133, batch loss:0.2136370837688446, Training time:26276.94209432602
batch reward last col mean 0.08312050998210907 first col mean 0.10853279381990433 all mean 0.08420667797327042
0.2775694727897644 0.2775694727897644
rl training, epoch8, iter0, batch196/1133, batch loss:0.2775694727897644, Training time:26278.566853761673
batch reward last col mean 0.08735653758049011 first col mean 0.10355358570814133 all mean 0.08810265362262726
0.25974148511886597 0.25974148511886597
rl training, epoch8, iter0, batch197/1133, batch loss:0.25974148511886597, Training time:26280.44807124138
batch reward last col mean 0.09552260488271713 first col mean 0.11205334961414337 all mean 0.09259279072284698
0.2570912539958954 0.2570912539958954
rl training, epoch8, iter0, batch198/1133, batch loss:0.2570912539958954, Training time:26282.241297006607
batch reward last col mean 0.13565556704998016 first col mean 0.09603099524974823 all mean 0.12183697521686554
0.2841727137565613 0.2841727137565613
rl training, epoch8, iter0, batch199/1133, batch loss:0.2841727137565613, Training time:26283.945120811462
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.45328726606987685 Time: 95.46690201759338 s
loss of true 0.19497713816844564 loss of gen 0.16557050765954806 loss of other 0.0927396203947746 first score 0.09891042113304138
batch reward last col mean 0.10939270257949829 first col mean 0.08585149049758911 all mean 0.10056587308645248
0.27531254291534424 0.27531254291534424
rl training, epoch8, iter0, batch200/1133, batch loss:0.27531254291534424, Training time:26380.934808969498
batch reward last col mean 0.10180681943893433 first col mean 0.09550367295742035 all mean 0.10286922007799149
0.29493260383605957 0.29493260383605957
rl training, epoch8, iter0, batch201/1133, batch loss:0.29493260383605957, Training time:26382.82072687149
batch reward last col mean 0.09082120656967163 first col mean 0.1176186352968216 all mean 0.09968027472496033
0.28301289677619934 0.28301289677619934
rl training, epoch8, iter0, batch202/1133, batch loss:0.28301289677619934, Training time:26384.631026506424
batch reward last col mean 0.11482643336057663 first col mean 0.09204559028148651 all mean 0.10965540260076523
0.26556000113487244 0.26556000113487244
rl training, epoch8, iter0, batch203/1133, batch loss:0.26556000113487244, Training time:26387.19385266304
batch reward last col mean 0.13528479635715485 first col mean 0.12355729937553406 all mean 0.1268455535173416
0.30161789059638977 0.30161789059638977
rl training, epoch8, iter0, batch204/1133, batch loss:0.30161789059638977, Training time:26389.991797208786
batch reward last col mean 0.09633484482765198 first col mean 0.09215880930423737 all mean 0.10026624798774719
0.25140029191970825 0.25140029191970825
rl training, epoch8, iter0, batch205/1133, batch loss:0.25140029191970825, Training time:26392.7802798748
batch reward last col mean 0.09683185070753098 first col mean 0.11579188704490662 all mean 0.09940755367279053
0.27612006664276123 0.27612006664276123
rl training, epoch8, iter0, batch206/1133, batch loss:0.27612006664276123, Training time:26395.52121114731
batch reward last col mean 0.08234591782093048 first col mean 0.10844467580318451 all mean 0.09291987866163254
0.26446232199668884 0.26446232199668884
rl training, epoch8, iter0, batch207/1133, batch loss:0.26446232199668884, Training time:26397.476432800293
batch reward last col mean 0.09185295552015305 first col mean 0.0873897597193718 all mean 0.09766422212123871
0.270490825176239 0.270490825176239
rl training, epoch8, iter0, batch208/1133, batch loss:0.270490825176239, Training time:26399.206376791
batch reward last col mean 0.07559462636709213 first col mean 0.0938112661242485 all mean 0.09041612595319748
0.2872214615345001 0.2872214615345001
rl training, epoch8, iter0, batch209/1133, batch loss:0.2872214615345001, Training time:26400.915312051773
batch reward last col mean 0.09707425534725189 first col mean 0.1072758361697197 all mean 0.10026945918798447
0.3063206374645233 0.3063206374645233
rl training, epoch8, iter0, batch210/1133, batch loss:0.3063206374645233, Training time:26402.705323696136
batch reward last col mean 0.0783374160528183 first col mean 0.10966624319553375 all mean 0.08557086437940598
0.2719360589981079 0.2719360589981079
rl training, epoch8, iter0, batch211/1133, batch loss:0.2719360589981079, Training time:26404.965203523636
batch reward last col mean 0.11455965787172318 first col mean 0.11247579008340836 all mean 0.11133044958114624
0.311348021030426 0.311348021030426
rl training, epoch8, iter0, batch212/1133, batch loss:0.311348021030426, Training time:26407.12020134926
batch reward last col mean 0.11656428128480911 first col mean 0.12287643551826477 all mean 0.10937628149986267
0.23679256439208984 0.23679256439208984
rl training, epoch8, iter0, batch213/1133, batch loss:0.23679256439208984, Training time:26409.83069586754
batch reward last col mean 0.11699587106704712 first col mean 0.10810015350580215 all mean 0.11267132312059402
0.3066082000732422 0.3066082298755646
rl training, epoch8, iter0, batch214/1133, batch loss:0.3066082298755646, Training time:26412.359395503998
batch reward last col mean 0.11579877138137817 first col mean 0.11061259359121323 all mean 0.11800383031368256
0.3045855164527893 0.3045855164527893
rl training, epoch8, iter0, batch215/1133, batch loss:0.3045855164527893, Training time:26414.18075609207
batch reward last col mean 0.0944383442401886 first col mean 0.09783761203289032 all mean 0.09905187785625458
0.27554816007614136 0.27554816007614136
rl training, epoch8, iter0, batch216/1133, batch loss:0.27554816007614136, Training time:26416.331468582153
batch reward last col mean 0.06643778085708618 first col mean 0.09926331043243408 all mean 0.07392407953739166
0.21997493505477905 0.21997494995594025
rl training, epoch8, iter0, batch217/1133, batch loss:0.21997494995594025, Training time:26418.03597354889
batch reward last col mean 0.11153003573417664 first col mean 0.11534619331359863 all mean 0.10865463316440582
0.30747872591018677 0.30747872591018677
rl training, epoch8, iter0, batch218/1133, batch loss:0.30747872591018677, Training time:26419.91695713997
batch reward last col mean 0.06948501616716385 first col mean 0.09685955941677094 all mean 0.07831417769193649
0.2465486228466034 0.2465486228466034
rl training, epoch8, iter0, batch219/1133, batch loss:0.2465486228466034, Training time:26422.228281021118
batch reward last col mean 0.08647556602954865 first col mean 0.10653271526098251 all mean 0.09691684693098068
0.2680874168872833 0.2680874168872833
rl training, epoch8, iter0, batch220/1133, batch loss:0.2680874168872833, Training time:26423.955555677414
batch reward last col mean 0.09965087473392487 first col mean 0.10102112591266632 all mean 0.09796180576086044
0.2551497220993042 0.2551497220993042
rl training, epoch8, iter0, batch221/1133, batch loss:0.2551497220993042, Training time:26425.74101471901
batch reward last col mean 0.07745325565338135 first col mean 0.09079370647668839 all mean 0.08412671834230423
0.24767720699310303 0.24767720699310303
rl training, epoch8, iter0, batch222/1133, batch loss:0.24767720699310303, Training time:26427.717515707016
batch reward last col mean 0.10797025263309479 first col mean 0.08860000222921371 all mean 0.10444430261850357
0.2660813331604004 0.2660813331604004
rl training, epoch8, iter0, batch223/1133, batch loss:0.2660813331604004, Training time:26429.488793373108
batch reward last col mean 0.0652230903506279 first col mean 0.12565279006958008 all mean 0.07876763492822647
0.26282793283462524 0.26282793283462524
rl training, epoch8, iter0, batch224/1133, batch loss:0.26282793283462524, Training time:26431.53137898445
batch reward last col mean 0.04898618906736374 first col mean 0.10943005979061127 all mean 0.06509863585233688
0.2337879091501236 0.2337879091501236
rl training, epoch8, iter0, batch225/1133, batch loss:0.2337879091501236, Training time:26433.39255309105
batch reward last col mean 0.07618021965026855 first col mean 0.10508967936038971 all mean 0.08527349680662155
0.2647843062877655 0.2647843360900879
rl training, epoch8, iter0, batch226/1133, batch loss:0.2647843360900879, Training time:26435.248356819153
batch reward last col mean 0.11468923836946487 first col mean 0.10292039811611176 all mean 0.10455229878425598
0.2790748178958893 0.2790748178958893
rl training, epoch8, iter0, batch227/1133, batch loss:0.2790748178958893, Training time:26437.00879740715
batch reward last col mean 0.0644163191318512 first col mean 0.10488508641719818 all mean 0.07549334317445755
0.25116103887557983 0.25116103887557983
rl training, epoch8, iter0, batch228/1133, batch loss:0.25116103887557983, Training time:26438.94227719307
batch reward last col mean 0.10255289077758789 first col mean 0.09471525251865387 all mean 0.1029379591345787
0.2536752223968506 0.2536752223968506
rl training, epoch8, iter0, batch229/1133, batch loss:0.2536752223968506, Training time:26440.90242433548
batch reward last col mean 0.11552710086107254 first col mean 0.10362283885478973 all mean 0.11106996238231659
0.27987194061279297 0.27987194061279297
rl training, epoch8, iter0, batch230/1133, batch loss:0.27987194061279297, Training time:26442.978945970535
batch reward last col mean 0.07723510265350342 first col mean 0.09940017759799957 all mean 0.08222059905529022
0.24250634014606476 0.24250634014606476
rl training, epoch8, iter0, batch231/1133, batch loss:0.24250634014606476, Training time:26445.033472776413
batch reward last col mean 0.09965482354164124 first col mean 0.10559393465518951 all mean 0.09687674045562744
0.28903326392173767 0.28903326392173767
rl training, epoch8, iter0, batch232/1133, batch loss:0.28903326392173767, Training time:26446.945422172546
batch reward last col mean 0.09043833613395691 first col mean 0.09541325271129608 all mean 0.09758280217647552
0.2527587115764618 0.2527587115764618
rl training, epoch8, iter0, batch233/1133, batch loss:0.2527587115764618, Training time:26448.42503786087
batch reward last col mean 0.09131859987974167 first col mean 0.11658221483230591 all mean 0.09740954637527466
0.2650071382522583 0.2650071382522583
rl training, epoch8, iter0, batch234/1133, batch loss:0.2650071382522583, Training time:26450.235182523727
batch reward last col mean 0.10113267600536346 first col mean 0.09980538487434387 all mean 0.10208267718553543
0.2655331790447235 0.2655331790447235
rl training, epoch8, iter0, batch235/1133, batch loss:0.2655331790447235, Training time:26453.00994873047
batch reward last col mean 0.06452986598014832 first col mean 0.10611764341592789 all mean 0.082119882106781
0.2545003592967987 0.2545003592967987
rl training, epoch8, iter0, batch236/1133, batch loss:0.2545003592967987, Training time:26454.4873919487
batch reward last col mean 0.09260496497154236 first col mean 0.1268543303012848 all mean 0.09929504245519638
0.2962905168533325 0.2962905168533325
rl training, epoch8, iter0, batch237/1133, batch loss:0.2962905168533325, Training time:26456.396673440933
batch reward last col mean 0.1130925640463829 first col mean 0.08911803364753723 all mean 0.10915268957614899
0.30905675888061523 0.30905672907829285
rl training, epoch8, iter0, batch238/1133, batch loss:0.30905672907829285, Training time:26458.493645191193
batch reward last col mean 0.08813367784023285 first col mean 0.09449104219675064 all mean 0.09551875293254852
0.29360225796699524 0.29360225796699524
rl training, epoch8, iter0, batch239/1133, batch loss:0.29360225796699524, Training time:26460.66336297989
batch reward last col mean 0.11801746487617493 first col mean 0.10844287276268005 all mean 0.11485147476196289
0.25373226404190063 0.25373226404190063
rl training, epoch8, iter0, batch240/1133, batch loss:0.25373226404190063, Training time:26462.642781972885
batch reward last col mean 0.1022636666893959 first col mean 0.10378502309322357 all mean 0.10188054293394089
0.2527450621128082 0.2527450621128082
rl training, epoch8, iter0, batch241/1133, batch loss:0.2527450621128082, Training time:26464.15272474289
batch reward last col mean 0.08502163738012314 first col mean 0.105170339345932 all mean 0.08969125896692276
0.25207462906837463 0.25207462906837463
rl training, epoch8, iter0, batch242/1133, batch loss:0.25207462906837463, Training time:26465.751356601715
batch reward last col mean 0.0962466299533844 first col mean 0.10409405082464218 all mean 0.09527166932821274
0.30869370698928833 0.30869370698928833
rl training, epoch8, iter0, batch243/1133, batch loss:0.30869370698928833, Training time:26468.92849421501
batch reward last col mean 0.1170995682477951 first col mean 0.0906788781285286 all mean 0.11138549447059631
0.2868266999721527 0.2868266701698303
rl training, epoch8, iter0, batch244/1133, batch loss:0.2868266701698303, Training time:26470.726645946503
batch reward last col mean 0.11053287982940674 first col mean 0.10311609506607056 all mean 0.10254249721765518
0.2986017167568207 0.2986017167568207
rl training, epoch8, iter0, batch245/1133, batch loss:0.2986017167568207, Training time:26472.359990358353
batch reward last col mean 0.07479409873485565 first col mean 0.08586044609546661 all mean 0.07868831604719162
0.23283620178699493 0.23283620178699493
rl training, epoch8, iter0, batch246/1133, batch loss:0.23283620178699493, Training time:26474.452122688293
batch reward last col mean 0.09742216765880585 first col mean 0.11251778900623322 all mean 0.10418311506509781
0.28063416481018066 0.28063416481018066
rl training, epoch8, iter0, batch247/1133, batch loss:0.28063416481018066, Training time:26476.389489650726
batch reward last col mean 0.08898524940013885 first col mean 0.10884193331003189 all mean 0.09388528019189835
0.2643413841724396 0.2643413841724396
rl training, epoch8, iter0, batch248/1133, batch loss:0.2643413841724396, Training time:26478.015664100647
batch reward last col mean 0.08507026731967926 first col mean 0.12165936827659607 all mean 0.09381000697612762
0.264325350522995 0.264325350522995
rl training, epoch8, iter0, batch249/1133, batch loss:0.264325350522995, Training time:26479.914935112
batch reward last col mean 0.10666212439537048 first col mean 0.11226320266723633 all mean 0.10762456804513931
0.2657466232776642 0.2657466232776642
rl training, epoch8, iter0, batch250/1133, batch loss:0.2657466232776642, Training time:26481.996111869812
batch reward last col mean 0.0798598900437355 first col mean 0.11267566680908203 all mean 0.09179588407278061
0.28215208649635315 0.28215208649635315
rl training, epoch8, iter0, batch251/1133, batch loss:0.28215208649635315, Training time:26483.53547668457
batch reward last col mean 0.09728366136550903 first col mean 0.11151261627674103 all mean 0.10211142897605896
0.2775700092315674 0.2775700092315674
rl training, epoch8, iter0, batch252/1133, batch loss:0.2775700092315674, Training time:26485.427491903305
batch reward last col mean 0.10385676473379135 first col mean 0.0987846851348877 all mean 0.1011638343334198
0.2572861909866333 0.2572861909866333
rl training, epoch8, iter0, batch253/1133, batch loss:0.2572861909866333, Training time:26487.03687930107
batch reward last col mean 0.10899589955806732 first col mean 0.11809536814689636 all mean 0.10124114900827408
0.24466562271118164 0.24466562271118164
rl training, epoch8, iter0, batch254/1133, batch loss:0.24466562271118164, Training time:26488.896519184113
batch reward last col mean 0.08484167605638504 first col mean 0.10988090932369232 all mean 0.09197845309972763
0.2635746896266937 0.2635746896266937
rl training, epoch8, iter0, batch255/1133, batch loss:0.2635746896266937, Training time:26490.753204107285
batch reward last col mean 0.11362005770206451 first col mean 0.09864292293787003 all mean 0.10613219439983368
0.2622950077056885 0.2622950077056885
rl training, epoch8, iter0, batch256/1133, batch loss:0.2622950077056885, Training time:26492.64396238327
batch reward last col mean 0.09092967212200165 first col mean 0.10057991743087769 all mean 0.09819817543029785
0.3011816143989563 0.3011815845966339
rl training, epoch8, iter0, batch257/1133, batch loss:0.3011815845966339, Training time:26494.08859705925
batch reward last col mean 0.08304227143526077 first col mean 0.10587036609649658 all mean 0.0863766297698021
0.25781333446502686 0.25781333446502686
rl training, epoch8, iter0, batch258/1133, batch loss:0.25781333446502686, Training time:26496.196430921555
batch reward last col mean 0.10969594866037369 first col mean 0.10177908092737198 all mean 0.1088458001613617
0.25339680910110474 0.25339677929878235
rl training, epoch8, iter0, batch259/1133, batch loss:0.25339677929878235, Training time:26498.050771713257
batch reward last col mean 0.11095770448446274 first col mean 0.1111675426363945 all mean 0.10902074724435806
0.2771469056606293 0.2771468758583069
rl training, epoch8, iter0, batch260/1133, batch loss:0.2771468758583069, Training time:26499.852687597275
batch reward last col mean 0.11270620673894882 first col mean 0.11138752102851868 all mean 0.11280401051044464
0.2736591696739197 0.2736591696739197
rl training, epoch8, iter0, batch261/1133, batch loss:0.2736591696739197, Training time:26502.3632209301
batch reward last col mean 0.09482437372207642 first col mean 0.08547143638134003 all mean 0.09719239920377731
0.2566763460636139 0.2566763460636139
rl training, epoch8, iter0, batch262/1133, batch loss:0.2566763460636139, Training time:26504.337099790573
batch reward last col mean 0.11334950476884842 first col mean 0.12473165988922119 all mean 0.11351262778043747
0.3301609456539154 0.3301609456539154
rl training, epoch8, iter0, batch263/1133, batch loss:0.3301609456539154, Training time:26506.227672576904
batch reward last col mean 0.09984556585550308 first col mean 0.10797901451587677 all mean 0.09909019619226456
0.2800324857234955 0.2800324559211731
rl training, epoch8, iter0, batch264/1133, batch loss:0.2800324559211731, Training time:26508.280643463135
batch reward last col mean 0.06927988678216934 first col mean 0.11148581653833389 all mean 0.0790240541100502
0.23221032321453094 0.23221030831336975
rl training, epoch8, iter0, batch265/1133, batch loss:0.23221030831336975, Training time:26509.812819957733
batch reward last col mean 0.05858403816819191 first col mean 0.12098842859268188 all mean 0.07055051624774933
0.23985475301742554 0.23985475301742554
rl training, epoch8, iter0, batch266/1133, batch loss:0.23985475301742554, Training time:26511.427701234818
batch reward last col mean 0.10386833548545837 first col mean 0.09928898513317108 all mean 0.09990926086902618
0.24897287786006927 0.24897287786006927
rl training, epoch8, iter0, batch267/1133, batch loss:0.24897287786006927, Training time:26513.295498609543
batch reward last col mean 0.09473296254873276 first col mean 0.10566316545009613 all mean 0.09634134918451309
0.2741755545139313 0.2741755545139313
rl training, epoch8, iter0, batch268/1133, batch loss:0.2741755545139313, Training time:26515.11116886139
batch reward last col mean 0.1008111760020256 first col mean 0.11589135229587555 all mean 0.10545165091753006
0.2998954653739929 0.2998954653739929
rl training, epoch8, iter0, batch269/1133, batch loss:0.2998954653739929, Training time:26517.45254611969
batch reward last col mean 0.08756470680236816 first col mean 0.09501361101865768 all mean 0.0909317284822464
0.26057612895965576 0.26057612895965576
rl training, epoch8, iter0, batch270/1133, batch loss:0.26057612895965576, Training time:26519.83301305771
batch reward last col mean 0.11845410615205765 first col mean 0.10441839694976807 all mean 0.11193128675222397
0.2961939871311188 0.2961939871311188
rl training, epoch8, iter0, batch271/1133, batch loss:0.2961939871311188, Training time:26521.944576978683
batch reward last col mean 0.0963723361492157 first col mean 0.11910487711429596 all mean 0.09947498887777328
0.2991691529750824 0.2991691529750824
rl training, epoch8, iter0, batch272/1133, batch loss:0.2991691529750824, Training time:26523.841913223267
batch reward last col mean 0.11759538948535919 first col mean 0.10217643529176712 all mean 0.11720636487007141
0.31504499912261963 0.31504496932029724
rl training, epoch8, iter0, batch273/1133, batch loss:0.31504496932029724, Training time:26526.09623360634
batch reward last col mean 0.0926181823015213 first col mean 0.1088164895772934 all mean 0.09407610446214676
0.27395185828208923 0.27395185828208923
rl training, epoch8, iter0, batch274/1133, batch loss:0.27395185828208923, Training time:26528.43125271797
batch reward last col mean 0.06022997945547104 first col mean 0.0682118684053421 all mean 0.07058089226484299
0.21314719319343567 0.21314719319343567
rl training, epoch8, iter0, batch275/1133, batch loss:0.21314719319343567, Training time:26530.30367922783
batch reward last col mean 0.08590743690729141 first col mean 0.0800342708826065 all mean 0.09281186759471893
0.24668428301811218 0.24668428301811218
rl training, epoch8, iter0, batch276/1133, batch loss:0.24668428301811218, Training time:26531.99637413025
batch reward last col mean 0.0982363298535347 first col mean 0.08886726200580597 all mean 0.09977385401725769
0.28169506788253784 0.28169506788253784
rl training, epoch8, iter0, batch277/1133, batch loss:0.28169506788253784, Training time:26534.21234869957
batch reward last col mean 0.13819532096385956 first col mean 0.09376614540815353 all mean 0.13411128520965576
0.3073095679283142 0.3073095679283142
rl training, epoch8, iter0, batch278/1133, batch loss:0.3073095679283142, Training time:26536.275837421417
batch reward last col mean 0.08032137155532837 first col mean 0.09774993360042572 all mean 0.0957208201289177
0.3232816457748413 0.3232816457748413
rl training, epoch8, iter0, batch279/1133, batch loss:0.3232816457748413, Training time:26538.4892244339
batch reward last col mean 0.11604554206132889 first col mean 0.10264916718006134 all mean 0.11664105951786041
0.2745446264743805 0.2745445966720581
rl training, epoch8, iter0, batch280/1133, batch loss:0.2745445966720581, Training time:26540.91671180725
batch reward last col mean 0.1467277854681015 first col mean 0.11285340785980225 all mean 0.12978650629520416
0.2625596225261688 0.2625596225261688
rl training, epoch8, iter0, batch281/1133, batch loss:0.2625596225261688, Training time:26543.578952789307
batch reward last col mean 0.10470011830329895 first col mean 0.12255185842514038 all mean 0.10898234695196152
0.29658252000808716 0.29658252000808716
rl training, epoch8, iter0, batch282/1133, batch loss:0.29658252000808716, Training time:26545.31898188591
batch reward last col mean 0.11392609030008316 first col mean 0.10896329581737518 all mean 0.11224674433469772
0.26751476526260376 0.26751473546028137
rl training, epoch8, iter0, batch283/1133, batch loss:0.26751473546028137, Training time:26547.791340351105
batch reward last col mean 0.08541496098041534 first col mean 0.09887076169252396 all mean 0.09421990066766739
0.2672814130783081 0.2672814130783081
rl training, epoch8, iter0, batch284/1133, batch loss:0.2672814130783081, Training time:26549.490995645523
batch reward last col mean 0.137998566031456 first col mean 0.10926368087530136 all mean 0.12964588403701782
0.3328883945941925 0.3328883647918701
rl training, epoch8, iter0, batch285/1133, batch loss:0.3328883647918701, Training time:26551.43234229088
batch reward last col mean 0.10045270621776581 first col mean 0.12027095258235931 all mean 0.09959860891103745
0.24720065295696259 0.24720065295696259
rl training, epoch8, iter0, batch286/1133, batch loss:0.24720065295696259, Training time:26553.204722881317
batch reward last col mean 0.09518322348594666 first col mean 0.08705945312976837 all mean 0.10069883614778519
0.29472124576568604 0.29472121596336365
rl training, epoch8, iter0, batch287/1133, batch loss:0.29472121596336365, Training time:26555.376338005066
batch reward last col mean 0.0842076987028122 first col mean 0.09424270689487457 all mean 0.08881904929876328
0.24356618523597717 0.24356618523597717
rl training, epoch8, iter0, batch288/1133, batch loss:0.24356618523597717, Training time:26557.313908100128
batch reward last col mean 0.0976874828338623 first col mean 0.11616423726081848 all mean 0.10236262530088425
0.3162637948989868 0.3162637948989868
rl training, epoch8, iter0, batch289/1133, batch loss:0.3162637948989868, Training time:26559.252712488174
batch reward last col mean 0.07458437234163284 first col mean 0.10809493064880371 all mean 0.08827657252550125
0.2737526297569275 0.2737526297569275
rl training, epoch8, iter0, batch290/1133, batch loss:0.2737526297569275, Training time:26560.86807322502
batch reward last col mean 0.1008630245923996 first col mean 0.10335967689752579 all mean 0.09975223243236542
0.2857951819896698 0.2857952117919922
rl training, epoch8, iter0, batch291/1133, batch loss:0.2857952117919922, Training time:26562.933192014694
batch reward last col mean 0.09141429513692856 first col mean 0.09617140889167786 all mean 0.09498319029808044
0.2749778926372528 0.2749778926372528
rl training, epoch8, iter0, batch292/1133, batch loss:0.2749778926372528, Training time:26565.940941810608
batch reward last col mean 0.08101758360862732 first col mean 0.11491300165653229 all mean 0.09199006110429764
0.2743651568889618 0.2743651568889618
rl training, epoch8, iter0, batch293/1133, batch loss:0.2743651568889618, Training time:26567.82309103012
batch reward last col mean 0.13567443192005157 first col mean 0.10654936730861664 all mean 0.1311265081167221
0.34297293424606323 0.34297287464141846
rl training, epoch8, iter0, batch294/1133, batch loss:0.34297287464141846, Training time:26569.474573612213
batch reward last col mean 0.11102612316608429 first col mean 0.09408712387084961 all mean 0.09952255338430405
0.2991188168525696 0.2991187870502472
rl training, epoch8, iter0, batch295/1133, batch loss:0.2991187870502472, Training time:26571.050196409225
batch reward last col mean 0.09217571467161179 first col mean 0.10382428765296936 all mean 0.09704618155956268
0.2740287482738495 0.2740287482738495
rl training, epoch8, iter0, batch296/1133, batch loss:0.2740287482738495, Training time:26573.33020734787
batch reward last col mean 0.12420114874839783 first col mean 0.11818307638168335 all mean 0.12436766177415848
0.2806878983974457 0.2806878983974457
rl training, epoch8, iter0, batch297/1133, batch loss:0.2806878983974457, Training time:26575.27555179596
batch reward last col mean 0.12425796687602997 first col mean 0.115766242146492 all mean 0.12230633199214935
0.32335492968559265 0.32335492968559265
rl training, epoch8, iter0, batch298/1133, batch loss:0.32335492968559265, Training time:26577.012314796448
batch reward last col mean 0.12671926617622375 first col mean 0.10137838125228882 all mean 0.12273512780666351
0.3149675130844116 0.3149675130844116
rl training, epoch8, iter0, batch299/1133, batch loss:0.3149675130844116, Training time:26579.03944683075
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.45822112976399965 Time: 97.3117368221283 s
loss of true 0.19630087854214084 loss of gen 0.1681365877560883 loss of other 0.09378366411186012 first score 0.10085272043943405
batch reward last col mean 0.07102411985397339 first col mean 0.10625043511390686 all mean 0.0803050845861435
0.24749745428562164 0.24749745428562164
rl training, epoch8, iter0, batch300/1133, batch loss:0.24749745428562164, Training time:26677.827920675278
batch reward last col mean 0.10853974521160126 first col mean 0.0899486392736435 all mean 0.10553077608346939
0.2911330461502075 0.2911330461502075
rl training, epoch8, iter0, batch301/1133, batch loss:0.2911330461502075, Training time:26680.32903766632
batch reward last col mean 0.11005271971225739 first col mean 0.10905852168798447 all mean 0.10317820310592651
0.2885623276233673 0.2885623276233673
rl training, epoch8, iter0, batch302/1133, batch loss:0.2885623276233673, Training time:26682.233280420303
batch reward last col mean 0.14730627834796906 first col mean 0.10776947438716888 all mean 0.13415923714637756
0.3032100200653076 0.30321004986763
rl training, epoch8, iter0, batch303/1133, batch loss:0.30321004986763, Training time:26684.024242401123
batch reward last col mean 0.09759266674518585 first col mean 0.09734966605901718 all mean 0.10281022638082504
0.31007224321365356 0.31007227301597595
rl training, epoch8, iter0, batch304/1133, batch loss:0.31007227301597595, Training time:26685.632875204086
batch reward last col mean 0.12465483695268631 first col mean 0.08732392638921738 all mean 0.11233506351709366
0.28251874446868896 0.28251874446868896
rl training, epoch8, iter0, batch305/1133, batch loss:0.28251874446868896, Training time:26687.204277276993
batch reward last col mean 0.10803744196891785 first col mean 0.11629314720630646 all mean 0.10574686527252197
0.2778725326061249 0.2778725326061249
rl training, epoch8, iter0, batch306/1133, batch loss:0.2778725326061249, Training time:26688.82690525055
batch reward last col mean 0.10565084218978882 first col mean 0.09029297530651093 all mean 0.09717004746198654
0.26139140129089355 0.26139140129089355
rl training, epoch8, iter0, batch307/1133, batch loss:0.26139140129089355, Training time:26690.46704006195
batch reward last col mean 0.09683284163475037 first col mean 0.09229405224323273 all mean 0.10703419893980026
0.272902250289917 0.272902250289917
rl training, epoch8, iter0, batch308/1133, batch loss:0.272902250289917, Training time:26692.09360599518
batch reward last col mean 0.11648448556661606 first col mean 0.10256155580282211 all mean 0.11623552441596985
0.31967222690582275 0.31967219710350037
rl training, epoch8, iter0, batch309/1133, batch loss:0.31967219710350037, Training time:26694.122231721878
batch reward last col mean 0.11675257980823517 first col mean 0.10397946834564209 all mean 0.11220428347587585
0.3214317560195923 0.3214317560195923
rl training, epoch8, iter0, batch310/1133, batch loss:0.3214317560195923, Training time:26696.05029439926
batch reward last col mean 0.09281938523054123 first col mean 0.10459020733833313 all mean 0.09433339536190033
0.2637726068496704 0.2637726068496704
rl training, epoch8, iter0, batch311/1133, batch loss:0.2637726068496704, Training time:26697.70761346817
batch reward last col mean 0.09099128842353821 first col mean 0.09517957270145416 all mean 0.09986114501953125
0.3051563501358032 0.3051563501358032
rl training, epoch8, iter0, batch312/1133, batch loss:0.3051563501358032, Training time:26699.54136443138
batch reward last col mean 0.09072260558605194 first col mean 0.09421493858098984 all mean 0.09297425299882889
0.228510782122612 0.228510782122612
rl training, epoch8, iter0, batch313/1133, batch loss:0.228510782122612, Training time:26701.261092424393
batch reward last col mean 0.0903066098690033 first col mean 0.08691313862800598 all mean 0.09428848326206207
0.2643674612045288 0.2643674612045288
rl training, epoch8, iter0, batch314/1133, batch loss:0.2643674612045288, Training time:26703.52876830101
batch reward last col mean 0.0919070690870285 first col mean 0.0962471142411232 all mean 0.10097867995500565
0.28349995613098145 0.28349995613098145
rl training, epoch8, iter0, batch315/1133, batch loss:0.28349995613098145, Training time:26705.280958890915
batch reward last col mean 0.09651337563991547 first col mean 0.08547863364219666 all mean 0.09356626868247986
0.23107585310935974 0.23107585310935974
rl training, epoch8, iter0, batch316/1133, batch loss:0.23107585310935974, Training time:26706.961916446686
batch reward last col mean 0.08568663150072098 first col mean 0.10733309388160706 all mean 0.0890200138092041
0.2835085391998291 0.2835085391998291
rl training, epoch8, iter0, batch317/1133, batch loss:0.2835085391998291, Training time:26709.25551176071
batch reward last col mean 0.11682683229446411 first col mean 0.10340121388435364 all mean 0.11136180907487869
0.2757655382156372 0.2757655382156372
rl training, epoch8, iter0, batch318/1133, batch loss:0.2757655382156372, Training time:26710.992485761642
batch reward last col mean 0.10660621523857117 first col mean 0.11350499838590622 all mean 0.10411959141492844
0.292032390832901 0.292032390832901
rl training, epoch8, iter0, batch319/1133, batch loss:0.292032390832901, Training time:26712.90756869316
batch reward last col mean 0.09938837587833405 first col mean 0.11634890735149384 all mean 0.10105425119400024
0.288315087556839 0.288315087556839
rl training, epoch8, iter0, batch320/1133, batch loss:0.288315087556839, Training time:26714.86134815216
batch reward last col mean 0.10746545344591141 first col mean 0.11225251853466034 all mean 0.10775890201330185
0.2765171229839325 0.2765171229839325
rl training, epoch8, iter0, batch321/1133, batch loss:0.2765171229839325, Training time:26717.04506802559
batch reward last col mean 0.08622559905052185 first col mean 0.09168172627687454 all mean 0.09196863323450089
0.27760574221611023 0.27760574221611023
rl training, epoch8, iter0, batch322/1133, batch loss:0.27760574221611023, Training time:26718.578961610794
batch reward last col mean 0.10194578766822815 first col mean 0.10759379714727402 all mean 0.09759963303804398
0.2703527808189392 0.2703527808189392
rl training, epoch8, iter0, batch323/1133, batch loss:0.2703527808189392, Training time:26720.28987979889
batch reward last col mean 0.082434743642807 first col mean 0.07587967813014984 all mean 0.09004460275173187
0.2648863196372986 0.2648862898349762
rl training, epoch8, iter0, batch324/1133, batch loss:0.2648862898349762, Training time:26722.086657762527
batch reward last col mean 0.07356083393096924 first col mean 0.08932574838399887 all mean 0.07893037050962448
0.23711228370666504 0.23711228370666504
rl training, epoch8, iter0, batch325/1133, batch loss:0.23711228370666504, Training time:26723.582597255707
batch reward last col mean 0.10453808307647705 first col mean 0.09507822245359421 all mean 0.10570019483566284
0.2859797477722168 0.2859797179698944
rl training, epoch8, iter0, batch326/1133, batch loss:0.2859797179698944, Training time:26724.969344377518
batch reward last col mean 0.10173898935317993 first col mean 0.10019712895154953 all mean 0.10748856514692307
0.3014856278896332 0.3014856278896332
rl training, epoch8, iter0, batch327/1133, batch loss:0.3014856278896332, Training time:26727.074924230576
batch reward last col mean 0.0823630839586258 first col mean 0.10779149830341339 all mean 0.09174110740423203
0.27298757433891296 0.27298757433891296
rl training, epoch8, iter0, batch328/1133, batch loss:0.27298757433891296, Training time:26728.704463243484
batch reward last col mean 0.10211136937141418 first col mean 0.10329738259315491 all mean 0.10620328783988953
0.27656078338623047 0.27656078338623047
rl training, epoch8, iter0, batch329/1133, batch loss:0.27656078338623047, Training time:26730.269299268723
batch reward last col mean 0.11208155006170273 first col mean 0.10346241295337677 all mean 0.11037177592515945
0.2925041615962982 0.2925041615962982
rl training, epoch8, iter0, batch330/1133, batch loss:0.2925041615962982, Training time:26731.77783346176
batch reward last col mean 0.12296675890684128 first col mean 0.10051943361759186 all mean 0.11650052666664124
0.3200156092643738 0.3200156092643738
rl training, epoch8, iter0, batch331/1133, batch loss:0.3200156092643738, Training time:26733.455671787262
batch reward last col mean 0.13329221308231354 first col mean 0.09157265722751617 all mean 0.12593665719032288
0.3478899896144867 0.3478899896144867
rl training, epoch8, iter0, batch332/1133, batch loss:0.3478899896144867, Training time:26735.201649188995
batch reward last col mean 0.1146431416273117 first col mean 0.10898701101541519 all mean 0.10819604247808456
0.28054022789001465 0.28054022789001465
rl training, epoch8, iter0, batch333/1133, batch loss:0.28054022789001465, Training time:26737.078199148178
batch reward last col mean 0.11037518084049225 first col mean 0.11261029541492462 all mean 0.11084450036287308
0.3052557408809662 0.3052557408809662
rl training, epoch8, iter0, batch334/1133, batch loss:0.3052557408809662, Training time:26738.816261291504
batch reward last col mean 0.10451336205005646 first col mean 0.0992172583937645 all mean 0.10347434878349304
0.3042164444923401 0.3042164444923401
rl training, epoch8, iter0, batch335/1133, batch loss:0.3042164444923401, Training time:26741.057186365128
batch reward last col mean 0.10484273731708527 first col mean 0.10484150797128677 all mean 0.10278196632862091
0.2983080744743347 0.29830804467201233
rl training, epoch8, iter0, batch336/1133, batch loss:0.29830804467201233, Training time:26742.93543124199
batch reward last col mean 0.10575608164072037 first col mean 0.09357820451259613 all mean 0.10316570848226547
0.2594965398311615 0.2594965398311615
rl training, epoch8, iter0, batch337/1133, batch loss:0.2594965398311615, Training time:26744.717089891434
batch reward last col mean 0.12642601132392883 first col mean 0.11157777160406113 all mean 0.12344727665185928
0.286461740732193 0.286461740732193
rl training, epoch8, iter0, batch338/1133, batch loss:0.286461740732193, Training time:26746.42133808136
batch reward last col mean 0.09493854641914368 first col mean 0.1066761463880539 all mean 0.09473792463541031
0.24780385196208954 0.24780385196208954
rl training, epoch8, iter0, batch339/1133, batch loss:0.24780385196208954, Training time:26748.688001394272
batch reward last col mean 0.09382980316877365 first col mean 0.09296064078807831 all mean 0.0946621298789978
0.3172873556613922 0.3172873556613922
rl training, epoch8, iter0, batch340/1133, batch loss:0.3172873556613922, Training time:26751.220170736313
batch reward last col mean 0.08979450911283493 first col mean 0.09832384437322617 all mean 0.08979877829551697
0.25090232491493225 0.25090232491493225
rl training, epoch8, iter0, batch341/1133, batch loss:0.25090232491493225, Training time:26753.10479283333
batch reward last col mean 0.07364906370639801 first col mean 0.10791755467653275 all mean 0.08264826238155365
0.26887625455856323 0.26887625455856323
rl training, epoch8, iter0, batch342/1133, batch loss:0.26887625455856323, Training time:26755.107932806015
batch reward last col mean 0.0904204249382019 first col mean 0.11889136582612991 all mean 0.09068547934293747
0.26762494444847107 0.26762494444847107
rl training, epoch8, iter0, batch343/1133, batch loss:0.26762494444847107, Training time:26756.888721227646
batch reward last col mean 0.10875903815031052 first col mean 0.11037510633468628 all mean 0.11175708472728729
0.31874457001686096 0.31874457001686096
rl training, epoch8, iter0, batch344/1133, batch loss:0.31874457001686096, Training time:26758.67152261734
batch reward last col mean 0.06266042590141296 first col mean 0.10686347633600235 all mean 0.07311593741178513
0.2582153081893921 0.2582153081893921
rl training, epoch8, iter0, batch345/1133, batch loss:0.2582153081893921, Training time:26760.896535396576
batch reward last col mean 0.08965878188610077 first col mean 0.0969766229391098 all mean 0.09381989389657974
0.2686260938644409 0.2686260938644409
rl training, epoch8, iter0, batch346/1133, batch loss:0.2686260938644409, Training time:26762.736671447754
batch reward last col mean 0.11185825616121292 first col mean 0.10804371535778046 all mean 0.10681594908237457
0.2958238422870636 0.2958238422870636
rl training, epoch8, iter0, batch347/1133, batch loss:0.2958238422870636, Training time:26764.848978996277
batch reward last col mean 0.0862477496266365 first col mean 0.1077510416507721 all mean 0.08738920092582703
0.2504315972328186 0.2504315972328186
rl training, epoch8, iter0, batch348/1133, batch loss:0.2504315972328186, Training time:26766.9647667408
batch reward last col mean 0.08369579911231995 first col mean 0.11444348841905594 all mean 0.09310335665941238
0.2637369930744171 0.2637369930744171
rl training, epoch8, iter0, batch349/1133, batch loss:0.2637369930744171, Training time:26768.930938720703
batch reward last col mean 0.09861037880182266 first col mean 0.09514525532722473 all mean 0.10330274701118469
0.30551862716674805 0.30551862716674805
rl training, epoch8, iter0, batch350/1133, batch loss:0.30551862716674805, Training time:26770.582601070404
batch reward last col mean 0.10835501551628113 first col mean 0.12475220113992691 all mean 0.10715113580226898
0.2723868787288666 0.2723868489265442
rl training, epoch8, iter0, batch351/1133, batch loss:0.2723868489265442, Training time:26772.704459905624
batch reward last col mean 0.13466376066207886 first col mean 0.07732506096363068 all mean 0.12273754179477692
0.3469514548778534 0.3469514548778534
rl training, epoch8, iter0, batch352/1133, batch loss:0.3469514548778534, Training time:26774.39810013771
batch reward last col mean 0.09086869657039642 first col mean 0.09787987172603607 all mean 0.09306081384420395
0.2441270500421524 0.2441270500421524
rl training, epoch8, iter0, batch353/1133, batch loss:0.2441270500421524, Training time:26776.09229516983
batch reward last col mean 0.12681613862514496 first col mean 0.12114597111940384 all mean 0.1227358803153038
0.3001070022583008 0.3001070022583008
rl training, epoch8, iter0, batch354/1133, batch loss:0.3001070022583008, Training time:26777.613838672638
batch reward last col mean 0.11058126389980316 first col mean 0.08849866688251495 all mean 0.10595804452896118
0.27237948775291443 0.27237948775291443
rl training, epoch8, iter0, batch355/1133, batch loss:0.27237948775291443, Training time:26779.296947717667
batch reward last col mean 0.08651872724294662 first col mean 0.10286885499954224 all mean 0.09146153926849365
0.2428530603647232 0.2428530603647232
rl training, epoch8, iter0, batch356/1133, batch loss:0.2428530603647232, Training time:26780.768229961395
batch reward last col mean 0.08820697665214539 first col mean 0.1000218614935875 all mean 0.09621983766555786
0.2824854850769043 0.2824854850769043
rl training, epoch8, iter0, batch357/1133, batch loss:0.2824854850769043, Training time:26783.01665854454
batch reward last col mean 0.1056126058101654 first col mean 0.10290895402431488 all mean 0.10435941070318222
0.2923470735549927 0.2923470735549927
rl training, epoch8, iter0, batch358/1133, batch loss:0.2923470735549927, Training time:26785.883654117584
batch reward last col mean 0.08509253710508347 first col mean 0.10827504098415375 all mean 0.09186513721942902
0.27158328890800476 0.27158328890800476
rl training, epoch8, iter0, batch359/1133, batch loss:0.27158328890800476, Training time:26787.788242340088
batch reward last col mean 0.08388599753379822 first col mean 0.11067502200603485 all mean 0.09235542267560959
0.251837819814682 0.251837819814682
rl training, epoch8, iter0, batch360/1133, batch loss:0.251837819814682, Training time:26789.513826608658
batch reward last col mean 0.10818963497877121 first col mean 0.10423518717288971 all mean 0.1061888262629509
0.30756136775016785 0.30756136775016785
rl training, epoch8, iter0, batch361/1133, batch loss:0.30756136775016785, Training time:26791.41423225403
batch reward last col mean 0.10387768596410751 first col mean 0.09740518033504486 all mean 0.09844917804002762
0.26321104168891907 0.26321104168891907
rl training, epoch8, iter0, batch362/1133, batch loss:0.26321104168891907, Training time:26793.102564811707
batch reward last col mean 0.08558604121208191 first col mean 0.10262224823236465 all mean 0.08414105325937271
0.27584177255630493 0.27584177255630493
rl training, epoch8, iter0, batch363/1133, batch loss:0.27584177255630493, Training time:26794.682678461075
batch reward last col mean 0.050682153552770615 first col mean 0.08554843813180923 all mean 0.06558483839035034
0.21898064017295837 0.21898064017295837
rl training, epoch8, iter0, batch364/1133, batch loss:0.21898064017295837, Training time:26796.311362743378
batch reward last col mean 0.12882627546787262 first col mean 0.10629978775978088 all mean 0.12518110871315002
0.32100334763526917 0.32100334763526917
rl training, epoch8, iter0, batch365/1133, batch loss:0.32100334763526917, Training time:26797.865746498108
batch reward last col mean 0.09627673029899597 first col mean 0.1238817572593689 all mean 0.10381103307008743
0.2506925165653229 0.2506925165653229
rl training, epoch8, iter0, batch366/1133, batch loss:0.2506925165653229, Training time:26799.580905675888
batch reward last col mean 0.09490831196308136 first col mean 0.10603094846010208 all mean 0.09750320017337799
0.2889482378959656 0.2889482378959656
rl training, epoch8, iter0, batch367/1133, batch loss:0.2889482378959656, Training time:26801.455768823624
batch reward last col mean 0.09968540072441101 first col mean 0.12618891894817352 all mean 0.10917214304208755
0.32016104459762573 0.32016104459762573
rl training, epoch8, iter0, batch368/1133, batch loss:0.32016104459762573, Training time:26803.289878845215
batch reward last col mean 0.11663373559713364 first col mean 0.09858939796686172 all mean 0.11031004041433334
0.2598547041416168 0.2598547041416168
rl training, epoch8, iter0, batch369/1133, batch loss:0.2598547041416168, Training time:26805.253260850906
batch reward last col mean 0.10072045773267746 first col mean 0.09685004502534866 all mean 0.10310573130846024
0.31095078587532043 0.31095078587532043
rl training, epoch8, iter0, batch370/1133, batch loss:0.31095078587532043, Training time:26806.879935264587
batch reward last col mean 0.11082294583320618 first col mean 0.09927762299776077 all mean 0.10579786449670792
0.291255921125412 0.291255921125412
rl training, epoch8, iter0, batch371/1133, batch loss:0.291255921125412, Training time:26809.25126504898
batch reward last col mean 0.10060611367225647 first col mean 0.10500385612249374 all mean 0.1015743613243103
0.27394405007362366 0.27394405007362366
rl training, epoch8, iter0, batch372/1133, batch loss:0.27394405007362366, Training time:26811.292264938354
batch reward last col mean 0.06376293301582336 first col mean 0.10275711864233017 all mean 0.07909391820430756
0.2578372657299042 0.2578372657299042
rl training, epoch8, iter0, batch373/1133, batch loss:0.2578372657299042, Training time:26813.142546653748
batch reward last col mean 0.10008559376001358 first col mean 0.11109033972024918 all mean 0.09995362907648087
0.3161504864692688 0.3161504864692688
rl training, epoch8, iter0, batch374/1133, batch loss:0.3161504864692688, Training time:26815.217128515244
batch reward last col mean 0.08420034497976303 first col mean 0.09918266534805298 all mean 0.09022989869117737
0.24562956392765045 0.24562956392765045
rl training, epoch8, iter0, batch375/1133, batch loss:0.24562956392765045, Training time:26817.233503341675
batch reward last col mean 0.11128296703100204 first col mean 0.11420270800590515 all mean 0.10472777485847473
0.2708449065685272 0.2708449065685272
rl training, epoch8, iter0, batch376/1133, batch loss:0.2708449065685272, Training time:26819.047785520554
batch reward last col mean 0.07180662453174591 first col mean 0.12314905226230621 all mean 0.08135778456926346
0.27889615297317505 0.27889615297317505
rl training, epoch8, iter0, batch377/1133, batch loss:0.27889615297317505, Training time:26821.707460403442
batch reward last col mean 0.10514304041862488 first col mean 0.10857833176851273 all mean 0.10396408289670944
0.2774304449558258 0.2774304449558258
rl training, epoch8, iter0, batch378/1133, batch loss:0.2774304449558258, Training time:26823.666501760483
batch reward last col mean 0.09644119441509247 first col mean 0.10906167328357697 all mean 0.09899711608886719
0.3083760440349579 0.3083760440349579
rl training, epoch8, iter0, batch379/1133, batch loss:0.3083760440349579, Training time:26825.829020261765
batch reward last col mean 0.11628782749176025 first col mean 0.10674771666526794 all mean 0.11308616399765015
0.2613080143928528 0.2613080143928528
rl training, epoch8, iter0, batch380/1133, batch loss:0.2613080143928528, Training time:26827.42793226242
batch reward last col mean 0.10006166994571686 first col mean 0.1008327528834343 all mean 0.1037219986319542
0.3250601887702942 0.3250601887702942
rl training, epoch8, iter0, batch381/1133, batch loss:0.3250601887702942, Training time:26829.14422893524
batch reward last col mean 0.09812763333320618 first col mean 0.1101948618888855 all mean 0.09404069185256958
0.2771969139575958 0.2771969139575958
rl training, epoch8, iter0, batch382/1133, batch loss:0.2771969139575958, Training time:26831.00774693489
batch reward last col mean 0.11140812933444977 first col mean 0.1048780232667923 all mean 0.10942043364048004
0.3023945391178131 0.3023945391178131
rl training, epoch8, iter0, batch383/1133, batch loss:0.3023945391178131, Training time:26832.897304058075
batch reward last col mean 0.1198347955942154 first col mean 0.13443611562252045 all mean 0.11938411742448807
0.3416885733604431 0.3416885733604431
rl training, epoch8, iter0, batch384/1133, batch loss:0.3416885733604431, Training time:26834.973446130753
batch reward last col mean 0.09204734861850739 first col mean 0.10873116552829742 all mean 0.09846830368041992
0.28259536623954773 0.28259536623954773
rl training, epoch8, iter0, batch385/1133, batch loss:0.28259536623954773, Training time:26836.56281232834
batch reward last col mean 0.0938730239868164 first col mean 0.09000858664512634 all mean 0.09390658885240555
0.28373757004737854 0.28373757004737854
rl training, epoch8, iter0, batch386/1133, batch loss:0.28373757004737854, Training time:26838.61948275566
batch reward last col mean 0.0911070704460144 first col mean 0.09335663169622421 all mean 0.09139560163021088
0.29117056727409363 0.29117056727409363
rl training, epoch8, iter0, batch387/1133, batch loss:0.29117056727409363, Training time:26840.605721712112
batch reward last col mean 0.0919078141450882 first col mean 0.11088845133781433 all mean 0.09635989367961884
0.2967618405818939 0.2967618405818939
rl training, epoch8, iter0, batch388/1133, batch loss:0.2967618405818939, Training time:26842.516652822495
batch reward last col mean 0.0852290689945221 first col mean 0.12208773195743561 all mean 0.09000226855278015
0.2905040383338928 0.2905040383338928
rl training, epoch8, iter0, batch389/1133, batch loss:0.2905040383338928, Training time:26844.744173765182
batch reward last col mean 0.10408376902341843 first col mean 0.119432732462883 all mean 0.10545874387025833
0.29586267471313477 0.29586267471313477
rl training, epoch8, iter0, batch390/1133, batch loss:0.29586267471313477, Training time:26846.52250623703
batch reward last col mean 0.07466098666191101 first col mean 0.1196523979306221 all mean 0.08441789448261261
0.24553599953651428 0.24553599953651428
rl training, epoch8, iter0, batch391/1133, batch loss:0.24553599953651428, Training time:26848.259021520615
batch reward last col mean 0.10032708197832108 first col mean 0.10968160629272461 all mean 0.09971273690462112
0.29506489634513855 0.29506489634513855
rl training, epoch8, iter0, batch392/1133, batch loss:0.29506489634513855, Training time:26850.153437137604
batch reward last col mean 0.09828923642635345 first col mean 0.10452446341514587 all mean 0.1049053743481636
0.26624444127082825 0.26624444127082825
rl training, epoch8, iter0, batch393/1133, batch loss:0.26624444127082825, Training time:26852.094675540924
batch reward last col mean 0.12459606677293777 first col mean 0.10974913090467453 all mean 0.11763668060302734
0.2952042818069458 0.2952042818069458
rl training, epoch8, iter0, batch394/1133, batch loss:0.2952042818069458, Training time:26854.563210487366
batch reward last col mean 0.08064807951450348 first col mean 0.10136254876852036 all mean 0.0906587541103363
0.29923000931739807 0.29923000931739807
rl training, epoch8, iter0, batch395/1133, batch loss:0.29923000931739807, Training time:26857.349417209625
batch reward last col mean 0.1060231626033783 first col mean 0.11776933073997498 all mean 0.10693676024675369
0.2847975492477417 0.2847975194454193
rl training, epoch8, iter0, batch396/1133, batch loss:0.2847975194454193, Training time:26859.672558307648
batch reward last col mean 0.08881306648254395 first col mean 0.09212200343608856 all mean 0.09315011650323868
0.24854877591133118 0.2485487461090088
rl training, epoch8, iter0, batch397/1133, batch loss:0.2485487461090088, Training time:26861.772166252136
batch reward last col mean 0.12416984885931015 first col mean 0.12548096477985382 all mean 0.1229066550731659
0.3280068039894104 0.3280068039894104
rl training, epoch8, iter0, batch398/1133, batch loss:0.3280068039894104, Training time:26864.328485250473
batch reward last col mean 0.08953079581260681 first col mean 0.09368221461772919 all mean 0.0931154191493988
0.26804086565971375 0.26804086565971375
rl training, epoch8, iter0, batch399/1133, batch loss:0.26804086565971375, Training time:26866.351900100708
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4590990903202875 Time: 99.3226809501648 s
loss of true 0.19740293989745475 loss of gen 0.16828576887366736 loss of other 0.09341038148998163 first score 0.1260460466146469
batch reward last col mean 0.07901140302419662 first col mean 0.09413763135671616 all mean 0.08215103298425674
0.24934542179107666 0.24934542179107666
rl training, epoch8, iter0, batch400/1133, batch loss:0.24934542179107666, Training time:26968.264897108078
batch reward last col mean 0.07730165123939514 first col mean 0.09717794507741928 all mean 0.08254528045654297
0.23643897473812103 0.23643897473812103
rl training, epoch8, iter0, batch401/1133, batch loss:0.23643897473812103, Training time:26970.36795258522
batch reward last col mean 0.08567257970571518 first col mean 0.0982930064201355 all mean 0.09120447188615799
0.2656155228614807 0.2656155228614807
rl training, epoch8, iter0, batch402/1133, batch loss:0.2656155228614807, Training time:26972.498064517975
batch reward last col mean 0.10219252854585648 first col mean 0.08835195004940033 all mean 0.09727601706981659
0.22780963778495789 0.22780963778495789
rl training, epoch8, iter0, batch403/1133, batch loss:0.22780963778495789, Training time:26974.399826288223
batch reward last col mean 0.09143511205911636 first col mean 0.09425359219312668 all mean 0.0918460562825203
0.2432597279548645 0.2432597279548645
rl training, epoch8, iter0, batch404/1133, batch loss:0.2432597279548645, Training time:26976.733173131943
batch reward last col mean 0.08894641697406769 first col mean 0.0947875902056694 all mean 0.08755183964967728
0.21822601556777954 0.21822601556777954
rl training, epoch8, iter0, batch405/1133, batch loss:0.21822601556777954, Training time:26978.705899953842
batch reward last col mean 0.06385728716850281 first col mean 0.10054484754800797 all mean 0.07323189824819565
0.22577621042728424 0.22577621042728424
rl training, epoch8, iter0, batch406/1133, batch loss:0.22577621042728424, Training time:26980.888775348663
batch reward last col mean 0.07743322104215622 first col mean 0.09214620292186737 all mean 0.08315269649028778
0.2550176680088043 0.2550176680088043
rl training, epoch8, iter0, batch407/1133, batch loss:0.2550176680088043, Training time:26982.576716899872
batch reward last col mean 0.10876556485891342 first col mean 0.09185171127319336 all mean 0.0960526242852211
0.2723526060581207 0.27235257625579834
rl training, epoch8, iter0, batch408/1133, batch loss:0.27235257625579834, Training time:26984.635897159576
batch reward last col mean 0.07299335300922394 first col mean 0.07894812524318695 all mean 0.07891268283128738
0.30624154210090637 0.30624154210090637
rl training, epoch8, iter0, batch409/1133, batch loss:0.30624154210090637, Training time:26987.374616861343
batch reward last col mean 0.07992972433567047 first col mean 0.09244123846292496 all mean 0.08012595027685165
0.2500912547111511 0.2500912547111511
rl training, epoch8, iter0, batch410/1133, batch loss:0.2500912547111511, Training time:26989.254189491272
batch reward last col mean 0.09972217679023743 first col mean 0.08688635379076004 all mean 0.09632280468940735
0.23685088753700256 0.23685088753700256
rl training, epoch8, iter0, batch411/1133, batch loss:0.23685088753700256, Training time:26991.571687221527
batch reward last col mean 0.06659990549087524 first col mean 0.08262878656387329 all mean 0.074080690741539
0.21475426852703094 0.21475426852703094
rl training, epoch8, iter0, batch412/1133, batch loss:0.21475426852703094, Training time:26993.608105421066
batch reward last col mean 0.10267715901136398 first col mean 0.10246570408344269 all mean 0.0998227670788765
0.2701595723628998 0.2701595723628998
rl training, epoch8, iter0, batch413/1133, batch loss:0.2701595723628998, Training time:26995.63965702057
batch reward last col mean 0.09849701821804047 first col mean 0.08047522604465485 all mean 0.09983275085687637
0.28067803382873535 0.28067803382873535
rl training, epoch8, iter0, batch414/1133, batch loss:0.28067803382873535, Training time:26998.16408419609
batch reward last col mean 0.07078517973423004 first col mean 0.07946203649044037 all mean 0.07502028346061707
0.2487907111644745 0.2487907111644745
rl training, epoch8, iter0, batch415/1133, batch loss:0.2487907111644745, Training time:27000.15226125717
batch reward last col mean 0.07827934622764587 first col mean 0.10032875835895538 all mean 0.08496610820293427
0.2831241190433502 0.2831241190433502
rl training, epoch8, iter0, batch416/1133, batch loss:0.2831241190433502, Training time:27002.476840019226
batch reward last col mean 0.08672689646482468 first col mean 0.10090147703886032 all mean 0.08843455463647842
0.2626340687274933 0.2626340687274933
rl training, epoch8, iter0, batch417/1133, batch loss:0.2626340687274933, Training time:27004.456946134567
batch reward last col mean 0.082875557243824 first col mean 0.0929301381111145 all mean 0.0890621542930603
0.23513168096542358 0.23513168096542358
rl training, epoch8, iter0, batch418/1133, batch loss:0.23513168096542358, Training time:27007.069646835327
batch reward last col mean 0.07264789193868637 first col mean 0.09623608738183975 all mean 0.07658647745847702
0.21177856624126434 0.21177856624126434
rl training, epoch8, iter0, batch419/1133, batch loss:0.21177856624126434, Training time:27010.46359729767
batch reward last col mean 0.09613059461116791 first col mean 0.08190089464187622 all mean 0.09740661829710007
0.2391604632139206 0.2391604334115982
rl training, epoch8, iter0, batch420/1133, batch loss:0.2391604334115982, Training time:27013.656713485718
batch reward last col mean 0.09644024074077606 first col mean 0.0965186357498169 all mean 0.10324528813362122
0.2583356201648712 0.2583356499671936
rl training, epoch8, iter0, batch421/1133, batch loss:0.2583356499671936, Training time:27015.88184928894
batch reward last col mean 0.07251596450805664 first col mean 0.08568404614925385 all mean 0.07940300554037094
0.22189489006996155 0.22189489006996155
rl training, epoch8, iter0, batch422/1133, batch loss:0.22189489006996155, Training time:27018.003619909286
batch reward last col mean 0.0768340677022934 first col mean 0.1022053137421608 all mean 0.08493295311927795
0.24588227272033691 0.24588227272033691
rl training, epoch8, iter0, batch423/1133, batch loss:0.24588227272033691, Training time:27019.828532218933
batch reward last col mean 0.07298368215560913 first col mean 0.09440877288579941 all mean 0.08052980899810791
0.2082102745771408 0.2082102745771408
rl training, epoch8, iter0, batch424/1133, batch loss:0.2082102745771408, Training time:27022.679770946503
batch reward last col mean 0.07898016273975372 first col mean 0.10133200883865356 all mean 0.08160176873207092
0.2382257878780365 0.2382257878780365
rl training, epoch8, iter0, batch425/1133, batch loss:0.2382257878780365, Training time:27025.238802433014
batch reward last col mean 0.04966519773006439 first col mean 0.10008794069290161 all mean 0.06261485069990158
0.21264350414276123 0.21264348924160004
rl training, epoch8, iter0, batch426/1133, batch loss:0.21264348924160004, Training time:27027.609832525253
batch reward last col mean 0.09261272102594376 first col mean 0.08846556395292282 all mean 0.08856511861085892
0.25844520330429077 0.25844520330429077
rl training, epoch8, iter0, batch427/1133, batch loss:0.25844520330429077, Training time:27029.7326772213
batch reward last col mean 0.09222471714019775 first col mean 0.095371313393116 all mean 0.09559662640094757
0.24950823187828064 0.24950823187828064
rl training, epoch8, iter0, batch428/1133, batch loss:0.24950823187828064, Training time:27031.79936170578
batch reward last col mean 0.11056312173604965 first col mean 0.11049190908670425 all mean 0.11169743537902832
0.25228217244148254 0.25228220224380493
rl training, epoch8, iter0, batch429/1133, batch loss:0.25228220224380493, Training time:27034.201030492783
batch reward last col mean 0.0837678536772728 first col mean 0.09706585854291916 all mean 0.09136542677879333
0.2668522894382477 0.2668522894382477
rl training, epoch8, iter0, batch430/1133, batch loss:0.2668522894382477, Training time:27036.216274023056
batch reward last col mean 0.09021180868148804 first col mean 0.10136677324771881 all mean 0.09403110295534134
0.23390892148017883 0.23390892148017883
rl training, epoch8, iter0, batch431/1133, batch loss:0.23390892148017883, Training time:27038.95928287506
batch reward last col mean 0.09784704446792603 first col mean 0.10472039133310318 all mean 0.10278593003749847
0.27708932757377625 0.27708932757377625
rl training, epoch8, iter0, batch432/1133, batch loss:0.27708932757377625, Training time:27041.221649885178
batch reward last col mean 0.08400803059339523 first col mean 0.0904003381729126 all mean 0.08798684179782867
0.2464190274477005 0.2464190274477005
rl training, epoch8, iter0, batch433/1133, batch loss:0.2464190274477005, Training time:27043.030687093735
batch reward last col mean 0.08585433661937714 first col mean 0.08311294764280319 all mean 0.09040392190217972
0.2526616156101227 0.2526616156101227
rl training, epoch8, iter0, batch434/1133, batch loss:0.2526616156101227, Training time:27045.022366285324
batch reward last col mean 0.13034461438655853 first col mean 0.10020573437213898 all mean 0.11000936478376389
0.271820068359375 0.271820068359375
rl training, epoch8, iter0, batch435/1133, batch loss:0.271820068359375, Training time:27046.891497135162
batch reward last col mean 0.09730564802885056 first col mean 0.10186602920293808 all mean 0.0963049903512001
0.2822019159793854 0.2822019159793854
rl training, epoch8, iter0, batch436/1133, batch loss:0.2822019159793854, Training time:27049.06368136406
batch reward last col mean 0.09137126803398132 first col mean 0.10079684853553772 all mean 0.09088799357414246
0.2383183091878891 0.2383183091878891
rl training, epoch8, iter0, batch437/1133, batch loss:0.2383183091878891, Training time:27050.794197559357
batch reward last col mean 0.0954771637916565 first col mean 0.09748642146587372 all mean 0.09433665126562119
0.24703575670719147 0.24703575670719147
rl training, epoch8, iter0, batch438/1133, batch loss:0.24703575670719147, Training time:27053.280437469482
batch reward last col mean 0.09543656557798386 first col mean 0.09418603032827377 all mean 0.09489705413579941
0.21674446761608124 0.21674446761608124
rl training, epoch8, iter0, batch439/1133, batch loss:0.21674446761608124, Training time:27055.04440999031
batch reward last col mean 0.0788082480430603 first col mean 0.10448252409696579 all mean 0.07981027662754059
0.2585090696811676 0.2585090696811676
rl training, epoch8, iter0, batch440/1133, batch loss:0.2585090696811676, Training time:27057.07248067856
batch reward last col mean 0.10663782060146332 first col mean 0.08833622932434082 all mean 0.0974838137626648
0.24604803323745728 0.24604803323745728
rl training, epoch8, iter0, batch441/1133, batch loss:0.24604803323745728, Training time:27059.137971401215
batch reward last col mean 0.09398815780878067 first col mean 0.08478301018476486 all mean 0.09015369415283203
0.22829337418079376 0.22829337418079376
rl training, epoch8, iter0, batch442/1133, batch loss:0.22829337418079376, Training time:27061.287831783295
batch reward last col mean 0.11133839190006256 first col mean 0.10941484570503235 all mean 0.10763698816299438
0.25827181339263916 0.25827181339263916
rl training, epoch8, iter0, batch443/1133, batch loss:0.25827181339263916, Training time:27063.088312149048
batch reward last col mean 0.09589648246765137 first col mean 0.08922116458415985 all mean 0.09716232866048813
0.23200498521327972 0.23200498521327972
rl training, epoch8, iter0, batch444/1133, batch loss:0.23200498521327972, Training time:27064.899091959
batch reward last col mean 0.10630777478218079 first col mean 0.08774926513433456 all mean 0.10622665286064148
0.2554713189601898 0.2554713189601898
rl training, epoch8, iter0, batch445/1133, batch loss:0.2554713189601898, Training time:27067.39103603363
batch reward last col mean 0.11821899563074112 first col mean 0.10010802745819092 all mean 0.11383894830942154
0.26924657821655273 0.26924657821655273
rl training, epoch8, iter0, batch446/1133, batch loss:0.26924657821655273, Training time:27069.442719459534
batch reward last col mean 0.10252310335636139 first col mean 0.10849522799253464 all mean 0.09968128800392151
0.24303552508354187 0.24303549528121948
rl training, epoch8, iter0, batch447/1133, batch loss:0.24303549528121948, Training time:27071.310502052307
batch reward last col mean 0.09867970645427704 first col mean 0.10544366389513016 all mean 0.10227039456367493
0.25448885560035706 0.25448885560035706
rl training, epoch8, iter0, batch448/1133, batch loss:0.25448885560035706, Training time:27073.31015563011
batch reward last col mean 0.09542317688465118 first col mean 0.10996422171592712 all mean 0.09060278534889221
0.23143315315246582 0.23143315315246582
rl training, epoch8, iter0, batch449/1133, batch loss:0.23143315315246582, Training time:27074.99279808998
batch reward last col mean 0.09818550199270248 first col mean 0.09740595519542694 all mean 0.09645608812570572
0.2639993727207184 0.2639993727207184
rl training, epoch8, iter0, batch450/1133, batch loss:0.2639993727207184, Training time:27076.64771580696
batch reward last col mean 0.0854315534234047 first col mean 0.10013826936483383 all mean 0.09226824343204498
0.2669258415699005 0.2669258415699005
rl training, epoch8, iter0, batch451/1133, batch loss:0.2669258415699005, Training time:27078.36466526985
batch reward last col mean 0.0970064103603363 first col mean 0.08809366822242737 all mean 0.09529294818639755
0.2419942319393158 0.2419942170381546
rl training, epoch8, iter0, batch452/1133, batch loss:0.2419942170381546, Training time:27080.22740626335
batch reward last col mean 0.07203759998083115 first col mean 0.10211294144392014 all mean 0.0804666206240654
0.23348060250282288 0.23348060250282288
rl training, epoch8, iter0, batch453/1133, batch loss:0.23348060250282288, Training time:27082.197797060013
batch reward last col mean 0.11062982678413391 first col mean 0.11309970170259476 all mean 0.10654865205287933
0.25746840238571167 0.25746840238571167
rl training, epoch8, iter0, batch454/1133, batch loss:0.25746840238571167, Training time:27084.296706676483
batch reward last col mean 0.06758210062980652 first col mean 0.0903267189860344 all mean 0.07376369088888168
0.2282552868127823 0.2282552719116211
rl training, epoch8, iter0, batch455/1133, batch loss:0.2282552719116211, Training time:27086.571833848953
batch reward last col mean 0.06305362284183502 first col mean 0.09949693828821182 all mean 0.07365922629833221
0.21267247200012207 0.21267245709896088
rl training, epoch8, iter0, batch456/1133, batch loss:0.21267245709896088, Training time:27088.464857816696
batch reward last col mean 0.08699463307857513 first col mean 0.09938894957304001 all mean 0.08455484360456467
0.2574245035648346 0.2574245035648346
rl training, epoch8, iter0, batch457/1133, batch loss:0.2574245035648346, Training time:27090.390882253647
batch reward last col mean 0.0800919160246849 first col mean 0.09411010146141052 all mean 0.08209242671728134
0.26234662532806396 0.26234662532806396
rl training, epoch8, iter0, batch458/1133, batch loss:0.26234662532806396, Training time:27092.322712183
batch reward last col mean 0.10677679628133774 first col mean 0.11617742478847504 all mean 0.10669732838869095
0.3067326247692108 0.3067326247692108
rl training, epoch8, iter0, batch459/1133, batch loss:0.3067326247692108, Training time:27094.41170024872
batch reward last col mean 0.10502925515174866 first col mean 0.08976168185472488 all mean 0.09943950921297073
0.2518325448036194 0.2518325448036194
rl training, epoch8, iter0, batch460/1133, batch loss:0.2518325448036194, Training time:27096.961069583893
batch reward last col mean 0.09898294508457184 first col mean 0.09237958490848541 all mean 0.09819333255290985
0.26382407546043396 0.26382410526275635
rl training, epoch8, iter0, batch461/1133, batch loss:0.26382410526275635, Training time:27098.46362543106
batch reward last col mean 0.1040147989988327 first col mean 0.09207699447870255 all mean 0.09928737580776215
0.24551567435264587 0.24551567435264587
rl training, epoch8, iter0, batch462/1133, batch loss:0.24551567435264587, Training time:27100.40251326561
batch reward last col mean 0.07196926325559616 first col mean 0.1042160764336586 all mean 0.08023838698863983
0.2620338201522827 0.2620338201522827
rl training, epoch8, iter0, batch463/1133, batch loss:0.2620338201522827, Training time:27102.51786017418
batch reward last col mean 0.09763792902231216 first col mean 0.10221857577562332 all mean 0.09634208679199219
0.20741453766822815 0.20741453766822815
rl training, epoch8, iter0, batch464/1133, batch loss:0.20741453766822815, Training time:27104.599487304688
batch reward last col mean 0.14435914158821106 first col mean 0.12039069831371307 all mean 0.12962576746940613
0.3027684986591339 0.3027684986591339
rl training, epoch8, iter0, batch465/1133, batch loss:0.3027684986591339, Training time:27106.41555070877
batch reward last col mean 0.09023527801036835 first col mean 0.0970810204744339 all mean 0.09536617249250412
0.2969811260700226 0.2969811260700226
rl training, epoch8, iter0, batch466/1133, batch loss:0.2969811260700226, Training time:27108.36344909668
batch reward last col mean 0.11967650055885315 first col mean 0.11660634726285934 all mean 0.11542198807001114
0.29585176706314087 0.2958517372608185
rl training, epoch8, iter0, batch467/1133, batch loss:0.2958517372608185, Training time:27111.169830083847
batch reward last col mean 0.08522741496562958 first col mean 0.11537345498800278 all mean 0.08955176174640656
0.21904130280017853 0.21904130280017853
rl training, epoch8, iter0, batch468/1133, batch loss:0.21904130280017853, Training time:27113.22039604187
batch reward last col mean 0.10425126552581787 first col mean 0.10155509412288666 all mean 0.10124891996383667
0.2612782120704651 0.2612782120704651
rl training, epoch8, iter0, batch469/1133, batch loss:0.2612782120704651, Training time:27115.02189517021
batch reward last col mean 0.10366322100162506 first col mean 0.11511991173028946 all mean 0.10702098906040192
0.2841116189956665 0.2841116189956665
rl training, epoch8, iter0, batch470/1133, batch loss:0.2841116189956665, Training time:27116.652029037476
batch reward last col mean 0.1114489734172821 first col mean 0.10506885498762131 all mean 0.10630761831998825
0.27955129742622375 0.27955129742622375
rl training, epoch8, iter0, batch471/1133, batch loss:0.27955129742622375, Training time:27119.22591996193
batch reward last col mean 0.08043444901704788 first col mean 0.10389338433742523 all mean 0.0842902809381485
0.27751266956329346 0.27751266956329346
rl training, epoch8, iter0, batch472/1133, batch loss:0.27751266956329346, Training time:27122.12957572937
batch reward last col mean 0.12467670440673828 first col mean 0.09421330690383911 all mean 0.11184501647949219
0.2795517146587372 0.2795517146587372
rl training, epoch8, iter0, batch473/1133, batch loss:0.2795517146587372, Training time:27124.100836277008
batch reward last col mean 0.1070103868842125 first col mean 0.09261990338563919 all mean 0.10813213884830475
0.3310898244380951 0.3310897648334503
rl training, epoch8, iter0, batch474/1133, batch loss:0.3310897648334503, Training time:27126.483461618423
batch reward last col mean 0.09212381392717361 first col mean 0.09451520442962646 all mean 0.0920582190155983
0.2521499693393707 0.2521499693393707
rl training, epoch8, iter0, batch475/1133, batch loss:0.2521499693393707, Training time:27128.372278690338
batch reward last col mean 0.11431249231100082 first col mean 0.11818315088748932 all mean 0.11432656645774841
0.3058794438838959 0.30587947368621826
rl training, epoch8, iter0, batch476/1133, batch loss:0.30587947368621826, Training time:27130.373727321625
batch reward last col mean 0.15528926253318787 first col mean 0.1078576147556305 all mean 0.13495482504367828
0.27108296751976013 0.27108293771743774
rl training, epoch8, iter0, batch477/1133, batch loss:0.27108293771743774, Training time:27132.432463169098
batch reward last col mean 0.11717911064624786 first col mean 0.10717504471540451 all mean 0.10793236643075943
0.2526059150695801 0.2526059150695801
rl training, epoch8, iter0, batch478/1133, batch loss:0.2526059150695801, Training time:27134.92924451828
batch reward last col mean 0.13286036252975464 first col mean 0.10104276239871979 all mean 0.12194133549928665
0.24459215998649597 0.24459217488765717
rl training, epoch8, iter0, batch479/1133, batch loss:0.24459217488765717, Training time:27136.74770092964
batch reward last col mean 0.07987312972545624 first col mean 0.09255720674991608 all mean 0.08447367697954178
0.2348938137292862 0.2348938286304474
rl training, epoch8, iter0, batch480/1133, batch loss:0.2348938286304474, Training time:27139.467319250107
batch reward last col mean 0.06865930557250977 first col mean 0.08569169044494629 all mean 0.07498717308044434
0.23645222187042236 0.23645222187042236
rl training, epoch8, iter0, batch481/1133, batch loss:0.23645222187042236, Training time:27142.133020401
batch reward last col mean 0.09646033495664597 first col mean 0.09696365147829056 all mean 0.0990968644618988
0.2623423635959625 0.2623423635959625
rl training, epoch8, iter0, batch482/1133, batch loss:0.2623423635959625, Training time:27144.544574022293
batch reward last col mean 0.1053135022521019 first col mean 0.09563280642032623 all mean 0.09725531190633774
0.22122807800769806 0.22122807800769806
rl training, epoch8, iter0, batch483/1133, batch loss:0.22122807800769806, Training time:27146.631719589233
batch reward last col mean 0.08591368794441223 first col mean 0.08239385485649109 all mean 0.09058422595262527
0.2590700685977936 0.2590700685977936
rl training, epoch8, iter0, batch484/1133, batch loss:0.2590700685977936, Training time:27148.479822158813
batch reward last col mean 0.14303459227085114 first col mean 0.11374029517173767 all mean 0.13097456097602844
0.2919743061065674 0.2919743061065674
rl training, epoch8, iter0, batch485/1133, batch loss:0.2919743061065674, Training time:27150.23070716858
batch reward last col mean 0.10285396873950958 first col mean 0.08465836942195892 all mean 0.10166902840137482
0.27160966396331787 0.27160966396331787
rl training, epoch8, iter0, batch486/1133, batch loss:0.27160966396331787, Training time:27152.89070868492
batch reward last col mean 0.09484142810106277 first col mean 0.10183067619800568 all mean 0.09586649388074875
0.2874610424041748 0.2874610424041748
rl training, epoch8, iter0, batch487/1133, batch loss:0.2874610424041748, Training time:27155.47326207161
batch reward last col mean 0.06677424907684326 first col mean 0.11422114819288254 all mean 0.07565424591302872
0.21270351111888885 0.21270349621772766
rl training, epoch8, iter0, batch488/1133, batch loss:0.21270349621772766, Training time:27157.244569540024
batch reward last col mean 0.10048992931842804 first col mean 0.1137821227312088 all mean 0.10345190763473511
0.2829357385635376 0.2829357385635376
rl training, epoch8, iter0, batch489/1133, batch loss:0.2829357385635376, Training time:27158.951574087143
batch reward last col mean 0.07975806295871735 first col mean 0.1056424230337143 all mean 0.08915326744318008
0.26084911823272705 0.26084911823272705
rl training, epoch8, iter0, batch490/1133, batch loss:0.26084911823272705, Training time:27160.87973880768
batch reward last col mean 0.09982635080814362 first col mean 0.0859854519367218 all mean 0.09831126779317856
0.22784759104251862 0.22784759104251862
rl training, epoch8, iter0, batch491/1133, batch loss:0.22784759104251862, Training time:27162.912616491318
batch reward last col mean 0.131148099899292 first col mean 0.12178324162960052 all mean 0.12707500159740448
0.326185017824173 0.326185017824173
rl training, epoch8, iter0, batch492/1133, batch loss:0.326185017824173, Training time:27165.848436832428
batch reward last col mean 0.04780066758394241 first col mean 0.11696086078882217 all mean 0.0644935742020607
0.2149706780910492 0.2149706780910492
rl training, epoch8, iter0, batch493/1133, batch loss:0.2149706780910492, Training time:27167.489186525345
batch reward last col mean 0.1009829044342041 first col mean 0.10729048401117325 all mean 0.10183929651975632
0.27499955892562866 0.27499955892562866
rl training, epoch8, iter0, batch494/1133, batch loss:0.27499955892562866, Training time:27169.637013196945
batch reward last col mean 0.10126593708992004 first col mean 0.10258673131465912 all mean 0.10404258966445923
0.2915668189525604 0.2915668189525604
rl training, epoch8, iter0, batch495/1133, batch loss:0.2915668189525604, Training time:27171.804449558258
batch reward last col mean 0.10745200514793396 first col mean 0.10127625614404678 all mean 0.1140417754650116
0.33257192373275757 0.33257192373275757
rl training, epoch8, iter0, batch496/1133, batch loss:0.33257192373275757, Training time:27173.95764541626
batch reward last col mean 0.06605857610702515 first col mean 0.10425740480422974 all mean 0.06986279785633087
0.23538824915885925 0.23538823425769806
rl training, epoch8, iter0, batch497/1133, batch loss:0.23538823425769806, Training time:27177.57790160179
batch reward last col mean 0.09581517428159714 first col mean 0.11680926382541656 all mean 0.0948420837521553
0.2558386027812958 0.2558386027812958
rl training, epoch8, iter0, batch498/1133, batch loss:0.2558386027812958, Training time:27179.94914150238
batch reward last col mean 0.07973428070545197 first col mean 0.12155080586671829 all mean 0.08979345113039017
0.26685425639152527 0.26685425639152527
rl training, epoch8, iter0, batch499/1133, batch loss:0.26685425639152527, Training time:27181.91081237793
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46085129137704145 Time: 100.6026930809021 s
loss of true 0.19753035107941513 loss of gen 0.17115601809779207 loss of other 0.09216492168197617 first score 0.08192038536071777
batch reward last col mean 0.10840043425559998 first col mean 0.09818362444639206 all mean 0.10692855715751648
0.29419708251953125 0.29419711232185364
rl training, epoch8, iter0, batch500/1133, batch loss:0.29419711232185364, Training time:27284.30929493904
batch reward last col mean 0.08472312241792679 first col mean 0.10973677039146423 all mean 0.0891171395778656
0.22812995314598083 0.22812993824481964
rl training, epoch8, iter0, batch501/1133, batch loss:0.22812993824481964, Training time:27286.517555713654
batch reward last col mean 0.13216820359230042 first col mean 0.11168232560157776 all mean 0.1235167533159256
0.28126075863838196 0.28126075863838196
rl training, epoch8, iter0, batch502/1133, batch loss:0.28126075863838196, Training time:27288.43959927559
batch reward last col mean 0.08284291625022888 first col mean 0.09697483479976654 all mean 0.09126754850149155
0.26010969281196594 0.26010969281196594
rl training, epoch8, iter0, batch503/1133, batch loss:0.26010969281196594, Training time:27290.79898905754
batch reward last col mean 0.11328496038913727 first col mean 0.10875250399112701 all mean 0.1099405363202095
0.2667587101459503 0.2667587101459503
rl training, epoch8, iter0, batch504/1133, batch loss:0.2667587101459503, Training time:27292.920714616776
batch reward last col mean 0.12478749454021454 first col mean 0.10692282766103745 all mean 0.11336426436901093
0.26019927859306335 0.26019927859306335
rl training, epoch8, iter0, batch505/1133, batch loss:0.26019927859306335, Training time:27294.89155769348
batch reward last col mean 0.09662393480539322 first col mean 0.10017475485801697 all mean 0.09999100863933563
0.26494869589805603 0.26494869589805603
rl training, epoch8, iter0, batch506/1133, batch loss:0.26494869589805603, Training time:27296.92913031578
batch reward last col mean 0.10467968881130219 first col mean 0.09320133179426193 all mean 0.10431436449289322
0.2844650447368622 0.2844650149345398
rl training, epoch8, iter0, batch507/1133, batch loss:0.2844650149345398, Training time:27300.208264112473
batch reward last col mean 0.09710142016410828 first col mean 0.10365473479032516 all mean 0.10069428384304047
0.26229244470596313 0.26229244470596313
rl training, epoch8, iter0, batch508/1133, batch loss:0.26229244470596313, Training time:27302.085517644882
batch reward last col mean 0.09739676117897034 first col mean 0.1051330417394638 all mean 0.10163424164056778
0.27604371309280396 0.27604371309280396
rl training, epoch8, iter0, batch509/1133, batch loss:0.27604371309280396, Training time:27304.339588165283
batch reward last col mean 0.10552909970283508 first col mean 0.12624305486679077 all mean 0.10553435236215591
0.2610788643360138 0.2610788643360138
rl training, epoch8, iter0, batch510/1133, batch loss:0.2610788643360138, Training time:27306.311094522476
batch reward last col mean 0.11894060671329498 first col mean 0.11518069356679916 all mean 0.11686287075281143
0.255443274974823 0.255443274974823
rl training, epoch8, iter0, batch511/1133, batch loss:0.255443274974823, Training time:27309.05691766739
batch reward last col mean 0.10171716660261154 first col mean 0.09184645116329193 all mean 0.1034875139594078
0.26081421971321106 0.26081421971321106
rl training, epoch8, iter0, batch512/1133, batch loss:0.26081421971321106, Training time:27310.99938058853
batch reward last col mean 0.1384565234184265 first col mean 0.12464238703250885 all mean 0.13570190966129303
0.39162200689315796 0.39162200689315796
rl training, epoch8, iter0, batch513/1133, batch loss:0.39162200689315796, Training time:27313.15753507614
batch reward last col mean 0.10255464911460876 first col mean 0.0959005206823349 all mean 0.10050057619810104
0.2678239643573761 0.2678239345550537
rl training, epoch8, iter0, batch514/1133, batch loss:0.2678239345550537, Training time:27315.167914152145
batch reward last col mean 0.09594928473234177 first col mean 0.11882364749908447 all mean 0.10089251399040222
0.26804888248443604 0.26804888248443604
rl training, epoch8, iter0, batch515/1133, batch loss:0.26804888248443604, Training time:27317.696952581406
batch reward last col mean 0.09676583111286163 first col mean 0.09125978499650955 all mean 0.09633788466453552
0.2601381540298462 0.2601381540298462
rl training, epoch8, iter0, batch516/1133, batch loss:0.2601381540298462, Training time:27320.757215738297
batch reward last col mean 0.11305845528841019 first col mean 0.10684369504451752 all mean 0.11893700808286667
0.3279801905155182 0.3279801905155182
rl training, epoch8, iter0, batch517/1133, batch loss:0.3279801905155182, Training time:27322.56339740753
batch reward last col mean 0.12792304158210754 first col mean 0.1140734925866127 all mean 0.12462327629327774
0.29075488448143005 0.29075488448143005
rl training, epoch8, iter0, batch518/1133, batch loss:0.29075488448143005, Training time:27325.016615390778
batch reward last col mean 0.10781228542327881 first col mean 0.10498716682195663 all mean 0.10900333523750305
0.29123884439468384 0.29123884439468384
rl training, epoch8, iter0, batch519/1133, batch loss:0.29123884439468384, Training time:27327.15838599205
batch reward last col mean 0.10734695941209793 first col mean 0.12568402290344238 all mean 0.10662689805030823
0.3089790344238281 0.3089790344238281
rl training, epoch8, iter0, batch520/1133, batch loss:0.3089790344238281, Training time:27330.666546344757
batch reward last col mean 0.09701447933912277 first col mean 0.10907004773616791 all mean 0.10233902931213379
0.26529592275619507 0.26529592275619507
rl training, epoch8, iter0, batch521/1133, batch loss:0.26529592275619507, Training time:27332.986337184906
batch reward last col mean 0.08023719489574432 first col mean 0.1017608493566513 all mean 0.08735255897045135
0.2437337338924408 0.2437337338924408
rl training, epoch8, iter0, batch522/1133, batch loss:0.2437337338924408, Training time:27334.83821296692
batch reward last col mean 0.1117570549249649 first col mean 0.11866960674524307 all mean 0.10753251612186432
0.26434648036956787 0.2643464505672455
rl training, epoch8, iter0, batch523/1133, batch loss:0.2643464505672455, Training time:27337.285386800766
batch reward last col mean 0.12463301420211792 first col mean 0.09577129036188126 all mean 0.1222008690237999
0.32362857460975647 0.32362857460975647
rl training, epoch8, iter0, batch524/1133, batch loss:0.32362857460975647, Training time:27340.37397480011
batch reward last col mean 0.1037481427192688 first col mean 0.10625161975622177 all mean 0.11168697476387024
0.32404017448425293 0.32404017448425293
rl training, epoch8, iter0, batch525/1133, batch loss:0.32404017448425293, Training time:27342.92411184311
batch reward last col mean 0.08227803558111191 first col mean 0.12084780633449554 all mean 0.08909432590007782
0.2889249920845032 0.2889249920845032
rl training, epoch8, iter0, batch526/1133, batch loss:0.2889249920845032, Training time:27345.115314245224
batch reward last col mean 0.125855952501297 first col mean 0.11238688975572586 all mean 0.12438682466745377
0.3124478757381439 0.3124478757381439
rl training, epoch8, iter0, batch527/1133, batch loss:0.3124478757381439, Training time:27347.15594625473
batch reward last col mean 0.12856769561767578 first col mean 0.0955340638756752 all mean 0.11903717368841171
0.2693289518356323 0.2693289518356323
rl training, epoch8, iter0, batch528/1133, batch loss:0.2693289518356323, Training time:27349.24446129799
batch reward last col mean 0.11057043820619583 first col mean 0.11074521392583847 all mean 0.11133863776922226
0.285954087972641 0.285954087972641
rl training, epoch8, iter0, batch529/1133, batch loss:0.285954087972641, Training time:27351.01615023613
batch reward last col mean 0.15528640151023865 first col mean 0.10877520591020584 all mean 0.1496802419424057
0.29975879192352295 0.29975879192352295
rl training, epoch8, iter0, batch530/1133, batch loss:0.29975879192352295, Training time:27353.302257061005
batch reward last col mean 0.117800273001194 first col mean 0.11009161919355392 all mean 0.11798147112131119
0.33013030886650085 0.33013030886650085
rl training, epoch8, iter0, batch531/1133, batch loss:0.33013030886650085, Training time:27355.308923482895
batch reward last col mean 0.09614528715610504 first col mean 0.10949541628360748 all mean 0.09651464223861694
0.2697336971759796 0.2697336971759796
rl training, epoch8, iter0, batch532/1133, batch loss:0.2697336971759796, Training time:27357.2558760643
batch reward last col mean 0.10516871511936188 first col mean 0.11129837483167648 all mean 0.11004219204187393
0.2698906660079956 0.2698906660079956
rl training, epoch8, iter0, batch533/1133, batch loss:0.2698906660079956, Training time:27359.152027606964
batch reward last col mean 0.12089813500642776 first col mean 0.11901608854532242 all mean 0.11811999976634979
0.2823199927806854 0.2823199927806854
rl training, epoch8, iter0, batch534/1133, batch loss:0.2823199927806854, Training time:27361.3991856575
batch reward last col mean 0.1093478724360466 first col mean 0.10616233944892883 all mean 0.10895605385303497
0.2946432828903198 0.2946432828903198
rl training, epoch8, iter0, batch535/1133, batch loss:0.2946432828903198, Training time:27363.289052248
batch reward last col mean 0.10807928442955017 first col mean 0.11063452064990997 all mean 0.10362254083156586
0.2997635304927826 0.2997635304927826
rl training, epoch8, iter0, batch536/1133, batch loss:0.2997635304927826, Training time:27365.267550468445
batch reward last col mean 0.12247179448604584 first col mean 0.11558530479669571 all mean 0.11369000375270844
0.2828657329082489 0.2828657329082489
rl training, epoch8, iter0, batch537/1133, batch loss:0.2828657329082489, Training time:27366.80103969574
batch reward last col mean 0.07622197270393372 first col mean 0.11991097033023834 all mean 0.086171954870224
0.22702980041503906 0.22702980041503906
rl training, epoch8, iter0, batch538/1133, batch loss:0.22702980041503906, Training time:27368.669908761978
batch reward last col mean 0.0882103368639946 first col mean 0.12351661175489426 all mean 0.09013912826776505
0.2836011052131653 0.2836011052131653
rl training, epoch8, iter0, batch539/1133, batch loss:0.2836011052131653, Training time:27370.384454727173
batch reward last col mean 0.08953607827425003 first col mean 0.11275944113731384 all mean 0.09670539200305939
0.2612107992172241 0.2612107992172241
rl training, epoch8, iter0, batch540/1133, batch loss:0.2612107992172241, Training time:27372.16507101059
batch reward last col mean 0.08462878316640854 first col mean 0.10760445892810822 all mean 0.09002070873975754
0.2677992582321167 0.2677992582321167
rl training, epoch8, iter0, batch541/1133, batch loss:0.2677992582321167, Training time:27373.97465777397
batch reward last col mean 0.11798703670501709 first col mean 0.11760290712118149 all mean 0.12278944998979568
0.3137975037097931 0.3137975037097931
rl training, epoch8, iter0, batch542/1133, batch loss:0.3137975037097931, Training time:27375.949262857437
batch reward last col mean 0.1415848433971405 first col mean 0.11000202596187592 all mean 0.13340768218040466
0.2908993065357208 0.2908993065357208
rl training, epoch8, iter0, batch543/1133, batch loss:0.2908993065357208, Training time:27378.28958106041
batch reward last col mean 0.10875827074050903 first col mean 0.11134641617536545 all mean 0.10655848681926727
0.28423914313316345 0.28423914313316345
rl training, epoch8, iter0, batch544/1133, batch loss:0.28423914313316345, Training time:27380.33654999733
batch reward last col mean 0.1243693009018898 first col mean 0.12796512246131897 all mean 0.11496919393539429
0.2788974940776825 0.2788974940776825
rl training, epoch8, iter0, batch545/1133, batch loss:0.2788974940776825, Training time:27382.169125795364
batch reward last col mean 0.12989358603954315 first col mean 0.10244398564100266 all mean 0.12196394056081772
0.26737892627716064 0.26737892627716064
rl training, epoch8, iter0, batch546/1133, batch loss:0.26737892627716064, Training time:27384.395342111588
batch reward last col mean 0.11831808090209961 first col mean 0.09816310554742813 all mean 0.1215594932436943
0.29380181431770325 0.29380181431770325
rl training, epoch8, iter0, batch547/1133, batch loss:0.29380181431770325, Training time:27386.087364196777
batch reward last col mean 0.12123901396989822 first col mean 0.11150689423084259 all mean 0.11740102618932724
0.26473405957221985 0.26473405957221985
rl training, epoch8, iter0, batch548/1133, batch loss:0.26473405957221985, Training time:27387.916202545166
batch reward last col mean 0.10163301229476929 first col mean 0.10284173488616943 all mean 0.09938520193099976
0.27849239110946655 0.27849239110946655
rl training, epoch8, iter0, batch549/1133, batch loss:0.27849239110946655, Training time:27389.69216299057
batch reward last col mean 0.08189567178487778 first col mean 0.10037542879581451 all mean 0.09071658551692963
0.27160385251045227 0.2716038227081299
rl training, epoch8, iter0, batch550/1133, batch loss:0.2716038227081299, Training time:27391.600685596466
batch reward last col mean 0.08117762953042984 first col mean 0.09694206714630127 all mean 0.08675159513950348
0.28309711813926697 0.28309711813926697
rl training, epoch8, iter0, batch551/1133, batch loss:0.28309711813926697, Training time:27393.586514234543
batch reward last col mean 0.06825399398803711 first col mean 0.12569376826286316 all mean 0.07700498402118683
0.24870198965072632 0.24870198965072632
rl training, epoch8, iter0, batch552/1133, batch loss:0.24870198965072632, Training time:27396.986348628998
batch reward last col mean 0.12583184242248535 first col mean 0.11265319585800171 all mean 0.11810106039047241
0.2466602623462677 0.2466602772474289
rl training, epoch8, iter0, batch553/1133, batch loss:0.2466602772474289, Training time:27398.859870672226
batch reward last col mean 0.1016269102692604 first col mean 0.11426164209842682 all mean 0.10078804939985275
0.2785918712615967 0.2785918712615967
rl training, epoch8, iter0, batch554/1133, batch loss:0.2785918712615967, Training time:27400.48061108589
batch reward last col mean 0.07155804336071014 first col mean 0.10992845147848129 all mean 0.08002343028783798
0.26328161358833313 0.26328161358833313
rl training, epoch8, iter0, batch555/1133, batch loss:0.26328161358833313, Training time:27402.76351571083
batch reward last col mean 0.09150904417037964 first col mean 0.10043385624885559 all mean 0.09962688386440277
0.266561359167099 0.266561359167099
rl training, epoch8, iter0, batch556/1133, batch loss:0.266561359167099, Training time:27404.482157945633
batch reward last col mean 0.11375191807746887 first col mean 0.10778902471065521 all mean 0.11534536629915237
0.28794538974761963 0.28794538974761963
rl training, epoch8, iter0, batch557/1133, batch loss:0.28794538974761963, Training time:27406.32742667198
batch reward last col mean 0.09819018095731735 first col mean 0.11063724011182785 all mean 0.10827363282442093
0.3097279667854309 0.3097279667854309
rl training, epoch8, iter0, batch558/1133, batch loss:0.3097279667854309, Training time:27408.153005361557
batch reward last col mean 0.10914569348096848 first col mean 0.09605583548545837 all mean 0.10922373086214066
0.24602998793125153 0.24602998793125153
rl training, epoch8, iter0, batch559/1133, batch loss:0.24602998793125153, Training time:27409.93448972702
batch reward last col mean 0.08663014322519302 first col mean 0.10624164342880249 all mean 0.0934971421957016
0.27333277463912964 0.27333277463912964
rl training, epoch8, iter0, batch560/1133, batch loss:0.27333277463912964, Training time:27412.310618162155
batch reward last col mean 0.11238722503185272 first col mean 0.11613628268241882 all mean 0.10722483694553375
0.2626758813858032 0.2626758813858032
rl training, epoch8, iter0, batch561/1133, batch loss:0.2626758813858032, Training time:27414.027416706085
batch reward last col mean 0.08057747036218643 first col mean 0.12371760606765747 all mean 0.09021659940481186
0.25914937257766724 0.25914937257766724
rl training, epoch8, iter0, batch562/1133, batch loss:0.25914937257766724, Training time:27416.328622817993
batch reward last col mean 0.0948336124420166 first col mean 0.11208395659923553 all mean 0.09139306098222733
0.23767328262329102 0.23767328262329102
rl training, epoch8, iter0, batch563/1133, batch loss:0.23767328262329102, Training time:27418.22683238983
batch reward last col mean 0.0893133282661438 first col mean 0.10335522145032883 all mean 0.09005703777074814
0.2564941942691803 0.2564941942691803
rl training, epoch8, iter0, batch564/1133, batch loss:0.2564941942691803, Training time:27420.235948085785
batch reward last col mean 0.13077981770038605 first col mean 0.13436436653137207 all mean 0.1304139643907547
0.2711149752140045 0.2711149752140045
rl training, epoch8, iter0, batch565/1133, batch loss:0.2711149752140045, Training time:27422.43182349205
batch reward last col mean 0.1311257779598236 first col mean 0.09596683084964752 all mean 0.13188911974430084
0.2998538911342621 0.2998538911342621
rl training, epoch8, iter0, batch566/1133, batch loss:0.2998538911342621, Training time:27425.04155778885
batch reward last col mean 0.08519118279218674 first col mean 0.10128231346607208 all mean 0.08877269923686981
0.22838644683361053 0.22838644683361053
rl training, epoch8, iter0, batch567/1133, batch loss:0.22838644683361053, Training time:27427.696131706238
batch reward last col mean 0.14123959839344025 first col mean 0.0992208868265152 all mean 0.13476406037807465
0.2986346185207367 0.2986346185207367
rl training, epoch8, iter0, batch568/1133, batch loss:0.2986346185207367, Training time:27429.622084617615
batch reward last col mean 0.08937937021255493 first col mean 0.09798499196767807 all mean 0.08938702940940857
0.24402877688407898 0.24402877688407898
rl training, epoch8, iter0, batch569/1133, batch loss:0.24402877688407898, Training time:27431.972878456116
batch reward last col mean 0.1018880158662796 first col mean 0.09751308709383011 all mean 0.09878891706466675
0.25998663902282715 0.25998663902282715
rl training, epoch8, iter0, batch570/1133, batch loss:0.25998663902282715, Training time:27433.76905155182
batch reward last col mean 0.10756385326385498 first col mean 0.10718382894992828 all mean 0.10626517236232758
0.2837393283843994 0.2837393283843994
rl training, epoch8, iter0, batch571/1133, batch loss:0.2837393283843994, Training time:27436.01287841797
batch reward last col mean 0.08072419464588165 first col mean 0.0970754474401474 all mean 0.09182263910770416
0.3101012110710144 0.3101012110710144
rl training, epoch8, iter0, batch572/1133, batch loss:0.3101012110710144, Training time:27437.86175584793
batch reward last col mean 0.10413581132888794 first col mean 0.10400725156068802 all mean 0.10088668763637543
0.3170323967933655 0.3170323967933655
rl training, epoch8, iter0, batch573/1133, batch loss:0.3170323967933655, Training time:27440.15806388855
batch reward last col mean 0.12117232382297516 first col mean 0.10984349995851517 all mean 0.1190861314535141
0.30392390489578247 0.3039238750934601
rl training, epoch8, iter0, batch574/1133, batch loss:0.3039238750934601, Training time:27442.192566156387
batch reward last col mean 0.10044775903224945 first col mean 0.13074468076229095 all mean 0.1059146448969841
0.26858624815940857 0.26858624815940857
rl training, epoch8, iter0, batch575/1133, batch loss:0.26858624815940857, Training time:27443.851642131805
batch reward last col mean 0.12872710824012756 first col mean 0.10719341784715652 all mean 0.12123658508062363
0.29522982239723206 0.29522982239723206
rl training, epoch8, iter0, batch576/1133, batch loss:0.29522982239723206, Training time:27445.853298187256
batch reward last col mean 0.0944531038403511 first col mean 0.09927411377429962 all mean 0.0956498384475708
0.2763268053531647 0.2763268053531647
rl training, epoch8, iter0, batch577/1133, batch loss:0.2763268053531647, Training time:27448.07966518402
batch reward last col mean 0.11812393367290497 first col mean 0.1158364787697792 all mean 0.11500139534473419
0.23351052403450012 0.23351052403450012
rl training, epoch8, iter0, batch578/1133, batch loss:0.23351052403450012, Training time:27450.888864278793
batch reward last col mean 0.11714454740285873 first col mean 0.09862115979194641 all mean 0.11911937594413757
0.26532816886901855 0.26532816886901855
rl training, epoch8, iter0, batch579/1133, batch loss:0.26532816886901855, Training time:27453.49781847
batch reward last col mean 0.08634988218545914 first col mean 0.10349909216165543 all mean 0.09345222264528275
0.24826373159885406 0.24826373159885406
rl training, epoch8, iter0, batch580/1133, batch loss:0.24826373159885406, Training time:27455.502573251724
batch reward last col mean 0.13000839948654175 first col mean 0.09250227361917496 all mean 0.12238988280296326
0.2991024851799011 0.2991024851799011
rl training, epoch8, iter0, batch581/1133, batch loss:0.2991024851799011, Training time:27457.320921182632
batch reward last col mean 0.13883629441261292 first col mean 0.11076896637678146 all mean 0.13173146545886993
0.2916434705257416 0.2916434705257416
rl training, epoch8, iter0, batch582/1133, batch loss:0.2916434705257416, Training time:27459.839522600174
batch reward last col mean 0.08635401725769043 first col mean 0.11477525532245636 all mean 0.09309528023004532
0.2662481367588043 0.2662481367588043
rl training, epoch8, iter0, batch583/1133, batch loss:0.2662481367588043, Training time:27461.82268166542
batch reward last col mean 0.0794326663017273 first col mean 0.11069028079509735 all mean 0.08698047697544098
0.2503308653831482 0.2503308653831482
rl training, epoch8, iter0, batch584/1133, batch loss:0.2503308653831482, Training time:27463.59536075592
batch reward last col mean 0.09345544874668121 first col mean 0.10641520470380783 all mean 0.09543362259864807
0.26600661873817444 0.2660066485404968
rl training, epoch8, iter0, batch585/1133, batch loss:0.2660066485404968, Training time:27465.960527181625
batch reward last col mean 0.10162916779518127 first col mean 0.09461753070354462 all mean 0.10579857975244522
0.2796943783760071 0.2796943783760071
rl training, epoch8, iter0, batch586/1133, batch loss:0.2796943783760071, Training time:27467.605400800705
batch reward last col mean 0.09643234312534332 first col mean 0.09677788615226746 all mean 0.1008627861738205
0.31616488099098206 0.31616488099098206
rl training, epoch8, iter0, batch587/1133, batch loss:0.31616488099098206, Training time:27469.898560523987
batch reward last col mean 0.12448139488697052 first col mean 0.11351587623357773 all mean 0.11596162617206573
0.29345598816871643 0.29345598816871643
rl training, epoch8, iter0, batch588/1133, batch loss:0.29345598816871643, Training time:27471.956387758255
batch reward last col mean 0.10445915162563324 first col mean 0.11989527195692062 all mean 0.10970254242420197
0.2912144958972931 0.2912144958972931
rl training, epoch8, iter0, batch589/1133, batch loss:0.2912144958972931, Training time:27474.047806978226
batch reward last col mean 0.10039502382278442 first col mean 0.11969049274921417 all mean 0.10003149509429932
0.27448588609695435 0.27448588609695435
rl training, epoch8, iter0, batch590/1133, batch loss:0.27448588609695435, Training time:27475.753350257874
batch reward last col mean 0.08967263251543045 first col mean 0.09438668191432953 all mean 0.0967339351773262
0.2465430200099945 0.2465430200099945
rl training, epoch8, iter0, batch591/1133, batch loss:0.2465430200099945, Training time:27477.90516090393
batch reward last col mean 0.07682731747627258 first col mean 0.1050461158156395 all mean 0.08887515217065811
0.27684253454208374 0.27684253454208374
rl training, epoch8, iter0, batch592/1133, batch loss:0.27684253454208374, Training time:27480.006491184235
batch reward last col mean 0.08420583605766296 first col mean 0.1237713098526001 all mean 0.09105762094259262
0.28733766078948975 0.28733763098716736
rl training, epoch8, iter0, batch593/1133, batch loss:0.28733763098716736, Training time:27481.809079647064
batch reward last col mean 0.0925908088684082 first col mean 0.11844032257795334 all mean 0.10325013846158981
0.2939032018184662 0.2939032018184662
rl training, epoch8, iter0, batch594/1133, batch loss:0.2939032018184662, Training time:27483.838881015778
batch reward last col mean 0.06337738782167435 first col mean 0.10135479271411896 all mean 0.07341082394123077
0.20305125415325165 0.20305125415325165
rl training, epoch8, iter0, batch595/1133, batch loss:0.20305125415325165, Training time:27485.699899435043
batch reward last col mean 0.09961718320846558 first col mean 0.1057809367775917 all mean 0.09930483251810074
0.26643556356430054 0.26643556356430054
rl training, epoch8, iter0, batch596/1133, batch loss:0.26643556356430054, Training time:27487.32930803299
batch reward last col mean 0.0927344411611557 first col mean 0.12739942967891693 all mean 0.09794837981462479
0.26517173647880554 0.26517173647880554
rl training, epoch8, iter0, batch597/1133, batch loss:0.26517173647880554, Training time:27489.42755126953
batch reward last col mean 0.1115061342716217 first col mean 0.10290947556495667 all mean 0.10868460685014725
0.29668331146240234 0.29668331146240234
rl training, epoch8, iter0, batch598/1133, batch loss:0.29668331146240234, Training time:27491.411250591278
batch reward last col mean 0.12274879962205887 first col mean 0.10921888053417206 all mean 0.11755451560020447
0.2917134165763855 0.2917134165763855
rl training, epoch8, iter0, batch599/1133, batch loss:0.2917134165763855, Training time:27493.450617551804
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46002903478080365 Time: 99.5459189414978 s
loss of true 0.19809548426600335 loss of gen 0.16812568282197243 loss of other 0.09380786871046012 first score 0.11655498296022415
batch reward last col mean 0.09528066217899323 first col mean 0.10281914472579956 all mean 0.0975048840045929
0.25098559260368347 0.25098559260368347
rl training, epoch8, iter0, batch600/1133, batch loss:0.25098559260368347, Training time:27594.89071249962
batch reward last col mean 0.09739266335964203 first col mean 0.1123548299074173 all mean 0.10434514284133911
0.2529914975166321 0.2529914975166321
rl training, epoch8, iter0, batch601/1133, batch loss:0.2529914975166321, Training time:27596.87439441681
batch reward last col mean 0.09619969874620438 first col mean 0.10134458541870117 all mean 0.09833192825317383
0.24246543645858765 0.24246545135974884
rl training, epoch8, iter0, batch602/1133, batch loss:0.24246545135974884, Training time:27598.88133788109
batch reward last col mean 0.10317044705152512 first col mean 0.09008315205574036 all mean 0.10166247934103012
0.2649635076522827 0.2649635076522827
rl training, epoch8, iter0, batch603/1133, batch loss:0.2649635076522827, Training time:27600.50559234619
batch reward last col mean 0.13937416672706604 first col mean 0.11374342441558838 all mean 0.1258930265903473
0.3103915750980377 0.3103915750980377
rl training, epoch8, iter0, batch604/1133, batch loss:0.3103915750980377, Training time:27602.569541692734
batch reward last col mean 0.08299410343170166 first col mean 0.1114933043718338 all mean 0.09279688447713852
0.26063069701194763 0.26063069701194763
rl training, epoch8, iter0, batch605/1133, batch loss:0.26063069701194763, Training time:27604.643651247025
batch reward last col mean 0.12047970294952393 first col mean 0.09923045337200165 all mean 0.1142842173576355
0.2572082281112671 0.2572082281112671
rl training, epoch8, iter0, batch606/1133, batch loss:0.2572082281112671, Training time:27606.59826183319
batch reward last col mean 0.10316493362188339 first col mean 0.10731634497642517 all mean 0.10600430518388748
0.26542702317237854 0.26542702317237854
rl training, epoch8, iter0, batch607/1133, batch loss:0.26542702317237854, Training time:27608.813124895096
batch reward last col mean 0.09349984675645828 first col mean 0.0979587584733963 all mean 0.10344542562961578
0.29981130361557007 0.2998112738132477
rl training, epoch8, iter0, batch608/1133, batch loss:0.2998112738132477, Training time:27610.396054267883
batch reward last col mean 0.10371741652488708 first col mean 0.1016438901424408 all mean 0.10429606586694717
0.2721490263938904 0.2721490263938904
rl training, epoch8, iter0, batch609/1133, batch loss:0.2721490263938904, Training time:27611.984112262726
batch reward last col mean 0.08991122245788574 first col mean 0.09226587414741516 all mean 0.09586343169212341
0.25463923811912537 0.25463923811912537
rl training, epoch8, iter0, batch610/1133, batch loss:0.25463923811912537, Training time:27613.655440807343
batch reward last col mean 0.08106333017349243 first col mean 0.09027653932571411 all mean 0.08463801443576813
0.25459742546081543 0.25459742546081543
rl training, epoch8, iter0, batch611/1133, batch loss:0.25459742546081543, Training time:27615.469554901123
batch reward last col mean 0.08919303119182587 first col mean 0.09625919163227081 all mean 0.08903532475233078
0.22273540496826172 0.22273540496826172
rl training, epoch8, iter0, batch612/1133, batch loss:0.22273540496826172, Training time:27617.129811286926
batch reward last col mean 0.09196220338344574 first col mean 0.10106799006462097 all mean 0.09434439986944199
0.21922148764133453 0.21922147274017334
rl training, epoch8, iter0, batch613/1133, batch loss:0.21922147274017334, Training time:27619.703940868378
batch reward last col mean 0.11357314884662628 first col mean 0.09305727481842041 all mean 0.10378474742174149
0.24917399883270264 0.24917399883270264
rl training, epoch8, iter0, batch614/1133, batch loss:0.24917399883270264, Training time:27621.37590289116
batch reward last col mean 0.08089527487754822 first col mean 0.1105063408613205 all mean 0.08665862679481506
0.24963916838169098 0.24963916838169098
rl training, epoch8, iter0, batch615/1133, batch loss:0.24963916838169098, Training time:27623.308688879013
batch reward last col mean 0.08856088668107986 first col mean 0.10686375200748444 all mean 0.09898123890161514
0.2780448794364929 0.2780448794364929
rl training, epoch8, iter0, batch616/1133, batch loss:0.2780448794364929, Training time:27625.030207395554
batch reward last col mean 0.11271022260189056 first col mean 0.11640176922082901 all mean 0.1083812564611435
0.2707066535949707 0.2707066535949707
rl training, epoch8, iter0, batch617/1133, batch loss:0.2707066535949707, Training time:27627.66644692421
batch reward last col mean 0.10420383512973785 first col mean 0.12441259622573853 all mean 0.10394171625375748
0.27590399980545044 0.27590399980545044
rl training, epoch8, iter0, batch618/1133, batch loss:0.27590399980545044, Training time:27629.65951514244
batch reward last col mean 0.08668089658021927 first col mean 0.09487517923116684 all mean 0.08900682628154755
0.23639152944087982 0.23639152944087982
rl training, epoch8, iter0, batch619/1133, batch loss:0.23639152944087982, Training time:27632.13387942314
batch reward last col mean 0.12480540573596954 first col mean 0.11661441624164581 all mean 0.1183374896645546
0.2878245711326599 0.2878245711326599
rl training, epoch8, iter0, batch620/1133, batch loss:0.2878245711326599, Training time:27634.540609121323
batch reward last col mean 0.1253892183303833 first col mean 0.11586229503154755 all mean 0.11953124403953552
0.3058251738548279 0.3058251738548279
rl training, epoch8, iter0, batch621/1133, batch loss:0.3058251738548279, Training time:27636.70095515251
batch reward last col mean 0.07376311719417572 first col mean 0.10085177421569824 all mean 0.0809997096657753
0.23180875182151794 0.23180876672267914
rl training, epoch8, iter0, batch622/1133, batch loss:0.23180876672267914, Training time:27638.924711465836
batch reward last col mean 0.12382711470127106 first col mean 0.10824796557426453 all mean 0.1229453831911087
0.3247862160205841 0.3247862160205841
rl training, epoch8, iter0, batch623/1133, batch loss:0.3247862160205841, Training time:27640.527032136917
batch reward last col mean 0.07492213696241379 first col mean 0.10900510847568512 all mean 0.08499739319086075
0.242424875497818 0.2424248605966568
rl training, epoch8, iter0, batch624/1133, batch loss:0.2424248605966568, Training time:27642.524342298508
batch reward last col mean 0.07956628501415253 first col mean 0.10110010951757431 all mean 0.08481525629758835
0.26290154457092285 0.26290154457092285
rl training, epoch8, iter0, batch625/1133, batch loss:0.26290154457092285, Training time:27644.841591835022
batch reward last col mean 0.14876917004585266 first col mean 0.1190066784620285 all mean 0.1317204385995865
0.32315143942832947 0.32315143942832947
rl training, epoch8, iter0, batch626/1133, batch loss:0.32315143942832947, Training time:27646.65364074707
batch reward last col mean 0.1218387633562088 first col mean 0.11368107795715332 all mean 0.11475049704313278
0.2564237713813782 0.2564237713813782
rl training, epoch8, iter0, batch627/1133, batch loss:0.2564237713813782, Training time:27648.699736356735
batch reward last col mean 0.10364090651273727 first col mean 0.11253918707370758 all mean 0.10567717999219894
0.264232337474823 0.264232337474823
rl training, epoch8, iter0, batch628/1133, batch loss:0.264232337474823, Training time:27650.484696626663
batch reward last col mean 0.06769601255655289 first col mean 0.11160969734191895 all mean 0.08062466233968735
0.25506505370140076 0.25506502389907837
rl training, epoch8, iter0, batch629/1133, batch loss:0.25506502389907837, Training time:27652.559628248215
batch reward last col mean 0.09652360528707504 first col mean 0.11075103282928467 all mean 0.1008458063006401
0.2616541385650635 0.2616541385650635
rl training, epoch8, iter0, batch630/1133, batch loss:0.2616541385650635, Training time:27654.092955827713
batch reward last col mean 0.10624963790178299 first col mean 0.09851541370153427 all mean 0.11363217979669571
0.31066060066223145 0.31066060066223145
rl training, epoch8, iter0, batch631/1133, batch loss:0.31066060066223145, Training time:27656.31029701233
batch reward last col mean 0.12029197067022324 first col mean 0.11062130331993103 all mean 0.11327876895666122
0.29108914732933044 0.29108914732933044
rl training, epoch8, iter0, batch632/1133, batch loss:0.29108914732933044, Training time:27658.3362095356
batch reward last col mean 0.10598130524158478 first col mean 0.10612253844738007 all mean 0.09777163714170456
0.2710968852043152 0.2710968852043152
rl training, epoch8, iter0, batch633/1133, batch loss:0.2710968852043152, Training time:27660.178278684616
batch reward last col mean 0.11414260417222977 first col mean 0.10590407252311707 all mean 0.11431089788675308
0.3071649670600891 0.3071649670600891
rl training, epoch8, iter0, batch634/1133, batch loss:0.3071649670600891, Training time:27662.945575237274
batch reward last col mean 0.08267703652381897 first col mean 0.10249466449022293 all mean 0.09084364771842957
0.30683937668800354 0.30683934688568115
rl training, epoch8, iter0, batch635/1133, batch loss:0.30683934688568115, Training time:27665.388588905334
batch reward last col mean 0.08768391609191895 first col mean 0.09149709343910217 all mean 0.08803930878639221
0.2479887306690216 0.2479887306690216
rl training, epoch8, iter0, batch636/1133, batch loss:0.2479887306690216, Training time:27666.924753189087
batch reward last col mean 0.09790961444377899 first col mean 0.10976754128932953 all mean 0.09886085242033005
0.2805646061897278 0.2805646061897278
rl training, epoch8, iter0, batch637/1133, batch loss:0.2805646061897278, Training time:27669.272782564163
batch reward last col mean 0.1083730086684227 first col mean 0.1049099862575531 all mean 0.10262087732553482
0.3005801737308502 0.3005801737308502
rl training, epoch8, iter0, batch638/1133, batch loss:0.3005801737308502, Training time:27671.716406583786
batch reward last col mean 0.09884844720363617 first col mean 0.10124436765909195 all mean 0.1045018807053566
0.32613739371299744 0.32613739371299744
rl training, epoch8, iter0, batch639/1133, batch loss:0.32613739371299744, Training time:27673.65666627884
batch reward last col mean 0.08116462826728821 first col mean 0.10512226074934006 all mean 0.0880974605679512
0.26411011815071106 0.26411011815071106
rl training, epoch8, iter0, batch640/1133, batch loss:0.26411011815071106, Training time:27676.377633333206
batch reward last col mean 0.06573037803173065 first col mean 0.09922660887241364 all mean 0.08161967247724533
0.2650192975997925 0.2650192975997925
rl training, epoch8, iter0, batch641/1133, batch loss:0.2650192975997925, Training time:27678.348004102707
batch reward last col mean 0.08157455921173096 first col mean 0.10131487995386124 all mean 0.08368255198001862
0.24230384826660156 0.24230384826660156
rl training, epoch8, iter0, batch642/1133, batch loss:0.24230384826660156, Training time:27680.422161579132
batch reward last col mean 0.13810677826404572 first col mean 0.09587536007165909 all mean 0.1306256651878357
0.3170788884162903 0.3170788884162903
rl training, epoch8, iter0, batch643/1133, batch loss:0.3170788884162903, Training time:27682.271127939224
batch reward last col mean 0.08251721411943436 first col mean 0.10626824200153351 all mean 0.09195300936698914
0.2994263470172882 0.2994263172149658
rl training, epoch8, iter0, batch644/1133, batch loss:0.2994263172149658, Training time:27685.508997440338
batch reward last col mean 0.09013234823942184 first col mean 0.10282766073942184 all mean 0.09277743101119995
0.26923665404319763 0.26923665404319763
rl training, epoch8, iter0, batch645/1133, batch loss:0.26923665404319763, Training time:27687.563791036606
batch reward last col mean 0.09358763694763184 first col mean 0.10093656927347183 all mean 0.0968216061592102
0.28604698181152344 0.28604698181152344
rl training, epoch8, iter0, batch646/1133, batch loss:0.28604698181152344, Training time:27689.66254425049
batch reward last col mean 0.08509166538715363 first col mean 0.1053534746170044 all mean 0.09148730337619781
0.2543300986289978 0.2543300986289978
rl training, epoch8, iter0, batch647/1133, batch loss:0.2543300986289978, Training time:27692.073554754257
batch reward last col mean 0.10562427341938019 first col mean 0.10527647286653519 all mean 0.11147058755159378
0.326074481010437 0.326074481010437
rl training, epoch8, iter0, batch648/1133, batch loss:0.326074481010437, Training time:27694.214326620102
batch reward last col mean 0.08746597170829773 first col mean 0.09120501577854156 all mean 0.08973047882318497
0.2573303282260895 0.2573303282260895
rl training, epoch8, iter0, batch649/1133, batch loss:0.2573303282260895, Training time:27695.911334991455
batch reward last col mean 0.09307096898555756 first col mean 0.10624032467603683 all mean 0.10405644029378891
0.26341789960861206 0.26341792941093445
rl training, epoch8, iter0, batch650/1133, batch loss:0.26341792941093445, Training time:27698.053121089935
batch reward last col mean 0.09642104059457779 first col mean 0.1034320592880249 all mean 0.10146667063236237
0.277627557516098 0.277627557516098
rl training, epoch8, iter0, batch651/1133, batch loss:0.277627557516098, Training time:27700.072579860687
batch reward last col mean 0.11130521446466446 first col mean 0.10913490504026413 all mean 0.11363353580236435
0.3189367949962616 0.3189367949962616
rl training, epoch8, iter0, batch652/1133, batch loss:0.3189367949962616, Training time:27701.713838100433
batch reward last col mean 0.12271009385585785 first col mean 0.09677952527999878 all mean 0.11549749225378036
0.2774811089038849 0.2774811089038849
rl training, epoch8, iter0, batch653/1133, batch loss:0.2774811089038849, Training time:27704.06237268448
batch reward last col mean 0.09429323673248291 first col mean 0.0965745598077774 all mean 0.09626619517803192
0.275765985250473 0.275765985250473
rl training, epoch8, iter0, batch654/1133, batch loss:0.275765985250473, Training time:27706.44784474373
batch reward last col mean 0.09782923758029938 first col mean 0.10864292830228806 all mean 0.10657774657011032
0.2736033797264099 0.2736033797264099
rl training, epoch8, iter0, batch655/1133, batch loss:0.2736033797264099, Training time:27707.920270204544
batch reward last col mean 0.10827624052762985 first col mean 0.1056254580616951 all mean 0.10944602638483047
0.29985564947128296 0.29985564947128296
rl training, epoch8, iter0, batch656/1133, batch loss:0.29985564947128296, Training time:27710.180278778076
batch reward last col mean 0.07192105054855347 first col mean 0.10300850123167038 all mean 0.0810333639383316
0.2734382152557373 0.2734382152557373
rl training, epoch8, iter0, batch657/1133, batch loss:0.2734382152557373, Training time:27713.256324768066
batch reward last col mean 0.1108790934085846 first col mean 0.13275304436683655 all mean 0.10615935921669006
0.2773470878601074 0.2773470878601074
rl training, epoch8, iter0, batch658/1133, batch loss:0.2773470878601074, Training time:27715.468886852264
batch reward last col mean 0.0993790552020073 first col mean 0.11043945699930191 all mean 0.09990585595369339
0.24145640432834625 0.24145640432834625
rl training, epoch8, iter0, batch659/1133, batch loss:0.24145640432834625, Training time:27717.86796617508
batch reward last col mean 0.071571484208107 first col mean 0.11535882204771042 all mean 0.07786360383033752
0.22305524349212646 0.22305524349212646
rl training, epoch8, iter0, batch660/1133, batch loss:0.22305524349212646, Training time:27720.07741212845
batch reward last col mean 0.04591771215200424 first col mean 0.09410637617111206 all mean 0.06048140302300453
0.23055939376354218 0.23055939376354218
rl training, epoch8, iter0, batch661/1133, batch loss:0.23055939376354218, Training time:27722.525060653687
batch reward last col mean 0.051679398864507675 first col mean 0.10172207653522491 all mean 0.06432347744703293
0.22454328835010529 0.22454328835010529
rl training, epoch8, iter0, batch662/1133, batch loss:0.22454328835010529, Training time:27724.368770360947
batch reward last col mean 0.11525657773017883 first col mean 0.10952378064393997 all mean 0.11438527703285217
0.28661346435546875 0.28661346435546875
rl training, epoch8, iter0, batch663/1133, batch loss:0.28661346435546875, Training time:27726.10125732422
batch reward last col mean 0.08180743455886841 first col mean 0.12337462604045868 all mean 0.09300170093774796
0.2651990056037903 0.2651990056037903
rl training, epoch8, iter0, batch664/1133, batch loss:0.2651990056037903, Training time:27727.921513319016
batch reward last col mean 0.09314986318349838 first col mean 0.11006440222263336 all mean 0.09642712026834488
0.23795729875564575 0.23795728385448456
rl training, epoch8, iter0, batch665/1133, batch loss:0.23795728385448456, Training time:27730.042160987854
batch reward last col mean 0.10702617466449738 first col mean 0.14518022537231445 all mean 0.10830966383218765
0.2773827612400055 0.2773827612400055
rl training, epoch8, iter0, batch666/1133, batch loss:0.2773827612400055, Training time:27731.848646879196
batch reward last col mean 0.06760244071483612 first col mean 0.10369978100061417 all mean 0.08103685826063156
0.23614872992038727 0.23614872992038727
rl training, epoch8, iter0, batch667/1133, batch loss:0.23614872992038727, Training time:27733.814159870148
batch reward last col mean 0.10288047045469284 first col mean 0.10021781921386719 all mean 0.08804711699485779
0.28617167472839355 0.28617167472839355
rl training, epoch8, iter0, batch668/1133, batch loss:0.28617167472839355, Training time:27735.657027959824
batch reward last col mean 0.08403287827968597 first col mean 0.0954219400882721 all mean 0.09284243732690811
0.2619745135307312 0.2619745135307312
rl training, epoch8, iter0, batch669/1133, batch loss:0.2619745135307312, Training time:27737.563706874847
batch reward last col mean 0.10644949972629547 first col mean 0.11518402397632599 all mean 0.10746727883815765
0.2666151523590088 0.2666151225566864
rl training, epoch8, iter0, batch670/1133, batch loss:0.2666151225566864, Training time:27739.36444377899
batch reward last col mean 0.13567189872264862 first col mean 0.11183945089578629 all mean 0.13142512738704681
0.30135172605514526 0.30135172605514526
rl training, epoch8, iter0, batch671/1133, batch loss:0.30135172605514526, Training time:27742.085904359818
batch reward last col mean 0.09629379212856293 first col mean 0.10583337396383286 all mean 0.10374210774898529
0.28705281019210815 0.28705281019210815
rl training, epoch8, iter0, batch672/1133, batch loss:0.28705281019210815, Training time:27743.971635580063
batch reward last col mean 0.09475653618574142 first col mean 0.11076109111309052 all mean 0.10190729051828384
0.261890172958374 0.261890172958374
rl training, epoch8, iter0, batch673/1133, batch loss:0.261890172958374, Training time:27746.01346540451
batch reward last col mean 0.13388925790786743 first col mean 0.09857364743947983 all mean 0.13301442563533783
0.2755929231643677 0.2755929231643677
rl training, epoch8, iter0, batch674/1133, batch loss:0.2755929231643677, Training time:27748.33219718933
batch reward last col mean 0.08657887578010559 first col mean 0.10359436273574829 all mean 0.09646162390708923
0.2659297287464142 0.2659297585487366
rl training, epoch8, iter0, batch675/1133, batch loss:0.2659297585487366, Training time:27750.346524238586
batch reward last col mean 0.11151452362537384 first col mean 0.09766644984483719 all mean 0.11114382743835449
0.2936708927154541 0.2936708927154541
rl training, epoch8, iter0, batch676/1133, batch loss:0.2936708927154541, Training time:27752.361756801605
batch reward last col mean 0.05756115913391113 first col mean 0.11556573212146759 all mean 0.06856676936149597
0.24164646863937378 0.24164646863937378
rl training, epoch8, iter0, batch677/1133, batch loss:0.24164646863937378, Training time:27754.52325797081
batch reward last col mean 0.10427358001470566 first col mean 0.09587199240922928 all mean 0.11045742779970169
0.28943875432014465 0.28943875432014465
rl training, epoch8, iter0, batch678/1133, batch loss:0.28943875432014465, Training time:27756.393316030502
batch reward last col mean 0.1112978532910347 first col mean 0.10683484375476837 all mean 0.10570124536752701
0.2709304988384247 0.27093052864074707
rl training, epoch8, iter0, batch679/1133, batch loss:0.27093052864074707, Training time:27758.859249830246
batch reward last col mean 0.09836632758378983 first col mean 0.1035068929195404 all mean 0.10296650230884552
0.30071836709976196 0.30071836709976196
rl training, epoch8, iter0, batch680/1133, batch loss:0.30071836709976196, Training time:27761.41426706314
batch reward last col mean 0.13201728463172913 first col mean 0.091886006295681 all mean 0.12230631709098816
0.3150475025177002 0.3150475025177002
rl training, epoch8, iter0, batch681/1133, batch loss:0.3150475025177002, Training time:27763.376913785934
batch reward last col mean 0.14161087572574615 first col mean 0.12012531608343124 all mean 0.1336016207933426
0.31823962926864624 0.31823959946632385
rl training, epoch8, iter0, batch682/1133, batch loss:0.31823959946632385, Training time:27765.48509287834
batch reward last col mean 0.07343526929616928 first col mean 0.10844537615776062 all mean 0.07357390969991684
0.2300524115562439 0.2300524115562439
rl training, epoch8, iter0, batch683/1133, batch loss:0.2300524115562439, Training time:27767.13120341301
batch reward last col mean 0.096530981361866 first col mean 0.10097798705101013 all mean 0.09447512775659561
0.26334625482559204 0.26334625482559204
rl training, epoch8, iter0, batch684/1133, batch loss:0.26334625482559204, Training time:27769.25842666626
batch reward last col mean 0.10786207020282745 first col mean 0.12158025801181793 all mean 0.11256934702396393
0.30862006545066833 0.30862006545066833
rl training, epoch8, iter0, batch685/1133, batch loss:0.30862006545066833, Training time:27771.111766576767
batch reward last col mean 0.09461789578199387 first col mean 0.1125907152891159 all mean 0.09883134812116623
0.279667466878891 0.279667466878891
rl training, epoch8, iter0, batch686/1133, batch loss:0.279667466878891, Training time:27773.22568511963
batch reward last col mean 0.09809958189725876 first col mean 0.11698134243488312 all mean 0.10241097956895828
0.24655692279338837 0.24655692279338837
rl training, epoch8, iter0, batch687/1133, batch loss:0.24655692279338837, Training time:27774.942144870758
batch reward last col mean 0.12705950438976288 first col mean 0.10740622133016586 all mean 0.11820895969867706
0.31417936086654663 0.31417936086654663
rl training, epoch8, iter0, batch688/1133, batch loss:0.31417936086654663, Training time:27776.613730430603
batch reward last col mean 0.07678652554750443 first col mean 0.12484241276979446 all mean 0.08299525827169418
0.2672934830188751 0.2672934830188751
rl training, epoch8, iter0, batch689/1133, batch loss:0.2672934830188751, Training time:27778.718811273575
batch reward last col mean 0.0848727896809578 first col mean 0.10035370290279388 all mean 0.09828103333711624
0.28750503063201904 0.28750503063201904
rl training, epoch8, iter0, batch690/1133, batch loss:0.28750503063201904, Training time:27780.817414283752
batch reward last col mean 0.14048640429973602 first col mean 0.12819570302963257 all mean 0.13798373937606812
0.31773000955581665 0.31773000955581665
rl training, epoch8, iter0, batch691/1133, batch loss:0.31773000955581665, Training time:27782.69629716873
batch reward last col mean 0.12853726744651794 first col mean 0.10917411744594574 all mean 0.124121755361557
0.3415851593017578 0.34158509969711304
rl training, epoch8, iter0, batch692/1133, batch loss:0.34158509969711304, Training time:27784.454733371735
batch reward last col mean 0.09263821691274643 first col mean 0.10408788919448853 all mean 0.09676572680473328
0.2904098629951477 0.2904098629951477
rl training, epoch8, iter0, batch693/1133, batch loss:0.2904098629951477, Training time:27786.29776930809
batch reward last col mean 0.08669242262840271 first col mean 0.1088084876537323 all mean 0.09168235212564468
0.24755115807056427 0.24755115807056427
rl training, epoch8, iter0, batch694/1133, batch loss:0.24755115807056427, Training time:27788.779967308044
batch reward last col mean 0.1285405457019806 first col mean 0.10498658567667007 all mean 0.11977115273475647
0.34127482771873474 0.34127482771873474
rl training, epoch8, iter0, batch695/1133, batch loss:0.34127482771873474, Training time:27790.913487911224
batch reward last col mean 0.1284698247909546 first col mean 0.11499153077602386 all mean 0.1255781650543213
0.3406641185283661 0.3406641185283661
rl training, epoch8, iter0, batch696/1133, batch loss:0.3406641185283661, Training time:27793.30694770813
batch reward last col mean 0.07337947934865952 first col mean 0.11229915916919708 all mean 0.07832449674606323
0.21337087452411652 0.21337087452411652
rl training, epoch8, iter0, batch697/1133, batch loss:0.21337087452411652, Training time:27795.592209100723
batch reward last col mean 0.0973973348736763 first col mean 0.11660371720790863 all mean 0.09857667237520218
0.2966097593307495 0.2966097593307495
rl training, epoch8, iter0, batch698/1133, batch loss:0.2966097593307495, Training time:27797.949904203415
batch reward last col mean 0.10882051289081573 first col mean 0.12749476730823517 all mean 0.11666843295097351
0.3381906747817993 0.3381906747817993
rl training, epoch8, iter0, batch699/1133, batch loss:0.3381906747817993, Training time:27800.182020187378
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4634045086807628 Time: 101.93731117248535 s
loss of true 0.20038325959012662 loss of gen 0.1709395909496145 loss of other 0.09208165755411585 first score 0.13600975275039673
batch reward last col mean 0.12133431434631348 first col mean 0.12144609540700912 all mean 0.11637681722640991
0.2942471504211426 0.2942471504211426
rl training, epoch8, iter0, batch700/1133, batch loss:0.2942471504211426, Training time:27904.24751639366
batch reward last col mean 0.11329842358827591 first col mean 0.09562960267066956 all mean 0.11094978451728821
0.3342381715774536 0.3342381715774536
rl training, epoch8, iter0, batch701/1133, batch loss:0.3342381715774536, Training time:27907.03532886505
batch reward last col mean 0.12344760447740555 first col mean 0.1142570897936821 all mean 0.1185782328248024
0.30521366000175476 0.30521366000175476
rl training, epoch8, iter0, batch702/1133, batch loss:0.30521366000175476, Training time:27908.817383527756
batch reward last col mean 0.09705504775047302 first col mean 0.11361438035964966 all mean 0.10435988754034042
0.30027252435684204 0.30027252435684204
rl training, epoch8, iter0, batch703/1133, batch loss:0.30027252435684204, Training time:27910.85570859909
batch reward last col mean 0.09813734889030457 first col mean 0.10694672912359238 all mean 0.10325031727552414
0.28703081607818604 0.28703081607818604
rl training, epoch8, iter0, batch704/1133, batch loss:0.28703081607818604, Training time:27912.587334156036
batch reward last col mean 0.07299800962209702 first col mean 0.12510772049427032 all mean 0.0830090194940567
0.26697298884391785 0.26697298884391785
rl training, epoch8, iter0, batch705/1133, batch loss:0.26697298884391785, Training time:27914.8932762146
batch reward last col mean 0.07239270210266113 first col mean 0.10291489958763123 all mean 0.07942144572734833
0.2731403112411499 0.2731403410434723
rl training, epoch8, iter0, batch706/1133, batch loss:0.2731403410434723, Training time:27918.185790538788
batch reward last col mean 0.12794752418994904 first col mean 0.13095948100090027 all mean 0.12811918556690216
0.3379705846309662 0.3379705846309662
rl training, epoch8, iter0, batch707/1133, batch loss:0.3379705846309662, Training time:27920.50557732582
batch reward last col mean 0.07039134204387665 first col mean 0.09776904433965683 all mean 0.08039771765470505
0.2634805142879486 0.2634805142879486
rl training, epoch8, iter0, batch708/1133, batch loss:0.2634805142879486, Training time:27922.519391298294
batch reward last col mean 0.09763845801353455 first col mean 0.10207828134298325 all mean 0.09969177842140198
0.27400797605514526 0.27400797605514526
rl training, epoch8, iter0, batch709/1133, batch loss:0.27400797605514526, Training time:27924.29995584488
batch reward last col mean 0.05780988559126854 first col mean 0.1086297258734703 all mean 0.07336069643497467
0.2437267005443573 0.2437267005443573
rl training, epoch8, iter0, batch710/1133, batch loss:0.2437267005443573, Training time:27925.941136837006
batch reward last col mean 0.11260195076465607 first col mean 0.11904855072498322 all mean 0.11170820891857147
0.28172746300697327 0.28172746300697327
rl training, epoch8, iter0, batch711/1133, batch loss:0.28172746300697327, Training time:27927.835616588593
batch reward last col mean 0.09795986860990524 first col mean 0.11405046284198761 all mean 0.10008659213781357
0.27143922448158264 0.27143922448158264
rl training, epoch8, iter0, batch712/1133, batch loss:0.27143922448158264, Training time:27931.78024983406
batch reward last col mean 0.10515959560871124 first col mean 0.10718788206577301 all mean 0.10300351679325104
0.2970373034477234 0.2970373034477234
rl training, epoch8, iter0, batch713/1133, batch loss:0.2970373034477234, Training time:27933.681256771088
batch reward last col mean 0.11162330210208893 first col mean 0.11627065390348434 all mean 0.10995195060968399
0.32871755957603455 0.32871755957603455
rl training, epoch8, iter0, batch714/1133, batch loss:0.32871755957603455, Training time:27936.033700466156
batch reward last col mean 0.10325299203395844 first col mean 0.11378149688243866 all mean 0.10870763659477234
0.29899388551712036 0.29899388551712036
rl training, epoch8, iter0, batch715/1133, batch loss:0.29899388551712036, Training time:27937.867135047913
batch reward last col mean 0.09164783358573914 first col mean 0.08909013867378235 all mean 0.09525307267904282
0.26938503980636597 0.26938503980636597
rl training, epoch8, iter0, batch716/1133, batch loss:0.26938503980636597, Training time:27940.310372829437
batch reward last col mean 0.0835837870836258 first col mean 0.1073988825082779 all mean 0.09362401068210602
0.26925647258758545 0.26925647258758545
rl training, epoch8, iter0, batch717/1133, batch loss:0.26925647258758545, Training time:27942.1923327446
batch reward last col mean 0.13018254935741425 first col mean 0.1008399948477745 all mean 0.12527066469192505
0.3021441698074341 0.3021441400051117
rl training, epoch8, iter0, batch718/1133, batch loss:0.3021441400051117, Training time:27944.08141231537
batch reward last col mean 0.09419963508844376 first col mean 0.10811476409435272 all mean 0.10133311152458191
0.3084811866283417 0.3084811866283417
rl training, epoch8, iter0, batch719/1133, batch loss:0.3084811866283417, Training time:27946.106282949448
batch reward last col mean 0.12252886593341827 first col mean 0.0982150062918663 all mean 0.11222029477357864
0.3028348684310913 0.3028348684310913
rl training, epoch8, iter0, batch720/1133, batch loss:0.3028348684310913, Training time:27948.098891973495
batch reward last col mean 0.11524182558059692 first col mean 0.09483705461025238 all mean 0.11510700732469559
0.329227089881897 0.329227089881897
rl training, epoch8, iter0, batch721/1133, batch loss:0.329227089881897, Training time:27950.307285547256
batch reward last col mean 0.10854535549879074 first col mean 0.10974811017513275 all mean 0.10543333739042282
0.2743062376976013 0.2743062376976013
rl training, epoch8, iter0, batch722/1133, batch loss:0.2743062376976013, Training time:27952.498322963715
batch reward last col mean 0.10377544164657593 first col mean 0.11346469819545746 all mean 0.10452837496995926
0.2743302285671234 0.2743302285671234
rl training, epoch8, iter0, batch723/1133, batch loss:0.2743302285671234, Training time:27954.32671022415
batch reward last col mean 0.0967182144522667 first col mean 0.09543497115373611 all mean 0.1013028547167778
0.2946307957172394 0.2946307957172394
rl training, epoch8, iter0, batch724/1133, batch loss:0.2946307957172394, Training time:27956.363924980164
batch reward last col mean 0.10635394603013992 first col mean 0.10618853569030762 all mean 0.1072365939617157
0.2792961895465851 0.2792961597442627
rl training, epoch8, iter0, batch725/1133, batch loss:0.2792961597442627, Training time:27958.75037240982
batch reward last col mean 0.10743815451860428 first col mean 0.10652368515729904 all mean 0.10820083320140839
0.28136205673217773 0.28136205673217773
rl training, epoch8, iter0, batch726/1133, batch loss:0.28136205673217773, Training time:27960.574101686478
batch reward last col mean 0.09483003616333008 first col mean 0.1172468438744545 all mean 0.09407586604356766
0.2789590656757355 0.2789590656757355
rl training, epoch8, iter0, batch727/1133, batch loss:0.2789590656757355, Training time:27963.370509386063
batch reward last col mean 0.1589062660932541 first col mean 0.10066536068916321 all mean 0.14102858304977417
0.3596465289592743 0.3596465289592743
rl training, epoch8, iter0, batch728/1133, batch loss:0.3596465289592743, Training time:27965.399403572083
batch reward last col mean 0.10386861115694046 first col mean 0.12089703977108002 all mean 0.11139196157455444
0.30025917291641235 0.30025914311408997
rl training, epoch8, iter0, batch729/1133, batch loss:0.30025914311408997, Training time:27967.3496465683
batch reward last col mean 0.1163986325263977 first col mean 0.10717998445034027 all mean 0.11422406136989594
0.3112971782684326 0.3112971782684326
rl training, epoch8, iter0, batch730/1133, batch loss:0.3112971782684326, Training time:27969.512189388275
batch reward last col mean 0.09559091180562973 first col mean 0.12917804718017578 all mean 0.09855024516582489
0.3204081356525421 0.3204081356525421
rl training, epoch8, iter0, batch731/1133, batch loss:0.3204081356525421, Training time:27971.693464756012
batch reward last col mean 0.08956663310527802 first col mean 0.12126860022544861 all mean 0.09744910150766373
0.328502357006073 0.3285023272037506
rl training, epoch8, iter0, batch732/1133, batch loss:0.3285023272037506, Training time:27974.136376857758
batch reward last col mean 0.10846153646707535 first col mean 0.12725792825222015 all mean 0.10789930075407028
0.276093989610672 0.276093989610672
rl training, epoch8, iter0, batch733/1133, batch loss:0.276093989610672, Training time:27976.17772769928
batch reward last col mean 0.1389404535293579 first col mean 0.12601947784423828 all mean 0.13001921772956848
0.2699965536594391 0.2699965536594391
rl training, epoch8, iter0, batch734/1133, batch loss:0.2699965536594391, Training time:27979.000821352005
batch reward last col mean 0.12071986496448517 first col mean 0.10043315589427948 all mean 0.11258970201015472
0.29098474979400635 0.29098477959632874
rl training, epoch8, iter0, batch735/1133, batch loss:0.29098477959632874, Training time:27981.46182870865
batch reward last col mean 0.12052299827337265 first col mean 0.12522020936012268 all mean 0.11342310160398483
0.28854626417160034 0.28854626417160034
rl training, epoch8, iter0, batch736/1133, batch loss:0.28854626417160034, Training time:27983.37202167511
batch reward last col mean 0.07111067324876785 first col mean 0.11257737129926682 all mean 0.08280257135629654
0.24727296829223633 0.24727298319339752
rl training, epoch8, iter0, batch737/1133, batch loss:0.24727298319339752, Training time:27985.663283586502
batch reward last col mean 0.09916780143976212 first col mean 0.12505465745925903 all mean 0.11295118182897568
0.31679636240005493 0.31679636240005493
rl training, epoch8, iter0, batch738/1133, batch loss:0.31679636240005493, Training time:27987.236015558243
batch reward last col mean 0.11026668548583984 first col mean 0.09789633750915527 all mean 0.1110624298453331
0.28967443108558655 0.28967443108558655
rl training, epoch8, iter0, batch739/1133, batch loss:0.28967443108558655, Training time:27989.310677051544
batch reward last col mean 0.09963857382535934 first col mean 0.11289098858833313 all mean 0.09904079139232635
0.2765332758426666 0.2765332758426666
rl training, epoch8, iter0, batch740/1133, batch loss:0.2765332758426666, Training time:27991.032919168472
batch reward last col mean 0.10557098686695099 first col mean 0.11831948161125183 all mean 0.10561318695545197
0.2700933814048767 0.2700933814048767
rl training, epoch8, iter0, batch741/1133, batch loss:0.2700933814048767, Training time:27993.459885835648
batch reward last col mean 0.12420631945133209 first col mean 0.11715422570705414 all mean 0.1252971738576889
0.3199736177921295 0.3199736177921295
rl training, epoch8, iter0, batch742/1133, batch loss:0.3199736177921295, Training time:27995.639526844025
batch reward last col mean 0.11754702031612396 first col mean 0.1188448891043663 all mean 0.12164484709501266
0.3111766278743744 0.3111766576766968
rl training, epoch8, iter0, batch743/1133, batch loss:0.3111766576766968, Training time:27998.16671895981
batch reward last col mean 0.10688532143831253 first col mean 0.11184928566217422 all mean 0.1072385162115097
0.29025155305862427 0.29025155305862427
rl training, epoch8, iter0, batch744/1133, batch loss:0.29025155305862427, Training time:27999.971098184586
batch reward last col mean 0.1132110059261322 first col mean 0.10448911786079407 all mean 0.1142735481262207
0.2923952043056488 0.2923952043056488
rl training, epoch8, iter0, batch745/1133, batch loss:0.2923952043056488, Training time:28002.417227983475
batch reward last col mean 0.12754492461681366 first col mean 0.08899945765733719 all mean 0.11895149201154709
0.28292301297187805 0.28292301297187805
rl training, epoch8, iter0, batch746/1133, batch loss:0.28292301297187805, Training time:28004.11940765381
batch reward last col mean 0.1272566318511963 first col mean 0.12202347069978714 all mean 0.1276308298110962
0.3040854036808014 0.3040854036808014
rl training, epoch8, iter0, batch747/1133, batch loss:0.3040854036808014, Training time:28006.43922019005
batch reward last col mean 0.10525193065404892 first col mean 0.11511462181806564 all mean 0.10340552777051926
0.27773764729499817 0.27773764729499817
rl training, epoch8, iter0, batch748/1133, batch loss:0.27773764729499817, Training time:28008.270602226257
batch reward last col mean 0.12381793558597565 first col mean 0.10887846350669861 all mean 0.11907359957695007
0.30836668610572815 0.30836668610572815
rl training, epoch8, iter0, batch749/1133, batch loss:0.30836668610572815, Training time:28010.346293449402
batch reward last col mean 0.1112208142876625 first col mean 0.09772593528032303 all mean 0.1023586168885231
0.2566321790218353 0.25663214921951294
rl training, epoch8, iter0, batch750/1133, batch loss:0.25663214921951294, Training time:28012.604935646057
batch reward last col mean 0.12211815267801285 first col mean 0.12268438935279846 all mean 0.12114259600639343
0.282444566488266 0.2824445366859436
rl training, epoch8, iter0, batch751/1133, batch loss:0.2824445366859436, Training time:28015.147430181503
batch reward last col mean 0.1059776246547699 first col mean 0.12657777965068817 all mean 0.10693242400884628
0.2849475145339966 0.2849475145339966
rl training, epoch8, iter0, batch752/1133, batch loss:0.2849475145339966, Training time:28017.563075065613
batch reward last col mean 0.10715135186910629 first col mean 0.12680314481258392 all mean 0.10397598892450333
0.29277971386909485 0.29277971386909485
rl training, epoch8, iter0, batch753/1133, batch loss:0.29277971386909485, Training time:28019.411418914795
batch reward last col mean 0.12065612524747849 first col mean 0.09687763452529907 all mean 0.1209840402007103
0.318195641040802 0.318195641040802
rl training, epoch8, iter0, batch754/1133, batch loss:0.318195641040802, Training time:28022.33945608139
batch reward last col mean 0.10674037784337997 first col mean 0.12408746778964996 all mean 0.10842998325824738
0.2809634804725647 0.2809634804725647
rl training, epoch8, iter0, batch755/1133, batch loss:0.2809634804725647, Training time:28025.349447250366
batch reward last col mean 0.12659956514835358 first col mean 0.09887702763080597 all mean 0.11862052232027054
0.28650662302970886 0.28650665283203125
rl training, epoch8, iter0, batch756/1133, batch loss:0.28650665283203125, Training time:28028.06789112091
batch reward last col mean 0.0977298766374588 first col mean 0.12405582517385483 all mean 0.10289154201745987
0.25549057126045227 0.25549057126045227
rl training, epoch8, iter0, batch757/1133, batch loss:0.25549057126045227, Training time:28030.960859060287
batch reward last col mean 0.1337057650089264 first col mean 0.12253659963607788 all mean 0.12560315430164337
0.30339515209198 0.30339515209198
rl training, epoch8, iter0, batch758/1133, batch loss:0.30339515209198, Training time:28032.830793857574
batch reward last col mean 0.08132470399141312 first col mean 0.10470738261938095 all mean 0.09147302806377411
0.28481072187423706 0.28481072187423706
rl training, epoch8, iter0, batch759/1133, batch loss:0.28481072187423706, Training time:28034.87429690361
batch reward last col mean 0.08829399943351746 first col mean 0.12260618805885315 all mean 0.09516304731369019
0.2816229462623596 0.2816229462623596
rl training, epoch8, iter0, batch760/1133, batch loss:0.2816229462623596, Training time:28037.077036619186
batch reward last col mean 0.11417093127965927 first col mean 0.10340704023838043 all mean 0.11617535352706909
0.25654053688049316 0.25654053688049316
rl training, epoch8, iter0, batch761/1133, batch loss:0.25654053688049316, Training time:28038.70584011078
batch reward last col mean 0.128291517496109 first col mean 0.09755292534828186 all mean 0.12417030334472656
0.2995576560497284 0.299557626247406
rl training, epoch8, iter0, batch762/1133, batch loss:0.299557626247406, Training time:28041.72903561592
batch reward last col mean 0.10013942420482635 first col mean 0.11323003470897675 all mean 0.1039806604385376
0.3151090145111084 0.3151090145111084
rl training, epoch8, iter0, batch763/1133, batch loss:0.3151090145111084, Training time:28044.188151836395
batch reward last col mean 0.11454114317893982 first col mean 0.11910634487867355 all mean 0.11702844500541687
0.3167223036289215 0.3167223334312439
rl training, epoch8, iter0, batch764/1133, batch loss:0.3167223334312439, Training time:28046.581364393234
batch reward last col mean 0.082577645778656 first col mean 0.1076144427061081 all mean 0.09034392982721329
0.2714727818965912 0.2714727818965912
rl training, epoch8, iter0, batch765/1133, batch loss:0.2714727818965912, Training time:28048.66170310974
batch reward last col mean 0.1010054349899292 first col mean 0.1099761575460434 all mean 0.10142925381660461
0.293743759393692 0.293743759393692
rl training, epoch8, iter0, batch766/1133, batch loss:0.293743759393692, Training time:28050.506990909576
batch reward last col mean 0.13086353242397308 first col mean 0.119411900639534 all mean 0.12666383385658264
0.34311604499816895 0.34311604499816895
rl training, epoch8, iter0, batch767/1133, batch loss:0.34311604499816895, Training time:28052.41753411293
batch reward last col mean 0.12334240972995758 first col mean 0.13307532668113708 all mean 0.11340853571891785
0.3705516457557678 0.3705516457557678
rl training, epoch8, iter0, batch768/1133, batch loss:0.3705516457557678, Training time:28054.347683668137
batch reward last col mean 0.10267887264490128 first col mean 0.11015878617763519 all mean 0.10611359775066376
0.274802565574646 0.274802565574646
rl training, epoch8, iter0, batch769/1133, batch loss:0.274802565574646, Training time:28056.42853617668
batch reward last col mean 0.11577384173870087 first col mean 0.10477319359779358 all mean 0.10911241173744202
0.28844544291496277 0.2884454131126404
rl training, epoch8, iter0, batch770/1133, batch loss:0.2884454131126404, Training time:28058.753826618195
batch reward last col mean 0.11157512664794922 first col mean 0.10673131048679352 all mean 0.11711597442626953
0.2663895785808563 0.2663895785808563
rl training, epoch8, iter0, batch771/1133, batch loss:0.2663895785808563, Training time:28060.586285352707
batch reward last col mean 0.12027175724506378 first col mean 0.10216240584850311 all mean 0.11914260685443878
0.2693628668785095 0.2693628668785095
rl training, epoch8, iter0, batch772/1133, batch loss:0.2693628668785095, Training time:28062.255559921265
batch reward last col mean 0.14331616461277008 first col mean 0.10767249017953873 all mean 0.13119351863861084
0.3319675028324127 0.3319675028324127
rl training, epoch8, iter0, batch773/1133, batch loss:0.3319675028324127, Training time:28064.24616098404
batch reward last col mean 0.0987892746925354 first col mean 0.10730984061956406 all mean 0.10639361292123795
0.30165398120880127 0.30165398120880127
rl training, epoch8, iter0, batch774/1133, batch loss:0.30165398120880127, Training time:28066.72487282753
batch reward last col mean 0.10374122112989426 first col mean 0.10182450711727142 all mean 0.1030031368136406
0.32535144686698914 0.32535144686698914
rl training, epoch8, iter0, batch775/1133, batch loss:0.32535144686698914, Training time:28068.61639070511
batch reward last col mean 0.11081130057573318 first col mean 0.10725075006484985 all mean 0.11644866317510605
0.29198500514030457 0.29198500514030457
rl training, epoch8, iter0, batch776/1133, batch loss:0.29198500514030457, Training time:28070.39883375168
batch reward last col mean 0.08895104378461838 first col mean 0.12145230174064636 all mean 0.09828013926744461
0.2943507134914398 0.29435068368911743
rl training, epoch8, iter0, batch777/1133, batch loss:0.29435068368911743, Training time:28072.936846971512
batch reward last col mean 0.12548935413360596 first col mean 0.10215272009372711 all mean 0.11708610504865646
0.33343231678009033 0.33343231678009033
rl training, epoch8, iter0, batch778/1133, batch loss:0.33343231678009033, Training time:28074.604025125504
batch reward last col mean 0.0884457379579544 first col mean 0.10538884997367859 all mean 0.09573647379875183
0.27715879678726196 0.27715879678726196
rl training, epoch8, iter0, batch779/1133, batch loss:0.27715879678726196, Training time:28076.411072015762
batch reward last col mean 0.08729811012744904 first col mean 0.10316915810108185 all mean 0.09376655519008636
0.2789413332939148 0.2789413332939148
rl training, epoch8, iter0, batch780/1133, batch loss:0.2789413332939148, Training time:28078.930048942566
batch reward last col mean 0.09702084958553314 first col mean 0.10978726297616959 all mean 0.097709521651268
0.2555328607559204 0.2555328607559204
rl training, epoch8, iter0, batch781/1133, batch loss:0.2555328607559204, Training time:28081.587616682053
batch reward last col mean 0.10310027748346329 first col mean 0.11339929699897766 all mean 0.10956001281738281
0.35416194796562195 0.35416194796562195
rl training, epoch8, iter0, batch782/1133, batch loss:0.35416194796562195, Training time:28084.45586705208
batch reward last col mean 0.10600817948579788 first col mean 0.09686531126499176 all mean 0.11077389121055603
0.3024984896183014 0.3024984896183014
rl training, epoch8, iter0, batch783/1133, batch loss:0.3024984896183014, Training time:28087.40906047821
batch reward last col mean 0.14848242700099945 first col mean 0.11849278956651688 all mean 0.14220894873142242
0.3565126955509186 0.3565126955509186
rl training, epoch8, iter0, batch784/1133, batch loss:0.3565126955509186, Training time:28090.050443172455
batch reward last col mean 0.12073422968387604 first col mean 0.1071850061416626 all mean 0.11913011968135834
0.28381603956222534 0.28381603956222534
rl training, epoch8, iter0, batch785/1133, batch loss:0.28381603956222534, Training time:28091.77833175659
batch reward last col mean 0.12785367667675018 first col mean 0.11235649138689041 all mean 0.1196957677602768
0.26242756843566895 0.26242756843566895
rl training, epoch8, iter0, batch786/1133, batch loss:0.26242756843566895, Training time:28094.320947885513
batch reward last col mean 0.0717226192355156 first col mean 0.10995031893253326 all mean 0.08295568078756332
0.260016530752182 0.260016530752182
rl training, epoch8, iter0, batch787/1133, batch loss:0.260016530752182, Training time:28096.047528505325
batch reward last col mean 0.08890742063522339 first col mean 0.09929203987121582 all mean 0.09871881455183029
0.27768296003341675 0.27768296003341675
rl training, epoch8, iter0, batch788/1133, batch loss:0.27768296003341675, Training time:28097.803857803345
batch reward last col mean 0.11631269007921219 first col mean 0.1233106404542923 all mean 0.1201690211892128
0.3414275348186493 0.3414275646209717
rl training, epoch8, iter0, batch789/1133, batch loss:0.3414275646209717, Training time:28100.741935014725
batch reward last col mean 0.10118288546800613 first col mean 0.11785691976547241 all mean 0.10822596400976181
0.31195253133773804 0.3119525611400604
rl training, epoch8, iter0, batch790/1133, batch loss:0.3119525611400604, Training time:28103.18017911911
batch reward last col mean 0.0704752504825592 first col mean 0.10088160634040833 all mean 0.08198036253452301
0.2646011412143707 0.2646011412143707
rl training, epoch8, iter0, batch791/1133, batch loss:0.2646011412143707, Training time:28105.1449944973
batch reward last col mean 0.14243651926517487 first col mean 0.09857118129730225 all mean 0.12818561494350433
0.35086312890052795 0.35086312890052795
rl training, epoch8, iter0, batch792/1133, batch loss:0.35086312890052795, Training time:28107.529277324677
batch reward last col mean 0.11347834765911102 first col mean 0.11010946333408356 all mean 0.11302399635314941
0.33379027247428894 0.33379027247428894
rl training, epoch8, iter0, batch793/1133, batch loss:0.33379027247428894, Training time:28110.040286064148
batch reward last col mean 0.07311714440584183 first col mean 0.10384922474622726 all mean 0.08499762415885925
0.25025948882102966 0.25025948882102966
rl training, epoch8, iter0, batch794/1133, batch loss:0.25025948882102966, Training time:28112.023935317993
batch reward last col mean 0.08264446258544922 first col mean 0.11758925020694733 all mean 0.08952115476131439
0.2715025544166565 0.2715025544166565
rl training, epoch8, iter0, batch795/1133, batch loss:0.2715025544166565, Training time:28114.441566944122
batch reward last col mean 0.09517768025398254 first col mean 0.12289944291114807 all mean 0.1009470596909523
0.2671758532524109 0.2671758234500885
rl training, epoch8, iter0, batch796/1133, batch loss:0.2671758234500885, Training time:28117.560546398163
batch reward last col mean 0.09351655840873718 first col mean 0.10076043009757996 all mean 0.09916337579488754
0.2910216748714447 0.2910216748714447
rl training, epoch8, iter0, batch797/1133, batch loss:0.2910216748714447, Training time:28119.642223596573
batch reward last col mean 0.13515788316726685 first col mean 0.10481253266334534 all mean 0.12959632277488708
0.3403826951980591 0.3403826951980591
rl training, epoch8, iter0, batch798/1133, batch loss:0.3403826951980591, Training time:28122.015993118286
batch reward last col mean 0.12492530047893524 first col mean 0.11536554247140884 all mean 0.12168194353580475
0.31151068210601807 0.31151068210601807
rl training, epoch8, iter0, batch799/1133, batch loss:0.31151068210601807, Training time:28124.400360822678
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46585625883550213 Time: 100.9745078086853 s
loss of true 0.19987420785090404 loss of gen 0.17366425532252516 loss of other 0.09231779575906858 first score 0.10357437282800674
batch reward last col mean 0.12999355792999268 first col mean 0.12943460047245026 all mean 0.12523238360881805
0.3066146969795227 0.3066146671772003
rl training, epoch8, iter0, batch800/1133, batch loss:0.3066146671772003, Training time:28227.247124671936
batch reward last col mean 0.0932624489068985 first col mean 0.11198679357767105 all mean 0.09827250242233276
0.28040748834609985 0.28040748834609985
rl training, epoch8, iter0, batch801/1133, batch loss:0.28040748834609985, Training time:28229.32145524025
batch reward last col mean 0.08134691417217255 first col mean 0.10968459397554398 all mean 0.09053643047809601
0.2624688446521759 0.2624688446521759
rl training, epoch8, iter0, batch802/1133, batch loss:0.2624688446521759, Training time:28231.173532485962
batch reward last col mean 0.07014085352420807 first col mean 0.09088961780071259 all mean 0.07746407389640808
0.23796159029006958 0.23796159029006958
rl training, epoch8, iter0, batch803/1133, batch loss:0.23796159029006958, Training time:28233.01637506485
batch reward last col mean 0.10702134668827057 first col mean 0.10876503586769104 all mean 0.10356666892766953
0.2646375596523285 0.2646375894546509
rl training, epoch8, iter0, batch804/1133, batch loss:0.2646375894546509, Training time:28235.753564834595
batch reward last col mean 0.12204043567180634 first col mean 0.11259540915489197 all mean 0.1142866387963295
0.3394450545310974 0.3394450545310974
rl training, epoch8, iter0, batch805/1133, batch loss:0.3394450545310974, Training time:28238.143858909607
batch reward last col mean 0.07162026315927505 first col mean 0.12975744903087616 all mean 0.08698184788227081
0.2542572319507599 0.2542572319507599
rl training, epoch8, iter0, batch806/1133, batch loss:0.2542572319507599, Training time:28240.244706869125
batch reward last col mean 0.10470977425575256 first col mean 0.09440194070339203 all mean 0.10550615191459656
0.3120344579219818 0.3120344579219818
rl training, epoch8, iter0, batch807/1133, batch loss:0.3120344579219818, Training time:28242.203703165054
batch reward last col mean 0.08616453409194946 first col mean 0.11003661900758743 all mean 0.09385805577039719
0.281388521194458 0.281388521194458
rl training, epoch8, iter0, batch808/1133, batch loss:0.281388521194458, Training time:28244.295873880386
batch reward last col mean 0.13547086715698242 first col mean 0.10974996536970139 all mean 0.12392543256282806
0.3250932991504669 0.3250932991504669
rl training, epoch8, iter0, batch809/1133, batch loss:0.3250932991504669, Training time:28246.18013858795
batch reward last col mean 0.10099617391824722 first col mean 0.10534346848726273 all mean 0.10206124186515808
0.2555253803730011 0.2555253803730011
rl training, epoch8, iter0, batch810/1133, batch loss:0.2555253803730011, Training time:28248.259808063507
batch reward last col mean 0.08716551959514618 first col mean 0.09759216010570526 all mean 0.09700772166252136
0.2940296530723572 0.2940296530723572
rl training, epoch8, iter0, batch811/1133, batch loss:0.2940296530723572, Training time:28250.40155529976
batch reward last col mean 0.07302821427583694 first col mean 0.11665693670511246 all mean 0.07761109620332718
0.2662474811077118 0.2662474811077118
rl training, epoch8, iter0, batch812/1133, batch loss:0.2662474811077118, Training time:28252.712005615234
batch reward last col mean 0.11711551249027252 first col mean 0.0998997911810875 all mean 0.11229003965854645
0.3039275109767914 0.3039275109767914
rl training, epoch8, iter0, batch813/1133, batch loss:0.3039275109767914, Training time:28254.761541366577
batch reward last col mean 0.11839648336172104 first col mean 0.09472798556089401 all mean 0.10727748274803162
0.28936704993247986 0.28936707973480225
rl training, epoch8, iter0, batch814/1133, batch loss:0.28936707973480225, Training time:28256.46902036667
batch reward last col mean 0.09924455732107162 first col mean 0.10709332674741745 all mean 0.10266352444887161
0.2799226641654968 0.2799226641654968
rl training, epoch8, iter0, batch815/1133, batch loss:0.2799226641654968, Training time:28258.426755666733
batch reward last col mean 0.10462544858455658 first col mean 0.09555280953645706 all mean 0.10167127102613449
0.26706740260124207 0.26706740260124207
rl training, epoch8, iter0, batch816/1133, batch loss:0.26706740260124207, Training time:28260.259736776352
batch reward last col mean 0.09372679144144058 first col mean 0.11723887175321579 all mean 0.09597098082304001
0.2748267650604248 0.2748267650604248
rl training, epoch8, iter0, batch817/1133, batch loss:0.2748267650604248, Training time:28263.21811723709
batch reward last col mean 0.10724064707756042 first col mean 0.10287939012050629 all mean 0.10519206523895264
0.2637978792190552 0.2637978792190552
rl training, epoch8, iter0, batch818/1133, batch loss:0.2637978792190552, Training time:28265.296271800995
batch reward last col mean 0.0896100178360939 first col mean 0.10028789192438126 all mean 0.09226781874895096
0.2819277346134186 0.28192776441574097
rl training, epoch8, iter0, batch819/1133, batch loss:0.28192776441574097, Training time:28267.426454782486
batch reward last col mean 0.12827332317829132 first col mean 0.10470835119485855 all mean 0.1274326592683792
0.323263555765152 0.323263555765152
rl training, epoch8, iter0, batch820/1133, batch loss:0.323263555765152, Training time:28270.049081087112
batch reward last col mean 0.0828837975859642 first col mean 0.1054493635892868 all mean 0.08752891421318054
0.24567361176013947 0.24567361176013947
rl training, epoch8, iter0, batch821/1133, batch loss:0.24567361176013947, Training time:28272.194816589355
batch reward last col mean 0.08680127561092377 first col mean 0.10545095801353455 all mean 0.08924213796854019
0.22740289568901062 0.22740289568901062
rl training, epoch8, iter0, batch822/1133, batch loss:0.22740289568901062, Training time:28274.807275772095
batch reward last col mean 0.09493505209684372 first col mean 0.10404390841722488 all mean 0.09978880733251572
0.2856840193271637 0.2856840491294861
rl training, epoch8, iter0, batch823/1133, batch loss:0.2856840491294861, Training time:28276.67701601982
batch reward last col mean 0.09803766012191772 first col mean 0.11497136205434799 all mean 0.09879373759031296
0.24799908697605133 0.24799908697605133
rl training, epoch8, iter0, batch824/1133, batch loss:0.24799908697605133, Training time:28278.980097055435
batch reward last col mean 0.1284487545490265 first col mean 0.12771961092948914 all mean 0.12147781252861023
0.3314778506755829 0.3314778506755829
rl training, epoch8, iter0, batch825/1133, batch loss:0.3314778506755829, Training time:28281.23169541359
batch reward last col mean 0.10806866735219955 first col mean 0.10892824828624725 all mean 0.10206630080938339
0.27779507637023926 0.27779507637023926
rl training, epoch8, iter0, batch826/1133, batch loss:0.27779507637023926, Training time:28283.273181438446
batch reward last col mean 0.07738697528839111 first col mean 0.12428098917007446 all mean 0.08849506080150604
0.26566123962402344 0.26566123962402344
rl training, epoch8, iter0, batch827/1133, batch loss:0.26566123962402344, Training time:28285.18523335457
batch reward last col mean 0.09716150164604187 first col mean 0.14244544506072998 all mean 0.10427135974168777
0.3153526484966278 0.3153526186943054
rl training, epoch8, iter0, batch828/1133, batch loss:0.3153526186943054, Training time:28286.96362233162
batch reward last col mean 0.12937518954277039 first col mean 0.11760777235031128 all mean 0.11936254799365997
0.28899267315864563 0.28899267315864563
rl training, epoch8, iter0, batch829/1133, batch loss:0.28899267315864563, Training time:28289.176292657852
batch reward last col mean 0.06664062291383743 first col mean 0.11968982219696045 all mean 0.07619572430849075
0.2584596276283264 0.2584596276283264
rl training, epoch8, iter0, batch830/1133, batch loss:0.2584596276283264, Training time:28291.56123161316
batch reward last col mean 0.11359760165214539 first col mean 0.11756649613380432 all mean 0.1162332072854042
0.2970658540725708 0.2970658540725708
rl training, epoch8, iter0, batch831/1133, batch loss:0.2970658540725708, Training time:28293.38020348549
batch reward last col mean 0.10497937351465225 first col mean 0.10565359890460968 all mean 0.10425369441509247
0.28852149844169617 0.28852149844169617
rl training, epoch8, iter0, batch832/1133, batch loss:0.28852149844169617, Training time:28295.25626540184
batch reward last col mean 0.09921322017908096 first col mean 0.10686417669057846 all mean 0.10113765299320221
0.24813586473464966 0.24813586473464966
rl training, epoch8, iter0, batch833/1133, batch loss:0.24813586473464966, Training time:28297.616100788116
batch reward last col mean 0.10441114008426666 first col mean 0.14017422497272491 all mean 0.10306230187416077
0.2959372103214264 0.2959372103214264
rl training, epoch8, iter0, batch834/1133, batch loss:0.2959372103214264, Training time:28299.8746342659
batch reward last col mean 0.08414190262556076 first col mean 0.1135164424777031 all mean 0.09376145899295807
0.28022265434265137 0.28022265434265137
rl training, epoch8, iter0, batch835/1133, batch loss:0.28022265434265137, Training time:28301.61216402054
batch reward last col mean 0.10557029396295547 first col mean 0.12116748094558716 all mean 0.10264560580253601
0.27719902992248535 0.27719902992248535
rl training, epoch8, iter0, batch836/1133, batch loss:0.27719902992248535, Training time:28303.647357702255
batch reward last col mean 0.1025083065032959 first col mean 0.09621573984622955 all mean 0.1032262071967125
0.2920510172843933 0.2920510172843933
rl training, epoch8, iter0, batch837/1133, batch loss:0.2920510172843933, Training time:28305.655438184738
batch reward last col mean 0.10952484607696533 first col mean 0.11795449256896973 all mean 0.11639374494552612
0.3137689232826233 0.3137689232826233
rl training, epoch8, iter0, batch838/1133, batch loss:0.3137689232826233, Training time:28307.788519382477
batch reward last col mean 0.1071975901722908 first col mean 0.09644844383001328 all mean 0.10335210710763931
0.29071280360221863 0.29071280360221863
rl training, epoch8, iter0, batch839/1133, batch loss:0.29071280360221863, Training time:28311.183629751205
batch reward last col mean 0.09399926662445068 first col mean 0.1090468168258667 all mean 0.0933467224240303
0.27143874764442444 0.27143874764442444
rl training, epoch8, iter0, batch840/1133, batch loss:0.27143874764442444, Training time:28313.500700235367
batch reward last col mean 0.07461857050657272 first col mean 0.12188290059566498 all mean 0.08334262669086456
0.27202656865119934 0.27202656865119934
rl training, epoch8, iter0, batch841/1133, batch loss:0.27202656865119934, Training time:28315.655426502228
batch reward last col mean 0.09472085535526276 first col mean 0.12930096685886383 all mean 0.0979408472776413
0.26406869292259216 0.26406869292259216
rl training, epoch8, iter0, batch842/1133, batch loss:0.26406869292259216, Training time:28318.060507059097
batch reward last col mean 0.10548560321331024 first col mean 0.09983865916728973 all mean 0.10468363016843796
0.28628596663475037 0.28628596663475037
rl training, epoch8, iter0, batch843/1133, batch loss:0.28628596663475037, Training time:28319.952888011932
batch reward last col mean 0.13562551140785217 first col mean 0.08057305216789246 all mean 0.1265588402748108
0.2620411813259125 0.2620411813259125
rl training, epoch8, iter0, batch844/1133, batch loss:0.2620411813259125, Training time:28321.884605407715
batch reward last col mean 0.08410809934139252 first col mean 0.09674069285392761 all mean 0.08594140410423279
0.2366514950990677 0.2366514950990677
rl training, epoch8, iter0, batch845/1133, batch loss:0.2366514950990677, Training time:28325.704882621765
batch reward last col mean 0.09613139182329178 first col mean 0.08739330619573593 all mean 0.09972276538610458
0.2618490159511566 0.2618490159511566
rl training, epoch8, iter0, batch846/1133, batch loss:0.2618490159511566, Training time:28328.935067653656
batch reward last col mean 0.10458367317914963 first col mean 0.09669758379459381 all mean 0.10625442862510681
0.29638242721557617 0.29638242721557617
rl training, epoch8, iter0, batch847/1133, batch loss:0.29638242721557617, Training time:28330.94290304184
batch reward last col mean 0.09580326080322266 first col mean 0.10789617896080017 all mean 0.10663075000047684
0.2557097375392914 0.2557097375392914
rl training, epoch8, iter0, batch848/1133, batch loss:0.2557097375392914, Training time:28333.020862817764
batch reward last col mean 0.08134390413761139 first col mean 0.08668698370456696 all mean 0.08656250685453415
0.23228493332862854 0.23228490352630615
rl training, epoch8, iter0, batch849/1133, batch loss:0.23228490352630615, Training time:28335.37238907814
batch reward last col mean 0.07471727579832077 first col mean 0.11404082179069519 all mean 0.08085951209068298
0.23945066332817078 0.23945066332817078
rl training, epoch8, iter0, batch850/1133, batch loss:0.23945066332817078, Training time:28337.753796577454
batch reward last col mean 0.13485735654830933 first col mean 0.09261476993560791 all mean 0.1271478831768036
0.3231510519981384 0.3231510519981384
rl training, epoch8, iter0, batch851/1133, batch loss:0.3231510519981384, Training time:28340.487102746964
batch reward last col mean 0.10959357768297195 first col mean 0.10355190187692642 all mean 0.10334718972444534
0.2617661952972412 0.2617661952972412
rl training, epoch8, iter0, batch852/1133, batch loss:0.2617661952972412, Training time:28342.51432442665
batch reward last col mean 0.08446140587329865 first col mean 0.10443753749132156 all mean 0.0849781334400177
0.2706705331802368 0.2706705331802368
rl training, epoch8, iter0, batch853/1133, batch loss:0.2706705331802368, Training time:28345.905114889145
batch reward last col mean 0.09413651376962662 first col mean 0.1029331237077713 all mean 0.09766454994678497
0.2573275566101074 0.2573275566101074
rl training, epoch8, iter0, batch854/1133, batch loss:0.2573275566101074, Training time:28348.27139019966
batch reward last col mean 0.09078052639961243 first col mean 0.09578289836645126 all mean 0.09879609942436218
0.2659577429294586 0.2659577429294586
rl training, epoch8, iter0, batch855/1133, batch loss:0.2659577429294586, Training time:28350.813430547714
batch reward last col mean 0.11718524247407913 first col mean 0.12208832800388336 all mean 0.10866230726242065
0.2870001494884491 0.2870001494884491
rl training, epoch8, iter0, batch856/1133, batch loss:0.2870001494884491, Training time:28352.894550800323
batch reward last col mean 0.09706449508666992 first col mean 0.10959035903215408 all mean 0.09889698028564453
0.2912540137767792 0.2912540137767792
rl training, epoch8, iter0, batch857/1133, batch loss:0.2912540137767792, Training time:28355.376354932785
batch reward last col mean 0.12124837934970856 first col mean 0.10119212418794632 all mean 0.11540345102548599
0.2836953103542328 0.2836953103542328
rl training, epoch8, iter0, batch858/1133, batch loss:0.2836953103542328, Training time:28357.454226732254
batch reward last col mean 0.08667386323213577 first col mean 0.10993446409702301 all mean 0.09327525645494461
0.2969578802585602 0.2969578802585602
rl training, epoch8, iter0, batch859/1133, batch loss:0.2969578802585602, Training time:28359.471585035324
batch reward last col mean 0.09481216967105865 first col mean 0.1191234141588211 all mean 0.10334371030330658
0.2890315651893616 0.2890315651893616
rl training, epoch8, iter0, batch860/1133, batch loss:0.2890315651893616, Training time:28361.655846357346
batch reward last col mean 0.09143213927745819 first col mean 0.10281039774417877 all mean 0.0956127792596817
0.2884937822818756 0.2884937822818756
rl training, epoch8, iter0, batch861/1133, batch loss:0.2884937822818756, Training time:28364.047940015793
batch reward last col mean 0.08107637614011765 first col mean 0.11592846363782883 all mean 0.09039002656936646
0.27160629630088806 0.27160629630088806
rl training, epoch8, iter0, batch862/1133, batch loss:0.27160629630088806, Training time:28366.568484783173
batch reward last col mean 0.11563793569803238 first col mean 0.13017767667770386 all mean 0.10881632566452026
0.3061540126800537 0.3061540126800537
rl training, epoch8, iter0, batch863/1133, batch loss:0.3061540126800537, Training time:28368.67296218872
batch reward last col mean 0.13270363211631775 first col mean 0.11791405081748962 all mean 0.12854264676570892
0.29499539732933044 0.29499539732933044
rl training, epoch8, iter0, batch864/1133, batch loss:0.29499539732933044, Training time:28370.65175843239
batch reward last col mean 0.0825926810503006 first col mean 0.12609553337097168 all mean 0.09212985634803772
0.235919788479805 0.235919788479805
rl training, epoch8, iter0, batch865/1133, batch loss:0.235919788479805, Training time:28372.9525949955
batch reward last col mean 0.09918208420276642 first col mean 0.094929039478302 all mean 0.10189174115657806
0.2567363977432251 0.2567363977432251
rl training, epoch8, iter0, batch866/1133, batch loss:0.2567363977432251, Training time:28375.39926624298
batch reward last col mean 0.06402704119682312 first col mean 0.09174301475286484 all mean 0.07336471229791641
0.24428758025169373 0.24428758025169373
rl training, epoch8, iter0, batch867/1133, batch loss:0.24428758025169373, Training time:28378.100722789764
batch reward last col mean 0.10820303112268448 first col mean 0.11602316051721573 all mean 0.108498215675354
0.29340100288391113 0.29340100288391113
rl training, epoch8, iter0, batch868/1133, batch loss:0.29340100288391113, Training time:28380.071615695953
batch reward last col mean 0.10333772748708725 first col mean 0.10023954510688782 all mean 0.10300418734550476
0.2990485727787018 0.2990485429763794
rl training, epoch8, iter0, batch869/1133, batch loss:0.2990485429763794, Training time:28382.382818698883
batch reward last col mean 0.0883217304944992 first col mean 0.09358100593090057 all mean 0.09417302906513214
0.2572556138038635 0.2572556138038635
rl training, epoch8, iter0, batch870/1133, batch loss:0.2572556138038635, Training time:28384.18789100647
batch reward last col mean 0.14013957977294922 first col mean 0.10919956862926483 all mean 0.13042287528514862
0.3250747621059418 0.3250747621059418
rl training, epoch8, iter0, batch871/1133, batch loss:0.3250747621059418, Training time:28387.389356851578
batch reward last col mean 0.10647192597389221 first col mean 0.11526857316493988 all mean 0.11354465037584305
0.303131639957428 0.30313166975975037
rl training, epoch8, iter0, batch872/1133, batch loss:0.30313166975975037, Training time:28390.214475870132
batch reward last col mean 0.12077951431274414 first col mean 0.1241089254617691 all mean 0.12432269006967545
0.35445693135261536 0.35445696115493774
rl training, epoch8, iter0, batch873/1133, batch loss:0.35445696115493774, Training time:28393.022874593735
batch reward last col mean 0.11135605722665787 first col mean 0.11747673153877258 all mean 0.11466061323881149
0.33023911714553833 0.33023911714553833
rl training, epoch8, iter0, batch874/1133, batch loss:0.33023911714553833, Training time:28395.383748054504
batch reward last col mean 0.09153317660093307 first col mean 0.10974912345409393 all mean 0.0985676571726799
0.2865125238895416 0.2865125238895416
rl training, epoch8, iter0, batch875/1133, batch loss:0.2865125238895416, Training time:28397.325615406036
batch reward last col mean 0.08133505284786224 first col mean 0.1238836944103241 all mean 0.08741991966962814
0.2771645188331604 0.2771645188331604
rl training, epoch8, iter0, batch876/1133, batch loss:0.2771645188331604, Training time:28399.91706252098
batch reward last col mean 0.0869334265589714 first col mean 0.10210537910461426 all mean 0.0956190899014473
0.2726633846759796 0.2726633846759796
rl training, epoch8, iter0, batch877/1133, batch loss:0.2726633846759796, Training time:28402.59869337082
batch reward last col mean 0.09433706104755402 first col mean 0.10900358855724335 all mean 0.09262138605117798
0.2962137460708618 0.2962137758731842
rl training, epoch8, iter0, batch878/1133, batch loss:0.2962137758731842, Training time:28405.083205223083
batch reward last col mean 0.09882170706987381 first col mean 0.11158141493797302 all mean 0.10071065276861191
0.2851974070072174 0.2851974070072174
rl training, epoch8, iter0, batch879/1133, batch loss:0.2851974070072174, Training time:28406.91720724106
batch reward last col mean 0.11858606338500977 first col mean 0.1124621257185936 all mean 0.11286324262619019
0.2774942219257355 0.2774942219257355
rl training, epoch8, iter0, batch880/1133, batch loss:0.2774942219257355, Training time:28409.33643579483
batch reward last col mean 0.11557114124298096 first col mean 0.11365684866905212 all mean 0.11655568331480026
0.3107132017612457 0.3107132017612457
rl training, epoch8, iter0, batch881/1133, batch loss:0.3107132017612457, Training time:28412.16134238243
batch reward last col mean 0.11895807087421417 first col mean 0.1134231686592102 all mean 0.11656847596168518
0.3542819321155548 0.3542819321155548
rl training, epoch8, iter0, batch882/1133, batch loss:0.3542819321155548, Training time:28414.072041988373
batch reward last col mean 0.1169617623090744 first col mean 0.10722467303276062 all mean 0.11488045752048492
0.3013927936553955 0.3013927936553955
rl training, epoch8, iter0, batch883/1133, batch loss:0.3013927936553955, Training time:28416.321046829224
batch reward last col mean 0.1050986722111702 first col mean 0.11801102757453918 all mean 0.10765662789344788
0.29336440563201904 0.29336440563201904
rl training, epoch8, iter0, batch884/1133, batch loss:0.29336440563201904, Training time:28418.416996479034
batch reward last col mean 0.11613120138645172 first col mean 0.11409977078437805 all mean 0.11202848702669144
0.27008485794067383 0.27008485794067383
rl training, epoch8, iter0, batch885/1133, batch loss:0.27008485794067383, Training time:28420.79297351837
batch reward last col mean 0.10842502862215042 first col mean 0.09366114437580109 all mean 0.11253505200147629
0.3349599242210388 0.3349599242210388
rl training, epoch8, iter0, batch886/1133, batch loss:0.3349599242210388, Training time:28423.700932979584
batch reward last col mean 0.139971524477005 first col mean 0.11737221479415894 all mean 0.12720753252506256
0.275000661611557 0.275000661611557
rl training, epoch8, iter0, batch887/1133, batch loss:0.275000661611557, Training time:28425.95168042183
batch reward last col mean 0.07208012789487839 first col mean 0.09087624400854111 all mean 0.07751274108886719
0.25770193338394165 0.25770193338394165
rl training, epoch8, iter0, batch888/1133, batch loss:0.25770193338394165, Training time:28428.809275388718
batch reward last col mean 0.11334455758333206 first col mean 0.09541837871074677 all mean 0.1101975217461586
0.32182571291923523 0.32182571291923523
rl training, epoch8, iter0, batch889/1133, batch loss:0.32182571291923523, Training time:28431.942378282547
batch reward last col mean 0.12141744792461395 first col mean 0.11776821315288544 all mean 0.11754364520311356
0.3344138264656067 0.3344138264656067
rl training, epoch8, iter0, batch890/1133, batch loss:0.3344138264656067, Training time:28434.390525579453
batch reward last col mean 0.07624517381191254 first col mean 0.11584492027759552 all mean 0.0917278379201889
0.302286297082901 0.302286297082901
rl training, epoch8, iter0, batch891/1133, batch loss:0.302286297082901, Training time:28436.578775644302
batch reward last col mean 0.12222645431756973 first col mean 0.12966251373291016 all mean 0.12168583273887634
0.3570551872253418 0.3570551872253418
rl training, epoch8, iter0, batch892/1133, batch loss:0.3570551872253418, Training time:28439.521959781647
batch reward last col mean 0.09734265506267548 first col mean 0.10791835933923721 all mean 0.09782441705465317
0.2868827283382416 0.2868827283382416
rl training, epoch8, iter0, batch893/1133, batch loss:0.2868827283382416, Training time:28441.844935417175
batch reward last col mean 0.11759090423583984 first col mean 0.11875485628843307 all mean 0.1207185685634613
0.281941294670105 0.2819412648677826
rl training, epoch8, iter0, batch894/1133, batch loss:0.2819412648677826, Training time:28444.640184879303
batch reward last col mean 0.08558168262243271 first col mean 0.11670341342687607 all mean 0.09825970232486725
0.29978808760643005 0.29978808760643005
rl training, epoch8, iter0, batch895/1133, batch loss:0.29978808760643005, Training time:28446.99489402771
batch reward last col mean 0.12328457832336426 first col mean 0.1196514144539833 all mean 0.12082069367170334
0.28502383828163147 0.28502383828163147
rl training, epoch8, iter0, batch896/1133, batch loss:0.28502383828163147, Training time:28448.937067985535
batch reward last col mean 0.0876811072230339 first col mean 0.10426266491413116 all mean 0.0990583598613739
0.3039565086364746 0.3039565086364746
rl training, epoch8, iter0, batch897/1133, batch loss:0.3039565086364746, Training time:28451.168752908707
batch reward last col mean 0.1040714755654335 first col mean 0.13071748614311218 all mean 0.10405497252941132
0.2553066909313202 0.2553066909313202
rl training, epoch8, iter0, batch898/1133, batch loss:0.2553066909313202, Training time:28452.837030887604
batch reward last col mean 0.10013938695192337 first col mean 0.1156827062368393 all mean 0.10317609459161758
0.27716904878616333 0.27716901898384094
rl training, epoch8, iter0, batch899/1133, batch loss:0.27716901898384094, Training time:28455.64267873764
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.46990570449660757 Time: 103.5097131729126 s
loss of true 0.20279174488751317 loss of gen 0.17442595046621873 loss of other 0.09268800892586847 first score 0.12946829199790955
batch reward last col mean 0.06834978610277176 first col mean 0.09936390817165375 all mean 0.07410638779401779
0.2344760000705719 0.2344760000705719
rl training, epoch8, iter0, batch900/1133, batch loss:0.2344760000705719, Training time:28561.594214200974
batch reward last col mean 0.0995839536190033 first col mean 0.10645051300525665 all mean 0.09886938333511353
0.28470417857170105 0.28470417857170105
rl training, epoch8, iter0, batch901/1133, batch loss:0.28470417857170105, Training time:28563.97188282013
batch reward last col mean 0.11146453022956848 first col mean 0.11195360124111176 all mean 0.10874279588460922
0.29112008213996887 0.29112008213996887
rl training, epoch8, iter0, batch902/1133, batch loss:0.29112008213996887, Training time:28566.17564058304
batch reward last col mean 0.08499832451343536 first col mean 0.09992263466119766 all mean 0.09141500294208527
0.2545226812362671 0.2545226812362671
rl training, epoch8, iter0, batch903/1133, batch loss:0.2545226812362671, Training time:28568.23673939705
batch reward last col mean 0.09333119541406631 first col mean 0.10792824625968933 all mean 0.09687117487192154
0.2859768867492676 0.2859768867492676
rl training, epoch8, iter0, batch904/1133, batch loss:0.2859768867492676, Training time:28570.552459716797
batch reward last col mean 0.07385986298322678 first col mean 0.10761576890945435 all mean 0.08210000395774841
0.24331112205982208 0.24331112205982208
rl training, epoch8, iter0, batch905/1133, batch loss:0.24331112205982208, Training time:28573.37439084053
batch reward last col mean 0.12441548705101013 first col mean 0.10102257877588272 all mean 0.11835303902626038
0.27928006649017334 0.27928006649017334
rl training, epoch8, iter0, batch906/1133, batch loss:0.27928006649017334, Training time:28575.788635969162
batch reward last col mean 0.10842285305261612 first col mean 0.0950850322842598 all mean 0.10715140402317047
0.23738262057304382 0.23738262057304382
rl training, epoch8, iter0, batch907/1133, batch loss:0.23738262057304382, Training time:28578.96650338173
batch reward last col mean 0.12200811505317688 first col mean 0.09967482089996338 all mean 0.11872223019599915
0.2596387267112732 0.2596387267112732
rl training, epoch8, iter0, batch908/1133, batch loss:0.2596387267112732, Training time:28581.38090324402
batch reward last col mean 0.07487791776657104 first col mean 0.11051877588033676 all mean 0.08167312294244766
0.2505384683609009 0.2505384683609009
rl training, epoch8, iter0, batch909/1133, batch loss:0.2505384683609009, Training time:28583.579667568207
batch reward last col mean 0.06460495293140411 first col mean 0.09340662509202957 all mean 0.07452535629272461
0.2484203428030014 0.2484203428030014
rl training, epoch8, iter0, batch910/1133, batch loss:0.2484203428030014, Training time:28585.597501277924
batch reward last col mean 0.11507020890712738 first col mean 0.09377773106098175 all mean 0.11159658432006836
0.24408480525016785 0.24408480525016785
rl training, epoch8, iter0, batch911/1133, batch loss:0.24408480525016785, Training time:28588.54108762741
batch reward last col mean 0.1359717696905136 first col mean 0.10045667737722397 all mean 0.12528952956199646
0.2566831111907959 0.2566831111907959
rl training, epoch8, iter0, batch912/1133, batch loss:0.2566831111907959, Training time:28591.32368516922
batch reward last col mean 0.062159281224012375 first col mean 0.09537848830223083 all mean 0.07561451196670532
0.22771796584129333 0.22771798074245453
rl training, epoch8, iter0, batch913/1133, batch loss:0.22771798074245453, Training time:28593.918076992035
batch reward last col mean 0.10025031864643097 first col mean 0.09773041307926178 all mean 0.10432121157646179
0.27246177196502686 0.27246177196502686
rl training, epoch8, iter0, batch914/1133, batch loss:0.27246177196502686, Training time:28596.224943876266
batch reward last col mean 0.10076159238815308 first col mean 0.08673205226659775 all mean 0.10462690144777298
0.2836935520172119 0.2836935520172119
rl training, epoch8, iter0, batch915/1133, batch loss:0.2836935520172119, Training time:28598.934181690216
batch reward last col mean 0.0876452773809433 first col mean 0.10462582111358643 all mean 0.08724267035722733
0.2087695151567459 0.2087695151567459
rl training, epoch8, iter0, batch916/1133, batch loss:0.2087695151567459, Training time:28601.751905202866
batch reward last col mean 0.09019939601421356 first col mean 0.11029081046581268 all mean 0.08907432109117508
0.2198762744665146 0.2198762744665146
rl training, epoch8, iter0, batch917/1133, batch loss:0.2198762744665146, Training time:28604.90416240692
batch reward last col mean 0.10479047894477844 first col mean 0.09815611690282822 all mean 0.10288470983505249
0.22313843667507172 0.22313843667507172
rl training, epoch8, iter0, batch918/1133, batch loss:0.22313843667507172, Training time:28607.057023525238
batch reward last col mean 0.11763425171375275 first col mean 0.10802382975816727 all mean 0.11087426543235779
0.25081419944763184 0.25081419944763184
rl training, epoch8, iter0, batch919/1133, batch loss:0.25081419944763184, Training time:28609.44557929039
batch reward last col mean 0.12301219254732132 first col mean 0.09674955904483795 all mean 0.1156032532453537
0.2568027675151825 0.2568027675151825
rl training, epoch8, iter0, batch920/1133, batch loss:0.2568027675151825, Training time:28611.451687812805
batch reward last col mean 0.10269175469875336 first col mean 0.11331029236316681 all mean 0.10360226035118103
0.28332018852233887 0.28332018852233887
rl training, epoch8, iter0, batch921/1133, batch loss:0.28332018852233887, Training time:28614.181891679764
batch reward last col mean 0.10803364217281342 first col mean 0.10225027799606323 all mean 0.1065332368016243
0.22843784093856812 0.22843784093856812
rl training, epoch8, iter0, batch922/1133, batch loss:0.22843784093856812, Training time:28616.991191148758
batch reward last col mean 0.09407585114240646 first col mean 0.08962249010801315 all mean 0.0970359593629837
0.2776932120323181 0.2776932120323181
rl training, epoch8, iter0, batch923/1133, batch loss:0.2776932120323181, Training time:28619.211356163025
batch reward last col mean 0.08230216056108475 first col mean 0.10539545118808746 all mean 0.0903487578034401
0.2543613016605377 0.2543613016605377
rl training, epoch8, iter0, batch924/1133, batch loss:0.2543613016605377, Training time:28620.960172891617
batch reward last col mean 0.08303070068359375 first col mean 0.09679917991161346 all mean 0.09558164328336716
0.28753340244293213 0.28753340244293213
rl training, epoch8, iter0, batch925/1133, batch loss:0.28753340244293213, Training time:28622.832847833633
batch reward last col mean 0.09893573820590973 first col mean 0.11723031848669052 all mean 0.10135260969400406
0.26628729701042175 0.26628729701042175
rl training, epoch8, iter0, batch926/1133, batch loss:0.26628729701042175, Training time:28624.824749708176
batch reward last col mean 0.11825603246688843 first col mean 0.12510867416858673 all mean 0.11548227816820145
0.29374730587005615 0.29374730587005615
rl training, epoch8, iter0, batch927/1133, batch loss:0.29374730587005615, Training time:28627.841348171234
batch reward last col mean 0.08942127972841263 first col mean 0.0950838103890419 all mean 0.0963866114616394
0.22467055916786194 0.22467055916786194
rl training, epoch8, iter0, batch928/1133, batch loss:0.22467055916786194, Training time:28630.368222236633
batch reward last col mean 0.08543498069047928 first col mean 0.11906774342060089 all mean 0.09075815230607986
0.2393369972705841 0.2393369972705841
rl training, epoch8, iter0, batch929/1133, batch loss:0.2393369972705841, Training time:28632.47667646408
batch reward last col mean 0.0868569165468216 first col mean 0.10850977897644043 all mean 0.09552071243524551
0.2618103623390198 0.2618103623390198
rl training, epoch8, iter0, batch930/1133, batch loss:0.2618103623390198, Training time:28634.848516225815
batch reward last col mean 0.10549890995025635 first col mean 0.1045786514878273 all mean 0.10286473482847214
0.25774866342544556 0.25774866342544556
rl training, epoch8, iter0, batch931/1133, batch loss:0.25774866342544556, Training time:28636.86998438835
batch reward last col mean 0.09974236786365509 first col mean 0.10187589377164841 all mean 0.0975024625658989
0.23797686398029327 0.23797686398029327
rl training, epoch8, iter0, batch932/1133, batch loss:0.23797686398029327, Training time:28638.788345098495
batch reward last col mean 0.05684589594602585 first col mean 0.11103849858045578 all mean 0.06585323810577393
0.21733592450618744 0.21733592450618744
rl training, epoch8, iter0, batch933/1133, batch loss:0.21733592450618744, Training time:28640.52002453804
batch reward last col mean 0.12171206623315811 first col mean 0.1019987165927887 all mean 0.11747235804796219
0.28711915016174316 0.28711915016174316
rl training, epoch8, iter0, batch934/1133, batch loss:0.28711915016174316, Training time:28642.49828863144
batch reward last col mean 0.07957236468791962 first col mean 0.08567984402179718 all mean 0.09003165364265442
0.25796830654144287 0.25796830654144287
rl training, epoch8, iter0, batch935/1133, batch loss:0.25796830654144287, Training time:28644.637800455093
batch reward last col mean 0.0784236416220665 first col mean 0.115738645195961 all mean 0.0860464945435524
0.2464323341846466 0.2464323341846466
rl training, epoch8, iter0, batch936/1133, batch loss:0.2464323341846466, Training time:28646.914532899857
batch reward last col mean 0.10553663969039917 first col mean 0.10232512652873993 all mean 0.10600091516971588
0.29180726408958435 0.29180726408958435
rl training, epoch8, iter0, batch937/1133, batch loss:0.29180726408958435, Training time:28649.09619998932
batch reward last col mean 0.07469518482685089 first col mean 0.09135839343070984 all mean 0.08017531037330627
0.24447162449359894 0.24447162449359894
rl training, epoch8, iter0, batch938/1133, batch loss:0.24447162449359894, Training time:28651.12959599495
batch reward last col mean 0.08433933556079865 first col mean 0.10618510842323303 all mean 0.09523555636405945
0.27257171273231506 0.27257171273231506
rl training, epoch8, iter0, batch939/1133, batch loss:0.27257171273231506, Training time:28652.8263835907
batch reward last col mean 0.11199573427438736 first col mean 0.1109098494052887 all mean 0.1114138662815094
0.29376736283302307 0.29376736283302307
rl training, epoch8, iter0, batch940/1133, batch loss:0.29376736283302307, Training time:28655.077781677246
batch reward last col mean 0.10915781557559967 first col mean 0.10991838574409485 all mean 0.10746851563453674
0.2728494703769684 0.2728494703769684
rl training, epoch8, iter0, batch941/1133, batch loss:0.2728494703769684, Training time:28657.049677848816
batch reward last col mean 0.10399709641933441 first col mean 0.10338301956653595 all mean 0.09996658563613892
0.25733622908592224 0.25733622908592224
rl training, epoch8, iter0, batch942/1133, batch loss:0.25733622908592224, Training time:28659.206910848618
batch reward last col mean 0.10350751876831055 first col mean 0.12344907969236374 all mean 0.10387770086526871
0.27252131700515747 0.27252134680747986
rl training, epoch8, iter0, batch943/1133, batch loss:0.27252134680747986, Training time:28661.924837350845
batch reward last col mean 0.11512649059295654 first col mean 0.09754133969545364 all mean 0.11315736919641495
0.2681219279766083 0.2681219279766083
rl training, epoch8, iter0, batch944/1133, batch loss:0.2681219279766083, Training time:28664.173626422882
batch reward last col mean 0.10249456018209457 first col mean 0.10583925247192383 all mean 0.1020408421754837
0.29395225644111633 0.29395225644111633
rl training, epoch8, iter0, batch945/1133, batch loss:0.29395225644111633, Training time:28666.130666732788
batch reward last col mean 0.09952851384878159 first col mean 0.08768083155155182 all mean 0.10165910422801971
0.26668253540992737 0.26668253540992737
rl training, epoch8, iter0, batch946/1133, batch loss:0.26668253540992737, Training time:28668.324525117874
batch reward last col mean 0.09887703508138657 first col mean 0.10568349808454514 all mean 0.09632957726716995
0.24842149019241333 0.24842149019241333
rl training, epoch8, iter0, batch947/1133, batch loss:0.24842149019241333, Training time:28673.0434923172
batch reward last col mean 0.12259282171726227 first col mean 0.1077297106385231 all mean 0.11701151728630066
0.2755819857120514 0.2755819857120514
rl training, epoch8, iter0, batch948/1133, batch loss:0.2755819857120514, Training time:28675.39015698433
batch reward last col mean 0.10699544101953506 first col mean 0.09752179682254791 all mean 0.10741762071847916
0.30966442823410034 0.30966439843177795
rl training, epoch8, iter0, batch949/1133, batch loss:0.30966439843177795, Training time:28677.176629066467
batch reward last col mean 0.10777269303798676 first col mean 0.10455489158630371 all mean 0.10770214349031448
0.2884799838066101 0.2884799838066101
rl training, epoch8, iter0, batch950/1133, batch loss:0.2884799838066101, Training time:28679.153047800064
batch reward last col mean 0.08910126984119415 first col mean 0.11605408042669296 all mean 0.09202522784471512
0.26569822430610657 0.26569822430610657
rl training, epoch8, iter0, batch951/1133, batch loss:0.26569822430610657, Training time:28681.249530792236
batch reward last col mean 0.13574308156967163 first col mean 0.10459063947200775 all mean 0.13019335269927979
0.3054851293563843 0.3054851293563843
rl training, epoch8, iter0, batch952/1133, batch loss:0.3054851293563843, Training time:28683.45512199402
batch reward last col mean 0.0949382483959198 first col mean 0.09987187385559082 all mean 0.09687096625566483
0.2548481225967407 0.2548481225967407
rl training, epoch8, iter0, batch953/1133, batch loss:0.2548481225967407, Training time:28685.470376729965
batch reward last col mean 0.10564562678337097 first col mean 0.10792560875415802 all mean 0.10620765388011932
0.29283422231674194 0.29283422231674194
rl training, epoch8, iter0, batch954/1133, batch loss:0.29283422231674194, Training time:28687.260407686234
batch reward last col mean 0.07697577029466629 first col mean 0.10489780455827713 all mean 0.08269895613193512
0.2378150373697281 0.2378150373697281
rl training, epoch8, iter0, batch955/1133, batch loss:0.2378150373697281, Training time:28688.998064756393
batch reward last col mean 0.11707768589258194 first col mean 0.09583507478237152 all mean 0.11576549708843231
0.3019712567329407 0.3019712567329407
rl training, epoch8, iter0, batch956/1133, batch loss:0.3019712567329407, Training time:28691.77163028717
batch reward last col mean 0.09398815780878067 first col mean 0.10890413075685501 all mean 0.09711435437202454
0.2519333064556122 0.2519333064556122
rl training, epoch8, iter0, batch957/1133, batch loss:0.2519333064556122, Training time:28694.506967544556
batch reward last col mean 0.11724894493818283 first col mean 0.11826413124799728 all mean 0.11607953161001205
0.29228684306144714 0.29228684306144714
rl training, epoch8, iter0, batch958/1133, batch loss:0.29228684306144714, Training time:28696.458476543427
batch reward last col mean 0.1284581869840622 first col mean 0.10998344421386719 all mean 0.12590953707695007
0.2730603516101837 0.27306032180786133
rl training, epoch8, iter0, batch959/1133, batch loss:0.27306032180786133, Training time:28698.412310361862
batch reward last col mean 0.0637061819434166 first col mean 0.1277047097682953 all mean 0.07192472368478775
0.2409369945526123 0.2409369945526123
rl training, epoch8, iter0, batch960/1133, batch loss:0.2409369945526123, Training time:28700.485162734985
batch reward last col mean 0.1241200864315033 first col mean 0.12533938884735107 all mean 0.12451264262199402
0.33066993951797485 0.33066993951797485
rl training, epoch8, iter0, batch961/1133, batch loss:0.33066993951797485, Training time:28702.50872850418
batch reward last col mean 0.12817718088626862 first col mean 0.09600330144166946 all mean 0.11755384504795074
0.2596985101699829 0.2596985101699829
rl training, epoch8, iter0, batch962/1133, batch loss:0.2596985101699829, Training time:28704.810755968094
batch reward last col mean 0.06927900016307831 first col mean 0.09835285693407059 all mean 0.07461384683847427
0.2058124989271164 0.2058124989271164
rl training, epoch8, iter0, batch963/1133, batch loss:0.2058124989271164, Training time:28707.560888767242
batch reward last col mean 0.13437333703041077 first col mean 0.11478913575410843 all mean 0.12065725028514862
0.2895070016384125 0.2895070016384125
rl training, epoch8, iter0, batch964/1133, batch loss:0.2895070016384125, Training time:28709.566025972366
batch reward last col mean 0.0731932744383812 first col mean 0.09432727098464966 all mean 0.08003363013267517
0.2102600485086441 0.2102600485086441
rl training, epoch8, iter0, batch965/1133, batch loss:0.2102600485086441, Training time:28711.53287410736
batch reward last col mean 0.11390262842178345 first col mean 0.10440419614315033 all mean 0.10812414437532425
0.28607794642448425 0.28607794642448425
rl training, epoch8, iter0, batch966/1133, batch loss:0.28607794642448425, Training time:28713.435804367065
batch reward last col mean 0.05853307992219925 first col mean 0.12099667638540268 all mean 0.0723826065659523
0.27932122349739075 0.27932122349739075
rl training, epoch8, iter0, batch967/1133, batch loss:0.27932122349739075, Training time:28715.714470863342
batch reward last col mean 0.12544631958007812 first col mean 0.10747364163398743 all mean 0.11157605797052383
0.24981750547885895 0.24981750547885895
rl training, epoch8, iter0, batch968/1133, batch loss:0.24981750547885895, Training time:28717.42523241043
batch reward last col mean 0.08724068105220795 first col mean 0.10952293872833252 all mean 0.0924350917339325
0.24339500069618225 0.24339500069618225
rl training, epoch8, iter0, batch969/1133, batch loss:0.24339500069618225, Training time:28719.80296730995
batch reward last col mean 0.07348120212554932 first col mean 0.10647808015346527 all mean 0.07788689434528351
0.2694597840309143 0.2694597840309143
rl training, epoch8, iter0, batch970/1133, batch loss:0.2694597840309143, Training time:28724.144653320312
batch reward last col mean 0.1300145834684372 first col mean 0.11141817271709442 all mean 0.11979562044143677
0.2931896150112152 0.2931896150112152
rl training, epoch8, iter0, batch971/1133, batch loss:0.2931896150112152, Training time:28726.10583472252
batch reward last col mean 0.08078088611364365 first col mean 0.10265376418828964 all mean 0.0824408009648323
0.23476535081863403 0.23476535081863403
rl training, epoch8, iter0, batch972/1133, batch loss:0.23476535081863403, Training time:28728.2612555027
batch reward last col mean 0.13916167616844177 first col mean 0.10399742424488068 all mean 0.13598032295703888
0.2857041358947754 0.2857041358947754
rl training, epoch8, iter0, batch973/1133, batch loss:0.2857041358947754, Training time:28730.798453569412
batch reward last col mean 0.08660556375980377 first col mean 0.10839511454105377 all mean 0.0845157653093338
0.2299201339483261 0.2299201339483261
rl training, epoch8, iter0, batch974/1133, batch loss:0.2299201339483261, Training time:28732.755061626434
batch reward last col mean 0.11974776536226273 first col mean 0.11092722415924072 all mean 0.11160013824701309
0.3003404140472412 0.3003404140472412
rl training, epoch8, iter0, batch975/1133, batch loss:0.3003404140472412, Training time:28734.580587863922
batch reward last col mean 0.14658193290233612 first col mean 0.12139807641506195 all mean 0.13803105056285858
0.2727022171020508 0.27270224690437317
rl training, epoch8, iter0, batch976/1133, batch loss:0.27270224690437317, Training time:28736.666041135788
batch reward last col mean 0.10188260674476624 first col mean 0.0927911102771759 all mean 0.10348790884017944
0.27767080068588257 0.27767080068588257
rl training, epoch8, iter0, batch977/1133, batch loss:0.27767080068588257, Training time:28738.67633318901
batch reward last col mean 0.0910281240940094 first col mean 0.09485658258199692 all mean 0.0935550183057785
0.2567903995513916 0.2567903995513916
rl training, epoch8, iter0, batch978/1133, batch loss:0.2567903995513916, Training time:28741.85754776001
batch reward last col mean 0.0716448426246643 first col mean 0.12241371721029282 all mean 0.08081556111574173
0.2459048330783844 0.2459048330783844
rl training, epoch8, iter0, batch979/1133, batch loss:0.2459048330783844, Training time:28744.341181993484
batch reward last col mean 0.09088193625211716 first col mean 0.10892531275749207 all mean 0.08872708678245544
0.24868462979793549 0.24868462979793549
rl training, epoch8, iter0, batch980/1133, batch loss:0.24868462979793549, Training time:28746.364194631577
batch reward last col mean 0.12628212571144104 first col mean 0.09290523827075958 all mean 0.12074179947376251
0.3101462721824646 0.3101462721824646
rl training, epoch8, iter0, batch981/1133, batch loss:0.3101462721824646, Training time:28749.245342731476
batch reward last col mean 0.09657526761293411 first col mean 0.11046397686004639 all mean 0.100688636302948
0.25666800141334534 0.25666800141334534
rl training, epoch8, iter0, batch982/1133, batch loss:0.25666800141334534, Training time:28751.516172647476
batch reward last col mean 0.10043075680732727 first col mean 0.11052268743515015 all mean 0.10176490992307663
0.2678353786468506 0.2678353488445282
rl training, epoch8, iter0, batch983/1133, batch loss:0.2678353488445282, Training time:28754.126125335693
batch reward last col mean 0.10561873018741608 first col mean 0.11119851469993591 all mean 0.1031116470694542
0.27583473920822144 0.27583473920822144
rl training, epoch8, iter0, batch984/1133, batch loss:0.27583473920822144, Training time:28755.727172136307
batch reward last col mean 0.0969867929816246 first col mean 0.09597522765398026 all mean 0.09258650988340378
0.25009432435035706 0.25009429454803467
rl training, epoch8, iter0, batch985/1133, batch loss:0.25009429454803467, Training time:28757.59955239296
batch reward last col mean 0.10984034836292267 first col mean 0.11720048636198044 all mean 0.11036235094070435
0.29777222871780396 0.29777222871780396
rl training, epoch8, iter0, batch986/1133, batch loss:0.29777222871780396, Training time:28759.397248983383
batch reward last col mean 0.11214784532785416 first col mean 0.10166965425014496 all mean 0.10808396339416504
0.2521311044692993 0.2521311044692993
rl training, epoch8, iter0, batch987/1133, batch loss:0.2521311044692993, Training time:28761.09874534607
batch reward last col mean 0.1268118917942047 first col mean 0.09979861974716187 all mean 0.11596036702394485
0.29118046164512634 0.29118043184280396
rl training, epoch8, iter0, batch988/1133, batch loss:0.29118043184280396, Training time:28762.989011526108
batch reward last col mean 0.11671889573335648 first col mean 0.10027651488780975 all mean 0.11863909661769867
0.2869352400302887 0.2869352400302887
rl training, epoch8, iter0, batch989/1133, batch loss:0.2869352400302887, Training time:28764.961027383804
batch reward last col mean 0.09120725095272064 first col mean 0.10654990375041962 all mean 0.08929236978292465
0.2732333242893219 0.2732333242893219
rl training, epoch8, iter0, batch990/1133, batch loss:0.2732333242893219, Training time:28766.904162168503
batch reward last col mean 0.1061726063489914 first col mean 0.10977472364902496 all mean 0.10229991376399994
0.2608756124973297 0.2608756124973297
rl training, epoch8, iter0, batch991/1133, batch loss:0.2608756124973297, Training time:28769.052760362625
batch reward last col mean 0.11247020214796066 first col mean 0.11223184317350388 all mean 0.11124246567487717
0.29002946615219116 0.29002946615219116
rl training, epoch8, iter0, batch992/1133, batch loss:0.29002946615219116, Training time:28771.199872016907
batch reward last col mean 0.08616312593221664 first col mean 0.11103032529354095 all mean 0.0900723785161972
0.2808023989200592 0.2808023691177368
rl training, epoch8, iter0, batch993/1133, batch loss:0.2808023691177368, Training time:28773.675713539124
batch reward last col mean 0.0998782366514206 first col mean 0.11221568286418915 all mean 0.10064961016178131
0.2702499032020569 0.2702499032020569
rl training, epoch8, iter0, batch994/1133, batch loss:0.2702499032020569, Training time:28776.437592744827
batch reward last col mean 0.08839636296033859 first col mean 0.11099733412265778 all mean 0.09231632947921753
0.25350677967071533 0.25350677967071533
rl training, epoch8, iter0, batch995/1133, batch loss:0.25350677967071533, Training time:28778.538257598877
batch reward last col mean 0.09102985262870789 first col mean 0.11495373398065567 all mean 0.09981708973646164
0.26305845379829407 0.26305845379829407
rl training, epoch8, iter0, batch996/1133, batch loss:0.26305845379829407, Training time:28781.322657585144
batch reward last col mean 0.1066860482096672 first col mean 0.09579440206289291 all mean 0.10617836564779282
0.2609751224517822 0.26097509264945984
rl training, epoch8, iter0, batch997/1133, batch loss:0.26097509264945984, Training time:28784.085062742233
batch reward last col mean 0.09328007698059082 first col mean 0.11930025368928909 all mean 0.0997430607676506
0.2832337021827698 0.2832337021827698
rl training, epoch8, iter0, batch998/1133, batch loss:0.2832337021827698, Training time:28785.934366941452
batch reward last col mean 0.09369558095932007 first col mean 0.10622994601726532 all mean 0.09454513341188431
0.2607174515724182 0.2607174515724182
rl training, epoch8, iter0, batch999/1133, batch loss:0.2607174515724182, Training time:28787.63977909088
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4665984629216914 Time: 100.8286280632019 s
loss of true 0.2018524888189409 loss of gen 0.17123386159289336 loss of other 0.0935121121563984 first score 0.12912330031394958
batch reward last col mean 0.10712169110774994 first col mean 0.11861086636781693 all mean 0.10671710222959518
0.25345370173454285 0.25345370173454285
rl training, epoch8, iter0, batch1000/1133, batch loss:0.25345370173454285, Training time:28890.542573928833
batch reward last col mean 0.12027999013662338 first col mean 0.09466390311717987 all mean 0.11293809115886688
0.26745516061782837 0.267455130815506
rl training, epoch8, iter0, batch1001/1133, batch loss:0.267455130815506, Training time:28893.07199883461
batch reward last col mean 0.10795021057128906 first col mean 0.11546261608600616 all mean 0.10700634866952896
0.26459282636642456 0.26459282636642456
rl training, epoch8, iter0, batch1002/1133, batch loss:0.26459282636642456, Training time:28895.037881612778
batch reward last col mean 0.13118906319141388 first col mean 0.10708798468112946 all mean 0.12047941237688065
0.3069152235984802 0.3069152235984802
rl training, epoch8, iter0, batch1003/1133, batch loss:0.3069152235984802, Training time:28896.817118644714
batch reward last col mean 0.10453104227781296 first col mean 0.09801588952541351 all mean 0.10806954652070999
0.2872987389564514 0.2872987389564514
rl training, epoch8, iter0, batch1004/1133, batch loss:0.2872987389564514, Training time:28899.53552532196
batch reward last col mean 0.08520869165658951 first col mean 0.0956234484910965 all mean 0.0924408957362175
0.2423291802406311 0.2423291802406311
rl training, epoch8, iter0, batch1005/1133, batch loss:0.2423291802406311, Training time:28902.02377963066
batch reward last col mean 0.08584846556186676 first col mean 0.08941474556922913 all mean 0.08388343453407288
0.23044757544994354 0.23044757544994354
rl training, epoch8, iter0, batch1006/1133, batch loss:0.23044757544994354, Training time:28904.63382434845
batch reward last col mean 0.1196640133857727 first col mean 0.091324582695961 all mean 0.11155405640602112
0.2674029767513275 0.2674029767513275
rl training, epoch8, iter0, batch1007/1133, batch loss:0.2674029767513275, Training time:28906.905280590057
batch reward last col mean 0.08059358596801758 first col mean 0.10885286331176758 all mean 0.09027125686407089
0.2695002257823944 0.2695002257823944
rl training, epoch8, iter0, batch1008/1133, batch loss:0.2695002257823944, Training time:28909.045459508896
batch reward last col mean 0.08956608921289444 first col mean 0.09505365788936615 all mean 0.09489941596984863
0.23302310705184937 0.23302310705184937
rl training, epoch8, iter0, batch1009/1133, batch loss:0.23302310705184937, Training time:28911.442740917206
batch reward last col mean 0.09600679576396942 first col mean 0.10387054085731506 all mean 0.10017725080251694
0.26459985971450806 0.26459985971450806
rl training, epoch8, iter0, batch1010/1133, batch loss:0.26459985971450806, Training time:28913.817219257355
batch reward last col mean 0.11908818781375885 first col mean 0.1202707439661026 all mean 0.11488880217075348
0.29541951417922974 0.29541951417922974
rl training, epoch8, iter0, batch1011/1133, batch loss:0.29541951417922974, Training time:28916.03899860382
batch reward last col mean 0.1520719826221466 first col mean 0.08914738893508911 all mean 0.13415558636188507
0.26497313380241394 0.26497313380241394
rl training, epoch8, iter0, batch1012/1133, batch loss:0.26497313380241394, Training time:28918.14317035675
batch reward last col mean 0.07993900775909424 first col mean 0.10194363445043564 all mean 0.08467791229486465
0.23969657719135284 0.23969657719135284
rl training, epoch8, iter0, batch1013/1133, batch loss:0.23969657719135284, Training time:28920.10197854042
batch reward last col mean 0.11712794750928879 first col mean 0.10321934521198273 all mean 0.10783566534519196
0.2532161772251129 0.2532161772251129
rl training, epoch8, iter0, batch1014/1133, batch loss:0.2532161772251129, Training time:28921.918037891388
batch reward last col mean 0.1034456193447113 first col mean 0.1027938574552536 all mean 0.09848996251821518
0.27454090118408203 0.27454090118408203
rl training, epoch8, iter0, batch1015/1133, batch loss:0.27454090118408203, Training time:28925.025731563568
batch reward last col mean 0.09959037601947784 first col mean 0.07949992269277573 all mean 0.09478110820055008
0.23431606590747833 0.23431606590747833
rl training, epoch8, iter0, batch1016/1133, batch loss:0.23431606590747833, Training time:28927.218829631805
batch reward last col mean 0.06991821527481079 first col mean 0.0877205953001976 all mean 0.07965743541717529
0.23333027958869934 0.23333027958869934
rl training, epoch8, iter0, batch1017/1133, batch loss:0.23333027958869934, Training time:28929.43386864662
batch reward last col mean 0.10021759569644928 first col mean 0.09759803116321564 all mean 0.09675944596529007
0.29168999195098877 0.29168999195098877
rl training, epoch8, iter0, batch1018/1133, batch loss:0.29168999195098877, Training time:28931.91673207283
batch reward last col mean 0.09483553469181061 first col mean 0.09994029253721237 all mean 0.09518429636955261
0.2601419687271118 0.2601419687271118
rl training, epoch8, iter0, batch1019/1133, batch loss:0.2601419687271118, Training time:28934.044352531433
batch reward last col mean 0.12473797798156738 first col mean 0.08957742154598236 all mean 0.12157180160284042
0.2743121087551117 0.2743121087551117
rl training, epoch8, iter0, batch1020/1133, batch loss:0.2743121087551117, Training time:28936.06590294838
batch reward last col mean 0.058738403022289276 first col mean 0.09537189453840256 all mean 0.07171358913183212
0.2187144011259079 0.2187144011259079
rl training, epoch8, iter0, batch1021/1133, batch loss:0.2187144011259079, Training time:28938.267250299454
batch reward last col mean 0.11437293887138367 first col mean 0.14168395102024078 all mean 0.10844087600708008
0.26020342111587524 0.26020342111587524
rl training, epoch8, iter0, batch1022/1133, batch loss:0.26020342111587524, Training time:28940.31565475464
batch reward last col mean 0.14204558730125427 first col mean 0.11274830251932144 all mean 0.12721356749534607
0.30733394622802734 0.30733394622802734
rl training, epoch8, iter0, batch1023/1133, batch loss:0.30733394622802734, Training time:28942.619403123856
batch reward last col mean 0.08932654559612274 first col mean 0.09264705330133438 all mean 0.09646621346473694
0.26051658391952515 0.26051661372184753
rl training, epoch8, iter0, batch1024/1133, batch loss:0.26051661372184753, Training time:28944.47506737709
batch reward last col mean 0.07657673954963684 first col mean 0.09996791929006577 all mean 0.08813928067684174
0.25041958689689636 0.250419557094574
rl training, epoch8, iter0, batch1025/1133, batch loss:0.250419557094574, Training time:28946.179437875748
batch reward last col mean 0.07394050806760788 first col mean 0.08578650653362274 all mean 0.07376177608966827
0.23206447064876556 0.23206444084644318
rl training, epoch8, iter0, batch1026/1133, batch loss:0.23206444084644318, Training time:28948.49606180191
batch reward last col mean 0.07324019819498062 first col mean 0.08242446184158325 all mean 0.08111266046762466
0.24277840554714203 0.24277840554714203
rl training, epoch8, iter0, batch1027/1133, batch loss:0.24277840554714203, Training time:28950.463627576828
batch reward last col mean 0.06749323010444641 first col mean 0.10611733794212341 all mean 0.07475397735834122
0.22825077176094055 0.22825077176094055
rl training, epoch8, iter0, batch1028/1133, batch loss:0.22825077176094055, Training time:28952.736543655396
batch reward last col mean 0.11545684933662415 first col mean 0.10795937478542328 all mean 0.11114498972892761
0.2561456561088562 0.2561456561088562
rl training, epoch8, iter0, batch1029/1133, batch loss:0.2561456561088562, Training time:28955.026913881302
batch reward last col mean 0.11965347826480865 first col mean 0.09414276480674744 all mean 0.11440237611532211
0.2807203233242035 0.2807203233242035
rl training, epoch8, iter0, batch1030/1133, batch loss:0.2807203233242035, Training time:28957.93053483963
batch reward last col mean 0.09806020557880402 first col mean 0.10198415815830231 all mean 0.09608036279678345
0.25721219182014465 0.25721219182014465
rl training, epoch8, iter0, batch1031/1133, batch loss:0.25721219182014465, Training time:28960.30892252922
batch reward last col mean 0.10059355199337006 first col mean 0.10322706401348114 all mean 0.09593504667282104
0.24433965981006622 0.24433965981006622
rl training, epoch8, iter0, batch1032/1133, batch loss:0.24433965981006622, Training time:28962.441016197205
batch reward last col mean 0.09450872242450714 first col mean 0.11171287298202515 all mean 0.09640917181968689
0.23363423347473145 0.23363423347473145
rl training, epoch8, iter0, batch1033/1133, batch loss:0.23363423347473145, Training time:28964.435628652573
batch reward last col mean 0.08339531719684601 first col mean 0.09458503127098083 all mean 0.08894112706184387
0.2527104616165161 0.2527104616165161
rl training, epoch8, iter0, batch1034/1133, batch loss:0.2527104616165161, Training time:28966.6179087162
batch reward last col mean 0.13941553235054016 first col mean 0.07960186153650284 all mean 0.12920774519443512
0.2663353681564331 0.2663353681564331
rl training, epoch8, iter0, batch1035/1133, batch loss:0.2663353681564331, Training time:28968.980198144913
batch reward last col mean 0.09572678059339523 first col mean 0.08363661170005798 all mean 0.09552959352731705
0.24934716522693634 0.24934716522693634
rl training, epoch8, iter0, batch1036/1133, batch loss:0.24934716522693634, Training time:28970.83667230606
batch reward last col mean 0.1217651218175888 first col mean 0.09136395901441574 all mean 0.11268211901187897
0.24221327900886536 0.24221327900886536
rl training, epoch8, iter0, batch1037/1133, batch loss:0.24221327900886536, Training time:28972.996605157852
batch reward last col mean 0.14800982177257538 first col mean 0.12283870577812195 all mean 0.1385839730501175
0.3010549545288086 0.3010549545288086
rl training, epoch8, iter0, batch1038/1133, batch loss:0.3010549545288086, Training time:28975.560260295868
batch reward last col mean 0.10332135111093521 first col mean 0.0944334864616394 all mean 0.10769130289554596
0.28820598125457764 0.28820598125457764
rl training, epoch8, iter0, batch1039/1133, batch loss:0.28820598125457764, Training time:28977.463174819946
batch reward last col mean 0.10700404644012451 first col mean 0.10198673605918884 all mean 0.10138548910617828
0.24087145924568176 0.24087145924568176
rl training, epoch8, iter0, batch1040/1133, batch loss:0.24087145924568176, Training time:28979.975874900818
batch reward last col mean 0.09798164665699005 first col mean 0.11120910942554474 all mean 0.09948514401912689
0.25479018688201904 0.25479018688201904
rl training, epoch8, iter0, batch1041/1133, batch loss:0.25479018688201904, Training time:28982.63492321968
batch reward last col mean 0.09287521988153458 first col mean 0.09013968706130981 all mean 0.09658122062683105
0.25464171171188354 0.25464174151420593
rl training, epoch8, iter0, batch1042/1133, batch loss:0.25464174151420593, Training time:28985.078560829163
batch reward last col mean 0.08343598991632462 first col mean 0.12412652373313904 all mean 0.09065338969230652
0.26221930980682373 0.26221930980682373
rl training, epoch8, iter0, batch1043/1133, batch loss:0.26221930980682373, Training time:28986.913945674896
batch reward last col mean 0.0716853141784668 first col mean 0.09242159873247147 all mean 0.08123412728309631
0.22916162014007568 0.2291616052389145
rl training, epoch8, iter0, batch1044/1133, batch loss:0.2291616052389145, Training time:28989.012078285217
batch reward last col mean 0.06661339104175568 first col mean 0.0978216826915741 all mean 0.07978088408708572
0.25136810541152954 0.25136807560920715
rl training, epoch8, iter0, batch1045/1133, batch loss:0.25136807560920715, Training time:28991.004789352417
batch reward last col mean 0.11065451800823212 first col mean 0.0978841632604599 all mean 0.10824307799339294
0.2506151497364044 0.2506151497364044
rl training, epoch8, iter0, batch1046/1133, batch loss:0.2506151497364044, Training time:28993.5667450428
batch reward last col mean 0.11338312178850174 first col mean 0.10651517659425735 all mean 0.10931691527366638
0.2598317563533783 0.2598317563533783
rl training, epoch8, iter0, batch1047/1133, batch loss:0.2598317563533783, Training time:28996.21666431427
batch reward last col mean 0.09034474939107895 first col mean 0.10412059724330902 all mean 0.0951230525970459
0.257895290851593 0.257895290851593
rl training, epoch8, iter0, batch1048/1133, batch loss:0.257895290851593, Training time:28998.646758317947
batch reward last col mean 0.11305610835552216 first col mean 0.09814707934856415 all mean 0.107488252222538
0.25336506962776184 0.25336506962776184
rl training, epoch8, iter0, batch1049/1133, batch loss:0.25336506962776184, Training time:29000.54658794403
batch reward last col mean 0.12414085119962692 first col mean 0.09985563158988953 all mean 0.11875124275684357
0.2970331311225891 0.2970331311225891
rl training, epoch8, iter0, batch1050/1133, batch loss:0.2970331311225891, Training time:29002.54775905609
batch reward last col mean 0.10356906056404114 first col mean 0.09295453131198883 all mean 0.1055331602692604
0.27049773931503296 0.27049773931503296
rl training, epoch8, iter0, batch1051/1133, batch loss:0.27049773931503296, Training time:29004.23961353302
batch reward last col mean 0.0729508101940155 first col mean 0.09105570614337921 all mean 0.07391875982284546
0.19128961861133575 0.19128961861133575
rl training, epoch8, iter0, batch1052/1133, batch loss:0.19128961861133575, Training time:29006.190243959427
batch reward last col mean 0.1367189735174179 first col mean 0.11218613386154175 all mean 0.12021767348051071
0.2851530611515045 0.2851530611515045
rl training, epoch8, iter0, batch1053/1133, batch loss:0.2851530611515045, Training time:29007.912068367004
batch reward last col mean 0.09301657229661942 first col mean 0.10561127215623856 all mean 0.09540722519159317
0.2901173532009125 0.2901173532009125
rl training, epoch8, iter0, batch1054/1133, batch loss:0.2901173532009125, Training time:29009.894235610962
batch reward last col mean 0.10903794318437576 first col mean 0.09308601915836334 all mean 0.10954855382442474
0.2794065475463867 0.2794065475463867
rl training, epoch8, iter0, batch1055/1133, batch loss:0.2794065475463867, Training time:29011.716426372528
batch reward last col mean 0.1133015975356102 first col mean 0.0969591960310936 all mean 0.09768891334533691
0.2639155387878418 0.2639155387878418
rl training, epoch8, iter0, batch1056/1133, batch loss:0.2639155387878418, Training time:29013.387897253036
batch reward last col mean 0.101385198533535 first col mean 0.12440109252929688 all mean 0.10098740458488464
0.2640460133552551 0.26404598355293274
rl training, epoch8, iter0, batch1057/1133, batch loss:0.26404598355293274, Training time:29014.925617694855
batch reward last col mean 0.07289257645606995 first col mean 0.1152440756559372 all mean 0.07762521505355835
0.2559795379638672 0.2559795379638672
rl training, epoch8, iter0, batch1058/1133, batch loss:0.2559795379638672, Training time:29017.49736404419
batch reward last col mean 0.08354437351226807 first col mean 0.09152399003505707 all mean 0.08677968382835388
0.2414914220571518 0.2414914220571518
rl training, epoch8, iter0, batch1059/1133, batch loss:0.2414914220571518, Training time:29020.537223815918
batch reward last col mean 0.0781126320362091 first col mean 0.11650940775871277 all mean 0.09132804721593857
0.2684068977832794 0.2684068977832794
rl training, epoch8, iter0, batch1060/1133, batch loss:0.2684068977832794, Training time:29022.684960126877
batch reward last col mean 0.1288284957408905 first col mean 0.10183733701705933 all mean 0.12793202698230743
0.30053025484085083 0.30053025484085083
rl training, epoch8, iter0, batch1061/1133, batch loss:0.30053025484085083, Training time:29025.048976659775
batch reward last col mean 0.10458875447511673 first col mean 0.11931933462619781 all mean 0.11297784000635147
0.28116005659103394 0.28116005659103394
rl training, epoch8, iter0, batch1062/1133, batch loss:0.28116005659103394, Training time:29026.306763648987
batch reward last col mean 0.09730179607868195 first col mean 0.08635349571704865 all mean 0.09231563657522202
0.2535167336463928 0.2535167336463928
rl training, epoch8, iter0, batch1063/1133, batch loss:0.2535167336463928, Training time:29028.94824910164
batch reward last col mean 0.11362148076295853 first col mean 0.11303161084651947 all mean 0.10426969826221466
0.2900907099246979 0.2900907099246979
rl training, epoch8, iter0, batch1064/1133, batch loss:0.2900907099246979, Training time:29030.92400074005
batch reward last col mean 0.08909200131893158 first col mean 0.09421337395906448 all mean 0.09401381015777588
0.22654880583286285 0.22654880583286285
rl training, epoch8, iter0, batch1065/1133, batch loss:0.22654880583286285, Training time:29032.599650382996
batch reward last col mean 0.094601571559906 first col mean 0.1153530478477478 all mean 0.0924137532711029
0.2628348767757416 0.2628348767757416
rl training, epoch8, iter0, batch1066/1133, batch loss:0.2628348767757416, Training time:29034.922367811203
batch reward last col mean 0.09682326018810272 first col mean 0.10578438639640808 all mean 0.10448210686445236
0.2635152041912079 0.2635152041912079
rl training, epoch8, iter0, batch1067/1133, batch loss:0.2635152041912079, Training time:29036.674916028976
batch reward last col mean 0.08068153262138367 first col mean 0.11935364454984665 all mean 0.09183726459741592
0.2540552318096161 0.2540552318096161
rl training, epoch8, iter0, batch1068/1133, batch loss:0.2540552318096161, Training time:29038.74457502365
batch reward last col mean 0.13247700035572052 first col mean 0.11552803218364716 all mean 0.12170429527759552
0.298281192779541 0.29828116297721863
rl training, epoch8, iter0, batch1069/1133, batch loss:0.29828116297721863, Training time:29041.008890151978
batch reward last col mean 0.08121253550052643 first col mean 0.1003102958202362 all mean 0.087973952293396
0.24680447578430176 0.24680447578430176
rl training, epoch8, iter0, batch1070/1133, batch loss:0.24680447578430176, Training time:29043.02051949501
batch reward last col mean 0.1013345718383789 first col mean 0.11711873859167099 all mean 0.10189066082239151
0.24371588230133057 0.24371588230133057
rl training, epoch8, iter0, batch1071/1133, batch loss:0.24371588230133057, Training time:29044.949033260345
batch reward last col mean 0.12233705073595047 first col mean 0.116429403424263 all mean 0.1186550036072731
0.3096403479576111 0.3096403479576111
rl training, epoch8, iter0, batch1072/1133, batch loss:0.3096403479576111, Training time:29047.051831007004
batch reward last col mean 0.12443862855434418 first col mean 0.10937904566526413 all mean 0.11756279319524765
0.28493961691856384 0.28493961691856384
rl training, epoch8, iter0, batch1073/1133, batch loss:0.28493961691856384, Training time:29048.623864412308
batch reward last col mean 0.1173337996006012 first col mean 0.12733222544193268 all mean 0.11568351089954376
0.2911791205406189 0.2911791205406189
rl training, epoch8, iter0, batch1074/1133, batch loss:0.2911791205406189, Training time:29050.67632460594
batch reward last col mean 0.0979001522064209 first col mean 0.11279632896184921 all mean 0.09348750114440918
0.24086011946201324 0.24086011946201324
rl training, epoch8, iter0, batch1075/1133, batch loss:0.24086011946201324, Training time:29052.238048791885
batch reward last col mean 0.08614600449800491 first col mean 0.09428036957979202 all mean 0.09180330485105515
0.24420511722564697 0.24420508742332458
rl training, epoch8, iter0, batch1076/1133, batch loss:0.24420508742332458, Training time:29054.30946445465
batch reward last col mean 0.11645515263080597 first col mean 0.10717755556106567 all mean 0.10976073145866394
0.3151029944419861 0.3151029944419861
rl training, epoch8, iter0, batch1077/1133, batch loss:0.3151029944419861, Training time:29056.20549082756
batch reward last col mean 0.13680073618888855 first col mean 0.11516664922237396 all mean 0.13485750555992126
0.3120313882827759 0.3120313882827759
rl training, epoch8, iter0, batch1078/1133, batch loss:0.3120313882827759, Training time:29058.260751724243
batch reward last col mean 0.12241953611373901 first col mean 0.10902314633131027 all mean 0.11646249145269394
0.318556010723114 0.318556010723114
rl training, epoch8, iter0, batch1079/1133, batch loss:0.318556010723114, Training time:29059.897564649582
batch reward last col mean 0.1331697404384613 first col mean 0.11042103171348572 all mean 0.12927831709384918
0.33017900586128235 0.33017900586128235
rl training, epoch8, iter0, batch1080/1133, batch loss:0.33017900586128235, Training time:29061.259856700897
batch reward last col mean 0.10320669412612915 first col mean 0.11178290098905563 all mean 0.10389447212219238
0.27487683296203613 0.2748768627643585
rl training, epoch8, iter0, batch1081/1133, batch loss:0.2748768627643585, Training time:29063.755030870438
batch reward last col mean 0.11643856763839722 first col mean 0.10330642014741898 all mean 0.11522719264030457
0.2676783800125122 0.2676783800125122
rl training, epoch8, iter0, batch1082/1133, batch loss:0.2676783800125122, Training time:29066.048944711685
batch reward last col mean 0.07522714138031006 first col mean 0.10471992194652557 all mean 0.0857771635055542
0.29159966111183167 0.29159966111183167
rl training, epoch8, iter0, batch1083/1133, batch loss:0.29159966111183167, Training time:29067.849311351776
batch reward last col mean 0.11410978436470032 first col mean 0.11011763662099838 all mean 0.10765529423952103
0.2770901322364807 0.2770901322364807
rl training, epoch8, iter0, batch1084/1133, batch loss:0.2770901322364807, Training time:29069.442849636078
batch reward last col mean 0.07031158357858658 first col mean 0.11445637047290802 all mean 0.07745717465877533
0.2555091381072998 0.2555091679096222
rl training, epoch8, iter0, batch1085/1133, batch loss:0.2555091679096222, Training time:29071.303062200546
batch reward last col mean 0.08191199600696564 first col mean 0.09405117481946945 all mean 0.08795037865638733
0.2741641402244568 0.2741641402244568
rl training, epoch8, iter0, batch1086/1133, batch loss:0.2741641402244568, Training time:29073.86848807335
batch reward last col mean 0.13005119562149048 first col mean 0.0989704504609108 all mean 0.12395331263542175
0.27132511138916016 0.27132511138916016
rl training, epoch8, iter0, batch1087/1133, batch loss:0.27132511138916016, Training time:29075.68416404724
batch reward last col mean 0.10891541838645935 first col mean 0.0920746847987175 all mean 0.10765213519334793
0.26275891065597534 0.26275891065597534
rl training, epoch8, iter0, batch1088/1133, batch loss:0.26275891065597534, Training time:29077.071336984634
batch reward last col mean 0.11791350692510605 first col mean 0.109839528799057 all mean 0.10694891959428787
0.23787716031074524 0.23787716031074524
rl training, epoch8, iter0, batch1089/1133, batch loss:0.23787716031074524, Training time:29078.79217982292
batch reward last col mean 0.12417910993099213 first col mean 0.11283217370510101 all mean 0.11464232206344604
0.30601686239242554 0.30601686239242554
rl training, epoch8, iter0, batch1090/1133, batch loss:0.30601686239242554, Training time:29080.960782289505
batch reward last col mean 0.09854017198085785 first col mean 0.10021118819713593 all mean 0.09951645135879517
0.2735826075077057 0.2735826075077057
rl training, epoch8, iter0, batch1091/1133, batch loss:0.2735826075077057, Training time:29083.18443632126
batch reward last col mean 0.09866064786911011 first col mean 0.09711651504039764 all mean 0.10050714015960693
0.2961786985397339 0.2961786985397339
rl training, epoch8, iter0, batch1092/1133, batch loss:0.2961786985397339, Training time:29085.890028238297
batch reward last col mean 0.11396344006061554 first col mean 0.09830975532531738 all mean 0.11129244416952133
0.26014813780784607 0.26014813780784607
rl training, epoch8, iter0, batch1093/1133, batch loss:0.26014813780784607, Training time:29087.648837804794
batch reward last col mean 0.1086161732673645 first col mean 0.1152423620223999 all mean 0.10986547917127609
0.3039379119873047 0.3039379119873047
rl training, epoch8, iter0, batch1094/1133, batch loss:0.3039379119873047, Training time:29089.371619701385
batch reward last col mean 0.09724175930023193 first col mean 0.12743936479091644 all mean 0.10149981081485748
0.27537375688552856 0.27537378668785095
rl training, epoch8, iter0, batch1095/1133, batch loss:0.27537378668785095, Training time:29091.383014202118
batch reward last col mean 0.08714816719293594 first col mean 0.13079941272735596 all mean 0.09436973929405212
0.2798810601234436 0.279881089925766
rl training, epoch8, iter0, batch1096/1133, batch loss:0.279881089925766, Training time:29093.143264770508
batch reward last col mean 0.08094269037246704 first col mean 0.12150553613901138 all mean 0.08672427386045456
0.2932315766811371 0.2932315766811371
rl training, epoch8, iter0, batch1097/1133, batch loss:0.2932315766811371, Training time:29095.03649163246
batch reward last col mean 0.15127500891685486 first col mean 0.1314028799533844 all mean 0.14034514129161835
0.3006129860877991 0.3006129860877991
rl training, epoch8, iter0, batch1098/1133, batch loss:0.3006129860877991, Training time:29096.997371912003
batch reward last col mean 0.10081172734498978 first col mean 0.09478360414505005 all mean 0.09992147982120514
0.24666514992713928 0.24666514992713928
rl training, epoch8, iter0, batch1099/1133, batch loss:0.24666514992713928, Training time:29099.710151433945
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4641520381762933 Time: 98.53522682189941 s
loss of true 0.20154755727600862 loss of gen 0.1713416884733004 loss of other 0.09126279263248353 first score 0.07366347312927246
batch reward last col mean 0.11903753131628036 first col mean 0.08282814919948578 all mean 0.12117742747068405
0.3196970522403717 0.3196970522403717
rl training, epoch8, iter0, batch1100/1133, batch loss:0.3196970522403717, Training time:29199.57605290413
batch reward last col mean 0.10059614479541779 first col mean 0.10562020540237427 all mean 0.10211747139692307
0.26860323548316956 0.26860323548316956
rl training, epoch8, iter0, batch1101/1133, batch loss:0.26860323548316956, Training time:29201.19735145569
batch reward last col mean 0.08333876729011536 first col mean 0.11848098039627075 all mean 0.09527952969074249
0.28438809514045715 0.28438809514045715
rl training, epoch8, iter0, batch1102/1133, batch loss:0.28438809514045715, Training time:29203.084506750107
batch reward last col mean 0.13122329115867615 first col mean 0.09762655198574066 all mean 0.12772855162620544
0.32414886355400085 0.32414886355400085
rl training, epoch8, iter0, batch1103/1133, batch loss:0.32414886355400085, Training time:29205.164421081543
batch reward last col mean 0.08376343548297882 first col mean 0.0965142622590065 all mean 0.08985340595245361
0.2778748571872711 0.2778748571872711
rl training, epoch8, iter0, batch1104/1133, batch loss:0.2778748571872711, Training time:29207.233401298523
batch reward last col mean 0.09877242147922516 first col mean 0.10263980180025101 all mean 0.09885800629854202
0.24967645108699799 0.24967645108699799
rl training, epoch8, iter0, batch1105/1133, batch loss:0.24967645108699799, Training time:29208.961580991745
batch reward last col mean 0.05760274827480316 first col mean 0.0815594270825386 all mean 0.06823759526014328
0.2505287528038025 0.2505287528038025
rl training, epoch8, iter0, batch1106/1133, batch loss:0.2505287528038025, Training time:29210.89274454117
batch reward last col mean 0.10905133932828903 first col mean 0.1212770864367485 all mean 0.10655283182859421
0.2751174867153168 0.2751174867153168
rl training, epoch8, iter0, batch1107/1133, batch loss:0.2751174867153168, Training time:29212.81907939911
batch reward last col mean 0.10062053054571152 first col mean 0.11816192418336868 all mean 0.10320975631475449
0.2734931707382202 0.2734931707382202
rl training, epoch8, iter0, batch1108/1133, batch loss:0.2734931707382202, Training time:29214.84809088707
batch reward last col mean 0.07329415529966354 first col mean 0.10812488943338394 all mean 0.08457579463720322
0.2531185746192932 0.2531185746192932
rl training, epoch8, iter0, batch1109/1133, batch loss:0.2531185746192932, Training time:29216.912323713303
batch reward last col mean 0.10016598552465439 first col mean 0.09370754659175873 all mean 0.09700538218021393
0.2723868787288666 0.2723868787288666
rl training, epoch8, iter0, batch1110/1133, batch loss:0.2723868787288666, Training time:29218.68417096138
batch reward last col mean 0.10474357008934021 first col mean 0.10093189775943756 all mean 0.10014387965202332
0.24750205874443054 0.24750205874443054
rl training, epoch8, iter0, batch1111/1133, batch loss:0.24750205874443054, Training time:29220.480628490448
batch reward last col mean 0.10246342420578003 first col mean 0.10592299699783325 all mean 0.1028837040066719
0.31814873218536377 0.31814873218536377
rl training, epoch8, iter0, batch1112/1133, batch loss:0.31814873218536377, Training time:29222.572630405426
batch reward last col mean 0.07817251980304718 first col mean 0.09276002645492554 all mean 0.08087728172540665
0.25817930698394775 0.25817930698394775
rl training, epoch8, iter0, batch1113/1133, batch loss:0.25817930698394775, Training time:29224.529584646225
batch reward last col mean 0.08487161248922348 first col mean 0.09753020107746124 all mean 0.08432628214359283
0.24617892503738403 0.24617889523506165
rl training, epoch8, iter0, batch1114/1133, batch loss:0.24617889523506165, Training time:29226.78256034851
batch reward last col mean 0.10924030095338821 first col mean 0.10771284997463226 all mean 0.1056852862238884
0.2860543131828308 0.2860543131828308
rl training, epoch8, iter0, batch1115/1133, batch loss:0.2860543131828308, Training time:29229.215351581573
batch reward last col mean 0.14302858710289001 first col mean 0.10902329534292221 all mean 0.13136325776576996
0.34160929918289185 0.34160929918289185
rl training, epoch8, iter0, batch1116/1133, batch loss:0.34160929918289185, Training time:29232.957934617996
batch reward last col mean 0.07270025461912155 first col mean 0.10666174441576004 all mean 0.08628679066896439
0.27093711495399475 0.27093711495399475
rl training, epoch8, iter0, batch1117/1133, batch loss:0.27093711495399475, Training time:29234.89035820961
batch reward last col mean 0.07787950336933136 first col mean 0.09409109503030777 all mean 0.08333329856395721
0.22068442404270172 0.22068442404270172
rl training, epoch8, iter0, batch1118/1133, batch loss:0.22068442404270172, Training time:29236.862807750702
batch reward last col mean 0.08148081600666046 first col mean 0.10420973598957062 all mean 0.08934251219034195
0.2541166841983795 0.2541166841983795
rl training, epoch8, iter0, batch1119/1133, batch loss:0.2541166841983795, Training time:29238.719454050064
batch reward last col mean 0.10246825218200684 first col mean 0.10467071086168289 all mean 0.10521364212036133
0.27298280596733093 0.27298280596733093
rl training, epoch8, iter0, batch1120/1133, batch loss:0.27298280596733093, Training time:29242.066901683807
batch reward last col mean 0.10788406431674957 first col mean 0.10961412638425827 all mean 0.10580860823392868
0.26266908645629883 0.26266908645629883
rl training, epoch8, iter0, batch1121/1133, batch loss:0.26266908645629883, Training time:29244.074568510056
batch reward last col mean 0.10249573737382889 first col mean 0.09903523325920105 all mean 0.10391819477081299
0.25715768337249756 0.25715768337249756
rl training, epoch8, iter0, batch1122/1133, batch loss:0.25715768337249756, Training time:29245.91621041298
batch reward last col mean 0.09427416324615479 first col mean 0.09528446197509766 all mean 0.09583932161331177
0.26990368962287903 0.26990368962287903
rl training, epoch8, iter0, batch1123/1133, batch loss:0.26990368962287903, Training time:29249.267622947693
batch reward last col mean 0.09521688520908356 first col mean 0.10663525015115738 all mean 0.09563600271940231
0.2669912278652191 0.2669912278652191
rl training, epoch8, iter0, batch1124/1133, batch loss:0.2669912278652191, Training time:29251.484847545624
batch reward last col mean 0.06579598039388657 first col mean 0.10530588775873184 all mean 0.0753973051905632
0.22654590010643005 0.22654590010643005
rl training, epoch8, iter0, batch1125/1133, batch loss:0.22654590010643005, Training time:29253.09216284752
batch reward last col mean 0.12220724672079086 first col mean 0.11181987822055817 all mean 0.1150224432349205
0.2783786356449127 0.2783786356449127
rl training, epoch8, iter0, batch1126/1133, batch loss:0.2783786356449127, Training time:29255.011334180832
batch reward last col mean 0.09511695802211761 first col mean 0.11089523881673813 all mean 0.09508918970823288
0.26147031784057617 0.26147031784057617
rl training, epoch8, iter0, batch1127/1133, batch loss:0.26147031784057617, Training time:29256.946094751358
batch reward last col mean 0.10148303210735321 first col mean 0.10674485564231873 all mean 0.09950766712427139
0.28260597586631775 0.28260597586631775
rl training, epoch8, iter0, batch1128/1133, batch loss:0.28260597586631775, Training time:29258.878143310547
batch reward last col mean 0.08914601802825928 first col mean 0.09514349699020386 all mean 0.0971776470541954
0.2661610245704651 0.2661610245704651
rl training, epoch8, iter0, batch1129/1133, batch loss:0.2661610245704651, Training time:29260.921788930893
batch reward last col mean 0.08693777769804001 first col mean 0.10495869815349579 all mean 0.09229517728090286
0.25254344940185547 0.25254344940185547
rl training, epoch8, iter0, batch1130/1133, batch loss:0.25254344940185547, Training time:29262.89402103424
batch reward last col mean 0.10249745845794678 first col mean 0.09715616703033447 all mean 0.0986105352640152
0.25641173124313354 0.25641176104545593
rl training, epoch8, iter0, batch1131/1133, batch loss:0.25641176104545593, Training time:29264.752408742905
batch reward last col mean 0.07863102853298187 first col mean 0.1037338376045227 all mean 0.08531135320663452
0.24143774807453156 0.24143774807453156
rl training, epoch8, iter0, batch1132/1133, batch loss:0.24143774807453156, Training time:29266.218751192093
rl training, epoch 8, iter 0, loss:0.27192038412075176, Training time:29266.21897339821 
rl epoch 8, begin RL for generator...
begin to train g model alone...
cur_epoch: 0
G Training Loss: 2.9535363181333887 Time: 118.56808304786682 s
rl epoch 8, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4377491879100202 Time: 100.41650557518005 s
loss of true 0.1859275662822736 loss of gen 0.16038276107171312 loss of other 0.09143886105580763 first score 0.08489210903644562
rl epoch 9, begin RL for generator...
batch reward last col mean 0.06976030021905899 first col mean 0.09359002858400345 all mean 0.07860293239355087
0.2610446810722351 0.2610446810722351
rl training, epoch9, iter0, batch0/1133, batch loss:0.2610446810722351, Training time:29487.07971930504
batch reward last col mean 0.0860479474067688 first col mean 0.08687178045511246 all mean 0.08687523752450943
0.24730852246284485 0.24730852246284485
rl training, epoch9, iter0, batch1/1133, batch loss:0.24730852246284485, Training time:29490.351933002472
batch reward last col mean 0.0830281525850296 first col mean 0.09456615149974823 all mean 0.08444257825613022
0.2348565310239792 0.2348565310239792
rl training, epoch9, iter0, batch2/1133, batch loss:0.2348565310239792, Training time:29493.983635902405
batch reward last col mean 0.08812016248703003 first col mean 0.10797905176877975 all mean 0.08832583576440811
0.23237206041812897 0.23237206041812897
rl training, epoch9, iter0, batch3/1133, batch loss:0.23237206041812897, Training time:29496.592483758926
batch reward last col mean 0.0764404758810997 first col mean 0.09739772975444794 all mean 0.07833405584096909
0.24304525554180145 0.24304525554180145
rl training, epoch9, iter0, batch4/1133, batch loss:0.24304525554180145, Training time:29499.070491313934
batch reward last col mean 0.05322565138339996 first col mean 0.09575772285461426 all mean 0.061642568558454514
0.2475305199623108 0.2475305199623108
rl training, epoch9, iter0, batch5/1133, batch loss:0.2475305199623108, Training time:29501.683290719986
batch reward last col mean 0.08175249397754669 first col mean 0.10777588188648224 all mean 0.08447394520044327
0.2332228720188141 0.2332228720188141
rl training, epoch9, iter0, batch6/1133, batch loss:0.2332228720188141, Training time:29503.779810667038
batch reward last col mean 0.11325542628765106 first col mean 0.09343819320201874 all mean 0.11222466081380844
0.3143364489078522 0.3143364489078522
rl training, epoch9, iter0, batch7/1133, batch loss:0.3143364489078522, Training time:29506.008194208145
batch reward last col mean 0.09171438962221146 first col mean 0.07633861899375916 all mean 0.0926888957619667
0.2845105528831482 0.2845105230808258
rl training, epoch9, iter0, batch8/1133, batch loss:0.2845105230808258, Training time:29508.551474809647
batch reward last col mean 0.0616920106112957 first col mean 0.08840397745370865 all mean 0.06816399842500687
0.25011467933654785 0.25011467933654785
rl training, epoch9, iter0, batch9/1133, batch loss:0.25011467933654785, Training time:29510.52093076706
batch reward last col mean 0.11289336532354355 first col mean 0.09386099129915237 all mean 0.10409674793481827
0.22236913442611694 0.22236913442611694
rl training, epoch9, iter0, batch10/1133, batch loss:0.22236913442611694, Training time:29512.862229824066
batch reward last col mean 0.05668546259403229 first col mean 0.09970933198928833 all mean 0.06312507390975952
0.2281678169965744 0.2281678169965744
rl training, epoch9, iter0, batch11/1133, batch loss:0.2281678169965744, Training time:29516.52205181122
batch reward last col mean 0.09732235223054886 first col mean 0.08376805484294891 all mean 0.09524379670619965
0.24868997931480408 0.24868997931480408
rl training, epoch9, iter0, batch12/1133, batch loss:0.24868997931480408, Training time:29519.53967499733
batch reward last col mean 0.07660271972417831 first col mean 0.08636148273944855 all mean 0.08269795775413513
0.23761634528636932 0.23761634528636932
rl training, epoch9, iter0, batch13/1133, batch loss:0.23761634528636932, Training time:29521.494017601013
batch reward last col mean 0.06806115061044693 first col mean 0.08241812884807587 all mean 0.07724778354167938
0.22429592907428741 0.22429592907428741
rl training, epoch9, iter0, batch14/1133, batch loss:0.22429592907428741, Training time:29523.747352600098
batch reward last col mean 0.08063119649887085 first col mean 0.10034201294183731 all mean 0.08232709020376205
0.2880517244338989 0.2880517244338989
rl training, epoch9, iter0, batch15/1133, batch loss:0.2880517244338989, Training time:29526.941225528717
batch reward last col mean 0.08862776309251785 first col mean 0.09951061755418777 all mean 0.09168421477079391
0.3131422996520996 0.3131422996520996
rl training, epoch9, iter0, batch16/1133, batch loss:0.3131422996520996, Training time:29530.235891103745
batch reward last col mean 0.07915658503770828 first col mean 0.08247088640928268 all mean 0.08093075454235077
0.2125764787197113 0.2125764787197113
rl training, epoch9, iter0, batch17/1133, batch loss:0.2125764787197113, Training time:29533.167110443115
batch reward last col mean 0.09368648380041122 first col mean 0.09308861196041107 all mean 0.09189091622829437
0.23739013075828552 0.23739013075828552
rl training, epoch9, iter0, batch18/1133, batch loss:0.23739013075828552, Training time:29534.791385173798
batch reward last col mean 0.08833996951580048 first col mean 0.09107464551925659 all mean 0.08920745551586151
0.26327237486839294 0.26327237486839294
rl training, epoch9, iter0, batch19/1133, batch loss:0.26327237486839294, Training time:29536.875629901886
batch reward last col mean 0.09811785072088242 first col mean 0.08906492590904236 all mean 0.09750475734472275
0.29688602685928345 0.29688602685928345
rl training, epoch9, iter0, batch20/1133, batch loss:0.29688602685928345, Training time:29538.928205251694
batch reward last col mean 0.07069820910692215 first col mean 0.08538948744535446 all mean 0.07688980549573898
0.2387135922908783 0.2387135922908783
rl training, epoch9, iter0, batch21/1133, batch loss:0.2387135922908783, Training time:29541.110904455185
batch reward last col mean 0.08343197405338287 first col mean 0.09379570186138153 all mean 0.08752382546663284
0.21866168081760406 0.21866168081760406
rl training, epoch9, iter0, batch22/1133, batch loss:0.21866168081760406, Training time:29543.481838941574
batch reward last col mean 0.08574046194553375 first col mean 0.09418277442455292 all mean 0.09219714999198914
0.28035926818847656 0.28035926818847656
rl training, epoch9, iter0, batch23/1133, batch loss:0.28035926818847656, Training time:29546.00411272049
batch reward last col mean 0.10855989158153534 first col mean 0.0788252130150795 all mean 0.10516256839036942
0.2882503569126129 0.2882503271102905
rl training, epoch9, iter0, batch24/1133, batch loss:0.2882503271102905, Training time:29548.42033982277
batch reward last col mean 0.07402858883142471 first col mean 0.08591318130493164 all mean 0.07865093648433685
0.281624436378479 0.281624436378479
rl training, epoch9, iter0, batch25/1133, batch loss:0.281624436378479, Training time:29551.001558065414
batch reward last col mean 0.09135985374450684 first col mean 0.08594776690006256 all mean 0.09259963035583496
0.2638535499572754 0.2638535499572754
rl training, epoch9, iter0, batch26/1133, batch loss:0.2638535499572754, Training time:29553.134437322617
batch reward last col mean 0.08391672372817993 first col mean 0.08572623878717422 all mean 0.08488409966230392
0.24782343208789825 0.24782343208789825
rl training, epoch9, iter0, batch27/1133, batch loss:0.24782343208789825, Training time:29555.517287254333
batch reward last col mean 0.11428758502006531 first col mean 0.08227649331092834 all mean 0.10544495284557343
0.2659721374511719 0.2659721374511719
rl training, epoch9, iter0, batch28/1133, batch loss:0.2659721374511719, Training time:29558.14495062828
batch reward last col mean 0.08735723048448563 first col mean 0.08268988877534866 all mean 0.0851677879691124
0.22844554483890533 0.22844554483890533
rl training, epoch9, iter0, batch29/1133, batch loss:0.22844554483890533, Training time:29560.53618144989
batch reward last col mean 0.0994720607995987 first col mean 0.10097602009773254 all mean 0.10133606195449829
0.2516261041164398 0.2516261041164398
rl training, epoch9, iter0, batch30/1133, batch loss:0.2516261041164398, Training time:29563.06188392639
batch reward last col mean 0.10373688489198685 first col mean 0.08554331213235855 all mean 0.10359595715999603
0.23993505537509918 0.23993505537509918
rl training, epoch9, iter0, batch31/1133, batch loss:0.23993505537509918, Training time:29565.588764429092
batch reward last col mean 0.11767701059579849 first col mean 0.08904843777418137 all mean 0.10876587778329849
0.27032238245010376 0.27032238245010376
rl training, epoch9, iter0, batch32/1133, batch loss:0.27032238245010376, Training time:29567.915427446365
batch reward last col mean 0.0939379632472992 first col mean 0.10013584792613983 all mean 0.09195277839899063
0.2807079255580902 0.2807079553604126
rl training, epoch9, iter0, batch33/1133, batch loss:0.2807079553604126, Training time:29570.596663475037
batch reward last col mean 0.07298579812049866 first col mean 0.09285877645015717 all mean 0.07811140269041061
0.23527032136917114 0.23527032136917114
rl training, epoch9, iter0, batch34/1133, batch loss:0.23527032136917114, Training time:29573.38475728035
batch reward last col mean 0.07933630049228668 first col mean 0.07223529368638992 all mean 0.07790759205818176
0.23166069388389587 0.23166069388389587
rl training, epoch9, iter0, batch35/1133, batch loss:0.23166069388389587, Training time:29575.670649766922
batch reward last col mean 0.10907821357250214 first col mean 0.09658093750476837 all mean 0.10093672573566437
0.2225416600704193 0.2225416749715805
rl training, epoch9, iter0, batch36/1133, batch loss:0.2225416749715805, Training time:29578.25060749054
batch reward last col mean 0.06890612095594406 first col mean 0.10212645679712296 all mean 0.07848963141441345
0.2368849366903305 0.2368849366903305
rl training, epoch9, iter0, batch37/1133, batch loss:0.2368849366903305, Training time:29580.67461490631
batch reward last col mean 0.08401336520910263 first col mean 0.09566987305879593 all mean 0.08499301970005035
0.2576946020126343 0.2576946020126343
rl training, epoch9, iter0, batch38/1133, batch loss:0.2576946020126343, Training time:29583.068158388138
batch reward last col mean 0.10322722792625427 first col mean 0.09963904321193695 all mean 0.10314306616783142
0.23919819295406342 0.23919819295406342
rl training, epoch9, iter0, batch39/1133, batch loss:0.23919819295406342, Training time:29585.635774850845
batch reward last col mean 0.07664906978607178 first col mean 0.09961362183094025 all mean 0.08231426775455475
0.22973525524139404 0.22973525524139404
rl training, epoch9, iter0, batch40/1133, batch loss:0.22973525524139404, Training time:29588.13875555992
batch reward last col mean 0.12358980625867844 first col mean 0.10147606581449509 all mean 0.11569511145353317
0.24527792632579803 0.24527792632579803
rl training, epoch9, iter0, batch41/1133, batch loss:0.24527792632579803, Training time:29590.417573451996
batch reward last col mean 0.09648214280605316 first col mean 0.10391145199537277 all mean 0.09577030688524246
0.23327070474624634 0.23327068984508514
rl training, epoch9, iter0, batch42/1133, batch loss:0.23327068984508514, Training time:29592.52951979637
batch reward last col mean 0.11577274650335312 first col mean 0.11186891049146652 all mean 0.10844268649816513
0.29624152183532715 0.29624149203300476
rl training, epoch9, iter0, batch43/1133, batch loss:0.29624149203300476, Training time:29594.501461029053
batch reward last col mean 0.07389034330844879 first col mean 0.08718295395374298 all mean 0.07629676163196564
0.22461502254009247 0.22461502254009247
rl training, epoch9, iter0, batch44/1133, batch loss:0.22461502254009247, Training time:29597.072545289993
batch reward last col mean 0.05929798632860184 first col mean 0.08932717144489288 all mean 0.06750404089689255
0.2227371782064438 0.2227371782064438
rl training, epoch9, iter0, batch45/1133, batch loss:0.2227371782064438, Training time:29599.746424674988
batch reward last col mean 0.10421251505613327 first col mean 0.08684947341680527 all mean 0.10984387993812561
0.27706897258758545 0.27706897258758545
rl training, epoch9, iter0, batch46/1133, batch loss:0.27706897258758545, Training time:29601.480273246765
batch reward last col mean 0.11173814535140991 first col mean 0.08994186669588089 all mean 0.10319534689188004
0.2773054838180542 0.2773054838180542
rl training, epoch9, iter0, batch47/1133, batch loss:0.2773054838180542, Training time:29603.71207165718
batch reward last col mean 0.08926122635602951 first col mean 0.09197570383548737 all mean 0.08742145448923111
0.24060319364070892 0.24060319364070892
rl training, epoch9, iter0, batch48/1133, batch loss:0.24060319364070892, Training time:29605.644456386566
batch reward last col mean 0.08625524491071701 first col mean 0.08560361713171005 all mean 0.08740963041782379
0.22807025909423828 0.22807027399539948
rl training, epoch9, iter0, batch49/1133, batch loss:0.22807027399539948, Training time:29607.815138816833
batch reward last col mean 0.0908287987112999 first col mean 0.09605129063129425 all mean 0.09075137972831726
0.23845256865024567 0.23845256865024567
rl training, epoch9, iter0, batch50/1133, batch loss:0.23845256865024567, Training time:29609.48171401024
batch reward last col mean 0.08846592903137207 first col mean 0.09771635383367538 all mean 0.09036941826343536
0.25932347774505615 0.25932347774505615
rl training, epoch9, iter0, batch51/1133, batch loss:0.25932347774505615, Training time:29611.633868932724
batch reward last col mean 0.07396329939365387 first col mean 0.08226804435253143 all mean 0.07694954425096512
0.24788381159305573 0.24788381159305573
rl training, epoch9, iter0, batch52/1133, batch loss:0.24788381159305573, Training time:29613.699486732483
batch reward last col mean 0.1386680006980896 first col mean 0.09189502149820328 all mean 0.12926551699638367
0.26915478706359863 0.26915478706359863
rl training, epoch9, iter0, batch53/1133, batch loss:0.26915478706359863, Training time:29616.301374197006
batch reward last col mean 0.08532773703336716 first col mean 0.08261995017528534 all mean 0.08630234003067017
0.23130767047405243 0.23130767047405243
rl training, epoch9, iter0, batch54/1133, batch loss:0.23130767047405243, Training time:29619.415833711624
batch reward last col mean 0.0985439270734787 first col mean 0.10108692198991776 all mean 0.09888609498739243
0.3025759160518646 0.3025759160518646
rl training, epoch9, iter0, batch55/1133, batch loss:0.3025759160518646, Training time:29622.187940597534
batch reward last col mean 0.11321274936199188 first col mean 0.09025971591472626 all mean 0.10190288722515106
0.2623046040534973 0.2623046040534973
rl training, epoch9, iter0, batch56/1133, batch loss:0.2623046040534973, Training time:29624.254326581955
batch reward last col mean 0.09816502034664154 first col mean 0.10738180577754974 all mean 0.09782486408948898
0.28331515192985535 0.28331515192985535
rl training, epoch9, iter0, batch57/1133, batch loss:0.28331515192985535, Training time:29626.79133105278
batch reward last col mean 0.11668697744607925 first col mean 0.0919484943151474 all mean 0.11527197062969208
0.2890593409538269 0.2890593409538269
rl training, epoch9, iter0, batch58/1133, batch loss:0.2890593409538269, Training time:29629.0064971447
batch reward last col mean 0.10791215300559998 first col mean 0.10836277902126312 all mean 0.10644432157278061
0.27753737568855286 0.27753737568855286
rl training, epoch9, iter0, batch59/1133, batch loss:0.27753737568855286, Training time:29630.87334370613
batch reward last col mean 0.10801822692155838 first col mean 0.09670878946781158 all mean 0.09476731717586517
0.2736785113811493 0.2736785113811493
rl training, epoch9, iter0, batch60/1133, batch loss:0.2736785113811493, Training time:29632.49774670601
batch reward last col mean 0.06122078001499176 first col mean 0.08328995108604431 all mean 0.07584499567747116
0.233150914311409 0.233150914311409
rl training, epoch9, iter0, batch61/1133, batch loss:0.233150914311409, Training time:29634.73592376709
batch reward last col mean 0.09762276709079742 first col mean 0.09792066365480423 all mean 0.09572536498308182
0.2373688817024231 0.2373688817024231
rl training, epoch9, iter0, batch62/1133, batch loss:0.2373688817024231, Training time:29636.460984945297
batch reward last col mean 0.0665588229894638 first col mean 0.09839534759521484 all mean 0.07868693768978119
0.24819906055927277 0.24819906055927277
rl training, epoch9, iter0, batch63/1133, batch loss:0.24819906055927277, Training time:29638.36881351471
batch reward last col mean 0.12820176780223846 first col mean 0.10754339396953583 all mean 0.11973470449447632
0.30275216698646545 0.30275216698646545
rl training, epoch9, iter0, batch64/1133, batch loss:0.30275216698646545, Training time:29640.311241149902
batch reward last col mean 0.0927644893527031 first col mean 0.08263358473777771 all mean 0.09406094998121262
0.24806785583496094 0.24806785583496094
rl training, epoch9, iter0, batch65/1133, batch loss:0.24806785583496094, Training time:29642.21420288086
batch reward last col mean 0.08038008958101273 first col mean 0.09153586626052856 all mean 0.08260143548250198
0.24899472296237946 0.24899472296237946
rl training, epoch9, iter0, batch66/1133, batch loss:0.24899472296237946, Training time:29645.180366039276
batch reward last col mean 0.050941500812768936 first col mean 0.10293450951576233 all mean 0.06324698776006699
0.24529635906219482 0.24529635906219482
rl training, epoch9, iter0, batch67/1133, batch loss:0.24529635906219482, Training time:29647.832279920578
batch reward last col mean 0.10355046391487122 first col mean 0.09988605231046677 all mean 0.10506603866815567
0.26790523529052734 0.26790523529052734
rl training, epoch9, iter0, batch68/1133, batch loss:0.26790523529052734, Training time:29649.68059706688
batch reward last col mean 0.1066506952047348 first col mean 0.1181882917881012 all mean 0.10226353257894516
0.2652297914028168 0.2652297914028168
rl training, epoch9, iter0, batch69/1133, batch loss:0.2652297914028168, Training time:29651.80714225769
batch reward last col mean 0.07729485630989075 first col mean 0.10459115356206894 all mean 0.0806017518043518
0.2544255554676056 0.2544255554676056
rl training, epoch9, iter0, batch70/1133, batch loss:0.2544255554676056, Training time:29653.89744925499
batch reward last col mean 0.06863768398761749 first col mean 0.10805115103721619 all mean 0.07449924200773239
0.2030159831047058 0.2030159831047058
rl training, epoch9, iter0, batch71/1133, batch loss:0.2030159831047058, Training time:29655.909759283066
batch reward last col mean 0.07594577968120575 first col mean 0.08869994431734085 all mean 0.08360715955495834
0.23412840068340302 0.23412840068340302
rl training, epoch9, iter0, batch72/1133, batch loss:0.23412840068340302, Training time:29658.233385324478
batch reward last col mean 0.07716161012649536 first col mean 0.087447889149189 all mean 0.08128984272480011
0.22485563158988953 0.22485563158988953
rl training, epoch9, iter0, batch73/1133, batch loss:0.22485563158988953, Training time:29659.988350629807
batch reward last col mean 0.10628216713666916 first col mean 0.0961083173751831 all mean 0.10421062260866165
0.24783378839492798 0.24783378839492798
rl training, epoch9, iter0, batch74/1133, batch loss:0.24783378839492798, Training time:29662.1369702816
batch reward last col mean 0.07640975713729858 first col mean 0.08932623267173767 all mean 0.0850900188088417
0.23398418724536896 0.23398420214653015
rl training, epoch9, iter0, batch75/1133, batch loss:0.23398420214653015, Training time:29664.48471069336
batch reward last col mean 0.06448633968830109 first col mean 0.09233944118022919 all mean 0.07596426457166672
0.26902690529823303 0.26902690529823303
rl training, epoch9, iter0, batch76/1133, batch loss:0.26902690529823303, Training time:29666.7184984684
batch reward last col mean 0.10705359280109406 first col mean 0.0870414525270462 all mean 0.10129435360431671
0.262602835893631 0.262602835893631
rl training, epoch9, iter0, batch77/1133, batch loss:0.262602835893631, Training time:29668.604833364487
batch reward last col mean 0.0703195333480835 first col mean 0.09927070885896683 all mean 0.07895985245704651
0.2540854811668396 0.2540854811668396
rl training, epoch9, iter0, batch78/1133, batch loss:0.2540854811668396, Training time:29670.440673828125
batch reward last col mean 0.09232732653617859 first col mean 0.09350724518299103 all mean 0.0935378447175026
0.24168343842029572 0.24168343842029572
rl training, epoch9, iter0, batch79/1133, batch loss:0.24168343842029572, Training time:29672.58607506752
batch reward last col mean 0.07031774520874023 first col mean 0.0978848934173584 all mean 0.07929220795631409
0.26536935567855835 0.26536935567855835
rl training, epoch9, iter0, batch80/1133, batch loss:0.26536935567855835, Training time:29674.75170469284
batch reward last col mean 0.08116212487220764 first col mean 0.09460142999887466 all mean 0.08658396452665329
0.263969749212265 0.2639697194099426
rl training, epoch9, iter0, batch81/1133, batch loss:0.2639697194099426, Training time:29676.93816971779
batch reward last col mean 0.10134465992450714 first col mean 0.10003457963466644 all mean 0.096091628074646
0.2473263144493103 0.2473263144493103
rl training, epoch9, iter0, batch82/1133, batch loss:0.2473263144493103, Training time:29678.773034095764
batch reward last col mean 0.12408016622066498 first col mean 0.0939030572772026 all mean 0.11890079826116562
0.27903804183006287 0.27903804183006287
rl training, epoch9, iter0, batch83/1133, batch loss:0.27903804183006287, Training time:29680.95108985901
batch reward last col mean 0.09446975588798523 first col mean 0.09518715739250183 all mean 0.09651408344507217
0.24513055384159088 0.24513055384159088
rl training, epoch9, iter0, batch84/1133, batch loss:0.24513055384159088, Training time:29683.050560951233
batch reward last col mean 0.09519036114215851 first col mean 0.09171745926141739 all mean 0.09223255515098572
0.23405951261520386 0.23405951261520386
rl training, epoch9, iter0, batch85/1133, batch loss:0.23405951261520386, Training time:29685.787341594696
batch reward last col mean 0.11741821467876434 first col mean 0.09706934541463852 all mean 0.10853970795869827
0.2556268870830536 0.2556268870830536
rl training, epoch9, iter0, batch86/1133, batch loss:0.2556268870830536, Training time:29687.656137943268
batch reward last col mean 0.09651215374469757 first col mean 0.08414484560489655 all mean 0.09789995104074478
0.23900637030601501 0.23900637030601501
rl training, epoch9, iter0, batch87/1133, batch loss:0.23900637030601501, Training time:29689.420746326447
batch reward last col mean 0.07493327558040619 first col mean 0.09744496643543243 all mean 0.08103803545236588
0.2597635090351105 0.2597635090351105
rl training, epoch9, iter0, batch88/1133, batch loss:0.2597635090351105, Training time:29691.160152196884
batch reward last col mean 0.09038913249969482 first col mean 0.09932882338762283 all mean 0.09264793246984482
0.2668534815311432 0.2668534815311432
rl training, epoch9, iter0, batch89/1133, batch loss:0.2668534815311432, Training time:29692.86513400078
batch reward last col mean 0.08438114821910858 first col mean 0.10258428007364273 all mean 0.09129108488559723
0.24397332966327667 0.24397332966327667
rl training, epoch9, iter0, batch90/1133, batch loss:0.24397332966327667, Training time:29694.96676325798
batch reward last col mean 0.057194784283638 first col mean 0.0760151818394661 all mean 0.060816291719675064
0.19966313242912292 0.19966310262680054
rl training, epoch9, iter0, batch91/1133, batch loss:0.19966310262680054, Training time:29696.84235405922
batch reward last col mean 0.08107102662324905 first col mean 0.10446267575025558 all mean 0.08664315938949585
0.23166292905807495 0.23166292905807495
rl training, epoch9, iter0, batch92/1133, batch loss:0.23166292905807495, Training time:29698.733483552933
batch reward last col mean 0.09672385454177856 first col mean 0.10274101048707962 all mean 0.09724429249763489
0.2693840265274048 0.2693840265274048
rl training, epoch9, iter0, batch93/1133, batch loss:0.2693840265274048, Training time:29701.072870016098
batch reward last col mean 0.102986179292202 first col mean 0.09510847181081772 all mean 0.09762097895145416
0.22932147979736328 0.22932147979736328
rl training, epoch9, iter0, batch94/1133, batch loss:0.22932147979736328, Training time:29702.88789653778
batch reward last col mean 0.053112972527742386 first col mean 0.09779499471187592 all mean 0.06314898282289505
0.2036016434431076 0.2036016434431076
rl training, epoch9, iter0, batch95/1133, batch loss:0.2036016434431076, Training time:29704.72652578354
batch reward last col mean 0.1309930384159088 first col mean 0.10868143290281296 all mean 0.12206374108791351
0.26910150051116943 0.26910150051116943
rl training, epoch9, iter0, batch96/1133, batch loss:0.26910150051116943, Training time:29706.71713399887
batch reward last col mean 0.1255500763654709 first col mean 0.08976081013679504 all mean 0.1241418644785881
0.2645218074321747 0.2645218074321747
rl training, epoch9, iter0, batch97/1133, batch loss:0.2645218074321747, Training time:29709.075111865997
batch reward last col mean 0.1354352831840515 first col mean 0.11513949185609818 all mean 0.1237558051943779
0.32437562942504883 0.32437562942504883
rl training, epoch9, iter0, batch98/1133, batch loss:0.32437562942504883, Training time:29710.96359562874
batch reward last col mean 0.10653367638587952 first col mean 0.0936216413974762 all mean 0.1025991439819336
0.2568614184856415 0.2568614184856415
rl training, epoch9, iter0, batch99/1133, batch loss:0.2568614184856415, Training time:29713.509782791138
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.43752691202319416 Time: 97.48450922966003 s
loss of true 0.1863563104819536 loss of gen 0.15918307655407912 loss of other 0.09198752423914418 first score 0.1057620644569397
batch reward last col mean 0.08235476911067963 first col mean 0.09175334125757217 all mean 0.08518583327531815
0.23898756504058838 0.23898756504058838
rl training, epoch9, iter0, batch100/1133, batch loss:0.23898756504058838, Training time:29813.28201341629
batch reward last col mean 0.11458796262741089 first col mean 0.0869445949792862 all mean 0.11127172410488129
0.25702810287475586 0.2570280432701111
rl training, epoch9, iter0, batch101/1133, batch loss:0.2570280432701111, Training time:29815.873050928116
batch reward last col mean 0.07413012534379959 first col mean 0.09561483561992645 all mean 0.07953042536973953
0.26413553953170776 0.26413553953170776
rl training, epoch9, iter0, batch102/1133, batch loss:0.26413553953170776, Training time:29818.147257328033
batch reward last col mean 0.07816483080387115 first col mean 0.10385221987962723 all mean 0.07766066491603851
0.22247785329818726 0.22247783839702606
rl training, epoch9, iter0, batch103/1133, batch loss:0.22247783839702606, Training time:29820.00426387787
batch reward last col mean 0.09157909452915192 first col mean 0.08117549121379852 all mean 0.09788188338279724
0.2768513858318329 0.2768513858318329
rl training, epoch9, iter0, batch104/1133, batch loss:0.2768513858318329, Training time:29822.168768644333
batch reward last col mean 0.0970606729388237 first col mean 0.10063475370407104 all mean 0.0993308499455452
0.2308545559644699 0.2308545559644699
rl training, epoch9, iter0, batch105/1133, batch loss:0.2308545559644699, Training time:29824.29051542282
batch reward last col mean 0.06268113851547241 first col mean 0.09381580352783203 all mean 0.0713849663734436
0.24710766971111298 0.24710766971111298
rl training, epoch9, iter0, batch106/1133, batch loss:0.24710766971111298, Training time:29827.005499124527
batch reward last col mean 0.1066456213593483 first col mean 0.0883660539984703 all mean 0.09618115425109863
0.2586630582809448 0.2586630582809448
rl training, epoch9, iter0, batch107/1133, batch loss:0.2586630582809448, Training time:29828.897779226303
batch reward last col mean 0.07083411514759064 first col mean 0.08959761261940002 all mean 0.0751679539680481
0.2335880547761917 0.2335880547761917
rl training, epoch9, iter0, batch108/1133, batch loss:0.2335880547761917, Training time:29831.25359106064
batch reward last col mean 0.07873311638832092 first col mean 0.08874353766441345 all mean 0.08157133311033249
0.25994163751602173 0.25994163751602173
rl training, epoch9, iter0, batch109/1133, batch loss:0.25994163751602173, Training time:29833.78373336792
batch reward last col mean 0.0777745395898819 first col mean 0.09964026510715485 all mean 0.08563081175088882
0.2549313008785248 0.2549312710762024
rl training, epoch9, iter0, batch110/1133, batch loss:0.2549312710762024, Training time:29835.363011598587
batch reward last col mean 0.08361808955669403 first col mean 0.0951065644621849 all mean 0.08581578731536865
0.23517782986164093 0.23517782986164093
rl training, epoch9, iter0, batch111/1133, batch loss:0.23517782986164093, Training time:29837.382746458054
batch reward last col mean 0.11104356497526169 first col mean 0.08100824803113937 all mean 0.10633832216262817
0.23819522559642792 0.23819521069526672
rl training, epoch9, iter0, batch112/1133, batch loss:0.23819521069526672, Training time:29840.411368370056
batch reward last col mean 0.1238572746515274 first col mean 0.11255903542041779 all mean 0.11173193156719208
0.2957308292388916 0.2957308292388916
rl training, epoch9, iter0, batch113/1133, batch loss:0.2957308292388916, Training time:29842.673693418503
batch reward last col mean 0.0675419270992279 first col mean 0.08952529728412628 all mean 0.07284855097532272
0.22890281677246094 0.22890281677246094
rl training, epoch9, iter0, batch114/1133, batch loss:0.22890281677246094, Training time:29845.168406248093
batch reward last col mean 0.08268994092941284 first col mean 0.09229341149330139 all mean 0.08286091685295105
0.2442016899585724 0.24420171976089478
rl training, epoch9, iter0, batch115/1133, batch loss:0.24420171976089478, Training time:29847.327748060226
batch reward last col mean 0.06493090838193893 first col mean 0.10789810121059418 all mean 0.06777409464120865
0.22329038381576538 0.22329038381576538
rl training, epoch9, iter0, batch116/1133, batch loss:0.22329038381576538, Training time:29849.14590239525
batch reward last col mean 0.04589956998825073 first col mean 0.08451236039400101 all mean 0.06258741021156311
0.24886642396450043 0.24886642396450043
rl training, epoch9, iter0, batch117/1133, batch loss:0.24886642396450043, Training time:29851.10477924347
batch reward last col mean 0.08863405883312225 first col mean 0.08487143367528915 all mean 0.08847374469041824
0.2287089079618454 0.2287089079618454
rl training, epoch9, iter0, batch118/1133, batch loss:0.2287089079618454, Training time:29853.043300151825
batch reward last col mean 0.10931070148944855 first col mean 0.07576055824756622 all mean 0.10327845066785812
0.28012341260910034 0.28012341260910034
rl training, epoch9, iter0, batch119/1133, batch loss:0.28012341260910034, Training time:29855.025722503662
batch reward last col mean 0.09031956642866135 first col mean 0.09787335991859436 all mean 0.0896996334195137
0.21880389750003815 0.21880388259887695
rl training, epoch9, iter0, batch120/1133, batch loss:0.21880388259887695, Training time:29856.77702856064
batch reward last col mean 0.07814621925354004 first col mean 0.09370255470275879 all mean 0.08451718091964722
0.266598641872406 0.266598641872406
rl training, epoch9, iter0, batch121/1133, batch loss:0.266598641872406, Training time:29858.676205158234
batch reward last col mean 0.08559741079807281 first col mean 0.09783771634101868 all mean 0.08431144803762436
0.22344408929347992 0.22344408929347992
rl training, epoch9, iter0, batch122/1133, batch loss:0.22344408929347992, Training time:29860.333755731583
batch reward last col mean 0.06679125875234604 first col mean 0.10528989881277084 all mean 0.07305620610713959
0.2194598913192749 0.2194598913192749
rl training, epoch9, iter0, batch123/1133, batch loss:0.2194598913192749, Training time:29862.50511789322
batch reward last col mean 0.07755998522043228 first col mean 0.09299848973751068 all mean 0.08667866885662079
0.22246238589286804 0.22246238589286804
rl training, epoch9, iter0, batch124/1133, batch loss:0.22246238589286804, Training time:29864.511836528778
batch reward last col mean 0.09745299816131592 first col mean 0.09338586032390594 all mean 0.09008600562810898
0.24466466903686523 0.24466466903686523
rl training, epoch9, iter0, batch125/1133, batch loss:0.24466466903686523, Training time:29866.088024139404
batch reward last col mean 0.12101374566555023 first col mean 0.11102226376533508 all mean 0.1140298843383789
0.3054613471031189 0.3054613471031189
rl training, epoch9, iter0, batch126/1133, batch loss:0.3054613471031189, Training time:29868.770963668823
batch reward last col mean 0.09905366599559784 first col mean 0.08225739747285843 all mean 0.10012848675251007
0.26615044474601746 0.26615044474601746
rl training, epoch9, iter0, batch127/1133, batch loss:0.26615044474601746, Training time:29870.671808719635
batch reward last col mean 0.08458864688873291 first col mean 0.08980092406272888 all mean 0.0902455747127533
0.2390633523464203 0.2390633523464203
rl training, epoch9, iter0, batch128/1133, batch loss:0.2390633523464203, Training time:29872.490612506866
batch reward last col mean 0.08040555566549301 first col mean 0.08895698189735413 all mean 0.08445371687412262
0.24936509132385254 0.24936506152153015
rl training, epoch9, iter0, batch129/1133, batch loss:0.24936506152153015, Training time:29874.194464683533
batch reward last col mean 0.09538228064775467 first col mean 0.10096640139818192 all mean 0.09602048248052597
0.26799634099006653 0.26799634099006653
rl training, epoch9, iter0, batch130/1133, batch loss:0.26799634099006653, Training time:29875.958158016205
batch reward last col mean 0.08827652782201767 first col mean 0.09692764282226562 all mean 0.09187812358140945
0.24350744485855103 0.24350744485855103
rl training, epoch9, iter0, batch131/1133, batch loss:0.24350744485855103, Training time:29877.56021308899
batch reward last col mean 0.09205150604248047 first col mean 0.10211699455976486 all mean 0.0886743813753128
0.23576878011226654 0.23576878011226654
rl training, epoch9, iter0, batch132/1133, batch loss:0.23576878011226654, Training time:29879.427696228027
batch reward last col mean 0.08783513307571411 first col mean 0.0911312997341156 all mean 0.08652618527412415
0.22386930882930756 0.22386930882930756
rl training, epoch9, iter0, batch133/1133, batch loss:0.22386930882930756, Training time:29881.585066318512
batch reward last col mean 0.07963019609451294 first col mean 0.09253370016813278 all mean 0.0863451287150383
0.25543245673179626 0.25543245673179626
rl training, epoch9, iter0, batch134/1133, batch loss:0.25543245673179626, Training time:29883.145287275314
batch reward last col mean 0.10794838517904282 first col mean 0.08935678750276566 all mean 0.10103746503591537
0.2580466568470001 0.2580466568470001
rl training, epoch9, iter0, batch135/1133, batch loss:0.2580466568470001, Training time:29884.95453095436
batch reward last col mean 0.049585748463869095 first col mean 0.0923551693558693 all mean 0.06156587600708008
0.22188887000083923 0.22188887000083923
rl training, epoch9, iter0, batch136/1133, batch loss:0.22188887000083923, Training time:29886.783609628677
batch reward last col mean 0.07715557515621185 first col mean 0.07742644846439362 all mean 0.08504773676395416
0.2591622769832611 0.2591622769832611
rl training, epoch9, iter0, batch137/1133, batch loss:0.2591622769832611, Training time:29888.952029943466
batch reward last col mean 0.07473693042993546 first col mean 0.10009431838989258 all mean 0.08144603669643402
0.2430272102355957 0.2430272400379181
rl training, epoch9, iter0, batch138/1133, batch loss:0.2430272400379181, Training time:29891.003758907318
batch reward last col mean 0.0720861554145813 first col mean 0.09650587290525436 all mean 0.08271539211273193
0.2613773047924042 0.2613773047924042
rl training, epoch9, iter0, batch139/1133, batch loss:0.2613773047924042, Training time:29892.57174730301
batch reward last col mean 0.0895891785621643 first col mean 0.08783400803804398 all mean 0.0906846821308136
0.2369880974292755 0.2369880974292755
rl training, epoch9, iter0, batch140/1133, batch loss:0.2369880974292755, Training time:29894.771798849106
batch reward last col mean 0.11844071745872498 first col mean 0.09438830614089966 all mean 0.11409135162830353
0.2926662862300873 0.2926662862300873
rl training, epoch9, iter0, batch141/1133, batch loss:0.2926662862300873, Training time:29896.534005880356
batch reward last col mean 0.09675026684999466 first col mean 0.09465647488832474 all mean 0.09320788830518723
0.21550460159778595 0.21550460159778595
rl training, epoch9, iter0, batch142/1133, batch loss:0.21550460159778595, Training time:29899.18847632408
batch reward last col mean 0.07269127666950226 first col mean 0.08643710613250732 all mean 0.07781901210546494
0.2475307732820511 0.2475307732820511
rl training, epoch9, iter0, batch143/1133, batch loss:0.2475307732820511, Training time:29901.471245765686
batch reward last col mean 0.08462376892566681 first col mean 0.0934717133641243 all mean 0.08310896158218384
0.2313491255044937 0.2313491255044937
rl training, epoch9, iter0, batch144/1133, batch loss:0.2313491255044937, Training time:29903.311553955078
batch reward last col mean 0.07645182311534882 first col mean 0.0848536416888237 all mean 0.08039866387844086
0.23813201487064362 0.23813201487064362
rl training, epoch9, iter0, batch145/1133, batch loss:0.23813201487064362, Training time:29905.767379522324
batch reward last col mean 0.10025324672460556 first col mean 0.09585265070199966 all mean 0.09870410710573196
0.25030529499053955 0.25030529499053955
rl training, epoch9, iter0, batch146/1133, batch loss:0.25030529499053955, Training time:29907.66162443161
batch reward last col mean 0.082243911921978 first col mean 0.08791845291852951 all mean 0.08067790418863297
0.23623314499855042 0.2362331598997116
rl training, epoch9, iter0, batch147/1133, batch loss:0.2362331598997116, Training time:29909.741008758545
batch reward last col mean 0.07681214064359665 first col mean 0.10417579859495163 all mean 0.08074773848056793
0.22284357249736786 0.22284357249736786
rl training, epoch9, iter0, batch148/1133, batch loss:0.22284357249736786, Training time:29911.63576388359
batch reward last col mean 0.11033768951892853 first col mean 0.08868050575256348 all mean 0.10243887454271317
0.25599631667137146 0.25599631667137146
rl training, epoch9, iter0, batch149/1133, batch loss:0.25599631667137146, Training time:29913.600342273712
batch reward last col mean 0.09106360375881195 first col mean 0.0937655046582222 all mean 0.09768661856651306
0.2670809328556061 0.2670809328556061
rl training, epoch9, iter0, batch150/1133, batch loss:0.2670809328556061, Training time:29915.535738945007
batch reward last col mean 0.0714968889951706 first col mean 0.09770555794239044 all mean 0.08137769997119904
0.23467674851417542 0.23467674851417542
rl training, epoch9, iter0, batch151/1133, batch loss:0.23467674851417542, Training time:29917.127598524094
batch reward last col mean 0.08420626819133759 first col mean 0.09084640443325043 all mean 0.08605638146400452
0.2416049987077713 0.2416050136089325
rl training, epoch9, iter0, batch152/1133, batch loss:0.2416050136089325, Training time:29919.47860431671
batch reward last col mean 0.07206214219331741 first col mean 0.09228801727294922 all mean 0.0762617290019989
0.23631703853607178 0.23631703853607178
rl training, epoch9, iter0, batch153/1133, batch loss:0.23631703853607178, Training time:29922.077617406845
batch reward last col mean 0.07309765368700027 first col mean 0.09777697175741196 all mean 0.07731741666793823
0.2253067046403885 0.2253067046403885
rl training, epoch9, iter0, batch154/1133, batch loss:0.2253067046403885, Training time:29925.688610315323
batch reward last col mean 0.103224016726017 first col mean 0.09477533400058746 all mean 0.10063321143388748
0.24962779879570007 0.24962779879570007
rl training, epoch9, iter0, batch155/1133, batch loss:0.24962779879570007, Training time:29927.49482345581
batch reward last col mean 0.10135899484157562 first col mean 0.09245333820581436 all mean 0.09972073137760162
0.25427958369255066 0.25427958369255066
rl training, epoch9, iter0, batch156/1133, batch loss:0.25427958369255066, Training time:29929.506422281265
batch reward last col mean 0.07224290817975998 first col mean 0.09168505668640137 all mean 0.07865010201931
0.24350908398628235 0.24350909888744354
rl training, epoch9, iter0, batch157/1133, batch loss:0.24350909888744354, Training time:29932.5934176445
batch reward last col mean 0.06815879046916962 first col mean 0.09425706416368484 all mean 0.07853320986032486
0.23465590178966522 0.23465590178966522
rl training, epoch9, iter0, batch158/1133, batch loss:0.23465590178966522, Training time:29934.61754322052
batch reward last col mean 0.09238632023334503 first col mean 0.08106164634227753 all mean 0.09268812090158463
0.2668378949165344 0.26683786511421204
rl training, epoch9, iter0, batch159/1133, batch loss:0.26683786511421204, Training time:29936.544081687927
batch reward last col mean 0.12183474004268646 first col mean 0.08336309343576431 all mean 0.11289828270673752
0.26302656531333923 0.26302656531333923
rl training, epoch9, iter0, batch160/1133, batch loss:0.26302656531333923, Training time:29938.142737150192
batch reward last col mean 0.11259892582893372 first col mean 0.08879557251930237 all mean 0.11156744509935379
0.3017229437828064 0.3017229437828064
rl training, epoch9, iter0, batch161/1133, batch loss:0.3017229437828064, Training time:29940.39382982254
batch reward last col mean 0.08061983436346054 first col mean 0.10494646430015564 all mean 0.08332226425409317
0.22673435509204865 0.22673435509204865
rl training, epoch9, iter0, batch162/1133, batch loss:0.22673435509204865, Training time:29942.40954017639
batch reward last col mean 0.09671591222286224 first col mean 0.11112917959690094 all mean 0.09785094857215881
0.2357596606016159 0.2357596755027771
rl training, epoch9, iter0, batch163/1133, batch loss:0.2357596755027771, Training time:29944.587897777557
batch reward last col mean 0.07280328869819641 first col mean 0.09372198581695557 all mean 0.07174240052700043
0.24716220796108246 0.24716220796108246
rl training, epoch9, iter0, batch164/1133, batch loss:0.24716220796108246, Training time:29947.184441804886
batch reward last col mean 0.09340812265872955 first col mean 0.10591079294681549 all mean 0.09707816690206528
0.26268723607063293 0.26268720626831055
rl training, epoch9, iter0, batch165/1133, batch loss:0.26268720626831055, Training time:29949.226060390472
batch reward last col mean 0.1088455319404602 first col mean 0.10783694684505463 all mean 0.09917429089546204
0.25312864780426025 0.25312864780426025
rl training, epoch9, iter0, batch166/1133, batch loss:0.25312864780426025, Training time:29950.72385406494
batch reward last col mean 0.09517639875411987 first col mean 0.0850137397646904 all mean 0.0980103462934494
0.272012323141098 0.272012323141098
rl training, epoch9, iter0, batch167/1133, batch loss:0.272012323141098, Training time:29952.64718413353
batch reward last col mean 0.09991730749607086 first col mean 0.10217657685279846 all mean 0.09815847128629684
0.2788084149360657 0.2788084149360657
rl training, epoch9, iter0, batch168/1133, batch loss:0.2788084149360657, Training time:29954.349316596985
batch reward last col mean 0.08738885819911957 first col mean 0.0938442274928093 all mean 0.08863405138254166
0.239488884806633 0.239488884806633
rl training, epoch9, iter0, batch169/1133, batch loss:0.239488884806633, Training time:29956.512697458267
batch reward last col mean 0.09583185613155365 first col mean 0.08834531158208847 all mean 0.09200488775968552
0.2380126267671585 0.2380126267671585
rl training, epoch9, iter0, batch170/1133, batch loss:0.2380126267671585, Training time:29958.10839152336
batch reward last col mean 0.0922197476029396 first col mean 0.08749353885650635 all mean 0.09047986567020416
0.2538658082485199 0.2538658082485199
rl training, epoch9, iter0, batch171/1133, batch loss:0.2538658082485199, Training time:29960.327971935272
batch reward last col mean 0.10511156171560287 first col mean 0.09731189906597137 all mean 0.10704377293586731
0.28542807698249817 0.28542807698249817
rl training, epoch9, iter0, batch172/1133, batch loss:0.28542807698249817, Training time:29961.9367685318
batch reward last col mean 0.10023393481969833 first col mean 0.08766508847475052 all mean 0.10375037789344788
0.2875128388404846 0.2875128388404846
rl training, epoch9, iter0, batch173/1133, batch loss:0.2875128388404846, Training time:29964.247739315033
batch reward last col mean 0.06995375454425812 first col mean 0.09554710239171982 all mean 0.07943718880414963
0.2620260715484619 0.2620260715484619
rl training, epoch9, iter0, batch174/1133, batch loss:0.2620260715484619, Training time:29966.59934067726
batch reward last col mean 0.0741630420088768 first col mean 0.08101242035627365 all mean 0.07997917383909225
0.24112959206104279 0.24112959206104279
rl training, epoch9, iter0, batch175/1133, batch loss:0.24112959206104279, Training time:29969.22639155388
batch reward last col mean 0.09578634053468704 first col mean 0.10641533136367798 all mean 0.09784305840730667
0.2574879229068756 0.2574879229068756
rl training, epoch9, iter0, batch176/1133, batch loss:0.2574879229068756, Training time:29972.066294431686
batch reward last col mean 0.08764371275901794 first col mean 0.09256793558597565 all mean 0.0860627219080925
0.24822808802127838 0.24822811782360077
rl training, epoch9, iter0, batch177/1133, batch loss:0.24822811782360077, Training time:29974.807909965515
batch reward last col mean 0.13260799646377563 first col mean 0.10856384038925171 all mean 0.1264028549194336
0.28110095858573914 0.28110095858573914
rl training, epoch9, iter0, batch178/1133, batch loss:0.28110095858573914, Training time:29978.22953891754
batch reward last col mean 0.07184372842311859 first col mean 0.09192924201488495 all mean 0.0814133957028389
0.25481268763542175 0.25481268763542175
rl training, epoch9, iter0, batch179/1133, batch loss:0.25481268763542175, Training time:29980.06787776947
batch reward last col mean 0.08081457018852234 first col mean 0.0924585834145546 all mean 0.08358713239431381
0.2374848574399948 0.2374848574399948
rl training, epoch9, iter0, batch180/1133, batch loss:0.2374848574399948, Training time:29981.956240415573
batch reward last col mean 0.08008631318807602 first col mean 0.09880302846431732 all mean 0.0839921161532402
0.23193275928497314 0.23193275928497314
rl training, epoch9, iter0, batch181/1133, batch loss:0.23193275928497314, Training time:29984.348454236984
batch reward last col mean 0.0908404067158699 first col mean 0.09221219271421432 all mean 0.09271129220724106
0.25585415959358215 0.25585415959358215
rl training, epoch9, iter0, batch182/1133, batch loss:0.25585415959358215, Training time:29986.485414266586
batch reward last col mean 0.1049119159579277 first col mean 0.08652395009994507 all mean 0.10053462535142899
0.25757065415382385 0.25757065415382385
rl training, epoch9, iter0, batch183/1133, batch loss:0.25757065415382385, Training time:29988.172482013702
batch reward last col mean 0.06739848852157593 first col mean 0.08872091770172119 all mean 0.07727999985218048
0.27717524766921997 0.27717524766921997
rl training, epoch9, iter0, batch184/1133, batch loss:0.27717524766921997, Training time:29990.095505952835
batch reward last col mean 0.07943713665008545 first col mean 0.09616030752658844 all mean 0.08442569524049759
0.2671613097190857 0.2671612799167633
rl training, epoch9, iter0, batch185/1133, batch loss:0.2671612799167633, Training time:29992.32948565483
batch reward last col mean 0.07240312546491623 first col mean 0.0968494564294815 all mean 0.07807335257530212
0.23068293929100037 0.23068293929100037
rl training, epoch9, iter0, batch186/1133, batch loss:0.23068293929100037, Training time:29994.334717035294
batch reward last col mean 0.08422349393367767 first col mean 0.09785401821136475 all mean 0.08621465414762497
0.24393995106220245 0.24393992125988007
rl training, epoch9, iter0, batch187/1133, batch loss:0.24393992125988007, Training time:29997.12552666664
batch reward last col mean 0.08054948598146439 first col mean 0.09192253649234772 all mean 0.08032694458961487
0.22470803558826447 0.22470803558826447
rl training, epoch9, iter0, batch188/1133, batch loss:0.22470803558826447, Training time:29999.7802233696
batch reward last col mean 0.08243736624717712 first col mean 0.10461793839931488 all mean 0.0849372074007988
0.2313532531261444 0.2313532680273056
rl training, epoch9, iter0, batch189/1133, batch loss:0.2313532680273056, Training time:30002.617346286774
batch reward last col mean 0.0668141171336174 first col mean 0.0990447998046875 all mean 0.07692498713731766
0.26281407475471497 0.26281407475471497
rl training, epoch9, iter0, batch190/1133, batch loss:0.26281407475471497, Training time:30004.979749917984
batch reward last col mean 0.09116179496049881 first col mean 0.10020053386688232 all mean 0.09224183857440948
0.24252548813819885 0.24252548813819885
rl training, epoch9, iter0, batch191/1133, batch loss:0.24252548813819885, Training time:30007.680496692657
batch reward last col mean 0.09475021809339523 first col mean 0.10726402699947357 all mean 0.09767580777406693
0.2654483914375305 0.2654483914375305
rl training, epoch9, iter0, batch192/1133, batch loss:0.2654483914375305, Training time:30010.66081380844
batch reward last col mean 0.10170184075832367 first col mean 0.10669407248497009 all mean 0.09792595356702805
0.24338945746421814 0.24338945746421814
rl training, epoch9, iter0, batch193/1133, batch loss:0.24338945746421814, Training time:30012.568021774292
batch reward last col mean 0.07970862090587616 first col mean 0.07282861322164536 all mean 0.07992662489414215
0.24277926981449127 0.24277925491333008
rl training, epoch9, iter0, batch194/1133, batch loss:0.24277925491333008, Training time:30014.449811458588
batch reward last col mean 0.09678128361701965 first col mean 0.08574991673231125 all mean 0.09694462269544601
0.22159545123577118 0.22159545123577118
rl training, epoch9, iter0, batch195/1133, batch loss:0.22159545123577118, Training time:30016.675762414932
batch reward last col mean 0.08448689430952072 first col mean 0.10280275344848633 all mean 0.08801877498626709
0.23132093250751495 0.23132091760635376
rl training, epoch9, iter0, batch196/1133, batch loss:0.23132091760635376, Training time:30019.055032491684
batch reward last col mean 0.09688770025968552 first col mean 0.09003899991512299 all mean 0.10165949165821075
0.26757314801216125 0.26757311820983887
rl training, epoch9, iter0, batch197/1133, batch loss:0.26757311820983887, Training time:30021.34640431404
batch reward last col mean 0.09069852530956268 first col mean 0.10414024442434311 all mean 0.09423594921827316
0.2472221851348877 0.2472221851348877
rl training, epoch9, iter0, batch198/1133, batch loss:0.2472221851348877, Training time:30023.53818655014
batch reward last col mean 0.1259693205356598 first col mean 0.08538015931844711 all mean 0.11487898975610733
0.2669034004211426 0.2669034004211426
rl training, epoch9, iter0, batch199/1133, batch loss:0.2669034004211426, Training time:30025.49304318428
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.44655208448761874 Time: 98.76220655441284 s
loss of true 0.19060762225266378 loss of gen 0.16274485426041688 loss of other 0.09319960717144705 first score 0.10008108615875244
batch reward last col mean 0.06713509559631348 first col mean 0.10766193270683289 all mean 0.08084340393543243
0.2558121681213379 0.2558121681213379
rl training, epoch9, iter0, batch200/1133, batch loss:0.2558121681213379, Training time:30126.336446523666
batch reward last col mean 0.1270240843296051 first col mean 0.10507529973983765 all mean 0.11974935978651047
0.29328614473342896 0.29328614473342896
rl training, epoch9, iter0, batch201/1133, batch loss:0.29328614473342896, Training time:30128.172163248062
batch reward last col mean 0.07868403196334839 first col mean 0.0955561101436615 all mean 0.08619023859500885
0.2603957951068878 0.2603957951068878
rl training, epoch9, iter0, batch202/1133, batch loss:0.2603957951068878, Training time:30130.3967397213
batch reward last col mean 0.10874529927968979 first col mean 0.11204896122217178 all mean 0.10262458026409149
0.2583630681037903 0.2583630681037903
rl training, epoch9, iter0, batch203/1133, batch loss:0.2583630681037903, Training time:30132.489452838898
batch reward last col mean 0.13046781718730927 first col mean 0.10459105670452118 all mean 0.12221382558345795
0.2746061682701111 0.2746061682701111
rl training, epoch9, iter0, batch204/1133, batch loss:0.2746061682701111, Training time:30135.89288520813
batch reward last col mean 0.1266230195760727 first col mean 0.10536488145589828 all mean 0.11956708133220673
0.300018310546875 0.300018310546875
rl training, epoch9, iter0, batch205/1133, batch loss:0.300018310546875, Training time:30138.627039194107
batch reward last col mean 0.12785252928733826 first col mean 0.0960213840007782 all mean 0.12214846909046173
0.2679423987865448 0.2679423987865448
rl training, epoch9, iter0, batch206/1133, batch loss:0.2679423987865448, Training time:30141.46916770935
batch reward last col mean 0.08436614274978638 first col mean 0.10652739554643631 all mean 0.0830865278840065
0.23475752770900726 0.23475748300552368
rl training, epoch9, iter0, batch207/1133, batch loss:0.23475748300552368, Training time:30143.757956266403
batch reward last col mean 0.07613353431224823 first col mean 0.11094197630882263 all mean 0.08020526170730591
0.2562682330608368 0.2562682330608368
rl training, epoch9, iter0, batch208/1133, batch loss:0.2562682330608368, Training time:30146.00541162491
batch reward last col mean 0.10494522005319595 first col mean 0.09468592703342438 all mean 0.10057270526885986
0.2679753601551056 0.2679753601551056
rl training, epoch9, iter0, batch209/1133, batch loss:0.2679753601551056, Training time:30148.244819402695
batch reward last col mean 0.09770400822162628 first col mean 0.09049183875322342 all mean 0.10138528048992157
0.2923094630241394 0.2923094630241394
rl training, epoch9, iter0, batch210/1133, batch loss:0.2923094630241394, Training time:30150.425944328308
batch reward last col mean 0.08653069287538528 first col mean 0.09906908869743347 all mean 0.08721712231636047
0.27277103066444397 0.27277103066444397
rl training, epoch9, iter0, batch211/1133, batch loss:0.27277103066444397, Training time:30152.51261615753
batch reward last col mean 0.1122090071439743 first col mean 0.1114499419927597 all mean 0.11143816262483597
0.26961347460746765 0.26961347460746765
rl training, epoch9, iter0, batch212/1133, batch loss:0.26961347460746765, Training time:30154.83268547058
batch reward last col mean 0.06814392656087875 first col mean 0.09798917919397354 all mean 0.07968313992023468
0.25420081615448 0.25420081615448
rl training, epoch9, iter0, batch213/1133, batch loss:0.25420081615448, Training time:30156.82590007782
batch reward last col mean 0.11171222478151321 first col mean 0.1118716150522232 all mean 0.10488633066415787
0.28327152132987976 0.28327152132987976
rl training, epoch9, iter0, batch214/1133, batch loss:0.28327152132987976, Training time:30158.781703710556
batch reward last col mean 0.09917369484901428 first col mean 0.09773445129394531 all mean 0.09941276162862778
0.28003883361816406 0.28003886342048645
rl training, epoch9, iter0, batch215/1133, batch loss:0.28003886342048645, Training time:30160.944794416428
batch reward last col mean 0.12161796540021896 first col mean 0.10883630067110062 all mean 0.11661408841609955
0.28167831897735596 0.28167831897735596
rl training, epoch9, iter0, batch216/1133, batch loss:0.28167831897735596, Training time:30163.196212291718
batch reward last col mean 0.09953657537698746 first col mean 0.09821565449237823 all mean 0.09619762003421783
0.25146982073783875 0.25146982073783875
rl training, epoch9, iter0, batch217/1133, batch loss:0.25146982073783875, Training time:30165.745602607727
batch reward last col mean 0.07284140586853027 first col mean 0.09843877702951431 all mean 0.08349672704935074
0.2693685293197632 0.2693685293197632
rl training, epoch9, iter0, batch218/1133, batch loss:0.2693685293197632, Training time:30167.543827056885
batch reward last col mean 0.07883792370557785 first col mean 0.09795462340116501 all mean 0.09086637943983078
0.2712235152721405 0.2712235152721405
rl training, epoch9, iter0, batch219/1133, batch loss:0.2712235152721405, Training time:30169.696846961975
batch reward last col mean 0.07829736918210983 first col mean 0.09797658026218414 all mean 0.0875648632645607
0.2485242784023285 0.2485242784023285
rl training, epoch9, iter0, batch220/1133, batch loss:0.2485242784023285, Training time:30172.292455673218
batch reward last col mean 0.11571737378835678 first col mean 0.11170177161693573 all mean 0.11351363360881805
0.2787456810474396 0.2787456810474396
rl training, epoch9, iter0, batch221/1133, batch loss:0.2787456810474396, Training time:30174.593316078186
batch reward last col mean 0.06553579866886139 first col mean 0.10976981371641159 all mean 0.07612752914428711
0.2455332726240158 0.2455332726240158
rl training, epoch9, iter0, batch222/1133, batch loss:0.2455332726240158, Training time:30176.489604234695
batch reward last col mean 0.10024247318506241 first col mean 0.1027030497789383 all mean 0.10161576420068741
0.2671942710876465 0.2671942710876465
rl training, epoch9, iter0, batch223/1133, batch loss:0.2671942710876465, Training time:30178.503880500793
batch reward last col mean 0.12474089115858078 first col mean 0.11531444638967514 all mean 0.12494650483131409
0.2986901104450226 0.2986901104450226
rl training, epoch9, iter0, batch224/1133, batch loss:0.2986901104450226, Training time:30180.15541934967
batch reward last col mean 0.11559019982814789 first col mean 0.10956859588623047 all mean 0.10578762739896774
0.30729174613952637 0.30729174613952637
rl training, epoch9, iter0, batch225/1133, batch loss:0.30729174613952637, Training time:30182.579962015152
batch reward last col mean 0.11286516487598419 first col mean 0.09692437946796417 all mean 0.1074918732047081
0.24587541818618774 0.24587541818618774
rl training, epoch9, iter0, batch226/1133, batch loss:0.24587541818618774, Training time:30184.98759317398
batch reward last col mean 0.0959300696849823 first col mean 0.09671401232481003 all mean 0.09763741493225098
0.23053930699825287 0.23053930699825287
rl training, epoch9, iter0, batch227/1133, batch loss:0.23053930699825287, Training time:30186.777244091034
batch reward last col mean 0.08426934480667114 first col mean 0.09347008168697357 all mean 0.08526294678449631
0.22023537755012512 0.22023537755012512
rl training, epoch9, iter0, batch228/1133, batch loss:0.22023537755012512, Training time:30189.487243890762
batch reward last col mean 0.07820096611976624 first col mean 0.0923289805650711 all mean 0.08563587814569473
0.26137644052505493 0.26137644052505493
rl training, epoch9, iter0, batch229/1133, batch loss:0.26137644052505493, Training time:30191.39294552803
batch reward last col mean 0.14020197093486786 first col mean 0.08993333578109741 all mean 0.13154886662960052
0.29562029242515564 0.29562029242515564
rl training, epoch9, iter0, batch230/1133, batch loss:0.29562029242515564, Training time:30193.167687654495
batch reward last col mean 0.09135977178812027 first col mean 0.10860615223646164 all mean 0.10067599266767502
0.29170411825180054 0.29170411825180054
rl training, epoch9, iter0, batch231/1133, batch loss:0.29170411825180054, Training time:30194.915472984314
batch reward last col mean 0.09067478030920029 first col mean 0.08919665962457657 all mean 0.08860806375741959
0.24576176702976227 0.24576176702976227
rl training, epoch9, iter0, batch232/1133, batch loss:0.24576176702976227, Training time:30196.666783094406
batch reward last col mean 0.1066526547074318 first col mean 0.11095059663057327 all mean 0.10213598608970642
0.2821843922138214 0.2821843922138214
rl training, epoch9, iter0, batch233/1133, batch loss:0.2821843922138214, Training time:30198.665364265442
batch reward last col mean 0.07867211848497391 first col mean 0.10375016182661057 all mean 0.0856650099158287
0.2637784779071808 0.2637784779071808
rl training, epoch9, iter0, batch234/1133, batch loss:0.2637784779071808, Training time:30200.740161895752
batch reward last col mean 0.07554730772972107 first col mean 0.12581631541252136 all mean 0.08524131774902344
0.26733705401420593 0.26733705401420593
rl training, epoch9, iter0, batch235/1133, batch loss:0.26733705401420593, Training time:30203.034409999847
batch reward last col mean 0.09646865725517273 first col mean 0.10948213934898376 all mean 0.10188490897417068
0.27754926681518555 0.27754926681518555
rl training, epoch9, iter0, batch236/1133, batch loss:0.27754926681518555, Training time:30205.709983587265
batch reward last col mean 0.08936694264411926 first col mean 0.0800028145313263 all mean 0.09232255816459656
0.24021831154823303 0.24021831154823303
rl training, epoch9, iter0, batch237/1133, batch loss:0.24021831154823303, Training time:30207.335943698883
batch reward last col mean 0.08664672076702118 first col mean 0.10859844088554382 all mean 0.092315673828125
0.2795117497444153 0.2795117497444153
rl training, epoch9, iter0, batch238/1133, batch loss:0.2795117497444153, Training time:30209.85800266266
batch reward last col mean 0.12238042056560516 first col mean 0.11375447362661362 all mean 0.1164233610033989
0.26379647850990295 0.26379647850990295
rl training, epoch9, iter0, batch239/1133, batch loss:0.26379647850990295, Training time:30212.13607120514
batch reward last col mean 0.08143938332796097 first col mean 0.10972394049167633 all mean 0.08967767655849457
0.2756337821483612 0.2756337821483612
rl training, epoch9, iter0, batch240/1133, batch loss:0.2756337821483612, Training time:30214.45093512535
batch reward last col mean 0.11602325737476349 first col mean 0.10895036160945892 all mean 0.10720746964216232
0.2544591724872589 0.2544591426849365
rl training, epoch9, iter0, batch241/1133, batch loss:0.2544591426849365, Training time:30216.01916217804
batch reward last col mean 0.11720417439937592 first col mean 0.11401515454053879 all mean 0.11513112485408783
0.2699335813522339 0.2699335813522339
rl training, epoch9, iter0, batch242/1133, batch loss:0.2699335813522339, Training time:30218.018017292023
batch reward last col mean 0.1241629347205162 first col mean 0.10460425168275833 all mean 0.11134326457977295
0.2976280450820923 0.2976280450820923
rl training, epoch9, iter0, batch243/1133, batch loss:0.2976280450820923, Training time:30219.987642526627
batch reward last col mean 0.09968109428882599 first col mean 0.09971052408218384 all mean 0.10043923556804657
0.305743545293808 0.305743545293808
rl training, epoch9, iter0, batch244/1133, batch loss:0.305743545293808, Training time:30222.07257962227
batch reward last col mean 0.09800545871257782 first col mean 0.10314322263002396 all mean 0.09320701658725739
0.2506381571292877 0.2506381571292877
rl training, epoch9, iter0, batch245/1133, batch loss:0.2506381571292877, Training time:30224.843560934067
batch reward last col mean 0.11639507859945297 first col mean 0.09026923030614853 all mean 0.11076588928699493
0.2577846944332123 0.2577846646308899
rl training, epoch9, iter0, batch246/1133, batch loss:0.2577846646308899, Training time:30227.144345760345
batch reward last col mean 0.08580313622951508 first col mean 0.108968086540699 all mean 0.09016001224517822
0.2748599946498871 0.2748599946498871
rl training, epoch9, iter0, batch247/1133, batch loss:0.2748599946498871, Training time:30228.897025108337
batch reward last col mean 0.11262249201536179 first col mean 0.07633363455533981 all mean 0.1033792495727539
0.2683386504650116 0.2683386504650116
rl training, epoch9, iter0, batch248/1133, batch loss:0.2683386504650116, Training time:30231.29793357849
batch reward last col mean 0.08691930770874023 first col mean 0.09176575392484665 all mean 0.0949563980102539
0.28736400604248047 0.2873639762401581
rl training, epoch9, iter0, batch249/1133, batch loss:0.2873639762401581, Training time:30233.35784459114
batch reward last col mean 0.09182091057300568 first col mean 0.10670007020235062 all mean 0.09637657552957535
0.2931244671344757 0.2931244373321533
rl training, epoch9, iter0, batch250/1133, batch loss:0.2931244373321533, Training time:30235.311713457108
batch reward last col mean 0.10040837526321411 first col mean 0.1178041398525238 all mean 0.10413268953561783
0.267314612865448 0.267314612865448
rl training, epoch9, iter0, batch251/1133, batch loss:0.267314612865448, Training time:30237.14059114456
batch reward last col mean 0.08739165961742401 first col mean 0.10893666744232178 all mean 0.092722587287426
0.24277064204216003 0.24277064204216003
rl training, epoch9, iter0, batch252/1133, batch loss:0.24277064204216003, Training time:30239.01825428009
batch reward last col mean 0.07368513941764832 first col mean 0.09730184823274612 all mean 0.07956133782863617
0.25439220666885376 0.25439223647117615
rl training, epoch9, iter0, batch253/1133, batch loss:0.25439223647117615, Training time:30241.011130809784
batch reward last col mean 0.0789811834692955 first col mean 0.10635054111480713 all mean 0.0822586938738823
0.24843834340572357 0.24843834340572357
rl training, epoch9, iter0, batch254/1133, batch loss:0.24843834340572357, Training time:30243.466634988785
batch reward last col mean 0.1417822390794754 first col mean 0.11332996189594269 all mean 0.1281956434249878
0.29548364877700806 0.29548361897468567
rl training, epoch9, iter0, batch255/1133, batch loss:0.29548361897468567, Training time:30245.733858585358
batch reward last col mean 0.10521010309457779 first col mean 0.10757569968700409 all mean 0.10705352574586868
0.30741411447525024 0.30741408467292786
rl training, epoch9, iter0, batch256/1133, batch loss:0.30741408467292786, Training time:30247.70832490921
batch reward last col mean 0.08890140801668167 first col mean 0.08502587676048279 all mean 0.08697940409183502
0.27314531803131104 0.27314531803131104
rl training, epoch9, iter0, batch257/1133, batch loss:0.27314531803131104, Training time:30249.999411821365
batch reward last col mean 0.10192122310400009 first col mean 0.09003400802612305 all mean 0.10200347006320953
0.24647493660449982 0.24647493660449982
rl training, epoch9, iter0, batch258/1133, batch loss:0.24647493660449982, Training time:30253.069566488266
batch reward last col mean 0.1304924488067627 first col mean 0.10214680433273315 all mean 0.12650763988494873
0.29127517342567444 0.2912752032279968
rl training, epoch9, iter0, batch259/1133, batch loss:0.2912752032279968, Training time:30255.106588840485
batch reward last col mean 0.09954900294542313 first col mean 0.10564695298671722 all mean 0.09841718524694443
0.2733128070831299 0.2733128070831299
rl training, epoch9, iter0, batch260/1133, batch loss:0.2733128070831299, Training time:30257.394223690033
batch reward last col mean 0.07765989005565643 first col mean 0.10739023983478546 all mean 0.08121269941329956
0.2638702988624573 0.2638702988624573
rl training, epoch9, iter0, batch261/1133, batch loss:0.2638702988624573, Training time:30260.244029521942
batch reward last col mean 0.10101352632045746 first col mean 0.1249786913394928 all mean 0.10118652880191803
0.24295444786548615 0.24295444786548615
rl training, epoch9, iter0, batch262/1133, batch loss:0.24295444786548615, Training time:30262.832339525223
batch reward last col mean 0.08650285750627518 first col mean 0.10827440023422241 all mean 0.0930338129401207
0.24833033978939056 0.24833033978939056
rl training, epoch9, iter0, batch263/1133, batch loss:0.24833033978939056, Training time:30264.494040966034
batch reward last col mean 0.10858756303787231 first col mean 0.11498560756444931 all mean 0.11034611612558365
0.2965668737888336 0.2965668737888336
rl training, epoch9, iter0, batch264/1133, batch loss:0.2965668737888336, Training time:30266.159099817276
batch reward last col mean 0.06400978565216064 first col mean 0.09675087034702301 all mean 0.07401509582996368
0.2207093983888626 0.2207093983888626
rl training, epoch9, iter0, batch265/1133, batch loss:0.2207093983888626, Training time:30267.89040207863
batch reward last col mean 0.11570839583873749 first col mean 0.10548046231269836 all mean 0.11651435494422913
0.2924039661884308 0.2924039661884308
rl training, epoch9, iter0, batch266/1133, batch loss:0.2924039661884308, Training time:30269.60081744194
batch reward last col mean 0.09792232513427734 first col mean 0.10404324531555176 all mean 0.09855636209249496
0.2593371570110321 0.2593371570110321
rl training, epoch9, iter0, batch267/1133, batch loss:0.2593371570110321, Training time:30271.4870929718
batch reward last col mean 0.0841648131608963 first col mean 0.08903180807828903 all mean 0.08458325266838074
0.23439821600914001 0.23439821600914001
rl training, epoch9, iter0, batch268/1133, batch loss:0.23439821600914001, Training time:30273.382640838623
batch reward last col mean 0.0974753201007843 first col mean 0.11936798691749573 all mean 0.09893333911895752
0.23976153135299683 0.23976153135299683
rl training, epoch9, iter0, batch269/1133, batch loss:0.23976153135299683, Training time:30275.340007781982
batch reward last col mean 0.10047540068626404 first col mean 0.0955415815114975 all mean 0.10049691796302795
0.2753377854824066 0.2753377854824066
rl training, epoch9, iter0, batch270/1133, batch loss:0.2753377854824066, Training time:30278.120924711227
batch reward last col mean 0.11275942623615265 first col mean 0.11563773453235626 all mean 0.11064174771308899
0.34069445729255676 0.3406944274902344
rl training, epoch9, iter0, batch271/1133, batch loss:0.3406944274902344, Training time:30279.81981229782
batch reward last col mean 0.08756928890943527 first col mean 0.11082612723112106 all mean 0.0918358713388443
0.2682453989982605 0.2682453989982605
rl training, epoch9, iter0, batch272/1133, batch loss:0.2682453989982605, Training time:30281.58528280258
batch reward last col mean 0.10626009106636047 first col mean 0.10820099711418152 all mean 0.10444486141204834
0.27848076820373535 0.27848076820373535
rl training, epoch9, iter0, batch273/1133, batch loss:0.27848076820373535, Training time:30284.490574121475
batch reward last col mean 0.10292523354291916 first col mean 0.09801660478115082 all mean 0.1038132905960083
0.22659750282764435 0.22659750282764435
rl training, epoch9, iter0, batch274/1133, batch loss:0.22659750282764435, Training time:30287.212099313736
batch reward last col mean 0.10038967430591583 first col mean 0.11441173404455185 all mean 0.09688447415828705
0.2466791570186615 0.2466791570186615
rl training, epoch9, iter0, batch275/1133, batch loss:0.2466791570186615, Training time:30289.17317056656
batch reward last col mean 0.06467190384864807 first col mean 0.09924500435590744 all mean 0.0728948637843132
0.2415628284215927 0.2415628284215927
rl training, epoch9, iter0, batch276/1133, batch loss:0.2415628284215927, Training time:30291.536611795425
batch reward last col mean 0.08351178467273712 first col mean 0.10051856935024261 all mean 0.08702027797698975
0.23018041253089905 0.23018041253089905
rl training, epoch9, iter0, batch277/1133, batch loss:0.23018041253089905, Training time:30293.62686562538
batch reward last col mean 0.10547898709774017 first col mean 0.10849983990192413 all mean 0.10915837436914444
0.30486205220222473 0.30486205220222473
rl training, epoch9, iter0, batch278/1133, batch loss:0.30486205220222473, Training time:30295.56472969055
batch reward last col mean 0.1196058988571167 first col mean 0.11839006841182709 all mean 0.11598000675439835
0.31919345259666443 0.31919339299201965
rl training, epoch9, iter0, batch279/1133, batch loss:0.31919339299201965, Training time:30297.73907351494
batch reward last col mean 0.09713960438966751 first col mean 0.10411184281110764 all mean 0.10268522799015045
0.2826285660266876 0.2826285660266876
rl training, epoch9, iter0, batch280/1133, batch loss:0.2826285660266876, Training time:30299.66113638878
batch reward last col mean 0.09952423721551895 first col mean 0.13338488340377808 all mean 0.0982382744550705
0.2897557318210602 0.2897557318210602
rl training, epoch9, iter0, batch281/1133, batch loss:0.2897557318210602, Training time:30301.828221797943
batch reward last col mean 0.1195518970489502 first col mean 0.09249061346054077 all mean 0.11304973065853119
0.2880239486694336 0.2880239188671112
rl training, epoch9, iter0, batch282/1133, batch loss:0.2880239188671112, Training time:30303.49257349968
batch reward last col mean 0.10809120535850525 first col mean 0.10511704534292221 all mean 0.10606129467487335
0.30803343653678894 0.30803343653678894
rl training, epoch9, iter0, batch283/1133, batch loss:0.30803343653678894, Training time:30306.020124912262
batch reward last col mean 0.09064367413520813 first col mean 0.08754017949104309 all mean 0.09701921045780182
0.22720634937286377 0.22720634937286377
rl training, epoch9, iter0, batch284/1133, batch loss:0.22720634937286377, Training time:30308.144008636475
batch reward last col mean 0.09987449645996094 first col mean 0.1026274785399437 all mean 0.10181073099374771
0.27840226888656616 0.2784022390842438
rl training, epoch9, iter0, batch285/1133, batch loss:0.2784022390842438, Training time:30310.10785984993
batch reward last col mean 0.10921107977628708 first col mean 0.10533540695905685 all mean 0.10533241927623749
0.2915208637714386 0.2915208637714386
rl training, epoch9, iter0, batch286/1133, batch loss:0.2915208637714386, Training time:30312.507247686386
batch reward last col mean 0.12066053599119186 first col mean 0.09898892790079117 all mean 0.11611317843198776
0.30646589398384094 0.30646589398384094
rl training, epoch9, iter0, batch287/1133, batch loss:0.30646589398384094, Training time:30314.30720758438
batch reward last col mean 0.12885677814483643 first col mean 0.11358136683702469 all mean 0.1265859603881836
0.32803860306739807 0.32803860306739807
rl training, epoch9, iter0, batch288/1133, batch loss:0.32803860306739807, Training time:30316.035138368607
batch reward last col mean 0.12259788811206818 first col mean 0.11033211648464203 all mean 0.11624403297901154
0.3167324960231781 0.3167324960231781
rl training, epoch9, iter0, batch289/1133, batch loss:0.3167324960231781, Training time:30317.828724861145
batch reward last col mean 0.09491343796253204 first col mean 0.11557905375957489 all mean 0.09854260087013245
0.26446953415870667 0.2644695043563843
rl training, epoch9, iter0, batch290/1133, batch loss:0.2644695043563843, Training time:30320.446978092194
batch reward last col mean 0.10958661884069443 first col mean 0.09890224039554596 all mean 0.10785353928804398
0.27736976742744446 0.27736976742744446
rl training, epoch9, iter0, batch291/1133, batch loss:0.27736976742744446, Training time:30322.596137046814
batch reward last col mean 0.09490689635276794 first col mean 0.11315783858299255 all mean 0.09790874272584915
0.30451807379722595 0.30451807379722595
rl training, epoch9, iter0, batch292/1133, batch loss:0.30451807379722595, Training time:30324.67221069336
batch reward last col mean 0.0849054753780365 first col mean 0.09397464990615845 all mean 0.08748163282871246
0.2547588348388672 0.2547588348388672
rl training, epoch9, iter0, batch293/1133, batch loss:0.2547588348388672, Training time:30327.929119110107
batch reward last col mean 0.11753663420677185 first col mean 0.1059836745262146 all mean 0.11429590731859207
0.25502005219459534 0.25502005219459534
rl training, epoch9, iter0, batch294/1133, batch loss:0.25502005219459534, Training time:30330.27045750618
batch reward last col mean 0.07005514204502106 first col mean 0.11778637766838074 all mean 0.08180446177721024
0.2348804622888565 0.2348804622888565
rl training, epoch9, iter0, batch295/1133, batch loss:0.2348804622888565, Training time:30332.160444498062
batch reward last col mean 0.11186691373586655 first col mean 0.10266506671905518 all mean 0.1081637293100357
0.332346647977829 0.332346647977829
rl training, epoch9, iter0, batch296/1133, batch loss:0.332346647977829, Training time:30334.325466156006
batch reward last col mean 0.12341319024562836 first col mean 0.09672528505325317 all mean 0.12180806696414948
0.29130518436431885 0.29130518436431885
rl training, epoch9, iter0, batch297/1133, batch loss:0.29130518436431885, Training time:30335.97265100479
batch reward last col mean 0.07468220591545105 first col mean 0.10299969464540482 all mean 0.08226863294839859
0.23485951125621796 0.23485952615737915
rl training, epoch9, iter0, batch298/1133, batch loss:0.23485952615737915, Training time:30337.905167102814
batch reward last col mean 0.12833118438720703 first col mean 0.09828214347362518 all mean 0.12223262339830399
0.2785445749759674 0.2785445749759674
rl training, epoch9, iter0, batch299/1133, batch loss:0.2785445749759674, Training time:30339.785499095917
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.45349918693856445 Time: 97.94013452529907 s
loss of true 0.19476539860598724 loss of gen 0.16657372097183096 loss of other 0.09216006747911383 first score 0.114874467253685
batch reward last col mean 0.12283161282539368 first col mean 0.08324074000120163 all mean 0.11856097728013992
0.24790896475315094 0.24790896475315094
rl training, epoch9, iter0, batch300/1133, batch loss:0.24790896475315094, Training time:30439.514729976654
batch reward last col mean 0.1100093200802803 first col mean 0.08699660003185272 all mean 0.1053374856710434
0.2817712128162384 0.2817712128162384
rl training, epoch9, iter0, batch301/1133, batch loss:0.2817712128162384, Training time:30442.07323718071
batch reward last col mean 0.10628651082515717 first col mean 0.09853313118219376 all mean 0.10926347225904465
0.30409765243530273 0.30409765243530273
rl training, epoch9, iter0, batch302/1133, batch loss:0.30409765243530273, Training time:30443.984533548355
batch reward last col mean 0.13103142380714417 first col mean 0.10286463797092438 all mean 0.11619286239147186
0.26575732231140137 0.26575732231140137
rl training, epoch9, iter0, batch303/1133, batch loss:0.26575732231140137, Training time:30445.983731746674
batch reward last col mean 0.09735303372144699 first col mean 0.11232689023017883 all mean 0.10027321428060532
0.3006981909275055 0.3006981909275055
rl training, epoch9, iter0, batch304/1133, batch loss:0.3006981909275055, Training time:30448.884734630585
batch reward last col mean 0.08065676689147949 first col mean 0.10858526825904846 all mean 0.0886068344116211
0.2831990718841553 0.2831990718841553
rl training, epoch9, iter0, batch305/1133, batch loss:0.2831990718841553, Training time:30450.88089823723
batch reward last col mean 0.1121213361620903 first col mean 0.1130720004439354 all mean 0.11014846712350845
0.27916383743286133 0.2791638672351837
rl training, epoch9, iter0, batch306/1133, batch loss:0.2791638672351837, Training time:30452.94391655922
batch reward last col mean 0.08320131152868271 first col mean 0.10628078877925873 all mean 0.08824192732572556
0.2578570246696472 0.2578570246696472
rl training, epoch9, iter0, batch307/1133, batch loss:0.2578570246696472, Training time:30455.606673002243
batch reward last col mean 0.08788630366325378 first col mean 0.10581189393997192 all mean 0.09351073205471039
0.2900104820728302 0.2900104820728302
rl training, epoch9, iter0, batch308/1133, batch loss:0.2900104820728302, Training time:30457.679394483566
batch reward last col mean 0.09408234804868698 first col mean 0.11321836709976196 all mean 0.09370328485965729
0.23818068206310272 0.23818068206310272
rl training, epoch9, iter0, batch309/1133, batch loss:0.23818068206310272, Training time:30459.83519268036
batch reward last col mean 0.1076832190155983 first col mean 0.1210402324795723 all mean 0.10463498532772064
0.2791425883769989 0.2791425883769989
rl training, epoch9, iter0, batch310/1133, batch loss:0.2791425883769989, Training time:30462.169585704803
batch reward last col mean 0.08022472262382507 first col mean 0.09099305421113968 all mean 0.0798376202583313
0.25632596015930176 0.25632593035697937
rl training, epoch9, iter0, batch311/1133, batch loss:0.25632593035697937, Training time:30464.101310014725
batch reward last col mean 0.09184807538986206 first col mean 0.11577226221561432 all mean 0.09468995779752731
0.254431813955307 0.254431813955307
rl training, epoch9, iter0, batch312/1133, batch loss:0.254431813955307, Training time:30465.779675722122
batch reward last col mean 0.1222224086523056 first col mean 0.08876916021108627 all mean 0.11668044328689575
0.29041531682014465 0.29041531682014465
rl training, epoch9, iter0, batch313/1133, batch loss:0.29041531682014465, Training time:30467.788360118866
batch reward last col mean 0.09245138615369797 first col mean 0.10666793584823608 all mean 0.09816105663776398
0.29093101620674133 0.29093101620674133
rl training, epoch9, iter0, batch314/1133, batch loss:0.29093101620674133, Training time:30469.577411413193
batch reward last col mean 0.13162343204021454 first col mean 0.10609160363674164 all mean 0.12068483978509903
0.27407845854759216 0.27407845854759216
rl training, epoch9, iter0, batch315/1133, batch loss:0.27407845854759216, Training time:30471.61164999008
batch reward last col mean 0.08492080867290497 first col mean 0.10226130485534668 all mean 0.09106701612472534
0.24327395856380463 0.24327395856380463
rl training, epoch9, iter0, batch316/1133, batch loss:0.24327395856380463, Training time:30473.653990983963
batch reward last col mean 0.09300732612609863 first col mean 0.09208686649799347 all mean 0.09692449867725372
0.25499269366264343 0.25499269366264343
rl training, epoch9, iter0, batch317/1133, batch loss:0.25499269366264343, Training time:30475.421278476715
batch reward last col mean 0.08900463581085205 first col mean 0.10190881788730621 all mean 0.09132210910320282
0.278217077255249 0.278217077255249
rl training, epoch9, iter0, batch318/1133, batch loss:0.278217077255249, Training time:30477.361024856567
batch reward last col mean 0.11229017376899719 first col mean 0.08940637856721878 all mean 0.10527939349412918
0.2156522125005722 0.2156522125005722
rl training, epoch9, iter0, batch319/1133, batch loss:0.2156522125005722, Training time:30479.780936956406
batch reward last col mean 0.1043364480137825 first col mean 0.08758871257305145 all mean 0.10059836506843567
0.26361435651779175 0.26361435651779175
rl training, epoch9, iter0, batch320/1133, batch loss:0.26361435651779175, Training time:30481.98370075226
batch reward last col mean 0.13019385933876038 first col mean 0.10262688994407654 all mean 0.11875997483730316
0.3178800940513611 0.3178800940513611
rl training, epoch9, iter0, batch321/1133, batch loss:0.3178800940513611, Training time:30484.184368133545
batch reward last col mean 0.0799216628074646 first col mean 0.10654737055301666 all mean 0.08710583299398422
0.24561788141727448 0.24561788141727448
rl training, epoch9, iter0, batch322/1133, batch loss:0.24561788141727448, Training time:30486.094068288803
batch reward last col mean 0.11219444870948792 first col mean 0.10772132873535156 all mean 0.10681206732988358
0.2886342704296112 0.2886342704296112
rl training, epoch9, iter0, batch323/1133, batch loss:0.2886342704296112, Training time:30488.01610136032
batch reward last col mean 0.0709172785282135 first col mean 0.10563966631889343 all mean 0.08290461450815201
0.2794411778450012 0.2794411778450012
rl training, epoch9, iter0, batch324/1133, batch loss:0.2794411778450012, Training time:30490.25731444359
batch reward last col mean 0.14690051972866058 first col mean 0.11661547422409058 all mean 0.135186105966568
0.29999202489852905 0.29999202489852905
rl training, epoch9, iter0, batch325/1133, batch loss:0.29999202489852905, Training time:30492.457205057144
batch reward last col mean 0.08986058831214905 first col mean 0.09244409203529358 all mean 0.09444047510623932
0.25695475935935974 0.25695475935935974
rl training, epoch9, iter0, batch326/1133, batch loss:0.25695475935935974, Training time:30494.912756681442
batch reward last col mean 0.06852304190397263 first col mean 0.11076866090297699 all mean 0.0834248811006546
0.2720188796520233 0.2720188796520233
rl training, epoch9, iter0, batch327/1133, batch loss:0.2720188796520233, Training time:30496.723156690598
batch reward last col mean 0.14812959730625153 first col mean 0.10188880562782288 all mean 0.13420860469341278
0.297342985868454 0.29734301567077637
rl training, epoch9, iter0, batch328/1133, batch loss:0.29734301567077637, Training time:30499.05407357216
batch reward last col mean 0.11801236867904663 first col mean 0.10835181176662445 all mean 0.11589176952838898
0.3125860393047333 0.3125860393047333
rl training, epoch9, iter0, batch329/1133, batch loss:0.3125860393047333, Training time:30501.393268108368
batch reward last col mean 0.12199608236551285 first col mean 0.10982920974493027 all mean 0.11698848754167557
0.2701871693134308 0.2701871693134308
rl training, epoch9, iter0, batch330/1133, batch loss:0.2701871693134308, Training time:30504.462429761887
batch reward last col mean 0.07070604711771011 first col mean 0.10029500722885132 all mean 0.07524043321609497
0.24287866055965424 0.24287866055965424
rl training, epoch9, iter0, batch331/1133, batch loss:0.24287866055965424, Training time:30506.166172266006
batch reward last col mean 0.12397780269384384 first col mean 0.11645230650901794 all mean 0.11260326206684113
0.3063950836658478 0.3063950836658478
rl training, epoch9, iter0, batch332/1133, batch loss:0.3063950836658478, Training time:30508.295734405518
batch reward last col mean 0.11786623299121857 first col mean 0.124334417283535 all mean 0.11413371562957764
0.2683613896369934 0.2683613896369934
rl training, epoch9, iter0, batch333/1133, batch loss:0.2683613896369934, Training time:30510.826488494873
batch reward last col mean 0.07623675465583801 first col mean 0.10302352905273438 all mean 0.08768697082996368
0.2671096622943878 0.2671096622943878
rl training, epoch9, iter0, batch334/1133, batch loss:0.2671096622943878, Training time:30512.933042287827
batch reward last col mean 0.11490579694509506 first col mean 0.10562266409397125 all mean 0.10969014465808868
0.26331230998039246 0.26331230998039246
rl training, epoch9, iter0, batch335/1133, batch loss:0.26331230998039246, Training time:30515.17625927925
batch reward last col mean 0.09367615729570389 first col mean 0.09589440375566483 all mean 0.098725825548172
0.29103001952171326 0.29103001952171326
rl training, epoch9, iter0, batch336/1133, batch loss:0.29103001952171326, Training time:30517.114038467407
batch reward last col mean 0.08317513763904572 first col mean 0.09682710468769073 all mean 0.0853186622262001
0.25711584091186523 0.25711581110954285
rl training, epoch9, iter0, batch337/1133, batch loss:0.25711581110954285, Training time:30519.866229772568
batch reward last col mean 0.09956740587949753 first col mean 0.11388282477855682 all mean 0.10898078978061676
0.3001432418823242 0.3001432418823242
rl training, epoch9, iter0, batch338/1133, batch loss:0.3001432418823242, Training time:30521.645211696625
batch reward last col mean 0.0901031643152237 first col mean 0.1082506775856018 all mean 0.09654390811920166
0.29574209451675415 0.29574209451675415
rl training, epoch9, iter0, batch339/1133, batch loss:0.29574209451675415, Training time:30523.625428199768
batch reward last col mean 0.06546618789434433 first col mean 0.0861019715666771 all mean 0.06958350539207458
0.2586769759654999 0.2586769461631775
rl training, epoch9, iter0, batch340/1133, batch loss:0.2586769461631775, Training time:30525.780549287796
batch reward last col mean 0.07718891650438309 first col mean 0.09869693219661713 all mean 0.084015391767025
0.2473958283662796 0.2473958134651184
rl training, epoch9, iter0, batch341/1133, batch loss:0.2473958134651184, Training time:30527.38535642624
batch reward last col mean 0.10108650475740433 first col mean 0.09535904973745346 all mean 0.10237020999193192
0.2412741631269455 0.2412741631269455
rl training, epoch9, iter0, batch342/1133, batch loss:0.2412741631269455, Training time:30529.257434129715
batch reward last col mean 0.0955500453710556 first col mean 0.09070324897766113 all mean 0.09605662524700165
0.28117236495018005 0.28117236495018005
rl training, epoch9, iter0, batch343/1133, batch loss:0.28117236495018005, Training time:30531.43624687195
batch reward last col mean 0.1303061991930008 first col mean 0.10085656493902206 all mean 0.1225033700466156
0.30615127086639404 0.30615130066871643
rl training, epoch9, iter0, batch344/1133, batch loss:0.30615130066871643, Training time:30533.3623547554
batch reward last col mean 0.07309246808290482 first col mean 0.09651309251785278 all mean 0.07949734479188919
0.2116953283548355 0.21169529855251312
rl training, epoch9, iter0, batch345/1133, batch loss:0.21169529855251312, Training time:30535.23992085457
batch reward last col mean 0.0729525238275528 first col mean 0.09344597160816193 all mean 0.08211729675531387
0.2630259096622467 0.2630259096622467
rl training, epoch9, iter0, batch346/1133, batch loss:0.2630259096622467, Training time:30537.25457882881
batch reward last col mean 0.05968596413731575 first col mean 0.11656472831964493 all mean 0.07361416518688202
0.2364625632762909 0.2364625632762909
rl training, epoch9, iter0, batch347/1133, batch loss:0.2364625632762909, Training time:30539.493770122528
batch reward last col mean 0.09516160935163498 first col mean 0.10476779192686081 all mean 0.09638211876153946
0.25062301754951477 0.25062301754951477
rl training, epoch9, iter0, batch348/1133, batch loss:0.25062301754951477, Training time:30541.279179811478
batch reward last col mean 0.08652975410223007 first col mean 0.10817411541938782 all mean 0.0897168442606926
0.2356589287519455 0.2356589287519455
rl training, epoch9, iter0, batch349/1133, batch loss:0.2356589287519455, Training time:30543.729189395905
batch reward last col mean 0.11232204735279083 first col mean 0.11417829990386963 all mean 0.10817856341600418
0.2732188403606415 0.2732188403606415
rl training, epoch9, iter0, batch350/1133, batch loss:0.2732188403606415, Training time:30545.666097164154
batch reward last col mean 0.10881722718477249 first col mean 0.09888611733913422 all mean 0.10038662701845169
0.27540892362594604 0.27540892362594604
rl training, epoch9, iter0, batch351/1133, batch loss:0.27540892362594604, Training time:30547.419342041016
batch reward last col mean 0.09096870571374893 first col mean 0.10238923132419586 all mean 0.09611693024635315
0.30676335096359253 0.30676332116127014
rl training, epoch9, iter0, batch352/1133, batch loss:0.30676332116127014, Training time:30549.02409887314
batch reward last col mean 0.09731921553611755 first col mean 0.10690195113420486 all mean 0.09892129898071289
0.27583274245262146 0.27583274245262146
rl training, epoch9, iter0, batch353/1133, batch loss:0.27583274245262146, Training time:30550.987710237503
batch reward last col mean 0.11669522523880005 first col mean 0.1057228296995163 all mean 0.11039891093969345
0.26830238103866577 0.26830238103866577
rl training, epoch9, iter0, batch354/1133, batch loss:0.26830238103866577, Training time:30553.76552772522
batch reward last col mean 0.10602125525474548 first col mean 0.10986799001693726 all mean 0.10632351785898209
0.2993745803833008 0.2993745803833008
rl training, epoch9, iter0, batch355/1133, batch loss:0.2993745803833008, Training time:30556.2166223526
batch reward last col mean 0.09830082952976227 first col mean 0.11697930842638016 all mean 0.10222606360912323
0.3271186053752899 0.32711857557296753
rl training, epoch9, iter0, batch356/1133, batch loss:0.32711857557296753, Training time:30558.538116455078
batch reward last col mean 0.10288028419017792 first col mean 0.11234091222286224 all mean 0.1025705337524414
0.2523791790008545 0.2523791790008545
rl training, epoch9, iter0, batch357/1133, batch loss:0.2523791790008545, Training time:30560.482736587524
batch reward last col mean 0.0920531302690506 first col mean 0.10540296137332916 all mean 0.0949849858880043
0.2833273112773895 0.28332728147506714
rl training, epoch9, iter0, batch358/1133, batch loss:0.28332728147506714, Training time:30562.673691272736
batch reward last col mean 0.10792381316423416 first col mean 0.10523982346057892 all mean 0.10668542981147766
0.2901109755039215 0.2901109755039215
rl training, epoch9, iter0, batch359/1133, batch loss:0.2901109755039215, Training time:30565.153327703476
batch reward last col mean 0.09574097394943237 first col mean 0.09758149087429047 all mean 0.095985047519207
0.2773674726486206 0.2773674428462982
rl training, epoch9, iter0, batch360/1133, batch loss:0.2773674428462982, Training time:30567.18069267273
batch reward last col mean 0.11682438105344772 first col mean 0.10363273322582245 all mean 0.11270294338464737
0.2565948963165283 0.2565948963165283
rl training, epoch9, iter0, batch361/1133, batch loss:0.2565948963165283, Training time:30570.290373325348
batch reward last col mean 0.06207481771707535 first col mean 0.08953368663787842 all mean 0.0760796070098877
0.24791476130485535 0.24791476130485535
rl training, epoch9, iter0, batch362/1133, batch loss:0.24791476130485535, Training time:30571.987204790115
batch reward last col mean 0.09879457950592041 first col mean 0.11816665530204773 all mean 0.10096211731433868
0.26612263917922974 0.26612263917922974
rl training, epoch9, iter0, batch363/1133, batch loss:0.26612263917922974, Training time:30574.07830452919
batch reward last col mean 0.10236643254756927 first col mean 0.09885834157466888 all mean 0.10388411581516266
0.2596973776817322 0.2596973776817322
rl training, epoch9, iter0, batch364/1133, batch loss:0.2596973776817322, Training time:30575.839012384415
batch reward last col mean 0.09623795002698898 first col mean 0.10528721660375595 all mean 0.0964200347661972
0.24513386189937592 0.24513386189937592
rl training, epoch9, iter0, batch365/1133, batch loss:0.24513386189937592, Training time:30578.368826150894
batch reward last col mean 0.08888769149780273 first col mean 0.12784847617149353 all mean 0.09751836210489273
0.3035653233528137 0.3035653233528137
rl training, epoch9, iter0, batch366/1133, batch loss:0.3035653233528137, Training time:30580.09901690483
batch reward last col mean 0.09095797687768936 first col mean 0.11455310881137848 all mean 0.09588301181793213
0.25288161635398865 0.25288158655166626
rl training, epoch9, iter0, batch367/1133, batch loss:0.25288158655166626, Training time:30581.81046772003
batch reward last col mean 0.08652423322200775 first col mean 0.10287085175514221 all mean 0.09005627781152725
0.23345786333084106 0.23345786333084106
rl training, epoch9, iter0, batch368/1133, batch loss:0.23345786333084106, Training time:30583.709793806076
batch reward last col mean 0.08758670091629028 first col mean 0.12023676186800003 all mean 0.09455615282058716
0.2439219206571579 0.2439219206571579
rl training, epoch9, iter0, batch369/1133, batch loss:0.2439219206571579, Training time:30585.52234005928
batch reward last col mean 0.07484328746795654 first col mean 0.09499047696590424 all mean 0.08361602574586868
0.26046374440193176 0.26046374440193176
rl training, epoch9, iter0, batch370/1133, batch loss:0.26046374440193176, Training time:30587.524457216263
batch reward last col mean 0.11064199358224869 first col mean 0.105150505900383 all mean 0.11229246109724045
0.2768322825431824 0.2768322825431824
rl training, epoch9, iter0, batch371/1133, batch loss:0.2768322825431824, Training time:30589.92063307762
batch reward last col mean 0.10460061579942703 first col mean 0.08918634802103043 all mean 0.1020098477602005
0.28450149297714233 0.28450149297714233
rl training, epoch9, iter0, batch372/1133, batch loss:0.28450149297714233, Training time:30591.7627491951
batch reward last col mean 0.13423939049243927 first col mean 0.09279059618711472 all mean 0.1298101842403412
0.3432565927505493 0.3432565927505493
rl training, epoch9, iter0, batch373/1133, batch loss:0.3432565927505493, Training time:30593.48059272766
batch reward last col mean 0.08106821775436401 first col mean 0.1195542961359024 all mean 0.08919503539800644
0.24594786763191223 0.24594786763191223
rl training, epoch9, iter0, batch374/1133, batch loss:0.24594786763191223, Training time:30595.435729026794
batch reward last col mean 0.08614594489336014 first col mean 0.0998789519071579 all mean 0.0896216407418251
0.2695520222187042 0.2695520520210266
rl training, epoch9, iter0, batch375/1133, batch loss:0.2695520520210266, Training time:30597.2041618824
batch reward last col mean 0.09518598765134811 first col mean 0.10619328916072845 all mean 0.09934541583061218
0.2632428705692291 0.2632428705692291
rl training, epoch9, iter0, batch376/1133, batch loss:0.2632428705692291, Training time:30599.2134308815
batch reward last col mean 0.09902991354465485 first col mean 0.09661564975976944 all mean 0.0990259125828743
0.27630627155303955 0.27630627155303955
rl training, epoch9, iter0, batch377/1133, batch loss:0.27630627155303955, Training time:30600.97327232361
batch reward last col mean 0.12444302439689636 first col mean 0.12021246552467346 all mean 0.1205105111002922
0.2893420159816742 0.2893420159816742
rl training, epoch9, iter0, batch378/1133, batch loss:0.2893420159816742, Training time:30602.709804296494
batch reward last col mean 0.09849101305007935 first col mean 0.1132255494594574 all mean 0.09981200098991394
0.286360502243042 0.286360502243042
rl training, epoch9, iter0, batch379/1133, batch loss:0.286360502243042, Training time:30604.706084012985
batch reward last col mean 0.10062218457460403 first col mean 0.10051607340574265 all mean 0.1076183095574379
0.28797051310539246 0.28797051310539246
rl training, epoch9, iter0, batch380/1133, batch loss:0.28797051310539246, Training time:30606.507556915283
batch reward last col mean 0.09678298234939575 first col mean 0.10928159952163696 all mean 0.09947437793016434
0.28086113929748535 0.28086113929748535
rl training, epoch9, iter0, batch381/1133, batch loss:0.28086113929748535, Training time:30608.74478340149
batch reward last col mean 0.08149039000272751 first col mean 0.09366142749786377 all mean 0.0852578654885292
0.27207812666893005 0.27207812666893005
rl training, epoch9, iter0, batch382/1133, batch loss:0.27207812666893005, Training time:30610.567479372025
batch reward last col mean 0.0627068430185318 first col mean 0.0923016145825386 all mean 0.07000487297773361
0.21579653024673462 0.21579653024673462
rl training, epoch9, iter0, batch383/1133, batch loss:0.21579653024673462, Training time:30612.931641101837
batch reward last col mean 0.07826599478721619 first col mean 0.1156267523765564 all mean 0.08812891691923141
0.25477334856987 0.25477334856987
rl training, epoch9, iter0, batch384/1133, batch loss:0.25477334856987, Training time:30615.524434566498
batch reward last col mean 0.10695096850395203 first col mean 0.09532959014177322 all mean 0.09644531458616257
0.27042385935783386 0.27042388916015625
rl training, epoch9, iter0, batch385/1133, batch loss:0.27042388916015625, Training time:30617.350325345993
batch reward last col mean 0.09185215830802917 first col mean 0.10751134157180786 all mean 0.09536807239055634
0.2710425853729248 0.2710426151752472
rl training, epoch9, iter0, batch386/1133, batch loss:0.2710426151752472, Training time:30619.848690986633
batch reward last col mean 0.12382420152425766 first col mean 0.11096726357936859 all mean 0.11744596809148788
0.2711013853549957 0.27110135555267334
rl training, epoch9, iter0, batch387/1133, batch loss:0.27110135555267334, Training time:30621.699963092804
batch reward last col mean 0.0651349127292633 first col mean 0.10752260684967041 all mean 0.07943905889987946
0.24174226820468903 0.2417422980070114
rl training, epoch9, iter0, batch388/1133, batch loss:0.2417422980070114, Training time:30623.143604040146
batch reward last col mean 0.08063933998346329 first col mean 0.09726709127426147 all mean 0.087550587952137
0.2592385411262512 0.2592385411262512
rl training, epoch9, iter0, batch389/1133, batch loss:0.2592385411262512, Training time:30624.93043231964
batch reward last col mean 0.07926701009273529 first col mean 0.08256741613149643 all mean 0.08447819203138351
0.271039217710495 0.271039217710495
rl training, epoch9, iter0, batch390/1133, batch loss:0.271039217710495, Training time:30626.99724459648
batch reward last col mean 0.10104550421237946 first col mean 0.10578297823667526 all mean 0.09620359539985657
0.2822258174419403 0.2822258174419403
rl training, epoch9, iter0, batch391/1133, batch loss:0.2822258174419403, Training time:30629.103754281998
batch reward last col mean 0.09378819167613983 first col mean 0.0898175984621048 all mean 0.09396582841873169
0.2633395791053772 0.2633395493030548
rl training, epoch9, iter0, batch392/1133, batch loss:0.2633395493030548, Training time:30630.86058330536
batch reward last col mean 0.08751234412193298 first col mean 0.10247085988521576 all mean 0.09044849127531052
0.24732361733913422 0.24732360243797302
rl training, epoch9, iter0, batch393/1133, batch loss:0.24732360243797302, Training time:30633.010570526123
batch reward last col mean 0.10582880675792694 first col mean 0.10577133297920227 all mean 0.1026078462600708
0.2865664064884186 0.2865664064884186
rl training, epoch9, iter0, batch394/1133, batch loss:0.2865664064884186, Training time:30635.19635629654
batch reward last col mean 0.1327224224805832 first col mean 0.10203242301940918 all mean 0.1167781725525856
0.277055025100708 0.277055025100708
rl training, epoch9, iter0, batch395/1133, batch loss:0.277055025100708, Training time:30637.36981654167
batch reward last col mean 0.1263405680656433 first col mean 0.10498011112213135 all mean 0.12491929531097412
0.303762823343277 0.303762823343277
rl training, epoch9, iter0, batch396/1133, batch loss:0.303762823343277, Training time:30639.299582481384
batch reward last col mean 0.08205818384885788 first col mean 0.0971275046467781 all mean 0.09224763512611389
0.2791979908943176 0.27919796109199524
rl training, epoch9, iter0, batch397/1133, batch loss:0.27919796109199524, Training time:30640.82437634468
batch reward last col mean 0.06882036477327347 first col mean 0.11962155252695084 all mean 0.07463992387056351
0.2188299596309662 0.2188299596309662
rl training, epoch9, iter0, batch398/1133, batch loss:0.2188299596309662, Training time:30644.131287813187
batch reward last col mean 0.12407048046588898 first col mean 0.1300525814294815 all mean 0.11814022064208984
0.2977514863014221 0.2977514863014221
rl training, epoch9, iter0, batch399/1133, batch loss:0.2977514863014221, Training time:30646.64189171791
_____train D during RL_____
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4533287693942845 Time: 97.29750514030457 s
loss of true 0.1944528849432138 loss of gen 0.16611882896283403 loss of other 0.09275705607021055 first score 0.07913820445537567
batch reward last col mean 0.06762655079364777 first col mean 0.09338974952697754 all mean 0.07675858587026596
0.24550053477287292 0.24550053477287292
rl training, epoch9, iter0, batch400/1133, batch loss:0.24550053477287292, Training time:30746.27606534958
batch reward last col mean 0.0699654370546341 first col mean 0.1032787412405014 all mean 0.07711837440729141
0.2218511998653412 0.2218511998653412
rl training, epoch9, iter0, batch401/1133, batch loss:0.2218511998653412, Training time:30747.930282115936
batch reward last col mean 0.1311561018228531 first col mean 0.09767354279756546 all mean 0.12201666086912155
0.2810571789741516 0.2810571789741516
rl training, epoch9, iter0, batch402/1133, batch loss:0.2810571789741516, Training time:30750.299162626266
batch reward last col mean 0.07810524106025696 first col mean 0.10855850577354431 all mean 0.09376052767038345
0.2911367416381836 0.2911367416381836
rl training, epoch9, iter0, batch403/1133, batch loss:0.2911367416381836, Training time:30751.787942409515
batch reward last col mean 0.1038879007101059 first col mean 0.09183938801288605 all mean 0.10768990218639374
0.2791721224784851 0.2791721522808075
rl training, epoch9, iter0, batch404/1133, batch loss:0.2791721522808075, Training time:30754.040905952454
batch reward last col mean 0.09994150698184967 first col mean 0.09870623052120209 all mean 0.0976121798157692
0.2439533919095993 0.2439533919095993
rl training, epoch9, iter0, batch405/1133, batch loss:0.2439533919095993, Training time:30756.14252305031
batch reward last col mean 0.07726000249385834 first col mean 0.10666517913341522 all mean 0.08630813658237457
0.2355092465877533 0.2355092465877533
rl training, epoch9, iter0, batch406/1133, batch loss:0.2355092465877533, Training time:30757.804674863815
batch reward last col mean 0.11896611750125885 first col mean 0.10426848381757736 all mean 0.11201781034469604
0.2635003626346588 0.2635003626346588
rl training, epoch9, iter0, batch407/1133, batch loss:0.2635003626346588, Training time:30759.774421215057
batch reward last col mean 0.09972269833087921 first col mean 0.10236761718988419 all mean 0.09731479734182358
0.27207881212234497 0.27207881212234497
rl training, epoch9, iter0, batch408/1133, batch loss:0.27207881212234497, Training time:30761.73694205284
batch reward last col mean 0.07771746814250946 first col mean 0.09063228964805603 all mean 0.08400332927703857
0.24616292119026184 0.24616292119026184
rl training, epoch9, iter0, batch409/1133, batch loss:0.24616292119026184, Training time:30763.414835214615
batch reward last col mean 0.10848833620548248 first col mean 0.08392155170440674 all mean 0.10864025354385376
0.26255226135253906 0.26255226135253906
rl training, epoch9, iter0, batch410/1133, batch loss:0.26255226135253906, Training time:30765.13416314125
batch reward last col mean 0.0853201225399971 first col mean 0.10528441518545151 all mean 0.08936399221420288
0.23707540333271027 0.23707540333271027
rl training, epoch9, iter0, batch411/1133, batch loss:0.23707540333271027, Training time:30767.690661907196
batch reward last col mean 0.11394701153039932 first col mean 0.1137031763792038 all mean 0.10718675702810287
0.27428993582725525 0.27428993582725525
rl training, epoch9, iter0, batch412/1133, batch loss:0.27428993582725525, Training time:30770.63453221321
batch reward last col mean 0.08028613775968552 first col mean 0.0958082303404808 all mean 0.08735592663288116
0.2553666830062866 0.2553666830062866
rl training, epoch9, iter0, batch413/1133, batch loss:0.2553666830062866, Training time:30772.461035251617
batch reward last col mean 0.10540956258773804 first col mean 0.10368065536022186 all mean 0.09929846227169037
0.24236832559108734 0.24236832559108734
rl training, epoch9, iter0, batch414/1133, batch loss:0.24236832559108734, Training time:30774.334485292435
batch reward last col mean 0.08538079261779785 first col mean 0.11319675296545029 all mean 0.08595186471939087
0.24857336282730103 0.24857336282730103
rl training, epoch9, iter0, batch415/1133, batch loss:0.24857336282730103, Training time:30776.558041095734
batch reward last col mean 0.1024772971868515 first col mean 0.0912853479385376 all mean 0.1095246821641922
0.3140310049057007 0.3140310049057007
rl training, epoch9, iter0, batch416/1133, batch loss:0.3140310049057007, Training time:30778.42359638214
batch reward last col mean 0.09968869388103485 first col mean 0.10378114879131317 all mean 0.09685035794973373
0.2696278393268585 0.2696278393268585
rl training, epoch9, iter0, batch417/1133, batch loss:0.2696278393268585, Training time:30780.71270418167
batch reward last col mean 0.12126635015010834 first col mean 0.10675380378961563 all mean 0.11437530815601349
0.2919667363166809 0.2919667363166809
rl training, epoch9, iter0, batch418/1133, batch loss:0.2919667363166809, Training time:30782.587579488754
batch reward last col mean 0.09772618860006332 first col mean 0.09317982196807861 all mean 0.103508360683918
0.31044527888298035 0.31044527888298035
rl training, epoch9, iter0, batch419/1133, batch loss:0.31044527888298035, Training time:30785.11103463173
batch reward last col mean 0.07714937627315521 first col mean 0.1064351424574852 all mean 0.08664017170667648
0.2506483793258667 0.2506484091281891
rl training, epoch9, iter0, batch420/1133, batch loss:0.2506484091281891, Training time:30787.078804254532
batch reward last col mean 0.08487159013748169 first col mean 0.10498086363077164 all mean 0.09310062229633331
0.2591255009174347 0.2591255009174347
rl training, epoch9, iter0, batch421/1133, batch loss:0.2591255009174347, Training time:30788.97162628174
batch reward last col mean 0.09389463067054749 first col mean 0.09706370532512665 all mean 0.0993482917547226
0.258846253156662 0.2588462233543396
rl training, epoch9, iter0, batch422/1133, batch loss:0.2588462233543396, Training time:30791.151727199554
batch reward last col mean 0.10207359492778778 first col mean 0.0989060252904892 all mean 0.10055699944496155
0.2929733097553253 0.2929733097553253
rl training, epoch9, iter0, batch423/1133, batch loss:0.2929733097553253, Training time:30792.76294708252
batch reward last col mean 0.0969114601612091 first col mean 0.10203632712364197 all mean 0.09539978206157684
0.2543277144432068 0.2543277442455292
rl training, epoch9, iter0, batch424/1133, batch loss:0.2543277442455292, Training time:30795.320798158646
batch reward last col mean 0.07422858476638794 first col mean 0.09451167285442352 all mean 0.08250663429498672
0.25765496492385864 0.25765496492385864
rl training, epoch9, iter0, batch425/1133, batch loss:0.25765496492385864, Training time:30797.00909471512
batch reward last col mean 0.10960051417350769 first col mean 0.10431607067584991 all mean 0.10585062950849533
0.2973851263523102 0.2973851263523102
rl training, epoch9, iter0, batch426/1133, batch loss:0.2973851263523102, Training time:30798.8284804821
batch reward last col mean 0.12672871351242065 first col mean 0.09904811531305313 all mean 0.11849747598171234
0.3237897753715515 0.3237897753715515
rl training, epoch9, iter0, batch427/1133, batch loss:0.3237897753715515, Training time:30800.62660741806
batch reward last col mean 0.08198787271976471 first col mean 0.10488857328891754 all mean 0.09052214026451111
0.28150463104248047 0.28150463104248047
rl training, epoch9, iter0, batch428/1133, batch loss:0.28150463104248047, Training time:30802.759856700897
batch reward last col mean 0.07358653843402863 first col mean 0.11586087942123413 all mean 0.0850287452340126
0.23131710290908813 0.23131707310676575
rl training, epoch9, iter0, batch429/1133, batch loss:0.23131707310676575, Training time:30805.29771876335
batch reward last col mean 0.085593082010746 first col mean 0.11094281822443008 all mean 0.09170561283826828
0.2588173449039459 0.2588173449039459
rl training, epoch9, iter0, batch430/1133, batch loss:0.2588173449039459, Training time:30807.037504673004
batch reward last col mean 0.08360937982797623 first col mean 0.09777204692363739 all mean 0.09133704751729965
0.2516743540763855 0.2516743540763855
rl training, epoch9, iter0, batch431/1133, batch loss:0.2516743540763855, Training time:30809.268174171448
batch reward last col mean 0.11579523980617523 first col mean 0.10906357318162918 all mean 0.11386752873659134
0.3035110533237457 0.3035110533237457
rl training, epoch9, iter0, batch432/1133, batch loss:0.3035110533237457, Training time:30811.27374100685
batch reward last col mean 0.07069884240627289 first col mean 0.10510879755020142 all mean 0.08165678381919861
0.25245556235313416 0.25245556235313416
rl training, epoch9, iter0, batch433/1133, batch loss:0.25245556235313416, Training time:30813.429958343506
batch reward last col mean 0.0874951034784317 first col mean 0.10538674890995026 all mean 0.09144384413957596
0.27109459042549133 0.27109459042549133
rl training, epoch9, iter0, batch434/1133, batch loss:0.27109459042549133, Training time:30815.644613027573
batch reward last col mean 0.10528305172920227 first col mean 0.08668622374534607 all mean 0.1028829887509346
0.25260987877845764 0.25260987877845764
rl training, epoch9, iter0, batch435/1133, batch loss:0.25260987877845764, Training time:30817.877325296402
batch reward last col mean 0.11069376766681671 first col mean 0.11128286272287369 all mean 0.10834571719169617
0.30623766779899597 0.30623766779899597
rl training, epoch9, iter0, batch436/1133, batch loss:0.30623766779899597, Training time:30820.348755836487
batch reward last col mean 0.08286825567483902 first col mean 0.09460875391960144 all mean 0.08670784533023834
0.24041789770126343 0.24041791260242462
rl training, epoch9, iter0, batch437/1133, batch loss:0.24041791260242462, Training time:30822.07189822197
batch reward last col mean 0.10146007686853409 first col mean 0.09462803602218628 all mean 0.10475089401006699
0.31725093722343445 0.31725093722343445
rl training, epoch9, iter0, batch438/1133, batch loss:0.31725093722343445, Training time:30824.04075360298
batch reward last col mean 0.0883139967918396 first col mean 0.09370800852775574 all mean 0.0947732925415039
0.25315457582473755 0.25315457582473755
rl training, epoch9, iter0, batch439/1133, batch loss:0.25315457582473755, Training time:30826.50483751297
batch reward last col mean 0.10793845355510712 first col mean 0.1011323481798172 all mean 0.11132389307022095
0.3120933473110199 0.3120933473110199
rl training, epoch9, iter0, batch440/1133, batch loss:0.3120933473110199, Training time:30828.325571775436
batch reward last col mean 0.06698285043239594 first col mean 0.09781249612569809 all mean 0.07754741609096527
0.2671642005443573 0.2671642005443573
rl training, epoch9, iter0, batch441/1133, batch loss:0.2671642005443573, Training time:30830.486664056778
batch reward last col mean 0.10218369960784912 first col mean 0.10147450119256973 all mean 0.10347678512334824
0.2598707675933838 0.2598707675933838
rl training, epoch9, iter0, batch442/1133, batch loss:0.2598707675933838, Training time:30834.389605998993
batch reward last col mean 0.1317545473575592 first col mean 0.1086101159453392 all mean 0.11954647302627563
0.2864634692668915 0.2864634692668915
rl training, epoch9, iter0, batch443/1133, batch loss:0.2864634692668915, Training time:30836.564908981323
batch reward last col mean 0.09671172499656677 first col mean 0.09755461663007736 all mean 0.10129496455192566
0.295737087726593 0.29573705792427063
rl training, epoch9, iter0, batch444/1133, batch loss:0.29573705792427063, Training time:30838.617587327957
batch reward last col mean 0.12329056113958359 first col mean 0.10785721242427826 all mean 0.11907460540533066
0.2843746244907379 0.2843746244907379
rl training, epoch9, iter0, batch445/1133, batch loss:0.2843746244907379, Training time:30841.384999752045
batch reward last col mean 0.10047057271003723 first col mean 0.10641121119260788 all mean 0.10923269391059875
0.27490848302841187 0.27490848302841187
rl training, epoch9, iter0, batch446/1133, batch loss:0.27490848302841187, Training time:30843.22159433365
batch reward last col mean 0.0926954597234726 first col mean 0.09937943518161774 all mean 0.09785476326942444
0.23894251883029938 0.23894253373146057
rl training, epoch9, iter0, batch447/1133, batch loss:0.23894253373146057, Training time:30845.518414974213
batch reward last col mean 0.15002433955669403 first col mean 0.09615835547447205 all mean 0.1358713060617447
0.2733927071094513 0.2733927369117737
rl training, epoch9, iter0, batch448/1133, batch loss:0.2733927369117737, Training time:30847.7054874897
batch reward last col mean 0.10875555872917175 first col mean 0.08494813740253448 all mean 0.10178826749324799
0.28595170378685 0.28595170378685
rl training, epoch9, iter0, batch449/1133, batch loss:0.28595170378685, Training time:30850.2375562191
batch reward last col mean 0.09151630103588104 first col mean 0.0911177396774292 all mean 0.0936393141746521
0.27257347106933594 0.27257344126701355
rl training, epoch9, iter0, batch450/1133, batch loss:0.27257344126701355, Training time:30852.252497673035
batch reward last col mean 0.11117108166217804 first col mean 0.12386532872915268 all mean 0.10787247121334076
0.28864747285842896 0.28864747285842896
rl training, epoch9, iter0, batch451/1133, batch loss:0.28864747285842896, Training time:30854.200108528137
batch reward last col mean 0.10144595056772232 first col mean 0.1043718159198761 all mean 0.10524716973304749
0.268733412027359 0.268733412027359
rl training, epoch9, iter0, batch452/1133, batch loss:0.268733412027359, Training time:30855.916160821915
batch reward last col mean 0.10011394321918488 first col mean 0.12572693824768066 all mean 0.10112147033214569
0.23044833540916443 0.23044832050800323
rl training, epoch9, iter0, batch453/1133, batch loss:0.23044832050800323, Training time:30858.13693189621
batch reward last col mean 0.09727161377668381 first col mean 0.10198062658309937 all mean 0.10632247477769852
0.2623369097709656 0.2623369097709656
rl training, epoch9, iter0, batch454/1133, batch loss:0.2623369097709656, Training time:30860.04700112343
batch reward last col mean 0.10158651322126389 first col mean 0.0919145941734314 all mean 0.10548660904169083
0.31211355328559875 0.31211355328559875
rl training, epoch9, iter0, batch455/1133, batch loss:0.31211355328559875, Training time:30861.886439085007
batch reward last col mean 0.1127459704875946 first col mean 0.10602548718452454 all mean 0.11033155024051666
0.2619539499282837 0.2619539499282837
rl training, epoch9, iter0, batch456/1133, batch loss:0.2619539499282837, Training time:30863.564784765244
batch reward last col mean 0.0906563401222229 first col mean 0.10437460243701935 all mean 0.09020756185054779
0.27165699005126953 0.27165699005126953
rl training, epoch9, iter0, batch457/1133, batch loss:0.27165699005126953, Training time:30865.672865390778
batch reward last col mean 0.12167685478925705 first col mean 0.10725708305835724 all mean 0.11744009703397751
0.2739333212375641 0.2739333212375641
rl training, epoch9, iter0, batch458/1133, batch loss:0.2739333212375641, Training time:30868.355738401413
batch reward last col mean 0.07062406837940216 first col mean 0.09581805765628815 all mean 0.07817333191633224
0.22748637199401855 0.22748637199401855
rl training, epoch9, iter0, batch459/1133, batch loss:0.22748637199401855, Training time:30870.419941663742
batch reward last col mean 0.10887394100427628 first col mean 0.10640647262334824 all mean 0.10905016958713531
0.2737501859664917 0.2737501859664917
rl training, epoch9, iter0, batch460/1133, batch loss:0.2737501859664917, Training time:30872.24915122986
batch reward last col mean 0.10016731917858124 first col mean 0.1168232262134552 all mean 0.10392194986343384
0.2855212986469269 0.2855212986469269
rl training, epoch9, iter0, batch461/1133, batch loss:0.2855212986469269, Training time:30874.824979543686
batch reward last col mean 0.11781582236289978 first col mean 0.11459812521934509 all mean 0.11872374266386032
0.2753603756427765 0.2753604054450989
rl training, epoch9, iter0, batch462/1133, batch loss:0.2753604054450989, Training time:30877.21887779236
batch reward last col mean 0.15188844501972198 first col mean 0.1257089376449585 all mean 0.1360102742910385
0.2746012210845947 0.2746012210845947
rl training, epoch9, iter0, batch463/1133, batch loss:0.2746012210845947, Training time:30878.808360099792
batch reward last col mean 0.1026974469423294 first col mean 0.09401315450668335 all mean 0.09585180133581161
0.27275776863098145 0.27275776863098145
rl training, epoch9, iter0, batch464/1133, batch loss:0.27275776863098145, Training time:30880.66188597679
batch reward last col mean 0.10133306682109833 first col mean 0.09503458440303802 all mean 0.10748055577278137
0.32473471760749817 0.32473471760749817
rl training, epoch9, iter0, batch465/1133, batch loss:0.32473471760749817, Training time:30883.11253809929
batch reward last col mean 0.12566646933555603 first col mean 0.11932327598333359 all mean 0.12356112897396088
0.3384198248386383 0.3384198248386383
rl training, epoch9, iter0, batch466/1133, batch loss:0.3384198248386383, Training time:30885.16577410698
batch reward last col mean 0.10709702968597412 first col mean 0.10795049369335175 all mean 0.10944832861423492
0.3019869923591614 0.3019869923591614
rl training, epoch9, iter0, batch467/1133, batch loss:0.3019869923591614, Training time:30887.317073345184
batch reward last col mean 0.11267932504415512 first col mean 0.10337679088115692 all mean 0.10680627077817917
0.2568058669567108 0.2568058669567108
rl training, epoch9, iter0, batch468/1133, batch loss:0.2568058669567108, Training time:30889.656178236008
batch reward last col mean 0.059942860156297684 first col mean 0.0933445394039154 all mean 0.07250705361366272
0.22707855701446533 0.22707855701446533
rl training, epoch9, iter0, batch469/1133, batch loss:0.22707855701446533, Training time:30891.64133167267
batch reward last col mean 0.07260555773973465 first col mean 0.10397493839263916 all mean 0.08160029351711273
0.2468026578426361 0.2468026578426361
rl training, epoch9, iter0, batch470/1133, batch loss:0.2468026578426361, Training time:30893.658429145813
batch reward last col mean 0.08149964362382889 first col mean 0.10844999551773071 all mean 0.09148569405078888
0.33275410532951355 0.33275407552719116
rl training, epoch9, iter0, batch471/1133, batch loss:0.33275407552719116, Training time:30895.981503486633
batch reward last col mean 0.09978037327528 first col mean 0.11238348484039307 all mean 0.10217759013175964
0.25018489360809326 0.25018489360809326
rl training, epoch9, iter0, batch472/1133, batch loss:0.25018489360809326, Training time:30898.432421922684
batch reward last col mean 0.10798036307096481 first col mean 0.11745954304933548 all mean 0.10701801627874374
0.30615341663360596 0.30615341663360596
rl training, epoch9, iter0, batch473/1133, batch loss:0.30615341663360596, Training time:30901.181733608246
batch reward last col mean 0.06674131751060486 first col mean 0.10830600559711456 all mean 0.07970978319644928
0.26073944568634033 0.26073944568634033
rl training, epoch9, iter0, batch474/1133, batch loss:0.26073944568634033, Training time:30903.147493600845
batch reward last col mean 0.12268007546663284 first col mean 0.09412059187889099 all mean 0.11546695232391357
0.27198484539985657 0.27198484539985657
rl training, epoch9, iter0, batch475/1133, batch loss:0.27198484539985657, Training time:30905.176411628723
batch reward last col mean 0.1092665046453476 first col mean 0.11423279345035553 all mean 0.1110161766409874
0.306511789560318 0.306511789560318
rl training, epoch9, iter0, batch476/1133, batch loss:0.306511789560318, Training time:30907.615788459778
batch reward last col mean 0.11668034642934799 first col mean 0.09647081792354584 all mean 0.11822208762168884
0.30489176511764526 0.30489176511764526
rl training, epoch9, iter0, batch477/1133, batch loss:0.30489176511764526, Training time:30909.43104147911
batch reward last col mean 0.09535135328769684 first col mean 0.0968264788389206 all mean 0.09469285607337952
0.26155856251716614 0.26155856251716614
rl training, epoch9, iter0, batch478/1133, batch loss:0.26155856251716614, Training time:30911.467987537384
batch reward last col mean 0.12941190600395203 first col mean 0.10224291682243347 all mean 0.1192486509680748
0.28655311465263367 0.28655311465263367
rl training, epoch9, iter0, batch479/1133, batch loss:0.28655311465263367, Training time:30913.344861745834
batch reward last col mean 0.14458231627941132 first col mean 0.09980269521474838 all mean 0.13250386714935303
0.25776374340057373 0.25776374340057373
rl training, epoch9, iter0, batch480/1133, batch loss:0.25776374340057373, Training time:30915.997376680374
batch reward last col mean 0.10781141370534897 first col mean 0.10678747296333313 all mean 0.11149201542139053
0.280877947807312 0.280877947807312
rl training, epoch9, iter0, batch481/1133, batch loss:0.280877947807312, Training time:30918.888541460037
batch reward last col mean 0.10108784586191177 first col mean 0.09886704385280609 all mean 0.0940520316362381
0.24141329526901245 0.24141329526901245
rl training, epoch9, iter0, batch482/1133, batch loss:0.24141329526901245, Training time:30921.374648094177
batch reward last col mean 0.1176929771900177 first col mean 0.11553323268890381 all mean 0.1076628714799881
0.2968069612979889 0.2968069612979889
rl training, epoch9, iter0, batch483/1133, batch loss:0.2968069612979889, Training time:30923.229220867157
batch reward last col mean 0.11288322508335114 first col mean 0.11309093236923218 all mean 0.10795990377664566
0.30275243520736694 0.30275243520736694
rl training, epoch9, iter0, batch484/1133, batch loss:0.30275243520736694, Training time:30925.152010679245
batch reward last col mean 0.13310527801513672 first col mean 0.11966565996408463 all mean 0.12084357440471649
0.3426525294780731 0.3426525890827179
rl training, epoch9, iter0, batch485/1133, batch loss:0.3426525890827179, Training time:30927.354870796204
batch reward last col mean 0.0979795902967453 first col mean 0.10667500644922256 all mean 0.10382655262947083
0.2813781797885895 0.2813781797885895
rl training, epoch9, iter0, batch486/1133, batch loss:0.2813781797885895, Training time:30929.20664548874
batch reward last col mean 0.1296214908361435 first col mean 0.11849227547645569 all mean 0.12135471403598785
0.2774057388305664 0.2774057388305664
rl training, epoch9, iter0, batch487/1133, batch loss:0.2774057388305664, Training time:30930.983625411987
batch reward last col mean 0.08833278715610504 first col mean 0.10358092188835144 all mean 0.0927029550075531
0.2576979100704193 0.2576979100704193
rl training, epoch9, iter0, batch488/1133, batch loss:0.2576979100704193, Training time:30933.127675771713
batch reward last col mean 0.09539583325386047 first col mean 0.10131019353866577 all mean 0.09655001014471054
0.2835506498813629 0.2835506498813629
rl training, epoch9, iter0, batch489/1133, batch loss:0.2835506498813629, Training time:30936.41363310814
batch reward last col mean 0.10284513980150223 first col mean 0.1108667179942131 all mean 0.09945721924304962
0.28091055154800415 0.28091055154800415
rl training, epoch9, iter0, batch490/1133, batch loss:0.28091055154800415, Training time:30938.99089360237
batch reward last col mean 0.09660167992115021 first col mean 0.10265011340379715 all mean 0.09484206140041351
0.2767002284526825 0.2767002284526825
rl training, epoch9, iter0, batch491/1133, batch loss:0.2767002284526825, Training time:30941.088661670685
batch reward last col mean 0.12149262428283691 first col mean 0.09865646809339523 all mean 0.11937766522169113
0.29769307374954224 0.2976931035518646
rl training, epoch9, iter0, batch492/1133, batch loss:0.2976931035518646, Training time:30943.041435480118
batch reward last col mean 0.13368508219718933 first col mean 0.10653261840343475 all mean 0.1306656450033188
0.3107871413230896 0.3107871413230896
rl training, epoch9, iter0, batch493/1133, batch loss:0.3107871413230896, Training time:30945.362437725067
batch reward last col mean 0.11450160294771194 first col mean 0.10110115259885788 all mean 0.11319600045681
0.27666205167770386 0.27666205167770386
rl training, epoch9, iter0, batch494/1133, batch loss:0.27666205167770386, Training time:30947.749457359314
batch reward last col mean 0.0937606692314148 first col mean 0.10499972105026245 all mean 0.09311608970165253
0.23281846940517426 0.23281846940517426
rl training, epoch9, iter0, batch495/1133, batch loss:0.23281846940517426, Training time:30949.61786723137
batch reward last col mean 0.08085574209690094 first col mean 0.12022922933101654 all mean 0.08826473355293274
0.28305551409721375 0.28305551409721375
rl training, epoch9, iter0, batch496/1133, batch loss:0.28305551409721375, Training time:30952.355895280838
batch reward last col mean 0.12285400927066803 first col mean 0.10733390599489212 all mean 0.1265864074230194
0.2893073260784149 0.2893073260784149
rl training, epoch9, iter0, batch497/1133, batch loss:0.2893073260784149, Training time:30954.190442562103
batch reward last col mean 0.10381332784891129 first col mean 0.11262723058462143 all mean 0.10389893501996994
0.268688827753067 0.268688827753067
rl training, epoch9, iter0, batch498/1133, batch loss:0.268688827753067, Training time:30955.84535598755
batch reward last col mean 0.08807051181793213 first col mean 0.1089489534497261 all mean 0.09786392003297806
0.2824688255786896 0.2824688255786896
rl training, epoch9, iter0, batch499/1133, batch loss:0.2824688255786896, Training time:30957.876198768616
_____train D during RL_____
begin to train d model alone...
