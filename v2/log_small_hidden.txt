loaded G
Using device cuda:5
begin to train d model alone...
cur_epoch: 0
D Training Loss: 1.8913455711248588 Time: 100.98993110656738 s
1.0883114747867475 0.41213908472037236 0.39089501092027884
cur_epoch: 1
D Training Loss: 1.6868085178356726 Time: 100.38660550117493 s
0.9472770605167244 0.4083688510590071 0.3311626071542738
cur_epoch: 2
D Training Loss: 1.5686240782278993 Time: 99.68039298057556 s
0.8700869788349148 0.3936857362553175 0.3048513633217942
cur_epoch: 3
D Training Loss: 1.4848594346724036 Time: 99.6344268321991 s
0.8149053762680855 0.38142641082024636 0.2885276460979012
cur_epoch: 4
D Training Loss: 1.3919095602692069 Time: 99.22961139678955 s
0.7564472798110107 0.36724565898225253 0.2682166207262824
cur_epoch: 5
D Training Loss: 1.3207444700643434 Time: 98.97469019889832 s
0.710745164175951 0.3525644819213559 0.2574348233094388
cur_epoch: 6
D Training Loss: 1.2619423313890004 Time: 99.19042420387268 s
0.6727204590588677 0.33631900410576404 0.25290286930282874
cur_epoch: 7
D Training Loss: 1.2069582407809103 Time: 99.93055033683777 s
0.6386495218904062 0.32172767572032596 0.24658104343321716
cur_epoch: 8
D Training Loss: 1.1558152928566996 Time: 99.48074460029602 s
0.6061827400460879 0.3070025609613833 0.24262999200705185
cur_epoch: 9
D Training Loss: 1.105133086837506 Time: 100.62121248245239 s
0.5734439489595257 0.29468948719570937 0.23699965173442702
begin to eval d model alone...
D Eval Loss: 1.0624805629253387 Time: 2.011378765106201 s
cur_epoch: 10
D Training Loss: 1.0614458471931194 Time: 98.783212184906 s
0.5472333335497689 0.2823887973208398 0.2318237145075415
cur_epoch: 11
D Training Loss: 1.0268999188217776 Time: 100.16136264801025 s
0.5250357179544926 0.27265184748151716 0.22921235485878647
cur_epoch: 12
D Training Loss: 0.9960710414194577 Time: 100.61508750915527 s
0.5059818126728128 0.2650223313604744 0.2250668973730185
cur_epoch: 13
D Training Loss: 0.960337323576396 Time: 99.91202282905579 s
0.48332812032758504 0.2557548820341149 0.2212543216815904
cur_epoch: 14
D Training Loss: 0.9317702474787712 Time: 100.15477061271667 s
0.46459633456534866 0.2481443684709251 0.21902954478444825
begin rl....
rl epoch 0, begin RL for generator...
batch reward last col mean 0.1528494656085968 first col mean 0.15866658091545105 all mean 0.15775078535079956
0.5572578310966492 0.5572578310966492
rl training, epoch0, iter0, batch0/1133, batch loss:0.5572578310966492, Training time:2.4892642498016357
batch reward last col mean 0.14257307350635529 first col mean 0.17757084965705872 all mean 0.14848780632019043
0.4835875332355499 0.4835875332355499
rl training, epoch0, iter0, batch1/1133, batch loss:0.4835875332355499, Training time:4.604426622390747
batch reward last col mean 0.1456529200077057 first col mean 0.18688930571079254 all mean 0.15599432587623596
0.5880336165428162 0.5880335569381714
rl training, epoch0, iter0, batch2/1133, batch loss:0.5880335569381714, Training time:7.068037986755371
batch reward last col mean 0.14601795375347137 first col mean 0.18188929557800293 all mean 0.1465025395154953
0.5007809996604919 0.5007809996604919
rl training, epoch0, iter0, batch3/1133, batch loss:0.5007809996604919, Training time:9.920764446258545
batch reward last col mean 0.18201449513435364 first col mean 0.18184742331504822 all mean 0.18019719421863556
0.5710845589637756 0.5710845589637756
rl training, epoch0, iter0, batch4/1133, batch loss:0.5710845589637756, Training time:12.76829981803894
batch reward last col mean 0.16159296035766602 first col mean 0.18096862733364105 all mean 0.1702064424753189
0.5792559385299683 0.5792559385299683
rl training, epoch0, iter0, batch5/1133, batch loss:0.5792559385299683, Training time:15.415927171707153
batch reward last col mean 0.2023625373840332 first col mean 0.18104666471481323 all mean 0.1967763602733612
0.7357771396636963 0.7357771396636963
rl training, epoch0, iter0, batch6/1133, batch loss:0.7357771396636963, Training time:18.28631854057312
batch reward last col mean 0.17074227333068848 first col mean 0.17773112654685974 all mean 0.17157310247421265
0.5641277432441711 0.5641277432441711
rl training, epoch0, iter0, batch7/1133, batch loss:0.5641277432441711, Training time:20.98432493209839
batch reward last col mean 0.1676959991455078 first col mean 0.1850374937057495 all mean 0.17134347558021545
0.5572828054428101 0.5572828054428101
rl training, epoch0, iter0, batch8/1133, batch loss:0.5572828054428101, Training time:23.497057914733887
batch reward last col mean 0.17499080300331116 first col mean 0.16660603880882263 all mean 0.1750996708869934
0.5835862159729004 0.5835862159729004
rl training, epoch0, iter0, batch9/1133, batch loss:0.5835862159729004, Training time:25.929333686828613
batch reward last col mean 0.15314675867557526 first col mean 0.18106527626514435 all mean 0.15925665199756622
0.5379047393798828 0.5379047393798828
rl training, epoch0, iter0, batch10/1133, batch loss:0.5379047393798828, Training time:29.75464367866516
batch reward last col mean 0.180373877286911 first col mean 0.1878233700990677 all mean 0.18481652438640594
0.603908121585846 0.603908121585846
rl training, epoch0, iter0, batch11/1133, batch loss:0.603908121585846, Training time:35.60762929916382
batch reward last col mean 0.1914464235305786 first col mean 0.18948428332805634 all mean 0.18844255805015564
0.5897623300552368 0.5897623300552368
rl training, epoch0, iter0, batch12/1133, batch loss:0.5897623300552368, Training time:38.62677478790283
batch reward last col mean 0.1448862999677658 first col mean 0.17030051350593567 all mean 0.15441539883613586
0.5824963450431824 0.5824963450431824
rl training, epoch0, iter0, batch13/1133, batch loss:0.5824963450431824, Training time:42.049198627471924
batch reward last col mean 0.15441977977752686 first col mean 0.17193228006362915 all mean 0.16008226573467255
0.5830265283584595 0.5830265283584595
rl training, epoch0, iter0, batch14/1133, batch loss:0.5830265283584595, Training time:44.61324715614319
batch reward last col mean 0.17568807303905487 first col mean 0.1787576675415039 all mean 0.1793353110551834
0.6051995158195496 0.6051995158195496
rl training, epoch0, iter0, batch15/1133, batch loss:0.6051995158195496, Training time:47.461172103881836
batch reward last col mean 0.17936846613883972 first col mean 0.19822311401367188 all mean 0.18512777984142303
0.609848141670227 0.609848141670227
rl training, epoch0, iter0, batch16/1133, batch loss:0.609848141670227, Training time:50.848140716552734
batch reward last col mean 0.1539549082517624 first col mean 0.19241741299629211 all mean 0.15692266821861267
0.5422232747077942 0.5422232747077942
rl training, epoch0, iter0, batch17/1133, batch loss:0.5422232747077942, Training time:58.38839650154114
batch reward last col mean 0.17953936755657196 first col mean 0.19738589227199554 all mean 0.17872010171413422
0.6049467921257019 0.6049467921257019
rl training, epoch0, iter0, batch18/1133, batch loss:0.6049467921257019, Training time:60.80330204963684
batch reward last col mean 0.18425461649894714 first col mean 0.1928291916847229 all mean 0.19005101919174194
0.6464964747428894 0.6464964747428894
rl training, epoch0, iter0, batch19/1133, batch loss:0.6464964747428894, Training time:63.68948745727539
batch reward last col mean 0.18381580710411072 first col mean 0.2006688117980957 all mean 0.1861678808927536
0.5587645173072815 0.5587645173072815
rl training, epoch0, iter0, batch20/1133, batch loss:0.5587645173072815, Training time:66.35821723937988
batch reward last col mean 0.18391472101211548 first col mean 0.1857556253671646 all mean 0.18187250196933746
0.5755441188812256 0.5755440592765808
rl training, epoch0, iter0, batch21/1133, batch loss:0.5755440592765808, Training time:68.9999029636383
batch reward last col mean 0.18897472321987152 first col mean 0.19839678704738617 all mean 0.19322292506694794
0.6719676852226257 0.6719676852226257
rl training, epoch0, iter0, batch22/1133, batch loss:0.6719676852226257, Training time:71.58743929862976
batch reward last col mean 0.17830884456634521 first col mean 0.2010136842727661 all mean 0.18058988451957703
0.6162561774253845 0.6162561774253845
rl training, epoch0, iter0, batch23/1133, batch loss:0.6162561774253845, Training time:73.59299230575562
batch reward last col mean 0.2039080709218979 first col mean 0.18501296639442444 all mean 0.19878631830215454
0.6199560761451721 0.6199561357498169
rl training, epoch0, iter0, batch24/1133, batch loss:0.6199561357498169, Training time:75.42404890060425
batch reward last col mean 0.22760224342346191 first col mean 0.20541834831237793 all mean 0.22326193749904633
0.6761083602905273 0.6761083602905273
rl training, epoch0, iter0, batch25/1133, batch loss:0.6761083602905273, Training time:78.72126770019531
batch reward last col mean 0.18951556086540222 first col mean 0.19451700150966644 all mean 0.1936493068933487
0.6950547099113464 0.6950547099113464
rl training, epoch0, iter0, batch26/1133, batch loss:0.6950547099113464, Training time:80.82898950576782
batch reward last col mean 0.1492249220609665 first col mean 0.19192594289779663 all mean 0.15829652547836304
0.5642217993736267 0.5642217993736267
rl training, epoch0, iter0, batch27/1133, batch loss:0.5642217993736267, Training time:82.81092262268066
batch reward last col mean 0.19661015272140503 first col mean 0.21383875608444214 all mean 0.20181536674499512
0.6383863091468811 0.6383863091468811
rl training, epoch0, iter0, batch28/1133, batch loss:0.6383863091468811, Training time:84.45795249938965
batch reward last col mean 0.2116672247648239 first col mean 0.21576355397701263 all mean 0.21276603639125824
0.6545558571815491 0.6545558571815491
rl training, epoch0, iter0, batch29/1133, batch loss:0.6545558571815491, Training time:87.19648885726929
batch reward last col mean 0.16778066754341125 first col mean 0.18094342947006226 all mean 0.17612522840499878
0.6025439500808716 0.6025439500808716
rl training, epoch0, iter0, batch30/1133, batch loss:0.6025439500808716, Training time:89.36849594116211
batch reward last col mean 0.17167484760284424 first col mean 0.19445480406284332 all mean 0.1744970679283142
0.5610899925231934 0.5610899925231934
rl training, epoch0, iter0, batch31/1133, batch loss:0.5610899925231934, Training time:92.24812078475952
batch reward last col mean 0.20468264818191528 first col mean 0.20904940366744995 all mean 0.20213435590267181
0.7165083289146423 0.7165082693099976
rl training, epoch0, iter0, batch32/1133, batch loss:0.7165082693099976, Training time:94.46742653846741
batch reward last col mean 0.24261420965194702 first col mean 0.20723628997802734 all mean 0.23695872724056244
0.6615910530090332 0.6615910530090332
rl training, epoch0, iter0, batch33/1133, batch loss:0.6615910530090332, Training time:96.77941226959229
batch reward last col mean 0.18487459421157837 first col mean 0.20316192507743835 all mean 0.1873052567243576
0.6247543096542358 0.6247543096542358
rl training, epoch0, iter0, batch34/1133, batch loss:0.6247543096542358, Training time:98.87204504013062
batch reward last col mean 0.21057501435279846 first col mean 0.18613912165164948 all mean 0.21088261902332306
0.6584790349006653 0.6584790349006653
rl training, epoch0, iter0, batch35/1133, batch loss:0.6584790349006653, Training time:101.1067898273468
batch reward last col mean 0.2153770625591278 first col mean 0.20282335579395294 all mean 0.2104627788066864
0.6647205352783203 0.6647205352783203
rl training, epoch0, iter0, batch36/1133, batch loss:0.6647205352783203, Training time:102.66973686218262
batch reward last col mean 0.19367475807666779 first col mean 0.21854184567928314 all mean 0.19263654947280884
0.6061077117919922 0.6061077117919922
rl training, epoch0, iter0, batch37/1133, batch loss:0.6061077117919922, Training time:105.0328438282013
batch reward last col mean 0.19236916303634644 first col mean 0.2044752538204193 all mean 0.19270730018615723
0.5829938650131226 0.5829938650131226
rl training, epoch0, iter0, batch38/1133, batch loss:0.5829938650131226, Training time:106.5320405960083
batch reward last col mean 0.21506837010383606 first col mean 0.1979721486568451 all mean 0.21072131395339966
0.6836162209510803 0.6836162209510803
rl training, epoch0, iter0, batch39/1133, batch loss:0.6836162209510803, Training time:108.29127669334412
batch reward last col mean 0.15740753710269928 first col mean 0.21689678728580475 all mean 0.17090310156345367
0.5699240565299988 0.5699240565299988
rl training, epoch0, iter0, batch40/1133, batch loss:0.5699240565299988, Training time:109.925852060318
batch reward last col mean 0.2355453372001648 first col mean 0.22359570860862732 all mean 0.22441458702087402
0.5711877346038818 0.5711877346038818
rl training, epoch0, iter0, batch41/1133, batch loss:0.5711877346038818, Training time:111.5805230140686
batch reward last col mean 0.18601152300834656 first col mean 0.2097788155078888 all mean 0.19216623902320862
0.6159605979919434 0.6159605979919434
rl training, epoch0, iter0, batch42/1133, batch loss:0.6159605979919434, Training time:113.23742818832397
batch reward last col mean 0.20557568967342377 first col mean 0.19513919949531555 all mean 0.2040490359067917
0.662353515625 0.6623534560203552
rl training, epoch0, iter0, batch43/1133, batch loss:0.6623534560203552, Training time:115.29713439941406
batch reward last col mean 0.190670907497406 first col mean 0.20422661304473877 all mean 0.19317227602005005
0.6110187768936157 0.6110187768936157
rl training, epoch0, iter0, batch44/1133, batch loss:0.6110187768936157, Training time:117.11782670021057
batch reward last col mean 0.21108415722846985 first col mean 0.19109167158603668 all mean 0.21002349257469177
0.6648048162460327 0.6648047566413879
rl training, epoch0, iter0, batch45/1133, batch loss:0.6648047566413879, Training time:119.8951199054718
batch reward last col mean 0.21611285209655762 first col mean 0.1964142620563507 all mean 0.20573027431964874
0.5812989473342896 0.5812990069389343
rl training, epoch0, iter0, batch46/1133, batch loss:0.5812990069389343, Training time:121.65395665168762
batch reward last col mean 0.15159600973129272 first col mean 0.20783159136772156 all mean 0.16761523485183716
0.6201287508010864 0.6201287508010864
rl training, epoch0, iter0, batch47/1133, batch loss:0.6201287508010864, Training time:123.92001605033875
batch reward last col mean 0.1698603332042694 first col mean 0.20318441092967987 all mean 0.1843075454235077
0.6060112118721008 0.6060112118721008
rl training, epoch0, iter0, batch48/1133, batch loss:0.6060112118721008, Training time:125.62732172012329
batch reward last col mean 0.1565839648246765 first col mean 0.2146691083908081 all mean 0.16253308951854706
0.5422199964523315 0.5422199964523315
rl training, epoch0, iter0, batch49/1133, batch loss:0.5422199964523315, Training time:127.51047158241272
batch reward last col mean 0.19305695593357086 first col mean 0.2037181854248047 all mean 0.1928676962852478
0.6299285888671875 0.6299285888671875
rl training, epoch0, iter0, batch50/1133, batch loss:0.6299285888671875, Training time:129.74909591674805
batch reward last col mean 0.24382425844669342 first col mean 0.20258915424346924 all mean 0.2360030710697174
0.69300776720047 0.69300776720047
rl training, epoch0, iter0, batch51/1133, batch loss:0.69300776720047, Training time:131.91214895248413
batch reward last col mean 0.19067063927650452 first col mean 0.19692370295524597 all mean 0.1959477812051773
0.5739524364471436 0.5739524364471436
rl training, epoch0, iter0, batch52/1133, batch loss:0.5739524364471436, Training time:133.8206820487976
batch reward last col mean 0.2338135987520218 first col mean 0.21249225735664368 all mean 0.2283071130514145
0.747478187084198 0.747478187084198
rl training, epoch0, iter0, batch53/1133, batch loss:0.747478187084198, Training time:136.8766644001007
batch reward last col mean 0.19867506623268127 first col mean 0.20891283452510834 all mean 0.19961833953857422
0.6704989075660706 0.6704989075660706
rl training, epoch0, iter0, batch54/1133, batch loss:0.6704989075660706, Training time:139.22646498680115
batch reward last col mean 0.19817695021629333 first col mean 0.23530524969100952 all mean 0.20388680696487427
0.7026777863502502 0.7026777863502502
rl training, epoch0, iter0, batch55/1133, batch loss:0.7026777863502502, Training time:141.42545890808105
batch reward last col mean 0.1889098435640335 first col mean 0.21559704840183258 all mean 0.20017267763614655
0.711197555065155 0.711197555065155
rl training, epoch0, iter0, batch56/1133, batch loss:0.711197555065155, Training time:143.1799066066742
batch reward last col mean 0.229879692196846 first col mean 0.22009862959384918 all mean 0.2248905748128891
0.7401825189590454 0.7401825189590454
rl training, epoch0, iter0, batch57/1133, batch loss:0.7401825189590454, Training time:144.85948777198792
batch reward last col mean 0.20242717862129211 first col mean 0.21792538464069366 all mean 0.20273606479167938
0.6364006400108337 0.6364006400108337
rl training, epoch0, iter0, batch58/1133, batch loss:0.6364006400108337, Training time:146.89834260940552
batch reward last col mean 0.23356908559799194 first col mean 0.24016305804252625 all mean 0.23327916860580444
0.7335212826728821 0.7335212826728821
rl training, epoch0, iter0, batch59/1133, batch loss:0.7335212826728821, Training time:148.38138461112976
batch reward last col mean 0.23254670202732086 first col mean 0.21995867788791656 all mean 0.2318163961172104
0.6925264000892639 0.6925265192985535
rl training, epoch0, iter0, batch60/1133, batch loss:0.6925265192985535, Training time:150.44024562835693
batch reward last col mean 0.2331995964050293 first col mean 0.21030953526496887 all mean 0.23146861791610718
0.7522490620613098 0.7522490620613098
rl training, epoch0, iter0, batch61/1133, batch loss:0.7522490620613098, Training time:152.44128012657166
batch reward last col mean 0.20209962129592896 first col mean 0.20220988988876343 all mean 0.2043045312166214
0.7116541266441345 0.7116541266441345
rl training, epoch0, iter0, batch62/1133, batch loss:0.7116541266441345, Training time:154.35330176353455
batch reward last col mean 0.2061147689819336 first col mean 0.21340230107307434 all mean 0.21441321074962616
0.7160276174545288 0.7160276174545288
rl training, epoch0, iter0, batch63/1133, batch loss:0.7160276174545288, Training time:156.0311131477356
batch reward last col mean 0.2029896229505539 first col mean 0.21702653169631958 all mean 0.2068595439195633
0.6994310617446899 0.6994310617446899
rl training, epoch0, iter0, batch64/1133, batch loss:0.6994310617446899, Training time:157.87425756454468
batch reward last col mean 0.19144827127456665 first col mean 0.22179535031318665 all mean 0.19959649443626404
0.6839451789855957 0.6839451789855957
rl training, epoch0, iter0, batch65/1133, batch loss:0.6839451789855957, Training time:159.42760968208313
batch reward last col mean 0.23688729107379913 first col mean 0.23392610251903534 all mean 0.2308051437139511
0.7408477663993835 0.7408477663993835
rl training, epoch0, iter0, batch66/1133, batch loss:0.7408477663993835, Training time:161.6537823677063
batch reward last col mean 0.1914624273777008 first col mean 0.21708889305591583 all mean 0.19816584885120392
0.7448378801345825 0.7448378801345825
rl training, epoch0, iter0, batch67/1133, batch loss:0.7448378801345825, Training time:164.01303553581238
batch reward last col mean 0.22782161831855774 first col mean 0.22150248289108276 all mean 0.22341063618659973
0.7513037919998169 0.7513037919998169
rl training, epoch0, iter0, batch68/1133, batch loss:0.7513037919998169, Training time:165.58352255821228
batch reward last col mean 0.2566070258617401 first col mean 0.216484934091568 all mean 0.24092909693717957
0.7484468221664429 0.7484468221664429
rl training, epoch0, iter0, batch69/1133, batch loss:0.7484468221664429, Training time:167.14518523216248
batch reward last col mean 0.21406103670597076 first col mean 0.20563003420829773 all mean 0.21522526443004608
0.6669034957885742 0.6669034957885742
rl training, epoch0, iter0, batch70/1133, batch loss:0.6669034957885742, Training time:168.6551923751831
batch reward last col mean 0.2443186491727829 first col mean 0.19050650298595428 all mean 0.2368149310350418
0.718317985534668 0.7183178663253784
rl training, epoch0, iter0, batch71/1133, batch loss:0.7183178663253784, Training time:170.5043444633484
batch reward last col mean 0.22762757539749146 first col mean 0.22515368461608887 all mean 0.22539633512496948
0.760452926158905 0.760452926158905
rl training, epoch0, iter0, batch72/1133, batch loss:0.760452926158905, Training time:172.6453561782837
batch reward last col mean 0.22903084754943848 first col mean 0.21606962382793427 all mean 0.22315682470798492
0.7300092577934265 0.7300092577934265
rl training, epoch0, iter0, batch73/1133, batch loss:0.7300092577934265, Training time:174.36740398406982
batch reward last col mean 0.2035745084285736 first col mean 0.2285330444574356 all mean 0.20711076259613037
0.6529066562652588 0.6529066562652588
rl training, epoch0, iter0, batch74/1133, batch loss:0.6529066562652588, Training time:175.98116064071655
batch reward last col mean 0.26642653346061707 first col mean 0.23273354768753052 all mean 0.2548927068710327
0.7289382219314575 0.7289382815361023
rl training, epoch0, iter0, batch75/1133, batch loss:0.7289382815361023, Training time:177.76875495910645
batch reward last col mean 0.20017367601394653 first col mean 0.19822432100772858 all mean 0.20524932444095612
0.7269325256347656 0.7269325256347656
rl training, epoch0, iter0, batch76/1133, batch loss:0.7269325256347656, Training time:179.42125725746155
batch reward last col mean 0.1892789602279663 first col mean 0.23154182732105255 all mean 0.20627108216285706
0.671328604221344 0.671328604221344
rl training, epoch0, iter0, batch77/1133, batch loss:0.671328604221344, Training time:180.79190373420715
batch reward last col mean 0.21038083732128143 first col mean 0.260230153799057 all mean 0.21653681993484497
0.6918994784355164 0.6918994784355164
rl training, epoch0, iter0, batch78/1133, batch loss:0.6918994784355164, Training time:182.3613657951355
batch reward last col mean 0.2683860957622528 first col mean 0.23521022498607635 all mean 0.25112658739089966
0.8073433637619019 0.8073433637619019
rl training, epoch0, iter0, batch79/1133, batch loss:0.8073433637619019, Training time:183.7375349998474
batch reward last col mean 0.2712453305721283 first col mean 0.22742703557014465 all mean 0.2609800100326538
0.7687684297561646 0.7687684297561646
rl training, epoch0, iter0, batch80/1133, batch loss:0.7687684297561646, Training time:186.42311787605286
batch reward last col mean 0.24062488973140717 first col mean 0.22652940452098846 all mean 0.2355809062719345
0.7544261813163757 0.7544261813163757
rl training, epoch0, iter0, batch81/1133, batch loss:0.7544261813163757, Training time:188.0253164768219
batch reward last col mean 0.2636272609233856 first col mean 0.25955939292907715 all mean 0.25967690348625183
0.8287642002105713 0.8287642002105713
rl training, epoch0, iter0, batch82/1133, batch loss:0.8287642002105713, Training time:189.69200706481934
batch reward last col mean 0.25211894512176514 first col mean 0.24504438042640686 all mean 0.25265800952911377
0.8113670349121094 0.8113670349121094
rl training, epoch0, iter0, batch83/1133, batch loss:0.8113670349121094, Training time:191.20843529701233
batch reward last col mean 0.22978824377059937 first col mean 0.23511317372322083 all mean 0.23380830883979797
0.737729549407959 0.737729549407959
rl training, epoch0, iter0, batch84/1133, batch loss:0.737729549407959, Training time:192.62491011619568
batch reward last col mean 0.2691878080368042 first col mean 0.23799747228622437 all mean 0.25610026717185974
0.749954104423523 0.749954104423523
rl training, epoch0, iter0, batch85/1133, batch loss:0.749954104423523, Training time:194.26633524894714
batch reward last col mean 0.22400376200675964 first col mean 0.23469571769237518 all mean 0.22750096023082733
0.7971270084381104 0.7971270084381104
rl training, epoch0, iter0, batch86/1133, batch loss:0.7971270084381104, Training time:195.66713643074036
batch reward last col mean 0.2094300091266632 first col mean 0.24752451479434967 all mean 0.21706180274486542
0.7168022990226746 0.7168022990226746
rl training, epoch0, iter0, batch87/1133, batch loss:0.7168022990226746, Training time:197.25671362876892
batch reward last col mean 0.21908923983573914 first col mean 0.236271470785141 all mean 0.22601264715194702
0.70280522108078 0.70280522108078
rl training, epoch0, iter0, batch88/1133, batch loss:0.70280522108078, Training time:199.33418822288513
batch reward last col mean 0.2511560916900635 first col mean 0.261902391910553 all mean 0.24893435835838318
0.7848947048187256 0.7848947048187256
rl training, epoch0, iter0, batch89/1133, batch loss:0.7848947048187256, Training time:200.69066309928894
batch reward last col mean 0.2916800379753113 first col mean 0.2353617250919342 all mean 0.2720300555229187
0.8168459534645081 0.8168459534645081
rl training, epoch0, iter0, batch90/1133, batch loss:0.8168459534645081, Training time:202.07245588302612
batch reward last col mean 0.24290338158607483 first col mean 0.24766290187835693 all mean 0.24455179274082184
0.833034873008728 0.833034873008728
rl training, epoch0, iter0, batch91/1133, batch loss:0.833034873008728, Training time:203.62258577346802
batch reward last col mean 0.24588438868522644 first col mean 0.22152546048164368 all mean 0.24132564663887024
0.775827944278717 0.775827944278717
rl training, epoch0, iter0, batch92/1133, batch loss:0.775827944278717, Training time:205.69509506225586
batch reward last col mean 0.2314557135105133 first col mean 0.24247826635837555 all mean 0.23000791668891907
0.7601532936096191 0.7601532936096191
rl training, epoch0, iter0, batch93/1133, batch loss:0.7601532936096191, Training time:207.10470271110535
batch reward last col mean 0.21042382717132568 first col mean 0.2550557851791382 all mean 0.21968983113765717
0.7243928909301758 0.7243928909301758
rl training, epoch0, iter0, batch94/1133, batch loss:0.7243928909301758, Training time:208.82079219818115
batch reward last col mean 0.2569655179977417 first col mean 0.24286746978759766 all mean 0.25348174571990967
0.8019698858261108 0.8019698262214661
rl training, epoch0, iter0, batch95/1133, batch loss:0.8019698262214661, Training time:210.38617777824402
batch reward last col mean 0.23454515635967255 first col mean 0.2440127432346344 all mean 0.23706722259521484
0.754154622554779 0.754154622554779
rl training, epoch0, iter0, batch96/1133, batch loss:0.754154622554779, Training time:211.9455041885376
batch reward last col mean 0.2664984464645386 first col mean 0.24384325742721558 all mean 0.26508766412734985
0.8355443477630615 0.8355443477630615
rl training, epoch0, iter0, batch97/1133, batch loss:0.8355443477630615, Training time:215.7606906890869
batch reward last col mean 0.23702216148376465 first col mean 0.2554141879081726 all mean 0.23907120525836945
0.8126052021980286 0.8126052021980286
rl training, epoch0, iter0, batch98/1133, batch loss:0.8126052021980286, Training time:218.0140461921692
batch reward last col mean 0.2430185079574585 first col mean 0.2506505846977234 all mean 0.2486623376607895
0.7744505405426025 0.7744505405426025
rl training, epoch0, iter0, batch99/1133, batch loss:0.7744505405426025, Training time:219.61705088615417
batch reward last col mean 0.24693480134010315 first col mean 0.2555701732635498 all mean 0.249180868268013
0.7399513721466064 0.7399513721466064
rl training, epoch0, iter0, batch100/1133, batch loss:0.7399513721466064, Training time:221.5684313774109
batch reward last col mean 0.23943698406219482 first col mean 0.2625527083873749 all mean 0.24050664901733398
0.7840919494628906 0.7840920090675354
rl training, epoch0, iter0, batch101/1133, batch loss:0.7840920090675354, Training time:224.31356358528137
batch reward last col mean 0.25177931785583496 first col mean 0.25441494584083557 all mean 0.25050073862075806
0.7826128602027893 0.7826128602027893
rl training, epoch0, iter0, batch102/1133, batch loss:0.7826128602027893, Training time:226.32062315940857
batch reward last col mean 0.2570446729660034 first col mean 0.24526849389076233 all mean 0.2520641088485718
0.7933839559555054 0.7933839559555054
rl training, epoch0, iter0, batch103/1133, batch loss:0.7933839559555054, Training time:228.29166555404663
batch reward last col mean 0.26392117142677307 first col mean 0.2666143774986267 all mean 0.2633735239505768
0.7942068576812744 0.7942069172859192
rl training, epoch0, iter0, batch104/1133, batch loss:0.7942069172859192, Training time:230.36559414863586
batch reward last col mean 0.29205089807510376 first col mean 0.2634119391441345 all mean 0.28728199005126953
0.9240448474884033 0.9240448474884033
rl training, epoch0, iter0, batch105/1133, batch loss:0.9240448474884033, Training time:232.10186672210693
batch reward last col mean 0.28510016202926636 first col mean 0.2588675618171692 all mean 0.2709590196609497
0.8477209806442261 0.8477209806442261
rl training, epoch0, iter0, batch106/1133, batch loss:0.8477209806442261, Training time:234.2935106754303
batch reward last col mean 0.26150640845298767 first col mean 0.2902474105358124 all mean 0.26181888580322266
0.7383164167404175 0.7383164167404175
rl training, epoch0, iter0, batch107/1133, batch loss:0.7383164167404175, Training time:236.11084270477295
batch reward last col mean 0.3099198639392853 first col mean 0.26984715461730957 all mean 0.2982126474380493
0.879655659198761 0.879655659198761
rl training, epoch0, iter0, batch108/1133, batch loss:0.879655659198761, Training time:237.88062953948975
batch reward last col mean 0.2741566300392151 first col mean 0.2683755159378052 all mean 0.27415767312049866
0.8432436585426331 0.8432435989379883
rl training, epoch0, iter0, batch109/1133, batch loss:0.8432435989379883, Training time:239.9153482913971
batch reward last col mean 0.30687522888183594 first col mean 0.27585941553115845 all mean 0.300476610660553
0.9133034348487854 0.9133034348487854
rl training, epoch0, iter0, batch110/1133, batch loss:0.9133034348487854, Training time:242.13804292678833
batch reward last col mean 0.22596976161003113 first col mean 0.2602461278438568 all mean 0.23552659153938293
0.8233996033668518 0.8233996033668518
rl training, epoch0, iter0, batch111/1133, batch loss:0.8233996033668518, Training time:243.83475708961487
batch reward last col mean 0.2628919780254364 first col mean 0.25777217745780945 all mean 0.26480832695961
0.7773173451423645 0.7773173451423645
rl training, epoch0, iter0, batch112/1133, batch loss:0.7773173451423645, Training time:246.08388423919678
batch reward last col mean 0.25488442182540894 first col mean 0.2487645000219345 all mean 0.26053687930107117
0.8480642437934875 0.8480642437934875
rl training, epoch0, iter0, batch113/1133, batch loss:0.8480642437934875, Training time:248.43265557289124
batch reward last col mean 0.27495720982551575 first col mean 0.24456316232681274 all mean 0.26973864436149597
0.8222545981407166 0.8222545981407166
rl training, epoch0, iter0, batch114/1133, batch loss:0.8222545981407166, Training time:251.7234468460083
batch reward last col mean 0.2346726655960083 first col mean 0.2678682804107666 all mean 0.23958146572113037
0.8349987268447876 0.8349987268447876
rl training, epoch0, iter0, batch115/1133, batch loss:0.8349987268447876, Training time:253.72291231155396
batch reward last col mean 0.257540225982666 first col mean 0.27072277665138245 all mean 0.263367623090744
0.8903971314430237 0.8903971314430237
rl training, epoch0, iter0, batch116/1133, batch loss:0.8903971314430237, Training time:256.43383955955505
batch reward last col mean 0.2875385880470276 first col mean 0.2622634172439575 all mean 0.27926304936408997
0.9412021636962891 0.9412021636962891
rl training, epoch0, iter0, batch117/1133, batch loss:0.9412021636962891, Training time:258.1698250770569
batch reward last col mean 0.30243295431137085 first col mean 0.2511148452758789 all mean 0.2951500713825226
0.9190970659255981 0.9190970659255981
rl training, epoch0, iter0, batch118/1133, batch loss:0.9190970659255981, Training time:259.81356859207153
batch reward last col mean 0.26604512333869934 first col mean 0.24863103032112122 all mean 0.2692369520664215
0.8157525062561035 0.8157525062561035
rl training, epoch0, iter0, batch119/1133, batch loss:0.8157525062561035, Training time:261.4739363193512
batch reward last col mean 0.2841668128967285 first col mean 0.2638959288597107 all mean 0.2814505398273468
0.937497615814209 0.937497615814209
rl training, epoch0, iter0, batch120/1133, batch loss:0.937497615814209, Training time:263.5043272972107
batch reward last col mean 0.2584341764450073 first col mean 0.2659183442592621 all mean 0.26365742087364197
0.8768064975738525 0.8768064379692078
rl training, epoch0, iter0, batch121/1133, batch loss:0.8768064379692078, Training time:265.36078238487244
batch reward last col mean 0.2587750256061554 first col mean 0.2744658589363098 all mean 0.25745558738708496
0.815740168094635 0.815740168094635
rl training, epoch0, iter0, batch122/1133, batch loss:0.815740168094635, Training time:267.5781624317169
batch reward last col mean 0.2798132300376892 first col mean 0.2730572819709778 all mean 0.276277095079422
0.8979431986808777 0.8979431986808777
rl training, epoch0, iter0, batch123/1133, batch loss:0.8979431986808777, Training time:269.243038892746
batch reward last col mean 0.24191217124462128 first col mean 0.26180151104927063 all mean 0.2510976791381836
0.8144378066062927 0.8144378066062927
rl training, epoch0, iter0, batch124/1133, batch loss:0.8144378066062927, Training time:270.8380591869354
batch reward last col mean 0.3106295168399811 first col mean 0.28624340891838074 all mean 0.3003562092781067
0.9606508016586304 0.9606508016586304
rl training, epoch0, iter0, batch125/1133, batch loss:0.9606508016586304, Training time:272.5565893650055
batch reward last col mean 0.2482631802558899 first col mean 0.27555522322654724 all mean 0.258510559797287
0.8650822639465332 0.8650822639465332
rl training, epoch0, iter0, batch126/1133, batch loss:0.8650822639465332, Training time:274.42078399658203
batch reward last col mean 0.25552451610565186 first col mean 0.2867996394634247 all mean 0.26027604937553406
0.8828604221343994 0.8828604817390442
rl training, epoch0, iter0, batch127/1133, batch loss:0.8828604817390442, Training time:276.8743486404419
batch reward last col mean 0.2259775847196579 first col mean 0.2620684504508972 all mean 0.23308050632476807
0.7625093460083008 0.7625093460083008
rl training, epoch0, iter0, batch128/1133, batch loss:0.7625093460083008, Training time:278.9040710926056
batch reward last col mean 0.2815323770046234 first col mean 0.2745428681373596 all mean 0.2813625931739807
0.856353759765625 0.856353759765625
rl training, epoch0, iter0, batch129/1133, batch loss:0.856353759765625, Training time:280.9364564418793
batch reward last col mean 0.2518450915813446 first col mean 0.2774285078048706 all mean 0.2493155151605606
0.7490534782409668 0.7490534782409668
rl training, epoch0, iter0, batch130/1133, batch loss:0.7490534782409668, Training time:282.55084228515625
batch reward last col mean 0.25196555256843567 first col mean 0.29106295108795166 all mean 0.26451873779296875
0.9264973998069763 0.9264973998069763
rl training, epoch0, iter0, batch131/1133, batch loss:0.9264973998069763, Training time:284.0398302078247
batch reward last col mean 0.24635961651802063 first col mean 0.27432698011398315 all mean 0.25833308696746826
0.9003747701644897 0.9003747701644897
rl training, epoch0, iter0, batch132/1133, batch loss:0.9003747701644897, Training time:285.4383375644684
batch reward last col mean 0.2965258061885834 first col mean 0.2613382935523987 all mean 0.29106196761131287
0.8916022777557373 0.8916022777557373
rl training, epoch0, iter0, batch133/1133, batch loss:0.8916022777557373, Training time:287.62738251686096
batch reward last col mean 0.24035993218421936 first col mean 0.28351378440856934 all mean 0.24905696511268616
0.8475556373596191 0.8475556373596191
rl training, epoch0, iter0, batch134/1133, batch loss:0.8475556373596191, Training time:289.3500220775604
batch reward last col mean 0.2787465751171112 first col mean 0.2927805185317993 all mean 0.27665770053863525
0.8913551568984985 0.8913550972938538
rl training, epoch0, iter0, batch135/1133, batch loss:0.8913550972938538, Training time:291.4078152179718
batch reward last col mean 0.25481435656547546 first col mean 0.27262401580810547 all mean 0.2541530430316925
0.8537200093269348 0.8537200093269348
rl training, epoch0, iter0, batch136/1133, batch loss:0.8537200093269348, Training time:293.06481432914734
batch reward last col mean 0.28774550557136536 first col mean 0.2919026017189026 all mean 0.28539273142814636
0.9115708470344543 0.9115708470344543
rl training, epoch0, iter0, batch137/1133, batch loss:0.9115708470344543, Training time:295.1740200519562
batch reward last col mean 0.2586228549480438 first col mean 0.2749328315258026 all mean 0.25655651092529297
0.8527129888534546 0.8527130484580994
rl training, epoch0, iter0, batch138/1133, batch loss:0.8527130484580994, Training time:297.0097870826721
batch reward last col mean 0.2761806845664978 first col mean 0.2894553244113922 all mean 0.28099367022514343
0.9030907154083252 0.9030907154083252
rl training, epoch0, iter0, batch139/1133, batch loss:0.9030907154083252, Training time:299.19815325737
batch reward last col mean 0.2588660418987274 first col mean 0.29133841395378113 all mean 0.2680438756942749
0.858880877494812 0.858880877494812
rl training, epoch0, iter0, batch140/1133, batch loss:0.858880877494812, Training time:301.42769408226013
batch reward last col mean 0.25557583570480347 first col mean 0.2907148003578186 all mean 0.2634645104408264
0.9160483479499817 0.9160483479499817
rl training, epoch0, iter0, batch141/1133, batch loss:0.9160483479499817, Training time:304.2630932331085
batch reward last col mean 0.27556949853897095 first col mean 0.3048648536205292 all mean 0.2762840986251831
0.933302104473114 0.933302104473114
rl training, epoch0, iter0, batch142/1133, batch loss:0.933302104473114, Training time:306.22001099586487
batch reward last col mean 0.26945286989212036 first col mean 0.2903447449207306 all mean 0.2776755690574646
0.9725379347801208 0.9725378751754761
rl training, epoch0, iter0, batch143/1133, batch loss:0.9725378751754761, Training time:308.5970182418823
batch reward last col mean 0.29202765226364136 first col mean 0.28635528683662415 all mean 0.2902674674987793
0.8059649467468262 0.8059649467468262
rl training, epoch0, iter0, batch144/1133, batch loss:0.8059649467468262, Training time:311.0472164154053
batch reward last col mean 0.2824869155883789 first col mean 0.2804252505302429 all mean 0.28397780656814575
0.8502070307731628 0.8502069711685181
rl training, epoch0, iter0, batch145/1133, batch loss:0.8502069711685181, Training time:313.3007535934448
batch reward last col mean 0.27133792638778687 first col mean 0.30716678500175476 all mean 0.2728677988052368
0.8713942766189575 0.8713942170143127
rl training, epoch0, iter0, batch146/1133, batch loss:0.8713942170143127, Training time:315.581426858902
batch reward last col mean 0.2801305055618286 first col mean 0.2797258198261261 all mean 0.2834567725658417
0.8643602132797241 0.8643602132797241
rl training, epoch0, iter0, batch147/1133, batch loss:0.8643602132797241, Training time:317.5244677066803
batch reward last col mean 0.3152063488960266 first col mean 0.28886765241622925 all mean 0.3135671019554138
0.9450315237045288 0.9450315237045288
rl training, epoch0, iter0, batch148/1133, batch loss:0.9450315237045288, Training time:320.7134459018707
batch reward last col mean 0.2991601228713989 first col mean 0.2931511402130127 all mean 0.29916685819625854
1.0137150287628174 1.0137150287628174
rl training, epoch0, iter0, batch149/1133, batch loss:1.0137150287628174, Training time:323.1175801753998
batch reward last col mean 0.2822147011756897 first col mean 0.2847698926925659 all mean 0.283062219619751
0.9977033734321594 0.9977033734321594
rl training, epoch0, iter0, batch150/1133, batch loss:0.9977033734321594, Training time:326.0491256713867
batch reward last col mean 0.27115628123283386 first col mean 0.2812994122505188 all mean 0.27659615874290466
0.8764301538467407 0.8764301538467407
rl training, epoch0, iter0, batch151/1133, batch loss:0.8764301538467407, Training time:328.4703085422516
batch reward last col mean 0.2965221405029297 first col mean 0.2926901578903198 all mean 0.3014380633831024
0.9673783779144287 0.9673783779144287
rl training, epoch0, iter0, batch152/1133, batch loss:0.9673783779144287, Training time:331.7564537525177
batch reward last col mean 0.26664358377456665 first col mean 0.3142264187335968 all mean 0.27043870091438293
0.8336213827133179 0.8336213827133179
rl training, epoch0, iter0, batch153/1133, batch loss:0.8336213827133179, Training time:336.9196105003357
batch reward last col mean 0.2508159875869751 first col mean 0.28160184621810913 all mean 0.2621381878852844
0.910825252532959 0.9108253121376038
rl training, epoch0, iter0, batch154/1133, batch loss:0.9108253121376038, Training time:339.6677188873291
batch reward last col mean 0.2927061915397644 first col mean 0.2976735234260559 all mean 0.3043798804283142
1.042310118675232 1.042310118675232
rl training, epoch0, iter0, batch155/1133, batch loss:1.042310118675232, Training time:342.30062341690063
batch reward last col mean 0.2688142657279968 first col mean 0.2921530604362488 all mean 0.27192217111587524
0.8497341871261597 0.8497341871261597
rl training, epoch0, iter0, batch156/1133, batch loss:0.8497341871261597, Training time:345.4070448875427
batch reward last col mean 0.29289984703063965 first col mean 0.2907477915287018 all mean 0.2917383313179016
0.9772427082061768 0.9772427082061768
rl training, epoch0, iter0, batch157/1133, batch loss:0.9772427082061768, Training time:349.2529146671295
batch reward last col mean 0.2793978154659271 first col mean 0.30484193563461304 all mean 0.2854044735431671
0.9306492805480957 0.9306492805480957
rl training, epoch0, iter0, batch158/1133, batch loss:0.9306492805480957, Training time:353.91997361183167
batch reward last col mean 0.26612889766693115 first col mean 0.31559672951698303 all mean 0.2827056646347046
0.91658616065979 0.91658616065979
rl training, epoch0, iter0, batch159/1133, batch loss:0.91658616065979, Training time:357.00658679008484
batch reward last col mean 0.29492974281311035 first col mean 0.31122517585754395 all mean 0.29688382148742676
1.0044684410095215 1.0044684410095215
rl training, epoch0, iter0, batch160/1133, batch loss:1.0044684410095215, Training time:360.57314133644104
batch reward last col mean 0.3291466236114502 first col mean 0.30339741706848145 all mean 0.3275255262851715
1.0652762651443481 1.0652762651443481
rl training, epoch0, iter0, batch161/1133, batch loss:1.0652762651443481, Training time:366.5895674228668
batch reward last col mean 0.27133482694625854 first col mean 0.299335777759552 all mean 0.2719511091709137
0.8295966982841492 0.8295966982841492
rl training, epoch0, iter0, batch162/1133, batch loss:0.8295966982841492, Training time:372.3552579879761
batch reward last col mean 0.2813623249530792 first col mean 0.29709336161613464 all mean 0.2789565920829773
0.8031549453735352 0.8031549453735352
rl training, epoch0, iter0, batch163/1133, batch loss:0.8031549453735352, Training time:377.76118755340576
batch reward last col mean 0.3273389935493469 first col mean 0.3134118318557739 all mean 0.3245603144168854
0.9408988952636719 0.9408990144729614
rl training, epoch0, iter0, batch164/1133, batch loss:0.9408990144729614, Training time:382.03610038757324
batch reward last col mean 0.26029065251350403 first col mean 0.30556145310401917 all mean 0.2657044231891632
0.8863593339920044 0.8863592743873596
rl training, epoch0, iter0, batch165/1133, batch loss:0.8863592743873596, Training time:386.05085253715515
batch reward last col mean 0.27833181619644165 first col mean 0.2752302885055542 all mean 0.27864837646484375
0.9016276001930237 0.9016276001930237
rl training, epoch0, iter0, batch166/1133, batch loss:0.9016276001930237, Training time:390.2534499168396
batch reward last col mean 0.30953818559646606 first col mean 0.2973041236400604 all mean 0.31518879532814026
0.9185792207717896 0.9185792207717896
rl training, epoch0, iter0, batch167/1133, batch loss:0.9185792207717896, Training time:393.98130226135254
batch reward last col mean 0.3116084337234497 first col mean 0.30990368127822876 all mean 0.31380507349967957
0.9288254976272583 0.9288254976272583
rl training, epoch0, iter0, batch168/1133, batch loss:0.9288254976272583, Training time:404.1963164806366
batch reward last col mean 0.26854488253593445 first col mean 0.2911858558654785 all mean 0.2726946771144867
0.8515759706497192 0.8515759706497192
rl training, epoch0, iter0, batch169/1133, batch loss:0.8515759706497192, Training time:409.4890880584717
batch reward last col mean 0.28693297505378723 first col mean 0.2827076315879822 all mean 0.29359880089759827
0.9483259320259094 0.9483259320259094
rl training, epoch0, iter0, batch170/1133, batch loss:0.9483259320259094, Training time:412.6771385669708
batch reward last col mean 0.33850282430648804 first col mean 0.35246211290359497 all mean 0.33326804637908936
1.0061941146850586 1.0061941146850586
rl training, epoch0, iter0, batch171/1133, batch loss:1.0061941146850586, Training time:417.41986632347107
batch reward last col mean 0.33380794525146484 first col mean 0.3002001643180847 all mean 0.33308401703834534
1.0238739252090454 1.0238739252090454
rl training, epoch0, iter0, batch172/1133, batch loss:1.0238739252090454, Training time:422.3805434703827
batch reward last col mean 0.3148972988128662 first col mean 0.31822633743286133 all mean 0.32024437189102173
0.9954484105110168 0.9954484105110168
rl training, epoch0, iter0, batch173/1133, batch loss:0.9954484105110168, Training time:427.719673871994
batch reward last col mean 0.30302906036376953 first col mean 0.29140448570251465 all mean 0.30371761322021484
0.9597963690757751 0.9597963690757751
rl training, epoch0, iter0, batch174/1133, batch loss:0.9597963690757751, Training time:432.6688024997711
batch reward last col mean 0.3226380944252014 first col mean 0.33251699805259705 all mean 0.324842631816864
0.8977422118186951 0.8977422118186951
rl training, epoch0, iter0, batch175/1133, batch loss:0.8977422118186951, Training time:436.73580050468445
batch reward last col mean 0.32044368982315063 first col mean 0.31585192680358887 all mean 0.3118461072444916
0.9288854002952576 0.9288853406906128
rl training, epoch0, iter0, batch176/1133, batch loss:0.9288853406906128, Training time:441.10824060440063
batch reward last col mean 0.3474271595478058 first col mean 0.328095018863678 all mean 0.33762890100479126
0.9125270843505859 0.9125270843505859
rl training, epoch0, iter0, batch177/1133, batch loss:0.9125270843505859, Training time:444.6867392063141
batch reward last col mean 0.3393542468547821 first col mean 0.3272087574005127 all mean 0.3380879759788513
0.9750731587409973 0.9750731587409973
rl training, epoch0, iter0, batch178/1133, batch loss:0.9750731587409973, Training time:448.00732946395874
batch reward last col mean 0.3293585777282715 first col mean 0.33115649223327637 all mean 0.32932329177856445
0.9718604683876038 0.9718604683876038
rl training, epoch0, iter0, batch179/1133, batch loss:0.9718604683876038, Training time:451.3021504878998
batch reward last col mean 0.30787304043769836 first col mean 0.33425387740135193 all mean 0.30901485681533813
0.8682937026023865 0.8682937026023865
rl training, epoch0, iter0, batch180/1133, batch loss:0.8682937026023865, Training time:454.06365942955017
batch reward last col mean 0.3317534625530243 first col mean 0.3110661804676056 all mean 0.3269982635974884
0.9147273302078247 0.9147273302078247
rl training, epoch0, iter0, batch181/1133, batch loss:0.9147273302078247, Training time:457.56133222579956
batch reward last col mean 0.31615695357322693 first col mean 0.30756473541259766 all mean 0.3121611177921295
0.9109514355659485 0.9109513759613037
rl training, epoch0, iter0, batch182/1133, batch loss:0.9109513759613037, Training time:460.6446223258972
batch reward last col mean 0.30692943930625916 first col mean 0.33831897377967834 all mean 0.31582656502723694
0.9341931939125061 0.9341932535171509
rl training, epoch0, iter0, batch183/1133, batch loss:0.9341932535171509, Training time:463.4813747406006
batch reward last col mean 0.2599175274372101 first col mean 0.29635390639305115 all mean 0.269047349691391
0.7770737409591675 0.7770737409591675
rl training, epoch0, iter0, batch184/1133, batch loss:0.7770737409591675, Training time:466.33271861076355
batch reward last col mean 0.30720677971839905 first col mean 0.3004830479621887 all mean 0.3071800768375397
0.8652620911598206 0.8652620911598206
rl training, epoch0, iter0, batch185/1133, batch loss:0.8652620911598206, Training time:468.80706572532654
batch reward last col mean 0.2918945848941803 first col mean 0.30903130769729614 all mean 0.2993338704109192
0.7991129755973816 0.7991129755973816
rl training, epoch0, iter0, batch186/1133, batch loss:0.7991129755973816, Training time:470.65621852874756
batch reward last col mean 0.27926188707351685 first col mean 0.3366455137729645 all mean 0.29581981897354126
0.8957276344299316 0.8957276344299316
rl training, epoch0, iter0, batch187/1133, batch loss:0.8957276344299316, Training time:472.6196188926697
batch reward last col mean 0.35073500871658325 first col mean 0.3273695111274719 all mean 0.34178367257118225
0.9305931329727173 0.9305931329727173
rl training, epoch0, iter0, batch188/1133, batch loss:0.9305931329727173, Training time:476.4627363681793
batch reward last col mean 0.34812235832214355 first col mean 0.34778130054473877 all mean 0.3399127721786499
1.028017520904541 1.028017520904541
rl training, epoch0, iter0, batch189/1133, batch loss:1.028017520904541, Training time:478.6771731376648
batch reward last col mean 0.31696999073028564 first col mean 0.33213651180267334 all mean 0.3139669597148895
0.9459689259529114 0.9459689259529114
rl training, epoch0, iter0, batch190/1133, batch loss:0.9459689259529114, Training time:481.34596729278564
batch reward last col mean 0.3157937228679657 first col mean 0.32627320289611816 all mean 0.3168301582336426
0.8402268290519714 0.8402268290519714
rl training, epoch0, iter0, batch191/1133, batch loss:0.8402268290519714, Training time:483.8395240306854
batch reward last col mean 0.31814372539520264 first col mean 0.31536081433296204 all mean 0.3241857588291168
0.9095187187194824 0.9095186591148376
rl training, epoch0, iter0, batch192/1133, batch loss:0.9095186591148376, Training time:485.80940103530884
batch reward last col mean 0.3444949984550476 first col mean 0.334178626537323 all mean 0.3427738547325134
0.9361016750335693 0.9361016750335693
rl training, epoch0, iter0, batch193/1133, batch loss:0.9361016750335693, Training time:487.74636125564575
batch reward last col mean 0.3125239610671997 first col mean 0.3048730194568634 all mean 0.30970653891563416
0.8789135813713074 0.8789135813713074
rl training, epoch0, iter0, batch194/1133, batch loss:0.8789135813713074, Training time:490.11669659614563
batch reward last col mean 0.3451122045516968 first col mean 0.31255093216896057 all mean 0.34479624032974243
0.9373871088027954 0.9373871088027954
rl training, epoch0, iter0, batch195/1133, batch loss:0.9373871088027954, Training time:492.9666049480438
batch reward last col mean 0.3178113102912903 first col mean 0.2817903161048889 all mean 0.31627362966537476
0.8257524967193604 0.8257525563240051
rl training, epoch0, iter0, batch196/1133, batch loss:0.8257525563240051, Training time:495.6717014312744
batch reward last col mean 0.3253507912158966 first col mean 0.339851975440979 all mean 0.33019471168518066
0.8819253444671631 0.8819252252578735
rl training, epoch0, iter0, batch197/1133, batch loss:0.8819252252578735, Training time:498.7293586730957
batch reward last col mean 0.3351571261882782 first col mean 0.32890599966049194 all mean 0.33377504348754883
0.8833432197570801 0.8833432197570801
rl training, epoch0, iter0, batch198/1133, batch loss:0.8833432197570801, Training time:503.85924100875854
batch reward last col mean 0.3290731906890869 first col mean 0.31124114990234375 all mean 0.32528236508369446
0.838535487651825 0.838535487651825
rl training, epoch0, iter0, batch199/1133, batch loss:0.838535487651825, Training time:506.5507094860077
batch reward last col mean 0.3069223463535309 first col mean 0.33186620473861694 all mean 0.32460126280784607
0.8691287040710449 0.8691287040710449
rl training, epoch0, iter0, batch200/1133, batch loss:0.8691287040710449, Training time:508.8197817802429
batch reward last col mean 0.3115614950656891 first col mean 0.31604525446891785 all mean 0.3159996569156647
0.8325478434562683 0.8325477242469788
rl training, epoch0, iter0, batch201/1133, batch loss:0.8325477242469788, Training time:513.2777543067932
batch reward last col mean 0.32545900344848633 first col mean 0.3020203113555908 all mean 0.32093536853790283
0.8577550649642944 0.8577550649642944
rl training, epoch0, iter0, batch202/1133, batch loss:0.8577550649642944, Training time:515.515433549881
batch reward last col mean 0.3509204089641571 first col mean 0.32077422738075256 all mean 0.3464809060096741
0.8591392040252686 0.8591392040252686
rl training, epoch0, iter0, batch203/1133, batch loss:0.8591392040252686, Training time:519.1450734138489
batch reward last col mean 0.33736035227775574 first col mean 0.32144415378570557 all mean 0.3293706476688385
0.8582474589347839 0.8582474589347839
rl training, epoch0, iter0, batch204/1133, batch loss:0.8582474589347839, Training time:521.9860303401947
batch reward last col mean 0.32330837845802307 first col mean 0.3499913215637207 all mean 0.32937926054000854
0.8852458000183105 0.8852458000183105
rl training, epoch0, iter0, batch205/1133, batch loss:0.8852458000183105, Training time:524.922342300415
batch reward last col mean 0.2792235016822815 first col mean 0.3247271776199341 all mean 0.2862059772014618
0.7626304030418396 0.7626304030418396
rl training, epoch0, iter0, batch206/1133, batch loss:0.7626304030418396, Training time:528.5890326499939
batch reward last col mean 0.29943063855171204 first col mean 0.32619941234588623 all mean 0.3074239194393158
0.8875727653503418 0.8875727653503418
rl training, epoch0, iter0, batch207/1133, batch loss:0.8875727653503418, Training time:531.5006356239319
batch reward last col mean 0.3441793620586395 first col mean 0.35059964656829834 all mean 0.34690865874290466
0.8934559226036072 0.8934559226036072
rl training, epoch0, iter0, batch208/1133, batch loss:0.8934559226036072, Training time:534.1428759098053
batch reward last col mean 0.3320128321647644 first col mean 0.36124691367149353 all mean 0.33333632349967957
0.8870327472686768 0.8870327472686768
rl training, epoch0, iter0, batch209/1133, batch loss:0.8870327472686768, Training time:537.1138126850128
batch reward last col mean 0.3145221173763275 first col mean 0.32652387022972107 all mean 0.3221189081668854
0.8168640732765198 0.816864013671875
rl training, epoch0, iter0, batch210/1133, batch loss:0.816864013671875, Training time:539.1794188022614
batch reward last col mean 0.3407127261161804 first col mean 0.3343035578727722 all mean 0.3332260251045227
0.8423168063163757 0.8423168063163757
rl training, epoch0, iter0, batch211/1133, batch loss:0.8423168063163757, Training time:541.2151854038239
batch reward last col mean 0.33732688426971436 first col mean 0.3597836196422577 all mean 0.3411926329135895
0.8384241461753845 0.8384241461753845
rl training, epoch0, iter0, batch212/1133, batch loss:0.8384241461753845, Training time:544.4755036830902
batch reward last col mean 0.32137805223464966 first col mean 0.34815484285354614 all mean 0.32797932624816895
0.8652414083480835 0.8652414083480835
rl training, epoch0, iter0, batch213/1133, batch loss:0.8652414083480835, Training time:547.7830691337585
batch reward last col mean 0.35768336057662964 first col mean 0.3296160399913788 all mean 0.34914684295654297
0.8881611227989197 0.8881611227989197
rl training, epoch0, iter0, batch214/1133, batch loss:0.8881611227989197, Training time:550.451878786087
batch reward last col mean 0.3458828926086426 first col mean 0.32718610763549805 all mean 0.33855247497558594
0.9055620431900024 0.9055620431900024
rl training, epoch0, iter0, batch215/1133, batch loss:0.9055620431900024, Training time:554.8089110851288
batch reward last col mean 0.32190829515457153 first col mean 0.32462313771247864 all mean 0.3203285336494446
0.8272762894630432 0.8272762298583984
rl training, epoch0, iter0, batch216/1133, batch loss:0.8272762298583984, Training time:557.327639579773
batch reward last col mean 0.3286237418651581 first col mean 0.3234538733959198 all mean 0.33083000779151917
0.8868839144706726 0.8868839144706726
rl training, epoch0, iter0, batch217/1133, batch loss:0.8868839144706726, Training time:559.9666516780853
batch reward last col mean 0.35941529273986816 first col mean 0.3312041759490967 all mean 0.35246598720550537
0.9479259252548218 0.9479259252548218
rl training, epoch0, iter0, batch218/1133, batch loss:0.9479259252548218, Training time:562.9112002849579
batch reward last col mean 0.360791951417923 first col mean 0.3382923901081085 all mean 0.3565131723880768
0.8910865187644958 0.8910864591598511
rl training, epoch0, iter0, batch219/1133, batch loss:0.8910864591598511, Training time:565.2987384796143
batch reward last col mean 0.30628588795661926 first col mean 0.29004842042922974 all mean 0.312030166387558
0.8372184634208679 0.8372184634208679
rl training, epoch0, iter0, batch220/1133, batch loss:0.8372184634208679, Training time:567.8330132961273
batch reward last col mean 0.3209465444087982 first col mean 0.3679918050765991 all mean 0.3275999128818512
0.8566728830337524 0.8566728234291077
rl training, epoch0, iter0, batch221/1133, batch loss:0.8566728234291077, Training time:571.3876938819885
batch reward last col mean 0.29858994483947754 first col mean 0.3061327636241913 all mean 0.3044136166572571
0.7627568244934082 0.7627568244934082
rl training, epoch0, iter0, batch222/1133, batch loss:0.7627568244934082, Training time:573.7395043373108
batch reward last col mean 0.3502636253833771 first col mean 0.3520418405532837 all mean 0.3506535589694977
0.8282390832901001 0.8282390832901001
rl training, epoch0, iter0, batch223/1133, batch loss:0.8282390832901001, Training time:576.5419092178345
batch reward last col mean 0.36228981614112854 first col mean 0.329182505607605 all mean 0.3529030680656433
0.8819116353988647 0.88191157579422
rl training, epoch0, iter0, batch224/1133, batch loss:0.88191157579422, Training time:579.1729130744934
batch reward last col mean 0.3511292636394501 first col mean 0.33932241797447205 all mean 0.3486361503601074
0.8017337918281555 0.8017337918281555
rl training, epoch0, iter0, batch225/1133, batch loss:0.8017337918281555, Training time:582.2080614566803
batch reward last col mean 0.30289745330810547 first col mean 0.29869043827056885 all mean 0.30384838581085205
0.7533048987388611 0.7533048987388611
rl training, epoch0, iter0, batch226/1133, batch loss:0.7533048987388611, Training time:584.6417560577393
batch reward last col mean 0.30735743045806885 first col mean 0.30834895372390747 all mean 0.30932724475860596
0.765001118183136 0.765001118183136
rl training, epoch0, iter0, batch227/1133, batch loss:0.765001118183136, Training time:588.0188083648682
batch reward last col mean 0.36833471059799194 first col mean 0.3532752990722656 all mean 0.3665865659713745
0.9623869061470032 0.9623869061470032
rl training, epoch0, iter0, batch228/1133, batch loss:0.9623869061470032, Training time:591.0676958560944
batch reward last col mean 0.3296884298324585 first col mean 0.3470742404460907 all mean 0.333894282579422
0.9092019200325012 0.9092019200325012
rl training, epoch0, iter0, batch229/1133, batch loss:0.9092019200325012, Training time:594.1718847751617
batch reward last col mean 0.34170961380004883 first col mean 0.3459744453430176 all mean 0.3472687005996704
0.8803597092628479 0.8803597092628479
rl training, epoch0, iter0, batch230/1133, batch loss:0.8803597092628479, Training time:597.7642080783844
batch reward last col mean 0.3209528923034668 first col mean 0.3119467794895172 all mean 0.31808140873908997
0.7575485706329346 0.7575485706329346
rl training, epoch0, iter0, batch231/1133, batch loss:0.7575485706329346, Training time:601.0706269741058
batch reward last col mean 0.3329428434371948 first col mean 0.3236374258995056 all mean 0.328178733587265
0.8816338181495667 0.8816338181495667
rl training, epoch0, iter0, batch232/1133, batch loss:0.8816338181495667, Training time:604.6823379993439
batch reward last col mean 0.36388593912124634 first col mean 0.32050788402557373 all mean 0.3537916839122772
0.8119384050369263 0.8119384050369263
rl training, epoch0, iter0, batch233/1133, batch loss:0.8119384050369263, Training time:607.6818952560425
batch reward last col mean 0.3434847593307495 first col mean 0.33882227540016174 all mean 0.33873388171195984
0.8442431092262268 0.8442431092262268
rl training, epoch0, iter0, batch234/1133, batch loss:0.8442431092262268, Training time:611.74782371521
batch reward last col mean 0.3195347487926483 first col mean 0.3622797727584839 all mean 0.3232335150241852
0.8511200547218323 0.8511200547218323
rl training, epoch0, iter0, batch235/1133, batch loss:0.8511200547218323, Training time:617.0621564388275
batch reward last col mean 0.3355531692504883 first col mean 0.3486407399177551 all mean 0.33890485763549805
0.8764677047729492 0.8764676451683044
rl training, epoch0, iter0, batch236/1133, batch loss:0.8764676451683044, Training time:621.4642314910889
batch reward last col mean 0.3733353018760681 first col mean 0.333477258682251 all mean 0.3676738739013672
0.967721164226532 0.967721164226532
rl training, epoch0, iter0, batch237/1133, batch loss:0.967721164226532, Training time:626.9873633384705
batch reward last col mean 0.3464195132255554 first col mean 0.33347228169441223 all mean 0.3450433313846588
0.9122896194458008 0.9122896790504456
rl training, epoch0, iter0, batch238/1133, batch loss:0.9122896790504456, Training time:631.3433835506439
batch reward last col mean 0.33973991870880127 first col mean 0.35267919301986694 all mean 0.33314698934555054
0.869925856590271 0.869925856590271
rl training, epoch0, iter0, batch239/1133, batch loss:0.869925856590271, Training time:635.696946144104
batch reward last col mean 0.3073802590370178 first col mean 0.32641762495040894 all mean 0.30886268615722656
0.7640500068664551 0.7640500068664551
rl training, epoch0, iter0, batch240/1133, batch loss:0.7640500068664551, Training time:641.662282705307
batch reward last col mean 0.31901293992996216 first col mean 0.334272563457489 all mean 0.3235158622264862
0.9465107917785645 0.9465107917785645
rl training, epoch0, iter0, batch241/1133, batch loss:0.9465107917785645, Training time:648.3445055484772
batch reward last col mean 0.29849421977996826 first col mean 0.32751739025115967 all mean 0.31023234128952026
0.8746886253356934 0.8746886253356934
rl training, epoch0, iter0, batch242/1133, batch loss:0.8746886253356934, Training time:653.0969605445862
batch reward last col mean 0.2944568693637848 first col mean 0.3083588182926178 all mean 0.29935571551322937
0.7983118891716003 0.7983118891716003
rl training, epoch0, iter0, batch243/1133, batch loss:0.7983118891716003, Training time:657.878201007843
batch reward last col mean 0.33031633496284485 first col mean 0.34292542934417725 all mean 0.327760249376297
0.9019914865493774 0.9019915461540222
rl training, epoch0, iter0, batch244/1133, batch loss:0.9019915461540222, Training time:665.7070245742798
batch reward last col mean 0.29762279987335205 first col mean 0.3508132994174957 all mean 0.3022271990776062
0.8392171859741211 0.8392171859741211
rl training, epoch0, iter0, batch245/1133, batch loss:0.8392171859741211, Training time:671.921966791153
batch reward last col mean 0.3556164503097534 first col mean 0.3477630913257599 all mean 0.3538752794265747
0.9609573483467102 0.9609573483467102
rl training, epoch0, iter0, batch246/1133, batch loss:0.9609573483467102, Training time:679.4303679466248
batch reward last col mean 0.3656967282295227 first col mean 0.33611753582954407 all mean 0.365814208984375
0.9771296381950378 0.9771296381950378
rl training, epoch0, iter0, batch247/1133, batch loss:0.9771296381950378, Training time:684.4582908153534
batch reward last col mean 0.3677995204925537 first col mean 0.3481738567352295 all mean 0.36310848593711853
0.8778370022773743 0.877837061882019
rl training, epoch0, iter0, batch248/1133, batch loss:0.877837061882019, Training time:692.494606256485
batch reward last col mean 0.3162749409675598 first col mean 0.3463037312030792 all mean 0.31686294078826904
0.7836512923240662 0.7836512923240662
rl training, epoch0, iter0, batch249/1133, batch loss:0.7836512923240662, Training time:704.754264831543
batch reward last col mean 0.3203886151313782 first col mean 0.34256890416145325 all mean 0.32492735981941223
0.8540500402450562 0.8540500402450562
rl training, epoch0, iter0, batch250/1133, batch loss:0.8540500402450562, Training time:710.9013750553131
batch reward last col mean 0.3361169993877411 first col mean 0.3701851963996887 all mean 0.3343285918235779
0.8016709685325623 0.8016709685325623
rl training, epoch0, iter0, batch251/1133, batch loss:0.8016709685325623, Training time:723.3586273193359
batch reward last col mean 0.29972946643829346 first col mean 0.32045093178749084 all mean 0.3062947392463684
0.8174399137496948 0.8174399137496948
rl training, epoch0, iter0, batch252/1133, batch loss:0.8174399137496948, Training time:730.6234815120697
batch reward last col mean 0.34982937574386597 first col mean 0.36611878871917725 all mean 0.3472788631916046
0.9525787234306335 0.9525787234306335
rl training, epoch0, iter0, batch253/1133, batch loss:0.9525787234306335, Training time:736.5602986812592
batch reward last col mean 0.3196733593940735 first col mean 0.3456305265426636 all mean 0.32429397106170654
0.9183786511421204 0.9183786511421204
rl training, epoch0, iter0, batch254/1133, batch loss:0.9183786511421204, Training time:751.4824652671814
batch reward last col mean 0.3917964696884155 first col mean 0.3721168041229248 all mean 0.3899184465408325
1.0215710401535034 1.0215710401535034
rl training, epoch0, iter0, batch255/1133, batch loss:1.0215710401535034, Training time:765.6752107143402
batch reward last col mean 0.2734174430370331 first col mean 0.2927287220954895 all mean 0.27588486671447754
0.6689682006835938 0.6689682006835938
rl training, epoch0, iter0, batch256/1133, batch loss:0.6689682006835938, Training time:774.9349751472473
batch reward last col mean 0.31756967306137085 first col mean 0.35391664505004883 all mean 0.3194311261177063
0.8259859085083008 0.8259859085083008
rl training, epoch0, iter0, batch257/1133, batch loss:0.8259859085083008, Training time:788.9617984294891
batch reward last col mean 0.369258314371109 first col mean 0.3490944504737854 all mean 0.3636132776737213
0.8963881134986877 0.896388053894043
rl training, epoch0, iter0, batch258/1133, batch loss:0.896388053894043, Training time:800.3812346458435
batch reward last col mean 0.36825671792030334 first col mean 0.37602555751800537 all mean 0.3721216320991516
0.9534322619438171 0.9534320831298828
rl training, epoch0, iter0, batch259/1133, batch loss:0.9534320831298828, Training time:816.4729433059692
batch reward last col mean 0.2946523129940033 first col mean 0.3136839270591736 all mean 0.29667729139328003
0.8075957298278809 0.8075957298278809
rl training, epoch0, iter0, batch260/1133, batch loss:0.8075957298278809, Training time:831.5456521511078
batch reward last col mean 0.34605276584625244 first col mean 0.34205394983291626 all mean 0.3484174609184265
0.8467011451721191 0.8467011451721191
rl training, epoch0, iter0, batch261/1133, batch loss:0.8467011451721191, Training time:847.1493411064148
batch reward last col mean 0.40513840317726135 first col mean 0.3873273730278015 all mean 0.39820075035095215
0.9678366184234619 0.9678366184234619
rl training, epoch0, iter0, batch262/1133, batch loss:0.9678366184234619, Training time:857.7240500450134
batch reward last col mean 0.367820680141449 first col mean 0.3756859302520752 all mean 0.36653754115104675
0.9764880537986755 0.9764880537986755
rl training, epoch0, iter0, batch263/1133, batch loss:0.9764880537986755, Training time:874.4950184822083
batch reward last col mean 0.31485769152641296 first col mean 0.3453298509120941 all mean 0.3202727138996124
0.8760846853256226 0.8760846853256226
rl training, epoch0, iter0, batch264/1133, batch loss:0.8760846853256226, Training time:887.4610831737518
batch reward last col mean 0.32517823576927185 first col mean 0.32931721210479736 all mean 0.3294926583766937
0.8591994047164917 0.8591994047164917
rl training, epoch0, iter0, batch265/1133, batch loss:0.8591994047164917, Training time:904.536146402359
batch reward last col mean 0.35607630014419556 first col mean 0.35819166898727417 all mean 0.35321468114852905
0.8900482058525085 0.8900482058525085
rl training, epoch0, iter0, batch266/1133, batch loss:0.8900482058525085, Training time:919.3268644809723
batch reward last col mean 0.30158209800720215 first col mean 0.33038994669914246 all mean 0.30437904596328735
0.8509529829025269 0.8509530425071716
rl training, epoch0, iter0, batch267/1133, batch loss:0.8509530425071716, Training time:928.5440056324005
batch reward last col mean 0.2928590476512909 first col mean 0.31813549995422363 all mean 0.29349982738494873
0.8159597516059875 0.8159597516059875
rl training, epoch0, iter0, batch268/1133, batch loss:0.8159597516059875, Training time:939.2170767784119
batch reward last col mean 0.3272269666194916 first col mean 0.32414963841438293 all mean 0.3216545283794403
0.8189398646354675 0.8189398646354675
rl training, epoch0, iter0, batch269/1133, batch loss:0.8189398646354675, Training time:948.7129180431366
batch reward last col mean 0.3059172034263611 first col mean 0.34953826665878296 all mean 0.31367072463035583
0.8987396955490112 0.8987396955490112
rl training, epoch0, iter0, batch270/1133, batch loss:0.8987396955490112, Training time:964.5672583580017
batch reward last col mean 0.3618028461933136 first col mean 0.3467838168144226 all mean 0.3587583601474762
0.875823438167572 0.875823438167572
rl training, epoch0, iter0, batch271/1133, batch loss:0.875823438167572, Training time:972.2699177265167
batch reward last col mean 0.31102821230888367 first col mean 0.30579954385757446 all mean 0.3164471387863159
0.9230133295059204 0.9230133295059204
rl training, epoch0, iter0, batch272/1133, batch loss:0.9230133295059204, Training time:986.1197941303253
batch reward last col mean 0.32721763849258423 first col mean 0.3290315866470337 all mean 0.32240310311317444
0.8343127965927124 0.8343127965927124
rl training, epoch0, iter0, batch273/1133, batch loss:0.8343127965927124, Training time:996.2538006305695
batch reward last col mean 0.349561870098114 first col mean 0.35488831996917725 all mean 0.352059006690979
0.9199981689453125 0.9199981689453125
rl training, epoch0, iter0, batch274/1133, batch loss:0.9199981689453125, Training time:1010.1378939151764
batch reward last col mean 0.36666083335876465 first col mean 0.3389371335506439 all mean 0.3666810989379883
0.9594820141792297 0.9594820141792297
rl training, epoch0, iter0, batch275/1133, batch loss:0.9594820141792297, Training time:1021.4410622119904
batch reward last col mean 0.3119314908981323 first col mean 0.36274829506874084 all mean 0.31742769479751587
0.9066792130470276 0.9066792130470276
rl training, epoch0, iter0, batch276/1133, batch loss:0.9066792130470276, Training time:1037.3298001289368
batch reward last col mean 0.33509111404418945 first col mean 0.3524712324142456 all mean 0.3366518020629883
0.9712069630622864 0.9712069630622864
rl training, epoch0, iter0, batch277/1133, batch loss:0.9712069630622864, Training time:1053.424204826355
batch reward last col mean 0.32765114307403564 first col mean 0.35094931721687317 all mean 0.32983699440956116
0.849794328212738 0.8497942090034485
rl training, epoch0, iter0, batch278/1133, batch loss:0.8497942090034485, Training time:1069.8492612838745
batch reward last col mean 0.31614720821380615 first col mean 0.3119313716888428 all mean 0.3180968463420868
0.8303698301315308 0.8303698301315308
rl training, epoch0, iter0, batch279/1133, batch loss:0.8303698301315308, Training time:1084.5733144283295
batch reward last col mean 0.3222614526748657 first col mean 0.3307943046092987 all mean 0.3289685547351837
0.8538427352905273 0.8538427352905273
rl training, epoch0, iter0, batch280/1133, batch loss:0.8538427352905273, Training time:1100.6820845603943
batch reward last col mean 0.29400140047073364 first col mean 0.3443451523780823 all mean 0.3017210066318512
0.8864961862564087 0.8864961862564087
rl training, epoch0, iter0, batch281/1133, batch loss:0.8864961862564087, Training time:1117.9075529575348
batch reward last col mean 0.3437371850013733 first col mean 0.3470384478569031 all mean 0.33969300985336304
0.8861343860626221 0.8861343860626221
rl training, epoch0, iter0, batch282/1133, batch loss:0.8861343860626221, Training time:1134.9920337200165
batch reward last col mean 0.3179118037223816 first col mean 0.3440864086151123 all mean 0.31602007150650024
0.8866918087005615 0.8866918087005615
rl training, epoch0, iter0, batch283/1133, batch loss:0.8866918087005615, Training time:1152.153579235077
batch reward last col mean 0.3554879426956177 first col mean 0.340053915977478 all mean 0.3570697009563446
0.9763489365577698 0.9763489365577698
rl training, epoch0, iter0, batch284/1133, batch loss:0.9763489365577698, Training time:1169.7993052005768
batch reward last col mean 0.3521689176559448 first col mean 0.3722972273826599 all mean 0.3514496088027954
0.9760082960128784 0.9760082364082336
rl training, epoch0, iter0, batch285/1133, batch loss:0.9760082364082336, Training time:1186.790268421173
batch reward last col mean 0.34441936016082764 first col mean 0.37264031171798706 all mean 0.3393319249153137
0.9280446171760559 0.9280446171760559
rl training, epoch0, iter0, batch286/1133, batch loss:0.9280446171760559, Training time:1204.3738856315613
batch reward last col mean 0.3228197991847992 first col mean 0.334041565656662 all mean 0.32573407888412476
0.8650853037834167 0.8650853037834167
rl training, epoch0, iter0, batch287/1133, batch loss:0.8650853037834167, Training time:1220.64142537117
batch reward last col mean 0.32300010323524475 first col mean 0.3347969651222229 all mean 0.32038193941116333
0.9132807850837708 0.9132807850837708
rl training, epoch0, iter0, batch288/1133, batch loss:0.9132807850837708, Training time:1238.1992626190186
batch reward last col mean 0.3800698220729828 first col mean 0.35684067010879517 all mean 0.37643054127693176
0.9461264610290527 0.9461264610290527
rl training, epoch0, iter0, batch289/1133, batch loss:0.9461264610290527, Training time:1254.6405375003815
batch reward last col mean 0.3787693679332733 first col mean 0.36407148838043213 all mean 0.3663560748100281
0.960500955581665 0.9605008959770203
rl training, epoch0, iter0, batch290/1133, batch loss:0.9605008959770203, Training time:1272.4215342998505
batch reward last col mean 0.36817634105682373 first col mean 0.36865782737731934 all mean 0.35997867584228516
1.0674853324890137 1.0674853324890137
rl training, epoch0, iter0, batch291/1133, batch loss:1.0674853324890137, Training time:1290.2485246658325
batch reward last col mean 0.31711500883102417 first col mean 0.3658866286277771 all mean 0.3264569044113159
0.8878413438796997 0.8878412246704102
rl training, epoch0, iter0, batch292/1133, batch loss:0.8878412246704102, Training time:1306.0217905044556
batch reward last col mean 0.38732367753982544 first col mean 0.39635586738586426 all mean 0.3877827525138855
0.9858351349830627 0.9858351945877075
rl training, epoch0, iter0, batch293/1133, batch loss:0.9858351945877075, Training time:1323.8912899494171
batch reward last col mean 0.39700448513031006 first col mean 0.3857075572013855 all mean 0.3917972147464752
0.968648374080658 0.9686484932899475
rl training, epoch0, iter0, batch294/1133, batch loss:0.9686484932899475, Training time:1340.90452003479
batch reward last col mean 0.3654831647872925 first col mean 0.3748674988746643 all mean 0.3656763434410095
0.9821351766586304 0.9821351766586304
rl training, epoch0, iter0, batch295/1133, batch loss:0.9821351766586304, Training time:1358.630880355835
batch reward last col mean 0.32295888662338257 first col mean 0.3816763162612915 all mean 0.3290207087993622
0.9022864103317261 0.9022864103317261
rl training, epoch0, iter0, batch296/1133, batch loss:0.9022864103317261, Training time:1375.8341979980469
batch reward last col mean 0.3066844046115875 first col mean 0.3169757127761841 all mean 0.31558915972709656
0.8642863631248474 0.8642863631248474
rl training, epoch0, iter0, batch297/1133, batch loss:0.8642863631248474, Training time:1393.2302813529968
batch reward last col mean 0.3901788890361786 first col mean 0.37002143263816833 all mean 0.39522692561149597
1.0413992404937744 1.0413992404937744
rl training, epoch0, iter0, batch298/1133, batch loss:1.0413992404937744, Training time:1410.5280621051788
batch reward last col mean 0.3854149878025055 first col mean 0.4014890193939209 all mean 0.38391023874282837
1.0521178245544434 1.0521178245544434
rl training, epoch0, iter0, batch299/1133, batch loss:1.0521178245544434, Training time:1427.9864785671234
batch reward last col mean 0.3349422812461853 first col mean 0.35074949264526367 all mean 0.3391501307487488
0.8889326453208923 0.8889326453208923
rl training, epoch0, iter0, batch300/1133, batch loss:0.8889326453208923, Training time:1445.0192880630493
batch reward last col mean 0.34928569197654724 first col mean 0.35572266578674316 all mean 0.35272544622421265
0.9827380776405334 0.9827380776405334
rl training, epoch0, iter0, batch301/1133, batch loss:0.9827380776405334, Training time:1461.6465940475464
batch reward last col mean 0.33819055557250977 first col mean 0.35463207960128784 all mean 0.3391766846179962
0.9206631183624268 0.9206631183624268
rl training, epoch0, iter0, batch302/1133, batch loss:0.9206631183624268, Training time:1479.2041523456573
batch reward last col mean 0.32054051756858826 first col mean 0.33677101135253906 all mean 0.31984516978263855
0.9307267665863037 0.9307267665863037
rl training, epoch0, iter0, batch303/1133, batch loss:0.9307267665863037, Training time:1493.25536775589
batch reward last col mean 0.36088675260543823 first col mean 0.3445684611797333 all mean 0.36351871490478516
0.94081711769104 0.94081711769104
rl training, epoch0, iter0, batch304/1133, batch loss:0.94081711769104, Training time:1512.7147834300995
batch reward last col mean 0.34786128997802734 first col mean 0.31175801157951355 all mean 0.3388347327709198
0.9287064075469971 0.9287064075469971
rl training, epoch0, iter0, batch305/1133, batch loss:0.9287064075469971, Training time:1530.122136592865
batch reward last col mean 0.35201507806777954 first col mean 0.3766985237598419 all mean 0.35324737429618835
0.8795634508132935 0.8795634508132935
rl training, epoch0, iter0, batch306/1133, batch loss:0.8795634508132935, Training time:1547.291276216507
batch reward last col mean 0.37275761365890503 first col mean 0.35618287324905396 all mean 0.37340137362480164
0.8899850845336914 0.8899850845336914
rl training, epoch0, iter0, batch307/1133, batch loss:0.8899850845336914, Training time:1564.2748301029205
batch reward last col mean 0.3514379560947418 first col mean 0.34172967076301575 all mean 0.3483348786830902
0.967627227306366 0.967627227306366
rl training, epoch0, iter0, batch308/1133, batch loss:0.967627227306366, Training time:1581.2940421104431
batch reward last col mean 0.37723734974861145 first col mean 0.358358770608902 all mean 0.3793450593948364
1.0650675296783447 1.0650675296783447
rl training, epoch0, iter0, batch309/1133, batch loss:1.0650675296783447, Training time:1596.5244081020355
batch reward last col mean 0.3452342748641968 first col mean 0.37609004974365234 all mean 0.3438241481781006
0.9612500071525574 0.9612499475479126
rl training, epoch0, iter0, batch310/1133, batch loss:0.9612499475479126, Training time:1613.6835379600525
batch reward last col mean 0.3894656300544739 first col mean 0.39418619871139526 all mean 0.39341384172439575
1.0884010791778564 1.0884010791778564
rl training, epoch0, iter0, batch311/1133, batch loss:1.0884010791778564, Training time:1629.3039457798004
batch reward last col mean 0.34178638458251953 first col mean 0.3620200753211975 all mean 0.337430477142334
0.9603583812713623 0.9603582620620728
rl training, epoch0, iter0, batch312/1133, batch loss:0.9603582620620728, Training time:1645.3005347251892
batch reward last col mean 0.2898584008216858 first col mean 0.3382760286331177 all mean 0.2981160879135132
0.8948386311531067 0.8948386311531067
rl training, epoch0, iter0, batch313/1133, batch loss:0.8948386311531067, Training time:1660.9586036205292
batch reward last col mean 0.37502363324165344 first col mean 0.37184154987335205 all mean 0.37524551153182983
1.0166540145874023 1.0166540145874023
rl training, epoch0, iter0, batch314/1133, batch loss:1.0166540145874023, Training time:1676.0399096012115
batch reward last col mean 0.3634859025478363 first col mean 0.36459779739379883 all mean 0.3632969558238983
0.9741603136062622 0.9741603136062622
rl training, epoch0, iter0, batch315/1133, batch loss:0.9741603136062622, Training time:1690.7570464611053
batch reward last col mean 0.40026789903640747 first col mean 0.36113184690475464 all mean 0.39920663833618164
0.9457870721817017 0.9457870721817017
rl training, epoch0, iter0, batch316/1133, batch loss:0.9457870721817017, Training time:1708.63574552536
batch reward last col mean 0.33200961351394653 first col mean 0.3523978590965271 all mean 0.3338965177536011
0.9612712264060974 0.9612712264060974
rl training, epoch0, iter0, batch317/1133, batch loss:0.9612712264060974, Training time:1725.918066740036
batch reward last col mean 0.34341639280319214 first col mean 0.37697020173072815 all mean 0.34695565700531006
0.9317399263381958 0.9317400455474854
rl training, epoch0, iter0, batch318/1133, batch loss:0.9317400455474854, Training time:1744.8184583187103
batch reward last col mean 0.34450238943099976 first col mean 0.3341253101825714 all mean 0.3445771336555481
0.8553844094276428 0.855384349822998
rl training, epoch0, iter0, batch319/1133, batch loss:0.855384349822998, Training time:1762.5181484222412
batch reward last col mean 0.3727301359176636 first col mean 0.33943623304367065 all mean 0.3626764416694641
0.8440085053443909 0.8440083861351013
rl training, epoch0, iter0, batch320/1133, batch loss:0.8440083861351013, Training time:1779.9977774620056
batch reward last col mean 0.2974209189414978 first col mean 0.3293861150741577 all mean 0.3019927740097046
0.8587204813957214 0.8587204813957214
rl training, epoch0, iter0, batch321/1133, batch loss:0.8587204813957214, Training time:1798.3524751663208
batch reward last col mean 0.38153401017189026 first col mean 0.38941699266433716 all mean 0.3784387707710266
1.0471452474594116 1.0471452474594116
rl training, epoch0, iter0, batch322/1133, batch loss:1.0471452474594116, Training time:1815.9588220119476
batch reward last col mean 0.3926427364349365 first col mean 0.38832005858421326 all mean 0.3900815546512604
1.0505675077438354 1.0505675077438354
rl training, epoch0, iter0, batch323/1133, batch loss:1.0505675077438354, Training time:1833.4701578617096
batch reward last col mean 0.38064372539520264 first col mean 0.37455159425735474 all mean 0.3833487629890442
0.8892096281051636 0.8892096281051636
rl training, epoch0, iter0, batch324/1133, batch loss:0.8892096281051636, Training time:1851.4847576618195
batch reward last col mean 0.37409740686416626 first col mean 0.37256044149398804 all mean 0.37554243206977844
1.006293535232544 1.006293535232544
rl training, epoch0, iter0, batch325/1133, batch loss:1.006293535232544, Training time:1869.4463930130005
batch reward last col mean 0.3304838538169861 first col mean 0.33198657631874084 all mean 0.33272841572761536
0.8526773452758789 0.8526773452758789
rl training, epoch0, iter0, batch326/1133, batch loss:0.8526773452758789, Training time:1887.3736567497253
batch reward last col mean 0.35628196597099304 first col mean 0.37689900398254395 all mean 0.35589608550071716
0.8371598124504089 0.8371598124504089
rl training, epoch0, iter0, batch327/1133, batch loss:0.8371598124504089, Training time:1905.0990953445435
batch reward last col mean 0.3778805136680603 first col mean 0.3449486792087555 all mean 0.3797600567340851
0.8932023644447327 0.8932023644447327
rl training, epoch0, iter0, batch328/1133, batch loss:0.8932023644447327, Training time:1922.9893617630005
batch reward last col mean 0.32599663734436035 first col mean 0.3480381965637207 all mean 0.3324935734272003
0.8011142611503601 0.8011142611503601
rl training, epoch0, iter0, batch329/1133, batch loss:0.8011142611503601, Training time:1940.7240808010101
batch reward last col mean 0.410148024559021 first col mean 0.37768515944480896 all mean 0.40789324045181274
0.898962676525116 0.898962676525116
rl training, epoch0, iter0, batch330/1133, batch loss:0.898962676525116, Training time:1959.5785701274872
batch reward last col mean 0.3295994997024536 first col mean 0.36737170815467834 all mean 0.3452322483062744
0.7926706075668335 0.7926706075668335
rl training, epoch0, iter0, batch331/1133, batch loss:0.7926706075668335, Training time:1979.5255117416382
batch reward last col mean 0.33852893114089966 first col mean 0.35203173756599426 all mean 0.35625696182250977
0.8680375814437866 0.8680375814437866
rl training, epoch0, iter0, batch332/1133, batch loss:0.8680375814437866, Training time:1997.5632753372192
batch reward last col mean 0.391453355550766 first col mean 0.38020551204681396 all mean 0.39216142892837524
0.8971312642097473 0.8971312642097473
rl training, epoch0, iter0, batch333/1133, batch loss:0.8971312642097473, Training time:2015.6151413917542
batch reward last col mean 0.3963698744773865 first col mean 0.3571329414844513 all mean 0.3845997452735901
0.8275582790374756 0.8275582790374756
rl training, epoch0, iter0, batch334/1133, batch loss:0.8275582790374756, Training time:2033.6646122932434
batch reward last col mean 0.3319183588027954 first col mean 0.38465580344200134 all mean 0.3594484031200409
0.8144146203994751 0.8144146203994751
rl training, epoch0, iter0, batch335/1133, batch loss:0.8144146203994751, Training time:2051.3865790367126
batch reward last col mean 0.3577243983745575 first col mean 0.36533430218696594 all mean 0.3671864867210388
0.788739025592804 0.7887389659881592
rl training, epoch0, iter0, batch336/1133, batch loss:0.7887389659881592, Training time:2069.134598493576
batch reward last col mean 0.48019033670425415 first col mean 0.4396933317184448 all mean 0.4652675986289978
0.9165348410606384 0.9165348410606384
rl training, epoch0, iter0, batch337/1133, batch loss:0.9165348410606384, Training time:2086.9419960975647
batch reward last col mean 0.4228293001651764 first col mean 0.46635282039642334 all mean 0.44721418619155884
0.8517965078353882 0.8517965078353882
rl training, epoch0, iter0, batch338/1133, batch loss:0.8517965078353882, Training time:2104.6921484470367
batch reward last col mean 0.43929657340049744 first col mean 0.4810737073421478 all mean 0.4603431820869446
0.866424024105072 0.8664240837097168
rl training, epoch0, iter0, batch339/1133, batch loss:0.8664240837097168, Training time:2122.7111546993256
batch reward last col mean 0.42571645975112915 first col mean 0.4529680013656616 all mean 0.4612700343132019
0.8606187105178833 0.8606187105178833
rl training, epoch0, iter0, batch340/1133, batch loss:0.8606187105178833, Training time:2140.6576809883118
batch reward last col mean 0.41582658886909485 first col mean 0.5166375041007996 all mean 0.4565620720386505
0.8403889536857605 0.8403889536857605
rl training, epoch0, iter0, batch341/1133, batch loss:0.8403889536857605, Training time:2158.5706963539124
batch reward last col mean 0.5131754279136658 first col mean 0.562810480594635 all mean 0.5481593012809753
0.8470692038536072 0.8470692038536072
rl training, epoch0, iter0, batch342/1133, batch loss:0.8470692038536072, Training time:2176.5021498203278
batch reward last col mean 0.5252740383148193 first col mean 0.5621514916419983 all mean 0.5713081955909729
0.8689912557601929 0.8689912557601929
rl training, epoch0, iter0, batch343/1133, batch loss:0.8689912557601929, Training time:2194.296483516693
batch reward last col mean 0.5813909769058228 first col mean 0.6625635027885437 all mean 0.6236116290092468
0.8363497853279114 0.8363497853279114
rl training, epoch0, iter0, batch344/1133, batch loss:0.8363497853279114, Training time:2212.153227329254
batch reward last col mean 0.5495072603225708 first col mean 0.6376010179519653 all mean 0.5790247917175293
0.7819899320602417 0.7819899320602417
rl training, epoch0, iter0, batch345/1133, batch loss:0.7819899320602417, Training time:2229.957779407501
batch reward last col mean 0.6303146481513977 first col mean 0.6566849946975708 all mean 0.6570371389389038
0.7942014932632446 0.7942014336585999
rl training, epoch0, iter0, batch346/1133, batch loss:0.7942014336585999, Training time:2247.7244052886963
batch reward last col mean 0.7035839557647705 first col mean 0.736894965171814 all mean 0.7223182320594788
0.7652150988578796 0.7652150392532349
rl training, epoch0, iter0, batch347/1133, batch loss:0.7652150392532349, Training time:2265.212381839752
batch reward last col mean 0.6560556888580322 first col mean 0.7169540524482727 all mean 0.6925174593925476
0.6915213465690613 0.6915213465690613
rl training, epoch0, iter0, batch348/1133, batch loss:0.6915213465690613, Training time:2283.4056000709534
batch reward last col mean 0.6888629794120789 first col mean 0.7371882200241089 all mean 0.7238396406173706
0.7152469754219055 0.7152469754219055
rl training, epoch0, iter0, batch349/1133, batch loss:0.7152469754219055, Training time:2300.884293317795
batch reward last col mean 0.693733274936676 first col mean 0.7321032881736755 all mean 0.7130035161972046
0.718201220035553 0.718201220035553
rl training, epoch0, iter0, batch350/1133, batch loss:0.718201220035553, Training time:2318.2369775772095
batch reward last col mean 0.7095924615859985 first col mean 0.7525063753128052 all mean 0.7398020625114441
0.6941008567810059 0.6941008567810059
rl training, epoch0, iter0, batch351/1133, batch loss:0.6941008567810059, Training time:2335.606740951538
batch reward last col mean 0.6957213282585144 first col mean 0.7518144845962524 all mean 0.7361035346984863
0.6777152419090271 0.6777151226997375
rl training, epoch0, iter0, batch352/1133, batch loss:0.6777151226997375, Training time:2352.8770706653595
batch reward last col mean 0.7095884084701538 first col mean 0.7533654570579529 all mean 0.7438217997550964
0.6523086428642273 0.6523086428642273
rl training, epoch0, iter0, batch353/1133, batch loss:0.6523086428642273, Training time:2370.1867406368256
batch reward last col mean 0.7501757740974426 first col mean 0.7455539703369141 all mean 0.7532175779342651
0.7069095969200134 0.7069095969200134
rl training, epoch0, iter0, batch354/1133, batch loss:0.7069095969200134, Training time:2387.4541013240814
batch reward last col mean 0.7680788040161133 first col mean 0.7873859405517578 all mean 0.7931503057479858
0.632965087890625 0.632965087890625
rl training, epoch0, iter0, batch355/1133, batch loss:0.632965087890625, Training time:2404.785407066345
batch reward last col mean 0.7525337338447571 first col mean 0.7808709740638733 all mean 0.7767617702484131
0.6367684602737427 0.6367684602737427
rl training, epoch0, iter0, batch356/1133, batch loss:0.6367684602737427, Training time:2422.2776057720184
batch reward last col mean 0.7868033051490784 first col mean 0.8100121021270752 all mean 0.7963619232177734
0.5887989401817322 0.5887989401817322
rl training, epoch0, iter0, batch357/1133, batch loss:0.5887989401817322, Training time:2439.6140625476837
batch reward last col mean 0.7738454341888428 first col mean 0.8201660513877869 all mean 0.7930290102958679
0.5814494490623474 0.5814494490623474
rl training, epoch0, iter0, batch358/1133, batch loss:0.5814494490623474, Training time:2456.8857119083405
batch reward last col mean 0.7558900117874146 first col mean 0.7865027189254761 all mean 0.7639796733856201
0.537533700466156 0.537533700466156
rl training, epoch0, iter0, batch359/1133, batch loss:0.537533700466156, Training time:2474.103731393814
batch reward last col mean 0.7649069428443909 first col mean 0.8280475735664368 all mean 0.7855051755905151
0.5571403503417969 0.5571403503417969
rl training, epoch0, iter0, batch360/1133, batch loss:0.5571403503417969, Training time:2491.533776283264
batch reward last col mean 0.7834442853927612 first col mean 0.84149569272995 all mean 0.7911316752433777
0.5358949303627014 0.5358949303627014
rl training, epoch0, iter0, batch361/1133, batch loss:0.5358949303627014, Training time:2508.853260755539
batch reward last col mean 0.8029566407203674 first col mean 0.8171259164810181 all mean 0.8027645945549011
0.5352185964584351 0.5352185964584351
rl training, epoch0, iter0, batch362/1133, batch loss:0.5352185964584351, Training time:2528.0097234249115
batch reward last col mean 0.8113603591918945 first col mean 0.7901585102081299 all mean 0.7938993573188782
0.5125027298927307 0.5125027298927307
rl training, epoch0, iter0, batch363/1133, batch loss:0.5125027298927307, Training time:2546.3451805114746
batch reward last col mean 0.8117320537567139 first col mean 0.7834473848342896 all mean 0.8032236099243164
0.5326773524284363 0.5326773524284363
rl training, epoch0, iter0, batch364/1133, batch loss:0.5326773524284363, Training time:2563.624678850174
batch reward last col mean 0.8074902892112732 first col mean 0.8529239892959595 all mean 0.8178412914276123
0.5682099461555481 0.5682099461555481
rl training, epoch0, iter0, batch365/1133, batch loss:0.5682099461555481, Training time:2580.885666370392
batch reward last col mean 0.8252437710762024 first col mean 0.8549213409423828 all mean 0.8380311727523804
0.5642563104629517 0.5642563104629517
rl training, epoch0, iter0, batch366/1133, batch loss:0.5642563104629517, Training time:2598.031312942505
batch reward last col mean 0.8198381662368774 first col mean 0.8353539705276489 all mean 0.8421626091003418
0.5446311235427856 0.5446311235427856
rl training, epoch0, iter0, batch367/1133, batch loss:0.5446311235427856, Training time:2615.1792385578156
batch reward last col mean 0.8453550338745117 first col mean 0.8382775783538818 all mean 0.8614007234573364
0.581360936164856 0.581360936164856
rl training, epoch0, iter0, batch368/1133, batch loss:0.581360936164856, Training time:2632.458240509033
batch reward last col mean 0.7880973815917969 first col mean 0.8117303848266602 all mean 0.7971487045288086
0.6385524868965149 0.6385524868965149
rl training, epoch0, iter0, batch369/1133, batch loss:0.6385524868965149, Training time:2649.5985522270203
batch reward last col mean 0.747256875038147 first col mean 0.8084439039230347 all mean 0.7806150913238525
0.6361411213874817 0.6361411213874817
rl training, epoch0, iter0, batch370/1133, batch loss:0.6361411213874817, Training time:2666.9368069171906
batch reward last col mean 0.6729915142059326 first col mean 0.7587097883224487 all mean 0.7196152806282043
0.6079407334327698 0.6079407334327698
rl training, epoch0, iter0, batch371/1133, batch loss:0.6079407334327698, Training time:2684.10510802269
batch reward last col mean 0.7469273805618286 first col mean 0.7998442649841309 all mean 0.7789605855941772
0.5989761352539062 0.5989761352539062
rl training, epoch0, iter0, batch372/1133, batch loss:0.5989761352539062, Training time:2701.430513858795
batch reward last col mean 0.8117942810058594 first col mean 0.8459219336509705 all mean 0.8287508487701416
0.6429954767227173 0.6429954767227173
rl training, epoch0, iter0, batch373/1133, batch loss:0.6429954767227173, Training time:2718.5230317115784
batch reward last col mean 0.7639705538749695 first col mean 0.8033266067504883 all mean 0.7749797701835632
0.6015211939811707 0.6015211939811707
rl training, epoch0, iter0, batch374/1133, batch loss:0.6015211939811707, Training time:2736.074106693268
batch reward last col mean 0.803138017654419 first col mean 0.8416956663131714 all mean 0.8158034682273865
0.5730665326118469 0.5730665922164917
rl training, epoch0, iter0, batch375/1133, batch loss:0.5730665922164917, Training time:2753.2041668891907
batch reward last col mean 0.7958094477653503 first col mean 0.830790102481842 all mean 0.8175879716873169
0.5836223363876343 0.5836223363876343
rl training, epoch0, iter0, batch376/1133, batch loss:0.5836223363876343, Training time:2770.3440911769867
batch reward last col mean 0.8347533941268921 first col mean 0.8350778818130493 all mean 0.8540282845497131
0.5217961072921753 0.5217961072921753
rl training, epoch0, iter0, batch377/1133, batch loss:0.5217961072921753, Training time:2787.4606006145477
batch reward last col mean 0.8466648459434509 first col mean 0.8102993965148926 all mean 0.8293907046318054
0.4804005026817322 0.4804005026817322
rl training, epoch0, iter0, batch378/1133, batch loss:0.4804005026817322, Training time:2804.9237728118896
batch reward last col mean 0.8478747606277466 first col mean 0.8352600336074829 all mean 0.8481308221817017
0.4553182125091553 0.4553182125091553
rl training, epoch0, iter0, batch379/1133, batch loss:0.4553182125091553, Training time:2822.1613969802856
batch reward last col mean 0.847830057144165 first col mean 0.8136711716651917 all mean 0.8312287926673889
0.47714561223983765 0.47714561223983765
rl training, epoch0, iter0, batch380/1133, batch loss:0.47714561223983765, Training time:2839.368371963501
batch reward last col mean 0.8304702639579773 first col mean 0.8232010006904602 all mean 0.8249078392982483
0.42122378945350647 0.42122378945350647
rl training, epoch0, iter0, batch381/1133, batch loss:0.42122378945350647, Training time:2856.5215995311737
batch reward last col mean 0.8263684511184692 first col mean 0.8493467569351196 all mean 0.8341366052627563
0.4241543710231781 0.4241543412208557
rl training, epoch0, iter0, batch382/1133, batch loss:0.4241543412208557, Training time:2873.729613304138
batch reward last col mean 0.8527189493179321 first col mean 0.8181635737419128 all mean 0.8147507309913635
0.3952152132987976 0.3952152132987976
rl training, epoch0, iter0, batch383/1133, batch loss:0.3952152132987976, Training time:2890.9439754486084
batch reward last col mean 0.8506590127944946 first col mean 0.8374769687652588 all mean 0.8451945781707764
0.40959393978118896 0.40959396958351135
rl training, epoch0, iter0, batch384/1133, batch loss:0.40959396958351135, Training time:2908.2643897533417
batch reward last col mean 0.8597457408905029 first col mean 0.8172445893287659 all mean 0.8350184559822083
0.38062432408332825 0.38062432408332825
rl training, epoch0, iter0, batch385/1133, batch loss:0.38062432408332825, Training time:2925.4301199913025
batch reward last col mean 0.832292914390564 first col mean 0.8001355528831482 all mean 0.8134970664978027
0.40157249569892883 0.40157249569892883
rl training, epoch0, iter0, batch386/1133, batch loss:0.40157249569892883, Training time:2942.696766138077
batch reward last col mean 0.8336030840873718 first col mean 0.8229491710662842 all mean 0.8158155679702759
0.39493054151535034 0.39493054151535034
rl training, epoch0, iter0, batch387/1133, batch loss:0.39493054151535034, Training time:2962.0975024700165
batch reward last col mean 0.8687105178833008 first col mean 0.8333597183227539 all mean 0.8437846899032593
0.3984008729457855 0.3984008729457855
rl training, epoch0, iter0, batch388/1133, batch loss:0.3984008729457855, Training time:2981.1937198638916
batch reward last col mean 0.8699887990951538 first col mean 0.8410735726356506 all mean 0.842248797416687
0.3786628246307373 0.3786628246307373
rl training, epoch0, iter0, batch389/1133, batch loss:0.3786628246307373, Training time:2998.428968191147
batch reward last col mean 0.8124762177467346 first col mean 0.819708526134491 all mean 0.8011044859886169
0.3748338222503662 0.3748338222503662
rl training, epoch0, iter0, batch390/1133, batch loss:0.3748338222503662, Training time:3015.620542526245
batch reward last col mean 0.893566906452179 first col mean 0.8450985550880432 all mean 0.8667179346084595
0.39317137002944946 0.39317142963409424
rl training, epoch0, iter0, batch391/1133, batch loss:0.39317142963409424, Training time:3032.6813173294067
batch reward last col mean 0.8429510593414307 first col mean 0.8266409039497375 all mean 0.8348830938339233
0.424762487411499 0.424762487411499
rl training, epoch0, iter0, batch392/1133, batch loss:0.424762487411499, Training time:3049.9665961265564
batch reward last col mean 0.8473443984985352 first col mean 0.8319494724273682 all mean 0.8302457332611084
0.3999151885509491 0.3999151885509491
rl training, epoch0, iter0, batch393/1133, batch loss:0.3999151885509491, Training time:3067.098981618881
batch reward last col mean 0.8189280033111572 first col mean 0.8350242376327515 all mean 0.8203897476196289
0.4129728674888611 0.4129728674888611
rl training, epoch0, iter0, batch394/1133, batch loss:0.4129728674888611, Training time:3084.2191038131714
batch reward last col mean 0.8689351081848145 first col mean 0.8361721634864807 all mean 0.8425816893577576
0.3943334221839905 0.3943334221839905
rl training, epoch0, iter0, batch395/1133, batch loss:0.3943334221839905, Training time:3101.658417224884
batch reward last col mean 0.8452460169792175 first col mean 0.8269009590148926 all mean 0.823828399181366
0.4206908643245697 0.4206908345222473
rl training, epoch0, iter0, batch396/1133, batch loss:0.4206908345222473, Training time:3118.929879426956
batch reward last col mean 0.867445170879364 first col mean 0.8714230060577393 all mean 0.8566030859947205
0.4479629695415497 0.4479629695415497
rl training, epoch0, iter0, batch397/1133, batch loss:0.4479629695415497, Training time:3136.141528367996
batch reward last col mean 0.8764568567276001 first col mean 0.8514344692230225 all mean 0.8522725701332092
0.41474950313568115 0.41474950313568115
rl training, epoch0, iter0, batch398/1133, batch loss:0.41474950313568115, Training time:3153.522255897522
batch reward last col mean 0.8639048337936401 first col mean 0.8689663410186768 all mean 0.8672860860824585
0.4536270797252655 0.4536270797252655
rl training, epoch0, iter0, batch399/1133, batch loss:0.4536270797252655, Training time:3170.7859406471252
batch reward last col mean 0.8272177577018738 first col mean 0.8340733051300049 all mean 0.8305827379226685
0.4470066726207733 0.44700661301612854
rl training, epoch0, iter0, batch400/1133, batch loss:0.44700661301612854, Training time:3189.2656457424164
batch reward last col mean 0.8139861226081848 first col mean 0.7939960360527039 all mean 0.803627073764801
0.4695497155189514 0.4695497155189514
rl training, epoch0, iter0, batch401/1133, batch loss:0.4695497155189514, Training time:3208.2759368419647
batch reward last col mean 0.8516668677330017 first col mean 0.8445375561714172 all mean 0.8417401313781738
0.4849468767642975 0.4849468767642975
rl training, epoch0, iter0, batch402/1133, batch loss:0.4849468767642975, Training time:3225.469671010971
batch reward last col mean 0.8784286975860596 first col mean 0.892750084400177 all mean 0.8728653192520142
0.4714497923851013 0.4714497923851013
rl training, epoch0, iter0, batch403/1133, batch loss:0.4714497923851013, Training time:3242.638367176056
batch reward last col mean 0.8394732475280762 first col mean 0.8390922546386719 all mean 0.8354949355125427
0.48544934391975403 0.48544934391975403
rl training, epoch0, iter0, batch404/1133, batch loss:0.48544934391975403, Training time:3259.7749404907227
batch reward last col mean 0.8766393065452576 first col mean 0.875541627407074 all mean 0.867345929145813
0.4877045452594757 0.4877045452594757
rl training, epoch0, iter0, batch405/1133, batch loss:0.4877045452594757, Training time:3277.2614748477936
batch reward last col mean 0.895045816898346 first col mean 0.8986592292785645 all mean 0.8920595049858093
0.50932776927948 0.50932776927948
rl training, epoch0, iter0, batch406/1133, batch loss:0.50932776927948, Training time:3295.1285433769226
batch reward last col mean 0.8858674764633179 first col mean 0.885406494140625 all mean 0.8790649771690369
0.5104305148124695 0.5104305148124695
rl training, epoch0, iter0, batch407/1133, batch loss:0.5104305148124695, Training time:3312.292508840561
batch reward last col mean 0.8547566533088684 first col mean 0.83852219581604 all mean 0.8469382524490356
0.4978671073913574 0.4978671073913574
rl training, epoch0, iter0, batch408/1133, batch loss:0.4978671073913574, Training time:3329.6080224514008
batch reward last col mean 0.8668131232261658 first col mean 0.8528966307640076 all mean 0.8626364469528198
0.5268600583076477 0.5268600583076477
rl training, epoch0, iter0, batch409/1133, batch loss:0.5268600583076477, Training time:3346.8812510967255
batch reward last col mean 0.8588776588439941 first col mean 0.8571230173110962 all mean 0.8642803430557251
0.4819457530975342 0.4819457530975342
rl training, epoch0, iter0, batch410/1133, batch loss:0.4819457530975342, Training time:3364.005229949951
batch reward last col mean 0.8687294125556946 first col mean 0.8688051700592041 all mean 0.8637522459030151
0.5034655332565308 0.503465473651886
rl training, epoch0, iter0, batch411/1133, batch loss:0.503465473651886, Training time:3381.2384810447693
batch reward last col mean 0.887223482131958 first col mean 0.8853204846382141 all mean 0.8746384382247925
0.5168289542198181 0.5168289542198181
rl training, epoch0, iter0, batch412/1133, batch loss:0.5168289542198181, Training time:3398.443239212036
batch reward last col mean 0.8515537977218628 first col mean 0.8543927669525146 all mean 0.846106767654419
0.5145149230957031 0.5145150423049927
rl training, epoch0, iter0, batch413/1133, batch loss:0.5145150423049927, Training time:3415.693562746048
batch reward last col mean 0.8847123384475708 first col mean 0.8883891701698303 all mean 0.8910191059112549
0.5129913091659546 0.5129913091659546
rl training, epoch0, iter0, batch414/1133, batch loss:0.5129913091659546, Training time:3432.8233139514923
batch reward last col mean 0.8833508491516113 first col mean 0.880902886390686 all mean 0.8718051314353943
0.5278891921043396 0.5278891921043396
rl training, epoch0, iter0, batch415/1133, batch loss:0.5278891921043396, Training time:3450.0977799892426
batch reward last col mean 0.8681992292404175 first col mean 0.8884400129318237 all mean 0.8825236558914185
0.5134096741676331 0.5134096741676331
rl training, epoch0, iter0, batch416/1133, batch loss:0.5134096741676331, Training time:3467.4047889709473
batch reward last col mean 0.8835287094116211 first col mean 0.8756440281867981 all mean 0.8908213376998901
0.5279470682144165 0.5279470086097717
rl training, epoch0, iter0, batch417/1133, batch loss:0.5279470086097717, Training time:3484.6485636234283
batch reward last col mean 0.879635214805603 first col mean 0.8906772136688232 all mean 0.8836909532546997
0.5095199346542358 0.5095199346542358
rl training, epoch0, iter0, batch418/1133, batch loss:0.5095199346542358, Training time:3501.784673690796
batch reward last col mean 0.8881900906562805 first col mean 0.8893554210662842 all mean 0.8919253349304199
0.5444936752319336 0.5444936752319336
rl training, epoch0, iter0, batch419/1133, batch loss:0.5444936752319336, Training time:3518.940188407898
batch reward last col mean 0.875343382358551 first col mean 0.8672457337379456 all mean 0.8670839071273804
0.49900534749031067 0.49900534749031067
rl training, epoch0, iter0, batch420/1133, batch loss:0.49900534749031067, Training time:3536.0502438545227
batch reward last col mean 0.8938080072402954 first col mean 0.9000028371810913 all mean 0.8948051929473877
0.5192472338676453 0.5192472338676453
rl training, epoch0, iter0, batch421/1133, batch loss:0.5192472338676453, Training time:3553.194881916046
batch reward last col mean 0.8791040182113647 first col mean 0.8709039688110352 all mean 0.875999391078949
0.510505735874176 0.510505735874176
rl training, epoch0, iter0, batch422/1133, batch loss:0.510505735874176, Training time:3570.4536831378937
batch reward last col mean 0.8790875673294067 first col mean 0.8822463750839233 all mean 0.8859244585037231
0.5105230212211609 0.5105230212211609
rl training, epoch0, iter0, batch423/1133, batch loss:0.5105230212211609, Training time:3587.543151140213
batch reward last col mean 0.8942514657974243 first col mean 0.8895890712738037 all mean 0.895203173160553
0.5098850727081299 0.5098850727081299
rl training, epoch0, iter0, batch424/1133, batch loss:0.5098850727081299, Training time:3604.82919549942
batch reward last col mean 0.8833891749382019 first col mean 0.8967894911766052 all mean 0.8942618370056152
0.5046184062957764 0.5046184062957764
rl training, epoch0, iter0, batch425/1133, batch loss:0.5046184062957764, Training time:3621.9936468601227
batch reward last col mean 0.852298378944397 first col mean 0.8695247769355774 all mean 0.8602228760719299
0.5376722812652588 0.5376722812652588
rl training, epoch0, iter0, batch426/1133, batch loss:0.5376722812652588, Training time:3641.160015106201
batch reward last col mean 0.8864888548851013 first col mean 0.8956246972084045 all mean 0.8863317966461182
0.5617163777351379 0.5617163777351379
rl training, epoch0, iter0, batch427/1133, batch loss:0.5617163777351379, Training time:3658.432998895645
batch reward last col mean 0.8321923017501831 first col mean 0.8759478330612183 all mean 0.8558176755905151
0.57099449634552 0.5709944367408752
rl training, epoch0, iter0, batch428/1133, batch loss:0.5709944367408752, Training time:3675.7732198238373
batch reward last col mean 0.8407883644104004 first col mean 0.8850089311599731 all mean 0.8697327971458435
0.5648759007453918 0.5648759007453918
rl training, epoch0, iter0, batch429/1133, batch loss:0.5648759007453918, Training time:3694.6606991291046
batch reward last col mean 0.8729220628738403 first col mean 0.8774668574333191 all mean 0.8738608956336975
0.5790008306503296 0.5790008306503296
rl training, epoch0, iter0, batch430/1133, batch loss:0.5790008306503296, Training time:3711.7671353816986
batch reward last col mean 0.8452960848808289 first col mean 0.8829553127288818 all mean 0.8682706952095032
0.6061557531356812 0.6061557531356812
rl training, epoch0, iter0, batch431/1133, batch loss:0.6061557531356812, Training time:3729.032922267914
batch reward last col mean 0.7944043874740601 first col mean 0.8430521488189697 all mean 0.8154751658439636
0.5565422177314758 0.5565422177314758
rl training, epoch0, iter0, batch432/1133, batch loss:0.5565422177314758, Training time:3746.059030532837
batch reward last col mean 0.8269777894020081 first col mean 0.8575764298439026 all mean 0.8617022037506104
0.597805917263031 0.597805917263031
rl training, epoch0, iter0, batch433/1133, batch loss:0.597805917263031, Training time:3763.1402010917664
batch reward last col mean 0.8081924915313721 first col mean 0.8827947974205017 all mean 0.8597041964530945
0.5799717307090759 0.5799717307090759
rl training, epoch0, iter0, batch434/1133, batch loss:0.5799717307090759, Training time:3780.069314956665
batch reward last col mean 0.8367852568626404 first col mean 0.890564501285553 all mean 0.87920743227005
0.5970012545585632 0.5970012545585632
rl training, epoch0, iter0, batch435/1133, batch loss:0.5970012545585632, Training time:3796.995929002762
batch reward last col mean 0.806921660900116 first col mean 0.8562251925468445 all mean 0.8349790573120117
0.5836923718452454 0.5836923718452454
rl training, epoch0, iter0, batch436/1133, batch loss:0.5836923718452454, Training time:3814.2139983177185
batch reward last col mean 0.7818769812583923 first col mean 0.8555958271026611 all mean 0.8078083992004395
0.5728060603141785 0.5728060603141785
rl training, epoch0, iter0, batch437/1133, batch loss:0.5728060603141785, Training time:3832.997470140457
batch reward last col mean 0.7598349452018738 first col mean 0.8374384045600891 all mean 0.8032857775688171
0.5550286769866943 0.5550286769866943
rl training, epoch0, iter0, batch438/1133, batch loss:0.5550286769866943, Training time:3850.7185111045837
batch reward last col mean 0.7823276519775391 first col mean 0.8530072569847107 all mean 0.8294480443000793
0.5606235861778259 0.5606235861778259
rl training, epoch0, iter0, batch439/1133, batch loss:0.5606235861778259, Training time:3868.0135695934296
batch reward last col mean 0.7550026178359985 first col mean 0.8345726728439331 all mean 0.8160303235054016
0.5722630023956299 0.5722630023956299
rl training, epoch0, iter0, batch440/1133, batch loss:0.5722630023956299, Training time:3885.182635784149
batch reward last col mean 0.8149733543395996 first col mean 0.8708871603012085 all mean 0.8594701886177063
0.5635287761688232 0.5635287165641785
rl training, epoch0, iter0, batch441/1133, batch loss:0.5635287165641785, Training time:3902.6974313259125
batch reward last col mean 0.8262884616851807 first col mean 0.8728009462356567 all mean 0.8558632135391235
0.5612973570823669 0.5612973570823669
rl training, epoch0, iter0, batch442/1133, batch loss:0.5612973570823669, Training time:3919.8450050354004
batch reward last col mean 0.803408145904541 first col mean 0.8782635927200317 all mean 0.8461042642593384
0.5861073136329651 0.5861073136329651
rl training, epoch0, iter0, batch443/1133, batch loss:0.5861073136329651, Training time:3937.6148598194122
batch reward last col mean 0.8523388504981995 first col mean 0.9044055342674255 all mean 0.8894832134246826
0.5646528005599976 0.5646528005599976
rl training, epoch0, iter0, batch444/1133, batch loss:0.5646528005599976, Training time:3954.653508424759
batch reward last col mean 0.8278089165687561 first col mean 0.8680948615074158 all mean 0.8602542877197266
0.5575559735298157 0.5575559735298157
rl training, epoch0, iter0, batch445/1133, batch loss:0.5575559735298157, Training time:3971.7236824035645
batch reward last col mean 0.860191822052002 first col mean 0.8829028010368347 all mean 0.8802677989006042
0.5485995411872864 0.5485995411872864
rl training, epoch0, iter0, batch446/1133, batch loss:0.5485995411872864, Training time:3988.75333237648
batch reward last col mean 0.8691989779472351 first col mean 0.8934136629104614 all mean 0.8888665437698364
0.5026373863220215 0.5026373863220215
rl training, epoch0, iter0, batch447/1133, batch loss:0.5026373863220215, Training time:4005.676404237747
batch reward last col mean 0.8727579116821289 first col mean 0.9030788540840149 all mean 0.8984322547912598
0.5334137678146362 0.5334136486053467
rl training, epoch0, iter0, batch448/1133, batch loss:0.5334136486053467, Training time:4022.701130628586
batch reward last col mean 0.8497899174690247 first col mean 0.8444626927375793 all mean 0.8537580966949463
0.4554484486579895 0.4554484784603119
rl training, epoch0, iter0, batch449/1133, batch loss:0.4554484784603119, Training time:4039.6032757759094
batch reward last col mean 0.848349928855896 first col mean 0.8638229966163635 all mean 0.8582873344421387
0.46225953102111816 0.4622594714164734
rl training, epoch0, iter0, batch450/1133, batch loss:0.4622594714164734, Training time:4056.5804381370544
batch reward last col mean 0.8996174335479736 first col mean 0.8928512334823608 all mean 0.8886362910270691
0.44443702697753906 0.44443702697753906
rl training, epoch0, iter0, batch451/1133, batch loss:0.44443702697753906, Training time:4073.615248441696
batch reward last col mean 0.8775622248649597 first col mean 0.8673402070999146 all mean 0.8705481290817261
0.42931509017944336 0.42931509017944336
rl training, epoch0, iter0, batch452/1133, batch loss:0.42931509017944336, Training time:4090.8976640701294
batch reward last col mean 0.871070146560669 first col mean 0.8723703622817993 all mean 0.8637397289276123
0.3856637179851532 0.3856637477874756
rl training, epoch0, iter0, batch453/1133, batch loss:0.3856637477874756, Training time:4108.09104847908
batch reward last col mean 0.8682787418365479 first col mean 0.8615365624427795 all mean 0.8720090389251709
0.37042123079299927 0.37042123079299927
rl training, epoch0, iter0, batch454/1133, batch loss:0.37042123079299927, Training time:4127.067213773727
batch reward last col mean 0.8890860080718994 first col mean 0.8717045783996582 all mean 0.8750067949295044
0.34919506311416626 0.34919506311416626
rl training, epoch0, iter0, batch455/1133, batch loss:0.34919506311416626, Training time:4144.2981815338135
batch reward last col mean 0.8740714192390442 first col mean 0.8719000220298767 all mean 0.8812049031257629
0.3493053615093231 0.3493053615093231
rl training, epoch0, iter0, batch456/1133, batch loss:0.3493053615093231, Training time:4161.590374469757
batch reward last col mean 0.893569827079773 first col mean 0.8687413334846497 all mean 0.8745038509368896
0.33678925037384033 0.33678925037384033
rl training, epoch0, iter0, batch457/1133, batch loss:0.33678925037384033, Training time:4178.814884185791
batch reward last col mean 0.8991193175315857 first col mean 0.8640774488449097 all mean 0.8729619979858398
0.31182995438575745 0.31182995438575745
rl training, epoch0, iter0, batch458/1133, batch loss:0.31182995438575745, Training time:4195.980507850647
batch reward last col mean 0.8687528371810913 first col mean 0.8456634879112244 all mean 0.8577458262443542
0.2919858992099762 0.2919858992099762
rl training, epoch0, iter0, batch459/1133, batch loss:0.2919858992099762, Training time:4212.935605287552
batch reward last col mean 0.9023439884185791 first col mean 0.8729270696640015 all mean 0.8809077143669128
0.3287702202796936 0.3287702202796936
rl training, epoch0, iter0, batch460/1133, batch loss:0.3287702202796936, Training time:4229.925070285797
batch reward last col mean 0.8544518351554871 first col mean 0.8301345109939575 all mean 0.836608350276947
0.2992011606693268 0.2992011606693268
rl training, epoch0, iter0, batch461/1133, batch loss:0.2992011606693268, Training time:4246.922575950623
batch reward last col mean 0.8670144081115723 first col mean 0.8289451003074646 all mean 0.8372789025306702
0.27766767144203186 0.27766767144203186
rl training, epoch0, iter0, batch462/1133, batch loss:0.27766767144203186, Training time:4263.947471380234
batch reward last col mean 0.8585643768310547 first col mean 0.8352872729301453 all mean 0.843598484992981
0.27051693201065063 0.27051690220832825
rl training, epoch0, iter0, batch463/1133, batch loss:0.27051690220832825, Training time:4280.997912406921
batch reward last col mean 0.8632083535194397 first col mean 0.8434516191482544 all mean 0.8476364612579346
0.2670603096485138 0.2670603096485138
rl training, epoch0, iter0, batch464/1133, batch loss:0.2670603096485138, Training time:4297.993448495865
batch reward last col mean 0.8876615762710571 first col mean 0.8463491797447205 all mean 0.8597819209098816
0.27507293224334717 0.27507293224334717
rl training, epoch0, iter0, batch465/1133, batch loss:0.27507293224334717, Training time:4315.291372299194
batch reward last col mean 0.8501125574111938 first col mean 0.8064596652984619 all mean 0.8223361968994141
0.2494727522134781 0.24947276711463928
rl training, epoch0, iter0, batch466/1133, batch loss:0.24947276711463928, Training time:4332.504581451416
batch reward last col mean 0.8488249778747559 first col mean 0.823275089263916 all mean 0.8340620398521423
0.2757304012775421 0.2757304012775421
rl training, epoch0, iter0, batch467/1133, batch loss:0.2757304012775421, Training time:4349.6710460186005
batch reward last col mean 0.8705785274505615 first col mean 0.8459864854812622 all mean 0.8478571772575378
0.2602177560329437 0.2602177560329437
rl training, epoch0, iter0, batch468/1133, batch loss:0.2602177560329437, Training time:4366.878420114517
batch reward last col mean 0.9145601987838745 first col mean 0.8791595101356506 all mean 0.8864060044288635
0.26785334944725037 0.26785334944725037
rl training, epoch0, iter0, batch469/1133, batch loss:0.26785334944725037, Training time:4384.579816102982
batch reward last col mean 0.8347139358520508 first col mean 0.8085711598396301 all mean 0.815297544002533
0.25581350922584534 0.25581350922584534
rl training, epoch0, iter0, batch470/1133, batch loss:0.25581350922584534, Training time:4401.724097251892
batch reward last col mean 0.8294428586959839 first col mean 0.8089558482170105 all mean 0.8094650506973267
0.25667744874954224 0.25667744874954224
rl training, epoch0, iter0, batch471/1133, batch loss:0.25667744874954224, Training time:4420.696526050568
batch reward last col mean 0.877072274684906 first col mean 0.8349841237068176 all mean 0.8470394015312195
0.29405614733695984 0.29405614733695984
rl training, epoch0, iter0, batch472/1133, batch loss:0.29405614733695984, Training time:4437.78843331337
batch reward last col mean 0.8396099805831909 first col mean 0.8082214593887329 all mean 0.8189704418182373
0.24580416083335876 0.24580416083335876
rl training, epoch0, iter0, batch473/1133, batch loss:0.24580416083335876, Training time:4454.939793348312
batch reward last col mean 0.8791711926460266 first col mean 0.834430456161499 all mean 0.8532736897468567
0.27021560072898865 0.27021560072898865
rl training, epoch0, iter0, batch474/1133, batch loss:0.27021560072898865, Training time:4472.253958940506
batch reward last col mean 0.8152176737785339 first col mean 0.7932164669036865 all mean 0.7932296991348267
0.2291892170906067 0.2291892170906067
rl training, epoch0, iter0, batch475/1133, batch loss:0.2291892170906067, Training time:4489.322899580002
batch reward last col mean 0.8371745347976685 first col mean 0.8243618011474609 all mean 0.8212411403656006
0.2629237473011017 0.2629237473011017
rl training, epoch0, iter0, batch476/1133, batch loss:0.2629237473011017, Training time:4506.326341629028
batch reward last col mean 0.8871968984603882 first col mean 0.8540422916412354 all mean 0.8594217896461487
0.25177261233329773 0.25177261233329773
rl training, epoch0, iter0, batch477/1133, batch loss:0.25177261233329773, Training time:4523.44315123558
batch reward last col mean 0.8628191351890564 first col mean 0.8324766755104065 all mean 0.8410696387290955
0.24096953868865967 0.24096953868865967
rl training, epoch0, iter0, batch478/1133, batch loss:0.24096953868865967, Training time:4540.39781665802
batch reward last col mean 0.8801844120025635 first col mean 0.8569740653038025 all mean 0.8476223349571228
0.27224040031433105 0.27224037051200867
rl training, epoch0, iter0, batch479/1133, batch loss:0.27224037051200867, Training time:4557.415527820587
batch reward last col mean 0.8708261847496033 first col mean 0.811636209487915 all mean 0.8281807899475098
0.28032582998275757 0.2803258001804352
rl training, epoch0, iter0, batch480/1133, batch loss:0.2803258001804352, Training time:4574.388580799103
batch reward last col mean 0.8051415085792542 first col mean 0.7847685813903809 all mean 0.792977511882782
0.23733903467655182 0.23733901977539062
rl training, epoch0, iter0, batch481/1133, batch loss:0.23733901977539062, Training time:4591.599218606949
batch reward last col mean 0.8758294582366943 first col mean 0.852149486541748 all mean 0.8588671684265137
0.27961212396621704 0.27961212396621704
rl training, epoch0, iter0, batch482/1133, batch loss:0.27961212396621704, Training time:4608.635424852371
batch reward last col mean 0.8463935256004333 first col mean 0.8069408535957336 all mean 0.8160725831985474
0.2696841359138489 0.2696841359138489
rl training, epoch0, iter0, batch483/1133, batch loss:0.2696841359138489, Training time:4625.849015235901
batch reward last col mean 0.8717986941337585 first col mean 0.8197721242904663 all mean 0.829136073589325
0.2750391662120819 0.2750391662120819
rl training, epoch0, iter0, batch484/1133, batch loss:0.2750391662120819, Training time:4643.050661563873
batch reward last col mean 0.8792679309844971 first col mean 0.8478894233703613 all mean 0.8651636242866516
0.28581276535987854 0.28581276535987854
rl training, epoch0, iter0, batch485/1133, batch loss:0.28581276535987854, Training time:4660.232142210007
batch reward last col mean 0.8380210399627686 first col mean 0.8083963990211487 all mean 0.8166771531105042
0.2827327847480774 0.2827327847480774
rl training, epoch0, iter0, batch486/1133, batch loss:0.2827327847480774, Training time:4677.3991959095
batch reward last col mean 0.8899627923965454 first col mean 0.8744210600852966 all mean 0.8732137084007263
0.3234815001487732 0.3234815001487732
rl training, epoch0, iter0, batch487/1133, batch loss:0.3234815001487732, Training time:4694.5746166706085
batch reward last col mean 0.8820682764053345 first col mean 0.8641318082809448 all mean 0.8628063797950745
0.3163730204105377 0.3163730204105377
rl training, epoch0, iter0, batch488/1133, batch loss:0.3163730204105377, Training time:4711.752304792404
batch reward last col mean 0.8671369552612305 first col mean 0.8403741717338562 all mean 0.8458818197250366
0.3055095076560974 0.305509477853775
rl training, epoch0, iter0, batch489/1133, batch loss:0.305509477853775, Training time:4728.795469522476
batch reward last col mean 0.8892625570297241 first col mean 0.8722285628318787 all mean 0.8782628178596497
0.32957708835601807 0.32957708835601807
rl training, epoch0, iter0, batch490/1133, batch loss:0.32957708835601807, Training time:4746.056910037994
batch reward last col mean 0.8869264721870422 first col mean 0.8926773071289062 all mean 0.88444983959198
0.3500852882862091 0.3500852882862091
rl training, epoch0, iter0, batch491/1133, batch loss:0.3500852882862091, Training time:4763.236802816391
batch reward last col mean 0.881540834903717 first col mean 0.8554668426513672 all mean 0.8539154529571533
0.3140954077243805 0.3140954077243805
rl training, epoch0, iter0, batch492/1133, batch loss:0.3140954077243805, Training time:4780.349633932114
batch reward last col mean 0.8818329572677612 first col mean 0.8687649965286255 all mean 0.8636159896850586
0.3228205144405365 0.3228205144405365
rl training, epoch0, iter0, batch493/1133, batch loss:0.3228205144405365, Training time:4797.423843860626
batch reward last col mean 0.8630402088165283 first col mean 0.8625264763832092 all mean 0.8470525741577148
0.3248540759086609 0.3248540759086609
rl training, epoch0, iter0, batch494/1133, batch loss:0.3248540759086609, Training time:4814.549845457077
batch reward last col mean 0.9154576063156128 first col mean 0.880189061164856 all mean 0.8891509175300598
0.3626755177974701 0.3626755177974701
rl training, epoch0, iter0, batch495/1133, batch loss:0.3626755177974701, Training time:4831.64462685585
batch reward last col mean 0.8503270149230957 first col mean 0.8482027649879456 all mean 0.836371123790741
0.350917249917984 0.350917249917984
rl training, epoch0, iter0, batch496/1133, batch loss:0.350917249917984, Training time:4848.890250205994
batch reward last col mean 0.8999657034873962 first col mean 0.8875696063041687 all mean 0.8865863680839539
0.36297252774238586 0.36297252774238586
rl training, epoch0, iter0, batch497/1133, batch loss:0.36297252774238586, Training time:4867.875229358673
batch reward last col mean 0.9060016870498657 first col mean 0.8842251300811768 all mean 0.8814584612846375
0.3659943640232086 0.3659944236278534
rl training, epoch0, iter0, batch498/1133, batch loss:0.3659944236278534, Training time:4885.988929033279
batch reward last col mean 0.900965690612793 first col mean 0.8850184082984924 all mean 0.8868945837020874
0.35038742423057556 0.3503873944282532
rl training, epoch0, iter0, batch499/1133, batch loss:0.3503873944282532, Training time:4903.231969118118
batch reward last col mean 0.9092608690261841 first col mean 0.9002960920333862 all mean 0.9022079706192017
0.3750665783882141 0.3750665783882141
rl training, epoch0, iter0, batch500/1133, batch loss:0.3750665783882141, Training time:4920.2953951358795
batch reward last col mean 0.8767035007476807 first col mean 0.8586367964744568 all mean 0.8611317873001099
0.38169974088668823 0.38169974088668823
rl training, epoch0, iter0, batch501/1133, batch loss:0.38169974088668823, Training time:4937.372027873993
batch reward last col mean 0.8780596852302551 first col mean 0.875332236289978 all mean 0.8776995539665222
0.3970854580402374 0.3970854580402374
rl training, epoch0, iter0, batch502/1133, batch loss:0.3970854580402374, Training time:4954.38513302803
batch reward last col mean 0.8994745016098022 first col mean 0.889200747013092 all mean 0.8934030532836914
0.42826566100120544 0.42826566100120544
rl training, epoch0, iter0, batch503/1133, batch loss:0.42826566100120544, Training time:4971.335837841034
batch reward last col mean 0.8716622591018677 first col mean 0.8649981617927551 all mean 0.8714977502822876
0.3995887041091919 0.3995887041091919
rl training, epoch0, iter0, batch504/1133, batch loss:0.3995887041091919, Training time:4988.303029537201
batch reward last col mean 0.8987184166908264 first col mean 0.8913434743881226 all mean 0.8922524452209473
0.40024250745773315 0.40024250745773315
rl training, epoch0, iter0, batch505/1133, batch loss:0.40024250745773315, Training time:5006.655919551849
batch reward last col mean 0.8876564502716064 first col mean 0.8926226496696472 all mean 0.8846225738525391
0.43987739086151123 0.43987739086151123
rl training, epoch0, iter0, batch506/1133, batch loss:0.43987739086151123, Training time:5023.950907468796
batch reward last col mean 0.8863693475723267 first col mean 0.9008909463882446 all mean 0.9000657796859741
0.39688044786453247 0.3968804180622101
rl training, epoch0, iter0, batch507/1133, batch loss:0.3968804180622101, Training time:5040.992660522461
batch reward last col mean 0.8890926241874695 first col mean 0.8897202014923096 all mean 0.8928948044776917
0.40929967164993286 0.40929967164993286
rl training, epoch0, iter0, batch508/1133, batch loss:0.40929967164993286, Training time:5057.9734036922455
batch reward last col mean 0.8990070819854736 first col mean 0.8996933102607727 all mean 0.907569169998169
0.4012521207332611 0.40125206112861633
rl training, epoch0, iter0, batch509/1133, batch loss:0.40125206112861633, Training time:5075.340619087219
batch reward last col mean 0.8826831579208374 first col mean 0.8866010308265686 all mean 0.885739266872406
0.3666379451751709 0.3666379451751709
rl training, epoch0, iter0, batch510/1133, batch loss:0.3666379451751709, Training time:5092.468945741653
batch reward last col mean 0.8966965079307556 first col mean 0.9000632762908936 all mean 0.904384434223175
0.39758193492889404 0.39758193492889404
rl training, epoch0, iter0, batch511/1133, batch loss:0.39758193492889404, Training time:5109.796556711197
batch reward last col mean 0.8798850178718567 first col mean 0.882888913154602 all mean 0.8785366415977478
0.3835029602050781 0.3835029602050781
rl training, epoch0, iter0, batch512/1133, batch loss:0.3835029602050781, Training time:5126.977393627167
batch reward last col mean 0.9135560989379883 first col mean 0.89995938539505 all mean 0.9062646627426147
0.36720010638237 0.36720010638237
rl training, epoch0, iter0, batch513/1133, batch loss:0.36720010638237, Training time:5146.086810350418
batch reward last col mean 0.8795203566551208 first col mean 0.8819862604141235 all mean 0.8804389238357544
0.3502916693687439 0.3502916693687439
rl training, epoch0, iter0, batch514/1133, batch loss:0.3502916693687439, Training time:5163.233579874039
batch reward last col mean 0.8819403052330017 first col mean 0.8635720610618591 all mean 0.853810727596283
0.354250431060791 0.3542504608631134
rl training, epoch0, iter0, batch515/1133, batch loss:0.3542504608631134, Training time:5180.341214179993
batch reward last col mean 0.8901089429855347 first col mean 0.8890458941459656 all mean 0.8828679919242859
0.35639670491218567 0.35639670491218567
rl training, epoch0, iter0, batch516/1133, batch loss:0.35639670491218567, Training time:5197.342126369476
batch reward last col mean 0.866687536239624 first col mean 0.8353602886199951 all mean 0.8485302329063416
0.329635888338089 0.329635888338089
rl training, epoch0, iter0, batch517/1133, batch loss:0.329635888338089, Training time:5214.391262769699
batch reward last col mean 0.8490444421768188 first col mean 0.8202334642410278 all mean 0.8240869045257568
0.3079832196235657 0.3079832196235657
rl training, epoch0, iter0, batch518/1133, batch loss:0.3079832196235657, Training time:5231.421541452408
batch reward last col mean 0.861931324005127 first col mean 0.8319723606109619 all mean 0.8419630527496338
0.3331547677516937 0.33315473794937134
rl training, epoch0, iter0, batch519/1133, batch loss:0.33315473794937134, Training time:5248.750985860825
batch reward last col mean 0.8814350366592407 first col mean 0.866050660610199 all mean 0.8626630306243896
0.36415591835975647 0.36415591835975647
rl training, epoch0, iter0, batch520/1133, batch loss:0.36415591835975647, Training time:5266.02357339859
batch reward last col mean 0.8689063787460327 first col mean 0.8542165160179138 all mean 0.8597874641418457
0.35259687900543213 0.35259687900543213
rl training, epoch0, iter0, batch521/1133, batch loss:0.35259687900543213, Training time:5283.253523111343
batch reward last col mean 0.895065426826477 first col mean 0.8922163248062134 all mean 0.8846622109413147
0.36606186628341675 0.36606186628341675
rl training, epoch0, iter0, batch522/1133, batch loss:0.36606186628341675, Training time:5300.498173236847
batch reward last col mean 0.8912367820739746 first col mean 0.8663486242294312 all mean 0.8772097229957581
0.39084479212760925 0.39084479212760925
rl training, epoch0, iter0, batch523/1133, batch loss:0.39084479212760925, Training time:5318.131073474884
batch reward last col mean 0.915294885635376 first col mean 0.8950284123420715 all mean 0.8997074365615845
0.39530497789382935 0.39530497789382935
rl training, epoch0, iter0, batch524/1133, batch loss:0.39530497789382935, Training time:5335.307965517044
batch reward last col mean 0.8670926094055176 first col mean 0.8699665665626526 all mean 0.8647089600563049
0.4135444462299347 0.4135444462299347
rl training, epoch0, iter0, batch525/1133, batch loss:0.4135444462299347, Training time:5352.585500955582
batch reward last col mean 0.8864552974700928 first col mean 0.8645999431610107 all mean 0.8637980222702026
0.3842783570289612 0.38427838683128357
rl training, epoch0, iter0, batch526/1133, batch loss:0.38427838683128357, Training time:5369.762355804443
batch reward last col mean 0.8609144687652588 first col mean 0.8461211323738098 all mean 0.8436539173126221
0.4091254770755768 0.4091254770755768
rl training, epoch0, iter0, batch527/1133, batch loss:0.4091254770755768, Training time:5388.013855218887
batch reward last col mean 0.8787449598312378 first col mean 0.8924510478973389 all mean 0.8871640563011169
0.42810124158859253 0.42810124158859253
rl training, epoch0, iter0, batch528/1133, batch loss:0.42810124158859253, Training time:5407.043446063995
batch reward last col mean 0.8627014756202698 first col mean 0.8619884252548218 all mean 0.8598112463951111
0.41286134719848633 0.41286134719848633
rl training, epoch0, iter0, batch529/1133, batch loss:0.41286134719848633, Training time:5424.305740356445
batch reward last col mean 0.8947088718414307 first col mean 0.8938447833061218 all mean 0.8904963731765747
0.4300896227359772 0.4300896227359772
rl training, epoch0, iter0, batch530/1133, batch loss:0.4300896227359772, Training time:5441.49577832222
batch reward last col mean 0.8941221833229065 first col mean 0.8903221487998962 all mean 0.8966651558876038
0.4862440228462219 0.4862440228462219
rl training, epoch0, iter0, batch531/1133, batch loss:0.4862440228462219, Training time:5458.703961849213
batch reward last col mean 0.8787649869918823 first col mean 0.867231547832489 all mean 0.873321533203125
0.44186118245124817 0.4418611526489258
rl training, epoch0, iter0, batch532/1133, batch loss:0.4418611526489258, Training time:5475.93527007103
batch reward last col mean 0.8992385864257812 first col mean 0.8987820744514465 all mean 0.8967013955116272
0.46304476261138916 0.46304476261138916
rl training, epoch0, iter0, batch533/1133, batch loss:0.46304476261138916, Training time:5492.877405405045
batch reward last col mean 0.9271463751792908 first col mean 0.9204087257385254 all mean 0.9217754602432251
0.4855259656906128 0.4855259656906128
rl training, epoch0, iter0, batch534/1133, batch loss:0.4855259656906128, Training time:5509.79342508316
batch reward last col mean 0.8911401629447937 first col mean 0.8943849205970764 all mean 0.8873030543327332
0.4539661407470703 0.4539661407470703
rl training, epoch0, iter0, batch535/1133, batch loss:0.4539661407470703, Training time:5528.29621887207
batch reward last col mean 0.8561692237854004 first col mean 0.8516325950622559 all mean 0.8603573441505432
0.4476670026779175 0.4476670026779175
rl training, epoch0, iter0, batch536/1133, batch loss:0.4476670026779175, Training time:5547.389501094818
batch reward last col mean 0.8570886254310608 first col mean 0.8763561248779297 all mean 0.8745653629302979
0.4436216652393341 0.4436216652393341
rl training, epoch0, iter0, batch537/1133, batch loss:0.4436216652393341, Training time:5564.4731566905975
batch reward last col mean 0.8580647110939026 first col mean 0.889725923538208 all mean 0.8751391768455505
0.44566670060157776 0.44566670060157776
rl training, epoch0, iter0, batch538/1133, batch loss:0.44566670060157776, Training time:5581.627823114395
batch reward last col mean 0.8742780685424805 first col mean 0.8775522112846375 all mean 0.8775930404663086
0.4396483302116394 0.439648300409317
rl training, epoch0, iter0, batch539/1133, batch loss:0.439648300409317, Training time:5598.837686061859
batch reward last col mean 0.8928387761116028 first col mean 0.8882325887680054 all mean 0.8922029733657837
0.42510977387428284 0.42510977387428284
rl training, epoch0, iter0, batch540/1133, batch loss:0.42510977387428284, Training time:5616.051285028458
batch reward last col mean 0.8688799142837524 first col mean 0.8730593919754028 all mean 0.8675421476364136
0.4433121681213379 0.4433121681213379
rl training, epoch0, iter0, batch541/1133, batch loss:0.4433121681213379, Training time:5633.897174835205
batch reward last col mean 0.8757368922233582 first col mean 0.87529456615448 all mean 0.8855834603309631
0.43441665172576904 0.4344167113304138
rl training, epoch0, iter0, batch542/1133, batch loss:0.4344167113304138, Training time:5650.954058885574
batch reward last col mean 0.8976837396621704 first col mean 0.8743045330047607 all mean 0.879294216632843
0.425424724817276 0.4254247844219208
rl training, epoch0, iter0, batch543/1133, batch loss:0.4254247844219208, Training time:5668.047265052795
batch reward last col mean 0.9276313781738281 first col mean 0.9180643558502197 all mean 0.9158539175987244
0.41941842436790466 0.41941845417022705
rl training, epoch0, iter0, batch544/1133, batch loss:0.41941845417022705, Training time:5685.183267354965
batch reward last col mean 0.8793853521347046 first col mean 0.8741451501846313 all mean 0.8733786940574646
0.4045318365097046 0.4045318365097046
rl training, epoch0, iter0, batch545/1133, batch loss:0.4045318365097046, Training time:5702.247680425644
batch reward last col mean 0.8725557327270508 first col mean 0.8585290908813477 all mean 0.8604070544242859
0.4016248881816864 0.4016248881816864
rl training, epoch0, iter0, batch546/1133, batch loss:0.4016248881816864, Training time:5719.29097032547
batch reward last col mean 0.8780259490013123 first col mean 0.8603910803794861 all mean 0.8660006523132324
0.41504454612731934 0.41504454612731934
rl training, epoch0, iter0, batch547/1133, batch loss:0.41504454612731934, Training time:5736.590097427368
batch reward last col mean 0.8952078819274902 first col mean 0.8773637413978577 all mean 0.8844435214996338
0.41091710329055786 0.41091710329055786
rl training, epoch0, iter0, batch548/1133, batch loss:0.41091710329055786, Training time:5755.581892490387
batch reward last col mean 0.9131606221199036 first col mean 0.9086966514587402 all mean 0.9067575335502625
0.44272637367248535 0.44272637367248535
rl training, epoch0, iter0, batch549/1133, batch loss:0.44272637367248535, Training time:5772.524066209793
batch reward last col mean 0.8704770803451538 first col mean 0.845897912979126 all mean 0.8543553352355957
0.3932960331439972 0.3932960033416748
rl training, epoch0, iter0, batch550/1133, batch loss:0.3932960033416748, Training time:5789.411099433899
batch reward last col mean 0.89957195520401 first col mean 0.890202522277832 all mean 0.8905795216560364
0.4152762293815613 0.41527625918388367
rl training, epoch0, iter0, batch551/1133, batch loss:0.41527625918388367, Training time:5808.39582157135
batch reward last col mean 0.8933839797973633 first col mean 0.8944359421730042 all mean 0.8877566456794739
0.4218216836452484 0.4218216836452484
rl training, epoch0, iter0, batch552/1133, batch loss:0.4218216836452484, Training time:5825.325484752655
batch reward last col mean 0.8967241644859314 first col mean 0.8728113770484924 all mean 0.8757939338684082
0.4318438172340393 0.4318438172340393
rl training, epoch0, iter0, batch553/1133, batch loss:0.4318438172340393, Training time:5842.39030790329
batch reward last col mean 0.8882008194923401 first col mean 0.878119945526123 all mean 0.8768036365509033
0.41157978773117065 0.41157978773117065
rl training, epoch0, iter0, batch554/1133, batch loss:0.41157978773117065, Training time:5859.530556678772
batch reward last col mean 0.8675632476806641 first col mean 0.8675532341003418 all mean 0.8727911710739136
0.4339796006679535 0.4339796006679535
rl training, epoch0, iter0, batch555/1133, batch loss:0.4339796006679535, Training time:5876.606668949127
batch reward last col mean 0.9257127046585083 first col mean 0.9231090545654297 all mean 0.9245328307151794
0.4545072317123413 0.4545072317123413
rl training, epoch0, iter0, batch556/1133, batch loss:0.4545072317123413, Training time:5893.589541912079
batch reward last col mean 0.9045942425727844 first col mean 0.8999292850494385 all mean 0.8973233103752136
0.4481496512889862 0.4481496512889862
rl training, epoch0, iter0, batch557/1133, batch loss:0.4481496512889862, Training time:5910.698446273804
batch reward last col mean 0.9006873965263367 first col mean 0.9095998406410217 all mean 0.9085833430290222
0.44319531321525574 0.44319531321525574
rl training, epoch0, iter0, batch558/1133, batch loss:0.44319531321525574, Training time:5927.723332643509
batch reward last col mean 0.8948654532432556 first col mean 0.8968112468719482 all mean 0.8872299194335938
0.4648379683494568 0.4648379683494568
rl training, epoch0, iter0, batch559/1133, batch loss:0.4648379683494568, Training time:5944.88747549057
batch reward last col mean 0.8898180723190308 first col mean 0.8962534666061401 all mean 0.8974290490150452
0.4852786362171173 0.4852786362171173
rl training, epoch0, iter0, batch560/1133, batch loss:0.4852786362171173, Training time:5961.995188713074
batch reward last col mean 0.8900312781333923 first col mean 0.8940108418464661 all mean 0.8960662484169006
0.4686797857284546 0.4686797857284546
rl training, epoch0, iter0, batch561/1133, batch loss:0.4686797857284546, Training time:5979.136600494385
batch reward last col mean 0.8927699327468872 first col mean 0.8928363919258118 all mean 0.8883447647094727
0.43420886993408203 0.43420886993408203
rl training, epoch0, iter0, batch562/1133, batch loss:0.43420886993408203, Training time:5996.143297672272
batch reward last col mean 0.8786923885345459 first col mean 0.8982754945755005 all mean 0.8956235647201538
0.4574829041957855 0.4574829041957855
rl training, epoch0, iter0, batch563/1133, batch loss:0.4574829041957855, Training time:6013.1667149066925
batch reward last col mean 0.8628184795379639 first col mean 0.8722536563873291 all mean 0.8659518361091614
0.44299793243408203 0.4429979622364044
rl training, epoch0, iter0, batch564/1133, batch loss:0.4429979622364044, Training time:6030.207801103592
batch reward last col mean 0.8563648462295532 first col mean 0.8567692041397095 all mean 0.8542324900627136
0.4398159980773926 0.4398159980773926
rl training, epoch0, iter0, batch565/1133, batch loss:0.4398159980773926, Training time:6047.4182505607605
batch reward last col mean 0.8914695382118225 first col mean 0.8813307285308838 all mean 0.8786853551864624
0.4308604896068573 0.4308605492115021
rl training, epoch0, iter0, batch566/1133, batch loss:0.4308605492115021, Training time:6064.51561331749
batch reward last col mean 0.8885610103607178 first col mean 0.8850418925285339 all mean 0.879067599773407
0.4150223135948181 0.4150223135948181
rl training, epoch0, iter0, batch567/1133, batch loss:0.4150223135948181, Training time:6081.71785068512
batch reward last col mean 0.912264347076416 first col mean 0.8976161479949951 all mean 0.8978117108345032
0.4117177426815033 0.4117177426815033
rl training, epoch0, iter0, batch568/1133, batch loss:0.4117177426815033, Training time:6098.748658418655
batch reward last col mean 0.895422101020813 first col mean 0.8857808709144592 all mean 0.8852643966674805
0.41428080201148987 0.41428080201148987
rl training, epoch0, iter0, batch569/1133, batch loss:0.41428080201148987, Training time:6115.837416648865
batch reward last col mean 0.8994947075843811 first col mean 0.8927534818649292 all mean 0.8977231383323669
0.3835749626159668 0.3835749626159668
rl training, epoch0, iter0, batch570/1133, batch loss:0.3835749626159668, Training time:6132.9399037361145
batch reward last col mean 0.8939839601516724 first col mean 0.883686900138855 all mean 0.886884331703186
0.39495912194252014 0.39495912194252014
rl training, epoch0, iter0, batch571/1133, batch loss:0.39495912194252014, Training time:6149.962296247482
batch reward last col mean 0.8915451765060425 first col mean 0.8614058494567871 all mean 0.8624083995819092
0.3881963789463043 0.3881963789463043
rl training, epoch0, iter0, batch572/1133, batch loss:0.3881963789463043, Training time:6167.055744171143
batch reward last col mean 0.917980968952179 first col mean 0.8992068767547607 all mean 0.9018374085426331
0.38059160113334656 0.38059157133102417
rl training, epoch0, iter0, batch573/1133, batch loss:0.38059157133102417, Training time:6186.055405855179
batch reward last col mean 0.915093719959259 first col mean 0.9106642007827759 all mean 0.912567138671875
0.377055287361145 0.377055287361145
rl training, epoch0, iter0, batch574/1133, batch loss:0.377055287361145, Training time:6203.1910717487335
batch reward last col mean 0.9145092368125916 first col mean 0.8936232924461365 all mean 0.8988713026046753
0.385663777589798 0.385663777589798
rl training, epoch0, iter0, batch575/1133, batch loss:0.385663777589798, Training time:6220.2334315776825
batch reward last col mean 0.8723838329315186 first col mean 0.8694709539413452 all mean 0.8715830445289612
0.36884430050849915 0.36884430050849915
rl training, epoch0, iter0, batch576/1133, batch loss:0.36884430050849915, Training time:6237.135966539383
batch reward last col mean 0.8921027183532715 first col mean 0.8642637133598328 all mean 0.8695518374443054
0.3744814097881317 0.3744814097881317
rl training, epoch0, iter0, batch577/1133, batch loss:0.3744814097881317, Training time:6254.324912309647
batch reward last col mean 0.9043706655502319 first col mean 0.8930271863937378 all mean 0.897258460521698
0.3751511573791504 0.3751511573791504
rl training, epoch0, iter0, batch578/1133, batch loss:0.3751511573791504, Training time:6271.402812004089
batch reward last col mean 0.933271586894989 first col mean 0.8995769023895264 all mean 0.9101772308349609
0.3928566873073578 0.3928566873073578
rl training, epoch0, iter0, batch579/1133, batch loss:0.3928566873073578, Training time:6288.504784345627
batch reward last col mean 0.9204738736152649 first col mean 0.8951047658920288 all mean 0.9055584073066711
0.3770853579044342 0.3770853579044342
rl training, epoch0, iter0, batch580/1133, batch loss:0.3770853579044342, Training time:6305.610046386719
batch reward last col mean 0.8641307353973389 first col mean 0.8601544499397278 all mean 0.8456949591636658
0.37794849276542664 0.37794849276542664
rl training, epoch0, iter0, batch581/1133, batch loss:0.37794849276542664, Training time:6322.678654909134
batch reward last col mean 0.869638979434967 first col mean 0.8861693143844604 all mean 0.8776779770851135
0.4061352610588074 0.4061352610588074
rl training, epoch0, iter0, batch582/1133, batch loss:0.4061352610588074, Training time:6339.670490980148
batch reward last col mean 0.8786666989326477 first col mean 0.855039119720459 all mean 0.8578561544418335
0.3755352795124054 0.375535249710083
rl training, epoch0, iter0, batch583/1133, batch loss:0.375535249710083, Training time:6356.918615818024
batch reward last col mean 0.8604044914245605 first col mean 0.8524652123451233 all mean 0.8526817560195923
0.39277851581573486 0.39277851581573486
rl training, epoch0, iter0, batch584/1133, batch loss:0.39277851581573486, Training time:6374.085604429245
batch reward last col mean 0.933221161365509 first col mean 0.8999547958374023 all mean 0.9094932079315186
0.3829788863658905 0.3829788863658905
rl training, epoch0, iter0, batch585/1133, batch loss:0.3829788863658905, Training time:6390.960736036301
batch reward last col mean 0.8886234760284424 first col mean 0.8756558895111084 all mean 0.8804144263267517
0.4115253686904907 0.4115253686904907
rl training, epoch0, iter0, batch586/1133, batch loss:0.4115253686904907, Training time:6407.885463237762
batch reward last col mean 0.8893898725509644 first col mean 0.879704475402832 all mean 0.8796102404594421
0.40384694933891296 0.4038469195365906
rl training, epoch0, iter0, batch587/1133, batch loss:0.4038469195365906, Training time:6424.870312452316
batch reward last col mean 0.9049726724624634 first col mean 0.8929980993270874 all mean 0.8976471424102783
0.43377262353897095 0.43377262353897095
rl training, epoch0, iter0, batch588/1133, batch loss:0.43377262353897095, Training time:6441.829478740692
batch reward last col mean 0.8827050924301147 first col mean 0.8870714902877808 all mean 0.8823513984680176
0.386574387550354 0.386574387550354
rl training, epoch0, iter0, batch589/1133, batch loss:0.386574387550354, Training time:6459.008888959885
batch reward last col mean 0.9122650623321533 first col mean 0.905099630355835 all mean 0.9022254347801208
0.42381471395492554 0.42381468415260315
rl training, epoch0, iter0, batch590/1133, batch loss:0.42381468415260315, Training time:6478.084960460663
batch reward last col mean 0.8813349008560181 first col mean 0.8696333765983582 all mean 0.8689665198326111
0.40777069330215454 0.40777066349983215
rl training, epoch0, iter0, batch591/1133, batch loss:0.40777066349983215, Training time:6495.9573764801025
batch reward last col mean 0.9213428497314453 first col mean 0.9102491140365601 all mean 0.9154400825500488
0.3993821144104004 0.3993821144104004
rl training, epoch0, iter0, batch592/1133, batch loss:0.3993821144104004, Training time:6513.009680509567
batch reward last col mean 0.8909836411476135 first col mean 0.8711848258972168 all mean 0.8772544264793396
0.40416204929351807 0.40416204929351807
rl training, epoch0, iter0, batch593/1133, batch loss:0.40416204929351807, Training time:6530.322632312775
batch reward last col mean 0.9032250046730042 first col mean 0.8749262690544128 all mean 0.8870223164558411
0.41592949628829956 0.41592949628829956
rl training, epoch0, iter0, batch594/1133, batch loss:0.41592949628829956, Training time:6547.427048206329
batch reward last col mean 0.8799422383308411 first col mean 0.8682913780212402 all mean 0.8652323484420776
0.4455154836177826 0.4455154836177826
rl training, epoch0, iter0, batch595/1133, batch loss:0.4455154836177826, Training time:6564.637976646423
batch reward last col mean 0.9040392637252808 first col mean 0.8944980502128601 all mean 0.8936992883682251
0.43732306361198425 0.43732306361198425
rl training, epoch0, iter0, batch596/1133, batch loss:0.43732306361198425, Training time:6582.772403478622
batch reward last col mean 0.8920417428016663 first col mean 0.8822484612464905 all mean 0.8867907524108887
0.4211839437484741 0.4211839437484741
rl training, epoch0, iter0, batch597/1133, batch loss:0.4211839437484741, Training time:6599.951195478439
batch reward last col mean 0.8977630138397217 first col mean 0.8953148722648621 all mean 0.8950411081314087
0.40928202867507935 0.40928202867507935
rl training, epoch0, iter0, batch598/1133, batch loss:0.40928202867507935, Training time:6619.2815554142
batch reward last col mean 0.8831762075424194 first col mean 0.8813109397888184 all mean 0.885551929473877
0.4320661127567291 0.4320661425590515
rl training, epoch0, iter0, batch599/1133, batch loss:0.4320661425590515, Training time:6636.484041929245
batch reward last col mean 0.9071444869041443 first col mean 0.9130227565765381 all mean 0.9023284316062927
0.41748949885368347 0.41748949885368347
rl training, epoch0, iter0, batch600/1133, batch loss:0.41748949885368347, Training time:6653.626418352127
batch reward last col mean 0.8637357950210571 first col mean 0.8751811981201172 all mean 0.872582733631134
0.39668601751327515 0.39668598771095276
rl training, epoch0, iter0, batch601/1133, batch loss:0.39668598771095276, Training time:6670.7624707221985
batch reward last col mean 0.8916866779327393 first col mean 0.8777623772621155 all mean 0.8797723054885864
0.4134264886379242 0.4134264886379242
rl training, epoch0, iter0, batch602/1133, batch loss:0.4134264886379242, Training time:6687.851958990097
batch reward last col mean 0.9150098562240601 first col mean 0.900811493396759 all mean 0.8955546617507935
0.41508057713508606 0.41508057713508606
rl training, epoch0, iter0, batch603/1133, batch loss:0.41508057713508606, Training time:6705.004706859589
batch reward last col mean 0.8857944011688232 first col mean 0.897294819355011 all mean 0.8856432437896729
0.42231395840644836 0.42231395840644836
rl training, epoch0, iter0, batch604/1133, batch loss:0.42231395840644836, Training time:6722.001708507538
batch reward last col mean 0.9137046337127686 first col mean 0.9011868238449097 all mean 0.9045442342758179
0.41160961985588074 0.41160961985588074
rl training, epoch0, iter0, batch605/1133, batch loss:0.41160961985588074, Training time:6739.013404130936
batch reward last col mean 0.878279983997345 first col mean 0.8762039542198181 all mean 0.8832189440727234
0.4146605134010315 0.4146605134010315
rl training, epoch0, iter0, batch606/1133, batch loss:0.4146605134010315, Training time:6758.027692556381
batch reward last col mean 0.8963373303413391 first col mean 0.8906971216201782 all mean 0.8902387619018555
0.42729464173316956 0.42729467153549194
rl training, epoch0, iter0, batch607/1133, batch loss:0.42729467153549194, Training time:6775.160964250565
batch reward last col mean 0.8930501341819763 first col mean 0.894096851348877 all mean 0.8899503946304321
0.40535491704940796 0.40535491704940796
rl training, epoch0, iter0, batch608/1133, batch loss:0.40535491704940796, Training time:6792.333696603775
batch reward last col mean 0.8987123966217041 first col mean 0.9122375845909119 all mean 0.9034522175788879
0.4314914047718048 0.4314914047718048
rl training, epoch0, iter0, batch609/1133, batch loss:0.4314914047718048, Training time:6809.581157684326
batch reward last col mean 0.9226582050323486 first col mean 0.9200620651245117 all mean 0.9182688593864441
0.42103877663612366 0.42103877663612366
rl training, epoch0, iter0, batch610/1133, batch loss:0.42103877663612366, Training time:6827.015173196793
batch reward last col mean 0.8869308233261108 first col mean 0.8884214162826538 all mean 0.878376841545105
0.4181087613105774 0.4181087613105774
rl training, epoch0, iter0, batch611/1133, batch loss:0.4181087613105774, Training time:6844.15686249733
batch reward last col mean 0.9059911966323853 first col mean 0.8898112773895264 all mean 0.895173192024231
0.4372968375682831 0.4372968375682831
rl training, epoch0, iter0, batch612/1133, batch loss:0.4372968375682831, Training time:6862.557027339935
batch reward last col mean 0.9075509309768677 first col mean 0.9075033664703369 all mean 0.9012906551361084
0.4434244632720947 0.4434244632720947
rl training, epoch0, iter0, batch613/1133, batch loss:0.4434244632720947, Training time:6879.766947031021
batch reward last col mean 0.8932057023048401 first col mean 0.9034601449966431 all mean 0.9045534133911133
0.41391584277153015 0.41391584277153015
rl training, epoch0, iter0, batch614/1133, batch loss:0.41391584277153015, Training time:6896.8766441345215
batch reward last col mean 0.9234308004379272 first col mean 0.9222312569618225 all mean 0.9229233860969543
0.45500075817108154 0.45500075817108154
rl training, epoch0, iter0, batch615/1133, batch loss:0.45500075817108154, Training time:6914.000014066696
batch reward last col mean 0.8935644030570984 first col mean 0.896031379699707 all mean 0.8974157571792603
0.40918678045272827 0.40918678045272827
rl training, epoch0, iter0, batch616/1133, batch loss:0.40918678045272827, Training time:6931.003794908524
batch reward last col mean 0.8461500406265259 first col mean 0.8438460230827332 all mean 0.8501357436180115
0.3999003469944 0.3999003469944
rl training, epoch0, iter0, batch617/1133, batch loss:0.3999003469944, Training time:6948.024322509766
batch reward last col mean 0.8863967657089233 first col mean 0.8753073811531067 all mean 0.8760620951652527
0.4128507971763611 0.4128507971763611
rl training, epoch0, iter0, batch618/1133, batch loss:0.4128507971763611, Training time:6965.029569149017
batch reward last col mean 0.9120090007781982 first col mean 0.8984377384185791 all mean 0.8961958289146423
0.4088348150253296 0.4088348150253296
rl training, epoch0, iter0, batch619/1133, batch loss:0.4088348150253296, Training time:6982.03879237175
batch reward last col mean 0.8869268298149109 first col mean 0.894967794418335 all mean 0.8971039652824402
0.433918297290802 0.433918297290802
rl training, epoch0, iter0, batch620/1133, batch loss:0.433918297290802, Training time:6999.1373925209045
batch reward last col mean 0.924340009689331 first col mean 0.9060547947883606 all mean 0.9038999676704407
0.41024595499038696 0.41024595499038696
rl training, epoch0, iter0, batch621/1133, batch loss:0.41024595499038696, Training time:7016.333034038544
batch reward last col mean 0.8953412771224976 first col mean 0.8826217651367188 all mean 0.891112744808197
0.40894216299057007 0.40894216299057007
rl training, epoch0, iter0, batch622/1133, batch loss:0.40894216299057007, Training time:7033.5951817035675
batch reward last col mean 0.9252769947052002 first col mean 0.9141949415206909 all mean 0.9069565534591675
0.4197200536727905 0.4197200536727905
rl training, epoch0, iter0, batch623/1133, batch loss:0.4197200536727905, Training time:7050.837121486664
batch reward last col mean 0.8828729391098022 first col mean 0.8844302296638489 all mean 0.8796218633651733
0.40342697501182556 0.40342697501182556
rl training, epoch0, iter0, batch624/1133, batch loss:0.40342697501182556, Training time:7067.896625041962
batch reward last col mean 0.8965312242507935 first col mean 0.8811207413673401 all mean 0.8841198086738586
0.4001946449279785 0.4001946449279785
rl training, epoch0, iter0, batch625/1133, batch loss:0.4001946449279785, Training time:7084.972157716751
batch reward last col mean 0.8986344337463379 first col mean 0.9014755487442017 all mean 0.8996955156326294
0.40110763907432556 0.40110763907432556
rl training, epoch0, iter0, batch626/1133, batch loss:0.40110763907432556, Training time:7102.516292333603
batch reward last col mean 0.91617351770401 first col mean 0.8905742764472961 all mean 0.8986895084381104
0.4018123149871826 0.40181228518486023
rl training, epoch0, iter0, batch627/1133, batch loss:0.40181228518486023, Training time:7119.935646772385
batch reward last col mean 0.9081677198410034 first col mean 0.9102354049682617 all mean 0.9121946096420288
0.39546528458595276 0.39546528458595276
rl training, epoch0, iter0, batch628/1133, batch loss:0.39546528458595276, Training time:7137.003964662552
batch reward last col mean 0.9038558006286621 first col mean 0.8847125768661499 all mean 0.8872830271720886
0.3703837990760803 0.3703837990760803
rl training, epoch0, iter0, batch629/1133, batch loss:0.3703837990760803, Training time:7154.077463388443
batch reward last col mean 0.8888815641403198 first col mean 0.8497997522354126 all mean 0.8596150279045105
0.37309783697128296 0.37309783697128296
rl training, epoch0, iter0, batch630/1133, batch loss:0.37309783697128296, Training time:7172.5555872917175
batch reward last col mean 0.8853082060813904 first col mean 0.8809797763824463 all mean 0.8814828395843506
0.36682939529418945 0.36682939529418945
rl training, epoch0, iter0, batch631/1133, batch loss:0.36682939529418945, Training time:7189.606116294861
batch reward last col mean 0.9082112312316895 first col mean 0.898009181022644 all mean 0.8998781442642212
0.3687434494495392 0.3687434494495392
rl training, epoch0, iter0, batch632/1133, batch loss:0.3687434494495392, Training time:7206.636807918549
batch reward last col mean 0.9004555940628052 first col mean 0.8770827651023865 all mean 0.8836087584495544
0.35881760716438293 0.35881757736206055
rl training, epoch0, iter0, batch633/1133, batch loss:0.35881757736206055, Training time:7223.757541656494
batch reward last col mean 0.8843108415603638 first col mean 0.8753065466880798 all mean 0.8781943321228027
0.3377605080604553 0.3377605080604553
rl training, epoch0, iter0, batch634/1133, batch loss:0.3377605080604553, Training time:7240.826275348663
batch reward last col mean 0.8844188451766968 first col mean 0.8931008577346802 all mean 0.8907734155654907
0.3405793011188507 0.3405793011188507
rl training, epoch0, iter0, batch635/1133, batch loss:0.3405793011188507, Training time:7257.912831783295
batch reward last col mean 0.885475754737854 first col mean 0.8599944710731506 all mean 0.8693490028381348
0.35297685861587524 0.35297685861587524
rl training, epoch0, iter0, batch636/1133, batch loss:0.35297685861587524, Training time:7274.8408715724945
batch reward last col mean 0.8944330215454102 first col mean 0.8772822022438049 all mean 0.8819361925125122
0.361088365316391 0.3610883057117462
rl training, epoch0, iter0, batch637/1133, batch loss:0.3610883057117462, Training time:7291.861669063568
batch reward last col mean 0.8972600698471069 first col mean 0.8803701996803284 all mean 0.8813149929046631
0.3614567816257477 0.3614567816257477
rl training, epoch0, iter0, batch638/1133, batch loss:0.3614567816257477, Training time:7308.753962516785
batch reward last col mean 0.8675929307937622 first col mean 0.8543881773948669 all mean 0.8597016930580139
0.34152036905288696 0.34152036905288696
rl training, epoch0, iter0, batch639/1133, batch loss:0.34152036905288696, Training time:7325.5928111076355
batch reward last col mean 0.9077744483947754 first col mean 0.8899986147880554 all mean 0.8932809829711914
0.34134188294410706 0.34134188294410706
rl training, epoch0, iter0, batch640/1133, batch loss:0.34134188294410706, Training time:7342.580220460892
batch reward last col mean 0.8717801570892334 first col mean 0.8725119829177856 all mean 0.869470477104187
0.3438446819782257 0.3438446819782257
rl training, epoch0, iter0, batch641/1133, batch loss:0.3438446819782257, Training time:7359.500651836395
batch reward last col mean 0.8973346948623657 first col mean 0.8967033624649048 all mean 0.8992637991905212
0.36785823106765747 0.36785823106765747
rl training, epoch0, iter0, batch642/1133, batch loss:0.36785823106765747, Training time:7376.377871513367
batch reward last col mean 0.8515557050704956 first col mean 0.849657416343689 all mean 0.8494621515274048
0.3345884382724762 0.3345884382724762
rl training, epoch0, iter0, batch643/1133, batch loss:0.3345884382724762, Training time:7393.3739948272705
batch reward last col mean 0.9131858348846436 first col mean 0.8919509649276733 all mean 0.9003124237060547
0.3508440852165222 0.3508440852165222
rl training, epoch0, iter0, batch644/1133, batch loss:0.3508440852165222, Training time:7410.326560020447
batch reward last col mean 0.8989923596382141 first col mean 0.8698822259902954 all mean 0.875247061252594
0.3447476029396057 0.3447475731372833
rl training, epoch0, iter0, batch645/1133, batch loss:0.3447475731372833, Training time:7427.326313257217
batch reward last col mean 0.8799186944961548 first col mean 0.875214695930481 all mean 0.8797914385795593
0.3355480432510376 0.3355480432510376
rl training, epoch0, iter0, batch646/1133, batch loss:0.3355480432510376, Training time:7444.31352353096
batch reward last col mean 0.8926795721054077 first col mean 0.8911499977111816 all mean 0.8855375051498413
0.3472328782081604 0.3472328782081604
rl training, epoch0, iter0, batch647/1133, batch loss:0.3472328782081604, Training time:7461.204996347427
batch reward last col mean 0.8851746320724487 first col mean 0.8766095638275146 all mean 0.8755775094032288
0.3517172336578369 0.3517172336578369
rl training, epoch0, iter0, batch648/1133, batch loss:0.3517172336578369, Training time:7478.0999002456665
batch reward last col mean 0.8839171528816223 first col mean 0.8599075675010681 all mean 0.8608627319335938
0.3347814381122589 0.3347814381122589
rl training, epoch0, iter0, batch649/1133, batch loss:0.3347814381122589, Training time:7495.091095685959
batch reward last col mean 0.8553551435470581 first col mean 0.8363292813301086 all mean 0.8347406983375549
0.3039608597755432 0.3039608597755432
rl training, epoch0, iter0, batch650/1133, batch loss:0.3039608597755432, Training time:7512.0813047885895
batch reward last col mean 0.8794469237327576 first col mean 0.8445063233375549 all mean 0.8529776334762573
0.3189884424209595 0.3189884424209595
rl training, epoch0, iter0, batch651/1133, batch loss:0.3189884424209595, Training time:7529.338438034058
batch reward last col mean 0.8748865127563477 first col mean 0.8580266237258911 all mean 0.8623862266540527
0.34072956442832947 0.34072956442832947
rl training, epoch0, iter0, batch652/1133, batch loss:0.34072956442832947, Training time:7546.515393257141
batch reward last col mean 0.902878999710083 first col mean 0.8728699684143066 all mean 0.8757780194282532
0.30382436513900757 0.30382436513900757
rl training, epoch0, iter0, batch653/1133, batch loss:0.30382436513900757, Training time:7563.866307020187
batch reward last col mean 0.8735755085945129 first col mean 0.8474246263504028 all mean 0.8514654636383057
0.3127598762512207 0.3127598762512207
rl training, epoch0, iter0, batch654/1133, batch loss:0.3127598762512207, Training time:7581.705989599228
batch reward last col mean 0.8921030759811401 first col mean 0.8812868595123291 all mean 0.8778694272041321
0.3191927671432495 0.3191927671432495
rl training, epoch0, iter0, batch655/1133, batch loss:0.3191927671432495, Training time:7600.659460544586
batch reward last col mean 0.874354898929596 first col mean 0.8631209135055542 all mean 0.8605436086654663
0.3290400207042694 0.3290400207042694
rl training, epoch0, iter0, batch656/1133, batch loss:0.3290400207042694, Training time:7617.985644578934
batch reward last col mean 0.8650448322296143 first col mean 0.8517063856124878 all mean 0.8477450013160706
0.3282373547554016 0.3282373547554016
rl training, epoch0, iter0, batch657/1133, batch loss:0.3282373547554016, Training time:7635.147656917572
batch reward last col mean 0.8705926537513733 first col mean 0.8398370146751404 all mean 0.8448262810707092
0.33232706785202026 0.33232709765434265
rl training, epoch0, iter0, batch658/1133, batch loss:0.33232709765434265, Training time:7652.313792228699
batch reward last col mean 0.8954277634620667 first col mean 0.8825940489768982 all mean 0.8796581625938416
0.3611970841884613 0.3611970841884613
rl training, epoch0, iter0, batch659/1133, batch loss:0.3611970841884613, Training time:7669.577437400818
batch reward last col mean 0.8969549536705017 first col mean 0.8630414009094238 all mean 0.8698734045028687
0.3625801205635071 0.3625801205635071
rl training, epoch0, iter0, batch660/1133, batch loss:0.3625801205635071, Training time:7686.729954004288
batch reward last col mean 0.896388590335846 first col mean 0.8772064447402954 all mean 0.8866870999336243
0.3760800063610077 0.3760800063610077
rl training, epoch0, iter0, batch661/1133, batch loss:0.3760800063610077, Training time:7705.717773199081
batch reward last col mean 0.9111704230308533 first col mean 0.8815994262695312 all mean 0.8814520239830017
0.38354238867759705 0.38354238867759705
rl training, epoch0, iter0, batch662/1133, batch loss:0.38354238867759705, Training time:7722.840800285339
batch reward last col mean 0.8801781535148621 first col mean 0.8815602660179138 all mean 0.8654942512512207
0.3791502118110657 0.3791501820087433
rl training, epoch0, iter0, batch663/1133, batch loss:0.3791501820087433, Training time:7739.972699403763
batch reward last col mean 0.8984731435775757 first col mean 0.8922086954116821 all mean 0.8899320363998413
0.38923224806785583 0.38923224806785583
rl training, epoch0, iter0, batch664/1133, batch loss:0.38923224806785583, Training time:7756.931788444519
batch reward last col mean 0.8972784280776978 first col mean 0.8869293928146362 all mean 0.8864644169807434
0.4152441918849945 0.4152441918849945
rl training, epoch0, iter0, batch665/1133, batch loss:0.4152441918849945, Training time:7773.9137144088745
batch reward last col mean 0.9126754403114319 first col mean 0.8911789655685425 all mean 0.8996903896331787
0.4550057649612427 0.45500579476356506
rl training, epoch0, iter0, batch666/1133, batch loss:0.45500579476356506, Training time:7790.918012142181
batch reward last col mean 0.8669652938842773 first col mean 0.8505972623825073 all mean 0.865629255771637
0.4522360563278198 0.4522360563278198
rl training, epoch0, iter0, batch667/1133, batch loss:0.4522360563278198, Training time:7807.843868494034
batch reward last col mean 0.8869989514350891 first col mean 0.9043673872947693 all mean 0.9052023887634277
0.4773862957954407 0.4773862957954407
rl training, epoch0, iter0, batch668/1133, batch loss:0.4773862957954407, Training time:7824.794855356216
batch reward last col mean 0.8714112043380737 first col mean 0.8876363039016724 all mean 0.8705317378044128
0.48352333903312683 0.48352333903312683
rl training, epoch0, iter0, batch669/1133, batch loss:0.48352333903312683, Training time:7842.059203147888
batch reward last col mean 0.9050937294960022 first col mean 0.8933331966400146 all mean 0.905487596988678
0.5249615907669067 0.5249615907669067
rl training, epoch0, iter0, batch670/1133, batch loss:0.5249615907669067, Training time:7859.160766839981
batch reward last col mean 0.8909571170806885 first col mean 0.8918119072914124 all mean 0.8973023295402527
0.5344520211219788 0.5344520211219788
rl training, epoch0, iter0, batch671/1133, batch loss:0.5344520211219788, Training time:7876.365756034851
batch reward last col mean 0.8893622159957886 first col mean 0.8861584663391113 all mean 0.8767772912979126
0.5337377190589905 0.5337377190589905
rl training, epoch0, iter0, batch672/1133, batch loss:0.5337377190589905, Training time:7893.589456319809
batch reward last col mean 0.8929840326309204 first col mean 0.8957863450050354 all mean 0.891503632068634
0.5474818348884583 0.5474818348884583
rl training, epoch0, iter0, batch673/1133, batch loss:0.5474818348884583, Training time:7910.793404817581
batch reward last col mean 0.8892748951911926 first col mean 0.8892979025840759 all mean 0.8840769529342651
0.5423109531402588 0.542310893535614
rl training, epoch0, iter0, batch674/1133, batch loss:0.542310893535614, Training time:7928.018136501312
batch reward last col mean 0.9008837938308716 first col mean 0.8926671743392944 all mean 0.9009180068969727
0.5635073781013489 0.5635073781013489
rl training, epoch0, iter0, batch675/1133, batch loss:0.5635073781013489, Training time:7945.184631824493
batch reward last col mean 0.9038684368133545 first col mean 0.8813273906707764 all mean 0.8925926089286804
0.5464661717414856 0.5464661717414856
rl training, epoch0, iter0, batch676/1133, batch loss:0.5464661717414856, Training time:7962.305832386017
batch reward last col mean 0.8946290016174316 first col mean 0.900666356086731 all mean 0.9053781032562256
0.5959877371788025 0.5959876775741577
rl training, epoch0, iter0, batch677/1133, batch loss:0.5959876775741577, Training time:7980.540796995163
batch reward last col mean 0.8794158697128296 first col mean 0.9045267105102539 all mean 0.902076244354248
0.5797362923622131 0.5797362923622131
rl training, epoch0, iter0, batch678/1133, batch loss:0.5797362923622131, Training time:7997.785152435303
batch reward last col mean 0.8943817019462585 first col mean 0.9021925926208496 all mean 0.8953968286514282
0.5890059471130371 0.5890059471130371
rl training, epoch0, iter0, batch679/1133, batch loss:0.5890059471130371, Training time:8015.061259508133
batch reward last col mean 0.8888716697692871 first col mean 0.8908402919769287 all mean 0.9060339331626892
0.593882143497467 0.5938820838928223
rl training, epoch0, iter0, batch680/1133, batch loss:0.5938820838928223, Training time:8032.338134765625
batch reward last col mean 0.8714627027511597 first col mean 0.8959169983863831 all mean 0.8876807689666748
0.6101868748664856 0.6101868748664856
rl training, epoch0, iter0, batch681/1133, batch loss:0.6101868748664856, Training time:8049.473609924316
batch reward last col mean 0.8937145471572876 first col mean 0.8772810101509094 all mean 0.8885405659675598
0.6044473648071289 0.6044473648071289
rl training, epoch0, iter0, batch682/1133, batch loss:0.6044473648071289, Training time:8066.5926723480225
batch reward last col mean 0.8288307785987854 first col mean 0.8689731955528259 all mean 0.8569590449333191
0.6107394695281982 0.6107394695281982
rl training, epoch0, iter0, batch683/1133, batch loss:0.6107394695281982, Training time:8083.890730381012
batch reward last col mean 0.8712206482887268 first col mean 0.8967045545578003 all mean 0.8884903788566589
0.6031614542007446 0.6031614542007446
rl training, epoch0, iter0, batch684/1133, batch loss:0.6031614542007446, Training time:8100.935870409012
batch reward last col mean 0.8655356168746948 first col mean 0.8987112641334534 all mean 0.8932000994682312
0.6239427328109741 0.6239427328109741
rl training, epoch0, iter0, batch685/1133, batch loss:0.6239427328109741, Training time:8118.169386386871
batch reward last col mean 0.8855147361755371 first col mean 0.8870725631713867 all mean 0.885869562625885
0.6499073505401611 0.6499073505401611
rl training, epoch0, iter0, batch686/1133, batch loss:0.6499073505401611, Training time:8135.389583110809
batch reward last col mean 0.8968193531036377 first col mean 0.9197814464569092 all mean 0.9174625873565674
0.6448496580123901 0.6448496580123901
rl training, epoch0, iter0, batch687/1133, batch loss:0.6448496580123901, Training time:8152.349399805069
batch reward last col mean 0.8569396138191223 first col mean 0.8789036870002747 all mean 0.8729037642478943
0.6261618137359619 0.6261618733406067
rl training, epoch0, iter0, batch688/1133, batch loss:0.6261618733406067, Training time:8169.471614599228
batch reward last col mean 0.8350672721862793 first col mean 0.8855788111686707 all mean 0.8761717081069946
0.6399111151695251 0.6399111151695251
rl training, epoch0, iter0, batch689/1133, batch loss:0.6399111151695251, Training time:8186.658873081207
batch reward last col mean 0.8205912113189697 first col mean 0.8744543790817261 all mean 0.8693271279335022
0.6433936953544617 0.6433937549591064
rl training, epoch0, iter0, batch690/1133, batch loss:0.6433937549591064, Training time:8205.63283586502
batch reward last col mean 0.8476930856704712 first col mean 0.8804541826248169 all mean 0.8638441562652588
0.6323075294494629 0.6323075294494629
rl training, epoch0, iter0, batch691/1133, batch loss:0.6323075294494629, Training time:8222.949636936188
batch reward last col mean 0.8327499628067017 first col mean 0.8663119673728943 all mean 0.8516762256622314
0.6329169869422913 0.6329169869422913
rl training, epoch0, iter0, batch692/1133, batch loss:0.6329169869422913, Training time:8240.282737731934
batch reward last col mean 0.904749870300293 first col mean 0.9129799008369446 all mean 0.9070573449134827
0.6404500603675842 0.6404500603675842
rl training, epoch0, iter0, batch693/1133, batch loss:0.6404500603675842, Training time:8257.37035036087
batch reward last col mean 0.8713594079017639 first col mean 0.8967868089675903 all mean 0.8978713154792786
0.6210049390792847 0.6210048794746399
rl training, epoch0, iter0, batch694/1133, batch loss:0.6210048794746399, Training time:8274.442237854004
batch reward last col mean 0.8610143661499023 first col mean 0.9133611917495728 all mean 0.8993880748748779
0.6120545268058777 0.6120545268058777
rl training, epoch0, iter0, batch695/1133, batch loss:0.6120545268058777, Training time:8291.525005340576
batch reward last col mean 0.899410605430603 first col mean 0.9026114344596863 all mean 0.8994869589805603
0.6043431162834167 0.6043431162834167
rl training, epoch0, iter0, batch696/1133, batch loss:0.6043431162834167, Training time:8308.468329906464
batch reward last col mean 0.8619609475135803 first col mean 0.8800367712974548 all mean 0.883047878742218
0.5757738947868347 0.5757738947868347
rl training, epoch0, iter0, batch697/1133, batch loss:0.5757738947868347, Training time:8325.45771932602
batch reward last col mean 0.879756510257721 first col mean 0.8935964107513428 all mean 0.880344808101654
0.5776464343070984 0.5776464343070984
rl training, epoch0, iter0, batch698/1133, batch loss:0.5776464343070984, Training time:8342.545740365982
batch reward last col mean 0.8329829573631287 first col mean 0.8744221925735474 all mean 0.8708660006523132
0.5660849213600159 0.5660849213600159
rl training, epoch0, iter0, batch699/1133, batch loss:0.5660849213600159, Training time:8359.575960874557
batch reward last col mean 0.9075502753257751 first col mean 0.9093101024627686 all mean 0.9042106866836548
0.5681831240653992 0.5681831240653992
rl training, epoch0, iter0, batch700/1133, batch loss:0.5681831240653992, Training time:8376.507430553436
batch reward last col mean 0.9270952939987183 first col mean 0.926433265209198 all mean 0.9240853786468506
0.5488680601119995 0.5488681197166443
rl training, epoch0, iter0, batch701/1133, batch loss:0.5488681197166443, Training time:8393.614349842072
batch reward last col mean 0.9383480548858643 first col mean 0.9030351638793945 all mean 0.9186984896659851
0.5553650856018066 0.5553650856018066
rl training, epoch0, iter0, batch702/1133, batch loss:0.5553650856018066, Training time:8412.63707113266
batch reward last col mean 0.8888936042785645 first col mean 0.8774389028549194 all mean 0.8849576711654663
0.5043948888778687 0.5043948888778687
rl training, epoch0, iter0, batch703/1133, batch loss:0.5043948888778687, Training time:8429.669175863266
batch reward last col mean 0.9063485860824585 first col mean 0.8983101844787598 all mean 0.8963902592658997
0.5209291577339172 0.5209291577339172
rl training, epoch0, iter0, batch704/1133, batch loss:0.5209291577339172, Training time:8446.72931933403
batch reward last col mean 0.9132565855979919 first col mean 0.8881091475486755 all mean 0.8991010189056396
0.5095298886299133 0.5095298290252686
rl training, epoch0, iter0, batch705/1133, batch loss:0.5095298290252686, Training time:8463.961597681046
batch reward last col mean 0.8890986442565918 first col mean 0.8782432079315186 all mean 0.8822444081306458
0.4934232234954834 0.4934232234954834
rl training, epoch0, iter0, batch706/1133, batch loss:0.4934232234954834, Training time:8482.467364549637
batch reward last col mean 0.894125759601593 first col mean 0.8876349925994873 all mean 0.8898930549621582
0.4986071288585663 0.4986071288585663
rl training, epoch0, iter0, batch707/1133, batch loss:0.4986071288585663, Training time:8501.115941762924
batch reward last col mean 0.9114815592765808 first col mean 0.900544285774231 all mean 0.9105090498924255
0.4953014552593231 0.4953014552593231
rl training, epoch0, iter0, batch708/1133, batch loss:0.4953014552593231, Training time:8518.243010997772
batch reward last col mean 0.8768381476402283 first col mean 0.8816074728965759 all mean 0.8829043507575989
0.4882583022117615 0.4882582426071167
rl training, epoch0, iter0, batch709/1133, batch loss:0.4882582426071167, Training time:8535.48102736473
batch reward last col mean 0.8957316875457764 first col mean 0.8892062306404114 all mean 0.8948060870170593
0.4858887791633606 0.4858887791633606
rl training, epoch0, iter0, batch710/1133, batch loss:0.4858887791633606, Training time:8552.477211475372
batch reward last col mean 0.8509232997894287 first col mean 0.8642386198043823 all mean 0.8511710166931152
0.46180659532546997 0.46180659532546997
rl training, epoch0, iter0, batch711/1133, batch loss:0.46180659532546997, Training time:8569.415276288986
batch reward last col mean 0.9137735962867737 first col mean 0.9010877013206482 all mean 0.904391348361969
0.48377683758735657 0.48377683758735657
rl training, epoch0, iter0, batch712/1133, batch loss:0.48377683758735657, Training time:8586.413340806961
batch reward last col mean 0.9310216903686523 first col mean 0.9087314605712891 all mean 0.9165888428688049
0.4757702052593231 0.4757702052593231
rl training, epoch0, iter0, batch713/1133, batch loss:0.4757702052593231, Training time:8603.442239284515
batch reward last col mean 0.8404548764228821 first col mean 0.8369685411453247 all mean 0.8381540179252625
0.4258539080619812 0.4258539080619812
rl training, epoch0, iter0, batch714/1133, batch loss:0.4258539080619812, Training time:8620.514968156815
batch reward last col mean 0.8954004645347595 first col mean 0.8629707098007202 all mean 0.8714154362678528
0.4433264434337616 0.4433264434337616
rl training, epoch0, iter0, batch715/1133, batch loss:0.4433264434337616, Training time:8637.485395669937
batch reward last col mean 0.8959550857543945 first col mean 0.8734577298164368 all mean 0.8830873966217041
0.4429066479206085 0.4429067075252533
rl training, epoch0, iter0, batch716/1133, batch loss:0.4429067075252533, Training time:8654.702157735825
batch reward last col mean 0.8745417594909668 first col mean 0.8829081058502197 all mean 0.8820555806159973
0.4321608543395996 0.4321608543395996
rl training, epoch0, iter0, batch717/1133, batch loss:0.4321608543395996, Training time:8671.899901390076
batch reward last col mean 0.8993122577667236 first col mean 0.8845534324645996 all mean 0.8857136964797974
0.44032391905784607 0.44032391905784607
rl training, epoch0, iter0, batch718/1133, batch loss:0.44032391905784607, Training time:8689.060824155807
batch reward last col mean 0.8852964639663696 first col mean 0.8554016947746277 all mean 0.8697053790092468
0.3827266991138458 0.3827266991138458
rl training, epoch0, iter0, batch719/1133, batch loss:0.3827266991138458, Training time:8706.205642700195
batch reward last col mean 0.8771160840988159 first col mean 0.8441105484962463 all mean 0.8510549664497375
0.38599225878715515 0.38599222898483276
rl training, epoch0, iter0, batch720/1133, batch loss:0.38599222898483276, Training time:8723.337154626846
batch reward last col mean 0.8967361450195312 first col mean 0.8798792362213135 all mean 0.8879701495170593
0.4024234414100647 0.4024234414100647
rl training, epoch0, iter0, batch721/1133, batch loss:0.4024234414100647, Training time:8740.553438901901
batch reward last col mean 0.8928728103637695 first col mean 0.8780404329299927 all mean 0.8779361844062805
0.39873629808425903 0.39873629808425903
rl training, epoch0, iter0, batch722/1133, batch loss:0.39873629808425903, Training time:8757.61811375618
batch reward last col mean 0.8847464919090271 first col mean 0.8472448587417603 all mean 0.8544942140579224
0.3784286081790924 0.3784286081790924
rl training, epoch0, iter0, batch723/1133, batch loss:0.3784286081790924, Training time:8774.62449669838
batch reward last col mean 0.8761674761772156 first col mean 0.862393856048584 all mean 0.8518692851066589
0.38139504194259644 0.38139504194259644
rl training, epoch0, iter0, batch724/1133, batch loss:0.38139504194259644, Training time:8791.753717422485
batch reward last col mean 0.9126728773117065 first col mean 0.8732529878616333 all mean 0.8793724775314331
0.4068773090839386 0.4068773090839386
rl training, epoch0, iter0, batch725/1133, batch loss:0.4068773090839386, Training time:8808.831243753433
batch reward last col mean 0.9108275175094604 first col mean 0.8888698816299438 all mean 0.8971221446990967
0.40690505504608154 0.40690505504608154
rl training, epoch0, iter0, batch726/1133, batch loss:0.40690505504608154, Training time:8826.04341173172
batch reward last col mean 0.883378267288208 first col mean 0.8602708578109741 all mean 0.8667186498641968
0.4208768308162689 0.4208768308162689
rl training, epoch0, iter0, batch727/1133, batch loss:0.4208768308162689, Training time:8843.312024593353
batch reward last col mean 0.8560206890106201 first col mean 0.8390650749206543 all mean 0.844204306602478
0.41218820214271545 0.41218817234039307
rl training, epoch0, iter0, batch728/1133, batch loss:0.41218817234039307, Training time:8860.653361320496
batch reward last col mean 0.8916496634483337 first col mean 0.8761798143386841 all mean 0.8793484568595886
0.4390980005264282 0.43909797072410583
rl training, epoch0, iter0, batch729/1133, batch loss:0.43909797072410583, Training time:8877.87134361267
batch reward last col mean 0.8651790022850037 first col mean 0.855525016784668 all mean 0.8641054034233093
0.4689924418926239 0.4689924418926239
rl training, epoch0, iter0, batch730/1133, batch loss:0.4689924418926239, Training time:8895.120598316193
batch reward last col mean 0.9136176705360413 first col mean 0.9166016578674316 all mean 0.913678765296936
0.48200544714927673 0.48200544714927673
rl training, epoch0, iter0, batch731/1133, batch loss:0.48200544714927673, Training time:8912.281908035278
batch reward last col mean 0.8989588022232056 first col mean 0.8773860335350037 all mean 0.8899465203285217
0.49125856161117554 0.49125856161117554
rl training, epoch0, iter0, batch732/1133, batch loss:0.49125856161117554, Training time:8929.423642158508
batch reward last col mean 0.8749942183494568 first col mean 0.8576918840408325 all mean 0.865102231502533
0.49582281708717346 0.49582281708717346
rl training, epoch0, iter0, batch733/1133, batch loss:0.49582281708717346, Training time:8946.454112291336
batch reward last col mean 0.8871596455574036 first col mean 0.8791350722312927 all mean 0.8848527073860168
0.4972362518310547 0.4972362518310547
rl training, epoch0, iter0, batch734/1133, batch loss:0.4972362518310547, Training time:8963.637742519379
batch reward last col mean 0.9175580143928528 first col mean 0.904633641242981 all mean 0.9060853719711304
0.5219777822494507 0.5219777822494507
rl training, epoch0, iter0, batch735/1133, batch loss:0.5219777822494507, Training time:8981.699944257736
batch reward last col mean 0.9155218601226807 first col mean 0.9080128073692322 all mean 0.9106413125991821
0.5467383861541748 0.5467383861541748
rl training, epoch0, iter0, batch736/1133, batch loss:0.5467383861541748, Training time:8998.686764717102
batch reward last col mean 0.888778567314148 first col mean 0.880217969417572 all mean 0.8922182321548462
0.5792657136917114 0.5792657136917114
rl training, epoch0, iter0, batch737/1133, batch loss:0.5792657136917114, Training time:9015.93685555458
batch reward last col mean 0.8808311223983765 first col mean 0.9008549451828003 all mean 0.889957070350647
0.5614656805992126 0.5614656805992126
rl training, epoch0, iter0, batch738/1133, batch loss:0.5614656805992126, Training time:9033.097375869751
batch reward last col mean 0.8979645371437073 first col mean 0.8837608098983765 all mean 0.8906623125076294
0.5602659583091736 0.5602659583091736
rl training, epoch0, iter0, batch739/1133, batch loss:0.5602659583091736, Training time:9050.146271944046
batch reward last col mean 0.8747773766517639 first col mean 0.8905514478683472 all mean 0.8887240290641785
0.5589393973350525 0.5589393973350525
rl training, epoch0, iter0, batch740/1133, batch loss:0.5589393973350525, Training time:9067.31763124466
batch reward last col mean 0.8988519906997681 first col mean 0.9117820858955383 all mean 0.9123095870018005
0.5838994979858398 0.5838994979858398
rl training, epoch0, iter0, batch741/1133, batch loss:0.5838994979858398, Training time:9084.373125553131
batch reward last col mean 0.9042934775352478 first col mean 0.8921718597412109 all mean 0.8945441842079163
0.566011905670166 0.566011905670166
rl training, epoch0, iter0, batch742/1133, batch loss:0.566011905670166, Training time:9101.54457116127
batch reward last col mean 0.888095498085022 first col mean 0.8958908319473267 all mean 0.892976701259613
0.5720686912536621 0.5720686912536621
rl training, epoch0, iter0, batch743/1133, batch loss:0.5720686912536621, Training time:9118.726865053177
batch reward last col mean 0.9146665334701538 first col mean 0.9108762741088867 all mean 0.9070984721183777
0.5956279039382935 0.5956279039382935
rl training, epoch0, iter0, batch744/1133, batch loss:0.5956279039382935, Training time:9135.764907598495
batch reward last col mean 0.9245659708976746 first col mean 0.9222153425216675 all mean 0.9224409461021423
0.5898823738098145 0.5898823738098145
rl training, epoch0, iter0, batch745/1133, batch loss:0.5898823738098145, Training time:9152.721053123474
batch reward last col mean 0.8812167644500732 first col mean 0.8815727233886719 all mean 0.8837296962738037
0.5350983142852783 0.5350983142852783
rl training, epoch0, iter0, batch746/1133, batch loss:0.5350983142852783, Training time:9170.11756515503
batch reward last col mean 0.9068875908851624 first col mean 0.9103131294250488 all mean 0.9070180058479309
0.532025933265686 0.532025933265686
rl training, epoch0, iter0, batch747/1133, batch loss:0.532025933265686, Training time:9187.248281478882
batch reward last col mean 0.8884333372116089 first col mean 0.8742250204086304 all mean 0.8793851137161255
0.5393768548965454 0.5393768548965454
rl training, epoch0, iter0, batch748/1133, batch loss:0.5393768548965454, Training time:9204.456644296646
batch reward last col mean 0.9120132923126221 first col mean 0.9051584005355835 all mean 0.9106914401054382
0.5470623970031738 0.5470623970031738
rl training, epoch0, iter0, batch749/1133, batch loss:0.5470623970031738, Training time:9221.59263586998
batch reward last col mean 0.9112869501113892 first col mean 0.8952041864395142 all mean 0.9043645262718201
0.5460062026977539 0.5460062026977539
rl training, epoch0, iter0, batch750/1133, batch loss:0.5460062026977539, Training time:9238.686568260193
batch reward last col mean 0.8863232135772705 first col mean 0.8809857964515686 all mean 0.8843836188316345
0.5297456979751587 0.5297456979751587
rl training, epoch0, iter0, batch751/1133, batch loss:0.5297456979751587, Training time:9255.792714118958
batch reward last col mean 0.9095783233642578 first col mean 0.8987261652946472 all mean 0.8950993418693542
0.5390478372573853 0.5390478372573853
rl training, epoch0, iter0, batch752/1133, batch loss:0.5390478372573853, Training time:9272.898075819016
batch reward last col mean 0.8898829221725464 first col mean 0.9021154046058655 all mean 0.8950689435005188
0.5262407064437866 0.5262407064437866
rl training, epoch0, iter0, batch753/1133, batch loss:0.5262407064437866, Training time:9290.972301244736
batch reward last col mean 0.9199429750442505 first col mean 0.9237095713615417 all mean 0.9170783162117004
0.5224235653877258 0.5224235653877258
rl training, epoch0, iter0, batch754/1133, batch loss:0.5224235653877258, Training time:9310.104861021042
batch reward last col mean 0.9108616709709167 first col mean 0.918723464012146 all mean 0.9084190726280212
0.4981835186481476 0.4981835186481476
rl training, epoch0, iter0, batch755/1133, batch loss:0.4981835186481476, Training time:9327.249692678452
batch reward last col mean 0.8909555077552795 first col mean 0.8745176792144775 all mean 0.8783287405967712
0.5157365202903748 0.5157365202903748
rl training, epoch0, iter0, batch756/1133, batch loss:0.5157365202903748, Training time:9344.750099658966
batch reward last col mean 0.930236279964447 first col mean 0.9067274332046509 all mean 0.9138470888137817
0.4974423944950104 0.4974423944950104
rl training, epoch0, iter0, batch757/1133, batch loss:0.4974423944950104, Training time:9361.9133310318
batch reward last col mean 0.89182448387146 first col mean 0.8850581645965576 all mean 0.8884158730506897
0.4848073422908783 0.4848073422908783
rl training, epoch0, iter0, batch758/1133, batch loss:0.4848073422908783, Training time:9379.136711597443
batch reward last col mean 0.9052581787109375 first col mean 0.8712670803070068 all mean 0.8847155570983887
0.48098137974739075 0.48098137974739075
rl training, epoch0, iter0, batch759/1133, batch loss:0.48098137974739075, Training time:9396.316040277481
batch reward last col mean 0.8857383728027344 first col mean 0.8595679998397827 all mean 0.8699687123298645
0.4627024233341217 0.4627024233341217
rl training, epoch0, iter0, batch760/1133, batch loss:0.4627024233341217, Training time:9413.38642501831
batch reward last col mean 0.8967500329017639 first col mean 0.8848089575767517 all mean 0.8807135820388794
0.46430641412734985 0.46430641412734985
rl training, epoch0, iter0, batch761/1133, batch loss:0.46430641412734985, Training time:9430.571840763092
batch reward last col mean 0.9022672176361084 first col mean 0.8835598230361938 all mean 0.8895385265350342
0.47050464153289795 0.47050464153289795
rl training, epoch0, iter0, batch762/1133, batch loss:0.47050464153289795, Training time:9447.70145702362
batch reward last col mean 0.8754048347473145 first col mean 0.8651043176651001 all mean 0.8646813631057739
0.44340017437934875 0.44340017437934875
rl training, epoch0, iter0, batch763/1133, batch loss:0.44340017437934875, Training time:9464.955675125122
batch reward last col mean 0.886134147644043 first col mean 0.8659256100654602 all mean 0.8712030053138733
0.45115262269973755 0.45115262269973755
rl training, epoch0, iter0, batch764/1133, batch loss:0.45115262269973755, Training time:9482.115176200867
batch reward last col mean 0.8892362713813782 first col mean 0.8732452392578125 all mean 0.8773206472396851
0.46765264868736267 0.46765264868736267
rl training, epoch0, iter0, batch765/1133, batch loss:0.46765264868736267, Training time:9499.224572896957
batch reward last col mean 0.8624780178070068 first col mean 0.8566644191741943 all mean 0.8518787622451782
0.46428993344306946 0.46428993344306946
rl training, epoch0, iter0, batch766/1133, batch loss:0.46428993344306946, Training time:9516.34901022911
batch reward last col mean 0.8993747234344482 first col mean 0.901587724685669 all mean 0.8988181948661804
0.4798268675804138 0.4798268973827362
rl training, epoch0, iter0, batch767/1133, batch loss:0.4798268973827362, Training time:9533.406775951385
batch reward last col mean 0.8957839608192444 first col mean 0.9028770327568054 all mean 0.8973594903945923
0.4998697340488434 0.4998697340488434
rl training, epoch0, iter0, batch768/1133, batch loss:0.4998697340488434, Training time:9550.490131139755
batch reward last col mean 0.8954519033432007 first col mean 0.8967263698577881 all mean 0.8953071236610413
0.4953192472457886 0.4953191876411438
rl training, epoch0, iter0, batch769/1133, batch loss:0.4953191876411438, Training time:9567.743087053299
batch reward last col mean 0.8735318779945374 first col mean 0.8861331939697266 all mean 0.8757892847061157
0.5164231061935425 0.5164231061935425
rl training, epoch0, iter0, batch770/1133, batch loss:0.5164231061935425, Training time:9584.879462957382
batch reward last col mean 0.9106296300888062 first col mean 0.9102823138237 all mean 0.9045702219009399
0.5498781204223633 0.5498781800270081
rl training, epoch0, iter0, batch771/1133, batch loss:0.5498781800270081, Training time:9601.911986589432
batch reward last col mean 0.8696058988571167 first col mean 0.8837952613830566 all mean 0.8789436221122742
0.5036807060241699 0.5036806464195251
rl training, epoch0, iter0, batch772/1133, batch loss:0.5036806464195251, Training time:9619.179950475693
batch reward last col mean 0.9122533202171326 first col mean 0.9243641495704651 all mean 0.9149294495582581
0.5588125586509705 0.5588125586509705
rl training, epoch0, iter0, batch773/1133, batch loss:0.5588125586509705, Training time:9636.30580163002
batch reward last col mean 0.871338963508606 first col mean 0.8801440000534058 all mean 0.8818979859352112
0.5357505679130554 0.5357505679130554
rl training, epoch0, iter0, batch774/1133, batch loss:0.5357505679130554, Training time:9653.402356386185
batch reward last col mean 0.8992187976837158 first col mean 0.8826884031295776 all mean 0.8878315687179565
0.5234867930412292 0.5234867930412292
rl training, epoch0, iter0, batch775/1133, batch loss:0.5234867930412292, Training time:9670.368366003036
batch reward last col mean 0.8967272639274597 first col mean 0.8988386392593384 all mean 0.9005500674247742
0.5576907992362976 0.5576907396316528
rl training, epoch0, iter0, batch776/1133, batch loss:0.5576907396316528, Training time:9687.48495221138
batch reward last col mean 0.9040731191635132 first col mean 0.899997353553772 all mean 0.905493974685669
0.5484391450881958 0.5484391450881958
rl training, epoch0, iter0, batch777/1133, batch loss:0.5484391450881958, Training time:9704.949476480484
batch reward last col mean 0.8745100498199463 first col mean 0.8734985589981079 all mean 0.8821089863777161
0.5552252531051636 0.5552253127098083
rl training, epoch0, iter0, batch778/1133, batch loss:0.5552253127098083, Training time:9722.169483423233
batch reward last col mean 0.8805849552154541 first col mean 0.9109562635421753 all mean 0.902217447757721
0.5691279172897339 0.5691279172897339
rl training, epoch0, iter0, batch779/1133, batch loss:0.5691279172897339, Training time:9739.437498807907
batch reward last col mean 0.9197444319725037 first col mean 0.9004725217819214 all mean 0.9012525081634521
0.5772793889045715 0.5772793889045715
rl training, epoch0, iter0, batch780/1133, batch loss:0.5772793889045715, Training time:9756.690398216248
batch reward last col mean 0.8900066614151001 first col mean 0.8922107219696045 all mean 0.8962400555610657
0.5575874447822571 0.5575874447822571
rl training, epoch0, iter0, batch781/1133, batch loss:0.5575874447822571, Training time:9773.846975564957
batch reward last col mean 0.892723560333252 first col mean 0.9131540060043335 all mean 0.9119163751602173
0.5432754158973694 0.5432754755020142
rl training, epoch0, iter0, batch782/1133, batch loss:0.5432754755020142, Training time:9790.965362071991
batch reward last col mean 0.90765380859375 first col mean 0.8983482718467712 all mean 0.8989171385765076
0.5220295190811157 0.5220295190811157
rl training, epoch0, iter0, batch783/1133, batch loss:0.5220295190811157, Training time:9810.045795917511
batch reward last col mean 0.9141234755516052 first col mean 0.9062501192092896 all mean 0.9133471250534058
0.5492416024208069 0.5492416024208069
rl training, epoch0, iter0, batch784/1133, batch loss:0.5492416024208069, Training time:9829.172765731812
batch reward last col mean 0.8864824771881104 first col mean 0.8631541132926941 all mean 0.8655568361282349
0.5060077905654907 0.5060077905654907
rl training, epoch0, iter0, batch785/1133, batch loss:0.5060077905654907, Training time:9846.462007045746
batch reward last col mean 0.897688627243042 first col mean 0.8790130615234375 all mean 0.8878501057624817
0.4863260090351105 0.4863260090351105
rl training, epoch0, iter0, batch786/1133, batch loss:0.4863260090351105, Training time:9863.645440101624
batch reward last col mean 0.8987622261047363 first col mean 0.8856003284454346 all mean 0.885688841342926
0.4904114603996277 0.4904114603996277
rl training, epoch0, iter0, batch787/1133, batch loss:0.4904114603996277, Training time:9881.092669248581
batch reward last col mean 0.9076765775680542 first col mean 0.9111803770065308 all mean 0.9062213897705078
0.49413761496543884 0.49413758516311646
rl training, epoch0, iter0, batch788/1133, batch loss:0.49413758516311646, Training time:9898.121292352676
batch reward last col mean 0.8928079009056091 first col mean 0.868046760559082 all mean 0.8768081665039062
0.4628136456012726 0.4628136456012726
rl training, epoch0, iter0, batch789/1133, batch loss:0.4628136456012726, Training time:9915.193517446518
batch reward last col mean 0.8894994258880615 first col mean 0.875781774520874 all mean 0.8839232325553894
0.457395076751709 0.457395076751709
rl training, epoch0, iter0, batch790/1133, batch loss:0.457395076751709, Training time:9932.188201904297
batch reward last col mean 0.8736716508865356 first col mean 0.8400204181671143 all mean 0.8582170009613037
0.4538617730140686 0.4538617730140686
rl training, epoch0, iter0, batch791/1133, batch loss:0.4538617730140686, Training time:9949.172612428665
batch reward last col mean 0.923880398273468 first col mean 0.8912864327430725 all mean 0.8988879919052124
0.4690615236759186 0.4690615236759186
rl training, epoch0, iter0, batch792/1133, batch loss:0.4690615236759186, Training time:9966.185690879822
batch reward last col mean 0.9311655759811401 first col mean 0.895601749420166 all mean 0.906579852104187
0.4634622633457184 0.4634622633457184
rl training, epoch0, iter0, batch793/1133, batch loss:0.4634622633457184, Training time:9983.54028725624
batch reward last col mean 0.9139374494552612 first col mean 0.8779522180557251 all mean 0.8905719518661499
0.47933316230773926 0.47933316230773926
rl training, epoch0, iter0, batch794/1133, batch loss:0.47933316230773926, Training time:10000.634919404984
batch reward last col mean 0.9002925157546997 first col mean 0.8740234971046448 all mean 0.8805625438690186
0.46344491839408875 0.46344491839408875
rl training, epoch0, iter0, batch795/1133, batch loss:0.46344491839408875, Training time:10019.073649644852
batch reward last col mean 0.9090816974639893 first col mean 0.8644072413444519 all mean 0.8791725635528564
0.4544760286808014 0.4544760286808014
rl training, epoch0, iter0, batch796/1133, batch loss:0.4544760286808014, Training time:10036.218950986862
batch reward last col mean 0.9018057584762573 first col mean 0.8857834339141846 all mean 0.8902324438095093
0.4907722771167755 0.4907722771167755
rl training, epoch0, iter0, batch797/1133, batch loss:0.4907722771167755, Training time:10053.480187416077
batch reward last col mean 0.8733593225479126 first col mean 0.8554309606552124 all mean 0.8641278743743896
0.4843296408653259 0.4843296408653259
rl training, epoch0, iter0, batch798/1133, batch loss:0.4843296408653259, Training time:10070.74769616127
batch reward last col mean 0.8842446804046631 first col mean 0.8855298161506653 all mean 0.8934934735298157
0.4655030369758606 0.4655030369758606
rl training, epoch0, iter0, batch799/1133, batch loss:0.4655030369758606, Training time:10088.161332130432
batch reward last col mean 0.9179310202598572 first col mean 0.8714838027954102 all mean 0.8882783055305481
0.49563005566596985 0.49563005566596985
rl training, epoch0, iter0, batch800/1133, batch loss:0.49563005566596985, Training time:10105.388406991959
batch reward last col mean 0.9217574000358582 first col mean 0.9045940041542053 all mean 0.9144942164421082
0.4922964572906494 0.4922964572906494
rl training, epoch0, iter0, batch801/1133, batch loss:0.4922964572906494, Training time:10122.618337154388
batch reward last col mean 0.9368759393692017 first col mean 0.898354709148407 all mean 0.9031714200973511
0.49115145206451416 0.49115145206451416
rl training, epoch0, iter0, batch802/1133, batch loss:0.49115145206451416, Training time:10139.789663791656
batch reward last col mean 0.8971390724182129 first col mean 0.8700624704360962 all mean 0.8725782632827759
0.496171772480011 0.4961718022823334
rl training, epoch0, iter0, batch803/1133, batch loss:0.4961718022823334, Training time:10157.958025932312
batch reward last col mean 0.8775954246520996 first col mean 0.8478379845619202 all mean 0.8649777770042419
0.48355236649513245 0.48355236649513245
rl training, epoch0, iter0, batch804/1133, batch loss:0.48355236649513245, Training time:10176.961492300034
batch reward last col mean 0.8901107311248779 first col mean 0.8747755885124207 all mean 0.8739725947380066
0.5126142501831055 0.5126142501831055
rl training, epoch0, iter0, batch805/1133, batch loss:0.5126142501831055, Training time:10196.031296491623
batch reward last col mean 0.9242198467254639 first col mean 0.9026855230331421 all mean 0.9109828472137451
0.5047667622566223 0.5047667622566223
rl training, epoch0, iter0, batch806/1133, batch loss:0.5047667622566223, Training time:10214.468275547028
batch reward last col mean 0.8468852043151855 first col mean 0.8574221730232239 all mean 0.851168692111969
0.5112510919570923 0.5112510919570923
rl training, epoch0, iter0, batch807/1133, batch loss:0.5112510919570923, Training time:10233.161850690842
batch reward last col mean 0.9024331569671631 first col mean 0.8812271952629089 all mean 0.8880064487457275
0.5435677170753479 0.5435677170753479
rl training, epoch0, iter0, batch808/1133, batch loss:0.5435677170753479, Training time:10252.034842252731
batch reward last col mean 0.8731856346130371 first col mean 0.8651373386383057 all mean 0.8682665824890137
0.5283640623092651 0.5283640623092651
rl training, epoch0, iter0, batch809/1133, batch loss:0.5283640623092651, Training time:10269.351000785828
batch reward last col mean 0.9114454388618469 first col mean 0.8801577091217041 all mean 0.8967431783676147
0.5129601359367371 0.5129601359367371
rl training, epoch0, iter0, batch810/1133, batch loss:0.5129601359367371, Training time:10286.496960163116
batch reward last col mean 0.8880751729011536 first col mean 0.8656038045883179 all mean 0.8734273910522461
0.5521657466888428 0.5521657466888428
rl training, epoch0, iter0, batch811/1133, batch loss:0.5521657466888428, Training time:10303.660229444504
batch reward last col mean 0.8793177604675293 first col mean 0.8757308721542358 all mean 0.8799711465835571
0.5157791376113892 0.5157791376113892
rl training, epoch0, iter0, batch812/1133, batch loss:0.5157791376113892, Training time:10320.83383846283
batch reward last col mean 0.9017887115478516 first col mean 0.8912312984466553 all mean 0.8940021991729736
0.5379124283790588 0.5379124283790588
rl training, epoch0, iter0, batch813/1133, batch loss:0.5379124283790588, Training time:10338.120731115341
batch reward last col mean 0.8878493309020996 first col mean 0.8883554935455322 all mean 0.8862469792366028
0.5449917316436768 0.5449917316436768
rl training, epoch0, iter0, batch814/1133, batch loss:0.5449917316436768, Training time:10355.362184286118
batch reward last col mean 0.8767389059066772 first col mean 0.8660039901733398 all mean 0.8693810701370239
0.5595706701278687 0.5595706701278687
rl training, epoch0, iter0, batch815/1133, batch loss:0.5595706701278687, Training time:10372.65625
batch reward last col mean 0.8941667675971985 first col mean 0.8921829462051392 all mean 0.8896036148071289
0.5864607691764832 0.5864607095718384
rl training, epoch0, iter0, batch816/1133, batch loss:0.5864607095718384, Training time:10389.911947250366
batch reward last col mean 0.9107897877693176 first col mean 0.8947617411613464 all mean 0.9067832827568054
0.5862370133399963 0.5862369537353516
rl training, epoch0, iter0, batch817/1133, batch loss:0.5862369537353516, Training time:10407.144353866577
batch reward last col mean 0.8918530344963074 first col mean 0.9072931408882141 all mean 0.909913957118988
0.6480731964111328 0.6480731964111328
rl training, epoch0, iter0, batch818/1133, batch loss:0.6480731964111328, Training time:10424.393192768097
batch reward last col mean 0.9197449684143066 first col mean 0.8877785801887512 all mean 0.8859699964523315
0.6205378174781799 0.6205378174781799
rl training, epoch0, iter0, batch819/1133, batch loss:0.6205378174781799, Training time:10441.72378230095
batch reward last col mean 0.9075418710708618 first col mean 0.8966616988182068 all mean 0.9049474596977234
0.6388429999351501 0.6388429999351501
rl training, epoch0, iter0, batch820/1133, batch loss:0.6388429999351501, Training time:10458.877933979034
batch reward last col mean 0.9130768775939941 first col mean 0.9204299449920654 all mean 0.9139540195465088
0.664185643196106 0.664185643196106
rl training, epoch0, iter0, batch821/1133, batch loss:0.664185643196106, Training time:10476.048082351685
batch reward last col mean 0.8655270934104919 first col mean 0.9020875692367554 all mean 0.8950803875923157
0.6523534655570984 0.6523534655570984
rl training, epoch0, iter0, batch822/1133, batch loss:0.6523534655570984, Training time:10493.234332323074
batch reward last col mean 0.8537811040878296 first col mean 0.8686442971229553 all mean 0.8603734374046326
0.6515335440635681 0.6515335440635681
rl training, epoch0, iter0, batch823/1133, batch loss:0.6515335440635681, Training time:10510.466116428375
batch reward last col mean 0.8963188529014587 first col mean 0.8997529745101929 all mean 0.9087567329406738
0.6891888976097107 0.6891888976097107
rl training, epoch0, iter0, batch824/1133, batch loss:0.6891888976097107, Training time:10527.487641334534
batch reward last col mean 0.8886442184448242 first col mean 0.9010212421417236 all mean 0.897273600101471
0.6963422298431396 0.6963422298431396
rl training, epoch0, iter0, batch825/1133, batch loss:0.6963422298431396, Training time:10544.690586328506
batch reward last col mean 0.8870927691459656 first col mean 0.8962235450744629 all mean 0.8958576917648315
0.7262030839920044 0.7262029647827148
rl training, epoch0, iter0, batch826/1133, batch loss:0.7262029647827148, Training time:10561.884466648102
batch reward last col mean 0.8916362524032593 first col mean 0.9063875079154968 all mean 0.9040637016296387
0.7068744897842407 0.7068744897842407
rl training, epoch0, iter0, batch827/1133, batch loss:0.7068744897842407, Training time:10579.209612846375
batch reward last col mean 0.888207197189331 first col mean 0.8832187652587891 all mean 0.9000788331031799
0.7222498059272766 0.7222498059272766
rl training, epoch0, iter0, batch828/1133, batch loss:0.7222498059272766, Training time:10596.513077020645
batch reward last col mean 0.8794315457344055 first col mean 0.9056703448295593 all mean 0.9085909128189087
0.7597239017486572 0.7597239017486572
rl training, epoch0, iter0, batch829/1133, batch loss:0.7597239017486572, Training time:10613.76679110527
batch reward last col mean 0.8847565054893494 first col mean 0.896483302116394 all mean 0.9005840420722961
0.7562114596366882 0.7562114596366882
rl training, epoch0, iter0, batch830/1133, batch loss:0.7562114596366882, Training time:10630.907092571259
batch reward last col mean 0.899208664894104 first col mean 0.8875285387039185 all mean 0.8919854760169983
0.7270200848579407 0.7270200848579407
rl training, epoch0, iter0, batch831/1133, batch loss:0.7270200848579407, Training time:10648.089995145798
batch reward last col mean 0.8885273337364197 first col mean 0.8990414142608643 all mean 0.8893001079559326
0.7910933494567871 0.7910934090614319
rl training, epoch0, iter0, batch832/1133, batch loss:0.7910934090614319, Training time:10665.232667684555
batch reward last col mean 0.8690521717071533 first col mean 0.8911478519439697 all mean 0.8941382765769958
0.7933793663978577 0.7933793663978577
rl training, epoch0, iter0, batch833/1133, batch loss:0.7933793663978577, Training time:10682.429624795914
batch reward last col mean 0.8867011070251465 first col mean 0.8864970803260803 all mean 0.8898998498916626
0.7862027883529663 0.7862027883529663
rl training, epoch0, iter0, batch834/1133, batch loss:0.7862027883529663, Training time:10699.560779094696
batch reward last col mean 0.8242962956428528 first col mean 0.883996844291687 all mean 0.8899431228637695
0.7669055461883545 0.7669055461883545
rl training, epoch0, iter0, batch835/1133, batch loss:0.7669055461883545, Training time:10716.7013463974
batch reward last col mean 0.8659377694129944 first col mean 0.8899494409561157 all mean 0.8998791575431824
0.789869487285614 0.789869487285614
rl training, epoch0, iter0, batch836/1133, batch loss:0.789869487285614, Training time:10733.841665506363
batch reward last col mean 0.8651177883148193 first col mean 0.8981460928916931 all mean 0.8829071521759033
0.7904887795448303 0.7904887795448303
rl training, epoch0, iter0, batch837/1133, batch loss:0.7904887795448303, Training time:10750.989487886429
batch reward last col mean 0.8875669240951538 first col mean 0.920243501663208 all mean 0.9041454195976257
0.7983960509300232 0.7983960509300232
rl training, epoch0, iter0, batch838/1133, batch loss:0.7983960509300232, Training time:10768.48207449913
batch reward last col mean 0.8145602941513062 first col mean 0.8830839395523071 all mean 0.8652024865150452
0.7562420964241028 0.7562420964241028
rl training, epoch0, iter0, batch839/1133, batch loss:0.7562420964241028, Training time:10785.689600944519
batch reward last col mean 0.8482257723808289 first col mean 0.9024269580841064 all mean 0.8841813206672668
0.7705065011978149 0.7705065011978149
rl training, epoch0, iter0, batch840/1133, batch loss:0.7705065011978149, Training time:10804.532819747925
batch reward last col mean 0.8140032887458801 first col mean 0.8684970140457153 all mean 0.864112138748169
0.7575225234031677 0.7575224041938782
rl training, epoch0, iter0, batch841/1133, batch loss:0.7575224041938782, Training time:10821.653971672058
batch reward last col mean 0.8471901416778564 first col mean 0.8903529047966003 all mean 0.8859226703643799
0.732688307762146 0.732688307762146
rl training, epoch0, iter0, batch842/1133, batch loss:0.732688307762146, Training time:10838.651790380478
batch reward last col mean 0.8851479291915894 first col mean 0.9204208850860596 all mean 0.9163950085639954
0.7672613263130188 0.7672613263130188
rl training, epoch0, iter0, batch843/1133, batch loss:0.7672613263130188, Training time:10856.832973480225
batch reward last col mean 0.8719042539596558 first col mean 0.8752155900001526 all mean 0.8887891173362732
0.7179352641105652 0.7179352641105652
rl training, epoch0, iter0, batch844/1133, batch loss:0.7179352641105652, Training time:10873.91565155983
batch reward last col mean 0.8589572906494141 first col mean 0.895131528377533 all mean 0.8821799755096436
0.7086193561553955 0.7086193561553955
rl training, epoch0, iter0, batch845/1133, batch loss:0.7086193561553955, Training time:10891.085536718369
batch reward last col mean 0.901293158531189 first col mean 0.9006634950637817 all mean 0.9035037159919739
0.7122266292572021 0.7122266292572021
rl training, epoch0, iter0, batch846/1133, batch loss:0.7122266292572021, Training time:10909.016261100769
batch reward last col mean 0.8732571601867676 first col mean 0.8835256099700928 all mean 0.8833125829696655
0.6738540530204773 0.6738540530204773
rl training, epoch0, iter0, batch847/1133, batch loss:0.6738540530204773, Training time:10926.113314628601
batch reward last col mean 0.8950791358947754 first col mean 0.9097878932952881 all mean 0.9030393958091736
0.6399470567703247 0.6399470567703247
rl training, epoch0, iter0, batch848/1133, batch loss:0.6399470567703247, Training time:10944.807190179825
batch reward last col mean 0.918674647808075 first col mean 0.9183964729309082 all mean 0.9195903539657593
0.6468582153320312 0.6468582153320312
rl training, epoch0, iter0, batch849/1133, batch loss:0.6468582153320312, Training time:10961.856303691864
batch reward last col mean 0.8857457637786865 first col mean 0.8973716497421265 all mean 0.9028528332710266
0.6264187693595886 0.6264187693595886
rl training, epoch0, iter0, batch850/1133, batch loss:0.6264187693595886, Training time:10978.939309358597
batch reward last col mean 0.9052917957305908 first col mean 0.9106168150901794 all mean 0.9089524745941162
0.5804709196090698 0.5804709196090698
rl training, epoch0, iter0, batch851/1133, batch loss:0.5804709196090698, Training time:10995.9285800457
batch reward last col mean 0.8991623520851135 first col mean 0.8963900208473206 all mean 0.8975666761398315
0.5166179537773132 0.5166179537773132
rl training, epoch0, iter0, batch852/1133, batch loss:0.5166179537773132, Training time:11012.876031160355
batch reward last col mean 0.8917149305343628 first col mean 0.8503537774085999 all mean 0.8656716346740723
0.5282109975814819 0.5282109975814819
rl training, epoch0, iter0, batch853/1133, batch loss:0.5282109975814819, Training time:11029.847697019577
batch reward last col mean 0.8889423608779907 first col mean 0.8539724349975586 all mean 0.8656326532363892
0.4738636314868927 0.4738636314868927
rl training, epoch0, iter0, batch854/1133, batch loss:0.4738636314868927, Training time:11046.77698802948
batch reward last col mean 0.9237300157546997 first col mean 0.8762062788009644 all mean 0.8885710835456848
0.48751845955848694 0.48751845955848694
rl training, epoch0, iter0, batch855/1133, batch loss:0.48751845955848694, Training time:11063.67728304863
batch reward last col mean 0.8996390104293823 first col mean 0.8669862747192383 all mean 0.8771559596061707
0.4560023248195648 0.45600229501724243
rl training, epoch0, iter0, batch856/1133, batch loss:0.45600229501724243, Training time:11080.658147335052
batch reward last col mean 0.9177765250205994 first col mean 0.8932616710662842 all mean 0.897500216960907
0.45370379090309143 0.4537038207054138
rl training, epoch0, iter0, batch857/1133, batch loss:0.4537038207054138, Training time:11097.585672140121
batch reward last col mean 0.9298253059387207 first col mean 0.8985816240310669 all mean 0.9045529365539551
0.44301116466522217 0.44301119446754456
rl training, epoch0, iter0, batch858/1133, batch loss:0.44301119446754456, Training time:11114.685764074326
batch reward last col mean 0.8937761187553406 first col mean 0.859614908695221 all mean 0.8815168142318726
0.45052364468574524 0.45052364468574524
rl training, epoch0, iter0, batch859/1133, batch loss:0.45052364468574524, Training time:11131.773209810257
batch reward last col mean 0.9007580280303955 first col mean 0.8490238785743713 all mean 0.8697662353515625
0.41534119844436646 0.41534119844436646
rl training, epoch0, iter0, batch860/1133, batch loss:0.41534119844436646, Training time:11148.94103550911
batch reward last col mean 0.8830362558364868 first col mean 0.8550185561180115 all mean 0.8653484582901001
0.41459184885025024 0.41459184885025024
rl training, epoch0, iter0, batch861/1133, batch loss:0.41459184885025024, Training time:11166.109070539474
batch reward last col mean 0.8754724860191345 first col mean 0.8243461847305298 all mean 0.8402381539344788
0.386974036693573 0.386974036693573
rl training, epoch0, iter0, batch862/1133, batch loss:0.386974036693573, Training time:11183.108140230179
batch reward last col mean 0.8973017930984497 first col mean 0.8702376484870911 all mean 0.8774265050888062
0.4103541672229767 0.4103541672229767
rl training, epoch0, iter0, batch863/1133, batch loss:0.4103541672229767, Training time:11200.191940546036
batch reward last col mean 0.8690081834793091 first col mean 0.8210266828536987 all mean 0.8326429724693298
0.4223316013813019 0.4223316013813019
rl training, epoch0, iter0, batch864/1133, batch loss:0.4223316013813019, Training time:11217.470540523529
batch reward last col mean 0.8926560878753662 first col mean 0.8535412549972534 all mean 0.8662019371986389
0.41759437322616577 0.41759437322616577
rl training, epoch0, iter0, batch865/1133, batch loss:0.41759437322616577, Training time:11234.4735724926
batch reward last col mean 0.8982057571411133 first col mean 0.8445647954940796 all mean 0.86163729429245
0.41720256209373474 0.41720256209373474
rl training, epoch0, iter0, batch866/1133, batch loss:0.41720256209373474, Training time:11251.492507219315
batch reward last col mean 0.9089113473892212 first col mean 0.8749181628227234 all mean 0.8853822350502014
0.4436148405075073 0.4436148405075073
rl training, epoch0, iter0, batch867/1133, batch loss:0.4436148405075073, Training time:11268.788021326065
batch reward last col mean 0.9069637060165405 first col mean 0.8604533076286316 all mean 0.8741857409477234
0.44560739398002625 0.44560739398002625
rl training, epoch0, iter0, batch868/1133, batch loss:0.44560739398002625, Training time:11285.97378396988
batch reward last col mean 0.8983802795410156 first col mean 0.8599432706832886 all mean 0.8702109456062317
0.44809743762016296 0.44809743762016296
rl training, epoch0, iter0, batch869/1133, batch loss:0.44809743762016296, Training time:11303.42073225975
batch reward last col mean 0.9151327013969421 first col mean 0.8842625617980957 all mean 0.888116180896759
0.449374258518219 0.449374258518219
rl training, epoch0, iter0, batch870/1133, batch loss:0.449374258518219, Training time:11320.618167638779
batch reward last col mean 0.8739054203033447 first col mean 0.8767098188400269 all mean 0.878382682800293
0.4426938593387604 0.4426938593387604
rl training, epoch0, iter0, batch871/1133, batch loss:0.4426938593387604, Training time:11337.665539979935
batch reward last col mean 0.8853882551193237 first col mean 0.8795429468154907 all mean 0.882082998752594
0.4276401102542877 0.4276401102542877
rl training, epoch0, iter0, batch872/1133, batch loss:0.4276401102542877, Training time:11354.702279090881
batch reward last col mean 0.9053488373756409 first col mean 0.8790220618247986 all mean 0.8855727910995483
0.4660434424877167 0.46604350209236145
rl training, epoch0, iter0, batch873/1133, batch loss:0.46604350209236145, Training time:11371.92921590805
batch reward last col mean 0.9151625633239746 first col mean 0.8760525584220886 all mean 0.8897395133972168
0.45886877179145813 0.45886877179145813
rl training, epoch0, iter0, batch874/1133, batch loss:0.45886877179145813, Training time:11389.065536022186
batch reward last col mean 0.9037765264511108 first col mean 0.8771333694458008 all mean 0.8804660439491272
0.4623683989048004 0.4623684287071228
rl training, epoch0, iter0, batch875/1133, batch loss:0.4623684287071228, Training time:11407.074044466019
batch reward last col mean 0.9070219397544861 first col mean 0.8717805743217468 all mean 0.8850529193878174
0.4604060649871826 0.4604060649871826
rl training, epoch0, iter0, batch876/1133, batch loss:0.4604060649871826, Training time:11426.060733318329
batch reward last col mean 0.8836477994918823 first col mean 0.8870421648025513 all mean 0.8822386860847473
0.4780837893486023 0.4780837893486023
rl training, epoch0, iter0, batch877/1133, batch loss:0.4780837893486023, Training time:11443.332335233688
batch reward last col mean 0.8818064332008362 first col mean 0.864834189414978 all mean 0.8677459359169006
0.4647620916366577 0.4647620916366577
rl training, epoch0, iter0, batch878/1133, batch loss:0.4647620916366577, Training time:11460.550074577332
batch reward last col mean 0.9512336254119873 first col mean 0.9243057370185852 all mean 0.9311332106590271
0.5206111669540405 0.5206111073493958
rl training, epoch0, iter0, batch879/1133, batch loss:0.5206111073493958, Training time:11477.55126619339
batch reward last col mean 0.8969542384147644 first col mean 0.8607943654060364 all mean 0.8763609528541565
0.4828099012374878 0.4828099012374878
rl training, epoch0, iter0, batch880/1133, batch loss:0.4828099012374878, Training time:11494.751227140427
batch reward last col mean 0.8917465806007385 first col mean 0.8915156126022339 all mean 0.8910351395606995
0.5038254261016846 0.5038254261016846
rl training, epoch0, iter0, batch881/1133, batch loss:0.5038254261016846, Training time:11511.753698348999
batch reward last col mean 0.9359121918678284 first col mean 0.9125305414199829 all mean 0.9188204407691956
0.5012175440788269 0.5012175440788269
rl training, epoch0, iter0, batch882/1133, batch loss:0.5012175440788269, Training time:11530.478956460953
batch reward last col mean 0.8969069719314575 first col mean 0.8844350576400757 all mean 0.8894539475440979
0.5151236057281494 0.5151236057281494
rl training, epoch0, iter0, batch883/1133, batch loss:0.5151236057281494, Training time:11549.488256454468
batch reward last col mean 0.9126936197280884 first col mean 0.8912949562072754 all mean 0.8981649279594421
0.4941118359565735 0.4941118359565735
rl training, epoch0, iter0, batch884/1133, batch loss:0.4941118359565735, Training time:11566.55222606659
batch reward last col mean 0.890617847442627 first col mean 0.8662619590759277 all mean 0.8738961815834045
0.4720160663127899 0.4720160663127899
rl training, epoch0, iter0, batch885/1133, batch loss:0.4720160663127899, Training time:11583.70592713356
batch reward last col mean 0.9219467639923096 first col mean 0.8977607488632202 all mean 0.8981927633285522
0.49074140191078186 0.4907413721084595
rl training, epoch0, iter0, batch886/1133, batch loss:0.4907413721084595, Training time:11600.9163479805
batch reward last col mean 0.9133973717689514 first col mean 0.8857583403587341 all mean 0.8921446204185486
0.4799581468105316 0.47995808720588684
rl training, epoch0, iter0, batch887/1133, batch loss:0.47995808720588684, Training time:11618.101687192917
batch reward last col mean 0.9210116267204285 first col mean 0.9004310369491577 all mean 0.9048501253128052
0.4750819802284241 0.4750819802284241
rl training, epoch0, iter0, batch888/1133, batch loss:0.4750819802284241, Training time:11636.23057770729
batch reward last col mean 0.9040465354919434 first col mean 0.8675886392593384 all mean 0.8743686676025391
0.4812975525856018 0.4812975525856018
rl training, epoch0, iter0, batch889/1133, batch loss:0.4812975525856018, Training time:11655.073066711426
batch reward last col mean 0.8978070020675659 first col mean 0.8639987707138062 all mean 0.8746953010559082
0.47641438245773315 0.47641438245773315
rl training, epoch0, iter0, batch890/1133, batch loss:0.47641438245773315, Training time:11672.185372829437
batch reward last col mean 0.903633713722229 first col mean 0.8628525733947754 all mean 0.8792799115180969
0.46902427077293396 0.46902427077293396
rl training, epoch0, iter0, batch891/1133, batch loss:0.46902427077293396, Training time:11689.329929113388
batch reward last col mean 0.890861988067627 first col mean 0.8563547134399414 all mean 0.8633296489715576
0.4666196405887604 0.4666196405887604
rl training, epoch0, iter0, batch892/1133, batch loss:0.4666196405887604, Training time:11706.57756447792
batch reward last col mean 0.9128360152244568 first col mean 0.9049407243728638 all mean 0.9038425087928772
0.4791475534439087 0.4791475534439087
rl training, epoch0, iter0, batch893/1133, batch loss:0.4791475534439087, Training time:11723.63159751892
batch reward last col mean 0.9073576331138611 first col mean 0.8754119277000427 all mean 0.8843884468078613
0.4795052707195282 0.4795052707195282
rl training, epoch0, iter0, batch894/1133, batch loss:0.4795052707195282, Training time:11740.75737285614
batch reward last col mean 0.9242519736289978 first col mean 0.89480060338974 all mean 0.9031578302383423
0.5008619427680969 0.5008619427680969
rl training, epoch0, iter0, batch895/1133, batch loss:0.5008619427680969, Training time:11757.898446798325
batch reward last col mean 0.9300296306610107 first col mean 0.9154453277587891 all mean 0.9216063022613525
0.49915507435798645 0.49915507435798645
rl training, epoch0, iter0, batch896/1133, batch loss:0.49915507435798645, Training time:11774.9974796772
batch reward last col mean 0.905057966709137 first col mean 0.8932499885559082 all mean 0.8978151082992554
0.5011610984802246 0.5011610984802246
rl training, epoch0, iter0, batch897/1133, batch loss:0.5011610984802246, Training time:11792.121724367142
batch reward last col mean 0.8941700458526611 first col mean 0.8796082139015198 all mean 0.8839741945266724
0.47227030992507935 0.47227030992507935
rl training, epoch0, iter0, batch898/1133, batch loss:0.47227030992507935, Training time:11809.387128829956
batch reward last col mean 0.9178975224494934 first col mean 0.8867331743240356 all mean 0.8953123688697815
0.4885706901550293 0.4885706901550293
rl training, epoch0, iter0, batch899/1133, batch loss:0.4885706901550293, Training time:11826.469856977463
batch reward last col mean 0.8942811489105225 first col mean 0.8803435564041138 all mean 0.8832369446754456
0.4942186772823334 0.4942186772823334
rl training, epoch0, iter0, batch900/1133, batch loss:0.4942186772823334, Training time:11843.670759677887
batch reward last col mean 0.8812642693519592 first col mean 0.878973126411438 all mean 0.8797398805618286
0.48456186056137085 0.48456186056137085
rl training, epoch0, iter0, batch901/1133, batch loss:0.48456186056137085, Training time:11860.847803354263
batch reward last col mean 0.9236248135566711 first col mean 0.876940131187439 all mean 0.8875946402549744
0.5039395093917847 0.5039395093917847
rl training, epoch0, iter0, batch902/1133, batch loss:0.5039395093917847, Training time:11877.965670108795
batch reward last col mean 0.9185841083526611 first col mean 0.913609504699707 all mean 0.911316454410553
0.521967887878418 0.521967887878418
rl training, epoch0, iter0, batch903/1133, batch loss:0.521967887878418, Training time:11895.016987800598
batch reward last col mean 0.9249745607376099 first col mean 0.9100209474563599 all mean 0.909445583820343
0.5247759819030762 0.5247759819030762
rl training, epoch0, iter0, batch904/1133, batch loss:0.5247759819030762, Training time:11912.254116296768
batch reward last col mean 0.8995546698570251 first col mean 0.8930760622024536 all mean 0.8991062045097351
0.5437929630279541 0.5437929630279541
rl training, epoch0, iter0, batch905/1133, batch loss:0.5437929630279541, Training time:11929.411260128021
batch reward last col mean 0.8790515661239624 first col mean 0.8722480535507202 all mean 0.8750699758529663
0.5189597010612488 0.5189597010612488
rl training, epoch0, iter0, batch906/1133, batch loss:0.5189597010612488, Training time:11946.621939182281
batch reward last col mean 0.9028803110122681 first col mean 0.8782733082771301 all mean 0.8844122886657715
0.5284926891326904 0.5284926891326904
rl training, epoch0, iter0, batch907/1133, batch loss:0.5284926891326904, Training time:11963.933787345886
batch reward last col mean 0.87310391664505 first col mean 0.8893470764160156 all mean 0.89272540807724
0.5352084040641785 0.5352084040641785
rl training, epoch0, iter0, batch908/1133, batch loss:0.5352084040641785, Training time:11981.105059862137
batch reward last col mean 0.8727556467056274 first col mean 0.8827750086784363 all mean 0.8766466975212097
0.5431461930274963 0.5431461930274963
rl training, epoch0, iter0, batch909/1133, batch loss:0.5431461930274963, Training time:11998.305266857147
batch reward last col mean 0.9122018218040466 first col mean 0.9115374088287354 all mean 0.910825252532959
0.536298394203186 0.536298394203186
rl training, epoch0, iter0, batch910/1133, batch loss:0.536298394203186, Training time:12015.489780664444
batch reward last col mean 0.9168590903282166 first col mean 0.9160451292991638 all mean 0.910153329372406
0.5516805052757263 0.5516805052757263
rl training, epoch0, iter0, batch911/1133, batch loss:0.5516805052757263, Training time:12032.464621305466
batch reward last col mean 0.9172828197479248 first col mean 0.8958491086959839 all mean 0.9053253531455994
0.5425650477409363 0.5425650477409363
rl training, epoch0, iter0, batch912/1133, batch loss:0.5425650477409363, Training time:12049.560537338257
batch reward last col mean 0.9022495150566101 first col mean 0.9047096967697144 all mean 0.9033599495887756
0.5618236064910889 0.5618236064910889
rl training, epoch0, iter0, batch913/1133, batch loss:0.5618236064910889, Training time:12066.597929477692
batch reward last col mean 0.9134663939476013 first col mean 0.8837189078330994 all mean 0.8919069170951843
0.5223672986030579 0.5223672986030579
rl training, epoch0, iter0, batch914/1133, batch loss:0.5223672986030579, Training time:12083.78258395195
batch reward last col mean 0.9223291873931885 first col mean 0.9005742073059082 all mean 0.9056498408317566
0.5570326447486877 0.5570326447486877
rl training, epoch0, iter0, batch915/1133, batch loss:0.5570326447486877, Training time:12101.549388170242
batch reward last col mean 0.9061921834945679 first col mean 0.8903003931045532 all mean 0.8934173583984375
0.5424380302429199 0.5424380302429199
rl training, epoch0, iter0, batch916/1133, batch loss:0.5424380302429199, Training time:12118.712682008743
batch reward last col mean 0.9259265065193176 first col mean 0.9047688245773315 all mean 0.9034858345985413
0.5321382880210876 0.5321382880210876
rl training, epoch0, iter0, batch917/1133, batch loss:0.5321382880210876, Training time:12135.817665100098
batch reward last col mean 0.914349377155304 first col mean 0.9035524129867554 all mean 0.9067503213882446
0.5363461971282959 0.5363461971282959
rl training, epoch0, iter0, batch918/1133, batch loss:0.5363461971282959, Training time:12153.088392734528
batch reward last col mean 0.930255651473999 first col mean 0.9003987312316895 all mean 0.9032943248748779
0.5579054951667786 0.5579054951667786
rl training, epoch0, iter0, batch919/1133, batch loss:0.5579054951667786, Training time:12170.162691831589
batch reward last col mean 0.9075048565864563 first col mean 0.8866093158721924 all mean 0.8976148962974548
0.5038615465164185 0.5038615465164185
rl training, epoch0, iter0, batch920/1133, batch loss:0.5038615465164185, Training time:12187.337141275406
batch reward last col mean 0.9326204061508179 first col mean 0.9200997352600098 all mean 0.9207088351249695
0.5316538214683533 0.5316538214683533
rl training, epoch0, iter0, batch921/1133, batch loss:0.5316538214683533, Training time:12204.409417390823
batch reward last col mean 0.8991137742996216 first col mean 0.8920089602470398 all mean 0.891633152961731
0.5119929313659668 0.5119929313659668
rl training, epoch0, iter0, batch922/1133, batch loss:0.5119929313659668, Training time:12221.534569263458
batch reward last col mean 0.9161641597747803 first col mean 0.8801819682121277 all mean 0.8888104557991028
0.5184130668640137 0.5184130668640137
rl training, epoch0, iter0, batch923/1133, batch loss:0.5184130668640137, Training time:12238.707382202148
batch reward last col mean 0.9178931713104248 first col mean 0.8741328716278076 all mean 0.8862543702125549
0.5156329870223999 0.5156329870223999
rl training, epoch0, iter0, batch924/1133, batch loss:0.5156329870223999, Training time:12255.676698923111
batch reward last col mean 0.9055202603340149 first col mean 0.8821783065795898 all mean 0.8923224806785583
0.5314968824386597 0.5314968824386597
rl training, epoch0, iter0, batch925/1133, batch loss:0.5314968824386597, Training time:12272.761439323425
batch reward last col mean 0.9239903092384338 first col mean 0.8898346424102783 all mean 0.8970552682876587
0.562830924987793 0.562830924987793
rl training, epoch0, iter0, batch926/1133, batch loss:0.562830924987793, Training time:12289.836519002914
batch reward last col mean 0.9266390204429626 first col mean 0.915002167224884 all mean 0.9175788164138794
0.5505983829498291 0.5505983829498291
rl training, epoch0, iter0, batch927/1133, batch loss:0.5505983829498291, Training time:12306.99629354477
batch reward last col mean 0.915833055973053 first col mean 0.8741445541381836 all mean 0.883069634437561
0.5394984483718872 0.539498507976532
rl training, epoch0, iter0, batch928/1133, batch loss:0.539498507976532, Training time:12324.32333612442
batch reward last col mean 0.941880464553833 first col mean 0.8974839448928833 all mean 0.9075263142585754
0.5619093179702759 0.5619093179702759
rl training, epoch0, iter0, batch929/1133, batch loss:0.5619093179702759, Training time:12341.488461732864
batch reward last col mean 0.9324138164520264 first col mean 0.928447961807251 all mean 0.9294115304946899
0.5761888027191162 0.5761888027191162
rl training, epoch0, iter0, batch930/1133, batch loss:0.5761888027191162, Training time:12358.718407392502
batch reward last col mean 0.9265617728233337 first col mean 0.8980127573013306 all mean 0.9026855826377869
0.5755159854888916 0.5755159854888916
rl training, epoch0, iter0, batch931/1133, batch loss:0.5755159854888916, Training time:12375.954332113266
batch reward last col mean 0.9308875799179077 first col mean 0.898863673210144 all mean 0.9077325463294983
0.5918689370155334 0.5918689966201782
rl training, epoch0, iter0, batch932/1133, batch loss:0.5918689966201782, Training time:12393.153923273087
batch reward last col mean 0.958669126033783 first col mean 0.9118410348892212 all mean 0.92229825258255
0.5830509066581726 0.5830509066581726
rl training, epoch0, iter0, batch933/1133, batch loss:0.5830509066581726, Training time:12410.718172311783
batch reward last col mean 0.9345486760139465 first col mean 0.914936900138855 all mean 0.914059579372406
0.6059484481811523 0.6059484481811523
rl training, epoch0, iter0, batch934/1133, batch loss:0.6059484481811523, Training time:12427.800395488739
batch reward last col mean 0.9453991651535034 first col mean 0.9030740261077881 all mean 0.9156051874160767
0.5955265164375305 0.5955265760421753
rl training, epoch0, iter0, batch935/1133, batch loss:0.5955265760421753, Training time:12444.837485074997
batch reward last col mean 0.9546313285827637 first col mean 0.9248082041740417 all mean 0.9291321635246277
0.600761353969574 0.600761353969574
rl training, epoch0, iter0, batch936/1133, batch loss:0.600761353969574, Training time:12461.7871696949
batch reward last col mean 0.9529556632041931 first col mean 0.9261698126792908 all mean 0.9283446669578552
0.616453230381012 0.616453230381012
rl training, epoch0, iter0, batch937/1133, batch loss:0.616453230381012, Training time:12478.82142829895
batch reward last col mean 0.9204515814781189 first col mean 0.8827432990074158 all mean 0.8975145816802979
0.5942202806472778 0.5942202806472778
rl training, epoch0, iter0, batch938/1133, batch loss:0.5942202806472778, Training time:12496.323374509811
batch reward last col mean 0.9296243190765381 first col mean 0.8923916220664978 all mean 0.9012682437896729
0.5837745666503906 0.5837745666503906
rl training, epoch0, iter0, batch939/1133, batch loss:0.5837745666503906, Training time:12513.692016124725
batch reward last col mean 0.9456503391265869 first col mean 0.9120732545852661 all mean 0.9163083434104919
0.6423171162605286 0.6423171162605286
rl training, epoch0, iter0, batch940/1133, batch loss:0.6423171162605286, Training time:12530.884481430054
batch reward last col mean 0.9541906118392944 first col mean 0.9232380390167236 all mean 0.932742178440094
0.6370058655738831 0.6370058655738831
rl training, epoch0, iter0, batch941/1133, batch loss:0.6370058655738831, Training time:12548.217689037323
batch reward last col mean 0.9405229687690735 first col mean 0.9069312214851379 all mean 0.9165444374084473
0.6479237675666809 0.6479237675666809
rl training, epoch0, iter0, batch942/1133, batch loss:0.6479237675666809, Training time:12565.393122196198
batch reward last col mean 0.9487196803092957 first col mean 0.9229938983917236 all mean 0.9292574524879456
0.6564149260520935 0.6564149260520935
rl training, epoch0, iter0, batch943/1133, batch loss:0.6564149260520935, Training time:12582.56831240654
batch reward last col mean 0.930809736251831 first col mean 0.9308613538742065 all mean 0.9254201054573059
0.6710726618766785 0.6710726618766785
rl training, epoch0, iter0, batch944/1133, batch loss:0.6710726618766785, Training time:12599.790841817856
batch reward last col mean 0.940209150314331 first col mean 0.9379441142082214 all mean 0.9376947283744812
0.6993702054023743 0.6993700861930847
rl training, epoch0, iter0, batch945/1133, batch loss:0.6993700861930847, Training time:12618.5843937397
batch reward last col mean 0.9628697037696838 first col mean 0.932529628276825 all mean 0.9419597387313843
0.7104520797729492 0.7104520797729492
rl training, epoch0, iter0, batch946/1133, batch loss:0.7104520797729492, Training time:12637.60033750534
batch reward last col mean 0.939888596534729 first col mean 0.9355669617652893 all mean 0.9350018501281738
0.7223773002624512 0.7223773002624512
rl training, epoch0, iter0, batch947/1133, batch loss:0.7223773002624512, Training time:12656.543768405914
batch reward last col mean 0.9231197834014893 first col mean 0.9237974286079407 all mean 0.9279677271842957
0.754461407661438 0.754461407661438
rl training, epoch0, iter0, batch948/1133, batch loss:0.754461407661438, Training time:12673.799330949783
batch reward last col mean 0.9324334859848022 first col mean 0.93406742811203 all mean 0.9358939528465271
0.7243455648422241 0.7243455648422241
rl training, epoch0, iter0, batch949/1133, batch loss:0.7243455648422241, Training time:12691.013220310211
batch reward last col mean 0.9253790974617004 first col mean 0.9305111765861511 all mean 0.9335422515869141
0.7359415888786316 0.7359415888786316
rl training, epoch0, iter0, batch950/1133, batch loss:0.7359415888786316, Training time:12708.214450120926
batch reward last col mean 0.9383603930473328 first col mean 0.9454736709594727 all mean 0.936974287033081
0.7833340167999268 0.7833340167999268
rl training, epoch0, iter0, batch951/1133, batch loss:0.7833340167999268, Training time:12725.437519311905
batch reward last col mean 0.9320353269577026 first col mean 0.940455436706543 all mean 0.9434572458267212
0.7674880027770996 0.7674880623817444
rl training, epoch0, iter0, batch952/1133, batch loss:0.7674880623817444, Training time:12742.483723163605
batch reward last col mean 0.931171178817749 first col mean 0.9381399154663086 all mean 0.9404274225234985
0.7753005623817444 0.7753005623817444
rl training, epoch0, iter0, batch953/1133, batch loss:0.7753005623817444, Training time:12759.63330245018
batch reward last col mean 0.9477152824401855 first col mean 0.9466846585273743 all mean 0.9528016448020935
0.7625067234039307 0.7625067234039307
rl training, epoch0, iter0, batch954/1133, batch loss:0.7625067234039307, Training time:12776.861213207245
RL early break
rl training, epoch 0, iter 0, loss:0.6081550492354089, Training time:12776.866161823273 
rl epoch 0, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.5839584007109568 Time: 144.12926125526428 s
0.2573722074727305 0.006648493238871147 0.31993769908887776
cur_epoch: 1
D Training Loss: 0.554700026734151 Time: 147.36533546447754 s
0.2445416634364772 0.0002879401508531141 0.3098704232147912
cur_epoch: 2
D Training Loss: 0.5379979007820692 Time: 145.71692895889282 s
0.23495554049406447 0.0003450615491538289 0.3026972987277257
cur_epoch: 3
D Training Loss: 0.5222909208535096 Time: 145.12842178344727 s
0.22646964997026842 0.0003050997834243066 0.29551616959464516
cur_epoch: 4
D Training Loss: 0.5093677051016848 Time: 143.8526005744934 s
0.21886468762885336 0.00027331197250427854 0.2902297050891886
rl epoch 1, begin RL for generator...
batch reward last col mean 1.793605406419374e-07 first col mean 2.1603611912723863e-06 all mean 9.11985171114793e-06
2.0947884422639618e-06 2.0947882148902863e-06
rl training, epoch1, iter0, batch0/1133, batch loss:2.0947882148902863e-06, Training time:13520.168795347214
batch reward last col mean 1.495620949754084e-06 first col mean 1.141341101629223e-07 all mean 7.141882633732166e-06
5.966125627310248e-06 5.9661242630681954e-06
rl training, epoch1, iter0, batch1/1133, batch loss:5.9661242630681954e-06, Training time:13538.969839811325
batch reward last col mean 5.652298568747938e-06 first col mean 1.1935607062696363e-06 all mean 8.743390935705975e-06
5.5109835557232145e-06 5.5109835557232145e-06
rl training, epoch1, iter0, batch2/1133, batch loss:5.5109835557232145e-06, Training time:13557.961652755737
batch reward last col mean 0.00012443917512428015 first col mean 3.178726501573692e-06 all mean 0.00011566801549633965
0.0001314699329668656 0.0001314699329668656
rl training, epoch1, iter0, batch3/1133, batch loss:0.0001314699329668656, Training time:13575.165427923203
batch reward last col mean 2.497841933291056e-06 first col mean 4.513915712323069e-07 all mean 1.3231455341156106e-05
2.2014395653968677e-05 2.2014393834979273e-05
rl training, epoch1, iter0, batch4/1133, batch loss:2.2014393834979273e-05, Training time:13592.333253383636
batch reward last col mean 2.754208310307149e-07 first col mean 8.459798118565232e-05 all mean 3.0852286727167666e-05
5.610310836345889e-05 5.610310108750127e-05
rl training, epoch1, iter0, batch5/1133, batch loss:5.610310108750127e-05, Training time:13609.453119516373
batch reward last col mean 1.99376700038556e-06 first col mean 2.7267290079180384e-06 all mean 7.443385129590752e-06
7.882594218244776e-06 7.882594218244776e-06
rl training, epoch1, iter0, batch6/1133, batch loss:7.882594218244776e-06, Training time:13626.706849336624
batch reward last col mean 4.701901730186364e-07 first col mean 3.6997246297687525e-06 all mean 1.8714112229645252e-05
1.8550750610302202e-05 1.8550750610302202e-05
rl training, epoch1, iter0, batch7/1133, batch loss:1.8550750610302202e-05, Training time:13644.079028606415
batch reward last col mean 8.238043847086374e-07 first col mean 2.402304062343319e-06 all mean 9.033024070959073e-06
9.274102012568619e-06 9.274100193579216e-06
rl training, epoch1, iter0, batch8/1133, batch loss:9.274100193579216e-06, Training time:13661.25805234909
batch reward last col mean 4.623838776751654e-06 first col mean 1.9143149074807297e-06 all mean 1.5836285456316546e-05
1.4271522559283767e-05 1.4271525287767872e-05
rl training, epoch1, iter0, batch9/1133, batch loss:1.4271525287767872e-05, Training time:13678.44067788124
batch reward last col mean 7.350600299105281e-06 first col mean 7.755319529678673e-06 all mean 3.2140727853402495e-05
1.5423682270920835e-05 1.5423680451931432e-05
rl training, epoch1, iter0, batch10/1133, batch loss:1.5423680451931432e-05, Training time:13696.43404507637
batch reward last col mean 5.374436682359374e-07 first col mean 8.294945814668608e-07 all mean 4.161689957982162e-06
3.261598976678215e-06 3.261599431425566e-06
rl training, epoch1, iter0, batch11/1133, batch loss:3.261599431425566e-06, Training time:13715.373709440231
batch reward last col mean 2.601729249818163e-07 first col mean 6.880272849230096e-05 all mean 1.365896241622977e-05
1.1004282896465156e-05 1.1004281986970454e-05
rl training, epoch1, iter0, batch12/1133, batch loss:1.1004281986970454e-05, Training time:13732.568130254745
batch reward last col mean 3.385829768376425e-05 first col mean 5.43747205483669e-07 all mean 3.203540836693719e-05
2.113634764100425e-05 2.1136351278983057e-05
rl training, epoch1, iter0, batch13/1133, batch loss:2.1136351278983057e-05, Training time:13749.733595609665
batch reward last col mean 6.847079703220516e-07 first col mean 0.0004347760695964098 all mean 7.587342679471476e-06
4.7167532102321275e-06 4.7167527554847766e-06
rl training, epoch1, iter0, batch14/1133, batch loss:4.7167527554847766e-06, Training time:13766.839598178864
batch reward last col mean 3.3730043469404336e-06 first col mean 4.84527890876052e-06 all mean 2.9671300580957904e-05
0.00012257197522558272 0.00012257197522558272
rl training, epoch1, iter0, batch15/1133, batch loss:0.00012257197522558272, Training time:13784.08925652504
batch reward last col mean 9.695492053651833e-07 first col mean 6.127957021817565e-05 all mean 7.294418992387364e-06
5.711805897590239e-06 5.711805897590239e-06
rl training, epoch1, iter0, batch16/1133, batch loss:5.711805897590239e-06, Training time:13801.226942539215
batch reward last col mean 4.822906703338958e-06 first col mean 6.165626018628245e-06 all mean 4.1190909541910514e-05
3.3406191505491734e-05 3.340620605740696e-05
rl training, epoch1, iter0, batch17/1133, batch loss:3.340620605740696e-05, Training time:13820.117040872574
batch reward last col mean 3.5319146718393313e-07 first col mean 3.4891320410679327e-06 all mean 2.400613266217988e-05
6.898545689182356e-05 6.898545689182356e-05
rl training, epoch1, iter0, batch18/1133, batch loss:6.898545689182356e-05, Training time:13837.272106647491
batch reward last col mean 1.6507543421084847e-07 first col mean 2.7641551696433453e-06 all mean 9.362600394524634e-06
7.383824140561046e-06 7.383824140561046e-06
rl training, epoch1, iter0, batch19/1133, batch loss:7.383824140561046e-06, Training time:13854.26697921753
batch reward last col mean 8.482805213816391e-08 first col mean 4.722872120055399e-07 all mean 2.0750860130647197e-05
2.2904787329025567e-05 2.2904781872057356e-05
rl training, epoch1, iter0, batch20/1133, batch loss:2.2904781872057356e-05, Training time:13871.345717430115
batch reward last col mean 6.529505185426387e-07 first col mean 8.479758434987161e-06 all mean 5.8274850744055584e-05
7.301877485588193e-05 7.301878213183954e-05
rl training, epoch1, iter0, batch21/1133, batch loss:7.301878213183954e-05, Training time:13888.468434810638
batch reward last col mean 1.6907685562728147e-07 first col mean 7.651644864381524e-07 all mean 3.699250737554394e-05
1.729342147882562e-05 1.7293423297815025e-05
rl training, epoch1, iter0, batch22/1133, batch loss:1.7293423297815025e-05, Training time:13906.141351222992
batch reward last col mean 1.0645838983691647e-06 first col mean 0.0015090527012944221 all mean 9.090918319998309e-05
0.00020429748110473156 0.00020429748110473156
rl training, epoch1, iter0, batch23/1133, batch loss:0.00020429748110473156, Training time:13923.185420036316
batch reward last col mean 0.00010252386709908023 first col mean 2.9865253736716113e-07 all mean 8.996733231469989e-05
3.4888969821622595e-05 3.488897709758021e-05
rl training, epoch1, iter0, batch24/1133, batch loss:3.488897709758021e-05, Training time:13940.104427099228
batch reward last col mean 3.0545570552931167e-06 first col mean 3.096246291534044e-05 all mean 3.892215681844391e-05
6.956759170861915e-05 6.956759170861915e-05
rl training, epoch1, iter0, batch25/1133, batch loss:6.956759170861915e-05, Training time:13959.931565523148
batch reward last col mean 1.0130997907253914e-06 first col mean 2.5521574571030214e-05 all mean 3.9794416807126254e-05
8.025563874980435e-05 8.025563147384673e-05
rl training, epoch1, iter0, batch26/1133, batch loss:8.025563147384673e-05, Training time:13977.072455644608
batch reward last col mean 0.000594503537286073 first col mean 6.021297303959727e-05 all mean 0.00034881284227594733
7.779240695526823e-05 7.779240695526823e-05
rl training, epoch1, iter0, batch27/1133, batch loss:7.779240695526823e-05, Training time:13994.020661115646
batch reward last col mean 2.4461410248477478e-06 first col mean 3.1091602181732014e-07 all mean 4.4702712330035865e-05
7.36059810151346e-05 7.36059810151346e-05
rl training, epoch1, iter0, batch28/1133, batch loss:7.36059810151346e-05, Training time:14010.932172060013
batch reward last col mean 7.563260169263231e-07 first col mean 5.431780323306157e-07 all mean 1.1335628187225666e-05
1.313837037741905e-05 1.313837037741905e-05
rl training, epoch1, iter0, batch29/1133, batch loss:1.313837037741905e-05, Training time:14027.722103357315
batch reward last col mean 2.9750808607786894e-06 first col mean 1.488112047809409e-06 all mean 2.7207759558223188e-05
2.9246217309264466e-05 2.9246210033306852e-05
rl training, epoch1, iter0, batch30/1133, batch loss:2.9246210033306852e-05, Training time:14044.621814489365
batch reward last col mean 1.9248358512413688e-05 first col mean 7.077034297253704e-06 all mean 8.439754310529679e-06
6.066518380976049e-06 6.0665170167339966e-06
rl training, epoch1, iter0, batch31/1133, batch loss:6.0665170167339966e-06, Training time:14063.675347328186
batch reward last col mean 4.84923532440007e-07 first col mean 4.4010866417920624e-07 all mean 3.448616189416498e-05
2.9731176255154423e-05 2.9731176255154423e-05
rl training, epoch1, iter0, batch32/1133, batch loss:2.9731176255154423e-05, Training time:14082.66994714737
batch reward last col mean 0.0010390300303697586 first col mean 2.5351523618155625e-06 all mean 5.079863331047818e-05
0.00012425499153323472 0.00012425499153323472
rl training, epoch1, iter0, batch33/1133, batch loss:0.00012425499153323472, Training time:14100.337966680527
batch reward last col mean 4.059643288201187e-07 first col mean 9.285538453696063e-07 all mean 1.225176947627915e-05
8.979652193374932e-06 8.979650374385528e-06
rl training, epoch1, iter0, batch34/1133, batch loss:8.979650374385528e-06, Training time:14117.290237426758
batch reward last col mean 3.0062506993999705e-05 first col mean 6.680730166408466e-06 all mean 5.734867227147333e-05
3.9864338759798557e-05 3.9864338759798557e-05
rl training, epoch1, iter0, batch35/1133, batch loss:3.9864338759798557e-05, Training time:14134.193697214127
batch reward last col mean 2.81550597946989e-07 first col mean 9.065122867468745e-06 all mean 5.201876410865225e-05
0.00011984822049271315 0.000119848242320586
rl training, epoch1, iter0, batch36/1133, batch loss:0.000119848242320586, Training time:14151.130616664886
batch reward last col mean 4.964396794093773e-05 first col mean 2.3334641809924506e-06 all mean 5.277780655887909e-05
5.888645682716742e-05 5.888645682716742e-05
rl training, epoch1, iter0, batch37/1133, batch loss:5.888645682716742e-05, Training time:14168.168543577194
batch reward last col mean 4.277190600987524e-05 first col mean 1.8923905145129538e-06 all mean 5.1758430345216766e-05
3.895404370268807e-05 3.8954047340666875e-05
rl training, epoch1, iter0, batch38/1133, batch loss:3.8954047340666875e-05, Training time:14185.136605739594
batch reward last col mean 5.703763577002974e-07 first col mean 5.063422577222809e-06 all mean 1.6084075468825176e-05
1.2930460798088461e-05 1.2930460798088461e-05
rl training, epoch1, iter0, batch39/1133, batch loss:1.2930460798088461e-05, Training time:14202.363255262375
batch reward last col mean 0.0011565933236852288 first col mean 9.598648466635495e-05 all mean 0.0010649901814758778
0.00014557145186699927 0.00014557145186699927
rl training, epoch1, iter0, batch40/1133, batch loss:0.00014557145186699927, Training time:14219.514415025711
batch reward last col mean 9.803106877370737e-06 first col mean 6.698491051793098e-05 all mean 5.0330283556832e-05
6.253691390156746e-05 6.253692117752507e-05
rl training, epoch1, iter0, batch41/1133, batch loss:6.253692117752507e-05, Training time:14236.588696241379
batch reward last col mean 1.6059414065239253e-07 first col mean 1.2890125617559534e-05 all mean 8.305266965180635e-05
0.00014818701311014593 0.00014818702766206115
rl training, epoch1, iter0, batch42/1133, batch loss:0.00014818702766206115, Training time:14253.661398410797
batch reward last col mean 5.87628562698228e-07 first col mean 2.4628488972666673e-05 all mean 3.4600285289343446e-05
7.37546433811076e-05 7.375463610514998e-05
rl training, epoch1, iter0, batch43/1133, batch loss:7.375463610514998e-05, Training time:14270.624868392944
batch reward last col mean 0.0004536359047051519 first col mean 5.660664555762196e-06 all mean 0.00013960403157398105
9.745924762682989e-05 9.74592549027875e-05
rl training, epoch1, iter0, batch44/1133, batch loss:9.74592549027875e-05, Training time:14287.615659475327
batch reward last col mean 2.518145549856854e-07 first col mean 8.52806078910362e-06 all mean 3.3472599170636386e-05
2.7238764232606627e-05 2.7238764232606627e-05
rl training, epoch1, iter0, batch45/1133, batch loss:2.7238764232606627e-05, Training time:14305.211647033691
batch reward last col mean 5.247736680757953e-06 first col mean 3.24379579978995e-05 all mean 8.4781160694547e-05
0.00015027106564957649 0.00015027103654574603
rl training, epoch1, iter0, batch46/1133, batch loss:0.00015027103654574603, Training time:14322.320722818375
batch reward last col mean 4.731786020784057e-07 first col mean 0.00021001587447244674 all mean 3.7681555113522336e-05
7.58590322220698e-05 7.585902494611219e-05
rl training, epoch1, iter0, batch47/1133, batch loss:7.585902494611219e-05, Training time:14340.004411935806
batch reward last col mean 7.951013571982912e-07 first col mean 1.0639298125170171e-05 all mean 3.4152566513512284e-05
0.00015713358880020678 0.00015713358880020678
rl training, epoch1, iter0, batch48/1133, batch loss:0.00015713358880020678, Training time:14357.157463788986
batch reward last col mean 0.00025576711050234735 first col mean 0.0003127712698187679 all mean 0.00025642343098297715
6.306497380137444e-05 6.306496652541682e-05
rl training, epoch1, iter0, batch49/1133, batch loss:6.306496652541682e-05, Training time:14374.231459140778
batch reward last col mean 5.779687853646465e-06 first col mean 0.0002977248514071107 all mean 4.967292625224218e-05
4.5616481656907126e-05 4.561647801892832e-05
rl training, epoch1, iter0, batch50/1133, batch loss:4.561647801892832e-05, Training time:14391.249327421188
batch reward last col mean 1.892959699034691e-05 first col mean 0.0003669133875519037 all mean 6.399640551535413e-05
9.236752521246672e-05 9.236752521246672e-05
rl training, epoch1, iter0, batch51/1133, batch loss:9.236752521246672e-05, Training time:14408.394706964493
batch reward last col mean 5.189011790207587e-05 first col mean 0.0006717353244312108 all mean 5.9504949604161084e-05
6.473367830039933e-05 6.473367830039933e-05
rl training, epoch1, iter0, batch52/1133, batch loss:6.473367830039933e-05, Training time:14425.655571222305
batch reward last col mean 6.210082119650906e-06 first col mean 2.5695751446619397e-06 all mean 6.350380863295868e-05
7.479087071260437e-05 7.479087071260437e-05
rl training, epoch1, iter0, batch53/1133, batch loss:7.479087071260437e-05, Training time:14442.894781827927
batch reward last col mean 2.4569455945311347e-06 first col mean 1.1029589586541988e-05 all mean 2.4991446480271406e-05
1.8829869077308103e-05 1.8829869077308103e-05
rl training, epoch1, iter0, batch54/1133, batch loss:1.8829869077308103e-05, Training time:14460.103950738907
batch reward last col mean 0.0008770573767833412 first col mean 1.9410656022955664e-05 all mean 0.00029791530687361956
0.00012592051643878222 0.00012592051643878222
rl training, epoch1, iter0, batch55/1133, batch loss:0.00012592051643878222, Training time:14477.383463144302
batch reward last col mean 2.7454239898361266e-05 first col mean 3.084600393776782e-05 all mean 4.4211632484802976e-05
8.90786832314916e-05 8.907867595553398e-05
rl training, epoch1, iter0, batch56/1133, batch loss:8.907867595553398e-05, Training time:14494.58669924736
batch reward last col mean 7.988551806192845e-05 first col mean 0.00014116967213340104 all mean 3.9243681385414675e-05
2.8182115784147754e-05 2.8182115784147754e-05
rl training, epoch1, iter0, batch57/1133, batch loss:2.8182115784147754e-05, Training time:14511.812000513077
batch reward last col mean 9.840396160143428e-06 first col mean 0.001276697381399572 all mean 4.4553344196174294e-05
0.00024258786288555712 0.00024258786288555712
rl training, epoch1, iter0, batch58/1133, batch loss:0.00024258786288555712, Training time:14529.053413629532
batch reward last col mean 3.4708705243247095e-06 first col mean 2.326880166947376e-05 all mean 2.89731178781949e-05
1.1036836440325715e-05 1.1036837349820416e-05
rl training, epoch1, iter0, batch59/1133, batch loss:1.1036837349820416e-05, Training time:14546.369557857513
batch reward last col mean 8.17120417195838e-06 first col mean 1.9858554878737777e-05 all mean 3.0891034839442e-05
2.5486229787929915e-05 2.5486229787929915e-05
rl training, epoch1, iter0, batch60/1133, batch loss:2.5486229787929915e-05, Training time:14563.609834432602
batch reward last col mean 9.297134965891019e-06 first col mean 1.8082822862197645e-05 all mean 2.231372673122678e-05
3.626545731094666e-05 3.626545731094666e-05
rl training, epoch1, iter0, batch61/1133, batch loss:3.626545731094666e-05, Training time:14580.884816169739
batch reward last col mean 1.5911638911347836e-05 first col mean 0.0017706225626170635 all mean 3.52956194547005e-05
7.656601519556716e-05 7.656602247152478e-05
rl training, epoch1, iter0, batch62/1133, batch loss:7.656602247152478e-05, Training time:14598.136506319046
batch reward last col mean 0.002109481720253825 first col mean 6.473191206168849e-06 all mean 0.0019336267141625285
0.00010175596980843693 0.00010175596253247932
rl training, epoch1, iter0, batch63/1133, batch loss:0.00010175596253247932, Training time:14615.407979011536
batch reward last col mean 2.397367552475771e-06 first col mean 7.564611337329552e-07 all mean 3.083191768382676e-05
4.720479410025291e-05 4.720479410025291e-05
rl training, epoch1, iter0, batch64/1133, batch loss:4.720479410025291e-05, Training time:14632.624274253845
batch reward last col mean 9.146629054157529e-06 first col mean 0.00011630888911895454 all mean 2.888855306082405e-05
6.259329529711977e-05 6.259329529711977e-05
rl training, epoch1, iter0, batch65/1133, batch loss:6.259329529711977e-05, Training time:14649.861933231354
batch reward last col mean 9.085469355341047e-05 first col mean 4.551378424366703e-06 all mean 0.00011549935152288526
2.2753685698262416e-05 2.2753680241294205e-05
rl training, epoch1, iter0, batch66/1133, batch loss:2.2753680241294205e-05, Training time:14667.06633067131
batch reward last col mean 1.709991806819744e-06 first col mean 0.00011074478970840573 all mean 2.9293119951034896e-05
3.464159817667678e-05 3.464159817667678e-05
rl training, epoch1, iter0, batch67/1133, batch loss:3.464159817667678e-05, Training time:14684.341437578201
batch reward last col mean 2.8617854695767164e-05 first col mean 1.8186026863986626e-05 all mean 1.9431578039075248e-05
1.5755918866489083e-05 1.5755918866489083e-05
rl training, epoch1, iter0, batch68/1133, batch loss:1.5755918866489083e-05, Training time:14701.846160888672
batch reward last col mean 5.127255280967802e-05 first col mean 2.134740316250827e-05 all mean 4.5395125198410824e-05
3.312969420221634e-05 3.3129690564237535e-05
rl training, epoch1, iter0, batch69/1133, batch loss:3.3129690564237535e-05, Training time:14718.989716053009
batch reward last col mean 2.336091938559548e-06 first col mean 8.412574970861897e-05 all mean 1.4595398170058616e-05
8.24676317279227e-06 8.24676317279227e-06
rl training, epoch1, iter0, batch70/1133, batch loss:8.24676317279227e-06, Training time:14737.565578222275
batch reward last col mean 3.25281666846422e-06 first col mean 4.984215138392756e-06 all mean 3.0321301892399788e-05
1.6889449398149736e-05 1.688945121713914e-05
rl training, epoch1, iter0, batch71/1133, batch loss:1.688945121713914e-05, Training time:14754.849980354309
batch reward last col mean 1.4199587212715414e-06 first col mean 3.4954387047037017e-06 all mean 2.8730739359161817e-05
8.278308087028563e-05 8.278305904241279e-05
rl training, epoch1, iter0, batch72/1133, batch loss:8.278305904241279e-05, Training time:14772.062355995178
batch reward last col mean 2.838330033227976e-07 first col mean 1.2291387974983081e-05 all mean 2.251484511361923e-05
1.5984071069397032e-05 1.5984072888386436e-05
rl training, epoch1, iter0, batch73/1133, batch loss:1.5984072888386436e-05, Training time:14789.305029630661
batch reward last col mean 3.4302524909435306e-07 first col mean 1.2018267625535373e-06 all mean 1.908739432110451e-05
1.6446645531686954e-05 1.644664371269755e-05
rl training, epoch1, iter0, batch74/1133, batch loss:1.644664371269755e-05, Training time:14806.549984455109
batch reward last col mean 0.00016112549928948283 first col mean 3.057884896406904e-05 all mean 3.1079765903996304e-05
4.974925468559377e-05 4.974925468559377e-05
rl training, epoch1, iter0, batch75/1133, batch loss:4.974925468559377e-05, Training time:14823.78345656395
batch reward last col mean 5.810217089674552e-07 first col mean 1.079287926586403e-06 all mean 3.868727435474284e-05
5.679301102645695e-05 5.679301102645695e-05
rl training, epoch1, iter0, batch76/1133, batch loss:5.679301102645695e-05, Training time:14841.145274400711
batch reward last col mean 3.310372630949132e-05 first col mean 3.14885146508459e-05 all mean 1.8681806977838278e-05
1.967364914889913e-05 1.9673650967888534e-05
rl training, epoch1, iter0, batch77/1133, batch loss:1.9673650967888534e-05, Training time:14858.43314409256
batch reward last col mean 7.746624760329723e-06 first col mean 0.0007121982052922249 all mean 8.48377967486158e-05
0.00016960750508587807 0.00016960750508587807
rl training, epoch1, iter0, batch78/1133, batch loss:0.00016960750508587807, Training time:14875.492149114609
batch reward last col mean 0.0006445859326049685 first col mean 3.3329597499687225e-06 all mean 0.0006075918208807707
0.00010653858043951914 0.00010653858043951914
rl training, epoch1, iter0, batch79/1133, batch loss:0.00010653858043951914, Training time:14892.602314472198
batch reward last col mean 6.0906855651410297e-05 first col mean 3.7697084280807758e-06 all mean 6.40380967524834e-05
2.363087514822837e-05 2.363088060519658e-05
rl training, epoch1, iter0, batch80/1133, batch loss:2.363088060519658e-05, Training time:14909.816566705704
batch reward last col mean 2.686678044483415e-06 first col mean 0.0008042266708798707 all mean 4.1701474401634187e-05
0.0001133406040025875 0.00011334061855450273
rl training, epoch1, iter0, batch81/1133, batch loss:0.00011334061855450273, Training time:14926.985035419464
batch reward last col mean 8.218188440878293e-07 first col mean 0.00019599492952693254 all mean 1.7333204596070573e-05
1.4512125744658988e-05 1.4512124835164286e-05
rl training, epoch1, iter0, batch82/1133, batch loss:1.4512124835164286e-05, Training time:14944.097783088684
batch reward last col mean 0.001000775140710175 first col mean 5.090903505333699e-05 all mean 0.0006172581342980266
0.00010928265692200512 0.00010928265692200512
rl training, epoch1, iter0, batch83/1133, batch loss:0.00010928265692200512, Training time:14964.402524232864
batch reward last col mean 9.431490070710424e-06 first col mean 6.777443923056126e-05 all mean 3.0357066862052307e-05
2.49110071308678e-05 2.49110071308678e-05
rl training, epoch1, iter0, batch84/1133, batch loss:2.49110071308678e-05, Training time:14981.651421785355
batch reward last col mean 2.683971615624614e-06 first col mean 6.017592681928363e-07 all mean 1.1485122740850784e-05
7.493688826798461e-06 7.493688826798461e-06
rl training, epoch1, iter0, batch85/1133, batch loss:7.493688826798461e-06, Training time:14998.913664579391
batch reward last col mean 9.333045909443172e-07 first col mean 0.00012982086627744138 all mean 2.536701322242152e-05
1.3135587323631626e-05 1.3135582776158117e-05
rl training, epoch1, iter0, batch86/1133, batch loss:1.3135582776158117e-05, Training time:15016.078685998917
batch reward last col mean 6.116498752817279e-06 first col mean 4.66878464067122e-06 all mean 2.5465336875640787e-05
2.1486057448782958e-05 2.1486061086761765e-05
rl training, epoch1, iter0, batch87/1133, batch loss:2.1486061086761765e-05, Training time:15033.419311761856
batch reward last col mean 9.963171976323792e-08 first col mean 8.539466762158554e-06 all mean 2.3618909835931845e-05
1.1595304385991767e-05 1.1595302567002364e-05
rl training, epoch1, iter0, batch88/1133, batch loss:1.1595302567002364e-05, Training time:15050.580492734909
batch reward last col mean 0.0013864656211808324 first col mean 6.929857931936567e-07 all mean 0.0008121752762235701
8.947372407419607e-05 8.947372407419607e-05
rl training, epoch1, iter0, batch89/1133, batch loss:8.947372407419607e-05, Training time:15067.818559408188
batch reward last col mean 8.655130159240798e-07 first col mean 1.794067065929994e-05 all mean 1.9712540961336344e-05
2.182278512918856e-05 2.182278512918856e-05
rl training, epoch1, iter0, batch90/1133, batch loss:2.182278512918856e-05, Training time:15085.037334918976
batch reward last col mean 8.733807703720231e-07 first col mean 1.9290878299216274e-06 all mean 2.2678748791804537e-05
2.0238290744600818e-05 2.0238290744600818e-05
rl training, epoch1, iter0, batch91/1133, batch loss:2.0238290744600818e-05, Training time:15102.307397842407
batch reward last col mean 3.4088483857885876e-07 first col mean 3.57685138396846e-07 all mean 1.43223769555334e-05
1.0784434380184393e-05 1.0784434380184393e-05
rl training, epoch1, iter0, batch92/1133, batch loss:1.0784434380184393e-05, Training time:15119.452993869781
batch reward last col mean 4.46544572696439e-06 first col mean 0.0015871254727244377 all mean 6.533856503665447e-05
4.168662417214364e-05 4.168663144810125e-05
rl training, epoch1, iter0, batch93/1133, batch loss:4.168663144810125e-05, Training time:15136.693160533905
batch reward last col mean 1.6192089447031321e-07 first col mean 8.904031574274995e-07 all mean 5.432360012491699e-06
4.0900126805354375e-06 4.0900126805354375e-06
rl training, epoch1, iter0, batch94/1133, batch loss:4.0900126805354375e-06, Training time:15153.82578921318
batch reward last col mean 1.4893348065925238e-07 first col mean 1.643041287024971e-06 all mean 2.144841528206598e-05
1.2843845979659818e-05 1.2843845070165116e-05
rl training, epoch1, iter0, batch95/1133, batch loss:1.2843845070165116e-05, Training time:15170.993489742279
batch reward last col mean 7.119657766452292e-06 first col mean 1.719056672300212e-05 all mean 2.211789797001984e-05
1.385096493322635e-05 1.3850967661710456e-05
rl training, epoch1, iter0, batch96/1133, batch loss:1.3850967661710456e-05, Training time:15190.062325239182
batch reward last col mean 2.581109811217175e-06 first col mean 5.65357731829863e-06 all mean 5.7829653087537736e-05
0.0001622696581762284 0.00016226964362431318
rl training, epoch1, iter0, batch97/1133, batch loss:0.00016226964362431318, Training time:15207.34692788124
batch reward last col mean 4.990299203200266e-06 first col mean 5.606892045761924e-06 all mean 2.1054160242783837e-05
1.609875471331179e-05 1.6098751075332984e-05
rl training, epoch1, iter0, batch98/1133, batch loss:1.6098751075332984e-05, Training time:15224.570848226547
batch reward last col mean 9.824910307543178e-08 first col mean 1.1157766266478575e-06 all mean 6.8213557824492455e-06
6.1819064285373315e-06 6.1819064285373315e-06
rl training, epoch1, iter0, batch99/1133, batch loss:6.1819064285373315e-06, Training time:15243.417433977127
batch reward last col mean 0.0069568040780723095 first col mean 2.180325645895209e-05 all mean 0.006596202962100506
0.0003650856961030513 0.0003650857543107122
rl training, epoch1, iter0, batch100/1133, batch loss:0.0003650857543107122, Training time:15262.65093922615
batch reward last col mean 0.000907345034647733 first col mean 1.1841109426313778e-06 all mean 0.0006619797786697745
0.0001410145778208971 0.00014101459237281233
rl training, epoch1, iter0, batch101/1133, batch loss:0.00014101459237281233, Training time:15279.728190898895
batch reward last col mean 4.516007479082873e-08 first col mean 0.00016740348655730486 all mean 1.0553160791459959e-05
9.938730727299117e-06 9.93873254628852e-06
rl training, epoch1, iter0, batch102/1133, batch loss:9.93873254628852e-06, Training time:15296.891152143478
batch reward last col mean 7.193717692643986e-07 first col mean 5.5024233006406575e-05 all mean 1.7398759155184962e-05
8.959354090620764e-06 8.959351362136658e-06
rl training, epoch1, iter0, batch103/1133, batch loss:8.959351362136658e-06, Training time:15314.130922555923
batch reward last col mean 8.841914677759632e-05 first col mean 5.0274893510504626e-06 all mean 4.329223884269595e-05
4.6176748583093286e-05 4.617674494511448e-05
rl training, epoch1, iter0, batch104/1133, batch loss:4.617674494511448e-05, Training time:15331.271189212799
batch reward last col mean 1.7990705600823276e-06 first col mean 5.909785249968991e-05 all mean 6.880560977151617e-05
9.80972545221448e-05 9.80972545221448e-05
rl training, epoch1, iter0, batch105/1133, batch loss:9.80972545221448e-05, Training time:15348.482610702515
batch reward last col mean 2.0277537259971723e-05 first col mean 2.4783721528365277e-06 all mean 2.5797891794354655e-05
1.7604794265935197e-05 1.7604794265935197e-05
rl training, epoch1, iter0, batch106/1133, batch loss:1.7604794265935197e-05, Training time:15365.71522641182
batch reward last col mean 1.1691865438478999e-05 first col mean 1.4839916730124969e-05 all mean 3.7556241295533255e-05
2.6238452846882865e-05 2.623844557092525e-05
rl training, epoch1, iter0, batch107/1133, batch loss:2.623844557092525e-05, Training time:15384.75758600235
batch reward last col mean 3.8702215533703566e-05 first col mean 4.190602703602053e-05 all mean 2.4792463591438718e-05
4.124084080103785e-05 4.1240844439016655e-05
rl training, epoch1, iter0, batch108/1133, batch loss:4.1240844439016655e-05, Training time:15403.819627046585
batch reward last col mean 2.9097973310854286e-06 first col mean 0.00012500424054451287 all mean 5.0627117161639035e-05
0.00013570193550549448 0.00013570193550549448
rl training, epoch1, iter0, batch109/1133, batch loss:0.00013570193550549448, Training time:15422.90943980217
batch reward last col mean 4.2294890590710565e-05 first col mean 1.919389433169272e-06 all mean 2.2532765797222964e-05
1.5745763448649086e-05 1.5745763448649086e-05
rl training, epoch1, iter0, batch110/1133, batch loss:1.5745763448649086e-05, Training time:15440.124503850937
batch reward last col mean 1.4033159459359013e-05 first col mean 3.108104351667862e-07 all mean 2.746719474089332e-05
3.0910505302017555e-05 3.0910505302017555e-05
rl training, epoch1, iter0, batch111/1133, batch loss:3.0910505302017555e-05, Training time:15457.385613441467
batch reward last col mean 2.1055792842616938e-07 first col mean 0.0002842538815457374 all mean 3.2032225135480985e-05
7.196725346148014e-05 7.196724618552253e-05
rl training, epoch1, iter0, batch112/1133, batch loss:7.196724618552253e-05, Training time:15474.50668168068
batch reward last col mean 3.4771196055771725e-07 first col mean 4.946470653521828e-06 all mean 1.151812648458872e-05
1.0718953490140848e-05 1.0718952580646146e-05
rl training, epoch1, iter0, batch113/1133, batch loss:1.0718952580646146e-05, Training time:15491.6712641716
batch reward last col mean 0.00038382873754017055 first col mean 0.00047585414722561836 all mean 1.825852450565435e-05
3.607233156799339e-05 3.607233156799339e-05
rl training, epoch1, iter0, batch114/1133, batch loss:3.607233156799339e-05, Training time:15508.797982931137
batch reward last col mean 8.647884186530064e-08 first col mean 0.0010105547262355685 all mean 3.4544933441793546e-05
9.572386625222862e-05 9.572387352818623e-05
rl training, epoch1, iter0, batch115/1133, batch loss:9.572387352818623e-05, Training time:15525.92207145691
batch reward last col mean 0.0038087433204054832 first col mean 1.8951783431475633e-07 all mean 0.002993249334394932
0.0002018507948378101 0.00020185078028589487
rl training, epoch1, iter0, batch116/1133, batch loss:0.00020185078028589487, Training time:15543.1254632473
batch reward last col mean 2.774224049062468e-05 first col mean 1.3460705758916447e-06 all mean 3.6218643799657e-05
3.173156073899008e-05 3.173156073899008e-05
rl training, epoch1, iter0, batch117/1133, batch loss:3.173156073899008e-05, Training time:15560.337399244308
batch reward last col mean 3.502645313346875e-06 first col mean 5.7925535656977445e-06 all mean 1.4706112779094838e-05
1.1483300113468431e-05 1.1483300113468431e-05
rl training, epoch1, iter0, batch118/1133, batch loss:1.1483300113468431e-05, Training time:15577.724376916885
batch reward last col mean 4.931319199386053e-05 first col mean 5.102683644508943e-06 all mean 6.03473890805617e-05
9.966232755687088e-05 9.966232755687088e-05
rl training, epoch1, iter0, batch119/1133, batch loss:9.966232755687088e-05, Training time:15594.93898487091
batch reward last col mean 4.729682586912531e-06 first col mean 0.0009100500610657036 all mean 2.236600084870588e-05
1.8771568647935055e-05 1.8771563190966845e-05
rl training, epoch1, iter0, batch120/1133, batch loss:1.8771563190966845e-05, Training time:15612.037108182907
batch reward last col mean 3.3996007005043793e-06 first col mean 3.876652499457123e-06 all mean 4.368108420749195e-05
5.438041625893675e-05 5.4380408982979134e-05
rl training, epoch1, iter0, batch121/1133, batch loss:5.4380408982979134e-05, Training time:15629.1058614254
batch reward last col mean 1.783549305400811e-05 first col mean 1.2060052085871575e-06 all mean 5.29801836819388e-05
6.0484951973194256e-05 6.0484951973194256e-05
rl training, epoch1, iter0, batch122/1133, batch loss:6.0484951973194256e-05, Training time:15646.10546207428
batch reward last col mean 8.330565606229356e-07 first col mean 1.0890602197832777e-06 all mean 1.5137577065615915e-05
1.2124734894314315e-05 1.2124735803809017e-05
rl training, epoch1, iter0, batch123/1133, batch loss:1.2124735803809017e-05, Training time:15663.147115707397
batch reward last col mean 1.5926862033666112e-06 first col mean 4.821406037081033e-06 all mean 2.959528865176253e-05
5.7811826991382986e-05 5.781183790531941e-05
rl training, epoch1, iter0, batch124/1133, batch loss:5.781183790531941e-05, Training time:15680.168668031693
batch reward last col mean 5.287580734147923e-06 first col mean 3.0731532660865923e-06 all mean 1.1737225577235222e-05
1.2303238690947182e-05 1.230323778145248e-05
rl training, epoch1, iter0, batch125/1133, batch loss:1.230323778145248e-05, Training time:15697.112872838974
batch reward last col mean 2.148755083908327e-05 first col mean 1.736498575155565e-06 all mean 2.345905522815883e-05
9.8969649116043e-06 9.8969649116043e-06
rl training, epoch1, iter0, batch126/1133, batch loss:9.8969649116043e-06, Training time:15714.024425506592
batch reward last col mean 1.0417819140684514e-07 first col mean 3.3608889680181164e-06 all mean 2.4046912585617974e-05
3.067602665396407e-05 3.067602665396407e-05
rl training, epoch1, iter0, batch127/1133, batch loss:3.067602665396407e-05, Training time:15731.073270559311
batch reward last col mean 5.623620381811634e-06 first col mean 7.52618097976665e-06 all mean 3.1645922717871144e-05
3.487326102913357e-05 3.487326102913357e-05
rl training, epoch1, iter0, batch128/1133, batch loss:3.487326102913357e-05, Training time:15748.143073558807
batch reward last col mean 1.2991231415071525e-06 first col mean 1.1540171271917643e-06 all mean 7.053971057757735e-05
0.0003055853012483567 0.0003055853012483567
rl training, epoch1, iter0, batch129/1133, batch loss:0.0003055853012483567, Training time:15765.221025943756
batch reward last col mean 4.522605195234064e-06 first col mean 7.851734153518919e-06 all mean 6.006431794958189e-05
0.00018017990805674344 0.00018017989350482821
rl training, epoch1, iter0, batch130/1133, batch loss:0.00018017989350482821, Training time:15782.237710237503
batch reward last col mean 1.682622894350061e-07 first col mean 3.0480887289741077e-06 all mean 2.6877818527282216e-05
5.771515134256333e-06 5.7715178627404384e-06
rl training, epoch1, iter0, batch131/1133, batch loss:5.7715178627404384e-06, Training time:15800.544005155563
batch reward last col mean 3.3597465517232195e-05 first col mean 1.4344643659569556e-06 all mean 3.982834823546e-05
4.0238126530312e-05 4.0238133806269616e-05
rl training, epoch1, iter0, batch132/1133, batch loss:4.0238133806269616e-05, Training time:15819.35394001007
batch reward last col mean 8.24269500299124e-06 first col mean 1.4710540199303068e-06 all mean 1.2313763363636099e-05
1.2239700481586624e-05 1.2239699572091922e-05
rl training, epoch1, iter0, batch133/1133, batch loss:1.2239699572091922e-05, Training time:15836.42451095581
batch reward last col mean 1.3707622201764025e-06 first col mean 0.00047766423085704446 all mean 4.830322359339334e-05
0.00017465365817770362 0.00017465365817770362
rl training, epoch1, iter0, batch134/1133, batch loss:0.00017465365817770362, Training time:15853.665508031845
batch reward last col mean 7.338515388255473e-06 first col mean 8.173227251973003e-05 all mean 2.7394646167522296e-05
2.5656840080046095e-05 2.5656840080046095e-05
rl training, epoch1, iter0, batch135/1133, batch loss:2.5656840080046095e-05, Training time:15870.622443675995
batch reward last col mean 2.3709715605946258e-05 first col mean 5.6909455452114344e-05 all mean 5.6860957556637004e-05
6.963982741581276e-05 6.963982741581276e-05
rl training, epoch1, iter0, batch136/1133, batch loss:6.963982741581276e-05, Training time:15889.573676586151
batch reward last col mean 7.69271809986094e-06 first col mean 3.5665154882735806e-06 all mean 4.8931982746580616e-05
6.834132364019752e-05 6.83413163642399e-05
rl training, epoch1, iter0, batch137/1133, batch loss:6.83413163642399e-05, Training time:15908.567611932755
batch reward last col mean 7.443060781042732e-07 first col mean 7.489636118407361e-06 all mean 2.3076372599462047e-05
2.0874771507806145e-05 2.0874766050837934e-05
rl training, epoch1, iter0, batch138/1133, batch loss:2.0874766050837934e-05, Training time:15927.544167995453
batch reward last col mean 2.31035892284126e-06 first col mean 2.9492837256839266e-06 all mean 2.5428149456274696e-05
1.8544631529948674e-05 1.854463516792748e-05
rl training, epoch1, iter0, batch139/1133, batch loss:1.854463516792748e-05, Training time:15944.569050312042
batch reward last col mean 6.580028752978251e-07 first col mean 2.3338652681559324e-06 all mean 4.95047279400751e-05
2.476630652381573e-05 2.4766313799773343e-05
rl training, epoch1, iter0, batch140/1133, batch loss:2.4766313799773343e-05, Training time:15962.482833147049
batch reward last col mean 1.1755356354115065e-05 first col mean 1.1292788713035407e-06 all mean 3.723868212546222e-05
2.8263979402254336e-05 2.8263977583264932e-05
rl training, epoch1, iter0, batch141/1133, batch loss:2.8263977583264932e-05, Training time:15981.477106332779
batch reward last col mean 3.9314504647336435e-06 first col mean 0.0009055385016836226 all mean 3.160562118864618e-05
1.983991933229845e-05 1.983991933229845e-05
rl training, epoch1, iter0, batch142/1133, batch loss:1.983991933229845e-05, Training time:16000.46513724327
batch reward last col mean 9.70320324995555e-05 first col mean 0.000593881297390908 all mean 0.00015306833665817976
0.0002248420933028683 0.00022484212240669876
rl training, epoch1, iter0, batch143/1133, batch loss:0.00022484212240669876, Training time:16019.639878988266
batch reward last col mean 2.129268614226021e-05 first col mean 0.00030886117019690573 all mean 5.8853827795246616e-05
0.00022487205569632351 0.00022487205569632351
rl training, epoch1, iter0, batch144/1133, batch loss:0.00022487205569632351, Training time:16038.537164211273
batch reward last col mean 3.2309353628079407e-06 first col mean 8.270573744084686e-06 all mean 4.173228080617264e-05
0.00014282306074164808 0.0001428230752935633
rl training, epoch1, iter0, batch145/1133, batch loss:0.0001428230752935633, Training time:16055.669641494751
batch reward last col mean 5.361595754038717e-07 first col mean 2.488200152583886e-05 all mean 0.00010354184632888064
0.00014450571325141937 0.00014450569869950414
rl training, epoch1, iter0, batch146/1133, batch loss:0.00014450569869950414, Training time:16074.573718547821
batch reward last col mean 4.875933882431127e-06 first col mean 1.6161845906026429e-06 all mean 3.295150236226618e-05
4.8069112381199375e-05 4.8069112381199375e-05
rl training, epoch1, iter0, batch147/1133, batch loss:4.8069112381199375e-05, Training time:16093.582373857498
batch reward last col mean 8.151375368470326e-05 first col mean 1.830211840569973e-05 all mean 2.2217896912479773e-05
4.0766302845440805e-05 4.0766299207462e-05
rl training, epoch1, iter0, batch148/1133, batch loss:4.0766299207462e-05, Training time:16110.856442689896
batch reward last col mean 1.8926599295809865e-05 first col mean 1.3421210496744607e-05 all mean 1.297491598961642e-05
7.270213700394379e-06 7.270213700394379e-06
rl training, epoch1, iter0, batch149/1133, batch loss:7.270213700394379e-06, Training time:16128.092390537262
batch reward last col mean 0.0007104428950697184 first col mean 2.761678388196742e-06 all mean 0.0007117708446457982
0.00021566716895904392 0.00021566718351095915
rl training, epoch1, iter0, batch150/1133, batch loss:0.00021566718351095915, Training time:16145.175765991211
batch reward last col mean 2.2570264263777062e-05 first col mean 4.458799139683833e-06 all mean 3.972212289227173e-05
6.321670662146062e-05 6.321670662146062e-05
rl training, epoch1, iter0, batch151/1133, batch loss:6.321670662146062e-05, Training time:16162.446896791458
batch reward last col mean 8.526873784830968e-07 first col mean 1.6235762814176269e-06 all mean 1.5986150174285285e-05
2.97730239253724e-05 2.9773020287393592e-05
rl training, epoch1, iter0, batch152/1133, batch loss:2.9773020287393592e-05, Training time:16179.551438808441
batch reward last col mean 1.612689175090054e-06 first col mean 9.459376997256186e-07 all mean 3.113597267656587e-05
5.654848791891709e-05 5.654848428093828e-05
rl training, epoch1, iter0, batch153/1133, batch loss:5.654848428093828e-05, Training time:16196.674778938293
batch reward last col mean 0.00031954620499163866 first col mean 1.5533257169408898e-07 all mean 0.00023060300736688077
3.666221527964808e-05 3.666221891762689e-05
rl training, epoch1, iter0, batch154/1133, batch loss:3.666221891762689e-05, Training time:16213.781460285187
batch reward last col mean 1.8203876379629946e-06 first col mean 3.068046135012992e-05 all mean 2.4294036848004907e-05
1.678640728641767e-05 1.6786403648438863e-05
rl training, epoch1, iter0, batch155/1133, batch loss:1.6786403648438863e-05, Training time:16230.889464139938
batch reward last col mean 2.2223741325433366e-05 first col mean 1.728090865071863e-05 all mean 2.85248679574579e-05
2.2670488760923035e-05 2.267048512294423e-05
rl training, epoch1, iter0, batch156/1133, batch loss:2.267048512294423e-05, Training time:16248.191129922867
batch reward last col mean 0.0004804411728400737 first col mean 2.514399511710508e-06 all mean 0.00016670759941916913
0.00013739900896325707 0.00013739900896325707
rl training, epoch1, iter0, batch157/1133, batch loss:0.00013739900896325707, Training time:16265.314531803131
batch reward last col mean 4.988136765859963e-07 first col mean 1.468842583562946e-06 all mean 1.3560080333263613e-05
2.5145054678432643e-05 2.5145054678432643e-05
rl training, epoch1, iter0, batch158/1133, batch loss:2.5145054678432643e-05, Training time:16282.656572580338
batch reward last col mean 9.60268039307266e-07 first col mean 1.1364669262547977e-05 all mean 7.055257810861804e-06
8.21599405753659e-06 8.215993148041889e-06
rl training, epoch1, iter0, batch159/1133, batch loss:8.215993148041889e-06, Training time:16299.657388210297
batch reward last col mean 8.591932783019729e-07 first col mean 0.0007908658590167761 all mean 4.390071262605488e-05
5.7399807701585814e-05 5.739981133956462e-05
rl training, epoch1, iter0, batch160/1133, batch loss:5.739981133956462e-05, Training time:16316.593273639679
batch reward last col mean 1.2519943993538618e-05 first col mean 3.510137503326405e-06 all mean 2.317926009709481e-05
3.7981371860951185e-05 3.798137549892999e-05
rl training, epoch1, iter0, batch161/1133, batch loss:3.798137549892999e-05, Training time:16333.602150678635
batch reward last col mean 1.1843456377391703e-05 first col mean 0.0019392360700294375 all mean 6.865163595648482e-05
0.00018273557361681014 0.00018273554451297969
rl training, epoch1, iter0, batch162/1133, batch loss:0.00018273554451297969, Training time:16350.622207403183
batch reward last col mean 1.7489437595941126e-06 first col mean 5.313975998433307e-05 all mean 3.7309087929315865e-05
9.642432269174606e-05 9.642432269174606e-05
rl training, epoch1, iter0, batch163/1133, batch loss:9.642432269174606e-05, Training time:16367.769026756287
batch reward last col mean 7.932469543447951e-07 first col mean 0.0010227480670437217 all mean 3.2059495424618945e-05
4.396254735183902e-05 4.396255098981783e-05
rl training, epoch1, iter0, batch164/1133, batch loss:4.396255098981783e-05, Training time:16384.889479875565
batch reward last col mean 5.532106683858729e-07 first col mean 7.711250873398967e-06 all mean 5.8096935390494764e-05
6.454968388425186e-05 6.454969116020948e-05
rl training, epoch1, iter0, batch165/1133, batch loss:6.454969116020948e-05, Training time:16402.210802316666
batch reward last col mean 2.638899331941502e-06 first col mean 5.303509169607423e-05 all mean 6.701065285596997e-05
0.00021794569329358637 0.00021794569329358637
rl training, epoch1, iter0, batch166/1133, batch loss:0.00021794569329358637, Training time:16419.348116636276
batch reward last col mean 2.189709630329162e-05 first col mean 1.397387222823454e-05 all mean 5.2503492042887956e-05
6.263057002797723e-05 6.263057002797723e-05
rl training, epoch1, iter0, batch167/1133, batch loss:6.263057002797723e-05, Training time:16436.76708292961
batch reward last col mean 1.9334220269229263e-05 first col mean 3.024965280928882e-06 all mean 3.382930299267173e-05
7.137007924029604e-05 7.137007924029604e-05
rl training, epoch1, iter0, batch168/1133, batch loss:7.137007924029604e-05, Training time:16454.29394197464
batch reward last col mean 1.021662455968908e-06 first col mean 5.8956829889211804e-05 all mean 3.313312845421024e-05
3.285010461695492e-05 3.285010461695492e-05
rl training, epoch1, iter0, batch169/1133, batch loss:3.285010461695492e-05, Training time:16471.46505665779
batch reward last col mean 4.607186383509543e-06 first col mean 7.976580036483938e-07 all mean 4.459701813175343e-05
0.0001435482845408842 0.00014354826998896897
rl training, epoch1, iter0, batch170/1133, batch loss:0.00014354826998896897, Training time:16488.76660323143
batch reward last col mean 1.3230127478891518e-05 first col mean 2.1161667973501608e-05 all mean 1.9501147107803263e-05
1.7818145352066495e-05 1.7818147171055898e-05
rl training, epoch1, iter0, batch171/1133, batch loss:1.7818147171055898e-05, Training time:16505.873215675354
batch reward last col mean 7.114130312402267e-06 first col mean 1.1809564057330135e-05 all mean 5.657798101310618e-05
4.979009827366099e-05 4.97901055496186e-05
rl training, epoch1, iter0, batch172/1133, batch loss:4.97901055496186e-05, Training time:16523.116575717926
batch reward last col mean 1.8593739241623553e-06 first col mean 6.775157089577988e-05 all mean 2.0763205611729063e-05
2.9810371415806003e-05 2.9810371415806003e-05
rl training, epoch1, iter0, batch173/1133, batch loss:2.9810371415806003e-05, Training time:16540.32608985901
batch reward last col mean 2.8879378533019917e-06 first col mean 7.2643756539036985e-06 all mean 2.8100368581363e-05
1.2768725355272181e-05 1.2768725355272181e-05
rl training, epoch1, iter0, batch174/1133, batch loss:1.2768725355272181e-05, Training time:16557.488404512405
batch reward last col mean 1.4407666526494722e-07 first col mean 2.6273355047123914e-07 all mean 1.6907993995118886e-05
4.748304490931332e-06 4.748306309920736e-06
rl training, epoch1, iter0, batch175/1133, batch loss:4.748306309920736e-06, Training time:16574.683090925217
batch reward last col mean 1.2330493518675212e-05 first col mean 4.657583303924184e-06 all mean 2.5924222427420318e-05
4.512821033131331e-05 4.51282030553557e-05
rl training, epoch1, iter0, batch176/1133, batch loss:4.51282030553557e-05, Training time:16591.824014663696
batch reward last col mean 7.873089634813368e-05 first col mean 3.2786285828478867e-06 all mean 5.010435779695399e-05
1.5310193703044206e-05 1.5310197341023013e-05
rl training, epoch1, iter0, batch177/1133, batch loss:1.5310197341023013e-05, Training time:16608.9811296463
batch reward last col mean 2.4678029149072245e-06 first col mean 2.3899141524452716e-05 all mean 2.1260979337967e-05
1.1901729521923698e-05 1.1901731340913102e-05
rl training, epoch1, iter0, batch178/1133, batch loss:1.1901731340913102e-05, Training time:16626.162296533585
batch reward last col mean 2.80396056950849e-06 first col mean 6.969598325667903e-05 all mean 2.4048935301834717e-05
3.5071450838586316e-05 3.507144720060751e-05
rl training, epoch1, iter0, batch179/1133, batch loss:3.507144720060751e-05, Training time:16643.285171985626
batch reward last col mean 0.0012630554847419262 first col mean 0.00023828276607673615 all mean 0.0012472934322431684
0.00014318455941975117 0.0001431845303159207
rl training, epoch1, iter0, batch180/1133, batch loss:0.0001431845303159207, Training time:16660.38819503784
batch reward last col mean 6.540003960253671e-05 first col mean 3.3654330763965845e-05 all mean 0.0001589374733157456
0.00012863693700637668 0.00012863692245446146
rl training, epoch1, iter0, batch181/1133, batch loss:0.00012863692245446146, Training time:16677.529079675674
batch reward last col mean 2.788358324323781e-05 first col mean 1.700610482657794e-06 all mean 2.6848116249311715e-05
2.8853282856289297e-05 2.8853282856289297e-05
rl training, epoch1, iter0, batch182/1133, batch loss:2.8853282856289297e-05, Training time:16694.688794612885
batch reward last col mean 2.7924888854613528e-06 first col mean 0.0003547756059560925 all mean 6.307741568889469e-05
0.0002331834693904966 0.00023318348394241184
rl training, epoch1, iter0, batch183/1133, batch loss:0.00023318348394241184, Training time:16711.817872047424
batch reward last col mean 4.561688456306001e-06 first col mean 1.6144475011969917e-05 all mean 5.006001447327435e-05
0.00016076822066679597 0.00016076822066679597
rl training, epoch1, iter0, batch184/1133, batch loss:0.00016076822066679597, Training time:16728.939044475555
batch reward last col mean 7.16656450094888e-06 first col mean 3.844423645205097e-06 all mean 2.9013623134233057e-05
4.62186144432053e-05 4.621860716724768e-05
rl training, epoch1, iter0, batch185/1133, batch loss:4.621860716724768e-05, Training time:16745.998992204666
batch reward last col mean 1.4498522205030895e-06 first col mean 1.8857732584365294e-06 all mean 2.619860060804058e-05
2.796187618514523e-05 2.7961878004134633e-05
rl training, epoch1, iter0, batch186/1133, batch loss:2.7961878004134633e-05, Training time:16763.30970144272
batch reward last col mean 3.632529842434451e-05 first col mean 4.038407951156842e-06 all mean 3.876832852256484e-05
3.19177852361463e-05 3.19177852361463e-05
rl training, epoch1, iter0, batch187/1133, batch loss:3.19177852361463e-05, Training time:16780.67551636696
batch reward last col mean 2.624818762342329e-06 first col mean 2.449279691063566e-06 all mean 3.608656697906554e-05
2.973223126900848e-05 2.9732229450019076e-05
rl training, epoch1, iter0, batch188/1133, batch loss:2.9732229450019076e-05, Training time:16797.738481998444
batch reward last col mean 0.000787553028203547 first col mean 6.621565989917144e-05 all mean 0.0007520596263930202
0.00010178621596423909 0.00010178621596423909
rl training, epoch1, iter0, batch189/1133, batch loss:0.00010178621596423909, Training time:16814.753725528717
batch reward last col mean 4.242376235197298e-06 first col mean 1.156461348728044e-05 all mean 2.0934654457960278e-05
3.024735997314565e-05 3.024735997314565e-05
rl training, epoch1, iter0, batch190/1133, batch loss:3.024735997314565e-05, Training time:16831.994244098663
batch reward last col mean 7.583739261463052e-06 first col mean 0.0017183938762173057 all mean 3.4673801565077156e-05
1.6053563740570098e-05 1.6053556464612484e-05
rl training, epoch1, iter0, batch191/1133, batch loss:1.6053556464612484e-05, Training time:16849.233901500702
batch reward last col mean 5.167700010133558e-07 first col mean 1.2367372619337402e-06 all mean 4.175917638349347e-05
9.159762703347951e-05 9.15976197575219e-05
rl training, epoch1, iter0, batch192/1133, batch loss:9.15976197575219e-05, Training time:16866.229458093643
batch reward last col mean 3.1096440125111258e-06 first col mean 7.40430209589249e-07 all mean 3.924678821931593e-05
5.822960156365298e-05 5.822959792567417e-05
rl training, epoch1, iter0, batch193/1133, batch loss:5.822959792567417e-05, Training time:16883.38143134117
batch reward last col mean 1.9466921003186144e-05 first col mean 7.729895514785312e-06 all mean 1.3947908882983029e-05
5.9183803386986256e-06 5.918379883951275e-06
rl training, epoch1, iter0, batch194/1133, batch loss:5.918379883951275e-06, Training time:16900.62354040146
batch reward last col mean 4.7439795025638887e-07 first col mean 0.001201879931613803 all mean 3.453365570749156e-05
4.3740194087149575e-05 4.374020136310719e-05
rl training, epoch1, iter0, batch195/1133, batch loss:4.374020136310719e-05, Training time:16917.86644101143
batch reward last col mean 3.7939622416161e-05 first col mean 1.2877827657575835e-06 all mean 5.087985482532531e-05
5.6865184888010845e-05 5.6865184888010845e-05
rl training, epoch1, iter0, batch196/1133, batch loss:5.6865184888010845e-05, Training time:16935.153739452362
batch reward last col mean 2.622557440190576e-05 first col mean 6.683126684947638e-06 all mean 7.085766264935955e-05
0.00015600443293806165 0.00015600443293806165
rl training, epoch1, iter0, batch197/1133, batch loss:0.00015600443293806165, Training time:16952.330705165863
batch reward last col mean 9.527303518552799e-06 first col mean 3.904705408785958e-06 all mean 4.554781116894446e-05
3.239231955376454e-05 3.2392308639828116e-05
rl training, epoch1, iter0, batch198/1133, batch loss:3.2392308639828116e-05, Training time:16969.533200740814
batch reward last col mean 1.709346975076187e-06 first col mean 1.5841826552787097e-06 all mean 6.07968722761143e-05
0.00013317604316398501 0.00013317602861206979
rl training, epoch1, iter0, batch199/1133, batch loss:0.00013317602861206979, Training time:16986.65892624855
batch reward last col mean 0.005824800580739975 first col mean 4.321328378864564e-05 all mean 0.004191160202026367
0.0006104512140154839 0.0006104513304308057
rl training, epoch1, iter0, batch200/1133, batch loss:0.0006104513304308057, Training time:17003.7499730587
batch reward last col mean 4.1386333577975165e-06 first col mean 0.000723295786883682 all mean 2.1364507119869813e-05
1.7198442947119474e-05 1.7198442947119474e-05
rl training, epoch1, iter0, batch201/1133, batch loss:1.7198442947119474e-05, Training time:17021.63688325882
batch reward last col mean 7.253640887938673e-07 first col mean 2.4569101242377656e-06 all mean 2.0512057744781487e-05
1.969223376363516e-05 1.9692235582624562e-05
rl training, epoch1, iter0, batch202/1133, batch loss:1.9692235582624562e-05, Training time:17038.84562444687
batch reward last col mean 3.04529930872377e-06 first col mean 8.664221695653396e-07 all mean 2.096371645166073e-05
2.0904433768009767e-05 2.090443013003096e-05
rl training, epoch1, iter0, batch203/1133, batch loss:2.090443013003096e-05, Training time:17056.02991437912
batch reward last col mean 1.0138840480067302e-05 first col mean 7.472509082617762e-07 all mean 2.6652847736841068e-05
5.2291965403128415e-05 5.229197267908603e-05
rl training, epoch1, iter0, batch204/1133, batch loss:5.229197267908603e-05, Training time:17073.24874329567
batch reward last col mean 0.0015811935300007463 first col mean 4.09124504585634e-06 all mean 0.0012082635657861829
0.00019601495296228677 0.00019601495296228677
rl training, epoch1, iter0, batch205/1133, batch loss:0.00019601495296228677, Training time:17090.472875595093
batch reward last col mean 6.157972052278637e-07 first col mean 8.170763976522721e-06 all mean 3.333219501655549e-05
4.518785499385558e-05 4.5187851355876774e-05
rl training, epoch1, iter0, batch206/1133, batch loss:4.5187851355876774e-05, Training time:17107.588187217712
batch reward last col mean 0.00013895530719310045 first col mean 3.5996160931972554e-06 all mean 6.480153388110921e-05
2.8571217626449652e-05 2.8571217626449652e-05
rl training, epoch1, iter0, batch207/1133, batch loss:2.8571217626449652e-05, Training time:17124.821613788605
batch reward last col mean 1.0680564628273714e-06 first col mean 1.3640128599945456e-05 all mean 1.456882273487281e-05
9.02722058526706e-06 9.02722058526706e-06
rl training, epoch1, iter0, batch208/1133, batch loss:9.02722058526706e-06, Training time:17142.248413324356
batch reward last col mean 1.3472214277499006e-07 first col mean 2.691720737857395e-06 all mean 3.052140527870506e-05
1.691289980954025e-05 1.6912903447519056e-05
rl training, epoch1, iter0, batch209/1133, batch loss:1.6912903447519056e-05, Training time:17159.89290189743
batch reward last col mean 2.2227797671803273e-05 first col mean 3.0475725907308515e-06 all mean 3.7905530916759744e-05
3.37954297719989e-05 3.37954297719989e-05
rl training, epoch1, iter0, batch210/1133, batch loss:3.37954297719989e-05, Training time:17177.048978090286
batch reward last col mean 1.1474816119516618e-06 first col mean 0.0017146931495517492 all mean 9.417768160346895e-05
0.00021101096353959292 0.00021101097809150815
rl training, epoch1, iter0, batch211/1133, batch loss:0.00021101097809150815, Training time:17194.168113470078
batch reward last col mean 3.36107092380189e-07 first col mean 6.235291039047297e-06 all mean 3.446436676313169e-05
2.1161395125091076e-05 2.1161389668122865e-05
rl training, epoch1, iter0, batch212/1133, batch loss:2.1161389668122865e-05, Training time:17211.14568400383
batch reward last col mean 2.130274197043036e-06 first col mean 4.013842954009306e-06 all mean 3.227399429306388e-05
3.789166294154711e-05 3.7891670217504725e-05
rl training, epoch1, iter0, batch213/1133, batch loss:3.7891670217504725e-05, Training time:17228.329473018646
batch reward last col mean 6.145354291220428e-06 first col mean 8.076103767962195e-07 all mean 5.8371319028083235e-05
7.026451930869371e-05 7.026451930869371e-05
rl training, epoch1, iter0, batch214/1133, batch loss:7.026451930869371e-05, Training time:17245.59372472763
batch reward last col mean 0.004700887482613325 first col mean 0.00023067065922077745 all mean 0.00417529558762908
0.00043390123755671084 0.00043390123755671084
rl training, epoch1, iter0, batch215/1133, batch loss:0.00043390123755671084, Training time:17262.790425777435
batch reward last col mean 1.6025126114982413e-06 first col mean 9.064729056262877e-06 all mean 8.748193067731336e-06
8.33621288620634e-06 8.336213795701042e-06
rl training, epoch1, iter0, batch216/1133, batch loss:8.336213795701042e-06, Training time:17279.987867116928
batch reward last col mean 8.593726670369506e-05 first col mean 0.0001897207839647308 all mean 4.991480818716809e-05
3.543861384969205e-05 3.543861384969205e-05
rl training, epoch1, iter0, batch217/1133, batch loss:3.543861384969205e-05, Training time:17297.181208372116
batch reward last col mean 1.4402760371012846e-06 first col mean 1.0859634130611084e-05 all mean 8.7294502009172e-06
1.060021259036148e-05 1.0600210771372076e-05
rl training, epoch1, iter0, batch218/1133, batch loss:1.0600210771372076e-05, Training time:17314.28996682167
batch reward last col mean 6.068493121347274e-07 first col mean 5.478286198012938e-07 all mean 1.5385292499559e-05
1.1713932508428115e-05 1.1713932508428115e-05
rl training, epoch1, iter0, batch219/1133, batch loss:1.1713932508428115e-05, Training time:17331.353559732437
batch reward last col mean 0.000524332164786756 first col mean 7.257385732373223e-06 all mean 0.0005267983651719987
6.778751412639394e-05 6.778751412639394e-05
rl training, epoch1, iter0, batch220/1133, batch loss:6.778751412639394e-05, Training time:17348.432670116425
batch reward last col mean 1.1025518631413433e-07 first col mean 0.00027821279945783317 all mean 3.299288800917566e-05
7.93329527368769e-05 7.933294546091929e-05
rl training, epoch1, iter0, batch221/1133, batch loss:7.933294546091929e-05, Training time:17365.487574338913
batch reward last col mean 0.00010626735456753522 first col mean 0.00015679839998483658 all mean 6.144931103335693e-05
0.0001322730240644887 0.0001322730240644887
rl training, epoch1, iter0, batch222/1133, batch loss:0.0001322730240644887, Training time:17382.591076612473
batch reward last col mean 2.874664914997993e-07 first col mean 9.570494512445293e-06 all mean 2.8558852136484347e-05
6.974714779062197e-05 6.974715506657958e-05
rl training, epoch1, iter0, batch223/1133, batch loss:6.974715506657958e-05, Training time:17399.590925216675
batch reward last col mean 5.308222057465173e-07 first col mean 2.0309234969317913e-05 all mean 3.62203354598023e-05
7.126759010134265e-05 7.126759010134265e-05
rl training, epoch1, iter0, batch224/1133, batch loss:7.126759010134265e-05, Training time:17416.80604672432
batch reward last col mean 4.2023069113383826e-07 first col mean 5.024472193326801e-05 all mean 3.298206866020337e-05
6.018144267727621e-05 6.018144267727621e-05
rl training, epoch1, iter0, batch225/1133, batch loss:6.018144267727621e-05, Training time:17433.961406230927
batch reward last col mean 4.168789018876851e-06 first col mean 4.434227776073385e-06 all mean 6.600464985240251e-05
0.0003207674599252641 0.0003207674599252641
rl training, epoch1, iter0, batch226/1133, batch loss:0.0003207674599252641, Training time:17450.948350191116
batch reward last col mean 1.9777593479375355e-05 first col mean 1.0952007869491354e-06 all mean 2.5559711502864957e-05
1.1808837371063419e-05 1.1808837371063419e-05
rl training, epoch1, iter0, batch227/1133, batch loss:1.1808837371063419e-05, Training time:17467.906745433807
batch reward last col mean 7.206790178315714e-05 first col mean 2.6698155124904588e-05 all mean 3.619388007791713e-05
3.776029188884422e-05 3.776029188884422e-05
rl training, epoch1, iter0, batch228/1133, batch loss:3.776029188884422e-05, Training time:17484.947290182114
batch reward last col mean 1.6521532870683586e-06 first col mean 8.540429234926705e-07 all mean 1.2157147466496099e-05
1.3955494068795815e-05 1.395549679727992e-05
rl training, epoch1, iter0, batch229/1133, batch loss:1.395549679727992e-05, Training time:17502.023507118225
batch reward last col mean 1.794105628505349e-05 first col mean 0.00017967801250051707 all mean 2.9220753276604228e-05
1.7136115275206976e-05 1.713611163722817e-05
rl training, epoch1, iter0, batch230/1133, batch loss:1.713611163722817e-05, Training time:17519.427528619766
batch reward last col mean 3.91151888834429e-06 first col mean 6.209158163983375e-05 all mean 2.8331432986306027e-05
2.7562809918890707e-05 2.756281173788011e-05
rl training, epoch1, iter0, batch231/1133, batch loss:2.756281173788011e-05, Training time:17536.419273614883
batch reward last col mean 2.2822919731879665e-07 first col mean 0.0036488070618361235 all mean 7.304207247216254e-05
0.00012802485434804112 0.00012802485434804112
rl training, epoch1, iter0, batch232/1133, batch loss:0.00012802485434804112, Training time:17553.649656534195
batch reward last col mean 6.471844699262874e-06 first col mean 0.0016802569152787328 all mean 7.084695243975148e-05
7.363278564298525e-05 7.363278564298525e-05
rl training, epoch1, iter0, batch233/1133, batch loss:7.363278564298525e-05, Training time:17570.769248008728
batch reward last col mean 4.744226771435933e-07 first col mean 1.531061570858583e-05 all mean 4.021152199129574e-05
6.799850234529004e-05 6.799850962124765e-05
rl training, epoch1, iter0, batch234/1133, batch loss:6.799850962124765e-05, Training time:17587.993391275406
batch reward last col mean 1.060948216036195e-05 first col mean 4.860361855207884e-07 all mean 3.208094494766556e-05
3.3900021662702784e-05 3.3900021662702784e-05
rl training, epoch1, iter0, batch235/1133, batch loss:3.3900021662702784e-05, Training time:17605.04644536972
batch reward last col mean 1.535946285002865e-05 first col mean 0.00012398757098708302 all mean 2.9095237550791353e-05
1.250642799277557e-05 1.250642799277557e-05
rl training, epoch1, iter0, batch236/1133, batch loss:1.250642799277557e-05, Training time:17622.2031788826
batch reward last col mean 0.0030118583235889673 first col mean 1.7599959392100573e-06 all mean 0.0029563482385128736
0.0002692013804335147 0.00026920140953734517
rl training, epoch1, iter0, batch237/1133, batch loss:0.00026920140953734517, Training time:17639.414792776108
batch reward last col mean 4.012532315300632e-07 first col mean 4.688299668487161e-06 all mean 7.212533091660589e-05
0.00016493117436766624 0.00016493117436766624
rl training, epoch1, iter0, batch238/1133, batch loss:0.00016493117436766624, Training time:17656.745402812958
batch reward last col mean 8.39708955027163e-05 first col mean 1.6697547835065052e-05 all mean 0.0001291660446440801
4.336209167377092e-05 4.3362095311749727e-05
rl training, epoch1, iter0, batch239/1133, batch loss:4.3362095311749727e-05, Training time:17674.010900259018
batch reward last col mean 5.532358500204282e-06 first col mean 4.517604611464776e-05 all mean 3.335258588776924e-05
8.305683149956167e-05 8.305683149956167e-05
rl training, epoch1, iter0, batch240/1133, batch loss:8.305683149956167e-05, Training time:17691.173571825027
batch reward last col mean 1.4189074136083946e-05 first col mean 0.001324120326898992 all mean 2.7120371669298038e-05
6.762910197721794e-05 6.762909470126033e-05
rl training, epoch1, iter0, batch241/1133, batch loss:6.762909470126033e-05, Training time:17708.189215183258
batch reward last col mean 1.6849207895575091e-06 first col mean 8.514395631209482e-06 all mean 5.116853571962565e-05
9.612008580006659e-05 9.612007852410898e-05
rl training, epoch1, iter0, batch242/1133, batch loss:9.612007852410898e-05, Training time:17726.52302312851
batch reward last col mean 1.0863072930078488e-05 first col mean 2.8996344099141425e-06 all mean 3.2353844289900735e-05
4.7645567974541336e-05 4.7645567974541336e-05
rl training, epoch1, iter0, batch243/1133, batch loss:4.7645567974541336e-05, Training time:17743.77929186821
batch reward last col mean 3.115107574558351e-06 first col mean 7.457411265932024e-05 all mean 4.604256173479371e-05
0.00010855460277525708 0.00010855459549929947
rl training, epoch1, iter0, batch244/1133, batch loss:0.00010855459549929947, Training time:17760.98620533943
batch reward last col mean 1.8514062958274735e-06 first col mean 0.00012383298599161208 all mean 1.9517199689289555e-05
2.4872186259017326e-05 2.487218807800673e-05
rl training, epoch1, iter0, batch245/1133, batch loss:2.487218807800673e-05, Training time:17778.156795024872
batch reward last col mean 0.0069048344157636166 first col mean 0.0004118615761399269 all mean 0.006312970537692308
0.0008004700066521764 0.0008004701230674982
rl training, epoch1, iter0, batch246/1133, batch loss:0.0008004701230674982, Training time:17795.2863137722
batch reward last col mean 1.3875057902623666e-06 first col mean 0.001915843109600246 all mean 5.627349310088903e-05
3.4138778573833406e-05 3.4138767659896985e-05
rl training, epoch1, iter0, batch247/1133, batch loss:3.4138767659896985e-05, Training time:17813.733783721924
batch reward last col mean 1.4847418583485705e-07 first col mean 5.765034984506201e-06 all mean 3.388799086678773e-05
1.729308678477537e-05 1.7293079508817755e-05
rl training, epoch1, iter0, batch248/1133, batch loss:1.7293079508817755e-05, Training time:17832.873403549194
batch reward last col mean 3.06471592921298e-05 first col mean 0.0013702405849471688 all mean 5.364165917853825e-05
2.887232585635502e-05 2.8872334951302037e-05
rl training, epoch1, iter0, batch249/1133, batch loss:2.8872334951302037e-05, Training time:17851.96799492836
batch reward last col mean 3.312748231110163e-05 first col mean 5.860043529537506e-06 all mean 5.228414011071436e-05
5.678695742972195e-05 5.678695742972195e-05
rl training, epoch1, iter0, batch250/1133, batch loss:5.678695742972195e-05, Training time:17869.17719721794
batch reward last col mean 1.528871393929876e-06 first col mean 3.211968578398228e-05 all mean 2.166301965189632e-05
8.111486386042088e-05 8.111485658446327e-05
rl training, epoch1, iter0, batch251/1133, batch loss:8.111485658446327e-05, Training time:17886.311007022858
batch reward last col mean 0.0002711101551540196 first col mean 0.00038160840631462634 all mean 0.00027490255888551474
3.8149981264723465e-05 3.814998854068108e-05
rl training, epoch1, iter0, batch252/1133, batch loss:3.814998854068108e-05, Training time:17903.48565864563
batch reward last col mean 1.2335471183178015e-05 first col mean 2.4956589186331257e-06 all mean 4.973119939677417e-05
0.00010250381455989555 0.00010250381455989555
rl training, epoch1, iter0, batch253/1133, batch loss:0.00010250381455989555, Training time:17921.653151988983
batch reward last col mean 6.014254267938668e-07 first col mean 0.001823535654693842 all mean 4.242221257300116e-05
4.446446109795943e-05 4.446447201189585e-05
rl training, epoch1, iter0, batch254/1133, batch loss:4.446447201189585e-05, Training time:17938.699199438095
batch reward last col mean 5.055748260929249e-06 first col mean 3.3847583836177364e-05 all mean 1.672767939453479e-05
1.4990887393651064e-05 1.4990887393651064e-05
rl training, epoch1, iter0, batch255/1133, batch loss:1.4990887393651064e-05, Training time:17955.706182718277
batch reward last col mean 5.800898179586511e-07 first col mean 0.00010332409874536097 all mean 4.173890920355916e-05
0.00010246257443213835 0.00010246257443213835
rl training, epoch1, iter0, batch256/1133, batch loss:0.00010246257443213835, Training time:17973.415115594864
batch reward last col mean 2.2769458155380562e-05 first col mean 0.0001950307487277314 all mean 6.467143975896761e-05
0.00012346515723038465 0.00012346517178229988
rl training, epoch1, iter0, batch257/1133, batch loss:0.00012346517178229988, Training time:17990.638782024384
batch reward last col mean 0.000353850016836077 first col mean 2.89484432869358e-06 all mean 0.0003607218968681991
0.00012288578727748245 0.00012288578727748245
rl training, epoch1, iter0, batch258/1133, batch loss:0.00012288578727748245, Training time:18008.904698848724
batch reward last col mean 6.572173879249021e-05 first col mean 6.295532330113929e-06 all mean 2.5224513592547737e-05
2.5441266188863665e-05 2.544126800785307e-05
rl training, epoch1, iter0, batch259/1133, batch loss:2.544126800785307e-05, Training time:18026.19497847557
batch reward last col mean 2.3415354007738642e-05 first col mean 1.7770558997654007e-06 all mean 3.596947863115929e-05
4.587134753819555e-05 4.587134753819555e-05
rl training, epoch1, iter0, batch260/1133, batch loss:4.587134753819555e-05, Training time:18043.42868256569
batch reward last col mean 4.0480449570168275e-07 first col mean 0.0005389737780205905 all mean 3.419113636482507e-05
0.0001440482446923852 0.0001440482446923852
rl training, epoch1, iter0, batch261/1133, batch loss:0.0001440482446923852, Training time:18060.63854289055
batch reward last col mean 1.0422768355056178e-06 first col mean 0.0018939876463264227 all mean 7.945931429276243e-05
0.0001830510445870459 0.0001830510445870459
rl training, epoch1, iter0, batch262/1133, batch loss:0.0001830510445870459, Training time:18077.80952692032
batch reward last col mean 2.5980511964007746e-07 first col mean 2.9541811272792984e-06 all mean 6.578029115189565e-06
1.0378557817602996e-05 1.0378557817602996e-05
rl training, epoch1, iter0, batch263/1133, batch loss:1.0378557817602996e-05, Training time:18094.992810726166
batch reward last col mean 4.421354788064491e-06 first col mean 2.3113974748412147e-05 all mean 4.248343611834571e-05
5.0355120038148016e-05 5.0355120038148016e-05
rl training, epoch1, iter0, batch264/1133, batch loss:5.0355120038148016e-05, Training time:18112.253206014633
batch reward last col mean 0.00033956713741645217 first col mean 0.0002093238872475922 all mean 0.00026224134489893913
0.0002153442765120417 0.0002153442765120417
rl training, epoch1, iter0, batch265/1133, batch loss:0.0002153442765120417, Training time:18129.492721557617
batch reward last col mean 6.784100605727872e-07 first col mean 5.672840188708506e-07 all mean 5.04154922964517e-05
3.087676304858178e-05 3.0876755772624165e-05
rl training, epoch1, iter0, batch266/1133, batch loss:3.0876755772624165e-05, Training time:18148.652665138245
batch reward last col mean 8.997127309839925e-08 first col mean 2.465657871653093e-06 all mean 5.1528892072383314e-05
5.9369223890826106e-05 5.9369223890826106e-05
rl training, epoch1, iter0, batch267/1133, batch loss:5.9369223890826106e-05, Training time:18165.809792995453
batch reward last col mean 7.911618922662456e-06 first col mean 1.86129236681154e-05 all mean 5.509803304448724e-05
4.229107071296312e-05 4.229107071296312e-05
rl training, epoch1, iter0, batch268/1133, batch loss:4.229107071296312e-05, Training time:18182.890414714813
batch reward last col mean 5.662761850544484e-06 first col mean 5.677796252712142e-06 all mean 2.1736461349064484e-05
1.8778951925924048e-05 1.8778950106934644e-05
rl training, epoch1, iter0, batch269/1133, batch loss:1.8778950106934644e-05, Training time:18199.974807024002
batch reward last col mean 0.005352373700588942 first col mean 7.181823548307875e-06 all mean 0.0051112547516822815
0.00029102611006237566 0.0002910261391662061
rl training, epoch1, iter0, batch270/1133, batch loss:0.0002910261391662061, Training time:18217.08580493927
batch reward last col mean 5.693980710930191e-06 first col mean 0.00020244403276592493 all mean 4.4088596041547135e-05
7.828258094377816e-05 7.828257366782054e-05
rl training, epoch1, iter0, batch271/1133, batch loss:7.828257366782054e-05, Training time:18234.257395505905
batch reward last col mean 1.0806056707224343e-06 first col mean 7.836612212486216e-07 all mean 4.8929294280242175e-05
0.00011786026152549312 0.00011786026152549312
rl training, epoch1, iter0, batch272/1133, batch loss:0.00011786026152549312, Training time:18251.342248678207
batch reward last col mean 3.944649506593123e-06 first col mean 1.0942355402221438e-05 all mean 2.5194485715474002e-05
4.694663221016526e-05 4.694663584814407e-05
rl training, epoch1, iter0, batch273/1133, batch loss:4.694663584814407e-05, Training time:18268.48080086708
batch reward last col mean 0.0015273155877366662 first col mean 0.0003081596514675766 all mean 0.0007364739431068301
0.0001367606600979343 0.0001367606600979343
rl training, epoch1, iter0, batch274/1133, batch loss:0.0001367606600979343, Training time:18286.058132886887
batch reward last col mean 1.5096757124410942e-06 first col mean 1.3807924005959649e-05 all mean 2.3937496735015884e-05
0.00011843586253235117 0.00011843586253235117
rl training, epoch1, iter0, batch275/1133, batch loss:0.00011843586253235117, Training time:18303.253775835037
batch reward last col mean 3.1857999260864744e-07 first col mean 2.449092335155001e-06 all mean 3.678402936202474e-05
6.0275877331150696e-05 6.0275877331150696e-05
rl training, epoch1, iter0, batch276/1133, batch loss:6.0275877331150696e-05, Training time:18320.4561150074
batch reward last col mean 0.0007375566638074815 first col mean 1.5669816093577538e-06 all mean 0.0006508492515422404
0.0006755004869773984 0.0006755006033927202
rl training, epoch1, iter0, batch277/1133, batch loss:0.0006755006033927202, Training time:18337.513872385025
batch reward last col mean 3.0421442716033198e-05 first col mean 7.52669393477845e-06 all mean 2.3963480998645537e-05
1.4721926163474564e-05 1.4721928891958669e-05
rl training, epoch1, iter0, batch278/1133, batch loss:1.4721928891958669e-05, Training time:18354.79353237152
batch reward last col mean 6.096488141338341e-05 first col mean 2.4719997782085557e-06 all mean 3.9001221011858433e-05
2.278792999277357e-05 2.278792999277357e-05
rl training, epoch1, iter0, batch279/1133, batch loss:2.278792999277357e-05, Training time:18372.11769747734
batch reward last col mean 3.667400960694067e-05 first col mean 1.32344785015448e-05 all mean 4.774549961439334e-05
1.7194790416397154e-05 1.7194790416397154e-05
rl training, epoch1, iter0, batch280/1133, batch loss:1.7194790416397154e-05, Training time:18389.41257596016
batch reward last col mean 3.218315782760328e-07 first col mean 9.878523997031152e-05 all mean 1.3344695616979152e-05
6.920167379576014e-06 6.9201669248286635e-06
rl training, epoch1, iter0, batch281/1133, batch loss:6.9201669248286635e-06, Training time:18406.346769094467
batch reward last col mean 0.007143673952668905 first col mean 4.2164185288129374e-05 all mean 0.006343541666865349
0.0008612457313574851 0.0008612457313574851
rl training, epoch1, iter0, batch282/1133, batch loss:0.0008612457313574851, Training time:18423.301899194717
batch reward last col mean 6.022644811309874e-06 first col mean 3.4199479159724433e-07 all mean 3.244238541810773e-05
3.872522574965842e-05 3.872522574965842e-05
rl training, epoch1, iter0, batch283/1133, batch loss:3.872522574965842e-05, Training time:18440.389407634735
batch reward last col mean 0.0035994735080748796 first col mean 0.0006347420276142657 all mean 0.00327892554923892
0.0003505577624309808 0.0003505577624309808
rl training, epoch1, iter0, batch284/1133, batch loss:0.0003505577624309808, Training time:18459.24361681938
batch reward last col mean 1.2405801498971414e-05 first col mean 1.9874420104315504e-05 all mean 2.147675331798382e-05
2.5820078008109704e-05 2.58200761891203e-05
rl training, epoch1, iter0, batch285/1133, batch loss:2.58200761891203e-05, Training time:18476.53957605362
batch reward last col mean 0.004390592221170664 first col mean 9.522426807961892e-06 all mean 0.004074497614055872
0.00032359655597247183 0.00032359655597247183
rl training, epoch1, iter0, batch286/1133, batch loss:0.00032359655597247183, Training time:18493.717292547226
batch reward last col mean 1.6073588994913734e-05 first col mean 2.3111102564143948e-05 all mean 1.6258589312201366e-05
2.6243347747367807e-05 2.6243345928378403e-05
rl training, epoch1, iter0, batch287/1133, batch loss:2.6243345928378403e-05, Training time:18510.87955880165
batch reward last col mean 1.1853977639475488e-06 first col mean 0.00017735871369950473 all mean 5.714674625778571e-05
6.841764115961269e-05 6.84176484355703e-05
rl training, epoch1, iter0, batch288/1133, batch loss:6.84176484355703e-05, Training time:18528.060956954956
batch reward last col mean 1.3164939218768268e-06 first col mean 2.1521861981455004e-06 all mean 2.749537816271186e-05
2.9491373425116763e-05 2.949137160612736e-05
rl training, epoch1, iter0, batch289/1133, batch loss:2.949137160612736e-05, Training time:18545.19979071617
batch reward last col mean 4.273232480045408e-05 first col mean 5.772721488028765e-05 all mean 6.101331382524222e-05
1.931407314259559e-05 1.931406768562738e-05
rl training, epoch1, iter0, batch290/1133, batch loss:1.931406768562738e-05, Training time:18562.291664361954
batch reward last col mean 0.00014256684517022222 first col mean 4.195232122583548e-06 all mean 0.0001288781495532021
4.4434058509068564e-05 4.4434058509068564e-05
rl training, epoch1, iter0, batch291/1133, batch loss:4.4434058509068564e-05, Training time:18579.597076416016
batch reward last col mean 4.252946382621303e-05 first col mean 1.04927391930687e-06 all mean 6.607731484109536e-05
2.584086723800283e-05 2.584086723800283e-05
rl training, epoch1, iter0, batch292/1133, batch loss:2.584086723800283e-05, Training time:18596.73369884491
batch reward last col mean 1.9828214590233983e-06 first col mean 6.400210986612365e-05 all mean 1.3690526429854799e-05
8.638849067210685e-06 8.638850886200089e-06
rl training, epoch1, iter0, batch293/1133, batch loss:8.638850886200089e-06, Training time:18613.84713459015
batch reward last col mean 7.198030971267144e-07 first col mean 1.5204610463115387e-05 all mean 3.088834637310356e-05
4.02876794396434e-05 4.0287672163685784e-05
rl training, epoch1, iter0, batch294/1133, batch loss:4.0287672163685784e-05, Training time:18631.005395650864
batch reward last col mean 2.310282980033662e-06 first col mean 8.796700967650395e-07 all mean 3.484889384708367e-05
5.445764327305369e-05 5.4457639635074884e-05
rl training, epoch1, iter0, batch295/1133, batch loss:5.4457639635074884e-05, Training time:18648.12573671341
batch reward last col mean 4.294483005651273e-06 first col mean 1.170683026430197e-05 all mean 6.718144868500531e-05
0.00018374493811279535 0.00018374493811279535
rl training, epoch1, iter0, batch296/1133, batch loss:0.00018374493811279535, Training time:18665.183098077774
batch reward last col mean 0.0002288662362843752 first col mean 6.205249064805685e-06 all mean 9.848178160609677e-05
8.651283133076504e-05 8.651283133076504e-05
rl training, epoch1, iter0, batch297/1133, batch loss:8.651283133076504e-05, Training time:18682.24821829796
batch reward last col mean 7.83596334485992e-08 first col mean 1.3652249435835984e-05 all mean 3.4776225220412016e-05
0.00021844475122634321 0.00021844475122634321
rl training, epoch1, iter0, batch298/1133, batch loss:0.00021844475122634321, Training time:18699.404930353165
batch reward last col mean 0.00015333150804508477 first col mean 2.873970743166865e-06 all mean 0.00019010476535186172
8.306581730721518e-05 8.306581730721518e-05
rl training, epoch1, iter0, batch299/1133, batch loss:8.306581730721518e-05, Training time:18716.609226226807
batch reward last col mean 1.2825853445974644e-06 first col mean 0.0005849325680173934 all mean 3.877672861563042e-05
5.280545155983418e-05 5.280545155983418e-05
rl training, epoch1, iter0, batch300/1133, batch loss:5.280545155983418e-05, Training time:18733.846844673157
batch reward last col mean 1.5802095276740147e-06 first col mean 5.699966095562559e-06 all mean 3.3655818697297946e-05
0.00012285372940823436 0.00012285375851206481
rl training, epoch1, iter0, batch301/1133, batch loss:0.00012285375851206481, Training time:18750.908801078796
batch reward last col mean 4.644967702915892e-06 first col mean 1.2332310461715679e-06 all mean 1.853272806329187e-05
1.0348016076022759e-05 1.0348016076022759e-05
rl training, epoch1, iter0, batch302/1133, batch loss:1.0348016076022759e-05, Training time:18767.872486829758
batch reward last col mean 0.00011216417624382302 first col mean 3.919727896573022e-05 all mean 0.00011290196562185884
7.944824756123126e-05 7.944824756123126e-05
rl training, epoch1, iter0, batch303/1133, batch loss:7.944824756123126e-05, Training time:18785.08747935295
batch reward last col mean 4.5410884922603145e-05 first col mean 0.0002048320311587304 all mean 6.736643990734592e-05
0.00016099278582260013 0.00016099278582260013
rl training, epoch1, iter0, batch304/1133, batch loss:0.00016099278582260013, Training time:18802.14699935913
batch reward last col mean 3.05458452203311e-05 first col mean 0.00022982488735578954 all mean 8.135246025631204e-05
0.00011414185428293422 0.0001141418470069766
rl training, epoch1, iter0, batch305/1133, batch loss:0.0001141418470069766, Training time:18819.214200496674
batch reward last col mean 3.076278289881884e-06 first col mean 7.002632628427818e-05 all mean 1.210196569445543e-05
1.1106221791123971e-05 1.1106221791123971e-05
rl training, epoch1, iter0, batch306/1133, batch loss:1.1106221791123971e-05, Training time:18836.216315984726
batch reward last col mean 7.257465313159628e-07 first col mean 3.015392394445371e-06 all mean 1.633629835851025e-05
1.1780555723817088e-05 1.1780554814322386e-05
rl training, epoch1, iter0, batch307/1133, batch loss:1.1780554814322386e-05, Training time:18853.308134317398
batch reward last col mean 4.104061736143194e-05 first col mean 4.8770129069453105e-05 all mean 3.822015059995465e-05
8.946359594119713e-05 8.946359594119713e-05
rl training, epoch1, iter0, batch308/1133, batch loss:8.946359594119713e-05, Training time:18871.305127859116
batch reward last col mean 3.787110699704499e-06 first col mean 1.3679534276889171e-05 all mean 2.237297667306848e-05
4.770391751662828e-05 4.770391751662828e-05
rl training, epoch1, iter0, batch309/1133, batch loss:4.770391751662828e-05, Training time:18888.46041083336
batch reward last col mean 0.00020902528194710612 first col mean 1.9446124497335404e-05 all mean 0.00012049744691466913
0.00016563534154556692 0.00016563534154556692
rl training, epoch1, iter0, batch310/1133, batch loss:0.00016563534154556692, Training time:18905.553921699524
batch reward last col mean 3.056312607441214e-06 first col mean 0.0010436851298436522 all mean 3.346236189827323e-05
7.932388689368963e-05 7.932388689368963e-05
rl training, epoch1, iter0, batch311/1133, batch loss:7.932388689368963e-05, Training time:18923.233842611313
batch reward last col mean 9.122003916672838e-07 first col mean 4.571701083477819e-06 all mean 2.248095188406296e-05
3.502748586470261e-05 3.502748586470261e-05
rl training, epoch1, iter0, batch312/1133, batch loss:3.502748586470261e-05, Training time:18940.30863261223
batch reward last col mean 2.2351629013428465e-05 first col mean 2.644046162458835e-06 all mean 4.620754043571651e-05
5.900739415665157e-05 5.900739779463038e-05
rl training, epoch1, iter0, batch313/1133, batch loss:5.900739779463038e-05, Training time:18957.383038282394
batch reward last col mean 2.0188483176752925e-05 first col mean 0.0001752532261889428 all mean 3.139823456876911e-05
1.0363441106164828e-05 1.0363441106164828e-05
rl training, epoch1, iter0, batch314/1133, batch loss:1.0363441106164828e-05, Training time:18974.34086585045
batch reward last col mean 3.9803109075364773e-07 first col mean 0.00029854904278181493 all mean 2.9827337129972875e-05
3.4860673622461036e-05 3.486067726043984e-05
rl training, epoch1, iter0, batch315/1133, batch loss:3.486067726043984e-05, Training time:18991.53724002838
batch reward last col mean 2.2088766854722053e-05 first col mean 6.898909487063065e-05 all mean 5.112700455356389e-05
0.00011020778038073331 0.00011020778038073331
rl training, epoch1, iter0, batch316/1133, batch loss:0.00011020778038073331, Training time:19008.758440494537
batch reward last col mean 3.6099856970395194e-06 first col mean 7.239538604153495e-07 all mean 4.1156970837619156e-05
0.00010241346171824262 0.00010241346899420023
rl training, epoch1, iter0, batch317/1133, batch loss:0.00010241346899420023, Training time:19025.956276655197
batch reward last col mean 2.6147454263991676e-05 first col mean 1.045122462528525e-05 all mean 6.713328912155703e-05
0.00014652987010776997 0.00014652987010776997
rl training, epoch1, iter0, batch318/1133, batch loss:0.00014652987010776997, Training time:19043.236793994904
batch reward last col mean 2.7078262974100653e-06 first col mean 1.1659907386274426e-06 all mean 1.9521314243320376e-05
1.054061885952251e-05 1.0540617950027809e-05
rl training, epoch1, iter0, batch319/1133, batch loss:1.0540617950027809e-05, Training time:19060.560614585876
batch reward last col mean 1.993040496017784e-05 first col mean 1.5154353150137467e-06 all mean 2.705257065827027e-05
1.9297149265185e-05 1.9297147446195595e-05
rl training, epoch1, iter0, batch320/1133, batch loss:1.9297147446195595e-05, Training time:19077.84942984581
batch reward last col mean 1.0641000471878215e-06 first col mean 7.763046596664935e-06 all mean 2.3825208700145595e-05
3.2014177122619e-05 3.201418076059781e-05
rl training, epoch1, iter0, batch321/1133, batch loss:3.201418076059781e-05, Training time:19094.996479272842
batch reward last col mean 0.00010123472020495683 first col mean 0.00021964797633700073 all mean 6.755084177711979e-05
3.43754691130016e-05 3.4375476388959214e-05
rl training, epoch1, iter0, batch322/1133, batch loss:3.4375476388959214e-05, Training time:19112.02996993065
batch reward last col mean 5.350147148419637e-06 first col mean 0.00011807830014731735 all mean 2.9624963644891977e-05
3.408705015317537e-05 3.408705015317537e-05
rl training, epoch1, iter0, batch323/1133, batch loss:3.408705015317537e-05, Training time:19129.333610773087
batch reward last col mean 9.584018698660657e-06 first col mean 0.001830724417231977 all mean 0.00011129082122351974
0.0003136353043373674 0.0003136353043373674
rl training, epoch1, iter0, batch324/1133, batch loss:0.0003136353043373674, Training time:19146.498438596725
batch reward last col mean 0.0004185763536952436 first col mean 3.8298876461340114e-06 all mean 0.00036088129854761064
5.0757371354848146e-05 5.0757374992826954e-05
rl training, epoch1, iter0, batch325/1133, batch loss:5.0757374992826954e-05, Training time:19163.669289827347
batch reward last col mean 1.1321951205900405e-05 first col mean 5.839241339344881e-07 all mean 4.660932609112933e-05
8.685100328875706e-05 8.685098873684183e-05
rl training, epoch1, iter0, batch326/1133, batch loss:8.685098873684183e-05, Training time:19180.79370188713
batch reward last col mean 2.3837326352804666e-06 first col mean 0.0018219674238935113 all mean 5.538908953894861e-05
6.05948043812532e-05 6.059481529518962e-05
rl training, epoch1, iter0, batch327/1133, batch loss:6.059481529518962e-05, Training time:19197.936985254288
batch reward last col mean 4.670168345910497e-05 first col mean 7.149641987780342e-06 all mean 7.730898505542427e-05
6.600364577025175e-05 6.600364577025175e-05
rl training, epoch1, iter0, batch328/1133, batch loss:6.600364577025175e-05, Training time:19216.97846865654
batch reward last col mean 7.864316557970596e-07 first col mean 8.694881898918538e-07 all mean 2.048787791864015e-05
4.337925565778278e-05 4.337925565778278e-05
rl training, epoch1, iter0, batch329/1133, batch loss:4.337925565778278e-05, Training time:19234.16166329384
batch reward last col mean 1.6629998071948648e-06 first col mean 1.1158400411659386e-05 all mean 4.4919004722032696e-05
5.018521915189922e-05 5.0185211875941604e-05
rl training, epoch1, iter0, batch330/1133, batch loss:5.0185211875941604e-05, Training time:19251.218353271484
batch reward last col mean 6.243453753995709e-07 first col mean 1.2026441254420206e-05 all mean 1.0168902008445002e-05
2.832358040905092e-05 2.832358040905092e-05
rl training, epoch1, iter0, batch331/1133, batch loss:2.832358040905092e-05, Training time:19268.336929559708
batch reward last col mean 1.5992036139778065e-07 first col mean 1.4961621673137415e-05 all mean 6.528045196318999e-05
0.00014513179485220462 0.00014513179485220462
rl training, epoch1, iter0, batch332/1133, batch loss:0.00014513179485220462, Training time:19285.53211593628
batch reward last col mean 1.6974728112018056e-07 first col mean 9.852080438577104e-06 all mean 9.551452421874274e-06
6.500034942291677e-06 6.5000331233022735e-06
rl training, epoch1, iter0, batch333/1133, batch loss:6.5000331233022735e-06, Training time:19302.632536888123
batch reward last col mean 6.590579459953005e-07 first col mean 3.226972239644965e-06 all mean 2.746897553151939e-05
1.3099945135763846e-05 1.3099948773742653e-05
rl training, epoch1, iter0, batch334/1133, batch loss:1.3099948773742653e-05, Training time:19319.83657836914
batch reward last col mean 1.5381132811853604e-07 first col mean 0.00025017253938131034 all mean 6.019750071573071e-05
6.749282329110429e-05 6.749282329110429e-05
rl training, epoch1, iter0, batch335/1133, batch loss:6.749282329110429e-05, Training time:19337.024118423462
batch reward last col mean 0.0025164729449898005 first col mean 9.814438271860126e-06 all mean 0.0008246055222116411
0.00038241708534769714 0.00038241708534769714
rl training, epoch1, iter0, batch336/1133, batch loss:0.00038241708534769714, Training time:19354.159591436386
batch reward last col mean 2.6044003789138515e-06 first col mean 3.088837183895521e-05 all mean 4.2430976463947445e-05
8.808950951788574e-05 8.808950951788574e-05
rl training, epoch1, iter0, batch337/1133, batch loss:8.808950951788574e-05, Training time:19371.43595314026
batch reward last col mean 0.0003445297188591212 first col mean 3.0658258765470237e-05 all mean 0.00024881187709979713
7.934481982374564e-05 7.934482709970325e-05
rl training, epoch1, iter0, batch338/1133, batch loss:7.934482709970325e-05, Training time:19388.68260550499
batch reward last col mean 3.045103767362889e-06 first col mean 6.614278845518129e-06 all mean 1.1538119906617794e-05
7.914495654404163e-06 7.914495654404163e-06
rl training, epoch1, iter0, batch339/1133, batch loss:7.914495654404163e-06, Training time:19405.803758621216
batch reward last col mean 2.5353756427648477e-06 first col mean 0.00020225784101057798 all mean 2.044245775323361e-05
2.870645039365627e-05 2.8706448574666865e-05
rl training, epoch1, iter0, batch340/1133, batch loss:2.8706448574666865e-05, Training time:19422.89513015747
batch reward last col mean 0.00011271476978436112 first col mean 5.872341262147529e-06 all mean 5.8610454289009795e-05
6.78212454658933e-05 6.782125274185091e-05
rl training, epoch1, iter0, batch341/1133, batch loss:6.782125274185091e-05, Training time:19439.93440270424
batch reward last col mean 1.856338087691256e-07 first col mean 9.445993055123836e-05 all mean 2.2841715690447018e-05
2.4359816961805336e-05 2.4359816961805336e-05
rl training, epoch1, iter0, batch342/1133, batch loss:2.4359816961805336e-05, Training time:19457.106494903564
batch reward last col mean 1.8790425428960589e-06 first col mean 2.6061159132950706e-06 all mean 4.544590774457902e-05
4.5529584895120934e-05 4.552959217107855e-05
rl training, epoch1, iter0, batch343/1133, batch loss:4.552959217107855e-05, Training time:19474.143979787827
batch reward last col mean 1.5375857174149132e-06 first col mean 0.0015072483802214265 all mean 6.764147838111967e-05
0.00010547423880780116 0.00010547423880780116
rl training, epoch1, iter0, batch344/1133, batch loss:0.00010547423880780116, Training time:19491.280518054962
batch reward last col mean 7.739077773294412e-06 first col mean 0.0006524171330966055 all mean 5.70730262552388e-05
4.00946919398848e-05 4.0094681025948375e-05
rl training, epoch1, iter0, batch345/1133, batch loss:4.0094681025948375e-05, Training time:19508.73545908928
batch reward last col mean 2.9653849651367636e-06 first col mean 0.0019363956525921822 all mean 5.1195751439081505e-05
8.62612432683818e-05 8.626123599242419e-05
rl training, epoch1, iter0, batch346/1133, batch loss:8.626123599242419e-05, Training time:19525.926893234253
batch reward last col mean 1.3531540616895654e-06 first col mean 0.0016628776211291552 all mean 5.3354269766714424e-05
8.072046330198646e-05 8.072045602602884e-05
rl training, epoch1, iter0, batch347/1133, batch loss:8.072045602602884e-05, Training time:19544.5989921093
batch reward last col mean 1.9633571923804993e-07 first col mean 0.00012786866864189506 all mean 4.171452019363642e-05
8.284474461106583e-05 8.284474461106583e-05
rl training, epoch1, iter0, batch348/1133, batch loss:8.284474461106583e-05, Training time:19561.72118139267
batch reward last col mean 0.00022855012502986938 first col mean 0.00031803097226656973 all mean 0.0001268255291506648
7.679661212023348e-05 7.679661212023348e-05
rl training, epoch1, iter0, batch349/1133, batch loss:7.679661212023348e-05, Training time:19578.742305278778
batch reward last col mean 7.865385850891471e-05 first col mean 0.0008214552653953433 all mean 5.581308505497873e-05
6.150065746624023e-05 6.150065746624023e-05
rl training, epoch1, iter0, batch350/1133, batch loss:6.150065746624023e-05, Training time:19595.778180122375
batch reward last col mean 6.387465418811189e-06 first col mean 0.0002659399760887027 all mean 2.4771812604740262e-05
4.1718914872035384e-05 4.1718922147993e-05
rl training, epoch1, iter0, batch351/1133, batch loss:4.1718922147993e-05, Training time:19612.950543642044
batch reward last col mean 7.573917741865444e-07 first col mean 2.3472716748074163e-06 all mean 3.601597200031392e-05
3.5413497244007885e-05 3.541349360602908e-05
rl training, epoch1, iter0, batch352/1133, batch loss:3.541349360602908e-05, Training time:19630.18653321266
batch reward last col mean 2.3264256299171393e-07 first col mean 1.3496764950104989e-05 all mean 5.3108680731384084e-05
8.56690967339091e-05 8.566911128582433e-05
rl training, epoch1, iter0, batch353/1133, batch loss:8.566911128582433e-05, Training time:19647.38277363777
batch reward last col mean 0.0018366151489317417 first col mean 7.129184496079688e-07 all mean 0.0017632570816203952
0.00017336847668047994 0.00017336847668047994
rl training, epoch1, iter0, batch354/1133, batch loss:0.00017336847668047994, Training time:19664.509541511536
batch reward last col mean 7.722364898654632e-07 first col mean 0.00013691085041500628 all mean 1.912823245220352e-05
1.8938731955131516e-05 1.8938731955131516e-05
rl training, epoch1, iter0, batch355/1133, batch loss:1.8938731955131516e-05, Training time:19681.583562850952
batch reward last col mean 8.357137267012149e-05 first col mean 0.0017705410718917847 all mean 6.426171603379771e-05
4.0184157114708796e-05 4.01841607526876e-05
rl training, epoch1, iter0, batch356/1133, batch loss:4.01841607526876e-05, Training time:19698.67248725891
batch reward last col mean 9.777872946870048e-06 first col mean 0.0005686155636794865 all mean 2.91331198241096e-05
6.49802532279864e-05 6.49802532279864e-05
rl training, epoch1, iter0, batch357/1133, batch loss:6.49802532279864e-05, Training time:19717.769724845886
batch reward last col mean 0.003481765976175666 first col mean 1.4741559425601736e-05 all mean 0.003132387762889266
0.00024266405671369284 0.00024266405671369284
rl training, epoch1, iter0, batch358/1133, batch loss:0.00024266405671369284, Training time:19736.920686483383
batch reward last col mean 1.3481013411364984e-05 first col mean 5.42086418136023e-05 all mean 3.692027530632913e-05
4.623361746780574e-05 4.623361746780574e-05
rl training, epoch1, iter0, batch359/1133, batch loss:4.623361746780574e-05, Training time:19754.08069062233
batch reward last col mean 6.130461406428367e-05 first col mean 1.421095021214569e-06 all mean 4.18824129155837e-05
2.0806917746085674e-05 2.0806917746085674e-05
rl training, epoch1, iter0, batch360/1133, batch loss:2.0806917746085674e-05, Training time:19773.19058227539
batch reward last col mean 6.100933387642726e-05 first col mean 6.715528343193e-06 all mean 6.026998380548321e-05
1.412505480402615e-05 1.4125052075542044e-05
rl training, epoch1, iter0, batch361/1133, batch loss:1.4125052075542044e-05, Training time:19790.350150108337
batch reward last col mean 0.0011499206302687526 first col mean 2.8540937364596175e-06 all mean 0.0010438269237056375
0.00014838928473182023 0.00014838928473182023
rl training, epoch1, iter0, batch362/1133, batch loss:0.00014838928473182023, Training time:19809.37060189247
batch reward last col mean 5.4905671277083457e-05 first col mean 7.287308108061552e-06 all mean 3.703115362441167e-05
1.7150761777884327e-05 1.7150761777884327e-05
rl training, epoch1, iter0, batch363/1133, batch loss:1.7150761777884327e-05, Training time:19826.549482107162
batch reward last col mean 3.978799577453174e-05 first col mean 0.0009800560073927045 all mean 7.390445534838364e-05
5.9593738114926964e-05 5.959375266684219e-05
rl training, epoch1, iter0, batch364/1133, batch loss:5.959375266684219e-05, Training time:19844.538318395615
batch reward last col mean 8.772344699536916e-07 first col mean 0.0007897327304817736 all mean 4.4214735680725425e-05
0.00010161214595427737 0.00010161215323023498
rl training, epoch1, iter0, batch365/1133, batch loss:0.00010161215323023498, Training time:19861.651420354843
batch reward last col mean 7.328216270252597e-06 first col mean 1.599755705683492e-05 all mean 2.022203079832252e-05
1.106528998207068e-05 1.1065291801060084e-05
rl training, epoch1, iter0, batch366/1133, batch loss:1.1065291801060084e-05, Training time:19879.00859975815
batch reward last col mean 0.0036106908228248358 first col mean 7.390787573058333e-07 all mean 0.0034237615764141083
0.00034059036988765 0.0003405904280953109
rl training, epoch1, iter0, batch367/1133, batch loss:0.0003405904280953109, Training time:19896.169843912125
batch reward last col mean 2.8892529826407554e-06 first col mean 6.1734872360830195e-06 all mean 1.117786541726673e-05
1.2745000276481733e-05 1.2745001185976434e-05
rl training, epoch1, iter0, batch368/1133, batch loss:1.2745001185976434e-05, Training time:19913.396379947662
batch reward last col mean 7.597620879096212e-06 first col mean 9.967899677576497e-05 all mean 3.075872882618569e-05
2.969850720546674e-05 2.969850720546674e-05
rl training, epoch1, iter0, batch369/1133, batch loss:2.969850720546674e-05, Training time:19930.550668239594
batch reward last col mean 4.7286084736697376e-05 first col mean 0.0001648378965910524 all mean 5.1646162319229916e-05
9.396437963005155e-05 9.396437963005155e-05
rl training, epoch1, iter0, batch370/1133, batch loss:9.396437963005155e-05, Training time:19947.72173142433
batch reward last col mean 5.7357239711564034e-05 first col mean 0.00012072250683559105 all mean 5.2012728701811284e-05
0.0001726507325656712 0.0001726507325656712
rl training, epoch1, iter0, batch371/1133, batch loss:0.0001726507325656712, Training time:19964.92122030258
batch reward last col mean 3.057585445276345e-06 first col mean 8.047251321841031e-05 all mean 2.6050272936117835e-05
5.016177601646632e-05 5.016177601646632e-05
rl training, epoch1, iter0, batch372/1133, batch loss:5.016177601646632e-05, Training time:19982.137999773026
batch reward last col mean 3.810007001447957e-06 first col mean 7.105198278622993e-07 all mean 1.4368533811648376e-05
2.179475995944813e-05 2.179475995944813e-05
rl training, epoch1, iter0, batch373/1133, batch loss:2.179475995944813e-05, Training time:19999.13315153122
batch reward last col mean 0.00016978333587758243 first col mean 4.001104571216274e-06 all mean 0.00015728466678410769
4.5582772145280614e-05 4.558277942123823e-05
rl training, epoch1, iter0, batch374/1133, batch loss:4.558277942123823e-05, Training time:20016.074637413025
batch reward last col mean 4.59236980532296e-05 first col mean 3.366103919688612e-05 all mean 6.857756670797244e-05
5.884706479264423e-05 5.884706479264423e-05
rl training, epoch1, iter0, batch375/1133, batch loss:5.884706479264423e-05, Training time:20033.361084461212
batch reward last col mean 1.1203200301679317e-05 first col mean 3.883404133375734e-06 all mean 3.3766962587833405e-05
1.5904519386822358e-05 1.590451574884355e-05
rl training, epoch1, iter0, batch376/1133, batch loss:1.590451574884355e-05, Training time:20050.350510835648
batch reward last col mean 4.302115939935902e-06 first col mean 0.00032586732413619757 all mean 4.693317168857902e-05
0.00011566857574507594 0.00011566857574507594
rl training, epoch1, iter0, batch377/1133, batch loss:0.00011566857574507594, Training time:20067.3942091465
batch reward last col mean 1.8894028244176297e-06 first col mean 5.7745717640500516e-05 all mean 7.856937008909881e-05
0.0001805928914109245 0.0001805928477551788
rl training, epoch1, iter0, batch378/1133, batch loss:0.0001805928477551788, Training time:20084.5328104496
batch reward last col mean 0.0014843062963336706 first col mean 5.353333108359948e-05 all mean 0.0008470268803648651
0.00013021966151427478 0.00013021964696235955
rl training, epoch1, iter0, batch379/1133, batch loss:0.00013021964696235955, Training time:20101.641540527344
batch reward last col mean 3.1098332442525134e-07 first col mean 4.256034571881173e-06 all mean 1.562423858558759e-05
1.8738050130195916e-05 1.8738048311206512e-05
rl training, epoch1, iter0, batch380/1133, batch loss:1.8738048311206512e-05, Training time:20118.71110534668
batch reward last col mean 7.553192631348793e-07 first col mean 1.558766143716639e-06 all mean 4.118021024623886e-05
3.814914089161903e-05 3.814914089161903e-05
rl training, epoch1, iter0, batch381/1133, batch loss:3.814914089161903e-05, Training time:20135.793623685837
batch reward last col mean 0.00029050413286313415 first col mean 0.0020669016521424055 all mean 0.000219302048208192
0.0001026944155455567 0.0001026944155455567
rl training, epoch1, iter0, batch382/1133, batch loss:0.0001026944155455567, Training time:20152.94597172737
batch reward last col mean 3.944991021853639e-06 first col mean 0.000297812424832955 all mean 7.466365059372038e-05
0.0002044533030129969 0.00020445331756491214
rl training, epoch1, iter0, batch383/1133, batch loss:0.00020445331756491214, Training time:20170.041428089142
batch reward last col mean 5.050707727605186e-07 first col mean 0.000596989004407078 all mean 4.573844125843607e-05
6.422519072657451e-05 6.42251834506169e-05
rl training, epoch1, iter0, batch384/1133, batch loss:6.42251834506169e-05, Training time:20187.158985614777
batch reward last col mean 9.048098036146257e-06 first col mean 0.00034462049370631576 all mean 3.211638977518305e-05
7.495889440178871e-05 7.495889440178871e-05
rl training, epoch1, iter0, batch385/1133, batch loss:7.495889440178871e-05, Training time:20204.336059093475
batch reward last col mean 0.005874124821275473 first col mean 7.895738463048474e-07 all mean 0.005545380059629679
0.00038295070407912135 0.00038295070407912135
rl training, epoch1, iter0, batch386/1133, batch loss:0.00038295070407912135, Training time:20221.597570180893
batch reward last col mean 1.5827832839931943e-06 first col mean 5.994712410029024e-06 all mean 3.094721250818111e-05
1.6705009329598397e-05 1.6705012967577204e-05
rl training, epoch1, iter0, batch387/1133, batch loss:1.6705012967577204e-05, Training time:20238.78133034706
batch reward last col mean 5.830804639117559e-07 first col mean 1.0246086276310962e-05 all mean 3.05768808175344e-05
3.5833614674629644e-05 3.5833611036650836e-05
rl training, epoch1, iter0, batch388/1133, batch loss:3.5833611036650836e-05, Training time:20255.913107156754
batch reward last col mean 1.5713764867086866e-07 first col mean 3.5546966046240414e-06 all mean 1.4945175280445255e-05
5.559552664635703e-05 5.559552664635703e-05
rl training, epoch1, iter0, batch389/1133, batch loss:5.559552664635703e-05, Training time:20272.969365119934
batch reward last col mean 7.112884077287163e-07 first col mean 6.762001430615783e-05 all mean 6.530083192046732e-05
0.00016246949962805957 0.00016246949962805957
rl training, epoch1, iter0, batch390/1133, batch loss:0.00016246949962805957, Training time:20290.179458379745
batch reward last col mean 1.0962246051349211e-05 first col mean 7.598167576361448e-05 all mean 1.4469315829046536e-05
1.665349191171117e-05 1.665349191171117e-05
rl training, epoch1, iter0, batch391/1133, batch loss:1.665349191171117e-05, Training time:20307.210873126984
batch reward last col mean 1.1084500329161528e-05 first col mean 2.600694278953597e-05 all mean 3.675739571917802e-05
6.0246256907703355e-05 6.024626418366097e-05
rl training, epoch1, iter0, batch392/1133, batch loss:6.024626418366097e-05, Training time:20324.216206789017
batch reward last col mean 4.257990440237336e-06 first col mean 2.4643716756145295e-07 all mean 5.049003448220901e-05
3.531672336976044e-05 3.531670881784521e-05
rl training, epoch1, iter0, batch393/1133, batch loss:3.531670881784521e-05, Training time:20341.223809719086
batch reward last col mean 1.0706909051805269e-05 first col mean 2.4695018510101363e-05 all mean 2.474081702530384e-05
2.048326496151276e-05 2.048326496151276e-05
rl training, epoch1, iter0, batch394/1133, batch loss:2.048326496151276e-05, Training time:20358.394649505615
batch reward last col mean 7.834242751414422e-06 first col mean 9.558193596603815e-07 all mean 2.0691710233222693e-05
2.318072074558586e-05 2.3180718926596455e-05
rl training, epoch1, iter0, batch395/1133, batch loss:2.3180718926596455e-05, Training time:20375.698517799377
batch reward last col mean 7.827356603229418e-05 first col mean 4.272916157788131e-06 all mean 4.2382016545161605e-05
2.273191057611257e-05 2.2731912395101972e-05
rl training, epoch1, iter0, batch396/1133, batch loss:2.2731912395101972e-05, Training time:20392.73353266716
batch reward last col mean 4.994323035134585e-07 first col mean 5.71814189243014e-06 all mean 2.40165045397589e-05
4.294508107705042e-05 4.2945084715029225e-05
rl training, epoch1, iter0, batch397/1133, batch loss:4.2945084715029225e-05, Training time:20409.913146018982
batch reward last col mean 1.541910989999451e-07 first col mean 2.849837255780585e-05 all mean 4.3898995500057936e-05
5.698920722352341e-05 5.698920722352341e-05
rl training, epoch1, iter0, batch398/1133, batch loss:5.698920722352341e-05, Training time:20426.976396799088
batch reward last col mean 0.0033143507316708565 first col mean 0.00021558383014053106 all mean 0.003097487147897482
0.0005841475795023143 0.0005841475212946534
rl training, epoch1, iter0, batch399/1133, batch loss:0.0005841475212946534, Training time:20444.11676454544
batch reward last col mean 0.004955705255270004 first col mean 0.00012643753143493086 all mean 0.004888507071882486
0.0006463128956966102 0.0006463128956966102
rl training, epoch1, iter0, batch400/1133, batch loss:0.0006463128956966102, Training time:20461.241552829742
batch reward last col mean 2.238841005919312e-07 first col mean 0.00010252325591864064 all mean 3.031691630894784e-05
6.636208127019927e-05 6.636208854615688e-05
rl training, epoch1, iter0, batch401/1133, batch loss:6.636208854615688e-05, Training time:20478.422244787216
batch reward last col mean 1.6413392813774408e-06 first col mean 3.2609004847472534e-05 all mean 1.881847310869489e-05
2.2604932382819243e-05 2.2604934201808646e-05
rl training, epoch1, iter0, batch402/1133, batch loss:2.2604934201808646e-05, Training time:20495.60187983513
batch reward last col mean 0.00015065292245708406 first col mean 0.0006160650518722832 all mean 4.542219539871439e-05
3.84075210604351e-05 3.84075210604351e-05
rl training, epoch1, iter0, batch403/1133, batch loss:3.84075210604351e-05, Training time:20512.69540834427
batch reward last col mean 4.476564299693564e-06 first col mean 3.8855496313772164e-06 all mean 1.7712683984427713e-05
7.9356495916727e-06 7.935653229651507e-06
rl training, epoch1, iter0, batch404/1133, batch loss:7.935653229651507e-06, Training time:20529.867203712463
batch reward last col mean 6.479809599113651e-06 first col mean 6.146376836113632e-05 all mean 3.488647053018212e-05
4.0572427678853273e-05 4.057243495481089e-05
rl training, epoch1, iter0, batch405/1133, batch loss:4.057243495481089e-05, Training time:20547.11362028122
batch reward last col mean 0.00014701914915349334 first col mean 2.9109069146215916e-06 all mean 4.47008824266959e-05
4.667108441935852e-05 4.6671080781379715e-05
rl training, epoch1, iter0, batch406/1133, batch loss:4.6671080781379715e-05, Training time:20564.25510787964
batch reward last col mean 0.0012365046422928572 first col mean 8.633202014607377e-06 all mean 0.0010929224081337452
0.00010903652582783252 0.00010903652582783252
rl training, epoch1, iter0, batch407/1133, batch loss:0.00010903652582783252, Training time:20581.332362413406
batch reward last col mean 2.8880608624604065e-06 first col mean 0.00012082794273737818 all mean 4.265086681698449e-05
8.787211845628917e-05 8.787211845628917e-05
rl training, epoch1, iter0, batch408/1133, batch loss:8.787211845628917e-05, Training time:20598.449431419373
batch reward last col mean 2.3451320885214955e-05 first col mean 0.00023916721693240106 all mean 3.85788080166094e-05
2.9582533898064867e-05 2.9582533898064867e-05
rl training, epoch1, iter0, batch409/1133, batch loss:2.9582533898064867e-05, Training time:20615.503438472748
batch reward last col mean 2.571821596575319e-06 first col mean 4.562911271932535e-05 all mean 6.072009273339063e-05
5.243116174824536e-05 5.243117266218178e-05
rl training, epoch1, iter0, batch410/1133, batch loss:5.243117266218178e-05, Training time:20633.211755990982
batch reward last col mean 7.228619779198198e-06 first col mean 6.321114778984338e-05 all mean 5.96671125094872e-05
6.484331970568746e-05 6.484331242972985e-05
rl training, epoch1, iter0, batch411/1133, batch loss:6.484331242972985e-05, Training time:20650.433107852936
batch reward last col mean 9.783225323189981e-07 first col mean 5.241782127995975e-05 all mean 6.189612031448632e-05
0.00011839334183605388 0.00011839334911201149
rl training, epoch1, iter0, batch412/1133, batch loss:0.00011839334911201149, Training time:20667.544573307037
batch reward last col mean 1.506724061073328e-06 first col mean 0.0004133709007874131 all mean 2.1586705770459957e-05
6.125350046204403e-05 6.125350046204403e-05
rl training, epoch1, iter0, batch413/1133, batch loss:6.125350046204403e-05, Training time:20684.687928915024
batch reward last col mean 1.346935641777236e-05 first col mean 3.175687425027718e-06 all mean 5.013546979171224e-05
4.936717959935777e-05 4.936718687531538e-05
rl training, epoch1, iter0, batch414/1133, batch loss:4.936718687531538e-05, Training time:20701.616667985916
batch reward last col mean 0.001984720816835761 first col mean 0.00012670339492615312 all mean 0.0016809660010039806
0.0002351988950977102 0.00023519890964962542
rl training, epoch1, iter0, batch415/1133, batch loss:0.00023519890964962542, Training time:20718.72447323799
batch reward last col mean 3.760146000786335e-06 first col mean 6.919224233570276e-07 all mean 2.192219835706055e-05
1.1904830898856744e-05 1.1904831808351446e-05
rl training, epoch1, iter0, batch416/1133, batch loss:1.1904831808351446e-05, Training time:20735.793454408646
batch reward last col mean 4.225436714477837e-05 first col mean 4.1120060814137105e-06 all mean 6.0601036238949746e-05
0.00010449643013998866 0.00010449643013998866
rl training, epoch1, iter0, batch417/1133, batch loss:0.00010449643013998866, Training time:20752.69882464409
batch reward last col mean 3.324360295664519e-05 first col mean 8.83677876117872e-06 all mean 0.00020318047609180212
0.000672884751111269 0.0006728846929036081
rl training, epoch1, iter0, batch418/1133, batch loss:0.0006728846929036081, Training time:20771.656502723694
batch reward last col mean 3.402509719308e-06 first col mean 0.0006208496051840484 all mean 8.402572711929679e-05
8.168419299181551e-05 8.168421481968835e-05
rl training, epoch1, iter0, batch419/1133, batch loss:8.168421481968835e-05, Training time:20788.751471042633
batch reward last col mean 1.8425091639073798e-06 first col mean 3.993945938418619e-05 all mean 7.068675768096e-05
0.00013602731633000076 0.00013602731633000076
rl training, epoch1, iter0, batch420/1133, batch loss:0.00013602731633000076, Training time:20805.82026743889
batch reward last col mean 5.5594041441509034e-06 first col mean 2.3294634956982918e-05 all mean 3.7986275856383145e-05
7.722382724750787e-05 7.722382724750787e-05
rl training, epoch1, iter0, batch421/1133, batch loss:7.722382724750787e-05, Training time:20823.157512426376
batch reward last col mean 1.2990087725484045e-06 first col mean 8.077098027570173e-05 all mean 3.0403667551581748e-05
6.686086271656677e-05 6.686086271656677e-05
rl training, epoch1, iter0, batch422/1133, batch loss:6.686086271656677e-05, Training time:20840.262293815613
batch reward last col mean 0.00017735973233357072 first col mean 0.0017759391339495778 all mean 0.00021104516054037958
0.00027476437389850616 0.00027476437389850616
rl training, epoch1, iter0, batch423/1133, batch loss:0.00027476437389850616, Training time:20858.038661003113
batch reward last col mean 4.438645646587247e-06 first col mean 3.088796074735001e-05 all mean 2.3170166969066486e-05
3.1919444154482335e-05 3.191944779246114e-05
rl training, epoch1, iter0, batch424/1133, batch loss:3.191944779246114e-05, Training time:20876.937199115753
batch reward last col mean 1.007448759082763e-06 first col mean 3.34421338266111e-06 all mean 2.2289808839559555e-05
4.554008773993701e-05 4.554008773993701e-05
rl training, epoch1, iter0, batch425/1133, batch loss:4.554008773993701e-05, Training time:20894.12259745598
batch reward last col mean 2.025062286747925e-07 first col mean 6.204056262504309e-06 all mean 3.2661089790053666e-05
6.302015390247107e-05 6.302016117842868e-05
rl training, epoch1, iter0, batch426/1133, batch loss:6.302016117842868e-05, Training time:20911.285495758057
batch reward last col mean 1.474024088565784e-06 first col mean 0.0018749114824458957 all mean 7.064927194733173e-05
0.00017118074174504727 0.00017118074174504727
rl training, epoch1, iter0, batch427/1133, batch loss:0.00017118074174504727, Training time:20928.40804553032
batch reward last col mean 2.6670190322874987e-07 first col mean 7.866048690630123e-06 all mean 3.166271926602349e-05
6.114431016612798e-05 6.114431016612798e-05
rl training, epoch1, iter0, batch428/1133, batch loss:6.114431016612798e-05, Training time:20945.710457086563
batch reward last col mean 6.170650158310309e-05 first col mean 2.962468352052383e-05 all mean 5.358869748306461e-05
3.515683056320995e-05 3.515683056320995e-05
rl training, epoch1, iter0, batch429/1133, batch loss:3.515683056320995e-05, Training time:20962.89324116707
batch reward last col mean 7.469400770787615e-06 first col mean 6.075141300243558e-06 all mean 2.9084327252348885e-05
1.7003767425194383e-05 1.7003763787215576e-05
rl training, epoch1, iter0, batch430/1133, batch loss:1.7003763787215576e-05, Training time:20979.894705295563
batch reward last col mean 3.2686473332432797e-06 first col mean 0.00012749667803291231 all mean 4.756233829539269e-05
9.941987809725106e-05 9.941987809725106e-05
rl training, epoch1, iter0, batch431/1133, batch loss:9.941987809725106e-05, Training time:20996.968368768692
batch reward last col mean 1.4525031701850821e-06 first col mean 8.047095434449147e-06 all mean 2.465474244672805e-05
3.06559304590337e-05 3.06559304590337e-05
rl training, epoch1, iter0, batch432/1133, batch loss:3.06559304590337e-05, Training time:21014.03619146347
batch reward last col mean 4.4392322706698906e-06 first col mean 0.0009140754118561745 all mean 3.5622284485725686e-05
4.6250977902673185e-05 4.6250977902673185e-05
rl training, epoch1, iter0, batch433/1133, batch loss:4.6250977902673185e-05, Training time:21031.101052761078
batch reward last col mean 2.5365698093082756e-05 first col mean 4.42601231043227e-05 all mean 3.574970469344407e-05
1.7624464817345142e-05 1.7624466636334546e-05
rl training, epoch1, iter0, batch434/1133, batch loss:1.7624466636334546e-05, Training time:21048.20865535736
batch reward last col mean 2.517126631573774e-06 first col mean 0.0012719526421278715 all mean 5.836253330926411e-05
3.342509808135219e-05 3.342510899528861e-05
rl training, epoch1, iter0, batch435/1133, batch loss:3.342510899528861e-05, Training time:21065.115040063858
batch reward last col mean 0.00010462085629114881 first col mean 1.1114915650978219e-05 all mean 8.609279757365584e-05
2.3396552933263592e-05 2.3396552933263592e-05
rl training, epoch1, iter0, batch436/1133, batch loss:2.3396552933263592e-05, Training time:21082.22986316681
batch reward last col mean 8.178370194400486e-07 first col mean 6.756937636964722e-06 all mean 5.473085548146628e-05
6.537351873703301e-05 6.537350418511778e-05
rl training, epoch1, iter0, batch437/1133, batch loss:6.537350418511778e-05, Training time:21099.337495803833
batch reward last col mean 0.00012235662143211812 first col mean 8.365503163076937e-06 all mean 0.00011729358811862767
6.397637480404228e-05 6.397636752808467e-05
rl training, epoch1, iter0, batch438/1133, batch loss:6.397636752808467e-05, Training time:21116.307789087296
batch reward last col mean 4.971274734089093e-07 first col mean 1.6221780242631212e-05 all mean 4.7954355977708474e-05
0.00013953031157143414 0.00013953031157143414
rl training, epoch1, iter0, batch439/1133, batch loss:0.00013953031157143414, Training time:21134.700524806976
batch reward last col mean 0.0026332400739192963 first col mean 0.001169005874544382 all mean 0.0006967760273255408
0.00044655907549895346 0.00044655907549895346
rl training, epoch1, iter0, batch440/1133, batch loss:0.00044655907549895346, Training time:21152.203036546707
batch reward last col mean 3.7003783290856518e-06 first col mean 1.2771341744155507e-06 all mean 3.338194437674247e-05
2.679995850485284e-05 2.6799954866874032e-05
rl training, epoch1, iter0, batch441/1133, batch loss:2.6799954866874032e-05, Training time:21169.27202486992
batch reward last col mean 1.242431380887865e-06 first col mean 0.0004954098840244114 all mean 2.2901696866028942e-05
5.183464600122534e-05 5.183464600122534e-05
rl training, epoch1, iter0, batch442/1133, batch loss:5.183464600122534e-05, Training time:21186.333657741547
batch reward last col mean 2.065394255623687e-06 first col mean 9.12987525225617e-06 all mean 1.9369070287211798e-05
2.8261820261832327e-05 2.8261823899811134e-05
rl training, epoch1, iter0, batch443/1133, batch loss:2.8261823899811134e-05, Training time:21203.396493911743
batch reward last col mean 6.032381065779191e-07 first col mean 0.0013181687099859118 all mean 7.678558176849037e-05
0.00025280710542574525 0.00025280710542574525
rl training, epoch1, iter0, batch444/1133, batch loss:0.00025280710542574525, Training time:21220.514202594757
batch reward last col mean 4.0692309994483367e-05 first col mean 7.353050750680268e-05 all mean 8.843788236845285e-05
0.00012329329911153764 0.00012329329911153764
rl training, epoch1, iter0, batch445/1133, batch loss:0.00012329329911153764, Training time:21237.662257671356
batch reward last col mean 3.852063343856571e-07 first col mean 4.657641966332449e-06 all mean 1.906940815388225e-05
4.316152990213595e-05 4.316152990213595e-05
rl training, epoch1, iter0, batch446/1133, batch loss:4.316152990213595e-05, Training time:21254.704285621643
batch reward last col mean 2.223330056949635e-06 first col mean 9.587869135430083e-05 all mean 3.27142006426584e-05
1.4551794265571516e-05 1.4551797903550323e-05
rl training, epoch1, iter0, batch447/1133, batch loss:1.4551797903550323e-05, Training time:21273.14333796501
batch reward last col mean 3.3869196158775594e-06 first col mean 8.577429071010556e-06 all mean 3.2503539841854945e-05
9.820851846598089e-05 9.820851119002327e-05
rl training, epoch1, iter0, batch448/1133, batch loss:9.820851119002327e-05, Training time:21290.173364639282
batch reward last col mean 2.3654090455238475e-06 first col mean 2.5588906282791868e-05 all mean 3.420947541599162e-05
4.691884169005789e-05 4.691884169005789e-05
rl training, epoch1, iter0, batch449/1133, batch loss:4.691884169005789e-05, Training time:21307.100964546204
batch reward last col mean 3.262007339799311e-06 first col mean 5.745639555243542e-06 all mean 3.614989691413939e-05
8.06373791419901e-05 8.06373791419901e-05
rl training, epoch1, iter0, batch450/1133, batch loss:8.06373791419901e-05, Training time:21324.32441520691
batch reward last col mean 4.619790161086712e-06 first col mean 0.00025453270063735545 all mean 4.931932926410809e-05
3.529967580107041e-05 3.529967580107041e-05
rl training, epoch1, iter0, batch451/1133, batch loss:3.529967580107041e-05, Training time:21341.372400283813
batch reward last col mean 1.00803072200506e-06 first col mean 1.1203777830814943e-05 all mean 4.415439980220981e-05
4.100910882698372e-05 4.100910518900491e-05
rl training, epoch1, iter0, batch452/1133, batch loss:4.100910518900491e-05, Training time:21358.552896261215
batch reward last col mean 2.6081579562742263e-05 first col mean 1.3590354228654178e-06 all mean 6.452945672208443e-05
0.00018957452266477048 0.00018957452266477048
rl training, epoch1, iter0, batch453/1133, batch loss:0.00018957452266477048, Training time:21375.626432418823
batch reward last col mean 1.4056563486519735e-05 first col mean 7.13160407030955e-05 all mean 2.4218728867708705e-05
2.320261592103634e-05 2.3202617740025744e-05
rl training, epoch1, iter0, batch454/1133, batch loss:2.3202617740025744e-05, Training time:21392.74490571022
batch reward last col mean 0.00014593811647500843 first col mean 0.0007021569181233644 all mean 0.00018043338786810637
3.4738699469016865e-05 3.473870310699567e-05
rl training, epoch1, iter0, batch455/1133, batch loss:3.473870310699567e-05, Training time:21410.14934039116
batch reward last col mean 8.744574984120845e-07 first col mean 1.4460752026934642e-05 all mean 0.00018137604638468474
0.0012132159899920225 0.0012132159899920225
rl training, epoch1, iter0, batch456/1133, batch loss:0.0012132159899920225, Training time:21427.273243665695
batch reward last col mean 2.154652429453563e-05 first col mean 4.1485006363473076e-07 all mean 3.756735168281011e-05
3.542528429534286e-05 3.5425280657364056e-05
rl training, epoch1, iter0, batch457/1133, batch loss:3.5425280657364056e-05, Training time:21444.494109153748
batch reward last col mean 6.641232630499871e-07 first col mean 2.526326170482207e-05 all mean 4.102579259779304e-05
4.540478403214365e-05 4.540478403214365e-05
rl training, epoch1, iter0, batch458/1133, batch loss:4.540478403214365e-05, Training time:21463.49294400215
batch reward last col mean 0.00017428585852030665 first col mean 5.885786322323838e-06 all mean 5.1492501370375976e-05
4.392725168145262e-05 4.3927244405495e-05
rl training, epoch1, iter0, batch459/1133, batch loss:4.3927244405495e-05, Training time:21480.543757915497
batch reward last col mean 5.90224260577088e-07 first col mean 1.113962207455188e-05 all mean 2.7649950425256975e-05
2.060068800346926e-05 2.0600691641448066e-05
rl training, epoch1, iter0, batch460/1133, batch loss:2.0600691641448066e-05, Training time:21497.729487895966
batch reward last col mean 0.0002903150161728263 first col mean 1.6701062122592703e-05 all mean 5.593313107965514e-05
7.144646951928735e-05 7.144646224332973e-05
rl training, epoch1, iter0, batch461/1133, batch loss:7.144646224332973e-05, Training time:21514.892179965973
batch reward last col mean 6.156779818411451e-06 first col mean 1.543595544717391e-06 all mean 2.929990296252072e-05
3.203701999154873e-05 3.203702362952754e-05
rl training, epoch1, iter0, batch462/1133, batch loss:3.203702362952754e-05, Training time:21531.91369485855
batch reward last col mean 5.679895593857509e-07 first col mean 4.5204883463156875e-06 all mean 3.108165765297599e-05
4.9439524445915595e-05 4.9439524445915595e-05
rl training, epoch1, iter0, batch463/1133, batch loss:4.9439524445915595e-05, Training time:21549.07110452652
batch reward last col mean 1.0835756256710738e-05 first col mean 2.2632229956798255e-05 all mean 7.368327351287007e-05
0.00021226238459348679 0.00021226238459348679
rl training, epoch1, iter0, batch464/1133, batch loss:0.00021226238459348679, Training time:21566.02144908905
batch reward last col mean 4.113591785426252e-06 first col mean 7.318959251279011e-05 all mean 3.997025123680942e-05
9.592220885679126e-05 9.592222340870649e-05
rl training, epoch1, iter0, batch465/1133, batch loss:9.592222340870649e-05, Training time:21583.240678071976
batch reward last col mean 3.8114356470941857e-07 first col mean 1.2922409041493665e-05 all mean 2.7850550395669416e-05
4.283660018700175e-05 4.283660018700175e-05
rl training, epoch1, iter0, batch466/1133, batch loss:4.283660018700175e-05, Training time:21600.16846561432
batch reward last col mean 1.9409328615438426e-06 first col mean 2.4846833639458055e-06 all mean 3.165352973155677e-05
8.469585736747831e-05 8.469585736747831e-05
rl training, epoch1, iter0, batch467/1133, batch loss:8.469585736747831e-05, Training time:21617.169592380524
batch reward last col mean 5.443984264275059e-06 first col mean 0.0007205097936093807 all mean 2.7373120246920735e-05
3.762545020435937e-05 3.762545020435937e-05
rl training, epoch1, iter0, batch468/1133, batch loss:3.762545020435937e-05, Training time:21634.133073806763
batch reward last col mean 3.059289156226441e-05 first col mean 1.433611487300368e-06 all mean 8.539474220015109e-05
0.00013576814671978354 0.000135768175823614
rl training, epoch1, iter0, batch469/1133, batch loss:0.000135768175823614, Training time:21651.097781181335
batch reward last col mean 0.0007670372142456472 first col mean 4.2864237911999226e-05 all mean 0.0007612768677063286
9.451113146496937e-05 9.451113146496937e-05
rl training, epoch1, iter0, batch470/1133, batch loss:9.451113146496937e-05, Training time:21668.04788517952
batch reward last col mean 0.00041990497265942395 first col mean 9.346212755190209e-05 all mean 0.0004175353387836367
8.396413613809273e-05 8.396413613809273e-05
rl training, epoch1, iter0, batch471/1133, batch loss:8.396413613809273e-05, Training time:21686.57186126709
batch reward last col mean 2.945165579149034e-05 first col mean 5.0676415412453935e-05 all mean 7.097963680280373e-05
9.042354940902442e-05 9.042355668498203e-05
rl training, epoch1, iter0, batch472/1133, batch loss:9.042355668498203e-05, Training time:21705.4750995636
batch reward last col mean 0.0008536286186426878 first col mean 4.4465643441071734e-05 all mean 0.0004215967783238739
0.00011513385106809437 0.00011513385106809437
rl training, epoch1, iter0, batch473/1133, batch loss:0.00011513385106809437, Training time:21722.677273273468
batch reward last col mean 2.7622556899586925e-06 first col mean 1.1338130207150243e-05 all mean 3.0426566809182987e-05
7.855271542211995e-05 7.855272997403517e-05
rl training, epoch1, iter0, batch474/1133, batch loss:7.855272997403517e-05, Training time:21739.79293036461
batch reward last col mean 4.735144830192439e-05 first col mean 1.75024542841129e-05 all mean 4.3875941628357396e-05
2.8987094992771745e-05 2.8987094992771745e-05
rl training, epoch1, iter0, batch475/1133, batch loss:2.8987094992771745e-05, Training time:21756.930374622345
batch reward last col mean 6.201390351634473e-05 first col mean 7.834249799998361e-07 all mean 5.555725874728523e-05
7.685035961912945e-05 7.685036689508706e-05
rl training, epoch1, iter0, batch476/1133, batch loss:7.685036689508706e-05, Training time:21774.193474769592
batch reward last col mean 6.60419900668785e-05 first col mean 3.7202662497293204e-06 all mean 0.00012582320778165013
0.00038117714575491846 0.00038117714575491846
rl training, epoch1, iter0, batch477/1133, batch loss:0.00038117714575491846, Training time:21791.28943181038
batch reward last col mean 3.829441084235441e-06 first col mean 7.039616320980713e-06 all mean 7.890437700552866e-05
0.00027697262703441083 0.00027697262703441083
rl training, epoch1, iter0, batch478/1133, batch loss:0.00027697262703441083, Training time:21808.476623773575
batch reward last col mean 1.2126723959227093e-05 first col mean 4.160609705650131e-07 all mean 7.55357468733564e-05
0.00016537430929020047 0.0001653743238421157
rl training, epoch1, iter0, batch479/1133, batch loss:0.0001653743238421157, Training time:21825.597209692
batch reward last col mean 4.535845164355123e-06 first col mean 2.984773118441808e-06 all mean 3.637159534264356e-05
7.382289913948625e-05 7.382289913948625e-05
rl training, epoch1, iter0, batch480/1133, batch loss:7.382289913948625e-05, Training time:21842.707599401474
batch reward last col mean 0.000792287231888622 first col mean 3.3865858313220087e-06 all mean 0.0007025721133686602
0.0002457847585901618 0.0002457847585901618
rl training, epoch1, iter0, batch481/1133, batch loss:0.0002457847585901618, Training time:21860.079999685287
batch reward last col mean 7.83107680035755e-06 first col mean 9.41164034884423e-06 all mean 6.224746175576001e-05
0.00018849187472369522 0.00018849190382752568
rl training, epoch1, iter0, batch482/1133, batch loss:0.00018849190382752568, Training time:21877.20813059807
batch reward last col mean 0.008947283029556274 first col mean 0.00010516952897887677 all mean 0.007839703932404518
0.0007708763587288558 0.0007708763587288558
rl training, epoch1, iter0, batch483/1133, batch loss:0.0007708763587288558, Training time:21894.316004514694
batch reward last col mean 2.020688225456979e-05 first col mean 1.2014833373541478e-05 all mean 4.505076867644675e-05
1.4326104974315967e-05 1.4326108612294775e-05
rl training, epoch1, iter0, batch484/1133, batch loss:1.4326108612294775e-05, Training time:21911.57348561287
batch reward last col mean 0.0001826023799367249 first col mean 4.1683888412080705e-06 all mean 0.00019050942501053214
2.9731801987509243e-05 2.9731803806498647e-05
rl training, epoch1, iter0, batch485/1133, batch loss:2.9731803806498647e-05, Training time:21928.665593862534
batch reward last col mean 4.140093096793862e-06 first col mean 1.8517530406825244e-05 all mean 1.9279912521596998e-05
8.144070307025686e-06 8.144069397530984e-06
rl training, epoch1, iter0, batch486/1133, batch loss:8.144069397530984e-06, Training time:21945.701102495193
batch reward last col mean 1.6888444633877953e-06 first col mean 1.691745092102792e-05 all mean 3.107449447270483e-05
4.286809780751355e-05 4.2868090531555936e-05
rl training, epoch1, iter0, batch487/1133, batch loss:4.2868090531555936e-05, Training time:21962.816705703735
batch reward last col mean 5.909450555918738e-05 first col mean 1.1358119081705809e-05 all mean 5.1474838983267546e-05
6.626381946261972e-05 6.626382673857734e-05
rl training, epoch1, iter0, batch488/1133, batch loss:6.626382673857734e-05, Training time:21979.724605083466
batch reward last col mean 7.678465408389457e-06 first col mean 1.530236841063015e-05 all mean 3.467249553068541e-05
4.0930408431449905e-05 4.0930408431449905e-05
rl training, epoch1, iter0, batch489/1133, batch loss:4.0930408431449905e-05, Training time:21996.529952526093
batch reward last col mean 2.3969163521542214e-05 first col mean 5.885582368136966e-07 all mean 4.418224489199929e-05
4.311503653298132e-05 4.311503653298132e-05
rl training, epoch1, iter0, batch490/1133, batch loss:4.311503653298132e-05, Training time:22013.813994169235
batch reward last col mean 0.00020118383690714836 first col mean 4.770660598296672e-05 all mean 5.3662490245187655e-05
7.837556040612981e-05 7.837554585421458e-05
rl training, epoch1, iter0, batch491/1133, batch loss:7.837554585421458e-05, Training time:22030.906183481216
batch reward last col mean 2.9236712180136237e-06 first col mean 1.276235343539156e-05 all mean 9.630627755541354e-05
0.00010493360605323687 0.00010493359150132164
rl training, epoch1, iter0, batch492/1133, batch loss:0.00010493359150132164, Training time:22047.86349916458
batch reward last col mean 0.0003043301112484187 first col mean 0.00015037278353702277 all mean 0.0002423615223960951
6.351745832944289e-05 6.351745105348527e-05
rl training, epoch1, iter0, batch493/1133, batch loss:6.351745105348527e-05, Training time:22064.841114282608
batch reward last col mean 6.858761025796412e-07 first col mean 2.2910116967977956e-05 all mean 3.212568844901398e-05
7.950851431814954e-05 7.950850704219192e-05
rl training, epoch1, iter0, batch494/1133, batch loss:7.950850704219192e-05, Training time:22081.8309173584
batch reward last col mean 2.6155465093324892e-05 first col mean 1.19833725875651e-06 all mean 3.827201362582855e-05
2.1494392058230005e-05 2.149439387721941e-05
rl training, epoch1, iter0, batch495/1133, batch loss:2.149439387721941e-05, Training time:22099.216170310974
batch reward last col mean 2.0170135030639358e-05 first col mean 5.235580374574056e-06 all mean 7.105352415237576e-05
0.00014628987992182374 0.0001462898653699085
rl training, epoch1, iter0, batch496/1133, batch loss:0.0001462898653699085, Training time:22118.192048549652
batch reward last col mean 2.59320881923486e-06 first col mean 1.2323007467784919e-05 all mean 4.169186286162585e-05
3.829675551969558e-05 3.829675551969558e-05
rl training, epoch1, iter0, batch497/1133, batch loss:3.829675551969558e-05, Training time:22135.207263946533
batch reward last col mean 2.4178530111385044e-06 first col mean 1.3319843674253207e-05 all mean 9.413109182787593e-06
1.312315453105839e-05 1.312315453105839e-05
rl training, epoch1, iter0, batch498/1133, batch loss:1.312315453105839e-05, Training time:22152.26620531082
batch reward last col mean 6.656451887465664e-07 first col mean 0.000879956700373441 all mean 6.116570148151368e-05
0.00017020062659867108 0.0001702006411505863
rl training, epoch1, iter0, batch499/1133, batch loss:0.0001702006411505863, Training time:22169.31959080696
batch reward last col mean 4.2659323185034737e-07 first col mean 1.6959666027105413e-06 all mean 8.352140139322728e-05
0.00013459248293656856 0.00013459248293656856
rl training, epoch1, iter0, batch500/1133, batch loss:0.00013459248293656856, Training time:22186.605228185654
batch reward last col mean 0.0016942142974585295 first col mean 0.0012554707936942577 all mean 0.001431695302017033
0.0001897347392514348 0.0001897347392514348
rl training, epoch1, iter0, batch501/1133, batch loss:0.0001897347392514348, Training time:22203.5936896801
batch reward last col mean 7.887668971306994e-07 first col mean 2.1330861272872426e-05 all mean 9.451075129618403e-06
1.0361392924096435e-05 1.0361392924096435e-05
rl training, epoch1, iter0, batch502/1133, batch loss:1.0361392924096435e-05, Training time:22220.683179616928
batch reward last col mean 2.4563678380218334e-06 first col mean 9.312849442721927e-07 all mean 5.867828804184683e-05
0.00011513014032971114 0.0001151301185018383
rl training, epoch1, iter0, batch503/1133, batch loss:0.0001151301185018383, Training time:22237.76141691208
batch reward last col mean 6.344268967950484e-07 first col mean 0.00041589466854929924 all mean 1.2755772331729531e-05
2.7842865165439434e-05 2.7842865165439434e-05
rl training, epoch1, iter0, batch504/1133, batch loss:2.7842865165439434e-05, Training time:22254.82350921631
batch reward last col mean 7.086138793965802e-05 first col mean 4.243917283019982e-05 all mean 6.17088662693277e-05
8.574726962251589e-05 8.574726962251589e-05
rl training, epoch1, iter0, batch505/1133, batch loss:8.574726962251589e-05, Training time:22271.824513196945
batch reward last col mean 1.1230489690206014e-05 first col mean 1.80996516974119e-06 all mean 2.1499881768249907e-05
1.23104809972574e-05 1.2310478268773295e-05
rl training, epoch1, iter0, batch506/1133, batch loss:1.2310478268773295e-05, Training time:22288.98118543625
batch reward last col mean 2.695087459869683e-07 first col mean 2.3926852463773685e-06 all mean 3.872127490467392e-05
4.153591362410225e-05 4.153591362410225e-05
rl training, epoch1, iter0, batch507/1133, batch loss:4.153591362410225e-05, Training time:22306.009627342224
batch reward last col mean 5.314293503033696e-07 first col mean 2.3712382244411856e-06 all mean 1.9963741578976624e-05
2.1911702788202092e-05 2.191170096921269e-05
rl training, epoch1, iter0, batch508/1133, batch loss:2.191170096921269e-05, Training time:22322.949677228928
batch reward last col mean 1.2663779216381954e-06 first col mean 1.2820873962482437e-05 all mean 2.501776543795131e-05
2.408321961411275e-05 2.408321961411275e-05
rl training, epoch1, iter0, batch509/1133, batch loss:2.408321961411275e-05, Training time:22339.86642074585
batch reward last col mean 0.0005704434588551521 first col mean 9.662126831244677e-05 all mean 0.0005499344551935792
0.0001238640397787094 0.00012386402522679418
rl training, epoch1, iter0, batch510/1133, batch loss:0.00012386402522679418, Training time:22356.90909409523
batch reward last col mean 1.7446085621486418e-05 first col mean 3.444767935434356e-05 all mean 6.467165803769603e-05
0.00010067294351756573 0.00010067295806948096
rl training, epoch1, iter0, batch511/1133, batch loss:0.00010067295806948096, Training time:22373.958356380463
batch reward last col mean 5.4966654715826735e-05 first col mean 1.86055626727466e-06 all mean 3.9224356441991404e-05
2.878048508136999e-05 2.878048508136999e-05
rl training, epoch1, iter0, batch512/1133, batch loss:2.878048508136999e-05, Training time:22390.992268800735
batch reward last col mean 3.881990778609179e-06 first col mean 0.0016212858026847243 all mean 4.9190333811566234e-05
0.0001509038993390277 0.00015090392844285816
rl training, epoch1, iter0, batch513/1133, batch loss:0.00015090392844285816, Training time:22408.07657265663
batch reward last col mean 2.8641361495829187e-06 first col mean 8.820027142064646e-05 all mean 7.490427378797904e-05
8.573710510972887e-05 8.573709055781364e-05
rl training, epoch1, iter0, batch514/1133, batch loss:8.573709055781364e-05, Training time:22425.125280857086
batch reward last col mean 3.5492128517944366e-05 first col mean 3.7487225199583918e-06 all mean 6.889864016557112e-05
2.9729651942034252e-05 2.972966103698127e-05
rl training, epoch1, iter0, batch515/1133, batch loss:2.972966103698127e-05, Training time:22442.126489400864
batch reward last col mean 1.9977255760750268e-06 first col mean 1.4086747796682175e-05 all mean 3.415759056224488e-05
7.628716412000358e-05 7.62871713959612e-05
rl training, epoch1, iter0, batch516/1133, batch loss:7.62871713959612e-05, Training time:22459.215063095093
batch reward last col mean 2.3827753466321155e-05 first col mean 4.343080581747927e-05 all mean 7.182721310527995e-05
0.00018621010531205684 0.00018621010531205684
rl training, epoch1, iter0, batch517/1133, batch loss:0.00018621010531205684, Training time:22476.32291316986
batch reward last col mean 1.1596536069191643e-06 first col mean 0.0002601399028208107 all mean 5.430350574897602e-05
4.532249295152724e-05 4.532250022748485e-05
rl training, epoch1, iter0, batch518/1133, batch loss:4.532250022748485e-05, Training time:22493.37977719307
batch reward last col mean 3.6718051887874026e-07 first col mean 3.291074972366914e-05 all mean 4.5149183279136196e-05
4.9314483476337045e-05 4.931448711431585e-05
rl training, epoch1, iter0, batch519/1133, batch loss:4.931448711431585e-05, Training time:22510.431665182114
batch reward last col mean 7.208716965578787e-07 first col mean 1.5348776287282817e-05 all mean 4.819615060114302e-05
7.543026731582358e-05 7.543026731582358e-05
rl training, epoch1, iter0, batch520/1133, batch loss:7.543026731582358e-05, Training time:22527.613842010498
batch reward last col mean 9.099356361730315e-07 first col mean 5.9227859310340136e-05 all mean 2.6017329219030216e-05
2.139656680810731e-05 2.139656680810731e-05
rl training, epoch1, iter0, batch521/1133, batch loss:2.139656680810731e-05, Training time:22544.6249063015
batch reward last col mean 1.4836983837085427e-06 first col mean 0.0002996617986354977 all mean 4.0695613279240206e-05
2.4530176233383827e-05 2.4530176233383827e-05
rl training, epoch1, iter0, batch522/1133, batch loss:2.4530176233383827e-05, Training time:22561.921803712845
batch reward last col mean 1.9299795894767158e-06 first col mean 1.0508506420592312e-06 all mean 4.200746843707748e-05
0.00014471047325059772 0.00014471047325059772
rl training, epoch1, iter0, batch523/1133, batch loss:0.00014471047325059772, Training time:22579.08721256256
batch reward last col mean 2.6815391720447224e-06 first col mean 0.0007451762212440372 all mean 2.162956661777571e-05
5.182985114515759e-05 5.1829858421115205e-05
rl training, epoch1, iter0, batch524/1133, batch loss:5.1829858421115205e-05, Training time:22596.233319997787
batch reward last col mean 0.009931113570928574 first col mean 4.262195943738334e-05 all mean 0.006978184450417757
0.000640017562545836 0.000640017562545836
rl training, epoch1, iter0, batch525/1133, batch loss:0.000640017562545836, Training time:22613.587189912796
batch reward last col mean 3.5282864701002836e-05 first col mean 1.1887153959833086e-05 all mean 3.988542812294327e-05
9.217870683642104e-05 9.21786850085482e-05
rl training, epoch1, iter0, batch526/1133, batch loss:9.21786850085482e-05, Training time:22630.839408397675
batch reward last col mean 2.1947593609183969e-07 first col mean 2.384912249908666e-06 all mean 4.592091863742098e-05
8.812433225102723e-05 8.812433952698484e-05
rl training, epoch1, iter0, batch527/1133, batch loss:8.812433952698484e-05, Training time:22647.968633174896
batch reward last col mean 3.4136824979214e-05 first col mean 2.3134518869483145e-06 all mean 5.823711398988962e-05
4.521594019024633e-05 4.521594019024633e-05
rl training, epoch1, iter0, batch528/1133, batch loss:4.521594019024633e-05, Training time:22665.18885588646
batch reward last col mean 3.042215212190058e-06 first col mean 9.873547242023051e-05 all mean 4.570025339489803e-05
3.376461609150283e-05 3.376461245352402e-05
rl training, epoch1, iter0, batch529/1133, batch loss:3.376461245352402e-05, Training time:22682.23957681656
batch reward last col mean 3.1250847314368e-06 first col mean 9.316458454122767e-05 all mean 5.702081398339942e-05
8.646070637041703e-05 8.646070637041703e-05
rl training, epoch1, iter0, batch530/1133, batch loss:8.646070637041703e-05, Training time:22699.378121852875
batch reward last col mean 3.94394760405703e-07 first col mean 0.0020670981612056494 all mean 6.673646566923708e-05
7.267478213179857e-05 7.267478940775618e-05
rl training, epoch1, iter0, batch531/1133, batch loss:7.267478940775618e-05, Training time:22717.087910413742
batch reward last col mean 6.678329214082623e-07 first col mean 3.234537871321663e-05 all mean 4.870725024375133e-05
0.00019954622257500887 0.00019954622257500887
rl training, epoch1, iter0, batch532/1133, batch loss:0.00019954622257500887, Training time:22736.00113606453
batch reward last col mean 6.379890692187473e-06 first col mean 0.0018399888649582863 all mean 5.0796712457668036e-05
4.3846921471413225e-05 4.3846932385349646e-05
rl training, epoch1, iter0, batch533/1133, batch loss:4.3846932385349646e-05, Training time:22753.297211408615
batch reward last col mean 1.5443926315583667e-07 first col mean 4.4975335185881704e-05 all mean 4.108046414330602e-05
0.0001335056876996532 0.0001335056876996532
rl training, epoch1, iter0, batch534/1133, batch loss:0.0001335056876996532, Training time:22770.605417490005
batch reward last col mean 5.773018756372039e-07 first col mean 2.0279678665247047e-06 all mean 7.405239011859521e-05
0.00010330160148441792 0.00010330157965654507
rl training, epoch1, iter0, batch535/1133, batch loss:0.00010330157965654507, Training time:22787.560748577118
batch reward last col mean 0.002206402597948909 first col mean 0.00014761844067834318 all mean 0.0019438702147454023
0.00013003399362787604 0.00013003399362787604
rl training, epoch1, iter0, batch536/1133, batch loss:0.00013003399362787604, Training time:22804.67300581932
batch reward last col mean 0.007183120120316744 first col mean 3.508208101266064e-05 all mean 0.006806944962590933
0.00028619737713597715 0.0002861973480321467
rl training, epoch1, iter0, batch537/1133, batch loss:0.0002861973480321467, Training time:22821.70485305786
batch reward last col mean 3.752918473765021e-07 first col mean 8.051976328715682e-05 all mean 1.0622519766911864e-05
7.889112566772383e-06 7.889112566772383e-06
rl training, epoch1, iter0, batch538/1133, batch loss:7.889112566772383e-06, Training time:22838.906497001648
batch reward last col mean 0.0022800301667302847 first col mean 1.6271085769403726e-05 all mean 0.0011785478563979268
0.0003479598381090909 0.00034795975079759955
rl training, epoch1, iter0, batch539/1133, batch loss:0.00034795975079759955, Training time:22856.062638521194
batch reward last col mean 4.953768439008854e-06 first col mean 0.00032587474561296403 all mean 2.7889875127584673e-05
7.590936729684472e-05 7.590936729684472e-05
rl training, epoch1, iter0, batch540/1133, batch loss:7.590936729684472e-05, Training time:22872.96265935898
batch reward last col mean 2.3297106963582337e-06 first col mean 0.00015206538955681026 all mean 7.178134546848014e-05
8.211030217353255e-05 8.211028762161732e-05
rl training, epoch1, iter0, batch541/1133, batch loss:8.211028762161732e-05, Training time:22889.964307546616
batch reward last col mean 8.473242587569985e-07 first col mean 1.0466213097970467e-05 all mean 2.1373778508859687e-05
2.8176504201837815e-05 2.8176504201837815e-05
rl training, epoch1, iter0, batch542/1133, batch loss:2.8176504201837815e-05, Training time:22906.877853631973
batch reward last col mean 0.0012103315675631166 first col mean 2.0803083316423e-05 all mean 0.000851557357236743
0.000108309555798769 0.00010830952669493854
rl training, epoch1, iter0, batch543/1133, batch loss:0.00010830952669493854, Training time:22923.931032896042
batch reward last col mean 1.6981596218101913e-06 first col mean 1.918102952913614e-06 all mean 1.6558826246182434e-05
2.0073362975381315e-05 2.0073362975381315e-05
rl training, epoch1, iter0, batch544/1133, batch loss:2.0073362975381315e-05, Training time:22940.97323846817
batch reward last col mean 0.0007210658513940871 first col mean 0.00018280222138855606 all mean 0.00018833090143743902
0.00011898171942448243 0.00011898171942448243
rl training, epoch1, iter0, batch545/1133, batch loss:0.00011898171942448243, Training time:22957.740597724915
batch reward last col mean 5.50171421309642e-07 first col mean 3.914194621756906e-06 all mean 4.883308429270983e-05
6.223130185389891e-05 6.22312945779413e-05
rl training, epoch1, iter0, batch546/1133, batch loss:6.22312945779413e-05, Training time:22974.710656404495
batch reward last col mean 5.8380952395964414e-05 first col mean 1.5482461321880692e-06 all mean 0.00010470971028553322
0.0002133108355337754 0.0002133107918780297
rl training, epoch1, iter0, batch547/1133, batch loss:0.0002133107918780297, Training time:22992.045348405838
batch reward last col mean 5.540568963624537e-07 first col mean 3.662864401121624e-05 all mean 9.574123396305367e-05
0.00022827755310572684 0.00022827750944998115
rl training, epoch1, iter0, batch548/1133, batch loss:0.00022827750944998115, Training time:23008.99049973488
batch reward last col mean 2.5337340048281476e-05 first col mean 6.474749534390867e-05 all mean 5.448307274491526e-05
2.1972544345771894e-05 2.19725479837507e-05
rl training, epoch1, iter0, batch549/1133, batch loss:2.19725479837507e-05, Training time:23027.92093372345
batch reward last col mean 1.6696203601895832e-06 first col mean 3.30251750710886e-05 all mean 4.99719099025242e-05
8.067455928539857e-05 8.067456656135619e-05
rl training, epoch1, iter0, batch550/1133, batch loss:8.067456656135619e-05, Training time:23045.00900197029
batch reward last col mean 8.06481409654225e-07 first col mean 8.153792805387639e-06 all mean 6.780531839467585e-05
5.578823765972629e-05 5.578825221164152e-05
rl training, epoch1, iter0, batch551/1133, batch loss:5.578825221164152e-05, Training time:23063.746772527695
batch reward last col mean 2.4986540665850043e-05 first col mean 0.0009889547945931554 all mean 4.903875378658995e-05
4.548683136817999e-05 4.54868350061588e-05
rl training, epoch1, iter0, batch552/1133, batch loss:4.54868350061588e-05, Training time:23080.8523209095
batch reward last col mean 2.3532103909928992e-07 first col mean 3.269064109190367e-06 all mean 3.3049745979951695e-05
2.8922842830070294e-05 2.89228464680491e-05
rl training, epoch1, iter0, batch553/1133, batch loss:2.89228464680491e-05, Training time:23097.809720516205
batch reward last col mean 9.018718628794886e-06 first col mean 3.482097099549719e-06 all mean 2.579249849077314e-05
3.651729639386758e-05 3.651729639386758e-05
rl training, epoch1, iter0, batch554/1133, batch loss:3.651729639386758e-05, Training time:23115.017474651337
batch reward last col mean 0.010459394194185734 first col mean 1.09993038677203e-06 all mean 0.009863429702818394
0.0007899507763795555 0.0007899507763795555
rl training, epoch1, iter0, batch555/1133, batch loss:0.0007899507763795555, Training time:23132.226787805557
batch reward last col mean 4.7510286549368175e-07 first col mean 0.000943695951718837 all mean 6.202294753165916e-05
7.158554944908246e-05 7.158553489716724e-05
rl training, epoch1, iter0, batch556/1133, batch loss:7.158553489716724e-05, Training time:23149.404556274414
batch reward last col mean 4.322403583501e-06 first col mean 6.298049811448436e-06 all mean 3.6619567254092544e-05
4.245966556482017e-05 4.245966556482017e-05
rl training, epoch1, iter0, batch557/1133, batch loss:4.245966556482017e-05, Training time:23167.398899555206
batch reward last col mean 1.4773456314287614e-05 first col mean 4.893107075076841e-07 all mean 3.648518759291619e-05
2.817737913574092e-05 2.8177375497762114e-05
rl training, epoch1, iter0, batch558/1133, batch loss:2.8177375497762114e-05, Training time:23184.465430021286
batch reward last col mean 2.355632204853464e-07 first col mean 6.349636123559321e-07 all mean 3.17088451993186e-05
3.261453821323812e-05 3.261453457525931e-05
rl training, epoch1, iter0, batch559/1133, batch loss:3.261453457525931e-05, Training time:23201.55464053154
batch reward last col mean 5.332063665264286e-06 first col mean 2.4299113192682853e-06 all mean 2.3986847736523487e-05
2.0665334886871278e-05 2.0665336705860682e-05
rl training, epoch1, iter0, batch560/1133, batch loss:2.0665336705860682e-05, Training time:23218.51395010948
batch reward last col mean 1.4650614730271627e-06 first col mean 1.3067265172139741e-05 all mean 1.8210095731774345e-05
3.9670165278948843e-05 3.9670161640970036e-05
rl training, epoch1, iter0, batch561/1133, batch loss:3.9670161640970036e-05, Training time:23235.464161157608
batch reward last col mean 9.295986092183739e-05 first col mean 9.872318514680956e-06 all mean 0.00012113776756450534
7.609432941535488e-05 7.609432941535488e-05
rl training, epoch1, iter0, batch562/1133, batch loss:7.609432941535488e-05, Training time:23252.47363948822
batch reward last col mean 6.849071360193193e-05 first col mean 1.2141894330852665e-05 all mean 5.8615307352738455e-05
4.762547541758977e-05 4.762547541758977e-05
rl training, epoch1, iter0, batch563/1133, batch loss:4.762547541758977e-05, Training time:23269.58448076248
batch reward last col mean 8.306465133500751e-07 first col mean 1.5766738670208724e-06 all mean 2.3112095732358284e-05
4.863630238105543e-05 4.863630238105543e-05
rl training, epoch1, iter0, batch564/1133, batch loss:4.863630238105543e-05, Training time:23286.594440698624
batch reward last col mean 5.529771442525089e-06 first col mean 1.2926347153552342e-05 all mean 4.573892510961741e-05
5.0531809392850846e-05 5.053180575487204e-05
rl training, epoch1, iter0, batch565/1133, batch loss:5.053180575487204e-05, Training time:23303.694734096527
batch reward last col mean 1.0217986528004985e-06 first col mean 2.9837724468961824e-06 all mean 3.0006662200321443e-05
3.053879481740296e-05 3.053879481740296e-05
rl training, epoch1, iter0, batch566/1133, batch loss:3.053879481740296e-05, Training time:23320.79283261299
batch reward last col mean 4.2129209759877995e-05 first col mean 0.00011369655112503096 all mean 7.794734119670466e-05
9.16692879400216e-05 9.166929521597922e-05
rl training, epoch1, iter0, batch567/1133, batch loss:9.166929521597922e-05, Training time:23337.893749713898
batch reward last col mean 4.636232802113227e-07 first col mean 0.0018836170202121139 all mean 0.0001380505709676072
0.00030933262314647436 0.0003093325940426439
rl training, epoch1, iter0, batch568/1133, batch loss:0.0003093325940426439, Training time:23354.896077632904
batch reward last col mean 3.2168962206924334e-05 first col mean 7.83966897870414e-05 all mean 4.8730213165981695e-05
5.109432095196098e-05 5.10943318658974e-05
rl training, epoch1, iter0, batch569/1133, batch loss:5.10943318658974e-05, Training time:23371.88988137245
batch reward last col mean 3.0773337584832916e-06 first col mean 1.1373536835890263e-05 all mean 5.2274815971031785e-05
0.00015909949433989823 0.00015909949433989823
rl training, epoch1, iter0, batch570/1133, batch loss:0.00015909949433989823, Training time:23388.848028421402
batch reward last col mean 3.521424218888569e-07 first col mean 6.312315235845745e-06 all mean 6.469980871770531e-05
0.00013725305325351655 0.00013725303870160133
rl training, epoch1, iter0, batch571/1133, batch loss:0.00013725303870160133, Training time:23405.862078666687
batch reward last col mean 3.0663086363347247e-06 first col mean 1.1762903341150377e-05 all mean 1.7607069821679033e-05
3.195879980921745e-05 3.195879980921745e-05
rl training, epoch1, iter0, batch572/1133, batch loss:3.195879980921745e-05, Training time:23422.875094652176
batch reward last col mean 7.665409793844447e-05 first col mean 4.253012593835592e-05 all mean 5.395026892074384e-05
3.1876137654762715e-05 3.1876137654762715e-05
rl training, epoch1, iter0, batch573/1133, batch loss:3.1876137654762715e-05, Training time:23439.80005979538
batch reward last col mean 0.0004594277997966856 first col mean 7.637625458301045e-06 all mean 0.00024156030849553645
0.00010171190660912544 0.00010171191388508305
rl training, epoch1, iter0, batch574/1133, batch loss:0.00010171191388508305, Training time:23456.984350442886
batch reward last col mean 3.303305129520595e-05 first col mean 0.0003301740507595241 all mean 3.2205185561906546e-05
4.2951378418365493e-05 4.2951378418365493e-05
rl training, epoch1, iter0, batch575/1133, batch loss:4.2951378418365493e-05, Training time:23474.036336421967
batch reward last col mean 0.00027117805439047515 first col mean 7.309253760467982e-06 all mean 0.00028435245621949434
0.00010355824633734301 0.00010355823178542778
rl training, epoch1, iter0, batch576/1133, batch loss:0.00010355823178542778, Training time:23491.21298456192
batch reward last col mean 3.24843313137535e-07 first col mean 0.0015967517392709851 all mean 0.00010839795868378133
0.0003858930431306362 0.0003858930431306362
rl training, epoch1, iter0, batch577/1133, batch loss:0.0003858930431306362, Training time:23508.389020204544
batch reward last col mean 3.568399915820919e-05 first col mean 4.346894274931401e-05 all mean 2.478236820024904e-05
1.6603535186732188e-05 1.6603535186732188e-05
rl training, epoch1, iter0, batch578/1133, batch loss:1.6603535186732188e-05, Training time:23525.48112678528
batch reward last col mean 1.6439551018265774e-06 first col mean 0.00029934136546216905 all mean 7.129119330784306e-05
7.077229383867234e-05 7.077230111462995e-05
rl training, epoch1, iter0, batch579/1133, batch loss:7.077230111462995e-05, Training time:23542.618010044098
batch reward last col mean 0.00012047930795233697 first col mean 6.729433152941056e-06 all mean 0.00014580045535694808
8.12993457657285e-05 8.12993457657285e-05
rl training, epoch1, iter0, batch580/1133, batch loss:8.12993457657285e-05, Training time:23559.68332028389
batch reward last col mean 1.589252133271657e-05 first col mean 0.0006438787095248699 all mean 5.312705980031751e-05
5.441602843347937e-05 5.441602843347937e-05
rl training, epoch1, iter0, batch581/1133, batch loss:5.441602843347937e-05, Training time:23576.60132956505
batch reward last col mean 2.1437799659906887e-06 first col mean 7.756207196507603e-06 all mean 6.8494031438604e-05
0.00012304604751989245 0.00012304606207180768
rl training, epoch1, iter0, batch582/1133, batch loss:0.00012304606207180768, Training time:23593.817660570145
batch reward last col mean 5.064123797637876e-06 first col mean 5.197208884055726e-05 all mean 1.530219742562622e-05
1.574039924889803e-05 1.5740397429908626e-05
rl training, epoch1, iter0, batch583/1133, batch loss:1.5740397429908626e-05, Training time:23611.110307216644
batch reward last col mean 2.2555536816071253e-06 first col mean 2.904707571360632e-06 all mean 6.389115151250735e-05
4.635887671611272e-05 4.635887671611272e-05
rl training, epoch1, iter0, batch584/1133, batch loss:4.635887671611272e-05, Training time:23628.30228829384
batch reward last col mean 0.005687561817467213 first col mean 0.0001830795663408935 all mean 0.005245056003332138
0.0005811391165480018 0.0005811391165480018
rl training, epoch1, iter0, batch585/1133, batch loss:0.0005811391165480018, Training time:23645.30534720421
batch reward last col mean 3.142614878015593e-05 first col mean 1.3909653716837056e-05 all mean 1.82130988832796e-05
1.2513928595581092e-05 1.2513926776591688e-05
rl training, epoch1, iter0, batch586/1133, batch loss:1.2513926776591688e-05, Training time:23662.309806108475
batch reward last col mean 5.30998659087345e-06 first col mean 2.2752788936486468e-05 all mean 4.2312090954510495e-05
4.352293035481125e-05 4.352293035481125e-05
rl training, epoch1, iter0, batch587/1133, batch loss:4.352293035481125e-05, Training time:23679.272748708725
batch reward last col mean 3.063411350012757e-05 first col mean 2.9820074587405543e-07 all mean 6.064950503059663e-05
5.1616603741422296e-05 5.161660010344349e-05
rl training, epoch1, iter0, batch588/1133, batch loss:5.161660010344349e-05, Training time:23696.289234161377
batch reward last col mean 3.2426520192530006e-05 first col mean 0.0017720704199746251 all mean 5.9816808061441407e-05
1.3277974176162388e-05 1.3277975995151792e-05
rl training, epoch1, iter0, batch589/1133, batch loss:1.3277975995151792e-05, Training time:23713.105886220932
batch reward last col mean 3.1461015623790445e-06 first col mean 4.9558209866518155e-05 all mean 9.103549382416531e-05
0.00019371352391317487 0.00019371350936125964
rl training, epoch1, iter0, batch590/1133, batch loss:0.00019371350936125964, Training time:23731.48380756378
batch reward last col mean 2.639376907609403e-05 first col mean 3.1956454904502607e-07 all mean 7.266646571224555e-05
4.912161239190027e-05 4.912161239190027e-05
rl training, epoch1, iter0, batch591/1133, batch loss:4.912161239190027e-05, Training time:23748.594599962234
batch reward last col mean 3.04148261420778e-06 first col mean 1.5770049230923178e-06 all mean 3.685024785227142e-05
8.795929898042232e-05 8.795929898042232e-05
rl training, epoch1, iter0, batch592/1133, batch loss:8.795929898042232e-05, Training time:23766.66059398651
batch reward last col mean 1.0236481102765538e-05 first col mean 0.0020624594762921333 all mean 0.00010697013203753158
0.0003814908559434116 0.0003814908559434116
rl training, epoch1, iter0, batch593/1133, batch loss:0.0003814908559434116, Training time:23783.691054582596
batch reward last col mean 1.0486277233212604e-06 first col mean 0.00010292726074112579 all mean 2.311742355232127e-05
2.6907182473223656e-05 2.690718429221306e-05
rl training, epoch1, iter0, batch594/1133, batch loss:2.690718429221306e-05, Training time:23800.7292573452
batch reward last col mean 2.8141867005615495e-06 first col mean 1.9053724145123851e-06 all mean 2.4803754058666527e-05
2.035812576650642e-05 2.0358129404485226e-05
rl training, epoch1, iter0, batch595/1133, batch loss:2.0358129404485226e-05, Training time:23819.69914317131
batch reward last col mean 0.00013698090333491564 first col mean 0.0015327335568144917 all mean 0.0001252933725481853
9.105347999138758e-05 9.105347999138758e-05
rl training, epoch1, iter0, batch596/1133, batch loss:9.105347999138758e-05, Training time:23838.532549619675
batch reward last col mean 9.386573219671845e-05 first col mean 0.001656579552218318 all mean 0.00012502245954237878
0.0001421995839336887 0.0001421995839336887
rl training, epoch1, iter0, batch597/1133, batch loss:0.0001421995839336887, Training time:23855.485679149628
batch reward last col mean 7.234916211018572e-06 first col mean 0.0019577965140342712 all mean 8.414589683525264e-05
8.80568113643676e-05 8.805682591628283e-05
rl training, epoch1, iter0, batch598/1133, batch loss:8.805682591628283e-05, Training time:23872.65649151802
batch reward last col mean 0.00017776330059859902 first col mean 3.815838226728374e-06 all mean 0.0001778265432221815
0.00039449945325031877 0.00039449945325031877
rl training, epoch1, iter0, batch599/1133, batch loss:0.00039449945325031877, Training time:23889.743895292282
batch reward last col mean 2.439007403154392e-06 first col mean 0.0006092523690313101 all mean 3.516182550811209e-05
4.179459574515931e-05 4.179459574515931e-05
rl training, epoch1, iter0, batch600/1133, batch loss:4.179459574515931e-05, Training time:23906.803572416306
batch reward last col mean 2.3525733922724612e-05 first col mean 7.95262440078659e-06 all mean 3.584424848668277e-05
2.1737145289080217e-05 2.1737139832112007e-05
rl training, epoch1, iter0, batch601/1133, batch loss:2.1737139832112007e-05, Training time:23923.847591161728
batch reward last col mean 8.107334110718512e-07 first col mean 0.0009725857526063919 all mean 5.1645623898366466e-05
4.663821164285764e-05 4.6638218918815255e-05
rl training, epoch1, iter0, batch602/1133, batch loss:4.6638218918815255e-05, Training time:23940.906417369843
batch reward last col mean 0.004140564706176519 first col mean 5.422408867161721e-05 all mean 0.003478780621662736
0.0005470053292810917 0.0005470053292810917
rl training, epoch1, iter0, batch603/1133, batch loss:0.0005470053292810917, Training time:23958.06504559517
batch reward last col mean 1.5466744116565678e-06 first col mean 5.273413989925757e-06 all mean 4.149323285673745e-05
4.7576682845829055e-05 4.757668648380786e-05
rl training, epoch1, iter0, batch604/1133, batch loss:4.757668648380786e-05, Training time:23975.16061091423
batch reward last col mean 2.743909703895042e-07 first col mean 1.2988311937078834e-06 all mean 2.760317329375539e-05
3.323412602185272e-05 3.323412238387391e-05
rl training, epoch1, iter0, batch605/1133, batch loss:3.323412238387391e-05, Training time:23992.291703224182
batch reward last col mean 0.00028823426691815257 first col mean 0.0017353127477690578 all mean 0.00026449907454662025
0.00012957473518326879 0.00012957472063135356
rl training, epoch1, iter0, batch606/1133, batch loss:0.00012957472063135356, Training time:24009.453457593918
batch reward last col mean 0.00010338321590097621 first col mean 6.979890895308927e-05 all mean 0.0001237107499036938
2.6235748009639792e-05 2.623574255267158e-05
rl training, epoch1, iter0, batch607/1133, batch loss:2.623574255267158e-05, Training time:24026.39315700531
batch reward last col mean 2.942105675174389e-05 first col mean 9.616716852178797e-06 all mean 3.583313446142711e-05
5.4640859161736444e-05 5.464086279971525e-05
rl training, epoch1, iter0, batch608/1133, batch loss:5.464086279971525e-05, Training time:24043.318006277084
batch reward last col mean 0.00023576481908094138 first col mean 5.16006502948585e-06 all mean 0.0002763865632005036
0.00024303479585796595 0.00024303479585796595
rl training, epoch1, iter0, batch609/1133, batch loss:0.00024303479585796595, Training time:24060.430360794067
batch reward last col mean 1.1479617114673601e-06 first col mean 8.601253284723498e-06 all mean 4.976940908818506e-05
0.00031357549596577883 0.00031357549596577883
rl training, epoch1, iter0, batch610/1133, batch loss:0.00031357549596577883, Training time:24077.41720223427
batch reward last col mean 5.158646558811597e-07 first col mean 6.220339855644852e-05 all mean 5.07136937812902e-05
7.765115879010409e-05 7.765114423818886e-05
rl training, epoch1, iter0, batch611/1133, batch loss:7.765114423818886e-05, Training time:24094.44517970085
batch reward last col mean 6.997643140493892e-07 first col mean 0.00012568497913889587 all mean 0.00011992277723038569
0.00015672938025090843 0.0001567293656989932
rl training, epoch1, iter0, batch612/1133, batch loss:0.0001567293656989932, Training time:24111.589829921722
batch reward last col mean 1.5520158740400802e-06 first col mean 1.282325047213817e-05 all mean 5.288710963213816e-05
5.184886686038226e-05 5.1848870498361066e-05
rl training, epoch1, iter0, batch613/1133, batch loss:5.1848870498361066e-05, Training time:24128.5867497921
batch reward last col mean 2.4019955162657425e-06 first col mean 2.9411507966869976e-06 all mean 3.8478381611639634e-05
2.397863136138767e-05 2.3978629542398266e-05
rl training, epoch1, iter0, batch614/1133, batch loss:2.3978629542398266e-05, Training time:24145.597759962082
batch reward last col mean 7.961106166476384e-05 first col mean 0.0007026323582977057 all mean 0.00011395136243663728
9.470471559325233e-05 9.470471559325233e-05
rl training, epoch1, iter0, batch615/1133, batch loss:9.470471559325233e-05, Training time:24162.555302619934
batch reward last col mean 3.779220378419268e-06 first col mean 6.672215386060998e-05 all mean 6.013995880493894e-05
5.90180279687047e-05 5.90180279687047e-05
rl training, epoch1, iter0, batch616/1133, batch loss:5.90180279687047e-05, Training time:24179.62159180641
batch reward last col mean 6.143419000181893e-07 first col mean 9.586111445969436e-06 all mean 3.405288953217678e-05
3.964714414905757e-05 3.964713687309995e-05
rl training, epoch1, iter0, batch617/1133, batch loss:3.964713687309995e-05, Training time:24196.564677476883
batch reward last col mean 4.972441729478305e-06 first col mean 7.452272257069126e-05 all mean 2.609259172459133e-05
1.9189445083611645e-05 1.918944690260105e-05
rl training, epoch1, iter0, batch618/1133, batch loss:1.918944690260105e-05, Training time:24213.478560447693
batch reward last col mean 7.005939437476627e-07 first col mean 4.4379148675943725e-06 all mean 5.044948557042517e-05
8.219169831136242e-05 8.219168375944719e-05
rl training, epoch1, iter0, batch619/1133, batch loss:8.219168375944719e-05, Training time:24230.359151124954
batch reward last col mean 2.207174475188367e-06 first col mean 1.025407300403458e-06 all mean 4.412734415382147e-05
6.891599332448095e-05 6.891597877256572e-05
rl training, epoch1, iter0, batch620/1133, batch loss:6.891597877256572e-05, Training time:24247.365480422974
batch reward last col mean 0.0001320099545409903 first col mean 8.267338125733659e-05 all mean 0.00016011907428037375
0.00017241209570784122 0.00017241212481167167
rl training, epoch1, iter0, batch621/1133, batch loss:0.00017241212481167167, Training time:24264.31678724289
batch reward last col mean 1.032902332553931e-07 first col mean 0.0002513953950256109 all mean 3.465339250396937e-05
5.018819138058461e-05 5.0188184104627e-05
rl training, epoch1, iter0, batch622/1133, batch loss:5.0188184104627e-05, Training time:24281.389938116074
batch reward last col mean 2.360222970310133e-05 first col mean 1.4058850865694694e-05 all mean 4.280670327716507e-05
8.164803148247302e-05 8.164803148247302e-05
rl training, epoch1, iter0, batch623/1133, batch loss:8.164803148247302e-05, Training time:24298.518297433853
batch reward last col mean 5.131775196787203e-06 first col mean 1.9960622012149543e-05 all mean 4.967110726283863e-05
3.4232136385980994e-05 3.4232136385980994e-05
rl training, epoch1, iter0, batch624/1133, batch loss:3.4232136385980994e-05, Training time:24315.961638212204
batch reward last col mean 7.176281360443681e-05 first col mean 2.3286729629035108e-05 all mean 0.00010068537812912837
3.7688649172196165e-05 3.7688649172196165e-05
rl training, epoch1, iter0, batch625/1133, batch loss:3.7688649172196165e-05, Training time:24333.16852426529
batch reward last col mean 3.114751052635256e-07 first col mean 9.971587132895365e-06 all mean 3.4629756555659696e-05
3.688292781589553e-05 3.6882931453874335e-05
rl training, epoch1, iter0, batch626/1133, batch loss:3.6882931453874335e-05, Training time:24350.331692695618
batch reward last col mean 4.327096121414797e-06 first col mean 0.00037198944482952356 all mean 8.524519944330677e-05
0.00019655830692499876 0.00019655830692499876
rl training, epoch1, iter0, batch627/1133, batch loss:0.00019655830692499876, Training time:24367.438134908676
batch reward last col mean 0.00035270987427793443 first col mean 0.00019904975488316268 all mean 0.00015175103908404708
4.739458381664008e-05 4.739458381664008e-05
rl training, epoch1, iter0, batch628/1133, batch loss:4.739458381664008e-05, Training time:24384.6060628891
batch reward last col mean 1.2126862202421762e-05 first col mean 0.00013693231448996812 all mean 7.923820521682501e-05
0.00011407550482545048 0.00011407550482545048
rl training, epoch1, iter0, batch629/1133, batch loss:0.00011407550482545048, Training time:24401.84492278099
batch reward last col mean 1.9998477000626735e-05 first col mean 3.6775772969122045e-06 all mean 4.532713137450628e-05
3.1134990422287956e-05 3.113498678430915e-05
rl training, epoch1, iter0, batch630/1133, batch loss:3.113498678430915e-05, Training time:24419.273906469345
batch reward last col mean 0.00010970024595735595 first col mean 4.896954487776384e-05 all mean 0.00010329625365557149
8.940417319536209e-05 8.940416591940448e-05
rl training, epoch1, iter0, batch631/1133, batch loss:8.940416591940448e-05, Training time:24436.356860876083
batch reward last col mean 3.4310896808165126e-06 first col mean 8.104186235868838e-06 all mean 5.371065344661474e-05
6.0792201111325994e-05 6.0792212025262415e-05
rl training, epoch1, iter0, batch632/1133, batch loss:6.0792212025262415e-05, Training time:24455.316885232925
batch reward last col mean 0.00016017473535612226 first col mean 6.852786100353114e-06 all mean 8.445622370345518e-05
5.653286279994063e-05 5.6532870075898245e-05
rl training, epoch1, iter0, batch633/1133, batch loss:5.6532870075898245e-05, Training time:24472.493574380875
batch reward last col mean 4.2474118799873395e-07 first col mean 1.1889988854818512e-05 all mean 3.155395825160667e-05
6.446163024520501e-05 6.446163024520501e-05
rl training, epoch1, iter0, batch634/1133, batch loss:6.446163024520501e-05, Training time:24489.667089939117
batch reward last col mean 7.764256588416174e-05 first col mean 3.571284469217062e-05 all mean 5.6433775171171874e-05
7.91969068814069e-05 7.91969068814069e-05
rl training, epoch1, iter0, batch635/1133, batch loss:7.91969068814069e-05, Training time:24507.748483657837
batch reward last col mean 3.233159759474802e-06 first col mean 1.2929358490509912e-06 all mean 2.8606471460079774e-05
5.219651211518794e-05 5.2196508477209136e-05
rl training, epoch1, iter0, batch636/1133, batch loss:5.2196508477209136e-05, Training time:24524.834294080734
batch reward last col mean 1.1618158168857917e-05 first col mean 8.291470976473647e-07 all mean 2.9587272365461104e-05
2.6586512831272557e-05 2.6586512831272557e-05
rl training, epoch1, iter0, batch637/1133, batch loss:2.6586512831272557e-05, Training time:24541.974374055862
batch reward last col mean 4.256791271473048e-06 first col mean 0.0012731128372251987 all mean 5.689422323484905e-05
7.354316039709374e-05 7.354316039709374e-05
rl training, epoch1, iter0, batch638/1133, batch loss:7.354316039709374e-05, Training time:24559.01198363304
batch reward last col mean 1.257506369256589e-06 first col mean 1.5382843230327126e-06 all mean 4.5357846829574555e-05
0.00025960442144423723 0.0002596044505480677
rl training, epoch1, iter0, batch639/1133, batch loss:0.0002596044505480677, Training time:24576.093985319138
batch reward last col mean 3.1700951694801915e-06 first col mean 6.30285358056426e-05 all mean 3.744270361494273e-05
3.7979021726641804e-05 3.7979021726641804e-05
rl training, epoch1, iter0, batch640/1133, batch loss:3.7979021726641804e-05, Training time:24593.230054855347
batch reward last col mean 2.8336845048215764e-07 first col mean 3.175600340910023e-06 all mean 3.840084173134528e-05
1.731395059323404e-05 1.7313952412223443e-05
rl training, epoch1, iter0, batch641/1133, batch loss:1.7313952412223443e-05, Training time:24610.33615231514
batch reward last col mean 0.00012071352102793753 first col mean 1.8322789401281625e-05 all mean 8.040487591642886e-05
9.996381413657218e-05 9.996381413657218e-05
rl training, epoch1, iter0, batch642/1133, batch loss:9.996381413657218e-05, Training time:24627.489419460297
batch reward last col mean 6.78539254295174e-06 first col mean 0.0011897250078618526 all mean 3.4525306546129286e-05
1.7460053641116247e-05 1.7460057279095054e-05
rl training, epoch1, iter0, batch643/1133, batch loss:1.7460057279095054e-05, Training time:24644.66709280014
batch reward last col mean 0.002779412316158414 first col mean 3.3697422622935846e-05 all mean 0.002690280321985483
0.0003936264256481081 0.0003936264547519386
rl training, epoch1, iter0, batch644/1133, batch loss:0.0003936264547519386, Training time:24661.72825360298
batch reward last col mean 8.241820069088135e-06 first col mean 9.320804110757308e-07 all mean 9.54188872128725e-05
0.0002943645231425762 0.00029436449403874576
rl training, epoch1, iter0, batch645/1133, batch loss:0.00029436449403874576, Training time:24678.815834760666
batch reward last col mean 4.177129540039459e-07 first col mean 1.4146969533612719e-06 all mean 6.661839870503172e-05
0.0002145085745723918 0.0002145085745723918
rl training, epoch1, iter0, batch646/1133, batch loss:0.0002145085745723918, Training time:24696.15977191925
batch reward last col mean 9.598986071068794e-05 first col mean 3.3221849662368186e-06 all mean 4.231213824823499e-05
5.025811697123572e-05 5.025811697123572e-05
rl training, epoch1, iter0, batch647/1133, batch loss:5.025811697123572e-05, Training time:24713.32671713829
batch reward last col mean 1.48594642723765e-06 first col mean 7.413831326630316e-07 all mean 6.393244257196784e-05
0.00018315365014132112 0.00018315365014132112
rl training, epoch1, iter0, batch648/1133, batch loss:0.00018315365014132112, Training time:24730.580228567123
batch reward last col mean 0.00018003526201937348 first col mean 1.3870471775589976e-06 all mean 0.00016981859516818076
2.9990313123562373e-05 2.9990313123562373e-05
rl training, epoch1, iter0, batch649/1133, batch loss:2.9990313123562373e-05, Training time:24747.639746189117
batch reward last col mean 3.4175975542893866e-06 first col mean 0.0005453031044453382 all mean 7.291463407455012e-05
0.00015354443166870624 0.000153544417116791
rl training, epoch1, iter0, batch650/1133, batch loss:0.000153544417116791, Training time:24764.604464530945
batch reward last col mean 8.066650480031967e-06 first col mean 2.468369075359078e-06 all mean 4.256292959325947e-05
3.5183857107767835e-05 3.518385346978903e-05
rl training, epoch1, iter0, batch651/1133, batch loss:3.518385346978903e-05, Training time:24781.634944200516
batch reward last col mean 5.0046314754581545e-06 first col mean 4.296100541978376e-06 all mean 1.503698240412632e-05
2.625986780913081e-05 2.6259864171152003e-05
rl training, epoch1, iter0, batch652/1133, batch loss:2.6259864171152003e-05, Training time:24798.68936729431
batch reward last col mean 5.175236310606124e-06 first col mean 0.0014534747460857034 all mean 5.585763938142918e-05
6.178256444400176e-05 6.178257899591699e-05
rl training, epoch1, iter0, batch653/1133, batch loss:6.178257899591699e-05, Training time:24815.797691822052
batch reward last col mean 1.4004814374857233e-07 first col mean 1.4708886737935245e-05 all mean 0.0001010334090096876
0.00022458299645222723 0.00022458299645222723
rl training, epoch1, iter0, batch654/1133, batch loss:0.00022458299645222723, Training time:24832.983417987823
batch reward last col mean 4.3027137053286424e-07 first col mean 1.2654545571422204e-05 all mean 4.118429933441803e-05
8.546586468582973e-05 8.546587923774496e-05
rl training, epoch1, iter0, batch655/1133, batch loss:8.546587923774496e-05, Training time:24850.193405151367
batch reward last col mean 2.4965938791865483e-06 first col mean 3.36639532179106e-05 all mean 6.707706779707223e-05
0.0001080479851225391 0.00010804797057062387
rl training, epoch1, iter0, batch656/1133, batch loss:0.00010804797057062387, Training time:24867.32825112343
batch reward last col mean 1.537507341708988e-05 first col mean 0.000253328587859869 all mean 4.19041643908713e-05
2.9486984203686006e-05 2.9486984203686006e-05
rl training, epoch1, iter0, batch657/1133, batch loss:2.9486984203686006e-05, Training time:24884.503255605698
batch reward last col mean 7.525075602643483e-07 first col mean 3.1217565265251324e-05 all mean 8.088244067039341e-05
0.00024261481303256005 0.00024261482758447528
rl training, epoch1, iter0, batch658/1133, batch loss:0.00024261482758447528, Training time:24901.62143588066
batch reward last col mean 2.978732425162889e-07 first col mean 2.8698359528789297e-05 all mean 5.1772014558082446e-05
7.81579437898472e-05 7.815792923793197e-05
rl training, epoch1, iter0, batch659/1133, batch loss:7.815792923793197e-05, Training time:24918.781856536865
batch reward last col mean 1.9621007595560513e-05 first col mean 0.0005012098117731512 all mean 4.30433101428207e-05
4.6420725993812084e-05 4.6420725993812084e-05
rl training, epoch1, iter0, batch660/1133, batch loss:4.6420725993812084e-05, Training time:24935.809458732605
batch reward last col mean 7.846429070923477e-06 first col mean 1.028373844746966e-06 all mean 5.088686157250777e-05
5.7675319112604484e-05 5.7675330026540905e-05
rl training, epoch1, iter0, batch661/1133, batch loss:5.7675330026540905e-05, Training time:24952.925662517548
batch reward last col mean 1.540084667794872e-05 first col mean 0.0015815387014299631 all mean 4.588139199768193e-05
2.9421613362501375e-05 2.9421613362501375e-05
rl training, epoch1, iter0, batch662/1133, batch loss:2.9421613362501375e-05, Training time:24970.104091644287
batch reward last col mean 3.641203511506319e-05 first col mean 5.871066605322994e-05 all mean 8.893440099200234e-05
3.916819332516752e-05 3.9168189687188715e-05
rl training, epoch1, iter0, batch663/1133, batch loss:3.9168189687188715e-05, Training time:24987.178203582764
batch reward last col mean 3.5893999665859155e-06 first col mean 0.0012232426088303328 all mean 5.621724631055258e-05
4.0964594518300146e-05 4.0964594518300146e-05
rl training, epoch1, iter0, batch664/1133, batch loss:4.0964594518300146e-05, Training time:25004.358546972275
batch reward last col mean 0.007416022941470146 first col mean 9.093526387005113e-06 all mean 0.006935165263712406
0.0005337393959052861 0.0005337393959052861
rl training, epoch1, iter0, batch665/1133, batch loss:0.0005337393959052861, Training time:25021.375777244568
batch reward last col mean 1.4450190064962953e-05 first col mean 0.0011788412230089307 all mean 5.59702493774239e-05
5.5544696806464344e-05 5.554470408242196e-05
rl training, epoch1, iter0, batch666/1133, batch loss:5.554470408242196e-05, Training time:25038.427188396454
batch reward last col mean 0.0014190126676112413 first col mean 0.0019101881189271808 all mean 0.0012686668196693063
0.000147537502925843 0.000147537502925843
rl training, epoch1, iter0, batch667/1133, batch loss:0.000147537502925843, Training time:25055.398054122925
batch reward last col mean 0.00017188518540933728 first col mean 4.508977781370049e-06 all mean 0.0001977853535208851
0.00045732842409051955 0.0004573283949866891
rl training, epoch1, iter0, batch668/1133, batch loss:0.0004573283949866891, Training time:25072.73104453087
batch reward last col mean 6.673390089417808e-06 first col mean 0.0010730696376413107 all mean 0.00012439268175512552
0.0002764227974694222 0.0002764227974694222
rl training, epoch1, iter0, batch669/1133, batch loss:0.0002764227974694222, Training time:25090.009900808334
batch reward last col mean 0.00044928709394298494 first col mean 3.3961025565076852e-06 all mean 0.0004206992161925882
7.65595177654177e-05 7.65595177654177e-05
rl training, epoch1, iter0, batch670/1133, batch loss:7.65595177654177e-05, Training time:25108.988007068634
batch reward last col mean 2.2523183361045085e-05 first col mean 9.651132859289646e-05 all mean 8.854983752826229e-05
9.778945241123438e-05 9.778946696314961e-05
rl training, epoch1, iter0, batch671/1133, batch loss:9.778946696314961e-05, Training time:25126.01027417183
batch reward last col mean 0.0005174889811314642 first col mean 8.856942486090702e-07 all mean 0.0004917040932923555
0.00010151416063308716 0.00010151415335712954
rl training, epoch1, iter0, batch672/1133, batch loss:0.00010151415335712954, Training time:25143.1953060627
batch reward last col mean 0.00021835094958078116 first col mean 2.2308975076157367e-06 all mean 0.0001525805564597249
7.874405855545774e-05 7.874405855545774e-05
rl training, epoch1, iter0, batch673/1133, batch loss:7.874405855545774e-05, Training time:25160.331270694733
batch reward last col mean 5.7920606195693836e-05 first col mean 1.7565358575666323e-05 all mean 0.00010014379950007424
6.0320024203974754e-05 6.0320024203974754e-05
rl training, epoch1, iter0, batch674/1133, batch loss:6.0320024203974754e-05, Training time:25177.369149684906
batch reward last col mean 0.0001091605590772815 first col mean 2.651180147950072e-05 all mean 9.79181204456836e-05
9.313019108958542e-05 9.313019836554304e-05
rl training, epoch1, iter0, batch675/1133, batch loss:9.313019836554304e-05, Training time:25194.306385040283
batch reward last col mean 5.130186195856368e-07 first col mean 2.0383388346090214e-06 all mean 6.197329639689997e-05
9.413956286152825e-05 9.413956286152825e-05
rl training, epoch1, iter0, batch676/1133, batch loss:9.413956286152825e-05, Training time:25211.47040081024
batch reward last col mean 0.0004699557030107826 first col mean 5.3279651183402166e-05 all mean 0.00046643873793073
7.408894452964887e-05 7.408895180560648e-05
rl training, epoch1, iter0, batch677/1133, batch loss:7.408895180560648e-05, Training time:25228.481441497803
batch reward last col mean 0.0001300852745771408 first col mean 0.0006365606095641851 all mean 9.522210893919691e-05
0.00013015330478083342 0.00013015331933274865
rl training, epoch1, iter0, batch678/1133, batch loss:0.00013015331933274865, Training time:25245.452901124954
batch reward last col mean 0.0029417029581964016 first col mean 0.0005161894951015711 all mean 0.0025565980467945337
0.00018685462418943644 0.00018685463874135166
rl training, epoch1, iter0, batch679/1133, batch loss:0.00018685463874135166, Training time:25262.39980363846
batch reward last col mean 1.0516927432036027e-05 first col mean 8.300601621158421e-05 all mean 2.9635959435836412e-05
2.8800803193007596e-05 2.8800801374018192e-05
rl training, epoch1, iter0, batch680/1133, batch loss:2.8800801374018192e-05, Training time:25279.391119003296
batch reward last col mean 0.007523698266595602 first col mean 3.905165613105055e-06 all mean 0.007132373750209808
0.000277678482234478 0.00027767851133830845
rl training, epoch1, iter0, batch681/1133, batch loss:0.00027767851133830845, Training time:25296.550775051117
batch reward last col mean 3.2864772947505116e-05 first col mean 0.00038692879024893045 all mean 5.597653944278136e-05
2.4738659703871235e-05 2.4738654246903025e-05
rl training, epoch1, iter0, batch682/1133, batch loss:2.4738654246903025e-05, Training time:25314.606645345688
batch reward last col mean 0.00016977784980554134 first col mean 0.00014558683324139565 all mean 9.700340160634369e-05
3.1141858926275745e-05 3.114186620223336e-05
rl training, epoch1, iter0, batch683/1133, batch loss:3.114186620223336e-05, Training time:25333.647110939026
batch reward last col mean 4.4081508576709894e-07 first col mean 0.00023943294945638627 all mean 8.443790284218267e-05
0.0001461317588109523 0.0001461317588109523
rl training, epoch1, iter0, batch684/1133, batch loss:0.0001461317588109523, Training time:25350.697513341904
batch reward last col mean 5.7758465118240565e-05 first col mean 6.3417587625735905e-06 all mean 4.3168220145162195e-05
9.195329039357603e-05 9.195328311761841e-05
rl training, epoch1, iter0, batch685/1133, batch loss:9.195328311761841e-05, Training time:25367.809181690216
batch reward last col mean 0.00042395744821988046 first col mean 1.1530606798260123e-06 all mean 0.0002287567622261122
0.00012763244740199298 0.0001276324619539082
rl training, epoch1, iter0, batch686/1133, batch loss:0.0001276324619539082, Training time:25384.82574248314
batch reward last col mean 5.178402489036671e-07 first col mean 6.214275799720781e-06 all mean 1.85091466846643e-05
1.7357526303385384e-05 1.7357528122374788e-05
rl training, epoch1, iter0, batch687/1133, batch loss:1.7357528122374788e-05, Training time:25401.91880106926
batch reward last col mean 2.341117664172998e-07 first col mean 1.76489120349288e-05 all mean 1.5141885342018213e-05
9.490862794336863e-06 9.490862794336863e-06
rl training, epoch1, iter0, batch688/1133, batch loss:9.490862794336863e-06, Training time:25418.98643064499
batch reward last col mean 0.00046241594827733934 first col mean 6.287804717430845e-05 all mean 0.0002594393736217171
0.00021382994600571692 0.00021382994600571692
rl training, epoch1, iter0, batch689/1133, batch loss:0.00021382994600571692, Training time:25436.07616996765
batch reward last col mean 1.0007259334088303e-05 first col mean 3.663198367576115e-05 all mean 9.713356121210381e-05
0.00010247328464174643 0.00010247328464174643
rl training, epoch1, iter0, batch690/1133, batch loss:0.00010247328464174643, Training time:25453.03782892227
batch reward last col mean 6.033174031472299e-07 first col mean 7.98546097939834e-05 all mean 4.0106591768562794e-05
0.0001112879763240926 0.0001112879763240926
rl training, epoch1, iter0, batch691/1133, batch loss:0.0001112879763240926, Training time:25470.1990981102
batch reward last col mean 3.949659367208369e-05 first col mean 1.0651608135958668e-05 all mean 3.33944772137329e-05
6.611839489778504e-05 6.611839489778504e-05
rl training, epoch1, iter0, batch692/1133, batch loss:6.611839489778504e-05, Training time:25488.713079690933
batch reward last col mean 8.043009529501433e-07 first col mean 7.954366083140485e-06 all mean 5.740007691201754e-05
3.440174623392522e-05 3.4401757147861645e-05
rl training, epoch1, iter0, batch693/1133, batch loss:3.4401757147861645e-05, Training time:25505.893572330475
batch reward last col mean 4.643220563593786e-06 first col mean 0.0001484650420024991 all mean 1.4752381503058132e-05
9.224097084370442e-06 9.224097084370442e-06
rl training, epoch1, iter0, batch694/1133, batch loss:9.224097084370442e-06, Training time:25523.156732320786
batch reward last col mean 5.1408431318122894e-05 first col mean 1.7197085071529727e-06 all mean 5.489783870871179e-05
3.8467034755740315e-05 3.846703839371912e-05
rl training, epoch1, iter0, batch695/1133, batch loss:3.846703839371912e-05, Training time:25540.402546167374
batch reward last col mean 0.0016097211046144366 first col mean 4.9452246457803994e-06 all mean 0.0011294998694211245
0.0003425580507609993 0.0003425580507609993
rl training, epoch1, iter0, batch696/1133, batch loss:0.0003425580507609993, Training time:25557.48258805275
batch reward last col mean 0.0012534253764897585 first col mean 3.4554414014564827e-06 all mean 0.0010851676343008876
0.00017142220167443156 0.00017142220167443156
rl training, epoch1, iter0, batch697/1133, batch loss:0.00017142220167443156, Training time:25574.744991779327
batch reward last col mean 1.2245209290995263e-06 first col mean 6.24928679826553e-06 all mean 4.320816515246406e-05
3.474028562777676e-05 3.474028198979795e-05
rl training, epoch1, iter0, batch698/1133, batch loss:3.474028198979795e-05, Training time:25592.048432826996
batch reward last col mean 6.708726868964732e-05 first col mean 4.78068341180915e-06 all mean 0.00010067555558634922
3.7281632103258744e-05 3.728162846527994e-05
rl training, epoch1, iter0, batch699/1133, batch loss:3.728162846527994e-05, Training time:25608.97437286377
batch reward last col mean 3.5113669127895264e-07 first col mean 0.0018813912756741047 all mean 8.024513954296708e-05
0.00018835543596651405 0.00018835543596651405
rl training, epoch1, iter0, batch700/1133, batch loss:0.00018835543596651405, Training time:25626.104679346085
batch reward last col mean 0.005892617627978325 first col mean 7.215156529127853e-06 all mean 0.004972606897354126
0.0005185240297578275 0.0005185240297578275
rl training, epoch1, iter0, batch701/1133, batch loss:0.0005185240297578275, Training time:25643.241483926773
batch reward last col mean 0.00017189107893500477 first col mean 7.54194275032205e-07 all mean 0.00020554184447973967
0.00013721662980969995 0.00013721661525778472
rl training, epoch1, iter0, batch702/1133, batch loss:0.00013721661525778472, Training time:25662.133985042572
batch reward last col mean 3.8747560893170885e-07 first col mean 3.1127197871683165e-05 all mean 4.5243115891935304e-05
5.982195580145344e-05 5.982195943943225e-05
rl training, epoch1, iter0, batch703/1133, batch loss:5.982195943943225e-05, Training time:25681.140281677246
batch reward last col mean 9.882822951112757e-07 first col mean 0.0007223750581033528 all mean 7.423044735332951e-05
0.00010762263991637155 0.00010762263264041394
rl training, epoch1, iter0, batch704/1133, batch loss:0.00010762263264041394, Training time:25698.279601812363
batch reward last col mean 5.5671462177997455e-06 first col mean 0.0005939777474850416 all mean 3.788277899730019e-05
9.066015627468005e-05 9.066015627468005e-05
rl training, epoch1, iter0, batch705/1133, batch loss:9.066015627468005e-05, Training time:25715.485743284225
batch reward last col mean 6.907544957357459e-06 first col mean 3.33401512762066e-05 all mean 7.407217344734818e-05
0.00024132334510795772 0.00024132334510795772
rl training, epoch1, iter0, batch706/1133, batch loss:0.00024132334510795772, Training time:25733.446437358856
batch reward last col mean 4.596230064635165e-05 first col mean 0.0005340193747542799 all mean 5.420801608124748e-05
6.196840695338324e-05 6.196840695338324e-05
rl training, epoch1, iter0, batch707/1133, batch loss:6.196840695338324e-05, Training time:25750.503194332123
batch reward last col mean 1.0983780157403089e-05 first col mean 0.00025788156199268997 all mean 5.623319884762168e-05
0.0001086364864022471 0.00010863646457437426
rl training, epoch1, iter0, batch708/1133, batch loss:0.00010863646457437426, Training time:25767.459953069687
batch reward last col mean 0.00011461562826298177 first col mean 7.0639498517266475e-06 all mean 5.764432717114687e-05
6.334841600619256e-05 6.334840873023495e-05
rl training, epoch1, iter0, batch709/1133, batch loss:6.334840873023495e-05, Training time:25784.67571592331
batch reward last col mean 6.473400389950257e-06 first col mean 0.0016627069562673569 all mean 5.7395991461817175e-05
0.00011441924289101735 0.00011441924289101735
rl training, epoch1, iter0, batch710/1133, batch loss:0.00011441924289101735, Training time:25801.70313835144
batch reward last col mean 1.687961230345536e-05 first col mean 1.872474058473017e-05 all mean 3.5917135392082855e-05
2.126542676705867e-05 2.126542676705867e-05
rl training, epoch1, iter0, batch711/1133, batch loss:2.126542676705867e-05, Training time:25819.940212249756
batch reward last col mean 6.063291039026808e-06 first col mean 1.5322797480621375e-05 all mean 5.2029463404323906e-05
9.582022903487086e-05 9.582022903487086e-05
rl training, epoch1, iter0, batch712/1133, batch loss:9.582022903487086e-05, Training time:25836.95312857628
batch reward last col mean 1.0051250683318358e-05 first col mean 4.128093860344961e-05 all mean 3.24750471918378e-05
7.408620149362832e-05 7.408620149362832e-05
rl training, epoch1, iter0, batch713/1133, batch loss:7.408620149362832e-05, Training time:25854.11978816986
batch reward last col mean 7.347421728809422e-07 first col mean 0.0005682461196556687 all mean 8.455945499008521e-05
0.00021687117987312376 0.00021687117987312376
rl training, epoch1, iter0, batch714/1133, batch loss:0.00021687117987312376, Training time:25871.077898979187
batch reward last col mean 9.161195521301124e-06 first col mean 2.15198342630174e-05 all mean 5.9172958572162315e-05
7.284583989530802e-05 7.284584717126563e-05
rl training, epoch1, iter0, batch715/1133, batch loss:7.284584717126563e-05, Training time:25888.0099234581
batch reward last col mean 3.3736384921212448e-06 first col mean 5.185983172850683e-05 all mean 3.910640953108668e-05
4.690816058428027e-05 4.690816058428027e-05
rl training, epoch1, iter0, batch716/1133, batch loss:4.690816058428027e-05, Training time:25904.970752716064
batch reward last col mean 0.0005704606301151216 first col mean 4.94613823320833e-06 all mean 0.00011141323193442076
9.914710972225294e-05 9.914710972225294e-05
rl training, epoch1, iter0, batch717/1133, batch loss:9.914710972225294e-05, Training time:25922.238047122955
batch reward last col mean 1.1626770174189005e-05 first col mean 1.2653641533688642e-05 all mean 0.0001998748048208654
0.00029098332743160427 0.0002909833565354347
rl training, epoch1, iter0, batch718/1133, batch loss:0.0002909833565354347, Training time:25939.412304401398
batch reward last col mean 1.1073417226725724e-05 first col mean 0.0009291345486417413 all mean 4.4378641177900136e-05
4.711246583610773e-05 4.7112462198128924e-05
rl training, epoch1, iter0, batch719/1133, batch loss:4.7112462198128924e-05, Training time:25957.560516357422
batch reward last col mean 5.6644887081347406e-05 first col mean 4.260428795532789e-06 all mean 4.246573007549159e-05
6.523190677398816e-05 6.523190677398816e-05
rl training, epoch1, iter0, batch720/1133, batch loss:6.523190677398816e-05, Training time:25974.54358458519
batch reward last col mean 1.6303862366839894e-06 first col mean 0.0003274009213782847 all mean 5.4224183259066194e-05
0.00010168933658860624 0.00010168934386456385
rl training, epoch1, iter0, batch721/1133, batch loss:0.00010168934386456385, Training time:25991.552079439163
batch reward last col mean 1.3972085071145557e-06 first col mean 5.159515694685979e-06 all mean 2.8272817871766165e-05
3.580908742151223e-05 3.5809094697469845e-05
rl training, epoch1, iter0, batch722/1133, batch loss:3.5809094697469845e-05, Training time:26009.087022781372
batch reward last col mean 0.0002100415003951639 first col mean 0.00015689025167375803 all mean 0.00023823024821467698
0.00020193915406707674 0.00020193913951516151
rl training, epoch1, iter0, batch723/1133, batch loss:0.00020193913951516151, Training time:26028.002851963043
batch reward last col mean 1.004818932415219e-05 first col mean 0.0003333817876409739 all mean 0.00011674770212266594
0.00017206672055181116 0.00017206670599989593
rl training, epoch1, iter0, batch724/1133, batch loss:0.00017206670599989593, Training time:26045.078258514404
batch reward last col mean 0.0047858236357569695 first col mean 8.199898729799315e-06 all mean 0.004450384993106127
0.0003872952947858721 0.00038729526568204165
rl training, epoch1, iter0, batch725/1133, batch loss:0.00038729526568204165, Training time:26062.224246025085
batch reward last col mean 1.1180131878063548e-05 first col mean 2.1850664779776707e-06 all mean 5.7945413573179394e-05
5.297744064591825e-05 5.297744428389706e-05
rl training, epoch1, iter0, batch726/1133, batch loss:5.297744428389706e-05, Training time:26079.361023187637
batch reward last col mean 2.529806806705892e-05 first col mean 2.642210165504366e-05 all mean 8.704901119926944e-05
0.00021285723778419197 0.0002128572523361072
rl training, epoch1, iter0, batch727/1133, batch loss:0.0002128572523361072, Training time:26096.533377170563
batch reward last col mean 8.54545651236549e-05 first col mean 1.1200769222341478e-05 all mean 9.829473856370896e-05
4.33961431554053e-05 4.33961431554053e-05
rl training, epoch1, iter0, batch728/1133, batch loss:4.33961431554053e-05, Training time:26113.653845071793
batch reward last col mean 1.3906216736359056e-05 first col mean 6.473631856351858e-06 all mean 3.836017640423961e-05
2.7155427233083174e-05 2.715542541409377e-05
rl training, epoch1, iter0, batch729/1133, batch loss:2.715542541409377e-05, Training time:26130.637461423874
batch reward last col mean 2.844778350663546e-07 first col mean 6.3474421040155e-05 all mean 4.9581176426727325e-05
4.2005944123957306e-05 4.20059404859785e-05
rl training, epoch1, iter0, batch730/1133, batch loss:4.20059404859785e-05, Training time:26147.754732131958
batch reward last col mean 1.8533788761487813e-06 first col mean 3.3966494811465964e-05 all mean 3.930635648430325e-05
6.908701470820233e-05 6.908701470820233e-05
rl training, epoch1, iter0, batch731/1133, batch loss:6.908701470820233e-05, Training time:26164.795871019363
batch reward last col mean 1.995894308493007e-05 first col mean 1.932329723786097e-05 all mean 3.402062429813668e-05
4.1415882151341066e-05 4.1415882151341066e-05
rl training, epoch1, iter0, batch732/1133, batch loss:4.1415882151341066e-05, Training time:26181.95414042473
batch reward last col mean 0.00015506159979850054 first col mean 0.00021788806770928204 all mean 0.00019164037075825036
7.734804967185482e-05 7.73480351199396e-05
rl training, epoch1, iter0, batch733/1133, batch loss:7.73480351199396e-05, Training time:26199.108268260956
batch reward last col mean 8.835790140437894e-06 first col mean 0.00103615946136415 all mean 0.00011274078133283183
0.00025448057567700744 0.00025448057567700744
rl training, epoch1, iter0, batch734/1133, batch loss:0.00025448057567700744, Training time:26217.92537999153
batch reward last col mean 2.1850546545465477e-05 first col mean 0.0008958462276495993 all mean 8.122282451950014e-05
0.00018053516396321356 0.00018053516396321356
rl training, epoch1, iter0, batch735/1133, batch loss:0.00018053516396321356, Training time:26235.897406816483
batch reward last col mean 2.5559558025634033e-07 first col mean 0.0007143666152842343 all mean 6.959509482840076e-05
7.131360325729474e-05 7.131360325729474e-05
rl training, epoch1, iter0, batch736/1133, batch loss:7.131360325729474e-05, Training time:26253.092483520508
batch reward last col mean 7.778678991599008e-06 first col mean 0.0029686172492802143 all mean 0.00013108389975968748
5.566292747971602e-05 5.566290928982198e-05
rl training, epoch1, iter0, batch737/1133, batch loss:5.566290928982198e-05, Training time:26270.221330165863
batch reward last col mean 6.337635568343103e-05 first col mean 1.1367878869350534e-05 all mean 8.512258500559255e-05
7.55432338337414e-05 7.554324110969901e-05
rl training, epoch1, iter0, batch738/1133, batch loss:7.554324110969901e-05, Training time:26287.633266210556
batch reward last col mean 2.9762998110527406e-07 first col mean 4.239336703903973e-05 all mean 4.0431910747429356e-05
9.552812116453424e-05 9.552811388857663e-05
rl training, epoch1, iter0, batch739/1133, batch loss:9.552811388857663e-05, Training time:26306.391204357147
batch reward last col mean 1.9942908124903624e-07 first col mean 0.001074236468411982 all mean 5.8492994867265224e-05
7.836481381673366e-05 7.836482109269127e-05
rl training, epoch1, iter0, batch740/1133, batch loss:7.836482109269127e-05, Training time:26323.388845205307
batch reward last col mean 9.690808838058729e-06 first col mean 0.0003716613573487848 all mean 0.00010958123311866075
0.0002566389157436788 0.0002566389157436788
rl training, epoch1, iter0, batch741/1133, batch loss:0.0002566389157436788, Training time:26340.525329351425
batch reward last col mean 8.24658854980953e-06 first col mean 0.00024190807016566396 all mean 4.248322147759609e-05
5.803806925541721e-05 5.803806925541721e-05
rl training, epoch1, iter0, batch742/1133, batch loss:5.803806925541721e-05, Training time:26358.81410241127
batch reward last col mean 0.00024033867521211505 first col mean 1.3375389244174585e-05 all mean 0.0002244821225758642
7.687939796596766e-05 7.687939796596766e-05
rl training, epoch1, iter0, batch743/1133, batch loss:7.687939796596766e-05, Training time:26377.218035697937
batch reward last col mean 1.5780070725668338e-06 first col mean 8.554142550565302e-05 all mean 3.907010250259191e-05
8.554304804420099e-05 8.554304804420099e-05
rl training, epoch1, iter0, batch744/1133, batch loss:8.554304804420099e-05, Training time:26395.409724473953
batch reward last col mean 0.0003570622648112476 first col mean 1.947683995240368e-05 all mean 0.00017203536117449403
0.00011650186934275553 0.00011650186934275553
rl training, epoch1, iter0, batch745/1133, batch loss:0.00011650186934275553, Training time:26412.118596076965
batch reward last col mean 0.00019445329962763935 first col mean 2.6848096240428276e-05 all mean 0.0002206062345067039
5.4152118536876515e-05 5.415212217485532e-05
rl training, epoch1, iter0, batch746/1133, batch loss:5.415212217485532e-05, Training time:26428.925485372543
batch reward last col mean 0.0038109547458589077 first col mean 1.0451647085574223e-06 all mean 0.003500875551253557
0.0005164561443962157 0.0005164561443962157
rl training, epoch1, iter0, batch747/1133, batch loss:0.0005164561443962157, Training time:26445.72943711281
batch reward last col mean 6.991644454501511e-07 first col mean 2.6486539354664274e-05 all mean 4.011975761386566e-05
2.984533057315275e-05 2.984533057315275e-05
rl training, epoch1, iter0, batch748/1133, batch loss:2.984533057315275e-05, Training time:26463.74164867401
batch reward last col mean 1.5386411860163207e-06 first col mean 2.2088777768658474e-05 all mean 3.803216895903461e-05
0.00012044861796312034 0.00012044861796312034
rl training, epoch1, iter0, batch749/1133, batch loss:0.00012044861796312034, Training time:26482.07064652443
batch reward last col mean 1.4088584066485055e-05 first col mean 4.289042408345267e-06 all mean 4.6388675400521606e-05
3.38011268468108e-05 3.38011268468108e-05
rl training, epoch1, iter0, batch750/1133, batch loss:3.38011268468108e-05, Training time:26500.361463546753
batch reward last col mean 0.00011569668276933953 first col mean 1.8718965293373913e-05 all mean 5.154098471393809e-05
4.3710271711461246e-05 4.371027534944005e-05
rl training, epoch1, iter0, batch751/1133, batch loss:4.371027534944005e-05, Training time:26516.94428920746
batch reward last col mean 1.404261274728924e-05 first col mean 1.5116168469830882e-05 all mean 7.411224214592949e-05
0.00012816510570701212 0.00012816510570701212
rl training, epoch1, iter0, batch752/1133, batch loss:0.00012816510570701212, Training time:26533.41056227684
batch reward last col mean 3.311441105324775e-05 first col mean 0.0015712814638391137 all mean 0.0001062297378666699
0.00010050180571852252 0.00010050182027043775
rl training, epoch1, iter0, batch753/1133, batch loss:0.00010050182027043775, Training time:26550.35880470276
batch reward last col mean 0.00021195359295234084 first col mean 9.286140993935987e-06 all mean 0.00021858866966795176
0.00021898254635743797 0.00021898254635743797
rl training, epoch1, iter0, batch754/1133, batch loss:0.00021898254635743797, Training time:26566.923635959625
batch reward last col mean 1.1303482096991502e-06 first col mean 7.582251328130951e-06 all mean 4.2967189074261114e-05
3.997394742327742e-05 3.997395106125623e-05
rl training, epoch1, iter0, batch755/1133, batch loss:3.997395106125623e-05, Training time:26583.425766706467
batch reward last col mean 8.715589387975342e-07 first col mean 0.00018866645405068994 all mean 8.445095591014251e-05
0.00013971859880257398 0.00013971858425065875
rl training, epoch1, iter0, batch756/1133, batch loss:0.00013971858425065875, Training time:26599.96223282814
batch reward last col mean 4.33683926530648e-05 first col mean 4.529793659457937e-05 all mean 8.573236118536443e-05
4.731385342893191e-05 4.731386070488952e-05
rl training, epoch1, iter0, batch757/1133, batch loss:4.731386070488952e-05, Training time:26616.692620515823
batch reward last col mean 2.7804355795524316e-06 first col mean 2.2801255909143947e-05 all mean 5.8753172197612e-05
7.012616697466001e-05 7.012617425061762e-05
rl training, epoch1, iter0, batch758/1133, batch loss:7.012617425061762e-05, Training time:26633.265285253525
batch reward last col mean 0.00041197723476216197 first col mean 6.525868957396597e-05 all mean 0.00038133878842927516
8.477402298012748e-05 8.477400842821226e-05
rl training, epoch1, iter0, batch759/1133, batch loss:8.477400842821226e-05, Training time:26649.88026881218
batch reward last col mean 2.49743607128039e-07 first col mean 2.8851793103967793e-05 all mean 0.0001020605704979971
0.00014519350952468812 0.00014519350952468812
rl training, epoch1, iter0, batch760/1133, batch loss:0.00014519350952468812, Training time:26666.63144636154
batch reward last col mean 9.776407750905491e-06 first col mean 2.7553312975214794e-05 all mean 6.60555888316594e-05
5.99245322518982e-05 5.992454316583462e-05
rl training, epoch1, iter0, batch761/1133, batch loss:5.992454316583462e-05, Training time:26683.472500562668
batch reward last col mean 0.00020316534209996462 first col mean 0.0001488051057094708 all mean 8.858955698087811e-05
0.00018911901861429214 0.00018911901861429214
rl training, epoch1, iter0, batch762/1133, batch loss:0.00018911901861429214, Training time:26701.527931451797
batch reward last col mean 2.458416474837577e-06 first col mean 0.0002343328669667244 all mean 6.940439197933301e-05
0.00018738911603577435 0.00018738910148385912
rl training, epoch1, iter0, batch763/1133, batch loss:0.00018738910148385912, Training time:26719.953181028366
batch reward last col mean 8.801083595244563e-07 first col mean 6.007218689774163e-05 all mean 3.2860447390703484e-05
2.969348497572355e-05 2.9693488613702357e-05
rl training, epoch1, iter0, batch764/1133, batch loss:2.9693488613702357e-05, Training time:26737.310472726822
batch reward last col mean 6.197886978043243e-05 first col mean 0.00016399276501033455 all mean 0.00011321055353619158
0.00012080349551979452 0.00012080348824383691
rl training, epoch1, iter0, batch765/1133, batch loss:0.00012080348824383691, Training time:26754.231937885284
batch reward last col mean 5.675612555933185e-06 first col mean 3.483593536657281e-05 all mean 7.819844176992774e-05
0.0001994212798308581 0.00019942129438277334
rl training, epoch1, iter0, batch766/1133, batch loss:0.00019942129438277334, Training time:26771.421676158905
batch reward last col mean 6.306810291789589e-07 first col mean 1.6030035112635233e-05 all mean 7.320666190935299e-05
4.3751202611019835e-05 4.3751188059104607e-05
rl training, epoch1, iter0, batch767/1133, batch loss:4.3751188059104607e-05, Training time:26789.888510227203
batch reward last col mean 1.8577451328383177e-06 first col mean 5.280806362861767e-06 all mean 7.609448221046478e-05
0.00016128411516547203 0.00016128411516547203
rl training, epoch1, iter0, batch768/1133, batch loss:0.00016128411516547203, Training time:26806.480920791626
batch reward last col mean 2.0235684132785536e-05 first col mean 0.000128241372294724 all mean 9.037771815201268e-05
0.00039507466135546565 0.00039507466135546565
rl training, epoch1, iter0, batch769/1133, batch loss:0.00039507466135546565, Training time:26823.079068899155
batch reward last col mean 9.876492867988418e-07 first col mean 0.002029893919825554 all mean 7.661182462470606e-05
0.00010430205293232575 0.00010430206020828336
rl training, epoch1, iter0, batch770/1133, batch loss:0.00010430206020828336, Training time:26839.688835144043
batch reward last col mean 0.0004154617781750858 first col mean 0.0005534035735763609 all mean 0.00041372753912582994
0.00012316116772126406 0.0001231611822731793
rl training, epoch1, iter0, batch771/1133, batch loss:0.0001231611822731793, Training time:26856.304094552994
batch reward last col mean 1.1039139735657955e-06 first col mean 0.00018409619224257767 all mean 8.757410250836983e-05
0.00014187236956786364 0.00014187234046403319
rl training, epoch1, iter0, batch772/1133, batch loss:0.00014187234046403319, Training time:26872.96877360344
batch reward last col mean 0.00766212772578001 first col mean 4.7558256483171135e-05 all mean 0.007144399918615818
0.00047660773270763457 0.00047660773270763457
rl training, epoch1, iter0, batch773/1133, batch loss:0.00047660773270763457, Training time:26889.763052225113
batch reward last col mean 1.8291582819074392e-05 first col mean 5.7938919781008735e-05 all mean 9.635713649913669e-05
0.00010261309944326058 0.00010261311399517581
rl training, epoch1, iter0, batch774/1133, batch loss:0.00010261311399517581, Training time:26908.159048080444
batch reward last col mean 1.3718229638470802e-05 first col mean 0.0013519786298274994 all mean 8.611619705334306e-05
0.00013025371299590915 0.00013025369844399393
rl training, epoch1, iter0, batch775/1133, batch loss:0.00013025369844399393, Training time:26926.57988190651
batch reward last col mean 3.2983093660732266e-06 first col mean 0.0002539863926358521 all mean 7.865532097639516e-05
0.00014445645501837134 0.00014445645501837134
rl training, epoch1, iter0, batch776/1133, batch loss:0.00014445645501837134, Training time:26945.020077705383
batch reward last col mean 2.0032970496686175e-05 first col mean 4.271810394129716e-05 all mean 5.8798024838324636e-05
9.819032857194543e-05 9.819032857194543e-05
rl training, epoch1, iter0, batch777/1133, batch loss:9.819032857194543e-05, Training time:26961.767283201218
batch reward last col mean 6.771647349523846e-06 first col mean 6.462313467636704e-05 all mean 4.1452371078776196e-05
8.017418440431356e-05 8.017418440431356e-05
rl training, epoch1, iter0, batch778/1133, batch loss:8.017418440431356e-05, Training time:26978.361815929413
batch reward last col mean 0.00012668300769291818 first col mean 0.00014646672934759408 all mean 0.0001531280722701922
9.593692084308714e-05 9.593692084308714e-05
rl training, epoch1, iter0, batch779/1133, batch loss:9.593692084308714e-05, Training time:26994.70095682144
batch reward last col mean 4.3861362541974813e-07 first col mean 0.00023649403010495007 all mean 7.795265992172062e-05
0.0001676091633271426 0.0001676091633271426
rl training, epoch1, iter0, batch780/1133, batch loss:0.0001676091633271426, Training time:27010.972935914993
batch reward last col mean 9.426345968677197e-06 first col mean 1.5298506696126424e-05 all mean 0.00011265779903624207
0.0002735939924605191 0.0002735939924605191
rl training, epoch1, iter0, batch781/1133, batch loss:0.0002735939924605191, Training time:27027.243377923965
batch reward last col mean 4.093813549843617e-05 first col mean 5.169445103092585e-06 all mean 0.00011767951218644157
0.0004779933951795101 0.00047799336607567966
rl training, epoch1, iter0, batch782/1133, batch loss:0.00047799336607567966, Training time:27043.452213525772
batch reward last col mean 0.00023047151626087725 first col mean 7.461382210749434e-06 all mean 0.0003281336394138634
0.00027443532599136233 0.00027443538419902325
rl training, epoch1, iter0, batch783/1133, batch loss:0.00027443538419902325, Training time:27059.676906108856
batch reward last col mean 0.00014448066940531135 first col mean 4.248763434588909e-05 all mean 0.00012776028597727418
0.0003103881317656487 0.0003103881317656487
rl training, epoch1, iter0, batch784/1133, batch loss:0.0003103881317656487, Training time:27076.033318519592
batch reward last col mean 1.5198462278931402e-05 first col mean 5.511020390258636e-06 all mean 4.6907924115657806e-05
3.710127930389717e-05 3.710127930389717e-05
rl training, epoch1, iter0, batch785/1133, batch loss:3.710127930389717e-05, Training time:27092.246814727783
batch reward last col mean 1.4920489775249735e-05 first col mean 2.7242867872701026e-05 all mean 3.3826916478574276e-05
5.2492960094241425e-05 5.2492960094241425e-05
rl training, epoch1, iter0, batch786/1133, batch loss:5.2492960094241425e-05, Training time:27108.61619400978
batch reward last col mean 3.807310713455081e-05 first col mean 3.047324571525678e-05 all mean 0.0001692771475063637
0.00041784532368183136 0.0004178453527856618
rl training, epoch1, iter0, batch787/1133, batch loss:0.0004178453527856618, Training time:27124.907398939133
batch reward last col mean 0.0005357467452995479 first col mean 1.9321380023029633e-05 all mean 0.00022757983242627233
0.00026705829077400267 0.00026705829077400267
rl training, epoch1, iter0, batch788/1133, batch loss:0.00026705829077400267, Training time:27141.136152505875
batch reward last col mean 3.7430131669680122e-06 first col mean 3.108768578385934e-05 all mean 6.826304161222652e-05
5.518355465028435e-05 5.518355101230554e-05
rl training, epoch1, iter0, batch789/1133, batch loss:5.518355101230554e-05, Training time:27159.423149108887
batch reward last col mean 6.97648999903322e-07 first col mean 0.001483711414039135 all mean 2.7235870220465586e-05
0.0001306663325522095 0.0001306663325522095
rl training, epoch1, iter0, batch790/1133, batch loss:0.0001306663325522095, Training time:27176.369623184204
batch reward last col mean 1.2852048712375108e-05 first col mean 1.648098759687855e-06 all mean 5.604302714345977e-05
5.605156911769882e-05 5.60515582037624e-05
rl training, epoch1, iter0, batch791/1133, batch loss:5.60515582037624e-05, Training time:27193.678837537766
batch reward last col mean 1.4536707567458507e-05 first col mean 0.0005332209402695298 all mean 4.947564593749121e-05
0.0002185496559832245 0.00021854967053513974
rl training, epoch1, iter0, batch792/1133, batch loss:0.00021854967053513974, Training time:27210.782017469406
batch reward last col mean 2.0540306650218554e-05 first col mean 0.0006880927248857915 all mean 6.939256127225235e-05
3.709717930178158e-05 3.7097186577739194e-05
rl training, epoch1, iter0, batch793/1133, batch loss:3.7097186577739194e-05, Training time:27227.452073335648
batch reward last col mean 3.2451815059175715e-05 first col mean 0.002139253308996558 all mean 8.31924335216172e-05
5.010673339711502e-05 5.010673339711502e-05
rl training, epoch1, iter0, batch794/1133, batch loss:5.010673339711502e-05, Training time:27245.968015670776
batch reward last col mean 8.217351569328457e-05 first col mean 5.791578223579563e-05 all mean 4.314497346058488e-05
0.00012932080426253378 0.00012932080426253378
rl training, epoch1, iter0, batch795/1133, batch loss:0.00012932080426253378, Training time:27263.65006494522
batch reward last col mean 2.939512569355429e-06 first col mean 1.7682741599855945e-05 all mean 5.800417056889273e-05
2.846786446752958e-05 2.8467860829550773e-05
rl training, epoch1, iter0, batch796/1133, batch loss:2.8467860829550773e-05, Training time:27280.85303068161
batch reward last col mean 3.611955605720141e-07 first col mean 0.00011793331941589713 all mean 2.391072121099569e-05
4.035473466501571e-05 4.0354731027036905e-05
rl training, epoch1, iter0, batch797/1133, batch loss:4.0354731027036905e-05, Training time:27298.320672035217
batch reward last col mean 9.053263170244463e-07 first col mean 5.666226115863537e-06 all mean 6.828537880210206e-05
0.00017984872101806104 0.0001798487064661458
rl training, epoch1, iter0, batch798/1133, batch loss:0.0001798487064661458, Training time:27315.974431991577
batch reward last col mean 2.2717591491527855e-05 first col mean 3.5451159874355653e-06 all mean 5.3779938752995804e-05
0.00011592200462473556 0.00011592200462473556
rl training, epoch1, iter0, batch799/1133, batch loss:0.00011592200462473556, Training time:27333.410978078842
batch reward last col mean 6.002289865136845e-06 first col mean 7.737682608421892e-06 all mean 5.0190639740321785e-05
2.6590327252051793e-05 2.6590332709020004e-05
rl training, epoch1, iter0, batch800/1133, batch loss:2.6590332709020004e-05, Training time:27350.347241163254
batch reward last col mean 0.00027288065757602453 first col mean 8.266525583167095e-06 all mean 9.321109246229753e-05
0.00017857541388366371 0.00017857541388366371
rl training, epoch1, iter0, batch801/1133, batch loss:0.00017857541388366371, Training time:27368.820023059845
batch reward last col mean 0.0010369145311415195 first col mean 3.262108293711208e-05 all mean 0.0008311744313687086
0.0001292601227760315 0.0001292601227760315
rl training, epoch1, iter0, batch802/1133, batch loss:0.0001292601227760315, Training time:27387.231509923935
batch reward last col mean 1.5916988559183665e-05 first col mean 1.8168198039347772e-06 all mean 3.5151857446180657e-05
8.242295734817162e-05 8.242295734817162e-05
rl training, epoch1, iter0, batch803/1133, batch loss:8.242295734817162e-05, Training time:27406.20770907402
batch reward last col mean 3.2137172638613265e-06 first col mean 3.107966676907381e-06 all mean 5.827052882523276e-05
5.9338592109270394e-05 5.933858483331278e-05
rl training, epoch1, iter0, batch804/1133, batch loss:5.933858483331278e-05, Training time:27424.51638031006
batch reward last col mean 1.3349415439734003e-06 first col mean 0.0012609007535502315 all mean 5.288858665153384e-05
5.876334398635663e-05 5.876334398635663e-05
rl training, epoch1, iter0, batch805/1133, batch loss:5.876334398635663e-05, Training time:27443.43844819069
batch reward last col mean 4.437545430846512e-05 first col mean 3.7603062992275227e-06 all mean 6.135904550319538e-05
0.0001907753321575001 0.0001907753321575001
rl training, epoch1, iter0, batch806/1133, batch loss:0.0001907753321575001, Training time:27460.963351726532
batch reward last col mean 9.550380127620883e-06 first col mean 1.2778446944139432e-05 all mean 6.422236037906259e-05
9.614787995815277e-05 9.614787995815277e-05
rl training, epoch1, iter0, batch807/1133, batch loss:9.614787995815277e-05, Training time:27478.199209690094
batch reward last col mean 3.8272412439255277e-07 first col mean 0.0002473704516887665 all mean 0.00015656727191526443
0.00025938707403838634 0.00025938707403838634
rl training, epoch1, iter0, batch808/1133, batch loss:0.00025938707403838634, Training time:27496.208374023438
batch reward last col mean 0.0016030868282541633 first col mean 3.63546860171482e-05 all mean 0.0007425418589264154
0.00018045744218397886 0.00018045742763206363
rl training, epoch1, iter0, batch809/1133, batch loss:0.00018045742763206363, Training time:27514.65642142296
batch reward last col mean 0.0047524068504571915 first col mean 0.0019688389729708433 all mean 0.004470145795494318
0.0003451902884989977 0.0003451902302913368
rl training, epoch1, iter0, batch810/1133, batch loss:0.0003451902302913368, Training time:27533.696632385254
batch reward last col mean 2.033808868873166e-06 first col mean 1.4086101600696566e-06 all mean 3.291774191893637e-05
3.280051168985665e-05 3.280051168985665e-05
rl training, epoch1, iter0, batch811/1133, batch loss:3.280051168985665e-05, Training time:27550.664498090744
batch reward last col mean 5.054283178651531e-07 first col mean 0.0004901250940747559 all mean 5.4547279432881624e-05
0.00011271140829194337 0.00011271140101598576
rl training, epoch1, iter0, batch812/1133, batch loss:0.00011271140101598576, Training time:27569.567866563797
batch reward last col mean 1.3482818758348003e-05 first col mean 2.029381903412286e-06 all mean 8.769345004111528e-05
0.00018391673802398145 0.00018391675257589668
rl training, epoch1, iter0, batch813/1133, batch loss:0.00018391675257589668, Training time:27589.040807724
batch reward last col mean 0.002150228712707758 first col mean 3.464032124611549e-05 all mean 0.0020385433454066515
0.00023622141452506185 0.00023622141452506185
rl training, epoch1, iter0, batch814/1133, batch loss:0.00023622141452506185, Training time:27608.665283203125
batch reward last col mean 0.0010574526386335492 first col mean 0.0003485753550194204 all mean 0.00010220141848549247
0.0001541854435345158 0.00015418545808643103
rl training, epoch1, iter0, batch815/1133, batch loss:0.00015418545808643103, Training time:27627.338838338852
batch reward last col mean 1.9025719666387886e-05 first col mean 1.9198942027287558e-05 all mean 0.00010896159801632166
0.00018732187163550407 0.0001873218861874193
rl training, epoch1, iter0, batch816/1133, batch loss:0.0001873218861874193, Training time:27645.610260248184
batch reward last col mean 1.66777579124755e-06 first col mean 2.4230814233305864e-05 all mean 4.5842520194128156e-05
0.00012401604908518493 0.00012401606363710016
rl training, epoch1, iter0, batch817/1133, batch loss:0.00012401606363710016, Training time:27663.304166793823
batch reward last col mean 2.52200635486588e-07 first col mean 1.8971706595038995e-05 all mean 8.367138070752844e-05
0.00012691144365817308 0.0001269114582100883
rl training, epoch1, iter0, batch818/1133, batch loss:0.0001269114582100883, Training time:27680.384679555893
batch reward last col mean 3.6307901609689e-05 first col mean 0.0010975615587085485 all mean 0.00011470810568425804
0.00022189209994394332 0.00022189211449585855
rl training, epoch1, iter0, batch819/1133, batch loss:0.00022189211449585855, Training time:27698.626722097397
batch reward last col mean 4.540134978014976e-05 first col mean 0.0003010316868312657 all mean 8.488308958476409e-05
0.0001608031161595136 0.0001608031161595136
rl training, epoch1, iter0, batch820/1133, batch loss:0.0001608031161595136, Training time:27715.063505887985
batch reward last col mean 0.0003796216915361583 first col mean 7.151762110879645e-05 all mean 0.0004060981736984104
0.00016260349366348237 0.00016260347911156714
rl training, epoch1, iter0, batch821/1133, batch loss:0.00016260347911156714, Training time:27731.35931801796
batch reward last col mean 2.5576362077117665e-06 first col mean 3.7821237128810026e-06 all mean 4.6372915676329285e-05
3.7461948522832245e-05 3.746195579878986e-05
rl training, epoch1, iter0, batch822/1133, batch loss:3.746195579878986e-05, Training time:27747.73740029335
batch reward last col mean 0.0005212351097725332 first col mean 3.6070975966140395e-06 all mean 0.000536895589902997
0.00014030429883860052 0.00014030429883860052
rl training, epoch1, iter0, batch823/1133, batch loss:0.00014030429883860052, Training time:27764.074192523956
batch reward last col mean 3.9064678276190534e-05 first col mean 0.00020167892216704786 all mean 0.00014866112906020135
0.0004841595364268869 0.0004841595364268869
rl training, epoch1, iter0, batch824/1133, batch loss:0.0004841595364268869, Training time:27780.400761127472
batch reward last col mean 1.8679962749956758e-06 first col mean 0.0007443207432515919 all mean 6.309989839792252e-05
0.00010310566722182557 0.00010310565994586796
rl training, epoch1, iter0, batch825/1133, batch loss:0.00010310565994586796, Training time:27796.77060484886
batch reward last col mean 0.00022182460816111416 first col mean 2.6798361432156526e-06 all mean 0.00018888269551098347
9.802368003875017e-05 9.802365821087733e-05
rl training, epoch1, iter0, batch826/1133, batch loss:9.802365821087733e-05, Training time:27813.043501853943
batch reward last col mean 4.4270112994126976e-05 first col mean 3.950309292122256e-06 all mean 8.618178981123492e-05
6.145971565274522e-05 6.145971565274522e-05
rl training, epoch1, iter0, batch827/1133, batch loss:6.145971565274522e-05, Training time:27829.322048187256
batch reward last col mean 1.2504141295721638e-06 first col mean 1.1248752343817614e-05 all mean 0.00012937266728840768
0.00016093457816168666 0.00016093457816168666
rl training, epoch1, iter0, batch828/1133, batch loss:0.00016093457816168666, Training time:27845.542023181915
batch reward last col mean 3.972847480326891e-05 first col mean 0.000367434840882197 all mean 8.009944576770067e-05
7.310169166885316e-05 7.310168439289555e-05
rl training, epoch1, iter0, batch829/1133, batch loss:7.310168439289555e-05, Training time:27861.925498723984
batch reward last col mean 0.0009801257401704788 first col mean 0.0017783800140023232 all mean 0.0007762914756312966
0.000312994874548167 0.00031299484544433653
rl training, epoch1, iter0, batch830/1133, batch loss:0.00031299484544433653, Training time:27878.445120811462
batch reward last col mean 4.493735104915686e-06 first col mean 0.003176160389557481 all mean 7.621469558216631e-05
0.000159809656906873 0.000159809656906873
rl training, epoch1, iter0, batch831/1133, batch loss:0.000159809656906873, Training time:27894.96510863304
batch reward last col mean 1.292582737733028e-06 first col mean 0.0001382771588396281 all mean 8.818854985293001e-05
0.00022967078257352114 0.00022967075346969068
rl training, epoch1, iter0, batch832/1133, batch loss:0.00022967075346969068, Training time:27911.445822954178
batch reward last col mean 3.4755735214275774e-06 first col mean 4.930901923216879e-06 all mean 6.180090713314712e-05
5.605154001386836e-05 5.6051547289825976e-05
rl training, epoch1, iter0, batch833/1133, batch loss:5.6051547289825976e-05, Training time:27927.965267658234
batch reward last col mean 4.976536729373038e-07 first col mean 6.680199294351041e-05 all mean 3.303869016235694e-05
5.99214035901241e-05 5.9921396314166486e-05
rl training, epoch1, iter0, batch834/1133, batch loss:5.9921396314166486e-05, Training time:27944.46885061264
batch reward last col mean 0.0006033237441442907 first col mean 0.00011818494385806844 all mean 0.00034564666566438973
0.00042001917609013617 0.0004200192342977971
rl training, epoch1, iter0, batch835/1133, batch loss:0.0004200192342977971, Training time:27960.71228337288
batch reward last col mean 7.255830496433191e-07 first col mean 0.0035620396956801414 all mean 9.057629358721897e-05
0.00012815016089007258 0.00012815016089007258
rl training, epoch1, iter0, batch836/1133, batch loss:0.00012815016089007258, Training time:27977.01738190651
batch reward last col mean 0.0001204776344820857 first col mean 3.458777064224705e-05 all mean 0.00015853956574574113
9.787851013243198e-05 9.787850285647437e-05
rl training, epoch1, iter0, batch837/1133, batch loss:9.787850285647437e-05, Training time:27994.709249973297
batch reward last col mean 9.92738023342099e-06 first col mean 5.7419142649450805e-06 all mean 2.9077682484057732e-05
2.5769928470253944e-05 2.576992665126454e-05
rl training, epoch1, iter0, batch838/1133, batch loss:2.576992665126454e-05, Training time:28012.7353682518
batch reward last col mean 3.504705091472715e-05 first col mean 2.0030891391797923e-05 all mean 5.0851176638389006e-05
6.203699740581214e-05 6.203699740581214e-05
rl training, epoch1, iter0, batch839/1133, batch loss:6.203699740581214e-05, Training time:28029.558324575424
batch reward last col mean 6.192542059579864e-06 first col mean 5.664289346896112e-06 all mean 3.3000273106154054e-05
4.576131686917506e-05 4.576131686917506e-05
rl training, epoch1, iter0, batch840/1133, batch loss:4.576131686917506e-05, Training time:28046.406985282898
batch reward last col mean 7.97339794189611e-07 first col mean 8.184642865671776e-06 all mean 5.582610538112931e-05
0.00014241393364500254 0.00014241391909308732
rl training, epoch1, iter0, batch841/1133, batch loss:0.00014241391909308732, Training time:28064.967965364456
batch reward last col mean 0.00042285368544980884 first col mean 2.7618083549896255e-05 all mean 0.00040705647552385926
0.00012001262075500563 0.00012001262075500563
rl training, epoch1, iter0, batch842/1133, batch loss:0.00012001262075500563, Training time:28081.657994508743
batch reward last col mean 1.2805082860722905e-06 first col mean 0.0001465452223783359 all mean 7.857385935494676e-05
8.145574247464538e-05 8.145574247464538e-05
rl training, epoch1, iter0, batch843/1133, batch loss:8.145574247464538e-05, Training time:28098.381204605103
batch reward last col mean 0.00013008421228732914 first col mean 4.863981303060427e-05 all mean 0.00018968772201333195
0.0001805494393920526 0.0001805494393920526
rl training, epoch1, iter0, batch844/1133, batch loss:0.0001805494393920526, Training time:28114.9988758564
batch reward last col mean 1.9560140572139062e-05 first col mean 2.790481084957719e-05 all mean 0.000136867820401676
0.00021917950653005391 0.00021917950653005391
rl training, epoch1, iter0, batch845/1133, batch loss:0.00021917950653005391, Training time:28131.51121711731
batch reward last col mean 7.34639843358309e-06 first col mean 0.0005817494238726795 all mean 7.600497337989509e-05
8.766376413404942e-05 8.766374958213419e-05
rl training, epoch1, iter0, batch846/1133, batch loss:8.766374958213419e-05, Training time:28148.063020944595
batch reward last col mean 5.330048679752508e-06 first col mean 0.00016024660726543516 all mean 8.074135257629678e-05
0.00011073199857492 0.00011073202040279284
rl training, epoch1, iter0, batch847/1133, batch loss:0.00011073202040279284, Training time:28164.67109298706
batch reward last col mean 0.00013151686289347708 first col mean 2.207501165685244e-05 all mean 0.00013080846110824496
0.00033123447792604566 0.00033123453613370657
rl training, epoch1, iter0, batch848/1133, batch loss:0.00033123453613370657, Training time:28181.991669893265
batch reward last col mean 0.006910460535436869 first col mean 0.0002479793911334127 all mean 0.00598370423540473
0.0007500051870010793 0.0007500051870010793
rl training, epoch1, iter0, batch849/1133, batch loss:0.0007500051870010793, Training time:28200.076860189438
batch reward last col mean 0.00015557227015960962 first col mean 6.9657271524192765e-06 all mean 0.00013781817688141018
0.000122982615721412 0.000122982615721412
rl training, epoch1, iter0, batch850/1133, batch loss:0.000122982615721412, Training time:28218.223831176758
batch reward last col mean 3.885981811890815e-07 first col mean 0.001955093815922737 all mean 0.0001541335805086419
0.0002781721414066851 0.00027817219961434603
rl training, epoch1, iter0, batch851/1133, batch loss:0.00027817219961434603, Training time:28236.24166893959
batch reward last col mean 2.1056139303254895e-06 first col mean 0.0018936670385301113 all mean 8.539688860764727e-05
0.00031089060939848423 0.00031089060939848423
rl training, epoch1, iter0, batch852/1133, batch loss:0.00031089060939848423, Training time:28254.332798719406
batch reward last col mean 4.810135010302474e-07 first col mean 0.00016467890236526728 all mean 8.365676330868155e-05
0.00011115771485492587 0.00011115773668279871
rl training, epoch1, iter0, batch853/1133, batch loss:0.00011115773668279871, Training time:28272.536254882812
batch reward last col mean 1.959919927685405e-06 first col mean 0.0001784047926776111 all mean 3.077573637710884e-05
4.195168730802834e-05 4.195168730802834e-05
rl training, epoch1, iter0, batch854/1133, batch loss:4.195168730802834e-05, Training time:28290.776802778244
batch reward last col mean 5.7695592659001704e-06 first col mean 6.27826557320077e-06 all mean 4.5317367039388046e-05
7.200465915957466e-05 7.200465915957466e-05
rl training, epoch1, iter0, batch855/1133, batch loss:7.200465915957466e-05, Training time:28308.86581349373
batch reward last col mean 0.00028854969423264265 first col mean 1.3284036867844407e-05 all mean 0.00010969040886266157
6.923887849552557e-05 6.923887849552557e-05
rl training, epoch1, iter0, batch856/1133, batch loss:6.923887849552557e-05, Training time:28326.9696931839
batch reward last col mean 1.5989073745004134e-06 first col mean 4.645356057153549e-06 all mean 4.686499232775532e-05
3.1873623811407015e-05 3.1873623811407015e-05
rl training, epoch1, iter0, batch857/1133, batch loss:3.1873623811407015e-05, Training time:28345.146940231323
batch reward last col mean 2.9222844659670955e-06 first col mean 6.970673712203279e-05 all mean 4.721570439869538e-05
0.00013190116442274302 0.00013190116442274302
rl training, epoch1, iter0, batch858/1133, batch loss:0.00013190116442274302, Training time:28363.14998626709
batch reward last col mean 3.65910236723721e-05 first col mean 1.0676727470126934e-05 all mean 7.079475471982732e-05
4.255663952790201e-05 4.255663225194439e-05
rl training, epoch1, iter0, batch859/1133, batch loss:4.255663225194439e-05, Training time:28381.278825044632
batch reward last col mean 0.0001428144023520872 first col mean 0.00020099170797038823 all mean 0.0001912473380798474
7.78812391217798e-05 7.78812391217798e-05
rl training, epoch1, iter0, batch860/1133, batch loss:7.78812391217798e-05, Training time:28399.617659807205
batch reward last col mean 9.237907215720043e-05 first col mean 0.0017859367653727531 all mean 0.00013731852232012898
0.00011390422150725499 0.00011390419967938215
rl training, epoch1, iter0, batch861/1133, batch loss:0.00011390419967938215, Training time:28417.932409524918
batch reward last col mean 2.3422097683578613e-07 first col mean 0.0011137730907648802 all mean 0.00013985579425934702
0.0005168009083718061 0.0005168009083718061
rl training, epoch1, iter0, batch862/1133, batch loss:0.0005168009083718061, Training time:28434.476311206818
batch reward last col mean 1.626473749638535e-05 first col mean 2.4773323730187258e-06 all mean 7.723144517512992e-05
7.56863082642667e-05 7.568631554022431e-05
rl training, epoch1, iter0, batch863/1133, batch loss:7.568631554022431e-05, Training time:28451.110231161118
batch reward last col mean 0.0004757690476253629 first col mean 3.16562618536409e-05 all mean 0.000374145049136132
0.0001750062801875174 0.0001750062801875174
rl training, epoch1, iter0, batch864/1133, batch loss:0.0001750062801875174, Training time:28467.763088464737
batch reward last col mean 0.00012621232599485666 first col mean 0.00010252422362100333 all mean 0.00012333650374785066
0.0002550255449023098 0.0002550255449023098
rl training, epoch1, iter0, batch865/1133, batch loss:0.0002550255449023098, Training time:28484.38270354271
batch reward last col mean 9.914189831761178e-06 first col mean 0.00013232399942353368 all mean 8.540861745132133e-05
0.00011002150131389499 0.00011002149403793737
rl training, epoch1, iter0, batch866/1133, batch loss:0.00011002149403793737, Training time:28500.865102767944
batch reward last col mean 2.5793290205911035e-06 first col mean 1.0423053026897833e-05 all mean 4.4709478970617056e-05
9.73299247561954e-05 9.732991748023778e-05
rl training, epoch1, iter0, batch867/1133, batch loss:9.732991748023778e-05, Training time:28518.666635274887
batch reward last col mean 4.312938472139649e-06 first col mean 1.0470787856320385e-05 all mean 2.9545668439823203e-05
3.9822010876378044e-05 3.982200360042043e-05
rl training, epoch1, iter0, batch868/1133, batch loss:3.982200360042043e-05, Training time:28536.700077533722
batch reward last col mean 4.578951973144285e-07 first col mean 0.0003279944648966193 all mean 5.022275581723079e-05
0.00010086372640216723 0.000100863711850252
rl training, epoch1, iter0, batch869/1133, batch loss:0.000100863711850252, Training time:28554.94909620285
batch reward last col mean 4.233833351463545e-06 first col mean 0.001609215629287064 all mean 0.00028268698952160776
0.0007685383898206055 0.0007685383898206055
rl training, epoch1, iter0, batch870/1133, batch loss:0.0007685383898206055, Training time:28572.887469291687
batch reward last col mean 4.1270582187280525e-06 first col mean 0.0017188612837344408 all mean 6.982654304010794e-05
9.1917063400615e-05 9.1917063400615e-05
rl training, epoch1, iter0, batch871/1133, batch loss:9.1917063400615e-05, Training time:28591.28805732727
batch reward last col mean 0.003679137909784913 first col mean 0.00026011091540567577 all mean 0.0031488663516938686
0.00046517624286934733 0.00046517624286934733
rl training, epoch1, iter0, batch872/1133, batch loss:0.00046517624286934733, Training time:28607.906682014465
batch reward last col mean 0.00037415666156448424 first col mean 0.0001476262550568208 all mean 8.646547212265432e-05
0.00019349728245288134 0.00019349728245288134
rl training, epoch1, iter0, batch873/1133, batch loss:0.00019349728245288134, Training time:28626.395266532898
batch reward last col mean 3.9983140595722944e-05 first col mean 2.3411810161633184e-06 all mean 5.834981857333332e-05
7.712768274359405e-05 7.712767546763644e-05
rl training, epoch1, iter0, batch874/1133, batch loss:7.712767546763644e-05, Training time:28643.10637974739
batch reward last col mean 0.007432049140334129 first col mean 7.079688657540828e-05 all mean 0.006837279070168734
0.0005682403570972383 0.0005682404735125601
rl training, epoch1, iter0, batch875/1133, batch loss:0.0005682404735125601, Training time:28661.67372775078
batch reward last col mean 7.176017788879108e-07 first col mean 1.0858576615646598e-06 all mean 4.485801764531061e-05
9.974160639103502e-05 9.974160639103502e-05
rl training, epoch1, iter0, batch876/1133, batch loss:9.974160639103502e-05, Training time:28679.745148181915
batch reward last col mean 2.944776156255102e-07 first col mean 0.00010537151683820412 all mean 9.15768468985334e-05
0.00015485477342735976 0.000154854787979275
rl training, epoch1, iter0, batch877/1133, batch loss:0.000154854787979275, Training time:28697.892835617065
batch reward last col mean 2.736948999881861e-06 first col mean 0.0012204404920339584 all mean 7.965959230205044e-05
0.00041971218888647854 0.00041971218888647854
rl training, epoch1, iter0, batch878/1133, batch loss:0.00041971218888647854, Training time:28716.342755317688
batch reward last col mean 1.2280672763154143e-06 first col mean 3.238664794480428e-05 all mean 8.77632264746353e-05
0.0001300505391554907 0.0001300505391554907
rl training, epoch1, iter0, batch879/1133, batch loss:0.0001300505391554907, Training time:28732.76335167885
batch reward last col mean 0.00017037783982232213 first col mean 9.409773338120431e-05 all mean 0.00012625039380509406
0.0001265743630938232 0.00012657434854190797
rl training, epoch1, iter0, batch880/1133, batch loss:0.00012657434854190797, Training time:28749.20902276039
batch reward last col mean 0.0001825373328756541 first col mean 7.297994670807384e-06 all mean 0.0003378675028216094
0.0007553344476036727 0.0007553344476036727
rl training, epoch1, iter0, batch881/1133, batch loss:0.0007553344476036727, Training time:28765.650441646576
batch reward last col mean 2.1473786659953475e-07 first col mean 0.0005586062907241285 all mean 7.113401807146147e-05
9.09474547370337e-05 9.094746201299131e-05
rl training, epoch1, iter0, batch882/1133, batch loss:9.094746201299131e-05, Training time:28782.140029907227
batch reward last col mean 5.5284719564951956e-05 first col mean 2.2972219085204415e-05 all mean 0.0001228592445841059
0.00025612718309275806 0.00025612718309275806
rl training, epoch1, iter0, batch883/1133, batch loss:0.00025612718309275806, Training time:28798.589423179626
batch reward last col mean 0.00014853871834930032 first col mean 0.0003107528609689325 all mean 0.00011462129623396322
0.00037567521212622523 0.00037567521212622523
rl training, epoch1, iter0, batch884/1133, batch loss:0.00037567521212622523, Training time:28814.81440281868
batch reward last col mean 0.0001677747059147805 first col mean 8.664124493407144e-07 all mean 0.00016398960724473
0.0003641726798377931 0.0003641726216301322
rl training, epoch1, iter0, batch885/1133, batch loss:0.0003641726216301322, Training time:28831.238400697708
batch reward last col mean 3.329814717289992e-05 first col mean 0.00063067686278373 all mean 7.863083737902343e-05
0.0001354717678623274 0.0001354717678623274
rl training, epoch1, iter0, batch886/1133, batch loss:0.0001354717678623274, Training time:28847.603729486465
batch reward last col mean 1.76097330495395e-06 first col mean 1.1113496839243453e-05 all mean 0.00016071007121354342
0.0004161915276199579 0.0004161915276199579
rl training, epoch1, iter0, batch887/1133, batch loss:0.0004161915276199579, Training time:28863.977198123932
batch reward last col mean 0.0001460401399526745 first col mean 6.047037823009305e-05 all mean 0.00017464417032897472
7.86698583397083e-05 7.86698583397083e-05
rl training, epoch1, iter0, batch888/1133, batch loss:7.86698583397083e-05, Training time:28880.361060142517
batch reward last col mean 4.561778951028828e-06 first col mean 0.00020911009050905704 all mean 3.9716058381600305e-05
4.371875184006058e-05 4.371875184006058e-05
rl training, epoch1, iter0, batch889/1133, batch loss:4.371875184006058e-05, Training time:28896.793801546097
batch reward last col mean 2.8627709980355576e-06 first col mean 0.0001536364434286952 all mean 0.00011342582001816481
0.0003316527290735394 0.0003316527290735394
rl training, epoch1, iter0, batch890/1133, batch loss:0.0003316527290735394, Training time:28913.221164226532
batch reward last col mean 3.6164365155855194e-05 first col mean 0.0007691647042520344 all mean 0.00013421173207461834
0.00029455439653247595 0.00029455439653247595
rl training, epoch1, iter0, batch891/1133, batch loss:0.00029455439653247595, Training time:28929.90905857086
batch reward last col mean 1.1119011844584747e-07 first col mean 6.587079406017438e-05 all mean 3.794318763539195e-05
4.843539500143379e-05 4.843539500143379e-05
rl training, epoch1, iter0, batch892/1133, batch loss:4.843539500143379e-05, Training time:28946.786328077316
batch reward last col mean 9.381277777720243e-06 first col mean 0.0013593081384897232 all mean 0.00014541514974553138
0.0001850063999881968 0.0001850063999881968
rl training, epoch1, iter0, batch893/1133, batch loss:0.0001850063999881968, Training time:28963.815125226974
batch reward last col mean 8.108162728603929e-05 first col mean 9.683759708423167e-05 all mean 0.0001382963382638991
0.0003190090646967292 0.0003190091229043901
rl training, epoch1, iter0, batch894/1133, batch loss:0.0003190091229043901, Training time:28980.94194674492
batch reward last col mean 4.60245519207092e-06 first col mean 0.0002301014756085351 all mean 7.808374357409775e-05
6.658004713244736e-05 6.658003258053213e-05
rl training, epoch1, iter0, batch895/1133, batch loss:6.658003258053213e-05, Training time:28997.745546340942
batch reward last col mean 3.2655872928444296e-05 first col mean 4.111116140848026e-05 all mean 0.00011097168317064643
0.00016840334865264595 0.00016840334865264595
rl training, epoch1, iter0, batch896/1133, batch loss:0.00016840334865264595, Training time:29014.65858221054
batch reward last col mean 0.0003190663701388985 first col mean 4.58230988442665e-06 all mean 0.00034163868986070156
0.00020571614732034504 0.00020571614732034504
rl training, epoch1, iter0, batch897/1133, batch loss:0.00020571614732034504, Training time:29031.465481758118
batch reward last col mean 1.17426645829255e-06 first col mean 0.00023133937793318182 all mean 0.00011595138494158164
0.00023859721841290593 0.00023859718930907547
rl training, epoch1, iter0, batch898/1133, batch loss:0.00023859718930907547, Training time:29049.31883740425
batch reward last col mean 0.0011163344606757164 first col mean 0.00016138122009579092 all mean 0.0010973403695970774
0.00014594499953091145 0.00014594499953091145
rl training, epoch1, iter0, batch899/1133, batch loss:0.00014594499953091145, Training time:29067.788435935974
batch reward last col mean 0.0003068827500101179 first col mean 1.832020188885508e-06 all mean 0.0003409118507988751
0.00014492306218016893 0.00014492309128399938
rl training, epoch1, iter0, batch900/1133, batch loss:0.00014492309128399938, Training time:29084.591988563538
batch reward last col mean 0.0006237732595764101 first col mean 0.00014061812544241548 all mean 0.0004653563373722136
0.00022897461894899607 0.00022897461894899607
rl training, epoch1, iter0, batch901/1133, batch loss:0.00022897461894899607, Training time:29101.353240013123
batch reward last col mean 3.7487527606572257e-06 first col mean 2.754853539954638e-06 all mean 7.017627649474889e-05
0.00023781281197443604 0.00023781281197443604
rl training, epoch1, iter0, batch902/1133, batch loss:0.00023781281197443604, Training time:29118.27848482132
batch reward last col mean 1.2650494340959995e-07 first col mean 5.232271723798476e-05 all mean 7.363221811829135e-05
0.00014019160880707204 0.00014019160880707204
rl training, epoch1, iter0, batch903/1133, batch loss:0.00014019160880707204, Training time:29134.991574525833
batch reward last col mean 1.1418572285037953e-05 first col mean 0.00039870492764748633 all mean 7.24854544387199e-05
0.0002206965145887807 0.0002206965145887807
rl training, epoch1, iter0, batch904/1133, batch loss:0.0002206965145887807, Training time:29153.65661382675
batch reward last col mean 6.303182090050541e-06 first col mean 4.786409772350453e-05 all mean 4.517705747275613e-05
4.830852412851527e-05 4.830853140447289e-05
rl training, epoch1, iter0, batch905/1133, batch loss:4.830853140447289e-05, Training time:29170.48412179947
batch reward last col mean 0.0002135604154318571 first col mean 1.3944680176791735e-05 all mean 0.0002306704263901338
0.00022761995205655694 0.00022761989384889603
rl training, epoch1, iter0, batch906/1133, batch loss:0.00022761989384889603, Training time:29187.172165870667
batch reward last col mean 0.00023315934231504798 first col mean 0.00010936512990156189 all mean 0.00022080123017076403
0.00023690047964919358 0.00023690047964919358
rl training, epoch1, iter0, batch907/1133, batch loss:0.00023690047964919358, Training time:29204.17234635353
batch reward last col mean 0.0024790805764496326 first col mean 0.0004216548695694655 all mean 0.0022587734274566174
0.0004313515091780573 0.0004313514509703964
rl training, epoch1, iter0, batch908/1133, batch loss:0.0004313514509703964, Training time:29222.961148023605
batch reward last col mean 2.4242299332399853e-05 first col mean 9.35544176172698e-06 all mean 6.822469003964216e-05
0.00012486001651268452 0.00012486001651268452
rl training, epoch1, iter0, batch909/1133, batch loss:0.00012486001651268452, Training time:29239.895901441574
batch reward last col mean 0.00018529080261942 first col mean 1.4416634712688392e-06 all mean 0.00020418534404598176
0.0001639197434997186 0.0001639197434997186
rl training, epoch1, iter0, batch910/1133, batch loss:0.0001639197434997186, Training time:29256.780400276184
batch reward last col mean 4.231305865687318e-07 first col mean 0.0018611152190715075 all mean 0.00010557463974691927
0.00025640445528551936 0.00025640445528551936
rl training, epoch1, iter0, batch911/1133, batch loss:0.00025640445528551936, Training time:29273.678505659103
batch reward last col mean 0.004473231732845306 first col mean 1.2771839692504727e-06 all mean 0.0008479953394271433
0.0006476741982623935 0.0006476741982623935
rl training, epoch1, iter0, batch912/1133, batch loss:0.0006476741982623935, Training time:29290.481974601746
batch reward last col mean 8.221021744247992e-06 first col mean 8.021472240216099e-06 all mean 2.8785285394405946e-05
4.584410635288805e-05 4.584410635288805e-05
rl training, epoch1, iter0, batch913/1133, batch loss:4.584410635288805e-05, Training time:29307.380803346634
batch reward last col mean 0.0013146497076377273 first col mean 0.0008992140647023916 all mean 0.0012410534545779228
0.00014546350575983524 0.00014546352031175047
rl training, epoch1, iter0, batch914/1133, batch loss:0.00014546352031175047, Training time:29324.36204957962
batch reward last col mean 0.003439505584537983 first col mean 8.437992619292345e-06 all mean 0.0031234126072376966
0.0005132862133905292 0.0005132862715981901
rl training, epoch1, iter0, batch915/1133, batch loss:0.0005132862715981901, Training time:29342.89125394821
batch reward last col mean 8.260973913820635e-07 first col mean 9.228386261384003e-06 all mean 5.5376487580360845e-05
8.109991176752374e-05 8.109991176752374e-05
rl training, epoch1, iter0, batch916/1133, batch loss:8.109991176752374e-05, Training time:29359.57751917839
batch reward last col mean 1.3728085832553916e-05 first col mean 0.0016926794778555632 all mean 0.00017289309471379966
0.0003716532373800874 0.00037165317917242646
rl training, epoch1, iter0, batch917/1133, batch loss:0.00037165317917242646, Training time:29376.625344991684
batch reward last col mean 1.3549745290220017e-06 first col mean 3.114262653980404e-05 all mean 0.00012268614955246449
0.00018811981135513633 0.00018811981135513633
rl training, epoch1, iter0, batch918/1133, batch loss:0.00018811981135513633, Training time:29393.335975408554
batch reward last col mean 1.1946996210099314e-06 first col mean 0.00012504369078669697 all mean 0.0001316343987127766
0.00029168586479499936 0.00029168586479499936
rl training, epoch1, iter0, batch919/1133, batch loss:0.00029168586479499936, Training time:29410.164072990417
batch reward last col mean 0.00019573100144043565 first col mean 1.031319970934419e-05 all mean 0.00028163293609395623
0.00025049224495887756 0.00025049224495887756
rl training, epoch1, iter0, batch920/1133, batch loss:0.00025049224495887756, Training time:29427.655605793
batch reward last col mean 5.052959022577852e-05 first col mean 0.0003006247279699892 all mean 4.811252802028321e-05
1.3340745681489352e-05 1.3340746590984054e-05
rl training, epoch1, iter0, batch921/1133, batch loss:1.3340746590984054e-05, Training time:29446.248942136765
batch reward last col mean 3.8638322052975127e-07 first col mean 9.903254976961762e-06 all mean 3.061020834138617e-05
2.9698494472540915e-05 2.969849629153032e-05
rl training, epoch1, iter0, batch922/1133, batch loss:2.969849629153032e-05, Training time:29463.08261871338
batch reward last col mean 0.0001270514476345852 first col mean 4.491690924623981e-05 all mean 0.00019507468095980585
9.078825678443536e-05 9.078824950847775e-05
rl training, epoch1, iter0, batch923/1133, batch loss:9.078824950847775e-05, Training time:29481.601716279984
batch reward last col mean 1.000773954729084e-05 first col mean 4.784112752531655e-05 all mean 5.459527164930478e-05
5.186978887650184e-05 5.186979615245946e-05
rl training, epoch1, iter0, batch924/1133, batch loss:5.186979615245946e-05, Training time:29498.394250154495
batch reward last col mean 6.463943282142282e-05 first col mean 2.2313781300908886e-05 all mean 8.793106826487929e-05
0.00020791240967810154 0.00020791238057427108
rl training, epoch1, iter0, batch925/1133, batch loss:0.00020791238057427108, Training time:29514.988620996475
batch reward last col mean 6.430032954085618e-06 first col mean 0.00030445129959844053 all mean 0.000101182893558871
0.00010931497672572732 0.00010931496217381209
rl training, epoch1, iter0, batch926/1133, batch loss:0.00010931496217381209, Training time:29531.72534775734
batch reward last col mean 3.507772419197863e-07 first col mean 0.00027651668642647564 all mean 0.00017991126514971256
0.0003234166943002492 0.0003234166360925883
rl training, epoch1, iter0, batch927/1133, batch loss:0.0003234166360925883, Training time:29548.46370434761
batch reward last col mean 1.8441429347149096e-05 first col mean 0.0015060404548421502 all mean 0.00018037765403278172
0.0004034929443150759 0.00040349297341890633
rl training, epoch1, iter0, batch928/1133, batch loss:0.00040349297341890633, Training time:29565.264570236206
batch reward last col mean 0.0001901619543787092 first col mean 0.001209984882734716 all mean 0.00020442971435841173
0.0001790775713743642 0.0001790775713743642
rl training, epoch1, iter0, batch929/1133, batch loss:0.0001790775713743642, Training time:29581.96064543724
batch reward last col mean 5.1065457228105515e-05 first col mean 0.00015536586579401046 all mean 4.994832124793902e-05
2.8442393158911727e-05 2.8442393158911727e-05
rl training, epoch1, iter0, batch930/1133, batch loss:2.8442393158911727e-05, Training time:29598.70328617096
batch reward last col mean 1.3048787650404847e-06 first col mean 5.6505650718463585e-06 all mean 4.4649423216469586e-05
7.33428678358905e-05 7.33428678358905e-05
rl training, epoch1, iter0, batch931/1133, batch loss:7.33428678358905e-05, Training time:29616.354118824005
batch reward last col mean 1.4365531569637824e-05 first col mean 0.0010728962952271104 all mean 8.985445310827345e-05
0.00011616482515819371 0.00011616482515819371
rl training, epoch1, iter0, batch932/1133, batch loss:0.00011616482515819371, Training time:29634.469586849213
batch reward last col mean 0.0007520156214013696 first col mean 0.003175246063619852 all mean 0.0006700512021780014
9.067807695828378e-05 9.06780842342414e-05
rl training, epoch1, iter0, batch933/1133, batch loss:9.06780842342414e-05, Training time:29651.174231767654
batch reward last col mean 1.1237663784413598e-05 first col mean 3.0309578505693935e-05 all mean 4.714002716355026e-05
0.0001251179346581921 0.00012511794921010733
rl training, epoch1, iter0, batch934/1133, batch loss:0.00012511794921010733, Training time:29668.441945552826
batch reward last col mean 3.22970881825313e-05 first col mean 1.1150663340231404e-05 all mean 5.550376954488456e-05
0.00011101480049546808 0.00011101480049546808
rl training, epoch1, iter0, batch935/1133, batch loss:0.00011101480049546808, Training time:29685.223748922348
batch reward last col mean 0.00011044379061786458 first col mean 0.00033504728344269097 all mean 0.00010508293053135276
9.00131999514997e-05 9.00131999514997e-05
rl training, epoch1, iter0, batch936/1133, batch loss:9.00131999514997e-05, Training time:29701.712326526642
batch reward last col mean 1.411850917065749e-06 first col mean 8.926399459596723e-05 all mean 5.279362449073233e-05
0.0001097917920560576 0.0001097917920560576
rl training, epoch1, iter0, batch937/1133, batch loss:0.0001097917920560576, Training time:29718.46471810341
batch reward last col mean 0.0001503049861639738 first col mean 0.0006370391929522157 all mean 0.00013296019460540265
0.00011198606807738543 0.00011198606807738543
rl training, epoch1, iter0, batch938/1133, batch loss:0.00011198606807738543, Training time:29735.838820934296
batch reward last col mean 1.775192686181981e-05 first col mean 0.0013896271120756865 all mean 4.700922727352008e-05
4.405977961141616e-05 4.405978324939497e-05
rl training, epoch1, iter0, batch939/1133, batch loss:4.405978324939497e-05, Training time:29754.260120868683
batch reward last col mean 0.001594550791196525 first col mean 2.2280391931417398e-05 all mean 0.0006329406169243157
0.000606691581197083 0.000606691581197083
rl training, epoch1, iter0, batch940/1133, batch loss:0.000606691581197083, Training time:29772.84640479088
batch reward last col mean 5.845186933584046e-06 first col mean 4.3357820686651394e-05 all mean 4.053255179314874e-05
5.15629981236998e-05 5.15629981236998e-05
rl training, epoch1, iter0, batch941/1133, batch loss:5.15629981236998e-05, Training time:29789.576382875443
batch reward last col mean 7.975732296472415e-05 first col mean 0.0008005391573533416 all mean 0.00011632401583483443
0.00017950133769772947 0.00017950133769772947
rl training, epoch1, iter0, batch942/1133, batch loss:0.00017950133769772947, Training time:29806.515198230743
batch reward last col mean 0.000464417360490188 first col mean 0.00010216319788014516 all mean 0.0005033714114688337
0.0002484927827026695 0.00024849281180649996
rl training, epoch1, iter0, batch943/1133, batch loss:0.00024849281180649996, Training time:29823.471015930176
batch reward last col mean 0.002398840617388487 first col mean 0.00010536403715377674 all mean 0.0022993593011051416
0.0004367457004263997 0.00043674572953023016
rl training, epoch1, iter0, batch944/1133, batch loss:0.00043674572953023016, Training time:29840.347248077393
batch reward last col mean 0.0002019352396018803 first col mean 0.00042558167479000986 all mean 0.00021048096823506057
0.0002213203115388751 0.00022132028243504465
rl training, epoch1, iter0, batch945/1133, batch loss:0.00022132028243504465, Training time:29857.16907596588
batch reward last col mean 9.039191354531795e-06 first col mean 0.0017113781068474054 all mean 5.620035153697245e-05
5.9410267567727715e-05 5.941028211964294e-05
rl training, epoch1, iter0, batch946/1133, batch loss:5.941028211964294e-05, Training time:29873.95449614525
batch reward last col mean 0.00012521122698672116 first col mean 0.00013276212848722935 all mean 0.00025429404922761023
0.0004350307281129062 0.0004350307281129062
rl training, epoch1, iter0, batch947/1133, batch loss:0.0004350307281129062, Training time:29891.15358901024
batch reward last col mean 0.00014313067367766052 first col mean 1.3843929082213435e-05 all mean 0.00014927698066458106
0.00010886429663514718 0.00010886429663514718
rl training, epoch1, iter0, batch948/1133, batch loss:0.00010886429663514718, Training time:29909.697174310684
batch reward last col mean 9.57129304879345e-05 first col mean 0.0018540845485404134 all mean 4.650798291550018e-05
3.382038266863674e-05 3.3820386306615546e-05
rl training, epoch1, iter0, batch949/1133, batch loss:3.3820386306615546e-05, Training time:29928.314200162888
batch reward last col mean 0.0003525007632561028 first col mean 0.0002465369179844856 all mean 0.00024879706325009465
9.291301830671728e-05 9.291301830671728e-05
rl training, epoch1, iter0, batch950/1133, batch loss:9.291301830671728e-05, Training time:29945.87901377678
batch reward last col mean 6.263609066081699e-06 first col mean 0.003356972010806203 all mean 0.00039865990402176976
0.0013485393719747663 0.0013485393719747663
rl training, epoch1, iter0, batch951/1133, batch loss:0.0013485393719747663, Training time:29963.9257645607
batch reward last col mean 0.00011811093281721696 first col mean 0.0021640032064169645 all mean 0.00017950116307474673
0.0001298840797971934 0.0001298840797971934
rl training, epoch1, iter0, batch952/1133, batch loss:0.0001298840797971934, Training time:29980.730032444
batch reward last col mean 0.008124628104269505 first col mean 0.0032206419855356216 all mean 0.00755125330761075
0.0006299709784798324 0.0006299709784798324
rl training, epoch1, iter0, batch953/1133, batch loss:0.0006299709784798324, Training time:29997.542293787003
batch reward last col mean 9.303965384788171e-07 first col mean 1.4493229173240252e-05 all mean 6.755226058885455e-05
9.379778930451721e-05 9.379778930451721e-05
rl training, epoch1, iter0, batch954/1133, batch loss:9.379778930451721e-05, Training time:30015.49277973175
batch reward last col mean 1.967648586287396e-06 first col mean 0.0019485228694975376 all mean 9.356821101391688e-05
0.00018780844402499497 0.00018780842947307974
rl training, epoch1, iter0, batch955/1133, batch loss:0.00018780842947307974, Training time:30032.503105401993
batch reward last col mean 2.1133548671059543e-06 first col mean 6.261873204493895e-05 all mean 0.0001483009400544688
0.00025919912150129676 0.0002591991506051272
rl training, epoch1, iter0, batch956/1133, batch loss:0.0002591991506051272, Training time:30049.241602897644
batch reward last col mean 1.688164411461912e-05 first col mean 5.96606005274225e-05 all mean 0.00015768689627293497
0.00039269591798074543 0.0003926958597730845
rl training, epoch1, iter0, batch957/1133, batch loss:0.0003926958597730845, Training time:30066.713103055954
batch reward last col mean 5.449890977615723e-06 first col mean 0.0007364152697846293 all mean 9.795178630156443e-05
0.0001290472282562405 0.00012904721370432526
rl training, epoch1, iter0, batch958/1133, batch loss:0.00012904721370432526, Training time:30085.298158168793
batch reward last col mean 2.06389267987106e-06 first col mean 0.00013139285147190094 all mean 0.00014254283451009542
0.0002236019936390221 0.0002236019936390221
rl training, epoch1, iter0, batch959/1133, batch loss:0.0002236019936390221, Training time:30102.14457988739
batch reward last col mean 0.0006695028278045356 first col mean 2.842022877302952e-05 all mean 0.0006206367979757488
0.00011707148951245472 0.00011707149678841233
rl training, epoch1, iter0, batch960/1133, batch loss:0.00011707149678841233, Training time:30118.914204597473
batch reward last col mean 1.2296202839934267e-05 first col mean 4.05572063755244e-05 all mean 5.155309190740809e-05
6.32174705970101e-05 6.32174705970101e-05
rl training, epoch1, iter0, batch961/1133, batch loss:6.32174705970101e-05, Training time:30135.88686990738
batch reward last col mean 6.542272217302525e-07 first col mean 0.0005177051643840969 all mean 0.00016570214938838035
0.00038226228207349777 0.00038226231117732823
rl training, epoch1, iter0, batch962/1133, batch loss:0.00038226231117732823, Training time:30152.713587284088
batch reward last col mean 1.3790623597742524e-05 first col mean 0.0004500746726989746 all mean 0.000288468407234177
0.000693310284987092 0.000693310284987092
rl training, epoch1, iter0, batch963/1133, batch loss:0.000693310284987092, Training time:30169.57678747177
batch reward last col mean 0.010286995209753513 first col mean 0.0015263663372024894 all mean 0.009985717013478279
0.0008587204501964152 0.0008587203919887543
rl training, epoch1, iter0, batch964/1133, batch loss:0.0008587203919887543, Training time:30186.3787252903
batch reward last col mean 0.0002262074704049155 first col mean 2.6926674763672054e-05 all mean 0.00012998399324715137
0.0003056217101402581 0.0003056217101402581
rl training, epoch1, iter0, batch965/1133, batch loss:0.0003056217101402581, Training time:30203.190390348434
batch reward last col mean 8.117525794659741e-06 first col mean 0.0026862684171646833 all mean 9.321948164142668e-05
0.0001143837216659449 0.0001143837216659449
rl training, epoch1, iter0, batch966/1133, batch loss:0.0001143837216659449, Training time:30219.89280128479
batch reward last col mean 2.7991252409265144e-06 first col mean 0.00014964600268285722 all mean 5.982109723845497e-05
0.0001424025249434635 0.0001424025249434635
rl training, epoch1, iter0, batch967/1133, batch loss:0.0001424025249434635, Training time:30236.831290960312
batch reward last col mean 0.0003808405308518559 first col mean 0.002345392946153879 all mean 0.0004123647231608629
0.000424406782258302 0.000424406782258302
rl training, epoch1, iter0, batch968/1133, batch loss:0.000424406782258302, Training time:30253.390756607056
batch reward last col mean 4.134983828407712e-05 first col mean 7.243255095090717e-05 all mean 7.411343540297821e-05
6.69311557430774e-05 6.693114119116217e-05
rl training, epoch1, iter0, batch969/1133, batch loss:6.693114119116217e-05, Training time:30271.45360803604
batch reward last col mean 9.455138183511735e-07 first col mean 3.4359251003479585e-05 all mean 0.00011429585720179603
0.00033354086917825043 0.00033354086917825043
rl training, epoch1, iter0, batch970/1133, batch loss:0.00033354086917825043, Training time:30287.99995470047
batch reward last col mean 7.318377356568817e-06 first col mean 0.0003116571169812232 all mean 7.488970004487783e-05
0.00018157312297262251 0.00018157313752453774
rl training, epoch1, iter0, batch971/1133, batch loss:0.00018157313752453774, Training time:30304.570444345474
batch reward last col mean 1.4717192243551835e-05 first col mean 0.0016423562774434686 all mean 0.00013067087274976075
0.0001586085418239236 0.0001586085418239236
rl training, epoch1, iter0, batch972/1133, batch loss:0.0001586085418239236, Training time:30321.49303507805
batch reward last col mean 1.2742844774038531e-05 first col mean 9.961154864868149e-05 all mean 9.747009607963264e-05
0.0003003506863024086 0.0003003506863024086
rl training, epoch1, iter0, batch973/1133, batch loss:0.0003003506863024086, Training time:30338.587891578674
batch reward last col mean 1.2823925317206886e-06 first col mean 0.0018085516057908535 all mean 0.00014364355592988431
0.00033136247657239437 0.0003313624474685639
rl training, epoch1, iter0, batch974/1133, batch loss:0.0003313624474685639, Training time:30355.532149791718
batch reward last col mean 1.8396098084849655e-06 first col mean 4.918382728646975e-06 all mean 6.157936149975285e-05
7.854656723793596e-05 7.854656723793596e-05
rl training, epoch1, iter0, batch975/1133, batch loss:7.854656723793596e-05, Training time:30372.325464487076
batch reward last col mean 6.436777039198205e-05 first col mean 5.917334419791587e-06 all mean 0.00014905707212164998
0.00020046134886797518 0.00020046133431605995
rl training, epoch1, iter0, batch976/1133, batch loss:0.00020046133431605995, Training time:30390.862963199615
batch reward last col mean 2.3865698040026473e-06 first col mean 2.2187925424077548e-05 all mean 8.732571586733684e-05
0.00016307584883179516 0.00016307584883179516
rl training, epoch1, iter0, batch977/1133, batch loss:0.00016307584883179516, Training time:30407.810479402542
batch reward last col mean 5.049900937592611e-05 first col mean 0.0018209292320534587 all mean 0.00012332065671216697
0.00022269043256528676 0.00022269043256528676
rl training, epoch1, iter0, batch978/1133, batch loss:0.00022269043256528676, Training time:30424.67677283287
batch reward last col mean 0.00011948624160140753 first col mean 0.0001970709126908332 all mean 0.0001391874538967386
0.00026975266519002616 0.00026975266519002616
rl training, epoch1, iter0, batch979/1133, batch loss:0.00026975266519002616, Training time:30441.501695394516
batch reward last col mean 2.5983081286540255e-06 first col mean 4.8923702706815675e-05 all mean 0.00011186384654138237
0.00031376787228509784 0.00031376787228509784
rl training, epoch1, iter0, batch980/1133, batch loss:0.00031376787228509784, Training time:30458.236342430115
batch reward last col mean 8.987285400507972e-05 first col mean 1.5400197298731655e-05 all mean 0.00012013043306069449
0.00045358831994235516 0.00045358831994235516
rl training, epoch1, iter0, batch981/1133, batch loss:0.00045358831994235516, Training time:30475.189683437347
batch reward last col mean 0.00012713694013655186 first col mean 0.00018203163926955312 all mean 0.000204463503905572
0.0002215638232883066 0.00022156380873639137
rl training, epoch1, iter0, batch982/1133, batch loss:0.00022156380873639137, Training time:30491.86979842186
batch reward last col mean 0.0001508426503278315 first col mean 2.1588681192952208e-05 all mean 9.603672515368089e-05
0.00028164914692752063 0.00028164914692752063
rl training, epoch1, iter0, batch983/1133, batch loss:0.00028164914692752063, Training time:30509.769332408905
batch reward last col mean 2.2819142486696364e-07 first col mean 0.00018679344793781638 all mean 4.97409600939136e-05
0.00011607824853854254 0.00011607824853854254
rl training, epoch1, iter0, batch984/1133, batch loss:0.00011607824853854254, Training time:30526.568031787872
batch reward last col mean 1.2758735010720557e-06 first col mean 0.0018819118849933147 all mean 6.009666685713455e-05
0.00022620570962317288 0.00022620570962317288
rl training, epoch1, iter0, batch985/1133, batch loss:0.00022620570962317288, Training time:30543.68213748932
batch reward last col mean 2.1183299395488575e-05 first col mean 2.279785121572786e-06 all mean 0.00014805453247390687
0.00037529654218815267 0.00037529654218815267
rl training, epoch1, iter0, batch986/1133, batch loss:0.00037529654218815267, Training time:30560.451698303223
batch reward last col mean 0.010514539666473866 first col mean 0.0004183004202786833 all mean 0.009279660880565643
0.001096220570616424 0.001096220570616424
rl training, epoch1, iter0, batch987/1133, batch loss:0.001096220570616424, Training time:30577.4419631958
batch reward last col mean 2.3856352981965756e-07 first col mean 0.0004993395996280015 all mean 7.080790965119377e-05
0.00016793426766525954 0.00016793428221717477
rl training, epoch1, iter0, batch988/1133, batch loss:0.00016793428221717477, Training time:30594.4142870903
batch reward last col mean 1.2018119832646335e-06 first col mean 0.00010063896479550749 all mean 7.567728607682511e-05
0.00023592179059050977 0.00023592179059050977
rl training, epoch1, iter0, batch989/1133, batch loss:0.00023592179059050977, Training time:30611.388209104538
batch reward last col mean 0.00011104291479568928 first col mean 5.776655598310754e-05 all mean 0.00014891091268509626
0.00023349191178567708 0.0002334918681299314
rl training, epoch1, iter0, batch990/1133, batch loss:0.0002334918681299314, Training time:30628.433475732803
batch reward last col mean 0.0007460014894604683 first col mean 0.0006085230270400643 all mean 0.0007993278559297323
0.00020122117712162435 0.00020122117712162435
rl training, epoch1, iter0, batch991/1133, batch loss:0.00020122117712162435, Training time:30645.513620376587
batch reward last col mean 0.0007137909415178001 first col mean 0.00013606161519419402 all mean 0.0007603982812725008
0.00014965598529670388 0.00014965598529670388
rl training, epoch1, iter0, batch992/1133, batch loss:0.00014965598529670388, Training time:30662.723935842514
batch reward last col mean 0.008659407496452332 first col mean 4.679244011640549e-05 all mean 0.007050462067127228
0.0004586699069477618 0.0004586699651554227
rl training, epoch1, iter0, batch993/1133, batch loss:0.0004586699651554227, Training time:30679.52160024643
batch reward last col mean 0.00019031958072446287 first col mean 0.0019981046207249165 all mean 0.0001559563825139776
0.00035324913915246725 0.00035324919736012816
rl training, epoch1, iter0, batch994/1133, batch loss:0.00035324919736012816, Training time:30696.38541817665
batch reward last col mean 5.535936452361057e-06 first col mean 0.0011057634837925434 all mean 0.00014380403445102274
0.0002342804364161566 0.0002342804364161566
rl training, epoch1, iter0, batch995/1133, batch loss:0.0002342804364161566, Training time:30713.882693767548
batch reward last col mean 3.6488677324086893e-06 first col mean 0.001400924171321094 all mean 0.0001038678310578689
0.00026293558767065406 0.0002629356167744845
rl training, epoch1, iter0, batch996/1133, batch loss:0.0002629356167744845, Training time:30730.527779340744
batch reward last col mean 2.098276854667347e-05 first col mean 1.2000988135696389e-05 all mean 8.310592966154218e-05
0.00017289837705902755 0.0001728983479551971
rl training, epoch1, iter0, batch997/1133, batch loss:0.0001728983479551971, Training time:30747.737668275833
batch reward last col mean 0.006587892305105925 first col mean 0.0003573654976207763 all mean 0.006077731493860483
0.0004917697515338659 0.0004917697515338659
rl training, epoch1, iter0, batch998/1133, batch loss:0.0004917697515338659, Training time:30766.345932245255
batch reward last col mean 0.0003392338694538921 first col mean 6.096578999859048e-06 all mean 0.00024659099290147424
0.0005307664978317916 0.0005307664978317916
rl training, epoch1, iter0, batch999/1133, batch loss:0.0005307664978317916, Training time:30784.298372745514
batch reward last col mean 0.003829977009445429 first col mean 0.00013329859939403832 all mean 0.003740800777450204
0.00038629648042842746 0.00038629648042842746
rl training, epoch1, iter0, batch1000/1133, batch loss:0.00038629648042842746, Training time:30801.25280237198
batch reward last col mean 0.0002509667247068137 first col mean 0.0015963870100677013 all mean 0.00018780064419843256
0.00023240421433001757 0.00023240421433001757
rl training, epoch1, iter0, batch1001/1133, batch loss:0.00023240421433001757, Training time:30819.721971988678
batch reward last col mean 3.0271294235717505e-05 first col mean 0.0014745331136509776 all mean 9.558002057019621e-05
9.788793977349997e-05 9.788792522158474e-05
rl training, epoch1, iter0, batch1002/1133, batch loss:9.788792522158474e-05, Training time:30838.309445619583
batch reward last col mean 0.0009392050560563803 first col mean 0.0004015587910544127 all mean 0.00028253078926354647
0.00016229911125265062 0.00016229911125265062
rl training, epoch1, iter0, batch1003/1133, batch loss:0.00016229911125265062, Training time:30855.20527625084
batch reward last col mean 2.2259793695411645e-05 first col mean 0.00044356961734592915 all mean 0.00010160381498280913
0.00034676524228416383 0.0003467652131803334
rl training, epoch1, iter0, batch1004/1133, batch loss:0.0003467652131803334, Training time:30872.221257925034
batch reward last col mean 1.0111616575159132e-05 first col mean 3.741567343240604e-05 all mean 0.0001680125860730186
0.00035117639345116913 0.00035117639345116913
rl training, epoch1, iter0, batch1005/1133, batch loss:0.00035117639345116913, Training time:30889.08225274086
batch reward last col mean 1.5999794413801283e-05 first col mean 0.0007040872005745769 all mean 6.13167358096689e-05
6.284213304752484e-05 6.284213304752484e-05
rl training, epoch1, iter0, batch1006/1133, batch loss:6.284213304752484e-05, Training time:30905.913400888443
batch reward last col mean 4.853877180721611e-05 first col mean 2.4708993805688806e-05 all mean 0.00015055302355904132
0.00046514926361851394 0.00046514926361851394
rl training, epoch1, iter0, batch1007/1133, batch loss:0.00046514926361851394, Training time:30922.830588817596
batch reward last col mean 0.0013827863149344921 first col mean 4.337986865721177e-06 all mean 0.0013537948252633214
0.0004811888502445072 0.0004811888502445072
rl training, epoch1, iter0, batch1008/1133, batch loss:0.0004811888502445072, Training time:30939.727651834488
batch reward last col mean 0.007524003274738789 first col mean 7.900127093307674e-05 all mean 0.007282197009772062
0.0003918308357242495 0.0003918308357242495
rl training, epoch1, iter0, batch1009/1133, batch loss:0.0003918308357242495, Training time:30956.605164051056
batch reward last col mean 0.007477947045117617 first col mean 0.002382956212386489 all mean 0.006825490389019251
0.000574718345887959 0.000574718345887959
rl training, epoch1, iter0, batch1010/1133, batch loss:0.000574718345887959, Training time:30974.7751789093
batch reward last col mean 5.1082929530821275e-06 first col mean 0.000655232579447329 all mean 0.00012085204798495397
0.00020405746181495488 0.0002040574763668701
rl training, epoch1, iter0, batch1011/1133, batch loss:0.0002040574763668701, Training time:30992.15349841118
batch reward last col mean 0.00014017069770488888 first col mean 0.002170165302231908 all mean 0.00019539306231308728
0.00024844822473824024 0.0002484481956344098
rl training, epoch1, iter0, batch1012/1133, batch loss:0.0002484481956344098, Training time:31010.133119106293
batch reward last col mean 1.7540480257594027e-05 first col mean 5.786301699117757e-06 all mean 0.00013673891953658313
0.000281563145108521 0.00028156311600469053
rl training, epoch1, iter0, batch1013/1133, batch loss:0.00028156311600469053, Training time:31026.88905954361
batch reward last col mean 5.542429789784364e-06 first col mean 0.0018694553291425109 all mean 0.00016623787814751267
0.0004527137498371303 0.0004527137498371303
rl training, epoch1, iter0, batch1014/1133, batch loss:0.0004527137498371303, Training time:31044.689420461655
batch reward last col mean 0.0011759032495319843 first col mean 0.000472762796562165 all mean 0.0012041237205266953
0.0002643997431732714 0.0002643997431732714
rl training, epoch1, iter0, batch1015/1133, batch loss:0.0002643997431732714, Training time:31062.833706378937
batch reward last col mean 0.004824393894523382 first col mean 0.00030741881346330047 all mean 0.004621875938028097
0.0008519864059053361 0.0008519864059053361
rl training, epoch1, iter0, batch1016/1133, batch loss:0.0008519864059053361, Training time:31079.725694417953
batch reward last col mean 8.29645578050986e-05 first col mean 2.0336536181275733e-05 all mean 0.00012947310460731387
0.0003103911585640162 0.0003103911003563553
rl training, epoch1, iter0, batch1017/1133, batch loss:0.0003103911003563553, Training time:31097.772122621536
batch reward last col mean 0.003306033555418253 first col mean 2.86404956568731e-05 all mean 0.0031328119803220034
0.00020040599338244647 0.00020040599338244647
rl training, epoch1, iter0, batch1018/1133, batch loss:0.00020040599338244647, Training time:31114.654823064804
batch reward last col mean 5.3460320486919954e-05 first col mean 0.00026856159092858434 all mean 0.00011806710972450674
8.851233724271879e-05 8.851233724271879e-05
rl training, epoch1, iter0, batch1019/1133, batch loss:8.851233724271879e-05, Training time:31131.677788972855
batch reward last col mean 2.4795133867883123e-05 first col mean 0.00011122690921183676 all mean 0.0002359243226237595
0.0004269670753274113 0.0004269671335350722
rl training, epoch1, iter0, batch1020/1133, batch loss:0.0004269671335350722, Training time:31150.10863184929
batch reward last col mean 7.725773320998996e-05 first col mean 0.00015555787831544876 all mean 0.00015467246703337878
0.00012580877228174359 0.00012580877228174359
rl training, epoch1, iter0, batch1021/1133, batch loss:0.00012580877228174359, Training time:31166.82301259041
batch reward last col mean 3.8985344872344285e-05 first col mean 0.0005401314701884985 all mean 0.00022041000192984939
0.00041092411265708506 0.00041092405444942415
rl training, epoch1, iter0, batch1022/1133, batch loss:0.00041092405444942415, Training time:31183.34064722061
batch reward last col mean 9.760788816493005e-05 first col mean 0.001771323848515749 all mean 0.0001325015036854893
0.0001982916728593409 0.0001982916728593409
rl training, epoch1, iter0, batch1023/1133, batch loss:0.0001982916728593409, Training time:31200.03620171547
batch reward last col mean 1.269256358682469e-06 first col mean 0.0018926520133391023 all mean 0.00013880657206755131
0.00031353349913842976 0.0003135335282422602
rl training, epoch1, iter0, batch1024/1133, batch loss:0.0003135335282422602, Training time:31216.661605596542
batch reward last col mean 3.2883694984775502e-06 first col mean 0.002150263637304306 all mean 0.0002848696894943714
0.0008542726864106953 0.0008542726864106953
rl training, epoch1, iter0, batch1025/1133, batch loss:0.0008542726864106953, Training time:31233.363945961
batch reward last col mean 0.00016660740948282182 first col mean 0.004078122321516275 all mean 0.00032749524689279497
0.0005537443794310093 0.0005537443794310093
rl training, epoch1, iter0, batch1026/1133, batch loss:0.0005537443794310093, Training time:31251.8425052166
batch reward last col mean 9.689591706774081e-07 first col mean 0.0001913993910420686 all mean 9.472600504523143e-05
0.0001975918421521783 0.00019759187125600874
rl training, epoch1, iter0, batch1027/1133, batch loss:0.00019759187125600874, Training time:31270.029242038727
batch reward last col mean 0.007437584921717644 first col mean 0.0018079926958307624 all mean 0.007349597290158272
0.0007967216079123318 0.0007967216079123318
rl training, epoch1, iter0, batch1028/1133, batch loss:0.0007967216079123318, Training time:31288.09658718109
batch reward last col mean 6.084306733100675e-06 first col mean 0.0009979888563975692 all mean 7.836207078071311e-05
9.938438597600907e-05 9.938438597600907e-05
rl training, epoch1, iter0, batch1029/1133, batch loss:9.938438597600907e-05, Training time:31306.292083740234
batch reward last col mean 1.5705805708421394e-05 first col mean 0.0004629596078302711 all mean 0.00018150290998164564
0.00028696403023786843 0.00028696403023786843
rl training, epoch1, iter0, batch1030/1133, batch loss:0.00028696403023786843, Training time:31324.477452993393
batch reward last col mean 1.138100924436003e-05 first col mean 2.8665059289778583e-05 all mean 0.0001393561251461506
0.00026096164947375655 0.00026096164947375655
rl training, epoch1, iter0, batch1031/1133, batch loss:0.00026096164947375655, Training time:31342.526275634766
batch reward last col mean 3.490802919259295e-05 first col mean 0.0011323136277496815 all mean 0.00013990863226354122
0.00021305764676071703 0.00021305764676071703
rl training, epoch1, iter0, batch1032/1133, batch loss:0.00021305764676071703, Training time:31360.67242217064
batch reward last col mean 4.728665589937009e-05 first col mean 0.0018186854431405663 all mean 0.0001822581689339131
0.0004694400995504111 0.0004694400995504111
rl training, epoch1, iter0, batch1033/1133, batch loss:0.0004694400995504111, Training time:31377.201676368713
batch reward last col mean 3.844595994451083e-05 first col mean 0.0017470411257818341 all mean 8.295517909573391e-05
8.326802344527096e-05 8.326800889335573e-05
rl training, epoch1, iter0, batch1034/1133, batch loss:8.326800889335573e-05, Training time:31395.544729232788
batch reward last col mean 0.007692151237279177 first col mean 0.00018680692301131785 all mean 0.006751056760549545
0.00027585847419686615 0.00027585847419686615
rl training, epoch1, iter0, batch1035/1133, batch loss:0.00027585847419686615, Training time:31412.282792568207
batch reward last col mean 2.1257615117065143e-06 first col mean 7.329903382924385e-06 all mean 0.00015161735063884407
0.0005318491021171212 0.0005318491603247821
rl training, epoch1, iter0, batch1036/1133, batch loss:0.0005318491603247821, Training time:31430.91930913925
batch reward last col mean 4.254204213793855e-06 first col mean 2.0586989194271155e-05 all mean 0.00014829567226115614
0.0003065291966777295 0.0003065291966777295
rl training, epoch1, iter0, batch1037/1133, batch loss:0.0003065291966777295, Training time:31449.621126890182
batch reward last col mean 2.3287142880690226e-07 first col mean 0.0007564131519757211 all mean 0.00014433913747780025
0.00024042151926551014 0.0002404215483693406
rl training, epoch1, iter0, batch1038/1133, batch loss:0.0002404215483693406, Training time:31466.16801261902
batch reward last col mean 0.007700584828853607 first col mean 0.0008121028658933938 all mean 0.006736904848366976
0.0007866646628826857 0.0007866646628826857
rl training, epoch1, iter0, batch1039/1133, batch loss:0.0007866646628826857, Training time:31482.7297205925
batch reward last col mean 1.7716629372444004e-05 first col mean 0.0021765909623354673 all mean 0.00014678569277748466
0.00024175514408852905 0.00024175510043278337
rl training, epoch1, iter0, batch1040/1133, batch loss:0.00024175510043278337, Training time:31499.818707227707
batch reward last col mean 0.0017265917267650366 first col mean 0.0010767476633191109 all mean 0.0016312701627612114
0.0002674279676284641 0.0002674279676284641
rl training, epoch1, iter0, batch1041/1133, batch loss:0.0002674279676284641, Training time:31518.046565294266
batch reward last col mean 0.00018855452071875334 first col mean 0.001127745257690549 all mean 0.00022994949540589005
0.00012921064626425505 0.00012921063171233982
rl training, epoch1, iter0, batch1042/1133, batch loss:0.00012921063171233982, Training time:31536.069488048553
batch reward last col mean 9.873949238681234e-06 first col mean 0.0020304061472415924 all mean 0.00030061573488637805
0.0009234951576218009 0.0009234951576218009
rl training, epoch1, iter0, batch1043/1133, batch loss:0.0009234951576218009, Training time:31554.234949588776
batch reward last col mean 1.8794036805047654e-05 first col mean 0.0033657385502010584 all mean 0.00011645797349046916
0.00014266314974520355 0.00014266316429711878
rl training, epoch1, iter0, batch1044/1133, batch loss:0.00014266316429711878, Training time:31572.21966934204
batch reward last col mean 0.00759620638564229 first col mean 0.00047683954471722245 all mean 0.007611957378685474
0.0018739887746050954 0.0018739887746050954
rl training, epoch1, iter0, batch1045/1133, batch loss:0.0018739887746050954, Training time:31588.653708457947
batch reward last col mean 7.0853502620593645e-06 first col mean 0.0001321437011938542 all mean 0.00015032567898742855
0.0004374405543785542 0.0004374405543785542
rl training, epoch1, iter0, batch1046/1133, batch loss:0.0004374405543785542, Training time:31605.06878566742
batch reward last col mean 1.11632937205286e-06 first col mean 0.001419033040292561 all mean 9.551610128255561e-05
0.0001462756481487304 0.0001462756481487304
rl training, epoch1, iter0, batch1047/1133, batch loss:0.0001462756481487304, Training time:31621.657527685165
batch reward last col mean 0.001247470616362989 first col mean 0.0006289827870205045 all mean 0.001245462684892118
0.00022370358055923134 0.00022370358055923134
rl training, epoch1, iter0, batch1048/1133, batch loss:0.00022370358055923134, Training time:31639.459213018417
batch reward last col mean 3.830783043667907e-06 first col mean 2.383371247560717e-05 all mean 0.00010131209273822606
0.00019647530280053616 0.00019647530280053616
rl training, epoch1, iter0, batch1049/1133, batch loss:0.00019647530280053616, Training time:31657.77354502678
batch reward last col mean 0.0005292713758535683 first col mean 1.0648701390891802e-05 all mean 0.0003330172330606729
0.0002001064276555553 0.0002001064276555553
rl training, epoch1, iter0, batch1050/1133, batch loss:0.0002001064276555553, Training time:31675.897691488266
batch reward last col mean 8.136082033161074e-05 first col mean 0.0013342387974262238 all mean 0.00028029363602399826
0.0007374782580882311 0.0007374783745035529
rl training, epoch1, iter0, batch1051/1133, batch loss:0.0007374783745035529, Training time:31694.276992559433
batch reward last col mean 2.2143904061522335e-06 first col mean 0.006644205655902624 all mean 0.0003358935355208814
0.0010176226496696472 0.0010176225332543254
rl training, epoch1, iter0, batch1052/1133, batch loss:0.0010176225332543254, Training time:31711.098277568817
batch reward last col mean 6.356131780194119e-05 first col mean 0.00030588096706196666 all mean 0.00018324774282518774
0.0002216943830717355 0.0002216943830717355
rl training, epoch1, iter0, batch1053/1133, batch loss:0.0002216943830717355, Training time:31727.904660463333
batch reward last col mean 5.11160305904923e-06 first col mean 0.0008899522945284843 all mean 0.0001271763612749055
0.0002809111319947988 0.0002809111319947988
rl training, epoch1, iter0, batch1054/1133, batch loss:0.0002809111319947988, Training time:31744.880991220474
batch reward last col mean 0.0005418455111794174 first col mean 0.000664501974824816 all mean 0.0005237525328993797
0.0003484789340291172 0.0003484789340291172
rl training, epoch1, iter0, batch1055/1133, batch loss:0.0003484789340291172, Training time:31763.308502197266
batch reward last col mean 1.0236213938696892e-06 first col mean 0.002333964454010129 all mean 0.00020030456653330475
0.0002477043599355966 0.0002477043599355966
rl training, epoch1, iter0, batch1056/1133, batch loss:0.0002477043599355966, Training time:31780.18173289299
batch reward last col mean 0.0015068536158651114 first col mean 1.2430726201273501e-05 all mean 0.0015288187423720956
0.0003684250405058265 0.00036842506960965693
rl training, epoch1, iter0, batch1057/1133, batch loss:0.00036842506960965693, Training time:31796.873304843903
batch reward last col mean 0.00346007919870317 first col mean 0.0003493676776997745 all mean 0.003164060181006789
0.0009749563178047538 0.0009749563760124147
rl training, epoch1, iter0, batch1058/1133, batch loss:0.0009749563760124147, Training time:31813.670909166336
batch reward last col mean 4.413560873217648e-06 first col mean 0.0006898983847349882 all mean 9.307002619607374e-05
0.00014280519098974764 0.00014280517643783242
rl training, epoch1, iter0, batch1059/1133, batch loss:0.00014280517643783242, Training time:31830.47050189972
batch reward last col mean 3.006161750818137e-05 first col mean 3.42214698321186e-05 all mean 9.0418616309762e-05
9.238538768840954e-05 9.238539496436715e-05
rl training, epoch1, iter0, batch1060/1133, batch loss:9.238539496436715e-05, Training time:31847.110666513443
batch reward last col mean 1.503160092397593e-05 first col mean 0.0018614886794239283 all mean 0.00017021385428961366
0.0003799534169957042 0.0003799534169957042
rl training, epoch1, iter0, batch1061/1133, batch loss:0.0003799534169957042, Training time:31864.099336624146
batch reward last col mean 0.0013121701776981354 first col mean 0.003259145189076662 all mean 0.0012478212593123317
0.00024216249585151672 0.00024216249585151672
rl training, epoch1, iter0, batch1062/1133, batch loss:0.00024216249585151672, Training time:31881.972720384598
batch reward last col mean 0.002872271230444312 first col mean 0.0003000190481543541 all mean 0.002788387704640627
0.0005255635478533804 0.0005255635478533804
rl training, epoch1, iter0, batch1063/1133, batch loss:0.0005255635478533804, Training time:31898.240525960922
batch reward last col mean 6.400135816875263e-07 first col mean 0.0027574559208005667 all mean 0.00020228681387379766
0.0003807194880209863 0.00038071945891715586
rl training, epoch1, iter0, batch1064/1133, batch loss:0.00038071945891715586, Training time:31915.779799461365
batch reward last col mean 3.283168189227581e-05 first col mean 0.0033004602883011103 all mean 0.0003549054963514209
0.0006796587258577347 0.0006796588422730565
rl training, epoch1, iter0, batch1065/1133, batch loss:0.0006796588422730565, Training time:31932.263052225113
batch reward last col mean 0.00026006432017311454 first col mean 1.5508875321756932e-06 all mean 0.00026592088397592306
0.00010154163464903831 0.00010154163464903831
rl training, epoch1, iter0, batch1066/1133, batch loss:0.00010154163464903831, Training time:31948.666427373886
batch reward last col mean 0.002465922385454178 first col mean 8.801333933661226e-06 all mean 0.0006217038026079535
0.0005496669909916818 0.0005496669909916818
rl training, epoch1, iter0, batch1067/1133, batch loss:0.0005496669909916818, Training time:31965.16028237343
batch reward last col mean 1.7493724726591608e-06 first col mean 0.0018945062765851617 all mean 0.0002653780102264136
0.0006714561604894698 0.0006714562769047916
rl training, epoch1, iter0, batch1068/1133, batch loss:0.0006714562769047916, Training time:31981.653402090073
batch reward last col mean 0.0001583512348588556 first col mean 0.0007582289981655777 all mean 0.00022208021255210042
0.00032298159203492105 0.00032298159203492105
rl training, epoch1, iter0, batch1069/1133, batch loss:0.00032298159203492105, Training time:31999.100081682205
batch reward last col mean 3.9001580631747856e-08 first col mean 0.0031209997832775116 all mean 0.00021688595006708056
0.00022084808733779937 0.00022084808733779937
rl training, epoch1, iter0, batch1070/1133, batch loss:0.00022084808733779937, Training time:32015.85521888733
batch reward last col mean 0.007321991957724094 first col mean 0.0029776375740766525 all mean 0.007334142457693815
0.0008727568783797324 0.0008727568783797324
rl training, epoch1, iter0, batch1071/1133, batch loss:0.0008727568783797324, Training time:32032.92091536522
batch reward last col mean 0.0024501336738467216 first col mean 0.0016923253424465656 all mean 0.002356788609176874
0.0005251849070191383 0.0005251849070191383
rl training, epoch1, iter0, batch1072/1133, batch loss:0.0005251849070191383, Training time:32051.15524482727
batch reward last col mean 0.0012106967624276876 first col mean 4.755381087306887e-05 all mean 0.0010441725607961416
0.0001615162327652797 0.0001615162327652797
rl training, epoch1, iter0, batch1073/1133, batch loss:0.0001615162327652797, Training time:32068.189965963364
batch reward last col mean 0.0017026634886860847 first col mean 5.578857962973416e-05 all mean 0.0012876190012320876
0.0006529747042804956 0.0006529747042804956
rl training, epoch1, iter0, batch1074/1133, batch loss:0.0006529747042804956, Training time:32085.05335855484
batch reward last col mean 3.543237198755378e-06 first col mean 0.0020493094343692064 all mean 0.00015962676843628287
0.00043647794518619776 0.00043647794518619776
rl training, epoch1, iter0, batch1075/1133, batch loss:0.00043647794518619776, Training time:32101.8670399189
batch reward last col mean 1.2570063745442894e-06 first col mean 8.551916835131124e-05 all mean 0.00011360481585143134
0.0003021936281584203 0.0003021936281584203
rl training, epoch1, iter0, batch1076/1133, batch loss:0.0003021936281584203, Training time:32118.67172718048
batch reward last col mean 0.00015606574015691876 first col mean 0.004359911195933819 all mean 0.0003220550424885005
0.0004997398937121034 0.0004997398937121034
rl training, epoch1, iter0, batch1077/1133, batch loss:0.0004997398937121034, Training time:32135.357305765152
batch reward last col mean 2.4458213374600746e-06 first col mean 0.0020164181478321552 all mean 0.00029681212618015707
0.0006746288854628801 0.0006746288854628801
rl training, epoch1, iter0, batch1078/1133, batch loss:0.0006746288854628801, Training time:32152.015302419662
batch reward last col mean 0.0017069538589566946 first col mean 0.0018674187595024705 all mean 0.0018600588664412498
0.0021398570388555527 0.0021398570388555527
rl training, epoch1, iter0, batch1079/1133, batch loss:0.0021398570388555527, Training time:32170.49224114418
batch reward last col mean 1.781160244718194e-05 first col mean 0.0012545918580144644 all mean 0.0003418664273340255
0.0007952909218147397 0.0007952908636070788
rl training, epoch1, iter0, batch1080/1133, batch loss:0.0007952908636070788, Training time:32187.394000291824
batch reward last col mean 0.0001149865856859833 first col mean 4.1220406274078414e-05 all mean 0.00013417156878858805
6.73887989250943e-05 6.73887989250943e-05
rl training, epoch1, iter0, batch1081/1133, batch loss:6.73887989250943e-05, Training time:32205.45190668106
batch reward last col mean 7.081583316903561e-05 first col mean 8.387540583498776e-05 all mean 0.0002312386641278863
0.0006821279530413449 0.000682127894833684
rl training, epoch1, iter0, batch1082/1133, batch loss:0.000682127894833684, Training time:32224.102897167206
batch reward last col mean 0.0008596816915087402 first col mean 0.0017524462891742587 all mean 0.000840218155644834
0.0001937509950948879 0.00019375096599105746
rl training, epoch1, iter0, batch1083/1133, batch loss:0.00019375096599105746, Training time:32242.263133764267
batch reward last col mean 0.0032152021303772926 first col mean 0.00016897270688787103 all mean 0.0014019828522577882
0.00047507238923572004 0.00047507238923572004
rl training, epoch1, iter0, batch1084/1133, batch loss:0.00047507238923572004, Training time:32260.87898159027
batch reward last col mean 1.4761361853743438e-05 first col mean 0.004668959882110357 all mean 0.00029237609123811126
0.00041921413503587246 0.00041921413503587246
rl training, epoch1, iter0, batch1085/1133, batch loss:0.00041921413503587246, Training time:32279.465801000595
batch reward last col mean 5.004329068469815e-06 first col mean 0.0009133316343650222 all mean 0.00016290562052745372
0.0002839378430508077 0.0002839378430508077
rl training, epoch1, iter0, batch1086/1133, batch loss:0.0002839378430508077, Training time:32296.313525915146
batch reward last col mean 6.730354652972892e-05 first col mean 0.0018226237734779716 all mean 0.00015568346134386957
0.00034729071194306016 0.00034729071194306016
rl training, epoch1, iter0, batch1087/1133, batch loss:0.00034729071194306016, Training time:32313.398032426834
batch reward last col mean 0.000880419451277703 first col mean 0.0024488328490406275 all mean 0.0009444709867238998
0.000215738415136002 0.000215738415136002
rl training, epoch1, iter0, batch1088/1133, batch loss:0.000215738415136002, Training time:32330.354797124863
batch reward last col mean 1.476578472647816e-05 first col mean 1.3544259672926273e-05 all mean 0.0001377536973450333
0.00030009160400368273 0.0003000916331075132
rl training, epoch1, iter0, batch1089/1133, batch loss:0.0003000916331075132, Training time:32347.33797597885
batch reward last col mean 4.19314528699033e-06 first col mean 4.1840125049930066e-05 all mean 0.0002179517614422366
0.000732039101421833 0.000732039101421833
rl training, epoch1, iter0, batch1090/1133, batch loss:0.000732039101421833, Training time:32364.348885536194
batch reward last col mean 1.1850660484924447e-05 first col mean 7.79510592110455e-05 all mean 0.000157618778757751
0.0003523120249155909 0.0003523120249155909
rl training, epoch1, iter0, batch1091/1133, batch loss:0.0003523120249155909, Training time:32381.268523931503
batch reward last col mean 6.020653927407693e-06 first col mean 0.0007922481163404882 all mean 0.000225334195420146
0.0004651344788726419 0.0004651344788726419
rl training, epoch1, iter0, batch1092/1133, batch loss:0.0004651344788726419, Training time:32398.467517614365
batch reward last col mean 0.007081898860633373 first col mean 0.000993196154013276 all mean 0.006368326488882303
0.0009413256193511188 0.0009413256193511188
rl training, epoch1, iter0, batch1093/1133, batch loss:0.0009413256193511188, Training time:32416.15692090988
batch reward last col mean 0.008024558424949646 first col mean 0.0020573229994624853 all mean 0.007202687207609415
0.0006988557288423181 0.0006988557288423181
rl training, epoch1, iter0, batch1094/1133, batch loss:0.0006988557288423181, Training time:32434.89707517624
batch reward last col mean 1.7876816400530515e-06 first col mean 0.0019097102340310812 all mean 0.00027338817017152905
0.0005602126475423574 0.0005602126475423574
rl training, epoch1, iter0, batch1095/1133, batch loss:0.0005602126475423574, Training time:32453.35678911209
batch reward last col mean 5.559311375691323e-06 first col mean 0.001116211642511189 all mean 0.00027923937886953354
0.0004897849867120385 0.0004897849867120385
rl training, epoch1, iter0, batch1096/1133, batch loss:0.0004897849867120385, Training time:32471.460733890533
batch reward last col mean 3.028142782568466e-05 first col mean 0.0006179753108881414 all mean 0.00016217638039961457
0.0003016037226188928 0.0003016037226188928
rl training, epoch1, iter0, batch1097/1133, batch loss:0.0003016037226188928, Training time:32488.79354286194
batch reward last col mean 0.00030525727197527885 first col mean 0.0030152476392686367 all mean 0.0003734793863259256
0.00028451031539589167 0.00028451031539589167
rl training, epoch1, iter0, batch1098/1133, batch loss:0.00028451031539589167, Training time:32507.53673005104
batch reward last col mean 0.001668419106863439 first col mean 0.0005776610923931003 all mean 0.0016836171271279454
0.00036703847581520677 0.00036703847581520677
rl training, epoch1, iter0, batch1099/1133, batch loss:0.00036703847581520677, Training time:32526.216028690338
batch reward last col mean 0.002310100942850113 first col mean 0.002348855137825012 all mean 0.0020949761383235455
0.0005157248815521598 0.0005157248815521598
rl training, epoch1, iter0, batch1100/1133, batch loss:0.0005157248815521598, Training time:32543.119304656982
batch reward last col mean 0.008388189598917961 first col mean 0.0004527552518993616 all mean 0.007420745212584734
0.0035003372468054295 0.003500337013974786
rl training, epoch1, iter0, batch1101/1133, batch loss:0.003500337013974786, Training time:32560.05580997467
batch reward last col mean 4.901129432255402e-05 first col mean 0.000330829294398427 all mean 0.0002559289860073477
0.0005175194819457829 0.0005175194819457829
rl training, epoch1, iter0, batch1102/1133, batch loss:0.0005175194819457829, Training time:32576.982703447342
batch reward last col mean 1.1308065040793736e-05 first col mean 0.0011278901947662234 all mean 0.00016094371676445007
0.0003652653540484607 0.0003652653540484607
rl training, epoch1, iter0, batch1103/1133, batch loss:0.0003652653540484607, Training time:32594.431218624115
batch reward last col mean 2.574940367594536e-07 first col mean 0.002034467877820134 all mean 0.000206606782739982
0.0005518001853488386 0.0005518001853488386
rl training, epoch1, iter0, batch1104/1133, batch loss:0.0005518001853488386, Training time:32613.12858605385
batch reward last col mean 2.99174316751305e-05 first col mean 0.0012881600996479392 all mean 0.00014684216876048595
0.0003330534091219306 0.00033305343822576106
rl training, epoch1, iter0, batch1105/1133, batch loss:0.00033305343822576106, Training time:32631.749900579453
batch reward last col mean 0.004609495401382446 first col mean 0.0015354044735431671 all mean 0.0015650243731215596
0.0008197664283216 0.0008197664283216
rl training, epoch1, iter0, batch1106/1133, batch loss:0.0008197664283216, Training time:32648.466298103333
batch reward last col mean 0.0008889422751963139 first col mean 0.0017692102119326591 all mean 0.0010027586249634624
0.000532852835021913 0.000532852835021913
rl training, epoch1, iter0, batch1107/1133, batch loss:0.000532852835021913, Training time:32666.594938755035
batch reward last col mean 0.0002944930165540427 first col mean 0.0011580903083086014 all mean 0.00030781241366639733
0.00030813305056653917 0.0003081330214627087
rl training, epoch1, iter0, batch1108/1133, batch loss:0.0003081330214627087, Training time:32685.19760942459
batch reward last col mean 5.142667760082986e-06 first col mean 0.00033898046240210533 all mean 0.00014769259723834693
0.00041754645644687116 0.0004175464273430407
rl training, epoch1, iter0, batch1109/1133, batch loss:0.0004175464273430407, Training time:32702.014950990677
batch reward last col mean 9.667500853538513e-05 first col mean 0.0020933838095515966 all mean 0.000408767256885767
0.0009031089721247554 0.0009031089721247554
rl training, epoch1, iter0, batch1110/1133, batch loss:0.0009031089721247554, Training time:32718.91307592392
batch reward last col mean 0.007770876865833998 first col mean 0.005162423942238092 all mean 0.007339996285736561
0.0013133262982591987 0.0013133261818438768
rl training, epoch1, iter0, batch1111/1133, batch loss:0.0013133261818438768, Training time:32735.270179986954
batch reward last col mean 7.449884265042783e-07 first col mean 0.00532143097370863 all mean 0.00012654802412725985
0.0002474295033607632 0.00024742953246459365
rl training, epoch1, iter0, batch1112/1133, batch loss:0.00024742953246459365, Training time:32752.71555042267
batch reward last col mean 2.8992568331887014e-05 first col mean 0.0018347891746088862 all mean 0.00029537477530539036
0.0007756520644761622 0.0007756520644761622
rl training, epoch1, iter0, batch1113/1133, batch loss:0.0007756520644761622, Training time:32770.44136381149
batch reward last col mean 5.251575566944666e-05 first col mean 3.915701017831452e-05 all mean 0.00027025514282286167
0.0005617585848085582 0.0005617585266008973
rl training, epoch1, iter0, batch1114/1133, batch loss:0.0005617585266008973, Training time:32789.03723073006
batch reward last col mean 1.2695072655333206e-05 first col mean 6.580101853614906e-06 all mean 0.00012479127326514572
0.0002798801870085299 0.0002798801870085299
rl training, epoch1, iter0, batch1115/1133, batch loss:0.0002798801870085299, Training time:32805.94046163559
batch reward last col mean 0.0055137029848992825 first col mean 8.438735676463693e-06 all mean 0.004952451214194298
0.0006317943334579468 0.0006317943334579468
rl training, epoch1, iter0, batch1116/1133, batch loss:0.0006317943334579468, Training time:32822.567398548126
batch reward last col mean 0.0022470804397016764 first col mean 0.005870368797332048 all mean 0.002287052571773529
0.0019955115858465433 0.0019955113530158997
rl training, epoch1, iter0, batch1117/1133, batch loss:0.0019955113530158997, Training time:32839.31811332703
batch reward last col mean 0.003413541242480278 first col mean 0.0019502724753692746 all mean 0.0032994209323078394
0.000535460829269141 0.000535460829269141
rl training, epoch1, iter0, batch1118/1133, batch loss:0.000535460829269141, Training time:32858.01127886772
batch reward last col mean 0.00013231567572802305 first col mean 0.0013208157615736127 all mean 0.000331203656969592
0.0005471624317578971 0.000547162489965558
rl training, epoch1, iter0, batch1119/1133, batch loss:0.000547162489965558, Training time:32874.9165763855
batch reward last col mean 0.007271552924066782 first col mean 0.001828029751777649 all mean 0.006061803083866835
0.0025813784450292587 0.002581378212198615
rl training, epoch1, iter0, batch1120/1133, batch loss:0.002581378212198615, Training time:32891.90135240555
batch reward last col mean 0.007322177290916443 first col mean 0.0038776961155235767 all mean 0.007500757463276386
0.0013124804245308042 0.0013124806573614478
rl training, epoch1, iter0, batch1121/1133, batch loss:0.0013124806573614478, Training time:32908.93153476715
batch reward last col mean 5.3470816055778414e-05 first col mean 0.0018530379747971892 all mean 0.00017759726324584335
0.00034152017906308174 0.00034152017906308174
rl training, epoch1, iter0, batch1122/1133, batch loss:0.00034152017906308174, Training time:32925.777908325195
batch reward last col mean 0.007900369353592396 first col mean 0.0035147294402122498 all mean 0.005204298067837954
0.0017062160186469555 0.0017062159022316337
rl training, epoch1, iter0, batch1123/1133, batch loss:0.0017062159022316337, Training time:32942.7329659462
batch reward last col mean 3.3438054742873646e-06 first col mean 0.0023852670565247536 all mean 0.00013075557944830507
0.00018690871365834028 0.00018690871365834028
rl training, epoch1, iter0, batch1124/1133, batch loss:0.00018690871365834028, Training time:32959.5167324543
batch reward last col mean 0.00017563573783263564 first col mean 3.0237453756853938e-05 all mean 0.0001623819989617914
0.0003632144653238356 0.0003632144653238356
rl training, epoch1, iter0, batch1125/1133, batch loss:0.0003632144653238356, Training time:32976.13608121872
batch reward last col mean 0.001320056733675301 first col mean 0.002928410656750202 all mean 0.0015558009035885334
0.0012742334511131048 0.0012742334511131048
rl training, epoch1, iter0, batch1126/1133, batch loss:0.0012742334511131048, Training time:32992.677907943726
batch reward last col mean 2.34321328207443e-06 first col mean 1.0132984243682586e-05 all mean 0.0001278838753933087
0.0002348345733480528 0.00023483455879613757
rl training, epoch1, iter0, batch1127/1133, batch loss:0.00023483455879613757, Training time:33009.17208337784
batch reward last col mean 4.90737147629261e-05 first col mean 0.0008200113079510629 all mean 0.00017891843162942678
0.00034433603286743164 0.00034433603286743164
rl training, epoch1, iter0, batch1128/1133, batch loss:0.00034433603286743164, Training time:33025.95126700401
batch reward last col mean 0.00018810626352205873 first col mean 0.004570698365569115 all mean 0.0005134419188834727
0.0008989269845187664 0.0008989269845187664
rl training, epoch1, iter0, batch1129/1133, batch loss:0.0008989269845187664, Training time:33044.515090703964
batch reward last col mean 0.0013827199582010508 first col mean 0.001734433462843299 all mean 0.0010305814212188125
0.0005324765807017684 0.0005324765807017684
rl training, epoch1, iter0, batch1130/1133, batch loss:0.0005324765807017684, Training time:33063.34660696983
batch reward last col mean 0.004846087656915188 first col mean 0.002667532069608569 all mean 0.0056716264225542545
0.005173188168555498 0.005173188168555498
rl training, epoch1, iter0, batch1131/1133, batch loss:0.005173188168555498, Training time:33082.371690034866
batch reward last col mean 5.115624048812606e-07 first col mean 0.00015016522957012057 all mean 0.0006124706123955548
0.0023315963335335255 0.0023315963335335255
rl training, epoch1, iter0, batch1132/1133, batch loss:0.0023315963335335255, Training time:33098.874561309814
rl training, epoch 1, iter 0, loss:0.00017318695793660494, Training time:33098.87485361099 
rl epoch 1, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.49735668514643955 Time: 139.59390449523926 s
0.21286506115706327 0.004430593448696897 0.28006103107441027
cur_epoch: 1
D Training Loss: 0.48622259339819096 Time: 138.4406156539917 s
0.20682689618559297 0.0032071124237445046 0.27618858500960014
cur_epoch: 2
D Training Loss: 0.4744695892980008 Time: 138.98186707496643 s
0.20134971403933583 0.003168107472860904 0.26995176683851607
cur_epoch: 3
D Training Loss: 0.4672128619446969 Time: 137.9067816734314 s
0.19609147919849915 0.0029659133150173565 0.26815546939884366
cur_epoch: 4
D Training Loss: 0.4543511945119708 Time: 140.83350157737732 s
0.18997616573365936 0.0027829178756995513 0.26159211025891427
rl epoch 2, begin RL for generator...
batch reward last col mean 4.5956244321132544e-07 first col mean 0.0006614510202780366 all mean 0.00019684844301082194
0.0006236506742425263 0.0006236506742425263
rl training, epoch2, iter0, batch0/1133, batch loss:0.0006236506742425263, Training time:33811.51247739792
batch reward last col mean 7.459084372385405e-06 first col mean 0.002898335224017501 all mean 0.00020770182891283184
0.0006202775985002518 0.0006202775985002518
rl training, epoch2, iter0, batch1/1133, batch loss:0.0006202775985002518, Training time:33828.459045410156
batch reward last col mean 1.4126561609373312e-07 first col mean 0.0024839884135872126 all mean 0.0002577829291112721
0.0009251072769984603 0.0009251073352061212
rl training, epoch2, iter0, batch2/1133, batch loss:0.0009251073352061212, Training time:33845.28775525093
batch reward last col mean 2.6986890588887036e-06 first col mean 0.0011015583295375109 all mean 0.00017296207079198211
0.0006375504308380187 0.0006375503726303577
rl training, epoch2, iter0, batch3/1133, batch loss:0.0006375503726303577, Training time:33862.08853292465
batch reward last col mean 3.5951438803749625e-07 first col mean 0.002710894914343953 all mean 0.00015697583148721606
0.0005496590165421367 0.0005496590165421367
rl training, epoch2, iter0, batch4/1133, batch loss:0.0005496590165421367, Training time:33879.38817691803
batch reward last col mean 2.3364148091786774e-06 first col mean 0.0009324158891104162 all mean 0.0004267031326889992
0.0013266358291730285 0.0013266358291730285
rl training, epoch2, iter0, batch5/1133, batch loss:0.0013266358291730285, Training time:33896.29099011421
batch reward last col mean 4.209452981740469e-07 first col mean 0.00027759268414229155 all mean 5.2204337407602e-05
9.699551446828991e-05 9.699551446828991e-05
rl training, epoch2, iter0, batch6/1133, batch loss:9.699551446828991e-05, Training time:33913.25156211853
batch reward last col mean 7.501993968617171e-05 first col mean 6.427924745366909e-06 all mean 0.00016177791985683143
0.0003009223728440702 0.0003009223728440702
rl training, epoch2, iter0, batch7/1133, batch loss:0.0003009223728440702, Training time:33929.91381192207
batch reward last col mean 2.551188060806453e-07 first col mean 0.004080821759998798 all mean 0.00015862380678299814
0.0005400392110459507 0.0005400392110459507
rl training, epoch2, iter0, batch8/1133, batch loss:0.0005400392110459507, Training time:33946.724210977554
batch reward last col mean 1.3573128399002599e-06 first col mean 0.0020235448610037565 all mean 9.180171036859974e-05
0.00019908214744646102 0.00019908214744646102
rl training, epoch2, iter0, batch9/1133, batch loss:0.00019908214744646102, Training time:33963.5510904789
batch reward last col mean 1.5095417893462582e-06 first col mean 0.0008267450029961765 all mean 0.00010759498400148004
0.00021643124637193978 0.00021643123182002455
rl training, epoch2, iter0, batch10/1133, batch loss:0.00021643123182002455, Training time:33980.46053338051
batch reward last col mean 2.5431705580558628e-05 first col mean 0.003375024301931262 all mean 0.0002764489618130028
0.0007611885666847229 0.0007611885666847229
rl training, epoch2, iter0, batch11/1133, batch loss:0.0007611885666847229, Training time:33997.4611518383
batch reward last col mean 0.0011032357579097152 first col mean 0.001738978549838066 all mean 0.0012252439046278596
0.00047442715731449425 0.00047442715731449425
rl training, epoch2, iter0, batch12/1133, batch loss:0.00047442715731449425, Training time:34014.41280388832
batch reward last col mean 0.007540357764810324 first col mean 0.00031831199885345995 all mean 0.007115342188626528
0.0012605939991772175 0.0012605942320078611
rl training, epoch2, iter0, batch13/1133, batch loss:0.0012605942320078611, Training time:34031.44905233383
batch reward last col mean 5.635697380057536e-05 first col mean 2.911939736804925e-05 all mean 0.0001087058917619288
0.0002727487008087337 0.0002727487008087337
rl training, epoch2, iter0, batch14/1133, batch loss:0.0002727487008087337, Training time:34048.35701775551
batch reward last col mean 1.8601494389258733e-07 first col mean 0.001909156097099185 all mean 0.00027727591805160046
0.0007349629886448383 0.0007349629886448383
rl training, epoch2, iter0, batch15/1133, batch loss:0.0007349629886448383, Training time:34065.78444647789
batch reward last col mean 3.0729452191735618e-06 first col mean 2.540008608775679e-05 all mean 7.279017881955951e-05
0.0001907962141558528 0.0001907962141558528
rl training, epoch2, iter0, batch16/1133, batch loss:0.0001907962141558528, Training time:34082.84382247925
batch reward last col mean 0.0072373137809336185 first col mean 0.0026683651376515627 all mean 0.006649928633123636
0.0007331461529247463 0.0007331462111324072
rl training, epoch2, iter0, batch17/1133, batch loss:0.0007331462111324072, Training time:34099.71913743019
batch reward last col mean 5.720389140151383e-07 first col mean 0.002843212801963091 all mean 0.00015550840180367231
0.00040090372203849256 0.00040090372203849256
rl training, epoch2, iter0, batch18/1133, batch loss:0.00040090372203849256, Training time:34116.67138504982
batch reward last col mean 2.134139549525571e-07 first col mean 0.003054375760257244 all mean 9.531262185191736e-05
6.980108446441591e-05 6.980108446441591e-05
rl training, epoch2, iter0, batch19/1133, batch loss:6.980108446441591e-05, Training time:34133.46553039551
batch reward last col mean 1.6464142618133337e-06 first col mean 0.002502875868231058 all mean 0.000396951858419925
0.0015098509611561894 0.0015098509611561894
rl training, epoch2, iter0, batch20/1133, batch loss:0.0015098509611561894, Training time:34150.3924407959
batch reward last col mean 0.00503428652882576 first col mean 0.0023266186472028494 all mean 0.0049882312305271626
0.0006695948541164398 0.0006695948541164398
rl training, epoch2, iter0, batch21/1133, batch loss:0.0006695948541164398, Training time:34167.70449471474
batch reward last col mean 3.515352773320046e-07 first col mean 0.0028530415147542953 all mean 5.172137025510892e-05
0.00010050872515421361 0.00010050871787825599
rl training, epoch2, iter0, batch22/1133, batch loss:0.00010050871787825599, Training time:34184.440784454346
batch reward last col mean 5.1850511226803064e-06 first col mean 0.0032352684065699577 all mean 0.00017349222616758198
0.0004082911182194948 0.00040829108911566436
rl training, epoch2, iter0, batch23/1133, batch loss:0.00040829108911566436, Training time:34202.740849494934
batch reward last col mean 3.6075620300835e-05 first col mean 0.0009719670051708817 all mean 0.00019229976169299334
0.00040798907866701484 0.00040798907866701484
rl training, epoch2, iter0, batch24/1133, batch loss:0.00040798907866701484, Training time:34219.235029459
batch reward last col mean 1.8815293856278004e-07 first col mean 0.004140965640544891 all mean 0.00032369137625209987
0.0007741876761429012 0.0007741876761429012
rl training, epoch2, iter0, batch25/1133, batch loss:0.0007741876761429012, Training time:34236.24219441414
batch reward last col mean 0.005830428563058376 first col mean 0.0039210510440170765 all mean 0.00579453120008111
0.002063629450276494 0.0020636299159377813
rl training, epoch2, iter0, batch26/1133, batch loss:0.0020636299159377813, Training time:34254.22076296806
batch reward last col mean 0.009073533117771149 first col mean 0.004523345734924078 all mean 0.008443052880465984
0.0011625983752310276 0.0011625982588157058
rl training, epoch2, iter0, batch27/1133, batch loss:0.0011625982588157058, Training time:34271.481580019
batch reward last col mean 0.0005827031563967466 first col mean 0.0004235017404425889 all mean 0.0008451034082099795
0.0008220733143389225 0.0008220731979236007
rl training, epoch2, iter0, batch28/1133, batch loss:0.0008220731979236007, Training time:34289.01140975952
batch reward last col mean 1.1674724191834684e-05 first col mean 0.001361536211334169 all mean 0.0002695147995837033
0.0005910768522880971 0.0005910768522880971
rl training, epoch2, iter0, batch29/1133, batch loss:0.0005910768522880971, Training time:34306.61469435692
batch reward last col mean 0.00446970434859395 first col mean 0.0023712560068815947 all mean 0.004809621721506119
0.0036821793764829636 0.003682179609313607
rl training, epoch2, iter0, batch30/1133, batch loss:0.003682179609313607, Training time:34324.11355757713
batch reward last col mean 0.000604998494964093 first col mean 0.001883322955109179 all mean 0.0006872556987218559
0.0004047733673360199 0.0004047733382321894
rl training, epoch2, iter0, batch31/1133, batch loss:0.0004047733382321894, Training time:34340.701333999634
batch reward last col mean 0.0006873431266285479 first col mean 0.0002002787368837744 all mean 0.0007195600774139166
0.0005352344596758485 0.0005352344596758485
rl training, epoch2, iter0, batch32/1133, batch loss:0.0005352344596758485, Training time:34357.281774282455
batch reward last col mean 0.0021003687288612127 first col mean 0.010661580599844456 all mean 0.0020519262179732323
0.0014145193854346871 0.0014145193854346871
rl training, epoch2, iter0, batch33/1133, batch loss:0.0014145193854346871, Training time:34373.92090153694
batch reward last col mean 1.434136265743291e-05 first col mean 0.0025658358354121447 all mean 0.00026261559105478227
0.0007701548747718334 0.0007701548165641725
rl training, epoch2, iter0, batch34/1133, batch loss:0.0007701548165641725, Training time:34390.93371748924
batch reward last col mean 0.0071068680845201015 first col mean 0.003774571232497692 all mean 0.006619956810027361
0.0006017668056301773 0.0006017668056301773
rl training, epoch2, iter0, batch35/1133, batch loss:0.0006017668056301773, Training time:34407.83166098595
batch reward last col mean 9.958899909179308e-07 first col mean 0.00018910256039816886 all mean 0.0002350116119487211
0.0006271062884479761 0.0006271062302403152
rl training, epoch2, iter0, batch36/1133, batch loss:0.0006271062302403152, Training time:34424.41989707947
batch reward last col mean 0.010019931010901928 first col mean 0.0061322664842009544 all mean 0.008877637796103954
0.001416633604094386 0.001416633604094386
rl training, epoch2, iter0, batch37/1133, batch loss:0.001416633604094386, Training time:34441.18156838417
batch reward last col mean 7.456023467966588e-06 first col mean 0.0005718849133700132 all mean 0.0005003277910873294
0.001420359592884779 0.0014203592436388135
rl training, epoch2, iter0, batch38/1133, batch loss:0.0014203592436388135, Training time:34457.99490380287
batch reward last col mean 6.841968115622876e-06 first col mean 0.008066129870712757 all mean 0.000179941751412116
0.0002539465785957873 0.0002539465785957873
rl training, epoch2, iter0, batch39/1133, batch loss:0.0002539465785957873, Training time:34474.7769985199
batch reward last col mean 2.2724065274815075e-05 first col mean 0.008218837901949883 all mean 0.000348585017491132
0.0008185968617908657 0.0008185969199985266
rl training, epoch2, iter0, batch40/1133, batch loss:0.0008185969199985266, Training time:34491.752809762955
batch reward last col mean 0.007099138107150793 first col mean 0.005536876618862152 all mean 0.006589554715901613
0.0016700158594176173 0.0016700158594176173
rl training, epoch2, iter0, batch41/1133, batch loss:0.0016700158594176173, Training time:34508.79802894592
batch reward last col mean 2.790791882034682e-07 first col mean 0.0009840547572821379 all mean 0.0002242654445581138
0.0009298429940827191 0.00092984305229038
rl training, epoch2, iter0, batch42/1133, batch loss:0.00092984305229038, Training time:34526.340780735016
batch reward last col mean 0.0038350983522832394 first col mean 0.003997822757810354 all mean 0.0034080659970641136
0.0008981412975117564 0.0008981412975117564
rl training, epoch2, iter0, batch43/1133, batch loss:0.0008981412975117564, Training time:34544.1584277153
batch reward last col mean 1.1666952559608035e-06 first col mean 0.0034706853330135345 all mean 0.00046333158388733864
0.0012744890991598368 0.0012744890991598368
rl training, epoch2, iter0, batch44/1133, batch loss:0.0012744890991598368, Training time:34562.61891412735
batch reward last col mean 8.90844731316065e-08 first col mean 3.148646328554605e-06 all mean 0.00021413082140497863
0.0009618162293918431 0.0009618162293918431
rl training, epoch2, iter0, batch45/1133, batch loss:0.0009618162293918431, Training time:34580.51518559456
batch reward last col mean 0.0062354011461138725 first col mean 0.0020325491204857826 all mean 0.005495183169841766
0.0017878195503726602 0.0017878195503726602
rl training, epoch2, iter0, batch46/1133, batch loss:0.0017878195503726602, Training time:34598.61695981026
batch reward last col mean 6.410552941815695e-07 first col mean 0.0047540380619466305 all mean 0.0002661403559613973
0.0005703933420591056 0.0005703933420591056
rl training, epoch2, iter0, batch47/1133, batch loss:0.0005703933420591056, Training time:34616.22311544418
batch reward last col mean 0.006629114504903555 first col mean 0.0004979109507985413 all mean 0.005339937284588814
0.0014525663573294878 0.001452566240914166
rl training, epoch2, iter0, batch48/1133, batch loss:0.001452566240914166, Training time:34636.27623105049
batch reward last col mean 3.03721634509202e-07 first col mean 0.003892377018928528 all mean 0.00044269399950280786
0.0015160699840635061 0.0015160699840635061
rl training, epoch2, iter0, batch49/1133, batch loss:0.0015160699840635061, Training time:34653.25349235535
batch reward last col mean 0.015048977918922901 first col mean 0.00431904848664999 all mean 0.013595395721495152
0.003036517882719636 0.003036517882719636
rl training, epoch2, iter0, batch50/1133, batch loss:0.003036517882719636, Training time:34670.241743564606
batch reward last col mean 1.1088986866525374e-06 first col mean 0.005546093452721834 all mean 0.0002512589271645993
0.0004878572071902454 0.0004878572071902454
rl training, epoch2, iter0, batch51/1133, batch loss:0.0004878572071902454, Training time:34687.06199121475
batch reward last col mean 0.0044659702107310295 first col mean 0.00358709879219532 all mean 0.0043972632847726345
0.0008865927811712027 0.0008865927811712027
rl training, epoch2, iter0, batch52/1133, batch loss:0.0008865927811712027, Training time:34703.91823339462
batch reward last col mean 4.3059594645455945e-06 first col mean 0.0037426664493978024 all mean 0.00026338305906392634
0.0006449457723647356 0.0006449458305723965
rl training, epoch2, iter0, batch53/1133, batch loss:0.0006449458305723965, Training time:34721.30905485153
batch reward last col mean 1.0301978363713715e-06 first col mean 0.00409166282042861 all mean 0.0005753120058216155
0.0021187327802181244 0.0021187327802181244
rl training, epoch2, iter0, batch54/1133, batch loss:0.0021187327802181244, Training time:34739.11552405357
batch reward last col mean 0.006091811694204807 first col mean 0.0059031532146036625 all mean 0.0055091241374611855
0.0010916012106463313 0.0010916012106463313
rl training, epoch2, iter0, batch55/1133, batch loss:0.0010916012106463313, Training time:34756.22954559326
batch reward last col mean 0.006199239287525415 first col mean 0.0013063345104455948 all mean 0.005582708399742842
0.0011851034360006452 0.0011851033195853233
rl training, epoch2, iter0, batch56/1133, batch loss:0.0011851033195853233, Training time:34773.260944366455
batch reward last col mean 0.005057031754404306 first col mean 0.0019830656237900257 all mean 0.005056786350905895
0.001125702285207808 0.001125702285207808
rl training, epoch2, iter0, batch57/1133, batch loss:0.001125702285207808, Training time:34790.17321777344
batch reward last col mean 4.523032475844957e-05 first col mean 0.005325552076101303 all mean 0.0010136463679373264
0.0028864156920462847 0.0028864159248769283
rl training, epoch2, iter0, batch58/1133, batch loss:0.0028864159248769283, Training time:34807.12862753868
batch reward last col mean 0.0006163325160741806 first col mean 0.0035756404977291822 all mean 0.0010706806788221002
0.0020907691214233637 0.0020907691214233637
rl training, epoch2, iter0, batch59/1133, batch loss:0.0020907691214233637, Training time:34824.413415670395
batch reward last col mean 0.002329165581613779 first col mean 0.004773876629769802 all mean 0.0023606265895068645
0.0013014978030696511 0.0013014978030696511
rl training, epoch2, iter0, batch60/1133, batch loss:0.0013014978030696511, Training time:34841.56746006012
batch reward last col mean 0.005771529860794544 first col mean 0.0011333671864122152 all mean 0.005553586408495903
0.0009194238809868693 0.0009194238809868693
rl training, epoch2, iter0, batch61/1133, batch loss:0.0009194238809868693, Training time:34858.46536421776
batch reward last col mean 0.009574441239237785 first col mean 0.005779060535132885 all mean 0.009170342236757278
0.001010313630104065 0.0010103135136887431
rl training, epoch2, iter0, batch62/1133, batch loss:0.0010103135136887431, Training time:34875.51475572586
batch reward last col mean 2.7164912808075314e-06 first col mean 0.0028401354793459177 all mean 0.00031842998578213155
0.0009633933659642935 0.0009633934241719544
rl training, epoch2, iter0, batch63/1133, batch loss:0.0009633934241719544, Training time:34892.64081335068
batch reward last col mean 0.0010525648249313235 first col mean 0.005470646545290947 all mean 0.0012134189018979669
0.0009320111712440848 0.0009320111712440848
rl training, epoch2, iter0, batch64/1133, batch loss:0.0009320111712440848, Training time:34909.68106389046
batch reward last col mean 1.9839885680994485e-06 first col mean 0.006053074728697538 all mean 0.00015607799286954105
0.0003101943002548069 0.00031019432935863733
rl training, epoch2, iter0, batch65/1133, batch loss:0.00031019432935863733, Training time:34926.7793970108
batch reward last col mean 0.0041138543747365475 first col mean 0.005718968342989683 all mean 0.005793715361505747
0.007344071287661791 0.0073440722189843655
rl training, epoch2, iter0, batch66/1133, batch loss:0.0073440722189843655, Training time:34943.82270669937
batch reward last col mean 0.0029760084580630064 first col mean 0.002324160886928439 all mean 0.0033073406666517258
0.0021221498027443886 0.0021221498027443886
rl training, epoch2, iter0, batch67/1133, batch loss:0.0021221498027443886, Training time:34960.79215717316
batch reward last col mean 0.00048730301205068827 first col mean 0.0032125746365636587 all mean 0.0006757951341569424
0.0006653640884906054 0.0006653640884906054
rl training, epoch2, iter0, batch68/1133, batch loss:0.0006653640884906054, Training time:34977.83652305603
batch reward last col mean 0.011955143883824348 first col mean 0.005219893530011177 all mean 0.01162764523178339
0.004376374650746584 0.004376374650746584
rl training, epoch2, iter0, batch69/1133, batch loss:0.004376374650746584, Training time:34994.852330207825
batch reward last col mean 3.373958679731004e-05 first col mean 0.006753011140972376 all mean 0.0003029910149052739
0.0006624204688705504 0.0006624204688705504
rl training, epoch2, iter0, batch70/1133, batch loss:0.0006624204688705504, Training time:35012.45701313019
batch reward last col mean 0.007080703973770142 first col mean 0.005918540060520172 all mean 0.007273656316101551
0.0032733583357185125 0.0032733583357185125
rl training, epoch2, iter0, batch71/1133, batch loss:0.0032733583357185125, Training time:35030.74458050728
batch reward last col mean 0.01669861562550068 first col mean 0.00370559049770236 all mean 0.016412701457738876
0.0034029693342745304 0.003402969567105174
rl training, epoch2, iter0, batch72/1133, batch loss:0.003402969567105174, Training time:35047.67825293541
batch reward last col mean 0.005853922106325626 first col mean 0.0058697424829006195 all mean 0.00566801056265831
0.0020071810577064753 0.0020071810577064753
rl training, epoch2, iter0, batch73/1133, batch loss:0.0020071810577064753, Training time:35065.25243639946
batch reward last col mean 0.0034102099016308784 first col mean 0.003450414165854454 all mean 0.00334127526730299
0.0012400929117575288 0.0012400929117575288
rl training, epoch2, iter0, batch74/1133, batch loss:0.0012400929117575288, Training time:35083.20033431053
batch reward last col mean 0.01349740568548441 first col mean 0.013675632886588573 all mean 0.013042711652815342
0.004073775839060545 0.004073775839060545
rl training, epoch2, iter0, batch75/1133, batch loss:0.004073775839060545, Training time:35100.27902126312
batch reward last col mean 0.008469709195196629 first col mean 0.008446994237601757 all mean 0.008062897250056267
0.001783552928827703 0.001783552928827703
rl training, epoch2, iter0, batch76/1133, batch loss:0.001783552928827703, Training time:35117.47443628311
batch reward last col mean 0.0027585336938500404 first col mean 0.00296727754175663 all mean 0.003040140029042959
0.0017517487285658717 0.0017517487285658717
rl training, epoch2, iter0, batch77/1133, batch loss:0.0017517487285658717, Training time:35136.37351489067
batch reward last col mean 0.006989397574216127 first col mean 0.006328526884317398 all mean 0.0066574448719620705
0.0027266384568065405 0.0027266384568065405
rl training, epoch2, iter0, batch78/1133, batch loss:0.0027266384568065405, Training time:35153.382675886154
batch reward last col mean 0.009485793299973011 first col mean 0.00733352592214942 all mean 0.008512974716722965
0.001983308233320713 0.001983308233320713
rl training, epoch2, iter0, batch79/1133, batch loss:0.001983308233320713, Training time:35170.4208009243
batch reward last col mean 0.007248226553201675 first col mean 0.008784415200352669 all mean 0.007068975828588009
0.001604782184585929 0.001604782184585929
rl training, epoch2, iter0, batch80/1133, batch loss:0.001604782184585929, Training time:35187.45866107941
batch reward last col mean 0.02203744277358055 first col mean 0.008317560888826847 all mean 0.020941725000739098
0.0031475841533392668 0.0031475841533392668
rl training, epoch2, iter0, batch81/1133, batch loss:0.0031475841533392668, Training time:35204.35311794281
batch reward last col mean 0.008231542073190212 first col mean 0.008065832778811455 all mean 0.00802674237638712
0.0028616979252547026 0.0028616979252547026
rl training, epoch2, iter0, batch82/1133, batch loss:0.0028616979252547026, Training time:35221.28380870819
batch reward last col mean 0.009381145238876343 first col mean 0.005658252164721489 all mean 0.00938136875629425
0.002251771278679371 0.002251771278679371
rl training, epoch2, iter0, batch83/1133, batch loss:0.002251771278679371, Training time:35238.32247543335
batch reward last col mean 0.018134405836462975 first col mean 0.010518594644963741 all mean 0.016537155956029892
0.005737568251788616 0.005737568251788616
rl training, epoch2, iter0, batch84/1133, batch loss:0.005737568251788616, Training time:35255.42103290558
batch reward last col mean 0.003088493598625064 first col mean 0.009139838628470898 all mean 0.003264777595177293
0.0032568781170994043 0.0032568781170994043
rl training, epoch2, iter0, batch85/1133, batch loss:0.0032568781170994043, Training time:35272.51538300514
batch reward last col mean 0.0021955459378659725 first col mean 0.009999931789934635 all mean 0.0032338795717805624
0.0033943881280720234 0.0033943881280720234
rl training, epoch2, iter0, batch86/1133, batch loss:0.0033943881280720234, Training time:35289.561302661896
batch reward last col mean 0.01311883982270956 first col mean 0.005552638787776232 all mean 0.012664313428103924
0.003677217522636056 0.003677218221127987
rl training, epoch2, iter0, batch87/1133, batch loss:0.003677218221127987, Training time:35306.70875930786
batch reward last col mean 0.0012292107567191124 first col mean 0.008768631145358086 all mean 0.0020502577535808086
0.0029179968405514956 0.0029179968405514956
rl training, epoch2, iter0, batch88/1133, batch loss:0.0029179968405514956, Training time:35323.78775191307
batch reward last col mean 0.007006782107055187 first col mean 0.00436815433204174 all mean 0.008024744689464569
0.005663962569087744 0.005663962569087744
rl training, epoch2, iter0, batch89/1133, batch loss:0.005663962569087744, Training time:35340.94537067413
batch reward last col mean 0.009864920750260353 first col mean 0.010796669870615005 all mean 0.009860376827418804
0.002647083019837737 0.002647083019837737
rl training, epoch2, iter0, batch90/1133, batch loss:0.002647083019837737, Training time:35358.09800410271
batch reward last col mean 0.010304796509444714 first col mean 0.009415911510586739 all mean 0.010033266618847847
0.00561084970831871 0.005610848776996136
rl training, epoch2, iter0, batch91/1133, batch loss:0.005610848776996136, Training time:35375.09408760071
batch reward last col mean 0.022330552339553833 first col mean 0.01194087229669094 all mean 0.020648807287216187
0.012267491780221462 0.012267491780221462
rl training, epoch2, iter0, batch92/1133, batch loss:0.012267491780221462, Training time:35391.97396445274
batch reward last col mean 0.02403539977967739 first col mean 0.004469062201678753 all mean 0.023321999236941338
0.005726734641939402 0.005726734641939402
rl training, epoch2, iter0, batch93/1133, batch loss:0.005726734641939402, Training time:35411.04848098755
batch reward last col mean 0.017240509390830994 first col mean 0.007111461367458105 all mean 0.01761467568576336
0.00672893924638629 0.00672893924638629
rl training, epoch2, iter0, batch94/1133, batch loss:0.00672893924638629, Training time:35428.177893161774
batch reward last col mean 0.019784800708293915 first col mean 0.019441761076450348 all mean 0.01920568384230137
0.005269560497254133 0.005269560497254133
rl training, epoch2, iter0, batch95/1133, batch loss:0.005269560497254133, Training time:35445.34278011322
batch reward last col mean 0.003184243105351925 first col mean 0.012751840986311436 all mean 0.0047360933385789394
0.006055452395230532 0.006055452395230532
rl training, epoch2, iter0, batch96/1133, batch loss:0.006055452395230532, Training time:35462.315058231354
batch reward last col mean 0.016900628805160522 first col mean 0.011290209367871284 all mean 0.016004744917154312
0.004109622444957495 0.004109622444957495
rl training, epoch2, iter0, batch97/1133, batch loss:0.004109622444957495, Training time:35479.301700115204
batch reward last col mean 0.02130615897476673 first col mean 0.022031145170331 all mean 0.02178363688290119
0.010423834435641766 0.010423834435641766
rl training, epoch2, iter0, batch98/1133, batch loss:0.010423834435641766, Training time:35496.45814681053
batch reward last col mean 0.02237694524228573 first col mean 0.024356339126825333 all mean 0.022492120042443275
0.007755611091852188 0.007755610626190901
rl training, epoch2, iter0, batch99/1133, batch loss:0.007755610626190901, Training time:35513.57224702835
batch reward last col mean 0.013639614917337894 first col mean 0.030470602214336395 all mean 0.014275907538831234
0.007486632559448481 0.007486632559448481
rl training, epoch2, iter0, batch100/1133, batch loss:0.007486632559448481, Training time:35530.75908279419
batch reward last col mean 0.014326954260468483 first col mean 0.009496643207967281 all mean 0.013971937820315361
0.0038939137011766434 0.0038939137011766434
rl training, epoch2, iter0, batch101/1133, batch loss:0.0038939137011766434, Training time:35547.788437604904
batch reward last col mean 0.019303657114505768 first col mean 0.01811501570045948 all mean 0.01995602436363697
0.007898087613284588 0.007898087613284588
rl training, epoch2, iter0, batch102/1133, batch loss:0.007898087613284588, Training time:35564.90865278244
batch reward last col mean 0.03305128961801529 first col mean 0.026899417862296104 all mean 0.03189394623041153
0.014026972465217113 0.014026972465217113
rl training, epoch2, iter0, batch103/1133, batch loss:0.014026972465217113, Training time:35584.153384923935
batch reward last col mean 0.04623265564441681 first col mean 0.02480991743505001 all mean 0.04459911584854126
0.01220426894724369 0.01220426894724369
rl training, epoch2, iter0, batch104/1133, batch loss:0.01220426894724369, Training time:35601.4651362896
batch reward last col mean 0.017141124233603477 first col mean 0.023905787616968155 all mean 0.01952187903225422
0.01621118187904358 0.01621118187904358
rl training, epoch2, iter0, batch105/1133, batch loss:0.01621118187904358, Training time:35618.70918464661
batch reward last col mean 0.032579340040683746 first col mean 0.02414242923259735 all mean 0.03295278921723366
0.01451118104159832 0.01451117917895317
rl training, epoch2, iter0, batch106/1133, batch loss:0.01451117917895317, Training time:35635.84863162041
batch reward last col mean 0.008144121617078781 first col mean 0.02239544689655304 all mean 0.010920471511781216
0.013362210243940353 0.013362208381295204
rl training, epoch2, iter0, batch107/1133, batch loss:0.013362208381295204, Training time:35653.07361745834
batch reward last col mean 0.03321018069982529 first col mean 0.032168470323085785 all mean 0.0325535349547863
0.022314133122563362 0.022314133122563362
rl training, epoch2, iter0, batch108/1133, batch loss:0.022314133122563362, Training time:35670.229625463486
batch reward last col mean 0.04569685086607933 first col mean 0.039697688072919846 all mean 0.043724000453948975
0.018489567562937737 0.018489567562937737
rl training, epoch2, iter0, batch109/1133, batch loss:0.018489567562937737, Training time:35687.30411529541
batch reward last col mean 0.028875818476080894 first col mean 0.04970221221446991 all mean 0.02955654263496399
0.020864615216851234 0.020864613354206085
rl training, epoch2, iter0, batch110/1133, batch loss:0.020864613354206085, Training time:35704.389167547226
batch reward last col mean 0.02466302365064621 first col mean 0.04918202757835388 all mean 0.026675399392843246
0.023528730496764183 0.023528730496764183
rl training, epoch2, iter0, batch111/1133, batch loss:0.023528730496764183, Training time:35721.54941058159
batch reward last col mean 0.00895620882511139 first col mean 0.024918030947446823 all mean 0.011278390884399414
0.011259756051003933 0.011259756051003933
rl training, epoch2, iter0, batch112/1133, batch loss:0.011259756051003933, Training time:35738.759570121765
batch reward last col mean 0.026799093931913376 first col mean 0.034262873232364655 all mean 0.027883023023605347
0.02169065549969673 0.02169065549969673
rl training, epoch2, iter0, batch113/1133, batch loss:0.02169065549969673, Training time:35756.52526092529
batch reward last col mean 0.07152573019266129 first col mean 0.0382576622068882 all mean 0.0699540227651596
0.023843219503760338 0.023843219503760338
rl training, epoch2, iter0, batch114/1133, batch loss:0.023843219503760338, Training time:35773.95553946495
batch reward last col mean 0.06543347239494324 first col mean 0.05486588552594185 all mean 0.06415461748838425
0.02331605926156044 0.02331605926156044
rl training, epoch2, iter0, batch115/1133, batch loss:0.02331605926156044, Training time:35791.233189344406
batch reward last col mean 0.049812380224466324 first col mean 0.0509120412170887 all mean 0.049921128898859024
0.025274835526943207 0.025274835526943207
rl training, epoch2, iter0, batch116/1133, batch loss:0.025274835526943207, Training time:35808.409740924835
batch reward last col mean 0.03303542733192444 first col mean 0.04603009670972824 all mean 0.03538752719759941
0.023844026029109955 0.023844022303819656
rl training, epoch2, iter0, batch117/1133, batch loss:0.023844022303819656, Training time:35825.875571489334
batch reward last col mean 0.05238576978445053 first col mean 0.04926701635122299 all mean 0.05253402516245842
0.025399358943104744 0.025399358943104744
rl training, epoch2, iter0, batch118/1133, batch loss:0.025399358943104744, Training time:35843.17720365524
batch reward last col mean 0.04006589949131012 first col mean 0.04040657728910446 all mean 0.03928319737315178
0.01673871837556362 0.01673871837556362
rl training, epoch2, iter0, batch119/1133, batch loss:0.01673871837556362, Training time:35860.302402973175
batch reward last col mean 0.062044981867074966 first col mean 0.06180195510387421 all mean 0.06238684803247452
0.024288160726428032 0.024288157001137733
rl training, epoch2, iter0, batch120/1133, batch loss:0.024288157001137733, Training time:35877.61639523506
batch reward last col mean 0.060811661183834076 first col mean 0.05098812282085419 all mean 0.06040997430682182
0.0333419032394886 0.0333419032394886
rl training, epoch2, iter0, batch121/1133, batch loss:0.0333419032394886, Training time:35894.758009433746
batch reward last col mean 0.040920257568359375 first col mean 0.04508429020643234 all mean 0.04057781770825386
0.020324377343058586 0.020324375480413437
rl training, epoch2, iter0, batch122/1133, batch loss:0.020324375480413437, Training time:35912.110958099365
batch reward last col mean 0.046355269849300385 first col mean 0.045030318200588226 all mean 0.04551496356725693
0.019561076536774635 0.019561076536774635
rl training, epoch2, iter0, batch123/1133, batch loss:0.019561076536774635, Training time:35931.12873888016
batch reward last col mean 0.046994052827358246 first col mean 0.05032983794808388 all mean 0.04759849235415459
0.033530279994010925 0.033530279994010925
rl training, epoch2, iter0, batch124/1133, batch loss:0.033530279994010925, Training time:35948.80126309395
batch reward last col mean 0.08893024921417236 first col mean 0.06903648376464844 all mean 0.08793523907661438
0.03996643051505089 0.03996643051505089
rl training, epoch2, iter0, batch125/1133, batch loss:0.03996643051505089, Training time:35966.32200026512
batch reward last col mean 0.061369530856609344 first col mean 0.05595635250210762 all mean 0.06020236760377884
0.03856690227985382 0.03856690227985382
rl training, epoch2, iter0, batch126/1133, batch loss:0.03856690227985382, Training time:35983.78511738777
batch reward last col mean 0.065671406686306 first col mean 0.07460159063339233 all mean 0.06603790819644928
0.035172995179891586 0.035172995179891586
rl training, epoch2, iter0, batch127/1133, batch loss:0.035172995179891586, Training time:36001.35092186928
batch reward last col mean 0.10558062046766281 first col mean 0.09983109682798386 all mean 0.10466782003641129
0.06152137368917465 0.06152137368917465
rl training, epoch2, iter0, batch128/1133, batch loss:0.06152137368917465, Training time:36018.934292793274
batch reward last col mean 0.07647363096475601 first col mean 0.07540818303823471 all mean 0.07563399523496628
0.04553060233592987 0.04553060233592987
rl training, epoch2, iter0, batch129/1133, batch loss:0.04553060233592987, Training time:36036.433995485306
batch reward last col mean 0.10108251869678497 first col mean 0.0587988942861557 all mean 0.09720049798488617
0.03830859065055847 0.03830859065055847
rl training, epoch2, iter0, batch130/1133, batch loss:0.03830859065055847, Training time:36053.98158144951
batch reward last col mean 0.08690299093723297 first col mean 0.08475073426961899 all mean 0.08685201406478882
0.052941497415304184 0.052941497415304184
rl training, epoch2, iter0, batch131/1133, batch loss:0.052941497415304184, Training time:36071.57895231247
batch reward last col mean 0.0591982863843441 first col mean 0.05749174952507019 all mean 0.058482881635427475
0.028712866827845573 0.028712866827845573
rl training, epoch2, iter0, batch132/1133, batch loss:0.028712866827845573, Training time:36089.10862827301
batch reward last col mean 0.07940226793289185 first col mean 0.0693829134106636 all mean 0.07992517948150635
0.05663524568080902 0.05663524568080902
rl training, epoch2, iter0, batch133/1133, batch loss:0.05663524568080902, Training time:36106.82385993004
batch reward last col mean 0.07210630178451538 first col mean 0.08917848765850067 all mean 0.07348199933767319
0.0447084940969944 0.0447084940969944
rl training, epoch2, iter0, batch134/1133, batch loss:0.0447084940969944, Training time:36124.2813475132
batch reward last col mean 0.10456711053848267 first col mean 0.08066529035568237 all mean 0.10493302345275879
0.06420275568962097 0.06420275568962097
rl training, epoch2, iter0, batch135/1133, batch loss:0.06420275568962097, Training time:36141.884467840195
batch reward last col mean 0.08842285722494125 first col mean 0.0916932076215744 all mean 0.09116149693727493
0.06445831805467606 0.06445831060409546
rl training, epoch2, iter0, batch136/1133, batch loss:0.06445831060409546, Training time:36159.54543495178
batch reward last col mean 0.08203388750553131 first col mean 0.10217828303575516 all mean 0.0829903781414032
0.06517330557107925 0.06517330557107925
rl training, epoch2, iter0, batch137/1133, batch loss:0.06517330557107925, Training time:36177.04398345947
batch reward last col mean 0.1234358549118042 first col mean 0.09197651594877243 all mean 0.11913397908210754
0.0829382836818695 0.0829382836818695
rl training, epoch2, iter0, batch138/1133, batch loss:0.0829382836818695, Training time:36196.5288977623
batch reward last col mean 0.09781511127948761 first col mean 0.07934752106666565 all mean 0.09831483662128448
0.0665944516658783 0.0665944516658783
rl training, epoch2, iter0, batch139/1133, batch loss:0.0665944516658783, Training time:36214.12804865837
batch reward last col mean 0.08522504568099976 first col mean 0.1162501871585846 all mean 0.08735410124063492
0.060732949525117874 0.060732949525117874
rl training, epoch2, iter0, batch140/1133, batch loss:0.060732949525117874, Training time:36231.88775014877
batch reward last col mean 0.11930180341005325 first col mean 0.1643606573343277 all mean 0.12278080731630325
0.09107397496700287 0.09107396751642227
rl training, epoch2, iter0, batch141/1133, batch loss:0.09107396751642227, Training time:36249.64397954941
batch reward last col mean 0.09268032759428024 first col mean 0.10183504968881607 all mean 0.0938311517238617
0.07177355140447617 0.07177355140447617
rl training, epoch2, iter0, batch142/1133, batch loss:0.07177355140447617, Training time:36267.35693717003
batch reward last col mean 0.13949468731880188 first col mean 0.14001943171024323 all mean 0.14089520275592804
0.12740571796894073 0.12740571796894073
rl training, epoch2, iter0, batch143/1133, batch loss:0.12740571796894073, Training time:36285.1136906147
batch reward last col mean 0.153126060962677 first col mean 0.14906148612499237 all mean 0.14984697103500366
0.15129725635051727 0.15129725635051727
rl training, epoch2, iter0, batch144/1133, batch loss:0.15129725635051727, Training time:36302.81396651268
batch reward last col mean 0.14055012166500092 first col mean 0.16237562894821167 all mean 0.14130625128746033
0.12358096987009048 0.12358096987009048
rl training, epoch2, iter0, batch145/1133, batch loss:0.12358096987009048, Training time:36320.685725450516
batch reward last col mean 0.18117298185825348 first col mean 0.1649072766304016 all mean 0.17955122888088226
0.18927785754203796 0.18927785754203796
rl training, epoch2, iter0, batch146/1133, batch loss:0.18927785754203796, Training time:36339.17359662056
batch reward last col mean 0.2098446786403656 first col mean 0.17083479464054108 all mean 0.206825390458107
0.2445477545261383 0.2445477545261383
rl training, epoch2, iter0, batch147/1133, batch loss:0.2445477545261383, Training time:36356.9931409359
batch reward last col mean 0.1433466076850891 first col mean 0.17018181085586548 all mean 0.14827953279018402
0.23549985885620117 0.23549985885620117
rl training, epoch2, iter0, batch148/1133, batch loss:0.23549985885620117, Training time:36374.77789926529
batch reward last col mean 0.206447571516037 first col mean 0.2121334969997406 all mean 0.2054348737001419
0.3316126763820648 0.3316126763820648
rl training, epoch2, iter0, batch149/1133, batch loss:0.3316126763820648, Training time:36392.88957452774
batch reward last col mean 0.16974347829818726 first col mean 0.19792455434799194 all mean 0.17207255959510803
0.2975701689720154 0.2975701689720154
rl training, epoch2, iter0, batch150/1133, batch loss:0.2975701689720154, Training time:36410.77488899231
batch reward last col mean 0.24743704497814178 first col mean 0.21833699941635132 all mean 0.248842254281044
0.565180778503418 0.565180778503418
rl training, epoch2, iter0, batch151/1133, batch loss:0.565180778503418, Training time:36428.638283491135
batch reward last col mean 0.20686423778533936 first col mean 0.25331398844718933 all mean 0.20892499387264252
0.46794411540031433 0.46794411540031433
rl training, epoch2, iter0, batch152/1133, batch loss:0.46794411540031433, Training time:36447.74850654602
batch reward last col mean 0.2778557240962982 first col mean 0.2692815065383911 all mean 0.27500060200691223
0.4928176999092102 0.49281764030456543
rl training, epoch2, iter0, batch153/1133, batch loss:0.49281764030456543, Training time:36466.04023528099
batch reward last col mean 0.22098103165626526 first col mean 0.23871055245399475 all mean 0.2250373363494873
0.6666758060455322 0.6666758060455322
rl training, epoch2, iter0, batch154/1133, batch loss:0.6666758060455322, Training time:36482.19362258911
batch reward last col mean 0.22812309861183167 first col mean 0.2347830832004547 all mean 0.22937990725040436
0.7062838077545166 0.7062838077545166
rl training, epoch2, iter0, batch155/1133, batch loss:0.7062838077545166, Training time:36498.89478993416
batch reward last col mean 0.28565704822540283 first col mean 0.26633208990097046 all mean 0.28068962693214417
0.7625769972801208 0.7625769972801208
rl training, epoch2, iter0, batch156/1133, batch loss:0.7625769972801208, Training time:36505.58103966713
batch reward last col mean 0.3012270927429199 first col mean 0.25050559639930725 all mean 0.2997329533100128
0.734375 0.734375
rl training, epoch2, iter0, batch157/1133, batch loss:0.734375, Training time:36519.80393266678
batch reward last col mean 0.2705210745334625 first col mean 0.2874374985694885 all mean 0.2702188491821289
0.8232601881027222 0.8232601881027222
rl training, epoch2, iter0, batch158/1133, batch loss:0.8232601881027222, Training time:36536.01956295967
batch reward last col mean 0.28687041997909546 first col mean 0.26897475123405457 all mean 0.2844711244106293
0.75242680311203 0.75242680311203
rl training, epoch2, iter0, batch159/1133, batch loss:0.75242680311203, Training time:36548.876506567
batch reward last col mean 0.25388914346694946 first col mean 0.2659142315387726 all mean 0.26313233375549316
0.8270115852355957 0.8270115852355957
rl training, epoch2, iter0, batch160/1133, batch loss:0.8270115852355957, Training time:36551.65595459938
batch reward last col mean 0.2752837538719177 first col mean 0.30256032943725586 all mean 0.27540919184684753
0.6868417263031006 0.6868417263031006
rl training, epoch2, iter0, batch161/1133, batch loss:0.6868417263031006, Training time:36557.13420653343
batch reward last col mean 0.3426697850227356 first col mean 0.3144642114639282 all mean 0.3386635482311249
0.8414022922515869 0.8414022922515869
rl training, epoch2, iter0, batch162/1133, batch loss:0.8414022922515869, Training time:36570.973170518875
batch reward last col mean 0.3306189477443695 first col mean 0.308235228061676 all mean 0.3290056586265564
0.8497863411903381 0.8497862815856934
rl training, epoch2, iter0, batch163/1133, batch loss:0.8497862815856934, Training time:36583.75348711014
batch reward last col mean 0.30291542410850525 first col mean 0.3138129711151123 all mean 0.3030618727207184
0.7894730567932129 0.7894730567932129
rl training, epoch2, iter0, batch164/1133, batch loss:0.7894730567932129, Training time:36591.60931253433
batch reward last col mean 0.2615787386894226 first col mean 0.2943032383918762 all mean 0.26436010003089905
0.7562564015388489 0.7562563419342041
rl training, epoch2, iter0, batch165/1133, batch loss:0.7562563419342041, Training time:36602.172062397
batch reward last col mean 0.2857362926006317 first col mean 0.30828097462654114 all mean 0.28650224208831787
0.7629164457321167 0.7629163861274719
rl training, epoch2, iter0, batch166/1133, batch loss:0.7629163861274719, Training time:36606.92341756821
batch reward last col mean 0.3579232394695282 first col mean 0.30811142921447754 all mean 0.3482664227485657
1.0057594776153564 1.005759596824646
rl training, epoch2, iter0, batch167/1133, batch loss:1.005759596824646, Training time:36610.38507795334
batch reward last col mean 0.3281201422214508 first col mean 0.2851056456565857 all mean 0.32563114166259766
0.9477353692054749 0.9477353692054749
rl training, epoch2, iter0, batch168/1133, batch loss:0.9477353692054749, Training time:36614.39287352562
batch reward last col mean 0.31357911229133606 first col mean 0.32511118054389954 all mean 0.31634271144866943
0.9901441931724548 0.9901441335678101
rl training, epoch2, iter0, batch169/1133, batch loss:0.9901441335678101, Training time:36618.82610154152
batch reward last col mean 0.32975661754608154 first col mean 0.30390065908432007 all mean 0.32186979055404663
0.9482377171516418 0.9482377171516418
rl training, epoch2, iter0, batch170/1133, batch loss:0.9482377171516418, Training time:36621.48817610741
batch reward last col mean 0.31296876072883606 first col mean 0.3058120012283325 all mean 0.31242111325263977
0.9776677489280701 0.9776677489280701
rl training, epoch2, iter0, batch171/1133, batch loss:0.9776677489280701, Training time:36624.02798581123
batch reward last col mean 0.2854727506637573 first col mean 0.3145757019519806 all mean 0.28846275806427
0.9987539649009705 0.9987540245056152
rl training, epoch2, iter0, batch172/1133, batch loss:0.9987540245056152, Training time:36628.417100191116
batch reward last col mean 0.2991136312484741 first col mean 0.3177277743816376 all mean 0.2971133589744568
1.0345032215118408 1.0345032215118408
rl training, epoch2, iter0, batch173/1133, batch loss:1.0345032215118408, Training time:36631.331129312515
batch reward last col mean 0.32102170586586 first col mean 0.3151353597640991 all mean 0.32174497842788696
1.0611766576766968 1.0611765384674072
rl training, epoch2, iter0, batch174/1133, batch loss:1.0611765384674072, Training time:36634.301355838776
batch reward last col mean 0.3280620872974396 first col mean 0.2785083055496216 all mean 0.32490476965904236
1.122875690460205 1.122875690460205
rl training, epoch2, iter0, batch175/1133, batch loss:1.122875690460205, Training time:36636.67640852928
batch reward last col mean 0.3170798420906067 first col mean 0.3194553852081299 all mean 0.3231101334095001
1.1353727579116821 1.1353727579116821
rl training, epoch2, iter0, batch176/1133, batch loss:1.1353727579116821, Training time:36639.48898243904
batch reward last col mean 0.32186293601989746 first col mean 0.3060609996318817 all mean 0.31612902879714966
1.1264466047286987 1.1264466047286987
rl training, epoch2, iter0, batch177/1133, batch loss:1.1264466047286987, Training time:36642.35360002518
batch reward last col mean 0.25340718030929565 first col mean 0.3034997284412384 all mean 0.26148825883865356
0.9929720163345337 0.9929720163345337
rl training, epoch2, iter0, batch178/1133, batch loss:0.9929720163345337, Training time:36646.17886328697
batch reward last col mean 0.3574444055557251 first col mean 0.30714261531829834 all mean 0.34409084916114807
1.1591066122055054 1.1591066122055054
rl training, epoch2, iter0, batch179/1133, batch loss:1.1591066122055054, Training time:36649.00467085838
batch reward last col mean 0.22900328040122986 first col mean 0.26703038811683655 all mean 0.23236732184886932
0.8680294752120972 0.8680294752120972
rl training, epoch2, iter0, batch180/1133, batch loss:0.8680294752120972, Training time:36652.04618167877
batch reward last col mean 0.24362128973007202 first col mean 0.2593538165092468 all mean 0.24683891236782074
0.9355089664459229 0.9355090260505676
rl training, epoch2, iter0, batch181/1133, batch loss:0.9355090260505676, Training time:36654.73980498314
batch reward last col mean 0.29257702827453613 first col mean 0.2913174629211426 all mean 0.2900649309158325
0.9359950423240662 0.9359951019287109
rl training, epoch2, iter0, batch182/1133, batch loss:0.9359951019287109, Training time:36657.73576068878
batch reward last col mean 0.30153530836105347 first col mean 0.28971168398857117 all mean 0.29235613346099854
0.9806475043296814 0.9806474447250366
rl training, epoch2, iter0, batch183/1133, batch loss:0.9806474447250366, Training time:36660.688839673996
batch reward last col mean 0.2594956159591675 first col mean 0.2688548266887665 all mean 0.2574152648448944
0.8517292141914368 0.8517292141914368
rl training, epoch2, iter0, batch184/1133, batch loss:0.8517292141914368, Training time:36664.92363405228
batch reward last col mean 0.3201445937156677 first col mean 0.28615039587020874 all mean 0.31667929887771606
1.0857070684432983 1.0857070684432983
rl training, epoch2, iter0, batch185/1133, batch loss:1.0857070684432983, Training time:36668.46062541008
batch reward last col mean 0.24026085436344147 first col mean 0.27810436487197876 all mean 0.24647170305252075
0.8299583196640015 0.8299583196640015
rl training, epoch2, iter0, batch186/1133, batch loss:0.8299583196640015, Training time:36672.833127975464
batch reward last col mean 0.2242577224969864 first col mean 0.2573886513710022 all mean 0.2349073886871338
0.8552943468093872 0.8552943468093872
rl training, epoch2, iter0, batch187/1133, batch loss:0.8552943468093872, Training time:36675.892023563385
batch reward last col mean 0.2786096930503845 first col mean 0.27561548352241516 all mean 0.2836751639842987
0.9913505911827087 0.9913505911827087
rl training, epoch2, iter0, batch188/1133, batch loss:0.9913505911827087, Training time:36682.034618616104
batch reward last col mean 0.3157169818878174 first col mean 0.32765093445777893 all mean 0.3181574046611786
1.1204785108566284 1.1204785108566284
rl training, epoch2, iter0, batch189/1133, batch loss:1.1204785108566284, Training time:36688.10494208336
batch reward last col mean 0.2850072681903839 first col mean 0.30851924419403076 all mean 0.2832074463367462
0.994072437286377 0.994072437286377
rl training, epoch2, iter0, batch190/1133, batch loss:0.994072437286377, Training time:36693.91575360298
batch reward last col mean 0.307089626789093 first col mean 0.30313605070114136 all mean 0.30828657746315
1.057010531425476 1.057010531425476
rl training, epoch2, iter0, batch191/1133, batch loss:1.057010531425476, Training time:36698.05974841118
batch reward last col mean 0.30137255787849426 first col mean 0.3079655170440674 all mean 0.30654650926589966
1.012479543685913 1.012479543685913
rl training, epoch2, iter0, batch192/1133, batch loss:1.012479543685913, Training time:36702.46888375282
batch reward last col mean 0.28660646080970764 first col mean 0.28906866908073425 all mean 0.2829405665397644
1.1418317556381226 1.1418317556381226
rl training, epoch2, iter0, batch193/1133, batch loss:1.1418317556381226, Training time:36710.751324892044
batch reward last col mean 0.32283836603164673 first col mean 0.3009069859981537 all mean 0.32222577929496765
1.179431676864624 1.179431676864624
rl training, epoch2, iter0, batch194/1133, batch loss:1.179431676864624, Training time:36715.61315584183
batch reward last col mean 0.2907540202140808 first col mean 0.32910221815109253 all mean 0.29507213830947876
1.19647216796875 1.1964722871780396
rl training, epoch2, iter0, batch195/1133, batch loss:1.1964722871780396, Training time:36721.303765296936
batch reward last col mean 0.28310370445251465 first col mean 0.31472769379615784 all mean 0.2842704653739929
1.0736582279205322 1.0736582279205322
rl training, epoch2, iter0, batch196/1133, batch loss:1.0736582279205322, Training time:36728.100437641144
batch reward last col mean 0.30771109461784363 first col mean 0.31394413113594055 all mean 0.306753009557724
1.095426082611084 1.095426082611084
rl training, epoch2, iter0, batch197/1133, batch loss:1.095426082611084, Training time:36740.15629529953
batch reward last col mean 0.2821139097213745 first col mean 0.3167400062084198 all mean 0.27750903367996216
1.1344270706176758 1.1344270706176758
rl training, epoch2, iter0, batch198/1133, batch loss:1.1344270706176758, Training time:36747.15351366997
batch reward last col mean 0.3063487410545349 first col mean 0.3409581482410431 all mean 0.30299806594848633
1.22422456741333 1.22422456741333
rl training, epoch2, iter0, batch199/1133, batch loss:1.22422456741333, Training time:36754.66950249672
batch reward last col mean 0.26621851325035095 first col mean 0.2905770242214203 all mean 0.2750030755996704
1.0949304103851318 1.0949304103851318
rl training, epoch2, iter0, batch200/1133, batch loss:1.0949304103851318, Training time:36762.55335044861
batch reward last col mean 0.2903496026992798 first col mean 0.31082645058631897 all mean 0.2995728850364685
1.1303272247314453 1.1303272247314453
rl training, epoch2, iter0, batch201/1133, batch loss:1.1303272247314453, Training time:36767.86907696724
batch reward last col mean 0.2900931239128113 first col mean 0.2937164604663849 all mean 0.28982433676719666
1.110392451286316 1.110392451286316
rl training, epoch2, iter0, batch202/1133, batch loss:1.110392451286316, Training time:36772.78873348236
batch reward last col mean 0.29596003890037537 first col mean 0.3155413866043091 all mean 0.29560044407844543
0.9827690124511719 0.9827690124511719
rl training, epoch2, iter0, batch203/1133, batch loss:0.9827690124511719, Training time:36777.67425727844
batch reward last col mean 0.32142385840415955 first col mean 0.29927292466163635 all mean 0.313955694437027
1.0696991682052612 1.0696991682052612
rl training, epoch2, iter0, batch204/1133, batch loss:1.0696991682052612, Training time:36785.80652976036
batch reward last col mean 0.31288060545921326 first col mean 0.2779802680015564 all mean 0.3117888867855072
1.2180838584899902 1.2180838584899902
rl training, epoch2, iter0, batch205/1133, batch loss:1.2180838584899902, Training time:36795.278294086456
batch reward last col mean 0.3171745538711548 first col mean 0.3123229742050171 all mean 0.3195752501487732
1.2424639463424683 1.2424639463424683
rl training, epoch2, iter0, batch206/1133, batch loss:1.2424639463424683, Training time:36801.20373558998
batch reward last col mean 0.2842719554901123 first col mean 0.31494036316871643 all mean 0.2856975495815277
1.131876826286316 1.131876826286316
rl training, epoch2, iter0, batch207/1133, batch loss:1.131876826286316, Training time:36809.679604530334
batch reward last col mean 0.31366217136383057 first col mean 0.30179089307785034 all mean 0.313189297914505
1.1118465662002563 1.1118465662002563
rl training, epoch2, iter0, batch208/1133, batch loss:1.1118465662002563, Training time:36816.181830883026
batch reward last col mean 0.3167412281036377 first col mean 0.3290916681289673 all mean 0.31903716921806335
1.237898588180542 1.237898588180542
rl training, epoch2, iter0, batch209/1133, batch loss:1.237898588180542, Training time:36824.04245710373
batch reward last col mean 0.3086729347705841 first col mean 0.33947426080703735 all mean 0.3152775466442108
1.1608065366744995 1.16080641746521
rl training, epoch2, iter0, batch210/1133, batch loss:1.16080641746521, Training time:36837.32792139053
batch reward last col mean 0.31659799814224243 first col mean 0.32520151138305664 all mean 0.3132021725177765
1.2103323936462402 1.2103323936462402
rl training, epoch2, iter0, batch211/1133, batch loss:1.2103323936462402, Training time:36847.31399059296
batch reward last col mean 0.3214872479438782 first col mean 0.30999746918678284 all mean 0.31999412178993225
1.2115870714187622 1.2115869522094727
rl training, epoch2, iter0, batch212/1133, batch loss:1.2115869522094727, Training time:36856.254903793335
batch reward last col mean 0.30780985951423645 first col mean 0.288446307182312 all mean 0.3063373565673828
1.0878256559371948 1.0878256559371948
rl training, epoch2, iter0, batch213/1133, batch loss:1.0878256559371948, Training time:36862.49731469154
batch reward last col mean 0.2884027659893036 first col mean 0.323689728975296 all mean 0.29510506987571716
1.0959049463272095 1.0959049463272095
rl training, epoch2, iter0, batch214/1133, batch loss:1.0959049463272095, Training time:36869.331515312195
batch reward last col mean 0.3384539484977722 first col mean 0.35542452335357666 all mean 0.34068429470062256
1.1849671602249146 1.1849671602249146
rl training, epoch2, iter0, batch215/1133, batch loss:1.1849671602249146, Training time:36876.9818251133
batch reward last col mean 0.3521503210067749 first col mean 0.3459050953388214 all mean 0.34658685326576233
1.1688958406448364 1.1688958406448364
rl training, epoch2, iter0, batch216/1133, batch loss:1.1688958406448364, Training time:36880.81579995155
batch reward last col mean 0.33003631234169006 first col mean 0.36277496814727783 all mean 0.334687203168869
1.1160675287246704 1.1160675287246704
rl training, epoch2, iter0, batch217/1133, batch loss:1.1160675287246704, Training time:36884.916841983795
batch reward last col mean 0.4176044166088104 first col mean 0.37097492814064026 all mean 0.4102177023887634
1.3773283958435059 1.3773283958435059
rl training, epoch2, iter0, batch218/1133, batch loss:1.3773283958435059, Training time:36888.91179037094
batch reward last col mean 0.3852037191390991 first col mean 0.32864058017730713 all mean 0.37195631861686707
1.2187120914459229 1.2187120914459229
rl training, epoch2, iter0, batch219/1133, batch loss:1.2187120914459229, Training time:36894.75867795944
batch reward last col mean 0.3661844730377197 first col mean 0.3785344958305359 all mean 0.36728039383888245
1.2094112634658813 1.2094112634658813
rl training, epoch2, iter0, batch220/1133, batch loss:1.2094112634658813, Training time:36899.27277803421
batch reward last col mean 0.3296571969985962 first col mean 0.329832524061203 all mean 0.3319779634475708
1.2533296346664429 1.2533296346664429
rl training, epoch2, iter0, batch221/1133, batch loss:1.2533296346664429, Training time:36904.28117465973
batch reward last col mean 0.3380992114543915 first col mean 0.34665772318840027 all mean 0.33967307209968567
1.1999866962432861 1.1999866962432861
rl training, epoch2, iter0, batch222/1133, batch loss:1.1999866962432861, Training time:36910.27829146385
batch reward last col mean 0.32090285420417786 first col mean 0.38259392976760864 all mean 0.3294663429260254
1.4767457246780396 1.4767457246780396
rl training, epoch2, iter0, batch223/1133, batch loss:1.4767457246780396, Training time:36915.81671285629
batch reward last col mean 0.33905524015426636 first col mean 0.33698293566703796 all mean 0.3382161259651184
1.2303098440170288 1.2303098440170288
rl training, epoch2, iter0, batch224/1133, batch loss:1.2303098440170288, Training time:36919.14964365959
batch reward last col mean 0.38302183151245117 first col mean 0.3555915951728821 all mean 0.3813404440879822
1.4078631401062012 1.4078631401062012
rl training, epoch2, iter0, batch225/1133, batch loss:1.4078631401062012, Training time:36925.21816897392
batch reward last col mean 0.279954731464386 first col mean 0.323519229888916 all mean 0.29217058420181274
1.1020303964614868 1.1020303964614868
rl training, epoch2, iter0, batch226/1133, batch loss:1.1020303964614868, Training time:36930.79884338379
batch reward last col mean 0.38155609369277954 first col mean 0.3687628507614136 all mean 0.3809683620929718
1.3662410974502563 1.3662410974502563
rl training, epoch2, iter0, batch227/1133, batch loss:1.3662410974502563, Training time:36941.619381427765
batch reward last col mean 0.3524467945098877 first col mean 0.37845751643180847 all mean 0.36134907603263855
1.339341640472412 1.3393417596817017
rl training, epoch2, iter0, batch228/1133, batch loss:1.3393417596817017, Training time:36947.95955634117
batch reward last col mean 0.3939343988895416 first col mean 0.3553396761417389 all mean 0.38355958461761475
1.3146449327468872 1.3146449327468872
rl training, epoch2, iter0, batch229/1133, batch loss:1.3146449327468872, Training time:36953.804376125336
batch reward last col mean 0.41620731353759766 first col mean 0.36721718311309814 all mean 0.40677952766418457
1.353779911994934 1.353779911994934
rl training, epoch2, iter0, batch230/1133, batch loss:1.353779911994934, Training time:36959.6131670475
batch reward last col mean 0.38485729694366455 first col mean 0.3789958357810974 all mean 0.37790587544441223
1.2782124280929565 1.2782124280929565
rl training, epoch2, iter0, batch231/1133, batch loss:1.2782124280929565, Training time:36965.752403736115
batch reward last col mean 0.3646041452884674 first col mean 0.35954415798187256 all mean 0.36897504329681396
1.4256796836853027 1.4256796836853027
rl training, epoch2, iter0, batch232/1133, batch loss:1.4256796836853027, Training time:36972.17029070854
batch reward last col mean 0.36245831847190857 first col mean 0.394722044467926 all mean 0.3763180673122406
1.3363957405090332 1.3363957405090332
rl training, epoch2, iter0, batch233/1133, batch loss:1.3363957405090332, Training time:36976.14083600044
batch reward last col mean 0.38694173097610474 first col mean 0.3356001377105713 all mean 0.3794774115085602
1.2106199264526367 1.2106199264526367
rl training, epoch2, iter0, batch234/1133, batch loss:1.2106199264526367, Training time:36983.13230252266
batch reward last col mean 0.3855055868625641 first col mean 0.3397625684738159 all mean 0.37562429904937744
1.2880922555923462 1.2880922555923462
rl training, epoch2, iter0, batch235/1133, batch loss:1.2880922555923462, Training time:36988.8203163147
batch reward last col mean 0.3207848370075226 first col mean 0.35357949137687683 all mean 0.3256707787513733
1.1456962823867798 1.1456964015960693
rl training, epoch2, iter0, batch236/1133, batch loss:1.1456964015960693, Training time:36994.24930906296
batch reward last col mean 0.41731852293014526 first col mean 0.36571046710014343 all mean 0.4079682230949402
1.36980140209198 1.36980140209198
rl training, epoch2, iter0, batch237/1133, batch loss:1.36980140209198, Training time:36998.717641592026
batch reward last col mean 0.3515062928199768 first col mean 0.3529888391494751 all mean 0.3549444377422333
1.2490850687026978 1.2490850687026978
rl training, epoch2, iter0, batch238/1133, batch loss:1.2490850687026978, Training time:37005.45309615135
batch reward last col mean 0.35095298290252686 first col mean 0.38513636589050293 all mean 0.3547183573246002
1.2781747579574585 1.2781747579574585
rl training, epoch2, iter0, batch239/1133, batch loss:1.2781747579574585, Training time:37011.42710399628
batch reward last col mean 0.3557434678077698 first col mean 0.3638255000114441 all mean 0.36109334230422974
1.1232681274414062 1.1232681274414062
rl training, epoch2, iter0, batch240/1133, batch loss:1.1232681274414062, Training time:37014.965299129486
batch reward last col mean 0.375373899936676 first col mean 0.37035709619522095 all mean 0.3776595890522003
1.2873127460479736 1.2873127460479736
rl training, epoch2, iter0, batch241/1133, batch loss:1.2873127460479736, Training time:37021.378954172134
batch reward last col mean 0.351246178150177 first col mean 0.39650261402130127 all mean 0.3592965006828308
1.203366756439209 1.2033666372299194
rl training, epoch2, iter0, batch242/1133, batch loss:1.2033666372299194, Training time:37025.096735715866
batch reward last col mean 0.3298908770084381 first col mean 0.39198800921440125 all mean 0.3436671495437622
1.167711615562439 1.167711615562439
rl training, epoch2, iter0, batch243/1133, batch loss:1.167711615562439, Training time:37029.43715786934
batch reward last col mean 0.3626297414302826 first col mean 0.3484337329864502 all mean 0.3596462309360504
1.0908071994781494 1.090807318687439
rl training, epoch2, iter0, batch244/1133, batch loss:1.090807318687439, Training time:37032.69046163559
batch reward last col mean 0.38513755798339844 first col mean 0.3995966911315918 all mean 0.3927154242992401
1.283115029335022 1.2831149101257324
rl training, epoch2, iter0, batch245/1133, batch loss:1.2831149101257324, Training time:37036.752165555954
batch reward last col mean 0.350751131772995 first col mean 0.36751359701156616 all mean 0.34765753149986267
1.0820026397705078 1.0820026397705078
rl training, epoch2, iter0, batch246/1133, batch loss:1.0820026397705078, Training time:37041.75181508064
batch reward last col mean 0.2924824357032776 first col mean 0.35115671157836914 all mean 0.2935032248497009
0.9451032280921936 0.9451032876968384
rl training, epoch2, iter0, batch247/1133, batch loss:0.9451032876968384, Training time:37049.43045568466
batch reward last col mean 0.36820119619369507 first col mean 0.39787501096725464 all mean 0.376095175743103
1.0089683532714844 1.0089683532714844
rl training, epoch2, iter0, batch248/1133, batch loss:1.0089683532714844, Training time:37052.549482584
batch reward last col mean 0.417832612991333 first col mean 0.412893682718277 all mean 0.41445639729499817
1.4805786609649658 1.4805787801742554
rl training, epoch2, iter0, batch249/1133, batch loss:1.4805787801742554, Training time:37057.910427093506
batch reward last col mean 0.339851051568985 first col mean 0.3764001131057739 all mean 0.34699559211730957
1.1933064460754395 1.1933064460754395
rl training, epoch2, iter0, batch250/1133, batch loss:1.1933064460754395, Training time:37065.0140004158
batch reward last col mean 0.38554471731185913 first col mean 0.4277016520500183 all mean 0.39022761583328247
1.1959480047225952 1.1959481239318848
rl training, epoch2, iter0, batch251/1133, batch loss:1.1959481239318848, Training time:37069.3448536396
batch reward last col mean 0.3772713541984558 first col mean 0.4218534827232361 all mean 0.3828732967376709
1.1751885414123535 1.175188422203064
rl training, epoch2, iter0, batch252/1133, batch loss:1.175188422203064, Training time:37072.1987323761
batch reward last col mean 0.4133264720439911 first col mean 0.3956150710582733 all mean 0.3999992907047272
1.132115364074707 1.1321152448654175
rl training, epoch2, iter0, batch253/1133, batch loss:1.1321152448654175, Training time:37075.56807208061
batch reward last col mean 0.4196290373802185 first col mean 0.3854101300239563 all mean 0.411793053150177
1.206291675567627 1.206291675567627
rl training, epoch2, iter0, batch254/1133, batch loss:1.206291675567627, Training time:37079.286526203156
batch reward last col mean 0.35562819242477417 first col mean 0.36178702116012573 all mean 0.36364611983299255
1.0670663118362427 1.0670663118362427
rl training, epoch2, iter0, batch255/1133, batch loss:1.0670663118362427, Training time:37081.890580415726
batch reward last col mean 0.3463245630264282 first col mean 0.38341671228408813 all mean 0.3519512116909027
1.091644525527954 1.091644525527954
rl training, epoch2, iter0, batch256/1133, batch loss:1.091644525527954, Training time:37086.37026977539
batch reward last col mean 0.3761204779148102 first col mean 0.37817201018333435 all mean 0.38452574610710144
1.145602822303772 1.1456027030944824
rl training, epoch2, iter0, batch257/1133, batch loss:1.1456027030944824, Training time:37089.425454854965
batch reward last col mean 0.3408131003379822 first col mean 0.4021207392215729 all mean 0.3575581908226013
1.011819839477539 1.0118197202682495
rl training, epoch2, iter0, batch258/1133, batch loss:1.0118197202682495, Training time:37091.27814412117
batch reward last col mean 0.4010821282863617 first col mean 0.3534047305583954 all mean 0.3976971209049225
1.099412441253662 1.099412441253662
rl training, epoch2, iter0, batch259/1133, batch loss:1.099412441253662, Training time:37094.81178832054
batch reward last col mean 0.43724942207336426 first col mean 0.41170597076416016 all mean 0.4308815896511078
1.240411639213562 1.240411639213562
rl training, epoch2, iter0, batch260/1133, batch loss:1.240411639213562, Training time:37098.37355732918
batch reward last col mean 0.4161726236343384 first col mean 0.383148193359375 all mean 0.4169573485851288
1.1670783758163452 1.1670783758163452
rl training, epoch2, iter0, batch261/1133, batch loss:1.1670783758163452, Training time:37100.8565454483
batch reward last col mean 0.4547739028930664 first col mean 0.39507704973220825 all mean 0.451476514339447
1.2335710525512695 1.2335710525512695
rl training, epoch2, iter0, batch262/1133, batch loss:1.2335710525512695, Training time:37103.55530118942
batch reward last col mean 0.42520904541015625 first col mean 0.41989004611968994 all mean 0.4233739376068115
1.2554163932800293 1.2554163932800293
rl training, epoch2, iter0, batch263/1133, batch loss:1.2554163932800293, Training time:37105.976373910904
batch reward last col mean 0.3828260898590088 first col mean 0.4124213457107544 all mean 0.3907260596752167
1.2105059623718262 1.2105059623718262
rl training, epoch2, iter0, batch264/1133, batch loss:1.2105059623718262, Training time:37108.52179598808
batch reward last col mean 0.4164436459541321 first col mean 0.3753039836883545 all mean 0.41135865449905396
1.0637991428375244 1.0637991428375244
rl training, epoch2, iter0, batch265/1133, batch loss:1.0637991428375244, Training time:37111.12940454483
batch reward last col mean 0.4265214502811432 first col mean 0.4371107220649719 all mean 0.4339666962623596
1.278494119644165 1.278494119644165
rl training, epoch2, iter0, batch266/1133, batch loss:1.278494119644165, Training time:37114.62634444237
batch reward last col mean 0.3879093527793884 first col mean 0.4023628830909729 all mean 0.38556841015815735
1.0319422483444214 1.0319422483444214
rl training, epoch2, iter0, batch267/1133, batch loss:1.0319422483444214, Training time:37117.45707011223
batch reward last col mean 0.40381455421447754 first col mean 0.4438231289386749 all mean 0.4130307734012604
1.0587800741195679 1.0587801933288574
rl training, epoch2, iter0, batch268/1133, batch loss:1.0587801933288574, Training time:37120.80196118355
batch reward last col mean 0.3688732385635376 first col mean 0.37141096591949463 all mean 0.37144482135772705
1.167364239692688 1.167364239692688
rl training, epoch2, iter0, batch269/1133, batch loss:1.167364239692688, Training time:37124.922617435455
batch reward last col mean 0.3560625910758972 first col mean 0.37301939725875854 all mean 0.3631301522254944
1.0297057628631592 1.0297057628631592
rl training, epoch2, iter0, batch270/1133, batch loss:1.0297057628631592, Training time:37128.043536663055
batch reward last col mean 0.41372278332710266 first col mean 0.38853198289871216 all mean 0.40610259771347046
1.0190162658691406 1.0190162658691406
rl training, epoch2, iter0, batch271/1133, batch loss:1.0190162658691406, Training time:37131.802345991135
batch reward last col mean 0.4215008616447449 first col mean 0.37123459577560425 all mean 0.4149046242237091
1.1132370233535767 1.1132370233535767
rl training, epoch2, iter0, batch272/1133, batch loss:1.1132370233535767, Training time:37136.497967004776
batch reward last col mean 0.4050791561603546 first col mean 0.40065696835517883 all mean 0.4056316316127777
1.06076979637146 1.06076979637146
rl training, epoch2, iter0, batch273/1133, batch loss:1.06076979637146, Training time:37141.51916241646
batch reward last col mean 0.4098692238330841 first col mean 0.40414509177207947 all mean 0.4041074514389038
1.026585578918457 1.026585578918457
rl training, epoch2, iter0, batch274/1133, batch loss:1.026585578918457, Training time:37147.745891571045
batch reward last col mean 0.4130091369152069 first col mean 0.39162832498550415 all mean 0.41175952553749084
1.091785192489624 1.091785192489624
rl training, epoch2, iter0, batch275/1133, batch loss:1.091785192489624, Training time:37151.83256006241
batch reward last col mean 0.3856791853904724 first col mean 0.4037601947784424 all mean 0.3827660381793976
1.0280526876449585 1.0280526876449585
rl training, epoch2, iter0, batch276/1133, batch loss:1.0280526876449585, Training time:37159.66714954376
batch reward last col mean 0.4061432480812073 first col mean 0.39019709825515747 all mean 0.4002460539340973
0.9948157072067261 0.9948157072067261
rl training, epoch2, iter0, batch277/1133, batch loss:0.9948157072067261, Training time:37164.593858003616
batch reward last col mean 0.40296536684036255 first col mean 0.37723463773727417 all mean 0.4042164385318756
0.957098126411438 0.9570980072021484
rl training, epoch2, iter0, batch278/1133, batch loss:0.9570980072021484, Training time:37169.99260663986
batch reward last col mean 0.32884106040000916 first col mean 0.3532885015010834 all mean 0.33098235726356506
0.8896775841712952 0.8896775841712952
rl training, epoch2, iter0, batch279/1133, batch loss:0.8896775841712952, Training time:37175.75216507912
batch reward last col mean 0.3868486285209656 first col mean 0.3881666660308838 all mean 0.38014188408851624
0.9980722069740295 0.9980722069740295
rl training, epoch2, iter0, batch280/1133, batch loss:0.9980722069740295, Training time:37181.26633262634
batch reward last col mean 0.3909980058670044 first col mean 0.406150221824646 all mean 0.38916850090026855
0.9599363207817078 0.9599363207817078
rl training, epoch2, iter0, batch281/1133, batch loss:0.9599363207817078, Training time:37188.4413421154
batch reward last col mean 0.4048572778701782 first col mean 0.38651561737060547 all mean 0.40548399090766907
1.0572454929351807 1.0572454929351807
rl training, epoch2, iter0, batch282/1133, batch loss:1.0572454929351807, Training time:37196.55014657974
batch reward last col mean 0.4073839783668518 first col mean 0.43463560938835144 all mean 0.4028112590312958
1.0421820878982544 1.0421820878982544
rl training, epoch2, iter0, batch283/1133, batch loss:1.0421820878982544, Training time:37202.4774582386
batch reward last col mean 0.3773207366466522 first col mean 0.35016971826553345 all mean 0.3730851709842682
0.9451431035995483 0.9451431035995483
rl training, epoch2, iter0, batch284/1133, batch loss:0.9451431035995483, Training time:37208.86082172394
batch reward last col mean 0.3801538944244385 first col mean 0.40074288845062256 all mean 0.3826945722103119
0.8848629593849182 0.8848629593849182
rl training, epoch2, iter0, batch285/1133, batch loss:0.8848629593849182, Training time:37216.72369670868
batch reward last col mean 0.3857250213623047 first col mean 0.3856663703918457 all mean 0.3843558728694916
0.9339563250541687 0.9339563250541687
rl training, epoch2, iter0, batch286/1133, batch loss:0.9339563250541687, Training time:37223.853927373886
batch reward last col mean 0.37255749106407166 first col mean 0.415377676486969 all mean 0.3778558671474457
0.9263049960136414 0.9263049960136414
rl training, epoch2, iter0, batch287/1133, batch loss:0.9263049960136414, Training time:37230.737857580185
batch reward last col mean 0.4444047510623932 first col mean 0.44444766640663147 all mean 0.4522995948791504
1.1755316257476807 1.1755316257476807
rl training, epoch2, iter0, batch288/1133, batch loss:1.1755316257476807, Training time:37243.259106874466
batch reward last col mean 0.4154953360557556 first col mean 0.40073883533477783 all mean 0.4092390835285187
0.9685949087142944 0.9685949087142944
rl training, epoch2, iter0, batch289/1133, batch loss:0.9685949087142944, Training time:37248.947555065155
batch reward last col mean 0.3912062346935272 first col mean 0.3960192799568176 all mean 0.3966943323612213
1.0149296522140503 1.0149297714233398
rl training, epoch2, iter0, batch290/1133, batch loss:1.0149297714233398, Training time:37256.47043776512
batch reward last col mean 0.37858662009239197 first col mean 0.43217381834983826 all mean 0.39313122630119324
0.9897603988647461 0.9897603988647461
rl training, epoch2, iter0, batch291/1133, batch loss:0.9897603988647461, Training time:37267.045115470886
batch reward last col mean 0.4103776812553406 first col mean 0.40115439891815186 all mean 0.41032660007476807
0.9644615054130554 0.9644615054130554
rl training, epoch2, iter0, batch292/1133, batch loss:0.9644615054130554, Training time:37279.936962366104
batch reward last col mean 0.417511910200119 first col mean 0.3975447416305542 all mean 0.41198015213012695
0.9451591968536377 0.9451591968536377
rl training, epoch2, iter0, batch293/1133, batch loss:0.9451591968536377, Training time:37288.237191438675
batch reward last col mean 0.4362245798110962 first col mean 0.42377352714538574 all mean 0.43766623735427856
1.0346232652664185 1.0346232652664185
rl training, epoch2, iter0, batch294/1133, batch loss:1.0346232652664185, Training time:37297.35824775696
batch reward last col mean 0.40833455324172974 first col mean 0.424963116645813 all mean 0.41319331526756287
0.9712324738502502 0.9712324738502502
rl training, epoch2, iter0, batch295/1133, batch loss:0.9712324738502502, Training time:37309.24090027809
batch reward last col mean 0.372771680355072 first col mean 0.4277079105377197 all mean 0.38168075680732727
0.8780127763748169 0.8780127763748169
rl training, epoch2, iter0, batch296/1133, batch loss:0.8780127763748169, Training time:37320.337161779404
batch reward last col mean 0.40628236532211304 first col mean 0.4249555766582489 all mean 0.41528093814849854
0.9101185202598572 0.9101185202598572
rl training, epoch2, iter0, batch297/1133, batch loss:0.9101185202598572, Training time:37333.37030315399
batch reward last col mean 0.3512032628059387 first col mean 0.3816134035587311 all mean 0.3584077060222626
0.8295177817344666 0.8295177817344666
rl training, epoch2, iter0, batch298/1133, batch loss:0.8295177817344666, Training time:37346.936806201935
batch reward last col mean 0.44788503646850586 first col mean 0.4098273515701294 all mean 0.43880683183670044
0.8441206216812134 0.8441206216812134
rl training, epoch2, iter0, batch299/1133, batch loss:0.8441206216812134, Training time:37362.996366500854
batch reward last col mean 0.3760039210319519 first col mean 0.39289310574531555 all mean 0.38648393750190735
0.8177608251571655 0.8177608251571655
rl training, epoch2, iter0, batch300/1133, batch loss:0.8177608251571655, Training time:37380.80145192146
batch reward last col mean 0.408160537481308 first col mean 0.3887120187282562 all mean 0.39653053879737854
0.8577072024345398 0.8577072024345398
rl training, epoch2, iter0, batch301/1133, batch loss:0.8577072024345398, Training time:37400.282219171524
batch reward last col mean 0.3691408932209015 first col mean 0.36466184258461 all mean 0.3747069537639618
0.7325423955917358 0.7325423955917358
rl training, epoch2, iter0, batch302/1133, batch loss:0.7325423955917358, Training time:37418.03882718086
batch reward last col mean 0.40222615003585815 first col mean 0.39363256096839905 all mean 0.39885565638542175
0.7959716320037842 0.7959716320037842
rl training, epoch2, iter0, batch303/1133, batch loss:0.7959716320037842, Training time:37435.925667762756
batch reward last col mean 0.44560953974723816 first col mean 0.3947148323059082 all mean 0.43499454855918884
0.8674068450927734 0.8674068450927734
rl training, epoch2, iter0, batch304/1133, batch loss:0.8674068450927734, Training time:37453.69236326218
batch reward last col mean 0.4071439504623413 first col mean 0.3815167546272278 all mean 0.4032849669456482
0.9170634150505066 0.9170634150505066
rl training, epoch2, iter0, batch305/1133, batch loss:0.9170634150505066, Training time:37471.390498399734
batch reward last col mean 0.38312828540802 first col mean 0.40552204847335815 all mean 0.3934476375579834
0.7815662026405334 0.7815662026405334
rl training, epoch2, iter0, batch306/1133, batch loss:0.7815662026405334, Training time:37491.27939581871
batch reward last col mean 0.38612183928489685 first col mean 0.3978821635246277 all mean 0.39032796025276184
0.860225260257721 0.860225260257721
rl training, epoch2, iter0, batch307/1133, batch loss:0.860225260257721, Training time:37511.27296447754
batch reward last col mean 0.39205625653266907 first col mean 0.3858274221420288 all mean 0.3951587975025177
0.8316798210144043 0.8316798210144043
rl training, epoch2, iter0, batch308/1133, batch loss:0.8316798210144043, Training time:37529.16086792946
batch reward last col mean 0.3759806752204895 first col mean 0.4266103506088257 all mean 0.3902992010116577
0.8058326244354248 0.8058326244354248
rl training, epoch2, iter0, batch309/1133, batch loss:0.8058326244354248, Training time:37548.07381153107
batch reward last col mean 0.4114683270454407 first col mean 0.3830324411392212 all mean 0.41019201278686523
0.8287543058395386 0.8287543058395386
rl training, epoch2, iter0, batch310/1133, batch loss:0.8287543058395386, Training time:37567.8588142395
batch reward last col mean 0.3751819133758545 first col mean 0.36830174922943115 all mean 0.379544734954834
0.7688872218132019 0.7688872218132019
rl training, epoch2, iter0, batch311/1133, batch loss:0.7688872218132019, Training time:37585.78131866455
batch reward last col mean 0.40918517112731934 first col mean 0.4031674265861511 all mean 0.4076085686683655
0.7791083455085754 0.7791083455085754
rl training, epoch2, iter0, batch312/1133, batch loss:0.7791083455085754, Training time:37603.60812020302
batch reward last col mean 0.3755808472633362 first col mean 0.40029656887054443 all mean 0.3785236179828644
0.8397634029388428 0.8397634029388428
rl training, epoch2, iter0, batch313/1133, batch loss:0.8397634029388428, Training time:37621.5329451561
batch reward last col mean 0.38950902223587036 first col mean 0.452492356300354 all mean 0.40249302983283997
0.8322104811668396 0.8322104811668396
rl training, epoch2, iter0, batch314/1133, batch loss:0.8322104811668396, Training time:37639.39781856537
batch reward last col mean 0.49428537487983704 first col mean 0.45126330852508545 all mean 0.48982229828834534
0.9215657711029053 0.9215657114982605
rl training, epoch2, iter0, batch315/1133, batch loss:0.9215657114982605, Training time:37657.40152144432
batch reward last col mean 0.4064420461654663 first col mean 0.4611733555793762 all mean 0.4160574674606323
0.9206001162528992 0.9206001162528992
rl training, epoch2, iter0, batch316/1133, batch loss:0.9206001162528992, Training time:37675.10513830185
batch reward last col mean 0.4201374650001526 first col mean 0.41756075620651245 all mean 0.41768142580986023
0.8869773745536804 0.8869773745536804
rl training, epoch2, iter0, batch317/1133, batch loss:0.8869773745536804, Training time:37694.09014081955
batch reward last col mean 0.3969573676586151 first col mean 0.40732255578041077 all mean 0.3947535455226898
0.7891069650650024 0.7891069650650024
rl training, epoch2, iter0, batch318/1133, batch loss:0.7891069650650024, Training time:37713.66527724266
batch reward last col mean 0.36899325251579285 first col mean 0.40541505813598633 all mean 0.38414931297302246
0.8770390748977661 0.8770390748977661
rl training, epoch2, iter0, batch319/1133, batch loss:0.8770390748977661, Training time:37731.572367191315
batch reward last col mean 0.4090423583984375 first col mean 0.3852985203266144 all mean 0.39184409379959106
0.798884928226471 0.798884928226471
rl training, epoch2, iter0, batch320/1133, batch loss:0.798884928226471, Training time:37749.67652487755
batch reward last col mean 0.3526870906352997 first col mean 0.3769974112510681 all mean 0.37473630905151367
0.8370386958122253 0.8370386958122253
rl training, epoch2, iter0, batch321/1133, batch loss:0.8370386958122253, Training time:37767.66945362091
batch reward last col mean 0.3630125820636749 first col mean 0.39747798442840576 all mean 0.3763784170150757
0.7961618304252625 0.7961618304252625
rl training, epoch2, iter0, batch322/1133, batch loss:0.7961618304252625, Training time:37785.71759724617
batch reward last col mean 0.46758460998535156 first col mean 0.4556461572647095 all mean 0.4762289226055145
0.9084504246711731 0.9084504246711731
rl training, epoch2, iter0, batch323/1133, batch loss:0.9084504246711731, Training time:37803.69306230545
batch reward last col mean 0.42917943000793457 first col mean 0.3911415636539459 all mean 0.4204641878604889
0.8373068571090698 0.8373068571090698
rl training, epoch2, iter0, batch324/1133, batch loss:0.8373068571090698, Training time:37821.38212585449
batch reward last col mean 0.39993196725845337 first col mean 0.4380773603916168 all mean 0.40130409598350525
0.8774140477180481 0.8774140477180481
rl training, epoch2, iter0, batch325/1133, batch loss:0.8774140477180481, Training time:37839.36000084877
batch reward last col mean 0.4447210431098938 first col mean 0.4682820439338684 all mean 0.4437462389469147
0.9067122936248779 0.9067122340202332
rl training, epoch2, iter0, batch326/1133, batch loss:0.9067122340202332, Training time:37857.31083416939
batch reward last col mean 0.44229257106781006 first col mean 0.44629454612731934 all mean 0.44325122237205505
0.8838977217674255 0.883897602558136
rl training, epoch2, iter0, batch327/1133, batch loss:0.883897602558136, Training time:37875.290868997574
batch reward last col mean 0.3741038739681244 first col mean 0.39532235264778137 all mean 0.39318862557411194
0.8851039409637451 0.8851039409637451
rl training, epoch2, iter0, batch328/1133, batch loss:0.8851039409637451, Training time:37893.27049899101
batch reward last col mean 0.38296616077423096 first col mean 0.4369257390499115 all mean 0.3913910686969757
0.8484906554222107 0.8484906554222107
rl training, epoch2, iter0, batch329/1133, batch loss:0.8484906554222107, Training time:37911.2775285244
batch reward last col mean 0.4121835231781006 first col mean 0.4211026728153229 all mean 0.41721290349960327
0.8533618450164795 0.8533618450164795
rl training, epoch2, iter0, batch330/1133, batch loss:0.8533618450164795, Training time:37929.14882564545
batch reward last col mean 0.47170665860176086 first col mean 0.4439191222190857 all mean 0.43864133954048157
0.8970579504966736 0.8970578908920288
rl training, epoch2, iter0, batch331/1133, batch loss:0.8970578908920288, Training time:37946.829191446304
batch reward last col mean 0.4276198446750641 first col mean 0.4612278640270233 all mean 0.4397587180137634
0.8906108736991882 0.8906108736991882
rl training, epoch2, iter0, batch332/1133, batch loss:0.8906108736991882, Training time:37964.829280138016
batch reward last col mean 0.39319750666618347 first col mean 0.42902833223342896 all mean 0.42580175399780273
0.8076709508895874 0.8076709508895874
rl training, epoch2, iter0, batch333/1133, batch loss:0.8076709508895874, Training time:37982.729996442795
batch reward last col mean 0.44214093685150146 first col mean 0.4666749835014343 all mean 0.4378875494003296
0.9045842289924622 0.9045842289924622
rl training, epoch2, iter0, batch334/1133, batch loss:0.9045842289924622, Training time:38000.61308097839
batch reward last col mean 0.43368589878082275 first col mean 0.42899638414382935 all mean 0.4471115469932556
0.9252231121063232 0.9252231121063232
rl training, epoch2, iter0, batch335/1133, batch loss:0.9252231121063232, Training time:38018.38952469826
batch reward last col mean 0.45019906759262085 first col mean 0.4511551260948181 all mean 0.4394721984863281
0.8428934216499329 0.8428934216499329
rl training, epoch2, iter0, batch336/1133, batch loss:0.8428934216499329, Training time:38038.132385492325
batch reward last col mean 0.4381626844406128 first col mean 0.5272916555404663 all mean 0.47387996315956116
0.893768310546875 0.8937683701515198
rl training, epoch2, iter0, batch337/1133, batch loss:0.8937683701515198, Training time:38055.87790584564
batch reward last col mean 0.4391653537750244 first col mean 0.4484884738922119 all mean 0.4594270586967468
0.8657119870185852 0.8657119870185852
rl training, epoch2, iter0, batch338/1133, batch loss:0.8657119870185852, Training time:38073.725665569305
batch reward last col mean 0.5196529626846313 first col mean 0.4588431119918823 all mean 0.4975113570690155
0.911588191986084 0.911588191986084
rl training, epoch2, iter0, batch339/1133, batch loss:0.911588191986084, Training time:38091.400032520294
batch reward last col mean 0.4695824384689331 first col mean 0.44458019733428955 all mean 0.45570042729377747
0.8901643753051758 0.8901642560958862
rl training, epoch2, iter0, batch340/1133, batch loss:0.8901642560958862, Training time:38109.03923916817
batch reward last col mean 0.49819809198379517 first col mean 0.5217866897583008 all mean 0.4923291802406311
0.9410621523857117 0.9410621523857117
rl training, epoch2, iter0, batch341/1133, batch loss:0.9410621523857117, Training time:38126.64224123955
batch reward last col mean 0.4976166784763336 first col mean 0.5034945607185364 all mean 0.5014382004737854
0.9635251760482788 0.9635251760482788
rl training, epoch2, iter0, batch342/1133, batch loss:0.9635251760482788, Training time:38144.34323763847
batch reward last col mean 0.5194647908210754 first col mean 0.5232722759246826 all mean 0.5169742703437805
0.9425129890441895 0.9425129294395447
rl training, epoch2, iter0, batch343/1133, batch loss:0.9425129294395447, Training time:38163.77631139755
batch reward last col mean 0.49782922863960266 first col mean 0.5646255016326904 all mean 0.5481768250465393
0.9720340371131897 0.9720340371131897
rl training, epoch2, iter0, batch344/1133, batch loss:0.9720340371131897, Training time:38183.48976135254
batch reward last col mean 0.4825887978076935 first col mean 0.537400484085083 all mean 0.5023313164710999
0.932786762714386 0.9327868819236755
rl training, epoch2, iter0, batch345/1133, batch loss:0.9327868819236755, Training time:38201.16932296753
batch reward last col mean 0.5238996744155884 first col mean 0.5555402040481567 all mean 0.5442747473716736
0.9896279573440552 0.9896279573440552
rl training, epoch2, iter0, batch346/1133, batch loss:0.9896279573440552, Training time:38218.66100668907
batch reward last col mean 0.543546199798584 first col mean 0.5604662895202637 all mean 0.5388180613517761
0.943307638168335 0.943307638168335
rl training, epoch2, iter0, batch347/1133, batch loss:0.943307638168335, Training time:38236.08865714073
batch reward last col mean 0.5107452869415283 first col mean 0.5587979555130005 all mean 0.5401626825332642
0.9785462021827698 0.9785462021827698
rl training, epoch2, iter0, batch348/1133, batch loss:0.9785462021827698, Training time:38253.66956114769
batch reward last col mean 0.5604361295700073 first col mean 0.5650878548622131 all mean 0.5642167925834656
0.952331006526947 0.952331006526947
rl training, epoch2, iter0, batch349/1133, batch loss:0.952331006526947, Training time:38271.13303899765
batch reward last col mean 0.56192547082901 first col mean 0.586517333984375 all mean 0.5817760229110718
0.9637654423713684 0.9637654423713684
rl training, epoch2, iter0, batch350/1133, batch loss:0.9637654423713684, Training time:38288.69906759262
batch reward last col mean 0.5562435984611511 first col mean 0.6029174327850342 all mean 0.5757254362106323
0.9500678181648254 0.9500678181648254
rl training, epoch2, iter0, batch351/1133, batch loss:0.9500678181648254, Training time:38306.16141486168
batch reward last col mean 0.658141016960144 first col mean 0.6326897740364075 all mean 0.5901880264282227
0.9638457298278809 0.9638457894325256
rl training, epoch2, iter0, batch352/1133, batch loss:0.9638457894325256, Training time:38323.524384498596
batch reward last col mean 0.5884010791778564 first col mean 0.6053180694580078 all mean 0.602586030960083
0.9728183746337891 0.9728183746337891
rl training, epoch2, iter0, batch353/1133, batch loss:0.9728183746337891, Training time:38341.06481075287
batch reward last col mean 0.6149014830589294 first col mean 0.6375004053115845 all mean 0.6180729269981384
0.9221572875976562 0.9221572875976562
rl training, epoch2, iter0, batch354/1133, batch loss:0.9221572875976562, Training time:38358.34628176689
batch reward last col mean 0.5587918758392334 first col mean 0.6085958480834961 all mean 0.6092566251754761
0.9711346626281738 0.9711345434188843
rl training, epoch2, iter0, batch355/1133, batch loss:0.9711345434188843, Training time:38375.68142414093
batch reward last col mean 0.603421151638031 first col mean 0.6260644197463989 all mean 0.6243830323219299
0.9515830278396606 0.9515830278396606
rl training, epoch2, iter0, batch356/1133, batch loss:0.9515830278396606, Training time:38393.04487848282
batch reward last col mean 0.5292178392410278 first col mean 0.6316511631011963 all mean 0.6045466661453247
0.9171383380889893 0.9171384572982788
rl training, epoch2, iter0, batch357/1133, batch loss:0.9171384572982788, Training time:38410.43187212944
batch reward last col mean 0.6513947248458862 first col mean 0.6590150594711304 all mean 0.638063907623291
0.9703131914138794 0.9703131914138794
rl training, epoch2, iter0, batch358/1133, batch loss:0.9703131914138794, Training time:38427.7631881237
batch reward last col mean 0.6349031925201416 first col mean 0.6589856743812561 all mean 0.6578019261360168
0.9900043606758118 0.9900043606758118
rl training, epoch2, iter0, batch359/1133, batch loss:0.9900043606758118, Training time:38445.232231378555
batch reward last col mean 0.599892795085907 first col mean 0.6363002061843872 all mean 0.6320223808288574
0.9343010783195496 0.9343010783195496
rl training, epoch2, iter0, batch360/1133, batch loss:0.9343010783195496, Training time:38462.677802324295
batch reward last col mean 0.677343487739563 first col mean 0.6828637719154358 all mean 0.6751311421394348
0.9916111826896667 0.9916111826896667
rl training, epoch2, iter0, batch361/1133, batch loss:0.9916111826896667, Training time:38480.07791566849
batch reward last col mean 0.6330655813217163 first col mean 0.6804814338684082 all mean 0.6531451940536499
0.9461706280708313 0.9461706280708313
rl training, epoch2, iter0, batch362/1133, batch loss:0.9461706280708313, Training time:38497.358926057816
batch reward last col mean 0.642899751663208 first col mean 0.6908897757530212 all mean 0.6734713912010193
0.9341477155685425 0.9341477155685425
rl training, epoch2, iter0, batch363/1133, batch loss:0.9341477155685425, Training time:38514.6148352623
batch reward last col mean 0.643936038017273 first col mean 0.7087794542312622 all mean 0.6932709217071533
0.9505932331085205 0.950593113899231
rl training, epoch2, iter0, batch364/1133, batch loss:0.950593113899231, Training time:38531.53486037254
batch reward last col mean 0.7018911838531494 first col mean 0.6933055520057678 all mean 0.7053609490394592
0.9617789387702942 0.9617789387702942
rl training, epoch2, iter0, batch365/1133, batch loss:0.9617789387702942, Training time:38548.52144765854
batch reward last col mean 0.6766929626464844 first col mean 0.6997107267379761 all mean 0.7180177569389343
0.9542986154556274 0.9542986154556274
rl training, epoch2, iter0, batch366/1133, batch loss:0.9542986154556274, Training time:38565.46915459633
batch reward last col mean 0.7455360889434814 first col mean 0.7633419632911682 all mean 0.7344169020652771
0.9360311031341553 0.9360311031341553
rl training, epoch2, iter0, batch367/1133, batch loss:0.9360311031341553, Training time:38582.358394384384
batch reward last col mean 0.7395981550216675 first col mean 0.7598364949226379 all mean 0.7669706344604492
0.9566080570220947 0.9566080570220947
rl training, epoch2, iter0, batch368/1133, batch loss:0.9566080570220947, Training time:38599.40227293968
batch reward last col mean 0.7747769355773926 first col mean 0.7461471557617188 all mean 0.7385141253471375
0.9155126214027405 0.9155126214027405
rl training, epoch2, iter0, batch369/1133, batch loss:0.9155126214027405, Training time:38616.42555856705
batch reward last col mean 0.7611982822418213 first col mean 0.7615911364555359 all mean 0.7677297592163086
0.9340974688529968 0.9340974688529968
rl training, epoch2, iter0, batch370/1133, batch loss:0.9340974688529968, Training time:38633.42737150192
batch reward last col mean 0.7384319305419922 first col mean 0.8165326118469238 all mean 0.7959970831871033
0.9262908101081848 0.9262908101081848
rl training, epoch2, iter0, batch371/1133, batch loss:0.9262908101081848, Training time:38650.69746589661
batch reward last col mean 0.8212206959724426 first col mean 0.8066935539245605 all mean 0.8157109618186951
0.9373784065246582 0.9373784065246582
rl training, epoch2, iter0, batch372/1133, batch loss:0.9373784065246582, Training time:38667.79954957962
batch reward last col mean 0.8134676218032837 first col mean 0.8622647523880005 all mean 0.8350896239280701
0.9329490661621094 0.9329490661621094
rl training, epoch2, iter0, batch373/1133, batch loss:0.9329490661621094, Training time:38684.86785411835
batch reward last col mean 0.8517249822616577 first col mean 0.8434122800827026 all mean 0.8470540642738342
0.9274961352348328 0.927496075630188
rl training, epoch2, iter0, batch374/1133, batch loss:0.927496075630188, Training time:38701.99703001976
batch reward last col mean 0.8503361344337463 first col mean 0.8687183260917664 all mean 0.866230309009552
0.8873056769371033 0.8873056769371033
rl training, epoch2, iter0, batch375/1133, batch loss:0.8873056769371033, Training time:38719.464609622955
batch reward last col mean 0.8156212568283081 first col mean 0.8521301746368408 all mean 0.8491095304489136
0.8597847819328308 0.8597847819328308
rl training, epoch2, iter0, batch376/1133, batch loss:0.8597847819328308, Training time:38736.439834833145
batch reward last col mean 0.8415708541870117 first col mean 0.8835616707801819 all mean 0.8731387257575989
0.8598837852478027 0.8598837852478027
rl training, epoch2, iter0, batch377/1133, batch loss:0.8598837852478027, Training time:38753.411710977554
batch reward last col mean 0.8893361687660217 first col mean 0.8998777866363525 all mean 0.8929548859596252
0.8671733736991882 0.8671733736991882
rl training, epoch2, iter0, batch378/1133, batch loss:0.8671733736991882, Training time:38770.48391222954
batch reward last col mean 0.8670833706855774 first col mean 0.8956997394561768 all mean 0.9123753905296326
0.9156593680381775 0.9156593680381775
rl training, epoch2, iter0, batch379/1133, batch loss:0.9156593680381775, Training time:38787.601214170456
batch reward last col mean 0.912655234336853 first col mean 0.9078800082206726 all mean 0.9174927473068237
0.9287270307540894 0.9287270307540894
rl training, epoch2, iter0, batch380/1133, batch loss:0.9287270307540894, Training time:38804.663720846176
batch reward last col mean 0.9111616611480713 first col mean 0.9441066980361938 all mean 0.9349156618118286
0.9748300313949585 0.9748300313949585
rl training, epoch2, iter0, batch381/1133, batch loss:0.9748300313949585, Training time:38821.79301548004
batch reward last col mean 0.9445755481719971 first col mean 0.9500124454498291 all mean 0.9474456310272217
0.9723286628723145 0.9723285436630249
rl training, epoch2, iter0, batch382/1133, batch loss:0.9723285436630249, Training time:38838.87628412247
batch reward last col mean 0.9468452334403992 first col mean 0.9613252282142639 all mean 0.9509254097938538
0.9899807572364807 0.9899806380271912
rl training, epoch2, iter0, batch383/1133, batch loss:0.9899806380271912, Training time:38855.983274936676
RL early break
rl training, epoch 2, iter 0, loss:0.6189497758060156, Training time:38855.989037036896 
rl epoch 2, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.4592585611269733 Time: 142.05530214309692 s
0.1895486695423972 0.007574383851225986 0.262135507451783
cur_epoch: 1
D Training Loss: 0.4403194229053588 Time: 143.53047585487366 s
0.18247256157073108 0.0010854622626234676 0.2567613986760562
cur_epoch: 2
D Training Loss: 0.42470575923006404 Time: 143.27168679237366 s
0.175815942698049 0.0007903848729353517 0.2480994318295451
cur_epoch: 3
D Training Loss: 0.4192176678226989 Time: 143.2645812034607 s
0.17253700478720854 0.0006178822216799275 0.24606278147433358
cur_epoch: 4
D Training Loss: 0.40919815670675863 Time: 140.30700850486755 s
0.16708497401895717 0.00048765312764076894 0.24162552897659742
rl epoch 3, begin RL for generator...
batch reward last col mean 0.0032476582564413548 first col mean 0.00019914083532057703 all mean 0.0031566813122481108
0.00018822975107468665 0.00018822975107468665
rl training, epoch3, iter0, batch0/1133, batch loss:0.00018822975107468665, Training time:39585.291714429855
batch reward last col mean 2.670865796972066e-06 first col mean 0.00011131546489195898 all mean 3.071485843975097e-05
2.2911526684765704e-05 2.2911526684765704e-05
rl training, epoch3, iter0, batch1/1133, batch loss:2.2911526684765704e-05, Training time:39602.369822502136
batch reward last col mean 1.2756036085193045e-05 first col mean 0.0017092737834900618 all mean 4.5209879317553714e-05
4.0552822611061856e-05 4.0552811697125435e-05
rl training, epoch3, iter0, batch2/1133, batch loss:4.0552811697125435e-05, Training time:39619.65498805046
batch reward last col mean 7.916064350865781e-05 first col mean 2.960671736218501e-05 all mean 3.088002267759293e-05
3.87504551326856e-05 3.87504551326856e-05
rl training, epoch3, iter0, batch3/1133, batch loss:3.87504551326856e-05, Training time:39638.500771045685
batch reward last col mean 0.0002496134547982365 first col mean 0.00011465515854069963 all mean 0.00014364674279931933
5.0432739953976125e-05 5.043274722993374e-05
rl training, epoch3, iter0, batch4/1133, batch loss:5.043274722993374e-05, Training time:39657.301445007324
batch reward last col mean 7.453304988302989e-06 first col mean 3.6671739508165047e-05 all mean 6.147486419649795e-05
4.568555232253857e-05 4.568554140860215e-05
rl training, epoch3, iter0, batch5/1133, batch loss:4.568554140860215e-05, Training time:39676.14900422096
batch reward last col mean 4.125736086280085e-05 first col mean 7.546111078227113e-07 all mean 6.415267853299156e-05
0.00010929338168352842 0.00010929338168352842
rl training, epoch3, iter0, batch6/1133, batch loss:0.00010929338168352842, Training time:39693.10638165474
batch reward last col mean 2.0024890545755625e-05 first col mean 0.00040985082159750164 all mean 4.468265615287237e-05
3.97499134123791e-05 3.97499134123791e-05
rl training, epoch3, iter0, batch7/1133, batch loss:3.97499134123791e-05, Training time:39710.05277967453
batch reward last col mean 5.57815728825517e-05 first col mean 5.587819032371044e-05 all mean 6.0738337197108194e-05
3.525682768668048e-05 3.525682768668048e-05
rl training, epoch3, iter0, batch8/1133, batch loss:3.525682768668048e-05, Training time:39727.11186361313
batch reward last col mean 1.3611110261990689e-05 first col mean 2.1983344140608096e-06 all mean 0.00011822979286080226
0.00022862086188979447 0.00022862086188979447
rl training, epoch3, iter0, batch9/1133, batch loss:0.00022862086188979447, Training time:39743.95411539078
batch reward last col mean 7.14419320502202e-06 first col mean 0.00024949313956312835 all mean 4.520974835031666e-05
2.316284917469602e-05 2.3162847355706617e-05
rl training, epoch3, iter0, batch10/1133, batch loss:2.3162847355706617e-05, Training time:39760.78833794594
batch reward last col mean 5.745341695728712e-05 first col mean 8.138300472637638e-05 all mean 4.285843169782311e-05
8.062203414738178e-05 8.06220414233394e-05
rl training, epoch3, iter0, batch11/1133, batch loss:8.06220414233394e-05, Training time:39777.484884262085
batch reward last col mean 0.005116195417940617 first col mean 8.664404049341101e-06 all mean 0.0043145534582436085
0.00013502566434908658 0.0001350256789010018
rl training, epoch3, iter0, batch12/1133, batch loss:0.0001350256789010018, Training time:39794.24143195152
batch reward last col mean 1.8738149947239435e-06 first col mean 7.473202276742086e-05 all mean 3.0670780688524246e-05
7.360961171798408e-05 7.360961171798408e-05
rl training, epoch3, iter0, batch13/1133, batch loss:7.360961171798408e-05, Training time:39812.21775817871
batch reward last col mean 3.3858501410577446e-05 first col mean 2.445313111820724e-05 all mean 4.601739055942744e-05
2.855876664398238e-05 2.855876664398238e-05
rl training, epoch3, iter0, batch14/1133, batch loss:2.855876664398238e-05, Training time:39830.78724145889
batch reward last col mean 5.684498773916857e-07 first col mean 8.632164826849476e-05 all mean 6.284357368713245e-05
0.00013993537868373096 0.00013993536413181573
rl training, epoch3, iter0, batch15/1133, batch loss:0.00013993536413181573, Training time:39849.649527311325
batch reward last col mean 0.00027574284467846155 first col mean 4.349191294750199e-05 all mean 0.00016608258010819554
0.00039894896326586604 0.00039894896326586604
rl training, epoch3, iter0, batch16/1133, batch loss:0.00039894896326586604, Training time:39866.715928554535
batch reward last col mean 3.3206740681634983e-06 first col mean 0.0003824120794888586 all mean 4.615259967977181e-05
4.271628495189361e-05 4.2716277675936e-05
rl training, epoch3, iter0, batch17/1133, batch loss:4.2716277675936e-05, Training time:39883.78782749176
batch reward last col mean 0.00024228906841017306 first col mean 1.0801359167089686e-05 all mean 0.00010172757174586877
5.5127631640061736e-05 5.5127620726125315e-05
rl training, epoch3, iter0, batch18/1133, batch loss:5.5127620726125315e-05, Training time:39900.71930384636
batch reward last col mean 3.51348290905662e-07 first col mean 2.551952093199361e-06 all mean 6.181671778904274e-05
9.195609163725749e-05 9.195608436129987e-05
rl training, epoch3, iter0, batch19/1133, batch loss:9.195608436129987e-05, Training time:39917.72960686684
batch reward last col mean 6.938408478163183e-05 first col mean 4.62656589661492e-06 all mean 4.069786155014299e-05
4.5548335037892684e-05 4.5548335037892684e-05
rl training, epoch3, iter0, batch20/1133, batch loss:4.5548335037892684e-05, Training time:39934.81264424324
batch reward last col mean 2.294174919370562e-06 first col mean 0.0004000642220489681 all mean 3.012999331986066e-05
2.364754254813306e-05 2.3647546186111867e-05
rl training, epoch3, iter0, batch21/1133, batch loss:2.3647546186111867e-05, Training time:39951.82930588722
batch reward last col mean 5.522337687580148e-06 first col mean 0.00020810114801861346 all mean 6.967748049646616e-05
0.00021575958817265928 0.00021575958817265928
rl training, epoch3, iter0, batch22/1133, batch loss:0.00021575958817265928, Training time:39968.92853093147
batch reward last col mean 0.0005934626678936183 first col mean 8.388037531403825e-05 all mean 0.00043364675366319716
7.663580618100241e-05 7.663581345696002e-05
rl training, epoch3, iter0, batch23/1133, batch loss:7.663581345696002e-05, Training time:39985.885247945786
batch reward last col mean 0.004976226016879082 first col mean 6.815208507759962e-06 all mean 0.004370598588138819
0.00041609664913266897 0.00041609667823649943
rl training, epoch3, iter0, batch24/1133, batch loss:0.00041609667823649943, Training time:40002.756180763245
batch reward last col mean 1.4194836239767028e-06 first col mean 4.155252463533543e-05 all mean 2.007453986152541e-05
1.574210727994796e-05 1.574210727994796e-05
rl training, epoch3, iter0, batch25/1133, batch loss:1.574210727994796e-05, Training time:40019.56198596954
batch reward last col mean 5.7076449593296275e-06 first col mean 0.0008280297042801976 all mean 5.1390277803875506e-05
2.141340883099474e-05 2.1413417925941758e-05
rl training, epoch3, iter0, batch26/1133, batch loss:2.1413417925941758e-05, Training time:40036.33315062523
batch reward last col mean 7.805732820997946e-06 first col mean 1.824145692808088e-05 all mean 2.4355736968573183e-05
3.065539203817025e-05 3.0655395676149055e-05
rl training, epoch3, iter0, batch27/1133, batch loss:3.0655395676149055e-05, Training time:40053.153146743774
batch reward last col mean 5.256986332824454e-05 first col mean 2.8831268537032884e-06 all mean 8.329685806529596e-05
6.733358168276027e-05 6.733358168276027e-05
rl training, epoch3, iter0, batch28/1133, batch loss:6.733358168276027e-05, Training time:40070.008974313736
batch reward last col mean 4.429120508575579e-06 first col mean 0.000721550197340548 all mean 2.5304896553279832e-05
4.105670814169571e-05 4.1056711779674515e-05
rl training, epoch3, iter0, batch29/1133, batch loss:4.1056711779674515e-05, Training time:40087.08139324188
batch reward last col mean 0.00014744351210538298 first col mean 0.0003147511451970786 all mean 0.0001426925737177953
2.980040335387457e-05 2.980040335387457e-05
rl training, epoch3, iter0, batch30/1133, batch loss:2.980040335387457e-05, Training time:40104.18202996254
batch reward last col mean 1.4478293905995088e-06 first col mean 1.095561970032577e-06 all mean 2.8172235033707693e-05
1.62352662300691e-05 1.62352662300691e-05
rl training, epoch3, iter0, batch31/1133, batch loss:1.62352662300691e-05, Training time:40121.22656059265
batch reward last col mean 1.946801603480708e-06 first col mean 6.93309766575112e-06 all mean 1.627562778594438e-05
3.0871262424625456e-05 3.087126970058307e-05
rl training, epoch3, iter0, batch32/1133, batch loss:3.087126970058307e-05, Training time:40138.332515478134
batch reward last col mean 3.5544217098504305e-06 first col mean 4.690697892328899e-07 all mean 3.156595630571246e-05
2.5553004888934083e-05 2.5553004888934083e-05
rl training, epoch3, iter0, batch33/1133, batch loss:2.5553004888934083e-05, Training time:40155.32534503937
batch reward last col mean 2.9973188020449015e-07 first col mean 2.821721318468917e-05 all mean 6.42940285615623e-05
0.00014481694961432368 0.00014481694961432368
rl training, epoch3, iter0, batch34/1133, batch loss:0.00014481694961432368, Training time:40172.201706171036
batch reward last col mean 7.19878812560637e-07 first col mean 3.5774523894360755e-06 all mean 4.0152510337065905e-05
2.205533382948488e-05 2.2055332010495476e-05
rl training, epoch3, iter0, batch35/1133, batch loss:2.2055332010495476e-05, Training time:40189.21882224083
batch reward last col mean 3.4060130928992294e-06 first col mean 0.00013796209532301873 all mean 5.3063697123434395e-05
8.204938058042899e-05 8.204938058042899e-05
rl training, epoch3, iter0, batch36/1133, batch loss:8.204938058042899e-05, Training time:40206.14646196365
batch reward last col mean 1.0955893685604678e-06 first col mean 6.73662225381122e-06 all mean 4.792554318555631e-05
8.15064922790043e-05 8.15064922790043e-05
rl training, epoch3, iter0, batch37/1133, batch loss:8.15064922790043e-05, Training time:40223.10409808159
batch reward last col mean 0.00021022865257691592 first col mean 1.1055221875722054e-05 all mean 7.83202558523044e-05
3.47330751537811e-05 3.4733082429738715e-05
rl training, epoch3, iter0, batch38/1133, batch loss:3.4733082429738715e-05, Training time:40241.868061065674
batch reward last col mean 1.3789915556117194e-06 first col mean 3.696515875617479e-07 all mean 8.321799214172643e-06
1.3622310689243022e-05 1.3622310689243022e-05
rl training, epoch3, iter0, batch39/1133, batch loss:1.3622310689243022e-05, Training time:40259.07433104515
batch reward last col mean 3.7313786833692575e-06 first col mean 5.214231350691989e-05 all mean 3.197702608304098e-05
0.00012082129251211882 0.00012082129251211882
rl training, epoch3, iter0, batch40/1133, batch loss:0.00012082129251211882, Training time:40275.94425749779
batch reward last col mean 4.229800651955884e-06 first col mean 0.0007750559016130865 all mean 5.558722114074044e-05
4.370337046566419e-05 4.3703366827685386e-05
rl training, epoch3, iter0, batch41/1133, batch loss:4.3703366827685386e-05, Training time:40292.68665289879
batch reward last col mean 0.002737866947427392 first col mean 1.4732842828379944e-05 all mean 0.002511765109375119
0.0004118360811844468 0.0004118360811844468
rl training, epoch3, iter0, batch42/1133, batch loss:0.0004118360811844468, Training time:40309.43524003029
batch reward last col mean 3.3087133488152176e-05 first col mean 1.4483923678199062e-06 all mean 4.354027987574227e-05
1.9594090190366842e-05 1.9594090190366842e-05
rl training, epoch3, iter0, batch43/1133, batch loss:1.9594090190366842e-05, Training time:40326.13784146309
batch reward last col mean 7.582774514958146e-07 first col mean 2.956278649435262e-06 all mean 5.974329906166531e-05
7.547837594756857e-05 7.547836139565334e-05
rl training, epoch3, iter0, batch44/1133, batch loss:7.547836139565334e-05, Training time:40343.23919868469
batch reward last col mean 2.61440800386481e-05 first col mean 2.397739990556147e-06 all mean 3.348650352563709e-05
4.638669634005055e-05 4.638669634005055e-05
rl training, epoch3, iter0, batch45/1133, batch loss:4.638669634005055e-05, Training time:40360.143429517746
batch reward last col mean 7.652665772184264e-06 first col mean 0.00020182333537377417 all mean 3.486058994894847e-05
6.25099492026493e-05 6.25099492026493e-05
rl training, epoch3, iter0, batch46/1133, batch loss:6.25099492026493e-05, Training time:40377.00078582764
batch reward last col mean 3.677883341879351e-06 first col mean 3.9964314055396244e-05 all mean 2.2629526938544586e-05
2.5494859073660336e-05 2.5494857254670933e-05
rl training, epoch3, iter0, batch47/1133, batch loss:2.5494857254670933e-05, Training time:40393.90488576889
batch reward last col mean 3.028383730452333e-07 first col mean 2.775236225716071e-06 all mean 1.8128355804947205e-05
2.661557482497301e-05 2.6615571186994202e-05
rl training, epoch3, iter0, batch48/1133, batch loss:2.6615571186994202e-05, Training time:40411.0173368454
batch reward last col mean 9.522537766315509e-06 first col mean 4.9560472689336166e-05 all mean 4.851503763347864e-05
0.00018191778508480638 0.00018191777053289115
rl training, epoch3, iter0, batch49/1133, batch loss:0.00018191777053289115, Training time:40428.124053001404
batch reward last col mean 1.953491164385923e-06 first col mean 3.489021992209018e-06 all mean 4.367508154246025e-05
3.426528928685002e-05 3.426528564887121e-05
rl training, epoch3, iter0, batch50/1133, batch loss:3.426528564887121e-05, Training time:40445.185212135315
batch reward last col mean 1.760406667017378e-05 first col mean 1.0434638170409016e-05 all mean 3.202909283572808e-05
4.653477662941441e-05 4.653477662941441e-05
rl training, epoch3, iter0, batch51/1133, batch loss:4.653477662941441e-05, Training time:40462.30632185936
batch reward last col mean 5.27067595612607e-06 first col mean 0.0002596713602542877 all mean 2.940036756626796e-05
7.925238605821505e-06 7.92524133430561e-06
rl training, epoch3, iter0, batch52/1133, batch loss:7.92524133430561e-06, Training time:40479.47905945778
batch reward last col mean 6.206686521181837e-06 first col mean 5.678886282112217e-06 all mean 1.816233452700544e-05
2.2158201318234205e-05 2.215820313722361e-05
rl training, epoch3, iter0, batch53/1133, batch loss:2.215820313722361e-05, Training time:40496.65529537201
batch reward last col mean 2.9699201604671543e-06 first col mean 0.00017463244148530066 all mean 3.09981987811625e-05
1.478816648159409e-05 1.478816648159409e-05
rl training, epoch3, iter0, batch54/1133, batch loss:1.478816648159409e-05, Training time:40513.777492284775
batch reward last col mean 5.423351922217989e-06 first col mean 1.8368249584455043e-05 all mean 5.836937634740025e-05
5.1753238949459046e-05 5.1753238949459046e-05
rl training, epoch3, iter0, batch55/1133, batch loss:5.1753238949459046e-05, Training time:40530.88896012306
batch reward last col mean 1.559263523631671e-06 first col mean 1.4326923292173888e-06 all mean 3.545428262441419e-05
1.813751987356227e-05 1.8137523511541076e-05
rl training, epoch3, iter0, batch56/1133, batch loss:1.8137523511541076e-05, Training time:40547.88956594467
batch reward last col mean 1.125527774092916e-06 first col mean 3.4209504065074725e-06 all mean 2.671136098797433e-05
2.6392872314318083e-05 2.6392872314318083e-05
rl training, epoch3, iter0, batch57/1133, batch loss:2.6392872314318083e-05, Training time:40564.95279812813
batch reward last col mean 1.8595035271573579e-06 first col mean 2.4400285383308074e-06 all mean 3.937488509109244e-05
8.592952508479357e-05 8.592953236075118e-05
rl training, epoch3, iter0, batch58/1133, batch loss:8.592953236075118e-05, Training time:40581.9860970974
batch reward last col mean 4.3420236579549965e-06 first col mean 5.585674807662144e-05 all mean 8.19178530946374e-05
0.00019644865824375302 0.0001964487018994987
rl training, epoch3, iter0, batch59/1133, batch loss:0.0001964487018994987, Training time:40598.98219513893
batch reward last col mean 8.56294445839012e-06 first col mean 0.002119079465046525 all mean 4.7345201892312616e-05
1.986179267987609e-05 1.9861794498865493e-05
rl training, epoch3, iter0, batch60/1133, batch loss:1.9861794498865493e-05, Training time:40615.94731593132
batch reward last col mean 5.400424197432585e-05 first col mean 1.6354324543499388e-06 all mean 3.3368425647495314e-05
3.66431922884658e-05 3.66431922884658e-05
rl training, epoch3, iter0, batch61/1133, batch loss:3.66431922884658e-05, Training time:40632.9934592247
batch reward last col mean 2.2766023903386667e-05 first col mean 1.5918441931717098e-05 all mean 4.5378310460364446e-05
4.768688449985348e-05 4.768688086187467e-05
rl training, epoch3, iter0, batch62/1133, batch loss:4.768688086187467e-05, Training time:40650.116669893265
batch reward last col mean 5.470679980135174e-07 first col mean 3.675655989354709e-06 all mean 5.563905506278388e-05
0.00011699744209181517 0.00011699743481585756
rl training, epoch3, iter0, batch63/1133, batch loss:0.00011699743481585756, Training time:40667.25487446785
batch reward last col mean 2.0940840386174386e-06 first col mean 1.4697032383992337e-05 all mean 1.682641595834866e-05
1.7405218386556953e-05 1.740521656756755e-05
rl training, epoch3, iter0, batch64/1133, batch loss:1.740521656756755e-05, Training time:40684.34005856514
batch reward last col mean 3.804692823905498e-06 first col mean 2.3164524463936687e-05 all mean 1.6678748579579405e-05
2.9396034733508714e-05 2.939603291451931e-05
rl training, epoch3, iter0, batch65/1133, batch loss:2.939603291451931e-05, Training time:40701.398071050644
batch reward last col mean 2.9572565836133435e-06 first col mean 0.00010785987979033962 all mean 2.4841072445269674e-05
3.0337838325067423e-05 3.0337838325067423e-05
rl training, epoch3, iter0, batch66/1133, batch loss:3.0337838325067423e-05, Training time:40718.37236523628
batch reward last col mean 2.701043285924243e-06 first col mean 1.971518031496089e-06 all mean 3.5633482184493914e-05
2.2629894374404103e-05 2.26298925554147e-05
rl training, epoch3, iter0, batch67/1133, batch loss:2.26298925554147e-05, Training time:40735.28866505623
batch reward last col mean 7.38775838726724e-07 first col mean 5.069471626484301e-06 all mean 1.3860621947969776e-05
7.390898190351436e-06 7.390897735604085e-06
rl training, epoch3, iter0, batch68/1133, batch loss:7.390897735604085e-06, Training time:40752.18881440163
batch reward last col mean 4.997891664970666e-06 first col mean 1.9989802240161225e-06 all mean 2.2603928300668485e-05
4.454169175005518e-05 4.454168811207637e-05
rl training, epoch3, iter0, batch69/1133, batch loss:4.454168811207637e-05, Training time:40769.26153898239
batch reward last col mean 4.208167752040026e-07 first col mean 7.077294867485762e-06 all mean 1.0439741345180664e-05
8.579112545703538e-06 8.579112545703538e-06
rl training, epoch3, iter0, batch70/1133, batch loss:8.579112545703538e-06, Training time:40786.21771860123
batch reward last col mean 0.0011253075208514929 first col mean 3.892187669407576e-05 all mean 0.0006957061705179513
9.477721323492005e-05 9.477721323492005e-05
rl training, epoch3, iter0, batch71/1133, batch loss:9.477721323492005e-05, Training time:40805.42064499855
batch reward last col mean 1.8332855688640848e-05 first col mean 0.0011811855947598815 all mean 9.160431363852695e-05
0.00015397628885693848 0.0001539763034088537
rl training, epoch3, iter0, batch72/1133, batch loss:0.0001539763034088537, Training time:40823.44010043144
batch reward last col mean 2.628434231155552e-06 first col mean 8.121135692817916e-07 all mean 1.3185464013076853e-05
7.835887117835227e-06 7.835888936824631e-06
rl training, epoch3, iter0, batch73/1133, batch loss:7.835888936824631e-06, Training time:40840.3294813633
batch reward last col mean 2.541392518651264e-07 first col mean 0.00035834917798638344 all mean 3.718327570823021e-05
3.87030013371259e-05 3.87030013371259e-05
rl training, epoch3, iter0, batch74/1133, batch loss:3.87030013371259e-05, Training time:40857.245946884155
batch reward last col mean 1.6660889741615392e-05 first col mean 3.2298512451234274e-06 all mean 2.445843165332917e-05
1.9697150491992943e-05 1.9697150491992943e-05
rl training, epoch3, iter0, batch75/1133, batch loss:1.9697150491992943e-05, Training time:40874.13489770889
batch reward last col mean 0.00035367158125154674 first col mean 6.581038860531407e-07 all mean 0.0002082924183923751
4.579545930027962e-05 4.5795462938258424e-05
rl training, epoch3, iter0, batch76/1133, batch loss:4.5795462938258424e-05, Training time:40891.09846019745
batch reward last col mean 8.045858521654736e-07 first col mean 3.281100725871511e-05 all mean 2.150687032553833e-05
1.654087463975884e-05 1.6540872820769437e-05
rl training, epoch3, iter0, batch77/1133, batch loss:1.6540872820769437e-05, Training time:40908.08994078636
batch reward last col mean 2.3704573322902434e-05 first col mean 5.030105967307463e-06 all mean 3.357547029736452e-05
1.7650099835009314e-05 1.7650096197030507e-05
rl training, epoch3, iter0, batch78/1133, batch loss:1.7650096197030507e-05, Training time:40926.11566400528
batch reward last col mean 9.424375093658455e-06 first col mean 3.879820724250749e-06 all mean 2.2244879801291972e-05
1.4657094652648084e-05 1.4657093743153382e-05
rl training, epoch3, iter0, batch79/1133, batch loss:1.4657093743153382e-05, Training time:40943.30374574661
batch reward last col mean 3.9484566514147446e-06 first col mean 4.217680179863237e-05 all mean 2.4311209926963784e-05
4.402437116368674e-05 4.402436752570793e-05
rl training, epoch3, iter0, batch80/1133, batch loss:4.402436752570793e-05, Training time:40960.58655643463
batch reward last col mean 0.0001106473064282909 first col mean 1.7742488580552163e-06 all mean 7.915924652479589e-05
4.33285313192755e-05 4.33285313192755e-05
rl training, epoch3, iter0, batch81/1133, batch loss:4.33285313192755e-05, Training time:40977.62182402611
batch reward last col mean 0.001839859178289771 first col mean 1.4542414646712132e-05 all mean 0.0016779517754912376
0.00012230245920363814 0.0001223024446517229
rl training, epoch3, iter0, batch82/1133, batch loss:0.0001223024446517229, Training time:40994.69855976105
batch reward last col mean 0.00012561910261865705 first col mean 9.975537250284106e-05 all mean 8.667325892020017e-05
3.3562213502591476e-05 3.356221714057028e-05
rl training, epoch3, iter0, batch83/1133, batch loss:3.356221714057028e-05, Training time:41012.88884592056
batch reward last col mean 1.677745967754163e-05 first col mean 3.6698147596325725e-06 all mean 2.157926428481005e-05
2.6288664230378345e-05 2.6288664230378345e-05
rl training, epoch3, iter0, batch84/1133, batch loss:2.6288664230378345e-05, Training time:41031.508831977844
batch reward last col mean 1.0323088645236567e-05 first col mean 0.000170541723491624 all mean 2.2278522010310553e-05
2.4859069526428357e-05 2.4859067707438953e-05
rl training, epoch3, iter0, batch85/1133, batch loss:2.4859067707438953e-05, Training time:41049.981638908386
batch reward last col mean 0.0003587386745493859 first col mean 1.932624172695796e-06 all mean 0.00016809831140562892
3.684767580125481e-05 3.684767580125481e-05
rl training, epoch3, iter0, batch86/1133, batch loss:3.684767580125481e-05, Training time:41067.157990694046
batch reward last col mean 1.8331247702008113e-05 first col mean 1.7223272152477875e-05 all mean 2.5748886400833726e-05
2.8639657102758065e-05 2.8639651645789854e-05
rl training, epoch3, iter0, batch87/1133, batch loss:2.8639651645789854e-05, Training time:41084.07151603699
batch reward last col mean 0.001479842234402895 first col mean 3.50484106093063e-06 all mean 6.336989463306963e-05
0.00012488132051657885 0.00012488132051657885
rl training, epoch3, iter0, batch88/1133, batch loss:0.00012488132051657885, Training time:41100.84485435486
batch reward last col mean 1.3243464991319343e-06 first col mean 2.125265837094048e-06 all mean 4.09056301577948e-05
5.210225936025381e-05 5.210225936025381e-05
rl training, epoch3, iter0, batch89/1133, batch loss:5.210225936025381e-05, Training time:41119.46695065498
batch reward last col mean 1.7337886220047949e-06 first col mean 3.508978352328995e-07 all mean 3.2807383831823245e-05
6.155855226097628e-05 6.15585595369339e-05
rl training, epoch3, iter0, batch90/1133, batch loss:6.15585595369339e-05, Training time:41136.4214990139
batch reward last col mean 3.5806856431008782e-06 first col mean 4.185257694189204e-06 all mean 2.0303217752370983e-05
2.5222967451554723e-05 2.5222967451554723e-05
rl training, epoch3, iter0, batch91/1133, batch loss:2.5222967451554723e-05, Training time:41153.44158220291
batch reward last col mean 5.863786100235302e-06 first col mean 1.3013750503887422e-05 all mean 4.338081635069102e-05
5.6553599279141054e-05 5.6553595641162246e-05
rl training, epoch3, iter0, batch92/1133, batch loss:5.6553595641162246e-05, Training time:41170.27710175514
batch reward last col mean 9.652444532548543e-06 first col mean 6.240880338737043e-06 all mean 2.412363755865954e-05
2.09801673918264e-05 2.098016375384759e-05
rl training, epoch3, iter0, batch93/1133, batch loss:2.098016375384759e-05, Training time:41187.202655792236
batch reward last col mean 0.0003791584458667785 first col mean 2.3124506697058678e-05 all mean 0.00026756033184938133
9.590016270522028e-05 9.59001699811779e-05
rl training, epoch3, iter0, batch94/1133, batch loss:9.59001699811779e-05, Training time:41204.12059521675
batch reward last col mean 1.75895092979772e-05 first col mean 2.602307176857721e-06 all mean 5.242098632152192e-05
4.9297897930955514e-05 4.929789429297671e-05
rl training, epoch3, iter0, batch95/1133, batch loss:4.929789429297671e-05, Training time:41221.09042882919
batch reward last col mean 2.1632738935295492e-05 first col mean 0.0014488418819382787 all mean 3.776581070269458e-05
2.638777186803054e-05 2.6387768230051734e-05
rl training, epoch3, iter0, batch96/1133, batch loss:2.6387768230051734e-05, Training time:41239.216748952866
batch reward last col mean 3.369311525602825e-05 first col mean 3.3478384011687012e-06 all mean 3.641040893853642e-05
6.882876914460212e-05 6.882877642055973e-05
rl training, epoch3, iter0, batch97/1133, batch loss:6.882877642055973e-05, Training time:41257.82862973213
batch reward last col mean 1.3143940122972708e-06 first col mean 9.95948284980841e-05 all mean 2.9463795726769604e-05
1.8151451513404027e-05 1.815144787542522e-05
rl training, epoch3, iter0, batch98/1133, batch loss:1.815144787542522e-05, Training time:41274.58908987045
batch reward last col mean 2.2658227862848435e-06 first col mean 1.889857776404824e-05 all mean 2.8500278858700767e-05
3.103247581748292e-05 3.103247217950411e-05
rl training, epoch3, iter0, batch99/1133, batch loss:3.103247217950411e-05, Training time:41292.91383481026
batch reward last col mean 0.00013180705718696117 first col mean 9.8217087725061e-06 all mean 0.00011084553261753172
0.000161545627634041 0.000161545627634041
rl training, epoch3, iter0, batch100/1133, batch loss:0.000161545627634041, Training time:41311.531937122345
batch reward last col mean 3.3828429877758026e-05 first col mean 2.2969848032516893e-06 all mean 4.191985499346629e-05
3.3734388125594705e-05 3.3734388125594705e-05
rl training, epoch3, iter0, batch101/1133, batch loss:3.3734388125594705e-05, Training time:41328.56017899513
batch reward last col mean 1.8506718333810568e-05 first col mean 0.00010059241321869195 all mean 3.695736813824624e-05
9.306324500357732e-05 9.30632304516621e-05
rl training, epoch3, iter0, batch102/1133, batch loss:9.30632304516621e-05, Training time:41346.26884436607
batch reward last col mean 1.3674195997737115e-06 first col mean 2.7260666684014723e-05 all mean 2.5312438083346933e-05
2.9616312531288713e-05 2.961631071229931e-05
rl training, epoch3, iter0, batch103/1133, batch loss:2.961631071229931e-05, Training time:41363.112111091614
batch reward last col mean 2.8129161364631727e-06 first col mean 1.8995287973666564e-06 all mean 3.40965561917983e-05
8.630548836663365e-05 8.630548836663365e-05
rl training, epoch3, iter0, batch104/1133, batch loss:8.630548836663365e-05, Training time:41379.745624780655
batch reward last col mean 0.00017168582417070866 first col mean 0.0011022684630006552 all mean 0.0001879142364487052
3.061579627683386e-05 3.0615803552791476e-05
rl training, epoch3, iter0, batch105/1133, batch loss:3.0615803552791476e-05, Training time:41396.60749721527
batch reward last col mean 5.722682772102416e-07 first col mean 6.635951194766676e-06 all mean 2.1989053493598476e-05
1.096787764254259e-05 1.0967879461531993e-05
rl training, epoch3, iter0, batch106/1133, batch loss:1.0967879461531993e-05, Training time:41415.31540250778
batch reward last col mean 1.7442287969515746e-07 first col mean 0.0007909790147095919 all mean 9.854301606537774e-05
0.00012675017933361232 0.00012675019388552755
rl training, epoch3, iter0, batch107/1133, batch loss:0.00012675019388552755, Training time:41432.2464222908
batch reward last col mean 3.040366038931097e-07 first col mean 1.218402644553862e-06 all mean 2.721523014770355e-05
3.55772499460727e-05 3.55772499460727e-05
rl training, epoch3, iter0, batch108/1133, batch loss:3.55772499460727e-05, Training time:41449.37257838249
batch reward last col mean 3.476102210697718e-05 first col mean 2.7012267764803255e-06 all mean 3.163323344779201e-05
2.261964800709393e-05 2.2619646188104525e-05
rl training, epoch3, iter0, batch109/1133, batch loss:2.2619646188104525e-05, Training time:41466.43728733063
batch reward last col mean 1.3018352547078393e-05 first col mean 9.188020158035215e-06 all mean 3.4223179682157934e-05
7.007643580436707e-05 7.007642852840945e-05
rl training, epoch3, iter0, batch110/1133, batch loss:7.007642852840945e-05, Training time:41483.52183008194
batch reward last col mean 0.00561849121004343 first col mean 5.771391329290054e-07 all mean 0.005387433804571629
0.0002880650863517076 0.0002880650863517076
rl training, epoch3, iter0, batch111/1133, batch loss:0.0002880650863517076, Training time:41500.557114601135
batch reward last col mean 8.955153134593274e-07 first col mean 3.9964525058167055e-06 all mean 1.4455680684477556e-05
1.539676304673776e-05 1.5396761227748357e-05
rl training, epoch3, iter0, batch112/1133, batch loss:1.5396761227748357e-05, Training time:41517.44244289398
batch reward last col mean 8.466287545161322e-05 first col mean 0.00044386222725734115 all mean 3.487893991405144e-05
2.0052859326824546e-05 2.0052859326824546e-05
rl training, epoch3, iter0, batch113/1133, batch loss:2.0052859326824546e-05, Training time:41536.14565825462
batch reward last col mean 1.3253083125164267e-05 first col mean 1.3501435205398593e-06 all mean 6.498205766547471e-05
0.00011606900079641491 0.00011606900079641491
rl training, epoch3, iter0, batch114/1133, batch loss:0.00011606900079641491, Training time:41554.71814060211
batch reward last col mean 3.3908804653037805e-07 first col mean 9.047881576407235e-06 all mean 3.207542249583639e-05
8.977582911029458e-05 8.977581455837935e-05
rl training, epoch3, iter0, batch115/1133, batch loss:8.977581455837935e-05, Training time:41571.50967168808
batch reward last col mean 3.217007815692341e-07 first col mean 0.00043208946590311825 all mean 3.356825982336886e-05
2.3637028789380565e-05 2.3637028789380565e-05
rl training, epoch3, iter0, batch116/1133, batch loss:2.3637028789380565e-05, Training time:41588.24771285057
batch reward last col mean 1.2623180737136863e-05 first col mean 0.0007865984225645661 all mean 2.9040855224593543e-05
2.5566128897480667e-05 2.5566128897480667e-05
rl training, epoch3, iter0, batch117/1133, batch loss:2.5566128897480667e-05, Training time:41605.13313770294
batch reward last col mean 0.003290826454758644 first col mean 5.760206022387138e-06 all mean 0.0027246030513197184
0.00025801738956943154 0.00025801738956943154
rl training, epoch3, iter0, batch118/1133, batch loss:0.00025801738956943154, Training time:41622.277651786804
batch reward last col mean 4.648155936592957e-06 first col mean 6.698259085169411e-07 all mean 4.414588329382241e-05
5.658925147145055e-05 5.6589247833471745e-05
rl training, epoch3, iter0, batch119/1133, batch loss:5.6589247833471745e-05, Training time:41639.30959939957
batch reward last col mean 1.0014871804742143e-05 first col mean 0.0009720600210130215 all mean 4.026184615213424e-05
3.788061439990997e-05 3.7880610761931166e-05
rl training, epoch3, iter0, batch120/1133, batch loss:3.7880610761931166e-05, Training time:41656.312843322754
batch reward last col mean 0.00021329830633476377 first col mean 8.918242997424386e-07 all mean 0.00020371338177938014
0.00014507760351989418 0.0001450776180718094
rl training, epoch3, iter0, batch121/1133, batch loss:0.0001450776180718094, Training time:41673.05252480507
batch reward last col mean 3.329739399760001e-07 first col mean 2.4065384423010983e-06 all mean 3.678699067677371e-05
4.4307103962637484e-05 4.4307103962637484e-05
rl training, epoch3, iter0, batch122/1133, batch loss:4.4307103962637484e-05, Training time:41689.87764811516
batch reward last col mean 0.0024335775524377823 first col mean 1.3188540606279275e-06 all mean 0.002310096984729171
0.00025968949194066226 0.0002596894628368318
rl training, epoch3, iter0, batch123/1133, batch loss:0.0002596894628368318, Training time:41706.754177331924
batch reward last col mean 1.4801165661992854e-06 first col mean 4.264496055839118e-06 all mean 4.521934170043096e-05
2.4147679141606204e-05 2.4147679141606204e-05
rl training, epoch3, iter0, batch124/1133, batch loss:2.4147679141606204e-05, Training time:41723.626470804214
batch reward last col mean 2.754484194156248e-05 first col mean 8.232008440245409e-06 all mean 4.149907545070164e-05
1.9742052245419472e-05 1.9742052245419472e-05
rl training, epoch3, iter0, batch125/1133, batch loss:1.9742052245419472e-05, Training time:41740.73894762993
batch reward last col mean 2.8684667086054105e-06 first col mean 3.600696800276637e-06 all mean 4.080875078216195e-05
9.637079347157851e-05 9.637079347157851e-05
rl training, epoch3, iter0, batch126/1133, batch loss:9.637079347157851e-05, Training time:41757.75845575333
batch reward last col mean 4.2122641730202304e-07 first col mean 1.2981965937797213e-06 all mean 2.0820205463678576e-05
1.393313505104743e-05 1.3933136870036833e-05
rl training, epoch3, iter0, batch127/1133, batch loss:1.3933136870036833e-05, Training time:41774.712886571884
batch reward last col mean 1.6673727714078268e-06 first col mean 5.8311692555435e-05 all mean 6.153608410386369e-05
4.272724618203938e-05 4.272724618203938e-05
rl training, epoch3, iter0, batch128/1133, batch loss:4.272724618203938e-05, Training time:41791.70009851456
batch reward last col mean 3.04376544590923e-06 first col mean 0.0001231451751664281 all mean 7.659872062504292e-05
5.5897438869578764e-05 5.589742067968473e-05
rl training, epoch3, iter0, batch129/1133, batch loss:5.589742067968473e-05, Training time:41808.58347439766
batch reward last col mean 0.00011033088230760768 first col mean 0.00011064109276048839 all mean 0.00012345871073193848
0.00010191623732680455 0.00010191623732680455
rl training, epoch3, iter0, batch130/1133, batch loss:0.00010191623732680455, Training time:41825.4654712677
batch reward last col mean 5.239779966359492e-06 first col mean 1.6020691191442893e-06 all mean 3.476088750176132e-05
2.8816597477998585e-05 2.8816597477998585e-05
rl training, epoch3, iter0, batch131/1133, batch loss:2.8816597477998585e-05, Training time:41842.272018671036
batch reward last col mean 9.552868505124934e-06 first col mean 7.2535972321929876e-06 all mean 2.314959783689119e-05
3.849023050861433e-05 3.849023414659314e-05
rl training, epoch3, iter0, batch132/1133, batch loss:3.849023414659314e-05, Training time:41860.22940325737
batch reward last col mean 5.417321631284722e-07 first col mean 0.00022209480812307447 all mean 4.419570541358553e-05
9.783104906091467e-05 9.783104906091467e-05
rl training, epoch3, iter0, batch133/1133, batch loss:9.783104906091467e-05, Training time:41877.017736911774
batch reward last col mean 2.934382109742728e-06 first col mean 3.3669052754703443e-06 all mean 7.30317406123504e-05
0.00017474271589890122 0.00017474273045081645
rl training, epoch3, iter0, batch134/1133, batch loss:0.00017474273045081645, Training time:41893.98351979256
batch reward last col mean 3.610725798353087e-07 first col mean 1.2728962246910669e-05 all mean 1.5205377167148981e-05
1.2679207429755479e-05 1.2679206520260777e-05
rl training, epoch3, iter0, batch135/1133, batch loss:1.2679206520260777e-05, Training time:41910.909574747086
batch reward last col mean 4.992869889974827e-06 first col mean 1.6407910152338445e-05 all mean 3.157936953357421e-05
1.6503643564647064e-05 1.6503645383636467e-05
rl training, epoch3, iter0, batch136/1133, batch loss:1.6503645383636467e-05, Training time:41927.84526395798
batch reward last col mean 0.00023261731257662177 first col mean 1.0694793672882952e-05 all mean 0.0002618898288346827
0.0001729339564917609 0.0001729339564917609
rl training, epoch3, iter0, batch137/1133, batch loss:0.0001729339564917609, Training time:41944.83452320099
batch reward last col mean 1.0683420441637281e-06 first col mean 3.1202202080748975e-05 all mean 6.205079262144864e-05
0.00029041158268228173 0.00029041158268228173
rl training, epoch3, iter0, batch138/1133, batch loss:0.00029041158268228173, Training time:41961.90814304352
batch reward last col mean 8.08719732958707e-07 first col mean 1.0126447023139917e-06 all mean 1.2073811376467347e-05
1.6920386769925244e-05 1.6920386769925244e-05
rl training, epoch3, iter0, batch139/1133, batch loss:1.6920386769925244e-05, Training time:41978.94525194168
batch reward last col mean 0.0001192444542539306 first col mean 7.914253728813492e-06 all mean 0.00013185397256165743
0.0001322465541306883 0.0001322465541306883
rl training, epoch3, iter0, batch140/1133, batch loss:0.0001322465541306883, Training time:41995.96945357323
batch reward last col mean 2.0396048057591543e-05 first col mean 1.0312011227142648e-06 all mean 2.9299408197402954e-05
7.076827751006931e-05 7.07682702341117e-05
rl training, epoch3, iter0, batch141/1133, batch loss:7.07682702341117e-05, Training time:42013.0480389595
batch reward last col mean 1.062900719261961e-05 first col mean 2.3536431399406865e-06 all mean 5.202292959438637e-05
4.475688547245227e-05 4.475688547245227e-05
rl training, epoch3, iter0, batch142/1133, batch loss:4.475688547245227e-05, Training time:42029.9237742424
batch reward last col mean 1.697845982562285e-05 first col mean 2.99781436297053e-06 all mean 2.4331338863703422e-05
2.075326665362809e-05 2.0753268472617492e-05
rl training, epoch3, iter0, batch143/1133, batch loss:2.0753268472617492e-05, Training time:42046.75344777107
batch reward last col mean 1.6231979316216893e-05 first col mean 2.6144212824874558e-05 all mean 5.5604850786039606e-05
6.523163028759882e-05 6.523161573568359e-05
rl training, epoch3, iter0, batch144/1133, batch loss:6.523161573568359e-05, Training time:42063.58595299721
batch reward last col mean 4.896640803053742e-06 first col mean 0.0002469593018759042 all mean 5.200616578804329e-05
0.0001249810156878084 0.00012498100113589317
rl training, epoch3, iter0, batch145/1133, batch loss:0.00012498100113589317, Training time:42080.558057546616
batch reward last col mean 7.943888704176061e-06 first col mean 5.2774976211367175e-05 all mean 3.402999209356494e-05
1.3544431567424908e-05 1.3544431567424908e-05
rl training, epoch3, iter0, batch146/1133, batch loss:1.3544431567424908e-05, Training time:42097.57125854492
batch reward last col mean 0.0010464383522048593 first col mean 7.634535904799122e-06 all mean 0.0009987849043682218
9.571350528858602e-05 9.571350528858602e-05
rl training, epoch3, iter0, batch147/1133, batch loss:9.571350528858602e-05, Training time:42114.35820889473
batch reward last col mean 1.3105925518175354e-06 first col mean 0.00014616266707889736 all mean 4.1703278839122504e-05
7.583531260024756e-05 7.583530532428995e-05
rl training, epoch3, iter0, batch148/1133, batch loss:7.583530532428995e-05, Training time:42131.19118666649
batch reward last col mean 0.00010802837641676888 first col mean 5.220200910116546e-05 all mean 2.5319246560684405e-05
2.8098349503125064e-05 2.8098351322114468e-05
rl training, epoch3, iter0, batch149/1133, batch loss:2.8098351322114468e-05, Training time:42147.947217702866
batch reward last col mean 1.1397289654269116e-06 first col mean 0.0024591567926108837 all mean 4.423038262757473e-05
2.2121108486317098e-05 2.2121115762274712e-05
rl training, epoch3, iter0, batch150/1133, batch loss:2.2121115762274712e-05, Training time:42164.879794597626
batch reward last col mean 3.9883857425593305e-06 first col mean 2.019357452809345e-06 all mean 2.622517422423698e-05
3.459129948168993e-05 3.459129584371112e-05
rl training, epoch3, iter0, batch151/1133, batch loss:3.459129584371112e-05, Training time:42181.890906095505
batch reward last col mean 2.5583219667169033e-06 first col mean 1.0471308087289799e-05 all mean 2.9662924134754576e-05
2.744983066804707e-05 2.7449827030068263e-05
rl training, epoch3, iter0, batch152/1133, batch loss:2.7449827030068263e-05, Training time:42198.90176820755
batch reward last col mean 0.0008871979080140591 first col mean 9.892021807900164e-06 all mean 0.0008912918856367469
0.00012600306945387274 0.00012600306945387274
rl training, epoch3, iter0, batch153/1133, batch loss:0.00012600306945387274, Training time:42215.90743756294
batch reward last col mean 2.79286524573763e-07 first col mean 0.0005319330375641584 all mean 4.35970832768362e-05
2.8633579859160818e-05 2.863357622118201e-05
rl training, epoch3, iter0, batch154/1133, batch loss:2.863357622118201e-05, Training time:42232.777953624725
batch reward last col mean 1.506305466136837e-06 first col mean 2.146665792679414e-06 all mean 2.7625434086075984e-05
4.6693319745827466e-05 4.6693319745827466e-05
rl training, epoch3, iter0, batch155/1133, batch loss:4.6693319745827466e-05, Training time:42249.74356460571
batch reward last col mean 6.56210831948556e-05 first col mean 1.3873536772734951e-05 all mean 9.53159760683775e-05
3.730211756192148e-05 3.730211756192148e-05
rl training, epoch3, iter0, batch156/1133, batch loss:3.730211756192148e-05, Training time:42266.57688617706
batch reward last col mean 1.3644661521539092e-05 first col mean 0.0002370798320043832 all mean 6.012462472426705e-05
3.486874629743397e-05 3.486874993541278e-05
rl training, epoch3, iter0, batch157/1133, batch loss:3.486874993541278e-05, Training time:42284.310879945755
batch reward last col mean 5.252093615126796e-06 first col mean 2.2003894628142007e-05 all mean 4.025726957479492e-05
8.827845886116847e-05 8.827846613712609e-05
rl training, epoch3, iter0, batch158/1133, batch loss:8.827846613712609e-05, Training time:42301.37133717537
batch reward last col mean 0.0002169829822378233 first col mean 0.0015143482014536858 all mean 4.727569466922432e-05
4.928673297399655e-05 4.9286725698038936e-05
rl training, epoch3, iter0, batch159/1133, batch loss:4.9286725698038936e-05, Training time:42319.113114118576
batch reward last col mean 4.32539945904864e-06 first col mean 6.010693596181227e-06 all mean 5.845564737683162e-05
4.5991051592864096e-05 4.5991051592864096e-05
rl training, epoch3, iter0, batch160/1133, batch loss:4.5991051592864096e-05, Training time:42337.72344017029
batch reward last col mean 8.338706152244413e-07 first col mean 2.8703236694127554e-06 all mean 3.13053787976969e-05
6.566362571902573e-05 6.566362571902573e-05
rl training, epoch3, iter0, batch161/1133, batch loss:6.566362571902573e-05, Training time:42356.4953827858
batch reward last col mean 5.710588766305591e-07 first col mean 1.160983856607345e-06 all mean 5.856865755049512e-05
0.0001521300437161699 0.00015213001461233944
rl training, epoch3, iter0, batch162/1133, batch loss:0.00015213001461233944, Training time:42373.85988616943
batch reward last col mean 1.7827993360697292e-05 first col mean 3.736239159479737e-05 all mean 2.94115707220044e-05
6.47546912659891e-05 6.475467671407387e-05
rl training, epoch3, iter0, batch163/1133, batch loss:6.475467671407387e-05, Training time:42390.86950302124
batch reward last col mean 2.7407440938986838e-05 first col mean 1.1980796443822328e-05 all mean 5.002117541152984e-05
4.975499541615136e-05 4.975499905413017e-05
rl training, epoch3, iter0, batch164/1133, batch loss:4.975499905413017e-05, Training time:42407.55697798729
batch reward last col mean 5.339940685189504e-07 first col mean 6.984872743487358e-05 all mean 2.4780792955425568e-05
5.1364298997214064e-05 5.136429535923526e-05
rl training, epoch3, iter0, batch165/1133, batch loss:5.136429535923526e-05, Training time:42424.468027830124
batch reward last col mean 1.0078564628202002e-05 first col mean 0.0001755774428602308 all mean 4.7257039113901556e-05
5.111196151119657e-05 5.111196151119657e-05
rl training, epoch3, iter0, batch166/1133, batch loss:5.111196151119657e-05, Training time:42441.467401981354
batch reward last col mean 2.8895879040646832e-06 first col mean 1.7572045180713758e-05 all mean 3.5637873224914074e-05
5.361093644751236e-05 5.361092553357594e-05
rl training, epoch3, iter0, batch167/1133, batch loss:5.361092553357594e-05, Training time:42458.947939157486
batch reward last col mean 1.959012479346711e-06 first col mean 2.0353485524537973e-05 all mean 1.2014758794975933e-05
7.013339200057089e-06 7.013340109551791e-06
rl training, epoch3, iter0, batch168/1133, batch loss:7.013340109551791e-06, Training time:42476.361050367355
batch reward last col mean 1.2084919944754802e-05 first col mean 3.972040212829597e-05 all mean 3.799386104219593e-05
2.2763771994505078e-05 2.2763771994505078e-05
rl training, epoch3, iter0, batch169/1133, batch loss:2.2763771994505078e-05, Training time:42494.12768530846
batch reward last col mean 7.163056920944655e-07 first col mean 3.1017996661830693e-05 all mean 4.5389107981463894e-05
0.00013349131040740758 0.00013349129585549235
rl training, epoch3, iter0, batch170/1133, batch loss:0.00013349129585549235, Training time:42512.45246100426
batch reward last col mean 3.370559625182068e-06 first col mean 1.566494393046014e-05 all mean 5.598994539468549e-05
5.231146496953443e-05 5.231145769357681e-05
rl training, epoch3, iter0, batch171/1133, batch loss:5.231145769357681e-05, Training time:42529.53739786148
batch reward last col mean 0.0003583582874853164 first col mean 0.00020805471285711974 all mean 3.1836498237680644e-05
2.794357351376675e-05 2.7943571694777347e-05
rl training, epoch3, iter0, batch172/1133, batch loss:2.7943571694777347e-05, Training time:42547.16557431221
batch reward last col mean 8.249200618593022e-06 first col mean 3.7229983718134463e-06 all mean 4.039899431518279e-05
5.839809819008224e-05 5.839809819008224e-05
rl training, epoch3, iter0, batch173/1133, batch loss:5.839809819008224e-05, Training time:42564.59741950035
batch reward last col mean 5.3235348786984105e-06 first col mean 9.530034731142223e-05 all mean 2.466857768013142e-05
1.1488868949527387e-05 1.1488866221043281e-05
rl training, epoch3, iter0, batch174/1133, batch loss:1.1488866221043281e-05, Training time:42583.154472112656
batch reward last col mean 4.7636157773922605e-07 first col mean 0.0010954359313473105 all mean 6.649753049714491e-05
6.456484697991982e-05 6.456484697991982e-05
rl training, epoch3, iter0, batch175/1133, batch loss:6.456484697991982e-05, Training time:42601.958656311035
batch reward last col mean 1.0227710163235315e-06 first col mean 2.8745753297698684e-05 all mean 1.8644605006556958e-05
1.7306279914919287e-05 1.7306279914919287e-05
rl training, epoch3, iter0, batch176/1133, batch loss:1.7306279914919287e-05, Training time:42620.18387532234
batch reward last col mean 3.3317095926577167e-07 first col mean 6.550188118126243e-06 all mean 2.4972525352495722e-05
3.0186172807589173e-05 3.0186172807589173e-05
rl training, epoch3, iter0, batch177/1133, batch loss:3.0186172807589173e-05, Training time:42638.338708400726
batch reward last col mean 2.8726199730044755e-07 first col mean 0.0017695396672934294 all mean 6.379902333719656e-05
4.49980580015108e-05 4.49980580015108e-05
rl training, epoch3, iter0, batch178/1133, batch loss:4.49980580015108e-05, Training time:42655.592505693436
batch reward last col mean 1.6493393559358083e-05 first col mean 1.442253278582939e-06 all mean 5.332759610610083e-05
8.692441770108417e-05 8.692441042512655e-05
rl training, epoch3, iter0, batch179/1133, batch loss:8.692441042512655e-05, Training time:42673.70509934425
batch reward last col mean 2.1314492641977267e-06 first col mean 2.152038860003813e-06 all mean 4.589035961544141e-05
5.5423246521968395e-05 5.5423246521968395e-05
rl training, epoch3, iter0, batch180/1133, batch loss:5.5423246521968395e-05, Training time:42692.01720285416
batch reward last col mean 6.977792963880347e-06 first col mean 0.0002479027316439897 all mean 3.1502218917012215e-05
3.1217739888234064e-05 3.121774716419168e-05
rl training, epoch3, iter0, batch181/1133, batch loss:3.121774716419168e-05, Training time:42709.47323489189
batch reward last col mean 3.2322716947419394e-07 first col mean 2.2123163944343105e-05 all mean 2.2276948584476486e-05
2.4035787646425888e-05 2.403578400844708e-05
rl training, epoch3, iter0, batch182/1133, batch loss:2.403578400844708e-05, Training time:42726.63117003441
batch reward last col mean 1.4808577361691277e-05 first col mean 0.0014575797831639647 all mean 6.41465449007228e-05
6.711894820909947e-05 6.711894820909947e-05
rl training, epoch3, iter0, batch183/1133, batch loss:6.711894820909947e-05, Training time:42744.468685388565
batch reward last col mean 1.3586788554675877e-05 first col mean 0.0006129348184913397 all mean 2.5330795324407518e-05
1.7722575648804195e-05 1.772257382981479e-05
rl training, epoch3, iter0, batch184/1133, batch loss:1.772257382981479e-05, Training time:42761.885125637054
batch reward last col mean 1.7228768456334365e-06 first col mean 5.645177225233056e-06 all mean 3.18301645165775e-05
8.362674998352304e-05 8.36267281556502e-05
rl training, epoch3, iter0, batch185/1133, batch loss:8.36267281556502e-05, Training time:42779.10419654846
batch reward last col mean 1.101344150811201e-05 first col mean 3.7551892546616727e-06 all mean 5.2389586926437914e-05
5.481805055751465e-05 5.4818061471451074e-05
rl training, epoch3, iter0, batch186/1133, batch loss:5.4818061471451074e-05, Training time:42797.28559446335
batch reward last col mean 0.0002826713025569916 first col mean 3.19310720442445e-06 all mean 0.0002545686438679695
3.986421143054031e-05 3.986421143054031e-05
rl training, epoch3, iter0, batch187/1133, batch loss:3.986421143054031e-05, Training time:42815.44916963577
batch reward last col mean 2.2619329683948308e-05 first col mean 6.489972747658612e-06 all mean 3.121752888546325e-05
4.418666867422871e-05 4.418666867422871e-05
rl training, epoch3, iter0, batch188/1133, batch loss:4.418666867422871e-05, Training time:42833.165707826614
batch reward last col mean 2.4663218027853873e-06 first col mean 7.16172726242803e-05 all mean 6.545407813973725e-05
0.00010116031626239419 0.00010116031626239419
rl training, epoch3, iter0, batch189/1133, batch loss:0.00010116031626239419, Training time:42850.76207256317
batch reward last col mean 4.57233227280085e-06 first col mean 5.141205292602535e-06 all mean 4.614165300154127e-05
7.645838923053816e-05 7.645838195458055e-05
rl training, epoch3, iter0, batch190/1133, batch loss:7.645838195458055e-05, Training time:42868.62357068062
batch reward last col mean 2.0815599782508798e-05 first col mean 9.88981901173247e-06 all mean 3.2217660191236064e-05
2.7815411158371717e-05 2.781540752039291e-05
rl training, epoch3, iter0, batch191/1133, batch loss:2.781540752039291e-05, Training time:42886.90815448761
batch reward last col mean 3.3315336622763425e-06 first col mean 3.5225095871282974e-06 all mean 2.013454468396958e-05
3.212840965716168e-05 3.212840965716168e-05
rl training, epoch3, iter0, batch192/1133, batch loss:3.212840965716168e-05, Training time:42904.912684202194
batch reward last col mean 6.780496732972097e-06 first col mean 0.0005980823771096766 all mean 1.9559820430004038e-05
1.1272844858467579e-05 1.1272846677456982e-05
rl training, epoch3, iter0, batch193/1133, batch loss:1.1272846677456982e-05, Training time:42922.73735547066
batch reward last col mean 5.553462756324734e-07 first col mean 0.00011647382052615285 all mean 1.6032769053708762e-05
1.3779691471427213e-05 1.3779691471427213e-05
rl training, epoch3, iter0, batch194/1133, batch loss:1.3779691471427213e-05, Training time:42941.32690215111
batch reward last col mean 4.474191882763989e-06 first col mean 4.45655587100191e-06 all mean 4.520342554314993e-05
4.6308028686326e-05 4.630802141036838e-05
rl training, epoch3, iter0, batch195/1133, batch loss:4.630802141036838e-05, Training time:42959.78126335144
batch reward last col mean 5.769049380432989e-07 first col mean 0.0003671034355647862 all mean 3.002534322149586e-05
1.7349637346342206e-05 1.7349635527352802e-05
rl training, epoch3, iter0, batch196/1133, batch loss:1.7349635527352802e-05, Training time:42978.08401417732
batch reward last col mean 8.820850894153409e-07 first col mean 2.9362040550040547e-06 all mean 2.5722003556438722e-05
2.0588702682289295e-05 2.0588708139257506e-05
rl training, epoch3, iter0, batch197/1133, batch loss:2.0588708139257506e-05, Training time:42996.27069377899
batch reward last col mean 1.0368215953349136e-05 first col mean 9.957465408660937e-06 all mean 2.358281926717609e-05
1.4381389519257937e-05 1.4381388609763235e-05
rl training, epoch3, iter0, batch198/1133, batch loss:1.4381388609763235e-05, Training time:43013.55979537964
batch reward last col mean 1.4797386711506988e-06 first col mean 0.00011321329657221213 all mean 1.756856363499537e-05
1.7975373339140788e-05 1.7975371520151384e-05
rl training, epoch3, iter0, batch199/1133, batch loss:1.7975371520151384e-05, Training time:43031.40792250633
batch reward last col mean 0.00017325321095995605 first col mean 0.00019910580886062235 all mean 0.00010869459947571158
3.167621252941899e-05 3.16762161673978e-05
rl training, epoch3, iter0, batch200/1133, batch loss:3.16762161673978e-05, Training time:43049.250863313675
batch reward last col mean 4.0377267396252137e-07 first col mean 0.0006776567315682769 all mean 5.5927834182512015e-05
0.00014571721840184182 0.0001457172038499266
rl training, epoch3, iter0, batch201/1133, batch loss:0.0001457172038499266, Training time:43067.25865101814
batch reward last col mean 7.249532245623413e-07 first col mean 2.940920057881158e-05 all mean 1.5675268514314666e-05
2.0265160856069997e-05 2.0265159037080593e-05
rl training, epoch3, iter0, batch202/1133, batch loss:2.0265159037080593e-05, Training time:43085.34961819649
batch reward last col mean 0.0006634708843193948 first col mean 1.8307009668205865e-05 all mean 0.0006592511781491339
0.0001241888094227761 0.00012418879487086087
rl training, epoch3, iter0, batch203/1133, batch loss:0.00012418879487086087, Training time:43103.520011901855
batch reward last col mean 1.0705002750910353e-06 first col mean 0.0003244093677494675 all mean 3.2476684282300994e-05
2.835892519215122e-05 2.8358923373161815e-05
rl training, epoch3, iter0, batch204/1133, batch loss:2.8358923373161815e-05, Training time:43121.46367311478
batch reward last col mean 2.164263577242309e-07 first col mean 5.5924632761161774e-05 all mean 7.208059832919389e-05
5.2738323574885726e-05 5.2738312660949305e-05
rl training, epoch3, iter0, batch205/1133, batch loss:5.2738312660949305e-05, Training time:43139.854524850845
batch reward last col mean 1.284622953789949e-06 first col mean 0.00023208223865367472 all mean 3.430454671615735e-05
3.9217073208419606e-05 3.921706593246199e-05
rl training, epoch3, iter0, batch206/1133, batch loss:3.921706593246199e-05, Training time:43157.83800625801
batch reward last col mean 0.0013311384245753288 first col mean 1.8576974980533123e-05 all mean 0.0012640609638765454
0.0002006596332648769 0.0002006596332648769
rl training, epoch3, iter0, batch207/1133, batch loss:0.0002006596332648769, Training time:43175.48855018616
batch reward last col mean 2.1439942429424264e-05 first col mean 0.0019162941025570035 all mean 7.550720329163596e-05
8.066953887464479e-05 8.066953887464479e-05
rl training, epoch3, iter0, batch208/1133, batch loss:8.066953887464479e-05, Training time:43193.55145287514
batch reward last col mean 3.7870660207772744e-07 first col mean 2.609467401271104e-06 all mean 1.6947600670391694e-05
1.4692634067614563e-05 1.4692635886603966e-05
rl training, epoch3, iter0, batch209/1133, batch loss:1.4692635886603966e-05, Training time:43211.294662714005
batch reward last col mean 0.00035406401730142534 first col mean 1.0284058589604683e-05 all mean 7.305247709155083e-05
9.473685349803418e-05 9.473685349803418e-05
rl training, epoch3, iter0, batch210/1133, batch loss:9.473685349803418e-05, Training time:43228.73779249191
batch reward last col mean 1.199991129396949e-05 first col mean 5.311398126650602e-06 all mean 2.2910126062924974e-05
1.183728363685077e-05 1.1837279998871963e-05
rl training, epoch3, iter0, batch211/1133, batch loss:1.1837279998871963e-05, Training time:43246.17076396942
batch reward last col mean 0.0009769785683602095 first col mean 1.6052641740316176e-06 all mean 0.000647428969386965
0.00015329952293541282 0.00015329952293541282
rl training, epoch3, iter0, batch212/1133, batch loss:0.00015329952293541282, Training time:43264.1021091938
batch reward last col mean 0.0010656396625563502 first col mean 0.0015972631517797709 all mean 0.000536171137355268
7.737360283499584e-05 7.737359555903822e-05
rl training, epoch3, iter0, batch213/1133, batch loss:7.737359555903822e-05, Training time:43282.49218630791
batch reward last col mean 0.00018816188094206154 first col mean 4.2133426177315414e-05 all mean 0.0001245275343535468
5.4721502237953246e-05 5.4721502237953246e-05
rl training, epoch3, iter0, batch214/1133, batch loss:5.4721502237953246e-05, Training time:43300.73237299919
batch reward last col mean 1.8520422599976882e-05 first col mean 5.3811795623914804e-06 all mean 6.44166357233189e-05
8.742489444557577e-05 8.742489444557577e-05
rl training, epoch3, iter0, batch215/1133, batch loss:8.742489444557577e-05, Training time:43319.31799340248
batch reward last col mean 2.7545556804398075e-06 first col mean 5.202136435400462e-06 all mean 3.1422547181136906e-05
5.486781446961686e-05 5.486781446961686e-05
rl training, epoch3, iter0, batch216/1133, batch loss:5.486781446961686e-05, Training time:43337.438364982605
batch reward last col mean 0.0008972387295216322 first col mean 8.214504305215087e-06 all mean 3.7436206184793264e-05
8.990505739348009e-05 8.990505739348009e-05
rl training, epoch3, iter0, batch217/1133, batch loss:8.990505739348009e-05, Training time:43355.82269382477
batch reward last col mean 3.7563684600172564e-05 first col mean 1.0859157555387355e-06 all mean 3.219402060494758e-05
2.15203981497325e-05 2.15203981497325e-05
rl training, epoch3, iter0, batch218/1133, batch loss:2.15203981497325e-05, Training time:43374.4356174469
batch reward last col mean 0.00777410389855504 first col mean 5.790825525764376e-05 all mean 0.007214281242340803
0.0003659216163214296 0.0003659216163214296
rl training, epoch3, iter0, batch219/1133, batch loss:0.0003659216163214296, Training time:43392.31695103645
batch reward last col mean 9.156782994068635e-07 first col mean 3.605415258789435e-05 all mean 3.897690839949064e-05
5.0092632591258734e-05 5.0092632591258734e-05
rl training, epoch3, iter0, batch220/1133, batch loss:5.0092632591258734e-05, Training time:43410.84520959854
batch reward last col mean 1.3989792932989076e-05 first col mean 0.0008222006727010012 all mean 2.2269212422543205e-05
2.322194086445961e-05 2.322194086445961e-05
rl training, epoch3, iter0, batch221/1133, batch loss:2.322194086445961e-05, Training time:43428.12288022041
batch reward last col mean 2.8978352929698303e-05 first col mean 7.525763976445887e-06 all mean 4.248720870236866e-05
3.9395778003381565e-05 3.9395778003381565e-05
rl training, epoch3, iter0, batch222/1133, batch loss:3.9395778003381565e-05, Training time:43446.41927576065
batch reward last col mean 7.206692316685803e-06 first col mean 0.0008013241458684206 all mean 4.5579694415209815e-05
7.712509977864102e-05 7.712511433055624e-05
rl training, epoch3, iter0, batch223/1133, batch loss:7.712511433055624e-05, Training time:43465.23534035683
batch reward last col mean 3.9151780129031977e-07 first col mean 0.0016349315410479903 all mean 2.8442300390452147e-05
9.911885172186885e-06 9.911890629155096e-06
rl training, epoch3, iter0, batch224/1133, batch loss:9.911890629155096e-06, Training time:43482.943631887436
batch reward last col mean 1.4354898212332046e-06 first col mean 3.83700717065949e-06 all mean 5.50283511984162e-05
5.5165273806778714e-05 5.5165273806778714e-05
rl training, epoch3, iter0, batch225/1133, batch loss:5.5165273806778714e-05, Training time:43501.66558408737
batch reward last col mean 9.35388816287741e-05 first col mean 4.185670695733279e-05 all mean 5.407227945397608e-05
2.7659747502184473e-05 2.7659747502184473e-05
rl training, epoch3, iter0, batch226/1133, batch loss:2.7659747502184473e-05, Training time:43519.211711883545
batch reward last col mean 0.0001833821734180674 first col mean 4.419595370563911e-06 all mean 0.00017091452900785953
4.8695826990297064e-05 4.8695826990297064e-05
rl training, epoch3, iter0, batch227/1133, batch loss:4.8695826990297064e-05, Training time:43537.6030933857
batch reward last col mean 5.452190180221805e-06 first col mean 2.2510480448545422e-06 all mean 2.573967503849417e-05
3.0469564080704004e-05 3.0469569537672214e-05
rl training, epoch3, iter0, batch228/1133, batch loss:3.0469569537672214e-05, Training time:43555.438823223114
batch reward last col mean 6.731092980771791e-07 first col mean 3.6259680769035185e-07 all mean 3.3232976420549676e-05
3.0792056350037456e-05 3.0792056350037456e-05
rl training, epoch3, iter0, batch229/1133, batch loss:3.0792056350037456e-05, Training time:43574.1260240078
batch reward last col mean 6.608684088860173e-06 first col mean 9.111550753004849e-06 all mean 3.245656262151897e-05
4.20199976360891e-05 4.20199976360891e-05
rl training, epoch3, iter0, batch230/1133, batch loss:4.20199976360891e-05, Training time:43591.44575238228
batch reward last col mean 9.645147656556219e-06 first col mean 8.46297825773945e-06 all mean 1.9394698028918356e-05
1.640140362724196e-05 1.640140362724196e-05
rl training, epoch3, iter0, batch231/1133, batch loss:1.640140362724196e-05, Training time:43608.74647188187
batch reward last col mean 3.893453595082974e-07 first col mean 0.001105939387343824 all mean 4.745380283566192e-05
4.971220187144354e-05 4.9712194595485926e-05
rl training, epoch3, iter0, batch232/1133, batch loss:4.9712194595485926e-05, Training time:43626.10861325264
batch reward last col mean 1.1243059816479217e-06 first col mean 0.0011142153525725007 all mean 5.07139484398067e-05
6.458019197452813e-05 6.458020652644336e-05
rl training, epoch3, iter0, batch233/1133, batch loss:6.458020652644336e-05, Training time:43644.60081601143
batch reward last col mean 0.00042950481292791665 first col mean 0.0005105891032144427 all mean 2.435132410028018e-05
5.2495161071419716e-05 5.249515743344091e-05
rl training, epoch3, iter0, batch234/1133, batch loss:5.249515743344091e-05, Training time:43662.7270026207
batch reward last col mean 2.460934774717316e-05 first col mean 2.7065868835052243e-06 all mean 4.387703302199952e-05
4.244792216923088e-05 4.2447914893273264e-05
rl training, epoch3, iter0, batch235/1133, batch loss:4.2447914893273264e-05, Training time:43680.60007786751
batch reward last col mean 3.651846554930671e-06 first col mean 1.753045353325433e-06 all mean 8.016706124180928e-05
0.0001773097610566765 0.00017730977560859174
rl training, epoch3, iter0, batch236/1133, batch loss:0.00017730977560859174, Training time:43698.95102238655
batch reward last col mean 4.647625974030234e-05 first col mean 2.88953488052357e-05 all mean 5.8161967899650335e-05
1.9700275515788235e-05 1.9700275515788235e-05
rl training, epoch3, iter0, batch237/1133, batch loss:1.9700275515788235e-05, Training time:43717.192061424255
batch reward last col mean 0.00499718077480793 first col mean 0.00016909871192183346 all mean 0.0013004459906369448
0.00044459637138061225 0.0004445962840691209
rl training, epoch3, iter0, batch238/1133, batch loss:0.0004445962840691209, Training time:43735.62660455704
batch reward last col mean 7.702606126258615e-06 first col mean 0.001113972393795848 all mean 4.8990925279213116e-05
3.949194433516823e-05 3.949193705921061e-05
rl training, epoch3, iter0, batch239/1133, batch loss:3.949193705921061e-05, Training time:43753.44633460045
batch reward last col mean 9.421473805559799e-06 first col mean 1.4059726709092502e-05 all mean 2.891546319006011e-05
2.232809129054658e-05 2.2328094928525388e-05
rl training, epoch3, iter0, batch240/1133, batch loss:2.2328094928525388e-05, Training time:43771.45101642609
batch reward last col mean 1.0028354608948575e-06 first col mean 2.7002975912182592e-05 all mean 2.661214239196852e-05
2.7482721634441987e-05 2.7482721634441987e-05
rl training, epoch3, iter0, batch241/1133, batch loss:2.7482721634441987e-05, Training time:43789.47034358978
batch reward last col mean 0.006991435773670673 first col mean 1.8784994608722627e-06 all mean 0.0062238858081400394
0.00031604079413227737 0.0003160408232361078
rl training, epoch3, iter0, batch242/1133, batch loss:0.0003160408232361078, Training time:43807.8301012516
batch reward last col mean 9.069653117421694e-08 first col mean 3.647275661933236e-06 all mean 1.8729453586274758e-05
1.3220901564636733e-05 1.3220901564636733e-05
rl training, epoch3, iter0, batch243/1133, batch loss:1.3220901564636733e-05, Training time:43826.178433179855
batch reward last col mean 8.633182346784452e-07 first col mean 0.0016486805398017168 all mean 4.2925043089780957e-05
1.3968383427709341e-05 1.3968383427709341e-05
rl training, epoch3, iter0, batch244/1133, batch loss:1.3968383427709341e-05, Training time:43843.79359459877
batch reward last col mean 1.3653720998263452e-06 first col mean 0.00016623570991214365 all mean 2.771397339529358e-05
1.9629389498732053e-05 1.9629391317721456e-05
rl training, epoch3, iter0, batch245/1133, batch loss:1.9629391317721456e-05, Training time:43861.42901468277
batch reward last col mean 3.657644072063704e-07 first col mean 0.0007049554260447621 all mean 4.968260691384785e-05
5.287902240525e-05 5.287902240525e-05
rl training, epoch3, iter0, batch246/1133, batch loss:5.287902240525e-05, Training time:43878.967874765396
batch reward last col mean 0.0009371946798637509 first col mean 5.41170720680384e-06 all mean 0.0008904894930310547
4.984935003449209e-05 4.984935003449209e-05
rl training, epoch3, iter0, batch247/1133, batch loss:4.984935003449209e-05, Training time:43896.56674909592
batch reward last col mean 1.4963966350478586e-05 first col mean 6.045090685802279e-06 all mean 1.7204969481099397e-05
2.2362459276337177e-05 2.2362459276337177e-05
rl training, epoch3, iter0, batch248/1133, batch loss:2.2362459276337177e-05, Training time:43915.03811454773
batch reward last col mean 0.00014212753740139306 first col mean 2.276152190461289e-05 all mean 0.00011732169514289126
3.2532872864976525e-05 3.2532872864976525e-05
rl training, epoch3, iter0, batch249/1133, batch loss:3.2532872864976525e-05, Training time:43932.91497850418
batch reward last col mean 8.376432560908142e-07 first col mean 1.3777707863482647e-05 all mean 4.4184314901940525e-05
3.268123327870853e-05 3.2681229640729725e-05
rl training, epoch3, iter0, batch250/1133, batch loss:3.2681229640729725e-05, Training time:43950.60666632652
batch reward last col mean 0.0009747233707457781 first col mean 8.938511018641293e-05 all mean 0.0008674348355270922
0.00011574730888241902 0.00011574730888241902
rl training, epoch3, iter0, batch251/1133, batch loss:0.00011574730888241902, Training time:43968.30145454407
batch reward last col mean 0.0009927903302013874 first col mean 1.7299518731306307e-05 all mean 0.0007240412523970008
0.0001209462498081848 0.00012094624253222719
rl training, epoch3, iter0, batch252/1133, batch loss:0.00012094624253222719, Training time:43987.07712173462
batch reward last col mean 1.2919006167066982e-06 first col mean 1.9119815988233313e-06 all mean 2.2232503397390246e-05
1.3355321243579965e-05 1.335532397206407e-05
rl training, epoch3, iter0, batch253/1133, batch loss:1.335532397206407e-05, Training time:44004.81446361542
batch reward last col mean 5.80462710786378e-06 first col mean 1.8264143363921903e-05 all mean 5.197554128244519e-05
6.699396908516064e-05 6.699397636111826e-05
rl training, epoch3, iter0, batch254/1133, batch loss:6.699397636111826e-05, Training time:44023.40857386589
batch reward last col mean 7.478866609744728e-05 first col mean 0.00022430151875596493 all mean 2.3749200408929028e-05
2.040183244389482e-05 2.040183244389482e-05
rl training, epoch3, iter0, batch255/1133, batch loss:2.040183244389482e-05, Training time:44040.81358766556
batch reward last col mean 7.56827944314864e-07 first col mean 0.0005601131124421954 all mean 4.1914467146852985e-05
5.6157150538638234e-05 5.615714326268062e-05
rl training, epoch3, iter0, batch256/1133, batch loss:5.615714326268062e-05, Training time:44058.67666745186
batch reward last col mean 7.411518890876323e-05 first col mean 9.095348104892764e-06 all mean 1.879215233202558e-05
2.7888943805010058e-05 2.7888941986020654e-05
rl training, epoch3, iter0, batch257/1133, batch loss:2.7888941986020654e-05, Training time:44077.31704592705
batch reward last col mean 0.0004082546220161021 first col mean 7.909101441327948e-06 all mean 7.356339483521879e-05
0.0001322931348113343 0.0001322931348113343
rl training, epoch3, iter0, batch258/1133, batch loss:0.0001322931348113343, Training time:44095.767540454865
batch reward last col mean 2.953324838017579e-05 first col mean 2.706104623939609e-06 all mean 2.7322530513629317e-05
1.7274585843551904e-05 1.72745840245625e-05
rl training, epoch3, iter0, batch259/1133, batch loss:1.72745840245625e-05, Training time:44114.184025764465
batch reward last col mean 2.221513113909168e-06 first col mean 0.00013226181908976287 all mean 2.3170878193923272e-05
2.879568091884721e-05 2.879568091884721e-05
rl training, epoch3, iter0, batch260/1133, batch loss:2.879568091884721e-05, Training time:44132.26999759674
batch reward last col mean 0.0001366731448797509 first col mean 2.95446916425135e-05 all mean 0.00018752014148049057
0.00011281075421720743 0.00011281075421720743
rl training, epoch3, iter0, batch261/1133, batch loss:0.00011281075421720743, Training time:44150.60710144043
batch reward last col mean 0.003411714918911457 first col mean 6.984387709962903e-06 all mean 0.0032029678113758564
0.00016050909471232444 0.00016050909471232444
rl training, epoch3, iter0, batch262/1133, batch loss:0.00016050909471232444, Training time:44168.63347864151
batch reward last col mean 3.5899219597013143e-07 first col mean 4.962547791365068e-06 all mean 2.995483373524621e-05
8.452854672214016e-05 8.452854672214016e-05
rl training, epoch3, iter0, batch263/1133, batch loss:8.452854672214016e-05, Training time:44186.707632780075
batch reward last col mean 2.147547093045432e-05 first col mean 1.1061717486882117e-05 all mean 5.7678593293530867e-05
2.0718218365800567e-05 2.071822018478997e-05
rl training, epoch3, iter0, batch264/1133, batch loss:2.071822018478997e-05, Training time:44205.10085296631
batch reward last col mean 3.8653419323964044e-05 first col mean 3.5402806588535896e-06 all mean 4.213313513901085e-05
3.5061308153672144e-05 3.5061308153672144e-05
rl training, epoch3, iter0, batch265/1133, batch loss:3.5061308153672144e-05, Training time:44222.88075661659
batch reward last col mean 0.0006188937113620341 first col mean 2.9888371955166804e-06 all mean 0.0005877717630937696
0.0001960369700100273 0.00019603695545811206
rl training, epoch3, iter0, batch266/1133, batch loss:0.00019603695545811206, Training time:44241.59589743614
batch reward last col mean 2.5293325961683877e-05 first col mean 9.435247193323448e-05 all mean 5.204298213357106e-05
5.432169928099029e-05 5.432169928099029e-05
rl training, epoch3, iter0, batch267/1133, batch loss:5.432169928099029e-05, Training time:44259.0641784668
batch reward last col mean 6.118970304669347e-06 first col mean 1.3817649460179382e-06 all mean 5.4576936236117035e-05
0.00010056388418888673 0.0001005638696369715
rl training, epoch3, iter0, batch268/1133, batch loss:0.0001005638696369715, Training time:44277.820246219635
batch reward last col mean 6.548992132593412e-06 first col mean 1.2492181440393324e-06 all mean 4.598696978064254e-05
2.897828926506918e-05 2.89783001790056e-05
rl training, epoch3, iter0, batch269/1133, batch loss:2.89783001790056e-05, Training time:44296.01299786568
batch reward last col mean 2.5264131181756966e-05 first col mean 7.787605136400089e-05 all mean 6.223830132512376e-05
4.179356983513571e-05 4.179355892119929e-05
rl training, epoch3, iter0, batch270/1133, batch loss:4.179355892119929e-05, Training time:44313.782173871994
batch reward last col mean 5.861405952600762e-05 first col mean 2.437307557556778e-06 all mean 7.88162142271176e-05
2.8755830498994328e-05 2.8755828680004925e-05
rl training, epoch3, iter0, batch271/1133, batch loss:2.8755828680004925e-05, Training time:44331.835600852966
batch reward last col mean 2.9759567041764967e-05 first col mean 3.6921021546731936e-06 all mean 3.89306151191704e-05
7.167879084590822e-05 7.167879084590822e-05
rl training, epoch3, iter0, batch272/1133, batch loss:7.167879084590822e-05, Training time:44349.65425038338
batch reward last col mean 6.0419370129238814e-05 first col mean 0.00012252038868609816 all mean 4.488394552026875e-05
2.0296683942433447e-05 2.0296687580412254e-05
rl training, epoch3, iter0, batch273/1133, batch loss:2.0296687580412254e-05, Training time:44367.37198257446
batch reward last col mean 8.345387527697312e-07 first col mean 0.0010621983092278242 all mean 6.598004983970895e-05
3.632902735262178e-05 3.6329020076664165e-05
rl training, epoch3, iter0, batch274/1133, batch loss:3.6329020076664165e-05, Training time:44385.53772187233
batch reward last col mean 0.00033703952794894576 first col mean 1.2242995580891147e-05 all mean 5.4235300922300667e-05
4.057140540680848e-05 4.0571401768829674e-05
rl training, epoch3, iter0, batch275/1133, batch loss:4.0571401768829674e-05, Training time:44403.34251952171
batch reward last col mean 2.4429300538031384e-07 first col mean 7.312778325285763e-05 all mean 3.778748578042723e-05
6.072798350942321e-05 6.0727990785380825e-05
rl training, epoch3, iter0, batch276/1133, batch loss:6.0727990785380825e-05, Training time:44420.79832267761
batch reward last col mean 0.00012305701966397464 first col mean 2.882048420360661e-06 all mean 3.9086931792553514e-05
3.8044192478992045e-05 3.8044192478992045e-05
rl training, epoch3, iter0, batch277/1133, batch loss:3.8044192478992045e-05, Training time:44439.17733621597
batch reward last col mean 1.9604663066274952e-06 first col mean 2.858954985640594e-06 all mean 4.415529110701755e-05
0.00014183983148541301 0.0001418398169334978
rl training, epoch3, iter0, batch278/1133, batch loss:0.0001418398169334978, Training time:44457.53538250923
batch reward last col mean 2.979986311402172e-05 first col mean 5.548026820179075e-06 all mean 6.747762381564826e-05
0.00018430031195748597 0.00018430031195748597
rl training, epoch3, iter0, batch279/1133, batch loss:0.00018430031195748597, Training time:44475.99837756157
batch reward last col mean 0.0005754937301389873 first col mean 1.0277063665853348e-05 all mean 0.0004356716526672244
9.55693976720795e-05 9.556941222399473e-05
rl training, epoch3, iter0, batch280/1133, batch loss:9.556941222399473e-05, Training time:44493.85239696503
batch reward last col mean 3.442708111833781e-05 first col mean 0.00018088372598867863 all mean 3.392125654499978e-05
4.0811937651596963e-05 4.081192673766054e-05
rl training, epoch3, iter0, batch281/1133, batch loss:4.081192673766054e-05, Training time:44511.61889243126
batch reward last col mean 2.4485430913046002e-05 first col mean 0.00012950695236213505 all mean 3.087722870986909e-05
1.5569909010082483e-05 1.5569910829071887e-05
rl training, epoch3, iter0, batch282/1133, batch loss:1.5569910829071887e-05, Training time:44529.437026023865
batch reward last col mean 7.427234436363506e-07 first col mean 4.244386673235567e-06 all mean 2.7821070034406148e-05
3.517427830956876e-05 3.5174274671589956e-05
rl training, epoch3, iter0, batch283/1133, batch loss:3.5174274671589956e-05, Training time:44547.387144327164
batch reward last col mean 0.0002238840243080631 first col mean 1.5455545508302748e-05 all mean 0.0001975867198780179
3.435890903347172e-05 3.435890903347172e-05
rl training, epoch3, iter0, batch284/1133, batch loss:3.435890903347172e-05, Training time:44565.90904164314
batch reward last col mean 3.3057533528335625e-06 first col mean 0.000867745082359761 all mean 5.608724313788116e-05
3.330652180011384e-05 3.330652180011384e-05
rl training, epoch3, iter0, batch285/1133, batch loss:3.330652180011384e-05, Training time:44583.65362739563
batch reward last col mean 1.5258544863172574e-06 first col mean 0.001636892557144165 all mean 5.195484482101165e-05
0.0001961683010449633 0.0001961683010449633
rl training, epoch3, iter0, batch286/1133, batch loss:0.0001961683010449633, Training time:44601.656474113464
batch reward last col mean 0.0005550144123844802 first col mean 4.348882157501066e-06 all mean 0.0005359638598747551
6.360439874697477e-05 6.360439874697477e-05
rl training, epoch3, iter0, batch287/1133, batch loss:6.360439874697477e-05, Training time:44620.18604564667
batch reward last col mean 0.00012430234346538782 first col mean 0.002549830125644803 all mean 0.00012943771434947848
0.00012463296297937632 0.00012463296297937632
rl training, epoch3, iter0, batch288/1133, batch loss:0.00012463296297937632, Training time:44638.15992116928
batch reward last col mean 2.261848385387566e-05 first col mean 1.9122304365737364e-05 all mean 3.029768959095236e-05
2.4465887690894306e-05 2.446589496685192e-05
rl training, epoch3, iter0, batch289/1133, batch loss:2.446589496685192e-05, Training time:44655.71872854233
batch reward last col mean 2.171464757338981e-06 first col mean 9.006961772684008e-05 all mean 3.239549187128432e-05
6.421426951419562e-05 6.421426951419562e-05
rl training, epoch3, iter0, batch290/1133, batch loss:6.421426951419562e-05, Training time:44673.57006239891
batch reward last col mean 7.839394129405264e-06 first col mean 4.7042347432579845e-05 all mean 4.149142841924913e-05
5.135472019901499e-05 5.135472019901499e-05
rl training, epoch3, iter0, batch291/1133, batch loss:5.135472019901499e-05, Training time:44691.54909300804
batch reward last col mean 0.0001380651956424117 first col mean 4.308846655476373e-06 all mean 5.082879579276778e-05
2.294097976118792e-05 2.294097976118792e-05
rl training, epoch3, iter0, batch292/1133, batch loss:2.294097976118792e-05, Training time:44710.24770402908
batch reward last col mean 1.2711545878119068e-06 first col mean 8.86669113242533e-06 all mean 3.047064456040971e-05
5.1236103900009766e-05 5.1236092986073345e-05
rl training, epoch3, iter0, batch293/1133, batch loss:5.1236092986073345e-05, Training time:44728.35783815384
batch reward last col mean 5.8692843595054e-05 first col mean 8.707091183168814e-05 all mean 6.295314233284444e-05
4.609841562341899e-05 4.609841562341899e-05
rl training, epoch3, iter0, batch294/1133, batch loss:4.609841562341899e-05, Training time:44746.09779381752
batch reward last col mean 3.3181872822751757e-06 first col mean 1.1138209856653702e-06 all mean 3.185289824614301e-05
5.2464842156041414e-05 5.2464842156041414e-05
rl training, epoch3, iter0, batch295/1133, batch loss:5.2464842156041414e-05, Training time:44764.447499752045
batch reward last col mean 1.9947735836467473e-06 first col mean 0.00034648351720534265 all mean 6.187757389852777e-05
7.46830046409741e-05 7.46830046409741e-05
rl training, epoch3, iter0, batch296/1133, batch loss:7.46830046409741e-05, Training time:44782.52295088768
batch reward last col mean 1.9953298760810867e-05 first col mean 3.363088399055414e-05 all mean 3.58456491085235e-05
4.337223435868509e-05 4.3372230720706284e-05
rl training, epoch3, iter0, batch297/1133, batch loss:4.3372230720706284e-05, Training time:44800.890318870544
batch reward last col mean 0.0014323643408715725 first col mean 1.4299228496383876e-05 all mean 0.00120910769328475
0.00026901770615950227 0.00026901770615950227
rl training, epoch3, iter0, batch298/1133, batch loss:0.00026901770615950227, Training time:44819.245473861694
batch reward last col mean 4.226911187288351e-06 first col mean 0.0004551786696538329 all mean 2.3970991605892777e-05
1.6846404832904227e-05 1.684640119492542e-05
rl training, epoch3, iter0, batch299/1133, batch loss:1.684640119492542e-05, Training time:44838.139258146286
batch reward last col mean 9.633895388105884e-07 first col mean 0.0004803022602573037 all mean 2.843990114342887e-05
2.3660590159124695e-05 2.3660590159124695e-05
rl training, epoch3, iter0, batch300/1133, batch loss:2.3660590159124695e-05, Training time:44856.54598426819
batch reward last col mean 1.912438528961502e-05 first col mean 0.00015477265696972609 all mean 8.266147051472217e-05
0.0001060208523995243 0.0001060208523995243
rl training, epoch3, iter0, batch301/1133, batch loss:0.0001060208523995243, Training time:44874.12324142456
batch reward last col mean 3.92802721762564e-05 first col mean 5.501597479451448e-05 all mean 3.509818634483963e-05
6.740675598848611e-05 6.740676326444373e-05
rl training, epoch3, iter0, batch302/1133, batch loss:6.740676326444373e-05, Training time:44891.89039874077
batch reward last col mean 9.822691026784014e-06 first col mean 6.28874622634612e-05 all mean 3.948599987779744e-05
6.984600622672588e-05 6.984600622672588e-05
rl training, epoch3, iter0, batch303/1133, batch loss:6.984600622672588e-05, Training time:44909.94327044487
batch reward last col mean 2.7149393645231612e-05 first col mean 4.855434781347867e-06 all mean 2.500169284758158e-05
2.899987157434225e-05 2.899987157434225e-05
rl training, epoch3, iter0, batch304/1133, batch loss:2.899987157434225e-05, Training time:44928.199090480804
batch reward last col mean 1.8496560869607492e-06 first col mean 5.376070475904271e-05 all mean 3.218337951693684e-05
2.799041430989746e-05 2.7990410671918653e-05
rl training, epoch3, iter0, batch305/1133, batch loss:2.7990410671918653e-05, Training time:44945.32930493355
batch reward last col mean 2.1774393133000558e-07 first col mean 1.3009528174734442e-06 all mean 5.392583625507541e-05
0.0002582392480690032 0.0002582392771728337
rl training, epoch3, iter0, batch306/1133, batch loss:0.0002582392771728337, Training time:44963.10858488083
batch reward last col mean 6.3799452618695796e-06 first col mean 1.372247606923338e-05 all mean 5.1958515541628e-05
9.697913628770038e-05 9.697912901174277e-05
rl training, epoch3, iter0, batch307/1133, batch loss:9.697912901174277e-05, Training time:44980.59760475159
batch reward last col mean 9.239483915735036e-07 first col mean 6.550666512339376e-06 all mean 2.7324484108248726e-05
2.572979974502232e-05 2.572979974502232e-05
rl training, epoch3, iter0, batch308/1133, batch loss:2.572979974502232e-05, Training time:44998.97972846031
batch reward last col mean 7.763388566672802e-06 first col mean 4.103458923054859e-05 all mean 3.781666237046011e-05
3.867990380967967e-05 3.8679900171700865e-05
rl training, epoch3, iter0, batch309/1133, batch loss:3.8679900171700865e-05, Training time:45017.39051938057
batch reward last col mean 8.62406668602489e-05 first col mean 5.474486442835769e-06 all mean 5.842688915436156e-05
4.916593024972826e-05 4.916593388770707e-05
rl training, epoch3, iter0, batch310/1133, batch loss:4.916593388770707e-05, Training time:45035.27317786217
batch reward last col mean 9.370032216793334e-07 first col mean 2.645785571075976e-06 all mean 2.389163273619488e-05
2.6569819965516217e-05 2.656981632753741e-05
rl training, epoch3, iter0, batch311/1133, batch loss:2.656981632753741e-05, Training time:45053.45826268196
batch reward last col mean 2.3176783088274533e-06 first col mean 2.5022312911460176e-05 all mean 2.8627484425669536e-05
3.4675780625548214e-05 3.467577698756941e-05
rl training, epoch3, iter0, batch312/1133, batch loss:3.467577698756941e-05, Training time:45071.025114774704
batch reward last col mean 4.739465566672152e-06 first col mean 0.00013812239922117442 all mean 3.319902316434309e-05
1.932478517119307e-05 1.932478517119307e-05
rl training, epoch3, iter0, batch313/1133, batch loss:1.932478517119307e-05, Training time:45088.40224480629
batch reward last col mean 2.1233381630736403e-05 first col mean 1.0369170013291296e-05 all mean 4.9114838475361466e-05
7.071148866089061e-05 7.071149593684822e-05
rl training, epoch3, iter0, batch314/1133, batch loss:7.071149593684822e-05, Training time:45105.63123202324
batch reward last col mean 1.895979221444577e-05 first col mean 1.5612989727742388e-06 all mean 7.500332139898092e-05
5.9522724768612534e-05 5.9522724768612534e-05
rl training, epoch3, iter0, batch315/1133, batch loss:5.9522724768612534e-05, Training time:45123.87148165703
batch reward last col mean 1.9970827906945487e-06 first col mean 2.8677039153990336e-05 all mean 3.406343239475973e-05
6.607351679122075e-05 6.607350951526314e-05
rl training, epoch3, iter0, batch316/1133, batch loss:6.607350951526314e-05, Training time:45141.4586789608
batch reward last col mean 3.2710499908716884e-07 first col mean 1.4963698049541563e-05 all mean 2.508174475224223e-05
3.634603490354493e-05 3.6346031265566126e-05
rl training, epoch3, iter0, batch317/1133, batch loss:3.6346031265566126e-05, Training time:45158.95915603638
batch reward last col mean 1.1849914471895318e-06 first col mean 9.6436808235012e-05 all mean 2.012806544371415e-05
1.9711756976903416e-05 1.971175879589282e-05
rl training, epoch3, iter0, batch318/1133, batch loss:1.971175879589282e-05, Training time:45176.81846857071
batch reward last col mean 4.7620933401049115e-06 first col mean 3.874213689414319e-06 all mean 3.0011695344001055e-05
3.296805880381726e-05 3.296805880381726e-05
rl training, epoch3, iter0, batch319/1133, batch loss:3.296805880381726e-05, Training time:45194.89786171913
batch reward last col mean 5.11812831973657e-05 first col mean 8.10524943517521e-06 all mean 4.3560688936850056e-05
4.790276943822391e-05 4.7902765800245106e-05
rl training, epoch3, iter0, batch320/1133, batch loss:4.7902765800245106e-05, Training time:45214.11309838295
batch reward last col mean 0.000580497900955379 first col mean 1.7116432218244881e-06 all mean 0.0004834042047150433
9.376756497658789e-05 9.37675722525455e-05
rl training, epoch3, iter0, batch321/1133, batch loss:9.37675722525455e-05, Training time:45231.80925035477
batch reward last col mean 6.129162102297414e-06 first col mean 6.50524816592224e-05 all mean 6.59165671095252e-05
0.00018677528714761138 0.00018677528714761138
rl training, epoch3, iter0, batch322/1133, batch loss:0.00018677528714761138, Training time:45249.8585524559
batch reward last col mean 1.4149495655146893e-06 first col mean 2.8110691800975474e-06 all mean 3.63389917765744e-05
3.993627251475118e-05 3.993627615272999e-05
rl training, epoch3, iter0, batch323/1133, batch loss:3.993627615272999e-05, Training time:45267.8238594532
batch reward last col mean 5.5650393733230885e-06 first col mean 0.001714597805403173 all mean 8.81148807820864e-05
0.00015499051369260997 0.0001549905282445252
rl training, epoch3, iter0, batch324/1133, batch loss:0.0001549905282445252, Training time:45285.7244913578
batch reward last col mean 4.427698172548844e-07 first col mean 2.16058106161654e-06 all mean 3.60075973731e-05
2.0210576622048393e-05 2.0210572984069586e-05
rl training, epoch3, iter0, batch325/1133, batch loss:2.0210572984069586e-05, Training time:45304.678133010864
batch reward last col mean 1.1585145784920314e-06 first col mean 0.0006918448489159346 all mean 3.20615254167933e-05
1.2728900401270948e-05 1.2728907677228563e-05
rl training, epoch3, iter0, batch326/1133, batch loss:1.2728907677228563e-05, Training time:45322.44289970398
batch reward last col mean 6.326552011159947e-07 first col mean 1.78905302163912e-05 all mean 4.369392991065979e-05
7.305731560336426e-05 7.305731560336426e-05
rl training, epoch3, iter0, batch327/1133, batch loss:7.305731560336426e-05, Training time:45340.02639460564
batch reward last col mean 5.2000946197949816e-06 first col mean 3.1236362701747566e-05 all mean 4.4107709982199594e-05
2.3907969080028124e-05 2.390796180407051e-05
rl training, epoch3, iter0, batch328/1133, batch loss:2.390796180407051e-05, Training time:45358.21586585045
batch reward last col mean 1.0732688906500698e-06 first col mean 0.0008697842713445425 all mean 3.276451025158167e-05
1.7801914509618655e-05 1.7801918147597462e-05
rl training, epoch3, iter0, batch329/1133, batch loss:1.7801918147597462e-05, Training time:45376.12857937813
batch reward last col mean 4.369001089798985e-06 first col mean 0.00038469393621198833 all mean 2.1893127268413082e-05
1.293070636165794e-05 1.293070636165794e-05
rl training, epoch3, iter0, batch330/1133, batch loss:1.293070636165794e-05, Training time:45393.43352890015
batch reward last col mean 1.3968556231702678e-06 first col mean 3.5968809243058786e-05 all mean 4.472667205845937e-05
9.353963105240837e-05 9.353963832836598e-05
rl training, epoch3, iter0, batch331/1133, batch loss:9.353963832836598e-05, Training time:45410.866849184036
batch reward last col mean 7.823691134944966e-07 first col mean 4.956072643835796e-06 all mean 3.5944656701758504e-05
4.307215931476094e-05 4.3072152038803324e-05
rl training, epoch3, iter0, batch332/1133, batch loss:4.3072152038803324e-05, Training time:45428.3722884655
batch reward last col mean 9.312036013398028e-07 first col mean 0.00045394551125355065 all mean 4.820062895305455e-05
9.655384928919375e-05 9.655384928919375e-05
rl training, epoch3, iter0, batch333/1133, batch loss:9.655384928919375e-05, Training time:45446.127143621445
batch reward last col mean 2.323252829228295e-06 first col mean 0.00011553590593393892 all mean 1.6166008208529092e-05
1.568129846418742e-05 1.568129846418742e-05
rl training, epoch3, iter0, batch334/1133, batch loss:1.568129846418742e-05, Training time:45464.00921010971
batch reward last col mean 9.96276639853022e-07 first col mean 7.403227755276021e-06 all mean 2.6249952497892082e-05
3.8715075788786635e-05 3.8715075788786635e-05
rl training, epoch3, iter0, batch335/1133, batch loss:3.8715075788786635e-05, Training time:45483.050349235535
batch reward last col mean 3.097705484833568e-05 first col mean 5.715561201213859e-06 all mean 0.000135733702336438
0.0004268214979674667 0.0004268214979674667
rl training, epoch3, iter0, batch336/1133, batch loss:0.0004268214979674667, Training time:45501.34579372406
batch reward last col mean 0.0012437640689313412 first col mean 6.681682862108573e-05 all mean 0.0012084648478776217
7.231730705825612e-05 7.231730705825612e-05
rl training, epoch3, iter0, batch337/1133, batch loss:7.231730705825612e-05, Training time:45519.16546821594
batch reward last col mean 5.821369632030837e-05 first col mean 4.85091695736628e-05 all mean 2.8453036065911874e-05
5.877972944290377e-05 5.877972944290377e-05
rl training, epoch3, iter0, batch338/1133, batch loss:5.877972944290377e-05, Training time:45538.00968337059
batch reward last col mean 1.1083432127634296e-06 first col mean 7.854170576138131e-07 all mean 2.3190785213955678e-05
4.5836488425266e-05 4.583648478728719e-05
rl training, epoch3, iter0, batch339/1133, batch loss:4.583648478728719e-05, Training time:45556.6641190052
batch reward last col mean 0.00367326894775033 first col mean 1.4684679854326532e-06 all mean 0.0033287787809967995
0.0001258904521819204 0.00012589043763000518
rl training, epoch3, iter0, batch340/1133, batch loss:0.00012589043763000518, Training time:45575.125881910324
batch reward last col mean 0.003802443854510784 first col mean 5.186117959965486e-06 all mean 0.00333098485134542
0.0002801699738483876 0.0002801699738483876
rl training, epoch3, iter0, batch341/1133, batch loss:0.0002801699738483876, Training time:45593.26232409477
batch reward last col mean 2.2388051093003014e-06 first col mean 1.704908390820492e-05 all mean 4.0720606193644926e-05
7.008714601397514e-05 7.008715328993276e-05
rl training, epoch3, iter0, batch342/1133, batch loss:7.008715328993276e-05, Training time:45611.688230752945
batch reward last col mean 0.0002673911803867668 first col mean 0.00012390344636514783 all mean 0.00016534345922991633
3.5612803912954405e-05 3.56128002749756e-05
rl training, epoch3, iter0, batch343/1133, batch loss:3.56128002749756e-05, Training time:45629.30247807503
batch reward last col mean 2.2295740564004518e-05 first col mean 0.0018806415610015392 all mean 8.173907554009929e-05
0.00014117819955572486 0.00014117818500380963
rl training, epoch3, iter0, batch344/1133, batch loss:0.00014117818500380963, Training time:45647.4234559536
batch reward last col mean 6.14931013842579e-06 first col mean 0.0003933614934794605 all mean 3.3026029996108264e-05
5.360564682632685e-05 5.360563955036923e-05
rl training, epoch3, iter0, batch345/1133, batch loss:5.360563955036923e-05, Training time:45665.6941409111
batch reward last col mean 7.249252666952088e-05 first col mean 1.0672966709535103e-05 all mean 3.231112350476906e-05
4.40435906057246e-05 4.404359788168222e-05
rl training, epoch3, iter0, batch346/1133, batch loss:4.404359788168222e-05, Training time:45684.04878640175
batch reward last col mean 8.505759979016148e-06 first col mean 6.7152868723496795e-06 all mean 2.2057838577893563e-05
2.8071770429960452e-05 2.807176497299224e-05
rl training, epoch3, iter0, batch347/1133, batch loss:2.807176497299224e-05, Training time:45702.24581074715
batch reward last col mean 1.6690171378286323e-06 first col mean 0.00046520994510501623 all mean 2.9684655601158738e-05
1.5982861441443674e-05 1.5982863260433078e-05
rl training, epoch3, iter0, batch348/1133, batch loss:1.5982863260433078e-05, Training time:45720.04506802559
batch reward last col mean 7.038656804070342e-06 first col mean 3.206873770977836e-06 all mean 3.055130218854174e-05
4.1885698010446504e-05 4.1885698010446504e-05
rl training, epoch3, iter0, batch349/1133, batch loss:4.1885698010446504e-05, Training time:45737.797936201096
batch reward last col mean 4.136888037464814e-06 first col mean 0.0011705149663612247 all mean 4.073865420650691e-05
1.4039605048310477e-05 1.4039605048310477e-05
rl training, epoch3, iter0, batch350/1133, batch loss:1.4039605048310477e-05, Training time:45756.05876326561
batch reward last col mean 4.1928688006009907e-05 first col mean 1.459268901271571e-06 all mean 4.483666270971298e-05
4.057640035171062e-05 4.057640035171062e-05
rl training, epoch3, iter0, batch351/1133, batch loss:4.057640035171062e-05, Training time:45774.282891988754
batch reward last col mean 1.8687935153138824e-05 first col mean 1.1804722817032598e-05 all mean 4.439841359271668e-05
2.510577360226307e-05 2.510577360226307e-05
rl training, epoch3, iter0, batch352/1133, batch loss:2.510577360226307e-05, Training time:45792.16541671753
batch reward last col mean 1.2228948435222264e-05 first col mean 0.00017586829198990017 all mean 5.047000740887597e-05
0.00012139766477048397 0.00012139767204644158
rl training, epoch3, iter0, batch353/1133, batch loss:0.00012139767204644158, Training time:45809.95508933067
batch reward last col mean 0.0007412518607452512 first col mean 2.66611241386272e-05 all mean 0.0005826512933708727
0.00024485119502060115 0.00024485119502060115
rl training, epoch3, iter0, batch354/1133, batch loss:0.00024485119502060115, Training time:45828.331099033356
batch reward last col mean 2.999533353431616e-05 first col mean 4.491350864554988e-06 all mean 3.4179458452854306e-05
2.634454176586587e-05 2.634454722283408e-05
rl training, epoch3, iter0, batch355/1133, batch loss:2.634454722283408e-05, Training time:45845.98740148544
batch reward last col mean 3.7194938613538397e-06 first col mean 0.00014692891272716224 all mean 2.5545126845827326e-05
2.0885210687993094e-05 2.0885210687993094e-05
rl training, epoch3, iter0, batch356/1133, batch loss:2.0885210687993094e-05, Training time:45864.01005625725
batch reward last col mean 1.092026741389418e-05 first col mean 3.1335650419350713e-05 all mean 6.05751592956949e-05
0.00014968845061957836 0.0001496884215157479
rl training, epoch3, iter0, batch357/1133, batch loss:0.0001496884215157479, Training time:45881.6752371788
batch reward last col mean 0.00014289855607785285 first col mean 4.779365553986281e-06 all mean 0.00016604081611149013
4.282374356989749e-05 4.282374356989749e-05
rl training, epoch3, iter0, batch358/1133, batch loss:4.282374356989749e-05, Training time:45899.96180176735
batch reward last col mean 9.234167009708472e-06 first col mean 1.558526128064841e-05 all mean 3.9155431295512244e-05
5.368511483538896e-05 5.368511483538896e-05
rl training, epoch3, iter0, batch359/1133, batch loss:5.368511483538896e-05, Training time:45918.4836769104
batch reward last col mean 3.6840754091826966e-06 first col mean 3.4243380468979012e-06 all mean 6.406295869965106e-05
8.893939957488328e-05 8.893938502296805e-05
rl training, epoch3, iter0, batch360/1133, batch loss:8.893938502296805e-05, Training time:45935.907528162
batch reward last col mean 0.00019977147167082876 first col mean 0.0006526802899315953 all mean 0.00019820057787001133
3.181882493663579e-05 3.181882493663579e-05
rl training, epoch3, iter0, batch361/1133, batch loss:3.181882493663579e-05, Training time:45953.36842870712
batch reward last col mean 2.048332680715248e-05 first col mean 0.0015700827352702618 all mean 3.2822419598232955e-05
0.0001207292516482994 0.00012072924437234178
rl training, epoch3, iter0, batch362/1133, batch loss:0.00012072924437234178, Training time:45970.720036029816
batch reward last col mean 6.283758557401597e-05 first col mean 8.528644684702158e-06 all mean 7.569637091364712e-05
2.312240394530818e-05 2.312240394530818e-05
rl training, epoch3, iter0, batch363/1133, batch loss:2.312240394530818e-05, Training time:45988.87586045265
batch reward last col mean 8.784985766396858e-06 first col mean 1.1776958672271576e-05 all mean 3.988105891039595e-05
6.211054278537631e-05 6.21105355094187e-05
rl training, epoch3, iter0, batch364/1133, batch loss:6.21105355094187e-05, Training time:46006.81963276863
batch reward last col mean 1.2017881999781821e-05 first col mean 2.322288855793886e-05 all mean 2.7988260626443662e-05
3.950585232814774e-05 3.950584869016893e-05
rl training, epoch3, iter0, batch365/1133, batch loss:3.950584869016893e-05, Training time:46024.704364299774
batch reward last col mean 7.827395165804774e-06 first col mean 0.0016629196470603347 all mean 4.948072455590591e-05
2.747073449427262e-05 2.7470738132251427e-05
rl training, epoch3, iter0, batch366/1133, batch loss:2.7470738132251427e-05, Training time:46042.41577911377
batch reward last col mean 7.289402788046573e-07 first col mean 0.0003381752176210284 all mean 5.042718112235889e-05
5.823714309372008e-05 5.823714309372008e-05
rl training, epoch3, iter0, batch367/1133, batch loss:5.823714309372008e-05, Training time:46060.25608634949
batch reward last col mean 4.3313821151969023e-07 first col mean 1.1832639756903518e-06 all mean 2.7884954761248082e-05
3.0243978471844457e-05 3.0243983928812668e-05
rl training, epoch3, iter0, batch368/1133, batch loss:3.0243983928812668e-05, Training time:46078.778972387314
batch reward last col mean 0.0001988298026844859 first col mean 1.5949362932587974e-05 all mean 0.00019011562108062208
6.206565740285441e-05 6.206565740285441e-05
rl training, epoch3, iter0, batch369/1133, batch loss:6.206565740285441e-05, Training time:46096.44998025894
batch reward last col mean 7.091049337759614e-05 first col mean 2.51171768468339e-05 all mean 9.245643741451204e-05
2.5062936401809566e-05 2.5062936401809566e-05
rl training, epoch3, iter0, batch370/1133, batch loss:2.5062936401809566e-05, Training time:46114.31994986534
batch reward last col mean 9.938115545082837e-05 first col mean 0.0005892715998925269 all mean 8.438453369308263e-05
6.339471292449161e-05 6.3394705648534e-05
rl training, epoch3, iter0, batch371/1133, batch loss:6.3394705648534e-05, Training time:46132.095210552216
batch reward last col mean 2.834085762515315e-06 first col mean 1.1733710607586545e-06 all mean 2.6090465325978585e-05
3.491797178867273e-05 3.491796815069392e-05
rl training, epoch3, iter0, batch372/1133, batch loss:3.491796815069392e-05, Training time:46150.04941391945
batch reward last col mean 1.481036406403291e-06 first col mean 1.0457147254783195e-06 all mean 2.5381312298122793e-05
2.8860644306405447e-05 2.8860642487416044e-05
rl training, epoch3, iter0, batch373/1133, batch loss:2.8860642487416044e-05, Training time:46168.32960176468
batch reward last col mean 1.4226653775040177e-06 first col mean 0.002054136246442795 all mean 6.958909943932667e-05
7.576101052109152e-05 7.576101779704913e-05
rl training, epoch3, iter0, batch374/1133, batch loss:7.576101779704913e-05, Training time:46186.27430963516
batch reward last col mean 3.972959348175209e-06 first col mean 3.059874507016502e-05 all mean 4.51765263278503e-05
3.4717948437901214e-05 3.4717948437901214e-05
rl training, epoch3, iter0, batch375/1133, batch loss:3.4717948437901214e-05, Training time:46204.57404232025
batch reward last col mean 3.3832846384029835e-05 first col mean 4.195881410851143e-05 all mean 7.810135866748169e-05
8.371014700969681e-05 8.371015428565443e-05
rl training, epoch3, iter0, batch376/1133, batch loss:8.371015428565443e-05, Training time:46223.13959503174
batch reward last col mean 2.6438276563567342e-06 first col mean 2.8975537134101614e-05 all mean 2.2284846636466682e-05
2.461951589793898e-05 2.4619512259960175e-05
rl training, epoch3, iter0, batch377/1133, batch loss:2.4619512259960175e-05, Training time:46240.54693055153
batch reward last col mean 4.231918865116313e-06 first col mean 4.076970071764663e-06 all mean 2.3728849555482157e-05
2.6752188205136918e-05 2.675219002412632e-05
rl training, epoch3, iter0, batch378/1133, batch loss:2.675219002412632e-05, Training time:46258.570276498795
batch reward last col mean 9.678676633484429e-07 first col mean 4.605028152582236e-06 all mean 1.0595381354505662e-05
1.1556830031622667e-05 1.1556830031622667e-05
rl training, epoch3, iter0, batch379/1133, batch loss:1.1556830031622667e-05, Training time:46276.75394821167
batch reward last col mean 4.3108073555231385e-07 first col mean 5.178980700293323e-06 all mean 3.8423313526436687e-05
4.985655323253013e-05 4.985654231859371e-05
rl training, epoch3, iter0, batch380/1133, batch loss:4.985654231859371e-05, Training time:46294.384578228
batch reward last col mean 4.067894224135671e-06 first col mean 5.292400237522088e-05 all mean 4.725110193248838e-05
0.00019380514277145267 0.00019380514277145267
rl training, epoch3, iter0, batch381/1133, batch loss:0.00019380514277145267, Training time:46311.82446861267
batch reward last col mean 0.00011108600301668048 first col mean 3.473266770015471e-05 all mean 8.862369577400386e-05
0.0002409292064839974 0.0002409292064839974
rl training, epoch3, iter0, batch382/1133, batch loss:0.0002409292064839974, Training time:46329.47929596901
batch reward last col mean 1.2862355106335599e-05 first col mean 0.0014188711065798998 all mean 7.265839667525142e-05
8.64688481669873e-05 8.64688481669873e-05
rl training, epoch3, iter0, batch383/1133, batch loss:8.64688481669873e-05, Training time:46347.258405447006
batch reward last col mean 2.0288711311877705e-05 first col mean 3.7408033676911145e-05 all mean 4.944803731632419e-05
3.559193646651693e-05 3.559193646651693e-05
rl training, epoch3, iter0, batch384/1133, batch loss:3.559193646651693e-05, Training time:46365.073385715485
batch reward last col mean 0.004645655397325754 first col mean 0.0018510669469833374 all mean 0.00428404426202178
0.0003599830961320549 0.00035998315433971584
rl training, epoch3, iter0, batch385/1133, batch loss:0.00035998315433971584, Training time:46383.09929084778
batch reward last col mean 9.617608884582296e-05 first col mean 1.3966091501060873e-05 all mean 0.00011756268941098824
3.841382567770779e-05 3.84138293156866e-05
rl training, epoch3, iter0, batch386/1133, batch loss:3.84138293156866e-05, Training time:46401.241220235825
batch reward last col mean 1.0451403795741498e-05 first col mean 2.4705694158910774e-05 all mean 5.5541495385114104e-05
6.0783117078244686e-05 6.0783117078244686e-05
rl training, epoch3, iter0, batch387/1133, batch loss:6.0783117078244686e-05, Training time:46419.32093954086
batch reward last col mean 0.00012413514195941389 first col mean 1.6125468391692266e-06 all mean 3.788348476518877e-05
5.93552176724188e-05 5.935523222433403e-05
rl training, epoch3, iter0, batch388/1133, batch loss:5.935523222433403e-05, Training time:46437.07405233383
batch reward last col mean 4.42626378571731e-06 first col mean 2.336229499633191e-06 all mean 2.2158637875691056e-05
4.128813452553004e-05 4.128813452553004e-05
rl training, epoch3, iter0, batch389/1133, batch loss:4.128813452553004e-05, Training time:46455.0823431015
batch reward last col mean 2.34842514146294e-06 first col mean 5.342695294530131e-05 all mean 4.467891631065868e-05
0.00011371105938451365 0.00011371105938451365
rl training, epoch3, iter0, batch390/1133, batch loss:0.00011371105938451365, Training time:46473.37480139732
batch reward last col mean 7.830237223060976e-07 first col mean 6.480918727902463e-06 all mean 1.8347063814871944e-05
2.066390516120009e-05 2.066390516120009e-05
rl training, epoch3, iter0, batch391/1133, batch loss:2.066390516120009e-05, Training time:46492.0154736042
batch reward last col mean 9.249408321920782e-06 first col mean 7.957319212437142e-06 all mean 3.663916504592635e-05
4.427045860211365e-05 4.427044768817723e-05
rl training, epoch3, iter0, batch392/1133, batch loss:4.427044768817723e-05, Training time:46510.18965315819
batch reward last col mean 3.457021011854522e-05 first col mean 0.00042502317228354514 all mean 5.939889888395555e-05
4.3745574657805264e-05 4.374556738184765e-05
rl training, epoch3, iter0, batch393/1133, batch loss:4.374556738184765e-05, Training time:46528.17227101326
batch reward last col mean 1.8838783262253855e-06 first col mean 1.5694213288952596e-05 all mean 2.288481300638523e-05
1.6883852367755026e-05 1.688385418674443e-05
rl training, epoch3, iter0, batch394/1133, batch loss:1.688385418674443e-05, Training time:46545.42623376846
batch reward last col mean 3.7258773772919085e-06 first col mean 0.000979201402515173 all mean 7.692015788052231e-05
0.00018422545690555125 0.00018422547145746648
rl training, epoch3, iter0, batch395/1133, batch loss:0.00018422547145746648, Training time:46562.79664182663
batch reward last col mean 0.00010968885908368975 first col mean 7.13868867023848e-05 all mean 4.460402124095708e-05
2.8646001737797633e-05 2.8646001737797633e-05
rl training, epoch3, iter0, batch396/1133, batch loss:2.8646001737797633e-05, Training time:46581.01257777214
batch reward last col mean 2.294691057613818e-06 first col mean 1.5126687458177912e-06 all mean 5.5721160606481135e-05
6.333264900604263e-05 6.333264900604263e-05
rl training, epoch3, iter0, batch397/1133, batch loss:6.333264900604263e-05, Training time:46598.95316553116
batch reward last col mean 3.923446456610691e-06 first col mean 1.2607850294443779e-05 all mean 3.3594638807699084e-05
4.76121022074949e-05 4.7612109483452514e-05
rl training, epoch3, iter0, batch398/1133, batch loss:4.7612109483452514e-05, Training time:46617.16320037842
batch reward last col mean 8.412293027504347e-06 first col mean 1.0186747203988489e-05 all mean 4.185806756140664e-05
6.571404082933441e-05 6.571404082933441e-05
rl training, epoch3, iter0, batch399/1133, batch loss:6.571404082933441e-05, Training time:46635.08673429489
batch reward last col mean 5.656373787132907e-07 first col mean 8.025395072763786e-05 all mean 2.7538620997802354e-05
3.1106595997698605e-05 3.1106595997698605e-05
rl training, epoch3, iter0, batch400/1133, batch loss:3.1106595997698605e-05, Training time:46653.35935354233
batch reward last col mean 0.0008830438018776476 first col mean 1.062456431100145e-05 all mean 0.0006930394447408617
7.139748049667105e-05 7.139748049667105e-05
rl training, epoch3, iter0, batch401/1133, batch loss:7.139748049667105e-05, Training time:46671.3715569973
batch reward last col mean 2.0573172321292077e-07 first col mean 3.3731797884684056e-05 all mean 5.34841965418309e-05
5.892480839975178e-05 5.892479748581536e-05
rl training, epoch3, iter0, batch402/1133, batch loss:5.892479748581536e-05, Training time:46689.489953517914
batch reward last col mean 0.006727687083184719 first col mean 7.066624675644562e-05 all mean 0.005741668865084648
0.0002548839256633073 0.00025488389655947685
rl training, epoch3, iter0, batch403/1133, batch loss:0.00025488389655947685, Training time:46707.09830093384
batch reward last col mean 0.0004263307782821357 first col mean 3.9169553929241374e-05 all mean 0.0002652635448612273
7.227509195217863e-05 7.227509195217863e-05
rl training, epoch3, iter0, batch404/1133, batch loss:7.227509195217863e-05, Training time:46724.92573595047
batch reward last col mean 3.254647526773624e-05 first col mean 1.9403792975936085e-05 all mean 2.219382076873444e-05
4.483496013563126e-05 4.483496377361007e-05
rl training, epoch3, iter0, batch405/1133, batch loss:4.483496377361007e-05, Training time:46743.05238199234
batch reward last col mean 4.529132638708688e-06 first col mean 0.00015192896535154432 all mean 7.37563386792317e-05
0.0001754783879732713 0.00017547837342135608
rl training, epoch3, iter0, batch406/1133, batch loss:0.00017547837342135608, Training time:46761.07642054558
batch reward last col mean 0.0003044901241082698 first col mean 5.365128799894592e-06 all mean 3.652468876680359e-05
6.666817353107035e-05 6.666816625511274e-05
rl training, epoch3, iter0, batch407/1133, batch loss:6.666816625511274e-05, Training time:46779.25023341179
batch reward last col mean 4.092711151315598e-06 first col mean 1.1213504876650404e-05 all mean 3.4971406421391293e-05
4.8526653699809685e-05 4.8526653699809685e-05
rl training, epoch3, iter0, batch408/1133, batch loss:4.8526653699809685e-05, Training time:46797.17197442055
batch reward last col mean 6.545882342834375e-07 first col mean 3.760285835596733e-05 all mean 3.65889718523249e-05
6.052810567780398e-05 6.052811295376159e-05
rl training, epoch3, iter0, batch409/1133, batch loss:6.052811295376159e-05, Training time:46814.602237463
batch reward last col mean 4.01531215175055e-05 first col mean 1.0557731002336368e-05 all mean 6.065963680157438e-05
7.996656495379284e-05 7.996656495379284e-05
rl training, epoch3, iter0, batch410/1133, batch loss:7.996656495379284e-05, Training time:46832.109735012054
batch reward last col mean 5.8554574934532866e-05 first col mean 0.0029755262657999992 all mean 0.00013242998102214187
0.00016610970487818122 0.00016610970487818122
rl training, epoch3, iter0, batch411/1133, batch loss:0.00016610970487818122, Training time:46850.48937320709
batch reward last col mean 8.964459993876517e-06 first col mean 0.000145567930303514 all mean 4.5708049583481625e-05
4.208433529129252e-05 4.2084328015334904e-05
rl training, epoch3, iter0, batch412/1133, batch loss:4.2084328015334904e-05, Training time:46867.99487900734
batch reward last col mean 7.146291864046361e-06 first col mean 3.73017173842527e-05 all mean 5.0777776777977124e-05
8.973325020633638e-05 8.973324293037876e-05
rl training, epoch3, iter0, batch413/1133, batch loss:8.973324293037876e-05, Training time:46885.7061252594
batch reward last col mean 5.052678898209706e-05 first col mean 1.1125477612949908e-05 all mean 6.979311729082838e-05
4.166052895016037e-05 4.166052895016037e-05
rl training, epoch3, iter0, batch414/1133, batch loss:4.166052895016037e-05, Training time:46903.07206654549
batch reward last col mean 0.005642215721309185 first col mean 3.323901182739064e-05 all mean 0.005317238159477711
0.0004631589399650693 0.0004631588817574084
rl training, epoch3, iter0, batch415/1133, batch loss:0.0004631588817574084, Training time:46920.424689531326
batch reward last col mean 3.5666148505697493e-06 first col mean 0.0012850110651925206 all mean 8.581234578741714e-05
5.4011590691516176e-05 5.401158341555856e-05
rl training, epoch3, iter0, batch416/1133, batch loss:5.401158341555856e-05, Training time:46938.502232551575
batch reward last col mean 5.484821485879365e-06 first col mean 0.00021710843429900706 all mean 3.9594822737853974e-05
5.071829218650237e-05 5.071829218650237e-05
rl training, epoch3, iter0, batch417/1133, batch loss:5.071829218650237e-05, Training time:46955.92977762222
batch reward last col mean 5.482614596985513e-06 first col mean 5.026885264669545e-05 all mean 5.371886072680354e-05
6.71999150654301e-05 6.71999150654301e-05
rl training, epoch3, iter0, batch418/1133, batch loss:6.71999150654301e-05, Training time:46974.04114866257
batch reward last col mean 0.0006160128978081048 first col mean 0.0006622160435654223 all mean 0.0006178469047881663
4.063179949298501e-05 4.063180313096382e-05
rl training, epoch3, iter0, batch419/1133, batch loss:4.063180313096382e-05, Training time:46992.418028116226
batch reward last col mean 1.3806966308038682e-05 first col mean 8.975342643680051e-05 all mean 3.122655471088365e-05
4.141359750065021e-05 4.1413593862671405e-05
rl training, epoch3, iter0, batch420/1133, batch loss:4.1413593862671405e-05, Training time:47010.400456905365
batch reward last col mean 7.2787552198860794e-06 first col mean 9.03227919479832e-06 all mean 2.820367444655858e-05
3.48735811712686e-05 3.487357753328979e-05
rl training, epoch3, iter0, batch421/1133, batch loss:3.487357753328979e-05, Training time:47028.69726085663
batch reward last col mean 1.9493998593134165e-07 first col mean 2.2550741050508805e-05 all mean 2.7353307814337313e-05
3.8529666198883206e-05 3.8529666198883206e-05
rl training, epoch3, iter0, batch422/1133, batch loss:3.8529666198883206e-05, Training time:47046.88598585129
batch reward last col mean 6.697071512462571e-05 first col mean 1.2825036719732452e-05 all mean 6.561799818882719e-05
3.784973523579538e-05 3.7849738873774186e-05
rl training, epoch3, iter0, batch423/1133, batch loss:3.7849738873774186e-05, Training time:47064.358474969864
batch reward last col mean 7.900139462435618e-05 first col mean 3.295555870863609e-05 all mean 5.054021312389523e-05
5.037679511588067e-05 5.037679147790186e-05
rl training, epoch3, iter0, batch424/1133, batch loss:5.037679147790186e-05, Training time:47082.435041189194
batch reward last col mean 3.915747583960183e-06 first col mean 8.216314017772675e-05 all mean 0.00013547537673730403
0.0002829334116540849 0.00028293338255025446
rl training, epoch3, iter0, batch425/1133, batch loss:0.00028293338255025446, Training time:47100.62785124779
batch reward last col mean 0.0002471606421750039 first col mean 0.0002397330681560561 all mean 0.00031771729118190706
0.00037527759559452534 0.00037527759559452534
rl training, epoch3, iter0, batch426/1133, batch loss:0.00037527759559452534, Training time:47118.2290866375
batch reward last col mean 1.2597445220308146e-06 first col mean 1.4789053238928318e-05 all mean 4.0395749238086864e-05
3.1576648325426504e-05 3.1576648325426504e-05
rl training, epoch3, iter0, batch427/1133, batch loss:3.1576648325426504e-05, Training time:47136.270859479904
batch reward last col mean 2.7162346668774262e-05 first col mean 1.171871554106474e-05 all mean 5.073972715763375e-05
6.07086876698304e-05 6.07086876698304e-05
rl training, epoch3, iter0, batch428/1133, batch loss:6.07086876698304e-05, Training time:47153.73918032646
batch reward last col mean 2.405800614724285e-06 first col mean 6.307163403107552e-06 all mean 5.01692047691904e-05
5.893470734008588e-05 5.893470734008588e-05
rl training, epoch3, iter0, batch429/1133, batch loss:5.893470734008588e-05, Training time:47171.855283498764
batch reward last col mean 3.93465506931534e-06 first col mean 5.077718469692627e-06 all mean 5.058546594227664e-05
6.187719554873183e-05 6.187719554873183e-05
rl training, epoch3, iter0, batch430/1133, batch loss:6.187719554873183e-05, Training time:47189.464985609055
batch reward last col mean 0.007147975265979767 first col mean 6.276525255088927e-06 all mean 0.006608118303120136
0.0005761479842476547 0.0005761479842476547
rl training, epoch3, iter0, batch431/1133, batch loss:0.0005761479842476547, Training time:47206.754565000534
batch reward last col mean 0.0008261995972134173 first col mean 3.089508390985429e-05 all mean 0.0006243831012398005
0.00015467911725863814 0.00015467911725863814
rl training, epoch3, iter0, batch432/1133, batch loss:0.00015467911725863814, Training time:47224.84515094757
batch reward last col mean 0.00019160003284923732 first col mean 0.00020550546469166875 all mean 9.151286940323189e-05
7.109965372364968e-05 7.109966827556491e-05
rl training, epoch3, iter0, batch433/1133, batch loss:7.109966827556491e-05, Training time:47242.88480782509
batch reward last col mean 1.7891668903757818e-05 first col mean 7.173222547862679e-05 all mean 5.02796501677949e-05
4.7639114200137556e-05 4.763912511407398e-05
rl training, epoch3, iter0, batch434/1133, batch loss:4.763912511407398e-05, Training time:47260.15475964546
batch reward last col mean 0.0004525005351752043 first col mean 1.726927985146176e-05 all mean 0.0004146087740082294
7.521289080614224e-05 7.521289080614224e-05
rl training, epoch3, iter0, batch435/1133, batch loss:7.521289080614224e-05, Training time:47278.42731976509
batch reward last col mean 2.3331244847213384e-07 first col mean 9.835314995143563e-05 all mean 3.8599027902819216e-05
5.946254896116443e-05 5.946255259914324e-05
rl training, epoch3, iter0, batch436/1133, batch loss:5.946255259914324e-05, Training time:47295.95945119858
batch reward last col mean 0.000320209888741374 first col mean 8.165741746779531e-05 all mean 0.0002922372950706631
5.213871190790087e-05 5.213871190790087e-05
rl training, epoch3, iter0, batch437/1133, batch loss:5.213871190790087e-05, Training time:47313.67072367668
batch reward last col mean 8.518541108060163e-06 first col mean 0.0011676009744405746 all mean 0.0001349010708509013
0.0004374149430077523 0.00043741491390392184
rl training, epoch3, iter0, batch438/1133, batch loss:0.00043741491390392184, Training time:47332.067331790924
batch reward last col mean 1.00166073480068e-06 first col mean 4.8986548790708184e-05 all mean 4.2827661673072726e-05
5.4171207011677325e-05 5.4171196097740903e-05
rl training, epoch3, iter0, batch439/1133, batch loss:5.4171196097740903e-05, Training time:47350.86791110039
batch reward last col mean 2.4983955881907605e-06 first col mean 2.2062970401748316e-06 all mean 5.1120783609803766e-05
6.353094795485958e-05 6.353094795485958e-05
rl training, epoch3, iter0, batch440/1133, batch loss:6.353094795485958e-05, Training time:47368.57078433037
batch reward last col mean 0.0001244553131982684 first col mean 1.0727333574322984e-05 all mean 6.894524267408997e-05
4.54426663054619e-05 4.54426663054619e-05
rl training, epoch3, iter0, batch441/1133, batch loss:4.54426663054619e-05, Training time:47387.37313055992
batch reward last col mean 4.849727247346891e-06 first col mean 7.969920261530206e-05 all mean 4.244391311658546e-05
2.7800973839475773e-05 2.7800973839475773e-05
rl training, epoch3, iter0, batch442/1133, batch loss:2.7800973839475773e-05, Training time:47405.54173326492
batch reward last col mean 5.758238330599852e-05 first col mean 0.00016398332081735134 all mean 5.9359754231991246e-05
4.226071177981794e-05 4.2260704503860325e-05
rl training, epoch3, iter0, batch443/1133, batch loss:4.2260704503860325e-05, Training time:47423.02173089981
batch reward last col mean 1.0320682122255675e-06 first col mean 2.9504139092750847e-05 all mean 3.633485903264955e-05
4.7117613576119766e-05 4.711761721409857e-05
rl training, epoch3, iter0, batch444/1133, batch loss:4.711761721409857e-05, Training time:47441.03805065155
batch reward last col mean 1.98061638911895e-06 first col mean 1.181449079012964e-05 all mean 6.198079063324258e-05
8.533326763426885e-05 8.533327491022646e-05
rl training, epoch3, iter0, batch445/1133, batch loss:8.533327491022646e-05, Training time:47458.68036818504
batch reward last col mean 3.0394392069865717e-06 first col mean 0.0006413109367713332 all mean 0.00010805955389514565
0.00035527950967662036 0.00035527950967662036
rl training, epoch3, iter0, batch446/1133, batch loss:0.00035527950967662036, Training time:47476.892557621
batch reward last col mean 2.470428626111243e-05 first col mean 0.00010953882883768529 all mean 5.597606650553644e-05
3.464564724708907e-05 3.464563997113146e-05
rl training, epoch3, iter0, batch447/1133, batch loss:3.464563997113146e-05, Training time:47494.63488340378
batch reward last col mean 5.915892870689277e-06 first col mean 0.00017791788559406996 all mean 8.134814561344683e-05
0.0002065522421617061 0.00020655227126553655
rl training, epoch3, iter0, batch448/1133, batch loss:0.00020655227126553655, Training time:47512.84598684311
batch reward last col mean 0.004578756634145975 first col mean 1.2314118976064492e-05 all mean 0.004522646777331829
0.000490966544020921 0.0004909664276055992
rl training, epoch3, iter0, batch449/1133, batch loss:0.0004909664276055992, Training time:47530.03090715408
batch reward last col mean 4.912534132017754e-05 first col mean 0.0019867706578224897 all mean 8.17570835351944e-05
5.049683022662066e-05 5.0496837502578273e-05
rl training, epoch3, iter0, batch450/1133, batch loss:5.0496837502578273e-05, Training time:47548.371478796005
batch reward last col mean 7.489326526410878e-05 first col mean 0.0004880080232396722 all mean 0.00010245240991935134
3.182169530191459e-05 3.182169166393578e-05
rl training, epoch3, iter0, batch451/1133, batch loss:3.182169166393578e-05, Training time:47566.48026752472
batch reward last col mean 7.88439137977548e-05 first col mean 9.503304681857117e-06 all mean 9.67712257988751e-05
0.00012432273069862276 0.00012432273069862276
rl training, epoch3, iter0, batch452/1133, batch loss:0.00012432273069862276, Training time:47583.94038653374
batch reward last col mean 0.0002990983775816858 first col mean 0.0006215930916368961 all mean 5.268371387501247e-05
4.1474013414699584e-05 4.1474013414699584e-05
rl training, epoch3, iter0, batch453/1133, batch loss:4.1474013414699584e-05, Training time:47601.260135650635
batch reward last col mean 6.566510819538962e-07 first col mean 1.1528848517627921e-05 all mean 5.97373436903581e-05
8.346319373231381e-05 8.34631864563562e-05
rl training, epoch3, iter0, batch454/1133, batch loss:8.34631864563562e-05, Training time:47619.34793758392
batch reward last col mean 5.119314209878212e-06 first col mean 7.483486115233973e-06 all mean 5.061240153736435e-05
5.1320916099939495e-05 5.1320916099939495e-05
rl training, epoch3, iter0, batch455/1133, batch loss:5.1320916099939495e-05, Training time:47636.892397880554
batch reward last col mean 2.255847539345268e-05 first col mean 2.8683261916739866e-05 all mean 5.3090665460331365e-05
4.0633705793879926e-05 4.0633705793879926e-05
rl training, epoch3, iter0, batch456/1133, batch loss:4.0633705793879926e-05, Training time:47655.00990653038
batch reward last col mean 1.1135098247905262e-05 first col mean 5.019853779231198e-05 all mean 3.757759986910969e-05
3.023766475962475e-05 3.023766475962475e-05
rl training, epoch3, iter0, batch457/1133, batch loss:3.023766475962475e-05, Training time:47673.411563158035
batch reward last col mean 2.2023116343916627e-06 first col mean 4.6940267566242255e-06 all mean 5.5570151744177565e-05
0.0001173195632873103 0.00011731957056326792
rl training, epoch3, iter0, batch458/1133, batch loss:0.00011731957056326792, Training time:47691.50555586815
batch reward last col mean 0.00040513044223189354 first col mean 0.0003937323344871402 all mean 0.0003461310116108507
0.00010546505654929206 0.00010546503472141922
rl training, epoch3, iter0, batch459/1133, batch loss:0.00010546503472141922, Training time:47709.52703642845
batch reward last col mean 2.7399642021919135e-07 first col mean 0.0001742303866194561 all mean 2.867363036784809e-05
6.701514939777553e-05 6.701514939777553e-05
rl training, epoch3, iter0, batch460/1133, batch loss:6.701514939777553e-05, Training time:47728.146453142166
batch reward last col mean 9.278925972466823e-06 first col mean 0.0007568870787508786 all mean 3.5000637581106275e-05
2.696353658393491e-05 2.696354204090312e-05
rl training, epoch3, iter0, batch461/1133, batch loss:2.696354204090312e-05, Training time:47746.06444787979
batch reward last col mean 1.4284012650023215e-05 first col mean 0.0001470414426876232 all mean 7.802079926477745e-05
7.811096293153241e-05 7.811097748344764e-05
rl training, epoch3, iter0, batch462/1133, batch loss:7.811097748344764e-05, Training time:47763.68703579903
batch reward last col mean 3.1451181712327525e-05 first col mean 7.767473107378464e-06 all mean 2.835983468685299e-05
2.5369105060235597e-05 2.536910142225679e-05
rl training, epoch3, iter0, batch463/1133, batch loss:2.536910142225679e-05, Training time:47781.6752448082
batch reward last col mean 3.1669719646743033e-06 first col mean 0.000299215957056731 all mean 5.27761185367126e-05
4.8678524763090536e-05 4.867851748713292e-05
rl training, epoch3, iter0, batch464/1133, batch loss:4.867851748713292e-05, Training time:47800.21775317192
batch reward last col mean 0.00012801926641259342 first col mean 2.6029341825051233e-05 all mean 0.00011827325215563178
0.00020977626263629645 0.00020977626263629645
rl training, epoch3, iter0, batch465/1133, batch loss:0.00020977626263629645, Training time:47817.4646999836
batch reward last col mean 0.00011265918874414638 first col mean 7.877679308876395e-06 all mean 0.00013193119957577437
5.1925839215982705e-05 5.19258355780039e-05
rl training, epoch3, iter0, batch466/1133, batch loss:5.19258355780039e-05, Training time:47835.63883948326
batch reward last col mean 4.348266520537436e-05 first col mean 0.0006944465567357838 all mean 8.063465793384239e-05
6.502613541670144e-05 6.502613541670144e-05
rl training, epoch3, iter0, batch467/1133, batch loss:6.502613541670144e-05, Training time:47853.18734169006
batch reward last col mean 1.7524049326311797e-05 first col mean 5.086224064143607e-06 all mean 7.211687625385821e-05
0.00015182806237135082 0.0001518280478194356
rl training, epoch3, iter0, batch468/1133, batch loss:0.0001518280478194356, Training time:47871.64896988869
batch reward last col mean 8.473735988445696e-07 first col mean 0.00039316367474384606 all mean 3.6283523513702676e-05
5.713749851565808e-05 5.713749851565808e-05
rl training, epoch3, iter0, batch469/1133, batch loss:5.713749851565808e-05, Training time:47889.963861465454
batch reward last col mean 1.9754120330617297e-06 first col mean 9.131251204053115e-07 all mean 3.386926618986763e-05
7.10425665602088e-05 7.104257383616641e-05
rl training, epoch3, iter0, batch470/1133, batch loss:7.104257383616641e-05, Training time:47908.342932224274
batch reward last col mean 5.051779226050712e-07 first col mean 5.557494660024531e-06 all mean 8.20638015284203e-05
0.00018009787891060114 0.00018009787891060114
rl training, epoch3, iter0, batch471/1133, batch loss:0.00018009787891060114, Training time:47926.413596868515
batch reward last col mean 2.212253548350418e-06 first col mean 4.4994798372499645e-05 all mean 3.738847954082303e-05
3.478227517916821e-05 3.478227517916821e-05
rl training, epoch3, iter0, batch472/1133, batch loss:3.478227517916821e-05, Training time:47944.67122507095
batch reward last col mean 4.8201694880845025e-05 first col mean 2.505847623979207e-05 all mean 6.0320511693134904e-05
0.00012296988279558718 0.00012296988279558718
rl training, epoch3, iter0, batch473/1133, batch loss:0.00012296988279558718, Training time:47963.51628994942
batch reward last col mean 1.5153304047998972e-05 first col mean 2.8452209335227963e-06 all mean 2.6538766178418882e-05
2.458428753016051e-05 2.458428753016051e-05
rl training, epoch3, iter0, batch474/1133, batch loss:2.458428753016051e-05, Training time:47981.19749832153
batch reward last col mean 0.0002100665878970176 first col mean 9.931964086717926e-06 all mean 0.0001312275999225676
0.0001196243247250095 0.00011962431744905189
rl training, epoch3, iter0, batch475/1133, batch loss:0.00011962431744905189, Training time:47999.25661754608
batch reward last col mean 2.614150071167387e-05 first col mean 0.0001368670054944232 all mean 6.849672354292125e-05
3.895319241564721e-05 3.8953196053626016e-05
rl training, epoch3, iter0, batch476/1133, batch loss:3.8953196053626016e-05, Training time:48017.175946474075
batch reward last col mean 6.885418406454846e-05 first col mean 9.561045590089634e-05 all mean 6.578306783922017e-05
4.02535661123693e-05 4.02535661123693e-05
rl training, epoch3, iter0, batch477/1133, batch loss:4.02535661123693e-05, Training time:48035.19506287575
batch reward last col mean 1.2901935406262055e-05 first col mean 8.308727956318762e-06 all mean 6.155137089081109e-05
7.553117029601708e-05 7.55311775719747e-05
rl training, epoch3, iter0, batch478/1133, batch loss:7.55311775719747e-05, Training time:48053.94894194603
batch reward last col mean 3.0415762012125924e-05 first col mean 1.6845957361510955e-05 all mean 9.038361167768016e-05
9.869676432572305e-05 9.869676432572305e-05
rl training, epoch3, iter0, batch479/1133, batch loss:9.869676432572305e-05, Training time:48071.8694062233
batch reward last col mean 3.823928636847995e-06 first col mean 9.708321158541366e-05 all mean 4.0191353036789224e-05
3.639902570284903e-05 3.6399022064870223e-05
rl training, epoch3, iter0, batch480/1133, batch loss:3.6399022064870223e-05, Training time:48090.01324868202
batch reward last col mean 0.00014513719361275434 first col mean 1.8316608475288376e-05 all mean 0.00012645959213841707
6.278807268245146e-05 6.278807995840907e-05
rl training, epoch3, iter0, batch481/1133, batch loss:6.278807995840907e-05, Training time:48107.42978000641
batch reward last col mean 1.1995713293799781e-06 first col mean 3.0432320272666402e-06 all mean 4.1094677726505324e-05
5.5290951422648504e-05 5.5290951422648504e-05
rl training, epoch3, iter0, batch482/1133, batch loss:5.5290951422648504e-05, Training time:48125.756073236465
batch reward last col mean 2.06572913157288e-05 first col mean 9.146422235062346e-05 all mean 6.242578092496842e-05
8.608170901425183e-05 8.608170901425183e-05
rl training, epoch3, iter0, batch483/1133, batch loss:8.608170901425183e-05, Training time:48143.97958827019
batch reward last col mean 0.000284092704532668 first col mean 1.4744761756446678e-05 all mean 0.0002967134932987392
5.121302092447877e-05 5.1213024562457576e-05
rl training, epoch3, iter0, batch484/1133, batch loss:5.1213024562457576e-05, Training time:48161.28479218483
batch reward last col mean 0.00016553953173570335 first col mean 9.844863234320655e-05 all mean 6.441249570343643e-05
9.685537224868312e-05 9.685537224868312e-05
rl training, epoch3, iter0, batch485/1133, batch loss:9.685537224868312e-05, Training time:48179.30408906937
batch reward last col mean 1.3998617305333028e-06 first col mean 7.643558637937531e-05 all mean 6.132569251349196e-05
6.473019311670214e-05 6.473020039265975e-05
rl training, epoch3, iter0, batch486/1133, batch loss:6.473020039265975e-05, Training time:48197.163400411606
batch reward last col mean 0.00456088874489069 first col mean 8.333434379892424e-06 all mean 0.004277701955288649
0.00019905717635992914 0.00019905719091184437
rl training, epoch3, iter0, batch487/1133, batch loss:0.00019905719091184437, Training time:48215.57100558281
batch reward last col mean 2.230705285910517e-05 first col mean 0.0007419920875690877 all mean 0.00012264536053407937
5.896003858651966e-05 5.896002039662562e-05
rl training, epoch3, iter0, batch488/1133, batch loss:5.896002039662562e-05, Training time:48234.91055750847
batch reward last col mean 7.1362173912348226e-06 first col mean 6.098184530856088e-05 all mean 6.503348413389176e-05
5.925452569499612e-05 5.92545147810597e-05
rl training, epoch3, iter0, batch489/1133, batch loss:5.92545147810597e-05, Training time:48254.36177659035
batch reward last col mean 6.571066023752792e-06 first col mean 1.02149160738918e-05 all mean 9.766751463757828e-05
0.00012346972653176636 0.00012346974108368158
rl training, epoch3, iter0, batch490/1133, batch loss:0.00012346974108368158, Training time:48272.37672805786
batch reward last col mean 0.00010352785466238856 first col mean 0.00010773505346151069 all mean 6.195658352226019e-05
8.52116136229597e-05 8.521162089891732e-05
rl training, epoch3, iter0, batch491/1133, batch loss:8.521162089891732e-05, Training time:48290.19080615044
batch reward last col mean 0.00026549590984359384 first col mean 0.00011504474241519347 all mean 0.0002255909057566896
8.731443813303486e-05 8.731442358111963e-05
rl training, epoch3, iter0, batch492/1133, batch loss:8.731442358111963e-05, Training time:48308.95062446594
batch reward last col mean 1.6104528413052321e-06 first col mean 7.870660920161754e-05 all mean 4.556584462989122e-05
8.880297536961734e-05 8.880298992153257e-05
rl training, epoch3, iter0, batch493/1133, batch loss:8.880298992153257e-05, Training time:48326.948035001755
batch reward last col mean 5.573061116592726e-06 first col mean 0.0002698529278859496 all mean 4.098665158380754e-05
3.409252894925885e-05 3.409252894925885e-05
rl training, epoch3, iter0, batch494/1133, batch loss:3.409252894925885e-05, Training time:48345.09109854698
batch reward last col mean 1.0881014532060362e-05 first col mean 0.00016319280257448554 all mean 5.017288276576437e-05
6.452629168052226e-05 6.452629168052226e-05
rl training, epoch3, iter0, batch495/1133, batch loss:6.452629168052226e-05, Training time:48362.74181032181
batch reward last col mean 2.4509065497113625e-06 first col mean 0.0001186139415949583 all mean 3.615798050304875e-05
3.901741001754999e-05 3.901741001754999e-05
rl training, epoch3, iter0, batch496/1133, batch loss:3.901741001754999e-05, Training time:48380.62633776665
batch reward last col mean 1.77396225353732e-06 first col mean 0.00023808469995856285 all mean 4.731656372314319e-05
2.0280194803490303e-05 2.0280194803490303e-05
rl training, epoch3, iter0, batch497/1133, batch loss:2.0280194803490303e-05, Training time:48398.70326423645
batch reward last col mean 4.175007234152872e-06 first col mean 0.0009144408977590501 all mean 6.619995110668242e-05
4.958928911946714e-05 4.958928911946714e-05
rl training, epoch3, iter0, batch498/1133, batch loss:4.958928911946714e-05, Training time:48417.015830516815
batch reward last col mean 0.0009638718329370022 first col mean 1.0939148523902986e-05 all mean 0.0006114923162385821
0.00045803573448210955 0.00045803573448210955
rl training, epoch3, iter0, batch499/1133, batch loss:0.00045803573448210955, Training time:48435.019159793854
batch reward last col mean 0.0005069241742603481 first col mean 2.0128966298216255e-06 all mean 4.8117948608705774e-05
8.477584924548864e-05 8.477584196953103e-05
rl training, epoch3, iter0, batch500/1133, batch loss:8.477584196953103e-05, Training time:48452.222604990005
batch reward last col mean 0.0002717532915994525 first col mean 2.3850216166465543e-05 all mean 0.0001453156874049455
4.5194265112513676e-05 4.5194265112513676e-05
rl training, epoch3, iter0, batch501/1133, batch loss:4.5194265112513676e-05, Training time:48470.73005104065
batch reward last col mean 2.6996676751878113e-05 first col mean 3.1171182399702957e-06 all mean 8.400934166274965e-05
0.0001242136349901557 0.0001242136349901557
rl training, epoch3, iter0, batch502/1133, batch loss:0.0001242136349901557, Training time:48488.945897102356
batch reward last col mean 6.147233762021642e-06 first col mean 0.00020561499695759267 all mean 4.217274909024127e-05
1.2961208994966e-05 1.2961217180418316e-05
rl training, epoch3, iter0, batch503/1133, batch loss:1.2961217180418316e-05, Training time:48506.752208948135
batch reward last col mean 2.6294108465663157e-05 first col mean 2.665782449184917e-05 all mean 3.3237542083952576e-05
3.0694460292579606e-05 3.069445301662199e-05
rl training, epoch3, iter0, batch504/1133, batch loss:3.069445301662199e-05, Training time:48525.391617298126
batch reward last col mean 0.00011094377259723842 first col mean 3.211951843695715e-05 all mean 9.192689321935177e-05
0.00010268545156577602 0.00010268545156577602
rl training, epoch3, iter0, batch505/1133, batch loss:0.00010268545156577602, Training time:48543.32927465439
batch reward last col mean 1.8729919247562066e-05 first col mean 7.224017463158816e-05 all mean 4.715848626801744e-05
3.5437216865830123e-05 3.5437213227851316e-05
rl training, epoch3, iter0, batch506/1133, batch loss:3.5437213227851316e-05, Training time:48560.5996761322
batch reward last col mean 2.6608322514221072e-06 first col mean 0.0007595332572236657 all mean 8.070665353443474e-05
0.00014471086615230888 0.00014471086615230888
rl training, epoch3, iter0, batch507/1133, batch loss:0.00014471086615230888, Training time:48578.228540182114
batch reward last col mean 4.722889570984989e-06 first col mean 3.93518312193919e-05 all mean 4.8491830966668203e-05
4.6846806071698666e-05 4.684680970967747e-05
rl training, epoch3, iter0, batch508/1133, batch loss:4.684680970967747e-05, Training time:48596.57334566116
batch reward last col mean 5.761914508184418e-06 first col mean 1.26635723063373e-06 all mean 1.7033256881404668e-05
3.0517576306010596e-05 3.051757266803179e-05
rl training, epoch3, iter0, batch509/1133, batch loss:3.051757266803179e-05, Training time:48614.073241233826
batch reward last col mean 6.066262585591176e-07 first col mean 5.578450145549141e-05 all mean 7.178201485658064e-05
0.00011704329517669976 0.00011704328790074214
rl training, epoch3, iter0, batch510/1133, batch loss:0.00011704328790074214, Training time:48631.62028384209
batch reward last col mean 4.5050837798044086e-05 first col mean 0.00011634325346676633 all mean 7.723065937170759e-05
6.91610766807571e-05 6.91610766807571e-05
rl training, epoch3, iter0, batch511/1133, batch loss:6.91610766807571e-05, Training time:48650.09018564224
batch reward last col mean 4.979251116310479e-06 first col mean 2.7684732231136877e-06 all mean 2.8300950361881405e-05
3.7855392292840406e-05 3.785538501688279e-05
rl training, epoch3, iter0, batch512/1133, batch loss:3.785538501688279e-05, Training time:48668.26273775101
batch reward last col mean 4.192366304778261e-06 first col mean 3.459093932178803e-05 all mean 0.00010404087515780702
0.0002356373006477952 0.00023563731519971043
rl training, epoch3, iter0, batch513/1133, batch loss:0.00023563731519971043, Training time:48685.819274663925
batch reward last col mean 0.005997402593493462 first col mean 4.4159722165204585e-05 all mean 0.00453609274700284
0.0004606670991051942 0.0004606670991051942
rl training, epoch3, iter0, batch514/1133, batch loss:0.0004606670991051942, Training time:48703.93786907196
batch reward last col mean 1.7749898688634858e-05 first col mean 0.00016052540740929544 all mean 5.168165807845071e-05
6.356469384627417e-05 6.356469384627417e-05
rl training, epoch3, iter0, batch515/1133, batch loss:6.356469384627417e-05, Training time:48721.99471998215
batch reward last col mean 5.3731723710370716e-06 first col mean 2.7360927106201416e-06 all mean 6.435625982703641e-05
8.328157127834857e-05 8.328157127834857e-05
rl training, epoch3, iter0, batch516/1133, batch loss:8.328157127834857e-05, Training time:48740.02503156662
batch reward last col mean 4.69712758786045e-05 first col mean 2.386161759204697e-05 all mean 6.943913467694074e-05
0.00013641825353261083 0.00013641825353261083
rl training, epoch3, iter0, batch517/1133, batch loss:0.00013641825353261083, Training time:48758.74582648277
batch reward last col mean 4.5012897317064926e-05 first col mean 1.877713657449931e-06 all mean 5.853475158801302e-05
4.444333171704784e-05 4.4443324441090226e-05
rl training, epoch3, iter0, batch518/1133, batch loss:4.4443324441090226e-05, Training time:48776.05913233757
batch reward last col mean 1.9525477910065092e-06 first col mean 6.493291039078031e-06 all mean 4.409663597471081e-05
5.7044213463086635e-05 5.7044224377023056e-05
rl training, epoch3, iter0, batch519/1133, batch loss:5.7044224377023056e-05, Training time:48793.93013095856
batch reward last col mean 0.00045091938227415085 first col mean 0.00028756074607372284 all mean 0.0001332139945589006
9.493055404163897e-05 9.493054676568136e-05
rl training, epoch3, iter0, batch520/1133, batch loss:9.493054676568136e-05, Training time:48812.311796188354
batch reward last col mean 0.0002936749660875648 first col mean 0.0001366713986499235 all mean 0.00025634709163568914
0.0001118055879487656 0.0001118055879487656
rl training, epoch3, iter0, batch521/1133, batch loss:0.0001118055879487656, Training time:48829.63004565239
batch reward last col mean 1.646927103138296e-06 first col mean 2.4177890736609697e-05 all mean 4.2532938095973805e-05
0.00010548010322963819 0.0001054801105055958
rl training, epoch3, iter0, batch522/1133, batch loss:0.0001054801105055958, Training time:48847.11798930168
batch reward last col mean 1.0033909347839653e-06 first col mean 1.943835559359286e-05 all mean 5.15622305101715e-05
7.61518967919983e-05 7.615188951604068e-05
rl training, epoch3, iter0, batch523/1133, batch loss:7.615188951604068e-05, Training time:48864.443855285645
batch reward last col mean 0.002528608776628971 first col mean 0.0008061200496740639 all mean 0.0004902367363683879
0.00029148891917429864 0.00029148891917429864
rl training, epoch3, iter0, batch524/1133, batch loss:0.00029148891917429864, Training time:48881.8543305397
batch reward last col mean 0.00024458946427330375 first col mean 1.9793058527284302e-05 all mean 0.000284229579847306
9.24116829992272e-05 9.24116829992272e-05
rl training, epoch3, iter0, batch525/1133, batch loss:9.24116829992272e-05, Training time:48900.24520158768
batch reward last col mean 6.57443024465465e-07 first col mean 5.262043487164192e-06 all mean 4.2493145883781835e-05
2.7388770831748843e-05 2.7388767193770036e-05
rl training, epoch3, iter0, batch526/1133, batch loss:2.7388767193770036e-05, Training time:48918.47762918472
batch reward last col mean 8.212775719584897e-05 first col mean 2.2075901142670773e-05 all mean 6.086350549594499e-05
5.524572407011874e-05 5.524572770809755e-05
rl training, epoch3, iter0, batch527/1133, batch loss:5.524572770809755e-05, Training time:48936.31515622139
batch reward last col mean 7.397731678793207e-06 first col mean 0.00031897806911729276 all mean 0.00011580062709981576
0.00027196924202144146 0.00027196924202144146
rl training, epoch3, iter0, batch528/1133, batch loss:0.00027196924202144146, Training time:48954.450499773026
batch reward last col mean 3.086461947532371e-05 first col mean 6.788313476135954e-05 all mean 7.447465031873435e-05
8.30238132039085e-05 8.302383503178135e-05
rl training, epoch3, iter0, batch529/1133, batch loss:8.302383503178135e-05, Training time:48972.37557005882
batch reward last col mean 5.0815851864172146e-06 first col mean 1.0495479727978818e-05 all mean 6.102683983044699e-05
4.8899048124440014e-05 4.889903721050359e-05
rl training, epoch3, iter0, batch530/1133, batch loss:4.889903721050359e-05, Training time:48991.006731033325
batch reward last col mean 0.0002584907924756408 first col mean 0.000539578206371516 all mean 0.00023028277792036533
0.00013862266496289521 0.00013862266496289521
rl training, epoch3, iter0, batch531/1133, batch loss:0.00013862266496289521, Training time:49009.27030420303
batch reward last col mean 8.11394420452416e-06 first col mean 7.1056369961297605e-06 all mean 7.574330811621621e-05
7.30846295482479e-05 7.30846295482479e-05
rl training, epoch3, iter0, batch532/1133, batch loss:7.30846295482479e-05, Training time:49027.314903497696
batch reward last col mean 3.497857687762007e-05 first col mean 5.270401743473485e-05 all mean 7.485395326511934e-05
9.217837214237079e-05 9.217837214237079e-05
rl training, epoch3, iter0, batch533/1133, batch loss:9.217837214237079e-05, Training time:49044.31005311012
batch reward last col mean 4.465828624233836e-06 first col mean 0.00034691300243139267 all mean 5.2818068070337176e-05
4.9526388465892524e-05 4.9526388465892524e-05
rl training, epoch3, iter0, batch534/1133, batch loss:4.9526388465892524e-05, Training time:49061.69040226936
batch reward last col mean 0.00021926105546299368 first col mean 1.0857095730898436e-05 all mean 0.00011192933015991002
5.6503900850657374e-05 5.6503900850657374e-05
rl training, epoch3, iter0, batch535/1133, batch loss:5.6503900850657374e-05, Training time:49079.28519678116
batch reward last col mean 0.0003895206318702549 first col mean 4.214685031911358e-05 all mean 0.0003276007482782006
0.00011618811549851671 0.00011618811549851671
rl training, epoch3, iter0, batch536/1133, batch loss:0.00011618811549851671, Training time:49098.01661944389
batch reward last col mean 0.00012567048543132842 first col mean 2.016552934946958e-05 all mean 0.00014500562974717468
0.00018497371638659388 0.0001849737309385091
rl training, epoch3, iter0, batch537/1133, batch loss:0.0001849737309385091, Training time:49114.98898148537
batch reward last col mean 5.7000008382601663e-05 first col mean 0.00015310423623304814 all mean 0.00011420503142289817
0.00015954207628965378 0.000159542090841569
rl training, epoch3, iter0, batch538/1133, batch loss:0.000159542090841569, Training time:49132.02948093414
batch reward last col mean 0.00012077097926521674 first col mean 9.420919013791718e-06 all mean 9.222748485626653e-05
0.00012518629955593497 0.00012518628500401974
rl training, epoch3, iter0, batch539/1133, batch loss:0.00012518628500401974, Training time:49149.08343267441
batch reward last col mean 0.00026696964050643146 first col mean 0.000327357993228361 all mean 0.0001406408700859174
0.00018312114116270095 0.00018312112661078572
rl training, epoch3, iter0, batch540/1133, batch loss:0.00018312112661078572, Training time:49166.038650751114
batch reward last col mean 1.8411456039757468e-05 first col mean 0.001267894171178341 all mean 5.292367495712824e-05
6.0181348089827225e-05 6.018135172780603e-05
rl training, epoch3, iter0, batch541/1133, batch loss:6.018135172780603e-05, Training time:49182.99799013138
batch reward last col mean 1.2757605873048306e-05 first col mean 6.231612132978626e-06 all mean 0.00014449693844653666
0.00017082954582292587 0.00017082958947867155
rl training, epoch3, iter0, batch542/1133, batch loss:0.00017082958947867155, Training time:49201.59643244743
batch reward last col mean 0.0001343798649031669 first col mean 1.1211617675144225e-05 all mean 0.0001335279957856983
9.228703856933862e-05 9.228703856933862e-05
rl training, epoch3, iter0, batch543/1133, batch loss:9.228703856933862e-05, Training time:49219.00673890114
batch reward last col mean 2.5190624910464976e-06 first col mean 8.07909673312679e-05 all mean 6.456374103436247e-05
8.573022932978347e-05 8.573022932978347e-05
rl training, epoch3, iter0, batch544/1133, batch loss:8.573022932978347e-05, Training time:49237.57895207405
batch reward last col mean 1.286202973460604e-06 first col mean 2.7778558433055878e-05 all mean 3.148540054098703e-05
2.9617960535688326e-05 2.9617960535688326e-05
rl training, epoch3, iter0, batch545/1133, batch loss:2.9617960535688326e-05, Training time:49254.48231124878
batch reward last col mean 5.680301910615526e-06 first col mean 1.8027318219537847e-05 all mean 6.175588350743055e-05
7.658484537387267e-05 7.658484537387267e-05
rl training, epoch3, iter0, batch546/1133, batch loss:7.658484537387267e-05, Training time:49271.384394168854
batch reward last col mean 7.83974101068452e-05 first col mean 5.99085797148291e-05 all mean 7.638882379978895e-05
9.012121154228225e-05 9.012120426632464e-05
rl training, epoch3, iter0, batch547/1133, batch loss:9.012120426632464e-05, Training time:49288.21581697464
batch reward last col mean 2.2284611986833625e-06 first col mean 3.402005313546397e-05 all mean 4.6414068492595106e-05
4.505507604335435e-05 4.505507604335435e-05
rl training, epoch3, iter0, batch548/1133, batch loss:4.505507604335435e-05, Training time:49304.7933177948
batch reward last col mean 0.0005832050810568035 first col mean 0.000812413461972028 all mean 6.967603258090094e-05
8.112956129480153e-05 8.112956129480153e-05
rl training, epoch3, iter0, batch549/1133, batch loss:8.112956129480153e-05, Training time:49321.428565979004
batch reward last col mean 2.6046936909551732e-05 first col mean 6.486974598374218e-05 all mean 9.300387318944559e-05
8.019659435376525e-05 8.019660162972286e-05
rl training, epoch3, iter0, batch550/1133, batch loss:8.019660162972286e-05, Training time:49338.40021300316
batch reward last col mean 9.424943709746003e-05 first col mean 5.893604247830808e-05 all mean 0.00010856687731575221
0.0001562057004775852 0.00015620571502950042
rl training, epoch3, iter0, batch551/1133, batch loss:0.00015620571502950042, Training time:49355.3753092289
batch reward last col mean 4.389345122035593e-05 first col mean 0.0001225910527864471 all mean 5.5831140343798324e-05
5.1896269724238664e-05 5.1896269724238664e-05
rl training, epoch3, iter0, batch552/1133, batch loss:5.1896269724238664e-05, Training time:49372.433490753174
batch reward last col mean 4.547044227365404e-06 first col mean 1.569046071381308e-05 all mean 9.212257282342762e-05
0.00012788447202183306 0.00012788447202183306
rl training, epoch3, iter0, batch553/1133, batch loss:0.00012788447202183306, Training time:49389.417051792145
batch reward last col mean 2.2581341454497306e-06 first col mean 6.091027535148896e-05 all mean 7.413302955683321e-05
9.620607306715101e-05 9.620608034310862e-05
rl training, epoch3, iter0, batch554/1133, batch loss:9.620608034310862e-05, Training time:49406.56402206421
batch reward last col mean 1.3121203664923087e-05 first col mean 2.340289211133495e-05 all mean 6.354908691719174e-05
5.9959911595797166e-05 5.9959911595797166e-05
rl training, epoch3, iter0, batch555/1133, batch loss:5.9959911595797166e-05, Training time:49423.4769487381
batch reward last col mean 1.512662765890127e-05 first col mean 9.147946911980398e-06 all mean 7.448455289704725e-05
6.347778253257275e-05 6.347778253257275e-05
rl training, epoch3, iter0, batch556/1133, batch loss:6.347778253257275e-05, Training time:49440.5194940567
batch reward last col mean 3.25207270179817e-06 first col mean 0.0017980094999074936 all mean 9.651652362663299e-05
8.68406641529873e-05 8.684065687702969e-05
rl training, epoch3, iter0, batch557/1133, batch loss:8.684065687702969e-05, Training time:49457.42413806915
batch reward last col mean 1.2839936971431598e-06 first col mean 0.00021259394998196512 all mean 0.00010740975994849578
0.0001201186387334019 0.00012011864600935951
rl training, epoch3, iter0, batch558/1133, batch loss:0.00012011864600935951, Training time:49474.41363072395
batch reward last col mean 4.2607634895830415e-06 first col mean 1.7021586245391518e-05 all mean 3.345287041156553e-05
2.9979126338730566e-05 2.9979126338730566e-05
rl training, epoch3, iter0, batch559/1133, batch loss:2.9979126338730566e-05, Training time:49491.438178777695
batch reward last col mean 2.0880564989056438e-05 first col mean 0.0016955642495304346 all mean 0.00020713005505967885
0.0004012968565803021 0.0004012968565803021
rl training, epoch3, iter0, batch560/1133, batch loss:0.0004012968565803021, Training time:49508.47400403023
batch reward last col mean 2.4453083824482746e-05 first col mean 0.0017613557865843177 all mean 0.00010488539555808529
6.817776011303067e-05 6.817776738898829e-05
rl training, epoch3, iter0, batch561/1133, batch loss:6.817776738898829e-05, Training time:49525.44353604317
batch reward last col mean 8.944384148890094e-07 first col mean 6.99013180565089e-05 all mean 7.230354094645008e-05
0.00011248559167142957 0.00011248559167142957
rl training, epoch3, iter0, batch562/1133, batch loss:0.00011248559167142957, Training time:49542.56354308128
batch reward last col mean 3.336797090014443e-05 first col mean 0.00013696249516215175 all mean 6.639110506512225e-05
0.00026431927108205855 0.00026431927108205855
rl training, epoch3, iter0, batch563/1133, batch loss:0.00026431927108205855, Training time:49559.539955616
batch reward last col mean 1.6797432181192562e-05 first col mean 1.2983460692339577e-05 all mean 8.281327609438449e-05
0.00014000236114952713 0.00014000237570144236
rl training, epoch3, iter0, batch564/1133, batch loss:0.00014000237570144236, Training time:49576.433326244354
batch reward last col mean 9.263654646929353e-06 first col mean 3.6561501474352553e-05 all mean 8.796316978987306e-05
4.334486220614053e-05 4.33448440162465e-05
rl training, epoch3, iter0, batch565/1133, batch loss:4.33448440162465e-05, Training time:49593.42110466957
batch reward last col mean 0.000287671631667763 first col mean 1.0316251064068638e-05 all mean 0.00020112560014240444
0.00012832426000386477 0.00012832426000386477
rl training, epoch3, iter0, batch566/1133, batch loss:0.00012832426000386477, Training time:49610.48208332062
batch reward last col mean 1.2092412362108007e-05 first col mean 3.153397483401932e-05 all mean 0.00010025685332948342
9.303558908868581e-05 9.303556726081297e-05
rl training, epoch3, iter0, batch567/1133, batch loss:9.303556726081297e-05, Training time:49627.58400321007
batch reward last col mean 0.0077735953964293 first col mean 2.6058669391204603e-05 all mean 0.0070806387811899185
0.0005572765949182212 0.0005572765949182212
rl training, epoch3, iter0, batch568/1133, batch loss:0.0005572765949182212, Training time:49644.59951591492
batch reward last col mean 4.4311389046924887e-07 first col mean 0.0003432108787819743 all mean 3.403047958272509e-05
3.104772622464225e-05 3.104772258666344e-05
rl training, epoch3, iter0, batch569/1133, batch loss:3.104772258666344e-05, Training time:49661.61810851097
batch reward last col mean 2.1862797439098358e-05 first col mean 0.0003348480968270451 all mean 0.00010496507456991822
9.108239464694634e-05 9.108239464694634e-05
rl training, epoch3, iter0, batch570/1133, batch loss:9.108239464694634e-05, Training time:49678.680072784424
batch reward last col mean 1.0814724191732239e-05 first col mean 0.00015158960013650358 all mean 9.271598537452519e-05
0.00010315592226106673 0.00010315592226106673
rl training, epoch3, iter0, batch571/1133, batch loss:0.00010315592226106673, Training time:49696.719173669815
batch reward last col mean 0.00013377844879869372 first col mean 9.696060260466766e-06 all mean 0.00010563834803178906
0.000124097234220244 0.00012409721966832876
rl training, epoch3, iter0, batch572/1133, batch loss:0.00012409721966832876, Training time:49715.20912051201
batch reward last col mean 2.377376404183451e-06 first col mean 0.0001839406177168712 all mean 9.934167610481381e-05
0.0001940260990522802 0.00019402608450036496
rl training, epoch3, iter0, batch573/1133, batch loss:0.00019402608450036496, Training time:49733.71876049042
batch reward last col mean 2.9285843993420713e-05 first col mean 0.00024609084357507527 all mean 0.00014414328325074166
0.0001926710392581299 0.0001926710392581299
rl training, epoch3, iter0, batch574/1133, batch loss:0.0001926710392581299, Training time:49750.6824491024
batch reward last col mean 1.7566268070368096e-05 first col mean 3.973391358158551e-06 all mean 7.08718434907496e-05
0.00012102165055694059 0.00012102165055694059
rl training, epoch3, iter0, batch575/1133, batch loss:0.00012102165055694059, Training time:49767.39055156708
batch reward last col mean 3.915371962648351e-06 first col mean 6.1825630837120116e-06 all mean 5.433421392808668e-05
7.661823474336416e-05 7.661824201932177e-05
rl training, epoch3, iter0, batch576/1133, batch loss:7.661824201932177e-05, Training time:49784.485384464264
batch reward last col mean 9.045564183907118e-06 first col mean 0.0004017338214907795 all mean 8.204289770219475e-05
0.0001796322176232934 0.00017963220307137817
rl training, epoch3, iter0, batch577/1133, batch loss:0.00017963220307137817, Training time:49801.579199790955
batch reward last col mean 6.6842658270616084e-06 first col mean 2.8194386686664075e-05 all mean 8.924230496631935e-05
0.000103626778582111 0.000103626778582111
rl training, epoch3, iter0, batch578/1133, batch loss:0.000103626778582111, Training time:49818.52910351753
batch reward last col mean 6.422586011467502e-05 first col mean 0.0007604520651511848 all mean 0.00013197398220654577
0.00020798295736312866 0.0002079829719150439
rl training, epoch3, iter0, batch579/1133, batch loss:0.0002079829719150439, Training time:49835.51787304878
batch reward last col mean 0.001589507912285626 first col mean 0.00015412217180710286 all mean 0.001568466774187982
0.0001640589616727084 0.00016405894712079316
rl training, epoch3, iter0, batch580/1133, batch loss:0.00016405894712079316, Training time:49852.54673075676
batch reward last col mean 3.4159497772634495e-06 first col mean 0.00023168278858065605 all mean 2.9719423764618114e-05
2.9921138775534928e-05 2.9921138775534928e-05
rl training, epoch3, iter0, batch581/1133, batch loss:2.9921138775534928e-05, Training time:49869.49852967262
batch reward last col mean 8.220086442634056e-07 first col mean 3.2484400435350835e-05 all mean 0.0001293124514631927
0.0002401285310043022 0.0002401285310043022
rl training, epoch3, iter0, batch582/1133, batch loss:0.0002401285310043022, Training time:49886.45682930946
batch reward last col mean 2.516675704100635e-05 first col mean 3.167751492583193e-05 all mean 9.730146121000871e-05
0.00012048387725371867 0.00012048389908159152
rl training, epoch3, iter0, batch583/1133, batch loss:0.00012048389908159152, Training time:49903.47892999649
batch reward last col mean 0.0006286141579039395 first col mean 1.997165963985026e-05 all mean 0.0006392182549461722
0.0001194216383737512 0.0001194216383737512
rl training, epoch3, iter0, batch584/1133, batch loss:0.0001194216383737512, Training time:49920.40060758591
batch reward last col mean 1.1841503692266997e-05 first col mean 5.05447642353829e-05 all mean 7.717122207395732e-05
9.217864135280252e-05 9.21786340768449e-05
rl training, epoch3, iter0, batch585/1133, batch loss:9.21786340768449e-05, Training time:49939.09261274338
batch reward last col mean 0.007398535963147879 first col mean 1.7083410057239234e-05 all mean 0.0056707728654146194
0.0004017456085421145 0.0004017456085421145
rl training, epoch3, iter0, batch586/1133, batch loss:0.0004017456085421145, Training time:49955.994377851486
batch reward last col mean 5.063886055722833e-05 first col mean 1.1607080523390323e-05 all mean 8.816555782686919e-05
9.239774954039603e-05 9.239776409231126e-05
rl training, epoch3, iter0, batch587/1133, batch loss:9.239776409231126e-05, Training time:49972.797266960144
batch reward last col mean 2.9616585379699245e-06 first col mean 0.0008190535590983927 all mean 6.792993372073397e-05
5.3966010455042124e-05 5.396600681706332e-05
rl training, epoch3, iter0, batch588/1133, batch loss:5.396600681706332e-05, Training time:49989.535930395126
batch reward last col mean 7.67688688938506e-05 first col mean 2.1233930965536274e-05 all mean 9.56139774643816e-05
0.00012248242273926735 0.00012248243729118258
rl training, epoch3, iter0, batch589/1133, batch loss:0.00012248243729118258, Training time:50006.51022863388
batch reward last col mean 0.0014775689924135804 first col mean 0.0018598800525069237 all mean 0.0012613155413419008
0.00014453145558945835 0.00014453145558945835
rl training, epoch3, iter0, batch590/1133, batch loss:0.00014453145558945835, Training time:50025.19587087631
batch reward last col mean 6.825446234870469e-07 first col mean 0.00013041900820098817 all mean 9.7650547104422e-05
0.00022900127805769444 0.00022900132171344012
rl training, epoch3, iter0, batch591/1133, batch loss:0.00022900132171344012, Training time:50042.059463977814
batch reward last col mean 8.442074431513902e-06 first col mean 8.311427518492565e-05 all mean 6.492851389339194e-05
5.425351264420897e-05 5.425352355814539e-05
rl training, epoch3, iter0, batch592/1133, batch loss:5.425352355814539e-05, Training time:50058.9022026062
batch reward last col mean 0.0026651122607290745 first col mean 0.0011186228366568685 all mean 0.0007031632121652365
0.00019361548766028136 0.00019361548766028136
rl training, epoch3, iter0, batch593/1133, batch loss:0.00019361548766028136, Training time:50075.781989097595
batch reward last col mean 0.0019595713820308447 first col mean 0.001312318374402821 all mean 0.0012725233100354671
0.0003010774089489132 0.0003010774089489132
rl training, epoch3, iter0, batch594/1133, batch loss:0.0003010774089489132, Training time:50092.95713663101
batch reward last col mean 0.0003400001733098179 first col mean 2.196470404669526e-06 all mean 0.00028226629365235567
5.86321039008908e-05 5.863209662493318e-05
rl training, epoch3, iter0, batch595/1133, batch loss:5.863209662493318e-05, Training time:50109.91716194153
batch reward last col mean 1.5222271031234413e-05 first col mean 0.0005206972127780318 all mean 9.905460319714621e-05
0.00028513066354207695 0.00028513066354207695
rl training, epoch3, iter0, batch596/1133, batch loss:0.00028513066354207695, Training time:50126.71399092674
batch reward last col mean 0.0027383549604564905 first col mean 0.00012456382683012635 all mean 0.0005665039643645287
0.0002576890983618796 0.0002576890983618796
rl training, epoch3, iter0, batch597/1133, batch loss:0.0002576890983618796, Training time:50143.53224849701
batch reward last col mean 1.0667512469808571e-05 first col mean 0.0019155695335939527 all mean 7.7508702815976e-05
4.75421802548226e-05 4.7542183892801404e-05
rl training, epoch3, iter0, batch598/1133, batch loss:4.7542183892801404e-05, Training time:50160.32793402672
batch reward last col mean 9.441578731639311e-05 first col mean 0.0012887152843177319 all mean 0.00022451971017289907
0.0005025290884077549 0.000502529030200094
rl training, epoch3, iter0, batch599/1133, batch loss:0.000502529030200094, Training time:50177.115036726
batch reward last col mean 0.0006732991896569729 first col mean 2.2725522285327315e-05 all mean 0.0007890934939496219
0.0005327342078089714 0.0005327341496013105
rl training, epoch3, iter0, batch600/1133, batch loss:0.0005327341496013105, Training time:50193.82451248169
batch reward last col mean 8.580474059272092e-06 first col mean 0.00015348616580013186 all mean 8.376131154363975e-05
0.00010065043170470744 0.00010065042442874983
rl training, epoch3, iter0, batch601/1133, batch loss:0.00010065042442874983, Training time:50210.553423166275
batch reward last col mean 0.00031009630765765905 first col mean 0.00027629834949038923 all mean 0.00023214906104840338
0.00011195663682883605 0.00011195662955287844
rl training, epoch3, iter0, batch602/1133, batch loss:0.00011195662955287844, Training time:50227.27333688736
batch reward last col mean 9.166293239104562e-06 first col mean 0.0005018591182306409 all mean 8.015321509446949e-05
5.937606329098344e-05 5.937605965300463e-05
rl training, epoch3, iter0, batch603/1133, batch loss:5.937605965300463e-05, Training time:50244.13187670708
batch reward last col mean 0.00014908486627973616 first col mean 0.00012894893006887287 all mean 0.0001224339212058112
9.22148537938483e-05 9.22148537938483e-05
rl training, epoch3, iter0, batch604/1133, batch loss:9.22148537938483e-05, Training time:50261.131210803986
batch reward last col mean 5.49979813513346e-06 first col mean 0.0008537439280189574 all mean 0.00010089750867336988
0.00012272702588234097 0.00012272702588234097
rl training, epoch3, iter0, batch605/1133, batch loss:0.00012272702588234097, Training time:50278.049364089966
batch reward last col mean 0.0002286338567500934 first col mean 1.3404162928054575e-05 all mean 0.000283053086604923
0.00010703839507186785 0.00010703838779591024
rl training, epoch3, iter0, batch606/1133, batch loss:0.00010703838779591024, Training time:50294.9232275486
batch reward last col mean 2.1472642401931807e-05 first col mean 0.000707648228853941 all mean 0.000120973025332205
0.00039912795182317495 0.0003991279227193445
rl training, epoch3, iter0, batch607/1133, batch loss:0.0003991279227193445, Training time:50311.59253358841
batch reward last col mean 0.006461402866989374 first col mean 0.0001386522053508088 all mean 0.005573525559157133
0.0005243462510406971 0.000524346309248358
rl training, epoch3, iter0, batch608/1133, batch loss:0.000524346309248358, Training time:50328.39104485512
batch reward last col mean 0.0026386973913758993 first col mean 0.0008247687947005033 all mean 0.0022319506388157606
0.00026166424504481256 0.0002616642159409821
rl training, epoch3, iter0, batch609/1133, batch loss:0.0002616642159409821, Training time:50345.20608305931
batch reward last col mean 1.8729369912762195e-05 first col mean 4.258604349161033e-06 all mean 0.00010191369074163958
0.0001256440009456128 0.00012564398639369756
rl training, epoch3, iter0, batch610/1133, batch loss:0.00012564398639369756, Training time:50362.04612016678
batch reward last col mean 6.06717048867722e-06 first col mean 3.868724525091238e-05 all mean 3.664450559881516e-05
4.315123078413308e-05 4.315123806009069e-05
rl training, epoch3, iter0, batch611/1133, batch loss:4.315123806009069e-05, Training time:50379.1021900177
batch reward last col mean 3.293067857157439e-05 first col mean 1.9463919670670293e-05 all mean 9.463351307203993e-05
0.00024036187096498907 0.00024036187096498907
rl training, epoch3, iter0, batch612/1133, batch loss:0.00024036187096498907, Training time:50396.12287425995
batch reward last col mean 3.6887718124489766e-06 first col mean 4.166025610174984e-05 all mean 5.058377064415254e-05
7.053001172607765e-05 7.053001172607765e-05
rl training, epoch3, iter0, batch613/1133, batch loss:7.053001172607765e-05, Training time:50413.10408735275
batch reward last col mean 0.0001135408238042146 first col mean 3.772653508349322e-05 all mean 9.961458999896422e-05
4.6360757551155984e-05 4.6360757551155984e-05
rl training, epoch3, iter0, batch614/1133, batch loss:4.6360757551155984e-05, Training time:50431.12263417244
batch reward last col mean 0.0003320093674119562 first col mean 1.9669860193971545e-05 all mean 0.00016865431098267436
0.0002769141865428537 0.0002769141865428537
rl training, epoch3, iter0, batch615/1133, batch loss:0.0002769141865428537, Training time:50448.04245400429
batch reward last col mean 5.549113211600343e-06 first col mean 3.907482096110471e-06 all mean 7.494782039429992e-05
0.00011352874571457505 0.00011352876026649028
rl training, epoch3, iter0, batch616/1133, batch loss:0.00011352876026649028, Training time:50466.181418418884
batch reward last col mean 4.7143646497715963e-07 first col mean 0.00040791378705762327 all mean 9.782124107005075e-05
0.0002066558663500473 0.0002066558663500473
rl training, epoch3, iter0, batch617/1133, batch loss:0.0002066558663500473, Training time:50484.80444574356
batch reward last col mean 3.7970425182720646e-05 first col mean 5.995218816678971e-05 all mean 0.00012559420429170132
0.00016169420268852264 0.00016169420268852264
rl training, epoch3, iter0, batch618/1133, batch loss:0.00016169420268852264, Training time:50503.35961437225
batch reward last col mean 0.0006611717981286347 first col mean 0.0020789476111531258 all mean 0.0006473775138147175
0.00014263179036788642 0.00014263179036788642
rl training, epoch3, iter0, batch619/1133, batch loss:0.00014263179036788642, Training time:50520.20770525932
batch reward last col mean 1.0104614375450183e-05 first col mean 2.0220559235895053e-05 all mean 0.00019112108566332608
0.0003416628751438111 0.0003416628751438111
rl training, epoch3, iter0, batch620/1133, batch loss:0.0003416628751438111, Training time:50536.92510962486
batch reward last col mean 3.5086659408989362e-06 first col mean 6.5868680394487455e-06 all mean 0.00014587871555704623
0.00018213393923360854 0.0001821339101297781
rl training, epoch3, iter0, batch621/1133, batch loss:0.0001821339101297781, Training time:50553.87644457817
batch reward last col mean 0.0005089450278319418 first col mean 0.00011745700612664223 all mean 0.000539366330485791
0.00012527842773124576 0.00012527844228316098
rl training, epoch3, iter0, batch622/1133, batch loss:0.00012527844228316098, Training time:50570.730793237686
batch reward last col mean 1.9229364625061862e-06 first col mean 0.0004939078353345394 all mean 0.00012857973342761397
0.00010544080578256398 0.00010544078395469114
rl training, epoch3, iter0, batch623/1133, batch loss:0.00010544078395469114, Training time:50587.67079424858
batch reward last col mean 0.00011643638572422788 first col mean 6.925452908035368e-05 all mean 0.0001187041198136285
0.00010224935249425471 0.00010224935249425471
rl training, epoch3, iter0, batch624/1133, batch loss:0.00010224935249425471, Training time:50604.74956989288
batch reward last col mean 7.470417767763138e-05 first col mean 1.0729269888543058e-05 all mean 6.728631706209853e-05
4.1050869185710326e-05 4.105086554773152e-05
rl training, epoch3, iter0, batch625/1133, batch loss:4.105086554773152e-05, Training time:50621.742260456085
batch reward last col mean 0.00029343218193389475 first col mean 0.000376393087208271 all mean 0.00023911365133244544
0.0001562722318340093 0.0001562722318340093
rl training, epoch3, iter0, batch626/1133, batch loss:0.0001562722318340093, Training time:50638.730916023254
batch reward last col mean 1.7567360828252276e-06 first col mean 4.5911157940281555e-05 all mean 8.42191802803427e-05
9.781122207641602e-05 9.781122935237363e-05
rl training, epoch3, iter0, batch627/1133, batch loss:9.781122935237363e-05, Training time:50655.626479148865
batch reward last col mean 0.004137759562581778 first col mean 6.176199531182647e-05 all mean 0.0035609754268079996
0.0003666291886474937 0.0003666291886474937
rl training, epoch3, iter0, batch628/1133, batch loss:0.0003666291886474937, Training time:50672.65102171898
batch reward last col mean 0.0027299660723656416 first col mean 5.0989965529879555e-05 all mean 0.0021855272352695465
0.0003161034546792507 0.0003161034546792507
rl training, epoch3, iter0, batch629/1133, batch loss:0.0003161034546792507, Training time:50689.664674282074
batch reward last col mean 1.0510683750908356e-05 first col mean 0.00011781241482822224 all mean 7.068222475936636e-05
8.549167978344485e-05 8.549167978344485e-05
rl training, epoch3, iter0, batch630/1133, batch loss:8.549167978344485e-05, Training time:50706.587517499924
batch reward last col mean 0.00027442301507107913 first col mean 0.0014440360246226192 all mean 0.00026715395506471395
0.00032248589559458196 0.00032248583738692105
rl training, epoch3, iter0, batch631/1133, batch loss:0.00032248583738692105, Training time:50725.28949522972
batch reward last col mean 9.195684469887055e-06 first col mean 3.266907515353523e-05 all mean 0.0001270573411602527
0.00019872204575221986 0.00019872204575221986
rl training, epoch3, iter0, batch632/1133, batch loss:0.00019872204575221986, Training time:50743.82092547417
batch reward last col mean 8.211678505176678e-06 first col mean 0.0002720764896366745 all mean 0.0001405804796377197
0.00016985635738819838 0.00016985635738819838
rl training, epoch3, iter0, batch633/1133, batch loss:0.00016985635738819838, Training time:50762.47800016403
batch reward last col mean 8.674766286276281e-05 first col mean 0.0011623067548498511 all mean 0.00016037760360632092
0.00010910954733844846 0.00010910954733844846
rl training, epoch3, iter0, batch634/1133, batch loss:0.00010910954733844846, Training time:50781.15343093872
batch reward last col mean 0.0011824689572677016 first col mean 0.0001429884578101337 all mean 0.0011644166661426425
0.0003107477386947721 0.00031074779690243304
rl training, epoch3, iter0, batch635/1133, batch loss:0.00031074779690243304, Training time:50799.72620892525
batch reward last col mean 1.1461459507700056e-05 first col mean 9.092500840779394e-05 all mean 0.00012270812294445932
0.0002511441125534475 0.0002511441125534475
rl training, epoch3, iter0, batch636/1133, batch loss:0.0002511441125534475, Training time:50816.608402729034
batch reward last col mean 0.0006569059332832694 first col mean 0.0019026856170967221 all mean 0.0002675665309652686
0.0001646332093514502 0.00016463319479953498
rl training, epoch3, iter0, batch637/1133, batch loss:0.00016463319479953498, Training time:50833.49549531937
batch reward last col mean 2.480438070051605e-06 first col mean 0.00011643110337899998 all mean 0.00014862956595607102
0.00016279597184620798 0.00016279595729429275
rl training, epoch3, iter0, batch638/1133, batch loss:0.00016279595729429275, Training time:50850.11979365349
batch reward last col mean 0.0002704486541915685 first col mean 1.5275285477400757e-05 all mean 0.0002953903458546847
0.00018647826800588518 0.0001864782825578004
rl training, epoch3, iter0, batch639/1133, batch loss:0.0001864782825578004, Training time:50866.78912758827
batch reward last col mean 0.0006948439404368401 first col mean 0.00016510557907167822 all mean 0.0006036727572791278
0.00020857136405538768 0.0002085713786073029
rl training, epoch3, iter0, batch640/1133, batch loss:0.0002085713786073029, Training time:50884.703448057175
batch reward last col mean 0.006295615807175636 first col mean 0.0012356131337583065 all mean 0.006065138150006533
0.0002589067444205284 0.0002589067444205284
rl training, epoch3, iter0, batch641/1133, batch loss:0.0002589067444205284, Training time:50903.18367600441
batch reward last col mean 4.857047679251991e-05 first col mean 7.112409366527572e-05 all mean 0.00019403822079766542
0.00019254814833402634 0.00019254816288594157
rl training, epoch3, iter0, batch642/1133, batch loss:0.00019254816288594157, Training time:50920.11009812355
batch reward last col mean 0.000818280503153801 first col mean 0.0006544850766658783 all mean 0.0003337785310577601
0.00017032786854542792 0.00017032786854542792
rl training, epoch3, iter0, batch643/1133, batch loss:0.00017032786854542792, Training time:50937.15685200691
batch reward last col mean 0.0009652790613472462 first col mean 0.001712291268631816 all mean 0.000902252271771431
0.00014857100904919207 0.0001485710236011073
rl training, epoch3, iter0, batch644/1133, batch loss:0.0001485710236011073, Training time:50954.23551225662
batch reward last col mean 3.3103471650974825e-05 first col mean 5.901198528590612e-05 all mean 0.00012688613787759095
0.00014186647604219615 0.0001418665051460266
rl training, epoch3, iter0, batch645/1133, batch loss:0.0001418665051460266, Training time:50971.36128568649
batch reward last col mean 0.00756707601249218 first col mean 0.0016133824829012156 all mean 0.006938650738447905
0.00076627655653283 0.00076627655653283
rl training, epoch3, iter0, batch646/1133, batch loss:0.00076627655653283, Training time:50988.36711478233
batch reward last col mean 0.00024862776626832783 first col mean 0.00016692274948582053 all mean 0.00029439598438329995
0.00017067503358703107 0.00017067501903511584
rl training, epoch3, iter0, batch647/1133, batch loss:0.00017067501903511584, Training time:51005.691106796265
batch reward last col mean 4.331886430009035e-06 first col mean 0.0002226198703283444 all mean 0.00017221434973180294
0.0001856565213529393 0.0001856565213529393
rl training, epoch3, iter0, batch648/1133, batch loss:0.0001856565213529393, Training time:51022.78702902794
batch reward last col mean 8.82232484400447e-07 first col mean 0.000976107083261013 all mean 0.0001195142394863069
0.0001681666326476261 0.00016816661809571087
rl training, epoch3, iter0, batch649/1133, batch loss:0.00016816661809571087, Training time:51039.704337358475
batch reward last col mean 6.025341463100631e-06 first col mean 0.0008452774491161108 all mean 0.00016462014173157513
0.00023955968208611012 0.00023955968208611012
rl training, epoch3, iter0, batch650/1133, batch loss:0.00023955968208611012, Training time:51056.523710012436
batch reward last col mean 0.00012217309267725796 first col mean 0.00021983933402225375 all mean 0.00022937158064451069
0.00013381858298089355 0.00013381858298089355
rl training, epoch3, iter0, batch651/1133, batch loss:0.00013381858298089355, Training time:51073.38526725769
batch reward last col mean 0.0022489442490041256 first col mean 0.00013813705299980938 all mean 0.001550296088680625
0.0004890410345979035 0.0004890410928055644
rl training, epoch3, iter0, batch652/1133, batch loss:0.0004890410928055644, Training time:51090.1897110939
batch reward last col mean 0.0001037708279909566 first col mean 6.509420927613974e-05 all mean 0.00012863549636676908
0.00011603014718275517 0.00011603015445871279
rl training, epoch3, iter0, batch653/1133, batch loss:0.00011603015445871279, Training time:51107.5956492424
batch reward last col mean 0.007330683991312981 first col mean 0.00018233447917737067 all mean 0.004584800451993942
0.0006274421466514468 0.0006274421466514468
rl training, epoch3, iter0, batch654/1133, batch loss:0.0006274421466514468, Training time:51124.83897781372
batch reward last col mean 0.0002174435940105468 first col mean 0.00036027992609888315 all mean 0.00021004665177315474
0.0002487898455001414 0.0002487898455001414
rl training, epoch3, iter0, batch655/1133, batch loss:0.0002487898455001414, Training time:51142.34487462044
batch reward last col mean 8.294283179566264e-05 first col mean 0.0004491870931815356 all mean 0.00021392214694060385
0.00031899771420285106 0.00031899771420285106
rl training, epoch3, iter0, batch656/1133, batch loss:0.00031899771420285106, Training time:51160.993359327316
batch reward last col mean 0.004273831378668547 first col mean 0.0002041650441242382 all mean 0.004189050290733576
0.0003569078107830137 0.0003569078107830137
rl training, epoch3, iter0, batch657/1133, batch loss:0.0003569078107830137, Training time:51178.81948328018
batch reward last col mean 0.0002206863573519513 first col mean 0.0005348115810193121 all mean 0.0003941464819945395
0.0004681838327087462 0.00046818380360491574
rl training, epoch3, iter0, batch658/1133, batch loss:0.00046818380360491574, Training time:51196.06225562096
batch reward last col mean 2.8382475647958927e-05 first col mean 0.0014363056980073452 all mean 0.00030596909346058965
0.0002925936714746058 0.0002925936714746058
rl training, epoch3, iter0, batch659/1133, batch loss:0.0002925936714746058, Training time:51213.05649161339
batch reward last col mean 0.002477230504155159 first col mean 0.0001462290238123387 all mean 0.0016476101009175181
0.0007609326275996864 0.0007609326275996864
rl training, epoch3, iter0, batch660/1133, batch loss:0.0007609326275996864, Training time:51229.977610588074
batch reward last col mean 0.00010785502672661096 first col mean 0.0004653465293813497 all mean 0.00031515536829829216
0.0003140376356896013 0.00031403766479343176
rl training, epoch3, iter0, batch661/1133, batch loss:0.00031403766479343176, Training time:51247.10116434097
batch reward last col mean 5.6128741562133655e-05 first col mean 0.00040599520434625447 all mean 0.0005574116366915405
0.0009498593863099813 0.0009498593281023204
rl training, epoch3, iter0, batch662/1133, batch loss:0.0009498593281023204, Training time:51264.19956994057
batch reward last col mean 0.0018104042392224073 first col mean 7.655592344235629e-05 all mean 0.0007587121799588203
0.0007424051873385906 0.0007424051873385906
rl training, epoch3, iter0, batch663/1133, batch loss:0.0007424051873385906, Training time:51281.39343070984
batch reward last col mean 0.0003633291053120047 first col mean 0.002651657909154892 all mean 0.0005830680602230132
0.000678809592500329 0.0006788096507079899
rl training, epoch3, iter0, batch664/1133, batch loss:0.0006788096507079899, Training time:51298.51597094536
batch reward last col mean 0.0005516373203136027 first col mean 0.0014656573766842484 all mean 0.000641206162981689
0.0006175736198201776 0.0006175736198201776
rl training, epoch3, iter0, batch665/1133, batch loss:0.0006175736198201776, Training time:51315.469588041306
batch reward last col mean 0.0024000825360417366 first col mean 0.0005541605059988797 all mean 0.001680393354035914
0.000999458017759025 0.000999458017759025
rl training, epoch3, iter0, batch666/1133, batch loss:0.000999458017759025, Training time:51332.38409972191
batch reward last col mean 0.0005368442507460713 first col mean 0.0011784664820879698 all mean 0.0004779465380124748
0.0006336010410450399 0.000633600982837379
rl training, epoch3, iter0, batch667/1133, batch loss:0.000633600982837379, Training time:51349.168508291245
batch reward last col mean 0.006400917656719685 first col mean 0.0010305800242349505 all mean 0.006621227134019136
0.0014641783200204372 0.0014641783200204372
rl training, epoch3, iter0, batch668/1133, batch loss:0.0014641783200204372, Training time:51366.86782813072
batch reward last col mean 0.0014989927876740694 first col mean 0.0006662454688921571 all mean 0.001448027091100812
0.0010242878925055265 0.0010242881253361702
rl training, epoch3, iter0, batch669/1133, batch loss:0.0010242881253361702, Training time:51385.705686569214
batch reward last col mean 0.0012032700469717383 first col mean 0.0016622396651655436 all mean 0.00141627318225801
0.00199484103359282 0.00199484103359282
rl training, epoch3, iter0, batch670/1133, batch loss:0.00199484103359282, Training time:51404.63650083542
batch reward last col mean 0.0015424921875819564 first col mean 0.0005597892450168729 all mean 0.000689568230882287
0.0010059543419629335 0.0010059543419629335
rl training, epoch3, iter0, batch671/1133, batch loss:0.0010059543419629335, Training time:51423.36539149284
batch reward last col mean 0.000678235141094774 first col mean 0.0020844251848757267 all mean 0.0009592238930054009
0.0009293777984566987 0.0009293777984566987
rl training, epoch3, iter0, batch672/1133, batch loss:0.0009293777984566987, Training time:51442.137949705124
batch reward last col mean 0.0006780973635613918 first col mean 0.0017980416305363178 all mean 0.0008589169010519981
0.0009025732288137078 0.0009025732288137078
rl training, epoch3, iter0, batch673/1133, batch loss:0.0009025732288137078, Training time:51460.55282449722
batch reward last col mean 0.00010388292866991833 first col mean 0.0019831564277410507 all mean 0.0009082509204745293
0.001161170774139464 0.001161170774139464
rl training, epoch3, iter0, batch674/1133, batch loss:0.001161170774139464, Training time:51479.473064661026
batch reward last col mean 0.00031649216543883085 first col mean 0.0010811581742018461 all mean 0.0008447890286333859
0.0011092385975643992 0.0011092385975643992
rl training, epoch3, iter0, batch675/1133, batch loss:0.0011092385975643992, Training time:51496.71349024773
batch reward last col mean 0.0007575858617201447 first col mean 0.0006446263287216425 all mean 0.0009981351904571056
0.0011979601113125682 0.0011979599948972464
rl training, epoch3, iter0, batch676/1133, batch loss:0.0011979599948972464, Training time:51513.981642484665
batch reward last col mean 0.0002415459166513756 first col mean 0.0005642853793688118 all mean 0.0010861209593713284
0.0012183352373540401 0.0012183351209387183
rl training, epoch3, iter0, batch677/1133, batch loss:0.0012183351209387183, Training time:51531.15762042999
batch reward last col mean 0.001971614081412554 first col mean 0.002403693739324808 all mean 0.0026948789600282907
0.0015280286315828562 0.001528028747998178
rl training, epoch3, iter0, batch678/1133, batch loss:0.001528028747998178, Training time:51548.26171255112
batch reward last col mean 0.0016334204701706767 first col mean 0.0009460533037781715 all mean 0.000992050627246499
0.0008585664909332991 0.0008585663745179772
rl training, epoch3, iter0, batch679/1133, batch loss:0.0008585663745179772, Training time:51565.47957444191
batch reward last col mean 0.004085151478648186 first col mean 0.0005382690578699112 all mean 0.0040774052031338215
0.001655185129493475 0.001655185129493475
rl training, epoch3, iter0, batch680/1133, batch loss:0.001655185129493475, Training time:51582.611307144165
batch reward last col mean 0.0017276882426813245 first col mean 0.0005242795450612903 all mean 0.0014752200804650784
0.001626156852580607 0.001626156852580607
rl training, epoch3, iter0, batch681/1133, batch loss:0.001626156852580607, Training time:51599.744946956635
batch reward last col mean 0.0018392974743619561 first col mean 0.0034210840240120888 all mean 0.002208694815635681
0.00179172377102077 0.00179172377102077
rl training, epoch3, iter0, batch682/1133, batch loss:0.00179172377102077, Training time:51616.62667798996
batch reward last col mean 0.0016901151975616813 first col mean 0.000821405032183975 all mean 0.001074924715794623
0.0011712104314938188 0.0011712104314938188
rl training, epoch3, iter0, batch683/1133, batch loss:0.0011712104314938188, Training time:51635.66023015976
batch reward last col mean 0.0014699369203299284 first col mean 0.0016772946109995246 all mean 0.0021336046047508717
0.0021987336222082376 0.0021987336222082376
rl training, epoch3, iter0, batch684/1133, batch loss:0.0021987336222082376, Training time:51654.51837468147
batch reward last col mean 0.001004007295705378 first col mean 0.0006758857052773237 all mean 0.001150166499428451
0.001607570331543684 0.001607570331543684
rl training, epoch3, iter0, batch685/1133, batch loss:0.001607570331543684, Training time:51673.6183924675
batch reward last col mean 0.00073046243051067 first col mean 0.0010741680162027478 all mean 0.001409313757903874
0.0018593220738694072 0.0018593220738694072
rl training, epoch3, iter0, batch686/1133, batch loss:0.0018593220738694072, Training time:51690.9456551075
batch reward last col mean 0.0016408172668889165 first col mean 0.0019278741674497724 all mean 0.002010616008192301
0.0014224086189642549 0.0014224086189642549
rl training, epoch3, iter0, batch687/1133, batch loss:0.0014224086189642549, Training time:51708.271213293076
batch reward last col mean 0.00532066123560071 first col mean 0.0011341468198224902 all mean 0.002160543343052268
0.002205231925472617 0.002205231925472617
rl training, epoch3, iter0, batch688/1133, batch loss:0.002205231925472617, Training time:51725.58650970459
batch reward last col mean 0.0003025150508619845 first col mean 0.0020454232580959797 all mean 0.001169442432001233
0.0014679196756333113 0.0014679196756333113
rl training, epoch3, iter0, batch689/1133, batch loss:0.0014679196756333113, Training time:51742.92274141312
batch reward last col mean 0.003631759434938431 first col mean 0.0041086734272539616 all mean 0.0017889821901917458
0.0021539058070629835 0.0021539058070629835
rl training, epoch3, iter0, batch690/1133, batch loss:0.0021539058070629835, Training time:51760.22701191902
batch reward last col mean 0.003174956887960434 first col mean 0.0008006696007214487 all mean 0.0020655242260545492
0.001989897806197405 0.001989897806197405
rl training, epoch3, iter0, batch691/1133, batch loss:0.001989897806197405, Training time:51777.40328502655
batch reward last col mean 0.0017658615252003074 first col mean 0.001781689701601863 all mean 0.001336419489234686
0.0017161747673526406 0.0017161747673526406
rl training, epoch3, iter0, batch692/1133, batch loss:0.0017161747673526406, Training time:51794.575390815735
batch reward last col mean 0.001352172577753663 first col mean 0.0008088778704404831 all mean 0.0019458767492324114
0.0020010494627058506 0.0020010494627058506
rl training, epoch3, iter0, batch693/1133, batch loss:0.0020010494627058506, Training time:51811.79126906395
batch reward last col mean 0.006389620713889599 first col mean 0.0015941151650622487 all mean 0.004420124925673008
0.0018600223120301962 0.0018600223120301962
rl training, epoch3, iter0, batch694/1133, batch loss:0.0018600223120301962, Training time:51829.468287706375
batch reward last col mean 0.0004358357982710004 first col mean 0.00339373666793108 all mean 0.0013511162251234055
0.0018962161848321557 0.0018962163012474775
rl training, epoch3, iter0, batch695/1133, batch loss:0.0018962163012474775, Training time:51847.179763793945
batch reward last col mean 0.0014381957007572055 first col mean 0.005325620993971825 all mean 0.002396725583821535
0.0027270459104329348 0.0027270459104329348
rl training, epoch3, iter0, batch696/1133, batch loss:0.0027270459104329348, Training time:51864.34131073952
batch reward last col mean 0.013269903138279915 first col mean 0.004658214747905731 all mean 0.0068815117701888084
0.004186578094959259 0.004186578094959259
rl training, epoch3, iter0, batch697/1133, batch loss:0.004186578094959259, Training time:51881.45234584808
batch reward last col mean 0.002475009299814701 first col mean 0.002685778308659792 all mean 0.0028693703934550285
0.003404854563996196 0.003404855029657483
rl training, epoch3, iter0, batch698/1133, batch loss:0.003404855029657483, Training time:51898.50770831108
batch reward last col mean 0.005334577988833189 first col mean 0.0015439682174474 all mean 0.0024121992755681276
0.0025901326444000006 0.0025901326444000006
rl training, epoch3, iter0, batch699/1133, batch loss:0.0025901326444000006, Training time:51915.786209106445
batch reward last col mean 0.00035947313881479204 first col mean 0.00381341390311718 all mean 0.002258723136037588
0.003468233160674572 0.003468233160674572
rl training, epoch3, iter0, batch700/1133, batch loss:0.003468233160674572, Training time:51933.1811375618
batch reward last col mean 0.00328578008338809 first col mean 0.0048002395778894424 all mean 0.0034297804813832045
0.002224524039775133 0.002224524039775133
rl training, epoch3, iter0, batch701/1133, batch loss:0.002224524039775133, Training time:51950.56927227974
batch reward last col mean 0.0044245547614991665 first col mean 0.004447326064109802 all mean 0.0026505228597670794
0.003132095793262124 0.003132095793262124
rl training, epoch3, iter0, batch702/1133, batch loss:0.003132095793262124, Training time:51967.90265417099
batch reward last col mean 0.003256055526435375 first col mean 0.0020654997788369656 all mean 0.0027436637319624424
0.0035012292210012674 0.0035012292210012674
rl training, epoch3, iter0, batch703/1133, batch loss:0.0035012292210012674, Training time:51985.391996622086
batch reward last col mean 0.005890378728508949 first col mean 0.002312228549271822 all mean 0.004155568778514862
0.003045459045097232 0.003045459045097232
rl training, epoch3, iter0, batch704/1133, batch loss:0.003045459045097232, Training time:52002.526960134506
batch reward last col mean 0.0048407819122076035 first col mean 0.0057203685864806175 all mean 0.004450440872460604
0.003743288107216358 0.003743288107216358
rl training, epoch3, iter0, batch705/1133, batch loss:0.003743288107216358, Training time:52019.52219057083
batch reward last col mean 0.002690342953428626 first col mean 0.004221951588988304 all mean 0.0031539476476609707
0.004090315196663141 0.004090314731001854
rl training, epoch3, iter0, batch706/1133, batch loss:0.004090314731001854, Training time:52036.78665328026
batch reward last col mean 0.00516075873747468 first col mean 0.0045853895135223866 all mean 0.0036705622915178537
0.004393258597701788 0.004393258597701788
rl training, epoch3, iter0, batch707/1133, batch loss:0.004393258597701788, Training time:52054.11396622658
batch reward last col mean 0.0068673365749418736 first col mean 0.007316484581679106 all mean 0.005267827771604061
0.004790882579982281 0.004790882114320993
rl training, epoch3, iter0, batch708/1133, batch loss:0.004790882114320993, Training time:52071.31541442871
batch reward last col mean 0.0024550522211939096 first col mean 0.004715460818260908 all mean 0.003797549521550536
0.003307872684672475 0.003307872684672475
rl training, epoch3, iter0, batch709/1133, batch loss:0.003307872684672475, Training time:52088.53397321701
batch reward last col mean 0.00655275909230113 first col mean 0.006903494708240032 all mean 0.005046317353844643
0.00322501128539443 0.00322501128539443
rl training, epoch3, iter0, batch710/1133, batch loss:0.00322501128539443, Training time:52105.70223379135
batch reward last col mean 0.009346379898488522 first col mean 0.007051128428429365 all mean 0.009911922737956047
0.00487777404487133 0.00487777404487133
rl training, epoch3, iter0, batch711/1133, batch loss:0.00487777404487133, Training time:52122.83732533455
batch reward last col mean 0.004674052819609642 first col mean 0.005918709561228752 all mean 0.004730230197310448
0.004412992391735315 0.004412992857396603
rl training, epoch3, iter0, batch712/1133, batch loss:0.004412992857396603, Training time:52140.10148501396
batch reward last col mean 0.0018233092268928885 first col mean 0.006809618789702654 all mean 0.0042900098487734795
0.005191769916564226 0.005191769916564226
rl training, epoch3, iter0, batch713/1133, batch loss:0.005191769916564226, Training time:52157.534143686295
batch reward last col mean 0.008514161221683025 first col mean 0.004160385578870773 all mean 0.0076079354621469975
0.00406469264999032 0.00406469264999032
rl training, epoch3, iter0, batch714/1133, batch loss:0.00406469264999032, Training time:52175.03896164894
batch reward last col mean 0.012393455021083355 first col mean 0.0036398638039827347 all mean 0.007198644336313009
0.006383208092302084 0.006383208092302084
rl training, epoch3, iter0, batch715/1133, batch loss:0.006383208092302084, Training time:52192.43533754349
batch reward last col mean 0.0036222017370164394 first col mean 0.008706765249371529 all mean 0.004497457295656204
0.0061357938684523106 0.0061357938684523106
rl training, epoch3, iter0, batch716/1133, batch loss:0.0061357938684523106, Training time:52209.83256959915
batch reward last col mean 0.006598606705665588 first col mean 0.006719212047755718 all mean 0.0066912355832755566
0.007026765029877424 0.007026765029877424
rl training, epoch3, iter0, batch717/1133, batch loss:0.007026765029877424, Training time:52227.19750833511
batch reward last col mean 0.023947611451148987 first col mean 0.006739082746207714 all mean 0.010057498700916767
0.007011207286268473 0.007011205889284611
rl training, epoch3, iter0, batch718/1133, batch loss:0.007011205889284611, Training time:52244.564594745636
batch reward last col mean 0.013458909466862679 first col mean 0.006433099042624235 all mean 0.00857784878462553
0.007063576485961676 0.007063576951622963
rl training, epoch3, iter0, batch719/1133, batch loss:0.007063576951622963, Training time:52261.91752123833
batch reward last col mean 0.01568761095404625 first col mean 0.007057141046971083 all mean 0.009888356551527977
0.007268488872796297 0.007268488872796297
rl training, epoch3, iter0, batch720/1133, batch loss:0.007268488872796297, Training time:52279.27332305908
batch reward last col mean 0.015283345244824886 first col mean 0.0074700783006846905 all mean 0.010528413578867912
0.008679836057126522 0.008679836057126522
rl training, epoch3, iter0, batch721/1133, batch loss:0.008679836057126522, Training time:52296.610280036926
batch reward last col mean 0.009187662973999977 first col mean 0.007621104829013348 all mean 0.007216616068035364
0.008390219882130623 0.008390218950808048
rl training, epoch3, iter0, batch722/1133, batch loss:0.008390218950808048, Training time:52313.88696718216
batch reward last col mean 0.014125972054898739 first col mean 0.008215709589421749 all mean 0.01361737959086895
0.009914256632328033 0.009914256632328033
rl training, epoch3, iter0, batch723/1133, batch loss:0.009914256632328033, Training time:52331.33727669716
batch reward last col mean 0.0039299954660236835 first col mean 0.011663433164358139 all mean 0.0065873595885932446
0.008703448809683323 0.008703448809683323
rl training, epoch3, iter0, batch724/1133, batch loss:0.008703448809683323, Training time:52350.57908701897
batch reward last col mean 0.008752241730690002 first col mean 0.010365496389567852 all mean 0.010279868729412556
0.010843158699572086 0.010843158699572086
rl training, epoch3, iter0, batch725/1133, batch loss:0.010843158699572086, Training time:52368.06338810921
batch reward last col mean 0.018091294914484024 first col mean 0.01132642850279808 all mean 0.015427423641085625
0.01643524132668972 0.01643524318933487
rl training, epoch3, iter0, batch726/1133, batch loss:0.01643524318933487, Training time:52386.38582587242
batch reward last col mean 0.016975698992609978 first col mean 0.011029625311493874 all mean 0.014753611758351326
0.013304886408150196 0.013304886408150196
rl training, epoch3, iter0, batch727/1133, batch loss:0.013304886408150196, Training time:52405.71424865723
batch reward last col mean 0.02025713212788105 first col mean 0.01736326888203621 all mean 0.017466528341174126
0.0164736770093441 0.0164736770093441
rl training, epoch3, iter0, batch728/1133, batch loss:0.0164736770093441, Training time:52423.13818526268
batch reward last col mean 0.018938440829515457 first col mean 0.014932464808225632 all mean 0.017052944749593735
0.016082769259810448 0.016082769259810448
rl training, epoch3, iter0, batch729/1133, batch loss:0.016082769259810448, Training time:52440.40408563614
batch reward last col mean 0.009775913320481777 first col mean 0.015041329897940159 all mean 0.012805825099349022
0.012791815213859081 0.012791815213859081
rl training, epoch3, iter0, batch730/1133, batch loss:0.012791815213859081, Training time:52457.75189757347
batch reward last col mean 0.02857808582484722 first col mean 0.019947228953242302 all mean 0.02389955334365368
0.021952800452709198 0.021952800452709198
rl training, epoch3, iter0, batch731/1133, batch loss:0.021952800452709198, Training time:52475.370649814606
batch reward last col mean 0.025094272568821907 first col mean 0.024890759959816933 all mean 0.023984869942069054
0.02530115284025669 0.02530115284025669
rl training, epoch3, iter0, batch732/1133, batch loss:0.02530115284025669, Training time:52493.07411956787
batch reward last col mean 0.017829744145274162 first col mean 0.02352083846926689 all mean 0.020964808762073517
0.02585463970899582 0.02585463970899582
rl training, epoch3, iter0, batch733/1133, batch loss:0.02585463970899582, Training time:52510.57350754738
batch reward last col mean 0.02258162572979927 first col mean 0.026189621537923813 all mean 0.022916119545698166
0.020775096490979195 0.020775094628334045
rl training, epoch3, iter0, batch734/1133, batch loss:0.020775094628334045, Training time:52527.99791789055
batch reward last col mean 0.043934524059295654 first col mean 0.027411723509430885 all mean 0.03047015517950058
0.03207189962267876 0.03207189962267876
rl training, epoch3, iter0, batch735/1133, batch loss:0.03207189962267876, Training time:52545.184062957764
batch reward last col mean 0.03006106987595558 first col mean 0.03978259116411209 all mean 0.03507400304079056
0.0415889248251915 0.0415889248251915
rl training, epoch3, iter0, batch736/1133, batch loss:0.0415889248251915, Training time:52562.44552707672
batch reward last col mean 0.04667620360851288 first col mean 0.029364775866270065 all mean 0.04454607889056206
0.04038709029555321 0.04038709029555321
rl training, epoch3, iter0, batch737/1133, batch loss:0.04038709029555321, Training time:52579.87553238869
batch reward last col mean 0.04467492178082466 first col mean 0.030262578278779984 all mean 0.04055318608880043
0.041995901614427567 0.041995901614427567
rl training, epoch3, iter0, batch738/1133, batch loss:0.041995901614427567, Training time:52597.25072789192
batch reward last col mean 0.04713296517729759 first col mean 0.0453997440636158 all mean 0.047636572271585464
0.05784554407000542 0.05784554407000542
rl training, epoch3, iter0, batch739/1133, batch loss:0.05784554407000542, Training time:52614.61705446243
batch reward last col mean 0.053820013999938965 first col mean 0.06440694630146027 all mean 0.05774945765733719
0.08048124611377716 0.08048124611377716
rl training, epoch3, iter0, batch740/1133, batch loss:0.08048124611377716, Training time:52632.00232195854
batch reward last col mean 0.053925901651382446 first col mean 0.06598225980997086 all mean 0.06521735340356827
0.08560334146022797 0.08560334146022797
rl training, epoch3, iter0, batch741/1133, batch loss:0.08560334146022797, Training time:52649.79618048668
batch reward last col mean 0.08199168741703033 first col mean 0.08317220211029053 all mean 0.0842462033033371
0.10134483873844147 0.10134483128786087
rl training, epoch3, iter0, batch742/1133, batch loss:0.10134483128786087, Training time:52667.19942688942
batch reward last col mean 0.08064243197441101 first col mean 0.1136055737733841 all mean 0.09383385628461838
0.12372814863920212 0.12372816354036331
rl training, epoch3, iter0, batch743/1133, batch loss:0.12372816354036331, Training time:52684.823050022125
batch reward last col mean 0.11470641195774078 first col mean 0.11202042549848557 all mean 0.11184481531381607
0.13185037672519684 0.13185037672519684
rl training, epoch3, iter0, batch744/1133, batch loss:0.13185037672519684, Training time:52702.49327421188
batch reward last col mean 0.10830146819353104 first col mean 0.13125859200954437 all mean 0.10285253077745438
0.1385219544172287 0.1385219544172287
rl training, epoch3, iter0, batch745/1133, batch loss:0.1385219544172287, Training time:52720.076081991196
batch reward last col mean 0.12218603491783142 first col mean 0.13723886013031006 all mean 0.1317962408065796
0.1587141454219818 0.158714160323143
rl training, epoch3, iter0, batch746/1133, batch loss:0.158714160323143, Training time:52739.19817829132
batch reward last col mean 0.13076910376548767 first col mean 0.14633682370185852 all mean 0.1467558741569519
0.20384836196899414 0.20384836196899414
rl training, epoch3, iter0, batch747/1133, batch loss:0.20384836196899414, Training time:52759.10831403732
batch reward last col mean 0.18438562750816345 first col mean 0.18474380671977997 all mean 0.19162945449352264
0.23329156637191772 0.23329156637191772
rl training, epoch3, iter0, batch748/1133, batch loss:0.23329156637191772, Training time:52776.98752331734
batch reward last col mean 0.21541598439216614 first col mean 0.19434820115566254 all mean 0.20972278714179993
0.2584039568901062 0.2584039568901062
rl training, epoch3, iter0, batch749/1133, batch loss:0.2584039568901062, Training time:52794.83918595314
batch reward last col mean 0.2289266586303711 first col mean 0.21417546272277832 all mean 0.21724528074264526
0.2747840881347656 0.2747840881347656
rl training, epoch3, iter0, batch750/1133, batch loss:0.2747840881347656, Training time:52812.67012500763
batch reward last col mean 0.22621646523475647 first col mean 0.24861836433410645 all mean 0.22534310817718506
0.29180797934532166 0.29180794954299927
rl training, epoch3, iter0, batch751/1133, batch loss:0.29180794954299927, Training time:52830.58495950699
batch reward last col mean 0.18993911147117615 first col mean 0.2033349722623825 all mean 0.20517407357692719
0.2967721223831177 0.2967721223831177
rl training, epoch3, iter0, batch752/1133, batch loss:0.2967721223831177, Training time:52849.02535223961
batch reward last col mean 0.22774377465248108 first col mean 0.24388642609119415 all mean 0.2342987060546875
0.2792097330093384 0.2792097330093384
rl training, epoch3, iter0, batch753/1133, batch loss:0.2792097330093384, Training time:52866.78934454918
batch reward last col mean 0.21427594125270844 first col mean 0.234152153134346 all mean 0.2190977931022644
0.2932065725326538 0.2932065725326538
rl training, epoch3, iter0, batch754/1133, batch loss:0.2932065725326538, Training time:52884.44943380356
batch reward last col mean 0.2007012963294983 first col mean 0.23967352509498596 all mean 0.2130042314529419
0.3013675808906555 0.3013675808906555
rl training, epoch3, iter0, batch755/1133, batch loss:0.3013675808906555, Training time:52902.204870700836
batch reward last col mean 0.25082701444625854 first col mean 0.25534915924072266 all mean 0.2517291307449341
0.319240927696228 0.319240927696228
rl training, epoch3, iter0, batch756/1133, batch loss:0.319240927696228, Training time:52920.008138656616
batch reward last col mean 0.28662365674972534 first col mean 0.25347310304641724 all mean 0.27143970131874084
0.34887200593948364 0.34887200593948364
rl training, epoch3, iter0, batch757/1133, batch loss:0.34887200593948364, Training time:52937.6964840889
batch reward last col mean 0.2557395100593567 first col mean 0.25634703040122986 all mean 0.25610244274139404
0.3408619463443756 0.3408619463443756
rl training, epoch3, iter0, batch758/1133, batch loss:0.3408619463443756, Training time:52955.37769293785
batch reward last col mean 0.3345922529697418 first col mean 0.3122766613960266 all mean 0.33193907141685486
0.44794711470603943 0.44794711470603943
rl training, epoch3, iter0, batch759/1133, batch loss:0.44794711470603943, Training time:52973.0179233551
batch reward last col mean 0.2666255831718445 first col mean 0.2909555435180664 all mean 0.27523818612098694
0.37266045808792114 0.37266042828559875
rl training, epoch3, iter0, batch760/1133, batch loss:0.37266042828559875, Training time:52990.379314661026
batch reward last col mean 0.28330257534980774 first col mean 0.26055487990379333 all mean 0.2744416296482086
0.386058509349823 0.386058509349823
rl training, epoch3, iter0, batch761/1133, batch loss:0.386058509349823, Training time:53007.73607182503
batch reward last col mean 0.2352961003780365 first col mean 0.2556876540184021 all mean 0.24904131889343262
0.39316096901893616 0.39316096901893616
rl training, epoch3, iter0, batch762/1133, batch loss:0.39316096901893616, Training time:53025.34070277214
batch reward last col mean 0.32795464992523193 first col mean 0.32918286323547363 all mean 0.3195510506629944
0.4376237392425537 0.4376237988471985
rl training, epoch3, iter0, batch763/1133, batch loss:0.4376237988471985, Training time:53043.190514326096
batch reward last col mean 0.2791086435317993 first col mean 0.25347164273262024 all mean 0.2702840268611908
0.35710394382476807 0.3571038842201233
rl training, epoch3, iter0, batch764/1133, batch loss:0.3571038842201233, Training time:53060.93123245239
batch reward last col mean 0.2551380693912506 first col mean 0.26766401529312134 all mean 0.27159518003463745
0.4092605412006378 0.4092605412006378
rl training, epoch3, iter0, batch765/1133, batch loss:0.4092605412006378, Training time:53078.73219251633
batch reward last col mean 0.3164115250110626 first col mean 0.3031299114227295 all mean 0.31102851033210754
0.45303475856781006 0.45303475856781006
rl training, epoch3, iter0, batch766/1133, batch loss:0.45303475856781006, Training time:53096.213460445404
batch reward last col mean 0.3044048547744751 first col mean 0.2955092191696167 all mean 0.30594903230667114
0.4753921627998352 0.4753921627998352
rl training, epoch3, iter0, batch767/1133, batch loss:0.4753921627998352, Training time:53110.9424135685
batch reward last col mean 0.28849512338638306 first col mean 0.2647351026535034 all mean 0.2813108265399933
0.38881683349609375 0.38881683349609375
rl training, epoch3, iter0, batch768/1133, batch loss:0.38881683349609375, Training time:53125.91356778145
batch reward last col mean 0.2388264387845993 first col mean 0.24757632613182068 all mean 0.24466782808303833
0.36736005544662476 0.36736005544662476
rl training, epoch3, iter0, batch769/1133, batch loss:0.36736005544662476, Training time:53143.63680768013
batch reward last col mean 0.2288818657398224 first col mean 0.22550749778747559 all mean 0.23017171025276184
0.27063703536987305 0.27063703536987305
rl training, epoch3, iter0, batch770/1133, batch loss:0.27063703536987305, Training time:53161.22848892212
batch reward last col mean 0.22584407031536102 first col mean 0.23905032873153687 all mean 0.2253735065460205
0.24342131614685059 0.24342131614685059
rl training, epoch3, iter0, batch771/1133, batch loss:0.24342131614685059, Training time:53178.80079960823
batch reward last col mean 0.25953978300094604 first col mean 0.25445762276649475 all mean 0.25891655683517456
0.2832893133163452 0.2832893133163452
rl training, epoch3, iter0, batch772/1133, batch loss:0.2832893133163452, Training time:53196.41658616066
batch reward last col mean 0.2549786865711212 first col mean 0.22410598397254944 all mean 0.241738960146904
0.2652958035469055 0.26529577374458313
rl training, epoch3, iter0, batch773/1133, batch loss:0.26529577374458313, Training time:53215.71539521217
batch reward last col mean 0.2481534481048584 first col mean 0.22137314081192017 all mean 0.23788979649543762
0.2757139503955841 0.2757139503955841
rl training, epoch3, iter0, batch774/1133, batch loss:0.2757139503955841, Training time:53233.97874569893
batch reward last col mean 0.2656978368759155 first col mean 0.278110146522522 all mean 0.26930660009384155
0.3778885304927826 0.3778885304927826
rl training, epoch3, iter0, batch775/1133, batch loss:0.3778885304927826, Training time:53251.39890599251
batch reward last col mean 0.31803637742996216 first col mean 0.31030526757240295 all mean 0.31524503231048584
0.42390793561935425 0.42390793561935425
rl training, epoch3, iter0, batch776/1133, batch loss:0.42390793561935425, Training time:53267.68446683884
batch reward last col mean 0.35075944662094116 first col mean 0.32279670238494873 all mean 0.3483705222606659
0.4371821880340576 0.4371821880340576
rl training, epoch3, iter0, batch777/1133, batch loss:0.4371821880340576, Training time:53279.4160091877
batch reward last col mean 0.29835760593414307 first col mean 0.3043091297149658 all mean 0.2999899089336395
0.4652057886123657 0.4652057886123657
rl training, epoch3, iter0, batch778/1133, batch loss:0.4652057886123657, Training time:53288.34182739258
batch reward last col mean 0.30491262674331665 first col mean 0.2861331105232239 all mean 0.2948770523071289
0.42110177874565125 0.42110177874565125
rl training, epoch3, iter0, batch779/1133, batch loss:0.42110177874565125, Training time:53296.699973106384
batch reward last col mean 0.24565911293029785 first col mean 0.2750336527824402 all mean 0.25596821308135986
0.4531276226043701 0.4531276226043701
rl training, epoch3, iter0, batch780/1133, batch loss:0.4531276226043701, Training time:53305.29562282562
batch reward last col mean 0.31880438327789307 first col mean 0.32925617694854736 all mean 0.32250094413757324
0.556084930896759 0.556084930896759
rl training, epoch3, iter0, batch781/1133, batch loss:0.556084930896759, Training time:53311.65383410454
batch reward last col mean 0.28890618681907654 first col mean 0.2877846956253052 all mean 0.28462663292884827
0.4478105902671814 0.447810560464859
rl training, epoch3, iter0, batch782/1133, batch loss:0.447810560464859, Training time:53317.42286682129
batch reward last col mean 0.30215153098106384 first col mean 0.3072076439857483 all mean 0.30718156695365906
0.5459071397781372 0.5459071397781372
rl training, epoch3, iter0, batch783/1133, batch loss:0.5459071397781372, Training time:53324.47575736046
batch reward last col mean 0.3506205976009369 first col mean 0.34490102529525757 all mean 0.35073572397232056
0.6043108701705933 0.6043108701705933
rl training, epoch3, iter0, batch784/1133, batch loss:0.6043108701705933, Training time:53331.537965774536
batch reward last col mean 0.29313719272613525 first col mean 0.3210532069206238 all mean 0.2917633652687073
0.48815593123435974 0.48815593123435974
rl training, epoch3, iter0, batch785/1133, batch loss:0.48815593123435974, Training time:53338.65761256218
batch reward last col mean 0.289815217256546 first col mean 0.28261783719062805 all mean 0.28766176104545593
0.5145701169967651 0.5145701169967651
rl training, epoch3, iter0, batch786/1133, batch loss:0.5145701169967651, Training time:53347.020542383194
batch reward last col mean 0.3851478099822998 first col mean 0.35236549377441406 all mean 0.3763584792613983
0.618339478969574 0.618339478969574
rl training, epoch3, iter0, batch787/1133, batch loss:0.618339478969574, Training time:53355.173478126526
batch reward last col mean 0.3342013955116272 first col mean 0.33493342995643616 all mean 0.3331162929534912
0.5315154790878296 0.5315154790878296
rl training, epoch3, iter0, batch788/1133, batch loss:0.5315154790878296, Training time:53364.89398121834
batch reward last col mean 0.30977585911750793 first col mean 0.33016765117645264 all mean 0.31328800320625305
0.5830077528953552 0.5830077528953552
rl training, epoch3, iter0, batch789/1133, batch loss:0.5830077528953552, Training time:53373.292699337006
batch reward last col mean 0.37412571907043457 first col mean 0.35236191749572754 all mean 0.3731997609138489
0.6791440844535828 0.6791440844535828
rl training, epoch3, iter0, batch790/1133, batch loss:0.6791440844535828, Training time:53381.55705809593
batch reward last col mean 0.3371359705924988 first col mean 0.3583615720272064 all mean 0.33795788884162903
0.598115861415863 0.598115861415863
rl training, epoch3, iter0, batch791/1133, batch loss:0.598115861415863, Training time:53395.89041543007
batch reward last col mean 0.3470340669155121 first col mean 0.31507599353790283 all mean 0.3423886001110077
0.5365443229675293 0.5365443229675293
rl training, epoch3, iter0, batch792/1133, batch loss:0.5365443229675293, Training time:53405.48837828636
batch reward last col mean 0.3357042670249939 first col mean 0.3491663634777069 all mean 0.33894264698028564
0.6531977653503418 0.6531977653503418
rl training, epoch3, iter0, batch793/1133, batch loss:0.6531977653503418, Training time:53414.20330452919
batch reward last col mean 0.3573701083660126 first col mean 0.3513960838317871 all mean 0.3579794466495514
0.664383053779602 0.6643829345703125
rl training, epoch3, iter0, batch794/1133, batch loss:0.6643829345703125, Training time:53424.19130706787
batch reward last col mean 0.28194645047187805 first col mean 0.29948484897613525 all mean 0.2898412048816681
0.5391857624053955 0.5391857028007507
rl training, epoch3, iter0, batch795/1133, batch loss:0.5391857028007507, Training time:53432.34150147438
batch reward last col mean 0.40164339542388916 first col mean 0.36660680174827576 all mean 0.401537150144577
0.7656697630882263 0.7656696438789368
rl training, epoch3, iter0, batch796/1133, batch loss:0.7656696438789368, Training time:53441.84608411789
batch reward last col mean 0.3515181541442871 first col mean 0.34084391593933105 all mean 0.3500763773918152
0.5869763493537903 0.5869763493537903
rl training, epoch3, iter0, batch797/1133, batch loss:0.5869763493537903, Training time:53455.81731367111
batch reward last col mean 0.3974262475967407 first col mean 0.34966522455215454 all mean 0.3924506604671478
0.6672702431678772 0.6672702431678772
rl training, epoch3, iter0, batch798/1133, batch loss:0.6672702431678772, Training time:53466.787314891815
batch reward last col mean 0.3547408878803253 first col mean 0.3773932456970215 all mean 0.35832077264785767
0.6523390412330627 0.6523390412330627
rl training, epoch3, iter0, batch799/1133, batch loss:0.6523390412330627, Training time:53480.97410774231
batch reward last col mean 0.33348411321640015 first col mean 0.3707534074783325 all mean 0.33842527866363525
0.6346530914306641 0.6346530914306641
rl training, epoch3, iter0, batch800/1133, batch loss:0.6346530914306641, Training time:53491.25828719139
batch reward last col mean 0.3898884356021881 first col mean 0.3938218057155609 all mean 0.3931574523448944
0.8203539252281189 0.8203539252281189
rl training, epoch3, iter0, batch801/1133, batch loss:0.8203539252281189, Training time:53500.914083480835
batch reward last col mean 0.39594459533691406 first col mean 0.42470210790634155 all mean 0.40243980288505554
0.8855167031288147 0.8855167031288147
rl training, epoch3, iter0, batch802/1133, batch loss:0.8855167031288147, Training time:53517.16653418541
batch reward last col mean 0.41798868775367737 first col mean 0.38284528255462646 all mean 0.4143359959125519
0.7918088436126709 0.7918088436126709
rl training, epoch3, iter0, batch803/1133, batch loss:0.7918088436126709, Training time:53534.17883372307
batch reward last col mean 0.43005043268203735 first col mean 0.4313104450702667 all mean 0.43523120880126953
0.8377085328102112 0.8377085328102112
rl training, epoch3, iter0, batch804/1133, batch loss:0.8377085328102112, Training time:53551.962347984314
batch reward last col mean 0.40212559700012207 first col mean 0.4133281111717224 all mean 0.4160093367099762
0.7945138812065125 0.7945138812065125
rl training, epoch3, iter0, batch805/1133, batch loss:0.7945138812065125, Training time:53570.12589073181
batch reward last col mean 0.3871912658214569 first col mean 0.36350172758102417 all mean 0.3729707598686218
0.7423961758613586 0.7423961758613586
rl training, epoch3, iter0, batch806/1133, batch loss:0.7423961758613586, Training time:53588.15359544754
batch reward last col mean 0.3880891799926758 first col mean 0.4024354815483093 all mean 0.4018116891384125
0.8356291055679321 0.8356291055679321
rl training, epoch3, iter0, batch807/1133, batch loss:0.8356291055679321, Training time:53606.25849986076
batch reward last col mean 0.480243444442749 first col mean 0.4623132646083832 all mean 0.47663524746894836
0.9653944969177246 0.9653944969177246
rl training, epoch3, iter0, batch808/1133, batch loss:0.9653944969177246, Training time:53624.288201093674
batch reward last col mean 0.37236857414245605 first col mean 0.3783642053604126 all mean 0.38049471378326416
0.8073142170906067 0.8073142170906067
rl training, epoch3, iter0, batch809/1133, batch loss:0.8073142170906067, Training time:53643.16201734543
batch reward last col mean 0.3421595096588135 first col mean 0.3604801893234253 all mean 0.3586156964302063
0.7845288515090942 0.7845288515090942
rl training, epoch3, iter0, batch810/1133, batch loss:0.7845288515090942, Training time:53662.20498609543
batch reward last col mean 0.44048506021499634 first col mean 0.4048895835876465 all mean 0.43780356645584106
0.8408022522926331 0.8408022522926331
rl training, epoch3, iter0, batch811/1133, batch loss:0.8408022522926331, Training time:53680.150165081024
batch reward last col mean 0.4144826829433441 first col mean 0.3826005458831787 all mean 0.4107910692691803
0.8494277000427246 0.8494277000427246
rl training, epoch3, iter0, batch812/1133, batch loss:0.8494277000427246, Training time:53698.28493523598
batch reward last col mean 0.43489760160446167 first col mean 0.41622108221054077 all mean 0.4295977056026459
0.9558296203613281 0.9558295011520386
rl training, epoch3, iter0, batch813/1133, batch loss:0.9558295011520386, Training time:53716.59905552864
batch reward last col mean 0.43106016516685486 first col mean 0.38297778367996216 all mean 0.40972045063972473
0.8548529148101807 0.8548529148101807
rl training, epoch3, iter0, batch814/1133, batch loss:0.8548529148101807, Training time:53736.51404953003
batch reward last col mean 0.34827834367752075 first col mean 0.40058982372283936 all mean 0.36797770857810974
0.8538668751716614 0.8538668751716614
rl training, epoch3, iter0, batch815/1133, batch loss:0.8538668751716614, Training time:53756.094853401184
batch reward last col mean 0.33820581436157227 first col mean 0.39816901087760925 all mean 0.36643674969673157
0.8850744366645813 0.8850744366645813
rl training, epoch3, iter0, batch816/1133, batch loss:0.8850744366645813, Training time:53774.063547849655
batch reward last col mean 0.36790087819099426 first col mean 0.39730024337768555 all mean 0.3791351318359375
0.7888731360435486 0.7888731360435486
rl training, epoch3, iter0, batch817/1133, batch loss:0.7888731360435486, Training time:53793.477848529816
batch reward last col mean 0.3959733247756958 first col mean 0.39623188972473145 all mean 0.40361589193344116
0.8614601492881775 0.8614601492881775
rl training, epoch3, iter0, batch818/1133, batch loss:0.8614601492881775, Training time:53811.29617357254
batch reward last col mean 0.3551006019115448 first col mean 0.35959407687187195 all mean 0.36584043502807617
0.8428990840911865 0.8428990244865417
rl training, epoch3, iter0, batch819/1133, batch loss:0.8428990244865417, Training time:53829.17155981064
batch reward last col mean 0.3857307434082031 first col mean 0.36691856384277344 all mean 0.3890487849712372
0.8618608117103577 0.8618608117103577
rl training, epoch3, iter0, batch820/1133, batch loss:0.8618608117103577, Training time:53847.15412354469
batch reward last col mean 0.40081650018692017 first col mean 0.39322811365127563 all mean 0.3960474133491516
0.921000063419342 0.921000063419342
rl training, epoch3, iter0, batch821/1133, batch loss:0.921000063419342, Training time:53865.15752720833
batch reward last col mean 0.3090631067752838 first col mean 0.35550034046173096 all mean 0.33765363693237305
0.811251699924469 0.8112516403198242
rl training, epoch3, iter0, batch822/1133, batch loss:0.8112516403198242, Training time:53883.32020187378
batch reward last col mean 0.341524213552475 first col mean 0.37131792306900024 all mean 0.3590466380119324
0.7931029200553894 0.7931029200553894
rl training, epoch3, iter0, batch823/1133, batch loss:0.7931029200553894, Training time:53901.35670375824
batch reward last col mean 0.36112239956855774 first col mean 0.3907812833786011 all mean 0.3720042407512665
0.8048574924468994 0.8048574924468994
rl training, epoch3, iter0, batch824/1133, batch loss:0.8048574924468994, Training time:53919.1613843441
batch reward last col mean 0.3769316077232361 first col mean 0.4081825315952301 all mean 0.3990141749382019
0.8496994972229004 0.8496993780136108
rl training, epoch3, iter0, batch825/1133, batch loss:0.8496993780136108, Training time:53936.92932057381
batch reward last col mean 0.4011085331439972 first col mean 0.4483999013900757 all mean 0.418124258518219
0.862287163734436 0.8622872233390808
rl training, epoch3, iter0, batch826/1133, batch loss:0.8622872233390808, Training time:53955.0108897686
batch reward last col mean 0.3736238479614258 first col mean 0.4339272975921631 all mean 0.3921968936920166
0.7930849194526672 0.7930849194526672
rl training, epoch3, iter0, batch827/1133, batch loss:0.7930849194526672, Training time:53972.785943984985
batch reward last col mean 0.38247448205947876 first col mean 0.4177212119102478 all mean 0.40815630555152893
0.8272310495376587 0.8272310495376587
rl training, epoch3, iter0, batch828/1133, batch loss:0.8272310495376587, Training time:53990.63497519493
batch reward last col mean 0.39923104643821716 first col mean 0.43879878520965576 all mean 0.4232323467731476
0.8846994042396545 0.8846994042396545
rl training, epoch3, iter0, batch829/1133, batch loss:0.8846994042396545, Training time:54008.388372182846
batch reward last col mean 0.43021780252456665 first col mean 0.4596059024333954 all mean 0.4650755226612091
0.8830938339233398 0.8830938339233398
rl training, epoch3, iter0, batch830/1133, batch loss:0.8830938339233398, Training time:54025.84945368767
batch reward last col mean 0.4298320710659027 first col mean 0.4412926733493805 all mean 0.4392421245574951
0.8355617523193359 0.8355617523193359
rl training, epoch3, iter0, batch831/1133, batch loss:0.8355617523193359, Training time:54043.41610002518
batch reward last col mean 0.3908293843269348 first col mean 0.4331861138343811 all mean 0.4155774414539337
0.8192725777626038 0.8192725777626038
rl training, epoch3, iter0, batch832/1133, batch loss:0.8192725777626038, Training time:54060.8427093029
batch reward last col mean 0.4538447856903076 first col mean 0.43726861476898193 all mean 0.4632018804550171
0.8604350686073303 0.8604350686073303
rl training, epoch3, iter0, batch833/1133, batch loss:0.8604350686073303, Training time:54078.341480493546
batch reward last col mean 0.5182512998580933 first col mean 0.4889337122440338 all mean 0.515735387802124
0.9390771389007568 0.9390771389007568
rl training, epoch3, iter0, batch834/1133, batch loss:0.9390771389007568, Training time:54096.25931978226
batch reward last col mean 0.4660060703754425 first col mean 0.4624665379524231 all mean 0.4856266677379608
0.8838726878166199 0.8838726878166199
rl training, epoch3, iter0, batch835/1133, batch loss:0.8838726878166199, Training time:54114.049288749695
batch reward last col mean 0.47404322028160095 first col mean 0.47751063108444214 all mean 0.4951585829257965
0.8691407442092896 0.8691407442092896
rl training, epoch3, iter0, batch836/1133, batch loss:0.8691407442092896, Training time:54131.73667526245
batch reward last col mean 0.49936091899871826 first col mean 0.5282968878746033 all mean 0.5018649697303772
0.8849321603775024 0.8849321603775024
rl training, epoch3, iter0, batch837/1133, batch loss:0.8849321603775024, Training time:54149.63680243492
batch reward last col mean 0.48418664932250977 first col mean 0.5895918607711792 all mean 0.5444524884223938
0.9349337816238403 0.9349337816238403
rl training, epoch3, iter0, batch838/1133, batch loss:0.9349337816238403, Training time:54167.21250677109
batch reward last col mean 0.5494733452796936 first col mean 0.5626438856124878 all mean 0.548810601234436
0.932989776134491 0.932989776134491
rl training, epoch3, iter0, batch839/1133, batch loss:0.932989776134491, Training time:54184.87140536308
batch reward last col mean 0.544657826423645 first col mean 0.5581684708595276 all mean 0.5757153630256653
0.9339175224304199 0.9339175224304199
rl training, epoch3, iter0, batch840/1133, batch loss:0.9339175224304199, Training time:54202.20055055618
batch reward last col mean 0.5454750657081604 first col mean 0.6256990432739258 all mean 0.5793983340263367
0.9238719940185547 0.9238719940185547
rl training, epoch3, iter0, batch841/1133, batch loss:0.9238719940185547, Training time:54219.376368522644
batch reward last col mean 0.6393672227859497 first col mean 0.6330037713050842 all mean 0.6375402212142944
0.9976905584335327 0.9976904392242432
rl training, epoch3, iter0, batch842/1133, batch loss:0.9976904392242432, Training time:54236.71906232834
batch reward last col mean 0.6211174726486206 first col mean 0.6443092226982117 all mean 0.6349340677261353
0.9450604319572449 0.9450604319572449
rl training, epoch3, iter0, batch843/1133, batch loss:0.9450604319572449, Training time:54254.37459206581
batch reward last col mean 0.6125361919403076 first col mean 0.6253073215484619 all mean 0.6240941882133484
0.9405476450920105 0.9405476450920105
rl training, epoch3, iter0, batch844/1133, batch loss:0.9405476450920105, Training time:54273.27565217018
batch reward last col mean 0.6730051636695862 first col mean 0.6791611909866333 all mean 0.6551649570465088
0.996570348739624 0.996570348739624
rl training, epoch3, iter0, batch845/1133, batch loss:0.996570348739624, Training time:54290.420379161835
batch reward last col mean 0.5647661089897156 first col mean 0.6702313423156738 all mean 0.6244431734085083
0.9862304925918579 0.9862304925918579
rl training, epoch3, iter0, batch846/1133, batch loss:0.9862304925918579, Training time:54307.45274853706
batch reward last col mean 0.6485846042633057 first col mean 0.6812248229980469 all mean 0.6651149988174438
1.0082943439483643 1.0082943439483643
rl training, epoch3, iter0, batch847/1133, batch loss:1.0082943439483643, Training time:54324.39049935341
batch reward last col mean 0.6660339832305908 first col mean 0.6256049871444702 all mean 0.6495054364204407
0.9777495265007019 0.9777494668960571
rl training, epoch3, iter0, batch848/1133, batch loss:0.9777494668960571, Training time:54341.350028038025
batch reward last col mean 0.6423515677452087 first col mean 0.6608530282974243 all mean 0.6551245450973511
0.9893079996109009 0.9893079996109009
rl training, epoch3, iter0, batch849/1133, batch loss:0.9893079996109009, Training time:54358.15459680557
batch reward last col mean 0.6426864862442017 first col mean 0.6518773436546326 all mean 0.6610599160194397
0.9421126246452332 0.9421126246452332
rl training, epoch3, iter0, batch850/1133, batch loss:0.9421126246452332, Training time:54375.4828710556
batch reward last col mean 0.7013618350028992 first col mean 0.6417489051818848 all mean 0.669620156288147
0.9841993451118469 0.9841993451118469
rl training, epoch3, iter0, batch851/1133, batch loss:0.9841993451118469, Training time:54392.478451251984
batch reward last col mean 0.6467157602310181 first col mean 0.6718275547027588 all mean 0.6782420873641968
0.9449816346168518 0.9449816346168518
rl training, epoch3, iter0, batch852/1133, batch loss:0.9449816346168518, Training time:54409.23699116707
batch reward last col mean 0.6745546460151672 first col mean 0.5905696153640747 all mean 0.6174637675285339
0.8748791217803955 0.874879002571106
rl training, epoch3, iter0, batch853/1133, batch loss:0.874879002571106, Training time:54426.31512284279
batch reward last col mean 0.5976290702819824 first col mean 0.6437990069389343 all mean 0.6292048692703247
0.9428086876869202 0.9428086876869202
rl training, epoch3, iter0, batch854/1133, batch loss:0.9428086876869202, Training time:54445.18491077423
batch reward last col mean 0.6535832285881042 first col mean 0.6593527793884277 all mean 0.6732093691825867
1.0057913064956665 1.0057913064956665
rl training, epoch3, iter0, batch855/1133, batch loss:1.0057913064956665, Training time:54463.98120260239
batch reward last col mean 0.679179310798645 first col mean 0.7031551599502563 all mean 0.6911775469779968
1.0604979991912842 1.0604979991912842
rl training, epoch3, iter0, batch856/1133, batch loss:1.0604979991912842, Training time:54481.007269859314
batch reward last col mean 0.6153135895729065 first col mean 0.6649037599563599 all mean 0.6550353169441223
0.9702001214027405 0.9702001214027405
rl training, epoch3, iter0, batch857/1133, batch loss:0.9702001214027405, Training time:54498.04182291031
batch reward last col mean 0.6762751936912537 first col mean 0.6427651643753052 all mean 0.6379676461219788
0.9810351133346558 0.9810351133346558
rl training, epoch3, iter0, batch858/1133, batch loss:0.9810351133346558, Training time:54515.161282777786
batch reward last col mean 0.5773540139198303 first col mean 0.6810191869735718 all mean 0.6255048513412476
0.9912043213844299 0.9912043213844299
rl training, epoch3, iter0, batch859/1133, batch loss:0.9912043213844299, Training time:54532.1291179657
batch reward last col mean 0.6983287930488586 first col mean 0.6486219167709351 all mean 0.6759399175643921
1.0815651416778564 1.0815651416778564
rl training, epoch3, iter0, batch860/1133, batch loss:1.0815651416778564, Training time:54549.122401714325
batch reward last col mean 0.6435205340385437 first col mean 0.7028605937957764 all mean 0.6881590485572815
1.091212272644043 1.091212272644043
rl training, epoch3, iter0, batch861/1133, batch loss:1.091212272644043, Training time:54566.200291633606
batch reward last col mean 0.6460531949996948 first col mean 0.6643692255020142 all mean 0.6782279014587402
1.0958960056304932 1.0958960056304932
rl training, epoch3, iter0, batch862/1133, batch loss:1.0958960056304932, Training time:54583.159667015076
batch reward last col mean 0.690401017665863 first col mean 0.674072265625 all mean 0.6716465950012207
1.0838098526000977 1.0838098526000977
rl training, epoch3, iter0, batch863/1133, batch loss:1.0838098526000977, Training time:54600.16724395752
batch reward last col mean 0.6921619176864624 first col mean 0.7159825563430786 all mean 0.705177903175354
1.1346487998962402 1.1346487998962402
rl training, epoch3, iter0, batch864/1133, batch loss:1.1346487998962402, Training time:54616.91697025299
batch reward last col mean 0.637850821018219 first col mean 0.6852522492408752 all mean 0.6719704270362854
1.1027824878692627 1.1027824878692627
rl training, epoch3, iter0, batch865/1133, batch loss:1.1027824878692627, Training time:54633.70907688141
batch reward last col mean 0.6524054408073425 first col mean 0.6746154427528381 all mean 0.6603435277938843
1.0945173501968384 1.0945173501968384
rl training, epoch3, iter0, batch866/1133, batch loss:1.0945173501968384, Training time:54650.65968585014
batch reward last col mean 0.6397910714149475 first col mean 0.6608326435089111 all mean 0.6646676063537598
1.1049822568893433 1.1049822568893433
rl training, epoch3, iter0, batch867/1133, batch loss:1.1049822568893433, Training time:54667.60556721687
batch reward last col mean 0.6890971660614014 first col mean 0.6398906707763672 all mean 0.6698486804962158
1.0955439805984497 1.0955439805984497
rl training, epoch3, iter0, batch868/1133, batch loss:1.0955439805984497, Training time:54684.524668455124
batch reward last col mean 0.7013328075408936 first col mean 0.6772891283035278 all mean 0.6801162958145142
1.1148463487625122 1.1148463487625122
rl training, epoch3, iter0, batch869/1133, batch loss:1.1148463487625122, Training time:54701.47295331955
batch reward last col mean 0.6567225456237793 first col mean 0.6478333473205566 all mean 0.6627200245857239
1.064444661140442 1.064444661140442
rl training, epoch3, iter0, batch870/1133, batch loss:1.064444661140442, Training time:54718.440989494324
batch reward last col mean 0.6403213739395142 first col mean 0.6759988069534302 all mean 0.6509041786193848
1.0687906742095947 1.0687906742095947
rl training, epoch3, iter0, batch871/1133, batch loss:1.0687906742095947, Training time:54735.3805141449
batch reward last col mean 0.6619194149971008 first col mean 0.680633008480072 all mean 0.6828533411026001
1.0865980386734009 1.0865981578826904
rl training, epoch3, iter0, batch872/1133, batch loss:1.0865981578826904, Training time:54752.257083415985
batch reward last col mean 0.6906641721725464 first col mean 0.6926063299179077 all mean 0.6961024403572083
1.09258234500885 1.09258234500885
rl training, epoch3, iter0, batch873/1133, batch loss:1.09258234500885, Training time:54769.11355161667
batch reward last col mean 0.7056763768196106 first col mean 0.6836786270141602 all mean 0.6920546889305115
1.086051106452942 1.086051106452942
rl training, epoch3, iter0, batch874/1133, batch loss:1.086051106452942, Training time:54785.886009693146
batch reward last col mean 0.7365317940711975 first col mean 0.7442578077316284 all mean 0.7444456219673157
1.1257964372634888 1.1257964372634888
rl training, epoch3, iter0, batch875/1133, batch loss:1.1257964372634888, Training time:54802.56506586075
batch reward last col mean 0.7320882678031921 first col mean 0.7335330843925476 all mean 0.7280701994895935
1.0809725522994995 1.080972671508789
rl training, epoch3, iter0, batch876/1133, batch loss:1.080972671508789, Training time:54819.213733911514
batch reward last col mean 0.7368411421775818 first col mean 0.7521234750747681 all mean 0.7322419285774231
1.0347449779510498 1.0347449779510498
rl training, epoch3, iter0, batch877/1133, batch loss:1.0347449779510498, Training time:54836.42926669121
batch reward last col mean 0.7028801441192627 first col mean 0.737061083316803 all mean 0.7339951992034912
1.0235440731048584 1.0235440731048584
rl training, epoch3, iter0, batch878/1133, batch loss:1.0235440731048584, Training time:54853.35099649429
batch reward last col mean 0.6832394599914551 first col mean 0.7189321517944336 all mean 0.7086300849914551
0.9891906380653381 0.9891906976699829
rl training, epoch3, iter0, batch879/1133, batch loss:0.9891906976699829, Training time:54870.249527454376
batch reward last col mean 0.743150532245636 first col mean 0.7695033550262451 all mean 0.7497144937515259
1.0033395290374756 1.003339409828186
rl training, epoch3, iter0, batch880/1133, batch loss:1.003339409828186, Training time:54887.13207554817
batch reward last col mean 0.7859801650047302 first col mean 0.7564419507980347 all mean 0.7631632685661316
0.9880455732345581 0.9880455732345581
rl training, epoch3, iter0, batch881/1133, batch loss:0.9880455732345581, Training time:54903.857241392136
batch reward last col mean 0.7548689842224121 first col mean 0.7976102828979492 all mean 0.7850050330162048
0.9987427592277527 0.9987428188323975
rl training, epoch3, iter0, batch882/1133, batch loss:0.9987428188323975, Training time:54920.685141563416
batch reward last col mean 0.7689564824104309 first col mean 0.782191812992096 all mean 0.7689566612243652
0.9588096737861633 0.9588096737861633
rl training, epoch3, iter0, batch883/1133, batch loss:0.9588096737861633, Training time:54937.640816926956
batch reward last col mean 0.7632402181625366 first col mean 0.7528365254402161 all mean 0.7514722347259521
0.8723670244216919 0.8723670244216919
rl training, epoch3, iter0, batch884/1133, batch loss:0.8723670244216919, Training time:54955.78071761131
batch reward last col mean 0.7283419370651245 first col mean 0.774793267250061 all mean 0.7677130103111267
0.8515691161155701 0.8515691161155701
rl training, epoch3, iter0, batch885/1133, batch loss:0.8515691161155701, Training time:54974.3863093853
batch reward last col mean 0.7350027561187744 first col mean 0.7634878158569336 all mean 0.7657116055488586
0.8111105561256409 0.8111105561256409
rl training, epoch3, iter0, batch886/1133, batch loss:0.8111105561256409, Training time:54991.86865568161
batch reward last col mean 0.7821168303489685 first col mean 0.7777150869369507 all mean 0.792998194694519
0.8175200819969177 0.8175200819969177
rl training, epoch3, iter0, batch887/1133, batch loss:0.8175200819969177, Training time:55008.753168821335
batch reward last col mean 0.8089054822921753 first col mean 0.7907688617706299 all mean 0.7904981970787048
0.792259156703949 0.792259156703949
rl training, epoch3, iter0, batch888/1133, batch loss:0.792259156703949, Training time:55025.69767475128
batch reward last col mean 0.8199607729911804 first col mean 0.7998712658882141 all mean 0.7865884304046631
0.7215222120285034 0.7215222120285034
rl training, epoch3, iter0, batch889/1133, batch loss:0.7215222120285034, Training time:55042.4547522068
batch reward last col mean 0.775915265083313 first col mean 0.7792643308639526 all mean 0.7836962342262268
0.6869187951087952 0.6869189143180847
rl training, epoch3, iter0, batch890/1133, batch loss:0.6869189143180847, Training time:55060.96173930168
batch reward last col mean 0.8093860149383545 first col mean 0.8037306666374207 all mean 0.7973821759223938
0.6835964322090149 0.6835964322090149
rl training, epoch3, iter0, batch891/1133, batch loss:0.6835964322090149, Training time:55077.76744675636
batch reward last col mean 0.8092089891433716 first col mean 0.801982045173645 all mean 0.7989673018455505
0.6525002121925354 0.6525002121925354
rl training, epoch3, iter0, batch892/1133, batch loss:0.6525002121925354, Training time:55094.37820863724
batch reward last col mean 0.7836689949035645 first col mean 0.8276821374893188 all mean 0.8232229948043823
0.6375666856765747 0.6375666856765747
rl training, epoch3, iter0, batch893/1133, batch loss:0.6375666856765747, Training time:55111.47563910484
batch reward last col mean 0.7979968786239624 first col mean 0.8253514170646667 all mean 0.8214915990829468
0.6099482178688049 0.6099482178688049
rl training, epoch3, iter0, batch894/1133, batch loss:0.6099482178688049, Training time:55128.36759901047
batch reward last col mean 0.8277736902236938 first col mean 0.8370838165283203 all mean 0.8384522795677185
0.6186159253120422 0.6186158657073975
rl training, epoch3, iter0, batch895/1133, batch loss:0.6186158657073975, Training time:55145.11630344391
batch reward last col mean 0.8040449023246765 first col mean 0.7949901819229126 all mean 0.8155064582824707
0.5912676453590393 0.5912676453590393
rl training, epoch3, iter0, batch896/1133, batch loss:0.5912676453590393, Training time:55162.12161421776
batch reward last col mean 0.8574095368385315 first col mean 0.8407217264175415 all mean 0.8433386087417603
0.5934265851974487 0.5934265851974487
rl training, epoch3, iter0, batch897/1133, batch loss:0.5934265851974487, Training time:55180.79457950592
batch reward last col mean 0.8639295697212219 first col mean 0.8501487374305725 all mean 0.8439275026321411
0.5952697396278381 0.5952697396278381
rl training, epoch3, iter0, batch898/1133, batch loss:0.5952697396278381, Training time:55199.711591243744
batch reward last col mean 0.7994058132171631 first col mean 0.8545886278152466 all mean 0.8333295583724976
0.5546295642852783 0.5546295642852783
rl training, epoch3, iter0, batch899/1133, batch loss:0.5546295642852783, Training time:55216.64077997208
batch reward last col mean 0.8005859851837158 first col mean 0.8102269768714905 all mean 0.8034825325012207
0.5553327202796936 0.5553327202796936
rl training, epoch3, iter0, batch900/1133, batch loss:0.5553327202796936, Training time:55233.309589624405
batch reward last col mean 0.8267795443534851 first col mean 0.8648954629898071 all mean 0.8418623805046082
0.5550326108932495 0.5550326108932495
rl training, epoch3, iter0, batch901/1133, batch loss:0.5550326108932495, Training time:55250.1882352829
batch reward last col mean 0.8540553450584412 first col mean 0.8395729660987854 all mean 0.8271996974945068
0.5756734013557434 0.5756734013557434
rl training, epoch3, iter0, batch902/1133, batch loss:0.5756734013557434, Training time:55267.03120326996
batch reward last col mean 0.8016133308410645 first col mean 0.8307592272758484 all mean 0.8240953683853149
0.564241886138916 0.564241886138916
rl training, epoch3, iter0, batch903/1133, batch loss:0.564241886138916, Training time:55284.442786216736
batch reward last col mean 0.8017393350601196 first col mean 0.8342626094818115 all mean 0.818692147731781
0.5722208619117737 0.5722208619117737
rl training, epoch3, iter0, batch904/1133, batch loss:0.5722208619117737, Training time:55301.26008558273
batch reward last col mean 0.8611437678337097 first col mean 0.8611142635345459 all mean 0.8558884263038635
0.5849496722221375 0.5849496126174927
rl training, epoch3, iter0, batch905/1133, batch loss:0.5849496126174927, Training time:55318.03275561333
batch reward last col mean 0.7949110269546509 first col mean 0.8218560814857483 all mean 0.8161541223526001
0.5695989727973938 0.5695989727973938
rl training, epoch3, iter0, batch906/1133, batch loss:0.5695989727973938, Training time:55334.75734710693
batch reward last col mean 0.8387547731399536 first col mean 0.828312337398529 all mean 0.8302749991416931
0.5687516927719116 0.5687516927719116
rl training, epoch3, iter0, batch907/1133, batch loss:0.5687516927719116, Training time:55351.5329041481
batch reward last col mean 0.8058555126190186 first col mean 0.8226113319396973 all mean 0.8197612762451172
0.5467577576637268 0.5467577576637268
rl training, epoch3, iter0, batch908/1133, batch loss:0.5467577576637268, Training time:55369.351242780685
batch reward last col mean 0.8633089065551758 first col mean 0.8526982069015503 all mean 0.8345407843589783
0.580743670463562 0.580743670463562
rl training, epoch3, iter0, batch909/1133, batch loss:0.580743670463562, Training time:55386.18630981445
batch reward last col mean 0.8146717548370361 first col mean 0.8446515798568726 all mean 0.8314319849014282
0.5610836744308472 0.5610836148262024
rl training, epoch3, iter0, batch910/1133, batch loss:0.5610836148262024, Training time:55404.732338666916
batch reward last col mean 0.842399537563324 first col mean 0.8468555808067322 all mean 0.8408545255661011
0.5571736693382263 0.5571736097335815
rl training, epoch3, iter0, batch911/1133, batch loss:0.5571736097335815, Training time:55422.425706624985
batch reward last col mean 0.8509386777877808 first col mean 0.8624447584152222 all mean 0.8493489027023315
0.5669556260108948 0.56695556640625
rl training, epoch3, iter0, batch912/1133, batch loss:0.56695556640625, Training time:55439.33560061455
batch reward last col mean 0.8272747993469238 first col mean 0.8452227115631104 all mean 0.8458914756774902
0.5521411299705505 0.5521411299705505
rl training, epoch3, iter0, batch913/1133, batch loss:0.5521411299705505, Training time:55456.42199087143
batch reward last col mean 0.8406089544296265 first col mean 0.8454234600067139 all mean 0.8217013478279114
0.5210680365562439 0.5210680365562439
rl training, epoch3, iter0, batch914/1133, batch loss:0.5210680365562439, Training time:55474.749472379684
batch reward last col mean 0.8509534597396851 first col mean 0.8195611238479614 all mean 0.8147172331809998
0.514924943447113 0.514924943447113
rl training, epoch3, iter0, batch915/1133, batch loss:0.514924943447113, Training time:55491.57248735428
batch reward last col mean 0.883693516254425 first col mean 0.8819549083709717 all mean 0.8686073422431946
0.5461609363555908 0.5461609363555908
rl training, epoch3, iter0, batch916/1133, batch loss:0.5461609363555908, Training time:55508.33095264435
batch reward last col mean 0.8224914073944092 first col mean 0.8020039796829224 all mean 0.8261702060699463
0.5197312235832214 0.5197312235832214
rl training, epoch3, iter0, batch917/1133, batch loss:0.5197312235832214, Training time:55525.00839519501
batch reward last col mean 0.8462619185447693 first col mean 0.8446989059448242 all mean 0.8477514982223511
0.5356931686401367 0.5356931686401367
rl training, epoch3, iter0, batch918/1133, batch loss:0.5356931686401367, Training time:55541.869388103485
batch reward last col mean 0.7952587604522705 first col mean 0.8357677459716797 all mean 0.817689836025238
0.5209871530532837 0.5209871530532837
rl training, epoch3, iter0, batch919/1133, batch loss:0.5209871530532837, Training time:55558.35230302811
batch reward last col mean 0.7976649403572083 first col mean 0.8484708070755005 all mean 0.8277608156204224
0.5809350609779358 0.5809350609779358
rl training, epoch3, iter0, batch920/1133, batch loss:0.5809350609779358, Training time:55575.33622932434
batch reward last col mean 0.8499540090560913 first col mean 0.8587465882301331 all mean 0.8465739488601685
0.585462212562561 0.5854621529579163
rl training, epoch3, iter0, batch921/1133, batch loss:0.5854621529579163, Training time:55592.89973282814
batch reward last col mean 0.8582921624183655 first col mean 0.860226035118103 all mean 0.8620139360427856
0.6138314604759216 0.6138314604759216
rl training, epoch3, iter0, batch922/1133, batch loss:0.6138314604759216, Training time:55610.394423246384
batch reward last col mean 0.8647674918174744 first col mean 0.8253340125083923 all mean 0.836641252040863
0.5970462560653687 0.5970462560653687
rl training, epoch3, iter0, batch923/1133, batch loss:0.5970462560653687, Training time:55628.36856365204
batch reward last col mean 0.8396322727203369 first col mean 0.8169263601303101 all mean 0.8160669207572937
0.622858464717865 0.622858464717865
rl training, epoch3, iter0, batch924/1133, batch loss:0.622858464717865, Training time:55647.117998600006
batch reward last col mean 0.8002009391784668 first col mean 0.8292268514633179 all mean 0.8230116963386536
0.6433567404747009 0.6433566808700562
rl training, epoch3, iter0, batch925/1133, batch loss:0.6433566808700562, Training time:55664.401332616806
batch reward last col mean 0.8217864036560059 first col mean 0.815999448299408 all mean 0.8210197687149048
0.6393479108810425 0.6393479108810425
rl training, epoch3, iter0, batch926/1133, batch loss:0.6393479108810425, Training time:55683.075949668884
batch reward last col mean 0.8385483622550964 first col mean 0.8084919452667236 all mean 0.8232651352882385
0.6618379354476929 0.6618379354476929
rl training, epoch3, iter0, batch927/1133, batch loss:0.6618379354476929, Training time:55700.57902979851
batch reward last col mean 0.7970973253250122 first col mean 0.7984874248504639 all mean 0.8059008121490479
0.6549186706542969 0.6549186706542969
rl training, epoch3, iter0, batch928/1133, batch loss:0.6549186706542969, Training time:55719.61640572548
batch reward last col mean 0.8504177331924438 first col mean 0.829852283000946 all mean 0.8242307901382446
0.6497004628181458 0.6497004628181458
rl training, epoch3, iter0, batch929/1133, batch loss:0.6497004628181458, Training time:55738.48465824127
batch reward last col mean 0.8319835662841797 first col mean 0.8153596520423889 all mean 0.8266183137893677
0.6602432131767273 0.6602432131767273
rl training, epoch3, iter0, batch930/1133, batch loss:0.6602432131767273, Training time:55757.72988963127
batch reward last col mean 0.8300144672393799 first col mean 0.83365398645401 all mean 0.8243235349655151
0.6553125977516174 0.6553125977516174
rl training, epoch3, iter0, batch931/1133, batch loss:0.6553125977516174, Training time:55775.700279951096
batch reward last col mean 0.80149245262146 first col mean 0.8116790056228638 all mean 0.8194037675857544
0.6019048690795898 0.6019048690795898
rl training, epoch3, iter0, batch932/1133, batch loss:0.6019048690795898, Training time:55792.33779549599
batch reward last col mean 0.8272266387939453 first col mean 0.833184540271759 all mean 0.835438072681427
0.6202815771102905 0.6202815771102905
rl training, epoch3, iter0, batch933/1133, batch loss:0.6202815771102905, Training time:55809.25627064705
batch reward last col mean 0.8321410417556763 first col mean 0.8277732133865356 all mean 0.8304774165153503
0.560899019241333 0.560899019241333
rl training, epoch3, iter0, batch934/1133, batch loss:0.560899019241333, Training time:55826.05187535286
batch reward last col mean 0.8014665246009827 first col mean 0.8172149658203125 all mean 0.8179423809051514
0.5764668583869934 0.5764668583869934
rl training, epoch3, iter0, batch935/1133, batch loss:0.5764668583869934, Training time:55842.8536593914
batch reward last col mean 0.826106071472168 first col mean 0.8689582347869873 all mean 0.83945631980896
0.5767711400985718 0.5767711400985718
rl training, epoch3, iter0, batch936/1133, batch loss:0.5767711400985718, Training time:55859.53725814819
batch reward last col mean 0.8238890171051025 first col mean 0.8159496188163757 all mean 0.8091268539428711
0.5167243480682373 0.5167243480682373
rl training, epoch3, iter0, batch937/1133, batch loss:0.5167243480682373, Training time:55876.88854885101
batch reward last col mean 0.8511307835578918 first col mean 0.8486442565917969 all mean 0.8501788973808289
0.5747620463371277 0.5747620463371277
rl training, epoch3, iter0, batch938/1133, batch loss:0.5747620463371277, Training time:55894.2719950676
batch reward last col mean 0.8384991884231567 first col mean 0.832460880279541 all mean 0.8310244679450989
0.5420929193496704 0.5420929193496704
rl training, epoch3, iter0, batch939/1133, batch loss:0.5420929193496704, Training time:55912.12030029297
batch reward last col mean 0.8281840682029724 first col mean 0.8270130157470703 all mean 0.8313243985176086
0.5333711504936218 0.5333711504936218
rl training, epoch3, iter0, batch940/1133, batch loss:0.5333711504936218, Training time:55930.872665166855
batch reward last col mean 0.8213413953781128 first col mean 0.8052831292152405 all mean 0.8233034014701843
0.5128363966941833 0.5128363966941833
rl training, epoch3, iter0, batch941/1133, batch loss:0.5128363966941833, Training time:55950.13259243965
batch reward last col mean 0.8547868728637695 first col mean 0.8499699831008911 all mean 0.8480119109153748
0.5267990827560425 0.5267990827560425
rl training, epoch3, iter0, batch942/1133, batch loss:0.5267990827560425, Training time:55968.58689045906
batch reward last col mean 0.897855818271637 first col mean 0.867561936378479 all mean 0.8632599711418152
0.5402590036392212 0.5402590036392212
rl training, epoch3, iter0, batch943/1133, batch loss:0.5402590036392212, Training time:55986.81939268112
batch reward last col mean 0.8682622909545898 first col mean 0.8842238783836365 all mean 0.8798202276229858
0.5314787030220032 0.5314787030220032
rl training, epoch3, iter0, batch944/1133, batch loss:0.5314787030220032, Training time:56005.861277103424
batch reward last col mean 0.8432813882827759 first col mean 0.8694478869438171 all mean 0.8574848175048828
0.5197641253471375 0.5197641253471375
rl training, epoch3, iter0, batch945/1133, batch loss:0.5197641253471375, Training time:56024.09723210335
batch reward last col mean 0.8201635479927063 first col mean 0.8302560448646545 all mean 0.838100254535675
0.507679283618927 0.507679283618927
rl training, epoch3, iter0, batch946/1133, batch loss:0.507679283618927, Training time:56042.83478116989
batch reward last col mean 0.8096044063568115 first col mean 0.8244811296463013 all mean 0.7951427698135376
0.4686576724052429 0.4686576724052429
rl training, epoch3, iter0, batch947/1133, batch loss:0.4686576724052429, Training time:56059.6145927906
batch reward last col mean 0.8653984665870667 first col mean 0.8783653974533081 all mean 0.8675557971000671
0.5244575142860413 0.5244575142860413
rl training, epoch3, iter0, batch948/1133, batch loss:0.5244575142860413, Training time:56076.568502664566
batch reward last col mean 0.8457822799682617 first col mean 0.8458423614501953 all mean 0.8293173313140869
0.4850536286830902 0.4850535988807678
rl training, epoch3, iter0, batch949/1133, batch loss:0.4850535988807678, Training time:56093.62209534645
batch reward last col mean 0.8461160063743591 first col mean 0.8508814573287964 all mean 0.8547685146331787
0.49285972118377686 0.49285969138145447
rl training, epoch3, iter0, batch950/1133, batch loss:0.49285969138145447, Training time:56110.65108585358
batch reward last col mean 0.8497478365898132 first col mean 0.8356447219848633 all mean 0.830909788608551
0.5044944882392883 0.5044944882392883
rl training, epoch3, iter0, batch951/1133, batch loss:0.5044944882392883, Training time:56127.62165808678
batch reward last col mean 0.8170754909515381 first col mean 0.8227875232696533 all mean 0.827020525932312
0.4650122821331024 0.4650123417377472
rl training, epoch3, iter0, batch952/1133, batch loss:0.4650123417377472, Training time:56144.67188477516
batch reward last col mean 0.8832053542137146 first col mean 0.8489973545074463 all mean 0.8512025475502014
0.4786186218261719 0.4786186218261719
rl training, epoch3, iter0, batch953/1133, batch loss:0.4786186218261719, Training time:56161.571977853775
batch reward last col mean 0.8605597019195557 first col mean 0.8419373035430908 all mean 0.8475475311279297
0.49801942706108093 0.49801939725875854
rl training, epoch3, iter0, batch954/1133, batch loss:0.49801939725875854, Training time:56178.41414093971
batch reward last col mean 0.8445849418640137 first col mean 0.8662936091423035 all mean 0.8462193012237549
0.483763724565506 0.4837636947631836
rl training, epoch3, iter0, batch955/1133, batch loss:0.4837636947631836, Training time:56195.20235157013
batch reward last col mean 0.8771325945854187 first col mean 0.8621307015419006 all mean 0.8568941354751587
0.49465233087539673 0.49465233087539673
rl training, epoch3, iter0, batch956/1133, batch loss:0.49465233087539673, Training time:56212.09147357941
batch reward last col mean 0.8570631742477417 first col mean 0.8714607954025269 all mean 0.8588908910751343
0.49446728825569153 0.49446728825569153
rl training, epoch3, iter0, batch957/1133, batch loss:0.49446728825569153, Training time:56228.97355723381
batch reward last col mean 0.8217585682868958 first col mean 0.8622567057609558 all mean 0.8494964241981506
0.5045847296714783 0.5045847296714783
rl training, epoch3, iter0, batch958/1133, batch loss:0.5045847296714783, Training time:56245.856224536896
batch reward last col mean 0.8829326033592224 first col mean 0.8578820824623108 all mean 0.8452855944633484
0.5033838152885437 0.5033838152885437
rl training, epoch3, iter0, batch959/1133, batch loss:0.5033838152885437, Training time:56262.696066856384
batch reward last col mean 0.8850404024124146 first col mean 0.8712378740310669 all mean 0.8817912340164185
0.5320382714271545 0.5320382714271545
rl training, epoch3, iter0, batch960/1133, batch loss:0.5320382714271545, Training time:56279.41690683365
batch reward last col mean 0.8696986436843872 first col mean 0.853998064994812 all mean 0.8492702841758728
0.5071008205413818 0.5071008205413818
rl training, epoch3, iter0, batch961/1133, batch loss:0.5071008205413818, Training time:56296.180362463
batch reward last col mean 0.8790594935417175 first col mean 0.8715014457702637 all mean 0.8704005479812622
0.49090376496315 0.49090376496315
rl training, epoch3, iter0, batch962/1133, batch loss:0.49090376496315, Training time:56313.053151369095
batch reward last col mean 0.8402215242385864 first col mean 0.8563907742500305 all mean 0.8579978346824646
0.5076133012771606 0.5076133012771606
rl training, epoch3, iter0, batch963/1133, batch loss:0.5076133012771606, Training time:56329.93751001358
batch reward last col mean 0.8922046422958374 first col mean 0.8646069169044495 all mean 0.8802767395973206
0.5195802450180054 0.5195802450180054
rl training, epoch3, iter0, batch964/1133, batch loss:0.5195802450180054, Training time:56346.96144747734
batch reward last col mean 0.8944687843322754 first col mean 0.8566662669181824 all mean 0.8645885586738586
0.5058854222297668 0.5058854222297668
rl training, epoch3, iter0, batch965/1133, batch loss:0.5058854222297668, Training time:56363.847026109695
batch reward last col mean 0.8781236410140991 first col mean 0.8620621562004089 all mean 0.8656914234161377
0.4995620548725128 0.4995620548725128
rl training, epoch3, iter0, batch966/1133, batch loss:0.4995620548725128, Training time:56380.688802957535
batch reward last col mean 0.8970638513565063 first col mean 0.8996703624725342 all mean 0.9005247354507446
0.5271082520484924 0.5271082520484924
rl training, epoch3, iter0, batch967/1133, batch loss:0.5271082520484924, Training time:56397.629457235336
batch reward last col mean 0.8813121914863586 first col mean 0.862670361995697 all mean 0.8723224401473999
0.5334038734436035 0.5334038734436035
rl training, epoch3, iter0, batch968/1133, batch loss:0.5334038734436035, Training time:56414.61749172211
batch reward last col mean 0.8953900337219238 first col mean 0.8727445602416992 all mean 0.883058488368988
0.5196709036827087 0.519670844078064
rl training, epoch3, iter0, batch969/1133, batch loss:0.519670844078064, Training time:56431.67569255829
batch reward last col mean 0.907534658908844 first col mean 0.8759949207305908 all mean 0.8834960460662842
0.516140341758728 0.516140341758728
rl training, epoch3, iter0, batch970/1133, batch loss:0.516140341758728, Training time:56448.62995862961
batch reward last col mean 0.8789015412330627 first col mean 0.8988733291625977 all mean 0.8943936228752136
0.5143569111824036 0.5143568515777588
rl training, epoch3, iter0, batch971/1133, batch loss:0.5143568515777588, Training time:56465.58622980118
batch reward last col mean 0.8612053394317627 first col mean 0.8800413608551025 all mean 0.870818018913269
0.5124707818031311 0.5124707818031311
rl training, epoch3, iter0, batch972/1133, batch loss:0.5124707818031311, Training time:56482.597009181976
batch reward last col mean 0.8333703279495239 first col mean 0.8777855634689331 all mean 0.8592039346694946
0.5139852166175842 0.5139852166175842
rl training, epoch3, iter0, batch973/1133, batch loss:0.5139852166175842, Training time:56499.535054922104
batch reward last col mean 0.8708993196487427 first col mean 0.8911092281341553 all mean 0.8834977746009827
0.5155348181724548 0.5155348181724548
rl training, epoch3, iter0, batch974/1133, batch loss:0.5155348181724548, Training time:56516.40819001198
batch reward last col mean 0.8939515352249146 first col mean 0.9044703841209412 all mean 0.8982647061347961
0.540149986743927 0.540149986743927
rl training, epoch3, iter0, batch975/1133, batch loss:0.540149986743927, Training time:56533.21140170097
batch reward last col mean 0.8861520290374756 first col mean 0.875443160533905 all mean 0.8840079307556152
0.5275619029998779 0.5275618433952332
rl training, epoch3, iter0, batch976/1133, batch loss:0.5275618433952332, Training time:56549.93071579933
batch reward last col mean 0.9199666976928711 first col mean 0.894055962562561 all mean 0.8880367279052734
0.5024000406265259 0.5024000406265259
rl training, epoch3, iter0, batch977/1133, batch loss:0.5024000406265259, Training time:56566.78197455406
batch reward last col mean 0.9199717044830322 first col mean 0.9141685962677002 all mean 0.9122641086578369
0.5337510704994202 0.5337510108947754
rl training, epoch3, iter0, batch978/1133, batch loss:0.5337510108947754, Training time:56583.67427325249
batch reward last col mean 0.9088607430458069 first col mean 0.8946114778518677 all mean 0.8941071033477783
0.5106977224349976 0.5106977224349976
rl training, epoch3, iter0, batch979/1133, batch loss:0.5106977224349976, Training time:56600.6429002285
batch reward last col mean 0.9064574241638184 first col mean 0.8835453391075134 all mean 0.8841226696968079
0.5281999111175537 0.5281999111175537
rl training, epoch3, iter0, batch980/1133, batch loss:0.5281999111175537, Training time:56617.489832639694
batch reward last col mean 0.8794596195220947 first col mean 0.8825172781944275 all mean 0.8865969181060791
0.5537751317024231 0.5537751317024231
rl training, epoch3, iter0, batch981/1133, batch loss:0.5537751317024231, Training time:56634.33787870407
batch reward last col mean 0.9037125706672668 first col mean 0.8980551958084106 all mean 0.9108847975730896
0.5809349417686462 0.5809349417686462
rl training, epoch3, iter0, batch982/1133, batch loss:0.5809349417686462, Training time:56651.17698740959
batch reward last col mean 0.9206347465515137 first col mean 0.9141342639923096 all mean 0.9037275314331055
0.5790531635284424 0.5790531635284424
rl training, epoch3, iter0, batch983/1133, batch loss:0.5790531635284424, Training time:56668.09786295891
batch reward last col mean 0.8956628441810608 first col mean 0.9119256734848022 all mean 0.906629204750061
0.5697949528694153 0.5697950124740601
rl training, epoch3, iter0, batch984/1133, batch loss:0.5697950124740601, Training time:56684.991547584534
batch reward last col mean 0.9515986442565918 first col mean 0.9296063780784607 all mean 0.9302830696105957
0.5674206018447876 0.5674206018447876
rl training, epoch3, iter0, batch985/1133, batch loss:0.5674206018447876, Training time:56701.907240867615
batch reward last col mean 0.9192380309104919 first col mean 0.9199306964874268 all mean 0.921750545501709
0.5778658986091614 0.5778658986091614
rl training, epoch3, iter0, batch986/1133, batch loss:0.5778658986091614, Training time:56718.85272717476
batch reward last col mean 0.9105222225189209 first col mean 0.9437982439994812 all mean 0.936270534992218
0.5702338814735413 0.5702338814735413
rl training, epoch3, iter0, batch987/1133, batch loss:0.5702338814735413, Training time:56735.67776584625
batch reward last col mean 0.9264938831329346 first col mean 0.9243947267532349 all mean 0.9189261794090271
0.5721532106399536 0.5721532106399536
rl training, epoch3, iter0, batch988/1133, batch loss:0.5721532106399536, Training time:56752.65247583389
batch reward last col mean 0.9372135996818542 first col mean 0.9480268359184265 all mean 0.9376330971717834
0.5671401619911194 0.5671401023864746
rl training, epoch3, iter0, batch989/1133, batch loss:0.5671401023864746, Training time:56769.66877102852
batch reward last col mean 0.9202507138252258 first col mean 0.930359423160553 all mean 0.9320812821388245
0.5288959741592407 0.5288959741592407
rl training, epoch3, iter0, batch990/1133, batch loss:0.5288959741592407, Training time:56786.59645628929
batch reward last col mean 0.9130867719650269 first col mean 0.9381726980209351 all mean 0.9406958818435669
0.5401669144630432 0.5401669144630432
rl training, epoch3, iter0, batch991/1133, batch loss:0.5401669144630432, Training time:56803.48241639137
batch reward last col mean 0.940263569355011 first col mean 0.9448158740997314 all mean 0.9310007095336914
0.5336577892303467 0.5336577892303467
rl training, epoch3, iter0, batch992/1133, batch loss:0.5336577892303467, Training time:56821.654790878296
batch reward last col mean 0.897994875907898 first col mean 0.9451477527618408 all mean 0.9119837880134583
0.4872033894062042 0.4872033894062042
rl training, epoch3, iter0, batch993/1133, batch loss:0.4872033894062042, Training time:56840.094797849655
batch reward last col mean 0.9337167143821716 first col mean 0.9440454244613647 all mean 0.9407601952552795
0.48553383350372314 0.48553383350372314
rl training, epoch3, iter0, batch994/1133, batch loss:0.48553383350372314, Training time:56857.981231451035
batch reward last col mean 0.9315494298934937 first col mean 0.9404793381690979 all mean 0.9324601292610168
0.5129897594451904 0.5129897594451904
rl training, epoch3, iter0, batch995/1133, batch loss:0.5129897594451904, Training time:56876.46616816521
batch reward last col mean 0.9359568953514099 first col mean 0.9316374659538269 all mean 0.923119306564331
0.4830826222896576 0.48308265209198
rl training, epoch3, iter0, batch996/1133, batch loss:0.48308265209198, Training time:56893.33272457123
batch reward last col mean 0.9292303323745728 first col mean 0.9363524913787842 all mean 0.9316797256469727
0.48457759618759155 0.48457759618759155
rl training, epoch3, iter0, batch997/1133, batch loss:0.48457759618759155, Training time:56910.12320518494
batch reward last col mean 0.9195065498352051 first col mean 0.930929958820343 all mean 0.9310108423233032
0.4982469975948334 0.4982469975948334
rl training, epoch3, iter0, batch998/1133, batch loss:0.4982469975948334, Training time:56926.886629104614
batch reward last col mean 0.9447922110557556 first col mean 0.9215580821037292 all mean 0.9390961527824402
0.4839093089103699 0.4839093089103699
rl training, epoch3, iter0, batch999/1133, batch loss:0.4839093089103699, Training time:56945.49542784691
batch reward last col mean 0.9328355193138123 first col mean 0.9387255907058716 all mean 0.9435703754425049
0.500420868396759 0.500420868396759
rl training, epoch3, iter0, batch1000/1133, batch loss:0.500420868396759, Training time:56962.277252435684
batch reward last col mean 0.9334244132041931 first col mean 0.9151391386985779 all mean 0.9272513389587402
0.4956364333629608 0.4956364333629608
rl training, epoch3, iter0, batch1001/1133, batch loss:0.4956364333629608, Training time:56979.010623931885
batch reward last col mean 0.9108729362487793 first col mean 0.9302825927734375 all mean 0.91898113489151
0.482660710811615 0.482660710811615
rl training, epoch3, iter0, batch1002/1133, batch loss:0.482660710811615, Training time:56995.983380794525
batch reward last col mean 0.9361029267311096 first col mean 0.947568953037262 all mean 0.9453554749488831
0.4897696375846863 0.4897696375846863
rl training, epoch3, iter0, batch1003/1133, batch loss:0.4897696375846863, Training time:57012.716636657715
batch reward last col mean 0.9059553146362305 first col mean 0.9212766885757446 all mean 0.9288669228553772
0.510648250579834 0.510648250579834
rl training, epoch3, iter0, batch1004/1133, batch loss:0.510648250579834, Training time:57029.52142047882
batch reward last col mean 0.9255982637405396 first col mean 0.9187677502632141 all mean 0.9219176769256592
0.47673314809799194 0.47673311829566956
rl training, epoch3, iter0, batch1005/1133, batch loss:0.47673311829566956, Training time:57046.4853913784
batch reward last col mean 0.8797522783279419 first col mean 0.9093199372291565 all mean 0.9035046696662903
0.4802960157394409 0.4802960157394409
rl training, epoch3, iter0, batch1006/1133, batch loss:0.4802960157394409, Training time:57063.35362172127
batch reward last col mean 0.9185351729393005 first col mean 0.9277780055999756 all mean 0.9163299202919006
0.492441326379776 0.492441326379776
rl training, epoch3, iter0, batch1007/1133, batch loss:0.492441326379776, Training time:57082.050421476364
batch reward last col mean 0.9331459403038025 first col mean 0.9218226671218872 all mean 0.9186310172080994
0.49476560950279236 0.49476560950279236
rl training, epoch3, iter0, batch1008/1133, batch loss:0.49476560950279236, Training time:57098.89937520027
batch reward last col mean 0.9496282339096069 first col mean 0.9399958848953247 all mean 0.9367710947990417
0.49115052819252014 0.49115046858787537
rl training, epoch3, iter0, batch1009/1133, batch loss:0.49115046858787537, Training time:57115.734053611755
batch reward last col mean 0.9028668403625488 first col mean 0.9264848232269287 all mean 0.925866961479187
0.4977649748325348 0.4977650046348572
rl training, epoch3, iter0, batch1010/1133, batch loss:0.4977650046348572, Training time:57132.59675741196
batch reward last col mean 0.9115405082702637 first col mean 0.9292834401130676 all mean 0.9324409365653992
0.5235821604728699 0.5235821604728699
rl training, epoch3, iter0, batch1011/1133, batch loss:0.5235821604728699, Training time:57149.283207416534
batch reward last col mean 0.920671820640564 first col mean 0.9393869638442993 all mean 0.9380657076835632
0.4889209568500519 0.4889209568500519
rl training, epoch3, iter0, batch1012/1133, batch loss:0.4889209568500519, Training time:57166.16161108017
batch reward last col mean 0.9142424464225769 first col mean 0.9272385835647583 all mean 0.9265609979629517
0.4997846484184265 0.4997846484184265
rl training, epoch3, iter0, batch1013/1133, batch loss:0.4997846484184265, Training time:57183.08208608627
batch reward last col mean 0.9286466240882874 first col mean 0.9200071096420288 all mean 0.9317452907562256
0.49763673543930054 0.49763673543930054
rl training, epoch3, iter0, batch1014/1133, batch loss:0.49763673543930054, Training time:57199.90779829025
batch reward last col mean 0.9067226648330688 first col mean 0.9337360858917236 all mean 0.9291571378707886
0.4928145110607147 0.4928145110607147
rl training, epoch3, iter0, batch1015/1133, batch loss:0.4928145110607147, Training time:57216.73727965355
batch reward last col mean 0.9341585636138916 first col mean 0.9291831851005554 all mean 0.929340660572052
0.4984876215457916 0.49848756194114685
rl training, epoch3, iter0, batch1016/1133, batch loss:0.49848756194114685, Training time:57235.085001945496
batch reward last col mean 0.9229400753974915 first col mean 0.9393308162689209 all mean 0.9402600526809692
0.5020599961280823 0.5020599961280823
rl training, epoch3, iter0, batch1017/1133, batch loss:0.5020599961280823, Training time:57251.86588025093
batch reward last col mean 0.9187881350517273 first col mean 0.9499204754829407 all mean 0.9435441493988037
0.5163775682449341 0.5163775682449341
rl training, epoch3, iter0, batch1018/1133, batch loss:0.5163775682449341, Training time:57269.473615169525
batch reward last col mean 0.9437015056610107 first col mean 0.9250659346580505 all mean 0.9317995309829712
0.5014854669570923 0.5014854669570923
rl training, epoch3, iter0, batch1019/1133, batch loss:0.5014854669570923, Training time:57287.7029876709
batch reward last col mean 0.9147631525993347 first col mean 0.9309680461883545 all mean 0.9355407357215881
0.5208972096443176 0.5208972096443176
rl training, epoch3, iter0, batch1020/1133, batch loss:0.5208972096443176, Training time:57304.33468770981
batch reward last col mean 0.906776487827301 first col mean 0.9377331733703613 all mean 0.9251477718353271
0.5214843153953552 0.5214843153953552
rl training, epoch3, iter0, batch1021/1133, batch loss:0.5214843153953552, Training time:57320.965690374374
batch reward last col mean 0.9167985916137695 first col mean 0.9215378165245056 all mean 0.9261319041252136
0.510989248752594 0.510989248752594
rl training, epoch3, iter0, batch1022/1133, batch loss:0.510989248752594, Training time:57337.711168289185
batch reward last col mean 0.9386930465698242 first col mean 0.9271149635314941 all mean 0.9305587410926819
0.5226592421531677 0.5226592421531677
rl training, epoch3, iter0, batch1023/1133, batch loss:0.5226592421531677, Training time:57354.47588443756
batch reward last col mean 0.9417212605476379 first col mean 0.9433425068855286 all mean 0.9377056360244751
0.5425336360931396 0.5425336360931396
rl training, epoch3, iter0, batch1024/1133, batch loss:0.5425336360931396, Training time:57371.243331193924
batch reward last col mean 0.9251020550727844 first col mean 0.9443974494934082 all mean 0.9349266290664673
0.5409943461418152 0.5409943461418152
rl training, epoch3, iter0, batch1025/1133, batch loss:0.5409943461418152, Training time:57388.065448999405
batch reward last col mean 0.933983325958252 first col mean 0.937792181968689 all mean 0.9410901069641113
0.5566134452819824 0.5566133856773376
rl training, epoch3, iter0, batch1026/1133, batch loss:0.5566133856773376, Training time:57405.003455638885
batch reward last col mean 0.9529496431350708 first col mean 0.9452092051506042 all mean 0.9425656199455261
0.532158613204956 0.532158613204956
rl training, epoch3, iter0, batch1027/1133, batch loss:0.532158613204956, Training time:57421.79315805435
batch reward last col mean 0.9273737668991089 first col mean 0.9321402311325073 all mean 0.9278197884559631
0.5455530285835266 0.5455530285835266
rl training, epoch3, iter0, batch1028/1133, batch loss:0.5455530285835266, Training time:57438.648614645004
batch reward last col mean 0.9296557903289795 first col mean 0.9488011002540588 all mean 0.9267843961715698
0.5379495024681091 0.5379494428634644
rl training, epoch3, iter0, batch1029/1133, batch loss:0.5379494428634644, Training time:57455.40652227402
batch reward last col mean 0.9078422784805298 first col mean 0.9399240016937256 all mean 0.9407177567481995
0.5378642678260803 0.5378642678260803
rl training, epoch3, iter0, batch1030/1133, batch loss:0.5378642678260803, Training time:57472.041972875595
batch reward last col mean 0.9361081123352051 first col mean 0.9385635852813721 all mean 0.9404389262199402
0.5487303137779236 0.5487303137779236
rl training, epoch3, iter0, batch1031/1133, batch loss:0.5487303137779236, Training time:57488.70598864555
batch reward last col mean 0.9590696692466736 first col mean 0.9256585836410522 all mean 0.9362219572067261
0.5522515773773193 0.5522515773773193
rl training, epoch3, iter0, batch1032/1133, batch loss:0.5522515773773193, Training time:57505.40525460243
batch reward last col mean 0.9390174150466919 first col mean 0.940194845199585 all mean 0.9294897317886353
0.5499105453491211 0.5499105453491211
rl training, epoch3, iter0, batch1033/1133, batch loss:0.5499105453491211, Training time:57522.2287671566
batch reward last col mean 0.8921782970428467 first col mean 0.9357052445411682 all mean 0.9241037368774414
0.5327863693237305 0.5327863693237305
rl training, epoch3, iter0, batch1034/1133, batch loss:0.5327863693237305, Training time:57539.12365055084
batch reward last col mean 0.9392609000205994 first col mean 0.940580427646637 all mean 0.9432591795921326
0.5562496185302734 0.5562496185302734
rl training, epoch3, iter0, batch1035/1133, batch loss:0.5562496185302734, Training time:57556.383976221085
batch reward last col mean 0.9335615634918213 first col mean 0.9292039275169373 all mean 0.9320829510688782
0.5291833877563477 0.5291833877563477
rl training, epoch3, iter0, batch1036/1133, batch loss:0.5291833877563477, Training time:57574.05910015106
batch reward last col mean 0.9232791662216187 first col mean 0.9224754571914673 all mean 0.9296586513519287
0.5252038836479187 0.5252038836479187
rl training, epoch3, iter0, batch1037/1133, batch loss:0.5252038836479187, Training time:57590.97800016403
batch reward last col mean 0.9184845685958862 first col mean 0.9257261753082275 all mean 0.9262726306915283
0.5422630906105042 0.5422630906105042
rl training, epoch3, iter0, batch1038/1133, batch loss:0.5422630906105042, Training time:57607.96167469025
batch reward last col mean 0.920933723449707 first col mean 0.9382954239845276 all mean 0.9303844571113586
0.5381571054458618 0.5381571054458618
rl training, epoch3, iter0, batch1039/1133, batch loss:0.5381571054458618, Training time:57626.70612502098
batch reward last col mean 0.9489015936851501 first col mean 0.9326876401901245 all mean 0.9483400583267212
0.5329738855361938 0.5329738855361938
rl training, epoch3, iter0, batch1040/1133, batch loss:0.5329738855361938, Training time:57645.61097216606
batch reward last col mean 0.9107767343521118 first col mean 0.9195094108581543 all mean 0.9212667942047119
0.5347132682800293 0.5347132682800293
rl training, epoch3, iter0, batch1041/1133, batch loss:0.5347132682800293, Training time:57662.397198200226
batch reward last col mean 0.9121840596199036 first col mean 0.9297974705696106 all mean 0.9373623728752136
0.5471999049186707 0.5471998453140259
rl training, epoch3, iter0, batch1042/1133, batch loss:0.5471998453140259, Training time:57679.377744197845
batch reward last col mean 0.9236125349998474 first col mean 0.9325309991836548 all mean 0.9343122839927673
0.5582664608955383 0.5582664608955383
rl training, epoch3, iter0, batch1043/1133, batch loss:0.5582664608955383, Training time:57696.19307136536
batch reward last col mean 0.9320670366287231 first col mean 0.9457879662513733 all mean 0.9344323873519897
0.5477175712585449 0.5477175712585449
rl training, epoch3, iter0, batch1044/1133, batch loss:0.5477175712585449, Training time:57714.46064543724
batch reward last col mean 0.9362717270851135 first col mean 0.9362375140190125 all mean 0.9322801232337952
0.5565640330314636 0.5565640330314636
rl training, epoch3, iter0, batch1045/1133, batch loss:0.5565640330314636, Training time:57732.669719457626
batch reward last col mean 0.9519339203834534 first col mean 0.9394974112510681 all mean 0.9432414174079895
0.5536862015724182 0.5536861419677734
rl training, epoch3, iter0, batch1046/1133, batch loss:0.5536861419677734, Training time:57749.59369921684
batch reward last col mean 0.9127281904220581 first col mean 0.9443735480308533 all mean 0.9350032806396484
0.5542851686477661 0.5542851686477661
rl training, epoch3, iter0, batch1047/1133, batch loss:0.5542851686477661, Training time:57766.46294569969
batch reward last col mean 0.9267429113388062 first col mean 0.9271758794784546 all mean 0.9339576363563538
0.5420292019844055 0.5420292019844055
rl training, epoch3, iter0, batch1048/1133, batch loss:0.5420292019844055, Training time:57783.39106678963
batch reward last col mean 0.9059494733810425 first col mean 0.9182220101356506 all mean 0.9198416471481323
0.5313262939453125 0.5313262939453125
rl training, epoch3, iter0, batch1049/1133, batch loss:0.5313262939453125, Training time:57800.271003723145
batch reward last col mean 0.9083729982376099 first col mean 0.9318687319755554 all mean 0.921425461769104
0.5126384496688843 0.5126384496688843
rl training, epoch3, iter0, batch1050/1133, batch loss:0.5126384496688843, Training time:57817.148019075394
batch reward last col mean 0.9286816716194153 first col mean 0.9401090145111084 all mean 0.9318755865097046
0.5449745655059814 0.5449745655059814
rl training, epoch3, iter0, batch1051/1133, batch loss:0.5449745655059814, Training time:57833.79248166084
batch reward last col mean 0.8990858793258667 first col mean 0.9181008338928223 all mean 0.9144755601882935
0.5085933208465576 0.5085933208465576
rl training, epoch3, iter0, batch1052/1133, batch loss:0.5085933208465576, Training time:57850.6531996727
batch reward last col mean 0.9151832461357117 first col mean 0.9183100461959839 all mean 0.9117157459259033
0.5299094319343567 0.5299094319343567
rl training, epoch3, iter0, batch1053/1133, batch loss:0.5299094319343567, Training time:57867.588678598404
batch reward last col mean 0.9034872055053711 first col mean 0.9327182173728943 all mean 0.9371264576911926
0.5412365794181824 0.5412365794181824
rl training, epoch3, iter0, batch1054/1133, batch loss:0.5412365794181824, Training time:57884.685270786285
batch reward last col mean 0.9323334693908691 first col mean 0.9453495740890503 all mean 0.9273991584777832
0.527373194694519 0.527373194694519
rl training, epoch3, iter0, batch1055/1133, batch loss:0.527373194694519, Training time:57901.68922781944
batch reward last col mean 0.9397093057632446 first col mean 0.9193186163902283 all mean 0.9230664968490601
0.5032006502151489 0.5032006502151489
rl training, epoch3, iter0, batch1056/1133, batch loss:0.5032006502151489, Training time:57918.66064238548
batch reward last col mean 0.9446607232093811 first col mean 0.9355736970901489 all mean 0.9356712698936462
0.5098573565483093 0.5098573565483093
rl training, epoch3, iter0, batch1057/1133, batch loss:0.5098573565483093, Training time:57935.58989191055
batch reward last col mean 0.9099370241165161 first col mean 0.9130217432975769 all mean 0.9209824204444885
0.5208870768547058 0.5208870768547058
rl training, epoch3, iter0, batch1058/1133, batch loss:0.5208870768547058, Training time:57952.591616392136
batch reward last col mean 0.9538939595222473 first col mean 0.9288058876991272 all mean 0.927277684211731
0.5178248286247253 0.5178248286247253
rl training, epoch3, iter0, batch1059/1133, batch loss:0.5178248286247253, Training time:57970.984036684036
batch reward last col mean 0.9111642837524414 first col mean 0.9130989909172058 all mean 0.910001814365387
0.5128706097602844 0.5128706097602844
rl training, epoch3, iter0, batch1060/1133, batch loss:0.5128706097602844, Training time:57989.51128363609
batch reward last col mean 0.9123454093933105 first col mean 0.931277871131897 all mean 0.9194631576538086
0.5247419476509094 0.5247419476509094
rl training, epoch3, iter0, batch1061/1133, batch loss:0.5247419476509094, Training time:58008.24534010887
batch reward last col mean 0.9345618486404419 first col mean 0.916408896446228 all mean 0.9163231253623962
0.5126941800117493 0.512694239616394
rl training, epoch3, iter0, batch1062/1133, batch loss:0.512694239616394, Training time:58026.94571328163
batch reward last col mean 0.9257651567459106 first col mean 0.9199570417404175 all mean 0.9200040102005005
0.5144378542900085 0.5144378542900085
rl training, epoch3, iter0, batch1063/1133, batch loss:0.5144378542900085, Training time:58043.92809724808
batch reward last col mean 0.9232766628265381 first col mean 0.9215497374534607 all mean 0.9219686985015869
0.5250627398490906 0.5250627398490906
rl training, epoch3, iter0, batch1064/1133, batch loss:0.5250627398490906, Training time:58060.77717399597
batch reward last col mean 0.9087667465209961 first col mean 0.9174797534942627 all mean 0.9164262413978577
0.5122190713882446 0.5122190713882446
rl training, epoch3, iter0, batch1065/1133, batch loss:0.5122190713882446, Training time:58078.88266992569
batch reward last col mean 0.9043554067611694 first col mean 0.9014939069747925 all mean 0.9106141924858093
0.5090188980102539 0.5090188384056091
rl training, epoch3, iter0, batch1066/1133, batch loss:0.5090188384056091, Training time:58096.28144979477
batch reward last col mean 0.9250940680503845 first col mean 0.9259952902793884 all mean 0.9228396415710449
0.5188299417495728 0.5188299417495728
rl training, epoch3, iter0, batch1067/1133, batch loss:0.5188299417495728, Training time:58114.50577020645
batch reward last col mean 0.9040045738220215 first col mean 0.9198058843612671 all mean 0.9183347821235657
0.5262875556945801 0.5262875556945801
rl training, epoch3, iter0, batch1068/1133, batch loss:0.5262875556945801, Training time:58133.142580747604
batch reward last col mean 0.8589164614677429 first col mean 0.8995361328125 all mean 0.9096696376800537
0.5161821246147156 0.5161821246147156
rl training, epoch3, iter0, batch1069/1133, batch loss:0.5161821246147156, Training time:58150.13153004646
batch reward last col mean 0.8946632742881775 first col mean 0.9090005159378052 all mean 0.9060060381889343
0.5027462244033813 0.5027462244033813
rl training, epoch3, iter0, batch1070/1133, batch loss:0.5027462244033813, Training time:58167.133014678955
batch reward last col mean 0.9070066213607788 first col mean 0.9076898694038391 all mean 0.9093564748764038
0.5019655823707581 0.5019655823707581
rl training, epoch3, iter0, batch1071/1133, batch loss:0.5019655823707581, Training time:58184.16714811325
batch reward last col mean 0.8964804410934448 first col mean 0.9217955470085144 all mean 0.9093490839004517
0.5159723162651062 0.5159723162651062
rl training, epoch3, iter0, batch1072/1133, batch loss:0.5159723162651062, Training time:58201.2599170208
batch reward last col mean 0.9170123338699341 first col mean 0.9033660888671875 all mean 0.8982915282249451
0.49038928747177124 0.49038931727409363
rl training, epoch3, iter0, batch1073/1133, batch loss:0.49038931727409363, Training time:58218.206490039825
batch reward last col mean 0.9241946339607239 first col mean 0.9092519283294678 all mean 0.9104078412055969
0.5078649520874023 0.5078649520874023
rl training, epoch3, iter0, batch1074/1133, batch loss:0.5078649520874023, Training time:58235.01120233536
batch reward last col mean 0.9180688261985779 first col mean 0.9092955589294434 all mean 0.9184986352920532
0.5067073702812195 0.5067073702812195
rl training, epoch3, iter0, batch1075/1133, batch loss:0.5067073702812195, Training time:58251.75567984581
batch reward last col mean 0.8991279006004333 first col mean 0.9094151258468628 all mean 0.8947038650512695
0.4979511499404907 0.4979511499404907
rl training, epoch3, iter0, batch1076/1133, batch loss:0.4979511499404907, Training time:58270.37705826759
batch reward last col mean 0.9176294207572937 first col mean 0.9165840148925781 all mean 0.9002664089202881
0.5017374753952026 0.5017374753952026
rl training, epoch3, iter0, batch1077/1133, batch loss:0.5017374753952026, Training time:58287.280415296555
batch reward last col mean 0.8751890659332275 first col mean 0.8928157687187195 all mean 0.8958165049552917
0.4707293212413788 0.4707293212413788
rl training, epoch3, iter0, batch1078/1133, batch loss:0.4707293212413788, Training time:58304.198409080505
batch reward last col mean 0.9258866310119629 first col mean 0.9029860496520996 all mean 0.8937556147575378
0.4774518311023712 0.4774518311023712
rl training, epoch3, iter0, batch1079/1133, batch loss:0.4774518311023712, Training time:58321.1762111187
batch reward last col mean 0.9057512283325195 first col mean 0.9043669700622559 all mean 0.8943678736686707
0.4800555408000946 0.4800555408000946
rl training, epoch3, iter0, batch1080/1133, batch loss:0.4800555408000946, Training time:58338.06526041031
batch reward last col mean 0.910158097743988 first col mean 0.8988627791404724 all mean 0.8921822309494019
0.47508618235588074 0.47508618235588074
rl training, epoch3, iter0, batch1081/1133, batch loss:0.47508618235588074, Training time:58354.913222551346
batch reward last col mean 0.8789919018745422 first col mean 0.8722892999649048 all mean 0.8674987554550171
0.4624441862106323 0.4624441862106323
rl training, epoch3, iter0, batch1082/1133, batch loss:0.4624441862106323, Training time:58371.87336730957
batch reward last col mean 0.894790530204773 first col mean 0.8871704339981079 all mean 0.8781567811965942
0.4455832242965698 0.4455832242965698
rl training, epoch3, iter0, batch1083/1133, batch loss:0.4455832242965698, Training time:58388.603513240814
batch reward last col mean 0.8899939060211182 first col mean 0.8844866156578064 all mean 0.8945619463920593
0.47935962677001953 0.47935962677001953
rl training, epoch3, iter0, batch1084/1133, batch loss:0.47935962677001953, Training time:58405.500749111176
batch reward last col mean 0.898334801197052 first col mean 0.8827155828475952 all mean 0.8885079622268677
0.4724296033382416 0.4724296033382416
rl training, epoch3, iter0, batch1085/1133, batch loss:0.4724296033382416, Training time:58424.1434841156
batch reward last col mean 0.9044325351715088 first col mean 0.8852198123931885 all mean 0.8824220895767212
0.46929818391799927 0.4692981541156769
rl training, epoch3, iter0, batch1086/1133, batch loss:0.4692981541156769, Training time:58442.61364340782
batch reward last col mean 0.8656927943229675 first col mean 0.8393734693527222 all mean 0.8658149242401123
0.4515409469604492 0.4515409469604492
rl training, epoch3, iter0, batch1087/1133, batch loss:0.4515409469604492, Training time:58461.21784877777
batch reward last col mean 0.8671962022781372 first col mean 0.8597292304039001 all mean 0.860205352306366
0.48306331038475037 0.483063280582428
rl training, epoch3, iter0, batch1088/1133, batch loss:0.483063280582428, Training time:58479.6630423069
batch reward last col mean 0.9047657251358032 first col mean 0.9027969241142273 all mean 0.8973278999328613
0.49517345428466797 0.49517345428466797
rl training, epoch3, iter0, batch1089/1133, batch loss:0.49517345428466797, Training time:58498.3685131073
batch reward last col mean 0.8843626379966736 first col mean 0.8972548246383667 all mean 0.8803419470787048
0.49067792296409607 0.49067792296409607
rl training, epoch3, iter0, batch1090/1133, batch loss:0.49067792296409607, Training time:58516.933307647705
batch reward last col mean 0.8959771394729614 first col mean 0.879442572593689 all mean 0.8848111629486084
0.4737156629562378 0.4737156629562378
rl training, epoch3, iter0, batch1091/1133, batch loss:0.4737156629562378, Training time:58535.02286720276
batch reward last col mean 0.8556263446807861 first col mean 0.8567735552787781 all mean 0.8473017811775208
0.4588020145893097 0.4588020145893097
rl training, epoch3, iter0, batch1092/1133, batch loss:0.4588020145893097, Training time:58551.91131544113
batch reward last col mean 0.8827242851257324 first col mean 0.885272741317749 all mean 0.8843131065368652
0.4926842451095581 0.4926842451095581
rl training, epoch3, iter0, batch1093/1133, batch loss:0.4926842451095581, Training time:58568.74199104309
batch reward last col mean 0.8774329423904419 first col mean 0.8729519248008728 all mean 0.8668233752250671
0.4858579635620117 0.4858579635620117
rl training, epoch3, iter0, batch1094/1133, batch loss:0.4858579635620117, Training time:58585.59334588051
batch reward last col mean 0.8792804479598999 first col mean 0.8910443186759949 all mean 0.8848366737365723
0.5135617256164551 0.5135617852210999
rl training, epoch3, iter0, batch1095/1133, batch loss:0.5135617852210999, Training time:58602.48189020157
batch reward last col mean 0.8503865003585815 first col mean 0.8678334355354309 all mean 0.8526477813720703
0.4628370702266693 0.4628370404243469
rl training, epoch3, iter0, batch1096/1133, batch loss:0.4628370404243469, Training time:58619.33658981323
batch reward last col mean 0.8912511467933655 first col mean 0.8716989755630493 all mean 0.887786328792572
0.48132070899009705 0.48132070899009705
rl training, epoch3, iter0, batch1097/1133, batch loss:0.48132070899009705, Training time:58636.071766614914
batch reward last col mean 0.8454394936561584 first col mean 0.8748046159744263 all mean 0.8815112709999084
0.48407432436943054 0.48407432436943054
rl training, epoch3, iter0, batch1098/1133, batch loss:0.48407432436943054, Training time:58653.038358688354
batch reward last col mean 0.8663816452026367 first col mean 0.8697367906570435 all mean 0.8679302334785461
0.4745979607105255 0.4745979607105255
rl training, epoch3, iter0, batch1099/1133, batch loss:0.4745979607105255, Training time:58670.0099439621
batch reward last col mean 0.8648150563240051 first col mean 0.8938795924186707 all mean 0.8710051774978638
0.4657362401485443 0.4657362401485443
rl training, epoch3, iter0, batch1100/1133, batch loss:0.4657362401485443, Training time:58686.85904955864
batch reward last col mean 0.8623915910720825 first col mean 0.852763831615448 all mean 0.8671061992645264
0.47458502650260925 0.47458502650260925
rl training, epoch3, iter0, batch1101/1133, batch loss:0.47458502650260925, Training time:58703.57851552963
batch reward last col mean 0.8834258317947388 first col mean 0.8748712539672852 all mean 0.8797043561935425
0.46757030487060547 0.46757030487060547
rl training, epoch3, iter0, batch1102/1133, batch loss:0.46757030487060547, Training time:58720.30170416832
batch reward last col mean 0.8853387236595154 first col mean 0.8773695230484009 all mean 0.8719115853309631
0.48272064328193665 0.48272064328193665
rl training, epoch3, iter0, batch1103/1133, batch loss:0.48272064328193665, Training time:58737.02075767517
batch reward last col mean 0.8641377091407776 first col mean 0.8792235851287842 all mean 0.8688080310821533
0.45050719380378723 0.45050719380378723
rl training, epoch3, iter0, batch1104/1133, batch loss:0.45050719380378723, Training time:58753.77514410019
batch reward last col mean 0.9179123044013977 first col mean 0.8869659304618835 all mean 0.8855921626091003
0.4825209379196167 0.4825209379196167
rl training, epoch3, iter0, batch1105/1133, batch loss:0.4825209379196167, Training time:58770.42716526985
batch reward last col mean 0.8676555156707764 first col mean 0.8507417440414429 all mean 0.8705675601959229
0.4783722758293152 0.4783722460269928
rl training, epoch3, iter0, batch1106/1133, batch loss:0.4783722460269928, Training time:58787.30107498169
batch reward last col mean 0.8319532871246338 first col mean 0.8404646515846252 all mean 0.8662833571434021
0.4772074520587921 0.4772074520587921
rl training, epoch3, iter0, batch1107/1133, batch loss:0.4772074520587921, Training time:58804.18198347092
batch reward last col mean 0.8922234177589417 first col mean 0.885344922542572 all mean 0.8848829865455627
0.47507381439208984 0.47507375478744507
rl training, epoch3, iter0, batch1108/1133, batch loss:0.47507375478744507, Training time:58821.519819021225
batch reward last col mean 0.8557131886482239 first col mean 0.8650854825973511 all mean 0.8590156435966492
0.4800848960876465 0.48008492588996887
rl training, epoch3, iter0, batch1109/1133, batch loss:0.48008492588996887, Training time:58838.583359479904
batch reward last col mean 0.9310305118560791 first col mean 0.9022305607795715 all mean 0.892388105392456
0.489833265542984 0.489833265542984
rl training, epoch3, iter0, batch1110/1133, batch loss:0.489833265542984, Training time:58855.53390097618
batch reward last col mean 0.8432497978210449 first col mean 0.8793637156486511 all mean 0.8673282265663147
0.47596317529678345 0.47596317529678345
rl training, epoch3, iter0, batch1111/1133, batch loss:0.47596317529678345, Training time:58872.38332128525
batch reward last col mean 0.8684195876121521 first col mean 0.8821268677711487 all mean 0.88514244556427
0.46360763907432556 0.46360766887664795
rl training, epoch3, iter0, batch1112/1133, batch loss:0.46360766887664795, Training time:58889.39795207977
batch reward last col mean 0.8944768309593201 first col mean 0.9018348455429077 all mean 0.8878036737442017
0.4940466582775116 0.4940466582775116
rl training, epoch3, iter0, batch1113/1133, batch loss:0.4940466582775116, Training time:58906.29163098335
batch reward last col mean 0.8612771034240723 first col mean 0.895301103591919 all mean 0.8789791464805603
0.44577911496162415 0.44577911496162415
rl training, epoch3, iter0, batch1114/1133, batch loss:0.44577911496162415, Training time:58923.316843509674
batch reward last col mean 0.9012851119041443 first col mean 0.8897183537483215 all mean 0.8925589919090271
0.4556558132171631 0.4556558132171631
rl training, epoch3, iter0, batch1115/1133, batch loss:0.4556558132171631, Training time:58940.265300512314
batch reward last col mean 0.9264150261878967 first col mean 0.8964077830314636 all mean 0.8971545100212097
0.44297105073928833 0.44297105073928833
rl training, epoch3, iter0, batch1116/1133, batch loss:0.44297105073928833, Training time:58958.69088816643
batch reward last col mean 0.8829315304756165 first col mean 0.9172413349151611 all mean 0.8967938423156738
0.4396611750125885 0.4396611750125885
rl training, epoch3, iter0, batch1117/1133, batch loss:0.4396611750125885, Training time:58977.338547468185
batch reward last col mean 0.9216382503509521 first col mean 0.8962715268135071 all mean 0.9084485769271851
0.45224055647850037 0.45224055647850037
rl training, epoch3, iter0, batch1118/1133, batch loss:0.45224055647850037, Training time:58995.952013492584
batch reward last col mean 0.9097580909729004 first col mean 0.898177444934845 all mean 0.896797239780426
0.4356849789619446 0.4356849789619446
rl training, epoch3, iter0, batch1119/1133, batch loss:0.4356849789619446, Training time:59012.74145054817
batch reward last col mean 0.8994885683059692 first col mean 0.8869625926017761 all mean 0.8940033316612244
0.42584744095802307 0.42584744095802307
rl training, epoch3, iter0, batch1120/1133, batch loss:0.42584744095802307, Training time:59029.6486389637
batch reward last col mean 0.9159408807754517 first col mean 0.9002631306648254 all mean 0.9053457379341125
0.4300333559513092 0.4300333559513092
rl training, epoch3, iter0, batch1121/1133, batch loss:0.4300333559513092, Training time:59046.468863487244
batch reward last col mean 0.9010836482048035 first col mean 0.9108120799064636 all mean 0.8936821222305298
0.41900134086608887 0.41900134086608887
rl training, epoch3, iter0, batch1122/1133, batch loss:0.41900134086608887, Training time:59063.23162841797
batch reward last col mean 0.8959971070289612 first col mean 0.9113770723342896 all mean 0.8962618708610535
0.43725353479385376 0.43725353479385376
rl training, epoch3, iter0, batch1123/1133, batch loss:0.43725353479385376, Training time:59080.03178310394
batch reward last col mean 0.8902106881141663 first col mean 0.9024765491485596 all mean 0.8937172889709473
0.4359334409236908 0.4359334409236908
rl training, epoch3, iter0, batch1124/1133, batch loss:0.4359334409236908, Training time:59096.7736787796
batch reward last col mean 0.9035819172859192 first col mean 0.9000097513198853 all mean 0.8944740891456604
0.4427356421947479 0.44273561239242554
rl training, epoch3, iter0, batch1125/1133, batch loss:0.44273561239242554, Training time:59114.21788764
batch reward last col mean 0.8603413105010986 first col mean 0.9056048393249512 all mean 0.8849040269851685
0.43546053767204285 0.43546053767204285
rl training, epoch3, iter0, batch1126/1133, batch loss:0.43546053767204285, Training time:59131.131306648254
batch reward last col mean 0.8957117795944214 first col mean 0.898951530456543 all mean 0.9006734490394592
0.43201613426208496 0.43201613426208496
rl training, epoch3, iter0, batch1127/1133, batch loss:0.43201613426208496, Training time:59148.158655405045
batch reward last col mean 0.9167927503585815 first col mean 0.8801617622375488 all mean 0.8910977840423584
0.4343448281288147 0.4343448281288147
rl training, epoch3, iter0, batch1128/1133, batch loss:0.4343448281288147, Training time:59165.149725437164
batch reward last col mean 0.8760807514190674 first col mean 0.8823443651199341 all mean 0.8864396214485168
0.44738924503326416 0.44738924503326416
rl training, epoch3, iter0, batch1129/1133, batch loss:0.44738924503326416, Training time:59182.12972307205
batch reward last col mean 0.886009693145752 first col mean 0.8971042633056641 all mean 0.8929312229156494
0.45229828357696533 0.45229828357696533
rl training, epoch3, iter0, batch1130/1133, batch loss:0.45229828357696533, Training time:59199.06234264374
batch reward last col mean 0.9105035066604614 first col mean 0.9051114320755005 all mean 0.8956539034843445
0.4461309015750885 0.4461309015750885
rl training, epoch3, iter0, batch1131/1133, batch loss:0.4461309015750885, Training time:59216.10401535034
batch reward last col mean 0.9147169589996338 first col mean 0.8605909943580627 all mean 0.878332257270813
0.43406942486763 0.43406942486763
rl training, epoch3, iter0, batch1132/1133, batch loss:0.43406942486763, Training time:59233.70455288887
rl training, epoch 3, iter 0, loss:0.20729777832345028, Training time:59233.704708337784 
rl epoch 3, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.415255770665928 Time: 139.88344740867615 s
0.16769828413927965 0.005754973370402838 0.24180251235653633
cur_epoch: 1
D Training Loss: 0.3983433147446834 Time: 138.66962361335754 s
0.16185094834373573 7.080285049256913e-05 0.23642156337571166
cur_epoch: 2
D Training Loss: 0.3934696654461173 Time: 141.19020438194275 s
0.16016998007854105 5.780564736300508e-05 0.2332418796007126
cur_epoch: 3
D Training Loss: 0.38944017076955256 Time: 139.78946495056152 s
0.1570475639583048 3.286050275167809e-05 0.23235974626554814
cur_epoch: 4
D Training Loss: 0.384903383815278 Time: 139.35362601280212 s
0.15569880536353808 2.5742170179336564e-05 0.229178836031604
rl epoch 4, begin RL for generator...
batch reward last col mean 7.498283957829699e-05 first col mean 3.6939093206456164e-06 all mean 3.433192614465952e-05
2.222745752078481e-05 2.2227455701795407e-05
rl training, epoch4, iter0, batch0/1133, batch loss:2.2227455701795407e-05, Training time:59949.576802015305
batch reward last col mean 2.010479693126399e-05 first col mean 1.3918497643317096e-05 all mean 2.1351892428356223e-05
3.691172969411127e-05 3.691172969411127e-05
rl training, epoch4, iter0, batch1/1133, batch loss:3.691172969411127e-05, Training time:59966.442079782486
batch reward last col mean 1.4586555607820628e-06 first col mean 4.14041505791829e-06 all mean 1.2980724932276644e-05
7.080405794113176e-06 7.080404429871123e-06
rl training, epoch4, iter0, batch2/1133, batch loss:7.080404429871123e-06, Training time:59983.44894695282
batch reward last col mean 4.378569428808987e-06 first col mean 1.715863254503347e-05 all mean 3.251595262554474e-05
8.973421245173085e-06 8.973420335678384e-06
rl training, epoch4, iter0, batch3/1133, batch loss:8.973420335678384e-06, Training time:60000.324983119965
batch reward last col mean 1.7542696468808572e-06 first col mean 5.757367944170255e-06 all mean 2.3293172489502467e-05
1.0361633940192405e-05 1.03616312117083e-05
rl training, epoch4, iter0, batch4/1133, batch loss:1.03616312117083e-05, Training time:60017.020921468735
batch reward last col mean 0.00010865960939554498 first col mean 3.0819414860161487e-06 all mean 2.3219519789563492e-05
4.3850261135958135e-05 4.385025386000052e-05
rl training, epoch4, iter0, batch5/1133, batch loss:4.385025386000052e-05, Training time:60033.89710688591
batch reward last col mean 4.636929133994272e-06 first col mean 4.491203526413301e-06 all mean 2.309847877768334e-05
1.1587704648263752e-05 1.158770373876905e-05
rl training, epoch4, iter0, batch6/1133, batch loss:1.158770373876905e-05, Training time:60050.61346554756
batch reward last col mean 4.446728780749254e-06 first col mean 6.761272379662842e-05 all mean 1.790800888556987e-05
1.2364566828182433e-05 1.2364567737677135e-05
rl training, epoch4, iter0, batch7/1133, batch loss:1.2364567737677135e-05, Training time:60069.31380367279
batch reward last col mean 1.2375846836221172e-06 first col mean 2.3340098778135143e-06 all mean 1.0439117431815248e-05
5.420895377028501e-06 5.420895377028501e-06
rl training, epoch4, iter0, batch8/1133, batch loss:5.420895377028501e-06, Training time:60086.093324422836
batch reward last col mean 1.3756378393736668e-05 first col mean 1.7376009054714814e-05 all mean 3.0352586691151373e-05
8.470869943266734e-06 8.47086721478263e-06
rl training, epoch4, iter0, batch9/1133, batch loss:8.47086721478263e-06, Training time:60103.382890701294
batch reward last col mean 1.6841524939081864e-06 first col mean 6.6307584347669035e-06 all mean 2.686971492948942e-05
3.2185485906666145e-05 3.2185485906666145e-05
rl training, epoch4, iter0, batch10/1133, batch loss:3.2185485906666145e-05, Training time:60120.24289417267
batch reward last col mean 3.099665491390624e-06 first col mean 5.051836524216924e-06 all mean 1.9440036339801736e-05
4.281972451281035e-06 4.281976089259842e-06
rl training, epoch4, iter0, batch11/1133, batch loss:4.281976089259842e-06, Training time:60137.014063596725
batch reward last col mean 1.77877282112604e-05 first col mean 1.7489230231149122e-05 all mean 3.096029467997141e-05
1.688108932285104e-05 1.688108386588283e-05
rl training, epoch4, iter0, batch12/1133, batch loss:1.688108386588283e-05, Training time:60153.79322743416
batch reward last col mean 1.2513925867096987e-05 first col mean 1.236856678588083e-05 all mean 3.931373430532403e-05
2.252427839266602e-05 2.2524276573676616e-05
rl training, epoch4, iter0, batch13/1133, batch loss:2.2524276573676616e-05, Training time:60170.72230005264
batch reward last col mean 2.119294549629558e-06 first col mean 7.694408850511536e-06 all mean 3.511999238980934e-05
1.4002451280248351e-05 1.400245037075365e-05
rl training, epoch4, iter0, batch14/1133, batch loss:1.400245037075365e-05, Training time:60187.740576028824
batch reward last col mean 7.680925591557752e-06 first col mean 1.2112593140045647e-05 all mean 2.3149386834120378e-05
5.418813998403493e-06 5.418812634161441e-06
rl training, epoch4, iter0, batch15/1133, batch loss:5.418812634161441e-06, Training time:60204.75581908226
batch reward last col mean 1.3316301192389801e-05 first col mean 2.066455181193305e-06 all mean 4.8467598389834166e-05
6.3824181779637e-06 6.382411356753437e-06
rl training, epoch4, iter0, batch16/1133, batch loss:6.382411356753437e-06, Training time:60221.83310055733
batch reward last col mean 1.956782398337964e-05 first col mean 2.539288288971875e-06 all mean 2.2630874809692614e-05
1.294329558731988e-05 1.2943293768330477e-05
rl training, epoch4, iter0, batch17/1133, batch loss:1.2943293768330477e-05, Training time:60238.79382610321
batch reward last col mean 3.4048200632241787e-06 first col mean 9.996376320486888e-06 all mean 4.592460754793137e-05
2.354974640184082e-05 2.3549750039819628e-05
rl training, epoch4, iter0, batch18/1133, batch loss:2.3549750039819628e-05, Training time:60255.69566035271
batch reward last col mean 6.078607384552015e-06 first col mean 6.738231604686007e-05 all mean 3.6040510167367756e-05
4.3577729229582474e-05 4.3577729229582474e-05
rl training, epoch4, iter0, batch19/1133, batch loss:4.3577729229582474e-05, Training time:60272.55739927292
batch reward last col mean 2.940664217021549e-06 first col mean 8.531583262083586e-06 all mean 4.807917503057979e-05
8.741189049032982e-06 8.741179954085965e-06
rl training, epoch4, iter0, batch20/1133, batch loss:8.741179954085965e-06, Training time:60289.50920629501
batch reward last col mean 7.971651939442381e-06 first col mean 0.00012253476597834378 all mean 8.009824523469433e-05
2.714466245379299e-05 2.7144649720867164e-05
rl training, epoch4, iter0, batch21/1133, batch loss:2.7144649720867164e-05, Training time:60306.25979137421
batch reward last col mean 4.8486122068425175e-06 first col mean 0.00014998474216554314 all mean 6.537903391290456e-05
5.4323078074958175e-05 5.432308171293698e-05
rl training, epoch4, iter0, batch22/1133, batch loss:5.432308171293698e-05, Training time:60324.60092687607
batch reward last col mean 9.086586032935884e-06 first col mean 1.0148876754101366e-05 all mean 0.00010186125291511416
8.750099368626252e-05 8.750099368626252e-05
rl training, epoch4, iter0, batch23/1133, batch loss:8.750099368626252e-05, Training time:60343.04622554779
batch reward last col mean 1.6998346836771816e-05 first col mean 1.8363858544034883e-05 all mean 3.532200935296714e-05
1.8821296180249192e-05 1.8821292542270385e-05
rl training, epoch4, iter0, batch24/1133, batch loss:1.8821292542270385e-05, Training time:60359.934134721756
batch reward last col mean 9.708830475574359e-05 first col mean 2.7924328605877236e-05 all mean 4.3354189983801916e-05
2.1787633158965036e-05 2.1787633158965036e-05
rl training, epoch4, iter0, batch25/1133, batch loss:2.1787633158965036e-05, Training time:60376.70281791687
batch reward last col mean 3.400903551664669e-06 first col mean 3.375946562300669e-06 all mean 2.204771590186283e-05
1.2010660611849744e-05 1.2010657883365639e-05
rl training, epoch4, iter0, batch26/1133, batch loss:1.2010657883365639e-05, Training time:60393.25132012367
batch reward last col mean 3.87489171771449e-06 first col mean 3.4677312214626e-05 all mean 4.2306248360546306e-05
9.552437404636294e-05 9.552437404636294e-05
rl training, epoch4, iter0, batch27/1133, batch loss:9.552437404636294e-05, Training time:60409.8417737484
batch reward last col mean 2.0972394850105047e-05 first col mean 3.847145308100153e-06 all mean 6.52965682093054e-05
3.7340847484301776e-05 3.7340836570365354e-05
rl training, epoch4, iter0, batch28/1133, batch loss:3.7340836570365354e-05, Training time:60426.88910651207
batch reward last col mean 4.5355445763561875e-05 first col mean 5.294479251460871e-06 all mean 4.792367690242827e-05
1.8856038877856918e-05 1.88560297829099e-05
rl training, epoch4, iter0, batch29/1133, batch loss:1.88560297829099e-05, Training time:60443.48286867142
batch reward last col mean 3.7961776797601487e-06 first col mean 8.986722605186515e-06 all mean 8.505136793246493e-05
1.816571966628544e-05 1.816572512325365e-05
rl training, epoch4, iter0, batch30/1133, batch loss:1.816572512325365e-05, Training time:60460.18424296379
batch reward last col mean 7.83871473686304e-06 first col mean 2.314597077202052e-05 all mean 3.5732489777728915e-05
3.793942232732661e-05 3.7939418689347804e-05
rl training, epoch4, iter0, batch31/1133, batch loss:3.7939418689347804e-05, Training time:60478.196177482605
batch reward last col mean 8.445391358691268e-06 first col mean 0.00021983114129398018 all mean 6.892667443025857e-05
2.514408879505936e-05 2.514408879505936e-05
rl training, epoch4, iter0, batch32/1133, batch loss:2.514408879505936e-05, Training time:60495.15202498436
batch reward last col mean 1.1086494851042517e-05 first col mean 2.4624994694022462e-05 all mean 6.41447477391921e-05
2.2555630494025536e-05 2.255563776998315e-05
rl training, epoch4, iter0, batch33/1133, batch loss:2.255563776998315e-05, Training time:60512.13877415657
batch reward last col mean 4.047257789352443e-06 first col mean 7.315099537663627e-06 all mean 2.5694154828670435e-05
1.738530227157753e-05 1.738530227157753e-05
rl training, epoch4, iter0, batch34/1133, batch loss:1.738530227157753e-05, Training time:60529.138192653656
batch reward last col mean 6.522296644106973e-06 first col mean 4.295190592529252e-06 all mean 2.9542123229475692e-05
1.4908614502928685e-05 1.4908607226971071e-05
rl training, epoch4, iter0, batch35/1133, batch loss:1.4908607226971071e-05, Training time:60546.03119158745
batch reward last col mean 1.9840726963593625e-05 first col mean 1.1141921277157962e-05 all mean 3.8987698644632474e-05
2.936829514510464e-05 2.9368293326115236e-05
rl training, epoch4, iter0, batch36/1133, batch loss:2.9368293326115236e-05, Training time:60562.88547325134
batch reward last col mean 0.003684626892209053 first col mean 4.7115649067563936e-05 all mean 0.00011356399045325816
0.0004312917299102992 0.00043129175901412964
rl training, epoch4, iter0, batch37/1133, batch loss:0.00043129175901412964, Training time:60579.811375141144
batch reward last col mean 1.9945994154113578e-06 first col mean 2.1840152840013616e-05 all mean 2.8365662728901953e-05
9.55730865825899e-06 9.557305929774884e-06
rl training, epoch4, iter0, batch38/1133, batch loss:9.557305929774884e-06, Training time:60596.718027830124
batch reward last col mean 0.00037582096410915256 first col mean 8.203978723031469e-06 all mean 0.00010159709199797362
9.464804315939546e-05 9.464803588343784e-05
rl training, epoch4, iter0, batch39/1133, batch loss:9.464803588343784e-05, Training time:60613.41155171394
batch reward last col mean 3.8055534332670504e-06 first col mean 4.848607659369009e-06 all mean 3.7448149669216946e-05
1.2188105756649747e-05 1.2188104847155046e-05
rl training, epoch4, iter0, batch40/1133, batch loss:1.2188104847155046e-05, Training time:60630.29045057297
batch reward last col mean 2.3138853066484444e-05 first col mean 7.194574664026732e-06 all mean 6.0053291235817596e-05
5.1526702009141445e-05 5.152670928509906e-05
rl training, epoch4, iter0, batch41/1133, batch loss:5.152670928509906e-05, Training time:60648.07427573204
batch reward last col mean 4.87791039631702e-05 first col mean 2.540628202041262e-06 all mean 3.8723530451534316e-05
1.5774694475112483e-05 1.577468719915487e-05
rl training, epoch4, iter0, batch42/1133, batch loss:1.577468719915487e-05, Training time:60666.666660785675
batch reward last col mean 3.2460771762998775e-05 first col mean 8.237060683313757e-06 all mean 5.794600656372495e-05
3.16708319587633e-05 3.167083559674211e-05
rl training, epoch4, iter0, batch43/1133, batch loss:3.167083559674211e-05, Training time:60683.66111588478
batch reward last col mean 8.98424787010299e-06 first col mean 0.0004779433074872941 all mean 2.592876808193978e-05
1.3233523532107938e-05 1.3233522622613236e-05
rl training, epoch4, iter0, batch44/1133, batch loss:1.3233522622613236e-05, Training time:60700.74987602234
batch reward last col mean 1.8952057416754542e-06 first col mean 7.920276402728632e-06 all mean 2.6483989131520502e-05
4.79393384011928e-06 4.793932475877227e-06
rl training, epoch4, iter0, batch45/1133, batch loss:4.793932475877227e-06, Training time:60717.43143439293
batch reward last col mean 6.009949720464647e-05 first col mean 3.660398942884058e-05 all mean 5.7812165323412046e-05
2.6730604076874442e-05 2.6730614990810864e-05
rl training, epoch4, iter0, batch46/1133, batch loss:2.6730614990810864e-05, Training time:60734.29276895523
batch reward last col mean 0.0001371132821077481 first col mean 1.9476170564303175e-05 all mean 4.918085323879495e-05
4.972158058080822e-05 4.972158421878703e-05
rl training, epoch4, iter0, batch47/1133, batch loss:4.972158421878703e-05, Training time:60751.244879961014
batch reward last col mean 3.482593001535861e-06 first col mean 2.9738303055637516e-05 all mean 2.5772382286959328e-05
6.658131951553514e-06 6.658127404080005e-06
rl training, epoch4, iter0, batch48/1133, batch loss:6.658127404080005e-06, Training time:60768.19804310799
batch reward last col mean 1.6201679500227328e-06 first col mean 4.512519353738753e-06 all mean 2.849999327736441e-05
1.0236158232146408e-05 1.0236154594167601e-05
rl training, epoch4, iter0, batch49/1133, batch loss:1.0236154594167601e-05, Training time:60785.155561208725
batch reward last col mean 4.603760316967964e-06 first col mean 7.12148312231875e-06 all mean 3.9867642044555396e-05
1.925131982716266e-05 1.9251318008173257e-05
rl training, epoch4, iter0, batch50/1133, batch loss:1.9251318008173257e-05, Training time:60802.10717868805
batch reward last col mean 7.96422864368651e-06 first col mean 1.034586239256896e-05 all mean 4.4464577513281256e-05
4.077514313394204e-05 4.0775135857984424e-05
rl training, epoch4, iter0, batch51/1133, batch loss:4.0775135857984424e-05, Training time:60819.06005978584
batch reward last col mean 1.5674794440201367e-06 first col mean 7.125064257706981e-06 all mean 3.150077100144699e-05
1.0399813618278131e-05 1.0399809070804622e-05
rl training, epoch4, iter0, batch52/1133, batch loss:1.0399809070804622e-05, Training time:60835.97926449776
batch reward last col mean 2.5633678887970746e-05 first col mean 2.439711352053564e-05 all mean 4.943656676914543e-05
1.9943341612815857e-05 1.994334343180526e-05
rl training, epoch4, iter0, batch53/1133, batch loss:1.994334343180526e-05, Training time:60852.88854432106
batch reward last col mean 0.0005491698393598199 first col mean 1.1972470019827597e-05 all mean 6.65846819174476e-05
6.404831947293133e-05 6.404831219697371e-05
rl training, epoch4, iter0, batch54/1133, batch loss:6.404831219697371e-05, Training time:60870.15356516838
batch reward last col mean 6.347271119011566e-05 first col mean 1.284628888242878e-05 all mean 3.4163083910243586e-05
3.376227687112987e-05 3.376227687112987e-05
rl training, epoch4, iter0, batch55/1133, batch loss:3.376227687112987e-05, Training time:60886.95896744728
batch reward last col mean 0.00015731905295979232 first col mean 9.056931958184578e-06 all mean 9.439553832635283e-05
4.049806375405751e-05 4.049807830597274e-05
rl training, epoch4, iter0, batch56/1133, batch loss:4.049807830597274e-05, Training time:60903.90502214432
batch reward last col mean 2.4981582100735977e-06 first col mean 3.7940865240670973e-06 all mean 0.00010277153342030942
2.9441665901686065e-05 2.944165862572845e-05
rl training, epoch4, iter0, batch57/1133, batch loss:2.944165862572845e-05, Training time:60920.821244478226
batch reward last col mean 2.732691200435511e-06 first col mean 2.487210622348357e-06 all mean 1.534929651825223e-05
9.280701306124683e-06 9.280700396629982e-06
rl training, epoch4, iter0, batch58/1133, batch loss:9.280700396629982e-06, Training time:60939.42354655266
batch reward last col mean 6.6875859374704305e-06 first col mean 7.727681804681197e-06 all mean 4.5836695790058e-05
2.1917881895205937e-05 2.1917881895205937e-05
rl training, epoch4, iter0, batch59/1133, batch loss:2.1917881895205937e-05, Training time:60957.9382789135
batch reward last col mean 3.525878128129989e-06 first col mean 1.1920215911231935e-05 all mean 3.2819531043060124e-05
1.4713525160914287e-05 1.4713527889398392e-05
rl training, epoch4, iter0, batch60/1133, batch loss:1.4713527889398392e-05, Training time:60976.58451652527
batch reward last col mean 0.00013902815408073366 first col mean 3.975259460275993e-05 all mean 4.2191717511741444e-05
1.6750731447245926e-05 1.6750729628256522e-05
rl training, epoch4, iter0, batch61/1133, batch loss:1.6750729628256522e-05, Training time:60995.26557683945
batch reward last col mean 7.417749657179229e-06 first col mean 0.001428147661499679 all mean 0.00012818395043723285
3.657380511867814e-05 3.657380511867814e-05
rl training, epoch4, iter0, batch62/1133, batch loss:3.657380511867814e-05, Training time:61012.23812150955
batch reward last col mean 6.437130195990903e-06 first col mean 9.171109923045151e-06 all mean 2.057568599411752e-05
8.440051715297159e-06 8.440051715297159e-06
rl training, epoch4, iter0, batch63/1133, batch loss:8.440051715297159e-06, Training time:61030.98887467384
batch reward last col mean 2.504225449229125e-06 first col mean 8.984228770714253e-06 all mean 3.693427788675763e-05
4.074351454619318e-05 4.074351454619318e-05
rl training, epoch4, iter0, batch64/1133, batch loss:4.074351454619318e-05, Training time:61047.93281912804
batch reward last col mean 2.4368922822759487e-05 first col mean 7.445204573741648e-06 all mean 7.012744026724249e-05
4.7867215471342206e-05 4.7867204557405785e-05
rl training, epoch4, iter0, batch65/1133, batch loss:4.7867204557405785e-05, Training time:61064.76004219055
batch reward last col mean 1.111607525672298e-05 first col mean 0.0007050625863485038 all mean 4.782204996445216e-05
3.066015415242873e-05 3.066016506636515e-05
rl training, epoch4, iter0, batch66/1133, batch loss:3.066016506636515e-05, Training time:61081.76365709305
batch reward last col mean 7.776645361445844e-06 first col mean 5.734038495575078e-06 all mean 7.024257502052933e-05
3.7865214835619554e-05 3.7865214835619554e-05
rl training, epoch4, iter0, batch67/1133, batch loss:3.7865214835619554e-05, Training time:61100.700400829315
batch reward last col mean 2.2067511054046918e-06 first col mean 1.6359634173568338e-05 all mean 5.0956154154846445e-05
1.3173434126656502e-05 1.3173449588066433e-05
rl training, epoch4, iter0, batch68/1133, batch loss:1.3173449588066433e-05, Training time:61119.5507748127
batch reward last col mean 7.960854418342933e-06 first col mean 1.5115787391550839e-05 all mean 2.286029302922543e-05
1.2679703104367945e-05 1.267970037588384e-05
rl training, epoch4, iter0, batch69/1133, batch loss:1.267970037588384e-05, Training time:61138.14913868904
batch reward last col mean 1.4994602679507807e-06 first col mean 3.884168108925223e-06 all mean 3.9549402572447434e-05
1.1587578228500206e-05 1.1587563676584978e-05
rl training, epoch4, iter0, batch70/1133, batch loss:1.1587563676584978e-05, Training time:61155.068537950516
batch reward last col mean 2.7502701414050534e-05 first col mean 3.34840979121509e-06 all mean 4.191449988866225e-05
1.496711320214672e-05 1.496711320214672e-05
rl training, epoch4, iter0, batch71/1133, batch loss:1.496711320214672e-05, Training time:61171.978296518326
batch reward last col mean 2.410092747595627e-06 first col mean 3.469907824182883e-06 all mean 3.138461397611536e-05
1.4250061212806031e-05 1.4250067579268944e-05
rl training, epoch4, iter0, batch72/1133, batch loss:1.4250067579268944e-05, Training time:61188.96391034126
batch reward last col mean 8.159116259776056e-05 first col mean 1.7848246898211073e-06 all mean 4.633657226804644e-05
1.4099519830779172e-05 1.4099525287747383e-05
rl training, epoch4, iter0, batch73/1133, batch loss:1.4099525287747383e-05, Training time:61205.85261130333
batch reward last col mean 3.2878597266972065e-06 first col mean 9.554326425131876e-06 all mean 6.269552250159904e-05
4.520883521763608e-05 4.5208827941678464e-05
rl training, epoch4, iter0, batch74/1133, batch loss:4.5208827941678464e-05, Training time:61222.70670461655
batch reward last col mean 3.8298876461340114e-06 first col mean 4.492922380450182e-05 all mean 5.30077850271482e-05
1.0234144610876683e-05 1.023414824885549e-05
rl training, epoch4, iter0, batch75/1133, batch loss:1.023414824885549e-05, Training time:61239.64375305176
batch reward last col mean 1.3819363630318549e-05 first col mean 1.2313582374190446e-05 all mean 5.357086411095224e-05
9.625761776987929e-06 9.62576723395614e-06
rl training, epoch4, iter0, batch76/1133, batch loss:9.62576723395614e-06, Training time:61256.41091775894
batch reward last col mean 4.236565473547671e-06 first col mean 7.906376595201436e-06 all mean 3.897712304024026e-05
1.1411415471229702e-05 1.1411408195272088e-05
rl training, epoch4, iter0, batch77/1133, batch loss:1.1411408195272088e-05, Training time:61273.94525504112
batch reward last col mean 5.9504909586394206e-06 first col mean 1.5731364328530617e-05 all mean 3.6399618693394586e-05
5.336290996638127e-06 5.336297363101039e-06
rl training, epoch4, iter0, batch78/1133, batch loss:5.336297363101039e-06, Training time:61290.83066725731
batch reward last col mean 1.862854514911305e-05 first col mean 7.62364379625069e-06 all mean 7.763758912915364e-05
4.308022471377626e-05 4.308022471377626e-05
rl training, epoch4, iter0, batch79/1133, batch loss:4.308022471377626e-05, Training time:61307.77450466156
batch reward last col mean 2.375526946707396e-06 first col mean 2.9599334084196016e-05 all mean 6.868764467071742e-05
0.00022621615789830685 0.0002262161287944764
rl training, epoch4, iter0, batch80/1133, batch loss:0.0002262161287944764, Training time:61324.75635766983
batch reward last col mean 5.0031587306875736e-05 first col mean 2.11477617995115e-06 all mean 3.9512724470114335e-05
1.4817831470281817e-05 1.481783328927122e-05
rl training, epoch4, iter0, batch81/1133, batch loss:1.481783328927122e-05, Training time:61341.60170817375
batch reward last col mean 5.207914909988176e-06 first col mean 9.875050636765081e-06 all mean 2.7212694476475008e-05
9.540134669805411e-06 9.540138307784218e-06
rl training, epoch4, iter0, batch82/1133, batch loss:9.540138307784218e-06, Training time:61358.469485998154
batch reward last col mean 7.0650430643581785e-06 first col mean 7.742166417301632e-06 all mean 2.9145312510081567e-05
1.0937092156382278e-05 1.0937087608908769e-05
rl training, epoch4, iter0, batch83/1133, batch loss:1.0937087608908769e-05, Training time:61375.378459692
batch reward last col mean 2.3479895389755256e-05 first col mean 5.0493781600380316e-05 all mean 5.25419891346246e-05
2.32102902373299e-05 2.3210293875308707e-05
rl training, epoch4, iter0, batch84/1133, batch loss:2.3210293875308707e-05, Training time:61392.36088681221
batch reward last col mean 2.355244396312628e-05 first col mean 1.9557888663257472e-05 all mean 5.949463593424298e-05
2.7468297048471868e-05 2.7468300686450675e-05
rl training, epoch4, iter0, batch85/1133, batch loss:2.7468300686450675e-05, Training time:61409.28191280365
batch reward last col mean 4.9494828999741e-06 first col mean 2.2393774997908622e-05 all mean 4.9472397222416475e-05
1.5221126886899583e-05 1.5221138710330706e-05
rl training, epoch4, iter0, batch86/1133, batch loss:1.5221138710330706e-05, Training time:61426.12124347687
batch reward last col mean 8.810734470898751e-07 first col mean 8.174575668817852e-06 all mean 3.558851676643826e-05
2.10020734812133e-05 2.1002071662223898e-05
rl training, epoch4, iter0, batch87/1133, batch loss:2.1002071662223898e-05, Training time:61443.11254167557
batch reward last col mean 3.479221732050064e-06 first col mean 3.3540000003995374e-06 all mean 3.747706796275452e-05
7.72061412135372e-06 7.720613211859018e-06
rl training, epoch4, iter0, batch88/1133, batch loss:7.720613211859018e-06, Training time:61460.094558000565
batch reward last col mean 2.8335521164990496e-06 first col mean 4.384907697385643e-06 all mean 1.6065898307715543e-05
8.34340517030796e-06 8.343408808286767e-06
rl training, epoch4, iter0, batch89/1133, batch loss:8.343408808286767e-06, Training time:61476.8861644268
batch reward last col mean 0.00013119788491167128 first col mean 0.00015136330330278724 all mean 7.839829049771652e-05
3.769308750634082e-05 3.7693091144319624e-05
rl training, epoch4, iter0, batch90/1133, batch loss:3.7693091144319624e-05, Training time:61493.70198106766
batch reward last col mean 7.348903181991773e-06 first col mean 8.745109880692326e-06 all mean 4.7368834202643484e-05
2.3504224373027682e-05 2.3504224373027682e-05
rl training, epoch4, iter0, batch91/1133, batch loss:2.3504224373027682e-05, Training time:61510.5064303875
batch reward last col mean 9.378435606777202e-06 first col mean 2.7065947506343946e-05 all mean 6.115675205364823e-05
1.373367922496982e-05 1.3733672858506907e-05
rl training, epoch4, iter0, batch92/1133, batch loss:1.3733672858506907e-05, Training time:61527.33225083351
batch reward last col mean 2.512113724151277e-06 first col mean 6.31041484666639e-06 all mean 3.9465288864448667e-05
1.4397659469977953e-05 1.4397659469977953e-05
rl training, epoch4, iter0, batch93/1133, batch loss:1.4397659469977953e-05, Training time:61544.14797234535
batch reward last col mean 3.1174556625046534e-06 first col mean 0.00017673589172773063 all mean 4.515464388532564e-05
2.113650225510355e-05 2.113650771207176e-05
rl training, epoch4, iter0, batch94/1133, batch loss:2.113650771207176e-05, Training time:61560.688021183014
batch reward last col mean 5.959820555290207e-06 first col mean 6.10857387073338e-05 all mean 6.690531154163182e-05
2.72395718639018e-05 2.7239557311986573e-05
rl training, epoch4, iter0, batch95/1133, batch loss:2.7239557311986573e-05, Training time:61577.55869078636
batch reward last col mean 4.48334412794793e-06 first col mean 8.091726158454549e-06 all mean 6.160728662507609e-05
2.3147949832491577e-05 2.314796620339621e-05
rl training, epoch4, iter0, batch96/1133, batch loss:2.314796620339621e-05, Training time:61594.5040204525
batch reward last col mean 1.518123553978512e-05 first col mean 4.754907058668323e-05 all mean 4.5165095798438415e-05
4.4022272049915045e-05 4.402227932587266e-05
rl training, epoch4, iter0, batch97/1133, batch loss:4.402227932587266e-05, Training time:61612.690752744675
batch reward last col mean 6.65118886900018e-06 first col mean 8.028180673136376e-06 all mean 3.425467002671212e-05
4.825794530916028e-05 4.825795258511789e-05
rl training, epoch4, iter0, batch98/1133, batch loss:4.825795258511789e-05, Training time:61631.133860588074
batch reward last col mean 4.296786300983513e-06 first col mean 1.9995320599264232e-06 all mean 3.8142286939546466e-05
3.516901779221371e-05 3.516901779221371e-05
rl training, epoch4, iter0, batch99/1133, batch loss:3.516901779221371e-05, Training time:61649.79259777069
batch reward last col mean 1.4419144463317934e-05 first col mean 1.1065605576732196e-05 all mean 3.715013372129761e-05
1.0004283467424102e-05 1.0004279829445295e-05
rl training, epoch4, iter0, batch100/1133, batch loss:1.0004279829445295e-05, Training time:61667.0583088398
batch reward last col mean 9.74538670561742e-06 first col mean 2.041584230028093e-05 all mean 7.075736357364804e-05
8.033009362407029e-05 8.033007179619744e-05
rl training, epoch4, iter0, batch101/1133, batch loss:8.033007179619744e-05, Training time:61683.95156741142
batch reward last col mean 9.78652860794682e-06 first col mean 6.3873435465211514e-06 all mean 4.294105383451097e-05
2.648287045303732e-05 2.648287045303732e-05
rl training, epoch4, iter0, batch102/1133, batch loss:2.648287045303732e-05, Training time:61700.78559207916
batch reward last col mean 1.8669981727725826e-05 first col mean 7.798459591867868e-06 all mean 1.2831841559091117e-05
1.3382200449996162e-05 1.338219954050146e-05
rl training, epoch4, iter0, batch103/1133, batch loss:1.338219954050146e-05, Training time:61719.65535855293
batch reward last col mean 2.9952989279991016e-06 first col mean 1.5762213934067404e-06 all mean 5.54712642042432e-05
4.5213568228064105e-05 4.521356095210649e-05
rl training, epoch4, iter0, batch104/1133, batch loss:4.521356095210649e-05, Training time:61736.55026578903
batch reward last col mean 1.7686205637801322e-06 first col mean 0.00015413298388011754 all mean 4.865132723352872e-05
1.2583525858644862e-05 1.2583536772581283e-05
rl training, epoch4, iter0, batch105/1133, batch loss:1.2583536772581283e-05, Training time:61753.4382891655
batch reward last col mean 3.103894414380193e-05 first col mean 6.443369056796655e-05 all mean 5.093050276627764e-05
2.6425608666613698e-05 2.6425603209645487e-05
rl training, epoch4, iter0, batch106/1133, batch loss:2.6425603209645487e-05, Training time:61770.186903476715
batch reward last col mean 7.885652303230017e-05 first col mean 2.2839543817099184e-05 all mean 6.411317008314654e-05
3.091923281317577e-05 3.0919236451154575e-05
rl training, epoch4, iter0, batch107/1133, batch loss:3.0919236451154575e-05, Training time:61786.994330883026
batch reward last col mean 3.470911178737879e-05 first col mean 1.696414801699575e-05 all mean 5.693084676750004e-05
6.049543299013749e-05 6.049543299013749e-05
rl training, epoch4, iter0, batch108/1133, batch loss:6.049543299013749e-05, Training time:61803.880215168
batch reward last col mean 9.188908734358847e-06 first col mean 9.226143447449431e-05 all mean 5.632443571812473e-05
2.671941911103204e-05 2.671941911103204e-05
rl training, epoch4, iter0, batch109/1133, batch loss:2.671941911103204e-05, Training time:61821.48289370537
batch reward last col mean 1.1106876627309248e-05 first col mean 4.074880052939989e-06 all mean 4.27651139034424e-05
1.9223774870624766e-05 1.9223773051635362e-05
rl training, epoch4, iter0, batch110/1133, batch loss:1.9223773051635362e-05, Training time:61838.57457661629
batch reward last col mean 1.3677220522367861e-05 first col mean 6.587236384802964e-06 all mean 7.544204709120095e-05
2.1686224499717355e-05 2.168623177567497e-05
rl training, epoch4, iter0, batch111/1133, batch loss:2.168623177567497e-05, Training time:61855.3439116478
batch reward last col mean 6.351552292471752e-05 first col mean 4.902105501969345e-05 all mean 8.852253085933626e-05
6.012135054334067e-05 6.012134690536186e-05
rl training, epoch4, iter0, batch112/1133, batch loss:6.012134690536186e-05, Training time:61872.087708711624
batch reward last col mean 6.205106274137506e-06 first col mean 1.7837257928476902e-06 all mean 7.493295561289415e-05
2.341254730708897e-05 2.3412560040014796e-05
rl training, epoch4, iter0, batch113/1133, batch loss:2.3412560040014796e-05, Training time:61888.850009441376
batch reward last col mean 1.132795318881108e-06 first col mean 0.00010118786303792149 all mean 4.9048441724153236e-05
1.922424962685909e-05 1.9224255083827302e-05
rl training, epoch4, iter0, batch114/1133, batch loss:1.9224255083827302e-05, Training time:61907.48450946808
batch reward last col mean 6.841291906312108e-06 first col mean 3.153802936139982e-06 all mean 8.339739724760875e-05
5.824501204187982e-05 5.824501204187982e-05
rl training, epoch4, iter0, batch115/1133, batch loss:5.824501204187982e-05, Training time:61926.057473659515
batch reward last col mean 1.2062816495017614e-05 first col mean 3.494739758025389e-06 all mean 3.862829544232227e-05
1.2180090379843023e-05 1.2180089470348321e-05
rl training, epoch4, iter0, batch116/1133, batch loss:1.2180089470348321e-05, Training time:61944.82249927521
batch reward last col mean 1.7632237359066494e-05 first col mean 1.622681156732142e-05 all mean 6.17742189206183e-05
5.489141040015966e-05 5.489141040015966e-05
rl training, epoch4, iter0, batch117/1133, batch loss:5.489141040015966e-05, Training time:61961.723682403564
batch reward last col mean 0.00019006215734407306 first col mean 7.148566510295495e-06 all mean 5.61176311748568e-05
3.4973407309735194e-05 3.497340003377758e-05
rl training, epoch4, iter0, batch118/1133, batch loss:3.497340003377758e-05, Training time:61978.70553779602
batch reward last col mean 4.455722955754027e-05 first col mean 2.3139900804380886e-06 all mean 4.776565401698463e-05
3.4676617360673845e-05 3.467661372269504e-05
rl training, epoch4, iter0, batch119/1133, batch loss:3.467661372269504e-05, Training time:61995.70799660683
batch reward last col mean 2.9366061426117085e-05 first col mean 9.392856009071693e-05 all mean 9.578080789651722e-05
3.8077003409853205e-05 3.807702523772605e-05
rl training, epoch4, iter0, batch120/1133, batch loss:3.807702523772605e-05, Training time:62012.69572019577
batch reward last col mean 6.433653652493376e-06 first col mean 1.7418653442291543e-05 all mean 5.825348853250034e-05
2.2579833967029117e-05 2.257984488096554e-05
rl training, epoch4, iter0, batch121/1133, batch loss:2.257984488096554e-05, Training time:62029.65940117836
batch reward last col mean 7.0239684646367095e-06 first col mean 2.2726282622897997e-05 all mean 6.607086106669158e-05
2.0058336303918622e-05 2.0058338122908026e-05
rl training, epoch4, iter0, batch122/1133, batch loss:2.0058338122908026e-05, Training time:62046.60915994644
batch reward last col mean 0.0002995641843881458 first col mean 1.3989489161758684e-05 all mean 3.520063910400495e-05
6.46174667053856e-05 6.46174667053856e-05
rl training, epoch4, iter0, batch123/1133, batch loss:6.46174667053856e-05, Training time:62063.59365296364
batch reward last col mean 2.772900006675627e-05 first col mean 0.00012266673729754984 all mean 5.255361247691326e-05
1.4389504940481856e-05 1.438950675947126e-05
rl training, epoch4, iter0, batch124/1133, batch loss:1.438950675947126e-05, Training time:62080.57584118843
batch reward last col mean 6.0562879298231564e-06 first col mean 3.3506471481814515e-06 all mean 4.4317799620330334e-05
2.0107203454244882e-05 2.0107205273234285e-05
rl training, epoch4, iter0, batch125/1133, batch loss:2.0107205273234285e-05, Training time:62099.21324753761
batch reward last col mean 2.5944668777810875e-06 first col mean 0.00019539326603990048 all mean 3.041688250959851e-05
3.823978840955533e-05 3.823978840955533e-05
rl training, epoch4, iter0, batch126/1133, batch loss:3.823978840955533e-05, Training time:62116.05777812004
batch reward last col mean 4.536114829534199e-06 first col mean 4.286337207304314e-05 all mean 4.6438661229331046e-05
5.1544113375712186e-05 5.154410973773338e-05
rl training, epoch4, iter0, batch127/1133, batch loss:5.154410973773338e-05, Training time:62132.91631937027
batch reward last col mean 4.114158400625456e-06 first col mean 1.0779111107694916e-05 all mean 2.2899388568475842e-05
9.637115908844862e-06 9.637114089855459e-06
rl training, epoch4, iter0, batch128/1133, batch loss:9.637114089855459e-06, Training time:62149.846172094345
batch reward last col mean 1.2186913409095723e-05 first col mean 9.200086424243636e-06 all mean 2.2845650164526887e-05
3.541202386259101e-05 3.541203113854863e-05
rl training, epoch4, iter0, batch129/1133, batch loss:3.541203113854863e-05, Training time:62168.625135183334
batch reward last col mean 4.344877197581809e-06 first col mean 9.400526323588565e-06 all mean 3.684174225782044e-05
7.74078034737613e-06 7.740779437881429e-06
rl training, epoch4, iter0, batch130/1133, batch loss:7.740779437881429e-06, Training time:62185.525844573975
batch reward last col mean 5.501796749740606e-06 first col mean 2.2909920517122373e-05 all mean 4.472662112675607e-05
1.0988675967382733e-05 1.0988677786372136e-05
rl training, epoch4, iter0, batch131/1133, batch loss:1.0988677786372136e-05, Training time:62204.199063539505
batch reward last col mean 3.1679170206189156e-05 first col mean 0.0002915749792009592 all mean 7.50936014810577e-05
2.1283378373482265e-05 2.1283387468429282e-05
rl training, epoch4, iter0, batch132/1133, batch loss:2.1283387468429282e-05, Training time:62221.115021944046
batch reward last col mean 1.1872332834172994e-05 first col mean 2.8536545869428664e-05 all mean 4.8701356718083844e-05
1.0208018466073554e-05 1.0208013009105343e-05
rl training, epoch4, iter0, batch133/1133, batch loss:1.0208013009105343e-05, Training time:62237.99331378937
batch reward last col mean 1.128264830185799e-05 first col mean 3.322180646136985e-06 all mean 1.965075898624491e-05
1.540739685879089e-05 1.540739685879089e-05
rl training, epoch4, iter0, batch134/1133, batch loss:1.540739685879089e-05, Training time:62254.84899163246
batch reward last col mean 8.25930055725621e-06 first col mean 1.1734889085346367e-05 all mean 7.357686263276264e-05
3.750800897250883e-05 3.750801624846645e-05
rl training, epoch4, iter0, batch135/1133, batch loss:3.750801624846645e-05, Training time:62271.77745056152
batch reward last col mean 1.5199157132883556e-05 first col mean 1.0774899237731006e-05 all mean 6.128825043560937e-05
2.7676851459546015e-05 2.7676851459546015e-05
rl training, epoch4, iter0, batch136/1133, batch loss:2.7676851459546015e-05, Training time:62288.62602329254
batch reward last col mean 3.317314985906705e-05 first col mean 4.075272499903804e-06 all mean 7.15360656613484e-05
0.00017572331125847995 0.00017572329670656472
rl training, epoch4, iter0, batch137/1133, batch loss:0.00017572329670656472, Training time:62305.44601225853
batch reward last col mean 6.314267920970451e-06 first col mean 4.977297521691071e-06 all mean 4.089795402251184e-05
1.0179454875469673e-05 1.0179448509006761e-05
rl training, epoch4, iter0, batch138/1133, batch loss:1.0179448509006761e-05, Training time:62322.2575237751
batch reward last col mean 8.159573553712107e-06 first col mean 6.624972593272105e-05 all mean 6.71579982736148e-05
3.0897481337888166e-05 3.0897481337888166e-05
rl training, epoch4, iter0, batch139/1133, batch loss:3.0897481337888166e-05, Training time:62339.1394264698
batch reward last col mean 1.5896468539722264e-05 first col mean 1.2544390301627573e-05 all mean 5.8955964050255716e-05
1.9733939552679658e-05 1.973393591470085e-05
rl training, epoch4, iter0, batch140/1133, batch loss:1.973393591470085e-05, Training time:62355.98831868172
batch reward last col mean 4.533518949756399e-05 first col mean 1.7920521713676862e-05 all mean 3.2346390071325004e-05
1.675519706623163e-05 1.675519706623163e-05
rl training, epoch4, iter0, batch141/1133, batch loss:1.675519706623163e-05, Training time:62372.71240711212
batch reward last col mean 1.4677352737635374e-05 first col mean 8.464138954877853e-05 all mean 6.766394653823227e-05
2.458722701703664e-05 2.4587216103100218e-05
rl training, epoch4, iter0, batch142/1133, batch loss:2.4587216103100218e-05, Training time:62389.308958768845
batch reward last col mean 1.3948092600912787e-05 first col mean 1.0831713552761357e-05 all mean 4.5333079469855875e-05
2.699037031561602e-05 2.699037031561602e-05
rl training, epoch4, iter0, batch143/1133, batch loss:2.699037031561602e-05, Training time:62407.87990498543
batch reward last col mean 1.4815010217716917e-05 first col mean 5.728023097617552e-06 all mean 4.5228953240439296e-05
2.1521724193007685e-05 2.152172601199709e-05
rl training, epoch4, iter0, batch144/1133, batch loss:2.152172601199709e-05, Training time:62424.897617816925
batch reward last col mean 2.291268856424722e-06 first col mean 0.00012790097389370203 all mean 6.62401071167551e-05
1.7477688743383624e-05 1.7477685105404817e-05
rl training, epoch4, iter0, batch145/1133, batch loss:1.7477685105404817e-05, Training time:62441.76401972771
batch reward last col mean 3.809436066148919e-06 first col mean 7.802541404089425e-06 all mean 6.244139513000846e-05
1.2711363524431363e-05 1.2711363524431363e-05
rl training, epoch4, iter0, batch146/1133, batch loss:1.2711363524431363e-05, Training time:62458.607151031494
batch reward last col mean 7.292767350008944e-06 first col mean 3.717089612109703e-06 all mean 7.377384463325143e-05
8.50848027766915e-06 8.50847482070094e-06
rl training, epoch4, iter0, batch147/1133, batch loss:8.50847482070094e-06, Training time:62476.207544088364
batch reward last col mean 4.995848939870484e-06 first col mean 1.9567651179386303e-05 all mean 4.654494478018023e-05
1.0821763680723961e-05 1.082176822819747e-05
rl training, epoch4, iter0, batch148/1133, batch loss:1.082176822819747e-05, Training time:62493.036787986755
batch reward last col mean 4.8857855290407315e-06 first col mean 3.815082891378552e-06 all mean 2.3555217921966687e-05
1.0773319445434026e-05 1.0773318535939325e-05
rl training, epoch4, iter0, batch149/1133, batch loss:1.0773318535939325e-05, Training time:62509.86618280411
batch reward last col mean 6.091689101594966e-06 first col mean 7.98835390014574e-06 all mean 2.725232843658887e-05
1.0554393156780861e-05 1.055439224728616e-05
rl training, epoch4, iter0, batch150/1133, batch loss:1.055439224728616e-05, Training time:62526.56459212303
batch reward last col mean 7.1049003054213244e-06 first col mean 1.0627814845065586e-05 all mean 4.3953034037258476e-05
3.368025863892399e-05 3.3680247724987566e-05
rl training, epoch4, iter0, batch151/1133, batch loss:3.3680247724987566e-05, Training time:62543.399159908295
batch reward last col mean 2.4762211978668347e-05 first col mean 1.7861534615803976e-06 all mean 3.8934609619900584e-05
1.823810816858895e-05 1.823811180656776e-05
rl training, epoch4, iter0, batch152/1133, batch loss:1.823811180656776e-05, Training time:62560.30529952049
batch reward last col mean 8.230884304794017e-06 first col mean 6.198856681294274e-06 all mean 3.658150671981275e-05
2.861639040929731e-05 2.861639040929731e-05
rl training, epoch4, iter0, batch153/1133, batch loss:2.861639040929731e-05, Training time:62577.19332456589
batch reward last col mean 6.548620149260387e-05 first col mean 2.4401308110100217e-05 all mean 4.858346801484004e-05
1.9460905605228618e-05 1.9460905605228618e-05
rl training, epoch4, iter0, batch154/1133, batch loss:1.9460905605228618e-05, Training time:62594.02288579941
batch reward last col mean 1.2260919902473688e-05 first col mean 4.782628457178362e-05 all mean 5.983340088278055e-05
5.544701707549393e-05 5.5447013437515125e-05
rl training, epoch4, iter0, batch155/1133, batch loss:5.5447013437515125e-05, Training time:62610.9541990757
batch reward last col mean 2.990506345668109e-06 first col mean 1.4185410691425204e-05 all mean 2.4231188945122994e-05
6.08471964369528e-06 6.084724191168789e-06
rl training, epoch4, iter0, batch156/1133, batch loss:6.084724191168789e-06, Training time:62628.00314974785
batch reward last col mean 6.2118183450365905e-06 first col mean 9.800192856346257e-06 all mean 2.8220658350619487e-05
1.9376362615730613e-05 1.9376362615730613e-05
rl training, epoch4, iter0, batch157/1133, batch loss:1.9376362615730613e-05, Training time:62645.021453619
batch reward last col mean 1.281352888327092e-05 first col mean 3.3060707664844813e-06 all mean 2.5995148462243378e-05
9.765082722879015e-06 9.765080903889611e-06
rl training, epoch4, iter0, batch158/1133, batch loss:9.765080903889611e-06, Training time:62662.96868944168
batch reward last col mean 1.502114628237905e-05 first col mean 3.136015493510058e-06 all mean 3.401337380637415e-05
1.9768740457948297e-05 1.9768740457948297e-05
rl training, epoch4, iter0, batch159/1133, batch loss:1.9768740457948297e-05, Training time:62679.87732887268
batch reward last col mean 2.5514736989862286e-06 first col mean 5.334238721843576e-06 all mean 1.6607895304332487e-05
6.184755420690635e-06 6.184755420690635e-06
rl training, epoch4, iter0, batch160/1133, batch loss:6.184755420690635e-06, Training time:62696.760508298874
batch reward last col mean 6.282777758315206e-05 first col mean 5.314225290931063e-06 all mean 4.2752391891554e-05
2.0710511307697743e-05 2.071050403174013e-05
rl training, epoch4, iter0, batch161/1133, batch loss:2.071050403174013e-05, Training time:62713.68122172356
batch reward last col mean 6.764210411347449e-06 first col mean 2.2715041723131435e-06 all mean 2.1916550394962542e-05
3.232230665162206e-05 3.232230665162206e-05
rl training, epoch4, iter0, batch162/1133, batch loss:3.232230665162206e-05, Training time:62731.14931631088
batch reward last col mean 4.989197987015359e-05 first col mean 9.285324267693795e-06 all mean 5.556058749789372e-05
2.7722824597731233e-05 2.772283369267825e-05
rl training, epoch4, iter0, batch163/1133, batch loss:2.772283369267825e-05, Training time:62748.182097435
batch reward last col mean 0.0014840357471257448 first col mean 1.8959945009555668e-05 all mean 5.238746962277219e-05
5.630642772302963e-05 5.630642408505082e-05
rl training, epoch4, iter0, batch164/1133, batch loss:5.630642408505082e-05, Training time:62765.12169456482
batch reward last col mean 5.800203507533297e-05 first col mean 3.7445147427206393e-06 all mean 1.588911072758492e-05
1.3538354323827662e-05 1.3538354323827662e-05
rl training, epoch4, iter0, batch165/1133, batch loss:1.3538354323827662e-05, Training time:62781.96830558777
batch reward last col mean 0.00013980137009639293 first col mean 8.794219320407137e-05 all mean 5.5141917982837185e-05
6.701808160869405e-05 6.701808160869405e-05
rl training, epoch4, iter0, batch166/1133, batch loss:6.701808160869405e-05, Training time:62799.761878967285
batch reward last col mean 0.00025090770213864744 first col mean 6.028808456903789e-06 all mean 7.261183782247826e-05
4.2873558413702995e-05 4.287356568966061e-05
rl training, epoch4, iter0, batch167/1133, batch loss:4.287356568966061e-05, Training time:62816.725059747696
batch reward last col mean 1.0891330020967871e-05 first col mean 3.593898100007209e-06 all mean 3.751386611838825e-05
1.4793323316553142e-05 1.4793328773521353e-05
rl training, epoch4, iter0, batch168/1133, batch loss:1.4793328773521353e-05, Training time:62833.688975572586
batch reward last col mean 5.214948942011688e-06 first col mean 3.5731427487917244e-06 all mean 4.97437831654679e-05
9.573689567332622e-06 9.573689567332622e-06
rl training, epoch4, iter0, batch169/1133, batch loss:9.573689567332622e-06, Training time:62850.62934374809
batch reward last col mean 1.0050334822153673e-06 first col mean 4.938363781548105e-05 all mean 3.1656825740356e-05
6.122580998635385e-06 6.122592822066508e-06
rl training, epoch4, iter0, batch170/1133, batch loss:6.122592822066508e-06, Training time:62867.54117965698
batch reward last col mean 9.78287571342662e-05 first col mean 4.795336280949414e-06 all mean 4.5617496652994305e-05
3.16006044158712e-05 3.160059350193478e-05
rl training, epoch4, iter0, batch171/1133, batch loss:3.160059350193478e-05, Training time:62884.4804315567
batch reward last col mean 1.70320927281864e-05 first col mean 2.6861371225095354e-06 all mean 3.0346036510309204e-05
2.2042027921997942e-05 2.204202610300854e-05
rl training, epoch4, iter0, batch172/1133, batch loss:2.204202610300854e-05, Training time:62901.42726278305
batch reward last col mean 0.00011463843111414462 first col mean 1.1795347745646723e-05 all mean 8.256998989963904e-05
3.9722599467495456e-05 3.9722599467495456e-05
rl training, epoch4, iter0, batch173/1133, batch loss:3.9722599467495456e-05, Training time:62919.89785051346
batch reward last col mean 2.2692183847539127e-05 first col mean 5.216867975832429e-06 all mean 5.46730007044971e-05
2.083682375086937e-05 2.083682375086937e-05
rl training, epoch4, iter0, batch174/1133, batch loss:2.083682375086937e-05, Training time:62938.50984668732
batch reward last col mean 2.2038561837689485e-06 first col mean 1.9205374428565847e-06 all mean 4.9114190915133804e-05
1.3128978025633842e-05 1.3128969840181526e-05
rl training, epoch4, iter0, batch175/1133, batch loss:1.3128969840181526e-05, Training time:62955.41882300377
batch reward last col mean 0.0002485230506863445 first col mean 7.3929468271671794e-06 all mean 8.5117069829721e-05
3.273208858445287e-05 3.2732077670516446e-05
rl training, epoch4, iter0, batch176/1133, batch loss:3.2732077670516446e-05, Training time:62972.25495505333
batch reward last col mean 1.5060232954056119e-06 first col mean 1.2336840882198885e-05 all mean 3.7704496207879856e-05
1.817695374484174e-05 1.8176950106862932e-05
rl training, epoch4, iter0, batch177/1133, batch loss:1.8176950106862932e-05, Training time:62989.15348935127
batch reward last col mean 7.213238404801814e-06 first col mean 1.7305494111496955e-05 all mean 8.533798245480284e-05
3.098975503235124e-05 3.098976958426647e-05
rl training, epoch4, iter0, batch178/1133, batch loss:3.098976958426647e-05, Training time:63005.9435710907
batch reward last col mean 0.00012739651720039546 first col mean 2.0673735434684204e-06 all mean 4.36429436376784e-05
2.3169694031821564e-05 2.3169704945757985e-05
rl training, epoch4, iter0, batch179/1133, batch loss:2.3169704945757985e-05, Training time:63022.725554943085
batch reward last col mean 8.109273039735854e-06 first col mean 2.558416235842742e-05 all mean 3.0375522328540683e-05
1.024904031510232e-05 1.0249033039144706e-05
rl training, epoch4, iter0, batch180/1133, batch loss:1.0249033039144706e-05, Training time:63039.38453245163
batch reward last col mean 3.865742655762006e-06 first col mean 3.891972937708488e-06 all mean 9.875340037979186e-05
2.480175498931203e-05 2.4801764084259048e-05
rl training, epoch4, iter0, batch181/1133, batch loss:2.4801764084259048e-05, Training time:63056.687980890274
batch reward last col mean 5.842747668793891e-06 first col mean 2.3148527361627202e-06 all mean 2.842546018655412e-05
1.2596992746694013e-05 1.259699092770461e-05
rl training, epoch4, iter0, batch182/1133, batch loss:1.259699092770461e-05, Training time:63073.40313386917
batch reward last col mean 4.863266894972185e-06 first col mean 4.205844015814364e-05 all mean 7.631611515535042e-05
1.5988011000445113e-05 1.59880037244875e-05
rl training, epoch4, iter0, batch183/1133, batch loss:1.59880037244875e-05, Training time:63090.42036342621
batch reward last col mean 4.790448656422086e-06 first col mean 3.2669604479451664e-06 all mean 3.8756417779950425e-05
2.8682967240456492e-05 2.8682963602477685e-05
rl training, epoch4, iter0, batch184/1133, batch loss:2.8682963602477685e-05, Training time:63107.29284501076
batch reward last col mean 5.098662768432405e-06 first col mean 7.881233614170924e-06 all mean 3.734745041583665e-05
1.924911884998437e-05 1.924912430695258e-05
rl training, epoch4, iter0, batch185/1133, batch loss:1.924912430695258e-05, Training time:63124.1113755703
batch reward last col mean 3.7796351534780115e-05 first col mean 8.024155249586329e-06 all mean 8.894245547708124e-05
8.441569661954418e-05 8.441571844741702e-05
rl training, epoch4, iter0, batch186/1133, batch loss:8.441571844741702e-05, Training time:63140.831604003906
batch reward last col mean 6.232540727069136e-06 first col mean 5.253792096482357e-06 all mean 3.364724398124963e-05
3.4938380849780515e-05 3.493838448775932e-05
rl training, epoch4, iter0, batch187/1133, batch loss:3.493838448775932e-05, Training time:63157.65078878403
batch reward last col mean 6.434725037252065e-06 first col mean 8.71694919624133e-06 all mean 2.3347922251559794e-05
1.2789715583494399e-05 1.27897164929891e-05
rl training, epoch4, iter0, batch188/1133, batch loss:1.27897164929891e-05, Training time:63176.29354953766
batch reward last col mean 3.9177946746349335e-05 first col mean 3.9003152778605e-06 all mean 2.0226181732141413e-05
7.131745860533556e-06 7.131747224775609e-06
rl training, epoch4, iter0, batch189/1133, batch loss:7.131747224775609e-06, Training time:63193.07267689705
batch reward last col mean 2.3880365915829316e-06 first col mean 1.7180399254357326e-06 all mean 4.5104228775016963e-05
2.3431177396560088e-05 2.3431186491507106e-05
rl training, epoch4, iter0, batch190/1133, batch loss:2.3431186491507106e-05, Training time:63209.660447359085
batch reward last col mean 9.013183444039896e-06 first col mean 7.168013780756155e-06 all mean 6.565354851773009e-05
3.999241016572341e-05 3.999241744168103e-05
rl training, epoch4, iter0, batch191/1133, batch loss:3.999241744168103e-05, Training time:63228.358155965805
batch reward last col mean 6.728371317876736e-06 first col mean 1.0687864232750144e-05 all mean 7.068764534778893e-05
3.525531792547554e-05 3.5255310649517924e-05
rl training, epoch4, iter0, batch192/1133, batch loss:3.5255310649517924e-05, Training time:63246.83276391029
batch reward last col mean 0.0006121799815446138 first col mean 8.468254236504436e-06 all mean 7.106070552254096e-05
8.084826549747959e-05 8.084826549747959e-05
rl training, epoch4, iter0, batch193/1133, batch loss:8.084826549747959e-05, Training time:63265.281613349915
batch reward last col mean 1.7654025214142166e-05 first col mean 1.2879392670583911e-05 all mean 8.224049815908074e-05
0.00011422820534789935 0.00011422819807194173
rl training, epoch4, iter0, batch194/1133, batch loss:0.00011422819807194173, Training time:63283.92163681984
batch reward last col mean 8.095426892396063e-06 first col mean 0.00010891956480918452 all mean 5.8837667893385515e-05
3.388760160305537e-05 3.3887612516991794e-05
rl training, epoch4, iter0, batch195/1133, batch loss:3.3887612516991794e-05, Training time:63302.54500555992
batch reward last col mean 4.560106390272267e-06 first col mean 9.548430170980282e-06 all mean 3.9126847696024925e-05
2.3427517589880154e-05 2.3427517589880154e-05
rl training, epoch4, iter0, batch196/1133, batch loss:2.3427517589880154e-05, Training time:63320.70995402336
batch reward last col mean 1.0323107744625304e-05 first col mean 6.934365046618041e-06 all mean 1.632302337384317e-05
1.135912043537246e-05 1.1359121344867162e-05
rl training, epoch4, iter0, batch197/1133, batch loss:1.1359121344867162e-05, Training time:63337.69316124916
batch reward last col mean 1.1926752449653577e-05 first col mean 1.5140704817895312e-05 all mean 3.926353019778617e-05
1.1364227248122916e-05 1.1364230886101723e-05
rl training, epoch4, iter0, batch198/1133, batch loss:1.1364230886101723e-05, Training time:63354.65143656731
batch reward last col mean 2.6555599106359296e-05 first col mean 2.028603557846509e-05 all mean 4.8570709623163566e-05
1.9510227502905764e-05 1.9510227502905764e-05
rl training, epoch4, iter0, batch199/1133, batch loss:1.9510227502905764e-05, Training time:63371.51647233963
batch reward last col mean 0.00045142797171138227 first col mean 6.600679625989869e-06 all mean 4.909229028271511e-05
2.0914509150316007e-05 2.0914512788294815e-05
rl training, epoch4, iter0, batch200/1133, batch loss:2.0914512788294815e-05, Training time:63388.35567235947
batch reward last col mean 1.8486745148038608e-06 first col mean 4.466192694962956e-05 all mean 1.9941278878832236e-05
1.047627392836148e-05 1.047627392836148e-05
rl training, epoch4, iter0, batch201/1133, batch loss:1.047627392836148e-05, Training time:63405.32743048668
batch reward last col mean 1.0653017852746416e-05 first col mean 1.7020631275954656e-05 all mean 3.347407982801087e-05
1.4956570339563768e-05 1.495656579209026e-05
rl training, epoch4, iter0, batch202/1133, batch loss:1.495656579209026e-05, Training time:63422.08259725571
batch reward last col mean 4.572775196720613e-06 first col mean 3.523834311636165e-05 all mean 0.0001454628654755652
6.460565782617778e-05 6.460565782617778e-05
rl training, epoch4, iter0, batch203/1133, batch loss:6.460565782617778e-05, Training time:63438.99255681038
batch reward last col mean 4.369883390609175e-05 first col mean 7.156142964959145e-05 all mean 5.2280309319030493e-05
1.7646216292632744e-05 1.764621447364334e-05
rl training, epoch4, iter0, batch204/1133, batch loss:1.764621447364334e-05, Training time:63455.929753780365
batch reward last col mean 5.9912392316618934e-05 first col mean 8.133468327287119e-06 all mean 5.272236739983782e-05
2.067772948066704e-05 2.067772402369883e-05
rl training, epoch4, iter0, batch205/1133, batch loss:2.067772402369883e-05, Training time:63472.79803824425
batch reward last col mean 0.0003710821911226958 first col mean 5.616527414531447e-05 all mean 6.582470086868852e-05
6.976169242989272e-05 6.976170698180795e-05
rl training, epoch4, iter0, batch206/1133, batch loss:6.976170698180795e-05, Training time:63491.32363033295
batch reward last col mean 4.206572157272603e-06 first col mean 1.1709988939401228e-05 all mean 1.7119509720942006e-05
7.97136362962192e-06 7.97136362962192e-06
rl training, epoch4, iter0, batch207/1133, batch loss:7.97136362962192e-06, Training time:63507.939146995544
batch reward last col mean 1.7246371498913504e-05 first col mean 4.697365056927083e-06 all mean 4.112269016331993e-05
4.6135555749060586e-05 4.61355630250182e-05
rl training, epoch4, iter0, batch208/1133, batch loss:4.61355630250182e-05, Training time:63524.54037857056
batch reward last col mean 1.1893582723132567e-06 first col mean 2.5253923467971617e-06 all mean 2.6228912247461267e-05
1.7038646547007374e-05 1.703865018498618e-05
rl training, epoch4, iter0, batch209/1133, batch loss:1.703865018498618e-05, Training time:63541.07749581337
batch reward last col mean 6.4090963860508054e-06 first col mean 1.297038579650689e-05 all mean 4.757943679578602e-05
3.0153789339237846e-05 3.0153783882269636e-05
rl training, epoch4, iter0, batch210/1133, batch loss:3.0153783882269636e-05, Training time:63559.27320480347
batch reward last col mean 1.6749998394516297e-05 first col mean 2.496792831152561e-06 all mean 2.5455685317865573e-05
1.4644798284280114e-05 1.4644797374785412e-05
rl training, epoch4, iter0, batch211/1133, batch loss:1.4644797374785412e-05, Training time:63578.06580257416
batch reward last col mean 9.886736734188162e-06 first col mean 1.4363767149916384e-05 all mean 5.167633207747713e-05
4.2301395296817645e-05 4.230138074490242e-05
rl training, epoch4, iter0, batch212/1133, batch loss:4.230138074490242e-05, Training time:63595.02948760986
batch reward last col mean 0.00010794703121064231 first col mean 7.578468648716807e-05 all mean 6.924555782461539e-05
1.949555371538736e-05 1.9495560991344973e-05
rl training, epoch4, iter0, batch213/1133, batch loss:1.9495560991344973e-05, Training time:63612.133883953094
batch reward last col mean 4.71729845230584e-06 first col mean 3.5309751638124e-06 all mean 5.408113429439254e-05
2.1042656953795813e-05 2.104265513480641e-05
rl training, epoch4, iter0, batch214/1133, batch loss:2.104265513480641e-05, Training time:63629.10434293747
batch reward last col mean 8.254034582932945e-06 first col mean 9.941059033735655e-06 all mean 3.61391794285737e-05
6.671915616607293e-05 6.671915616607293e-05
rl training, epoch4, iter0, batch215/1133, batch loss:6.671915616607293e-05, Training time:63646.05699300766
batch reward last col mean 2.114609014824964e-05 first col mean 9.949922241503373e-05 all mean 5.254094867268577e-05
3.5201283026253805e-05 3.520127575029619e-05
rl training, epoch4, iter0, batch216/1133, batch loss:3.520127575029619e-05, Training time:63662.89931678772
batch reward last col mean 6.1830683080188464e-06 first col mean 3.7120826164027676e-05 all mean 4.551042366074398e-05
1.804427847673651e-05 1.8044280295725912e-05
rl training, epoch4, iter0, batch217/1133, batch loss:1.8044280295725912e-05, Training time:63679.72188425064
batch reward last col mean 3.803416984737851e-05 first col mean 5.315713224263163e-06 all mean 2.6298672310076654e-05
1.3397197108133696e-05 1.3397199836617801e-05
rl training, epoch4, iter0, batch218/1133, batch loss:1.3397199836617801e-05, Training time:63696.70251441002
batch reward last col mean 3.854421265714336e-06 first col mean 1.0858117093448527e-05 all mean 2.6381840143585578e-05
1.159967632702319e-05 1.1599675417528488e-05
rl training, epoch4, iter0, batch219/1133, batch loss:1.1599675417528488e-05, Training time:63713.55205488205
batch reward last col mean 8.929586329031736e-05 first col mean 7.641982665518299e-05 all mean 3.927879879483953e-05
3.362310235388577e-05 3.362310235388577e-05
rl training, epoch4, iter0, batch220/1133, batch loss:3.362310235388577e-05, Training time:63731.33365678787
batch reward last col mean 5.109463018015958e-06 first col mean 6.464564648922533e-06 all mean 6.099053280195221e-05
2.360079815844074e-05 2.360080361540895e-05
rl training, epoch4, iter0, batch221/1133, batch loss:2.360080361540895e-05, Training time:63749.77781033516
batch reward last col mean 8.127919136313722e-05 first col mean 7.762134373479057e-06 all mean 3.2747113436926156e-05
2.0569774278555997e-05 2.056977064057719e-05
rl training, epoch4, iter0, batch222/1133, batch loss:2.056977064057719e-05, Training time:63766.60909700394
batch reward last col mean 0.0005316060269251466 first col mean 5.884285201318562e-05 all mean 0.00014232784451451153
9.29795132833533e-05 9.297950600739568e-05
rl training, epoch4, iter0, batch223/1133, batch loss:9.297950600739568e-05, Training time:63783.45291137695
batch reward last col mean 3.991652192780748e-06 first col mean 6.569085599039681e-06 all mean 7.280337013071403e-05
2.1176676455070265e-05 2.1176680093049072e-05
rl training, epoch4, iter0, batch224/1133, batch loss:2.1176680093049072e-05, Training time:63800.217361450195
batch reward last col mean 6.480458523583366e-06 first col mean 6.462256806116784e-06 all mean 2.279855470987968e-05
1.6137240891112015e-05 1.6137246348080225e-05
rl training, epoch4, iter0, batch225/1133, batch loss:1.6137246348080225e-05, Training time:63817.08086323738
batch reward last col mean 1.7730526451487094e-05 first col mean 9.192130164592527e-06 all mean 3.1150189897743985e-05
9.658618182584178e-06 9.658612725615967e-06
rl training, epoch4, iter0, batch226/1133, batch loss:9.658612725615967e-06, Training time:63834.00289106369
batch reward last col mean 5.15981901116902e-06 first col mean 8.950039045885205e-06 all mean 4.1341842006659135e-05
2.272678648296278e-05 2.272678648296278e-05
rl training, epoch4, iter0, batch227/1133, batch loss:2.272678648296278e-05, Training time:63850.91255545616
batch reward last col mean 0.004805080592632294 first col mean 5.565113951888634e-06 all mean 0.0024093121755868196
0.0006816984387114644 0.0006816983805038035
rl training, epoch4, iter0, batch228/1133, batch loss:0.0006816983805038035, Training time:63867.91095495224
batch reward last col mean 7.3839787546603475e-06 first col mean 8.06279422249645e-06 all mean 4.656204691855237e-05
2.49925724347122e-05 2.4992570615722798e-05
rl training, epoch4, iter0, batch229/1133, batch loss:2.4992570615722798e-05, Training time:63885.054651260376
batch reward last col mean 0.0020412164740264416 first col mean 3.73410648535355e-06 all mean 0.00048044242430478334
0.00018365102005191147 0.00018365102005191147
rl training, epoch4, iter0, batch230/1133, batch loss:0.00018365102005191147, Training time:63902.11036539078
batch reward last col mean 5.416135536506772e-06 first col mean 1.786575921869371e-05 all mean 4.016249658889137e-05
1.8929928046418354e-05 1.8929924408439547e-05
rl training, epoch4, iter0, batch231/1133, batch loss:1.8929924408439547e-05, Training time:63918.94780373573
batch reward last col mean 4.3556799937505275e-05 first col mean 8.563665687688626e-06 all mean 6.263008253881708e-05
3.142323112115264e-05 3.142323112115264e-05
rl training, epoch4, iter0, batch232/1133, batch loss:3.142323112115264e-05, Training time:63935.95205903053
batch reward last col mean 2.0123882222833345e-06 first col mean 2.4841472622938454e-05 all mean 2.7113681426271796e-05
1.0189753083977848e-05 1.0189755812461954e-05
rl training, epoch4, iter0, batch233/1133, batch loss:1.0189755812461954e-05, Training time:63953.26972556114
batch reward last col mean 1.3535307516576722e-05 first col mean 9.74205704551423e-06 all mean 6.203834345797077e-05
2.8397709684213623e-05 2.8397716960171238e-05
rl training, epoch4, iter0, batch234/1133, batch loss:2.8397716960171238e-05, Training time:63971.69857978821
batch reward last col mean 3.2784319046186283e-06 first col mean 6.672748895653058e-06 all mean 3.885463593178429e-05
1.5204500414256472e-05 1.5204508599708788e-05
rl training, epoch4, iter0, batch235/1133, batch loss:1.5204508599708788e-05, Training time:63988.90539979935
batch reward last col mean 1.2902662547276122e-06 first col mean 1.9859424355672672e-05 all mean 1.6947375115705654e-05
8.173479727702215e-06 8.173480637196917e-06
rl training, epoch4, iter0, batch236/1133, batch loss:8.173480637196917e-06, Training time:64005.56248378754
batch reward last col mean 3.885837213601917e-05 first col mean 5.666719516739249e-05 all mean 5.7147361076204106e-05
1.631263512535952e-05 1.6312631487380713e-05
rl training, epoch4, iter0, batch237/1133, batch loss:1.6312631487380713e-05, Training time:64023.0298576355
batch reward last col mean 1.6254809452220798e-05 first col mean 1.1944204743485898e-05 all mean 5.100483031128533e-05
1.4858124814054463e-05 1.4858130271022674e-05
rl training, epoch4, iter0, batch238/1133, batch loss:1.4858130271022674e-05, Training time:64039.8402531147
batch reward last col mean 1.363860701530939e-05 first col mean 1.3727320038015023e-05 all mean 3.822962389676832e-05
4.07323932449799e-05 4.073238233104348e-05
rl training, epoch4, iter0, batch239/1133, batch loss:4.073238233104348e-05, Training time:64056.53351736069
batch reward last col mean 0.0009534014388918877 first col mean 3.962013579439372e-06 all mean 4.394397547002882e-05
4.0991664718603715e-05 4.0991675632540137e-05
rl training, epoch4, iter0, batch240/1133, batch loss:4.0991675632540137e-05, Training time:64073.43927907944
batch reward last col mean 2.9805571557517396e-06 first col mean 7.871504749346059e-06 all mean 5.472156044561416e-05
6.88771842760616e-06 6.887707058922388e-06
rl training, epoch4, iter0, batch241/1133, batch loss:6.887707058922388e-06, Training time:64090.233674287796
batch reward last col mean 7.841545448172837e-05 first col mean 9.862475053523667e-06 all mean 4.632649142877199e-05
1.4055359315534588e-05 1.4055362953513395e-05
rl training, epoch4, iter0, batch242/1133, batch loss:1.4055362953513395e-05, Training time:64107.217606544495
batch reward last col mean 7.346021448029205e-06 first col mean 3.979007487941999e-06 all mean 3.851470319204964e-05
1.4214054317562841e-05 1.4214054317562841e-05
rl training, epoch4, iter0, batch243/1133, batch loss:1.4214054317562841e-05, Training time:64124.188091278076
batch reward last col mean 6.283398306550225e-06 first col mean 5.666776814905461e-06 all mean 5.195750782149844e-05
1.7883168766275048e-05 1.7883166947285645e-05
rl training, epoch4, iter0, batch244/1133, batch loss:1.7883166947285645e-05, Training time:64141.09224700928
batch reward last col mean 2.8048559670423856e-06 first col mean 3.655321961559821e-06 all mean 3.867226041620597e-05
1.7076845324481837e-05 1.7076845324481837e-05
rl training, epoch4, iter0, batch245/1133, batch loss:1.7076845324481837e-05, Training time:64157.93035244942
batch reward last col mean 1.3575431694334839e-05 first col mean 3.6380247365741525e-06 all mean 3.359461697982624e-05
9.878545824903995e-06 9.878553100861609e-06
rl training, epoch4, iter0, batch246/1133, batch loss:9.878553100861609e-06, Training time:64174.87533402443
batch reward last col mean 8.031018296605907e-06 first col mean 4.068332600581925e-06 all mean 5.2484843763522804e-05
9.407896141055971e-05 9.40789541346021e-05
rl training, epoch4, iter0, batch247/1133, batch loss:9.40789541346021e-05, Training time:64191.80641937256
batch reward last col mean 1.3939422842668137e-06 first col mean 2.6410277769173263e-06 all mean 1.7924894564202987e-05
2.8299837140366435e-05 2.8299840778345242e-05
rl training, epoch4, iter0, batch248/1133, batch loss:2.8299840778345242e-05, Training time:64208.71469926834
batch reward last col mean 2.22612579818815e-05 first col mean 0.0012527885846793652 all mean 7.933855522423983e-05
5.231028262642212e-05 5.231030081631616e-05
rl training, epoch4, iter0, batch249/1133, batch loss:5.231030081631616e-05, Training time:64225.57700419426
batch reward last col mean 3.456891136011109e-05 first col mean 2.0860647964582313e-06 all mean 2.1308967916411348e-05
9.497867722529918e-06 9.497867722529918e-06
rl training, epoch4, iter0, batch250/1133, batch loss:9.497867722529918e-06, Training time:64242.41340613365
batch reward last col mean 1.21934162962134e-05 first col mean 1.3472672435455024e-05 all mean 8.030268509173766e-05
3.873369860230014e-05 3.873370587825775e-05
rl training, epoch4, iter0, batch251/1133, batch loss:3.873370587825775e-05, Training time:64259.20490336418
batch reward last col mean 1.4776338502997532e-05 first col mean 8.842306851875037e-05 all mean 6.769575702492148e-05
0.00015055564290378243 0.00015055564290378243
rl training, epoch4, iter0, batch252/1133, batch loss:0.00015055564290378243, Training time:64276.269360780716
batch reward last col mean 2.5590904897399014e-06 first col mean 4.170477041043341e-05 all mean 1.9588555005611852e-05
8.969890586740803e-06 8.969891496235505e-06
rl training, epoch4, iter0, batch253/1133, batch loss:8.969891496235505e-06, Training time:64294.993589639664
batch reward last col mean 2.984568482133909e-06 first col mean 0.00021101918537169695 all mean 3.821391146630049e-05
6.947064321138896e-06 6.94707159709651e-06
rl training, epoch4, iter0, batch254/1133, batch loss:6.94707159709651e-06, Training time:64311.86531972885
batch reward last col mean 8.344160050910432e-06 first col mean 0.0001677522959653288 all mean 4.356835052021779e-05
1.676105421211105e-05 1.6761056031100452e-05
rl training, epoch4, iter0, batch255/1133, batch loss:1.6761056031100452e-05, Training time:64328.791061639786
batch reward last col mean 3.6088181332161184e-06 first col mean 4.627613634511363e-06 all mean 2.9421073122648522e-05
2.0610183128155768e-05 2.061017949017696e-05
rl training, epoch4, iter0, batch256/1133, batch loss:2.061017949017696e-05, Training time:64346.72559094429
batch reward last col mean 1.6187643268494867e-05 first col mean 8.394162250624504e-06 all mean 5.1615836127894e-05
1.4718885722686537e-05 1.471888754167594e-05
rl training, epoch4, iter0, batch257/1133, batch loss:1.471888754167594e-05, Training time:64363.530168771744
batch reward last col mean 2.773515006992966e-06 first col mean 5.118382887303596e-06 all mean 5.090225749881938e-05
3.045505036425311e-05 3.0455048545263708e-05
rl training, epoch4, iter0, batch258/1133, batch loss:3.0455048545263708e-05, Training time:64382.28698039055
batch reward last col mean 1.0022804417531006e-05 first col mean 1.8875813111662865e-05 all mean 5.963398143649101e-05
2.6284422347089276e-05 2.6284427804057486e-05
rl training, epoch4, iter0, batch259/1133, batch loss:2.6284427804057486e-05, Training time:64399.17034339905
batch reward last col mean 2.2666954464511946e-05 first col mean 1.098854136216687e-05 all mean 5.083441283204593e-05
2.3455264454241842e-05 2.3455260816263035e-05
rl training, epoch4, iter0, batch260/1133, batch loss:2.3455260816263035e-05, Training time:64416.09655022621
batch reward last col mean 2.5004374037962407e-05 first col mean 2.4053031665971503e-05 all mean 6.88647196511738e-05
2.656583092175424e-05 2.656583092175424e-05
rl training, epoch4, iter0, batch261/1133, batch loss:2.656583092175424e-05, Training time:64433.03841423988
batch reward last col mean 1.184937991638435e-05 first col mean 4.516289664024953e-06 all mean 3.597452450776473e-05
4.07325969717931e-05 4.07325969717931e-05
rl training, epoch4, iter0, batch262/1133, batch loss:4.07325969717931e-05, Training time:64449.95928931236
batch reward last col mean 3.097115768468939e-05 first col mean 6.982283139223e-06 all mean 5.485734436661005e-05
4.4694719690596685e-05 4.46947269665543e-05
rl training, epoch4, iter0, batch263/1133, batch loss:4.46947269665543e-05, Training time:64466.937891960144
batch reward last col mean 2.48119727075391e-06 first col mean 4.8519174015382305e-05 all mean 3.0027094908291474e-05
2.2559619537787512e-05 2.25596140808193e-05
rl training, epoch4, iter0, batch264/1133, batch loss:2.25596140808193e-05, Training time:64485.4443488121
batch reward last col mean 6.62649908917956e-05 first col mean 5.817204055347247e-06 all mean 5.428204167401418e-05
4.4800057366956025e-05 4.4800057366956025e-05
rl training, epoch4, iter0, batch265/1133, batch loss:4.4800057366956025e-05, Training time:64503.84293675423
batch reward last col mean 6.60464047541609e-06 first col mean 5.269320809020428e-06 all mean 3.716337960213423e-05
1.295516540267272e-05 1.2955166312167421e-05
rl training, epoch4, iter0, batch266/1133, batch loss:1.2955166312167421e-05, Training time:64520.75734734535
batch reward last col mean 3.381608257768676e-05 first col mean 6.0729375945811626e-06 all mean 1.906573015730828e-05
1.1520976840984076e-05 1.1520977750478778e-05
rl training, epoch4, iter0, batch267/1133, batch loss:1.1520977750478778e-05, Training time:64537.77308654785
batch reward last col mean 6.275153282331303e-06 first col mean 9.855010830506217e-06 all mean 7.284325693035498e-05
4.5250446419231594e-05 4.5250442781252787e-05
rl training, epoch4, iter0, batch268/1133, batch loss:4.5250442781252787e-05, Training time:64554.72472572327
batch reward last col mean 2.119202326866798e-05 first col mean 2.1488262973434757e-06 all mean 6.588253745576367e-05
9.251939445675816e-06 9.251943993149325e-06
rl training, epoch4, iter0, batch269/1133, batch loss:9.251943993149325e-06, Training time:64571.62921881676
batch reward last col mean 0.00011047935549868271 first col mean 1.868040817498695e-05 all mean 5.66454473300837e-05
1.8486263797967695e-05 1.848626197897829e-05
rl training, epoch4, iter0, batch270/1133, batch loss:1.848626197897829e-05, Training time:64588.48569941521
batch reward last col mean 5.386327757150866e-06 first col mean 3.983190254075453e-06 all mean 6.62083039060235e-05
2.6986341254087165e-05 2.698633943509776e-05
rl training, epoch4, iter0, batch271/1133, batch loss:2.698633943509776e-05, Training time:64605.46009516716
batch reward last col mean 6.159550594020402e-06 first col mean 5.433664227894042e-06 all mean 4.960273508913815e-05
8.008020813576877e-06 8.008028089534491e-06
rl training, epoch4, iter0, batch272/1133, batch loss:8.008028089534491e-06, Training time:64622.37993979454
batch reward last col mean 1.966837999134441e-06 first col mean 4.3926465878030285e-06 all mean 1.910315768327564e-05
7.386949164356338e-06 7.386950983345741e-06
rl training, epoch4, iter0, batch273/1133, batch loss:7.386950983345741e-06, Training time:64639.62311172485
batch reward last col mean 6.426780601032078e-05 first col mean 0.0006421368452720344 all mean 5.417885404312983e-05
3.6912966606905684e-05 3.691297024488449e-05
rl training, epoch4, iter0, batch274/1133, batch loss:3.691297024488449e-05, Training time:64658.250487565994
batch reward last col mean 9.299799785367213e-06 first col mean 3.787353762163548e-06 all mean 5.516521923709661e-05
1.1855569027829915e-05 1.18555608423776e-05
rl training, epoch4, iter0, batch275/1133, batch loss:1.18555608423776e-05, Training time:64676.88778781891
batch reward last col mean 8.045724825933576e-06 first col mean 3.3921310205187183e-06 all mean 1.9452732885838486e-05
5.513883934327168e-06 5.51388484382187e-06
rl training, epoch4, iter0, batch276/1133, batch loss:5.51388484382187e-06, Training time:64695.64345788956
batch reward last col mean 2.1030966763646575e-06 first col mean 5.833730028825812e-05 all mean 3.724345879163593e-05
1.057747704180656e-05 1.0577479770290665e-05
rl training, epoch4, iter0, batch277/1133, batch loss:1.0577479770290665e-05, Training time:64714.29080748558
batch reward last col mean 5.124011750012869e-06 first col mean 2.7331403543939814e-05 all mean 3.795258453465067e-05
8.533179425285198e-06 8.53317033033818e-06
rl training, epoch4, iter0, batch278/1133, batch loss:8.53317033033818e-06, Training time:64731.193137168884
batch reward last col mean 4.72516239824472e-06 first col mean 4.1922485252143815e-06 all mean 1.658246219449211e-05
7.454990281985374e-06 7.4549889177433215e-06
rl training, epoch4, iter0, batch279/1133, batch loss:7.4549889177433215e-06, Training time:64748.02213358879
batch reward last col mean 1.15243237814866e-05 first col mean 6.305712304310873e-05 all mean 2.780596878437791e-05
1.1239118066441733e-05 1.1239118066441733e-05
rl training, epoch4, iter0, batch280/1133, batch loss:1.1239118066441733e-05, Training time:64764.963372945786
batch reward last col mean 2.8800219297409058e-05 first col mean 1.7812573787523434e-05 all mean 9.833317744778469e-05
9.670035797171295e-05 9.670034341979772e-05
rl training, epoch4, iter0, batch281/1133, batch loss:9.670034341979772e-05, Training time:64781.845890522
batch reward last col mean 1.4011185157869477e-05 first col mean 4.17534465668723e-06 all mean 4.751959568238817e-05
0.00010139282676391304 0.00010139281221199781
rl training, epoch4, iter0, batch282/1133, batch loss:0.00010139281221199781, Training time:64798.757157087326
batch reward last col mean 9.697767382021993e-06 first col mean 3.176077007083222e-05 all mean 4.8003403207985684e-05
2.081112324958667e-05 2.081112688756548e-05
rl training, epoch4, iter0, batch283/1133, batch loss:2.081112688756548e-05, Training time:64815.74403810501
batch reward last col mean 1.6074949371613911e-06 first col mean 1.8168277165386826e-05 all mean 5.919348041061312e-05
1.6486706954310648e-05 1.6486719687236473e-05
rl training, epoch4, iter0, batch284/1133, batch loss:1.6486719687236473e-05, Training time:64832.66657781601
batch reward last col mean 1.2327032891334966e-05 first col mean 0.00031068373937159777 all mean 7.787572394590825e-05
2.064419459202327e-05 2.0644192773033865e-05
rl training, epoch4, iter0, batch285/1133, batch loss:2.0644192773033865e-05, Training time:64849.552943229675
batch reward last col mean 6.668055448244559e-06 first col mean 2.321890315215569e-05 all mean 4.20563155785203e-05
1.460760449845111e-05 1.46075990414829e-05
rl training, epoch4, iter0, batch286/1133, batch loss:1.46075990414829e-05, Training time:64866.753188848495
batch reward last col mean 1.1737868135242024e-06 first col mean 2.6743030048237415e-06 all mean 2.034873796219472e-05
3.648629444796825e-06 3.6486339922703337e-06
rl training, epoch4, iter0, batch287/1133, batch loss:3.6486339922703337e-06, Training time:64883.61509823799
batch reward last col mean 2.9481032015610253e-06 first col mean 0.00024455541279166937 all mean 4.532332604867406e-05
9.635188325773925e-05 9.635188325773925e-05
rl training, epoch4, iter0, batch288/1133, batch loss:9.635188325773925e-05, Training time:64900.481427907944
batch reward last col mean 3.9369137994071934e-06 first col mean 5.508302365342388e-06 all mean 2.5316070605185814e-05
5.543009137909394e-06 5.543008683162043e-06
rl training, epoch4, iter0, batch289/1133, batch loss:5.543008683162043e-06, Training time:64917.36307668686
batch reward last col mean 4.624361281457823e-06 first col mean 1.2576654626172967e-05 all mean 2.922122621384915e-05
3.285017555754166e-06 3.2850173283804907e-06
rl training, epoch4, iter0, batch290/1133, batch loss:3.2850173283804907e-06, Training time:64934.28436946869
batch reward last col mean 2.0780631530215032e-05 first col mean 6.189984105731128e-06 all mean 7.088252459652722e-05
9.207949005940463e-06 9.207938092004042e-06
rl training, epoch4, iter0, batch291/1133, batch loss:9.207938092004042e-06, Training time:64951.05561685562
batch reward last col mean 7.741856279608328e-06 first col mean 0.0014611966907978058 all mean 5.1831295422744006e-05
1.0653090612322558e-05 1.0653085155354347e-05
rl training, epoch4, iter0, batch292/1133, batch loss:1.0653085155354347e-05, Training time:64967.92539978027
batch reward last col mean 1.590411011420656e-05 first col mean 2.5519814244034933e-06 all mean 2.6270708985975944e-05
8.648530638311058e-06 8.648533366795164e-06
rl training, epoch4, iter0, batch293/1133, batch loss:8.648533366795164e-06, Training time:64984.766439437866
batch reward last col mean 1.469125254516257e-05 first col mean 2.8349701096885838e-05 all mean 5.376151602831669e-05
2.685678373381961e-05 2.685678373381961e-05
rl training, epoch4, iter0, batch294/1133, batch loss:2.685678373381961e-05, Training time:65001.738521814346
batch reward last col mean 0.0003691992023959756 first col mean 7.796047611918766e-06 all mean 7.971391460159793e-05
5.2304811106296256e-05 5.2304811106296256e-05
rl training, epoch4, iter0, batch295/1133, batch loss:5.2304811106296256e-05, Training time:65018.71229958534
batch reward last col mean 6.3145625972538255e-06 first col mean 4.4213329601916485e-06 all mean 4.3956173612968996e-05
8.929088835429866e-06 8.929093382903375e-06
rl training, epoch4, iter0, batch296/1133, batch loss:8.929093382903375e-06, Training time:65035.70388674736
batch reward last col mean 5.36581001142622e-06 first col mean 5.262195372779388e-06 all mean 6.130654946900904e-05
2.600611696834676e-05 2.600611696834676e-05
rl training, epoch4, iter0, batch297/1133, batch loss:2.600611696834676e-05, Training time:65052.72288751602
batch reward last col mean 4.2187157305306755e-06 first col mean 3.2639575238135876e-06 all mean 6.297196523519233e-05
3.240061778342351e-05 3.240061778342351e-05
rl training, epoch4, iter0, batch298/1133, batch loss:3.240061778342351e-05, Training time:65069.770451784134
batch reward last col mean 1.139905634772731e-05 first col mean 1.315855115535669e-05 all mean 4.796999928657897e-05
2.0377867258503102e-05 2.0377865439513698e-05
rl training, epoch4, iter0, batch299/1133, batch loss:2.0377865439513698e-05, Training time:65086.809540748596
batch reward last col mean 7.03597788742627e-06 first col mean 6.066010246286169e-05 all mean 3.839165219687857e-05
1.4718513739353511e-05 1.4718521015311126e-05
rl training, epoch4, iter0, batch300/1133, batch loss:1.4718521015311126e-05, Training time:65103.78623223305
batch reward last col mean 7.148725853767246e-05 first col mean 4.947120942233596e-06 all mean 2.64942482317565e-05
7.54186330595985e-05 7.541862578364089e-05
rl training, epoch4, iter0, batch301/1133, batch loss:7.541862578364089e-05, Training time:65121.16965723038
batch reward last col mean 1.25050064525567e-05 first col mean 6.83349062455818e-05 all mean 5.5086129577830434e-05
1.150245952885598e-05 1.1502456800371874e-05
rl training, epoch4, iter0, batch302/1133, batch loss:1.1502456800371874e-05, Training time:65139.87691569328
batch reward last col mean 2.5459955850237748e-06 first col mean 9.152977327175904e-06 all mean 7.474017183994874e-05
5.754977973992936e-05 5.754977246397175e-05
rl training, epoch4, iter0, batch303/1133, batch loss:5.754977246397175e-05, Training time:65157.713091135025
batch reward last col mean 0.00031586934346705675 first col mean 5.6889839470386505e-06 all mean 5.161041553947143e-05
2.5926143280230463e-05 2.5926143280230463e-05
rl training, epoch4, iter0, batch304/1133, batch loss:2.5926143280230463e-05, Training time:65174.72177028656
batch reward last col mean 3.949795427615754e-06 first col mean 7.734995051578153e-06 all mean 2.9088794690323994e-05
1.4106538401392754e-05 1.4106539310887456e-05
rl training, epoch4, iter0, batch305/1133, batch loss:1.4106539310887456e-05, Training time:65191.66695713997
batch reward last col mean 9.46906948229298e-06 first col mean 0.00020753752323798835 all mean 3.1807539926376194e-05
1.6271053027594462e-05 1.627105666557327e-05
rl training, epoch4, iter0, batch306/1133, batch loss:1.627105666557327e-05, Training time:65208.401109457016
batch reward last col mean 6.888433745189104e-06 first col mean 9.92823697743006e-06 all mean 8.834979962557554e-05
4.509725476964377e-05 4.509723657974973e-05
rl training, epoch4, iter0, batch307/1133, batch loss:4.509723657974973e-05, Training time:65226.571502923965
batch reward last col mean 8.837819041218609e-05 first col mean 9.592262358637527e-06 all mean 3.342660056659952e-05
1.7071166439563967e-05 1.7071164620574564e-05
rl training, epoch4, iter0, batch308/1133, batch loss:1.7071164620574564e-05, Training time:65243.69574761391
batch reward last col mean 3.6461265153775457e-06 first col mean 2.672265145520214e-05 all mean 5.651026367559098e-05
2.5903629648382775e-05 2.590363146737218e-05
rl training, epoch4, iter0, batch309/1133, batch loss:2.590363146737218e-05, Training time:65260.550629615784
batch reward last col mean 0.0016096712788566947 first col mean 4.0451009226671886e-06 all mean 3.418017877265811e-05
0.00013433671847451478 0.00013433671847451478
rl training, epoch4, iter0, batch310/1133, batch loss:0.00013433671847451478, Training time:65277.45387649536
batch reward last col mean 1.515119151918043e-06 first col mean 4.816464752366301e-06 all mean 2.9660390282515436e-05
1.8277805793331936e-05 1.827780761232134e-05
rl training, epoch4, iter0, batch311/1133, batch loss:1.827780761232134e-05, Training time:65294.53741264343
batch reward last col mean 2.8221563752595102e-06 first col mean 4.337097379902843e-06 all mean 5.522763967746869e-05
6.465033220592886e-05 6.465032492997125e-05
rl training, epoch4, iter0, batch312/1133, batch loss:6.465032492997125e-05, Training time:65311.536321401596
batch reward last col mean 5.849358785781078e-05 first col mean 5.337672973837471e-06 all mean 3.678693974507041e-05
4.8910991608863696e-05 4.8910991608863696e-05
rl training, epoch4, iter0, batch313/1133, batch loss:4.8910991608863696e-05, Training time:65328.4772465229
batch reward last col mean 1.7593245502212085e-05 first col mean 2.369732783336076e-06 all mean 5.1017173973377794e-05
2.299238803971093e-05 2.299238803971093e-05
rl training, epoch4, iter0, batch314/1133, batch loss:2.299238803971093e-05, Training time:65345.34282922745
batch reward last col mean 4.967931090504862e-06 first col mean 1.1259126040386036e-05 all mean 8.749945845920593e-05
0.00011748151882784441 0.00011748152610380203
rl training, epoch4, iter0, batch315/1133, batch loss:0.00011748152610380203, Training time:65362.21440029144
batch reward last col mean 3.825131898338441e-06 first col mean 1.2614015759027097e-05 all mean 0.0001065507167368196
3.905716584995389e-05 3.905716584995389e-05
rl training, epoch4, iter0, batch316/1133, batch loss:3.905716584995389e-05, Training time:65379.03395652771
batch reward last col mean 2.368743298575282e-05 first col mean 1.4597435438190587e-05 all mean 5.298493488226086e-05
2.4720611691009253e-05 2.472060987201985e-05
rl training, epoch4, iter0, batch317/1133, batch loss:2.472060987201985e-05, Training time:65396.074029922485
batch reward last col mean 1.7140546333394013e-05 first col mean 7.738823114777915e-06 all mean 3.6512414226308465e-05
9.336694347439334e-06 9.336696166428737e-06
rl training, epoch4, iter0, batch318/1133, batch loss:9.336696166428737e-06, Training time:65412.916640520096
batch reward last col mean 7.359184110100614e-06 first col mean 3.384999945410527e-05 all mean 1.7314507203991525e-05
1.3297193618200254e-05 1.3297194527694955e-05
rl training, epoch4, iter0, batch319/1133, batch loss:1.3297194527694955e-05, Training time:65429.74850320816
batch reward last col mean 0.000690012238919735 first col mean 9.743346709001344e-06 all mean 8.27752155601047e-05
0.00017351297719869763 0.00017351299175061285
rl training, epoch4, iter0, batch320/1133, batch loss:0.00017351299175061285, Training time:65446.55708384514
batch reward last col mean 9.31218164623715e-06 first col mean 4.9956315706367604e-06 all mean 4.5418615627568215e-05
1.0528537131904159e-05 1.0528536222409457e-05
rl training, epoch4, iter0, batch321/1133, batch loss:1.0528536222409457e-05, Training time:65463.355798244476
batch reward last col mean 2.9393702334346017e-06 first col mean 1.2174180483270902e-05 all mean 3.557204036042094e-05
1.2939210137119517e-05 1.2939212865603622e-05
rl training, epoch4, iter0, batch322/1133, batch loss:1.2939212865603622e-05, Training time:65480.31694364548
batch reward last col mean 1.3774435501545668e-05 first col mean 9.86923259915784e-06 all mean 8.195087139029056e-05
3.026485319423955e-05 3.0264860470197164e-05
rl training, epoch4, iter0, batch323/1133, batch loss:3.0264860470197164e-05, Training time:65497.32700371742
batch reward last col mean 4.0792747313389555e-05 first col mean 1.106393574445974e-05 all mean 3.138485408271663e-05
1.6577172573306598e-05 1.6577165297348984e-05
rl training, epoch4, iter0, batch324/1133, batch loss:1.6577165297348984e-05, Training time:65514.2335395813
batch reward last col mean 0.00023582189169246703 first col mean 2.6131026970688254e-05 all mean 6.935742567293346e-05
3.6431854823604226e-05 3.643184754764661e-05
rl training, epoch4, iter0, batch325/1133, batch loss:3.643184754764661e-05, Training time:65531.1851811409
batch reward last col mean 0.00010235117224510759 first col mean 1.2733868970826734e-05 all mean 0.00011893616465386003
3.90539898944553e-05 3.905396442860365e-05
rl training, epoch4, iter0, batch326/1133, batch loss:3.905396442860365e-05, Training time:65547.96383571625
batch reward last col mean 3.244624531362206e-05 first col mean 3.480039958958514e-05 all mean 9.85510996542871e-05
4.890008858637884e-05 4.890008131042123e-05
rl training, epoch4, iter0, batch327/1133, batch loss:4.890008131042123e-05, Training time:65564.71269655228
batch reward last col mean 7.87254157330608e-06 first col mean 2.056432822428178e-05 all mean 0.00010620417015161365
4.15449176216498e-05 4.15449176216498e-05
rl training, epoch4, iter0, batch328/1133, batch loss:4.15449176216498e-05, Training time:65581.63753056526
batch reward last col mean 3.701601826833212e-06 first col mean 1.8051077859126963e-05 all mean 5.734915248467587e-05
1.944436735357158e-05 1.9444370991550386e-05
rl training, epoch4, iter0, batch329/1133, batch loss:1.9444370991550386e-05, Training time:65598.59172987938
batch reward last col mean 1.4349902812682558e-05 first col mean 6.972145456529688e-06 all mean 4.4124895794084296e-05
1.2760036042891443e-05 1.2760043318849057e-05
rl training, epoch4, iter0, batch330/1133, batch loss:1.2760043318849057e-05, Training time:65615.47738099098
batch reward last col mean 4.470538442546967e-06 first col mean 3.5116718208882958e-06 all mean 4.0054754208540544e-05
7.910946806077845e-06 7.910927706689108e-06
rl training, epoch4, iter0, batch331/1133, batch loss:7.910927706689108e-06, Training time:65632.41781449318
batch reward last col mean 0.0003758111270144582 first col mean 1.3940591998107266e-05 all mean 5.1114744564983994e-05
2.4360097086173482e-05 2.4360093448194675e-05
rl training, epoch4, iter0, batch332/1133, batch loss:2.4360093448194675e-05, Training time:65649.45581626892
batch reward last col mean 6.0991067584836856e-05 first col mean 2.691839881663327e-06 all mean 2.2348556740325876e-05
1.2893318853457458e-05 1.2893318853457458e-05
rl training, epoch4, iter0, batch333/1133, batch loss:1.2893318853457458e-05, Training time:65666.41803741455
batch reward last col mean 3.1723507163405884e-06 first col mean 6.943164044059813e-05 all mean 0.00014298790483735502
4.631845513358712e-05 4.631844785762951e-05
rl training, epoch4, iter0, batch334/1133, batch loss:4.631844785762951e-05, Training time:65683.2943046093
batch reward last col mean 0.0002654962881933898 first col mean 0.0018197438912466168 all mean 9.144822979578748e-05
6.019552529323846e-05 6.019551801728085e-05
rl training, epoch4, iter0, batch335/1133, batch loss:6.019551801728085e-05, Training time:65701.65374779701
batch reward last col mean 2.4366675006604055e-06 first col mean 2.5352380816912046e-06 all mean 3.0862469429848716e-05
5.315197995514609e-06 5.315198905009311e-06
rl training, epoch4, iter0, batch336/1133, batch loss:5.315198905009311e-06, Training time:65718.5708785057
batch reward last col mean 0.00016147157293744385 first col mean 1.620584043848794e-05 all mean 3.562612255336717e-05
7.381939940387383e-05 7.381939940387383e-05
rl training, epoch4, iter0, batch337/1133, batch loss:7.381939940387383e-05, Training time:65735.31287288666
batch reward last col mean 8.170463115675375e-05 first col mean 2.1738822397310287e-05 all mean 4.984711995348334e-05
1.502897976024542e-05 1.5028977941256016e-05
rl training, epoch4, iter0, batch338/1133, batch loss:1.5028977941256016e-05, Training time:65752.1313738823
batch reward last col mean 5.04619174535037e-06 first col mean 3.8494372347486205e-06 all mean 5.629993756883778e-05
1.2895155123260338e-05 1.289515148528153e-05
rl training, epoch4, iter0, batch339/1133, batch loss:1.289515148528153e-05, Training time:65770.59258627892
batch reward last col mean 2.799336925818352e-06 first col mean 2.269932110721129e-06 all mean 4.0333492506761104e-05
2.3394686650135554e-05 2.339469392609317e-05
rl training, epoch4, iter0, batch340/1133, batch loss:2.339469392609317e-05, Training time:65789.29964232445
batch reward last col mean 2.8048008971381932e-05 first col mean 0.00011107217142125592 all mean 8.511492342222482e-05
4.5889093598816544e-05 4.5889104512752965e-05
rl training, epoch4, iter0, batch341/1133, batch loss:4.5889104512752965e-05, Training time:65806.3131172657
batch reward last col mean 1.932291297634947e-06 first col mean 9.904097169055603e-06 all mean 0.00010024726361734793
3.062896212213673e-05 3.062897303607315e-05
rl training, epoch4, iter0, batch342/1133, batch loss:3.062897303607315e-05, Training time:65823.69845747948
batch reward last col mean 0.00030519632855430245 first col mean 6.663890235358849e-05 all mean 8.733237336855382e-05
6.190264684846625e-05 6.190263957250863e-05
rl training, epoch4, iter0, batch343/1133, batch loss:6.190263957250863e-05, Training time:65840.57725405693
batch reward last col mean 2.4618400402687257e-06 first col mean 1.1641140190477017e-05 all mean 4.351571624283679e-05
0.00015327394066844136 0.00015327392611652613
rl training, epoch4, iter0, batch344/1133, batch loss:0.00015327392611652613, Training time:65857.92282366753
batch reward last col mean 3.1076083359948825e-06 first col mean 5.996118943585316e-06 all mean 7.520556391682476e-05
7.669525075471029e-05 7.66952580306679e-05
rl training, epoch4, iter0, batch345/1133, batch loss:7.66952580306679e-05, Training time:65876.47065448761
batch reward last col mean 9.280307494918816e-06 first col mean 5.346204852685332e-05 all mean 3.273871334386058e-05
1.4619852663599886e-05 1.4619850844610482e-05
rl training, epoch4, iter0, batch346/1133, batch loss:1.4619850844610482e-05, Training time:65895.03042554855
batch reward last col mean 2.0334321106929565e-06 first col mean 8.811147381493356e-06 all mean 3.161220593028702e-05
2.1424337319331244e-05 2.142433550034184e-05
rl training, epoch4, iter0, batch347/1133, batch loss:2.142433550034184e-05, Training time:65913.81701827049
batch reward last col mean 7.159317647165153e-06 first col mean 5.925835466769058e-06 all mean 4.796436405740678e-05
3.589995321817696e-05 3.5899960494134575e-05
rl training, epoch4, iter0, batch348/1133, batch loss:3.5899960494134575e-05, Training time:65930.65260267258
batch reward last col mean 5.007300205761567e-05 first col mean 1.78183017851552e-05 all mean 1.58100483531598e-05
1.168926519312663e-05 1.1689266102621332e-05
rl training, epoch4, iter0, batch349/1133, batch loss:1.1689266102621332e-05, Training time:65947.4342508316
batch reward last col mean 4.972631359123625e-06 first col mean 3.921692950825673e-06 all mean 4.839306348003447e-05
3.0946743208914995e-05 3.0946743208914995e-05
rl training, epoch4, iter0, batch350/1133, batch loss:3.0946743208914995e-05, Training time:65964.3205986023
batch reward last col mean 1.4181802725943271e-05 first col mean 5.244415660854429e-06 all mean 6.373187352437526e-05
5.8721419918583706e-05 5.872142719454132e-05
rl training, epoch4, iter0, batch351/1133, batch loss:5.872142719454132e-05, Training time:65981.05190396309
batch reward last col mean 8.256924047600478e-06 first col mean 1.1400918083381839e-05 all mean 1.424267884431174e-05
1.0659379768185318e-05 1.065938067768002e-05
rl training, epoch4, iter0, batch352/1133, batch loss:1.065938067768002e-05, Training time:65997.79277300835
batch reward last col mean 8.689530659466982e-06 first col mean 3.356275556143373e-05 all mean 8.33020094432868e-05
3.39500984409824e-05 3.395008752704598e-05
rl training, epoch4, iter0, batch353/1133, batch loss:3.395008752704598e-05, Training time:66014.7709646225
batch reward last col mean 1.6758316633058712e-05 first col mean 2.05072428798303e-05 all mean 4.12544613936916e-05
1.1373536835890263e-05 1.1373536835890263e-05
rl training, epoch4, iter0, batch354/1133, batch loss:1.1373536835890263e-05, Training time:66031.66717171669
batch reward last col mean 4.176812944933772e-05 first col mean 1.3718434274778701e-05 all mean 0.00011320075282128528
3.085360731347464e-05 3.0853600037517026e-05
rl training, epoch4, iter0, batch355/1133, batch loss:3.0853600037517026e-05, Training time:66048.63154411316
batch reward last col mean 3.2975028716464294e-06 first col mean 3.646999857664923e-06 all mean 6.484220648417249e-05
1.421997876605019e-05 1.4219979675544892e-05
rl training, epoch4, iter0, batch356/1133, batch loss:1.4219979675544892e-05, Training time:66065.45630335808
batch reward last col mean 2.2902821001480334e-05 first col mean 8.009382145246491e-05 all mean 9.655085887061432e-05
6.626275717280805e-05 6.626277172472328e-05
rl training, epoch4, iter0, batch357/1133, batch loss:6.626277172472328e-05, Training time:66082.35512208939
batch reward last col mean 3.258240894865594e-06 first col mean 1.135566208176897e-06 all mean 2.8627839128603227e-05
1.5200808775261976e-05 1.5200814232230186e-05
rl training, epoch4, iter0, batch358/1133, batch loss:1.5200814232230186e-05, Training time:66099.38216757774
batch reward last col mean 7.156836545618717e-06 first col mean 1.1023816114175133e-05 all mean 3.178182305418886e-05
2.213012703577988e-05 2.2130128854769282e-05
rl training, epoch4, iter0, batch359/1133, batch loss:2.2130128854769282e-05, Training time:66116.277780056
batch reward last col mean 7.757683488307521e-05 first col mean 4.0069928218144923e-05 all mean 0.00010000998736359179
0.00011832138989120722 0.0001183213826152496
rl training, epoch4, iter0, batch360/1133, batch loss:0.0001183213826152496, Training time:66133.11689805984
batch reward last col mean 1.1660478776320815e-05 first col mean 4.2610240598150995e-06 all mean 6.438950367737561e-05
2.6318033633287996e-05 2.6318026357330382e-05
rl training, epoch4, iter0, batch361/1133, batch loss:2.6318026357330382e-05, Training time:66150.96003317833
batch reward last col mean 2.048257738351822e-05 first col mean 0.0008345434907823801 all mean 6.640306673943996e-05
2.013987977989018e-05 2.0139857952017337e-05
rl training, epoch4, iter0, batch362/1133, batch loss:2.0139857952017337e-05, Training time:66167.7141187191
batch reward last col mean 0.0015791503246873617 first col mean 7.723244380031247e-06 all mean 0.00011728405661415309
0.00020549357577692717 0.00020549356122501194
rl training, epoch4, iter0, batch363/1133, batch loss:0.00020549356122501194, Training time:66184.60530734062
batch reward last col mean 5.344810051610693e-05 first col mean 0.00011715501022990793 all mean 8.801127114566043e-05
3.290244785603136e-05 3.290244421805255e-05
rl training, epoch4, iter0, batch364/1133, batch loss:3.290244421805255e-05, Training time:66201.47199296951
batch reward last col mean 3.8997959563857876e-06 first col mean 2.442070126562612e-06 all mean 2.4486478650942445e-05
3.928716523660114e-06 3.928717887902167e-06
rl training, epoch4, iter0, batch365/1133, batch loss:3.928717887902167e-06, Training time:66218.30408620834
batch reward last col mean 4.988676664652303e-06 first col mean 9.796386621019337e-06 all mean 3.4491709811845794e-05
1.4571262909157667e-05 1.4571261090168264e-05
rl training, epoch4, iter0, batch366/1133, batch loss:1.4571261090168264e-05, Training time:66235.23722314835
batch reward last col mean 0.0002273596910526976 first col mean 1.487339977757074e-05 all mean 3.183288936270401e-05
3.915874913218431e-05 3.9158745494205505e-05
rl training, epoch4, iter0, batch367/1133, batch loss:3.9158745494205505e-05, Training time:66252.09388327599
batch reward last col mean 8.516469279129524e-06 first col mean 4.233810614096001e-06 all mean 8.35613245726563e-05
2.4268165361718275e-05 2.4268168999697082e-05
rl training, epoch4, iter0, batch368/1133, batch loss:2.4268168999697082e-05, Training time:66268.77034211159
batch reward last col mean 4.405727395351278e-06 first col mean 1.405092280037934e-05 all mean 2.7116928322357126e-05
1.94185740838293e-05 1.941857044585049e-05
rl training, epoch4, iter0, batch369/1133, batch loss:1.941857044585049e-05, Training time:66285.52686214447
batch reward last col mean 8.26533778308658e-06 first col mean 6.200007192092016e-06 all mean 3.3994288969552144e-05
6.407820364984218e-06 6.407828095689183e-06
rl training, epoch4, iter0, batch370/1133, batch loss:6.407828095689183e-06, Training time:66302.04486393929
batch reward last col mean 2.3407430944644148e-06 first col mean 0.0001490987924626097 all mean 4.465848542167805e-05
3.090381505899131e-05 3.090380414505489e-05
rl training, epoch4, iter0, batch371/1133, batch loss:3.090380414505489e-05, Training time:66318.72580051422
batch reward last col mean 0.00034426164347678423 first col mean 9.725344716571271e-05 all mean 0.0001186726221931167
0.0001092872116714716 0.00010928720439551398
rl training, epoch4, iter0, batch372/1133, batch loss:0.00010928720439551398, Training time:66335.440097332
batch reward last col mean 4.976926902600098e-06 first col mean 1.670097844908014e-05 all mean 3.500392267596908e-05
3.314428249723278e-05 3.314427885925397e-05
rl training, epoch4, iter0, batch373/1133, batch loss:3.314427885925397e-05, Training time:66352.1892709732
batch reward last col mean 0.00015549348609056324 first col mean 2.7947024136665277e-05 all mean 9.73852802417241e-05
9.63036363827996e-05 9.630364365875721e-05
rl training, epoch4, iter0, batch374/1133, batch loss:9.630364365875721e-05, Training time:66369.26183962822
batch reward last col mean 7.946310506667942e-05 first col mean 1.696444996923674e-05 all mean 0.00011002413521055132
5.475595753523521e-05 5.4755964811192825e-05
rl training, epoch4, iter0, batch375/1133, batch loss:5.4755964811192825e-05, Training time:66386.50810694695
batch reward last col mean 3.764370194403455e-05 first col mean 6.181921889947262e-06 all mean 6.742540426785126e-05
3.5580043913796544e-05 3.558004027581774e-05
rl training, epoch4, iter0, batch376/1133, batch loss:3.558004027581774e-05, Training time:66403.22460985184
batch reward last col mean 1.2509096450230572e-05 first col mean 1.329835595242912e-05 all mean 4.706997060566209e-05
1.3996787856740411e-05 1.3996775123814587e-05
rl training, epoch4, iter0, batch377/1133, batch loss:1.3996775123814587e-05, Training time:66419.9508049488
batch reward last col mean 1.0351302080380265e-05 first col mean 4.617037848220207e-05 all mean 8.366051042685285e-05
6.004020178806968e-05 6.004020178806968e-05
rl training, epoch4, iter0, batch378/1133, batch loss:6.004020178806968e-05, Training time:66436.69918751717
batch reward last col mean 2.507028511899989e-06 first col mean 9.811595191422384e-06 all mean 3.100130197708495e-05
1.4921243746357504e-05 1.492123647039989e-05
rl training, epoch4, iter0, batch379/1133, batch loss:1.492123647039989e-05, Training time:66453.69510984421
batch reward last col mean 2.0018202121718787e-05 first col mean 5.972817234578542e-06 all mean 1.643080759095028e-05
7.545855169155402e-06 7.545856988144806e-06
rl training, epoch4, iter0, batch380/1133, batch loss:7.545856988144806e-06, Training time:66470.6878144741
batch reward last col mean 1.6795047486084513e-06 first col mean 1.9708406398422085e-05 all mean 3.2361276680603623e-05
9.254191354557406e-06 9.25419863051502e-06
rl training, epoch4, iter0, batch381/1133, batch loss:9.25419863051502e-06, Training time:66487.66826343536
batch reward last col mean 1.1323965054543805e-06 first col mean 2.209630110883154e-06 all mean 3.129858669126406e-05
1.5180052287178114e-05 1.5180057744146325e-05
rl training, epoch4, iter0, batch382/1133, batch loss:1.5180057744146325e-05, Training time:66504.60967326164
batch reward last col mean 1.2213543413963635e-05 first col mean 9.454893188376445e-06 all mean 7.060866482788697e-05
4.402888589538634e-05 4.402887498144992e-05
rl training, epoch4, iter0, batch383/1133, batch loss:4.402887498144992e-05, Training time:66521.53920722008
batch reward last col mean 7.033678684820188e-06 first col mean 7.017900497885421e-05 all mean 5.5255724873859435e-05
4.831209662370384e-05 4.831210389966145e-05
rl training, epoch4, iter0, batch384/1133, batch loss:4.831210389966145e-05, Training time:66538.72987365723
batch reward last col mean 1.7598177919353475e-06 first col mean 5.0370643293717876e-05 all mean 8.49632760946406e-06
4.647185505746165e-06 4.647185960493516e-06
rl training, epoch4, iter0, batch385/1133, batch loss:4.647185960493516e-06, Training time:66555.66824102402
batch reward last col mean 4.446400635060854e-05 first col mean 6.321435193967773e-06 all mean 4.7316309064626694e-05
2.1360978280426934e-05 2.1360978280426934e-05
rl training, epoch4, iter0, batch386/1133, batch loss:2.1360978280426934e-05, Training time:66572.63211083412
batch reward last col mean 1.5950055967550725e-05 first col mean 9.342902558273636e-06 all mean 8.676844299770892e-05
5.2261806558817625e-05 5.2261795644881204e-05
rl training, epoch4, iter0, batch387/1133, batch loss:5.2261795644881204e-05, Training time:66589.70492863655
batch reward last col mean 3.5058687899436336e-06 first col mean 6.504478278657189e-06 all mean 2.2106276446720585e-05
1.5365134458988905e-05 1.5365130821010098e-05
rl training, epoch4, iter0, batch388/1133, batch loss:1.5365130821010098e-05, Training time:66606.53828072548
batch reward last col mean 6.218485395947937e-06 first col mean 6.463651061494602e-06 all mean 4.5981269067851827e-05
1.026826157612959e-05 1.026827249006601e-05
rl training, epoch4, iter0, batch389/1133, batch loss:1.026827249006601e-05, Training time:66624.55935454369
batch reward last col mean 3.299970558146015e-05 first col mean 4.724705286207609e-05 all mean 0.0001021192001644522
3.5157150705344975e-05 3.515715798130259e-05
rl training, epoch4, iter0, batch390/1133, batch loss:3.515715798130259e-05, Training time:66641.47275829315
batch reward last col mean 2.3749635147396475e-06 first col mean 1.9585309928515926e-05 all mean 3.490614108159207e-05
2.067525747406762e-05 2.067525747406762e-05
rl training, epoch4, iter0, batch391/1133, batch loss:2.067525747406762e-05, Training time:66660.09782719612
batch reward last col mean 1.567981598782353e-05 first col mean 1.5061295925988816e-05 all mean 2.4351973479497246e-05
1.4669928532384802e-05 1.4669932170363609e-05
rl training, epoch4, iter0, batch392/1133, batch loss:1.4669932170363609e-05, Training time:66678.2949962616
batch reward last col mean 2.541244384701713e-06 first col mean 1.3718065929424483e-05 all mean 6.909589137649164e-05
3.529393143253401e-05 3.52939277945552e-05
rl training, epoch4, iter0, batch393/1133, batch loss:3.52939277945552e-05, Training time:66695.05520796776
batch reward last col mean 4.199871909804642e-05 first col mean 3.1397215934703127e-05 all mean 5.170893564354628e-05
1.4884939446346834e-05 1.4884940355841536e-05
rl training, epoch4, iter0, batch394/1133, batch loss:1.4884940355841536e-05, Training time:66713.29441380501
batch reward last col mean 0.00016303517622873187 first col mean 3.82204825655208e-06 all mean 5.4329895647242665e-05
4.0799877751851454e-05 4.0799877751851454e-05
rl training, epoch4, iter0, batch395/1133, batch loss:4.0799877751851454e-05, Training time:66730.161952734
batch reward last col mean 5.411263555288315e-05 first col mean 2.713388539632433e-06 all mean 6.336706428555772e-05
9.7924996225629e-05 9.792498167371377e-05
rl training, epoch4, iter0, batch396/1133, batch loss:9.792498167371377e-05, Training time:66747.0973739624
batch reward last col mean 1.1892475413333159e-05 first col mean 1.692311343504116e-05 all mean 2.735444468271453e-05
1.004600926535204e-05 1.0046011993836146e-05
rl training, epoch4, iter0, batch397/1133, batch loss:1.0046011993836146e-05, Training time:66764.28419804573
batch reward last col mean 8.308225005748682e-06 first col mean 3.6665207971964264e-06 all mean 3.259269578848034e-05
7.872298738220707e-06 7.872299647715408e-06
rl training, epoch4, iter0, batch398/1133, batch loss:7.872299647715408e-06, Training time:66781.25315356255
batch reward last col mean 0.0037045839708298445 first col mean 1.1113308573840186e-05 all mean 0.001998382154852152
0.000382810685550794 0.000382810685550794
rl training, epoch4, iter0, batch399/1133, batch loss:0.000382810685550794, Training time:66797.88896012306
batch reward last col mean 4.6549671424145345e-06 first col mean 5.298132236930542e-06 all mean 2.9232023734948598e-05
1.8762513718684204e-05 1.8762513718684204e-05
rl training, epoch4, iter0, batch400/1133, batch loss:1.8762513718684204e-05, Training time:66816.13891410828
batch reward last col mean 2.3353538836090593e-06 first col mean 3.3022927254933165e-06 all mean 3.780057159019634e-05
2.337507794436533e-05 2.337508340133354e-05
rl training, epoch4, iter0, batch401/1133, batch loss:2.337508340133354e-05, Training time:66833.33827257156
batch reward last col mean 1.7389782442478463e-05 first col mean 7.417620508931577e-06 all mean 5.9523361414903775e-05
1.9999584765173495e-05 1.9999595679109916e-05
rl training, epoch4, iter0, batch402/1133, batch loss:1.9999595679109916e-05, Training time:66850.4530620575
batch reward last col mean 3.7462364161910955e-06 first col mean 6.881792069179937e-05 all mean 9.999671601690352e-05
0.00014012918109074235 0.00014012916653882712
rl training, epoch4, iter0, batch403/1133, batch loss:0.00014012916653882712, Training time:66867.72952246666
batch reward last col mean 1.1983307558693923e-05 first col mean 3.251925591030158e-05 all mean 6.92465910105966e-05
1.8571019609225914e-05 1.8571021428215317e-05
rl training, epoch4, iter0, batch404/1133, batch loss:1.8571021428215317e-05, Training time:66886.34555506706
batch reward last col mean 1.0338691936340183e-05 first col mean 1.61257939907955e-05 all mean 6.137294258223847e-05
3.66840286005754e-05 3.668403223855421e-05
rl training, epoch4, iter0, batch405/1133, batch loss:3.668403223855421e-05, Training time:66903.16899323463
batch reward last col mean 0.00013963384844828397 first col mean 2.134591522917617e-05 all mean 8.392745803575963e-05
3.631056097219698e-05 3.631054642028175e-05
rl training, epoch4, iter0, batch406/1133, batch loss:3.631054642028175e-05, Training time:66920.30801558495
batch reward last col mean 0.00014155005919747055 first col mean 3.568303554857266e-06 all mean 5.271279951557517e-05
2.373398638155777e-05 2.3733988200547174e-05
rl training, epoch4, iter0, batch407/1133, batch loss:2.3733988200547174e-05, Training time:66937.1656241417
batch reward last col mean 1.4115768863121048e-05 first col mean 3.5801203921437263e-06 all mean 2.99643179459963e-05
1.2049326869600918e-05 1.2049326869600918e-05
rl training, epoch4, iter0, batch408/1133, batch loss:1.2049326869600918e-05, Training time:66954.07715129852
batch reward last col mean 2.7908240554097574e-06 first col mean 8.985119166027289e-06 all mean 2.974888229800854e-05
1.1667501894407906e-05 1.1667500984913204e-05
rl training, epoch4, iter0, batch409/1133, batch loss:1.1667500984913204e-05, Training time:66971.11485385895
batch reward last col mean 4.701572379417485e-06 first col mean 1.9782646631938405e-05 all mean 8.214634726755321e-05
3.241667945985682e-05 3.241668673581444e-05
rl training, epoch4, iter0, batch410/1133, batch loss:3.241668673581444e-05, Training time:66988.26242375374
batch reward last col mean 3.4369650165899657e-06 first col mean 5.374729153118096e-05 all mean 6.13978918408975e-05
2.468577804393135e-05 2.4685779862920754e-05
rl training, epoch4, iter0, batch411/1133, batch loss:2.4685779862920754e-05, Training time:67005.29824066162
batch reward last col mean 2.151099579350557e-06 first col mean 3.6721062315336894e-06 all mean 3.518366429489106e-05
1.2117192454752512e-05 1.2117193364247214e-05
rl training, epoch4, iter0, batch412/1133, batch loss:1.2117193364247214e-05, Training time:67022.21074414253
batch reward last col mean 1.3665261576534249e-05 first col mean 4.7326753701781854e-05 all mean 9.231198782799765e-05
9.6323543402832e-05 9.632355067878962e-05
rl training, epoch4, iter0, batch413/1133, batch loss:9.632355067878962e-05, Training time:67038.90897345543
batch reward last col mean 0.004520792979747057 first col mean 7.293620456039207e-06 all mean 0.00011692436237353832
0.0004424600920174271 0.000442460150225088
rl training, epoch4, iter0, batch414/1133, batch loss:0.000442460150225088, Training time:67055.67698669434
batch reward last col mean 2.912505578933633e-06 first col mean 3.114365199508029e-06 all mean 4.488532795221545e-05
1.348315072391415e-05 1.348315072391415e-05
rl training, epoch4, iter0, batch415/1133, batch loss:1.348315072391415e-05, Training time:67072.45837283134
batch reward last col mean 2.1789255697513e-05 first col mean 1.7948128515854478e-05 all mean 7.199538231361657e-05
1.9877847080351785e-05 1.9877847080351785e-05
rl training, epoch4, iter0, batch416/1133, batch loss:1.9877847080351785e-05, Training time:67089.15617108345
batch reward last col mean 0.00013225909788161516 first col mean 4.2401516111567616e-05 all mean 0.00010996296623488888
3.6732435546582565e-05 3.6732435546582565e-05
rl training, epoch4, iter0, batch417/1133, batch loss:3.6732435546582565e-05, Training time:67106.23046374321
batch reward last col mean 3.5445045796222985e-05 first col mean 0.0003051560779567808 all mean 5.799859354738146e-05
5.05124444316607e-05 5.05124444316607e-05
rl training, epoch4, iter0, batch418/1133, batch loss:5.05124444316607e-05, Training time:67123.12034273148
batch reward last col mean 4.631716728908941e-05 first col mean 3.307559381937608e-06 all mean 4.587375951814465e-05
2.240027424704749e-05 2.240027424704749e-05
rl training, epoch4, iter0, batch419/1133, batch loss:2.240027424704749e-05, Training time:67140.09759283066
batch reward last col mean 1.2399060551615548e-06 first col mean 2.2241521946853027e-05 all mean 7.772128446958959e-05
1.6127602066262625e-05 1.6127612980199046e-05
rl training, epoch4, iter0, batch420/1133, batch loss:1.6127612980199046e-05, Training time:67156.85864400864
batch reward last col mean 8.01890273578465e-05 first col mean 2.06501608772669e-05 all mean 6.173493602545932e-05
4.6199140342650935e-05 4.6199151256587356e-05
rl training, epoch4, iter0, batch421/1133, batch loss:4.6199151256587356e-05, Training time:67173.69279623032
batch reward last col mean 2.5003171685966663e-05 first col mean 7.700047717662528e-06 all mean 5.773926750407554e-05
1.2995268662052695e-05 1.2995274119020905e-05
rl training, epoch4, iter0, batch422/1133, batch loss:1.2995274119020905e-05, Training time:67190.5389392376
batch reward last col mean 2.0655181288020685e-05 first col mean 1.3127528291079216e-05 all mean 2.1180325347813778e-05
1.1108228136436082e-05 1.1108228136436082e-05
rl training, epoch4, iter0, batch423/1133, batch loss:1.1108228136436082e-05, Training time:67207.38616394997
batch reward last col mean 2.74794456345262e-06 first col mean 1.4978677427279763e-05 all mean 4.7143545089056715e-05
1.8301670934306458e-05 1.8301678210264072e-05
rl training, epoch4, iter0, batch424/1133, batch loss:1.8301678210264072e-05, Training time:67225.8116118908
batch reward last col mean 4.143264504818944e-06 first col mean 5.1521228670026176e-06 all mean 8.209473890019581e-05
0.0001314715191256255 0.00013147149002179503
rl training, epoch4, iter0, batch425/1133, batch loss:0.00013147149002179503, Training time:67242.91531825066
batch reward last col mean 0.00018585829820949584 first col mean 1.6270874766632915e-05 all mean 3.4381781006231904e-05
1.9119559510727413e-05 1.911956314870622e-05
rl training, epoch4, iter0, batch426/1133, batch loss:1.911956314870622e-05, Training time:67259.96772408485
batch reward last col mean 4.0271816033055075e-06 first col mean 6.598964773729676e-06 all mean 2.8859381927759387e-05
0.0001105663541238755 0.0001105663541238755
rl training, epoch4, iter0, batch427/1133, batch loss:0.0001105663541238755, Training time:67276.95135712624
batch reward last col mean 2.1366313376347534e-06 first col mean 9.579607649357058e-06 all mean 2.9772354537271895e-05
9.977972695196513e-06 9.9779663287336e-06
rl training, epoch4, iter0, batch428/1133, batch loss:9.9779663287336e-06, Training time:67293.78542351723
batch reward last col mean 1.2472097296267748e-05 first col mean 7.152618309191894e-06 all mean 2.6462279492989182e-05
1.0256485438731033e-05 1.0256482710246928e-05
rl training, epoch4, iter0, batch429/1133, batch loss:1.0256482710246928e-05, Training time:67310.62920641899
batch reward last col mean 3.9153928810264915e-06 first col mean 9.516289537714329e-06 all mean 6.42056402284652e-05
2.220351598225534e-05 2.220351052528713e-05
rl training, epoch4, iter0, batch430/1133, batch loss:2.220351052528713e-05, Training time:67327.46660423279
batch reward last col mean 6.021938588673947e-06 first col mean 2.6133059236599365e-06 all mean 4.025434100185521e-05
1.2012002116534859e-05 1.2012001207040157e-05
rl training, epoch4, iter0, batch431/1133, batch loss:1.2012001207040157e-05, Training time:67344.36099648476
batch reward last col mean 4.011494638689328e-06 first col mean 3.136815212201327e-05 all mean 6.447629857575521e-05
1.93267496797489e-05 1.9326746041770093e-05
rl training, epoch4, iter0, batch432/1133, batch loss:1.9326746041770093e-05, Training time:67362.58795022964
batch reward last col mean 4.186351816315437e-06 first col mean 7.086271943990141e-05 all mean 2.5988545530708507e-05
1.086706470232457e-05 1.0867061973840464e-05
rl training, epoch4, iter0, batch433/1133, batch loss:1.0867061973840464e-05, Training time:67381.1877708435
batch reward last col mean 7.5191542237007525e-06 first col mean 7.482404726033565e-06 all mean 5.834641706314869e-05
4.4446376705309376e-05 4.444638034328818e-05
rl training, epoch4, iter0, batch434/1133, batch loss:4.444638034328818e-05, Training time:67399.78133678436
batch reward last col mean 2.794544570861035e-06 first col mean 0.001028242171742022 all mean 7.554298645118251e-05
0.00010244021541438997 0.00010244020813843235
rl training, epoch4, iter0, batch435/1133, batch loss:0.00010244020813843235, Training time:67418.34618759155
batch reward last col mean 8.53984420245979e-06 first col mean 4.830943726119585e-05 all mean 2.9386597816483118e-05
2.6259796868544072e-05 2.625978595460765e-05
rl training, epoch4, iter0, batch436/1133, batch loss:2.625978595460765e-05, Training time:67435.27070522308
batch reward last col mean 2.301683707628399e-06 first col mean 1.310882726102136e-05 all mean 4.501485454966314e-05
1.208880257763667e-05 1.2088799849152565e-05
rl training, epoch4, iter0, batch437/1133, batch loss:1.2088799849152565e-05, Training time:67451.95074152946
batch reward last col mean 0.0009298590593971312 first col mean 5.095868618809618e-05 all mean 7.92324062786065e-05
0.00016403193876612931 0.0001640319242142141
rl training, epoch4, iter0, batch438/1133, batch loss:0.0001640319242142141, Training time:67469.61692285538
batch reward last col mean 0.0003571311535779387 first col mean 4.850103869102895e-05 all mean 0.0003742830012924969
5.535316813620739e-05 5.535316813620739e-05
rl training, epoch4, iter0, batch439/1133, batch loss:5.535316813620739e-05, Training time:67488.40511322021
batch reward last col mean 1.1233348232053686e-05 first col mean 6.734506314387545e-06 all mean 2.7666175810736604e-05
1.935912405315321e-05 1.935912405315321e-05
rl training, epoch4, iter0, batch440/1133, batch loss:1.935912405315321e-05, Training time:67506.88623905182
batch reward last col mean 1.8564483980298974e-05 first col mean 6.167763785924762e-05 all mean 6.277536886045709e-05
3.8939735532039776e-05 3.893973189406097e-05
rl training, epoch4, iter0, batch441/1133, batch loss:3.893973189406097e-05, Training time:67525.37958335876
batch reward last col mean 0.0006151319830678403 first col mean 0.0018815274816006422 all mean 7.728104537818581e-05
3.788891262956895e-05 3.7888905353611335e-05
rl training, epoch4, iter0, batch442/1133, batch loss:3.7888905353611335e-05, Training time:67544.11936974525
batch reward last col mean 2.3404809326166287e-06 first col mean 4.424609869602136e-06 all mean 3.123052738374099e-05
4.2808901525859255e-06 4.280888788343873e-06
rl training, epoch4, iter0, batch443/1133, batch loss:4.280888788343873e-06, Training time:67561.2231388092
batch reward last col mean 3.2647490115778055e-06 first col mean 2.1641875719069503e-05 all mean 2.086127824441064e-05
8.439832527074032e-06 8.439830708084628e-06
rl training, epoch4, iter0, batch444/1133, batch loss:8.439830708084628e-06, Training time:67578.02066659927
batch reward last col mean 7.619293319294229e-05 first col mean 2.3862414764153073e-06 all mean 3.5941804526373744e-05
5.1408940635155886e-05 5.1408940635155886e-05
rl training, epoch4, iter0, batch445/1133, batch loss:5.1408940635155886e-05, Training time:67594.83885526657
batch reward last col mean 1.0767125786514953e-05 first col mean 5.673969099007081e-06 all mean 5.337610127753578e-05
1.7886717614601366e-05 1.7886717614601366e-05
rl training, epoch4, iter0, batch446/1133, batch loss:1.7886717614601366e-05, Training time:67611.67586612701
batch reward last col mean 1.39537933137035e-05 first col mean 2.9905306746513816e-06 all mean 3.947343793697655e-05
1.806389082048554e-05 1.806389082048554e-05
rl training, epoch4, iter0, batch447/1133, batch loss:1.806389082048554e-05, Training time:67628.48629903793
batch reward last col mean 2.735934458542033e-06 first col mean 3.6633853596867993e-05 all mean 2.8213589757797308e-05
1.1683149750751909e-05 1.1683151569741312e-05
rl training, epoch4, iter0, batch448/1133, batch loss:1.1683151569741312e-05, Training time:67647.28578662872
batch reward last col mean 5.737900210078806e-05 first col mean 2.2628673832514323e-05 all mean 0.000127272549434565
6.637330807279795e-05 6.637330079684034e-05
rl training, epoch4, iter0, batch449/1133, batch loss:6.637330079684034e-05, Training time:67665.81445908546
batch reward last col mean 9.124654025072232e-05 first col mean 2.1854979422641918e-05 all mean 6.706712883897126e-05
2.8225931600900367e-05 2.822595342877321e-05
rl training, epoch4, iter0, batch450/1133, batch loss:2.822595342877321e-05, Training time:67682.65751886368
batch reward last col mean 1.754890581651125e-05 first col mean 5.098714609630406e-05 all mean 3.1640131055610254e-05
1.559546944918111e-05 1.559546944918111e-05
rl training, epoch4, iter0, batch451/1133, batch loss:1.559546944918111e-05, Training time:67699.51748657227
batch reward last col mean 1.8399859982309863e-05 first col mean 4.836396328755654e-06 all mean 8.17441032268107e-05
0.00011206045019207522 0.00011206045746803284
rl training, epoch4, iter0, batch452/1133, batch loss:0.00011206045746803284, Training time:67716.48142528534
batch reward last col mean 9.427945042261854e-05 first col mean 3.494276370474836e-06 all mean 4.901624924968928e-05
2.782241972454358e-05 2.7822416086564772e-05
rl training, epoch4, iter0, batch453/1133, batch loss:2.7822416086564772e-05, Training time:67733.74567341805
batch reward last col mean 6.590408156625926e-05 first col mean 2.620704981382005e-05 all mean 0.00010993011528626084
5.593853711616248e-05 5.593853711616248e-05
rl training, epoch4, iter0, batch454/1133, batch loss:5.593853711616248e-05, Training time:67750.73253202438
batch reward last col mean 3.504503547446802e-05 first col mean 1.6723579392419197e-05 all mean 5.4254604037851095e-05
3.875006586895324e-05 3.875006586895324e-05
rl training, epoch4, iter0, batch455/1133, batch loss:3.875006586895324e-05, Training time:67767.70927119255
batch reward last col mean 0.00041431636782363057 first col mean 1.1784715752582997e-05 all mean 9.356085502076894e-05
6.499129085568711e-05 6.499129085568711e-05
rl training, epoch4, iter0, batch456/1133, batch loss:6.499129085568711e-05, Training time:67784.69631719589
batch reward last col mean 2.3455435439245775e-05 first col mean 1.1275254109932575e-05 all mean 5.911922926316038e-05
2.67736213572789e-05 2.6773614081321284e-05
rl training, epoch4, iter0, batch457/1133, batch loss:2.6773614081321284e-05, Training time:67801.64493584633
batch reward last col mean 1.5490990335820243e-05 first col mean 3.343906064401381e-05 all mean 5.791260628029704e-05
3.2072843168862164e-05 3.207283589290455e-05
rl training, epoch4, iter0, batch458/1133, batch loss:3.207283589290455e-05, Training time:67818.40022325516
batch reward last col mean 1.5809644537512213e-05 first col mean 1.1659993106150068e-05 all mean 5.4119718697620556e-05
1.069434165401617e-05 1.0694338016037364e-05
rl training, epoch4, iter0, batch459/1133, batch loss:1.0694338016037364e-05, Training time:67835.29064106941
batch reward last col mean 3.161437234666664e-06 first col mean 5.657244400936179e-06 all mean 2.875461541407276e-05
4.858239663008135e-06 4.858235570281977e-06
rl training, epoch4, iter0, batch460/1133, batch loss:4.858235570281977e-06, Training time:67852.17337703705
batch reward last col mean 6.876551196910441e-05 first col mean 4.107795757590793e-05 all mean 5.3263964218785986e-05
1.2870499631389976e-05 1.2870505997852888e-05
rl training, epoch4, iter0, batch461/1133, batch loss:1.2870505997852888e-05, Training time:67868.97795176506
batch reward last col mean 1.3208905329520348e-05 first col mean 9.808686627366114e-06 all mean 3.187299444107339e-05
1.3801164641336072e-05 1.380116827931488e-05
rl training, epoch4, iter0, batch462/1133, batch loss:1.380116827931488e-05, Training time:67885.8274679184
batch reward last col mean 0.00013571638555731624 first col mean 4.093515963177197e-05 all mean 6.023779496899806e-05
3.392068174434826e-05 3.392068174434826e-05
rl training, epoch4, iter0, batch463/1133, batch loss:3.392068174434826e-05, Training time:67902.60677599907
batch reward last col mean 2.004224825213896e-06 first col mean 1.4097303392190952e-05 all mean 2.0968063836335205e-05
1.276265629712725e-05 1.2762654478137847e-05
rl training, epoch4, iter0, batch464/1133, batch loss:1.2762654478137847e-05, Training time:67919.46123623848
batch reward last col mean 1.8908525817096233e-05 first col mean 1.801208964025136e-05 all mean 6.684438267257065e-05
4.479443305172026e-05 4.479442213778384e-05
rl training, epoch4, iter0, batch465/1133, batch loss:4.479442213778384e-05, Training time:67936.26189780235
batch reward last col mean 6.857405242044479e-05 first col mean 5.614946530840825e-06 all mean 2.9951752367196605e-05
1.0423977073514834e-05 1.042397980199894e-05
rl training, epoch4, iter0, batch466/1133, batch loss:1.042397980199894e-05, Training time:67953.12945318222
batch reward last col mean 3.978153017669683e-06 first col mean 3.0602100196119864e-06 all mean 5.610500738839619e-05
3.2856180041562766e-05 3.2856169127626345e-05
rl training, epoch4, iter0, batch467/1133, batch loss:3.2856169127626345e-05, Training time:67969.86767458916
batch reward last col mean 2.68847870756872e-05 first col mean 9.058104296855163e-06 all mean 9.002495062304661e-05
3.890166772180237e-05 3.890167863573879e-05
rl training, epoch4, iter0, batch468/1133, batch loss:3.890167863573879e-05, Training time:67988.48455238342
batch reward last col mean 5.574338501901366e-06 first col mean 0.000148350591189228 all mean 4.8501122364541516e-05
1.7198981367982924e-05 1.7198975911014713e-05
rl training, epoch4, iter0, batch469/1133, batch loss:1.7198975911014713e-05, Training time:68007.32611203194
batch reward last col mean 7.181294677138794e-06 first col mean 2.9675477435375797e-06 all mean 5.071206032880582e-05
3.7912173866061494e-05 3.791217022808269e-05
rl training, epoch4, iter0, batch470/1133, batch loss:3.791217022808269e-05, Training time:68026.15456151962
batch reward last col mean 0.00011245378118474036 first col mean 0.00014835096953902394 all mean 7.848583481973037e-05
0.00015676340262871236 0.00015676340262871236
rl training, epoch4, iter0, batch471/1133, batch loss:0.00015676340262871236, Training time:68043.17659163475
batch reward last col mean 5.244434760243166e-06 first col mean 7.165335409808904e-05 all mean 6.237476191017777e-05
9.540939936414361e-05 9.540937753627077e-05
rl training, epoch4, iter0, batch472/1133, batch loss:9.540937753627077e-05, Training time:68059.89783835411
batch reward last col mean 0.00012635109305847436 first col mean 6.938718797755428e-06 all mean 5.2877381676808e-05
3.3232212445000187e-05 3.323220880702138e-05
rl training, epoch4, iter0, batch473/1133, batch loss:3.323220880702138e-05, Training time:68076.81330490112
batch reward last col mean 8.655550118419342e-06 first col mean 5.1885159336961806e-05 all mean 6.958439917070791e-05
2.8233707780600525e-05 2.8233711418579333e-05
rl training, epoch4, iter0, batch474/1133, batch loss:2.8233711418579333e-05, Training time:68093.89387011528
batch reward last col mean 0.00010212951019639149 first col mean 1.8161652405979112e-05 all mean 0.00010200312681263313
0.00013176989159546793 0.00013176989159546793
rl training, epoch4, iter0, batch475/1133, batch loss:0.00013176989159546793, Training time:68110.60425066948
batch reward last col mean 1.0616538929753006e-05 first col mean 1.046493707690388e-05 all mean 4.8463869461556897e-05
3.07497066387441e-05 3.07497066387441e-05
rl training, epoch4, iter0, batch476/1133, batch loss:3.07497066387441e-05, Training time:68127.60264110565
batch reward last col mean 0.00018910189101006836 first col mean 0.00016154498734977096 all mean 2.9286720746313222e-05
2.2075644665164873e-05 2.2075646484154277e-05
rl training, epoch4, iter0, batch477/1133, batch loss:2.2075646484154277e-05, Training time:68144.41667151451
batch reward last col mean 6.0815429606009275e-05 first col mean 1.7087930245907046e-05 all mean 5.736648745369166e-05
4.0796312532620504e-05 4.0796312532620504e-05
rl training, epoch4, iter0, batch478/1133, batch loss:4.0796312532620504e-05, Training time:68161.13653707504
batch reward last col mean 1.763755062711425e-05 first col mean 6.6425664044800214e-06 all mean 4.796650318894535e-05
3.9507260225946084e-05 3.9507260225946084e-05
rl training, epoch4, iter0, batch479/1133, batch loss:3.9507260225946084e-05, Training time:68178.04800271988
batch reward last col mean 6.8708695835084654e-06 first col mean 7.8003740782151e-06 all mean 3.029897197848186e-05
1.1939113392145373e-05 1.1939110663661268e-05
rl training, epoch4, iter0, batch480/1133, batch loss:1.1939110663661268e-05, Training time:68196.72376799583
batch reward last col mean 6.71550806146115e-05 first col mean 2.845521521521732e-06 all mean 2.409452645224519e-05
1.1440366506576538e-05 1.1440369235060643e-05
rl training, epoch4, iter0, batch481/1133, batch loss:1.1440369235060643e-05, Training time:68215.37301325798
batch reward last col mean 4.0529757825424895e-06 first col mean 7.239606020448264e-06 all mean 6.764670251868665e-05
7.522465602960438e-05 7.522466330556199e-05
rl training, epoch4, iter0, batch482/1133, batch loss:7.522466330556199e-05, Training time:68232.30953526497
batch reward last col mean 4.765609446621966e-06 first col mean 1.5568159142276272e-05 all mean 8.892331970855594e-05
0.00011786034156102687 0.00011786031973315403
rl training, epoch4, iter0, batch483/1133, batch loss:0.00011786031973315403, Training time:68250.05002355576
batch reward last col mean 6.759474217687966e-06 first col mean 4.770923624164425e-06 all mean 2.1813852072227746e-05
1.3042994396528229e-05 1.3042996215517633e-05
rl training, epoch4, iter0, batch484/1133, batch loss:1.3042996215517633e-05, Training time:68266.92217874527
batch reward last col mean 4.125919076614082e-06 first col mean 4.401970727485605e-06 all mean 5.45793300261721e-05
2.6866715415962972e-05 2.6866708140005358e-05
rl training, epoch4, iter0, batch485/1133, batch loss:2.6866708140005358e-05, Training time:68283.66477918625
batch reward last col mean 5.544606210605707e-06 first col mean 6.449396460084245e-05 all mean 5.0741135055432096e-05
3.510135502438061e-05 3.510134411044419e-05
rl training, epoch4, iter0, batch486/1133, batch loss:3.510134411044419e-05, Training time:68300.63475394249
batch reward last col mean 1.7568432667758316e-05 first col mean 9.352724191558082e-06 all mean 2.935817974503152e-05
1.8346494471188635e-05 1.8346490833209828e-05
rl training, epoch4, iter0, batch487/1133, batch loss:1.8346490833209828e-05, Training time:68317.60693502426
batch reward last col mean 3.7516412703553215e-05 first col mean 3.839128112304024e-06 all mean 4.852402344113216e-05
2.1109437511768192e-05 2.110944660671521e-05
rl training, epoch4, iter0, batch488/1133, batch loss:2.110944660671521e-05, Training time:68334.44306063652
batch reward last col mean 0.00013699536793865263 first col mean 1.8405822629574686e-05 all mean 0.00014005314733367413
4.992210597265512e-05 4.992210233467631e-05
rl training, epoch4, iter0, batch489/1133, batch loss:4.992210233467631e-05, Training time:68351.41012740135
batch reward last col mean 1.0129813745152205e-05 first col mean 3.4327706543990644e-06 all mean 4.465725942282006e-05
1.5225590686895885e-05 1.5225579772959463e-05
rl training, epoch4, iter0, batch490/1133, batch loss:1.5225579772959463e-05, Training time:68368.18527770042
batch reward last col mean 3.154598016408272e-05 first col mean 2.2605139747611247e-05 all mean 5.397004133556038e-05
3.56782074959483e-05 3.56782074959483e-05
rl training, epoch4, iter0, batch491/1133, batch loss:3.56782074959483e-05, Training time:68386.8038957119
batch reward last col mean 4.0707432162889745e-06 first col mean 5.779069397249259e-06 all mean 4.4810378312831745e-05
8.921861081034876e-06 8.921858352550771e-06
rl training, epoch4, iter0, batch492/1133, batch loss:8.921858352550771e-06, Training time:68405.15811276436
batch reward last col mean 1.2583584066305775e-05 first col mean 6.832751296315109e-06 all mean 9.129472891800106e-05
0.00010261154238833115 0.0001026115205604583
rl training, epoch4, iter0, batch493/1133, batch loss:0.0001026115205604583, Training time:68423.67403578758
batch reward last col mean 4.9328042223351076e-05 first col mean 2.0204941392876208e-05 all mean 1.7415601178072393e-05
1.023568165692268e-05 1.023568165692268e-05
rl training, epoch4, iter0, batch494/1133, batch loss:1.023568165692268e-05, Training time:68442.24486088753
batch reward last col mean 0.0031676674261689186 first col mean 3.3273943245148985e-06 all mean 0.00014506536535918713
0.00028333679074421525 0.00028333679074421525
rl training, epoch4, iter0, batch495/1133, batch loss:0.00028333679074421525, Training time:68459.18994855881
batch reward last col mean 3.382809882168658e-05 first col mean 2.2433734557125717e-05 all mean 2.6786250600707717e-05
1.797278309823014e-05 1.7972784917219542e-05
rl training, epoch4, iter0, batch496/1133, batch loss:1.7972784917219542e-05, Training time:68476.16687655449
batch reward last col mean 2.0163261069683358e-05 first col mean 0.0007771893870085478 all mean 4.968026769347489e-05
1.77082656591665e-05 1.7708269297145307e-05
rl training, epoch4, iter0, batch497/1133, batch loss:1.7708269297145307e-05, Training time:68493.37423157692
batch reward last col mean 2.265048897243105e-05 first col mean 7.204490884760162e-06 all mean 4.135674316785298e-05
2.160149597330019e-05 2.160149597330019e-05
rl training, epoch4, iter0, batch498/1133, batch loss:2.160149597330019e-05, Training time:68511.98254489899
batch reward last col mean 1.9298444385640323e-05 first col mean 3.778497557505034e-05 all mean 7.20068856026046e-05
3.5605109587777406e-05 3.5605109587777406e-05
rl training, epoch4, iter0, batch499/1133, batch loss:3.5605109587777406e-05, Training time:68528.70807886124
batch reward last col mean 2.0783018044312485e-05 first col mean 1.3813682926411275e-05 all mean 4.384273779578507e-05
2.8283006031415425e-05 2.8283004212426022e-05
rl training, epoch4, iter0, batch500/1133, batch loss:2.8283004212426022e-05, Training time:68545.40900182724
batch reward last col mean 0.00037153251469135284 first col mean 3.502463368931785e-05 all mean 4.9252364988205954e-05
3.7742476706625894e-05 3.77424803446047e-05
rl training, epoch4, iter0, batch501/1133, batch loss:3.77424803446047e-05, Training time:68562.27114963531
batch reward last col mean 3.2570802432019264e-05 first col mean 0.00035586036392487586 all mean 4.837677988689393e-05
8.745711966184899e-05 8.745713421376422e-05
rl training, epoch4, iter0, batch502/1133, batch loss:8.745713421376422e-05, Training time:68579.07488179207
batch reward last col mean 1.7135196685558185e-05 first col mean 6.900308108015452e-06 all mean 6.12507647019811e-05
2.2689562683808617e-05 2.2689562683808617e-05
rl training, epoch4, iter0, batch503/1133, batch loss:2.2689562683808617e-05, Training time:68596.18274259567
batch reward last col mean 1.4834494322712999e-05 first col mean 4.0742920646152925e-06 all mean 5.6890516134444624e-05
1.8548007574281655e-05 1.8548011212260462e-05
rl training, epoch4, iter0, batch504/1133, batch loss:1.8548011212260462e-05, Training time:68613.26148581505
batch reward last col mean 7.551344424427953e-06 first col mean 3.64358947990695e-06 all mean 7.387041114270687e-05
6.154442962724715e-05 6.154442235128954e-05
rl training, epoch4, iter0, batch505/1133, batch loss:6.154442235128954e-05, Training time:68630.3568508625
batch reward last col mean 5.636256901198067e-05 first col mean 7.441339403158054e-05 all mean 9.321231482317671e-05
3.764246866921894e-05 3.764247230719775e-05
rl training, epoch4, iter0, batch506/1133, batch loss:3.764247230719775e-05, Training time:68647.26735258102
batch reward last col mean 4.781321422342444e-06 first col mean 0.00010180094977840781 all mean 4.044287561555393e-05
1.4931007171981037e-05 1.4930996258044615e-05
rl training, epoch4, iter0, batch507/1133, batch loss:1.4930996258044615e-05, Training time:68665.87740540504
batch reward last col mean 1.9738914488698356e-05 first col mean 5.545148269447964e-06 all mean 6.468548235716298e-05
7.027715764706954e-05 7.027715764706954e-05
rl training, epoch4, iter0, batch508/1133, batch loss:7.027715764706954e-05, Training time:68682.70794248581
batch reward last col mean 3.2391656077379594e-06 first col mean 1.0149913578061387e-05 all mean 8.49634307087399e-05
4.055718454765156e-05 4.0557177271693945e-05
rl training, epoch4, iter0, batch509/1133, batch loss:4.0557177271693945e-05, Training time:68699.57700228691
batch reward last col mean 1.4061853107705247e-05 first col mean 7.804565939295571e-06 all mean 3.238639692426659e-05
1.402566886099521e-05 1.4025672498974018e-05
rl training, epoch4, iter0, batch510/1133, batch loss:1.4025672498974018e-05, Training time:68716.40955805779
batch reward last col mean 1.7276211110583972e-06 first col mean 3.5506241147231776e-06 all mean 5.1721355703193694e-05
1.5454661479452625e-05 1.5454661479452625e-05
rl training, epoch4, iter0, batch511/1133, batch loss:1.5454661479452625e-05, Training time:68733.25846242905
batch reward last col mean 1.2393120414344594e-05 first col mean 4.531237664195942e-06 all mean 4.1912338929250836e-05
1.9530087229213677e-05 1.953008904820308e-05
rl training, epoch4, iter0, batch512/1133, batch loss:1.953008904820308e-05, Training time:68750.20784330368
batch reward last col mean 1.039536073221825e-05 first col mean 2.3969461835804395e-05 all mean 7.576617645099759e-05
2.875239442801103e-05 2.8752387152053416e-05
rl training, epoch4, iter0, batch513/1133, batch loss:2.8752387152053416e-05, Training time:68767.15166521072
batch reward last col mean 0.00011822485248558223 first col mean 2.278542160638608e-05 all mean 5.035129652242176e-05
2.1816544176544994e-05 2.1816538719576783e-05
rl training, epoch4, iter0, batch514/1133, batch loss:2.1816538719576783e-05, Training time:68784.00293803215
batch reward last col mean 3.701402420119848e-06 first col mean 1.3221005247032735e-05 all mean 4.345095658209175e-05
1.1031459507648833e-05 1.1031464055122342e-05
rl training, epoch4, iter0, batch515/1133, batch loss:1.1031464055122342e-05, Training time:68800.8704957962
batch reward last col mean 6.177164777909638e-06 first col mean 2.3796005734766368e-06 all mean 4.779380833497271e-05
7.078944236127427e-06 7.078936050675111e-06
rl training, epoch4, iter0, batch516/1133, batch loss:7.078936050675111e-06, Training time:68817.91266870499
batch reward last col mean 0.00020559539552778006 first col mean 3.0795516067883e-05 all mean 7.360380550380796e-05
6.374745134962723e-05 6.3747436797712e-05
rl training, epoch4, iter0, batch517/1133, batch loss:6.3747436797712e-05, Training time:68834.97559261322
batch reward last col mean 7.506521797040477e-06 first col mean 2.657395725691458e-06 all mean 3.702857065945864e-05
3.174039738951251e-05 3.17403937515337e-05
rl training, epoch4, iter0, batch518/1133, batch loss:3.17403937515337e-05, Training time:68851.95761108398
batch reward last col mean 6.194954494276317e-06 first col mean 1.0714988093241118e-05 all mean 4.78850124636665e-05
2.518575274734758e-05 2.5185747290379368e-05
rl training, epoch4, iter0, batch519/1133, batch loss:2.5185747290379368e-05, Training time:68869.00670361519
batch reward last col mean 4.849435754294973e-06 first col mean 4.802411422133446e-05 all mean 3.523858686094172e-05
1.9876781152561307e-05 1.98767775145825e-05
rl training, epoch4, iter0, batch520/1133, batch loss:1.98767775145825e-05, Training time:68885.87915110588
batch reward last col mean 9.17424858926097e-06 first col mean 4.7485073082498275e-06 all mean 4.125383566133678e-05
1.3801073691865895e-05 1.3801068234897684e-05
rl training, epoch4, iter0, batch521/1133, batch loss:1.3801068234897684e-05, Training time:68902.85246491432
batch reward last col mean 6.880544242449105e-05 first col mean 5.735313152399613e-06 all mean 3.7792986404383555e-05
2.815550396917388e-05 2.815550033119507e-05
rl training, epoch4, iter0, batch522/1133, batch loss:2.815550033119507e-05, Training time:68919.51594805717
batch reward last col mean 6.164681963127805e-06 first col mean 6.999197466939222e-06 all mean 7.347914652200416e-05
1.9482557036099024e-05 1.9482553398120217e-05
rl training, epoch4, iter0, batch523/1133, batch loss:1.9482553398120217e-05, Training time:68937.02880430222
batch reward last col mean 1.9660192265291698e-05 first col mean 5.577303818427026e-05 all mean 5.728329415433109e-05
3.261100209783763e-05 3.261100937379524e-05
rl training, epoch4, iter0, batch524/1133, batch loss:3.261100937379524e-05, Training time:68954.30151677132
batch reward last col mean 9.210833377437666e-05 first col mean 1.210402047036041e-06 all mean 1.367526056128554e-05
1.1289519534329884e-05 1.1289516805845778e-05
rl training, epoch4, iter0, batch525/1133, batch loss:1.1289516805845778e-05, Training time:68971.16265153885
batch reward last col mean 2.7113661417388357e-05 first col mean 6.69570144964382e-05 all mean 3.172652577632107e-05
1.1341559002175927e-05 1.134156082116533e-05
rl training, epoch4, iter0, batch526/1133, batch loss:1.134156082116533e-05, Training time:68989.05545544624
batch reward last col mean 5.408089418779127e-05 first col mean 2.300839696545154e-05 all mean 6.435226532630622e-05
2.831711753970012e-05 2.8317124815657735e-05
rl training, epoch4, iter0, batch527/1133, batch loss:2.8317124815657735e-05, Training time:69005.95291948318
batch reward last col mean 0.00018079410074278712 first col mean 3.5205208405386657e-05 all mean 6.230134749785066e-05
0.00014901248505339026 0.00014901247050147504
rl training, epoch4, iter0, batch528/1133, batch loss:0.00014901247050147504, Training time:69024.20161676407
batch reward last col mean 4.733810055768117e-05 first col mean 2.9179616831243038e-05 all mean 4.6658507926622406e-05
1.3496975043381099e-05 1.3496972314896993e-05
rl training, epoch4, iter0, batch529/1133, batch loss:1.3496972314896993e-05, Training time:69042.41802954674
batch reward last col mean 0.00144374615047127 first col mean 1.1862812243634835e-05 all mean 0.0009488984360359609
8.590227662352845e-05 8.590226934757084e-05
rl training, epoch4, iter0, batch530/1133, batch loss:8.590226934757084e-05, Training time:69060.72051882744
batch reward last col mean 3.937853762181476e-06 first col mean 1.011311360343825e-05 all mean 0.00010116509656654671
0.00017330629634670913 0.00017330629634670913
rl training, epoch4, iter0, batch531/1133, batch loss:0.00017330629634670913, Training time:69077.70631337166
batch reward last col mean 5.900222276977729e-06 first col mean 5.248522029432934e-06 all mean 3.5583096178015694e-05
9.658992894401308e-06 9.658992894401308e-06
rl training, epoch4, iter0, batch532/1133, batch loss:9.658992894401308e-06, Training time:69094.53318405151
batch reward last col mean 1.8811306290444918e-05 first col mean 3.0356184652191587e-05 all mean 5.880689059267752e-05
3.589709376683459e-05 3.589708649087697e-05
rl training, epoch4, iter0, batch533/1133, batch loss:3.589708649087697e-05, Training time:69111.34185934067
batch reward last col mean 2.881190084735863e-05 first col mean 3.670093974506017e-06 all mean 6.465967453550547e-05
2.0489793314482085e-05 2.0489796952460892e-05
rl training, epoch4, iter0, batch534/1133, batch loss:2.0489796952460892e-05, Training time:69128.15633010864
batch reward last col mean 0.0006011949153617024 first col mean 7.154722879931796e-06 all mean 8.947142487158999e-05
8.889335731510073e-05 8.889336459105834e-05
rl training, epoch4, iter0, batch535/1133, batch loss:8.889336459105834e-05, Training time:69144.87564444542
batch reward last col mean 3.8440764910774305e-05 first col mean 1.137948629548191e-06 all mean 3.253433897043578e-05
1.8028578779194504e-05 1.80285769602051e-05
rl training, epoch4, iter0, batch536/1133, batch loss:1.80285769602051e-05, Training time:69161.60340452194
batch reward last col mean 8.005906238395255e-06 first col mean 1.6590627637924626e-05 all mean 4.6843040763633326e-05
4.731478838948533e-05 4.731478838948533e-05
rl training, epoch4, iter0, batch537/1133, batch loss:4.731478838948533e-05, Training time:69178.41113615036
batch reward last col mean 3.930224556825124e-05 first col mean 2.6675165827327874e-06 all mean 1.5899373465799727e-05
7.978486792126205e-06 7.978485882631503e-06
rl training, epoch4, iter0, batch538/1133, batch loss:7.978485882631503e-06, Training time:69195.43447637558
batch reward last col mean 0.0004743325989693403 first col mean 1.6855323110576137e-06 all mean 1.6828829757287167e-05
4.659725891542621e-05 4.6597251639468595e-05
rl training, epoch4, iter0, batch539/1133, batch loss:4.6597251639468595e-05, Training time:69212.3301820755
batch reward last col mean 3.112472768407315e-05 first col mean 3.7120435081305914e-06 all mean 6.490088708233088e-05
5.045082434662618e-05 5.045081707066856e-05
rl training, epoch4, iter0, batch540/1133, batch loss:5.045081707066856e-05, Training time:69229.19329428673
batch reward last col mean 5.154745849722531e-06 first col mean 4.8728961701272056e-05 all mean 0.00011802142398664728
4.972725946572609e-05 4.97272631037049e-05
rl training, epoch4, iter0, batch541/1133, batch loss:4.97272631037049e-05, Training time:69245.9829647541
batch reward last col mean 6.519346243294422e-06 first col mean 8.714723662706092e-06 all mean 3.203990854672156e-05
2.570472497609444e-05 2.5704721338115633e-05
rl training, epoch4, iter0, batch542/1133, batch loss:2.5704721338115633e-05, Training time:69262.80925607681
batch reward last col mean 4.473119133763248e-06 first col mean 2.4044634301390033e-06 all mean 4.662156425183639e-05
4.862432979280129e-05 4.8624322516843677e-05
rl training, epoch4, iter0, batch543/1133, batch loss:4.8624322516843677e-05, Training time:69279.74931025505
batch reward last col mean 9.486261660640594e-06 first col mean 5.388942099671112e-06 all mean 5.077645982964896e-05
1.4397426639334299e-05 1.439741663489258e-05
rl training, epoch4, iter0, batch544/1133, batch loss:1.439741663489258e-05, Training time:69296.75857281685
batch reward last col mean 5.1652004913194105e-06 first col mean 1.009356856229715e-05 all mean 5.746748865931295e-05
2.526933531044051e-05 2.5269331672461703e-05
rl training, epoch4, iter0, batch545/1133, batch loss:2.5269331672461703e-05, Training time:69313.64802336693
batch reward last col mean 0.0026979020331054926 first col mean 8.951665222411975e-06 all mean 0.0005822489620186388
0.00029656843980774283 0.00029656843980774283
rl training, epoch4, iter0, batch546/1133, batch loss:0.00029656843980774283, Training time:69330.54156684875
batch reward last col mean 3.861995537590701e-06 first col mean 0.00017023850523401052 all mean 3.585192098398693e-05
1.7196114640682936e-05 1.719611100270413e-05
rl training, epoch4, iter0, batch547/1133, batch loss:1.719611100270413e-05, Training time:69348.33374524117
batch reward last col mean 1.9711906134034507e-06 first col mean 3.533639301167568e-06 all mean 5.442419569590129e-05
2.6528081434662454e-05 2.6528086891630664e-05
rl training, epoch4, iter0, batch548/1133, batch loss:2.6528086891630664e-05, Training time:69365.2054259777
batch reward last col mean 3.1275518267648295e-05 first col mean 2.701735411392292e-06 all mean 2.9625538445543498e-05
3.274183109169826e-05 3.274183109169826e-05
rl training, epoch4, iter0, batch549/1133, batch loss:3.274183109169826e-05, Training time:69382.1715157032
batch reward last col mean 7.715394531260245e-06 first col mean 1.826267907745205e-05 all mean 5.957472967565991e-05
3.135601946269162e-05 3.135601946269162e-05
rl training, epoch4, iter0, batch550/1133, batch loss:3.135601946269162e-05, Training time:69399.12677693367
batch reward last col mean 4.435532900970429e-06 first col mean 9.026898624142632e-06 all mean 3.1169955036602914e-05
1.981154127861373e-05 1.981154127861373e-05
rl training, epoch4, iter0, batch551/1133, batch loss:1.981154127861373e-05, Training time:69416.14272713661
batch reward last col mean 4.149577762291301e-06 first col mean 9.905302249535453e-06 all mean 2.8816823032684624e-05
1.1950209227507003e-05 1.1950206499022897e-05
rl training, epoch4, iter0, batch552/1133, batch loss:1.1950206499022897e-05, Training time:69433.1505844593
batch reward last col mean 7.203346285677981e-06 first col mean 3.826852662314195e-06 all mean 4.864926086156629e-05
2.7255666282144375e-05 2.7255666282144375e-05
rl training, epoch4, iter0, batch553/1133, batch loss:2.7255666282144375e-05, Training time:69450.04909777641
batch reward last col mean 7.67487108532805e-06 first col mean 2.0034292901982553e-05 all mean 4.180190444458276e-05
9.14402335183695e-06 9.144025170826353e-06
rl training, epoch4, iter0, batch554/1133, batch loss:9.144025170826353e-06, Training time:69466.96650147438
batch reward last col mean 1.0806201316881925e-05 first col mean 0.0004680977435782552 all mean 0.00013557393685914576
6.961160397622734e-05 6.961158942431211e-05
rl training, epoch4, iter0, batch555/1133, batch loss:6.961158942431211e-05, Training time:69484.0490489006
batch reward last col mean 6.710783964081202e-06 first col mean 1.0540939911152236e-05 all mean 3.776031735469587e-05
1.0451069101691246e-05 1.0451073649164755e-05
rl training, epoch4, iter0, batch556/1133, batch loss:1.0451073649164755e-05, Training time:69501.0992808342
batch reward last col mean 2.4761848180787638e-06 first col mean 0.0013292593648657203 all mean 8.756663009990007e-05
4.188414823147468e-05 4.18841555074323e-05
rl training, epoch4, iter0, batch557/1133, batch loss:4.18841555074323e-05, Training time:69517.88861942291
batch reward last col mean 4.510453072725795e-05 first col mean 1.515043004474137e-05 all mean 1.9138617062708363e-05
1.7279162420891225e-05 1.727916423988063e-05
rl training, epoch4, iter0, batch558/1133, batch loss:1.727916423988063e-05, Training time:69534.86512064934
batch reward last col mean 3.1986496651370544e-06 first col mean 4.186798378214007e-06 all mean 5.137953121447936e-05
6.08048248977866e-05 6.0804810345871374e-05
rl training, epoch4, iter0, batch559/1133, batch loss:6.0804810345871374e-05, Training time:69551.67230200768
batch reward last col mean 1.2816439266316593e-05 first col mean 3.251761881983839e-06 all mean 3.462798849795945e-05
1.2649436030187644e-05 1.2649433301703539e-05
rl training, epoch4, iter0, batch560/1133, batch loss:1.2649433301703539e-05, Training time:69569.79293489456
batch reward last col mean 4.0969523979583755e-05 first col mean 2.6078583687194623e-05 all mean 9.920317097567022e-05
3.3584281482035294e-05 3.3584281482035294e-05
rl training, epoch4, iter0, batch561/1133, batch loss:3.3584281482035294e-05, Training time:69587.02151274681
batch reward last col mean 3.3438325772294775e-05 first col mean 1.1946022823394742e-05 all mean 8.226907812058926e-05
8.26578980195336e-05 8.265790529549122e-05
rl training, epoch4, iter0, batch562/1133, batch loss:8.265790529549122e-05, Training time:69604.06694531441
batch reward last col mean 6.699295772705227e-05 first col mean 0.0002536627871450037 all mean 9.153561404673383e-05
8.999572310131043e-05 8.999571582535282e-05
rl training, epoch4, iter0, batch563/1133, batch loss:8.999571582535282e-05, Training time:69622.56135964394
batch reward last col mean 9.158306056633592e-05 first col mean 8.232943400798831e-06 all mean 7.264583109645173e-05
3.3447508030803874e-05 3.344750075484626e-05
rl training, epoch4, iter0, batch564/1133, batch loss:3.344750075484626e-05, Training time:69639.31859397888
batch reward last col mean 0.0003318334056530148 first col mean 8.06413845566567e-06 all mean 5.518135003512725e-05
3.530922913341783e-05 3.530924368533306e-05
rl training, epoch4, iter0, batch565/1133, batch loss:3.530924368533306e-05, Training time:69656.37169837952
batch reward last col mean 2.8366874175844714e-05 first col mean 0.0009448860073462129 all mean 0.00013537262566387653
6.859258428448811e-05 6.859256973257288e-05
rl training, epoch4, iter0, batch566/1133, batch loss:6.859256973257288e-05, Training time:69673.41541862488
batch reward last col mean 1.8689245280256728e-06 first col mean 2.5505098619760247e-06 all mean 2.9030859877821058e-05
1.1889806955878157e-05 1.1889806955878157e-05
rl training, epoch4, iter0, batch567/1133, batch loss:1.1889806955878157e-05, Training time:69690.40088820457
batch reward last col mean 2.841933564923238e-06 first col mean 1.561868702992797e-05 all mean 2.180042974941898e-05
8.434574738203082e-06 8.434572919213679e-06
rl training, epoch4, iter0, batch568/1133, batch loss:8.434572919213679e-06, Training time:69707.1640894413
batch reward last col mean 1.6004378267098218e-05 first col mean 7.80810478318017e-06 all mean 6.950499664526433e-05
2.477745874784887e-05 2.477745874784887e-05
rl training, epoch4, iter0, batch569/1133, batch loss:2.477745874784887e-05, Training time:69724.17752480507
batch reward last col mean 0.00021586677758023143 first col mean 3.16690875479253e-06 all mean 0.00010934238525805995
8.949545008363202e-05 8.949545008363202e-05
rl training, epoch4, iter0, batch570/1133, batch loss:8.949545008363202e-05, Training time:69741.17424535751
batch reward last col mean 8.741312740312424e-06 first col mean 3.444573303568177e-05 all mean 8.859672379912809e-05
4.2314131860621274e-05 4.2314142774557695e-05
rl training, epoch4, iter0, batch571/1133, batch loss:4.2314142774557695e-05, Training time:69759.87801408768
batch reward last col mean 0.0001327732315985486 first col mean 1.8527991414885037e-05 all mean 7.470026321243495e-05
5.469426832860336e-05 5.469427924253978e-05
rl training, epoch4, iter0, batch572/1133, batch loss:5.469427924253978e-05, Training time:69776.79544115067
batch reward last col mean 2.9394041121122427e-06 first col mean 7.698329682170879e-06 all mean 7.837890007067472e-05
9.448851051274687e-05 9.448851051274687e-05
rl training, epoch4, iter0, batch573/1133, batch loss:9.448851051274687e-05, Training time:69793.6716310978
batch reward last col mean 0.00010532641317695379 first col mean 4.768521830555983e-05 all mean 9.255165787180886e-05
4.45357509306632e-05 4.453574729268439e-05
rl training, epoch4, iter0, batch574/1133, batch loss:4.453574729268439e-05, Training time:69810.40387201309
batch reward last col mean 1.159379280579742e-05 first col mean 1.5502744645345956e-05 all mean 6.786295853089541e-05
1.658503242651932e-05 1.6585025150561705e-05
rl training, epoch4, iter0, batch575/1133, batch loss:1.6585025150561705e-05, Training time:69826.97879743576
batch reward last col mean 5.167773451830726e-06 first col mean 9.06591594684869e-06 all mean 6.129504618002102e-05
2.99689872917952e-05 2.9968989110784605e-05
rl training, epoch4, iter0, batch576/1133, batch loss:2.9968989110784605e-05, Training time:69843.78104782104
batch reward last col mean 7.568496221210808e-05 first col mean 0.0004659230762626976 all mean 5.932238855166361e-05
3.203900996595621e-05 3.203902087989263e-05
rl training, epoch4, iter0, batch577/1133, batch loss:3.203902087989263e-05, Training time:69862.37835383415
batch reward last col mean 1.4173244380799588e-05 first col mean 1.1871077731484547e-05 all mean 9.355771180707961e-05
5.704733484890312e-05 5.704734576283954e-05
rl training, epoch4, iter0, batch578/1133, batch loss:5.704734576283954e-05, Training time:69881.01797676086
batch reward last col mean 3.186584945069626e-05 first col mean 9.382677490066271e-06 all mean 7.786146306898445e-05
3.0120851079118438e-05 3.012086199305486e-05
rl training, epoch4, iter0, batch579/1133, batch loss:3.012086199305486e-05, Training time:69897.94282245636
batch reward last col mean 8.642710781714413e-06 first col mean 5.873925147170667e-06 all mean 2.9668921342818066e-05
7.98578912508674e-05 7.985789852682501e-05
rl training, epoch4, iter0, batch580/1133, batch loss:7.985789852682501e-05, Training time:69915.09930944443
batch reward last col mean 4.673400326282717e-06 first col mean 4.9146136007038876e-05 all mean 4.527192868408747e-05
1.376591626467416e-05 1.3765921721642371e-05
rl training, epoch4, iter0, batch581/1133, batch loss:1.3765921721642371e-05, Training time:69932.5329823494
batch reward last col mean 5.599721134785796e-06 first col mean 5.1827319111907855e-06 all mean 4.5813561882823706e-05
2.2287673345999792e-05 2.2287673345999792e-05
rl training, epoch4, iter0, batch582/1133, batch loss:2.2287673345999792e-05, Training time:69949.32341957092
batch reward last col mean 1.1991023711743765e-05 first col mean 7.520853159803664e-06 all mean 3.0068453270359896e-05
6.488769031420816e-06 6.488769031420816e-06
rl training, epoch4, iter0, batch583/1133, batch loss:6.488769031420816e-06, Training time:69968.00713086128
batch reward last col mean 1.3193222230256652e-06 first col mean 3.980908331868704e-06 all mean 7.122873648768291e-05
2.386727101111319e-05 2.3867278287070803e-05
rl training, epoch4, iter0, batch584/1133, batch loss:2.3867278287070803e-05, Training time:69985.02628612518
batch reward last col mean 5.400386726250872e-06 first col mean 4.9992999265668914e-05 all mean 3.7197471101535484e-05
7.250340422615409e-05 7.250340422615409e-05
rl training, epoch4, iter0, batch585/1133, batch loss:7.250340422615409e-05, Training time:70001.7583694458
batch reward last col mean 3.8647935980407055e-06 first col mean 1.355065523966914e-05 all mean 5.995751416776329e-05
1.819407771108672e-05 1.8194079530076124e-05
rl training, epoch4, iter0, batch586/1133, batch loss:1.8194079530076124e-05, Training time:70020.48301267624
batch reward last col mean 6.558220775332302e-06 first col mean 4.4111629904364236e-06 all mean 3.4707227314356714e-05
1.4185379768605344e-05 1.4185380678100046e-05
rl training, epoch4, iter0, batch587/1133, batch loss:1.4185380678100046e-05, Training time:70037.32935810089
batch reward last col mean 2.371689788560616e-06 first col mean 1.690344106464181e-05 all mean 3.1129013223107904e-05
1.062825776898535e-05 1.062825776898535e-05
rl training, epoch4, iter0, batch588/1133, batch loss:1.062825776898535e-05, Training time:70054.10225439072
batch reward last col mean 1.4134706361801364e-05 first col mean 1.902155645439052e-06 all mean 2.859836422430817e-05
1.3711433894059155e-05 1.3711432984564453e-05
rl training, epoch4, iter0, batch589/1133, batch loss:1.3711432984564453e-05, Training time:70070.84852433205
batch reward last col mean 2.0442825189093128e-05 first col mean 1.4491635738522746e-05 all mean 8.574775711167604e-05
4.105652988073416e-05 4.105652988073416e-05
rl training, epoch4, iter0, batch590/1133, batch loss:4.105652988073416e-05, Training time:70087.7936694622
batch reward last col mean 8.097490535874385e-07 first col mean 4.23046549258288e-06 all mean 4.2251958802808076e-05
4.0187886042986065e-05 4.0187886042986065e-05
rl training, epoch4, iter0, batch591/1133, batch loss:4.0187886042986065e-05, Training time:70104.68807005882
batch reward last col mean 0.002639343263581395 first col mean 6.357906386256218e-06 all mean 0.002291648183017969
0.0002227100048912689 0.0002227100048912689
rl training, epoch4, iter0, batch592/1133, batch loss:0.0002227100048912689, Training time:70122.20828676224
batch reward last col mean 1.2070598131685983e-05 first col mean 1.6447760572191328e-05 all mean 4.673864896176383e-05
1.882026481325738e-05 1.882026481325738e-05
rl training, epoch4, iter0, batch593/1133, batch loss:1.882026481325738e-05, Training time:70139.11220932007
batch reward last col mean 4.396364602143876e-06 first col mean 1.6237427189480513e-05 all mean 2.8710774131468497e-05
2.338908780075144e-05 2.3389084162772633e-05
rl training, epoch4, iter0, batch594/1133, batch loss:2.3389084162772633e-05, Training time:70155.94368052483
batch reward last col mean 7.195177204266656e-06 first col mean 2.9108596208970994e-06 all mean 3.3853248169180006e-05
8.354691999556962e-06 8.354690180567559e-06
rl training, epoch4, iter0, batch595/1133, batch loss:8.354690180567559e-06, Training time:70173.51856708527
batch reward last col mean 1.980189699679613e-05 first col mean 4.360926141089294e-06 all mean 5.427899304777384e-05
1.7359890989609994e-05 1.7359885532641783e-05
rl training, epoch4, iter0, batch596/1133, batch loss:1.7359885532641783e-05, Training time:70190.32125163078
batch reward last col mean 9.85297083389014e-06 first col mean 0.00017373271111864597 all mean 4.1899205825757235e-05
1.6130376025103033e-05 1.6130377844092436e-05
rl training, epoch4, iter0, batch597/1133, batch loss:1.6130377844092436e-05, Training time:70207.96002292633
batch reward last col mean 9.651390428189188e-05 first col mean 6.992818271100987e-06 all mean 8.961494313552976e-05
4.9431466322857887e-05 4.943145177094266e-05
rl training, epoch4, iter0, batch598/1133, batch loss:4.943145177094266e-05, Training time:70226.6359963417
batch reward last col mean 1.193580283143092e-05 first col mean 4.757603619509609e-06 all mean 2.370313995925244e-05
1.4945940165489446e-05 1.4945940165489446e-05
rl training, epoch4, iter0, batch599/1133, batch loss:1.4945940165489446e-05, Training time:70245.23894119263
batch reward last col mean 6.271330676099751e-06 first col mean 6.304694124992238e-06 all mean 3.6718400224344805e-05
4.994360642740503e-05 4.994361734134145e-05
rl training, epoch4, iter0, batch600/1133, batch loss:4.994361734134145e-05, Training time:70263.8811109066
batch reward last col mean 8.388064452446997e-05 first col mean 5.231642353464849e-05 all mean 6.786906305933371e-05
2.9588245524792e-05 2.9588238248834386e-05
rl training, epoch4, iter0, batch601/1133, batch loss:2.9588238248834386e-05, Training time:70280.77377676964
batch reward last col mean 2.66446568275569e-06 first col mean 2.6108323254447896e-06 all mean 6.994361319812015e-05
0.00025173070025630295 0.00025173070025630295
rl training, epoch4, iter0, batch602/1133, batch loss:0.00025173070025630295, Training time:70297.74852466583
batch reward last col mean 4.8011585022322834e-05 first col mean 2.3940887331264094e-05 all mean 5.0071252189809456e-05
1.5121831893338822e-05 1.5121828255360015e-05
rl training, epoch4, iter0, batch603/1133, batch loss:1.5121828255360015e-05, Training time:70314.7555847168
batch reward last col mean 2.650903752510203e-06 first col mean 3.741131513379514e-05 all mean 5.705875810235739e-05
2.4564649720559828e-05 2.4564653358538635e-05
rl training, epoch4, iter0, batch604/1133, batch loss:2.4564653358538635e-05, Training time:70331.83384537697
batch reward last col mean 6.0782285800087266e-06 first col mean 1.9127942323393654e-06 all mean 8.196708222385496e-05
3.803602157859132e-05 3.80360143026337e-05
rl training, epoch4, iter0, batch605/1133, batch loss:3.80360143026337e-05, Training time:70349.17354869843
batch reward last col mean 2.0756331196025712e-06 first col mean 9.529067938274238e-06 all mean 3.844827369903214e-05
2.767688420135528e-05 2.7676882382365875e-05
rl training, epoch4, iter0, batch606/1133, batch loss:2.7676882382365875e-05, Training time:70366.11774277687
batch reward last col mean 2.6774410798680037e-05 first col mean 1.5140127288759686e-05 all mean 9.262734965886921e-05
1.7210390069521964e-05 1.7210384612553753e-05
rl training, epoch4, iter0, batch607/1133, batch loss:1.7210384612553753e-05, Training time:70382.95441412926
batch reward last col mean 3.866197403112892e-06 first col mean 1.4419249055208638e-05 all mean 5.4079828260000795e-05
1.4962900422688108e-05 1.4962898603698704e-05
rl training, epoch4, iter0, batch608/1133, batch loss:1.4962898603698704e-05, Training time:70399.6863451004
batch reward last col mean 1.1189746373929665e-06 first col mean 5.412147856986849e-06 all mean 3.870044383802451e-05
2.2205938876140863e-05 2.220592796220444e-05
rl training, epoch4, iter0, batch609/1133, batch loss:2.220592796220444e-05, Training time:70417.83792448044
batch reward last col mean 1.112766949518118e-05 first col mean 6.140226105344482e-06 all mean 0.00010657336679287255
3.966440635849722e-05 3.966441363445483e-05
rl training, epoch4, iter0, batch610/1133, batch loss:3.966441363445483e-05, Training time:70436.06852865219
batch reward last col mean 2.343191681575263e-06 first col mean 6.65438483338221e-06 all mean 0.000123347039334476
6.954751734156162e-05 6.954753189347684e-05
rl training, epoch4, iter0, batch611/1133, batch loss:6.954753189347684e-05, Training time:70454.64237165451
batch reward last col mean 6.316977305687033e-06 first col mean 1.822719059418887e-05 all mean 8.997471013572067e-05
4.0404906030744314e-05 4.040491330670193e-05
rl training, epoch4, iter0, batch612/1133, batch loss:4.040491330670193e-05, Training time:70473.26099777222
batch reward last col mean 3.513113369990606e-06 first col mean 3.216852974219364e-06 all mean 3.8006528484402224e-05
2.659960046003107e-05 2.6599593184073456e-05
rl training, epoch4, iter0, batch613/1133, batch loss:2.6599593184073456e-05, Training time:70490.03962039948
batch reward last col mean 2.1475334506249055e-05 first col mean 1.4541503333020955e-05 all mean 0.0001055146349244751
4.631794581655413e-05 4.631794581655413e-05
rl training, epoch4, iter0, batch614/1133, batch loss:4.631794581655413e-05, Training time:70508.15330982208
batch reward last col mean 1.2853913631261094e-06 first col mean 5.496673111338168e-06 all mean 4.976197669748217e-05
1.8117039871867746e-05 1.8117034414899535e-05
rl training, epoch4, iter0, batch615/1133, batch loss:1.8117034414899535e-05, Training time:70526.60300254822
batch reward last col mean 1.0046810530184302e-05 first col mean 7.3201581471948884e-06 all mean 7.787811773596331e-05
3.724905036506243e-05 3.7249046727083623e-05
rl training, epoch4, iter0, batch616/1133, batch loss:3.7249046727083623e-05, Training time:70543.47541570663
batch reward last col mean 3.7022618926130235e-06 first col mean 2.811264948832104e-06 all mean 3.0141718525555916e-05
1.4064062270335853e-05 1.406405590387294e-05
rl training, epoch4, iter0, batch617/1133, batch loss:1.406405590387294e-05, Training time:70561.04766249657
batch reward last col mean 1.8743281543720514e-05 first col mean 4.18050558437244e-06 all mean 4.159871241427027e-05
3.173888399032876e-05 3.173889126628637e-05
rl training, epoch4, iter0, batch618/1133, batch loss:3.173889126628637e-05, Training time:70577.98394060135
batch reward last col mean 6.045604823157191e-05 first col mean 9.836690878728405e-06 all mean 5.0748229114105925e-05
2.369908725086134e-05 2.369909270782955e-05
rl training, epoch4, iter0, batch619/1133, batch loss:2.369909270782955e-05, Training time:70594.89443016052
batch reward last col mean 1.4651566743850708e-05 first col mean 5.299820259097032e-05 all mean 6.103621126385406e-05
2.0770999981323257e-05 2.077099634334445e-05
rl training, epoch4, iter0, batch620/1133, batch loss:2.077099634334445e-05, Training time:70611.98195886612
batch reward last col mean 1.1357358289387776e-06 first col mean 0.00012401753338053823 all mean 6.158273026812822e-05
7.982626812008675e-06 7.982627721503377e-06
rl training, epoch4, iter0, batch621/1133, batch loss:7.982627721503377e-06, Training time:70628.74596476555
batch reward last col mean 0.0002295445738127455 first col mean 1.2213637091917917e-05 all mean 7.38926901249215e-05
2.5855792046058923e-05 2.5855777494143695e-05
rl training, epoch4, iter0, batch622/1133, batch loss:2.5855777494143695e-05, Training time:70645.69520401955
batch reward last col mean 4.186915248283185e-05 first col mean 7.091211955412291e-06 all mean 4.3620271753752604e-05
1.1759408153011464e-05 1.175942179543199e-05
rl training, epoch4, iter0, batch623/1133, batch loss:1.175942179543199e-05, Training time:70662.60439229012
batch reward last col mean 4.5161115849623457e-05 first col mean 7.31396221453906e-06 all mean 7.260409620357677e-05
3.7356396205723286e-05 3.735638892976567e-05
rl training, epoch4, iter0, batch624/1133, batch loss:3.735638892976567e-05, Training time:70679.48166918755
batch reward last col mean 3.211011062376201e-06 first col mean 7.071424079185817e-06 all mean 5.5532036640215665e-05
1.3857826161256526e-05 1.3857818885298911e-05
rl training, epoch4, iter0, batch625/1133, batch loss:1.3857818885298911e-05, Training time:70696.41091322899
batch reward last col mean 1.2186014828330372e-05 first col mean 6.358473456202773e-06 all mean 3.3539723517606035e-05
2.3732973204459995e-05 2.373297138547059e-05
rl training, epoch4, iter0, batch626/1133, batch loss:2.373297138547059e-05, Training time:70714.0710401535
batch reward last col mean 2.1336712961783633e-05 first col mean 7.017124062258517e-06 all mean 4.1425453673582524e-05
2.4293502065120265e-05 2.429350024613086e-05
rl training, epoch4, iter0, batch627/1133, batch loss:2.429350024613086e-05, Training time:70732.66372442245
batch reward last col mean 8.112384239211679e-05 first col mean 3.832788479485316e-06 all mean 0.00010246304736938328
4.6965080400696024e-05 4.696508403867483e-05
rl training, epoch4, iter0, batch628/1133, batch loss:4.696508403867483e-05, Training time:70749.38416695595
batch reward last col mean 3.948455741920043e-06 first col mean 1.6915477317525074e-05 all mean 5.806354238302447e-05
4.02831647079438e-05 4.02831647079438e-05
rl training, epoch4, iter0, batch629/1133, batch loss:4.02831647079438e-05, Training time:70766.28094625473
batch reward last col mean 5.659489943354856e-06 first col mean 3.8138593936309917e-06 all mean 4.39385803474579e-05
2.852115903806407e-05 2.8521157219074667e-05
rl training, epoch4, iter0, batch630/1133, batch loss:2.8521157219074667e-05, Training time:70783.02234220505
batch reward last col mean 5.962593149888562e-06 first col mean 0.00010232290514977649 all mean 2.8374599423841573e-05
8.845589036354795e-06 8.845585398375988e-06
rl training, epoch4, iter0, batch631/1133, batch loss:8.845585398375988e-06, Training time:70800.51967906952
batch reward last col mean 6.622985893045552e-06 first col mean 8.473751222481951e-06 all mean 5.737624451285228e-05
0.00012940741726197302 0.00012940741726197302
rl training, epoch4, iter0, batch632/1133, batch loss:0.00012940741726197302, Training time:70819.17183661461
batch reward last col mean 1.2282821444387082e-05 first col mean 4.756739144795574e-06 all mean 3.7332629290176556e-05
1.7620361177250743e-05 1.762036481522955e-05
rl training, epoch4, iter0, batch633/1133, batch loss:1.762036481522955e-05, Training time:70836.09170436859
batch reward last col mean 6.0724050854332745e-06 first col mean 1.1729431207641028e-05 all mean 4.056163379573263e-05
2.611189484014176e-05 2.611189484014176e-05
rl training, epoch4, iter0, batch634/1133, batch loss:2.611189484014176e-05, Training time:70853.07920479774
batch reward last col mean 3.2082616598927416e-06 first col mean 5.170628355699591e-05 all mean 5.922678246861324e-05
4.3706008000299335e-05 4.3706018914235756e-05
rl training, epoch4, iter0, batch635/1133, batch loss:4.3706018914235756e-05, Training time:70870.01743125916
batch reward last col mean 4.812388851860305e-06 first col mean 9.985939868784044e-06 all mean 4.6363857109099627e-05
5.621829041047022e-05 5.6218279496533796e-05
rl training, epoch4, iter0, batch636/1133, batch loss:5.6218279496533796e-05, Training time:70886.87749624252
batch reward last col mean 1.916208930197172e-05 first col mean 4.036543032270856e-06 all mean 3.2908883440541103e-05
1.5694293324486353e-05 1.5694293324486353e-05
rl training, epoch4, iter0, batch637/1133, batch loss:1.5694293324486353e-05, Training time:70903.65293955803
batch reward last col mean 3.31784576701466e-06 first col mean 2.225372736575082e-05 all mean 4.533790342975408e-05
1.1045212886529043e-05 1.1045215615013149e-05
rl training, epoch4, iter0, batch638/1133, batch loss:1.1045215615013149e-05, Training time:70920.5334982872
batch reward last col mean 1.903709016914945e-05 first col mean 0.00021012674551457167 all mean 6.666799163213e-05
5.516517921932973e-05 5.516517921932973e-05
rl training, epoch4, iter0, batch639/1133, batch loss:5.516517921932973e-05, Training time:70938.34896445274
batch reward last col mean 9.606039384379983e-06 first col mean 2.5324448870378546e-05 all mean 5.471314216265455e-05
6.978913916100282e-06 6.978916189837037e-06
rl training, epoch4, iter0, batch640/1133, batch loss:6.978916189837037e-06, Training time:70956.94041609764
batch reward last col mean 1.2257896742084995e-05 first col mean 1.4951221601222642e-05 all mean 7.983180694282055e-05
5.049147512181662e-05 5.04914642078802e-05
rl training, epoch4, iter0, batch641/1133, batch loss:5.04914642078802e-05, Training time:70975.1526916027
batch reward last col mean 0.00016799182048998773 first col mean 7.320404620259069e-06 all mean 4.2199120798613876e-05
1.8751739844447002e-05 1.8751739844447002e-05
rl training, epoch4, iter0, batch642/1133, batch loss:1.8751739844447002e-05, Training time:70992.21894550323
batch reward last col mean 3.5304578887007665e-06 first col mean 4.291880031814799e-06 all mean 7.441167690558359e-05
2.463946475472767e-05 2.4639457478770055e-05
rl training, epoch4, iter0, batch643/1133, batch loss:2.4639457478770055e-05, Training time:71009.01584458351
batch reward last col mean 0.0003374517254997045 first col mean 1.6152062016772106e-05 all mean 4.217398236505687e-05
7.1467220550403e-05 7.146722782636061e-05
rl training, epoch4, iter0, batch644/1133, batch loss:7.146722782636061e-05, Training time:71025.80619955063
batch reward last col mean 9.650930223870091e-07 first col mean 1.510378933744505e-05 all mean 3.092640690738335e-05
9.54402275965549e-06 9.544014574203175e-06
rl training, epoch4, iter0, batch645/1133, batch loss:9.544014574203175e-06, Training time:71042.63390684128
batch reward last col mean 1.0101494808623102e-05 first col mean 5.077477544546127e-05 all mean 6.015563121763989e-05
3.7762813008157536e-05 3.7762813008157536e-05
rl training, epoch4, iter0, batch646/1133, batch loss:3.7762813008157536e-05, Training time:71059.39749026299
batch reward last col mean 2.4745173504925333e-05 first col mean 8.642208740639035e-06 all mean 6.288351869443431e-05
1.4952239325793926e-05 1.495224660175154e-05
rl training, epoch4, iter0, batch647/1133, batch loss:1.495224660175154e-05, Training time:71076.5114827156
batch reward last col mean 2.425687671347987e-05 first col mean 2.516877793823369e-05 all mean 1.307951970375143e-05
9.383669748785906e-06 9.383669748785906e-06
rl training, epoch4, iter0, batch648/1133, batch loss:9.383669748785906e-06, Training time:71093.32106423378
batch reward last col mean 0.0006594584556296468 first col mean 2.5588622520444915e-05 all mean 0.0002540171844884753
6.836838292656466e-05 6.836839020252228e-05
rl training, epoch4, iter0, batch649/1133, batch loss:6.836839020252228e-05, Training time:71110.19845938683
batch reward last col mean 9.395289453095756e-06 first col mean 1.5167495803325437e-05 all mean 0.00010369243682362139
0.00013688666513189673 0.00013688667968381196
rl training, epoch4, iter0, batch650/1133, batch loss:0.00013688667968381196, Training time:71127.11072969437
batch reward last col mean 4.625789006240666e-05 first col mean 4.129964509047568e-06 all mean 4.2052452045027167e-05
2.610963383631315e-05 2.610962837934494e-05
rl training, epoch4, iter0, batch651/1133, batch loss:2.610962837934494e-05, Training time:71145.58474373817
batch reward last col mean 1.6029836842790246e-05 first col mean 1.546816565678455e-05 all mean 7.945513789309189e-05
2.7081152438768186e-05 2.708114880078938e-05
rl training, epoch4, iter0, batch652/1133, batch loss:2.708114880078938e-05, Training time:71162.42404961586
batch reward last col mean 0.0001244802842848003 first col mean 0.00011038613592972979 all mean 0.00013068981934338808
4.618907769327052e-05 4.618907769327052e-05
rl training, epoch4, iter0, batch653/1133, batch loss:4.618907769327052e-05, Training time:71179.38601613045
batch reward last col mean 5.157142368261702e-06 first col mean 4.900510248262435e-06 all mean 9.029106149682775e-05
3.7888341466896236e-05 3.788833782891743e-05
rl training, epoch4, iter0, batch654/1133, batch loss:3.788833782891743e-05, Training time:71196.22006082535
batch reward last col mean 9.274053809349425e-06 first col mean 6.804399163229391e-06 all mean 6.730468157911673e-05
2.893514283641707e-05 2.8935141017427668e-05
rl training, epoch4, iter0, batch655/1133, batch loss:2.8935141017427668e-05, Training time:71213.08544516563
batch reward last col mean 1.435587000742089e-05 first col mean 3.2953787012957036e-05 all mean 9.808025788515806e-05
6.523807678604499e-05 6.523807678604499e-05
rl training, epoch4, iter0, batch656/1133, batch loss:6.523807678604499e-05, Training time:71229.79341721535
batch reward last col mean 0.00013010125258006155 first col mean 3.5208449844503775e-05 all mean 0.00014733347052242607
4.334504046710208e-05 4.3345033191144466e-05
rl training, epoch4, iter0, batch657/1133, batch loss:4.3345033191144466e-05, Training time:71246.73489952087
batch reward last col mean 1.818958298827056e-05 first col mean 5.450326170830522e-06 all mean 4.202203490422107e-05
3.2391682907473296e-05 3.2391682907473296e-05
rl training, epoch4, iter0, batch658/1133, batch loss:3.2391682907473296e-05, Training time:71263.58635115623
batch reward last col mean 1.3370331544138025e-05 first col mean 2.4267246772069484e-05 all mean 6.112120172474533e-05
3.269100852776319e-05 3.26910158037208e-05
rl training, epoch4, iter0, batch659/1133, batch loss:3.26910158037208e-05, Training time:71280.43694400787
batch reward last col mean 1.9927201719838195e-05 first col mean 1.3321810911293142e-05 all mean 7.648909377167001e-05
4.014517617179081e-05 4.014517617179081e-05
rl training, epoch4, iter0, batch660/1133, batch loss:4.014517617179081e-05, Training time:71297.28467679024
batch reward last col mean 5.519677870324813e-06 first col mean 2.9825627279933542e-05 all mean 5.9035435697296634e-05
2.2689011530019343e-05 2.2689002435072325e-05
rl training, epoch4, iter0, batch661/1133, batch loss:2.2689002435072325e-05, Training time:71314.14351606369
batch reward last col mean 1.1126266144856345e-05 first col mean 3.093793202424422e-05 all mean 2.8077818569727242e-05
1.5357418305939063e-05 1.5357418305939063e-05
rl training, epoch4, iter0, batch662/1133, batch loss:1.5357418305939063e-05, Training time:71331.07398629189
batch reward last col mean 1.1159621863043867e-05 first col mean 8.271907972812187e-06 all mean 7.541111699538305e-05
4.38963616034016e-05 4.3896368879359215e-05
rl training, epoch4, iter0, batch663/1133, batch loss:4.3896368879359215e-05, Training time:71347.65388393402
batch reward last col mean 1.8708624338614754e-05 first col mean 4.446543243830092e-06 all mean 4.8002915718825534e-05
4.017026731162332e-05 4.017026731162332e-05
rl training, epoch4, iter0, batch664/1133, batch loss:4.017026731162332e-05, Training time:71364.41527414322
batch reward last col mean 6.867274350952357e-05 first col mean 0.0006524239433929324 all mean 9.169520490104333e-05
1.6496365788043477e-05 1.6496360331075266e-05
rl training, epoch4, iter0, batch665/1133, batch loss:1.6496360331075266e-05, Training time:71382.33273339272
batch reward last col mean 2.137812589353416e-05 first col mean 7.164710950746667e-06 all mean 4.835756044485606e-05
3.464116889517754e-05 3.464116889517754e-05
rl training, epoch4, iter0, batch666/1133, batch loss:3.464116889517754e-05, Training time:71399.7623705864
batch reward last col mean 3.68888649973087e-05 first col mean 1.0319376997358631e-05 all mean 2.9095375793986022e-05
2.1103831386426464e-05 2.1103827748447657e-05
rl training, epoch4, iter0, batch667/1133, batch loss:2.1103827748447657e-05, Training time:71418.0558450222
batch reward last col mean 5.103755756863393e-05 first col mean 2.1717234631069005e-05 all mean 3.066550561925396e-05
2.3589773263665847e-05 2.358977508265525e-05
rl training, epoch4, iter0, batch668/1133, batch loss:2.358977508265525e-05, Training time:71435.94897460938
batch reward last col mean 1.0746826774266083e-05 first col mean 1.536125409984379e-06 all mean 5.5342974519589916e-05
6.891987140988931e-05 6.891985685797408e-05
rl training, epoch4, iter0, batch669/1133, batch loss:6.891985685797408e-05, Training time:71452.81521224976
batch reward last col mean 0.00018015118257608265 first col mean 4.930351678922307e-06 all mean 9.852862422121689e-05
3.227271372452378e-05 3.2272710086544976e-05
rl training, epoch4, iter0, batch670/1133, batch loss:3.2272710086544976e-05, Training time:71471.55374217033
batch reward last col mean 1.2688980859820731e-05 first col mean 6.0992530052317306e-05 all mean 6.123018829384819e-05
2.576774568296969e-05 2.5767752958927304e-05
rl training, epoch4, iter0, batch671/1133, batch loss:2.5767752958927304e-05, Training time:71488.27902388573
batch reward last col mean 0.0002517988032195717 first col mean 2.4558282802900067e-06 all mean 3.169262345181778e-05
7.319393625948578e-05 7.319392898352817e-05
rl training, epoch4, iter0, batch672/1133, batch loss:7.319392898352817e-05, Training time:71505.12570142746
batch reward last col mean 2.3392620278173126e-05 first col mean 5.183309440326411e-06 all mean 4.226701275911182e-05
1.5999232346075587e-05 1.5999225070117973e-05
rl training, epoch4, iter0, batch673/1133, batch loss:1.5999225070117973e-05, Training time:71522.39620614052
batch reward last col mean 0.001427115872502327 first col mean 0.00037040183087810874 all mean 8.459258242510259e-05
6.149172986624762e-05 6.149173714220524e-05
rl training, epoch4, iter0, batch674/1133, batch loss:6.149173714220524e-05, Training time:71539.19882416725
batch reward last col mean 8.234344932134263e-06 first col mean 2.1222562281764112e-05 all mean 5.7785407989285886e-05
2.861463690351229e-05 2.8614638722501695e-05
rl training, epoch4, iter0, batch675/1133, batch loss:2.8614638722501695e-05, Training time:71556.10798668861
batch reward last col mean 7.219337476271903e-06 first col mean 1.7716292859404348e-05 all mean 7.661501877009869e-05
2.7656677048071288e-05 2.7656682505039498e-05
rl training, epoch4, iter0, batch676/1133, batch loss:2.7656682505039498e-05, Training time:71573.14153885841
batch reward last col mean 8.292040729429573e-05 first col mean 6.017765826982213e-06 all mean 4.826091026188806e-05
1.1184703907929361e-05 1.1184702998434659e-05
rl training, epoch4, iter0, batch677/1133, batch loss:1.1184702998434659e-05, Training time:71590.08441138268
batch reward last col mean 3.1515776299784193e-06 first col mean 4.023325800517341e-06 all mean 6.000807843520306e-05
1.1002991413988639e-05 1.1002999599440955e-05
rl training, epoch4, iter0, batch678/1133, batch loss:1.1002999599440955e-05, Training time:71607.03786683083
batch reward last col mean 0.00013561708328779787 first col mean 5.445833448902704e-05 all mean 8.127043111016974e-05
2.0737907107104547e-05 2.073791438306216e-05
rl training, epoch4, iter0, batch679/1133, batch loss:2.073791438306216e-05, Training time:71624.02480244637
batch reward last col mean 0.00017854025645647198 first col mean 0.00015525023627560586 all mean 0.0001014973022392951
3.605736492318101e-05 3.605736856115982e-05
rl training, epoch4, iter0, batch680/1133, batch loss:3.605736856115982e-05, Training time:71641.09886622429
batch reward last col mean 1.2514798072515987e-05 first col mean 7.681407441850752e-05 all mean 6.0703510825987905e-05
4.732808156404644e-05 4.7328077926067635e-05
rl training, epoch4, iter0, batch681/1133, batch loss:4.7328077926067635e-05, Training time:71657.9404990673
batch reward last col mean 4.381941835163161e-06 first col mean 8.16379724710714e-06 all mean 2.9774277209071442e-05
2.6363470169599168e-05 2.636347562656738e-05
rl training, epoch4, iter0, batch682/1133, batch loss:2.636347562656738e-05, Training time:71674.74780344963
batch reward last col mean 9.993613639380783e-05 first col mean 3.984374779975042e-05 all mean 8.191465894924477e-05
3.2766118238214403e-05 3.2766114600235596e-05
rl training, epoch4, iter0, batch683/1133, batch loss:3.2766114600235596e-05, Training time:71691.58304786682
batch reward last col mean 1.995588536374271e-05 first col mean 7.4319864324934315e-06 all mean 8.096394594758749e-05
3.6339701182441786e-05 3.633971209637821e-05
rl training, epoch4, iter0, batch684/1133, batch loss:3.633971209637821e-05, Training time:71708.52318763733
batch reward last col mean 1.5972627807059325e-06 first col mean 8.389008144149557e-06 all mean 3.355717853992246e-05
1.2489989785535727e-05 1.2489992514019832e-05
rl training, epoch4, iter0, batch685/1133, batch loss:1.2489992514019832e-05, Training time:71725.36769628525
batch reward last col mean 2.1905486846662825e-06 first col mean 4.9227264753426425e-06 all mean 5.797191261081025e-05
2.7967993446509354e-05 2.7967978894594125e-05
rl training, epoch4, iter0, batch686/1133, batch loss:2.7967978894594125e-05, Training time:71742.2103009224
batch reward last col mean 0.0014283389318734407 first col mean 8.657340913487133e-06 all mean 4.563448601402342e-05
6.189227133290842e-05 6.189227133290842e-05
rl training, epoch4, iter0, batch687/1133, batch loss:6.189227133290842e-05, Training time:71758.98148965836
batch reward last col mean 3.6141404962108936e-06 first col mean 1.5493740647798404e-05 all mean 3.167597242281772e-05
3.158493200317025e-05 3.158493200317025e-05
rl training, epoch4, iter0, batch688/1133, batch loss:3.158493200317025e-05, Training time:71775.90243601799
batch reward last col mean 8.283520401164424e-06 first col mean 0.0016726116882637143 all mean 7.225629815366119e-05
3.3831645851023495e-05 3.383165312698111e-05
rl training, epoch4, iter0, batch689/1133, batch loss:3.383165312698111e-05, Training time:71794.37102937698
batch reward last col mean 5.4330885177478194e-06 first col mean 1.5515384802711196e-05 all mean 4.195417568553239e-05
1.0796346032293513e-05 1.0796337846841197e-05
rl training, epoch4, iter0, batch690/1133, batch loss:1.0796337846841197e-05, Training time:71811.14168906212
batch reward last col mean 0.0010618866654112935 first col mean 2.9385571451712167e-06 all mean 9.501992462901399e-05
7.431086851283908e-05 7.431086851283908e-05
rl training, epoch4, iter0, batch691/1133, batch loss:7.431086851283908e-05, Training time:71827.73563289642
batch reward last col mean 0.0006704005063511431 first col mean 2.466316573190852e-06 all mean 0.0001256586838280782
6.435762770706788e-05 6.435762770706788e-05
rl training, epoch4, iter0, batch692/1133, batch loss:6.435762770706788e-05, Training time:71844.33793449402
batch reward last col mean 3.6340126825962216e-05 first col mean 1.4150488823361229e-05 all mean 6.907519127707928e-05
8.521074778400362e-05 8.5210740508046e-05
rl training, epoch4, iter0, batch693/1133, batch loss:8.5210740508046e-05, Training time:71861.11731696129
batch reward last col mean 5.586814040725585e-06 first col mean 0.00011977721442235634 all mean 3.261551682953723e-05
0.00011429237929405645 0.00011429237929405645
rl training, epoch4, iter0, batch694/1133, batch loss:0.00011429237929405645, Training time:71877.93596172333
batch reward last col mean 1.118185423365503e-06 first col mean 0.0002409631706541404 all mean 2.1834033759660088e-05
1.3249431503936648e-05 1.3249431503936648e-05
rl training, epoch4, iter0, batch695/1133, batch loss:1.3249431503936648e-05, Training time:71894.72150588036
batch reward last col mean 1.4776192074350547e-05 first col mean 0.00018015355453826487 all mean 6.87300052959472e-05
1.2147757843194995e-05 1.2147746929258574e-05
rl training, epoch4, iter0, batch696/1133, batch loss:1.2147746929258574e-05, Training time:71911.79201412201
batch reward last col mean 1.198035624838667e-05 first col mean 5.02903230881202e-06 all mean 6.203124212333933e-05
9.498393046669662e-05 9.498395229456946e-05
rl training, epoch4, iter0, batch697/1133, batch loss:9.498395229456946e-05, Training time:71930.58737659454
batch reward last col mean 5.052854703535559e-06 first col mean 2.45679693762213e-05 all mean 5.302463614498265e-05
2.138053605449386e-05 2.1380532416515052e-05
rl training, epoch4, iter0, batch698/1133, batch loss:2.1380532416515052e-05, Training time:71947.65326309204
batch reward last col mean 2.024117929977365e-05 first col mean 1.142660948971752e-05 all mean 7.345316407736391e-05
3.209791611880064e-05 3.209790156688541e-05
rl training, epoch4, iter0, batch699/1133, batch loss:3.209790156688541e-05, Training time:71964.52895569801
batch reward last col mean 2.103631413774565e-05 first col mean 1.373314080410637e-05 all mean 5.5749656894477084e-05
1.7129184925579466e-05 1.7129188563558273e-05
rl training, epoch4, iter0, batch700/1133, batch loss:1.7129188563558273e-05, Training time:71981.37914681435
batch reward last col mean 1.8717541024670936e-05 first col mean 6.7794721871905494e-06 all mean 0.0001487051777075976
4.877534229308367e-05 4.8775335017126054e-05
rl training, epoch4, iter0, batch701/1133, batch loss:4.8775335017126054e-05, Training time:71998.32274651527
batch reward last col mean 1.2145105756644625e-06 first col mean 1.3553419194067828e-05 all mean 3.966405347455293e-05
7.577193628094392e-06 7.577201813546708e-06
rl training, epoch4, iter0, batch702/1133, batch loss:7.577201813546708e-06, Training time:72015.03876948357
batch reward last col mean 1.0849025784409605e-06 first col mean 5.2059008339711e-06 all mean 3.491768802632578e-05
1.4584269592887722e-05 1.4584264135919511e-05
rl training, epoch4, iter0, batch703/1133, batch loss:1.4584264135919511e-05, Training time:72031.71033287048
batch reward last col mean 5.983810297038872e-06 first col mean 4.049736617162125e-06 all mean 9.66411316767335e-05
0.00012718531070277095 0.00012718531070277095
rl training, epoch4, iter0, batch704/1133, batch loss:0.00012718531070277095, Training time:72048.45623540878
batch reward last col mean 6.245053555176128e-06 first col mean 1.2314132618485019e-05 all mean 5.072359635960311e-05
3.0392508051590994e-05 3.0392508051590994e-05
rl training, epoch4, iter0, batch705/1133, batch loss:3.0392508051590994e-05, Training time:72065.08599567413
batch reward last col mean 0.0004085959808435291 first col mean 1.3633548405778129e-05 all mean 8.907692244974896e-05
0.0001257865224033594 0.00012578653695527464
rl training, epoch4, iter0, batch706/1133, batch loss:0.00012578653695527464, Training time:72083.70455098152
batch reward last col mean 1.7314952856395394e-05 first col mean 7.095836735970806e-06 all mean 6.14884847891517e-05
1.7433758330298588e-05 1.7433758330298588e-05
rl training, epoch4, iter0, batch707/1133, batch loss:1.7433758330298588e-05, Training time:72102.30307722092
batch reward last col mean 0.0007444318034686148 first col mean 5.635357592836954e-05 all mean 7.421620102832094e-05
7.474275480490178e-05 7.474275480490178e-05
rl training, epoch4, iter0, batch708/1133, batch loss:7.474275480490178e-05, Training time:72121.06447410583
batch reward last col mean 3.2315979296981823e-06 first col mean 1.8774968339130282e-05 all mean 2.3353919459623285e-05
1.803475788619835e-05 1.8034754248219542e-05
rl training, epoch4, iter0, batch709/1133, batch loss:1.8034754248219542e-05, Training time:72137.95808935165
batch reward last col mean 2.6305240680812858e-05 first col mean 4.3634867324726656e-05 all mean 7.159979577409104e-05
3.577835741452873e-05 3.577835741452873e-05
rl training, epoch4, iter0, batch710/1133, batch loss:3.577835741452873e-05, Training time:72154.96168804169
batch reward last col mean 1.7101756384363398e-05 first col mean 2.1570513126789592e-05 all mean 4.511575752985664e-05
2.230694008176215e-05 2.2306941900751553e-05
rl training, epoch4, iter0, batch711/1133, batch loss:2.2306941900751553e-05, Training time:72171.943318367
batch reward last col mean 1.8378155800746754e-05 first col mean 2.4429953555227257e-05 all mean 3.147150346194394e-05
1.50500536619802e-05 1.5050050933496095e-05
rl training, epoch4, iter0, batch712/1133, batch loss:1.5050050933496095e-05, Training time:72188.94506883621
batch reward last col mean 3.476239362498745e-05 first col mean 5.334479283192195e-06 all mean 2.201111965405289e-05
1.3056453099125065e-05 1.3056453099125065e-05
rl training, epoch4, iter0, batch713/1133, batch loss:1.3056453099125065e-05, Training time:72205.82380104065
batch reward last col mean 4.756522230309201e-06 first col mean 1.3564529126597336e-06 all mean 5.3305946494219825e-05
1.7935557480086572e-05 1.7935568394022994e-05
rl training, epoch4, iter0, batch714/1133, batch loss:1.7935568394022994e-05, Training time:72222.74224257469
batch reward last col mean 1.083513143385062e-05 first col mean 5.520952072401997e-06 all mean 8.04524970590137e-05
6.38065830571577e-05 6.380655395332724e-05
rl training, epoch4, iter0, batch715/1133, batch loss:6.380655395332724e-05, Training time:72239.621134758
batch reward last col mean 1.6635281099297572e-06 first col mean 1.0172197107749525e-05 all mean 4.039181294501759e-05
4.398008604766801e-05 4.398008604766801e-05
rl training, epoch4, iter0, batch716/1133, batch loss:4.398008604766801e-05, Training time:72256.43840646744
batch reward last col mean 1.7488586308900267e-05 first col mean 1.591422551427968e-05 all mean 3.2784941140562296e-05
5.6044216762529686e-05 5.6044216762529686e-05
rl training, epoch4, iter0, batch717/1133, batch loss:5.6044216762529686e-05, Training time:72273.16210508347
batch reward last col mean 8.453311238554306e-06 first col mean 3.149966232740553e-06 all mean 4.870686825597659e-05
2.8355229005683213e-05 2.8355218091746792e-05
rl training, epoch4, iter0, batch718/1133, batch loss:2.8355218091746792e-05, Training time:72290.14325141907
batch reward last col mean 9.719774971017614e-05 first col mean 1.3069450687908102e-05 all mean 8.77353668329306e-05
2.5135792384389788e-05 2.5135810574283823e-05
rl training, epoch4, iter0, batch719/1133, batch loss:2.5135810574283823e-05, Training time:72306.9340391159
batch reward last col mean 1.008227718557464e-05 first col mean 3.527695298544131e-05 all mean 7.012824789853767e-05
2.8996229957556352e-05 2.899622813856695e-05
rl training, epoch4, iter0, batch720/1133, batch loss:2.899622813856695e-05, Training time:72324.27738690376
batch reward last col mean 9.100045645027421e-06 first col mean 2.5678057227196405e-06 all mean 3.7272937333909795e-05
2.759089693427086e-05 2.759089693427086e-05
rl training, epoch4, iter0, batch721/1133, batch loss:2.759089693427086e-05, Training time:72342.7815208435
batch reward last col mean 0.0011611522641032934 first col mean 3.2169187761610374e-05 all mean 6.53339084237814e-05
0.00015856079699005932 0.00015856076788622886
rl training, epoch4, iter0, batch722/1133, batch loss:0.00015856076788622886, Training time:72359.44099283218
batch reward last col mean 8.314413207699545e-06 first col mean 1.6034411601140164e-05 all mean 4.3176161852898076e-05
5.721469278796576e-05 5.721468187402934e-05
rl training, epoch4, iter0, batch723/1133, batch loss:5.721468187402934e-05, Training time:72376.59270620346
batch reward last col mean 3.5075763662462123e-06 first col mean 3.968335931858746e-06 all mean 3.9213322452269495e-05
3.5478471545502543e-05 3.547846063156612e-05
rl training, epoch4, iter0, batch724/1133, batch loss:3.547846063156612e-05, Training time:72393.23756146431
batch reward last col mean 6.419899727916345e-05 first col mean 1.1098347385996021e-05 all mean 8.31364159239456e-05
3.456247941358015e-05 3.456247941358015e-05
rl training, epoch4, iter0, batch725/1133, batch loss:3.456247941358015e-05, Training time:72411.80351638794
batch reward last col mean 1.318519821325026e-06 first col mean 7.3664391493366566e-06 all mean 5.799457721877843e-05
2.1338513761293143e-05 2.1338504666346125e-05
rl training, epoch4, iter0, batch726/1133, batch loss:2.1338504666346125e-05, Training time:72428.79108333588
batch reward last col mean 4.247407105140155e-06 first col mean 1.9476974557619542e-05 all mean 4.2169176595052704e-05
1.0400283827038947e-05 1.0400276551081333e-05
rl training, epoch4, iter0, batch727/1133, batch loss:1.0400276551081333e-05, Training time:72445.55385684967
batch reward last col mean 3.2452585401188117e-06 first col mean 0.00010079634375870228 all mean 4.873558282270096e-05
2.451781983836554e-05 2.4517823476344347e-05
rl training, epoch4, iter0, batch728/1133, batch loss:2.4517823476344347e-05, Training time:72462.3972337246
batch reward last col mean 4.971034286427312e-06 first col mean 2.4449123884551227e-05 all mean 5.493263233802281e-05
3.4427273931214586e-05 3.442727029323578e-05
rl training, epoch4, iter0, batch729/1133, batch loss:3.442727029323578e-05, Training time:72479.13751602173
batch reward last col mean 0.00017551709606777877 first col mean 2.0071714970981702e-05 all mean 0.0001029364502755925
0.00010064864909509197 0.00010064864181913435
rl training, epoch4, iter0, batch730/1133, batch loss:0.00010064864181913435, Training time:72495.90462136269
batch reward last col mean 4.758005616167793e-06 first col mean 0.00012368560419417918 all mean 2.6205610993201844e-05
9.886540283332579e-06 9.886542102321982e-06
rl training, epoch4, iter0, batch731/1133, batch loss:9.886542102321982e-06, Training time:72512.80575060844
batch reward last col mean 4.674098818213679e-05 first col mean 1.2276964298507664e-05 all mean 4.781422467203811e-05
8.552841609343886e-05 8.552841609343886e-05
rl training, epoch4, iter0, batch732/1133, batch loss:8.552841609343886e-05, Training time:72529.47616028786
batch reward last col mean 4.7143246774794534e-05 first col mean 2.251206979053677e-06 all mean 5.779738421551883e-05
1.627275560167618e-05 1.6272757420665585e-05
rl training, epoch4, iter0, batch733/1133, batch loss:1.6272757420665585e-05, Training time:72547.30978012085
batch reward last col mean 1.8889459170168266e-05 first col mean 1.1523998182383366e-05 all mean 6.97861541993916e-05
5.5702883400954306e-05 5.5702872487017885e-05
rl training, epoch4, iter0, batch734/1133, batch loss:5.5702872487017885e-05, Training time:72565.96539878845
batch reward last col mean 5.418596174422419e-06 first col mean 6.262135684664827e-06 all mean 3.921520692529157e-05
6.630484222114319e-06 6.630478765146108e-06
rl training, epoch4, iter0, batch735/1133, batch loss:6.630478765146108e-06, Training time:72582.88502931595
batch reward last col mean 3.0337655516632367e-06 first col mean 5.083825726615032e-06 all mean 4.236727545503527e-05
6.489449879154563e-05 6.489450606750324e-05
rl training, epoch4, iter0, batch736/1133, batch loss:6.489450606750324e-05, Training time:72599.63782763481
batch reward last col mean 2.3943299311213195e-05 first col mean 5.069280814495869e-05 all mean 4.929508577333763e-05
3.788507092394866e-05 3.788507456192747e-05
rl training, epoch4, iter0, batch737/1133, batch loss:3.788507456192747e-05, Training time:72617.99950122833
batch reward last col mean 1.7750243159753154e-06 first col mean 2.666026603037608e-06 all mean 2.4798786398605444e-05
1.537640309834387e-05 1.537640673632268e-05
rl training, epoch4, iter0, batch738/1133, batch loss:1.537640673632268e-05, Training time:72636.45827507973
batch reward last col mean 4.332085609348724e-06 first col mean 1.700867505860515e-05 all mean 5.034919740865007e-05
6.4484206632187124e-06 6.448427484428976e-06
rl training, epoch4, iter0, batch739/1133, batch loss:6.448427484428976e-06, Training time:72654.96796798706
batch reward last col mean 2.482911668266752e-06 first col mean 9.07723224372603e-05 all mean 7.82154529588297e-05
3.287841900601052e-05 3.287843719590455e-05
rl training, epoch4, iter0, batch740/1133, batch loss:3.287843719590455e-05, Training time:72671.77939152718
batch reward last col mean 0.00011916286894120276 first col mean 1.3099812349537387e-05 all mean 0.00010139935329789296
5.1508526667021215e-05 5.150853394297883e-05
rl training, epoch4, iter0, batch741/1133, batch loss:5.150853394297883e-05, Training time:72688.61674308777
batch reward last col mean 2.4148837837856263e-05 first col mean 1.5959214579197578e-05 all mean 6.273423787206411e-05
0.00012782690464518964 0.00012782689009327441
rl training, epoch4, iter0, batch742/1133, batch loss:0.00012782689009327441, Training time:72705.6978187561
batch reward last col mean 1.5834782971069217e-05 first col mean 0.0005246836226433516 all mean 8.957833051681519e-05
4.9254216719418764e-05 4.925421308143996e-05
rl training, epoch4, iter0, batch743/1133, batch loss:4.925421308143996e-05, Training time:72722.44169425964
batch reward last col mean 7.6492469816003e-06 first col mean 1.3780694644083269e-05 all mean 6.598245090572163e-05
4.892393553745933e-05 4.892393189948052e-05
rl training, epoch4, iter0, batch744/1133, batch loss:4.892393189948052e-05, Training time:72739.31323599815
batch reward last col mean 0.00022028513194527477 first col mean 2.6951118343276903e-05 all mean 0.00012145419168518856
4.6763445425312966e-05 4.6763445425312966e-05
rl training, epoch4, iter0, batch745/1133, batch loss:4.6763445425312966e-05, Training time:72756.26301050186
batch reward last col mean 0.0006180945201776922 first col mean 5.038745712226955e-06 all mean 0.00017288749222643673
4.29630272265058e-05 4.296301995054819e-05
rl training, epoch4, iter0, batch746/1133, batch loss:4.296301995054819e-05, Training time:72773.33025574684
batch reward last col mean 4.321632513892837e-05 first col mean 5.254412826616317e-06 all mean 0.00013493321603164077
6.920429586898535e-05 6.920425948919728e-05
rl training, epoch4, iter0, batch747/1133, batch loss:6.920425948919728e-05, Training time:72790.23382258415
batch reward last col mean 1.567690196679905e-05 first col mean 3.940232545573963e-06 all mean 5.031813634559512e-05
9.841800419962965e-06 9.841807695920579e-06
rl training, epoch4, iter0, batch748/1133, batch loss:9.841807695920579e-06, Training time:72807.1197257042
batch reward last col mean 0.0028805946931242943 first col mean 0.00022594918846152723 all mean 8.624776819488034e-05
0.0002228324010502547 0.00022283237194642425
rl training, epoch4, iter0, batch749/1133, batch loss:0.00022283237194642425, Training time:72824.08395385742
batch reward last col mean 3.7374356907093897e-06 first col mean 1.2919105756736826e-05 all mean 0.00010267785546602681
5.162847810424864e-05 5.1628449000418186e-05
rl training, epoch4, iter0, batch750/1133, batch loss:5.1628449000418186e-05, Training time:72840.88333725929
batch reward last col mean 2.7775104172178544e-06 first col mean 8.080591214820743e-06 all mean 6.785340519854799e-05
4.3701766117010266e-05 4.3701755203073844e-05
rl training, epoch4, iter0, batch751/1133, batch loss:4.3701755203073844e-05, Training time:72857.74971580505
batch reward last col mean 9.778513231140096e-06 first col mean 1.5680290744057857e-05 all mean 4.3564905354287475e-05
1.4367239600687753e-05 1.4367236872203648e-05
rl training, epoch4, iter0, batch752/1133, batch loss:1.4367236872203648e-05, Training time:72874.54902482033
batch reward last col mean 3.725898204720579e-05 first col mean 7.370454568444984e-06 all mean 2.5655930585344322e-05
6.4739419940451626e-06 6.473939720308408e-06
rl training, epoch4, iter0, batch753/1133, batch loss:6.473939720308408e-06, Training time:72891.35507154465
batch reward last col mean 6.241667506401427e-06 first col mean 2.33174541790504e-05 all mean 7.307479245355353e-05
3.9763031963957474e-05 3.976302105002105e-05
rl training, epoch4, iter0, batch754/1133, batch loss:3.976302105002105e-05, Training time:72909.68158054352
batch reward last col mean 1.495748438173905e-05 first col mean 3.6933415685780346e-06 all mean 7.242424180731177e-05
3.774083234020509e-05 3.7740850530099124e-05
rl training, epoch4, iter0, batch755/1133, batch loss:3.7740850530099124e-05, Training time:72928.21272468567
batch reward last col mean 4.26287624577526e-06 first col mean 4.071333933097776e-06 all mean 2.112080437655095e-05
6.833898623881396e-06 6.83390089761815e-06
rl training, epoch4, iter0, batch756/1133, batch loss:6.83390089761815e-06, Training time:72946.79224324226
batch reward last col mean 0.0001683716254774481 first col mean 1.4716502846567892e-05 all mean 0.00016556539048906416
0.00012576114386320114 0.00012576114386320114
rl training, epoch4, iter0, batch757/1133, batch loss:0.00012576114386320114, Training time:72965.44152855873
batch reward last col mean 3.2798590837046504e-05 first col mean 0.00024197273887693882 all mean 3.4647546272026375e-05
2.3571396013721824e-05 2.3571397832711227e-05
rl training, epoch4, iter0, batch758/1133, batch loss:2.3571397832711227e-05, Training time:72984.0022854805
batch reward last col mean 7.489831477869302e-05 first col mean 6.0240945458645e-06 all mean 7.00773744028993e-05
4.529854777501896e-05 4.529854777501896e-05
rl training, epoch4, iter0, batch759/1133, batch loss:4.529854777501896e-05, Training time:73002.50741052628
batch reward last col mean 5.275517651170958e-06 first col mean 1.822030753828585e-05 all mean 0.00010722727165557444
0.00022866261133458465 0.00022866261133458465
rl training, epoch4, iter0, batch760/1133, batch loss:0.00022866261133458465, Training time:73019.30913686752
batch reward last col mean 1.5372927009593695e-05 first col mean 6.683151241304586e-06 all mean 4.847985110245645e-05
5.091366620035842e-05 5.091366620035842e-05
rl training, epoch4, iter0, batch761/1133, batch loss:5.091366620035842e-05, Training time:73036.08412790298
batch reward last col mean 1.9291270291432738e-05 first col mean 0.0003211971779819578 all mean 4.7506888222415e-05
1.4343448128784075e-05 1.4343448128784075e-05
rl training, epoch4, iter0, batch762/1133, batch loss:1.4343448128784075e-05, Training time:73052.91445112228
batch reward last col mean 4.579730102705071e-06 first col mean 1.0755222319858149e-05 all mean 2.3607628463651054e-05
1.3249479707155842e-05 1.3249479707155842e-05
rl training, epoch4, iter0, batch763/1133, batch loss:1.3249479707155842e-05, Training time:73070.49297499657
batch reward last col mean 0.00041660075658001006 first col mean 4.002653440693393e-06 all mean 0.00014702074986416847
6.723759724991396e-05 6.723758997395635e-05
rl training, epoch4, iter0, batch764/1133, batch loss:6.723758997395635e-05, Training time:73087.4372830391
batch reward last col mean 2.0592451619450003e-06 first col mean 0.00022627504949923605 all mean 6.646262772846967e-05
1.0001352166000288e-05 1.000136853690492e-05
rl training, epoch4, iter0, batch765/1133, batch loss:1.000136853690492e-05, Training time:73104.29869508743
batch reward last col mean 0.00017284636851400137 first col mean 4.976520358468406e-06 all mean 0.00012765711289830506
3.505354470689781e-05 3.505353379296139e-05
rl training, epoch4, iter0, batch766/1133, batch loss:3.505353379296139e-05, Training time:73121.14404058456
batch reward last col mean 8.736715244594961e-06 first col mean 5.3732164815301076e-06 all mean 4.2487703467486426e-05
1.3156805835023988e-05 1.3156798559066374e-05
rl training, epoch4, iter0, batch767/1133, batch loss:1.3156798559066374e-05, Training time:73137.94410157204
batch reward last col mean 2.2662875380774494e-06 first col mean 0.0006218163762241602 all mean 6.572710844920948e-05
1.7879629012895748e-05 1.7879632650874555e-05
rl training, epoch4, iter0, batch768/1133, batch loss:1.7879632650874555e-05, Training time:73154.91554784775
batch reward last col mean 7.453023863490671e-05 first col mean 4.1206294554285705e-06 all mean 4.9408714403398335e-05
6.379414116963744e-05 6.379414844559506e-05
rl training, epoch4, iter0, batch769/1133, batch loss:6.379414844559506e-05, Training time:73171.72410178185
batch reward last col mean 7.194718637038022e-05 first col mean 0.00021203588403295726 all mean 0.00010146330168936402
5.5433654779335484e-05 5.543365841731429e-05
rl training, epoch4, iter0, batch770/1133, batch loss:5.543365841731429e-05, Training time:73188.58882021904
batch reward last col mean 3.361549488545279e-06 first col mean 1.1520923180796672e-05 all mean 0.00013170727470424026
6.936238060006872e-05 6.936238060006872e-05
rl training, epoch4, iter0, batch771/1133, batch loss:6.936238060006872e-05, Training time:73205.47920632362
batch reward last col mean 3.384063120392966e-06 first col mean 3.8114774270070484e-06 all mean 4.727255873149261e-05
2.347478221054189e-05 2.3474785848520696e-05
rl training, epoch4, iter0, batch772/1133, batch loss:2.3474785848520696e-05, Training time:73223.37449359894
batch reward last col mean 2.855950924640638e-06 first col mean 2.238917659269646e-06 all mean 3.3669242839096114e-05
5.337849415809615e-06 5.337843504094053e-06
rl training, epoch4, iter0, batch773/1133, batch loss:5.337843504094053e-06, Training time:73241.99120283127
batch reward last col mean 4.718588024843484e-05 first col mean 6.112902337918058e-05 all mean 9.365940786665305e-05
3.983017450082116e-05 3.9830192690715194e-05
rl training, epoch4, iter0, batch774/1133, batch loss:3.9830192690715194e-05, Training time:73258.9260442257
batch reward last col mean 9.18511432246305e-06 first col mean 1.3554484212363604e-05 all mean 6.043238681741059e-05
4.988901855540462e-05 4.9889011279447004e-05
rl training, epoch4, iter0, batch775/1133, batch loss:4.9889011279447004e-05, Training time:73277.40694022179
batch reward last col mean 1.4559148439730052e-05 first col mean 5.675070497090928e-06 all mean 8.112862997222692e-05
5.014871931052767e-05 5.0148722948506474e-05
rl training, epoch4, iter0, batch776/1133, batch loss:5.0148722948506474e-05, Training time:73296.371489048
batch reward last col mean 4.872279077972053e-06 first col mean 3.4443099139025435e-05 all mean 3.1810228392714635e-05
2.235170904896222e-05 2.2351707229972817e-05
rl training, epoch4, iter0, batch777/1133, batch loss:2.2351707229972817e-05, Training time:73313.23947310448
batch reward last col mean 4.5967550249770284e-05 first col mean 8.838909707264975e-06 all mean 3.979025495937094e-05
4.3857267883140594e-05 4.385726060718298e-05
rl training, epoch4, iter0, batch778/1133, batch loss:4.385726060718298e-05, Training time:73330.21331596375
batch reward last col mean 5.371861789171817e-06 first col mean 3.395715611986816e-05 all mean 3.589990228647366e-05
1.5582298146910034e-05 1.5582298146910034e-05
rl training, epoch4, iter0, batch779/1133, batch loss:1.5582298146910034e-05, Training time:73347.22053313255
batch reward last col mean 5.705283911083825e-05 first col mean 0.00013480761845130473 all mean 7.141401874832809e-05
3.5095345083391294e-05 3.509533416945487e-05
rl training, epoch4, iter0, batch780/1133, batch loss:3.509533416945487e-05, Training time:73364.18460464478
batch reward last col mean 6.988458153500687e-06 first col mean 1.1557202014955692e-05 all mean 4.525498297880404e-05
1.4513189853460062e-05 1.4513185305986553e-05
rl training, epoch4, iter0, batch781/1133, batch loss:1.4513185305986553e-05, Training time:73381.15237474442
batch reward last col mean 5.020253411203157e-06 first col mean 3.3385990718670655e-06 all mean 5.2557006711140275e-05
1.8266149709234014e-05 1.8266140614286996e-05
rl training, epoch4, iter0, batch782/1133, batch loss:1.8266140614286996e-05, Training time:73397.98941755295
batch reward last col mean 4.375961725600064e-05 first col mean 0.0001271224464289844 all mean 1.8695704056881368e-05
2.7605252398643643e-05 2.760525057965424e-05
rl training, epoch4, iter0, batch783/1133, batch loss:2.760525057965424e-05, Training time:73414.88023376465
batch reward last col mean 6.8650538196379784e-06 first col mean 1.4325163647299632e-05 all mean 0.00010677302634576336
3.2094721973408014e-05 3.2094732887344435e-05
rl training, epoch4, iter0, batch784/1133, batch loss:3.2094732887344435e-05, Training time:73431.6174530983
batch reward last col mean 0.00020055304048582911 first col mean 6.706576186843449e-06 all mean 6.585723167518154e-05
3.438084604567848e-05 3.438083876972087e-05
rl training, epoch4, iter0, batch785/1133, batch loss:3.438083876972087e-05, Training time:73450.02746462822
batch reward last col mean 1.4144023225526325e-05 first col mean 3.1714895158074796e-05 all mean 5.775675890618004e-05
2.4534068870707415e-05 2.453405613778159e-05
rl training, epoch4, iter0, batch786/1133, batch loss:2.453405613778159e-05, Training time:73466.9992158413
batch reward last col mean 0.0002657948643900454 first col mean 6.386116001522169e-05 all mean 0.00011746169911930338
3.815226591541432e-05 3.815226227743551e-05
rl training, epoch4, iter0, batch787/1133, batch loss:3.815226227743551e-05, Training time:73483.96453547478
batch reward last col mean 1.7381258658133447e-05 first col mean 6.449930515373126e-05 all mean 4.183670171187259e-05
2.2385331249097362e-05 2.2385327611118555e-05
rl training, epoch4, iter0, batch788/1133, batch loss:2.2385327611118555e-05, Training time:73500.72355008125
batch reward last col mean 6.461012526415288e-05 first col mean 1.2169999536126852e-05 all mean 8.966957830125466e-05
8.160204015439376e-05 8.160203287843615e-05
rl training, epoch4, iter0, batch789/1133, batch loss:8.160203287843615e-05, Training time:73517.88400173187
batch reward last col mean 5.988911198073765e-06 first col mean 5.824433173984289e-06 all mean 3.384047522558831e-05
1.393376078340225e-05 1.3933753507444635e-05
rl training, epoch4, iter0, batch790/1133, batch loss:1.3933753507444635e-05, Training time:73534.76187062263
batch reward last col mean 1.5824685760890134e-05 first col mean 2.5445995561312884e-05 all mean 7.033022120594978e-05
4.4750708184437826e-05 4.4750697270501405e-05
rl training, epoch4, iter0, batch791/1133, batch loss:4.4750697270501405e-05, Training time:73551.53348588943
batch reward last col mean 5.876519935554825e-06 first col mean 0.0002689033281058073 all mean 6.776315422030166e-05
0.00011079892283305526 0.00011079892283305526
rl training, epoch4, iter0, batch792/1133, batch loss:0.00011079892283305526, Training time:73568.34688615799
batch reward last col mean 0.00012367629096843302 first col mean 7.863902283133939e-06 all mean 6.0470454627647996e-05
3.70560992450919e-05 3.7056106521049514e-05
rl training, epoch4, iter0, batch793/1133, batch loss:3.7056106521049514e-05, Training time:73585.10202527046
batch reward last col mean 0.0013462841743603349 first col mean 1.338589754595887e-05 all mean 0.0005822466919198632
0.00018069663201458752 0.00018069658835884184
rl training, epoch4, iter0, batch794/1133, batch loss:0.00018069658835884184, Training time:73602.02024006844
batch reward last col mean 9.290663001593202e-06 first col mean 1.6985664842650294e-05 all mean 6.299479719018564e-05
1.8924163668998517e-05 1.8924152755062096e-05
rl training, epoch4, iter0, batch795/1133, batch loss:1.8924152755062096e-05, Training time:73619.0253174305
batch reward last col mean 5.9883495850954205e-06 first col mean 2.1145071968931006e-06 all mean 4.666481981985271e-05
1.0375462807132863e-05 1.0375462807132863e-05
rl training, epoch4, iter0, batch796/1133, batch loss:1.0375462807132863e-05, Training time:73635.99927091599
batch reward last col mean 0.00030851445626467466 first col mean 2.9809740226482973e-05 all mean 3.4248685551574454e-05
6.0181599110364914e-05 6.018160274834372e-05
rl training, epoch4, iter0, batch797/1133, batch loss:6.018160274834372e-05, Training time:73652.98882770538
batch reward last col mean 1.4397986660696915e-06 first col mean 1.8604960132506676e-05 all mean 8.114233787637204e-05
3.908559665433131e-05 3.90855893783737e-05
rl training, epoch4, iter0, batch798/1133, batch loss:3.90855893783737e-05, Training time:73669.8972594738
batch reward last col mean 2.285316622874234e-05 first col mean 2.9179993816796923e-06 all mean 3.6102468584431335e-05
1.321052695857361e-05 1.3210529687057715e-05
rl training, epoch4, iter0, batch799/1133, batch loss:1.3210529687057715e-05, Training time:73686.95192575455
batch reward last col mean 2.063548527075909e-05 first col mean 5.133045306138229e-06 all mean 7.3969793447759e-05
4.100799924344756e-05 4.100799560546875e-05
rl training, epoch4, iter0, batch800/1133, batch loss:4.100799560546875e-05, Training time:73703.846326828
batch reward last col mean 0.00017556319653522223 first col mean 4.746373178932117e-06 all mean 6.319606472970918e-05
5.75525191379711e-05 5.755250822403468e-05
rl training, epoch4, iter0, batch801/1133, batch loss:5.755250822403468e-05, Training time:73720.91390299797
batch reward last col mean 5.282335678202799e-06 first col mean 7.521108636865392e-05 all mean 7.685121818212792e-05
4.691695357905701e-05 4.691696085501462e-05
rl training, epoch4, iter0, batch802/1133, batch loss:4.691696085501462e-05, Training time:73737.89916563034
batch reward last col mean 5.031652108300477e-06 first col mean 1.4596957043977454e-05 all mean 8.878809603629634e-05
3.60983976861462e-05 3.6098404962103814e-05
rl training, epoch4, iter0, batch803/1133, batch loss:3.6098404962103814e-05, Training time:73754.80538749695
batch reward last col mean 0.00016191723989322782 first col mean 4.876680577581283e-06 all mean 5.899541065446101e-05
4.3575375457294285e-05 4.357536818133667e-05
rl training, epoch4, iter0, batch804/1133, batch loss:4.357536818133667e-05, Training time:73772.42991566658
batch reward last col mean 3.776924131670967e-05 first col mean 6.713844413752668e-06 all mean 7.009900582488626e-05
2.8147811462986283e-05 2.8147813281975687e-05
rl training, epoch4, iter0, batch805/1133, batch loss:2.8147813281975687e-05, Training time:73790.99680566788
batch reward last col mean 8.145299943862483e-06 first col mean 4.925241228193045e-05 all mean 0.00012821276322938502
9.522480104351416e-05 9.522480104351416e-05
rl training, epoch4, iter0, batch806/1133, batch loss:9.522480104351416e-05, Training time:73808.7942931652
batch reward last col mean 2.6999598048860207e-05 first col mean 4.6191798901418224e-05 all mean 4.185519719612785e-05
2.2446412913268432e-05 2.244641655124724e-05
rl training, epoch4, iter0, batch807/1133, batch loss:2.244641655124724e-05, Training time:73827.42218494415
batch reward last col mean 1.1335033377690706e-05 first col mean 8.568025805288926e-06 all mean 0.00011406790872570127
0.00013125265832059085 0.00013125265832059085
rl training, epoch4, iter0, batch808/1133, batch loss:0.00013125265832059085, Training time:73845.4687757492
batch reward last col mean 2.591033080534544e-06 first col mean 4.1792154661379755e-06 all mean 3.5122287954436615e-05
5.256347139948048e-05 5.2563475037459284e-05
rl training, epoch4, iter0, batch809/1133, batch loss:5.2563475037459284e-05, Training time:73862.32158899307
batch reward last col mean 2.712039758989704e-06 first col mean 1.49993702507345e-05 all mean 5.555350435315631e-05
2.1961879610898905e-05 2.19618777919095e-05
rl training, epoch4, iter0, batch810/1133, batch loss:2.19618777919095e-05, Training time:73879.08253312111
batch reward last col mean 3.48535240846104e-06 first col mean 4.576769242703449e-06 all mean 6.7986169597134e-05
3.365124939591624e-05 3.3651253033895046e-05
rl training, epoch4, iter0, batch811/1133, batch loss:3.3651253033895046e-05, Training time:73895.79896473885
batch reward last col mean 8.865554264048114e-05 first col mean 0.0006881982553750277 all mean 0.00011848794383695349
3.86793544748798e-05 3.8679361750837415e-05
rl training, epoch4, iter0, batch812/1133, batch loss:3.8679361750837415e-05, Training time:73912.72409272194
batch reward last col mean 7.310189539566636e-05 first col mean 9.627777217247058e-06 all mean 7.236738747451454e-05
2.2992860976955853e-05 2.299284460605122e-05
rl training, epoch4, iter0, batch813/1133, batch loss:2.299284460605122e-05, Training time:73929.5979859829
batch reward last col mean 0.00039087096229195595 first col mean 2.1084193576825783e-05 all mean 9.62376652751118e-05
6.401728023774922e-05 6.401728751370683e-05
rl training, epoch4, iter0, batch814/1133, batch loss:6.401728751370683e-05, Training time:73946.46879029274
batch reward last col mean 1.0367491995566525e-05 first col mean 7.553308478236431e-06 all mean 2.5693703719298355e-05
1.0431841474201065e-05 1.0431843293190468e-05
rl training, epoch4, iter0, batch815/1133, batch loss:1.0431843293190468e-05, Training time:73963.48531937599
batch reward last col mean 9.35367279453203e-06 first col mean 1.7754252894519595e-06 all mean 2.6396413886686787e-05
8.210107807826716e-06 8.210106898332015e-06
rl training, epoch4, iter0, batch816/1133, batch loss:8.210106898332015e-06, Training time:73980.47509622574
batch reward last col mean 2.4817234134388855e-06 first col mean 6.285185008891858e-06 all mean 6.106045475462452e-05
2.7205418518860824e-05 2.720541669987142e-05
rl training, epoch4, iter0, batch817/1133, batch loss:2.720541669987142e-05, Training time:73997.44144105911
batch reward last col mean 7.780407031532377e-05 first col mean 1.3701979696634226e-05 all mean 8.915169746614993e-05
1.936572698468808e-05 1.9365737898624502e-05
rl training, epoch4, iter0, batch818/1133, batch loss:1.9365737898624502e-05, Training time:74014.38605594635
batch reward last col mean 6.4625714912835974e-06 first col mean 1.529441578895785e-05 all mean 7.698382250964642e-05
4.708680717158131e-05 4.708681444753893e-05
rl training, epoch4, iter0, batch819/1133, batch loss:4.708681444753893e-05, Training time:74031.37601208687
batch reward last col mean 1.7667705833446234e-05 first col mean 6.339982974168379e-06 all mean 8.033522317418829e-05
6.350295734591782e-05 6.350293551804498e-05
rl training, epoch4, iter0, batch820/1133, batch loss:6.350293551804498e-05, Training time:74048.28387212753
batch reward last col mean 0.0001668540935497731 first col mean 7.590023869852303e-06 all mean 0.00010055046004708856
5.7488083257339895e-05 5.748807598138228e-05
rl training, epoch4, iter0, batch821/1133, batch loss:5.748807598138228e-05, Training time:74065.19447612762
batch reward last col mean 1.9302031432744116e-05 first col mean 1.2078053259756416e-05 all mean 7.19890886102803e-05
3.319573443150148e-05 3.319573443150148e-05
rl training, epoch4, iter0, batch822/1133, batch loss:3.319573443150148e-05, Training time:74082.16679382324
batch reward last col mean 3.0687263006257126e-06 first col mean 0.00038339220918715 all mean 5.55718106625136e-05
4.9287078581983224e-05 4.92870676680468e-05
rl training, epoch4, iter0, batch823/1133, batch loss:4.92870676680468e-05, Training time:74099.04947829247
batch reward last col mean 2.8573260806297185e-06 first col mean 4.5065817175782286e-06 all mean 5.47554373042658e-05
2.5452731279074214e-05 2.5452722184127197e-05
rl training, epoch4, iter0, batch824/1133, batch loss:2.5452722184127197e-05, Training time:74115.96302175522
batch reward last col mean 3.818022014456801e-05 first col mean 1.8944907424156554e-05 all mean 3.575853043003008e-05
1.6365223928005435e-05 1.6365225746994838e-05
rl training, epoch4, iter0, batch825/1133, batch loss:1.6365225746994838e-05, Training time:74133.11900091171
batch reward last col mean 3.5197681427234784e-05 first col mean 1.369486199109815e-05 all mean 3.597946124500595e-05
1.5027716472104657e-05 1.5027710105641745e-05
rl training, epoch4, iter0, batch826/1133, batch loss:1.5027710105641745e-05, Training time:74149.9574971199
batch reward last col mean 0.00012473609240259975 first col mean 4.5139877329347655e-06 all mean 7.368132355622947e-05
2.5326140530523844e-05 2.532613325456623e-05
rl training, epoch4, iter0, batch827/1133, batch loss:2.532613325456623e-05, Training time:74166.92693734169
batch reward last col mean 1.8391285266261548e-05 first col mean 1.331440762442071e-05 all mean 8.331649587489665e-05
0.00012917976710014045 0.00012917975254822522
rl training, epoch4, iter0, batch828/1133, batch loss:0.00012917975254822522, Training time:74183.82370758057
batch reward last col mean 1.020386116579175e-05 first col mean 3.3961200642806944e-06 all mean 4.7416553570656106e-05
3.968180317315273e-05 3.968180317315273e-05
rl training, epoch4, iter0, batch829/1133, batch loss:3.968180317315273e-05, Training time:74200.67222213745
batch reward last col mean 1.10047667476465e-05 first col mean 9.939746632880997e-06 all mean 0.00010973754251608625
3.4915890864795074e-05 3.4915890864795074e-05
rl training, epoch4, iter0, batch830/1133, batch loss:3.4915890864795074e-05, Training time:74217.56049656868
batch reward last col mean 8.743595572013874e-06 first col mean 2.8970259791094577e-06 all mean 8.338814222952351e-05
6.428037886507809e-05 6.428037158912048e-05
rl training, epoch4, iter0, batch831/1133, batch loss:6.428037158912048e-05, Training time:74234.41426706314
batch reward last col mean 4.266703854227671e-06 first col mean 7.614745118189603e-05 all mean 4.396501026349142e-05
1.264522234123433e-05 1.2645225069718435e-05
rl training, epoch4, iter0, batch832/1133, batch loss:1.2645225069718435e-05, Training time:74251.16230750084
batch reward last col mean 4.461860953597352e-06 first col mean 1.863281249825377e-05 all mean 5.971132486592978e-05
3.798578472924419e-05 3.798578472924419e-05
rl training, epoch4, iter0, batch833/1133, batch loss:3.798578472924419e-05, Training time:74268.037815094
batch reward last col mean 0.00012084581976523623 first col mean 6.921642125234939e-06 all mean 0.00013272020441945642
3.475779521977529e-05 3.475779521977529e-05
rl training, epoch4, iter0, batch834/1133, batch loss:3.475779521977529e-05, Training time:74284.98116612434
batch reward last col mean 2.195349043176975e-05 first col mean 8.715529475011863e-06 all mean 5.2579383918782696e-05
2.223335650342051e-05 2.2233345589484088e-05
rl training, epoch4, iter0, batch835/1133, batch loss:2.2233345589484088e-05, Training time:74301.93512225151
batch reward last col mean 7.482195996999508e-06 first col mean 0.0006642851512879133 all mean 7.356076093856245e-05
4.797344081453048e-05 4.7973455366445705e-05
rl training, epoch4, iter0, batch836/1133, batch loss:4.7973455366445705e-05, Training time:74318.83723139763
batch reward last col mean 8.584675015299581e-06 first col mean 7.0100622906466015e-06 all mean 9.016111289383844e-05
6.130601104814559e-05 6.130600377218798e-05
rl training, epoch4, iter0, batch837/1133, batch loss:6.130600377218798e-05, Training time:74335.69393181801
batch reward last col mean 6.627118636970408e-06 first col mean 3.9988999560591765e-06 all mean 3.847256084554829e-05
9.118715752265416e-06 9.118704838328995e-06
rl training, epoch4, iter0, batch838/1133, batch loss:9.118704838328995e-06, Training time:74352.69639873505
batch reward last col mean 2.488747486495413e-05 first col mean 6.108069101173896e-06 all mean 7.501005893573165e-05
0.00013997651694808155 0.00013997651694808155
rl training, epoch4, iter0, batch839/1133, batch loss:0.00013997651694808155, Training time:74369.60714793205
batch reward last col mean 0.00014523742720484734 first col mean 0.00022180653468240052 all mean 5.167633207747713e-05
0.0001357762812403962 0.00013577626668848097
rl training, epoch4, iter0, batch840/1133, batch loss:0.00013577626668848097, Training time:74386.62819433212
batch reward last col mean 0.0002273852442158386 first col mean 2.9035989427939057e-05 all mean 5.7818444474833086e-05
4.360624370747246e-05 4.360624370747246e-05
rl training, epoch4, iter0, batch841/1133, batch loss:4.360624370747246e-05, Training time:74403.50001883507
batch reward last col mean 0.0034296317026019096 first col mean 1.1927582818316296e-05 all mean 8.567752229282632e-05
0.00024284144456032664 0.00024284144456032664
rl training, epoch4, iter0, batch842/1133, batch loss:0.00024284144456032664, Training time:74420.75391864777
batch reward last col mean 6.1127066146582365e-06 first col mean 4.852640813624021e-06 all mean 5.2045063057448715e-05
2.6299105229554698e-05 2.629911068652291e-05
rl training, epoch4, iter0, batch843/1133, batch loss:2.629911068652291e-05, Training time:74437.68536496162
batch reward last col mean 5.308101663104026e-06 first col mean 1.098031316359993e-05 all mean 2.8582930099219084e-05
1.6486426829942502e-05 1.6486432286910713e-05
rl training, epoch4, iter0, batch844/1133, batch loss:1.6486432286910713e-05, Training time:74456.20990538597
batch reward last col mean 9.570007023285143e-06 first col mean 7.86187683843309e-06 all mean 2.9656321203219704e-05
4.509164682531264e-06 4.509168320510071e-06
rl training, epoch4, iter0, batch845/1133, batch loss:4.509168320510071e-06, Training time:74474.36395907402
batch reward last col mean 4.820221511181444e-05 first col mean 3.00209262604767e-06 all mean 4.981968959327787e-05
1.587979932082817e-05 1.587979386385996e-05
rl training, epoch4, iter0, batch846/1133, batch loss:1.587979386385996e-05, Training time:74491.18306064606
batch reward last col mean 8.097938552964479e-05 first col mean 5.34623450221261e-06 all mean 6.819643749622628e-05
2.18789264181396e-05 2.1878935513086617e-05
rl training, epoch4, iter0, batch847/1133, batch loss:2.1878935513086617e-05, Training time:74507.92158222198
batch reward last col mean 2.376488919253461e-05 first col mean 1.0155729796679225e-05 all mean 7.95879604993388e-05
5.629637962556444e-05 5.629639417747967e-05
rl training, epoch4, iter0, batch848/1133, batch loss:5.629639417747967e-05, Training time:74524.84129619598
batch reward last col mean 2.8186348117742455e-06 first col mean 2.085558435283019e-06 all mean 3.0414050343097188e-05
1.1397629350540228e-05 1.139762480306672e-05
rl training, epoch4, iter0, batch849/1133, batch loss:1.139762480306672e-05, Training time:74541.8602848053
batch reward last col mean 1.4382068911800161e-05 first col mean 4.281528163119219e-06 all mean 5.796520781586878e-05
2.6926214559352957e-05 2.692620546440594e-05
rl training, epoch4, iter0, batch850/1133, batch loss:2.692620546440594e-05, Training time:74558.53616213799
batch reward last col mean 0.004768111743032932 first col mean 0.00023073164629749954 all mean 0.001944201416336
0.00019519335182849318 0.00019519335182849318
rl training, epoch4, iter0, batch851/1133, batch loss:0.00019519335182849318, Training time:74575.63290596008
batch reward last col mean 2.9551513307524147e-06 first col mean 5.398711800808087e-05 all mean 6.840855348855257e-05
2.2412828911910765e-05 2.2412817997974344e-05
rl training, epoch4, iter0, batch852/1133, batch loss:2.2412817997974344e-05, Training time:74592.67486572266
batch reward last col mean 7.838322198949754e-05 first col mean 7.073685992509127e-06 all mean 7.543356332462281e-05
3.683926479425281e-05 3.683926479425281e-05
rl training, epoch4, iter0, batch853/1133, batch loss:3.683926479425281e-05, Training time:74609.77876853943
batch reward last col mean 6.128831046225969e-06 first col mean 7.158419975894503e-06 all mean 5.5705160775687546e-05
1.841108314692974e-05 1.8411075870972127e-05
rl training, epoch4, iter0, batch854/1133, batch loss:1.8411075870972127e-05, Training time:74626.80764842033
batch reward last col mean 2.408297859801678e-06 first col mean 1.43727011163719e-05 all mean 8.083917782641947e-05
4.061526487930678e-05 4.061526487930678e-05
rl training, epoch4, iter0, batch855/1133, batch loss:4.061526487930678e-05, Training time:74643.58790421486
batch reward last col mean 1.171236544905696e-05 first col mean 1.1991859537374694e-05 all mean 0.00012185315426904708
0.0001624718279344961 0.00016247184248641133
rl training, epoch4, iter0, batch856/1133, batch loss:0.00016247184248641133, Training time:74660.49319458008
batch reward last col mean 5.98179849475855e-06 first col mean 3.2339270546799526e-05 all mean 8.850211452227086e-05
4.763843026012182e-05 4.7638415708206594e-05
rl training, epoch4, iter0, batch857/1133, batch loss:4.7638415708206594e-05, Training time:74677.24561858177
batch reward last col mean 2.4053988454397768e-05 first col mean 7.130066478566732e-06 all mean 6.810746708652005e-05
7.444150105584413e-05 7.444150833180174e-05
rl training, epoch4, iter0, batch858/1133, batch loss:7.444150833180174e-05, Training time:74694.04886722565
batch reward last col mean 8.995828466140665e-06 first col mean 2.8205209673615173e-05 all mean 5.767501352238469e-05
2.5065695808734745e-05 2.506570308469236e-05
rl training, epoch4, iter0, batch859/1133, batch loss:2.506570308469236e-05, Training time:74710.80891799927
batch reward last col mean 1.1308417015243322e-05 first col mean 1.842749406932853e-05 all mean 3.085594289586879e-05
9.89740055956645e-06 9.897397831082344e-06
rl training, epoch4, iter0, batch860/1133, batch loss:9.897397831082344e-06, Training time:74727.54151964188
batch reward last col mean 5.167347808310296e-06 first col mean 1.2762850019498728e-05 all mean 5.593010791926645e-05
1.6997992133838125e-05 1.699799577181693e-05
rl training, epoch4, iter0, batch861/1133, batch loss:1.699799577181693e-05, Training time:74744.27665710449
batch reward last col mean 1.467011770728277e-06 first col mean 0.0015188349643722177 all mean 9.228614362655208e-05
4.187808735878207e-05 4.1878065530909225e-05
rl training, epoch4, iter0, batch862/1133, batch loss:4.1878065530909225e-05, Training time:74760.98644948006
batch reward last col mean 2.7176389266969636e-05 first col mean 7.794369594193995e-05 all mean 7.053410809021443e-05
2.1854039005120285e-05 2.1854044462088495e-05
rl training, epoch4, iter0, batch863/1133, batch loss:2.1854044462088495e-05, Training time:74777.65525627136
batch reward last col mean 4.293446909287013e-05 first col mean 1.75351704001514e-06 all mean 0.00011481418914627284
2.864355883502867e-05 2.8643557016039267e-05
rl training, epoch4, iter0, batch864/1133, batch loss:2.8643557016039267e-05, Training time:74794.25890374184
batch reward last col mean 8.996014912554529e-06 first col mean 1.1380200703570154e-05 all mean 3.5014796594623476e-05
1.2599168258020654e-05 1.2599171895999461e-05
rl training, epoch4, iter0, batch865/1133, batch loss:1.2599171895999461e-05, Training time:74810.98789525032
batch reward last col mean 0.00016867504746187478 first col mean 2.001799293793738e-05 all mean 6.795131048420444e-05
2.837401370925363e-05 2.837400279531721e-05
rl training, epoch4, iter0, batch866/1133, batch loss:2.837400279531721e-05, Training time:74827.6189854145
batch reward last col mean 5.620809315587394e-05 first col mean 1.1838043974421453e-05 all mean 8.871165482560173e-05
3.132408528472297e-05 3.132408164674416e-05
rl training, epoch4, iter0, batch867/1133, batch loss:3.132408164674416e-05, Training time:74844.45496726036
batch reward last col mean 1.0110011317010503e-05 first col mean 6.057576683815569e-06 all mean 7.11432658135891e-05
9.252515155822039e-05 9.252515155822039e-05
rl training, epoch4, iter0, batch868/1133, batch loss:9.252515155822039e-05, Training time:74861.15731239319
batch reward last col mean 3.565151564544067e-05 first col mean 3.02289190585725e-05 all mean 7.923394878162071e-05
2.3118984245229512e-05 2.311898242624011e-05
rl training, epoch4, iter0, batch869/1133, batch loss:2.311898242624011e-05, Training time:74878.0480055809
batch reward last col mean 3.6527394513541367e-06 first col mean 8.723128303245176e-06 all mean 6.347031012410298e-05
4.6271481551229954e-05 4.6271492465166375e-05
rl training, epoch4, iter0, batch870/1133, batch loss:4.6271492465166375e-05, Training time:74894.8222849369
batch reward last col mean 8.980495294963475e-06 first col mean 1.2833159416913986e-05 all mean 5.65269474464003e-05
2.982125624839682e-05 2.9821247153449804e-05
rl training, epoch4, iter0, batch871/1133, batch loss:2.9821247153449804e-05, Training time:74911.75787854195
batch reward last col mean 1.8488475689082406e-05 first col mean 1.9896366211469285e-05 all mean 6.468401261372492e-05
5.48233583685942e-05 5.4823362006573007e-05
rl training, epoch4, iter0, batch872/1133, batch loss:5.4823362006573007e-05, Training time:74928.45176315308
batch reward last col mean 1.966839590750169e-05 first col mean 4.749848358187592e-06 all mean 5.479065657709725e-05
2.5909836040227674e-05 2.5909836040227674e-05
rl training, epoch4, iter0, batch873/1133, batch loss:2.5909836040227674e-05, Training time:74945.25018548965
batch reward last col mean 0.0004715447430498898 first col mean 3.8839875742269214e-06 all mean 3.104411734966561e-05
4.841303962166421e-05 4.841304325964302e-05
rl training, epoch4, iter0, batch874/1133, batch loss:4.841304325964302e-05, Training time:74962.00919055939
batch reward last col mean 3.026280637641321e-06 first col mean 1.36872440634761e-05 all mean 5.289361797622405e-05
2.244566348963417e-05 2.2445667127612978e-05
rl training, epoch4, iter0, batch875/1133, batch loss:2.2445667127612978e-05, Training time:74979.06557750702
batch reward last col mean 2.203442454629112e-05 first col mean 9.315063834947068e-06 all mean 5.948876423644833e-05
1.681873618508689e-05 1.6818743461044505e-05
rl training, epoch4, iter0, batch876/1133, batch loss:1.6818743461044505e-05, Training time:74996.08535218239
batch reward last col mean 3.6714943689730717e-06 first col mean 0.00017022933752741665 all mean 7.799543527653441e-05
2.7363359549781308e-05 2.7363352273823693e-05
rl training, epoch4, iter0, batch877/1133, batch loss:2.7363352273823693e-05, Training time:75013.05618166924
batch reward last col mean 1.2101785614504479e-05 first col mean 3.290553286205977e-05 all mean 8.74548131832853e-05
4.292856465326622e-05 4.2928561015287414e-05
rl training, epoch4, iter0, batch878/1133, batch loss:4.2928561015287414e-05, Training time:75030.12122988701
batch reward last col mean 1.8204977095592767e-05 first col mean 0.0001444079534849152 all mean 5.793373929918744e-05
6.679401121800765e-05 6.679401849396527e-05
rl training, epoch4, iter0, batch879/1133, batch loss:6.679401849396527e-05, Training time:75047.05980610847
batch reward last col mean 1.3236431186669506e-05 first col mean 3.369873866176931e-06 all mean 6.597526953555644e-05
0.00010153117182198912 0.00010153117182198912
rl training, epoch4, iter0, batch880/1133, batch loss:0.00010153117182198912, Training time:75063.95433211327
batch reward last col mean 8.749977496336214e-06 first col mean 6.527754885610193e-05 all mean 3.296481736470014e-05
8.200885531550739e-06 8.20088644104544e-06
rl training, epoch4, iter0, batch881/1133, batch loss:8.20088644104544e-06, Training time:75082.38689041138
batch reward last col mean 0.0005547255859710276 first col mean 4.023529527330538e-06 all mean 6.125766958575696e-05
2.4218845283030532e-05 2.421884346404113e-05
rl training, epoch4, iter0, batch882/1133, batch loss:2.421884346404113e-05, Training time:75099.3107945919
batch reward last col mean 5.726459494326264e-05 first col mean 1.3995247172715608e-05 all mean 5.4592572269029915e-05
3.1428378861164674e-05 3.142837522318587e-05
rl training, epoch4, iter0, batch883/1133, batch loss:3.142837522318587e-05, Training time:75116.13696575165
batch reward last col mean 1.9606603018473834e-05 first col mean 6.7333949118619785e-06 all mean 2.6661396987037733e-05
1.6041225535445847e-05 1.604122735443525e-05
rl training, epoch4, iter0, batch884/1133, batch loss:1.604122735443525e-05, Training time:75133.17785215378
batch reward last col mean 0.00021340488456189632 first col mean 6.487475911853835e-05 all mean 6.730909808538854e-05
5.8494344557402655e-05 5.8494344557402655e-05
rl training, epoch4, iter0, batch885/1133, batch loss:5.8494344557402655e-05, Training time:75150.05539488792
batch reward last col mean 7.447336975019425e-05 first col mean 3.520007885526866e-05 all mean 5.980659261695109e-05
5.6429835240123793e-05 5.6429835240123793e-05
rl training, epoch4, iter0, batch886/1133, batch loss:5.6429835240123793e-05, Training time:75166.99834012985
batch reward last col mean 1.3541074622480664e-05 first col mean 7.233473297674209e-06 all mean 3.2434763852506876e-05
5.1379072829149663e-05 5.1379072829149663e-05
rl training, epoch4, iter0, batch887/1133, batch loss:5.1379072829149663e-05, Training time:75184.04359722137
batch reward last col mean 1.5988387531251647e-05 first col mean 9.540141036268324e-06 all mean 8.479740063194185e-05
2.807541750371456e-05 2.8075415684725158e-05
rl training, epoch4, iter0, batch888/1133, batch loss:2.8075415684725158e-05, Training time:75200.91277074814
batch reward last col mean 8.795178291620687e-05 first col mean 7.699428533669561e-05 all mean 0.00010353983088862151
3.392589496797882e-05 3.392589133000001e-05
rl training, epoch4, iter0, batch889/1133, batch loss:3.392589133000001e-05, Training time:75217.79481720924
batch reward last col mean 1.8044524040305987e-05 first col mean 1.753927608660888e-05 all mean 6.262173701543361e-05
1.387834799970733e-05 1.3878341633244418e-05
rl training, epoch4, iter0, batch890/1133, batch loss:1.3878341633244418e-05, Training time:75234.67354130745
batch reward last col mean 2.833223516063299e-05 first col mean 6.057814971427433e-06 all mean 4.0833663661032915e-05
1.9161352611263283e-05 1.916135079227388e-05
rl training, epoch4, iter0, batch891/1133, batch loss:1.916135079227388e-05, Training time:75252.33601951599
batch reward last col mean 9.320311619376298e-06 first col mean 8.829832950141281e-06 all mean 3.8282778405118734e-05
2.1752099200966768e-05 2.1752099200966768e-05
rl training, epoch4, iter0, batch892/1133, batch loss:2.1752099200966768e-05, Training time:75271.07659339905
batch reward last col mean 1.5661165889468975e-05 first col mean 1.9648210582090542e-05 all mean 6.293839396676049e-05
1.801618782337755e-05 1.801619328034576e-05
rl training, epoch4, iter0, batch893/1133, batch loss:1.801619328034576e-05, Training time:75287.97341966629
batch reward last col mean 5.519032129086554e-06 first col mean 1.0071182259707712e-05 all mean 5.386785778682679e-05
3.352178828208707e-05 3.352178828208707e-05
rl training, epoch4, iter0, batch894/1133, batch loss:3.352178828208707e-05, Training time:75304.81595182419
batch reward last col mean 8.063294444582425e-06 first col mean 7.109939178917557e-05 all mean 7.673243089811876e-05
5.4748154070694e-05 5.4748161346651614e-05
rl training, epoch4, iter0, batch895/1133, batch loss:5.4748161346651614e-05, Training time:75322.23046326637
batch reward last col mean 4.093720417586155e-05 first col mean 4.377871664473787e-05 all mean 9.079293522518128e-05
5.789169154013507e-05 5.7891687902156264e-05
rl training, epoch4, iter0, batch896/1133, batch loss:5.7891687902156264e-05, Training time:75339.11308455467
batch reward last col mean 7.1757740442990325e-06 first col mean 9.205978130921721e-06 all mean 3.498603473417461e-05
2.7932936063734815e-05 2.7932932425756007e-05
rl training, epoch4, iter0, batch897/1133, batch loss:2.7932932425756007e-05, Training time:75355.7937746048
batch reward last col mean 3.457582351984456e-05 first col mean 7.0946307459962554e-06 all mean 5.63812573091127e-05
4.922861990053207e-05 4.922861262457445e-05
rl training, epoch4, iter0, batch898/1133, batch loss:4.922861262457445e-05, Training time:75373.30083966255
batch reward last col mean 1.457528651371831e-05 first col mean 8.815693945507519e-06 all mean 4.59850016341079e-05
2.9352037017815746e-05 2.935203883680515e-05
rl training, epoch4, iter0, batch899/1133, batch loss:2.935203883680515e-05, Training time:75390.26558685303
batch reward last col mean 3.845406808977714e-06 first col mean 9.529142516839784e-06 all mean 3.903011747752316e-05
1.5126169273571577e-05 1.5126162907108665e-05
rl training, epoch4, iter0, batch900/1133, batch loss:1.5126162907108665e-05, Training time:75407.2595026493
batch reward last col mean 1.0562233001110144e-05 first col mean 4.700109457189683e-06 all mean 4.2584975744830444e-05
1.1871516107930802e-05 1.1871517926920205e-05
rl training, epoch4, iter0, batch901/1133, batch loss:1.1871517926920205e-05, Training time:75424.22491407394
batch reward last col mean 8.068865281529725e-05 first col mean 4.464208814169979e-06 all mean 6.421000580303371e-05
2.1405019651865587e-05 2.1405019651865587e-05
rl training, epoch4, iter0, batch902/1133, batch loss:2.1405019651865587e-05, Training time:75441.27097582817
batch reward last col mean 5.481413154484471e-06 first col mean 1.8271314274898032e-06 all mean 2.9867007469874807e-05
2.854437661881093e-05 2.854437661881093e-05
rl training, epoch4, iter0, batch903/1133, batch loss:2.854437661881093e-05, Training time:75458.21705818176
batch reward last col mean 2.619431370476377e-06 first col mean 1.4371476027008612e-05 all mean 3.5708308132598177e-05
9.631279681343585e-06 9.631279681343585e-06
rl training, epoch4, iter0, batch904/1133, batch loss:9.631279681343585e-06, Training time:75476.92635345459
batch reward last col mean 8.633256220491603e-05 first col mean 8.301436537294649e-06 all mean 0.00011108572653029114
5.8493220421951264e-05 5.849322769790888e-05
rl training, epoch4, iter0, batch905/1133, batch loss:5.849322769790888e-05, Training time:75495.44353747368
batch reward last col mean 2.1949417714495212e-05 first col mean 6.991395366640063e-06 all mean 0.0001226353197125718
7.05599959474057e-05 7.055998867144808e-05
rl training, epoch4, iter0, batch906/1133, batch loss:7.055998867144808e-05, Training time:75512.36960530281
batch reward last col mean 4.38927199866157e-05 first col mean 2.3452845198335126e-05 all mean 7.080436625983566e-05
3.1480703910347074e-05 3.148069663438946e-05
rl training, epoch4, iter0, batch907/1133, batch loss:3.148069663438946e-05, Training time:75529.4046485424
batch reward last col mean 2.222984221589286e-06 first col mean 1.6628563344056602e-06 all mean 4.274036837159656e-05
2.5244544303859584e-05 2.524454248487018e-05
rl training, epoch4, iter0, batch908/1133, batch loss:2.524454248487018e-05, Training time:75546.72036147118
batch reward last col mean 8.43894940771861e-06 first col mean 4.738071947940625e-05 all mean 3.972418198827654e-05
2.166426020266954e-05 2.1664263840648346e-05
rl training, epoch4, iter0, batch909/1133, batch loss:2.1664263840648346e-05, Training time:75565.18487071991
batch reward last col mean 2.9668295610463247e-05 first col mean 5.451007018564269e-05 all mean 5.9726084145950153e-05
4.061649815412238e-05 4.0616483602207154e-05
rl training, epoch4, iter0, batch910/1133, batch loss:4.0616483602207154e-05, Training time:75584.00265645981
batch reward last col mean 7.210855528683169e-06 first col mean 3.665470558189554e-06 all mean 7.038723560981452e-05
2.8019996534567326e-05 2.8020005629514344e-05
rl training, epoch4, iter0, batch911/1133, batch loss:2.8020005629514344e-05, Training time:75602.8824725151
batch reward last col mean 1.1987543985014781e-05 first col mean 2.60517426795559e-05 all mean 7.537809869972989e-05
2.2954152882448398e-05 2.295414924446959e-05
rl training, epoch4, iter0, batch912/1133, batch loss:2.295414924446959e-05, Training time:75621.08689951897
batch reward last col mean 1.5581174011458643e-05 first col mean 1.8314818589715287e-05 all mean 7.380858005490154e-05
5.625681660603732e-05 5.625681296805851e-05
rl training, epoch4, iter0, batch913/1133, batch loss:5.625681296805851e-05, Training time:75639.22581100464
batch reward last col mean 2.2311487555271015e-06 first col mean 3.6589126466424204e-06 all mean 1.2234483619977254e-05
5.77325272388407e-06 5.773254088126123e-06
rl training, epoch4, iter0, batch914/1133, batch loss:5.773254088126123e-06, Training time:75657.4661450386
batch reward last col mean 1.8853759229386924e-06 first col mean 8.445072126050945e-06 all mean 4.659466867451556e-05
1.657886059547309e-05 1.6578864233451895e-05
rl training, epoch4, iter0, batch915/1133, batch loss:1.6578864233451895e-05, Training time:75676.04791235924
batch reward last col mean 3.220916823920561e-06 first col mean 6.910503543622326e-06 all mean 8.158370474120602e-05
1.726433401927352e-05 1.726432856230531e-05
rl training, epoch4, iter0, batch916/1133, batch loss:1.726432856230531e-05, Training time:75692.68248581886
batch reward last col mean 2.613415381347295e-05 first col mean 2.4019467673497275e-05 all mean 9.113900159718469e-05
6.455089896917343e-05 6.455087714130059e-05
rl training, epoch4, iter0, batch917/1133, batch loss:6.455087714130059e-05, Training time:75711.30344367027
batch reward last col mean 4.710067514679395e-06 first col mean 9.711376151244622e-06 all mean 7.864614599384367e-05
2.9757176889688708e-05 2.975717870867811e-05
rl training, epoch4, iter0, batch918/1133, batch loss:2.975717870867811e-05, Training time:75728.16061544418
batch reward last col mean 1.615693690837361e-05 first col mean 3.276114966865862e-06 all mean 8.06638490757905e-05
1.7619813661440276e-05 1.7619819118408486e-05
rl training, epoch4, iter0, batch919/1133, batch loss:1.7619819118408486e-05, Training time:75744.82966184616
batch reward last col mean 8.581782822147943e-06 first col mean 8.040688044275157e-06 all mean 9.852978837443516e-05
2.6904494006885216e-05 2.6904483092948794e-05
rl training, epoch4, iter0, batch920/1133, batch loss:2.6904483092948794e-05, Training time:75761.67752408981
batch reward last col mean 2.112851507263258e-05 first col mean 4.022590474050958e-06 all mean 5.712721394957043e-05
3.49863876181189e-05 3.498638398014009e-05
rl training, epoch4, iter0, batch921/1133, batch loss:3.498638398014009e-05, Training time:75780.53734850883
batch reward last col mean 8.23319896881003e-06 first col mean 1.4012142855790444e-05 all mean 9.44945786613971e-05
2.0940506146871485e-05 2.0940522517776117e-05
rl training, epoch4, iter0, batch922/1133, batch loss:2.0940522517776117e-05, Training time:75798.6772377491
batch reward last col mean 1.7415993625036208e-06 first col mean 5.0320559239480644e-06 all mean 0.00011888176231877878
3.730963362613693e-05 3.730964817805216e-05
rl training, epoch4, iter0, batch923/1133, batch loss:3.730964817805216e-05, Training time:75817.25378656387
batch reward last col mean 1.0831710824277252e-05 first col mean 7.968479621922597e-06 all mean 8.833473839331418e-05
3.8514055631821975e-05 3.851404835586436e-05
rl training, epoch4, iter0, batch924/1133, batch loss:3.851404835586436e-05, Training time:75835.53778338432
batch reward last col mean 1.3841487998433877e-05 first col mean 4.930434442940168e-06 all mean 6.13744487054646e-05
2.272142592119053e-05 2.2721427740179934e-05
rl training, epoch4, iter0, batch925/1133, batch loss:2.2721427740179934e-05, Training time:75854.27666378021
batch reward last col mean 5.521573257283308e-06 first col mean 5.704315299226437e-06 all mean 6.493699765997007e-05
3.292149267508648e-05 3.292148539912887e-05
rl training, epoch4, iter0, batch926/1133, batch loss:3.292148539912887e-05, Training time:75872.59882116318
batch reward last col mean 4.077461653650971e-06 first col mean 0.00011310059198876843 all mean 6.105396460043266e-05
4.53643842774909e-05 4.5364387915469706e-05
rl training, epoch4, iter0, batch927/1133, batch loss:4.5364387915469706e-05, Training time:75891.27431678772
batch reward last col mean 6.31582179266843e-06 first col mean 0.0004452423600014299 all mean 3.293498230050318e-05
1.893997614388354e-05 1.8939974324894138e-05
rl training, epoch4, iter0, batch928/1133, batch loss:1.8939974324894138e-05, Training time:75909.78216314316
batch reward last col mean 8.301259185827803e-06 first col mean 1.1362046279828064e-05 all mean 4.409347093314864e-05
1.334216085524531e-05 1.33421553982771e-05
rl training, epoch4, iter0, batch929/1133, batch loss:1.33421553982771e-05, Training time:75928.04196453094
batch reward last col mean 5.0724815991998184e-06 first col mean 3.47493878507521e-05 all mean 5.197452264837921e-05
1.2539627277874388e-05 1.253962818736909e-05
rl training, epoch4, iter0, batch930/1133, batch loss:1.253962818736909e-05, Training time:75946.79864788055
batch reward last col mean 1.7471456885687076e-06 first col mean 3.1530998967355117e-06 all mean 4.754451947519556e-05
1.5318790246965364e-05 1.5318786608986557e-05
rl training, epoch4, iter0, batch931/1133, batch loss:1.5318786608986557e-05, Training time:75964.25121974945
batch reward last col mean 1.4871923667669762e-05 first col mean 7.12300152372336e-06 all mean 3.310763349873014e-05
1.5005192835815251e-05 1.5005192835815251e-05
rl training, epoch4, iter0, batch932/1133, batch loss:1.5005192835815251e-05, Training time:75981.210231781
batch reward last col mean 6.5831000028993e-06 first col mean 1.8986849681823514e-05 all mean 0.00011170215293532237
4.343355612945743e-05 4.343355612945743e-05
rl training, epoch4, iter0, batch933/1133, batch loss:4.343355612945743e-05, Training time:75997.9305305481
batch reward last col mean 8.923139830585569e-05 first col mean 1.0026655218098313e-05 all mean 6.833867519162595e-05
1.1887440450664144e-05 1.1887434993695933e-05
rl training, epoch4, iter0, batch934/1133, batch loss:1.1887434993695933e-05, Training time:76014.65348386765
batch reward last col mean 0.00019561070075724274 first col mean 1.1159035238961224e-05 all mean 5.634644548990764e-05
2.9142494895495474e-05 2.9142496714484878e-05
rl training, epoch4, iter0, batch935/1133, batch loss:2.9142496714484878e-05, Training time:76031.45380187035
batch reward last col mean 7.878785982029513e-05 first col mean 3.507786459522322e-06 all mean 2.635070268297568e-05
1.3168567420507316e-05 1.3168569239496719e-05
rl training, epoch4, iter0, batch936/1133, batch loss:1.3168569239496719e-05, Training time:76048.05359172821
batch reward last col mean 1.726722803141456e-05 first col mean 7.246525910886703e-06 all mean 3.7945046642562374e-05
1.2992047231819015e-05 1.299204996030312e-05
rl training, epoch4, iter0, batch937/1133, batch loss:1.299204996030312e-05, Training time:76064.78140115738
batch reward last col mean 6.23221467321855e-06 first col mean 1.3554475117416587e-05 all mean 0.00011434287443989888
2.8641510652960278e-05 2.8641517928917892e-05
rl training, epoch4, iter0, batch938/1133, batch loss:2.8641517928917892e-05, Training time:76083.08648014069
batch reward last col mean 2.021253931161482e-05 first col mean 0.0004752335080411285 all mean 0.00010646651935530826
6.446191400755197e-05 6.446189945563674e-05
rl training, epoch4, iter0, batch939/1133, batch loss:6.446189945563674e-05, Training time:76101.14724302292
batch reward last col mean 4.120221547054825e-06 first col mean 3.295503483968787e-05 all mean 8.217546564992517e-05
3.122073030681349e-05 3.122073758277111e-05
rl training, epoch4, iter0, batch940/1133, batch loss:3.122073758277111e-05, Training time:76119.634319067
batch reward last col mean 4.915591125609353e-05 first col mean 2.0401465008035302e-05 all mean 0.00012905464973300695
4.4538432121044025e-05 4.4538432121044025e-05
rl training, epoch4, iter0, batch941/1133, batch loss:4.4538432121044025e-05, Training time:76137.06676220894
batch reward last col mean 1.1475465726107359e-05 first col mean 1.3262448192108423e-05 all mean 8.619052096037194e-05
4.452819121070206e-05 4.452819121070206e-05
rl training, epoch4, iter0, batch942/1133, batch loss:4.452819121070206e-05, Training time:76155.19671297073
batch reward last col mean 1.4409943105420098e-05 first col mean 1.329981296294136e-05 all mean 3.5170847695553675e-05
3.498914520605467e-05 3.498914520605467e-05
rl training, epoch4, iter0, batch943/1133, batch loss:3.498914520605467e-05, Training time:76174.73415732384
batch reward last col mean 3.0110531952232122e-05 first col mean 1.3335011317394674e-05 all mean 9.837117977440357e-05
5.96431564190425e-05 5.964315278106369e-05
rl training, epoch4, iter0, batch944/1133, batch loss:5.964315278106369e-05, Training time:76192.76942515373
batch reward last col mean 0.0001714251993689686 first col mean 1.209931360790506e-05 all mean 7.047734834486619e-05
4.226894452585839e-05 4.226893724990077e-05
rl training, epoch4, iter0, batch945/1133, batch loss:4.226893724990077e-05, Training time:76211.15515732765
batch reward last col mean 3.843243575829547e-06 first col mean 4.141069803154096e-05 all mean 0.00010576603381196037
1.7485743228462525e-05 1.7485745047451928e-05
rl training, epoch4, iter0, batch946/1133, batch loss:1.7485745047451928e-05, Training time:76228.9206020832
batch reward last col mean 3.393610677449033e-05 first col mean 1.5019437341834418e-05 all mean 3.8422851503128186e-05
1.739035542414058e-05 1.739035542414058e-05
rl training, epoch4, iter0, batch947/1133, batch loss:1.739035542414058e-05, Training time:76245.81417059898
batch reward last col mean 0.002001670654863119 first col mean 3.6697854284284404e-06 all mean 0.0012768687447533011
0.0001680939458310604 0.00016809393127914518
rl training, epoch4, iter0, batch948/1133, batch loss:0.00016809393127914518, Training time:76262.86079525948
batch reward last col mean 0.00011271140101598576 first col mean 3.7763888940389734e-06 all mean 5.602131932391785e-05
1.5138372873479966e-05 1.5138371963985264e-05
rl training, epoch4, iter0, batch949/1133, batch loss:1.5138371963985264e-05, Training time:76279.76563596725
batch reward last col mean 7.7879085438326e-06 first col mean 0.0009764744318090379 all mean 5.4900618124520406e-05
1.5976511349435896e-05 1.59765131684253e-05
rl training, epoch4, iter0, batch950/1133, batch loss:1.59765131684253e-05, Training time:76296.58525800705
batch reward last col mean 0.0038465133402496576 first col mean 0.00020509646856226027 all mean 0.0001310757506871596
0.00024060867144726217 0.00024060867144726217
rl training, epoch4, iter0, batch951/1133, batch loss:0.00024060867144726217, Training time:76313.6022260189
batch reward last col mean 4.625148449122207e-06 first col mean 2.010978278121911e-06 all mean 6.688104622298852e-05
4.792016989085823e-05 4.792016989085823e-05
rl training, epoch4, iter0, batch952/1133, batch loss:4.792016989085823e-05, Training time:76330.60848784447
batch reward last col mean 1.7663757034824812e-06 first col mean 6.652470801782329e-06 all mean 7.963577809277922e-05
3.368394754943438e-05 3.368394754943438e-05
rl training, epoch4, iter0, batch953/1133, batch loss:3.368394754943438e-05, Training time:76347.68182086945
batch reward last col mean 5.059857357991859e-06 first col mean 1.7172345906146802e-05 all mean 7.630305481143296e-05
6.888520147185773e-05 6.888520874781534e-05
rl training, epoch4, iter0, batch954/1133, batch loss:6.888520874781534e-05, Training time:76364.53191661835
batch reward last col mean 2.7387582122173626e-06 first col mean 3.670567093649879e-05 all mean 4.7294615797000006e-05
4.673173316405155e-05 4.6731725888093933e-05
rl training, epoch4, iter0, batch955/1133, batch loss:4.6731725888093933e-05, Training time:76381.30566501617
batch reward last col mean 8.17128147900803e-06 first col mean 1.5181662092800252e-05 all mean 4.5994442189112306e-05
2.438078990962822e-05 2.4380786271649413e-05
rl training, epoch4, iter0, batch956/1133, batch loss:2.4380786271649413e-05, Training time:76398.21594691277
batch reward last col mean 7.605702558066696e-05 first col mean 9.642190707381815e-05 all mean 0.0001063759918906726
7.493166776839644e-05 7.493167504435405e-05
rl training, epoch4, iter0, batch957/1133, batch loss:7.493167504435405e-05, Training time:76415.01667284966
batch reward last col mean 5.2903264986525755e-06 first col mean 0.00018477978301234543 all mean 4.909021663479507e-05
2.924452564911917e-05 2.9244527468108572e-05
rl training, epoch4, iter0, batch958/1133, batch loss:2.9244527468108572e-05, Training time:76433.39749670029
batch reward last col mean 5.574529950536089e-06 first col mean 1.1109115803265013e-05 all mean 5.878528827452101e-05
3.5324810596648604e-05 3.5324821510585025e-05
rl training, epoch4, iter0, batch959/1133, batch loss:3.5324821510585025e-05, Training time:76452.15059232712
batch reward last col mean 1.0013642167905346e-05 first col mean 8.524394615960773e-06 all mean 6.969992682570592e-05
1.8493174138711765e-05 1.8493172319722362e-05
rl training, epoch4, iter0, batch960/1133, batch loss:1.8493172319722362e-05, Training time:76470.88375329971
batch reward last col mean 4.267537406121846e-06 first col mean 1.1972648280789144e-05 all mean 5.2181960199959576e-05
4.898059705737978e-05 4.898060069535859e-05
rl training, epoch4, iter0, batch961/1133, batch loss:4.898060069535859e-05, Training time:76487.768512249
batch reward last col mean 5.066527955932543e-05 first col mean 0.00025430836831219494 all mean 0.0001221156562678516
6.542275514220819e-05 6.542275514220819e-05
rl training, epoch4, iter0, batch962/1133, batch loss:6.542275514220819e-05, Training time:76504.54068303108
batch reward last col mean 5.654242340824567e-05 first col mean 5.194729965296574e-06 all mean 5.226362918619998e-05
2.0713514459202997e-05 2.071352173516061e-05
rl training, epoch4, iter0, batch963/1133, batch loss:2.071352173516061e-05, Training time:76522.51888489723
batch reward last col mean 5.115789463161491e-06 first col mean 3.4850074825953925e-06 all mean 8.691130642546341e-05
3.896819180226885e-05 3.896820999216288e-05
rl training, epoch4, iter0, batch964/1133, batch loss:3.896820999216288e-05, Training time:76539.59406971931
batch reward last col mean 1.3027222848904785e-05 first col mean 8.619525942776818e-06 all mean 8.015714411158115e-05
8.938172686612234e-05 8.938172686612234e-05
rl training, epoch4, iter0, batch965/1133, batch loss:8.938172686612234e-05, Training time:76556.51778912544
batch reward last col mean 1.2942329021825572e-06 first col mean 2.5350291252834722e-06 all mean 4.414020440890454e-05
7.464366353815421e-05 7.464367809006944e-05
rl training, epoch4, iter0, batch966/1133, batch loss:7.464367809006944e-05, Training time:76573.45774197578
batch reward last col mean 8.343136869370937e-06 first col mean 4.6420900616794825e-06 all mean 6.146141095086932e-05
2.2429581804317422e-05 2.2429578166338615e-05
rl training, epoch4, iter0, batch967/1133, batch loss:2.2429578166338615e-05, Training time:76590.32863545418
batch reward last col mean 0.0005375752807594836 first col mean 2.290631709911395e-05 all mean 6.674197356915101e-05
9.249892173102126e-05 9.249892900697887e-05
rl training, epoch4, iter0, batch968/1133, batch loss:9.249892900697887e-05, Training time:76607.13790941238
batch reward last col mean 2.343391315662302e-06 first col mean 0.0006690401351079345 all mean 3.769144677789882e-05
1.0040628694696352e-05 1.0040625056717545e-05
rl training, epoch4, iter0, batch969/1133, batch loss:1.0040625056717545e-05, Training time:76624.15274477005
batch reward last col mean 6.1531404753623065e-06 first col mean 4.929402348352596e-05 all mean 5.3575404308503494e-05
1.8213102521258406e-05 1.8213102521258406e-05
rl training, epoch4, iter0, batch970/1133, batch loss:1.8213102521258406e-05, Training time:76641.05789208412
batch reward last col mean 3.6606249977921834e-06 first col mean 1.0933756129816175e-05 all mean 9.418476838618517e-05
8.257327135652304e-05 8.257327863248065e-05
rl training, epoch4, iter0, batch971/1133, batch loss:8.257327863248065e-05, Training time:76657.84690070152
batch reward last col mean 1.7510366888018325e-05 first col mean 7.251189344970044e-06 all mean 4.438458563527092e-05
1.6913390936679207e-05 1.6913389117689803e-05
rl training, epoch4, iter0, batch972/1133, batch loss:1.6913389117689803e-05, Training time:76674.48454880714
batch reward last col mean 8.445527055300772e-05 first col mean 3.190330289726262e-06 all mean 5.937308378634043e-05
3.228002242394723e-05 3.228002242394723e-05
rl training, epoch4, iter0, batch973/1133, batch loss:3.228002242394723e-05, Training time:76691.75449633598
batch reward last col mean 1.2275257176952437e-05 first col mean 9.65432536759181e-06 all mean 7.635358633706346e-05
0.00019370904192328453 0.00019370905647519976
rl training, epoch4, iter0, batch974/1133, batch loss:0.00019370905647519976, Training time:76710.4439842701
batch reward last col mean 9.76074534264626e-06 first col mean 8.118116966215894e-05 all mean 2.053743628493976e-05
1.7371787180309184e-05 1.7371783542330377e-05
rl training, epoch4, iter0, batch975/1133, batch loss:1.7371783542330377e-05, Training time:76729.08191394806
batch reward last col mean 1.0570363883743994e-05 first col mean 1.0387864676886238e-05 all mean 9.261676314054057e-05
1.8938522771350108e-05 1.89385191333713e-05
rl training, epoch4, iter0, batch976/1133, batch loss:1.89385191333713e-05, Training time:76747.65777540207
batch reward last col mean 0.0002254458813695237 first col mean 8.742851059651002e-05 all mean 0.00010474726877873763
5.461731052491814e-05 5.461731052491814e-05
rl training, epoch4, iter0, batch977/1133, batch loss:5.461731052491814e-05, Training time:76765.58548355103
batch reward last col mean 2.120109274983406e-05 first col mean 1.3000733815715648e-05 all mean 3.9914040826261044e-05
1.839111791923642e-05 1.8391123376204632e-05
rl training, epoch4, iter0, batch978/1133, batch loss:1.8391123376204632e-05, Training time:76782.4095082283
batch reward last col mean 6.56585325486958e-06 first col mean 0.0006859283312223852 all mean 9.328426676802337e-05
2.6734596758615226e-05 2.673459312063642e-05
rl training, epoch4, iter0, batch979/1133, batch loss:2.673459312063642e-05, Training time:76801.07361888885
batch reward last col mean 6.636211764998734e-05 first col mean 1.05136814454454e-05 all mean 0.0001162638800451532
2.903813037846703e-05 2.9038137654424645e-05
rl training, epoch4, iter0, batch980/1133, batch loss:2.9038137654424645e-05, Training time:76818.10827350616
batch reward last col mean 0.0027467955369502306 first col mean 2.051722549367696e-05 all mean 8.198277646442875e-05
0.00028529478004202247 0.00028529478004202247
rl training, epoch4, iter0, batch981/1133, batch loss:0.00028529478004202247, Training time:76835.06950759888
batch reward last col mean 7.151971658458933e-06 first col mean 0.00010123760148417205 all mean 7.553093018941581e-05
3.143008143524639e-05 3.143007052130997e-05
rl training, epoch4, iter0, batch982/1133, batch loss:3.143007052130997e-05, Training time:76852.011241436
batch reward last col mean 8.05224226496648e-06 first col mean 4.843110218644142e-06 all mean 2.3242519091581926e-05
8.99390761333052e-06 8.993903065857012e-06
rl training, epoch4, iter0, batch983/1133, batch loss:8.993903065857012e-06, Training time:76868.98039698601
batch reward last col mean 0.00020088993187528104 first col mean 8.57901068229694e-06 all mean 7.287794869625941e-05
6.15148528595455e-05 6.15148528595455e-05
rl training, epoch4, iter0, batch984/1133, batch loss:6.15148528595455e-05, Training time:76885.98546147346
batch reward last col mean 0.0004952935851179063 first col mean 6.724296326865442e-06 all mean 4.466279278858565e-05
1.8318964066565968e-05 1.8318967704544775e-05
rl training, epoch4, iter0, batch985/1133, batch loss:1.8318967704544775e-05, Training time:76904.41360783577
batch reward last col mean 4.596406142809428e-05 first col mean 3.0476028769044206e-05 all mean 6.402457074727863e-05
4.528922727331519e-05 4.528922727331519e-05
rl training, epoch4, iter0, batch986/1133, batch loss:4.528922727331519e-05, Training time:76923.03855752945
batch reward last col mean 1.2866920769738499e-05 first col mean 4.628063106792979e-05 all mean 0.0001138485677074641
8.20540517452173e-05 8.205404446925968e-05
rl training, epoch4, iter0, batch987/1133, batch loss:8.205404446925968e-05, Training time:76941.00838065147
batch reward last col mean 5.0455914788472e-06 first col mean 1.60008294187719e-05 all mean 0.0001079723660950549
5.5495485867140815e-05 5.5495471315225586e-05
rl training, epoch4, iter0, batch988/1133, batch loss:5.5495471315225586e-05, Training time:76957.84521913528
batch reward last col mean 0.007678834721446037 first col mean 8.695862561580725e-06 all mean 0.007416219916194677
0.0006594785954803228 0.0006594785954803228
rl training, epoch4, iter0, batch989/1133, batch loss:0.0006594785954803228, Training time:76974.89980864525
batch reward last col mean 3.5452951124170795e-05 first col mean 2.1428155378089286e-05 all mean 6.46487605990842e-05
0.00010050765558844432 0.00010050763376057148
rl training, epoch4, iter0, batch990/1133, batch loss:0.00010050763376057148, Training time:76991.72743034363
batch reward last col mean 5.8982936934626196e-06 first col mean 9.84919006441487e-06 all mean 6.596570165129378e-05
2.661117832758464e-05 2.661117832758464e-05
rl training, epoch4, iter0, batch991/1133, batch loss:2.661117832758464e-05, Training time:77008.48538851738
batch reward last col mean 2.099740959238261e-05 first col mean 6.909990770509467e-05 all mean 4.3168871343368664e-05
1.0013841347245034e-05 1.0013845894718543e-05
rl training, epoch4, iter0, batch992/1133, batch loss:1.0013845894718543e-05, Training time:77025.37050247192
batch reward last col mean 4.62631442132988e-06 first col mean 0.00041624653385952115 all mean 6.208424747455865e-05
3.0813098419457674e-05 3.0813098419457674e-05
rl training, epoch4, iter0, batch993/1133, batch loss:3.0813098419457674e-05, Training time:77043.90886902809
batch reward last col mean 8.355675163329579e-06 first col mean 3.164085137541406e-05 all mean 5.651501123793423e-05
2.0688903532573022e-05 2.0688903532573022e-05
rl training, epoch4, iter0, batch994/1133, batch loss:2.0688903532573022e-05, Training time:77062.30720806122
batch reward last col mean 4.3011543311877176e-05 first col mean 1.9685710867634043e-05 all mean 6.15642056800425e-05
1.6902475181268528e-05 1.6902475181268528e-05
rl training, epoch4, iter0, batch995/1133, batch loss:1.6902475181268528e-05, Training time:77080.16305708885
batch reward last col mean 1.7579934137756936e-05 first col mean 1.6050053091021255e-05 all mean 4.573442129185423e-05
1.0882852620852645e-05 1.0882856258831453e-05
rl training, epoch4, iter0, batch996/1133, batch loss:1.0882856258831453e-05, Training time:77097.12682580948
batch reward last col mean 4.654896110878326e-05 first col mean 4.04657403123565e-05 all mean 6.968708476051688e-05
4.5559067075373605e-05 4.55590634373948e-05
rl training, epoch4, iter0, batch997/1133, batch loss:4.55590634373948e-05, Training time:77113.84970617294
batch reward last col mean 8.088892172963824e-06 first col mean 8.487057129968889e-06 all mean 6.56005649943836e-05
8.788416744209826e-05 8.788416016614065e-05
rl training, epoch4, iter0, batch998/1133, batch loss:8.788416016614065e-05, Training time:77130.55701971054
batch reward last col mean 1.1090921816503396e-06 first col mean 3.187057927789283e-06 all mean 4.2017152736661956e-05
4.577371510094963e-05 4.577371510094963e-05
rl training, epoch4, iter0, batch999/1133, batch loss:4.577371510094963e-05, Training time:77147.55074167252
batch reward last col mean 2.3939419406815432e-05 first col mean 9.619709999242332e-06 all mean 3.9434955397155136e-05
4.238611290929839e-05 4.238610927131958e-05
rl training, epoch4, iter0, batch1000/1133, batch loss:4.238610927131958e-05, Training time:77164.5334186554
batch reward last col mean 3.354577529535163e-06 first col mean 5.027228326071054e-06 all mean 6.924662011442706e-05
4.5278291509021074e-05 4.5278291509021074e-05
rl training, epoch4, iter0, batch1001/1133, batch loss:4.5278291509021074e-05, Training time:77181.45786237717
batch reward last col mean 1.6728534319554456e-05 first col mean 1.7263602785533294e-05 all mean 5.944432632531971e-05
1.5117288057808764e-05 1.5117288057808764e-05
rl training, epoch4, iter0, batch1002/1133, batch loss:1.5117288057808764e-05, Training time:77198.2818300724
batch reward last col mean 0.00010216042574029416 first col mean 3.1063489586813375e-05 all mean 0.00014258375449571759
8.564149175072089e-05 8.564147719880566e-05
rl training, epoch4, iter0, batch1003/1133, batch loss:8.564147719880566e-05, Training time:77215.73620390892
batch reward last col mean 1.1887429536727723e-05 first col mean 5.781536401627818e-06 all mean 8.20649293018505e-05
6.154955917736515e-05 6.154954462544993e-05
rl training, epoch4, iter0, batch1004/1133, batch loss:6.154954462544993e-05, Training time:77232.48092198372
batch reward last col mean 1.7237006204595673e-06 first col mean 3.3525118396937614e-06 all mean 4.064962558913976e-05
1.337024696113076e-05 1.3370246051636059e-05
rl training, epoch4, iter0, batch1005/1133, batch loss:1.3370246051636059e-05, Training time:77250.45060396194
batch reward last col mean 1.5952020930853905e-06 first col mean 6.404172745533288e-05 all mean 5.04820782225579e-05
1.337652065558359e-05 1.3376517017604783e-05
rl training, epoch4, iter0, batch1006/1133, batch loss:1.3376517017604783e-05, Training time:77267.42308688164
batch reward last col mean 1.6041254639276303e-05 first col mean 9.284152838517912e-06 all mean 7.780673331581056e-05
2.7147681976202875e-05 2.7147676519234665e-05
rl training, epoch4, iter0, batch1007/1133, batch loss:2.7147676519234665e-05, Training time:77284.76457571983
batch reward last col mean 3.1063618735061027e-06 first col mean 1.3199105524108745e-05 all mean 8.858579531079158e-05
0.0001180964318336919 0.00011809642455773428
rl training, epoch4, iter0, batch1008/1133, batch loss:0.00011809642455773428, Training time:77301.50810432434
batch reward last col mean 2.5059098334168084e-05 first col mean 7.922780241642613e-06 all mean 0.00010742889571702108
9.003524610307068e-05 9.003524610307068e-05
rl training, epoch4, iter0, batch1009/1133, batch loss:9.003524610307068e-05, Training time:77318.24575042725
batch reward last col mean 0.00032330796238966286 first col mean 1.0711986760725267e-05 all mean 4.990975503460504e-05
2.866581235139165e-05 2.8665805075434037e-05
rl training, epoch4, iter0, batch1010/1133, batch loss:2.8665805075434037e-05, Training time:77335.14785599709
batch reward last col mean 0.00023513963969890028 first col mean 2.458105700497981e-05 all mean 8.387349953409284e-05
3.885083788190968e-05 3.8850834243930876e-05
rl training, epoch4, iter0, batch1011/1133, batch loss:3.8850834243930876e-05, Training time:77351.85814094543
batch reward last col mean 7.639503564860206e-06 first col mean 9.84866164799314e-06 all mean 7.953893509693444e-05
5.368886195356026e-05 5.368886922951788e-05
rl training, epoch4, iter0, batch1012/1133, batch loss:5.368886922951788e-05, Training time:77369.11632990837
batch reward last col mean 8.087290552794002e-06 first col mean 2.9025906769675203e-05 all mean 5.6108365242835134e-05
4.089590220246464e-05 4.089590220246464e-05
rl training, epoch4, iter0, batch1013/1133, batch loss:4.089590220246464e-05, Training time:77387.94540286064
batch reward last col mean 0.0007974740001372993 first col mean 8.674908713146579e-06 all mean 0.00010294354433426633
0.00011348862608429044 0.00011348862608429044
rl training, epoch4, iter0, batch1014/1133, batch loss:0.00011348862608429044, Training time:77404.88660764694
batch reward last col mean 7.0423889155790675e-06 first col mean 7.2075122261594515e-06 all mean 2.0906258214381523e-05
8.12698453955818e-06 8.126986358547583e-06
rl training, epoch4, iter0, batch1015/1133, batch loss:8.126986358547583e-06, Training time:77421.80921721458
batch reward last col mean 5.373175099521177e-06 first col mean 6.461299108195817e-06 all mean 4.447987521416508e-05
7.202379492809996e-05 7.202379492809996e-05
rl training, epoch4, iter0, batch1016/1133, batch loss:7.202379492809996e-05, Training time:77438.79840874672
batch reward last col mean 7.255577202158747e-06 first col mean 9.138791938312352e-06 all mean 0.00012180980411358178
0.0001672029757173732 0.0001672029757173732
rl training, epoch4, iter0, batch1017/1133, batch loss:0.0001672029757173732, Training time:77455.84579896927
batch reward last col mean 8.49023308546748e-06 first col mean 7.961857590998989e-06 all mean 5.7218727306462824e-05
3.620510324253701e-05 3.620510324253701e-05
rl training, epoch4, iter0, batch1018/1133, batch loss:3.620510324253701e-05, Training time:77472.75704932213
batch reward last col mean 5.680961749021662e-06 first col mean 1.4676281352876686e-05 all mean 5.2118979510851204e-05
2.6431494916323572e-05 2.643150401127059e-05
rl training, epoch4, iter0, batch1019/1133, batch loss:2.643150401127059e-05, Training time:77489.71263360977
batch reward last col mean 1.1796865919677657e-06 first col mean 3.6952990285499254e-06 all mean 1.246013016498182e-05
5.501744453795254e-06 5.501743999047903e-06
rl training, epoch4, iter0, batch1020/1133, batch loss:5.501743999047903e-06, Training time:77506.62345600128
batch reward last col mean 4.122793143324088e-06 first col mean 0.00011668364459183067 all mean 7.605893188156188e-05
2.8176613341202028e-05 2.8176620617159642e-05
rl training, epoch4, iter0, batch1021/1133, batch loss:2.8176620617159642e-05, Training time:77523.57746505737
batch reward last col mean 4.3107327655889094e-05 first col mean 1.865876402007416e-05 all mean 4.4305426854407415e-05
1.526371852378361e-05 1.526371852378361e-05
rl training, epoch4, iter0, batch1022/1133, batch loss:1.526371852378361e-05, Training time:77540.59109306335
batch reward last col mean 9.609457265469246e-06 first col mean 1.100526969821658e-05 all mean 9.371038322569802e-05
2.338566082471516e-05 2.338566082471516e-05
rl training, epoch4, iter0, batch1023/1133, batch loss:2.338566082471516e-05, Training time:77557.60179114342
batch reward last col mean 4.354149496066384e-06 first col mean 1.0933706107607577e-05 all mean 3.530891990521923e-05
1.1511585398693569e-05 1.1511593584145885e-05
rl training, epoch4, iter0, batch1024/1133, batch loss:1.1511593584145885e-05, Training time:77575.3455915451
batch reward last col mean 0.0003571895067580044 first col mean 8.101686944428366e-06 all mean 5.879135642317124e-05
4.980849553248845e-05 4.980848461855203e-05
rl training, epoch4, iter0, batch1025/1133, batch loss:4.980848461855203e-05, Training time:77593.26188111305
batch reward last col mean 5.5677664931863546e-05 first col mean 9.185723683913238e-06 all mean 6.62454913253896e-05
2.0635738110286184e-05 2.0635745386243798e-05
rl training, epoch4, iter0, batch1026/1133, batch loss:2.0635745386243798e-05, Training time:77612.01357293129
batch reward last col mean 0.0010566244600340724 first col mean 1.7835187463788316e-05 all mean 4.8855028580874205e-05
2.4478751583956182e-05 2.447874612698797e-05
rl training, epoch4, iter0, batch1027/1133, batch loss:2.447874612698797e-05, Training time:77628.84921574593
batch reward last col mean 5.5521545618830714e-06 first col mean 0.00019494631851557642 all mean 6.311495235422626e-05
2.3972253984538838e-05 2.3972257622517645e-05
rl training, epoch4, iter0, batch1028/1133, batch loss:2.3972257622517645e-05, Training time:77645.79387187958
batch reward last col mean 2.8982847197767114e-06 first col mean 7.395600732706953e-06 all mean 4.600704414770007e-05
9.454879182158038e-05 9.454879182158038e-05
rl training, epoch4, iter0, batch1029/1133, batch loss:9.454879182158038e-05, Training time:77662.88661837578
batch reward last col mean 0.0016432182164862752 first col mean 4.774482476932462e-06 all mean 0.0006705875275656581
0.00014918872329872102 0.0001491887087468058
rl training, epoch4, iter0, batch1030/1133, batch loss:0.0001491887087468058, Training time:77681.76829385757
batch reward last col mean 4.65649873149232e-06 first col mean 2.8582853701664135e-06 all mean 8.572469960199669e-05
3.24945904139895e-05 3.24945904139895e-05
rl training, epoch4, iter0, batch1031/1133, batch loss:3.24945904139895e-05, Training time:77698.69569921494
batch reward last col mean 0.0035201755817979574 first col mean 2.1083949377498357e-06 all mean 0.0011547730537131429
0.00020169872732367367 0.00020169872732367367
rl training, epoch4, iter0, batch1032/1133, batch loss:0.00020169872732367367, Training time:77716.82850265503
batch reward last col mean 3.2450327580590965e-06 first col mean 7.4825534284173045e-06 all mean 9.556255827192217e-05
8.974770753411576e-05 8.97476784302853e-05
rl training, epoch4, iter0, batch1033/1133, batch loss:8.97476784302853e-05, Training time:77733.61377811432
batch reward last col mean 1.3519245385396061e-06 first col mean 2.2193873974174494e-06 all mean 3.590398046071641e-05
8.786832040641457e-06 8.786839316599071e-06
rl training, epoch4, iter0, batch1034/1133, batch loss:8.786839316599071e-06, Training time:77750.52215766907
batch reward last col mean 5.1798473577946424e-05 first col mean 1.4989747796789743e-05 all mean 5.314566078595817e-05
2.5983259547501802e-05 2.598326864244882e-05
rl training, epoch4, iter0, batch1035/1133, batch loss:2.598326864244882e-05, Training time:77767.39008998871
batch reward last col mean 1.2923943359055556e-05 first col mean 2.4417882741545327e-05 all mean 4.8442867409903556e-05
1.5601261111442e-05 1.5601268387399614e-05
rl training, epoch4, iter0, batch1036/1133, batch loss:1.5601268387399614e-05, Training time:77784.16345500946
batch reward last col mean 8.136499673128128e-06 first col mean 2.312388642167207e-05 all mean 6.31693474133499e-05
2.548865813878365e-05 2.5488661776762456e-05
rl training, epoch4, iter0, batch1037/1133, batch loss:2.5488661776762456e-05, Training time:77800.917345047
batch reward last col mean 5.269437679089606e-05 first col mean 1.1659576557576656e-05 all mean 6.294937338680029e-05
2.3156495444709435e-05 2.315650817763526e-05
rl training, epoch4, iter0, batch1038/1133, batch loss:2.315650817763526e-05, Training time:77817.73446130753
batch reward last col mean 2.7711976144928485e-06 first col mean 3.0424889700952917e-06 all mean 4.942862506140955e-05
9.418513400305528e-06 9.418513400305528e-06
rl training, epoch4, iter0, batch1039/1133, batch loss:9.418513400305528e-06, Training time:77834.56474304199
batch reward last col mean 2.4486441816407023e-06 first col mean 3.860319338855334e-06 all mean 7.647178426850587e-05
5.058190072304569e-05 5.0581922550918534e-05
rl training, epoch4, iter0, batch1040/1133, batch loss:5.0581922550918534e-05, Training time:77851.42471790314
batch reward last col mean 6.6835727920988575e-06 first col mean 3.903443484887248e-06 all mean 4.496125256991945e-05
1.2519877600425389e-05 1.2519882147898898e-05
rl training, epoch4, iter0, batch1041/1133, batch loss:1.2519882147898898e-05, Training time:77868.4821639061
batch reward last col mean 4.943884414387867e-05 first col mean 1.2598575267475098e-05 all mean 6.156232848297805e-05
2.868233605113346e-05 2.868234514608048e-05
rl training, epoch4, iter0, batch1042/1133, batch loss:2.868234514608048e-05, Training time:77885.4239499569
batch reward last col mean 1.0055510756501462e-05 first col mean 7.536267730756663e-06 all mean 0.00012416076788213104
9.777332161320373e-05 9.77733070612885e-05
rl training, epoch4, iter0, batch1043/1133, batch loss:9.77733070612885e-05, Training time:77902.25305914879
batch reward last col mean 1.221560341946315e-05 first col mean 9.478608262725174e-06 all mean 4.233718937030062e-05
3.437345731072128e-05 3.437346458667889e-05
rl training, epoch4, iter0, batch1044/1133, batch loss:3.437346458667889e-05, Training time:77919.27148509026
batch reward last col mean 3.40338701789733e-05 first col mean 0.0001276561088161543 all mean 0.00013205039431340992
0.00011632582027232274 0.0001163257984444499
rl training, epoch4, iter0, batch1045/1133, batch loss:0.0001163257984444499, Training time:77935.9891178608
batch reward last col mean 9.119023161474615e-05 first col mean 1.1099283256044146e-05 all mean 9.334613423561677e-05
4.804558557225391e-05 4.804558557225391e-05
rl training, epoch4, iter0, batch1046/1133, batch loss:4.804558557225391e-05, Training time:77952.85788583755
batch reward last col mean 4.927451300318353e-05 first col mean 9.224116183759179e-06 all mean 6.20712962700054e-05
1.7424143152311444e-05 1.742413041938562e-05
rl training, epoch4, iter0, batch1047/1133, batch loss:1.742413041938562e-05, Training time:77971.5017182827
batch reward last col mean 0.0006522207404486835 first col mean 1.690696444711648e-05 all mean 3.201327126589604e-05
6.304519774857908e-05 6.304519774857908e-05
rl training, epoch4, iter0, batch1048/1133, batch loss:6.304519774857908e-05, Training time:77990.01894164085
batch reward last col mean 1.4410597941605374e-05 first col mean 6.749232852598652e-06 all mean 8.73638127814047e-05
0.00017653875693213195 0.00017653874238021672
rl training, epoch4, iter0, batch1049/1133, batch loss:0.00017653874238021672, Training time:78008.59608435631
batch reward last col mean 9.664849130786024e-06 first col mean 1.2320502719376236e-05 all mean 6.94005866535008e-05
1.6862091797520407e-05 1.686209907347802e-05
rl training, epoch4, iter0, batch1050/1133, batch loss:1.686209907347802e-05, Training time:78025.60089182854
batch reward last col mean 3.998694865003927e-06 first col mean 2.6447069103596732e-05 all mean 7.127319258870557e-05
6.64916806272231e-05 6.649168790318072e-05
rl training, epoch4, iter0, batch1051/1133, batch loss:6.649168790318072e-05, Training time:78042.3688492775
batch reward last col mean 1.0412493793410249e-05 first col mean 8.286921365652233e-05 all mean 5.30394354427699e-05
3.947806908399798e-05 3.947805817006156e-05
rl training, epoch4, iter0, batch1052/1133, batch loss:3.947805817006156e-05, Training time:78059.29488801956
batch reward last col mean 0.00030901332502253354 first col mean 2.659102392499335e-05 all mean 6.718280928907916e-05
6.250587466638535e-05 6.250587466638535e-05
rl training, epoch4, iter0, batch1053/1133, batch loss:6.250587466638535e-05, Training time:78076.23864674568
batch reward last col mean 0.00015146835357882082 first col mean 1.4615561667596921e-05 all mean 3.3907399483723566e-05
2.9963275665068068e-05 2.9963279303046875e-05
rl training, epoch4, iter0, batch1054/1133, batch loss:2.9963279303046875e-05, Training time:78093.06946396828
batch reward last col mean 0.00016829307423904538 first col mean 4.911307041766122e-05 all mean 5.577467891271226e-05
4.622022606781684e-05 4.6220218791859224e-05
rl training, epoch4, iter0, batch1055/1133, batch loss:4.6220218791859224e-05, Training time:78110.12928080559
batch reward last col mean 0.00021456304239109159 first col mean 1.0708574336604215e-05 all mean 6.18128979112953e-05
3.945414209738374e-05 3.9454145735362545e-05
rl training, epoch4, iter0, batch1056/1133, batch loss:3.9454145735362545e-05, Training time:78126.88208723068
batch reward last col mean 7.434884537360631e-06 first col mean 1.1065096259699203e-05 all mean 4.8416826757602394e-05
3.3604243071749806e-05 3.360425034770742e-05
rl training, epoch4, iter0, batch1057/1133, batch loss:3.360425034770742e-05, Training time:78143.68550777435
batch reward last col mean 0.00017856998601928353 first col mean 2.7060128559242003e-05 all mean 5.546454121940769e-05
4.390683170640841e-05 4.3906828068429604e-05
rl training, epoch4, iter0, batch1058/1133, batch loss:4.3906828068429604e-05, Training time:78162.52804303169
batch reward last col mean 2.0128862161072902e-05 first col mean 0.0001325460325460881 all mean 6.207253318279982e-05
2.267886884510517e-05 2.267886884510517e-05
rl training, epoch4, iter0, batch1059/1133, batch loss:2.267886884510517e-05, Training time:78179.67204642296
batch reward last col mean 2.8083857614547014e-05 first col mean 3.0819921903457725e-06 all mean 2.4379423848586157e-05
1.3261893400340341e-05 1.3261894309835043e-05
rl training, epoch4, iter0, batch1060/1133, batch loss:1.3261894309835043e-05, Training time:78196.64328598976
batch reward last col mean 3.721012399182655e-05 first col mean 8.720735422684811e-06 all mean 6.642047083005309e-05
1.39088042487856e-05 1.3908801520301495e-05
rl training, epoch4, iter0, batch1061/1133, batch loss:1.3908801520301495e-05, Training time:78213.48076105118
batch reward last col mean 9.527752263238654e-05 first col mean 1.4284643839346245e-05 all mean 7.300525612663478e-05
2.670970934559591e-05 2.6709700250648893e-05
rl training, epoch4, iter0, batch1062/1133, batch loss:2.6709700250648893e-05, Training time:78232.11189031601
batch reward last col mean 3.522457518556621e-06 first col mean 6.580409535672516e-05 all mean 3.843868034891784e-05
1.0869834113691468e-05 1.0869827747228555e-05
rl training, epoch4, iter0, batch1063/1133, batch loss:1.0869827747228555e-05, Training time:78249.71851158142
batch reward last col mean 1.8871454585678293e-06 first col mean 5.08340917804162e-06 all mean 5.8823468862101436e-05
4.226316013955511e-05 4.226316013955511e-05
rl training, epoch4, iter0, batch1064/1133, batch loss:4.226316013955511e-05, Training time:78268.41696810722
batch reward last col mean 3.1527447390544694e-06 first col mean 3.7037192669231445e-05 all mean 6.048765135346912e-05
2.0327743186498992e-05 2.0327750462456606e-05
rl training, epoch4, iter0, batch1065/1133, batch loss:2.0327750462456606e-05, Training time:78285.2677488327
batch reward last col mean 6.87359060975723e-05 first col mean 1.002361204882618e-05 all mean 6.974596908548847e-05
4.062615698785521e-05 4.062615698785521e-05
rl training, epoch4, iter0, batch1066/1133, batch loss:4.062615698785521e-05, Training time:78302.32736682892
batch reward last col mean 5.474897989188321e-06 first col mean 3.5888489946955815e-05 all mean 2.660128848219756e-05
1.3895350093662273e-05 1.3895347365178168e-05
rl training, epoch4, iter0, batch1067/1133, batch loss:1.3895347365178168e-05, Training time:78319.17734003067
batch reward last col mean 7.345063295360887e-06 first col mean 2.3107113520381972e-05 all mean 5.189296280150302e-05
1.730306030367501e-05 1.7303058484685607e-05
rl training, epoch4, iter0, batch1068/1133, batch loss:1.7303058484685607e-05, Training time:78337.66692376137
batch reward last col mean 3.3644348150119185e-05 first col mean 2.618078542582225e-05 all mean 8.10793717391789e-05
3.835988536593504e-05 3.8359881727956235e-05
rl training, epoch4, iter0, batch1069/1133, batch loss:3.8359881727956235e-05, Training time:78356.28843355179
batch reward last col mean 1.0140277026948752e-06 first col mean 0.00014359272608999163 all mean 5.835839328938164e-05
2.5374325559823774e-05 2.5374327378813177e-05
rl training, epoch4, iter0, batch1070/1133, batch loss:2.5374327378813177e-05, Training time:78373.1999411583
batch reward last col mean 1.3588485671789385e-05 first col mean 3.554093564162031e-05 all mean 7.783453474985436e-05
4.146043647779152e-05 4.146043647779152e-05
rl training, epoch4, iter0, batch1071/1133, batch loss:4.146043647779152e-05, Training time:78391.95616483688
batch reward last col mean 5.447103376354789e-06 first col mean 1.7023457985487767e-05 all mean 3.6134755646344274e-05
6.508595106424764e-05 6.508595106424764e-05
rl training, epoch4, iter0, batch1072/1133, batch loss:6.508595106424764e-05, Training time:78408.8459455967
batch reward last col mean 1.064259049599059e-05 first col mean 0.0008498033275827765 all mean 0.00012288002471905202
1.6326641343766823e-05 1.632663952477742e-05
rl training, epoch4, iter0, batch1073/1133, batch loss:1.632663952477742e-05, Training time:78425.78746175766
batch reward last col mean 1.9177126887370832e-05 first col mean 0.00016293063526973128 all mean 0.00015443697338923812
3.370748527231626e-05 3.370747799635865e-05
rl training, epoch4, iter0, batch1074/1133, batch loss:3.370747799635865e-05, Training time:78442.7890264988
batch reward last col mean 9.478918400418479e-06 first col mean 8.288323442684487e-06 all mean 0.00010320670116925612
9.698070789454505e-05 9.698070061858743e-05
rl training, epoch4, iter0, batch1075/1133, batch loss:9.698070061858743e-05, Training time:78459.60611724854
batch reward last col mean 0.0028754468075931072 first col mean 4.070406248501968e-06 all mean 0.0002015829086303711
0.00043964438373222947 0.00043964438373222947
rl training, epoch4, iter0, batch1076/1133, batch loss:0.00043964438373222947, Training time:78476.32322645187
batch reward last col mean 2.7844644137076102e-06 first col mean 0.0003705109120346606 all mean 4.625854853657074e-05
4.31390835728962e-05 4.313907629693858e-05
rl training, epoch4, iter0, batch1077/1133, batch loss:4.313907629693858e-05, Training time:78493.72049474716
batch reward last col mean 0.0001255673123523593 first col mean 1.2350689758022781e-05 all mean 6.327206938294694e-05
2.0270927052479237e-05 2.027092341450043e-05
rl training, epoch4, iter0, batch1078/1133, batch loss:2.027092341450043e-05, Training time:78510.31353783607
batch reward last col mean 3.3860444546007784e-06 first col mean 3.903457582055125e-06 all mean 7.68487952882424e-05
4.798987720278092e-05 4.79898699268233e-05
rl training, epoch4, iter0, batch1079/1133, batch loss:4.79898699268233e-05, Training time:78526.79088568687
batch reward last col mean 3.898891463904874e-06 first col mean 0.00012966393842361867 all mean 7.692052167840302e-05
2.8956512323929928e-05 2.8956514142919332e-05
rl training, epoch4, iter0, batch1080/1133, batch loss:2.8956514142919332e-05, Training time:78544.75317168236
batch reward last col mean 2.2587912098970264e-05 first col mean 3.29623362631537e-05 all mean 5.759790292358957e-05
1.3861007573723327e-05 1.3861010302207433e-05
rl training, epoch4, iter0, batch1081/1133, batch loss:1.3861010302207433e-05, Training time:78562.09711623192
batch reward last col mean 0.0036773651372641325 first col mean 0.0006098743760958314 all mean 0.0033520590513944626
0.00024770773597992957 0.00024770776508376
rl training, epoch4, iter0, batch1082/1133, batch loss:0.00024770776508376, Training time:78580.3440144062
batch reward last col mean 4.335508492658846e-06 first col mean 6.981989827181678e-06 all mean 3.2814299629535526e-05
7.472446213796502e-06 7.472446668543853e-06
rl training, epoch4, iter0, batch1083/1133, batch loss:7.472446668543853e-06, Training time:78598.71129107475
batch reward last col mean 8.614480611868203e-05 first col mean 7.462748271791497e-06 all mean 0.00011380897194612771
1.991035242099315e-05 1.9910354239982553e-05
rl training, epoch4, iter0, batch1084/1133, batch loss:1.9910354239982553e-05, Training time:78617.26505064964
batch reward last col mean 1.0201169061474502e-05 first col mean 6.841911726951366e-06 all mean 9.185668750433251e-05
1.9459812392597087e-05 1.9459810573607683e-05
rl training, epoch4, iter0, batch1085/1133, batch loss:1.9459810573607683e-05, Training time:78635.78785014153
batch reward last col mean 9.886643965728581e-06 first col mean 4.644250566343544e-06 all mean 8.095541852526367e-05
2.174849942093715e-05 2.1748503058915958e-05
rl training, epoch4, iter0, batch1086/1133, batch loss:2.1748503058915958e-05, Training time:78652.66736149788
batch reward last col mean 6.741697234247113e-06 first col mean 6.813684194639791e-06 all mean 2.9812710636178963e-05
1.7463838958065026e-05 1.7463833501096815e-05
rl training, epoch4, iter0, batch1087/1133, batch loss:1.7463833501096815e-05, Training time:78669.61772966385
batch reward last col mean 2.364811734878458e-06 first col mean 3.4510208934079856e-05 all mean 5.303099533193745e-05
1.4920962712494656e-05 1.4920960893505253e-05
rl training, epoch4, iter0, batch1088/1133, batch loss:1.4920960893505253e-05, Training time:78686.48285961151
batch reward last col mean 8.295341103803366e-05 first col mean 2.8782751542166807e-06 all mean 6.678200588794425e-05
0.00011478746455395594 0.00011478746455395594
rl training, epoch4, iter0, batch1089/1133, batch loss:0.00011478746455395594, Training time:78703.46005868912
batch reward last col mean 2.9996648663654923e-05 first col mean 3.3935591545741772e-06 all mean 8.730810804991052e-05
4.450665437616408e-05 4.450665437616408e-05
rl training, epoch4, iter0, batch1090/1133, batch loss:4.450665437616408e-05, Training time:78720.24174451828
batch reward last col mean 7.416876542265527e-06 first col mean 1.0908594049396925e-05 all mean 7.765457849018276e-05
3.19925784424413e-05 3.1992560252547264e-05
rl training, epoch4, iter0, batch1091/1133, batch loss:3.1992560252547264e-05, Training time:78737.03793668747
batch reward last col mean 0.005243942607194185 first col mean 3.150845031996141e-06 all mean 0.004903980530798435
0.00010649507021298632 0.00010649504838511348
rl training, epoch4, iter0, batch1092/1133, batch loss:0.00010649504838511348, Training time:78753.6413371563
batch reward last col mean 1.0154182746191509e-05 first col mean 2.56909811469086e-06 all mean 3.5916924389312044e-05
8.960057130025234e-06 8.960062586993445e-06
rl training, epoch4, iter0, batch1093/1133, batch loss:8.960062586993445e-06, Training time:78770.25244450569
batch reward last col mean 4.760353931487771e-06 first col mean 0.00016668638272676617 all mean 0.00010969134018523619
3.5381122870603576e-05 3.5381137422518805e-05
rl training, epoch4, iter0, batch1094/1133, batch loss:3.5381137422518805e-05, Training time:78786.81182646751
batch reward last col mean 2.853306978067849e-05 first col mean 7.419373105221894e-06 all mean 5.7990058849100024e-05
4.272686055628583e-05 4.272686055628583e-05
rl training, epoch4, iter0, batch1095/1133, batch loss:4.272686055628583e-05, Training time:78803.85317635536
batch reward last col mean 3.76451134798117e-06 first col mean 1.2143072126491461e-05 all mean 6.195933383423835e-05
2.6849373170989566e-05 2.684938044694718e-05
rl training, epoch4, iter0, batch1096/1133, batch loss:2.684938044694718e-05, Training time:78822.13202142715
batch reward last col mean 6.466636841651052e-05 first col mean 5.7095126976491883e-05 all mean 9.292351023759693e-05
2.9981845727888867e-05 2.998183663294185e-05
rl training, epoch4, iter0, batch1097/1133, batch loss:2.998183663294185e-05, Training time:78840.52642178535
batch reward last col mean 4.7397475100297015e-06 first col mean 5.994271305098664e-06 all mean 7.038957846816629e-05
2.3121345293475315e-05 2.312134347448591e-05
rl training, epoch4, iter0, batch1098/1133, batch loss:2.312134347448591e-05, Training time:78857.22670292854
batch reward last col mean 6.982963532209396e-05 first col mean 1.8237332142234663e-06 all mean 4.801756585948169e-05
5.763534500147216e-05 5.763534863945097e-05
rl training, epoch4, iter0, batch1099/1133, batch loss:5.763534863945097e-05, Training time:78874.84627342224
batch reward last col mean 6.457267318182858e-06 first col mean 1.2618745131476317e-05 all mean 5.019954187446274e-05
1.6263909856206737e-05 1.6263909856206737e-05
rl training, epoch4, iter0, batch1100/1133, batch loss:1.6263909856206737e-05, Training time:78891.5970594883
batch reward last col mean 0.00010782916797325015 first col mean 1.1655060006887652e-05 all mean 6.371011113515124e-05
2.120630961144343e-05 2.120630415447522e-05
rl training, epoch4, iter0, batch1101/1133, batch loss:2.120630415447522e-05, Training time:78908.36194491386
batch reward last col mean 1.5215176972560585e-05 first col mean 7.490540883736685e-05 all mean 0.0001302155142184347
6.070214294595644e-05 6.070215749787167e-05
rl training, epoch4, iter0, batch1102/1133, batch loss:6.070215749787167e-05, Training time:78925.08253097534
batch reward last col mean 5.7357901823706925e-06 first col mean 2.3795105335011613e-06 all mean 7.117068889783695e-05
1.9055414668400772e-05 1.905541284941137e-05
rl training, epoch4, iter0, batch1103/1133, batch loss:1.905541284941137e-05, Training time:78941.78980445862
batch reward last col mean 1.0726515029091388e-05 first col mean 4.1238695303036366e-06 all mean 5.020037497160956e-05
8.282165254058782e-06 8.282170711026993e-06
rl training, epoch4, iter0, batch1104/1133, batch loss:8.282170711026993e-06, Training time:78958.63247895241
batch reward last col mean 7.994400948518887e-05 first col mean 7.197642389655812e-06 all mean 4.795386121259071e-05
2.2906222511664964e-05 2.2906222511664964e-05
rl training, epoch4, iter0, batch1105/1133, batch loss:2.2906222511664964e-05, Training time:78975.59529328346
batch reward last col mean 2.489633970981231e-06 first col mean 4.51587266070419e-06 all mean 2.5488896426395513e-05
5.312236226018285e-06 5.312234407028882e-06
rl training, epoch4, iter0, batch1106/1133, batch loss:5.312234407028882e-06, Training time:78992.46584916115
batch reward last col mean 2.1348369045881554e-05 first col mean 6.854592356830835e-06 all mean 8.762419020058587e-05
1.6840253010741435e-05 1.684026028669905e-05
rl training, epoch4, iter0, batch1107/1133, batch loss:1.684026028669905e-05, Training time:79009.1662349701
batch reward last col mean 4.648782123695128e-06 first col mean 5.1472849008860067e-05 all mean 7.576846837764606e-05
2.4058455892372876e-05 2.4058454073383473e-05
rl training, epoch4, iter0, batch1108/1133, batch loss:2.4058454073383473e-05, Training time:79026.05955171585
batch reward last col mean 7.11045358912088e-05 first col mean 1.1328208529448602e-05 all mean 5.156169208930805e-05
2.322874206583947e-05 2.322872751392424e-05
rl training, epoch4, iter0, batch1109/1133, batch loss:2.322872751392424e-05, Training time:79042.8805103302
batch reward last col mean 1.2946640708833002e-05 first col mean 5.2324237913126126e-05 all mean 5.3843472414882854e-05
0.00010619589738780633 0.00010619591193972155
rl training, epoch4, iter0, batch1110/1133, batch loss:0.00010619591193972155, Training time:79059.71477270126
batch reward last col mean 3.446185701250215e-06 first col mean 2.8576873773999978e-06 all mean 2.3004376998869702e-05
4.111322141397977e-06 4.1113212319032755e-06
rl training, epoch4, iter0, batch1111/1133, batch loss:4.1113212319032755e-06, Training time:79076.47172808647
batch reward last col mean 0.00011717900633811951 first col mean 2.4691084036021493e-05 all mean 3.796970486291684e-05
2.527140168240294e-05 2.527140168240294e-05
rl training, epoch4, iter0, batch1112/1133, batch loss:2.527140168240294e-05, Training time:79093.09950470924
batch reward last col mean 0.0002835993655025959 first col mean 3.3726923902577255e-06 all mean 0.00021339689556043595
4.812942643184215e-05 4.812942643184215e-05
rl training, epoch4, iter0, batch1113/1133, batch loss:4.812942643184215e-05, Training time:79110.26068544388
batch reward last col mean 0.0016606366261839867 first col mean 4.0875092963688076e-06 all mean 9.470566874369979e-05
0.00018260173965245485 0.0001826017105486244
rl training, epoch4, iter0, batch1114/1133, batch loss:0.0001826017105486244, Training time:79127.02166223526
batch reward last col mean 0.00010628673044266179 first col mean 2.7275858883513138e-05 all mean 0.00011244824418099597
8.023157715797424e-05 8.023158443393186e-05
rl training, epoch4, iter0, batch1115/1133, batch loss:8.023158443393186e-05, Training time:79143.72428774834
batch reward last col mean 2.0338680769782513e-05 first col mean 0.00013464517542161047 all mean 6.330664473352954e-05
4.502462616073899e-05 4.50246297987178e-05
rl training, epoch4, iter0, batch1116/1133, batch loss:4.50246297987178e-05, Training time:79160.70587182045
batch reward last col mean 0.007294952403753996 first col mean 8.378564416489098e-06 all mean 0.0001448351249564439
0.0005197267746552825 0.0005197267746552825
rl training, epoch4, iter0, batch1117/1133, batch loss:0.0005197267746552825, Training time:79177.4692556858
batch reward last col mean 7.193626515800133e-06 first col mean 4.631281626643613e-05 all mean 0.0001236506795976311
2.677782322280109e-05 2.677782322280109e-05
rl training, epoch4, iter0, batch1118/1133, batch loss:2.677782322280109e-05, Training time:79194.19952630997
batch reward last col mean 1.9514953237376176e-05 first col mean 0.0001553604524815455 all mean 5.2792649512412027e-05
1.726101436361205e-05 1.7261012544622645e-05
rl training, epoch4, iter0, batch1119/1133, batch loss:1.7261012544622645e-05, Training time:79211.96979856491
batch reward last col mean 2.9290498787304386e-05 first col mean 7.475967777281767e-06 all mean 7.24347701179795e-05
3.7000027077738196e-05 3.7000030715717e-05
rl training, epoch4, iter0, batch1120/1133, batch loss:3.7000030715717e-05, Training time:79228.65325117111
batch reward last col mean 6.454018603108125e-06 first col mean 1.6328482161043212e-05 all mean 5.5271375458687544e-05
6.068778384360485e-05 6.0687776567647234e-05
rl training, epoch4, iter0, batch1121/1133, batch loss:6.0687776567647234e-05, Training time:79245.77187633514
batch reward last col mean 2.1577516235993244e-06 first col mean 9.65623894444434e-06 all mean 4.636567973648198e-05
5.5494849220849574e-05 5.5494849220849574e-05
rl training, epoch4, iter0, batch1122/1133, batch loss:5.5494849220849574e-05, Training time:79262.75320768356
batch reward last col mean 0.00247402535751462 first col mean 2.17800225073006e-05 all mean 0.0022922649513930082
0.00035543908597901464 0.00035543908597901464
rl training, epoch4, iter0, batch1123/1133, batch loss:0.00035543908597901464, Training time:79279.63223147392
batch reward last col mean 5.770107600255869e-05 first col mean 5.102579052618239e-06 all mean 5.2098814194323495e-05
5.964440424577333e-05 5.964440788375214e-05
rl training, epoch4, iter0, batch1124/1133, batch loss:5.964440788375214e-05, Training time:79296.6531214714
batch reward last col mean 1.0168404514843132e-05 first col mean 6.01536339672748e-06 all mean 0.00011118683323729783
5.2281233365647495e-05 5.228125155554153e-05
rl training, epoch4, iter0, batch1125/1133, batch loss:5.228125155554153e-05, Training time:79313.60153961182
batch reward last col mean 9.941792086465284e-06 first col mean 1.2650489225052297e-05 all mean 4.778652873937972e-05
2.5450028260820545e-05 2.545003007980995e-05
rl training, epoch4, iter0, batch1126/1133, batch loss:2.545003007980995e-05, Training time:79330.7203476429
batch reward last col mean 1.6405855376433465e-06 first col mean 2.0932893676217645e-06 all mean 7.309159991564229e-05
4.456102033145726e-05 4.4561009417520836e-05
rl training, epoch4, iter0, batch1127/1133, batch loss:4.4561009417520836e-05, Training time:79347.70766854286
batch reward last col mean 2.5931069103535265e-05 first col mean 3.5870078136213124e-05 all mean 5.736621096730232e-05
1.8371467376709916e-05 1.8371478290646337e-05
rl training, epoch4, iter0, batch1128/1133, batch loss:1.8371478290646337e-05, Training time:79364.68590927124
batch reward last col mean 9.061388846021146e-05 first col mean 1.0787702194647864e-05 all mean 3.76223360945005e-05
3.376156746526249e-05 3.376156746526249e-05
rl training, epoch4, iter0, batch1129/1133, batch loss:3.376156746526249e-05, Training time:79381.4934437275
batch reward last col mean 8.065705515036825e-06 first col mean 7.641103366040625e-06 all mean 5.511349081643857e-05
0.00010874102008529007 0.00010874100553337485
rl training, epoch4, iter0, batch1130/1133, batch loss:0.00010874100553337485, Training time:79398.3257060051
batch reward last col mean 0.0016659534303471446 first col mean 8.81589949131012e-06 all mean 0.00021315283083822578
0.0001330834929831326 0.0001330834929831326
rl training, epoch4, iter0, batch1131/1133, batch loss:0.0001330834929831326, Training time:79415.69974970818
batch reward last col mean 0.0002702841011341661 first col mean 6.2240983424999285e-06 all mean 6.823852163506672e-05
7.028265099506825e-05 7.028266554698348e-05
rl training, epoch4, iter0, batch1132/1133, batch loss:7.028266554698348e-05, Training time:79434.01296973228
rl training, epoch 4, iter 0, loss:4.135129933935232e-05, Training time:79434.01325583458 
rl epoch 4, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.375471284680417 Time: 140.7364146709442 s
0.15063254430640197 6.335121882573615e-05 0.22477538938266664
cur_epoch: 1
D Training Loss: 0.3698481583453235 Time: 137.96995949745178 s
0.1483386341952583 3.836004059017294e-05 0.22147116430649585
cur_epoch: 2
D Training Loss: 0.3606058032057081 Time: 138.31839156150818 s
0.14344609640571573 7.650302372492289e-05 0.21708320350848986
cur_epoch: 3
D Training Loss: 0.3604204913524012 Time: 138.48145365715027 s
0.1429066348225799 3.557327486851422e-05 0.21747828278253273
cur_epoch: 4
D Training Loss: 0.3530432481946718 Time: 140.30313372612 s
0.1403556297823379 3.486454757552091e-05 0.21265275361442187
rl epoch 5, begin RL for generator...
batch reward last col mean 0.0018791335169225931 first col mean 4.1214774682885036e-05 all mean 0.0011561185820028186
6.420704448828474e-05 6.420702993636951e-05
rl training, epoch5, iter0, batch0/1133, batch loss:6.420702993636951e-05, Training time:80146.59698534012
batch reward last col mean 1.912747393362224e-06 first col mean 6.642947482760064e-06 all mean 3.718616426340304e-05
7.240829745569499e-06 7.240833838295657e-06
rl training, epoch5, iter0, batch1/1133, batch loss:7.240833838295657e-06, Training time:80163.54051923752
batch reward last col mean 2.1021056454628706e-05 first col mean 4.3282641854602844e-05 all mean 3.413644662941806e-05
2.8278820536797866e-05 2.827882235578727e-05
rl training, epoch5, iter0, batch2/1133, batch loss:2.827882235578727e-05, Training time:80180.59270191193
batch reward last col mean 1.0233701459583244e-06 first col mean 8.580760913901031e-05 all mean 1.4699729945277795e-05
3.0227186016418273e-06 3.022717919520801e-06
rl training, epoch5, iter0, batch3/1133, batch loss:3.022717919520801e-06, Training time:80197.39028978348
batch reward last col mean 1.1401897381801973e-06 first col mean 2.9814257231919328e-06 all mean 1.2651713404920883e-05
9.930932719726115e-06 9.930933629220817e-06
rl training, epoch5, iter0, batch4/1133, batch loss:9.930933629220817e-06, Training time:80214.1681573391
batch reward last col mean 3.078461986660841e-06 first col mean 6.06449748374871e-06 all mean 1.0895373634411953e-05
3.680649342641118e-06 3.6806486605200917e-06
rl training, epoch5, iter0, batch5/1133, batch loss:3.6806486605200917e-06, Training time:80230.84128117561
batch reward last col mean 2.5402227947779465e-06 first col mean 5.023197445552796e-06 all mean 1.6546504411962815e-05
1.3979278037368204e-06 1.3979281447973335e-06
rl training, epoch5, iter0, batch6/1133, batch loss:1.3979281447973335e-06, Training time:80247.78527331352
batch reward last col mean 1.4209323126124218e-05 first col mean 1.7438607073927415e-06 all mean 8.09864195616683e-06
4.690488367486978e-06 4.69048927698168e-06
rl training, epoch5, iter0, batch7/1133, batch loss:4.69048927698168e-06, Training time:80264.51776075363
batch reward last col mean 3.021381598955486e-05 first col mean 1.8129687759937951e-06 all mean 1.3347345884540118e-05
5.803622570965672e-06 5.803622570965672e-06
rl training, epoch5, iter0, batch8/1133, batch loss:5.803622570965672e-06, Training time:80281.4509768486
batch reward last col mean 3.69774329556094e-06 first col mean 2.3099466943676816e-06 all mean 2.3649610739084892e-05
3.259378217990161e-06 3.259388449805556e-06
rl training, epoch5, iter0, batch9/1133, batch loss:3.259388449805556e-06, Training time:80298.32986164093
batch reward last col mean 6.066807600291213e-06 first col mean 6.609211595787201e-06 all mean 2.7913807571167126e-05
9.70690689428011e-06 9.706905075290706e-06
rl training, epoch5, iter0, batch10/1133, batch loss:9.706905075290706e-06, Training time:80315.21440839767
batch reward last col mean 2.982838623211137e-06 first col mean 2.5118868052231846e-06 all mean 1.0959181963698938e-05
5.466531547426712e-06 5.466530183184659e-06
rl training, epoch5, iter0, batch11/1133, batch loss:5.466530183184659e-06, Training time:80333.93462514877
batch reward last col mean 0.000635593431070447 first col mean 9.666771802585572e-06 all mean 0.0002736065653152764
2.7839438189403154e-05 2.783943637041375e-05
rl training, epoch5, iter0, batch12/1133, batch loss:2.783943637041375e-05, Training time:80350.90014719963
batch reward last col mean 4.288137006369652e-06 first col mean 4.567259566101711e-06 all mean 5.036303628003225e-05
5.564749153563753e-05 5.5647484259679914e-05
rl training, epoch5, iter0, batch13/1133, batch loss:5.5647484259679914e-05, Training time:80367.67883181572
batch reward last col mean 1.158382474386599e-06 first col mean 8.031449397094548e-06 all mean 8.96705205377657e-06
3.513427373036393e-06 3.5134266909153666e-06
rl training, epoch5, iter0, batch14/1133, batch loss:3.5134266909153666e-06, Training time:80384.41672730446
batch reward last col mean 2.1145829123270232e-06 first col mean 1.7733176491674385e-06 all mean 5.12850601808168e-05
4.510636699706083e-06 4.510634425969329e-06
rl training, epoch5, iter0, batch15/1133, batch loss:4.510634425969329e-06, Training time:80401.37201738358
batch reward last col mean 1.0145361102331663e-06 first col mean 1.6972408047877252e-06 all mean 1.0305372597940732e-05
9.810227311390918e-06 9.81022822088562e-06
rl training, epoch5, iter0, batch16/1133, batch loss:9.81022822088562e-06, Training time:80418.43879294395
batch reward last col mean 1.1199047548871022e-05 first col mean 2.3797215362719726e-06 all mean 4.226498640491627e-05
1.553782931296155e-05 1.5537831131950952e-05
rl training, epoch5, iter0, batch17/1133, batch loss:1.5537831131950952e-05, Training time:80435.48906087875
batch reward last col mean 7.750523764116224e-06 first col mean 1.50232754094759e-05 all mean 2.2524905944010243e-05
8.793831511866301e-06 8.7938306023716e-06
rl training, epoch5, iter0, batch18/1133, batch loss:8.7938306023716e-06, Training time:80452.44216299057
batch reward last col mean 3.409473947613151e-06 first col mean 1.1556852768990211e-05 all mean 4.802111288881861e-05
1.1693421583913732e-05 1.1693413398461416e-05
rl training, epoch5, iter0, batch19/1133, batch loss:1.1693413398461416e-05, Training time:80469.68924665451
batch reward last col mean 3.5522220969141927e-06 first col mean 2.6413495106680784e-06 all mean 1.1336197530908976e-05
4.205504865240073e-06 4.20550350099802e-06
rl training, epoch5, iter0, batch20/1133, batch loss:4.20550350099802e-06, Training time:80486.69083547592
batch reward last col mean 2.8235904210305307e-06 first col mean 1.8416172679280862e-05 all mean 9.970724022423383e-06
5.950436388957314e-06 5.950437298452016e-06
rl training, epoch5, iter0, batch21/1133, batch loss:5.950437298452016e-06, Training time:80503.49254250526
batch reward last col mean 0.0001292201632168144 first col mean 4.063750566274393e-06 all mean 2.6520110623096116e-05
2.2208074369700626e-05 2.220807618869003e-05
rl training, epoch5, iter0, batch22/1133, batch loss:2.220807618869003e-05, Training time:80520.20818972588
batch reward last col mean 2.0629240680136718e-06 first col mean 1.7768568341125501e-06 all mean 1.3697753274755087e-05
4.368650024844101e-06 4.368651389086153e-06
rl training, epoch5, iter0, batch23/1133, batch loss:4.368651389086153e-06, Training time:80537.12181544304
batch reward last col mean 8.697176781424787e-06 first col mean 8.159176445587946e-07 all mean 1.5530444215983152e-05
1.3154738553566858e-05 1.3154742191545665e-05
rl training, epoch5, iter0, batch24/1133, batch loss:1.3154742191545665e-05, Training time:80553.8277220726
batch reward last col mean 1.5657556104997639e-06 first col mean 1.4746851775271352e-06 all mean 9.266205779567827e-06
6.663420663244324e-06 6.66341884425492e-06
rl training, epoch5, iter0, batch25/1133, batch loss:6.66341884425492e-06, Training time:80570.69389772415
batch reward last col mean 2.1477976588357706e-06 first col mean 2.0632917312468635e-06 all mean 1.3688038052350748e-05
4.9618665798334405e-06 4.961863851349335e-06
rl training, epoch5, iter0, batch26/1133, batch loss:4.961863851349335e-06, Training time:80587.77361869812
batch reward last col mean 4.913885049973032e-07 first col mean 3.561405264917994e-06 all mean 2.1389958419604227e-05
5.029124167776899e-06 5.029127351008356e-06
rl training, epoch5, iter0, batch27/1133, batch loss:5.029127351008356e-06, Training time:80604.4326851368
batch reward last col mean 8.990150490717497e-07 first col mean 3.054788066947367e-06 all mean 6.169728749227943e-06
2.7854214295075508e-06 2.7854214295075508e-06
rl training, epoch5, iter0, batch28/1133, batch loss:2.7854214295075508e-06, Training time:80621.09336423874
batch reward last col mean 2.740803211054299e-05 first col mean 3.3923224691534415e-06 all mean 7.020456541795284e-05
2.2674350475426763e-05 2.2674341380479746e-05
rl training, epoch5, iter0, batch29/1133, batch loss:2.2674341380479746e-05, Training time:80638.62526035309
batch reward last col mean 7.69211783335777e-06 first col mean 3.0898318073013797e-06 all mean 5.0288748752791435e-05
4.555948180495761e-05 4.555948180495761e-05
rl training, epoch5, iter0, batch30/1133, batch loss:4.555948180495761e-05, Training time:80655.4408390522
batch reward last col mean 6.517762471958122e-07 first col mean 2.884279865611461e-06 all mean 2.7939418941969052e-05
1.663351577008143e-05 1.6633517589070834e-05
rl training, epoch5, iter0, batch31/1133, batch loss:1.6633517589070834e-05, Training time:80673.06369447708
batch reward last col mean 5.469096322485711e-07 first col mean 3.588500931073213e-06 all mean 8.91980562300887e-06
9.88217016129056e-06 9.88217016129056e-06
rl training, epoch5, iter0, batch32/1133, batch loss:9.88217016129056e-06, Training time:80690.00245690346
batch reward last col mean 1.0093600621985388e-06 first col mean 3.416417939661187e-06 all mean 9.882592166832183e-06
1.7327936802757904e-05 1.7327938621747307e-05
rl training, epoch5, iter0, batch33/1133, batch loss:1.7327938621747307e-05, Training time:80706.93459582329
batch reward last col mean 5.529777808988001e-06 first col mean 7.087770882208133e-06 all mean 3.6629098758567125e-05
0.00017462829418946058 0.00017462829418946058
rl training, epoch5, iter0, batch34/1133, batch loss:0.00017462829418946058, Training time:80723.82127404213
batch reward last col mean 2.906494955823291e-05 first col mean 2.905378551076865e-06 all mean 2.4653416403452866e-05
6.015868621034315e-06 6.0158781707286835e-06
rl training, epoch5, iter0, batch35/1133, batch loss:6.0158781707286835e-06, Training time:80740.65928125381
batch reward last col mean 4.947618890582817e-06 first col mean 2.2094368432590272e-06 all mean 4.308681673137471e-05
1.4413677490665577e-05 1.4413671124202665e-05
rl training, epoch5, iter0, batch36/1133, batch loss:1.4413671124202665e-05, Training time:80757.47751140594
batch reward last col mean 1.2645847391468124e-06 first col mean 2.548576503613731e-06 all mean 1.5720806914032437e-05
5.78547178520239e-06 5.7854722399497405e-06
rl training, epoch5, iter0, batch37/1133, batch loss:5.7854722399497405e-06, Training time:80774.47598719597
batch reward last col mean 3.1727529403724475e-06 first col mean 1.543645339552313e-06 all mean 9.671240150055382e-06
2.5634421035647392e-05 2.5634421035647392e-05
rl training, epoch5, iter0, batch38/1133, batch loss:2.5634421035647392e-05, Training time:80791.37012410164
batch reward last col mean 7.236432793433778e-06 first col mean 0.00013000203762203455 all mean 2.0505121938185766e-05
6.077827038097894e-06 6.077823400119087e-06
rl training, epoch5, iter0, batch39/1133, batch loss:6.077823400119087e-06, Training time:80808.16190433502
batch reward last col mean 7.940118393889861e-07 first col mean 8.49499338073656e-06 all mean 3.640774593804963e-05
2.533976839913521e-05 2.533976839913521e-05
rl training, epoch5, iter0, batch40/1133, batch loss:2.533976839913521e-05, Training time:80825.47303771973
batch reward last col mean 1.6766426824688097e-06 first col mean 0.0001940164074767381 all mean 1.2217381481605116e-05
7.073507276800228e-06 7.073504093568772e-06
rl training, epoch5, iter0, batch41/1133, batch loss:7.073504093568772e-06, Training time:80842.39076280594
batch reward last col mean 0.0010624380083754659 first col mean 9.894883987726644e-06 all mean 4.751652159029618e-05
6.961003236938268e-05 6.961003236938268e-05
rl training, epoch5, iter0, batch42/1133, batch loss:6.961003236938268e-05, Training time:80859.40147304535
batch reward last col mean 6.607693649129942e-06 first col mean 1.862592216639314e-05 all mean 1.2308941222727299e-05
4.845509010920068e-06 4.845506282435963e-06
rl training, epoch5, iter0, batch43/1133, batch loss:4.845506282435963e-06, Training time:80876.39971160889
batch reward last col mean 4.261546200723387e-05 first col mean 9.245475666830316e-06 all mean 2.8237642254680395e-05
1.3909816516388673e-05 1.390981469739927e-05
rl training, epoch5, iter0, batch44/1133, batch loss:1.390981469739927e-05, Training time:80893.45649051666
batch reward last col mean 1.9704154965438647e-06 first col mean 2.1488144739123527e-06 all mean 1.260061799257528e-05
3.9187411857710686e-06 3.918743914255174e-06
rl training, epoch5, iter0, batch45/1133, batch loss:3.918743914255174e-06, Training time:80910.4958088398
batch reward last col mean 7.039989782242628e-07 first col mean 3.4854579098464455e-06 all mean 1.0175647730648052e-05
1.8957562133437023e-06 1.895760419756698e-06
rl training, epoch5, iter0, batch46/1133, batch loss:1.895760419756698e-06, Training time:80927.57317495346
batch reward last col mean 9.952657364920015e-07 first col mean 2.130524444510229e-05 all mean 2.115502138622105e-05
5.675069769495167e-05 5.675069769495167e-05
rl training, epoch5, iter0, batch47/1133, batch loss:5.675069769495167e-05, Training time:80944.46767640114
batch reward last col mean 2.4644155928399414e-05 first col mean 7.598278443765594e-06 all mean 3.624501914600842e-05
1.5223829905153252e-05 1.5223829905153252e-05
rl training, epoch5, iter0, batch48/1133, batch loss:1.5223829905153252e-05, Training time:80961.39226412773
batch reward last col mean 7.1714644036546815e-06 first col mean 5.4848487707204185e-06 all mean 2.7358288207324222e-05
8.618000720161945e-05 8.618002902949229e-05
rl training, epoch5, iter0, batch49/1133, batch loss:8.618002902949229e-05, Training time:80978.09938693047
batch reward last col mean 8.783291559666395e-05 first col mean 1.5205338968371507e-05 all mean 3.2588424801360816e-05
1.2660407264775131e-05 1.2660406355280429e-05
rl training, epoch5, iter0, batch50/1133, batch loss:1.2660406355280429e-05, Training time:80994.96460723877
batch reward last col mean 5.851288278790889e-06 first col mean 1.6851986401889008e-06 all mean 9.839787708187941e-06
2.169743538615876e-06 2.1697424017474987e-06
rl training, epoch5, iter0, batch51/1133, batch loss:2.1697424017474987e-06, Training time:81012.03705453873
batch reward last col mean 1.0885551091632806e-06 first col mean 4.187812464806484e-06 all mean 3.681906673591584e-05
1.528717257315293e-05 1.528718348708935e-05
rl training, epoch5, iter0, batch52/1133, batch loss:1.528718348708935e-05, Training time:81030.56881332397
batch reward last col mean 0.0012117023579776287 first col mean 5.385884378483752e-06 all mean 4.8514782974962145e-05
6.740255048498511e-05 6.74025432090275e-05
rl training, epoch5, iter0, batch53/1133, batch loss:6.74025432090275e-05, Training time:81047.37726855278
batch reward last col mean 8.980591701401863e-06 first col mean 1.147373268395313e-06 all mean 2.043808126472868e-05
6.272945029195398e-06 6.272947757679503e-06
rl training, epoch5, iter0, batch54/1133, batch loss:6.272947757679503e-06, Training time:81065.62901902199
batch reward last col mean 3.0060728022363037e-06 first col mean 1.2263876669749152e-05 all mean 5.8980556786991656e-05
1.8603030184749514e-05 1.860303927969653e-05
rl training, epoch5, iter0, batch55/1133, batch loss:1.860303927969653e-05, Training time:81084.11454558372
batch reward last col mean 3.3332598832203075e-05 first col mean 1.2721568509732606e-06 all mean 3.4131549000449013e-06
2.100601250276668e-06 2.100601250276668e-06
rl training, epoch5, iter0, batch56/1133, batch loss:2.100601250276668e-06, Training time:81101.0657980442
batch reward last col mean 1.6064892633949057e-06 first col mean 2.1952082533971407e-06 all mean 1.0916344763245434e-05
2.271663561259629e-06 2.271664470754331e-06
rl training, epoch5, iter0, batch57/1133, batch loss:2.271664470754331e-06, Training time:81118.04626345634
batch reward last col mean 1.3893359209760092e-05 first col mean 1.2998508509554085e-06 all mean 1.2001200047961902e-05
5.253546987660229e-06 5.253544713923475e-06
rl training, epoch5, iter0, batch58/1133, batch loss:5.253544713923475e-06, Training time:81134.87189483643
batch reward last col mean 1.1589430641834042e-06 first col mean 1.933555722644087e-06 all mean 2.486746961949393e-05
2.1616284357151017e-05 2.1616287995129824e-05
rl training, epoch5, iter0, batch59/1133, batch loss:2.1616287995129824e-05, Training time:81151.78739666939
batch reward last col mean 9.622034667700063e-06 first col mean 1.821909063437488e-05 all mean 4.602129047270864e-05
1.6994317775242962e-05 1.6994319594232365e-05
rl training, epoch5, iter0, batch60/1133, batch loss:1.6994319594232365e-05, Training time:81169.4765856266
batch reward last col mean 4.8467936721863225e-06 first col mean 2.861211214622017e-06 all mean 9.033917194756214e-06
5.659972885041498e-06 5.659970611304743e-06
rl training, epoch5, iter0, batch61/1133, batch loss:5.659970611304743e-06, Training time:81186.47204589844
batch reward last col mean 4.9128334467241075e-06 first col mean 1.4687053408124484e-05 all mean 4.9753914936445653e-05
3.474885306786746e-05 3.474885306786746e-05
rl training, epoch5, iter0, batch62/1133, batch loss:3.474885306786746e-05, Training time:81203.483771801
batch reward last col mean 2.145131929864874e-06 first col mean 5.230102146924764e-07 all mean 1.003387660603039e-05
9.425078133062925e-06 9.425076314073522e-06
rl training, epoch5, iter0, batch63/1133, batch loss:9.425076314073522e-06, Training time:81220.48426103592
batch reward last col mean 1.0100507097376976e-06 first col mean 4.4290950427239295e-06 all mean 6.85211171003175e-06
2.1056168861832703e-06 2.105616204062244e-06
rl training, epoch5, iter0, batch64/1133, batch loss:2.105616204062244e-06, Training time:81237.40552139282
batch reward last col mean 9.485173677603598e-07 first col mean 1.3984180441184435e-05 all mean 2.8320380806690082e-05
1.4324728908832185e-05 1.432472163287457e-05
rl training, epoch5, iter0, batch65/1133, batch loss:1.432472163287457e-05, Training time:81256.22185444832
batch reward last col mean 2.4337407467101e-06 first col mean 1.579103923177172e-06 all mean 1.915852953970898e-05
3.175885012751678e-06 3.175884558004327e-06
rl training, epoch5, iter0, batch66/1133, batch loss:3.175884558004327e-06, Training time:81274.2215526104
batch reward last col mean 1.0115371878782753e-05 first col mean 3.1115050660446286e-05 all mean 2.534148734412156e-05
8.621490451332647e-06 8.62148681335384e-06
rl training, epoch5, iter0, batch67/1133, batch loss:8.62148681335384e-06, Training time:81291.17611002922
batch reward last col mean 3.7481995605048724e-06 first col mean 4.459280262381071e-06 all mean 2.8580489015439525e-05
9.315399438492022e-06 9.31539852899732e-06
rl training, epoch5, iter0, batch68/1133, batch loss:9.31539852899732e-06, Training time:81308.05922722816
batch reward last col mean 6.28214411335648e-06 first col mean 0.0006372452480718493 all mean 4.0946470107883215e-05
2.1889949493925087e-05 2.18899567698827e-05
rl training, epoch5, iter0, batch69/1133, batch loss:2.18899567698827e-05, Training time:81325.3428106308
batch reward last col mean 1.0197923074883875e-06 first col mean 1.0719596502895001e-05 all mean 1.0534020475461148e-05
7.907747203717008e-06 7.90774811321171e-06
rl training, epoch5, iter0, batch70/1133, batch loss:7.90774811321171e-06, Training time:81344.03714299202
batch reward last col mean 7.37439620479563e-07 first col mean 2.413280526525341e-06 all mean 9.286863132729195e-06
5.798380243504653e-06 5.7983788792626e-06
rl training, epoch5, iter0, batch71/1133, batch loss:5.7983788792626e-06, Training time:81360.89738488197
batch reward last col mean 0.00016533183224964887 first col mean 3.174536459482624e-06 all mean 1.044732653099345e-05
1.4381002984009683e-05 1.4381002984009683e-05
rl training, epoch5, iter0, batch72/1133, batch loss:1.4381002984009683e-05, Training time:81379.22138166428
batch reward last col mean 1.3188471257308265e-06 first col mean 1.4575176464859396e-05 all mean 1.3720726201427169e-05
2.742145170486765e-06 2.7421469894761685e-06
rl training, epoch5, iter0, batch73/1133, batch loss:2.7421469894761685e-06, Training time:81396.24371933937
batch reward last col mean 1.7442866919736844e-06 first col mean 1.7907898381963605e-06 all mean 8.426641215919517e-06
2.600797415652778e-06 2.6007985525211552e-06
rl training, epoch5, iter0, batch74/1133, batch loss:2.6007985525211552e-06, Training time:81412.73379588127
batch reward last col mean 1.7706497601466253e-06 first col mean 3.8052462514315266e-06 all mean 6.247125838854117e-06
3.9120923247537576e-06 3.912091415259056e-06
rl training, epoch5, iter0, batch75/1133, batch loss:3.912091415259056e-06, Training time:81431.50825762749
batch reward last col mean 1.1547240319487173e-06 first col mean 1.3450793630909175e-05 all mean 1.2900938600068912e-05
9.563296771375462e-06 9.563296771375462e-06
rl training, epoch5, iter0, batch76/1133, batch loss:9.563296771375462e-06, Training time:81448.40056300163
batch reward last col mean 2.804129280775669e-06 first col mean 2.2790363800595514e-06 all mean 1.5762825569254346e-05
8.015117600734811e-06 8.015117600734811e-06
rl training, epoch5, iter0, batch77/1133, batch loss:8.015117600734811e-06, Training time:81465.3508219719
batch reward last col mean 2.0012998902529944e-06 first col mean 4.5530807256000116e-05 all mean 1.0809010746015701e-05
6.520775059470907e-06 6.520775059470907e-06
rl training, epoch5, iter0, batch78/1133, batch loss:6.520775059470907e-06, Training time:81482.36006188393
batch reward last col mean 3.097340595559217e-06 first col mean 6.115682936069788e-06 all mean 2.6993475330527872e-05
6.920722626091447e-06 6.920714440639131e-06
rl training, epoch5, iter0, batch79/1133, batch loss:6.920714440639131e-06, Training time:81499.47892093658
batch reward last col mean 8.410277132497868e-07 first col mean 1.2620812412933446e-05 all mean 1.1068776075262576e-05
3.557592208380811e-06 3.557592208380811e-06
rl training, epoch5, iter0, batch80/1133, batch loss:3.557592208380811e-06, Training time:81516.5621612072
batch reward last col mean 1.3672424756805412e-06 first col mean 2.5952301712095505e-06 all mean 1.0531940461078193e-05
1.51139720401261e-05 1.5113970221136697e-05
rl training, epoch5, iter0, batch81/1133, batch loss:1.5113970221136697e-05, Training time:81533.68563699722
batch reward last col mean 4.284045644453727e-06 first col mean 1.672207531555614e-06 all mean 1.4489708519249689e-05
1.3268709153635427e-05 1.3268708244140726e-05
rl training, epoch5, iter0, batch82/1133, batch loss:1.3268708244140726e-05, Training time:81550.3216753006
batch reward last col mean 1.4671459211967885e-06 first col mean 2.7249627692071954e-06 all mean 9.788951501832344e-06
7.973254469106905e-06 7.973255378601607e-06
rl training, epoch5, iter0, batch83/1133, batch loss:7.973255378601607e-06, Training time:81567.06506371498
batch reward last col mean 6.424824732675916e-06 first col mean 1.028963288263185e-05 all mean 5.3744101023767143e-05
3.885680052917451e-05 3.88567968911957e-05
rl training, epoch5, iter0, batch84/1133, batch loss:3.88567968911957e-05, Training time:81583.5794467926
batch reward last col mean 0.00024346374266315252 first col mean 3.1418867365573533e-06 all mean 4.106813503312878e-05
3.836236646748148e-05 3.836235555354506e-05
rl training, epoch5, iter0, batch85/1133, batch loss:3.836235555354506e-05, Training time:81600.28850245476
batch reward last col mean 1.7803492937673582e-06 first col mean 3.4155984849348897e-06 all mean 1.5437988622579724e-05
9.029253305925522e-06 9.029255124914926e-06
rl training, epoch5, iter0, batch86/1133, batch loss:9.029255124914926e-06, Training time:81617.25700569153
batch reward last col mean 9.991967090172693e-06 first col mean 3.832943093584618e-06 all mean 1.827034429879859e-05
1.3128118553140666e-05 1.312811491516186e-05
rl training, epoch5, iter0, batch87/1133, batch loss:1.312811491516186e-05, Training time:81634.16909098625
batch reward last col mean 1.3804028640151955e-05 first col mean 3.5012080843443982e-06 all mean 3.70585621567443e-05
2.6155486921197735e-05 2.6155481464229524e-05
rl training, epoch5, iter0, batch88/1133, batch loss:2.6155481464229524e-05, Training time:81650.97268128395
batch reward last col mean 5.807353591080755e-05 first col mean 4.36368391092401e-05 all mean 2.8006787033518776e-05
6.383052095770836e-06 6.383035724866204e-06
rl training, epoch5, iter0, batch89/1133, batch loss:6.383035724866204e-06, Training time:81667.85193991661
batch reward last col mean 8.90285627974663e-06 first col mean 3.1191266316454858e-06 all mean 1.8778689991449937e-05
1.0646059308783151e-05 1.0646057489793748e-05
rl training, epoch5, iter0, batch90/1133, batch loss:1.0646057489793748e-05, Training time:81686.47969126701
batch reward last col mean 2.491172017471399e-05 first col mean 3.5762734569289023e-06 all mean 1.2846702702518087e-05
4.667003395297797e-06 4.667002485803096e-06
rl training, epoch5, iter0, batch91/1133, batch loss:4.667002485803096e-06, Training time:81703.47827029228
batch reward last col mean 1.116669977818674e-06 first col mean 1.2208793123136275e-05 all mean 6.491071417258354e-06
1.8930180658571771e-06 1.8930184069176903e-06
rl training, epoch5, iter0, batch92/1133, batch loss:1.8930184069176903e-06, Training time:81720.48125457764
batch reward last col mean 6.570096047653351e-06 first col mean 1.2494022030296037e-06 all mean 2.379766920057591e-05
2.1644995285896584e-05 2.1644986190949567e-05
rl training, epoch5, iter0, batch93/1133, batch loss:2.1644986190949567e-05, Training time:81737.48248624802
batch reward last col mean 4.1147264710161835e-05 first col mean 1.5534082194790244e-05 all mean 3.751515396288596e-05
7.353245018748567e-05 7.353245746344328e-05
rl training, epoch5, iter0, batch94/1133, batch loss:7.353245746344328e-05, Training time:81754.47043037415
batch reward last col mean 6.382150786521379e-06 first col mean 1.0420565104141133e-06 all mean 1.900440656754654e-05
2.5872843707475113e-06 2.5872870992316166e-06
rl training, epoch5, iter0, batch95/1133, batch loss:2.5872870992316166e-06, Training time:81771.40068793297
batch reward last col mean 3.138808096991852e-06 first col mean 1.3082879377179779e-05 all mean 2.3627449991181493e-05
7.772411663609091e-06 7.772409844619688e-06
rl training, epoch5, iter0, batch96/1133, batch loss:7.772409844619688e-06, Training time:81788.54911494255
batch reward last col mean 2.095739546348341e-06 first col mean 4.400274974614149e-06 all mean 1.4684051166113932e-05
3.2571792871749494e-06 3.257180196669651e-06
rl training, epoch5, iter0, batch97/1133, batch loss:3.257180196669651e-06, Training time:81805.40133595467
batch reward last col mean 6.308946467470378e-05 first col mean 3.974985702370759e-06 all mean 4.370666647446342e-05
2.225566095148679e-05 2.225567186542321e-05
rl training, epoch5, iter0, batch98/1133, batch loss:2.225567186542321e-05, Training time:81822.23810982704
batch reward last col mean 1.261689976672642e-05 first col mean 7.47773401599261e-06 all mean 1.5065917068568524e-05
6.019196007400751e-06 6.0191987358848564e-06
rl training, epoch5, iter0, batch99/1133, batch loss:6.0191987358848564e-06, Training time:81839.06297111511
batch reward last col mean 5.981720278214198e-06 first col mean 1.4942922916816315e-06 all mean 2.136597686330788e-05
1.1311439266137313e-05 1.1311441085126717e-05
rl training, epoch5, iter0, batch100/1133, batch loss:1.1311441085126717e-05, Training time:81856.64731740952
batch reward last col mean 5.030081410950515e-06 first col mean 2.1513735646294663e-06 all mean 1.5704612451372668e-05
5.291835805110168e-06 5.291833531373413e-06
rl training, epoch5, iter0, batch101/1133, batch loss:5.291833531373413e-06, Training time:81873.6257545948
batch reward last col mean 0.0006663025706075132 first col mean 1.5229197742883116e-06 all mean 2.4881521312636323e-05
2.8169199140393175e-05 2.816920095938258e-05
rl training, epoch5, iter0, batch102/1133, batch loss:2.816920095938258e-05, Training time:81891.94428443909
batch reward last col mean 1.3000732906220946e-05 first col mean 1.3641438272316009e-06 all mean 3.2535626814933494e-05
5.919629529671511e-06 5.919633167650318e-06
rl training, epoch5, iter0, batch103/1133, batch loss:5.919633167650318e-06, Training time:81909.00876045227
batch reward last col mean 1.262932983081555e-06 first col mean 2.2970721147430595e-06 all mean 3.113221828243695e-05
1.1155036190757528e-05 1.1155029824294616e-05
rl training, epoch5, iter0, batch104/1133, batch loss:1.1155029824294616e-05, Training time:81926.10435271263
batch reward last col mean 5.033208253735211e-06 first col mean 1.6694776832082425e-06 all mean 1.1277505109319463e-05
3.7965878618706483e-06 3.7965878618706483e-06
rl training, epoch5, iter0, batch105/1133, batch loss:3.7965878618706483e-06, Training time:81945.06191778183
batch reward last col mean 5.976218290015822e-06 first col mean 3.446741175139323e-05 all mean 3.859720891341567e-05
3.2761090551503e-05 3.276109418948181e-05
rl training, epoch5, iter0, batch106/1133, batch loss:3.276109418948181e-05, Training time:81963.80929756165
batch reward last col mean 3.195592580595985e-05 first col mean 7.402053597616032e-06 all mean 2.8807444323319942e-05
1.1376024303899612e-05 1.1376020665920805e-05
rl training, epoch5, iter0, batch107/1133, batch loss:1.1376020665920805e-05, Training time:81980.83737921715
batch reward last col mean 5.325739402906038e-05 first col mean 4.079144673596602e-06 all mean 1.804708517738618e-05
4.905474270344712e-06 4.905476089334115e-06
rl training, epoch5, iter0, batch108/1133, batch loss:4.905476089334115e-06, Training time:81997.84932017326
batch reward last col mean 1.7502190985396737e-06 first col mean 1.4326089967653388e-06 all mean 1.0426284461573232e-05
8.187776984414086e-06 8.187776074919384e-06
rl training, epoch5, iter0, batch109/1133, batch loss:8.187776074919384e-06, Training time:82014.87104392052
batch reward last col mean 3.109404133283533e-06 first col mean 3.5627383567771176e-06 all mean 6.1862401707912795e-06
2.9904633720434504e-06 2.9904638267908012e-06
rl training, epoch5, iter0, batch110/1133, batch loss:2.9904638267908012e-06, Training time:82031.85715413094
batch reward last col mean 2.0964349459973164e-05 first col mean 4.574052582029253e-06 all mean 1.7053222109097987e-05
4.315628757467493e-06 4.315627847972792e-06
rl training, epoch5, iter0, batch111/1133, batch loss:4.315627847972792e-06, Training time:82048.80060744286
batch reward last col mean 9.178660320685594e-07 first col mean 4.031046046293341e-06 all mean 1.3996916095493361e-05
6.598436812055297e-06 6.598440450034104e-06
rl training, epoch5, iter0, batch112/1133, batch loss:6.598440450034104e-06, Training time:82067.83161735535
batch reward last col mean 1.8944139810628258e-05 first col mean 2.5026149614859605e-06 all mean 2.3807977413525805e-05
1.1095563422713894e-05 1.1095565241703298e-05
rl training, epoch5, iter0, batch113/1133, batch loss:1.1095565241703298e-05, Training time:82084.84715533257
batch reward last col mean 2.400531684543239e-06 first col mean 2.0117963686061557e-06 all mean 1.3451528502628207e-05
5.409354344010353e-06 5.409356162999757e-06
rl training, epoch5, iter0, batch114/1133, batch loss:5.409356162999757e-06, Training time:82101.73842382431
batch reward last col mean 8.439310477115214e-07 first col mean 9.390066679770825e-07 all mean 1.6380783563363366e-05
1.2835619600082282e-05 1.283562414755579e-05
rl training, epoch5, iter0, batch115/1133, batch loss:1.283562414755579e-05, Training time:82119.75167751312
batch reward last col mean 5.180279458727455e-07 first col mean 9.627535746403737e-07 all mean 3.5477733035804704e-05
9.3105654741521e-06 9.310569112130906e-06
rl training, epoch5, iter0, batch116/1133, batch loss:9.310569112130906e-06, Training time:82136.59079265594
batch reward last col mean 1.4733252555743093e-06 first col mean 3.348091240695794e-06 all mean 1.4100545740802772e-05
7.560563517472474e-06 7.560563062725123e-06
rl training, epoch5, iter0, batch117/1133, batch loss:7.560563062725123e-06, Training time:82153.8977227211
batch reward last col mean 1.9340515791554935e-05 first col mean 5.965637683402747e-06 all mean 3.139389446005225e-05
2.6666841222322546e-05 2.6666832127375528e-05
rl training, epoch5, iter0, batch118/1133, batch loss:2.6666832127375528e-05, Training time:82171.5572502613
batch reward last col mean 2.211322498624213e-05 first col mean 8.311665169458138e-07 all mean 1.1551976058399305e-05
5.3238632062857505e-06 5.323864115780452e-06
rl training, epoch5, iter0, batch119/1133, batch loss:5.323864115780452e-06, Training time:82188.41740226746
batch reward last col mean 8.430883099208586e-06 first col mean 9.325674000137951e-06 all mean 9.138607310887892e-06
5.726924882765161e-06 5.726925792259863e-06
rl training, epoch5, iter0, batch120/1133, batch loss:5.726925792259863e-06, Training time:82205.45188808441
batch reward last col mean 2.2279989480011864e-06 first col mean 4.651148628909141e-06 all mean 5.724399670725688e-05
4.4824086216976866e-05 4.482407894101925e-05
rl training, epoch5, iter0, batch121/1133, batch loss:4.482407894101925e-05, Training time:82222.44506120682
batch reward last col mean 3.572092964532203e-06 first col mean 1.0385492714704014e-05 all mean 3.6853434721706435e-05
3.954891872126609e-05 3.95489223592449e-05
rl training, epoch5, iter0, batch122/1133, batch loss:3.95489223592449e-05, Training time:82239.48702192307
batch reward last col mean 7.24484550573834e-07 first col mean 6.621369266213151e-06 all mean 2.9872386221541092e-05
1.787172550393734e-05 1.7871727322926745e-05
rl training, epoch5, iter0, batch123/1133, batch loss:1.7871727322926745e-05, Training time:82256.51367592812
batch reward last col mean 9.903093086904846e-06 first col mean 2.6411837552586803e-06 all mean 4.3420863221399486e-05
2.3431735826306976e-05 2.3431741283275187e-05
rl training, epoch5, iter0, batch124/1133, batch loss:2.3431741283275187e-05, Training time:82273.53480172157
batch reward last col mean 1.4469478628598154e-06 first col mean 3.3310780054307543e-06 all mean 2.4494893295923248e-05
2.181811760237906e-05 2.1818115783389658e-05
rl training, epoch5, iter0, batch125/1133, batch loss:2.1818115783389658e-05, Training time:82290.73030304909
batch reward last col mean 1.318066892963543e-06 first col mean 9.375025001645554e-06 all mean 4.072309457114898e-05
6.799609400331974e-05 6.799609400331974e-05
rl training, epoch5, iter0, batch126/1133, batch loss:6.799609400331974e-05, Training time:82307.85875797272
batch reward last col mean 2.0428207790246233e-05 first col mean 1.4153808933770051e-06 all mean 3.5852590372087434e-05
1.2390210940793622e-05 1.239021003129892e-05
rl training, epoch5, iter0, batch127/1133, batch loss:1.239021003129892e-05, Training time:82326.27904081345
batch reward last col mean 2.854637205018662e-05 first col mean 3.4417930692143273e-06 all mean 1.1580879800021648e-05
7.864670806156937e-06 7.864671715651639e-06
rl training, epoch5, iter0, batch128/1133, batch loss:7.864671715651639e-06, Training time:82344.4521472454
batch reward last col mean 1.3787127500108909e-05 first col mean 5.095897904539015e-06 all mean 3.1756702810525894e-05
2.1715284674428403e-05 2.1715286493417807e-05
rl training, epoch5, iter0, batch129/1133, batch loss:2.1715286493417807e-05, Training time:82362.91086363792
batch reward last col mean 1.2605863730641431e-06 first col mean 3.364404165040469e-06 all mean 5.092610990686808e-06
3.343657908772002e-06 3.343657908772002e-06
rl training, epoch5, iter0, batch130/1133, batch loss:3.343657908772002e-06, Training time:82379.84947228432
batch reward last col mean 1.7992735592997633e-05 first col mean 4.7208745854732115e-06 all mean 2.7300002329866402e-05
1.1073609130107798e-05 1.1073612768086605e-05
rl training, epoch5, iter0, batch131/1133, batch loss:1.1073612768086605e-05, Training time:82397.84636282921
batch reward last col mean 2.4921899239416234e-05 first col mean 4.870134944212623e-06 all mean 5.572844384005293e-05
3.297251168987714e-05 3.297251168987714e-05
rl training, epoch5, iter0, batch132/1133, batch loss:3.297251168987714e-05, Training time:82415.64770436287
batch reward last col mean 1.8108688664142392e-06 first col mean 2.662895440153079e-06 all mean 2.5629462470533326e-05
7.197842205641791e-05 7.197842205641791e-05
rl training, epoch5, iter0, batch133/1133, batch loss:7.197842205641791e-05, Training time:82434.15140533447
batch reward last col mean 0.0028478894382715225 first col mean 2.193261707361671e-06 all mean 0.00047197361709550023
5.912639244343154e-05 5.912639244343154e-05
rl training, epoch5, iter0, batch134/1133, batch loss:5.912639244343154e-05, Training time:82452.19706320763
batch reward last col mean 7.163515874708537e-06 first col mean 3.3503094982734183e-06 all mean 2.8138363632024266e-05
1.2016683285764884e-05 1.201668601424899e-05
rl training, epoch5, iter0, batch135/1133, batch loss:1.201668601424899e-05, Training time:82469.1162173748
batch reward last col mean 0.005230486858636141 first col mean 3.842086698568892e-06 all mean 8.305624942295253e-05
0.0001606660516699776 0.00016066603711806238
rl training, epoch5, iter0, batch136/1133, batch loss:0.00016066603711806238, Training time:82486.085542202
batch reward last col mean 6.516473149531521e-06 first col mean 1.7029641412591445e-06 all mean 1.0032626960310154e-05
3.6251590245228726e-06 3.6251578876544954e-06
rl training, epoch5, iter0, batch137/1133, batch loss:3.6251578876544954e-06, Training time:82503.07875680923
batch reward last col mean 1.1816289315902395e-06 first col mean 9.867146218311973e-06 all mean 8.622937457403168e-06
3.5662292248161975e-06 3.5662283153214958e-06
rl training, epoch5, iter0, batch138/1133, batch loss:3.5662283153214958e-06, Training time:82520.06738138199
batch reward last col mean 2.2466047084890306e-06 first col mean 2.016263124460238e-06 all mean 2.994849819515366e-05
1.117271494877059e-05 1.117271494877059e-05
rl training, epoch5, iter0, batch139/1133, batch loss:1.117271494877059e-05, Training time:82537.11509466171
batch reward last col mean 1.1669078048726078e-05 first col mean 1.254851554222114e-06 all mean 1.4312040548247751e-05
6.487057362392079e-06 6.487056452897377e-06
rl training, epoch5, iter0, batch140/1133, batch loss:6.487056452897377e-06, Training time:82554.13082718849
batch reward last col mean 2.784635171337868e-06 first col mean 1.723950481391512e-05 all mean 1.3307464541867375e-05
5.3189323807600886e-06 5.318931471265387e-06
rl training, epoch5, iter0, batch141/1133, batch loss:5.318931471265387e-06, Training time:82570.97757959366
batch reward last col mean 2.3172187866293825e-06 first col mean 2.132468125637388e-06 all mean 2.0840872821281664e-05
4.989796252630185e-06 4.989797616872238e-06
rl training, epoch5, iter0, batch142/1133, batch loss:4.989797616872238e-06, Training time:82589.57354068756
batch reward last col mean 7.799353056725522e-07 first col mean 1.793601768440567e-05 all mean 1.5752344552311115e-05
7.886296771175694e-06 7.886297680670395e-06
rl training, epoch5, iter0, batch143/1133, batch loss:7.886297680670395e-06, Training time:82606.29744768143
batch reward last col mean 2.1262546852085507e-06 first col mean 1.4518572243105154e-05 all mean 3.5290959203848615e-05
9.608214895706624e-06 9.608216714696027e-06
rl training, epoch5, iter0, batch144/1133, batch loss:9.608216714696027e-06, Training time:82625.01661610603
batch reward last col mean 0.0002005022979574278 first col mean 1.7361917343805544e-06 all mean 1.4493771232082509e-05
2.0992492864024825e-05 2.0992491045035422e-05
rl training, epoch5, iter0, batch145/1133, batch loss:2.0992491045035422e-05, Training time:82642.11805534363
batch reward last col mean 3.852292593364837e-06 first col mean 7.479102350771427e-06 all mean 2.106456486217212e-05
2.7691039576893672e-05 2.7691039576893672e-05
rl training, epoch5, iter0, batch146/1133, batch loss:2.7691039576893672e-05, Training time:82658.92270255089
batch reward last col mean 1.536525451228954e-05 first col mean 1.9097547010460403e-06 all mean 3.0411742045544088e-05
2.9075032216496766e-05 2.9075030397507362e-05
rl training, epoch5, iter0, batch147/1133, batch loss:2.9075030397507362e-05, Training time:82677.35436987877
batch reward last col mean 3.4523218346294016e-05 first col mean 3.707474661496235e-06 all mean 5.8583194913808256e-05
1.2351963960099965e-05 1.2351975783531088e-05
rl training, epoch5, iter0, batch148/1133, batch loss:1.2351975783531088e-05, Training time:82696.02422618866
batch reward last col mean 2.35227016673889e-05 first col mean 1.6822667021187954e-05 all mean 3.132038546027616e-05
2.6696310669649392e-05 2.66963143076282e-05
rl training, epoch5, iter0, batch149/1133, batch loss:2.66963143076282e-05, Training time:82714.29462885857
batch reward last col mean 1.4598547295463504e-06 first col mean 6.9543480094580445e-06 all mean 1.8586801161291078e-05
2.0710615444841096e-06 2.0710594981210306e-06
rl training, epoch5, iter0, batch150/1133, batch loss:2.0710594981210306e-06, Training time:82733.0124411583
batch reward last col mean 5.800665121569182e-07 first col mean 6.283080438151956e-06 all mean 1.8961534806294367e-05
5.0449766604288016e-06 5.044980298407609e-06
rl training, epoch5, iter0, batch151/1133, batch loss:5.044980298407609e-06, Training time:82750.07344341278
batch reward last col mean 2.654990794326295e-06 first col mean 3.0826579404674703e-06 all mean 3.335143264848739e-05
8.456119758193381e-06 8.45610884425696e-06
rl training, epoch5, iter0, batch152/1133, batch loss:8.45610884425696e-06, Training time:82767.03816986084
batch reward last col mean 1.0095819561684038e-05 first col mean 9.462559091844014e-07 all mean 2.374001451244112e-05
2.9864691896364093e-05 2.9864699172321707e-05
rl training, epoch5, iter0, batch153/1133, batch loss:2.9864699172321707e-05, Training time:82783.88259577751
batch reward last col mean 1.3982778455101652e-06 first col mean 8.823360985843465e-06 all mean 6.3148431763693225e-06
2.5845865820883773e-06 2.5845847630989738e-06
rl training, epoch5, iter0, batch154/1133, batch loss:2.5845847630989738e-06, Training time:82800.79325032234
batch reward last col mean 3.3493663522676798e-06 first col mean 2.363462044741027e-06 all mean 1.054084987117676e-05
3.695284021887346e-06 3.6952835671399953e-06
rl training, epoch5, iter0, batch155/1133, batch loss:3.6952835671399953e-06, Training time:82817.63803124428
batch reward last col mean 9.046972309079138e-07 first col mean 2.802322569550597e-06 all mean 1.6751720977481455e-05
3.0467926990240812e-06 3.0467913347820286e-06
rl training, epoch5, iter0, batch156/1133, batch loss:3.0467913347820286e-06, Training time:82834.41420865059
batch reward last col mean 7.344401092268527e-05 first col mean 1.058988618751755e-05 all mean 5.146114563103765e-05
8.708162204129621e-05 8.708163659321144e-05
rl training, epoch5, iter0, batch157/1133, batch loss:8.708163659321144e-05, Training time:82851.05256295204
batch reward last col mean 1.9674025679705665e-06 first col mean 4.84005158796208e-06 all mean 4.61751660623122e-05
3.0162664188537747e-05 3.0162658731569536e-05
rl training, epoch5, iter0, batch158/1133, batch loss:3.0162658731569536e-05, Training time:82867.96366548538
batch reward last col mean 4.195901055936702e-06 first col mean 4.123136477574008e-06 all mean 8.72537202667445e-06
4.630098828783957e-06 4.63010019302601e-06
rl training, epoch5, iter0, batch159/1133, batch loss:4.63010019302601e-06, Training time:82884.7557451725
batch reward last col mean 7.587453183077741e-06 first col mean 9.725736163090914e-06 all mean 3.2345426006941125e-05
5.1905000873375684e-05 5.1905000873375684e-05
rl training, epoch5, iter0, batch160/1133, batch loss:5.1905000873375684e-05, Training time:82901.58922314644
batch reward last col mean 1.159708858722297e-06 first col mean 7.680256203457247e-06 all mean 4.0015773265622556e-05
5.215525743551552e-05 5.215525743551552e-05
rl training, epoch5, iter0, batch161/1133, batch loss:5.215525743551552e-05, Training time:82918.23597455025
batch reward last col mean 2.2560154775419505e-06 first col mean 2.5393215764779598e-05 all mean 2.4513670723536052e-05
8.578938832215499e-06 8.578937013226096e-06
rl training, epoch5, iter0, batch162/1133, batch loss:8.578937013226096e-06, Training time:82934.84941840172
batch reward last col mean 7.015318988123909e-05 first col mean 2.0572097128024325e-06 all mean 3.427267074584961e-05
1.9658065866678953e-05 1.965806404768955e-05
rl training, epoch5, iter0, batch163/1133, batch loss:1.965806404768955e-05, Training time:82951.57763695717
batch reward last col mean 0.0002158471179427579 first col mean 6.523476940856199e-07 all mean 3.352451676619239e-05
3.053571708733216e-05 3.053570617339574e-05
rl training, epoch5, iter0, batch164/1133, batch loss:3.053570617339574e-05, Training time:82968.38623642921
batch reward last col mean 1.550202796352096e-06 first col mean 5.667970526701538e-06 all mean 5.0435755838407204e-05
2.130214670614805e-05 2.1302133973222226e-05
rl training, epoch5, iter0, batch165/1133, batch loss:2.1302133973222226e-05, Training time:82985.28482532501
batch reward last col mean 1.272249392059166e-05 first col mean 2.6482796329219127e-06 all mean 3.6967790947528556e-05
5.590136424871162e-06 5.590140062849969e-06
rl training, epoch5, iter0, batch166/1133, batch loss:5.590140062849969e-06, Training time:83002.2314786911
batch reward last col mean 2.7237480026087724e-05 first col mean 2.975378265546169e-06 all mean 2.2985217583482154e-05
1.1879191333719064e-05 1.1879190424224362e-05
rl training, epoch5, iter0, batch167/1133, batch loss:1.1879190424224362e-05, Training time:83019.0680963993
batch reward last col mean 2.6940548195852898e-05 first col mean 7.783623914292548e-06 all mean 1.1637470379355364e-05
6.080298135202611e-06 6.08029768045526e-06
rl training, epoch5, iter0, batch168/1133, batch loss:6.08029768045526e-06, Training time:83036.0901324749
batch reward last col mean 1.6412594732173602e-06 first col mean 5.0166872824775055e-06 all mean 1.832776251831092e-05
7.160354471125174e-06 7.160349014156964e-06
rl training, epoch5, iter0, batch169/1133, batch loss:7.160349014156964e-06, Training time:83053.09670853615
batch reward last col mean 2.3438115022145212e-05 first col mean 5.2971158766013104e-06 all mean 4.526242628344335e-05
1.3246240996522829e-05 1.3246237358544022e-05
rl training, epoch5, iter0, batch170/1133, batch loss:1.3246237358544022e-05, Training time:83070.08050560951
batch reward last col mean 1.8322028836337267e-06 first col mean 1.9351764422026463e-05 all mean 6.403179668268422e-06
6.283203219936695e-06 6.283202310441993e-06
rl training, epoch5, iter0, batch171/1133, batch loss:6.283202310441993e-06, Training time:83086.97948288918
batch reward last col mean 1.3971764474263182e-06 first col mean 1.2229522326379083e-05 all mean 3.839167402475141e-05
2.1080271835671738e-05 2.1080270016682334e-05
rl training, epoch5, iter0, batch172/1133, batch loss:2.1080270016682334e-05, Training time:83103.8516125679
batch reward last col mean 2.1958410798106343e-05 first col mean 3.0309891371871345e-05 all mean 5.842515383847058e-05
3.5058354114880785e-05 3.5058354114880785e-05
rl training, epoch5, iter0, batch173/1133, batch loss:3.5058354114880785e-05, Training time:83120.62574362755
batch reward last col mean 6.797358946641907e-05 first col mean 1.8709937648964114e-05 all mean 2.748966471699532e-05
8.947797141445335e-06 8.947791684477124e-06
rl training, epoch5, iter0, batch174/1133, batch loss:8.947791684477124e-06, Training time:83137.37790632248
batch reward last col mean 2.2814367639512056e-06 first col mean 1.4689102272313903e-06 all mean 3.0248524126363918e-05
1.4613243365602102e-05 1.4613240637117997e-05
rl training, epoch5, iter0, batch175/1133, batch loss:1.4613240637117997e-05, Training time:83154.21394753456
batch reward last col mean 1.3477298352881917e-06 first col mean 4.1637718823039904e-05 all mean 2.6589548724587075e-05
6.550510079250671e-06 6.550509169755969e-06
rl training, epoch5, iter0, batch176/1133, batch loss:6.550509169755969e-06, Training time:83171.14350962639
batch reward last col mean 1.155569520960853e-06 first col mean 3.7441409403982107e-06 all mean 2.7160987883689813e-05
1.3486763236869592e-05 1.3486764146364294e-05
rl training, epoch5, iter0, batch177/1133, batch loss:1.3486764146364294e-05, Training time:83187.95410466194
batch reward last col mean 3.0343696835188894e-06 first col mean 1.0570637414275552e-06 all mean 3.485467823338695e-05
1.5769212041050196e-05 1.576920840307139e-05
rl training, epoch5, iter0, batch178/1133, batch loss:1.576920840307139e-05, Training time:83205.03250336647
batch reward last col mean 5.8240475482307374e-06 first col mean 1.1634007023531012e-05 all mean 5.5536751460749656e-05
2.6811667339643463e-05 2.6811661882675253e-05
rl training, epoch5, iter0, batch179/1133, batch loss:2.6811661882675253e-05, Training time:83221.76166152954
batch reward last col mean 1.6979970496322494e-06 first col mean 5.6281551223946735e-05 all mean 5.521777438843856e-06
2.8551037303259363e-06 2.8551039576996118e-06
rl training, epoch5, iter0, batch180/1133, batch loss:2.8551039576996118e-06, Training time:83238.52785205841
batch reward last col mean 9.002251317724586e-05 first col mean 0.001708432100713253 all mean 3.919035953003913e-05
1.0963790373352822e-05 1.0963793101836927e-05
rl training, epoch5, iter0, batch181/1133, batch loss:1.0963793101836927e-05, Training time:83256.51840901375
batch reward last col mean 6.627404218306765e-06 first col mean 2.234643034171313e-06 all mean 2.4824012143653817e-05
6.326069524220657e-06 6.326064976747148e-06
rl training, epoch5, iter0, batch182/1133, batch loss:6.326064976747148e-06, Training time:83273.43875026703
batch reward last col mean 9.062773642654065e-07 first col mean 2.9699724564125063e-06 all mean 2.3953485651873052e-05
5.074806904303841e-05 5.07480617670808e-05
rl training, epoch5, iter0, batch183/1133, batch loss:5.07480617670808e-05, Training time:83290.8496594429
batch reward last col mean 2.1546969946939498e-05 first col mean 2.3809193407942075e-06 all mean 1.61473399202805e-05
5.0369299060548656e-06 5.03693217979162e-06
rl training, epoch5, iter0, batch184/1133, batch loss:5.03693217979162e-06, Training time:83307.93249678612
batch reward last col mean 5.110803613206372e-06 first col mean 4.862446985498536e-06 all mean 9.498635336058214e-06
4.957261353411013e-06 4.957263172400417e-06
rl training, epoch5, iter0, batch185/1133, batch loss:4.957263172400417e-06, Training time:83324.98689770699
batch reward last col mean 3.665830445243046e-05 first col mean 1.6514941307832487e-06 all mean 2.2698010070598684e-05
4.095084477739874e-06 4.0950917536974885e-06
rl training, epoch5, iter0, batch186/1133, batch loss:4.0950917536974885e-06, Training time:83341.98607993126
batch reward last col mean 3.6326373447082005e-06 first col mean 2.4292005491588498e-06 all mean 1.6094263628474437e-05
5.310334472596878e-06 5.310339020070387e-06
rl training, epoch5, iter0, batch187/1133, batch loss:5.310339020070387e-06, Training time:83359.05698537827
batch reward last col mean 2.745976644291659e-06 first col mean 6.353492608468514e-06 all mean 3.474433833616786e-05
2.460725954733789e-05 2.4607252271380275e-05
rl training, epoch5, iter0, batch188/1133, batch loss:2.4607252271380275e-05, Training time:83376.03744244576
batch reward last col mean 7.877520147303585e-06 first col mean 4.419992819748586e-06 all mean 2.3481732569052838e-05
5.546829925151542e-05 5.5468302889494225e-05
rl training, epoch5, iter0, batch189/1133, batch loss:5.5468302889494225e-05, Training time:83392.76596164703
batch reward last col mean 2.544604058130062e-06 first col mean 2.0019867861265084e-06 all mean 1.1558096048247535e-05
8.116180651995819e-06 8.11618156149052e-06
rl training, epoch5, iter0, batch190/1133, batch loss:8.11618156149052e-06, Training time:83411.1813621521
batch reward last col mean 1.2701417290372774e-05 first col mean 6.5911776800930966e-06 all mean 3.9180697058327496e-05
3.3995926060015336e-05 3.3995926060015336e-05
rl training, epoch5, iter0, batch191/1133, batch loss:3.3995926060015336e-05, Training time:83428.04275894165
batch reward last col mean 2.6996344786311965e-06 first col mean 6.143602604424814e-06 all mean 2.7805601348518394e-05
8.086129128059838e-06 8.086130947049242e-06
rl training, epoch5, iter0, batch192/1133, batch loss:8.086130947049242e-06, Training time:83445.47784781456
batch reward last col mean 0.0011510683689266443 first col mean 1.7938923519977834e-06 all mean 3.6248136893846095e-05
4.1346356738358736e-05 4.1346356738358736e-05
rl training, epoch5, iter0, batch193/1133, batch loss:4.1346356738358736e-05, Training time:83462.25162577629
batch reward last col mean 3.7109805361978943e-06 first col mean 2.060041651930078e-06 all mean 1.5362109479610808e-05
9.604692422726657e-06 9.604690603737254e-06
rl training, epoch5, iter0, batch194/1133, batch loss:9.604690603737254e-06, Training time:83479.28520607948
batch reward last col mean 7.464407190127531e-06 first col mean 3.5149823816027492e-06 all mean 5.7502667914377525e-05
2.872466211556457e-05 2.8724653020617552e-05
rl training, epoch5, iter0, batch195/1133, batch loss:2.8724653020617552e-05, Training time:83496.2095322609
batch reward last col mean 6.245355507417116e-06 first col mean 9.408378900843672e-06 all mean 2.9449232897604816e-05
8.778345545579214e-06 8.778346455073915e-06
rl training, epoch5, iter0, batch196/1133, batch loss:8.778346455073915e-06, Training time:83513.09322214127
batch reward last col mean 2.229510073448182e-06 first col mean 6.8124559220450465e-06 all mean 2.2207806978258304e-05
6.0785650930483826e-06 6.0785614550695755e-06
rl training, epoch5, iter0, batch197/1133, batch loss:6.0785614550695755e-06, Training time:83530.0646238327
batch reward last col mean 0.00047321818419732153 first col mean 6.198947630764451e-06 all mean 2.9079561500111595e-05
5.226294888416305e-05 5.2262945246184245e-05
rl training, epoch5, iter0, batch198/1133, batch loss:5.2262945246184245e-05, Training time:83547.00709271431
batch reward last col mean 7.079147962940624e-06 first col mean 6.239625690795947e-06 all mean 5.7264255701738875e-06
6.4052974266815e-06 6.4052974266815e-06
rl training, epoch5, iter0, batch199/1133, batch loss:6.4052974266815e-06, Training time:83564.0005941391
batch reward last col mean 1.5016174984339159e-05 first col mean 1.4559177543560509e-06 all mean 2.715460504987277e-05
1.2014586900477298e-05 1.2014585990982596e-05
rl training, epoch5, iter0, batch200/1133, batch loss:1.2014585990982596e-05, Training time:83580.98958778381
batch reward last col mean 2.5610318061808357e-06 first col mean 1.4084142776482622e-06 all mean 1.6791504094726406e-05
3.9111684600356966e-05 3.9111684600356966e-05
rl training, epoch5, iter0, batch201/1133, batch loss:3.9111684600356966e-05, Training time:83598.04445815086
batch reward last col mean 5.439248980110278e-06 first col mean 4.608618837664835e-06 all mean 6.3942161432350986e-06
3.1424212920683203e-06 3.1424219741893467e-06
rl training, epoch5, iter0, batch202/1133, batch loss:3.1424219741893467e-06, Training time:83614.97205162048
batch reward last col mean 4.32720327125935e-07 first col mean 2.2742444798495853e-06 all mean 3.670903606689535e-05
1.503684416093165e-05 1.5036845070426352e-05
rl training, epoch5, iter0, batch203/1133, batch loss:1.5036845070426352e-05, Training time:83632.04477334023
batch reward last col mean 1.1331978839734802e-06 first col mean 1.0814571851369692e-06 all mean 3.19205537380185e-05
7.905876373115461e-06 7.905878192104865e-06
rl training, epoch5, iter0, batch204/1133, batch loss:7.905878192104865e-06, Training time:83649.03151202202
batch reward last col mean 2.0973050141037675e-06 first col mean 8.759052434470505e-06 all mean 1.1048095984733663e-05
4.528155386651633e-06 4.528155841398984e-06
rl training, epoch5, iter0, batch205/1133, batch loss:4.528155841398984e-06, Training time:83665.96386361122
batch reward last col mean 4.132270078116562e-06 first col mean 1.2346886251179967e-06 all mean 8.647651156934444e-06
3.2537018341827206e-06 3.2537031984247733e-06
rl training, epoch5, iter0, batch206/1133, batch loss:3.2537031984247733e-06, Training time:83684.53186321259
batch reward last col mean 4.178579729341436e-06 first col mean 1.9138967672915896e-06 all mean 2.3831133148632944e-05
1.089758279704256e-05 1.0897584616031963e-05
rl training, epoch5, iter0, batch207/1133, batch loss:1.0897584616031963e-05, Training time:83701.28609967232
batch reward last col mean 0.00011739108595065773 first col mean 2.6074833385791862e-06 all mean 1.1485004506539553e-05
1.0883852155529894e-05 1.0883853065024596e-05
rl training, epoch5, iter0, batch208/1133, batch loss:1.0883853065024596e-05, Training time:83719.34001994133
batch reward last col mean 0.00016314872482325882 first col mean 2.1869834654353326e-06 all mean 8.815590990707278e-05
4.546471609501168e-05 4.5464712457032874e-05
rl training, epoch5, iter0, batch209/1133, batch loss:4.5464712457032874e-05, Training time:83737.86733531952
batch reward last col mean 1.349345166090643e-05 first col mean 5.154306563781574e-06 all mean 1.1835828445327934e-05
1.0098819075210486e-05 1.0098819075210486e-05
rl training, epoch5, iter0, batch210/1133, batch loss:1.0098819075210486e-05, Training time:83756.46437263489
batch reward last col mean 2.6249836082570255e-06 first col mean 4.0725772123550996e-05 all mean 5.238633821136318e-05
2.8423257390386425e-05 2.842325920937583e-05
rl training, epoch5, iter0, batch211/1133, batch loss:2.842325920937583e-05, Training time:83774.64595460892
batch reward last col mean 8.055549187702127e-06 first col mean 2.9394357170531293e-06 all mean 4.6076827857177705e-05
1.605345096322708e-05 1.605343641131185e-05
rl training, epoch5, iter0, batch212/1133, batch loss:1.605343641131185e-05, Training time:83791.397408247
batch reward last col mean 8.885524948709644e-06 first col mean 2.031339363384177e-06 all mean 5.9683952713385224e-06
6.032549208612181e-06 6.032550118106883e-06
rl training, epoch5, iter0, batch213/1133, batch loss:6.032550118106883e-06, Training time:83808.33229136467
batch reward last col mean 0.001807788503356278 first col mean 2.025911499003996e-06 all mean 0.0004327775095589459
0.0001568461739225313 0.0001568461739225313
rl training, epoch5, iter0, batch214/1133, batch loss:0.0001568461739225313, Training time:83825.6548075676
batch reward last col mean 0.006593507248908281 first col mean 2.3731322471576277e-06 all mean 0.0008153293747454882
0.0004991309833712876 0.0004991309833712876
rl training, epoch5, iter0, batch215/1133, batch loss:0.0004991309833712876, Training time:83844.26873517036
batch reward last col mean 1.1607456826823181e-06 first col mean 1.981814875762211e-06 all mean 1.047067235049326e-05
3.04791547023342e-06 3.0479136512440164e-06
rl training, epoch5, iter0, batch216/1133, batch loss:3.0479136512440164e-06, Training time:83861.02476263046
batch reward last col mean 1.114605493057752e-05 first col mean 8.033478479774203e-06 all mean 2.8617461794056e-05
2.0470713934628293e-05 2.0470713934628293e-05
rl training, epoch5, iter0, batch217/1133, batch loss:2.0470713934628293e-05, Training time:83877.90201115608
batch reward last col mean 1.870098913059337e-06 first col mean 0.0003590233391150832 all mean 3.524582280078903e-05
6.073746135371039e-06 6.073755230318056e-06
rl training, epoch5, iter0, batch218/1133, batch loss:6.073755230318056e-06, Training time:83894.64319777489
batch reward last col mean 3.5758494050242007e-06 first col mean 4.822119080927223e-05 all mean 1.615310065972153e-05
7.977103450684808e-06 7.97710436017951e-06
rl training, epoch5, iter0, batch219/1133, batch loss:7.97710436017951e-06, Training time:83911.47514009476
batch reward last col mean 2.7280734684609342e-06 first col mean 2.481567753420677e-05 all mean 1.5118976989469957e-05
4.147508207097417e-06 4.147508661844768e-06
rl training, epoch5, iter0, batch220/1133, batch loss:4.147508661844768e-06, Training time:83928.18605995178
batch reward last col mean 1.536255695100408e-06 first col mean 6.032526584931475e-07 all mean 7.292233931366354e-06
5.070935003459454e-06 5.070936367701506e-06
rl training, epoch5, iter0, batch221/1133, batch loss:5.070936367701506e-06, Training time:83945.1003639698
batch reward last col mean 1.2255593446752755e-06 first col mean 1.1027563232346438e-05 all mean 2.1126361389178783e-05
5.706380306946812e-06 5.706382125936216e-06
rl training, epoch5, iter0, batch222/1133, batch loss:5.706382125936216e-06, Training time:83963.52569890022
batch reward last col mean 3.133072823402472e-05 first col mean 1.2331925063335802e-06 all mean 9.56768144533271e-06
4.737047220260138e-06 4.737047220260138e-06
rl training, epoch5, iter0, batch223/1133, batch loss:4.737047220260138e-06, Training time:83982.2366476059
batch reward last col mean 0.00046639476204290986 first col mean 1.390337729390012e-06 all mean 4.873264697380364e-05
5.3490428399527445e-05 5.349041384761222e-05
rl training, epoch5, iter0, batch224/1133, batch loss:5.349041384761222e-05, Training time:84000.86105632782
batch reward last col mean 9.200868589687161e-06 first col mean 6.702549626425025e-07 all mean 1.0285762073181104e-05
5.470066298585152e-06 5.4700653890904505e-06
rl training, epoch5, iter0, batch225/1133, batch loss:5.4700653890904505e-06, Training time:84017.7501938343
batch reward last col mean 1.957525228135637e-06 first col mean 9.218867944582598e-07 all mean 2.074026269838214e-05
1.1422283023421187e-05 1.142228484241059e-05
rl training, epoch5, iter0, batch226/1133, batch loss:1.142228484241059e-05, Training time:84036.28259897232
batch reward last col mean 2.968873013742268e-05 first col mean 1.765393426467199e-05 all mean 4.912863005301915e-05
2.8303593353484757e-05 2.8303593353484757e-05
rl training, epoch5, iter0, batch227/1133, batch loss:2.8303593353484757e-05, Training time:84053.15291213989
batch reward last col mean 8.60390173329506e-06 first col mean 0.00019327184418216348 all mean 4.346875721239485e-05
3.858155832858756e-05 3.8581565604545176e-05
rl training, epoch5, iter0, batch228/1133, batch loss:3.8581565604545176e-05, Training time:84069.85975766182
batch reward last col mean 2.5161198209389113e-06 first col mean 9.495341146248393e-06 all mean 2.4444792870781384e-05
3.760382969630882e-05 3.7603826058330014e-05
rl training, epoch5, iter0, batch229/1133, batch loss:3.7603826058330014e-05, Training time:84086.67792057991
batch reward last col mean 3.709088559844531e-06 first col mean 1.058938323694747e-05 all mean 5.368909478420392e-05
1.9183695258107036e-05 1.9183689801138826e-05
rl training, epoch5, iter0, batch230/1133, batch loss:1.9183689801138826e-05, Training time:84103.49855589867
batch reward last col mean 2.016318603637046e-06 first col mean 8.84133100953477e-07 all mean 2.7531583327800035e-05
8.861017704475671e-06 8.861029527906794e-06
rl training, epoch5, iter0, batch231/1133, batch loss:8.861029527906794e-06, Training time:84122.17626476288
batch reward last col mean 5.4950746743998025e-06 first col mean 6.2508379414794035e-06 all mean 4.7529421863146126e-05
3.5879071219824255e-05 3.587907849578187e-05
rl training, epoch5, iter0, batch232/1133, batch loss:3.587907849578187e-05, Training time:84139.4733042717
batch reward last col mean 4.634967808669899e-06 first col mean 2.37367203226313e-06 all mean 2.6429434001329355e-05
2.464539102220442e-05 2.4645392841193825e-05
rl training, epoch5, iter0, batch233/1133, batch loss:2.4645392841193825e-05, Training time:84158.15694880486
batch reward last col mean 9.348441381007433e-05 first col mean 5.337085895007476e-06 all mean 5.543283623410389e-05
1.666836760705337e-05 1.6668371245032176e-05
rl training, epoch5, iter0, batch234/1133, batch loss:1.6668371245032176e-05, Training time:84175.03745365143
batch reward last col mean 0.00022583799727726728 first col mean 6.490754458354786e-06 all mean 8.134324161801487e-06
9.637142284191214e-06 9.637141374696512e-06
rl training, epoch5, iter0, batch235/1133, batch loss:9.637141374696512e-06, Training time:84193.70092129707
batch reward last col mean 3.7581096421490656e-06 first col mean 8.063434506766498e-06 all mean 4.6835350076435134e-05
9.738022527017165e-06 9.738017979543656e-06
rl training, epoch5, iter0, batch236/1133, batch loss:9.738017979543656e-06, Training time:84210.4137339592
batch reward last col mean 1.7600034425413469e-06 first col mean 1.7974055026570568e-06 all mean 2.4403716452070512e-05
1.3969448446005117e-05 1.3969445717521012e-05
rl training, epoch5, iter0, batch237/1133, batch loss:1.3969445717521012e-05, Training time:84227.30133843422
batch reward last col mean 1.2544911442091689e-05 first col mean 3.2408283004770055e-05 all mean 8.520598385075573e-06
3.888564151566243e-06 3.888563696818892e-06
rl training, epoch5, iter0, batch238/1133, batch loss:3.888563696818892e-06, Training time:84245.97396564484
batch reward last col mean 0.0012411326169967651 first col mean 2.2040521798771806e-06 all mean 6.57289638184011e-05
3.3904525480465963e-05 3.3904521842487156e-05
rl training, epoch5, iter0, batch239/1133, batch loss:3.3904521842487156e-05, Training time:84264.36417794228
batch reward last col mean 3.9004289646982215e-06 first col mean 2.088992732751649e-05 all mean 1.2892179256596137e-05
4.6215915062930435e-05 4.621590778697282e-05
rl training, epoch5, iter0, batch240/1133, batch loss:4.621590778697282e-05, Training time:84281.15385556221
batch reward last col mean 7.750514669169206e-06 first col mean 1.5539882951998152e-05 all mean 7.763444955344312e-06
7.054366506054066e-06 7.054365596559364e-06
rl training, epoch5, iter0, batch241/1133, batch loss:7.054365596559364e-06, Training time:84298.04853391647
batch reward last col mean 7.135967462090775e-05 first col mean 7.316322353290161e-06 all mean 4.875535887549631e-05
1.5396692106151022e-05 1.539669574412983e-05
rl training, epoch5, iter0, batch242/1133, batch loss:1.539669574412983e-05, Training time:84316.64723563194
batch reward last col mean 1.2447590961528476e-05 first col mean 1.8822045149136102e-06 all mean 4.679426638176665e-05
1.1249194358242676e-05 1.1249209819652606e-05
rl training, epoch5, iter0, batch243/1133, batch loss:1.1249209819652606e-05, Training time:84335.26357936859
batch reward last col mean 6.07789697824046e-05 first col mean 8.712443104741396e-07 all mean 3.4766781027428806e-05
1.3487626347341575e-05 1.3487627256836277e-05
rl training, epoch5, iter0, batch244/1133, batch loss:1.3487627256836277e-05, Training time:84352.03116488457
batch reward last col mean 4.037749931740109e-06 first col mean 2.6913667170447297e-06 all mean 2.272758683830034e-05
1.2704589607892558e-05 1.2704591426881962e-05
rl training, epoch5, iter0, batch245/1133, batch loss:1.2704591426881962e-05, Training time:84368.84379458427
batch reward last col mean 2.4050925276242197e-05 first col mean 5.42234147360432e-06 all mean 1.2217021321703214e-05
9.032108209794387e-06 9.032108209794387e-06
rl training, epoch5, iter0, batch246/1133, batch loss:9.032108209794387e-06, Training time:84385.66448044777
batch reward last col mean 2.508789066268946e-06 first col mean 2.7480049539008178e-05 all mean 1.8235134120914154e-05
7.134637598937843e-06 7.1346357799484394e-06
rl training, epoch5, iter0, batch247/1133, batch loss:7.1346357799484394e-06, Training time:84402.68884944916
batch reward last col mean 3.3362146041326923e-06 first col mean 3.7276436160027515e-06 all mean 2.4586362997069955e-05
1.150297248386778e-05 1.1502974302857183e-05
rl training, epoch5, iter0, batch248/1133, batch loss:1.1502974302857183e-05, Training time:84419.67585206032
batch reward last col mean 1.6888774325707345e-06 first col mean 1.6568023056606762e-05 all mean 4.717639967566356e-05
5.118276385474019e-05 5.118276021676138e-05
rl training, epoch5, iter0, batch249/1133, batch loss:5.118276021676138e-05, Training time:84436.80639982224
batch reward last col mean 1.5104965314094443e-06 first col mean 1.5479523653993965e-06 all mean 9.111717190535273e-06
3.1311535622080555e-06 3.13115583594481e-06
rl training, epoch5, iter0, batch250/1133, batch loss:3.13115583594481e-06, Training time:84453.74358725548
batch reward last col mean 1.2311676982790232e-05 first col mean 1.7501772617833922e-06 all mean 2.4254217350971885e-05
1.170370069303317e-05 1.1703697964549065e-05
rl training, epoch5, iter0, batch251/1133, batch loss:1.1703697964549065e-05, Training time:84472.47794985771
batch reward last col mean 3.8796092667325865e-06 first col mean 5.393662831920665e-06 all mean 1.526919731986709e-05
1.043972406478133e-05 1.0439723155286629e-05
rl training, epoch5, iter0, batch252/1133, batch loss:1.0439723155286629e-05, Training time:84489.19098734856
batch reward last col mean 9.397222129337024e-06 first col mean 4.338503458711784e-06 all mean 2.3094689822755754e-05
1.0719656529545318e-05 1.0719656529545318e-05
rl training, epoch5, iter0, batch253/1133, batch loss:1.0719656529545318e-05, Training time:84506.02565813065
batch reward last col mean 7.706651558692101e-06 first col mean 1.698229198154877e-06 all mean 1.7449387087253854e-05
4.180808900855482e-06 4.180808446108131e-06
rl training, epoch5, iter0, batch254/1133, batch loss:4.180808446108131e-06, Training time:84522.59715437889
batch reward last col mean 1.5686941878811922e-06 first col mean 3.957119133701781e-06 all mean 1.229111512657255e-05
6.460888471337967e-06 6.460889380832668e-06
rl training, epoch5, iter0, batch255/1133, batch loss:6.460889380832668e-06, Training time:84539.40218877792
batch reward last col mean 1.145492660725722e-06 first col mean 4.901683496427722e-06 all mean 2.11789520108141e-05
1.0305096111551393e-05 1.0305098840035498e-05
rl training, epoch5, iter0, batch256/1133, batch loss:1.0305098840035498e-05, Training time:84558.07578158379
batch reward last col mean 4.3549494876060635e-05 first col mean 2.6390380298835225e-05 all mean 3.21086154144723e-05
1.5005789464339614e-05 1.5005791283329017e-05
rl training, epoch5, iter0, batch257/1133, batch loss:1.5005791283329017e-05, Training time:84576.53417110443
batch reward last col mean 6.791356668145454e-07 first col mean 3.0032547329028603e-06 all mean 8.799286661087535e-06
2.882946091631311e-06 2.8829479106207145e-06
rl training, epoch5, iter0, batch258/1133, batch loss:2.8829479106207145e-06, Training time:84593.86154699326
batch reward last col mean 1.8647921024239622e-05 first col mean 4.1614393921918236e-06 all mean 9.820986633712891e-06
4.809368874703068e-06 4.809368874703068e-06
rl training, epoch5, iter0, batch259/1133, batch loss:4.809368874703068e-06, Training time:84612.31671667099
batch reward last col mean 6.524820946651744e-06 first col mean 5.495251116371946e-06 all mean 4.429407636052929e-05
4.368714871816337e-05 4.368713780422695e-05
rl training, epoch5, iter0, batch260/1133, batch loss:4.368713780422695e-05, Training time:84629.75372028351
batch reward last col mean 0.002027538837864995 first col mean 3.045955281777424e-06 all mean 0.000254507118370384
4.540293957688846e-05 4.540293957688846e-05
rl training, epoch5, iter0, batch261/1133, batch loss:4.540293957688846e-05, Training time:84648.27340126038
batch reward last col mean 7.905805432528723e-06 first col mean 4.590925891534425e-05 all mean 2.761108407867141e-05
1.3636573385156225e-05 1.3636572475661524e-05
rl training, epoch5, iter0, batch262/1133, batch loss:1.3636572475661524e-05, Training time:84665.12141036987
batch reward last col mean 5.454666052173707e-07 first col mean 3.057743469980778e-06 all mean 1.6238438547588885e-05
3.912351985491114e-06 3.912349257007008e-06
rl training, epoch5, iter0, batch263/1133, batch loss:3.912349257007008e-06, Training time:84681.93724226952
batch reward last col mean 4.74843682241044e-06 first col mean 6.108842353569344e-05 all mean 2.3767261154716834e-05
1.0715520147641655e-05 1.0715520147641655e-05
rl training, epoch5, iter0, batch264/1133, batch loss:1.0715520147641655e-05, Training time:84698.86920380592
batch reward last col mean 2.5591152734705247e-05 first col mean 3.086429842369398e-06 all mean 5.68647519685328e-05
1.2112655895180069e-05 1.211266135214828e-05
rl training, epoch5, iter0, batch265/1133, batch loss:1.211266135214828e-05, Training time:84715.97617769241
batch reward last col mean 3.474983532214537e-05 first col mean 7.212025593617e-06 all mean 1.573912777530495e-05
6.576283794856863e-06 6.576282885362161e-06
rl training, epoch5, iter0, batch266/1133, batch loss:6.576282885362161e-06, Training time:84732.97546863556
batch reward last col mean 7.292647933354601e-05 first col mean 1.3885371572541771e-06 all mean 2.241980291728396e-05
2.2153082682052627e-05 2.215307904407382e-05
rl training, epoch5, iter0, batch267/1133, batch loss:2.215307904407382e-05, Training time:84749.59291601181
batch reward last col mean 1.6525205865036696e-05 first col mean 5.090651029604487e-06 all mean 1.975177656277083e-05
5.806998615298653e-06 5.806993613077793e-06
rl training, epoch5, iter0, batch268/1133, batch loss:5.806993613077793e-06, Training time:84766.31068348885
batch reward last col mean 7.18833052815171e-06 first col mean 7.784761692164466e-05 all mean 7.733894562989008e-06
4.679056473833043e-06 4.679055564338341e-06
rl training, epoch5, iter0, batch269/1133, batch loss:4.679055564338341e-06, Training time:84784.50903534889
batch reward last col mean 4.717952833743766e-06 first col mean 1.757081463438226e-06 all mean 4.853351856581867e-05
7.425560761475936e-05 7.425560761475936e-05
rl training, epoch5, iter0, batch270/1133, batch loss:7.425560761475936e-05, Training time:84801.29699063301
batch reward last col mean 0.00022558709315489978 first col mean 2.0408026557561243e-06 all mean 3.3674983569653705e-05
3.037407441297546e-05 3.0374081688933074e-05
rl training, epoch5, iter0, batch271/1133, batch loss:3.0374081688933074e-05, Training time:84818.08704686165
batch reward last col mean 2.09714721677301e-06 first col mean 1.27905877889134e-06 all mean 8.76801732374588e-06
7.061315500322962e-06 7.06131459082826e-06
rl training, epoch5, iter0, batch272/1133, batch loss:7.06131459082826e-06, Training time:84835.22986531258
batch reward last col mean 4.879554580838885e-06 first col mean 3.4876002246164717e-06 all mean 9.534883247397374e-06
4.960083060723264e-06 4.9600839702179655e-06
rl training, epoch5, iter0, batch273/1133, batch loss:4.9600839702179655e-06, Training time:84853.81839156151
batch reward last col mean 3.600553554861108e-06 first col mean 3.1175127332971897e-06 all mean 1.56974474521121e-05
3.7949239413137548e-06 3.794918484345544e-06
rl training, epoch5, iter0, batch274/1133, batch loss:3.794918484345544e-06, Training time:84872.37353897095
batch reward last col mean 1.2334501207078574e-06 first col mean 1.3919225239078514e-06 all mean 1.9549437638488598e-05
2.703130303416401e-05 2.7031301215174608e-05
rl training, epoch5, iter0, batch275/1133, batch loss:2.7031301215174608e-05, Training time:84890.86837720871
batch reward last col mean 1.2188050959593966e-06 first col mean 1.3014943760936148e-05 all mean 2.31685844482854e-05
5.284658254822716e-05 5.284658254822716e-05
rl training, epoch5, iter0, batch276/1133, batch loss:5.284658254822716e-05, Training time:84908.65735697746
batch reward last col mean 1.8461729496266344e-06 first col mean 4.388483830553014e-06 all mean 4.148032530792989e-05
3.2920175726758316e-05 3.2920175726758316e-05
rl training, epoch5, iter0, batch277/1133, batch loss:3.2920175726758316e-05, Training time:84926.80123281479
batch reward last col mean 1.5126357538974844e-05 first col mean 8.94010463525774e-06 all mean 7.842978811822832e-05
1.1784008165705018e-05 1.1784007256210316e-05
rl training, epoch5, iter0, batch278/1133, batch loss:1.1784007256210316e-05, Training time:84945.19645428658
batch reward last col mean 4.787114903592737e-06 first col mean 1.472645408284734e-06 all mean 9.544884960632771e-06
5.209951268625446e-06 5.209951268625446e-06
rl training, epoch5, iter0, batch279/1133, batch loss:5.209951268625446e-06, Training time:84963.80906653404
batch reward last col mean 2.1745920548710274e-06 first col mean 3.796873897954356e-06 all mean 3.2010197173804045e-05
9.454462997382507e-06 9.454458449908998e-06
rl training, epoch5, iter0, batch280/1133, batch loss:9.454458449908998e-06, Training time:84982.56743621826
batch reward last col mean 0.00015670947323087603 first col mean 8.685762622917537e-06 all mean 2.3360660634352826e-05
1.6772562958067283e-05 1.6772564777056687e-05
rl training, epoch5, iter0, batch281/1133, batch loss:1.6772564777056687e-05, Training time:84999.40067243576
batch reward last col mean 6.292175385169685e-06 first col mean 3.468758222879842e-06 all mean 3.143307912978344e-05
2.4262384613393806e-05 2.4262380975415e-05
rl training, epoch5, iter0, batch282/1133, batch loss:2.4262380975415e-05, Training time:85016.32705020905
batch reward last col mean 2.8237263904884458e-05 first col mean 4.008395535493037e-06 all mean 1.376734689984005e-05
2.3347261958406307e-05 2.3347261958406307e-05
rl training, epoch5, iter0, batch283/1133, batch loss:2.3347261958406307e-05, Training time:85033.23445534706
batch reward last col mean 0.006280773784965277 first col mean 9.44478961173445e-06 all mean 0.0013441462069749832
0.0002107413311023265 0.00021074131655041128
rl training, epoch5, iter0, batch284/1133, batch loss:0.00021074131655041128, Training time:85052.05971598625
batch reward last col mean 1.646841724323167e-06 first col mean 1.4396625829249388e-06 all mean 1.2731969945889432e-05
2.866766408260446e-06 2.866764816644718e-06
rl training, epoch5, iter0, batch285/1133, batch loss:2.866764816644718e-06, Training time:85069.01525497437
batch reward last col mean 1.3702360774914268e-06 first col mean 2.4057558221102227e-06 all mean 7.620139058417408e-06
3.2650798402755754e-06 3.265076657044119e-06
rl training, epoch5, iter0, batch286/1133, batch loss:3.265076657044119e-06, Training time:85086.02003335953
batch reward last col mean 8.366112069779774e-07 first col mean 7.921245924080722e-06 all mean 1.3461724847729784e-05
3.744595005628071e-06 3.74459455088072e-06
rl training, epoch5, iter0, batch287/1133, batch loss:3.74459455088072e-06, Training time:85103.05820727348
batch reward last col mean 2.751922693278175e-06 first col mean 4.569759767036885e-06 all mean 2.7978550861007534e-05
6.55628609820269e-05 6.556285370606929e-05
rl training, epoch5, iter0, batch288/1133, batch loss:6.556285370606929e-05, Training time:85119.95758771896
batch reward last col mean 8.300160516228061e-06 first col mean 5.5396494644810446e-06 all mean 1.9684954168042168e-05
9.928917279466987e-06 9.92891364148818e-06
rl training, epoch5, iter0, batch289/1133, batch loss:9.92891364148818e-06, Training time:85136.79684710503
batch reward last col mean 0.00012143715866841376 first col mean 1.0371380994911306e-05 all mean 2.9514818379539065e-05
2.0959825633326545e-05 2.0959829271305352e-05
rl training, epoch5, iter0, batch290/1133, batch loss:2.0959829271305352e-05, Training time:85153.63708806038
batch reward last col mean 1.167080995401193e-06 first col mean 3.179173745593289e-06 all mean 1.5474279280169867e-05
5.951430921413703e-06 5.9514286476769485e-06
rl training, epoch5, iter0, batch291/1133, batch loss:5.9514286476769485e-06, Training time:85171.90100979805
batch reward last col mean 1.1140582500956953e-06 first col mean 6.633861630689353e-06 all mean 1.704592796158977e-05
6.237826255528489e-06 6.237823527044384e-06
rl training, epoch5, iter0, batch292/1133, batch loss:6.237823527044384e-06, Training time:85188.83129906654
batch reward last col mean 8.457945455120353e-07 first col mean 5.908132152399048e-07 all mean 2.3622027583769523e-05
1.0299732821295038e-05 1.0299730092810933e-05
rl training, epoch5, iter0, batch293/1133, batch loss:1.0299730092810933e-05, Training time:85206.2562391758
batch reward last col mean 0.00029208511114120483 first col mean 1.4571385236195056e-06 all mean 0.00013435482105705887
2.0509132809820585e-05 2.0509138266788796e-05
rl training, epoch5, iter0, batch294/1133, batch loss:2.0509138266788796e-05, Training time:85223.00978016853
batch reward last col mean 8.664713277539704e-06 first col mean 1.5956591141730314e-06 all mean 4.1805276850936934e-05
2.5895898943417706e-05 2.58958953054389e-05
rl training, epoch5, iter0, batch295/1133, batch loss:2.58958953054389e-05, Training time:85239.92665743828
batch reward last col mean 2.387701897532679e-06 first col mean 1.1043242693631328e-06 all mean 1.6459587641293183e-05
6.296786068560323e-06 6.29678470431827e-06
rl training, epoch5, iter0, batch296/1133, batch loss:6.29678470431827e-06, Training time:85257.97019934654
batch reward last col mean 0.005027468781918287 first col mean 9.629500254959567e-07 all mean 0.000769446138292551
0.00015530158998444676 0.00015530157543253154
rl training, epoch5, iter0, batch297/1133, batch loss:0.00015530157543253154, Training time:85274.76300024986
batch reward last col mean 1.2616580988833448e-06 first col mean 2.3283906557480805e-05 all mean 2.3564707589684986e-05
1.2268837053852621e-05 1.2268835234863218e-05
rl training, epoch5, iter0, batch298/1133, batch loss:1.2268835234863218e-05, Training time:85293.83122992516
batch reward last col mean 6.9679344960604794e-06 first col mean 4.527585133473622e-06 all mean 5.154860991751775e-05
2.4928156562964432e-05 2.4928158381953835e-05
rl training, epoch5, iter0, batch299/1133, batch loss:2.4928158381953835e-05, Training time:85310.770611763
batch reward last col mean 4.029252522741444e-06 first col mean 7.352235115831718e-06 all mean 3.274109258200042e-05
2.275216502312105e-05 2.275216502312105e-05
rl training, epoch5, iter0, batch300/1133, batch loss:2.275216502312105e-05, Training time:85329.06183815002
batch reward last col mean 3.52123606717214e-05 first col mean 3.7840145523659885e-06 all mean 2.220496753579937e-05
8.88691283762455e-06 8.88691283762455e-06
rl training, epoch5, iter0, batch301/1133, batch loss:8.88691283762455e-06, Training time:85346.06880664825
batch reward last col mean 0.0010255714878439903 first col mean 2.7737009077100083e-05 all mean 0.0004112290625926107
2.0061514078406617e-05 2.006151589739602e-05
rl training, epoch5, iter0, batch302/1133, batch loss:2.006151589739602e-05, Training time:85363.109333992
batch reward last col mean 2.4996088541229255e-06 first col mean 1.0671717973309569e-05 all mean 1.2901590707770083e-05
2.694087243071408e-06 2.6940870156977326e-06
rl training, epoch5, iter0, batch303/1133, batch loss:2.6940870156977326e-06, Training time:85380.1270172596
batch reward last col mean 1.275831323255261e-06 first col mean 5.493559001479298e-06 all mean 2.059119833575096e-05
3.909111910616048e-05 3.909111910616048e-05
rl training, epoch5, iter0, batch304/1133, batch loss:3.909111910616048e-05, Training time:85397.0611383915
batch reward last col mean 6.730788300046697e-07 first col mean 3.3490662190160947e-06 all mean 4.552451355266385e-05
8.523546057404019e-06 8.52355151437223e-06
rl training, epoch5, iter0, batch305/1133, batch loss:8.52355151437223e-06, Training time:85413.93141460419
batch reward last col mean 2.5296383228123887e-06 first col mean 2.5476472274021944e-06 all mean 1.9557757696020417e-05
4.984905899618752e-06 4.984902716387296e-06
rl training, epoch5, iter0, batch306/1133, batch loss:4.984902716387296e-06, Training time:85430.90982174873
batch reward last col mean 3.410156296013156e-06 first col mean 4.865923256147653e-05 all mean 1.7620805010665208e-05
9.201295142702293e-06 9.201294233207591e-06
rl training, epoch5, iter0, batch307/1133, batch loss:9.201294233207591e-06, Training time:85447.74408650398
batch reward last col mean 5.479984793055337e-06 first col mean 2.898597449529916e-05 all mean 4.070401701028459e-05
8.178649295587093e-05 8.178648567991331e-05
rl training, epoch5, iter0, batch308/1133, batch loss:8.178648567991331e-05, Training time:85466.13228440285
batch reward last col mean 4.640456609195098e-06 first col mean 1.2422060535755008e-06 all mean 2.5283266950282268e-05
8.494376743328758e-06 8.494382200296968e-06
rl training, epoch5, iter0, batch309/1133, batch loss:8.494382200296968e-06, Training time:85482.98783802986
batch reward last col mean 7.4666045293270145e-06 first col mean 0.00011702624760800973 all mean 6.486985512310639e-05
3.187370748491958e-05 3.1873700208961964e-05
rl training, epoch5, iter0, batch310/1133, batch loss:3.1873700208961964e-05, Training time:85499.79385709763
batch reward last col mean 0.0002472961787134409 first col mean 9.778873209143057e-05 all mean 6.0461450630100444e-05
3.608359838835895e-05 3.6083605664316565e-05
rl training, epoch5, iter0, batch311/1133, batch loss:3.6083605664316565e-05, Training time:85517.14758324623
batch reward last col mean 8.15461407910334e-06 first col mean 5.481655080075143e-06 all mean 3.559646211215295e-05
6.570779078174382e-05 6.570779078174382e-05
rl training, epoch5, iter0, batch312/1133, batch loss:6.570779078174382e-05, Training time:85533.77771759033
batch reward last col mean 4.097332748642657e-06 first col mean 3.911508429155219e-06 all mean 3.229592402931303e-05
9.190745004161727e-06 9.19074136618292e-06
rl training, epoch5, iter0, batch313/1133, batch loss:9.19074136618292e-06, Training time:85550.54913401604
batch reward last col mean 3.1062252219271613e-06 first col mean 3.9411070247297175e-06 all mean 4.8717341996962205e-05
4.1286290070274845e-05 4.1286290070274845e-05
rl training, epoch5, iter0, batch314/1133, batch loss:4.1286290070274845e-05, Training time:85567.2290225029
batch reward last col mean 1.3411419104158995e-06 first col mean 8.327575642397278e-07 all mean 1.0466575076861773e-05
3.688390279421583e-06 3.688390961542609e-06
rl training, epoch5, iter0, batch315/1133, batch loss:3.688390961542609e-06, Training time:85585.13514494896
batch reward last col mean 1.4086017472436652e-05 first col mean 4.7964667828637175e-06 all mean 1.6134081306518055e-05
1.595544017618522e-05 1.5955443814164028e-05
rl training, epoch5, iter0, batch316/1133, batch loss:1.5955443814164028e-05, Training time:85602.19909095764
batch reward last col mean 6.934175871720072e-06 first col mean 7.568715432171302e-07 all mean 4.0291073673870414e-05
6.3105453591560945e-06 6.310546723398147e-06
rl training, epoch5, iter0, batch317/1133, batch loss:6.310546723398147e-06, Training time:85619.2420501709
batch reward last col mean 2.961983000204782e-06 first col mean 0.0002859078231267631 all mean 2.534696068323683e-05
8.755311682762112e-06 8.755314411246218e-06
rl training, epoch5, iter0, batch318/1133, batch loss:8.755314411246218e-06, Training time:85636.31682658195
batch reward last col mean 9.175408308692568e-07 first col mean 1.4739549442310818e-05 all mean 2.5225963327102363e-05
1.1815138350357302e-05 1.1815144716820214e-05
rl training, epoch5, iter0, batch319/1133, batch loss:1.1815144716820214e-05, Training time:85653.39133405685
batch reward last col mean 3.471028321655467e-06 first col mean 2.9367297429416794e-06 all mean 3.593898145481944e-05
9.184105692838784e-06 9.184105692838784e-06
rl training, epoch5, iter0, batch320/1133, batch loss:9.184105692838784e-06, Training time:85670.44316005707
batch reward last col mean 4.6463273974950425e-06 first col mean 5.087904355605133e-07 all mean 1.4958954125177115e-05
4.301864464650862e-06 4.301865828892915e-06
rl training, epoch5, iter0, batch321/1133, batch loss:4.301865828892915e-06, Training time:85687.37457942963
batch reward last col mean 0.00012862708535976708 first col mean 8.568216571802623e-07 all mean 7.2783145697030704e-06
1.0929592463071458e-05 1.092959337256616e-05
rl training, epoch5, iter0, batch322/1133, batch loss:1.092959337256616e-05, Training time:85704.35660672188
batch reward last col mean 2.0981364286853932e-05 first col mean 8.824781616567634e-06 all mean 1.8005290257860906e-05
8.83623943082057e-06 8.836235792841762e-06
rl training, epoch5, iter0, batch323/1133, batch loss:8.836235792841762e-06, Training time:85721.59106373787
batch reward last col mean 3.3943862945307046e-05 first col mean 3.7196343328105286e-05 all mean 1.5254855497914832e-05
8.19308388599893e-06 8.193084795493633e-06
rl training, epoch5, iter0, batch324/1133, batch loss:8.193084795493633e-06, Training time:85738.85531949997
batch reward last col mean 4.223682935844408e-06 first col mean 2.1846958588866983e-06 all mean 2.581265835033264e-05
1.1118177098978776e-05 1.111817346099997e-05
rl training, epoch5, iter0, batch325/1133, batch loss:1.111817346099997e-05, Training time:85756.37023329735
batch reward last col mean 3.1882159419183154e-06 first col mean 2.0949499230482616e-05 all mean 1.4102679415373132e-05
5.135842911840882e-06 5.13584200234618e-06
rl training, epoch5, iter0, batch326/1133, batch loss:5.13584200234618e-06, Training time:85774.3576476574
batch reward last col mean 3.8219768612179905e-06 first col mean 2.52475274464814e-06 all mean 1.917273948492948e-05
4.437029019754846e-06 4.437024472281337e-06
rl training, epoch5, iter0, batch327/1133, batch loss:4.437024472281337e-06, Training time:85792.758852005
batch reward last col mean 9.182924259221181e-06 first col mean 3.195183126081247e-06 all mean 1.1755903869925532e-05
1.7937010852620006e-05 1.7937010852620006e-05
rl training, epoch5, iter0, batch328/1133, batch loss:1.7937010852620006e-05, Training time:85811.4816558361
batch reward last col mean 1.3364887308853213e-05 first col mean 5.543224688153714e-06 all mean 5.4908974561840296e-05
7.77096465753857e-06 7.770960110065062e-06
rl training, epoch5, iter0, batch329/1133, batch loss:7.770960110065062e-06, Training time:85830.43301916122
batch reward last col mean 1.5268691413439228e-06 first col mean 6.209187176864361e-06 all mean 2.6082518161274493e-05
1.7122320059570484e-05 1.7122316421591677e-05
rl training, epoch5, iter0, batch330/1133, batch loss:1.7122316421591677e-05, Training time:85848.66081595421
batch reward last col mean 2.710304897846072e-06 first col mean 3.4298354876227677e-06 all mean 1.965103183465544e-05
5.419647095550317e-06 5.419645731308265e-06
rl training, epoch5, iter0, batch331/1133, batch loss:5.419645731308265e-06, Training time:85867.53336811066
batch reward last col mean 0.0004553484031930566 first col mean 5.122819402458845e-06 all mean 4.78265828860458e-05
3.479409497231245e-05 3.479408405837603e-05
rl training, epoch5, iter0, batch332/1133, batch loss:3.479408405837603e-05, Training time:85885.91612648964
batch reward last col mean 2.6405225071357563e-05 first col mean 1.7678801668807864e-05 all mean 2.180442970711738e-05
3.164010922773741e-05 3.164010922773741e-05
rl training, epoch5, iter0, batch333/1133, batch loss:3.164010922773741e-05, Training time:85903.14898324013
batch reward last col mean 1.207236664413358e-06 first col mean 3.5045959521085024e-06 all mean 2.9291868486325257e-05
7.069003004289698e-06 7.06899891156354e-06
rl training, epoch5, iter0, batch334/1133, batch loss:7.06899891156354e-06, Training time:85920.24393439293
batch reward last col mean 5.659389330503473e-07 first col mean 1.482627908444556e-06 all mean 2.620892701088451e-05
8.662627806188539e-06 8.662624168209732e-06
rl training, epoch5, iter0, batch335/1133, batch loss:8.662624168209732e-06, Training time:85937.58115816116
batch reward last col mean 9.082220458367374e-06 first col mean 4.263321898179129e-06 all mean 3.6785750126000494e-05
1.7901202227221802e-05 1.7901194951264188e-05
rl training, epoch5, iter0, batch336/1133, batch loss:1.7901194951264188e-05, Training time:85954.72487831116
batch reward last col mean 2.931714516307693e-05 first col mean 1.6055340665843687e-06 all mean 1.0234294677502476e-05
4.79606296721613e-06 4.796063876710832e-06
rl training, epoch5, iter0, batch337/1133, batch loss:4.796063876710832e-06, Training time:85971.86920285225
batch reward last col mean 7.287220341822831e-06 first col mean 9.672077794675715e-06 all mean 1.3626879081130028e-05
7.692206054343842e-06 7.692206054343842e-06
rl training, epoch5, iter0, batch338/1133, batch loss:7.692206054343842e-06, Training time:85989.13440012932
batch reward last col mean 1.6989819414447993e-05 first col mean 3.0501687433570623e-06 all mean 4.7001743951113895e-05
5.4423515393864363e-05 5.4423515393864363e-05
rl training, epoch5, iter0, batch339/1133, batch loss:5.4423515393864363e-05, Training time:86007.43130397797
batch reward last col mean 8.53539177114726e-07 first col mean 2.356801815039944e-06 all mean 1.3815600141242612e-05
1.5055047697387636e-05 1.5055046787892934e-05
rl training, epoch5, iter0, batch340/1133, batch loss:1.5055046787892934e-05, Training time:86027.31757307053
batch reward last col mean 2.949861027445877e-06 first col mean 2.5912936507666018e-06 all mean 2.6395864551886916e-05
6.341796961351065e-06 6.341804237308679e-06
rl training, epoch5, iter0, batch341/1133, batch loss:6.341804237308679e-06, Training time:86045.17069768906
batch reward last col mean 4.9586665227252524e-06 first col mean 2.902109827118693e-06 all mean 9.494487130723428e-06
2.1404630388133228e-06 2.1404630388133228e-06
rl training, epoch5, iter0, batch342/1133, batch loss:2.1404630388133228e-06, Training time:86064.74239468575
batch reward last col mean 8.119409903883934e-05 first col mean 0.0002731392451096326 all mean 5.28469099663198e-05
9.043335012393072e-06 9.043333193403669e-06
rl training, epoch5, iter0, batch343/1133, batch loss:9.043333193403669e-06, Training time:86083.19598174095
batch reward last col mean 7.070130436659383e-07 first col mean 1.1903680388059001e-06 all mean 1.2156830962339882e-05
1.0775846931210253e-05 1.0775844202726148e-05
rl training, epoch5, iter0, batch344/1133, batch loss:1.0775844202726148e-05, Training time:86102.43868207932
batch reward last col mean 0.00018136025755666196 first col mean 2.4636647140141577e-06 all mean 6.0465175920398906e-05
4.601269029080868e-05 4.6012693928787485e-05
rl training, epoch5, iter0, batch345/1133, batch loss:4.6012693928787485e-05, Training time:86121.86086964607
batch reward last col mean 2.6967802114086226e-05 first col mean 2.864055204554461e-05 all mean 5.748408875660971e-05
5.136155232321471e-05 5.136155596119352e-05
rl training, epoch5, iter0, batch346/1133, batch loss:5.136155596119352e-05, Training time:86140.61351060867
batch reward last col mean 6.390182534232736e-06 first col mean 0.0003090287500526756 all mean 4.65413395431824e-05
1.8857474060496315e-05 1.8857483155443333e-05
rl training, epoch5, iter0, batch347/1133, batch loss:1.8857483155443333e-05, Training time:86157.72965741158
batch reward last col mean 1.116889279728639e-06 first col mean 5.713958216801984e-06 all mean 3.03950764646288e-05
8.179603355529252e-06 8.17959698906634e-06
rl training, epoch5, iter0, batch348/1133, batch loss:8.17959698906634e-06, Training time:86176.2333483696
batch reward last col mean 1.4818909903624444e-06 first col mean 7.11958500687615e-06 all mean 3.843858576146886e-05
6.376042620104272e-06 6.376048986567184e-06
rl training, epoch5, iter0, batch349/1133, batch loss:6.376048986567184e-06, Training time:86195.13060355186
batch reward last col mean 4.967263521393761e-06 first col mean 2.097589458571747e-06 all mean 2.986283288919367e-05
7.65778349887114e-06 7.657788046344649e-06
rl training, epoch5, iter0, batch350/1133, batch loss:7.657788046344649e-06, Training time:86212.26647949219
batch reward last col mean 1.1196926607226487e-05 first col mean 5.334336037776666e-06 all mean 1.615367909835186e-05
3.039455350517528e-06 3.0394523946597474e-06
rl training, epoch5, iter0, batch351/1133, batch loss:3.0394523946597474e-06, Training time:86229.35995721817
batch reward last col mean 0.00025462755002081394 first col mean 0.0005244997446425259 all mean 5.520951162907295e-05
5.283248901832849e-05 5.283248901832849e-05
rl training, epoch5, iter0, batch352/1133, batch loss:5.283248901832849e-05, Training time:86246.5356259346
batch reward last col mean 2.4935692636063322e-05 first col mean 6.575022780452855e-06 all mean 1.6284438970615156e-05
2.6745019567897543e-05 2.6745015929918736e-05
rl training, epoch5, iter0, batch353/1133, batch loss:2.6745015929918736e-05, Training time:86263.71127295494
batch reward last col mean 8.230950356846733e-07 first col mean 3.3274282031925395e-05 all mean 1.4151806681184098e-05
4.350107246864354e-06 4.350111794337863e-06
rl training, epoch5, iter0, batch354/1133, batch loss:4.350111794337863e-06, Training time:86281.94216918945
batch reward last col mean 7.920707503217272e-07 first col mean 3.468538852757774e-05 all mean 1.4501727491733618e-05
8.80259267432848e-06 8.802590855339076e-06
rl training, epoch5, iter0, batch355/1133, batch loss:8.802590855339076e-06, Training time:86301.29559707642
batch reward last col mean 0.00026036682538688183 first col mean 0.00014583131996914744 all mean 8.942681597545743e-05
6.053713150322437e-05 6.053713150322437e-05
rl training, epoch5, iter0, batch356/1133, batch loss:6.053713150322437e-05, Training time:86319.95328950882
batch reward last col mean 2.018262648562086e-06 first col mean 0.0001558070507599041 all mean 2.0797397155547515e-05
1.1093399734818377e-05 1.1093404282291885e-05
rl training, epoch5, iter0, batch357/1133, batch loss:1.1093404282291885e-05, Training time:86339.04811286926
batch reward last col mean 1.9306555714138085e-06 first col mean 3.5623006624518894e-06 all mean 1.2588948266056832e-05
6.408544322766829e-06 6.408542503777426e-06
rl training, epoch5, iter0, batch358/1133, batch loss:6.408542503777426e-06, Training time:86357.70246243477
batch reward last col mean 7.927835099508229e-07 first col mean 3.258244987591752e-06 all mean 2.0217052224325016e-05
4.04936472477857e-05 4.049365088576451e-05
rl training, epoch5, iter0, batch359/1133, batch loss:4.049365088576451e-05, Training time:86374.83702611923
batch reward last col mean 1.52706388689694e-06 first col mean 8.81599476088013e-07 all mean 3.2622610888211057e-05
4.067058853252092e-06 4.067056124767987e-06
rl training, epoch5, iter0, batch360/1133, batch loss:4.067056124767987e-06, Training time:86393.52946662903
batch reward last col mean 1.3426764780888334e-05 first col mean 1.1233944405830698e-06 all mean 1.6082818547147326e-05
1.2363551832095254e-05 1.2363549103611149e-05
rl training, epoch5, iter0, batch361/1133, batch loss:1.2363549103611149e-05, Training time:86411.59882092476
batch reward last col mean 2.0006027625640854e-06 first col mean 6.491914973594248e-06 all mean 4.0826133044902235e-05
1.6853196939337067e-05 1.6853196939337067e-05
rl training, epoch5, iter0, batch362/1133, batch loss:1.6853196939337067e-05, Training time:86430.45156908035
batch reward last col mean 4.8085148591781035e-05 first col mean 1.3590465641755145e-06 all mean 5.9038186009274796e-05
0.0001015250090858899 0.00010152499453397468
rl training, epoch5, iter0, batch363/1133, batch loss:0.00010152499453397468, Training time:86449.37373375893
batch reward last col mean 4.846336196351331e-06 first col mean 6.1382565945677925e-06 all mean 5.686544318450615e-05
2.0174544260953553e-05 2.0174549717921764e-05
rl training, epoch5, iter0, batch364/1133, batch loss:2.0174549717921764e-05, Training time:86467.3173532486
batch reward last col mean 2.064021373371361e-06 first col mean 2.8126564757258166e-06 all mean 3.92975598515477e-05
7.73057672631694e-06 7.730574907327536e-06
rl training, epoch5, iter0, batch365/1133, batch loss:7.730574907327536e-06, Training time:86486.02760577202
batch reward last col mean 1.851596380220144e-06 first col mean 0.0002275986917084083 all mean 6.673608004348353e-05
2.420219243504107e-05 2.4202190616051666e-05
rl training, epoch5, iter0, batch366/1133, batch loss:2.4202190616051666e-05, Training time:86503.06133437157
batch reward last col mean 4.668494057114003e-06 first col mean 9.80318759502552e-07 all mean 1.0159036719414871e-05
2.8096678761357907e-06 2.8096676487621153e-06
rl training, epoch5, iter0, batch367/1133, batch loss:2.8096676487621153e-06, Training time:86520.17258024216
batch reward last col mean 1.9756359961320413e-06 first col mean 2.628147967698169e-06 all mean 2.366931948927231e-05
6.544305051647825e-06 6.544304142153123e-06
rl training, epoch5, iter0, batch368/1133, batch loss:6.544304142153123e-06, Training time:86537.13044905663
batch reward last col mean 7.714908861089498e-06 first col mean 4.787943544215523e-05 all mean 2.308164221176412e-05
7.852438102418091e-06 7.852439011912793e-06
rl training, epoch5, iter0, batch369/1133, batch loss:7.852439011912793e-06, Training time:86555.23595094681
batch reward last col mean 4.5347915147431195e-06 first col mean 9.175670356853516e-07 all mean 2.9032875318080187e-05
1.4979463230702095e-05 1.4979465049691498e-05
rl training, epoch5, iter0, batch370/1133, batch loss:1.4979465049691498e-05, Training time:86574.13878655434
batch reward last col mean 3.505160566419363e-05 first col mean 2.0985701212339336e-06 all mean 4.489039565669373e-05
3.991414268966764e-05 3.991414268966764e-05
rl training, epoch5, iter0, batch371/1133, batch loss:3.991414268966764e-05, Training time:86591.74685525894
batch reward last col mean 4.770806299347896e-06 first col mean 5.767296443082159e-06 all mean 2.494709951861296e-05
5.624162895401241e-06 5.624154709948925e-06
rl training, epoch5, iter0, batch372/1133, batch loss:5.624154709948925e-06, Training time:86610.48412680626
batch reward last col mean 1.5633476095899823e-06 first col mean 6.099735401221551e-07 all mean 9.398962902196217e-06
6.048703653505072e-06 6.048703653505072e-06
rl training, epoch5, iter0, batch373/1133, batch loss:6.048703653505072e-06, Training time:86629.11070895195
batch reward last col mean 1.291878925258061e-05 first col mean 2.8099991595809115e-06 all mean 1.4718093552801292e-05
2.022070111706853e-05 2.022070111706853e-05
rl training, epoch5, iter0, batch374/1133, batch loss:2.022070111706853e-05, Training time:86647.99098801613
batch reward last col mean 3.017057679244317e-05 first col mean 1.1563060979824513e-06 all mean 3.1420186132891104e-05
2.124410639225971e-05 2.1244108211249113e-05
rl training, epoch5, iter0, batch375/1133, batch loss:2.1244108211249113e-05, Training time:86667.33935332298
batch reward last col mean 1.1325614650559146e-05 first col mean 6.868175205454463e-06 all mean 2.1995600036461838e-05
2.9393993827397935e-05 2.9393993827397935e-05
rl training, epoch5, iter0, batch376/1133, batch loss:2.9393993827397935e-05, Training time:86687.37701702118
batch reward last col mean 6.942270829313202e-07 first col mean 1.687701114860829e-06 all mean 3.01350919471588e-05
4.509362042881548e-06 4.509366135607706e-06
rl training, epoch5, iter0, batch377/1133, batch loss:4.509366135607706e-06, Training time:86705.65299630165
batch reward last col mean 2.988763662870042e-05 first col mean 2.9340831133595202e-06 all mean 1.2474488357838709e-05
8.83212032931624e-06 8.832122148305643e-06
rl training, epoch5, iter0, batch378/1133, batch loss:8.832122148305643e-06, Training time:86724.254499197
batch reward last col mean 5.152598419044807e-07 first col mean 6.2128747231327e-05 all mean 3.09766546706669e-05
1.0436292541271541e-05 1.0436292541271541e-05
rl training, epoch5, iter0, batch379/1133, batch loss:1.0436292541271541e-05, Training time:86741.4964621067
batch reward last col mean 1.380619892188406e-06 first col mean 1.4254379721023724e-06 all mean 1.0686321729735937e-05
9.246771696780343e-06 9.246771696780343e-06
rl training, epoch5, iter0, batch380/1133, batch loss:9.246771696780343e-06, Training time:86758.6203956604
batch reward last col mean 3.844885213766247e-05 first col mean 4.347087269707117e-06 all mean 1.835528928495478e-05
8.334558515343815e-06 8.33456124382792e-06
rl training, epoch5, iter0, batch381/1133, batch loss:8.33456124382792e-06, Training time:86777.01572847366
batch reward last col mean 5.375510227167979e-06 first col mean 2.040817435045028e-06 all mean 2.751546708168462e-05
1.8835333321476355e-05 1.8835329683497548e-05
rl training, epoch5, iter0, batch382/1133, batch loss:1.8835329683497548e-05, Training time:86794.16265511513
batch reward last col mean 1.2017433618893847e-05 first col mean 1.3331114132597577e-05 all mean 1.2711408999166451e-05
8.686278306413442e-06 8.686276487424038e-06
rl training, epoch5, iter0, batch383/1133, batch loss:8.686276487424038e-06, Training time:86811.17340612411
batch reward last col mean 1.6570832030993188e-06 first col mean 2.9613911465276033e-06 all mean 2.4182481865864247e-05
0.0001025459059746936 0.0001025459059746936
rl training, epoch5, iter0, batch384/1133, batch loss:0.0001025459059746936, Training time:86828.22689723969
batch reward last col mean 4.0787217585602775e-06 first col mean 1.59838491526898e-05 all mean 5.80193373025395e-05
2.5018280211952515e-05 2.5018294763867743e-05
rl training, epoch5, iter0, batch385/1133, batch loss:2.5018294763867743e-05, Training time:86846.62707591057
batch reward last col mean 9.805877425606013e-07 first col mean 6.991720056248596e-06 all mean 8.780023199506104e-05
3.965479481848888e-05 3.965478390455246e-05
rl training, epoch5, iter0, batch386/1133, batch loss:3.965478390455246e-05, Training time:86863.95759057999
batch reward last col mean 5.190172942093341e-06 first col mean 4.34262574344757e-06 all mean 3.6803656257689e-05
1.3301296348799951e-05 1.3301292710821144e-05
rl training, epoch5, iter0, batch387/1133, batch loss:1.3301292710821144e-05, Training time:86881.68109750748
batch reward last col mean 8.15025543943193e-07 first col mean 1.5272916016328963e-06 all mean 2.273957579745911e-05
8.481688382744323e-06 8.481692930217832e-06
rl training, epoch5, iter0, batch388/1133, batch loss:8.481692930217832e-06, Training time:86900.67863583565
batch reward last col mean 4.198145234113326e-06 first col mean 0.00011033417104044929 all mean 1.6427962691523135e-05
3.106959638898843e-06 3.106955546172685e-06
rl training, epoch5, iter0, batch389/1133, batch loss:3.106955546172685e-06, Training time:86918.97791957855
batch reward last col mean 1.4783599908696488e-06 first col mean 3.1985589885152876e-05 all mean 1.707644696580246e-05
8.597281521360856e-06 8.597279702371452e-06
rl training, epoch5, iter0, batch390/1133, batch loss:8.597279702371452e-06, Training time:86936.93541955948
batch reward last col mean 1.490574618401297e-06 first col mean 6.9502548285527155e-06 all mean 4.533697210717946e-05
5.406589843914844e-05 5.406589116319083e-05
rl training, epoch5, iter0, batch391/1133, batch loss:5.406589116319083e-05, Training time:86955.1892991066
batch reward last col mean 8.283068382297643e-07 first col mean 7.519850555581797e-07 all mean 1.5313031326513737e-05
8.1027301348513e-06 8.102731953840703e-06
rl training, epoch5, iter0, batch392/1133, batch loss:8.102731953840703e-06, Training time:86972.66861057281
batch reward last col mean 2.5075510166061576e-06 first col mean 2.056267021544045e-06 all mean 4.260712375980802e-05
1.6678255633451045e-05 1.6678270185366273e-05
rl training, epoch5, iter0, batch393/1133, batch loss:1.6678270185366273e-05, Training time:86991.38967871666
batch reward last col mean 0.0007293584058061242 first col mean 7.501037089241436e-07 all mean 0.00020804523956030607
3.167369868606329e-05 3.167369504808448e-05
rl training, epoch5, iter0, batch394/1133, batch loss:3.167369504808448e-05, Training time:87009.1216583252
batch reward last col mean 1.8733649085334036e-06 first col mean 1.8233165974379517e-05 all mean 2.9086384529364295e-05
2.3099953978089616e-05 2.3099952159100212e-05
rl training, epoch5, iter0, batch395/1133, batch loss:2.3099952159100212e-05, Training time:87026.68015956879
batch reward last col mean 3.033464054169599e-06 first col mean 2.4140538243955234e-06 all mean 2.0017005226691253e-05
6.050913270883029e-06 6.050914635125082e-06
rl training, epoch5, iter0, batch396/1133, batch loss:6.050914635125082e-06, Training time:87044.00799322128
batch reward last col mean 6.99287120369263e-05 first col mean 3.2881773677218007e-06 all mean 2.2426063878810965e-05
5.9107342167408206e-06 5.9107342167408206e-06
rl training, epoch5, iter0, batch397/1133, batch loss:5.9107342167408206e-06, Training time:87062.4684855938
batch reward last col mean 1.647401631998946e-06 first col mean 1.6687777133483905e-06 all mean 2.469527862558607e-05
3.4409661111567402e-06 3.4409620184305822e-06
rl training, epoch5, iter0, batch398/1133, batch loss:3.4409620184305822e-06, Training time:87079.16725850105
batch reward last col mean 0.0001166902802651748 first col mean 2.2494070435641333e-05 all mean 1.0941349501081277e-05
2.0286623112042435e-05 2.0286624931031838e-05
rl training, epoch5, iter0, batch399/1133, batch loss:2.0286624931031838e-05, Training time:87096.00517225266
batch reward last col mean 4.796988650923595e-05 first col mean 2.7759269869420677e-06 all mean 3.1302486604545265e-05
5.263511411612853e-06 5.263508683128748e-06
rl training, epoch5, iter0, batch400/1133, batch loss:5.263508683128748e-06, Training time:87112.73760056496
batch reward last col mean 7.202035703812726e-06 first col mean 7.719848326814827e-06 all mean 2.1732690584030934e-05
1.0296217624272685e-05 1.0296215805283282e-05
rl training, epoch5, iter0, batch401/1133, batch loss:1.0296215805283282e-05, Training time:87129.43595576286
batch reward last col mean 1.939056119226734e-06 first col mean 1.4425829704123316e-06 all mean 1.0901210771407932e-05
3.3716817142703803e-06 3.371681486896705e-06
rl training, epoch5, iter0, batch402/1133, batch loss:3.371681486896705e-06, Training time:87146.18987560272
batch reward last col mean 8.300717308884487e-05 first col mean 4.0762824937701225e-06 all mean 7.901639037299901e-05
2.176205271098297e-05 2.176205816795118e-05
rl training, epoch5, iter0, batch403/1133, batch loss:2.176205816795118e-05, Training time:87162.98496937752
batch reward last col mean 1.0496415825400618e-06 first col mean 7.813420779712033e-06 all mean 1.2252578926563729e-05
1.456098380003823e-05 1.456098380003823e-05
rl training, epoch5, iter0, batch404/1133, batch loss:1.456098380003823e-05, Training time:87179.75287079811
batch reward last col mean 1.62946059845126e-06 first col mean 1.908893318613991e-05 all mean 1.630288352316711e-05
1.1690702194755431e-05 1.1690699466271326e-05
rl training, epoch5, iter0, batch405/1133, batch loss:1.1690699466271326e-05, Training time:87196.45410704613
batch reward last col mean 6.820165253884625e-06 first col mean 2.589597897895146e-06 all mean 1.720981344988104e-05
5.736191724281525e-06 5.73618899579742e-06
rl training, epoch5, iter0, batch406/1133, batch loss:5.73618899579742e-06, Training time:87213.7335281372
batch reward last col mean 5.073601414551376e-07 first col mean 3.4001157018792583e-06 all mean 1.982690446311608e-05
8.074458492046688e-06 8.074457582551986e-06
rl training, epoch5, iter0, batch407/1133, batch loss:8.074457582551986e-06, Training time:87230.771068573
batch reward last col mean 2.892055363190593e-06 first col mean 5.553993560170056e-06 all mean 1.664166666159872e-05
8.903649359126575e-06 8.903651178115979e-06
rl training, epoch5, iter0, batch408/1133, batch loss:8.903651178115979e-06, Training time:87248.71791124344
batch reward last col mean 0.00010230229963781312 first col mean 2.3470552150683943e-06 all mean 1.5474744941457175e-05
1.1065350008720998e-05 1.1065355465689208e-05
rl training, epoch5, iter0, batch409/1133, batch loss:1.1065355465689208e-05, Training time:87266.49480247498
batch reward last col mean 6.721788849972654e-06 first col mean 1.8745120087260148e-06 all mean 4.220027039991692e-05
7.764650035824161e-06 7.76464912632946e-06
rl training, epoch5, iter0, batch410/1133, batch loss:7.76464912632946e-06, Training time:87284.67336797714
batch reward last col mean 4.486788384383544e-06 first col mean 3.696267413033638e-06 all mean 3.236694465158507e-05
1.661188252910506e-05 1.6611889805062674e-05
rl training, epoch5, iter0, batch411/1133, batch loss:1.6611889805062674e-05, Training time:87303.7260620594
batch reward last col mean 3.4490226425987203e-06 first col mean 2.048617488981108e-06 all mean 7.774260666337796e-06
2.0279437649151077e-06 2.027943992288783e-06
rl training, epoch5, iter0, batch412/1133, batch loss:2.027943992288783e-06, Training time:87320.77743387222
batch reward last col mean 1.2552127373055555e-06 first col mean 3.0767746466153767e-06 all mean 2.567182673374191e-05
1.748296563164331e-05 1.7482967450632714e-05
rl training, epoch5, iter0, batch413/1133, batch loss:1.7482967450632714e-05, Training time:87338.8410255909
batch reward last col mean 7.389953680103645e-06 first col mean 1.3208118616603315e-05 all mean 4.793088373844512e-05
2.1428375475807115e-05 2.142839366570115e-05
rl training, epoch5, iter0, batch414/1133, batch loss:2.142839366570115e-05, Training time:87356.70896458626
batch reward last col mean 3.760695472010411e-05 first col mean 4.561464265862014e-06 all mean 2.8246971851331182e-05
5.659067937813234e-06 5.659082034981111e-06
rl training, epoch5, iter0, batch415/1133, batch loss:5.659082034981111e-06, Training time:87374.55818986893
batch reward last col mean 8.782179179434024e-07 first col mean 0.0008018127991817892 all mean 3.096125874435529e-05
3.178732731612399e-05 3.1787334592081606e-05
rl training, epoch5, iter0, batch416/1133, batch loss:3.1787334592081606e-05, Training time:87391.14789843559
batch reward last col mean 2.2267156509769848e-06 first col mean 9.922307071974501e-06 all mean 1.700963548501022e-05
8.802123375062365e-06 8.802125194051769e-06
rl training, epoch5, iter0, batch417/1133, batch loss:8.802125194051769e-06, Training time:87407.97910356522
batch reward last col mean 1.6378980944864452e-06 first col mean 1.9893273929483257e-05 all mean 2.7521737138158642e-05
1.1958503819187172e-05 1.1958500181208365e-05
rl training, epoch5, iter0, batch418/1133, batch loss:1.1958500181208365e-05, Training time:87424.62383508682
batch reward last col mean 4.431202796695288e-06 first col mean 1.5812292986083776e-06 all mean 3.68065302609466e-05
1.4934880709915888e-05 1.4934886166884098e-05
rl training, epoch5, iter0, batch419/1133, batch loss:1.4934886166884098e-05, Training time:87441.34046769142
batch reward last col mean 3.776152652790188e-06 first col mean 0.00025045385700650513 all mean 3.7667996366508305e-05
4.539082055998733e-06 4.5390906961984e-06
rl training, epoch5, iter0, batch420/1133, batch loss:4.5390906961984e-06, Training time:87458.13222622871
batch reward last col mean 1.4590784758183872e-06 first col mean 1.5697811477366486e-06 all mean 1.6038160538300872e-05
7.020827069936786e-06 7.020827069936786e-06
rl training, epoch5, iter0, batch421/1133, batch loss:7.020827069936786e-06, Training time:87474.7770421505
batch reward last col mean 5.277298441797029e-06 first col mean 4.684127816290129e-06 all mean 3.79186421923805e-05
1.954842264240142e-05 1.9548415366443805e-05
rl training, epoch5, iter0, batch422/1133, batch loss:1.9548415366443805e-05, Training time:87493.29701471329
batch reward last col mean 2.2611643544223625e-06 first col mean 7.291261681530159e-06 all mean 6.873694655951113e-05
3.8019388739485294e-05 3.80193923774641e-05
rl training, epoch5, iter0, batch423/1133, batch loss:3.80193923774641e-05, Training time:87511.78338956833
batch reward last col mean 6.778038368793204e-05 first col mean 5.358062367122329e-07 all mean 4.684944360633381e-05
1.4736998309672344e-05 1.4737000128661748e-05
rl training, epoch5, iter0, batch424/1133, batch loss:1.4737000128661748e-05, Training time:87530.31647849083
batch reward last col mean 3.865430244331947e-06 first col mean 4.212398380332161e-06 all mean 1.099023393180687e-05
6.37852963336627e-06 6.378530088113621e-06
rl training, epoch5, iter0, batch425/1133, batch loss:6.378530088113621e-06, Training time:87548.76305913925
batch reward last col mean 2.3103596049622865e-06 first col mean 3.286992523499066e-06 all mean 4.61361269117333e-05
7.39636379876174e-05 7.396362343570217e-05
rl training, epoch5, iter0, batch426/1133, batch loss:7.396362343570217e-05, Training time:87565.42769432068
batch reward last col mean 1.083116558220354e-06 first col mean 2.3136220988817513e-05 all mean 1.9445114958216436e-05
5.955388132861117e-06 5.955386768619064e-06
rl training, epoch5, iter0, batch427/1133, batch loss:5.955386768619064e-06, Training time:87582.10571360588
batch reward last col mean 1.1674666893668473e-05 first col mean 8.131194590532687e-06 all mean 4.389794776216149e-05
1.5748999430797994e-05 1.5748999430797994e-05
rl training, epoch5, iter0, batch428/1133, batch loss:1.5748999430797994e-05, Training time:87599.93904209137
batch reward last col mean 6.726299488946097e-06 first col mean 3.4498159493523417e-06 all mean 9.534339369565714e-06
5.715032330044778e-06 5.715032784792129e-06
rl training, epoch5, iter0, batch429/1133, batch loss:5.715032784792129e-06, Training time:87617.72293996811
batch reward last col mean 1.2840831686844467e-06 first col mean 2.0590268832165748e-06 all mean 1.3925745406595524e-05
5.819058515044162e-06 5.819059879286215e-06
rl training, epoch5, iter0, batch430/1133, batch loss:5.819059879286215e-06, Training time:87636.6788084507
batch reward last col mean 1.7563265828357544e-06 first col mean 1.2081057320756372e-05 all mean 4.751671804115176e-05
1.1480666216812097e-05 1.148065803135978e-05
rl training, epoch5, iter0, batch431/1133, batch loss:1.148065803135978e-05, Training time:87654.6180434227
batch reward last col mean 0.0005537887336686254 first col mean 2.0168768060102593e-06 all mean 1.9323857486597262e-05
8.67123671923764e-05 8.67123671923764e-05
rl training, epoch5, iter0, batch432/1133, batch loss:8.67123671923764e-05, Training time:87672.58352923393
batch reward last col mean 1.225062533194432e-06 first col mean 2.795694126689341e-05 all mean 4.518066270975396e-05
1.539281765872147e-05 1.539282857265789e-05
rl training, epoch5, iter0, batch433/1133, batch loss:1.539282857265789e-05, Training time:87690.06972289085
batch reward last col mean 5.0472035582060926e-06 first col mean 3.8959833545959555e-06 all mean 3.132126948912628e-05
5.4259480748442e-06 5.425951258075656e-06
rl training, epoch5, iter0, batch434/1133, batch loss:5.425951258075656e-06, Training time:87707.22481179237
batch reward last col mean 1.0618064152367879e-06 first col mean 1.9723956938833e-06 all mean 2.2876003640703857e-05
9.63546790444525e-06 9.635474270908162e-06
rl training, epoch5, iter0, batch435/1133, batch loss:9.635474270908162e-06, Training time:87724.33392715454
batch reward last col mean 8.688384127708559e-07 first col mean 3.0344872357090935e-06 all mean 2.0778317775693722e-05
2.569472235336434e-05 2.5694725991343148e-05
rl training, epoch5, iter0, batch436/1133, batch loss:2.5694725991343148e-05, Training time:87742.88090920448
batch reward last col mean 0.00010565387492533773 first col mean 8.27751932774845e-07 all mean 5.609481013379991e-05
4.277729658497265e-06 4.277729658497265e-06
rl training, epoch5, iter0, batch437/1133, batch loss:4.277729658497265e-06, Training time:87761.37226605415
batch reward last col mean 1.2121829513489502e-06 first col mean 1.1753550097637344e-06 all mean 2.975125244120136e-05
8.411597264057491e-06 8.411593626078684e-06
rl training, epoch5, iter0, batch438/1133, batch loss:8.411593626078684e-06, Training time:87778.90847611427
batch reward last col mean 2.526389152990305e-06 first col mean 3.38239283337316e-06 all mean 2.289553958689794e-05
3.0312153285194654e-06 3.0312157832668163e-06
rl training, epoch5, iter0, batch439/1133, batch loss:3.0312157832668163e-06, Training time:87796.34489870071
batch reward last col mean 2.1817525066580856e-06 first col mean 4.783175609190948e-05 all mean 6.90382657921873e-05
2.8298758479650132e-05 2.8298758479650132e-05
rl training, epoch5, iter0, batch440/1133, batch loss:2.8298758479650132e-05, Training time:87814.85331296921
batch reward last col mean 9.811818699745345e-07 first col mean 1.5692183978899266e-06 all mean 3.187774564139545e-05
0.00012260934454388916 0.00012260934454388916
rl training, epoch5, iter0, batch441/1133, batch loss:0.00012260934454388916, Training time:87833.40600013733
batch reward last col mean 1.250052605428209e-06 first col mean 1.653831191106292e-06 all mean 2.8070755433873273e-05
6.877825944684446e-05 6.877825217088684e-05
rl training, epoch5, iter0, batch442/1133, batch loss:6.877825217088684e-05, Training time:87851.92317533493
batch reward last col mean 1.6545170637982665e-06 first col mean 1.1474834309410653e-06 all mean 1.7513490092824213e-05
9.334420610684901e-06 9.334418791695498e-06
rl training, epoch5, iter0, batch443/1133, batch loss:9.334418791695498e-06, Training time:87870.3953678608
batch reward last col mean 1.630574274713581e-06 first col mean 2.930727532657329e-06 all mean 1.3800715350953396e-05
6.266397122089984e-06 6.266397576837335e-06
rl training, epoch5, iter0, batch444/1133, batch loss:6.266397576837335e-06, Training time:87888.87809848785
batch reward last col mean 8.541028364561498e-06 first col mean 3.601529897423461e-06 all mean 2.8544553060783073e-05
8.80045899975812e-06 8.800461728242226e-06
rl training, epoch5, iter0, batch445/1133, batch loss:8.800461728242226e-06, Training time:87907.34040570259
batch reward last col mean 7.310000000870787e-07 first col mean 5.68508994547301e-06 all mean 1.6870673789526336e-05
6.509738341264892e-06 6.509740160254296e-06
rl training, epoch5, iter0, batch446/1133, batch loss:6.509740160254296e-06, Training time:87924.42283439636
batch reward last col mean 2.4128605673467973e-06 first col mean 8.504028301103972e-06 all mean 1.6234949725912884e-05
7.251609076774912e-06 7.251611350511666e-06
rl training, epoch5, iter0, batch447/1133, batch loss:7.251611350511666e-06, Training time:87942.41074752808
batch reward last col mean 1.8359171463089297e-06 first col mean 4.70016948384e-06 all mean 3.963549534091726e-05
6.254645541048376e-06 6.25464235781692e-06
rl training, epoch5, iter0, batch448/1133, batch loss:6.25464235781692e-06, Training time:87961.32172179222
batch reward last col mean 0.0008454836788587272 first col mean 0.00011675574205582961 all mean 0.0005689188838005066
8.713632996659726e-05 8.713632269063964e-05
rl training, epoch5, iter0, batch449/1133, batch loss:8.713632269063964e-05, Training time:87980.46836733818
batch reward last col mean 2.031869826168986e-06 first col mean 9.134196261584293e-07 all mean 3.2584721338935196e-05
7.830916001694277e-05 7.830914546502754e-05
rl training, epoch5, iter0, batch450/1133, batch loss:7.830914546502754e-05, Training time:87999.89013195038
batch reward last col mean 0.0003228446003049612 first col mean 1.5614272342645563e-05 all mean 0.00017240713350474834
6.201600626809523e-05 6.201601354405284e-05
rl training, epoch5, iter0, batch451/1133, batch loss:6.201601354405284e-05, Training time:88018.16912508011
batch reward last col mean 3.3834626265161205e-06 first col mean 1.4948496982469806e-06 all mean 1.7937334632733837e-05
6.680392743874108e-06 6.680398200842319e-06
rl training, epoch5, iter0, batch452/1133, batch loss:6.680398200842319e-06, Training time:88034.90822339058
batch reward last col mean 2.7818668968393467e-05 first col mean 2.9003922463743947e-06 all mean 3.218579513486475e-05
1.6368881915695965e-05 1.6368876458727755e-05
rl training, epoch5, iter0, batch453/1133, batch loss:1.6368876458727755e-05, Training time:88051.63039541245
batch reward last col mean 1.612854248378426e-05 first col mean 4.335109406383708e-05 all mean 7.132043538149446e-05
1.87993955478305e-05 1.8799379176925868e-05
rl training, epoch5, iter0, batch454/1133, batch loss:1.8799379176925868e-05, Training time:88069.06270980835
batch reward last col mean 1.9882105334545486e-05 first col mean 2.1669495254172944e-05 all mean 3.569120599422604e-05
1.526717096567154e-05 1.5267172784660943e-05
rl training, epoch5, iter0, batch455/1133, batch loss:1.5267172784660943e-05, Training time:88085.73977518082
batch reward last col mean 7.240986178658204e-06 first col mean 2.9742082006123383e-06 all mean 7.389287202386186e-05
2.813544233504217e-05 2.813542596413754e-05
rl training, epoch5, iter0, batch456/1133, batch loss:2.813542596413754e-05, Training time:88102.41948199272
batch reward last col mean 4.302576144254999e-07 first col mean 2.106439524141024e-06 all mean 4.892548531643115e-05
0.00016090298595372587 0.00016090297140181065
rl training, epoch5, iter0, batch457/1133, batch loss:0.00016090297140181065, Training time:88119.02099442482
batch reward last col mean 0.0034431328531354666 first col mean 1.4538316008838592e-06 all mean 0.0004951398586854339
0.0001267969491891563 0.00012679693463724107
rl training, epoch5, iter0, batch458/1133, batch loss:0.00012679693463724107, Training time:88135.4856030941
batch reward last col mean 1.3489872117133928e-06 first col mean 5.4088077376945876e-06 all mean 1.9740853531402536e-05
1.0871288395719603e-05 1.0871288395719603e-05
rl training, epoch5, iter0, batch459/1133, batch loss:1.0871288395719603e-05, Training time:88152.01163458824
batch reward last col mean 6.501394977931341e-07 first col mean 1.0650428521330468e-05 all mean 2.6963640266330913e-05
1.0424325409985613e-05 1.0424322681501508e-05
rl training, epoch5, iter0, batch460/1133, batch loss:1.0424322681501508e-05, Training time:88168.7141726017
batch reward last col mean 1.883235313471232e-06 first col mean 2.340461151106865e-06 all mean 4.3614203605102375e-05
5.727733514504507e-05 5.7277320593129843e-05
rl training, epoch5, iter0, batch461/1133, batch loss:5.7277320593129843e-05, Training time:88187.82885479927
batch reward last col mean 3.380224370630458e-06 first col mean 2.401996880507795e-06 all mean 2.6201476430287585e-05
4.419583274284378e-05 4.419582910486497e-05
rl training, epoch5, iter0, batch462/1133, batch loss:4.419582910486497e-05, Training time:88206.13983917236
batch reward last col mean 6.161524197523249e-07 first col mean 2.2289316348178545e-06 all mean 4.809782330994494e-05
1.3344279977900442e-05 1.3344298167794477e-05
rl training, epoch5, iter0, batch463/1133, batch loss:1.3344298167794477e-05, Training time:88224.4535267353
batch reward last col mean 2.7418043373472756e-06 first col mean 1.3822260370943695e-05 all mean 1.8058815840049647e-05
1.0372616088716313e-05 1.037261426972691e-05
rl training, epoch5, iter0, batch464/1133, batch loss:1.037261426972691e-05, Training time:88242.68963623047
batch reward last col mean 3.477123527773074e-06 first col mean 2.9411071409413125e-06 all mean 3.5879835195373744e-05
2.091056012432091e-05 2.091056558128912e-05
rl training, epoch5, iter0, batch465/1133, batch loss:2.091056558128912e-05, Training time:88261.60494089127
batch reward last col mean 7.079831266310066e-05 first col mean 2.173250322812237e-06 all mean 3.112880949629471e-05
1.38416025947663e-05 1.38416025947663e-05
rl training, epoch5, iter0, batch466/1133, batch loss:1.38416025947663e-05, Training time:88280.84406852722
batch reward last col mean 2.8724630283250008e-06 first col mean 3.574013589968672e-06 all mean 3.236765041947365e-05
1.5555824575130828e-05 1.5555824575130828e-05
rl training, epoch5, iter0, batch467/1133, batch loss:1.5555824575130828e-05, Training time:88299.08237791061
batch reward last col mean 2.7352784854883794e-06 first col mean 1.892637101263972e-06 all mean 3.674597246572375e-05
8.694075404491741e-06 8.694078132975847e-06
rl training, epoch5, iter0, batch468/1133, batch loss:8.694078132975847e-06, Training time:88316.10964417458
batch reward last col mean 0.0009020261932164431 first col mean 1.9420469470787793e-05 all mean 0.0005618660943582654
4.463234290597029e-05 4.4632335630012676e-05
rl training, epoch5, iter0, batch469/1133, batch loss:4.4632335630012676e-05, Training time:88332.8085076809
batch reward last col mean 1.4195568383001955e-06 first col mean 1.4158243857309571e-06 all mean 3.9858186937635764e-05
1.1621975318121258e-05 1.162195530923782e-05
rl training, epoch5, iter0, batch470/1133, batch loss:1.162195530923782e-05, Training time:88349.4521920681
batch reward last col mean 3.3655596780590713e-06 first col mean 2.9762638860120205e-06 all mean 1.867624268925283e-05
7.788828042976093e-06 7.788828042976093e-06
rl training, epoch5, iter0, batch471/1133, batch loss:7.788828042976093e-06, Training time:88366.10732626915
batch reward last col mean 1.078154491551686e-05 first col mean 3.7591535146930255e-06 all mean 2.1615047444356605e-05
2.955785021185875e-05 2.955784475489054e-05
rl training, epoch5, iter0, batch472/1133, batch loss:2.955784475489054e-05, Training time:88382.68887853622
batch reward last col mean 2.9089319468766917e-06 first col mean 6.151888555905316e-06 all mean 3.486069181235507e-05
8.018904736672994e-06 8.018911103135906e-06
rl training, epoch5, iter0, batch473/1133, batch loss:8.018911103135906e-06, Training time:88399.38683533669
batch reward last col mean 4.1515986595186405e-06 first col mean 1.1412751518946607e-05 all mean 5.671979670296423e-05
4.112122769583948e-05 4.1121234971797094e-05
rl training, epoch5, iter0, batch474/1133, batch loss:4.1121234971797094e-05, Training time:88415.96166610718
batch reward last col mean 7.398647312584217e-07 first col mean 3.7858721952943597e-06 all mean 3.921462848666124e-05
1.9279350453871302e-05 1.9279343177913688e-05
rl training, epoch5, iter0, batch475/1133, batch loss:1.9279343177913688e-05, Training time:88432.74580979347
batch reward last col mean 2.6049292500829324e-06 first col mean 1.0989879228873178e-06 all mean 1.2010339560220018e-05
3.835816642094869e-06 3.83581709684222e-06
rl training, epoch5, iter0, batch476/1133, batch loss:3.83581709684222e-06, Training time:88449.48179626465
batch reward last col mean 1.0616573717925348e-06 first col mean 1.15918078336108e-06 all mean 8.25518600322539e-06
6.536400633194717e-06 6.536400633194717e-06
rl training, epoch5, iter0, batch477/1133, batch loss:6.536400633194717e-06, Training time:88466.22395730019
batch reward last col mean 1.2677035101660294e-06 first col mean 2.14662259168108e-06 all mean 3.0181521651684307e-05
3.930511593353003e-05 3.930511593353003e-05
rl training, epoch5, iter0, batch478/1133, batch loss:3.930511593353003e-05, Training time:88482.90554523468
batch reward last col mean 2.1365658540162258e-06 first col mean 1.5223330592561979e-05 all mean 3.150905104121193e-05
8.478933523292653e-06 8.478936251776759e-06
rl training, epoch5, iter0, batch479/1133, batch loss:8.478936251776759e-06, Training time:88499.93635678291
batch reward last col mean 3.411431634958717e-07 first col mean 9.514998282611487e-07 all mean 1.9290182535769418e-05
8.44299211166799e-06 8.442988473689184e-06
rl training, epoch5, iter0, batch480/1133, batch loss:8.442988473689184e-06, Training time:88518.35144877434
batch reward last col mean 1.302704049521708e-06 first col mean 1.1950344742217567e-05 all mean 1.9963223166996613e-05
9.954408596968278e-06 9.954407687473577e-06
rl training, epoch5, iter0, batch481/1133, batch loss:9.954407687473577e-06, Training time:88536.81058979034
batch reward last col mean 8.621284450782696e-07 first col mean 4.1490270632493775e-06 all mean 4.3433337850729004e-05
3.7505153159145266e-05 3.7505153159145266e-05
rl training, epoch5, iter0, batch482/1133, batch loss:3.7505153159145266e-05, Training time:88554.76822400093
batch reward last col mean 1.629952748771757e-05 first col mean 6.317529368971009e-06 all mean 4.439869735506363e-05
8.7803900896688e-06 8.78037553775357e-06
rl training, epoch5, iter0, batch483/1133, batch loss:8.78037553775357e-06, Training time:88572.79324889183
batch reward last col mean 2.105727617163211e-05 first col mean 1.8956691292260075e-06 all mean 1.844441248977091e-05
4.868179530603811e-06 4.86818407807732e-06
rl training, epoch5, iter0, batch484/1133, batch loss:4.86818407807732e-06, Training time:88590.83255529404
batch reward last col mean 5.268603331387567e-07 first col mean 3.541832120390609e-05 all mean 3.9035756344674155e-05
2.2827287466498092e-05 2.2827289285487495e-05
rl training, epoch5, iter0, batch485/1133, batch loss:2.2827289285487495e-05, Training time:88607.59806609154
batch reward last col mean 6.429060704249423e-06 first col mean 2.9161851671233308e-06 all mean 2.821982889145147e-05
1.2275056178623345e-05 1.2275052540644538e-05
rl training, epoch5, iter0, batch486/1133, batch loss:1.2275052540644538e-05, Training time:88624.45648527145
batch reward last col mean 2.0020929696329404e-06 first col mean 1.0335129445593338e-06 all mean 3.397440377739258e-05
1.5104566955415066e-05 1.5104564226930961e-05
rl training, epoch5, iter0, batch487/1133, batch loss:1.5104564226930961e-05, Training time:88641.16375303268
batch reward last col mean 3.9847209336585365e-06 first col mean 1.485632765252376e-05 all mean 3.378059409442358e-05
6.570051937160315e-06 6.570061032107333e-06
rl training, epoch5, iter0, batch488/1133, batch loss:6.570061032107333e-06, Training time:88657.95440340042
batch reward last col mean 3.132216806989163e-05 first col mean 9.919382864609361e-05 all mean 4.665495362132788e-05
9.207756193063688e-06 9.207750736095477e-06
rl training, epoch5, iter0, batch489/1133, batch loss:9.207750736095477e-06, Training time:88674.69019985199
batch reward last col mean 1.3335263702174416e-06 first col mean 7.954830834933091e-06 all mean 3.354095679242164e-05
3.8228001358220354e-05 3.822799772024155e-05
rl training, epoch5, iter0, batch490/1133, batch loss:3.822799772024155e-05, Training time:88691.2104229927
batch reward last col mean 1.8984741473104805e-05 first col mean 5.349827915779315e-06 all mean 2.030944961006753e-05
1.093518494599266e-05 1.0935183127003256e-05
rl training, epoch5, iter0, batch491/1133, batch loss:1.0935183127003256e-05, Training time:88709.35126686096
batch reward last col mean 4.3459804146550596e-06 first col mean 8.69958967086859e-06 all mean 1.5070295376062859e-05
4.778324182552751e-06 4.778325092047453e-06
rl training, epoch5, iter0, batch492/1133, batch loss:4.778325092047453e-06, Training time:88726.43902873993
batch reward last col mean 4.023234396299813e-06 first col mean 8.399494618060999e-06 all mean 4.2748819396365434e-05
3.4120079362764955e-05 3.412007572478615e-05
rl training, epoch5, iter0, batch493/1133, batch loss:3.412007572478615e-05, Training time:88743.2651424408
batch reward last col mean 1.4240863492887001e-06 first col mean 1.6513047285116045e-06 all mean 3.6476940294960514e-05
9.491411037743092e-05 9.491411037743092e-05
rl training, epoch5, iter0, batch494/1133, batch loss:9.491411037743092e-05, Training time:88762.71150135994
batch reward last col mean 6.3035317907633726e-06 first col mean 2.6233035441691754e-06 all mean 2.6765730581246316e-05
7.252461728057824e-06 7.2524558163422626e-06
rl training, epoch5, iter0, batch495/1133, batch loss:7.2524558163422626e-06, Training time:88780.62149906158
batch reward last col mean 9.212438953909441e-07 first col mean 1.3275077890284592e-06 all mean 1.028423139359802e-05
1.7589125036465703e-06 1.7589131857675966e-06
rl training, epoch5, iter0, batch496/1133, batch loss:1.7589131857675966e-06, Training time:88798.00498700142
batch reward last col mean 6.049701551091857e-05 first col mean 6.786347057641251e-07 all mean 4.421463381731883e-05
1.9592440366977826e-05 1.9592444004956633e-05
rl training, epoch5, iter0, batch497/1133, batch loss:1.9592444004956633e-05, Training time:88815.35713815689
batch reward last col mean 7.659518246327934e-07 first col mean 7.742006005173607e-07 all mean 1.4103438843449112e-05
2.369394678680692e-06 2.3693955881753936e-06
rl training, epoch5, iter0, batch498/1133, batch loss:2.3693955881753936e-06, Training time:88833.71183013916
batch reward last col mean 5.907505737923202e-07 first col mean 1.2594865665960242e-06 all mean 3.252027090638876e-05
1.3823792869516183e-05 1.3823785593558569e-05
rl training, epoch5, iter0, batch499/1133, batch loss:1.3823785593558569e-05, Training time:88851.7635834217
batch reward last col mean 1.2129749848099891e-05 first col mean 1.0046212537417887e-06 all mean 1.3526308066502679e-05
8.856542081048246e-06 8.856541171553545e-06
rl training, epoch5, iter0, batch500/1133, batch loss:8.856541171553545e-06, Training time:88870.97814536095
batch reward last col mean 1.6090671124402434e-05 first col mean 2.0772408788616303e-06 all mean 3.462281893007457e-05
1.7539992768433876e-05 1.7540001863380894e-05
rl training, epoch5, iter0, batch501/1133, batch loss:1.7540001863380894e-05, Training time:88891.66393256187
batch reward last col mean 2.729481593632954e-06 first col mean 1.8945602278108709e-06 all mean 3.882333476212807e-05
1.545855229778681e-05 1.545855229778681e-05
rl training, epoch5, iter0, batch502/1133, batch loss:1.545855229778681e-05, Training time:88910.79689645767
batch reward last col mean 2.146550286852289e-06 first col mean 0.00011409478611312807 all mean 7.279946294147521e-05
1.5101161807251628e-05 1.5101155440788716e-05
rl training, epoch5, iter0, batch503/1133, batch loss:1.5101155440788716e-05, Training time:88928.4851155281
batch reward last col mean 3.208075668226229e-06 first col mean 1.3899916666559875e-05 all mean 4.712339796242304e-05
1.732816599542275e-05 1.732817145239096e-05
rl training, epoch5, iter0, batch504/1133, batch loss:1.732817145239096e-05, Training time:88945.7420630455
batch reward last col mean 1.5370612800325034e-06 first col mean 9.509117262496147e-06 all mean 5.51197117601987e-05
2.274282269354444e-05 2.274282815051265e-05
rl training, epoch5, iter0, batch505/1133, batch loss:2.274282815051265e-05, Training time:88963.37770462036
batch reward last col mean 2.5610797820263542e-06 first col mean 1.3307940207596403e-06 all mean 2.7572976250667125e-05
8.368052476726007e-06 8.368045200768393e-06
rl training, epoch5, iter0, batch506/1133, batch loss:8.368045200768393e-06, Training time:88981.29103159904
batch reward last col mean 4.323056145949522e-06 first col mean 5.732145837100688e-06 all mean 1.313161374127958e-05
4.321082542446675e-06 4.321076175983762e-06
rl training, epoch5, iter0, batch507/1133, batch loss:4.321076175983762e-06, Training time:88998.43650507927
batch reward last col mean 3.2211592042585835e-06 first col mean 8.617658750154078e-06 all mean 3.0360635719262064e-05
0.00013452721759676933 0.00013452721759676933
rl training, epoch5, iter0, batch508/1133, batch loss:0.00013452721759676933, Training time:89016.55087900162
batch reward last col mean 1.2787248124368489e-05 first col mean 2.853685145964846e-06 all mean 5.1850660383934155e-05
1.2165457519586198e-05 1.216546388604911e-05
rl training, epoch5, iter0, batch509/1133, batch loss:1.216546388604911e-05, Training time:89034.97371602058
batch reward last col mean 2.239274181192741e-06 first col mean 1.6141425476234872e-06 all mean 2.1561994799412787e-05
1.6559632058488205e-05 1.655963933444582e-05
rl training, epoch5, iter0, batch510/1133, batch loss:1.655963933444582e-05, Training time:89053.9416270256
batch reward last col mean 1.437863102182746e-05 first col mean 1.1623216778389178e-05 all mean 8.063647692324594e-05
1.3282368854561355e-05 1.3282345207699109e-05
rl training, epoch5, iter0, batch511/1133, batch loss:1.3282345207699109e-05, Training time:89072.84071087837
batch reward last col mean 7.328259471250931e-06 first col mean 8.883864211384207e-06 all mean 1.235665513377171e-05
4.4797661757911555e-06 4.479765721043805e-06
rl training, epoch5, iter0, batch512/1133, batch loss:4.479765721043805e-06, Training time:89091.73676371574
batch reward last col mean 3.152156568830833e-05 first col mean 3.2780601486592786e-06 all mean 6.860451685497537e-05
2.709939690248575e-05 2.709939690248575e-05
rl training, epoch5, iter0, batch513/1133, batch loss:2.709939690248575e-05, Training time:89110.80474805832
batch reward last col mean 5.16178879479412e-05 first col mean 7.14447014615871e-06 all mean 1.546803287055809e-05
9.324651728093158e-06 9.324653547082562e-06
rl training, epoch5, iter0, batch514/1133, batch loss:9.324653547082562e-06, Training time:89129.37241744995
batch reward last col mean 1.292723391088657e-05 first col mean 4.601337423082441e-06 all mean 2.9569755497504957e-05
1.3366749044507742e-05 1.336674813501304e-05
rl training, epoch5, iter0, batch515/1133, batch loss:1.336674813501304e-05, Training time:89148.54033923149
batch reward last col mean 4.172360604570713e-06 first col mean 2.206465524068335e-06 all mean 3.465387999312952e-05
6.641408162977314e-06 6.641415438934928e-06
rl training, epoch5, iter0, batch516/1133, batch loss:6.641415438934928e-06, Training time:89166.70142269135
batch reward last col mean 5.1017004807363264e-06 first col mean 3.4160939321736805e-06 all mean 5.2268587751314044e-05
8.094080112641677e-05 8.094078657450154e-05
rl training, epoch5, iter0, batch517/1133, batch loss:8.094078657450154e-05, Training time:89183.66838860512
batch reward last col mean 1.2222003533679526e-06 first col mean 8.809100108919665e-06 all mean 5.1373472160776146e-06
1.8524538063502405e-06 1.8524542610975914e-06
rl training, epoch5, iter0, batch518/1133, batch loss:1.8524542610975914e-06, Training time:89202.64848709106
batch reward last col mean 2.3218260594148887e-06 first col mean 0.00014361445209942758 all mean 1.5257874110830016e-05
5.674622116202954e-06 5.674623480445007e-06
rl training, epoch5, iter0, batch519/1133, batch loss:5.674623480445007e-06, Training time:89220.90273833275
batch reward last col mean 8.599822649557609e-06 first col mean 0.0005847166175954044 all mean 6.460339500335976e-05
1.697143670753576e-05 1.697142761258874e-05
rl training, epoch5, iter0, batch520/1133, batch loss:1.697142761258874e-05, Training time:89239.32464361191
batch reward last col mean 2.186801111747627e-06 first col mean 7.66977682360448e-05 all mean 1.8460248611518182e-05
3.560399272828363e-05 3.5603996366262436e-05
rl training, epoch5, iter0, batch521/1133, batch loss:3.5603996366262436e-05, Training time:89256.40192770958
batch reward last col mean 5.742378561990336e-06 first col mean 5.859812972630607e-06 all mean 1.3623187442135531e-05
7.932975677249487e-06 7.93297658674419e-06
rl training, epoch5, iter0, batch522/1133, batch loss:7.93297658674419e-06, Training time:89273.47181749344
batch reward last col mean 0.00012944272020831704 first col mean 1.0149442459805869e-05 all mean 6.842726725153625e-05
1.3234962352726143e-05 1.3234965081210248e-05
rl training, epoch5, iter0, batch523/1133, batch loss:1.3234965081210248e-05, Training time:89290.56647062302
batch reward last col mean 4.0107597669702955e-06 first col mean 4.699896180682117e-06 all mean 1.762502870406024e-05
1.1431478924350813e-05 1.1431481652834918e-05
rl training, epoch5, iter0, batch524/1133, batch loss:1.1431481652834918e-05, Training time:89308.98409724236
batch reward last col mean 3.245870175305754e-05 first col mean 0.00026537207304500043 all mean 2.4938088245107792e-05
1.1842977983178571e-05 1.1842977983178571e-05
rl training, epoch5, iter0, batch525/1133, batch loss:1.1842977983178571e-05, Training time:89328.30577874184
batch reward last col mean 1.0105281944561284e-06 first col mean 1.3538493476517033e-05 all mean 2.1732259483542293e-05
1.1785308743128553e-05 1.1785316019086167e-05
rl training, epoch5, iter0, batch526/1133, batch loss:1.1785316019086167e-05, Training time:89346.5962357521
batch reward last col mean 0.002253515413030982 first col mean 0.00029276779969222844 all mean 8.503474964527413e-05
0.000297066115308553 0.000297066115308553
rl training, epoch5, iter0, batch527/1133, batch loss:0.000297066115308553, Training time:89364.57508468628
batch reward last col mean 1.5070266954353428e-06 first col mean 2.827011257977574e-06 all mean 5.770792085968424e-06
2.639610329424613e-06 2.6396110115456395e-06
rl training, epoch5, iter0, batch528/1133, batch loss:2.6396110115456395e-06, Training time:89381.99769854546
batch reward last col mean 1.521328158560209e-06 first col mean 8.860877187544247e-07 all mean 1.776887984306086e-05
2.1602711058221757e-05 2.1602711058221757e-05
rl training, epoch5, iter0, batch529/1133, batch loss:2.1602711058221757e-05, Training time:89400.71909832954
batch reward last col mean 3.6906569675920764e-06 first col mean 2.3303142370423302e-05 all mean 5.7057048252318054e-05
3.8146652514114976e-05 3.814664523815736e-05
rl training, epoch5, iter0, batch530/1133, batch loss:3.814664523815736e-05, Training time:89418.9338798523
batch reward last col mean 2.2391600396076683e-06 first col mean 1.336150035058381e-05 all mean 1.4021755305293482e-05
3.5163830034434795e-06 3.516380729706725e-06
rl training, epoch5, iter0, batch531/1133, batch loss:3.516380729706725e-06, Training time:89435.95200014114
batch reward last col mean 1.9320800674904604e-06 first col mean 1.6915099649850163e-06 all mean 1.1990858183708042e-05
5.702474481950048e-06 5.70247539144475e-06
rl training, epoch5, iter0, batch532/1133, batch loss:5.70247539144475e-06, Training time:89454.65452837944
batch reward last col mean 4.187680133327376e-06 first col mean 6.5574413383728825e-06 all mean 2.26822176045971e-05
7.692077815590892e-06 7.692077815590892e-06
rl training, epoch5, iter0, batch533/1133, batch loss:7.692077815590892e-06, Training time:89473.43666791916
batch reward last col mean 2.1561645553447306e-06 first col mean 3.3943113066925434e-06 all mean 3.527248918544501e-05
3.9067854231689125e-05 3.906786150764674e-05
rl training, epoch5, iter0, batch534/1133, batch loss:3.906786150764674e-05, Training time:89490.80697655678
batch reward last col mean 3.7900088045716984e-07 first col mean 1.3976646187074948e-06 all mean 2.567708543210756e-05
3.006690531037748e-05 3.006690531037748e-05
rl training, epoch5, iter0, batch535/1133, batch loss:3.006690531037748e-05, Training time:89507.83933591843
batch reward last col mean 1.011476228995889e-06 first col mean 2.6599188913678518e-06 all mean 3.9777289202902466e-05
7.281428679561941e-06 7.281429134309292e-06
rl training, epoch5, iter0, batch536/1133, batch loss:7.281429134309292e-06, Training time:89524.98106956482
batch reward last col mean 1.3357062016439158e-05 first col mean 6.853877493995242e-06 all mean 1.8797760276356712e-05
5.576344847213477e-06 5.576342118729372e-06
rl training, epoch5, iter0, batch537/1133, batch loss:5.576342118729372e-06, Training time:89542.10839891434
batch reward last col mean 9.410555321665015e-06 first col mean 1.9154094843543135e-06 all mean 3.228775676689111e-05
1.3491448953573126e-05 1.3491448953573126e-05
rl training, epoch5, iter0, batch538/1133, batch loss:1.3491448953573126e-05, Training time:89559.78771281242
batch reward last col mean 3.579597432690207e-06 first col mean 7.380314855254255e-06 all mean 6.680962542304769e-05
5.0562783144414425e-05 5.056277950643562e-05
rl training, epoch5, iter0, batch539/1133, batch loss:5.056277950643562e-05, Training time:89578.56352305412
batch reward last col mean 1.8725748986980761e-06 first col mean 6.526442462018167e-07 all mean 9.056609087565448e-06
5.770681582362158e-06 5.770683401351562e-06
rl training, epoch5, iter0, batch540/1133, batch loss:5.770683401351562e-06, Training time:89597.46080708504
batch reward last col mean 1.0866781849472318e-05 first col mean 1.051354274750338e-06 all mean 3.3623196941334754e-05
3.962950358982198e-05 3.962949995184317e-05
rl training, epoch5, iter0, batch541/1133, batch loss:3.962949995184317e-05, Training time:89614.70217061043
batch reward last col mean 2.4392052182520274e-06 first col mean 3.2828043003974017e-06 all mean 4.123475810047239e-05
3.137422390864231e-05 3.13742202706635e-05
rl training, epoch5, iter0, batch542/1133, batch loss:3.13742202706635e-05, Training time:89632.02674627304
batch reward last col mean 1.4323325103759998e-06 first col mean 2.807774080793024e-06 all mean 2.6233245080220513e-05
2.437779403408058e-05 2.437778857711237e-05
rl training, epoch5, iter0, batch543/1133, batch loss:2.437778857711237e-05, Training time:89650.31010651588
batch reward last col mean 1.3293906704348046e-06 first col mean 1.2146934977863566e-06 all mean 4.868848918704316e-05
2.0080839021829888e-05 2.0080833564861678e-05
rl training, epoch5, iter0, batch544/1133, batch loss:2.0080833564861678e-05, Training time:89668.10611701012
batch reward last col mean 6.417384383894387e-07 first col mean 5.709619017579826e-06 all mean 2.5099523554672487e-05
1.3435500477498863e-05 1.3435499568004161e-05
rl training, epoch5, iter0, batch545/1133, batch loss:1.3435499568004161e-05, Training time:89685.99195218086
batch reward last col mean 8.262821211246774e-06 first col mean 2.110055174853187e-05 all mean 2.5983565137721598e-05
6.81200117469416e-06 6.811995717725949e-06
rl training, epoch5, iter0, batch546/1133, batch loss:6.811995717725949e-06, Training time:89703.64763975143
batch reward last col mean 1.4465584172285162e-05 first col mean 1.9438082745182328e-05 all mean 2.3596850951435044e-05
7.494312285416527e-06 7.494305918953614e-06
rl training, epoch5, iter0, batch547/1133, batch loss:7.494305918953614e-06, Training time:89721.869079113
batch reward last col mean 3.112632384727476e-06 first col mean 2.6110601538675837e-06 all mean 1.850069747888483e-05
1.2571647857839707e-05 1.2571646038850304e-05
rl training, epoch5, iter0, batch548/1133, batch loss:1.2571646038850304e-05, Training time:89740.97003245354
batch reward last col mean 1.3170416650609695e-06 first col mean 4.276417257642606e-06 all mean 4.017311584902927e-05
1.1077687304350547e-05 1.1077681847382337e-05
rl training, epoch5, iter0, batch549/1133, batch loss:1.1077681847382337e-05, Training time:89758.69432091713
batch reward last col mean 3.0106300528132124e-06 first col mean 1.0379341802035924e-05 all mean 2.5654941055108793e-05
7.660082701477222e-06 7.66008179198252e-06
rl training, epoch5, iter0, batch550/1133, batch loss:7.66008179198252e-06, Training time:89776.58633732796
batch reward last col mean 2.6602526759234024e-06 first col mean 2.958724053314654e-06 all mean 1.9639886886579916e-05
1.4820585420238785e-05 1.4820586329733487e-05
rl training, epoch5, iter0, batch551/1133, batch loss:1.4820586329733487e-05, Training time:89793.74890494347
batch reward last col mean 2.290159318363294e-05 first col mean 6.214879249455407e-06 all mean 5.5874745157780126e-05
1.7749231119523756e-05 1.7749225662555546e-05
rl training, epoch5, iter0, batch552/1133, batch loss:1.7749225662555546e-05, Training time:89811.08198094368
batch reward last col mean 1.1328364053042606e-05 first col mean 1.105921796806797e-06 all mean 2.5557672415743582e-05
1.1506882401590701e-05 1.1506881492096e-05
rl training, epoch5, iter0, batch553/1133, batch loss:1.1506881492096e-05, Training time:89830.07377433777
batch reward last col mean 1.9466808680590475e-06 first col mean 3.3460103168181377e-06 all mean 2.2450723918154836e-05
1.4153682968753856e-05 1.4153678421280347e-05
rl training, epoch5, iter0, batch554/1133, batch loss:1.4153678421280347e-05, Training time:89848.97611188889
batch reward last col mean 3.220830694772303e-05 first col mean 1.684959170233924e-05 all mean 1.9782650269917212e-05
8.118823643599171e-06 8.118824553093873e-06
rl training, epoch5, iter0, batch555/1133, batch loss:8.118824553093873e-06, Training time:89866.1970653534
batch reward last col mean 6.812197739236581e-07 first col mean 2.829270897564129e-06 all mean 1.503725980001036e-05
3.1349860364571214e-05 3.134985672659241e-05
rl training, epoch5, iter0, batch556/1133, batch loss:3.134985672659241e-05, Training time:89883.43073701859
batch reward last col mean 9.580140613252297e-06 first col mean 3.164694589941064e-06 all mean 3.0342505851876922e-05
5.2438183047343045e-05 5.243818668532185e-05
rl training, epoch5, iter0, batch557/1133, batch loss:5.243818668532185e-05, Training time:89902.29401946068
batch reward last col mean 4.264024937583599e-06 first col mean 2.2673063995171105e-06 all mean 3.9037910028127953e-05
1.8547079889685847e-05 1.854707625170704e-05
rl training, epoch5, iter0, batch558/1133, batch loss:1.854707625170704e-05, Training time:89920.34698534012
batch reward last col mean 2.323973149032099e-06 first col mean 8.393393363803625e-05 all mean 2.2341337171383202e-05
8.01342957856832e-06 8.013423212105408e-06
rl training, epoch5, iter0, batch559/1133, batch loss:8.013423212105408e-06, Training time:89937.75554895401
batch reward last col mean 4.0997405449161306e-05 first col mean 5.4153247219801415e-06 all mean 7.773239485686645e-05
4.9559235776541755e-05 4.955921758664772e-05
rl training, epoch5, iter0, batch560/1133, batch loss:4.955921758664772e-05, Training time:89956.7882335186
batch reward last col mean 1.1471446669020224e-05 first col mean 6.317448878689902e-06 all mean 9.691133527667262e-06
3.0448907182289986e-06 3.044889808734297e-06
rl training, epoch5, iter0, batch561/1133, batch loss:3.044889808734297e-06, Training time:89976.12984538078
batch reward last col mean 2.2604081095778383e-06 first col mean 1.4982302900534705e-06 all mean 1.4690983334730845e-05
5.405701358540682e-06 5.405703177530086e-06
rl training, epoch5, iter0, batch562/1133, batch loss:5.405703177530086e-06, Training time:89993.59704184532
batch reward last col mean 8.50144169817213e-06 first col mean 7.648215614608489e-06 all mean 2.388285065535456e-05
8.070127478276845e-06 8.070128387771547e-06
rl training, epoch5, iter0, batch563/1133, batch loss:8.070128387771547e-06, Training time:90012.13259744644
batch reward last col mean 1.2826192232751055e-06 first col mean 7.367218586296076e-07 all mean 1.9249269826104864e-05
8.749576409172732e-06 8.74958004715154e-06
rl training, epoch5, iter0, batch564/1133, batch loss:8.74958004715154e-06, Training time:90031.06388616562
batch reward last col mean 2.3986056476132944e-05 first col mean 2.046202280325815e-05 all mean 3.35799741151277e-05
1.0847871635633055e-05 1.0847873454622459e-05
rl training, epoch5, iter0, batch565/1133, batch loss:1.0847873454622459e-05, Training time:90048.9034769535
batch reward last col mean 1.4751212802366354e-06 first col mean 0.0004056710749864578 all mean 1.2809045074391179e-05
7.126075615815353e-06 7.126074706320651e-06
rl training, epoch5, iter0, batch566/1133, batch loss:7.126074706320651e-06, Training time:90065.90605449677
batch reward last col mean 1.600325845174666e-06 first col mean 1.853481626312714e-05 all mean 1.5235621503961738e-05
2.337118530704174e-06 2.3371208044409286e-06
rl training, epoch5, iter0, batch567/1133, batch loss:2.3371208044409286e-06, Training time:90084.74550056458
batch reward last col mean 1.0723972081905231e-05 first col mean 0.00015241536311805248 all mean 1.9732364307856187e-05
3.472241587587632e-05 3.472241587587632e-05
rl training, epoch5, iter0, batch568/1133, batch loss:3.472241587587632e-05, Training time:90102.36481571198
batch reward last col mean 4.179240931989625e-06 first col mean 4.345615707279649e-06 all mean 1.7921684047905728e-05
9.894037248159293e-06 9.894034519675188e-06
rl training, epoch5, iter0, batch569/1133, batch loss:9.894034519675188e-06, Training time:90121.36157536507
batch reward last col mean 2.338369426979625e-07 first col mean 1.621811179575161e-06 all mean 1.7187465346069075e-05
4.428717602422694e-06 4.428722149896203e-06
rl training, epoch5, iter0, batch570/1133, batch loss:4.428722149896203e-06, Training time:90139.46291708946
batch reward last col mean 1.4013803593115881e-06 first col mean 3.738427494681673e-06 all mean 1.985567905649077e-05
9.022140147862956e-06 9.02213741937885e-06
rl training, epoch5, iter0, batch571/1133, batch loss:9.02213741937885e-06, Training time:90156.79193902016
batch reward last col mean 3.5106163522868883e-06 first col mean 5.391122613218613e-06 all mean 4.839166285819374e-05
3.0006596716702916e-05 3.000659307872411e-05
rl training, epoch5, iter0, batch572/1133, batch loss:3.000659307872411e-05, Training time:90175.05948495865
batch reward last col mean 2.5773555535124615e-05 first col mean 4.26144515586202e-06 all mean 5.0355996791040525e-05
2.5408917281311005e-05 2.5408915462321602e-05
rl training, epoch5, iter0, batch573/1133, batch loss:2.5408915462321602e-05, Training time:90193.74148631096
batch reward last col mean 0.00026665881159715354 first col mean 2.3050379240885377e-05 all mean 7.397428271360695e-05
0.00013385547208599746 0.0001338554866379127
rl training, epoch5, iter0, batch574/1133, batch loss:0.0001338554866379127, Training time:90211.09192299843
batch reward last col mean 1.3593306675829808e-06 first col mean 0.00012107215297874063 all mean 9.422838047612458e-06
1.8085949022861314e-06 1.808595925467671e-06
rl training, epoch5, iter0, batch575/1133, batch loss:1.808595925467671e-06, Training time:90230.07792639732
batch reward last col mean 5.4311803978635e-06 first col mean 1.6459880498587154e-06 all mean 4.258968692738563e-05
0.00017364535597153008 0.00017364539962727576
rl training, epoch5, iter0, batch576/1133, batch loss:0.00017364539962727576, Training time:90247.11590099335
batch reward last col mean 1.7060646086974884e-06 first col mean 1.2288373909541406e-06 all mean 1.5373918358818628e-05
6.872906396893086e-06 6.872905487398384e-06
rl training, epoch5, iter0, batch577/1133, batch loss:6.872905487398384e-06, Training time:90265.32824778557
batch reward last col mean 4.64671074951184e-06 first col mean 4.270176941645332e-05 all mean 1.0838413800229318e-05
7.545213975390652e-06 7.545212156401249e-06
rl training, epoch5, iter0, batch578/1133, batch loss:7.545212156401249e-06, Training time:90284.66534519196
batch reward last col mean 2.2613496184931137e-05 first col mean 3.5014281820622273e-06 all mean 4.9945352657232434e-05
8.278957466245629e-06 8.278972927655559e-06
rl training, epoch5, iter0, batch579/1133, batch loss:8.278972927655559e-06, Training time:90304.17485141754
batch reward last col mean 1.143692543337238e-06 first col mean 0.00023788446560502052 all mean 2.6146264644921757e-05
1.327952395513421e-05 1.3279521226650104e-05
rl training, epoch5, iter0, batch580/1133, batch loss:1.3279521226650104e-05, Training time:90323.11480307579
batch reward last col mean 2.8736196782119805e-06 first col mean 1.8418861600366654e-06 all mean 1.4697006008645985e-05
7.29186240278068e-06 7.2918642217700835e-06
rl training, epoch5, iter0, batch581/1133, batch loss:7.2918642217700835e-06, Training time:90341.69685435295
batch reward last col mean 6.088572490625666e-07 first col mean 1.381414676870918e-06 all mean 1.0590083547867835e-05
1.694707498245407e-05 1.694707498245407e-05
rl training, epoch5, iter0, batch582/1133, batch loss:1.694707498245407e-05, Training time:90360.02658104897
batch reward last col mean 5.1898732635891065e-06 first col mean 1.4604905800297274e-06 all mean 1.5746118151582778e-05
3.6670357985713053e-06 3.6670337522082264e-06
rl training, epoch5, iter0, batch583/1133, batch loss:3.6670337522082264e-06, Training time:90377.07142782211
batch reward last col mean 2.9068356525385752e-05 first col mean 1.0195942195423413e-05 all mean 7.84640506026335e-05
0.0002181045856559649 0.00021810457110404968
rl training, epoch5, iter0, batch584/1133, batch loss:0.00021810457110404968, Training time:90395.76659011841
batch reward last col mean 3.996083705715137e-06 first col mean 1.5992043245205423e-06 all mean 4.530103979050182e-05
8.320654887938872e-05 8.32065416034311e-05
rl training, epoch5, iter0, batch585/1133, batch loss:8.32065416034311e-05, Training time:90414.0230345726
batch reward last col mean 5.09615165356081e-06 first col mean 2.7625706024991814e-06 all mean 3.700358502101153e-05
1.085967778635677e-05 1.0859675967367366e-05
rl training, epoch5, iter0, batch586/1133, batch loss:1.0859675967367366e-05, Training time:90432.51517987251
batch reward last col mean 9.598044243830373e-07 first col mean 1.0342482710257173e-06 all mean 1.8860751879401505e-05
1.837522904679645e-05 1.8375227227807045e-05
rl training, epoch5, iter0, batch587/1133, batch loss:1.8375227227807045e-05, Training time:90450.1927075386
batch reward last col mean 1.3966534879727988e-06 first col mean 6.4455325627932325e-06 all mean 4.1771225369302556e-05
1.3980346921016462e-05 1.3980351468489971e-05
rl training, epoch5, iter0, batch588/1133, batch loss:1.3980351468489971e-05, Training time:90468.99909830093
batch reward last col mean 1.6133594726852607e-06 first col mean 8.005032577784732e-05 all mean 9.180247616313864e-06
3.2322961942554684e-06 3.232295512134442e-06
rl training, epoch5, iter0, batch589/1133, batch loss:3.232295512134442e-06, Training time:90485.95586323738
batch reward last col mean 4.175756657787133e-06 first col mean 6.143874088593293e-06 all mean 8.834606887830887e-06
3.1173935894912574e-06 3.117396545349038e-06
rl training, epoch5, iter0, batch590/1133, batch loss:3.117396545349038e-06, Training time:90503.30449724197
batch reward last col mean 4.913965312880464e-06 first col mean 6.157180905574933e-05 all mean 1.0323195965611376e-05
6.00943303652457e-06 6.009431672282517e-06
rl training, epoch5, iter0, batch591/1133, batch loss:6.009431672282517e-06, Training time:90521.31860423088
batch reward last col mean 2.2367679775925353e-05 first col mean 2.8388603823259473e-05 all mean 9.857078111963347e-06
6.0178044805070385e-06 6.0178044805070385e-06
rl training, epoch5, iter0, batch592/1133, batch loss:6.0178044805070385e-06, Training time:90538.50317621231
batch reward last col mean 1.935899717864231e-06 first col mean 3.3073570193664636e-06 all mean 2.9909646400483325e-05
3.984451268479461e-06 3.984453087468864e-06
rl training, epoch5, iter0, batch593/1133, batch loss:3.984453087468864e-06, Training time:90556.89089155197
batch reward last col mean 6.129098892415641e-06 first col mean 5.0199396355310455e-06 all mean 5.428171425592154e-05
4.969779183738865e-05 4.9697784561431035e-05
rl training, epoch5, iter0, batch594/1133, batch loss:4.9697784561431035e-05, Training time:90576.67274618149
batch reward last col mean 8.052020348259248e-06 first col mean 3.71450255443051e-06 all mean 1.6224788851104677e-05
1.4236852621252183e-05 1.4236852621252183e-05
rl training, epoch5, iter0, batch595/1133, batch loss:1.4236852621252183e-05, Training time:90594.70354866982
batch reward last col mean 1.6184681044251192e-06 first col mean 1.4187796750775306e-06 all mean 9.074121408048086e-06
3.6268268104322487e-06 3.6268252188165206e-06
rl training, epoch5, iter0, batch596/1133, batch loss:3.6268252188165206e-06, Training time:90614.15695476532
batch reward last col mean 5.5183874792419374e-05 first col mean 1.6251515262410976e-05 all mean 2.2308891857392155e-05
2.3540726033388637e-05 2.354072239540983e-05
rl training, epoch5, iter0, batch597/1133, batch loss:2.354072239540983e-05, Training time:90633.19722008705
batch reward last col mean 2.6533150958130136e-05 first col mean 9.743625014380086e-06 all mean 6.422730075428262e-05
1.2443989362509456e-05 1.2444003004929982e-05
rl training, epoch5, iter0, batch598/1133, batch loss:1.2444003004929982e-05, Training time:90653.13726115227
batch reward last col mean 8.155671821441501e-06 first col mean 1.8223909137304872e-05 all mean 2.470725121384021e-05
1.2868540579802357e-05 1.2868545127275866e-05
rl training, epoch5, iter0, batch599/1133, batch loss:1.2868545127275866e-05, Training time:90672.05061340332
batch reward last col mean 4.8570418584859e-06 first col mean 0.00014552214997820556 all mean 3.980758265242912e-05
1.454021276003914e-05 1.4540216398017947e-05
rl training, epoch5, iter0, batch600/1133, batch loss:1.4540216398017947e-05, Training time:90690.61832857132
batch reward last col mean 3.2318341709469678e-06 first col mean 2.4795513127173763e-06 all mean 3.975310755777173e-05
3.0418892492889427e-05 3.041888885491062e-05
rl training, epoch5, iter0, batch601/1133, batch loss:3.041888885491062e-05, Training time:90708.94012594223
batch reward last col mean 2.337637624805211e-06 first col mean 2.8813269636884797e-06 all mean 2.094006777042523e-05
5.906972091906937e-06 5.9069734561489895e-06
rl training, epoch5, iter0, batch602/1133, batch loss:5.9069734561489895e-06, Training time:90727.81539034843
batch reward last col mean 4.312202690925915e-06 first col mean 1.7588922673894558e-06 all mean 3.393585575395264e-05
1.0687837857403792e-05 1.0687832400435582e-05
rl training, epoch5, iter0, batch603/1133, batch loss:1.0687832400435582e-05, Training time:90746.54276657104
batch reward last col mean 5.801721272291616e-07 first col mean 5.3246321840560995e-06 all mean 3.893786924891174e-05
4.6790653868811205e-05 4.6790653868811205e-05
rl training, epoch5, iter0, batch604/1133, batch loss:4.6790653868811205e-05, Training time:90764.89124298096
batch reward last col mean 2.243474682472879e-06 first col mean 3.592093435145216e-06 all mean 3.8126014260342345e-05
2.8461177862482145e-05 2.8461177862482145e-05
rl training, epoch5, iter0, batch605/1133, batch loss:2.8461177862482145e-05, Training time:90782.84259343147
batch reward last col mean 6.491085514426231e-06 first col mean 0.00022901040210854262 all mean 2.173024768126197e-05
4.0147251638700254e-06 4.014725618617376e-06
rl training, epoch5, iter0, batch606/1133, batch loss:4.014725618617376e-06, Training time:90801.33670043945
batch reward last col mean 1.7483952206021058e-06 first col mean 7.770021284159156e-07 all mean 2.341277286177501e-05
1.0564313015493099e-05 1.0564309377514292e-05
rl training, epoch5, iter0, batch607/1133, batch loss:1.0564309377514292e-05, Training time:90819.68482613564
batch reward last col mean 1.123088804888539e-05 first col mean 2.3703352781012654e-05 all mean 3.3399759558960795e-05
1.9710463675437495e-05 1.9710460037458688e-05
rl training, epoch5, iter0, batch608/1133, batch loss:1.9710460037458688e-05, Training time:90836.78068518639
batch reward last col mean 2.7860285626957193e-05 first col mean 3.4799304557964206e-06 all mean 5.3930834837956354e-05
2.984060483868234e-05 2.9840617571608163e-05
rl training, epoch5, iter0, batch609/1133, batch loss:2.9840617571608163e-05, Training time:90855.7517426014
batch reward last col mean 4.191193511360325e-06 first col mean 3.294572525192052e-05 all mean 1.4283863492892124e-05
1.3046037565800361e-05 1.3046039384789765e-05
rl training, epoch5, iter0, batch610/1133, batch loss:1.3046039384789765e-05, Training time:90874.72780537605
batch reward last col mean 1.1412580533942673e-06 first col mean 7.266429747687653e-05 all mean 6.987795586610446e-06
1.0236956768494565e-05 1.0236956768494565e-05
rl training, epoch5, iter0, batch611/1133, batch loss:1.0236956768494565e-05, Training time:90892.97710680962
batch reward last col mean 2.412848516541999e-05 first col mean 9.409888662048616e-06 all mean 2.4088209102046676e-05
1.1500250366225373e-05 1.1500249456730671e-05
rl training, epoch5, iter0, batch612/1133, batch loss:1.1500249456730671e-05, Training time:90912.04288935661
batch reward last col mean 1.5142805978030083e-06 first col mean 9.525207360638888e-07 all mean 2.0827525077038445e-05
1.7383541717208573e-06 1.7383518979841028e-06
rl training, epoch5, iter0, batch613/1133, batch loss:1.7383518979841028e-06, Training time:90929.60563063622
batch reward last col mean 1.9403685200813925e-06 first col mean 1.7465569044361473e-06 all mean 2.691033841983881e-05
1.0095665857079439e-05 1.0095668585563544e-05
rl training, epoch5, iter0, batch614/1133, batch loss:1.0095668585563544e-05, Training time:90947.64724707603
batch reward last col mean 0.00015817154780961573 first col mean 3.8743171899113804e-05 all mean 3.6821798857999966e-05
5.822800085297786e-05 5.822799357702024e-05
rl training, epoch5, iter0, batch615/1133, batch loss:5.822799357702024e-05, Training time:90965.98778009415
batch reward last col mean 2.501993003534153e-05 first col mean 1.6073782944658888e-06 all mean 3.974374340032227e-05
4.7232235374394804e-05 4.723223901237361e-05
rl training, epoch5, iter0, batch616/1133, batch loss:4.723223901237361e-05, Training time:90984.6740205288
batch reward last col mean 1.6238704120041803e-05 first col mean 5.709032848244533e-06 all mean 2.5348746930831112e-05
1.0426554581499659e-05 1.0426557309983764e-05
rl training, epoch5, iter0, batch617/1133, batch loss:1.0426557309983764e-05, Training time:91004.28285312653
batch reward last col mean 1.6346424672519788e-05 first col mean 3.662525386971538e-06 all mean 6.492681131931022e-05
7.329457002924755e-05 7.329454820137471e-05
rl training, epoch5, iter0, batch618/1133, batch loss:7.329454820137471e-05, Training time:91023.50866031647
batch reward last col mean 1.1969284969381988e-05 first col mean 3.47763966601633e-06 all mean 1.5957504729158245e-05
8.547470315534156e-06 8.547468496544752e-06
rl training, epoch5, iter0, batch619/1133, batch loss:8.547468496544752e-06, Training time:91041.57459664345
batch reward last col mean 4.571018507704139e-06 first col mean 7.765721647956525e-07 all mean 1.2192846043035388e-05
1.0286681572324596e-05 1.0286681572324596e-05
rl training, epoch5, iter0, batch620/1133, batch loss:1.0286681572324596e-05, Training time:91059.42423462868
batch reward last col mean 9.923587640514597e-07 first col mean 1.1334926966810599e-05 all mean 2.6725063435151242e-05
1.8302922399016097e-05 1.830291876103729e-05
rl training, epoch5, iter0, batch621/1133, batch loss:1.830291876103729e-05, Training time:91077.52081847191
batch reward last col mean 3.615668447309872e-06 first col mean 1.2132071788073517e-05 all mean 2.8574475436471403e-05
2.0443707398953848e-05 2.0443707398953848e-05
rl training, epoch5, iter0, batch622/1133, batch loss:2.0443707398953848e-05, Training time:91095.02166485786
batch reward last col mean 1.0647527233231813e-05 first col mean 4.401543264975771e-06 all mean 2.349106034671422e-05
6.409442903532181e-06 6.409439720300725e-06
rl training, epoch5, iter0, batch623/1133, batch loss:6.409439720300725e-06, Training time:91113.23817205429
batch reward last col mean 1.4559361716237618e-06 first col mean 2.4587911866547074e-06 all mean 3.059958544326946e-05
2.6755258659250103e-05 2.67552568402607e-05
rl training, epoch5, iter0, batch624/1133, batch loss:2.67552568402607e-05, Training time:91131.37873458862
batch reward last col mean 1.7804361505113775e-06 first col mean 1.377995158691192e-05 all mean 2.4989838493638672e-05
1.2836112546210643e-05 1.283611072722124e-05
rl training, epoch5, iter0, batch625/1133, batch loss:1.283611072722124e-05, Training time:91148.77325820923
batch reward last col mean 1.1692936823237687e-06 first col mean 1.212664574268274e-05 all mean 2.209882586612366e-05
9.280558515456505e-06 9.280558515456505e-06
rl training, epoch5, iter0, batch626/1133, batch loss:9.280558515456505e-06, Training time:91167.18183803558
batch reward last col mean 2.6497159524296876e-06 first col mean 1.3164462870918214e-06 all mean 2.6042351237265393e-05
1.7630520233069547e-05 1.7630520233069547e-05
rl training, epoch5, iter0, batch627/1133, batch loss:1.7630520233069547e-05, Training time:91185.26610159874
batch reward last col mean 7.462037956429413e-07 first col mean 0.0004824036732316017 all mean 3.462327003944665e-05
8.511018677381799e-06 8.5110195868765e-06
rl training, epoch5, iter0, batch628/1133, batch loss:8.5110195868765e-06, Training time:91203.72534751892
batch reward last col mean 3.873254172503948e-06 first col mean 2.9471095331246033e-05 all mean 8.31708312034607e-05
5.478698221850209e-05 5.478699313243851e-05
rl training, epoch5, iter0, batch629/1133, batch loss:5.478699313243851e-05, Training time:91220.91301679611
batch reward last col mean 5.8384026488056406e-05 first col mean 1.1866360409840127e-06 all mean 8.23544105514884e-05
0.00012861388677265495 0.00012861390132457018
rl training, epoch5, iter0, batch630/1133, batch loss:0.00012861390132457018, Training time:91238.10026454926
batch reward last col mean 1.0415570841360022e-06 first col mean 5.087855242891237e-06 all mean 9.413033694727346e-06
6.273706731008133e-06 6.273706731008133e-06
rl training, epoch5, iter0, batch631/1133, batch loss:6.273706731008133e-06, Training time:91255.32149195671
batch reward last col mean 4.713299858849496e-06 first col mean 7.420048859785311e-06 all mean 2.1683976228814572e-05
1.0129449037776794e-05 1.012944721878739e-05
rl training, epoch5, iter0, batch632/1133, batch loss:1.012944721878739e-05, Training time:91274.5777323246
batch reward last col mean 2.2294871087069623e-06 first col mean 4.020917913294397e-06 all mean 2.986194522236474e-05
8.399173566431273e-06 8.399166290473659e-06
rl training, epoch5, iter0, batch633/1133, batch loss:8.399166290473659e-06, Training time:91293.0754301548
batch reward last col mean 4.6890722842363175e-06 first col mean 1.5096844663275988e-06 all mean 2.5730532797751948e-05
8.899677595763933e-06 8.89967577677453e-06
rl training, epoch5, iter0, batch634/1133, batch loss:8.89967577677453e-06, Training time:91311.14842319489
batch reward last col mean 6.785973255318822e-06 first col mean 5.08798484588624e-06 all mean 2.8065769583918154e-05
4.274842285667546e-05 4.274842285667546e-05
rl training, epoch5, iter0, batch635/1133, batch loss:4.274842285667546e-05, Training time:91329.06920218468
batch reward last col mean 2.2768135750084184e-06 first col mean 2.3606110062246444e-06 all mean 2.7027042960980907e-05
1.2952377801411785e-05 1.2952373253938276e-05
rl training, epoch5, iter0, batch636/1133, batch loss:1.2952373253938276e-05, Training time:91347.64433860779
batch reward last col mean 4.4178923417348415e-06 first col mean 6.312989171419758e-06 all mean 2.6199213607469574e-05
7.3617652560642455e-06 7.361762982327491e-06
rl training, epoch5, iter0, batch637/1133, batch loss:7.361762982327491e-06, Training time:91365.75111746788
batch reward last col mean 2.2068734324420802e-06 first col mean 3.723576810443774e-06 all mean 1.8762482795864344e-05
2.5602827008697204e-05 2.5602828827686608e-05
rl training, epoch5, iter0, batch638/1133, batch loss:2.5602828827686608e-05, Training time:91384.66659832001
batch reward last col mean 1.340298808827356e-06 first col mean 1.9316401449032128e-05 all mean 5.000569944968447e-05
2.3043961846269667e-05 2.3043954570312053e-05
rl training, epoch5, iter0, batch639/1133, batch loss:2.3043954570312053e-05, Training time:91402.5655195713
batch reward last col mean 4.536338019534014e-05 first col mean 2.73436830866558e-06 all mean 1.165997309726663e-05
7.971018021635246e-06 7.971019840624649e-06
rl training, epoch5, iter0, batch640/1133, batch loss:7.971019840624649e-06, Training time:91419.7403087616
batch reward last col mean 3.4617776236700593e-06 first col mean 1.8404580259812064e-06 all mean 2.4832117560436018e-05
2.1141648176126182e-05 2.114164271915797e-05
rl training, epoch5, iter0, batch641/1133, batch loss:2.114164271915797e-05, Training time:91438.1443734169
batch reward last col mean 9.878216360448278e-07 first col mean 2.358707661187509e-06 all mean 2.2256732336245477e-05
2.0248509827069938e-05 2.0248509827069938e-05
rl training, epoch5, iter0, batch642/1133, batch loss:2.0248509827069938e-05, Training time:91455.14543795586
batch reward last col mean 7.870701779211231e-07 first col mean 1.3630624380311929e-06 all mean 2.170836705772672e-05
3.1722989660920575e-05 3.172298602294177e-05
rl training, epoch5, iter0, batch643/1133, batch loss:3.172298602294177e-05, Training time:91472.11104083061
batch reward last col mean 1.4887697261656285e-06 first col mean 3.435665348661132e-06 all mean 3.4020380553556606e-05
1.4480777281278279e-05 1.4480770914815366e-05
rl training, epoch5, iter0, batch644/1133, batch loss:1.4480770914815366e-05, Training time:91489.77405309677
batch reward last col mean 4.889282718067989e-05 first col mean 9.202566616295371e-06 all mean 4.165026984992437e-05
1.5018135854916181e-05 1.5018131307442673e-05
rl training, epoch5, iter0, batch645/1133, batch loss:1.5018131307442673e-05, Training time:91507.75225377083
batch reward last col mean 2.4778935767244548e-05 first col mean 2.0124245565966703e-05 all mean 3.401010326342657e-05
4.4254917156649753e-05 4.4254917156649753e-05
rl training, epoch5, iter0, batch646/1133, batch loss:4.4254917156649753e-05, Training time:91526.88047671318
batch reward last col mean 5.75634976485162e-06 first col mean 5.3284534260455985e-06 all mean 3.1495077564613894e-05
5.339485596778104e-06 5.33948878000956e-06
rl training, epoch5, iter0, batch647/1133, batch loss:5.33948878000956e-06, Training time:91545.4541246891
batch reward last col mean 0.0031537250615656376 first col mean 1.5086994835655787e-06 all mean 0.001862633740529418
7.785019988659769e-05 7.785020716255531e-05
rl training, epoch5, iter0, batch648/1133, batch loss:7.785020716255531e-05, Training time:91563.80925559998
batch reward last col mean 1.0121955710928887e-05 first col mean 1.3270081353766727e-06 all mean 6.453155492636142e-06
5.560436875384767e-06 5.5604373301321175e-06
rl training, epoch5, iter0, batch649/1133, batch loss:5.5604373301321175e-06, Training time:91582.47705602646
batch reward last col mean 1.7850725271273404e-05 first col mean 1.642605980123335e-06 all mean 1.7501926777185872e-05
5.840526682732161e-06 5.840528501721565e-06
rl training, epoch5, iter0, batch650/1133, batch loss:5.840528501721565e-06, Training time:91600.79238247871
batch reward last col mean 4.572664238366997e-06 first col mean 2.7056078124587657e-06 all mean 1.7705569916870445e-05
5.915419023949653e-06 5.915419933444355e-06
rl training, epoch5, iter0, batch651/1133, batch loss:5.915419933444355e-06, Training time:91619.45310950279
batch reward last col mean 3.290202812422649e-06 first col mean 2.727207902353257e-05 all mean 1.9805336705758236e-05
2.9301056201802567e-05 2.9301056201802567e-05
rl training, epoch5, iter0, batch652/1133, batch loss:2.9301056201802567e-05, Training time:91638.18876361847
batch reward last col mean 1.3035111123826937e-06 first col mean 1.952598040588782e-06 all mean 3.55790471076034e-05
2.910363400587812e-05 2.9103635824867524e-05
rl training, epoch5, iter0, batch653/1133, batch loss:2.9103635824867524e-05, Training time:91656.67498159409
batch reward last col mean 7.970655815370264e-07 first col mean 1.6004316421458498e-05 all mean 7.722145710431505e-06
2.754621618805686e-06 2.754621618805686e-06
rl training, epoch5, iter0, batch654/1133, batch loss:2.754621618805686e-06, Training time:91674.95325779915
batch reward last col mean 7.403164659081085e-07 first col mean 4.272973455954343e-05 all mean 1.9008652088814415e-05
9.520492312731221e-06 9.520492312731221e-06
rl training, epoch5, iter0, batch655/1133, batch loss:9.520492312731221e-06, Training time:91693.01763725281
batch reward last col mean 8.470997272524983e-07 first col mean 3.367273848198238e-06 all mean 2.6092544430866838e-05
6.431476322177332e-06 6.431477231672034e-06
rl training, epoch5, iter0, batch656/1133, batch loss:6.431477231672034e-06, Training time:91711.94931650162
batch reward last col mean 3.231136133763357e-06 first col mean 1.7316987168669584e-06 all mean 4.1797982703428715e-05
4.781455572810955e-06 4.781460575031815e-06
rl training, epoch5, iter0, batch657/1133, batch loss:4.781460575031815e-06, Training time:91730.80157899857
batch reward last col mean 1.6561141819693148e-05 first col mean 9.568410860083532e-06 all mean 8.404692380281631e-06
6.8338522396516055e-06 6.833851784904255e-06
rl training, epoch5, iter0, batch658/1133, batch loss:6.833851784904255e-06, Training time:91747.93382501602
batch reward last col mean 5.2002320444444194e-05 first col mean 3.158173058182001e-06 all mean 2.7589008823269978e-05
8.83207394508645e-06 8.83207394508645e-06
rl training, epoch5, iter0, batch659/1133, batch loss:8.83207394508645e-06, Training time:91765.0231719017
batch reward last col mean 2.7199441774428124e-06 first col mean 1.1850489499920513e-05 all mean 2.666069849510677e-05
1.8698658095672727e-05 1.8698663552640937e-05
rl training, epoch5, iter0, batch660/1133, batch loss:1.8698663552640937e-05, Training time:91782.27674221992
batch reward last col mean 8.260306640295312e-05 first col mean 2.1570802346104756e-05 all mean 8.615657861810178e-05
3.8953483453951776e-05 3.8953472540015355e-05
rl training, epoch5, iter0, batch661/1133, batch loss:3.8953472540015355e-05, Training time:91801.15324902534
batch reward last col mean 8.347029734068201e-07 first col mean 3.3819965210568625e-06 all mean 5.559932833421044e-05
1.7444164768676274e-05 1.744415749271866e-05
rl training, epoch5, iter0, batch662/1133, batch loss:1.744415749271866e-05, Training time:91820.43619275093
batch reward last col mean 9.825506595007027e-07 first col mean 3.830018613371067e-06 all mean 4.618421007762663e-05
3.917598587577231e-05 3.9175971323857084e-05
rl training, epoch5, iter0, batch663/1133, batch loss:3.9175971323857084e-05, Training time:91838.85384964943
batch reward last col mean 2.2250233087106608e-06 first col mean 1.2038060958730057e-05 all mean 4.212243220536038e-05
8.428635192103684e-05 8.428633736912161e-05
rl training, epoch5, iter0, batch664/1133, batch loss:8.428633736912161e-05, Training time:91858.8486289978
batch reward last col mean 4.938205620419467e-06 first col mean 1.6811671912364545e-06 all mean 2.6174247977905907e-05
1.2953798432135954e-05 1.2953797522641253e-05
rl training, epoch5, iter0, batch665/1133, batch loss:1.2953797522641253e-05, Training time:91876.89019823074
batch reward last col mean 4.6773047870374285e-06 first col mean 2.1924015527474694e-05 all mean 3.991305493400432e-05
9.684608812676743e-05 9.684608085080981e-05
rl training, epoch5, iter0, batch666/1133, batch loss:9.684608085080981e-05, Training time:91895.21392917633
batch reward last col mean 1.2193106613267446e-06 first col mean 2.022407670665416e-06 all mean 2.093930379487574e-05
7.2739362622087356e-06 7.2739403549348935e-06
rl training, epoch5, iter0, batch667/1133, batch loss:7.2739403549348935e-06, Training time:91913.8792142868
batch reward last col mean 8.335647180501837e-06 first col mean 3.4964825772476615e-06 all mean 2.3821263312129304e-05
1.1433829968154896e-05 1.1433830877649598e-05
rl training, epoch5, iter0, batch668/1133, batch loss:1.1433830877649598e-05, Training time:91931.84863996506
batch reward last col mean 2.0792197119590128e-06 first col mean 0.00013718754053115845 all mean 2.4170143660739996e-05
3.640884870037553e-06 3.6408703181223245e-06
rl training, epoch5, iter0, batch669/1133, batch loss:3.6408703181223245e-06, Training time:91950.83223438263
batch reward last col mean 3.443741888986551e-06 first col mean 1.1911939509445801e-05 all mean 2.345270331716165e-05
6.134753220976563e-06 6.134754585218616e-06
rl training, epoch5, iter0, batch670/1133, batch loss:6.134754585218616e-06, Training time:91967.8818769455
batch reward last col mean 2.383462924626656e-05 first col mean 3.9540923353342805e-06 all mean 1.7944150386028923e-05
5.865808361704694e-06 5.8658110901887994e-06
rl training, epoch5, iter0, batch671/1133, batch loss:5.8658110901887994e-06, Training time:91985.94251585007
batch reward last col mean 5.796633558929898e-06 first col mean 1.209509377986251e-06 all mean 2.212958861491643e-05
1.8517908756621182e-05 1.851791239459999e-05
rl training, epoch5, iter0, batch672/1133, batch loss:1.851791239459999e-05, Training time:92005.01952552795
batch reward last col mean 4.859175533056259e-07 first col mean 2.6697973680711584e-06 all mean 5.903096462134272e-05
5.1110640924889594e-05 5.111063364893198e-05
rl training, epoch5, iter0, batch673/1133, batch loss:5.111063364893198e-05, Training time:92022.71024751663
batch reward last col mean 3.398891931283288e-05 first col mean 1.9274489204690326e-06 all mean 9.197375220537651e-06
4.926044766762061e-06 4.926043402520008e-06
rl training, epoch5, iter0, batch674/1133, batch loss:4.926043402520008e-06, Training time:92039.77581095695
batch reward last col mean 2.094524825224653e-05 first col mean 1.3207625215727603e-06 all mean 7.648071914445609e-06
3.206607061656541e-06 3.2066077437775675e-06
rl training, epoch5, iter0, batch675/1133, batch loss:3.2066077437775675e-06, Training time:92058.65458202362
batch reward last col mean 1.3056711622994044e-06 first col mean 3.972726062784204e-06 all mean 1.605254328751471e-05
9.200962267641444e-06 9.200958629662637e-06
rl training, epoch5, iter0, batch676/1133, batch loss:9.200958629662637e-06, Training time:92075.99872469902
batch reward last col mean 1.3956062048237072e-06 first col mean 8.13791120890528e-06 all mean 2.5388249923707917e-05
9.355107977171429e-06 9.35510888666613e-06
rl training, epoch5, iter0, batch677/1133, batch loss:9.35510888666613e-06, Training time:92094.93374443054
batch reward last col mean 6.807541649322957e-05 first col mean 1.7867160977402818e-06 all mean 2.6916164642898366e-05
1.8277958588441834e-05 1.827796222642064e-05
rl training, epoch5, iter0, batch678/1133, batch loss:1.827796222642064e-05, Training time:92113.81748509407
batch reward last col mean 4.6083045162959024e-05 first col mean 1.4537379229295766e-06 all mean 5.508197864401154e-05
6.720153032802045e-05 6.720153032802045e-05
rl training, epoch5, iter0, batch679/1133, batch loss:6.720153032802045e-05, Training time:92132.77993440628
batch reward last col mean 3.872426532325335e-06 first col mean 4.69038150185952e-06 all mean 7.51907064113766e-05
3.0507566407322884e-05 3.0507568226312287e-05
rl training, epoch5, iter0, batch680/1133, batch loss:3.0507568226312287e-05, Training time:92151.5692152977
batch reward last col mean 0.00043131853453814983 first col mean 2.1598887087748153e-06 all mean 0.00020841252990067005
1.9277098544989713e-05 1.9277100363979116e-05
rl training, epoch5, iter0, batch681/1133, batch loss:1.9277100363979116e-05, Training time:92170.51936864853
batch reward last col mean 8.580316716688685e-06 first col mean 2.324144361409708e-06 all mean 9.745736861077603e-06
9.442314876650926e-06 9.442314876650926e-06
rl training, epoch5, iter0, batch682/1133, batch loss:9.442314876650926e-06, Training time:92187.94658637047
batch reward last col mean 4.159098898526281e-05 first col mean 5.254044026514748e-06 all mean 6.202703661983833e-05
1.1552951946214307e-05 1.1552943760761991e-05
rl training, epoch5, iter0, batch683/1133, batch loss:1.1552943760761991e-05, Training time:92206.19390130043
batch reward last col mean 3.069354306717287e-06 first col mean 1.9435617559793172e-06 all mean 1.3481711903295945e-05
7.812251169525553e-06 7.812251169525553e-06
rl training, epoch5, iter0, batch684/1133, batch loss:7.812251169525553e-06, Training time:92224.01164412498
batch reward last col mean 0.004643165040761232 first col mean 1.6834381995067815e-06 all mean 0.0024766733404248953
0.00020723204943351448 0.00020723203488159925
rl training, epoch5, iter0, batch685/1133, batch loss:0.00020723203488159925, Training time:92242.1252617836
batch reward last col mean 3.178655606461689e-05 first col mean 1.1509979458423913e-06 all mean 2.219096313638147e-05
9.706416676635854e-06 9.70641485764645e-06
rl training, epoch5, iter0, batch686/1133, batch loss:9.70641485764645e-06, Training time:92259.20786261559
batch reward last col mean 1.4104033425610396e-06 first col mean 2.169150502595585e-05 all mean 1.9529823475750163e-05
1.0915899110841565e-05 1.0915900020336267e-05
rl training, epoch5, iter0, batch687/1133, batch loss:1.0915900020336267e-05, Training time:92276.36470460892
batch reward last col mean 1.908934336825041e-06 first col mean 1.3189501260058023e-06 all mean 3.524768544593826e-05
6.966033106436953e-05 6.966033834032714e-05
rl training, epoch5, iter0, batch688/1133, batch loss:6.966033834032714e-05, Training time:92293.36516571045
batch reward last col mean 0.00013366833445616066 first col mean 0.0005467496230266988 all mean 7.229416951304302e-05
3.23153508361429e-05 3.2315339922206476e-05
rl training, epoch5, iter0, batch689/1133, batch loss:3.2315339922206476e-05, Training time:92310.37513804436
batch reward last col mean 1.8640159396454692e-05 first col mean 2.109557954099728e-06 all mean 1.757306745275855e-05
6.071490588510642e-06 6.071489224268589e-06
rl training, epoch5, iter0, batch690/1133, batch loss:6.071489224268589e-06, Training time:92327.59017753601
batch reward last col mean 0.00023642033920623362 first col mean 2.8859949452453293e-06 all mean 2.2441972760134377e-05
1.588286795595195e-05 1.5882866136962548e-05
rl training, epoch5, iter0, batch691/1133, batch loss:1.5882866136962548e-05, Training time:92344.88587331772
batch reward last col mean 1.497567723163229e-06 first col mean 4.765615449286997e-05 all mean 5.221068568062037e-05
2.2128955606603995e-05 2.21289574255934e-05
rl training, epoch5, iter0, batch692/1133, batch loss:2.21289574255934e-05, Training time:92362.36160874367
batch reward last col mean 9.076750870917749e-07 first col mean 1.632250700822624e-06 all mean 2.2289055777946487e-05
1.865474223450292e-05 1.8654738596524112e-05
rl training, epoch5, iter0, batch693/1133, batch loss:1.8654738596524112e-05, Training time:92379.98141050339
batch reward last col mean 2.2569649900106015e-06 first col mean 8.00233283371199e-06 all mean 3.810043563134968e-05
2.124660022673197e-05 2.124660022673197e-05
rl training, epoch5, iter0, batch694/1133, batch loss:2.124660022673197e-05, Training time:92399.12338328362
batch reward last col mean 1.0209572792518884e-05 first col mean 8.868025361152831e-06 all mean 4.526679185801186e-05
1.3146079254511278e-05 1.3146076526027173e-05
rl training, epoch5, iter0, batch695/1133, batch loss:1.3146076526027173e-05, Training time:92418.38947033882
batch reward last col mean 1.244895202034968e-06 first col mean 0.00022014435671735555 all mean 3.213587842765264e-05
1.0895220839302056e-05 1.0895223567786161e-05
rl training, epoch5, iter0, batch696/1133, batch loss:1.0895223567786161e-05, Training time:92437.56082963943
batch reward last col mean 1.7855130636235117e-06 first col mean 1.2591044651344419e-06 all mean 2.2981837901170366e-05
6.231093720998615e-06 6.231092811503913e-06
rl training, epoch5, iter0, batch697/1133, batch loss:6.231092811503913e-06, Training time:92456.29097938538
batch reward last col mean 1.9055189568462083e-06 first col mean 2.738847615546547e-05 all mean 6.279545777942985e-05
3.120080509688705e-05 3.120081964880228e-05
rl training, epoch5, iter0, batch698/1133, batch loss:3.120081964880228e-05, Training time:92475.55208277702
batch reward last col mean 3.101853508269414e-05 first col mean 3.1536210371996276e-06 all mean 5.9156707720831037e-05
8.448099106317386e-05 8.448099833913147e-05
rl training, epoch5, iter0, batch699/1133, batch loss:8.448099833913147e-05, Training time:92493.72504544258
batch reward last col mean 4.699900273408275e-06 first col mean 2.377096734562656e-06 all mean 3.547567030182108e-05
1.0497979928913992e-05 1.0497980838408694e-05
rl training, epoch5, iter0, batch700/1133, batch loss:1.0497980838408694e-05, Training time:92512.15417218208
batch reward last col mean 0.00026504119159653783 first col mean 0.0009694944019429386 all mean 0.0001578512164996937
2.200929884565994e-05 2.200930794060696e-05
rl training, epoch5, iter0, batch701/1133, batch loss:2.200930794060696e-05, Training time:92531.12911701202
batch reward last col mean 3.0152381441439502e-05 first col mean 6.5205358623643406e-06 all mean 6.395057425834239e-05
4.657102908822708e-05 4.65710400021635e-05
rl training, epoch5, iter0, batch702/1133, batch loss:4.65710400021635e-05, Training time:92548.37470340729
batch reward last col mean 8.511738997185603e-06 first col mean 0.00013035642041359097 all mean 1.3549325558415148e-05
5.940504706813954e-06 5.940505616308656e-06
rl training, epoch5, iter0, batch703/1133, batch loss:5.940505616308656e-06, Training time:92566.49944853783
batch reward last col mean 3.8361795304808766e-06 first col mean 4.198606802674476e-06 all mean 2.9107724913046695e-05
1.618062196939718e-05 1.618061651242897e-05
rl training, epoch5, iter0, batch704/1133, batch loss:1.618061651242897e-05, Training time:92585.47836565971
batch reward last col mean 1.4814459063927643e-05 first col mean 9.785113661564537e-07 all mean 1.1810519026766997e-05
1.3466695236274973e-05 1.3466691598296165e-05
rl training, epoch5, iter0, batch705/1133, batch loss:1.3466691598296165e-05, Training time:92604.48501133919
batch reward last col mean 2.357814992137719e-06 first col mean 2.784529442578787e-06 all mean 2.7867241442436352e-05
1.548181171528995e-05 1.548181171528995e-05
rl training, epoch5, iter0, batch706/1133, batch loss:1.548181171528995e-05, Training time:92622.9089691639
batch reward last col mean 9.197767212754115e-06 first col mean 5.207054528000299e-06 all mean 2.53982962021837e-05
2.1744504920206964e-05 2.1744504920206964e-05
rl training, epoch5, iter0, batch707/1133, batch loss:2.1744504920206964e-05, Training time:92639.95365595818
batch reward last col mean 5.028619125369005e-05 first col mean 3.3205120416823775e-05 all mean 2.221414069936145e-05
1.4884699339745566e-05 1.4884698430250864e-05
rl training, epoch5, iter0, batch708/1133, batch loss:1.4884698430250864e-05, Training time:92657.91811609268
batch reward last col mean 1.723357490845956e-05 first col mean 9.186860552290455e-06 all mean 2.2586578779737465e-05
1.3158208275854122e-05 1.3158210094843525e-05
rl training, epoch5, iter0, batch709/1133, batch loss:1.3158210094843525e-05, Training time:92676.84999990463
batch reward last col mean 5.456723374663852e-05 first col mean 2.3064701508701546e-06 all mean 7.993796316441149e-05
2.632061114127282e-05 2.6320629331166856e-05
rl training, epoch5, iter0, batch710/1133, batch loss:2.6320629331166856e-05, Training time:92694.32904958725
batch reward last col mean 4.027883278467925e-06 first col mean 0.0001098484790418297 all mean 4.157975854468532e-05
2.609383409435395e-05 2.6093830456375144e-05
rl training, epoch5, iter0, batch711/1133, batch loss:2.6093830456375144e-05, Training time:92712.4037554264
batch reward last col mean 3.335959490868845e-06 first col mean 1.4724290849699173e-05 all mean 2.0878384020761587e-05
3.236510747228749e-05 3.236510747228749e-05
rl training, epoch5, iter0, batch712/1133, batch loss:3.236510747228749e-05, Training time:92731.87405085564
batch reward last col mean 3.3227913718292257e-06 first col mean 7.391678082058206e-06 all mean 2.728553045017179e-05
2.5334236852359027e-05 2.5334236852359027e-05
rl training, epoch5, iter0, batch713/1133, batch loss:2.5334236852359027e-05, Training time:92750.3336930275
batch reward last col mean 3.7332192732719705e-06 first col mean 1.8378719914835528e-06 all mean 4.788435035152361e-05
5.373130989028141e-05 5.373132080421783e-05
rl training, epoch5, iter0, batch714/1133, batch loss:5.373132080421783e-05, Training time:92768.65781021118
batch reward last col mean 2.1353180272853933e-06 first col mean 2.1379770259954967e-05 all mean 2.3190892534330487e-05
9.916799172060564e-06 9.916798262565862e-06
rl training, epoch5, iter0, batch715/1133, batch loss:9.916798262565862e-06, Training time:92787.22367119789
batch reward last col mean 1.8951141100842506e-06 first col mean 5.771653377451003e-06 all mean 6.45086620352231e-05
0.0001511020091129467 0.00015110199456103146
rl training, epoch5, iter0, batch716/1133, batch loss:0.00015110199456103146, Training time:92805.96842479706
batch reward last col mean 1.2561657740661758e-06 first col mean 2.210817683589994e-06 all mean 2.911642695835326e-05
1.931056431203615e-05 1.931056431203615e-05
rl training, epoch5, iter0, batch717/1133, batch loss:1.931056431203615e-05, Training time:92824.00646305084
batch reward last col mean 2.292062526976224e-05 first col mean 9.305847197538242e-05 all mean 6.809156911913306e-05
0.0001518571370979771 0.0001518571370979771
rl training, epoch5, iter0, batch718/1133, batch loss:0.0001518571370979771, Training time:92841.79837608337
batch reward last col mean 1.6940764453465817e-06 first col mean 5.387876626627985e-06 all mean 4.795443965122104e-05
2.4152373953256756e-05 2.4152372134267353e-05
rl training, epoch5, iter0, batch719/1133, batch loss:2.4152372134267353e-05, Training time:92860.67809152603
batch reward last col mean 0.0001243605511263013 first col mean 5.2382374633452855e-06 all mean 4.943102612742223e-05
4.733377863885835e-05 4.733377863885835e-05
rl training, epoch5, iter0, batch720/1133, batch loss:4.733377863885835e-05, Training time:92878.23719120026
batch reward last col mean 1.453447794119711e-06 first col mean 0.00017678416043054312 all mean 3.7184199754847214e-05
1.3455122825689614e-05 1.3455118278216105e-05
rl training, epoch5, iter0, batch721/1133, batch loss:1.3455118278216105e-05, Training time:92895.222240448
batch reward last col mean 1.1088246765211807e-06 first col mean 3.4999975468963385e-05 all mean 2.892180418712087e-05
9.139462235907558e-06 9.139466783381067e-06
rl training, epoch5, iter0, batch722/1133, batch loss:9.139466783381067e-06, Training time:92912.48655986786
batch reward last col mean 7.999078661669046e-07 first col mean 1.462544105379493e-06 all mean 1.2609090845216997e-05
5.19524110131897e-06 5.1952406465716194e-06
rl training, epoch5, iter0, batch723/1133, batch loss:5.1952406465716194e-06, Training time:92930.14770960808
batch reward last col mean 4.6515055146301165e-05 first col mean 5.728261385229416e-06 all mean 3.4037933801300824e-05
0.00012244128447491676 0.00012244128447491676
rl training, epoch5, iter0, batch724/1133, batch loss:0.00012244128447491676, Training time:92947.95839047432
batch reward last col mean 1.0152433560506324e-06 first col mean 6.786657195334556e-06 all mean 8.620844710094389e-06
1.2445174434105866e-05 1.2445172615116462e-05
rl training, epoch5, iter0, batch725/1133, batch loss:1.2445172615116462e-05, Training time:92965.05814790726
batch reward last col mean 2.1627471141982824e-05 first col mean 5.406178388511762e-06 all mean 4.129839362576604e-05
3.3943324524443597e-05 3.394333180040121e-05
rl training, epoch5, iter0, batch726/1133, batch loss:3.394333180040121e-05, Training time:92983.88299584389
batch reward last col mean 0.00032578554237261415 first col mean 2.800562469928991e-06 all mean 1.4543536053679418e-05
3.0005256121512502e-05 3.000525975949131e-05
rl training, epoch5, iter0, batch727/1133, batch loss:3.000525975949131e-05, Training time:93000.84262919426
batch reward last col mean 4.4880260929858196e-07 first col mean 5.950739250693005e-06 all mean 8.704058018338401e-06
1.120491015171865e-05 1.1204909242223948e-05
rl training, epoch5, iter0, batch728/1133, batch loss:1.1204909242223948e-05, Training time:93017.61656451225
batch reward last col mean 1.0436111779199564e-06 first col mean 1.1306822216283763e-06 all mean 2.9255717890919186e-05
1.1588486813707277e-05 1.1588484085223172e-05
rl training, epoch5, iter0, batch729/1133, batch loss:1.1588484085223172e-05, Training time:93034.32992815971
batch reward last col mean 0.0001696124963928014 first col mean 1.602623706276063e-05 all mean 6.143738573882729e-05
1.8914483007392846e-05 1.8914488464361057e-05
rl training, epoch5, iter0, batch730/1133, batch loss:1.8914488464361057e-05, Training time:93051.08532452583
batch reward last col mean 4.8230027459794655e-05 first col mean 2.702128313103458e-06 all mean 6.120863690739498e-05
2.4110871891025454e-05 2.4110857339110225e-05
rl training, epoch5, iter0, batch731/1133, batch loss:2.4110857339110225e-05, Training time:93068.74633836746
batch reward last col mean 2.637958459672518e-06 first col mean 1.781439777914784e-06 all mean 6.061068415874615e-05
2.8472581107052974e-05 2.8472586564021185e-05
rl training, epoch5, iter0, batch732/1133, batch loss:2.8472586564021185e-05, Training time:93087.58333516121
batch reward last col mean 4.229621026752284e-06 first col mean 8.027504009078257e-06 all mean 2.2411963072954677e-05
7.649506187590305e-06 7.649509825569112e-06
rl training, epoch5, iter0, batch733/1133, batch loss:7.649509825569112e-06, Training time:93106.44767785072
batch reward last col mean 1.6027731817302993e-06 first col mean 1.8349188621868961e-06 all mean 4.001961133326404e-05
7.883051694079768e-06 7.88305260357447e-06
rl training, epoch5, iter0, batch734/1133, batch loss:7.88305260357447e-06, Training time:93125.3168182373
batch reward last col mean 5.887069391974364e-07 first col mean 4.650485720958386e-07 all mean 3.334935536258854e-05
5.287180101731792e-06 5.287171916279476e-06
rl training, epoch5, iter0, batch735/1133, batch loss:5.287171916279476e-06, Training time:93143.98973345757
batch reward last col mean 1.0390924217063002e-05 first col mean 1.1325539162498899e-05 all mean 5.569345739786513e-05
8.767582767177373e-05 8.767582767177373e-05
rl training, epoch5, iter0, batch736/1133, batch loss:8.767582767177373e-05, Training time:93161.78486037254
batch reward last col mean 2.9591612928925315e-06 first col mean 4.105675088794669e-06 all mean 3.8639456761302426e-05
1.1360336429788731e-05 1.1360341886756942e-05
rl training, epoch5, iter0, batch737/1133, batch loss:1.1360341886756942e-05, Training time:93179.74816393852
batch reward last col mean 3.6916408134857193e-06 first col mean 6.9134657678660005e-06 all mean 5.1139209972461686e-05
2.806595148285851e-05 2.8065953301847912e-05
rl training, epoch5, iter0, batch738/1133, batch loss:2.8065953301847912e-05, Training time:93197.87555718422
batch reward last col mean 2.773936103039887e-06 first col mean 0.0015335557982325554 all mean 3.652841041912325e-05
1.2053305908921175e-05 1.2053310456394684e-05
rl training, epoch5, iter0, batch739/1133, batch loss:1.2053310456394684e-05, Training time:93215.19603347778
batch reward last col mean 5.489124532687129e-07 first col mean 1.3867854704585625e-06 all mean 4.89886588184163e-05
5.3555977501673624e-05 5.3555988415610045e-05
rl training, epoch5, iter0, batch740/1133, batch loss:5.3555988415610045e-05, Training time:93234.4605793953
batch reward last col mean 7.7079330367269e-06 first col mean 8.828603313304484e-06 all mean 2.2623898985330015e-05
1.522731690783985e-05 1.5227314179355744e-05
rl training, epoch5, iter0, batch741/1133, batch loss:1.5227314179355744e-05, Training time:93253.6369342804
batch reward last col mean 2.5470075343037024e-05 first col mean 1.0125370863534044e-05 all mean 4.661382990889251e-05
2.8570746508194134e-05 2.8570741051225923e-05
rl training, epoch5, iter0, batch742/1133, batch loss:2.8570741051225923e-05, Training time:93271.1129412651
batch reward last col mean 2.188800635849475e-06 first col mean 6.139263859950006e-06 all mean 5.165915717952885e-05
1.2389780749799684e-05 1.2389782568789087e-05
rl training, epoch5, iter0, batch743/1133, batch loss:1.2389782568789087e-05, Training time:93289.84324026108
batch reward last col mean 5.541549853660399e-06 first col mean 1.2307850738579873e-05 all mean 4.5768494601361454e-05
2.3130600311560556e-05 2.313060758751817e-05
rl training, epoch5, iter0, batch744/1133, batch loss:2.313060758751817e-05, Training time:93308.36588597298
batch reward last col mean 4.6570551148761297e-07 first col mean 2.2492367861559615e-06 all mean 3.0326384148793295e-05
6.689751899102703e-06 6.689751899102703e-06
rl training, epoch5, iter0, batch745/1133, batch loss:6.689751899102703e-06, Training time:93325.52986812592
batch reward last col mean 0.004756178706884384 first col mean 1.908337617351208e-05 all mean 0.003443993628025055
0.00016732839867472649 0.00016732842777855694
rl training, epoch5, iter0, batch746/1133, batch loss:0.00016732842777855694, Training time:93342.67250132561
batch reward last col mean 6.302570909610949e-07 first col mean 4.325703230279032e-06 all mean 2.288590621901676e-05
3.5822472455038223e-06 3.5822520203510066e-06
rl training, epoch5, iter0, batch747/1133, batch loss:3.5822520203510066e-06, Training time:93359.79095172882
batch reward last col mean 0.0015779531095176935 first col mean 2.397974412815529e-06 all mean 0.00010709030175348744
4.3532621930353343e-05 4.3532618292374536e-05
rl training, epoch5, iter0, batch748/1133, batch loss:4.3532618292374536e-05, Training time:93376.77332615852
batch reward last col mean 6.820960152253974e-06 first col mean 5.429474640550325e-06 all mean 4.058261765749194e-05
9.418602530786302e-06 9.4186016212916e-06
rl training, epoch5, iter0, batch749/1133, batch loss:9.4186016212916e-06, Training time:93394.89012265205
batch reward last col mean 0.0014739673351868987 first col mean 3.4429242532496573e-06 all mean 0.0007821207982487977
0.0002057690144283697 0.0002057690144283697
rl training, epoch5, iter0, batch750/1133, batch loss:0.0002057690144283697, Training time:93413.97570490837
batch reward last col mean 1.7660537423580536e-06 first col mean 2.1137921066838317e-05 all mean 2.6673946194932796e-05
8.388878632104024e-05 8.388878632104024e-05
rl training, epoch5, iter0, batch751/1133, batch loss:8.388878632104024e-05, Training time:93431.65041780472
batch reward last col mean 1.4728507267136592e-06 first col mean 1.0059928172267973e-05 all mean 3.7636797060258687e-05
1.0817122529260814e-05 1.081712071027141e-05
rl training, epoch5, iter0, batch752/1133, batch loss:1.081712071027141e-05, Training time:93448.86094546318
batch reward last col mean 3.5112366276734974e-06 first col mean 4.743591489386745e-06 all mean 2.0666288037318736e-05
4.973411250830395e-06 4.973409431840992e-06
rl training, epoch5, iter0, batch753/1133, batch loss:4.973409431840992e-06, Training time:93466.15091991425
batch reward last col mean 9.84108010015916e-06 first col mean 7.532674317189958e-06 all mean 3.86042520403862e-05
1.5233417798299342e-05 1.5233419617288746e-05
rl training, epoch5, iter0, batch754/1133, batch loss:1.5233419617288746e-05, Training time:93483.85416507721
batch reward last col mean 2.6007489850599086e-06 first col mean 2.429240794299403e-06 all mean 3.70390152966138e-05
5.582367066381266e-06 5.582375706580933e-06
rl training, epoch5, iter0, batch755/1133, batch loss:5.582375706580933e-06, Training time:93501.51225781441
batch reward last col mean 0.0016973220044746995 first col mean 1.0546411886025453e-06 all mean 0.0010518943890929222
8.334298763656989e-05 8.33429949125275e-05
rl training, epoch5, iter0, batch756/1133, batch loss:8.33429949125275e-05, Training time:93520.03256583214
batch reward last col mean 2.8827902497141622e-05 first col mean 3.2328230190614704e-06 all mean 4.350149538367987e-05
3.83236474590376e-05 3.83236474590376e-05
rl training, epoch5, iter0, batch757/1133, batch loss:3.83236474590376e-05, Training time:93537.05898213387
batch reward last col mean 2.6073819299199386e-06 first col mean 0.000600483501330018 all mean 4.8573012463748455e-05
9.97803817881504e-06 9.978040907299146e-06
rl training, epoch5, iter0, batch758/1133, batch loss:9.978040907299146e-06, Training time:93553.99987840652
batch reward last col mean 1.4133829608908854e-06 first col mean 5.703095212084008e-06 all mean 2.2417429136112332e-05
1.0036325875262264e-05 1.003632860374637e-05
rl training, epoch5, iter0, batch759/1133, batch loss:1.003632860374637e-05, Training time:93571.23506259918
batch reward last col mean 1.4999588984210277e-06 first col mean 3.0259993764047977e-06 all mean 4.919376442558132e-05
1.6530100765521638e-05 1.6530100765521638e-05
rl training, epoch5, iter0, batch760/1133, batch loss:1.6530100765521638e-05, Training time:93589.45159482956
batch reward last col mean 9.42403005410597e-07 first col mean 0.0010470990091562271 all mean 3.7091256672283635e-05
3.1509374821325764e-05 3.150938209728338e-05
rl training, epoch5, iter0, batch761/1133, batch loss:3.150938209728338e-05, Training time:93608.37869930267
batch reward last col mean 4.8587946366751567e-05 first col mean 5.2903480536770076e-05 all mean 4.777119465870783e-05
1.4184155588736758e-05 1.4184158317220863e-05
rl training, epoch5, iter0, batch762/1133, batch loss:1.4184158317220863e-05, Training time:93625.49000191689
batch reward last col mean 5.918123406445375e-06 first col mean 3.423862381168874e-06 all mean 5.263438288238831e-05
2.7473455702420324e-05 2.7473461159388535e-05
rl training, epoch5, iter0, batch763/1133, batch loss:2.7473461159388535e-05, Training time:93642.60948109627
batch reward last col mean 6.334454610623652e-06 first col mean 2.846919414878357e-06 all mean 5.954289372311905e-05
5.8835092204390094e-05 5.883508492843248e-05
rl training, epoch5, iter0, batch764/1133, batch loss:5.883508492843248e-05, Training time:93661.74519228935
batch reward last col mean 1.3280272241900093e-06 first col mean 8.964672701949894e-07 all mean 3.9008973544696346e-05
6.104445219534682e-06 6.104460680944612e-06
rl training, epoch5, iter0, batch765/1133, batch loss:6.104460680944612e-06, Training time:93680.25126457214
batch reward last col mean 2.2683698261971585e-05 first col mean 1.8906916920968797e-06 all mean 2.1436348106362857e-05
2.9768811145913787e-05 2.9768811145913787e-05
rl training, epoch5, iter0, batch766/1133, batch loss:2.9768811145913787e-05, Training time:93698.39760684967
batch reward last col mean 8.721806921130337e-07 first col mean 3.883164936269168e-06 all mean 2.120893623214215e-05
4.818650268134661e-05 4.818650268134661e-05
rl training, epoch5, iter0, batch767/1133, batch loss:4.818650268134661e-05, Training time:93717.30988717079
batch reward last col mean 8.220776521739026e-07 first col mean 7.638627721462399e-05 all mean 2.5566097974660806e-05
3.9225947148224805e-06 3.922596533811884e-06
rl training, epoch5, iter0, batch768/1133, batch loss:3.922596533811884e-06, Training time:93736.72552680969
batch reward last col mean 2.630596554809017e-06 first col mean 1.247757495548285e-06 all mean 4.714200986200012e-05
1.5024457752588205e-05 1.5024449567135889e-05
rl training, epoch5, iter0, batch769/1133, batch loss:1.5024449567135889e-05, Training time:93755.71900320053
batch reward last col mean 1.1094634828623384e-06 first col mean 1.1382664979464607e-06 all mean 3.481261228444055e-05
4.4095377234043553e-05 4.409536632010713e-05
rl training, epoch5, iter0, batch770/1133, batch loss:4.409536632010713e-05, Training time:93774.88038563728
batch reward last col mean 2.5535877284710295e-05 first col mean 0.0003376581589691341 all mean 3.3680451451800764e-05
6.946116172912298e-06 6.9461175371543504e-06
rl training, epoch5, iter0, batch771/1133, batch loss:6.9461175371543504e-06, Training time:93793.14095425606
batch reward last col mean 2.678869350347668e-06 first col mean 6.866060630272841e-06 all mean 5.280187542666681e-05
2.5673367417766713e-05 2.5673367417766713e-05
rl training, epoch5, iter0, batch772/1133, batch loss:2.5673367417766713e-05, Training time:93810.74574494362
batch reward last col mean 3.160369715260458e-06 first col mean 8.542051546100993e-06 all mean 7.940401701489463e-05
1.0167342225031462e-05 1.0167324035137426e-05
rl training, epoch5, iter0, batch773/1133, batch loss:1.0167324035137426e-05, Training time:93828.39559912682
batch reward last col mean 0.0002463405835442245 first col mean 0.00028496337472461164 all mean 4.7939556679921225e-05
2.353255513298791e-05 2.353255513298791e-05
rl training, epoch5, iter0, batch774/1133, batch loss:2.353255513298791e-05, Training time:93845.80958795547
batch reward last col mean 6.735851911798818e-07 first col mean 7.933768756629433e-06 all mean 4.686018655775115e-05
1.603026430530008e-05 1.603025521035306e-05
rl training, epoch5, iter0, batch775/1133, batch loss:1.603025521035306e-05, Training time:93863.27744054794
batch reward last col mean 5.294720540405251e-05 first col mean 1.2232093467900995e-05 all mean 2.503290852473583e-05
1.637420427869074e-05 1.6374206097680144e-05
rl training, epoch5, iter0, batch776/1133, batch loss:1.6374206097680144e-05, Training time:93880.69651818275
batch reward last col mean 0.0006204670062288642 first col mean 2.88305591311655e-06 all mean 4.078119673067704e-05
8.333592268172652e-05 8.333590812981129e-05
rl training, epoch5, iter0, batch777/1133, batch loss:8.333590812981129e-05, Training time:93897.77319645882
batch reward last col mean 2.0419411157490686e-06 first col mean 1.743677898957685e-06 all mean 3.0278102713054977e-05
1.8797960365191102e-05 1.87979585462017e-05
rl training, epoch5, iter0, batch778/1133, batch loss:1.87979585462017e-05, Training time:93916.00111699104
batch reward last col mean 1.8404417687634123e-06 first col mean 1.1178602790096193e-06 all mean 3.083632327616215e-05
6.306514478637837e-06 6.30651084065903e-06
rl training, epoch5, iter0, batch779/1133, batch loss:6.30651084065903e-06, Training time:93934.70763707161
batch reward last col mean 0.00031544530065730214 first col mean 8.282635462819599e-06 all mean 0.00017276982543990016
9.260371734853834e-05 9.260373190045357e-05
rl training, epoch5, iter0, batch780/1133, batch loss:9.260373190045357e-05, Training time:93953.3842291832
batch reward last col mean 0.00040407260530628264 first col mean 1.2468631211959291e-06 all mean 1.9395152776269242e-05
4.213051579426974e-05 4.2130523070227355e-05
rl training, epoch5, iter0, batch781/1133, batch loss:4.2130523070227355e-05, Training time:93970.53201270103
batch reward last col mean 7.069034381856909e-06 first col mean 3.137045496259816e-05 all mean 6.419146666303277e-05
1.559278643981088e-05 1.5592770068906248e-05
rl training, epoch5, iter0, batch782/1133, batch loss:1.5592770068906248e-05, Training time:93988.06281018257
batch reward last col mean 4.652514235203853e-06 first col mean 2.320840212632902e-05 all mean 3.173875666107051e-05
2.3396671167574823e-05 2.3396676624543034e-05
rl training, epoch5, iter0, batch783/1133, batch loss:2.3396676624543034e-05, Training time:94006.9948580265
batch reward last col mean 5.9118438002769835e-06 first col mean 1.8798934888764052e-06 all mean 2.6113073545275256e-05
8.433082984993234e-05 8.433082984993234e-05
rl training, epoch5, iter0, batch784/1133, batch loss:8.433082984993234e-05, Training time:94025.2493481636
batch reward last col mean 1.4882549294270575e-05 first col mean 0.0001179791142931208 all mean 5.014850466977805e-05
1.2892482118331827e-05 1.2892472113890108e-05
rl training, epoch5, iter0, batch785/1133, batch loss:1.2892472113890108e-05, Training time:94043.60849380493
batch reward last col mean 1.5565343346679583e-05 first col mean 1.3294320524437353e-06 all mean 4.4080778025090694e-05
5.138129199622199e-05 5.138128835824318e-05
rl training, epoch5, iter0, batch786/1133, batch loss:5.138128835824318e-05, Training time:94062.9115793705
batch reward last col mean 1.605349325473071e-06 first col mean 7.779905786264862e-07 all mean 2.6242054445901886e-05
9.963390766642988e-06 9.963388038158882e-06
rl training, epoch5, iter0, batch787/1133, batch loss:9.963388038158882e-06, Training time:94082.10568451881
batch reward last col mean 2.5016155632329173e-05 first col mean 0.00014405006368178874 all mean 2.9814118533977307e-05
1.722975866869092e-05 1.7229760487680323e-05
rl training, epoch5, iter0, batch788/1133, batch loss:1.7229760487680323e-05, Training time:94100.1584455967
batch reward last col mean 1.8206195818493143e-05 first col mean 2.047515044978354e-05 all mean 2.826890158758033e-05
1.4117297723714728e-05 1.411728862876771e-05
rl training, epoch5, iter0, batch789/1133, batch loss:1.411728862876771e-05, Training time:94118.68871212006
batch reward last col mean 4.238687324686907e-05 first col mean 0.0001967700372915715 all mean 5.173952376935631e-05
1.0982602361764293e-05 1.0982618732668925e-05
rl training, epoch5, iter0, batch790/1133, batch loss:1.0982618732668925e-05, Training time:94136.90168642998
batch reward last col mean 4.753170742333168e-06 first col mean 3.0300575417641085e-06 all mean 3.575536538846791e-05
2.020190549956169e-05 2.0201912775519304e-05
rl training, epoch5, iter0, batch791/1133, batch loss:2.0201912775519304e-05, Training time:94153.90137696266
batch reward last col mean 9.495764061284717e-06 first col mean 2.7685475743055576e-06 all mean 4.490297578740865e-05
8.041671389946714e-05 8.041670662350953e-05
rl training, epoch5, iter0, batch792/1133, batch loss:8.041670662350953e-05, Training time:94170.88586640358
batch reward last col mean 7.512577440138557e-07 first col mean 6.699347636640596e-07 all mean 1.4639294931839686e-05
7.735281542409211e-06 7.735282451903913e-06
rl training, epoch5, iter0, batch793/1133, batch loss:7.735282451903913e-06, Training time:94188.05752325058
batch reward last col mean 2.060397673631087e-05 first col mean 3.439759439061163e-06 all mean 4.9003159801941365e-05
1.3531427612178959e-05 1.3531440345104784e-05
rl training, epoch5, iter0, batch794/1133, batch loss:1.3531440345104784e-05, Training time:94206.40300893784
batch reward last col mean 1.9333149339217925e-06 first col mean 0.00020008521096315235 all mean 2.3342916392721236e-05
3.814234560195473e-06 3.814228421106236e-06
rl training, epoch5, iter0, batch795/1133, batch loss:3.814228421106236e-06, Training time:94225.32431864738
batch reward last col mean 2.751251258814591e-06 first col mean 4.246991011314094e-06 all mean 3.3981377782765776e-05
6.017439955030568e-05 6.0174403188284487e-05
rl training, epoch5, iter0, batch796/1133, batch loss:6.0174403188284487e-05, Training time:94244.16159844398
batch reward last col mean 2.7394151402404532e-05 first col mean 6.0241131905058865e-06 all mean 7.010941772023216e-05
4.134881237405352e-05 4.134881237405352e-05
rl training, epoch5, iter0, batch797/1133, batch loss:4.134881237405352e-05, Training time:94262.2143983841
batch reward last col mean 1.844380130933132e-05 first col mean 1.4436205901802168e-06 all mean 3.451636075624265e-05
7.26466350897681e-06 7.264655323524494e-06
rl training, epoch5, iter0, batch798/1133, batch loss:7.264655323524494e-06, Training time:94280.74333000183
batch reward last col mean 5.0925718824146315e-05 first col mean 2.524367118894588e-06 all mean 5.0232731155119836e-05
2.9145743610570207e-05 2.9145752705517225e-05
rl training, epoch5, iter0, batch799/1133, batch loss:2.9145752705517225e-05, Training time:94300.09523177147
batch reward last col mean 1.8199624491899158e-06 first col mean 7.599709988426184e-06 all mean 2.4419636247330345e-05
8.932654964155518e-06 8.932657692639623e-06
rl training, epoch5, iter0, batch800/1133, batch loss:8.932657692639623e-06, Training time:94319.10572361946
batch reward last col mean 1.367704044241691e-06 first col mean 3.0799910746281967e-06 all mean 5.0886890676338226e-05
2.4242799554485828e-05 2.4242806830443442e-05
rl training, epoch5, iter0, batch801/1133, batch loss:2.4242806830443442e-05, Training time:94338.07836008072
batch reward last col mean 2.994613168993965e-06 first col mean 2.8708741410810035e-06 all mean 7.93019135016948e-05
6.284633127506822e-05 6.284632399911061e-05
rl training, epoch5, iter0, batch802/1133, batch loss:6.284632399911061e-05, Training time:94355.57362437248
batch reward last col mean 2.0048466922162334e-06 first col mean 6.429001950891688e-05 all mean 3.143841240671463e-05
1.1181467925780453e-05 1.1181463378306944e-05
rl training, epoch5, iter0, batch803/1133, batch loss:1.1181463378306944e-05, Training time:94374.30795192719
batch reward last col mean 2.0064810541953193e-06 first col mean 9.091061656363308e-06 all mean 2.2683945644530468e-05
1.4660253327747341e-05 1.4660254237242043e-05
rl training, epoch5, iter0, batch804/1133, batch loss:1.4660254237242043e-05, Training time:94393.21157026291
batch reward last col mean 1.8752489268081263e-06 first col mean 1.4609305253543425e-05 all mean 4.0026843635132536e-05
6.476605631178245e-05 6.476605631178245e-05
rl training, epoch5, iter0, batch805/1133, batch loss:6.476605631178245e-05, Training time:94411.77126407623
batch reward last col mean 1.7179211226903135e-06 first col mean 8.457436706521548e-06 all mean 4.991922833141871e-05
2.1061432562419213e-05 2.1061427105451003e-05
rl training, epoch5, iter0, batch806/1133, batch loss:2.1061427105451003e-05, Training time:94429.25169062614
batch reward last col mean 1.567649633216206e-06 first col mean 3.1347151434601983e-06 all mean 2.5761875804164447e-05
8.184999387594871e-06 8.184987564163748e-06
rl training, epoch5, iter0, batch807/1133, batch loss:8.184987564163748e-06, Training time:94448.32167887688
batch reward last col mean 0.007611072156578302 first col mean 1.97858244064264e-05 all mean 0.007410257589071989
0.000649857334792614 0.000649857334792614
rl training, epoch5, iter0, batch808/1133, batch loss:0.000649857334792614, Training time:94466.94390797615
batch reward last col mean 5.163999503565719e-06 first col mean 4.403699676913675e-06 all mean 1.1920568795176223e-05
4.946581157128094e-06 4.946581157128094e-06
rl training, epoch5, iter0, batch809/1133, batch loss:4.946581157128094e-06, Training time:94484.8068716526
batch reward last col mean 5.275193871057127e-06 first col mean 1.4588880503652035e-06 all mean 4.056043326272629e-05
1.7670354282017797e-05 1.767035064403899e-05
rl training, epoch5, iter0, batch810/1133, batch loss:1.767035064403899e-05, Training time:94502.54774546623
batch reward last col mean 1.1452042599557899e-05 first col mean 9.606180810806109e-07 all mean 5.831686212331988e-05
3.282351099187508e-05 3.282351099187508e-05
rl training, epoch5, iter0, batch811/1133, batch loss:3.282351099187508e-05, Training time:94521.02831673622
batch reward last col mean 4.65922785224393e-05 first col mean 0.00011766399256885052 all mean 5.152563244337216e-05
2.6009083740063943e-05 2.6009078283095732e-05
rl training, epoch5, iter0, batch812/1133, batch loss:2.6009078283095732e-05, Training time:94539.51458740234
batch reward last col mean 5.680944013874978e-06 first col mean 1.8712852352109621e-06 all mean 4.1339117160532624e-05
1.1795302270911634e-05 1.179530045192223e-05
rl training, epoch5, iter0, batch813/1133, batch loss:1.179530045192223e-05, Training time:94557.63386654854
batch reward last col mean 8.556539796700235e-07 first col mean 1.838617208704818e-05 all mean 3.7475030694622546e-05
3.12565389322117e-05 3.125652438029647e-05
rl training, epoch5, iter0, batch814/1133, batch loss:3.125652438029647e-05, Training time:94576.20300531387
batch reward last col mean 1.2936314988110098e-06 first col mean 6.581182788067963e-06 all mean 2.8274840587982908e-05
1.2579715075844433e-05 1.2579715985339135e-05
rl training, epoch5, iter0, batch815/1133, batch loss:1.2579715985339135e-05, Training time:94595.44844865799
batch reward last col mean 2.4254570689663524e-06 first col mean 6.952666808501817e-06 all mean 4.248493132763542e-05
6.509700597234769e-06 6.509700142487418e-06
rl training, epoch5, iter0, batch816/1133, batch loss:6.509700142487418e-06, Training time:94614.3591837883
batch reward last col mean 8.144903631546185e-07 first col mean 1.4938295862521045e-05 all mean 1.9777777197305113e-05
1.3908061191614252e-05 1.3908053915656637e-05
rl training, epoch5, iter0, batch817/1133, batch loss:1.3908053915656637e-05, Training time:94632.8170940876
batch reward last col mean 1.140193944593193e-06 first col mean 5.356252131605288e-06 all mean 1.436326692783041e-05
3.092370207014028e-06 3.0923654321668437e-06
rl training, epoch5, iter0, batch818/1133, batch loss:3.0923654321668437e-06, Training time:94650.46446037292
batch reward last col mean 1.2146981589467032e-06 first col mean 3.5682580346474424e-05 all mean 3.2140465918928385e-05
2.4268272682093084e-05 2.4268267225124873e-05
rl training, epoch5, iter0, batch819/1133, batch loss:2.4268267225124873e-05, Training time:94669.32203292847
batch reward last col mean 4.899170562566724e-06 first col mean 1.8561970591690624e-06 all mean 3.4408600185997784e-05
1.531145790067967e-05 1.5311466995626688e-05
rl training, epoch5, iter0, batch820/1133, batch loss:1.5311466995626688e-05, Training time:94688.26081609726
batch reward last col mean 2.7513299301062943e-06 first col mean 1.9319800230732653e-06 all mean 1.501579572504852e-05
4.048165919812163e-06 4.048166374559514e-06
rl training, epoch5, iter0, batch821/1133, batch loss:4.048166374559514e-06, Training time:94707.06769800186
batch reward last col mean 6.825139735155972e-06 first col mean 1.7649348365011974e-06 all mean 1.424718811904313e-05
5.933714874117868e-06 5.933714419370517e-06
rl training, epoch5, iter0, batch822/1133, batch loss:5.933714419370517e-06, Training time:94724.767203331
batch reward last col mean 7.943420496303588e-05 first col mean 4.6936707803979516e-05 all mean 2.5618437575758435e-05
2.0295687136240304e-05 2.0295687136240304e-05
rl training, epoch5, iter0, batch823/1133, batch loss:2.0295687136240304e-05, Training time:94741.84056210518
batch reward last col mean 5.717640306102112e-06 first col mean 0.0004554644401650876 all mean 3.7937275919830427e-05
1.151893229689449e-05 1.1518931387399789e-05
rl training, epoch5, iter0, batch824/1133, batch loss:1.1518931387399789e-05, Training time:94760.35286855698
batch reward last col mean 3.449139967415249e-06 first col mean 0.0016098141204565763 all mean 0.00010867973469430581
3.184167871950194e-05 3.1841675081523135e-05
rl training, epoch5, iter0, batch825/1133, batch loss:3.1841675081523135e-05, Training time:94778.26084828377
batch reward last col mean 0.0028914627619087696 first col mean 5.8694076869869605e-06 all mean 0.0010180138051509857
0.00018868061306420714 0.00018868061306420714
rl training, epoch5, iter0, batch826/1133, batch loss:0.00018868061306420714, Training time:94795.36036872864
batch reward last col mean 6.312560003607359e-07 first col mean 2.590773647170863e-06 all mean 1.2282756870263256e-05
6.810686500102747e-06 6.810686500102747e-06
rl training, epoch5, iter0, batch827/1133, batch loss:6.810686500102747e-06, Training time:94813.84303951263
batch reward last col mean 2.829555705829989e-05 first col mean 2.2538229131896514e-06 all mean 2.106440661009401e-05
5.184911515243584e-06 5.184909696254181e-06
rl training, epoch5, iter0, batch828/1133, batch loss:5.184909696254181e-06, Training time:94830.93546509743
batch reward last col mean 2.1205455595918465e-06 first col mean 8.29895452625351e-06 all mean 6.464539183070883e-05
3.3471347705926746e-05 3.3471336791990325e-05
rl training, epoch5, iter0, batch829/1133, batch loss:3.3471336791990325e-05, Training time:94849.99966573715
batch reward last col mean 5.7727193052414805e-06 first col mean 1.255378720088629e-06 all mean 3.542179547366686e-05
1.6046642485889606e-05 1.6046642485889606e-05
rl training, epoch5, iter0, batch830/1133, batch loss:1.6046642485889606e-05, Training time:94869.44807839394
batch reward last col mean 0.00013151047460269183 first col mean 4.2519990529399365e-05 all mean 4.053500742884353e-05
1.9206767319701612e-05 1.92067618627334e-05
rl training, epoch5, iter0, batch831/1133, batch loss:1.92067618627334e-05, Training time:94888.68172574043
batch reward last col mean 1.682318361417856e-05 first col mean 2.836758085322799e-06 all mean 2.9487198844435625e-05
3.0194059945642948e-05 3.019405630766414e-05
rl training, epoch5, iter0, batch832/1133, batch loss:3.019405630766414e-05, Training time:94906.77020430565
batch reward last col mean 3.17056628773571e-06 first col mean 0.00032914531766436994 all mean 4.2237112211296335e-05
1.6731391951907426e-05 1.673139377089683e-05
rl training, epoch5, iter0, batch833/1133, batch loss:1.673139377089683e-05, Training time:94924.50812649727
batch reward last col mean 4.188777438685065e-06 first col mean 8.73562657943694e-06 all mean 2.428403422527481e-05
1.3360852790356148e-05 1.3360852790356148e-05
rl training, epoch5, iter0, batch834/1133, batch loss:1.3360852790356148e-05, Training time:94941.67761874199
batch reward last col mean 1.6116500773932785e-05 first col mean 8.642589932605915e-07 all mean 4.5769218559144065e-05
4.251378049957566e-05 4.251378049957566e-05
rl training, epoch5, iter0, batch835/1133, batch loss:4.251378049957566e-05, Training time:94959.54544997215
batch reward last col mean 3.6669378005171893e-06 first col mean 1.4187866099746316e-06 all mean 1.782776234904304e-05
9.343569217890035e-06 9.343571036879439e-06
rl training, epoch5, iter0, batch836/1133, batch loss:9.343571036879439e-06, Training time:94976.8228764534
batch reward last col mean 2.6670345505408477e-06 first col mean 4.010846168966964e-06 all mean 2.7452659196569584e-05
8.490030268148985e-06 8.490022082696669e-06
rl training, epoch5, iter0, batch837/1133, batch loss:8.490022082696669e-06, Training time:94994.70047926903
batch reward last col mean 8.400025990340509e-07 first col mean 1.0306524700354203e-06 all mean 2.7921003493247554e-05
3.678193752421066e-05 3.678193752421066e-05
rl training, epoch5, iter0, batch838/1133, batch loss:3.678193752421066e-05, Training time:95011.74868679047
batch reward last col mean 1.013283736028825e-06 first col mean 5.324624362401664e-05 all mean 5.471886834129691e-05
2.933297037088778e-05 2.9332968551898375e-05
rl training, epoch5, iter0, batch839/1133, batch loss:2.9332968551898375e-05, Training time:95028.93374538422
batch reward last col mean 8.462084224447608e-06 first col mean 5.019015588914044e-05 all mean 2.6600371711538173e-05
9.129093996307347e-06 9.129093996307347e-06
rl training, epoch5, iter0, batch840/1133, batch loss:9.129093996307347e-06, Training time:95046.97097706795
batch reward last col mean 0.0009689675644040108 first col mean 3.6178739719616715e-06 all mean 0.00042141680023632944
9.595219307811931e-05 9.59521858021617e-05
rl training, epoch5, iter0, batch841/1133, batch loss:9.59521858021617e-05, Training time:95066.0359659195
batch reward last col mean 1.8030388673651032e-05 first col mean 0.00025761971483007073 all mean 6.683752144454047e-05
1.847516068664845e-05 1.8475151591701433e-05
rl training, epoch5, iter0, batch842/1133, batch loss:1.8475151591701433e-05, Training time:95084.88198375702
batch reward last col mean 0.00016027726815082133 first col mean 5.270666224532761e-05 all mean 1.0090770956594497e-05
1.3699755072593689e-05 1.3699752344109584e-05
rl training, epoch5, iter0, batch843/1133, batch loss:1.3699752344109584e-05, Training time:95103.93628692627
batch reward last col mean 0.0002662573824636638 first col mean 5.9637245612975676e-06 all mean 0.00032977256341837347
0.00019094366871286184 0.00019094371236860752
rl training, epoch5, iter0, batch844/1133, batch loss:0.00019094371236860752, Training time:95123.01432657242
batch reward last col mean 1.8600117073219735e-06 first col mean 3.0622873055108357e-06 all mean 3.964440111303702e-05
1.4432734133151826e-05 1.4432725038204808e-05
rl training, epoch5, iter0, batch845/1133, batch loss:1.4432725038204808e-05, Training time:95142.04511642456
batch reward last col mean 1.3918750028096838e-06 first col mean 2.4592175122961635e-06 all mean 2.4409459001617506e-05
7.830151844245847e-06 7.830147296772338e-06
rl training, epoch5, iter0, batch846/1133, batch loss:7.830147296772338e-06, Training time:95161.8033092022
batch reward last col mean 1.618958958715666e-05 first col mean 5.189210696698865e-06 all mean 1.8230695786769502e-05
5.653677817463176e-06 5.653682364936685e-06
rl training, epoch5, iter0, batch847/1133, batch loss:5.653682364936685e-06, Training time:95179.35059070587
batch reward last col mean 3.0567575777240563e-06 first col mean 1.3379089978116099e-06 all mean 2.6743013222585432e-05
7.079240276652854e-06 7.079232091200538e-06
rl training, epoch5, iter0, batch848/1133, batch loss:7.079232091200538e-06, Training time:95196.87577962875
batch reward last col mean 1.3303753803484142e-05 first col mean 3.3398482628399506e-06 all mean 5.9471887652762234e-05
2.4819522877805866e-05 2.4819539248710498e-05
rl training, epoch5, iter0, batch849/1133, batch loss:2.4819539248710498e-05, Training time:95214.27025604248
batch reward last col mean 1.1464638873803779e-06 first col mean 2.4233390831795987e-06 all mean 4.386216096463613e-05
6.100354221416637e-05 6.100353493820876e-05
rl training, epoch5, iter0, batch850/1133, batch loss:6.100353493820876e-05, Training time:95233.76953577995
batch reward last col mean 3.8608250179095194e-05 first col mean 9.099650924326852e-06 all mean 4.22107768827118e-05
3.330373510834761e-05 3.3303727832389995e-05
rl training, epoch5, iter0, batch851/1133, batch loss:3.3303727832389995e-05, Training time:95253.06801652908
batch reward last col mean 1.5286382222257089e-06 first col mean 1.3130264051142149e-05 all mean 8.492392225889489e-05
6.94125410518609e-05 6.941255560377613e-05
rl training, epoch5, iter0, batch852/1133, batch loss:6.941255560377613e-05, Training time:95270.27516412735
batch reward last col mean 5.074334126220492e-07 first col mean 2.7389105525799096e-06 all mean 6.0354261222528294e-05
3.317590744700283e-05 3.3175900171045214e-05
rl training, epoch5, iter0, batch853/1133, batch loss:3.3175900171045214e-05, Training time:95287.80830979347
batch reward last col mean 0.0027162637561559677 first col mean 1.485336269979598e-06 all mean 0.0007713868981227279
0.00010808309161802754 0.00010808308434206992
rl training, epoch5, iter0, batch854/1133, batch loss:0.00010808308434206992, Training time:95306.24007105827
batch reward last col mean 0.0012211923021823168 first col mean 5.064481229055673e-06 all mean 5.094824518891983e-05
0.00011383218225091696 0.00011383218225091696
rl training, epoch5, iter0, batch855/1133, batch loss:0.00011383218225091696, Training time:95323.35471844673
batch reward last col mean 1.231597480000346e-06 first col mean 4.127004103793297e-06 all mean 2.086754102492705e-05
1.502378290751949e-05 1.5023787454992998e-05
rl training, epoch5, iter0, batch856/1133, batch loss:1.5023787454992998e-05, Training time:95341.46533179283
batch reward last col mean 3.50281970895594e-06 first col mean 1.8425598682370037e-06 all mean 1.7595379176782444e-05
2.519194094929844e-05 2.519194094929844e-05
rl training, epoch5, iter0, batch857/1133, batch loss:2.519194094929844e-05, Training time:95359.08395314217
batch reward last col mean 5.479013907461194e-06 first col mean 1.0504742022021674e-05 all mean 5.284119106363505e-05
6.855962419649586e-05 6.855962419649586e-05
rl training, epoch5, iter0, batch858/1133, batch loss:6.855962419649586e-05, Training time:95377.64399051666
batch reward last col mean 1.1704155440384056e-06 first col mean 2.0924089767504483e-05 all mean 3.295577334938571e-05
1.3532851880881935e-05 1.3532852790376637e-05
rl training, epoch5, iter0, batch859/1133, batch loss:1.3532852790376637e-05, Training time:95395.93416070938
batch reward last col mean 1.0023461527453037e-06 first col mean 2.814273557305569e-06 all mean 4.658325997297652e-05
1.0896253115788568e-05 1.0896262210735586e-05
rl training, epoch5, iter0, batch860/1133, batch loss:1.0896262210735586e-05, Training time:95414.01027607918
batch reward last col mean 9.912079804053064e-06 first col mean 5.5008863455441315e-06 all mean 9.605121158529073e-05
0.0001829086832003668 0.0001829086832003668
rl training, epoch5, iter0, batch861/1133, batch loss:0.0001829086832003668, Training time:95432.11798429489
batch reward last col mean 7.577346536891127e-07 first col mean 2.7529872568266e-06 all mean 5.9417383454274386e-05
3.365235170349479e-05 3.365234442753717e-05
rl training, epoch5, iter0, batch862/1133, batch loss:3.365234442753717e-05, Training time:95449.17465949059
batch reward last col mean 1.6779969200797495e-06 first col mean 5.259783392830286e-06 all mean 3.341437331982888e-05
2.4983721232274547e-05 2.4983715775306337e-05
rl training, epoch5, iter0, batch863/1133, batch loss:2.4983715775306337e-05, Training time:95466.63409948349
batch reward last col mean 3.024905936399591e-06 first col mean 1.6137005331984255e-06 all mean 2.4706469048396684e-05
2.74629783234559e-05 2.74629783234559e-05
rl training, epoch5, iter0, batch864/1133, batch loss:2.74629783234559e-05, Training time:95484.2631251812
batch reward last col mean 7.005157840467291e-06 first col mean 9.205134119838476e-05 all mean 1.8525613995734602e-05
2.6426832846482284e-05 2.6426832846482284e-05
rl training, epoch5, iter0, batch865/1133, batch loss:2.6426832846482284e-05, Training time:95502.02640271187
batch reward last col mean 2.536537294872687e-06 first col mean 6.557851065736031e-06 all mean 1.740738116495777e-05
6.835991825937526e-06 6.835989552200772e-06
rl training, epoch5, iter0, batch866/1133, batch loss:6.835989552200772e-06, Training time:95519.50405478477
batch reward last col mean 0.005187283270061016 first col mean 1.2551102372526657e-05 all mean 0.00011500548862386495
0.00034262880217283964 0.00034262880217283964
rl training, epoch5, iter0, batch867/1133, batch loss:0.00034262880217283964, Training time:95537.06907439232
batch reward last col mean 0.0001465831883251667 first col mean 7.156695937737823e-05 all mean 0.00010555109474807978
4.951197843183763e-05 4.951197115588002e-05
rl training, epoch5, iter0, batch868/1133, batch loss:4.951197115588002e-05, Training time:95555.08932638168
batch reward last col mean 0.0007664226577617228 first col mean 0.000108444168290589 all mean 0.00013093800225760788
2.2657657609670423e-05 2.2657657609670423e-05
rl training, epoch5, iter0, batch869/1133, batch loss:2.2657657609670423e-05, Training time:95572.99012255669
batch reward last col mean 1.8180143115387182e-06 first col mean 2.452014450682327e-05 all mean 5.677809167536907e-05
2.2202793843462132e-05 2.2202793843462132e-05
rl training, epoch5, iter0, batch870/1133, batch loss:2.2202793843462132e-05, Training time:95591.3419213295
batch reward last col mean 5.371316547098104e-06 first col mean 1.2979864550288767e-05 all mean 2.8652482797042467e-05
1.65403416758636e-05 1.6540339856874198e-05
rl training, epoch5, iter0, batch871/1133, batch loss:1.6540339856874198e-05, Training time:95610.54636383057
batch reward last col mean 1.6177566521946574e-06 first col mean 7.489185372833163e-05 all mean 5.2945561037631705e-05
4.185051147942431e-05 4.1850507841445506e-05
rl training, epoch5, iter0, batch872/1133, batch loss:4.1850507841445506e-05, Training time:95629.52605652809
batch reward last col mean 4.323988378018839e-06 first col mean 0.0002700788318179548 all mean 5.68333052797243e-05
1.4327710232464597e-05 1.4327714779938105e-05
rl training, epoch5, iter0, batch873/1133, batch loss:1.4327714779938105e-05, Training time:95646.72995257378
batch reward last col mean 1.956122787305503e-06 first col mean 2.4054234017967246e-06 all mean 5.742973371525295e-05
2.6781350243254565e-05 2.6781346605275758e-05
rl training, epoch5, iter0, batch874/1133, batch loss:2.6781346605275758e-05, Training time:95665.13203191757
batch reward last col mean 8.111981628644571e-07 first col mean 3.2300713428412564e-06 all mean 1.704643182165455e-05
1.1575716598599683e-05 1.1575716598599683e-05
rl training, epoch5, iter0, batch875/1133, batch loss:1.1575716598599683e-05, Training time:95683.4023399353
batch reward last col mean 6.95171411280171e-06 first col mean 2.67136529146228e-05 all mean 2.152025444956962e-05
1.0488467523828149e-05 1.0488467523828149e-05
rl training, epoch5, iter0, batch876/1133, batch loss:1.0488467523828149e-05, Training time:95702.33433389664
batch reward last col mean 0.00017595733515918255 first col mean 5.817883356940001e-05 all mean 3.0366498322109692e-05
2.4014128939597867e-05 2.4014128939597867e-05
rl training, epoch5, iter0, batch877/1133, batch loss:2.4014128939597867e-05, Training time:95720.2974588871
batch reward last col mean 5.783008236903697e-05 first col mean 4.532653747446602e-06 all mean 4.809261372429319e-05
2.4693095838301815e-05 2.4693095838301815e-05
rl training, epoch5, iter0, batch878/1133, batch loss:2.4693095838301815e-05, Training time:95737.70171618462
batch reward last col mean 1.9342912764841458e-06 first col mean 4.222810730425408e-06 all mean 3.013902278325986e-05
2.702540768950712e-05 2.702540223253891e-05
rl training, epoch5, iter0, batch879/1133, batch loss:2.702540223253891e-05, Training time:95755.0925552845
batch reward last col mean 5.52329811398522e-06 first col mean 7.239680599013809e-06 all mean 2.472187225066591e-05
5.0243734222021885e-06 5.0243734222021885e-06
rl training, epoch5, iter0, batch880/1133, batch loss:5.0243734222021885e-06, Training time:95772.40763545036
batch reward last col mean 1.8279986306879437e-06 first col mean 6.723674232489429e-06 all mean 1.5446177712874487e-05
2.4229188966273796e-06 2.422923671474564e-06
rl training, epoch5, iter0, batch881/1133, batch loss:2.422923671474564e-06, Training time:95789.98258042336
batch reward last col mean 3.3791052373999264e-06 first col mean 1.653343133511953e-06 all mean 2.120978751918301e-05
8.48025501909433e-06 8.480259566567838e-06
rl training, epoch5, iter0, batch882/1133, batch loss:8.480259566567838e-06, Training time:95807.447306633
batch reward last col mean 8.269102181657217e-06 first col mean 0.00011068919411627576 all mean 5.672759289154783e-05
5.0793300033546984e-05 5.079329275758937e-05
rl training, epoch5, iter0, batch883/1133, batch loss:5.079329275758937e-05, Training time:95825.19333767891
batch reward last col mean 2.8520894375105854e-06 first col mean 3.8094692627055338e-06 all mean 2.3049024093779735e-05
6.96725783200236e-06 6.967260105739115e-06
rl training, epoch5, iter0, batch884/1133, batch loss:6.967260105739115e-06, Training time:95842.63568472862
batch reward last col mean 9.226535439665895e-06 first col mean 2.13346697819361e-06 all mean 6.41509031993337e-05
2.5687839297461323e-05 2.568783202150371e-05
rl training, epoch5, iter0, batch885/1133, batch loss:2.568783202150371e-05, Training time:95860.59987139702
batch reward last col mean 5.897533355891937e-06 first col mean 1.1236307727813255e-05 all mean 5.68741379538551e-05
6.956249853828922e-05 6.956250581424683e-05
rl training, epoch5, iter0, batch886/1133, batch loss:6.956250581424683e-05, Training time:95879.5008046627
batch reward last col mean 2.7088001388619887e-06 first col mean 1.7957412637770176e-05 all mean 1.3265851521282457e-05
6.1844539231969975e-06 6.184451194712892e-06
rl training, epoch5, iter0, batch887/1133, batch loss:6.184451194712892e-06, Training time:95898.11207342148
batch reward last col mean 0.00031788027263246477 first col mean 1.7007487258524634e-05 all mean 9.94268775684759e-05
3.213319359929301e-05 3.2133197237271816e-05
rl training, epoch5, iter0, batch888/1133, batch loss:3.2133197237271816e-05, Training time:95916.76069378853
batch reward last col mean 6.598388608836103e-07 first col mean 2.4498499442415778e-06 all mean 2.6383737349533476e-05
2.1263942471705377e-05 2.126393883372657e-05
rl training, epoch5, iter0, batch889/1133, batch loss:2.126393883372657e-05, Training time:95934.5629606247
batch reward last col mean 1.2512928151409142e-06 first col mean 0.0004213549545966089 all mean 6.5435582655482e-05
1.070134385372512e-05 1.0701334758778103e-05
rl training, epoch5, iter0, batch890/1133, batch loss:1.0701334758778103e-05, Training time:95951.72197818756
batch reward last col mean 4.3149434532097075e-06 first col mean 3.4555587262730114e-06 all mean 7.51557745388709e-05
3.7338370020734146e-05 3.7338359106797725e-05
rl training, epoch5, iter0, batch891/1133, batch loss:3.7338359106797725e-05, Training time:95969.8401696682
batch reward last col mean 4.693385926657356e-05 first col mean 7.802839536452666e-05 all mean 3.9970505895325914e-05
1.2317015716689639e-05 1.2317012988205533e-05
rl training, epoch5, iter0, batch892/1133, batch loss:1.2317012988205533e-05, Training time:95989.02208447456
batch reward last col mean 1.0434488103783224e-05 first col mean 1.801303028514667e-06 all mean 2.9037471904302947e-05
4.530298610916361e-05 4.5302993385121226e-05
rl training, epoch5, iter0, batch893/1133, batch loss:4.5302993385121226e-05, Training time:96006.9497461319
batch reward last col mean 7.33746710466221e-05 first col mean 0.0005628340877592564 all mean 4.731960507342592e-05
1.0580269190541003e-05 1.0580270100035705e-05
rl training, epoch5, iter0, batch894/1133, batch loss:1.0580270100035705e-05, Training time:96024.3461265564
batch reward last col mean 5.070354518466047e-07 first col mean 4.944077772961464e-06 all mean 2.5921852284227498e-05
5.921551291976357e-06 5.921553565713111e-06
rl training, epoch5, iter0, batch895/1133, batch loss:5.921553565713111e-06, Training time:96043.10050415993
batch reward last col mean 7.932936796350987e-07 first col mean 2.029677716564038e-06 all mean 4.350449671619572e-05
3.663515963125974e-05 3.6635152355302125e-05
rl training, epoch5, iter0, batch896/1133, batch loss:3.6635152355302125e-05, Training time:96061.12123155594
batch reward last col mean 9.30060480186512e-07 first col mean 0.00022871035616844893 all mean 2.6635672838892788e-05
2.558613778091967e-05 2.5586135961930268e-05
rl training, epoch5, iter0, batch897/1133, batch loss:2.5586135961930268e-05, Training time:96079.37349367142
batch reward last col mean 2.517335360607831e-06 first col mean 2.360150574531872e-06 all mean 2.1675306925317273e-05
1.7894264601636678e-05 1.7894262782647274e-05
rl training, epoch5, iter0, batch898/1133, batch loss:1.7894262782647274e-05, Training time:96096.34981513023
batch reward last col mean 0.00010044405644293875 first col mean 5.8973764680558816e-06 all mean 4.9179674533661455e-05
2.7082400265499018e-05 2.7082400265499018e-05
rl training, epoch5, iter0, batch899/1133, batch loss:2.7082400265499018e-05, Training time:96113.19375872612
batch reward last col mean 1.1335808949297643e-06 first col mean 0.0014003905234858394 all mean 3.781406121561304e-05
4.72059182357043e-05 4.7205914597725496e-05
rl training, epoch5, iter0, batch900/1133, batch loss:4.7205914597725496e-05, Training time:96130.14688801765
batch reward last col mean 0.0009741674875840545 first col mean 9.486087947152555e-06 all mean 8.120439451886341e-05
5.901929398532957e-05 5.9019297623308375e-05
rl training, epoch5, iter0, batch901/1133, batch loss:5.9019297623308375e-05, Training time:96146.93700838089
batch reward last col mean 6.060374289518222e-06 first col mean 1.3796011444355827e-05 all mean 9.7837482826435e-06
6.336608748824801e-06 6.336609658319503e-06
rl training, epoch5, iter0, batch902/1133, batch loss:6.336609658319503e-06, Training time:96163.65231251717
batch reward last col mean 4.586643171933247e-07 first col mean 0.0015326023567467928 all mean 5.785558823845349e-05
7.34720379114151e-06 7.347209248109721e-06
rl training, epoch5, iter0, batch903/1133, batch loss:7.347209248109721e-06, Training time:96180.1879298687
batch reward last col mean 9.414794135409466e-07 first col mean 5.213514305069111e-05 all mean 4.88392252009362e-05
2.56974199146498e-05 2.569741445768159e-05
rl training, epoch5, iter0, batch904/1133, batch loss:2.569741445768159e-05, Training time:96198.44426178932
batch reward last col mean 7.5825582825927995e-06 first col mean 4.153689951635897e-05 all mean 6.41733713564463e-05
4.1247672925237566e-05 4.124767656321637e-05
rl training, epoch5, iter0, batch905/1133, batch loss:4.124767656321637e-05, Training time:96215.48180675507
batch reward last col mean 0.00016047533426899463 first col mean 3.944894615415251e-06 all mean 6.957181176403537e-05
2.5778819690458477e-05 2.5778808776522055e-05
rl training, epoch5, iter0, batch906/1133, batch loss:2.5778808776522055e-05, Training time:96233.086820364
batch reward last col mean 0.00013113662134855986 first col mean 3.283217893113033e-06 all mean 8.006843563634902e-05
3.70538946299348e-05 3.7053880078019574e-05
rl training, epoch5, iter0, batch907/1133, batch loss:3.7053880078019574e-05, Training time:96250.22673940659
batch reward last col mean 2.3820268324925564e-05 first col mean 0.0010194223141297698 all mean 0.00010081606160383672
0.00010334585385862738 0.00010334585385862738
rl training, epoch5, iter0, batch908/1133, batch loss:0.00010334585385862738, Training time:96268.70691347122
batch reward last col mean 3.829072738881223e-05 first col mean 5.403754130384186e-06 all mean 6.004819442750886e-05
3.073207335546613e-05 3.073206607950851e-05
rl training, epoch5, iter0, batch909/1133, batch loss:3.073206607950851e-05, Training time:96285.77658462524
batch reward last col mean 1.962882834050106e-06 first col mean 2.1690559606213355e-06 all mean 3.6528286727843806e-05
8.47747469379101e-06 8.47748015075922e-06
rl training, epoch5, iter0, batch910/1133, batch loss:8.47748015075922e-06, Training time:96302.8849978447
batch reward last col mean 1.7775337255443446e-06 first col mean 1.9541614165063947e-05 all mean 3.631804065662436e-05
1.4108610230323393e-05 1.4108612958807498e-05
rl training, epoch5, iter0, batch911/1133, batch loss:1.4108612958807498e-05, Training time:96319.52816963196
batch reward last col mean 1.3546794434660114e-05 first col mean 4.8174670155276544e-06 all mean 3.2741972972871736e-05
2.5639194063842297e-05 2.56391958828317e-05
rl training, epoch5, iter0, batch912/1133, batch loss:2.56391958828317e-05, Training time:96338.38862967491
batch reward last col mean 5.087592853669776e-06 first col mean 0.0002829990698955953 all mean 4.5625602069776505e-05
4.7710193030070513e-05 4.771019666804932e-05
rl training, epoch5, iter0, batch913/1133, batch loss:4.771019666804932e-05, Training time:96356.38279652596
batch reward last col mean 1.0685207598726265e-06 first col mean 7.803522748872638e-05 all mean 2.296142884006258e-05
1.162923490483081e-05 1.1629235814325511e-05
rl training, epoch5, iter0, batch914/1133, batch loss:1.1629235814325511e-05, Training time:96373.20130062103
batch reward last col mean 2.2708793494530255e-06 first col mean 8.566137239540694e-07 all mean 8.266411896329373e-06
1.1595535397646017e-05 1.1595536307140719e-05
rl training, epoch5, iter0, batch915/1133, batch loss:1.1595536307140719e-05, Training time:96389.90596365929
batch reward last col mean 5.306781531544402e-06 first col mean 1.2516222341218963e-05 all mean 2.216542634414509e-05
1.904721648315899e-05 1.9047212845180184e-05
rl training, epoch5, iter0, batch916/1133, batch loss:1.9047212845180184e-05, Training time:96406.91825127602
batch reward last col mean 4.449078005563933e-06 first col mean 4.417199670569971e-05 all mean 6.401881546480581e-05
2.0425202819751576e-05 2.0425197362783365e-05
rl training, epoch5, iter0, batch917/1133, batch loss:2.0425197362783365e-05, Training time:96424.0907304287
batch reward last col mean 9.653770575823728e-06 first col mean 3.1610984478902537e-06 all mean 1.5085212908161338e-05
4.0743198042036965e-06 4.074320713698398e-06
rl training, epoch5, iter0, batch918/1133, batch loss:4.074320713698398e-06, Training time:96442.41819882393
batch reward last col mean 1.9045489807467675e-06 first col mean 1.5314349184336606e-06 all mean 5.5907170462887734e-05
7.945661491248757e-05 7.945660036057234e-05
rl training, epoch5, iter0, batch919/1133, batch loss:7.945660036057234e-05, Training time:96461.36975240707
batch reward last col mean 1.1512122455314966e-06 first col mean 4.887491286353907e-06 all mean 1.2970548596058507e-05
2.4247245164588094e-05 2.4247245164588094e-05
rl training, epoch5, iter0, batch920/1133, batch loss:2.4247245164588094e-05, Training time:96479.91859054565
batch reward last col mean 5.309721927915234e-06 first col mean 9.761896762938704e-06 all mean 3.363336145412177e-05
9.38509856496239e-06 9.385101293446496e-06
rl training, epoch5, iter0, batch921/1133, batch loss:9.385101293446496e-06, Training time:96498.28137373924
batch reward last col mean 1.6832943856570637e-06 first col mean 1.997429080802249e-06 all mean 1.4958160136302467e-05
1.676729334576521e-05 1.6767291526775807e-05
rl training, epoch5, iter0, batch922/1133, batch loss:1.6767291526775807e-05, Training time:96517.5587515831
batch reward last col mean 2.765260433079675e-06 first col mean 2.5224282580893487e-05 all mean 4.082865416421555e-05
2.584760295576416e-05 2.584760295576416e-05
rl training, epoch5, iter0, batch923/1133, batch loss:2.584760295576416e-05, Training time:96536.19429373741
batch reward last col mean 5.187923306948505e-06 first col mean 6.042642780812457e-06 all mean 9.303596743848175e-05
3.570322587620467e-05 3.570322587620467e-05
rl training, epoch5, iter0, batch924/1133, batch loss:3.570322587620467e-05, Training time:96554.95431923866
batch reward last col mean 1.7410266082151793e-06 first col mean 2.391626139797154e-06 all mean 2.7344045520294458e-05
1.4415116311283782e-05 1.4415114492294379e-05
rl training, epoch5, iter0, batch925/1133, batch loss:1.4415114492294379e-05, Training time:96573.77862882614
batch reward last col mean 1.0161679711018223e-06 first col mean 1.3549708910431946e-06 all mean 4.795076165464707e-05
9.351924381917343e-05 9.351924381917343e-05
rl training, epoch5, iter0, batch926/1133, batch loss:9.351924381917343e-05, Training time:96591.99321198463
batch reward last col mean 1.9662056729430333e-06 first col mean 4.665047072194284e-06 all mean 4.937859921483323e-05
3.478237704257481e-05 3.478236249065958e-05
rl training, epoch5, iter0, batch927/1133, batch loss:3.478236249065958e-05, Training time:96610.34540772438
batch reward last col mean 8.209718362195417e-05 first col mean 6.666214903816581e-05 all mean 7.235897646751255e-05
1.4966713933972642e-05 1.496671848144615e-05
rl training, epoch5, iter0, batch928/1133, batch loss:1.496671848144615e-05, Training time:96628.56369304657
batch reward last col mean 0.0027335695922374725 first col mean 9.430601494386792e-06 all mean 0.000503765360917896
6.543831113958731e-05 6.543831113958731e-05
rl training, epoch5, iter0, batch929/1133, batch loss:6.543831113958731e-05, Training time:96646.12120509148
batch reward last col mean 8.174235517799389e-06 first col mean 1.2658170817303471e-05 all mean 4.399926183396019e-05
2.4502936867065728e-05 2.450294232403394e-05
rl training, epoch5, iter0, batch930/1133, batch loss:2.450294232403394e-05, Training time:96664.62114357948
batch reward last col mean 6.911273544574215e-07 first col mean 1.0681877938623074e-05 all mean 5.294204311212525e-05
4.019435800728388e-05 4.019435800728388e-05
rl training, epoch5, iter0, batch931/1133, batch loss:4.019435800728388e-05, Training time:96681.35771512985
batch reward last col mean 8.582799637224525e-06 first col mean 1.811621586966794e-06 all mean 5.24267707078252e-05
6.146208761492744e-06 6.146218765934464e-06
rl training, epoch5, iter0, batch932/1133, batch loss:6.146218765934464e-06, Training time:96698.04930710793
batch reward last col mean 3.116950665571494e-06 first col mean 2.0809775378438644e-06 all mean 1.4265801837609615e-05
1.4173598174238577e-05 1.4173596355249174e-05
rl training, epoch5, iter0, batch933/1133, batch loss:1.4173596355249174e-05, Training time:96716.14840555191
batch reward last col mean 0.003456257516518235 first col mean 2.553012336647953e-06 all mean 0.001964721828699112
6.874840619275346e-05 6.874839891679585e-05
rl training, epoch5, iter0, batch934/1133, batch loss:6.874839891679585e-05, Training time:96734.61818599701
batch reward last col mean 1.6283196373478859e-06 first col mean 1.520438127045054e-05 all mean 5.842809332534671e-05
1.4572246072930284e-05 1.457224880141439e-05
rl training, epoch5, iter0, batch935/1133, batch loss:1.457224880141439e-05, Training time:96752.06390714645
batch reward last col mean 7.098744845279725e-06 first col mean 4.767691279994324e-06 all mean 4.521108348853886e-05
4.9755315558286384e-05 4.9755315558286384e-05
rl training, epoch5, iter0, batch936/1133, batch loss:4.9755315558286384e-05, Training time:96770.25522899628
batch reward last col mean 6.689473138976609e-06 first col mean 6.150619356048992e-06 all mean 3.394353552721441e-05
3.266234489274211e-05 3.2662352168699726e-05
rl training, epoch5, iter0, batch937/1133, batch loss:3.2662352168699726e-05, Training time:96788.20205760002
batch reward last col mean 0.00019292059005238116 first col mean 4.0693535083846655e-06 all mean 7.1078167820815e-05
3.7659516237908974e-05 3.7659516237908974e-05
rl training, epoch5, iter0, batch938/1133, batch loss:3.7659516237908974e-05, Training time:96806.67708206177
batch reward last col mean 0.007399969734251499 first col mean 0.0006338490056805313 all mean 0.005587200168520212
0.0003577809256967157 0.0003577809256967157
rl training, epoch5, iter0, batch939/1133, batch loss:0.0003577809256967157, Training time:96824.95645260811
batch reward last col mean 1.4200537407305092e-05 first col mean 1.2702849744528066e-05 all mean 5.6157899962272495e-05
1.9470311599434353e-05 1.9470307961455546e-05
rl training, epoch5, iter0, batch940/1133, batch loss:1.9470307961455546e-05, Training time:96842.82852983475
batch reward last col mean 3.215096967323916e-06 first col mean 2.2516360331792384e-06 all mean 2.78996867564274e-05
3.007097438967321e-05 3.0070970751694404e-05
rl training, epoch5, iter0, batch941/1133, batch loss:3.0070970751694404e-05, Training time:96860.40992951393
batch reward last col mean 8.495085239701439e-07 first col mean 1.13010191853391e-05 all mean 5.735949889640324e-05
2.0395818864926696e-05 2.039580613200087e-05
rl training, epoch5, iter0, batch942/1133, batch loss:2.039580613200087e-05, Training time:96878.66165733337
batch reward last col mean 0.00024470247444696724 first col mean 2.5353042474307586e-06 all mean 0.00010143879626411945
5.186977796256542e-05 5.186977796256542e-05
rl training, epoch5, iter0, batch943/1133, batch loss:5.186977796256542e-05, Training time:96895.92591547966
batch reward last col mean 6.573370774276555e-05 first col mean 0.0005460980464704335 all mean 8.374414028367028e-05
4.209009057376534e-05 4.2090094211744145e-05
rl training, epoch5, iter0, batch944/1133, batch loss:4.2090094211744145e-05, Training time:96913.85448718071
batch reward last col mean 1.329408064520976e-06 first col mean 5.112101644044742e-05 all mean 3.293942063464783e-05
1.2630234778043814e-05 1.263024296349613e-05
rl training, epoch5, iter0, batch945/1133, batch loss:1.263024296349613e-05, Training time:96931.39083266258
batch reward last col mean 1.7461574088883935e-06 first col mean 6.881522494950332e-06 all mean 4.695252937381156e-05
1.646653799980413e-05 1.646654163778294e-05
rl training, epoch5, iter0, batch946/1133, batch loss:1.646654163778294e-05, Training time:96949.96900391579
batch reward last col mean 1.964654256880749e-05 first col mean 7.656661182409152e-06 all mean 4.296301995054819e-05
1.5408419130835682e-05 1.5408426406793296e-05
rl training, epoch5, iter0, batch947/1133, batch loss:1.5408426406793296e-05, Training time:96967.77155780792
batch reward last col mean 2.759286189757404e-06 first col mean 0.00012134296412114054 all mean 2.392682472418528e-05
1.3749604477197863e-05 1.3749603567703161e-05
rl training, epoch5, iter0, batch948/1133, batch loss:1.3749603567703161e-05, Training time:96986.5171508789
batch reward last col mean 0.0014513263013213873 first col mean 1.6092486475827172e-05 all mean 0.0001127772920881398
8.094218355836347e-05 8.094219083432108e-05
rl training, epoch5, iter0, batch949/1133, batch loss:8.094219083432108e-05, Training time:97004.51937627792
batch reward last col mean 8.164297469193116e-06 first col mean 1.0533300155657344e-05 all mean 0.00011144657764816657
4.7400819312315434e-05 4.740081567433663e-05
rl training, epoch5, iter0, batch950/1133, batch loss:4.740081567433663e-05, Training time:97023.06673979759
batch reward last col mean 0.0002580801083240658 first col mean 8.740144039620645e-06 all mean 0.0003434500249568373
0.00031193080940283835 0.00031193086761049926
rl training, epoch5, iter0, batch951/1133, batch loss:0.00031193086761049926, Training time:97041.893481493
batch reward last col mean 1.2044305321978754e-06 first col mean 4.082150189788081e-05 all mean 5.083172072772868e-05
5.413116741692647e-05 5.413116741692647e-05
rl training, epoch5, iter0, batch952/1133, batch loss:5.413116741692647e-05, Training time:97059.88969731331
batch reward last col mean 2.334692453587195e-06 first col mean 7.95756932348013e-06 all mean 4.647338209906593e-05
3.731064862222411e-05 3.731065589818172e-05
rl training, epoch5, iter0, batch953/1133, batch loss:3.731065589818172e-05, Training time:97077.05367159843
batch reward last col mean 7.914013622212224e-07 first col mean 0.0003550429246388376 all mean 4.8466921725776047e-05
2.184218647016678e-05 2.1842195565113798e-05
rl training, epoch5, iter0, batch954/1133, batch loss:2.1842195565113798e-05, Training time:97093.92579984665
batch reward last col mean 1.8610950064612553e-05 first col mean 4.861667548539117e-05 all mean 0.00013501118519343436
4.196296868030913e-05 4.196297231828794e-05
rl training, epoch5, iter0, batch955/1133, batch loss:4.196297231828794e-05, Training time:97111.22071433067
batch reward last col mean 0.0005306185339577496 first col mean 7.2201169132313225e-06 all mean 0.00011326005915179849
2.356706499995198e-05 2.3567068637930788e-05
rl training, epoch5, iter0, batch956/1133, batch loss:2.3567068637930788e-05, Training time:97129.22644400597
batch reward last col mean 7.694669648117269e-07 first col mean 1.5266862192220287e-06 all mean 1.3456277883960865e-05
1.588182021805551e-05 1.5881818399066105e-05
rl training, epoch5, iter0, batch957/1133, batch loss:1.5881818399066105e-05, Training time:97147.38361692429
batch reward last col mean 2.1885316527914256e-06 first col mean 4.441060809767805e-06 all mean 6.811474304413423e-05
6.784449942642823e-05 6.784449942642823e-05
rl training, epoch5, iter0, batch958/1133, batch loss:6.784449942642823e-05, Training time:97165.81430673599
batch reward last col mean 1.2903677770736977e-06 first col mean 7.300325705728028e-06 all mean 7.251970237120986e-05
6.046652197255753e-05 6.046652197255753e-05
rl training, epoch5, iter0, batch959/1133, batch loss:6.046652197255753e-05, Training time:97183.96918940544
batch reward last col mean 8.076483482000185e-07 first col mean 3.408824113648734e-06 all mean 1.9155681002303027e-05
1.912840707518626e-05 1.912840707518626e-05
rl training, epoch5, iter0, batch960/1133, batch loss:1.912840707518626e-05, Training time:97202.28267145157
batch reward last col mean 0.00025653219199739397 first col mean 6.393259809556184e-06 all mean 0.00024727839627303183
4.3408756027929485e-05 4.3408756027929485e-05
rl training, epoch5, iter0, batch961/1133, batch loss:4.3408756027929485e-05, Training time:97219.77147126198
batch reward last col mean 4.446240382094402e-06 first col mean 0.0018061086302623153 all mean 0.0001151899850810878
6.180146738188341e-05 6.180145282996818e-05
rl training, epoch5, iter0, batch962/1133, batch loss:6.180145282996818e-05, Training time:97237.65491509438
batch reward last col mean 0.0006027899798937142 first col mean 4.257345153746428e-06 all mean 0.0004383301129564643
7.687274046475068e-05 7.687274774070829e-05
rl training, epoch5, iter0, batch963/1133, batch loss:7.687274774070829e-05, Training time:97254.7170855999
batch reward last col mean 1.1844847449538065e-06 first col mean 2.6118891582882497e-06 all mean 6.166624370962381e-05
1.0367255526944064e-05 1.0367260983912274e-05
rl training, epoch5, iter0, batch964/1133, batch loss:1.0367260983912274e-05, Training time:97271.44559311867
batch reward last col mean 0.004344499204307795 first col mean 7.142288268369157e-06 all mean 0.0012764164712280035
0.00042377010686323047 0.00042377010686323047
rl training, epoch5, iter0, batch965/1133, batch loss:0.00042377010686323047, Training time:97289.3439502716
batch reward last col mean 0.0012652708683162928 first col mean 2.290630163770402e-06 all mean 0.00021869648480787873
6.521543400594965e-05 6.521544855786487e-05
rl training, epoch5, iter0, batch966/1133, batch loss:6.521544855786487e-05, Training time:97307.78478336334
batch reward last col mean 4.205340928820078e-07 first col mean 0.0001523994724266231 all mean 5.063533171778545e-05
2.630867311381735e-05 2.630867311381735e-05
rl training, epoch5, iter0, batch967/1133, batch loss:2.630867311381735e-05, Training time:97325.62078285217
batch reward last col mean 0.00023441374651156366 first col mean 2.2754007659386843e-05 all mean 6.659946666331962e-05
4.634006108972244e-05 4.6340068365680054e-05
rl training, epoch5, iter0, batch968/1133, batch loss:4.6340068365680054e-05, Training time:97342.106777668
batch reward last col mean 1.74255694673775e-06 first col mean 4.115321644349024e-06 all mean 7.65373624744825e-05
8.806964615359902e-05 8.80696316016838e-05
rl training, epoch5, iter0, batch969/1133, batch loss:8.80696316016838e-05, Training time:97359.64211320877
batch reward last col mean 1.5910720321699046e-05 first col mean 2.435044052617741e-06 all mean 4.715069735539146e-05
1.5052676644700114e-05 1.5052670278237201e-05
rl training, epoch5, iter0, batch970/1133, batch loss:1.5052670278237201e-05, Training time:97378.60486507416
batch reward last col mean 0.0012253151508048177 first col mean 0.00019062688807025552 all mean 0.0004777010472025722
5.4217012802837417e-05 5.421699461294338e-05
rl training, epoch5, iter0, batch971/1133, batch loss:5.421699461294338e-05, Training time:97397.3472456932
batch reward last col mean 2.0656998458434828e-06 first col mean 9.239955033990555e-06 all mean 7.0554917328991e-05
6.912538810865954e-05 6.912539538461715e-05
rl training, epoch5, iter0, batch972/1133, batch loss:6.912539538461715e-05, Training time:97415.18733930588
batch reward last col mean 2.780730255835806e-06 first col mean 1.9328610505908728e-05 all mean 5.6049946579150856e-05
2.9677470593014732e-05 2.9677470593014732e-05
rl training, epoch5, iter0, batch973/1133, batch loss:2.9677470593014732e-05, Training time:97433.85160017014
batch reward last col mean 1.5385967344627716e-06 first col mean 0.0003241567173972726 all mean 6.258250505197793e-05
1.913257256092038e-05 1.9132568922941573e-05
rl training, epoch5, iter0, batch974/1133, batch loss:1.9132568922941573e-05, Training time:97451.14750933647
batch reward last col mean 1.0484418453415856e-06 first col mean 1.2576206245284993e-05 all mean 4.959510624757968e-05
2.0362387658678927e-05 2.036239493463654e-05
rl training, epoch5, iter0, batch975/1133, batch loss:2.036239493463654e-05, Training time:97467.94140458107
batch reward last col mean 4.726647148345364e-06 first col mean 4.775343768415041e-06 all mean 0.00012020124995615333
5.944218355580233e-05 5.9442176279844716e-05
rl training, epoch5, iter0, batch976/1133, batch loss:5.9442176279844716e-05, Training time:97484.66033053398
batch reward last col mean 1.0366871720179915e-05 first col mean 4.602450644597411e-06 all mean 3.482727333903313e-05
1.7848427887656726e-05 1.7848426068667322e-05
rl training, epoch5, iter0, batch977/1133, batch loss:1.7848426068667322e-05, Training time:97502.6324224472
batch reward last col mean 4.808141966350377e-06 first col mean 7.969237231009174e-06 all mean 4.408029781188816e-05
3.6636640288634226e-05 3.6636640288634226e-05
rl training, epoch5, iter0, batch978/1133, batch loss:3.6636640288634226e-05, Training time:97521.30999231339
batch reward last col mean 1.463370062992908e-05 first col mean 0.0002014882629737258 all mean 6.587011739611626e-05
3.2319996535079554e-05 3.2319996535079554e-05
rl training, epoch5, iter0, batch979/1133, batch loss:3.2319996535079554e-05, Training time:97539.42757964134
batch reward last col mean 1.846566010499373e-05 first col mean 0.002252889797091484 all mean 9.117673471337184e-05
7.98508626758121e-05 7.985085539985448e-05
rl training, epoch5, iter0, batch980/1133, batch loss:7.985085539985448e-05, Training time:97556.26887631416
batch reward last col mean 2.477440830261912e-06 first col mean 1.774442171154078e-05 all mean 7.651512714801356e-05
4.7762616304680705e-05 4.776261994265951e-05
rl training, epoch5, iter0, batch981/1133, batch loss:4.776261994265951e-05, Training time:97572.86223435402
batch reward last col mean 9.346009392174892e-06 first col mean 2.4598448362667114e-05 all mean 0.00011412946332711726
1.7255961211048998e-05 1.7255981219932437e-05
rl training, epoch5, iter0, batch982/1133, batch loss:1.7255981219932437e-05, Training time:97589.39017057419
batch reward last col mean 0.0001675499661359936 first col mean 0.00025387966888956726 all mean 5.814058749820106e-05
6.324882997432724e-05 6.324882997432724e-05
rl training, epoch5, iter0, batch983/1133, batch loss:6.324882997432724e-05, Training time:97606.02362537384
batch reward last col mean 3.1313247745856643e-06 first col mean 4.904091838398017e-06 all mean 5.996379695716314e-05
1.662351678533014e-05 1.662351132836193e-05
rl training, epoch5, iter0, batch984/1133, batch loss:1.662351132836193e-05, Training time:97625.31318855286
batch reward last col mean 2.1386518710642122e-05 first col mean 5.574236183747416e-06 all mean 3.0844796128803864e-05
1.5743435142212547e-05 1.5743429685244337e-05
rl training, epoch5, iter0, batch985/1133, batch loss:1.5743429685244337e-05, Training time:97643.30960273743
batch reward last col mean 0.0002496364468242973 first col mean 9.063236916517781e-07 all mean 0.0001345659838989377
4.333908509579487e-05 4.333908509579487e-05
rl training, epoch5, iter0, batch986/1133, batch loss:4.333908509579487e-05, Training time:97661.40531992912
batch reward last col mean 0.009580347687005997 first col mean 1.7956663214135915e-06 all mean 0.00204643071629107
0.0007344045443460345 0.0007344045443460345
rl training, epoch5, iter0, batch987/1133, batch loss:0.0007344045443460345, Training time:97679.72140645981
batch reward last col mean 5.376006447477266e-05 first col mean 1.1873906260007061e-05 all mean 0.00015244742098730057
0.00020658172434195876 0.000206581738893874
rl training, epoch5, iter0, batch988/1133, batch loss:0.000206581738893874, Training time:97697.62613582611
batch reward last col mean 2.8657580060098553e-06 first col mean 3.1777140975464135e-05 all mean 2.4644843506393954e-05
3.0290228096419014e-05 3.0290222639450803e-05
rl training, epoch5, iter0, batch989/1133, batch loss:3.0290222639450803e-05, Training time:97714.20891737938
batch reward last col mean 2.613776132420753e-06 first col mean 2.138731724699028e-05 all mean 1.0792511602630839e-05
5.267510005069198e-06 5.267510459816549e-06
rl training, epoch5, iter0, batch990/1133, batch loss:5.267510459816549e-06, Training time:97730.83827328682
batch reward last col mean 2.620380200824002e-06 first col mean 1.913074584081187e-06 all mean 4.791036553797312e-05
1.700447865005117e-05 1.7004475012072362e-05
rl training, epoch5, iter0, batch991/1133, batch loss:1.7004475012072362e-05, Training time:97747.46003699303
batch reward last col mean 5.768619644186401e-07 first col mean 2.768201511571533e-06 all mean 1.701151268207468e-05
5.167224117030855e-06 5.167224571778206e-06
rl training, epoch5, iter0, batch992/1133, batch loss:5.167224571778206e-06, Training time:97764.06942009926
batch reward last col mean 8.113250260066707e-06 first col mean 1.1164385114170727e-06 all mean 8.149290806613863e-05
1.5854371667956002e-05 1.585436075401958e-05
rl training, epoch5, iter0, batch993/1133, batch loss:1.585436075401958e-05, Training time:97780.6660220623
batch reward last col mean 4.220036771585001e-06 first col mean 4.213269676256459e-06 all mean 3.408289194339886e-05
1.6227415471803397e-05 1.6227410014835186e-05
rl training, epoch5, iter0, batch994/1133, batch loss:1.6227410014835186e-05, Training time:97797.26166296005
batch reward last col mean 0.002315564313903451 first col mean 9.330770808446687e-06 all mean 0.0014632681850343943
0.00011958599498029798 0.00011958598770434037
rl training, epoch5, iter0, batch995/1133, batch loss:0.00011958598770434037, Training time:97816.13851499557
batch reward last col mean 1.7076287122108624e-06 first col mean 0.0003949820820707828 all mean 4.456342139746994e-05
1.4629258657805622e-05 1.4629259567300323e-05
rl training, epoch5, iter0, batch996/1133, batch loss:1.4629259567300323e-05, Training time:97835.35573005676
batch reward last col mean 1.2496527688199421e-06 first col mean 5.05299904034473e-05 all mean 8.686112414579839e-05
3.568463944247924e-05 3.5684653994394466e-05
rl training, epoch5, iter0, batch997/1133, batch loss:3.5684653994394466e-05, Training time:97853.88505268097
batch reward last col mean 1.1538253602338955e-05 first col mean 0.00014761376951355487 all mean 6.179363117553294e-05
1.592599983268883e-05 1.592601438460406e-05
rl training, epoch5, iter0, batch998/1133, batch loss:1.592601438460406e-05, Training time:97873.56269288063
batch reward last col mean 3.056642526644282e-06 first col mean 1.570693257235689e-06 all mean 3.477799327811226e-05
1.67326616065111e-05 1.6732659787521698e-05
rl training, epoch5, iter0, batch999/1133, batch loss:1.6732659787521698e-05, Training time:97891.66384863853
batch reward last col mean 3.559226115612546e-06 first col mean 1.4688228020531824e-06 all mean 6.068468792364001e-05
1.925716242112685e-05 1.9257144231232814e-05
rl training, epoch5, iter0, batch1000/1133, batch loss:1.9257144231232814e-05, Training time:97909.62346220016
batch reward last col mean 0.00011089746840298176 first col mean 0.0017997168470174074 all mean 0.00013508756819646806
4.839510438614525e-05 4.8395108024124056e-05
rl training, epoch5, iter0, batch1001/1133, batch loss:4.8395108024124056e-05, Training time:97927.1640598774
batch reward last col mean 1.6967713918347727e-06 first col mean 1.8207078028353862e-05 all mean 4.564091068459675e-05
7.157917025324423e-06 7.157917025324423e-06
rl training, epoch5, iter0, batch1002/1133, batch loss:7.157917025324423e-06, Training time:97945.34840106964
batch reward last col mean 4.263072241883492e-06 first col mean 1.934969986905344e-06 all mean 4.6824639866827056e-05
2.077447970805224e-05 2.077449062198866e-05
rl training, epoch5, iter0, batch1003/1133, batch loss:2.077449062198866e-05, Training time:97963.69236755371
batch reward last col mean 6.290986789281305e-07 first col mean 4.352996256784536e-06 all mean 7.003007340244949e-05
4.6614593884442e-05 4.661460479837842e-05
rl training, epoch5, iter0, batch1004/1133, batch loss:4.661460479837842e-05, Training time:97980.84924721718
batch reward last col mean 7.086229743435979e-05 first col mean 0.00029987958259880543 all mean 0.00011031850590370595
9.108603990171105e-05 9.108603262575343e-05
rl training, epoch5, iter0, batch1005/1133, batch loss:9.108603262575343e-05, Training time:97997.5216140747
batch reward last col mean 8.296451028400043e-07 first col mean 4.797077053808607e-06 all mean 1.799940764612984e-05
4.377910227049142e-05 4.377910227049142e-05
rl training, epoch5, iter0, batch1006/1133, batch loss:4.377910227049142e-05, Training time:98016.11138868332
batch reward last col mean 3.348720201756805e-05 first col mean 6.0073005442973226e-05 all mean 0.00014026851567905396
0.00016303097072523087 0.00016303095617331564
rl training, epoch5, iter0, batch1007/1133, batch loss:0.00016303095617331564, Training time:98032.89207649231
batch reward last col mean 0.00011839541548397392 first col mean 4.040261956106406e-06 all mean 0.00010390877287136391
5.3331150411395356e-05 5.3331150411395356e-05
rl training, epoch5, iter0, batch1008/1133, batch loss:5.3331150411395356e-05, Training time:98049.58249402046
batch reward last col mean 1.4318859939521644e-05 first col mean 6.892507371958345e-06 all mean 1.052822517522145e-05
4.912229087494779e-06 4.912227268505376e-06
rl training, epoch5, iter0, batch1009/1133, batch loss:4.912227268505376e-06, Training time:98066.67791199684
batch reward last col mean 3.6035476114193443e-06 first col mean 8.732547939871438e-06 all mean 7.741338777123019e-05
4.5383676479104906e-05 4.538366920314729e-05
rl training, epoch5, iter0, batch1010/1133, batch loss:4.538366920314729e-05, Training time:98083.34542155266
batch reward last col mean 7.638650276931003e-05 first col mean 3.6214469218975864e-06 all mean 5.922648051637225e-05
1.4817411283729598e-05 1.4817404007771984e-05
rl training, epoch5, iter0, batch1011/1133, batch loss:1.4817404007771984e-05, Training time:98100.52960824966
batch reward last col mean 0.0005107178585603833 first col mean 9.598713222658262e-05 all mean 0.0003184854576829821
9.084910561796278e-05 9.084909834200516e-05
rl training, epoch5, iter0, batch1012/1133, batch loss:9.084909834200516e-05, Training time:98118.57211732864
batch reward last col mean 1.4163654668664094e-05 first col mean 1.0718109479057603e-05 all mean 3.875453694490716e-05
5.3722571465186775e-05 5.3722571465186775e-05
rl training, epoch5, iter0, batch1013/1133, batch loss:5.3722571465186775e-05, Training time:98135.6486132145
batch reward last col mean 5.536744538403582e-06 first col mean 3.7456207792274654e-05 all mean 4.11770524806343e-05
0.00011621871090028435 0.00011621869634836912
rl training, epoch5, iter0, batch1014/1133, batch loss:0.00011621869634836912, Training time:98154.16154146194
batch reward last col mean 1.913574351419811e-06 first col mean 1.0847634257515892e-05 all mean 7.801964966347441e-05
4.7116576752159745e-05 4.7116576752159745e-05
rl training, epoch5, iter0, batch1015/1133, batch loss:4.7116576752159745e-05, Training time:98172.05691432953
batch reward last col mean 1.7091279005398974e-05 first col mean 1.8409078620607033e-05 all mean 4.7765945055289194e-05
6.439068238250911e-05 6.439068965846673e-05
rl training, epoch5, iter0, batch1016/1133, batch loss:6.439068965846673e-05, Training time:98189.88935184479
batch reward last col mean 0.0008152349619194865 first col mean 0.0011829007416963577 all mean 0.00019601514213718474
3.5640787245938554e-05 3.564080543583259e-05
rl training, epoch5, iter0, batch1017/1133, batch loss:3.564080543583259e-05, Training time:98208.85010170937
batch reward last col mean 1.008148728942615e-06 first col mean 1.8081685766446753e-06 all mean 6.127074448158965e-05
0.00015508032811339945 0.00015508032811339945
rl training, epoch5, iter0, batch1018/1133, batch loss:0.00015508032811339945, Training time:98227.19603037834
batch reward last col mean 4.773150976689067e-07 first col mean 1.101933094105334e-06 all mean 3.975192521465942e-05
2.7430081900092773e-05 2.743008553807158e-05
rl training, epoch5, iter0, batch1019/1133, batch loss:2.743008553807158e-05, Training time:98244.20902228355
batch reward last col mean 4.537067979981657e-06 first col mean 2.5273964638472535e-05 all mean 8.414628973696381e-05
4.160930620855652e-05 4.1609309846535325e-05
rl training, epoch5, iter0, batch1020/1133, batch loss:4.1609309846535325e-05, Training time:98263.01330900192
batch reward last col mean 2.1462032236740924e-05 first col mean 1.7085263834815123e-06 all mean 8.033754420466721e-05
4.23423080064822e-05 4.23423080064822e-05
rl training, epoch5, iter0, batch1021/1133, batch loss:4.23423080064822e-05, Training time:98280.6067416668
batch reward last col mean 2.029744428000413e-05 first col mean 0.00010605080024106428 all mean 0.00010154087794944644
2.9114939025021158e-05 2.911494993895758e-05
rl training, epoch5, iter0, batch1022/1133, batch loss:2.911494993895758e-05, Training time:98298.54703998566
batch reward last col mean 8.571111720812041e-06 first col mean 5.818908175569959e-05 all mean 9.471396333537996e-05
3.770920739043504e-05 3.7709200114477426e-05
rl training, epoch5, iter0, batch1023/1133, batch loss:3.7709200114477426e-05, Training time:98317.07706451416
batch reward last col mean 1.4534351976180915e-05 first col mean 4.914536475553177e-06 all mean 4.687583714257926e-05
1.069736299541546e-05 1.0697364814404864e-05
rl training, epoch5, iter0, batch1024/1133, batch loss:1.0697364814404864e-05, Training time:98334.86949539185
batch reward last col mean 2.1888020000915276e-06 first col mean 0.0005304316291585565 all mean 6.932308315299451e-05
5.132891237735748e-05 5.1328923291293904e-05
rl training, epoch5, iter0, batch1025/1133, batch loss:5.1328923291293904e-05, Training time:98352.81227850914
batch reward last col mean 6.703418193865218e-07 first col mean 1.5585699202347314e-06 all mean 2.405386112513952e-05
1.2605298252310604e-05 1.2605298252310604e-05
rl training, epoch5, iter0, batch1026/1133, batch loss:1.2605298252310604e-05, Training time:98371.62125587463
batch reward last col mean 3.261728352299542e-06 first col mean 1.4131050193100236e-05 all mean 2.204716656706296e-05
3.533588460413739e-05 3.533588460413739e-05
rl training, epoch5, iter0, batch1027/1133, batch loss:3.533588460413739e-05, Training time:98389.01403594017
batch reward last col mean 9.73499300016556e-06 first col mean 0.00010384642519056797 all mean 0.00010128893336514011
4.1183066059602425e-05 4.1183066059602425e-05
rl training, epoch5, iter0, batch1028/1133, batch loss:4.1183066059602425e-05, Training time:98405.66782212257
batch reward last col mean 1.4110539268585853e-05 first col mean 2.5119159545283765e-05 all mean 3.856642797472887e-05
3.125537114101462e-05 3.1255363865057006e-05
rl training, epoch5, iter0, batch1029/1133, batch loss:3.1255363865057006e-05, Training time:98422.42350816727
batch reward last col mean 3.7048935155326035e-06 first col mean 2.208590740337968e-05 all mean 0.00021436593669932336
0.00011673210246954113 0.00011673209519358352
rl training, epoch5, iter0, batch1030/1133, batch loss:0.00011673209519358352, Training time:98439.18551445007
batch reward last col mean 4.217783043714007e-06 first col mean 0.00012151446571806446 all mean 0.00010585477866698056
4.189606988802552e-05 4.18960589740891e-05
rl training, epoch5, iter0, batch1031/1133, batch loss:4.18960589740891e-05, Training time:98455.86870527267
batch reward last col mean 4.442678800842259e-06 first col mean 7.54102416067326e-07 all mean 4.117739445064217e-05
1.1230404197704047e-05 1.1230403288209345e-05
rl training, epoch5, iter0, batch1032/1133, batch loss:1.1230403288209345e-05, Training time:98474.33439588547
batch reward last col mean 4.990129127691034e-06 first col mean 2.484690230630804e-05 all mean 9.991231490857899e-05
4.671512942877598e-05 4.671512215281837e-05
rl training, epoch5, iter0, batch1033/1133, batch loss:4.671512215281837e-05, Training time:98492.37962913513
batch reward last col mean 1.697976404102519e-05 first col mean 1.408165644534165e-05 all mean 0.0001072826053132303
4.877790706814267e-05 4.877790706814267e-05
rl training, epoch5, iter0, batch1034/1133, batch loss:4.877790706814267e-05, Training time:98510.9523923397
batch reward last col mean 1.90990840565064e-06 first col mean 0.0006790646002627909 all mean 8.412644092459232e-05
1.5796065781614743e-05 1.579606396262534e-05
rl training, epoch5, iter0, batch1035/1133, batch loss:1.579606396262534e-05, Training time:98529.61748790741
batch reward last col mean 0.0021211495622992516 first col mean 8.403065294260159e-06 all mean 0.0009766938164830208
0.0001277062838198617 0.00012770629837177694
rl training, epoch5, iter0, batch1036/1133, batch loss:0.00012770629837177694, Training time:98547.17458248138
batch reward last col mean 2.8480128548835637e-06 first col mean 1.5433378166562761e-06 all mean 4.061797881149687e-05
3.6446603189688176e-05 3.644659955170937e-05
rl training, epoch5, iter0, batch1037/1133, batch loss:3.644659955170937e-05, Training time:98563.8851890564
batch reward last col mean 3.9945903154148255e-06 first col mean 4.590287971950602e-06 all mean 0.00013110772124491632
6.704823317704722e-05 6.704819679725915e-05
rl training, epoch5, iter0, batch1038/1133, batch loss:6.704819679725915e-05, Training time:98580.56219434738
batch reward last col mean 2.304284498677589e-05 first col mean 0.0001917569461511448 all mean 0.00011021320096915588
6.253587343962863e-05 6.253587343962863e-05
rl training, epoch5, iter0, batch1039/1133, batch loss:6.253587343962863e-05, Training time:98597.30557489395
batch reward last col mean 1.570658787386492e-05 first col mean 1.3466044947563205e-05 all mean 0.00010984706023009494
9.909725486068055e-05 9.909725486068055e-05
rl training, epoch5, iter0, batch1040/1133, batch loss:9.909725486068055e-05, Training time:98614.07839274406
batch reward last col mean 1.576821887283586e-05 first col mean 3.39913412972237e-06 all mean 9.034548565978184e-05
5.24764800502453e-05 5.2476472774287686e-05
rl training, epoch5, iter0, batch1041/1133, batch loss:5.2476472774287686e-05, Training time:98630.7685201168
batch reward last col mean 0.0008130851783789694 first col mean 2.425315869913902e-05 all mean 0.00044544105185195804
5.9270128986099735e-05 5.9270128986099735e-05
rl training, epoch5, iter0, batch1042/1133, batch loss:5.9270128986099735e-05, Training time:98647.9873623848
batch reward last col mean 2.3166545361164026e-05 first col mean 6.823825970059261e-06 all mean 0.0001389706158079207
6.704804400214925e-05 6.704802945023403e-05
rl training, epoch5, iter0, batch1043/1133, batch loss:6.704802945023403e-05, Training time:98666.1022760868
batch reward last col mean 1.542887844152574e-06 first col mean 5.126035830471665e-05 all mean 3.02890930470312e-05
6.434097940655192e-06 6.434092483686982e-06
rl training, epoch5, iter0, batch1044/1133, batch loss:6.434092483686982e-06, Training time:98682.91446471214
batch reward last col mean 1.0166656466026325e-05 first col mean 5.549184152187081e-06 all mean 8.542242721887305e-05
2.1576017388724722e-05 2.1576017388724722e-05
rl training, epoch5, iter0, batch1045/1133, batch loss:2.1576017388724722e-05, Training time:98699.54489183426
batch reward last col mean 1.0236608432023786e-05 first col mean 6.582246442121686e-06 all mean 3.8380996556952596e-05
1.0798990842886269e-05 1.0798995390359778e-05
rl training, epoch5, iter0, batch1046/1133, batch loss:1.0798995390359778e-05, Training time:98716.83576250076
batch reward last col mean 1.0010118785430677e-05 first col mean 3.863249276037095e-06 all mean 0.00012861975119449198
0.00018592196283861995 0.00018592196283861995
rl training, epoch5, iter0, batch1047/1133, batch loss:0.00018592196283861995, Training time:98734.09892773628
batch reward last col mean 3.282241777924355e-06 first col mean 8.527480531483889e-06 all mean 9.874173701973632e-05
3.554135037120432e-05 3.554135037120432e-05
rl training, epoch5, iter0, batch1048/1133, batch loss:3.554135037120432e-05, Training time:98751.23693823814
batch reward last col mean 2.0032499378430657e-05 first col mean 0.0005872034817002714 all mean 2.7919428248424083e-05
2.0915354980388656e-05 2.0915354980388656e-05
rl training, epoch5, iter0, batch1049/1133, batch loss:2.0915354980388656e-05, Training time:98770.42030668259
batch reward last col mean 0.00039062759606167674 first col mean 0.00018394659855403006 all mean 7.899598131189123e-05
2.8398786525940523e-05 2.8398786525940523e-05
rl training, epoch5, iter0, batch1050/1133, batch loss:2.8398786525940523e-05, Training time:98787.8737692833
batch reward last col mean 4.709745098807616e-06 first col mean 1.4688032024423592e-05 all mean 4.897221515420824e-05
7.04354970366694e-05 7.043548976071179e-05
rl training, epoch5, iter0, batch1051/1133, batch loss:7.043548976071179e-05, Training time:98805.91181087494
batch reward last col mean 7.729061621830624e-07 first col mean 3.020701342393295e-06 all mean 6.91627137712203e-05
4.047412585350685e-05 4.0474118577549234e-05
rl training, epoch5, iter0, batch1052/1133, batch loss:4.0474118577549234e-05, Training time:98823.85010623932
batch reward last col mean 1.6658505046507344e-06 first col mean 0.00012868549674749374 all mean 8.647835056763142e-05
1.640425580262672e-05 1.6404243069700897e-05
rl training, epoch5, iter0, batch1053/1133, batch loss:1.6404243069700897e-05, Training time:98840.93792414665
batch reward last col mean 6.369857146637514e-06 first col mean 0.00011096788512077183 all mean 5.544765372178517e-05
1.6783968021627516e-05 1.6783971659606323e-05
rl training, epoch5, iter0, batch1054/1133, batch loss:1.6783971659606323e-05, Training time:98857.85267949104
batch reward last col mean 2.0150105228822213e-06 first col mean 3.547067899489775e-05 all mean 4.379409801913425e-05
1.2594361578521784e-05 1.2594358850037679e-05
rl training, epoch5, iter0, batch1055/1133, batch loss:1.2594358850037679e-05, Training time:98874.64977025986
batch reward last col mean 2.8769647997251013e-06 first col mean 3.4856814181694062e-06 all mean 4.081231963937171e-05
9.455805411562324e-06 9.455806321057025e-06
rl training, epoch5, iter0, batch1056/1133, batch loss:9.455806321057025e-06, Training time:98891.62540888786
batch reward last col mean 1.0419685168017168e-05 first col mean 2.8836257115472108e-05 all mean 0.00011388607526896521
3.1669300369685516e-05 3.166930764564313e-05
rl training, epoch5, iter0, batch1057/1133, batch loss:3.166930764564313e-05, Training time:98908.3078622818
batch reward last col mean 1.8191969957115361e-06 first col mean 2.668660272320267e-06 all mean 4.524479663814418e-05
0.00010395304707344621 0.0001039530397974886
rl training, epoch5, iter0, batch1058/1133, batch loss:0.0001039530397974886, Training time:98924.93447041512
batch reward last col mean 1.2041172340104822e-05 first col mean 0.00014078679669182748 all mean 5.709460674552247e-05
2.0650224541896023e-05 2.065022272290662e-05
rl training, epoch5, iter0, batch1059/1133, batch loss:2.065022272290662e-05, Training time:98941.99291443825
batch reward last col mean 2.6774823709274642e-06 first col mean 8.285936928587034e-05 all mean 6.681008380837739e-05
6.571505218744278e-05 6.57150594634004e-05
rl training, epoch5, iter0, batch1060/1133, batch loss:6.57150594634004e-05, Training time:98960.02199673653
batch reward last col mean 1.1220964552194346e-05 first col mean 2.4943825337686576e-05 all mean 6.177164323162287e-05
3.340030525578186e-05 3.3400297979824245e-05
rl training, epoch5, iter0, batch1061/1133, batch loss:3.3400297979824245e-05, Training time:98977.49077153206
batch reward last col mean 7.74214458942879e-06 first col mean 0.00020501187827903777 all mean 0.00013306942128110677
0.00013789674267172813 0.00013789671356789768
rl training, epoch5, iter0, batch1062/1133, batch loss:0.00013789671356789768, Training time:98994.17003297806
batch reward last col mean 2.650093620104599e-06 first col mean 4.131148671149276e-06 all mean 0.0001063328018062748
2.67184241238283e-05 2.671841502888128e-05
rl training, epoch5, iter0, batch1063/1133, batch loss:2.671841502888128e-05, Training time:99011.11005759239
batch reward last col mean 6.2786989474261645e-06 first col mean 0.0008889199234545231 all mean 5.791068178950809e-05
2.808746103255544e-05 2.8087455575587228e-05
rl training, epoch5, iter0, batch1064/1133, batch loss:2.8087455575587228e-05, Training time:99027.93535137177
batch reward last col mean 3.360107075423002e-05 first col mean 9.694063010101672e-06 all mean 8.669053204357624e-05
6.960238533793017e-05 6.960238533793017e-05
rl training, epoch5, iter0, batch1065/1133, batch loss:6.960238533793017e-05, Training time:99044.62116456032
batch reward last col mean 2.1252337774058105e-06 first col mean 2.9622962756548077e-05 all mean 0.00011769734555855393
0.00020530063193291426 0.00020530063193291426
rl training, epoch5, iter0, batch1066/1133, batch loss:0.00020530063193291426, Training time:99062.81317043304
batch reward last col mean 1.471365521865664e-06 first col mean 4.056176112499088e-05 all mean 7.850467227399349e-05
4.0298502426594496e-05 4.029850970255211e-05
rl training, epoch5, iter0, batch1067/1133, batch loss:4.029850970255211e-05, Training time:99083.07723522186
batch reward last col mean 1.3678767572855577e-05 first col mean 0.0004649359034374356 all mean 6.105995998950675e-05
4.281952715246007e-05 4.281951623852365e-05
rl training, epoch5, iter0, batch1068/1133, batch loss:4.281951623852365e-05, Training time:99102.32977771759
batch reward last col mean 1.1723248007911025e-06 first col mean 1.3142766874807421e-05 all mean 4.146270657656714e-05
1.1955097761529032e-05 1.1955094123550225e-05
rl training, epoch5, iter0, batch1069/1133, batch loss:1.1955094123550225e-05, Training time:99119.74666309357
batch reward last col mean 1.3576825040217955e-05 first col mean 7.59196700528264e-05 all mean 2.7613426937023178e-05
1.3702848264074419e-05 1.3702851902053226e-05
rl training, epoch5, iter0, batch1070/1133, batch loss:1.3702851902053226e-05, Training time:99138.1009259224
batch reward last col mean 8.084352884907275e-05 first col mean 0.00010538280912442133 all mean 4.9351423513144255e-05
6.242020754143596e-05 6.242021481739357e-05
rl training, epoch5, iter0, batch1071/1133, batch loss:6.242021481739357e-05, Training time:99155.57729005814
batch reward last col mean 3.3686706046864856e-06 first col mean 1.8740374798653647e-05 all mean 0.00010302766168024391
3.860228389385156e-05 3.860229844576679e-05
rl training, epoch5, iter0, batch1072/1133, batch loss:3.860229844576679e-05, Training time:99172.43490672112
batch reward last col mean 0.0003551298868842423 first col mean 8.032859113882296e-06 all mean 0.0002986635372508317
7.605786231579259e-05 7.605784048791975e-05
rl training, epoch5, iter0, batch1073/1133, batch loss:7.605784048791975e-05, Training time:99189.16210436821
batch reward last col mean 1.492809496994596e-05 first col mean 0.00152100739069283 all mean 0.00012165005318820477
6.237402703845873e-05 6.237401976250112e-05
rl training, epoch5, iter0, batch1074/1133, batch loss:6.237401976250112e-05, Training time:99205.80730700493
batch reward last col mean 8.651865073261433e-07 first col mean 0.00010992079478455707 all mean 6.701504025841132e-05
0.000252756493864581 0.000252756493864581
rl training, epoch5, iter0, batch1075/1133, batch loss:0.000252756493864581, Training time:99222.30788707733
batch reward last col mean 0.0013715458335354924 first col mean 1.4821234799455851e-05 all mean 0.0007305185426957905
0.0001581204414833337 0.00015812041237950325
rl training, epoch5, iter0, batch1076/1133, batch loss:0.00015812041237950325, Training time:99239.04942798615
batch reward last col mean 1.8737239315669285e-06 first col mean 0.0002968843618873507 all mean 7.179627573350444e-05
3.858217314700596e-05 3.858217678498477e-05
rl training, epoch5, iter0, batch1077/1133, batch loss:3.858217678498477e-05, Training time:99255.75671672821
batch reward last col mean 2.6224028260912746e-05 first col mean 2.600142761366442e-05 all mean 5.504929140442982e-05
7.932600965432357e-06 7.932596417958848e-06
rl training, epoch5, iter0, batch1078/1133, batch loss:7.932596417958848e-06, Training time:99273.68302607536
batch reward last col mean 7.191974304987525e-07 first col mean 4.610188625520095e-05 all mean 2.577391751401592e-05
9.366649464936927e-06 9.366647645947523e-06
rl training, epoch5, iter0, batch1079/1133, batch loss:9.366647645947523e-06, Training time:99292.15209460258
batch reward last col mean 0.004025633446872234 first col mean 1.28087485791184e-05 all mean 0.002460543531924486
0.00022351861116476357 0.00022351861116476357
rl training, epoch5, iter0, batch1080/1133, batch loss:0.00022351861116476357, Training time:99308.88472938538
batch reward last col mean 7.317603376577608e-06 first col mean 3.987155196227832e-06 all mean 0.00011052872287109494
4.185036596027203e-05 4.185035504633561e-05
rl training, epoch5, iter0, batch1081/1133, batch loss:4.185035504633561e-05, Training time:99325.46748614311
batch reward last col mean 3.4673817026487086e-06 first col mean 2.830302582879085e-05 all mean 5.312118082656525e-05
4.601531327352859e-05 4.601532418746501e-05
rl training, epoch5, iter0, batch1082/1133, batch loss:4.601532418746501e-05, Training time:99344.15097284317
batch reward last col mean 1.4219307558960281e-05 first col mean 1.86131801456213e-05 all mean 9.927390783559531e-05
0.00011259716848144308 0.00011259716848144308
rl training, epoch5, iter0, batch1083/1133, batch loss:0.00011259716848144308, Training time:99361.82787203789
batch reward last col mean 0.00012212085130158812 first col mean 9.443564340472221e-05 all mean 0.00013316050171852112
0.00012255783076398075 0.00012255784531589597
rl training, epoch5, iter0, batch1084/1133, batch loss:0.00012255784531589597, Training time:99378.34985971451
batch reward last col mean 3.31965675286483e-05 first col mean 6.8579561229853425e-06 all mean 0.00010634357749950141
0.00014918284432496876 0.00014918284432496876
rl training, epoch5, iter0, batch1085/1133, batch loss:0.00014918284432496876, Training time:99396.74374961853
batch reward last col mean 3.864502286887728e-05 first col mean 3.7211907510936726e-06 all mean 0.00011113340588053688
5.959553163847886e-05 5.959554619039409e-05
rl training, epoch5, iter0, batch1086/1133, batch loss:5.959554619039409e-05, Training time:99414.03609347343
batch reward last col mean 1.6186938864848344e-06 first col mean 6.441629375331104e-05 all mean 3.817889228230342e-05
2.974222479679156e-05 2.9742237529717386e-05
rl training, epoch5, iter0, batch1087/1133, batch loss:2.9742237529717386e-05, Training time:99430.69844889641
batch reward last col mean 5.7045008361455984e-06 first col mean 1.0926094091701088e-06 all mean 7.995488704182208e-05
2.729057814576663e-05 2.7290576326777227e-05
rl training, epoch5, iter0, batch1088/1133, batch loss:2.7290576326777227e-05, Training time:99447.44449973106
batch reward last col mean 7.788399329911044e-07 first col mean 4.1914472603821196e-06 all mean 8.271804108517244e-05
2.6847032131627202e-05 2.684703576960601e-05
rl training, epoch5, iter0, batch1089/1133, batch loss:2.684703576960601e-05, Training time:99465.6381881237
batch reward last col mean 7.64804190112045e-06 first col mean 6.80093080518418e-07 all mean 5.018550291424617e-05
2.9522521799663082e-05 2.952252543764189e-05
rl training, epoch5, iter0, batch1090/1133, batch loss:2.952252543764189e-05, Training time:99484.17761850357
batch reward last col mean 4.565064045891631e-06 first col mean 4.0902132241171785e-06 all mean 5.733502621296793e-05
3.538696182658896e-05 3.5386954550631344e-05
rl training, epoch5, iter0, batch1091/1133, batch loss:3.5386954550631344e-05, Training time:99502.66536927223
batch reward last col mean 2.4478224077029154e-05 first col mean 5.2590689847420435e-06 all mean 4.9899219447979704e-05
2.564084752521012e-05 2.5640843887231313e-05
rl training, epoch5, iter0, batch1092/1133, batch loss:2.5640843887231313e-05, Training time:99520.30174922943
batch reward last col mean 4.122304017073475e-05 first col mean 2.737762770266272e-06 all mean 0.00011217853898415342
3.954227940994315e-05 3.9542272133985534e-05
rl training, epoch5, iter0, batch1093/1133, batch loss:3.9542272133985534e-05, Training time:99538.24558877945
batch reward last col mean 0.0001357365254079923 first col mean 0.0003308237355668098 all mean 0.00012979275197722018
8.070241892710328e-05 8.070241892710328e-05
rl training, epoch5, iter0, batch1094/1133, batch loss:8.070241892710328e-05, Training time:99555.69510269165
batch reward last col mean 7.469238425983349e-06 first col mean 3.280347664258443e-05 all mean 0.00011057475057896227
1.605465149623342e-05 1.6054655134212226e-05
rl training, epoch5, iter0, batch1095/1133, batch loss:1.6054655134212226e-05, Training time:99575.06553506851
batch reward last col mean 7.44950420994428e-06 first col mean 3.5415614547673613e-06 all mean 0.00010550712613621727
5.830368536408059e-05 5.8303670812165365e-05
rl training, epoch5, iter0, batch1096/1133, batch loss:5.8303670812165365e-05, Training time:99592.26425886154
batch reward last col mean 2.8693109925370663e-05 first col mean 2.8809945433749817e-06 all mean 0.00010180911340285093
6.007682532072067e-05 6.007682532072067e-05
rl training, epoch5, iter0, batch1097/1133, batch loss:6.007682532072067e-05, Training time:99609.54496359825
batch reward last col mean 2.3056376448948868e-05 first col mean 1.9320195860927925e-05 all mean 0.00010612082405714318
7.15741261956282e-05 7.15741261956282e-05
rl training, epoch5, iter0, batch1098/1133, batch loss:7.15741261956282e-05, Training time:99628.16653037071
batch reward last col mean 7.1837284849607386e-06 first col mean 4.9881291488418356e-06 all mean 7.057823677314445e-05
3.509592716000043e-05 3.5095930797979236e-05
rl training, epoch5, iter0, batch1099/1133, batch loss:3.5095930797979236e-05, Training time:99646.69410324097
batch reward last col mean 2.4970402591861784e-05 first col mean 3.8148817111505195e-05 all mean 4.435369555721991e-05
1.6761585357016884e-05 1.6761581719038077e-05
rl training, epoch5, iter0, batch1100/1133, batch loss:1.6761581719038077e-05, Training time:99663.44329714775
batch reward last col mean 3.0079265798121924e-06 first col mean 1.7780957932700403e-06 all mean 5.9129113651579246e-05
7.338941213674843e-05 7.338941941270605e-05
rl training, epoch5, iter0, batch1101/1133, batch loss:7.338941941270605e-05, Training time:99680.2048933506
batch reward last col mean 2.1644759726768825e-06 first col mean 1.8025821191258729e-06 all mean 5.44053727935534e-05
3.520576501614414e-05 3.520576501614414e-05
rl training, epoch5, iter0, batch1102/1133, batch loss:3.520576501614414e-05, Training time:99696.83837485313
batch reward last col mean 8.060351319727488e-06 first col mean 6.962520728848176e-07 all mean 6.616568862227723e-05
5.244643034529872e-05 5.2446415793383494e-05
rl training, epoch5, iter0, batch1103/1133, batch loss:5.2446415793383494e-05, Training time:99713.49604606628
batch reward last col mean 2.395831188550801e-06 first col mean 1.2746537549901404e-06 all mean 6.274529005168006e-05
4.278667256585322e-05 4.27866616519168e-05
rl training, epoch5, iter0, batch1104/1133, batch loss:4.27866616519168e-05, Training time:99730.1800763607
batch reward last col mean 0.0004879629996139556 first col mean 0.00013459099864121526 all mean 0.0004227926838211715
0.0002420906093902886 0.0002420906093902886
rl training, epoch5, iter0, batch1105/1133, batch loss:0.0002420906093902886, Training time:99746.82681035995
batch reward last col mean 0.00023760664043948054 first col mean 3.6926053326169495e-06 all mean 9.26870561670512e-05
0.0001722241722745821 0.0001722241722745821
rl training, epoch5, iter0, batch1106/1133, batch loss:0.0001722241722745821, Training time:99763.76930522919
batch reward last col mean 0.00445129256695509 first col mean 3.6338726204121485e-05 all mean 0.003174618585035205
0.00020627329649869353 0.00020627329649869353
rl training, epoch5, iter0, batch1107/1133, batch loss:0.00020627329649869353, Training time:99780.51962971687
batch reward last col mean 5.9637030062731355e-05 first col mean 3.2675134207238443e-06 all mean 7.349355291808024e-05
2.8106225727242418e-05 2.8106223908253014e-05
rl training, epoch5, iter0, batch1108/1133, batch loss:2.8106223908253014e-05, Training time:99799.11537694931
batch reward last col mean 4.3546768324631557e-07 first col mean 1.1998996569673182e-06 all mean 8.158683340298012e-05
5.8467976487008855e-05 5.846796921105124e-05
rl training, epoch5, iter0, batch1109/1133, batch loss:5.846796921105124e-05, Training time:99816.62454032898
batch reward last col mean 3.374261723365635e-05 first col mean 4.151287066633813e-05 all mean 8.603635069448501e-05
0.00012836759560741484 0.00012836759560741484
rl training, epoch5, iter0, batch1110/1133, batch loss:0.00012836759560741484, Training time:99834.01987147331
batch reward last col mean 1.0741127880464774e-05 first col mean 0.0001357517612632364 all mean 4.954334508511238e-05
5.0832175475079566e-05 5.0832175475079566e-05
rl training, epoch5, iter0, batch1111/1133, batch loss:5.0832175475079566e-05, Training time:99851.53298211098
batch reward last col mean 0.00031257374212145805 first col mean 4.595882728608558e-06 all mean 0.000254586135270074
0.00023905729176476598 0.00023905729176476598
rl training, epoch5, iter0, batch1112/1133, batch loss:0.00023905729176476598, Training time:99868.8770930767
batch reward last col mean 0.00012300156231503934 first col mean 3.512224429869093e-05 all mean 9.607819811208174e-05
4.4106796849519014e-05 4.410680048749782e-05
rl training, epoch5, iter0, batch1113/1133, batch loss:4.410680048749782e-05, Training time:99886.48200845718
batch reward last col mean 4.8276535380864516e-05 first col mean 2.289461690452299e-06 all mean 8.834607433527708e-05
5.326662721927278e-05 5.326661994331516e-05
rl training, epoch5, iter0, batch1114/1133, batch loss:5.326661994331516e-05, Training time:99903.64484524727
batch reward last col mean 0.000101333404018078 first col mean 0.00014551798813045025 all mean 9.015546675072983e-05
5.681641414412297e-05 5.681641414412297e-05
rl training, epoch5, iter0, batch1115/1133, batch loss:5.681641414412297e-05, Training time:99921.7051358223
batch reward last col mean 2.8743609163939254e-06 first col mean 1.5958255517034559e-06 all mean 0.00015666824765503407
7.826688670320436e-05 7.826689397916198e-05
rl training, epoch5, iter0, batch1116/1133, batch loss:7.826689397916198e-05, Training time:99940.76067590714
batch reward last col mean 0.00048699500621296465 first col mean 4.736149548989488e-06 all mean 0.00048555125249549747
0.00010934453894151375 0.00010934453166555613
rl training, epoch5, iter0, batch1117/1133, batch loss:0.00010934453166555613, Training time:99957.62548232079
batch reward last col mean 1.0163819297304144e-06 first col mean 6.665504042757675e-05 all mean 4.4087082642363384e-05
8.39957192511065e-06 8.399566468142439e-06
rl training, epoch5, iter0, batch1118/1133, batch loss:8.399566468142439e-06, Training time:99975.97987914085
batch reward last col mean 3.598212288125069e-06 first col mean 5.3767416829941794e-05 all mean 0.00010755972471088171
3.63546860171482e-05 3.635467874119058e-05
rl training, epoch5, iter0, batch1119/1133, batch loss:3.635467874119058e-05, Training time:99993.19743466377
batch reward last col mean 6.287289579631761e-06 first col mean 0.00021034033852629364 all mean 0.0001033791559166275
0.00038594065699726343 0.00038594065699726343
rl training, epoch5, iter0, batch1120/1133, batch loss:0.00038594065699726343, Training time:100010.46487641335
batch reward last col mean 3.364153371876455e-06 first col mean 5.8657838962972164e-05 all mean 4.1126160795101896e-05
1.4729482245456893e-05 1.472948042646749e-05
rl training, epoch5, iter0, batch1121/1133, batch loss:1.472948042646749e-05, Training time:100027.71298789978
batch reward last col mean 4.4557623368746135e-07 first col mean 0.0002805664262268692 all mean 0.0001029743580147624
1.367345430480782e-05 1.3673440662387293e-05
rl training, epoch5, iter0, batch1122/1133, batch loss:1.3673440662387293e-05, Training time:100046.1928601265
batch reward last col mean 7.982591341715306e-05 first col mean 0.0018111873650923371 all mean 0.0001323383185081184
6.293700425885618e-05 6.293698970694095e-05
rl training, epoch5, iter0, batch1123/1133, batch loss:6.293698970694095e-05, Training time:100064.55528283119
batch reward last col mean 9.446132025914267e-06 first col mean 5.054974735685391e-06 all mean 0.0001866170932771638
0.00011992750660283491 0.00011992750660283491
rl training, epoch5, iter0, batch1124/1133, batch loss:0.00011992750660283491, Training time:100081.71578621864
batch reward last col mean 1.1130590792163275e-05 first col mean 0.00018838219693861902 all mean 8.735061419429258e-05
5.15485844516661e-05 5.15485844516661e-05
rl training, epoch5, iter0, batch1125/1133, batch loss:5.15485844516661e-05, Training time:100099.34864234924
batch reward last col mean 1.211824042002263e-06 first col mean 4.09781159760314e-06 all mean 4.324218025431037e-05
4.151801113039255e-05 4.151802204432897e-05
rl training, epoch5, iter0, batch1126/1133, batch loss:4.151802204432897e-05, Training time:100116.28846716881
batch reward last col mean 1.2299768968659919e-05 first col mean 1.6530074162801611e-06 all mean 6.758238305337727e-05
5.022461118642241e-05 5.0224614824401215e-05
rl training, epoch5, iter0, batch1127/1133, batch loss:5.0224614824401215e-05, Training time:100135.197961092
batch reward last col mean 2.631251118145883e-05 first col mean 6.147681688162265e-06 all mean 9.541535109747201e-05
1.9205546777811833e-05 1.9205548596801236e-05
rl training, epoch5, iter0, batch1128/1133, batch loss:1.9205548596801236e-05, Training time:100154.10176968575
batch reward last col mean 2.0168388346064603e-06 first col mean 5.981702088320162e-06 all mean 0.0001030784405884333
7.621281838510185e-05 7.621281110914424e-05
rl training, epoch5, iter0, batch1129/1133, batch loss:7.621281110914424e-05, Training time:100172.87909269333
batch reward last col mean 2.3894461264717393e-05 first col mean 6.911207492521498e-06 all mean 0.00011866037675645202
5.966869866824709e-05 5.966868047835305e-05
rl training, epoch5, iter0, batch1130/1133, batch loss:5.966868047835305e-05, Training time:100190.18476390839
batch reward last col mean 9.910027984005865e-06 first col mean 2.225463504146319e-05 all mean 9.959348244592547e-05
4.182627162663266e-05 4.182626071269624e-05
rl training, epoch5, iter0, batch1131/1133, batch loss:4.182626071269624e-05, Training time:100208.75028777122
batch reward last col mean 0.0004572844773065299 first col mean 2.805837539199274e-05 all mean 0.00020713765115942806
6.94328555255197e-05 6.943284097360447e-05
rl training, epoch5, iter0, batch1132/1133, batch loss:6.943284097360447e-05, Training time:100227.0232284069
rl training, epoch 5, iter 0, loss:3.186050160057745e-05, Training time:100227.02353668213 
rl epoch 5, begin RL for discriminator...
begin to train d model alone...
cur_epoch: 0
D Training Loss: 0.35423247179465284 Time: 143.4309470653534 s
0.14002268950126914 9.598265953080449e-05 0.21411379950165432
cur_epoch: 1
D Training Loss: 0.34521970240972993 Time: 153.50035429000854 s
0.1360535052952678 5.1499595169529244e-05 0.20911469812269035
cur_epoch: 2
D Training Loss: 0.3432681294189337 Time: 159.9959897994995 s
0.13464584617175998 7.274850321990175e-05 0.2085495346274296
cur_epoch: 3
D Training Loss: 0.34400198001674287 Time: 156.9645552635193 s
0.135311303806589 6.546545366352742e-05 0.20862521041786367
cur_epoch: 4
D Training Loss: 0.3335390222461899 Time: 148.46853518486023 s
0.13022210493696967 4.718043947316077e-05 0.20326973704353224
rl epoch 6, begin RL for generator...
batch reward last col mean 5.942002644587774e-06 first col mean 3.145320442854427e-05 all mean 1.3096014299662784e-05
8.198343493859284e-06 8.198346222343389e-06
rl training, epoch6, iter0, batch0/1133, batch loss:8.198346222343389e-06, Training time:101006.58713459969
batch reward last col mean 1.7789533330869745e-06 first col mean 2.8228187147760764e-06 all mean 4.3471627577673644e-05
1.1106008059869055e-05 1.1106003512395546e-05
rl training, epoch6, iter0, batch1/1133, batch loss:1.1106003512395546e-05, Training time:101026.48156619072
batch reward last col mean 1.692865407676436e-05 first col mean 5.140158100402914e-05 all mean 3.641746297944337e-05
2.0383495211717673e-05 2.0383495211717673e-05
rl training, epoch6, iter0, batch2/1133, batch loss:2.0383495211717673e-05, Training time:101044.11720061302
batch reward last col mean 6.596353614440886e-06 first col mean 1.636924139347684e-06 all mean 8.263856216217391e-06
2.9127484140190063e-06 2.912749323513708e-06
rl training, epoch6, iter0, batch3/1133, batch loss:2.912749323513708e-06, Training time:101061.36708283424
batch reward last col mean 3.188231971762434e-07 first col mean 1.7579826590008452e-06 all mean 1.0151660717383493e-05
3.931856099370634e-06 3.931857463612687e-06
rl training, epoch6, iter0, batch4/1133, batch loss:3.931857463612687e-06, Training time:101078.76747322083
batch reward last col mean 4.575015736918431e-06 first col mean 4.15549220633693e-06 all mean 1.1426059245422948e-05
7.463348538294667e-06 7.463347628799966e-06
rl training, epoch6, iter0, batch5/1133, batch loss:7.463347628799966e-06, Training time:101095.67553329468
batch reward last col mean 1.472685380576877e-05 first col mean 9.787054295884445e-06 all mean 3.226740227546543e-05
5.135302490089089e-05 5.135301762493327e-05
rl training, epoch6, iter0, batch6/1133, batch loss:5.135301762493327e-05, Training time:101112.70360207558
batch reward last col mean 6.506623776658671e-06 first col mean 7.985473530425224e-06 all mean 3.299285162938759e-05
8.84707424120279e-06 8.84706878423458e-06
rl training, epoch6, iter0, batch7/1133, batch loss:8.84706878423458e-06, Training time:101130.40802884102
batch reward last col mean 4.273933154763654e-05 first col mean 5.682967639586423e-06 all mean 2.3058120859786868e-05
7.31603950043791e-06 7.316038136195857e-06
rl training, epoch6, iter0, batch8/1133, batch loss:7.316038136195857e-06, Training time:101148.85425829887
batch reward last col mean 0.00022795960830990225 first col mean 2.475223027431639e-06 all mean 0.00010247923637507483
1.0892208592849784e-05 1.0892208592849784e-05
rl training, epoch6, iter0, batch9/1133, batch loss:1.0892208592849784e-05, Training time:101166.29484510422
batch reward last col mean 2.830028051903355e-07 first col mean 6.188148290675599e-06 all mean 6.43674866296351e-05
6.364342698361725e-05 6.364342698361725e-05
rl training, epoch6, iter0, batch10/1133, batch loss:6.364342698361725e-05, Training time:101184.24372553825
batch reward last col mean 5.8471582633501384e-06 first col mean 1.3000320905121043e-05 all mean 2.154055255232379e-05
2.981358193210326e-05 2.981358193210326e-05
rl training, epoch6, iter0, batch11/1133, batch loss:2.981358193210326e-05, Training time:101202.70985341072
batch reward last col mean 5.303596117300913e-05 first col mean 7.2090265348379035e-06 all mean 3.5327975638210773e-05
9.376722118759062e-06 9.376723937748466e-06
rl training, epoch6, iter0, batch12/1133, batch loss:9.376723937748466e-06, Training time:101220.16654729843
batch reward last col mean 0.0011505854781717062 first col mean 3.83575570594985e-06 all mean 0.00017119884432759136
5.6398846936644986e-05 5.639885057462379e-05
rl training, epoch6, iter0, batch13/1133, batch loss:5.639885057462379e-05, Training time:101238.98747825623
batch reward last col mean 4.4170079490868375e-05 first col mean 5.537263859878294e-06 all mean 4.377040022518486e-05
1.6868678358150646e-05 1.686868017714005e-05
rl training, epoch6, iter0, batch14/1133, batch loss:1.686868017714005e-05, Training time:101255.94509530067
batch reward last col mean 6.94552227287204e-06 first col mean 8.597618943895213e-06 all mean 2.0651221348089166e-05
1.1251913747400977e-05 1.1251909199927468e-05
rl training, epoch6, iter0, batch15/1133, batch loss:1.1251909199927468e-05, Training time:101275.86138439178
batch reward last col mean 2.3268389668373857e-06 first col mean 4.565770723274909e-06 all mean 2.9602524591609836e-05
9.021632649819367e-06 9.021635378303472e-06
rl training, epoch6, iter0, batch16/1133, batch loss:9.021635378303472e-06, Training time:101293.73597359657
batch reward last col mean 3.1406807465828024e-06 first col mean 3.5806074265565258e-06 all mean 9.420134119864088e-06
3.5057998957199743e-06 3.505799213598948e-06
rl training, epoch6, iter0, batch17/1133, batch loss:3.505799213598948e-06, Training time:101311.5690639019
batch reward last col mean 4.9696634960127994e-05 first col mean 0.00026200481806881726 all mean 4.4447428081184626e-05
1.3461703019856941e-05 1.3461708476825152e-05
rl training, epoch6, iter0, batch18/1133, batch loss:1.3461708476825152e-05, Training time:101330.21379995346
batch reward last col mean 1.2242448974575382e-05 first col mean 3.1503968784818426e-05 all mean 3.323928467580117e-05
1.1953554349020123e-05 1.1953555258514825e-05
rl training, epoch6, iter0, batch19/1133, batch loss:1.1953555258514825e-05, Training time:101349.24444079399
batch reward last col mean 4.266837549948832e-06 first col mean 2.7374078854336403e-05 all mean 1.697942934697494e-05
9.972131920221727e-06 9.972131010727026e-06
rl training, epoch6, iter0, batch20/1133, batch loss:9.972131010727026e-06, Training time:101366.4405465126
batch reward last col mean 1.7557796354594757e-06 first col mean 2.2542001261172118e-06 all mean 1.510240417701425e-05
3.4835773021768546e-06 3.4835732094506966e-06
rl training, epoch6, iter0, batch21/1133, batch loss:3.4835732094506966e-06, Training time:101385.4826836586
batch reward last col mean 4.1111750761047006e-05 first col mean 1.759410042723175e-05 all mean 2.182796197303105e-05
1.9789464204222895e-05 1.9789464204222895e-05
rl training, epoch6, iter0, batch22/1133, batch loss:1.9789464204222895e-05, Training time:101402.94848275185
batch reward last col mean 1.1321376405248884e-06 first col mean 3.1072595447767526e-05 all mean 9.76747560343938e-06
4.703571903519332e-06 4.70357053927728e-06
rl training, epoch6, iter0, batch23/1133, batch loss:4.70357053927728e-06, Training time:101420.12701654434
batch reward last col mean 1.0739190656749997e-06 first col mean 4.53043639936368e-06 all mean 1.9356772099854425e-05
9.555570613883901e-06 9.555570613883901e-06
rl training, epoch6, iter0, batch24/1133, batch loss:9.555570613883901e-06, Training time:101439.3154528141
batch reward last col mean 1.3419881724985316e-05 first col mean 1.515258463768987e-05 all mean 4.4166026782477275e-05
8.383394015254453e-05 8.383395470445976e-05
rl training, epoch6, iter0, batch25/1133, batch loss:8.383395470445976e-05, Training time:101457.99548530579
batch reward last col mean 1.6439730643469375e-06 first col mean 5.302862064127112e-06 all mean 1.5110460481082555e-05
3.319393044876051e-06 3.319393499623402e-06
rl training, epoch6, iter0, batch26/1133, batch loss:3.319393499623402e-06, Training time:101476.37063884735
batch reward last col mean 0.0001893351727630943 first col mean 1.0517013834032696e-05 all mean 0.00010460137127665803
3.637568079284392e-05 3.6375691706780344e-05
rl training, epoch6, iter0, batch27/1133, batch loss:3.6375691706780344e-05, Training time:101493.48036885262
batch reward last col mean 5.6046170357149094e-05 first col mean 0.0008773519075475633 all mean 5.194173354539089e-05
3.0092562155914493e-05 3.0092567612882704e-05
rl training, epoch6, iter0, batch28/1133, batch loss:3.0092567612882704e-05, Training time:101510.9965941906
batch reward last col mean 1.160062083727098e-06 first col mean 3.72299509763252e-05 all mean 5.259965473669581e-05
5.386546763475053e-05 5.38654530828353e-05
rl training, epoch6, iter0, batch29/1133, batch loss:5.38654530828353e-05, Training time:101528.70976090431
batch reward last col mean 2.6824830001714872e-06 first col mean 6.621310603804886e-06 all mean 3.623537122621201e-05
3.088047378696501e-05 3.088047378696501e-05
rl training, epoch6, iter0, batch30/1133, batch loss:3.088047378696501e-05, Training time:101546.966796875
batch reward last col mean 3.7191341107245535e-05 first col mean 9.511186362942681e-07 all mean 1.0860105248866603e-05
8.099125807348173e-06 8.099126716842875e-06
rl training, epoch6, iter0, batch31/1133, batch loss:8.099126716842875e-06, Training time:101563.98513865471
batch reward last col mean 9.148407684733684e-07 first col mean 2.9028145945630968e-05 all mean 5.3714051318820566e-05
5.234145646682009e-05 5.234145646682009e-05
rl training, epoch6, iter0, batch32/1133, batch loss:5.234145646682009e-05, Training time:101581.29891681671
batch reward last col mean 2.101357858919073e-05 first col mean 2.375590156589169e-06 all mean 3.979522443842143e-05
1.323507876804797e-05 1.3235085134510882e-05
rl training, epoch6, iter0, batch33/1133, batch loss:1.3235085134510882e-05, Training time:101601.31698870659
batch reward last col mean 9.497587143414421e-07 first col mean 2.0228990251780488e-06 all mean 1.939239700732287e-05
5.877287549083121e-06 5.877287549083121e-06
rl training, epoch6, iter0, batch34/1133, batch loss:5.877287549083121e-06, Training time:101620.39320397377
batch reward last col mean 1.3968854091217509e-06 first col mean 1.4725312666996615e-06 all mean 2.2818805518909357e-05
3.294154339528177e-06 3.294150246802019e-06
rl training, epoch6, iter0, batch35/1133, batch loss:3.294150246802019e-06, Training time:101637.50450515747
batch reward last col mean 4.116113814234268e-06 first col mean 1.210794744110899e-05 all mean 4.2565938201732934e-05
1.544254701002501e-05 1.54425415530568e-05
rl training, epoch6, iter0, batch36/1133, batch loss:1.54425415530568e-05, Training time:101654.8183298111
batch reward last col mean 8.576087680012279e-07 first col mean 1.152669847215293e-05 all mean 3.431552977417596e-05
1.6403724657720886e-05 1.6403724657720886e-05
rl training, epoch6, iter0, batch37/1133, batch loss:1.6403724657720886e-05, Training time:101673.69841766357
batch reward last col mean 2.7418986974225845e-06 first col mean 2.6804948447534116e-06 all mean 1.2863799383922014e-05
3.0750616133445874e-05 3.075061977142468e-05
rl training, epoch6, iter0, batch38/1133, batch loss:3.075061977142468e-05, Training time:101692.56760525703
batch reward last col mean 1.38080781653116e-06 first col mean 7.557648132205941e-06 all mean 2.1488989659701474e-05
8.49530169944046e-06 8.495299880451057e-06
rl training, epoch6, iter0, batch39/1133, batch loss:8.495299880451057e-06, Training time:101711.42131519318
batch reward last col mean 3.155703961965628e-05 first col mean 6.15062344877515e-06 all mean 3.948163794120774e-05
1.647728458920028e-05 1.6477286408189684e-05
rl training, epoch6, iter0, batch40/1133, batch loss:1.6477286408189684e-05, Training time:101728.71981072426
batch reward last col mean 5.7767724683799315e-06 first col mean 8.842383749652072e-07 all mean 1.1734866347978823e-05
4.226749297231436e-06 4.226747478242032e-06
rl training, epoch6, iter0, batch41/1133, batch loss:4.226747478242032e-06, Training time:101747.90505242348
batch reward last col mean 1.7191290453411057e-06 first col mean 6.186423433973687e-06 all mean 2.5573770471964963e-05
1.3625180145027116e-05 1.3625180145027116e-05
rl training, epoch6, iter0, batch42/1133, batch loss:1.3625180145027116e-05, Training time:101767.1766769886
batch reward last col mean 1.2565969882416539e-06 first col mean 1.0881845810217783e-05 all mean 2.59219559666235e-05
2.8535354431369342e-05 2.853535261237994e-05
rl training, epoch6, iter0, batch43/1133, batch loss:2.853535261237994e-05, Training time:101784.24073004723
batch reward last col mean 9.72766792983748e-06 first col mean 1.4795587958360557e-05 all mean 2.3873813915997744e-05
1.4333436411106959e-05 1.433343732060166e-05
rl training, epoch6, iter0, batch44/1133, batch loss:1.433343732060166e-05, Training time:101801.36088466644
batch reward last col mean 1.0435401236463804e-05 first col mean 3.819911853497615e-06 all mean 3.8709695218130946e-05
1.6036499800975434e-05 1.6036496162996627e-05
rl training, epoch6, iter0, batch45/1133, batch loss:1.6036496162996627e-05, Training time:101820.10750126839
batch reward last col mean 6.591883447981672e-07 first col mean 7.888276741141453e-06 all mean 2.024336572503671e-05
7.33824708731845e-06 7.338245268329047e-06
rl training, epoch6, iter0, batch46/1133, batch loss:7.338245268329047e-06, Training time:101837.64861679077
batch reward last col mean 1.848022634476365e-06 first col mean 2.6190868993580807e-06 all mean 8.818548849376384e-06
3.672837465273915e-06 3.6728372379002394e-06
rl training, epoch6, iter0, batch47/1133, batch loss:3.6728372379002394e-06, Training time:101856.20402359962
batch reward last col mean 1.440493974769197e-06 first col mean 1.3624276107293554e-05 all mean 1.8381848349235952e-05
9.418471563549247e-06 9.418474292033352e-06
rl training, epoch6, iter0, batch48/1133, batch loss:9.418474292033352e-06, Training time:101873.53753685951
batch reward last col mean 1.0026728887169156e-06 first col mean 9.364012498735974e-07 all mean 1.2364568647171836e-05
1.2609943041752558e-05 1.2609943041752558e-05
rl training, epoch6, iter0, batch49/1133, batch loss:1.2609943041752558e-05, Training time:101890.58905005455
batch reward last col mean 3.5631005630420987e-06 first col mean 5.103847797727212e-05 all mean 2.0446977941901423e-05
8.509555300406646e-06 8.50955711939605e-06
rl training, epoch6, iter0, batch50/1133, batch loss:8.50955711939605e-06, Training time:101907.80274891853
batch reward last col mean 5.724738457502099e-06 first col mean 8.241267642006278e-05 all mean 2.777644112939015e-05
2.1553853002842516e-05 2.155384936486371e-05
rl training, epoch6, iter0, batch51/1133, batch loss:2.155384936486371e-05, Training time:101924.97429656982
batch reward last col mean 1.4874894986860454e-06 first col mean 2.064843783955439e-06 all mean 7.1271001615969e-06
2.8017029762850143e-06 2.801702294163988e-06
rl training, epoch6, iter0, batch52/1133, batch loss:2.801702294163988e-06, Training time:101942.465539217
batch reward last col mean 0.006967152468860149 first col mean 7.780775194987655e-05 all mean 0.006374475546181202
0.00087560253450647 0.00087560253450647
rl training, epoch6, iter0, batch53/1133, batch loss:0.00087560253450647, Training time:101959.44080376625
batch reward last col mean 2.71936846729659e-06 first col mean 5.646158570016269e-06 all mean 2.4214910808950663e-05
1.0399106940894853e-05 1.0399100574431941e-05
rl training, epoch6, iter0, batch54/1133, batch loss:1.0399100574431941e-05, Training time:101978.24194812775
batch reward last col mean 6.151270645204931e-05 first col mean 8.229163540818263e-06 all mean 5.3979169024387375e-05
4.3741209083236754e-05 4.3741209083236754e-05
rl training, epoch6, iter0, batch55/1133, batch loss:4.3741209083236754e-05, Training time:101997.22636651993
batch reward last col mean 4.737336894322652e-06 first col mean 6.450324235629523e-06 all mean 1.0561048839008436e-05
5.56601480639074e-06 5.5660166253801435e-06
rl training, epoch6, iter0, batch56/1133, batch loss:5.5660166253801435e-06, Training time:102015.86492562294
batch reward last col mean 1.701625660643913e-05 first col mean 0.0003697871579788625 all mean 5.3512045269599184e-05
6.559698522323743e-05 6.559698522323743e-05
rl training, epoch6, iter0, batch57/1133, batch loss:6.559698522323743e-05, Training time:102034.04876637459
batch reward last col mean 5.3812391342944466e-06 first col mean 2.550995304773096e-05 all mean 6.531194230774418e-05
5.329206396709196e-05 5.3292060329113156e-05
rl training, epoch6, iter0, batch58/1133, batch loss:5.3292060329113156e-05, Training time:102051.44207930565
batch reward last col mean 0.00036577708669938147 first col mean 1.1295172726022429e-06 all mean 2.2339143470162526e-05
4.482207805267535e-05 4.482207077671774e-05
rl training, epoch6, iter0, batch59/1133, batch loss:4.482207077671774e-05, Training time:102069.51661872864
batch reward last col mean 0.00022201024694368243 first col mean 8.281315240310505e-05 all mean 0.00015545639325864613
1.622891431907192e-05 1.622891068109311e-05
rl training, epoch6, iter0, batch60/1133, batch loss:1.622891068109311e-05, Training time:102087.21732997894
batch reward last col mean 2.2538176835951163e-06 first col mean 0.0002689854009076953 all mean 2.424353988317307e-05
8.755583621677943e-06 8.75558271218324e-06
rl training, epoch6, iter0, batch61/1133, batch loss:8.75558271218324e-06, Training time:102105.47369718552
batch reward last col mean 2.0436041268112604e-06 first col mean 7.745057519059628e-05 all mean 1.2527911167126149e-05
3.3082685604313156e-06 3.308268787804991e-06
rl training, epoch6, iter0, batch62/1133, batch loss:3.308268787804991e-06, Training time:102123.14417243004
batch reward last col mean 1.1914820788661018e-05 first col mean 5.464340574690141e-05 all mean 4.082926534465514e-05
4.747662751469761e-05 4.747662751469761e-05
rl training, epoch6, iter0, batch63/1133, batch loss:4.747662751469761e-05, Training time:102141.46507906914
batch reward last col mean 1.7133708070105058e-06 first col mean 0.00010119533544639125 all mean 8.775652531767264e-05
0.0002904993307311088 0.0002904993307311088
rl training, epoch6, iter0, batch64/1133, batch loss:0.0002904993307311088, Training time:102158.46697616577
batch reward last col mean 1.5334205727413064e-06 first col mean 2.657869117683731e-06 all mean 2.0967754608136602e-05
2.7415358999860473e-05 2.7415358999860473e-05
rl training, epoch6, iter0, batch65/1133, batch loss:2.7415358999860473e-05, Training time:102175.8369743824
